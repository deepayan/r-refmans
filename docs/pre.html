<!DOCTYPE html><html><head><title>Help for package pre</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {pre}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bsnullinteract'><p>Compute bootstrapped null interaction prediction rule ensembles</p></a></li>
<li><a href='#caret_pre_model'><p>Model set up for train function of package caret</p></a></li>
<li><a href='#carrillo'><p>Data on personality characteristics and depressive symptom severity</p></a></li>
<li><a href='#coef.gpe'><p>Coefficients for a General Prediction Ensemble (gpe)</p></a></li>
<li><a href='#coef.pre'><p>Coefficients for the final prediction rule ensemble</p></a></li>
<li><a href='#corplot'><p>Plot correlations between baselearners in a prediction rule ensemble (pre)</p></a></li>
<li><a href='#cvpre'><p>Full k-fold cross validation of a prediction rule ensemble (pre)</p></a></li>
<li><a href='#explain'><p>Explain predictions from final prediction rule ensemble</p></a></li>
<li><a href='#gpe'><p>Derive a General Prediction Ensemble (gpe)</p></a></li>
<li><a href='#gpe_cv.glmnet'><p>Default penalized trainer for gpe</p></a></li>
<li><a href='#gpe_rules_pre'><p>Get rule learner for gpe which mimics behavior of pre</p></a></li>
<li><a href='#gpe_sample'><p>Sampling Function Generator for gpe</p></a></li>
<li><a href='#gpe_trees'><p>Learner Functions Generators for gpe</p></a></li>
<li><a href='#importance.pre'><p>Calculate importances of baselearners and input variables in a prediction</p>
rule ensemble (pre)</a></li>
<li><a href='#interact'><p>Calculate interaction statistics for variables in a prediction rule ensemble</p>
(pre)</a></li>
<li><a href='#maxdepth_sampler'><p>Sampling function generator for specifying varying maximum tree depth</p>
in a prediction rule ensemble (pre)</a></li>
<li><a href='#mi_mean'><p>Compute the average dataset over imputed datasets.</p></a></li>
<li><a href='#mi_pre'><p>Fit a prediction rule ensemble to multiply-imputed data (experimental)</p></a></li>
<li><a href='#pairplot'><p>Create partial dependence plot for a pair of predictor variables in a prediction</p>
rule ensemble (pre)</a></li>
<li><a href='#plot.pre'><p>Plot method for class pre</p></a></li>
<li><a href='#pre'><p>Derive a prediction rule ensemble</p></a></li>
<li><a href='#predict.gpe'><p>Predicted values based on gpe ensemble</p></a></li>
<li><a href='#predict.pre'><p>Predicted values based on final prediction rule ensemble</p></a></li>
<li><a href='#print.gpe'><p>Print a General Prediction Ensemble (gpe)</p></a></li>
<li><a href='#print.pre'><p>Print method for objects of class pre</p></a></li>
<li><a href='#prune_pre'><p>Get the optimal lambda and gamma parameter values for an ensemble of given size</p></a></li>
<li><a href='#rare_level_sampler'><p>Dealing with rare factor levels in fitting prediction rule ensembles.</p></a></li>
<li><a href='#rTerm'><p>Wrapper Functions for terms in gpe</p></a></li>
<li><a href='#singleplot'><p>Create partial dependence plot for a single variable in a prediction rule</p>
ensemble (pre)</a></li>
<li><a href='#summary.gpe'><p>Summary method for a General Prediction Ensemble (gpe)</p></a></li>
<li><a href='#summary.pre'><p>Summary method for objects of class pre</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Prediction Rule Ensembles</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.7</td>
</tr>
<tr>
<td>Author:</td>
<td>Marjolein Fokkema [aut, cre],
  Benjamin Christoffersen [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Marjolein Fokkema &lt;m.fokkema@fsw.leidenuniv.nl&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Derives prediction rule ensembles (PREs). Largely follows the
    procedure for deriving PREs as described in Friedman &amp; Popescu (2008; 
    &lt;<a href="https://doi.org/10.1214%2F07-AOAS148">doi:10.1214/07-AOAS148</a>&gt;), with adjustments and improvements. The 
    main function pre() derives prediction rule ensembles consisting of 
    rules and/or linear terms for continuous, binary, count, multinomial, 
    and multivariate continuous responses. Function gpe() derives 
    generalized prediction ensembles, consisting of rules, hinge and linear 
    functions of the predictor variables.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/marjoleinF/pre">https://github.com/marjoleinF/pre</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/marjoleinF/pre/issues">https://github.com/marjoleinF/pre/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>earth, Formula, glmnet, graphics, methods, partykit (&ge;
1.2-0), rpart, stringr, survival, Matrix, MatrixModels</td>
</tr>
<tr>
<td>Suggests:</td>
<td>interp, datasets, doParallel, foreach, glmertree, grid,
mlbench, testthat, mboost, ggplot2, caret, pROC, knitr,
rmarkdown, mice, shape</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-12 15:44:17 UTC; fokkemam</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-12 19:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='bsnullinteract'>Compute bootstrapped null interaction prediction rule ensembles</h2><span id='topic+bsnullinteract'></span>

<h3>Description</h3>

<p><code>bsnullinteract</code> generates bootstrapped null interaction models,
which can be used to derive a reference distribution of the test statistic
calculated with <code><a href="#topic+interact">interact</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bsnullinteract(
  object,
  nsamp = 10,
  parallel = FALSE,
  penalty.par.val = "lambda.1se",
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bsnullinteract_+3A_object">object</code></td>
<td>
<p>object of class <code><a href="#topic+pre">pre</a></code>.</p>
</td></tr>
<tr><td><code id="bsnullinteract_+3A_nsamp">nsamp</code></td>
<td>
<p>numeric. Number of bootstrapped null interaction models to be
derived.</p>
</td></tr>
<tr><td><code id="bsnullinteract_+3A_parallel">parallel</code></td>
<td>
<p>logical. Should parallel foreach be used to generate initial
ensemble? Must register parallel beforehand, such as doMC or others.</p>
</td></tr>
<tr><td><code id="bsnullinteract_+3A_penalty.par.val">penalty.par.val</code></td>
<td>
<p>character or numeric. Value of the penalty parameter
<code class="reqn">\lambda</code> to be employed for selecting the final ensemble. The default
<code>"lambda.min"</code> employs the <code class="reqn">\lambda</code> value within 1 standard
error of the minimum cross-validated error. Alternatively, 
<code>"lambda.min"</code> may be specified, to employ the <code class="reqn">\lambda</code> value
with minimum cross-validated error, or a numeric value <code class="reqn">&gt;0</code> may be 
specified, with higher values yielding a sparser ensemble. To evaluate the 
trade-off between accuracy and sparsity of the final ensemble, inspect
<code>pre_object$glmnet.fit</code> and <code>plot(pre_object$glmnet.fit)</code>.</p>
</td></tr>
<tr><td><code id="bsnullinteract_+3A_verbose">verbose</code></td>
<td>
<p>logical. should progress be printed to the command line?</p>
</td></tr>
<tr><td><code id="bsnullinteract_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to <code><a href="#topic+predict.pre">predict.pre</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that computation of bootstrapped null interaction models is 
computationally intensive. The default number of samples is set to 10,
but for reliable results argument <code>nsamp</code> should be set to a higher
value (e.g., <code class="reqn">\ge 100</code>). 
</p>
<p>See also section 8.3 of Friedman &amp; Popescu (2008).
</p>


<h3>Value</h3>

<p>A list of length <code>nsamp</code> with null interaction models, to be
used as input for <code><a href="#topic+interact">interact</a></code>.
</p>


<h3>References</h3>

<p>Fokkema, M. (2020). Fitting prediction rule ensembles with R 
package pre. <em>Journal of Statistical Software, 92</em>(12), 1-30.
<a href="https://doi.org/10.18637/jss.v092.i12">doi:10.18637/jss.v092.i12</a>
</p>
<p>Friedman, J. H., &amp; Popescu, B. E. (2008). Predictive learning 
via rule ensembles. <em>The Annals of Applied Statistics, 2</em>(3), 916-954,
<a href="https://doi.org/10.1214/07-AOAS148">doi:10.1214/07-AOAS148</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pre">pre</a></code>, <code><a href="#topic+interact">interact</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(42)
airq.ens &lt;- pre(Ozone ~ ., data=airquality[complete.cases(airquality),])
nullmods &lt;- bsnullinteract(airq.ens)
interact(airq.ens, nullmods = nullmods, col = c("#7FBFF5", "#8CC876"))
</code></pre>

<hr>
<h2 id='caret_pre_model'>Model set up for train function of package caret</h2><span id='topic+caret_pre_model'></span>

<h3>Description</h3>

<p><code>caret_pre_model</code> is deprecated and provided for backwards compatibility
only. The object provides a model setup for function <code>train</code> of
package caret. It allows for tuning arguments sampfrac, maxdepth, learnrate, 
mtry, use.grad and penalty.par.val.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>caret_pre_model
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 17.
</p>


<h3>Details</h3>

<p>Object caret_pre_model is deprecated, and only included in package pre for backward 
compatibility. Parameters of function <code>pre()</code> can be tuned by using method 
<code>"pre"</code> in caret's function <code>train()</code>. See vignette on tuning for more
information and examples: <code>vignette("Tuning", package = "pre")</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Object caret_pre_model is only included in package pre for backward compatibility
## By now, function pre can be optimized in the default way by using the method "pre" 
## in caret's function train(). More information and instructions on tuning parameters
## of function pre() are provided in the vignette about tuning, which can be accessed
## from R by typing:
##
## vignette("Tuning", package = "pre")
##
</code></pre>

<hr>
<h2 id='carrillo'>Data on personality characteristics and depressive symptom severity</h2><span id='topic+carrillo'></span>

<h3>Description</h3>

<p>Dataset from a study by Carrillo et al. (2001), who assessed the extent to 
which the subscales of the NEO Personality Inventory (NEO-PI; Costa and 
McCrae 1985) could predict depressive symptomatology, as measured by the 
Beck Depression Inventory (BDI; Beck, Steer, and Carbin 1988). The NEO-PI 
assesses five major personality dimensions (Neuroticism, Extraversion, 
Openness to Experience, Agreeableness and Conscientiousness). Each of these
dimensions consist of six specific subtraits (facets). The NEO-PI and BDI 
were administered to 112 Spanish respondents. Respondents' age in years and 
sex were also recorded and included in the dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(carrillo)
</code></pre>


<h3>Format</h3>

<p>A data frame with 112 observations and 26 variables
</p>


<h3>Details</h3>


<ul>
<li><p> neuroticism facet and total scores: n1, n2, n3, n4, n5, n6, ntot
</p>
</li>
<li><p> extraversion facet and total scores: e1, e2, e3, e4, e5, e6, etot
</p>
</li>
<li><p> openness to experience facet and total scores: open1, open2, open3, 
open4, open5, open6, opentot
</p>
</li>
<li><p> altruism total score: altot
</p>
</li>
<li><p> conscientiousness total score: contot
</p>
</li>
<li><p> depression symptom severity: bdi
</p>
</li>
<li><p> sex: sexo
</p>
</li>
<li><p> age in years: edad
</p>
</li></ul>



<h3>References</h3>

<p>Beck, A.T., Steer, R.A. &amp; Carbin, M.G. (1988). Psychometric 
properties of the Beck Depression Inventory: Twenty-five years of 
evaluation. <em>Clinical Psychology Review, 8</em>(1), 77-100.
</p>
<p>Carrillo, J. M., Rojo, N., Sanchez-Bernardos, M. L., &amp; Avia, 
M. D. (2001). Openness to experience and depression. <em>European Journal 
of Psychological Assessment, 17</em>(2), 130.
</p>
<p>Costa, P.T. &amp; McCrae, R.R. (1985). <em>The NEO Personality Inventory.</em>
Psychological Assessment Resources, Odessa, FL.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("carrillo")
summary(carrillo)

</code></pre>

<hr>
<h2 id='coef.gpe'>Coefficients for a General Prediction Ensemble (gpe)</h2><span id='topic+coef.gpe'></span>

<h3>Description</h3>

<p>coef function for <code><a href="#topic+gpe">gpe</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gpe'
coef(object, penalty.par.val = "lambda.1se", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.gpe_+3A_object">object</code></td>
<td>
<p>object of class <code><a href="#topic+pre">pre</a></code></p>
</td></tr>
<tr><td><code id="coef.gpe_+3A_penalty.par.val">penalty.par.val</code></td>
<td>
<p>character or numeric. Value of the penalty parameter
<code class="reqn">\lambda</code> to be employed for selecting the final ensemble. The default
<code>"lambda.min"</code> employs the <code class="reqn">\lambda</code> value within 1 standard
error of the minimum cross-validated error. Alternatively, 
<code>"lambda.min"</code> may be specified, to employ the <code class="reqn">\lambda</code> value
with minimum cross-validated error, or a numeric value <code class="reqn">&gt;0</code> may be 
specified, with higher values yielding a sparser ensemble. To evaluate the 
trade-off between accuracy and sparsity of the final ensemble, inspect
<code>pre_object$glmnet.fit</code> and <code>plot(pre_object$glmnet.fit)</code>.</p>
</td></tr>
<tr><td><code id="coef.gpe_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to <code><a href="glmnet.html#topic+coef.cv.glmnet">coef.cv.glmnet</a></code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+coef.pre">coef.pre</a></code>, <code><a href="#topic+gpe">gpe</a></code>
</p>

<hr>
<h2 id='coef.pre'>Coefficients for the final prediction rule ensemble</h2><span id='topic+coef.pre'></span>

<h3>Description</h3>

<p><code>coef.pre</code> returns coefficients for prediction rules and linear terms in 
the final ensemble
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pre'
coef(object, penalty.par.val = "lambda.1se", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.pre_+3A_object">object</code></td>
<td>
<p>object of class <code><a href="#topic+pre">pre</a></code></p>
</td></tr>
<tr><td><code id="coef.pre_+3A_penalty.par.val">penalty.par.val</code></td>
<td>
<p>character or numeric. Value of the penalty parameter
<code class="reqn">\lambda</code> to be employed for selecting the final ensemble. The default
<code>"lambda.min"</code> employs the <code class="reqn">\lambda</code> value within 1 standard
error of the minimum cross-validated error. Alternatively, 
<code>"lambda.min"</code> may be specified, to employ the <code class="reqn">\lambda</code> value
with minimum cross-validated error, or a numeric value <code class="reqn">&gt;0</code> may be 
specified, with higher values yielding a sparser ensemble. To evaluate the 
trade-off between accuracy and sparsity of the final ensemble, inspect
<code>pre_object$glmnet.fit</code> and <code>plot(pre_object$glmnet.fit)</code>.</p>
</td></tr>
<tr><td><code id="coef.pre_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to <code><a href="glmnet.html#topic+coef.cv.glmnet">coef.cv.glmnet</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In some cases, duplicated variable names may appear in the model.
For example, the first variable is a factor named 'V1' and there are also
variables named 'V10' and/or 'V11' and/or 'V12' (etc). Then for 
for the binary factor V1, dummy contrast variables will be created, named 
'V10', 'V11', 'V12' (etc). As should be clear from this example, this yields 
duplicated variable names, which may yield problems, for example in the 
calculation of predictions and importances, later on. This can be prevented 
by renaming factor variables with numbers in their name, prior to analysis.
</p>


<h3>Value</h3>

<p>returns a dataframe with 3 columns: coefficient, rule (rule or 
variable name) and description (<code>NA</code> for linear terms, conditions for 
rules).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pre">pre</a></code>, <code><a href="#topic+plot.pre">plot.pre</a></code>, 
<code><a href="#topic+cvpre">cvpre</a></code>, <code><a href="#topic+importance.pre">importance.pre</a></code>, <code><a href="#topic+predict.pre">predict.pre</a></code>, 
<code><a href="#topic+interact">interact</a></code>, <code><a href="#topic+print.pre">print.pre</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(42)
airq.ens &lt;- pre(Ozone ~ ., data = airquality[complete.cases(airquality),])
coefs &lt;- coef(airq.ens)
</code></pre>

<hr>
<h2 id='corplot'>Plot correlations between baselearners in a prediction rule ensemble (pre)</h2><span id='topic+corplot'></span>

<h3>Description</h3>

<p><code>corplot</code> plots correlations between baselearners in a prediction rule ensemble
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corplot(
  object,
  penalty.par.val = "lambda.1se",
  colors = NULL,
  fig.plot = c(0, 0.85, 0, 1),
  fig.legend = c(0.8, 0.95, 0, 1),
  legend.breaks = seq(-1, 1, by = 0.1)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corplot_+3A_object">object</code></td>
<td>
<p>object of class pre</p>
</td></tr>
<tr><td><code id="corplot_+3A_penalty.par.val">penalty.par.val</code></td>
<td>
<p>character or numeric. Value of the penalty parameter
<code class="reqn">\lambda</code> to be employed for selecting the final ensemble. The default
<code>"lambda.min"</code> employs the <code class="reqn">\lambda</code> value within 1 standard
error of the minimum cross-validated error. Alternatively, 
<code>"lambda.min"</code> may be specified, to employ the <code class="reqn">\lambda</code> value
with minimum cross-validated error, or a numeric value <code class="reqn">&gt;0</code> may be 
specified, with higher values yielding a sparser ensemble. To evaluate the 
trade-off between accuracy and sparsity of the final ensemble, inspect
<code>pre_object$glmnet.fit</code> and <code>plot(pre_object$glmnet.fit)</code>.</p>
</td></tr>
<tr><td><code id="corplot_+3A_colors">colors</code></td>
<td>
<p>vector of contiguous colors to be used for plotting. If 
<code>colors = NULL</code> (default), <code>colorRampPalette</code> is used to generate
a sequence of 200 colors going from red to white to blue. A different set of 
plotting colors can be specified here, for example: 
<code>cm.colors(100)</code>, <code>rainbow_hcl)(100)</code> (the latter requires
package <code>colorspace</code>). 
or <code>colorRampPalette(c("red", "yellow", "green"))(100)</code>.</p>
</td></tr>
<tr><td><code id="corplot_+3A_fig.plot">fig.plot</code></td>
<td>
<p>plotting region to be used for correlation plot. See 
<code>fig</code> under <code><a href="graphics.html#topic+par">par</a></code>.</p>
</td></tr>
<tr><td><code id="corplot_+3A_fig.legend">fig.legend</code></td>
<td>
<p>plotting region to be used for legend. See <code>fig</code> 
under <code><a href="graphics.html#topic+par">par</a></code>.</p>
</td></tr>
<tr><td><code id="corplot_+3A_legend.breaks">legend.breaks</code></td>
<td>
<p>numeric vector of breakpoints to be depicted in the 
plot's legend. Should be a sequence from -1 to 1.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(42)
airq.ens &lt;- pre(Ozone ~ ., data = airquality[complete.cases(airquality),])
corplot(airq.ens)
</code></pre>

<hr>
<h2 id='cvpre'>Full k-fold cross validation of a prediction rule ensemble (pre)</h2><span id='topic+cvpre'></span>

<h3>Description</h3>

<p><code>cvpre</code> performs k-fold cross validation on the dataset used to create 
the specified prediction rule ensemble, providing an estimate of predictive 
accuracy on future observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvpre(
  object,
  k = 10,
  penalty.par.val = "lambda.1se",
  pclass = 0.5,
  foldids = NULL,
  verbose = FALSE,
  parallel = FALSE,
  print = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvpre_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+pre">pre</a></code>.</p>
</td></tr>
<tr><td><code id="cvpre_+3A_k">k</code></td>
<td>
<p>integer. The number of cross validation folds to be used.</p>
</td></tr>
<tr><td><code id="cvpre_+3A_penalty.par.val">penalty.par.val</code></td>
<td>
<p>character or numeric. Value of the penalty parameter
<code class="reqn">\lambda</code> to be employed for selecting the final ensemble. The default
<code>"lambda.min"</code> employs the <code class="reqn">\lambda</code> value within 1 standard
error of the minimum cross-validated error. Alternatively, 
<code>"lambda.min"</code> may be specified, to employ the <code class="reqn">\lambda</code> value
with minimum cross-validated error, or a numeric value <code class="reqn">&gt;0</code> may be 
specified, with higher values yielding a sparser ensemble. To evaluate the 
trade-off between accuracy and sparsity of the final ensemble, inspect
<code>pre_object$glmnet.fit</code> and <code>plot(pre_object$glmnet.fit)</code>.</p>
</td></tr>
<tr><td><code id="cvpre_+3A_pclass">pclass</code></td>
<td>
<p>numeric. Only used for binary classification. Cut-off value for the 
predicted probabilities that should be used to classify observations to the
second class.</p>
</td></tr>
<tr><td><code id="cvpre_+3A_foldids">foldids</code></td>
<td>
<p>numeric vector of <code>length(nrow(object$data))</code> (the number of
observations in the training data used to fit the original ensemble). Defaults to
<code>NULL</code>, resulting in the original training observations being randomly 
assigned to one of the <code class="reqn">k</code> folds. Depending on sample size, the number of 
factors in the data, the number of factor levels and their distributions, the
default may yield errors. See 'Details'.</p>
</td></tr>
<tr><td><code id="cvpre_+3A_verbose">verbose</code></td>
<td>
<p>logical. Should progress of the cross validation be printed 
to the command line?</p>
</td></tr>
<tr><td><code id="cvpre_+3A_parallel">parallel</code></td>
<td>
<p>logical. Should parallel foreach be used? Must register parallel 
beforehand, such as doMC or others.</p>
</td></tr>
<tr><td><code id="cvpre_+3A_print">print</code></td>
<td>
<p>logical. Should accuracy estimates be printed to the command line?</p>
</td></tr>
<tr><td><code id="cvpre_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to <code><a href="#topic+predict.pre">predict.pre</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The random sampling employed by default may yield folds including all 
observations with a given level of a given factor. This results in an error, 
as it requires predictions for factor levels to be computed that were not 
observed in the training data, which is impossible. By manually specifying the
<code>foldids</code> argument, users can make sure all class levels are represented in
each of the <code class="reqn">k</code> training partitions.
</p>


<h3>Value</h3>

<p>Calculates cross-validated estimates of predictive accuracy and prints 
these to the command line. For survival regression, accuracy is not calculated, 
as there is currently no agreed-upon way to best quantify accuracy in survival 
regression models. Users can compute their own accuracy estimates using the 
(invisibly returned) cross-validated predictions (<code>$cvpreds</code>). 
Invisibly, a list of three objects is returned: 
<code>accuracy</code> (containing accuracy estimates), <code>cvpreds</code>
(containing cross-validated predictions) and <code>fold_indicators</code> (a vector indicating
the cross validation fold each observation was part of). For (multivariate) continuous 
outcomes, accuracy is a list with elements <code>$MSE</code> (mean squared error on test 
observations) and <code>$MAE</code> (mean absolute error on test observations). For 
(binary and multiclass) classification, accuracy is a list with elements 
<code>$SEL</code> (mean squared error on predicted probabilities), <code>$AEL</code> (mean absolute 
error on predicted probabilities), <code>$MCR</code> (average misclassification error rate) 
and <code>$table</code> (proportion table with (mis)classification rates).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pre">pre</a></code>, <code><a href="#topic+plot.pre">plot.pre</a></code>, 
<code><a href="#topic+coef.pre">coef.pre</a></code>, <code><a href="#topic+importance.pre">importance.pre</a></code>, <code><a href="#topic+predict.pre">predict.pre</a></code>, 
<code><a href="#topic+interact">interact</a></code>, <code><a href="#topic+print.pre">print.pre</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(42)
airq.ens &lt;- pre(Ozone ~ ., data = airquality[complete.cases(airquality),])
airq.cv &lt;- cvpre(airq.ens)
</code></pre>

<hr>
<h2 id='explain'>Explain predictions from final prediction rule ensemble</h2><span id='topic+explain'></span>

<h3>Description</h3>

<p><code>explain</code> shows which rules apply to which observations and visualizes
the contribution of rules and linear predictors to the predicted values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>explain(
  object,
  newdata,
  penalty.par.val = "lambda.1se",
  response = 1L,
  plot = TRUE,
  intercept = FALSE,
  center.linear = FALSE,
  plot.max.nobs = 4,
  plot.dim = c(2, 2),
  plot.obs.names = TRUE,
  pred.type = "response",
  digits = 3L,
  cex = 0.8,
  ylab = "Contribution to linear predictor",
  bar.col = c("#E495A5", "#39BEB1"),
  rule.col = "darkgrey",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="explain_+3A_object">object</code></td>
<td>
<p>object of class <code><a href="#topic+pre">pre</a></code>.</p>
</td></tr>
<tr><td><code id="explain_+3A_newdata">newdata</code></td>
<td>
<p>optional dataframe of new (test) observations, including all
predictor variables used for deriving the prediction rule ensemble.</p>
</td></tr>
<tr><td><code id="explain_+3A_penalty.par.val">penalty.par.val</code></td>
<td>
<p>character or numeric. Value of the penalty parameter
<code class="reqn">\lambda</code> to be employed for selecting the final ensemble. The default
<code>"lambda.min"</code> employs the <code class="reqn">\lambda</code> value within 1 standard
error of the minimum cross-validated error. Alternatively, 
<code>"lambda.min"</code> may be specified, to employ the <code class="reqn">\lambda</code> value
with minimum cross-validated error, or a numeric value <code class="reqn">&gt;0</code> may be 
specified, with higher values yielding a sparser ensemble. To evaluate the 
trade-off between accuracy and sparsity of the final ensemble, inspect
<code>pre_object$glmnet.fit</code> and <code>plot(pre_object$glmnet.fit)</code>.</p>
</td></tr>
<tr><td><code id="explain_+3A_response">response</code></td>
<td>
<p>numeric or character vector of length one. Specifies the
name or number of the response variable (for multivariate responses) or
the name or number of the factor level (for multinomial responses) for 
which explanations and contributions should be computed and/or plotted.
Only used for<code>pre</code>s fitted to multivariate or multinomial responses.</p>
</td></tr>
<tr><td><code id="explain_+3A_plot">plot</code></td>
<td>
<p>logical. Should explanations be plotted?</p>
</td></tr>
<tr><td><code id="explain_+3A_intercept">intercept</code></td>
<td>
<p>logical. Specifies whether intercept should be included in
explaining predictions.</p>
</td></tr>
<tr><td><code id="explain_+3A_center.linear">center.linear</code></td>
<td>
<p>logical. Specifies whether linear terms should be
centered with respect to the training sample mean before computing their 
contribution to the predicted value. If <code>intercept = TRUE</code>, this
will also affect the intercept. That is, the value of the intercept returned
will differ from that of the value returned by the <code>print</code> method.</p>
</td></tr>
<tr><td><code id="explain_+3A_plot.max.nobs">plot.max.nobs</code></td>
<td>
<p>numeric. Specifies maximum number of observations
for which explanations will be plotted. The default (<code>4</code>) plots the
explanation for the first four observations supplied in <code>newdata</code>.</p>
</td></tr>
<tr><td><code id="explain_+3A_plot.dim">plot.dim</code></td>
<td>
<p>numeric vector of length 2. Specifies the number of rows and
columns in the resulting plot.</p>
</td></tr>
<tr><td><code id="explain_+3A_plot.obs.names">plot.obs.names</code></td>
<td>
<p>logical vector of length 1, NULL, or character vector 
of length <code>nrow(data)</code> supplying the names that should be used for
individual observations' plots. If <code>TRUE</code> (default), 
<code>rownames(newdata)</code> will be used as titles. If <code>NULL</code>,
<code>paste("Observation", 1:nrow(newdata))</code> will be used as titles. If 
<code>FALSE</code>, no titles will be plotted.</p>
</td></tr>
<tr><td><code id="explain_+3A_pred.type">pred.type</code></td>
<td>
<p>character. Specifies the type of predicted values to be 
computed, returned and provided in the plot(s). Note that the computed 
contributions must be additive and are therefore always on the scale of 
the linear predictor.</p>
</td></tr>
<tr><td><code id="explain_+3A_digits">digits</code></td>
<td>
<p>integer. Specifies the number of digits used in depcting the
predicted values in the plot.</p>
</td></tr>
<tr><td><code id="explain_+3A_cex">cex</code></td>
<td>
<p>numeric. Specifies the relative text size of title, tick and axis
labels.</p>
</td></tr>
<tr><td><code id="explain_+3A_ylab">ylab</code></td>
<td>
<p>character. Specifies the label for the horizonantal (y-) axis.</p>
</td></tr>
<tr><td><code id="explain_+3A_bar.col">bar.col</code></td>
<td>
<p>character vector of length two. Specifies the colors to be used for
plotting the positive and negative contributions to the predictions, respectively.</p>
</td></tr>
<tr><td><code id="explain_+3A_rule.col">rule.col</code></td>
<td>
<p>character. Specifies the color to be used for plotting the rule
descriptions. If <code>NULL</code>, rule descriptions are not plotted.</p>
</td></tr>
<tr><td><code id="explain_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to <code><a href="#topic+predict.pre">predict.pre</a></code> and 
<code><a href="glmnet.html#topic+predict.cv.glmnet">predict.cv.glmnet</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Provides a graphical depiction of the contribution of rules and
linear terms to the individual predictions (if <code>plot = TRUE</code>.
Invisibly returns a list with objects <code>predictors</code> and
<code>contribution</code>. <code>predictors</code> contains the values of the rules and
linear terms for each observation in <code>newdata</code>, for those rules
and linear terms included in the final ensemble with the specified
value of <code>penalty.par.val</code>. <code>contribution</code> contains the
values of <code>predictors</code>, multiplied by the estimated values
of the coefficients in the final ensemble selected with the
specified value of <code>penalty.par.val</code>.
All contributions are calculated w.r.t. the intercept, by default.
Thus, if a given rule applies to an observation in <code>newdata</code>, 
the contribution of that rule equals the estimated coefficient of
that rule. If a given rule does not apply to an observation in
<code>newdata</code>, the contribution of that rule equals 0. 
For linear terms, contributions can be centered, or not (the default).
Thus, by default the contribution of a linear terms for an 
observation in <code>newdata</code> equals the obeservation's value of the 
linear term, times the estimated coefficient of the linear term.
If <code>center.linear = TRUE</code>, the contribution of a linear term 
for an observation in <code>newdata</code> equals (the value of the linear
temr, minus the mean value of the linear term in the training data)
times the estimated coefficient for the linear term.
</p>


<h3>References</h3>

<p>Fokkema, M. &amp; Strobl, C. (2020). Fitting prediction rule 
ensembles to psychological research data: An introduction and tutorial. 
<em>Psychological Methods 25</em>(5), 636-652. <a href="https://doi.org/10.1037/met0000256">doi:10.1037/met0000256</a>,
<a href="https://arxiv.org/abs/1907.05302">https://arxiv.org/abs/1907.05302</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pre">pre</a></code>, <code><a href="#topic+plot.pre">plot.pre</a></code>,
<code><a href="#topic+coef.pre">coef.pre</a></code>, <code><a href="#topic+importance.pre">importance.pre</a></code>, <code><a href="#topic+cvpre">cvpre</a></code>,
<code><a href="#topic+interact">interact</a></code>, <code><a href="#topic+print.pre">print.pre</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>airq &lt;- airquality[complete.cases(airquality), ]
set.seed(1)
train &lt;- sample(1:nrow(airq), size = 100)
set.seed(42)
airq.ens &lt;- pre(Ozone ~ ., data = airq[train,])
airq.ens.exp &lt;- explain(airq.ens, newdata = airq[-train,])
airq.ens.exp$predictors
airq.ens.exp$contribution

## Can also include intercept in explanation:
airq.ens.exp &lt;- explain(airq.ens, newdata = airq[-train,])

## Fit PRE with linear terms only to illustrate effect of center.linear:
set.seed(42)
airq.ens2 &lt;- pre(Ozone ~ ., data = airq[train,], type = "linear")
## When not centered around their means, Month has negative and 
##   Day has positive contribution:
explain(airq.ens2, newdata = airq[-train,][1:2,],
        penalty.par.val = "lambda.min")$contribution
## After mean centering, contributions of Month and Day have switched
##   sign (for these two observations): 
explain(airq.ens2, newdata = airq[-train,][1:2,], 
        penalty.par.val = "lambda.min", center.linear = TRUE)$contribution

</code></pre>

<hr>
<h2 id='gpe'>Derive a General Prediction Ensemble (gpe)</h2><span id='topic+gpe'></span>

<h3>Description</h3>

<p>Provides an interface for deriving sparse prediction ensembles where basis functions are selected through L1 penalization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpe(
  formula,
  data,
  base_learners = list(gpe_trees(), gpe_linear()),
  weights = rep(1, times = nrow(data)),
  sample_func = gpe_sample(),
  verbose = FALSE,
  penalized_trainer = gpe_cv.glmnet(),
  model = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gpe_+3A_formula">formula</code></td>
<td>
<p>Symbolic description of the model to be fit of the form 
<code>y ~ x1 + x2 + ...+ xn</code>. If the output variable (left-hand side of the 
formula) is a factor, an ensemble for binary classification is created. 
Otherwise, an ensemble for prediction of a continuous variable is created.</p>
</td></tr>
<tr><td><code id="gpe_+3A_data">data</code></td>
<td>
<p><code>data.frame</code> containing the variables in the model.</p>
</td></tr>
<tr><td><code id="gpe_+3A_base_learners">base_learners</code></td>
<td>
<p>List of functions which has formal arguments 
<code>formula</code>, <code>data</code>, <code>weights</code>, <code>sample_func</code>, <code>verbose</code>,
and <code>family</code> and returns a vector of characters with terms for the 
final formula passed to <code>cv.glmnet</code>. See <code><a href="#topic+gpe_linear">gpe_linear</a></code>, 
<code><a href="#topic+gpe_trees">gpe_trees</a></code>, and <code><a href="#topic+gpe_earth">gpe_earth</a></code>.</p>
</td></tr>
<tr><td><code id="gpe_+3A_weights">weights</code></td>
<td>
<p>Case weights with length equal to number of rows in <code>data</code>.</p>
</td></tr>
<tr><td><code id="gpe_+3A_sample_func">sample_func</code></td>
<td>
<p>Function used to sample when learning with base learners. 
The function should have formal argument <code>n</code> and <code>weights</code> and 
return a vector of indices. See <code><a href="#topic+gpe_sample">gpe_sample</a></code>.</p>
</td></tr>
<tr><td><code id="gpe_+3A_verbose">verbose</code></td>
<td>
<p><code>TRUE</code> if comments should be posted throughout the 
computations.</p>
</td></tr>
<tr><td><code id="gpe_+3A_penalized_trainer">penalized_trainer</code></td>
<td>
<p>Function with formal arguments <code>x</code>, <code>y</code>, 
<code>weights</code>, <code>family</code> which returns a fit object. This can be changed 
to test other &quot;penalized trainers&quot; (like other function that perform an L1 
penalty or L2 penalty and elastic net penalty). Not using 
<code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a></code> may cause other function for <code>gpe</code> objects to 
fail. See <code><a href="#topic+gpe_cv.glmnet">gpe_cv.glmnet</a></code>.</p>
</td></tr>
<tr><td><code id="gpe_+3A_model">model</code></td>
<td>
<p><code>TRUE</code> if the <code>data</code> should added to the returned object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Provides a more general framework for making a sparse prediction ensemble than 
<code><a href="#topic+pre">pre</a></code>. 
</p>
<p>By default, a similar fit to <code><a href="#topic+pre">pre</a></code> is obtained. In addition, 
multivariate adaptive regression splines (Friedman, 1991) can be included
with <code>gpe_earth</code>. See examples. 
</p>
<p>Other customs base learners can be implemented. See <code><a href="#topic+gpe_trees">gpe_trees</a></code>, 
<code><a href="#topic+gpe_linear">gpe_linear</a></code> or <code><a href="#topic+gpe_earth">gpe_earth</a></code> for details of the setup. 
The sampling function given by <code>sample_func</code> can also be replaced by a 
custom sampling function. See <code><a href="#topic+gpe_sample">gpe_sample</a></code> for details of the setup.
</p>


<h3>Value</h3>

<p>An object of class <code>gpe</code>.
</p>


<h3>References</h3>

<p>Friedman, J. H., &amp; Popescu, B. E. (2008). Predictive learning via rule 
ensembles. <em>The Annals of Applied Statistics, 2</em>(3), 916-954.
Friedman, J. H. (1991). Multivariate adaptive regression splines. 
<em>The Annals of Statistics, 19</em>(1), 1-67.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pre">pre</a></code>, <code><a href="#topic+gpe_trees">gpe_trees</a></code>, 
<code><a href="#topic+gpe_linear">gpe_linear</a></code>, <code><a href="#topic+gpe_earth">gpe_earth</a></code>, 
<code><a href="#topic+gpe_sample">gpe_sample</a></code>, <code><a href="#topic+gpe_cv.glmnet">gpe_cv.glmnet</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Obtain similar fit to function pre:
gpe.rules &lt;- gpe(Ozone ~ ., data = airquality[complete.cases(airquality),], 
  base_learners = list(gpe_linear(), gpe_trees()))
gpe.rules
  
## Also include products of hinge functions using MARS:
gpe.hinge &lt;- gpe(Ozone ~ ., data = airquality[complete.cases(airquality),], 
  base_learners = list(gpe_linear(), gpe_trees(), gpe_earth()))

## End(Not run)
</code></pre>

<hr>
<h2 id='gpe_cv.glmnet'>Default penalized trainer for gpe</h2><span id='topic+gpe_cv.glmnet'></span>

<h3>Description</h3>

<p>Default &quot;penalizer function&quot; generator <code><a href="#topic+gpe">gpe</a></code> which uses <code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpe_cv.glmnet(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gpe_cv.glmnet_+3A_...">...</code></td>
<td>
<p>arguments to <code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a></code>. <code>x</code>, <code>y</code>, <code>weights</code> and <code>family</code> will not be used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a function with formal arguments <code>x, y, weights, family</code> and returns a fit object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpe">gpe</a></code>
</p>

<hr>
<h2 id='gpe_rules_pre'>Get rule learner for gpe which mimics behavior of pre</h2><span id='topic+gpe_rules_pre'></span>

<h3>Description</h3>

<p><code>gpe_rules_pre</code> generates a learner which generates rules like 
<code><a href="#topic+pre">pre</a></code>, which can be supplied to the <code><a href="#topic+gpe">gpe</a></code> 
base_learner argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpe_rules_pre(
  learnrate = 0.01,
  par.init = FALSE,
  mtry = Inf,
  maxdepth = 3L,
  ntrees = 500,
  tree.control = ctree_control(),
  use.grad = TRUE,
  removeduplicates = TRUE,
  removecomplements = TRUE,
  tree.unbiased = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gpe_rules_pre_+3A_learnrate">learnrate</code></td>
<td>
<p>numeric value <code class="reqn">&gt; 0</code>. Learning rate or boosting parameter.</p>
</td></tr>
<tr><td><code id="gpe_rules_pre_+3A_par.init">par.init</code></td>
<td>
<p>logical. Should parallel <code>foreach</code> be used to generate 
initial ensemble? Only used when <code>learnrate == 0</code>. Note: Must register 
parallel beforehand, such as doMC or others. Furthermore, setting 
<code>par.init = TRUE</code> will likely only increase computation time for smaller 
datasets.</p>
</td></tr>
<tr><td><code id="gpe_rules_pre_+3A_mtry">mtry</code></td>
<td>
<p>positive integer. Number of randomly selected predictor variables for 
creating each split in each tree. Ignored when <code>tree.unbiased=FALSE</code>.</p>
</td></tr>
<tr><td><code id="gpe_rules_pre_+3A_maxdepth">maxdepth</code></td>
<td>
<p>positive integer. Maximum number of conditions in rules. 
If <code>length(maxdepth) == 1</code>, it specifies the maximum depth of 
of each tree grown. If <code>length(maxdepth) == ntrees</code>, it specifies the
maximum depth of every consecutive tree grown. Alternatively, a random
sampling function may be supplied, which takes argument <code>ntrees</code> and 
returns integer values. See also <code><a href="#topic+maxdepth_sampler">maxdepth_sampler</a></code>.</p>
</td></tr>
<tr><td><code id="gpe_rules_pre_+3A_ntrees">ntrees</code></td>
<td>
<p>positive integer value. Number of trees to generate for the 
initial ensemble.</p>
</td></tr>
<tr><td><code id="gpe_rules_pre_+3A_tree.control">tree.control</code></td>
<td>
<p>list with control parameters to be passed to the tree 
fitting function, generated using <code><a href="partykit.html#topic+ctree_control">ctree_control</a></code>,
<code><a href="partykit.html#topic+mob_control">mob_control</a></code> (if <code>use.grad = FALSE</code>), or 
<code><a href="rpart.html#topic+rpart.control">rpart.control</a></code> (if <code>tree.unbiased = FALSE</code>).</p>
</td></tr>
<tr><td><code id="gpe_rules_pre_+3A_use.grad">use.grad</code></td>
<td>
<p>logical. Should gradient boosting with regression trees be
employed when <code>learnrate &gt; 0</code>? If <code>TRUE</code>, use trees fitted by 
<code><a href="partykit.html#topic+ctree">ctree</a></code> or <code><a href="rpart.html#topic+rpart">rpart</a></code> as in Friedman 
(2001), but without the line search. If <code>use.grad = FALSE</code>, 
<code><a href="partykit.html#topic+glmtree">glmtree</a></code> instead of <code><a href="partykit.html#topic+ctree">ctree</a></code> 
will be employed for rule induction, yielding longer computation times, 
higher complexity, but possibly higher predictive accuracy. See Details for 
supported combinations of <code>family</code>, <code>use.grad</code> and <code>learnrate</code>.</p>
</td></tr>
<tr><td><code id="gpe_rules_pre_+3A_removeduplicates">removeduplicates</code></td>
<td>
<p>logical. Remove rules from the ensemble which are 
identical to an earlier rule?</p>
</td></tr>
<tr><td><code id="gpe_rules_pre_+3A_removecomplements">removecomplements</code></td>
<td>
<p>logical. Remove rules from the ensemble which are
identical to (1 - an earlier rule)?</p>
</td></tr>
<tr><td><code id="gpe_rules_pre_+3A_tree.unbiased">tree.unbiased</code></td>
<td>
<p>logical. Should an unbiased tree generation algorithm 
be employed for rule generation? Defaults to <code>TRUE</code>, if set to 
<code>FALSE</code>, rules will be generated employing the CART algorithm
(which suffers from biased variable selection) as implemented in 
<code><a href="rpart.html#topic+rpart">rpart</a></code>. See details below for possible combinations 
with <code>family</code>, <code>use.grad</code> and <code>learnrate</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Obtain same fits with pre and gpe
set.seed(42)
gpe.mod &lt;- gpe(Ozone ~ ., data = airquality[complete.cases(airquality),],  
               base_learners = list(gpe_rules_pre(), gpe_linear()))
gpe.mod                
set.seed(42)
pre.mod &lt;- pre(Ozone ~ ., data = airquality[complete.cases(airquality),],)
pre.mod
</code></pre>

<hr>
<h2 id='gpe_sample'>Sampling Function Generator for gpe</h2><span id='topic+gpe_sample'></span>

<h3>Description</h3>

<p>Provides a sample function for <code><a href="#topic+gpe">gpe</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpe_sample(sampfrac = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gpe_sample_+3A_sampfrac">sampfrac</code></td>
<td>
<p>Fraction of <code>n</code> to use for sampling. It is the <code class="reqn">\eta / N</code> in Friedman &amp; Popescu (2008).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a function that takes an <code>n</code> argument for the number of observations and a <code>weights</code> argument for the case weights. The function returns a vector of indices.
</p>


<h3>References</h3>

<p>Friedman, J. H., &amp; Popescu, B. E. (2008). Predictive learning via rule ensembles. <em>The Annals of Applied Statistics, 2</em>(3), 916-954.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpe">gpe</a></code>
</p>

<hr>
<h2 id='gpe_trees'>Learner Functions Generators for gpe</h2><span id='topic+gpe_trees'></span><span id='topic+gpe_linear'></span><span id='topic+gpe_earth'></span>

<h3>Description</h3>

<p>Functions to get &quot;learner&quot; functions for <code><a href="#topic+gpe">gpe</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpe_trees(
  ...,
  remove_duplicates_complements = TRUE,
  mtry = Inf,
  ntrees = 500,
  maxdepth = 3L,
  learnrate = 0.01,
  parallel = FALSE,
  use_grad = TRUE,
  tree.control = ctree_control(mtry = mtry, maxdepth = maxdepth)
)

gpe_linear(..., winsfrac = 0.025, normalize = TRUE)

gpe_earth(
  ...,
  degree = 3,
  nk = 8,
  normalize = TRUE,
  ntrain = 100,
  learnrate = 0.1,
  cor_thresh = 0.99
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gpe_trees_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
<tr><td><code id="gpe_trees_+3A_remove_duplicates_complements">remove_duplicates_complements</code></td>
<td>
<p><code>TRUE</code>. Should rules with complementary or duplicate support be removed?</p>
</td></tr>
<tr><td><code id="gpe_trees_+3A_mtry">mtry</code></td>
<td>
<p>Number of input variables randomly sampled as candidates at each node for random forest like algorithms. The argument is passed to the tree methods in the <code>partykit</code> package.</p>
</td></tr>
<tr><td><code id="gpe_trees_+3A_ntrees">ntrees</code></td>
<td>
<p>Number of trees to fit. Will not have an effect if <code>tree.control</code> is used.</p>
</td></tr>
<tr><td><code id="gpe_trees_+3A_maxdepth">maxdepth</code></td>
<td>
<p>Maximum depth of trees. Will not have an effect if <code>tree.control</code> is used.</p>
</td></tr>
<tr><td><code id="gpe_trees_+3A_learnrate">learnrate</code></td>
<td>
<p>Learning rate for methods. Corresponds to the <code class="reqn">\nu</code> parameter in Friedman &amp; Popescu (2008).</p>
</td></tr>
<tr><td><code id="gpe_trees_+3A_parallel">parallel</code></td>
<td>
<p><code>TRUE</code>. Should basis functions be found in parallel?</p>
</td></tr>
<tr><td><code id="gpe_trees_+3A_use_grad">use_grad</code></td>
<td>
<p><code>TRUE</code>. Should binary outcomes use gradient boosting with regression trees when <code>learnrate &gt; 0</code>? That is, use <code><a href="partykit.html#topic+ctree">ctree</a></code> instead of <code><a href="partykit.html#topic+glmtree">glmtree</a></code> as in Friedman (2001) with a second order Taylor expansion instead of first order as in Chen and Guestrin (2016).</p>
</td></tr>
<tr><td><code id="gpe_trees_+3A_tree.control">tree.control</code></td>
<td>
<p><code><a href="partykit.html#topic+ctree_control">ctree_control</a></code> with options for the <code><a href="partykit.html#topic+ctree">ctree</a></code> function.</p>
</td></tr>
<tr><td><code id="gpe_trees_+3A_winsfrac">winsfrac</code></td>
<td>
<p>Quantile to winsorize linear terms. The value should be in <code class="reqn">[0,0.5)</code></p>
</td></tr>
<tr><td><code id="gpe_trees_+3A_normalize">normalize</code></td>
<td>
<p><code>TRUE</code>. Should value be scaled by .4 times the inverse standard deviation? If <code>TRUE</code>, gives linear terms the same influence as a typical rule.</p>
</td></tr>
<tr><td><code id="gpe_trees_+3A_degree">degree</code></td>
<td>
<p>Maximum degree of interactions in <code><a href="earth.html#topic+earth">earth</a></code> model.</p>
</td></tr>
<tr><td><code id="gpe_trees_+3A_nk">nk</code></td>
<td>
<p>Maximum number of basis functions in <code><a href="earth.html#topic+earth">earth</a></code> model.</p>
</td></tr>
<tr><td><code id="gpe_trees_+3A_ntrain">ntrain</code></td>
<td>
<p>Number of models to fit.</p>
</td></tr>
<tr><td><code id="gpe_trees_+3A_cor_thresh">cor_thresh</code></td>
<td>
<p>A threshold on the pairwise correlation for removal of basis functions. This is similar to <code>remove_duplicates_complements</code>. One of the basis functions in pairs where the correlation exceeds the threshold is excluded. <code>NULL</code> implies no exclusion. Setting a value closer to zero will decrease the time needed to fit the final model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gpe_trees</code> provides learners for tree method. Either <code><a href="partykit.html#topic+ctree">ctree</a></code> or <code><a href="partykit.html#topic+glmtree">glmtree</a></code> from the <code>partykit</code> package will be used.
</p>
<p><code>gpe_linear</code> provides linear terms for the <code>gpe</code>.
</p>
<p><code>gpe_earth</code> provides basis functions where each factor is a hinge function. The model is estimated with <code><a href="earth.html#topic+earth">earth</a></code>.
</p>


<h3>Value</h3>

<p>A function that has formal arguments <code>formula</code>, <code>data</code>, <code>weights</code>, <code>sample_func</code>, <code>verbose</code>, <code>family</code>, <code>...</code>. The function returns a vector with character where each element is a term for the final formula in the call to <code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a></code>
</p>


<h3>References</h3>

<p>Hothorn, T., &amp; Zeileis, A. (2015). partykit: A modular toolkit for recursive partytioning in R. <em>Journal of Machine Learning Research, 16</em>, 3905-3909.
</p>
<p>Friedman, J. H. (1991). Multivariate adaptive regression splines. <em>The Annals Statistics, 19</em>(1), 1-67.
</p>
<p>Friedman, J. H. (2001). Greedy function approximation: a gradient boosting machine. <em>The Annals of Applied Statistics, 29</em>(5), 1189-1232.
</p>
<p>Friedman, J. H. (1993). Fast MARS. Dept. of Statistics Technical Report No. 110, Stanford University.
</p>
<p>Friedman, J. H., &amp; Popescu, B. E. (2008). Predictive learning via rule ensembles. <em>The Annals of Applied Statistics, 2</em>(3), 916-954.
</p>
<p>Chen T., &amp; Guestrin C. (2016). Xgboost: A scalable tree boosting system. <em>Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>. ACM, 2016.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpe">gpe</a></code>, <code><a href="#topic+rTerm">rTerm</a></code>, <code><a href="#topic+lTerm">lTerm</a></code>, <code><a href="#topic+eTerm">eTerm</a></code>
</p>

<hr>
<h2 id='importance.pre'>Calculate importances of baselearners and input variables in a prediction 
rule ensemble (pre)</h2><span id='topic+importance.pre'></span><span id='topic+importance'></span>

<h3>Description</h3>

<p><code>importance.pre</code> calculates importances for rules, linear terms and input
variables in the prediction rule ensemble (pre), and creates a bar plot 
of variable importances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pre'
importance(
  x,
  standardize = FALSE,
  global = TRUE,
  penalty.par.val = "lambda.1se",
  gamma = NULL,
  quantprobs = c(0.75, 1),
  round = NA,
  plot = TRUE,
  ylab = "Importance",
  main = "Variable importances",
  abbreviate = 10L,
  diag.xlab = TRUE,
  diag.xlab.hor = 0,
  diag.xlab.vert = 2,
  cex.axis = 1,
  legend = "topright",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="importance.pre_+3A_x">x</code></td>
<td>
<p>an object of class <code><a href="#topic+pre">pre</a></code></p>
</td></tr>
<tr><td><code id="importance.pre_+3A_standardize">standardize</code></td>
<td>
<p>logical. Should baselearner importances be standardized 
with respect to the outcome variable? If <code>TRUE</code>, baselearner importances 
have a minimum of 0 and a maximum of 1. Only used for ensembles with 
numeric (non-count) response variables.</p>
</td></tr>
<tr><td><code id="importance.pre_+3A_global">global</code></td>
<td>
<p>logical. Should global importances be calculated? If 
<code>FALSE</code>, local importances will be calculated, given the quantiles 
of the predictions F(x) in <code>quantprobs</code>.</p>
</td></tr>
<tr><td><code id="importance.pre_+3A_penalty.par.val">penalty.par.val</code></td>
<td>
<p>character or numeric. Value of the penalty parameter
<code class="reqn">\lambda</code> to be employed for selecting the final ensemble. The default
<code>"lambda.min"</code> employs the <code class="reqn">\lambda</code> value within 1 standard
error of the minimum cross-validated error. Alternatively, 
<code>"lambda.min"</code> may be specified, to employ the <code class="reqn">\lambda</code> value
with minimum cross-validated error, or a numeric value <code class="reqn">&gt;0</code> may be 
specified, with higher values yielding a sparser ensemble. To evaluate the 
trade-off between accuracy and sparsity of the final ensemble, inspect
<code>pre_object$glmnet.fit</code> and <code>plot(pre_object$glmnet.fit)</code>.</p>
</td></tr>
<tr><td><code id="importance.pre_+3A_gamma">gamma</code></td>
<td>
<p>Mixing parameter for relaxed fits. See
<code><a href="glmnet.html#topic+coef.cv.glmnet">coef.cv.glmnet</a></code>.</p>
</td></tr>
<tr><td><code id="importance.pre_+3A_quantprobs">quantprobs</code></td>
<td>
<p>optional numeric vector of length two. Only used when
<code>global = FALSE</code>. Probabilities for calculating sample quantiles of the 
range of F(X), over which local importances are calculated. The default 
provides variable importances calculated over the 25% highest values of F(X).</p>
</td></tr>
<tr><td><code id="importance.pre_+3A_round">round</code></td>
<td>
<p>integer. Number of decimal places to round numeric results to.
If <code>NA</code> (default), no rounding is performed.</p>
</td></tr>
<tr><td><code id="importance.pre_+3A_plot">plot</code></td>
<td>
<p>logical. Should variable importances be plotted?</p>
</td></tr>
<tr><td><code id="importance.pre_+3A_ylab">ylab</code></td>
<td>
<p>character string. Plotting label for y-axis. Only used when
<code>plot = TRUE</code>.</p>
</td></tr>
<tr><td><code id="importance.pre_+3A_main">main</code></td>
<td>
<p>character string. Main title of the plot. Only used when
<code>plot = TRUE</code>.</p>
</td></tr>
<tr><td><code id="importance.pre_+3A_abbreviate">abbreviate</code></td>
<td>
<p>integer or logical. Number of characters to abbreviate 
x axis names to. If <code>FALSE</code>, no abbreviation is performed.</p>
</td></tr>
<tr><td><code id="importance.pre_+3A_diag.xlab">diag.xlab</code></td>
<td>
<p>logical. Should variable names be printed diagonally (that
is, in a 45 degree angle)? Alternatively, variable names may be printed 
vertically by specifying <code>diag.xlab = FALSE</code> and <code>las = 2</code>.</p>
</td></tr>
<tr><td><code id="importance.pre_+3A_diag.xlab.hor">diag.xlab.hor</code></td>
<td>
<p>numeric. Horizontal adjustment for lining up variable
names with bars in the plot if variable names are printed diagonally.</p>
</td></tr>
<tr><td><code id="importance.pre_+3A_diag.xlab.vert">diag.xlab.vert</code></td>
<td>
<p>positive integer. Vertical adjustment for position
of variable names, if printed diagonally. Corresponds to the number of 
character spaces added after variable names.</p>
</td></tr>
<tr><td><code id="importance.pre_+3A_cex.axis">cex.axis</code></td>
<td>
<p>numeric. The magnification to be used for axis annotation
relative to the current setting of <code>cex</code>.</p>
</td></tr>
<tr><td><code id="importance.pre_+3A_legend">legend</code></td>
<td>
<p>logical or character. Should legend be plotted for multinomial
or multivariate responses and if so, where? Defaults to <code>"topright"</code>, 
which puts the legend in the top-right corner of the plot. Alternatively, 
<code>"bottomright"</code>, <code>"bottom"</code>, <code>"bottomleft"</code>, <code>"left"</code>, 
<code>"topleft"</code>, <code>"top"</code>, <code>"topright"</code>, <code>"right"</code>, 
<code>"center"</code> and <code>FALSE</code> (which omits the legend) can be specified.</p>
</td></tr>
<tr><td><code id="importance.pre_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to <code>barplot</code> (only used
when <code>plot = TRUE</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See also sections 6 and 7 of Friedman &amp; Popecus (2008).
</p>


<h3>Value</h3>

<p>A list with two dataframes: <code>$baseimps</code>, giving the importances 
for baselearners in the ensemble, and <code>$varimps</code>, giving the importances 
for all predictor variables.
</p>


<h3>References</h3>

<p>Fokkema, M. (2020). Fitting prediction rule ensembles with R 
package pre. <em>Journal of Statistical Software, 92</em>(12), 1-30.
<a href="https://doi.org/10.18637/jss.v092.i12">doi:10.18637/jss.v092.i12</a>
</p>
<p>Fokkema, M. &amp; Strobl, C. (2020). Fitting prediction rule ensembles to psychological 
research data: An introduction and tutorial. <em>Psychological Methods 25</em>(5), 
636-652. <a href="https://doi.org/10.1037/met0000256">doi:10.1037/met0000256</a>, <a href="https://arxiv.org/abs/1907.05302">https://arxiv.org/abs/1907.05302</a>
</p>
<p>Friedman, J. H., &amp; Popescu, B. E. (2008). Predictive learning 
via rule ensembles. <em>The Annals of Applied Statistics, 2</em>(3), 916-954 
<a href="https://doi.org/10.1214/07-AOAS148">doi:10.1214/07-AOAS148</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pre">pre</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(42)
airq.ens &lt;- pre(Ozone ~ ., data = airquality[complete.cases(airquality),])
# calculate global importances:
importance(airq.ens)
# calculate local importances (default: over 25% highest predicted values):
importance(airq.ens, global = FALSE)
# calculate local importances (custom: over 25% lowest predicted values):
importance(airq.ens, global = FALSE, quantprobs = c(0, .25))
</code></pre>

<hr>
<h2 id='interact'>Calculate interaction statistics for variables in a prediction rule ensemble 
(pre)</h2><span id='topic+interact'></span>

<h3>Description</h3>

<p><code>interact</code> calculates test statistics for assessing the strength of
interactions between a set of user-specified input variable(s), and all 
other input variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interact(
  object,
  varnames = NULL,
  penalty.par.val = "lambda.1se",
  gamma = NULL,
  nullmods = NULL,
  quantprobs = c(0.05, 0.95),
  plot = TRUE,
  col = c("darkgrey", "lightgrey"),
  ylab = "Interaction strength",
  main = "Interaction test statistics",
  se.linewidth = 0.05,
  legend.text = c("observed", "null model median"),
  parallel = FALSE,
  k = 10,
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="interact_+3A_object">object</code></td>
<td>
<p>an object of class <code><a href="#topic+pre">pre</a></code>.</p>
</td></tr>
<tr><td><code id="interact_+3A_varnames">varnames</code></td>
<td>
<p>character vector. Names of variables for which interaction
statistics should be calculated. If <code>NULL</code>, interaction statistics for
all predictor variables with non-zeor coefficients will be calculated (which
may take a long time).</p>
</td></tr>
<tr><td><code id="interact_+3A_penalty.par.val">penalty.par.val</code></td>
<td>
<p>character or numeric. Value of the penalty parameter
<code class="reqn">\lambda</code> to be employed for selecting the final ensemble. The default
<code>"lambda.min"</code> employs the <code class="reqn">\lambda</code> value within 1 standard
error of the minimum cross-validated error. Alternatively, 
<code>"lambda.min"</code> may be specified, to employ the <code class="reqn">\lambda</code> value
with minimum cross-validated error, or a numeric value <code class="reqn">&gt;0</code> may be 
specified, with higher values yielding a sparser ensemble. To evaluate the 
trade-off between accuracy and sparsity of the final ensemble, inspect
<code>pre_object$glmnet.fit</code> and <code>plot(pre_object$glmnet.fit)</code>.</p>
</td></tr>
<tr><td><code id="interact_+3A_gamma">gamma</code></td>
<td>
<p>Mixing parameter for relaxed fits. See
<code><a href="glmnet.html#topic+coef.cv.glmnet">coef.cv.glmnet</a></code>.</p>
</td></tr>
<tr><td><code id="interact_+3A_nullmods">nullmods</code></td>
<td>
<p>object with bootstrapped null interaction models, resulting
from application of <code>bsnullinteract</code>.</p>
</td></tr>
<tr><td><code id="interact_+3A_quantprobs">quantprobs</code></td>
<td>
<p>numeric vector of length two. Probabilities that should be
used for plotting the range of bootstrapped null interaction model statistics.
Only used when <code>nullmods</code> argument is specified and <code>plot = TRUE</code>.
The default yields sample quantiles corresponding to .05 and .95 probabilities.</p>
</td></tr>
<tr><td><code id="interact_+3A_plot">plot</code></td>
<td>
<p>logical. Should interaction statistics be plotted?</p>
</td></tr>
<tr><td><code id="interact_+3A_col">col</code></td>
<td>
<p>character vector of length one or two. The first value specifies 
the color to be used for plotting the interaction statistic from the training
data, the second color is used for plotting the interaction statistic from 
the bootstrapped null interaction models. Only used when <code>plot = TRUE</code>. 
Only the first element will be used if <code>nullmods = NULL</code>.</p>
</td></tr>
<tr><td><code id="interact_+3A_ylab">ylab</code></td>
<td>
<p>character string. Label to be used for plotting y-axis.</p>
</td></tr>
<tr><td><code id="interact_+3A_main">main</code></td>
<td>
<p>character. Main title for the bar plot.</p>
</td></tr>
<tr><td><code id="interact_+3A_se.linewidth">se.linewidth</code></td>
<td>
<p>numeric. Width of the whiskers of the plotted standard 
error bars (in inches).</p>
</td></tr>
<tr><td><code id="interact_+3A_legend.text">legend.text</code></td>
<td>
<p>character vector of length two to be used for plotting
the legend. Only used when <code>nullmods</code> is specified. If <code>FALSE</code>,
no legend is plotted.</p>
</td></tr>
<tr><td><code id="interact_+3A_parallel">parallel</code></td>
<td>
<p>logical. Should parallel foreach be used? Must register
parallel beforehand, such as doMC or others.</p>
</td></tr>
<tr><td><code id="interact_+3A_k">k</code></td>
<td>
<p>integer. Calculating interaction test statistics is computationally
intensive, so  calculations are split up in several parts to prevent memory
allocation errors. If a memory allocation error still occurs, increase k.</p>
</td></tr>
<tr><td><code id="interact_+3A_verbose">verbose</code></td>
<td>
<p>logical. Should progress information be printed to the
command line?</p>
</td></tr>
<tr><td><code id="interact_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to <code>barplot</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Can be computationally intensive, especially when nullmods is 
specified, in which case setting <code style="white-space: pre;">&#8288;parallel = TRUE&#8288;</code> may improve speed.
</p>


<h3>Value</h3>

<p>Function <code>interact()</code> returns and plots interaction statistics
for the specified predictor variables. If nullmods is not specified, it 
returns and plots only the interaction test statistics for the specified 
fitted prediction rule ensemble. If nullmods is specified, the function 
returns a list, with elements <code>$fittedH2</code>, containing the interaction
statistics of the fitted ensemble, and <code>$nullH2</code>, which contains the
interaction test statistics for each of the bootstrapped null interaction 
models.
</p>
<p>If <code>plot = TRUE</code> (the default), a barplot is created with the 
interaction test statistic from the fitted prediction rule ensemble. If 
<code>nullmods</code> is specified, bars representing the median of the 
distribution of interaction test statistics of the bootstrapped null 
interaction models are plotted. In addition, error bars representing the
quantiles of the distribution (their value specified by the <code>quantprobs</code> 
argument) are plotted. These allow for testing the null hypothesis of no 
interaction effect for each of the input variables. 
</p>
<p>Note that the error rates of null hypothesis tests of interaction effects 
have not yet been studied in detail, but results are likely to get more 
reliable when the number of bootstrapped null interaction models is larger.
The default of the <code>bsnullinteract</code> function is to generate 10 
bootstrapped null interaction datasets, to yield shorter computation times.
To obtain a more reliable result, however, users are advised to
set the <code>nsamp</code> argument <code class="reqn">\ge 100</code>.
</p>
<p>See also section 8 of Friedman &amp; Popescu (2008).
</p>


<h3>References</h3>

<p>Fokkema, M. (2020). Fitting prediction rule ensembles with R 
package pre. <em>Journal of Statistical Software, 92</em>(12), 1-30.
<a href="https://doi.org/10.18637/jss.v092.i12">doi:10.18637/jss.v092.i12</a>
</p>
<p>Friedman, J. H., &amp; Popescu, B. E. (2008). Predictive learning 
via rule ensembles. <em>The Annals of Applied Statistics, 2</em>(3), 916-954,
<a href="https://doi.org/10.1214/07-AOAS148">doi:10.1214/07-AOAS148</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pre">pre</a></code>, <code><a href="#topic+bsnullinteract">bsnullinteract</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(42)
 airq.ens &lt;- pre(Ozone ~ ., data=airquality[complete.cases(airquality),])
 interact(airq.ens, c("Temp", "Wind", "Solar.R"))
</code></pre>

<hr>
<h2 id='maxdepth_sampler'>Sampling function generator for specifying varying maximum tree depth 
in a prediction rule ensemble (pre)</h2><span id='topic+maxdepth_sampler'></span>

<h3>Description</h3>

<p><code>maxdepth_sampler</code> generates a random sampling function, governed
by a pre-specified average tree depth.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>maxdepth_sampler(av.no.term.nodes = 4L, av.tree.depth = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="maxdepth_sampler_+3A_av.no.term.nodes">av.no.term.nodes</code></td>
<td>
<p>integer of length one. Specifies the average 
number of terminal nodes in trees used for rule inducation.</p>
</td></tr>
<tr><td><code id="maxdepth_sampler_+3A_av.tree.depth">av.tree.depth</code></td>
<td>
<p>integer of length one. Specifies the average maximum
tree depth in trees used for rule induction.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The original RuleFit implementation varying tree sizes for
rule induction. Furthermore, it defined tree size in terms of the number
of terminal nodes. In contrast, function <code><a href="#topic+pre">pre</a></code> defines the 
maximum tree size in terms of a (constant) tree depth. Function 
<code>maxdepth_sampler</code> allows for mimicing the behavior of the
orignal RuleFit implementation. In effect, the maximum tree depth is 
sampled from an exponential distribution with learning rate 
<code class="reqn">1/(\bar{L}-2)</code>, where <code class="reqn">\bar{L} \ge 2</code> represents the
average number of terminal nodes for trees in the ensemble. See
Friedman &amp; Popescu (2008, section 3.3).
</p>


<h3>Value</h3>

<p>Returns a random sampling function with single argument <code>ntrees</code>,
which can be supplied to the <code>maxdepth</code> argument of function 
<code><a href="#topic+pre">pre</a></code> to specify varying tree depths.
</p>


<h3>References</h3>

<p>Friedman, J. H., &amp; Popescu, B. E. (2008). Predictive learning 
via rule ensembles. <em>The Annals of Applied Statistics, 2</em>(3), 916-954.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pre">pre</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## RuleFit default is max. 4 terminal nodes, on average:
func1 &lt;- maxdepth_sampler()
set.seed(42)
func1(10)
mean(func1(1000))

## Max. 16 terminal nodes, on average (equals average maxdepth of 4):
func2 &lt;- maxdepth_sampler(av.no.term.nodes = 16L)
set.seed(42)
func2(10)
mean(func2(1000))

## Max. tree depth of 3, on average:
func3 &lt;- maxdepth_sampler(av.tree.depth = 3)
set.seed(42)
func3(10)
mean(func3(1000))

## Max. 2 of terminal nodes, on average (always yields maxdepth of 1):
func4 &lt;- maxdepth_sampler(av.no.term.nodes = 2L)
set.seed(42)
func4(10)
mean(func4(1000))

## Create rule ensemble with varying maxdepth:
set.seed(42)
airq.ens &lt;- pre(Ozone ~ ., data = airquality[complete.cases(airquality),],
                maxdepth = func1)
airq.ens
</code></pre>

<hr>
<h2 id='mi_mean'>Compute the average dataset over imputed datasets.</h2><span id='topic+mi_mean'></span>

<h3>Description</h3>

<p><code>mi_mean</code> computes the averages dataset over a list of imputed datasets.
Can be used to reduce computation time of functions <code>singleplot</code> and 
<code>pairplot</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mi_mean(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mi_mean_+3A_data">data</code></td>
<td>
<p>List of imputed datasets to compute the average dataset over.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is assumed every imputed dataset contains the same observations 
(but not the same values) in the same order.
</p>


<h3>Value</h3>

<p>A dataset that is the average over the imputed datasets specified
with <code>data</code>. For continuous predictors, the mean over imputed values is
returned, for categorical predictors, the majority class ovder imputed values
is returned. In case of a non-unique maximum, the value is sampled from the 
class with identical maximum counts.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mi_pre">mi_pre</a></code>, <code><a href="#topic+singleplot">singleplot</a></code>, <code><a href="#topic+pairplot">pairplot</a></code>
</p>

<hr>
<h2 id='mi_pre'>Fit a prediction rule ensemble to multiply-imputed data (experimental)</h2><span id='topic+mi_pre'></span>

<h3>Description</h3>

<p>Function <code>mi_pre</code> derives a sparse ensemble of rules and/or
linear rules based on imputed data. The function is still experimental,
so use at own risk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mi_pre(
  formula,
  data,
  weights = NULL,
  obs_ids = NULL,
  compl_frac = NULL,
  nfolds = 10L,
  sampfrac = 0.5,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mi_pre_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit of the form 
<code>y ~ x1 + x2 + ... + xn</code>. Response (left-hand side of the formula) 
should be of class numeric (for <code>family = "gaussian"</code> or
<code>"mgaussian"</code>), integer (for <code>family = "poisson"</code>), factor (for 
<code>family = "binomial"</code> or <code>"multinomial"</code>). See Examples below. 
Note that the minus sign (<code>-</code>) may not be used in the formula to omit
the intercept or variables in <code>data</code>, and neither should  <code>+ 0</code> 
be used to omit the intercept. To omit the intercept from the final ensemble, 
add <code>intercept = FALSE</code> to the call (although omitting the intercept from
the final ensemble will only very rarely be appropriate). To omit variables 
from the final ensemble, make sure they are excluded from <code>data</code>.</p>
</td></tr>
<tr><td><code id="mi_pre_+3A_data">data</code></td>
<td>
<p>A list of imputed datasets. The datasets must have identically-named
columns, but need not have the same number of rows (this can happen, for example.
if a bootstrap sampling approach had been employed for multiple imputation).</p>
</td></tr>
<tr><td><code id="mi_pre_+3A_weights">weights</code></td>
<td>
<p>A list of observation weights for each observation in each 
imputed dataset. The list must have the same length as <code>data</code>, and each 
element must be a numeric vector of length identical to the number of rows of 
the corresponding imputed dataset in <code>data</code>. The default is 
<code>NULL</code>, yielding constant observation weights w_i = 1/M, where M is the 
number of imputed datasets (i.e., <code>length(data)</code>).</p>
</td></tr>
<tr><td><code id="mi_pre_+3A_obs_ids">obs_ids</code></td>
<td>
<p>A list of observation ids, corresponding to the id in the
original data, of each observation in each imputed dataset. Defaults to 
<code>NULL</code>, which assumes that the imputed datasets contain the observations 
in identical order. If specified, the list must have
the same length as <code>data</code>, and each element must be a numeric or character 
vector of length identical to the number of rows of the corresponding imputed
dataset in <code>data</code>. At least some of the observations ids must be repeated 
at least some times, within or between imputed datasets.</p>
</td></tr>
<tr><td><code id="mi_pre_+3A_compl_frac">compl_frac</code></td>
<td>
<p>An optional list specifying the fraction of observed values
for each observation. This will be used to compute observation weights as
a function of the fraction of complete data per observations, as per 
Wan et al. (2015), but note that this is only recommended for users who
know the risks (i.e., an analysis more like complete-case analysis).
If specified, the list must have
the same length as <code>data</code>, and each element must be a numeric  
vector of length identical to the number of rows of the corresponding imputed
dataset in <code>data</code>.</p>
</td></tr>
<tr><td><code id="mi_pre_+3A_nfolds">nfolds</code></td>
<td>
<p>positive integer. Number of cross-validation folds to be used for 
selecting the optimal value of the penalty parameter <code class="reqn">\lambda</code> in selecting
the final ensemble.</p>
</td></tr>
<tr><td><code id="mi_pre_+3A_sampfrac">sampfrac</code></td>
<td>
<p>numeric value <code class="reqn">&gt; 0</code> and <code class="reqn">\le 1</code>. Specifies
the fraction of randomly selected training observations used to produce each 
tree. Values <code class="reqn">&lt; 1</code> will result in sampling without replacement (i.e., 
subsampling), a value of 1 will result in sampling with replacement 
(i.e., bootstrap sampling). Alternatively, a sampling function may be supplied, 
which should take arguments <code>n</code> (sample size) and <code>weights</code>.</p>
</td></tr>
<tr><td><code id="mi_pre_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to
<code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Experimental function to fit a prediction rule ensemble to 
multiply imputed data. Essentially, it is a wrapper function around function
<code>pre()</code>, the main differences relate to sampling for the tree induction
and fold assignment for estimation of the coefficients for the final ensemble.
</p>
<p>Function <code>mi_pre</code> implements a so-called stacking approach to the analysis
of imputed data (see also Wood et al., 2008), where imputed datasets are combined 
into one large dataset.
In addition to adjustments of the sampling procedures, adjustments to observation 
weight are made to counter the artificial inflation of sample size.  
</p>
<p>Observations which occur repeatedly across the imputed datasets will be 
completely in- or excluded from each sample or fold, to avoid overfitting. Thus,
complete observations instead of individual imputed observations are sampled,
for tree and rule induction, as well as the cross-validation for selecting the
penalty parameter values for the final ensemble.
</p>
<p>It is assumed that data have already been imputed (using e.g.,
R package mice or missForest), and therefore function <code>mi_pre</code> takes a 
<code>list</code> of imputed datasets as input data.
</p>
<p>Although the option to use the fraction of complete data for computing 
observation weight is provided through argument <code>compl_frac</code>, users
are not advised to use it. See e.g., Du et al. (2022): &quot;An alternative weight 
specification, proposed in Wan et al. (2015), is o_i = f_i/D, where f_i is 
the number of observed predictors out of the total number of predictors for 
subject i [...] upweighting subjects with less missingness and downweighting 
subjects with more missingness can, in some sense, be viewed as making the 
optimization more like complete-case analysis, which might be problematic 
for Missing at Random (MAR) and Missing not at Random (MNAR) scenarios.&quot;
</p>


<h3>Value</h3>

<p>An object of class <code>pre</code>.
</p>


<h3>References</h3>

<p>Du, J., Boss, J., Han, P., Beesley, L. J., Kleinsasser, M., Goutman, S.A., ... 
&amp; Mukherjee, B. (2022). Variable selection with multiply-imputed datasets: 
choosing between stacked and grouped methods. Journal of Computational and 
Graphical Statistics, 31(4), 1063-1075. <a href="https://doi.org/10.1080/10618600.2022.2035739">doi:10.1080/10618600.2022.2035739</a>.
</p>
<p>Wood, A. M., White, I. R., &amp; Royston, P. (2008). How should variable selection 
be performed with multiply imputed data? Statistics in medicine, 27(17), 
3227-3246. <a href="https://doi.org/10.1002/sim.3177">doi:10.1002/sim.3177</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pre">pre</a></code> <code><a href="#topic+mi_mean">mi_mean</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("mice")
set.seed(42)

## Shoot extra holes in airquality data
airq &lt;- sapply(airquality, function(x) {
  x[sample(1:nrow(airquality), size = 25)] &lt;- NA
  return(x)
})

## impute the data
imp &lt;- mice(airq, m = 5)
imp &lt;- as.list(complete(imp, action = "all"))

## fit a rule ensemble to the imputed data
set.seed(42)
airq.ens.mi &lt;- mi_pre(Ozone ~ . , data = imp)
</code></pre>

<hr>
<h2 id='pairplot'>Create partial dependence plot for a pair of predictor variables in a prediction 
rule ensemble (pre)</h2><span id='topic+pairplot'></span>

<h3>Description</h3>

<p><code>pairplot</code> creates a partial dependence plot to assess the effects of a
pair of predictor variables on the predictions of the ensemble. Note that plotting 
partial dependence is computationally intensive. Computation time will increase 
fast with increasing numbers of observations and variables. For large 
datasets, package 'plotmo' (Milborrow, 2019) provides more efficient functions 
for plotting partial dependence and also supports 'pre' models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pairplot(
  object,
  varnames,
  type = "both",
  gamma = NULL,
  penalty.par.val = "lambda.1se",
  response = NULL,
  nvals = c(20L, 20L),
  pred.type = "response",
  newdata = NULL,
  xlab = NULL,
  ylab = NULL,
  main = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pairplot_+3A_object">object</code></td>
<td>
<p>an object of class <code><a href="#topic+pre">pre</a></code></p>
</td></tr>
<tr><td><code id="pairplot_+3A_varnames">varnames</code></td>
<td>
<p>character vector of length two. Currently, pairplots can only
be requested for non-nominal variables. If varnames specifies the name(s) of
variables of class <code>"factor"</code>, an error will be printed.</p>
</td></tr>
<tr><td><code id="pairplot_+3A_type">type</code></td>
<td>
<p>character string. Type of plot to be generated. 
<code>type = "heatmap"</code> yields a heatmap plot, <code>type = "contour"</code> yields 
a contour plot, <code>type = "both"</code> yields a heatmap plot with added contours,
<code>type = "perspective"</code> yields a three dimensional plot.</p>
</td></tr>
<tr><td><code id="pairplot_+3A_gamma">gamma</code></td>
<td>
<p>Mixing parameter for relaxed fits. See
<code><a href="glmnet.html#topic+coef.cv.glmnet">coef.cv.glmnet</a></code>.</p>
</td></tr>
<tr><td><code id="pairplot_+3A_penalty.par.val">penalty.par.val</code></td>
<td>
<p>character or numeric. Value of the penalty parameter
<code class="reqn">\lambda</code> to be employed for selecting the final ensemble. The default
<code>"lambda.min"</code> employs the <code class="reqn">\lambda</code> value within 1 standard
error of the minimum cross-validated error. Alternatively, 
<code>"lambda.min"</code> may be specified, to employ the <code class="reqn">\lambda</code> value
with minimum cross-validated error, or a numeric value <code class="reqn">&gt;0</code> may be 
specified, with higher values yielding a sparser ensemble. To evaluate the 
trade-off between accuracy and sparsity of the final ensemble, inspect
<code>pre_object$glmnet.fit</code> and <code>plot(pre_object$glmnet.fit)</code>.</p>
</td></tr>
<tr><td><code id="pairplot_+3A_response">response</code></td>
<td>
<p>numeric vector of length 1. Only relevant for multivariate gaussian 
and multinomial responses. If <code>NULL</code> (default), PDPs for all response 
variables or categories will be produced. A single integer can be specified, 
indicating for which response variable or category PDPs should be produced.</p>
</td></tr>
<tr><td><code id="pairplot_+3A_nvals">nvals</code></td>
<td>
<p>optional numeric vector of length 2. For how many values of
x1 and x2 should partial dependence be plotted? If <code>NULL</code>, a grid of all possible
combinations of the observed values of the two predictor variables specified will be used 
(see details).</p>
</td></tr>
<tr><td><code id="pairplot_+3A_pred.type">pred.type</code></td>
<td>
<p>character string. Type of prediction to be plotted on z-axis.
<code>pred.type = "response"</code> gives fitted values for continuous outputs and
fitted probabilities for nominal outputs. <code>pred.type = "link"</code> gives fitted
values for continuous outputs and linear predictor values for nominal outputs.</p>
</td></tr>
<tr><td><code id="pairplot_+3A_newdata">newdata</code></td>
<td>
<p>Optional <code>data.frame</code> in which to look for variables 
with which to predict. If <code>NULL</code>, the <code>data.frame</code> used to fit the 
original ensemble will be used.</p>
</td></tr>
<tr><td><code id="pairplot_+3A_xlab">xlab</code></td>
<td>
<p>character. Label to be printed on the x-axis. If <code>NULL</code>,
the first elements of the supplied <code>varnames</code> will be printed on the x-axis.</p>
</td></tr>
<tr><td><code id="pairplot_+3A_ylab">ylab</code></td>
<td>
<p>character. Label to be printed on the y-axis. If <code>NULL</code>,
the second element of the supplied <code>varnames</code> will be printed on the y-axis.</p>
</td></tr>
<tr><td><code id="pairplot_+3A_main">main</code></td>
<td>
<p>Title for the plot. If <code>NULL</code>, the name of the response
will be printed.</p>
</td></tr>
<tr><td><code id="pairplot_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to <code><a href="graphics.html#topic+image">image</a></code>, 
<code><a href="graphics.html#topic+contour">contour</a></code> or <code><a href="graphics.html#topic+persp">persp</a></code> (depending on
whether <code>type</code> is specified to be <code>"heatmap"</code>, <code>"contour"</code>, <code>"both"</code> 
or <code>"perspective"</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Partial dependence functions are described in section 8.1 of Friedman &amp; 
Popescu (2008).
</p>
<p>By default, partial dependence will be plotted for each combination
of 20 values of the specified predictor variables. When <code>nvals = NULL</code> is
specified, a dependence plot will be created for every combination of the unique
observed values of the two specified predictor variables. If <code>NA</code> instead of
a numeric value is specified for one of the predictor variables, all observed
values for that variables will be used. Specifying <code>nvals = NULL</code> and 
<code>nvals = c(NA, NA)</code> will yield the exact same result.
</p>
<p>High values, <code>NA</code> or <code>NULL</code> for <code>nvals</code> result in long 
computation times and possibly memory problems. Also, <code><a href="#topic+pre">pre</a></code> 
ensembles derived from training datasets that are very wide or long may 
result in long computation times and/or memory allocation errors. 
In such cases, reducing
the values supplied to <code>nvals</code> will reduce computation time and/or
memory allocation errors. 
</p>
<p>When numeric value(s) are specified for <code>nvals</code>, values for the
minimum, maximum, and nvals - 2 intermediate values of the predictor variable
will be plotted. 
</p>
<p>Alternatively, <code>newdata</code> can be specified to provide a different (smaller) 
set of observations to compute partial dependence over.
If <code>mi_pre</code> was used to derive the original rule ensemble, 
<code>newdata = "mean.mi"</code> can be specified. This 
will result in an average dataset being computed over the imputed datasets, 
which are then used to compute partial dependence functions. This greatly 
reduces the number of observations and thereby computation time.
</p>
<p>If none of the variables specified with argument <code>varnames</code> was
selected for the final prediction rule ensemble, an error will be returned.
</p>


<h3>References</h3>

<p>Friedman, J. H., &amp; Popescu, B. E. (2008). Predictive learning 
via rule ensembles. <em>The Annals of Applied Statistics, 2</em>(3), 916-954.
</p>
<p>Milborrow, S. (2019). plotmo: Plot a model's residuals, response, and partial 
dependence plots. <a href="https://CRAN.R-project.org/package=plotmo">https://CRAN.R-project.org/package=plotmo</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pre">pre</a></code>, <code><a href="#topic+singleplot">singleplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>airq &lt;- airquality[complete.cases(airquality),]
set.seed(42)
airq.ens &lt;- pre(Ozone ~ ., data = airq)
pairplot(airq.ens, c("Temp", "Wind"))

## For multinomial and mgaussian families, one PDP is created per category or outcome
set.seed(42)
airq.ens3 &lt;- pre(Ozone + Wind ~ ., data = airq, family = "mgaussian")
pairplot(airq.ens3, varnames = c("Day", "Month"))

set.seed(42)
iris.ens &lt;- pre(Species ~ ., data = iris, family = "multinomial")
pairplot(iris.ens, varname = c("Petal.Width", "Petal.Length"))
</code></pre>

<hr>
<h2 id='plot.pre'>Plot method for class pre</h2><span id='topic+plot.pre'></span>

<h3>Description</h3>

<p><code>plot.pre</code> creates one or more plots depicting the rules in the final
ensemble as simple decision trees.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pre'
plot(
  x,
  penalty.par.val = "lambda.1se",
  gamma = NULL,
  linear.terms = TRUE,
  nterms = NULL,
  fill = "white",
  ask = FALSE,
  exit.label = "0",
  standardize = FALSE,
  plot.dim = c(3, 3),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.pre_+3A_x">x</code></td>
<td>
<p>an object of class <code><a href="#topic+pre">pre</a></code>.</p>
</td></tr>
<tr><td><code id="plot.pre_+3A_penalty.par.val">penalty.par.val</code></td>
<td>
<p>character or numeric. Value of the penalty parameter
<code class="reqn">\lambda</code> to be employed for selecting the final ensemble. The default
<code>"lambda.min"</code> employs the <code class="reqn">\lambda</code> value within 1 standard
error of the minimum cross-validated error. Alternatively, 
<code>"lambda.min"</code> may be specified, to employ the <code class="reqn">\lambda</code> value
with minimum cross-validated error, or a numeric value <code class="reqn">&gt;0</code> may be 
specified, with higher values yielding a sparser ensemble. To evaluate the 
trade-off between accuracy and sparsity of the final ensemble, inspect
<code>pre_object$glmnet.fit</code> and <code>plot(pre_object$glmnet.fit)</code>.</p>
</td></tr>
<tr><td><code id="plot.pre_+3A_gamma">gamma</code></td>
<td>
<p>Mixing parameter for relaxed fits. See
<code><a href="glmnet.html#topic+coef.cv.glmnet">coef.cv.glmnet</a></code>.</p>
</td></tr>
<tr><td><code id="plot.pre_+3A_linear.terms">linear.terms</code></td>
<td>
<p>logical. Should linear terms be included in the plot?</p>
</td></tr>
<tr><td><code id="plot.pre_+3A_nterms">nterms</code></td>
<td>
<p>numeric. The total number of terms (or rules, if 
<code>linear.terms = FALSE</code>) being plotted. Default is <code>NULL</code>, 
resulting in all terms of the final ensemble to be plotted.</p>
</td></tr>
<tr><td><code id="plot.pre_+3A_fill">fill</code></td>
<td>
<p>character of length 1 or 2. Background color(s) for terminal 
panels. If one color is specified, all terminal panels will have the 
specified background color. If two colors are specified (the default, the 
first color will be used as the background color for rules with a positively 
valued coefficient; the second color for rules with a negatively valued 
coefficient.</p>
</td></tr>
<tr><td><code id="plot.pre_+3A_ask">ask</code></td>
<td>
<p>logical. Should user be prompted before starting a new page of
plots?</p>
</td></tr>
<tr><td><code id="plot.pre_+3A_exit.label">exit.label</code></td>
<td>
<p>character string. Label to be printed in nodes to which 
the rule does not apply (&ldquo;exit nodes&rdquo;)?</p>
</td></tr>
<tr><td><code id="plot.pre_+3A_standardize">standardize</code></td>
<td>
<p>logical. Should printed importances be standardized? See
<code><a href="#topic+importance.pre">importance.pre</a></code>.</p>
</td></tr>
<tr><td><code id="plot.pre_+3A_plot.dim">plot.dim</code></td>
<td>
<p>integer vector of length two. Specifies the number of rows
and columns in the plot. The default yields a plot with three rows and three 
columns, depicting nine baselearners per plotting page.</p>
</td></tr>
<tr><td><code id="plot.pre_+3A_...">...</code></td>
<td>
<p>Arguments to be passed to <code><a href="grid.html#topic+gpar">gpar</a></code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+pre">pre</a></code>, <code><a href="#topic+print.pre">print.pre</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(42)
 airq.ens &lt;- pre(Ozone ~ ., data = airquality[complete.cases(airquality),])
 plot(airq.ens)
</code></pre>

<hr>
<h2 id='pre'>Derive a prediction rule ensemble</h2><span id='topic+pre'></span>

<h3>Description</h3>

<p>Function <code>pre</code> derives a sparse ensemble of rules and/or linear functions for 
prediction of a continuous, binary, count, multinomial, multivariate 
continuous or survival response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pre(
  formula,
  data,
  family = gaussian,
  ad.alpha = NA,
  ad.penalty = "lambda.min",
  use.grad = TRUE,
  weights,
  type = "both",
  sampfrac = 0.5,
  maxdepth = 3L,
  learnrate = 0.01,
  mtry = Inf,
  ntrees = 500,
  confirmatory = NULL,
  singleconditions = FALSE,
  winsfrac = 0.025,
  normalize = TRUE,
  standardize = FALSE,
  ordinal = TRUE,
  nfolds = 10L,
  tree.control,
  tree.unbiased = TRUE,
  removecomplements = TRUE,
  removeduplicates = TRUE,
  verbose = FALSE,
  par.init = FALSE,
  par.final = FALSE,
  sparse = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pre_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit of the form 
<code>y ~ x1 + x2 + ... + xn</code>. Response (left-hand side of the formula) 
should be of class numeric (for <code>family = "gaussian"</code> or
<code>"mgaussian"</code>), integer (for <code>family = "poisson"</code>), factor (for 
<code>family = "binomial"</code> or <code>"multinomial"</code>). See Examples below. 
Note that the minus sign (<code>-</code>) may not be used in the formula to omit
the intercept or variables in <code>data</code>, and neither should  <code>+ 0</code> 
be used to omit the intercept. To omit the intercept from the final ensemble, 
add <code>intercept = FALSE</code> to the call (although omitting the intercept from
the final ensemble will only very rarely be appropriate). To omit variables 
from the final ensemble, make sure they are excluded from <code>data</code>.</p>
</td></tr>
<tr><td><code id="pre_+3A_data">data</code></td>
<td>
<p><code>data.frame</code> containing the variables in the model. Response 
must be of class <code>factor</code> for classification, <code>numeric</code> for (count) 
regression, <code>Surv</code> for survival regression. Input variables must be of 
class numeric, factor or ordered factor. Otherwise, <code>pre</code> will attempt
to recode.</p>
</td></tr>
<tr><td><code id="pre_+3A_family">family</code></td>
<td>
<p>specifies a glm family object. Can be a character string (i.e., 
<code>"gaussian"</code>, <code>"binomial"</code>, <code>"poisson"</code>, <code>"multinomial"</code>, 
<code>"cox"</code> or <code>"mgaussian"</code>), or a corresponding family object 
(e.g., <code>gaussian</code>, <code>binomial</code> or <code>poisson</code>, see 
<code><a href="stats.html#topic+family">family</a></code>). Specification of argument <code>family</code> is 
strongly advised but not required. If <code>family</code> is not specified, 
Otherwise, the program will try to make an informed guess, based on the 
class of the response variable specified in <code>formula</code>. als see Examples 
below.</p>
</td></tr>
<tr><td><code id="pre_+3A_ad.alpha">ad.alpha</code></td>
<td>
<p>Alpha value to be used for computing the penalty weights for the
adaptive lasso. Defaults to <code>NA</code>, yielding standard lasso estimation. 
To use adaptive lasso, specify a value between (and including) 0 and 1. A value of
0 will yield ridge-estimated penalty weights for computing the final (lasso) 
penalized model. See <code>vignette("relaxed", "pre")</code> or 
argument <code>alpha</code> of <code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a></code>.</p>
</td></tr>
<tr><td><code id="pre_+3A_ad.penalty">ad.penalty</code></td>
<td>
<p>Penalty parameter value to be used for computing the penalty 
weights for the adaptive lasso. Defaults to <code>"lambda.min"</code>. If OLS instead
of elastic net regression should be used to compute weights, specify 
<code>ad.penalty = 0</code>. See also <code>vignette("relaxed", "pre")</code>.</p>
</td></tr>
<tr><td><code id="pre_+3A_use.grad">use.grad</code></td>
<td>
<p>logical. Should gradient boosting with regression trees be
employed when <code>learnrate &gt; 0</code>? If <code>TRUE</code>, use trees fitted by 
<code><a href="partykit.html#topic+ctree">ctree</a></code> or <code><a href="rpart.html#topic+rpart">rpart</a></code> as in Friedman 
(2001), but without the line search. If <code>use.grad = FALSE</code>, 
<code><a href="partykit.html#topic+glmtree">glmtree</a></code> instead of <code><a href="partykit.html#topic+ctree">ctree</a></code> 
will be employed for rule induction, yielding longer computation times, 
higher complexity, but possibly higher predictive accuracy. See Details for 
supported combinations of <code>family</code>, <code>use.grad</code> and <code>learnrate</code>.</p>
</td></tr>
<tr><td><code id="pre_+3A_weights">weights</code></td>
<td>
<p>optional vector of observation weights to be used for 
deriving the ensemble.</p>
</td></tr>
<tr><td><code id="pre_+3A_type">type</code></td>
<td>
<p>character. Specifies type of base learners to include in the 
ensemble. Defaults to <code>"both"</code> (initial ensemble will include both rules 
and linear functions). Other option are <code>"rules"</code> (prediction 
rules only) or <code>"linear"</code> (linear functions only).</p>
</td></tr>
<tr><td><code id="pre_+3A_sampfrac">sampfrac</code></td>
<td>
<p>numeric value <code class="reqn">&gt; 0</code> and <code class="reqn">\le 1</code>. Specifies
the fraction of randomly selected training observations used to produce each 
tree. Values <code class="reqn">&lt; 1</code> will result in sampling without replacement (i.e., 
subsampling), a value of 1 will result in sampling with replacement 
(i.e., bootstrap sampling). Alternatively, a sampling function may be supplied, 
which should take arguments <code>n</code> (sample size) and <code>weights</code>.</p>
</td></tr>
<tr><td><code id="pre_+3A_maxdepth">maxdepth</code></td>
<td>
<p>positive integer. Maximum number of conditions in rules. 
If <code>length(maxdepth) == 1</code>, it specifies the maximum depth of 
of each tree grown. If <code>length(maxdepth) == ntrees</code>, it specifies the
maximum depth of every consecutive tree grown. Alternatively, a random
sampling function may be supplied, which takes argument <code>ntrees</code> and 
returns integer values. See also <code><a href="#topic+maxdepth_sampler">maxdepth_sampler</a></code>.</p>
</td></tr>
<tr><td><code id="pre_+3A_learnrate">learnrate</code></td>
<td>
<p>numeric value <code class="reqn">&gt; 0</code>. Learning rate or boosting parameter.</p>
</td></tr>
<tr><td><code id="pre_+3A_mtry">mtry</code></td>
<td>
<p>positive integer. Number of randomly selected predictor variables for 
creating each split in each tree. Ignored when <code>tree.unbiased=FALSE</code>.</p>
</td></tr>
<tr><td><code id="pre_+3A_ntrees">ntrees</code></td>
<td>
<p>positive integer value. Number of trees to generate for the 
initial ensemble.</p>
</td></tr>
<tr><td><code id="pre_+3A_confirmatory">confirmatory</code></td>
<td>
<p>character vector. Specifies one or more confirmatory terms 
to be included in the final ensemble. Linear terms can be specified as the 
name of a predictor variable included in <code>data</code>, rules can be specified
as, for example, <code>"x1 &gt; 6 &amp; x2 &lt;= 8"</code>, where x1 and x2 should be names
of variables in <code>data</code>. Terms thus specified will be included in the
final ensemble, as their coefficients will not be penalized in the estimation.</p>
</td></tr>
<tr><td><code id="pre_+3A_singleconditions">singleconditions</code></td>
<td>
<p><code>TRUE</code>, <code>FALSE</code> or <code>"only"</code>. Should 
rules with multiple conditions be disaggregated? Node membership for all tree
except the root are coded as multi-condition rules. The conditions of these
rules can be disaggregated to avoid selection of multi-condition rules. If
<code>FALSE</code> (the default), all non-root nodes will be included as multi-condition 
rules in the initial ensemble. If <code>TRUE</code>, all nodes will additionally be 
included as single-condition rules. If <code>"only"</code>, all nodes will be included 
as single-condition rules only.</p>
</td></tr>
<tr><td><code id="pre_+3A_winsfrac">winsfrac</code></td>
<td>
<p>numeric value <code class="reqn">&gt; 0</code> and <code class="reqn">\le 0.5</code>. Quantiles of data 
distribution to be used for 
winsorizing linear terms. If set to 0, no winsorizing is performed. Note 
that ordinal variables are included as linear terms in estimating the
regression model and will also be winsorized.</p>
</td></tr>
<tr><td><code id="pre_+3A_normalize">normalize</code></td>
<td>
<p>logical. Normalize linear variables before estimating the 
regression model? Normalizing gives linear terms the same a priori influence 
as a typical rule, by dividing the (winsorized) linear term by 2.5 times its 
SD. <code>normalize = FALSE</code> will give more preference to linear terms for 
selection.</p>
</td></tr>
<tr><td><code id="pre_+3A_standardize">standardize</code></td>
<td>
<p>logical. Should rules and linear terms be standardized to
have SD equal to 1 before estimating the regression model? This will also 
standardize the dummified factors, users are advised to use the default 
<code>standardize = FALSE</code>.</p>
</td></tr>
<tr><td><code id="pre_+3A_ordinal">ordinal</code></td>
<td>
<p>logical. Should ordinal variables (i.e., ordered factors) be
treated as continuous for generating rules? <code>TRUE</code> (the default)
generally yields simpler rules, shorter computation times and better 
generalizability of the final ensemble.</p>
</td></tr>
<tr><td><code id="pre_+3A_nfolds">nfolds</code></td>
<td>
<p>positive integer. Number of cross-validation folds to be used for 
selecting the optimal value of the penalty parameter <code class="reqn">\lambda</code> in selecting
the final ensemble.</p>
</td></tr>
<tr><td><code id="pre_+3A_tree.control">tree.control</code></td>
<td>
<p>list with control parameters to be passed to the tree 
fitting function, generated using <code><a href="partykit.html#topic+ctree_control">ctree_control</a></code>,
<code><a href="partykit.html#topic+mob_control">mob_control</a></code> (if <code>use.grad = FALSE</code>), or 
<code><a href="rpart.html#topic+rpart.control">rpart.control</a></code> (if <code>tree.unbiased = FALSE</code>).</p>
</td></tr>
<tr><td><code id="pre_+3A_tree.unbiased">tree.unbiased</code></td>
<td>
<p>logical. Should an unbiased tree generation algorithm 
be employed for rule generation? Defaults to <code>TRUE</code>, if set to 
<code>FALSE</code>, rules will be generated employing the CART algorithm
(which suffers from biased variable selection) as implemented in 
<code><a href="rpart.html#topic+rpart">rpart</a></code>. See details below for possible combinations 
with <code>family</code>, <code>use.grad</code> and <code>learnrate</code>.</p>
</td></tr>
<tr><td><code id="pre_+3A_removecomplements">removecomplements</code></td>
<td>
<p>logical. Remove rules from the ensemble which are
identical to (1 - an earlier rule)?</p>
</td></tr>
<tr><td><code id="pre_+3A_removeduplicates">removeduplicates</code></td>
<td>
<p>logical. Remove rules from the ensemble which are 
identical to an earlier rule?</p>
</td></tr>
<tr><td><code id="pre_+3A_verbose">verbose</code></td>
<td>
<p>logical. Should progress be printed to the command line?</p>
</td></tr>
<tr><td><code id="pre_+3A_par.init">par.init</code></td>
<td>
<p>logical. Should parallel <code>foreach</code> be used to generate 
initial ensemble? Only used when <code>learnrate == 0</code>. Note: Must register 
parallel beforehand, such as doMC or others. Furthermore, setting 
<code>par.init = TRUE</code> will likely only increase computation time for smaller 
datasets.</p>
</td></tr>
<tr><td><code id="pre_+3A_par.final">par.final</code></td>
<td>
<p>logical. Should parallel <code>foreach</code> be used to perform cross 
validation for selecting the final ensemble? Must register parallel beforehand, 
such as doMC or others.</p>
</td></tr>
<tr><td><code id="pre_+3A_sparse">sparse</code></td>
<td>
<p>logical. Should sparse design matrices be used? May improve
computation times for large datasets.</p>
</td></tr>
<tr><td><code id="pre_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to
<code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that obervations with missing values will be removed prior to 
analysis (and a warning printed).
</p>
<p>In some cases, duplicated variable names may appear in the model.
For example, the first variable is a factor named 'V1' and there are also
variables named 'V10' and/or 'V11' and/or 'V12' (etc). Then for 
for the binary factor V1, dummy contrast variables will be created, named 
'V10', 'V11', 'V12' (etc). As should be clear from this example, this yields 
duplicated variable names, which may yield problems, for example in the 
calculation of predictions and importances, later on. This can be prevented 
by renaming factor variables with numbers in their name, prior to analysis.
</p>
<p>The table below provides an overview of combinations of response 
variable types, <code>use.grad</code>, <code>tree.unbiased</code> and
<code>learnrate</code> settings that are supported, and the tree induction 
algorithm that will be employed as a result:
</p>

<table>
<tr>
 <td style="text-align: left;">
<strong>use.grad</strong> </td><td style="text-align: center;"> <strong>tree.unbiased</strong> </td><td style="text-align: center;"> <strong>learnrate</strong> </td><td style="text-align: center;"> <strong>family</strong> </td><td style="text-align: center;"> <strong>tree alg.</strong> </td><td style="text-align: center;"> <strong>Response variable format</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;">
TRUE	</td><td style="text-align: center;"> TRUE	</td><td style="text-align: center;"> 0 </td><td style="text-align: center;"> gaussian	  </td><td style="text-align: center;"> ctree</td><td style="text-align: center;"> Single, numeric (non-integer) </td>
</tr>
<tr>
 <td style="text-align: left;">
TRUE	</td><td style="text-align: center;"> TRUE	</td><td style="text-align: center;"> 0 </td><td style="text-align: center;"> mgaussian	  </td><td style="text-align: center;"> ctree</td><td style="text-align: center;"> Multiple, numeric (non-integer) </td>
</tr>
<tr>
 <td style="text-align: left;">
TRUE	</td><td style="text-align: center;"> TRUE	</td><td style="text-align: center;"> 0 </td><td style="text-align: center;"> binomial	  </td><td style="text-align: center;"> ctree</td><td style="text-align: center;"> Single, factor with 2 levels </td>
</tr>
<tr>
 <td style="text-align: left;">
TRUE	</td><td style="text-align: center;"> TRUE	</td><td style="text-align: center;"> 0 </td><td style="text-align: center;"> multinomial	</td><td style="text-align: center;"> ctree</td><td style="text-align: center;"> Single, factor with &gt;2 levels </td>
</tr>
<tr>
 <td style="text-align: left;">
TRUE	</td><td style="text-align: center;"> TRUE	</td><td style="text-align: center;"> 0 </td><td style="text-align: center;"> poisson	    </td><td style="text-align: center;"> ctree</td><td style="text-align: center;"> Single, integer </td>
</tr>
<tr>
 <td style="text-align: left;">
TRUE </td><td style="text-align: center;"> TRUE </td><td style="text-align: center;"> 0 </td><td style="text-align: center;"> cox         </td><td style="text-align: center;"> ctree</td><td style="text-align: center;"> Object of class 'Surv' </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;">
TRUE	</td><td style="text-align: center;"> TRUE	</td><td style="text-align: center;"> &gt;0 </td><td style="text-align: center;"> 	gaussian	  </td><td style="text-align: center;"> ctree </td><td style="text-align: center;"> Single, numeric (non-integer) </td>
</tr>
<tr>
 <td style="text-align: left;">
TRUE	</td><td style="text-align: center;"> TRUE	</td><td style="text-align: center;"> &gt;0	</td><td style="text-align: center;"> mgaussian	  </td><td style="text-align: center;"> ctree </td><td style="text-align: center;"> Multiple, numeric (non-integer) </td>
</tr>
<tr>
 <td style="text-align: left;">
TRUE	</td><td style="text-align: center;"> TRUE	</td><td style="text-align: center;"> &gt;0	</td><td style="text-align: center;"> binomial	  </td><td style="text-align: center;"> ctree  </td><td style="text-align: center;"> Single, factor with 2 levels </td>
</tr>
<tr>
 <td style="text-align: left;">
TRUE	</td><td style="text-align: center;"> TRUE	</td><td style="text-align: center;"> &gt;0	</td><td style="text-align: center;"> multinomial	</td><td style="text-align: center;"> ctree </td><td style="text-align: center;"> Single, factor with &gt;2 levels </td>
</tr>
<tr>
 <td style="text-align: left;">
TRUE	</td><td style="text-align: center;"> TRUE	</td><td style="text-align: center;"> &gt;0	</td><td style="text-align: center;"> poisson	    </td><td style="text-align: center;"> ctree  </td><td style="text-align: center;"> Single, integer </td>
</tr>
<tr>
 <td style="text-align: left;">
TRUE </td><td style="text-align: center;"> TRUE </td><td style="text-align: center;"> &gt;0 </td><td style="text-align: center;"> cox         </td><td style="text-align: center;"> ctree</td><td style="text-align: center;"> Object of class 'Surv' </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;">
FALSE </td><td style="text-align: center;"> TRUE </td><td style="text-align: center;"> 0 </td><td style="text-align: center;"> gaussian	  </td><td style="text-align: center;"> glmtree </td><td style="text-align: center;"> Single, numeric (non-integer) </td>
</tr>
<tr>
 <td style="text-align: left;">
FALSE </td><td style="text-align: center;"> TRUE </td><td style="text-align: center;"> 0 </td><td style="text-align: center;"> binomial	  </td><td style="text-align: center;"> glmtree </td><td style="text-align: center;"> Single, factor with 2 levels </td>
</tr>
<tr>
 <td style="text-align: left;">
FALSE </td><td style="text-align: center;"> TRUE </td><td style="text-align: center;"> 0 </td><td style="text-align: center;"> poisson	    </td><td style="text-align: center;"> glmtree </td><td style="text-align: center;"> Single, integer </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;">
FALSE </td><td style="text-align: center;"> TRUE </td><td style="text-align: center;"> &gt;0 </td><td style="text-align: center;"> gaussian	  </td><td style="text-align: center;"> glmtree </td><td style="text-align: center;"> Single, numeric (non-integer) </td>
</tr>
<tr>
 <td style="text-align: left;">
FALSE </td><td style="text-align: center;"> TRUE </td><td style="text-align: center;"> &gt;0 </td><td style="text-align: center;"> binomial	  </td><td style="text-align: center;"> glmtree </td><td style="text-align: center;"> Single, factor with 2 levels </td>
</tr>
<tr>
 <td style="text-align: left;">
FALSE </td><td style="text-align: center;"> TRUE </td><td style="text-align: center;"> &gt;0 </td><td style="text-align: center;"> poisson	    </td><td style="text-align: center;"> glmtree </td><td style="text-align: center;"> Single, integer </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;">
TRUE	</td><td style="text-align: center;"> FALSE </td><td style="text-align: center;"> 0 </td><td style="text-align: center;"> gaussian	  </td><td style="text-align: center;"> rpart </td><td style="text-align: center;"> Single, numeric (non-integer) </td>
</tr>
<tr>
 <td style="text-align: left;">
TRUE	</td><td style="text-align: center;"> FALSE </td><td style="text-align: center;"> 0 </td><td style="text-align: center;"> binomial	  </td><td style="text-align: center;"> rpart </td><td style="text-align: center;"> Single, factor with 2 levels </td>
</tr>
<tr>
 <td style="text-align: left;">
TRUE	</td><td style="text-align: center;"> FALSE </td><td style="text-align: center;"> 0 </td><td style="text-align: center;"> multinomial	</td><td style="text-align: center;"> rpart </td><td style="text-align: center;"> Single, factor with &gt;2 levels </td>
</tr>
<tr>
 <td style="text-align: left;">
TRUE	</td><td style="text-align: center;"> FALSE </td><td style="text-align: center;"> 0 </td><td style="text-align: center;"> poisson	    </td><td style="text-align: center;"> rpart </td><td style="text-align: center;"> Single, integer </td>
</tr>
<tr>
 <td style="text-align: left;">
TRUE </td><td style="text-align: center;"> FALSE </td><td style="text-align: center;"> 0 </td><td style="text-align: center;"> cox         </td><td style="text-align: center;"> rpart</td><td style="text-align: center;"> Object of class 'Surv' </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;">
TRUE </td><td style="text-align: center;"> FALSE	</td><td style="text-align: center;"> &gt;0 </td><td style="text-align: center;"> gaussian	  </td><td style="text-align: center;"> rpart </td><td style="text-align: center;"> Single, numeric (non-integer) </td>
</tr>
<tr>
 <td style="text-align: left;">
TRUE </td><td style="text-align: center;"> FALSE	</td><td style="text-align: center;"> &gt;0 </td><td style="text-align: center;"> binomial	  </td><td style="text-align: center;"> rpart </td><td style="text-align: center;"> Single, factor with 2 levels </td>
</tr>
<tr>
 <td style="text-align: left;">
TRUE </td><td style="text-align: center;"> FALSE	</td><td style="text-align: center;"> &gt;0 </td><td style="text-align: center;"> poisson	  </td><td style="text-align: center;"> rpart </td><td style="text-align: center;"> Single, integer </td>
</tr>
<tr>
 <td style="text-align: left;">
TRUE </td><td style="text-align: center;"> FALSE </td><td style="text-align: center;"> &gt;0 </td><td style="text-align: center;"> cox         </td><td style="text-align: center;"> rpart </td><td style="text-align: center;"> Object of class 'Surv'
</td>
</tr>

</table>

<p>If an error along the lines of 'factor ... has new levels ...' is encountered, 
consult <code>?rare_level_sampler</code> for explanation and solutions.
</p>


<h3>Value</h3>

<p>An object of class <code>pre</code>. It contains the initial ensemble of 
rules and/or linear terms and a range of possible final ensembles. 
By default, the final ensemble employed by all other
methods and functions in package <code>pre</code> is selected using the 'minimum
cross validated error plus 1 standard error' criterion. All functions and 
methods for objects of class <code>pre</code> take a <code>penalty.parameter.val</code> 
argument, which can be used to select a different criterion.
</p>
<p>If only a set of rules needs to be generated, but the final regression model
should not be fitted, specify the hidden argument <code>fit.final = FALSE</code>.
</p>


<h3>Note</h3>

<p>Parts of the code for deriving rules from the nodes of trees was copied 
with permission from an internal function of the <code>partykit</code> package, written
by Achim Zeileis and Torsten Hothorn.
</p>


<h3>References</h3>

<p>Fokkema, M. (2020). Fitting prediction rule ensembles with R 
package pre. <em>Journal of Statistical Software, 92</em>(12), 1-30.
<a href="https://doi.org/10.18637/jss.v092.i12">doi:10.18637/jss.v092.i12</a>
</p>
<p>Fokkema, M. &amp; Strobl, C. (2020). Fitting prediction rule ensembles to psychological 
research data: An introduction and tutorial. <em>Psychological Methods 25</em>(5), 
636-652. <a href="https://doi.org/10.1037/met0000256">doi:10.1037/met0000256</a>, <a href="https://arxiv.org/abs/1907.05302">https://arxiv.org/abs/1907.05302</a>
</p>
<p>Friedman, J. H. (2001). Greedy function approximation: a gradient boosting 
machine. <em>The Annals of Applied Statistics, 29</em>(5), 1189-1232.
</p>
<p>Friedman, J. H., &amp; Popescu, B. E. (2008). Predictive learning via rule 
ensembles. <em>The Annals of Applied Statistics, 2</em>(3), 916-954, <a href="https://doi.org/10.1214/07-AOAS148">doi:10.1214/07-AOAS148</a>.
</p>
<p>Hothorn, T., &amp; Zeileis, A. (2015). partykit: A modular toolkit for recursive 
partytioning in R. <em>Journal of Machine Learning Research, 16</em>, 3905-3909.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.pre">print.pre</a></code>, <code><a href="#topic+plot.pre">plot.pre</a></code>, 
<code><a href="#topic+coef.pre">coef.pre</a></code>, <code><a href="#topic+importance.pre">importance.pre</a></code>, <code><a href="#topic+predict.pre">predict.pre</a></code>, 
<code><a href="#topic+interact">interact</a></code>, <code><a href="#topic+cvpre">cvpre</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Fit pre to a continuous response:
airq &lt;- airquality[complete.cases(airquality), ]
set.seed(42)
airq.ens &lt;- pre(Ozone ~ ., data = airq)
airq.ens
## Use relaxed lasso to estimate final model
airq.ens.rel &lt;- pre(Ozone ~ ., data = airq, relax = TRUE)
airq.ens.rel
## Use adaptive lasso to estimate final model
airq.ens.ad &lt;- pre(Ozone ~ ., data = airq, ad.alpha = 0)
airq.ens.ad

## Fit pre to a binary response:
airq2 &lt;- airquality[complete.cases(airquality), ]
airq2$Ozone &lt;- factor(airq2$Ozone &gt; median(airq2$Ozone))
set.seed(42)
airq.ens2 &lt;- pre(Ozone ~ ., data = airq2, family = "binomial")
airq.ens2

## Fit pre to a multivariate continuous response:
airq3 &lt;- airquality[complete.cases(airquality), ] 
set.seed(42)
airq.ens3 &lt;- pre(Ozone + Wind ~ ., data = airq3, family = "mgaussian")
airq.ens3

## Fit pre to a multinomial response:
set.seed(42)
iris.ens &lt;- pre(Species ~ ., data = iris, family = "multinomial")
iris.ens

## Fit pre to a survival response:
library("survival")
lung &lt;- lung[complete.cases(lung), ]
set.seed(42)
lung.ens &lt;- pre(Surv(time, status) ~ ., data = lung, family = "cox")
lung.ens

## Fit pre to a count response:
## Generate random data (partly based on Dobson (1990) Page 93: Randomized 
## Controlled Trial):
counts &lt;- rep(as.integer(c(18, 17, 15, 20, 10, 20, 25, 13, 12)), times = 10)
outcome &lt;- rep(gl(3, 1, 9), times = 10)
treatment &lt;- rep(gl(3, 3), times = 10)
noise1 &lt;- 1:90
set.seed(1)
noise2 &lt;- rnorm(90)
countdata &lt;- data.frame(treatment, outcome, counts, noise1, noise2)
set.seed(42)
count.ens &lt;- pre(counts ~ ., data = countdata, family = "poisson")
count.ens
</code></pre>

<hr>
<h2 id='predict.gpe'>Predicted values based on gpe ensemble</h2><span id='topic+predict.gpe'></span>

<h3>Description</h3>

<p>Predict function for <code><a href="#topic+gpe">gpe</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gpe'
predict(
  object,
  newdata = NULL,
  type = "link",
  penalty.par.val = "lambda.1se",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.gpe_+3A_object">object</code></td>
<td>
<p>of class <code><a href="#topic+gpe">gpe</a></code></p>
</td></tr>
<tr><td><code id="predict.gpe_+3A_newdata">newdata</code></td>
<td>
<p>optional new data to compute predictions for</p>
</td></tr>
<tr><td><code id="predict.gpe_+3A_type">type</code></td>
<td>
<p>argument passed to <code><a href="glmnet.html#topic+predict.cv.glmnet">predict.cv.glmnet</a></code></p>
</td></tr>
<tr><td><code id="predict.gpe_+3A_penalty.par.val">penalty.par.val</code></td>
<td>
<p>argument passed to <code>s</code> argument of <code><a href="glmnet.html#topic+predict.cv.glmnet">predict.cv.glmnet</a></code></p>
</td></tr>
<tr><td><code id="predict.gpe_+3A_...">...</code></td>
<td>
<p>Unused</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The initial training data is used if <code>newdata = NULL</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpe">gpe</a></code>
</p>

<hr>
<h2 id='predict.pre'>Predicted values based on final prediction rule ensemble</h2><span id='topic+predict.pre'></span>

<h3>Description</h3>

<p><code>predict.pre</code> generates predictions based on the final prediction rule
ensemble, for training or new (test) observations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pre'
predict(
  object,
  newdata = NULL,
  type = "link",
  penalty.par.val = "lambda.1se",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.pre_+3A_object">object</code></td>
<td>
<p>object of class <code><a href="#topic+pre">pre</a></code>.</p>
</td></tr>
<tr><td><code id="predict.pre_+3A_newdata">newdata</code></td>
<td>
<p>optional <code>data.frame</code> of new (test) observations, including all
predictor variables used for deriving the prediction rule ensemble.</p>
</td></tr>
<tr><td><code id="predict.pre_+3A_type">type</code></td>
<td>
<p>character string. The type of prediction required; the default
<code>type = "link"</code> is on the scale of the linear predictors. Alternatively,
for count and factor outputs, <code>type = "response"</code> may be specified to obtain
the fitted mean and fitted probabilities, respectively; <code>type = "class"</code> 
returns the predicted class membership.</p>
</td></tr>
<tr><td><code id="predict.pre_+3A_penalty.par.val">penalty.par.val</code></td>
<td>
<p>character or numeric. Value of the penalty parameter
<code class="reqn">\lambda</code> to be employed for selecting the final ensemble. The default
<code>"lambda.min"</code> employs the <code class="reqn">\lambda</code> value within 1 standard
error of the minimum cross-validated error. Alternatively, 
<code>"lambda.min"</code> may be specified, to employ the <code class="reqn">\lambda</code> value
with minimum cross-validated error, or a numeric value <code class="reqn">&gt;0</code> may be 
specified, with higher values yielding a sparser ensemble. To evaluate the 
trade-off between accuracy and sparsity of the final ensemble, inspect
<code>pre_object$glmnet.fit</code> and <code>plot(pre_object$glmnet.fit)</code>.</p>
</td></tr>
<tr><td><code id="predict.pre_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to 
<code><a href="glmnet.html#topic+predict.cv.glmnet">predict.cv.glmnet</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>newdata</code> is not provided, predictions for training data will be 
returned.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pre">pre</a></code>, <code><a href="#topic+plot.pre">plot.pre</a></code>, 
<code><a href="#topic+coef.pre">coef.pre</a></code>, <code><a href="#topic+importance.pre">importance.pre</a></code>, <code><a href="#topic+cvpre">cvpre</a></code>, 
<code><a href="#topic+interact">interact</a></code>, <code><a href="#topic+print.pre">print.pre</a></code>, 
<code><a href="glmnet.html#topic+predict.cv.glmnet">predict.cv.glmnet</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
train &lt;- sample(1:sum(complete.cases(airquality)), size = 100)
set.seed(42)
airq.ens &lt;- pre(Ozone ~ ., data = airquality[complete.cases(airquality),][train,])
predict(airq.ens)
predict(airq.ens, newdata = airquality[complete.cases(airquality),][-train,])


</code></pre>

<hr>
<h2 id='print.gpe'>Print a General Prediction Ensemble (gpe)</h2><span id='topic+print.gpe'></span>

<h3>Description</h3>

<p>Print a General Prediction Ensemble (gpe)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gpe'
print(x, penalty.par.val = "lambda.1se", digits = getOption("digits"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.gpe_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+gpe">gpe</a></code>.</p>
</td></tr>
<tr><td><code id="print.gpe_+3A_penalty.par.val">penalty.par.val</code></td>
<td>
<p>character or numeric. Value of the penalty parameter
<code class="reqn">\lambda</code> to be employed for selecting the final ensemble. The default
<code>"lambda.min"</code> employs the <code class="reqn">\lambda</code> value within 1 standard
error of the minimum cross-validated error. Alternatively, 
<code>"lambda.min"</code> may be specified, to employ the <code class="reqn">\lambda</code> value
with minimum cross-validated error, or a numeric value <code class="reqn">&gt;0</code> may be 
specified, with higher values yielding a sparser ensemble. To evaluate the 
trade-off between accuracy and sparsity of the final ensemble, inspect
<code>pre_object$glmnet.fit</code> and <code>plot(pre_object$glmnet.fit)</code>.</p>
</td></tr>
<tr><td><code id="print.gpe_+3A_digits">digits</code></td>
<td>
<p>Number of decimal places to print</p>
</td></tr>
<tr><td><code id="print.gpe_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to 
<code><a href="glmnet.html#topic+coef.cv.glmnet">coef.cv.glmnet</a></code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gpe">gpe</a></code> <code><a href="#topic+print.pre">print.pre</a></code>
</p>

<hr>
<h2 id='print.pre'>Print method for objects of class pre</h2><span id='topic+print.pre'></span>

<h3>Description</h3>

<p><code>print.pre</code> prints information about the generated prediction rule 
ensemble to the command line
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pre'
print(x, penalty.par.val = "lambda.1se", digits = getOption("digits"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.pre_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+pre">pre</a></code>.</p>
</td></tr>
<tr><td><code id="print.pre_+3A_penalty.par.val">penalty.par.val</code></td>
<td>
<p>character or numeric. Value of the penalty parameter
<code class="reqn">\lambda</code> to be employed for selecting the final ensemble. The default
<code>"lambda.min"</code> employs the <code class="reqn">\lambda</code> value within 1 standard
error of the minimum cross-validated error. Alternatively, 
<code>"lambda.min"</code> may be specified, to employ the <code class="reqn">\lambda</code> value
with minimum cross-validated error, or a numeric value <code class="reqn">&gt;0</code> may be 
specified, with higher values yielding a sparser ensemble. To evaluate the 
trade-off between accuracy and sparsity of the final ensemble, inspect
<code>pre_object$glmnet.fit</code> and <code>plot(pre_object$glmnet.fit)</code>.</p>
</td></tr>
<tr><td><code id="print.pre_+3A_digits">digits</code></td>
<td>
<p>Number of decimal places to print</p>
</td></tr>
<tr><td><code id="print.pre_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to 
<code><a href="glmnet.html#topic+coef.cv.glmnet">coef.cv.glmnet</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the CV error is estimated with data that was also used 
for learning rules and may be too optimistic. Use function <code><a href="#topic+cvpre">cvpre</a></code> to 
obtain a more realistic estimate of future prediction error.
</p>


<h3>Value</h3>

<p>Prints information about the fitted prediction rule ensemble.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pre">pre</a></code>, <code><a href="#topic+summary.pre">summary.pre</a></code>, <code><a href="#topic+plot.pre">plot.pre</a></code>, 
<code><a href="#topic+coef.pre">coef.pre</a></code>, <code><a href="#topic+importance.pre">importance.pre</a></code>, <code><a href="#topic+predict.pre">predict.pre</a></code>, 
<code><a href="#topic+interact">interact</a></code>, <code><a href="#topic+cvpre">cvpre</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(42)
airq.ens &lt;- pre(Ozone ~ ., data = airquality[complete.cases(airquality),])
print(airq.ens)
</code></pre>

<hr>
<h2 id='prune_pre'>Get the optimal lambda and gamma parameter values for an ensemble of given size</h2><span id='topic+prune_pre'></span>

<h3>Description</h3>

<p>Function <code>prune_pre</code> returns the optimal values of lambda and gamma for
the requested ensemble size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prune_pre(object, nonzero, plusminus = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prune_pre_+3A_object">object</code></td>
<td>
<p>an object of class <code><a href="#topic+pre">pre</a></code> that was fit using the relaxed lasso.
If an object of class <code><a href="#topic+pre">pre</a></code> is specified that was not fit using the relaxed lasso,
an error will be printed.</p>
</td></tr>
<tr><td><code id="prune_pre_+3A_nonzero">nonzero</code></td>
<td>
<p>maximum number of terms to retain.</p>
</td></tr>
<tr><td><code id="prune_pre_+3A_plusminus">plusminus</code></td>
<td>
<p>number of terms above and below <code>nonzero</code> for which CV results will be printed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The lambda and gamma values that yield optimal predictive accuracy for the specified
number of terms. These are invisibly returned, see Examples on how to use them. A sentence
describing what the optimal values are is printed to the command line, with an overview of
the performance (in terms of cross-validated accuracy and the number of terms retained) of 
lambda values near the optimum. If the specified number of terms to retain is lower than
what would be obtained using the <code>lambda.min</code> or <code>lambda.1se</code> criterion, a warning
will also be printed.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pre">pre</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Fit a rule ensemble to predict Ozone concentration
airq &lt;- airquality[complete.cases(airquality), ]
set.seed(42)
airq.ens &lt;- pre(Ozone ~ ., data = airq, relax = TRUE)

## Inspect the result (default lambda.1se criterion)
airq.ens

## Inspect the lambda path 
## (lower x-axis gives lambda values, upper x-axis corresponding no. of non-zero terms)
## Not run: plot(airq.ens$glmnet.fit)

## Accuracy still quite good with only 5 terms, obtain corresponding parameter values
opt_pars &lt;- prune_pre(airq.ens, nonzero = 5)
opt_pars

## Use the parameter values for interpretation and prediction, e.g.
predict(airq.ens, newdat = airq[c(22, 33), ], penalty = opt_pars$lambda, gamma = opt_pars$gamma)
summary(airq.ens, penalty = opt_pars$lambda, gamma = opt_pars$gamma)
print(airq.ens, penalty = opt_pars$lambda, gamma = opt_pars$gamma)

</code></pre>

<hr>
<h2 id='rare_level_sampler'>Dealing with rare factor levels in fitting prediction rule ensembles.</h2><span id='topic+rare_level_sampler'></span>

<h3>Description</h3>

<p>Provides a sampling function to be supplied to the <code>sampfrac</code>
argument of function <code>pre</code>, making sure that each level of specified factor(s)
are present in each sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rare_level_sampler(factors, data, sampfrac = 0.5, warning = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rare_level_sampler_+3A_factors">factors</code></td>
<td>
<p>Character vector with name(s) of factors with rare levels.</p>
</td></tr>
<tr><td><code id="rare_level_sampler_+3A_data">data</code></td>
<td>
<p><code>data.frame</code> containing the variables in the model. Response 
must be of class <code>factor</code> for classification, <code>numeric</code> for (count) 
regression, <code>Surv</code> for survival regression. Input variables must be of 
class numeric, factor or ordered factor. Otherwise, <code>pre</code> will attempt
to recode.</p>
</td></tr>
<tr><td><code id="rare_level_sampler_+3A_sampfrac">sampfrac</code></td>
<td>
<p>numeric value <code class="reqn">&gt; 0</code> and <code class="reqn">\le 1</code>. Specifies
the fraction of randomly selected training observations used to produce each 
tree. Values <code class="reqn">&lt; 1</code> will result in sampling without replacement (i.e., 
subsampling), a value of 1 will result in sampling with replacement 
(i.e., bootstrap sampling). Alternatively, a sampling function may be supplied, 
which should take arguments <code>n</code> (sample size) and <code>weights</code>.</p>
</td></tr>
<tr><td><code id="rare_level_sampler_+3A_warning">warning</code></td>
<td>
<p>logical. Whether a warning should be printed if observations with
rare factor levels are added to the training sample of the current iteration.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Categorical predictor variables (factors) with rare levels may be problematic 
in boosting algorithms employing sampling (which is employed by default in
function <code>pre</code>).
</p>
<p>If a sample in a given boosting iteration does not have any observations with a given
(rare) level of a factor, while this level is present in the full training dataset, and 
the factor is selected for splitting in the tree, then no prediction for that level of the factor
can be generated, resulting in an error. Note that boosting methods other than <code>pre</code> that also 
employ sampling (e.g., <code>gbm</code> or <code>xgboost</code>) may not generate an error in such cases, 
but also do not document how intermediate predictions are generated in such a case. It is likely that
these methods use one-hot-encoding of factors, which from a perspective of model interpretation 
introduces new problems, especially when the aim is to obtain a sparse set of rules as in 'pre'. 
</p>
<p>With function <code>pre()</code>, the rare-factor-level issue, if encountered, can be dealt with by the user 
in one of the following ways (in random order):
</p>

<ul>
<li><p> Use a sampling function that guarantees inclusion of rare factor levels in each sample. E.g., 
use <code>rare_level_sampler</code>, yielding a sampling function which creates training samples 
guaranteed to include each level of specified factor(s). Advantage: No loss of information, easy to implement, 
guaranteed to solve the issue. Disadvantage: May result in oversampling 
of observations with rare factor levels, potentially biasing results. The bias is likely small though, and 
will be larger for smaller sample sizes and sampling fractions, and for larger numbers of rare
levels. The latter will also increase computational demands. 
</p>
</li>
<li><p> Specify <code>learnrate = 0</code>. This results in a (su)bagging instead of boosting approach.
Advantage: Eliminates the rare-factor-level issue completely, because intermediate predictions
need not be computed. Disadvantage: Boosting with low learning rate often improves predictive accuracy.
</p>
</li>
<li><p> Data pre-processing: Before running function <code>pre()</code>, combine rare factor levels 
with other levels of the factors. Advantage: Limited loss of information. Disadvantage: Likely, but 
not guaranteed to solve the issue. 
</p>
</li>
<li><p> Data pre-processing: Apply one-hot encoding to the predictor matrix before applying function 'pre()'. This can easily be 
done through applying function <code><a href="stats.html#topic+model.matrix">model.matrix</a></code>. Advantage: Guaranteed to solve the error,
easy to implement. Disadvantage: One-hot-encoding increases the number of predictor variables 
which may reduce interpretability and, but probably to a lesser extent, accuracy.                                     
</p>
</li>
<li><p> Data pre-processing: Remove observations with rare factor levels from the dataset
before running function <code>pre()</code>. Advantage: Guaranteed to solve the error. Disadvantage: 
Removing outliers results in a loss of information, and may bias the results.
</p>
</li>
<li><p> Increase the value of <code>sampfrac</code> argument of function <code>pre()</code>. Advantage: Easy to
implement. Disadvantage: Larger samples are more likely but not guaranteed to contain all possible 
factor levels, thus not guaranteed to solve the issue.
</p>
</li></ul>



<h3>Value</h3>

<p>A sampling function, which generates sub- or bootstrap samples as usual in function <code>pre</code>, but 
checks if all levels of the specified factor(s) are present and adds observation with those levels if not. 
If <code>warning = TRUE</code>, a warning is issued).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pre">pre</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create dataset with two factors containing rare levels
dat &lt;- iris[iris$Species != "versicolor", ]
dat &lt;- rbind(dat, iris[iris$Species == "versicolor", ][1:5, ])
dat$factor2 &lt;- factor(rep(1:21, times = 5))

## Set up sampling function
samp_func &lt;- rare_level_sampler(c("Species", "factor2"), data = dat, 
                                  sampfrac = .51, warning = TRUE)

## Illustrate what it does                                                                   
N &lt;- nrow(dat)
wts &lt;- rep(1, times = nrow(dat))
set.seed(3)
dat[samp_func(n = N, weights = wts), ] # single sample
for (i in 1:500) dat[samp_func(n = N, weights = wts), ]
warnings() # to illustrate warnings that may occur when fitting a full PRE

## Illustrate use with function pre:
## (Note: low ntrees value merely to reduce computation time for the example)
set.seed(42)
# iris.ens &lt;- pre(Petal.Width ~ . , data = dat, ntrees = 20) # would yield error
iris.ens &lt;- pre(Petal.Width ~ . , data = dat, ntrees = 20, 
  sampfrac = samp_func) # should work
</code></pre>

<hr>
<h2 id='rTerm'>Wrapper Functions for terms in gpe</h2><span id='topic+rTerm'></span><span id='topic+lTerm'></span><span id='topic+eTerm'></span>

<h3>Description</h3>

<p>Wrapper functions for terms in gpe.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rTerm(x)

lTerm(x, lb = -Inf, ub = Inf, scale = 1/0.4)

eTerm(x, scale = 1/0.4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rTerm_+3A_x">x</code></td>
<td>
<p>Input symbol.</p>
</td></tr>
<tr><td><code id="rTerm_+3A_lb">lb</code></td>
<td>
<p>Lower quantile when winsorizing. <code>-Inf</code> yields no winsorizing in the lower tail.</p>
</td></tr>
<tr><td><code id="rTerm_+3A_ub">ub</code></td>
<td>
<p>Lower quantile when winsorizing. <code>Inf</code> yields no winsorizing in the upper tail.</p>
</td></tr>
<tr><td><code id="rTerm_+3A_scale">scale</code></td>
<td>
<p>Inverse value to time <code>x</code> by. Usually the standard deviation is used. <code>0.4 / scale</code> is used as the multiplier as suggested in Friedman &amp; Popescu (2008) and gives each linear term the same a-priori influence as a typical rule.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The motivation to use wrappers is to ease getting the different terms as shown in the examples and to simplify the formula passed to <code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a></code> in <code><a href="#topic+gpe">gpe</a></code>. <code>lTerm</code> potentially rescales and/or winsorizes <code>x</code> depending on the input. <code>eTerm</code> potentially rescale <code>x</code> depending on the input.
</p>


<h3>Value</h3>

<p><code>x</code> potentially transformed with additional information provided in the attributes.
</p>


<h3>References</h3>

<p>Friedman, J. H., &amp; Popescu, B. E. (2008). Predictive learning via rule ensembles. <em>The Annals of Applied Statistics, 2</em>(3), 916-954.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpe">gpe</a></code>, <code><a href="#topic+gpe_trees">gpe_trees</a></code> <code><a href="#topic+gpe_linear">gpe_linear</a></code> <code><a href="#topic+gpe_earth">gpe_earth</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mt &lt;- terms(
~ rTerm(x1 &lt; 0) + rTerm(x2 &gt; 0) + lTerm(x3) + eTerm(x4), 
specials = c("rTerm", "lTerm", "eTerm"))
attr(mt, "specials")
# $rTerm
# [1] 1 2
# 
# $lTerm
# [1] 3
# 
# $eTerm
# [1] 4

</code></pre>

<hr>
<h2 id='singleplot'>Create partial dependence plot for a single variable in a prediction rule 
ensemble (pre)</h2><span id='topic+singleplot'></span>

<h3>Description</h3>

<p><code>singleplot</code> creates a partial dependence plot, which shows the effect of
a predictor variable on the ensemble's predictions. Note that plotting partial 
dependence is computationally intensive. Computation time will increase fast 
with increasing numbers of observations and variables. For large 
datasets, package 'plotmo' (Milborrow, 2019) provides more efficient functions 
for plotting partial dependence and also supports 'pre' models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>singleplot(
  object,
  varname,
  penalty.par.val = "lambda.1se",
  nvals = NULL,
  type = "response",
  ylab = NULL,
  response = NULL,
  gamma = NULL,
  newdata = NULL,
  xlab = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="singleplot_+3A_object">object</code></td>
<td>
<p>an object of class <code><a href="#topic+pre">pre</a></code>.</p>
</td></tr>
<tr><td><code id="singleplot_+3A_varname">varname</code></td>
<td>
<p>character vector of length one, specifying the variable for
which the partial dependence plot should be created. Note that <code>varname</code>
should correspond to the variable as described in the model formula used
to generate the ensemble (i.e., including functions applied to the variable).</p>
</td></tr>
<tr><td><code id="singleplot_+3A_penalty.par.val">penalty.par.val</code></td>
<td>
<p>character or numeric. Value of the penalty parameter
<code class="reqn">\lambda</code> to be employed for selecting the final ensemble. The default
<code>"lambda.min"</code> employs the <code class="reqn">\lambda</code> value within 1 standard
error of the minimum cross-validated error. Alternatively, 
<code>"lambda.min"</code> may be specified, to employ the <code class="reqn">\lambda</code> value
with minimum cross-validated error, or a numeric value <code class="reqn">&gt;0</code> may be 
specified, with higher values yielding a sparser ensemble. To evaluate the 
trade-off between accuracy and sparsity of the final ensemble, inspect
<code>pre_object$glmnet.fit</code> and <code>plot(pre_object$glmnet.fit)</code>.</p>
</td></tr>
<tr><td><code id="singleplot_+3A_nvals">nvals</code></td>
<td>
<p>optional numeric vector of length one. For how many values of x
should the partial dependence plot be created?</p>
</td></tr>
<tr><td><code id="singleplot_+3A_type">type</code></td>
<td>
<p>character string. Type of prediction to be plotted on y-axis.
<code>type = "response"</code> gives fitted values for continuous outputs and
fitted probabilities for nominal outputs. <code>type = "link"</code> gives fitted
values for continuous outputs and linear predictor values for nominal outputs.</p>
</td></tr>
<tr><td><code id="singleplot_+3A_ylab">ylab</code></td>
<td>
<p>character. Label to be printed on the y-axis, defaults to the response
variable name(s).</p>
</td></tr>
<tr><td><code id="singleplot_+3A_response">response</code></td>
<td>
<p>numeric vector of length 1. Only relevant for multivariate gaussian 
and multinomial responses. If <code>NULL</code> (default), PDPs for all response 
variables or categories will be produced. A single integer can be specified, 
indicating for which response variable or category PDPs should be produced.</p>
</td></tr>
<tr><td><code id="singleplot_+3A_gamma">gamma</code></td>
<td>
<p>Mixing parameter for relaxed fits. See
<code><a href="glmnet.html#topic+coef.cv.glmnet">coef.cv.glmnet</a></code>.</p>
</td></tr>
<tr><td><code id="singleplot_+3A_newdata">newdata</code></td>
<td>
<p>Optional <code>data.frame</code> in which to look for variables 
with which to predict. If <code>NULL</code> (the default), the <code>data.frame</code> used to fit the 
original ensemble will be used. Smaller subsets of the original data can
be specified to (substantially) reduce computation time. See Details.</p>
</td></tr>
<tr><td><code id="singleplot_+3A_xlab">xlab</code></td>
<td>
<p>character. Label to be printed on the x-axis. If <code>NULL</code>,
the supplied <code>varname</code> will be printed on the x-axis.</p>
</td></tr>
<tr><td><code id="singleplot_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to 
<code><a href="graphics.html#topic+plot.default">plot.default</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, a partial dependence plot will be created for each unique
observed value of the specified predictor variable. See also section 8.1 of 
Friedman &amp; Popescu (2008).
</p>
<p>When the number of unique observed values is large, partial dependence functions
can take a very long time to compute. Specifying the <code>nvals</code> argument 
can substantially reduce computation time. When the
<code>nvals</code> argument is supplied, values for the minimum, maximum, and <code>(nvals - 2)</code>
intermediate values of the predictor variable will be plotted. Note that <code>nvals</code>
can be specified only for numeric and ordered input variables. If the plot is
requested for a nominal input variable, the <code>nvals</code> argument will be
ignored and a warning printed.
</p>
<p>Alternatively, <code>newdata</code> can be specified to provide a different (smaller) 
set of observations to compute partial dependence over.
If <code>mi_pre</code> was used to derive the original rule ensemble, 
function <code>mean_mi</code> can be used for this.
</p>


<h3>References</h3>

<p>Friedman, J. H., &amp; Popescu, B. E. (2008). Predictive learning 
via rule ensembles. <em>The Annals of Applied Statistics, 2</em>(3), 916-954.
</p>
<p>Milborrow, S. (2019). plotmo: Plot a model's residuals, response, and partial 
dependence plots. <a href="https://CRAN.R-project.org/package=plotmo">https://CRAN.R-project.org/package=plotmo</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pre">pre</a></code>, <code><a href="#topic+pairplot">pairplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>airq &lt;- airquality[complete.cases(airquality), ]
set.seed(42)
airq.ens &lt;- pre(Ozone ~ ., data = airquality[complete.cases(airquality),])
singleplot(airq.ens, "Temp")

## For multinomial and mgaussian families, one PDP is created per category or outcome
set.seed(42)
airq.ens3 &lt;- pre(Ozone + Wind ~ ., data = airq, family = "mgaussian")
singleplot(airq.ens3, varname = "Day")

set.seed(42)
iris.ens &lt;- pre(Species ~ ., data = iris, family = "multinomial")
singleplot(iris.ens, varname = "Petal.Width")
</code></pre>

<hr>
<h2 id='summary.gpe'>Summary method for a General Prediction Ensemble (gpe)</h2><span id='topic+summary.gpe'></span>

<h3>Description</h3>

<p><code>summary.gpe</code> prints information about the generated ensemble 
to the command line
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gpe'
summary(object, penalty.par.val = "lambda.1se", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.gpe_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+gpe">gpe</a></code>.</p>
</td></tr>
<tr><td><code id="summary.gpe_+3A_penalty.par.val">penalty.par.val</code></td>
<td>
<p>character or numeric. Value of the penalty parameter
<code class="reqn">\lambda</code> to be employed for selecting the final ensemble. The default
<code>"lambda.min"</code> employs the <code class="reqn">\lambda</code> value within 1 standard
error of the minimum cross-validated error. Alternatively, 
<code>"lambda.min"</code> may be specified, to employ the <code class="reqn">\lambda</code> value
with minimum cross-validated error, or a numeric value <code class="reqn">&gt;0</code> may be 
specified, with higher values yielding a sparser ensemble. To evaluate the 
trade-off between accuracy and sparsity of the final ensemble, inspect
<code>pre_object$glmnet.fit</code> and <code>plot(pre_object$glmnet.fit)</code>.</p>
</td></tr>
<tr><td><code id="summary.gpe_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to 
<code><a href="glmnet.html#topic+coef.cv.glmnet">coef.cv.glmnet</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the cv error is estimated with data that was also used 
for learning rules and may be too optimistic.
</p>


<h3>Value</h3>

<p>Prints information about the fitted ensemble.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpe">gpe</a></code>, <code><a href="#topic+print.gpe">print.gpe</a></code>, 
<code><a href="#topic+coef.gpe">coef.gpe</a></code>, <code><a href="#topic+predict.gpe">predict.gpe</a></code>
</p>

<hr>
<h2 id='summary.pre'>Summary method for objects of class pre</h2><span id='topic+summary.pre'></span>

<h3>Description</h3>

<p><code>summary.pre</code> prints information about the generated prediction rule 
ensemble to the command line
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pre'
summary(
  object,
  penalty.par.val = "lambda.1se",
  digits = getOption("digits"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.pre_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+pre">pre</a></code>.</p>
</td></tr>
<tr><td><code id="summary.pre_+3A_penalty.par.val">penalty.par.val</code></td>
<td>
<p>character or numeric. Value of the penalty parameter
<code class="reqn">\lambda</code> to be employed for selecting the final ensemble. The default
<code>"lambda.min"</code> employs the <code class="reqn">\lambda</code> value within 1 standard
error of the minimum cross-validated error. Alternatively, 
<code>"lambda.min"</code> may be specified, to employ the <code class="reqn">\lambda</code> value
with minimum cross-validated error, or a numeric value <code class="reqn">&gt;0</code> may be 
specified, with higher values yielding a sparser ensemble. To evaluate the 
trade-off between accuracy and sparsity of the final ensemble, inspect
<code>pre_object$glmnet.fit</code> and <code>plot(pre_object$glmnet.fit)</code>.</p>
</td></tr>
<tr><td><code id="summary.pre_+3A_digits">digits</code></td>
<td>
<p>Number of decimal places to print</p>
</td></tr>
<tr><td><code id="summary.pre_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to <code><a href="glmnet.html#topic+coef.cv.glmnet">coef.cv.glmnet</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the cv error is estimated with data that was also used 
for learning rules and may be too optimistic. Use <code><a href="#topic+cvpre">cvpre</a></code> to 
obtain a more realistic estimate of future prediction error.
</p>


<h3>Value</h3>

<p>Prints information about the fitted prediction rule ensemble.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pre">pre</a></code>, <code><a href="#topic+print.pre">print.pre</a></code>, <code><a href="#topic+plot.pre">plot.pre</a></code>, 
<code><a href="#topic+coef.pre">coef.pre</a></code>, <code><a href="#topic+importance.pre">importance.pre</a></code>, <code><a href="#topic+predict.pre">predict.pre</a></code>, 
<code><a href="#topic+interact">interact</a></code>, <code><a href="#topic+cvpre">cvpre</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(42)
airq.ens &lt;- pre(Ozone ~ ., data = airquality[complete.cases(airquality),])
summary(airq.ens)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
