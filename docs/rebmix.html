<!DOCTYPE html><html lang="en"><head><title>Help for package rebmix</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {rebmix}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#adult'><p>Adult Dataset</p></a></li>
<li><a href='#AIC-methods'>
<p>Akaike Information Criterion</p></a></li>
<li><a href='#AWE-methods'>
<p>Approximate Weight of Evidence Criterion</p></a></li>
<li><a href='#bearings'><p>Bearings Faults Detection Data</p></a></li>
<li><a href='#BFSMIX-methods'>
<p>Predicts Class Membership Based Upon the Best First Search Algorithm</p></a></li>
<li><a href='#BIC-methods'>
<p>Bayesian Information Criterion</p></a></li>
<li><a href='#bins-methods'>
<p>Binning of Data</p></a></li>
<li><a href='#boot-methods'>
<p>Parametric or Nonparametric Bootstrap for Standard Error and Coefficient of Variation Estimation</p></a></li>
<li><a href='#chistogram-methods'>
<p>Compact Histogram Calculation</p></a></li>
<li><a href='#chunk-methods'>
<p>Extracts Chunk from Train and Test Datasets</p></a></li>
<li><a href='#CLC-methods'>
<p>Classification Likelihood Criterion</p></a></li>
<li><a href='#demix-methods'>
<p>Empirical Density Calculation</p></a></li>
<li><a href='#dfmix-methods'>
<p>Predictive Marginal Density Calculation</p></a></li>
<li><a href='#EM.Control-class'><p>Class <code>"EM.Control"</code></p></a></li>
<li><a href='#EMMIX-methods'>
<p>EM Algorithm for Univariate or Multivariate Finite Mixture Estimation</p></a></li>
<li><a href='#EMMIX.Theta-class'><p>Class <code>"EMMIX.Theta"</code></p></a></li>
<li><a href='#fhistogram-methods'>
<p>Fast Histogram Calculation</p></a></li>
<li><a href='#galaxy'><p>Galaxy Dataset</p></a></li>
<li><a href='#Histogram-class'><p>Class <code>"Histogram"</code></p></a></li>
<li><a href='#HQC-methods'>
<p>Hannan-Quinn Information Criterion</p></a></li>
<li><a href='#ICL-methods'>
<p>Integrated Classification Likelihood Criterion</p></a></li>
<li><a href='#ICLBIC-methods'>
<p>Approximate Integrated Classification Likelihood Criterion</p></a></li>
<li><a href='#iris'><p>Iris Data Set</p></a></li>
<li><a href='#kseq'>
<p>Sequence of Bins or Nearest Neighbours Generation</p></a></li>
<li><a href='#labelmoments-methods'>
<p>Label Image Moments</p></a></li>
<li><a href='#logL'>
<p>Log Likelihood</p></a></li>
<li><a href='#mapclusters-methods'>
<p>Map Clusters</p></a></li>
<li><a href='#MDL-methods'>
<p>Minimum Description Length</p></a></li>
<li><a href='#mergelabels-methods'>
<p>Merge Labels Based on Probability Adjacency Matrix</p></a></li>
<li><a href='#optbins-methods'>
<p>Optimal Numbers of Bins Calculation</p></a></li>
<li><a href='#PC-methods'>
<p>Partition Coefficient</p></a></li>
<li><a href='#pemix-methods'>
<p>Empirical Distribution Function Calculation</p></a></li>
<li><a href='#pfmix-methods'>
<p>Predictive Marginal Distribution Function Calculation</p></a></li>
<li><a href='#plot-methods'>
<p>Plots RNGMIX, REBMIX, RCLRMIX and RCLSMIX Output</p></a></li>
<li><a href='#PRD-methods'>
<p>Total of Positive Relative Deviations</p></a></li>
<li><a href='#RCLRMIX-class'><p>Class <code>"RCLRMIX"</code></p></a></li>
<li><a href='#RCLRMIX-methods'>
<p>Predicts Cluster Membership Based Upon a Model Trained by REBMIX</p></a></li>
<li><a href='#RCLS.chunk-class'><p>Class <code>"RCLS.chunk"</code></p></a></li>
<li><a href='#RCLSMIX-class'><p>Class <code>"RCLSMIX"</code></p></a></li>
<li><a href='#RCLSMIX-methods'>
<p>Predicts Class Membership Based Upon a Model Trained by REBMIX</p></a></li>
<li><a href='#REBMIX-class'><p>Class <code>"REBMIX"</code></p></a></li>
<li><a href='#rebmix-internal'><p>Internal rebmix Functions, Methods and Classes</p></a></li>
<li><a href='#REBMIX-methods'>
<p>REBMIX Algorithm for Univariate or Multivariate Finite Mixture Estimation</p></a></li>
<li><a href='#REBMIX.boot-class'><p>Class <code>"REBMIX.boot"</code></p></a></li>
<li><a href='#RNGMIX-class'><p>Class <code>"RNGMIX"</code></p></a></li>
<li><a href='#RNGMIX-methods'>
<p>Random Univariate or Multivariate Finite Mixture Generation</p></a></li>
<li><a href='#RNGMIX.Theta-class'><p>Class <code>"RNGMIX.Theta"</code></p></a></li>
<li><a href='#sensorlessdrive'><p>Sensorless Drive Faults Detection Data</p></a></li>
<li><a href='#split-methods'>
<p>Splits Dataset into Train and Test Datasets</p></a></li>
<li><a href='#SSE-methods'>
<p>Sum of Squares Error</p></a></li>
<li><a href='#steelplates'><p>Steel Plates Faults Recognition Data</p></a></li>
<li><a href='#truck'><p>Truck Dataset</p></a></li>
<li><a href='#weibull'><p>Weibull Dataset 8.1</p></a></li>
<li><a href='#weibullnormal'><p>Weibull-normal Simulated Dataset</p></a></li>
<li><a href='#wine'><p>Wine Recognition Data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>2.16.0</td>
</tr>
<tr>
<td>Title:</td>
<td>Finite Mixture Modeling, Clustering &amp; Classification</td>
</tr>
<tr>
<td>Description:</td>
<td>Random univariate and multivariate finite mixture model generation, estimation, clustering, latent class analysis and classification. Variables can be continuous, discrete, independent or dependent and may follow normal, lognormal, Weibull, gamma, Gumbel, binomial, Poisson, Dirac, uniform or circular von Mises parametric families.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, stats, utils, graphics, grDevices</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Author:</td>
<td>Marko Nagode <a href="https://orcid.org/0000-0003-0637-3812"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Branislav Panic <a href="https://orcid.org/0000-0001-8349-8550"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Jernej Klemenc <a href="https://orcid.org/0000-0002-6778-6728"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Simon Oman <a href="https://orcid.org/0000-0001-8213-0818"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Marko Nagode &lt;marko.nagode@fs.uni-lj.si&gt;</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-07-10 12:35:02 UTC; PCNagodeM</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-07-10 14:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='adult'>Adult Dataset</h2><span id='topic+adult'></span>

<h3>Description</h3>

<p>The <code>adult</code> dataset containing 48842 instances with 16 continuous, binary and discrete variables was extracted from the census bureau database. Extraction was done by Barry Becker from the 1994 census bureau database.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(adult)
</code></pre>


<h3>Format</h3>

<p><code>adult</code> is a data frame with 48842 cases (rows) and 16 variables (columns) named:
</p>

<ol>
<li>
<p><code>Type</code> binary <code>train</code> or <code>test</code>.

</p>
</li>
<li>
<p><code>Age</code> continuous.

</p>
</li>
<li>
<p><code>Workclass</code> one of the 8 discrete values
<code>private</code>,
<code>self-emp-not-inc</code>,
<code>self-emp-inc</code>,
<code>federal-gov</code>,
<code>local-gov</code>,
<code>state-gov</code>,
<code>without-pay</code> or
<code>never-worked</code>.

</p>
</li>
<li>
<p><code>Fnlwgt</code> stands for continuous final weight.

</p>
</li>
<li>
<p><code>Education</code> one of the 16 discrete values
<code>bachelors</code>,
<code>some-college</code>,
<code>11th</code>,
<code>hs-grad</code>,
<code>prof-school</code>,
<code>assoc-acdm</code>,
<code>assoc-voc</code>,
<code>9th</code>,
<code>7th-8th</code>,
<code>12th</code>,
<code>masters</code>,
<code>1st-4th</code>,
<code>10th</code>,
<code>doctorate</code>,
<code>5th-6th</code> or
<code>preschool</code>.

</p>
</li>
<li>
<p><code>Education.Num</code> continuous.

</p>
</li>
<li>
<p><code>Marital.Status</code> one of the 7 discrete values
<code>married-civ-spouse</code>,
<code>divorced</code>,
<code>never-married</code>,
<code>separated</code>,
<code>widowed</code>,
<code>married-spouse-absent</code> or
<code>married-af-spouse</code>.

</p>
</li>
<li>
<p><code>Occupation</code> one of the 14 discrete values
<code>tech-support</code>,
<code>craft-repair</code>,
<code>other-service</code>,
<code>sales</code>,
<code>exec-managerial</code>,
<code>prof-specialty</code>,
<code>handlers-cleaners</code>,
<code>machine-op-inspct</code>,
<code>adm-clerical</code>,
<code>farming-fishing</code>,
<code>transport-moving</code>,
<code>priv-house-serv</code>,
<code>protective-serv</code> or
<code>armed-forces</code>.

</p>
</li>
<li>
<p><code>Relationship</code> one of the 6 discrete values
<code>wife</code>,
<code>own-child</code>,
<code>husband</code>,
<code>not-in-family</code>,
<code>other-relative</code> or
<code>unmarried</code>.

</p>
</li>
<li>
<p><code>Race</code> one of the 5 discrete values
<code>white</code>,
<code>asian-pac-islander</code>,
<code>amer-indian-eskimo</code>,
<code>other</code> or
<code>black</code>.

</p>
</li>
<li>
<p><code>Sex</code> binary <code>female</code> or <code>male</code>.

</p>
</li>
<li>
<p><code>Capital.Gain</code> continuous.

</p>
</li>
<li>
<p><code>Capital.Loss</code> continuous.

</p>
</li>
<li>
<p><code>Hours.Per.Week</code> continuous.

</p>
</li>
<li>
<p><code>Native.Country</code> one of the 41 discrete values
<code>united-states</code>,
<code>cambodia</code>,
<code>england</code>,
<code>puerto-rico</code>,
<code>canada</code>,
<code>germany</code>,
<code>outlying-us(guam-usvi-etc)</code>,
<code>india</code>,
<code>japan</code>,
<code>greece</code>,
<code>south</code>,
<code>china</code>,
<code>cuba</code>,
<code>iran</code>,
<code>honduras</code>,
<code>philippines</code>,
<code>italy</code>,
<code>poland</code>,
<code>jamaica</code>,
<code>vietnam</code>,
<code>mexico</code>,
<code>portugal</code>,
<code>ireland</code>,
<code>france</code>,
<code>dominican-republic</code>,
<code>laos</code>,
<code>ecuador</code>,
<code>taiwan</code>,
<code>haiti</code>,
<code>columbia</code>,
<code>hungary</code>,
<code>guatemala</code>,
<code>nicaragua</code>,
<code>scotland</code>,
<code>thailand</code>,
<code>yugoslavia</code>,
<code>el-salvador</code>,
<code>trinadad&amp;tobago</code>,
<code>peru</code>,
<code>hong</code> or
<code>holand-netherlands</code>.

</p>
</li>
<li>
<p><code>Income</code> binary <code>&lt;=50k</code> or <code>&gt;50k</code>.

</p>
</li></ol>



<h3>Source</h3>

<p>A. Asuncion and D. J. Newman. Uci machine learning repository, 2007. <a href="http://archive.ics.uci.edu/ml/">http://archive.ics.uci.edu/ml/</a>.
</p>


<h3>References</h3>

<p>A. Asuncion and D. J. Newman. Uci machine learning repository, 2007. <a href="http://archive.ics.uci.edu/ml/">http://archive.ics.uci.edu/ml/</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(adult)

# Find complete cases.

adult &lt;- adult[complete.cases(adult),]

# Show level attributes for binary and discrete variables.

levels(adult[["Type"]])
levels(adult[["Workclass"]])
levels(adult[["Education"]])
levels(adult[["Marital.Status"]])
levels(adult[["Occupation"]])
levels(adult[["Relationship"]])
levels(adult[["Race"]])
levels(adult[["Sex"]])
levels(adult[["Native.Country"]])
levels(adult[["Income"]])
</code></pre>

<hr>
<h2 id='AIC-methods'>
Akaike Information Criterion
</h2><span id='topic+AIC'></span><span id='topic+AIC3'></span><span id='topic+AIC4'></span><span id='topic+AICc'></span><span id='topic+CAIC'></span><span id='topic+AIC-methods'></span><span id='topic+AIC+2CREBMIX-method'></span><span id='topic+AIC+2CREBMVNORM-method'></span><span id='topic+AIC3-methods'></span><span id='topic+AIC3+2CREBMIX-method'></span><span id='topic+AIC3+2CREBMVNORM-method'></span><span id='topic+AIC4-methods'></span><span id='topic+AIC4+2CREBMIX-method'></span><span id='topic+AIC4+2CREBMVNORM-method'></span><span id='topic+AICc-methods'></span><span id='topic+AICc+2CREBMIX-method'></span><span id='topic+AICc+2CREBMVNORM-method'></span><span id='topic+CAIC-methods'></span><span id='topic+CAIC+2CREBMIX-method'></span><span id='topic+CAIC+2CREBMVNORM-method'></span>

<h3>Description</h3>

<p>Returns the Akaike information criterion at <code>pos</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'REBMIX'
AIC(x = NULL, pos = 1, ...)
## S4 method for signature 'REBMIX'
AIC3(x = NULL, pos = 1, ...)
## S4 method for signature 'REBMIX'
AIC4(x = NULL, pos = 1, ...)
## S4 method for signature 'REBMIX'
AICc(x = NULL, pos = 1, ...)
## S4 method for signature 'REBMIX'
CAIC(x = NULL, pos = 1, ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AIC-methods_+3A_x">x</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="AIC-methods_+3A_pos">pos</code></td>
<td>

<p>a desired row number in <code>x@summary</code> for which the information criterion is calculated. The default value is <code>1</code>.
</p>
</td></tr>
<tr><td><code id="AIC-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "REBMIX")</code></dt><dd><p>an object of class <code>REBMIX</code>.</p>
</dd>
<dt><code>signature(x = "REBMVNORM")</code></dt><dd><p>an object of class <code>REBMVNORM</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>H. Akaike. A new look at the statistical model identification. IEEE Transactions on Automatic Control, 19(51):716-723, 1974.<br /><br />
A. F. M. Smith and D. J. Spiegelhalter. Bayes factors and choice criteria for linear
models. Journal of the Royal Statistical Society. Series B, 42(2):213-220, 1980. https://www.jstor.org/stable/2984964.<br /><br />
H. Bozdogan. Model selection and akaike's information criterion (aic): The general theory and its
analytical extensions. Psychometrika, 52(3):345-370, 1987. <a href="https://doi.org/10.1007/BF02294361">doi:10.1007/BF02294361</a>.<br /><br />
C. M. Hurvich and C.-L. Tsai. Regression and time series model selection in small samples. Biometrika,
76(2):297-307, 1989. https://www.jstor.org/stable/2336663.
</p>

<hr>
<h2 id='AWE-methods'>
Approximate Weight of Evidence Criterion
</h2><span id='topic+AWE'></span><span id='topic+AWE-methods'></span><span id='topic+AWE+2CREBMIX-method'></span><span id='topic+AWE+2CREBMVNORM-method'></span>

<h3>Description</h3>

<p>Returns the approximate weight of evidence criterion at <code>pos</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'REBMIX'
AWE(x = NULL, pos = 1, ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AWE-methods_+3A_x">x</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="AWE-methods_+3A_pos">pos</code></td>
<td>

<p>a desired row number in <code>x@summary</code> for which the information criterion is calculated. The default value is <code>1</code>.
</p>
</td></tr>
<tr><td><code id="AWE-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "REBMIX")</code></dt><dd><p>an object of class <code>REBMIX</code>.</p>
</dd>
<dt><code>signature(x = "REBMVNORM")</code></dt><dd><p>an object of class <code>REBMVNORM</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>J. D. Banfield and A. E. Raftery. Model-based gaussian and non-gaussian clustering. Biometrics, 49(3):803-821, 1993. <a href="https://doi.org/10.2307/2532201">doi:10.2307/2532201</a>.
</p>

<hr>
<h2 id='bearings'>Bearings Faults Detection Data</h2><span id='topic+bearings'></span>

<h3>Description</h3>

<p>These data are the results of the extraction process from the vibrational data of healthy and faulty bearings. Different faults are considered: faultless (1), defect on outer race (2), 
defect on inner race (3) and defect on ball (4). The extracted features are: root mean square (RMS), square root of the amplitude (SRA), kurtosis value (KV), skewness value (SV), 
peak to peak value (PPV), crest factor (CF), impulse factor (IF), margin factor (MF), shape factor (SF), kurtosis factor (KF), frequency centre (FC), root mean square frequency (RMSF) 
and root variance frequency (RVF).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(bearings)
</code></pre>


<h3>Format</h3>

<p><code>bearings</code> is a data frame with 1906 cases (rows) and 14 variables (columns) named:
</p>

<ol>
<li>
<p><code>RMS</code> continuous.

</p>
</li>
<li>
<p><code>SRA</code> continuous.

</p>
</li>
<li>
<p><code>KV</code> continuous.

</p>
</li>
<li>
<p><code>SV</code> continuous.

</p>
</li>
<li>
<p><code>PPV</code> continuous.

</p>
</li>
<li>
<p><code>CF</code> continuous.

</p>
</li>
<li>
<p><code>IF</code> continuous.

</p>
</li>
<li> 
<p><code>MF</code> continuous.

</p>
</li>
<li>
<p><code>SF</code> continuous.

</p>
</li>
<li>
<p><code>KF</code> continuous.

</p>
</li>
<li>
<p><code>FC</code> continuous.

</p>
</li>
<li>
<p><code>RMSF</code> continuous.

</p>
</li>
<li>
<p><code>RVF</code> continuous.

</p>
</li>
<li>
<p><code>Class</code> discrete <code>1</code>, <code>2</code>, <code>3</code> or <code>4</code>.

</p>
</li></ol>



<h3>Source</h3>

<p>Case Western Reserve University Bearing Data Center Website <a href="https://engineering.case.edu/bearingdatacenter/welcome">https://engineering.case.edu/bearingdatacenter/welcome</a>.
</p>


<h3>References</h3>

<p>B. Panic, J. Klemenc and M. Nagode. Gaussian mixture model based classification revisited: Application to the bearing fault classification. Journal of Mechanical Engineering,
66(4):215-226, 2020. <a href="https://doi.org/10.5545/sv-jme.2020.6563">doi:10.5545/sv-jme.2020.6563</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(bearings)

# Split dataset into train (75

set.seed(3)

Bearings &lt;- split(p = 0.75, Dataset = bearings, class = 14)

# Estimate number of components, component weights and component
# parameters for train subsets.

bearingsest &lt;- REBMIX(model = "REBMVNORM",
  Dataset = a.train(Bearings),
  Preprocessing = "histogram",
  cmax = 15,
  Criterion = "BIC")

# Classification.

bearingscla &lt;- RCLSMIX(model = "RCLSMVNORM",
  x = list(bearingsest),
  Dataset = a.test(Bearings),
  Zt = a.Zt(Bearings))

bearingscla

summary(bearingscla)

## End(Not run)
</code></pre>

<hr>
<h2 id='BFSMIX-methods'>
Predicts Class Membership Based Upon the Best First Search Algorithm
</h2><span id='topic+BFSMIX'></span><span id='topic+BFSMIX-methods'></span><span id='topic+BFSMIX+2CRCLSMIX-method'></span><span id='topic+BFSMIX+2CRCLSMVNORM-method'></span>

<h3>Description</h3>

<p>Returns as default the optimized RCLSMIX algorithm output for mixtures of conditionally independent normal, lognormal, Weibull, gamma, Gumbel, binomial, Poisson, Dirac, uniform or von Mises component densities. If <code>model</code> equals <code>"RCLSMVNORM"</code> optimized output for mixtures of multivariate normal component densities with unrestricted variance-covariance matrices is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'RCLSMIX'
BFSMIX(model = "RCLSMIX", x = list(), Dataset = data.frame(),
       Zt = factor(), ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BFSMIX-methods_+3A_model">model</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="BFSMIX-methods_+3A_x">x</code></td>
<td>

<p>a list of objects of class <code>REBMIX</code> of length <code class="reqn">o</code> obtained by running <code><a href="#topic+REBMIX">REBMIX</a></code> on <code class="reqn">g = 1, \ldots, s</code> train datasets <code class="reqn">Y_{\mathrm{train}g}</code> all of length <code class="reqn">n_{\mathrm{train}g}</code>.
For the train datasets the corresponding class membership <code class="reqn">\bm{\Omega}_{g}</code> is known. This yields
<code class="reqn">n_{\mathrm{train}} = \sum_{g = 1}^{s} n_{\mathrm{train}g}</code>, while <code class="reqn">Y_{\mathrm{train}q} \cap Y_{\mathrm{train}g} = \emptyset</code> for all <code class="reqn">q \neq g</code>.
Each object in the list corresponds to one chunk, e.g., <code class="reqn">(y_{1j}, y_{3j})^{\top}</code>. The default value is <code>list()</code>.
</p>
</td></tr>
<tr><td><code id="BFSMIX-methods_+3A_dataset">Dataset</code></td>
<td>

<p>a data frame containing test dataset <code class="reqn">Y_{\mathrm{test}}</code> of length <code class="reqn">n_{\mathrm{test}}</code>. For the test dataset the corresponding class membership <code class="reqn">\bm{\Omega}_{g}</code> is not known.
The default value is <code>data.frame()</code>.
</p>
</td></tr>
<tr><td><code id="BFSMIX-methods_+3A_zt">Zt</code></td>
<td>

<p>a factor of true class membership <code class="reqn">\bm{\Omega}_{g}</code> for the test dataset. The default value is <code>factor()</code>.
</p>
</td></tr>
<tr><td><code id="BFSMIX-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an optimized object of class <code>RCLSMIX</code> or <code>RCLSMVNORM</code>.
</p>


<h3>Methods</h3>


<dl>
<dt><code>signature(model = "RCLSMIX")</code></dt><dd><p>a character giving the default class name <code>"RCLSMIX"</code> for mixtures of conditionally independent normal, lognormal, Weibull, gamma, Gumbel, binomial, Poisson, Dirac, uniform or von Mises component densities.</p>
</dd>
<dt><code>signature(model = "RCLSMVNORM")</code></dt><dd><p>a character giving the class name <code>"RCLSMVNORM"</code> for mixtures of multivariate normal component densities with unrestricted variance-covariance matrices.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>R. Kohavi and G. H. John. Wrappers for feature subset selection, Artificial Intelligence, 97(1-2):273-324, 1997.
<a href="https://doi.org/10.1016/S0004-3702%2897%2900043-X">doi:10.1016/S0004-3702(97)00043-X</a>.
</p>

<hr>
<h2 id='BIC-methods'>
Bayesian Information Criterion
</h2><span id='topic+BIC'></span><span id='topic+BIC-methods'></span><span id='topic+BIC+2CREBMIX-method'></span><span id='topic+BIC+2CREBMVNORM-method'></span>

<h3>Description</h3>

<p>Returns the Bayesian information criterion at <code>pos</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'REBMIX'
BIC(x = NULL, pos = 1, ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BIC-methods_+3A_x">x</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="BIC-methods_+3A_pos">pos</code></td>
<td>

<p>a desired row number in <code>x@summary</code> for which the information criterion is calculated. The default value is <code>1</code>.
</p>
</td></tr>
<tr><td><code id="BIC-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "REBMIX")</code></dt><dd><p>an object of class <code>REBMIX</code>.</p>
</dd>
<dt><code>signature(x = "REBMVNORM")</code></dt><dd><p>an object of class <code>REBMVNORM</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>G. Schwarz. Estimating the dimension of the model. The Annals of Statistics, 6(2):461-464, 1978.
</p>

<hr>
<h2 id='bins-methods'>
Binning of Data
</h2><span id='topic+bins'></span><span id='topic+bins-methods'></span><span id='topic+bins+2Clist-method'></span>

<h3>Description</h3>

<p>Returns the list of data frames containing bin means <code class="reqn">\bar{\bm{y}}_{1}, \ldots, \bar{\bm{y}}_{v}</code> and frequencies <code class="reqn">k_{1}, \ldots, k_{v}</code> for the histogram preprocessing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'list'
bins(Dataset = list(), K = matrix(),
     ymin = numeric(), ymax = numeric(), ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bins-methods_+3A_dataset">Dataset</code></td>
<td>

<p>a list of length <code class="reqn">n_{\mathrm{D}}</code> of data frames of size <code class="reqn">n \times d</code> containing <em>d</em>-dimensional datasets. Each of the <code class="reqn">d</code> columns
represents one random variable. Numbers of observations <code class="reqn">n</code> equal the number of rows in the datasets.
</p>
</td></tr>
<tr><td><code id="bins-methods_+3A_k">K</code></td>
<td>

<p>a matrix of size <code class="reqn">n_{\mathrm{D}} \times d</code> containing numbers of bins <code class="reqn">v_{1}, \ldots, v_{d}</code> for the histogram. 
If, e.g., <code>K = matrix(c(10, 15, 18, 5, 7, 9), byrow = TRUE, ncol = 3)</code> than <code class="reqn">d = 3</code> and the list <code>Dataset</code> contains <code class="reqn">n_{\mathrm{D}} = 2</code> data frames. Hence, different numbers of bins can be assigned to <code class="reqn">y_{1}, \ldots, y_{d}</code>.
The default value is <code>matrix()</code>.
</p>
</td></tr>
<tr><td><code id="bins-methods_+3A_ymin">ymin</code></td>
<td>

<p>a vector of length <code class="reqn">d</code> containing minimum observations. The default value is <code>numeric()</code>.
</p>
</td></tr>
<tr><td><code id="bins-methods_+3A_ymax">ymax</code></td>
<td>

<p>a vector of length <code class="reqn">d</code> containing maximum observations. The default value is <code>numeric()</code>.
</p>
</td></tr>
<tr><td><code id="bins-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "list")</code></dt><dd><p>a list of data frames.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Branislav Panic, Marko Nagode</p>


<h3>References</h3>

<p>M. Nagode. Finite mixture modeling via REBMIX.
Journal of Algorithms and Optimization, 3(2):14-28, 2015. <a href="https://repozitorij.uni-lj.si/Dokument.php?id=127674&amp;lang=eng">https://repozitorij.uni-lj.si/Dokument.php?id=127674&amp;lang=eng</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate multivariate normal datasets.

n &lt;- c(7, 10)

Theta &lt;- new("RNGMVNORM.Theta", c = 2, d = 2)

a.theta1(Theta, 1) &lt;- c(8, 6)
a.theta1(Theta, 2) &lt;- c(6, 8)
a.theta2(Theta, 1) &lt;- c(8, 2, 2, 4)
a.theta2(Theta, 2) &lt;- c(2, 1, 1, 4)

sim2d &lt;- RNGMIX(model = "RNGMVNORM", 
  Dataset.name = paste("sim2d_", 1:2, sep = ""),
  rseed = -1,
  n = n,
  Theta = a.Theta(Theta))

# Calculate optimal numbers of bins.

opt.k &lt;- optbins(Dataset = sim2d@Dataset,
  Rule = "Knuth equal",
  kmin = 1, 
  kmax = 20)

opt.k

Y &lt;- bins(Dataset = sim2d@Dataset, K = opt.k)

Y

opt.k &lt;- optbins(Dataset = sim2d@Dataset,
  Rule = "Knuth unequal",
  kmin = 1, 
  kmax = 20)

opt.k

Y &lt;- bins(Dataset = sim2d@Dataset, K = opt.k)

Y
</code></pre>

<hr>
<h2 id='boot-methods'>
Parametric or Nonparametric Bootstrap for Standard Error and Coefficient of Variation Estimation
</h2><span id='topic+boot'></span><span id='topic+boot-methods'></span><span id='topic+boot+2CREBMIX-method'></span><span id='topic+boot+2CREBMVNORM-method'></span><span id='topic+show+2CREBMIX.boot-method'></span><span id='topic+show+2CREBMVNORM.boot-method'></span><span id='topic+summary+2CREBMIX.boot-method'></span><span id='topic+summary+2CREBMVNORM.boot-method'></span>

<h3>Description</h3>

<p>Returns as default the boot output for mixtures of conditionally independent normal,
lognormal, Weibull, gamma, Gumbel, binomial, Poisson, Dirac, uniform or von Mises component densities. If
<code>x</code> is of class <code>RNGMVNORM</code> the boot output for mixtures of multivariate normal
component densities with unrestricted variance-covariance matrices is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'REBMIX'
boot(x = NULL, rseed = -1, pos = 1, Bootstrap = "parametric",
     B = 100, n = numeric(), replace = TRUE, prob = numeric(), ...)
## ... and for other signatures
## S4 method for signature 'REBMIX.boot'
summary(object, ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="boot-methods_+3A_x">x</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="boot-methods_+3A_rseed">rseed</code></td>
<td>

<p>set the random seed to any negative integer value to initialize the sequence. The first bootstrap dataset corresponds to it.
For each next bootstrap dataset the random seed is decremented <code class="reqn">r_{\mathrm{seed}} = r_{\mathrm{seed}} - 1</code>. The default value is <code>-1</code>.
</p>
</td></tr>
<tr><td><code id="boot-methods_+3A_pos">pos</code></td>
<td>

<p>a desired row number in <code>x@summary</code> to be bootstrapped. The default value is <code>1</code>.
</p>
</td></tr>
<tr><td><code id="boot-methods_+3A_bootstrap">Bootstrap</code></td>
<td>

<p>a character giving the bootstrap type. One of default <code>"parametric"</code> or <code>"nonparametric"</code>.
</p>
</td></tr>
<tr><td><code id="boot-methods_+3A_b">B</code></td>
<td>

<p>number of bootstrap datasets. The default value is <code>100</code>.
</p>
</td></tr>
<tr><td><code id="boot-methods_+3A_n">n</code></td>
<td>

<p>number of observations. The default value is <code>numeric()</code>.
</p>
</td></tr>
<tr><td><code id="boot-methods_+3A_replace">replace</code></td>
<td>

<p>logical. The sampling is with replacement if <code>TRUE</code>, see also <code><a href="base.html#topic+sample">sample</a></code>. The default value is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="boot-methods_+3A_prob">prob</code></td>
<td>

<p>a vector of length <code class="reqn">n</code> containing probability weights, see also <code><a href="base.html#topic+sample">sample</a></code>. The default value is <code>numeric()</code>.
</p>
</td></tr>
<tr><td><code id="boot-methods_+3A_...">...</code></td>
<td>

<p>maximum number of components <code>cmax</code>, minimum number of components <code>cmin</code> and further arguments to <code><a href="base.html#topic+sample">sample</a></code>; additional arguments affecting the summary produced.
</p>
</td></tr>
<tr><td><code id="boot-methods_+3A_object">object</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>REBMIX.boot</code> or <code>REBMVNORM.boot</code>.
</p>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "REBMIX")</code></dt><dd><p>an object of class <code>REBMIX</code> for mixtures of conditionally independent normal, lognormal, Weibull, gamma, Gumbel, binomial, Poisson, Dirac, uniform or von Mises component densities.</p>
</dd>
<dt><code>signature(x = "REBMVNORM")</code></dt><dd><p>an object of class <code>REBMVNORM</code> for mixtures of multivariate normal component densities with unrestricted variance-covariance matrices.</p>
</dd>
<dt><code>signature(object = "REBMIX")</code></dt><dd><p>an object of class <code>REBMIX</code>.</p>
</dd>
<dt><code>signature(object = "REBMVNORM")</code></dt><dd><p>an object of class <code>REBMVNORM</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>G. McLachlan and D. Peel. Finite Mixture Models. John Wiley &amp; Sons, New York, 2000.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(weibull)

# Create object of class EM.Control.

EM &lt;- new("EM.Control", strategy = "single", variant = "EM",
  acceleration = "fixed", acceleration.multiplier = 1.0, tolerance = 1.0E-4,
  maximum.iterations = 1000)

# Estimate number of components, component weights and component parameters.

weibullest &lt;- REBMIX(Dataset = list(weibull),
  Preprocessing = "kernel density estimation",
  cmin = 2,
  cmax = 4,
  Criterion = "BIC",
  pdf = "Weibull",
  EMcontrol = EM)

# Plot finite mixture.

plot(weibullest, what = c("pdf", "marginal cdf", "IC", "logL", "D"),
  nrow = 3, ncol = 2, npts = 1000)

# Bootstrap finite mixture.

weibullboot &lt;- boot(x = weibullest, Bootstrap = "nonparametric", B = 10)

weibullboot

## End(Not run)
</code></pre>

<hr>
<h2 id='chistogram-methods'>
Compact Histogram Calculation
</h2><span id='topic+chistogram'></span><span id='topic+chistogram-methods'></span><span id='topic+chistogram+2CHistogram-method'></span>

<h3>Description</h3>

<p>Returns an object of class <code>Histogram</code>. The method can be called recursively.
This way more than one dataset can be binned into one histogram. The method is time consuming.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'Histogram'
chistogram(x = NULL, Dataset = data.frame(),
           K = numeric(), ymin = numeric(), ymax = numeric(), ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chistogram-methods_+3A_x">x</code></td>
<td>

<p>an object of class <code>Histogram</code>.
</p>
</td></tr>
<tr><td><code id="chistogram-methods_+3A_dataset">Dataset</code></td>
<td>

<p>a data frame of size <code class="reqn">n \times d</code> containing <em>d</em>-dimensional dataset. Each of the <code class="reqn">d</code> columns
represents one random variable. Number of observations <code class="reqn">n</code> equals the number of rows in the dataset.
</p>
</td></tr>
<tr><td><code id="chistogram-methods_+3A_k">K</code></td>
<td>

<p>an integer or a vector of length <code class="reqn">d</code> containing numbers of bins <code class="reqn">v</code>.
</p>
</td></tr>
<tr><td><code id="chistogram-methods_+3A_ymin">ymin</code></td>
<td>

<p>a vector of length <code class="reqn">d</code> containing minimum observations.
</p>
</td></tr>
<tr><td><code id="chistogram-methods_+3A_ymax">ymax</code></td>
<td>

<p>a vector of length <code class="reqn">d</code> containing maximum observations.
</p>
</td></tr>
<tr><td><code id="chistogram-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "Histogram")</code></dt><dd><p>an object of class <code>Histogram</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Create three datasets.

set.seed(1)

n &lt;- 15

Dataset1 &lt;- as.data.frame(cbind(rnorm(n, 157, 8), rnorm(n, 71, 10)))
Dataset2 &lt;- as.data.frame(cbind(rnorm(n, 244, 14), rnorm(n, 61, 29)))
Dataset3 &lt;- as.data.frame(cbind(rnorm(n, 198, 8), rnorm(n, 252, 13)))

apply(Dataset1, 2, range)
apply(Dataset2, 2, range)
apply(Dataset3, 2, range)

# Bin the first dataset.

hist &lt;- chistogram(Dataset = Dataset1, K = c(4, 5), ymin = c(100.0, 0.0), ymax = c(300.0, 300.0))

# Bin the second dataset.

hist &lt;- chistogram(x = hist, Dataset = Dataset2)

# Bin the third dataset.

hist &lt;- chistogram(x = hist, Dataset = Dataset3)

hist
</code></pre>

<hr>
<h2 id='chunk-methods'>
Extracts Chunk from Train and Test Datasets
</h2><span id='topic+chunk'></span><span id='topic+chunk-methods'></span><span id='topic+chunk+2CRCLS.chunk-method'></span><span id='topic+show+2CRCLS.chunk-method'></span>

<h3>Description</h3>

<p>Returns (invisibly) the object containing train and test observations <code class="reqn">\bm{x}_{1}, \ldots, \bm{x}_{n}</code> as well as true class membership <code class="reqn">\bm{\Omega}_{g}</code> for the test dataset. Vectors <code class="reqn">\bm{x}</code> are subvectors of
<code class="reqn">\bm{y} = (y_{1}, \ldots, y_{d})^{\top}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'RCLS.chunk'
chunk(x = NULL, variables = expression(1:d))
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chunk-methods_+3A_x">x</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="chunk-methods_+3A_variables">variables</code></td>
<td>

<p>a vector containing indices of variables in subvectors <code class="reqn">\bm{x}</code>. The default value is <code>1:d</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>RCLS.chunk</code>.
</p>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "RCLS.chunk")</code></dt><dd><p>an object of class <code>RCLS.chunk</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)

# Split dataset into train (75%) and test (25%) subsets.

set.seed(5)

Iris &lt;- split(p = 0.75, Dataset = iris, class = 5)

# Extract chunk from train and test datasets.

Iris14 &lt;- chunk(x = Iris, variables = c(1,4))

Iris14
</code></pre>

<hr>
<h2 id='CLC-methods'>
Classification Likelihood Criterion
</h2><span id='topic+CLC'></span><span id='topic+CLC-methods'></span><span id='topic+CLC+2CREBMIX-method'></span><span id='topic+CLC+2CREBMVNORM-method'></span>

<h3>Description</h3>

<p>Returns the classification likelihood criterion at <code>pos</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'REBMIX'
CLC(x = NULL, pos = 1, ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CLC-methods_+3A_x">x</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="CLC-methods_+3A_pos">pos</code></td>
<td>

<p>a desired row number in <code>x@summary</code> for which the information criterion is calculated. The default value is <code>1</code>.
</p>
</td></tr>
<tr><td><code id="CLC-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "REBMIX")</code></dt><dd><p>an object of class <code>REBMIX</code>.</p>
</dd>
<dt><code>signature(x = "REBMVNORM")</code></dt><dd><p>an object of class <code>REBMVNORM</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>C. Biernacki and G. Govaert. Using the classification likelihood to choose the number of clusters. In
E. J. Wegman and S. P. Azen, editors, Computing Science and Statistics, 1997.
</p>

<hr>
<h2 id='demix-methods'>
Empirical Density Calculation
</h2><span id='topic+demix'></span><span id='topic+demix-methods'></span><span id='topic+demix+2CREBMIX-method'></span><span id='topic+demix+2CREBMVNORM-method'></span>

<h3>Description</h3>

<p>Returns the data frame containing observations <code class="reqn">\bm{x}_{1}, \ldots, \bm{x}_{n}</code> and empirical
densities <code class="reqn">f_{1}, \ldots, f_{n}</code> for the kernel density estimation or <em>k</em>-nearest neighbour or bin means <code class="reqn">\bar{\bm{x}}_{1}, \ldots, \bar{\bm{x}}_{v}</code>
and empirical densities <code class="reqn">f_{1}, \ldots, f_{v}</code> for the histogram preprocessing. Vectors <code class="reqn">\bm{x}</code> and <code class="reqn">\bar{\bm{x}}</code> are subvectors of
<code class="reqn">\bm{y} = (y_{1}, \ldots, y_{d})^{\top}</code> and <code class="reqn">\bar{\bm{y}} = (\bar{y}_{1}, \ldots, \bar{y}_{d})^{\top}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'REBMIX'
demix(x = NULL, pos = 1, variables = expression(1:d), ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="demix-methods_+3A_x">x</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="demix-methods_+3A_pos">pos</code></td>
<td>

<p>a desired row number in <code>x@summary</code> for which the empirical densities are calculated. The default value is <code>1</code>.
</p>
</td></tr>
<tr><td><code id="demix-methods_+3A_variables">variables</code></td>
<td>

<p>a vector containing indices of variables in subvectors <code class="reqn">\bm{x}</code> or <code class="reqn">\bar{\bm{x}}</code>. The default value is <code>1:d</code>.
</p>
</td></tr>
<tr><td><code id="demix-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "REBMIX")</code></dt><dd><p>an object of class <code>REBMIX</code>.</p>
</dd>
<dt><code>signature(x = "REBMVNORM")</code></dt><dd><p>an object of class <code>REBMVNORM</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>M. Nagode and M. Fajdiga. The rebmix algorithm for the univariate finite mixture estimation.
Communications in Statistics - Theory and Methods, 40(5):876-892, 2011a. <a href="https://doi.org/10.1080/03610920903480890">doi:10.1080/03610920903480890</a>.<br /><br />
M. Nagode and M. Fajdiga. The rebmix algorithm for the multivariate finite mixture estimation.
Communications in Statistics - Theory and Methods, 40(11):2022-2034, 2011b. <a href="https://doi.org/10.1080/03610921003725788">doi:10.1080/03610921003725788</a>.<br /><br />
M. Nagode. Finite mixture modeling via REBMIX.
Journal of Algorithms and Optimization, 3(2):14-28, 2015. <a href="https://repozitorij.uni-lj.si/Dokument.php?id=127674&amp;lang=eng">https://repozitorij.uni-lj.si/Dokument.php?id=127674&amp;lang=eng</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate simulated dataset.

n &lt;- c(15, 15)

Theta &lt;- new("RNGMIX.Theta", c = 2, pdf = rep("normal", 3))

a.theta1(Theta, 1) &lt;- c(10, 20, 30)
a.theta1(Theta, 2) &lt;- c(3, 4, 5)
a.theta2(Theta, 1) &lt;- c(3, 2, 1)
a.theta2(Theta, 2) &lt;- c(15, 10, 5)

simulated &lt;- RNGMIX(Dataset.name = paste("simulated_", 1:4, sep = ""),
  rseed = -1,
  n = n,
  Theta = a.Theta(Theta))

# Create object of class EM.Control.

EM &lt;- new("EM.Control", strategy = "best")

# Estimate number of components, component weights and component parameters.

simulatedest &lt;- REBMIX(model = "REBMVNORM",
  Dataset = a.Dataset(simulated),
  Preprocessing = "h",
  cmax = 8,
  Criterion = "BIC",
  EMcontrol = NULL)

# Preprocess simulated dataset.

f &lt;- demix(simulatedest, pos = 3, variables = c(1, 3))

f

# Plot finite mixture.

opar &lt;- plot(simulatedest, pos = 3, nrow = 3, ncol = 1)

par(usr = opar[[2]]$usr, mfg = c(2, 1))

text(x = f[, 1], y = f[, 2], labels = format(f[, 3], digits = 3), cex = 0.8, pos = 1)
</code></pre>

<hr>
<h2 id='dfmix-methods'>
Predictive Marginal Density Calculation
</h2><span id='topic+dfmix'></span><span id='topic+dfmix-methods'></span><span id='topic+dfmix+2CREBMIX-method'></span><span id='topic+dfmix+2CREBMVNORM-method'></span>

<h3>Description</h3>

<p>Returns the data frame containing observations <code class="reqn">\bm{x}_{1}, \ldots, \bm{x}_{n}</code> and
predictive marginal densities <code class="reqn">f(\bm{x} | c, \bm{w}, \bm{\Theta})</code>. Vectors <code class="reqn">\bm{x}</code> are subvectors of
<code class="reqn">\bm{y} = (y_{1}, \ldots, y_{d})^{\top}</code>. If <code class="reqn">\bm{x} = \bm{y}</code> the method returns the data frame containing observations <code class="reqn">\bm{y}_{1}, \ldots, \bm{y}_{n}</code> and
the corresponding predictive mixture densities <code class="reqn">f(\bm{y} | c, \bm{w}, \bm{\Theta})</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'REBMIX'
dfmix(x = NULL, Dataset = data.frame(), pos = 1, variables = expression(1:d), ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dfmix-methods_+3A_x">x</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="dfmix-methods_+3A_dataset">Dataset</code></td>
<td>

<p>a data frame containing observations <code class="reqn">\bm{y} = (y_{1}, \ldots, y_{d})^{\top}</code> for which the predictive marginal densities are calculated. The default value is <code>data.frame()</code>.
</p>
</td></tr>
<tr><td><code id="dfmix-methods_+3A_pos">pos</code></td>
<td>

<p>a desired row number in <code>x@summary</code> for which the predictive marginal densities are calculated. The default value is <code>1</code>.
</p>
</td></tr>
<tr><td><code id="dfmix-methods_+3A_variables">variables</code></td>
<td>

<p>a vector containing indices of variables in subvectors <code class="reqn">\bm{x}</code>. The default value is <code>1:d</code>.
</p>
</td></tr>
<tr><td><code id="dfmix-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "REBMIX")</code></dt><dd><p>an object of class <code>REBMIX</code>.</p>
</dd>
<dt><code>signature(x = "REBMVNORM")</code></dt><dd><p>an object of class <code>REBMVNORM</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>M. Nagode and M. Fajdiga. The rebmix algorithm for the univariate finite mixture estimation.
Communications in Statistics - Theory and Methods, 40(5):876-892, 2011a. <a href="https://doi.org/10.1080/03610920903480890">doi:10.1080/03610920903480890</a>.<br /><br />
M. Nagode and M. Fajdiga. The rebmix algorithm for the multivariate finite mixture estimation.
Communications in Statistics - Theory and Methods, 40(11):2022-2034, 2011b. <a href="https://doi.org/10.1080/03610921003725788">doi:10.1080/03610921003725788</a>.<br /><br />
M. Nagode. Finite mixture modeling via REBMIX.
Journal of Algorithms and Optimization, 3(2):14-28, 2015. <a href="https://repozitorij.uni-lj.si/Dokument.php?id=127674&amp;lang=eng">https://repozitorij.uni-lj.si/Dokument.php?id=127674&amp;lang=eng</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate simulated dataset.

n &lt;- c(15, 15)

Theta &lt;- new("RNGMIX.Theta", c = 2, pdf = rep("normal", 3))

a.theta1(Theta, 1) &lt;- c(10, 20, 30)
a.theta1(Theta, 2) &lt;- c(3, 4, 5)
a.theta2(Theta, 1) &lt;- c(3, 2, 1)
a.theta2(Theta, 2) &lt;- c(15, 10, 5)

simulated &lt;- RNGMIX(Dataset.name = paste("simulated_", 1:4, sep = ""),
  rseed = -1,
  n = n,
  Theta = a.Theta(Theta))

# Number of classes or nearest neighbours to be processed.

K &lt;- c(as.integer(1 + log2(sum(n))), # Minimum v follows Sturges rule.
  as.integer(10 * log10(sum(n)))) # Maximum v follows log10 rule.

# Estimate number of components, component weights and component parameters.

simulatedest &lt;- REBMIX(model = "REBMVNORM",
  Dataset = a.Dataset(simulated),
  Preprocessing = "h",
  cmax = 4,
  Criterion = "BIC")

# Preprocess simulated dataset.

Dataset &lt;- data.frame(c(-7, 1), NA, c(3, 7))

f &lt;- dfmix(simulatedest, Dataset = Dataset, pos = 3, variables = c(1, 3))

f

# Plot finite mixture.

opar &lt;- plot(simulatedest, pos = 3, nrow = 3, ncol = 1,
  contour.drawlabels = TRUE, contour.labcex = 0.6)

par(usr = opar[[2]]$usr, mfg = c(2, 1))

points(x = f[, 1], y = f[, 2])

text(x = f[, 1], y = f[, 2], labels = format(f[, 3], digits = 3), cex = 0.8, pos = 4)
</code></pre>

<hr>
<h2 id='EM.Control-class'>Class <code>"EM.Control"</code></h2><span id='topic+EM.Control-class'></span><span id='topic+show+2CEM.Control-method'></span>

<h3>Description</h3>

<p>Object of class <code>EM.Control</code>.</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>new("EM.Control", ...)</code>. Accessor methods for the slots are <code>a.strategy(x = NULL)</code>,
<code>a.variant(x = NULL)</code>, <code>a.acceleration(x = NULL)</code>, <code>a.tolerance(x = NULL)</code>, <code>a.acceleration.multiplier(x = NULL)</code>, 
<code>a.maximum.iterations(x = NULL)</code>, <code>a.K(x = NULL)</code> and <code>a. eliminate.zero.components (x = NULL)</code>, where <code>x</code> stands for an object of 
class <code>EM.Control</code>. Setter methods <code>a.strategy(x = NULL)</code>, <code>a.variant(x = NULL)</code>,
<code>a.acceleration(x = NULL)</code>, <code>a.tolerance(x = NULL)</code>, <code>a.acceleration.multiplier(x = NULL)</code>, <code>a.maximum.iterations(x = NULL)</code>, 
<code>a.K(x = NULL)</code> and <code>eliminate.zero.components</code> are provided to write to <code>strategy</code>, <code>variant</code>, <code>acceleration</code>, <code>tolerance</code>, 
<code>acceleration.multiplier</code>, <code>maximum.iterations</code> and <code>eliminate.zero.components</code> slot respectively.
</p>


<h3>Slots</h3>


<dl>
<dt><code>strategy</code>:</dt><dd>
<p>a character containing the EM and REBMIX strategy. One of <code>"none"</code>, <code>"exhaustive"</code>, <code>"best"</code> and <code>"single"</code>. The default value is <code>"none"</code>.
</p>
</dd>
<dt><code>variant</code>:</dt><dd>
<p>a character containing the type of the EM algorithm to be used. One of <code>"EM"</code> of <code>"ECM"</code>. The default value is <code>"EM"</code>.
</p>
</dd>
<dt><code>acceleration</code>:</dt><dd>
<p>a character containing the type of acceleration of the EM iteration increment. One of <code>"fixed"</code>, <code>"line"</code> or <code>"golden"</code>. The default value is <code>"fixed"</code>.
</p>
</dd>
<dt><code>tolerance</code>:</dt><dd>
<p>tolerance value for the EM convergence criteria. The default value is 1.0E-4.
</p>
</dd>
<dt><code>acceleration.multiplier</code>:</dt><dd>
<p>acceleration.multiplier <code class="reqn">a_{\mathrm{EM}}</code>, <code class="reqn">1.0 \leq a_{\mathrm{EM}} \leq 2.0</code>. acceleration.multiplier for the EM step increment. The default value is 1.0.
</p>
</dd>
<dt><code>maximum.iterations</code>:</dt><dd>
<p>a positive integer containing the maximum allowed number of iterations of the EM algorithm. The default value is 1000.
</p>
</dd>
<dt><code>K</code>:</dt><dd>
<p>an integer containing the number of bins for the histogram based EM algorithm. This option can reduce computational time drastically if the datasets contain a large number of observations <code class="reqn">n</code> and <code>K</code> is set to the value <code class="reqn">\ll n</code>. The default value of 0 means that the EM algorithm runs over all <code class="reqn">n</code>.
</p>
</dd>
<dt><code>eliminate.zero.components</code>:</dt><dd>
<p>a logical indicating if the componenets with <code class="reqn">w_{l} = 0</code> should be eliminated from output. Only used with <code>EMMIX-methods</code>.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Branislav Panic</p>


<h3>References</h3>

<p>B. Panic, J. Klemenc, M. Nagode. Improved initialization of the EM algorithm for mixture model parameter estimation.
Mathematics, 8(3):373, 2020.
<a href="https://doi.org/10.3390/math8030373">doi:10.3390/math8030373</a>.<br /><br />
A. P. Dempster et al. Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society. Series B, 39(1):1-38, 1977.
https://www.jstor.org/stable/2984875.<br /><br />
G. Celeux and G. Govaert. A classification EM algorithm for clustering and two stochastic versions, Computational Statistics &amp; Data Analysis, 14(3):315:332, 1992.
<a href="https://doi.org/10.1016/0167-9473%2892%2990042-E">doi:10.1016/0167-9473(92)90042-E</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Inline creation by new call.

EM &lt;- new("EM.Control", strategy = "exhaustive", 
  variant = "EM", acceleration = "fixed", 
  tolerance = 1e-4, acceleration.multiplier = 1.0, 
  maximum.iterations = 1000, K = 0)

EM

# Creation of EM object with setter method.

EM &lt;- new("EM.Control")

a.strategy(EM) &lt;- "exhaustive"
a.variant(EM) &lt;- "EM"
a.acceleration(EM) &lt;- "fixed"
a.tolerance(EM) &lt;- 1e-4
a.acceleration.multiplier(EM) &lt;- 1.0
a.maximum.iterations(EM) &lt;- 1000
a.K(EM) &lt;- 256

EM
</code></pre>

<hr>
<h2 id='EMMIX-methods'>
EM Algorithm for Univariate or Multivariate Finite Mixture Estimation
</h2><span id='topic+EMMIX'></span><span id='topic+EMMIX-methods'></span><span id='topic+EMMIX+2CREBMIX-method'></span><span id='topic+EMMIX+2CREBMVNORM-method'></span>

<h3>Description</h3>

<p>Returns as default the EM algorithm output for mixtures of conditionally independent normal, lognormal, Weibull, gamma, 
Gumbel, binomial, Poisson, Dirac or von Mises component densities. If <code>model</code> equals <code>"REBMVNORM"</code> output 
for mixtures of multivariate normal component densities with unrestricted variance-covariance matrices is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'REBMIX'
EMMIX(model = "REBMIX", Dataset = list(), 
       Theta = NULL, EMcontrol = NULL, ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EMMIX-methods_+3A_model">model</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="EMMIX-methods_+3A_dataset">Dataset</code></td>
<td>

<p>a list of length <code class="reqn">n_{\mathrm{D}}</code> of data frames of size <code class="reqn">n \times d</code> containing <em>d</em>-dimensional datasets. Each of the <code class="reqn">d</code> columns
represents one random variable. Numbers of observations <code class="reqn">n</code> equal the number of rows in the datasets.
</p>
</td></tr>
<tr><td><code id="EMMIX-methods_+3A_theta">Theta</code></td>
<td>

<p>an object of class <code>EMMIX.Theta</code> or <code>EMMVNORM.Theta</code>.
</p>
</td></tr>
<tr><td><code id="EMMIX-methods_+3A_emcontrol">EMcontrol</code></td>
<td>

<p>an object of class <code>EM.Control</code>.
</p>
</td></tr>
<tr><td><code id="EMMIX-methods_+3A_...">...</code></td>
<td>

<p>currently not used.  
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>REBMIX</code> or <code>REBMVNORM</code>.
</p>


<h3>Methods</h3>


<dl>
<dt><code>signature(model = "REBMIX")</code></dt><dd><p>a character giving the default class name <code>"REBMIX"</code> for mixtures of conditionally 
independent normal, lognormal, Weibull, gamma, Gumbel, binomial, Poisson, Dirac or von Mises component densities.</p>
</dd>
<dt><code>signature(model = "REBMVNORM")</code></dt><dd><p>a character giving the class name <code>"REBMVNORM"</code> for mixtures 
of multivariate normal component densities with unrestricted variance-covariance matrices.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Branislav Panic</p>


<h3>References</h3>

<p>B. Panic, J. Klemenc, M. Nagode. Improved initialization of the EM algorithm for mixture model parameter estimation.
Mathematics, 8(3):373, 2020.
<a href="https://doi.org/10.3390/math8030373">doi:10.3390/math8030373</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
devAskNewPage(ask = TRUE)

# Load faithful dataset.

data(faithful)

# Plot faithfull dataset.

plot(faithful)

# Number of dimensions.

d &lt;- ncol(faithful)

# Obtain 2 component solution with Gaussian mixtures.

c &lt;- 2

# Create EMMVNORM.Theta object with new call.

Theta &lt;- new("EMMVNORM.Theta", d = d, c = c)

# Set parameters of Theta.
# Weights.

a.w(Theta) &lt;- c(0.5, 0.5)

# Means.

a.theta1.all(Theta) &lt;- c(2.0, 55.0, 4.5, 80.0)

# Covariances.

a.theta2.all(Theta) &lt;- c(1, 0, 0, 1, 1, 0, 0, 1)

# Run EMMIX method.

model &lt;- EMMIX(model = "REBMVNORM", Dataset = list(faithful), Theta = Theta)

# show.

model

# summary.

summary(model)

# plot.

plot(model, nrow = 3, ncol = 2, what = c("pdf", "marginal pdf", "marginal cdf"))

# Create EMMIX.Theta object with new call.

Theta &lt;- new("EMMIX.Theta", c = c, pdf = c("normal", "normal"))

# Set parameters of Theta.
# Weights.

a.w(Theta) &lt;- c(0.5, 0.5)

# Means.

a.theta1.all(Theta) &lt;- c(2.0, 55.0, 4.5, 80.0)

# Covariances.

a.theta2.all(Theta) &lt;- c(1, 1, 1, 1)

# Run EMMIX method.

model &lt;- EMMIX(Dataset = list(faithful), Theta = Theta)

# show.

model

# summary.

summary(model)

# plot.

plot(model, nrow = 3, ncol = 2, what = c("pdf", "marginal pdf", "marginal cdf"))

## End(Not run)
</code></pre>

<hr>
<h2 id='EMMIX.Theta-class'>Class <code>"EMMIX.Theta"</code></h2><span id='topic+EMMIX.Theta-class'></span><span id='topic+EMMVNORM.Theta-class'></span><span id='topic+show+2CEMMIX.Theta-method'></span><span id='topic+show+2CEMMVNORM.Theta-method'></span>

<h3>Description</h3>

<p>Object of class <code>EMMIX.Theta</code>.</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>new("EMMIX.Theta", ...)</code>. Accessor methods for the slots are <code>a.c(x = NULL)</code>, <code>a.d(x = NULL)</code>,
<code>a.pdf(x = NULL)</code> and <code>a.Theta(x = NULL)</code>, where <code>x</code> stands for an object of class <code>EMMIX.Theta</code>. Setter methods
<code>a.theta1(x = NULL, l = numeric())</code>, <code>a.theta2(x = NULL, l = numeric())</code>, <code>a.theta3(x = NULL, l = numeric())</code>, 
<code>a.theta1.all(x = NULL)</code>, <code>a.theta2.all(x = NULL)</code>, <code>a.theta3.all(x = NULL)</code> and <code>a.w(x = NULL)</code> 
are provided to write to <code>Theta</code> slot, where <code class="reqn">l = 1, \ldots, c</code>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>c</code>:</dt><dd>
<p>number of components <code class="reqn">c &gt; 0</code>. The default value is <code>1</code>.
</p>
</dd>
<dt><code>d</code>:</dt><dd>
<p>number of dimensions.
</p>
</dd>
<dt><code>pdf</code>:</dt><dd>
<p>a character vector of length <code class="reqn">d</code> containing continuous or discrete parametric family types. One of <code>"normal"</code>, <code>"lognormal"</code>, <code>"Weibull"</code>, <code>"gamma"</code>, <code>"Gumbel"</code>, <code>"binomial"</code>, <code>"Poisson"</code>, <code>"Dirac"</code> or <code>"vonMises"</code>.
</p>
</dd>
<dt><code>Theta</code>:</dt><dd>
<p>a list containing <code class="reqn">c</code> parametric family types <code>pdfl</code>. One of <code>"normal"</code>, <code>"lognormal"</code>, <code>"Weibull"</code>, <code>"gamma"</code>, <code>"Gumbel"</code>, <code>"binomial"</code>, <code>"Poisson"</code>, <code>"Dirac"</code> or circular <code>"vonMises"</code> defined for <code class="reqn">0 \leq y_{i} \leq 2 \pi</code>.
Component parameters <code>theta1.l</code> follow the parametric family types. One of <code class="reqn">\mu_{il}</code> for normal, lognormal, Gumbel and von Mises distributions and <code class="reqn">\theta_{il}</code> for Weibull, gamma, binomial, Poisson and Dirac distributions.
Component parameters <code>theta2.l</code> follow <code>theta1.l</code>. One of <code class="reqn">\sigma_{il}</code> for normal, lognormal and Gumbel distributions, <code class="reqn">\beta_{il}</code> for Weibull and gamma distributions, <code class="reqn">p_{il}</code> for binomial distribution, <code class="reqn">\kappa_{il}</code> for von Mises distribution.
Component parameters <code>theta3.l</code> follow <code>theta2.l</code>. One of <code class="reqn">\xi_{il} \in \{-1, 1\}</code> for Gumbel distribution.
</p>
</dd>
<dt><code>w</code>:</dt><dd>
<p>a vector of length <code class="reqn">c</code> containing component weights <code class="reqn">w_{l}</code> summing to 1.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Branislav Panic</p>


<h3>Examples</h3>

<pre><code class='language-R'>Theta &lt;- new("EMMIX.Theta", c = 2, pdf = c("normal", "Gumbel"))  

a.w(Theta) &lt;- c(0.4, 0.6)

a.theta1(Theta, l = 1) &lt;- c(2, 10)
a.theta2(Theta, l = 1) &lt;- c(0.5, 2.3)
a.theta3(Theta, l = 1) &lt;- c(NA, 1.0)
a.theta1(Theta, l = 2) &lt;- c(20, 50)
a.theta2(Theta, l = 2) &lt;- c(3, 4.2)
a.theta3(Theta, l = 2) &lt;- c(NA, -1.0)

Theta

Theta &lt;- new("EMMIX.Theta", c = 2, pdf = c("normal", "Gumbel", "Poisson"))  

a.w(Theta) &lt;- c(0.4, 0.6)

a.theta1.all(Theta) &lt;- c(2, 10, 30, 20, 50, 60)
a.theta2.all(Theta) &lt;- c(0.5, 2.3, NA, 3, 4.2, NA)
a.theta3.all(Theta) &lt;- c(NA, 1.0, NA, NA, -1.0, NA)

Theta

Theta &lt;- new("EMMVNORM.Theta", c = 2, d = 3)

a.w(Theta) &lt;- c(0.4, 0.6)

a.theta1(Theta, l = 1) &lt;- c(2, 10, -20)
a.theta2(Theta, l = 1) &lt;- c(9, 0, 0, 0, 4, 0, 0, 0, 1)
a.theta1(Theta, l = 2) &lt;- c(-2.4, -15.1, 30)
a.theta2(Theta, l = 2) &lt;- c(4, -3.2, -0.2, -3.2, 4, 0, -0.2, 0, 1)

Theta

Theta &lt;- new("EMMVNORM.Theta", c = 2, d = 3)

a.w(Theta) &lt;- c(0.4, 0.6)

a.theta1.all(Theta) &lt;- c(2, 10, -20, -2.4, -15.1, 30)

a.theta2.all(Theta) &lt;- c(9, 0, 0, 0, 4, 0, 0, 0, 1, 
  4, -3.2, -0.2, -3.2, 4, 0, -0.2, 0, 1)

Theta
</code></pre>

<hr>
<h2 id='fhistogram-methods'>
Fast Histogram Calculation
</h2><span id='topic+fhistogram'></span><span id='topic+fhistogram-methods'></span><span id='topic+fhistogram+2CHistogram-method'></span>

<h3>Description</h3>

<p>Returns an object of class <code>Histogram</code>. The method can be called recursively.
This way more than one dataset can be binned into one histogram. Set <code>shrink</code> 
to <code>TRUE</code> only when the method is called for the last time to optimize the size of the object.
The method is memory consuming.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'Histogram'
fhistogram(x = NULL, Dataset = data.frame(),
           K = numeric(), ymin = numeric(), ymax = numeric(), 
           shrink = FALSE, ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fhistogram-methods_+3A_x">x</code></td>
<td>

<p>an object of class <code>Histogram</code>.
</p>
</td></tr>
<tr><td><code id="fhistogram-methods_+3A_dataset">Dataset</code></td>
<td>

<p>a data frame of size <code class="reqn">n \times d</code> containing <em>d</em>-dimensional dataset. Each of the <code class="reqn">d</code> columns
represents one random variable. Number of observations <code class="reqn">n</code> equals the number of rows in the dataset.
</p>
</td></tr>
<tr><td><code id="fhistogram-methods_+3A_k">K</code></td>
<td>

<p>an integer or a vector of length <code class="reqn">d</code> containing numbers of bins <code class="reqn">v</code>.
</p>
</td></tr>
<tr><td><code id="fhistogram-methods_+3A_ymin">ymin</code></td>
<td>

<p>a vector of length <code class="reqn">d</code> containing minimum observations.
</p>
</td></tr>
<tr><td><code id="fhistogram-methods_+3A_ymax">ymax</code></td>
<td>

<p>a vector of length <code class="reqn">d</code> containing maximum observations.
</p>
</td></tr>
<tr><td><code id="fhistogram-methods_+3A_shrink">shrink</code></td>
<td>

<p>logical. If <code>TRUE</code> the output is shrank to its optimal size. The default value is <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="fhistogram-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "Histogram")</code></dt><dd><p>an object of class <code>Histogram</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Create three datasets.

set.seed(1)

n &lt;- 15

Dataset1 &lt;- as.data.frame(cbind(rnorm(n, 157, 8), rnorm(n, 71, 10)))
Dataset2 &lt;- as.data.frame(cbind(rnorm(n, 244, 14), rnorm(n, 61, 29)))
Dataset3 &lt;- as.data.frame(cbind(rnorm(n, 198, 8), rnorm(n, 252, 13)))

apply(Dataset1, 2, range)
apply(Dataset2, 2, range)
apply(Dataset3, 2, range)

# Bin the first dataset.

hist &lt;- fhistogram(Dataset = Dataset1, K = c(4, 5), ymin = c(100.0, 0.0), ymax = c(300.0, 300.0))

# Bin the second dataset.

hist &lt;- fhistogram(x = hist, Dataset = Dataset2)

# Bin the third dataset and shrink the hist object.

hist &lt;- fhistogram(x = hist, Dataset = Dataset3, shrink = TRUE)

hist
</code></pre>

<hr>
<h2 id='galaxy'>Galaxy Dataset</h2><span id='topic+galaxy'></span>

<h3>Description</h3>

<p>The unfilled survey of the Corona Borealis region contains the velocities of 82 galaxies from 6 well separated conic sections of space.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(galaxy)
</code></pre>


<h3>Format</h3>

<p><code>galaxy</code> is a data frame with 82 cases (rows) and 1 continuous variable (columns) called <code>Velocity</code>.
</p>


<h3>Source</h3>

<p>K. Roeder. Density estimation with confidence sets exemplified by superclusters and voids
in the galaxies. Journal of American Statistical Association, 85(411):617-624, 1990. https://www.jstor.org/stable/2289993.
</p>


<h3>References</h3>

<p>S. Richardson and P. J. Green. On bayesian analysis of mixtures with an unknown number
of components. Journal of the Royal Statistical Society B, 59(4):731-792, 1997. https://www.jstor.org/stable/2985194.<br /><br />
G. McLachlan and D. Peel. Contribution to the discussion of paper by s. richardson
and p.j. green. Journal of the Royal Statistical Society B, 59(4):779-780, 1997. https://www.jstor.org/stable/2985194.<br /><br />
M. Stephens. Bayesian analysis of mixture models with an unknown number of components -
an alternative to reversible jump methods. The Annals of Statistics, 28(1):40-74, 2000. https://www.jstor.org/stable/2673981.
</p>

<hr>
<h2 id='Histogram-class'>Class <code>"Histogram"</code></h2><span id='topic+Histogram-class'></span>

<h3>Description</h3>

<p>Object of class <code>Histogram</code>.</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>new("Histogram", ...)</code>. Accessor methods for the slots are <code>a.Y(x = NULL)</code>, 
<code>a.K(x = NULL)</code>, <code>a.ymin(x = NULL)</code>, <code>a.ymax(x = NULL)</code>, <code>a.y0(x = NULL)</code>, <code>a.h(x = NULL)</code>, <code>a.n(x = NULL)</code> and <code>a.ns(x = NULL)</code>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>Y</code>:</dt><dd>
<p>a data frame of size <code class="reqn">v \times (d + 1)</code> containing <em>d</em>-dimensional histogram.
Each of the first <code class="reqn">d</code> columns represents one random variable and contains bin means 
<code class="reqn">\bar{\bm{y}}_{1}, \ldots, \bar{\bm{y}}_{v}</code>. Column <code class="reqn">d + 1</code> contains frequencies <code class="reqn">k_{1}, \ldots, k_{v}</code>.
</p>
</dd>
<dt><code>K</code>:</dt><dd>
<p>an integer or a vector of length <code class="reqn">d</code> containing numbers of bins <code class="reqn">v</code>.
</p>
</dd>
<dt><code>ymin</code>:</dt><dd>
<p>a vector of length <code class="reqn">d</code> containing minimum observations.
</p>
</dd>
<dt><code>ymax</code>:</dt><dd>
<p>a vector of length <code class="reqn">d</code> containing maximum observations.
</p>
</dd>
<dt><code>y0</code>:</dt><dd>
<p>a vector of length <code class="reqn">d</code> containing origins.
</p>
</dd>
<dt><code>h</code>:</dt><dd>
<p>a vector of length <code class="reqn">d</code> containing bin widths.
</p>
</dd>
<dt><code>n</code>:</dt><dd>
<p>an integer containing total number <code class="reqn">n</code> of observations.
</p>
</dd>
<dt><code>ns</code>:</dt><dd>
<p>an integer containing number <code class="reqn">n_{\mathrm{s}}</code> of samples.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>Examples</h3>

<pre><code class='language-R'>Y &lt;- as.data.frame(matrix(1.0, nrow = 8, ncol = 3))

hist &lt;- new("Histogram", Y = Y, K = c(4, 2), ymin = c(2, 1), ymax = c(10, 8))

a.Y(hist)
a.K(hist)
a.ymin(hist)
a.ymax(hist)
a.y0(hist)
a.h(hist)
a.n(hist)
a.ns(hist)

# Multiplay Y[ , d + 1] by 0.1.

a.Y(hist) &lt;- 0.1
</code></pre>

<hr>
<h2 id='HQC-methods'>
Hannan-Quinn Information Criterion
</h2><span id='topic+HQC'></span><span id='topic+HQC-methods'></span><span id='topic+HQC+2CREBMIX-method'></span><span id='topic+HQC+2CREBMVNORM-method'></span>

<h3>Description</h3>

<p>Returns the Hannan-Quinn information criterion at <code>pos</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'REBMIX'
HQC(x = NULL, pos = 1, ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="HQC-methods_+3A_x">x</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="HQC-methods_+3A_pos">pos</code></td>
<td>

<p>a desired row number in <code>x@summary</code> for which the information criterion is calculated. The default value is <code>1</code>.
</p>
</td></tr>
<tr><td><code id="HQC-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "REBMIX")</code></dt><dd><p>an object of class <code>REBMIX</code>.</p>
</dd>
<dt><code>signature(x = "REBMVNORM")</code></dt><dd><p>an object of class <code>REBMVNORM</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>E. J. Hannan and B. G. Quinn. The determination of the order of an autoregression.
Journal of the Royal Statistical Society. Series B, 41(2):190-195, 1979. https://www.jstor.org/stable/2985032.
</p>

<hr>
<h2 id='ICL-methods'>
Integrated Classification Likelihood Criterion
</h2><span id='topic+ICL'></span><span id='topic+ICL-methods'></span><span id='topic+ICL+2CREBMIX-method'></span><span id='topic+ICL+2CREBMVNORM-method'></span>

<h3>Description</h3>

<p>Returns the integrated classification likelihood criterion at <code>pos</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'REBMIX'
ICL(x = NULL, pos = 1, ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ICL-methods_+3A_x">x</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="ICL-methods_+3A_pos">pos</code></td>
<td>

<p>a desired row number in <code>x@summary</code> for which the information criterion is calculated. The default value is <code>1</code>.
</p>
</td></tr>
<tr><td><code id="ICL-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "REBMIX")</code></dt><dd><p>an object of class <code>REBMIX</code>.</p>
</dd>
<dt><code>signature(x = "REBMVNORM")</code></dt><dd><p>an object of class <code>REBMVNORM</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>C. Biernacki, G. Celeux and G. Govaert. Assessing a mixture model for clustering with the integrated
classification likelihood. Technical Report 3521, INRIA, Rhone-Alpes, 1998.
</p>

<hr>
<h2 id='ICLBIC-methods'>
Approximate Integrated Classification Likelihood Criterion
</h2><span id='topic+ICLBIC'></span><span id='topic+ICLBIC-methods'></span><span id='topic+ICLBIC+2CREBMIX-method'></span><span id='topic+ICLBIC+2CREBMVNORM-method'></span>

<h3>Description</h3>

<p>Returns the approximate integrated classification likelihood criterion at <code>pos</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'REBMIX'
ICLBIC(x = NULL, pos = 1, ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ICLBIC-methods_+3A_x">x</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="ICLBIC-methods_+3A_pos">pos</code></td>
<td>

<p>a desired row number in <code>x@summary</code> for which the information criterion is calculated. The default value is <code>1</code>.
</p>
</td></tr>
<tr><td><code id="ICLBIC-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "REBMIX")</code></dt><dd><p>an object of class <code>REBMIX</code>.</p>
</dd>
<dt><code>signature(x = "REBMVNORM")</code></dt><dd><p>an object of class <code>REBMVNORM</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>C. Biernacki, G. Celeux and G. Govaert. Assessing a mixture model for clustering with the integrated
classification likelihood. Technical Report 3521, INRIA, Rhone-Alpes, 1998.
</p>

<hr>
<h2 id='iris'>Iris Data Set</h2><span id='topic+iris'></span>

<h3>Description</h3>

<p>This is perhaps the best known database to be found in the pattern recognition literature.
Fisher's paper is a classic in the field and is referenced frequently to this day. The data set contains 3 classes of 50 instances each,
where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(iris)
</code></pre>


<h3>Format</h3>

<p><code>iris</code> is a data frame with 150 cases (rows) and 5 variables (columns) named:
</p>

<ol>
<li>
<p><code>Sepal.Length</code> continuous.

</p>
</li>
<li>
<p><code>Sepal.Width</code> continuous.

</p>
</li>
<li>
<p><code>Petal.Length</code> continuous.

</p>
</li>
<li>
<p><code>Petal.Width</code> continuous.

</p>
</li>
<li>
<p><code>Class</code> discrete <code>iris-setosa</code>, <code>iris-versicolour</code> or <code>iris-virginica</code>.

</p>
</li></ol>



<h3>Source</h3>

<p>A. Asuncion and D. J. Newman. Uci machine learning repository, 2007. <a href="http://archive.ics.uci.edu/ml/">http://archive.ics.uci.edu/ml/</a>.
</p>


<h3>References</h3>

<p>R. A. Fisher. The use of multiple measurements in taxonomic problems. Annals of Eugenics,
7(2):179-188, 1936.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
devAskNewPage(ask = TRUE)

data(iris)

# Show level attributes.

levels(iris[["Class"]])

# Split dataset into train (75

set.seed(5)

Iris &lt;- split(p = 0.6, Dataset = iris, class = 5)

# Estimate number of components, component weights and component
# parameters for train subsets.

n &lt;- range(a.ntrain(Iris))

irisest &lt;- REBMIX(model = "REBMVNORM",
  Dataset = a.train(Iris),
  Preprocessing = "histogram",
  cmax = 10,
  Criterion = "ICL-BIC",
  EMcontrol = new("EM.Control", strategy = "single"))

plot(irisest, pos = 1, nrow = 3, ncol = 2, what = c("pdf"))
plot(irisest, pos = 2, nrow = 3, ncol = 2, what = c("pdf"))
plot(irisest, pos = 3, nrow = 3, ncol = 2, what = c("pdf"))

# Selected chunks.

iriscla &lt;- RCLSMIX(model = "RCLSMVNORM",
  x = list(irisest),
  Dataset = a.test(Iris),
  Zt = a.Zt(Iris))

iriscla

summary(iriscla)

# Plot selected chunks.

plot(iriscla, nrow = 3, ncol = 2)

## End(Not run)
</code></pre>

<hr>
<h2 id='kseq'>
Sequence of Bins or Nearest Neighbours Generation
</h2><span id='topic+kseq'></span>

<h3>Description</h3>

<p>Returns (invisibly) a vector containing numbers of bins <code class="reqn">v</code> for the histogram and the kernel density estimation or numbers of nearest
neighbours <code class="reqn">k</code> for the <em>k</em>-nearest neighbour.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kseq(from = NULL, to = NULL, f = 0.05, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kseq_+3A_from">from</code></td>
<td>

<p>starting value of the sequence. The default value is <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="kseq_+3A_to">to</code></td>
<td>

<p>end value of the sequence. The default value is <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="kseq_+3A_f">f</code></td>
<td>

<p>number specifying the fraction by which the bins or nearest neighbours should be separated <code class="reqn">0.0 &lt; f &lt; 1.0</code>. The default value is <code>0.05</code>.
</p>
</td></tr>
<tr><td><code id="kseq_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate numbers of bins.

n &lt;- 10000

Sturges &lt;- as.integer(1 + log2(n)) # Minimum v follows Sturges rule.
Log10 &lt;- as.integer(10 * log10(n)) # Maximum v follows Log10 rule.
RootN &lt;- as.integer(2 * n^0.5) # Maximum v follows RootN rule.

K &lt;- kseq(from = Sturges, to = Log10, f = 0.05)

K

K &lt;- kseq(from = Sturges, to = RootN, f = 0.03)

K
</code></pre>

<hr>
<h2 id='labelmoments-methods'>
Label Image Moments
</h2><span id='topic+labelmoments'></span><span id='topic+labelmoments-methods'></span><span id='topic+labelmoments+2Carray-method'></span>

<h3>Description</h3>

<p>Returns the list with the data frame <code>Mij</code> containing the cluster levels <code class="reqn">l</code>, the numbers of pixels <code class="reqn">n</code> and the cluster moments
<code class="reqn">\bm{M} = (M_{\mathrm{10}}, M_{\mathrm{01}}, M_{\mathrm{11}})^{\top}</code> for 2D images or the data frame <code>Mijk</code> containing the cluster levels <code class="reqn">l</code>, the numbers of voxels <code class="reqn">n</code> and the cluster moments <code class="reqn">\bm{M} = (M_{\mathrm{100}}, M_{\mathrm{010}}, M_{\mathrm{001}}, M_{\mathrm{111}})^{\top}</code> 
for 3D images and the adjacency matrix <code>A</code> of size <code class="reqn">c_{\mathrm{max}} \times c_{\mathrm{max}}</code>. It may have some <code>NA</code> rows and columns. To calculate the adjacency matrix <code class="reqn">A(i,j) = \exp{(-\|\bm{M}_{i} - \bm{M}_{j}\|^2 / 2 \sigma^2)}</code>, the raw cluster moments are first converted into z-scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'array'
labelmoments(Zp = array(), cmax = integer(), Sigma = 1.0, ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="labelmoments-methods_+3A_zp">Zp</code></td>
<td>

<p>a 2D array of size <code class="reqn">width \times height</code> or a 3D array of size <code class="reqn">width \times height \times depth</code> containing the predictive cluster membership <code class="reqn">\bm{\Omega}_{l}</code>, where <code class="reqn">l \in \{ 0, 1, \ldots, c\}</code>. The cluster <code class="reqn">l = 0</code> may contain the pixels for 2D images or the voxels for 3D images, which are ignored by this method.
</p>
</td></tr>
<tr><td><code id="labelmoments-methods_+3A_cmax">cmax</code></td>
<td>

<p>maximum number of clusters <code class="reqn">c_{\mathrm{max}} \geq c</code>.
</p>
</td></tr>
<tr><td><code id="labelmoments-methods_+3A_sigma">Sigma</code></td>
<td>

<p>scale parameter <code class="reqn">\sigma</code> for the Gaussian kernel function <code class="reqn">\exp{(-\|\bm{M}_{i} - \bm{M}_{j}\|^2 / 2 \sigma^2)}</code>. The default value is <code>1.0</code>.
</p>
</td></tr>
<tr><td><code id="labelmoments-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Methods</h3>


<dl>
<dt><code>signature(Zp = "array")</code></dt><dd><p>an array.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode, Branislav Panic</p>


<h3>References</h3>

<p>A. Ng, M. Jordan and Y. Weiss. On spectral clustering: Analysis and an algorithm. Advances in Neural Information Processing Systems 14 (NIPS 2001).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Zp &lt;- matrix(rep(0, 100), nrow = 10, ncol = 10)

Zp[2, 2:4] &lt;- 1; 
Zp[2:4, 5] &lt;- 2; 
Zp[8, 7:10] &lt;- 3; 
Zp[9, 6] &lt;- 4; Zp[10, 5] &lt;- 4
Zp[10, 1:4] &lt;- 5
Zp[6:9, 1] &lt;- 6

labelmoments &lt;- labelmoments(Zp, cmax = 6, Sigma = 1.0)

set.seed(12)

mergelabels &lt;- mergelabels(list(labelmoments$A), w = 1.0, k = 2, nstart = 3)

Zp

mergelabels
</code></pre>

<hr>
<h2 id='logL'>
Log Likelihood
</h2><span id='topic+logL'></span><span id='topic+logL-methods'></span><span id='topic+logL+2CREBMIX-method'></span><span id='topic+logL+2CREBMVNORM-method'></span>

<h3>Description</h3>

<p>Returns the log likelihood at <code>pos</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'REBMIX'
logL(x = NULL, pos = 1, ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logL_+3A_x">x</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="logL_+3A_pos">pos</code></td>
<td>

<p>a desired row number in <code>x@summary</code> for which the information criterion is calculated. The default value is <code>1</code>.
</p>
</td></tr>
<tr><td><code id="logL_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "REBMIX")</code></dt><dd><p>an object of class <code>REBMIX</code>.</p>
</dd>
<dt><code>signature(x = "REBMVNORM")</code></dt><dd><p>an object of class <code>REBMVNORM</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>G. McLachlan and D. Peel. Finite Mixture Models. John Wiley &amp; Sons, New York, 2000.
</p>

<hr>
<h2 id='mapclusters-methods'>
Map Clusters
</h2><span id='topic+mapclusters'></span><span id='topic+mapclusters-methods'></span><span id='topic+mapclusters+2CRCLRMIX-method'></span><span id='topic+mapclusters+2CRCLRMVNORM-method'></span>

<h3>Description</h3>

<p>Returns a factor of predictive cluster membership for dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'RCLRMIX'
mapclusters(x = NULL, Dataset = data.frame(),
            s = expression(c), ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mapclusters-methods_+3A_x">x</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="mapclusters-methods_+3A_dataset">Dataset</code></td>
<td>

<p>a data frame of size <code class="reqn">n \times d</code> containing <em>d</em>-dimensional dataset. Each of the <code class="reqn">d</code> columns
represents one random variable. Number of observations <code class="reqn">n</code> equal the number of rows in the dataset.
</p>
</td></tr>
<tr><td><code id="mapclusters-methods_+3A_s">s</code></td>
<td>

<p>a desired number of clusters to be created. The default value is <code>expression(c)</code>.
</p>
</td></tr>
<tr><td><code id="mapclusters-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "RCLRMIX")</code></dt><dd><p>an object of class <code>RCLRMIX</code>.</p>
</dd>
<dt><code>signature(x = "RCLRMVNORM")</code></dt><dd><p>an object of class <code>RCLRMVNORM</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode, Branislav Panic</p>


<h3>Examples</h3>

<pre><code class='language-R'>devAskNewPage(ask = TRUE)

# Generate normal dataset.

n &lt;- c(50, 20, 40)

Theta &lt;- new("RNGMVNORM.Theta", c = 3, d = 2)

a.theta1(Theta, 1) &lt;- c(3, 10)
a.theta1(Theta, 2) &lt;- c(8, 6)
a.theta1(Theta, 3) &lt;- c(12, 11)
a.theta2(Theta, 1) &lt;- c(3, 0.3, 0.3, 2)
a.theta2(Theta, 2) &lt;- c(5.7, -2.3, -2.3, 3.5)
a.theta2(Theta, 3) &lt;- c(2, 1, 1, 2)

normal &lt;- RNGMIX(model = "RNGMVNORM", Dataset.name = paste("normal_", 1:10, sep = ""),
  n = n, Theta = a.Theta(Theta))

# Convert all datasets to single histogram.

hist &lt;- NULL

n &lt;- length(normal@Dataset)

hist &lt;- fhistogram(Dataset = normal@Dataset[[1]], K = c(10, 10), 
  ymin = a.ymin(normal), ymax = a.ymax(normal))

for (i in 2:n) {
  hist &lt;- fhistogram(x = hist, Dataset = normal@Dataset[[i]], shrink = i == n)
}

# Estimate number of components, component weights and component parameters.

normalest &lt;- REBMIX(model = "REBMVNORM",
  Dataset = list(hist),
  Preprocessing = "histogram",
  cmax = 6,
  Criterion = "BIC")

summary(normalest)

# Plot finite mixture.

plot(normalest)

# Cluster dataset.

normalclu &lt;- RCLRMIX(model = "RCLRMVNORM", x = normalest)

# Plot clusters.

plot(normalclu)

summary(normalclu)

# Map clusters.

Zp &lt;- mapclusters(x = normalclu, Dataset = a.Dataset(normal, 4))

Zt &lt;- a.Zt(normal)

Zp

Zt
</code></pre>

<hr>
<h2 id='MDL-methods'>
Minimum Description Length
</h2><span id='topic+MDL2'></span><span id='topic+MDL5'></span><span id='topic+MDL2-methods'></span><span id='topic+MDL2+2CREBMIX-method'></span><span id='topic+MDL2+2CREBMVNORM-method'></span><span id='topic+MDL5-methods'></span><span id='topic+MDL5+2CREBMIX-method'></span><span id='topic+MDL5+2CREBMVNORM-method'></span>

<h3>Description</h3>

<p>Returns the minimum desription length at <code>pos</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'REBMIX'
MDL2(x = NULL, pos = 1, ...)
## S4 method for signature 'REBMIX'
MDL5(x = NULL, pos = 1, ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MDL-methods_+3A_x">x</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="MDL-methods_+3A_pos">pos</code></td>
<td>

<p>a desired row number in <code>x@summary</code> for which the information criterion is calculated. The default value is <code>1</code>.
</p>
</td></tr>
<tr><td><code id="MDL-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "REBMIX")</code></dt><dd><p>an object of class <code>REBMIX</code>.</p>
</dd>
<dt><code>signature(x = "REBMVNORM")</code></dt><dd><p>an object of class <code>REBMVNORM</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>M. H. Hansen and B. Yu. Model selection and the principle of minimum description
length. Journal of the American Statistical Association, 96(454):746-774, 2001. https://www.jstor.org/stable/2670311.
</p>

<hr>
<h2 id='mergelabels-methods'>
Merge Labels Based on Probability Adjacency Matrix
</h2><span id='topic+mergelabels'></span><span id='topic+mergelabels-methods'></span><span id='topic+mergelabels+2Clist-method'></span>

<h3>Description</h3>

<p>Returns the list with the normalised adjacency matrix <code>L</code> of size <code class="reqn">c \times c</code>. The normalised adjacency matrix
<code class="reqn">L = D^{-1/2} P D^{-1/2}</code> depends on the probability adjacency matrix <code class="reqn">P(i,j) = \sum_{l = 1}^{n} p_{l} A_{l}(i,j)</code>, where <code class="reqn">p_{l} = w_{l} / \sum_{i = 1}^{c}\sum_{j = i + 1}^{c} A_{l}(i,j)</code>
and the degree matrix <code class="reqn">D(i,i) = \sum_{j = 1}^{c} P(i,j)</code>. The <code class="reqn">A_{l}</code> matrices may contain some <code>NA</code> rows and columns, which are eliminated by the method. 
The list also contains the vector of integers <code>cluster</code> of length <code class="reqn">k</code>, which indicates the cluster to which each label is assigned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'list'
mergelabels(A = list(), w = numeric(), k = 2, ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mergelabels-methods_+3A_a">A</code></td>
<td>

<p>a list of length <code class="reqn">n</code> of adjacency matrices <code class="reqn">A_{l}</code> of size <code class="reqn">c_{\mathrm{max}} \times c_{\mathrm{max}}</code>, where <code class="reqn">c_{\mathrm{max}} \geq c</code>.
</p>
</td></tr>
<tr><td><code id="mergelabels-methods_+3A_w">w</code></td>
<td>

<p>vector of length <code class="reqn">n</code> containing weights <code class="reqn">w_{l}</code> summing to 1.
</p>
</td></tr>
<tr><td><code id="mergelabels-methods_+3A_k">k</code></td>
<td>

<p>number of clusters <code class="reqn">k</code> for <code><a href="stats.html#topic+kmeans">kmeans</a></code>. The default value is 2.
</p>
</td></tr>
<tr><td><code id="mergelabels-methods_+3A_...">...</code></td>
<td>

<p>further arguments to <code><a href="stats.html#topic+kmeans">kmeans</a></code>.
</p>
</td></tr>
</table>


<h3>Methods</h3>


<dl>
<dt><code>signature(A = "list")</code></dt><dd><p>a list.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode, Branislav Panic</p>


<h3>References</h3>

<p>A. Ng, M. Jordan and Y. Weiss. On spectral clustering: Analysis and an algorithm. Advances in Neural Information Processing Systems 14 (NIPS 2001).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Zp &lt;- array(0, dim = c(10, 10, 2))

Zp[ , ,1][10, 1:4] &lt;- 1
Zp[ , ,1][1:4, 10] &lt;- 2

Zp[ , ,2][9, 1:5] &lt;- 3
Zp[ , ,2][1:6, 9] &lt;- 4

labelmoments &lt;- labelmoments(Zp, cmax = 4, Sigma = 1.0)

labelmoments

set.seed(3)

mergelabels &lt;- mergelabels(list(labelmoments$A), w = 1.0, k = 2, nstart = 5)

Zp

mergelabels
</code></pre>

<hr>
<h2 id='optbins-methods'>
Optimal Numbers of Bins Calculation
</h2><span id='topic+optbins'></span><span id='topic+optbins-methods'></span><span id='topic+optbins+2Clist-method'></span>

<h3>Description</h3>

<p>Returns the matrix of size <code class="reqn">n_{\mathrm{D}} \times d</code> containing optimal numbers of bins <code class="reqn">v_{1}, \ldots, v_{d}</code> for all processed datasets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'list'
optbins(Dataset = list(), Rule = "Knuth equal",
        ymin = numeric(), ymax = numeric(), kmin = numeric(),
        kmax = numeric(), ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="optbins-methods_+3A_dataset">Dataset</code></td>
<td>

<p>a list of length <code class="reqn">n_{\mathrm{D}}</code> of data frames of size <code class="reqn">n \times d</code> containing <em>d</em>-dimensional datasets. Each of the <code class="reqn">d</code> columns
represents one random variable. Numbers of observations <code class="reqn">n</code> equal the number of rows in the datasets.
</p>
</td></tr>
<tr><td><code id="optbins-methods_+3A_rule">Rule</code></td>
<td>

<p>a character giving the histogram binning rule. One of <code>"Sturges"</code>, <code>"Log10"</code>, <code>"RootN"</code>, default <code>"Knuth equal"</code> or <code>"Knuth unequal"</code>.
</p>
</td></tr>
<tr><td><code id="optbins-methods_+3A_ymin">ymin</code></td>
<td>

<p>a vector of length <code class="reqn">d</code> containing minimum observations. The default value is <code>numeric()</code>.
</p>
</td></tr>
<tr><td><code id="optbins-methods_+3A_ymax">ymax</code></td>
<td>

<p>a vector of length <code class="reqn">d</code> containing maximum observations. The default value is <code>numeric()</code>.
</p>
</td></tr>
<tr><td><code id="optbins-methods_+3A_kmin">kmin</code></td>
<td>

<p>lower limit of the number of bins. The default value is <code>numeric()</code>.
</p>
</td></tr>
<tr><td><code id="optbins-methods_+3A_kmax">kmax</code></td>
<td>

<p>upper limit of the number of bins. The default value is <code>numeric()</code>.
</p>
</td></tr>
<tr><td><code id="optbins-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "list")</code></dt><dd><p>a list of data frames.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Branislav Panic, Marko Nagode</p>


<h3>References</h3>

<p>K. K. Knuth. Optimal data-based binning for histograms and histogram-based probability density models. 
Digital Signal Processing, 95:102581, 2019.
<a href="https://doi.org/10.1016/j.dsp.2019.102581">doi:10.1016/j.dsp.2019.102581</a>.<br /><br />
B. Panic, J. Klemenc, M. Nagode. Improved initialization of the EM algorithm for mixture model parameter estimation.
Mathematics, 8(3):373, 2020.
<a href="https://doi.org/10.3390/math8030373">doi:10.3390/math8030373</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate multivariate normal datasets.

n &lt;- c(750, 1000)

Theta &lt;- new("RNGMVNORM.Theta", c = 2, d = 2)

a.theta1(Theta, 1) &lt;- c(8, 6)
a.theta1(Theta, 2) &lt;- c(6, 8)
a.theta2(Theta, 1) &lt;- c(8, 2, 2, 4)
a.theta2(Theta, 2) &lt;- c(2, 1, 1, 4)

sim2d &lt;- RNGMIX(model = "RNGMVNORM", 
  Dataset.name = paste("sim2d_", 1:5, sep = ""),
  rseed = -1,
  n = n,
  Theta = a.Theta(Theta))

# Calculate optimal numbers of bins.

opt.k &lt;- optbins(Dataset = sim2d@Dataset,
  Rule = "Knuth equal",
  ymin = sim2d@ymin,
  ymax = sim2d@ymax,
  kmin = 2, 
  kmax = 20)

opt.k

# Create object of class EM.Control.

EM &lt;- new("EM.Control", strategy = "exhaustive", variant = "EM",
  acceleration = "fixed", acceleration.multiplier = 1.0, tolerance = 1.0E-4,
  maximum.iterations = 1000)

# Estimate number of components, component weights and component parameters.

sim2dest &lt;- REBMIX(model = "REBMVNORM", 
  Dataset = a.Dataset(sim2d),
  Preprocessing = "h",
  cmax = 10,
  ymin = a.ymin(sim2d),
  ymax = a.ymax(sim2d),
  K = opt.k,
  Criterion = "BIC",
  EMcontrol = EM)

# Plot finite mixture.

plot(sim2dest, pos = 3, nrow = 4, what = c("pdf", "marginal pdf", "IC"))

# Estimate number of components, component weights and component 
# parameters for well known Iris dataset.

Dataset &lt;- list(iris[, c(1:4)])

# Calculate optimal numbers of bins using non-equal number of bins in each dimension.

opt.k &lt;- optbins(Dataset = Dataset,
  Rule = "Knuth unequal",
  kmin = 2, 
  kmax = 20)

opt.k

# Estimate number of components, component weights and component parameters.

irisest &lt;- REBMIX(model = "REBMVNORM", 
  Dataset = Dataset,
  Preprocessing = "h",
  cmax = 10,
  K = opt.k,
  Criterion = "BIC",
  EMcontrol = EM)
  
irisest
</code></pre>

<hr>
<h2 id='PC-methods'>
Partition Coefficient
</h2><span id='topic+PC'></span><span id='topic+PC-methods'></span><span id='topic+PC+2CREBMIX-method'></span><span id='topic+PC+2CREBMVNORM-method'></span>

<h3>Description</h3>

<p>Returns the partition coefficient of Bezdek at <code>pos</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'REBMIX'
PC(x = NULL, pos = 1, ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PC-methods_+3A_x">x</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="PC-methods_+3A_pos">pos</code></td>
<td>

<p>a desired row number in <code>x@summary</code> for which the information criterion is calculated. The default value is <code>1</code>.
</p>
</td></tr>
<tr><td><code id="PC-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "REBMIX")</code></dt><dd><p>an object of class <code>REBMIX</code>.</p>
</dd>
<dt><code>signature(x = "REBMVNORM")</code></dt><dd><p>an object of class <code>REBMVNORM</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>G. McLachlan and D. Peel. Finite Mixture Models. John Wiley &amp; Sons, New York, 2000.
</p>

<hr>
<h2 id='pemix-methods'>
Empirical Distribution Function Calculation
</h2><span id='topic+pemix'></span><span id='topic+pemix-methods'></span><span id='topic+pemix+2CREBMIX-method'></span><span id='topic+pemix+2CREBMVNORM-method'></span>

<h3>Description</h3>

<p>Returns the data frame containing observations <code class="reqn">\bm{x}_{1}, \ldots, \bm{x}_{n}</code> and empirical
distribution functions <code class="reqn">F_{1}, \ldots, F_{n}</code>. Vectors <code class="reqn">\bm{x}</code> are subvectors of
<code class="reqn">\bm{y} = (y_{1}, \ldots, y_{d})^{\top}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'REBMIX'
pemix(x = NULL, pos = 1, variables = expression(1:d),
      lower.tail = TRUE, log.p = FALSE, ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pemix-methods_+3A_x">x</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="pemix-methods_+3A_pos">pos</code></td>
<td>

<p>a desired row number in <code>x@summary</code> for which the empirical distribution functions are calculated. The default value is <code>1</code>.
</p>
</td></tr>
<tr><td><code id="pemix-methods_+3A_variables">variables</code></td>
<td>

<p>a vector containing indices of variables in subvectors <code class="reqn">\bm{x}</code>. The default value is <code>1:d</code>.
</p>
</td></tr>
<tr><td><code id="pemix-methods_+3A_lower.tail">lower.tail</code></td>
<td>

<p>logical. If <code>TRUE</code>, probabilities are <code class="reqn">P[X \leq x]</code>, otherwise, <code class="reqn">P[X &gt; x]</code>. The default value is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="pemix-methods_+3A_log.p">log.p</code></td>
<td>

<p>logical. if <code>TRUE</code>, probabilities <code class="reqn">p</code> are given as <code class="reqn">\log(p)</code>. The default value is <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="pemix-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "REBMIX")</code></dt><dd><p>an object of class <code>REBMIX</code>.</p>
</dd>
<dt><code>signature(x = "REBMVNORM")</code></dt><dd><p>an object of class <code>REBMVNORM</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>M. Nagode and M. Fajdiga. The rebmix algorithm for the univariate finite mixture estimation.
Communications in Statistics - Theory and Methods, 40(5):876-892, 2011a. <a href="https://doi.org/10.1080/03610920903480890">doi:10.1080/03610920903480890</a>.<br /><br />
M. Nagode and M. Fajdiga. The rebmix algorithm for the multivariate finite mixture estimation.
Communications in Statistics - Theory and Methods, 40(11):2022-2034, 2011b. <a href="https://doi.org/10.1080/03610921003725788">doi:10.1080/03610921003725788</a>.<br /><br />
M. Nagode. Finite mixture modeling via REBMIX.
Journal of Algorithms and Optimization, 3(2):14-28, 2015. <a href="https://repozitorij.uni-lj.si/Dokument.php?id=127674&amp;lang=eng">https://repozitorij.uni-lj.si/Dokument.php?id=127674&amp;lang=eng</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate simulated dataset.

n &lt;- c(15, 15)

Theta &lt;- new("RNGMIX.Theta", c = 2, pdf = rep("normal", 3))

a.theta1(Theta, 1) &lt;- c(10, 20, 30)
a.theta1(Theta, 2) &lt;- c(3, 4, 5)
a.theta2(Theta, 1) &lt;- c(3, 2, 1)
a.theta2(Theta, 2) &lt;- c(15, 10, 5)

simulated &lt;- RNGMIX(Dataset.name = paste("simulated_", 1:4, sep = ""),
  rseed = -1,
  n = n,
  Theta = a.Theta(Theta))

# Create object of class EM.Control.

EM &lt;- new("EM.Control", strategy = "exhaustive", variant = "ECM",
  acceleration = "fixed", acceleration.multiplier = 1.0, tolerance = 1.0E-4,
  maximum.iterations = 1000)

# Estimate number of components, component weights and component parameters.

simulatedest &lt;- REBMIX(Dataset = a.Dataset(simulated),
  Preprocessing = "kernel density estimation",
  cmax = 4,
  pdf = c("n", "n", "n"),
  EMcontrol = EM)

# Preprocess simulated dataset.

f &lt;- pemix(simulatedest, pos = 3, variables = c(1))

f
</code></pre>

<hr>
<h2 id='pfmix-methods'>
Predictive Marginal Distribution Function Calculation
</h2><span id='topic+pfmix'></span><span id='topic+pfmix-methods'></span><span id='topic+pfmix+2CREBMIX-method'></span><span id='topic+pfmix+2CREBMVNORM-method'></span>

<h3>Description</h3>

<p>Returns the data frame containing observations <code class="reqn">\bm{x}_{1}, \ldots, \bm{x}_{n}</code> and
predictive marginal distribution functions <code class="reqn">F(\bm{x} | c, \bm{w}, \bm{\Theta})</code>. Vectors <code class="reqn">\bm{x}</code> are subvectors of
<code class="reqn">\bm{y} = (y_{1}, \ldots, y_{d})^{\top}</code>. If <code class="reqn">\bm{x} = \bm{y}</code> the method returns the data frame containing observations <code class="reqn">\bm{y}_{1}, \ldots, \bm{y}_{n}</code> and
the corresponding predictive mixture distribution function <code class="reqn">F(\bm{y} | c, \bm{w}, \bm{\Theta})</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'REBMIX'
pfmix(x = NULL, Dataset = data.frame(), pos = 1,
      variables = expression(1:d), lower.tail = TRUE, log.p = FALSE, ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pfmix-methods_+3A_x">x</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="pfmix-methods_+3A_dataset">Dataset</code></td>
<td>

<p>a data frame containing observations <code class="reqn">\bm{y} = (y_{1}, \ldots, y_{d})^{\top}</code> for which the predictive marginal distribution functions are calculated. The default value is <code>data.frame()</code>.
</p>
</td></tr>
<tr><td><code id="pfmix-methods_+3A_pos">pos</code></td>
<td>

<p>a desired row number in <code>x@summary</code> for which the predictive marginal distribution functions are calculated. The default value is <code>1</code>.
</p>
</td></tr>
<tr><td><code id="pfmix-methods_+3A_variables">variables</code></td>
<td>

<p>a vector containing indices of variables in subvectors <code class="reqn">\bm{x}</code>. The default value is <code>1:d</code>.
</p>
</td></tr>
<tr><td><code id="pfmix-methods_+3A_lower.tail">lower.tail</code></td>
<td>

<p>logical. If <code>TRUE</code>, probabilities are <code class="reqn">P[X \leq x]</code>, otherwise, <code class="reqn">P[X &gt; x]</code>. The default value is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="pfmix-methods_+3A_log.p">log.p</code></td>
<td>

<p>logical. if <code>TRUE</code>, probabilities <code class="reqn">p</code> are given as <code class="reqn">\log(p)</code>. The default value is <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="pfmix-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "REBMIX")</code></dt><dd><p>an object of class <code>REBMIX</code>.</p>
</dd>
<dt><code>signature(x = "REBMVNORM")</code></dt><dd><p>an object of class <code>REBMVNORM</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>M. Nagode and M. Fajdiga. The rebmix algorithm for the univariate finite mixture estimation.
Communications in Statistics - Theory and Methods, 40(5):876-892, 2011a. <a href="https://doi.org/10.1080/03610920903480890">doi:10.1080/03610920903480890</a>.<br /><br />
M. Nagode and M. Fajdiga. The rebmix algorithm for the multivariate finite mixture estimation.
Communications in Statistics - Theory and Methods, 40(11):2022-2034, 2011b. <a href="https://doi.org/10.1080/03610921003725788">doi:10.1080/03610921003725788</a>.<br /><br />
M. Nagode. Finite mixture modeling via REBMIX.
Journal of Algorithms and Optimization, 3(2):14-28, 2015. <a href="https://repozitorij.uni-lj.si/Dokument.php?id=127674&amp;lang=eng">https://repozitorij.uni-lj.si/Dokument.php?id=127674&amp;lang=eng</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate simulated dataset.

n &lt;- c(15, 15)

Theta &lt;- new("RNGMIX.Theta", c = 2, pdf = rep("normal", 3))

a.theta1(Theta, 1) &lt;- c(10, 20, 30)
a.theta1(Theta, 2) &lt;- c(3, 4, 5)
a.theta2(Theta, 1) &lt;- c(3, 2, 1)
a.theta2(Theta, 2) &lt;- c(15, 10, 5)

simulated &lt;- RNGMIX(Dataset.name = paste("simulated_", 1:4, sep = ""),
  rseed = -1,
  n = n,
  Theta = a.Theta(Theta))

# Number of classes or nearest neighbours to be processed.

K &lt;- c(as.integer(1 + log2(sum(n))), # Minimum v follows Sturges rule.
  as.integer(10 * log10(sum(n)))) # Maximum v follows log10 rule.

# Estimate number of components, component weights and component parameters.

simulatedest &lt;- REBMIX(Dataset = a.Dataset(simulated),
  Preprocessing = "h",
  cmax = 4,
  Criterion = "BIC",
  pdf = c("n", "n", "n"))

# Preprocess simulated dataset.

Dataset &lt;- data.frame(c(25, 5, -20), NA, c(31, 20, 20))

f &lt;- pfmix(simulatedest, Dataset = Dataset, pos = 3, variables = c(1, 3))

f

# Plot finite mixture.

opar &lt;- plot(simulatedest, pos = 3, nrow = 3, ncol = 1,
  what = "pdf", contour.drawlabels = TRUE, contour.labcex = 0.6)

par(usr = opar[[2]]$usr, mfg = c(2, 1))

points(x = f[, 1], y = f[, 2])

text(x = f[, 1], y = f[, 2], labels = format(f[, 3], digits = 3), cex = 0.8, pos = 4)
</code></pre>

<hr>
<h2 id='plot-methods'>
Plots RNGMIX, REBMIX, RCLRMIX and RCLSMIX Output
</h2><span id='topic+plot-methods'></span><span id='topic+plot+2CREBMIX+2Cmissing-method'></span><span id='topic+plot+2CREBMVNORM+2Cmissing-method'></span><span id='topic+plot+2CRNGMIX+2Cmissing-method'></span><span id='topic+plot+2CRNGMVNORM+2Cmissing-method'></span><span id='topic+plot+2CRCLRMIX+2Cmissing-method'></span><span id='topic+plot+2CRCLRMVNORM+2Cmissing-method'></span><span id='topic+plot+2CRCLSMIX+2Cmissing-method'></span><span id='topic+plot+2CRCLSMVNORM+2Cmissing-method'></span>

<h3>Description</h3>

<p>Plots true clusters if <code>x</code> equals <code>"RNGMIX"</code>. Plots the REBMIX output
depending on <code>what</code> argument if <code>x</code> equals <code>"REBMIX"</code>.
Plots predictive clusters if <code>x</code> equals <code>"RCLRMIX"</code>.
Wrongly clustered observations are plotted only if <code>x@Zt</code> is available.
Plots predictive classes and wrongly classified observations if <code>x</code> equals <code>"RCLSMIX"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'RNGMIX,missing'
plot(x, y, pos = 1, nrow = 1, ncol = 1, cex = 0.8,
     fg = "black", lty = "solid", lwd = 1, pty = "m", tcl = 0.5,
     plot.cex = 0.8, plot.pch = 19, ...)
## S4 method for signature 'REBMIX,missing'
plot(x, y, pos = 1, what = c("pdf"),
     nrow = 1, ncol = 1, npts = 200, n = 200, cex = 0.8, fg = "black",
     lty = "solid", lwd = 1, pty = "m", tcl = 0.5,
     plot.cex = 0.8, plot.pch = 19, contour.drawlabels = FALSE,
     contour.labcex = 0.8, contour.method = "flattest",
     contour.nlevels = 12, log = "", ...)
## S4 method for signature 'RCLRMIX,missing'
plot(x, y, s = expression(c), nrow = 1, ncol = 1, cex = 0.8,
     fg = "black", lty = "solid", lwd = 1, pty = "m", tcl = 0.5,
     plot.cex = 0.8, plot.pch = 19, ...)
## S4 method for signature 'RCLSMIX,missing'
plot(x, y, nrow = 1, ncol = 1, cex = 0.8,
     fg = "black", lty = "solid", lwd = 1, pty = "m", tcl = 0.5,
     plot.cex = 0.8, plot.pch = 19, ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot-methods_+3A_x">x</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_y">y</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_pos">pos</code></td>
<td>

<p>a desired row number in <code>x@summary</code> to be plotted. The default value is <code>1</code>.
</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_s">s</code></td>
<td>

<p>a desired number of clusters to be plotted. The default value is <code>expression(c)</code>.
</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_what">what</code></td>
<td>

<p>a character vector giving the plot types. One of <code>"pdf"</code> for probability density function, <code>"marginal pdf"</code> 
for marginal probability density function, <code>"IC"</code> for information criterion depending on numbers of components 
<code class="reqn">c</code>, <code>"logL"</code> for log likelihood, <code>"D"</code> for total of positive relative deviations, <code>"K"</code> for information criterion depending 
on bins <code class="reqn">v</code> or numbers of nearest neighbours <code class="reqn">k</code>, <code>"cdf"</code> for univariate distribution function or
<code>"marginal cdf"</code> for marginal distribution function. The default value is <code>"pdf"</code>.
</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_nrow">nrow</code></td>
<td>

<p>a desired number of rows in which the empirical and predictive densities are to be plotted. The default value is <code>1</code>.
</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_ncol">ncol</code></td>
<td>

<p>a desired number of columns in which the empirical and predictive densities are to be plotted. The default value is <code>1</code>.
</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_npts">npts</code></td>
<td>

<p>a number of points at which the predictive densities are to be plotted. The default value is <code>200</code>.
</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_n">n</code></td>
<td>

<p>a number of observations to be plotted. The default value is <code>200</code>.
</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_cex">cex</code></td>
<td>

<p>a numerical value giving the amount by which the plotting text and symbols should be magnified
relative to the default, see also <code><a href="graphics.html#topic+par">par</a></code>. The default value is <code>0.8</code>.
</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_fg">fg</code></td>
<td>

<p>a colour used for things like axes and boxes around plots, see also <code><a href="graphics.html#topic+par">par</a></code>.
The default value is <code>"black"</code>.
</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_lty">lty</code></td>
<td>

<p>a line type, see also <code><a href="graphics.html#topic+par">par</a></code>. The default value is <code>"solid"</code>.
</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_lwd">lwd</code></td>
<td>

<p>a line width, see also <code><a href="graphics.html#topic+par">par</a></code>. The default value is <code>1</code>.
</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_pty">pty</code></td>
<td>

<p>a character specifying the type of the plot region to be used. One of <code>"s"</code> generating a square plotting
region or <code>"m"</code> generating the maximal plotting region. The default value is <code>"m"</code>.
</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_tcl">tcl</code></td>
<td>

<p>a length of tick marks as a fraction of the height of a line of the text, see also <code><a href="graphics.html#topic+par">par</a></code>.
The default value is <code>0.5</code>.
</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_plot.cex">plot.cex</code></td>
<td>

<p>a numerical vector giving the amount by which plotting characters and symbols should be
scaled relative to the default. It works as a multiple of <code><a href="graphics.html#topic+par">par</a>("cex")</code>. <code>NULL</code> and <code>NA</code> are
equivalent to <code>1.0</code>. Note that this does not affect annotation, see also <code><a href="graphics.html#topic+plot.default">plot.default</a></code>.
The default value is <code>0.8</code>.
</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_plot.pch">plot.pch</code></td>
<td>

<p>a vector of plotting characters or symbols, see also <code><a href="graphics.html#topic+points">points</a></code>. The default value is <code>19</code>.
</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_contour.drawlabels">contour.drawlabels</code></td>
<td>

<p>logical. The contours are labelled if <code>TRUE</code>. The default value is <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_contour.labcex">contour.labcex</code></td>
<td>

<p><code>cex</code> for contour labelling. The default value is <code>0.8</code>. This is an absolute size, not a multiple of
<code><a href="graphics.html#topic+par">par</a>("cex")</code>.
</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_contour.method">contour.method</code></td>
<td>

<p>a character specifying where the labels will be located. The possible values
are <code>"simple"</code>, <code>"edge"</code> and default <code>"flattest"</code>, see also <code><a href="graphics.html#topic+contour">contour</a></code>.
</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_contour.nlevels">contour.nlevels</code></td>
<td>

<p>a number of desired contour levels. The default value is <code>12</code>.
</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_log">log</code></td>
<td>

<p>a character which contains <code>"x"</code> if the x axis is to be logarithmic, <code>"y"</code> if the
y axis is to be logarithmic and <code>"xy"</code> or <code>"yx"</code> if both axes are to be logarithmic. The default value is <code>""</code>.
</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_...">...</code></td>
<td>

<p>further arguments to <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns (invisibly) a list containing graphical parameters <code>par</code>. Such a list can be passed as an argument to <code><a href="graphics.html#topic+par">par</a></code> to restore the parameter values.
</p>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "RNGMIX", y = "missing")</code></dt><dd><p>an object of class <code>RNGMIX</code>.</p>
</dd>
<dt><code>signature(x = "RNGMVNORM", y = "missing")</code></dt><dd><p>an object of class <code>RNGMVNORM</code>.</p>
</dd>
<dt><code>signature(x = "REBMIX", y = "missing")</code></dt><dd><p>an object of class <code>REBMIX</code>.</p>
</dd>
<dt><code>signature(x = "REBMVNORM", y = "missing")</code></dt><dd><p>an object of class <code>REBMVNORM</code>.</p>
</dd>
<dt><code>signature(x = "RCLRMIX", y = "missing")</code></dt><dd><p>an object of class <code>RCLRMIX</code>.</p>
</dd>
<dt><code>signature(x = "RCLRMVNORM", y = "missing")</code></dt><dd><p>an object of class <code>RCLRMVNORM</code>.</p>
</dd>
<dt><code>signature(x = "RCLSMIX", y = "missing")</code></dt><dd><p>an object of class <code>RCLSMIX</code>.</p>
</dd>
<dt><code>signature(x = "RCLSMVNORM", y = "missing")</code></dt><dd><p>an object of class <code>RCLSMVNORM</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>C. M. Bishop. Neural Networks for Pattern Recognition. Clarendon Press, Oxford, 1995.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
devAskNewPage(ask = TRUE)

data(wine)

colnames(wine)

# Remove Cultivar column from wine dataset.

winecolnames &lt;- !(colnames(wine) 

wine &lt;- wine[, winecolnames]

# Determine number of dimensions d and wine dataset size n.

d &lt;- ncol(wine)
n &lt;- nrow(wine)

wineest &lt;- REBMIX(model = "REBMVNORM",
  Dataset = list(wine = wine),
  Preprocessing = "kernel density estimation",
  Criterion = "ICL-BIC",
  EMcontrol = new("EM.Control", strategy = "best"))

# Plot finite mixture.

plot(wineest, what = c("pdf", "IC", "logL", "D"),
  nrow = 2, ncol = 2, pty = "s")

## End(Not run)
</code></pre>

<hr>
<h2 id='PRD-methods'>
Total of Positive Relative Deviations
</h2><span id='topic+PRD'></span><span id='topic+PRD-methods'></span><span id='topic+PRD+2CREBMIX-method'></span><span id='topic+PRD+2CREBMVNORM-method'></span>

<h3>Description</h3>

<p>Returns the total of positive relative deviations <code>D</code> at <code>pos</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'REBMIX'
PRD(x = NULL, pos = 1, ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PRD-methods_+3A_x">x</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="PRD-methods_+3A_pos">pos</code></td>
<td>

<p>a desired row number in <code>x@summary</code> for which the information criterion is calculated. The default value is <code>1</code>.
</p>
</td></tr>
<tr><td><code id="PRD-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "REBMIX")</code></dt><dd><p>an object of class <code>REBMIX</code>.</p>
</dd>
<dt><code>signature(x = "REBMVNORM")</code></dt><dd><p>an object of class <code>REBMVNORM</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>M. Nagode and M. Fajdiga. The rebmix algorithm for the univariate finite mixture estimation.
Communications in Statistics - Theory and Methods, 40(5):876-892, 2011a. <a href="https://doi.org/10.1080/03610920903480890">doi:10.1080/03610920903480890</a>.<br /><br />
M. Nagode and M. Fajdiga. The rebmix algorithm for the multivariate finite mixture estimation.
Communications in Statistics - Theory and Methods, 40(11):2022-2034, 2011b. <a href="https://doi.org/10.1080/03610921003725788">doi:10.1080/03610921003725788</a>.<br /><br />
M. Nagode. Finite mixture modeling via REBMIX.
Journal of Algorithms and Optimization, 3(2):14-28, 2015. <a href="https://repozitorij.uni-lj.si/Dokument.php?id=127674&amp;lang=eng">https://repozitorij.uni-lj.si/Dokument.php?id=127674&amp;lang=eng</a>.
</p>

<hr>
<h2 id='RCLRMIX-class'>Class <code>"RCLRMIX"</code></h2><span id='topic+RCLRMIX-class'></span><span id='topic+RCLRMVNORM-class'></span>

<h3>Description</h3>

<p>Object of class <code>RCLRMIX</code>.</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>new("RCLRMIX", ...)</code>.
Accessor methods for the slots are <code>a.Dataset(x = NULL)</code>, <code>a.pos(x = NULL)</code>, <code>a.Zt(x = NULL)</code>, 
<code>a.Zp(x = NULL, s = expression(c))</code>, <code>a.c(x = NULL)</code>,
<code>a.p(x = NULL, s = expression(c))</code>, <code>a.pi(x = NULL, s = expression(c))</code>, <br />
<code>a.P(x = NULL, s = expression(c))</code>, <code>a.tau(x = NULL, s = expression(c))</code>,
<code>a.prob(x = NULL)</code>, <code>a.Rule(x = NULL)</code>, <code>a.from(x = NULL)</code>, <code>a.to(x = NULL)</code>, 
<code>a.EN(x = NULL)</code> and <code>a.ED(x = NULL)</code>, where <code>x</code> stands for an object of class <code>RCLRMIX</code> and <code>s</code>
a desired number of clusters for which the slot is calculated.
</p>


<h3>Slots</h3>


<dl>
<dt><code>x</code>:</dt><dd>
<p>an object of class <code>REBMIX</code>.
</p>
</dd>
<dt><code>Dataset</code>:</dt><dd>
<p>a data frame or an object of class <code>Histogram</code> to be clustered.
</p>
</dd>
<dt><code>pos</code>:</dt><dd>
<p>a desired row number in <code>x@summary</code> for which the clustering is performed. The default value is <code>1</code>.
</p>
</dd>
<dt><code>Zt</code>:</dt><dd>
<p>a factor of true cluster membership.
</p>
</dd>
<dt><code>Zp</code>:</dt><dd>
<p>a factor of predictive cluster membership.
</p>
</dd>
<dt><code>c</code>:</dt><dd>
<p>number of nonempty clusters.
</p>
</dd>
<dt><code>p</code>:</dt><dd>
<p>a vector of length <code class="reqn">c</code> containing prior probabilities of cluster memberships <code class="reqn">p_{l}</code> summing to 1. The value is returned only if all variables in slot <code>x</code> follow either binomial or Dirac parametric families. The default value is <code>numeric()</code>.
</p>
</dd>
<dt><code>pi</code>:</dt><dd>
<p>a list of length <code class="reqn">d</code> of matrices of size <code class="reqn">c \times K_{i}</code> containing cluster conditional probabilities <code class="reqn">\pi_{ilk}</code>. Let <code class="reqn">\pi_{ilk}</code>
denote the cluster conditional probability that an observation in cluster <code class="reqn">l = 1, \ldots, c</code> produces the <code class="reqn">k</code>th outcome on the <code class="reqn">i</code>th variable.
Suppose we observe <code class="reqn">i = 1, \ldots, d</code> polytomous categorical variables (the manifest variables), each of which contains <code class="reqn">K_{i}</code> possible outcomes for observations <code class="reqn">j = 1, \ldots, n</code>.
A manifest variable is a variable that can be measured or observed directly. It must be coded as whole number starting at zero for the first outcome and increasing to the possible number of outcomes minus one.
It is presumed here that all variables are statistically independentand within clusters and that <code class="reqn">\bm{y}_{1}, \ldots, \bm{y}_{n}</code>
stands for an observed <code class="reqn">d</code> dimensional dataset of size <code class="reqn">n</code> of vector observations <code class="reqn">\bm{y}_{j} = (y_{1j}, \ldots, y_{ij}, \ldots, y_{dj})^\top</code>.
The value is returned only if all variables in slot <code>x</code> follow either binomial or Dirac parametric families. The default value is <code>list()</code>.
</p>
</dd>
<dt><code>P</code>:</dt><dd>
<p>a data frame containing true <code class="reqn">N_{\mathrm{t}}(\bm{y}_{\tilde{\jmath}})</code> and predictive <code class="reqn">N_{\mathrm{p}}(\bm{y}_{\tilde{\jmath}})</code> frequencies calculated for unique <code class="reqn">\bm{y}_{\tilde{\jmath}} \in \{ \bm{y}_{1}, \ldots, \bm{y}_{n} \}</code>, where <code class="reqn">\tilde{\jmath} = 1, \ldots, \tilde{n}</code> and <code class="reqn">\tilde{n} \leq n</code>.
</p>
</dd>
<dt><code>tau</code>:</dt><dd>
<p>a matrix of size <code class="reqn">n \times c</code> containing conditional probabilities <code class="reqn">\tau_{jl}</code> that observations <code class="reqn">\bm{y}_{1}, \ldots, \bm{y}_{n}</code> arise from clusters <code class="reqn">1, \ldots, c</code>.
</p>
</dd>
<dt><code>prob</code>:</dt><dd>
<p>a vector of length <code class="reqn">c</code> containing probabilities of correct clustering for <code class="reqn">s = 1, \ldots, c</code>.
</p>
</dd>
<dt><code>Rule</code>:</dt><dd>
<p>a character containing the merging rule. One of <code>"Entropy"</code> and <code>"Demp"</code>. The default value is <code>"Entropy"</code>.
</p>
</dd>
<dt><code>from</code>:</dt><dd>
<p>a vector of length <code class="reqn">c - 1</code> containing clusters merged to <code>to</code> clusters.
</p>
</dd>
<dt><code>to</code>:</dt><dd>
<p>a vector of length <code class="reqn">c - 1</code> containing clusters originating from <code>from</code> clusters.
</p>
</dd>
<dt><code>EN</code>:</dt><dd>
<p>a vector of length <code class="reqn">c - 1</code> containing entropies for combined clusters.
</p>
</dd>
<dt><code>ED</code>:</dt><dd>
<p>a vector of length <code class="reqn">c - 1</code> containing decrease of entropies for combined clusters.
</p>
</dd>
<dt><code>A</code>:</dt><dd>
<p>an adjacency matrix of size <code class="reqn">c_{\mathrm{max}} \times c_{\mathrm{max}}</code>, where <code class="reqn">c_{\mathrm{max}} \geq c</code>.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode, Branislav Panic</p>


<h3>References</h3>

<p>J. P. Baudry, A. E. Raftery, G. Celeux, K. Lo and R. Gottardo. Combining mixture components for clustering.
Journal of Computational and Graphical Statistics, 19(2):332-353, 2010. <a href="https://doi.org/10.1198/jcgs.2010.08111">doi:10.1198/jcgs.2010.08111</a> <br /><br />
S. Kyoya and K. Yamanishi. Summarizing finite mixture model with overlapping quantification. Entropy, 23(11):1503, 2021. <a href="https://doi.org/10.3390/e23111503">doi:10.3390/e23111503</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>devAskNewPage(ask = TRUE)

# Generate normal dataset.

n &lt;- c(500, 200, 400)

Theta &lt;- new("RNGMVNORM.Theta", c = 3, d = 2)

a.theta1(Theta, 1) &lt;- c(3, 10)
a.theta1(Theta, 2) &lt;- c(8, 6)
a.theta1(Theta, 3) &lt;- c(12, 11)
a.theta2(Theta, 1) &lt;- c(3, 0.3, 0.3, 2)
a.theta2(Theta, 2) &lt;- c(5.7, -2.3, -2.3, 3.5)
a.theta2(Theta, 3) &lt;- c(2, 1, 1, 2)

normal &lt;- RNGMIX(model = "RNGMVNORM", Dataset.name = "normal_1", n = n, Theta = a.Theta(Theta))

# Estimate number of components, component weights and component parameters.

normalest &lt;- REBMIX(model = "REBMVNORM",
  Dataset = a.Dataset(normal),
  Preprocessing = "histogram",
  cmax = 6,
  Criterion = "BIC")

summary(normalest)

# Plot finite mixture.

plot(normalest)

# Cluster dataset.

normalclu &lt;- RCLRMIX(model = "RCLRMVNORM", x = normalest, Zt = a.Zt(normal))

# Plot clusters.

plot(normalclu)

summary(normalclu)
</code></pre>

<hr>
<h2 id='RCLRMIX-methods'>
Predicts Cluster Membership Based Upon a Model Trained by REBMIX
</h2><span id='topic+RCLRMIX'></span><span id='topic+RCLRMIX-methods'></span><span id='topic+RCLRMIX+2CRCLRMIX-method'></span><span id='topic+RCLRMIX+2CRCLRMVNORM-method'></span><span id='topic+show+2CRCLRMIX-method'></span><span id='topic+show+2CRCLRMVNORM-method'></span><span id='topic+summary+2CRCLRMIX-method'></span><span id='topic+summary+2CRCLRMVNORM-method'></span>

<h3>Description</h3>

<p>Returns as default the RCLRMIX algorithm output for mixtures of conditionally independent normal, lognormal, Weibull, gamma, Gumbel, binomial, Poisson, Dirac, uniform or von Mises component densities, following the methodology proposed in the article cited in the references. If <code>model</code> equals <code>"RCLRMVNORM"</code> output for mixtures of multivariate normal component densities with unrestricted variance-covariance matrices is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'RCLRMIX'
RCLRMIX(model = "RCLRMIX", x = NULL, Dataset = NULL, 
        pos = 1, Zt = factor(), Rule = character(), ...)
## ... and for other signatures
## S4 method for signature 'RCLRMIX'
summary(object, ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RCLRMIX-methods_+3A_model">model</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="RCLRMIX-methods_+3A_x">x</code></td>
<td>

<p>an object of class <code>REBMIX</code>.
</p>
</td></tr>
<tr><td><code id="RCLRMIX-methods_+3A_dataset">Dataset</code></td>
<td>

<p>a data frame or an object of class <code>Histogram</code> to be clustered.
</p>
</td></tr>
<tr><td><code id="RCLRMIX-methods_+3A_pos">pos</code></td>
<td>

<p>a desired row number in <code>x@summary</code> for which the clustering is performed. The default value is <code>1</code>.
</p>
</td></tr>
<tr><td><code id="RCLRMIX-methods_+3A_zt">Zt</code></td>
<td>

<p>a factor of true cluster membership. The default value is <code>factor()</code>.
</p>
</td></tr>
<tr><td><code id="RCLRMIX-methods_+3A_rule">Rule</code></td>
<td>

<p>a character containing the merging rule. One of <code>"Entropy"</code> or <code>"Demp"</code>. The default value is <code>"Entropy"</code>.
</p>
</td></tr>
<tr><td><code id="RCLRMIX-methods_+3A_object">object</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="RCLRMIX-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>RCLRMIX</code> or <code>RCLRMVNORM</code>.
</p>


<h3>Methods</h3>


<dl>
<dt><code>signature(model = "RCLRMIX")</code></dt><dd><p>a character giving the default class name <code>"RCLRMIX"</code> for mixtures of conditionally independent normal, lognormal, Weibull, gamma, Gumbel, binomial, Poisson, Dirac, uniform or von Mises component densities.</p>
</dd>
<dt><code>signature(model = "RCLRMVNORM")</code></dt><dd><p>a character giving the class name <code>"RCLRMVNORM"</code> for mixtures of multivariate normal component densities with unrestricted variance-covariance matrices.</p>
</dd>
<dt><code>signature(object = "RCLRMIX")</code></dt><dd><p>an object of class <code>RCLRMIX</code>.</p>
</dd>
<dt><code>signature(object = "RCLRMVNORM")</code></dt><dd><p>an object of class <code>RCLRMVNORM</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>J. P. Baudry, A. E. Raftery, G. Celeux, K. Lo and R. Gottardo. Combining mixture components for clustering.
Journal of Computational and Graphical Statistics, 19(2):332-353, 2010. <a href="https://doi.org/10.1198/jcgs.2010.08111">doi:10.1198/jcgs.2010.08111</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>devAskNewPage(ask = TRUE)

# Generate Poisson dataset.

n &lt;- c(500, 200, 400)

Theta &lt;- new("RNGMIX.Theta", c = 3, pdf = "Poisson")

a.theta1(Theta) &lt;- c(3, 12, 36)

poisson &lt;- RNGMIX(Dataset.name = "Poisson_1", n = n, Theta = a.Theta(Theta))

# Estimate number of components, component weights and component parameters.

EM &lt;- new("EM.Control", strategy = "exhaustive")

poissonest &lt;- REBMIX(Dataset = a.Dataset(poisson),
  Preprocessing = "histogram",
  cmax = 6,
  Criterion = "BIC",
  pdf = rep("Poisson", 1),
  EMcontrol = EM)

summary(poissonest)

# Plot finite mixture.

plot(poissonest)

# Cluster dataset.

poissonclu &lt;- RCLRMIX(x = poissonest, Zt = a.Zt(poisson))

summary(poissonclu)

# Plot clusters.

plot(poissonclu)

# Create new dataset.

Dataset &lt;- sample.int(n = 50, size = 10, replace = TRUE)

Dataset &lt;- as.data.frame(Dataset)

# Cluster the dataset.

poissonclu &lt;- RCLRMIX(x = poissonest, Dataset = Dataset, Rule = "Demp")

a.Dataset(poissonclu)
</code></pre>

<hr>
<h2 id='RCLS.chunk-class'>Class <code>"RCLS.chunk"</code></h2><span id='topic+RCLS.chunk-class'></span>

<h3>Description</h3>

<p>Object of class <code>RCLS.chunk</code>.</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>new("RCLS.chunk", ...)</code>. Accessor methods for the slots are <code>a.s(x = NULL)</code>,
<code>a.levels(x = NULL)</code>, <code>a.ntrain(x = NULL)</code>, <code>a.train(x = NULL)</code>, <code>a.Zr(x = NULL)</code>, <code>a.ntest(x = NULL)</code>, <code>a.test(x = NULL)</code> and <code>a.Zt(x = NULL)</code>,
where <code>x</code> stands for an object of class <code>RCLS.chunk</code>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>s</code>:</dt><dd>
<p>finite set of size <code class="reqn">s</code> of classes <code class="reqn">\bm{\Omega} = \{\bm{\Omega}_{g}; \ g = 1, \ldots, s\}</code>.
</p>
</dd>
<dt><code>levels</code>:</dt><dd>
<p>a character vector of length <code class="reqn">s</code> containing class names <code class="reqn">\bm{\Omega}_{g}</code>.
</p>
</dd>
<dt><code>ntrain</code>:</dt><dd>
<p>a vector of length <code class="reqn">s</code> containing numbers of observations in train datasets <code class="reqn">Y_{\mathrm{train}g}</code>.
</p>
</dd>
<dt><code>train</code>:</dt><dd>
<p>a list of length <code class="reqn">n_{\mathrm{D}}</code> of data frames containing train datasets <code class="reqn">Y_{\mathrm{train}g}</code> of length <code class="reqn">n_{\mathrm{train}g}</code>.
</p>
</dd>
<dt><code>Zr</code>:</dt><dd>
<p>a list of factors of true class membership <code class="reqn">\bm{\Omega}_{g}</code> for the train datasets.
</p>
</dd>
<dt><code>ntest</code>:</dt><dd>
<p>number of observations in test dataset <code class="reqn">Y_{\mathrm{test}}</code>.
</p>
</dd>
<dt><code>test</code>:</dt><dd>
<p>a data frame containing test dataset <code class="reqn">Y_{\mathrm{test}}</code> of length <code class="reqn">n_{\mathrm{test}}</code>.
</p>
</dd>
<dt><code>Zt</code>:</dt><dd>
<p>a factor of true class membership <code class="reqn">\bm{\Omega}_{g}</code> for the test dataset.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>D. M. Dziuda. Data Mining for Genomics and Proteomics: Analysis of Gene and Protein
Expression Data. John Wiley &amp; Sons, New York, 2010.
</p>

<hr>
<h2 id='RCLSMIX-class'>Class <code>"RCLSMIX"</code></h2><span id='topic+RCLSMIX-class'></span><span id='topic+RCLSMVNORM-class'></span>

<h3>Description</h3>

<p>Object of class <code>RCLSMIX</code>.</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>new("RCLSMIX", ...)</code>. Accessor methods for the slots are <code>a.o(x = NULL)</code>,
<code>a.Dataset(x = NULL)</code>, <code>a.s(x = NULL)</code>, <code>a.ntrain(x = NULL)</code>, <code>a.P(x = NULL)</code>, <code>a.ntest(x = NULL)</code>, <code>a.Zt(x = NULL)</code>,
<code>a.Zp(x = NULL)</code>, <code>a.CM(x = NULL)</code>, <code>a.Accuracy(x = NULL)</code>, <code>a.Error(x = NULL)</code>, <code>a.Precision(x = NULL)</code>, <code>a.Sensitivity(x = NULL)</code>,
<code>a.Specificity(x = NULL)</code> and <code>a.Chunks(x = NULL)</code>, where <code>x</code> stands for an object of class <code>RCLSMIX</code>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>x</code>:</dt><dd>
<p>a list of objects of class <code>REBMIX</code> of length <code class="reqn">o</code> obtained by running <code><a href="#topic+REBMIX">REBMIX</a></code> on <code class="reqn">g = 1, \ldots, s</code> train datasets <code class="reqn">Y_{\mathrm{train}g}</code> all of length <code class="reqn">n_{\mathrm{train}g}</code>.
For the train datasets the corresponding class membership <code class="reqn">\bm{\Omega}_{g}</code> is known. This yields
<code class="reqn">n_{\mathrm{train}} = \sum_{g = 1}^{s} n_{\mathrm{train}g}</code>, while <code class="reqn">Y_{\mathrm{train}q} \cap Y_{\mathrm{train}g} = \emptyset</code> for all <code class="reqn">q \neq g</code>.
Each object in the list corresponds to one chunk, e.g., <code class="reqn">(y_{1j}, y_{3j})^{\top}</code>.
</p>
</dd>
<dt><code>o</code>:</dt><dd>
<p>number of chunks <code class="reqn">o</code>. <code class="reqn">Y = \{\bm{y}_{j}; \ j = 1, \ldots, n\}</code> is an observed <code class="reqn">d</code>-dimensional dataset of size <code class="reqn">n</code> of vector observations <code class="reqn">\bm{y}_{j} = (y_{1j}, \ldots, y_{dj})^{\top}</code> and
is partitioned into train and test datasets. Vector observations <code class="reqn">\bm{y}_{j}</code> may further be split into <code class="reqn">o</code> chunks when running <code><a href="#topic+REBMIX">REBMIX</a></code>, e.g.,
for <code class="reqn">d = 6</code> and <code class="reqn">o = 3</code> the set of chunks substituting <code class="reqn">\bm{y}_{j}</code> may be as follows <code class="reqn">(y_{1j}, y_{3j})^{\top}</code>, <code class="reqn">(y_{2j}, y_{4j}, y_{6j})^{\top}</code> and <code class="reqn">y_{5j}</code>.
</p>
</dd>
<dt><code>Dataset</code>:</dt><dd>
<p>a data frame containing test dataset <code class="reqn">Y_{\mathrm{test}}</code> of length <code class="reqn">n_{\mathrm{test}}</code>. For the test dataset the corresponding class membership <code class="reqn">\bm{\Omega}_{g}</code> is not known.
</p>
</dd>
<dt><code>s</code>:</dt><dd>
<p>finite set of size <code class="reqn">s</code> of classes <code class="reqn">\bm{\Omega} = \{\bm{\Omega}_{g}; \ g = 1, \ldots, s\}</code>.
</p>
</dd>
<dt><code>ntrain</code>:</dt><dd>
<p>a vector of length <code class="reqn">s</code> containing numbers of observations in train datasets <code class="reqn">Y_{\mathrm{train}g}</code>.
</p>
</dd>
<dt><code>P</code>:</dt><dd>
<p>a vector of length <code class="reqn">s</code> containing prior probabilities <code class="reqn">P(\bm{\Omega}_{g}) = \frac{n_{\mathrm{train}g}}{n_{\mathrm{train}}}</code>.
</p>
</dd>
<dt><code>ntest</code>:</dt><dd>
<p>number of observations in test dataset <code class="reqn">Y_{\mathrm{test}}</code>.
</p>
</dd>
<dt><code>Zt</code>:</dt><dd>
<p>a factor of true class membership <code class="reqn">\bm{\Omega}_{g}</code> for the test dataset.
</p>
</dd>
<dt><code>Zp</code>:</dt><dd>
<p>a factor of predictive class membership <code class="reqn">\bm{\Omega}_{g}</code> for the test dataset.
</p>
</dd>
<dt><code>CM</code>:</dt><dd>
<p>a table containing confusion matrix for multiclass classifier. It contains
number <code class="reqn">x_{qg}</code> of test observations with the true class <code class="reqn">q</code> that are classified into the class <code class="reqn">g</code>, where <code class="reqn">q, g = 1, \ldots, s</code>.
</p>
</dd>
<dt><code>Accuracy</code>:</dt><dd>
<p>proportion of all test observations that are classified correctly. <code class="reqn">\mathrm{Accuracy} = \frac{\sum_{g = 1}^{s} x_{gg}}{n_{\mathrm{test}}}</code>.
</p>
</dd>
<dt><code>Error</code>:</dt><dd>
<p>proportion of all test observations that are classified wrongly. <code class="reqn">\mathrm{Error} = 1 - \mathrm{Accuracy}</code>.
</p>
</dd>
<dt><code>Precision</code>:</dt><dd>
<p>a vector containing proportions of predictive observations in class <code class="reqn">g</code> that are
classified correctly into class <code class="reqn">g</code>. <code class="reqn">\mathrm{Precision}(g) = \frac{x_{gg}}{\sum_{q = 1}^{s} x_{qg}}</code>.
</p>
</dd>
<dt><code>Sensitivity</code>:</dt><dd>
<p>a vector containing proportions of test observations in class <code class="reqn">g</code> that are classified
correctly into class <code class="reqn">g</code>. <code class="reqn">\mathrm{Sensitivity}(g) = \frac{x_{gg}}{\sum_{q = 1}^{s} x_{gq}}</code>.
</p>
</dd>
<dt><code>Specificity</code>:</dt><dd>
<p>a vector containing proportions of test observations that are not in class <code class="reqn">g</code> and
are classified into the non <code class="reqn">g</code> class. <code class="reqn">\mathrm{Specificity}(g) = \frac{n_{\mathrm{test}} - \sum_{q = 1}^{s} x_{qg}}{n_{\mathrm{test}} - \sum_{q = 1}^{s} x_{gq}}</code>.
</p>
</dd>
<dt><code>Chunks</code>:</dt><dd>
<p>a vector containing selected chunks.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>D. M. Dziuda. Data Mining for Genomics and Proteomics: Analysis of Gene and Protein
Expression Data. John Wiley &amp; Sons, New York, 2010.
</p>

<hr>
<h2 id='RCLSMIX-methods'>
Predicts Class Membership Based Upon a Model Trained by REBMIX
</h2><span id='topic+RCLSMIX'></span><span id='topic+RCLSMIX-methods'></span><span id='topic+RCLSMIX+2CRCLSMIX-method'></span><span id='topic+RCLSMIX+2CRCLSMVNORM-method'></span><span id='topic+show+2CRCLSMIX-method'></span><span id='topic+show+2CRCLSMVNORM-method'></span><span id='topic+summary+2CRCLSMIX-method'></span><span id='topic+summary+2CRCLSMVNORM-method'></span>

<h3>Description</h3>

<p>Returns as default the RCLSMIX algorithm output for mixtures of conditionally independent normal, lognormal, Weibull, gamma, Gumbel, binomial, Poisson, Dirac, uniform or von Mises component densities. If <code>model</code> equals <code>"RCLSMVNORM"</code> output for mixtures of multivariate normal component densities with unrestricted variance-covariance matrices is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'RCLSMIX'
RCLSMIX(model = "RCLSMIX", x = list(), Dataset = data.frame(),
        Zt = factor(), ...)
## ... and for other signatures
## S4 method for signature 'RCLSMIX'
summary(object, ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RCLSMIX-methods_+3A_model">model</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="RCLSMIX-methods_+3A_x">x</code></td>
<td>

<p>a list of objects of class <code>REBMIX</code> of length <code class="reqn">o</code> obtained by running <code><a href="#topic+REBMIX">REBMIX</a></code> on <code class="reqn">g = 1, \ldots, s</code> train datasets <code class="reqn">Y_{\mathrm{train}g}</code> all of length <code class="reqn">n_{\mathrm{train}g}</code>.
For the train datasets the corresponding class membership <code class="reqn">\bm{\Omega}_{g}</code> is known. This yields
<code class="reqn">n_{\mathrm{train}} = \sum_{g = 1}^{s} n_{\mathrm{train}g}</code>, while <code class="reqn">Y_{\mathrm{train}q} \cap Y_{\mathrm{train}g} = \emptyset</code> for all <code class="reqn">q \neq g</code>.
Each object in the list corresponds to one chunk, e.g., <code class="reqn">(y_{1j}, y_{3j})^{\top}</code>. The default value is <code>list()</code>.
</p>
</td></tr>
<tr><td><code id="RCLSMIX-methods_+3A_dataset">Dataset</code></td>
<td>

<p>a data frame containing test dataset <code class="reqn">Y_{\mathrm{test}}</code> of length <code class="reqn">n_{\mathrm{test}}</code>. For the test dataset the corresponding class membership <code class="reqn">\bm{\Omega}_{g}</code> is not known.
The default value is <code>data.frame()</code>.
</p>
</td></tr>
<tr><td><code id="RCLSMIX-methods_+3A_zt">Zt</code></td>
<td>

<p>a factor of true class membership <code class="reqn">\bm{\Omega}_{g}</code> for the test dataset. The default value is <code>factor()</code>.
</p>
</td></tr>
<tr><td><code id="RCLSMIX-methods_+3A_object">object</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="RCLSMIX-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>RCLSMIX</code> or <code>RCLSMVNORM</code>.
</p>


<h3>Methods</h3>


<dl>
<dt><code>signature(model = "RCLSMIX")</code></dt><dd><p>a character giving the default class name <code>"RCLSMIX"</code> for mixtures of conditionally independent normal, lognormal, Weibull, gamma, Gumbel, binomial, Poisson, Dirac, uniform or von Mises component densities.</p>
</dd>
<dt><code>signature(model = "RCLSMVNORM")</code></dt><dd><p>a character giving the class name <code>"RCLSMVNORM"</code> for mixtures of multivariate normal component densities with unrestricted variance-covariance matrices.</p>
</dd>
<dt><code>signature(object = "RCLSMIX")</code></dt><dd><p>an object of class <code>RCLSMIX</code>.</p>
</dd>
<dt><code>signature(object = "RCLSMVNORM")</code></dt><dd><p>an object of class <code>RCLSMVNORM</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>R. O. Duda and P. E. Hart. Pattern Classification and Scene Analysis. John Wiley &amp; Sons, New
York, 1973.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
devAskNewPage(ask = TRUE)

data(adult)

# Find complete cases.

adult &lt;- adult[complete.cases(adult),]

# Replace levels with numbers.

adult &lt;- as.data.frame(data.matrix(adult))

# Find numbers of levels.

cmax &lt;- unlist(lapply(apply(adult[, c(-1, -16)], 2, unique), length))

cmax

# Split adult dataset into train and test subsets for two Incomes
# and remove Type and Income columns.

Adult &lt;- split(p = list(type = 1, train = 2, test = 1),
  Dataset = adult, class = 16)

# Estimate number of components, component weights and component parameters
# for the set of chunks 1:14.

adultest &lt;- list()

for (i in 1:14) {
  adultest[[i]] &lt;- REBMIX(Dataset = a.train(chunk(Adult, i)),
    Preprocessing = "histogram",
    cmax = min(120, cmax[i]),
    Criterion = "BIC",
    pdf = "Dirac",
    K = 1)
}

# Class membership prediction based upon the best first search algorithm.

adultcla &lt;- BFSMIX(x = adultest,
  Dataset = a.test(Adult),
  Zt = a.Zt(Adult))

adultcla

summary(adultcla)

# Plot selected chunks.

plot(adultcla, nrow = 5, ncol = 2)

## End(Not run)
</code></pre>

<hr>
<h2 id='REBMIX-class'>Class <code>"REBMIX"</code></h2><span id='topic+REBMIX-class'></span><span id='topic+REBMVNORM-class'></span>

<h3>Description</h3>

<p>Object of class <code>REBMIX</code>.</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>new("REBMIX", ...)</code>. Accessor methods for the slots are <code>a.Dataset(x = NULL, pos = 0)</code>,
<code>a.Preprocessing(x = NULL)</code>, <code>a.cmax(x = NULL)</code>, <code>a.cmin(x = NULL)</code>, <code>a.Criterion(x = NULL)</code>, <code>a.Variables(x = NULL)</code>,
<code>a.pdf(x = NULL)</code>, <code>a.theta1(x = NULL)</code>, <code>a.theta2(x = NULL)</code>, <code>a.theta3(x = NULL)</code>, <code>a.K(x = NULL)</code>, <code>a.ymin(x = NULL)</code>,
<code>a.ymax(x = NULL)</code>, <code>a.ar(x = NULL)</code>, <code>a.Restraints(x = NULL)</code>, <code>a.Mode(x = NULL)</code>, <code>a.w(x = NULL, pos = 0)</code>, <code>a.Theta(x = NULL, pos = 0)</code>, <code>a.summary(x = NULL, col.name = character(), pos = 0)</code>,
<code>a.summary.EM(x = NULL, col.name = character(), pos = 0)</code>, <code>a.pos(x = NULL)</code>,
<code>a.opt.c(x = NULL)</code>, <code>a.opt.IC(x = NULL)</code>, <code>a.opt.logL(x = NULL)</code>, <code>a.opt.Dmin(x = NULL)</code>, <code>a.opt.D(x = NULL)</code>, <code>a.all.K(x = NULL)</code>, <code>a.all.IC(x = NULL)</code>,
<code>a.theta1.all(x = NULL, pos = 1)</code>, <code>a.theta2.all(x = NULL, pos = 1)</code> and <code>a.theta3.all(x = NULL, pos = 1)</code>, where <code>x</code>, <code>pos</code> and <code>col.name</code> stand for an object of class <code>REBMIX</code>,
a desired slot item and a desired column name, respectively.
</p>


<h3>Slots</h3>


<dl>
<dt><code>Dataset</code>:</dt><dd>
<p>a list of length <code class="reqn">n_{\mathrm{D}}</code> of data frames or objects of class <code>Histogram</code>. 
Data frames should have size <code class="reqn">n \times d</code> containing <em>d</em>-dimensional datasets. Each of the <code class="reqn">d</code>
columns represents one random variable. Numbers of observations <code class="reqn">n</code> equal the number of rows in the datasets.
</p>
</dd>
<dt><code>Preprocessing</code>:</dt><dd>
<p>a character vector giving the preprocessing types. One of <code>"histogram"</code>, <br />
<code>"kernel density estimation"</code> or <code>"k-nearest neighbour"</code>.
</p>
</dd>
<dt><code>cmax</code>:</dt><dd>
<p>maximum number of components <code class="reqn">c_{\mathrm{max}} &gt; 0</code>. The default value is <code>15</code>.
</p>
</dd>
<dt><code>cmin</code>:</dt><dd>
<p>minimum number of components <code class="reqn">c_{\mathrm{min}} &gt; 0</code>. The default value is <code>1</code>.
</p>
</dd>
<dt><code>Criterion</code>:</dt><dd>
<p>a character giving the information criterion type. One of default Akaike <code>"AIC"</code>, <code>"AIC3"</code>, <code>"AIC4"</code> or <code>"AICc"</code>,
Bayesian <code>"BIC"</code>, consistent Akaike <code>"CAIC"</code>, Hannan-Quinn <code>"HQC"</code>, minimum description length <code>"MDL2"</code> or <code>"MDL5"</code>,
approximate weight of evidence <code>"AWE"</code>, classification likelihood <code>"CLC"</code>,
integrated classification likelihood <code>"ICL"</code> or <code>"ICL-BIC"</code>, partition coefficient <code>"PC"</code>,
total of positive relative deviations <code>"D"</code> or sum of squares error <code>"SSE"</code>.
</p>
</dd>
<dt><code>Variables</code>:</dt><dd>
<p>a character vector of length <code class="reqn">d</code> containing types of variables. One of <code>"continuous"</code> or <code>"discrete"</code>.
</p>
</dd>
<dt><code>pdf</code>:</dt><dd>
<p>a character vector of length <code class="reqn">d</code> containing continuous or discrete parametric family types. One of <code>"normal"</code>, <code>"lognormal"</code>, <code>"Weibull"</code>, <code>"gamma"</code>, <code>"Gumbel"</code>, <code>"binomial"</code>, <code>"Poisson"</code>, <code>"Dirac"</code>, <code>"uniform"</code> or <code>"vonMises"</code>.
</p>
</dd>
<dt><code>theta1</code>:</dt><dd>
<p>a vector of length <code class="reqn">d</code> containing initial component parameters. One of <code class="reqn">n_{il} = \textrm{number of categories} - 1</code> for <code>"binomial"</code> distribution.
</p>
</dd>
<dt><code>theta2</code>:</dt><dd>
<p>a vector of length <code class="reqn">d</code> containing initial component parameters. Currently not used.
</p>
</dd>
<dt><code>theta3</code>:</dt><dd>
<p>a vector of length <code class="reqn">d</code> containing initial component parameters. One of <code class="reqn">\xi_{il} \in \{-1, \textrm{NA}, 1\}</code> for <code>"Gumbel"</code> distribution.
</p>
</dd>
<dt><code>K</code>:</dt><dd>
<p>a character or a vector or a list of vectors containing numbers of bins <code class="reqn">v</code> for the histogram and the kernel density estimation or numbers of nearest
neighbours <code class="reqn">k</code> for the <em>k</em>-nearest neighbour. There is no genuine rule to identify <code class="reqn">v</code> or <code class="reqn">k</code>. Consequently,
the REBMIX algorithm identifies them from the set <code>K</code> of input values by
minimizing the information criterion. The Sturges rule <code class="reqn">v = 1 + \mathrm{log_{2}}(n)</code>, <code class="reqn">\mathrm{Log}_{10}</code> rule <code class="reqn">v = 10 \mathrm{log_{10}}(n)</code> or RootN
rule <code class="reqn">v = 2 \sqrt{n}</code> can be applied to estimate the limiting numbers of bins
or the rule of thumb <code class="reqn">k = \sqrt{n}</code> to guess the intermediate number of nearest neighbours. If, e.g., <code>K = c(10, 20, 40, 60)</code> and minimum <code>IC</code> coincides, e.g., <code>40</code>, brackets are set to <code>20</code> and <code>60</code> and the golden section is applied to refine the minimum search. See also <code><a href="#topic+kseq">kseq</a></code> for sequence of bins or nearest neighbours generation. The default value is <code>"auto"</code>.
</p>
</dd>
<dt><code>ymin</code>:</dt><dd>
<p>a vector of length <code class="reqn">d</code> containing minimum observations. The default value is <code>numeric()</code>.
</p>
</dd>
<dt><code>ymax</code>:</dt><dd>
<p>a vector of length <code class="reqn">d</code> containing maximum observations. The default value is <code>numeric()</code>.
</p>
</dd>
<dt><code>ar</code>:</dt><dd>
<p>acceleration rate <code class="reqn">0 &lt; a_{\mathrm{r}} \leq 1</code>. The default value is <code>0.1</code> and in most cases does not have to be altered.
</p>
</dd>
<dt><code>Restraints</code>:</dt><dd>
<p>a character giving the restraints type. One of <code>"rigid"</code> or default <code>"loose"</code>.
The rigid restraints are obsolete and applicable for well separated components only.
</p>
</dd>
<dt><code>Mode</code>:</dt><dd>
<p>a character giving the mode type. One of <code>"all"</code>, <code>"outliers"</code> or default <code>"outliersplus"</code>.The modes are determined in decreasing order of magnitude from all observations if <code>Mode = "all"</code>.
If <code>Mode = "outliers"</code>, the modes are determined in decreasing order of magnitude from outliers only. In the meantime, some outliers are reclassified as inliers. Finally, when all observations are inliers, the procedure is completed.
If <code>Mode = "outliersplus"</code>, the modes are determined in decreasing magnitude from the outliers only. In the meantime, some outliers are reclassified as inliers. Finally, if all observations are inliers, they are converted to outliers and the mode determination procedure is continued.
</p>
</dd>
<dt><code>w</code>:</dt><dd>
<p>a list of vectors of length <code class="reqn">c</code> containing component weights <code class="reqn">w_{l}</code> summing to 1.
</p>
</dd>
<dt><code>Theta</code>:</dt><dd>
<p>a list of lists each containing <code class="reqn">c</code> parametric family types <code>pdfl</code>. One of <code>"normal"</code>, <code>"lognormal"</code>, <code>"Weibull"</code>, <code>"gamma"</code>, <code>"Gumbel"</code>, <code>"binomial"</code>, <code>"Poisson"</code>, <code>"Dirac"</code>, <code>"uniform"</code> or circular <code>"vonMises"</code> defined for <code class="reqn">0 \leq y_{i} \leq 2 \pi</code>.
Component parameters <code>theta1.l</code> follow the parametric family types. One of <code class="reqn">\mu_{il}</code> for normal, lognormal, Gumbel and von Mises distributions, <code class="reqn">\theta_{il}</code> for Weibull, gamma, binomial, Poisson and Dirac distributions and <code class="reqn">a</code> for uniform distribution.
Component parameters <code>theta2.l</code> follow <code>theta1.l</code>. One of <code class="reqn">\sigma_{il}</code> for normal, lognormal and Gumbel distributions, <code class="reqn">\beta_{il}</code> for Weibull and gamma distributions, <code class="reqn">p_{il}</code> for binomial distribution, <code class="reqn">\kappa_{il}</code> for von Mises distribution and <code class="reqn">b</code> for uniform distribution.
Component parameters <code>theta3.l</code> follow <code>theta2.l</code>. One of <code class="reqn">\xi_{il}</code> for Gumbel distribution.
</p>
</dd>
<dt><code>summary</code>:</dt><dd>
<p>a data frame with additional information about dataset, preprocessing, <code class="reqn">c_{\mathrm{max}}</code>, <code class="reqn">c_{\mathrm{min}}</code>, information criterion type,
<code class="reqn">a_{\mathrm{r}}</code>, restraints type, mode type, optimal <code class="reqn">c</code>, optimal <code class="reqn">v</code> or <code class="reqn">k</code>, <code class="reqn">K</code>, <code class="reqn">y_{i0}</code>, <code class="reqn">y_{i\mathrm{min}}</code>, <code class="reqn">y_{i\mathrm{max}}</code>, optimal <code class="reqn">h_{i}</code>,
information criterion <code class="reqn">\mathrm{IC}</code>, log likelihood <code class="reqn">\mathrm{log}\, L</code> and degrees of freedom <code class="reqn">M</code>.
</p>
</dd>
<dt><code>summary.EM</code>:</dt><dd>
<p>a data frame with additional information about dataset, strategy for the EM algorithm <code>strategy</code>,
variant of the EM algorithm <code>variant</code>, acceleration type <code>acceleration</code>, tolerance <code>tolerance</code>, acceleration multilplier <code>acceleration.multiplier</code>,
maximum allowed number of iterations <code>maximum.iterations</code>, number of iterations used for obtaining optimal solution <code>opt.iterations.nbr</code> and total number of iterations of the EM algorithm <code>total.iterations.nbr</code>.
</p>
</dd>
<dt><code>pos</code>:</dt><dd>
<p>position in the <code>summary</code> data frame at which log likelihood <code class="reqn">\mathrm{log}\, L</code> attains its maximum.
</p>
</dd>
<dt><code>opt.c</code>:</dt><dd>
<p>a list of vectors containing numbers of components for optimal <code class="reqn">v</code> for the histogram and the kernel density estimation or for optimal number of nearest
neighbours <code class="reqn">k</code> for the <em>k</em>-nearest neighbour.
</p>
</dd>
<dt><code>opt.IC</code>:</dt><dd>
<p>a list of vectors containing information criteria for optimal <code class="reqn">v</code> for the histogram and the kernel density estimation or for optimal number of nearest
neighbours <code class="reqn">k</code> for the <em>k</em>-nearest neighbour.
</p>
</dd>
<dt><code>opt.logL</code>:</dt><dd>
<p>a list of vectors containing log likelihoods for optimal <code class="reqn">v</code> for the histogram and the kernel density estimation or for optimal number of nearest
neighbours <code class="reqn">k</code> for the <em>k</em>-nearest neighbour.
</p>
</dd>
<dt><code>opt.Dmin</code>:</dt><dd>
<p>a list of vectors containing <code class="reqn">D_{\mathrm{min}}</code> values for optimal <code class="reqn">v</code> for the histogram and the kernel density estimation or for optimal number of nearest
neighbours <code class="reqn">k</code> for the <em>k</em>-nearest neighbour.
</p>
</dd>
<dt><code>opt.D</code>:</dt><dd>
<p>a list of vectors containing totals of positive relative deviations for optimal <code class="reqn">v</code> for the histogram and the kernel density estimation or for optimal number of nearest
neighbours <code class="reqn">k</code> for the <em>k</em>-nearest neighbour.
</p>
</dd>
<dt><code>all.K</code>:</dt><dd>
<p>a list of vectors containing all processed numbers of bins <code class="reqn">v</code> for the histogram and the kernel density estimation or all processed numbers of nearest
neighbours <code class="reqn">k</code> for the <em>k</em>-nearest neighbour.
</p>
</dd>
<dt><code>all.IC</code>:</dt><dd>
<p>a list of vectors containing information criteria for all processed numbers of bins <code class="reqn">v</code> for the histogram and the kernel density estimation or for all processed numbers of nearest
neighbours <code class="reqn">k</code> for the <em>k</em>-nearest neighbour.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>

<hr>
<h2 id='rebmix-internal'>Internal rebmix Functions, Methods and Classes</h2><span id='topic+AIC+2CANY-method'></span><span id='topic+AIC3+2CANY-method'></span><span id='topic+AIC4+2CANY-method'></span><span id='topic+AICc+2CANY-method'></span><span id='topic+CAIC+2CANY-method'></span><span id='topic+AWE+2CANY-method'></span><span id='topic+BIC+2CANY-method'></span><span id='topic+CLC+2CANY-method'></span><span id='topic+HQC+2CANY-method'></span><span id='topic+ICL+2CANY-method'></span><span id='topic+ICLBIC+2CANY-method'></span><span id='topic+logL+2CANY-method'></span><span id='topic+MDL2+2CANY-method'></span><span id='topic+MDL5+2CANY-method'></span><span id='topic+PC+2CANY-method'></span><span id='topic+PRD+2CANY-method'></span><span id='topic+SSE+2CANY-method'></span><span id='topic+REBMIX+2CANY-method'></span><span id='topic+RNGMIX+2CANY-method'></span><span id='topic+RCLRMIX+2CANY-method'></span><span id='topic+RCLSMIX+2CANY-method'></span><span id='topic+BFSMIX+2CANY-method'></span><span id='topic+EMMIX+2CANY-method'></span><span id='topic+fhistogram+2CANY-method'></span><span id='topic+chistogram+2CANY-method'></span><span id='topic+mapclusters+2CANY-method'></span><span id='topic+labelmoments+2CANY-method'></span><span id='topic+mergelabels+2CANY-method'></span><span id='topic+a.d'></span><span id='topic+a.theta1+3C-'></span><span id='topic+a.theta2+3C-'></span><span id='topic+a.theta3+3C-'></span><span id='topic+a.c+2CRNGMIX.Theta-method'></span><span id='topic+a.d+2CRNGMIX.Theta-method'></span><span id='topic+a.pdf+2CRNGMIX.Theta-method'></span><span id='topic+a.Theta+2CRNGMIX.Theta-method'></span><span id='topic+a.theta1+3C-+2CRNGMIX.Theta+2CANY-method'></span><span id='topic+a.theta2+3C-+2CRNGMIX.Theta+2CANY-method'></span><span id='topic+a.theta3+3C-+2CRNGMIX.Theta+2CANY-method'></span><span id='topic+a.theta1+3C-+2CRNGMIX.Theta+2Cmissing-method'></span><span id='topic+a.theta2+3C-+2CRNGMIX.Theta+2Cmissing-method'></span><span id='topic+a.theta3+3C-+2CRNGMIX.Theta+2Cmissing-method'></span><span id='topic+a.c+2CRNGMVNORM.Theta-method'></span><span id='topic+a.d+2CRNGMVNORM.Theta-method'></span><span id='topic+a.pdf+2CRNGMVNORM.Theta-method'></span><span id='topic+a.Theta+2CRNGMVNORM.Theta-method'></span><span id='topic+a.theta1+3C-+2CRNGMVNORM.Theta+2CANY-method'></span><span id='topic+a.theta2+3C-+2CRNGMVNORM.Theta+2CANY-method'></span><span id='topic+a.theta1.all+3C-+2CRNGMIX.Theta-method'></span><span id='topic+a.theta2.all+3C-+2CRNGMIX.Theta-method'></span><span id='topic+a.theta3.all+3C-+2CRNGMIX.Theta-method'></span><span id='topic+a.theta1.all+3C-+2CRNGMVNORM.Theta-method'></span><span id='topic+a.theta2.all+3C-+2CRNGMVNORM.Theta-method'></span><span id='topic+a.Dataset.name'></span><span id='topic+a.rseed'></span><span id='topic+a.n'></span><span id='topic+a.Theta'></span><span id='topic+a.Dataset'></span><span id='topic+a.Zt'></span><span id='topic+a.w'></span><span id='topic+a.Variables'></span><span id='topic+a.ymin'></span><span id='topic+a.ymax'></span><span id='topic+a.Dataset.name+2CRNGMIX-method'></span><span id='topic+a.rseed+2CRNGMIX-method'></span><span id='topic+a.n+2CRNGMIX-method'></span><span id='topic+a.Theta+2CRNGMIX-method'></span><span id='topic+a.Dataset+2CRNGMIX-method'></span><span id='topic+a.Zt+2CRNGMIX-method'></span><span id='topic+a.w+2CRNGMIX-method'></span><span id='topic+a.Variables+2CRNGMIX-method'></span><span id='topic+a.ymin+2CRNGMIX-method'></span><span id='topic+a.ymax+2CRNGMIX-method'></span><span id='topic+a.Dataset.name+2CRNGMVNORM-method'></span><span id='topic+a.rseed+2CRNGMVNORM-method'></span><span id='topic+a.n+2CRNGMVNORM-method'></span><span id='topic+a.Theta+2CRNGMVNORM-method'></span><span id='topic+a.Dataset+2CRNGMVNORM-method'></span><span id='topic+a.Zt+2CRNGMVNORM-method'></span><span id='topic+a.w+2CRNGMVNORM-method'></span><span id='topic+a.Variables+2CRNGMVNORM-method'></span><span id='topic+a.ymin+2CRNGMVNORM-method'></span><span id='topic+a.ymax+2CRNGMVNORM-method'></span><span id='topic+a.Preprocessing'></span><span id='topic+a.cmax'></span><span id='topic+a.cmin'></span><span id='topic+a.Criterion'></span><span id='topic+a.pdf'></span><span id='topic+a.theta1'></span><span id='topic+a.theta2'></span><span id='topic+a.theta3'></span><span id='topic+a.theta1.all'></span><span id='topic+a.theta2.all'></span><span id='topic+a.theta3.all'></span><span id='topic+a.theta1.all+3C-'></span><span id='topic+a.theta2.all+3C-'></span><span id='topic+a.theta3.all+3C-'></span><span id='topic+a.K'></span><span id='topic+a.y0'></span><span id='topic+a.ar'></span><span id='topic+a.Restraints'></span><span id='topic+a.Mode'></span><span id='topic+a.summary'></span><span id='topic+a.pos'></span><span id='topic+a.opt.c'></span><span id='topic+a.opt.IC'></span><span id='topic+a.opt.logL'></span><span id='topic+a.opt.Dmin'></span><span id='topic+a.opt.D'></span><span id='topic+a.all.K'></span><span id='topic+a.all.IC'></span><span id='topic+a.Dataset+2CREBMIX-method'></span><span id='topic+a.Preprocessing+2CREBMIX-method'></span><span id='topic+a.cmax+2CREBMIX-method'></span><span id='topic+a.cmin+2CREBMIX-method'></span><span id='topic+a.Criterion+2CREBMIX-method'></span><span id='topic+a.Variables+2CREBMIX-method'></span><span id='topic+a.pdf+2CREBMIX-method'></span><span id='topic+a.theta1+2CREBMIX-method'></span><span id='topic+a.theta2+2CREBMIX-method'></span><span id='topic+a.theta3+2CREBMIX-method'></span><span id='topic+a.theta1.all+2CREBMIX-method'></span><span id='topic+a.theta2.all+2CREBMIX-method'></span><span id='topic+a.theta3.all+2CREBMIX-method'></span><span id='topic+a.theta2.all+2CREBMVNORM-method'></span><span id='topic+a.K+2CREBMIX-method'></span><span id='topic+a.ymin+2CREBMIX-method'></span><span id='topic+a.ymax+2CREBMIX-method'></span><span id='topic+a.ar+2CREBMIX-method'></span><span id='topic+a.Restraints+2CREBMIX-method'></span><span id='topic+a.Mode+2CREBMIX-method'></span><span id='topic+a.w+2CREBMIX-method'></span><span id='topic+a.Theta+2CREBMIX-method'></span><span id='topic+a.summary+2CREBMIX-method'></span><span id='topic+a.pos+2CREBMIX-method'></span><span id='topic+a.opt.c+2CREBMIX-method'></span><span id='topic+a.opt.IC+2CREBMIX-method'></span><span id='topic+a.opt.logL+2CREBMIX-method'></span><span id='topic+a.opt.Dmin+2CREBMIX-method'></span><span id='topic+a.opt.D+2CREBMIX-method'></span><span id='topic+a.all.K+2CREBMIX-method'></span><span id='topic+a.all.IC+2CREBMIX-method'></span><span id='topic+a.Dataset+2CREBMVNORM-method'></span><span id='topic+a.Preprocessing+2CREBMVNORM-method'></span><span id='topic+a.cmax+2CREBMVNORM-method'></span><span id='topic+a.cmin+2CREBMVNORM-method'></span><span id='topic+a.Criterion+2CREBMVNORM-method'></span><span id='topic+a.Variables+2CREBMVNORM-method'></span><span id='topic+a.pdf+2CREBMVNORM-method'></span><span id='topic+a.theta1+2CREBMVNORM-method'></span><span id='topic+a.theta2+2CREBMVNORM-method'></span><span id='topic+a.K+2CREBMVNORM-method'></span><span id='topic+a.ymin+2CREBMVNORM-method'></span><span id='topic+a.ymax+2CREBMVNORM-method'></span><span id='topic+a.ar+2CREBMVNORM-method'></span><span id='topic+a.Restraints+2CREBMVNORM-method'></span><span id='topic+a.Mode+2CREBMVNORM-method'></span><span id='topic+a.w+2CREBMVNORM-method'></span><span id='topic+a.Theta+2CREBMVNORM-method'></span><span id='topic+a.summary+2CREBMVNORM-method'></span><span id='topic+a.pos+2CREBMVNORM-method'></span><span id='topic+a.opt.c+2CREBMVNORM-method'></span><span id='topic+a.opt.IC+2CREBMVNORM-method'></span><span id='topic+a.opt.logL+2CREBMVNORM-method'></span><span id='topic+a.opt.Dmin+2CREBMVNORM-method'></span><span id='topic+a.opt.D+2CREBMVNORM-method'></span><span id='topic+a.all.K+2CREBMVNORM-method'></span><span id='topic+a.all.IC+2CREBMVNORM-method'></span><span id='topic+a.Bootstrap'></span><span id='topic+a.B'></span><span id='topic+a.replace'></span><span id='topic+a.prob'></span><span id='topic+a.c'></span><span id='topic+a.c.se'></span><span id='topic+a.c.cv'></span><span id='topic+a.c.mode'></span><span id='topic+a.c.prob'></span><span id='topic+a.w.se'></span><span id='topic+a.w.cv'></span><span id='topic+a.Theta.se'></span><span id='topic+a.Theta.cv'></span><span id='topic+a.rseed+2CREBMIX.boot-method'></span><span id='topic+a.pos+2CREBMIX.boot-method'></span><span id='topic+a.Bootstrap+2CREBMIX.boot-method'></span><span id='topic+a.B+2CREBMIX.boot-method'></span><span id='topic+a.n+2CREBMIX.boot-method'></span><span id='topic+a.replace+2CREBMIX.boot-method'></span><span id='topic+a.prob+2CREBMIX.boot-method'></span><span id='topic+a.c+2CREBMIX.boot-method'></span><span id='topic+a.c.se+2CREBMIX.boot-method'></span><span id='topic+a.c.cv+2CREBMIX.boot-method'></span><span id='topic+a.c.mode+2CREBMIX.boot-method'></span><span id='topic+a.c.prob+2CREBMIX.boot-method'></span><span id='topic+a.w+2CREBMIX.boot-method'></span><span id='topic+a.w.se+2CREBMIX.boot-method'></span><span id='topic+a.w.cv+2CREBMIX.boot-method'></span><span id='topic+a.Theta+2CREBMIX.boot-method'></span><span id='topic+a.Theta.se+2CREBMIX.boot-method'></span><span id='topic+a.Theta.cv+2CREBMIX.boot-method'></span><span id='topic+a.rseed+2CREBMVNORM.boot-method'></span><span id='topic+a.pos+2CREBMVNORM.boot-method'></span><span id='topic+a.Bootstrap+2CREBMVNORM.boot-method'></span><span id='topic+a.B+2CREBMVNORM.boot-method'></span><span id='topic+a.n+2CREBMVNORM.boot-method'></span><span id='topic+a.replace+2CREBMVNORM.boot-method'></span><span id='topic+a.prob+2CREBMVNORM.boot-method'></span><span id='topic+a.c+2CREBMVNORM.boot-method'></span><span id='topic+a.c.se+2CREBMVNORM.boot-method'></span><span id='topic+a.c.cv+2CREBMVNORM.boot-method'></span><span id='topic+a.c.mode+2CREBMVNORM.boot-method'></span><span id='topic+a.c.prob+2CREBMVNORM.boot-method'></span><span id='topic+a.w+2CREBMVNORM.boot-method'></span><span id='topic+a.w.se+2CREBMVNORM.boot-method'></span><span id='topic+a.w.cv+2CREBMVNORM.boot-method'></span><span id='topic+a.Theta+2CREBMVNORM.boot-method'></span><span id='topic+a.Theta.se+2CREBMVNORM.boot-method'></span><span id='topic+a.Theta.cv+2CREBMVNORM.boot-method'></span><span id='topic+a.Zp'></span><span id='topic+a.p'></span><span id='topic+a.pi'></span><span id='topic+a.P'></span><span id='topic+a.tau'></span><span id='topic+a.Rule'></span><span id='topic+a.from'></span><span id='topic+a.to'></span><span id='topic+a.EN'></span><span id='topic+a.ED'></span><span id='topic+a.Dataset+2CRCLRMIX-method'></span><span id='topic+a.pos+2CRCLRMIX-method'></span><span id='topic+a.Zt+2CRCLRMIX-method'></span><span id='topic+a.Zp+2CRCLRMIX-method'></span><span id='topic+a.c+2CRCLRMIX-method'></span><span id='topic+a.p+2CRCLRMIX-method'></span><span id='topic+a.pi+2CRCLRMIX-method'></span><span id='topic+a.P+2CRCLRMIX-method'></span><span id='topic+a.tau+2CRCLRMIX-method'></span><span id='topic+a.prob+2CRCLRMIX-method'></span><span id='topic+a.Rule+2CRCLRMIX-method'></span><span id='topic+a.from+2CRCLRMIX-method'></span><span id='topic+a.to+2CRCLRMIX-method'></span><span id='topic+a.EN+2CRCLRMIX-method'></span><span id='topic+a.ED+2CRCLRMIX-method'></span><span id='topic+a.Dataset+2CRCLRMVNORM-method'></span><span id='topic+a.pos+2CRCLRMVNORM-method'></span><span id='topic+a.Zt+2CRCLRMVNORM-method'></span><span id='topic+a.Zp+2CRCLRMVNORM-method'></span><span id='topic+a.c+2CRCLRMVNORM-method'></span><span id='topic+a.p+2CRCLRMVNORM-method'></span><span id='topic+a.pi+2CRCLRMVNORM-method'></span><span id='topic+a.P+2CRCLRMVNORM-method'></span><span id='topic+a.tau+2CRCLRMVNORM-method'></span><span id='topic+a.prob+2CRCLRMVNORM-method'></span><span id='topic+a.Rule+2CRCLRMVNORM-method'></span><span id='topic+a.from+2CRCLRMVNORM-method'></span><span id='topic+a.to+2CRCLRMVNORM-method'></span><span id='topic+a.EN+2CRCLRMVNORM-method'></span><span id='topic+a.ED+2CRCLRMVNORM-method'></span><span id='topic+a.levels'></span><span id='topic+a.train'></span><span id='topic+a.Zr'></span><span id='topic+a.test'></span><span id='topic+a.s+2CRCLS.chunk-method'></span><span id='topic+a.levels+2CRCLS.chunk-method'></span><span id='topic+a.ntrain+2CRCLS.chunk-method'></span><span id='topic+a.train+2CRCLS.chunk-method'></span><span id='topic+a.Zr+2CRCLS.chunk-method'></span><span id='topic+a.ntest+2CRCLS.chunk-method'></span><span id='topic+a.test+2CRCLS.chunk-method'></span><span id='topic+a.Zt+2CRCLS.chunk-method'></span><span id='topic+a.o'></span><span id='topic+a.s'></span><span id='topic+a.ntrain'></span><span id='topic+a.ntest'></span><span id='topic+a.CM'></span><span id='topic+a.Accuracy'></span><span id='topic+a.Error'></span><span id='topic+a.Precision'></span><span id='topic+a.Sensitivity'></span><span id='topic+a.Specificity'></span><span id='topic+a.Chunks'></span><span id='topic+a.o+2CRCLSMIX-method'></span><span id='topic+a.Dataset+2CRCLSMIX-method'></span><span id='topic+a.s+2CRCLSMIX-method'></span><span id='topic+a.ntrain+2CRCLSMIX-method'></span><span id='topic+a.P+2CRCLSMIX-method'></span><span id='topic+a.ntest+2CRCLSMIX-method'></span><span id='topic+a.Zt+2CRCLSMIX-method'></span><span id='topic+a.Zp+2CRCLSMIX-method'></span><span id='topic+a.CM+2CRCLSMIX-method'></span><span id='topic+a.Accuracy+2CRCLSMIX-method'></span><span id='topic+a.Error+2CRCLSMIX-method'></span><span id='topic+a.Precision+2CRCLSMIX-method'></span><span id='topic+a.Sensitivity+2CRCLSMIX-method'></span><span id='topic+a.Specificity+2CRCLSMIX-method'></span><span id='topic+a.Chunks+2CRCLSMIX-method'></span><span id='topic+a.o+2CRCLSMVNORM-method'></span><span id='topic+a.Dataset+2CRCLSMVNORM-method'></span><span id='topic+a.s+2CRCLSMVNORM-method'></span><span id='topic+a.ntrain+2CRCLSMVNORM-method'></span><span id='topic+a.P+2CRCLSMVNORM-method'></span><span id='topic+a.ntest+2CRCLSMVNORM-method'></span><span id='topic+a.Zt+2CRCLSMVNORM-method'></span><span id='topic+a.Zp+2CRCLSMVNORM-method'></span><span id='topic+a.CM+2CRCLSMVNORM-method'></span><span id='topic+a.Accuracy+2CRCLSMVNORM-method'></span><span id='topic+a.Error+2CRCLSMVNORM-method'></span><span id='topic+a.Precision+2CRCLSMVNORM-method'></span><span id='topic+a.Sensitivity+2CRCLSMVNORM-method'></span><span id='topic+a.Specificity+2CRCLSMVNORM-method'></span><span id='topic+a.Chunks+2CRCLSMVNORM-method'></span><span id='topic+a.strategy'></span><span id='topic+a.variant'></span><span id='topic+a.acceleration'></span><span id='topic+a.tolerance'></span><span id='topic+a.acceleration.multiplier'></span><span id='topic+a.maximum.iterations'></span><span id='topic+a.eliminate.zero.components'></span><span id='topic+a.strategy+2CEM.Control-method'></span><span id='topic+a.variant+2CEM.Control-method'></span><span id='topic+a.acceleration+2CEM.Control-method'></span><span id='topic+a.tolerance+2CEM.Control-method'></span><span id='topic+a.acceleration.multiplier+2CEM.Control-method'></span><span id='topic+a.maximum.iterations+2CEM.Control-method'></span><span id='topic+a.eliminate.zero.components+2CEM.Control-method'></span><span id='topic+a.K+2CEM.Control-method'></span><span id='topic+a.strategy+3C-'></span><span id='topic+a.variant+3C-'></span><span id='topic+a.acceleration+3C-'></span><span id='topic+a.tolerance+3C-'></span><span id='topic+a.acceleration.multiplier+3C-'></span><span id='topic+a.maximum.iterations+3C-'></span><span id='topic+a.eliminate.zero.components+3C-'></span><span id='topic+a.K+3C-'></span><span id='topic+a.strategy+3C-+2CEM.Control-method'></span><span id='topic+a.variant+3C-+2CEM.Control-method'></span><span id='topic+a.acceleration+3C-+2CEM.Control-method'></span><span id='topic+a.tolerance+3C-+2CEM.Control-method'></span><span id='topic+a.acceleration.multiplier+3C-+2CEM.Control-method'></span><span id='topic+a.maximum.iterations+3C-+2CEM.Control-method'></span><span id='topic+a.eliminate.zero.components+3C-+2CEM.Control-method'></span><span id='topic+a.K+3C-+2CEM.Control-method'></span><span id='topic+a.summary.EM'></span><span id='topic+a.summary.EM+2CREBMIX-method'></span><span id='topic+a.summary.EM+2CREBMVNORM-method'></span><span id='topic+a.w+2CEMMIX.Theta-method'></span><span id='topic+a.w+2CEMMVNORM.Theta-method'></span><span id='topic+a.w+3C-'></span><span id='topic+a.w+3C-+2CEMMIX.Theta-method'></span><span id='topic+a.w+3C-+2CEMMVNORM.Theta-method'></span><span id='topic+a.Y'></span><span id='topic+a.Y+3C-'></span><span id='topic+a.h'></span><span id='topic+a.ns'></span><span id='topic+a.Y+2CHistogram-method'></span><span id='topic+a.Y+3C-+2CHistogram-method'></span><span id='topic+a.K+2CHistogram-method'></span><span id='topic+a.ymin+2CHistogram-method'></span><span id='topic+a.ymax+2CHistogram-method'></span><span id='topic+a.y0+2CHistogram-method'></span><span id='topic+a.h+2CHistogram-method'></span><span id='topic+a.n+2CHistogram-method'></span><span id='topic+a.ns+2CHistogram-method'></span>

<h3>Description</h3>

<p>Internal rebmix functions, methods and classes.
</p>


<h3>Details</h3>

<p>These are not to be called by the user.
</p>

<hr>
<h2 id='REBMIX-methods'>
REBMIX Algorithm for Univariate or Multivariate Finite Mixture Estimation
</h2><span id='topic+REBMIX'></span><span id='topic+REBMIX-methods'></span><span id='topic+REBMIX+2CREBMIX-method'></span><span id='topic+REBMIX+2CREBMVNORM-method'></span><span id='topic+show+2CREBMIX-method'></span><span id='topic+show+2CREBMVNORM-method'></span><span id='topic+summary+2CREBMIX-method'></span><span id='topic+summary+2CREBMVNORM-method'></span>

<h3>Description</h3>

<p>Returns as default the REBMIX algorithm output for mixtures of conditionally independent normal, lognormal, Weibull, gamma, Gumbel, binomial, Poisson, Dirac, uniform or von Mises component densities. If <code>model</code> equals <code>"REBMVNORM"</code> output for mixtures of multivariate normal component densities with unrestricted variance-covariance matrices is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'REBMIX'
REBMIX(model = "REBMIX", Dataset = list(), Preprocessing = character(),
       cmax = 15, cmin = 1, Criterion = "AIC", pdf = character(), 
       theta1 = numeric(), theta2 = numeric(), theta3 = numeric(), K = "auto", 
       ymin = numeric(), ymax = numeric(), ar = 0.1, 
       Restraints = "loose", Mode = "outliersplus", EMcontrol = NULL, ...)
## ... and for other signatures
## S4 method for signature 'REBMIX'
summary(object, ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="REBMIX-methods_+3A_model">model</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="REBMIX-methods_+3A_dataset">Dataset</code></td>
<td>

<p>a list of length <code class="reqn">n_{\mathrm{D}}</code> of data frames or objects of class <code>Histogram</code>. 
Data frames should have size <code class="reqn">n \times d</code> containing <em>d</em>-dimensional datasets. Each of the <code class="reqn">d</code>
columns represents one random variable. Numbers of observations <code class="reqn">n</code> equal the number of rows in the datasets.
</p>
</td></tr>
<tr><td><code id="REBMIX-methods_+3A_preprocessing">Preprocessing</code></td>
<td>

<p>a character giving the preprocessing type. One of <code>"histogram"</code>, <br />
<code>"kernel density estimation"</code> or <code>"k-nearest neighbour"</code>.
</p>
</td></tr>
<tr><td><code id="REBMIX-methods_+3A_cmax">cmax</code></td>
<td>

<p>maximum number of components <code class="reqn">c_{\mathrm{max}} &gt; 0</code>. The default value is <code>15</code>.
</p>
</td></tr>
<tr><td><code id="REBMIX-methods_+3A_cmin">cmin</code></td>
<td>

<p>minimum number of components <code class="reqn">c_{\mathrm{min}} &gt; 0</code>. The default value is <code>1</code>. If <code class="reqn">c_{\mathrm{min}} &gt; 1</code>, it may happen that no solution is found,
and an error is returned by the method.
</p>
</td></tr>
<tr><td><code id="REBMIX-methods_+3A_criterion">Criterion</code></td>
<td>

<p>a character giving the information criterion type. One of default Akaike <code>"AIC"</code>, <code>"AIC3"</code>, <code>"AIC4"</code> or <code>"AICc"</code>,
Bayesian <code>"BIC"</code>, consistent Akaike <code>"CAIC"</code>, Hannan-Quinn <code>"HQC"</code>, minimum description length <code>"MDL2"</code> or <code>"MDL5"</code>,
approximate weight of evidence <code>"AWE"</code>, classification likelihood <code>"CLC"</code>,
integrated classification likelihood <code>"ICL"</code> or <code>"ICL-BIC"</code>, partition coefficient <code>"PC"</code>,
total of positive relative deviations <code>"D"</code> or sum of squares error <code>"SSE"</code>.
</p>
</td></tr>
<tr><td><code id="REBMIX-methods_+3A_pdf">pdf</code></td>
<td>

<p>a character vector of length <code class="reqn">d</code> containing continuous or discrete parametric family types. One of <code>"normal"</code>, <code>"lognormal"</code>, <code>"Weibull"</code>, <code>"gamma"</code>, <code>"Gumbel"</code>, <code>"binomial"</code>, <code>"Poisson"</code>, <code>"Dirac"</code>, <code>"uniform"</code> or <code>"vonMises"</code>.
</p>
</td></tr>
<tr><td><code id="REBMIX-methods_+3A_theta1">theta1</code></td>
<td>

<p>a vector of length <code class="reqn">d</code> containing initial component parameters. One of <code class="reqn">n_{il} = \textrm{number of categories} - 1</code> for <code>"binomial"</code> distribution.
</p>
</td></tr>
<tr><td><code id="REBMIX-methods_+3A_theta2">theta2</code></td>
<td>

<p>a vector of length <code class="reqn">d</code> containing initial component parameters. Currently not used.
</p>
</td></tr>
<tr><td><code id="REBMIX-methods_+3A_theta3">theta3</code></td>
<td>

<p>a vector of length <code class="reqn">d</code> containing initial component parameters. One of <code class="reqn">\xi_{il} \in \{-1, \textrm{NA}, 1\}</code> for <code>"Gumbel"</code> distribution.
</p>
</td></tr>
<tr><td><code id="REBMIX-methods_+3A_k">K</code></td>
<td>

<p>a character or a vector or a matrix of size <code class="reqn">n_{\mathrm{D}} \times d</code> containing numbers of bins <code class="reqn">v</code> or <code class="reqn">v_{1}, \ldots, v_{d}</code> for the histogram and the kernel density estimation or numbers of nearest
neighbours <code class="reqn">k</code> for the <em>k</em>-nearest neighbour. There is no genuine rule to identify <code class="reqn">v</code> or <code class="reqn">k</code>. Consequently,
the REBMIX algorithm identifies them from the set <code>K</code> of input values by
minimizing the information criterion. The Sturges rule <code class="reqn">v = 1 + \mathrm{log_{2}}(n)</code>, <code class="reqn">\mathrm{Log}_{10}</code> rule <code class="reqn">v = 10 \mathrm{log_{10}}(n)</code> or RootN
rule <code class="reqn">v = 2 \sqrt{n}</code> can be applied to estimate the limiting numbers of bins
or the rule of thumb <code class="reqn">k = \sqrt{n}</code> to guess the intermediate number of nearest neighbours. If, e.g., <code>K = c(10, 20, 40, 60)</code> and minimum <code>IC</code> coincides, e.g., <code>40</code>, brackets are set to <code>20</code> and <code>60</code> and the golden section is applied to refine the minimum search. 
If, e.g., <code>K = matrix(c(10, 15, 18, 5, 7, 9), byrow = TRUE, ncol = 3)</code> than <code class="reqn">d = 3</code> and the list <code>Dataset</code> contains <code class="reqn">n_{\mathrm{D}} = 2</code> frames. Hence, different numbers of bins can be assigned to <code class="reqn">y_{1}, \ldots, y_{d}</code>.
See also <code><a href="#topic+kseq">kseq</a></code> for sequence of bins or nearest neighbours generation. The default value is <code>"auto"</code>.
</p>
</td></tr>
<tr><td><code id="REBMIX-methods_+3A_ymin">ymin</code></td>
<td>

<p>a vector of length <code class="reqn">d</code> containing minimum observations. The default value is <code>numeric()</code>.
</p>
</td></tr>
<tr><td><code id="REBMIX-methods_+3A_ymax">ymax</code></td>
<td>

<p>a vector of length <code class="reqn">d</code> containing maximum observations. The default value is <code>numeric()</code>.
</p>
</td></tr>
<tr><td><code id="REBMIX-methods_+3A_ar">ar</code></td>
<td>

<p>acceleration rate <code class="reqn">0 &lt; a_{\mathrm{r}} \leq 1</code>. The default value is <code>0.1</code> and in most cases does not have to be altered.
</p>
</td></tr>
<tr><td><code id="REBMIX-methods_+3A_restraints">Restraints</code></td>
<td>

<p>a character giving the restraints type. One of <code>"rigid"</code> or default <code>"loose"</code>.
The rigid restraints are obsolete and applicable for well separated components only.
</p>
</td></tr>
<tr><td><code id="REBMIX-methods_+3A_mode">Mode</code></td>
<td>

<p>a character giving the mode type. One of <code>"all"</code>, <code>"outliers"</code> or default <code>"outliersplus"</code>. The modes are determined in decreasing order of magnitude from all observations if <code>Mode = "all"</code>.
If <code>Mode = "outliers"</code>, the modes are determined in decreasing order of magnitude from outliers only. In the meantime, some outliers are reclassified as inliers. Finally, when all observations are inliers, the procedure is completed.
If <code>Mode = "outliersplus"</code>, the modes are determined in decreasing magnitude from the outliers only. In the meantime, some outliers are reclassified as inliers. Finally, if all observations are inliers, they are converted to outliers and the mode determination procedure is continued.
</p>
</td></tr>
<tr><td><code id="REBMIX-methods_+3A_emcontrol">EMcontrol</code></td>
<td>

<p>an object of class <code>EM.Control</code>.
</p>
</td></tr>
<tr><td><code id="REBMIX-methods_+3A_object">object</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="REBMIX-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>REBMIX</code> or <code>REBMVNORM</code>.
</p>


<h3>Methods</h3>


<dl>
<dt><code>signature(model = "REBMIX")</code></dt><dd><p>a character giving the default class name <code>"REBMIX"</code> for mixtures of conditionally independent normal, lognormal, Weibull, gamma, Gumbel, binomial, Poisson, Dirac, uniform or von Mises component densities.</p>
</dd>
<dt><code>signature(model = "REBMVNORM")</code></dt><dd><p>a character giving the class name <code>"REBMVNORM"</code> for mixtures of multivariate normal component densities with unrestricted variance-covariance matrices.</p>
</dd>
<dt><code>signature(object = "REBMIX")</code></dt><dd><p>an object of class <code>REBMIX</code>.</p>
</dd>
<dt><code>signature(object = "REBMVNORM")</code></dt><dd><p>an object of class <code>REBMVNORM</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>H. A. Sturges. The choice of a class interval. Journal of American Statistical Association, 21(153):
65-66, 1926. https://www.jstor.org/stable/2965501.<br /><br />
P. F. Velleman. Interactive computing for exploratory data analysis I: display algorithms. Proceedings of the Statistical Computing Section,
American Statistical Association, 1976.<br /><br />
W. J. Dixon and R. A. Kronmal. The Choice of origin and scale for graphs. Journal of the ACM, 12(2):
259-261, 1965. <a href="https://doi.org/10.1145/321264.321277">doi:10.1145/321264.321277</a>.<br /><br />
M. Nagode and M. Fajdiga. A general multi-modal probability density function suitable for the
rainflow ranges of stationary random processes. International Journal of Fatigue, 20(3):211-223,
1998. <a href="https://doi.org/10.1016/S0142-1123%2897%2900106-0">doi:10.1016/S0142-1123(97)00106-0</a>.<br /><br />
M. Nagode and M. Fajdiga. An improved algorithm for parameter estimation suitable for mixed
weibull distributions. International Journal of Fatigue, 22(1):75-80, 2000. <a href="https://doi.org/10.1016/S0142-1123%2899%2900112-7">doi:10.1016/S0142-1123(99)00112-7</a>.<br /><br />
M. Nagode, J. Klemenc and M. Fajdiga. Parametric modelling and scatter prediction of rainflow
matrices. International Journal of Fatigue, 23(6):525-532, 2001. <a href="https://doi.org/10.1016/S0142-1123%2801%2900007-X">doi:10.1016/S0142-1123(01)00007-X</a>.<br /><br />
M. Nagode and M. Fajdiga. An alternative perspective on the mixture estimation problem. Reliability
Engineering &amp; System Safety, 91(4):388-397, 2006. <a href="https://doi.org/10.1016/j.ress.2005.02.005">doi:10.1016/j.ress.2005.02.005</a>.<br /><br />
M. Nagode and M. Fajdiga. The rebmix algorithm for the univariate finite mixture estimation.
Communications in Statistics - Theory and Methods, 40(5):876-892, 2011a. <a href="https://doi.org/10.1080/03610920903480890">doi:10.1080/03610920903480890</a>.<br /><br />
M. Nagode and M. Fajdiga. The rebmix algorithm for the multivariate finite mixture estimation.
Communications in Statistics - Theory and Methods, 40(11):2022-2034, 2011b. <a href="https://doi.org/10.1080/03610921003725788">doi:10.1080/03610921003725788</a>.<br /><br />
M. Nagode. Finite mixture modeling via REBMIX.
Journal of Algorithms and Optimization, 3(2):14-28, 2015. <a href="https://repozitorij.uni-lj.si/Dokument.php?id=127674&amp;lang=eng">https://repozitorij.uni-lj.si/Dokument.php?id=127674&amp;lang=eng</a>.<br /><br />
B. Panic, J. Klemenc, M. Nagode. Improved initialization of the EM algorithm for mixture model parameter estimation.
Mathematics, 8(3):373, 2020.
<a href="https://doi.org/10.3390/math8030373">doi:10.3390/math8030373</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate and plot univariate normal dataset.

n &lt;- c(998, 263, 1086, 487)

Theta &lt;- new("RNGMIX.Theta", c = 4, pdf = "normal")

a.theta1(Theta) &lt;- c(688, 265, 30, 934)
a.theta2(Theta) &lt;- c(72, 54, 34, 28)

normal &lt;- RNGMIX(Dataset.name = "complex1",
  rseed = -1,
  n = n,
  Theta = a.Theta(Theta))

normal

a.Dataset(normal, 1)[1:20,]

# Estimate number of components, component weights and component parameters.

normalest &lt;- REBMIX(Dataset = a.Dataset(normal),
  Preprocessing = "h",
  cmax = 8,
  Criterion = "BIC",
  pdf = "n")

normalest

BIC(normalest)

logL(normalest)

# Plot finite mixture.

plot(normalest, nrow = 2, what = c("pdf", "marginal cdf"), npts = 1000)

# EM algorithm utilization

# Load iris data.

data(iris)

Dataset &lt;- list(data.frame(iris[, c(1:4)]))

# Create EM.Control object.

EM &lt;- new("EM.Control", 
  strategy = "exhaustive", 
  variant = "EM", 
  acceleration = "fixed", 
  tolerance = 1e-4, 
  acceleration.multiplier = 1.0, 
  maximum.iterations = 1000)

# Mixture parameter estimation using REBMIX and EM algorithm.

irisest &lt;- REBMIX(model = "REBMVNORM", 
  Dataset = Dataset, 
  Preprocessing = "histogram",
  cmax = 10,
  Criterion = "BIC",
  EMcontrol = EM)

irisest

# Print total number of EM iterations used in Ehxaustive strategy from summary.EM slot.

a.summary.EM(irisest, col.name = "total.iterations.nbr", pos = 1)
</code></pre>

<hr>
<h2 id='REBMIX.boot-class'>Class <code>"REBMIX.boot"</code></h2><span id='topic+REBMIX.boot-class'></span><span id='topic+REBMVNORM.boot-class'></span>

<h3>Description</h3>

<p>Object of class <code>REBMIX.boot</code>.</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>new("REBMIX.boot", ...)</code>. Accessor methods for the slots are <code>a.rseed(x = NULL)</code>,
<code>a.pos(x = NULL)</code>, <code>a.Bootstrap(x = NULL)</code>, <code>a.B(x = NULL)</code>, <code>a.n(x = NULL)</code>, <code>a.replace(x = NULL)</code>, <code>a.prob(x = NULL)</code>,
<code>a.c(x = NULL)</code>, <code>a.c.se(x = NULL)</code>, <code>a.c.cv(x = NULL)</code>, <code>a.c.mode(x = NULL)</code>, <code>a.c.prob(x = NULL)</code>, <code>a.w(x = NULL)</code>,
<code>a.w.se(x = NULL)</code>, <code>a.w.cv(x = NULL)</code>, <code>a.Theta(x = NULL)</code>, <code>a.Theta.se(x = NULL)</code> and <code>a.Theta.cv(x = NULL)</code>, where <code>x</code> stands for an object of class <code>REBMIX.boot</code>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>x</code>:</dt><dd>
<p>an object of class <code>REBMIX</code>.
</p>
</dd>
<dt><code>rseed</code>:</dt><dd>
<p>set the random seed to any negative integer value to initialize the sequence. The first bootstrap dataset corresponds to it.
For each next bootstrap dataset the random seed is decremented <code class="reqn">r_{\mathrm{seed}} = r_{\mathrm{seed}} - 1</code>. The default value is <code>-1</code>.
</p>
</dd>
<dt><code>pos</code>:</dt><dd>
<p>a desired row number in <code>x@summary</code> to be bootstrapped. The default value is <code>1</code>.
</p>
</dd>
<dt><code>Bootstrap</code>:</dt><dd>
<p>a character giving the bootstrap type. One of default <code>"parametric"</code> or <code>"nonparametric"</code>.
</p>
</dd>
<dt><code>B</code>:</dt><dd>
<p>number of bootstrap datasets. The default value is <code>100</code>.
</p>
</dd>
<dt><code>n</code>:</dt><dd>
<p>number of observations. The default value is <code>numeric()</code>.
</p>
</dd>
<dt><code>replace</code>:</dt><dd>
<p>logical. The sampling is with replacement if <code>TRUE</code>, see also <code><a href="base.html#topic+sample">sample</a></code>. The default value is <code>TRUE</code>.
</p>
</dd>
<dt><code>prob</code>:</dt><dd>
<p>a vector of length <code class="reqn">n</code> containing probability weights, see also <code><a href="base.html#topic+sample">sample</a></code>. The default value is <code>numeric()</code>.
</p>
</dd>
<dt><code>c</code>:</dt><dd>
<p>a vector containing numbers of components for <code class="reqn">B</code> bootstrap datasets.
</p>
</dd>
<dt><code>c.se</code>:</dt><dd>
<p>standard error of numbers of components <code>c</code>.
</p>
</dd>
<dt><code>c.cv</code>:</dt><dd>
<p>coefficient of variation of numbers of components <code>c</code>.
</p>
</dd>
<dt><code>c.mode</code>:</dt><dd>
<p>mode of numbers of components <code>c</code>.
</p>
</dd>
<dt><code>c.prob</code>:</dt><dd>
<p>probability of mode <code>c.mode</code>.
</p>
</dd>
<dt><code>w</code>:</dt><dd>
<p>a matrix containing component weights for <code class="reqn">\leq B</code> bootstrap datasets.
</p>
</dd>
<dt><code>w.se</code>:</dt><dd>
<p>a vector containing standard errors of component weights <code>w</code>.
</p>
</dd>
<dt><code>w.cv</code>:</dt><dd>
<p>a vector containing coefficients of variation of component weights <code>w</code>.
</p>
</dd>
<dt><code>Theta</code>:</dt><dd>
<p>a list of matrices containing component parameters <code>theta1.l</code>, <code>theta2.l</code> and <code>theta3.l</code> for <code class="reqn">\leq B</code> bootstrap datasets.
</p>
</dd>
<dt><code>Theta.se</code>:</dt><dd>
<p>a list of vectors containing standard errors of component parameters <code>theta1.l</code>, <code>theta2.l</code> and <code>theta3.l</code>.
</p>
</dd>
<dt><code>Theta.cv</code>:</dt><dd>
<p>a list of vectors containing coefficients of variation of component parameters <code>theta1.l</code>, <code>theta2.l</code> and <code>theta3.l</code>.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>

<hr>
<h2 id='RNGMIX-class'>Class <code>"RNGMIX"</code></h2><span id='topic+RNGMIX-class'></span><span id='topic+RNGMVNORM-class'></span>

<h3>Description</h3>

<p>Object of class <code>RNGMIX</code>.</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>new("RNGMIX", ...)</code>. Accessor methods for the slots are <code>a.Dataset.name(x = NULL)</code>,
<code>a.rseed(x = NULL)</code>, <code>a.n(x = NULL)</code>, <code>a.Theta(x = NULL)</code>, <code>a.Dataset(x = NULL, pos = 0)</code>,
<code>a.Zt(x = NULL)</code>, <code>a.w(x = NULL)</code>, <code>a.Variables(x = NULL)</code>, <code>a.ymin(x = NULL)</code> and <code>a.ymax(x = NULL)</code>,
where <code>x</code> and <code>pos</code> stand for an object of class <code>RNGMIX</code> and a desired slot item, respectively.
</p>


<h3>Slots</h3>


<dl>
<dt><code>Dataset.name</code>:</dt><dd>
<p>a character vector containing list names of data frames of size <code class="reqn">n \times d</code> that <em>d</em>-dimensional datasets are written in.
</p>
</dd>
<dt><code>rseed</code>:</dt><dd>
<p>set the random seed to any negative integer value to initialize the sequence. The first file in <code>Dataset.name</code> corresponds to it.
For each next file the random seed is decremented <code class="reqn">r_{\mathrm{seed}} = r_{\mathrm{seed}} - 1</code>. The default value is <code>-1</code>.
</p>
</dd>
<dt><code>n</code>:</dt><dd>
<p>a vector containing numbers of observations in classes <code class="reqn">n_{l}</code>, where number of observations <code class="reqn">n = \sum_{l = 1}^{c} n_{l}</code>.
</p>
</dd>
<dt><code>Theta</code>:</dt><dd>
<p>a list containing <code class="reqn">c</code> parametric family types <code>pdfl</code>. One of <code>"normal"</code>, <code>"lognormal"</code>, <code>"Weibull"</code>, <code>"gamma"</code>, <code>"Gumbel"</code>, <code>"binomial"</code>, <code>"Poisson"</code>, <code>"Dirac"</code>, <code>"uniform"</code> or circular <code>"vonMises"</code> defined for <code class="reqn">0 \leq y_{i} \leq 2 \pi</code>.
Component parameters <code>theta1.l</code> follow the parametric family types. One of <code class="reqn">\mu_{il}</code> for normal, lognormal, Gumbel and von Mises distributions, <code class="reqn">\theta_{il}</code> for Weibull, gamma, binomial, Poisson and Dirac distributions and <code class="reqn">a</code> for uniform distribution.
Component parameters <code>theta2.l</code> follow <code>theta1.l</code>. One of <code class="reqn">\sigma_{il}</code> for normal, lognormal and Gumbel distributions, <code class="reqn">\beta_{il}</code> for Weibull and gamma distributions, <code class="reqn">p_{il}</code> for binomial distribution, <code class="reqn">\kappa_{il}</code> for von Mises distribution and <code class="reqn">b</code> for uniform distribution.
Component parameters <code>theta3.l</code> follow <code>theta2.l</code>. One of <code class="reqn">\xi_{il} \in \{-1, 1\}</code> for Gumbel distribution.
</p>
</dd>
<dt><code>Dataset</code>:</dt><dd>
<p>a list of length <code class="reqn">n_{\mathrm{D}}</code> of data frames of size <code class="reqn">n \times d</code> containing <em>d</em>-dimensional datasets. Each of the <code class="reqn">d</code> columns represents one random variable. Numbers of observations <code class="reqn">n</code> equal the number of rows
in the datasets.
</p>
</dd>
<dt><code>Zt</code>:</dt><dd>
<p>a factor of true cluster membership.
</p>
</dd>
<dt><code>w</code>:</dt><dd>
<p>a vector of length <code class="reqn">c</code> containing component weights <code class="reqn">w_{l}</code> summing to 1.
</p>
</dd>
<dt><code>Variables</code>:</dt><dd>
<p>a character vector containing types of variables. One of <code>"continuous"</code> or <code>"discrete"</code>.
</p>
</dd>
<dt><code>ymin</code>:</dt><dd>
<p>a vector of length <code class="reqn">d</code> containing minimum observations.
</p>
</dd>
<dt><code>ymax</code>:</dt><dd>
<p>a vector of length <code class="reqn">d</code> containing maximum observations.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>

<hr>
<h2 id='RNGMIX-methods'>
Random Univariate or Multivariate Finite Mixture Generation
</h2><span id='topic+RNGMIX'></span><span id='topic+RNGMIX-methods'></span><span id='topic+RNGMIX+2CRNGMIX-method'></span><span id='topic+RNGMIX+2CRNGMVNORM-method'></span><span id='topic+show+2CRNGMIX-method'></span><span id='topic+show+2CRNGMVNORM-method'></span>

<h3>Description</h3>

<p>Returns as default the RNGMIX univariate or multivariate random datasets for mixtures of conditionally independent normal, lognormal, Weibull, gamma, Gumbel, binomial, Poisson, Dirac, uniform or von Mises component densities.
If <code>model</code> equals <code>"RNGMVNORM"</code> multivariate random datasets for mixtures of multivariate normal component densities with unrestricted variance-covariance matrices are returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'RNGMIX'
RNGMIX(model = "RNGMIX", Dataset.name = character(),
       rseed = -1, n = numeric(), Theta = list(), ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RNGMIX-methods_+3A_model">model</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="RNGMIX-methods_+3A_dataset.name">Dataset.name</code></td>
<td>

<p>a character vector containing list names of data frames of size <code class="reqn">n \times d</code> that <em>d</em>-dimensional datasets are written in.
</p>
</td></tr>
<tr><td><code id="RNGMIX-methods_+3A_rseed">rseed</code></td>
<td>

<p>set the random seed to any negative integer value to initialize the sequence. The first file in <code>Dataset.name</code> corresponds to it.
For each next file the random seed is decremented <code class="reqn">r_{\mathrm{seed}} = r_{\mathrm{seed}} - 1</code>. The default value is <code>-1</code>.
</p>
</td></tr>
<tr><td><code id="RNGMIX-methods_+3A_n">n</code></td>
<td>

<p>a vector containing numbers of observations in classes <code class="reqn">n_{l}</code>, where number of observations <code class="reqn">n = \sum_{l = 1}^{c} n_{l}</code>.
</p>
</td></tr>
<tr><td><code id="RNGMIX-methods_+3A_theta">Theta</code></td>
<td>

<p>a list containing <code class="reqn">c</code> parametric family types <code>pdfl</code>. One of <code>"normal"</code>, <code>"lognormal"</code>, <code>"Weibull"</code>, <code>"gamma"</code>, <code>"Gumbel"</code>, <code>"binomial"</code>, <code>"Poisson"</code>, <code>"Dirac"</code>, <code>"uniform"</code> or circular <code>"vonMises"</code> defined for <code class="reqn">0 \leq y_{i} \leq 2 \pi</code>.
Component parameters <code>theta1.l</code> follow the parametric family types. One of <code class="reqn">\mu_{il}</code> for normal, lognormal, Gumbel and von Mises distributions, <code class="reqn">\theta_{il}</code> for Weibull, gamma, binomial, Poisson and Dirac distributions and <code class="reqn">a</code> for uniform distribution.
Component parameters <code>theta2.l</code> follow <code>theta1.l</code>. One of <code class="reqn">\sigma_{il}</code> for normal, lognormal and Gumbel distributions, <code class="reqn">\beta_{il}</code> for Weibull and gamma distributions, <code class="reqn">p_{il}</code> for binomial distribution, <code class="reqn">\kappa_{il}</code> for von Mises distribution and <code class="reqn">b</code> for uniform distribution.
Component parameters <code>theta3.l</code> follow <code>theta2.l</code>. One of <code class="reqn">\xi_{il} \in \{-1, 1\}</code> for Gumbel distribution.
</p>
</td></tr>
<tr><td><code id="RNGMIX-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>RNGMIX is based on the &quot;Minimal&quot; random number generator <code>ran1</code> of Park and Miller with the Bays-Durham shuffle and added safeguards that returns a uniform random deviate between 0.0 and 1.0
(exclusive of the endpoint values).
</p>


<h3>Value</h3>

<p>Returns an object of class <code>RNGMIX</code> or <code>RNGMVNORM</code>.
</p>


<h3>Methods</h3>


<dl>
<dt><code>signature(model = "RNGMIX")</code></dt><dd><p>a character giving the default class name <code>"RNGMIX"</code> for mixtures of conditionally independent normal, lognormal, Weibull, gamma, Gumbel, binomial, Poisson, Dirac, uniform or von Mises component densities.</p>
</dd>
<dt><code>signature(model = "RNGMVNORM")</code></dt><dd><p>a character giving the class name <code>"RNGMVNORM"</code> for mixtures of multivariate normal component densities with unrestricted variance-covariance matrices.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>W. H. Press, S. A. Teukolsky, W. T. Vetterling and B. P. Flannery. Numerical Recipes in C: The Art
of Scientific Computing. Cambridge University Press, Cambridge, 1992.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>devAskNewPage(ask = TRUE)

# Generate and print multivariate normal datasets with diagonal
# variance-covariance matrices.

n &lt;- c(75, 100, 125, 150, 175)

Theta &lt;- new("RNGMIX.Theta", c = 5, pdf = rep("normal", 4))

a.theta1(Theta, 1) &lt;- c(10, 12, 10, 12)
a.theta1(Theta, 2) &lt;- c(8.5, 10.5, 8.5, 10.5)
a.theta1(Theta, 3) &lt;- c(12, 14, 12, 14)
a.theta1(Theta, 4) &lt;- c(13, 15, 7, 9)
a.theta1(Theta, 5) &lt;- c(7, 9, 13, 15)
a.theta2(Theta, 1) &lt;- c(1, 1, 1, 1)
a.theta2(Theta, 2) &lt;- c(1, 1, 1, 1)
a.theta2(Theta, 3) &lt;- c(1, 1, 1, 1)
a.theta2(Theta, 4) &lt;- c(2, 2, 2, 2)
a.theta2(Theta, 5) &lt;- c(3, 3, 3, 3)

simulated &lt;- RNGMIX(Dataset.name = paste("simulated_", 1:25, sep = ""),
  rseed = -1,
  n = n,
  Theta = a.Theta(Theta))

simulated

plot(simulated, pos = 22, nrow = 2, ncol = 3)

# Generate and print multivariate normal datasets with unrestricted
# variance-covariance matrices.

n &lt;- c(200, 50, 50)

Theta &lt;- new("RNGMVNORM.Theta", c = 3, d = 3)

a.theta1(Theta, 1) &lt;- c(0, 0, 0)
a.theta1(Theta, 2) &lt;- c(-6, 3, 6)
a.theta1(Theta, 3) &lt;- c(6, 6, 4)
a.theta2(Theta, 1) &lt;- c(9, 0, 0, 0, 4, 0, 0, 0, 1)
a.theta2(Theta, 2) &lt;- c(4, -3.2, -0.2, -3.2, 4, 0, -0.2, 0, 1)
a.theta2(Theta, 3) &lt;- c(4, 3.2, 2.8, 3.2, 4, 2.4, 2.8, 2.4, 2)

simulated &lt;- RNGMIX(model = "RNGMVNORM",
  Dataset.name = paste("simulated_", 1:2, sep = ""),
  rseed = -1,
  n = n,
  Theta = a.Theta(Theta))

simulated

plot(simulated, pos = 2, nrow = 3, ncol = 1)

# Generate and print multivariate mixed continuous-discrete datasets.

n &lt;- c(400, 100, 500)

Theta &lt;- new("RNGMIX.Theta", c = 3, pdf = c("lognormal", "Poisson", "binomial", "Weibull"))

a.theta1(Theta, 1) &lt;- c(1, 2, 10, 2)
a.theta1(Theta, 2) &lt;- c(3.5, 10, 10, 10)
a.theta1(Theta, 3) &lt;- c(2.5, 15, 10, 25)
a.theta2(Theta, 1) &lt;- c(0.3, NA, 0.9, 3)
a.theta2(Theta, 2) &lt;- c(0.2, NA, 0.1, 7)
a.theta2(Theta, 3) &lt;- c(0.4, NA, 0.7, 20)

simulated &lt;- RNGMIX(Dataset.name = paste("simulated_", 1:5, sep = ""),
  rseed = -1,
  n = n,
  Theta = a.Theta(Theta))

simulated

plot(simulated, pos = 4, nrow = 2, ncol = 3)

# Generate and print univariate mixed Weibull dataset.

n &lt;- c(75, 100, 125, 150, 175)

Theta &lt;- new("RNGMIX.Theta", c = 5, pdf = "Weibull")

a.theta1(Theta) &lt;- c(12, 10, 14, 15, 9)
a.theta2(Theta) &lt;- c(2, 4.1, 3.2, 7.1, 5.3)

simulated &lt;- RNGMIX(Dataset.name = "simulated",
  rseed = -1,
  n = n,
  Theta = a.Theta(Theta))

simulated

plot(simulated, pos = 1)

# Generate and print multivariate normal datasets with unrestricted
# variance-covariance matrices.

# Set dimension, dataset size, number of components and seed.

d &lt;- 2; n &lt;- 1000; c &lt;- 10; set.seed(123)

# Component weights are generated.

w &lt;- runif(c, 0.1, 0.9); w &lt;- w / sum(w)

# Set range of means and rang of eigenvalues.

mu &lt;- c(-100, 100); lambda &lt;- c(1, 100)

# Component means and variance-covariance matrices are calculated.

Mu &lt;- list(); Sigma &lt;- list()

for (l in 1:c) {
  Mu[[l]] &lt;- runif(d, mu[1], mu[2])
  Lambda &lt;- diag(runif(d, lambda[1], lambda[2]), nrow = d, ncol = d)
  P &lt;- svd(matrix(runif(d * d, -1, 1), nc = d))$u
  Sigma[[l]] &lt;- P 
}

# Numbers of observations are calculated and component means and 
# variance-covariance matrices are stored.

n &lt;- round(w * n); Theta &lt;- list()

for (l in 1:c) {
  Theta[[paste0("pdf", l)]] &lt;- rep("normal", d)
  Theta[[paste0("theta1.", l)]] &lt;- Mu[[l]]
  Theta[[paste0("theta2.", l)]] &lt;- as.vector(Sigma[[l]])
}

# Dataset is generated.

simulated &lt;- RNGMIX(model = "RNGMVNORM", Dataset.name = "mvnorm_1",
  rseed = -1, n = n, Theta = Theta)

plot(simulated)

# Generate and print bivariate mixed uniform-Gumbel dataset.

n &lt;- c(100, 150)

Theta &lt;- new("RNGMIX.Theta", c = 2, pdf = c("uniform", "Gumbel"))

a.theta1(Theta, l = 1) &lt;- c(2, 10)
a.theta2(Theta, l = 1) &lt;- c(10, 2.3)
a.theta3(Theta, l = 1) &lt;- c(NA, 1.0)
a.theta1(Theta, l = 2) &lt;- c(10, 50)
a.theta2(Theta, l = 2) &lt;- c(30, 4.2)
a.theta3(Theta, l = 2) &lt;- c(NA, -1.0)

simulated &lt;- RNGMIX(Dataset.name = paste("simulated_", 1, sep = ""),
  rseed = -1,
  n = n,
  Theta = a.Theta(Theta))
  
plot(simulated)  
</code></pre>

<hr>
<h2 id='RNGMIX.Theta-class'>Class <code>"RNGMIX.Theta"</code></h2><span id='topic+RNGMIX.Theta-class'></span><span id='topic+RNGMVNORM.Theta-class'></span><span id='topic+show+2CRNGMIX.Theta-method'></span><span id='topic+show+2CRNGMVNORM.Theta-method'></span>

<h3>Description</h3>

<p>Object of class <code>RNGMIX.Theta</code>.</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>new("RNGMIX.Theta", ...)</code>. Accessor methods for the slots are <code>a.c(x = NULL)</code>, <code>a.d(x = NULL)</code>,
<code>a.pdf(x = NULL)</code> and <code>a.Theta(x = NULL)</code>, where <code>x</code> stands for an object of class <code>RNGMIX.Theta</code>. Setter methods
<code>a.theta1(x = NULL, l = numeric())</code>, <code>a.theta2(x = NULL, l = numeric())</code> and <code>a.theta3(x = NULL, l = numeric())</code>, 
<code>a.theta1.all(x = NULL)</code>, <code>a.theta2.all(x = NULL)</code> and <code>a.theta3.all(x = NULL)</code> 
are provided to write to <code>Theta</code> slot, where <code class="reqn">l = 1, \ldots, c</code>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>c</code>:</dt><dd>
<p>number of components <code class="reqn">c &gt; 0</code>. The default value is <code>1</code>.
</p>
</dd>
<dt><code>d</code>:</dt><dd>
<p>number of dimensions.
</p>
</dd>
<dt><code>pdf</code>:</dt><dd>
<p>a character vector of length <code class="reqn">d</code> containing continuous or discrete parametric family types. One of <code>"normal"</code>, <code>"lognormal"</code>, <code>"Weibull"</code>, <code>"gamma"</code>, <code>"Gumbel"</code>, <code>"binomial"</code>, <code>"Poisson"</code>, <code>"Dirac"</code>, <code>"uniform"</code> or <code>"vonMises"</code>.
</p>
</dd>
<dt><code>Theta</code>:</dt><dd>
<p>a list containing <code class="reqn">c</code> parametric family types <code>pdfl</code>. One of <code>"normal"</code>, <code>"lognormal"</code>, <code>"Weibull"</code>, <code>"gamma"</code>, <code>"Gumbel"</code>, <code>"binomial"</code>, <code>"Poisson"</code>, <code>"Dirac"</code>, <code>"uniform"</code> or circular <code>"vonMises"</code> defined for <code class="reqn">0 \leq y_{i} \leq 2 \pi</code>.
Component parameters <code>theta1.l</code> follow the parametric family types. One of <code class="reqn">\mu_{il}</code> for normal, lognormal, Gumbel and von Mises distributions, <code class="reqn">\theta_{il}</code> for Weibull, gamma, binomial, Poisson and Dirac distributions and <code class="reqn">a</code> for uniform distribution.
Component parameters <code>theta2.l</code> follow <code>theta1.l</code>. One of <code class="reqn">\sigma_{il}</code> for normal, lognormal and Gumbel distributions, <code class="reqn">\beta_{il}</code> for Weibull and gamma distributions, <code class="reqn">p_{il}</code> for binomial distribution, <code class="reqn">\kappa_{il}</code> for von Mises distribution and <code class="reqn">b</code> for uniform distribution.
Component parameters <code>theta3.l</code> follow <code>theta2.l</code>. One of <code class="reqn">\xi_{il} \in \{-1, 1\}</code> for Gumbel distribution.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>Examples</h3>

<pre><code class='language-R'>Theta &lt;- new("RNGMIX.Theta", c = 2, pdf = c("normal", "Gumbel"))  

a.theta1(Theta, l = 1) &lt;- c(2, 10)
a.theta2(Theta, l = 1) &lt;- c(0.5, 2.3)
a.theta3(Theta, l = 1) &lt;- c(NA, 1.0)
a.theta1(Theta, l = 2) &lt;- c(20, 50)
a.theta2(Theta, l = 2) &lt;- c(3, 4.2)
a.theta3(Theta, l = 2) &lt;- c(NA, -1.0)

Theta

Theta &lt;- new("RNGMIX.Theta", c = 2, pdf = c("normal", "Gumbel"))  

a.theta1.all(Theta) &lt;- c(2, 10, 20, 50)
a.theta2.all(Theta) &lt;- c(0.5, 2.3, 3, 4.2)
a.theta3.all(Theta) &lt;- c(NA, 1.0, NA, -1.0)

Theta

Theta &lt;- new("RNGMVNORM.Theta", c = 2, d = 3)

a.theta1(Theta, l = 1) &lt;- c(2, 10, -20)
a.theta1(Theta, l = 2) &lt;- c(-2.4, -15.1, 30)

Theta
</code></pre>

<hr>
<h2 id='sensorlessdrive'>Sensorless Drive Faults Detection Data</h2><span id='topic+sensorlessdrive'></span>

<h3>Description</h3>

<p>These data are the results of a sensorless drive diagnosis procedure. Features are extracted from the electric current drive signals. The drive has intact and defective components. 
This results in 11 different classes with different conditions. Each condition has been measured several times by 12 different operating conditions, this means by different speeds, 
load moments and load forces. The current signals are measured with a current probe and an oscilloscope on two phases. The original dataset contains 49 features, however, here only 3
are used, that is, features 5, 7 and 11. First class (1) are the healthy drives and the rest are the drives with fault components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(sensorlessdrive)
</code></pre>


<h3>Format</h3>

<p><code>sensorlessdrive</code> is a data frame with 58509 cases (rows) and 4 variables (columns) named:
</p>

<ol>
<li>
<p><code>V5</code> continuous.

</p>
</li>
<li>
<p><code>V7</code> continuous.

</p>
</li>
<li>
<p><code>V11</code> continuous.

</p>
</li>
<li>
<p><code>Class</code> discrete <code>1</code>, <code>2</code>, <code>3</code>, <code>4</code>, <code>5</code>, <code>6</code>, <code>7</code>, <code>8</code>, <code>9</code>, <code>10</code> or <code>11</code>.

</p>
</li></ol>



<h3>Source</h3>

<p>A. Asuncion and D. J. Newman. Uci machine learning repository, 2007. <a href="http://archive.ics.uci.edu/ml/">http://archive.ics.uci.edu/ml/</a>.
</p>


<h3>References</h3>

<p>F. Paschke1, C. Bayer, M. Bator, U. Moenks, A. Dicks, O. Enge-Rosenblatt and V. Lohweg. Sensorlose Zustandsueberwachung an Synchronmotoren. 
23. Workshop Computational Intelligence VDI/VDE-Gesellschaft Mess- und Automatisierungstechnik (GMA), 2013.<br /><br />
M. Bator, A. Dicks, U. Moenks and V. Lohweg. Feature extraction and reduction applied to sensorless drive diagnosis. 
22. Workshop Computational Intelligence VDI/VDE-Gesellschaft Mess- und Automatisierungstechnik (GMA), 2012. <a href="https://doi.org/10.13140/2.1.2421.5689">doi:10.13140/2.1.2421.5689</a>. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(sensorlessdrive)

# Split dataset into train (75

set.seed(3)

Drive &lt;- split(p = 0.75, Dataset = sensorlessdrive, class = 4)

# Estimate number of components, component weights and component
# parameters for train subsets.

driveest &lt;- REBMIX(model = "REBMVNORM",
  Dataset = a.train(Drive),
  Preprocessing = "histogram",
  cmax = 15,
  Criterion = "BIC")

# Classification.

drivecla &lt;- RCLSMIX(model = "RCLSMVNORM",
  x = list(driveest),
  Dataset = a.test(Drive),
  Zt = a.Zt(Drive))

drivecla

summary(drivecla)

## End(Not run)
</code></pre>

<hr>
<h2 id='split-methods'>
Splits Dataset into Train and Test Datasets
</h2><span id='topic+split'></span><span id='topic+split-methods'></span><span id='topic+split+2Cnumeric-method'></span><span id='topic+split+2Clist-method'></span>

<h3>Description</h3>

<p>Returns (invisibly) the object containing train and test observations <code class="reqn">\bm{y}_{1}, \ldots, \bm{y}_{n}</code> as well as true class membership <code class="reqn">\bm{\Omega}_{g}</code> for the test dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'numeric'
split(p = 0.75, Dataset = data.frame(), class = numeric(), ...)
## S4 method for signature 'list'
split(p = list(), Dataset = data.frame(), class = numeric(), ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="split-methods_+3A_p">p</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="split-methods_+3A_dataset">Dataset</code></td>
<td>

<p>a data frame containing dataset <code class="reqn">Y</code> of length <code class="reqn">n</code>. For the dataset the corresponding class membership <code class="reqn">\bm{\Omega}_{g}</code> is known.
The default value is <code>data.frame()</code>.
</p>
</td></tr>
<tr><td><code id="split-methods_+3A_class">class</code></td>
<td>

<p>a column number in <code>Dataset</code> containing the class membership information. The default value is <code>numeric()</code>.
</p>
</td></tr>
<tr><td><code id="split-methods_+3A_...">...</code></td>
<td>

<p>further arguments to <code><a href="base.html#topic+sample">sample</a></code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>RCLS.chunk</code>.
</p>


<h3>Methods</h3>


<dl>
<dt><code>signature(p = "numeric")</code></dt><dd><p>a number specifying the fraction of observations for training <code class="reqn">0.0 \leq p \leq 1.0</code>. The default value is <code>0.75</code>.</p>
</dd>
<dt><code>signature(p = "list")</code></dt><dd><p>a list composed of column number <code>p$type</code> in <code>Dataset</code> containing the type membership information followed by the corresponding train <code>p$train</code> and test <code>p$test</code> values.
The default value is <code>list()</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(iris)

# Split dataset into train (75

set.seed(5)

Iris &lt;- split(p = 0.75, Dataset = iris, class = 5)

Iris

# Generate simulated dataset.

N &lt;- 1000

class &lt;- c(rep("A", 0.4 * N), rep("B", 0.2 * N),
  rep("C", 0.1 * N), rep("D", 0.05 * N), rep("E", 0.25 * N))

type &lt;- c(rep("train", 0.75 * N), rep("test", 0.25 * N))

n &lt;- 300

Dataset &lt;- data.frame(1:n, sample(class, n))

colnames(Dataset) &lt;- c("y", "class")

# Split dataset into train (60

simulated &lt;- split(p = 0.6, Dataset = Dataset, class = 2)

simulated

# Generate simulated dataset.

Dataset &lt;- data.frame(1:n, sample(class, n), sample(type, n))

colnames(Dataset) &lt;- c("y", "class", "type")

# Split dataset into train and test subsets.

simulated &lt;- split(p = list(type = 3, train = "train",
  test = "test"), Dataset = Dataset, class = 2)

simulated

## End(Not run)
</code></pre>

<hr>
<h2 id='SSE-methods'>
Sum of Squares Error
</h2><span id='topic+SSE'></span><span id='topic+SSE-methods'></span><span id='topic+SSE+2CREBMIX-method'></span><span id='topic+SSE+2CREBMVNORM-method'></span>

<h3>Description</h3>

<p>Returns the sum of squares error at <code>pos</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'REBMIX'
SSE(x = NULL, pos = 1, ...)
## ... and for other signatures
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SSE-methods_+3A_x">x</code></td>
<td>

<p>see Methods section below.
</p>
</td></tr>
<tr><td><code id="SSE-methods_+3A_pos">pos</code></td>
<td>

<p>a desired row number in <code>x@summary</code> for which the information criterion is calculated. The default value is <code>1</code>.
</p>
</td></tr>
<tr><td><code id="SSE-methods_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "REBMIX")</code></dt><dd><p>an object of class <code>REBMIX</code>.</p>
</dd>
<dt><code>signature(x = "REBMVNORM")</code></dt><dd><p>an object of class <code>REBMVNORM</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Marko Nagode</p>


<h3>References</h3>

<p>C. M. Bishop. Neural Networks for Pattern Recognition. Clarendon Press, Oxford, 1995.
</p>

<hr>
<h2 id='steelplates'>Steel Plates Faults Recognition Data</h2><span id='topic+steelplates'></span>

<h3>Description</h3>

<p>These data are the results of an extraction process from images of faults of steel plates. There are seven different faults: Pastry (1), Z_Scratch (2), K_Scratch (3), Stains (4), Dirtiness (5),
Bumps (6), Other faults (7).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(steelplates)
</code></pre>


<h3>Format</h3>

<p><code>steelplates</code> is a data frame with 1941 cases (rows) and 28 variables (columns) named:
</p>

<ol>
<li>
<p><code>X_Minimum</code> integer.

</p>
</li>
<li>
<p><code>X_Maximum</code> integer.

</p>
</li>
<li>
<p><code>Y_Minimum</code> integer.

</p>
</li>
<li>
<p><code>Y_Maximum</code> integer.

</p>
</li>
<li>
<p><code>Pixels_Areas</code> integer.

</p>
</li>
<li>
<p><code>X_Perimeter</code> integer.

</p>
</li>
<li>
<p><code>Y_Perimeter</code> integer.

</p>
</li>
<li>
<p><code>Sum_of_Luminosity</code> integer.

</p>
</li>
<li>
<p><code>Minimum_of_Luminosity</code> integer.

</p>
</li>
<li>
<p><code>Maximum_of_Luminosity</code> integer.

</p>
</li>
<li>
<p><code>Length_of_Conveyer</code> integer.

</p>
</li>
<li>
<p><code>TypeOfSteel_A300</code> binary.

</p>
</li>
<li>
<p><code>TypeOfSteel_A400</code> binary.

</p>
</li>
<li>
<p><code>Steel_Plate_Thickness</code> integer.

</p>
</li>
<li>
<p><code>Edges_Index</code> continuous.

</p>
</li>
<li>
<p><code>Empty_Index</code> continuous.

</p>
</li>
<li>
<p><code>Square_Index</code> continuous.

</p>
</li>
<li>
<p><code>Outside_X_Index</code> continuous.

</p>
</li>
<li>
<p><code>Edges_X_Index</code> continuous.

</p>
</li>
<li>
<p><code>Edges_Y_Index</code> continuous.

</p>
</li>
<li>
<p><code>Outside_Global_Index</code> continuous.

</p>
</li>
<li>
<p><code>LogOfAreas</code> continuous.

</p>
</li>
<li>
<p><code>Log_X_Index</code> continuous.

</p>
</li>
<li>
<p><code>Log_Y_Index</code> continuous.

</p>
</li>
<li>
<p><code>Orientation_Index</code> continuous.

</p>
</li>
<li>
<p><code>Luminosity_Index</code> continuous.

</p>
</li>
<li>
<p><code>SigmoidOfAreas</code> continuous.

</p>
</li>
<li>
<p><code>Class</code> discrete <code>1</code>, <code>2</code>, <code>3</code>, <code>4</code>, <code>5</code>, <code>6</code> or <code>7</code>.

</p>
</li></ol>



<h3>Source</h3>

<p>A. Asuncion and D. J. Newman. Uci machine learning repository, 2007. <a href="http://archive.ics.uci.edu/ml/">http://archive.ics.uci.edu/ml/</a>.
</p>


<h3>References</h3>

<p>M. Buscema, S. Terzi, W. Tastle. A new meta-classifier. Annual Conference of the North American Fuzzy Information Processing Society - NAFIPS, 2010. <a href="https://doi.org/10.1109/NAFIPS.2010.5548298">doi:10.1109/NAFIPS.2010.5548298</a>.<br /><br />
M. Buscema. MetaNet*: The theory of independent judges. Substance Use &amp; Misuse. 33(2):439-461, 1998. <a href="https://doi.org/10.3109/10826089809115875">doi:10.3109/10826089809115875</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(steelplates)

# Split dataset into train (75

set.seed(3)

Steelplates &lt;- split(p = 0.75, Dataset = steelplates, class = 28)

# Estimate number of components, component weights and component
# parameters for train subsets.

steelplatesest &lt;- REBMIX(model = "REBMVNORM",
  Dataset = a.train(Steelplates),
  Preprocessing = "histogram",
  cmax = 15,
  Criterion = "BIC")

# Classification.

steelplatescla &lt;- RCLSMIX(model = "RCLSMVNORM",
  x = list(steelplatesest),
  Dataset = a.test(Steelplates),
  Zt = a.Zt(Steelplates))

steelplatescla

summary(steelplatescla)

## End(Not run)
</code></pre>

<hr>
<h2 id='truck'>Truck Dataset</h2><span id='topic+truck'></span>

<h3>Description</h3>

<p>The dataset contains amplitudes and means measured on a truck wheels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(truck)
</code></pre>


<h3>Format</h3>

<p><code>truck</code> is a data frame with 31665 rows and 2 variables (columns) named:
</p>

<ol>
<li>
<p><code>Amplitude</code> continuous.

</p>
</li>
<li>
<p><code>Mean</code> continuous.

</p>
</li></ol>



<h3>Author(s)</h3>

<p>Mitja Franko</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(truck)
</code></pre>

<hr>
<h2 id='weibull'>Weibull Dataset 8.1</h2><span id='topic+weibull'></span>

<h3>Description</h3>

<p>The complete data are the failure times in weeks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(weibull)
</code></pre>


<h3>Format</h3>

<p><code>weibull</code> is a data frame with 50 cases (rows) and 1 variables (columns) named:
</p>

<ol>
<li>
<p><code>Failure.Time</code> continuous.

</p>
</li></ol>



<h3>References</h3>

<p>D. N. P. Murthy, M. Xie and R. Jiang. Weibull Models. John Wiley &amp; Sons, New York, 2003.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(weibull)
</code></pre>

<hr>
<h2 id='weibullnormal'>Weibull-normal Simulated Dataset</h2><span id='topic+weibullnormal'></span>

<h3>Description</h3>

<p>The dataset contains amplitudes and means simulated from a three component Weibull-normal mixture.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(weibullnormal)
</code></pre>


<h3>Format</h3>

<p><code>weibullnormal</code> is a data frame with 10000 rows and 2 variables (columns) named:
</p>

<ol>
<li>
<p><code>Amplitude</code> continuous.

</p>
</li>
<li>
<p><code>Mean</code> continuous.

</p>
</li></ol>



<h3>Author(s)</h3>

<p>Mitja Franko</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(weibullnormal)
</code></pre>

<hr>
<h2 id='wine'>Wine Recognition Data</h2><span id='topic+wine'></span>

<h3>Description</h3>

<p>These data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three
different cultivars (1-3). The analysis determined the quantities of 13 constituents: alcohol, malic acid, ash, alcalinity of ash,
magnesium, total phenols, flavanoids, nonflavanoid phenols, proanthocyanins, colour intensity, hue, OD280/OD315 of diluted wines,
and proline found in each of the three types of the wines. The number of instances in classes 1 to 3 is 59, 71 and 48, respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(wine)
</code></pre>


<h3>Format</h3>

<p><code>wine</code> is a data frame with 178 cases (rows) and 14 variables (columns) named:
</p>

<ol>
<li>
<p><code>Alcohol</code> continuous.

</p>
</li>
<li>
<p><code>Malic.Acid</code> continuous.

</p>
</li>
<li>
<p><code>Ash</code> continuous.

</p>
</li>
<li>
<p><code>Alcalinity.of.Ash</code> continuous.

</p>
</li>
<li>
<p><code>Magnesium</code> continuous.

</p>
</li>
<li>
<p><code>Total.Phenols</code> continuous.

</p>
</li>
<li>
<p><code>Flavanoids</code> continuous.

</p>
</li>
<li>
<p><code>Nonflavanoid.Phenols</code> continuous.

</p>
</li>
<li>
<p><code>Proanthocyanins</code> continuous.

</p>
</li>
<li>
<p><code>Color.Intensity</code> continuous.

</p>
</li>
<li>
<p><code>Hue</code> continuous.

</p>
</li>
<li>
<p><code>OD280.OD315.of.Diluted.Wines</code> continuous.

</p>
</li>
<li>
<p><code>Proline</code> continuous.

</p>
</li>
<li>
<p><code>Cultivar</code> discrete <code>1</code>, <code>2</code> or <code>3</code>.

</p>
</li></ol>



<h3>Source</h3>

<p>A. Asuncion and D. J. Newman. Uci machine learning repository, 2007. <a href="http://archive.ics.uci.edu/ml/">http://archive.ics.uci.edu/ml/</a>.
</p>


<h3>References</h3>

<p>S. J. Roberts, R. Everson and I. Rezek. Maximum certainty data partitioning. Pattern Recognition,
33(5):833-839, 2000. <a href="https://doi.org/10.1016/S0031-3203%2899%2900086-2">doi:10.1016/S0031-3203(99)00086-2</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
devAskNewPage(ask = TRUE)

data(wine)

# Show level attributes.

levels(factor(wine[["Cultivar"]]))

# Split dataset into train (75

set.seed(3)

Wine &lt;- split(p = 0.75, Dataset = wine, class = 14)

# Estimate number of components, component weights and component
# parameters for train subsets.

n &lt;- range(a.ntrain(Wine))

K &lt;- c(as.integer(1 + log2(n[1])), # Minimum v follows Sturges rule.
  as.integer(10 * log10(n[2]))) # Maximum v follows log10 rule.

K &lt;- c(floor(K[1]^(1/13)), ceiling(K[2]^(1/13)))

wineest &lt;- REBMIX(model = "REBMVNORM",
  Dataset = a.train(Wine),
  Preprocessing = "kernel density estimation",
  cmax = 10,
  Criterion = "ICL-BIC",
  pdf = rep("normal", 13),
  K = K[1]:K[2],
  Restraints = "loose",
  Mode = "outliersplus")

plot(wineest, pos = 1, nrow = 7, ncol = 6, what = c("pdf"))
plot(wineest, pos = 2, nrow = 7, ncol = 6, what = c("pdf"))
plot(wineest, pos = 3, nrow = 7, ncol = 6, what = c("pdf"))

# Selected chunks.

winecla &lt;- RCLSMIX(model = "RCLSMVNORM",
  x = list(wineest),
  Dataset = a.test(Wine),
  Zt = a.Zt(Wine))

winecla

summary(winecla)

# Plot selected chunks.

plot(winecla, nrow = 7, ncol = 6)

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
