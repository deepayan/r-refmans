<!DOCTYPE html><html><head><title>Help for package clusterHD</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {clusterHD}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#diagPlot'>
<p>diagnostic plots for HTK-Means Clustering</p></a></li>
<li><a href='#getLambda'>
<p>select lambda based on AIC or BIC</p></a></li>
<li><a href='#HTKmeans'>
<p>HTK-Means Clustering</p></a></li>
<li><a href='#PVS'>
<p>Pooled variable scaling for cluster analysis</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Tools for Clustering High-Dimensional Data</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-08-10</td>
</tr>
<tr>
<td>Author:</td>
<td>Jakob Raymaekers [aut, cre],
  Ruben Zamar [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jakob Raymaekers &lt;j.raymaekers@maastrichtuniversity.nl&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Tools for clustering high-dimensional data.
  In particular, it contains the methods described in
   &lt;<a href="https://doi.org/10.1093%2Fbioinformatics%2Fbtaa243">doi:10.1093/bioinformatics/btaa243</a>&gt;,
   &lt;<a href="https://doi.org/10.48550/arXiv.2010.00950">doi:10.48550/arXiv.2010.00950</a>&gt;.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://arxiv.org/abs/2010.00950">https://arxiv.org/abs/2010.00950</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.7), stats, mclust, Ckmeans.1d.dp, cluster</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-08-10 08:50:03 UTC; u0105404</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-08-10 10:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='diagPlot'>
diagnostic plots for HTK-Means Clustering
</h2><span id='topic+diagPlot'></span>

<h3>Description</h3>

<p>Make diagnostic plots for HTK-means clustering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diagPlot(HTKmeans.out, type = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diagPlot_+3A_htkmeans.out">HTKmeans.out</code></td>
<td>
<p> the output of a call to <code><a href="#topic+HTKmeans">HTKmeans</a>.</code>
</p>
</td></tr>
<tr><td><code id="diagPlot_+3A_type">type</code></td>
<td>
<p> if <code>type = 1</code>, plots the regularization path. If <code>type = 2</code>, plots the differences in WCSS and ARI against the number of active variables.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This visualization plots the regularization path or 
the differences in WCSS and ARI against the number of active variables.
</p>


<h3>Value</h3>

<p>No return value, makes the plot directly.</p>


<h3>Author(s)</h3>

<p>J. Raymaekers and R.H. Zamar
</p>


<h3>References</h3>

<p>Raymaekers, Jakob, and Ruben H. Zamar. &quot;Regularized K-means through hard-thresholding.&quot; arXiv preprint arXiv:2010.00950 (2020).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+HTKmeans">HTKmeans</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- iris[, -5]
lambdas &lt;- seq(0, 1, by = 0.01)
HTKmeans.out &lt;- HTKmeans(X, 3, lambdas)

diagPlot(HTKmeans.out, 1)
diagPlot(HTKmeans.out, 2)

</code></pre>

<hr>
<h2 id='getLambda'>
select lambda based on AIC or BIC
</h2><span id='topic+getLambda'></span>

<h3>Description</h3>

<p>Select the regularization parameter for HTK-means clustering based on information criteria.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getLambda(HTKmeans.out, type  = "AIC")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getLambda_+3A_htkmeans.out">HTKmeans.out</code></td>
<td>
<p> the output of a call to <code><a href="#topic+HTKmeans">HTKmeans</a>.</code>
</p>
</td></tr>
<tr><td><code id="getLambda_+3A_type">type</code></td>
<td>
<p> either <code>"AIC"</code> (default) or 
<code>"BIC"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function selects the best lambda (based on information
criteria AIC or BIC) out of the <code>HTKmeans.out$inputargs$lambdas</code> sequence of values. 
</p>


<h3>Value</h3>

<p>The selected value for lambda
</p>


<h3>Author(s)</h3>

<p>J. Raymaekers and R.H. Zamar
</p>


<h3>References</h3>

<p>Raymaekers, Jakob, and Ruben H. Zamar. &quot;Regularized K-means through hard-thresholding.&quot; arXiv preprint arXiv:2010.00950 (2020).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+HTKmeans">HTKmeans</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- mclust::banknote
y &lt;- as.numeric(as.factor(X[, 1]))
lambdas &lt;- seq(0, 1, by = 0.01)
X &lt;- X[, -1]
HTKmeans.out &lt;- HTKmeans(X, 2, lambdas)

# Both AIC and BIC suggest a lambda of 0.02 here:


getLambda(HTKmeans.out, "AIC")
getLambda(HTKmeans.out, "BIC")

</code></pre>

<hr>
<h2 id='HTKmeans'>
HTK-Means Clustering
</h2><span id='topic+HTKmeans'></span>

<h3>Description</h3>

<p>Perform HTK-means clustering (Raymaekers and Zamar, 2022) on a data matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HTKmeans(X, k, lambdas = NULL,
         standardize = TRUE,
         iter.max = 100, nstart = 100,
         nlambdas = 50,
         lambda_max = 1,
         verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HTKmeans_+3A_x">X</code></td>
<td>
<p> a matrix containing the data.
</p>
</td></tr>
<tr><td><code id="HTKmeans_+3A_k">k</code></td>
<td>

<p>the number of clusters.
</p>
</td></tr>
<tr><td><code id="HTKmeans_+3A_lambdas">lambdas</code></td>
<td>

<p>a vector of values for the regularization parameter <code>lambda</code>.
Defaults to <code>NULL</code>, which generates a sequence of values automatically.
</p>
</td></tr>
<tr><td><code id="HTKmeans_+3A_standardize">standardize</code></td>
<td>

<p>logical flag for standardization to mean 0 and variance 1 of
the data in <code>X</code>. This is recommended, unless the variance
of the variables is known to quantify relevant information.
</p>
</td></tr>
<tr><td><code id="HTKmeans_+3A_iter.max">iter.max</code></td>
<td>

<p>the maximum number of iterations allowed.
</p>
</td></tr>
<tr><td><code id="HTKmeans_+3A_nstart">nstart</code></td>
<td>

<p>number of starts used when k-means is applied to generate
the starting values for HTK-means. See below for more info.
</p>
</td></tr>
<tr><td><code id="HTKmeans_+3A_nlambdas">nlambdas</code></td>
<td>

<p>Number of lambda values to generate automatically.
</p>
</td></tr>
<tr><td><code id="HTKmeans_+3A_lambda_max">lambda_max</code></td>
<td>

<p>Maximum value for the regularization paramater <code class="reqn">lambda</code>. If
<code>standardize = TRUE</code>, the default of 1 works well.
</p>
</td></tr>
<tr><td><code id="HTKmeans_+3A_verbose">verbose</code></td>
<td>

<p>Whether or not to print progress. Defaults to <code>FALSE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm starts by generating a number of sparse starting values. This is done using k-means on subsets of variables. See 
Raymaekers and Zamar (2022) for details. 
</p>


<h3>Value</h3>

<p>A list with components: <br />
</p>

<ul>
<li><p><code>HTKmeans.out</code> <br />
A list with length equal to the number of lambda values supplied in <code>lambdas</code>.
Each element of this list is in turn a list containing
</p>
<p>centers A matrix of cluster centres.
</p>
<p>cluster A vector of integers (from 1:<code>k</code>) indicating the cluster to which each point is allocated.
</p>
<p>itnb The number of iterations executed until convergence
</p>
<p>converged Whether the algorithm stopped by converging or through reaching the maximum number of itertions.

</p>
</li>
<li><p><code>inputargs</code> <br />
the input arguments to the function.

</p>
</li></ul>



<h3>Author(s)</h3>

<p>J. Raymaekers and R.H. Zamar
</p>


<h3>References</h3>

<p>Raymaekers, Jakob, and Ruben H. Zamar. &quot;Regularized K-means through hard-thresholding.&quot; arXiv preprint arXiv:2010.00950 (2020).
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+kmeans">kmeans</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- iris[, 1:4]
HTKmeans.out &lt;- HTKmeans(X, k = 3, lambdas = 0.8)
HTKmeans.out[[1]]$centers
pairs(X, col = HTKmeans.out[[1]]$cluster)
</code></pre>

<hr>
<h2 id='PVS'>
Pooled variable scaling for cluster analysis
</h2><span id='topic+PVS'></span>

<h3>Description</h3>

<p>The function computes a scale for each variable in the data. 
The result can then be used to standardize a dataset before applying
a clustering algorithm (such as k-means). The scale estimation is based on pooled scale estimators, which result from clustering the individual variables in the data. The method is proposed in Raymaekers, and Zamar (2020) &lt;doi:10.1093/bioinformatics/btaa243&gt;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PVS(X, kmax = 3, dist = "euclidean",
    method = "gap", B = 1000,
    gapMethod = "firstSEmax",
    minSize = 0.05, rDist = runif,
    SE.factor = 1, refDist = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PVS_+3A_x">X</code></td>
<td>
<p> an <code class="reqn">n</code> by <code class="reqn">p</code> data matrix.</p>
</td></tr>
<tr><td><code id="PVS_+3A_kmax">kmax</code></td>
<td>
<p> maximum number of clusters in one variable. Default is <code>3</code>.</p>
</td></tr>
<tr><td><code id="PVS_+3A_dist">dist</code></td>
<td>
<p><code>"euclidean"</code> for pooled standard deviation and <code>"manhattan"</code> for pooled mean absolute deviation. Default is <code>"euclidean"</code>.</p>
</td></tr>
<tr><td><code id="PVS_+3A_method">method</code></td>
<td>
<p>either <code>"gap"</code> or <code>"jump"</code> to determine the number of clusters. Default is <code>"gap"</code>.</p>
</td></tr>
<tr><td><code id="PVS_+3A_b">B</code></td>
<td>
<p> number of bootstrap samples for the reference distribution of the gap statistic. Default is <code>1000</code>.</p>
</td></tr>
<tr><td><code id="PVS_+3A_gapmethod">gapMethod</code></td>
<td>
<p>method to define number of clusters in the gap statistic. See <code><a href="cluster.html#topic+maxSE">cluster::maxSE</a></code> for more info. Defaults to <code>"firstSEmax"</code>.</p>
</td></tr>
<tr><td><code id="PVS_+3A_minsize">minSize</code></td>
<td>
<p> minimum cluster size as a percentage of the total number of observations. Defaults to <code>0.05</code>.</p>
</td></tr>
<tr><td><code id="PVS_+3A_rdist">rDist</code></td>
<td>
<p>Optional. Reference distribution (as a function) for the gap statistic. Defaults to <code>runif</code>, the uniform distribution.</p>
</td></tr>
<tr><td><code id="PVS_+3A_se.factor">SE.factor</code></td>
<td>
<p>factor for determining number of clusters when using the gap statistic.  See <code><a href="cluster.html#topic+maxSE">cluster::maxSE</a></code> for more details. Defaults to <code>1</code></p>
</td></tr>
<tr><td><code id="PVS_+3A_refdist">refDist</code></td>
<td>
<p> Optional. A <code>k</code> by <code>2</code> matrix with the mean and standard error of the reference distribution of the gap statistic in its columns. Can be used to avoid bootstrapping when repeatedly applying the function to same size data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length <code>p</code> containing the estimated scales for the variables.
</p>


<h3>Author(s)</h3>

<p>Jakob Raymaekers
</p>


<h3>References</h3>

<p>Raymaekers, J, Zamar, R.H. (2020). Pooled variable scaling for cluster analysis. <em>Bioinformatics</em>, <b>36</b>(12), 3849-3855. doi: <a href="https://doi.org/10.1093/bioinformatics/btaa243">10.1093/bioinformatics/btaa243</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

X &lt;- iris[, -5]
y &lt;- unclass(iris[, 5])

# Compute scales using different scale estimators.
# the pooled standard deviation is considerably smaller for variable 3 and 4:
sds     &lt;- apply(X, 2, sd); round(sds, 2)
ranges  &lt;- apply(X, 2, function(y) diff(range(y))); round(ranges, 2)
psds    &lt;- PVS(X); round(psds, 2)

# Now cluster using k-means after scaling the data

nbclus &lt;- 3
kmeans.std &lt;- kmeans(X, nbclus, nstart = 100) # no scaling
kmeans.sd  &lt;- kmeans(scale(X), nbclus, nstart = 100)
kmeans.rg  &lt;- kmeans(scale(X, scale = ranges), nbclus, nstart = 100)
kmeans.psd &lt;- kmeans(scale(X, scale = psds), nbclus, nstart = 100)

# Calculate the Adjusted Rand Index for each of the clustering outcomes
round(mclust::adjustedRandIndex(y, kmeans.std$cluster), 2) 
round(mclust::adjustedRandIndex(y, kmeans.sd$cluster), 2) 
round(mclust::adjustedRandIndex(y, kmeans.rg$cluster), 2) 
round(mclust::adjustedRandIndex(y, kmeans.psd$cluster), 2)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
