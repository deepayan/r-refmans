<!DOCTYPE html><html><head><title>Help for package correlation</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {correlation}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#correlation-package'><p>correlation: Methods for correlation analysis</p></a></li>
<li><a href='#cor_lower'><p>Return the upper or lower triangular part</p></a></li>
<li><a href='#cor_smooth'><p>Smooth a non-positive definite correlation matrix to make it positive definite</p></a></li>
<li><a href='#cor_sort'><p>Sort a correlation matrix to improve readability of groups and clusters</p></a></li>
<li><a href='#cor_test'><p>Correlation test</p></a></li>
<li><a href='#cor_text'><p>Correlation text</p></a></li>
<li><a href='#cor_to_ci'><p>Convert correlation to p-values and CIs</p></a></li>
<li><a href='#cor_to_cov'><p>Convert a correlation to covariance</p></a></li>
<li><a href='#cor_to_pcor'><p>Correlation Matrix to (Semi) Partial Correlations</p></a></li>
<li><a href='#correlation'><p>Correlation Analysis</p></a></li>
<li><a href='#correlation-deprecated'><p>Deprecated functions</p></a></li>
<li><a href='#display.easycormatrix'><p>Export tables into different output formats</p></a></li>
<li><a href='#is.cor'><p>Check if matrix ressembles a correlation matrix</p></a></li>
<li><a href='#isSquare'><p>Check if Square Matrix</p></a></li>
<li><a href='#matrix_inverse'><p>Matrix Inversion</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#visualisation_recipe.easycor_test'><p>Visualisation Recipe for 'correlation' Objects</p></a></li>
<li><a href='#z_fisher'><p>Fisher z-transformation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Methods for Correlation Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>0.8.4</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Brenton M. Wiernik &lt;brenton@wiernik.org&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Lightweight package for computing different kinds
    of correlations, such as partial correlations, Bayesian correlations,
    multilevel correlations, polychoric correlations, biweight
    correlations, distance correlations and more. Part of the 'easystats'
    ecosystem. References: Makowski et al. (2020) &lt;<a href="https://doi.org/10.21105%2Fjoss.02306">doi:10.21105/joss.02306</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://easystats.github.io/correlation/">https://easystats.github.io/correlation/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/easystats/correlation/issues">https://github.com/easystats/correlation/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6)</td>
</tr>
<tr>
<td>Imports:</td>
<td>bayestestR (&ge; 0.13.0), datasets, datawizard (&ge; 0.7.0),
insight (&ge; 0.19.1), parameters (&ge; 0.20.2), stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>BayesFactor, energy, ggplot2, ggraph, gt, Hmisc, knitr, lme4,
MASS, mbend, polycor, poorman, ppcor, psych, rmarkdown, rmcorr,
rstanarm, see (&ge; 0.7.5), testthat (&ge; 3.1.7), tidygraph, wdm,
WRS2</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3.9000</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Config/Needs/website:</td>
<td>rstudio/bslib, r-lib/pkgdown,
easystats/easystatstemplate</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-04-06 08:06:55 UTC; mail</td>
</tr>
<tr>
<td>Author:</td>
<td>Dominique Makowski
    <a href="https://orcid.org/0000-0001-5375-9967"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, inv]
    (@Dom_Makowski),
  Brenton M. Wiernik
    <a href="https://orcid.org/0000-0001-9560-6336"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre]
    (@bmwiernik),
  Indrajeet Patil <a href="https://orcid.org/0000-0003-1995-6531"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut] (@patilindrajeets),
  Daniel Lüdecke <a href="https://orcid.org/0000-0002-8895-3206"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut] (@strengejacke),
  Mattan S. Ben-Shachar
    <a href="https://orcid.org/0000-0002-4287-4801"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut]
    (@mattansb),
  Mark White [rev],
  Maximilian M. Rabe
    <a href="https://orcid.org/0000-0002-2556-5644"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [rev]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-04-06 09:23:26 UTC</td>
</tr>
</table>
<hr>
<h2 id='correlation-package'>correlation: Methods for correlation analysis</h2><span id='topic+correlation-package'></span><span id='topic+_PACKAGE'></span>

<h3>Description</h3>

<p>Lightweight package for computing different kinds of correlations,
such as partial correlations, Bayesian correlations, multilevel correlations,
polychoric correlations, biweight correlations, distance correlations and more.
Part of the 'easystats' ecosystem.
</p>
<p>References: Makowski et al. (2020) <a href="https://doi.org/10.21105/joss.02306">doi:10.21105/joss.02306</a>.
</p>


<h3>Details</h3>

<p><code>correlation</code>
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Brenton M. Wiernik <a href="mailto:brenton@wiernik.org">brenton@wiernik.org</a> (<a href="https://orcid.org/0000-0001-9560-6336">ORCID</a>) (@bmwiernik)
</p>
<p>Authors:
</p>

<ul>
<li><p> Dominique Makowski <a href="mailto:dom.makowski@gmail.com">dom.makowski@gmail.com</a> (<a href="https://orcid.org/0000-0001-5375-9967">ORCID</a>) (@Dom_Makowski) [inventor]
</p>
</li>
<li><p> Indrajeet Patil <a href="mailto:patilindrajeet.science@gmail.com">patilindrajeet.science@gmail.com</a> (<a href="https://orcid.org/0000-0003-1995-6531">ORCID</a>) (@patilindrajeets)
</p>
</li>
<li><p> Daniel Lüdecke <a href="mailto:d.luedecke@uke.de">d.luedecke@uke.de</a> (<a href="https://orcid.org/0000-0002-8895-3206">ORCID</a>) (@strengejacke)
</p>
</li>
<li><p> Mattan S. Ben-Shachar <a href="mailto:matanshm@post.bgu.ac.il">matanshm@post.bgu.ac.il</a> (<a href="https://orcid.org/0000-0002-4287-4801">ORCID</a>) (@mattansb)
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Mark White <a href="mailto:markhwhiteii@gmail.com">markhwhiteii@gmail.com</a> [reviewer]
</p>
</li>
<li><p> Maximilian M. Rabe <a href="mailto:maximilian.rabe@uni-potsdam.de">maximilian.rabe@uni-potsdam.de</a> (<a href="https://orcid.org/0000-0002-2556-5644">ORCID</a>) [reviewer]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://easystats.github.io/correlation/">https://easystats.github.io/correlation/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/easystats/correlation/issues">https://github.com/easystats/correlation/issues</a>
</p>
</li></ul>


<hr>
<h2 id='cor_lower'>Return the upper or lower triangular part</h2><span id='topic+cor_lower'></span>

<h3>Description</h3>

<p>Return the upper or lower triangular part of the correlation matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor_lower(x, diag = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cor_lower_+3A_x">x</code></td>
<td>
<p>A correlation object.</p>
</td></tr>
<tr><td><code id="cor_lower_+3A_diag">diag</code></td>
<td>
<p>Should the diagonal be included?</p>
</td></tr>
<tr><td><code id="cor_lower_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to or from other functions.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- correlation(mtcars, redundant = TRUE) # Generate full matrix
x &lt;- cor_lower(x)

if (require("ggplot2")) {
  ggplot(x, aes(x = Parameter2, y = Parameter1, fill = r)) +
    geom_tile()
}

# Sorted
x &lt;- correlation(mtcars, redundant = TRUE) # Generate full matrix
x &lt;- cor_sort(x)
x &lt;- cor_lower(x)

if (require("ggplot2")) {
  ggplot(x, aes(x = Parameter2, y = Parameter1, fill = r)) +
    geom_tile()
}
</code></pre>

<hr>
<h2 id='cor_smooth'>Smooth a non-positive definite correlation matrix to make it positive definite</h2><span id='topic+cor_smooth'></span><span id='topic+is.positive_definite'></span><span id='topic+is_positive_definite'></span>

<h3>Description</h3>

<p>Make correlations positive definite using <code>psych::cor.smooth</code>. If smoothing
is done, inferential statistics (<em>p</em>-values, confidence intervals, etc.) are
removed, as they are no longer valid.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor_smooth(x, method = "psych", verbose = TRUE, ...)

is.positive_definite(x, tol = 10^-12, ...)

is_positive_definite(x, tol = 10^-12, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cor_smooth_+3A_x">x</code></td>
<td>
<p>A correlation matrix.</p>
</td></tr>
<tr><td><code id="cor_smooth_+3A_method">method</code></td>
<td>
<p>Smoothing method. Can be <code>psych</code> (will use
<code>psych::cor.smooth()</code>), <code>hj</code> (Jorjani et al., 2003) or <code>lrs</code> (Schaeffer,
2014). For the two last, will use <code>mbend::bend()</code> (check its documentation
for details).</p>
</td></tr>
<tr><td><code id="cor_smooth_+3A_verbose">verbose</code></td>
<td>
<p>Set to <code>FALSE</code> to silence the function.</p>
</td></tr>
<tr><td><code id="cor_smooth_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to or from other functions.</p>
</td></tr>
<tr><td><code id="cor_smooth_+3A_tol">tol</code></td>
<td>
<p>The minimum eigenvalue to be considered as acceptable.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
data &lt;- as.matrix(mtcars)
# Make missing data so pairwise correlation matrix is non-positive definite
data[sample(seq_len(352), size = 60)] &lt;- NA
data &lt;- as.data.frame(data)
x &lt;- correlation(data)
is.positive_definite(x)

smoothed &lt;- cor_smooth(x)

</code></pre>

<hr>
<h2 id='cor_sort'>Sort a correlation matrix to improve readability of groups and clusters</h2><span id='topic+cor_sort'></span>

<h3>Description</h3>

<p>Sort a correlation matrix based on <code><a href="stats.html#topic+hclust">hclust()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor_sort(x, distance = "correlation", hclust_method = "complete", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cor_sort_+3A_x">x</code></td>
<td>
<p>A correlation matrix.</p>
</td></tr>
<tr><td><code id="cor_sort_+3A_distance">distance</code></td>
<td>
<p>How the distance between each variable should be calculated.
If <code>correlation</code> (default; suited for correlation matrices), the matrix
will be rescaled to 0-1 (<code>distance = 0</code> indicating correlation of <code>1</code>;
<code>distance = 1</code> indicating correlation of <code>-1</code>). If <code>raw</code>, then the matrix
will be used as a distance matrix as-is. Can be others (<code>euclidean</code>,
<code>manhattan</code>, ...), in which case it will be passed to <code><a href="stats.html#topic+dist">dist()</a></code> (see the
arguments for it).</p>
</td></tr>
<tr><td><code id="cor_sort_+3A_hclust_method">hclust_method</code></td>
<td>
<p>Argument passed down into the <code>method</code> argument of <code><a href="stats.html#topic+hclust">hclust()</a></code>.</p>
</td></tr>
<tr><td><code id="cor_sort_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to or from other functions.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- correlation(mtcars)

cor_sort(as.matrix(x))
cor_sort(x, hclust_method = "ward.D2") # It can also reorder the long form output
cor_sort(summary(x, redundant = TRUE)) # As well as from the summary
</code></pre>

<hr>
<h2 id='cor_test'>Correlation test</h2><span id='topic+cor_test'></span>

<h3>Description</h3>

<p>This function performs a correlation test between two variables.
You can easily visualize the result using <code><a href="#topic+visualisation_recipe.easycormatrix">plot()</a></code> (see examples <a href="https://easystats.github.io/correlation/reference/visualisation_recipe.easycormatrix.html#ref-examples"><strong>here</strong></a>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor_test(
  data,
  x,
  y,
  method = "pearson",
  ci = 0.95,
  bayesian = FALSE,
  bayesian_prior = "medium",
  bayesian_ci_method = "hdi",
  bayesian_test = c("pd", "rope", "bf"),
  include_factors = FALSE,
  partial = FALSE,
  partial_bayesian = FALSE,
  multilevel = FALSE,
  ranktransform = FALSE,
  winsorize = FALSE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cor_test_+3A_data">data</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="cor_test_+3A_x">x</code>, <code id="cor_test_+3A_y">y</code></td>
<td>
<p>Names of two variables present in the data.</p>
</td></tr>
<tr><td><code id="cor_test_+3A_method">method</code></td>
<td>
<p>A character string indicating which correlation coefficient is
to be used for the test. One of <code>"pearson"</code> (default),
<code>"kendall"</code>, <code>"spearman"</code> (but see also the <code>robust</code> argument), <code>"biserial"</code>,
<code>"polychoric"</code>, <code>"tetrachoric"</code>, <code>"biweight"</code>,
<code>"distance"</code>, <code>"percentage"</code> (for percentage bend correlation),
<code>"blomqvist"</code> (for Blomqvist's coefficient), <code>"hoeffding"</code> (for
Hoeffding's D), <code>"gamma"</code>, <code>"gaussian"</code> (for Gaussian Rank
correlation) or <code>"shepherd"</code> (for Shepherd's Pi correlation). Setting
<code>"auto"</code> will attempt at selecting the most relevant method
(polychoric when ordinal factors involved, tetrachoric when dichotomous
factors involved, point-biserial if one dichotomous and one continuous and
pearson otherwise). See below the <strong>details</strong> section for a description of
these indices.</p>
</td></tr>
<tr><td><code id="cor_test_+3A_ci">ci</code></td>
<td>
<p>Confidence/Credible Interval level. If <code>"default"</code>, then it is
set to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code> CI).</p>
</td></tr>
<tr><td><code id="cor_test_+3A_bayesian">bayesian</code></td>
<td>
<p>If <code>TRUE</code>, will run the correlations under a Bayesian
framework.</p>
</td></tr>
<tr><td><code id="cor_test_+3A_bayesian_prior">bayesian_prior</code></td>
<td>
<p>For the prior argument, several named values are
recognized: <code>"medium.narrow"</code>, <code>"medium"</code>, <code>"wide"</code>, and
<code>"ultrawide"</code>. These correspond to scale values of <code>1/sqrt(27)</code>,
<code>1/3</code>, <code>1/sqrt(3)</code> and <code>1</code>, respectively. See the
<code>BayesFactor::correlationBF</code> function.</p>
</td></tr>
<tr><td><code id="cor_test_+3A_bayesian_ci_method">bayesian_ci_method</code>, <code id="cor_test_+3A_bayesian_test">bayesian_test</code></td>
<td>
<p>See arguments in
<code><a href="parameters.html#topic+parameters">model_parameters()</a></code> for <code>BayesFactor</code> tests.</p>
</td></tr>
<tr><td><code id="cor_test_+3A_include_factors">include_factors</code></td>
<td>
<p>If <code>TRUE</code>, the factors are kept and eventually
converted to numeric or used as random effects (depending of
<code>multilevel</code>). If <code>FALSE</code>, factors are removed upfront.</p>
</td></tr>
<tr><td><code id="cor_test_+3A_partial">partial</code></td>
<td>
<p>Can be <code>TRUE</code> or <code>"semi"</code> for partial and
semi-partial correlations, respectively.</p>
</td></tr>
<tr><td><code id="cor_test_+3A_partial_bayesian">partial_bayesian</code></td>
<td>
<p>If partial correlations under a Bayesian framework
are needed, you will also need to set <code>partial_bayesian</code> to <code>TRUE</code> to
obtain &quot;full&quot; Bayesian partial correlations. Otherwise, you will obtain
pseudo-Bayesian partial correlations (i.e., Bayesian correlation based on
frequentist partialization).</p>
</td></tr>
<tr><td><code id="cor_test_+3A_multilevel">multilevel</code></td>
<td>
<p>If <code>TRUE</code>, the factors are included as random factors.
Else, if <code>FALSE</code> (default), they are included as fixed effects in the
simple regression model.</p>
</td></tr>
<tr><td><code id="cor_test_+3A_ranktransform">ranktransform</code></td>
<td>
<p>If <code>TRUE</code>, will rank-transform the variables prior to
estimating the correlation, which is one way of making the analysis more
resistant to extreme values (outliers). Note that, for instance, a Pearson's
correlation on rank-transformed data is equivalent to a Spearman's rank
correlation. Thus, using <code>robust=TRUE</code> and <code>method="spearman"</code> is
redundant. Nonetheless, it is an easy option to increase the robustness of the
correlation as well as flexible way to obtain Bayesian or multilevel
Spearman-like rank correlations.</p>
</td></tr>
<tr><td><code id="cor_test_+3A_winsorize">winsorize</code></td>
<td>
<p>Another way of making the correlation more &quot;robust&quot; (i.e.,
limiting the impact of extreme values). Can be either <code>FALSE</code> or a
number between 0 and 1 (e.g., <code>0.2</code>) that corresponds to the desired
threshold. See the <code><a href="datawizard.html#topic+winsorize">winsorize()</a></code> function for more details.</p>
</td></tr>
<tr><td><code id="cor_test_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings.</p>
</td></tr>
<tr><td><code id="cor_test_+3A_...">...</code></td>
<td>
<p>Additional arguments (e.g., <code>alternative</code>) to be passed to
other methods. See <code>stats::cor.test</code> for further details.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Correlation Types</h4>


<ul>
<li> <p><strong>Pearson's correlation</strong>: This is the most common correlation
method. It corresponds to the covariance of the two variables normalized
(i.e., divided) by the product of their standard deviations.
</p>
</li>
<li> <p><strong>Spearman's rank correlation</strong>: A non-parametric measure of rank
correlation (statistical dependence between the rankings of two variables).
The Spearman correlation between two variables is equal to the Pearson
correlation between the rank values of those two variables; while Pearson's
correlation assesses linear relationships, Spearman's correlation assesses
monotonic relationships (whether linear or not). Confidence Intervals (CI)
for Spearman's correlations are computed using the Fieller et al. (1957)
correction (see Bishara and Hittner, 2017).
</p>
</li>
<li> <p><strong>Kendall's rank correlation</strong>: In the normal case, the Kendall correlation
is preferred than the Spearman correlation because of a smaller gross error
sensitivity (GES) and a smaller asymptotic variance (AV), making it more
robust and more efficient. However, the interpretation of Kendall's tau is
less direct than that of Spearman's rho, in the sense that it quantifies the
difference between the percentage of concordant and discordant pairs among
all possible pairwise events. Confidence Intervals (CI) for Kendall's
correlations are computed using the Fieller et al. (1957) correction (see
Bishara and Hittner, 2017).
</p>
</li>
<li> <p><strong>Biweight midcorrelation</strong>: A measure of similarity that is
median-based, instead of the traditional mean-based, thus being less
sensitive to outliers. It can be used as a robust alternative to other
similarity metrics, such as Pearson correlation (Langfelder &amp; Horvath,
2012).
</p>
</li>
<li> <p><strong>Distance correlation</strong>: Distance correlation measures both
linear and non-linear association between two random variables or random
vectors. This is in contrast to Pearson's correlation, which can only detect
linear association between two random variables.
</p>
</li>
<li> <p><strong>Percentage bend correlation</strong>: Introduced by Wilcox (1994), it
is based on a down-weight of a specified percentage of marginal observations
deviating from the median (by default, <code style="white-space: pre;">&#8288;20%&#8288;</code>).
</p>
</li>
<li> <p><strong>Shepherd's Pi correlation</strong>: Equivalent to a Spearman's rank
correlation after outliers removal (by means of bootstrapped Mahalanobis
distance).
</p>
</li>
<li> <p><strong>Blomqvist’s coefficient</strong>: The Blomqvist’s coefficient (also
referred to as Blomqvist's Beta or medial correlation; Blomqvist, 1950) is a
median-based non-parametric correlation that has some advantages over
measures such as Spearman's or Kendall's estimates (see Shmid &amp; Schimdt,
2006).
</p>
</li>
<li> <p><strong>Hoeffding’s D</strong>: The Hoeffding’s D statistics is a
non-parametric rank based measure of association that detects more general
departures from independence (Hoeffding 1948), including non-linear
associations. Hoeffding’s D varies between -0.5 and 1 (if there are no tied
ranks, otherwise it can have lower values), with larger values indicating a
stronger relationship between the variables.
</p>
</li>
<li> <p><strong>Somers’ D</strong>: The Somers’ D statistics is a non-parametric rank
based measure of association between a binary variable and a continuous
variable, for instance, in the context of logistic regression the binary
outcome and the predicted probabilities for each outcome. Usually, Somers' D
is a measure of ordinal association, however, this implementation it is
limited to the case of a binary outcome.
</p>
</li>
<li> <p><strong>Point-Biserial and biserial correlation</strong>: Correlation
coefficient used when one variable is continuous and the other is dichotomous
(binary). Point-Biserial is equivalent to a Pearson's correlation, while
Biserial should be used when the binary variable is assumed to have an
underlying continuity. For example, anxiety level can be measured on a
continuous scale, but can be classified dichotomously as high/low.
</p>
</li>
<li> <p><strong>Gamma correlation</strong>: The Goodman-Kruskal gamma statistic is
similar to Kendall's Tau coefficient. It is relatively robust to outliers and
deals well with data that have many ties.
</p>
</li>
<li> <p><strong>Winsorized correlation</strong>: Correlation of variables that have
been formerly Winsorized, i.e., transformed by limiting extreme values to
reduce the effect of possibly spurious outliers.
</p>
</li>
<li> <p><strong>Gaussian rank Correlation</strong>: The Gaussian rank correlation
estimator is a simple and well-performing alternative for robust rank
correlations (Boudt et al., 2012). It is based on the Gaussian quantiles of
the ranks.
</p>
</li>
<li> <p><strong>Polychoric correlation</strong>: Correlation between two theorized
normally distributed continuous latent variables, from two observed ordinal
variables.
</p>
</li>
<li> <p><strong>Tetrachoric correlation</strong>: Special case of the polychoric
correlation applicable when both observed variables are dichotomous.
</p>
</li></ul>




<h4>Partial Correlation</h4>

<p><strong>Partial correlations</strong> are estimated as the correlation between two
variables after adjusting for the (linear) effect of one or more other
variable. The correlation test is then run after having partialized the
dataset, independently from it. In other words, it considers partialization
as an independent step generating a different dataset, rather than belonging
to the same model. This is why some discrepancies are to be expected for the
t- and p-values, CIs, BFs etc (but <em>not</em> the correlation coefficient)
compared to other implementations (e.g., <code>ppcor</code>). (The size of these
discrepancies depends on the number of covariates partialled-out and the
strength of the linear association between all variables.) Such partial
correlations can be represented as Gaussian Graphical Models (GGM), an
increasingly popular tool in psychology. A GGM traditionally include a set of
variables depicted as circles (&quot;nodes&quot;), and a set of lines that visualize
relationships between them, which thickness represents the strength of
association (see Bhushan et al., 2019).
</p>
<p><strong>Multilevel correlations</strong> are a special case of partial correlations where
the variable to be adjusted for is a factor and is included as a random
effect in a mixed model (note that the remaining continuous variables of the
dataset will still be included as fixed effects, similarly to regular partial
correlations). The model is a random intercept model, i.e. the multilevel
correlation is adjusted for <code>(1 | groupfactor)</code>.That said, there is an
important difference between using <code>cor_test()</code> and <code>correlation()</code>: If you
set <code>multilevel=TRUE</code> in <code>correlation()</code> but <code>partial</code> is set to <code>FALSE</code> (as
per default), then a back-transformation from partial to non-partial
correlation will be attempted (through <code><a href="#topic+pcor_to_cor">pcor_to_cor()</a></code>).
However, this is not possible when using <code>cor_test()</code> so that if you set
<code>multilevel=TRUE</code> in it, the resulting correlations are partial one. Note
that for Bayesian multilevel correlations, if <code>partial = FALSE</code>, the back
transformation will also recompute <em>p</em>-values based on the new <em>r</em> scores,
and will drop the Bayes factors (as they are not relevant anymore). To keep
Bayesian scores, set <code>partial = TRUE</code>.
</p>



<h4>Notes</h4>

<p>Kendall and Spearman correlations when <code>bayesian=TRUE</code>: These are technically
Pearson Bayesian correlations of rank transformed data, rather than pure
Bayesian rank correlations (which have different priors).
</p>



<h3>Examples</h3>

<pre><code class='language-R'>library(correlation)

cor_test(iris, "Sepal.Length", "Sepal.Width")
cor_test(iris, "Sepal.Length", "Sepal.Width", method = "spearman")
## Not run: 
cor_test(iris, "Sepal.Length", "Sepal.Width", method = "kendall")
cor_test(iris, "Sepal.Length", "Sepal.Width", method = "biweight")
cor_test(iris, "Sepal.Length", "Sepal.Width", method = "distance")
cor_test(iris, "Sepal.Length", "Sepal.Width", method = "percentage")

if (require("wdm", quietly = TRUE)) {
  cor_test(iris, "Sepal.Length", "Sepal.Width", method = "blomqvist")
}

if (require("Hmisc", quietly = TRUE)) {
  cor_test(iris, "Sepal.Length", "Sepal.Width", method = "hoeffding")
}
cor_test(iris, "Sepal.Length", "Sepal.Width", method = "gamma")
cor_test(iris, "Sepal.Length", "Sepal.Width", method = "gaussian")
cor_test(iris, "Sepal.Length", "Sepal.Width", method = "shepherd")
if (require("BayesFactor", quietly = TRUE)) {
  cor_test(iris, "Sepal.Length", "Sepal.Width", bayesian = TRUE)
}

# Robust (these two are equivalent)
cor_test(iris, "Sepal.Length", "Sepal.Width", method = "spearman")
cor_test(iris, "Sepal.Length", "Sepal.Width", method = "pearson", ranktransform = TRUE)

# Winsorized
cor_test(iris, "Sepal.Length", "Sepal.Width", winsorize = 0.2)

# Tetrachoric
if (require("psych", quietly = TRUE) &amp;&amp; require("rstanarm", quietly = TRUE)) {
  data &lt;- iris
  data$Sepal.Width_binary &lt;- ifelse(data$Sepal.Width &gt; 3, 1, 0)
  data$Petal.Width_binary &lt;- ifelse(data$Petal.Width &gt; 1.2, 1, 0)
  cor_test(data, "Sepal.Width_binary", "Petal.Width_binary", method = "tetrachoric")

  # Biserial
  cor_test(data, "Sepal.Width", "Petal.Width_binary", method = "biserial")

  # Polychoric
  data$Petal.Width_ordinal &lt;- as.factor(round(data$Petal.Width))
  data$Sepal.Length_ordinal &lt;- as.factor(round(data$Sepal.Length))
  cor_test(data, "Petal.Width_ordinal", "Sepal.Length_ordinal", method = "polychoric")

  # When one variable is continuous, will run 'polyserial' correlation
  cor_test(data, "Sepal.Width", "Sepal.Length_ordinal", method = "polychoric")
}

# Partial
cor_test(iris, "Sepal.Length", "Sepal.Width", partial = TRUE)
cor_test(iris, "Sepal.Length", "Sepal.Width", multilevel = TRUE)
cor_test(iris, "Sepal.Length", "Sepal.Width", partial_bayesian = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='cor_text'>Correlation text</h2><span id='topic+cor_text'></span>

<h3>Description</h3>

<p>This function returns a formatted character of correlation statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor_text(x, show_ci = TRUE, show_statistic = TRUE, show_sig = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cor_text_+3A_x">x</code></td>
<td>
<p>A dataframe with correlation statistics.</p>
</td></tr>
<tr><td><code id="cor_text_+3A_show_ci">show_ci</code>, <code id="cor_text_+3A_show_statistic">show_statistic</code>, <code id="cor_text_+3A_show_sig">show_sig</code></td>
<td>
<p>Toggle on/off different parts of the text.</p>
</td></tr>
<tr><td><code id="cor_text_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to or from other functions.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>rez &lt;- cor_test(mtcars, "mpg", "wt")

cor_text(rez)
cor_text(rez, show_statistic = FALSE, show_ci = FALSE, stars = TRUE)

rez &lt;- correlation(mtcars)

cor_text(rez)
</code></pre>

<hr>
<h2 id='cor_to_ci'>Convert correlation to p-values and CIs</h2><span id='topic+cor_to_ci'></span><span id='topic+cor_to_p'></span>

<h3>Description</h3>

<p>Get statistics, <em>p</em>-values and confidence intervals (CI) from correlation
coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor_to_ci(cor, n, ci = 0.95, method = "pearson", correction = "fieller", ...)

cor_to_p(cor, n, method = "pearson")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cor_to_ci_+3A_cor">cor</code></td>
<td>
<p>A correlation matrix or coefficient.</p>
</td></tr>
<tr><td><code id="cor_to_ci_+3A_n">n</code></td>
<td>
<p>The sample size (number of observations).</p>
</td></tr>
<tr><td><code id="cor_to_ci_+3A_ci">ci</code></td>
<td>
<p>Confidence/Credible Interval level. If <code>"default"</code>, then it is
set to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code> CI).</p>
</td></tr>
<tr><td><code id="cor_to_ci_+3A_method">method</code></td>
<td>
<p>A character string indicating which correlation coefficient is
to be used for the test. One of <code>"pearson"</code> (default),
<code>"kendall"</code>, <code>"spearman"</code> (but see also the <code>robust</code> argument), <code>"biserial"</code>,
<code>"polychoric"</code>, <code>"tetrachoric"</code>, <code>"biweight"</code>,
<code>"distance"</code>, <code>"percentage"</code> (for percentage bend correlation),
<code>"blomqvist"</code> (for Blomqvist's coefficient), <code>"hoeffding"</code> (for
Hoeffding's D), <code>"gamma"</code>, <code>"gaussian"</code> (for Gaussian Rank
correlation) or <code>"shepherd"</code> (for Shepherd's Pi correlation). Setting
<code>"auto"</code> will attempt at selecting the most relevant method
(polychoric when ordinal factors involved, tetrachoric when dichotomous
factors involved, point-biserial if one dichotomous and one continuous and
pearson otherwise). See below the <strong>details</strong> section for a description of
these indices.</p>
</td></tr>
<tr><td><code id="cor_to_ci_+3A_correction">correction</code></td>
<td>
<p>Only used if method is 'spearman' or 'kendall'. Can be
'fieller' (default; Fieller et al., 1957), 'bw' (only for Spearman) or
'none'. Bonett and Wright (2000) claim their correction ('bw') performs
better, though the Bishara and Hittner (2017) paper favours the Fieller
correction. Both are generally very similar.</p>
</td></tr>
<tr><td><code id="cor_to_ci_+3A_...">...</code></td>
<td>
<p>Additional arguments (e.g., <code>alternative</code>) to be passed to
other methods. See <code>stats::cor.test</code> for further details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing a <em>p</em>-value and the statistic or the CI bounds.
</p>


<h3>References</h3>

<p>Bishara, A. J., &amp; Hittner, J. B. (2017). Confidence intervals for
correlations when data are not normal. Behavior research methods, 49(1),
294-309.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cor.test(iris$Sepal.Length, iris$Sepal.Width)
cor_to_p(-0.1175698, n = 150)
cor_to_p(cor(iris[1:4]), n = 150)
cor_to_ci(-0.1175698, n = 150)
cor_to_ci(cor(iris[1:4]), n = 150)

cor.test(iris$Sepal.Length, iris$Sepal.Width, method = "spearman", exact = FALSE)
cor_to_p(-0.1667777, n = 150, method = "spearman")
cor_to_ci(-0.1667777, ci = 0.95, n = 150)

cor.test(iris$Sepal.Length, iris$Sepal.Width, method = "kendall", exact = FALSE)
cor_to_p(-0.07699679, n = 150, method = "kendall")
</code></pre>

<hr>
<h2 id='cor_to_cov'>Convert a correlation to covariance</h2><span id='topic+cor_to_cov'></span>

<h3>Description</h3>

<p>Convert a correlation to covariance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor_to_cov(cor, sd = NULL, variance = NULL, tol = .Machine$double.eps^(2/3))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cor_to_cov_+3A_cor">cor</code></td>
<td>
<p>A correlation matrix, or a partial or a semipartial
correlation matrix.</p>
</td></tr>
<tr><td><code id="cor_to_cov_+3A_sd">sd</code>, <code id="cor_to_cov_+3A_variance">variance</code></td>
<td>
<p>A vector that contains the standard deviations, or the
variance, of the variables in the correlation matrix.</p>
</td></tr>
<tr><td><code id="cor_to_cov_+3A_tol">tol</code></td>
<td>
<p>Relative tolerance to detect zero singular values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A covariance matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cor &lt;- cor(iris[1:4])
cov(iris[1:4])

cor_to_cov(cor, sd = sapply(iris[1:4], sd))
cor_to_cov(cor, variance = sapply(iris[1:4], var))
</code></pre>

<hr>
<h2 id='cor_to_pcor'>Correlation Matrix to (Semi) Partial Correlations</h2><span id='topic+cor_to_pcor'></span><span id='topic+pcor_to_cor'></span><span id='topic+cor_to_spcor'></span>

<h3>Description</h3>

<p>Convert a correlation matrix to a (semi)partial correlation matrix. Partial
correlations are a measure of the correlation between two variables that
remains after controlling for (i.e., &quot;partialling&quot; out) all the other
relationships. They can be used for graphical Gaussian models, as they
represent the direct interactions between two variables, conditioned on all
remaining variables. This means that the squared partial correlation between
a predictor X1 and a response variable Y can be interpreted as the proportion
of (unique) variance accounted for by X1 relative to the residual or
unexplained variance of Y that cannot be accounted by the other variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor_to_pcor(cor, tol = .Machine$double.eps^(2/3))

pcor_to_cor(pcor, tol = .Machine$double.eps^(2/3))

cor_to_spcor(cor = NULL, cov = NULL, tol = .Machine$double.eps^(2/3))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cor_to_pcor_+3A_cor">cor</code></td>
<td>
<p>A correlation matrix, or a partial or a semipartial
correlation matrix.</p>
</td></tr>
<tr><td><code id="cor_to_pcor_+3A_tol">tol</code></td>
<td>
<p>Relative tolerance to detect zero singular values.</p>
</td></tr>
<tr><td><code id="cor_to_pcor_+3A_pcor">pcor</code></td>
<td>
<p>A correlation matrix, or a partial or a semipartial
correlation matrix.</p>
</td></tr>
<tr><td><code id="cor_to_pcor_+3A_cov">cov</code></td>
<td>
<p>A covariance matrix (or a vector of the SD of the variables).
Required for semi-partial correlations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The semi-partial correlation is similar to the partial correlation statistic.
However, it represents (when squared) the proportion of (unique) variance
accounted for by the predictor X1, relative to the total variance of Y. Thus,
it might be seen as a better indicator of the &quot;practical relevance&quot; of a
predictor, because it is scaled to (i.e., relative to) the total variability
in the response variable.
</p>


<h3>Value</h3>

<p>The (semi) partial correlation matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cor &lt;- cor(iris[1:4])

# Partialize
cor_to_pcor(cor)
cor_to_spcor(cor, cov = sapply(iris[1:4], sd))

# Inverse
round(pcor_to_cor(cor_to_pcor(cor)) - cor, 2) # Should be 0
</code></pre>

<hr>
<h2 id='correlation'>Correlation Analysis</h2><span id='topic+correlation'></span>

<h3>Description</h3>

<p>Performs a correlation analysis.
You can easily visualize the result using <code><a href="#topic+visualisation_recipe.easycormatrix">plot()</a></code>
(see examples <a href="https://easystats.github.io/correlation/reference/visualisation_recipe.easycormatrix.html#ref-examples"><strong>here</strong></a>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>correlation(
  data,
  data2 = NULL,
  select = NULL,
  select2 = NULL,
  rename = NULL,
  method = "pearson",
  p_adjust = "holm",
  ci = 0.95,
  bayesian = FALSE,
  bayesian_prior = "medium",
  bayesian_ci_method = "hdi",
  bayesian_test = c("pd", "rope", "bf"),
  redundant = FALSE,
  include_factors = FALSE,
  partial = FALSE,
  partial_bayesian = FALSE,
  multilevel = FALSE,
  ranktransform = FALSE,
  winsorize = FALSE,
  verbose = TRUE,
  standardize_names = getOption("easystats.standardize_names", FALSE),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="correlation_+3A_data">data</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="correlation_+3A_data2">data2</code></td>
<td>
<p>An optional data frame. If specified, all pair-wise correlations
between the variables in <code>data</code> and <code>data2</code> will be computed.</p>
</td></tr>
<tr><td><code id="correlation_+3A_select">select</code>, <code id="correlation_+3A_select2">select2</code></td>
<td>
<p>(Ignored if <code>data2</code> is specified.) Optional names
of variables that should be selected for correlation. Instead of providing
the data frames with those variables that should be correlated, <code>data</code>
can be a data frame and <code>select</code> and <code>select2</code> are (quoted) names
of variables (columns) in <code>data</code>. <code>correlation()</code> will then
compute the correlation between <code>data[select]</code> and
<code>data[select2]</code>. If only <code>select</code> is specified, all pairwise
correlations between the <code>select</code> variables will be computed. This is
a &quot;pipe-friendly&quot; alternative way of using <code>correlation()</code> (see
'Examples').</p>
</td></tr>
<tr><td><code id="correlation_+3A_rename">rename</code></td>
<td>
<p>In case you wish to change the names of the variables in
the output, these arguments can be used to specify these alternative names.
Note that the number of names should be equal to the number of columns
selected. Ignored if <code>data2</code> is specified.</p>
</td></tr>
<tr><td><code id="correlation_+3A_method">method</code></td>
<td>
<p>A character string indicating which correlation coefficient is
to be used for the test. One of <code>"pearson"</code> (default),
<code>"kendall"</code>, <code>"spearman"</code> (but see also the <code>robust</code> argument), <code>"biserial"</code>,
<code>"polychoric"</code>, <code>"tetrachoric"</code>, <code>"biweight"</code>,
<code>"distance"</code>, <code>"percentage"</code> (for percentage bend correlation),
<code>"blomqvist"</code> (for Blomqvist's coefficient), <code>"hoeffding"</code> (for
Hoeffding's D), <code>"gamma"</code>, <code>"gaussian"</code> (for Gaussian Rank
correlation) or <code>"shepherd"</code> (for Shepherd's Pi correlation). Setting
<code>"auto"</code> will attempt at selecting the most relevant method
(polychoric when ordinal factors involved, tetrachoric when dichotomous
factors involved, point-biserial if one dichotomous and one continuous and
pearson otherwise). See below the <strong>details</strong> section for a description of
these indices.</p>
</td></tr>
<tr><td><code id="correlation_+3A_p_adjust">p_adjust</code></td>
<td>
<p>Correction method for frequentist correlations. Can be one of
<code>"holm"</code> (default), <code>"hochberg"</code>, <code>"hommel"</code>,
<code>"bonferroni"</code>, <code>"BH"</code>, <code>"BY"</code>, <code>"fdr"</code>,
<code>"somers"</code> or <code>"none"</code>. See
<code><a href="stats.html#topic+p.adjust">stats::p.adjust()</a></code> for further details.</p>
</td></tr>
<tr><td><code id="correlation_+3A_ci">ci</code></td>
<td>
<p>Confidence/Credible Interval level. If <code>"default"</code>, then it is
set to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code> CI).</p>
</td></tr>
<tr><td><code id="correlation_+3A_bayesian">bayesian</code></td>
<td>
<p>If <code>TRUE</code>, will run the correlations under a Bayesian
framework.</p>
</td></tr>
<tr><td><code id="correlation_+3A_bayesian_prior">bayesian_prior</code></td>
<td>
<p>For the prior argument, several named values are
recognized: <code>"medium.narrow"</code>, <code>"medium"</code>, <code>"wide"</code>, and
<code>"ultrawide"</code>. These correspond to scale values of <code>1/sqrt(27)</code>,
<code>1/3</code>, <code>1/sqrt(3)</code> and <code>1</code>, respectively. See the
<code>BayesFactor::correlationBF</code> function.</p>
</td></tr>
<tr><td><code id="correlation_+3A_bayesian_ci_method">bayesian_ci_method</code>, <code id="correlation_+3A_bayesian_test">bayesian_test</code></td>
<td>
<p>See arguments in
<code><a href="parameters.html#topic+parameters">model_parameters()</a></code> for <code>BayesFactor</code> tests.</p>
</td></tr>
<tr><td><code id="correlation_+3A_redundant">redundant</code></td>
<td>
<p>Should the data include redundant rows (where each given
correlation is repeated two times).</p>
</td></tr>
<tr><td><code id="correlation_+3A_include_factors">include_factors</code></td>
<td>
<p>If <code>TRUE</code>, the factors are kept and eventually
converted to numeric or used as random effects (depending of
<code>multilevel</code>). If <code>FALSE</code>, factors are removed upfront.</p>
</td></tr>
<tr><td><code id="correlation_+3A_partial">partial</code></td>
<td>
<p>Can be <code>TRUE</code> or <code>"semi"</code> for partial and
semi-partial correlations, respectively.</p>
</td></tr>
<tr><td><code id="correlation_+3A_partial_bayesian">partial_bayesian</code></td>
<td>
<p>If partial correlations under a Bayesian framework
are needed, you will also need to set <code>partial_bayesian</code> to <code>TRUE</code> to
obtain &quot;full&quot; Bayesian partial correlations. Otherwise, you will obtain
pseudo-Bayesian partial correlations (i.e., Bayesian correlation based on
frequentist partialization).</p>
</td></tr>
<tr><td><code id="correlation_+3A_multilevel">multilevel</code></td>
<td>
<p>If <code>TRUE</code>, the factors are included as random factors.
Else, if <code>FALSE</code> (default), they are included as fixed effects in the
simple regression model.</p>
</td></tr>
<tr><td><code id="correlation_+3A_ranktransform">ranktransform</code></td>
<td>
<p>If <code>TRUE</code>, will rank-transform the variables prior to
estimating the correlation, which is one way of making the analysis more
resistant to extreme values (outliers). Note that, for instance, a Pearson's
correlation on rank-transformed data is equivalent to a Spearman's rank
correlation. Thus, using <code>robust=TRUE</code> and <code>method="spearman"</code> is
redundant. Nonetheless, it is an easy option to increase the robustness of the
correlation as well as flexible way to obtain Bayesian or multilevel
Spearman-like rank correlations.</p>
</td></tr>
<tr><td><code id="correlation_+3A_winsorize">winsorize</code></td>
<td>
<p>Another way of making the correlation more &quot;robust&quot; (i.e.,
limiting the impact of extreme values). Can be either <code>FALSE</code> or a
number between 0 and 1 (e.g., <code>0.2</code>) that corresponds to the desired
threshold. See the <code><a href="datawizard.html#topic+winsorize">winsorize()</a></code> function for more details.</p>
</td></tr>
<tr><td><code id="correlation_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings.</p>
</td></tr>
<tr><td><code id="correlation_+3A_standardize_names">standardize_names</code></td>
<td>
<p>This option can be set to <code>TRUE</code> to run
<code><a href="insight.html#topic+standardize_names">insight::standardize_names()</a></code> on the output to get standardized column
names. This option can also be set globally by running
<code>options(easystats.standardize_names = TRUE)</code>.</p>
</td></tr>
<tr><td><code id="correlation_+3A_...">...</code></td>
<td>
<p>Additional arguments (e.g., <code>alternative</code>) to be passed to
other methods. See <code>stats::cor.test</code> for further details.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Correlation Types</h4>


<ul>
<li> <p><strong>Pearson's correlation</strong>: This is the most common correlation
method. It corresponds to the covariance of the two variables normalized
(i.e., divided) by the product of their standard deviations.
</p>
</li>
<li> <p><strong>Spearman's rank correlation</strong>: A non-parametric measure of rank
correlation (statistical dependence between the rankings of two variables).
The Spearman correlation between two variables is equal to the Pearson
correlation between the rank values of those two variables; while Pearson's
correlation assesses linear relationships, Spearman's correlation assesses
monotonic relationships (whether linear or not). Confidence Intervals (CI)
for Spearman's correlations are computed using the Fieller et al. (1957)
correction (see Bishara and Hittner, 2017).
</p>
</li>
<li> <p><strong>Kendall's rank correlation</strong>: In the normal case, the Kendall correlation
is preferred than the Spearman correlation because of a smaller gross error
sensitivity (GES) and a smaller asymptotic variance (AV), making it more
robust and more efficient. However, the interpretation of Kendall's tau is
less direct than that of Spearman's rho, in the sense that it quantifies the
difference between the percentage of concordant and discordant pairs among
all possible pairwise events. Confidence Intervals (CI) for Kendall's
correlations are computed using the Fieller et al. (1957) correction (see
Bishara and Hittner, 2017).
</p>
</li>
<li> <p><strong>Biweight midcorrelation</strong>: A measure of similarity that is
median-based, instead of the traditional mean-based, thus being less
sensitive to outliers. It can be used as a robust alternative to other
similarity metrics, such as Pearson correlation (Langfelder &amp; Horvath,
2012).
</p>
</li>
<li> <p><strong>Distance correlation</strong>: Distance correlation measures both
linear and non-linear association between two random variables or random
vectors. This is in contrast to Pearson's correlation, which can only detect
linear association between two random variables.
</p>
</li>
<li> <p><strong>Percentage bend correlation</strong>: Introduced by Wilcox (1994), it
is based on a down-weight of a specified percentage of marginal observations
deviating from the median (by default, <code style="white-space: pre;">&#8288;20%&#8288;</code>).
</p>
</li>
<li> <p><strong>Shepherd's Pi correlation</strong>: Equivalent to a Spearman's rank
correlation after outliers removal (by means of bootstrapped Mahalanobis
distance).
</p>
</li>
<li> <p><strong>Blomqvist’s coefficient</strong>: The Blomqvist’s coefficient (also
referred to as Blomqvist's Beta or medial correlation; Blomqvist, 1950) is a
median-based non-parametric correlation that has some advantages over
measures such as Spearman's or Kendall's estimates (see Shmid &amp; Schimdt,
2006).
</p>
</li>
<li> <p><strong>Hoeffding’s D</strong>: The Hoeffding’s D statistics is a
non-parametric rank based measure of association that detects more general
departures from independence (Hoeffding 1948), including non-linear
associations. Hoeffding’s D varies between -0.5 and 1 (if there are no tied
ranks, otherwise it can have lower values), with larger values indicating a
stronger relationship between the variables.
</p>
</li>
<li> <p><strong>Somers’ D</strong>: The Somers’ D statistics is a non-parametric rank
based measure of association between a binary variable and a continuous
variable, for instance, in the context of logistic regression the binary
outcome and the predicted probabilities for each outcome. Usually, Somers' D
is a measure of ordinal association, however, this implementation it is
limited to the case of a binary outcome.
</p>
</li>
<li> <p><strong>Point-Biserial and biserial correlation</strong>: Correlation
coefficient used when one variable is continuous and the other is dichotomous
(binary). Point-Biserial is equivalent to a Pearson's correlation, while
Biserial should be used when the binary variable is assumed to have an
underlying continuity. For example, anxiety level can be measured on a
continuous scale, but can be classified dichotomously as high/low.
</p>
</li>
<li> <p><strong>Gamma correlation</strong>: The Goodman-Kruskal gamma statistic is
similar to Kendall's Tau coefficient. It is relatively robust to outliers and
deals well with data that have many ties.
</p>
</li>
<li> <p><strong>Winsorized correlation</strong>: Correlation of variables that have
been formerly Winsorized, i.e., transformed by limiting extreme values to
reduce the effect of possibly spurious outliers.
</p>
</li>
<li> <p><strong>Gaussian rank Correlation</strong>: The Gaussian rank correlation
estimator is a simple and well-performing alternative for robust rank
correlations (Boudt et al., 2012). It is based on the Gaussian quantiles of
the ranks.
</p>
</li>
<li> <p><strong>Polychoric correlation</strong>: Correlation between two theorized
normally distributed continuous latent variables, from two observed ordinal
variables.
</p>
</li>
<li> <p><strong>Tetrachoric correlation</strong>: Special case of the polychoric
correlation applicable when both observed variables are dichotomous.
</p>
</li></ul>




<h4>Partial Correlation</h4>

<p><strong>Partial correlations</strong> are estimated as the correlation between two
variables after adjusting for the (linear) effect of one or more other
variable. The correlation test is then run after having partialized the
dataset, independently from it. In other words, it considers partialization
as an independent step generating a different dataset, rather than belonging
to the same model. This is why some discrepancies are to be expected for the
t- and p-values, CIs, BFs etc (but <em>not</em> the correlation coefficient)
compared to other implementations (e.g., <code>ppcor</code>). (The size of these
discrepancies depends on the number of covariates partialled-out and the
strength of the linear association between all variables.) Such partial
correlations can be represented as Gaussian Graphical Models (GGM), an
increasingly popular tool in psychology. A GGM traditionally include a set of
variables depicted as circles (&quot;nodes&quot;), and a set of lines that visualize
relationships between them, which thickness represents the strength of
association (see Bhushan et al., 2019).
</p>
<p><strong>Multilevel correlations</strong> are a special case of partial correlations where
the variable to be adjusted for is a factor and is included as a random
effect in a mixed model (note that the remaining continuous variables of the
dataset will still be included as fixed effects, similarly to regular partial
correlations). The model is a random intercept model, i.e. the multilevel
correlation is adjusted for <code>(1 | groupfactor)</code>.That said, there is an
important difference between using <code>cor_test()</code> and <code>correlation()</code>: If you
set <code>multilevel=TRUE</code> in <code>correlation()</code> but <code>partial</code> is set to <code>FALSE</code> (as
per default), then a back-transformation from partial to non-partial
correlation will be attempted (through <code><a href="#topic+pcor_to_cor">pcor_to_cor()</a></code>).
However, this is not possible when using <code>cor_test()</code> so that if you set
<code>multilevel=TRUE</code> in it, the resulting correlations are partial one. Note
that for Bayesian multilevel correlations, if <code>partial = FALSE</code>, the back
transformation will also recompute <em>p</em>-values based on the new <em>r</em> scores,
and will drop the Bayes factors (as they are not relevant anymore). To keep
Bayesian scores, set <code>partial = TRUE</code>.
</p>



<h4>Notes</h4>

<p>Kendall and Spearman correlations when <code>bayesian=TRUE</code>: These are technically
Pearson Bayesian correlations of rank transformed data, rather than pure
Bayesian rank correlations (which have different priors).
</p>



<h3>Value</h3>

<p>A correlation object that can be displayed using the <code>print</code>, <code>summary</code> or
<code>table</code> methods.
</p>


<h4>Multiple tests correction</h4>

<p>The <code>p_adjust</code> argument can be used to adjust p-values for multiple
comparisons. All adjustment methods available in <code>p.adjust</code> function
<code>stats</code> package are supported.
</p>



<h3>References</h3>


<ul>
<li><p> Boudt, K., Cornelissen, J., &amp; Croux, C. (2012). The Gaussian rank
correlation estimator: robustness properties. Statistics and Computing,
22(2), 471-483.
</p>
</li>
<li><p> Bhushan, N., Mohnert, F., Sloot, D., Jans, L., Albers, C., &amp; Steg, L.
(2019). Using a Gaussian graphical model to explore relationships between
items and variables in environmental psychology research. Frontiers in
psychology, 10, 1050.
</p>
</li>
<li><p> Bishara, A. J., &amp; Hittner, J. B. (2017). Confidence intervals for
correlations when data are not normal. Behavior research methods, 49(1),
294-309.
</p>
</li>
<li><p> Fieller, E. C., Hartley, H. O., &amp; Pearson, E. S. (1957). Tests for
rank correlation coefficients. I. Biometrika, 44(3/4), 470-481.
</p>
</li>
<li><p> Langfelder, P., &amp; Horvath, S. (2012). Fast R functions for robust
correlations and hierarchical clustering. Journal of statistical software,
46(11).
</p>
</li>
<li><p> Blomqvist, N. (1950). On a measure of dependence between two random
variables,Annals of Mathematical Statistics,21, 593–600
</p>
</li>
<li><p> Somers, R. H. (1962). A new asymmetric measure of association for
ordinal variables. American Sociological Review. 27 (6).
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>

library(correlation)
library(poorman)

results &lt;- correlation(iris)

results
summary(results)
summary(results, redundant = TRUE)

# pipe-friendly usage with  grouped dataframes from {dplyr} package
iris %&gt;%
  correlation(select = "Petal.Width", select2 = "Sepal.Length")

# Grouped dataframe
# grouped correlations
iris %&gt;%
  group_by(Species) %&gt;%
  correlation()

# selecting specific variables for correlation
mtcars %&gt;%
  group_by(am) %&gt;%
  correlation(
    select = c("cyl", "wt"),
    select2 = c("hp")
  )

# supplying custom variable names
correlation(anscombe, select = c("x1", "x2"), rename = c("var1", "var2"))

# automatic selection of correlation method
correlation(mtcars[-2], method = "auto")

</code></pre>

<hr>
<h2 id='correlation-deprecated'>Deprecated functions</h2><span id='topic+correlation-deprecated'></span><span id='topic+distance_mahalanobis'></span>

<h3>Description</h3>

<p>Deprecated functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>distance_mahalanobis(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="correlation-deprecated_+3A_...">...</code></td>
<td>
<p>Args.</p>
</td></tr>
</table>

<hr>
<h2 id='display.easycormatrix'>Export tables into different output formats</h2><span id='topic+display.easycormatrix'></span><span id='topic+print_md.easycorrelation'></span><span id='topic+print_html.easycorrelation'></span><span id='topic+print_md.easycormatrix'></span><span id='topic+print_html.easycormatrix'></span>

<h3>Description</h3>

<p>Export tables (i.e. data frame) into different output formats.
<code>print_md()</code> is a alias for <code>display(format = "markdown")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'easycormatrix'
display(
  object,
  format = "markdown",
  digits = 2,
  p_digits = 3,
  stars = TRUE,
  include_significance = NULL,
  ...
)

## S3 method for class 'easycorrelation'
print_md(x, digits = NULL, p_digits = NULL, stars = NULL, ...)

## S3 method for class 'easycorrelation'
print_html(x, digits = NULL, p_digits = NULL, stars = NULL, ...)

## S3 method for class 'easycormatrix'
print_md(
  x,
  digits = NULL,
  p_digits = NULL,
  stars = NULL,
  include_significance = NULL,
  ...
)

## S3 method for class 'easycormatrix'
print_html(
  x,
  digits = NULL,
  p_digits = NULL,
  stars = NULL,
  include_significance = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="display.easycormatrix_+3A_object">object</code>, <code id="display.easycormatrix_+3A_x">x</code></td>
<td>
<p>An object returned by
<code><a href="#topic+correlation">correlation()</a></code> or its summary.</p>
</td></tr>
<tr><td><code id="display.easycormatrix_+3A_format">format</code></td>
<td>
<p>String, indicating the output format. Currently, only
<code>"markdown"</code> is supported.</p>
</td></tr>
<tr><td><code id="display.easycormatrix_+3A_digits">digits</code>, <code id="display.easycormatrix_+3A_p_digits">p_digits</code></td>
<td>
<p>To do...</p>
</td></tr>
<tr><td><code id="display.easycormatrix_+3A_stars">stars</code></td>
<td>
<p>To do...</p>
</td></tr>
<tr><td><code id="display.easycormatrix_+3A_include_significance">include_significance</code></td>
<td>
<p>To do...</p>
</td></tr>
<tr><td><code id="display.easycormatrix_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>display()</code> is useful when the table-output from functions,
which is usually printed as formatted text-table to console, should
be formatted for pretty table-rendering in markdown documents, or if
knitted from rmarkdown to PDF or Word files.
</p>


<h3>Value</h3>

<p>A character vector. If <code>format = "markdown"</code>, the return value
will be a character vector in markdown-table format.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
corr &lt;- correlation(iris)
display(corr)

s &lt;- summary(corr)
display(s)
</code></pre>

<hr>
<h2 id='is.cor'>Check if matrix ressembles a correlation matrix</h2><span id='topic+is.cor'></span>

<h3>Description</h3>

<p>Check if matrix ressembles a correlation matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.cor(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.cor_+3A_x">x</code></td>
<td>
<p>A matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>TRUE</code> of the matrix is a correlation matrix or <code>FALSE</code> otherwise.
</p>

<hr>
<h2 id='isSquare'>Check if Square Matrix</h2><span id='topic+isSquare'></span>

<h3>Description</h3>

<p>Check if Square Matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isSquare(m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="isSquare_+3A_m">m</code></td>
<td>
<p>A matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>TRUE</code> of the matrix is square or <code>FALSE</code> otherwise.
</p>

<hr>
<h2 id='matrix_inverse'>Matrix Inversion</h2><span id='topic+matrix_inverse'></span>

<h3>Description</h3>

<p>Performs a Moore-Penrose generalized inverse (also called the Pseudoinverse).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matrix_inverse(m, tol = .Machine$double.eps^(2/3))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="matrix_inverse_+3A_m">m</code></td>
<td>
<p>Matrix for which the inverse is required.</p>
</td></tr>
<tr><td><code id="matrix_inverse_+3A_tol">tol</code></td>
<td>
<p>Relative tolerance to detect zero singular values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An inversed matrix.
</p>


<h3>See Also</h3>

<p>pinv from the pracma package
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- cor(iris[1:4])
matrix_inverse(m)
</code></pre>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+simulate_simpson'></span><span id='topic+visualisation_recipe'></span><span id='topic+standardize_names'></span><span id='topic+print_md'></span><span id='topic+print_html'></span><span id='topic+display'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>bayestestR</dt><dd><p><code><a href="bayestestR.html#topic+simulate_simpson">simulate_simpson</a></code></p>
</dd>
<dt>datawizard</dt><dd><p><code><a href="datawizard.html#topic+visualisation_recipe">visualisation_recipe</a></code></p>
</dd>
<dt>insight</dt><dd><p><code><a href="insight.html#topic+display">display</a></code>, <code><a href="insight.html#topic+display">print_html</a></code>, <code><a href="insight.html#topic+display">print_md</a></code>, <code><a href="insight.html#topic+standardize_names">standardize_names</a></code></p>
</dd>
</dl>

<hr>
<h2 id='visualisation_recipe.easycor_test'>Visualisation Recipe for 'correlation' Objects</h2><span id='topic+visualisation_recipe.easycor_test'></span><span id='topic+visualisation_recipe.easycormatrix'></span><span id='topic+visualisation_recipe.easycorrelation'></span>

<h3>Description</h3>

<p>Objects from the <code>correlation</code> package can be easily visualized. You can
simply run <code>plot()</code> on them, which will internally call the <code>visualisation_recipe()</code>
method to produce a basic <code>ggplot</code>. You can customize this plot ad-hoc or via
the arguments described below.
See examples <a href="https://easystats.github.io/correlation/reference/visualisation_recipe.easycormatrix.html#ref-examples"><strong>here</strong></a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'easycor_test'
visualisation_recipe(
  x,
  show_data = "point",
  show_text = "subtitle",
  smooth = NULL,
  point = NULL,
  text = NULL,
  labs = NULL,
  ...
)

## S3 method for class 'easycormatrix'
visualisation_recipe(
  x,
  show_data = "tile",
  show_text = "text",
  show_legend = TRUE,
  tile = NULL,
  point = NULL,
  text = NULL,
  scale = NULL,
  scale_fill = NULL,
  labs = NULL,
  type = show_data,
  ...
)

## S3 method for class 'easycorrelation'
visualisation_recipe(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="visualisation_recipe.easycor_test_+3A_x">x</code></td>
<td>
<p>A correlation object.</p>
</td></tr>
<tr><td><code id="visualisation_recipe.easycor_test_+3A_show_data">show_data</code></td>
<td>
<p>Show data. For correlation matrices, can be <code>"tile"</code>
(default) or <code>"point"</code>.</p>
</td></tr>
<tr><td><code id="visualisation_recipe.easycor_test_+3A_show_text">show_text</code></td>
<td>
<p>Show labels with matrix values.</p>
</td></tr>
<tr><td><code id="visualisation_recipe.easycor_test_+3A_...">...</code></td>
<td>
<p>Other arguments passed to other functions.</p>
</td></tr>
<tr><td><code id="visualisation_recipe.easycor_test_+3A_show_legend">show_legend</code></td>
<td>
<p>Show legend. Can be set to <code>FALSE</code> to remove the legend.</p>
</td></tr>
<tr><td><code id="visualisation_recipe.easycor_test_+3A_tile">tile</code>, <code id="visualisation_recipe.easycor_test_+3A_point">point</code>, <code id="visualisation_recipe.easycor_test_+3A_text">text</code>, <code id="visualisation_recipe.easycor_test_+3A_scale">scale</code>, <code id="visualisation_recipe.easycor_test_+3A_scale_fill">scale_fill</code>, <code id="visualisation_recipe.easycor_test_+3A_smooth">smooth</code>, <code id="visualisation_recipe.easycor_test_+3A_labs">labs</code></td>
<td>
<p>Additional aesthetics and
parameters for the geoms (see customization example).</p>
</td></tr>
<tr><td><code id="visualisation_recipe.easycor_test_+3A_type">type</code></td>
<td>
<p>Alias for <code>show_data</code>, for backwards compatibility.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
# ==============================================
# Correlation Test
# ==============================================
if (require("see")) {
  rez &lt;- cor_test(mtcars, "mpg", "wt")

  layers &lt;- visualisation_recipe(rez, labs = list(x = "Miles per Gallon (mpg)"))
  layers
  plot(layers)

  plot(rez,
    show_text = "label",
    point = list(color = "#f44336"),
    text = list(fontface = "bold"),
    show_statistic = FALSE, show_ci = FALSE, stars = TRUE
  )
}

# ==============================================
# Correlation Matrix
# ==============================================
if (require("see")) {
  rez &lt;- correlation(mtcars)

  x &lt;- cor_sort(as.matrix(rez))
  layers &lt;- visualisation_recipe(x)
  layers
  plot(layers)

  #' Get more details using `summary()`
  x &lt;- summary(rez, redundant = TRUE, digits = 3)
  plot(visualisation_recipe(x))

  # Customize
  x &lt;- summary(rez)
  layers &lt;- visualisation_recipe(x,
    show_data = "points",
    scale = list(range = c(10, 20)),
    scale_fill = list(
      high = "#FF5722",
      low = "#673AB7",
      name = "r"
    ),
    text = list(color = "white"),
    labs = list(title = "My Plot")
  )
  plot(layers) + theme_modern()
}

# ==============================================
# Correlation Results (easycorrelation)
# ==============================================
if (require("see") &amp;&amp; require("tidygraph") &amp;&amp; require("ggraph")) {
  rez &lt;- correlation(iris)

  layers &lt;- visualisation_recipe(rez)
  layers
  plot(layers)
}

</code></pre>

<hr>
<h2 id='z_fisher'>Fisher z-transformation</h2><span id='topic+z_fisher'></span>

<h3>Description</h3>

<p>The Fisher z-transformation converts the standard Pearson's <em>r</em> to a normally
distributed variable z'. It is used to compute confidence intervals to
correlations. The z' variable is different from the <em>z</em>-statistic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>z_fisher(r = NULL, z = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="z_fisher_+3A_r">r</code>, <code id="z_fisher_+3A_z">z</code></td>
<td>
<p>The r or the z' value to be converted.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The transformed value.
</p>


<h3>References</h3>

<p>Zar, J.H., (2014). Spearman Rank Correlation: Overview. Wiley StatsRef:
Statistics Reference Online. doi:10.1002/9781118445112.stat05964
</p>


<h3>Examples</h3>

<pre><code class='language-R'>z_fisher(r = 0.7)
z_fisher(z = 0.867)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
