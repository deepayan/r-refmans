<!DOCTYPE html><html><head><title>Help for package phacking</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {phacking}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#money_priming_meta'><p>Meta-analysis of money priming studies</p></a></li>
<li><a href='#phacking_meta'><p>Right-truncated meta-analysis</p></a></li>
<li><a href='#phacking-package'><p>phacking: Sensitivity Analysis for p-Hacking in Meta-Analyses</p></a></li>
<li><a href='#rtma_cdf'><p>Compute theoretical and empirical CDFs for a right-truncated meta-analysis</p></a></li>
<li><a href='#rtma_qqplot'><p>Diagnostic quantile-quantile plot for a right-truncated meta-analysis</p></a></li>
<li><a href='#z_density'><p>Z-score density plot</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Sensitivity Analysis for p-Hacking in Meta-Analyses</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Fits right-truncated meta-analysis (RTMA), a bias correction for
  the joint effects of p-hacking (i.e., manipulation of results within studies
  to obtain significant, positive estimates) and traditional publication bias
  (i.e., the selective publication of studies with significant, positive
  results) in meta-analyses [see Mathur MB (2022). "Sensitivity analysis for
  p-hacking in meta-analyses." &lt;<a href="https://doi.org/10.31219%2Fosf.io%2Fezjsx">doi:10.31219/osf.io/ezjsx</a>&gt;.]. Unlike publication
  bias alone, p-hacking that favors significant, positive results (termed
  "affirmative") can distort the distribution of affirmative results. To
  bias-correct results from affirmative studies would require strong assumptions
  on the exact nature of p-hacking. In contrast, joint p-hacking and publication
  bias do not distort the distribution of published nonaffirmative results when
  there is stringent p-hacking (e.g., investigators who hack always eventually
  obtain an affirmative result) or when there is stringent publication bias
  (e.g., nonaffirmative results from hacked studies are never published). This
  means that any published nonaffirmative results are from unhacked studies.
  Under these assumptions, RTMA involves analyzing only the published
  nonaffirmative results to essentially impute the full underlying distribution
  of all results prior to selection due to p-hacking and/or publication bias.
  The package also provides diagnostic plots described in Mathur (2022).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/mathurlabstanford/phacking">https://github.com/mathurlabstanford/phacking</a>,
<a href="https://mathurlabstanford.github.io/phacking/">https://mathurlabstanford.github.io/phacking/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/mathurlabstanford/phacking/issues">https://github.com/mathurlabstanford/phacking/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>Biarch:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, ggplot2, metabias, metafor, methods, purrr, rlang,
stats, stats4, truncnorm, Rcpp (&ge; 0.12.0), RcppParallel (&ge;
5.0.1), Rdpack, rstan (&ge; 2.18.1), rstantools (&ge; 2.2.0)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>BH (&ge; 1.66.0), Rcpp (&ge; 0.12.0), RcppEigen (&ge; 0.3.3.3.0),
RcppParallel (&ge; 5.0.1), rstan (&ge; 2.18.1), StanHeaders (&ge;
2.18.0)</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>GNU make</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-07-15 21:13:32 UTC; root</td>
</tr>
<tr>
<td>Author:</td>
<td>Peter Solymos <a href="https://orcid.org/0000-0001-7337-1740"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [cre, ctb],
  Maya Mathur [aut],
  Mika Braginsky [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Peter Solymos &lt;peter@analythium.io&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-07-17 14:00:14 UTC</td>
</tr>
</table>
<hr>
<h2 id='money_priming_meta'>Meta-analysis of money priming studies</h2><span id='topic+money_priming_meta'></span>

<h3>Description</h3>

<p>Dataset from a meta-analysis of experimental studies on the effect of money
primes on a variety of psychological and behavioral outcomes, in which some
studies were preregistered (Lodder et al. 2019).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>money_priming_meta
</code></pre>


<h3>Format</h3>

<p>A data frame with 287 rows and 4 variables:
</p>

<dl>
<dt>study</dt><dd><p>Code identifying the study</p>
</dd>
<dt>yi</dt><dd><p>Point estimate on the Hedges' <em>g</em> scale</p>
</dd>
<dt>vi</dt><dd><p>Variance of point estimate</p>
</dd>
<dt>zi</dt><dd><p>Z-score</p>
</dd>
<dt>preregistered</dt><dd><p>Logical indicating whether study was preregistered</p>
</dd>
</dl>



<h3>References</h3>

<p>Lodder P, Ong HH, Grasman RPPP, Wicherts JM (2019).
&ldquo;A comprehensive meta-analysis of money priming.&rdquo;
<em>Journal of Experimental Psychology: General</em>, <b>148</b>(4), 688.
</p>
<p>Lodder P, Ong HH, Grasman RPPP, Wicherts JM (2020).
&ldquo;A comprehensive meta-analysis of money priming.&rdquo;
OSF.
<a href="https://osf.io/dhp63">https://osf.io/dhp63</a>.
</p>

<hr>
<h2 id='phacking_meta'>Right-truncated meta-analysis</h2><span id='topic+phacking_meta'></span>

<h3>Description</h3>

<p>Fits right-truncated meta-analysis (RTMA), a bias correction for the joint
effects of p-hacking (i.e., manipulation of results within studies to obtain
significant, positive estimates) and traditional publication bias (i.e., the
selective publication of studies with significant, positive results) in
meta-analyses. This method analyzes only nonaffirmative studies (i.e., those
with significant, positive estimates). You can pass all studies in the meta-analysis
or only the nonaffirmative ones; if the former, the function will still analyze only
the nonaffirmative ones.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phacking_meta(
  yi,
  vi,
  sei,
  favor_positive = TRUE,
  alpha_select = 0.05,
  ci_level = 0.95,
  stan_control = list(adapt_delta = 0.98, max_treedepth = 20),
  parallelize = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="phacking_meta_+3A_yi">yi</code></td>
<td>
<p>A vector of point estimates to be meta-analyzed.</p>
</td></tr>
<tr><td><code id="phacking_meta_+3A_vi">vi</code></td>
<td>
<p>A vector of estimated variances (i.e., squared standard errors) for
the point estimates.</p>
</td></tr>
<tr><td><code id="phacking_meta_+3A_sei">sei</code></td>
<td>
<p>A vector of estimated standard errors for the point estimates.
(Only one of <code>vi</code> or <code>sei</code> needs to be specified).</p>
</td></tr>
<tr><td><code id="phacking_meta_+3A_favor_positive">favor_positive</code></td>
<td>
<p><code>TRUE</code> if publication bias are
assumed to favor significant positive estimates; <code>FALSE</code> if assumed to
favor significant negative estimates.</p>
</td></tr>
<tr><td><code id="phacking_meta_+3A_alpha_select">alpha_select</code></td>
<td>
<p>Alpha level at which an estimate's probability of being
favored by publication bias is assumed to change (i.e.,
the threshold at which study investigators, journal editors, etc., consider
an estimate to be significant).</p>
</td></tr>
<tr><td><code id="phacking_meta_+3A_ci_level">ci_level</code></td>
<td>
<p>Confidence interval level (as proportion) for the corrected
point estimate. (The alpha level for inference on the corrected point
estimate will be calculated from <code>ci_level</code>.)</p>
</td></tr>
<tr><td><code id="phacking_meta_+3A_stan_control">stan_control</code></td>
<td>
<p>List passed to <code><a href="rstan.html#topic+stanmodel-method-sampling">rstan::sampling()</a></code> as the <code>control</code>
argument.</p>
</td></tr>
<tr><td><code id="phacking_meta_+3A_parallelize">parallelize</code></td>
<td>
<p>Logical indicating whether to parallelize sampling.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code><a href="metabias.html#topic+metabias-class">metabias::metabias()</a></code>, a list containing:
</p>

<dl>
<dt>data</dt><dd><p>A tibble with one row per study and the columns
<code>yi</code>, <code>vi</code>, <code>sei</code>, <code>affirm</code>.</p>
</dd>
<dt>values</dt><dd><p>A list with the elements <code>favor_positive</code>, <code>alpha_select</code>, <code>ci_level</code>, <code>tcrit</code>, <code>k</code>, <code>k_affirmative</code>, <code>k_nonaffirmative</code>, <code>optim_converged</code>.
<code>optim_converged</code> indicates whether the optimization to find
the posterior mode converged.</p>
</dd>
<dt>stats</dt><dd><p>A tibble with two rows and the columns
<code>param</code>, <code>mode</code>, <code>median</code>, <code>mean</code>, <code>se</code>, <code>ci_lower</code>, <code>ci_upper</code>, <code>n_eff</code>, <code>r_hat</code>. We recommend reporting the <code>mode</code>
for the point estimate; <code>median</code> and <code>mean</code> represent
posterior medians and means respectively.</p>
</dd>
<dt>fit</dt><dd><p>A <code>stanfit</code> object (the result of fitting the RTMA model).</p>
</dd>
</dl>



<h3>References</h3>

<p>Mathur MB (2022).
&ldquo;Sensitivity analysis for p-hacking in meta-analyses.&rdquo;
<a href="https://doi.org/10.31219/osf.io/ezjsx">doi:10.31219/osf.io/ezjsx</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# passing all studies, though only nonaffirmative ones will be analyzed
money_priming_rtma &lt;- phacking_meta(money_priming_meta$yi, money_priming_meta$vi,
                                    parallelize = FALSE)

</code></pre>

<hr>
<h2 id='phacking-package'>phacking: Sensitivity Analysis for p-Hacking in Meta-Analyses</h2><span id='topic+phacking'></span><span id='topic+phacking-package'></span>

<h3>Description</h3>

<p>Fits right-truncated meta-analysis (RTMA), a bias correction for the joint effects of p-hacking (i.e., manipulation of results within studies to obtain significant, positive estimates) and traditional publication bias (i.e., the selective publication of studies with significant, positive results) in meta-analyses [see Mathur MB (2022). &quot;Sensitivity analysis for p-hacking in meta-analyses.&quot; <a href="https://doi.org/10.31219/osf.io/ezjsx">doi:10.31219/osf.io/ezjsx</a>.]. Unlike publication bias alone, p-hacking that favors significant, positive results (termed &quot;affirmative&quot;) can distort the distribution of affirmative results. To bias-correct results from affirmative studies would require strong assumptions on the exact nature of p-hacking. In contrast, joint p-hacking and publication bias do not distort the distribution of published nonaffirmative results when there is stringent p-hacking (e.g., investigators who hack always eventually obtain an affirmative result) or when there is stringent publication bias (e.g., nonaffirmative results from hacked studies are never published). This means that any published nonaffirmative results are from unhacked studies. Under these assumptions, RTMA involves analyzing only the published nonaffirmative results to essentially impute the full underlying distribution of all results prior to selection due to p-hacking and/or publication bias. The package also provides diagnostic plots described in Mathur (2022).
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Peter Solymos <a href="mailto:peter@analythium.io">peter@analythium.io</a> (<a href="https://orcid.org/0000-0001-7337-1740">ORCID</a>) [contributor]
</p>
<p>Authors:
</p>

<ul>
<li><p> Maya Mathur <a href="mailto:mmathur@stanford.edu">mmathur@stanford.edu</a>
</p>
</li>
<li><p> Mika Braginsky <a href="mailto:mika.br@gmail.com">mika.br@gmail.com</a>
</p>
</li></ul>



<h3>References</h3>

<p>Mathur MB (2022).
&ldquo;Sensitivity analysis for p-hacking in meta-analyses.&rdquo;
<a href="https://doi.org/10.31219/osf.io/ezjsx">doi:10.31219/osf.io/ezjsx</a>.
</p>
<p>Lodder P, Ong HH, Grasman RPPP, Wicherts JM (2019).
&ldquo;A comprehensive meta-analysis of money priming.&rdquo;
<em>Journal of Experimental Psychology: General</em>, <b>148</b>(4), 688.
</p>
<p>Stan Development Team (2022).
&ldquo;RStan: the R interface to Stan.&rdquo;
R package version 2.21.5.
<a href="https://mc-stan.org">https://mc-stan.org</a>.
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/mathurlabstanford/phacking">https://github.com/mathurlabstanford/phacking</a>
</p>
</li>
<li> <p><a href="https://mathurlabstanford.github.io/phacking/">https://mathurlabstanford.github.io/phacking/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/mathurlabstanford/phacking/issues">https://github.com/mathurlabstanford/phacking/issues</a>
</p>
</li></ul>


<hr>
<h2 id='rtma_cdf'>Compute theoretical and empirical CDFs for a right-truncated meta-analysis</h2><span id='topic+rtma_cdf'></span>

<h3>Description</h3>

<p>Compute theoretical and empirical CDFs for a right-truncated meta-analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rtma_cdf(rtma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rtma_cdf_+3A_rtma">rtma</code></td>
<td>
<p>Output of <code><a href="#topic+phacking_meta">phacking_meta()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with the columns <code>yi</code> (effect sizes), <code>cdfi</code>
(their fitted CDF) and <code>ecdfi</code> (their empirical CDF).
</p>
<p>A data frame with the CDF derived from a metabias object.
</p>


<h3>References</h3>

<p>Mathur MB (2022).
&ldquo;Sensitivity analysis for p-hacking in meta-analyses.&rdquo;
<a href="https://doi.org/10.31219/osf.io/ezjsx">doi:10.31219/osf.io/ezjsx</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
money_priming_rtma &lt;- phacking_meta(money_priming_meta$yi,
                                    money_priming_meta$vi,
                                    parallelize = FALSE)
rtma_cdf(money_priming_rtma)

</code></pre>

<hr>
<h2 id='rtma_qqplot'>Diagnostic quantile-quantile plot for a right-truncated meta-analysis</h2><span id='topic+rtma_qqplot'></span>

<h3>Description</h3>

<p>To assess the fit of right-truncated meta-analysis and possible violations of
its distributional assumptions, plots the fitted cumulative distribution
function (CDF) of the published nonaffirmative estimates versus their
empirical CDF. If the points do not adhere fairly closely to a 45-degree
line, the right-truncated meta-analysis may not fit adequately.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rtma_qqplot(rtma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rtma_qqplot_+3A_rtma">rtma</code></td>
<td>
<p>Output of <code><a href="#topic+phacking_meta">phacking_meta()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot2 object representing quantile-quantile plot.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
money_priming_rtma &lt;- phacking_meta(money_priming_meta$yi,
                                    money_priming_meta$vi,
                                    parallelize = FALSE)
rtma_qqplot(money_priming_rtma)

</code></pre>

<hr>
<h2 id='z_density'>Z-score density plot</h2><span id='topic+z_density'></span>

<h3>Description</h3>

<p>Plots the Z-scores of all published point estimates. When p-hacking favors
affirmative estimates over nonaffirmative estimates, as our methods and
others assume, Z-scores may disproportionately concentrate just above the
critical value (e.g., 1.96). Importantly, the presence of p-hacking does not
<em>guarantee</em> a concentration of Z-scores just above the critical value,
so it is prudent to proceed with the fitting RTMA even if no such
concentration is apparent. In contrast, if Z-scores also concentrate just
<em>below</em> the critical value, or if they also concentrate below the
sign-reversed critical value (e.g., -1.96), this could indicate forms of
p-hacking that violate the assumptions of RTMA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>z_density(yi, vi, sei, alpha_select = 0.05, crit_color = "red")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="z_density_+3A_yi">yi</code></td>
<td>
<p>A vector of point estimates to be meta-analyzed.</p>
</td></tr>
<tr><td><code id="z_density_+3A_vi">vi</code></td>
<td>
<p>A vector of estimated variances (i.e., squared standard errors) for
the point estimates.</p>
</td></tr>
<tr><td><code id="z_density_+3A_sei">sei</code></td>
<td>
<p>A vector of estimated standard errors for the point estimates.
(Only one of <code>vi</code> or <code>sei</code> needs to be specified).</p>
</td></tr>
<tr><td><code id="z_density_+3A_alpha_select">alpha_select</code></td>
<td>
<p>Alpha level at which an estimate's probability of being
favored by publication bias is assumed to change (i.e.,
the threshold at which study investigators, journal editors, etc., consider
an estimate to be significant).</p>
</td></tr>
<tr><td><code id="z_density_+3A_crit_color">crit_color</code></td>
<td>
<p>Color for line and text are critical z-score.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot2 object representing a Z-score density plot.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>z_density(money_priming_meta$yi, money_priming_meta$vi)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
