<!DOCTYPE html><html lang="en"><head><title>Help for package apm</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {apm}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#apm-package'><p>apm: Averaged Prediction Models</p></a></li>
<li><a href='#apm_est'><p>Estimate ATTs from models fits</p></a></li>
<li><a href='#apm_mod'><p>Generate models used to fit outcomes</p></a></li>
<li><a href='#apm_pre'><p>Fit validation models to pre-treatment data</p></a></li>
<li><a href='#plot.apm_pre_fits'><p>Plot outputs of <code>apm_pre()</code></p></a></li>
<li><a href='#ptpdata'><p>Dataset on Annual Homicide Rates</p></a></li>
<li><a href='#robustness_bound'><p>Compute the robustness changepoint</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Averaged Prediction Models</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>In panel data settings, specifies set of candidate models, fits them to data from pre-treatment validation periods, and selects model as average over candidate models, weighting each by posterior probability of being most robust given its differential average prediction errors in pre-treatment validation periods. Subsequent estimation and inference of causal effect's bounds accounts for both model and sampling uncertainty, and calculates the robustness changepoint value at which bounds go from excluding to including 0. The package also includes a range of diagnostic plots, such as those illustrating models' differential average prediction errors and the posterior distribution of which model is most robust.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, ggplot2 (&ge; 3.5.1), ggh4x (&ge; 0.2.8), ggrepel (&ge;
0.9.6), MASS, sandwich, pbapply (&ge; 1.7-2), fwb (&ge; 0.3.0), chk
(&ge; 0.10.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>parallel, knitr, rmarkdown</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/tl2624/apm">https://github.com/tl2624/apm</a>, <a href="https://tl2624.github.io/apm/">https://tl2624.github.io/apm/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/tl2624/apm/issues">https://github.com/tl2624/apm/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-09 03:17:30 UTC; ThomasLeavitt</td>
</tr>
<tr>
<td>Author:</td>
<td>Thomas Leavitt <a href="https://orcid.org/0000-0002-3668-6409"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Laura Hatfield <a href="https://orcid.org/0000-0003-0366-3929"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Noah Greifer <a href="https://orcid.org/0000-0003-3067-7154"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Thomas Leavitt &lt;thomas.leavitt@baruch.cuny.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-10 16:50:17 UTC</td>
</tr>
</table>
<hr>
<h2 id='apm-package'>apm: Averaged Prediction Models</h2><span id='topic+apm'></span><span id='topic+apm-package'></span>

<h3>Description</h3>

<p>In panel data settings, specifies set of candidate models, fits them to data from pre-treatment validation periods, and selects model as average over candidate models, weighting each by posterior probability of being most robust given its differential average prediction errors in pre-treatment validation periods. Subsequent estimation and inference of causal effect's bounds accounts for both model and sampling uncertainty, and calculates the robustness changepoint value at which bounds go from excluding to including 0. The package also includes a range of diagnostic plots, such as those illustrating models' differential average prediction errors and the posterior distribution of which model is most robust.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Thomas Leavitt <a href="mailto:thomas.leavitt@baruch.cuny.edu">thomas.leavitt@baruch.cuny.edu</a> (<a href="https://orcid.org/0000-0002-3668-6409">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Laura Hatfield <a href="mailto:hatfield@hcp.med.harvard.edu">hatfield@hcp.med.harvard.edu</a> (<a href="https://orcid.org/0000-0003-0366-3929">ORCID</a>)
</p>
</li>
<li><p> Noah Greifer <a href="mailto:ngreifer@iq.harvard.edu">ngreifer@iq.harvard.edu</a> (<a href="https://orcid.org/0000-0003-3067-7154">ORCID</a>)
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/tl2624/apm">https://github.com/tl2624/apm</a>
</p>
</li>
<li> <p><a href="https://tl2624.github.io/apm/">https://tl2624.github.io/apm/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/tl2624/apm/issues">https://github.com/tl2624/apm/issues</a>
</p>
</li></ul>


<hr>
<h2 id='apm_est'>Estimate ATTs from models fits</h2><span id='topic+apm_est'></span><span id='topic+summary.apm_est'></span><span id='topic+plot.apm_est'></span>

<h3>Description</h3>

<p><code>apm_est()</code> computes the ATTs from the models previously fit by <code><a href="#topic+apm_pre">apm_pre()</a></code>, choosing the optimal one by minimizing the largest absolute average prediction error across validation times. Optionally, this process can be simulated to arrive at a distribution of ATTs that accounts for the uncertainty in selecting the optimal model. <code>plot()</code> plots the resulting ATT(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>apm_est(
  fits,
  post_time,
  M = 0,
  R = 1000L,
  all_models = FALSE,
  cl = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'apm_est'
summary(object, level = 0.95, M = NULL, ...)

## S3 method for class 'apm_est'
plot(x, label = TRUE, size.weights = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="apm_est_+3A_fits">fits</code></td>
<td>
<p>an <code>apm_pre_fits</code> object; the output of a call to <code><a href="#topic+apm_pre">apm_pre()</a></code>.</p>
</td></tr>
<tr><td><code id="apm_est_+3A_post_time">post_time</code></td>
<td>
<p>the value of the time variable considered post-treatment, for which the ATT is to be estimated.</p>
</td></tr>
<tr><td><code id="apm_est_+3A_m">M</code></td>
<td>
<p>the sensitivity parameter for set identification. For <code>apm_est()</code>, the default is 0, i.e., under point identification. For <code>summary()</code>, this can be set to one or more positive values to produce uncertainty bounds for each value. Only allowed when not set to 0 in the call to <code>apm_est()</code>. See Details.</p>
</td></tr>
<tr><td><code id="apm_est_+3A_r">R</code></td>
<td>
<p>the number of bootstrap iterations used to compute the sampling variance of the ATT. Default is 1000. More is better but takes longer.</p>
</td></tr>
<tr><td><code id="apm_est_+3A_all_models">all_models</code></td>
<td>
<p><code>logical</code>; whether to compute ATTs for all models (<code>TRUE</code>) or just those with BMA weights greater than 0 (<code>FALSE</code>, default). This will not effect the final estimates but leaving as <code>FALSE</code> can speed up computation when some models have BMA weights of 0.</p>
</td></tr>
<tr><td><code id="apm_est_+3A_cl">cl</code></td>
<td>
<p>a cluster object created by <code><a href="parallel.html#topic+makeCluster">parallel::makeCluster()</a></code>, an integer to indicate number of child-processes (ignored on Windows) for parallel evaluations, or <code>"future"</code> to use a future backend. <code>NULL</code> (default) refers to sequential evaluation. See <code><a href="fwb.html#topic+fwb">fwb::fwb()</a></code> for details and issues related to replicability.</p>
</td></tr>
<tr><td><code id="apm_est_+3A_verbose">verbose</code></td>
<td>
<p><code>logical</code>; whether to print information about the progress of the estimation, including a progress bar. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="apm_est_+3A_...">...</code></td>
<td>
<p>other arguments passed to <code><a href="fwb.html#topic+fwb">fwb::fwb()</a></code>.</p>
</td></tr>
<tr><td><code id="apm_est_+3A_level">level</code></td>
<td>
<p>the desired confidence level. Set to 0 to ignore sampling variation in computing the interval bounds. Default is .95.</p>
</td></tr>
<tr><td><code id="apm_est_+3A_x">x</code>, <code id="apm_est_+3A_object">object</code></td>
<td>
<p>an <code>apm_est</code> object; the output of a call to <code>apm_est()</code>.</p>
</td></tr>
<tr><td><code id="apm_est_+3A_label">label</code></td>
<td>
<p><code>logical</code>; whether to label the ATT estimates. Requires <span class="pkg">ggrepel</span> to be installed. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="apm_est_+3A_size.weights">size.weights</code></td>
<td>
<p><code>logicsl</code>; whether to size the points based on their BMA weights. Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>apm_est()</code> estimates the ATT from each model and combines them to form the BMA-weighted estimate of the ATT. Uncertainty for the BMA-weighted ATT is computed by combining two variance components, one that account for sampling and another that accounts for model selection. The component due to sampling is computed by bootstrapping the process of fitting the outcome model for the post-treatment outcome identified by <code>post_time</code> and computing the difference between the observed outcome mean difference and the model-predicted outcome mean difference. The fractional weighted bootstrap as implemented in <code><a href="fwb.html#topic+fwb">fwb::fwb()</a></code> is used to ensure no units are dropped from the analysis. In each bootstrap sample, the BMA-weighted ATT estimate is computed as the weighted average of the ATTs computed from the models using the fixed BMA weights computed by <code><a href="#topic+apm_pre">apm_pre()</a></code>, and the variance is computed as the empirical variance over the bootstrapped estimates. The variance component due to model selection is computed as the BMA-weighted variance of the original ATTs.
</p>
<p>When <code>M</code> is greater than 0, bounds for set identification and their uncertainty are additionally computed. This involves bootstrapping the fitting of the pre-period models along with post-treatment models on order to compute the maximum absolute difference in average prediction errors for each model across validation periods. Each bootstrap sample produces a margin of error for each model computed as <code class="reqn">M \times \delta_m</code> where <code class="reqn">\delta_m</code> is the maximum absolute difference in average prediction errors for model <code class="reqn">m</code>. Upper and lower bounds for the set-identified BMA-weighted ATT are computed as <code class="reqn">\text{ATT}_m \pm M \times \delta_m</code>. The same procedure as above is then used to compute the variance of these bounds.
</p>
<p><code>summary()</code> displays the BMA-weighted ATT estimate, its standard error, and Wald confidence intervals. When <code>M</code> is greater than 0, bounds for the set-identified ATT are displayed in the confidence interval bound columns. The lower bound is computed as <code class="reqn">\text{LB} - \sigma_{LB}Z_{l}</code> and the upper bound as <code class="reqn">\text{UB} + \sigma_{UB}Z_{l}</code>, where <code class="reqn">\text{LB}</code> and <code class="reqn">\text{UB}</code> are the lower and upper bounds, <code class="reqn">\sigma_{LB}</code> and <code class="reqn">\sigma_{UB}</code> are their variances accounting for sampling and model selection, and <code class="reqn">Z_{l}</code> is the critical Z-statistic for confidence level <code class="reqn">l</code>. To display the set-identification bounds themselves, one should set <code>level = 0</code>.
</p>


<h3>Value</h3>

<p><code>apm_est()</code> returns an <code>apm_est</code> object, which contains the ATT estimates and their variance estimates. The following components are included:
</p>

<dl>
<dt>BMA_att</dt><dd><p>the BMA-weighted ATT</p>
</dd>
<dt>atts</dt><dd><p>a 1-column matrix containing the ATT estimates from each model (when <code>all_models = FALSE</code>, only models with positive BMA weights are included)</p>
</dd>
<dt>BMA_var</dt><dd><p>the total variance estimate for the BMA-weighted ATT incorporating the variance due to sampling and due to model selection</p>
</dd>
<dt>BMA_var_b</dt><dd><p>the bootstrap-based component of the variance estimate for the BMA-weighted ATT due to sampling</p>
</dd>
<dt>BMA_var_m</dt><dd><p>the component of the variance estimate for the BMA-weighted ATT due to model selection</p>
</dd>
<dt>M</dt><dd><p>the value of the sensitivity parameter <code>M</code></p>
</dd>
<dt>post_time</dt><dd><p>the value supplied to <code>post_time</code></p>
</dd>
<dt>observed_means</dt><dd><p>a matrix of the observed outcome means at each pre-treatment validation period</p>
</dd>
<dt>pred_errors</dt><dd><p>an array containing the average prediction errors for each model and each pre-treatment validation period</p>
</dd>
<dt>pred_error_diffs</dt><dd><p>a matrix containing the difference in average prediction errors between groups for each model and each pre-treatment validation period</p>
</dd>
<dt>BMA_weights</dt><dd><p>the BMA weights computed by <code>apm_pre()</code> (when <code>all_models = FALSE</code>, only positive BMA weights are included)</p>
</dd>
<dt>boot_out</dt><dd><p>an <code>fwb</code> object containing the bootstrap results</p>
</dd>
</dl>

<p><code>plot()</code> returns a <code>ggplot</code> object displaying the ATT for each model plotted against the maximum absolute difference in average prediction errors for that model. The model with the lowest maximum absolute difference in average prediction errors is displayed in red.
</p>
<p><code>summary()</code> produces a table with the BMA-weighted ATT, it's estimated standard error, and confidence interval limits. When <code>M</code> is greater than 0, additional rows for each value of <code>M</code> are included with the lower and upper bound. When <code>level</code> is greater than 0, these bounds include the uncertainty due to sampling and model selection; otherwise, they correspond to the set identification bounds for the ATT.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+apm_pre">apm_pre()</a></code> for computing the BMA weights; <code><a href="fwb.html#topic+fwb">fwb::fwb()</a></code> for the fractional weighted bootstrap.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("ptpdata")

# Combination of 4 models: 2 time trends, 2 lags
models &lt;- apm_mod(list(crude_rate ~ 1),
                  lag = 0:1,
                  time_trend = 0:1)
models

# Fit the models to data; unit_var must be supplied for
# fixed effects
fits &lt;- apm_pre(models,
                data = ptpdata,
                group_var = "group",
                time_var = "year",
                val_times = 2004:2007,
                unit_var = "state",
                nsim = 100,
                verbose = FALSE)

est &lt;- apm_est(fits,
               post_time = 2008,
               M = 1,
               R = 20,
               verbose = FALSE)

est

# ATT estimate and bounds for M = 1
summary(est)

# Bounds for other values of M
summary(est, M = c(.5, 1, 1.5, 2))

# Set-ID bounds without uncertainty
summary(est, level = 0)

plot(est)
</code></pre>

<hr>
<h2 id='apm_mod'>Generate models used to fit outcomes</h2><span id='topic+apm_mod'></span>

<h3>Description</h3>

<p><code>apm_mod()</code> generates a list of models characterized by a basic model formulas and other options (e.g., lags, families, etc.) that are supplied to <code><a href="#topic+apm_pre">apm_pre()</a></code>. These values are completely crossed to create a grid of model specifications, and multiple sets of model specifications can be combined using <code>c()</code> (see Examples).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>apm_mod(
  formula_list,
  family = "gaussian",
  lag = 0L,
  diff_k = 0L,
  log = FALSE,
  time_trend = 0L,
  fixef = FALSE,
  identiy_only_log = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="apm_mod_+3A_formula_list">formula_list</code></td>
<td>
<p>a list of model formulas with the outcome on the left side and predictions (or just an intercept) on the right side.</p>
</td></tr>
<tr><td><code id="apm_mod_+3A_family">family</code></td>
<td>
<p>a list of family specifications; see <code><a href="stats.html#topic+family">family()</a></code> for allowable options. These will eventually be passed to <code><a href="stats.html#topic+glm">glm()</a></code> when fitting the models in <code><a href="#topic+apm_pre">apm_pre()</a></code>. <code>"negbin"</code> can also be supplied to request a negative binomial model with a log link fit using <code><a href="MASS.html#topic+glm.nb">MASS::glm.nb()</a></code>. Default is <code>"gaussian"</code> to specify a linear model.</p>
</td></tr>
<tr><td><code id="apm_mod_+3A_lag">lag</code></td>
<td>
<p>a vector of integers indicating the desired outcome lags to be used as predictors. For example, a <code>lag</code> value of 3 means the outcome lagged once, twice, and three times will be included as predictors. Default is 0 for no lags.</p>
</td></tr>
<tr><td><code id="apm_mod_+3A_diff_k">diff_k</code></td>
<td>
<p>a vector of integers indicating the desired outcome lag to be used a an offset For example, a <code>diff_k</code> value of 1 means the prior time point's outcome will be included as an offset, equivalent to using the outcome minus its corresponding lag as the outcome of the corresponding model. Default is 0 for no lags. Any models with a <code>diff_k</code> value less than a <code>lag</code> value will be removed automatically. When used with a family with a log link, the lags are automatically log-transformed; an error will be thrown by <code>apm_pre()</code> if nonpositive values are present in the outcome.</p>
</td></tr>
<tr><td><code id="apm_mod_+3A_log">log</code></td>
<td>
<p>a logical vector indicating whether the outcome should be log-transformed. Default is <code>FALSE</code> to use the original outcome. When <code>lag</code> or <code>diff_k</code> are greater than 0, the outcome lags will also be log-transformed if <code>TRUE</code>. When the family has a log link and <code>diff_k</code> is greater than zero, the lag in the offset will be log transformed.</p>
</td></tr>
<tr><td><code id="apm_mod_+3A_time_trend">time_trend</code></td>
<td>
<p>a vector of integers indicating the desired powers to be included in a time trend. For example, a <code>time_trend</code> value of 2 means the time variable and its square will be included as predictors in the model. A value of 0 (the default) means time is not included as a predictor.</p>
</td></tr>
<tr><td><code id="apm_mod_+3A_fixef">fixef</code></td>
<td>
<p>a logical vector indicating whether unit fixed effects should be included as predictors. Default is <code>FALSE</code> to omit unit fixed effects.</p>
</td></tr>
<tr><td><code id="apm_mod_+3A_identiy_only_log">identiy_only_log</code></td>
<td>
<p><code>logical</code>; whether to omit any models in which <code>log</code> is <code>TRUE</code> but the link in the <code>family</code> specification corresponds to something other than <code>"identity"</code>. Default is <code>TRUE</code>, and this should probably not be changed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <code>apm_models</code> object, which is a list containing the full cross (less any omitted combinations) of the model features specified in the arguments, with each combination a list. These have a <code>print()</code> method and can be combined using <code>c()</code>. Each model is named automatically, but these can be set manually using <code><a href="base.html#topic+names">names()</a></code> as well. Models can be removed by setting their value to <code>NULL</code>; see Examples.
</p>


<h3>See Also</h3>

<p><a href="stats.html#topic+formula">formula</a>, <a href="stats.html#topic+family">family</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("ptpdata")

# Combination of 8 models: 1 baseline formulas,
# 2 families, 2 lags, 2 time trends
models1 &lt;- apm_mod(crude_rate ~ 1,
                   family = list("gaussian", "quasipoisson"),
                   time_trend = 0:1,
                   lag = 0:1, fixef = TRUE)
models1

# Add a single other model with a square time trend
models2 &lt;- apm_mod(crude_rate ~ 1,
                   family = "gaussian",
                   time_trend = 2,
                   fixef = FALSE)
models2

(models &lt;- c(models1, models2))

# Remove a model
models[[4]] &lt;- NULL
models
</code></pre>

<hr>
<h2 id='apm_pre'>Fit validation models to pre-treatment data</h2><span id='topic+apm_pre'></span><span id='topic+summary.apm_pre_fits'></span>

<h3>Description</h3>

<p><code>apm_pre()</code> fits models to the pre-treatment data to compute the observed prediction errors for each model in each period and compute the Bayesian model averaging (BMA) weights eventually used in <code><a href="#topic+apm_est">apm_est()</a></code> to estimate the treatment effect.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>apm_pre(
  models,
  data,
  weights = NULL,
  group_var,
  time_var,
  val_times,
  unit_var,
  nsim = 1000L,
  cl = NULL,
  verbose = TRUE
)

## S3 method for class 'apm_pre_fits'
summary(object, order = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="apm_pre_+3A_models">models</code></td>
<td>
<p>an <code>apm_models</code> object; the output of a call to <code><a href="#topic+apm_mod">apm_mod()</a></code>.</p>
</td></tr>
<tr><td><code id="apm_pre_+3A_data">data</code></td>
<td>
<p>a dataset containing all the variables named in the supplied models (i.e., the outcome and any predictors) as well as any variable named below.</p>
</td></tr>
<tr><td><code id="apm_pre_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights (e.g., sampling weights) used to fit weighted regression models.</p>
</td></tr>
<tr><td><code id="apm_pre_+3A_group_var">group_var</code></td>
<td>
<p>string; the name of the treatment variable in <code>data</code> defining the &quot;to be treated&quot; and &quot;not to be treated&quot; groups. The corresponding variable should take on values of 0 and 1 only.</p>
</td></tr>
<tr><td><code id="apm_pre_+3A_time_var">time_var</code></td>
<td>
<p>string; the name of the variable in <code>data</code> containing the time variable.</p>
</td></tr>
<tr><td><code id="apm_pre_+3A_val_times">val_times</code></td>
<td>
<p>a numeric vector corresponding to the pre-treatment times that will be used as validation times when select the model with the optimal average expected prediction error.</p>
</td></tr>
<tr><td><code id="apm_pre_+3A_unit_var">unit_var</code></td>
<td>
<p>string; the name of the unit ID variable in <code>data</code>.</p>
</td></tr>
<tr><td><code id="apm_pre_+3A_nsim">nsim</code></td>
<td>
<p>the number of simulated draws from the joint posterior of the fitted models to use to compute the BMA weights. Default is 1000. More is better but takes longer.</p>
</td></tr>
<tr><td><code id="apm_pre_+3A_cl">cl</code></td>
<td>
<p>a cluster object created by <code><a href="parallel.html#topic+makeCluster">parallel::makeCluster()</a></code>, or an integer to indicate number of child-processes (integer values are ignored on Windows) for parallel evaluations. It can also be <code>"future"</code> to use a future backend. <code>NULL</code> (default) refers to sequential evaluation. See the <code>cl</code> argument of <code><a href="pbapply.html#topic+pbapply">pbapply::pblapply()</a></code> for details.</p>
</td></tr>
<tr><td><code id="apm_pre_+3A_verbose">verbose</code></td>
<td>
<p><code>logical</code>; whether to print information about the progress of the estimation, including a progress bar. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="apm_pre_+3A_object">object</code></td>
<td>
<p>an <code>apm_pre_fit</code> object; the output of a call to <code>apm_pre()</code>.</p>
</td></tr>
<tr><td><code id="apm_pre_+3A_order">order</code></td>
<td>
<p>how to order the summary; <code>NULL</code> (the default) is the same ordering as the models supplied to <code>apm_pre()</code>, <code>"weights"</code> orders the models by their computed BMA weights with the highest weights on top, and <code>"errors"</code> orders the models by their maximum absolute difference in prediction errors with the smallest errors on top.</p>
</td></tr>
<tr><td><code id="apm_pre_+3A_...">...</code></td>
<td>
<p>ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>apm_pre()</code> creates a grid of all models and all time points and fits all corresponding models. For each validation time supplied to <code>val_times</code>, each model is fit using all previous times. For example, for a validation time of 5, a model is fit with data only from periods 1-4.
</p>
<p><code><a href="stats.html#topic+lm">lm()</a></code>, <code><a href="stats.html#topic+glm">glm()</a></code>, or <code><a href="MASS.html#topic+glm.nb">MASS::glm.nb()</a></code> are used to fit the given models. The joint covariance matrix of all the coefficients is computed using the SUEST method described in Mize et al. (2019, p164), which is also used by the STATA command <code>suest</code>. This is equivalent to the covariance matrix computed by stacking the score equations for the models and fitting them using M-estimation and yields the equivalent of the HC0 covariance matrix for all within-model covariances. The covariance is clustered by <code>unit_id</code>.
</p>
<p>To compute the BMA weights, random variate drawn from a multivariate normal distribution <code>nsim</code> times with mean vector equal to the concatenated model coefficients and covariance equal to the joint covariance matrix described above. For each iteration, the absolute average prediction errors are calculated for each model and validation period. A model is considered the &quot;winner&quot; if it its largest absolute average prediction error across validation periods is the smallest among all models. The BMA weight for each model is equal to the proportion of iterations in which that model was the &quot;winner&quot;.
</p>


<h3>Value</h3>

<p><code>apm_pre()</code> returns an <code>apm_pre_fits</code> object, which is a list containing the models supplied to <code>models</code>, a grid of all fitted models, a list of all model fit objects, a list of all estimated coefficients, the joint covariance of the coefficients, the dataset supplied to <code>data</code>, and other components supplied to <code>apm_pre()</code>.
</p>
<p><code>summary()</code> produces a data frame containing the BMA weights and maximum absolute difference in mean prediction errors for each model, ordered according <code>order</code>. An asterisk appears next to the model with the smallest error.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm()</a></code>,<code><a href="stats.html#topic+glm">glm()</a></code>, and <code><a href="MASS.html#topic+glm.nb">MASS::glm.nb()</a></code> for the functions used to fit the models; <code><a href="#topic+apm_est">apm_est()</a></code> to compute the ATT and its uncertainty; <code><a href="#topic+plot.apm_pre_fits">plot.apm_pre_fits()</a></code> for plotting an <code>apm_pre_fits</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("ptpdata")

# Combination of 8 models: 2 baseline formulas,
# 2 families, 2 lags
models &lt;- apm_mod(crude_rate ~ 1,
                  family = list("gaussian", "quasipoisson"),
                  time_trend = 0:1,
                  lag = 0:1)
models

# Fit the models to data
fits &lt;- apm_pre(models, data = ptpdata,
                group_var = "group",
                time_var = "year",
                val_times = 1999:2007,
                unit_var = "state",
                nsim = 200,
                verbose = FALSE)

fits

summary(fits)

plot(fits, type = "weights")

plot(fits, type = "error")
</code></pre>

<hr>
<h2 id='plot.apm_pre_fits'>Plot outputs of <code>apm_pre()</code></h2><span id='topic+plot.apm_pre_fits'></span>

<h3>Description</h3>

<p><code>plot()</code> displays the Bayesian model averaging (BMA) weights for each model (computed by <code>apm_fit()</code> as the posterior probability of selection) and the distribution of the difference in average prediction errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'apm_pre_fits'
plot(
  x,
  type = "weights",
  abs = TRUE,
  ncol = 4L,
  clip_at = 15,
  model = ".optimal",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.apm_pre_fits_+3A_x">x</code></td>
<td>
<p>an <code>apm_pre_fits</code> object; the output of a call to <code><a href="#topic+apm_pre">apm_pre()</a></code>.</p>
</td></tr>
<tr><td><code id="plot.apm_pre_fits_+3A_type">type</code></td>
<td>
<p>which values to plot: allowable options include <code>"weights"</code> to plot the BMA weights/posterior probabilities (default), <code>"errors"</code> to plot the difference in average predictions errors for all models across validation periods, <code>"predict"</code> to plot the time series and model predictions for each model, and <code>"corrected"</code> to plot the corrected predictions for the treated group for each model. Abbreviations allowed.</p>
</td></tr>
<tr><td><code id="plot.apm_pre_fits_+3A_abs">abs</code></td>
<td>
<p><code>logical</code>; when <code>type = "errors"</code>, whether to plot the differences in average prediction errors in absolute value (<code>TRUE</code>, default) or not (<code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="plot.apm_pre_fits_+3A_ncol">ncol</code></td>
<td>
<p>when <code>type</code> is <code>"errors"</code>, <code>"predict"</code>, or <code>"corrected"</code>, the number of columns to use to display the plots. Default is 4.</p>
</td></tr>
<tr><td><code id="plot.apm_pre_fits_+3A_clip_at">clip_at</code></td>
<td>
<p>when <code>type = "errors"</code>, the value (in robust z-score units) at which to clip the y-axis of the plot to prevent outliers from distorting it. Default is 15. Set to <code>Inf</code> to prevent clipping.</p>
</td></tr>
<tr><td><code id="plot.apm_pre_fits_+3A_model">model</code></td>
<td>
<p>string; when <code>type = "predict"</code> or <code>type = "corrected"</code>, the model(s) to plot. Allowable values include <code>".optimal"</code> to plot the model with the smallest maximum absolute difference in average prediction errors, <code>".all"</code> to plot all models (excluding the BMA-weighted predictions), or the names of one or more specific models. Abbreviations allowed.</p>
</td></tr>
<tr><td><code id="plot.apm_pre_fits_+3A_...">...</code></td>
<td>
<p>ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code>type = "weights"</code>, <code>plot()</code> displays a bar plot with a bar for each model with height equal to the BMA weight/posterior probability of selection for that model. (Note that the plot margins can sometimes cut off the model names; use <code>theme(plot.margins =)</code> after loading <code>ggplot2</code> to extend the left margin of the plot to ensure all text is visible. Alternatively, the axis text can be rotated using <code>theme(axis.text.x =)</code>.)
</p>
<p>When <code>type = "errors"</code>, <code>plot()</code> displays a lattice of bar plots with a plot for each model displaying the difference in average prediction errors for each validation period. The period with the largest difference in average prediction errors will be shaded black. The model with the smallest maximum absolute difference in average prediction errors will have a gray label.
</p>
<p>When <code>type = "predict"</code>, <code>plot()</code> displays a lattice of line plots with a plot for each model displaying the observed and predicted outcomes for each validation period under each model. The observed outcomes are displayed as points, while the predicted outcomes are displayed as lines.
</p>
<p>When <code>type = "corrected"</code>, <code>plot()</code> displays a lattice of line plots with a plot for each model displaying the observed and corrected predictions for the treated group for each validation period under each model. The observed outcomes are displayed as points, while the corrected predictions are displayed as lines. Corrected predictions are computed as the observed outcome in the treated group minus the prediction error in the treated group plus the prediction error in the control group.
</p>


<h3>Value</h3>

<p>A <code>ggplot</code> object, which can be manipulated using <code>ggplot2</code> syntax (after loading <code>ggplot2</code>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+apm_pre">apm_pre()</a></code> to to compute the difference in average prediction errors and BMA weights; <code><a href="ggplot2.html#topic+geom_bar">ggplot2::geom_col()</a></code>, which is used to create the plots.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("ptpdata")

# Combination of 8 models: 2 baseline formulas,
# 2 families, 2 lags
models &lt;- apm_mod(crude_rate ~ 1,
                  family = "gaussian",
                  time_trend = 0:1,
                  lag = 0:1,
                  diff_k = 0:1)
models

# Fit the models to data
fits &lt;- apm_pre(models, data = ptpdata,
                group_var = "group",
                time_var = "year",
                val_times = 1999:2007,
                unit_var = "state",
                nsim = 50,
                verbose = FALSE)
fits

plot(fits, type = "weights")

plot(fits, type = "error", ncol = 2)

plot(fits, type = "predict", model = ".optimal")

plot(fits, type = "corrected", model = ".optimal")
</code></pre>

<hr>
<h2 id='ptpdata'>Dataset on Annual Homicide Rates</h2><span id='topic+ptpdata'></span>

<h3>Description</h3>

<p>A dataset of homicide rates across 9 states from 1994 to 2008. Missouri repealed its permit-to-purchase (PTP) law in 2007.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ptpdata
</code></pre>


<h3>Format</h3>

<p>A dataframe of 7 variables with 135 observations (9 states, 15 years).
</p>


<h3>Details</h3>

<div class="sourceCode"><pre>details for dataset2
</pre></div>

<dl>
<dt>state</dt><dd><p>the name of the state; states present include Arkansas, Illinois, Iowa, Kansas, Kentucky, Missouri, Nebraska, Oklahoma, and Tennessee.</p>
</dd>
<dt>year</dt><dd><p>the year of each observation. Years range from 1994 to 2008.</p>
</dd>
<dt>deaths</dt><dd><p>the number of homicide deaths in the corresponding state in the corresponding year.</p>
</dd>
<dt>crude_rate</dt><dd><p>the homicide rate in the corresponding state in the corresponding year.</p>
</dd>
<dt>age_adj_rate</dt><dd><p>the age-adjusted homicide rate in the corresponding state in the corresponding year.</p>
</dd>
<dt>group</dt><dd><p>whether each observation belongs to the &quot;to-be-treated&quot; group; 1 for Missouri and 0 for all other states.</p>
</dd>
<dt>treat</dt><dd><p>whether each observation is treated; 1 for Missouri in 2008 and 0 otherwise.</p>
</dd>
</dl>


<hr>
<h2 id='robustness_bound'>Compute the robustness changepoint</h2><span id='topic+robustness_bound'></span>

<h3>Description</h3>

<p><code>robustness_bound()</code> computes the value of the sensitivity parameter M at which the robustness bounds change from excluding to including an ATT of 0.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>robustness_bound(object, level = 0.95)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="robustness_bound_+3A_object">object</code></td>
<td>
<p>an <code>apm_est</code> object; the output of a call to <code><a href="#topic+apm_est">apm_est()</a></code>. <code>M</code> must have been set to a nonzero value to use <code>robustness_bound()</code>.</p>
</td></tr>
<tr><td><code id="robustness_bound_+3A_level">level</code></td>
<td>
<p>the desired confidence level. Set to 0 to ignore sampling variation in computing the interval bounds. Default is .95.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A single number corresponding to the changepoint value of M. If there is no positive value of M for which the interval bounds cross 0, <code>NA</code> will be returned.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.apm_est">summary.apm_est()</a></code> for examining the ATT and bounds for a given value of <code>M</code>; <code><a href="stats.html#topic+uniroot">uniroot()</a></code> for the function that finds the changepoint value of <code>M</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("ptpdata")

# Combination of 4 models: 2 time trends, 2 lags
models &lt;- apm_mod(list(crude_rate ~ 1),
                  lag = 0:1,
                  time_trend = 0:1)
models

# Fit the models to data; unit_var must be supplied for
# fixed effects
fits &lt;- apm_pre(models,
                data = ptpdata,
                group_var = "group",
                time_var = "year",
                val_times = 2004:2007,
                unit_var = "state",
                nsim = 100,
                verbose = FALSE)

est &lt;- apm_est(fits,
               post_time = 2008,
               M = 1,
               R = 20,
               verbose = FALSE)

est

# ATT estimate and bounds for M = 1
summary(est)

#Changepoint value of M ignoring estimation uncertainty
(M &lt;- robustness_bound(est, level = 0))

summary(est, level = 0, M = M)

#Changepoint value of M accounting for estimation uncertainty
(M &lt;- robustness_bound(est, level = .95))

summary(est, level = .95, M = M)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
