<!DOCTYPE html><html><head><title>Help for package zoomerjoin</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {zoomerjoin}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#zoomerjoin-package'><p>zoomerjoin: Superlatively Fast Fuzzy Joins</p></a></li>
<li><a href='#dime_data'><p>Donors from DIME Database</p></a></li>
<li><a href='#em_link'><p>Fit a Probabilistic Matching Model using Naive Bayes + E.M.</p></a></li>
<li><a href='#euclidean_anti_join'><p>Spatial Anti Join Using LSH</p></a></li>
<li><a href='#euclidean_curve'><p>Plot S-Curve for a LSH with given hyperparameters</p></a></li>
<li><a href='#euclidean_full_join'><p>Spatial Full Join Using LSH</p></a></li>
<li><a href='#euclidean_inner_join'><p>Spatial Inner Join Using LSH</p></a></li>
<li><a href='#euclidean_left_join'><p>Spatial Left Join Using LSH</p></a></li>
<li><a href='#euclidean_probability'><p>Find Probability of Match Based on Similarity</p></a></li>
<li><a href='#euclidean_right_join'><p>Spatial Right Join Using LSH</p></a></li>
<li><a href='#jaccard_anti_join'><p>Fuzzy anti-join using minihashing</p></a></li>
<li><a href='#jaccard_curve'><p>Plot S-Curve for a LSH with given hyperparameters</p></a></li>
<li><a href='#jaccard_full_join'><p>Fuzzy full-join using minihashing</p></a></li>
<li><a href='#jaccard_hyper_grid_search'><p>Help Choose the Appropriate LSH Hyperparameters</p></a></li>
<li><a href='#jaccard_inner_join'><p>Fuzzy inner-join using minihashing</p></a></li>
<li><a href='#jaccard_left_join'><p>Fuzzy left-join using minihashing</p></a></li>
<li><a href='#jaccard_probability'><p>Find Probability of Match Based on Similarity</p></a></li>
<li><a href='#jaccard_right_join'><p>Fuzzy right-join using minihashing</p></a></li>
<li><a href='#jaccard_similarity'><p>Calculate jaccard_similarity of two character vectors</p></a></li>
<li><a href='#jaccard_string_group'><p>Fuzzy String Grouping Using Minhashing</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Superlatively Fast Fuzzy Joins</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.4</td>
</tr>
<tr>
<td>Description:</td>
<td>Empowers users to fuzzily-merge data frames with millions or tens of millions of rows in minutes with low memory usage.  The package uses the locality sensitive hashing algorithms developed by Datar, Immorlica, Indyk and Mirrokni (2004) &lt;<a href="https://doi.org/10.1145%2F997817.997857">doi:10.1145/997817.997857</a>&gt;, and Broder (1998) &lt;<a href="https://doi.org/10.1109%2FSEQUEN.1997.666900">doi:10.1109/SEQUEN.1997.666900</a>&gt; to avoid having to compare every pair of records in each dataset, resulting in fuzzy-merges that finish in linear time.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.0</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>Cargo (&gt;= 1.56) (Rust's package manager), rustc</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, tibble, tidyr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>babynames, covr, fuzzyjoin, igraph, knitr, rmarkdown,
stringdist, testthat (&ge; 3.0.0), tidyverse, purrr,
microbenchmark, profmem</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://beniamino.org/zoomerjoin/">https://beniamino.org/zoomerjoin/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/beniaminogreen/zoomerjoin/issues/">https://github.com/beniaminogreen/zoomerjoin/issues/</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>LazyDataCompression:</td>
<td>xz</td>
</tr>
<tr>
<td>Config/rextendr/version:</td>
<td>0.3.1.9000</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-29 01:44:30 UTC; beniamino</td>
</tr>
<tr>
<td>Author:</td>
<td>Beniamino Green [aut, cre, cph],
  Etienne Bacher [ctb],
  The authors of the dependency Rust crates [ctb, cph] (see inst/AUTHORS
    file for details)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Beniamino Green &lt;beniamino.green@yale.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-31 15:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='zoomerjoin-package'>zoomerjoin: Superlatively Fast Fuzzy Joins</h2><span id='topic+zoomerjoin'></span><span id='topic+zoomerjoin-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>Empowers users to fuzzily-merge data frames with millions or tens of millions of rows in minutes with low memory usage. The package uses the locality sensitive hashing algorithms developed by Datar, Immorlica, Indyk and Mirrokni (2004) <a href="https://doi.org/10.1145/997817.997857">doi:10.1145/997817.997857</a>, and Broder (1998) <a href="https://doi.org/10.1109/SEQUEN.1997.666900">doi:10.1109/SEQUEN.1997.666900</a> to avoid having to compare every pair of records in each dataset, resulting in fuzzy-merges that finish in linear time.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Beniamino Green <a href="mailto:beniamino.green@yale.edu">beniamino.green@yale.edu</a> [copyright holder]
</p>
<p>Other contributors:
</p>

<ul>
<li><p> Etienne Bacher <a href="mailto:etienne.bacher@protonmail.com">etienne.bacher@protonmail.com</a> [contributor]
</p>
</li>
<li><p> The authors of the dependency Rust crates (see inst/AUTHORS file for details) [contributor, copyright holder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://beniamino.org/zoomerjoin/">https://beniamino.org/zoomerjoin/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/beniaminogreen/zoomerjoin/issues/">https://github.com/beniaminogreen/zoomerjoin/issues/</a>
</p>
</li></ul>


<hr>
<h2 id='dime_data'>Donors from DIME Database</h2><span id='topic+dime_data'></span>

<h3>Description</h3>

<p>A set of donor names from the Database on Ideology, Money in Politics, and
Elections (DIME).  This dataset was used as a benchmark in the 2021 APSR
paper Adaptive Fuzzy String Matching: How to Merge Datasets with Only One
(Messy) Identifying Field by Aaron R. Kaufman and Aja Klevs, the dataset in
this package is a subset of the data from the replication archive of that
paper. The full dataset can be found in the paper's replication materials
here: <a href="https://doi.org/10.7910/DVN/4031UL">doi:10.7910/DVN/4031UL</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dime_data
</code></pre>


<h3>Format</h3>



<h4><code>dime_data</code></h4>

<p>A data frame with 10,000 rows and 2 columns:
</p>

<dl>
<dt>id</dt><dd><p>Numeric ID / Row Number</p>
</dd>
<dt>x</dt><dd><p>Donor Name</p>
</dd>
</dl>
<p>...
#' @source <a href="https://www.who.int/teams/global-tuberculosis-programme/data">https://www.who.int/teams/global-tuberculosis-programme/data</a>
</p>



<h3>Author(s)</h3>

<p>Adam Bonica
</p>


<h3>References</h3>

<p><a href="https://doi.org/10.7910/DVN/4031UL">doi:10.7910/DVN/4031UL</a>
</p>

<hr>
<h2 id='em_link'>Fit a Probabilistic Matching Model using Naive Bayes + E.M.</h2><span id='topic+em_link'></span>

<h3>Description</h3>

<p>A Rust implementation of the Naive Bayes / Fellegi-Sunter model of record
linkage as detailed in the article &quot;Using a Probabilistic Model to Assist
Merging of Large-Scale Administrative Records&quot; by Enamorado, Fifield and
Imai (2019). Takes an integer matrix describing the similarities between
each possible pair of observations, and a vector of initial guesses of the
probability each pair is a match (these can either be set from domain
knowledge, or one can hand-label a subset of the data and leave the rest as
p=.5). Iteratively refines these guesses using the Expectation Maximization
algorithm until an optima is reached. for more details, see
<a href="https://doi.org/10.1017/S0003055418000783">doi:10.1017/S0003055418000783</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>em_link(X, g, tol = 10^-6, max_iter = 10^3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="em_link_+3A_x">X</code></td>
<td>
<p>an integer matrix of similarities. Must go from 0 (the most
disagreement) to the maximum without any &quot;gaps&quot; or unused levels. As an
example, a column with values 0,1,2,3 is a valid column, but 0,1,2,4 is not
as three is omitted</p>
</td></tr>
<tr><td><code id="em_link_+3A_g">g</code></td>
<td>
<p>a vector of initial guesses that are iteratively improved using the
EM algorithm (my personal approach is to guess at logistic regression
coefficients and use them to create the intitial probability guesses). This
is chosen to avoid the model getting stuck in a local optimum, and to avoid
the problem of label-switching, where the labels for matches and non-matches
are reversed.</p>
</td></tr>
<tr><td><code id="em_link_+3A_tol">tol</code></td>
<td>
<p>tolerance in the sense of the infinity norm. i.e. how close the
parameters have to be between iterations before the EM algorithm terminates.</p>
</td></tr>
<tr><td><code id="em_link_+3A_max_iter">max_iter</code></td>
<td>
<p>iterations after which the algorithm will error out if it
has not converged.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of probabilities representing the posterior probability
each record pair is a match.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
inv_logit &lt;- function (x) {
   exp(x)/(1+exp(x))
}
n &lt;- 10^6
d &lt;- 1:n %% 5 == 0
X &lt;- cbind(
        as.integer(ifelse(d, runif(n)&lt;.8, runif(n)&lt;.2)),
        as.integer(ifelse(d, runif(n)&lt;.9, runif(n)&lt;.2)),
        as.integer(ifelse(d, runif(n)&lt;.7, runif(n)&lt;.2)),
        as.integer(ifelse(d, runif(n)&lt;.6, runif(n)&lt;.2)),
        as.integer(ifelse(d, runif(n)&lt;.5, runif(n)&lt;.2)),
        as.integer(ifelse(d, runif(n)&lt;.1, runif(n)&lt;.9)),
        as.integer(ifelse(d, runif(n)&lt;.1, runif(n)&lt;.9)),
        as.integer(ifelse(d, runif(n)&lt;.8, runif(n)&lt;.01))
        )

# inital guess at class assignments based on # a hypothetical logistic
# regression. Should be based on domain knowledge, or a handful of hand-coded
# observations.

x_sum &lt;- rowSums(X)
g &lt;- inv_logit((x_sum - mean(x_sum))/sd(x_sum))

out &lt;- em_link(X, g,tol=.0001, max_iter = 100)

</code></pre>

<hr>
<h2 id='euclidean_anti_join'>Spatial Anti Join Using LSH</h2><span id='topic+euclidean_anti_join'></span>

<h3>Description</h3>

<p>Spatial Anti Join Using LSH
</p>


<h3>Usage</h3>

<pre><code class='language-R'>euclidean_anti_join(
  a,
  b,
  by = NULL,
  threshold = 1,
  n_bands = 30,
  band_width = 5,
  r = 0.5,
  progress = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="euclidean_anti_join_+3A_a">a</code></td>
<td>
<p>the first dataframe you wish to join.</p>
</td></tr>
<tr><td><code id="euclidean_anti_join_+3A_b">b</code></td>
<td>
<p>the second dataframe you wish to join.</p>
</td></tr>
<tr><td><code id="euclidean_anti_join_+3A_by">by</code></td>
<td>
<p>a named vector indicating which columns to join on. Format should
be the same as dplyr: <code>by = c("column_name_in_df_a" = "column_name_in_df_b")</code>, but
two columns must be specified in each dataset (x column and y column). Specification
made with <code>dplyr::join_by()</code> are also accepted.</p>
</td></tr>
<tr><td><code id="euclidean_anti_join_+3A_threshold">threshold</code></td>
<td>
<p>the distance threshold below which units should be considered a match</p>
</td></tr>
<tr><td><code id="euclidean_anti_join_+3A_n_bands">n_bands</code></td>
<td>
<p>the number of bands used in the LSH algorithm (default
is 30). Use this in conjunction with the <code>band_width</code> to determine the
performance of the hashing.</p>
</td></tr>
<tr><td><code id="euclidean_anti_join_+3A_band_width">band_width</code></td>
<td>
<p>the length of each band used in the minihashing algorithm
(default is 5) Use this in conjunction with the <code>n_bands</code> to determine
the performance of the hashing.</p>
</td></tr>
<tr><td><code id="euclidean_anti_join_+3A_r">r</code></td>
<td>
<p>the r hyperparameter used to govern the sensitivity of the locality sensitive hash, as described in</p>
</td></tr>
<tr><td><code id="euclidean_anti_join_+3A_progress">progress</code></td>
<td>
<p>set to <code>TRUE</code> to print progress</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a tibble fuzzily-joined on the basis of the variables in <code>by.</code> Tries
to adhere to the same standards as the dplyr-joins, and uses the same
logical joining patterns (i.e. inner-join joins and keeps only observations in both datasets).
</p>


<h3>References</h3>

<p>Datar, Mayur, Nicole Immorlica, Pitor Indyk, and Vahab Mirrokni.
&quot;Locality-Sensitive Hashing Scheme Based on p-Stable Distributions&quot; SCG '04:
Proceedings of the twentieth annual symposium on Computational geometry
(2004): 253-262
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 10

X_1 &lt;- matrix(c(seq(0,1,1/(n-1)), seq(0,1,1/(n-1))), nrow=n)
X_2 &lt;- X_1 + .0000001

X_1 &lt;- as.data.frame(X_1)
X_2 &lt;- as.data.frame(X_2)

X_1$id_1 &lt;- 1:n
X_2$id_2 &lt;- 1:n


euclidean_anti_join(X_1, X_2, by = c("V1", "V2"), threshold =.00005)


</code></pre>

<hr>
<h2 id='euclidean_curve'>Plot S-Curve for a LSH with given hyperparameters</h2><span id='topic+euclidean_curve'></span>

<h3>Description</h3>

<p>Plot S-Curve for a LSH with given hyperparameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>euclidean_curve(n_bands, band_width, r, up_to = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="euclidean_curve_+3A_n_bands">n_bands</code></td>
<td>
<p>The number of LSH bands calculated</p>
</td></tr>
<tr><td><code id="euclidean_curve_+3A_band_width">band_width</code></td>
<td>
<p>The number of hashes in each band</p>
</td></tr>
<tr><td><code id="euclidean_curve_+3A_r">r</code></td>
<td>
<p>the &quot;r&quot; hyperparameter used to govern the sensitivity of the hash.</p>
</td></tr>
<tr><td><code id="euclidean_curve_+3A_up_to">up_to</code></td>
<td>
<p>the right extent of the x axis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot showing the probability a pair is proposed as a match, given
the Jaccard similarity of the two items.
</p>

<hr>
<h2 id='euclidean_full_join'>Spatial Full Join Using LSH</h2><span id='topic+euclidean_full_join'></span>

<h3>Description</h3>

<p>Spatial Full Join Using LSH
</p>


<h3>Usage</h3>

<pre><code class='language-R'>euclidean_full_join(
  a,
  b,
  by = NULL,
  threshold = 1,
  n_bands = 30,
  band_width = 5,
  r = 0.5,
  progress = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="euclidean_full_join_+3A_a">a</code></td>
<td>
<p>the first dataframe you wish to join.</p>
</td></tr>
<tr><td><code id="euclidean_full_join_+3A_b">b</code></td>
<td>
<p>the second dataframe you wish to join.</p>
</td></tr>
<tr><td><code id="euclidean_full_join_+3A_by">by</code></td>
<td>
<p>a named vector indicating which columns to join on. Format should
be the same as dplyr: <code>by = c("column_name_in_df_a" = "column_name_in_df_b")</code>, but
two columns must be specified in each dataset (x column and y column). Specification
made with <code>dplyr::join_by()</code> are also accepted.</p>
</td></tr>
<tr><td><code id="euclidean_full_join_+3A_threshold">threshold</code></td>
<td>
<p>the distance threshold below which units should be considered a match</p>
</td></tr>
<tr><td><code id="euclidean_full_join_+3A_n_bands">n_bands</code></td>
<td>
<p>the number of bands used in the LSH algorithm (default
is 30). Use this in conjunction with the <code>band_width</code> to determine the
performance of the hashing.</p>
</td></tr>
<tr><td><code id="euclidean_full_join_+3A_band_width">band_width</code></td>
<td>
<p>the length of each band used in the minihashing algorithm
(default is 5) Use this in conjunction with the <code>n_bands</code> to determine
the performance of the hashing.</p>
</td></tr>
<tr><td><code id="euclidean_full_join_+3A_r">r</code></td>
<td>
<p>the r hyperparameter used to govern the sensitivity of the locality sensitive hash, as described in</p>
</td></tr>
<tr><td><code id="euclidean_full_join_+3A_progress">progress</code></td>
<td>
<p>set to <code>TRUE</code> to print progress</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a tibble fuzzily-joined on the basis of the variables in <code>by.</code> Tries
to adhere to the same standards as the dplyr-joins, and uses the same
logical joining patterns (i.e. inner-join joins and keeps only observations in both datasets).
</p>


<h3>References</h3>

<p>Datar, Mayur, Nicole Immorlica, Pitor Indyk, and Vahab Mirrokni.
&quot;Locality-Sensitive Hashing Scheme Based on p-Stable Distributions&quot; SCG '04:
Proceedings of the twentieth annual symposium on Computational geometry
(2004): 253-262
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 10

X_1 &lt;- matrix(c(seq(0,1,1/(n-1)), seq(0,1,1/(n-1))), nrow=n)
X_2 &lt;- X_1 + .0000001

X_1 &lt;- as.data.frame(X_1)
X_2 &lt;- as.data.frame(X_2)

X_1$id_1 &lt;- 1:n
X_2$id_2 &lt;- 1:n

euclidean_full_join(X_1, X_2, by = c("V1", "V2"), threshold =.00005)

</code></pre>

<hr>
<h2 id='euclidean_inner_join'>Spatial Inner Join Using LSH</h2><span id='topic+euclidean_inner_join'></span>

<h3>Description</h3>

<p>Spatial Inner Join Using LSH
</p>


<h3>Usage</h3>

<pre><code class='language-R'>euclidean_inner_join(
  a,
  b,
  by = NULL,
  threshold = 1,
  n_bands = 30,
  band_width = 5,
  r = 0.5,
  progress = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="euclidean_inner_join_+3A_a">a</code></td>
<td>
<p>the first dataframe you wish to join.</p>
</td></tr>
<tr><td><code id="euclidean_inner_join_+3A_b">b</code></td>
<td>
<p>the second dataframe
you wish to join.</p>
</td></tr>
<tr><td><code id="euclidean_inner_join_+3A_by">by</code></td>
<td>
<p>a named vector indicating which columns to join on. Format should
be the same as dplyr: <code>by = c("column_name_in_df_a" = "column_name_in_df_b")</code>, but
two columns must be specified in each dataset (x column and y column).</p>
</td></tr>
<tr><td><code id="euclidean_inner_join_+3A_threshold">threshold</code></td>
<td>
<p>the distance threshold below which units should be considered a match</p>
</td></tr>
<tr><td><code id="euclidean_inner_join_+3A_n_bands">n_bands</code></td>
<td>
<p>the number of bands used in the LSH algorithm (default
is 30). Use this in conjunction with the <code>band_width</code> to determine the
performance of the hashing.</p>
</td></tr>
<tr><td><code id="euclidean_inner_join_+3A_band_width">band_width</code></td>
<td>
<p>the length of each band used in the minihashing algorithm
(default is 5) Use this in conjunction with the <code>n_bands</code> to determine
the performance of the hashing.</p>
</td></tr>
<tr><td><code id="euclidean_inner_join_+3A_r">r</code></td>
<td>
<p>the r hyperparameter used to govern the sensitivity of the locality sensitive hash, as described in</p>
</td></tr>
<tr><td><code id="euclidean_inner_join_+3A_progress">progress</code></td>
<td>
<p>set to <code>TRUE</code> to print progress</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a tibble fuzzily-joined on the basis of the variables in <code>by.</code> Tries
to adhere to the same standards as the dplyr-joins, and uses the same
logical joining patterns (i.e. inner-join joins and keeps only observations in both datasets).
</p>


<h3>References</h3>

<p>Datar, Mayur, Nicole Immorlica, Pitor Indyk, and Vahab Mirrokni.
&quot;Locality-Sensitive Hashing Scheme Based on p-Stable Distributions&quot; SCG '04:
Proceedings of the twentieth annual symposium on Computational geometry
(2004): 253-262
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 10

X_1 &lt;- matrix(c(seq(0,1,1/(n-1)), seq(0,1,1/(n-1))), nrow=n)
X_2 &lt;- X_1 + .0000001

X_1 &lt;- as.data.frame(X_1)
X_2 &lt;- as.data.frame(X_2)

X_1$id_1 &lt;- 1:n
X_2$id_2 &lt;- 1:n

euclidean_inner_join(X_1, X_2, by = c("V1", "V2"), threshold =.00005)


</code></pre>

<hr>
<h2 id='euclidean_left_join'>Spatial Left Join Using LSH</h2><span id='topic+euclidean_left_join'></span>

<h3>Description</h3>

<p>Spatial Left Join Using LSH
</p>


<h3>Usage</h3>

<pre><code class='language-R'>euclidean_left_join(
  a,
  b,
  by = NULL,
  threshold = 1,
  n_bands = 30,
  band_width = 5,
  r = 0.5,
  progress = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="euclidean_left_join_+3A_a">a</code></td>
<td>
<p>the first dataframe you wish to join.</p>
</td></tr>
<tr><td><code id="euclidean_left_join_+3A_b">b</code></td>
<td>
<p>the second dataframe you wish to join.</p>
</td></tr>
<tr><td><code id="euclidean_left_join_+3A_by">by</code></td>
<td>
<p>a named vector indicating which columns to join on. Format should
be the same as dplyr: <code>by = c("column_name_in_df_a" = "column_name_in_df_b")</code>, but
two columns must be specified in each dataset (x column and y column). Specification
made with <code>dplyr::join_by()</code> are also accepted.</p>
</td></tr>
<tr><td><code id="euclidean_left_join_+3A_threshold">threshold</code></td>
<td>
<p>the distance threshold below which units should be considered a match</p>
</td></tr>
<tr><td><code id="euclidean_left_join_+3A_n_bands">n_bands</code></td>
<td>
<p>the number of bands used in the LSH algorithm (default
is 30). Use this in conjunction with the <code>band_width</code> to determine the
performance of the hashing.</p>
</td></tr>
<tr><td><code id="euclidean_left_join_+3A_band_width">band_width</code></td>
<td>
<p>the length of each band used in the minihashing algorithm
(default is 5) Use this in conjunction with the <code>n_bands</code> to determine
the performance of the hashing.</p>
</td></tr>
<tr><td><code id="euclidean_left_join_+3A_r">r</code></td>
<td>
<p>the r hyperparameter used to govern the sensitivity of the locality sensitive hash, as described in</p>
</td></tr>
<tr><td><code id="euclidean_left_join_+3A_progress">progress</code></td>
<td>
<p>set to <code>TRUE</code> to print progress</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a tibble fuzzily-joined on the basis of the variables in <code>by.</code> Tries
to adhere to the same standards as the dplyr-joins, and uses the same
logical joining patterns (i.e. inner-join joins and keeps only observations in both datasets).
</p>


<h3>References</h3>

<p>Datar, Mayur, Nicole Immorlica, Pitor Indyk, and Vahab Mirrokni.
&quot;Locality-Sensitive Hashing Scheme Based on p-Stable Distributions&quot; SCG '04:
Proceedings of the twentieth annual symposium on Computational geometry
(2004): 253-262
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 10

X_1 &lt;- matrix(c(seq(0,1,1/(n-1)), seq(0,1,1/(n-1))), nrow=n)
X_2 &lt;- X_1 + .0000001

X_1 &lt;- as.data.frame(X_1)
X_2 &lt;- as.data.frame(X_2)

X_1$id_1 &lt;- 1:n
X_2$id_2 &lt;- 1:n

euclidean_left_join(X_1, X_2, by = c("V1", "V2"), threshold =.00005)


</code></pre>

<hr>
<h2 id='euclidean_probability'>Find Probability of Match Based on Similarity</h2><span id='topic+euclidean_probability'></span>

<h3>Description</h3>

<p>Find Probability of Match Based on Similarity
</p>


<h3>Usage</h3>

<pre><code class='language-R'>euclidean_probability(distance, n_bands, band_width, r)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="euclidean_probability_+3A_distance">distance</code></td>
<td>
<p>the euclidian distance between the two vectors you want to
compare.</p>
</td></tr>
<tr><td><code id="euclidean_probability_+3A_n_bands">n_bands</code></td>
<td>
<p>The number of LSH bands used in hashing.</p>
</td></tr>
<tr><td><code id="euclidean_probability_+3A_band_width">band_width</code></td>
<td>
<p>The number of hashes in each band.</p>
</td></tr>
<tr><td><code id="euclidean_probability_+3A_r">r</code></td>
<td>
<p>the &quot;r&quot; hyperparameter used to govern the sensitivity of the hash.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a decimal number giving the proability that the two items will be
returned as a candidate pair from the minihash algorithm.
</p>

<hr>
<h2 id='euclidean_right_join'>Spatial Right Join Using LSH</h2><span id='topic+euclidean_right_join'></span>

<h3>Description</h3>

<p>Spatial Right Join Using LSH
</p>


<h3>Usage</h3>

<pre><code class='language-R'>euclidean_right_join(
  a,
  b,
  by = NULL,
  threshold = 1,
  n_bands = 30,
  band_width = 5,
  r = 0.5,
  progress = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="euclidean_right_join_+3A_a">a</code></td>
<td>
<p>the first dataframe you wish to join.</p>
</td></tr>
<tr><td><code id="euclidean_right_join_+3A_b">b</code></td>
<td>
<p>the second dataframe you wish to join.</p>
</td></tr>
<tr><td><code id="euclidean_right_join_+3A_by">by</code></td>
<td>
<p>a named vector indicating which columns to join on. Format should
be the same as dplyr: <code>by = c("column_name_in_df_a" = "column_name_in_df_b")</code>, but
two columns must be specified in each dataset (x column and y column). Specification
made with <code>dplyr::join_by()</code> are also accepted.</p>
</td></tr>
<tr><td><code id="euclidean_right_join_+3A_threshold">threshold</code></td>
<td>
<p>the distance threshold below which units should be considered a match</p>
</td></tr>
<tr><td><code id="euclidean_right_join_+3A_n_bands">n_bands</code></td>
<td>
<p>the number of bands used in the LSH algorithm (default
is 30). Use this in conjunction with the <code>band_width</code> to determine the
performance of the hashing.</p>
</td></tr>
<tr><td><code id="euclidean_right_join_+3A_band_width">band_width</code></td>
<td>
<p>the length of each band used in the minihashing algorithm
(default is 5) Use this in conjunction with the <code>n_bands</code> to determine
the performance of the hashing.</p>
</td></tr>
<tr><td><code id="euclidean_right_join_+3A_r">r</code></td>
<td>
<p>the r hyperparameter used to govern the sensitivity of the locality sensitive hash, as described in</p>
</td></tr>
<tr><td><code id="euclidean_right_join_+3A_progress">progress</code></td>
<td>
<p>set to <code>TRUE</code> to print progress</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a tibble fuzzily-joined on the basis of the variables in <code>by.</code> Tries
to adhere to the same standards as the dplyr-joins, and uses the same
logical joining patterns (i.e. inner-join joins and keeps only observations in both datasets).
</p>


<h3>References</h3>

<p>Datar, Mayur, Nicole Immorlica, Pitor Indyk, and Vahab Mirrokni.
&quot;Locality-Sensitive Hashing Scheme Based on p-Stable Distributions&quot; SCG '04:
Proceedings of the twentieth annual symposium on Computational geometry
(2004): 253-262
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 10

X_1 &lt;- matrix(c(seq(0,1,1/(n-1)), seq(0,1,1/(n-1))), nrow=n)
X_2 &lt;- X_1 + .0000001
X_1 &lt;- as.data.frame(X_1)
X_2 &lt;- as.data.frame(X_2)

X_1$id_1 &lt;- 1:n
X_2$id_2 &lt;- 1:n

euclidean_right_join(X_1, X_2, by = c("V1", "V2"), threshold =.00005)


</code></pre>

<hr>
<h2 id='jaccard_anti_join'>Fuzzy anti-join using minihashing</h2><span id='topic+jaccard_anti_join'></span>

<h3>Description</h3>

<p>Fuzzy anti-join using minihashing
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jaccard_anti_join(
  a,
  b,
  by = NULL,
  block_by = NULL,
  n_gram_width = 2,
  n_bands = 50,
  band_width = 8,
  threshold = 0.7,
  progress = FALSE,
  clean = FALSE,
  similarity_column = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jaccard_anti_join_+3A_a">a</code></td>
<td>
<p>the first dataframe you wish to join.</p>
</td></tr>
<tr><td><code id="jaccard_anti_join_+3A_b">b</code></td>
<td>
<p>the second dataframe you wish to join.</p>
</td></tr>
<tr><td><code id="jaccard_anti_join_+3A_by">by</code></td>
<td>
<p>a named vector indicating which columns to join on. Format should
be the same as dplyr: <code>by = c("column_name_in_df_a" = "column_name_in_df_b")</code>, but
two columns must be specified in each dataset (x column and y column). Specification
made with <code>dplyr::join_by()</code> are also accepted.</p>
</td></tr>
<tr><td><code id="jaccard_anti_join_+3A_block_by">block_by</code></td>
<td>
<p>a named vector indicating which column to block on, such that
rows that disagree on this field cannot be considered a match. Format should
be the same as dplyr: <code>by = c("column_name_in_df_a" =
"column_name_in_df_b")</code></p>
</td></tr>
<tr><td><code id="jaccard_anti_join_+3A_n_gram_width">n_gram_width</code></td>
<td>
<p>the length of the n_grams used in calculating the
jaccard similarity. For best performance, I set this large enough that the
chance any string has a specific n_gram is low (i.e. <code>n_gram_width</code> = 2
or 3 when matching on first names, 5 or 6 when matching on entire
sentences).</p>
</td></tr>
<tr><td><code id="jaccard_anti_join_+3A_n_bands">n_bands</code></td>
<td>
<p>the number of bands used in the minihash algorithm (default
is 40). Use this in conjunction with the <code>band_width</code> to determine the
performance of the hashing. The default settings are for a
(.2,.8,.001,.999)-sensitive hash i.e. that pairs with a similarity of less
than .2 have a &gt;.1% chance of being compared, while pairs with a similarity
of greater than .8 have a &gt;99.9% chance of being compared.</p>
</td></tr>
<tr><td><code id="jaccard_anti_join_+3A_band_width">band_width</code></td>
<td>
<p>the length of each band used in the minihashing algorithm
(default is 8) Use this in conjunction with the <code>n_bands</code> to determine
the performance of the hashing. The default settings are for a
(.2,.8,.001,.999)-sensitive hash i.e. that pairs with a similarity of less
than .2 have a &gt;.1% chance of being compared, while pairs with a similarity
of greater than .8 have a &gt;99.9% chance of being compared.</p>
</td></tr>
<tr><td><code id="jaccard_anti_join_+3A_threshold">threshold</code></td>
<td>
<p>the jaccard similarity threshold above which two strings
should be considered a match (default is .95). The similarity is euqal to 1
</p>

<ul>
<li><p> the jaccard distance between the two strings, so 1 implies the strings are
identical, while a similarity of zero implies the strings are completely
dissimilar.
</p>
</li></ul>
</td></tr>
<tr><td><code id="jaccard_anti_join_+3A_progress">progress</code></td>
<td>
<p>set to <code>TRUE</code> to print progress</p>
</td></tr>
<tr><td><code id="jaccard_anti_join_+3A_clean">clean</code></td>
<td>
<p>should the strings that you fuzzy join on be cleaned (coerced
to lower-case, stripped of punctuation and spaces)? Default is FALSE</p>
</td></tr>
<tr><td><code id="jaccard_anti_join_+3A_similarity_column">similarity_column</code></td>
<td>
<p>an optional character vector. If provided, the data
frame will contain a column with this name giving the jaccard similarity
between the two fields. Extra column will not be present if anti-joining.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a tibble fuzzily-joined on the basis of the variables in <code>by.</code> Tries
to adhere to the same standards as the dplyr-joins, and uses the same
logical joining patterns (i.e. inner-join joins and keeps only observations in both datasets).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load baby names data
#install.packages("babynames")
library(babynames)

baby_names &lt;- data.frame(name = tolower(unique(babynames$name))[1:500])
baby_names_sans_vowels &lt;- data.frame(
                name_wo_vowels =gsub("[aeiouy]","", baby_names$name)
   )
# Check the probability two pairs of strings with
# similarity .8 will be matched with a band width of 30
# and 30 bands using the `jaccard_probability()` function:
jaccard_probability(.8,30,8)
# Run the join:
joined_names &lt;- jaccard_anti_join(
              baby_names,
              baby_names_sans_vowels,
              by = c("name"= "name_wo_vowels"),
              threshold = .8,
              n_bands = 20,
              band_width = 6,
              n_gram_width = 1,
              clean = FALSE # default
              )
joined_names
</code></pre>

<hr>
<h2 id='jaccard_curve'>Plot S-Curve for a LSH with given hyperparameters</h2><span id='topic+jaccard_curve'></span>

<h3>Description</h3>

<p>Plot S-Curve for a LSH with given hyperparameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jaccard_curve(n_bands, band_width)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jaccard_curve_+3A_n_bands">n_bands</code></td>
<td>
<p>The number of LSH bands calculated</p>
</td></tr>
<tr><td><code id="jaccard_curve_+3A_band_width">band_width</code></td>
<td>
<p>The number of hashes in each band</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot showing the probability a pair is proposed as a match, given
the Jaccard similarity of the two items.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Plot the probability two pairs will be matched as a function of their
# jaccard similarity, given the hyperparameters n_bands and band_width.
jaccard_curve(40,6)

</code></pre>

<hr>
<h2 id='jaccard_full_join'>Fuzzy full-join using minihashing</h2><span id='topic+jaccard_full_join'></span>

<h3>Description</h3>

<p>Fuzzy full-join using minihashing
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jaccard_full_join(
  a,
  b,
  by = NULL,
  block_by = NULL,
  n_gram_width = 2,
  n_bands = 50,
  band_width = 8,
  threshold = 0.7,
  progress = FALSE,
  clean = FALSE,
  similarity_column = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jaccard_full_join_+3A_a">a</code></td>
<td>
<p>the first dataframe you wish to join.</p>
</td></tr>
<tr><td><code id="jaccard_full_join_+3A_b">b</code></td>
<td>
<p>the second dataframe you wish to join.</p>
</td></tr>
<tr><td><code id="jaccard_full_join_+3A_by">by</code></td>
<td>
<p>a named vector indicating which columns to join on. Format should
be the same as dplyr: <code>by = c("column_name_in_df_a" = "column_name_in_df_b")</code>, but
two columns must be specified in each dataset (x column and y column). Specification
made with <code>dplyr::join_by()</code> are also accepted.</p>
</td></tr>
<tr><td><code id="jaccard_full_join_+3A_block_by">block_by</code></td>
<td>
<p>a named vector indicating which column to block on, such that
rows that disagree on this field cannot be considered a match. Format should
be the same as dplyr: <code>by = c("column_name_in_df_a" =
"column_name_in_df_b")</code></p>
</td></tr>
<tr><td><code id="jaccard_full_join_+3A_n_gram_width">n_gram_width</code></td>
<td>
<p>the length of the n_grams used in calculating the
jaccard similarity. For best performance, I set this large enough that the
chance any string has a specific n_gram is low (i.e. <code>n_gram_width</code> = 2
or 3 when matching on first names, 5 or 6 when matching on entire
sentences).</p>
</td></tr>
<tr><td><code id="jaccard_full_join_+3A_n_bands">n_bands</code></td>
<td>
<p>the number of bands used in the minihash algorithm (default
is 40). Use this in conjunction with the <code>band_width</code> to determine the
performance of the hashing. The default settings are for a
(.2,.8,.001,.999)-sensitive hash i.e. that pairs with a similarity of less
than .2 have a &gt;.1% chance of being compared, while pairs with a similarity
of greater than .8 have a &gt;99.9% chance of being compared.</p>
</td></tr>
<tr><td><code id="jaccard_full_join_+3A_band_width">band_width</code></td>
<td>
<p>the length of each band used in the minihashing algorithm
(default is 8) Use this in conjunction with the <code>n_bands</code> to determine
the performance of the hashing. The default settings are for a
(.2,.8,.001,.999)-sensitive hash i.e. that pairs with a similarity of less
than .2 have a &gt;.1% chance of being compared, while pairs with a similarity
of greater than .8 have a &gt;99.9% chance of being compared.</p>
</td></tr>
<tr><td><code id="jaccard_full_join_+3A_threshold">threshold</code></td>
<td>
<p>the jaccard similarity threshold above which two strings
should be considered a match (default is .95). The similarity is euqal to 1
</p>

<ul>
<li><p> the jaccard distance between the two strings, so 1 implies the strings are
identical, while a similarity of zero implies the strings are completely
dissimilar.
</p>
</li></ul>
</td></tr>
<tr><td><code id="jaccard_full_join_+3A_progress">progress</code></td>
<td>
<p>set to <code>TRUE</code> to print progress</p>
</td></tr>
<tr><td><code id="jaccard_full_join_+3A_clean">clean</code></td>
<td>
<p>should the strings that you fuzzy join on be cleaned (coerced
to lower-case, stripped of punctuation and spaces)? Default is FALSE</p>
</td></tr>
<tr><td><code id="jaccard_full_join_+3A_similarity_column">similarity_column</code></td>
<td>
<p>an optional character vector. If provided, the data
frame will contain a column with this name giving the jaccard similarity
between the two fields. Extra column will not be present if anti-joining.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a tibble fuzzily-joined on the basis of the variables in <code>by.</code> Tries
to adhere to the same standards as the dplyr-joins, and uses the same
logical joining patterns (i.e. inner-join joins and keeps only observations in both datasets).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load baby names data
#install.packages("babynames")
library(babynames)

baby_names &lt;- data.frame(name = tolower(unique(babynames$name))[1:500])
baby_names_sans_vowels &lt;- data.frame(
                name_wo_vowels =gsub("[aeiouy]","", baby_names$name)
   )
# Check the probability two pairs of strings with
# similarity .8 will be matched with a band width of 30
# and 30 bands using the `jaccard_probability()` function:
jaccard_probability(.8,30,8)
# Run the join:
joined_names &lt;- jaccard_full_join(
              baby_names,
              baby_names_sans_vowels,
              by = c("name"= "name_wo_vowels"),
              threshold = .8,
              n_bands = 20,
              band_width = 6,
              n_gram_width = 1,
              clean = FALSE # default
              )
joined_names
</code></pre>

<hr>
<h2 id='jaccard_hyper_grid_search'>Help Choose the Appropriate LSH Hyperparameters</h2><span id='topic+jaccard_hyper_grid_search'></span>

<h3>Description</h3>

<p>Runs a grid search to find the hyperparameters that will achieve an
(s1,s2,p1,p2)-sensitive locality sensitive hash. A locality sensitive hash
can be called (s1,s2,p1,p2)-sensitive if to strings with a similarity less
than s1 have a less than p1 chance of being compared, while two strings with
similarity s2 have a greater than p2 chance of being compared. As an
example, a (.1,.7,.001,.999)-sensitive LSH means that strings with
similarity less than .1 will have a .1% chance of being compared, while
strings with .7 similarity have a 99.9% chance of being compared.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jaccard_hyper_grid_search(s1 = 0.1, s2 = 0.7, p1 = 0.001, p2 = 0.999)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jaccard_hyper_grid_search_+3A_s1">s1</code></td>
<td>
<p>the s1 parameter (the first similaity).</p>
</td></tr>
<tr><td><code id="jaccard_hyper_grid_search_+3A_s2">s2</code></td>
<td>
<p>the s2 parameter (the second similarity, must be greater than s1).</p>
</td></tr>
<tr><td><code id="jaccard_hyper_grid_search_+3A_p1">p1</code></td>
<td>
<p>the p1 parameter (the first probability).</p>
</td></tr>
<tr><td><code id="jaccard_hyper_grid_search_+3A_p2">p2</code></td>
<td>
<p>the p2 parameter (the second probability, must be greater than p1).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named vector with the hyperparameters that will meet the LSH
criteria, while reducing runitme.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Help me find the parameters that will minimize runtime while ensuring that
# two strings with similarity .1 will be compared less than .1% of the time,
# strings with .8 similaity will have a 99.95% chance of being compared:
jaccard_hyper_grid_search(.1,.9,.001,.995)

</code></pre>

<hr>
<h2 id='jaccard_inner_join'>Fuzzy inner-join using minihashing</h2><span id='topic+jaccard_inner_join'></span>

<h3>Description</h3>

<p>Fuzzy inner-join using minihashing
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jaccard_inner_join(
  a,
  b,
  by = NULL,
  block_by = NULL,
  n_gram_width = 2,
  n_bands = 50,
  band_width = 8,
  threshold = 0.7,
  progress = FALSE,
  clean = FALSE,
  similarity_column = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jaccard_inner_join_+3A_a">a</code></td>
<td>
<p>the first dataframe you wish to join.</p>
</td></tr>
<tr><td><code id="jaccard_inner_join_+3A_b">b</code></td>
<td>
<p>the second dataframe you wish to join.</p>
</td></tr>
<tr><td><code id="jaccard_inner_join_+3A_by">by</code></td>
<td>
<p>a named vector indicating which columns to join on. Format should
be the same as dplyr: <code>by = c("column_name_in_df_a" = "column_name_in_df_b")</code>, but
two columns must be specified in each dataset (x column and y column). Specification
made with <code>dplyr::join_by()</code> are also accepted.</p>
</td></tr>
<tr><td><code id="jaccard_inner_join_+3A_block_by">block_by</code></td>
<td>
<p>a named vector indicating which column to block on, such that
rows that disagree on this field cannot be considered a match. Format should
be the same as dplyr: <code>by = c("column_name_in_df_a" =
"column_name_in_df_b")</code></p>
</td></tr>
<tr><td><code id="jaccard_inner_join_+3A_n_gram_width">n_gram_width</code></td>
<td>
<p>the length of the n_grams used in calculating the
jaccard similarity. For best performance, I set this large enough that the
chance any string has a specific n_gram is low (i.e. <code>n_gram_width</code> = 2
or 3 when matching on first names, 5 or 6 when matching on entire
sentences).</p>
</td></tr>
<tr><td><code id="jaccard_inner_join_+3A_n_bands">n_bands</code></td>
<td>
<p>the number of bands used in the minihash algorithm (default
is 40). Use this in conjunction with the <code>band_width</code> to determine the
performance of the hashing. The default settings are for a
(.2,.8,.001,.999)-sensitive hash i.e. that pairs with a similarity of less
than .2 have a &gt;.1% chance of being compared, while pairs with a similarity
of greater than .8 have a &gt;99.9% chance of being compared.</p>
</td></tr>
<tr><td><code id="jaccard_inner_join_+3A_band_width">band_width</code></td>
<td>
<p>the length of each band used in the minihashing algorithm
(default is 8) Use this in conjunction with the <code>n_bands</code> to determine
the performance of the hashing. The default settings are for a
(.2,.8,.001,.999)-sensitive hash i.e. that pairs with a similarity of less
than .2 have a &gt;.1% chance of being compared, while pairs with a similarity
of greater than .8 have a &gt;99.9% chance of being compared.</p>
</td></tr>
<tr><td><code id="jaccard_inner_join_+3A_threshold">threshold</code></td>
<td>
<p>the jaccard similarity threshold above which two strings
should be considered a match (default is .95). The similarity is euqal to 1
</p>

<ul>
<li><p> the jaccard distance between the two strings, so 1 implies the strings are
identical, while a similarity of zero implies the strings are completely
dissimilar.
</p>
</li></ul>
</td></tr>
<tr><td><code id="jaccard_inner_join_+3A_progress">progress</code></td>
<td>
<p>set to <code>TRUE</code> to print progress</p>
</td></tr>
<tr><td><code id="jaccard_inner_join_+3A_clean">clean</code></td>
<td>
<p>should the strings that you fuzzy join on be cleaned (coerced
to lower-case, stripped of punctuation and spaces)? Default is FALSE</p>
</td></tr>
<tr><td><code id="jaccard_inner_join_+3A_similarity_column">similarity_column</code></td>
<td>
<p>an optional character vector. If provided, the data
frame will contain a column with this name giving the jaccard similarity
between the two fields. Extra column will not be present if anti-joining.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a tibble fuzzily-joined on the basis of the variables in <code>by.</code> Tries
to adhere to the same standards as the dplyr-joins, and uses the same
logical joining patterns (i.e. inner-join joins and keeps only observations in both datasets).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load baby names data
#install.packages("babynames")
library(babynames)

baby_names &lt;- data.frame(name = tolower(unique(babynames$name))[1:500])
baby_names_sans_vowels &lt;- data.frame(
                name_wo_vowels =gsub("[aeiouy]","", baby_names$name)
   )
# Check the probability two pairs of strings with
# similarity .8 will be matched with a band width of 30
# and 30 bands using the `jaccard_probability()` function:
jaccard_probability(.8,30,8)
# Run the join:
joined_names &lt;- jaccard_inner_join(
              baby_names,
              baby_names_sans_vowels,
              by = c("name"= "name_wo_vowels"),
              threshold = .8,
              n_bands = 20,
              band_width = 6,
              n_gram_width = 1,
              clean = FALSE # default
              )
joined_names
</code></pre>

<hr>
<h2 id='jaccard_left_join'>Fuzzy left-join using minihashing</h2><span id='topic+jaccard_left_join'></span>

<h3>Description</h3>

<p>Fuzzy left-join using minihashing
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jaccard_left_join(
  a,
  b,
  by = NULL,
  block_by = NULL,
  n_gram_width = 2,
  n_bands = 50,
  band_width = 8,
  threshold = 0.7,
  progress = FALSE,
  clean = FALSE,
  similarity_column = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jaccard_left_join_+3A_a">a</code></td>
<td>
<p>the first dataframe you wish to join.</p>
</td></tr>
<tr><td><code id="jaccard_left_join_+3A_b">b</code></td>
<td>
<p>the second dataframe you wish to join.</p>
</td></tr>
<tr><td><code id="jaccard_left_join_+3A_by">by</code></td>
<td>
<p>a named vector indicating which columns to join on. Format should
be the same as dplyr: <code>by = c("column_name_in_df_a" = "column_name_in_df_b")</code>, but
two columns must be specified in each dataset (x column and y column). Specification
made with <code>dplyr::join_by()</code> are also accepted.</p>
</td></tr>
<tr><td><code id="jaccard_left_join_+3A_block_by">block_by</code></td>
<td>
<p>a named vector indicating which column to block on, such that
rows that disagree on this field cannot be considered a match. Format should
be the same as dplyr: <code>by = c("column_name_in_df_a" =
"column_name_in_df_b")</code></p>
</td></tr>
<tr><td><code id="jaccard_left_join_+3A_n_gram_width">n_gram_width</code></td>
<td>
<p>the length of the n_grams used in calculating the
jaccard similarity. For best performance, I set this large enough that the
chance any string has a specific n_gram is low (i.e. <code>n_gram_width</code> = 2
or 3 when matching on first names, 5 or 6 when matching on entire
sentences).</p>
</td></tr>
<tr><td><code id="jaccard_left_join_+3A_n_bands">n_bands</code></td>
<td>
<p>the number of bands used in the minihash algorithm (default
is 40). Use this in conjunction with the <code>band_width</code> to determine the
performance of the hashing. The default settings are for a
(.2,.8,.001,.999)-sensitive hash i.e. that pairs with a similarity of less
than .2 have a &gt;.1% chance of being compared, while pairs with a similarity
of greater than .8 have a &gt;99.9% chance of being compared.</p>
</td></tr>
<tr><td><code id="jaccard_left_join_+3A_band_width">band_width</code></td>
<td>
<p>the length of each band used in the minihashing algorithm
(default is 8) Use this in conjunction with the <code>n_bands</code> to determine
the performance of the hashing. The default settings are for a
(.2,.8,.001,.999)-sensitive hash i.e. that pairs with a similarity of less
than .2 have a &gt;.1% chance of being compared, while pairs with a similarity
of greater than .8 have a &gt;99.9% chance of being compared.</p>
</td></tr>
<tr><td><code id="jaccard_left_join_+3A_threshold">threshold</code></td>
<td>
<p>the jaccard similarity threshold above which two strings
should be considered a match (default is .95). The similarity is euqal to 1
</p>

<ul>
<li><p> the jaccard distance between the two strings, so 1 implies the strings are
identical, while a similarity of zero implies the strings are completely
dissimilar.
</p>
</li></ul>
</td></tr>
<tr><td><code id="jaccard_left_join_+3A_progress">progress</code></td>
<td>
<p>set to <code>TRUE</code> to print progress</p>
</td></tr>
<tr><td><code id="jaccard_left_join_+3A_clean">clean</code></td>
<td>
<p>should the strings that you fuzzy join on be cleaned (coerced
to lower-case, stripped of punctuation and spaces)? Default is FALSE</p>
</td></tr>
<tr><td><code id="jaccard_left_join_+3A_similarity_column">similarity_column</code></td>
<td>
<p>an optional character vector. If provided, the data
frame will contain a column with this name giving the jaccard similarity
between the two fields. Extra column will not be present if anti-joining.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a tibble fuzzily-joined on the basis of the variables in <code>by.</code> Tries
to adhere to the same standards as the dplyr-joins, and uses the same
logical joining patterns (i.e. inner-join joins and keeps only observations in both datasets).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load baby names data
#install.packages("babynames")
library(babynames)

baby_names &lt;- data.frame(name = tolower(unique(babynames$name))[1:500])
baby_names_sans_vowels &lt;- data.frame(
                name_wo_vowels =gsub("[aeiouy]","", baby_names$name)
   )
# Check the probability two pairs of strings with
# similarity .8 will be matched with a band width of 30
# and 30 bands using the `jaccard_probability()` function:
jaccard_probability(.8,30,8)
# Run the join:
joined_names &lt;- jaccard_left_join(
              baby_names,
              baby_names_sans_vowels,
              by = c("name"= "name_wo_vowels"),
              threshold = .8,
              n_bands = 20,
              band_width = 6,
              n_gram_width = 1,
              clean = FALSE # default
              )
joined_names
</code></pre>

<hr>
<h2 id='jaccard_probability'>Find Probability of Match Based on Similarity</h2><span id='topic+jaccard_probability'></span>

<h3>Description</h3>

<p>This is a port of the
<a href="https://docs.ropensci.org/textreuse/reference/lsh_probability.html">lsh_probability</a>
function from the
<a href="https://cran.r-project.org/package=textreuse">textreuse</a>
package, with arguments changed to reflect the hyperparameters in this
package. It gives the probability that two strings of jaccard similarity
<code>similarity</code> will be matched, given the chosen bandwidth and number of
bands.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jaccard_probability(similarity, n_bands, band_width)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jaccard_probability_+3A_similarity">similarity</code></td>
<td>
<p>the similarity of the two strings you want to compare</p>
</td></tr>
<tr><td><code id="jaccard_probability_+3A_n_bands">n_bands</code></td>
<td>
<p>The number of LSH bands used in hashing.</p>
</td></tr>
<tr><td><code id="jaccard_probability_+3A_band_width">band_width</code></td>
<td>
<p>The number of hashes in each band.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a decimal number giving the probability that the two items will be
returned as a candidate pair from the minhash algorithm.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Find the probability two pairs will be matched given they have a
# jaccard_similarity of .8,
# band width of 5, and 50 bands:
jaccard_probability(.8,5,50)
</code></pre>

<hr>
<h2 id='jaccard_right_join'>Fuzzy right-join using minihashing</h2><span id='topic+jaccard_right_join'></span>

<h3>Description</h3>

<p>Fuzzy right-join using minihashing
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jaccard_right_join(
  a,
  b,
  by = NULL,
  block_by = NULL,
  n_gram_width = 2,
  n_bands = 50,
  band_width = 8,
  threshold = 0.7,
  progress = FALSE,
  clean = FALSE,
  similarity_column = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jaccard_right_join_+3A_a">a</code></td>
<td>
<p>the first dataframe you wish to join.</p>
</td></tr>
<tr><td><code id="jaccard_right_join_+3A_b">b</code></td>
<td>
<p>the second dataframe you wish to join.</p>
</td></tr>
<tr><td><code id="jaccard_right_join_+3A_by">by</code></td>
<td>
<p>a named vector indicating which columns to join on. Format should
be the same as dplyr: <code>by = c("column_name_in_df_a" = "column_name_in_df_b")</code>, but
two columns must be specified in each dataset (x column and y column). Specification
made with <code>dplyr::join_by()</code> are also accepted.</p>
</td></tr>
<tr><td><code id="jaccard_right_join_+3A_block_by">block_by</code></td>
<td>
<p>a named vector indicating which column to block on, such that
rows that disagree on this field cannot be considered a match. Format should
be the same as dplyr: <code>by = c("column_name_in_df_a" =
"column_name_in_df_b")</code></p>
</td></tr>
<tr><td><code id="jaccard_right_join_+3A_n_gram_width">n_gram_width</code></td>
<td>
<p>the length of the n_grams used in calculating the
jaccard similarity. For best performance, I set this large enough that the
chance any string has a specific n_gram is low (i.e. <code>n_gram_width</code> = 2
or 3 when matching on first names, 5 or 6 when matching on entire
sentences).</p>
</td></tr>
<tr><td><code id="jaccard_right_join_+3A_n_bands">n_bands</code></td>
<td>
<p>the number of bands used in the minihash algorithm (default
is 40). Use this in conjunction with the <code>band_width</code> to determine the
performance of the hashing. The default settings are for a
(.2,.8,.001,.999)-sensitive hash i.e. that pairs with a similarity of less
than .2 have a &gt;.1% chance of being compared, while pairs with a similarity
of greater than .8 have a &gt;99.9% chance of being compared.</p>
</td></tr>
<tr><td><code id="jaccard_right_join_+3A_band_width">band_width</code></td>
<td>
<p>the length of each band used in the minihashing algorithm
(default is 8) Use this in conjunction with the <code>n_bands</code> to determine
the performance of the hashing. The default settings are for a
(.2,.8,.001,.999)-sensitive hash i.e. that pairs with a similarity of less
than .2 have a &gt;.1% chance of being compared, while pairs with a similarity
of greater than .8 have a &gt;99.9% chance of being compared.</p>
</td></tr>
<tr><td><code id="jaccard_right_join_+3A_threshold">threshold</code></td>
<td>
<p>the jaccard similarity threshold above which two strings
should be considered a match (default is .95). The similarity is euqal to 1
</p>

<ul>
<li><p> the jaccard distance between the two strings, so 1 implies the strings are
identical, while a similarity of zero implies the strings are completely
dissimilar.
</p>
</li></ul>
</td></tr>
<tr><td><code id="jaccard_right_join_+3A_progress">progress</code></td>
<td>
<p>set to <code>TRUE</code> to print progress</p>
</td></tr>
<tr><td><code id="jaccard_right_join_+3A_clean">clean</code></td>
<td>
<p>should the strings that you fuzzy join on be cleaned (coerced
to lower-case, stripped of punctuation and spaces)? Default is FALSE</p>
</td></tr>
<tr><td><code id="jaccard_right_join_+3A_similarity_column">similarity_column</code></td>
<td>
<p>an optional character vector. If provided, the data
frame will contain a column with this name giving the jaccard similarity
between the two fields. Extra column will not be present if anti-joining.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a tibble fuzzily-joined on the basis of the variables in <code>by.</code> Tries
to adhere to the same standards as the dplyr-joins, and uses the same
logical joining patterns (i.e. inner-join joins and keeps only observations in both datasets).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load baby names data
#install.packages("babynames")
library(babynames)

baby_names &lt;- data.frame(name = tolower(unique(babynames$name))[1:500])
baby_names_sans_vowels &lt;- data.frame(
                name_wo_vowels =gsub("[aeiouy]","", baby_names$name)
   )
# Check the probability two pairs of strings with
# similarity .8 will be matched with a band width of 30
# and 30 bands using the `jaccard_probability()` function:
jaccard_probability(.8,30,8)
# Run the join:
joined_names &lt;- jaccard_right_join(
              baby_names,
              baby_names_sans_vowels,
              by = c("name"= "name_wo_vowels"),
              threshold = .8,
              n_bands = 20,
              band_width = 6,
              n_gram_width = 1,
              clean = FALSE # default
              )
joined_names
</code></pre>

<hr>
<h2 id='jaccard_similarity'>Calculate jaccard_similarity of two character vectors</h2><span id='topic+jaccard_similarity'></span>

<h3>Description</h3>

<p>Calculate jaccard_similarity of two character vectors
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jaccard_similarity(a, b, ngram_width = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jaccard_similarity_+3A_a">a</code></td>
<td>
<p>the first character vector</p>
</td></tr>
<tr><td><code id="jaccard_similarity_+3A_b">b</code></td>
<td>
<p>the first character vector</p>
</td></tr>
<tr><td><code id="jaccard_similarity_+3A_ngram_width">ngram_width</code></td>
<td>
<p>the length of the shingles / ngrams used in the
similarity calculation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of jaccard similarities of the strings
</p>


<h3>Examples</h3>

<pre><code class='language-R'>jaccard_similarity(c("the quick brown fox","jumped over the lazy dog"),
    c("the quck bron fx","jumped over hte lazy dog"))

</code></pre>

<hr>
<h2 id='jaccard_string_group'>Fuzzy String Grouping Using Minhashing</h2><span id='topic+jaccard_string_group'></span>

<h3>Description</h3>

<p>Performs fuzzy string grouping in which similar strings are assigned to the
same group. Uses the <code>fastgreedy.community</code> community detection algorithm
from the <code>igraph</code> package to create the groups. Must have igraph installed
in order to use this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jaccard_string_group(
  string,
  n_gram_width = 2,
  n_bands = 45,
  band_width = 8,
  threshold = 0.7,
  progress = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jaccard_string_group_+3A_string">string</code></td>
<td>
<p>a character you wish to perform entity resolution on.</p>
</td></tr>
<tr><td><code id="jaccard_string_group_+3A_n_gram_width">n_gram_width</code></td>
<td>
<p>the length of the n_grams used in calculating the
jaccard similarity. For best performance, I set this large enough that the
chance any string has a specific n_gram is low (i.e. <code>n_gram_width</code> = 2
or 3 when matching on first names, 5 or 6 when matching on entire
sentences).</p>
</td></tr>
<tr><td><code id="jaccard_string_group_+3A_n_bands">n_bands</code></td>
<td>
<p>the number of bands used in the minihash algorithm (default
is 40). Use this in conjunction with the <code>band_width</code> to determine the
performance of the hashing. The default settings are for a
(.2,.8,.001,.999)-sensitive hash i.e. that pairs with a similarity of less
than .2 have a &gt;.1% chance of being compared, while pairs with a similarity
of greater than .8 have a &gt;99.9% chance of being compared.</p>
</td></tr>
<tr><td><code id="jaccard_string_group_+3A_band_width">band_width</code></td>
<td>
<p>the length of each band used in the minihashing algorithm
(default is 8) Use this in conjunction with the <code>n_bands</code> to determine
the performance of the hashing. The default settings are for a
(.2,.8,.001,.999)-sensitive hash i.e. that pairs with a similarity of less
than .2 have a &gt;.1% chance of being compared, while pairs with a similarity
of greater than .8 have a &gt;99.9% chance of being compared.</p>
</td></tr>
<tr><td><code id="jaccard_string_group_+3A_threshold">threshold</code></td>
<td>
<p>the jaccard similarity threshold above which two strings
should be considered a match (default is .95). The similarity is euqal to 1
</p>

<ul>
<li><p> the jaccard distance between the two strings, so 1 implies the strings are
identical, while a similarity of zero implies the strings are completely
dissimilar.
</p>
</li></ul>
</td></tr>
<tr><td><code id="jaccard_string_group_+3A_progress">progress</code></td>
<td>
<p>set to true to report progress of the algorithm</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a string vector storing the group of each element in the original
input strings. The input vector is grouped so that similar strings belong to
the same group, which is given a standardized name.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
string &lt;- c("beniamino", "jack", "benjamin", "beniamin",
    "jacky", "giacomo", "gaicomo")
jaccard_string_group(string, threshold = .2, n_bands=90, n_gram_width=1)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
