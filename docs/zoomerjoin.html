<!DOCTYPE html><html lang="en"><head><title>Help for package zoomerjoin</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {zoomerjoin}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#dime_data'><p>Donors from DIME Database</p></a></li>
<li><a href='#em_link'><p>Fit a Probabilistic Matching Model using Naive Bayes + E.M.</p></a></li>
<li><a href='#euclidean_anti_join'><p>Fuzzy joins for Euclidean distance using Locality Sensitive Hashing</p></a></li>
<li><a href='#euclidean_curve'><p>Plot S-Curve for a LSH with given hyperparameters</p></a></li>
<li><a href='#euclidean_probability'><p>Find Probability of Match Based on Similarity</p></a></li>
<li><a href='#hamming_distance'><p>Calculate Hamming distance of two character vectors</p></a></li>
<li><a href='#hamming_inner_join'><p>Fuzzy joins for Hamming distance using Locality Sensitive Hashing</p></a></li>
<li><a href='#hamming_probability'><p>Find Probability of Match Based on Similarity</p></a></li>
<li><a href='#jaccard_curve'><p>Plot S-Curve for a LSH with given hyperparameters</p></a></li>
<li><a href='#jaccard_hyper_grid_search'><p>Help Choose the Appropriate LSH Hyperparameters</p></a></li>
<li><a href='#jaccard_inner_join'><p>Fuzzy joins for Jaccard distance using MinHash</p></a></li>
<li><a href='#jaccard_probability'><p>Find Probability of Match Based on Similarity</p></a></li>
<li><a href='#jaccard_similarity'><p>Calculate Jaccard Similarity of two character vectors</p></a></li>
<li><a href='#jaccard_string_group'><p>Fuzzy String Grouping Using Minhashing</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Superlatively Fast Fuzzy Joins</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Empowers users to fuzzily-merge data frames with millions or tens of millions of rows in minutes with low memory usage.  The package uses the locality sensitive hashing algorithms developed by Datar, Immorlica, Indyk and Mirrokni (2004) &lt;<a href="https://doi.org/10.1145%2F997817.997857">doi:10.1145/997817.997857</a>&gt;, and Broder (1998) &lt;<a href="https://doi.org/10.1109%2FSEQUEN.1997.666900">doi:10.1109/SEQUEN.1997.666900</a>&gt; to avoid having to compare every pair of records in each dataset, resulting in fuzzy-merges that finish in linear time.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>Cargo (&gt;= 1.56) (Rust's package manager), rustc (&gt;=
1.70)</td>
</tr>
<tr>
<td>Imports:</td>
<td>collapse, dplyr, tibble, tidyr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>babynames, covr, fuzzyjoin, igraph, knitr, microbenchmark,
profmem, purrr, rmarkdown, stringdist, testthat (&ge; 3.0.0),
tidyverse, vdiffr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://beniamino.org/zoomerjoin/">https://beniamino.org/zoomerjoin/</a>,
<a href="https://github.com/beniaminogreen/zoomerjoin">https://github.com/beniaminogreen/zoomerjoin</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/beniaminogreen/zoomerjoin/issues">https://github.com/beniaminogreen/zoomerjoin/issues</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>LazyDataCompression:</td>
<td>xz</td>
</tr>
<tr>
<td>Config/rextendr/version:</td>
<td>0.3.1.9000</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-09-24 00:16:22 UTC; beniamino</td>
</tr>
<tr>
<td>Author:</td>
<td>Beniamino Green [aut, cre, cph],
  Etienne Bacher <a href="https://orcid.org/0000-0002-9271-5075"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  The authors of the dependency Rust crates [ctb, cph] (see inst/AUTHORS
    file for details)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Beniamino Green &lt;beniamino.green@yale.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-09-24 04:10:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='dime_data'>Donors from DIME Database</h2><span id='topic+dime_data'></span>

<h3>Description</h3>

<p>A set of donor names from the Database on Ideology, Money in Politics, and
Elections (DIME).  This dataset was used as a benchmark in the 2021 APSR
paper Adaptive Fuzzy String Matching: How to Merge Datasets with Only One
(Messy) Identifying Field by Aaron R. Kaufman and Aja Klevs, the dataset in
this package is a subset of the data from the replication archive of that
paper. The full dataset can be found in the paper's replication materials
here: <a href="https://doi.org/10.7910/DVN/4031UL">doi:10.7910/DVN/4031UL</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dime_data
</code></pre>


<h3>Format</h3>



<h4><code>dime_data</code></h4>

<p>A data frame with 10,000 rows and 2 columns:
</p>

<dl>
<dt>id</dt><dd><p>Numeric ID / Row Number</p>
</dd>
<dt>x</dt><dd><p>Donor Name</p>
</dd>
</dl>
<p>...
#' @source <a href="https://www.who.int/teams/global-tuberculosis-programme/data">https://www.who.int/teams/global-tuberculosis-programme/data</a>
</p>



<h3>Author(s)</h3>

<p>Adam Bonica
</p>


<h3>References</h3>

<p><a href="https://doi.org/10.7910/DVN/4031UL">doi:10.7910/DVN/4031UL</a>
</p>

<hr>
<h2 id='em_link'>Fit a Probabilistic Matching Model using Naive Bayes + E.M.</h2><span id='topic+em_link'></span>

<h3>Description</h3>

<p>A Rust implementation of the Naive Bayes / Fellegi-Sunter model of record
linkage as detailed in the article &quot;Using a Probabilistic Model to Assist
Merging of Large-Scale Administrative Records&quot; by Enamorado, Fifield and
Imai (2019). Takes an integer matrix describing the similarities between
each possible pair of observations, and a vector of initial guesses of the
probability each pair is a match (these can either be set from domain
knowledge, or one can hand-label a subset of the data and leave the rest as
p=.5). Iteratively refines these guesses using the Expectation Maximization
algorithm until an optima is reached. for more details, see
<a href="https://doi.org/10.1017/S0003055418000783">doi:10.1017/S0003055418000783</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>em_link(X, g, tol = 10^-6, max_iter = 10^3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="em_link_+3A_x">X</code></td>
<td>
<p>an integer matrix of similarities. Must go from 0 (the most
disagreement) to the maximum without any &quot;gaps&quot; or unused levels. As an
example, a column with values 0,1,2,3 is a valid column, but 0,1,2,4 is not
as three is omitted</p>
</td></tr>
<tr><td><code id="em_link_+3A_g">g</code></td>
<td>
<p>a vector of initial guesses that are iteratively improved using the
EM algorithm (my personal approach is to guess at logistic regression
coefficients and use them to create the intitial probability guesses). This
is chosen to avoid the model getting stuck in a local optimum, and to avoid
the problem of label-switching, where the labels for matches and non-matches
are reversed.</p>
</td></tr>
<tr><td><code id="em_link_+3A_tol">tol</code></td>
<td>
<p>tolerance in the sense of the infinity norm. i.e. how close the
parameters have to be between iterations before the EM algorithm terminates.</p>
</td></tr>
<tr><td><code id="em_link_+3A_max_iter">max_iter</code></td>
<td>
<p>iterations after which the algorithm will error out if it
has not converged.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of probabilities representing the posterior probability
each record pair is a match.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
inv_logit &lt;- function(x) {
  exp(x) / (1 + exp(x))
}
n &lt;- 10^6
d &lt;- 1:n %% 5 == 0
X &lt;- cbind(
  as.integer(ifelse(d, runif(n) &lt; .8, runif(n) &lt; .2)),
  as.integer(ifelse(d, runif(n) &lt; .9, runif(n) &lt; .2)),
  as.integer(ifelse(d, runif(n) &lt; .7, runif(n) &lt; .2)),
  as.integer(ifelse(d, runif(n) &lt; .6, runif(n) &lt; .2)),
  as.integer(ifelse(d, runif(n) &lt; .5, runif(n) &lt; .2)),
  as.integer(ifelse(d, runif(n) &lt; .1, runif(n) &lt; .9)),
  as.integer(ifelse(d, runif(n) &lt; .1, runif(n) &lt; .9)),
  as.integer(ifelse(d, runif(n) &lt; .8, runif(n) &lt; .01))
)

# inital guess at class assignments based on # a hypothetical logistic
# regression. Should be based on domain knowledge, or a handful of hand-coded
# observations.

x_sum &lt;- rowSums(X)
g &lt;- inv_logit((x_sum - mean(x_sum)) / sd(x_sum))

out &lt;- em_link(X, g, tol = .0001, max_iter = 100)

</code></pre>

<hr>
<h2 id='euclidean_anti_join'>Fuzzy joins for Euclidean distance using Locality Sensitive Hashing</h2><span id='topic+euclidean_anti_join'></span><span id='topic+euclidean_inner_join'></span><span id='topic+euclidean_left_join'></span><span id='topic+euclidean_right_join'></span><span id='topic+euclidean_full_join'></span>

<h3>Description</h3>

<p>Fuzzy joins for Euclidean distance using Locality Sensitive Hashing
</p>


<h3>Usage</h3>

<pre><code class='language-R'>euclidean_anti_join(
  a,
  b,
  by = NULL,
  threshold = 1,
  n_bands = 30,
  band_width = 5,
  r = 0.5,
  progress = FALSE
)

euclidean_inner_join(
  a,
  b,
  by = NULL,
  threshold = 1,
  n_bands = 30,
  band_width = 5,
  r = 0.5,
  progress = FALSE
)

euclidean_left_join(
  a,
  b,
  by = NULL,
  threshold = 1,
  n_bands = 30,
  band_width = 5,
  r = 0.5,
  progress = FALSE
)

euclidean_right_join(
  a,
  b,
  by = NULL,
  threshold = 1,
  n_bands = 30,
  band_width = 5,
  r = 0.5,
  progress = FALSE
)

euclidean_full_join(
  a,
  b,
  by = NULL,
  threshold = 1,
  n_bands = 30,
  band_width = 5,
  r = 0.5,
  progress = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="euclidean_anti_join_+3A_a">a</code>, <code id="euclidean_anti_join_+3A_b">b</code></td>
<td>
<p>The two dataframes to join.</p>
</td></tr>
<tr><td><code id="euclidean_anti_join_+3A_by">by</code></td>
<td>
<p>A named vector indicating which columns to join on. Format should
be the same as dplyr: <code>by = c("column_name_in_df_a" = "column_name_in_df_b")</code>, but two columns must be specified in each dataset
(x column and y column). Specification made with <code>dplyr::join_by()</code> are
also accepted.</p>
</td></tr>
<tr><td><code id="euclidean_anti_join_+3A_threshold">threshold</code></td>
<td>
<p>The distance threshold below which units should be
considered a match. Note that contrary to Jaccard joins, this value is
about the distance and not the similarity. Therefore, a lower value means a
higher similarity.</p>
</td></tr>
<tr><td><code id="euclidean_anti_join_+3A_n_bands">n_bands</code></td>
<td>
<p>The number of bands used in the minihash algorithm (default is
40). Use this in conjunction with the <code>band_width</code> to determine the
performance of the hashing. The default settings are for a
(.2, .8, .001, .999)-sensitive hash i.e. that pairs with a similarity of less
than .2 have a &gt;.1% chance of being compared, while pairs with a similarity
of greater than .8 have a &gt;99.9% chance of being compared.</p>
</td></tr>
<tr><td><code id="euclidean_anti_join_+3A_band_width">band_width</code></td>
<td>
<p>The length of each band used in the minihashing algorithm
(default is 8) Use this in conjunction with the <code>n_bands</code> to determine the
performance of the hashing. The default settings are for a
(.2, .8, .001, .999)-sensitive hash i.e. that pairs with a similarity of less
than .2 have a &gt;.1% chance of being compared, while pairs with a similarity
of greater than .8 have a &gt;99.9% chance of being compared.</p>
</td></tr>
<tr><td><code id="euclidean_anti_join_+3A_r">r</code></td>
<td>
<p>Hyperparameter used to govern the sensitivity of the locality
sensitive hash. Corresponds to the width of the hash bucket in the LSH
algorithm. Increasing values of <code>r</code> mean more hash collisions and higher
sensitivity (fewer false-negatives) at the cost of lower specificity (more
false-positives and longer run time). For more information, see the
description in <a href="https://doi.org/10.1145/997817.997857">doi:10.1145/997817.997857</a>.</p>
</td></tr>
<tr><td><code id="euclidean_anti_join_+3A_progress">progress</code></td>
<td>
<p>Set to <code>TRUE</code> to print progress.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble fuzzily-joined on the basis of the variables in <code>by.</code> Tries
to adhere to the same standards as the dplyr-joins, and uses the same
logical joining patterns (i.e. inner-join joins and keeps only observations
in both datasets).
</p>


<h3>References</h3>

<p>Datar, Mayur, Nicole Immorlica, Pitor Indyk, and Vahab Mirrokni.
&quot;Locality-Sensitive Hashing Scheme Based on p-Stable Distributions&quot; SCG
'04: Proceedings of the twentieth annual symposium on Computational
geometry (2004): 253-262
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 10

# Build two matrices that have close values
X_1 &lt;- matrix(c(seq(0, 1, 1 / (n - 1)), seq(0, 1, 1 / (n - 1))), nrow = n)
X_2 &lt;- X_1 + .0000001

X_1 &lt;- as.data.frame(X_1)
X_2 &lt;- as.data.frame(X_2)

X_1$id_1 &lt;- 1:n
X_2$id_2 &lt;- 1:n

# only keep observations that have a match
euclidean_inner_join(X_1, X_2, by = c("V1", "V2"), threshold = .00005)

# keep all observations from X_1, regardless of whether they have a match
euclidean_inner_join(X_1, X_2, by = c("V1", "V2"), threshold = .00005)
</code></pre>

<hr>
<h2 id='euclidean_curve'>Plot S-Curve for a LSH with given hyperparameters</h2><span id='topic+euclidean_curve'></span>

<h3>Description</h3>

<p>Plot S-Curve for a LSH with given hyperparameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>euclidean_curve(n_bands, band_width, r, up_to = 100)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="euclidean_curve_+3A_n_bands">n_bands</code></td>
<td>
<p>The number of LSH bands calculated</p>
</td></tr>
<tr><td><code id="euclidean_curve_+3A_band_width">band_width</code></td>
<td>
<p>The number of hashes in each band</p>
</td></tr>
<tr><td><code id="euclidean_curve_+3A_r">r</code></td>
<td>
<p>the &quot;r&quot; hyperparameter used to govern the sensitivity of the hash.</p>
</td></tr>
<tr><td><code id="euclidean_curve_+3A_up_to">up_to</code></td>
<td>
<p>the right extent of the x axis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot showing the probability a pair is proposed as a match, given
the Jaccard similarity of the two items.
</p>

<hr>
<h2 id='euclidean_probability'>Find Probability of Match Based on Similarity</h2><span id='topic+euclidean_probability'></span>

<h3>Description</h3>

<p>Find Probability of Match Based on Similarity
</p>


<h3>Usage</h3>

<pre><code class='language-R'>euclidean_probability(distance, n_bands, band_width, r)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="euclidean_probability_+3A_distance">distance</code></td>
<td>
<p>the euclidian distance between the two vectors you want to
compare.</p>
</td></tr>
<tr><td><code id="euclidean_probability_+3A_n_bands">n_bands</code></td>
<td>
<p>The number of LSH bands used in hashing.</p>
</td></tr>
<tr><td><code id="euclidean_probability_+3A_band_width">band_width</code></td>
<td>
<p>The number of hashes in each band.</p>
</td></tr>
<tr><td><code id="euclidean_probability_+3A_r">r</code></td>
<td>
<p>the &quot;r&quot; hyperparameter used to govern the sensitivity of the hash.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a decimal number giving the proability that the two items will be
returned as a candidate pair from the minihash algorithm.
</p>

<hr>
<h2 id='hamming_distance'>Calculate Hamming distance of two character vectors</h2><span id='topic+hamming_distance'></span>

<h3>Description</h3>

<p>Calculate Hamming distance of two character vectors
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hamming_distance(a, b)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hamming_distance_+3A_a">a</code></td>
<td>
<p>the first character vector</p>
</td></tr>
<tr><td><code id="hamming_distance_+3A_b">b</code></td>
<td>
<p>the first character vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of hamming similarities of the strings
</p>


<h3>Examples</h3>

<pre><code class='language-R'>hamming_distance(
  c("ACGTCGATGACGTGATGCGTAGCGTA", "ACGTCGATGTGCTCTCGTCGATCTAC"),
  c("ACGTCGACGACGTGATGCGCAGCGTA", "ACGTCGATGGGGTCTCGTCGATCTAC")
)

</code></pre>

<hr>
<h2 id='hamming_inner_join'>Fuzzy joins for Hamming distance using Locality Sensitive Hashing</h2><span id='topic+hamming_inner_join'></span><span id='topic+hamming_anti_join'></span><span id='topic+hamming_left_join'></span><span id='topic+hamming_right_join'></span><span id='topic+hamming_full_join'></span>

<h3>Description</h3>

<p>Find similar rows between two tables using the hamming distance. The hamming
distance is equal to the number characters two strings differ by, or is equal
to infinity if two strings are of different lengths
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hamming_inner_join(
  a,
  b,
  by = NULL,
  n_bands = 100,
  band_width = 8,
  threshold = 2,
  progress = FALSE,
  clean = FALSE,
  similarity_column = NULL
)

hamming_anti_join(
  a,
  b,
  by = NULL,
  n_bands = 100,
  band_width = 100,
  threshold = 2,
  progress = FALSE,
  clean = FALSE,
  similarity_column = NULL
)

hamming_left_join(
  a,
  b,
  by = NULL,
  n_bands = 100,
  band_width = 100,
  threshold = 2,
  progress = FALSE,
  clean = FALSE,
  similarity_column = NULL
)

hamming_right_join(
  a,
  b,
  by = NULL,
  n_bands = 100,
  band_width = 100,
  threshold = 2,
  progress = FALSE,
  clean = FALSE,
  similarity_column = NULL
)

hamming_full_join(
  a,
  b,
  by = NULL,
  n_bands = 100,
  band_width = 100,
  threshold = 2,
  progress = FALSE,
  clean = FALSE,
  similarity_column = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hamming_inner_join_+3A_a">a</code>, <code id="hamming_inner_join_+3A_b">b</code></td>
<td>
<p>The two dataframes to join.</p>
</td></tr>
<tr><td><code id="hamming_inner_join_+3A_by">by</code></td>
<td>
<p>A named vector indicating which columns to join on. Format should
be the same as dplyr: <code>by = c("column_name_in_df_a" = "column_name_in_df_b")</code>, but two columns must be specified in each dataset
(x column and y column). Specification made with <code>dplyr::join_by()</code> are
also accepted.</p>
</td></tr>
<tr><td><code id="hamming_inner_join_+3A_n_bands">n_bands</code></td>
<td>
<p>The number of bands used in the locality sensitive hashing
algorithm (default is 100). Use this in conjunction with the
<code>band_width</code> to determine the performance of the hashing. Generally
speaking, a higher number of bands leads to greater recall at the cost of
higher runtime.</p>
</td></tr>
<tr><td><code id="hamming_inner_join_+3A_band_width">band_width</code></td>
<td>
<p>The length of each band used in the minihashing algorithm
(default is 8). Use this in conjunction with the <code>n_bands</code> to
determine the performance of the hashing. Generally speaking a wider number
of bands decreases the number of false positives, decreasing runtime at the
cost of lower sensitivity (true matches are less likely to be found).</p>
</td></tr>
<tr><td><code id="hamming_inner_join_+3A_threshold">threshold</code></td>
<td>
<p>The Hamming distance threshold below which two strings
should be considered a match. A distance of zero corresponds to complete
equality between strings, while a distance of 'x' between two strings means
that 'x' substitutions must be made to transform one string into the other.</p>
</td></tr>
<tr><td><code id="hamming_inner_join_+3A_progress">progress</code></td>
<td>
<p>Set to <code>TRUE</code> to print progress.</p>
</td></tr>
<tr><td><code id="hamming_inner_join_+3A_clean">clean</code></td>
<td>
<p>Should the strings that you fuzzy join on be cleaned (coerced to
lower-case, stripped of punctuation and spaces)? Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="hamming_inner_join_+3A_similarity_column">similarity_column</code></td>
<td>
<p>An optional character vector. If provided, the data
frame will contain a column with this name giving the Hamming distance
between the two fields. Extra column will not be present if anti-joining.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble fuzzily-joined on the basis of the variables in <code>by.</code> Tries
to adhere to the same standards as the dplyr-joins, and uses the same
logical joining patterns (i.e. inner-join joins and keeps only observations
in both datasets).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load baby names data
# install.packages("babynames")
library(babynames)

baby_names &lt;- data.frame(name = tolower(unique(babynames$name))[1:500])
baby_names_mispelled &lt;- data.frame(
  name_mispelled = gsub("[aeiouy]", "x", baby_names$name)
)

# Run the join and only keep rows that have a match:
hamming_inner_join(
  baby_names,
  baby_names_mispelled,
  by = c("name" = "name_mispelled"),
  threshold = 3,
  n_bands = 150,
  band_width = 10,
  clean = FALSE # default
)

# Run the join and keep all rows from the first dataset, regardless of whether
# they have a match:
hamming_left_join(
  baby_names,
  baby_names_mispelled,
  by = c("name" = "name_mispelled"),
  threshold = 3,
  n_bands = 150,
  band_width = 10,
)
</code></pre>

<hr>
<h2 id='hamming_probability'>Find Probability of Match Based on Similarity</h2><span id='topic+hamming_probability'></span>

<h3>Description</h3>

<p>Find Probability of Match Based on Similarity
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hamming_probability(distance, input_length, n_bands, band_width)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hamming_probability_+3A_distance">distance</code></td>
<td>
<p>The hamming distance of the two strings you want to compare</p>
</td></tr>
<tr><td><code id="hamming_probability_+3A_input_length">input_length</code></td>
<td>
<p>the length (number of characters) of the input strings
you want to calculate.</p>
</td></tr>
<tr><td><code id="hamming_probability_+3A_n_bands">n_bands</code></td>
<td>
<p>The number of LSH bands used in hashing.</p>
</td></tr>
<tr><td><code id="hamming_probability_+3A_band_width">band_width</code></td>
<td>
<p>The number of hashes in each band.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A decimal number giving the probability that the two items will be
returned as a candidate pair from the lsh algotithm.
</p>

<hr>
<h2 id='jaccard_curve'>Plot S-Curve for a LSH with given hyperparameters</h2><span id='topic+jaccard_curve'></span>

<h3>Description</h3>

<p>Plot S-Curve for a LSH with given hyperparameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jaccard_curve(n_bands, band_width)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="jaccard_curve_+3A_n_bands">n_bands</code></td>
<td>
<p>The number of LSH bands calculated</p>
</td></tr>
<tr><td><code id="jaccard_curve_+3A_band_width">band_width</code></td>
<td>
<p>The number of hashes in each band</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot showing the probability a pair is proposed as a match, given
the Jaccard similarity of the two items.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Plot the probability two pairs will be matched as a function of their
# jaccard similarity, given the hyperparameters n_bands and band_width.
jaccard_curve(40, 6)

</code></pre>

<hr>
<h2 id='jaccard_hyper_grid_search'>Help Choose the Appropriate LSH Hyperparameters</h2><span id='topic+jaccard_hyper_grid_search'></span>

<h3>Description</h3>

<p>Runs a grid search to find the hyperparameters that will achieve an
(s1,s2,p1,p2)-sensitive locality sensitive hash. A locality sensitive hash
can be called (s1,s2,p1,p2)-sensitive if to strings with a similarity less
than s1 have a less than p1 chance of being compared, while two strings with
similarity s2 have a greater than p2 chance of being compared. As an
example, a (.1,.7,.001,.999)-sensitive LSH means that strings with
similarity less than .1 will have a .1% chance of being compared, while
strings with .7 similarity have a 99.9% chance of being compared.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jaccard_hyper_grid_search(s1 = 0.1, s2 = 0.7, p1 = 0.001, p2 = 0.999)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="jaccard_hyper_grid_search_+3A_s1">s1</code></td>
<td>
<p>the s1 parameter (the first similaity).</p>
</td></tr>
<tr><td><code id="jaccard_hyper_grid_search_+3A_s2">s2</code></td>
<td>
<p>the s2 parameter (the second similarity, must be greater than s1).</p>
</td></tr>
<tr><td><code id="jaccard_hyper_grid_search_+3A_p1">p1</code></td>
<td>
<p>the p1 parameter (the first probability).</p>
</td></tr>
<tr><td><code id="jaccard_hyper_grid_search_+3A_p2">p2</code></td>
<td>
<p>the p2 parameter (the second probability, must be greater than p1).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named vector with the hyperparameters that will meet the LSH
criteria, while reducing runitme.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Help me find the parameters that will minimize runtime while ensuring that
# two strings with similarity .1 will be compared less than .1% of the time,
# strings with .8 similaity will have a 99.95% chance of being compared:
jaccard_hyper_grid_search(.1, .9, .001, .995)

</code></pre>

<hr>
<h2 id='jaccard_inner_join'>Fuzzy joins for Jaccard distance using MinHash</h2><span id='topic+jaccard_inner_join'></span><span id='topic+jaccard_anti_join'></span><span id='topic+jaccard_left_join'></span><span id='topic+jaccard_right_join'></span><span id='topic+jaccard_full_join'></span>

<h3>Description</h3>

<p>Fuzzy joins for Jaccard distance using MinHash
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jaccard_inner_join(
  a,
  b,
  by = NULL,
  block_by = NULL,
  n_gram_width = 2,
  n_bands = 50,
  band_width = 8,
  threshold = 0.7,
  progress = FALSE,
  clean = FALSE,
  similarity_column = NULL
)

jaccard_anti_join(
  a,
  b,
  by = NULL,
  block_by = NULL,
  n_gram_width = 2,
  n_bands = 50,
  band_width = 8,
  threshold = 0.7,
  progress = FALSE,
  clean = FALSE,
  similarity_column = NULL
)

jaccard_left_join(
  a,
  b,
  by = NULL,
  block_by = NULL,
  n_gram_width = 2,
  n_bands = 50,
  band_width = 8,
  threshold = 0.7,
  progress = FALSE,
  clean = FALSE,
  similarity_column = NULL
)

jaccard_right_join(
  a,
  b,
  by = NULL,
  block_by = NULL,
  n_gram_width = 2,
  n_bands = 50,
  band_width = 8,
  threshold = 0.7,
  progress = FALSE,
  clean = FALSE,
  similarity_column = NULL
)

jaccard_full_join(
  a,
  b,
  by = NULL,
  block_by = NULL,
  n_gram_width = 2,
  n_bands = 50,
  band_width = 8,
  threshold = 0.7,
  progress = FALSE,
  clean = FALSE,
  similarity_column = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="jaccard_inner_join_+3A_a">a</code>, <code id="jaccard_inner_join_+3A_b">b</code></td>
<td>
<p>The two dataframes to join.</p>
</td></tr>
<tr><td><code id="jaccard_inner_join_+3A_by">by</code></td>
<td>
<p>A named vector indicating which columns to join on. Format should
be the same as dplyr: <code>by = c("column_name_in_df_a" = "column_name_in_df_b")</code>, but two columns must be specified in each dataset
(x column and y column). Specification made with <code>dplyr::join_by()</code> are
also accepted.</p>
</td></tr>
<tr><td><code id="jaccard_inner_join_+3A_block_by">block_by</code></td>
<td>
<p>A named vector indicating which column to block on, such that
rows that disagree on this field cannot be considered a match. Format
should be the same as dplyr: <code>by = c("column_name_in_df_a" = "column_name_in_df_b")</code></p>
</td></tr>
<tr><td><code id="jaccard_inner_join_+3A_n_gram_width">n_gram_width</code></td>
<td>
<p>The length of the n_grams used in calculating the Jaccard
similarity. For best performance, I set this large enough that the chance
any string has a specific n_gram is low (i.e. <code>n_gram_width</code> = 2 or 3 when
matching on first names, 5 or 6 when matching on entire sentences).</p>
</td></tr>
<tr><td><code id="jaccard_inner_join_+3A_n_bands">n_bands</code></td>
<td>
<p>The number of bands used in the minihash algorithm (default is
40). Use this in conjunction with the <code>band_width</code> to determine the
performance of the hashing. The default settings are for a
(.2, .8, .001, .999)-sensitive hash i.e. that pairs with a similarity of less
than .2 have a &gt;.1% chance of being compared, while pairs with a similarity
of greater than .8 have a &gt;99.9% chance of being compared.</p>
</td></tr>
<tr><td><code id="jaccard_inner_join_+3A_band_width">band_width</code></td>
<td>
<p>The length of each band used in the minihashing algorithm
(default is 8) Use this in conjunction with the <code>n_bands</code> to determine the
performance of the hashing. The default settings are for a
(.2, .8, .001, .999)-sensitive hash i.e. that pairs with a similarity of less
than .2 have a &gt;.1% chance of being compared, while pairs with a similarity
of greater than .8 have a &gt;99.9% chance of being compared.</p>
</td></tr>
<tr><td><code id="jaccard_inner_join_+3A_threshold">threshold</code></td>
<td>
<p>The Jaccard similarity threshold above which two strings
should be considered a match (default is .95). The similarity is equal to
1 - the Jaccard distance between the two strings, so 1 implies the strings
are identical, while a similarity of zero implies the strings are completely
dissimilar.</p>
</td></tr>
<tr><td><code id="jaccard_inner_join_+3A_progress">progress</code></td>
<td>
<p>Set to <code>TRUE</code> to print progress.</p>
</td></tr>
<tr><td><code id="jaccard_inner_join_+3A_clean">clean</code></td>
<td>
<p>Should the strings that you fuzzy join on be cleaned (coerced to
lower-case, stripped of punctuation and spaces)? Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="jaccard_inner_join_+3A_similarity_column">similarity_column</code></td>
<td>
<p>An optional character vector. If provided, the data
frame will contain a column with this name giving the Jaccard similarity
between the two fields. Extra column will not be present if anti-joining.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble fuzzily-joined on the basis of the variables in <code>by.</code> Tries
to adhere to the same standards as the dplyr-joins, and uses the same
logical joining patterns (i.e. inner-join joins and keeps only observations
in both datasets).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load baby names data
# install.packages("babynames")
library(babynames)

baby_names &lt;- data.frame(name = tolower(unique(babynames$name))[1:500])
baby_names_sans_vowels &lt;- data.frame(
  name_wo_vowels = gsub("[aeiouy]", "", baby_names$name)
)
# Check the probability two pairs of strings with similarity .8 will be
# matched with a band width of 8 and 30 bands using the `jaccard_probability()`
# function:
jaccard_probability(.8, 30, 8)

# Run the join and only keep rows that have a match:
jaccard_inner_join(
  baby_names,
  baby_names_sans_vowels,
  by = c("name" = "name_wo_vowels"),
  threshold = .8,
  n_bands = 20,
  band_width = 6,
  n_gram_width = 1,
  clean = FALSE # default
)

# Run the join and keep all rows from the first dataset, regardless of whether
# they have a match:
jaccard_left_join(
  baby_names,
  baby_names_sans_vowels,
  by = c("name" = "name_wo_vowels"),
  threshold = .8,
  n_bands = 20,
  band_width = 6,
  n_gram_width = 1
)
</code></pre>

<hr>
<h2 id='jaccard_probability'>Find Probability of Match Based on Similarity</h2><span id='topic+jaccard_probability'></span>

<h3>Description</h3>

<p>This is a port of the
<a href="https://docs.ropensci.org/textreuse/reference/lsh_probability.html">lsh_probability</a>
function from the
<a href="https://cran.r-project.org/package=textreuse">textreuse</a>
package, with arguments changed to reflect the hyperparameters in this
package. It gives the probability that two strings of jaccard similarity
<code>similarity</code> will be matched, given the chosen bandwidth and number of
bands.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jaccard_probability(similarity, n_bands, band_width)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="jaccard_probability_+3A_similarity">similarity</code></td>
<td>
<p>the similarity of the two strings you want to compare</p>
</td></tr>
<tr><td><code id="jaccard_probability_+3A_n_bands">n_bands</code></td>
<td>
<p>The number of LSH bands used in hashing.</p>
</td></tr>
<tr><td><code id="jaccard_probability_+3A_band_width">band_width</code></td>
<td>
<p>The number of hashes in each band.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a decimal number giving the probability that the two items will be
returned as a candidate pair from the minhash algorithm.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Find the probability two pairs will be matched given they have a
# jaccard_similarity of .8, band width of 5, and 50 bands:
jaccard_probability(.8, n_bands = 50, band_width = 5)
</code></pre>

<hr>
<h2 id='jaccard_similarity'>Calculate Jaccard Similarity of two character vectors</h2><span id='topic+jaccard_similarity'></span>

<h3>Description</h3>

<p>Calculate Jaccard Similarity of two character vectors
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jaccard_similarity(a, b, ngram_width = 2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="jaccard_similarity_+3A_a">a</code></td>
<td>
<p>the first character vector</p>
</td></tr>
<tr><td><code id="jaccard_similarity_+3A_b">b</code></td>
<td>
<p>the first character vector</p>
</td></tr>
<tr><td><code id="jaccard_similarity_+3A_ngram_width">ngram_width</code></td>
<td>
<p>the length of the shingles / ngrams used in the
similarity calculation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of jaccard similarities of the strings
</p>


<h3>Examples</h3>

<pre><code class='language-R'>jaccard_similarity(
  c("the quick brown fox", "jumped over the lazy dog"),
  c("the quck bron fx", "jumped over hte lazy dog")
)

</code></pre>

<hr>
<h2 id='jaccard_string_group'>Fuzzy String Grouping Using Minhashing</h2><span id='topic+jaccard_string_group'></span>

<h3>Description</h3>

<p>Performs fuzzy string grouping in which similar strings are assigned to the
same group. Uses the <code>cluster_fast_greedy()</code> community detection algorithm
from the <code>igraph</code> package to create the groups. Must have igraph installed
in order to use this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jaccard_string_group(
  string,
  n_gram_width = 2,
  n_bands = 45,
  band_width = 8,
  threshold = 0.7,
  progress = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="jaccard_string_group_+3A_string">string</code></td>
<td>
<p>a character you wish to perform entity resolution on.</p>
</td></tr>
<tr><td><code id="jaccard_string_group_+3A_n_gram_width">n_gram_width</code></td>
<td>
<p>the length of the n_grams used in calculating the
jaccard similarity. For best performance, I set this large enough that the
chance any string has a specific n_gram is low (i.e. <code>n_gram_width</code> = 2
or 3 when matching on first names, 5 or 6 when matching on entire
sentences).</p>
</td></tr>
<tr><td><code id="jaccard_string_group_+3A_n_bands">n_bands</code></td>
<td>
<p>the number of bands used in the minihash algorithm (default
is 40). Use this in conjunction with the <code>band_width</code> to determine the
performance of the hashing. The default settings are for a
(.2,.8,.001,.999)-sensitive hash i.e. that pairs with a similarity of less
than .2 have a &gt;.1% chance of being compared, while pairs with a similarity
of greater than .8 have a &gt;99.9% chance of being compared.</p>
</td></tr>
<tr><td><code id="jaccard_string_group_+3A_band_width">band_width</code></td>
<td>
<p>the length of each band used in the minihashing algorithm
(default is 8) Use this in conjunction with the <code>n_bands</code> to determine
the performance of the hashing. The default settings are for a
(.2,.8,.001,.999)-sensitive hash i.e. that pairs with a similarity of less
than .2 have a &gt;.1% chance of being compared, while pairs with a similarity
of greater than .8 have a &gt;99.9% chance of being compared.</p>
</td></tr>
<tr><td><code id="jaccard_string_group_+3A_threshold">threshold</code></td>
<td>
<p>the jaccard similarity threshold above which two strings
should be considered a match (default is .95). The similarity is euqal to 1
</p>

<ul>
<li><p> the jaccard distance between the two strings, so 1 implies the strings are
identical, while a similarity of zero implies the strings are completely
dissimilar.
</p>
</li></ul>
</td></tr>
<tr><td><code id="jaccard_string_group_+3A_progress">progress</code></td>
<td>
<p>set to true to report progress of the algorithm</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a string vector storing the group of each element in the original
input strings. The input vector is grouped so that similar strings belong to
the same group, which is given a standardized name.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
string &lt;- c(
  "beniamino", "jack", "benjamin", "beniamin",
  "jacky", "giacomo", "gaicomo"
)
jaccard_string_group(string, threshold = .2, n_bands = 90, n_gram_width = 1)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
