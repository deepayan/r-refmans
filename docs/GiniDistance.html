<!DOCTYPE html><html><head><title>Help for package GiniDistance</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {GiniDistance}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ConfidenceInterval'><p>Confidence Interval of Dependence measure</p></a></li>
<li><a href='#CriticalValue'><p>Find a critical value by permutation test of dependence between X and Y using kernel (Gini) distance covariance or correlation statistics</p></a></li>
<li><a href='#dCor'><p>Distance Covariance and Correlation Statistics</p></a></li>
<li><a href='#dCov'><p>Distance Covariance Statistic</p></a></li>
<li><a href='#gCor'><p>Gini Distance Covariance and Correlation Statistics</p></a></li>
<li><a href='#gCov'><p> Gini Distance Covariance Statistics</p></a></li>
<li><a href='#GiniDistance-package'><p>GiniDistance</p></a></li>
<li><a href='#gmd'><p>Gini Mean Difference</p></a></li>
<li><a href='#KdCor'><p>Kernel Distance Correlation Statistics</p></a></li>
<li><a href='#KdCov'><p>Kernel Distance Covariance Statistics</p></a></li>
<li><a href='#KgCor'><p> Kernel Gini Distance Correlation Statistics</p></a></li>
<li><a href='#KgCov'><p> Kernel Gini Distance Covariance Statistics</p></a></li>
<li><a href='#Kgmd'><p> Kernel Gini Mean Difference Statistics</p></a></li>
<li><a href='#PermutationTest'><p>Permutation test of dependence between X and Y using (Gini) distance covariance or correlation statistics</p></a></li>
<li><a href='#RcppgCor'><p>Gini Distance Correlation Statistics</p></a></li>
<li><a href='#RcppgCov'><p> Gini Distance Covariance Statistics</p></a></li>
<li><a href='#RcppGmd'><p> Gini Mean Difference Statistics</p></a></li>
<li><a href='#RcppKgCor'><p> Kernel Gini Distance Correlation Statistics</p></a></li>
<li><a href='#RcppKgCov'><p> Kernel Gini Distance Covariance Statistics</p></a></li>
<li><a href='#RcppKGmd'><p> Kernel Gini Mean Difference Statistics</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>A New Gini Correlation Between Quantitative and Qualitative
Variables</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Author:</td>
<td>Dao Nguyen and Xin Dang</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Dao Nguyen &lt;dxnguyen@go.olemiss.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>An implementation of a new Gini covariance and correlation to measure dependence between a categorical and numerical variables. Dang, X., Nguyen, D., Chen, Y. and Zhang, J., (2018) &lt;<a href="https://arxiv.org/abs/1809.09793">arXiv:1809.09793</a>&gt;. </td>
</tr>
<tr>
<td>Depends:</td>
<td>R(&ge; 3.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.0), energy, readxl, randomForest</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Collate:</td>
<td>GiniDistance-package.R RcppExports.R gmd.R gCov.R gCor.R
dCov.R dCor.R Kgmd.R KgCov.R KgCor.R KdCov.R KdCor.R
ConfidenceInterval.R PermutationTest.R utils.R</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.0</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-09-01 02:01:20 UTC; dao</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-09-02 06:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ConfidenceInterval'>Confidence Interval of Dependence measure</h2><span id='topic+ConfidenceInterval'></span>

<h3>Description</h3>

<p>Find confidence intervals for dependence measures in which Xs are quantitative, Y are categorical using jack-knife method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ConfidenceInterval(x, y, sigma, alpha, level, method)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ConfidenceInterval_+3A_x">x</code></td>
<td>
<p> data </p>
</td></tr>
<tr><td><code id="ConfidenceInterval_+3A_y">y</code></td>
<td>
<p> label of data or univariate response variable</p>
</td></tr>
<tr><td><code id="ConfidenceInterval_+3A_sigma">sigma</code></td>
<td>
<p> kernel parameter</p>
</td></tr>
<tr><td><code id="ConfidenceInterval_+3A_alpha">alpha</code></td>
<td>
<p> exponent on Euclidean distance, in (0,2]</p>
</td></tr>
<tr><td><code id="ConfidenceInterval_+3A_level">level</code></td>
<td>
<p> level of confidence, in [0,1]</p>
</td></tr>
<tr><td><code id="ConfidenceInterval_+3A_method">method</code></td>
<td>
<p> name of dependence measure which can chosen from &quot;gCor&quot;,&quot;gCov&quot;,&quot;dCor&quot;,&quot;dCov&quot;,&quot;KgCor&quot;, &quot;KgCov&quot;, &quot;KdCor&quot; and &quot;KdCov&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ConfidenceInterval</code> compute the confidence interval of the distance correlation statistics.
It is a self-contained R function returning a variance of the measure of dependence statistics. 
</p>
<p>The sample size (number of rows) of the data must agree with the length of the label vector, and samples must not contain missing values. Arguments
<code>x</code>, <code>y</code> are treated as data and labels. <code>alpha</code> if missing by default is 1, otherwise it is exponent on the Euclidean distance.
</p>
<p>Suppose a sample data <code class="reqn"> {\mathcal{D}} =\{(\bold{x}_i,y_i)\} </code> for <code class="reqn">i = 1,...,n</code> available. The confidence interval is built upon the asymptotic normality of sample dependence statistic. The asymptotic variance is estimated by the Jackknife method. 
More details refer to Shao and Tu (1996).   
</p>


<h3>Value</h3>

<p><code>ConfidenceInterval</code> returns the confidence interval of distance correlation
</p>


<h3>References</h3>

<p>Dang, X., Nguyen, D., Chen, Y. and Zhang, J. (2019). A new Gini correlation between quantitative and qualitative variables. Submitted. 
</p>
<p>Shao, J. and Tu, D. (1996). The Jackknife and Bootstrap. Springer, New York.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  x &lt;- iris[,1:4]
  y &lt;- unclass(iris[,5])
  ConfidenceInterval(x, y, alpha=1, level=0.95, method='gCor')
</code></pre>

<hr>
<h2 id='CriticalValue'>Find a critical value by permutation test of dependence between X and Y using kernel (Gini) distance covariance or correlation statistics</h2><span id='topic+CriticalValue'></span>

<h3>Description</h3>

<p>Find a critical value by permutation test using variance of kernel (Gini) distance covariance or correlation statistics,
in which Xs are quantitative, Y are categorical, sigma is kernel standard deviation, alpha is an exponent on Euclidean distance and returns the critical value of the measures of dependence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  CriticalValue(x, y, sigma, alpha, level, M = 1000, method)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CriticalValue_+3A_x">x</code></td>
<td>
<p> data </p>
</td></tr>
<tr><td><code id="CriticalValue_+3A_y">y</code></td>
<td>
<p> label of data or univariate response variable</p>
</td></tr>
<tr><td><code id="CriticalValue_+3A_sigma">sigma</code></td>
<td>
<p> kernel standard deviation</p>
</td></tr>
<tr><td><code id="CriticalValue_+3A_alpha">alpha</code></td>
<td>
<p> exponent on Euclidean distance, in (0,2]</p>
</td></tr>
<tr><td><code id="CriticalValue_+3A_level">level</code></td>
<td>
<p> significance level of the test, the default value = 0.05</p>
</td></tr>
<tr><td><code id="CriticalValue_+3A_m">M</code></td>
<td>
<p> number of permutations</p>
</td></tr>
<tr><td><code id="CriticalValue_+3A_method">method</code></td>
<td>
<p> string name of the method for permutation test, e.g. gCov</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>CriticalValue</code> compute the critical value of a dependence test of a kernel (Gini) distance covariance or correlation statistics.
It is a self-contained R function returning the critical value of the measure of dependence statistics. 
</p>
<p>The critical value of the test of significance level <code class="reqn">\gamma</code>, however, is obtained by a permutation procedure.
Let <code class="reqn">\nu = 1: n</code> be the vector of original sample indices of the sample for <code class="reqn">Y</code> labels and <code class="reqn">\hat{\rho}_g(\alpha) = \hat{\rho}(\nu;\alpha)</code>. 
Let <code class="reqn">\pi(\nu)</code> denote a permutation of the elements of <code class="reqn">\nu</code> and the corresponding <code class="reqn">\hat{\rho}_g(\pi;\alpha)</code> is computed. 
Under the <code class="reqn">{\cal H}_0</code>, <code class="reqn">\hat{\rho}_g(\nu)</code>
and <code class="reqn">\hat{\rho}_g(\pi;\alpha)</code> are identically distributed for every permutation <code class="reqn">\pi</code> of <code class="reqn">\nu</code>. 
Hence, based on <code class="reqn">M</code> permutations,  the critical value <code class="reqn">q_{\gamma}</code> is estimated by the <code class="reqn">(1-\gamma)100\%</code> sample 
quantile of <code class="reqn">\hat{\rho}_g(\pi_m;\alpha)</code>, <code class="reqn">m=1,...,M</code>. Usually <code class="reqn">100\leq M\leq 1000</code> is sufficient 
for a good estimation on the critical value.   
</p>
<p>See <code><a href="#topic+PermutationTest">PermutationTest</a></code> for a test of multivariate independence
based on the (Gini) distance statistic.
</p>


<h3>Value</h3>

<p><code>CriticalValue</code> returns return the critical value of the measures of the dependence of the permutation test of a specified function
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PermutationTest">PermutationTest</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  n = 50
  x &lt;- runif(n)
  y &lt;- c(rep(1,n/2),rep(2,n/2))
  CriticalValue(x, y, sigma=1, alpha=2, level=0.04, M = 1000, method='KgCov') 
</code></pre>

<hr>
<h2 id='dCor'>Distance Covariance and Correlation Statistics</h2><span id='topic+dCor'></span>

<h3>Description</h3>

<p>Computes distance covariance and correlation statistics, in which Xs are quantitative and Ys are categorical and return the measures of dependence.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  dCor(x, y, alpha)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dCor_+3A_x">x</code></td>
<td>
<p> data </p>
</td></tr>
<tr><td><code id="dCor_+3A_y">y</code></td>
<td>
<p> label of data or univariate response variable</p>
</td></tr>
<tr><td><code id="dCor_+3A_alpha">alpha</code></td>
<td>
<p> exponent on Euclidean distance, in (0,2]</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sample size (number of rows) of the data must agree with the length of the label vector, and samples must not contain missing values. Arguments
<code>x</code>, <code>y</code> are treated as data and labels.
</p>
<p><code>dCor</code> calls <code>dcor</code> function from energy package which computes the distance correlation between X and Y where both are numerical variables. If Y is categorical,  the set difference metric on the support of <code class="reqn">Y</code> is used. That is, <code class="reqn">d(y, y^\prime) =|y-y^\prime|:=  I(y\neq y^\prime),</code>
where <code class="reqn">I (\cdot)</code> is the indicator function. Then the sample distance correlation between data and labels is computed as follows. 
</p>
<p>Let <code class="reqn">A=(a_{ij})</code> be a symmetric, <code class="reqn">n \times n</code>, centered distance matrix of sample <code class="reqn">\mathbf x_1,\cdots, \mathbf x_n</code>. The <code class="reqn">(i,j)</code>-th entry of <code class="reqn">A</code> is <code class="reqn">a_{ij}-\frac{1}{n-2}a_{i\cdot}-\frac{1}{n-2}a_{\cdot j} + \frac{1}{(n-1)(n-2)}a_{\cdot \cdot}</code> if <code class="reqn">i \neq j</code> and 0 if <code class="reqn">i=j</code>,
where <code class="reqn">a_{ij} = \|\mathbf x_i-\mathbf x_j\|^{\alpha}</code>, <code class="reqn">a_{i\cdot} = \sum_{j=1}^n a_{ij}</code>, <code class="reqn">a_{\cdot j} = \sum_{i=1}^n a_{ij}</code>, and <code class="reqn">a_{\cdot \cdot}=\sum_{i,j=1}^n a_{ij}</code>. Similarly, using the set difference metric, a symmetric, <code class="reqn">n \times n</code>, centered distance matrix is calculated for samples <code class="reqn">y_1,\cdots, y_n</code> and denoted by <code class="reqn">B = (b_{ij})</code>. Unbiased estimators of <code class="reqn">\mbox{dCov}(\mathbf X,Y;\alpha)</code>, <code class="reqn">\mbox{dCov}(\mathbf X, \mathbf X;\alpha)</code> and <code class="reqn">\mbox{dCov}(\mathbf Y, \mathbf Y;\alpha)</code>  are given  respectively as,  <code class="reqn">\frac{1}{n(n-3)}\sum_{i\ne j}A_{ij}B_{ij}</code>, <code class="reqn">\frac{1}{n(n-3)}\sum_{i\ne j}A_{ij}^2</code> and <code class="reqn">\frac{1}{n(n-3)}\sum_{i\ne j}B_{ij}^2</code>. Then the distance correlation is 
</p>
<p style="text-align: center;"><code class="reqn">{dCor}(\mathbf{X}, Y; \alpha) = \frac{\mbox{ dCov}(\mathbf{X}, Y, \alpha)}{ \sqrt{\mbox{ dCov}(\mathbf{X},\mathbf{X};\alpha)} \sqrt{\mbox{ dCov}(Y,Y)}}.</code>
</p>



<h3>Value</h3>

<p><code>dCor</code> returns the sample distance variance of <code>x</code>, distance variance of <code>y</code>, distance covariance of <code>x</code> and <code>y</code> and distance correlation of <code>x</code>, <code>y</code>. 
</p>


<h3>References</h3>

<p>Lyons, R. (2013). Distance covariance in metric spaces. The Annals of Probability, 41 (5), 3284-3305. 
</p>
<p>Szekely, G. J., Rizzo, M. L. and Bakirov, N. (2007). Measuring and testing dependence by correlation of distances. Annals of Statistics, 35 (6), 2769-2794. 
</p>
<p>Rizzo, M.L. and Szekely, G.J., (2017). Energy: E-Statistics: Multivariate Inference via the Energy of Data (R Package), Version 1.7-0.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dCov">dCov</a></code>  <code><a href="#topic+KdCov">KdCov</a></code>  <code><a href="#topic+KdCor">KdCor</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  x &lt;- iris[,1:4]
  y &lt;- unclass(iris[,5])
  dCor(x, y, alpha = 1)
</code></pre>

<hr>
<h2 id='dCov'>Distance Covariance Statistic</h2><span id='topic+dCov'></span>

<h3>Description</h3>

<p>Computes distance covariance statistic,
in which Xs are quantitative and Y are categorical and return the measures of dependence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  dCov(x, y, alpha)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dCov_+3A_x">x</code></td>
<td>
<p> data </p>
</td></tr>
<tr><td><code id="dCov_+3A_y">y</code></td>
<td>
<p> label of data or response variable</p>
</td></tr>
<tr><td><code id="dCov_+3A_alpha">alpha</code></td>
<td>
<p> exponent on Euclidean distance, in (0,2]</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>dCov</code> calls <code>dcov</code> function from energy package to compute distance covariance statistic.
The sample size (number of rows) of the data must agree with the length of the label vector, and samples must not contain missing values. Arguments
<code>x</code>, <code>y</code> are treated as data and labels.
</p>
<p>The distance covariance (<cite>Sezekley07</cite>) is extended from Euclidean space to general metric spaces by Lyons (2013). Based on that idea, we define the discrete metric   
</p>
<p style="text-align: center;"><code class="reqn">d(y, y^\prime) =|y-y^\prime|:=  I(y\neq y^\prime),</code>
</p>

<p>where <code class="reqn">I (\cdot)</code> is the indicator function. Equipped with this set difference metric on the support of <code class="reqn">Y</code> and Euclidean 
distance on the support of <code class="reqn">\mathbf{X}</code>, the corresponding distance covariance and distance correlation for numerical <code class="reqn">\mathbf{X}</code> and categorical <code class="reqn">Y</code> variables are as follows. 
</p>
<p>Let <code class="reqn">A=(a_{ij})</code> be a symmetric, <code class="reqn">n \times n</code>, centered distance matrix of sample <code class="reqn">\bf x_1,\cdots, \bf x_n</code>. The <code class="reqn">(i,j)</code>-th entry of <code class="reqn">A</code> is <code class="reqn">a_{ij}-\frac{1}{n-2}a_{i\cdot}-\frac{1}{n-2}a_{\cdot j} + \frac{1}{(n-1)(n-2)}a_{\cdot \cdot}</code> if <code class="reqn">i \neq j</code> and 0 if <code class="reqn">i=j</code>,
where <code class="reqn">a_{ij} = \|\bf x_i-\bf x_j\|^{\alpha}</code>, <code class="reqn">a_{i\cdot} = \sum_{j=1}^n a_{ij}</code>, <code class="reqn">a_{\cdot j} = \sum_{i=1}^n a_{ij}</code>, and <code class="reqn">a_{\cdot \cdot}=\sum_{i,j=1}^n a_{ij}</code>. Similarly, using the set difference metric, a symmetric, <code class="reqn">n \times n</code>, centered distance matrix is calculated for samples <code class="reqn">y_1,\cdots, y_n</code> and denoted by <code class="reqn">B = (b_{ij})</code>. Unbiased estimators of <code class="reqn">\mbox{dCov}(\bf X,Y;\alpha)</code> is   
</p>
<p><code class="reqn">\frac{1}{n(n-3)}\sum_{i\ne j}A_{ij}B_{ij}</code>.
</p>


<h3>Value</h3>

<p><code>dCov</code> returns the sample distance covariance between data <code>x</code> and label <code>y</code>. 
</p>


<h3>References</h3>

<p>Lyons, R. (2013). Distance covariance in metric spaces. The Annals of Probability, 41 (5), 3284-3305. 
</p>
<p>Rizzo, M.L. and Szekely, G.J., (2017). Energy: E-Statistics: Multivariate Inference via the Energy of Data (R Package), Version 1.7-0.
</p>
<p>Szekely, G. J., Rizzo, M. L. and Bakirov, N. (2007). Measuring and testing dependence by correlation of distances. Annals of Statistics, 35 (6), 2769-2794.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dCor">dCor</a></code> <code><a href="#topic+KdCov">KdCov</a></code>  <code><a href="#topic+KdCor">KdCor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  x &lt;- iris[,1:4]
  y &lt;- unclass(iris[,5])
  dCov(x, y, alpha = 1)
</code></pre>

<hr>
<h2 id='gCor'>Gini Distance Covariance and Correlation Statistics</h2><span id='topic+gCor'></span>

<h3>Description</h3>

<p>Computes Gini distance covariance and correlation statistics,
in which Xs are quantitative, Y are categorical, alpha is exponent on the Euclidean distance and returns the measures of dependence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  gCor(x, y, alpha)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gCor_+3A_x">x</code></td>
<td>
<p> data </p>
</td></tr>
<tr><td><code id="gCor_+3A_y">y</code></td>
<td>
<p> label of data or univariate response variable</p>
</td></tr>
<tr><td><code id="gCor_+3A_alpha">alpha</code></td>
<td>
<p> exponent on Euclidean distance, in (0,2)</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gCor</code> compute Gini distance correlation statistics.
It is a self-contained R function returning a measure of dependence statistics. 
</p>
<p>The sample size (number of rows) of the data must agree with the length of the label vector, and samples must not contain missing values. Arguments
<code>x</code>, <code>y</code> are treated as data and labels. <code>alpha</code> if missing by default is 1, otherwise it is exponent on the Euclidean distance.
</p>
<p>Suppose a sample data <code class="reqn"> {\mathcal{D}} =\{(\mathbf{x}_i,y_i)\} </code> for <code class="reqn">i = 1,...,n</code> available. The sample counterparts can be easily computed. Let <code class="reqn">{\mathcal{I}}_k </code> be the index set of sample points with <code class="reqn">y_i =L_k</code>, then  <code class="reqn">p_k</code> is estimated by the sample proportion of that category, that is, <code class="reqn">\hat{p}_k= \frac{n_k}{n}</code> where <code class="reqn">n_k</code> is the number of elements in <code class="reqn">{\mathcal{I}}_k</code>. With a given <code class="reqn">\alpha \in (0,2)</code>, a point estimator of <code class="reqn">\rho_g(\alpha)</code> is given as follows.  
</p>
<p style="text-align: center;"><code class="reqn">\hat{\Delta}_k(\alpha)= {n_k \choose 2}^{-1} \sum_{i&lt;j \in {\mathcal{I}}_k} \|\mathbf{x}_i -\mathbf{x}_j\| ^{\alpha},</code>
</p>
 
<p style="text-align: center;"><code class="reqn">\hat{\Delta}(\alpha)={n \choose 2}^{-1} \sum_{1=i&lt;j=n} \|\mathbf{x}_i -\mathbf{x}_j\| ^{\alpha},</code>
</p>
 
<p style="text-align: center;"><code class="reqn">gCor=\hat{\rho}_g (\alpha)= 1-\frac{\sum_{k=1}^K \hat p_k \hat{\Delta}_k(\alpha)}{\hat{\Delta}(\alpha)}.</code>
</p>
 


<h3>Value</h3>

<p><code>gCor</code> returns the sample Gini distance covariacne and correlation between <code>x</code> and <code>y</code>.
</p>


<h3>References</h3>

<p>Dang, X., Nguyen, D., Chen, Y. and Zhang, J. (2019). A new Gini correlation between quantitative and qualitative variables. Submitted to Journal of American Statistics Association.   
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gmd">gmd</a></code> <code><a href="#topic+gCov">gCov</a></code> <code><a href="#topic+KgCov">KgCov</a></code>  <code><a href="#topic+KgCor">KgCor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  x &lt;- iris[,1:4]
  y &lt;- unclass(iris[,5])
  gCor(x, y, alpha = 1)
</code></pre>

<hr>
<h2 id='gCov'> Gini Distance Covariance Statistics</h2><span id='topic+gCov'></span>

<h3>Description</h3>

<p>Computes Gini distance covariance statistics,
in which Xs are quantitative, Y are categorical, alpha is an exponent on Euclidean distance and returns the measures of dependence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  gCov(x, y, alpha)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gCov_+3A_x">x</code></td>
<td>
<p> data </p>
</td></tr>
<tr><td><code id="gCov_+3A_y">y</code></td>
<td>
<p> label of data or univariate response variable</p>
</td></tr>
<tr><td><code id="gCov_+3A_alpha">alpha</code></td>
<td>
<p> exponent on Euclidean distance, in (0,2]</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gCov</code> compute Gini distance covariance statistics.
It is a self-contained R function returning a measure of dependence statistics. 
</p>
<p>The sample size (number of rows) of the data must agree with the length of the label vector, and samples must not contain missing values. Arguments
<code>x</code>, <code>y</code> are treated as data and labels. <code>alpha</code> if missing by default is 1, otherwise it is exponent on the Euclidean distance.
</p>
<p>Gini distance covariance is a new measure of dependence between random vectors and its labels. 
For all distributions with finite first moments, Gini distance
correlation gCov has the following fundamental properties:
</p>
<p>(1) gCov(X,Y) is defined for <code class="reqn">X</code> in arbitrary dimension quantitive variable and <code class="reqn">Y</code> a univariate categorical variable.
</p>
<p>(2) gCov(X,Y)=0 characterizes independence of <code class="reqn">X</code> and
<code class="reqn">Y</code>.
</p>
<p>Gini distance covariance satisfies <code class="reqn">0 \le gCov(X,Y)</code>, and
<code class="reqn">gCov = 0</code> only if <code class="reqn">X</code> and <code class="reqn">Y</code> are independent. Gini distance
covariance gCov provides a new approach to the problem of
testing the joint independence of random vectors. The formal
definitions of the population coefficients gCov is given in (DNCZ 2018). The empirical Gini distance covariance <code class="reqn">gCov_n(X,Y; alpha)</code>  is the nonnegative number computed as follows.
</p>
<p>Suppose a sample data <code class="reqn"> {\mathcal{D}} =\{(\mathbf{x}_i,y_i)\} </code> for <code class="reqn">i = 1,...,n</code> available. The sample counterparts can be easily computed. Let <code class="reqn">{\mathcal{I}}_k </code> be the index set of sample points with <code class="reqn">y_i =L_k</code>, then <code class="reqn">p_k</code> is estimated by the sample proportion of that category, that is, <code class="reqn">\hat{p}_k= \frac{n_k}{n}</code> where <code class="reqn">n_k</code> is the number of elements in <code class="reqn">{\mathcal{I}}_k</code>. With a given <code class="reqn">\alpha \in (0,2)</code>, a point estimator of <code class="reqn">\rho_g(\alpha)</code> is given as follows.  
</p>
<p style="text-align: center;"><code class="reqn">\hat{\Delta}_k(\alpha)= {n_k \choose 2}^{-1} \sum_{i&lt;j \in {\mathcal{I}}_k} \|\mathbf{x}_i -\mathbf{x}_j\| ^{\alpha},</code>
</p>
 
<p style="text-align: center;"><code class="reqn">\hat{\Delta}(\alpha)={n \choose 2}^{-1} \sum_{1=i&lt;j=n} \|\mathbf{x}_i -\mathbf{x}_j\| ^{\alpha},</code>
</p>
 
<p style="text-align: center;"><code class="reqn">{gCov}= \hat{\Delta}(\alpha)-\sum_{k=1}^K \hat p_k \hat{\Delta}_k(\alpha).</code>
</p>
 


<h3>Value</h3>

<p><code>gCov</code> returns the sample Gini distance covariance
</p>


<h3>References</h3>

<p>Dang, X., Nguyen, D., Chen, Y. and Zhang, J., (2019). A new Gini correlation between quantitative and qualitative variables, 
<em>Journal of the American Statistical Association (submitted)</em>,
<a href="https://arxiv.org/pdf/1809.09793.pdf">https://arxiv.org/pdf/1809.09793.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gCor">gCor</a></code> <code><a href="#topic+gmd">gmd</a></code>  <code><a href="#topic+KgCov">KgCov</a></code>  <code><a href="#topic+KgCor">KgCor</a></code>  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  x &lt;- iris[,1:4]
  y &lt;- unclass(iris[,5])
  gCov(x, y, alpha = 1) 
</code></pre>

<hr>
<h2 id='GiniDistance-package'>GiniDistance</h2><span id='topic+GiniDistance-package'></span><span id='topic+GiniDistance'></span>

<h3>Description</h3>

<p>A new Gini correlation to measure dependence between categorical and numerical variables are implemented. Analogous to Pearson in ANOVA model, the Gini
correlation is interpreted as the ratio of the between-group variation and the total
variation, but it characterizes independence (zero Gini correlation mutually implies
independence). Closely related to the distance correlation, the Gini correlation is of the simple formulation by considering the nature of the categorical variable. As a result, the
Gini correlation has a lower computational cost than the distance correlation and is more straightforward to perform inference. The dependence test and confidence interval are implemented. 
Also, the corresponding kernelized dependence measures are also implemented.
</p>


<h3>Details</h3>

<p>The details are described in the following papers &quot;A new Gini correlation between quantitative and qualitative variables&quot; and &quot;Estimating Feature-Label Dependence Using Gini Distance Statistics&quot;
</p>


<h3>Author(s)</h3>

<p> Dao Nguyen <a href="mailto:dxnguyen@olemiss.edu">dxnguyen@olemiss.edu</a> and
Xin Dang <a href="mailto:xdang@olemiss.edu">xdang@olemiss.edu</a>
</p>


<h3>References</h3>

<p>Dang, X., Nguyen, D., Chen, Y. and Zhang, J., (2019). A new Gini correlation between quantitative and qualitative variables, 
<em>Journal of the American Statistical Association (submitted)</em>,
<a href="https://arxiv.org/pdf/1809.09793.pdf">https://arxiv.org/pdf/1809.09793.pdf</a>
</p>
<p>Zhang, S., Dang, X., Nguyen, D. and Chen, Y. (2019). Estimating feature - label dependence using Gini distance statistics. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (submitted)</em>,
<a href="https://arXiv.org/pdf/1906.02171.pdf">https://arXiv.org/pdf/1906.02171.pdf</a>
</p>

<hr>
<h2 id='gmd'>Gini Mean Difference</h2><span id='topic+gmd'></span>

<h3>Description</h3>

<p>Computes Gini mean difference of x, where alpha is an exponent on the Euclidean distance and return the Gini mean difference. The default value for alpha is 1. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  gmd(x, alpha)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gmd_+3A_x">x</code></td>
<td>
<p>data</p>
</td></tr>
<tr><td><code id="gmd_+3A_alpha">alpha</code></td>
<td>
<p>exponent on Euclidean distance, in (0,2)</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gmd</code> compute Gini mean difference of data.
It is a self-contained R function dealing with both univariate and multivariate data. 
</p>
<p>The samples must not contain missing values.  <code>alpha</code> if missing by default is 1, otherwise it is exponent on the Euclidean distance.
</p>
<p>Gini mean difference (GMD) was originally introduced as an alternative measure of variability to the usual standard deviation (<cite>Gini14</cite>, <cite>Yitzhaki13</cite>). Let <code class="reqn">X</code> and <code class="reqn">X^\prime</code> be independent random variables from a univariate distribution <code class="reqn">F</code> with finite first moment in <code class="reqn">R</code>.  The GMD of <code class="reqn">F</code> is
</p>
<p><code class="reqn">\Delta=\Delta(X)=\Delta(F)=E|X-X^{\prime}|,</code>
</p>
<p>the expected distance between two independent random variables. If the sample data <code class="reqn">\mathbf x=\{x_1,x_2,...,x_n\}</code> is available, the sample Gini mean difference is calculated by 
</p>
<p><code class="reqn">\hat{\Delta} = {n \choose 2}^{-1} \sum_{1\leq i&lt;j\leq n} | x_i - x_j| = {n \choose 2}^{-1} \sum_{i=1}^n (2i-n-1) x_{(i)},</code>
</p>
<p>where <code class="reqn">x_{(1)} \leq x_{(2)} \leq \cdots \leq x_{(n)}</code> are the order statistics of <code class="reqn">\mathbf x</code> (<cite>Schechtman87</cite>). The computation complexity for univariate Gini Mean difference is <code class="reqn">O(n \log n)</code>.
</p>
<p>Gini mean difference has been generalized for multivariate distributions (<cite>Koshvoy97</cite>)  That is, the Gini mean difference of a distribution F in <code class="reqn">\mathbf{R}^d</code> is  <code class="reqn">\Delta =E \|\mathbf X -\mathbf X ^\prime\|,</code>
or even more generally for some <code class="reqn">\alpha \in (0,2)</code>,
</p>
<p><code class="reqn">\Delta(\alpha) = E \|\mathbf X-\mathbf X^\prime\|^{\alpha}</code>, 
</p>
<p>where <code class="reqn">\| \mathbf x \|</code> is the Euclidean norm. The sample Gini mean difference is computed by 
</p>
<p><code class="reqn">\hat{\Delta(\alpha)} = {n \choose 2}^{-1} \sum_{1\leq i&lt;j\leq n} \| x_i - x_j\|^{\alpha}.</code>
</p>
<p>Its computation complexity is <code class="reqn">O(n^2)</code>.
</p>


<h3>Value</h3>

<p><code>gmd</code> returns the sample Gini mean distance. 
</p>


<h3>References</h3>

<p>Gini, C. (1914). Sulla misura della concentrazione e della variabilita dei caratteri. Atti del Reale Istituto Veneto di Scienze, Lettere ed Aeti, 62, 1203-1248. English Translation: On the measurement of concentration and variability of characters (2005). Metron, LXIII(1), 3-38.
</p>
<p>Koshevoy, G. and Mosler, K. (1997). Multivariate Gini indices. Journal of Multivariate Analysis, 60, 252-276.
</p>
<p>Schechtman, E. and Yitzhaki, S. (1987). A measure of association based on Gini's mean difference. Communication in Statistics-Theory and Methods, 16 (1), 207-231.
</p>
<p>Yitzhaki, S. and Schechtman, E. (2013). The Gini Methodology, Springer, New York. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RcppGmd">RcppGmd</a></code>  <code><a href="#topic+gCov">gCov</a></code>  <code><a href="#topic+gCor">gCor</a></code>  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  n = 100
  x &lt;- runif(n)
  
  t0 = proc.time()
  gmd(x, alpha=1)
  proc.time()- t0
  
  t1 = proc.time()
  gmd(x, alpha=0.5)    
  proc.time()- t1
  
  x &lt;- matrix(runif(n), n/2, 2)
  gmd(x,alpha=1)
  
</code></pre>

<hr>
<h2 id='KdCor'>Kernel Distance Correlation Statistics</h2><span id='topic+KdCor'></span>

<h3>Description</h3>

<p>Computes Kernel distance correlation statistics,
in which Xs are quantitative, Y are categorical, sigma is kernel standard deviation and returns the measures of dependence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  KdCor(x, y, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KdCor_+3A_x">x</code></td>
<td>
<p> data </p>
</td></tr>
<tr><td><code id="KdCor_+3A_y">y</code></td>
<td>
<p> label of data or univariate response variable</p>
</td></tr>
<tr><td><code id="KdCor_+3A_sigma">sigma</code></td>
<td>
<p> kernel standard deviation</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>KdCor</code> compute distance correlation statistics.
The sample size (number of rows) of the data must agree with the length of the label vector, and samples must not contain missing values. Arguments
<code>x</code>, <code>y</code> are treated as data and labels. 
</p>
<p>The kernel distance correlation is defined as follow.
</p>
<p style="text-align: center;"><code class="reqn">{dCor}_{\kappa_X,\kappa_Y}(\mathbf{X}, Y) = \frac{\mbox{ dCov}_{\kappa_X,\kappa_Y}(\mathbf{X}, Y)}{ \sqrt{\mbox{ dCov}_{\kappa_X,\kappa_X}(\mathbf{X},\mathbf{X})} \sqrt{\mbox{ dCov}_{\kappa_Y,\kappa_Y}(Y,Y)}}</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\begin{array}{c}
  \mathrm{dCov}_{\kappa_X,\kappa_Y}(X,Y) = {E}d_{\kappa_X}(X,X')d_{\kappa_Y}(Y,Y') + {E}d_{\kappa_X}(X,X'){E}d_{\kappa_Y}(Y,Y') \\
  - 2{E}\left[{E}_{X'}d_{\kappa_X}(X,X') {E}_{Y'}d_{\kappa_Y}(Y,Y')\right].
  \end{array}
 </code>
</p>



<h3>Value</h3>

<p><code>KdCor</code> returns the sample kernel distance correlation
</p>


<h3>References</h3>

<p>Sejdinovic, D., Sriperumbudur, B., Gretton, A.  and Fukumizu, K. (2013). Equivalence of Distance-based and RKHS-based Statistics in Hypothesis Testing, The Annals of Statistics, 41 (5),  2263-2291. 
</p>
<p>Zhang, S., Dang, X., Nguyen, D. and Chen, Y. (2019). Estimating feature - label dependence using Gini distance statistics. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (submitted)</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+KgCov">KgCov</a></code>  <code><a href="#topic+KgCor">KgCor</a></code>  <code><a href="#topic+dCor">dCor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  x&lt;-iris[,1:4]
  y&lt;-unclass(iris[,5])
  KdCor(x, y, sigma=1)
</code></pre>

<hr>
<h2 id='KdCov'>Kernel Distance Covariance Statistics</h2><span id='topic+KdCov'></span>

<h3>Description</h3>

<p>Computes Kernel distance covariance statistics,
in which Xs are quantitative, Y are categorical, sigma is kernel standard deviation and returns the measures of dependence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  KdCov(x, y, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KdCov_+3A_x">x</code></td>
<td>
<p> data </p>
</td></tr>
<tr><td><code id="KdCov_+3A_y">y</code></td>
<td>
<p> label of data or univariate response variable</p>
</td></tr>
<tr><td><code id="KdCov_+3A_sigma">sigma</code></td>
<td>
<p> kernel standard deviation</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>KdCov</code> compute distance correlation statistics.
The sample size (number of rows) of the data must agree with the length of the label vector, and samples must not contain missing values. Arguments
<code>x</code>, <code>y</code> are treated as data and labels. 
</p>
<p>Distance covariance was introduced in (<cite>Szekely07</cite>) as a dependence measure between random variables <code class="reqn">X \in {R}^p</code> and <code class="reqn">Y \in {R}^q</code>. If <code class="reqn">X</code> and <code class="reqn">Y</code> are embedded into RKHS's induced by <code class="reqn">\kappa_X</code> and <code class="reqn">\kappa_Y</code>, respectively, the generalized distance covariance of <code class="reqn">X</code> and <code class="reqn">Y</code> is (<cite>Sejdinovic13</cite>):
</p>
<p style="text-align: center;"><code class="reqn">\begin{array}{c}
    \mathrm{dCov}_{\kappa_X,\kappa_Y}(X,Y) = {E}d_{\kappa_X}(X,X^{\prime})d_{\kappa_Y}(Y,Y^{\prime}) + {E}d_{\kappa_X}(X,X^{\prime}){E}d_{\kappa_Y}(Y,Y^{\prime}) \\
    - 2{E}\left[{E}_{X^{\prime}}d_{\kappa_X}(X,X^{\prime}) {E}_{Y^{\prime}}d_{\kappa_Y}(Y,Y^{\prime})\right].
    \end{array}
  </code>
</p>

<p>In the case of <code class="reqn">Y</code> being categorical, one may embed it using a set difference kernel <code class="reqn">\kappa_Y</code>,
</p>
<p style="text-align: center;"><code class="reqn">
    \kappa_Y(y,y^{\prime}) = \left\{ \begin{array}{cc}
    \frac{1}{2} &amp;  if \;y = y^{\prime},\\ 0 &amp; otherwise.
    \end{array} \right.
  </code>
</p>

<p>This is equivalent to embedding <code class="reqn">Y</code> as a simplex with edges of unit length (<cite>Lyons13</cite>), i.e., <code class="reqn">L_k</code> is represented by a <code class="reqn">K</code> dimensional vector of all zeros except its <code class="reqn">k</code>-th dimension, which has the value <code class="reqn">\frac{\sqrt{2}}{2}</code>. 
The distance induced by <code class="reqn">\kappa_Y</code> is called the set distance, i.e., <code class="reqn">d_{\kappa_Y}(y,y^{\prime})=0</code> if <code class="reqn">y=y^{\prime}</code> and <code class="reqn">1</code> otherwise. Using the set distance, we have the following results on the generalized distance covariance between a numerical 
and a categorical random variable.
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{dCov}_{\kappa_X,\kappa_Y}(X,Y) := \mathrm{dCov}_{\kappa_X}(X,Y) \nonumber = \sum_{k=1}^{K} p_k^2 \left[2 {E}d_{\kappa_X}(X_k,X) - {E}d_{\kappa_X}(X_k,{X_k}^{\prime}) - {E}d_{\kappa_X}(X,X^{\prime}) \right].</code>
</p>



<h3>Value</h3>

<p><code>KdCov</code> returns the sample kernel distance correlation
</p>


<h3>References</h3>

<p>Sejdinovic, D., Sriperumbudur, B., Gretton, A.  and Fukumizu, K. (2013). Equivalence of Distance-based and RKHS-based Statistics in Hypothesis Testing, The Annals of Statistics, 41 (5),  2263-2291. 
</p>
<p>Zhang, S., Dang, X., Nguyen, D. and Chen, Y. (2019). Estimating feature - label dependence using Gini distance statistics. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (submitted)</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+KgCov">KgCov</a></code>  <code><a href="#topic+KgCor">KgCor</a></code>  <code><a href="#topic+dCov">dCov</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  x&lt;-iris[,1:4]
  y&lt;-unclass(iris[,5])
  KdCov(x, y, sigma=1)
</code></pre>

<hr>
<h2 id='KgCor'> Kernel Gini Distance Correlation Statistics</h2><span id='topic+KgCor'></span>

<h3>Description</h3>

<p>Computes Kernel Gini distance correlation statistics,
in which Xs are quantitative, Y are categorical, sigma is kernel standard deviation, alpha is an exponent on the Euclidean distance and returns the kernel Gini mean difference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  KgCor(x, y, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KgCor_+3A_x">x</code></td>
<td>
<p> data </p>
</td></tr>
<tr><td><code id="KgCor_+3A_y">y</code></td>
<td>
<p> label of data or univariate response variable</p>
</td></tr>
<tr><td><code id="KgCor_+3A_sigma">sigma</code></td>
<td>
<p> kernel standard deviation</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>Kgcor</code> compute kernel Gini distance correlation statistics for data.
It is a self-contained R function dealing with both univariate and multivariate data. 
The sample size (number of rows) of the data must agree with the length of the label vector, and samples must not contain missing values. Arguments
<code>x</code>, <code>y</code> are treated as data and labels.
</p>
<p>Gini distance correlation are generalized to RKHS, <code class="reqn">\mathcal{H}_\kappa</code>, as
</p>
<p style="text-align: center;"><code class="reqn"> 
  \mathrm{gCor}_\kappa(X,Y)  = \frac{\sum_{k=1}^{K} p_k \left[ 2 {E}d_\kappa(X_k,X) - 
  {E}d_\kappa(X_k,{X_k}') - {E}d_\kappa(X,X')\right]}{{E}d_\kappa(X,X')}.</code>
</p>

<p>In this case, we use the default Gaussian distance function
</p>
<p style="text-align: center;"><code class="reqn">
  d_\kappa(x,x') = \sqrt{1-e^{-\frac{|x-x'|_q^2}{\sigma^2}}},
  </code>
</p>

<p>induced by a weighted Gaussian kernel, <code class="reqn">\kappa(x,x') = \frac{1}{2}e^{-\frac{|x-x'|_q^2}{\sigma^2}}.</code> 
</p>


<h3>Value</h3>

<p><code>KgCor</code> returns the sample Kernel Gini distance correlation between <code>x</code> and <code>y</code>.
</p>


<h3>References</h3>

<p>Zhang, S., Dang, X., Nguyen, D. and Chen, Y. (2019). Estimating feature - label dependence using Gini distance statistics. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (submitted)</em>,
<a href="https://arXiv.org/pdf/1906.02171.pdf">https://arXiv.org/pdf/1906.02171.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gCov">gCov</a></code>  <code><a href="#topic+gCor">gCor</a></code>  <code><a href="#topic+dCor">dCor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  x&lt;-iris[,1:4]
  y&lt;-unclass(iris[,5])
  KgCor(x, y, sigma=1)
</code></pre>

<hr>
<h2 id='KgCov'> Kernel Gini Distance Covariance Statistics</h2><span id='topic+KgCov'></span>

<h3>Description</h3>

<p>Computes Kernel Gini distance covariance statistics,
in which Xs are quantitative, Y are categorical, sigma is kernel standard deviation and returns the kernel Gini covariance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  KgCov(x, y, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KgCov_+3A_x">x</code></td>
<td>
<p> data </p>
</td></tr>
<tr><td><code id="KgCov_+3A_y">y</code></td>
<td>
<p> label of data or univariate response variable</p>
</td></tr>
<tr><td><code id="KgCov_+3A_sigma">sigma</code></td>
<td>
<p> kernel standard deviation</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>Kgcov</code> compute kernel Gini distance covariance statistics for data.
It is a self-contained R function dealing with both univariate and multivariate data. 
The sample size (number of rows) of the data must agree with the length of the label vector, and samples must not contain missing values. Arguments
<code>x</code>, <code>y</code> are treated as data and labels. 
</p>
<p>Gini distance covariance are generalized to reproducing kernel Hilbert space (RKHS), <code class="reqn">\mathcal{H}_\kappa</code>, as
</p>
<p style="text-align: center;"><code class="reqn">
  \mathrm{gCov}_\kappa(X,Y) = \sum_{k=1}^{K} p_k \left[ 2 {E}d_\kappa(X_k,X) - 
  {E}d_\kappa(X_k,{X_k}') - {E}d_\kappa(X,X')\right]</code>
</p>

<p>In this case, we use the default Gaussian distance function
</p>
<p style="text-align: center;"><code class="reqn">
    d_\kappa(x,x') = \sqrt{1-e^{-\frac{|x-x'|_q^2}{\sigma^2}}},
  </code>
</p>

<p>induced by a weighted Gaussian kernel, <code class="reqn">\kappa(x,x') = \frac{1}{2}e^{-\frac{|x-x'|_q^2}{\sigma^2}}.</code> 
</p>


<h3>Value</h3>

<p><code>KgCov</code> returns the sample Kernel Gini distance covariance of <code>x</code> and <code>y</code>.
</p>


<h3>References</h3>

<p>Zhang, S., Dang, X., Nguyen, D. and Chen, Y. (2019). Estimating feature - label dependence using Gini distance statistics. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (submitted)</em>,
<a href="https://arXiv.org/pdf/1906.02171.pdf">https://arXiv.org/pdf/1906.02171.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gCov">gCov</a></code>  <code><a href="#topic+gCor">gCor</a></code>  <code><a href="#topic+dCor">dCor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  x&lt;-iris[,1:4]
  y&lt;-unclass(iris[,5])
  KgCov(x, y, sigma=1)
</code></pre>

<hr>
<h2 id='Kgmd'> Kernel Gini Mean Difference Statistics</h2><span id='topic+Kgmd'></span>

<h3>Description</h3>

<p>Computes Kernel Gini mean difference statistics,
in which Xs are quantitative, sigma is kernel standard deviation, alpha is an exponent on the Euclidean distance and returns the kernel Gini mean difference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  Kgmd(x, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Kgmd_+3A_x">x</code></td>
<td>
<p> data </p>
</td></tr>
<tr><td><code id="Kgmd_+3A_sigma">sigma</code></td>
<td>
<p> kernel standard deviation</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>Kgmd</code> compute kernel Gini mean difference statistics for data.
It is a self-contained R function dealing with both univariate and multivariate data. 
</p>
<p>The sample size (number of rows) of the data must agree with the length of the label vector, and samples must not contain missing values. Argument
<code>x</code>, is treated as data.
</p>
<p>Energy distance based statistics naturally generalizes from a Euclidean space to metric spaces (<cite>Lyons13</cite>). By using a positive definite kernel (Mercer kernel) (<cite>Mercer1909</cite>), distributions are mapped into a RKHS (<cite>Smola07</cite>) with a kernel induced distance. Hence one can extend energy distances to a much richer family of statistics defined in RKHS (<cite>Sejdinovic13</cite>). Let <code class="reqn">\kappa: R^q \times R^q \rightarrow R</code> be a Mercer kernel (<cite>Mercer1909</cite>). There is an associated RKHS <code class="reqn">H_{\kappa}</code> of real functions on <code class="reqn">R^q</code> with reproducing kernel <code class="reqn">\kappa</code>, where the function <code class="reqn">d: {R}^q \times {R}^q \rightarrow{{R}}</code> defines a distance in <code class="reqn">\mathcal{H}_\kappa</code>,
</p>
<p style="text-align: center;"><code class="reqn">
  d_\kappa(x,x') = \sqrt{\kappa(x,x) + \kappa(x',x') - 2 \kappa(x,x')}.</code>
</p>

<p>Here <code>Kgcov</code> is defined as Gini distance covariance between <code class="reqn">x</code> and <code class="reqn">\mathrm{rank}(x)</code>. 
</p>


<h3>Value</h3>

<p><code>Kgmd</code> returns the sample Kernel Gini distance
</p>


<h3>References</h3>

<p>Lyons, R. (2013). Distance covariance in metric spaces. The Annals of Probability, 41 (5), 3284-3305. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gCov">gCov</a></code>  <code><a href="#topic+gCor">gCor</a></code>  <code><a href="#topic+dCor">dCor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  x&lt;-iris[,1]
  Kgmd(x, sigma=1)
</code></pre>

<hr>
<h2 id='PermutationTest'>Permutation test of dependence between X and Y using (Gini) distance covariance or correlation statistics</h2><span id='topic+PermutationTest'></span>

<h3>Description</h3>

<p>Perform permutation test using various dependence measures, 
in which Xs are quantitative, Y are categorical, alpha is an exponent on Euclidean distance, sigma is kernel parameter in kernel methods and return the test statistic, critical value, p-value and decision of the test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  PermutationTest(x, y,  method, sigma, alpha, M = 200, level = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PermutationTest_+3A_x">x</code></td>
<td>
<p> data </p>
</td></tr>
<tr><td><code id="PermutationTest_+3A_y">y</code></td>
<td>
<p> label of data or univariate response variable</p>
</td></tr>
<tr><td><code id="PermutationTest_+3A_method">method</code></td>
<td>
<p> name of permutation test method and is chosen from one of the method list: dCov, dCor, KdCov, KdCor, gCov, gCor, KgCov, Kgcor</p>
</td></tr>
<tr><td><code id="PermutationTest_+3A_sigma">sigma</code></td>
<td>
<p> kernel parameter for kenerl methods</p>
</td></tr>
<tr><td><code id="PermutationTest_+3A_alpha">alpha</code></td>
<td>
<p> exponent on Euclidean distance, in (0,2), the default value = 1</p>
</td></tr>
<tr><td><code id="PermutationTest_+3A_m">M</code></td>
<td>
<p>number of permutations</p>
</td></tr>  
<tr><td><code id="PermutationTest_+3A_level">level</code></td>
<td>
<p> significance level of the test, the default value = 0.05</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code class="reqn">H_0:</code> X and Y are independent <code class="reqn">\Longleftrightarrow H_0: F(x|y=1)=F(x|Y=2)=...=F(x|Y=K)</code>
</p>
<p><code>PermutationTest</code> compute the p-value value of a permutation test of a (Gini) distance covariance or correlation statistics.
It is a self-contained R function  the measure of dependence statistics. 
</p>
<p>The p-value is obtained by a permutation procedure.
Let <code class="reqn">\hat{\rho}(\nu)</code> be the sample dependnce measure based on the orginal sample indexed by <code class="reqn">\nu=\{1,2,...,n\}</code>.  Let <code class="reqn">\pi(\nu)</code> denote a permutation of the elements of <code class="reqn">\nu</code> and the corresponding <code class="reqn">\hat{\rho}(\pi)</code> is computed for the permutated data on y labels.   
Under the <code class="reqn">{\cal H}_0</code>, <code class="reqn">\hat{\rho}(\nu)</code>
and <code class="reqn">\hat{\rho}(\pi)</code> are identically distributed for every permutation <code class="reqn">\pi</code> of <code class="reqn">\nu</code>. 
Hence, based on <code class="reqn">M</code> permutations,  the critical value <code class="reqn">q_{\gamma}</code> is estimated by the <code class="reqn">(1-\gamma)100\%</code> sample 
quantile of <code class="reqn">\hat{\rho}(\pi_m)</code>, <code class="reqn">m=1,...,M</code> and the p-value is estimated by the proportion of
<code class="reqn">\hat{\rho}(\pi_m)</code> greater than <code class="reqn">\hat{\rho}(\nu)</code>. Usually <code class="reqn">100\leq M\leq 1000</code> is sufficient for a good estimation on the critical value or p-value.  The default value is <code class="reqn">M=200</code>.
</p>


<h3>Value</h3>

<p><code>PermutationTest</code> returns the p-value,  critical value and decision of the permutation test of a specified method.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gCor">gCor</a></code> <code><a href="#topic+gCov">gCov</a></code> <code><a href="#topic+dCor">dCor</a></code> <code><a href="#topic+dCov">dCov</a></code> <code><a href="#topic+KgCov">KgCov</a></code> <code><a href="#topic+KgCov">KgCov</a></code> <code><a href="#topic+KdCov">KdCov</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  n = 50
  x &lt;- runif(n)
  y &lt;- c(rep(1,n/2),rep(2,n/2))
  PermutationTest(x, y, method = "gCor", alpha = 2, M = 50 )
</code></pre>

<hr>
<h2 id='RcppgCor'>Gini Distance Correlation Statistics</h2><span id='topic+RcppgCor'></span>

<h3>Description</h3>

<p>Computes Gini distance correlation statistics,
in which Xs are quantitative, Y are categorical, alpha is exponent on the Euclidean distance and returns the measures of dependence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  RcppgCor(x, y, alpha)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RcppgCor_+3A_x">x</code></td>
<td>
<p> data </p>
</td></tr>
<tr><td><code id="RcppgCor_+3A_y">y</code></td>
<td>
<p> label of data or univariate response variable</p>
</td></tr>
<tr><td><code id="RcppgCor_+3A_alpha">alpha</code></td>
<td>
<p> exponent on Euclidean distance, in (0,2]</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>RcppgCor</code> compute Gini distance correlation statistic between <code>x</code> and <code>y</code>.
It is a Rcpp version of <a href="#topic+gCor">gCor</a>.  
</p>


<h3>Value</h3>

<p><code>RcppgCor</code> returns the sample Gini distance correlation
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RcppKgCov">RcppKgCov</a></code>  <code><a href="#topic+RcppKgCor">RcppKgCor</a></code>  <code><a href="#topic+RcppgCov">RcppgCov</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  x&lt;-iris[,1:4]
  y&lt;-unclass(iris[,5])
  RcppgCor(x, y, alpha=2)
</code></pre>

<hr>
<h2 id='RcppgCov'> Gini Distance Covariance Statistics</h2><span id='topic+RcppgCov'></span>

<h3>Description</h3>

<p>Computes Gini distance covariance statistics,
in which Xs are quantitative, Y are categorical, alpha is an exponent on Euclidean distance and returns the measures of dependence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  RcppgCov(x, y, alpha)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RcppgCov_+3A_x">x</code></td>
<td>
<p> data </p>
</td></tr>
<tr><td><code id="RcppgCov_+3A_y">y</code></td>
<td>
<p> label of data or univariate response variable</p>
</td></tr>
<tr><td><code id="RcppgCov_+3A_alpha">alpha</code></td>
<td>
<p> exponent on Euclidean distance, in (0,2]</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>RcppgCov</code> compute Gini distance covariance statistics.
It is Rcpp version of <a href="#topic+gCov">gCov</a>. 
</p>


<h3>Value</h3>

<p><code>RcppgCov</code> returns the sample Gini distance covariance
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RcppgCor">RcppgCor</a></code>  <code><a href="#topic+RcppKgCov">RcppKgCov</a></code>  <code><a href="#topic+RcppKgCor">RcppKgCor</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  x&lt;-iris[,1:4]
  y&lt;-unclass(iris[,5])
  RcppgCov(x, y, alpha=2)
</code></pre>

<hr>
<h2 id='RcppGmd'> Gini Mean Difference Statistics</h2><span id='topic+RcppGmd'></span>

<h3>Description</h3>

<p>Computes Gini mean difference of x, where alpha is an exponent on the Euclidean distance and return the Gini mean difference. The default value for alpha is 1. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  RcppGmd(x, alpha)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RcppGmd_+3A_x">x</code></td>
<td>
<p> data </p>
</td></tr>
<tr><td><code id="RcppGmd_+3A_alpha">alpha</code></td>
<td>
<p> exponent on Euclidean distance, in (0,2]</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>RcppGmd</code> compute Gini mean difference statistics for data.
It is a Rcpp version of <a href="#topic+gmd">gmd</a>. 
</p>


<h3>Value</h3>

<p><code>RcppGmd</code> returns the sample Gini mean difference of <code>x</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RcppKgCov">RcppKgCov</a></code>  <code><a href="#topic+RcppgCor">RcppgCor</a></code>   <code><a href="#topic+gCov">gCov</a></code>  <code><a href="#topic+gCor">gCor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  n=1000
  x&lt;-runif(n)
  RcppGmd(x, alpha=1)
</code></pre>

<hr>
<h2 id='RcppKgCor'> Kernel Gini Distance Correlation Statistics</h2><span id='topic+RcppKgCor'></span>

<h3>Description</h3>

<p>Computes Kernel Gini distance correlation statistics,
in which Xs are quantitative, Y are categorical, sigma is kernel standard deviation and return the kernel Gini mean difference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  RcppKgCor(x, y, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RcppKgCor_+3A_x">x</code></td>
<td>
<p> data </p>
</td></tr>
<tr><td><code id="RcppKgCor_+3A_y">y</code></td>
<td>
<p> label of data or univariate response variable</p>
</td></tr>
<tr><td><code id="RcppKgCor_+3A_sigma">sigma</code></td>
<td>
<p> kernel standard deviation</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>RcppKgCor</code> compute kernel Gini distance correlation statistics for data.
It is Rcpp version of <a href="#topic+KgCor">KgCor</a>.  
</p>


<h3>Value</h3>

<p><code>RcppKgCor</code> returns the sample Kernel Gini distance covariance
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gCov">gCov</a></code>  <code><a href="#topic+gCor">gCor</a></code>  <code><a href="#topic+dCor">dCor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  n=100
  x&lt;-runif(n)
  y&lt;-c(rep(1,n/2),rep(2,n/2))
  RcppKgCor(x, y, sigma=1)
</code></pre>

<hr>
<h2 id='RcppKgCov'> Kernel Gini Distance Covariance Statistics</h2><span id='topic+RcppKgCov'></span>

<h3>Description</h3>

<p>Computes Kernel Gini distance covariance statistics,
in which Xs are quantitative, Y are categorical, sigma is kernel standard deviation and return the kernel Gini mean difference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  RcppKgCov(x, y, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RcppKgCov_+3A_x">x</code></td>
<td>
<p> data </p>
</td></tr>
<tr><td><code id="RcppKgCov_+3A_y">y</code></td>
<td>
<p> label of data or univariate response variable</p>
</td></tr>
<tr><td><code id="RcppKgCov_+3A_sigma">sigma</code></td>
<td>
<p> kernel standard deviation</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>RcppKgCov</code> compute kernel Gini distance covariance statistics for data.
It is Rcpp version of <a href="#topic+KgCov">KgCov</a>.    
</p>


<h3>Value</h3>

<p><code>RcppKgCov</code> returns the sample Kernel Gini distance covariance
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gCov">gCov</a></code>  <code><a href="#topic+gCor">gCor</a></code>  <code><a href="#topic+dCor">dCor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  n=100
  x&lt;-runif(n)
  y&lt;-c(rep(1,n/2),rep(2,n/2))
  RcppKgCov(x, y, sigma=1)
</code></pre>

<hr>
<h2 id='RcppKGmd'> Kernel Gini Mean Difference Statistics</h2><span id='topic+RcppKGmd'></span>

<h3>Description</h3>

<p>Computes Kernel Gini mean difference of X, sigma is the kernel parameter and returns the kernel Gini mean difference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  RcppKGmd(x, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RcppKGmd_+3A_x">x</code></td>
<td>
<p> data </p>
</td></tr>
<tr><td><code id="RcppKGmd_+3A_sigma">sigma</code></td>
<td>
<p> kernel parameter for Gaussian kernel</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>RcppKGmd</code> compute kernel Gini mean difference for data 
It is Rcpp version of <a href="#topic+Kgmd">Kgmd</a>. 
</p>


<h3>Value</h3>

<p><code>RcppKGmd</code> returns the sample Kernel Gini distance
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gmd">gmd</a></code>  <code><a href="#topic+Kgmd">Kgmd</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  x&lt;-iris[,1]
  RcppKGmd(x, sigma=1)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
