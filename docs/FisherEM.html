<!DOCTYPE html><html><head><title>Help for package FisherEM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {FisherEM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#FisherEM-package'><p>The FisherEM Algorithm to Simultaneously Cluster and Visualize High-Dimensional Data</p></a></li>
<li><a href='#bfem'><p>The Bayesian Fisher-EM algorithm.</p></a></li>
<li><a href='#fem'>
<p>The Fisher-EM algorithm</p></a></li>
<li><a href='#fem.ari'>
<p>Adjusted Rand index</p></a></li>
<li><a href='#plot.bfem'><p>Plotting function</p></a></li>
<li><a href='#plot.fem'>
<p>The plot function for 'fem' objects.</p></a></li>
<li><a href='#print.fem'>
<p>The print function for 'fem' objects.</p></a></li>
<li><a href='#sfem'>
<p>The sparse Fisher-EM algorithm</p></a></li>
<li><a href='#simu_bfem'><p>Experimental setting of the chapter BFEM</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>The FisherEM Algorithm to Simultaneously Cluster and Visualize
High-Dimensional Data</td>
</tr>
<tr>
<td>Version:</td>
<td>1.6</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-09-28</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Author:</td>
<td>Charles Bouveyron, Camille Brunet &amp; Nicolas Jouvin.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Charles Bouveyron &lt;charles.bouveyron@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>MASS, parallel, elasticnet, ggplot2</td>
</tr>
<tr>
<td>Imports:</td>
<td>ellipse, plyr</td>
</tr>
<tr>
<td>Description:</td>
<td>The FisherEM algorithm, proposed by Bouveyron &amp; Brunet (2012) &lt;<a href="https://doi.org/10.1007%2Fs11222-011-9249-9">doi:10.1007/s11222-011-9249-9</a>&gt;,
        is an efficient method for the clustering of high-dimensional data. FisherEM models and 
        clusters the data in a discriminative and low-dimensional latent subspace. It also provides
        a low-dimensional representation of the clustered data. A sparse version of Fisher-EM
        algorithm is also provided.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, aricode</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-09-28 13:33:41 UTC; charles</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-09-28 14:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='FisherEM-package'>The FisherEM Algorithm to Simultaneously Cluster and Visualize High-Dimensional Data</h2><span id='topic+FisherEM-package'></span><span id='topic+FisherEM'></span>

<h3>Description</h3>

<p>The FisherEM algorithm, proposed by Bouveyron &amp; Brunet (201) &lt;doi:10.1007/s11222-011-9249-9&gt;, is an efficient method for the clustering of high-dimensional data. FisherEM models and clusters the data in a discriminative and low-dimensional latent subspace. It also provides a low-dimensional representation of the clustered data. A sparse version of Fisher-EM algorithm is also provided.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> FisherEM</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.2</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2012-07-09</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyLoad: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

 
<p>Charles Bouveyron, Camille Brunet &amp; Nicolas Jouvin.
</p>
<p>Maintainer: Charles Bouveyron &lt;charles.bouveyron@gmail.com&gt;
</p>


<h3>References</h3>

<p>Charles Bouveyron, Camille Brunet (2012), &quot;Simultaneous model-based clustering and visualization in the Fisher discriminative subspace.&quot;, Statistics and Computing, 22(1), 301-324 &lt;doi:10.1007/s11222-011-9249-9&gt;.
</p>
<p>Charles Bouveyron and Camille Brunet (2014), &quot;Discriminative variable selection for clustering with the sparse Fisher-EM algorithm&quot;, Computational Statistics, vol. 29(3-4), pp. 489-513 &lt;10.1007/s00180-013-0433-6&gt;.
</p>

<hr>
<h2 id='bfem'>The Bayesian Fisher-EM algorithm.</h2><span id='topic+bfem'></span>

<h3>Description</h3>

<p>The Bayesian Fisher-EM algorithm is built on a Bayesian formulation of the
model used in the <code><a href="#topic+fem">fem</a></code>. It is a subspace clustering method for
high-dimensional data. It is based on a Gaussian Mixture Model and on the
idea that the data lives in a common and low dimensional subspace. A VEM-like
algorithm estimates both the discriminative subspace and the parameters of
the mixture model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bfem(
  Y,
  K = 2:6,
  model = "AkjBk",
  method = "gs",
  crit = "icl",
  maxit.em = 100,
  eps.em = 1e-06,
  maxit.ve = 3,
  eps.ve = 1e-04,
  lambda = 1000,
  emp.bayes = T,
  init = "kmeans",
  nstart = 10,
  Tinit = c(),
  kernel = "",
  disp = FALSE,
  mc.cores = (detectCores() - 1),
  subset = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bfem_+3A_y">Y</code></td>
<td>
<p>The data matrix. 
Categorical variables and missing values are not
allowed.</p>
</td></tr>
<tr><td><code id="bfem_+3A_k">K</code></td>
<td>
<p>An integer vector specifying the numbers of mixture components
(clusters) among which the model selection criterion will choose the most
appropriate number of groups. Default is 2:6.</p>
</td></tr>
<tr><td><code id="bfem_+3A_model">model</code></td>
<td>
<p>A vector of Bayesian discriminative latent mixture (BDLM) models
to fit. There are 12 different models: &quot;DkBk&quot;, &quot;DkB&quot;, &quot;DBk&quot;, &quot;DB&quot;, &quot;AkjBk&quot;,
&quot;AkjB&quot;, &quot;AkBk&quot;, &quot;AkBk&quot;, &quot;AjBk&quot;, &quot;AjB&quot;, &quot;ABk&quot;, &quot;AB&quot;.  The option &quot;all&quot;
executes the Fisher-EM algorithm on the 12 DLM models and select the best
model according to the maximum value obtained by model selection criterion.
Similar to <code><a href="#topic+fem">fem</a></code></p>
</td></tr>
<tr><td><code id="bfem_+3A_method">method</code></td>
<td>
<p>The method used for the fitting of the projection matrix
associated to the discriminative subspace. Three methods are available:
'gs' (Gram-Schmidt, the original proposition), 'svd' (based on SVD, faster)
and 'reg' (the Fisher criterion is rewritten as a regression problem). The
'gs' method is the default method.</p>
</td></tr>
<tr><td><code id="bfem_+3A_crit">crit</code></td>
<td>
<p>The model selection criterion to use for selecting the most
appropriate model for the data. There are 3 possibilities: &quot;bic&quot;, &quot;aic&quot; or
&quot;icl&quot;. Default is &quot;icl&quot;.</p>
</td></tr>
<tr><td><code id="bfem_+3A_maxit.em">maxit.em</code></td>
<td>
<p>The maximum number of iterations before the stop of the main
EM loop in the BFEM algorithm.</p>
</td></tr>
<tr><td><code id="bfem_+3A_eps.em">eps.em</code></td>
<td>
<p>The threshold value for the likelihood differences (Aitken's
criterion) to stop the BFEM algorithm.</p>
</td></tr>
<tr><td><code id="bfem_+3A_maxit.ve">maxit.ve</code></td>
<td>
<p>The maximum number of iterations before the stop of the
VE-step loop (fixed point algorithm)</p>
</td></tr>
<tr><td><code id="bfem_+3A_eps.ve">eps.ve</code></td>
<td>
<p>The threshold value for the likelihood differences (Aitken's
criterion) to stop the BFEM algorithm.</p>
</td></tr>
<tr><td><code id="bfem_+3A_lambda">lambda</code></td>
<td>
<p>The initial value for the variance of the Gaussian prior on the
means in the latent space.</p>
</td></tr>
<tr><td><code id="bfem_+3A_emp.bayes">emp.bayes</code></td>
<td>
<p>Should the hyper-parameters (mean and variance) of the prior be updated ? Default to TRUE.</p>
</td></tr>
<tr><td><code id="bfem_+3A_init">init</code></td>
<td>
<p>The initialization method for the Fisher-EM algorithm. There are
4 options: &quot;random&quot; for a randomized initialization, &quot;kmeans&quot; for an
initialization by the kmeans algorithm, &quot;hclust&quot; for hierarchical
clustering initialization or &quot;user&quot; for a specific initialization through
the parameter &quot;Tinit&quot;. Default is &quot;kmeans&quot;. Notice that for &quot;kmeans&quot; and
&quot;random&quot;, several initializations are asked and the initialization
associated with the highest likelihood is kept (see &quot;nstart&quot;).</p>
</td></tr>
<tr><td><code id="bfem_+3A_nstart">nstart</code></td>
<td>
<p>The number of restart if the initialization is &quot;kmeans&quot; or
&quot;random&quot;. In such a case, the initialization associated with the highest
likelihood is kept.</p>
</td></tr>
<tr><td><code id="bfem_+3A_tinit">Tinit</code></td>
<td>
<p>A n x K matrix which contains posterior probabilities for
initializing the algorithm (each line corresponds to an individual).</p>
</td></tr>
<tr><td><code id="bfem_+3A_kernel">kernel</code></td>
<td>
<p>It enables to deal with the n &lt; p problem. By default, no
kernel (&quot; &quot;) is used. But the user has the choice between 3 options for the
kernel: &quot;linear&quot;, &quot;sigmoid&quot; or &quot;rbf&quot;.</p>
</td></tr>
<tr><td><code id="bfem_+3A_disp">disp</code></td>
<td>
<p>If true, some messages are printed during the clustering. Default
is false.</p>
</td></tr>
<tr><td><code id="bfem_+3A_mc.cores">mc.cores</code></td>
<td>
<p>The number of CPUs to use to fit in parallel the different
models (only for non-Windows platforms). Default is the number of available
cores minus 1.</p>
</td></tr>
<tr><td><code id="bfem_+3A_subset">subset</code></td>
<td>
<p>A positive integer defining the size of the subsample, default
is NULL. In case of large data sets, it might be useful to fit a FisherEM
model on a subsample of the data, and then use this model to predict
cluster assignments for the whole data set. Notice that in, such a case,
likelihood values and model selection criteria are computed for the
subsample and not the whole data set.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list is returned: </p>
  
<ul>
<li><p> K - The number of groups.
</p>
</li>
<li><p> cls - the group membership of each individual estimated by the BFEM algorithm 
</p>
</li>
<li><p> Tinit - The initial posterior probalities used to start the algorithm 
</p>
</li>
<li><p> d - the dimension of the discriminative subspace 
</p>
</li>
<li><p> elbos - A vector containing the evolution of the variational lower bound at each iteration 
</p>
</li>
<li><p> loglik - The final value of the variational lower bound 
</p>
</li>
<li><p> n_ite - The number of iteration until convergence of the BFEM algorithm 
</p>
</li>
<li><p> P - the posterior probabilities of each individual for each group 
</p>
</li>
<li><p> U - The loading matrix which determines the orientation of the discriminative subspace 
</p>
</li>
<li><p> param - A list containing the estimated parameters of the model 
</p>

<ul>
<li><p> PI - The mixture proportions 
</p>
</li>
<li><p> Sigmak - An array containing estimated cluster covariances in the latent space 
</p>
</li>
<li><p> Beta - The noise variance in each cluster 
</p>
</li></ul>

</li>
<li><p> var_param - A list containing the variational distribution parameters
</p>

<ul>
<li><p> logtau - A n x K matrix containing the logarithm of the multinomial parameters of q(Z) 
</p>
</li>
<li><p> Varmeank - A K x d matrix containing the variational mean 
</p>
</li>
<li><p> Varcovk -  A d x d x K array containing the variational covariance matrices.
</p>
</li></ul>

</li>
<li><p> proj - The projected data on the discriminative subspace. 
</p>
</li>
<li><p> aic - The value of the Akaike information criterion 
</p>
</li>
<li><p> bic - The value of the Bayesian information criterion 
</p>
</li>
<li><p> icl - The value of the integrated completed likelihood criterion 
</p>
</li>
<li><p> method - The method used in the F-step 
</p>
</li>
<li><p> call - The call of the function 
</p>
</li>
<li><p> crit - The model selection criterion used </p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+fem">fem</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Chang's 1983 setting
simu = simu_bfem(300, which = "Chang1983")
Y = simu$Y
res.bfem = bfem(Y, K = 2:6, model=c('AB'), init = 'kmeans', nstart = 1, 
               maxit.em = 10, eps.em = 1e-3, maxit.ve = 3, mc.cores = 2)

</code></pre>

<hr>
<h2 id='fem'>
The Fisher-EM algorithm
</h2><span id='topic+fem'></span>

<h3>Description</h3>

<p>The Fisher-EM algorithm is a subspace clustering method for high-dimensional data. It is based on the Gaussian Mixture Model and on the idea that the data lives in a common and low dimensional subspace. An EM-like algorithm estimates both the discriminative subspace and the parameters of the mixture model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fem(Y,K=2:6,model='AkjBk',method='gs',crit='icl',maxit=50,eps=1e-4,init='kmeans',
                nstart=5,Tinit=c(),kernel='',disp=FALSE,mc.cores=(detectCores()-1),
                subset=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fem_+3A_y">Y</code></td>
<td>
 
<p>The data matrix. Categorical variables and missing values are not allowed.
</p>
</td></tr>
<tr><td><code id="fem_+3A_k">K</code></td>
<td>

<p>An integer vector specifying the numbers of mixture components (clusters) among which the model selection criterion will choose the most appropriate number of groups. Default is 2:6.
</p>
</td></tr>
<tr><td><code id="fem_+3A_model">model</code></td>
<td>
<p>A vector of discriminative latent mixture (DLM) models to fit. There are 12 different models: &quot;DkBk&quot;, &quot;DkB&quot;, &quot;DBk&quot;, &quot;DB&quot;, &quot;AkjBk&quot;, &quot;AkjB&quot;, &quot;AkBk&quot;, &quot;AkBk&quot;, &quot;AjBk&quot;, &quot;AjB&quot;, &quot;ABk&quot;, &quot;AB&quot;.  The option &quot;all&quot; executes the Fisher-EM algorithm on the 12 DLM models and select the best model according to the maximum value obtained by model selection criterion. 
</p>
</td></tr> 
<tr><td><code id="fem_+3A_method">method</code></td>
<td>

<p>The method used for the fitting of the projection matrix associated to the discriminative subspace. Three methods are available: 'gs' (Gram-Schmidt, the original proposition), 'svd' (based on SVD, fastest approach, it should be preferred on large data sets) and 'reg' (the Fisher criterion is rewritten as a regression problem). The 'gs' method is the default method since it is the most efficient one on most data sets.
</p>
</td></tr>
<tr><td><code id="fem_+3A_crit">crit</code></td>
<td>
<p>The model selection criterion to use for selecting the most appropriate model for the data. There are 3 possibilities: &quot;bic&quot;, &quot;aic&quot; or &quot;icl&quot;. Default is &quot;icl&quot;.
</p>
</td></tr>
<tr><td><code id="fem_+3A_maxit">maxit</code></td>
<td>

<p>The maximum number of iterations before the stop of the Fisher-EM algorithm. 
</p>
</td></tr>
<tr><td><code id="fem_+3A_eps">eps</code></td>
<td>

<p>The threshold value for the likelihood differences to stop the Fisher-EM algorithm.
</p>
</td></tr>
<tr><td><code id="fem_+3A_init">init</code></td>
<td>

<p>The initialization method for the Fisher-EM algorithm. There are 4 options: &quot;random&quot; for a randomized initialization, &quot;kmeans&quot; for an initialization by the kmeans algorithm, &quot;hclust&quot; for hierarchical clustering initialization or &quot;user&quot; for a specific initialization through the parameter &quot;Tinit&quot;. Default is &quot;kmeans&quot;. Notice that for &quot;kmeans&quot; and &quot;random&quot;, several initializations are asked and the initialization associated with the highest likelihood is kept (see &quot;nstart&quot;).
</p>
</td></tr>
<tr><td><code id="fem_+3A_nstart">nstart</code></td>
<td>
<p>The number of restart if the initialization is &quot;kmeans&quot; or &quot;random&quot;. In such a case, the initialization associated with the highest likelihood is kept.
</p>
</td></tr>
<tr><td><code id="fem_+3A_tinit">Tinit</code></td>
<td>

<p>A n x K matrix which contains posterior probabilities for initializing the algorithm (each line corresponds to an individual).
</p>
</td></tr>
<tr><td><code id="fem_+3A_kernel">kernel</code></td>
<td>
<p>It enables to deal with the n &lt; p problem. By default, no kernel (&quot; &quot;) is used. But the user has the choice between 3 options for the kernel: &quot;linear&quot;, &quot;sigmoid&quot; or &quot;rbf&quot;.
</p>
</td></tr>
<tr><td><code id="fem_+3A_disp">disp</code></td>
<td>

<p>If true, some messages are printed during the clustering. Default is false.
</p>
</td></tr>
<tr><td><code id="fem_+3A_mc.cores">mc.cores</code></td>
<td>
<p>The number of CPUs to use to fit in parallel the different models (only for non-Windows platforms). Default is the number of available cores minus 1.</p>
</td></tr>
<tr><td><code id="fem_+3A_subset">subset</code></td>
<td>
<p>A positive integer defining the size of the subsample, default is NULL. In case of large data sets, it might be useful to fit a FisherEM model on a subsample of the data, and then use this model to predict cluster assignments for the whole data set. Notice that in, such a case, likelihood values and model selection criteria are computed for the subsample and not the whole data set.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list is returned: 
</p>
<table>
<tr><td><code>K</code></td>
<td>
<p>The number of groups.</p>
</td></tr>
<tr><td><code>cls</code></td>
<td>
<p>the group membership of each individual estimated by the Fisher-EM algorithm.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>the posterior probabilities of each individual for each group.</p>
</td></tr>
<tr><td><code>U</code></td>
<td>
<p>The loading matrix which determines the orientation of the discriminative subspace.</p>
</td></tr>
<tr><td><code>mean</code></td>
<td>
<p>The estimated mean in the subspace.</p>
</td></tr>
<tr><td><code>my</code></td>
<td>
<p>The estimated mean in the observation space.</p>
</td></tr>
<tr><td><code>prop</code></td>
<td>
<p>The estimated mixture proportion.</p>
</td></tr>
<tr><td><code>D</code></td>
<td>
<p>The covariance matrices in the subspace.</p>
</td></tr>
<tr><td><code>aic</code></td>
<td>
<p>The value of the Akaike information criterion.</p>
</td></tr>
<tr><td><code>bic</code></td>
<td>
<p>The value of the Bayesian information criterion.</p>
</td></tr>
<tr><td><code>icl</code></td>
<td>
<p>The value of the integrated completed likelihood criterion.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The log-likelihood values computed at each iteration of the FEM algorithm.</p>
</td></tr>
<tr><td><code>ll</code></td>
<td>
<p>the log-likelihood value obtained at the last iteration of the FEM algorithm.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>The method used.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The call of the function.</p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>Some information to pass to the plot.fem function.</p>
</td></tr>
<tr><td><code>crit</code></td>
<td>
<p>The model selction criterion used.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Charles Bouveyron, Camille Brunet &amp; Nicolas Jouvin.
</p>


<h3>References</h3>

<p>Charles Bouveyron and Camille Brunet (2012), Simultaneous model-based clustering and visualization in the Fisher discriminative subspace, Statistics and Computing, 22(1), 301-324 &lt;doi:10.1007/s11222-011-9249-9&gt;.
</p>
<p>Charles Bouveyron and Camille Brunet (2014), &quot;Discriminative variable selection for clustering with the sparse Fisher-EM algorithm&quot;, Computational Statistics, vol. 29(3-4), pp. 489-513 &lt;10.1007/s00180-013-0433-6&gt;.
</p>


<h3>See Also</h3>

<p>sfem, plot.fem, fem.ari, summary.fem</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
res = fem(iris[,-5],K=3,model='AkBk',method='gs')
res
plot(res)
fem.ari(res,as.numeric(iris$Species))
table(iris$Species,res$cls)


# Fit several models and numbers of groups (use by default on non-Windows
# platforms the parallel computing).
res = fem(iris[,-5],K=2:6,model='all',method='gs', mc.cores=2)
res
plot(res)
fem.ari(res,as.numeric(iris$Species))
table(iris$Species,res$cls)

</code></pre>

<hr>
<h2 id='fem.ari'>
Adjusted Rand index
</h2><span id='topic+fem.ari'></span>

<h3>Description</h3>

<p>The function computes the adjusted Rand index (ARI) which allows to compare two clustering partitions.</p>


<h3>Usage</h3>

<pre><code class='language-R'>fem.ari(x,y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fem.ari_+3A_x">x</code></td>
<td>

<p>A 'fem' object containing the first partition to compare.
</p>
</td></tr>
<tr><td><code id="fem.ari_+3A_y">y</code></td>
<td>

<p>The second partition to compare (as vector).
</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>ari</code></td>
<td>
<p>The value of the ARI.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>fem, sfem, plot.fem, summary.fem</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
res = fem(iris[,-5],K=3,model='DkBk',method='reg')
res
plot(res)
fem.ari(res,as.numeric(iris[,5]))
</code></pre>

<hr>
<h2 id='plot.bfem'>Plotting function</h2><span id='topic+plot.bfem'></span><span id='topic+plot_subspace'></span><span id='topic+plot_bound'></span><span id='topic+plot_crit'></span>

<h3>Description</h3>

<p>Utility function to plot the results of the BFEM algorithm. The S3 plot
function is a wrapper function over the 3 other functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bfem'
plot(x, type = "subspace", ...)

plot_subspace(
  x,
  alpha_levels = c(0.95),
  plot.dims = c(1, 2),
  show.ellipses = T,
  show.uncertainty = T,
  size = 2,
  cex.uncertainty = 1,
  ...
)

plot_bound(x, ...)

plot_crit(x, crit = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.bfem_+3A_x">x</code></td>
<td>
<p>The results of <code><a href="#topic+bfem">bfem</a></code>.</p>
</td></tr>
<tr><td><code id="plot.bfem_+3A_type">type</code></td>
<td>
<p>The plot type: </p>
 <ul>
<li><p> &quot;subspace&quot; (default) - Uses
<code>plot_subspace()</code> to plot the projected data </p>
</li>
<li><p> &quot;criterion&quot; - Uses
<code>plot_crit()</code> to plot the criterion value. </p>
</li>
<li><p> &quot;elbo&quot; - Uses
<code>plot_bound()</code> to plot the variational lower bound evolution. </p>
</li></ul>
</td></tr>
<tr><td><code id="plot.bfem_+3A_...">...</code></td>
<td>
<p>Additional parameter to pass to corxponding functions:</p>
</td></tr>
<tr><td><code id="plot.bfem_+3A_alpha_levels">alpha_levels</code></td>
<td>
<p>A vector giving the desired Gaussian ellipses level set. Default to 0.95.</p>
</td></tr>
<tr><td><code id="plot.bfem_+3A_plot.dims">plot.dims</code></td>
<td>
<p>The dimension to be plotted. Default to the first two dimensions.</p>
</td></tr>
<tr><td><code id="plot.bfem_+3A_show.ellipses">show.ellipses</code></td>
<td>
<p>Should Gaussian ellipses be plotted. Default to TRUE</p>
</td></tr>
<tr><td><code id="plot.bfem_+3A_show.uncertainty">show.uncertainty</code></td>
<td>
<p>Should uncertainty be plotted. A point is considered uncertain if its posterior probability of membership is peaked toward 2 or more clusters. Graphically, it can be displayed with a bigger point size depending on the uncertainty level, bigger points being more uncertain.</p>
</td></tr>
<tr><td><code id="plot.bfem_+3A_size">size</code></td>
<td>
<p>The point size.</p>
</td></tr>
<tr><td><code id="plot.bfem_+3A_cex.uncertainty">cex.uncertainty</code></td>
<td>
<p>The multiplicative factor for the basic point size controlling the size of uncertain points.</p>
</td></tr>
<tr><td><code id="plot.bfem_+3A_crit">crit</code></td>
<td>
<p>Used to specify which criterion should be plotted. Possible values are &quot;aic&quot;, &quot;bic&quot; and 'icl. The default is the criterion used in the algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a ggplot2 plot object
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>plot_subspace</code>: Plot Y projected on the 'plot.dims' dimensions of the latent space
</p>
</li>
<li> <p><code>plot_bound</code>: plot the variational bound evolution
</p>
</li>
<li> <p><code>plot_crit</code>: Plot the criterion xult
</p>
</li></ul>


<h3>Examples</h3>

<pre><code class='language-R'>
data(iris)
Y = iris[,-5]
res = bfem(Y, 3, model = 'DB')
gg = plot(x=res, type = "subspace")
print(gg)

</code></pre>

<hr>
<h2 id='plot.fem'>
The plot function for 'fem' objects.
</h2><span id='topic+plot.fem'></span>

<h3>Description</h3>

<p>This function plots different information about 'fem' objects such as model selection, log-likelihood evolution and visualization of the clustered data into the discriminative subspace fitted by the Fisher-EM algorithm.</p>


<h3>Usage</h3>

<pre><code class='language-R'> ## S3 method for class 'fem'
plot(x, frame=0, crit=c(),...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.fem_+3A_x">x</code></td>
<td>
<p>The fem object.
</p>
</td></tr>
<tr><td><code id="plot.fem_+3A_frame">frame</code></td>
<td>
<p>0: all plots; 1: selection of the number of groups; 2: log-likelihood; projection of the data into the discriminative subspace.
</p>
</td></tr>
<tr><td><code id="plot.fem_+3A_crit">crit</code></td>
<td>

<p>The model selection criterion to display. Default is the criterion used in the 'fem' function ('icl' by default).
</p>
</td></tr>
<tr><td><code id="plot.fem_+3A_...">...</code></td>
<td>

<p>Additional options to pass to the plot function.
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>fem, sfem, fem.ari, summary.fem</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
res = fem(iris[,-5],K=3,model='DkBk',method='reg')
res
plot(res)
fem.ari(res,as.numeric(iris[,5]))
</code></pre>

<hr>
<h2 id='print.fem'>
The print function for 'fem' objects.
</h2><span id='topic+print.fem'></span>

<h3>Description</h3>

<p>This function summarizes 'fem' objects. It in particular indicates which DLM model has been chosen and displays the loading matrix 'U' if the original dimension is smaller than 10.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ## S3 method for class 'fem'
print(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.fem_+3A_x">x</code></td>
<td>
<p>The fem object.</p>
</td></tr>
<tr><td><code id="print.fem_+3A_...">...</code></td>
<td>
<p>Additional options to pass to the summary function.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>fem, sfem, fem.ari, plot.fem</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
res = fem(iris[,-5],K=3,model='DkBk',method='reg')
res
plot(res)
fem.ari(res,as.numeric(iris[,5]))
</code></pre>

<hr>
<h2 id='sfem'>
The sparse Fisher-EM algorithm
</h2><span id='topic+sfem'></span>

<h3>Description</h3>

<p>The sparse Fisher-EM algorithm is a sparse version of the Fisher-EM algorithm. The sparsity is introduced within the F step which estimates the discriminative subspace. The sparsity on U is obtained by adding a l1 penalty to the optimization problem of the F step.</p>


<h3>Usage</h3>

<pre><code class='language-R'>sfem(Y,K=2:6,obj=NULL,model='AkjBk',method='reg',crit='icl',maxit=50,eps=1e-6,
    init='kmeans',nstart=5,Tinit=c(),kernel='',disp=FALSE,l1=0.1,l2=0,nbit=2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sfem_+3A_y">Y</code></td>
<td>
 
<p>The data matrix. Categorical variables and missing values are not allowed.
</p>
</td></tr>
<tr><td><code id="sfem_+3A_k">K</code></td>
<td>

<p>An integer vector specifying the numbers of mixture components (clusters) among which the model selection criterion will choose the most appropriate number of groups. Default is 2:6.
</p>
</td></tr>
<tr><td><code id="sfem_+3A_obj">obj</code></td>
<td>
<p>An object of class 'fem' previously learned with the 'fem' function which will be used as initialization of the sparse FisherEM algorithm.</p>
</td></tr>
<tr><td><code id="sfem_+3A_model">model</code></td>
<td>
<p>A vector of discriminative latent mixture (DLM) models to fit. There are 12 different models: &quot;DkBk&quot;, &quot;DkB&quot;, &quot;DBk&quot;, &quot;DB&quot;, &quot;AkjBk&quot;, &quot;AkjB&quot;, &quot;AkBk&quot;, &quot;AkBk&quot;, &quot;AjBk&quot;, &quot;AjB&quot;, &quot;ABk&quot;, &quot;AB&quot;.  The option &quot;all&quot; executes the Fisher-EM algorithm on the 12 DLM models and select the best model according to the maximum value obtained by model selection criterion. 
</p>
</td></tr> 
<tr><td><code id="sfem_+3A_method">method</code></td>
<td>

<p>The method use for the fitting of the projection matrix associated to the discriminative subspace. Three methods are available: 'svd', 'reg' and 'gs'. The 'reg' method is the default.
</p>
</td></tr>
<tr><td><code id="sfem_+3A_crit">crit</code></td>
<td>
<p>The model selection criterion to use for selecting the most appropriate model for the data. There are 3 possibilities: &quot;bic&quot;, &quot;aic&quot; or &quot;icl&quot;. Default is &quot;icl&quot;.
</p>
</td></tr>
<tr><td><code id="sfem_+3A_maxit">maxit</code></td>
<td>

<p>The maximum number of iterations before the stop of the Fisher-EM algorithm. 
</p>
</td></tr>
<tr><td><code id="sfem_+3A_eps">eps</code></td>
<td>

<p>The threshold value for the likelihood differences to stop the Fisher-EM algorithm.
</p>
</td></tr>
<tr><td><code id="sfem_+3A_init">init</code></td>
<td>

<p>The initialization method for the Fisher-EM algorithm. There are 4 options: &quot;random&quot; for a randomized initialization, &quot;kmeans&quot; for an initialization by the kmeans algorithm, &quot;hclust&quot; for hierarchical clustering initialization or &quot;user&quot; for a specific initialization through the parameter &quot;Tinit&quot;. Default is &quot;kmeans&quot;. Notice that for &quot;kmeans&quot; and &quot;random&quot;, several initializations are asked and the initialization associated with the highest likelihood is kept (see &quot;nstart&quot;).
</p>
</td></tr>
<tr><td><code id="sfem_+3A_nstart">nstart</code></td>
<td>
<p>The number of restart if the initialization is &quot;kmeans&quot; or &quot;random&quot;. In such a case, the initialization associated with the highest likelihood is kept.
</p>
</td></tr>
<tr><td><code id="sfem_+3A_tinit">Tinit</code></td>
<td>

<p>A n x K matrix which contains posterior probabilities for initializing the algorithm (each line corresponds to an individual).
</p>
</td></tr>
<tr><td><code id="sfem_+3A_kernel">kernel</code></td>
<td>
<p>It enables to deal with the n &lt; p problem. By default, no kernel (&quot; &quot;) is used. But the user has the choice between 3 options for the kernel: &quot;linear&quot;, &quot;sigmoid&quot; or &quot;rbf&quot;.
</p>
</td></tr>
<tr><td><code id="sfem_+3A_disp">disp</code></td>
<td>

<p>If true, some messages are printed during the clustering. Default is false.
</p>
</td></tr>
<tr><td><code id="sfem_+3A_l1">l1</code></td>
<td>

<p>The l1 penalty value (lasso) which has to be in [0,1]. A small value (close to 0) leads to a very sparse loading matrix whereas a value equals to 1 corresponds to no sparsity. Default is 0.1.
</p>
</td></tr>
<tr><td><code id="sfem_+3A_l2">l2</code></td>
<td>

<p>The l2 penalty value (elasticnet). Defaults is 0 (no regularization).
</p>
</td></tr>
<tr><td><code id="sfem_+3A_nbit">nbit</code></td>
<td>

<p>The number of iterations for the lasso procedure. Defaults is 2.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list is returned: 
</p>
<table>
<tr><td><code>K</code></td>
<td>
<p>The number of groups.</p>
</td></tr>
<tr><td><code>cls</code></td>
<td>
<p>the group membership of each individual estimated by the Fisher-EM algorithm.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>the posterior probabilities of each individual for each group.</p>
</td></tr>
<tr><td><code>U</code></td>
<td>
<p>The loading matrix which determines the orientation of the discriminative subspace.</p>
</td></tr>
<tr><td><code>mean</code></td>
<td>
<p>The estimated mean in the subspace.</p>
</td></tr>
<tr><td><code>my</code></td>
<td>
<p>The estimated mean in the observation space.</p>
</td></tr>
<tr><td><code>prop</code></td>
<td>
<p>The estimated mixture proportion.</p>
</td></tr>
<tr><td><code>D</code></td>
<td>
<p>The covariance matrices in the subspace.</p>
</td></tr>
<tr><td><code>aic</code></td>
<td>
<p>The value of the Akaike information criterion.</p>
</td></tr>
<tr><td><code>bic</code></td>
<td>
<p>The value of the Bayesian information criterion.</p>
</td></tr>
<tr><td><code>icl</code></td>
<td>
<p>The value of the integrated completed likelihood criterion.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The log-likelihood values computed at each iteration of the FEM algorithm.</p>
</td></tr>
<tr><td><code>ll</code></td>
<td>
<p>the log-likelihood value obtained at the last iteration of the FEM algorithm.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>The method used.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The call of the function.</p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>Some information to pass to the plot.fem function.</p>
</td></tr>
<tr><td><code>crit</code></td>
<td>
<p>The model selction criterion used.</p>
</td></tr>
<tr><td><code>l1</code></td>
<td>
<p>The l1 value.</p>
</td></tr>
<tr><td><code>l2</code></td>
<td>
<p>The l2 value.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Charles Bouveyron and Camille Brunet
</p>


<h3>References</h3>

<p>Charles Bouveyron and Camille Brunet (2012), Simultaneous model-based clustering and visualization in the Fisher discriminative subspace, Statistics and Computing, 22(1), 301-324 &lt;doi:10.1007/s11222-011-9249-9&gt;.
</p>
<p>Charles Bouveyron and Camille Brunet (2014), &quot;Discriminative variable selection for clustering with the sparse Fisher-EM algorithm&quot;, Computational Statistics, vol. 29(3-4), pp. 489-513 &lt;10.1007/s00180-013-0433-6&gt;.
</p>


<h3>See Also</h3>

<p>fem, plot.fem, fem.ari, summary.fem</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
res = sfem(iris[,-5],K=3,model='DkBk',l1=seq(.01,.3,.05))
res
plot(res)
fem.ari(res,as.numeric(iris[,5]))
</code></pre>

<hr>
<h2 id='simu_bfem'>Experimental setting of the chapter BFEM</h2><span id='topic+simu_bfem'></span>

<h3>Description</h3>

<p>Experimental setting of the chapter BFEM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simu_bfem(n, which = "Chang1983", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simu_bfem_+3A_n">n</code></td>
<td>
<p>Number of observations</p>
</td></tr>
<tr><td><code id="simu_bfem_+3A_which">which</code></td>
<td>
<p>Type of simulation, either:
</p>

<ul>
<li><p> &quot;Chang1983&quot; - Simulate the dataset of Chang's (1983) paper : a mixture of 2 Gaussian with in dimension p=15. 
</p>
</li>
<li><p> &quot;section4.2&quot; - Experimental setting of Section 4.2: DLM model in dimension p with d=2 and K=3, with noisy dimensions. 
</p>
</li>
<li><p> &quot;section4.3&quot; - Experimental setting of Section 4.3: Same as '&quot;section4.2&quot;' except the noise is expressed in term of signal-to-noise ration (decibels).
</p>
</li></ul>
</td></tr>
<tr><td><code id="simu_bfem_+3A_...">...</code></td>
<td>
<p>Additional param controlling the simulation
</p>

<ul>
<li><p> p - The desired observed space dimension, the latent dimension is kept fixed to d=2 and noisy Gaussian dimensions are added (useless for '&quot;Chang1983&quot;') 
</p>
</li>
<li><p> noise (for '&quot;section4.2&quot;' only) - Variance of the noise 
</p>
</li>
<li><p> snr (for '&quot;section4.3&quot;' only) - Signal-to-noise ratio (in decibels) representing the ratio of signal and noise variances in logarithmic scale. The greater snr, the smaller noise variance.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with slots
</p>

<ul>
<li><p> Y - The simulated data.
</p>
</li>
<li><p> cls - The true clustering.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>n = 300

# Chang's 1983 setting
simu = simu_bfem(n = n, which = "Chang1983")

# Section 4.2 setting
p = 25
noise = 1
simu = simu_bfem(n, which = "section4.2", p = p, noise = noise)

# Section4.3 setting
snr = 3 # noise variance is 2 times smaller than that of the signal.
simu = simu_bfem(n, which = "section4.3", snr = 10)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
