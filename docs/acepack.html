<!DOCTYPE html><html><head><title>Help for package acepack</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {acepack}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ace'><p>Alternating Conditional Expectations</p></a></li>
<li><a href='#avas'><p>Additivity and variance stabilization for regression</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Maintainer:</td>
<td>Shawn Garbett &lt;shawn.garbett@vumc.org&gt;</td>
</tr>
<tr>
<td>Version:</td>
<td>1.4.2</td>
</tr>
<tr>
<td>Author:</td>
<td>Phil Spector, Jerome Friedman, Robert Tibshirani, Thomas Lumley, Shawn Garbett, Jonathan Baron</td>
</tr>
<tr>
<td>Description:</td>
<td>Two nonparametric methods for multiple regression transform selection are provided.
  The first, Alternative Conditional Expectations (ACE), 
  is an algorithm to find the fixed point of maximal
  correlation, i.e. it finds a set of transformed response variables that maximizes R^2
  using smoothing functions [see Breiman, L., and J.H. Friedman. 1985. "Estimating Optimal Transformations
  for Multiple Regression and Correlation". Journal of the American Statistical Association.
  80:580-598. &lt;<a href="https://doi.org/10.1080%2F01621459.1985.10478157">doi:10.1080/01621459.1985.10478157</a>&gt;].
  Also included is the Additivity Variance Stabilization (AVAS) method which works better than ACE when
  correlation is low [see Tibshirani, R.. 1986. "Estimating Transformations for Regression via Additivity
  and Variance Stabilization". Journal of the American Statistical Association. 83:394-405. 
  &lt;<a href="https://doi.org/10.1080%2F01621459.1988.10478610">doi:10.1080/01621459.1988.10478610</a>&gt;]. A good introduction to these two methods is in chapter 16 of
  Frank Harrel's "Regression Modeling Strategies" in the Springer Series in Statistics.</td>
</tr>
<tr>
<td>Title:</td>
<td>ACE and AVAS for Selecting Multiple Regression Transformations</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-21 17:30:03 UTC; garbetsp</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-22 09:10:02 UTC</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
</table>
<hr>
<h2 id='ace'>Alternating Conditional Expectations</h2><span id='topic+ace'></span>

<h3>Description</h3>

<p>Uses the alternating conditional expectations algorithm to find the
transformations of y and x that maximise the proportion of variation
in y explained by x. When x is a matrix, it is transformed so that
its columns are equally weighted when predicting y.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ace(x, y, wt = rep(1, nrow(x)), cat = NULL, mon = NULL, lin = NULL,
   circ = NULL, delrsq = 0.01)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ace_+3A_x">x</code></td>
<td>
<p>a matrix containing the independent variables.</p>
</td></tr>
<tr><td><code id="ace_+3A_y">y</code></td>
<td>
<p>a vector containing the response variable.</p>
</td></tr>
<tr><td><code id="ace_+3A_wt">wt</code></td>
<td>
<p>an optional vector of weights.</p>
</td></tr>
<tr><td><code id="ace_+3A_cat">cat</code></td>
<td>
<p>an optional integer vector specifying which variables
assume categorical values.  Positive values in <code>cat</code> refer
to columns of the <code>x</code> matrix and zero to the response
variable.  Variables must be numeric, so a character variable
should first be transformed with as.numeric() and then specified
as categorical.</p>
</td></tr>
<tr><td><code id="ace_+3A_mon">mon</code></td>
<td>
<p>an optional integer vector specifying which variables are
to be transformed by monotone transformations.  Positive values
in <code>mon</code> refer to columns of the <code>x</code> matrix and zero
to the response variable.</p>
</td></tr>
<tr><td><code id="ace_+3A_lin">lin</code></td>
<td>
<p>an optional integer vector specifying which variables are
to be transformed by linear transformations.  Positive values in
<code>lin</code> refer to columns of the <code>x</code> matrix and zero to
the response variable.</p>
</td></tr>
<tr><td><code id="ace_+3A_circ">circ</code></td>
<td>
<p>an integer vector specifying which variables assume
circular (periodic) values.  Positive values in <code>circ</code>
refer to columns of the <code>x</code> matrix and zero to the response
variable.</p>
</td></tr>
<tr><td><code id="ace_+3A_delrsq">delrsq</code></td>
<td>
<p>termination threshold.  Iteration stops when R-squared
changes by less than <code>delrsq</code> in 3 consecutive iterations
(default 0.01).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A structure with the following components:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>the input x matrix.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>the input y vector.</p>
</td></tr>
<tr><td><code>tx</code></td>
<td>
<p>the transformed x values.</p>
</td></tr>
<tr><td><code>ty</code></td>
<td>
<p>the transformed y values.</p>
</td></tr>
<tr><td><code>rsq</code></td>
<td>
<p>the multiple R-squared value for the transformed values.</p>
</td></tr>
<tr><td><code>l</code></td>
<td>
<p>the codes for cat, mon, ...</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>not used in this version of ace</p>
</td></tr>
</table>


<h3>References</h3>

<p>Breiman and Friedman, Journal of the American Statistical
Association (September, 1985).
</p>
<p>The R code is adapted from S code for avas() by Tibshirani, in the
Statlib S archive; the FORTRAN is a double-precision version of
FORTRAN code by Friedman and Spector in the Statlib general
archive.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>TWOPI &lt;- 8*atan(1)
x &lt;- runif(200,0,TWOPI)
y &lt;- exp(sin(x)+rnorm(200)/2)
a &lt;- ace(x,y)
par(mfrow=c(3,1))
plot(a$y,a$ty)  # view the response transformation
plot(a$x,a$tx)  # view the carrier transformation
plot(a$tx,a$ty) # examine the linearity of the fitted model

# example when x is a matrix
X1 &lt;- 1:10
X2 &lt;- X1^2
X &lt;- cbind(X1,X2)
Y &lt;- 3*X1+X2
a1 &lt;- ace(X,Y)
plot(rowSums(a1$tx),a1$y)
(lm(a1$y ~ a1$tx)) # shows that the colums of X are equally weighted

# From D. Wang and M. Murphy (2005), Identifying nonlinear relationships
# regression using the ACE algorithm.  Journal of Applied Statistics,
# 32, 243-258.
X1 &lt;- runif(100)*2-1
X2 &lt;- runif(100)*2-1
X3 &lt;- runif(100)*2-1
X4 &lt;- runif(100)*2-1

# Original equation of Y:
Y &lt;- log(4 + sin(3*X1) + abs(X2) + X3^2 + X4 + .1*rnorm(100))

# Transformed version so that Y, after transformation, is a
# linear function of transforms of the X variables:
# exp(Y) = 4 + sin(3*X1) + abs(X2) + X3^2 + X4

a1 &lt;- ace(cbind(X1,X2,X3,X4),Y)

# For each variable, show its transform as a function of
# the original variable and the of the transform that created it,
# showing that the transform is recovered.
par(mfrow=c(2,1))

plot(X1,a1$tx[,1])
plot(sin(3*X1),a1$tx[,1])

plot(X2,a1$tx[,2])
plot(abs(X2),a1$tx[,2])

plot(X3,a1$tx[,3])
plot(X3^2,a1$tx[,3])

plot(X4,a1$tx[,4])
plot(X4,a1$tx[,4])

plot(Y,a1$ty)
plot(exp(Y),a1$ty)
</code></pre>

<hr>
<h2 id='avas'>Additivity and variance stabilization for regression</h2><span id='topic+avas'></span><span id='topic+avas.formula'></span>

<h3>Description</h3>

<p>Estimate transformations of <code>x</code> and <code>y</code> such that
the regression of <code>y</code> on <code>x</code> is approximately linear with
constant variance</p>


<h3>Usage</h3>

<pre><code class='language-R'>avas(x, y, wt = rep(1, nrow(x)), cat = NULL, mon = NULL, 
    lin = NULL, circ = NULL, delrsq = 0.01, yspan = 0) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="avas_+3A_x">x</code></td>
<td>
<p>a matrix containing the independent variables.</p>
</td></tr>
<tr><td><code id="avas_+3A_y">y</code></td>
<td>
<p>a vector containing the response variable.</p>
</td></tr>
<tr><td><code id="avas_+3A_wt">wt</code></td>
<td>
<p>an optional vector of weights.</p>
</td></tr>
<tr><td><code id="avas_+3A_cat">cat</code></td>
<td>
<p>an optional integer vector specifying which variables
assume categorical values.  Positive values in <code>cat</code> refer
to columns of the <code>x</code> matrix and zero to the response
variable.  Variables must be numeric, so a character variable
should first be transformed with as.numeric() and then specified
as categorical.</p>
</td></tr>
<tr><td><code id="avas_+3A_mon">mon</code></td>
<td>
<p>an optional integer vector specifying which variables are
to be transformed by monotone transformations.  Positive values
in <code>mon</code> refer to columns of the <code>x</code> matrix and zero
to the response variable.</p>
</td></tr>
<tr><td><code id="avas_+3A_lin">lin</code></td>
<td>
<p>an optional integer vector specifying which variables are
to be transformed by linear transformations.  Positive values in
<code>lin</code> refer to columns of the <code>x</code> matrix and zero to
the response variable.</p>
</td></tr>
<tr><td><code id="avas_+3A_circ">circ</code></td>
<td>
<p>an integer vector specifying which variables assume
circular (periodic) values.  Positive values in <code>circ</code>
refer to columns of the <code>x</code> matrix and zero to the response
variable.</p>
</td></tr>
<tr><td><code id="avas_+3A_delrsq">delrsq</code></td>
<td>
<p>termination threshold.  Iteration stops when R-squared
changes by less than <code>delrsq</code> in 3 consecutive iterations
(default 0.01).</p>
</td></tr>
<tr><td><code id="avas_+3A_yspan">yspan</code></td>
<td>
<p>Optional window size parameter for smoothing the
variance.  Range is <code class="reqn">[0,1]</code>.  Default is 0 (cross validated
choice). .5 is a reasonable alternative to try.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A structure with the following components:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>the input x matrix.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>the input y vector.</p>
</td></tr>
<tr><td><code>tx</code></td>
<td>
<p>the transformed x values.</p>
</td></tr>
<tr><td><code>ty</code></td>
<td>
<p>the transformed y values.</p>
</td></tr>
<tr><td><code>rsq</code></td>
<td>
<p>the multiple R-squared value for the transformed values.</p>
</td></tr>
<tr><td><code>l</code></td>
<td>
<p>the codes for cat, mon, ...</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>not used in this version of avas</p>
</td></tr>
<tr><td><code>yspan</code></td>
<td>
<p>span used for smoothing the variance</p>
</td></tr>
<tr><td><code>iters</code></td>
<td>
<p>iteration number and rsq for that iteration</p>
</td></tr>
<tr><td><code>niters</code></td>
<td>
<p>number of iterations used</p>
</td></tr>
</table>


<h3>References</h3>

<p>Rob Tibshirani (1987),
&ldquo;Estimating optimal transformations for regression&rdquo;. 
<em>Journal of the American Statistical Association</em> <b>83</b>,
394ff.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>TWOPI &lt;- 8*atan(1)
x &lt;- runif(200,0,TWOPI)
y &lt;- exp(sin(x)+rnorm(200)/2)
a &lt;- avas(x,y)
par(mfrow=c(3,1))
plot(a$y,a$ty)  # view the response transformation
plot(a$x,a$tx)  # view the carrier transformation
plot(a$tx,a$ty) # examine the linearity of the fitted model

# From D. Wang and M. Murphy (2005), Identifying nonlinear relationships
# regression using the ACE algorithm.  Journal of Applied Statistics,
# 32, 243-258, adapted for avas.
X1 &lt;- runif(100)*2-1
X2 &lt;- runif(100)*2-1
X3 &lt;- runif(100)*2-1
X4 &lt;- runif(100)*2-1

# Original equation of Y:
Y &lt;- log(4 + sin(3*X1) + abs(X2) + X3^2 + X4 + .1*rnorm(100))

# Transformed version so that Y, after transformation, is a
# linear function of transforms of the X variables:
# exp(Y) = 4 + sin(3*X1) + abs(X2) + X3^2 + X4

a1 &lt;- avas(cbind(X1,X2,X3,X4),Y)

par(mfrow=c(2,1))

# For each variable, show its transform as a function of
# the original variable and the of the transform that created it,
# showing that the transform is recovered.
plot(X1,a1$tx[,1])
plot(sin(3*X1),a1$tx[,1])

plot(X2,a1$tx[,2])
plot(abs(X2),a1$tx[,2])

plot(X3,a1$tx[,3])
plot(X3^2,a1$tx[,3])

plot(X4,a1$tx[,4])
plot(X4,a1$tx[,4])

plot(Y,a1$ty)
plot(exp(Y),a1$ty)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
