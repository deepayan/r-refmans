<!DOCTYPE html><html><head><title>Help for package glmmML</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {glmmML}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ghq'><p>Gauss-Hermite</p></a></li>
<li><a href='#glmmboot'><p>Generalized Linear Models with fixed effects grouping</p></a></li>
<li><a href='#glmmbootFit'><p>Generalized Linear Models with fixed effects grouping</p></a></li>
<li><a href='#glmmML'><p>Generalized Linear Models with random intercept</p></a></li>
<li><a href='#glmmML.fit'><p>Generalized Linear Model with random intercept</p></a></li>
<li><a href='#print.glmmboot'><p>Prints a 'glmmML' object.</p></a></li>
<li><a href='#print.glmmML'><p>Prints a 'glmmML' object.</p></a></li>
<li><a href='#summary.glmmboot'><p>Summary of a glmmboot object</p></a></li>
<li><a href='#summary.glmmML'><p>Summary of a glmmML object</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.6</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-11-28</td>
</tr>
<tr>
<td>Title:</td>
<td>Generalized Linear Models with Clustering</td>
</tr>
<tr>
<td>Description:</td>
<td>Binomial and Poisson regression for clustered data, fixed
        and random effects with bootstrapping.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.13.0)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Göran Broström &lt;goran.brostrom@umu.se&gt;</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, lme4</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-28 14:48:28 UTC; gobr0002</td>
</tr>
<tr>
<td>Author:</td>
<td>Göran Broström [aut, cre],
  Jianming Jin [ctb],
  Henrik Holmberg [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-28 17:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ghq'>Gauss-Hermite</h2><span id='topic+ghq'></span>

<h3>Description</h3>

<p>Calculates the zeros and weights needed for Gauss-Hermite quadrature. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ghq(n.points = 1, modified = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghq_+3A_n.points">n.points</code></td>
<td>
<p>Number of points.</p>
</td></tr>
<tr><td><code id="ghq_+3A_modified">modified</code></td>
<td>
<p>Multiply by exp(zeros**2)? Default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Based on a Fortran 66 subroutine written by professor Jianming Jin. 
</p>


<h3>Value</h3>

<p>A list vith components
</p>
<table>
<tr><td><code>zeros</code></td>
<td>
<p>The zeros (abscissas).</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>The weights</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The code is modified to suit the purpose of glmmML, with the permission
of professor Jin.</p>


<h3>Author(s)</h3>

<p>Jianming Jin, Univ. of Illinois, Urbana-Campaign</p>


<h3>References</h3>

<p>Gauss-Hermite</p>


<h3>See Also</h3>

<p><code><a href="#topic+glmmML">glmmML</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>ghq(15, FALSE)
</code></pre>

<hr>
<h2 id='glmmboot'>Generalized Linear Models with fixed effects grouping</h2><span id='topic+glmmboot'></span>

<h3>Description</h3>

<p>Fits grouped GLMs with fixed group effects. The significance of the
grouping is tested by simulation, with a bootstrap approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glmmboot(formula, family = binomial, data, cluster, weights, subset, na.action,
offset, contrasts = NULL, start.coef = NULL,
control = list(epsilon = 1e-08, maxit = 200, trace = FALSE), boot = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glmmboot_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit. The details of
model specification are given below.</p>
</td></tr>
<tr><td><code id="glmmboot_+3A_family">family</code></td>
<td>
<p>Currently, the only valid values are <code>binomial</code> and
<code>poisson</code>. The binomial family allows for the <code>logit</code> and
<code>cloglog</code> links.</p>
</td></tr>
<tr><td><code id="glmmboot_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model.
By default the variables are taken from
&lsquo;environment(formula)&rsquo;, typically the environment from which
&lsquo;glmmML&rsquo; is called.</p>
</td></tr>
<tr><td><code id="glmmboot_+3A_cluster">cluster</code></td>
<td>
<p>Factor indicating which items are correlated.</p>
</td></tr>
<tr><td><code id="glmmboot_+3A_weights">weights</code></td>
<td>
<p>Case weights.</p>
</td></tr>
<tr><td><code id="glmmboot_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="glmmboot_+3A_na.action">na.action</code></td>
<td>
<p>See glm.</p>
</td></tr>
<tr><td><code id="glmmboot_+3A_offset">offset</code></td>
<td>
<p>this can be used to specify an a priori known component to be
included in the linear predictor during fitting.</p>
</td></tr>
<tr><td><code id="glmmboot_+3A_contrasts">contrasts</code></td>
<td>
<p>an optional list. See the 'contrasts.arg' of 'model.matrix.default'.</p>
</td></tr>
<tr><td><code id="glmmboot_+3A_start.coef">start.coef</code></td>
<td>
<p>starting values for the parameters in the linear predictor.
Defaults to zero.</p>
</td></tr>
<tr><td><code id="glmmboot_+3A_control">control</code></td>
<td>
<p>Controls the convergence criteria. See
<code><a href="stats.html#topic+glm.control">glm.control</a></code> for details.</p>
</td></tr> 
<tr><td><code id="glmmboot_+3A_boot">boot</code></td>
<td>
<p>number of bootstrap replicates. If equal to zero, no test
of significance of the grouping factor is performed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The simulation is performed by 
simulating new response vectors from the fitted probabilities without
clustering, and comparing the maximized log likelihoods. The
maximizations are performed by profiling out the grouping factor. It is
a very fast procedure, compared to <code><a href="stats.html#topic+glm">glm</a></code>, when the grouping
factor has many levels.</p>


<h3>Value</h3>

<p>The return value is a list, an object of class 'glmmboot'.
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>Estimated regression coefficients</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>the max log likelihood</p>
</td></tr>
<tr><td><code>cluster.null.deviance</code></td>
<td>
<p>Deviance without the clustering</p>
</td></tr>
<tr><td><code>frail</code></td>
<td>
<p>The estimated cluster effects</p>
</td></tr>
<tr><td><code>bootLog</code></td>
<td>
<p>The logLik values from the bootstrap samples</p>
</td></tr>
<tr><td><code>bootP</code></td>
<td>
<p>Bootstrap p value</p>
</td></tr>
<tr><td><code>variance</code></td>
<td>
<p>Variance covariance matrix</p>
</td></tr>
<tr><td><code>sd</code></td>
<td>
<p>Standard error of regression parameters</p>
</td></tr>
<tr><td><code>boot_rep</code></td>
<td>
<p>No. of bootstrap replicates</p>
</td></tr>
<tr><td><code>mixed</code></td>
<td>
<p>Logical</p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>
<p>Deviance</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>Its degrees of freedom</p>
</td></tr>
<tr><td><code>aic</code></td>
<td>
<p>AIC</p>
</td></tr>
<tr><td><code>boot</code></td>
<td>
<p>Logical</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The function call</p>
</td></tr>
</table>


<h3>Note</h3>

<p>There is no overall intercept for this model; each cluster has its
own intercept. See <code>frail</code></p>


<h3>Author(s)</h3>

<p>G\&quot;oran Brostr\&quot;om and Henrik Holmberg</p>


<h3>References</h3>

<p>Brostr\&quot;om, G. and Holmberg, H. (2011). Generalized linear models with
clustered data: Fixed and random effects models. Computational
Statistics and Data Analysis 55:3123-3134.</p>


<h3>See Also</h3>

<p><code>link{glmmML}</code>, <code><a href="stats.html#topic+optim">optim</a></code>,
<code><a href="lme4.html#topic+lmer">lmer</a></code> in <code>Matrix</code>, and 
<code><a href="MASS.html#topic+glmmPQL">glmmPQL</a></code> in <code>MASS</code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:
id &lt;- factor(rep(1:20, rep(5, 20)))
y &lt;- rbinom(100, prob = rep(runif(20), rep(5, 20)), size = 1)
x &lt;- rnorm(100)
dat &lt;- data.frame(y = y, x = x, id = id)
res &lt;- glmmboot(y ~ x, cluster = id, data = dat, boot = 5000)
## End(Not run)
##system.time(res.glm &lt;- glm(y ~ x + id, family = binomial))
</code></pre>

<hr>
<h2 id='glmmbootFit'>Generalized Linear Models with fixed effects grouping</h2><span id='topic+glmmbootFit'></span>

<h3>Description</h3>

<p>'glmmbootFit' is the workhorse in the function <code>glmmboot</code>. It is
suitable to call instead of 'glmmboot', e.g. in simulations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glmmbootFit(X, Y, weights = rep(1, NROW(Y)),
start.coef = NULL, cluster = rep(1, length(Y)),
offset = rep(0, length(Y)), family = binomial(),
control = list(epsilon = 1.e-8, maxit = 200, trace
= FALSE), boot = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glmmbootFit_+3A_x">X</code></td>
<td>
<p>The design matrix (n * p).</p>
</td></tr>
<tr><td><code id="glmmbootFit_+3A_y">Y</code></td>
<td>
<p>The response vector of length n.</p>
</td></tr>
<tr><td><code id="glmmbootFit_+3A_weights">weights</code></td>
<td>
<p>Case weights.</p>
</td></tr>
<tr><td><code id="glmmbootFit_+3A_start.coef">start.coef</code></td>
<td>
<p>start values for the parameters in the linear
predictor (except the intercept).</p>
</td></tr>
<tr><td><code id="glmmbootFit_+3A_cluster">cluster</code></td>
<td>
<p>Factor indicating which items are correlated.</p>
</td></tr>
<tr><td><code id="glmmbootFit_+3A_offset">offset</code></td>
<td>
<p>this can be used to specify an a priori known component to be
included in the linear predictor during fitting.</p>
</td></tr>
<tr><td><code id="glmmbootFit_+3A_family">family</code></td>
<td>
<p>Currently, the only valid values are <code>binomial</code> and
<code>poisson</code>. The binomial family allows for the <code>logit</code> and
<code>cloglog</code> links.</p>
</td></tr>
<tr><td><code id="glmmbootFit_+3A_control">control</code></td>
<td>
<p>A list. Controls the convergence criteria. See
<code><a href="stats.html#topic+glm.control">glm.control</a></code> for details.</p>
</td></tr> 
<tr><td><code id="glmmbootFit_+3A_boot">boot</code></td>
<td>
<p>number of bootstrap replicates. If equal to zero, no test
of significance of the grouping factor is performed. If non-zero, it
should be large, at least, say, 2000.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>Estimated regression coefficients (note: No intercept).</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>The maximised log likelihood.</p>
</td></tr>
<tr><td><code>cluster.null.deviance</code></td>
<td>
<p>deviance from a moddel without cluster.</p>
</td></tr>
<tr><td><code>frail</code></td>
<td>
<p>The estimated cluster effects.</p>
</td></tr>
<tr><td><code>bootLog</code></td>
<td>
<p>The maximised bootstrap log likelihood values. A vector
of length <code>boot</code>.</p>
</td></tr>
<tr><td><code>bootP</code></td>
<td>
<p>The bootstrap p value.</p>
</td></tr>
<tr><td><code>variance</code></td>
<td>
<p>The variance-covariance matrix of the fixed effects
(no intercept).</p>
</td></tr>
<tr><td><code>sd</code></td>
<td>
<p>The standard errors of the <code>coefficients</code>.</p>
</td></tr>
<tr><td><code>boot_rep</code></td>
<td>
<p>The number of bootstrap replicates.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>A profiling approach is used to estimate the cluster effects. 
</p>


<h3>Author(s)</h3>

<p>Göran Broström</p>


<h3>See Also</h3>

<p><code><a href="#topic+glmmboot">glmmboot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run
x &lt;- matrix(rnorm(1000), ncol = 1)
id &lt;- rep(1:100, rep(10, 100))
y &lt;- rbinom(1000, size = 1, prob = 0.4)
fit &lt;- glmmbootFit(x, y, cluster = id, boot = 200)
summary(fit)
## End(Not run)
## Should show no effects. And boot too small.
</code></pre>

<hr>
<h2 id='glmmML'>Generalized Linear Models with random intercept</h2><span id='topic+glmmML'></span>

<h3>Description</h3>

<p>Fits GLMs with random intercept by Maximum Likelihood and numerical
integration via Gauss-Hermite quadrature.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glmmML(formula, family = binomial, data, cluster, weights,
cluster.weights, subset, na.action, 
offset, contrasts = NULL, prior = c("gaussian", "logistic", "cauchy"),
start.coef = NULL, start.sigma = NULL, fix.sigma = FALSE, x = FALSE, 
control = list(epsilon = 1e-08, maxit = 200, trace = FALSE),
method = c("Laplace", "ghq"), n.points = 8, boot = 0) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glmmML_+3A_formula">formula</code></td>
<td>
<p> a symbolic description of the model to be fit. The details of
model specification are given below.</p>
</td></tr>
<tr><td><code id="glmmML_+3A_family">family</code></td>
<td>
<p>Currently, the only valid values are <code>binomial</code> and
<code>poisson</code>. The binomial family allows for the <code>logit</code> and
<code>cloglog</code> links.</p>
</td></tr>
<tr><td><code id="glmmML_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model.
By default the variables are taken from
&lsquo;environment(formula)&rsquo;, typically the environment from which
&lsquo;glmmML&rsquo; is called.
</p>
</td></tr>
<tr><td><code id="glmmML_+3A_cluster">cluster</code></td>
<td>
<p>Factor indicating which items are correlated.</p>
</td></tr>
<tr><td><code id="glmmML_+3A_weights">weights</code></td>
<td>
<p>Case weights. Defaults to one.</p>
</td></tr>
<tr><td><code id="glmmML_+3A_cluster.weights">cluster.weights</code></td>
<td>
<p>Cluster weights. Defaults to one.</p>
</td></tr>
<tr><td><code id="glmmML_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="glmmML_+3A_na.action">na.action</code></td>
<td>
<p>See glm.</p>
</td></tr>
<tr><td><code id="glmmML_+3A_start.coef">start.coef</code></td>
<td>
<p>starting values for the parameters in the linear predictor.
Defaults to zero.</p>
</td></tr>
<tr><td><code id="glmmML_+3A_start.sigma">start.sigma</code></td>
<td>
<p>starting value for the mixing standard
deviation. Defaults to 0.5.</p>
</td></tr>
<tr><td><code id="glmmML_+3A_fix.sigma">fix.sigma</code></td>
<td>
<p>Should sigma be fixed at start.sigma?</p>
</td></tr>
<tr><td><code id="glmmML_+3A_x">x</code></td>
<td>
<p>If TRUE, the design matrix is returned (as x).</p>
</td></tr>
<tr><td><code id="glmmML_+3A_offset">offset</code></td>
<td>
<p>this can be used to specify an a priori known component to be
included in the linear predictor during fitting.</p>
</td></tr>
<tr><td><code id="glmmML_+3A_contrasts">contrasts</code></td>
<td>
<p>an optional list. See the 'contrasts.arg' of 'model.matrix.default'.</p>
</td></tr>
<tr><td><code id="glmmML_+3A_prior">prior</code></td>
<td>
<p>Which &quot;prior&quot; distribution (for the random effects)?
Possible choices are &quot;gaussian&quot; (default), &quot;logistic&quot;, and &quot;cauchy&quot;.</p>
</td></tr> 
<tr><td><code id="glmmML_+3A_control">control</code></td>
<td>
<p>Controls the convergence criteria. See
<code><a href="stats.html#topic+glm.control">glm.control</a></code> for details.</p>
</td></tr>
<tr><td><code id="glmmML_+3A_method">method</code></td>
<td>
<p>There are two choices &quot;Laplace&quot; (default) and &quot;ghq&quot;
(Gauss-Hermite). </p>
</td></tr>
<tr><td><code id="glmmML_+3A_n.points">n.points</code></td>
<td>
<p>Number of points in the Gauss-Hermite quadrature. If
n.points == 1, the Gauss-Hermite is the same as Laplace
approximation. If <code>method</code> is set to &quot;Laplace&quot;, this parameter
is ignored.</p>
</td></tr>
<tr><td><code id="glmmML_+3A_boot">boot</code></td>
<td>
<p>Do you want a bootstrap estimate of cluster effect? The default
is <em>No</em> (<code>boot = 0</code>). If you want to say yes, enter a
positive integer here. It should be equal to the number of bootstrap
samples you want to draw. A recomended absolute <em>minimum value</em> is
<code>boot = 2000</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The integrals in the log likelihood function are evaluated by the
Laplace approximation (default) or Gauss-Hermite quadrature. The latter
is now fully adaptive; however, only approximate estimates of variances
are available for the Gauss-Hermite (n.points &gt; 1) method.
</p>
<p>For the binomial families, the response can be a two-column matrix, see
the help page for glm for details.</p>


<h3>Value</h3>

<p>The return value is a list, an object of class 'glmmML'. The components are:
</p>
<table>
<tr><td><code>boot</code></td>
<td>
<p>No. of boot replicates</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>Logical</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>Estimated regression coefficients</p>
</td></tr>
<tr><td><code>coef.sd</code></td>
<td>
<p>Their standard errors</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>The estimated random effects' standard deviation</p>
</td></tr>
<tr><td><code>sigma.sd</code></td>
<td>
<p>Its standard error</p>
</td></tr>
<tr><td><code>variance</code></td>
<td>
<p>The estimated variance-covariance matrix. The last
column/row corresponds to the standard
deviation of the random effects (<code>sigma</code>)</p>
</td></tr> 
<tr><td><code>aic</code></td>
<td>
<p>AIC</p>
</td></tr>
<tr><td><code>bootP</code></td>
<td>
<p>Bootstrap p value from testing the null hypothesis of no
random effect (sigma = 0)</p>
</td></tr> 
<tr><td><code>deviance</code></td>
<td>
<p>Deviance</p>
</td></tr>
<tr><td><code>mixed</code></td>
<td>
<p>Logical</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>Degrees of freedom</p>
</td></tr>
<tr><td><code>cluster.null.deviance</code></td>
<td>
<p>Deviance from a glm with no
clustering. Subtracting <code>deviance</code> gives a test statistic for
the null hypothesis of no clustering. Its asymptotic distribution is
a symmetric mixture a constant at zero and a chi-squared distribution
with one df. The printed p-value is based on this.</p>
</td></tr>
<tr><td><code>cluster.null.df</code></td>
<td>
<p>Its degrees of freedom</p>
</td></tr>
<tr><td><code>posterior.modes</code></td>
<td>
<p>Estimated posterior modes of the random effects</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>The terms object</p>
</td></tr>
<tr><td><code>info</code></td>
<td>
<p>From hessian inversion. Should be 0. If not, no variances
could be estimated. You could try fixing sigma at the estimated
value and rerun.</p>
</td></tr>
<tr><td><code>prior</code></td>
<td>
<p>Which prior was used?</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The function call</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>The design matrix if asked for, otherwise not present</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The optimization may not converge with
the default value of <code>start.sigma</code>. In that case, try different
start values for sigma. If still no convergence, consider the
possibility to fix the value of sigma at several values and study the
profile likelihood.</p>


<h3>Author(s)</h3>

<p>G\&quot;oran Brostr\&quot;om</p>


<h3>References</h3>

<p>Brostr\&quot;om, G. and Holmberg, H. (2011). Generalized linear models with
clustered data: Fixed and random effects models. Computational
Statistics and Data Analysis 55:3123-3134.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+glmmboot">glmmboot</a></code>, <code><a href="stats.html#topic+glm">glm</a></code>, <code><a href="stats.html#topic+optim">optim</a></code>,
<code><a href="lme4.html#topic+lmer">lmer</a></code> in <code>Matrix</code>and
<code><a href="MASS.html#topic+glmmPQL">glmmPQL</a></code> in <code>MASS</code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>id &lt;- factor(rep(1:20, rep(5, 20)))
y &lt;- rbinom(100, prob = rep(runif(20), rep(5, 20)), size = 1)
x &lt;- rnorm(100)
dat &lt;- data.frame(y = y, x = x, id = id)
glmmML(y ~ x, data = dat, cluster = id)
</code></pre>

<hr>
<h2 id='glmmML.fit'>Generalized Linear Model with random intercept</h2><span id='topic+glmmML.fit'></span>

<h3>Description</h3>

<p>This function is called by <code>glmmML</code>, but it can also be called
directly by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glmmML.fit(X, Y, weights = rep(1, NROW(Y)), cluster.weights = rep(1, NROW(Y)),
start.coef = NULL, start.sigma = NULL,
fix.sigma = FALSE,
cluster = NULL, offset = rep(0, nobs), family = binomial(),
method = 1, n.points = 1,
control = list(epsilon = 1.e-8, maxit = 200, trace = FALSE),
intercept = TRUE, boot = 0, prior = 0) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glmmML.fit_+3A_x">X</code></td>
<td>
<p>Design matrix of covariates.</p>
</td></tr>
<tr><td><code id="glmmML.fit_+3A_y">Y</code></td>
<td>
<p>Response vector. Or two-column matrix.</p>
</td></tr>
<tr><td><code id="glmmML.fit_+3A_weights">weights</code></td>
<td>
<p>Case weights. Defaults to one.</p>
</td></tr>
<tr><td><code id="glmmML.fit_+3A_cluster.weights">cluster.weights</code></td>
<td>
<p>Cluster weights. Defaults to one.</p>
</td></tr>
<tr><td><code id="glmmML.fit_+3A_start.coef">start.coef</code></td>
<td>
<p>Starting values for the coefficients. </p>
</td></tr>
<tr><td><code id="glmmML.fit_+3A_start.sigma">start.sigma</code></td>
<td>
<p>Starting value for the mixing standard deviation.</p>
</td></tr>
<tr><td><code id="glmmML.fit_+3A_fix.sigma">fix.sigma</code></td>
<td>
<p>Should sigma be fixed at start.sigma?</p>
</td></tr>
<tr><td><code id="glmmML.fit_+3A_cluster">cluster</code></td>
<td>
<p>The clustering variable.</p>
</td></tr>
<tr><td><code id="glmmML.fit_+3A_offset">offset</code></td>
<td>
<p>The offset in the model.</p>
</td></tr>
<tr><td><code id="glmmML.fit_+3A_family">family</code></td>
<td>
<p>Family of distributions. Defaults to binomial with logit
link. Other possibilities are binomial with cloglog link and poisson
with log link.</p>
</td></tr>
<tr><td><code id="glmmML.fit_+3A_method">method</code></td>
<td>
<p>Laplace (1) or Gauss-hermite (0)?</p>
</td></tr>
<tr><td><code id="glmmML.fit_+3A_n.points">n.points</code></td>
<td>
<p>Number of points in the Gauss-Hermite
quadrature. Default is <code>n.points = 1</code>, which is equivalent to
Laplace approximation.</p>
</td></tr>
<tr><td><code id="glmmML.fit_+3A_control">control</code></td>
<td>
<p>Control of the iterations. See <code><a href="stats.html#topic+glm.control">glm.control</a></code>.</p>
</td></tr>
<tr><td><code id="glmmML.fit_+3A_intercept">intercept</code></td>
<td>
<p>Logical. If TRUE, an intercept is fitted.</p>
</td></tr>
<tr><td><code id="glmmML.fit_+3A_boot">boot</code></td>
<td>
<p>Integer. If &gt; 0, bootstrapping with <code>boot</code>
replicates.</p>
</td></tr>
<tr><td><code id="glmmML.fit_+3A_prior">prior</code></td>
<td>
<p>Which prior distribution? 0 for &quot;gaussian&quot;, 1 for
&quot;logistic&quot;, 2 for &quot;cauchy&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the optimisation, &quot;vmmin&quot; (in C code) is used.
</p>


<h3>Value</h3>

<p>A list. For details, see the code, and <code>glmmML</code>.
</p>


<h3>Author(s)</h3>

<p>Göran Broström</p>


<h3>References</h3>

<p>Broström (2003)</p>


<h3>See Also</h3>

<p><code><a href="#topic+glmmML">glmmML</a></code>, <code><a href="MASS.html#topic+glmmPQL">glmmPQL</a></code>, and
<code><a href="lme4.html#topic+lmer">lmer</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- cbind(rep(1, 14), rnorm(14))
y &lt;- rbinom(14, prob = 0.5, size = 1)
id &lt;- rep(1:7, 2)

glmmML.fit(x, y, cluster = id)


</code></pre>

<hr>
<h2 id='print.glmmboot'>Prints a 'glmmML' object.</h2><span id='topic+print.glmmboot'></span>

<h3>Description</h3>

<p>A glmmboot object is the output of <code>glmmboot</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glmmboot'
print(x, digits = max(3, getOption("digits") - 3), na.print = "", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.glmmboot_+3A_x">x</code></td>
<td>
<p>The glmmboot object</p>
</td></tr>
<tr><td><code id="print.glmmboot_+3A_digits">digits</code></td>
<td>
<p>Number of printed digits.</p>
</td></tr>
<tr><td><code id="print.glmmboot_+3A_na.print">na.print</code></td>
<td>
<p>How to print NAs</p>
</td></tr>
<tr><td><code id="print.glmmboot_+3A_...">...</code></td>
<td>
<p>Additional parameters, which are ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Nothing in particular.
</p>


<h3>Value</h3>

<p>A short summary of the object is printed.
</p>


<h3>Note</h3>

<p>This is the only summary method available for the moment.</p>


<h3>Author(s)</h3>

<p>Göran Broström</p>


<h3>See Also</h3>

<p><code><a href="#topic+glmmboot">glmmboot</a></code></p>

<hr>
<h2 id='print.glmmML'>Prints a 'glmmML' object.</h2><span id='topic+print.glmmML'></span>

<h3>Description</h3>

<p>A glmmML object is the output of <code>glmmML</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glmmML'
print(x, digits = max(3, getOption("digits") - 3), na.print = "", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.glmmML_+3A_x">x</code></td>
<td>
<p>The glmmML object</p>
</td></tr>
<tr><td><code id="print.glmmML_+3A_digits">digits</code></td>
<td>
<p>Number of printed digits.</p>
</td></tr>
<tr><td><code id="print.glmmML_+3A_na.print">na.print</code></td>
<td>
<p>How to print NAs</p>
</td></tr>
<tr><td><code id="print.glmmML_+3A_...">...</code></td>
<td>
<p>Additional parameters, which are ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Nothing in particular.
</p>


<h3>Value</h3>

<p>A short summary of the object is printed.
</p>


<h3>Note</h3>

<p>This is the only summary method available for the moment.</p>


<h3>Author(s)</h3>

<p>Göran Broström</p>


<h3>See Also</h3>

<p><code><a href="#topic+glmmML">glmmML</a></code></p>

<hr>
<h2 id='summary.glmmboot'>Summary of a glmmboot object</h2><span id='topic+summary.glmmboot'></span>

<h3>Description</h3>

<p>It simply calls <code>print.glmmboot</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glmmboot'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.glmmboot_+3A_object">object</code></td>
<td>
<p>A glmmboot object</p>
</td></tr>
<tr><td><code id="summary.glmmboot_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A summary method will be written soon.
</p>


<h3>Value</h3>

<p>Nothing is returned.
</p>


<h3>Note</h3>

<p>Preliminary</p>


<h3>Author(s)</h3>

<p>Göran Broström</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.glmmboot">print.glmmboot</a></code></p>

<hr>
<h2 id='summary.glmmML'>Summary of a glmmML object</h2><span id='topic+summary.glmmML'></span>

<h3>Description</h3>

<p>It simply calls <code>print.glmmML</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glmmML'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.glmmML_+3A_object">object</code></td>
<td>
<p>A glmmML object</p>
</td></tr>
<tr><td><code id="summary.glmmML_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nothing is returned.
</p>


<h3>Note</h3>

<p>Preliminary</p>


<h3>Author(s)</h3>

<p>Göran Broström</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.glmmML">print.glmmML</a></code></p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
