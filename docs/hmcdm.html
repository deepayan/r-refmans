<!DOCTYPE html><html><head><title>Help for package hmcdm</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {hmcdm}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Design_array'><p>Design array</p></a></li>
<li><a href='#ETAmat'><p>Generate ideal response matrix</p></a></li>
<li><a href='#hmcdm'><p>Gibbs sampler for learning models</p></a></li>
<li><a href='#hmcdm-package'><p>hmcdm: Hidden Markov Cognitive Diagnosis Models for Learning</p></a></li>
<li><a href='#inv_bijectionvector'><p>Convert integer to attribute pattern</p></a></li>
<li><a href='#L_real_array'><p>Observed response times array</p></a></li>
<li><a href='#OddsRatio'><p>Compute item pairwise odds ratio</p></a></li>
<li><a href='#pp_check.hmcdm'><p>Graphical posterior predictive checks for hidden Markov cognitive diagnosis model</p></a></li>
<li><a href='#print.summary.hmcdm'><p>Summarizing Hidden Markov Cognitive Diagnosis Model Fits</p></a></li>
<li><a href='#Q_list_g'><p>Generate a list of Q-matrices for each examinee.</p></a></li>
<li><a href='#Q_matrix'><p>Q-matrix</p></a></li>
<li><a href='#random_Q'><p>Generate random Q matrix</p></a></li>
<li><a href='#rOmega'><p>Generate a random transition matrix for the first order hidden Markov model</p></a></li>
<li><a href='#sim_alphas'><p>Generate attribute trajectories under the specified hidden Markov models</p></a></li>
<li><a href='#sim_hmcdm'><p>Simulate responses from the specified model (entire cube)</p></a></li>
<li><a href='#sim_RT'><p>Simulate item response times based on Wang et al.'s (2018) joint model of response times and accuracy in learning</p></a></li>
<li><a href='#Test_order'><p>Test block ordering of each test version</p></a></li>
<li><a href='#Test_versions'><p>Subjects' test version</p></a></li>
<li><a href='#TPmat'><p>Generate monotonicity matrix</p></a></li>
<li><a href='#Y_real_array'><p>Observed response accuracy array</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Hidden Markov Cognitive Diagnosis Models for Learning</td>
</tr>
<tr>
<td>Version:</td>
<td>2.1.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Fitting hidden Markov models of learning under the cognitive diagnosis framework.
  The estimation of the hidden Markov diagnostic classification model,
  the first order hidden Markov model, the reduced-reparameterized unified learning model,
  and the joint learning model for responses and response times.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/tmsalab/hmcdm">https://github.com/tmsalab/hmcdm</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/tmsalab/hmcdm/issues">https://github.com/tmsalab/hmcdm/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.0), stats (&ge; 3.0.0), bayesplot (&ge; 1.9.0),
rstantools (&ge; 1.0.0)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo, progress</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-03-20 00:43:14 UTC; sunbeomkwon</td>
</tr>
<tr>
<td>Author:</td>
<td>Susu Zhang [aut],
  Shiyu Wang [aut],
  Yinghan Chen [aut],
  Sunbeom Kwon [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Sunbeom Kwon &lt;sunbeom2@illinois.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-03-20 01:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='Design_array'>Design array</h2><span id='topic+Design_array'></span>

<h3>Description</h3>

<p><code>Design_array</code> contains item administration information at all time points in the Spatial
Rotation Learning Program.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Design_array
</code></pre>


<h3>Format</h3>

<p>An array of dimension N-by-J-by-L, containing each subject's item administration.
</p>


<h3>Details</h3>

<p>The data object <code>"Design_array"</code> contains an array of dimension N-by-J-by-L
indicating the items assigned (1/0) to each subject at each time point.
</p>


<h3>Author(s)</h3>

<p>Shiyu Wang, Yan Yang, Jeff Douglas, and Steve Culpepper
</p>


<h3>Source</h3>

<p>Spatial Rotation Learning Experiment at UIUC between Fall 2015 and Spring 2016.
</p>

<hr>
<h2 id='ETAmat'>Generate ideal response matrix</h2><span id='topic+ETAmat'></span>

<h3>Description</h3>

<p>Based on the Q matrix and the latent attribute space, generate the ideal response matrix for each skill pattern
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ETAmat(K, J, Q)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ETAmat_+3A_k">K</code></td>
<td>
<p>An <code>int</code> of the number of attributes</p>
</td></tr>
<tr><td><code id="ETAmat_+3A_j">J</code></td>
<td>
<p>An <code>int</code> of the number of items</p>
</td></tr>
<tr><td><code id="ETAmat_+3A_q">Q</code></td>
<td>
<p>A J-by-K Q <code>matrix</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A J-by-2^K ideal response <code>matrix</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Q = random_Q(15,4)
ETA = ETAmat(4,15,Q)
</code></pre>

<hr>
<h2 id='hmcdm'>Gibbs sampler for learning models</h2><span id='topic+hmcdm'></span>

<h3>Description</h3>

<p>Runs MCMC to estimate parameters of any of the listed learning models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hmcdm(
  Response,
  Q_matrix,
  model,
  Design_array = NULL,
  Test_order = NULL,
  Test_versions = NULL,
  chain_length = 100L,
  burn_in = 50L,
  G_version = NA_integer_,
  theta_propose = 0,
  Latency_array = NULL,
  deltas_propose = NULL,
  R = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hmcdm_+3A_response">Response</code></td>
<td>
<p>An <code>array</code> of dichotomous item responses. t-th slice is an N-by-J matrix of responses at time t.</p>
</td></tr>
<tr><td><code id="hmcdm_+3A_q_matrix">Q_matrix</code></td>
<td>
<p>A J-by-K Q-matrix.</p>
</td></tr>
<tr><td><code id="hmcdm_+3A_model">model</code></td>
<td>
<p>A <code>charactor</code> of the type of model fitted with the MCMC sampler, possible selections are
&quot;DINA_HO&quot;: Higher-Order Hidden Markov Diagnostic Classification Model with DINA responses;
&quot;DINA_HO_RT_joint&quot;: Higher-Order Hidden Markov DCM with DINA responses, log-Normal response times, and joint modeling of latent
speed and learning ability;
&quot;DINA_HO_RT_sep&quot;: Higher-Order Hidden Markov DCM with DINA responses, log-Normal response times, and separate modeling of latent
speed and learning ability;
&quot;rRUM_indept&quot;: Simple independent transition probability model with rRUM responses
&quot;NIDA_indept&quot;: Simple independent transition probability model with NIDA responses
&quot;DINA_FOHM&quot;: First Order Hidden Markov model with DINA responses</p>
</td></tr>
<tr><td><code id="hmcdm_+3A_design_array">Design_array</code></td>
<td>
<p>An <code>array</code> of dimension N-by-J-by-L indicating the items assigned (1/0) to each subject at each time point.
Either 'Design_array' or both 'Test_order' &amp; 'Test_versions' need to be provided to run HMCDM.</p>
</td></tr>
<tr><td><code id="hmcdm_+3A_test_order">Test_order</code></td>
<td>
<p>Optional. A <code>matrix</code> of the order of item blocks for each test version.</p>
</td></tr>
<tr><td><code id="hmcdm_+3A_test_versions">Test_versions</code></td>
<td>
<p>Optional. A <code>vector</code> of the test version of each learner.</p>
</td></tr>
<tr><td><code id="hmcdm_+3A_chain_length">chain_length</code></td>
<td>
<p>An <code>int</code> of the MCMC chain length.</p>
</td></tr>
<tr><td><code id="hmcdm_+3A_burn_in">burn_in</code></td>
<td>
<p>An <code>int</code> of the MCMC burn-in chain length.</p>
</td></tr>
<tr><td><code id="hmcdm_+3A_g_version">G_version</code></td>
<td>
<p>Optional. An <code>int</code> of the type of covariate for increased fluency (1: G is dichotomous depending on whether all skills required for
current item are mastered; 2: G cumulates practice effect on previous items using mastered skills; 3: G is a time block effect invariant across
subjects with different attribute trajectories)</p>
</td></tr>
<tr><td><code id="hmcdm_+3A_theta_propose">theta_propose</code></td>
<td>
<p>Optional. A <code>scalar</code> for the standard deviation of theta's proposal distribution in the MH sampling step.</p>
</td></tr>
<tr><td><code id="hmcdm_+3A_latency_array">Latency_array</code></td>
<td>
<p>Optional. A <code>array</code> of the response times. t-th slice is an N-by-J matrix of response times at time t.</p>
</td></tr>
<tr><td><code id="hmcdm_+3A_deltas_propose">deltas_propose</code></td>
<td>
<p>Optional. A <code>vector</code> for the band widths of each lambda's proposal distribution in the MH sampling step.</p>
</td></tr>
<tr><td><code id="hmcdm_+3A_r">R</code></td>
<td>
<p>Optional. A reachability <code>matrix</code> for the hierarchical relationship between attributes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> of parameter samples and Metropolis-Hastings acceptance rates (if applicable).
</p>


<h3>Author(s)</h3>

<p>Susu Zhang
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
output_FOHM = hmcdm(Y_real_array, Q_matrix, "DINA_FOHM", Design_array, 100, 30)

</code></pre>

<hr>
<h2 id='hmcdm-package'>hmcdm: Hidden Markov Cognitive Diagnosis Models for Learning</h2><span id='topic+hmcdm-package'></span><span id='topic+_PACKAGE'></span>

<h3>Description</h3>

<p>Fitting hidden Markov models of learning under the cognitive diagnosis framework. The estimation of the hidden Markov diagnostic classification model, the first order hidden Markov model, the reduced-reparameterized unified learning model, and the joint learning model for responses and response times.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Sunbeom Kwon <a href="mailto:sunbeom2@illinois.edu">sunbeom2@illinois.edu</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Susu Zhang <a href="mailto:szhan105@illinois.edu">szhan105@illinois.edu</a>
</p>
</li>
<li><p> Shiyu Wang <a href="mailto:swang44@uga.edu">swang44@uga.edu</a>
</p>
</li>
<li><p> Yinghan Chen <a href="mailto:yinghanc@unr.edu">yinghanc@unr.edu</a>
</p>
</li></ul>



<h3>References</h3>

<p>Wang, S., Yang, Y., Culpepper, S. A., &amp; Douglas, J. A. (2018) <a href="https://doi.org/10.3102/1076998617719727">doi:10.3102/1076998617719727</a> &quot;Tracking Skill Acquisition With Cognitive Diagnosis Models: A Higher-Order, Hidden Markov Model With Covariates.&quot;
</p>
<p>Chen, Y., Culpepper, S. A., Wang, S., &amp; Douglas, J. (2018) <a href="https://doi.org/10.1177/0146621617721250">doi:10.1177/0146621617721250</a> &quot;A hidden Markov model for learning trajectories in cognitive diagnosis with application to spatial rotation skills.&quot;
</p>
<p>Wang, S., Zhang, S., Douglas, J., &amp; Culpepper, S. (2018) <a href="https://doi.org/10.1080/15366367.2018.1435105">doi:10.1080/15366367.2018.1435105</a> &quot;Using Response Times to Assess Learning Progress: A Joint Model for Responses and Response Times.&quot;
</p>
<p>Zhang, S., Douglas, J. A., Wang, S. &amp; Culpepper, S. A. (2019) <a href="https://doi.org/10.1007/978-3-030-05584-4_24">doi:10.1007/978-3-030-05584-4_24</a> &quot;Reduced Reparameterized Unified Model Applied to Learning Spatial Rotation Skills.&quot;
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/tmsalab/hmcdm">https://github.com/tmsalab/hmcdm</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/tmsalab/hmcdm/issues">https://github.com/tmsalab/hmcdm/issues</a>
</p>
</li></ul>


<hr>
<h2 id='inv_bijectionvector'>Convert integer to attribute pattern</h2><span id='topic+inv_bijectionvector'></span>

<h3>Description</h3>

<p>Based on the bijective relationship between natural numbers and sum of powers of two,
convert integer between 0 and 2^K-1 to K-dimensional attribute pattern.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inv_bijectionvector(K, CL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="inv_bijectionvector_+3A_k">K</code></td>
<td>
<p>An <code>int</code> for the number of attributes</p>
</td></tr>
<tr><td><code id="inv_bijectionvector_+3A_cl">CL</code></td>
<td>
<p>An <code>int</code> between 0 and 2^K-1</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>vec</code> of the K-dimensional attribute pattern corresponding to CL.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>inv_bijectionvector(4,0)
</code></pre>

<hr>
<h2 id='L_real_array'>Observed response times array</h2><span id='topic+L_real_array'></span>

<h3>Description</h3>

<p><code>L_real_array</code> contains the observed latencies of responses of all subjects to all questions in the Spatial Rotation
Learning Program.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>L_real_array
</code></pre>


<h3>Format</h3>

<p>An array of dimensions N-by-J-by-L. Each slice of the array is an N-by-J matrix, containing the
subjects' response times in seconds to each item at time point l.
</p>


<h3>Author(s)</h3>

<p>Shiyu Wang, Yan Yang, Jeff Douglas, and Steve Culpepper
</p>


<h3>Source</h3>

<p>Spatial Rotation Learning Experiment at UIUC between Fall 2015 and Spring 2016.
</p>

<hr>
<h2 id='OddsRatio'>Compute item pairwise odds ratio</h2><span id='topic+OddsRatio'></span>

<h3>Description</h3>

<p>Based on a response matrix, calculate the item pairwise odds-ratio according do (n11<em>n00)/(n10</em>n01), where nij is the
number of people answering both item i and item j correctly
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OddsRatio(N, J, Yt)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OddsRatio_+3A_n">N</code></td>
<td>
<p>An <code>int</code> of the sample size</p>
</td></tr>
<tr><td><code id="OddsRatio_+3A_j">J</code></td>
<td>
<p>An <code>int</code> of the number of items</p>
</td></tr>
<tr><td><code id="OddsRatio_+3A_yt">Yt</code></td>
<td>
<p>An N-by-J response <code>matrix</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A J-by-J upper-triangular <code>matrix</code> of the item pairwise odds ratios
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
N = dim(Y_real_array)[1]
J = nrow(Q_matrix)
OddsRatio(N,J,Y_real_array[,,1])
</code></pre>

<hr>
<h2 id='pp_check.hmcdm'>Graphical posterior predictive checks for hidden Markov cognitive diagnosis model</h2><span id='topic+pp_check.hmcdm'></span>

<h3>Description</h3>

<p><code>pp_check</code> method for class <code>hmcdm</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hmcdm'
pp_check(object, plotfun = "dens_overlay", type = "total_score", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pp_check.hmcdm_+3A_object">object</code></td>
<td>
<p>a fitted model object of class &quot;<code>hmcdm</code>&quot;.</p>
</td></tr>
<tr><td><code id="pp_check.hmcdm_+3A_plotfun">plotfun</code></td>
<td>
<p>A character string naming the type of plot. The list of available
plot functions include <code>"dens_overlay"</code>, <code>"hist"</code>, <code>"stat_2d"</code>, <code>"scatter_avg"</code>, <code>"error_scatter_avg"</code>.
The default function is <code>"dens_overlay"</code>.</p>
</td></tr>
<tr><td><code id="pp_check.hmcdm_+3A_type">type</code></td>
<td>
<p>A character string naming the statistic to be used for obtaining posterior predictive distribution plot.
The list of available types include <code>"total_score"</code>, <code>"item_mean"</code>, <code>"item_OR"</code>, <code>"latency_mean"</code>, and <code>"latency_total"</code>. The default type is <code>"total_score"</code> which examines total scores of subjects.
Type <code>"item_mean"</code> is related to the first order moment and examines mean scores of all the items included in the test.
Type <code>"item_OR"</code> is related to the second order moment and examines odds ratios of all item pairs.
Types <code>"latency_mean"</code> and <code>"total_latency"</code> are available only for <code>hmcdm</code> objects that include item response time information (i.e., <code>hmcdm</code> object fitted with &quot;<code>DINA_HO_RT</code>&quot; model).</p>
</td></tr>
<tr><td><code id="pp_check.hmcdm_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Plots for checking the posterior predictive distributions. The default <code>Plotfun</code> <code>"dens_overlay"</code> plots density of each dataset are overlaid with the distribution of the observed values.
</p>


<h3>References</h3>

<p>Zhang, S., Douglas, J. A., Wang, S. &amp; Culpepper, S. A. (2019) &lt;<a href="https://doi.org/10.1007/978-3-030-05584-4_24">doi:10.1007/978-3-030-05584-4_24</a>&gt;
</p>


<h3>See Also</h3>

<p><code><a href="bayesplot.html#topic+PPC-distributions">bayesplot::ppc_dens_overlay()</a></code>
<code><a href="bayesplot.html#topic+PPC-test-statistics">bayesplot::ppc_stat()</a></code>
<code><a href="bayesplot.html#topic+PPC-test-statistics">bayesplot::ppc_stat_2d()</a></code>
<code><a href="bayesplot.html#topic+PPC-scatterplots">bayesplot::ppc_scatter_avg()</a></code>
<code><a href="bayesplot.html#topic+PPC-errors">bayesplot::ppc_error_scatter_avg()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
output_FOHM = hmcdm(Y_real_array,Q_matrix,"DINA_FOHM",Design_array,1000,500)
library(bayesplot)
pp_check(output_FOHM)
pp_check(output_FOHM, plotfun="hist", type="item_mean")

</code></pre>

<hr>
<h2 id='print.summary.hmcdm'>Summarizing Hidden Markov Cognitive Diagnosis Model Fits</h2><span id='topic+print.summary.hmcdm'></span><span id='topic+summary.hmcdm'></span>

<h3>Description</h3>

<p><code>summary</code> method for class &quot;<code>hmcdm</code>&quot; or &quot;<code>summary.hmcdm</code>&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.hmcdm'
print(x, ...)

## S3 method for class 'hmcdm'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.hmcdm_+3A_x">x</code></td>
<td>
<p>an object of class &quot;<code>hmcdm.summary</code>&quot;.</p>
</td></tr>
<tr><td><code id="print.summary.hmcdm_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="print.summary.hmcdm_+3A_object">object</code></td>
<td>
<p>a fitted model object of class &quot;<code>hmcdm</code>&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function <code>summary.hmcdm</code> computes and returns a <code>list</code> of point estimates of model parameters and model fit measures including DIC and PPP-values.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hmcdm">hmcdm()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
output_FOHM = hmcdm(Y_real_array,Q_matrix,"DINA_FOHM",Design_array,1000,500)
summary(output_FOHM)

</code></pre>

<hr>
<h2 id='Q_list_g'>Generate a list of Q-matrices for each examinee.</h2><span id='topic+Q_list_g'></span>

<h3>Description</h3>

<p>Generate a list of length N. Each element of the list is a JxK Q_matrix of all items
administered across all time points to the examinee, in the order of administration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Q_list_g(Q_matrix, Design_array)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Q_list_g_+3A_q_matrix">Q_matrix</code></td>
<td>
<p>A J-by-K matrix, indicating the item-skill relationship.</p>
</td></tr>
<tr><td><code id="Q_list_g_+3A_design_array">Design_array</code></td>
<td>
<p>An N-by-J-by-L array indicating whether examinee n has taken item j at l time point.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list length of N. Each element of the list is a JxK Q_matrix for each examinee.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
Q_examinee = Q_list_g(Q_matrix, Design_array)
</code></pre>

<hr>
<h2 id='Q_matrix'>Q-matrix</h2><span id='topic+Q_matrix'></span>

<h3>Description</h3>

<p><code>Q_matrix</code> contains the Q matrix of the items in the Spatial Rotation Learning Program.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Q_matrix
</code></pre>


<h3>Format</h3>

<p>A J-by-K matrix, indicating the item-skill relationship.
</p>


<h3>Author(s)</h3>

<p>Shiyu Wang, Yan Yang, Jeff Douglas, and Steve Culpepper
</p>


<h3>Source</h3>

<p>Spatial Rotation Learning Experiment at UIUC between Fall 2015 and Spring 2016.
</p>

<hr>
<h2 id='random_Q'>Generate random Q matrix</h2><span id='topic+random_Q'></span>

<h3>Description</h3>

<p>Creates a random Q matrix containing three identity matrices after row permutation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>random_Q(J, K)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="random_Q_+3A_j">J</code></td>
<td>
<p>An <code>int</code> that represents the number of items</p>
</td></tr>
<tr><td><code id="random_Q_+3A_k">K</code></td>
<td>
<p>An <code>int</code> that represents the number of attributes/skills</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dichotomous <code>matrix</code> for Q.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>random_Q(15,4)
</code></pre>

<hr>
<h2 id='rOmega'>Generate a random transition matrix for the first order hidden Markov model</h2><span id='topic+rOmega'></span>

<h3>Description</h3>

<p>Generate a random transition matrix under nondecreasing learning trajectory assumption
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rOmega(TP)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rOmega_+3A_tp">TP</code></td>
<td>
<p>A 2^K-by-2^K dichotomous matrix of indicating possible transitions under the monotonicity assumption, created with
the TPmat function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A 2^K-by-2^K transition matrix, the (i,j)th element indicating the transition probability of transitioning from i-th class to j-th class.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>K = ncol(Q_matrix)
TP = TPmat(K)
Omega_sim = rOmega(TP)
</code></pre>

<hr>
<h2 id='sim_alphas'>Generate attribute trajectories under the specified hidden Markov models</h2><span id='topic+sim_alphas'></span>

<h3>Description</h3>

<p>Based on the learning model parameters, create cube of attribute patterns
of all subjects across time.
Currently available learning models are Higher-order hidden Markov DCM('HO_sep'),
Higher-order hidden Markov DCM with learning ability as a random effect('HO_joint'),
the simple independent-attribute learning model('indept'),
and the first order hidden Markov model('FOHM').
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_alphas(
  model,
  lambdas = NULL,
  thetas = NULL,
  Q_matrix = NULL,
  Design_array = NULL,
  taus = NULL,
  Omega = NULL,
  N = NA_integer_,
  L = NA_integer_,
  R = NULL,
  alpha0 = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim_alphas_+3A_model">model</code></td>
<td>
<p>The learning model under which the attribute trajectories are generated. Available options are: 'HO_joint', 'HO_sep', 'indept', 'FOHM'.</p>
</td></tr>
<tr><td><code id="sim_alphas_+3A_lambdas">lambdas</code></td>
<td>
<p>A <code>vector</code> of transition model coefficients. With 'HO_sep' model specification, <code>lambdas</code> should be a length 4 <code>vector</code>. First entry is intercept of the logistic transition
model, second entry is the slope of general learning ability, third entry is the slope for number of other mastered skills,
fourth entry is the slope for amount of practice.
With 'HO_joint' model specification, <code>lambdas</code> should be a length 3 <code>vector</code>. First entry is intercept of the logistic transition
model, second entry is the slope for number of other mastered skills, third entry is the slope for amount of practice.</p>
</td></tr>
<tr><td><code id="sim_alphas_+3A_thetas">thetas</code></td>
<td>
<p>A length N <code>vector</code> of learning abilities of each subject.</p>
</td></tr>
<tr><td><code id="sim_alphas_+3A_q_matrix">Q_matrix</code></td>
<td>
<p>A J-by-K Q-matrix</p>
</td></tr>
<tr><td><code id="sim_alphas_+3A_design_array">Design_array</code></td>
<td>
<p>A N-by-J-by-L array indicating items administered to examinee n at time point l.</p>
</td></tr>
<tr><td><code id="sim_alphas_+3A_taus">taus</code></td>
<td>
<p>A length K <code>vector</code> of transition probabilities from 0 to 1 on each skill</p>
</td></tr>
<tr><td><code id="sim_alphas_+3A_omega">Omega</code></td>
<td>
<p>A 2^K-by-2^K <code>matrix</code> of transition probabilities from row pattern to column pattern</p>
</td></tr>
<tr><td><code id="sim_alphas_+3A_n">N</code></td>
<td>
<p>An <code>int</code> of number of examinees.</p>
</td></tr>
<tr><td><code id="sim_alphas_+3A_l">L</code></td>
<td>
<p>An <code>int</code> of number of time points.</p>
</td></tr>
<tr><td><code id="sim_alphas_+3A_r">R</code></td>
<td>
<p>A K-by-K dichotomous reachability <code>matrix</code> indicating the attribute hierarchies. The k,k'th entry of R is 1 if k' is prereq to k.</p>
</td></tr>
<tr><td><code id="sim_alphas_+3A_alpha0">alpha0</code></td>
<td>
<p>Optional. An N-by-K <code>matrix</code> of subjects' initial attribute patterns.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An N-by-K-by-L <code>array</code> of attribute patterns of subjects at each time point.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## HO_joint ##
N = nrow(Design_array)
J = nrow(Q_matrix)
K = ncol(Q_matrix)
L = dim(Design_array)[3]
class_0 &lt;- sample(1:2^K, N, replace = TRUE)
Alphas_0 &lt;- matrix(0,N,K)
for(i in 1:N){
  Alphas_0[i,] &lt;- inv_bijectionvector(K,(class_0[i]-1))
}
thetas_true = rnorm(N, 0, 1.8)
lambdas_true &lt;- c(-2, .4, .055)
Alphas &lt;- sim_alphas(model="HO_joint", 
                    lambdas=lambdas_true, 
                    thetas=thetas_true, 
                    Q_matrix=Q_matrix, 
                    Design_array=Design_array)

## HO_sep ##
N = dim(Design_array)[1]
J = nrow(Q_matrix)
K = ncol(Q_matrix)
L = dim(Design_array)[3]
class_0 &lt;- sample(1:2^K, N, replace = L)
Alphas_0 &lt;- matrix(0,N,K)
for(i in 1:N){
  Alphas_0[i,] &lt;- inv_bijectionvector(K,(class_0[i]-1))
}
thetas_true = rnorm(N)
lambdas_true = c(-1, 1.8, .277, .055)
Alphas &lt;- sim_alphas(model="HO_sep", 
                     lambdas=lambdas_true, 
                     thetas=thetas_true, 
                     Q_matrix=Q_matrix, 
                     Design_array=Design_array)

## indept ##
N = dim(Design_array)[1]
K = dim(Q_matrix)[2]
L = dim(Design_array)[3]
tau &lt;- numeric(K)
for(k in 1:K){
  tau[k] &lt;- runif(1,.2,.6)
}
R = matrix(0,K,K)
p_mastery &lt;- c(.5,.5,.4,.4)
Alphas_0 &lt;- matrix(0,N,K)
for(i in 1:N){
  for(k in 1:K){
    prereqs &lt;- which(R[k,]==1)
    if(length(prereqs)==0){
      Alphas_0[i,k] &lt;- rbinom(1,1,p_mastery[k])
    }
    if(length(prereqs)&gt;0){
      Alphas_0[i,k] &lt;- prod(Alphas_0[i,prereqs])*rbinom(1,1,p_mastery)
    }
  }
}
Alphas &lt;- sim_alphas(model="indept", taus=tau, N=N, L=L, R=R)

## FOHM ##
N = dim(Design_array)[1]
K = ncol(Q_matrix)
L = dim(Design_array)[3]
TP &lt;- TPmat(K)
Omega_true &lt;- rOmega(TP)
class_0 &lt;- sample(1:2^K, N, replace = L)
Alphas_0 &lt;- matrix(0,N,K)
for(i in 1:N){
  Alphas_0[i,] &lt;- inv_bijectionvector(K,(class_0[i]-1))
}
Alphas &lt;- sim_alphas(model="FOHM", Omega = Omega_true, N=N, L=L)

</code></pre>

<hr>
<h2 id='sim_hmcdm'>Simulate responses from the specified model (entire cube)</h2><span id='topic+sim_hmcdm'></span>

<h3>Description</h3>

<p>Simulate a cube of responses from the specified model for all persons on items across all time points.
Currently available models are <code>DINA</code>, <code>rRUM</code>, and <code>NIDA</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_hmcdm(
  model,
  alphas,
  Q_matrix,
  Design_array,
  itempars = NULL,
  r_stars = NULL,
  pi_stars = NULL,
  Svec = NULL,
  Gvec = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim_hmcdm_+3A_model">model</code></td>
<td>
<p>The cognitive diagnostic model under which the item responses are generated</p>
</td></tr>
<tr><td><code id="sim_hmcdm_+3A_alphas">alphas</code></td>
<td>
<p>An N-by-K-by-L <code>array</code> of attribute patterns of all persons across L time points</p>
</td></tr>
<tr><td><code id="sim_hmcdm_+3A_q_matrix">Q_matrix</code></td>
<td>
<p>A J-by-K of Q-matrix</p>
</td></tr>
<tr><td><code id="sim_hmcdm_+3A_design_array">Design_array</code></td>
<td>
<p>A N-by-J-by-L array indicating whether item j is administered to examinee i at l time point.</p>
</td></tr>
<tr><td><code id="sim_hmcdm_+3A_itempars">itempars</code></td>
<td>
<p>A J-by-2 <code>mat</code> of item parameters (slipping: 1st col, guessing: 2nd col).</p>
</td></tr>
<tr><td><code id="sim_hmcdm_+3A_r_stars">r_stars</code></td>
<td>
<p>A J-by-K <code>mat</code> of item penalty parameters for missing skills.</p>
</td></tr>
<tr><td><code id="sim_hmcdm_+3A_pi_stars">pi_stars</code></td>
<td>
<p>A length J <code>vector</code> of item correct response probability with all requisite skills.</p>
</td></tr>
<tr><td><code id="sim_hmcdm_+3A_svec">Svec</code></td>
<td>
<p>A length K <code>vector</code> of slipping probability in applying mastered skills</p>
</td></tr>
<tr><td><code id="sim_hmcdm_+3A_gvec">Gvec</code></td>
<td>
<p>A length K <code>vector</code> of guessing probability in applying mastered skills</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <code>array</code> of item responses from the specified model of examinees across all time points.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## DINA ##
N = nrow(Design_array)
J = nrow(Q_matrix)
thetas_true = rnorm(N, 0, 1.8)
lambdas_true &lt;- c(-2, .4, .055)
Alphas &lt;- sim_alphas(model="HO_joint", 
                    lambdas=lambdas_true, 
                    thetas=thetas_true, 
                    Q_matrix=Q_matrix, 
                    Design_array=Design_array)
itempars_true &lt;- matrix(runif(J*2,.1,.2), ncol=2)

Y_sim &lt;- sim_hmcdm(model="DINA",Alphas,Q_matrix,Design_array,
                   itempars=itempars_true)
                   
## rRUM ##
J = nrow(Q_matrix)
K = ncol(Q_matrix)
Smats &lt;- matrix(runif(J*K,.1,.3),c(J,K))
Gmats &lt;- matrix(runif(J*K,.1,.3),c(J,K))
r_stars &lt;- Gmats / (1-Smats)
pi_stars &lt;- apply((1-Smats)^Q_matrix, 1, prod)

Y_sim &lt;- sim_hmcdm(model="rRUM",Alphas,Q_matrix,Design_array,
                   r_stars=r_stars,pi_stars=pi_stars)

## NIDA ##
K = ncol(Q_matrix)
Svec &lt;- runif(K,.1,.3)
Gvec &lt;- runif(K,.1,.3)

Y_sim &lt;- sim_hmcdm(model="NIDA",Alphas,Q_matrix,Design_array,
                   Svec=Svec,Gvec=Gvec)

</code></pre>

<hr>
<h2 id='sim_RT'>Simulate item response times based on Wang et al.'s (2018) joint model of response times and accuracy in learning</h2><span id='topic+sim_RT'></span>

<h3>Description</h3>

<p>Simulate a cube of subjects' response times across time points according to a variant of the logNormal model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_RT(alphas, Q_matrix, Design_array, RT_itempars, taus, phi, G_version)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim_RT_+3A_alphas">alphas</code></td>
<td>
<p>An N-by-K-by-T <code>array</code> of attribute patterns of all persons across T time points</p>
</td></tr>
<tr><td><code id="sim_RT_+3A_q_matrix">Q_matrix</code></td>
<td>
<p>A J-by-K  Q-matrix for the test</p>
</td></tr>
<tr><td><code id="sim_RT_+3A_design_array">Design_array</code></td>
<td>
<p>A N-by-J-by-L array indicating whether item j is administered to examinee i at l time point.</p>
</td></tr>
<tr><td><code id="sim_RT_+3A_rt_itempars">RT_itempars</code></td>
<td>
<p>A J-by-2 <code>matrix</code> of item time discrimination and time intensity parameters</p>
</td></tr>
<tr><td><code id="sim_RT_+3A_taus">taus</code></td>
<td>
<p>A length N <code>vector</code> of latent speed of each person</p>
</td></tr>
<tr><td><code id="sim_RT_+3A_phi">phi</code></td>
<td>
<p>A <code>scalar</code> of slope of increase in fluency over time due to covariates (G)</p>
</td></tr>
<tr><td><code id="sim_RT_+3A_g_version">G_version</code></td>
<td>
<p>An <code>int</code> of the type of covariate for increased fluency (1: G is dichotomous depending on whether all skills required for
current item are mastered; 2: G cumulates practice effect on previous items using mastered skills; 3: G is a time block effect invariant across
subjects with different attribute trajectories)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>cube</code> of response times of subjects on each item across time
</p>


<h3>Examples</h3>

<pre><code class='language-R'>N = dim(Design_array)[1]
J = nrow(Q_matrix)
K = ncol(Q_matrix)
L = dim(Design_array)[3]
class_0 &lt;- sample(1:2^K, N, replace = TRUE)
Alphas_0 &lt;- matrix(0,N,K)
mu_thetatau = c(0,0)
Sig_thetatau = rbind(c(1.8^2,.4*.5*1.8),c(.4*.5*1.8,.25))
Z = matrix(rnorm(N*2),N,2)
thetatau_true = Z%*%chol(Sig_thetatau)
thetas_true = thetatau_true[,1]
taus_true = thetatau_true[,2]
G_version = 3
phi_true = 0.8
for(i in 1:N){
  Alphas_0[i,] &lt;- inv_bijectionvector(K,(class_0[i]-1))
}
lambdas_true &lt;- c(-2, .4, .055)     
Alphas &lt;- sim_alphas(model="HO_joint", 
                     lambdas=lambdas_true, 
                     thetas=thetas_true, 
                     Q_matrix=Q_matrix, 
                     Design_array=Design_array)
RT_itempars_true &lt;- matrix(NA, nrow=J, ncol=2)
RT_itempars_true[,2] &lt;- rnorm(J,3.45,.5)
RT_itempars_true[,1] &lt;- runif(J,1.5,2)
ETAs &lt;- ETAmat(K,J,Q_matrix)
L_sim &lt;- sim_RT(Alphas,Q_matrix,Design_array,RT_itempars_true,taus_true,phi_true,G_version)
</code></pre>

<hr>
<h2 id='Test_order'>Test block ordering of each test version</h2><span id='topic+Test_order'></span>

<h3>Description</h3>

<p><code>Test_order</code> contains the item block ordering corresponding to each test module.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Test_order
</code></pre>


<h3>Format</h3>

<p>A L-by-L matrix, each row is the order of item blocks for that test version.
</p>


<h3>Details</h3>

<p>Each row represents the test module number and shows the order of item blocks administered to a subject with the test module.
For example, the first row is the order of item block administration (1-2-3-4-5) to subjects with test
module 1.
</p>


<h3>Author(s)</h3>

<p>Shiyu Wang, Yan Yang, Jeff Douglas, and Steve Culpepper
</p>


<h3>Source</h3>

<p>Spatial Rotation Learning Experiment at UIUC between Fall 2015 and Spring 2016.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Test_versions">Test_versions</a></code>
</p>

<hr>
<h2 id='Test_versions'>Subjects' test version</h2><span id='topic+Test_versions'></span>

<h3>Description</h3>

<p><code>Test_versions</code> contains each subject's test module in the Spatial Rotation Learning Program.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Test_versions
</code></pre>


<h3>Format</h3>

<p>A vector of length N, containing each subject's assigned test module.
</p>


<h3>Details</h3>

<p>The data object <code>"Test_versions"</code> contains a vector of length N indicating the test module assigned to each subject.
Each test module consists of multiple item blocks with different orders over L time points.
The order of item blocks corresponding to each test module is presented in the data object <code>"Test_order"</code>.
</p>


<h3>Author(s)</h3>

<p>Shiyu Wang, Yan Yang, Jeff Douglas, and Steve Culpepper
</p>


<h3>Source</h3>

<p>Spatial Rotation Learning Experiment at UIUC between Fall 2015 and Spring 2016.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Test_order">Test_order</a></code>
</p>

<hr>
<h2 id='TPmat'>Generate monotonicity matrix</h2><span id='topic+TPmat'></span>

<h3>Description</h3>

<p>Based on the latent attribute space, generate a matrix indicating whether it is possible to
transition from pattern cc to cc' under the monotonicity learning assumption.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TPmat(K)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TPmat_+3A_k">K</code></td>
<td>
<p>An <code>int</code> of the number of attributes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A 2^K-by-2^K dichotomous <code>matrix</code> of whether it is possible to transition between two patterns
</p>


<h3>Examples</h3>

<pre><code class='language-R'>TP = TPmat(4)
</code></pre>

<hr>
<h2 id='Y_real_array'>Observed response accuracy array</h2><span id='topic+Y_real_array'></span>

<h3>Description</h3>

<p><code>Y_real_array</code> contains each subject's observed response accuracy (0/1) at all time points in the Spatial
Rotation Learning Program.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Y_real_array
</code></pre>


<h3>Format</h3>

<p>An array of dimensions N-by-J-by-L. Each slice of the array is an N-by-J matrix, containing the
subjects' response accuracy to each item at time point l.
</p>


<h3>Author(s)</h3>

<p>Shiyu Wang, Yan Yang, Jeff Douglas, and Steve Culpepper
</p>


<h3>Source</h3>

<p>Spatial Rotation Learning Experiment at UIUC between Fall 2015 and Spring 2016.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
