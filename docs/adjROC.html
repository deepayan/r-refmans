<!DOCTYPE html><html><head><title>Help for package adjROC</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {adjROC}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#adjroc'><p>adjroc</p></a></li>
<li><a href='#boot.adjroc'><p>boot.adjroc</p></a></li>
<li><a href='#boot.roc'><p>boot.roc</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Computing Sensitivity at a Fix Value of Specificity and Vice
Versa as Well as Bootstrap Metrics for ROC Curves</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3</td>
</tr>
<tr>
<td>Author:</td>
<td>E. F. Haghish</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>E. F. Haghish &lt;haghish@uio.no&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>For a binary classification the adjusted sensitivity and specificity 
             are measured for a given fixed threshold. If the threshold for either 
             sensitivity or specificity is not given, the crossing point between 
             the sensitivity and specificity curves are returned. For bootstrap 
             procedures, mean and CI bootstrap values of sensitivity, specificity, 
             crossing point between specificity and specificity as well as AUC 
             and AUCPR can be evaluated.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Imports:</td>
<td>ROCit, ggplot2, boot, yardstick</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/haghish/adjROC">https://github.com/haghish/adjROC</a>,
<a href="https://www.sv.uio.no/psi/english/people/aca/haghish/">https://www.sv.uio.no/psi/english/people/aca/haghish/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/haghish/adjROC/issues">https://github.com/haghish/adjROC/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-01-25 15:01:14 UTC; haghish</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-01-25 15:50:09 UTC</td>
</tr>
</table>
<hr>
<h2 id='adjroc'>adjroc</h2><span id='topic+adjroc'></span>

<h3>Description</h3>

<p>computes adjusted sensitivity, adjusted specificity, or the crossing
point between sensitivity and specificity for different thresholds
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjroc(
  score,
  class,
  method = "emp",
  sensitivity = NULL,
  specificity = NULL,
  plot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adjroc_+3A_score">score</code></td>
<td>
<p>A numeric array of diagnostic score i.e. the estimated probability of each diagnosis</p>
</td></tr>
<tr><td><code id="adjroc_+3A_class">class</code></td>
<td>
<p>A numeric array of equal length of <code>"score"</code>, including the actual class of the observations</p>
</td></tr>
<tr><td><code id="adjroc_+3A_method">method</code></td>
<td>
<p>Specifies the method for estimating the ROC curve. Three methods are supported, which are <code>"empirical"</code>, <code>"binormal"</code>, and <code>"nonparametric"</code></p>
</td></tr>
<tr><td><code id="adjroc_+3A_sensitivity">sensitivity</code></td>
<td>
<p>numeric. Specify the threshold of sensitivity</p>
</td></tr>
<tr><td><code id="adjroc_+3A_specificity">specificity</code></td>
<td>
<p>numeric. Specify the threshold of specificity</p>
</td></tr>
<tr><td><code id="adjroc_+3A_plot">plot</code></td>
<td>
<p>logical. if TRUE, the sensitivity and specificity will be plotted</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame including cutoff point, and adjusted sensitivity and specificity
based on the specified threshold
</p>


<h3>Examples</h3>

<pre><code class='language-R'># random classification and probability score
score &lt;- runif(10000, min=0, max=1)
class &lt;- sample(x = c(1,0), 10000, replace=TRUE)

# calculate adjusted sensitivity, when specificity threshold is 0.90:
adjroc(score = score, class = class, specificity = 0.9, plot = TRUE)

# calculate adjusted specificity, when sensitivity threshold equals 0.9
adjroc(score = score, class = class, sensitivity = 0.9, plot = TRUE)

# calculate the meeting point between sensitivity and specificity
adjroc(score = score, class = class, plot = TRUE)
</code></pre>

<hr>
<h2 id='boot.adjroc'>boot.adjroc</h2><span id='topic+boot.adjroc'></span>

<h3>Description</h3>

<p>computes bootstrap adjusted sensitivity, bootstrap adjusted
specificity, or bootstrap crossing point between sensitivity and
specificity for different thresholds
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot.adjroc(
  score,
  class,
  n = 100,
  method = "emp",
  sensitivity = NULL,
  specificity = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boot.adjroc_+3A_score">score</code></td>
<td>
<p>A numeric array of diagnostic score i.e. the estimated probability of each diagnosis</p>
</td></tr>
<tr><td><code id="boot.adjroc_+3A_class">class</code></td>
<td>
<p>A numeric array of equal length of <code>"score"</code>, including the actual class of the observations</p>
</td></tr>
<tr><td><code id="boot.adjroc_+3A_n">n</code></td>
<td>
<p>number of bootstrap samples.</p>
</td></tr>
<tr><td><code id="boot.adjroc_+3A_method">method</code></td>
<td>
<p>Specifies the method for estimating the ROC curve. Three methods are supported, which are <code>"empirical"</code>, <code>"binormal"</code>, and <code>"nonparametric"</code></p>
</td></tr>
<tr><td><code id="boot.adjroc_+3A_sensitivity">sensitivity</code></td>
<td>
<p>numeric. Specify the threshold of sensitivity.</p>
</td></tr>
<tr><td><code id="boot.adjroc_+3A_specificity">specificity</code></td>
<td>
<p>numeric. Specify the threshold of specificity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list including mean and CI of bootstrap value (sensitivity, specificity, or
the crossing point) and the bootstrap data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># random classification and probability score
score &lt;- runif(10000, min=0, max=1)
class &lt;- sample(x = c(1,0), 10000, replace=TRUE)

# calculate adjusted sensitivity, when specificity threshold is 0.90:
adjroc(score = score, class = class, specificity = 0.9, plot = TRUE)

# calculate adjusted specificity, when sensitivity threshold equals 0.9
boot.adjroc(score = score, class = class, n = 100, sensitivity = 0.9)

# calculate the bootstrap meeting point between sensitivity and specificity
boot.adjroc(score = score, class = class, n = 100)
</code></pre>

<hr>
<h2 id='boot.roc'>boot.roc</h2><span id='topic+boot.roc'></span>

<h3>Description</h3>

<p>computes bootstrap AUC and AUCPR for the ROC curve
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot.roc(
  score,
  class,
  metric = "AUC",
  n = 100,
  method = "emp",
  event_level = "first"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boot.roc_+3A_score">score</code></td>
<td>
<p>A numeric array of diagnostic score i.e. the estimated probability of each diagnosis</p>
</td></tr>
<tr><td><code id="boot.roc_+3A_class">class</code></td>
<td>
<p>A numeric array of equal length of <code>"score"</code>, including the
actual class of the observations</p>
</td></tr>
<tr><td><code id="boot.roc_+3A_metric">metric</code></td>
<td>
<p>character. specify the metric of interest which can be
<code>"AUC"</code> (Area Under the Curve, default) or  <code>"AUCPR"</code>
(Area Under the Precision-Recall Curve).</p>
</td></tr>
<tr><td><code id="boot.roc_+3A_n">n</code></td>
<td>
<p>number of bootstrap samples.</p>
</td></tr>
<tr><td><code id="boot.roc_+3A_method">method</code></td>
<td>
<p>Specifies the method for estimating the ROC curve. Three methods
are supported, which are <code>"empirical"</code>, <code>"binormal"</code>,
and <code>"nonparametric"</code></p>
</td></tr>
<tr><td><code id="boot.roc_+3A_event_level">event_level</code></td>
<td>
<p>character. only needed for bootstrapping AUCPR. this
argument specifies which level of the &quot;class&quot; should be
considered the positive event. the values can only be
<code>"first"</code> or <code>"second"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list including mean and CI of bootstrap value (sensitivity, specificity, or
the crossing point) and the bootstrap data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># random classification and probability score
score &lt;- runif(10000, min=0, max=1)
class &lt;- sample(x = c(1,0), 10000, replace=TRUE)

# calculate bootstrap AUC of the ROC curve
boot.roc(score = score, class = class, n = 100, metric = "AUC")

# calculate bootstrap AUCPR of the ROC curve
boot.roc(score = score, class = class, n = 100, metric = "AUCPR")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
