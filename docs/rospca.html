<!DOCTYPE html><html><head><title>Help for package rospca</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {rospca}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#angle'>
<p>Standardised last principal angle</p></a></li>
<li><a href='#dataGen'>
<p>Generate sparse data with outliers</p></a></li>
<li><a href='#diagPlot'>
<p>Diagnostic plot for PCA</p></a></li>
<li><a href='#Glass'>
<p>Glass data</p></a></li>
<li><a href='#robpca'>
<p>ROBust PCA algorithm</p></a></li>
<li><a href='#rospca'>
<p>RObust Sparse PCA algorithm</p></a></li>
<li><a href='#selectLambda'>
<p>Selection of sparsity parameter using IC</p></a></li>
<li><a href='#selectPlot'>
<p>Selection plot</p></a></li>
<li><a href='#zeroMeasure'>
<p>Zero measure</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-03-31</td>
</tr>
<tr>
<td>Title:</td>
<td>Robust Sparse PCA using the ROSPCA Algorithm</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementation of robust sparse PCA using the ROSPCA algorithm 
             of Hubert et al. (2016) &lt;<a href="https://doi.org/10.1080%2F00401706.2015.1093962">doi:10.1080/00401706.2015.1093962</a>&gt;.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Tom Reynkens &lt;tomreynkens@hotmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.14.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, graphics, parallel, mrfDepth (&ge; 1.0.5), robustbase (&ge;
0.92-6), pcaPP, rrcov, elasticnet, mvtnorm, pracma</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/TReynkens/rospca">https://github.com/TReynkens/rospca</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/TReynkens/rospca/issues">https://github.com/TReynkens/rospca/issues</a></td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-31 18:47:47 UTC; tom</td>
</tr>
<tr>
<td>Author:</td>
<td>Tom Reynkens <a href="https://orcid.org/0000-0002-5516-5107"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Valentin Todorov [ctb] (Original R code for PcaHubert and diagnostic
    plot in rrcov package),
  Mia Hubert [ctb],
  Eric Schmitt [ctb],
  Tim Verdonck [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-31 20:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='angle'>
Standardised last principal angle
</h2><span id='topic+angle'></span>

<h3>Description</h3>

<p>Standardised last principal angle between the subspaces generated by the columns of <code>A</code> and <code>B</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>angle(A, B)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="angle_+3A_a">A</code></td>
<td>
<p>Numeric matrix of size <code class="reqn">p</code> by <code class="reqn">k</code>.
</p>
</td></tr>
<tr><td><code id="angle_+3A_b">B</code></td>
<td>
<p>Numeric matrix of size <code class="reqn">q</code> by <code class="reqn">l</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We compute the last principal angle between the subspaces generated by the columns of <code>A</code> and <code>B</code> using
the algorithm in Bjorck and Golub (1973). This angle takes values between 0 and <code class="reqn">\pi/2</code>. We divide it by  <code class="reqn">\pi/2</code> to make it take values between 0 and 1, where 0 indicates that the subspaces are close.
</p>


<h3>Value</h3>

<p>Standardised last principal angle between <code>A</code> and <code>B</code>.
</p>


<h3>Author(s)</h3>

<p>Tom Reynkens
</p>


<h3>References</h3>

<p>Bjorck, A. and Golub, G. H. (1973), &ldquo;Numerical Methods for Computing Angles Between Linear Subspaces,&quot; <em>Mathematics of Computation</em>, 27, 579&ndash;594.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tmp &lt;- dataGen(m=1)

P &lt;- eigen(tmp$R)$vectors[,1:2]
PP &lt;- rospca(tmp$data[[1]], k=2)$loadings

angle(P, PP)
</code></pre>

<hr>
<h2 id='dataGen'>
Generate sparse data with outliers
</h2><span id='topic+dataGen'></span>

<h3>Description</h3>

<p>Generate sparse data with outliers using simulation scheme detailed in Hubert et al. (2016).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dataGen(m = 100, n = 100, p = 10, a = c(0.9,0.5,0), bLength = 4, SD = c(10,5,2), 
        eps = 0, seed = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dataGen_+3A_m">m</code></td>
<td>
<p>Number of datasets to generate, default is 100.</p>
</td></tr>
<tr><td><code id="dataGen_+3A_n">n</code></td>
<td>
<p>Number of observations, default is 100.</p>
</td></tr>
<tr><td><code id="dataGen_+3A_p">p</code></td>
<td>
<p>Number of dimensions, default is 10.</p>
</td></tr> 
<tr><td><code id="dataGen_+3A_a">a</code></td>
<td>
<p>Numeric vector containing the inner group correlations for each block. The number of useful blocks is thus given by <code class="reqn">k=length(a)-1</code> which should be at least 2. By default, the correlations are equal to 0.9, 0.5 and 0, respectively.</p>
</td></tr>
<tr><td><code id="dataGen_+3A_blength">bLength</code></td>
<td>
<p>Length of the blocks of useful variables, default is 4.</p>
</td></tr>
<tr><td><code id="dataGen_+3A_sd">SD</code></td>
<td>
<p>Numeric vector containing the standard deviations of the blocks of variables, default is <code>c(10,4,2)</code>. Note that <code>SD</code> and <code>a</code> should have the same length.</p>
</td></tr>
<tr><td><code id="dataGen_+3A_eps">eps</code></td>
<td>
<p>Proportion of contamination, should be between 0 and 0.5. Default is 0 (no contamination).</p>
</td></tr>
<tr><td><code id="dataGen_+3A_seed">seed</code></td>
<td>
<p>Logical indicating if a seed is used when generating the datasets, default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Firstly, we generate a correlation matrix such that it has sparse eigenvectors.
We design the correlation matrix to have <code class="reqn">length(a)=k+1</code> groups of variables with no correlation between variables from different groups. The first <code class="reqn">k</code> groups consist of <code>bLength</code> variables each. The correlation between the different variables of the group is equal to <code>a[1]</code> for group 1, .... .  The (k+1)th group contains the remaining <code class="reqn">p-k \times bLength</code> variables, which we specify to have correlation <code>a[k+1]</code>.  <br />
Secondly, the correlation matrix <code>R</code> is transformed into the covariance matrix <code class="reqn">\Sigma= V^{0.5} \cdot R \cdot V^{0.5}</code>, where <code class="reqn">V=diag(SD^2)</code>.<br />
Thirdly, the <code>n</code> observations are generated from a <code class="reqn">p</code>-variate normal distribution with mean the <code class="reqn">p</code>-variate zero-vector and covariance matrix <code class="reqn">\Sigma</code>. Standard normally distributed noise terms are also added to each of the <code>p</code> variables to make the sparse structure of the data harder to detect.<br />
Finally, <code class="reqn">(100 \times eps)\%</code> of the data points are randomly replaced by outliers. 
These outliers are generated from a <code class="reqn">p</code>-variate normal distribution as in Croux et al. (2013). <br />
The <code class="reqn">i</code>th eigenvector of <code class="reqn">R</code>, for <code class="reqn">i=1,...,k</code>, is given by a (sparse) vector with the <code class="reqn">(bLength \times (i-1)+1)</code>th till the <code class="reqn">(bLength \times i)</code>th elements equal to <code class="reqn">1/\sqrt{bLength}</code> and all other elements equal to zero.<br />
See Hubert et al. (2016) for more details.
</p>


<h3>Value</h3>

<p>A list with components:<br />
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>List of length <code class="reqn">m</code> containing all data matrices.</p>
</td></tr>
<tr><td><code>ind</code></td>
<td>
<p>List of length <code class="reqn">m</code> containing the numeric vectors with the indices of the contaminated observations.</p>
</td></tr>
<tr><td><code>R</code></td>
<td>
<p>Correlation matrix of the data, a numeric matrix of size <code class="reqn">p</code> by <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code>Sigma</code></td>
<td>
<p>Covariance matrix of the data (<code class="reqn">\Sigma</code>), a numeric matrix of size <code class="reqn">p</code> by <code class="reqn">p</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tom Reynkens
</p>


<h3>References</h3>

<p>Hubert, M., Reynkens, T., Schmitt, E. and Verdonck, T. (2016). &ldquo;Sparse PCA for High-Dimensional Data with Outliers,&rdquo; <em>Technometrics</em>, 58, 424&ndash;434.
</p>
<p>Croux, C., Filzmoser, P., and Fritz, H. (2013), &ldquo;Robust Sparse Principal Component Analysis,&rdquo; <em>Technometrics</em>, 55, 202&ndash;214.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- dataGen(m=1, n=100, p=10, eps=0.2, bLength=4)$data[[1]]

resR &lt;- robpca(X, k=2, skew=FALSE)
diagPlot(resR)
</code></pre>

<hr>
<h2 id='diagPlot'>
Diagnostic plot for PCA
</h2><span id='topic+diagPlot'></span>

<h3>Description</h3>

<p>Make diagnostic plot using the output from <code>robpca</code> or <code>rospca</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diagPlot(res, title = "Robust PCA", col = "black", pch = 16, labelOut = TRUE, id = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diagPlot_+3A_res">res</code></td>
<td>
<p>A list containing the orthogonal distances (<code>od</code>),
the score distances (<code>sd</code>) and their respective cut-offs (<code>cutoff.od</code> and <code>cutoff.sd</code>). Output from <code>robpca</code> or <code>rospca</code> can for example be used.</p>
</td></tr>
<tr><td><code id="diagPlot_+3A_title">title</code></td>
<td>
<p>Title of the plot, default is <code>"Robust PCA"</code>.</p>
</td></tr>
<tr><td><code id="diagPlot_+3A_col">col</code></td>
<td>
<p>Colour of the points in the plot, this can be a single colour for all points or a vector specifying the colour for each point. The default is <code>"black"</code>.</p>
</td></tr>
<tr><td><code id="diagPlot_+3A_pch">pch</code></td>
<td>
<p>Plotting characters or symbol used in the plot, see <a href="graphics.html#topic+points">points</a> for more details. The default is 16 which corresponds to filled circles.</p>
</td></tr>
<tr><td><code id="diagPlot_+3A_labelout">labelOut</code></td>
<td>
<p>Logical indicating if outliers should be labelled on the plot, default is <code>TRUE</code>.</p>
</td></tr> 
<tr><td><code id="diagPlot_+3A_id">id</code></td>
<td>
<p>Number of OD outliers and number of SD outliers to label on the plot, default is 3.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The diagnostic plot contains the score distances on the x-axis and the orthogonal distances on the y-axis.
To detect outliers, cut-offs for both distances are added, see Hubert et al. (2005).
</p>


<h3>Author(s)</h3>

<p>Tom Reynkens, based on R code from Valentin Todorov for the diagnostic plot in <span class="pkg">rrcov</span> (released under GPL-3).
</p>


<h3>References</h3>

<p>Hubert, M., Rousseeuw, P. J., and Vanden Branden, K. (2005), &ldquo;ROBPCA: A New Approach to Robust Principal Component Analysis,&rdquo; <em>Technometrics</em>, 47, 64&ndash;79.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- dataGen(m=1, n=100, p=10, eps=0.2, bLength=4)$data[[1]]

resR &lt;- robpca(X, k=2, skew=FALSE)
diagPlot(resR)
</code></pre>

<hr>
<h2 id='Glass'>
Glass data
</h2><span id='topic+Glass'></span>

<h3>Description</h3>

<p>Glass data of Lemberge et al. (2000) containing  Electron Probe X-ray Microanalysis (EPXMA) intensities for different wavelengths of 16&ndash;17th century archaeological glass vessels.
This dataset was also used in Hubert et al. (2005).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Glass)
</code></pre>


<h3>Format</h3>

<p>A data frame with 180 observations and 750 variables. These variables correspond to EPXMA intensities for different wavelengths and are indicated by <code>V1</code>, <code>V2</code>, ..., <code>V750</code>.
</p>


<h3>Source</h3>

<p>Lemberge, P., De Raedt, I., Janssens, K. H., Wei, F., and Van Espen, P. J. (2000), &ldquo;Quantitative Z-Analysis of the 16&ndash;17th Century Archaelogical Glass Vessels using PLS Regression of EPXMA and <code class="reqn">\mu</code>-XRF Data,&quot; <em>Journal of Chemometrics</em>, 14, 751&ndash;763.
</p>


<h3>References</h3>

<p>Hubert, M., Rousseeuw, P. J., and Vanden Branden, K. (2005), &ldquo;ROBPCA: A New Approach to Robust Principal Component Analysis,&rdquo; <em>Technometrics</em>, 47, 64&ndash;79.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Glass)

res &lt;- robpca(Glass, k=4, alpha=0.5)
matplot(res$loadings, type="l", lty=1)
</code></pre>

<hr>
<h2 id='robpca'>
ROBust PCA algorithm
</h2><span id='topic+robpca'></span>

<h3>Description</h3>

<p>ROBPCA algorithm of Hubert et al. (2005) including reweighting (Engelen et al., 2005) and possible extension to skewed data (Hubert et al., 2009).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>robpca (x, k = 0, kmax = 10, alpha = 0.75, h = NULL, mcd = FALSE, 
        ndir = "all", skew = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="robpca_+3A_x">x</code></td>
<td>
<p>An <code class="reqn">n</code> by <code class="reqn">p</code> matrix or data matrix with observations in the rows and variables in the columns.</p>
</td></tr>
<tr><td><code id="robpca_+3A_k">k</code></td>
<td>
<p>Number of principal components that will be used. When <code>k=0</code> (default), the number of components is selected using the criterion in Hubert et al. (2005).</p>
</td></tr>
<tr><td><code id="robpca_+3A_kmax">kmax</code></td>
<td>
<p>Maximal number of principal components that will be computed, default is 10.</p>
</td></tr> 
<tr><td><code id="robpca_+3A_alpha">alpha</code></td>
<td>
<p>Robustness parameter, default is 0.75.</p>
</td></tr>
<tr><td><code id="robpca_+3A_h">h</code></td>
<td>
<p>The number of outliers the algorithm should resist is given by <code class="reqn">n-h</code>. Any value for <code>h</code> between <code class="reqn">n/2</code> and <code class="reqn">n</code> may be specified. Default is <code>NULL</code> which uses <code>h=ceiling(alpha*n)+1</code>. Do not specify <code>alpha</code> and <code>h</code> at the same time. </p>
</td></tr>
<tr><td><code id="robpca_+3A_mcd">mcd</code></td>
<td>
<p>Logical indicating if the MCD adaptation of ROBPCA may be applied when the number of variables is sufficiently small (see Details). If <code>mcd=FALSE</code> (default), the full ROBPCA algorithm is always applied.</p>
</td></tr>
<tr><td><code id="robpca_+3A_ndir">ndir</code></td>
<td>
<p>Number of directions used when computing the outlyingness (or the adjusted outlyingness when <code>skew=TRUE</code>), see <code><a href="mrfDepth.html#topic+outlyingness">outlyingness</a></code> and <code><a href="mrfDepth.html#topic+adjOutl">adjOutl</a></code> for more details.</p>
</td></tr>
<tr><td><code id="robpca_+3A_skew">skew</code></td>
<td>
<p>Logical indicating if the version for skewed data (Hubert et al., 2009) is applied, default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="robpca_+3A_...">...</code></td>
<td>
<p>Other arguments to pass to methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is based extensively on <code>PcaHubert</code> from <span class="pkg">rrcov</span> and there are two main differences: 
</p>
<p>The outlyingness measure that is used for non-skewed data (<code>skew=FALSE</code>) is the Stahel-Donoho measure as described in Hubert et al. (2005) which is also used in <code><a href="rrcov.html#topic+PcaHubert">PcaHubert</a></code>. The implementation in <span class="pkg">mrfDepth</span> (which is used here) is however much faster than the one in <code><a href="rrcov.html#topic+PcaHubert">PcaHubert</a></code> and hence more, or even all, directions can be considered when computing the outlyingness measure.
</p>
<p>Moreover, the extension for skewed data of Hubert et al. (2009) (<code>skew=TRUE</code>) is also implemented here, but this is not included in <code><a href="rrcov.html#topic+PcaHubert">PcaHubert</a></code>. 
</p>
<p>For an extensive description of the ROBPCA algorithm we refer to Hubert et al. (2005) and to <code><a href="rrcov.html#topic+PcaHubert">PcaHubert</a></code>.
</p>
<p>When <code>mcd=TRUE</code> and <code class="reqn">n&lt;5 \times p</code>, we do not apply the full ROBPCA algorithm. The loadings and eigenvalues
are then computed as the eigenvectors and eigenvalues of the MCD estimator applied to the data set after the SVD step.
</p>


<h3>Value</h3>

<p>A list with components:<br />
</p>
<table>
<tr><td><code>loadings</code></td>
<td>
<p>Loadings matrix containing the robust loadings (eigenvectors), a numeric matrix of size <code class="reqn">p</code> by <code class="reqn">k</code>.</p>
</td></tr>
<tr><td><code>eigenvalues</code></td>
<td>
<p>Numeric vector of length <code class="reqn">k</code> containing the robust eigenvalues.</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>
<p>Scores matrix (computed as <code class="reqn">(X-center) \cdot loadings)</code>, a numeric matrix of size <code class="reqn">n</code> by <code class="reqn">k</code>.</p>
</td></tr>
<tr><td><code>center</code></td>
<td>
<p>Numeric vector of length <code class="reqn">k</code> containing the centre of the data.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>Number of (chosen) principal components.</p>
</td></tr>
<tr><td><code>H0</code></td>
<td>
<p>Logical vector of size <code class="reqn">n</code> indicating if an observation is in the initial h-subset.</p>
</td></tr>
<tr><td><code>H1</code></td>
<td>
<p>Logical vector of size <code class="reqn">n</code> indicating if an observation is kept in the reweighting step.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The robustness parameter <code class="reqn">\alpha</code> used throughout the algorithm.</p>
</td></tr>  
<tr><td><code>h</code></td>
<td>
<p>The <code class="reqn">h</code>-parameter used throughout the algorithm.</p>
</td></tr>
<tr><td><code>sd</code></td>
<td>
<p>Numeric vector of size <code class="reqn">n</code> containing the robust score distances within the robust PCA subspace.</p>
</td></tr>
<tr><td><code>od</code></td>
<td>
<p>Numeric vector of size <code class="reqn">n</code> containing the orthogonal distances to the robust PCA subspace.</p>
</td></tr>
<tr><td><code>cutoff.sd</code></td>
<td>
<p>Cut-off value for the robust score distances.</p>
</td></tr>
<tr><td><code>cutoff.od</code></td>
<td>
<p>Cut-off value for the orthogonal distances.</p>
</td></tr>
<tr><td><code>flag.sd</code></td>
<td>
<p>Numeric vector of size <code class="reqn">n</code> containing the SD-flags of the observations. The observations whose score distance is larger than <code>cutoff.sd</code> receive an SD-flag equal to zero. The other observations receive an SD-flag equal to 1.</p>
</td></tr>  
<tr><td><code>flag.od</code></td>
<td>
<p>Numeric vector of size <code class="reqn">n</code> containing the OD-flags of the observations. The observations whose orthogonal distance is larger than <code>cutoff.od</code> receive an OD-flag equal to zero. The other observations receive an OD-flag equal to 1.</p>
</td></tr>
<tr><td><code>flag.all</code></td>
<td>
<p>Numeric vector of size <code class="reqn">n</code> containing the flags of the observations. The observations whose score distance is larger than  <code>cutoff.sd</code> or whose orthogonal distance is 
larger than  <code>cutoff.od</code> can be considered as outliers and receive a flag equal to zero. 
The regular observations receive flag 1.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tom Reynkens, based on R code from Valentin Todorov for <code>PcaHubert</code> in <span class="pkg">rrcov</span> (released under GPL-3) and Matlab code from Katrien Van Driessen (for the univariate MCD).
</p>


<h3>References</h3>

<p>Hubert, M., Rousseeuw, P. J., and Vanden Branden, K. (2005), &ldquo;ROBPCA: A New Approach to Robust Principal Component Analysis,&rdquo; <em>Technometrics</em>, 47, 64&ndash;79.
</p>
<p>Engelen, S., Hubert, M. and Vanden Branden, K. (2005), &ldquo;A Comparison of Three Procedures for Robust PCA in
High Dimensions&quot;, <em>Austrian Journal of Statistics</em>, 34, 117&ndash;126.
</p>
<p>Hubert, M., Rousseeuw, P. J., and Verdonck, T. (2009), &ldquo;Robust PCA for Skewed Data and Its Outlier Map,&quot; <em>Computational Statistics &amp; Data Analysis</em>, 53, 2264&ndash;2274.
</p>


<h3>See Also</h3>

<p><code><a href="rrcov.html#topic+PcaHubert">PcaHubert</a></code>, <code><a href="mrfDepth.html#topic+outlyingness">outlyingness</a></code>, <code><a href="mrfDepth.html#topic+adjOutl">adjOutl</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- dataGen(m=1, n=100, p=10, eps=0.2, bLength=4)$data[[1]]

resR &lt;- robpca(X, k=2)
diagPlot(resR)
</code></pre>

<hr>
<h2 id='rospca'>
RObust Sparse PCA algorithm
</h2><span id='topic+rospca'></span>

<h3>Description</h3>

<p>Sparse robust PCA algorithm based on the ROBPCA algorithm of Hubert et al. (2005).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rospca(X, k, kmax = 10, alpha = 0.75, h = NULL, ndir = "all", grid = TRUE, 
       lambda = 10^(-6), sparse = "varnum", para, stand = TRUE, skew = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rospca_+3A_x">X</code></td>
<td>
<p>An <code class="reqn">n</code> by <code class="reqn">p</code> matrix or data matrix with observations in the rows and variables in the columns.</p>
</td></tr>
<tr><td><code id="rospca_+3A_k">k</code></td>
<td>
<p>Number of principal components that will be used.</p>
</td></tr>
<tr><td><code id="rospca_+3A_kmax">kmax</code></td>
<td>
<p>Maximal number of principal components that will be computed, default is 10.</p>
</td></tr> 
<tr><td><code id="rospca_+3A_alpha">alpha</code></td>
<td>
<p>Robustness parameter, default is 0.75.</p>
</td></tr>
<tr><td><code id="rospca_+3A_h">h</code></td>
<td>
<p>The number of outliers the algorithm should resist is given by <code class="reqn">n-h</code>. Any value for <code>h</code> between <code class="reqn">n/2</code> and <code class="reqn">n</code> may be specified. Default is <code>NULL</code> which uses <code>h=ceiling(alpha*n)+1</code>. Do not specify <code>alpha</code> and <code>h</code> at the same time. </p>
</td></tr>
<tr><td><code id="rospca_+3A_ndir">ndir</code></td>
<td>
<p>Number of directions used when computing the outlyingness (or the adjusted outlyingness when <code>skew=TRUE</code>), see <code><a href="mrfDepth.html#topic+outlyingness">outlyingness</a></code> and <code><a href="mrfDepth.html#topic+adjOutl">adjOutl</a></code> for more details.</p>
</td></tr>
<tr><td><code id="rospca_+3A_grid">grid</code></td>
<td>
<p>Logical indicating if the grid version of sparse PCA should be used (<code>sPCAgrid</code> with <code>method="sd"</code> from <span class="pkg">pcaPP</span>). Otherwise, the version of Zou et al. (2006) is used (<code>spca</code> from <span class="pkg">elasticnet</span>). Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="rospca_+3A_lambda">lambda</code></td>
<td>
<p>Sparsity parameter of <code>sPCAgrid</code> (when <code>grid=TRUE</code>) or ridge parameter of <code>spca</code> (when
<code>grid=FALSE</code>), default is <code class="reqn">10^{-6}</code>.</p>
</td></tr>
<tr><td><code id="rospca_+3A_sparse">sparse</code></td>
<td>
<p>Parameter for <code>spca</code> (only used when <code>grid=FALSE</code>), see <code><a href="elasticnet.html#topic+spca">spca</a></code> for more details.</p>
</td></tr>
<tr><td><code id="rospca_+3A_para">para</code></td>
<td>
<p>Parameter for <code>spca</code> (only used when <code>grid=FALSE</code>), see <code><a href="elasticnet.html#topic+spca">spca</a></code> for more details.</p>
</td></tr>
<tr><td><code id="rospca_+3A_stand">stand</code></td>
<td>
<p>If <code>TRUE</code>, the data are standardised robustly in the beginning and classically before applying sparse 
PCA. If <code>FALSE</code>, the data are only mean-centred before applying sparse PCA. Default is <code>TRUE</code>.</p>
</td></tr>  
<tr><td><code id="rospca_+3A_skew">skew</code></td>
<td>
<p>Logical indicating if the version for skewed data should be applied, default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ROSPCA algorithm consists of an outlier detection part (step 1), and a sparsification part (steps 2 and 3).
We give an overview of these steps here and refer to Hubert et al. (2016) for more details. 
</p>
<p><b>Step 1</b>: This is a robustness step similar to ROBPCA. When a standardisation is appropriate, the variables are first robustly standardised by means of the componentwise median and the <code class="reqn">Q_n</code>. Using the singular value decomposition (SVD) of the resulting data matrix, the <code class="reqn">p</code>-dimensional data space is reduced to the affine subspace spanned by the <code class="reqn">n</code> observations. Then, the subset of the <code class="reqn">h</code> observations with smallest outlyingness is selected (<code class="reqn">H_0</code>). Thereafter, a reweighting step is applied: given the orthogonal distances to the preliminary PCA subspace determined by the observations in <code class="reqn">H_0</code>, all observations with orthogonal distances (ODs) smaller than the corresponding cut-off are kept (<code class="reqn">H_1</code>).
</p>
<p><b>Step 2</b>: First, the data points with indices in <code class="reqn">H_1</code> are standardised using the componentwise median and the <code class="reqn">Q_n</code> and sparse PCA is applied to them. Then, an additional reweighting step is performed which incorporates information about the sparse structure of the data. Variables with zero loadings on all <code class="reqn">k</code> PCs are discarded and then the orthogonal distances to the estimated sparse PCA subspace are computed. This yields an index set <code class="reqn">H_2</code> of observations with orthogonal distance smaller than the cut-off corresponding to these new orthogonal distances. Thereafter, the subset of observations with indices in <code class="reqn">H_2</code> is standardised using the componentwise median and the <code class="reqn">Q_n</code> of the observations in <code class="reqn">H_1</code> (the same standardisation as in the first time sparse PCA is applied) and sparse PCA is applied to them which gives sparse loadings. Adding the discarded zero loadings again gives the loadings matrix <code class="reqn">P_2</code>.
</p>
<p><b>Step 3</b>: In the last step, the eigenvalues are estimated robustly by applying the <code class="reqn">Q_n^2</code> estimator on the scores of the observations with indices in <code class="reqn">H_2</code>. In order to robustly estimate the centre, the score distances are computed and all observations of <code class="reqn">H_2</code> with a score distance smaller than the corresponding cut-off are considered, this is the set <code class="reqn">H_3</code>. Then, the centre is estimated by the mean of these observations. Finally, the estimates of the eigenvalues are recomputed as the sample variance of the (new) scores of the observations with indices in <code class="reqn">H_3</code>.
The eigenvalues are sorted in descending order, so the order of the PCs may change. The columns of the loadings and scores matrices are changed accordingly.
</p>
<p>Note that when it is not necessary to standardise the data, they are only centred as in the scheme above, but not scaled.
</p>
<p>In contrast to Hubert et al. (2016), we allow for SPCA (Zou et al., 2006) to be used as the sparse PCA method inside ROSPCA (<code>grid=FALSE</code>). Moreover, we also include a skew-adjusted version of ROSPCA (<code>skew=TRUE</code>) similar to the skew-adjusted version of ROBPCA (Hubert et al., 2009). This adjusted version is not detailed in Hubert et al. (2016).
</p>


<h3>Value</h3>

<p>A list with components:<br />
</p>
<table>
<tr><td><code>loadings</code></td>
<td>
<p>Loadings matrix containing the sparse robust loadings (eigenvectors), a numeric matrix of size <code class="reqn">p</code> by <code class="reqn">k</code>.</p>
</td></tr>
<tr><td><code>eigenvalues</code></td>
<td>
<p>Numeric vector of length <code class="reqn">k</code> containing the robust eigenvalues.</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>
<p>Scores matrix (computed as <code class="reqn">(X-center) \cdot loadings)</code>, a numeric matrix of size <code class="reqn">n</code> by <code class="reqn">k</code>.</p>
</td></tr>
<tr><td><code>center</code></td>
<td>
<p>Numeric vector of length <code class="reqn">k</code> containing the centre of the data.</p>
</td></tr>
<tr><td><code>D</code></td>
<td>
<p>Matrix used to standardise the data before applying sparse PCA (identity matrix if <code>stand=FALSE</code>), a numeric matrix of size <code class="reqn">p</code> by <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>Number of (chosen) principal components.</p>
</td></tr>
<tr><td><code>H0</code></td>
<td>
<p>Logical vector of size <code class="reqn">n</code> indicating if an observation is in the initial h-subset.</p>
</td></tr>
<tr><td><code>H1</code></td>
<td>
<p>Logical vector of size <code class="reqn">n</code> indicating if an observation is kept in the non-sparse reweighting step (in robust part).</p>
</td></tr>
<tr><td><code>P1</code></td>
<td>
<p>Loadings matrix before applying sparse reweighting step, a numeric matrix of size <code class="reqn">p</code> by <code class="reqn">k</code>.</p>
</td></tr>
<tr><td><code>index</code></td>
<td>
<p>Numeric vector containing the indices of the variables that are used in the sparse reweighting step.</p>
</td></tr>
<tr><td><code>H2</code></td>
<td>
<p>Logical vector of size <code class="reqn">n</code> indicating if an observation is kept in the sparse reweighting step.</p>
</td></tr>
<tr><td><code>P2</code></td>
<td>
<p>Loadings matrix before estimating eigenvalues, a numeric matrix of size <code class="reqn">p</code> by <code class="reqn">k</code>.</p>
</td></tr>
<tr><td><code>H3</code></td>
<td>
<p>Logical vector of size <code class="reqn">n</code> indicating if an observation is kept in the final SD reweighting step.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The robustness parameter <code class="reqn">\alpha</code> used throughout the algorithm.</p>
</td></tr>  
<tr><td><code>h</code></td>
<td>
<p>The <code class="reqn">h</code>-parameter used throughout the algorithm.</p>
</td></tr>
<tr><td><code>sd</code></td>
<td>
<p>Numeric vector of size <code class="reqn">n</code> containing the robust score distances within the robust PCA subspace.</p>
</td></tr>
<tr><td><code>od</code></td>
<td>
<p>Numeric vector of size <code class="reqn">n</code> containing the orthogonal distances to the robust PCA subspace.</p>
</td></tr>
<tr><td><code>cutoff.sd</code></td>
<td>
<p>Cut-off value for the robust score distances.</p>
</td></tr>
<tr><td><code>cutoff.od</code></td>
<td>
<p>Cut-off value for the orthogonal distances.</p>
</td></tr>
<tr><td><code>flag.sd</code></td>
<td>
<p>Numeric vector of size <code class="reqn">n</code> containing the SD-flags of the observations. The observations whose score distance is larger than <code>cutoff.sd</code> receive an SD-flag equal to zero. The other observations receive an SD-flag equal to 1.</p>
</td></tr>  
<tr><td><code>flag.od</code></td>
<td>
<p>Numeric vector of size <code class="reqn">n</code> containing the OD-flags of the observations. The observations whose orthogonal distance is larger than <code>cutoff.od</code> receive an OD-flag equal to zero. The other observations receive an OD-flag equal to 1.</p>
</td></tr>
<tr><td><code>flag.all</code></td>
<td>
<p>Numeric vector of size <code class="reqn">n</code> containing the flags of the observations. The observations whose score distance is larger than  <code>cutoff.sd</code> or whose orthogonal distance is 
larger than  <code>cutoff.od</code> can be considered as outliers and receive a flag equal to zero. 
The regular observations receive flag 1.</p>
</td></tr>  
</table>


<h3>Author(s)</h3>

<p>Tom Reynkens, based on R code from Valentin Todorov for <code>PcaHubert</code> in <span class="pkg">rrcov</span> (released under GPL-3) and Matlab code from Katrien Van Driessen (for the univariate MCD).
</p>


<h3>References</h3>

<p>Hubert, M., Reynkens, T., Schmitt, E. and Verdonck, T. (2016). &ldquo;Sparse PCA for High-Dimensional Data with Outliers,&rdquo; <em>Technometrics</em>, 58, 424&ndash;434.
</p>
<p>Hubert, M., Rousseeuw, P. J., and Vanden Branden, K. (2005), &ldquo;ROBPCA: A New Approach to Robust Principal Component Analysis,&rdquo; <em>Technometrics</em>, 47, 64&ndash;79.
</p>
<p>Hubert, M., Rousseeuw, P. J., and Verdonck, T. (2009), &ldquo;Robust PCA for Skewed Data and Its Outlier Map,&quot; <em>Computational Statistics &amp; Data Analysis</em>, 53, 2264&ndash;2274.
</p>
<p>Croux, C., Filzmoser, P., and Fritz, H. (2013), &ldquo;Robust Sparse Principal Component Analysis,&rdquo; <em>Technometrics</em>, 55, 202&ndash;214.
</p>
<p>Zou, H., Hastie, T., and Tibshirani, R. (2006), &ldquo;Sparse Principal Component Analysis,&rdquo; <em>Journal of Computational and Graphical Statistics</em>, 15, 265&ndash;286.
</p>


<h3>See Also</h3>

<p><code><a href="rrcov.html#topic+PcaHubert">PcaHubert</a></code>, <code><a href="#topic+robpca">robpca</a></code>, <code><a href="mrfDepth.html#topic+outlyingness">outlyingness</a></code>, <code><a href="mrfDepth.html#topic+adjOutl">adjOutl</a></code>, <code><a href="pcaPP.html#topic+sPCAgrid">sPCAgrid</a></code>, <code><a href="elasticnet.html#topic+spca">spca</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- dataGen(m=1, n=100, p=10, eps=0.2, bLength=4)$data[[1]]

resRS &lt;- rospca(X, k=2, lambda=0.4, stand=TRUE)
diagPlot(resRS)
</code></pre>

<hr>
<h2 id='selectLambda'>
Selection of sparsity parameter using IC
</h2><span id='topic+selectLambda'></span>

<h3>Description</h3>

<p>Selection of the sparsity parameter for ROSPCA and SCoTLASS using BIC of Hubert et al. (2016), and for SRPCA using BIC of Croux et al. (2013).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>selectLambda(X, k, kmax = 10, method = "ROSPCA", lmin = 0, lmax = 2, lstep = 0.02,
             alpha = 0.75, stand = TRUE, skew = FALSE, multicore = FALSE, 
             mc.cores = NULL, P = NULL, ndir = "all")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="selectLambda_+3A_x">X</code></td>
<td>
<p>An <code class="reqn">n</code> by <code class="reqn">p</code> matrix or data matrix with observations in the rows and variables in the columns.</p>
</td></tr>
<tr><td><code id="selectLambda_+3A_k">k</code></td>
<td>

<p>Number of Principal Components (PCs).
</p>
</td></tr>
<tr><td><code id="selectLambda_+3A_kmax">kmax</code></td>
<td>

<p>Maximal number of PCs to be computed, only used when <code>method = "ROSPCA"</code> or <code>method = "ROSPCAg"</code>. Default is 10.</p>
</td></tr>
<tr><td><code id="selectLambda_+3A_method">method</code></td>
<td>

<p>PCA method to use: ROSPCA (<code>"ROSPCA"</code> or <code>"ROSPCAg"</code>), SCoTLASS (<code>"SCoTLASS"</code> or <code>"SPCAg"</code>) or SRPCA (<code>"SRPCA"</code>). Default is <code>"ROSPCA"</code>.
</p>
</td></tr>
<tr><td><code id="selectLambda_+3A_lmin">lmin</code></td>
<td>

<p>Minimal value of <code class="reqn">\lambda</code> to look at, default is 0.
</p>
</td></tr>
<tr><td><code id="selectLambda_+3A_lmax">lmax</code></td>
<td>

<p>Maximal value of <code class="reqn">\lambda</code> to look at, default is 2.
</p>
</td></tr>
<tr><td><code id="selectLambda_+3A_lstep">lstep</code></td>
<td>

<p>Difference between two consecutive values of <code class="reqn">\lambda</code>, i.e. the step size, default is 0.02.
</p>
</td></tr>
<tr><td><code id="selectLambda_+3A_alpha">alpha</code></td>
<td>

<p>Robustness parameter for ROSPCA, default is 0.75.
</p>
</td></tr>
<tr><td><code id="selectLambda_+3A_stand">stand</code></td>
<td>

<p>Logical indicating if the data should be standardised, default is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="selectLambda_+3A_skew">skew</code></td>
<td>

<p>Logical indicating if the skewed version of ROSPCA should be applied, default is <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="selectLambda_+3A_multicore">multicore</code></td>
<td>

<p>Logical indicating if multiple cores can be used, default is <code>TRUE</code>. Note that this is not possible for the Windows platform, so <code>multicore</code> is always <code>FALSE</code> there.
</p>
</td></tr>
<tr><td><code id="selectLambda_+3A_mc.cores">mc.cores</code></td>
<td>

<p>Number of cores to use if <code>multicore=TRUE</code>, default is <code>NULL</code> which corresponds to the number of cores minus 1.
</p>
</td></tr>
<tr><td><code id="selectLambda_+3A_p">P</code></td>
<td>

<p>True loadings matrix, a numeric matrix of size <code class="reqn">p</code> by <code class="reqn">k</code>. The default is <code>NULL</code> which means that no true loadings matrix is specified. 
</p>
</td></tr>
<tr><td><code id="selectLambda_+3A_ndir">ndir</code></td>
<td>
<p>Number of directions used when computing the outlyingness (or the adjusted outlyingness when <code>skew=TRUE</code>) in <code>rospca</code>, see <code><a href="mrfDepth.html#topic+outlyingness">outlyingness</a></code> and <code><a href="mrfDepth.html#topic+adjOutl">adjOutl</a></code> for more details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We select an optimal value of <code class="reqn">\lambda</code> for a certain method on a certain dataset by looking at an equidistant grid of <code class="reqn">\lambda</code> values. For each value of <code class="reqn">\lambda</code>, we apply the method on the dataset using this sparsity parameter, and compute an Information Criterion (IC). The optimal value of <code class="reqn">\lambda</code> is then the one corresponding to the minimal IC. The ICs we consider are the BIC of for Hubert et al. (2016) for ROSPCA and SCoTLASS, and the BIC of Croux et al. (2013) for SRPCA.
The BIC of Hubert et al. (2016) is defined as
</p>
<p style="text-align: center;"><code class="reqn">BIC(\lambda)=\ln(1/(h_1p)\sum_{i=1}^{h_1} OD^2_{(i)}(\lambda))+df(\lambda)\ln(h_1p)/(h_1p),</code>
</p>

<p>where <code class="reqn">h_1</code> is the size of <code class="reqn">H_1</code> (the subset of observations that are kept in the non-sparse reweighting step) and <code class="reqn">OD_{(i)}(\lambda)</code> is the <code class="reqn">i</code>th smallest orthogonal distance for the model when using <code class="reqn">\lambda</code> as the sparsity parameter. The degrees of freedom <code class="reqn">df(\lambda)</code> are the number of non-zero loadings when <code class="reqn">\lambda</code> is used as the sparsity parameter.
</p>


<h3>Value</h3>

<p>A list with components:<br />
</p>
<table>
<tr><td><code>opt.lambda</code></td>
<td>
<p>Value of <code class="reqn">\lambda</code> corresponding to minimal IC.</p>
</td></tr>
<tr><td><code>min.IC</code></td>
<td>
<p>Minimal value of IC.</p>
</td></tr>
<tr><td><code>Lambda</code></td>
<td>
<p>Numeric vector containing the used values of <code class="reqn">\lambda</code>.</p>
</td></tr>
<tr><td><code>IC</code></td>
<td>
<p>Numeric cector containing the IC values corresponding to all values of <code class="reqn">\lambda</code> in <code>Lambda</code>.</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>Loadings obtained using method with sparsity parameter <code>opt.lambda</code>, a numeric matrix of size <code class="reqn">p</code> by <code class="reqn">k</code>.</p>
</td></tr>
<tr><td><code>fit</code></td>
<td>
<p>Fit obtained using method with sparsity parameter <code>opt.lambda</code>. This is a list containing the loadings (<code>loadings</code>), the eigenvalues (<code>eigenvalues</code>), the standardised data matrix used as input (<code>Xst</code>), the scores matrix (<code>scores</code>), the orthogonal distances (<code>od</code>) and the score distances (<code>sd</code>).</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>Type of IC used: <code>BICod</code> (BIC of Hubert et al. (2016)) or <code>BIC</code> (BIC of Croux et al. (2013)).</p>
</td></tr>
<tr><td><code>measure</code></td>
<td>
<p>A numeric vector containing the standardised angles between the true and the estimated loadings matrix for each value of <code class="reqn">\lambda</code> if a loadings matrix is given. When no loadings matrix is given as input (<code>P=NULL</code>), <code>measure</code> is equal to <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tom Reynkens
</p>


<h3>References</h3>

<p>Hubert, M., Reynkens, T., Schmitt, E. and Verdonck, T. (2016). &ldquo;Sparse PCA for High-Dimensional Data with Outliers,&rdquo; <em>Technometrics</em>, 58, 424&ndash;434.
</p>
<p>Croux, C., Filzmoser, P., and Fritz, H. (2013), &ldquo;Robust Sparse Principal Component Analysis,&rdquo; <em>Technometrics</em>, 55, 202&ndash;214.
</p>


<h3>See Also</h3>

<p><a href="#topic+selectPlot">selectPlot</a>, <a href="parallel.html#topic+mclapply">mclapply</a>, <a href="#topic+angle">angle</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- dataGen(m=1, n=100, p=10, eps=0.2, bLength=4)$data[[1]]

sl &lt;- selectLambda(X, k=2, method="ROSPCA", lstep=0.1)
selectPlot(sl)
</code></pre>

<hr>
<h2 id='selectPlot'>
Selection plot
</h2><span id='topic+selectPlot'></span>

<h3>Description</h3>

<p>Plot Information Criterion (IC) versus values of the sparsity parameter <code class="reqn">\lambda</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>selectPlot(sl, indicate = TRUE, main = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="selectPlot_+3A_sl">sl</code></td>
<td>

<p>Output from <code>selectLambda</code> function.
</p>
</td></tr>
<tr><td><code id="selectPlot_+3A_indicate">indicate</code></td>
<td>

<p>Logical indicating if the value of <code class="reqn">\lambda</code> corresponding to the minimal IC is indicated on the plot, default is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="selectPlot_+3A_main">main</code></td>
<td>

<p>Title for the plot, default is <code>NULL</code> (no title).
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tom Reynkens
</p>


<h3>References</h3>

<p>Hubert, M., Reynkens, T., Schmitt, E. and Verdonck, T. (2016). &ldquo;Sparse PCA for High-Dimensional Data with Outliers,&rdquo; <em>Technometrics</em>, 58, 424&ndash;434.
</p>


<h3>See Also</h3>

<p><a href="#topic+selectLambda">selectLambda</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- dataGen(m=1, n=100, p=10, eps=0.2, bLength=4)$data[[1]]

sl &lt;- selectLambda(X, k=2, method="ROSPCA", lstep=0.1)
selectPlot(sl)
</code></pre>

<hr>
<h2 id='zeroMeasure'>
Zero measure
</h2><span id='topic+zeroMeasure'></span>

<h3>Description</h3>

<p>Compute the average zero measures and total zero measure for a list of matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zeroMeasure(Plist, P, prec = 10^(-5))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zeroMeasure_+3A_plist">Plist</code></td>
<td>

<p>List of estimated loadings matrices or a single estimated loadings matrix.
All these matrices should be numeric matrices of size <code class="reqn">p</code> by <code class="reqn">k</code>.
</p>
</td></tr>
<tr><td><code id="zeroMeasure_+3A_p">P</code></td>
<td>

<p>True loadings matrix, a numeric matrix of size <code class="reqn">p</code> by <code class="reqn">k</code>.
</p>
</td></tr>
<tr><td><code id="zeroMeasure_+3A_prec">prec</code></td>
<td>

<p>Precision used when determining if an element is non-zero, default is <code class="reqn">10^{-5}</code>.
We say that all elements with an absolute value smaller than <code>prec</code> are &ldquo;equal to zero&rdquo;.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <em>zero measure</em> is a way to compare how correctly a PCA method estimates the sparse loadings matrix <code>P</code>. For each element of an estimated loadings matrix, it is equal to one if the estimated and true value are both zero or both non-zero, and zero otherwise. We then take the average zero measure over all elements of an estimated loadings matrix and over all estimated loadings matrices which we call the <em>total zero measure</em>.
</p>


<h3>Value</h3>

<p>A list with components:<br />
</p>
<table>
<tr><td><code>measure</code></td>
<td>
<p>Numeric matrix of size <code class="reqn">p</code> by <code class="reqn">k</code> containing the average zero measure over all <code>length(Plist)</code> simulations for each element of <code>P</code>.</p>
</td></tr>
<tr><td><code>index</code></td>
<td>
<p>Numeric vector containing the indices of all data sets where the estimate was wrong (at least one of the zero measures for the elements of an estimated loadings matrix is equal to 0).</p>
</td></tr>
<tr><td><code>total</code></td>
<td>
<p>Total zero measure, i.e. the average zero measure over all elements of an estimated loadings matrix and over all estimated loadings matrices.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tom Reynkens
</p>


<h3>References</h3>

<p>Hubert, M., Reynkens, T., Schmitt, E. and Verdonck, T. (2016). &ldquo;Sparse PCA for High-Dimensional Data with Outliers,&rdquo; <em>Technometrics</em>, 58, 424&ndash;434.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>P &lt;- cbind(c(1,1), c(0,1))
Plist &lt;- list(matrix(1,2,2), P)

zeroMeasure(Plist, P)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
