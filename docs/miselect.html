<!DOCTYPE html><html><head><title>Help for package miselect</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {miselect}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#coef.cv.galasso'><p>Extract Coefficients From a &quot;cv.galasso&quot; Object</p></a></li>
<li><a href='#coef.cv.saenet'><p>Extract Coefficients From a &quot;cv.saenet&quot; Object</p></a></li>
<li><a href='#coef.galasso'><p>Extract Coefficients From a &quot;galasso&quot; Object</p></a></li>
<li><a href='#coef.saenet'><p>Extract Coefficients From a &quot;saenet&quot; Object</p></a></li>
<li><a href='#cv.galasso'><p>Cross Validated Multiple Imputation Grouped Adaptive LASSO</p></a></li>
<li><a href='#cv.saenet'><p>Cross Validated Multiple Imputation Stacked Adaptive Elastic Net</p></a></li>
<li><a href='#galasso'><p>Multiple Imputation Grouped Adaptive LASSO</p></a></li>
<li><a href='#miselect.df'><p>Synthetic Example Data For &quot;miselect&quot;</p></a></li>
<li><a href='#print.cv.galasso'><p>Print cv.galasso Objects</p></a></li>
<li><a href='#print.cv.saenet'><p>Print cv.saenet Objects</p></a></li>
<li><a href='#saenet'><p>Multiple Imputation Stacked Adaptive Elastic Net</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Variable Selection for Multiply Imputed Data</td>
</tr>
<tr>
<td>Version:</td>
<td>0.9.2</td>
</tr>
<tr>
<td>Description:</td>
<td>
    Penalized regression methods, such as lasso and elastic net, are used in
    many biomedical applications when simultaneous regression coefficient
    estimation and variable selection is desired. However, missing data
    complicates the implementation of these methods, particularly when
    missingness is handled using multiple imputation. Applying a variable
    selection algorithm on each imputed dataset will likely lead
    to different sets of selected predictors, making it difficult
    to ascertain a final active set without resorting to ad hoc
    combination rules. 'miselect' presents Stacked Adaptive Elastic Net (saenet)
    and Grouped Adaptive LASSO (galasso) for continuous and binary outcomes,
    developed by Du et al (2022) &lt;<a href="https://doi.org/10.1080%2F10618600.2022.2035739">doi:10.1080/10618600.2022.2035739</a>&gt;. They, 
    by construction, force selection of the same variables across multiply 
    imputed data. 'miselect' also provides cross validated variants of these 
    methods.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>mice, knitr, rmarkdown, testthat</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-05 15:39:46 UTC; mk</td>
</tr>
<tr>
<td>Author:</td>
<td>Michael Kleinsasser [cre],
  Alexander Rix [aut],
  Jiacong Du [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Michael Kleinsasser &lt;biostat-cran-manager@umich.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-05 17:00:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='coef.cv.galasso'>Extract Coefficients From a &quot;cv.galasso&quot; Object</h2><span id='topic+coef.cv.galasso'></span>

<h3>Description</h3>

<p>Extract Coefficients From a &quot;cv.galasso&quot; Object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.galasso'
coef(object, lambda = object$lambda.min, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.cv.galasso_+3A_object">object</code></td>
<td>
<p>A &quot;cv.galasso&quot; fit</p>
</td></tr>
<tr><td><code id="coef.cv.galasso_+3A_lambda">lambda</code></td>
<td>
<p>Chosen value of lambda. Must be between &quot;min(lambda)&quot; and
&quot;max(lambda)&quot;. Default is &quot;lambda.min&quot;</p>
</td></tr>
<tr><td><code id="coef.cv.galasso_+3A_...">...</code></td>
<td>
<p>Additional unused arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of numeric vectors containing the coefficients from running
<code>galasso</code> on <code>lambda</code> for each imputation.
</p>

<hr>
<h2 id='coef.cv.saenet'>Extract Coefficients From a &quot;cv.saenet&quot; Object</h2><span id='topic+coef.cv.saenet'></span>

<h3>Description</h3>

<p>Extract Coefficients From a &quot;cv.saenet&quot; Object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.saenet'
coef(object, lambda = object$lambda.min, alpha = object$alpha.min, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.cv.saenet_+3A_object">object</code></td>
<td>
<p>A &quot;cv.saenet&quot; fit</p>
</td></tr>
<tr><td><code id="coef.cv.saenet_+3A_lambda">lambda</code></td>
<td>
<p>Chosen value of lambda. Must be between &quot;min(lambda)&quot; and
&quot;max(lambda)&quot;. Default is &quot;lambda.min&quot;</p>
</td></tr>
<tr><td><code id="coef.cv.saenet_+3A_alpha">alpha</code></td>
<td>
<p>Chosen value of alpha. Must be between &quot;min(alpha)&quot; and
&quot;max(alpha)&quot;. Default is &quot;alpha.min&quot;</p>
</td></tr>
<tr><td><code id="coef.cv.saenet_+3A_...">...</code></td>
<td>
<p>Additional unused arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the coefficients from running
<code>saenet</code> on <code>lambda</code> and <code>alpha</code>.
</p>

<hr>
<h2 id='coef.galasso'>Extract Coefficients From a &quot;galasso&quot; Object</h2><span id='topic+coef.galasso'></span>

<h3>Description</h3>

<p>Extract Coefficients From a &quot;galasso&quot; Object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'galasso'
coef(object, lambda, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.galasso_+3A_object">object</code></td>
<td>
<p>A &quot;galasso&quot; fit</p>
</td></tr>
<tr><td><code id="coef.galasso_+3A_lambda">lambda</code></td>
<td>
<p>Chosen value of lambda. Must be between &quot;min(lambda)&quot; and
&quot;max(lambda)&quot;. Default is &quot;lambda.min&quot;</p>
</td></tr>
<tr><td><code id="coef.galasso_+3A_...">...</code></td>
<td>
<p>Additional unused arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of length D containing the coefficient estimates from running 
<code>galasso</code> on <code>lambda</code>.
</p>

<hr>
<h2 id='coef.saenet'>Extract Coefficients From a &quot;saenet&quot; Object</h2><span id='topic+coef.saenet'></span>

<h3>Description</h3>

<p><code>coef.galasso</code> averages the estimates across imputations to return a
single vector instead of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'saenet'
coef(object, lambda, alpha, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.saenet_+3A_object">object</code></td>
<td>
<p>A &quot;cv.saenet&quot; fit</p>
</td></tr>
<tr><td><code id="coef.saenet_+3A_lambda">lambda</code></td>
<td>
<p>Chosen value of lambda. Must be between &quot;min(lambda)&quot; and
&quot;max(lambda)&quot;. Default is &quot;lambda.min&quot;</p>
</td></tr>
<tr><td><code id="coef.saenet_+3A_alpha">alpha</code></td>
<td>
<p>Chosen value of alpha. Must be between &quot;min(alpha)&quot; and
&quot;max(alpha)&quot;. Default is &quot;alpha.min&quot;</p>
</td></tr>
<tr><td><code id="coef.saenet_+3A_...">...</code></td>
<td>
<p>Additional unused arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the coefficients from running
<code>saenet</code> on <code>lambda</code> and <code>alpha</code>.
</p>

<hr>
<h2 id='cv.galasso'>Cross Validated Multiple Imputation Grouped Adaptive LASSO</h2><span id='topic+cv.galasso'></span>

<h3>Description</h3>

<p>Does k-fold cross-validation for <code>galasso</code>, and returns an optimal value
for lambda.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.galasso(
  x,
  y,
  pf,
  adWeight,
  family = c("gaussian", "binomial"),
  nlambda = 100,
  lambda.min.ratio = ifelse(isTRUE(all.equal(adWeight, rep(1, p))), 0.001, 1e-06),
  lambda = NULL,
  nfolds = 5,
  foldid = NULL,
  maxit = 1000,
  eps = 1e-05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.galasso_+3A_x">x</code></td>
<td>
<p>A length <code>m</code> list of <code>n * p</code> numeric matrices. No matrix
should contain an intercept, or any missing values</p>
</td></tr>
<tr><td><code id="cv.galasso_+3A_y">y</code></td>
<td>
<p>A length <code>m</code> list of length <code>n</code> numeric response vectors.
No vector should contain missing values</p>
</td></tr>
<tr><td><code id="cv.galasso_+3A_pf">pf</code></td>
<td>
<p>Penalty factor. Can be used to differentially penalize certain
variables</p>
</td></tr>
<tr><td><code id="cv.galasso_+3A_adweight">adWeight</code></td>
<td>
<p>Numeric vector of length p representing the adaptive weights
for the L1 penalty</p>
</td></tr>
<tr><td><code id="cv.galasso_+3A_family">family</code></td>
<td>
<p>The type of response. &quot;gaussian&quot; implies a continuous response
and &quot;binomial&quot; implies a binary response. Default is &quot;gaussian&quot;.</p>
</td></tr>
<tr><td><code id="cv.galasso_+3A_nlambda">nlambda</code></td>
<td>
<p>Length of automatically generated &quot;lambda&quot; sequence. If
&quot;lambda&quot; is non NULL, &quot;nlambda&quot; is ignored. Default is 100</p>
</td></tr>
<tr><td><code id="cv.galasso_+3A_lambda.min.ratio">lambda.min.ratio</code></td>
<td>
<p>Ratio that determines the minimum value of &quot;lambda&quot;
when automatically generating a &quot;lambda&quot; sequence. If &quot;lambda&quot; is not
NULL, &quot;lambda.min.ratio&quot; is ignored. Default is 1e-4</p>
</td></tr>
<tr><td><code id="cv.galasso_+3A_lambda">lambda</code></td>
<td>
<p>Optional numeric vector of lambdas to fit. If NULL,
<code>galasso</code> will automatically generate a lambda sequence based off
of <code>nlambda</code> and <code>lambda.min.ratio</code>. Default is NULL</p>
</td></tr>
<tr><td><code id="cv.galasso_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of foldid to use for cross validation. Default is 5,
minimum is 3</p>
</td></tr>
<tr><td><code id="cv.galasso_+3A_foldid">foldid</code></td>
<td>
<p>an optional length <code>n</code> vector of values between 1 and
<code>cv.galasso</code> will automatically generate folds</p>
</td></tr>
<tr><td><code id="cv.galasso_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of iterations to run. Default is 10000</p>
</td></tr>
<tr><td><code id="cv.galasso_+3A_eps">eps</code></td>
<td>
<p>Tolerance for convergence. Default is 1e-5</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>cv.galasso</code> works by adding a group penalty to the aggregated objective
function to ensure selection consistency across imputations. Simulations
suggest that the &quot;stacked&quot; objective function approaches (i.e., <code>saenet</code>)
tend to be more computationally efficient and have better estimation and
selection properties.
</p>


<h3>Value</h3>

<p>An object of type &quot;cv.galasso&quot; with 7 elements:
</p>

<dl>
<dt>call</dt><dd><p>The call that generated the output.</p>
</dd>
<dt>lambda</dt><dd><p>The sequence of lambdas fit.</p>
</dd>
<dt>cvm</dt><dd><p>Average cross validation error for each &quot;lambda&quot;. For
family = &quot;gaussian&quot;, &quot;cvm&quot; corresponds to mean squared error,
and for binomial &quot;cvm&quot; corresponds to deviance.</p>
</dd>
<dt>cvse</dt><dd><p>Standard error of &quot;cvm&quot;.</p>
</dd>
<dt>galasso.fit</dt><dd><p>A &quot;galasso&quot; object fit to the full data.</p>
</dd>
<dt>lambda.min</dt><dd><p>The lambda value for the model with the minimum cross
validation error.</p>
</dd>
<dt>lambda.1se</dt><dd><p>The lambda value for the  sparsest model within one
standard error of the minimum cross validation error.</p>
</dd>
<dt>df</dt><dd><p>The number of nonzero coefficients for each value of lambda.</p>
</dd>
</dl>



<h3>References</h3>

<p>Du, J., Boss, J., Han, P., Beesley, L. J., Kleinsasser, M., Goutman, S. A., ... 
&amp; Mukherjee, B. (2022). Variable selection with multiply-imputed datasets: 
choosing between stacked and grouped methods. Journal of Computational and 
Graphical Statistics, 31(4), 1063-1075. &lt;doi:10.1080/10618600.2022.2035739&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(miselect)
library(mice)

set.seed(48109)

# Using the mice defaults for sake of example only.
mids &lt;- mice(miselect.df, m = 5, printFlag = FALSE)
dfs &lt;- lapply(1:5, function(i) complete(mids, action = i))

# Generate list of imputed design matrices and imputed responses
x &lt;- list()
y &lt;- list()
for (i in 1:5) {
    x[[i]] &lt;- as.matrix(dfs[[i]][, paste0("X", 1:20)])
    y[[i]] &lt;- dfs[[i]]$Y
}

pf       &lt;- rep(1, 20)
adWeight &lt;- rep(1, 20)

fit &lt;- cv.galasso(x, y, pf, adWeight)

# By default 'coef' returns the betas for lambda.min.
coef(fit)

</code></pre>

<hr>
<h2 id='cv.saenet'>Cross Validated Multiple Imputation Stacked Adaptive Elastic Net</h2><span id='topic+cv.saenet'></span>

<h3>Description</h3>

<p>Does k-fold cross-validation for <code>saenet</code>, and returns optimal values
for lambda and alpha.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.saenet(
  x,
  y,
  pf,
  adWeight,
  weights,
  family = c("gaussian", "binomial"),
  alpha = 1,
  nlambda = 100,
  lambda.min.ratio = ifelse(isTRUE(all.equal(adWeight, rep(1, p))), 0.001, 1e-06),
  lambda = NULL,
  nfolds = 5,
  foldid = NULL,
  maxit = 1000,
  eps = 1e-05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.saenet_+3A_x">x</code></td>
<td>
<p>A length <code>m</code> list of <code>n * p</code> numeric matrices. No matrix
should contain an intercept, or any missing values</p>
</td></tr>
<tr><td><code id="cv.saenet_+3A_y">y</code></td>
<td>
<p>A length <code>m</code> list of length <code>n</code> numeric response vectors.
No vector should contain missing values</p>
</td></tr>
<tr><td><code id="cv.saenet_+3A_pf">pf</code></td>
<td>
<p>Penalty factor of length <code>p</code>. Can be used to differentially
penalize certain variables. 0 indicates to not penalize the covariate</p>
</td></tr>
<tr><td><code id="cv.saenet_+3A_adweight">adWeight</code></td>
<td>
<p>Numeric vector of length p representing the adaptive weights
for the L1 penalty</p>
</td></tr>
<tr><td><code id="cv.saenet_+3A_weights">weights</code></td>
<td>
<p>Numeric vector of length n containing the proportion observed
(non-missing) for each row in the un-imputed data.</p>
</td></tr>
<tr><td><code id="cv.saenet_+3A_family">family</code></td>
<td>
<p>The type of response. &quot;gaussian&quot; implies a continuous response
and &quot;binomial&quot; implies a binary response. Default is &quot;gaussian&quot;.</p>
</td></tr>
<tr><td><code id="cv.saenet_+3A_alpha">alpha</code></td>
<td>
<p>Elastic net parameter. Can be a vector to cross validate over.
Default is 1</p>
</td></tr>
<tr><td><code id="cv.saenet_+3A_nlambda">nlambda</code></td>
<td>
<p>Length of automatically generated &quot;lambda&quot; sequence. If
&quot;lambda&quot; is non NULL, &quot;nlambda&quot; is ignored. Default is 100</p>
</td></tr>
<tr><td><code id="cv.saenet_+3A_lambda.min.ratio">lambda.min.ratio</code></td>
<td>
<p>Ratio that determines the minimum value of &quot;lambda&quot;
when automatically generating a &quot;lambda&quot; sequence. If &quot;lambda&quot; is not
NULL, &quot;lambda.min.ratio&quot; is ignored. Default is 1e-3</p>
</td></tr>
<tr><td><code id="cv.saenet_+3A_lambda">lambda</code></td>
<td>
<p>Optional numeric vector of lambdas to fit. If NULL,
<code>galasso</code> will automatically generate a lambda sequence based off
of <code>nlambda</code> and <code>lambda.min.ratio</code>. Default is NULL</p>
</td></tr>
<tr><td><code id="cv.saenet_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of foldid to use for cross validation. Default is 5,
minimum is 3</p>
</td></tr>
<tr><td><code id="cv.saenet_+3A_foldid">foldid</code></td>
<td>
<p>an optional length <code>n</code> vector of values between 1 and
<code>cv.galasso</code> will automatically generate folds</p>
</td></tr>
<tr><td><code id="cv.saenet_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of iterations to run. Default is 1000</p>
</td></tr>
<tr><td><code id="cv.saenet_+3A_eps">eps</code></td>
<td>
<p>Tolerance for convergence. Default is 1e-5</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>cv.saenet</code> works by stacking the multiply imputed data into a single
matrix and running a weighted adaptive elastic net on it. Simulations suggest
that the &quot;stacked&quot; objective function approaches tend to be more
computationally efficient and have better estimation and selection
properties.
</p>
<p>Due to stacking, the automatically generated <code>lambda</code> sequence
<code>cv.saenet</code> generates may end up underestimating <code>lambda.max</code>, and
thus the degrees of freedom  may be nonzero at the first lambda value.
</p>


<h3>Value</h3>

<p>An object of type &quot;cv.saenet&quot; with 9 elements:
</p>

<dl>
<dt>call</dt><dd><p>The call that generated the output.</p>
</dd>
<dt>lambda</dt><dd><p>Sequence of lambdas fit.</p>
</dd>
<dt>cvm</dt><dd><p>Average cross validation error for each lambda and alpha. For
family = &quot;gaussian&quot;, &quot;cvm&quot; corresponds to mean squared error,
and for binomial &quot;cvm&quot; corresponds to deviance.</p>
</dd>
<dt>cvse</dt><dd><p>Standard error of &quot;cvm&quot;.</p>
</dd>
<dt>saenet.fit</dt><dd><p>A &quot;saenet&quot; object fit to the full data.</p>
</dd>
<dt>lambda.min</dt><dd><p>The lambda value for the model with the minimum cross
validation error.</p>
</dd>
<dt>lambda.1se</dt><dd><p>The lambda value for the  sparsest model within one
standard error of the minimum cross validation error.</p>
</dd>
<dt>alpha.min</dt><dd><p>The alpha value for the model with the minimum cross
validation error.</p>
</dd>
<dt>alpha.1se</dt><dd><p>The alpha value for the  sparsest model within one
standard error of the minimum cross validation error.</p>
</dd>
<dt>df</dt><dd><p>The number of nonzero coefficients for each value of lambda and alpha.</p>
</dd>
</dl>



<h3>References</h3>

<p>Du, J., Boss, J., Han, P., Beesley, L. J., Kleinsasser, M., Goutman, S. A., ... 
&amp; Mukherjee, B. (2022). Variable selection with multiply-imputed datasets: 
choosing between stacked and grouped methods. Journal of Computational and 
Graphical Statistics, 31(4), 1063-1075. &lt;doi:10.1080/10618600.2022.2035739&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(miselect)
library(mice)

set.seed(48109)

# Using the mice defaults for sake of example only.
mids &lt;- mice(miselect.df, m = 5, printFlag = FALSE)
dfs &lt;- lapply(1:5, function(i) complete(mids, action = i))

# Generate list of imputed design matrices and imputed responses
x &lt;- list()
y &lt;- list()
for (i in 1:5) {
    x[[i]] &lt;- as.matrix(dfs[[i]][, paste0("X", 1:20)])
    y[[i]] &lt;- dfs[[i]]$Y
}

# Calculate observational weights
weights  &lt;- 1 - rowMeans(is.na(miselect.df))
pf       &lt;- rep(1, 20)
adWeight &lt;- rep(1, 20)

# Since 'Y' is a binary variable, we use 'family = "binomial"'
fit &lt;- cv.saenet(x, y, pf, adWeight, weights, family = "binomial")

# By default 'coef' returns the betas for (lambda.min , alpha.min)
coef(fit)


# You can also cross validate over alpha

fit &lt;- cv.saenet(x, y, pf, adWeight, weights, family = "binomial",
                 alpha = c(.5, 1))
# Get selected variables from the 1 standard error rule
coef(fit, lambda = fit$lambda.1se, alpha = fit$alpha.1se)


</code></pre>

<hr>
<h2 id='galasso'>Multiple Imputation Grouped Adaptive LASSO</h2><span id='topic+galasso'></span>

<h3>Description</h3>

<p><code>galasso</code> fits an adaptive LASSO for multiply imputed data. &quot;galasso&quot;
supports both continuous and binary responses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>galasso(
  x,
  y,
  pf,
  adWeight,
  family = c("gaussian", "binomial"),
  nlambda = 100,
  lambda.min.ratio = ifelse(isTRUE(all.equal(adWeight, rep(1, p))), 0.001, 1e-06),
  lambda = NULL,
  maxit = 10000,
  eps = 1e-05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="galasso_+3A_x">x</code></td>
<td>
<p>A length <code>m</code> list of <code>n * p</code> numeric matrices. No matrix
should contain an intercept, or any missing values</p>
</td></tr>
<tr><td><code id="galasso_+3A_y">y</code></td>
<td>
<p>A length <code>m</code> list of length <code>n</code> numeric response vectors.
No vector should contain missing values</p>
</td></tr>
<tr><td><code id="galasso_+3A_pf">pf</code></td>
<td>
<p>Penalty factor. Can be used to differentially penalize certain
variables</p>
</td></tr>
<tr><td><code id="galasso_+3A_adweight">adWeight</code></td>
<td>
<p>Numeric vector of length p representing the adaptive weights
for the L1 penalty</p>
</td></tr>
<tr><td><code id="galasso_+3A_family">family</code></td>
<td>
<p>The type of response. &quot;gaussian&quot; implies a continuous response
and &quot;binomial&quot; implies a binary response. Default is &quot;gaussian&quot;.</p>
</td></tr>
<tr><td><code id="galasso_+3A_nlambda">nlambda</code></td>
<td>
<p>Length of automatically generated &quot;lambda&quot; sequence. If
&quot;lambda&quot; is non NULL, &quot;nlambda&quot; is ignored. Default is 100</p>
</td></tr>
<tr><td><code id="galasso_+3A_lambda.min.ratio">lambda.min.ratio</code></td>
<td>
<p>Ratio that determines the minimum value of &quot;lambda&quot;
when automatically generating a &quot;lambda&quot; sequence. If &quot;lambda&quot; is not
NULL, &quot;lambda.min.ratio&quot; is ignored. Default is 1e-4</p>
</td></tr>
<tr><td><code id="galasso_+3A_lambda">lambda</code></td>
<td>
<p>Optional numeric vector of lambdas to fit. If NULL,
<code>galasso</code> will automatically generate a lambda sequence based off
of <code>nlambda</code> and <code>lambda.min.ratio</code>. Default is NULL</p>
</td></tr>
<tr><td><code id="galasso_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of iterations to run. Default is 10000</p>
</td></tr>
<tr><td><code id="galasso_+3A_eps">eps</code></td>
<td>
<p>Tolerance for convergence. Default is 1e-5</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>galasso</code> works by adding a group penalty to the aggregated objective
function to ensure selection consistency across imputations. The objective
function is:
</p>
<p style="text-align: center;"><code class="reqn">argmin_{\beta_{jk}} - L(\beta_{jk}| X_{ijk}, Y_{ik})</code>
</p>

<p style="text-align: center;"><code class="reqn">+ \lambda * \Sigma_{j=1}^{p} \hat{a}_j * pf_j * \sqrt{\Sigma_{k=1}^{m} \beta_{jk}^2}</code>
</p>

<p>Where L is the log likelihood,<code>a</code> is the adaptive weights, and
<code>pf</code> is the penalty factor. Simulations suggest that the &quot;stacked&quot;
objective function approach (i.e., <code>saenet</code>) tends to be more
computationally efficient and have better estimation and selection
properties. However, the advantage of <code>galasso</code> is that it allows one
to look at the differences between coefficient estimates across imputations.
</p>


<h3>Value</h3>

<p>An object with type galasso and subtype
galasso.gaussian or galasso.binomial, depending on which family was used.
Both subtypes have 4 elements:
</p>

<dl>
<dt>lambda</dt><dd><p>Sequence of lambda fit.</p>
</dd>
<dt>coef</dt><dd><p>a list of length D containing the coefficient estimates from running 
galasso at each value of lambda. Each element in the list is a nlambda x (p+1) matrix.</p>
</dd>
<dt>df</dt><dd><p>Number of nonzero betas at each value of lambda.</p>
</dd>
</dl>



<h3>References</h3>

<p>Du, J., Boss, J., Han, P., Beesley, L. J., Kleinsasser, M., Goutman, S. A., ... 
&amp; Mukherjee, B. (2022). Variable selection with multiply-imputed datasets: 
choosing between stacked and grouped methods. Journal of Computational and 
Graphical Statistics, 31(4), 1063-1075. &lt;doi:10.1080/10618600.2022.2035739&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(miselect)
library(mice)

mids &lt;- mice(miselect.df, m = 5, printFlag = FALSE)
dfs &lt;- lapply(1:5, function(i) complete(mids, action = i))

# Generate list of imputed design matrices and imputed responses
x &lt;- list()
y &lt;- list()
for (i in 1:5) {
    x[[i]] &lt;- as.matrix(dfs[[i]][, paste0("X", 1:20)])
    y[[i]] &lt;- dfs[[i]]$Y
}

pf       &lt;- rep(1, 20)
adWeight &lt;- rep(1, 20)

fit &lt;- galasso(x, y, pf, adWeight)

</code></pre>

<hr>
<h2 id='miselect.df'>Synthetic Example Data For &quot;miselect&quot;</h2><span id='topic+miselect.df'></span>

<h3>Description</h3>

<p>This synthetic data is taken from the first simulation case from the miselect
paper
</p>


<h3>Usage</h3>

<pre><code class='language-R'>miselect.df
</code></pre>


<h3>Format</h3>

<p>A data.frame with 500 observations on 21 variables:
</p>

<dl>
<dt>Y</dt><dd><p>Binary response.</p>
</dd>
<dt>X1-X20</dt><dd><p>Covariates with missing data.</p>
</dd>
</dl>


<hr>
<h2 id='print.cv.galasso'>Print cv.galasso Objects</h2><span id='topic+print.cv.galasso'></span>

<h3>Description</h3>

<p><code>print.cv.galasso</code> print the fit and returns it invisibly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.galasso'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.cv.galasso_+3A_x">x</code></td>
<td>
<p>An object of type &quot;cv.galasso&quot; to print</p>
</td></tr>
<tr><td><code id="print.cv.galasso_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods</p>
</td></tr>
</table>

<hr>
<h2 id='print.cv.saenet'>Print cv.saenet Objects</h2><span id='topic+print.cv.saenet'></span>

<h3>Description</h3>

<p><code>print.cv.saenet</code> print the fit and returns it invisibly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.saenet'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.cv.saenet_+3A_x">x</code></td>
<td>
<p>An object of type &quot;cv.saenet&quot; to print</p>
</td></tr>
<tr><td><code id="print.cv.saenet_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods</p>
</td></tr>
</table>

<hr>
<h2 id='saenet'>Multiple Imputation Stacked Adaptive Elastic Net</h2><span id='topic+saenet'></span>

<h3>Description</h3>

<p>Fits an adaptive elastic net for multiply imputed data. The data is stacked
and is penalized that each imputation selects the same betas at each value
of lambda. &quot;saenet&quot; supports both continuous and binary responses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>saenet(
  x,
  y,
  pf,
  adWeight,
  weights,
  family = c("gaussian", "binomial"),
  alpha = 1,
  nlambda = 100,
  lambda.min.ratio = ifelse(isTRUE(all.equal(adWeight, rep(1, p))), 0.001, 1e-06),
  lambda = NULL,
  maxit = 1000,
  eps = 1e-05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="saenet_+3A_x">x</code></td>
<td>
<p>A length <code>m</code> list of <code>n * p</code> numeric matrices. No matrix
should contain an intercept, or any missing values</p>
</td></tr>
<tr><td><code id="saenet_+3A_y">y</code></td>
<td>
<p>A length <code>m</code> list of length <code>n</code> numeric response vectors.
No vector should contain missing values</p>
</td></tr>
<tr><td><code id="saenet_+3A_pf">pf</code></td>
<td>
<p>Penalty factor. Can be used to differentially penalize certain
variables</p>
</td></tr>
<tr><td><code id="saenet_+3A_adweight">adWeight</code></td>
<td>
<p>Numeric vector of length p representing the adaptive weights
for the L1 penalty</p>
</td></tr>
<tr><td><code id="saenet_+3A_weights">weights</code></td>
<td>
<p>Numeric vector of length n containing the proportion observed
(non-missing) for each row in the un-imputed data.</p>
</td></tr>
<tr><td><code id="saenet_+3A_family">family</code></td>
<td>
<p>The type of response. &quot;gaussian&quot; implies a continuous response
and &quot;binomial&quot; implies a binary response. Default is &quot;gaussian&quot;.</p>
</td></tr>
<tr><td><code id="saenet_+3A_alpha">alpha</code></td>
<td>
<p>Elastic net parameter. Can be a vector to cross validate over.
Default is 1</p>
</td></tr>
<tr><td><code id="saenet_+3A_nlambda">nlambda</code></td>
<td>
<p>Length of automatically generated &quot;lambda&quot; sequence. If
&quot;lambda&quot; is non NULL, &quot;nlambda&quot; is ignored. Default is 100</p>
</td></tr>
<tr><td><code id="saenet_+3A_lambda.min.ratio">lambda.min.ratio</code></td>
<td>
<p>Ratio that determines the minimum value of &quot;lambda&quot;
when automatically generating a &quot;lambda&quot; sequence. If &quot;lambda&quot; is not
NULL, &quot;lambda.min.ratio&quot; is ignored. Default is 1e-3</p>
</td></tr>
<tr><td><code id="saenet_+3A_lambda">lambda</code></td>
<td>
<p>Optional numeric vector of lambdas to fit. If NULL,
<code>galasso</code> will automatically generate a lambda sequence based off
of <code>nlambda</code> and <code>lambda.min.ratio</code>. Default is NULL</p>
</td></tr>
<tr><td><code id="saenet_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of iterations to run. Default is 1000</p>
</td></tr>
<tr><td><code id="saenet_+3A_eps">eps</code></td>
<td>
<p>Tolerance for convergence. Default is 1e-5</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>saenet</code> works by stacking the multiply imputed data into a single
matrix and running a weighted adaptive elastic net on it. The objective
function is:
</p>
<p style="text-align: center;"><code class="reqn"> argmin_{\beta_j} -\frac{1}{n} \sum_{k=1}^{m} \sum_{i=1}^{n} o_i * L(\beta_j|Y_{ik},X_{ijk})</code>
</p>

<p style="text-align: center;"><code class="reqn"> + \lambda (\alpha \sum_{j=1}^{p} \hat{a}_j * pf_j |\beta_{j}|</code>
</p>

<p style="text-align: center;"><code class="reqn">+ (1 - \alpha)\sum_{j=1}^{p} pf_j * \beta_{j}^2)</code>
</p>

<p>Where L is the log likelihood, <code>o = w / m</code>, <code>a</code> is the
adaptive weights, and <code>pf</code> is the penalty factor. Simulations suggest
that the &quot;stacked&quot; objective function approach (i.e., <code>saenet</code>) tends
to be more computationally efficient and have better estimation and selection
properties. However, the advantage of <code>galasso</code> is that it allows one
to look at the differences between coefficient estimates across imputations.
</p>


<h3>Value</h3>

<p>An object with type saenet and subtype
saenet.gaussian or saenet.binomial, depending on which family was used.
Both subtypes have 4 elements:
</p>

<dl>
<dt>lambda</dt><dd><p>Sequence of lambda fit.</p>
</dd>
<dt>coef</dt><dd><p>nlambda x nalpha x p + 1 tensor representing the estimated betas
at each value of lambda and alpha.</p>
</dd>
<dt>df</dt><dd><p>Number of nonzero betas at each value of lambda and alpha.</p>
</dd>
</dl>



<h3>References</h3>

<p>Du, J., Boss, J., Han, P., Beesley, L. J., Kleinsasser, M., Goutman, S. A., ... 
&amp; Mukherjee, B. (2022). Variable selection with multiply-imputed datasets: 
choosing between stacked and grouped methods. Journal of Computational and 
Graphical Statistics, 31(4), 1063-1075. &lt;doi:10.1080/10618600.2022.2035739&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(miselect)
library(mice)

mids &lt;- mice(miselect.df, m = 5, printFlag = FALSE)
dfs &lt;- lapply(1:5, function(i) complete(mids, action = i))

# Generate list of imputed design matrices and imputed responses
x &lt;- list()
y &lt;- list()
for (i in 1:5) {
    x[[i]] &lt;- as.matrix(dfs[[i]][, paste0("X", 1:20)])
    y[[i]] &lt;- dfs[[i]]$Y
}

# Calculate observational weights
weights  &lt;- 1 - rowMeans(is.na(miselect.df))
pf       &lt;- rep(1, 20)
adWeight &lt;- rep(1, 20)

# Since 'Y' is a binary variable, we use 'family = "binomial"'
fit &lt;- saenet(x, y, pf, adWeight, weights, family = "binomial")

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
