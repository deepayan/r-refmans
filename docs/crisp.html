<!DOCTYPE html><html><head><title>Help for package crisp</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {crisp}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#crisp-package'><p>crisp: A package for fitting a model that partitions the covariate space into blocks in a data-adaptive way.</p></a></li>
<li><a href='#crisp'><p>Convex Regression with Interpretable Sharp Partitions (CRISP).</p></a></li>
<li><a href='#crispCV'><p>CRISP with Tuning Parameter Selection via Cross-Validation.</p></a></li>
<li><a href='#plot'><p>Plots Fit from <code>crisp</code> or <code>crispCV</code>.</p></a></li>
<li><a href='#plot.cvError'><p>Plots Cross-Validation Curve for <code>crispCV</code>.</p></a></li>
<li><a href='#plot.sim.data'><p>Plot Mean Model for Data.</p></a></li>
<li><a href='#predict'><p>Predicts Observations for a New Covariate Matrix using Fit from <code>crisp</code> or <code>crispCV</code>.</p></a></li>
<li><a href='#sim.data'><p>Simulate Data to Use with <code>crisp</code>.</p></a></li>
<li><a href='#summary'><p>Summarizes Fit from <code>crisp</code> or <code>crispCV</code>.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Fits a Model that Partitions the Covariate Space into Blocks in
a Data- Adaptive Way</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Ashley Petersen</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ashley Petersen &lt;ashleyjpete@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements convex regression with interpretable sharp partitions
    (CRISP), which considers the problem of predicting an outcome variable on the basis of two covariates, using an interpretable yet non-additive model. CRISP partitions the covariate space into blocks in a data-adaptive way, and fits a mean model within each block. Unlike other partitioning methods, CRISP is fit using a non-greedy approach by solving a convex optimization problem, resulting in low-variance fits. More details are provided in Petersen, A., Simon, N., and Witten, D. (2016). Convex Regression with Interpretable Sharp Partitions. Journal of Machine Learning Research, 17(94): 1-31 <a href="http://jmlr.org/papers/volume17/15-344/15-344.pdf">http://jmlr.org/papers/volume17/15-344/15-344.pdf</a>.</td>
</tr>
<tr>
<td>Imports:</td>
<td>Matrix, MASS, stats, methods, grDevices, graphics</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>5.0.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-01-04 15:50:10 UTC; ashleypetersen</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-01-05 10:39:31</td>
</tr>
</table>
<hr>
<h2 id='crisp-package'>crisp: A package for fitting a model that partitions the covariate space into blocks in a data-adaptive way.</h2><span id='topic+crisp-package'></span>

<h3>Description</h3>

<p>This package is called crisp for &quot;Convex Regression with Interpretable Sharp Partitions&quot;,
which considers the problem of predicting an outcome variable on the basis of two covariates,
using an interpretable yet non-additive model. CRISP partitions the covariate space into
blocks in a data-adaptive way, and fits a mean model within each block.
Unlike other partitioning methods, CRISP is fit using a non-greedy approach by solving a
convex optimization problem, resulting in low-variance fits. More details are provided
in Petersen, A., Simon, N., and Witten, D. (2016). Convex Regression with Interpretable
Sharp Partitions. Journal of Machine Learning Research, 17(94): 1-31 &lt;http://jmlr.org/papers/volume17/15-344/15-344.pdf&gt;.
</p>


<h3>Details</h3>

<p>The main functions are: (1)<code><a href="#topic+crisp">crisp</a></code> and (2)<code><a href="#topic+crispCV">crispCV</a></code>. The first function
<code><a href="#topic+crisp">crisp</a></code> fits CRISP for a sequence of tuning parameters and provides the fits
for this entire sequence of tuning parameters. The second function <code><a href="#topic+crispCV">crispCV</a></code> considers
a sequence of tuning parameters and provides the fits, but also returns the optimal tuning parameter,
as chosen using K-fold cross-validation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#general example illustrating all functions
#see specific function help pages for details of using each function

#generate data (using a very small 'n' for illustration purposes)
set.seed(1)
data &lt;- sim.data(n = 15, scenario = 2)
#plot the mean model for the scenario from which we generated data
plot(data)

#fit model for a range of tuning parameters, i.e., lambda values
#lambda sequence is chosen automatically if not specified
crisp.out &lt;- crisp(X = data$X, y = data$y)
#or fit model and select lambda using 2-fold cross-validation
#note: use larger 'n.fold' (e.g., 10) in practice
crispCV.out &lt;- crispCV(X = data$X, y = data$y, n.fold = 2)

#summarize all of the fits
summary(crisp.out)
#or just summarize a single fit
#we examine the fit with an index of 25. that is, lambda of
crisp.out$lambda.seq[25]
summary(crisp.out, lambda.index = 25)
#lastly, we can summarize the fit chosen using cross-validation
summary(crispCV.out)
#and also plot the cross-validation error
plot(summary(crispCV.out))
#the lambda chosen by cross-validation is also available using
crispCV.out$lambda.cv

#plot the estimated relationships between two predictors and outcome
#do this for a specific fit
plot(crisp.out, lambda.index = 25)
#or for the fit chosen using cross-validation
plot(crispCV.out)

#we can make predictions for a covariate matrix with new observations
#new.X with 20 observations
new.data &lt;- sim.data(n = 20, scenario = 2)
new.X &lt;- new.data$X
#these will give the same predictions:
yhat1 &lt;- predict(crisp.out, new.X = new.X, lambda.index = crispCV.out$index.cv)
yhat2 &lt;- predict(crispCV.out, new.X = new.X)

## End(Not run)
</code></pre>

<hr>
<h2 id='crisp'>Convex Regression with Interpretable Sharp Partitions (CRISP).</h2><span id='topic+crisp'></span>

<h3>Description</h3>

<p>This function implements CRISP, which considers the problem of predicting an outcome variable on the basis of two covariates, using an interpretable yet non-additive model.
CRISP partitions the covariate space into blocks in a data-adaptive way, and fits a mean model within each block. Unlike other partitioning methods,
CRISP is fit using a non-greedy approach by solving a convex optimization problem, resulting in low-variance fits.
More details are provided in Petersen, A., Simon, N., and Witten, D. (2016). Convex Regression with Interpretable Sharp Partitions. Journal of Machine Learning Research, 17(94): 1-31 &lt;http://jmlr.org/papers/volume17/15-344/15-344.pdf&gt;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crisp(y, X, q = NULL, lambda.min.ratio = 0.01, n.lambda = 50,
  lambda.seq = NULL, rho = 0.1, e_abs = 10^-4, e_rel = 10^-3,
  varyrho = TRUE, double.run = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crisp_+3A_y">y</code></td>
<td>
<p>An n-vector containing the response.</p>
</td></tr>
<tr><td><code id="crisp_+3A_x">X</code></td>
<td>
<p>An n x 2 matrix with each column containing a covariate.</p>
</td></tr>
<tr><td><code id="crisp_+3A_q">q</code></td>
<td>
<p>The desired granularity of the CRISP fit, <code>M.hat</code>, which will be a <code>q</code> by <code>q</code> matrix. <code>M.hat</code>
is a mean matrix whose element <code>M.hat[i,j]</code> contains the mean for pairs of covariate values within a quantile range
of the observed predictors <code>X[,1]</code> and <code>X[,2]</code>. For example, <code>M.hat[1,2]</code> represents the
mean of the observations with the first covariate value less than the <code>1/q</code>-quantile of <code>X[,1]</code>,
and the second covariate value between the <code>1/q</code>- and <code>2/q</code>-quantiles of <code>X[,2]</code>.
If left <code>NULL</code>, then <code>q=n</code> is used when n&lt;100, and <code>q=100</code> is used when n&gt;=100.
We recommend using <code>q&lt;=100</code> as higher values take longer to fit and provide an unneeded amount of granularity.</p>
</td></tr>
<tr><td><code id="crisp_+3A_lambda.min.ratio">lambda.min.ratio</code></td>
<td>
<p>The smallest value for <code>lambda.seq</code>, as a fraction of the maximum lambda value, which is the data-derived
smallest value for which the fit is a constant value. The default is 0.01.</p>
</td></tr>
<tr><td><code id="crisp_+3A_n.lambda">n.lambda</code></td>
<td>
<p>The number of lambda values to consider - the default is 50.</p>
</td></tr>
<tr><td><code id="crisp_+3A_lambda.seq">lambda.seq</code></td>
<td>
<p>A user-supplied sequence of positive lambda values to consider. The typical usage is to calculate
<code>lambda.seq</code> using <code>lambda.min.ratio</code> and <code>n.lambda</code>, but providing <code>lambda.seq</code> overrides this. If provided,
<code>lambda.seq</code> should be a decreasing sequence of values, since CRISP relies on warm starts for speed.
Thus fitting the model for a whole sequence of lambda values is often faster than fitting for a single lambda value.</p>
</td></tr>
<tr><td><code id="crisp_+3A_rho">rho</code></td>
<td>
<p>The penalty parameter for our ADMM algorithm. The default is 0.1.</p>
</td></tr>
<tr><td><code id="crisp_+3A_e_abs">e_abs</code>, <code id="crisp_+3A_e_rel">e_rel</code></td>
<td>
<p>Values used in the stopping criterion for our ADMM algorithm, and discussed in Appendix C.2 of the CRISP paper.</p>
</td></tr>
<tr><td><code id="crisp_+3A_varyrho">varyrho</code></td>
<td>
<p>Should <code>rho</code> be varied from iteration to iteration? This is discussed in Appendix C.3 of the CRISP paper.</p>
</td></tr>
<tr><td><code id="crisp_+3A_double.run">double.run</code></td>
<td>
<p>The initial complete run of our ADMM algorithm will yield sparsity in z_1i and z_2i, but not
necessarily exact equality of the rows and columns of <code>M.hat</code>. If <code>double.run</code> is <code>TRUE</code>, then the algorithm
is run a second time to obtain <code>M.hat</code> with exact equality of the appropriate rows and columns. This issue
is discussed further in Appendix C.4 of the CRISP paper.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>crisp</code>, which can be summarized using <code><a href="#topic+summary">summary</a></code>, plotted using <code><a href="#topic+plot">plot</a></code>, and used to predict outcome values for new covariates using <code><a href="#topic+predict">predict</a></code>.
</p>

<ul>
<li><p><code>M.hat.list</code>: A list of length <code>n.lambda</code> giving <code>M.hat</code> for each value of <code>lambda.seq</code>.
</p>
</li>
<li><p><code>num.blocks</code>: A vector of length <code>n.lambda</code> giving the number of blocks in <code>M.hat</code> for each value of <code>lambda.seq</code>.
</p>
</li>
<li><p><code>obj.vec</code>: A vector of length <code>n.lambda</code> giving the value of the objective of Eqn (4) in the CRISP paper for each value of <code>lambda.seq</code>.
</p>
</li>
<li><p>Other elements: As specified by the user.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+crispCV">crispCV</a></code>, <code><a href="#topic+plot">plot</a></code>, <code><a href="#topic+summary">summary</a></code>, <code><a href="#topic+predict">predict</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#See ?'crisp-package' for a full example of how to use this package

#generate data (using a very small 'n' for illustration purposes)
set.seed(1)
data &lt;- sim.data(n = 15, scenario = 2)

#fit model for a range of tuning parameters, i.e., lambda values
#lambda sequence is chosen automatically if not specified
crisp.out &lt;- crisp(X = data$X, y = data$y)

## End(Not run)
</code></pre>

<hr>
<h2 id='crispCV'>CRISP with Tuning Parameter Selection via Cross-Validation.</h2><span id='topic+crispCV'></span>

<h3>Description</h3>

<p>This function implements CRISP, which considers the problem of predicting an outcome variable on the basis of two covariates, using an interpretable yet non-additive model.
CRISP partitions the covariate space into blocks in a data-adaptive way, and fits a mean model within each block. Unlike other partitioning methods,
CRISP is fit using a non-greedy approach by solving a convex optimization problem, resulting in low-variance fits. This function differs
from the <code><a href="#topic+crisp">crisp</a></code> function in that the tuning parameter, lambda, is automatically selected using K-fold cross-validation.
More details are provided in Petersen, A., Simon, N., and Witten, D. (2016). Convex Regression with Interpretable Sharp Partitions. Journal of Machine Learning Research, 17(94): 1-31 &lt;http://jmlr.org/papers/volume17/15-344/15-344.pdf&gt;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crispCV(y, X, q = NULL, lambda.min.ratio = 0.01, n.lambda = 50,
  lambda.seq = NULL, fold = NULL, n.fold = NULL, seed = NULL,
  within1SE = FALSE, rho = 0.1, e_abs = 10^-4, e_rel = 10^-3,
  varyrho = TRUE, double.run = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crispCV_+3A_y">y</code></td>
<td>
<p>An n-vector containing the response.</p>
</td></tr>
<tr><td><code id="crispCV_+3A_x">X</code></td>
<td>
<p>An n x 2 matrix with each column containing a covariate.</p>
</td></tr>
<tr><td><code id="crispCV_+3A_q">q</code></td>
<td>
<p>The desired granularity of the CRISP fit, <code>M.hat</code>, which will be a <code>q</code> by <code>q</code> matrix. <code>M.hat</code>
is a mean matrix whose element <code>M.hat[i,j]</code> contains the mean for pairs of covariate values within a quantile range
of the observed predictors <code>X[,1]</code> and <code>X[,2]</code>. For example, <code>M.hat[1,2]</code> represents the
mean of the observations with the first covariate value less than the <code>1/q</code>-quantile of <code>X[,1]</code>,
and the second covariate value between the <code>1/q</code>- and <code>2/q</code>-quantiles of <code>X[,2]</code>.
If left <code>NULL</code>, then <code>q=n</code> is used when n&lt;100, and <code>q=100</code> is used when n&gt;=100.
We recommend using <code>q&lt;=100</code> as higher values take longer to fit and provide an unneeded amount of granularity.</p>
</td></tr>
<tr><td><code id="crispCV_+3A_lambda.min.ratio">lambda.min.ratio</code></td>
<td>
<p>The smallest value for <code>lambda.seq</code>, as a fraction of the maximum lambda value, which is the data-derived
smallest value for which the fit is a constant value. The default is 0.01.</p>
</td></tr>
<tr><td><code id="crispCV_+3A_n.lambda">n.lambda</code></td>
<td>
<p>The number of lambda values to consider - the default is 50.</p>
</td></tr>
<tr><td><code id="crispCV_+3A_lambda.seq">lambda.seq</code></td>
<td>
<p>A user-supplied sequence of positive lambda values to consider. The typical usage is to calculate
<code>lambda.seq</code> using <code>lambda.min.ratio</code> and <code>n.lambda</code>, but providing <code>lambda.seq</code> overrides this. If provided,
<code>lambda.seq</code> should be a decreasing sequence of values, since CRISP relies on warm starts for speed.
Thus fitting the model for a whole sequence of lambda values is often faster than fitting for a single lambda value.</p>
</td></tr>
<tr><td><code id="crispCV_+3A_fold">fold</code></td>
<td>
<p>User-supplied fold numbers for cross-validation. If supplied, <code>fold</code> should be an n-vector with entries in 1,...,K when doing K-fold cross-validation. The default is to choose <code>fold</code> using <code>n.fold</code>.</p>
</td></tr>
<tr><td><code id="crispCV_+3A_n.fold">n.fold</code></td>
<td>
<p>The number of folds, K, to use for the K-fold cross-validation selection of the tuning parameter, lambda. The default is 10 - specification of <code>fold</code> overrides use of <code>n.fold</code>.</p>
</td></tr>
<tr><td><code id="crispCV_+3A_seed">seed</code></td>
<td>
<p>An optional number used with <code>set.seed()</code> at the beginning of the function. This is only relevant if <code>fold</code> is not specified by the user.</p>
</td></tr>
<tr><td><code id="crispCV_+3A_within1se">within1SE</code></td>
<td>
<p>Logical value indicating how cross-validated tuning parameters should be chosen. If <code>within1SE=TRUE</code>, lambda is chosen to be the value corresponding to the most sparse model with cross-validation error within one standard error of the minimum cross-validation error. If <code>within1SE=FALSE</code>, lambda is chosen to be the value corresponding to the minimum cross-validation error.</p>
</td></tr>
<tr><td><code id="crispCV_+3A_rho">rho</code></td>
<td>
<p>The penalty parameter for our ADMM algorithm. The default is 0.1.</p>
</td></tr>
<tr><td><code id="crispCV_+3A_e_abs">e_abs</code>, <code id="crispCV_+3A_e_rel">e_rel</code></td>
<td>
<p>Values used in the stopping criterion for our ADMM algorithm, and discussed in Appendix C.2 of the CRISP paper.</p>
</td></tr>
<tr><td><code id="crispCV_+3A_varyrho">varyrho</code></td>
<td>
<p>Should <code>rho</code> be varied from iteration to iteration? This is discussed in Appendix C.3 of the CRISP paper.</p>
</td></tr>
<tr><td><code id="crispCV_+3A_double.run">double.run</code></td>
<td>
<p>The initial complete run of our ADMM algorithm will yield sparsity in z_1i and z_2i, but not
necessarily exact equality of the rows and columns of <code>M.hat</code>. If <code>double.run</code> is <code>TRUE</code>, then the algorithm
is run a second time to obtain <code>M.hat</code> with exact equality of the appropriate rows and columns. This issue
is discussed further in Appendix C.4 of the CRISP paper.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>crispCV</code>, which can be summarized using <code><a href="#topic+summary">summary</a></code>, plotted using <code><a href="#topic+plot">plot</a></code>, and used to predict outcome values for new covariates using <code><a href="#topic+predict">predict</a></code>.
</p>

<ul>
<li><p><code>lambda.cv</code>: Optimal lambda value chosen by K-fold cross-validation.
</p>
</li>
<li><p><code>index.cv</code>: The index of the model corresponding to the chosen tuning parameter, <code>lambda.cv</code>. That is, <code>lambda.cv=crisp.out$lambda.seq[index.cv]</code>.
</p>
</li>
<li><p><code>crisp.out</code>: An object of class <code>crisp</code> returned by <code><a href="#topic+crisp">crisp</a></code>.
</p>
</li>
<li><p><code>mean.cv.error</code>: An m-vector containing cross-validation error where m is the length of <code>lambda.seq</code>. Note that <code>mean.cv.error[i]</code> contains the cross-validation error for the tuning parameter <code>crisp.out$lambda.seq[i]</code>.
</p>
</li>
<li><p><code>se.cv.error</code>: An m-vector containing cross-validation standard error where m is the length of <code>lambda.seq</code>. Note that <code>se.cv.error[i]</code> contains the standard error of the cross-validation error for the tuning parameter <code>crisp.out$lambda.seq[i]</code>.
</p>
</li>
<li><p>Other elements: As specified by the user.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+crisp">crisp</a></code>, <code><a href="#topic+plot">plot</a></code>, <code><a href="#topic+summary">summary</a></code>, <code><a href="#topic+predict">predict</a></code>, <code><a href="#topic+plot.cvError">plot.cvError</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#See ?'crisp-package' for a full example of how to use this package

#generate data (using a very small 'n' for illustration purposes)
set.seed(1)
data &lt;- sim.data(n = 15, scenario = 2)

#fit model and select lambda using 2-fold cross-validation
#note: use larger 'n.fold' (e.g., 10) in practice
crispCV.out &lt;- crispCV(X = data$X, y = data$y, n.fold = 2)

## End(Not run)
</code></pre>

<hr>
<h2 id='plot'>Plots Fit from <code><a href="#topic+crisp">crisp</a></code> or <code><a href="#topic+crispCV">crispCV</a></code>.</h2><span id='topic+plot'></span><span id='topic+plot.crisp'></span><span id='topic+plot.crispCV'></span>

<h3>Description</h3>

<p>This function plots fit of the class <code>crispCV</code>, or class <code>crisp</code> with a user-specified tuning parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'crisp'
plot(x, lambda.index, title = NULL, x1lab = NULL,
  x2lab = NULL, min = NULL, max = NULL, cex.axis = 1, cex.lab = 1,
  color1 = "seagreen1", color2 = "steelblue1", color3 = "darkorchid4",
  ...)

## S3 method for class 'crispCV'
plot(x, title = NULL, x1lab = NULL, x2lab = NULL,
  min = NULL, max = NULL, cex.axis = 1, cex.lab = 1,
  color1 = "seagreen1", color2 = "steelblue1", color3 = "darkorchid4",
  ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_+3A_x">x</code></td>
<td>
<p>An object of class <code>crisp</code> or <code>crispCV</code>, which result from running the <code><a href="#topic+crisp">crisp</a></code> or <code><a href="#topic+crispCV">crispCV</a></code> functions, respectively.</p>
</td></tr>
<tr><td><code id="plot_+3A_lambda.index">lambda.index</code></td>
<td>
<p>The index for the desired value of lambda, i.e., <code>x$lambda.seq[lambda.index]</code>.</p>
</td></tr>
<tr><td><code id="plot_+3A_title">title</code></td>
<td>
<p>The title of the plot. By default, the value of lambda is noted.</p>
</td></tr>
<tr><td><code id="plot_+3A_x1lab">x1lab</code></td>
<td>
<p>The axis label for the first covariate. By default, it is &quot;X1&quot;.</p>
</td></tr>
<tr><td><code id="plot_+3A_x2lab">x2lab</code></td>
<td>
<p>The axis label for the second covariate. By default, it is &quot;X2&quot;.</p>
</td></tr>
<tr><td><code id="plot_+3A_min">min</code>, <code id="plot_+3A_max">max</code></td>
<td>
<p>The minimum and maximum y-values, respectively, to use when plotting the fit. By default, they are chosen to be the minimum and maximum of all of the fits, i.e., the minimum and maximum of <code>unlist(x$M.hat.list)</code>.</p>
</td></tr>
<tr><td><code id="plot_+3A_cex.axis">cex.axis</code></td>
<td>
<p>The magnification to be used for axis annotation relative to the current setting of <code>cex</code>.</p>
</td></tr>
<tr><td><code id="plot_+3A_cex.lab">cex.lab</code></td>
<td>
<p>The magnification to be used for x and y labels relative to the current setting of <code>cex</code>.</p>
</td></tr>
<tr><td><code id="plot_+3A_color1">color1</code>, <code id="plot_+3A_color2">color2</code>, <code id="plot_+3A_color3">color3</code></td>
<td>
<p>The colors to use to create the color gradient for plotting the response values. At least the first two must be specified, or the defaults of <code>"seagreen1"</code>, <code>"steelblue1"</code>, and <code>"darkorchid4"</code> will be used.</p>
</td></tr>
<tr><td><code id="plot_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed, which are ignored in this function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#See ?'crisp-package' for a full example of how to use this package

#generate data (using a very small 'n' for illustration purposes)
set.seed(1)
data &lt;- sim.data(n = 15, scenario = 2)

#fit model for a range of tuning parameters, i.e., lambda values
#lambda sequence is chosen automatically if not specified
crisp.out &lt;- crisp(X = data$X, y = data$y)
#or fit model and select lambda using 2-fold cross-validation
#note: use larger 'n.fold' (e.g., 10) in practice
crispCV.out &lt;- crispCV(X = data$X, y = data$y, n.fold = 2)

#plot the estimated relationships between two predictors and outcome
#do this for a specific fit
plot(crisp.out, lambda.index = 25)
#or for the fit chosen using cross-validation
plot(crispCV.out)

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.cvError'>Plots Cross-Validation Curve for <code><a href="#topic+crispCV">crispCV</a></code>.</h2><span id='topic+plot.cvError'></span>

<h3>Description</h3>

<p>This function plots the cross-validation curve for a series of models fit using <code><a href="#topic+crispCV">crispCV</a></code>. The cross-validation error with +/-1 standard error is plotted for each value of lambda considered in the call to <code><a href="#topic+crispCV">crispCV</a></code> with a dotted vertical line indicating the chosen lambda.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cvError'
plot(x, showSE = T, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cvError_+3A_x">x</code></td>
<td>
<p>An object of class <code>cvError</code>, which results from calling <code><a href="#topic+summary">summary</a></code> on an object of class <code><a href="#topic+crispCV">crispCV</a></code>.</p>
</td></tr>
<tr><td><code id="plot.cvError_+3A_showse">showSE</code></td>
<td>
<p>A logical value indicating whether the standard error of the curve should be plotted.</p>
</td></tr>
<tr><td><code id="plot.cvError_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed, which are ignored in this function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#See ?'crisp-package' for a full example of how to use this package

#generate data (using a very small 'n' for illustration purposes)
set.seed(1)
data &lt;- sim.data(n = 15, scenario = 2)

#fit model and select lambda using 2-fold cross-validation
#note: use larger 'n.fold' (e.g., 10) in practice
crispCV.out &lt;- crispCV(X = data$X, y = data$y, n.fold = 2)

#plot the cross-validation error
plot(summary(crispCV.out))

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.sim.data'>Plot Mean Model for Data.</h2><span id='topic+plot.sim.data'></span>

<h3>Description</h3>

<p>This function plots the mean model for the scenario from which data was generated using <code><a href="#topic+sim.data">sim.data</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sim.data'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.sim.data_+3A_x">x</code></td>
<td>
<p>An object of class <code>sim.data</code>, which results from running the <code><a href="#topic+sim.data">sim.data</a></code> function.</p>
</td></tr>
<tr><td><code id="plot.sim.data_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed, which are ignored in this function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sim.data">sim.data</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See ?'crisp-package' for a full example of how to use this package

#generate data (using a very small 'n' for illustration purposes)
set.seed(1)
data &lt;- sim.data(n = 15, scenario = 2)

#plot the mean model for the scenario from which we generated data
plot(data)
</code></pre>

<hr>
<h2 id='predict'>Predicts Observations for a New Covariate Matrix using Fit from <code><a href="#topic+crisp">crisp</a></code> or <code><a href="#topic+crispCV">crispCV</a></code>.</h2><span id='topic+predict'></span><span id='topic+predict.crisp'></span><span id='topic+predict.crispCV'></span>

<h3>Description</h3>

<p>This function makes predictions for a specified covariate matrix for a fit of the class <code>crispCV</code>, or class <code>crisp</code> with a user-specified tuning parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'crisp'
predict(object, new.X, lambda.index, ...)

## S3 method for class 'crispCV'
predict(object, new.X, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_+3A_object">object</code></td>
<td>
<p>An object of class <code>crisp</code> or <code>crispCV</code>, which result from running the <code><a href="#topic+crisp">crisp</a></code> or <code><a href="#topic+crispCV">crispCV</a></code> functions, respectively.</p>
</td></tr>
<tr><td><code id="predict_+3A_new.x">new.X</code></td>
<td>
<p>The covariate matrix for which to make predictions.</p>
</td></tr>
<tr><td><code id="predict_+3A_lambda.index">lambda.index</code></td>
<td>
<p>The index for the desired value of lambda, i.e., <code>object$lambda.seq[lambda.index]</code>.</p>
</td></tr>
<tr><td><code id="predict_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed, which are ignored in this function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ith prediction is made to be the value of <code>object$M.hat.list[[lambda.index]]</code> corresponding to the pair of covariates closest (in Euclidean distance) to <code>new.X[i,]</code>.
</p>


<h3>Value</h3>

<p>A vector containing the fitted y values for <code>new.X</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#See ?'crisp-package' for a full example of how to use this package

#generate data (using a very small 'n' for illustration purposes)
set.seed(1)
data &lt;- sim.data(n = 15, scenario = 2)

#fit model for a range of tuning parameters, i.e., lambda values
#lambda sequence is chosen automatically if not specified
crisp.out &lt;- crisp(X = data$X, y = data$y)
#or fit model and select lambda using 2-fold cross-validation
#note: use larger 'n.fold' (e.g., 10) in practice
crispCV.out &lt;- crispCV(X = data$X, y = data$y, n.fold = 2)

#we can make predictions for a covariate matrix with new observations
#new.X with 20 observations
new.data &lt;- sim.data(n = 20, scenario = 2)
new.X &lt;- new.data$X
#these will give the same predictions:
yhat1 &lt;- predict(crisp.out, new.X = new.X, lambda.index = crispCV.out$index.cv)
yhat2 &lt;- predict(crispCV.out, new.X = new.X)

## End(Not run)
</code></pre>

<hr>
<h2 id='sim.data'>Simulate Data to Use with <code><a href="#topic+crisp">crisp</a></code>.</h2><span id='topic+sim.data'></span>

<h3>Description</h3>

<p>This function generates data according to the simulation scenarios considered in Section 3 of the CRISP paper (and plotted in Figure 2 of the paper).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.data(n, scenario, noise = 1, X = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim.data_+3A_n">n</code></td>
<td>
<p>The number of observations.</p>
</td></tr>
<tr><td><code id="sim.data_+3A_scenario">scenario</code></td>
<td>
<p>The simulation scenario to use. Options are 1 (additive model), 2 (interaction model), 3 ('tetris' model), or 4 (smooth model), which correspond to the simulation scenarios of Section 3 of the CRISP paper. Each scenario has two covariates.</p>
</td></tr>
<tr><td><code id="sim.data_+3A_noise">noise</code></td>
<td>
<p>The standard deviation of the normally-distributed noise that is added to the signal.</p>
</td></tr>
<tr><td><code id="sim.data_+3A_x">X</code></td>
<td>
<p>The <code>n</code> x 2 covariate matrix, which is automatically generated if not specified.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing:
</p>

<ul>
<li><p><code>X</code>: An <code>n</code> x 2 covariate matrix.
</p>
</li>
<li><p><code>y</code>: An <code>n</code>-vector containing the response values.
</p>
</li>
<li><p>Other elements: As specified by the user.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+crisp">crisp</a></code>, <code><a href="#topic+crispCV">crispCV</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See ?'crisp-package' for a full example of how to use this package

#generate data (using a very small 'n' for illustration purposes)
set.seed(1)
data &lt;- sim.data(n = 15, scenario = 2)

#plot the mean model for the scenario from which we generated data
plot(data)
</code></pre>

<hr>
<h2 id='summary'>Summarizes Fit from <code><a href="#topic+crisp">crisp</a></code> or <code><a href="#topic+crispCV">crispCV</a></code>.</h2><span id='topic+summary'></span><span id='topic+summary.crisp'></span><span id='topic+summary.crispCV'></span>

<h3>Description</h3>

<p>This function summarizes fit of the class <code>crispCV</code> or <code>crisp</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'crisp'
summary(object, lambda.index = NULL, ...)

## S3 method for class 'crispCV'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary_+3A_object">object</code></td>
<td>
<p>An object of class <code>crisp</code> or <code>crispCV</code>, which result from running the <code><a href="#topic+crisp">crisp</a></code> or <code><a href="#topic+crispCV">crispCV</a></code> functions, respectively.</p>
</td></tr>
<tr><td><code id="summary_+3A_lambda.index">lambda.index</code></td>
<td>
<p>The index for the desired value of lambda, i.e., <code>object$lambda.seq[lambda.index]</code>. By default, fits for all values of lambda are summarized.</p>
</td></tr>
<tr><td><code id="summary_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed, which are ignored in this function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#See ?'crisp-package' for a full example of how to use this package
#generate data (using a very small 'n' for illustration purposes)
set.seed(1)
data &lt;- sim.data(n = 15, scenario = 2)

#fit model for a range of tuning parameters, i.e., lambda values
#lambda sequence is chosen automatically if not specified
crisp.out &lt;- crisp(X = data$X, y = data$y)
#or fit model and select lambda using 2-fold cross-validation
#note: use larger 'n.fold' (e.g., 10) in practice
crispCV.out &lt;- crispCV(X = data$X, y = data$y, n.fold = 2)

#summarize all of the fits
summary(crisp.out)
#or just summarize a single fit
#we examine the fit with an index of 25. that is, lambda of
crisp.out$lambda.seq[25]
summary(crisp.out, lambda.index = 25)
#lastly, we can summarize the fit chosen using cross-validation
summary(crispCV.out)

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
