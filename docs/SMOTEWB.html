<!DOCTYPE html><html><head><title>Help for package SMOTEWB</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SMOTEWB}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ADASYN'><p>Adaptive Synthetic Sampling</p></a></li>
<li><a href='#BLSMOTE'><p>Borderline Synthetic Minority Oversampling Technique</p></a></li>
<li><a href='#GSMOTE'><p>Geometric Synthetic Minority Oversamplnig Technique (GSMOTE)</p></a></li>
<li><a href='#ROS'><p>Random Oversampling (ROS)</p></a></li>
<li><a href='#ROSE'><p>Randomly Over Sampling Examples</p></a></li>
<li><a href='#RSLSMOTE'><p>Relocating safe-level SMOTE with minority outcast handling</p></a></li>
<li><a href='#RUS'><p>Random Undersampling (RUS)</p></a></li>
<li><a href='#RWO'><p>Random Walk Oversampling (SMOTE)</p></a></li>
<li><a href='#SLSMOTE'><p>Safe-level Synthetic Minority Oversampling Technique</p></a></li>
<li><a href='#SMOTE'><p>Synthetic Minority Oversampling Technique (SMOTE)</p></a></li>
<li><a href='#SMOTEWB'><p>SMOTE with boosting (SMOTEWB)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Imbalanced Resampling using SMOTE with Boosting (SMOTEWB)</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides the SMOTE with Boosting (SMOTEWB) algorithm. See
      F. SaÄŸlam, M. A. Cengiz (2022) &lt;<a href="https://doi.org/10.1016%2Fj.eswa.2022.117023">doi:10.1016/j.eswa.2022.117023</a>&gt;. It is a
      SMOTE-based resampling technique which creates synthetic data on the links 
      between nearest neighbors. SMOTEWB uses boosting weights to determine where
      to generate new samples and automatically decides the number of neighbors 
      for eacg sample. It is robust to noise and outperforms most of the 
      alternatives according to Matthew Correlation Coefficient metric.
      Alternative resampling methods are also available in the package.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.2)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, FNN, RANN, rpart, Rfast</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-04-08 13:55:07 UTC; sagla</td>
</tr>
<tr>
<td>Author:</td>
<td>Fatih Saglam <a href="https://orcid.org/0000-0002-2084-2008"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Fatih Saglam &lt;saglamf89@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-04-08 15:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ADASYN'>Adaptive Synthetic Sampling</h2><span id='topic+ADASYN'></span>

<h3>Description</h3>

<p>Generates synthetic data for minority class to balance imbalanced
datasets using ADASYN.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ADASYN(x, y, k = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ADASYN_+3A_x">x</code></td>
<td>
<p>feature matrix or data.frame.</p>
</td></tr>
<tr><td><code id="ADASYN_+3A_y">y</code></td>
<td>
<p>a factor class variable with two classes.</p>
</td></tr>
<tr><td><code id="ADASYN_+3A_k">k</code></td>
<td>
<p>number of neighbors. Default is 5.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Adaptive Synthetic Sampling (ADASYN) is an extension of the Synthetic Minority Over-sampling Technique
(SMOTE) algorithm, which is used to generate synthetic examples for the
minority class (He et al., 2008). In contrast to SMOTE, ADASYN adaptively generates synthetic
examples by focusing on the minority class examples that are harder to
learn, meaning those examples that are closer to the decision boundary.
</p>
<p>Note: Much faster than <code>smotefamily::ADAS()</code>.
</p>


<h3>Value</h3>

<p>a list with resampled dataset.
</p>
<table>
<tr><td><code>x_new</code></td>
<td>
<p>Resampled feature matrix.</p>
</td></tr>
<tr><td><code>y_new</code></td>
<td>
<p>Resampled target variable.</p>
</td></tr>
<tr><td><code>x_syn</code></td>
<td>
<p>Generated synthetic data.</p>
</td></tr>
<tr><td><code>C</code></td>
<td>
<p>Number of synthetic samples for each positive class samples.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Fatih Saglam, saglamf89@gmail.com
</p>


<h3>References</h3>

<p>He, H., Bai, Y., Garcia, E. A., &amp; Li, S. (2008, June). ADASYN: Adaptive
synthetic sampling approach for imbalanced learning. In 2008 IEEE
international joint conference on neural networks (IEEE world congress on
computational intelligence) (pp. 1322-1328). IEEE.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
x &lt;- rbind(matrix(rnorm(2000, 3, 1), ncol = 2, nrow = 1000),
           matrix(rnorm(100, 5, 1), ncol = 2, nrow = 50))
y &lt;- as.factor(c(rep("negative", 1000), rep("positive", 50)))

plot(x, col = y)

# resampling
m &lt;- ADASYN(x = x, y = y, k = 3)

plot(m$x_new, col = m$y_new)

</code></pre>

<hr>
<h2 id='BLSMOTE'>Borderline Synthetic Minority Oversampling Technique</h2><span id='topic+BLSMOTE'></span>

<h3>Description</h3>

<p><code>BLSMOTE()</code> applies BLSMOTE (Borderline-SMOTE) which is a
variation of the SMOTE algorithm that generates synthetic samples only in the
vicinity of the borderline instances in imbalanced datasets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BLSMOTE(x, y, k1 = 5, k2 = 5, type = "type1")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BLSMOTE_+3A_x">x</code></td>
<td>
<p>feature matrix or data.frame.</p>
</td></tr>
<tr><td><code id="BLSMOTE_+3A_y">y</code></td>
<td>
<p>a factor class variable with two classes.</p>
</td></tr>
<tr><td><code id="BLSMOTE_+3A_k1">k1</code></td>
<td>
<p>number of neighbors to link. Default is 5.</p>
</td></tr>
<tr><td><code id="BLSMOTE_+3A_k2">k2</code></td>
<td>
<p>number of neighbors to determine safe levels. Default is 5.</p>
</td></tr>
<tr><td><code id="BLSMOTE_+3A_type">type</code></td>
<td>
<p>&quot;type1&quot; or &quot;type2&quot;. Default is &quot;type1&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>BLSMOTE works by focusing on the instances that are near the decision
boundary between the minority and majority classes, known as borderline
instances. These instances are more informative and potentially more
challenging for classification, and thus generating synthetic samples in
their vicinity can be more effective than generating them randomly.
</p>
<p>Note: Much faster than <code>smotefamily::BLSMOTE()</code>.
</p>


<h3>Value</h3>

<p>a list with resampled dataset.
</p>
<table>
<tr><td><code>x_new</code></td>
<td>
<p>Resampled feature matrix.</p>
</td></tr>
<tr><td><code>y_new</code></td>
<td>
<p>Resampled target variable.</p>
</td></tr>
<tr><td><code>x_syn</code></td>
<td>
<p>Generated synthetic data.</p>
</td></tr>
<tr><td><code>C</code></td>
<td>
<p>Number of synthetic samples for each positive class samples.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Fatih Saglam, saglamf89@gmail.com
</p>


<h3>References</h3>

<p>Han, H., Wang, W. Y., &amp; Mao, B. H. (2005). Borderline-SMOTE: a new
over-sampling method in imbalanced data sets learning. In Advances in
Intelligent Computing: International Conference on Intelligent Computing,
ICIC 2005, Hefei, China, August 23-26, 2005, Proceedings, Part I 1
(pp. 878-887). Springer Berlin Heidelberg.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
x &lt;- rbind(matrix(rnorm(2000, 3, 1), ncol = 2, nrow = 1000),
           matrix(rnorm(100, 5, 1), ncol = 2, nrow = 50))
y &lt;- as.factor(c(rep("negative", 1000), rep("positive", 50)))

plot(x, col = y)

# resampling
m &lt;- BLSMOTE(x = x, y = y, k1 = 5, k2 = 5)

plot(m$x_new, col = m$y_new)

</code></pre>

<hr>
<h2 id='GSMOTE'>Geometric Synthetic Minority Oversamplnig Technique (GSMOTE)</h2><span id='topic+GSMOTE'></span>

<h3>Description</h3>

<p>Resampling with GSMOTE.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GSMOTE(x, y, k = 5, alpha_sel = "combined", alpha_trunc = 0.5, alpha_def = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GSMOTE_+3A_x">x</code></td>
<td>
<p>feature matrix.</p>
</td></tr>
<tr><td><code id="GSMOTE_+3A_y">y</code></td>
<td>
<p>a factor class variable with two classes.</p>
</td></tr>
<tr><td><code id="GSMOTE_+3A_k">k</code></td>
<td>
<p>number of neighbors. Default is 5.</p>
</td></tr>
<tr><td><code id="GSMOTE_+3A_alpha_sel">alpha_sel</code></td>
<td>
<p>selection method. Can be &quot;minority&quot;, &quot;majority&quot; or &quot;combined&quot;. Default is &quot;combined&quot;.</p>
</td></tr>
<tr><td><code id="GSMOTE_+3A_alpha_trunc">alpha_trunc</code></td>
<td>
<p>truncation factor. A numeric value in <code class="reqn">[-1,1]</code>. Default is 0.5.</p>
</td></tr>
<tr><td><code id="GSMOTE_+3A_alpha_def">alpha_def</code></td>
<td>
<p>deformation factor. A numeric value in <code class="reqn">[0,1]</code>. Default is 0.5</p>
</td></tr>
</table>


<h3>Details</h3>

<p>GSMOTE (Douzas &amp; Bacao, 2019) is an oversampling method which creates synthetic
samples geometrically around selected minority samples. Details are in the
paper (Douzas &amp; Bacao, 2019).
</p>
<p>NOTE: Can not work with classes more than 2. Only numerical variables are
allowed.
</p>


<h3>Value</h3>

<p>a list with resampled dataset.
</p>
<table>
<tr><td><code>x_new</code></td>
<td>
<p>Resampled feature matrix.</p>
</td></tr>
<tr><td><code>y_new</code></td>
<td>
<p>Resampled target variable.</p>
</td></tr>
<tr><td><code>x_syn</code></td>
<td>
<p>Generated synthetic feature data.</p>
</td></tr>
<tr><td><code>y_syn</code></td>
<td>
<p>Generated synthetic label data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Fatih Saglam, saglamf89@gmail.com
</p>


<h3>References</h3>

<p>Douzas, G., &amp; Bacao, F. (2019). Geometric SMOTE a geometrically enhanced
drop-in replacement for SMOTE. Information sciences, 501, 118-135.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
x &lt;- rbind(matrix(rnorm(2000, 3, 1), ncol = 2, nrow = 1000),
           matrix(rnorm(100, 5, 1), ncol = 2, nrow = 50))
y &lt;- as.factor(c(rep("negative", 1000), rep("positive", 50)))

plot(x, col = y)

# resampling
m &lt;- GSMOTE(x = x, y = y, k = 7)

plot(m$x_new, col = m$y_new)

</code></pre>

<hr>
<h2 id='ROS'>Random Oversampling (ROS)</h2><span id='topic+ROS'></span>

<h3>Description</h3>

<p>Resampling with ROS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ROS(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ROS_+3A_x">x</code></td>
<td>
<p>feature matrix.</p>
</td></tr>
<tr><td><code id="ROS_+3A_y">y</code></td>
<td>
<p>a factor class variable with two classes.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Random Oversampling (ROS) is a method of copying and pasting of positive
samples until balance is achieved.
</p>
<p>Can work with classes more than 2.
</p>


<h3>Value</h3>

<p>a list with resampled dataset.
</p>
<table>
<tr><td><code>x_new</code></td>
<td>
<p>Resampled feature matrix.</p>
</td></tr>
<tr><td><code>y_new</code></td>
<td>
<p>Resampled target variable.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Fatih Saglam, saglamf89@gmail.com
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
x &lt;- rbind(matrix(rnorm(2000, 3, 1), ncol = 2, nrow = 1000),
           matrix(rnorm(100, 5, 1), ncol = 2, nrow = 50))
y &lt;- as.factor(c(rep("negative", 1000), rep("positive", 50)))

plot(x, col = y)

# resampling
m &lt;- ROS(x = x, y = y)

plot(m$x_new, col = m$y_new)

</code></pre>

<hr>
<h2 id='ROSE'>Randomly Over Sampling Examples</h2><span id='topic+ROSE'></span>

<h3>Description</h3>

<p>Generates synthetic data for each class to balance imbalanced
datasets using kernel density estimations. Can be used for multiclass datasets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ROSE(x, y, h = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ROSE_+3A_x">x</code></td>
<td>
<p>feature matrix or data.frame.</p>
</td></tr>
<tr><td><code id="ROSE_+3A_y">y</code></td>
<td>
<p>a factor class variable. Can be multiclass.</p>
</td></tr>
<tr><td><code id="ROSE_+3A_h">h</code></td>
<td>
<p>A numeric vector of length one or number of classes in y. If one is
given, all classes will have same shrink factor. If a value is given for each
classes, it will match respectively to <code>levels(y)</code>. Default is 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Randomly Over Sampling Examples (ROSE) (Menardi and Torelli, 2014) is an
oversampling method which uses conditional kernel densities to balance dataset.
There is already an R package called 'ROSE' (Lunardon et al., 2014).
Difference is that this one is much faster and can be applied for more than two classes.
</p>


<h3>Value</h3>

<p>a list with resampled dataset.
</p>
<table>
<tr><td><code>x_new</code></td>
<td>
<p>Resampled feature matrix.</p>
</td></tr>
<tr><td><code>y_new</code></td>
<td>
<p>Resampled target variable.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Fatih Saglam, saglamf89@gmail.com
</p>


<h3>References</h3>

<p>Lunardon, N., Menardi, G., and Torelli, N. (2014). ROSE: a Package for Binary
Imbalanced Learning. R Jorunal, 6:82â€“92.
</p>
<p>Menardi, G. and Torelli, N. (2014). Training and assessing classification
rules with imbalanced data. Data Mining and Knowledge Discovery, 28:92â€“122.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
x &lt;- rbind(matrix(rnorm(2000, 3, 1), ncol = 2, nrow = 1000),
           matrix(rnorm(100, 5, 1), ncol = 2, nrow = 50))
y &lt;- as.factor(c(rep("negative", 1000), rep("positive", 50)))

plot(x, col = y)

# resampling
m &lt;- ROSE(x = x, y = y, h = c(0.12, 1))

plot(m$x_new, col = m$y_new)

</code></pre>

<hr>
<h2 id='RSLSMOTE'>Relocating safe-level SMOTE with minority outcast handling</h2><span id='topic+RSLSMOTE'></span>

<h3>Description</h3>

<p>The Relocating Safe-Level SMOTE (RSLS) algorithm improves the
quality of synthetic samples generated by Safe-Level SMOTE (SLS) by
relocating specific synthetic data points that are too close to the majority
class distribution towards the original minority class distribution in the
feature space.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RSLSMOTE(x, y, k1 = 5, k2 = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RSLSMOTE_+3A_x">x</code></td>
<td>
<p>feature matrix or data.frame.</p>
</td></tr>
<tr><td><code id="RSLSMOTE_+3A_y">y</code></td>
<td>
<p>a factor class variable with two classes.</p>
</td></tr>
<tr><td><code id="RSLSMOTE_+3A_k1">k1</code></td>
<td>
<p>number of neighbors to link. Default is 5.</p>
</td></tr>
<tr><td><code id="RSLSMOTE_+3A_k2">k2</code></td>
<td>
<p>number of neighbors to determine safe levels. Default is 5.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In Safe-level SMOTE (SLS), a safe-level threshold is used to control the number of synthetic
samples generated from each minority instance. This threshold is calculated
based on the number of minority and majority instances in the local
neighborhood of each minority instance. SLS generates synthetic samples that
are located closer to the original minority class distribution in the feature
space.
</p>
<p>In Relocating safe-level SMOTE (RSLS), after generating synthetic samples
using the SLS algorithm, the algorithm relocates specific synthetic data
points that are deemed to be too close to the majority class distribution in
the feature space. The relocation process moves these synthetic data points
towards the original minority class distribution in the feature space.
</p>
<p>This relocation process is performed by first identifying the synthetic data
points that are too close to the majority class distribution. Then, for each
identified synthetic data point, the algorithm calculates a relocation vector
based on the distance between the synthetic data point and its k nearest
minority class instances. This relocation vector is used to move the
synthetic data point towards the minority class distribution in the feature
space.
</p>
<p>Note: Much faster than <code>smotefamily::RSLS()</code>.
</p>


<h3>Value</h3>

<p>a list with resampled dataset.
</p>
<table>
<tr><td><code>x_new</code></td>
<td>
<p>Resampled feature matrix.</p>
</td></tr>
<tr><td><code>y_new</code></td>
<td>
<p>Resampled target variable.</p>
</td></tr>
<tr><td><code>x_syn</code></td>
<td>
<p>Generated synthetic data.</p>
</td></tr>
<tr><td><code>C</code></td>
<td>
<p>Number of synthetic samples for each positive class samples.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Fatih Saglam, saglamf89@gmail.com
</p>


<h3>References</h3>

<p>Siriseriwan, W., &amp; Sinapiromsaran, K. (2016). The effective redistribution
for imbalance dataset: Relocating safe-level SMOTE with minority outcast
handling. Chiang Mai J. Sci, 43(1), 234-246.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
x &lt;- rbind(matrix(rnorm(2000, 3, 1), ncol = 2, nrow = 1000),
           matrix(rnorm(100, 5, 1), ncol = 2, nrow = 50))
y &lt;- as.factor(c(rep("negative", 1000), rep("positive", 50)))

plot(x, col = y)

# resampling
m &lt;- RSLSMOTE(x = x, y = y, k1 = 5, k2 = 5)

plot(m$x_new, col = m$y_new)

</code></pre>

<hr>
<h2 id='RUS'>Random Undersampling (RUS)</h2><span id='topic+RUS'></span>

<h3>Description</h3>

<p>Resampling with RUS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RUS(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RUS_+3A_x">x</code></td>
<td>
<p>feature matrix.</p>
</td></tr>
<tr><td><code id="RUS_+3A_y">y</code></td>
<td>
<p>a factor class variable with two classes.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Random Undersampling (RUS) is a method of removing negative
samples until balance is achieved.
</p>
<p>Can work with classes more than 2.
</p>


<h3>Value</h3>

<p>a list with resampled dataset.
</p>
<table>
<tr><td><code>x_new</code></td>
<td>
<p>Resampled feature matrix.</p>
</td></tr>
<tr><td><code>y_new</code></td>
<td>
<p>Resampled target variable.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Fatih Saglam, saglamf89@gmail.com
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
x &lt;- rbind(matrix(rnorm(2000, 3, 1), ncol = 2, nrow = 1000),
           matrix(rnorm(100, 5, 1), ncol = 2, nrow = 50))
y &lt;- as.factor(c(rep("negative", 1000), rep("positive", 50)))

plot(x, col = y)

# resampling
m &lt;- RUS(x = x, y = y)

plot(m$x_new, col = m$y_new)

</code></pre>

<hr>
<h2 id='RWO'>Random Walk Oversampling (SMOTE)</h2><span id='topic+RWO'></span>

<h3>Description</h3>

<p>Resampling with RWO
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RWO(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RWO_+3A_x">x</code></td>
<td>
<p>feature matrix.</p>
</td></tr>
<tr><td><code id="RWO_+3A_y">y</code></td>
<td>
<p>a factor class variable with two classes.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>RWO (Zhang and Li, 2014) is an oversampling method which generates data using
variable standard error in a way that it preserves the variances of all variables.
</p>
<p>Can work with classes more than 2.
</p>


<h3>Value</h3>

<p>a list with resampled dataset.
</p>
<table>
<tr><td><code>x_new</code></td>
<td>
<p>Resampled feature matrix.</p>
</td></tr>
<tr><td><code>y_new</code></td>
<td>
<p>Resampled target variable.</p>
</td></tr>
<tr><td><code>x_syn</code></td>
<td>
<p>Generated synthetic feature data.</p>
</td></tr>
<tr><td><code>y_syn</code></td>
<td>
<p>Generated synthetic label data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Fatih Saglam, saglamf89@gmail.com
</p>


<h3>References</h3>

<p>Zhang, H., &amp; Li, M. (2014). RWO-Sampling: A random walk over-sampling
approach to imbalanced data classification. Information Fusion, 20, 99-116.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
x &lt;- rbind(matrix(rnorm(2000, 3, 1), ncol = 2, nrow = 1000),
           matrix(rnorm(100, 5, 1), ncol = 2, nrow = 50))
y &lt;- as.factor(c(rep("negative", 1000), rep("positive", 50)))

plot(x, col = y)

# resampling
m &lt;- RWO(x = x, y = y)

plot(m$x_new, col = m$y_new)

</code></pre>

<hr>
<h2 id='SLSMOTE'>Safe-level Synthetic Minority Oversampling Technique</h2><span id='topic+SLSMOTE'></span>

<h3>Description</h3>

<p><code>SLSMOTE()</code> generates synthetic samples by considering a
safe level of the nearest minority class examples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SLSMOTE(x, y, k1 = 5, k2 = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SLSMOTE_+3A_x">x</code></td>
<td>
<p>feature matrix or data.frame.</p>
</td></tr>
<tr><td><code id="SLSMOTE_+3A_y">y</code></td>
<td>
<p>a factor class variable with two classes.</p>
</td></tr>
<tr><td><code id="SLSMOTE_+3A_k1">k1</code></td>
<td>
<p>number of neighbors to link. Default is 5.</p>
</td></tr>
<tr><td><code id="SLSMOTE_+3A_k2">k2</code></td>
<td>
<p>number of neighbors to determine safe levels. Default is 5.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>SLSMOTE uses the safe-level distance metric to identify the minority class
samples that are safe to oversample. Safe-level distance measures the
distance between a minority class sample and its k-nearest minority class
neighbors. A sample is considered safe to oversample if its safe-level is
greater than a threshold. The safe-level of a sample is the ratio of minority
class samples among its k-nearest neighbors.
</p>
<p>In SLSMOTE, the oversampling process only applies to the safe minority class
samples, which avoids the generation of noisy samples that can lead to
overfitting. To generate synthetic samples, SLSMOTE randomly selects a
minority class sample and finds its k-nearest minority class neighbors.
Then, a random minority class neighbor is selected, and a synthetic sample
is generated by adding a random proportion of the difference between the
selected sample and its neighbor to the selected sample.
</p>
<p>Note: Much faster than <code>smotefamily::SLS()</code>.
</p>


<h3>Value</h3>

<p>a list with resampled dataset.
</p>
<table>
<tr><td><code>x_new</code></td>
<td>
<p>Resampled feature matrix.</p>
</td></tr>
<tr><td><code>y_new</code></td>
<td>
<p>Resampled target variable.</p>
</td></tr>
<tr><td><code>x_syn</code></td>
<td>
<p>Generated synthetic data.</p>
</td></tr>
<tr><td><code>C</code></td>
<td>
<p>Number of synthetic samples for each positive class samples.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Fatih Saglam, saglamf89@gmail.com
</p>


<h3>References</h3>

<p>Bunkhumpornpat, C., Sinapiromsaran, K., &amp; Lursinsap, C. (2009).
Safe-level-smote: Safe-level-synthetic minority over-sampling technique for
handling the class imbalanced problem. In Advances in Knowledge Discovery
and Data Mining: 13th Pacific-Asia Conference, PAKDD 2009 Bangkok, Thailand,
April 27-30, 2009 Proceedings 13 (pp. 475-482). Springer Berlin Heidelberg.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
x &lt;- rbind(matrix(rnorm(2000, 3, 1), ncol = 2, nrow = 1000),
           matrix(rnorm(100, 5, 1), ncol = 2, nrow = 50))
y &lt;- as.factor(c(rep("negative", 1000), rep("positive", 50)))

plot(x, col = y)

# resampling
m &lt;- SLSMOTE(x = x, y = y, k1 = 5, k2 = 5)

plot(m$x_new, col = m$y_new)

</code></pre>

<hr>
<h2 id='SMOTE'>Synthetic Minority Oversampling Technique (SMOTE)</h2><span id='topic+SMOTE'></span>

<h3>Description</h3>

<p>Resampling with SMOTE.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SMOTE(x, y, k = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SMOTE_+3A_x">x</code></td>
<td>
<p>feature matrix.</p>
</td></tr>
<tr><td><code id="SMOTE_+3A_y">y</code></td>
<td>
<p>a factor class variable with two classes.</p>
</td></tr>
<tr><td><code id="SMOTE_+3A_k">k</code></td>
<td>
<p>number of neighbors. Default is 5.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>SMOTE (Chawla et al., 2002) is an oversampling method which creates links
between positive samples and nearest neighbors and generates synthetic
samples along that link.
</p>
<p>It is well known that SMOTE is sensitive to noisy data. It may create more
noise.
</p>
<p>Can work with classes more than 2.
</p>
<p>Note: Much faster than <code>smotefamily::SMOTE()</code>.
</p>


<h3>Value</h3>

<p>a list with resampled dataset.
</p>
<table>
<tr><td><code>x_new</code></td>
<td>
<p>Resampled feature matrix.</p>
</td></tr>
<tr><td><code>y_new</code></td>
<td>
<p>Resampled target variable.</p>
</td></tr>
<tr><td><code>x_syn</code></td>
<td>
<p>Generated synthetic feature data.</p>
</td></tr>
<tr><td><code>y_syn</code></td>
<td>
<p>Generated synthetic label data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Fatih Saglam, saglamf89@gmail.com
</p>


<h3>References</h3>

<p>Chawla, N. V., Bowyer, K. W., Hall, L. O., &amp; Kegelmeyer, W. P. (2002). SMOTE:
synthetic minority over-sampling technique. Journal of artificial
intelligence research, 16, 321-357.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
x &lt;- rbind(matrix(rnorm(2000, 3, 1), ncol = 2, nrow = 1000),
           matrix(rnorm(100, 5, 1), ncol = 2, nrow = 50))
y &lt;- as.factor(c(rep("negative", 1000), rep("positive", 50)))

plot(x, col = y)

# resampling
m &lt;- SMOTE(x = x, y = y, k = 7)

plot(m$x_new, col = m$y_new)

</code></pre>

<hr>
<h2 id='SMOTEWB'>SMOTE with boosting (SMOTEWB)</h2><span id='topic+SMOTEWB'></span>

<h3>Description</h3>

<p>Resampling with SMOTE with boosting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SMOTEWB(x, y, n_weak_classifier = 100, class_weights = NULL, k_max = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SMOTEWB_+3A_x">x</code></td>
<td>
<p>feature matrix.</p>
</td></tr>
<tr><td><code id="SMOTEWB_+3A_y">y</code></td>
<td>
<p>a factor class variable with two classes.</p>
</td></tr>
<tr><td><code id="SMOTEWB_+3A_n_weak_classifier">n_weak_classifier</code></td>
<td>
<p>number of weak classifiers for boosting.</p>
</td></tr>
<tr><td><code id="SMOTEWB_+3A_class_weights">class_weights</code></td>
<td>
<p>numeric vector of length two. First number is for
positive class, and second is for negative. Higher the relative weight,
lesser noises for that class. By default,  <code class="reqn">2\times n_{neg}/n</code> for
positive and <code class="reqn">2\times n_{pos}/n</code> for negative class.</p>
</td></tr>
<tr><td><code id="SMOTEWB_+3A_k_max">k_max</code></td>
<td>
<p>to increase maximum number of neighbors. Default is
<code>ceiling(n_neg/n_pos)</code>.</p>
</td></tr>
<tr><td><code id="SMOTEWB_+3A_...">...</code></td>
<td>
<p>additional inputs for ada::ada().</p>
</td></tr>
</table>


<h3>Details</h3>

<p>SMOTEWB (Saglam &amp; Cengiz, 2022) is a SMOTE-based oversampling method which
can handle noisy data and adaptively decides the appropriate number of neighbors
to link during resampling with SMOTE.
</p>
<p>Trained model based on this method gives significantly better Matthew
Correlation Coefficient scores compared to others.
</p>


<h3>Value</h3>

<p>a list with resampled dataset.
</p>
<table>
<tr><td><code>x_new</code></td>
<td>
<p>Resampled feature matrix.</p>
</td></tr>
<tr><td><code>y_new</code></td>
<td>
<p>Resampled target variable.</p>
</td></tr>
<tr><td><code>x_syn</code></td>
<td>
<p>Generated synthetic data.</p>
</td></tr>
<tr><td><code>w</code></td>
<td>
<p>Boosting weights for original dataset.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>Number of nearest neighbors for positive class samples.</p>
</td></tr>
<tr><td><code>C</code></td>
<td>
<p>Number of synthetic samples for each positive class samples.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Fatih Saglam, saglamf89@gmail.com
</p>


<h3>References</h3>

<p>SaÄŸlam, F., &amp; Cengiz, M. A. (2022). A novel SMOTE-based resampling technique
trough noise detection and the boosting procedure. Expert Systems with
Applications, 200, 117023.
</p>
<p>Can work with 2 classes only yet.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
x &lt;- rbind(matrix(rnorm(2000, 3, 1), ncol = 2, nrow = 1000),
           matrix(rnorm(100, 5, 1), ncol = 2, nrow = 50))
y &lt;- as.factor(c(rep("negative", 1000), rep("positive", 50)))

plot(x, col = y)

# resampling
m &lt;- SMOTEWB(x = x, y = y, n_weak_classifier = 150)

plot(m$x_new, col = m$y_new)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
