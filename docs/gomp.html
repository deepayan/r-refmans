<!DOCTYPE html><html lang="en"><head><title>Help for package gomp</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {gomp}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#gomp-package'>
<p>The gamma-OMP Feature Selection Algorithm</p></a></li>
<li><a href='#Bootstrap+20bias+20correction+20for+20the+20performance+20of+20the+20cross-validation+20procedure'>
<p>Bootstrap bias correction for the performance of the cross-validation procedure</p></a></li>
<li><a href='#Cross-validation+20for+20gamma-Orthogonal+20Matching+20Pursuit+20+28gamma-OMP+29+20algorithm'>
<p>Cross-validation for the gamma-Orthogonal Matching Pursuit (gamma-OMP) algorithm</p></a></li>
<li><a href='#Generate+20random+20folds+20for+20cross-validation'>
<p>Generate random folds for cross-validation</p></a></li>
<li><a href='#The+20gamma-Orthogonal+20Matching+20Pursuit+20+28gamma-OMP+29+20algorithm'>
<p>The gama-Orthogonal Matching Pursuit (gamma-OMP) algorithm</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>The gamma-OMP Feature Selection Algorithm</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-01-11</td>
</tr>
<tr>
<td>Author:</td>
<td>Michail Tsagris [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Michail Tsagris &lt;mtsagris@uoc.gr&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>doParallel, foreach, Hmisc, MASS, nnet, ordinal, parallel,
quantreg, Rfast, Rfast2, stats, survival</td>
</tr>
<tr>
<td>Suggests:</td>
<td>dcorVS</td>
</tr>
<tr>
<td>Description:</td>
<td>The gamma-Orthogonal Matching Pursuit (gamma-OMP) is a recently suggested modification of the OMP feature selection algorithm for a wide range of response variables. The package offers many alternative regression models, such linear, robust, survival, multivariate etc., including k-fold cross-validation. References: Tsagris M., Papadovasilakis Z., Lakiotaki K. and Tsamardinos I. (2018). "Efficient feature selection on gene expression data: Which algorithm to use?" BioRxiv. &lt;<a href="https://doi.org/10.1101%2F431734">doi:10.1101/431734</a>&gt;. Tsagris M., Papadovasilakis Z., Lakiotaki K. and Tsamardinos I. (2022). "The gamma-OMP algorithm for feature selection with application to gene expression data". IEEE/ACM Transactions on Computational Biology and Bioinformatics 19(2): 1214&ndash;1224. &lt;<a href="https://doi.org/10.1109%2FTCBB.2020.3029952">doi:10.1109/TCBB.2020.3029952</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-11 11:49:10 UTC; mtsag</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-20 16:02:00 UTC</td>
</tr>
</table>
<hr>
<h2 id='gomp-package'>
The gamma-OMP Feature Selection Algorithm
</h2><span id='topic+gomp-package'></span>

<h3>Description</h3>

<p>The gamma-Orthogonal Matching Pursuit (gamma-OMP) is a recently suggested modification of the OMP feature selection algorithm for a wide range of response variables. The package offers many alternative regression models, such linear, robust, survival, multivariate etc., including k-fold cross-validation. References: Tsagris M., Papadovasilakis Z., Lakiotaki K. and Tsamardinos I. (2018). &quot;Efficient feature selection on gene expression data: Which algorithm to use?&quot; BioRxiv. &lt;doi:10.1101/431734&gt;. Tsagris M., Papadovasilakis Z., Lakiotaki K. and Tsamardinos I. (2022). &quot;The gamma-OMP algorithm for feature selection with application to gene expression data&quot;. IEEE/ACM Transactions on Computational Biology and Bioinformatics 19(2): 1214&ndash;1224.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> gomp</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.0</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2025-01-11</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Maintainers</h3>

<p>Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Tsagris M., Papadovasilakis Z., Lakiotaki K. and Tsamardinos I. (2018). Efficient feature selection on gene expression data: Which algorithm to use? BioRxiv.
</p>
<p>Tsagris M., Papadovasilakis Z., Lakiotaki K. and Tsamardinos I. (2022). The <code class="reqn">\gamma</code>-OMP algorithm for feature selection with application to gene expression data&quot;. IEEE/ACM Transactions on Computational Biology and Bioinformatics 19(2): 1214&ndash;1224.
</p>
<p>Alharbi N. (2024). Variable selection with time-to-event data: Cox or Weibull regression?
Communications in Statistics: Case Studies, Data Analysis and Applications (accepted for publication).
</p>

<hr>
<h2 id='Bootstrap+20bias+20correction+20for+20the+20performance+20of+20the+20cross-validation+20procedure'>
Bootstrap bias correction for the performance of the cross-validation procedure
</h2><span id='topic+bbc'></span>

<h3>Description</h3>

<p>Bootstrap bias correction for the performance of the cross-validation procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bbc(predictions, y, metric = "auc.gomp", conf = 0.95, B = 1000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Bootstrap+2B20bias+2B20correction+2B20for+2B20the+2B20performance+2B20of+2B20the+2B20cross-validation+2B20procedure_+3A_predictions">predictions</code></td>
<td>

<p>A matrix with the predictived values.
</p>
</td></tr>
<tr><td><code id="Bootstrap+2B20bias+2B20correction+2B20for+2B20the+2B20performance+2B20of+2B20the+2B20cross-validation+2B20procedure_+3A_y">y</code></td>
<td>

<p>A vector with the response variable, survival object, factor (ordered or unordered) or a numerical vector.
</p>
</td></tr>
<tr><td><code id="Bootstrap+2B20bias+2B20correction+2B20for+2B20the+2B20performance+2B20of+2B20the+2B20cross-validation+2B20procedure_+3A_metric">metric</code></td>
<td>

<p>The possible values are:
</p>
<p>a) Binary response: &quot;auc.gomp&quot; (area under the curve), &quot;fscore.gomp&quot; (F-score), &quot;prec.gomp&quot; (precision), &quot;euclid_sens.spec.gomp&quot; (Euclidean distance of sensitivity and specificity), &quot;spec.gomp&quot; (specificity), &quot;sens.gomp&quot; (sensitivity), &quot;acc.gomp&quot; (accuracy, proportion of correct classification).
</p>
<p>b) Multinomial response: &quot;acc_multinom.gomp&quot; (accuracy, proportion of correct classification).
</p>
<p>c) Ordinal response: &quot;ord_mae.gomp&quot; (mean absolute error).
</p>
<p>d) Continuous response: &quot;mae.gomp&quot; (MAE with continuous response), &quot;mse.gomp&quot; (mean squared error), &quot;pve.gomp&quot; (percentage of variance explained).
</p>
<p>e) Survival response &quot;ci.gomp&quot; (concordance index for Cox regression), &quot;ciwr.gomp&quot; (concordance index for Weibull regression).
</p>
<p>g) Count response &quot;poisdev.gomp&quot;.
</p>
<p>h) Binomial response &quot;binomdev.gomp&quot; (deviance of binomial regression).
</p>
<p>The &quot;nbdev.gomp&quot; (negative binomial deviance) is missing. For more information on these see <code><a href="#topic+cv.gomp">cv.gomp</a></code>. <b>Note</b> that they come with &quot;&quot;.
</p>
</td></tr>
<tr><td><code id="Bootstrap+2B20bias+2B20correction+2B20for+2B20the+2B20performance+2B20of+2B20the+2B20cross-validation+2B20procedure_+3A_conf">conf</code></td>
<td>

<p>A number between 0 and 1, the confidence level.
</p>
</td></tr>
<tr><td><code id="Bootstrap+2B20bias+2B20correction+2B20for+2B20the+2B20performance+2B20of+2B20the+2B20cross-validation+2B20procedure_+3A_b">B</code></td>
<td>

<p>The number of bootstrap replicates. The default number is 1000.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Upon completion of the cross-validation, the predicted values produced by all predictive models across all folds is collected in a matrix <code class="reqn">P</code> of dimensions <code class="reqn">n \times M</code>, where <code class="reqn">n</code> is the number of samples and <code class="reqn">M</code> the number of trained models or configurations. Sampled with replacement a fraction of rows (predictions) from <code class="reqn">P</code> are denoted as the in-sample values. On average, the newly created set will be comprised by 63.2% of the original individuals (The probability of sampling, with replacement, a sample of <code class="reqn">n</code> numbers from a set of <code class="reqn">n</code> numbers is <code class="reqn">1-\left(1-\frac{1}{n} \right)^n \simeq 1-\frac{1}{e}=0.632</code>), whereas the rest 36.8% will be random copies of them. The non re-sampled rows are denoted as out-of-sample values. The performance of each model in the in-sample rows is calculated and the model (or configuration) with the optimal performance is selected, followed by the calculation of performance in the out-of-sample values. This process is repeated B times and the average performance is returned.
</p>
<p>Note, that the only computational overhead is with the repetitive re-sampling and calculation of the predictive performance, i.e. no model is fitted nor trained. The final estimated performance usually underestimates the true performance, but this negative bias is smaller than the optimistic uncorrected performance.
</p>
<p>Note, that all metrics are for maximization. For this reason &quot;mse.gomp&quot;, &quot;mae.gomp&quot;, &quot;ord_mae.gomp&quot;, &quot;poisdev.gomp&quot;, &quot;binomdev.gomp&quot; are multiplied by -1.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table role = "presentation">
<tr><td><code>out.perf</code></td>
<td>

<p>The B out sampled performances. Their mean is the &quot;bbc.perf&quot; given above.
</p>
</td></tr>
<tr><td><code>bbc.perf</code></td>
<td>

<p>The bootstrap bias corrected performance of the chosen algorithm, model or configuration.
</p>
</td></tr>
<tr><td><code>ci</code></td>
<td>

<p>The (1- conf)% confidence interval of the BBC performance. It is based on the empirical or percentile method for bootstrap samples. The lower and upper 2.5% of the &quot;out.perf&quot;.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Ioannis Tsamardinos, Elissavet Greasidou and Giorgos Borboudakis (2018). Bootstrapping the out-of-sample predictions for efficient and accurate cross-validation. Machine Learning, 107: 1895&ndash;1922.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+cv.gomp">cv.gomp</a>, <a href="#topic+gomp">gomp</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>predictions &lt;- matrix( rbinom(200 * 50, 1, 0.7), ncol = 50)
y &lt;- rbinom(200, 1, 0.5)
gomp::bbc(predictions, y, metric = "auc.gomp")
</code></pre>

<hr>
<h2 id='Cross-validation+20for+20gamma-Orthogonal+20Matching+20Pursuit+20+28gamma-OMP+29+20algorithm'>
Cross-validation for the gamma-Orthogonal Matching Pursuit (gamma-OMP) algorithm
</h2><span id='topic+cv.gomp'></span>

<h3>Description</h3>

<p>The function performs a k-fold cross-validation for identifying the best tolerance values for the <code class="reqn">\gamma</code>-Orthogonal Matching Pursuit (<code class="reqn">\gamma</code>-OMP) algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.gomp(y, x, kfolds = 10, folds = NULL, tol = seq(4, 9, by = 1),
task = "C", metric = NULL, metricbbc = NULL, modeler = NULL, test = NULL,
method = "ar2", B = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Cross-validation+2B20for+2B20gamma-Orthogonal+2B20Matching+2B20Pursuit+2B20+2B28gamma-OMP+2B29+2B20algorithm_+3A_y">y</code></td>
<td>

<p>The response variable.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20gamma-Orthogonal+2B20Matching+2B20Pursuit+2B20+2B28gamma-OMP+2B29+2B20algorithm_+3A_x">x</code></td>
<td>

<p>A matrix with the predictor variables.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20gamma-Orthogonal+2B20Matching+2B20Pursuit+2B20+2B28gamma-OMP+2B29+2B20algorithm_+3A_kfolds">kfolds</code></td>
<td>

<p>The number of the folds in the k-fold Cross Validation (integer).
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20gamma-Orthogonal+2B20Matching+2B20Pursuit+2B20+2B28gamma-OMP+2B29+2B20algorithm_+3A_folds">folds</code></td>
<td>

<p>The folds of the data to use. If NULL the folds are created internally with the same function.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20gamma-Orthogonal+2B20Matching+2B20Pursuit+2B20+2B28gamma-OMP+2B29+2B20algorithm_+3A_tol">tol</code></td>
<td>

<p>A vector of tolerance values.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20gamma-Orthogonal+2B20Matching+2B20Pursuit+2B20+2B28gamma-OMP+2B29+2B20algorithm_+3A_task">task</code></td>
<td>

<p>A character (&quot;C&quot;, &quot;R&quot; or &quot;S&quot;). It can be &quot;C&quot; for classification (logistic, multinomial or ordinal regression), &quot;R&quot; for regression (robust and non robust linear regression, median regression,
(zero inflated) poisson and negative binomial regression, beta regression), &quot;S&quot; for survival regresion (Cox, Weibull or exponential regression).
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20gamma-Orthogonal+2B20Matching+2B20Pursuit+2B20+2B28gamma-OMP+2B29+2B20algorithm_+3A_metric">metric</code></td>
<td>

<p>A metric function provided by the user. If NULL the following functions will be used: auc.gomp, mse.gomp, ci.gomp for classification, regression and survival analysis tasks, respectively. See details for more. If you know what you have put it here to avoid the function choosing somehting else.
<b>Note</b> that you put these words as they are, without &quot;&quot;.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20gamma-Orthogonal+2B20Matching+2B20Pursuit+2B20+2B28gamma-OMP+2B29+2B20algorithm_+3A_metricbbc">metricbbc</code></td>
<td>

<p>This is the same argument as &quot;metric&quot; with the difference that &quot; &quot; must be placed. If for example, metric = auc.mxm, here metricbbc = &quot;auc.mxm&quot;. The same value must be given here. This argument is to be used with the function <code><a href="#topic+bbc">bbc</a></code> which does bootstrap bias correction of the estimated performance (Tsamardinos, Greasidou and Borboudakis, 2018). This argument is valid if the last argument (B) is more than 1.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20gamma-Orthogonal+2B20Matching+2B20Pursuit+2B20+2B28gamma-OMP+2B29+2B20algorithm_+3A_modeler">modeler</code></td>
<td>

<p>A modeling function provided by the user. If NULL the following functions will be used: glm.gomp, lm.gomp, coxph.gomp for classification, regression and survival analysis tasks, respectively. See details for more. If you know what you have put it here to avoid the function choosing somehting else. <b>Note</b> that you put these words as they are, without &quot;&quot;.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20gamma-Orthogonal+2B20Matching+2B20Pursuit+2B20+2B28gamma-OMP+2B29+2B20algorithm_+3A_test">test</code></td>
<td>

<p>A function object that defines the conditional independence test used in the SES function (see also SES help page). If NULL, &quot;cor&quot;, &quot;logistic&quot; and &quot;cox&quot; are used for classification, regression and survival analysis tasks, respectively. If you know what you have put it here to avoid the function choosing sometting else. Not all tests can be included here. &quot;mv&quot;, &quot;gamma&quot;, and &quot;tobit&quot; are anot available.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20gamma-Orthogonal+2B20Matching+2B20Pursuit+2B20+2B28gamma-OMP+2B29+2B20algorithm_+3A_method">method</code></td>
<td>

<p>This is only for the &quot;cor&quot;. You can either specify, &quot;ar2&quot; for the adjusted R-square or &quot;sse&quot; for the sum of squares of errors. The tolerance value in both cases must a number between 0 and 1. That will denote a percentage. If the percentage increase or decrease is less than the nubmer the algorithm stops. An alternative is &quot;BIC&quot; for BIC and the tolerance values are like in all other regression models.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20gamma-Orthogonal+2B20Matching+2B20Pursuit+2B20+2B28gamma-OMP+2B29+2B20algorithm_+3A_b">B</code></td>
<td>

<p>How many bootstrap re-samples to draw. This argument is to be used with the function <code><a href="#topic+bbc">bbc</a></code> which does bootstrap bias correction of the estimated performance (Tsamardinos, Greasidou and Borboudakis, 2018). If you have thousands of observations then this might not be necessary, as there is no optimistic bias to be corrected. What is the lower limit cannot be told beforehand however. SES and MMPC however were designed for the low sample cases, hence, bootstrap bias correction is perhaps a must thing to do.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details see also <code><a href="#topic+gomp">gomp</a></code>.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table role = "presentation">
<tr><td><code>cv_results_all</code></td>
<td>

<p>A list with predictions, performances and selected variables for each fold and each tolerance value. The elements are called
&quot;preds&quot;, &quot;performances&quot; and &quot;selectedVars&quot;.
</p>
</td></tr>
<tr><td><code>best_performance</code></td>
<td>

<p>A numeric value that represents the best average performance.
</p>
</td></tr>
<tr><td><code>best_configuration</code></td>
<td>

<p>A numeric value that represents the best tolerance value.
</p>
</td></tr>
<tr><td><code>bbc_best_performance</code></td>
<td>

<p>The bootstrap bias corrected best performance if B was more than 1, othwerwise this is NULL.
</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>

<p>The runtime of the cross-validation procedure.
</p>
</td></tr>
</table>
<p>Bear in mind that the values can be extracted with the $ symbol, i.e. this is an S3 class output.
</p>


<h3>Author(s)</h3>

<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Tsamardinos I., Greasidou E. and Borboudakis G. (2018).
Bootstrapping the out-of-sample predictions for efficient and accurate cross-validation.
Machine Learning, 107: 1895&ndash;1922.
<a href="https://link.springer.com/article/10.1007/s10994-018-5714-4">https://link.springer.com/article/10.1007/s10994-018-5714-4</a>
</p>
<p>Tsagris M., Papadovasilakis Z., Lakiotaki K. and Tsamardinos, I. (2022).
The <code class="reqn">\gamma</code>-OMP algorithm for feature selection with application to gene expression data.
IEEE/ACM Transactions on Computational Biology and Bioinformatics, 19(2): 1214&ndash;1224.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+gomp">gomp</a>, <a href="#topic+gomp.path">gomp.path</a>, <a href="#topic+bbc">bbc</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate a dataset with continuous data
x &lt;- matrix( rnorm(200 * 50), ncol = 50 )
# the target feature is the last column of the dataset as a vector
y &lt;- x[, 50]
x &lt;- x[, -50]
# run a 10 fold CV for the regression task
best_model &lt;- cv.gomp(y, x, kfolds = 5, task = "R",
tol = seq(0.001, 0.01,by = 0.001), method = "ar2" )
</code></pre>

<hr>
<h2 id='Generate+20random+20folds+20for+20cross-validation'>
Generate random folds for cross-validation
</h2><span id='topic+makefolds'></span>

<h3>Description</h3>

<p>Random folds for use in a cross validation are generated. There is the option for stratified splitting as well.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makefolds(ina, nfolds = 10, stratified = TRUE, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Generate+2B20random+2B20folds+2B20for+2B20cross-validation_+3A_ina">ina</code></td>
<td>

<p>A variable indicating the groupings.
</p>
</td></tr>
<tr><td><code id="Generate+2B20random+2B20folds+2B20for+2B20cross-validation_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds to produce.
</p>
</td></tr>
<tr><td><code id="Generate+2B20random+2B20folds+2B20for+2B20cross-validation_+3A_stratified">stratified</code></td>
<td>

<p>A boolean variable specifying whether stratified random (TRUE) or simple random (FALSE) sampling is to be used when producing the folds.
</p>
</td></tr>
<tr><td><code id="Generate+2B20random+2B20folds+2B20for+2B20cross-validation_+3A_seed">seed</code></td>
<td>

<p>You can specify your own seed number here or leave it NULL.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>I was inspired by the command in the package <b>TunePareto</b> in order to do the stratified version.
</p>


<h3>Value</h3>

<p>A list with nfolds elements where each elements is a fold containing the indices of the data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+cv.gomp">cv.gomp</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- gomp::makefolds(iris[, 5], nfolds = 5, stratified = TRUE)
table(iris[a[[1]], 5])  ## 10 values from each group
</code></pre>

<hr>
<h2 id='The+20gamma-Orthogonal+20Matching+20Pursuit+20+28gamma-OMP+29+20algorithm'>
The gama-Orthogonal Matching Pursuit (gamma-OMP) algorithm
</h2><span id='topic+gomp'></span><span id='topic+gomp.path'></span><span id='topic+boot.gomp'></span>

<h3>Description</h3>

<p>The <code class="reqn">\gamma</code>-Orthogonal Matching Pursuit (<code class="reqn">\gamma</code>-OMP) algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gomp(y, x, xstand = TRUE, tol = qchisq(0.95, 1), test = "logistic", method = "ar2" )

gomp.path(y, x, xstand = TRUE, tol = c(4, 5, 6), test = "logistic", method = "ar2" )

boot.gomp(y, x, tol = qchisq(0.95, 1), test = "logistic", method = "ar2",
B = 500, ncores = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="The+2B20gamma-Orthogonal+2B20Matching+2B20Pursuit+2B20+2B28gamma-OMP+2B29+2B20algorithm_+3A_y">y</code></td>
<td>

<p>The response variable, a numeric vector, a matrix or a Surv object.
</p>
</td></tr>
<tr><td><code id="The+2B20gamma-Orthogonal+2B20Matching+2B20Pursuit+2B20+2B28gamma-OMP+2B29+2B20algorithm_+3A_x">x</code></td>
<td>

<p>A matrix with continuous data, where the rows denote the observations and the columns are the variables.
</p>
</td></tr>
<tr><td><code id="The+2B20gamma-Orthogonal+2B20Matching+2B20Pursuit+2B20+2B28gamma-OMP+2B29+2B20algorithm_+3A_xstand">xstand</code></td>
<td>

<p>If this is TRUE the independent variables are standardised.
</p>
</td></tr>
<tr><td><code id="The+2B20gamma-Orthogonal+2B20Matching+2B20Pursuit+2B20+2B28gamma-OMP+2B29+2B20algorithm_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the algorithm. This is the change in the criterion value
between two successive steps. The default value is the 95% quantile of the <code class="reqn">\chi^2</code> distribution
with 1 degree of freedom. For test = &quot;normal&quot; the BIC is already calculated.
</p>
<p>In the case of &quot;gomp.path&quot; this is a vector of values. For each tolerance value the result of the gOMP is returned. It returns the whole path of solutions.
</p>
</td></tr>
<tr><td><code id="The+2B20gamma-Orthogonal+2B20Matching+2B20Pursuit+2B20+2B28gamma-OMP+2B29+2B20algorithm_+3A_test">test</code></td>
<td>

<p>This denotes the parametric model to be used each time. It depends upon the nature of the target variable.
The possible values are &quot;normal&quot; (or &quot;cor&quot; for the same purpose), &quot;logistic&quot;, &quot;poisson&quot;, &quot;qpoisson&quot;, &quot;qlogistic&quot;, &quot;normlog&quot;, &quot;mvreg&quot;, &quot;negbin&quot;, &quot;beta&quot;, &quot;gamma&quot;, &quot;mm&quot;, &quot;quantreg&quot;, &quot;ordinal&quot;, &quot;tobit&quot;, &quot;cox&quot;, &quot;weibull&quot;, &quot;log-logistic&quot; and &quot;multinom&quot;.
</p>
</td></tr>
<tr><td><code id="The+2B20gamma-Orthogonal+2B20Matching+2B20Pursuit+2B20+2B28gamma-OMP+2B29+2B20algorithm_+3A_method">method</code></td>
<td>

<p>This is only for the &quot;testIndFisher&quot;. You can either specify, &quot;ar2&quot; for the adjusted R-square or &quot;sse&quot; for the sum of squares of errors. The tolerance value in both cases must a number between 0 and 1. That will denote a percentage. If the percentage increase or decrease is less than the nubmer the algorithm stops. An alternative is &quot;BIC&quot; for BIC and the tolerance values are like in all other regression models.
</p>
</td></tr>
<tr><td><code id="The+2B20gamma-Orthogonal+2B20Matching+2B20Pursuit+2B20+2B28gamma-OMP+2B29+2B20algorithm_+3A_b">B</code></td>
<td>

<p>How many bootstrap samples to generate. The gOMP will be performed for each of these samples.
</p>
</td></tr>
<tr><td><code id="The+2B20gamma-Orthogonal+2B20Matching+2B20Pursuit+2B20+2B28gamma-OMP+2B29+2B20algorithm_+3A_ncores">ncores</code></td>
<td>

<p>How many cores to use. This argument is valid only if you have a multi-threaded machine.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including:
</p>
<table role = "presentation">
<tr><td><code>runtime</code></td>
<td>

<p>The runtime of the algorithm
</p>
</td></tr>
<tr><td><code>phi</code></td>
<td>

<p>The <code class="reqn">phi</code> coefficient, returned in the quasi binomial (qlogistic), quasi Poisson (qpoisson), Gamma (gamma) and Gaussian with log link (normlog). In all other cases this is NULL.
</p>
</td></tr>
<tr><td><code>res</code></td>
<td>

<p>For the case of &quot;gomp&quot; a matrix with two columns. The selected variable(s) and the criterion value at every step.
For the case of &quot;gomp.path&quot; a matrix with many columns. Every column contains the selected variables for each tolerance calue, starting from the smallest value (which selected most variables). The final column is the deviance of the model at each step.
For the &quot;boot.gomp&quot; this is a matrix with two columns. The first one is the selected variables and the second column is their proportion of selection.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Pati Y. C., Rezaiifar R. and Krishnaprasad P. S. (1993). Orthogonal matching pursuit: Recursive function approximation with applications to wavelet decomposition. In Signals, Systems and Computers. 1993 Conference Record of The Twenty-Seventh Asilomar Conference on. IEEE.
</p>
<p>Davis G. (1994). Adaptive Nonlinear Approximations. PhD thesis.
http://www.geoffdavis.net/papers/dissertation.pdf
</p>
<p>Mallat S. G. and Zhang Z. (1993). Matching pursuits with time-frequency dictionaries. IEEE Transactions on signal processing, 41(12), 3397&ndash;3415.
https://www.di.ens.fr/~mallat/papiers/MallatPursuit93.pdf
</p>
<p>Gharavi-Alkhansari M. and Huang T. S. (1998, May). A fast orthogonal matching pursuit algorithm. In Acoustics, Speech and Signal Processing, 1998.
Proceedings of the 1998 IEEE International Conference on (Vol. 3, pp. 1389&ndash;1392). IEEE.
</p>
<p>Chen S., Billings S. A. and Luo W. (1989). Orthogonal least squares methods and their application to non-linear system identification. International Journal of control, 50(5), 1873&ndash;1896.
</p>
<p>Lozano A., Swirszcz G. and Abe N. (2011). Group orthogonal matching pursuit for logistic regression. In Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics.
</p>
<p>Razavi S. A. Ollila E. and Koivunen V. (2012). Robust greedy algorithms for compressed sensing. In Signal Processing Conference (EUSIPCO), 2012 Proceedings of the 20th European. IEEE.
</p>
<p>Mazin Abdulrasool Hameed (2012). Comparative analysis of orthogonal matching pursuit and least angle regression. MSc thesis, Michigan State University.
https://www.google.gr/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;ved=0ahUKEwik9P3Yto7XAhUiCZoKHQ8XDr8QFgglMAA&amp;url=https
</p>
<p>Tsagris M., Papadovasilakis Z., Lakiotaki K. and Tsamardinos I. (2018). Efficient feature selection on gene expression data: Which algorithm to use? BioRxiv.
</p>
<p>Tsagris M., Papadovasilakis Z., Lakiotaki K. and Tsamardinos I. (2022).
The <code class="reqn">\gamma</code>-OMP algorithm for feature selection with application to gene expression data.
IEEE/ACM Transactions on Computational Biology and Bioinformatics, 19(2): 1214&ndash;1224.
</p>
<p>Alharbi N. (2024). Variable selection with time-to-event data: Cox or Weibull regression?
Communications in Statistics: Case Studies, Data Analysis and Applications (accepted for publication).
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+cv.gomp">cv.gomp</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rnorm(500 * 50), ncol = 50)
y &lt;- rnorm(500)
b &lt;- gomp::gomp(y, x, test = "cor")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
