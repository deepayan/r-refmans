<!DOCTYPE html><html lang="en"><head><title>Help for package samurais</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {samurais}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#samurais-package'><p>SaMUraiS: StAtistical Models for the UnsupeRvised segmentAtIon of time-Series</p></a></li>
<li><a href='#emHMMR'><p>emHMMR implemens the EM (Baum-Welch) algorithm to fit a HMMR model.</p></a></li>
<li><a href='#emMHMMR'><p>emMHMMR implemens the EM (Baum-Welch) algorithm to fit a MHMMR model.</p></a></li>
<li><a href='#emMRHLP'><p>emMRHLP implemens the EM algorithm to fit a MRHLP model.</p></a></li>
<li><a href='#emRHLP'><p>emRHLP implements the EM algorithm to fit a RHLP model.</p></a></li>
<li><a href='#fitPWRFisher'><p>fitPWRFisher implements an optimized dynamic programming algorithm to fit a</p>
PWR model.</a></li>
<li><a href='#hmmProcess'><p>hmmProcess calculates the probability distribution of a random process</p>
following a Markov chain</a></li>
<li><a href='#MData-class'><p>A Reference Class which represents multivariate data.</p></a></li>
<li><a href='#mkStochastic'><p>mkStochastic ensures that it is a stochastic vector, matrix or array.</p></a></li>
<li><a href='#ModelHMMR-class'><p>A Reference Class which represents a fitted HMMR model.</p></a></li>
<li><a href='#ModelMHMMR-class'><p>A Reference Class which represents a fitted MHMMR model.</p></a></li>
<li><a href='#ModelMRHLP-class'><p>A Reference Class which represents a fitted MRHLP model.</p></a></li>
<li><a href='#ModelPWR-class'><p>A Reference Class which represents a fitted PWR model.</p></a></li>
<li><a href='#ModelRHLP-class'><p>A Reference Class which represents a fitted RHLP model.</p></a></li>
<li><a href='#multivrealdataset'><p>Time series representing the three acceleration components recorded over time</p>
with body mounted accelerometers during the activity of a given person.</a></li>
<li><a href='#multivtoydataset'><p>A simulated non-stationary multidimensional time series with regime changes.</p></a></li>
<li><a href='#ParamHMMR-class'><p>A Reference Class which contains parameters of a HMMR model.</p></a></li>
<li><a href='#ParamMHMMR-class'><p>A Reference Class which contains parameters of a MHMMR model.</p></a></li>
<li><a href='#ParamMRHLP-class'><p>A Reference Class which contains the parameters of a MRHLP model.</p></a></li>
<li><a href='#ParamPWR-class'><p>A Reference Class which contains the parameters of a PWR model.</p></a></li>
<li><a href='#ParamRHLP-class'><p>A Reference Class which contains parameters of a RHLP model.</p></a></li>
<li><a href='#selectHMMR'><p>selectHMMR implements a model selection procedure to select an optimal HMMR</p>
model with unknown structure.</a></li>
<li><a href='#selectMHMMR'><p>selectMHMMR implements a model selection procedure to select an optimal MHMMR</p>
model with unknown structure.</a></li>
<li><a href='#selectMRHLP'><p>selecMRHLP implements a model selection procedure to select an optimal MRHLP</p>
model with unknown structure.</a></li>
<li><a href='#selectRHLP'><p>selecRHLP implements a model selection procedure to select an optimal RHLP</p>
model with unknown structure.</a></li>
<li><a href='#StatHMMR-class'><p>A Reference Class which contains statistics of a HMMR model.</p></a></li>
<li><a href='#StatMHMMR-class'><p>A Reference Class which contains statistics of a MHMMR model.</p></a></li>
<li><a href='#StatMRHLP-class'><p>A Reference Class which contains statistics of a MRHLP model.</p></a></li>
<li><a href='#StatPWR-class'><p>A Reference Class which contains statistics of a PWR model.</p></a></li>
<li><a href='#StatRHLP-class'><p>A Reference Class which contains statistics of a RHLP model.</p></a></li>
<li><a href='#univrealdataset'><p>Time series representing the electrical power consumption during a railway switch</p>
operation</a></li>
<li><a href='#univtoydataset'><p>A simulated non-stationary time series with regime changes.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Statistical Models for the Unsupervised Segmentation of
Time-Series ('SaMUraiS')</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides a variety of original and flexible user-friendly 
    statistical latent variable models and unsupervised learning algorithms to 
    segment and represent time-series data (univariate or multivariate), and 
    more generally, longitudinal data, which include regime changes. 
    'samurais' is built upon the following packages, each of them is an 
    autonomous time-series segmentation approach: Regression with Hidden 
    Logistic Process ('RHLP'), Hidden Markov Model Regression ('HMMR'), 
    Multivariate 'RHLP' ('MRHLP'), Multivariate 'HMMR' ('MHMMR'), Piece-Wise 
    regression ('PWR'). For the advantages/differences of each of them, the 
    user is referred to our mentioned paper references.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/fchamroukhi/SaMUraiS">https://github.com/fchamroukhi/SaMUraiS</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, stats, MASS, Rcpp</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Collate:</td>
<td>samurais-package.R RcppExports.R utils.R dynamicProg.R
fitPWRFisher.R mkStochastic.R hmmProcess.R MData.R ParamHMMR.R
ParamMHMMR.R ParamMRHLP.R ParamPWR.R ParamRHLP.R StatHMMR.R
StatMHMMR.R StatMRHLP.R StatPWR.R StatRHLP.R ModelHMMR.R
ModelMHMMR.R ModelMRHLP.R ModelPWR.R ModelRHLP.R emHMMR.R
emMHMMR.R emMRHLP.R emRHLP.R selectHMMR.R selectMHMMR.R
selectMRHLP.R selectRHLP.R data-multivrealdataset.R
data-multivtoydataset.R data-univrealdataset.R
data-univtoydataset.R</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-07-25 16:23:38 UTC; lecocq191</td>
</tr>
<tr>
<td>Author:</td>
<td>Faicel Chamroukhi <a href="https://orcid.org/0000-0002-5894-3103"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Marius Bartcus [aut],
  Florian Lecocq [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Florian Lecocq &lt;florian.lecocq@outlook.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-07-28 09:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='samurais-package'>SaMUraiS: StAtistical Models for the UnsupeRvised segmentAtIon of time-Series</h2><span id='topic+samurais'></span><span id='topic+samurais-package'></span>

<h3>Description</h3>

<p><code>samurais</code> is a toolbox including many original and flexible
user-friendly statistical latent variable models and efficient unsupervised
algorithms to segment and represent time-series data (univariate or
multivariate), and more generally, longitudinal data, which include regime
changes.
</p>
<p><code>samurais</code> contains the following time series segmentation models:
</p>

<ul>
<li><p> RHLP;
</p>
</li>
<li><p> HMM/HMMR;
</p>
</li>
<li><p> PWR;
</p>
</li>
<li><p> MRHLP;
</p>
</li>
<li><p> MHMMR;
</p>
</li></ul>

<p>For the advantages/differences of each of them, the user is referred to our
mentioned paper references.
</p>
<p>To learn more about <code>samurais</code>, start with the vignettes:
<code>browseVignettes(package = "samurais")</code>
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Florian Lecocq <a href="mailto:florian.lecocq@outlook.com">florian.lecocq@outlook.com</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Faicel Chamroukhi <a href="mailto:faicel.chamroukhi@unicaen.fr">faicel.chamroukhi@unicaen.fr</a> (0000-0002-5894-3103)
</p>
</li>
<li><p> Marius Bartcus <a href="mailto:marius.bartcus@gmail.com">marius.bartcus@gmail.com</a>
</p>
</li></ul>



<h3>References</h3>

<p>Chamroukhi, F., and Hien D. Nguyen. 2019. <em>Model-Based Clustering and Classification of Functional Data.</em> Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery. <a href="https://doi.org/10.1002/widm.1298">https://doi.org/10.1002/widm.1298</a>.
</p>
<p>Chamroukhi, F. 2015. <em>Statistical Learning of Latent Data Models for Complex Data Analysis.</em> Habilitation Thesis (HDR), Universite de Toulon. <a href="https://chamroukhi.com/Dossier/FChamroukhi-Habilitation.pdf">https://chamroukhi.com/Dossier/FChamroukhi-Habilitation.pdf</a>.
</p>
<p>Trabelsi, D., S. Mohammed, F. Chamroukhi, L. Oukhellou, and Y. Amirat. 2013. <em>An Unsupervised Approach for Automatic Activity Recognition Based on Hidden Markov Model Regression.</em> IEEE Transactions on Automation Science and Engineering 3 (10): 829&ndash;335. <a href="https://chamroukhi.com/papers/Chamroukhi-MHMMR-IeeeTase.pdf">https://chamroukhi.com/papers/Chamroukhi-MHMMR-IeeeTase.pdf</a>.
</p>
<p>Chamroukhi, F., D. Trabelsi, S. Mohammed, L. Oukhellou, and Y. Amirat. 2013. <em>Joint Segmentation of Multivariate Time Series with Hidden Process Regression for Human Activity Recognition.</em> Neurocomputing 120: 633&ndash;44. <a href="https://chamroukhi.com/papers/chamroukhi_et_al_neucomp2013b.pdf">https://chamroukhi.com/papers/chamroukhi_et_al_neucomp2013b.pdf</a>.
</p>
<p>Chamroukhi, F., A. Same, G. Govaert, and P. Aknin. 2010. <em>A Hidden Process Regression Model for Functional Data Description. Application to Curve Discrimination.</em> Neurocomputing 73 (7-9): 1210&ndash;21. <a href="https://chamroukhi.com/papers/chamroukhi_neucomp_2010.pdf">https://chamroukhi.com/papers/chamroukhi_neucomp_2010.pdf</a>.
</p>
<p>Chamroukhi, F. 2010. <em>Hidden Process Regression for Curve Modeling, Classification and Tracking.</em> Ph.D. Thesis, Universite de Technologie de Compiegne. <a href="https://chamroukhi.com/papers/FChamroukhi-Thesis.pdf">https://chamroukhi.com/papers/FChamroukhi-Thesis.pdf</a>.
</p>
<p>Chamroukhi, F., A. Same, G. Govaert, and P. Aknin. 2009. <em>Time Series Modeling by a Regression Approach Based on a Latent Process.</em> Neural Networks 22 (5-6): 593&ndash;602. <a href="https://chamroukhi.com/papers/Chamroukhi_Neural_Networks_2009.pdf">https://chamroukhi.com/papers/Chamroukhi_Neural_Networks_2009.pdf</a>.
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/fchamroukhi/SaMUraiS">https://github.com/fchamroukhi/SaMUraiS</a>
</p>
</li></ul>


<hr>
<h2 id='emHMMR'>emHMMR implemens the EM (Baum-Welch) algorithm to fit a HMMR model.</h2><span id='topic+emHMMR'></span>

<h3>Description</h3>

<p>emHMMR implements the maximum-likelihood parameter estimation of the HMMR
model by the Expectation-Maximization (EM) algorithm, known as Baum-Welch
algorithm in the context of HMMs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emHMMR(X, Y, K, p = 3, variance_type = c("heteroskedastic",
  "homoskedastic"), n_tries = 1, max_iter = 1500, threshold = 1e-06,
  verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="emHMMR_+3A_x">X</code></td>
<td>
<p>Numeric vector of length <em>m</em> representing the covariates/inputs
<code class="reqn">x_{1},\dots,x_{m}</code>.</p>
</td></tr>
<tr><td><code id="emHMMR_+3A_y">Y</code></td>
<td>
<p>Numeric vector of length <em>m</em> representing the observed
response/output <code class="reqn">y_{1},\dots,y_{m}</code>.</p>
</td></tr>
<tr><td><code id="emHMMR_+3A_k">K</code></td>
<td>
<p>The number of regimes/segments (HMMR components).</p>
</td></tr>
<tr><td><code id="emHMMR_+3A_p">p</code></td>
<td>
<p>Optional. The order of the polynomial regression. By default, <code>p</code> is
set at 3.</p>
</td></tr>
<tr><td><code id="emHMMR_+3A_variance_type">variance_type</code></td>
<td>
<p>Optional character indicating if the model is
&quot;homoskedastic&quot; or &quot;heteroskedastic&quot; (i.e same variance or different
variances for each of the K regmies). By default the model is
&quot;heteroskedastic&quot;.</p>
</td></tr>
<tr><td><code id="emHMMR_+3A_n_tries">n_tries</code></td>
<td>
<p>Optional. Number of runs of the EM algorithm. The solution
providing the highest log-likelihood will be returned.
</p>
<p>If <code>n_tries</code> &gt; 1, then for the first run, parameters are initialized by
uniformly segmenting the data into K segments, and for the next runs,
parameters are initialized by randomly segmenting the data into K
contiguous segments.</p>
</td></tr>
<tr><td><code id="emHMMR_+3A_max_iter">max_iter</code></td>
<td>
<p>Optional. The maximum number of iterations for the EM
algorithm.</p>
</td></tr>
<tr><td><code id="emHMMR_+3A_threshold">threshold</code></td>
<td>
<p>Optional. A numeric value specifying the threshold for the
relative difference of log-likelihood between two steps of the EM as
stopping criteria.</p>
</td></tr>
<tr><td><code id="emHMMR_+3A_verbose">verbose</code></td>
<td>
<p>Optional. A logical value indicating whether or not values of
the log-likelihood should be printed during EM iterations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>emHMMR function implements the EM algorithm for the HMMR model. This
function starts with an initialization of the parameters done by the method
<code>initParam</code> of the class <a href="#topic+ParamHMMR">ParamHMMR</a>, then it alternates between
the E-Step (method of the class <a href="#topic+StatHMMR">StatHMMR</a>) and the M-Step
(method of the class <a href="#topic+ParamHMMR">ParamHMMR</a>) until convergence (until the
relative variation of log-likelihood between two steps of the EM algorithm
is less than the <code>threshold</code> parameter).
</p>


<h3>Value</h3>

<p>EM returns an object of class <a href="#topic+ModelHMMR">ModelHMMR</a>.
</p>


<h3>See Also</h3>

<p><a href="#topic+ModelHMMR">ModelHMMR</a>, <a href="#topic+ParamHMMR">ParamHMMR</a>, <a href="#topic+StatHMMR">StatHMMR</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(univtoydataset)
hmmr &lt;- emHMMR(univtoydataset$x, univtoydataset$y, K = 5, p = 1, verbose = TRUE)

hmmr$summary()

hmmr$plot()

</code></pre>

<hr>
<h2 id='emMHMMR'>emMHMMR implemens the EM (Baum-Welch) algorithm to fit a MHMMR model.</h2><span id='topic+emMHMMR'></span>

<h3>Description</h3>

<p>emMHMMR implements the maximum-likelihood parameter estimation of the MHMMR
model by the Expectation-Maximization (EM) algorithm, known as Baum-Welch
algorithm in the context of HMMs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emMHMMR(X, Y, K, p = 3, variance_type = c("heteroskedastic",
  "homoskedastic"), n_tries = 1, max_iter = 1500, threshold = 1e-06,
  verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="emMHMMR_+3A_x">X</code></td>
<td>
<p>Numeric vector of length <em>m</em> representing the covariates/inputs
<code class="reqn">x_{1},\dots,x_{m}</code>.</p>
</td></tr>
<tr><td><code id="emMHMMR_+3A_y">Y</code></td>
<td>
<p>Matrix of size <code class="reqn">(m, d)</code> representing a <code class="reqn">d</code> dimension time
series observed at points <code class="reqn">1,\dots,m</code>.</p>
</td></tr>
<tr><td><code id="emMHMMR_+3A_k">K</code></td>
<td>
<p>The number of regimes (MHMMR components).</p>
</td></tr>
<tr><td><code id="emMHMMR_+3A_p">p</code></td>
<td>
<p>Optional. The order of the polynomial regression. By default, <code>p</code> is
set at 3.</p>
</td></tr>
<tr><td><code id="emMHMMR_+3A_variance_type">variance_type</code></td>
<td>
<p>Optional character indicating if the model is
&quot;homoskedastic&quot; or &quot;heteroskedastic&quot;. By default the model is
&quot;heteroskedastic&quot;.</p>
</td></tr>
<tr><td><code id="emMHMMR_+3A_n_tries">n_tries</code></td>
<td>
<p>Optional. Number of runs of the EM algorithm. The solution
providing the highest log-likelihood will be returned.
</p>
<p>If <code>n_tries</code> &gt; 1, then for the first run, parameters are initialized by
uniformly segmenting the data into K segments, and for the next runs,
parameters are initialized by randomly segmenting the data into K
contiguous segments.</p>
</td></tr>
<tr><td><code id="emMHMMR_+3A_max_iter">max_iter</code></td>
<td>
<p>Optional. The maximum number of iterations for the EM
algorithm.</p>
</td></tr>
<tr><td><code id="emMHMMR_+3A_threshold">threshold</code></td>
<td>
<p>Optional. A numeric value specifying the threshold for the
relative difference of log-likelihood between two steps of the EM as
stopping criteria.</p>
</td></tr>
<tr><td><code id="emMHMMR_+3A_verbose">verbose</code></td>
<td>
<p>Optional. A logical value indicating whether or not values of
the log-likelihood should be printed during EM iterations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>emMHMMR function implements the EM algorithm. This function starts
with an initialization of the parameters done by the method <code>initParam</code> of
the class <a href="#topic+ParamMHMMR">ParamMHMMR</a>, then it alternates between the E-Step
(method of the class <a href="#topic+StatMHMMR">StatMHMMR</a>) and the M-Step (method of the
class <a href="#topic+ParamMHMMR">ParamMHMMR</a>) until convergence (until the relative
variation of log-likelihood between two steps of the EM algorithm is less
than the <code>threshold</code> parameter).
</p>


<h3>Value</h3>

<p>EM returns an object of class <a href="#topic+ModelMHMMR">ModelMHMMR</a>.
</p>


<h3>See Also</h3>

<p><a href="#topic+ModelMHMMR">ModelMHMMR</a>, <a href="#topic+ParamMHMMR">ParamMHMMR</a>, <a href="#topic+StatMHMMR">StatMHMMR</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(multivtoydataset)

mhmmr &lt;- emMHMMR(multivtoydataset$x, multivtoydataset[,c("y1", "y2", "y3")],
                 K = 5, p = 1, verbose = TRUE)

mhmmr$summary()

mhmmr$plot()
</code></pre>

<hr>
<h2 id='emMRHLP'>emMRHLP implemens the EM algorithm to fit a MRHLP model.</h2><span id='topic+emMRHLP'></span>

<h3>Description</h3>

<p>emMRHLP implements the maximum-likelihood parameter estimation of the MRHLP
model by the Expectation-Maximization (EM) algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emMRHLP(X, Y, K, p = 3, q = 1, variance_type = c("heteroskedastic",
  "homoskedastic"), n_tries = 1, max_iter = 1500, threshold = 1e-06,
  verbose = FALSE, verbose_IRLS = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="emMRHLP_+3A_x">X</code></td>
<td>
<p>Numeric vector of length <em>m</em> representing the covariates/inputs
<code class="reqn">x_{1},\dots,x_{m}</code>.</p>
</td></tr>
<tr><td><code id="emMRHLP_+3A_y">Y</code></td>
<td>
<p>Matrix of size <code class="reqn">(m, d)</code> representing a <code class="reqn">d</code> dimension
function of <code>X</code> observed at points <code class="reqn">1,\dots,m</code>. <code>Y</code> is the observed
response/output.</p>
</td></tr>
<tr><td><code id="emMRHLP_+3A_k">K</code></td>
<td>
<p>The number of regimes (MRHLP components).</p>
</td></tr>
<tr><td><code id="emMRHLP_+3A_p">p</code></td>
<td>
<p>Optional. The order of the polynomial regression. By default, <code>p</code> is
set at 3.</p>
</td></tr>
<tr><td><code id="emMRHLP_+3A_q">q</code></td>
<td>
<p>Optional. The dimension of the logistic regression. For the purpose
of segmentation, it must be set to 1 (which is the default value).</p>
</td></tr>
<tr><td><code id="emMRHLP_+3A_variance_type">variance_type</code></td>
<td>
<p>Optional character indicating if the model is
&quot;homoskedastic&quot; or &quot;heteroskedastic&quot;. By default the model is
&quot;heteroskedastic&quot;.</p>
</td></tr>
<tr><td><code id="emMRHLP_+3A_n_tries">n_tries</code></td>
<td>
<p>Optional. Number of runs of the EM algorithm. The solution
providing the highest log-likelihood will be returned.
</p>
<p>If <code>n_tries</code> &gt; 1, then for the first run, parameters are initialized by
uniformly segmenting the data into K segments, and for the next runs,
parameters are initialized by randomly segmenting the data into K
contiguous segments.</p>
</td></tr>
<tr><td><code id="emMRHLP_+3A_max_iter">max_iter</code></td>
<td>
<p>Optional. The maximum number of iterations for the EM
algorithm.</p>
</td></tr>
<tr><td><code id="emMRHLP_+3A_threshold">threshold</code></td>
<td>
<p>Optional. A numeric value specifying the threshold for the
relative difference of log-likelihood between two steps of the EM as
stopping criteria.</p>
</td></tr>
<tr><td><code id="emMRHLP_+3A_verbose">verbose</code></td>
<td>
<p>Optional. A logical value indicating whether or not values of
the log-likelihood should be printed during EM iterations.</p>
</td></tr>
<tr><td><code id="emMRHLP_+3A_verbose_irls">verbose_IRLS</code></td>
<td>
<p>Optional. A logical value indicating whether or not
values of the criterion optimized by IRLS should be printed at each step of
the EM algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>emMRHLP function implements the EM algorithm of the MRHLP model.
This function starts with an initialization of the parameters done by the
method <code>initParam</code> of the class <a href="#topic+ParamMRHLP">ParamMRHLP</a>, then it
alternates between the E-Step (method of the class <a href="#topic+StatMRHLP">StatMRHLP</a>)
and the M-Step (method of the class <a href="#topic+ParamMRHLP">ParamMRHLP</a>) until
convergence (until the relative variation of log-likelihood between two
steps of the EM algorithm is less than the <code>threshold</code> parameter).
</p>


<h3>Value</h3>

<p>EM returns an object of class <a href="#topic+ModelMRHLP">ModelMRHLP</a>.
</p>


<h3>See Also</h3>

<p><a href="#topic+ModelMRHLP">ModelMRHLP</a>, <a href="#topic+ParamMRHLP">ParamMRHLP</a>, <a href="#topic+StatMRHLP">StatMRHLP</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(multivtoydataset)

mrhlp &lt;- emMRHLP(multivtoydataset$x, multivtoydataset[,c("y1", "y2", "y3")],
                 K = 5, p = 1, verbose = TRUE)

mrhlp$summary()

mrhlp$plot()
</code></pre>

<hr>
<h2 id='emRHLP'>emRHLP implements the EM algorithm to fit a RHLP model.</h2><span id='topic+emRHLP'></span>

<h3>Description</h3>

<p>emRHLP implements the maximum-likelihood parameter estimation of the RHLP
model by the Expectation-Maximization (EM) algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emRHLP(X, Y, K, p = 3, q = 1, variance_type = c("heteroskedastic",
  "homoskedastic"), n_tries = 1, max_iter = 1500, threshold = 1e-06,
  verbose = FALSE, verbose_IRLS = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="emRHLP_+3A_x">X</code></td>
<td>
<p>Numeric vector of length <em>m</em> representing the covariates/inputs
<code class="reqn">x_{1},\dots,x_{m}</code>.</p>
</td></tr>
<tr><td><code id="emRHLP_+3A_y">Y</code></td>
<td>
<p>Numeric vector of length <em>m</em> representing the observed
response/output <code class="reqn">y_{1},\dots,y_{m}</code>.</p>
</td></tr>
<tr><td><code id="emRHLP_+3A_k">K</code></td>
<td>
<p>The number of regimes (RHLP components).</p>
</td></tr>
<tr><td><code id="emRHLP_+3A_p">p</code></td>
<td>
<p>Optional. The order of the polynomial regression. By default, <code>p</code> is
set at 3.</p>
</td></tr>
<tr><td><code id="emRHLP_+3A_q">q</code></td>
<td>
<p>Optional. The dimension of the logistic regression. For the purpose
of segmentation, it must be set to 1 (which is the default value).</p>
</td></tr>
<tr><td><code id="emRHLP_+3A_variance_type">variance_type</code></td>
<td>
<p>Optional character indicating if the model is
&quot;homoskedastic&quot; or &quot;heteroskedastic&quot;. By default the model is
&quot;heteroskedastic&quot;.</p>
</td></tr>
<tr><td><code id="emRHLP_+3A_n_tries">n_tries</code></td>
<td>
<p>Optional. Number of runs of the EM algorithm. The solution
providing the highest log-likelihood will be returned.
</p>
<p>If <code>n_tries</code> &gt; 1, then for the first run, parameters are initialized by
uniformly segmenting the data into K segments, and for the next runs,
parameters are initialized by randomly segmenting the data into K
contiguous segments.</p>
</td></tr>
<tr><td><code id="emRHLP_+3A_max_iter">max_iter</code></td>
<td>
<p>Optional. The maximum number of iterations for the EM
algorithm.</p>
</td></tr>
<tr><td><code id="emRHLP_+3A_threshold">threshold</code></td>
<td>
<p>Optional. A numeric value specifying the threshold for the
relative difference of log-likelihood between two steps of the EM as
stopping criteria.</p>
</td></tr>
<tr><td><code id="emRHLP_+3A_verbose">verbose</code></td>
<td>
<p>Optional. A logical value indicating whether or not values of
the log-likelihood should be printed during EM iterations.</p>
</td></tr>
<tr><td><code id="emRHLP_+3A_verbose_irls">verbose_IRLS</code></td>
<td>
<p>Optional. A logical value indicating whether or not
values of the criterion optimized by IRLS should be printed at each step of
the EM algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>emRHLP function implements the EM algorithm for the RHLP model. This
function starts with an initialization of the parameters done by the method
<code>initParam</code> of the class <a href="#topic+ParamRHLP">ParamRHLP</a>, then it alternates between
the E-Step (method of the class <a href="#topic+StatRHLP">StatRHLP</a>) and the M-Step
(method of the class <a href="#topic+ParamRHLP">ParamRHLP</a>) until convergence (until the
relative variation of log-likelihood between two steps of the EM algorithm
is less than the <code>threshold</code> parameter).
</p>


<h3>Value</h3>

<p>EM returns an object of class <a href="#topic+ModelRHLP">ModelRHLP</a>.
</p>


<h3>See Also</h3>

<p><a href="#topic+ModelRHLP">ModelRHLP</a>, <a href="#topic+ParamRHLP">ParamRHLP</a>, <a href="#topic+StatRHLP">StatRHLP</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(univtoydataset)

rhlp &lt;- emRHLP(univtoydataset$x, univtoydataset$y, K = 3, p = 1, verbose = TRUE)

rhlp$summary()

rhlp$plot()
</code></pre>

<hr>
<h2 id='fitPWRFisher'>fitPWRFisher implements an optimized dynamic programming algorithm to fit a
PWR model.</h2><span id='topic+fitPWRFisher'></span>

<h3>Description</h3>

<p>fitPWRFisher is used to fit a Piecewise Regression (PWR) model by
maximum-likelihood via an optimized dynamic programming algorithm. The
estimation performed by the dynamic programming algorithm provides an optimal
segmentation of the time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitPWRFisher(X, Y, K, p = 3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitPWRFisher_+3A_x">X</code></td>
<td>
<p>Numeric vector of length <em>m</em> representing the covariates/inputs
<code class="reqn">x_{1},\dots,x_{m}</code>.</p>
</td></tr>
<tr><td><code id="fitPWRFisher_+3A_y">Y</code></td>
<td>
<p>Numeric vector of length <em>m</em> representing the observed
response/output <code class="reqn">y_{1},\dots,y_{m}</code>.</p>
</td></tr>
<tr><td><code id="fitPWRFisher_+3A_k">K</code></td>
<td>
<p>The number of regimes/segments (PWR components).</p>
</td></tr>
<tr><td><code id="fitPWRFisher_+3A_p">p</code></td>
<td>
<p>Optional. The order of the polynomial regression. By default, <code>p</code> is
set at 3.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>fitPWRFisher function implements an optimized dynamic programming
algorithm of the PWR model. This function starts with the calculation of
the &quot;cost matrix&quot; then it estimates the transition points given <code>K</code> the
number of regimes thanks to the method <code>computeDynamicProgram</code> (method of
the class <a href="#topic+ParamPWR">ParamPWR</a>).
</p>


<h3>Value</h3>

<p>fitPWRFisher returns an object of class <a href="#topic+ModelPWR">ModelPWR</a>.
</p>


<h3>See Also</h3>

<p><a href="#topic+ModelPWR">ModelPWR</a>, <a href="#topic+ParamPWR">ParamPWR</a>, <a href="#topic+StatPWR">StatPWR</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(univtoydataset)

pwr &lt;- fitPWRFisher(univtoydataset$x, univtoydataset$y, K = 5, p = 1)

pwr$summary()

pwr$plot()
</code></pre>

<hr>
<h2 id='hmmProcess'>hmmProcess calculates the probability distribution of a random process
following a Markov chain</h2><span id='topic+hmmProcess'></span>

<h3>Description</h3>

<p>hmmProcess calculates the probability distribution of a random process
following a Markov chain
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hmmProcess(prior, trans_mat, n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hmmProcess_+3A_prior">prior</code></td>
<td>
<p>Numeric vector or a one row matrix of length K representing the
prior probabilities of the Markov chain.</p>
</td></tr>
<tr><td><code id="hmmProcess_+3A_trans_mat">trans_mat</code></td>
<td>
<p>Matrix of size <code class="reqn">(K, K)</code> representing the transition
matrix of the Markov chain.</p>
</td></tr>
<tr><td><code id="hmmProcess_+3A_n">n</code></td>
<td>
<p>Numeric. Number of variables of the Markov chain.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>hmmProcess calculates the distribution
<code class="reqn">P(Z_{1},\dots,Z_{n};\pi,A)</code> of a Markov chain
<code class="reqn">(Z_{1},\dots,Z_{n})</code> with prior probability <code class="reqn">\pi</code> and transition
matrix <code class="reqn">A</code>.
</p>
<p>The calculation is based on the following formula:
</p>
<p><code class="reqn">P(Z_{i} = k) = \sum_{l} P(Z_{i} = k, Z_{i-1} = l) = \sum_{l} P(Z_{i} =
  k | Z_{i-1} = l) \times P(Z_{i-1} = l) = \sum_{l} A_{lk} \times
  P(Z_{i-1})</code>
</p>


<h3>Value</h3>

<p>Matrix of size <code class="reqn">(n, K)</code> giving the distribution of process given
the K-state Markov chain parameters.
</p>

<hr>
<h2 id='MData-class'>A Reference Class which represents multivariate data.</h2><span id='topic+MData-class'></span><span id='topic+MData'></span>

<h3>Description</h3>

<p>MData is a reference class which represents multivariate objects. The data
can be ordered by time (multivariate time series). In the last case, the
field <code>X</code> represents the time.
</p>


<h3>Fields</h3>


<dl>
<dt><code>X</code></dt><dd><p>Numeric vector of length <em>m</em>.</p>
</dd>
<dt><code>Y</code></dt><dd><p>Matrix of size <code class="reqn">(m, d)</code> representing a <code class="reqn">d</code> dimension
function of <code>X</code> observed at points <code class="reqn">1,\dots,m</code>.</p>
</dd>
</dl>

<hr>
<h2 id='mkStochastic'>mkStochastic ensures that it is a stochastic vector, matrix or array.</h2><span id='topic+mkStochastic'></span>

<h3>Description</h3>

<p>mkStochastic ensures that it is a stochastic vector, matrix or array.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mkStochastic(M)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mkStochastic_+3A_m">M</code></td>
<td>
<p>A vector, matrix or array to transform.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>mkStochastic ensures that the giving argument is a stochastic
vector, matrix or array, i.e., that the sum over the last dimension is 1.
</p>


<h3>Value</h3>

<p>A vector, matrix or array for which the sum over the last dimension
is 1.
</p>

<hr>
<h2 id='ModelHMMR-class'>A Reference Class which represents a fitted HMMR model.</h2><span id='topic+ModelHMMR-class'></span><span id='topic+ModelHMMR'></span>

<h3>Description</h3>

<p>ModelHMMR represents an estimated HMMR model.
</p>


<h3>Fields</h3>


<dl>
<dt><code>param</code></dt><dd><p>An object of class <a href="#topic+ParamHMMR">ParamHMMR</a>. It contains the
estimated values of the parameters.</p>
</dd>
<dt><code>stat</code></dt><dd><p>An object of class <a href="#topic+StatHMMR">StatHMMR</a>. It contains all the
statistics associated to the HMMR model.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>plot(what = c("predicted", "filtered", "smoothed", "regressors",
  "loglikelihood"), ...)</code></dt><dd><p>Plot method.
</p>

<dl>
<dt><code>what</code></dt><dd><p>The type of graph requested:
</p>

<ul>
<li> <p><code>"predicted" = </code> Predicted time series and predicted
regime probabilities (fields <code>predicted</code> and
<code>predict_prob</code> of class <a href="#topic+StatHMMR">StatHMMR</a>).
</p>
</li>
<li> <p><code>"filtered" = </code> Filtered time series and filtering
regime probabilities (fields <code>filtered</code> and
<code>filter_prob</code> of class <a href="#topic+StatHMMR">StatHMMR</a>).
</p>
</li>
<li> <p><code>"smoothed" = </code> Smoothed time series, and
segmentation (fields <code>smoothed</code> and <code>klas</code> of the
class StatHMMR).
</p>
</li>
<li> <p><code>"regressors" = </code> Polynomial regression components
(fields <code>regressors</code> and <code>tau_tk</code> of class
<a href="#topic+StatHMMR">StatHMMR</a>).
</p>
</li>
<li> <p><code>"loglikelihood" = </code> Value of the log-likelihood for
each iteration (field <code>stored_loglik</code> of class
<a href="#topic+StatHMMR">StatHMMR</a>).
</p>
</li></ul>

</dd>
<dt><code>...</code></dt><dd><p>Other graphics parameters.</p>
</dd>
</dl>

<p>By default, all the graphs mentioned above are produced.</p>
</dd>
<dt><code>summary(digits = getOption("digits"))</code></dt><dd><p>Summary method.
</p>

<dl>
<dt><code>digits</code></dt><dd><p>The number of significant digits to use when
printing.</p>
</dd>
</dl>
</dd>
</dl>


<h3>See Also</h3>

<p><a href="#topic+ParamHMMR">ParamHMMR</a>, <a href="#topic+StatHMMR">StatHMMR</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(univtoydataset)

hmmr &lt;- emHMMR(univtoydataset$x, univtoydataset$y, K = 5, p = 1, verbose = TRUE)

# hmmr is a ModelHMMR object. It contains some methods such as 'summary' and 'plot'
hmmr$summary()
hmmr$plot()

# hmmr has also two fields, stat and param which are reference classes as well

# Log-likelihood:
hmmr$stat$loglik

# Parameters of the polynomial regressions:
hmmr$param$beta
</code></pre>

<hr>
<h2 id='ModelMHMMR-class'>A Reference Class which represents a fitted MHMMR model.</h2><span id='topic+ModelMHMMR-class'></span><span id='topic+ModelMHMMR'></span>

<h3>Description</h3>

<p>ModelMHMMR represents an estimated MHMMR model.
</p>


<h3>Fields</h3>


<dl>
<dt><code>param</code></dt><dd><p>A <a href="#topic+ParamMHMMR">ParamMHMMR</a> object. It contains the estimated
values of the parameters.</p>
</dd>
<dt><code>stat</code></dt><dd><p>A <a href="#topic+StatMHMMR">StatMHMMR</a> object. It contains all the statistics
associated to the MHMMR model.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>plot(what = c("predicted", "filtered", "smoothed", "regressors",
  "loglikelihood"), ...)</code></dt><dd><p>Plot method.
</p>

<dl>
<dt><code>what</code></dt><dd><p>The type of graph requested:
</p>

<ul>
<li> <p><code>"predicted" = </code> Predicted time series and predicted
regime probabilities (fields <code>predicted</code> and
<code>predict_prob</code> of class <a href="#topic+StatMHMMR">StatMHMMR</a>).
</p>
</li>
<li> <p><code>"filtered" = </code> Filtered time series and filtering
regime probabilities (fields <code>filtered</code> and
<code>filter_prob</code> of class <a href="#topic+StatMHMMR">StatMHMMR</a>).
</p>
</li>
<li> <p><code>"smoothed" = </code> Smoothed time series, and
segmentation (fields <code>smoothed</code> and <code>klas</code> of class
<a href="#topic+StatMHMMR">StatMHMMR</a>).
</p>
</li>
<li> <p><code>"regressors" = </code> Polynomial regression components
(fields <code>regressors</code> and <code>tau_tk</code> of class
<a href="#topic+StatMHMMR">StatMHMMR</a>).
</p>
</li>
<li> <p><code>"loglikelihood" = </code> Value of the log-likelihood for
each iteration (field <code>stored_loglik</code> of class
<a href="#topic+StatMHMMR">StatMHMMR</a>).
</p>
</li></ul>

</dd>
<dt><code>...</code></dt><dd><p>Other graphics parameters.</p>
</dd>
</dl>

<p>By default, all the above graphs are produced.</p>
</dd>
<dt><code>summary(digits = getOption("digits"))</code></dt><dd><p>Summary method.
</p>

<dl>
<dt><code>digits</code></dt><dd><p>The number of significant digits to use when
printing.</p>
</dd>
</dl>
</dd>
</dl>


<h3>See Also</h3>

<p><a href="#topic+ParamMHMMR">ParamMHMMR</a>, <a href="#topic+StatMHMMR">StatMHMMR</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(multivtoydataset)

mhmmr &lt;- emMHMMR(multivtoydataset$x, multivtoydataset[,c("y1", "y2", "y3")],
                 K = 5, p = 1, verbose = TRUE)

# mhmmr is a ModelMHMMR object. It contains some methods such as 'summary' and 'plot'
mhmmr$summary()
mhmmr$plot()

# mhmmr has also two fields, stat and param which are reference classes as well

# Log-likelihood:
mhmmr$stat$loglik

# Parameters of the polynomial regressions:
mhmmr$param$beta
</code></pre>

<hr>
<h2 id='ModelMRHLP-class'>A Reference Class which represents a fitted MRHLP model.</h2><span id='topic+ModelMRHLP-class'></span><span id='topic+ModelMRHLP'></span>

<h3>Description</h3>

<p>ModelMRHLP represents an estimated MRHLP model.
</p>


<h3>Fields</h3>


<dl>
<dt><code>param</code></dt><dd><p>A <a href="#topic+ParamMRHLP">ParamMRHLP</a> object. It contains the estimated
values of the parameters.</p>
</dd>
<dt><code>stat</code></dt><dd><p>A <a href="#topic+StatMRHLP">StatMRHLP</a> object. It contains all the statistics
associated to the MRHLP model.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>plot(what = c("regressors", "estimatedsignal", "loglikelihood"), ...)</code></dt><dd><p>Plot method.
</p>

<dl>
<dt><code>what</code></dt><dd><p>The type of graph requested:
</p>

<ul>
<li> <p><code>"regressors" = </code> Polynomial regression components
(fields <code>polynomials</code> and <code>pi_ik</code> of class
<a href="#topic+StatMRHLP">StatMRHLP</a>).
</p>
</li>
<li> <p><code>"estimatedsignal" = </code> Estimated signal (fields
<code>Ex</code> and <code>klas</code> of class <a href="#topic+StatMRHLP">StatMRHLP</a>).
</p>
</li>
<li> <p><code>"loglikelihood" = </code> Value of the log-likelihood for
each iteration (field <code>stored_loglik</code> of class
<a href="#topic+StatMRHLP">StatMRHLP</a>).
</p>
</li></ul>

</dd>
<dt><code>...</code></dt><dd><p>Other graphics parameters.</p>
</dd>
</dl>

<p>By default, all the graphs mentioned above are produced.</p>
</dd>
<dt><code>summary(digits = getOption("digits"))</code></dt><dd><p>Summary method.
</p>

<dl>
<dt><code>digits</code></dt><dd><p>The number of significant digits to use when
printing.</p>
</dd>
</dl>
</dd>
</dl>


<h3>See Also</h3>

<p><a href="#topic+ParamMRHLP">ParamMRHLP</a>, <a href="#topic+StatMRHLP">StatMRHLP</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(multivtoydataset)

mrhlp &lt;- emMRHLP(multivtoydataset$x, multivtoydataset[,c("y1", "y2", "y3")],
                 K = 5, p = 1, verbose = TRUE)

# mrhlp is a ModelMRHLP object. It contains some methods such as 'summary' and 'plot'
mrhlp$summary()
mrhlp$plot()

# mrhlp has also two fields, stat and param which are reference classes as well

# Log-likelihood:
mrhlp$stat$loglik

# Parameters of the polynomial regressions:
mrhlp$param$beta
</code></pre>

<hr>
<h2 id='ModelPWR-class'>A Reference Class which represents a fitted PWR model.</h2><span id='topic+ModelPWR-class'></span><span id='topic+ModelPWR'></span>

<h3>Description</h3>

<p>ModelPWR represents an estimated PWR model.
</p>


<h3>Fields</h3>


<dl>
<dt><code>param</code></dt><dd><p>A <a href="#topic+ParamPWR">ParamPWR</a> object. It contains the estimated values
of the parameters.</p>
</dd>
<dt><code>stat</code></dt><dd><p>A <a href="#topic+StatPWR">StatPWR</a> object. It contains all the statistics
associated to the PWR model.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>plot(what = c("regressors", "segmentation"), ...)</code></dt><dd><p>Plot method.
</p>

<dl>
<dt><code>what</code></dt><dd><p>The type of graph requested:
</p>

<ul>
<li> <p><code>"regressors" = </code> Polynomial regression components
(field <code>regressors</code> of class <a href="#topic+StatPWR">StatPWR</a>).
</p>
</li>
<li> <p><code>"segmentation" = </code> Estimated signal
(field <code>mean_function</code> of class <a href="#topic+StatPWR">StatPWR</a>).
</p>
</li></ul>

</dd>
<dt><code>...</code></dt><dd><p>Other graphics parameters.</p>
</dd>
</dl>

<p>By default, all the graphs mentioned above are produced.</p>
</dd>
<dt><code>summary(digits = getOption("digits"))</code></dt><dd><p>Summary method.
</p>

<dl>
<dt><code>digits</code></dt><dd><p>The number of significant digits to use when
printing.</p>
</dd>
</dl>
</dd>
</dl>


<h3>See Also</h3>

<p><a href="#topic+ParamPWR">ParamPWR</a>, <a href="#topic+StatPWR">StatPWR</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(univtoydataset)

pwr &lt;- fitPWRFisher(univtoydataset$x, univtoydataset$y, K = 5, p = 1)

# pwr is a ModelPWR object. It contains some methods such as 'summary' and 'plot'
pwr$summary()
pwr$plot()

# pwr has also two fields, stat and param which are reference classes as well

# Value of the objective function:
pwr$stat$objective

# Parameters of the polynomial regressions:
pwr$param$beta
</code></pre>

<hr>
<h2 id='ModelRHLP-class'>A Reference Class which represents a fitted RHLP model.</h2><span id='topic+ModelRHLP-class'></span><span id='topic+ModelRHLP'></span>

<h3>Description</h3>

<p>ModelRHLP represents an estimated RHLP model.
</p>


<h3>Fields</h3>


<dl>
<dt><code>param</code></dt><dd><p>A <a href="#topic+ParamRHLP">ParamRHLP</a> object. It contains the estimated
values of the parameters.</p>
</dd>
<dt><code>stat</code></dt><dd><p>A <a href="#topic+StatRHLP">StatRHLP</a> object. It contains all the statistics
associated to the RHLP model.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>plot(what = c("regressors", "estimatedsignal", "loglikelihood"), ...)</code></dt><dd><p>Plot method.
</p>

<dl>
<dt><code>what</code></dt><dd><p>The type of graph requested:
</p>

<ul>
<li> <p><code>"regressors" = </code> Polynomial regression components
(fields <code>polynomials</code> and <code>pi_ik</code> of class
<a href="#topic+StatRHLP">StatRHLP</a>).
</p>
</li>
<li> <p><code>"estimatedsignal" = </code> Estimated signal (fields
<code>Ex</code> and <code>klas</code> of class <a href="#topic+StatRHLP">StatRHLP</a>).
</p>
</li>
<li> <p><code>"loglikelihood" = </code> Value of the log-likelihood for
each iteration (field <code>stored_loglik</code> of class
<a href="#topic+StatRHLP">StatRHLP</a>).
</p>
</li></ul>

</dd>
<dt><code>...</code></dt><dd><p>Other graphics parameters.</p>
</dd>
</dl>

<p>By default, all the graphs mentioned above are produced.</p>
</dd>
<dt><code>summary(digits = getOption("digits"))</code></dt><dd><p>Summary method.
</p>

<dl>
<dt><code>digits</code></dt><dd><p>The number of significant digits to use when
printing.</p>
</dd>
</dl>
</dd>
</dl>


<h3>See Also</h3>

<p><a href="#topic+ParamRHLP">ParamRHLP</a>, <a href="#topic+StatRHLP">StatRHLP</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(univtoydataset)

rhlp &lt;- emRHLP(univtoydataset$x, univtoydataset$y, K = 3, p = 1, verbose = TRUE)

# rhlp is a ModelMHMMR object. It contains some methods such as 'summary' and 'plot'
rhlp$summary()
rhlp$plot()

# rhlp has also two fields, stat and param which are reference classes as well

# Log-likelihood:
rhlp$stat$loglik

# Parameters of the polynomial regressions:
rhlp$param$beta
</code></pre>

<hr>
<h2 id='multivrealdataset'>Time series representing the three acceleration components recorded over time
with body mounted accelerometers during the activity of a given person.</h2><span id='topic+multivrealdataset'></span>

<h3>Description</h3>

<p>This dataset is provided for illustration only and represents the three
acceleration components recorded over time with body mounted accelerometers
during the activity of a given person. These data consist therefore of multidimensional time series with
several regime changes over time, each regime is associated with an activity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multivrealdataset
</code></pre>


<h3>Format</h3>

<p>A data frame with 2253 rows and 4 columns:
</p>

<dl>
<dt>x</dt><dd><p>The covariate variable (the sampling time).</p>
</dd>
<dt>y1</dt><dd><p>X axis component of the acceleration.</p>
</dd>
<dt>y2</dt><dd><p>Y axis component of the acceleration.</p>
</dd>
<dt>y3</dt><dd><p>Z axis component of the acceleration.</p>
</dd>
</dl>

<hr>
<h2 id='multivtoydataset'>A simulated non-stationary multidimensional time series with regime changes.</h2><span id='topic+multivtoydataset'></span>

<h3>Description</h3>

<p>A simulated non-stationary multidimensional time series with five regimes (segments).
This time series is used for illustration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multivtoydataset
</code></pre>


<h3>Format</h3>

<p>A data frame with 670 rows and 4 columns:
</p>

<dl>
<dt>x</dt><dd><p>The covariate variable (the sampling time for time series).</p>
</dd>
<dt>y1</dt><dd><p>The first dimension of the time series. The latter has been
generated as follows:
</p>

<ul>
<li><p>  First regime: 100 values of standard Normally distributed random numbers.
</p>
</li>
<li><p> Second regime: 120 values of Normally distributed random numbers
with mean 7 and unit variance.
</p>
</li>
<li><p> Third regime: 200 values of Normally distributed random numbers
with mean 4 and unit variance.
</p>
</li>
<li><p> Fourth regime: 100 values of Normally distributed random numbers
with mean -1 and unit variance.
</p>
</li>
<li><p> Fifth regime: 150 values of Normally distributed random numbers
with mean 3.5 and unit variance.
</p>
</li></ul>

</dd>
<dt>y2</dt><dd><p>The second dimension of the time series. The latter has been
generated as follows:
</p>

<ul>
<li><p>  First regime: 100 values of Normally distributed random numbers
with mean 1 and unit variance.
</p>
</li>
<li><p> Second regime: 120 values of Normally distributed random numbers
with mean 5 and unit variance.
</p>
</li>
<li><p> Third regime: 200 values of Normally distributed random numbers
with mean 6 and unit variance.
</p>
</li>
<li><p> Fourth regime: 100 values of Normally distributed random numbers
with mean -2 and unit variance.
</p>
</li>
<li><p> Fifth regime: 150 values of Normally distributed random numbers
with mean 2 and unit variance.
</p>
</li></ul>

</dd>
<dt>y3</dt><dd><p>The third dimension of the time series. The latter has been
generated as follows:
</p>

<ul>
<li><p>  First regime: 100 values of Normally distributed random numbers
with mean -2 and unit variance.
</p>
</li>
<li><p> Second regime: 120 values of Normally distributed random numbers
with mean 10 and unit variance.
</p>
</li>
<li><p> Third regime: 200 values of Normally distributed random numbers
with mean 8 and unit variance.
</p>
</li>
<li><p> Fourth regime: 100 values of Normally distributed random numbers and unit variance.
</p>
</li>
<li><p> Fifth regime: 150 values of Normally distributed random numbers
with mean 5 and unit variance.
</p>
</li></ul>

</dd>
</dl>

<hr>
<h2 id='ParamHMMR-class'>A Reference Class which contains parameters of a HMMR model.</h2><span id='topic+ParamHMMR-class'></span><span id='topic+ParamHMMR'></span>

<h3>Description</h3>

<p>ParamHMMR contains all the parameters of a HMMR model. The parameters are
calculated by the initialization Method and then updated by the Method
implementing the M-Step of the EM algorithm.
</p>


<h3>Fields</h3>


<dl>
<dt><code>X</code></dt><dd><p>Numeric vector of length <em>m</em> representing the covariates/inputs
<code class="reqn">x_{1},\dots,x_{m}</code>.</p>
</dd>
<dt><code>Y</code></dt><dd><p>Numeric vector of length <em>m</em> representing the observed
response/output <code class="reqn">y_{1},\dots,y_{m}</code>.</p>
</dd>
<dt><code>m</code></dt><dd><p>Numeric. Length of the response/output vector <code>Y</code>.</p>
</dd>
<dt><code>K</code></dt><dd><p>The number of regimes (HMMR components).</p>
</dd>
<dt><code>p</code></dt><dd><p>The order of the polynomial regression.</p>
</dd>
<dt><code>variance_type</code></dt><dd><p>Character indicating if the model is homoskedastic
(<code>variance_type = "homoskedastic"</code>) or heteroskedastic (<code>variance_type = "heteroskedastic"</code>). By default the model is heteroskedastic.</p>
</dd>
<dt><code>prior</code></dt><dd><p>The prior probabilities of the Markov chain. <code>prior</code> is a row
matrix of dimension <code class="reqn">(1, K)</code>.</p>
</dd>
<dt><code>trans_mat</code></dt><dd><p>The transition matrix of the Markov chain. <code>trans_mat</code> is a
matrix of dimension <code class="reqn">(K, K)</code>.</p>
</dd>
<dt><code>mask</code></dt><dd><p>Mask applied to the transition matrices <code>trans_mat</code>. By default,
a mask of order one is applied.</p>
</dd>
<dt><code>beta</code></dt><dd><p>Parameters of the polynomial regressions. <code class="reqn">\boldsymbol{\beta}
  = (\boldsymbol{\beta}_{1},\dots,\boldsymbol{\beta}_{K})</code> is a matrix of dimension <code class="reqn">(p + 1, K)</code>,
with <code>p</code> the order of the polynomial regression. <code>p</code> is fixed to 3 by
default.</p>
</dd>
<dt><code>sigma2</code></dt><dd><p>The variances for the <code>K</code> regimes. If HMMR model is
heteroskedastic (<code>variance_type = "heteroskedastic"</code>) then <code>sigma2</code> is a
matrix of size <code class="reqn">(K, 1)</code> (otherwise HMMR model is homoskedastic
(<code>variance_type = "homoskedastic"</code>) and <code>sigma2</code> is a matrix of size
<code class="reqn">(1, 1)</code>).</p>
</dd>
<dt><code>nu</code></dt><dd><p>The degree of freedom of the HMMR model representing the complexity
of the model.</p>
</dd>
<dt><code>phi</code></dt><dd><p>A list giving the regression design matrices for the polynomial
and the logistic regressions.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>initParam(try_algo = 1)</code></dt><dd><p>Method to initialize parameters <code>mask</code>, <code>prior</code>,
<code>trans_mat</code>, <code>beta</code> and <code>sigma2</code>.
</p>
<p>If <code>try_algo = 1</code> then <code>beta</code> and <code>sigma2</code> are
initialized by segmenting  the time series <code>Y</code> uniformly into
<code>K</code> contiguous segments. Otherwise, <code>beta</code> and
<code>sigma2</code> are initialized by segmenting randomly the time series
<code>Y</code> into <code>K</code> segments.</p>
</dd>
<dt><code>MStep(statHMMR)</code></dt><dd><p>Method which implements the M-step of the EM algorithm to learn the
parameters of the HMMR model based on statistics provided by the object
<code>statHMMR</code> of class <a href="#topic+StatHMMR">StatHMMR</a> (which contains the E-step).</p>
</dd>
</dl>

<hr>
<h2 id='ParamMHMMR-class'>A Reference Class which contains parameters of a MHMMR model.</h2><span id='topic+ParamMHMMR-class'></span><span id='topic+ParamMHMMR'></span>

<h3>Description</h3>

<p>ParamMHMMR contains all the parameters of a MHMMR model. The parameters are
calculated by the initialization Method and then updated by the Method
implementing the M-Step of the EM algorithm.
</p>


<h3>Fields</h3>


<dl>
<dt><code>mData</code></dt><dd><p><a href="#topic+MData">MData</a> object representing the sample (covariates/inputs
<code>X</code> and observed multivariate responses/outputs <code>Y</code>).</p>
</dd>
<dt><code>K</code></dt><dd><p>The number of regimes (MHMMR components).</p>
</dd>
<dt><code>p</code></dt><dd><p>The order of the polynomial regression.</p>
</dd>
<dt><code>variance_type</code></dt><dd><p>Character indicating if the model is homoskedastic
(<code>variance_type = "homoskedastic"</code>) or heteroskedastic (<code>variance_type = "heteroskedastic"</code>). By default the model is heteroskedastic.</p>
</dd>
<dt><code>prior</code></dt><dd><p>The prior probabilities of the Markov chain. <code>prior</code> is a row
matrix of dimension <code class="reqn">(1, K)</code>.</p>
</dd>
<dt><code>trans_mat</code></dt><dd><p>The transition matrix of the Markov chain. <code>trans_mat</code> is a
matrix of dimension <code class="reqn">(K, K)</code>.</p>
</dd>
<dt><code>mask</code></dt><dd><p>Mask applied to the transition matrices <code>trans_mat</code>. By default,
a mask of order one is applied.</p>
</dd>
<dt><code>beta</code></dt><dd><p>Parameters of the polynomial regressions. <code class="reqn">\boldsymbol{\beta}
  = (\boldsymbol{\beta}_{1},\dots,\boldsymbol{\beta}_{K})</code> is an array of dimension <code class="reqn">(p + 1, d, K)</code>,
with <code>p</code> the order of the polynomial regression. <code>p</code> is fixed to 3 by
default.</p>
</dd>
<dt><code>sigma2</code></dt><dd><p>The variances for the <code>K</code> regimes. If MRHLP model is
heteroskedastic (<code>variance_type = "heteroskedastic"</code>) then <code>sigma2</code> is an
array of size <code class="reqn">(d, d, K)</code> (otherwise MRHLP model is homoskedastic
(<code>variance_type = "homoskedastic"</code>) and <code>sigma2</code> is a matrix of size
<code class="reqn">(d, d)</code>).</p>
</dd>
<dt><code>nu</code></dt><dd><p>The degree of freedom of the MHMMR model representing the
complexity of the model.</p>
</dd>
<dt><code>phi</code></dt><dd><p>A list giving the regression design matrices for the polynomial
and the logistic regressions.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>initParam(try_algo = 1)</code></dt><dd><p>Method to initialize parameters <code>prior</code>, <code>trans_mat</code>,
<code>beta</code> and <code>sigma2</code>.
</p>
<p>If <code>try_algo = 1</code> then <code>beta</code> and <code>sigma2</code> are
initialized by segmenting  the time series <code>Y</code> uniformly into
<code>K</code> contiguous segments. Otherwise, <code>beta</code> and
<code>sigma2</code> are initialized by segmenting randomly the time series
<code>Y</code> into <code>K</code> segments.</p>
</dd>
<dt><code>MStep(statMHMMR)</code></dt><dd><p>Method which implements the M-step of the EM algorithm to learn the
parameters of the MHMMR model based on statistics provided by the object
<code>statMHMMR</code> of class <a href="#topic+StatMHMMR">StatMHMMR</a> (which contains the
E-step).</p>
</dd>
</dl>

<hr>
<h2 id='ParamMRHLP-class'>A Reference Class which contains the parameters of a MRHLP model.</h2><span id='topic+ParamMRHLP-class'></span><span id='topic+ParamMRHLP'></span>

<h3>Description</h3>

<p>ParamMRHLP contains all the parameters of a MRHLP model. The parameters are
calculated by the initialization Method and then updated by the Method
implementing the M-Step of the EM algorithm.
</p>


<h3>Fields</h3>


<dl>
<dt><code>mData</code></dt><dd><p><a href="#topic+MData">MData</a> object representing the sample (covariates/inputs
<code>X</code> and observed responses/outputs <code>Y</code>).</p>
</dd>
<dt><code>K</code></dt><dd><p>The number of regimes (MRHLP components).</p>
</dd>
<dt><code>p</code></dt><dd><p>The order of the polynomial regression.</p>
</dd>
<dt><code>q</code></dt><dd><p>The dimension of the logistic regression. For the purpose of
segmentation, it must be set to 1.</p>
</dd>
<dt><code>variance_type</code></dt><dd><p>Character indicating if the model is homoskedastic
(<code>variance_type = "homoskedastic"</code>) or heteroskedastic (<code>variance_type = "heteroskedastic"</code>). By default the model is heteroskedastic.</p>
</dd>
<dt><code>W</code></dt><dd><p>Parameters of the logistic process. <code class="reqn">\boldsymbol{W} =
  (\boldsymbol{w}_{1},\dots,\boldsymbol{w}_{K-1})</code>
is a matrix of dimension <code class="reqn">(q + 1, K - 1)</code>, with <code>q</code> the order of the
logistic regression. <code>q</code> is fixed to 1 by default.</p>
</dd>
<dt><code>beta</code></dt><dd><p>Parameters of the polynomial regressions. <code class="reqn">\boldsymbol{\beta}
  = (\boldsymbol{\beta}_{1},\dots,\boldsymbol{\beta}_{K})</code> is an array of dimension <code class="reqn">(p + 1, d, K)</code>,
with <code>p</code> the order of the polynomial regression. <code>p</code> is fixed to 3 by
default.</p>
</dd>
<dt><code>sigma2</code></dt><dd><p>The variances for the <code>K</code> regimes. If MRHLP model is
heteroskedastic (<code>variance_type = "heteroskedastic"</code>) then <code>sigma2</code> is an
array of size <code class="reqn">(d, d, K)</code> (otherwise MRHLP model is homoskedastic
(<code>variance_type = "homoskedastic"</code>) and <code>sigma2</code> is a matrix of size
<code class="reqn">(d, d)</code>).</p>
</dd>
<dt><code>nu</code></dt><dd><p>The degree of freedom of the MRHLP model representing the
complexity of the model.</p>
</dd>
<dt><code>phi</code></dt><dd><p>A list giving the regression design matrices for the polynomial
and the logistic regressions.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>initParam(try_algo = 1)</code></dt><dd><p>Method to initialize parameters <code>W</code>, <code>beta</code> and
<code>sigma2</code>.
</p>
<p>If <code>try_algo = 1</code> then <code>beta</code> and <code>sigma2</code> are
initialized by segmenting  the time series <code>Y</code> uniformly into
<code>K</code> contiguous segments. Otherwise, <code>W</code>, <code>beta</code> and
<code>sigma2</code> are initialized by segmenting randomly the time series
<code>Y</code> into <code>K</code> segments.</p>
</dd>
<dt><code>MStep(statMRHLP, verbose_IRLS)</code></dt><dd><p>Method which implements the M-step of the EM algorithm to learn the
parameters of the MRHLP model based on statistics provided by the object
<code>statMRHLP</code> of class <a href="#topic+StatMRHLP">StatMRHLP</a> (which contains the
E-step).</p>
</dd>
</dl>

<hr>
<h2 id='ParamPWR-class'>A Reference Class which contains the parameters of a PWR model.</h2><span id='topic+ParamPWR-class'></span><span id='topic+ParamPWR'></span>

<h3>Description</h3>

<p>ParamPWR contains all the parameters of a PWR model. The parameters are
calculated by the initialization Method and then updated by the Method
dynamic programming (here dynamic programming)
</p>


<h3>Fields</h3>


<dl>
<dt><code>X</code></dt><dd><p>Numeric vector of length <em>m</em> representing the covariates/inputs
<code class="reqn">x_{1},\dots,x_{m}</code>.</p>
</dd>
<dt><code>Y</code></dt><dd><p>Numeric vector of length <em>m</em> representing the observed
response/output <code class="reqn">y_{1},\dots,y_{m}</code>.</p>
</dd>
<dt><code>m</code></dt><dd><p>Numeric. Length of the response/output vector <code>Y</code>.</p>
</dd>
<dt><code>K</code></dt><dd><p>The number of regimes (PWR components).</p>
</dd>
<dt><code>p</code></dt><dd><p>The order of the polynomial regression. <code>p</code> is fixed to 3 by
default.</p>
</dd>
<dt><code>gamma</code></dt><dd><p>Set of transition points. <code>gamma</code> is a column matrix of size
<code class="reqn">(K + 1, 1)</code>.</p>
</dd>
<dt><code>beta</code></dt><dd><p>Parameters of the polynomial regressions. <code>beta</code> is a matrix of
dimension <code class="reqn">(p + 1, K)</code>, with <code>p</code> the order of the polynomial
regression. <code>p</code> is fixed to 3 by default.</p>
</dd>
<dt><code>sigma2</code></dt><dd><p>The variances for the <code>K</code> regimes. <code>sigma2</code> is a matrix of size
<code class="reqn">(K, 1)</code>.</p>
</dd>
<dt><code>phi</code></dt><dd><p>A list giving the regression design matrices for the polynomial
and the logistic regressions.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>computeDynamicProgram(C1, K)</code></dt><dd><p>Method which implements the dynamic programming based on the cost matrix
<code>C1</code> and the number of regimes/segments <code>K</code>.</p>
</dd>
<dt><code>computeParam()</code></dt><dd><p>Method which estimates the parameters <code>beta</code> and <code>sigma2</code>
knowing the transition points <code>gamma</code>.</p>
</dd>
</dl>

<hr>
<h2 id='ParamRHLP-class'>A Reference Class which contains parameters of a RHLP model.</h2><span id='topic+ParamRHLP-class'></span><span id='topic+ParamRHLP'></span>

<h3>Description</h3>

<p>ParamRHLP contains all the parameters of a RHLP model. The parameters are
calculated by the initialization Method and then updated by the Method
implementing the M-Step of the EM algorithm.
</p>


<h3>Fields</h3>


<dl>
<dt><code>X</code></dt><dd><p>Numeric vector of length <em>m</em> representing the covariates/inputs
<code class="reqn">x_{1},\dots,x_{m}</code>.</p>
</dd>
<dt><code>Y</code></dt><dd><p>Numeric vector of length <em>m</em> representing the observed
response/output <code class="reqn">y_{1},\dots,y_{m}</code>.</p>
</dd>
<dt><code>m</code></dt><dd><p>Numeric. Length of the response/output vector <code>Y</code>.</p>
</dd>
<dt><code>K</code></dt><dd><p>The number of regimes (RHLP components).</p>
</dd>
<dt><code>p</code></dt><dd><p>The order of the polynomial regression.</p>
</dd>
<dt><code>q</code></dt><dd><p>The dimension of the logistic regression. For the purpose of
segmentation, it must be set to 1.</p>
</dd>
<dt><code>variance_type</code></dt><dd><p>Character indicating if the model is homoskedastic
(<code>variance_type = "homoskedastic"</code>) or heteroskedastic (<code>variance_type = "heteroskedastic"</code>). By default the model is heteroskedastic.</p>
</dd>
<dt><code>W</code></dt><dd><p>Parameters of the logistic process. <code class="reqn">\boldsymbol{W} =
  (\boldsymbol{w}_{1},\dots,\boldsymbol{w}_{K-1})</code>
is a matrix of dimension <code class="reqn">(q + 1, K - 1)</code>, with <code>q</code> the order of the
logistic regression. <code>q</code> is fixed to 1 by default.</p>
</dd>
<dt><code>beta</code></dt><dd><p>Parameters of the polynomial regressions. <code class="reqn">\boldsymbol{\beta}
  = (\boldsymbol{\beta}_{1},\dots,\boldsymbol{\beta}_{K})</code> is a matrix of dimension <code class="reqn">(p + 1, K)</code>,
with <code>p</code> the order of the polynomial regression. <code>p</code> is fixed to 3 by
default.</p>
</dd>
<dt><code>sigma2</code></dt><dd><p>The variances for the <code>K</code> regimes. If RHLP model is
heteroskedastic (<code>variance_type = "heteroskedastic"</code>) then <code>sigma2</code> is a
matrix of size <code class="reqn">(K, 1)</code> (otherwise RHLP model is homoskedastic
(<code>variance_type = "homoskedastic"</code>) and <code>sigma2</code> is a matrix of size
<code class="reqn">(1, 1)</code>).</p>
</dd>
<dt><code>nu</code></dt><dd><p>The degree of freedom of the RHLP model representing the complexity
of the model.</p>
</dd>
<dt><code>phi</code></dt><dd><p>A list giving the regression design matrices for the polynomial
and the logistic regressions.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>initParam(try_algo = 1)</code></dt><dd><p>Method to initialize parameters <code>W</code>, <code>beta</code> and
<code>sigma2</code>.
</p>
<p>If <code>try_algo = 1</code> then <code>beta</code> and <code>sigma2</code> are
initialized by segmenting  the time series <code>Y</code> uniformly into
<code>K</code> contiguous segments. Otherwise, <code>W</code>, <code>beta</code> and
<code>sigma2</code> are initialized by segmenting randomly the time series
<code>Y</code> into <code>K</code> segments.</p>
</dd>
<dt><code>MStep(statRHLP, verbose_IRLS)</code></dt><dd><p>Method which implements the M-step of the EM algorithm to learn the
parameters of the RHLP model based on statistics provided by the object
<code>statRHLP</code> of class <a href="#topic+StatRHLP">StatRHLP</a> (which contains the E-step).</p>
</dd>
</dl>

<hr>
<h2 id='selectHMMR'>selectHMMR implements a model selection procedure to select an optimal HMMR
model with unknown structure.</h2><span id='topic+selectHMMR'></span>

<h3>Description</h3>

<p>selectHMMR implements a model selection procedure to select an optimal HMMR
model with unknown structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>selectHMMR(X, Y, Kmin = 1, Kmax = 10, pmin = 0, pmax = 4,
  criterion = c("BIC", "AIC"), verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="selectHMMR_+3A_x">X</code></td>
<td>
<p>Numeric vector of length <em>m</em> representing the covariates/inputs
<code class="reqn">x_{1},\dots,x_{m}</code>.</p>
</td></tr>
<tr><td><code id="selectHMMR_+3A_y">Y</code></td>
<td>
<p>Numeric vector of length <em>m</em> representing the observed
response/output <code class="reqn">y_{1},\dots,y_{m}</code>.</p>
</td></tr>
<tr><td><code id="selectHMMR_+3A_kmin">Kmin</code></td>
<td>
<p>The minimum number of regimes (HMMR components).</p>
</td></tr>
<tr><td><code id="selectHMMR_+3A_kmax">Kmax</code></td>
<td>
<p>The maximum number of regimes (HMMR components).</p>
</td></tr>
<tr><td><code id="selectHMMR_+3A_pmin">pmin</code></td>
<td>
<p>The minimum order of the polynomial regression.</p>
</td></tr>
<tr><td><code id="selectHMMR_+3A_pmax">pmax</code></td>
<td>
<p>The maximum order of the polynomial regression.</p>
</td></tr>
<tr><td><code id="selectHMMR_+3A_criterion">criterion</code></td>
<td>
<p>The criterion used to select the HMMR model (&quot;BIC&quot;, &quot;AIC&quot;).</p>
</td></tr>
<tr><td><code id="selectHMMR_+3A_verbose">verbose</code></td>
<td>
<p>Optional. A logical value indicating whether or not a summary
of the selected model should be displayed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>selectHMMR selects the optimal HMMR model among a set of model
candidates by optimizing a model selection criteria, including the Bayesian
Information Criterion (BIC). This function first fits the different HMMR
model candidates by varying the number of regimes <code>K</code> from <code>Kmin</code> to <code>Kmax</code>
and the order of the polynomial regression <code>p</code> from <code>pmin</code> to <code>pmax</code>. The
model having the highest value of the chosen selection criterion is then
selected.
</p>


<h3>Value</h3>

<p>selectHMMR returns an object of class <a href="#topic+ModelHMMR">ModelHMMR</a>
representing the selected HMMR model according to the chosen <code>criterion</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+ModelHMMR">ModelHMMR</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(univtoydataset)

selectedhmmr &lt;- selectHMMR(X = univtoydataset$x, Y = univtoydataset$y,
                           Kmin = 2, Kmax = 6, pmin = 0, pmax = 2)

selectedhmmr$plot()
</code></pre>

<hr>
<h2 id='selectMHMMR'>selectMHMMR implements a model selection procedure to select an optimal MHMMR
model with unknown structure.</h2><span id='topic+selectMHMMR'></span>

<h3>Description</h3>

<p>selectMHMMR implements a model selection procedure to select an optimal MHMMR
model with unknown structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>selectMHMMR(X, Y, Kmin = 1, Kmax = 10, pmin = 0, pmax = 4,
  criterion = c("BIC", "AIC"), verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="selectMHMMR_+3A_x">X</code></td>
<td>
<p>Numeric vector of length <em>m</em> representing the covariates/inputs
<code class="reqn">x_{1},\dots,x_{m}</code>.</p>
</td></tr>
<tr><td><code id="selectMHMMR_+3A_y">Y</code></td>
<td>
<p>Matrix of size <code class="reqn">(m, d)</code> representing a <code class="reqn">d</code> dimension time
series observed at points <code class="reqn">1,\dots,m</code>.</p>
</td></tr>
<tr><td><code id="selectMHMMR_+3A_kmin">Kmin</code></td>
<td>
<p>The minimum number of regimes (c components).</p>
</td></tr>
<tr><td><code id="selectMHMMR_+3A_kmax">Kmax</code></td>
<td>
<p>The maximum number of regimes (MHMMR components).</p>
</td></tr>
<tr><td><code id="selectMHMMR_+3A_pmin">pmin</code></td>
<td>
<p>The minimum order of the polynomial regression.</p>
</td></tr>
<tr><td><code id="selectMHMMR_+3A_pmax">pmax</code></td>
<td>
<p>The maximum order of the polynomial regression.</p>
</td></tr>
<tr><td><code id="selectMHMMR_+3A_criterion">criterion</code></td>
<td>
<p>The criterion used to select the MHMMR model (&quot;BIC&quot;, &quot;AIC&quot;).</p>
</td></tr>
<tr><td><code id="selectMHMMR_+3A_verbose">verbose</code></td>
<td>
<p>Optional. A logical value indicating whether or not a summary
of the selected model should be displayed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>selectMHMMR selects the optimal MHMMR model among a set of model
candidates by optimizing a model selection criteria, including the Bayesian
Information Criterion (BIC). This function first fits the different MHMMR
model candidates by varying the number of regimes <code>K</code> from <code>Kmin</code> to <code>Kmax</code>
and the order of the polynomial regression <code>p</code> from <code>pmin</code> to <code>pmax</code>. The
model having the highest value of the chosen selection criterion is then
selected.
</p>


<h3>Value</h3>

<p>selectMHMMR returns an object of class <a href="#topic+ModelMHMMR">ModelMHMMR</a>
representing the selected MHMMR model according to the chosen <code>criterion</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+ModelMHMMR">ModelMHMMR</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(multivtoydataset)
x &lt;- multivtoydataset$x
y &lt;- multivtoydataset[, c("y1", "y2", "y3")]

selectedmhmmr &lt;- selectMHMMR(X = x, Y = y, Kmin = 2, Kmax = 6,
                             pmin = 0, pmax = 2)

selectedmhmmr$summary()
</code></pre>

<hr>
<h2 id='selectMRHLP'>selecMRHLP implements a model selection procedure to select an optimal MRHLP
model with unknown structure.</h2><span id='topic+selectMRHLP'></span>

<h3>Description</h3>

<p>selecMRHLP implements a model selection procedure to select an optimal MRHLP
model with unknown structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>selectMRHLP(X, Y, Kmin = 1, Kmax = 10, pmin = 0, pmax = 4,
  criterion = c("BIC", "AIC"), verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="selectMRHLP_+3A_x">X</code></td>
<td>
<p>Numeric vector of length <em>m</em> representing the covariates/inputs
<code class="reqn">x_{1},\dots,x_{m}</code>.</p>
</td></tr>
<tr><td><code id="selectMRHLP_+3A_y">Y</code></td>
<td>
<p>Matrix of size <code class="reqn">(m, d)</code> representing a <code class="reqn">d</code> dimension
function of <code>X</code> observed at points <code class="reqn">1,\dots,m</code>. <code>Y</code> is the observed
response/output.</p>
</td></tr>
<tr><td><code id="selectMRHLP_+3A_kmin">Kmin</code></td>
<td>
<p>The minimum number of regimes (MRHLP components).</p>
</td></tr>
<tr><td><code id="selectMRHLP_+3A_kmax">Kmax</code></td>
<td>
<p>The maximum number of regimes (MRHLP components).</p>
</td></tr>
<tr><td><code id="selectMRHLP_+3A_pmin">pmin</code></td>
<td>
<p>The minimum order of the polynomial regression.</p>
</td></tr>
<tr><td><code id="selectMRHLP_+3A_pmax">pmax</code></td>
<td>
<p>The maximum order of the polynomial regression.</p>
</td></tr>
<tr><td><code id="selectMRHLP_+3A_criterion">criterion</code></td>
<td>
<p>The criterion used to select the MRHLP model (&quot;BIC&quot;, &quot;AIC&quot;).</p>
</td></tr>
<tr><td><code id="selectMRHLP_+3A_verbose">verbose</code></td>
<td>
<p>Optional. A logical value indicating whether or not a summary
of the selected model should be displayed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>selectMRHLP selects the optimal MRHLP model among a set of model
candidates by optimizing a model selection criteria, including the Bayesian
Information Criterion (BIC). This function first fits the different MRHLP
model candidates by varying the number of regimes <code>K</code> from <code>Kmin</code> to <code>Kmax</code>
and the order of the polynomial regression <code>p</code> from <code>pmin</code> to <code>pmax</code>. The
model having the highest value of the chosen selection criterion is then
selected.
</p>


<h3>Value</h3>

<p>selectMRHLP returns an object of class <a href="#topic+ModelMRHLP">ModelMRHLP</a>
representing the selected MRHLP model according to the chosen <code>criterion</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+ModelMRHLP">ModelMRHLP</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(multivtoydataset)

# Let's select a MRHLP model on a multivariate time series with 3 regimes:
data &lt;- multivtoydataset[1:320, ]
x &lt;- data$x
y &lt;- data[, c("y1", "y2", "y3")]

selectedmrhlp &lt;- selectMRHLP(X = x, Y = y, Kmin = 2, Kmax = 4,
                             pmin = 0, pmax = 1)

selectedmrhlp$summary()
</code></pre>

<hr>
<h2 id='selectRHLP'>selecRHLP implements a model selection procedure to select an optimal RHLP
model with unknown structure.</h2><span id='topic+selectRHLP'></span>

<h3>Description</h3>

<p>selecRHLP implements a model selection procedure to select an optimal RHLP
model with unknown structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>selectRHLP(X, Y, Kmin = 1, Kmax = 10, pmin = 0, pmax = 4,
  criterion = c("BIC", "AIC"), verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="selectRHLP_+3A_x">X</code></td>
<td>
<p>Numeric vector of length <em>m</em> representing the covariates/inputs
<code class="reqn">x_{1},\dots,x_{m}</code>.</p>
</td></tr>
<tr><td><code id="selectRHLP_+3A_y">Y</code></td>
<td>
<p>Numeric vector of length <em>m</em> representing the observed
response/output <code class="reqn">y_{1},\dots,y_{m}</code>.</p>
</td></tr>
<tr><td><code id="selectRHLP_+3A_kmin">Kmin</code></td>
<td>
<p>The minimum number of regimes (RHLP components).</p>
</td></tr>
<tr><td><code id="selectRHLP_+3A_kmax">Kmax</code></td>
<td>
<p>The maximum number of regimes (RHLP components).</p>
</td></tr>
<tr><td><code id="selectRHLP_+3A_pmin">pmin</code></td>
<td>
<p>The minimum order of the polynomial regression.</p>
</td></tr>
<tr><td><code id="selectRHLP_+3A_pmax">pmax</code></td>
<td>
<p>The maximum order of the polynomial regression.</p>
</td></tr>
<tr><td><code id="selectRHLP_+3A_criterion">criterion</code></td>
<td>
<p>The criterion used to select the RHLP model (&quot;BIC&quot;, &quot;AIC&quot;).</p>
</td></tr>
<tr><td><code id="selectRHLP_+3A_verbose">verbose</code></td>
<td>
<p>Optional. A logical value indicating whether or not a summary
of the selected model should be displayed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>selectRHLP selects the optimal MRHLP model among a set of model
candidates by optimizing a model selection criteria, including the Bayesian
Information Criterion (BIC). This function first fits the different RHLP
model candidates by varying the number of regimes <code>K</code> from <code>Kmin</code> to <code>Kmax</code>
and the order of the polynomial regression <code>p</code> from <code>pmin</code> to <code>pmax</code>. The
model having the highest value of the chosen selection criterion is then
selected.
</p>


<h3>Value</h3>

<p>selectRHLP returns an object of class <a href="#topic+ModelRHLP">ModelRHLP</a>
representing the selected RHLP model according to the chosen <code>criterion</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+ModelRHLP">ModelRHLP</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(univtoydataset)

# Let's select a RHLP model on a time series with 3 regimes:
data &lt;- univtoydataset[1:320,]

selectedrhlp &lt;- selectRHLP(X = data$x, Y = data$y,
                           Kmin = 2, Kmax = 4, pmin = 0, pmax = 1)

selectedrhlp$summary()
</code></pre>

<hr>
<h2 id='StatHMMR-class'>A Reference Class which contains statistics of a HMMR model.</h2><span id='topic+StatHMMR-class'></span><span id='topic+StatHMMR'></span>

<h3>Description</h3>

<p>StatHMMR contains all the statistics associated to a <a href="#topic+ParamHMMR">HMMR</a> model.
It mainly includes the E-Step of the EM algorithm calculating the posterior
distribution of the hidden variables (ie the smoothing probabilities), as
well as the calculation of the prediction and filtering probabilities, the
log-likelhood at each step of the algorithm and the obtained values of model
selection criteria..
</p>


<h3>Fields</h3>


<dl>
<dt><code>tau_tk</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> giving the posterior probability
that the observation <code class="reqn">Y_{i}</code> originates from the <code class="reqn">k</code>-th regression
model.</p>
</dd>
<dt><code>alpha_tk</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> giving the forwards
probabilities: <code class="reqn">P(Y_{1},\dots,Y_{t}, z_{t} = k)</code>.</p>
</dd>
<dt><code>beta_tk</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code>, giving the backwards
probabilities: <code class="reqn">P(Y_{t+1},\dots,Y_{m} | z_{t} =
  k)</code>.</p>
</dd>
<dt><code>xi_tkl</code></dt><dd><p>Array of size <code class="reqn">(m - 1, K, K)</code> giving the joint post
probabilities: <code class="reqn">xi_tk[t, k, l] = P(z_{t} = k, z_{t-1} = l |
  \boldsymbol{Y})</code> for <code class="reqn">t
  = 2,\dots,m</code>.</p>
</dd>
<dt><code>f_tk</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> giving the cumulative distribution
function <code class="reqn">f(y_{t} | z{_t} = k)</code>.</p>
</dd>
<dt><code>log_f_tk</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> giving the logarithm of the
cumulative distribution <code>f_tk</code>.</p>
</dd>
<dt><code>loglik</code></dt><dd><p>Numeric. Log-likelihood of the HMMR model.</p>
</dd>
<dt><code>stored_loglik</code></dt><dd><p>Numeric vector. Stored values of the log-likelihood at
each iteration of the EM algorithm.</p>
</dd>
<dt><code>klas</code></dt><dd><p>Column matrix of the labels issued from <code>z_ik</code>. Its elements are
<code class="reqn">klas(i) = k</code>, <code class="reqn">k = 1,\dots,K</code>.</p>
</dd>
<dt><code>z_ik</code></dt><dd><p>Hard segmentation logical matrix of dimension <code class="reqn">(m, K)</code>
obtained by the Maximum a posteriori (MAP) rule: <code class="reqn">z\_ik = 1 \
  \textrm{if} \ z\_ik = \textrm{arg} \ \textrm{max}_{s} \ P(z_{i} = s |
  \boldsymbol{Y})  = tau\_tk;\ 0 \ \textrm{otherwise}</code>, <code class="reqn">k = 1,\dots,K</code>.</p>
</dd>
<dt><code>state_probs</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> giving the distribution of the
Markov chain.
<code class="reqn">P(z_{1},\dots,z_{m};\pi,\boldsymbol{A})</code>
with <code class="reqn">\pi</code> the prior probabilities (field <code>prior</code> of the class
<a href="#topic+ParamHMMR">ParamHMMR</a>) and <code class="reqn">\boldsymbol{A}</code> the transition matrix
(field <code>trans_mat</code> of the class <a href="#topic+ParamHMMR">ParamHMMR</a>) of the Markov
chain.</p>
</dd>
<dt><code>BIC</code></dt><dd><p>Numeric. Value of BIC (Bayesian Information Criterion).</p>
</dd>
<dt><code>AIC</code></dt><dd><p>Numeric. Value of AIC (Akaike Information Criterion).</p>
</dd>
<dt><code>regressors</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> giving the values of the
estimated polynomial regression components.</p>
</dd>
<dt><code>predict_prob</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> giving the prediction
probabilities: <code class="reqn">P(z_{t} = k | y_{1},\dots,y_{t-1})</code>.</p>
</dd>
<dt><code>predicted</code></dt><dd><p>Row matrix of size <code class="reqn">(m, 1)</code> giving the sum of the
polynomial components weighted by the prediction probabilities
<code>predict_prob</code>.</p>
</dd>
<dt><code>filter_prob</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> giving the filtering
probabilities <code class="reqn">Pr(z_{t} = k | y_{1},\dots,y_{t})</code>.</p>
</dd>
<dt><code>filtered</code></dt><dd><p>Row matrix of size <code class="reqn">(m, 1)</code> giving the sum of the
polynomial components weighted by the filtering probabilities.</p>
</dd>
<dt><code>smoothed_regressors</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> giving the polynomial
components weighted by the posterior probability <code>tau_tk</code>.</p>
</dd>
<dt><code>smoothed</code></dt><dd><p>Row matrix of size <code class="reqn">(m, 1)</code> giving the sum of the
polynomial components weighted by the posterior probability <code>tau_tk</code>.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>computeLikelihood(paramHMMR)</code></dt><dd><p>Method to compute the log-likelihood based on some parameters given by
the object <code>paramHMMR</code> of class <a href="#topic+ParamHMMR">ParamHMMR</a>.</p>
</dd>
<dt><code>computeStats(paramHMMR)</code></dt><dd><p>Method used in the EM algorithm to compute statistics based on
parameters provided by the object <code>paramHMMR</code> of class
<a href="#topic+ParamHMMR">ParamHMMR</a>.</p>
</dd>
<dt><code>EStep(paramHMMR)</code></dt><dd><p>Method used in the EM algorithm to update statistics based on parameters
provided by the object <code>paramHMMR</code> of class <a href="#topic+ParamHMMR">ParamHMMR</a>
(prior and posterior probabilities).</p>
</dd>
<dt><code>MAP()</code></dt><dd><p>MAP calculates values of the fields <code>z_ik</code> and <code>klas</code>
by applying the Maximum A Posteriori Bayes allocation rule.
</p>
<p><code class="reqn">z\_ik = 1 \ \textrm{if} \ z\_ik = \textrm{arg} \
      \textrm{max}_{s} \ P(z_{i} = s | \boldsymbol{Y})  = tau\_tk;\ 0 \
      \textrm{otherwise}</code></p>
</dd>
</dl>


<h3>See Also</h3>

<p><a href="#topic+ParamHMMR">ParamHMMR</a>
</p>

<hr>
<h2 id='StatMHMMR-class'>A Reference Class which contains statistics of a MHMMR model.</h2><span id='topic+StatMHMMR-class'></span><span id='topic+StatMHMMR'></span>

<h3>Description</h3>

<p>StatMHMMR contains all the statistics associated to a <a href="#topic+ParamMHMMR">MHMMR</a>
model. It mainly includes the E-Step of the EM algorithm calculating the
posterior distribution of the hidden variables (ie the smoothing
probabilities), as well as the calculation of the prediction and filtering
probabilities, the log-likelhood at each step of the algorithm and the
obtained values of model selection criteria..
</p>


<h3>Fields</h3>


<dl>
<dt><code>tau_tk</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> giving the posterior probability
that the observation <code class="reqn">Y_{i}</code> originates from the <code class="reqn">k</code>-th regression
model.</p>
</dd>
<dt><code>alpha_tk</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> giving the forwards
probabilities: <code class="reqn">P(Y_{1},\dots,Y_{t}, z_{t} = k)</code>.</p>
</dd>
<dt><code>beta_tk</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code>, giving the backwards
probabilities: <code class="reqn">P(Y_{t+1},\dots,Y_{m} | z_{t} =
  k)</code>.</p>
</dd>
<dt><code>xi_tkl</code></dt><dd><p>Array of size <code class="reqn">(m - 1, K, K)</code> giving the joint post
probabilities: <code class="reqn">xi_tk[t, k, l] = P(z_{t} = k, z_{t-1} = l |
  \boldsymbol{Y})</code> for <code class="reqn">t
  = 2,\dots,m</code>.</p>
</dd>
<dt><code>f_tk</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> giving the cumulative distribution
function <code class="reqn">f(y_{t} | z{_t} = k)</code>.</p>
</dd>
<dt><code>log_f_tk</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> giving the logarithm of the
cumulative distribution <code>f_tk</code>.</p>
</dd>
<dt><code>loglik</code></dt><dd><p>Numeric. Log-likelihood of the MHMMR model.</p>
</dd>
<dt><code>stored_loglik</code></dt><dd><p>Numeric vector. Stored values of the log-likelihood at
each iteration of the EM algorithm.</p>
</dd>
<dt><code>klas</code></dt><dd><p>Column matrix of the labels issued from <code>z_ik</code>. Its elements are
<code class="reqn">klas(i) = k</code>, <code class="reqn">k = 1,\dots,K</code>.</p>
</dd>
<dt><code>z_ik</code></dt><dd><p>Hard segmentation logical matrix of dimension <code class="reqn">(m, K)</code>
obtained by the Maximum a posteriori (MAP) rule: <code class="reqn">z\_ik = 1 \
  \textrm{if} \ z\_ik = \textrm{arg} \ \textrm{max}_{s} \ P(z_{i} = s |
  \boldsymbol{Y})  = tau\_tk;\ 0 \ \textrm{otherwise}</code>, <code class="reqn">k = 1,\dots,K</code>.</p>
</dd>
<dt><code>state_probs</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> giving the distribution of the
Markov chain.
<code class="reqn">P(z_{1},\dots,z_{m};\pi,\boldsymbol{A})</code>
with <code class="reqn">\pi</code> the prior probabilities (field <code>prior</code> of the class
<a href="#topic+ParamMHMMR">ParamMHMMR</a>) and <code class="reqn">\boldsymbol{A}</code> the transition matrix
(field <code>trans_mat</code> of the class <a href="#topic+ParamMHMMR">ParamMHMMR</a>) of the Markov
chain.</p>
</dd>
<dt><code>BIC</code></dt><dd><p>Numeric. Value of BIC (Bayesian Information Criterion).</p>
</dd>
<dt><code>AIC</code></dt><dd><p>Numeric. Value of AIC (Akaike Information Criterion).</p>
</dd>
<dt><code>regressors</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> giving the values of the
estimated polynomial regression components.</p>
</dd>
<dt><code>predict_prob</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> giving the prediction
probabilities: <code class="reqn">P(z_{t} = k | y_{1},\dots,y_{t-1})</code>.</p>
</dd>
<dt><code>predicted</code></dt><dd><p>Row matrix of size <code class="reqn">(m, 1)</code> giving the sum of the
polynomial components weighted by the prediction probabilities
<code>predict_prob</code>.</p>
</dd>
<dt><code>filter_prob</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> giving the filtering
probabilities <code class="reqn">Pr(z_{t} = k | y_{1},\dots,y_{t})</code>.</p>
</dd>
<dt><code>filtered</code></dt><dd><p>Row matrix of size <code class="reqn">(m, 1)</code> giving the sum of the
polynomial components weighted by the filtering probabilities.</p>
</dd>
<dt><code>smoothed_regressors</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> giving the polynomial
components weighted by the posterior probability <code>tau_tk</code>.</p>
</dd>
<dt><code>smoothed</code></dt><dd><p>Row matrix of size <code class="reqn">(m, 1)</code> giving the sum of the
polynomial components weighted by the posterior probability <code>tau_tk</code>.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>computeLikelihood(paramMHMMR)</code></dt><dd><p>Method to compute the log-likelihood based on some parameters given by
the object <code>paramMHMMR</code> of class <a href="#topic+ParamMHMMR">ParamMHMMR</a>.</p>
</dd>
<dt><code>computeStats(paramMHMMR)</code></dt><dd><p>Method used in the EM algorithm to compute statistics based on
parameters provided by the object <code>paramMHMMR</code> of class
<a href="#topic+ParamMHMMR">ParamMHMMR</a>.</p>
</dd>
<dt><code>EStep(paramMHMMR)</code></dt><dd><p>Method used in the EM algorithm to update statistics based on parameters
provided by the object <code>paramMHMMR</code> of class <a href="#topic+ParamMHMMR">ParamMHMMR</a>
(prior and posterior probabilities).</p>
</dd>
<dt><code>MAP()</code></dt><dd><p>MAP calculates values of the fields <code>z_ik</code> and <code>klas</code>
by applying the Maximum A Posteriori Bayes allocation rule.
</p>
<p><code class="reqn">z\_ik = 1 \ \textrm{if} \ z\_ik = \textrm{arg} \
      \textrm{max}_{s} \ P(z_{i} = s | \boldsymbol{Y})  = tau\_tk;\ 0 \
      \textrm{otherwise}</code></p>
</dd>
</dl>


<h3>See Also</h3>

<p><a href="#topic+ParamMHMMR">ParamMHMMR</a>
</p>

<hr>
<h2 id='StatMRHLP-class'>A Reference Class which contains statistics of a MRHLP model.</h2><span id='topic+StatMRHLP-class'></span><span id='topic+StatMRHLP'></span>

<h3>Description</h3>

<p>StatMRHLP contains all the statistics associated to a <a href="#topic+ParamMRHLP">MRHLP</a>
model. It mainly includes the E-Step of the EM algorithm calculating the
posterior distribution of the hidden variables, as well as the calculation of
the log-likelhood at each step of the algorithm and the obtained values of
model selection criteria..
</p>


<h3>Fields</h3>


<dl>
<dt><code>pi_ik</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> representing the prior/logistic
probabilities <code class="reqn">\pi_{k}(x_{i}; \boldsymbol{\Psi}) = P(z_{i} = k |
  \boldsymbol{x}; \Psi)</code> of
the latent variable <code class="reqn">z_{i}, i = 1,\dots,m</code>.</p>
</dd>
<dt><code>z_ik</code></dt><dd><p>Hard segmentation logical matrix of dimension <code class="reqn">(m, K)</code>
obtained by the Maximum a posteriori (MAP) rule: <code class="reqn">z\_ik = 1 \
  \textrm{if} \ z\_ik = \textrm{arg} \ \textrm{max}_{s} \ \pi_{s}(x_{i};
  \boldsymbol{\Psi});\ 0 \ \textrm{otherwise}</code>, <code class="reqn">k = 1,\dots,K</code>.</p>
</dd>
<dt><code>klas</code></dt><dd><p>Column matrix of the labels issued from <code>z_ik</code>. Its elements are
<code class="reqn">klas(i) = k</code>, <code class="reqn">k = 1,\dots,K</code>.</p>
</dd>
<dt><code>tau_ik</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> giving the posterior probability
that the observation <code class="reqn">Y_{i}</code> originates from the <code class="reqn">k</code>-th regression
model.</p>
</dd>
<dt><code>polynomials</code></dt><dd><p>Array of size <code class="reqn">(m, d, K)</code> giving the values of the
estimated polynomial regression components.</p>
</dd>
<dt><code>weighted_polynomials</code></dt><dd><p>Array of size <code class="reqn">(m, d, K)</code> giving the values
of the estimated polynomial regression components weighted by the prior
probabilities <code>pi_ik</code>.</p>
</dd>
<dt><code>Ex</code></dt><dd><p>Matrix of size <em>(m, d)</em>. <code>Ex</code> is the curve expectation
(estimated signal): sum of the polynomial components weighted by the
logistic probabilities <code>pi_ik</code>.</p>
</dd>
<dt><code>loglik</code></dt><dd><p>Numeric. Observed-data log-likelihood of the MRHLP model.</p>
</dd>
<dt><code>com_loglik</code></dt><dd><p>Numeric. Complete-data log-likelihood of the MRHLP model.</p>
</dd>
<dt><code>stored_loglik</code></dt><dd><p>Numeric vector. Stored values of the log-likelihood at
each EM iteration.</p>
</dd>
<dt><code>stored_com_loglik</code></dt><dd><p>Numeric vector. Stored values of the Complete
log-likelihood at each EM iteration.</p>
</dd>
<dt><code>BIC</code></dt><dd><p>Numeric. Value of BIC (Bayesian Information Criterion).</p>
</dd>
<dt><code>ICL</code></dt><dd><p>Numeric. Value of ICL (Integrated Completed Likelihood).</p>
</dd>
<dt><code>AIC</code></dt><dd><p>Numeric. Value of AIC (Akaike Information Criterion).</p>
</dd>
<dt><code>log_piik_fik</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> giving the values of the
logarithm of the joint probability <code class="reqn">P(y_{i}, \ z_{i} = k |
  \boldsymbol{x}, \boldsymbol{\Psi})</code>, <code class="reqn">i
  = 1,\dots,m</code>.</p>
</dd>
<dt><code>log_sum_piik_fik</code></dt><dd><p>Column matrix of size <em>m</em> giving the values of
<code class="reqn">\textrm{log} \sum_{k = 1}^{K} P(y_{i}, \ z_{i} = k | \boldsymbol{x},
  \boldsymbol{\Psi})</code>,
<code class="reqn">i = 1,\dots,m</code>.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>computeLikelihood(reg_irls)</code></dt><dd><p>Method to compute the log-likelihood. <code>reg_irls</code> is the value of
the regularization part in the IRLS algorithm.</p>
</dd>
<dt><code>computeStats(paramMRHLP)</code></dt><dd><p>Method used in the EM algorithm to compute statistics based on
parameters provided by the object <code>paramMRHLP</code> of class
<a href="#topic+ParamMRHLP">ParamMRHLP</a>.</p>
</dd>
<dt><code>EStep(paramMRHLP)</code></dt><dd><p>Method used in the EM algorithm to update statistics based on parameters
provided by the object <code>paramMRHLP</code> of class <a href="#topic+ParamMRHLP">ParamMRHLP</a>
(prior and posterior probabilities).</p>
</dd>
<dt><code>MAP()</code></dt><dd><p>MAP calculates values of the fields <code>z_ik</code> and <code>klas</code>
by applying the Maximum A Posteriori Bayes allocation rule.
</p>
<p><code class="reqn">z_{ik} = 1 \ \textrm{if} \ k = \textrm{arg} \ \textrm{max}_{s}
      \ \pi_{s}(x_{i}; \boldsymbol{\Psi});\ 0 \ \textrm{otherwise}</code></p>
</dd>
</dl>


<h3>See Also</h3>

<p><a href="#topic+ParamMRHLP">ParamMRHLP</a>
</p>

<hr>
<h2 id='StatPWR-class'>A Reference Class which contains statistics of a PWR model.</h2><span id='topic+StatPWR-class'></span><span id='topic+StatPWR'></span>

<h3>Description</h3>

<p>StatPWR contains all the statistics associated to a <a href="#topic+ParamPWR">PWR</a> model.
</p>


<h3>Fields</h3>


<dl>
<dt><code>z_ik</code></dt><dd><p>Logical matrix of dimension <code class="reqn">(m, K)</code> giving the class vector.</p>
</dd>
<dt><code>klas</code></dt><dd><p>Column matrix of the labels issued from <code>z_ik</code>. Its elements are
<code class="reqn">klas(i) = k</code>, <code class="reqn">k = 1,\dots,K</code>.</p>
</dd>
<dt><code>mean_function</code></dt><dd><p>Approximation of the time series given the estimated
parameters. <code>mean_function</code> is a matrix of size <code class="reqn">(m, 1)</code>.</p>
</dd>
<dt><code>regressors</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> giving the values of the
estimated polynomial regression components.</p>
</dd>
<dt><code>objective</code></dt><dd><p>Numeric. Value of the objective function.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>computeStats(paramPWR)</code></dt><dd><p>Method used at the end of the dynamic programming algorithm to compute
statistics based on parameters provided by <code>paramPWR</code>.</p>
</dd>
</dl>


<h3>See Also</h3>

<p><a href="#topic+ParamPWR">ParamPWR</a>
</p>

<hr>
<h2 id='StatRHLP-class'>A Reference Class which contains statistics of a RHLP model.</h2><span id='topic+StatRHLP-class'></span><span id='topic+StatRHLP'></span>

<h3>Description</h3>

<p>StatRHLP contains all the statistics associated to a <a href="#topic+ParamRHLP">RHLP</a> model.
It mainly includes the E-Step of the EM algorithm calculating the posterior
distribution of the hidden variables, as well as the calculation of the
log-likelhood at each step of the algorithm and the obtained values of model
selection criteria..
</p>


<h3>Fields</h3>


<dl>
<dt><code>pi_ik</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> representing the prior/logistic
probabilities <code class="reqn">\pi_{k}(x_{i}; \boldsymbol{\Psi}) = P(z_{i} = k |
  \boldsymbol{x}; \Psi)</code> of
the latent variable <code class="reqn">z_{i}, i = 1,\dots,m</code>.</p>
</dd>
<dt><code>z_ik</code></dt><dd><p>Hard segmentation logical matrix of dimension <code class="reqn">(m, K)</code>
obtained by the Maximum a posteriori (MAP) rule: <code class="reqn">z\_ik = 1 \
  \textrm{if} \ z\_ik = \textrm{arg} \ \textrm{max}_{s} \ \pi_{s}(x_{i};
  \boldsymbol{\Psi});\ 0 \ \textrm{otherwise}</code>, <code class="reqn">k = 1,\dots,K</code>.</p>
</dd>
<dt><code>klas</code></dt><dd><p>Column matrix of the labels issued from <code>z_ik</code>. Its elements are
<code class="reqn">klas(i) = k</code>, <code class="reqn">k = 1,\dots,K</code>.</p>
</dd>
<dt><code>tau_ik</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> giving the posterior probability
that the observation <code class="reqn">Y_{i}</code> originates from the <code class="reqn">k</code>-th regression
model.</p>
</dd>
<dt><code>polynomials</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> giving the values of the
estimated polynomial regression components.</p>
</dd>
<dt><code>Ex</code></dt><dd><p>Column matrix of dimension <em>m</em>. <code>Ex</code> is the curve expectation
(estimated signal): sum of the polynomial components weighted by the
logistic probabilities <code>pi_ik</code>.</p>
</dd>
<dt><code>loglik</code></dt><dd><p>Numeric. Observed-data log-likelihood of the RHLP model.</p>
</dd>
<dt><code>com_loglik</code></dt><dd><p>Numeric. Complete-data log-likelihood of the RHLP model.</p>
</dd>
<dt><code>stored_loglik</code></dt><dd><p>Numeric vector. Stored values of the log-likelihood at
each EM iteration.</p>
</dd>
<dt><code>stored_com_loglik</code></dt><dd><p>Numeric vector. Stored values of the Complete
log-likelihood at each EM iteration.</p>
</dd>
<dt><code>BIC</code></dt><dd><p>Numeric. Value of BIC (Bayesian Information Criterion).</p>
</dd>
<dt><code>ICL</code></dt><dd><p>Numeric. Value of ICL (Integrated Completed Likelihood).</p>
</dd>
<dt><code>AIC</code></dt><dd><p>Numeric. Value of AIC (Akaike Information Criterion).</p>
</dd>
<dt><code>log_piik_fik</code></dt><dd><p>Matrix of size <code class="reqn">(m, K)</code> giving the values of the
logarithm of the joint probability <code class="reqn">P(y_{i}, \ z_{i} = k |
  \boldsymbol{x}, \boldsymbol{\Psi})</code>, <code class="reqn">i
  = 1,\dots,m</code>.</p>
</dd>
<dt><code>log_sum_piik_fik</code></dt><dd><p>Column matrix of size <em>m</em> giving the values of
<code class="reqn">\textrm{log} \sum_{k = 1}^{K} P(y_{i}, \ z_{i} = k | \boldsymbol{x},
  \boldsymbol{\Psi})</code>,
<code class="reqn">i = 1,\dots,m</code>.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>computeLikelihood(reg_irls)</code></dt><dd><p>Method to compute the log-likelihood. <code>reg_irls</code> is the value of
the regularization part in the IRLS algorithm.</p>
</dd>
<dt><code>computeStats(paramRHLP)</code></dt><dd><p>Method used in the EM algorithm to compute statistics based on
parameters provided by the object <code>paramRHLP</code> of class
<a href="#topic+ParamRHLP">ParamRHLP</a>.</p>
</dd>
<dt><code>EStep(paramRHLP)</code></dt><dd><p>Method used in the EM algorithm to update statistics based on parameters
provided by the object <code>paramRHLP</code> of class <a href="#topic+ParamRHLP">ParamRHLP</a>
(prior and posterior probabilities).</p>
</dd>
<dt><code>MAP()</code></dt><dd><p>MAP calculates values of the fields <code>z_ik</code> and <code>klas</code>
by applying the Maximum A Posteriori Bayes allocation rule.
</p>
<p><code class="reqn">z_{ik} = 1 \ \textrm{if} \ k = \textrm{arg} \ \textrm{max}_{s}
      \ \pi_{s}(x_{i}; \boldsymbol{\Psi});\ 0 \ \textrm{otherwise}</code></p>
</dd>
</dl>


<h3>See Also</h3>

<p><a href="#topic+ParamRHLP">ParamRHLP</a>
</p>

<hr>
<h2 id='univrealdataset'>Time series representing the electrical power consumption during a railway switch
operation</h2><span id='topic+univrealdataset'></span>

<h3>Description</h3>

<p>This dataset is provided for illustration only; It is issued from the switch
railway monitoring domain. The switch mechanism enables trains to be guided
from one track to another at a railway junction. During each switch
operation, a set of measurements are recorded. Each measurement represents
the consumed electrical power. The resulting time series present regime changes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>univrealdataset
</code></pre>


<h3>Format</h3>

<p>A data frame with 562 rows and 3 columns:
</p>

<dl>
<dt>x</dt><dd><p>The covariate variables which are the sampling time in this time-series case.</p>
</dd>
<dt>y1</dt><dd><p>Measurements of the electrical power consumed during time for a first example of switch operations.</p>
</dd>
<dt>y2</dt><dd><p>Measurements of the electrical power consumed during during time for another example of switch operations.</p>
</dd>
</dl>

<hr>
<h2 id='univtoydataset'>A simulated non-stationary time series with regime changes.</h2><span id='topic+univtoydataset'></span>

<h3>Description</h3>

<p>A simulated non-stationary time series with regime changes.
This time series is used for illustration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>univtoydataset
</code></pre>


<h3>Format</h3>

<p>A data frame with 670 rows and 2 columns:
</p>

<dl>
<dt>x</dt><dd><p>The covariate variable which is the time in this time-series case.</p>
</dd>
<dt>y</dt><dd><p>The time series. The latter has been generated as follows:
</p>

<ul>
<li><p>  First regime: 100 values of standard Normally distributed random numbers.
</p>
</li>
<li><p> Second regime: 120 values of Normally distributed random numbers
with mean 7 and unit variance.
</p>
</li>
<li><p> Third regime: 200 values of Normally distributed random numbers
with mean 4  and unit variance.
</p>
</li>
<li><p> Fourth regime: 100 values of Normally distributed random numbers
with mean -2 and unit variance.
</p>
</li>
<li><p> Fifth regime: 150 values of Normally distributed random numbers
with mean 3.5  and unit variance.
</p>
</li></ul>

</dd>
</dl>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
