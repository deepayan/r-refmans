<!DOCTYPE html><html><head><title>Help for package IndepTest</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {IndepTest}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#KLentropy'><p>KLentropy</p></a></li>
<li><a href='#L2OptW'><p>L2OptW</p></a></li>
<li><a href='#MINTauto'><p>MINTauto</p></a></li>
<li><a href='#MINTav'><p>MINTav</p></a></li>
<li><a href='#MINTknown'><p>MINTknown</p></a></li>
<li><a href='#MINTperm'><p>MINTknown</p></a></li>
<li><a href='#MINTregression'><p>MINTregression</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Nonparametric Independence Tests Based on Entropy Estimation</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2018-08-23</td>
</tr>
<tr>
<td>Author:</td>
<td>Thomas B. Berrett &lt;t.berrett@statslab.cam.ac.uk&gt; [aut], Daniel J. Grose &lt;dan.grose@lancaster.ac.uk&gt; [cre,ctb], Richard J. Samworth &lt;r.samworth@statslab.cam.ac.uk&gt; [aut]  </td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Daniel Grose &lt;dan.grose@lancaster.ac.uk&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementations of the weighted Kozachenko-Leonenko entropy estimator and independence tests based on this estimator, (Kozachenko and Leonenko (1987) <a href="http://mi.mathnet.ru/eng/ppi797">http://mi.mathnet.ru/eng/ppi797</a>). Also includes a goodness-of-fit test for a linear model which is an independence test between covariates and errors.</td>
</tr>
<tr>
<td>Depends:</td>
<td>FNN,mvtnorm</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL]</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-08-23 13:01:19 UTC; grosedj1</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-08-23 14:04:28 UTC</td>
</tr>
</table>
<hr>
<h2 id='KLentropy'>KLentropy</h2><span id='topic+KLentropy'></span>

<h3>Description</h3>

<p>Calculates the (weighted) Kozachenko&ndash;Leonenko entropy estimator studied in Berrett, Samworth and Yuan (2018), which is based on the <code class="reqn">k</code>-nearest neighbour distances of the sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KLentropy(x, k, weights = FALSE, stderror = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KLentropy_+3A_x">x</code></td>
<td>
<p>The <code class="reqn">n \times d</code> data matrix.</p>
</td></tr>
<tr><td><code id="KLentropy_+3A_k">k</code></td>
<td>
<p>The tuning parameter that gives the maximum number of neighbours that will be considered by the estimator.</p>
</td></tr>
<tr><td><code id="KLentropy_+3A_weights">weights</code></td>
<td>
<p>Specifies whether a weighted or unweighted estimator is used. If a weighted estimator is to be used then the default (<code>weights=TRUE</code>) results in the weights being calculated by <code><a href="#topic+L2OptW">L2OptW</a></code>, otherwise the user may specify their own weights.</p>
</td></tr>
<tr><td><code id="KLentropy_+3A_stderror">stderror</code></td>
<td>
<p>Specifies whether an estimate of the standard error of the weighted estimate is calculated. The calculation  is done using an unweighted version of the variance estimator described on page 7 of Berrett, Samworth and Yuan (2018).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The first element of the list is the unweighted estimator for the value of 1 up to the user-specified <code class="reqn">k</code>. The second element of the list is the weighted estimator, obtained by taking the inner product between the first element of the list and the weight vector. If <code>stderror=TRUE</code> the third element of the list is an estimate of the standard error of the weighted estimate.
</p>


<h3>References</h3>

<p>Berrett, T. B., Samworth, R. J. and Yuan, M. (2018).
&ldquo;Efficient multivariate entropy estimation via k-nearest neighbour distances.&rdquo;
<em>Annals of Statistics, to appear</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n=1000; x=rnorm(n); KLentropy(x,30,stderror=TRUE)   # The true value is 0.5*log(2*pi*exp(1)) = 1.42.
n=5000; x=matrix(rnorm(4*n),ncol=4)                 # The true value is 2*log(2*pi*exp(1)) = 5.68
KLentropy(x,30,weights=FALSE)                       # Unweighted estimator
KLentropy(x,30,weights=TRUE)                        # Weights chosen by L2OptW
w=runif(30); w=w/sum(w); KLentropy(x,30,weights=w)  # User-specified weights

</code></pre>

<hr>
<h2 id='L2OptW'>L2OptW</h2><span id='topic+L2OptW'></span>

<h3>Description</h3>

<p>Calculates a weight vector to be used for the weighted Kozachenko&ndash;Leonenko estimator. The weight vector has minimum <code class="reqn">L_2</code> norm subject to the linear and sum-to-one constraints of (2) in Berrett, Samworth and Yuan (2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>L2OptW(k, d)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="L2OptW_+3A_k">k</code></td>
<td>
<p>The tuning parameter that gives the number of neighbours that will be considered by the weighted Kozachenko&ndash;Leonenko estimator.</p>
</td></tr>
<tr><td><code id="L2OptW_+3A_d">d</code></td>
<td>
<p>The dimension of the data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The weight vector that is the solution of the optimisation problem.
</p>


<h3>References</h3>

<p>Berrett, T. B., Samworth, R. J. and Yuan, M. (2018).
&ldquo;Efficient multivariate entropy estimation via k-nearest neighbour distances.&rdquo;
<em>Annals of Statistics, to appear</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># When d &lt; 4 there are no linear constraints and the returned vector is (0,0,...,0,1).
L2OptW(100,3)    
w=L2OptW(100,4)
plot(w,type="l")
w=L2OptW(100,8);
# For each multiple of 4 that d increases an extra constraint is added.
plot(w,type="l")  
w=L2OptW(100,12)
plot(w, type="l") # This can be seen in the shape of the plot

</code></pre>

<hr>
<h2 id='MINTauto'>MINTauto</h2><span id='topic+MINTauto'></span>

<h3>Description</h3>

<p>Performs an independence test without knowledge of either marginal distribution using permutations and using a data-driven choice of <code class="reqn">k</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MINTauto(x, y, kmax, B1 = 1000, B2 = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MINTauto_+3A_x">x</code></td>
<td>
<p>The <code class="reqn">n \times d_{X}</code> data matrix of the <code class="reqn">X</code> values.</p>
</td></tr>
<tr><td><code id="MINTauto_+3A_y">y</code></td>
<td>
<p>The response vector of length <code class="reqn">n \times d_{Y}</code> data matrix of the <code class="reqn">Y</code> values.</p>
</td></tr>
<tr><td><code id="MINTauto_+3A_kmax">kmax</code></td>
<td>
<p>The maximum value of <code class="reqn">k</code> to be considered for estimation of the joint entropy <code class="reqn">H(X,Y)</code>.</p>
</td></tr>
<tr><td><code id="MINTauto_+3A_b1">B1</code></td>
<td>
<p>The number of repetitions used when choosing <code class="reqn">k</code>, set to 1000 by default.</p>
</td></tr>
<tr><td><code id="MINTauto_+3A_b2">B2</code></td>
<td>
<p>The  number of permutations to use for the final test, set at 1000 by default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code class="reqn">p</code>-value corresponding the independence test carried out and the value of <code class="reqn">k</code> used.
</p>


<h3>References</h3>

<p>Berrett, T. B. and Samworth R. J. (2017).
&ldquo;Nonparametric independence testing via mutual information.&rdquo;
<em>ArXiv e-prints</em>.
1711.06642.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Independent univariate normal data
x=rnorm(1000); y=rnorm(1000);
MINTauto(x,y,kmax=200,B1=100,B2=100)
# Dependent univariate normal data
library(mvtnorm)
data=rmvnorm(1000,sigma=matrix(c(1,0.5,0.5,1),ncol=2))  
MINTauto(data[,1],data[,2],kmax=200,B1=100,B2=100)
# Dependent multivariate normal data
Sigma=matrix(c(1,0,0,0,0,1,0,0,0,0,1,0.5,0,0,0.5,1),ncol=4)
data=rmvnorm(1000,sigma=Sigma)
MINTauto(data[,1:3],data[,4],kmax=50,B1=100,B2=100)


</code></pre>

<hr>
<h2 id='MINTav'>MINTav</h2><span id='topic+MINTav'></span>

<h3>Description</h3>

<p>Performs an independence test without knowledge of either marginal distribution using permutations and averaging over a range of values of <code class="reqn">k</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MINTav(x, y, K, B = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MINTav_+3A_x">x</code></td>
<td>
<p>The <code class="reqn">n \times d_{X}</code> data matrix of the <code class="reqn">X</code> values.</p>
</td></tr>
<tr><td><code id="MINTav_+3A_y">y</code></td>
<td>
<p>The <code class="reqn">n \times d_{Y}</code> data matrix of the <code class="reqn">Y</code> values.</p>
</td></tr>
<tr><td><code id="MINTav_+3A_k">K</code></td>
<td>
<p>The vector of values of <code class="reqn">k</code> to be considered for estimation of the joint entropy <code class="reqn">H(X,Y)</code>.</p>
</td></tr>
<tr><td><code id="MINTav_+3A_b">B</code></td>
<td>
<p>The number of permutations to use for the test, set at 1000 by default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code class="reqn">p</code>-value corresponding the independence test carried out.
</p>


<h3>References</h3>

<p>Berrett, T. B. and Samworth R. J. (2017).
&ldquo;Nonparametric independence testing via mutual information.&rdquo;
<em>ArXiv e-prints</em>.
1711.06642.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Independent univariate normal data
x=rnorm(1000); y=rnorm(1000);
MINTav(x,y,K=1:200,B=100)
# Dependent univariate normal data
library(mvtnorm);
data=rmvnorm(1000,sigma=matrix(c(1,0.5,0.5,1),ncol=2))  
MINTav(data[,1],data[,2],K=1:200,B=100)
# Dependent multivariate normal data
Sigma=matrix(c(1,0,0,0,0,1,0,0,0,0,1,0.5,0,0,0.5,1),ncol=4);
data=rmvnorm(1000,sigma=Sigma)
MINTav(data[,1:3],data[,4],K=1:50,B=100)


</code></pre>

<hr>
<h2 id='MINTknown'>MINTknown</h2><span id='topic+MINTknown'></span>

<h3>Description</h3>

<p>Performs an independence test when it is assumed that the marginal distribution of <code class="reqn">Y</code> is known and can be simulated from.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MINTknown(x, y, k, ky, w = FALSE, wy = FALSE, y0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MINTknown_+3A_x">x</code></td>
<td>
<p>The <code class="reqn">n \times d_X</code> data matrix of <code class="reqn">X</code> values.</p>
</td></tr>
<tr><td><code id="MINTknown_+3A_y">y</code></td>
<td>
<p>The <code class="reqn">n \times d_Y</code> data matrix of <code class="reqn">Y</code> values.</p>
</td></tr>
<tr><td><code id="MINTknown_+3A_k">k</code></td>
<td>
<p>The value of <code class="reqn">k</code> to be used for estimation of the joint entropy <code class="reqn">H(X,Y)</code>.</p>
</td></tr>
<tr><td><code id="MINTknown_+3A_ky">ky</code></td>
<td>
<p>The value of <code class="reqn">k</code> to be used for estimation of the marginal entropy <code class="reqn">H(Y)</code>.</p>
</td></tr>
<tr><td><code id="MINTknown_+3A_w">w</code></td>
<td>
<p>The weight vector to used for estimation of the joint entropy <code class="reqn">H(X,Y)</code>, with the same options as for the <code><a href="#topic+KLentropy">KLentropy</a></code> function.</p>
</td></tr>
<tr><td><code id="MINTknown_+3A_wy">wy</code></td>
<td>
<p>The weight vector to used for estimation of the marginal entropy <code class="reqn">H(Y)</code>, with the same options as for the <code><a href="#topic+KLentropy">KLentropy</a></code> function.</p>
</td></tr>
<tr><td><code id="MINTknown_+3A_y0">y0</code></td>
<td>
<p>The data matrix of simulated <code class="reqn">Y</code> values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code class="reqn">p</code>-value corresponding the independence test carried out.
</p>


<h3>References</h3>

<p>Berrett, T. B. and Samworth R. J. (2017).
&ldquo;Nonparametric independence testing via mutual information.&rdquo;
<em>ArXiv e-prints</em>.
1711.06642.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(mvtnorm)
x=rnorm(1000); y=rnorm(1000);
# Independent univariate normal data
MINTknown(x,y,k=20,ky=30,y0=rnorm(100000))  
library(mvtnorm)
# Dependent univariate normal data
data=rmvnorm(1000,sigma=matrix(c(1,0.5,0.5,1),ncol=2))
# Dependent multivariate normal data
MINTknown(data[,1],data[,2],k=20,ky=30,y0=rnorm(100000))   
Sigma=matrix(c(1,0,0,0,0,1,0,0,0,0,1,0.5,0,0,0.5,1),ncol=4)
data=rmvnorm(1000,sigma=Sigma)
MINTknown(data[,1:3],data[,4],k=20,ky=30,w=TRUE,wy=FALSE,y0=rnorm(100000))

</code></pre>

<hr>
<h2 id='MINTperm'>MINTknown</h2><span id='topic+MINTperm'></span>

<h3>Description</h3>

<p>Performs an independence test without knowledge of either marginal distribution using permutations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MINTperm(x, y, k, w = FALSE, B = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MINTperm_+3A_x">x</code></td>
<td>
<p>The <code class="reqn">n \times d_X</code> data matrix of <code class="reqn">X</code> values.</p>
</td></tr>
<tr><td><code id="MINTperm_+3A_y">y</code></td>
<td>
<p>The <code class="reqn">n \times d_Y</code> data matrix of <code class="reqn">Y</code> values.</p>
</td></tr>
<tr><td><code id="MINTperm_+3A_k">k</code></td>
<td>
<p>The value of <code class="reqn">k</code> to be used for estimation of the joint entropy <code class="reqn">H(X,Y)</code>.</p>
</td></tr>
<tr><td><code id="MINTperm_+3A_w">w</code></td>
<td>
<p>The weight vector to used for estimation of the joint entropy <code class="reqn">H(X,Y)</code>, with the same options as for the <code><a href="#topic+KLentropy">KLentropy</a></code> function.</p>
</td></tr>
<tr><td><code id="MINTperm_+3A_b">B</code></td>
<td>
<p>The number of permutations to use, set at 1000 by default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code class="reqn">p</code>-value corresponding the independence test carried out.
</p>


<h3>References</h3>

<p>Berrett, T. B. and Samworth R. J. (2017).
&ldquo;Nonparametric independence testing via mutual information.&rdquo;
<em>ArXiv e-prints</em>.
1711.06642.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Independent univariate normal data
x=rnorm(1000); y=rnorm(1000)
MINTperm(x,y,k=20,B=100)
# Dependent univariate normal data
library(mvtnorm)
data=rmvnorm(1000,sigma=matrix(c(1,0.5,0.5,1),ncol=2))  
MINTperm(data[,1],data[,2],k=20,B=100)
# Dependent multivariate normal data
Sigma=matrix(c(1,0,0,0,0,1,0,0,0,0,1,0.5,0,0,0.5,1),ncol=4)
data=rmvnorm(1000,sigma=Sigma)
MINTperm(data[,1:3],data[,4],k=20,w=TRUE,B=100)

</code></pre>

<hr>
<h2 id='MINTregression'>MINTregression</h2><span id='topic+MINTregression'></span>

<h3>Description</h3>

<p>Performs a goodness-of-fit test of a linear model by testing whether the errors are independent of the covariates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MINTregression(x, y, k, keps, w = FALSE, eps)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MINTregression_+3A_x">x</code></td>
<td>
<p>The <code class="reqn">n \times p</code> design matrix.</p>
</td></tr>
<tr><td><code id="MINTregression_+3A_y">y</code></td>
<td>
<p>The response vector of length <code class="reqn">n</code>.</p>
</td></tr>
<tr><td><code id="MINTregression_+3A_k">k</code></td>
<td>
<p>The value of <code class="reqn">k</code> to be used for estimation of the joint entropy <code class="reqn">H(X,\epsilon)</code>.</p>
</td></tr>
<tr><td><code id="MINTregression_+3A_keps">keps</code></td>
<td>
<p>The value of <code class="reqn">k</code> to be used for estimation of the marginal entropy <code class="reqn">H(\epsilon)</code>.</p>
</td></tr>
<tr><td><code id="MINTregression_+3A_w">w</code></td>
<td>
<p>The weight vector to be used for estimation of the joint entropy <code class="reqn">H(X,\epsilon)</code>, with the same options as for the <code><a href="#topic+KLentropy">KLentropy</a></code> function.</p>
</td></tr>
<tr><td><code id="MINTregression_+3A_eps">eps</code></td>
<td>
<p>A vector of null errors which should have the same distribution as the errors are assumed to have in the linear model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code class="reqn">p</code>-value corresponding the independence test carried out.
</p>


<h3>References</h3>

<p>Berrett, T. B. and Samworth R. J. (2017).
&ldquo;Nonparametric independence testing via mutual information.&rdquo;
<em>ArXiv e-prints</em>.
1711.06642.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Correctly specified linear model
x=runif(100,min=-1.5,max=1.5); y=x+rnorm(100)
plot(lm(y~x),which=1) 
MINTregression(x,y,5,10,w=FALSE,rnorm(10000))
# Misspecified mean linear model
x=runif(100,min=-1.5,max=1.5); y=x^3+rnorm(100)
plot(lm(y~x),which=1)
MINTregression(x,y,5,10,w=FALSE,rnorm(10000))
# Heteroscedastic linear model
x=runif(100,min=-1.5,max=1.5); y=x+x*rnorm(100);
plot(lm(y~x),which=1) 
MINTregression(x,y,5,10,w=FALSE,rnorm(10000))
# Multivariate misspecified mean linear model
x=matrix(runif(1500,min=-1.5,max=1.5),ncol=3)
y=x[,1]^3+0.3*x[,2]-0.3*x[,3]+rnorm(500)
plot(lm(y~x),which=1)
MINTregression(x,y,30,50,w=TRUE,rnorm(50000))  


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
