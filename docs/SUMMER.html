<!DOCTYPE html><html lang="en"><head><title>Help for package SUMMER</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SUMMER}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#SUMMER-package'><p>SUMMER: Small-Area-Estimation Unit/Area Models and Methods for Estimation in R</p></a></li>
<li><a href='#aggPixelPreds'><p>Helper function of <code>pixelPopToArea</code></p></a></li>
<li><a href='#aggPop'><p>Aggregate populations to the specified areal level</p></a></li>
<li><a href='#aggregateSurvey'><p>Aggregate estimators from different surveys.</p></a></li>
<li><a href='#Benchmark'><p>Benchmark posterior draws to national estimates</p></a></li>
<li><a href='#BRFSS'><p>The BRFSS dataset</p></a></li>
<li><a href='#calibrateByRegion'><p>Calibrate the point level totals so their sum matches the regional totals</p></a></li>
<li><a href='#changeRegion'><p>Map region names to a common set.</p></a></li>
<li><a href='#compareEstimates'><p>Plot heatmap comparing pairwise posterior exceedence probabilities for svysae object</p></a></li>
<li><a href='#DemoData'><p>Simulated child mortality person-month dataset.</p></a></li>
<li><a href='#DemoData2'><p>Simulated dataset for prevalence mapping.</p></a></li>
<li><a href='#DemoMap'><p>Uganda Admin-1 region map for illustration purpose</p></a></li>
<li><a href='#DemoMap2'><p>Kenya Admin-1 region map for illustration purpose</p></a></li>
<li><a href='#expit'><p>Expit transformation</p></a></li>
<li><a href='#fitGeneric'><p>Fit space-time smoothing models for a binary outcome from complex surveys.</p></a></li>
<li><a href='#fitINLA'><p>Smoothed direct estimates for mortality rates</p></a></li>
<li><a href='#fitINLA2'><p>Cluster-level space-time smoothing models for mortality rates</p></a></li>
<li><a href='#getAdjusted'><p>Adjust direct estimates and their associated variances</p></a></li>
<li><a href='#getAmat'><p>Extract adjacency matrix from the map</p></a></li>
<li><a href='#getAreaName'><p>Determines which administrative areas contain the given points</p></a></li>
<li><a href='#getBirths'><p>Reformat full birth records into person-month format</p></a></li>
<li><a href='#getCounts'><p>Aggregate person-month data into counts and totals by groups.</p></a></li>
<li><a href='#getDiag'><p>Extract posterior summaries of random effects</p></a></li>
<li><a href='#getDirect'><p>Obtain the Horvitz-Thompson direct estimates and standard errors using delta method for a single survey.</p></a></li>
<li><a href='#getDirectList'><p>Obtain the Horvitz-Thompson direct estimates and standard errors using delta method for multiple surveys.</p></a></li>
<li><a href='#getSmoothed'><p>Extract smoothed estimates.</p></a></li>
<li><a href='#hatchPlot'><p>Plot maps with uncertainty hatching.</p></a></li>
<li><a href='#iid.new'><p>New random IID models for m-year to period random effects</p></a></li>
<li><a href='#iid.new.pc'><p>New random IID models for m-year to period random effects</p></a></li>
<li><a href='#KenData'><p>Auxiliary data for Kenya 2014 DHS.</p></a></li>
<li><a href='#kenyaPopulationData'><p>Kenya 2009 Census Frame and Related Datasets</p></a></li>
<li><a href='#KingCounty'><p>Map of King County</p></a></li>
<li><a href='#logit'><p>Logit transformation</p></a></li>
<li><a href='#logitNormMean'><p>Calculate the mean of a distribution whose</p>
logit is Gaussian</a></li>
<li><a href='#makePopIntegrationTab'><p>Generating pixellated populations, and population frames</p></a></li>
<li><a href='#MalawiData'><p>Auxiliary data for Malawi 2000, 2004, 2010, and 2015 DHS.</p></a></li>
<li><a href='#MalawiMap'><p>Malawi Admin-2 map</p></a></li>
<li><a href='#mapEstimates'><p>Mapping estimates for svysae object</p></a></li>
<li><a href='#mapPlot'><p>Plot region-level variables on a map</p></a></li>
<li><a href='#mapPoints'><p>Map GPS points to polygon regions</p></a></li>
<li><a href='#plot.SUMMERproj'><p>Plot projection output.</p></a></li>
<li><a href='#poppRegionFromPopMat'><p>Generate a population frame of a similar format to poppa argument of <code>simPopCustom</code> with a custom set of regions</p></a></li>
<li><a href='#print.SUMMERmodel'><p>Print method for the smoothing models.</p></a></li>
<li><a href='#print.SUMMERmodel.svy'><p>Print method for the smoothing models from <code>smoothSurvey</code>.</p></a></li>
<li><a href='#print.SUMMERprojlist'><p>Print method for the combined projection output.</p></a></li>
<li><a href='#projKenya'><p>Map projection for Kenya</p></a></li>
<li><a href='#ridgePlot'><p>Calculate and plot posterior densities of the projected estimates</p></a></li>
<li><a href='#rst'><p>Simulate spatial and temporal random effects</p></a></li>
<li><a href='#rw.new'><p>New random walk 1 and 2 models for m-year to period random effects</p></a></li>
<li><a href='#rw.new.pc'><p>New random walk 1 and 2 models for m-year to period random effects</p></a></li>
<li><a href='#setThresholdsByRegion'><p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a></p></a></li>
<li><a href='#simhyper'><p>Simulate hyperpriors from an GMRF</p></a></li>
<li><a href='#simPop'><p>Simulate populations and areal prevalences</p></a></li>
<li><a href='#simPopInternal'><p>Internal functions for population simulation</p></a></li>
<li><a href='#simSPDE'><p>Simulate from the SPDE spatial model</p></a></li>
<li><a href='#smoothArea'><p>Small area estimation via basic area level model</p></a></li>
<li><a href='#smoothCluster'><p>Cluster-level space-time smoothing models for mortality rates</p></a></li>
<li><a href='#smoothDirect'><p>Smoothed direct estimates for mortality rates</p></a></li>
<li><a href='#smoothSurvey'><p>Fit space-time smoothing models for a binary outcome from complex surveys.</p></a></li>
<li><a href='#smoothUnit'><p>Smooth via basic unit level model</p></a></li>
<li><a href='#st.new'><p>New Type I to IV space time interaction models for m-year to period random effects</p></a></li>
<li><a href='#st.new.pc'><p>New Type I to IV space time interaction models for m-year to period random effects</p></a></li>
<li><a href='#summary.SUMMERmodel'><p>Summary method for the smoothing models.</p></a></li>
<li><a href='#summary.SUMMERmodel.svy'><p>Summary method for the smoothing model and output from <code>smoothSurvey</code>.</p></a></li>
<li><a href='#summary.SUMMERprojlist'><p>Summary method for the combined projection output.</p>
This function is the print method for class <code>SUMMERprojlist</code>.</a></li>
<li><a href='#tcpPlot'><p>Discrete-color maps based on the True Classification Probabilities</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Small-Area-Estimation Unit/Area Models and Methods for
Estimation in R</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-01-03</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides methods for spatial and spatio-temporal smoothing of demographic and health indicators using survey data, with particular focus on estimating and projecting under-five mortality rates, described in Mercer et al. (2015) &lt;<a href="https://doi.org/10.1214%2F15-AOAS872">doi:10.1214/15-AOAS872</a>&gt;, Li et al. (2019) &lt;<a href="https://doi.org/10.1371%2Fjournal.pone.0210645">doi:10.1371/journal.pone.0210645</a>&gt;, Wu et al. (DHS Spatial Analysis Reports No. 21, 2021), and Li et al. (2023) &lt;<a href="https://doi.org/10.48550%2FarXiv.2007.05117">doi:10.48550/arXiv.2007.05117</a>&gt;. </td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/richardli/SUMMER">https://github.com/richardli/SUMMER</a>,
<a href="https://richardli.github.io/SUMMER/">https://richardli.github.io/SUMMER/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/richardli/SUMMER/issues">https://github.com/richardli/SUMMER/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>survey, stats, spdep, survival, ggplot2, scales, utils,
Matrix, reshape2, viridis, sp, sf, shadowtext, ggridges,
methods, data.table, RColorBrewer, grDevices, fields, terra,
haven, lifecycle</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Additional_repositories:</td>
<td><a href="https://inla.r-inla-download.org/R/testing/">https://inla.r-inla-download.org/R/testing/</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td>INLA, sn, knitr, rmarkdown, readstata13, patchwork, rdhs,
R.rsp, sae, dplyr, tidyr, raster, fmesher, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>R.rsp, knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Config/build/clean-inst-doc:</td>
<td>FALSE</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Config/testthat/parallel:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-07 19:28:57 UTC; zehangli</td>
</tr>
<tr>
<td>Author:</td>
<td>Zehang R Li [cre, aut],
  Bryan D Martin [aut],
  Yuan Hsiao [aut],
  Jessica Godwin [aut],
  John Paige [aut],
  Peter Gao [aut],
  Jon Wakefield [aut],
  Samuel J Clark [aut],
  Geir-Arne Fuglstad [aut],
  Andrea Riebler [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Zehang R Li &lt;lizehang@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-07 22:20:10 UTC</td>
</tr>
</table>
<hr>
<h2 id='SUMMER-package'>SUMMER: Small-Area-Estimation Unit/Area Models and Methods for Estimation in R</h2><span id='topic+SUMMER-package'></span><span id='topic+SUMMER'></span>

<h3>Description</h3>

<p>Provides methods for spatial and spatio-temporal smoothing of demographic and health indicators using survey data, with particular focus on estimating and projecting under-five mortality rates, described in Mercer et al. (2015) <a href="https://doi.org/10.1214/15-AOAS872">doi:10.1214/15-AOAS872</a>, Li et al. (2019) <a href="https://doi.org/10.1371/journal.pone.0210645">doi:10.1371/journal.pone.0210645</a>, Wu et al. (DHS Spatial Analysis Reports No. 21, 2021), and Li et al. (2023) <a href="https://arxiv.org/abs/2007.05117">arXiv:2007.05117</a>.
</p>
<p>SUMMER provides methods for spatial and spatio-temporal smoothing of demographic and health indicators using survey data, with particular focus on estimating and projecting under-five mortality rates.
</p>


<h3>Details</h3>

<p>For details on the model implemented in this package, see Mercer et al. (2015) <a href="doi:10.1214/15-AOAS872">doi:10.1214/15-AOAS872</a> and Li et al. (2019) <a href="doi:10.1371/journal.pone.0210645">doi:10.1371/journal.pone.0210645</a>.
</p>
<p>The development version of the package will be maintained on <a href="https://github.com/richardli/SUMMER">https://github.com/richardli/SUMMER</a>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Zehang R Li <a href="mailto:lizehang@gmail.com">lizehang@gmail.com</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Bryan D Martin <a href="mailto:bmartin6@uw.edu">bmartin6@uw.edu</a>
</p>
</li>
<li><p> Yuan Hsiao <a href="mailto:yahsiao@uw.edu">yahsiao@uw.edu</a>
</p>
</li>
<li><p> Jessica Godwin <a href="mailto:jlg0003@uw.edu">jlg0003@uw.edu</a>
</p>
</li>
<li><p> John Paige <a href="mailto:paigejo@gmail.com">paigejo@gmail.com</a>
</p>
</li>
<li><p> Peter Gao <a href="mailto:petergao@uw.edu">petergao@uw.edu</a>
</p>
</li>
<li><p> Jon Wakefield <a href="mailto:jonno@uw.edu">jonno@uw.edu</a>
</p>
</li>
<li><p> Samuel J Clark <a href="mailto:work@samclark.net">work@samclark.net</a>
</p>
</li>
<li><p> Geir-Arne Fuglstad <a href="mailto:geir-arne.fuglstad@ntnu.no">geir-arne.fuglstad@ntnu.no</a>
</p>
</li>
<li><p> Andrea Riebler <a href="mailto:andrea.riebler@ntnu.no">andrea.riebler@ntnu.no</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/richardli/SUMMER">https://github.com/richardli/SUMMER</a>
</p>
</li>
<li> <p><a href="https://richardli.github.io/SUMMER/">https://richardli.github.io/SUMMER/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/richardli/SUMMER/issues">https://github.com/richardli/SUMMER/issues</a>
</p>
</li></ul>


<hr>
<h2 id='aggPixelPreds'>Helper function of <code><a href="#topic+pixelPopToArea">pixelPopToArea</a></code></h2><span id='topic+aggPixelPreds'></span>

<h3>Description</h3>

<p>Aggregates population from the
pixel level to the level of the area of interest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aggPixelPreds(
  Zg,
  Ng,
  areas,
  urban = target.pop.mat$urban,
  target.pop.mat = NULL,
  use.density = FALSE,
  stratify.by.urban = TRUE,
  normalize = use.density
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="aggPixelPreds_+3A_zg">Zg</code></td>
<td>
<p>nIntegrationPoint x nsim matrix of simulated response (population numerators) for each pixel and sample</p>
</td></tr>
<tr><td><code id="aggPixelPreds_+3A_ng">Ng</code></td>
<td>
<p>nIntegrationPoint x nsim matrix of simulated counts (population denominators) for each pixel and sample</p>
</td></tr>
<tr><td><code id="aggPixelPreds_+3A_areas">areas</code></td>
<td>
<p>nIntegrationPoint length character vector of areas (or subareas)</p>
</td></tr>
<tr><td><code id="aggPixelPreds_+3A_urban">urban</code></td>
<td>
<p>nIntegrationPoint length vector of indicators specifying whether or not pixels are urban or rural</p>
</td></tr>
<tr><td><code id="aggPixelPreds_+3A_target.pop.mat">target.pop.mat</code></td>
<td>
<p>same as in <code><a href="#topic+simPopCustom">simPopCustom</a></code></p>
</td></tr>
<tr><td><code id="aggPixelPreds_+3A_use.density">use.density</code></td>
<td>
<p>whether to use population density as aggregation weights.</p>
</td></tr>
<tr><td><code id="aggPixelPreds_+3A_stratify.by.urban">stratify.by.urban</code></td>
<td>
<p>whether or not to stratify simulations by urban/rural classification</p>
</td></tr>
<tr><td><code id="aggPixelPreds_+3A_normalize">normalize</code></td>
<td>
<p>if TRUE, pixel level aggregation weights within specified area are normalized to sum to 1. This produces an
average of the values in Zg rather than a sum. In general, should only be set to TRUE for smooth integrals of risk.</p>
</td></tr>
</table>

<hr>
<h2 id='aggPop'>Aggregate populations to the specified areal level</h2><span id='topic+aggPop'></span><span id='topic+pixelPopToArea'></span><span id='topic+areaPopToArea'></span>

<h3>Description</h3>

<p>Takes simulated populations and aggregates
them to the specified areal level. Also calculates the aggregated risk and prevalence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pixelPopToArea(
  pixel.level.pop,
  ea.samples,
  areas,
  stratify.by.urban = TRUE,
  target.pop.mat = NULL,
  do.fine.scale.risk = !is.null(pixel.level.pop$fineScaleRisk$p),
  do.smooth.risk = !is.null(pixel.level.pop$smoothRisk$p)
)

areaPopToArea(
  area.level.pop,
  areas.from,
  areas.to,
  stratify.by.urban = TRUE,
  do.fine.scale.risk = !is.null(area.level.pop$aggregationResults$pFineScaleRisk),
  do.smooth.risk = !is.null(area.level.pop$aggregationResults$pSmoothRisk)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="aggPop_+3A_pixel.level.pop">pixel.level.pop</code></td>
<td>
<p>pixel level population information that we want aggregate. In the same format as output from <code><a href="#topic+simPopCustom">simPopCustom</a></code></p>
</td></tr>
<tr><td><code id="aggPop_+3A_ea.samples">ea.samples</code></td>
<td>
<p>nIntegrationPoint x nsim matrix of the number of enumeration areas per pixel sampled in the input pixel level population</p>
</td></tr>
<tr><td><code id="aggPop_+3A_areas">areas</code></td>
<td>
<p>character vector of length nIntegrationPoints of area names over which we
want to aggregate. Can also be subareas</p>
</td></tr>
<tr><td><code id="aggPop_+3A_stratify.by.urban">stratify.by.urban</code></td>
<td>
<p>whether or not to stratify simulations by urban/rural classification</p>
</td></tr>
<tr><td><code id="aggPop_+3A_target.pop.mat">target.pop.mat</code></td>
<td>
<p>pixellated grid data frame with variables <code>lon</code>, <code>lat</code>, <code>pop</code> (target population), <code>area</code>, <code>subareas</code> (if subarea.level is TRUE), <code>urban</code> (if stratify.by.urban is TRUE), <code>east</code>, and <code>north</code></p>
</td></tr>
<tr><td><code id="aggPop_+3A_do.fine.scale.risk">do.fine.scale.risk</code></td>
<td>
<p>whether or not to calculate the fine scale risk in addition to the prevalence. See details</p>
</td></tr>
<tr><td><code id="aggPop_+3A_do.smooth.risk">do.smooth.risk</code></td>
<td>
<p>Whether or not to calculate the smooth risk in addition to the prevalence. See details</p>
</td></tr>
<tr><td><code id="aggPop_+3A_area.level.pop">area.level.pop</code></td>
<td>
<p>output of <code><a href="#topic+simPopCustom">simPopCustom</a></code> containing pixel level information
about the population of interest</p>
</td></tr>
<tr><td><code id="aggPop_+3A_areas.from">areas.from</code></td>
<td>
<p>character vector of length equal to the number of areas from which
we would like to aggregate containing the unique names of the areas.
Can also be subareas, but these are smaller than the &quot;to areas&quot;, and
each &quot;from area&quot; must be entirely contained in a single &quot;to area&quot;</p>
</td></tr>
<tr><td><code id="aggPop_+3A_areas.to">areas.to</code></td>
<td>
<p>character vector of length equal to the number of areas from which
we would like to aggregate containing the names of the areas containing
with each respective &lsquo;from&rsquo; area. Can also be a set of subareas,
but these are larger than the &quot;from areas&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a>
</p>


<h3>Value</h3>

<p>A list containing elements <code>fineScalePrevalence</code> and <code>fineScaleRisk</code>. Each
of these are in turn lists with aggregated prevalence and risk for the area of
interest, containg the following elements, were paranethesis indicate the elements
for the fineScaleRisk model rather than fineScalePrevalence:
</p>
<table role = "presentation">
<tr><td><code>p</code></td>
<td>
<p>Aggregated prevalence (risk), calculated as aggregate of Z divided by
aggregate of N</p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p>Aggregated (expected) population numerator</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>Aggregated (expected) population denominator</p>
</td></tr>
<tr><td><code>pUrban</code></td>
<td>
<p>Aggregated prevalence (risk) in urban part of the area, calculated
as aggregate of Z divided by aggregate of N</p>
</td></tr>
<tr><td><code>ZUrban</code></td>
<td>
<p>Aggregated (expected) population numerator in urban part of the area</p>
</td></tr>
<tr><td><code>NUrban</code></td>
<td>
<p>Aggregated (expected) population denominator in urban part of the area</p>
</td></tr>
<tr><td><code>pRural</code></td>
<td>
<p>Aggregated prevalence (risk) in rural part of the area, calculated
as aggregate of Z divided by aggregate of N</p>
</td></tr>
<tr><td><code>ZRural</code></td>
<td>
<p>Aggregated (expected) population numerator in rural part of the area</p>
</td></tr>
<tr><td><code>NRural</code></td>
<td>
<p>Aggregated (expected) population denominator in rural part of the area</p>
</td></tr>
<tr><td><code>A</code></td>
<td>
<p>Aggregation matrix used to aggregate from pixel level to areal level</p>
</td></tr>
<tr><td><code>AUrban</code></td>
<td>
<p>Aggregation matrix used to aggregate from pixel level to urban part of the areal level</p>
</td></tr>
<tr><td><code>ARural</code></td>
<td>
<p>Aggregation matrix used to aggregate from pixel level to rural part of the areal level</p>
</td></tr>
</table>


<h3>Functions</h3>


<ul>
<li> <p><code>pixelPopToArea()</code>: Aggregate from pixel to areal level
</p>
</li>
<li> <p><code>areaPopToArea()</code>: Aggregate areal populations to another areal level
</p>
</li></ul>


<h3>Author(s)</h3>

<p>John Paige
</p>


<h3>References</h3>

<p>Paige, John, Geir-Arne Fuglstad, Andrea Riebler, and Jon Wakefield. &quot;Spatial aggregation with respect to a population distribution: Impact on inference.&quot; Spatial Statistics 52 (2022): 100714.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+areaPopToArea">areaPopToArea</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# download Kenya GADM shapefiles from SUMMERdata github repository
githubURL &lt;- paste0("https://github.com/paigejo/SUMMERdata/blob/main/data/", 
                    "kenyaMaps.rda?raw=true")
tempDirectory = "~/"
mapsFilename = paste0(tempDirectory, "/kenyaMaps.rda")
if(!file.exists(mapsFilename)) {
  download.file(githubURL,mapsFilename)
}

# load it in
out = load(mapsFilename)
out
kenyaMesh &lt;- fmesher::fm_as_fm(kenyaMesh)

adm1@data$NAME_1 = as.character(adm1@data$NAME_1)
adm1@data$NAME_1[adm1@data$NAME_1 == "Trans Nzoia"] = "Trans-Nzoia"
adm1@data$NAME_1[adm1@data$NAME_1 == "Elgeyo-Marakwet"] = "Elgeyo Marakwet"
adm2@data$NAME_1 = as.character(adm2@data$NAME_1)
adm2@data$NAME_1[adm2@data$NAME_1 == "Trans Nzoia"] = "Trans-Nzoia"
adm2@data$NAME_1[adm2@data$NAME_1 == "Elgeyo-Marakwet"] = "Elgeyo Marakwet"

# some Admin-2 areas have the same name
adm2@data$NAME_2 = as.character(adm2@data$NAME_2)
adm2@data$NAME_2[(adm2@data$NAME_1 == "Bungoma") &amp; 
                   (adm2@data$NAME_2 == "Lugari")] = "Lugari, Bungoma"
adm2@data$NAME_2[(adm2@data$NAME_1 == "Kakamega") &amp; 
                   (adm2@data$NAME_2 == "Lugari")] = "Lugari, Kakamega"
adm2@data$NAME_2[(adm2@data$NAME_1 == "Meru") &amp; 
                   (adm2@data$NAME_2 == "Igembe South")] = "Igembe South, Meru"
adm2@data$NAME_2[(adm2@data$NAME_1 == "Tharaka-Nithi") &amp; 
                   (adm2@data$NAME_2 == "Igembe South")] = "Igembe South, Tharaka-Nithi"

# The spatial area of unknown 8 is so small, it causes problems unless its removed or 
# unioned with another subarea. Union it with neighboring Kakeguria:
newadm2 = adm2
unknown8I = which(newadm2$NAME_2 == "unknown 8")
newadm2$NAME_2[newadm2$NAME_2 %in% c("unknown 8", "Kapenguria")] &lt;- 
  "Kapenguria + unknown 8"
admin2.IDs &lt;- newadm2$NAME_2

newadm2@data = cbind(newadm2@data, NAME_2OLD = newadm2@data$NAME_2)
newadm2@data$NAME_2OLD = newadm2@data$NAME_2
newadm2@data$NAME_2 = admin2.IDs
newadm2$NAME_2 = admin2.IDs
temp &lt;- terra::aggregate(as(newadm2, "SpatVector"), by="NAME_2")

library(sf)
temp &lt;- sf::st_as_sf(temp)
temp &lt;- sf::as_Spatial(temp)

tempData = newadm2@data[-unknown8I,]
tempData = tempData[order(tempData$NAME_2),]
newadm2 &lt;- sp::SpatialPolygonsDataFrame(temp, tempData, match.ID = F)
adm2 = newadm2

# download 2014 Kenya population density TIF file

githubURL &lt;- paste0("https://github.com/paigejo/SUMMERdata/blob/main/data/", 
                    "Kenya2014Pop/worldpop_total_1y_2014_00_00.tif?raw=true")
popTIFFilename = paste0(tempDirectory, "/worldpop_total_1y_2014_00_00.tif")
if(!file.exists(popTIFFilename)) {
  download.file(githubURL,popTIFFilename)
}

# load it in
pop = terra::rast(popTIFFilename)

east.lim = c(-110.6405, 832.4544)
north.lim = c(-555.1739, 608.7130)

## Construct poppsubKenya, a table of urban/rural general population totals 
## in each subarea. Technically, this is not necessary since we can load in 
## poppsubKenya via data(kenyaPopulationData). First, we will need to calculate 
## the areas in km^2 of the areas and subareas

# use Lambert equal area projection of areas (Admin-1) and subareas (Admin-2)
midLon = mean(adm1@bbox[1,])
midLat = mean(adm1@bbox[2,])
p4s = paste0("+proj=laea +x_0=0 +y_0=0 +lon_0=", midLon, 
             " +lat_0=", midLat, " +units=km")

adm1_sf = st_as_sf(adm1)
adm1proj_sf = st_transform(adm1_sf, p4s)
adm1proj = as(adm1proj_sf, "Spatial")

adm2_sf = st_as_sf(adm2)
adm2proj_sf = st_transform(adm2_sf, p4s)
adm2proj = as(adm2proj_sf, "Spatial")

# now calculate spatial area in km^2
admin1Areas = as.numeric(st_area(adm1proj_sf))
admin2Areas = as.numeric(st_area(adm2proj_sf))

areapaKenya = data.frame(area=adm1proj@data$NAME_1, spatialArea=admin1Areas)
areapsubKenya = data.frame(area=adm2proj@data$NAME_1, subarea=adm2proj@data$NAME_2, 
                           spatialArea=admin2Areas)

# Calculate general population totals at the subarea (Admin-2) x urban/rural 
# level and using 1km resolution population grid. Assign urbanicity by 
# thresholding population density based on estimated proportion population 
# urban/rural, making sure total area (Admin-1) urban/rural populations in 
# each area matches poppaKenya.

data(kenyaPopulationData)
pop.matKenya &lt;- makePopIntegrationTab(
  km.res=5, pop=pop, domain.map.dat=adm0,
  east.lim=east.lim, north.lim=north.lim, map.projection=projKenya,
  poppa = poppaKenya, poppsub=poppsubKenya, 
  area.map.dat = adm1, subarea.map.dat = adm2,
  areaNameVar = "NAME_1", subareaNameVar="NAME_2")

##### Now we make a model for the risk. We will use an SPDE model with these 
##### parameters for the linear predictor on the logist scale, which are chosen 
##### to be of practical interest:
beta0=-2.9 # intercept
gamma=-1 # urban effect
rho=(1/3)^2 # spatial variance
eff.range = 400 # effective spatial range in km
sigma.epsilon=sqrt(1/2.5) # cluster (nugget) effect standard deviation

# simulate the population! Note that this produces multiple dense 
# nEA x nsim and nIntegrationPoint x nsim matrices. In the future 
# sparse matrices will and chunk by chunk computations may be incorporated.
simPop = simPopSPDE(nsim=1, easpa=easpaKenyaNeonatal, 
                    pop.mat=pop.matKenya, target.pop.mat=pop.matKenya, 
                    poppsub=poppsubKenya, spde.mesh=kenyaMesh, 
                    marg.var=rho, sigma.epsilon=sigma.epsilon, 
                    gamma=gamma, eff.range=eff.range, beta0=beta0, 
                    seed=123, inla.seed=12, n.HH.sampled=25, 
                    stratify.by.urban=TRUE, subarea.level=TRUE, 
                    do.fine.scale.risk=TRUE, 
                    min1.per.subarea=TRUE)

pixelPop = simPop$pixelPop
subareaPop = pixelPopToArea(pixel.level.pop=pixelPop, ea.samples=pixelPop$ea.samples, 
  areas=pop.matKenya$subarea, stratify.by.urban=TRUE, 
  target.pop.mat=pop.matKenya, do.fine.scale.risk=TRUE)

# get areas associated with each subarea for aggregation
tempAreasFrom = pop.matKenya$subarea
tempAreasTo = pop.matKenya$area
areas.from = sort(unique(tempAreasFrom))
areas.toI = match(areas.from, tempAreasFrom)
areas.to = tempAreasTo[areas.toI]

# do the aggregation from subareas to areas
outAreaLevel = areaPopToArea(area.level.pop=subareaPop, 
  areas.from=areas.from, areas.to=areas.to, 
  stratify.by.urban=TRUE, do.fine.scale.risk=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='aggregateSurvey'>Aggregate estimators from different surveys.</h2><span id='topic+aggregateSurvey'></span>

<h3>Description</h3>

<p>Aggregate estimators from different surveys.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aggregateSurvey(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="aggregateSurvey_+3A_data">data</code></td>
<td>
<p>Output from <code><a href="#topic+getDirectList">getDirectList</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Estimators aggregated across surveys.
</p>


<h3>Author(s)</h3>

<p>Zehang Richard Li
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(DemoData)
data(DemoMap)
years &lt;- levels(DemoData[[1]]$time)

# obtain direct estimates
data &lt;- getDirectList(births = DemoData, 
years = years, 
regionVar = "region", timeVar = "time", 
clusterVar = "~clustid+id", 
ageVar = "age", weightsVar = "weights", 
geo.recode = NULL)

# obtain maps
geo &lt;- DemoMap$geo
mat &lt;- DemoMap$Amat

# Simulate hyper priors
priors &lt;- simhyper(R = 2, nsamp = 1e+05, nsamp.check = 5000, Amat = mat, only.iid = TRUE)

# combine data from multiple surveys
data &lt;- aggregateSurvey(data)
utils::head(data)


## End(Not run)

</code></pre>

<hr>
<h2 id='Benchmark'>Benchmark posterior draws to national estimates</h2><span id='topic+Benchmark'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Benchmark(
  fitted,
  national,
  estVar,
  sdVar,
  timeVar = NULL,
  weight.region = NULL,
  method = c("MH", "Rejection")[2]
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Benchmark_+3A_fitted">fitted</code></td>
<td>
<p>output from <code><a href="#topic+getSmoothed">getSmoothed</a></code> to be benchmarked.</p>
</td></tr>
<tr><td><code id="Benchmark_+3A_national">national</code></td>
<td>
<p>a data frame of national level estimates that is benchmarked against, with at least two columns indicating national estimates (probability scale) and the associated standard error. If benchmarking over multiple time period, a third column indicating time period is needed.</p>
</td></tr>
<tr><td><code id="Benchmark_+3A_estvar">estVar</code></td>
<td>
<p>column name in <code>national</code> that indicates national estimates.</p>
</td></tr>
<tr><td><code id="Benchmark_+3A_sdvar">sdVar</code></td>
<td>
<p>column name in <code>national</code> that indicates standard errors of national estimates.</p>
</td></tr>
<tr><td><code id="Benchmark_+3A_timevar">timeVar</code></td>
<td>
<p>column name in <code>national</code> that indicates time periods.</p>
</td></tr>
<tr><td><code id="Benchmark_+3A_weight.region">weight.region</code></td>
<td>
<p>a data frame with a column <code>region</code> specifying subnational regions, a column <code>proportion</code> that specifies the proportion of population in each region. When multiple time periods exist, a third column <code>years</code> is required and the population proportions are the population proportions of each region in the corresponding time period.</p>
</td></tr>
<tr><td><code id="Benchmark_+3A_method">method</code></td>
<td>
<p>a string denoting the algorithm to use for benchmarking. Options include <code>MH</code> for Metropolis-Hastings, and <code>Rejection</code> for rejection sampler. Defaults to <code>Rejection</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Benchmarked object in S3 class SUMMERproj or SUMMERprojlist in the same format as the input object <code>fitted</code>.
</p>


<h3>Author(s)</h3>

<p>Taylor Okonek, Zehang Richard Li
</p>


<h3>References</h3>

<p>Okonek, Taylor, and Jon Wakefield. &quot;A computationally efficient approach to fully Bayesian benchmarking.&quot; Journal of Official Statistics 40, no. 2 (2024): 283-316.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
##  ------------------------------------------ ##
##     Benchmarking with smoothCluster output
##  ------------------------------------------ ##

data(DemoData)
# fit unstratified cluster-level model
counts.all &lt;- NULL
for(i in 1:length(DemoData)){
vars &lt;- c("clustid", "region", "time", "age")
counts &lt;- getCounts(DemoData[[i]][, c(vars, "died")], 
						variables = 'died',
	 			    by = vars, drop=TRUE)
counts$cluster &lt;- counts$clustid
counts$years &lt;- counts$time
counts$Y &lt;- counts$died
counts$survey &lt;- names(DemoData)[i]	
counts.all &lt;- rbind(counts.all, counts)
}
periods &lt;- c("85-89", "90-94", "95-99", "00-04", "05-09", "10-14", "15-19")
fit.bb  &lt;- smoothCluster(data = counts.all, Amat = DemoMap$Amat, 
				family = "betabinomial",
				year.label = periods, 
				survey.effect = TRUE)
est.bb &lt;- getSmoothed(fit.bb, nsim = 1e4, CI = 0.95, save.draws=TRUE)

# construct a simple population weight data frame with equal weights
weight.region &lt;- expand.grid(region = unique(counts.all$region), 
						 years = periods)
weight.region$proportion &lt;- 0.25

# construct a simple national estimates
national &lt;- data.frame(years = periods, 
				   est = seq(0.27, 0.1, length = 7), 
				   sd = runif(7, 0.01, 0.03))

 # benchmarking
est.bb.bench &lt;- Benchmark(est.bb, national, weight.region = weight.region, 
						estVar = "est", sdVar = "sd", timeVar = "years")

# Sanity check: Benchmarking comparison
compare &lt;- national
compare$before &lt;- NA
compare$after &lt;- NA
for(i in 1:dim(compare)[1]){
	weights &lt;- subset(weight.region, years == national$years[i])
	sub &lt;- subset(est.bb$overall, years == national$years[i])
	sub &lt;- merge(sub, weights)
	sub.bench &lt;- subset(est.bb.bench$overall, years == national$years[i])
	sub.bench &lt;- merge(sub.bench, weights)
	compare$before[i] &lt;- sum(sub$proportion * sub$median)
	compare$after[i] &lt;- sum(sub.bench$proportion * sub.bench$median)
}
plot(compare$est, compare$after, col = 2, pch = 10,
		 xlim = range(c(compare$est, compare$before, compare$after)),
		 ylim = range(c(compare$est, compare$before, compare$after)),
		 xlab = "External national estimates", 
		 ylab = "Weighted posterior median after benchmarking",
    main = "Sanity check: weighted average of area medians")
points(compare$est, compare$before)
abline(c(0, 1))
legend("topleft", c("Before benchmarking", "After benchmarking"), pch = c(1, 10), col = c(1, 2))

#  construct a simple national estimates
national &lt;- data.frame(years = periods, 
					   est = seq(0.22, 0.1, length = 7), 
					   sd = runif(7, 0.01, 0.03))
# national does not need to have all years
national_sub &lt;- national[1:3,]

# benchmarking
est.bb.bench &lt;- Benchmark(est.bb, national_sub, 
						weight.region = weight.region, 
						estVar = "est", sdVar = "sd", timeVar = "years")

# Sanity check: only benchmarked for three periods
compare &lt;- national
compare$before &lt;- NA
compare$after &lt;- NA
for(i in 1:dim(compare)[1]){
	weights &lt;- subset(weight.region, years == national$years[i])
	sub &lt;- subset(est.bb$overall, years == national$years[i])
	sub &lt;- merge(sub, weights)
	sub.bench &lt;- subset(est.bb.bench$overall, years == national$years[i])
	sub.bench &lt;- merge(sub.bench, weights)
	compare$before[i] &lt;- sum(sub$proportion * sub$median)
	compare$after[i] &lt;- sum(sub.bench$proportion * sub.bench$median)
}
plot(compare$est, compare$after, col = 2, pch = 10,
		 xlim = range(c(compare$est, compare$before, compare$after)),
		 ylim = range(c(compare$est, compare$before, compare$after)),
		 xlab = "External national estimates", 
		 ylab = "Weighted posterior median after benchmarking",
    main = "Sanity check: weighted average of area medians")
points(compare$est, compare$before)
abline(c(0, 1))
legend("topleft", c("Before benchmarking", "After benchmarking"), pch = c(1, 10), col = c(1, 2))

#  Another extreme benchmarking example, where almost all weights in central region
weight.region$proportion &lt;- 0.01
weight.region$proportion[weight.region$region == "central"] &lt;- 0.97
# benchmarking
est.bb.bench &lt;- Benchmark(est.bb, national, weight.region = weight.region, 
					estVar = "est", sdVar = "sd", timeVar = "years")
# It can be seen the central region are pulled to the national benchmark
plot(national$est, 
	 subset(est.bb.bench$overall, region == "central")$mean,
	 col = 2, pch = 10, xlab = "External national estimates", 
	 ylab = "Central region estimates") 
points(national$est, 
	 subset(est.bb$overall, region == "central")$mean) 
legend("topleft", c("Before benchmarking", "After benchmarking"), pch = c(1, 10),  col = c(1, 2))
abline(c(0, 1))

# Example with the MH method
# Benchmarking with MH should be applied when customized priors are 
#  specified for fixed effects when fitting the model
fit.bb.new  &lt;- smoothCluster(data = counts.all, Amat = DemoMap$Amat, 
				family = "betabinomial",
				year.label = periods, 
				survey.effect = TRUE, 
				control.fixed = list(
					mean=list(`age.intercept0:1`=-4, 
						       `age.intercept1-11:1`=-5,
						       `age.intercept12-23:1`=-8,
						       `age.intercept24-35:1`=-9,
						       `age.intercept36-47:1`=-10,
						       `age.intercept48-59:1`=-11), 
					prec=list(`age.intercept0:1`=10, 
						       `age.intercept1-11:1`=10,
						       `age.intercept12-23:1`=10,
						       `age.intercept24-35:1`=10,
						       `age.intercept36-47:1`=10,
						       `age.intercept48-59:1`=10)))
est.bb.new &lt;- getSmoothed(fit.bb.new, nsim = 10000, CI = 0.95, save.draws=TRUE)

#  construct a simple national estimates
national &lt;- data.frame(years = periods, 
					   est = seq(0.22, 0.1, length = 7), 
					   sd = runif(7, 0.01, 0.03))
weight.region &lt;- expand.grid(region = unique(counts.all$region), 
						 years = periods)
weight.region$proportion &lt;- 0.25					   
est.bb.bench.MH &lt;- Benchmark(est.bb.new, national, 
	weight.region = weight.region, 
	estVar = "est", sdVar = "sd", timeVar = "years",
	method = "MH")

compare &lt;- national
compare$before &lt;- NA
compare$after &lt;- NA
for(i in 1:dim(compare)[1]){
	weights &lt;- subset(weight.region, years == national$years[i])
	sub &lt;- subset(est.bb.new$overall, years == national$years[i])
	sub &lt;- merge(sub, weights)
	sub.bench &lt;- subset(est.bb.bench.MH$overall, years == national$years[i])
	sub.bench &lt;- merge(sub.bench, weights)
	compare$before[i] &lt;- sum(sub$proportion * sub$median)
	compare$after[i] &lt;- sum(sub.bench$proportion * sub.bench$median)
}
plot(compare$est, compare$after, col = 2, pch = 10,
		 xlim = range(c(compare$est, compare$before, compare$after)),
		 ylim = range(c(compare$est, compare$before, compare$after)),
		 xlab = "External national estimates", 
		 ylab = "Weighted posterior median after benchmarking",
    main = "Sanity check: weighted average of area medians")
points(compare$est, compare$before)
abline(c(0, 1))
legend("topleft", c("Before benchmarking", "After benchmarking"), pch = c(1, 10), col = c(1, 2))

##  ------------------------------------------ ##
##     Benchmarking with smoothDirect output
##  ------------------------------------------ ##
years &lt;- levels(DemoData[[1]]$time)
# obtain direct estimates
data_multi &lt;- getDirectList(births = DemoData, years = years,
                        regionVar = "region",  timeVar = "time", clusterVar = "~clustid+id",
                        ageVar = "age", weightsVar = "weights", geo.recode = NULL)
data &lt;- aggregateSurvey(data_multi)
#  subnational model
years.all &lt;- c(years, "15-19")
fit2 &lt;- smoothDirect(data = data, Amat = DemoMap$Amat,
                 year.label = years.all, year.range = c(1985, 2019),
                 time.model = "rw2", m = 5, type.st = 4)
out2a &lt;- getSmoothed(fit2, joint = TRUE, nsim = 1e5, save.draws = TRUE)

##
## Benchmarking for yearly estimates
##
weight.region &lt;- expand.grid(region = unique(data$region[data$region != "All"]),
                             years = 1985:2019)
weight.region$proportion &lt;- 0.25
# construct a simple national estimates
national &lt;- data.frame(years = 1985:2019,
                       est = seq(0.25, 0.15, length = 35),
                       sd = runif(35, 0.03, 0.05))
# Benchmarking to national estimates on the yearly scale
out2b &lt;- Benchmark(out2a, national, weight.region = weight.region,
                          estVar = "est", sdVar = "sd", timeVar = "years")
plot(out2a$overall)  
plot(out2b$overall) 

# combine the point estimate and compare with the benchmark values
national.est &lt;- aggregate(mean ~ years, 
   data = out2a$overall[out2a$overall$is.yearly, ], FUN = mean)
national.est.bench &lt;- aggregate(mean ~ years, 
   data = out2b$overall[out2b$overall$is.yearly, ], FUN = mean)

plot(national$est, national.est$mean,  
		 xlim = range(c(national$est, national.est$mean, national.est.bench$mean)),
		 ylim = range(c(national$est, national.est$mean, national.est.bench$mean)),
		 xlab = "External national estimates", 
		 ylab = "Weighted posterior median after benchmarking",
    main = "Sanity check: weighted average of area means")
points(national$est, national.est.bench$mean, col = 2, pch = 10)
abline(c(0, 1))
legend("topleft", c("Before benchmarking", "After benchmarking"), pch = c(1, 10), col = c(1, 2))



##
## Benchmarking for period estimates
##
weight.region &lt;- expand.grid(region = unique(data$region[data$region != "All"]),
                             years = years.all)
weight.region$proportion &lt;- 0.25
# construct a simple national estimates
national &lt;- data.frame(years = years.all,
                       est = seq(0.25, 0.15, len = 7),
                       sd = runif(7, 0.01, 0.03))
# Benchmarking to national estimates on the period scale
out2c &lt;- Benchmark(out2a, national, weight.region = weight.region,
                          estVar = "est", sdVar = "sd", timeVar = "years")
plot(out2a$overall)
plot(out2c$overall)

# combine the point estimate and compare with the benchmark values
national.est &lt;- aggregate(mean ~ years, 
			data = out2a$overall[!out2a$overall$is.yearly, ], FUN = mean)
national.est.bench &lt;- aggregate(mean ~ years, 
			data = out2c$overall[!out2b$overall$is.yearly, ], FUN = mean)

plot(national$est, national.est$mean,  
		 xlim = range(c(national$est, national.est$mean, national.est.bench$mean)),
		 ylim = range(c(national$est, national.est$mean, national.est.bench$mean)),
		 xlab = "External national estimates", 
		 ylab = "Weighted posterior median after benchmarking",
    main = "Sanity check: weighted average of area means")
points(national$est, national.est.bench$mean, col = 2, pch = 10)
abline(c(0, 1))
legend("topleft", c("Before benchmarking", "After benchmarking"), pch = c(1, 10), col = c(1, 2))


 
## End(Not run)
</code></pre>

<hr>
<h2 id='BRFSS'>The BRFSS dataset</h2><span id='topic+BRFSS'></span>

<h3>Description</h3>

<p>The Behavioral Risk Factor Surveillance System (BRFSS) is an annual telephone health survey conducted by the Centers for Disease Control and Prevention (CDC) that tracks health conditions and risk behaviors in the United States and its territories since 1984. This BRFSS dataset contains 16124 observations. The <code>diab2</code> variable is the binary indicator of Type II diabetes, <code>strata</code> is the strata indicator and <code>rwt_llcp</code> is the final design weight. Records with missing HRA code or diabetes status are removed from this dataset. See <a href="https://www.cdc.gov/brfss/annual_data/2013/pdf/Weighting_Data.pdf">https://www.cdc.gov/brfss/annual_data/2013/pdf/Weighting_Data.pdf</a> for more details of the weighting procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(BRFSS)
</code></pre>


<h3>Format</h3>

<p>A data.frame of 26 variables.
</p>


<h3>References</h3>

<p>Washington State Department of Health, Center for Health Statistics. Behavioral Risk Factor Surveillance System, supported in part by the Centers for Disease Control and Prevention. Corporative Agreement U58/DP006066-01 (2015).
</p>

<hr>
<h2 id='calibrateByRegion'>Calibrate the point level totals so their sum matches the regional totals</h2><span id='topic+calibrateByRegion'></span>

<h3>Description</h3>

<p>Calibrate/normalize the point level totals so their sum matches the
regional totals. Technically, the totals can be at any level smaller
than the region level specified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calibrateByRegion(point.totals, point.regions, regions, region.totals)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calibrateByRegion_+3A_point.totals">point.totals</code></td>
<td>
<p>Vector of point level totals that will be calibrated/normalized</p>
</td></tr>
<tr><td><code id="calibrateByRegion_+3A_point.regions">point.regions</code></td>
<td>
<p>Vector of regions associated with each point</p>
</td></tr>
<tr><td><code id="calibrateByRegion_+3A_regions">regions</code></td>
<td>
<p>Vector of region names</p>
</td></tr>
<tr><td><code id="calibrateByRegion_+3A_region.totals">region.totals</code></td>
<td>
<p>Vector of desired region level totals associated with <code>regions</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a>
</p>


<h3>Value</h3>

<p>A vector of same length as point.totals and point.regions containing
the calibrated/normalized point totals that sum to the correct regional totals
</p>
<p>Vector of updated point level totals, calibrated to match region totals
</p>


<h3>Author(s)</h3>

<p>John Paige
</p>


<h3>Examples</h3>

<pre><code class='language-R'>point.totals = c(1, 1, 1, 2)
point.regions = c("a", "a", "b", "b")
region.totals = c(10, 20)
regions = c("a", "b")
calibrateByRegion(point.totals, point.regions, regions, region.totals)

</code></pre>

<hr>
<h2 id='changeRegion'>Map region names to a common set.</h2><span id='topic+changeRegion'></span>

<h3>Description</h3>

<p>Map region names to a common set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>changeRegion(data, Bmat, regionVar = "region")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="changeRegion_+3A_data">data</code></td>
<td>
<p>Preprocessed data</p>
</td></tr>
<tr><td><code id="changeRegion_+3A_bmat">Bmat</code></td>
<td>
<p>Matrix of changes. Each row corresponds to a region name possibly in the data files, and each column corresponds to a region after mapping. The values in the matrix are binary. The row names and column names need to be specified to the region names.</p>
</td></tr>
<tr><td><code id="changeRegion_+3A_regionvar">regionVar</code></td>
<td>
<p>String indicating the region variable. Defaults to 'region'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data after changing region names
</p>


<h3>Author(s)</h3>

<p>Zehang Richard Li
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct a small test data
testdata &lt;- data.frame(region = c("north", "south", "east",
 "south", "east"), index = c(1:5))

# Construct a changing rule: combining south and east
Bmat &lt;- matrix(c(1, 0, 0, 0, 1, 1), 3, 2)
colnames(Bmat) &lt;- c("north", "south and east")
rownames(Bmat) &lt;- c("north", "south", "east")
print(Bmat)

# New data after transformation
test &lt;- changeRegion(testdata, Bmat, "region")
print(test)
</code></pre>

<hr>
<h2 id='compareEstimates'>Plot heatmap comparing pairwise posterior exceedence probabilities for svysae object</h2><span id='topic+compareEstimates'></span>

<h3>Description</h3>

<p>Plot heatmap comparing pairwise posterior exceedence probabilities for svysae object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compareEstimates(x, posterior.sample = NULL, title = NULL, return.plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compareEstimates_+3A_x">x</code></td>
<td>
<p>an object in the S3 class of svysae, fhModel, or clusterModel. Plots are created for all models in this object.</p>
</td></tr>
<tr><td><code id="compareEstimates_+3A_posterior.sample">posterior.sample</code></td>
<td>
<p>Matrix of posteriors samples of area level quantities with one row for each area and one column for each sample. This argument may be specified to only provide a heatmap for the desired samples.</p>
</td></tr>
<tr><td><code id="compareEstimates_+3A_title">title</code></td>
<td>
<p>Optional parameter changing the title of the plot</p>
</td></tr>
<tr><td><code id="compareEstimates_+3A_return.plot">return.plot</code></td>
<td>
<p>Logical indicator for whether the ggplot object is returned</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot containing heat map of pairwise comparisons
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(DemoData2)
data(DemoMap2)
library(survey)
des0 &lt;- svydesign(ids = ~clustid+id, strata = ~strata,
                  weights = ~weights, data = DemoData2, nest = TRUE)
Xmat &lt;- aggregate(age~region, data = DemoData2, FUN = mean)

cts.res &lt;- smoothArea(tobacco.use ~ 1,
                      domain = ~region,
                      design = des0,
                      adj.mat = DemoMap2$Amat, 
                      pc.u = 1,
                      pc.alpha = 0.01,
                      pc.u.phi = 0.5,
                      pc.alpha.phi = 2/3,
                      return.samples = TRUE)
compareEstimates(cts.res)

## End(Not run)
</code></pre>

<hr>
<h2 id='DemoData'>Simulated child mortality person-month dataset.</h2><span id='topic+DemoData'></span>

<h3>Description</h3>

<p>A small simulated dataset with 4 regions and 5 survey years. This  does not represent
any real country's data and are based on a subset of the model dataset
provided by DHS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(DemoData)
</code></pre>


<h3>Format</h3>

<p>A list of with five components, named by survey year.
</p>


<h3>Source</h3>

<p><a href="https://dhsprogram.com/data/model-datasets.cfm">https://dhsprogram.com/data/model-datasets.cfm</a>
</p>

<hr>
<h2 id='DemoData2'>Simulated dataset for prevalence mapping.</h2><span id='topic+DemoData2'></span>

<h3>Description</h3>

<p>A small fake dataset with 8 regions and two response variables: age and tobacco.use. This  does not represent
any real country's data and are based on a subset of the model dataset
provided by DHS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(DemoData2)
</code></pre>


<h3>Format</h3>

<p>A data.frame of 7 variables.
</p>


<h3>Source</h3>

<p><a href="https://dhsprogram.com/data/model-datasets.cfm">https://dhsprogram.com/data/model-datasets.cfm</a>
</p>

<hr>
<h2 id='DemoMap'>Uganda Admin-1 region map for illustration purpose</h2><span id='topic+DemoMap'></span>

<h3>Description</h3>

<p>Shapefiles are from 1995 Uganda Admin 1 regions provided by DHS, but the data do not represent real information about any country.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(DemoMap)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 2.
</p>


<h3>Details</h3>


<ul>
<li><p> geo. Geographic map files
</p>
</li>
<li><p> Amat. Adjacency matrix for regions
</p>
</li></ul>



<h3>Source</h3>

<p><a href="https://spatialdata.dhsprogram.com/boundaries/#view=table&amp;countryId=UG">https://spatialdata.dhsprogram.com/boundaries/#view=table&amp;countryId=UG</a>
</p>

<hr>
<h2 id='DemoMap2'>Kenya Admin-1 region map for illustration purpose</h2><span id='topic+DemoMap2'></span>

<h3>Description</h3>

<p>Shapefiles are from 2014 Kenya Admin 1 regions provided by DHS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(DemoMap2)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 2.
</p>


<h3>Details</h3>


<ul>
<li><p> geo Geographic map files
</p>
</li>
<li><p> Amat Adjacency matrix for regions
</p>
</li></ul>



<h3>Source</h3>

<p><a href="https://spatialdata.dhsprogram.com/boundaries/#view=table&amp;countryId=KE">https://spatialdata.dhsprogram.com/boundaries/#view=table&amp;countryId=KE</a>
</p>

<hr>
<h2 id='expit'>Expit transformation</h2><span id='topic+expit'></span>

<h3>Description</h3>

<p>Expit transformation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expit(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="expit_+3A_x">x</code></td>
<td>
<p>data</p>
</td></tr>
</table>


<h3>Value</h3>

<p>expit of x
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- .5
expit(x)

</code></pre>

<hr>
<h2 id='fitGeneric'>Fit space-time smoothing models for a binary outcome from complex surveys.</h2><span id='topic+fitGeneric'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a>
</p>
<p><code>fitGeneric()</code> was renamed to <code>smoothSurvey()</code> to create a more
consistent API.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitGeneric(...)
</code></pre>

<hr>
<h2 id='fitINLA'>Smoothed direct estimates for mortality rates</h2><span id='topic+fitINLA'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a>
</p>
<p><code>fitINLA()</code> was renamed to <code>smoothDirect()</code> to create a more
consistent API.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitINLA(...)
</code></pre>

<hr>
<h2 id='fitINLA2'>Cluster-level space-time smoothing models for mortality rates</h2><span id='topic+fitINLA2'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a>
</p>
<p><code>fitINLA2()</code> was renamed to <code>smoothCluster()</code> to create a more
consistent API.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitINLA2(...)
</code></pre>

<hr>
<h2 id='getAdjusted'>Adjust direct estimates and their associated variances</h2><span id='topic+getAdjusted'></span>

<h3>Description</h3>

<p>Adjust direct estimates and their associated variances
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getAdjusted(
  data,
  ratio,
  time = "years",
  region = "region",
  est = "mean",
  logit = "logit.est",
  logit.var = "var.est",
  logit.prec = "logit.prec",
  logit.lower = "lower",
  logit.upper = "upper",
  prob.lower = NULL,
  prob.upper = NULL,
  adj = "ratio",
  verbose = FALSE,
  lower = NULL,
  upper = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getAdjusted_+3A_data">data</code></td>
<td>
<p>data frame of the adjusted estimates and the associated uncertainties, see the arguments below for specific columns.</p>
</td></tr>
<tr><td><code id="getAdjusted_+3A_ratio">ratio</code></td>
<td>
<p>the ratio of unadjusted mortality rates to the true mortality rates. It can be either a data frame with the following three columns (region, time, and adj) if adjustment factor differ by region; or a data frame with the following two columns (time and adj) if adjustment factor only varies over time. The column names specifying region, time, and adjustment are specified by the arguments in the function call.</p>
</td></tr>
<tr><td><code id="getAdjusted_+3A_time">time</code></td>
<td>
<p>the column name for time in the data and adjustment ratio.</p>
</td></tr>
<tr><td><code id="getAdjusted_+3A_region">region</code></td>
<td>
<p>the column name for region in the data  and adjustment ratio.</p>
</td></tr>
<tr><td><code id="getAdjusted_+3A_est">est</code></td>
<td>
<p>the column name for unadjusted mortality rates in the data</p>
</td></tr>
<tr><td><code id="getAdjusted_+3A_logit">logit</code></td>
<td>
<p>the column name for the logit of the unadjusted mortality rates in the data</p>
</td></tr>
<tr><td><code id="getAdjusted_+3A_logit.var">logit.var</code></td>
<td>
<p>the column name for the variance of the logit of the unadjusted mortality rates in the data</p>
</td></tr>
<tr><td><code id="getAdjusted_+3A_logit.prec">logit.prec</code></td>
<td>
<p>the column name for the precision of the logit of the unadjusted mortality rates in the data</p>
</td></tr>
<tr><td><code id="getAdjusted_+3A_logit.lower">logit.lower</code></td>
<td>
<p>the column name for the 95% lower bound of the logit of the unadjusted mortality rates in the data</p>
</td></tr>
<tr><td><code id="getAdjusted_+3A_logit.upper">logit.upper</code></td>
<td>
<p>the column name for the 95% lower bound of the logit of the unadjusted mortality rates in the data</p>
</td></tr>
<tr><td><code id="getAdjusted_+3A_prob.lower">prob.lower</code></td>
<td>
<p>the column name for the 95% lower bound of the unadjusted mortality rates in the data. If this is provided instead of logit.lower, the logit scale lower bound will be created.</p>
</td></tr>
<tr><td><code id="getAdjusted_+3A_prob.upper">prob.upper</code></td>
<td>
<p>the column name for the 95% lower bound of the unadjusted mortality rates in the data. if this is provided instead of logit.upper, the logit scale upper bound will be created.</p>
</td></tr>
<tr><td><code id="getAdjusted_+3A_adj">adj</code></td>
<td>
<p>the column name for the adjustment ratio</p>
</td></tr>
<tr><td><code id="getAdjusted_+3A_verbose">verbose</code></td>
<td>
<p>logical indicator for whether to print out unadjusted row index</p>
</td></tr>
<tr><td><code id="getAdjusted_+3A_lower">lower</code></td>
<td>
<p>previous argument name for prob.lower. Will be removed in the next update</p>
</td></tr>
<tr><td><code id="getAdjusted_+3A_upper">upper</code></td>
<td>
<p>previous argument name for prob.upper. Will be removed in the next update</p>
</td></tr>
</table>


<h3>Value</h3>

<p>adjusted dataset of the same columns.
</p>


<h3>Author(s)</h3>

<p>Zehang Richard Li
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
years &lt;- levels(DemoData[[1]]$time)

# obtain direct estimates
data &lt;- getDirectList(births = DemoData, 
years = years,  
regionVar = "region", timeVar = "time", 
clusterVar = "~clustid+id", 
ageVar = "age", weightsVar = "weights", 
geo.recode = NULL)
# obtain direct estimates
data_multi &lt;- getDirectList(births = DemoData, years = years,
  regionVar = "region",  timeVar = "time", clusterVar = "~clustid+id",
  ageVar = "age", weightsVar = "weights", geo.recode = NULL)
data &lt;- aggregateSurvey(data_multi)

# randomly simulate adjustment factor
adj &lt;- expand.grid(region = unique(data$region), years = years)
adj$ratio &lt;- runif(dim(adj)[1], min = 0.5, max = 0.8)
data.adj &lt;- getAdjusted(data = data, ratio = adj)
 
## End(Not run)
</code></pre>

<hr>
<h2 id='getAmat'>Extract adjacency matrix from the map</h2><span id='topic+getAmat'></span>

<h3>Description</h3>

<p>Extract adjacency matrix from the map
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getAmat(geo, names)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getAmat_+3A_geo">geo</code></td>
<td>
<p>SpatialPolygonsDataFrame of the map</p>
</td></tr>
<tr><td><code id="getAmat_+3A_names">names</code></td>
<td>
<p>character vector of region ids to be added to the neighbours list</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Spatial djacency matrix.
</p>


<h3>Author(s)</h3>

<p>Zehang Richard Li
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(DemoMap) 
mat &lt;- getAmat(geo = DemoMap$geo, names = DemoMap$geo$REGNAME)
mat
DemoMap$Amat

## End(Not run) 
</code></pre>

<hr>
<h2 id='getAreaName'>Determines which administrative areas contain the given points</h2><span id='topic+getAreaName'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getAreaName(
  pts,
  shapefile,
  areaNameVar = "NAME_1",
  delta = 0.05,
  mean.neighbor = 50,
  max.bytes = 3 * 2^30
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getAreaName_+3A_pts">pts</code></td>
<td>
<p>2 column matrix of lon/lat coordinates</p>
</td></tr>
<tr><td><code id="getAreaName_+3A_shapefile">shapefile</code></td>
<td>
<p>A SpatialPolygonsDataFrame object</p>
</td></tr>
<tr><td><code id="getAreaName_+3A_areanamevar">areaNameVar</code></td>
<td>
<p>The column name in <code>slot(shapefile, "data")</code>
corresponding to the area level of interest</p>
</td></tr>
<tr><td><code id="getAreaName_+3A_delta">delta</code></td>
<td>
<p>Argument passed to fields::fields.rdist.near in fields package</p>
</td></tr>
<tr><td><code id="getAreaName_+3A_mean.neighbor">mean.neighbor</code></td>
<td>
<p>Argument passed to fields::fields.rdist.near in fields
package</p>
</td></tr>
<tr><td><code id="getAreaName_+3A_max.bytes">max.bytes</code></td>
<td>
<p>Maximum allowed memory in bytes (default is 3Gb). Determines
whether to call fields::fields.rdist.near which saves memory but requires
delta and mean.neighbor inputs to be specified for fields::fields.rdist.near</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For any points not in an area, they are assigned the nearest area using
fields::fields.rdist.near or fields::rdist depending on the number of points
and the maximum memory in bytes with a warning.
</p>
<p>delta and mean.neighbor arguments only used when some points
are not in areas, perhaps due to inconsistencies in shapefiles.
</p>


<h3>Value</h3>

<p>A list of area IDs, area names, whether or not
points are in multiple areas, and whether or not points
are in no areas and assigned to the nearest one.
</p>


<h3>Author(s)</h3>

<p>John Paige
</p>


<h3>See Also</h3>

<p><code><a href="#topic+projKenya">projKenya</a></code>, <code><a href="fields.html#topic+fields.rdist.near">fields.rdist.near</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# download Kenya GADM shapefiles from SUMMERdata github repository
githubURL &lt;- "https://github.com/paigejo/SUMMERdata/blob/main/data/kenyaMaps.rda?raw=true"
download.file(githubURL,"kenyaMaps.rda")

# load it in
load("kenyaMaps.rda")

# use the shapefile data to see what Admin1 and 2 areas the 
# points (0, 37) and (0.5, 38) are in
# (these are longitude/latitude coordinates)
pts = cbind(c(37, 38), c(0, .5))
head(slot(adm1, "data"))
admin1Areas = getAreaName(pts, adm1, "NAME_1")
admin2Areas = getAreaName(pts, adm2, "NAME_2")

## End(Not run)

</code></pre>

<hr>
<h2 id='getBirths'>Reformat full birth records into person-month format</h2><span id='topic+getBirths'></span>

<h3>Description</h3>

<p>Reformat full birth records into person-month format
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getBirths(
  filepath = NULL,
  data = NULL,
  surveyyear = NA,
  variables = c("caseid", "v001", "v002", "v004", "v005", "v021", "v022", "v023", "v024",
    "v025", "v139", "bidx"),
  strata = c("v024", "v025"),
  dob = "b3",
  alive = "b5",
  age = "b7",
  age.truncate = 24,
  date.interview = "v008",
  month.cut = c(1, 12, 24, 36, 48, 60),
  year.cut = seq(1980, 2020, by = 5),
  min.last.period = 0,
  cmc.adjust = 0,
  compact = FALSE,
  compact.by = c("v001", "v024", "v025", "v005")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getBirths_+3A_filepath">filepath</code></td>
<td>
<p>file path of raw .dta file from DHS. Only used when data frame is not provided in the function call.</p>
</td></tr>
<tr><td><code id="getBirths_+3A_data">data</code></td>
<td>
<p>data frame of a DHS survey</p>
</td></tr>
<tr><td><code id="getBirths_+3A_surveyyear">surveyyear</code></td>
<td>
<p>year of survey. Observations after this year will be excluded from the analysis.</p>
</td></tr>
<tr><td><code id="getBirths_+3A_variables">variables</code></td>
<td>
<p>vector of variables to be used in obtaining the person-month files. The variables correspond the the DHS recode manual VI. For early DHS data, the variable names may need to be changed.</p>
</td></tr>
<tr><td><code id="getBirths_+3A_strata">strata</code></td>
<td>
<p>vector of variable names used for strata. If a single variable is specified, then that variable will be used as strata indicator If multiple variables are specified, the interaction of these variables will be used as strata indicator.</p>
</td></tr>
<tr><td><code id="getBirths_+3A_dob">dob</code></td>
<td>
<p>variable name for the date of birth.</p>
</td></tr>
<tr><td><code id="getBirths_+3A_alive">alive</code></td>
<td>
<p>variable name for the indicator of whether child was alive or dead at the time of interview. It should be factor or character variable with levels &quot;no&quot; or &quot;yes&quot;. Other coding scheme will not be recognized and can lead to errors.</p>
</td></tr>
<tr><td><code id="getBirths_+3A_age">age</code></td>
<td>
<p>variable name for the age at death of the child in completed months.</p>
</td></tr>
<tr><td><code id="getBirths_+3A_age.truncate">age.truncate</code></td>
<td>
<p>the smallest age in months where only full years are reported. The default value is 24, which corresponds to the DHS practice of recording only age in full years for children over 2 years old. That is, for children with age starting from 24 months old, we assume the age variable reported in multiples of 12 are truncated from its true value. For example, children between age 24 to 35 months are all recorded as 24. To account for the truncation of age, 5 months are added to all ages recorded in multiples of 12 starting from 24. To avoid this adjustment, set this argument to NA.</p>
</td></tr>
<tr><td><code id="getBirths_+3A_date.interview">date.interview</code></td>
<td>
<p>variable name for the date of interview.</p>
</td></tr>
<tr><td><code id="getBirths_+3A_month.cut">month.cut</code></td>
<td>
<p>the cutoff of each bins of age group in the unit of months. Default values are 1, 12, 24, 36, 48, and 60, representing the age groups (0, 1), [1, 12), [12, 24), ..., [48, 60).</p>
</td></tr>
<tr><td><code id="getBirths_+3A_year.cut">year.cut</code></td>
<td>
<p>The cutoff of each bins of time periods, including both boundaries. Default values are 1980, 1985, ..., 2020, representing the time periods 80-84, 85-89, ..., 15-19. Notice that if each bin contains one year, the last year in the output is max(year.cut)-1. For example, if year.cut = 1980:2020, the last year in the output is 2019.</p>
</td></tr>
<tr><td><code id="getBirths_+3A_min.last.period">min.last.period</code></td>
<td>
<p>The cutoff for how many years the last period must contain in order to be counted in the output. For example, if the last period is 2015-2019 and min.last.period = 3, person-months for the last period will only be returned if survey contains observations at least in 2017. This argument avoids the situation that estimates for the last period being based on only a small number of initial years, if applicable. Default to be 0.</p>
</td></tr>
<tr><td><code id="getBirths_+3A_cmc.adjust">cmc.adjust</code></td>
<td>
<p>number of months to add to the recorded month in the dataset. Some DHS surveys does not use Gregorian calendar (the calendar used in most of the world). For example, the Ethiopian calendar is 92 months behind the Gregorian calendar in general. Then we can set cmc.adjust to 92, which adds 92 months to all dates in the dataset, effectively transforming the Ethiopian calendar to the Gregorian calendar.</p>
</td></tr>
<tr><td><code id="getBirths_+3A_compact">compact</code></td>
<td>
<p>logical indicator of whether the compact format is returned. In the compact output, person months are aggregated by cluster, age, and time. Total number of person months and deaths in each group are returned instead of the raw person-months.</p>
</td></tr>
<tr><td><code id="getBirths_+3A_compact.by">compact.by</code></td>
<td>
<p>vector of variables to summarize the compact form by.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns a new data frame where each row indicate a person-month, with the additional variables specified in the function argument.
</p>


<h3>Author(s)</h3>

<p>Zehang Richard Li, Bryan Martin, Laina Mercer
</p>


<h3>References</h3>

<p>Li, Z., Hsiao, Y., Godwin, J., Martin, B. D., Wakefield, J., Clark, S. J., &amp; with support from the United Nations Inter-agency Group for Child Mortality Estimation and its technical advisory group. (2019). <em>Changes in the spatial distribution of the under-five mortality rate: Small-area analysis of 122 DHS surveys in 262 subregions of 35 countries in Africa.</em> PloS one, 14(1), e0210645.
</p>
<p>Mercer, L. D., Wakefield, J., Pantazis, A., Lutambi, A. M., Masanja, H., &amp; Clark, S. (2015). <em>Space-time smoothing of complex survey data: small area estimation for child mortality.</em> The annals of applied statistics, 9(4), 1889.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# my_fp &lt;- "/myExampleFilepath/surveyData.DTA"
# DemoData &lt;- getBirths(filepath = my_fp, surveyyear = 2015) 

## End(Not run)

</code></pre>

<hr>
<h2 id='getCounts'>Aggregate person-month data into counts and totals by groups.</h2><span id='topic+getCounts'></span>

<h3>Description</h3>

<p>Aggregate person-month data into counts and totals by groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getCounts(data, variables, by, ignore = NULL, addtotal = TRUE, drop = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getCounts_+3A_data">data</code></td>
<td>
<p>dataset in person-month format</p>
</td></tr>
<tr><td><code id="getCounts_+3A_variables">variables</code></td>
<td>
<p>a character vector of the variables to aggregate</p>
</td></tr>
<tr><td><code id="getCounts_+3A_by">by</code></td>
<td>
<p>a character vector of columns that specifies which groups to aggregate by.</p>
</td></tr>
<tr><td><code id="getCounts_+3A_ignore">ignore</code></td>
<td>
<p>list of conditions not to impute 0. If left unspecified, any group levels not in the data will be imputed to have 0 counts.</p>
</td></tr>
<tr><td><code id="getCounts_+3A_addtotal">addtotal</code></td>
<td>
<p>logical indicator of whether to add a column of group total counts.</p>
</td></tr>
<tr><td><code id="getCounts_+3A_drop">drop</code></td>
<td>
<p>logical indicator of whether to drop all rows with total = 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame of the ggregated counts.
</p>


<h3>Author(s)</h3>

<p>Zehang Richard Li
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 
# a toy dataset with 4 time periods but one missing in data
timelist &lt;- factor(1:4)
data = data.frame(died = c(0,0,0,1,1,0,0), 
					area = c(rep(c("A", "B"), 3), "A"), 
					time = timelist[c(1,1,2,3,3,3,3)])
data
# without ignore argument, all levels will be imputed
getCounts(data, variables = "died", by = c("area", "time"))

# ignoring time = 4, the ignored level will not be imputed (but still in the output)
getCounts(data, variables = "died", by = c("area", "time"), 
			ignore = list("time"=c(4)) )

 
</code></pre>

<hr>
<h2 id='getDiag'>Extract posterior summaries of random effects</h2><span id='topic+getDiag'></span>

<h3>Description</h3>

<p>Extract posterior summaries of random effects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getDiag(
  fitted,
  inla_mod = deprecated(),
  field = c("space", "time", "spacetime")[1],
  CI = 0.95,
  draws = NULL,
  nsim = 1000,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getDiag_+3A_fitted">fitted</code></td>
<td>
<p>output from <code><a href="#topic+smoothDirect">smoothDirect</a></code> or <code><a href="#topic+smoothCluster">smoothCluster</a></code></p>
</td></tr>
<tr><td><code id="getDiag_+3A_inla_mod">inla_mod</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> replaced by <code>fitted</code>.</p>
</td></tr>
<tr><td><code id="getDiag_+3A_field">field</code></td>
<td>
<p>which random effects to plot. It can be one of the following: space, time, and spacetime.</p>
</td></tr>
<tr><td><code id="getDiag_+3A_ci">CI</code></td>
<td>
<p>Desired level of credible intervals</p>
</td></tr>
<tr><td><code id="getDiag_+3A_draws">draws</code></td>
<td>
<p>Posterior samples drawn from the fitted model. This argument allows the previously sampled draws (by setting save.draws to be TRUE) be used in new aggregation tasks.</p>
</td></tr>
<tr><td><code id="getDiag_+3A_nsim">nsim</code></td>
<td>
<p>number of simulations, only applicable for the cluster-level model space-time interaction terms when random slopes are included.</p>
</td></tr>
<tr><td><code id="getDiag_+3A_...">...</code></td>
<td>
<p>Unused arguments, for users with fitted object from the package before v1.0.0, arguments including Amat, year.label, and year.range can still be specified manually.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of diagnostic plots
</p>


<h3>Author(s)</h3>

<p>Zehang Richard Li
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  data(DemoMap)
  years &lt;- levels(DemoData[[1]]$time)
  
  # obtain direct estimates
  data &lt;- getDirectList(births = DemoData, 
  years = years,  
  regionVar = "region", timeVar = "time", 
  clusterVar = "~clustid+id", 
  ageVar = "age", weightsVar = "weights", 
  geo.recode = NULL)
  # obtain direct estimates
  data_multi &lt;- getDirectList(births = DemoData, years = years,
    regionVar = "region",  timeVar = "time", clusterVar = "~clustid+id",
    ageVar = "age", weightsVar = "weights", geo.recode = NULL)
  data &lt;- aggregateSurvey(data_multi)
  
  #  national model
  years.all &lt;- c(years, "15-19")
  fit1 &lt;- smoothDirect(data = data, geo = DemoMap$geo, Amat = DemoMap$Amat, 
    year.label = years.all, year.range = c(1985, 2019), 
    rw = 2, is.yearly=FALSE, m = 5)
random.time &lt;- getDiag(fit1, field = "time")
  random.space &lt;- getDiag(fit1, field = "space")
  random.spacetime &lt;- getDiag(fit1, field = "spacetime")

## End(Not run)

</code></pre>

<hr>
<h2 id='getDirect'>Obtain the Horvitz-Thompson direct estimates and standard errors using delta method for a single survey.</h2><span id='topic+getDirect'></span>

<h3>Description</h3>

<p>Obtain the Horvitz-Thompson direct estimates and standard errors using delta method for a single survey.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getDirect(
  births,
  years,
  regionVar = "region",
  timeVar = "time",
  clusterVar = "~v001+v002",
  ageVar = "age",
  weightsVar = "v005",
  Ntrials = NULL,
  geo.recode = NULL,
  national.only = FALSE,
  CI = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getDirect_+3A_births">births</code></td>
<td>
<p>A matrix child-month data from <code><a href="#topic+getBirths">getBirths</a></code></p>
</td></tr>
<tr><td><code id="getDirect_+3A_years">years</code></td>
<td>
<p>String vector of the year intervals used</p>
</td></tr>
<tr><td><code id="getDirect_+3A_regionvar">regionVar</code></td>
<td>
<p>Variable name for region in the input births data.</p>
</td></tr>
<tr><td><code id="getDirect_+3A_timevar">timeVar</code></td>
<td>
<p>Variable name for the time period indicator in the input births data.</p>
</td></tr>
<tr><td><code id="getDirect_+3A_clustervar">clusterVar</code></td>
<td>
<p>Variable name for cluster, typically '~v001 + v002'</p>
</td></tr>
<tr><td><code id="getDirect_+3A_agevar">ageVar</code></td>
<td>
<p>Variable name for age group. This variable need to be in the form of &quot;a-b&quot; where a and b are both ages in months. For example, &quot;1-11&quot; means age between 1 and 11 months, including both end points. An exception is age less than one month can be represented by &quot;0&quot; or &quot;0-0&quot;.</p>
</td></tr>
<tr><td><code id="getDirect_+3A_weightsvar">weightsVar</code></td>
<td>
<p>Variable name for sampling weights, typically 'v005'</p>
</td></tr>
<tr><td><code id="getDirect_+3A_ntrials">Ntrials</code></td>
<td>
<p>Variable for the total number of person-months if the input data (births) is in the compact form.</p>
</td></tr>
<tr><td><code id="getDirect_+3A_geo.recode">geo.recode</code></td>
<td>
<p>The recode matrix to be used if region name is not consistent across different surveys. See <code>changeRegion</code>.</p>
</td></tr>
<tr><td><code id="getDirect_+3A_national.only">national.only</code></td>
<td>
<p>Logical indicator to obtain only the national estimates</p>
</td></tr>
<tr><td><code id="getDirect_+3A_ci">CI</code></td>
<td>
<p>the desired confidence interval to calculate</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix of period-region summary of the Horvitz-Thompson direct estimates by region and time period specified in the argument, the standard errors using delta method for a single survey, the 95% confidence interval, and the logit of the estimates.
</p>


<h3>Author(s)</h3>

<p>Zehang Richard Li, Bryan Martin, Laina Mercer
</p>


<h3>References</h3>

<p>Li, Z., Hsiao, Y., Godwin, J., Martin, B. D., Wakefield, J., Clark, S. J., &amp; with support from the United Nations Inter-agency Group for Child Mortality Estimation and its technical advisory group. (2019). <em>Changes in the spatial distribution of the under-five mortality rate: Small-area analysis of 122 DHS surveys in 262 subregions of 35 countries in Africa.</em> PloS one, 14(1), e0210645.
</p>
<p>Mercer, L. D., Wakefield, J., Pantazis, A., Lutambi, A. M., Masanja, H., &amp; Clark, S. (2015). <em>Space-time smoothing of complex survey data: small area estimation for child mortality.</em> The annals of applied statistics, 9(4), 1889.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getDirectList">getDirectList</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(DemoData)
years &lt;- c("85-89", "90-94", "95-99", "00-04", "05-09", "10-14")
mean &lt;- getDirect(births = DemoData[[1]],  years = years, 
regionVar = "region", timeVar = "time", clusterVar = "~clustid+id", 
ageVar = "age", weightsVar = "weights", geo.recode = NULL)

## End(Not run)
</code></pre>

<hr>
<h2 id='getDirectList'>Obtain the Horvitz-Thompson direct estimates and standard errors using delta method for multiple surveys.</h2><span id='topic+getDirectList'></span>

<h3>Description</h3>

<p>Obtain the Horvitz-Thompson direct estimates and standard errors using delta method for multiple surveys.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getDirectList(
  births,
  years,
  regionVar = "region",
  timeVar = "time",
  clusterVar = "~v001+v002",
  ageVar = "age",
  weightsVar = "v005",
  Ntrials = NULL,
  geo.recode = NULL,
  national.only = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getDirectList_+3A_births">births</code></td>
<td>
<p>A list of child-month data from multiple surveys from <code><a href="#topic+getBirths">getBirths</a></code>. The name of the list is used as the identifier in the output.</p>
</td></tr>
<tr><td><code id="getDirectList_+3A_years">years</code></td>
<td>
<p>String vector of the year intervals used</p>
</td></tr>
<tr><td><code id="getDirectList_+3A_regionvar">regionVar</code></td>
<td>
<p>Variable name for region, typically 'v024', for older surveys might be 'v101'</p>
</td></tr>
<tr><td><code id="getDirectList_+3A_timevar">timeVar</code></td>
<td>
<p>Variable name for the time period indicator in the input births data.</p>
</td></tr>
<tr><td><code id="getDirectList_+3A_clustervar">clusterVar</code></td>
<td>
<p>Variable name for the IDs in the second-stage cluster sampling, typically '~v001 + v002', i.e., the cluster number and household number. When no cluster sampling design exists, this variable usually is the household ID.</p>
</td></tr>
<tr><td><code id="getDirectList_+3A_agevar">ageVar</code></td>
<td>
<p>Variable name for age group. This variable need to be in the form of &quot;a-b&quot; where a and b are both ages in months. For example, &quot;1-11&quot; means age between 1 and 11 months, including both end points. An exception is age less than one month can be represented by &quot;0&quot; or &quot;0-0&quot;.</p>
</td></tr>
<tr><td><code id="getDirectList_+3A_weightsvar">weightsVar</code></td>
<td>
<p>Variable name for sampling weights, typically 'v005'</p>
</td></tr>
<tr><td><code id="getDirectList_+3A_ntrials">Ntrials</code></td>
<td>
<p>Variable for the total number of person-months if the input data (births) is in the compact form.</p>
</td></tr>
<tr><td><code id="getDirectList_+3A_geo.recode">geo.recode</code></td>
<td>
<p>The recode matrix to be used if region name is not consistent across different surveys. See <code>changeRegion</code>.</p>
</td></tr>
<tr><td><code id="getDirectList_+3A_national.only">national.only</code></td>
<td>
<p>Logical indicator to obtain only the national estimates</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This is the extension to the <code><a href="#topic+getDirect">getDirect</a></code> function that returns estimates from multiple surveys. Additional columns in the output (survey and surveyYears) specify the estimates from different surveys.
</p>


<h3>Author(s)</h3>

<p>Zehang Richard Li, Bryan Martin, Laina Mercer
</p>


<h3>References</h3>

<p>Li, Z., Hsiao, Y., Godwin, J., Martin, B. D., Wakefield, J., Clark, S. J., &amp; with support from the United Nations Inter-agency Group for Child Mortality Estimation and its technical advisory group. (2019). <em>Changes in the spatial distribution of the under-five mortality rate: Small-area analysis of 122 DHS surveys in 262 subregions of 35 countries in Africa.</em> PloS one, 14(1), e0210645.
</p>
<p>Mercer, L. D., Wakefield, J., Pantazis, A., Lutambi, A. M., Masanja, H., &amp; Clark, S. (2015). <em>Space-time smoothing of complex survey data: small area estimation for child mortality.</em> The annals of applied statistics, 9(4), 1889.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getDirect">getDirect</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(DemoData)
years &lt;- c("85-89", "90-94", "95-99", "00-04", "05-09", "10-14")
mean &lt;- getDirectList(births = DemoData, years = years, 
regionVar = "region", timeVar = "time", clusterVar = "~clustid+id", 
ageVar = "age", weightsVar = "weights", geo.recode = NULL)

## End(Not run)
</code></pre>

<hr>
<h2 id='getSmoothed'>Extract smoothed estimates.</h2><span id='topic+getSmoothed'></span>

<h3>Description</h3>

<p>Extract smoothed estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getSmoothed(
  fitted,
  inla_mod = deprecated(),
  nsim = 1000,
  weight.strata = NULL,
  weight.frame = NULL,
  verbose = FALSE,
  mc = 0,
  include.time.unstruct = FALSE,
  include_time_unstruct = deprecated(),
  CI = 0.95,
  draws = NULL,
  save.draws = FALSE,
  include.subnational = TRUE,
  include_subnational = deprecated(),
  only.age = NULL,
  joint = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getSmoothed_+3A_fitted">fitted</code></td>
<td>
<p>output from <code><a href="#topic+smoothDirect">smoothDirect</a></code> or <code><a href="#topic+smoothCluster">smoothCluster</a></code></p>
</td></tr>
<tr><td><code id="getSmoothed_+3A_inla_mod">inla_mod</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> replaced by <code>fitted</code></p>
</td></tr>
<tr><td><code id="getSmoothed_+3A_nsim">nsim</code></td>
<td>
<p>number of simulations, only applicable for the cluster-level model or direct model when <code>joint = TRUE</code> is specified. The smooth direct model will draw 1e5 samples from the marginal distribution when <code>joint = FALSE</code> since the computation is faster.</p>
</td></tr>
<tr><td><code id="getSmoothed_+3A_weight.strata">weight.strata</code></td>
<td>
<p>a data frame with two columns specifying time and region, followed by columns specifying proportion of each strata for each region. This argument specifies the weights for strata-specific estimates on the probability scale.</p>
</td></tr>
<tr><td><code id="getSmoothed_+3A_weight.frame">weight.frame</code></td>
<td>
<p>a data frame with three columns, years, region, and the weight of each frame for the corresponding time period and region. This argument specifies the weights for frame-specific estimates on the logit scale. Notice this is different from weight.strata argument.</p>
</td></tr>
<tr><td><code id="getSmoothed_+3A_verbose">verbose</code></td>
<td>
<p>logical indicator whether to print progress messages from inla.posterior.sample.</p>
</td></tr>
<tr><td><code id="getSmoothed_+3A_mc">mc</code></td>
<td>
<p>number of monte carlo draws to approximate the marginal prevalence/hazards for binomial model. If mc = 0, analytical approximation is used. The analytical approximation is invalid for hazard modeling with more than one age groups.</p>
</td></tr>
<tr><td><code id="getSmoothed_+3A_include.time.unstruct">include.time.unstruct</code></td>
<td>
<p>Indicator whether to include the temporal unstructured effects (i.e., shocks) in the smoothed estimates from cluster-level model. The argument only applies to the cluster-level models (from <code><a href="#topic+smoothCluster">smoothCluster</a></code>). Default is FALSE which excludes all unstructured temporal components. If set to TRUE all  the unstructured temporal random effects will be included. Alternatively, if this is specified as a vector of   subset of year labels (as in the year.label argument), only the unstructured terms in the corresponding time periods will be added to the prediction.</p>
</td></tr>
<tr><td><code id="getSmoothed_+3A_include_time_unstruct">include_time_unstruct</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> replaced by <code>include.time.unstruct</code></p>
</td></tr>
<tr><td><code id="getSmoothed_+3A_ci">CI</code></td>
<td>
<p>Desired level of credible intervals</p>
</td></tr>
<tr><td><code id="getSmoothed_+3A_draws">draws</code></td>
<td>
<p>Posterior samples drawn from the fitted model. This argument allows the previously sampled draws (by setting save.draws to be TRUE) be used in new aggregation tasks.</p>
</td></tr>
<tr><td><code id="getSmoothed_+3A_save.draws">save.draws</code></td>
<td>
<p>Logical indicator whether the raw posterior draws will be saved. Saved draws can be used to accelerate aggregations with different weights.</p>
</td></tr>
<tr><td><code id="getSmoothed_+3A_include.subnational">include.subnational</code></td>
<td>
<p>logical indicator whether to include the spatial and space-time interaction components in the smoothed estimates. If set to FALSE, only the main temporal trends are returned.</p>
</td></tr>
<tr><td><code id="getSmoothed_+3A_include_subnational">include_subnational</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> replaced by <code>include.subnational</code></p>
</td></tr>
<tr><td><code id="getSmoothed_+3A_only.age">only.age</code></td>
<td>
<p>a vector of age groups used to compute the final estimates. Default to be NULL, which includes all age groups in the model. This argument can be used to extract mortality rates of finer age groups when fitting multiple age groups jointly.</p>
</td></tr>
<tr><td><code id="getSmoothed_+3A_joint">joint</code></td>
<td>
<p>Logical indicator whether the posterior draws should be drawn from the joint posterior or marginal distributions. Only releveant for the smooth direct model. Default from the marginal distribution (joint = FALSE).</p>
</td></tr>
<tr><td><code id="getSmoothed_+3A_...">...</code></td>
<td>
<p>Unused arguments, for users with fitted object from the package before v1.0.0, arguments including Amat, year.label, and year.range can still be specified manually.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame or a list of data frames of S3 class SUMMERproj, which contains the smoothed estimates.
</p>


<h3>Author(s)</h3>

<p>Zehang Richard Li
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.SUMMERproj">plot.SUMMERproj</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
years &lt;- levels(DemoData[[1]]$time)

# obtain direct estimates
data &lt;- getDirectList(births = DemoData, 
years = years,  
regionVar = "region", timeVar = "time", 
clusterVar = "~clustid+id", 
ageVar = "age", weightsVar = "weights", 
geo.recode = NULL)
# obtain direct estimates
data_multi &lt;- getDirectList(births = DemoData, years = years,
  regionVar = "region",  timeVar = "time", clusterVar = "~clustid+id",
  ageVar = "age", weightsVar = "weights", geo.recode = NULL)
data &lt;- aggregateSurvey(data_multi)

##
## The following example shows extracting estimates from 
##   fitted smoothDirect() model
##
#  national model
years.all &lt;- c(years, "15-19")
fit1 &lt;- smoothDirect(data = data, Amat = NULL, 
  year.label = years.all, year.range = c(1985, 2019), 
  rw = 2, is.yearly=FALSE, m = 5)
out1 &lt;- getSmoothed(fit1)
plot(out1, is.subnational=FALSE)

#  subnational model
fit2 &lt;- smoothDirect(data = data, Amat = mat, 
  year.label = years.all, year.range = c(1985, 2019), 
  rw = 2, is.yearly=TRUE, m = 5, type.st = 4)
out2 &lt;- getSmoothed(fit2)
plot(out2, is.yearly=TRUE, is.subnational=TRUE)

## The following examples compare the marginal posterior draws
##    with joint posterior draws. The latter gives draws of 
##    all estimates in addition to marginal summaries.
## The plots should fall closely along the 45 degree line 

#  national period model
years.all &lt;- c(years, "15-19")
fit0 &lt;- smoothDirect(data = data, Amat = NULL, 
year.label = years, year.range = c(1985, 2019), 
time.model = 'rw2', m = 1, control.compute = list(config =TRUE))
out0 &lt;- getSmoothed(fit0)
out0a &lt;- getSmoothed(fit0, joint = TRUE, nsim = 1e5)
par(mfrow = c(1, 3))
plot(out0$median, out0a$overall$median)
abline(c(0, 1))
plot(out0$upper, out0a$overall$upper)
abline(c(0, 1))
plot(out0$lower, out0a$overall$lower)
abline(c(0, 1))

#  national yearly model
years.all &lt;- c(years, "15-19")
fit1 &lt;- smoothDirect(data = data, Amat = NULL, 
year.label = years.all, year.range = c(1985, 2019), 
time.model = 'rw2', m = 5, control.compute = list(config =TRUE))
out1 &lt;- getSmoothed(fit1)
out1a &lt;- getSmoothed(fit1, joint = TRUE, nsim = 1e5, save.draws = TRUE)
par(mfrow = c(1, 3))
plot(out1$median, out1a$overall$median)
abline(c(0, 1))
plot(out1$upper, out1a$overall$upper)
abline(c(0, 1))
plot(out1$lower, out1a$overall$lower)
abline(c(0, 1))

#  subnational model
fit2 &lt;- smoothDirect(data = data, Amat = DemoMap$Amat, 
year.label = years.all, year.range = c(1985, 2019), 
time.model = 'rw2',is.yearly=TRUE, m = 5, type.st = 4, 
control.compute = list(config =TRUE))
out2 &lt;- getSmoothed(fit2)
out2a &lt;- getSmoothed(fit2, joint = TRUE, nsim = 1e5, save.draws = TRUE)
par(mfrow = c(1, 3))
plot(out2$median, out2a$overall$median)
abline(c(0, 1))
plot(out2$upper, out2a$overall$upper)
abline(c(0, 1))
plot(out2$lower, out2a$overall$lower)
abline(c(0, 1))

#  subnational space-only model combining all periods
fit3 &lt;- smoothDirect(data = data, 
       time.model = NULL, Amat = DemoMap$Amat, 
   control.compute = list(config =TRUE))
out3 &lt;- getSmoothed(fit3)
out3a &lt;- getSmoothed(fit3, joint = TRUE, nsim = 1e5, save.draws = TRUE)
par(mfrow = c(1, 3))
plot(out3$median, out3a$overall$median)
abline(c(0, 1))
plot(out3$upper, out3a$overall$upper)
abline(c(0, 1))
plot(out3$lower#' , out3a$overall$lower)
abline(c(0, 1))

## End(Not run)

</code></pre>

<hr>
<h2 id='hatchPlot'>Plot maps with uncertainty hatching.</h2><span id='topic+hatchPlot'></span>

<h3>Description</h3>

<p>This function visualizes the map with different variables. The input data frame can be either the long or wide format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hatchPlot(
  data,
  variables,
  values = NULL,
  labels = NULL,
  geo,
  by.data,
  by.geo,
  is.long = FALSE,
  lower,
  upper,
  lim = NULL,
  lim.CI = NULL,
  breaks.CI = NULL,
  ncol = 4,
  hatch = NULL,
  border = NULL,
  size = 1,
  legend.label = NULL,
  per1000 = FALSE,
  direction = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hatchPlot_+3A_data">data</code></td>
<td>
<p>a data frame with variables to be plotted</p>
</td></tr>
<tr><td><code id="hatchPlot_+3A_variables">variables</code></td>
<td>
<p>vector of variables to be plotted. If long format of data is used, only one variable can be selected</p>
</td></tr>
<tr><td><code id="hatchPlot_+3A_values">values</code></td>
<td>
<p>the column corresponding to the values to be plotted, only used when long format of data is used</p>
</td></tr>
<tr><td><code id="hatchPlot_+3A_labels">labels</code></td>
<td>
<p>vector of labels to use for each variable, only used when wide format of data is used</p>
</td></tr>
<tr><td><code id="hatchPlot_+3A_geo">geo</code></td>
<td>
<p>SpatialPolygonsDataFrame object for the map</p>
</td></tr>
<tr><td><code id="hatchPlot_+3A_by.data">by.data</code></td>
<td>
<p>column name specifying region names in the data</p>
</td></tr>
<tr><td><code id="hatchPlot_+3A_by.geo">by.geo</code></td>
<td>
<p>variable name specifying region names in the data</p>
</td></tr>
<tr><td><code id="hatchPlot_+3A_is.long">is.long</code></td>
<td>
<p>logical indicator of whether the data is in the long format, default to FALSE</p>
</td></tr>
<tr><td><code id="hatchPlot_+3A_lower">lower</code></td>
<td>
<p>column name of the lower bound of the CI</p>
</td></tr>
<tr><td><code id="hatchPlot_+3A_upper">upper</code></td>
<td>
<p>column name of the upper bound of the CI</p>
</td></tr>
<tr><td><code id="hatchPlot_+3A_lim">lim</code></td>
<td>
<p>fixed range of values for the variables to plot</p>
</td></tr>
<tr><td><code id="hatchPlot_+3A_lim.ci">lim.CI</code></td>
<td>
<p>fixed range of the CI widths to plot</p>
</td></tr>
<tr><td><code id="hatchPlot_+3A_breaks.ci">breaks.CI</code></td>
<td>
<p>a vector of numerical values that decides the breaks in the CI widths to be shown</p>
</td></tr>
<tr><td><code id="hatchPlot_+3A_ncol">ncol</code></td>
<td>
<p>number of columns for the output tabs</p>
</td></tr>
<tr><td><code id="hatchPlot_+3A_hatch">hatch</code></td>
<td>
<p>color of the hatching lines.</p>
</td></tr>
<tr><td><code id="hatchPlot_+3A_border">border</code></td>
<td>
<p>color of the polygon borders.</p>
</td></tr>
<tr><td><code id="hatchPlot_+3A_size">size</code></td>
<td>
<p>line width of the polygon borders.</p>
</td></tr>
<tr><td><code id="hatchPlot_+3A_legend.label">legend.label</code></td>
<td>
<p>Label for the color legend.</p>
</td></tr>
<tr><td><code id="hatchPlot_+3A_per1000">per1000</code></td>
<td>
<p>logical indicator to plot mortality rates as rates per 1,000 live births. Note that the added comparison data should always be in the probability scale.</p>
</td></tr>
<tr><td><code id="hatchPlot_+3A_direction">direction</code></td>
<td>
<p>Direction of the color scheme. It can be either 1 (smaller values are darker) or -1 (higher values are darker). Default is set to 1.</p>
</td></tr>
<tr><td><code id="hatchPlot_+3A_...">...</code></td>
<td>
<p>unused.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zehang Richard Li, Katie Wilson
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
years &lt;- levels(DemoData[[1]]$time)

# obtain direct estimates
data &lt;- getDirectList(births = DemoData, 
years = years,  
regionVar = "region", timeVar = "time", 
clusterVar = "~clustid+id", 
ageVar = "age", weightsVar = "weights", 
geo.recode = NULL)
# obtain direct estimates
data_multi &lt;- getDirectList(births = DemoData, years = years,
  regionVar = "region",  timeVar = "time", clusterVar = "~clustid+id",
  ageVar = "age", weightsVar = "weights", geo.recode = NULL)
data &lt;- aggregateSurvey(data_multi)

fit2 &lt;- smoothDirect(data = data, geo = geo, Amat = mat, 
  year.label = years.all, year.range = c(1985, 2019), 
  rw = 2, is.yearly=TRUE, m = 5, type.st = 4)
out2 &lt;- getSmoothed(fit2)

plot(out2, is.yearly=TRUE, is.subnational=TRUE)

hatchPlot(data = subset(out2, is.yearly==FALSE), geo = geo,
variables=c("years"), values = c("median"), 
by.data = "region", by.geo = "REGNAME", 
lower = "lower", upper = "upper", is.long=TRUE)


## End(Not run)
</code></pre>

<hr>
<h2 id='iid.new'>New random IID models for m-year to period random effects</h2><span id='topic+iid.new'></span>

<h3>Description</h3>

<p>New random IID models for m-year to period random effects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iid.new(
  cmd = c("graph", "Q", "mu", "initial", "log.norm.const", "log.prior", "quit"),
  theta = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="iid.new_+3A_cmd">cmd</code></td>
<td>
<p>list of model components</p>
</td></tr>
<tr><td><code id="iid.new_+3A_theta">theta</code></td>
<td>
<p>log precision</p>
</td></tr>
</table>

<hr>
<h2 id='iid.new.pc'>New random IID models for m-year to period random effects</h2><span id='topic+iid.new.pc'></span>

<h3>Description</h3>

<p>New random IID models for m-year to period random effects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iid.new.pc(
  cmd = c("graph", "Q", "mu", "initial", "log.norm.const", "log.prior", "quit"),
  theta = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="iid.new.pc_+3A_cmd">cmd</code></td>
<td>
<p>list of model components</p>
</td></tr>
<tr><td><code id="iid.new.pc_+3A_theta">theta</code></td>
<td>
<p>log precision</p>
</td></tr>
</table>

<hr>
<h2 id='KenData'>Auxiliary data for Kenya 2014 DHS.</h2><span id='topic+KenData'></span>

<h3>Description</h3>

<p>The list contains several data frames.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(KenData)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 4.
</p>


<h3>Details</h3>


<ul>
<li><p> HIV2014, a data frame with three columns: years (in five year periods),  region (8 Admin-1 region groups), and the estimated bias of the reported U5MR due to HIV for each 5 year period from 1990-1994 to 2010-2014. The bias is represented as the ratio of the reported U5MR to the true U5MR.
</p>
</li>
<li><p> HIV2014.yearly, a data frame with three columns: years (in one year interval),  region (8 Admin-1 region groups), and the estimated bias of the reported U5MR due to HIV for each year from 1980 to 2014. The bias is represented as the ratio of the reported U5MR to the true U5MR.
</p>
</li>
<li><p> IGME2019. Yearly Estimates of national under-5 child mortality in Kenya from the 2019 UN-IGME estimates.
</p>
</li>
<li><p> UrbanProp. Proportion of urban population by county and total population by county. Source: 2009 Kenya Population and Housing Census, and Table A2 of Kenya 2014 DHS report.
</p>
</li></ul>



<h3>References</h3>

<p>Neff Walker, Kenneth Hill, and Fengmin Zhao (2012) <em>Child mortality estimation: methods used to adjust for bias due to aids in estimating trends in under-five mortality.</em>, <br /> <em>PLoS Medicine, 9(8):e1001298</em>.
</p>

<hr>
<h2 id='kenyaPopulationData'>Kenya 2009 Census Frame and Related Datasets</h2><span id='topic+kenyaPopulationData'></span><span id='topic+easpaKenya'></span><span id='topic+easpaKenyaNeonatal'></span><span id='topic+poppaKenya'></span><span id='topic+poppsubKenya'></span>

<h3>Description</h3>

<p>Datasets related to the 2009 census frame for Kenya based on the 2009 Kenya Population and Housing
Census. General population totals are estimated for 2014. Based on 2014 population density
estimates interpolated with exponential growth rate between 2010 and 2015 from WorldPop data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(kenyaPopulationData)

easpaKenyaNeonatal

poppaKenya

poppsubKenya
</code></pre>


<h3>Format</h3>

<p>A number of data.frames with information about the 2009 Kenya Population and Housing Census and the population in Kenya at the time of the 2014 Demographic Health Survey. Some of the
data.frames have been adjusted to contain information about neonatals born from 2010-2014 rather than general population in 2014.
The dataset names are: easpaKenya, easpaKenyaNeonatal,
poppaKenya, and poppsubKenya.
</p>
<p>An object of class <code>data.frame</code> with 47 rows and 12 columns.
</p>
<p>An object of class <code>data.frame</code> with 47 rows and 6 columns.
</p>
<p>An object of class <code>data.frame</code> with 300 rows and 7 columns.
</p>


<h3>Source</h3>

<p><a href="https://dhsprogram.com/pubs/pdf/FR308/FR308.pdf">https://dhsprogram.com/pubs/pdf/FR308/FR308.pdf</a>
</p>


<h3>References</h3>

<p>Kenya National Bureau of Statistics, Ministry of Health/Kenya, National AIDS Control Council/Kenya, Kenya Medical Research Institute, and National Council For Population And Development/Kenya, 2015. Kenya Demographic and Health Survey 2014. Rockville, Maryland, USA. URL: http://dhsprogram.com/pubs/pdf/FR308/FR308.pdf.
</p>
<p>Stevens, F.R., Gaughan, A.E., Linard, C., Tatem, A.J., 2015. Disaggregat- ing census data for population mapping using random forests with remotely-sensed and ancillary data. PloS One 10, e0107042.
</p>
<p>Tatem, A.J., 2017. WorldPop, open data for spatial demography. Scientific Data 4.
</p>

<hr>
<h2 id='KingCounty'>Map of King County</h2><span id='topic+KingCounty'></span>

<h3>Description</h3>

<p>Shapefiles are King County in the Washington States.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KingCounty
</code></pre>


<h3>Format</h3>

<p>An object of class <code>SpatialPolygonsDataFrame</code> with 48 rows and 9 columns.
</p>

<hr>
<h2 id='logit'>Logit transformation</h2><span id='topic+logit'></span>

<h3>Description</h3>

<p>Logit transformation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logit(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logit_+3A_x">x</code></td>
<td>
<p>data</p>
</td></tr>
</table>


<h3>Value</h3>

<p>logit of x
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- .5
logit(x)

</code></pre>

<hr>
<h2 id='logitNormMean'>Calculate the mean of a distribution whose
logit is Gaussian</h2><span id='topic+logitNormMean'></span>

<h3>Description</h3>

<p>Adapted from logitnorm package.  Calculates the mean of a distribution whose
logit is Gaussian. Each row of muSigmaMat is a mean and standard deviation
on the logit scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logitNormMean(muSigmaMat, logisticApprox = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logitNormMean_+3A_musigmamat">muSigmaMat</code></td>
<td>
<p>An n x 2 matrix where each row is <code class="reqn">\mu</code> and <code class="reqn">\sigma</code>
on the logit scale for an independent random variable.</p>
</td></tr>
<tr><td><code id="logitNormMean_+3A_logisticapprox">logisticApprox</code></td>
<td>
<p>Whether or not to use logistic approximation to speed
up computation. See details for more information.</p>
</td></tr>
<tr><td><code id="logitNormMean_+3A_...">...</code></td>
<td>
<p>More arguments, passed to <code>integrate</code> function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code class="reqn">\mbox{logit}(Y) \sim N(\mu, \sigma^2)</code>,
This function calculates <code class="reqn">E[Y]</code> via either numerical integration or by
assuming that Y follows a logistic distribution. Under this approximation, setting
<code class="reqn">k = 16 \sqrt{3} / (15 \pi)</code>, we approximate
the expectation as:
</p>
<p style="text-align: center;"><code class="reqn">E[Y] = expit(\mu / \sqrt{1 + k^2 \sigma^2})</code>
</p>

<p>The above logistic approximation speeds up the computation, but also sacrifices
some accuracy.
</p>


<h3>Value</h3>

<p>A vector of expectations of the specified random variables
</p>


<h3>Author(s)</h3>

<p>John Paige
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mus = c(-5, 0, 5)
sigmas = rep(1, 3)
logitNormMean(cbind(mus, sigmas))
logitNormMean(cbind(mus, sigmas), TRUE)

</code></pre>

<hr>
<h2 id='makePopIntegrationTab'>Generating pixellated populations, and population frames</h2><span id='topic+makePopIntegrationTab'></span><span id='topic+getPoppsub'></span><span id='topic+adjustPopMat'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makePopIntegrationTab(
  km.res = 5,
  pop,
  domain.map.dat,
  east.lim,
  north.lim,
  map.projection,
  area.map.dat,
  subarea.map.dat,
  areaNameVar = "NAME_1",
  subareaNameVar = "NAME_2",
  poppa = NULL,
  poppsub = NULL,
  stratify.by.urban = TRUE,
  areapa = NULL,
  areapsub = NULL,
  custom.subset.polygons = NULL,
  area.polygon.subset.I = NULL,
  subarea.polygon.subset.I = NULL,
  mean.neighbor = 50,
  delta = 0.1,
  return.popp.tables = FALSE,
  set.na.to.zero = TRUE,
  fix.zero.pop.density.subareas = FALSE,
  extract.method = "bilinear"
)

getPoppsub(
  km.res = 1,
  pop,
  domain.map.dat,
  east.lim,
  north.lim,
  map.projection,
  poppa,
  areapa = NULL,
  areapsub,
  subarea.map.dat,
  subareaNameVar = "NAME_2",
  stratify.by.urban = TRUE,
  area.map.dat = NULL,
  areaNameVar = "NAME_1",
  area.polygon.subset.I = NULL,
  subarea.polygon.subset.I = NULL,
  custom.subset.polygons = NULL,
  mean.neighbor = 50,
  delta = 0.1,
  set.na.to.zero = TRUE,
  fix.zero.pop.density.subareas = FALSE
)

adjustPopMat(
  pop.mat,
  poppa.target = NULL,
  adjust.by = c("area", "subarea"),
  stratify.by.urban = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="makePopIntegrationTab_+3A_km.res">km.res</code></td>
<td>
<p>The resolution of the pixelated grid in km</p>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_pop">pop</code></td>
<td>
<p>Population density raster</p>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_domain.map.dat">domain.map.dat</code></td>
<td>
<p>A shapefile representing the full spatial domain (e.g. country)</p>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_east.lim">east.lim</code></td>
<td>
<p>Range in km easting over the spatial domain under the input projection</p>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_north.lim">north.lim</code></td>
<td>
<p>Range in km northing over the spatial domain under the input projection</p>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_map.projection">map.projection</code></td>
<td>
<p>A projection function taking longitude and latitude and returning easting and
northing in km. Or the inverse if inverse is set to TRUE. For example,
<code><a href="#topic+projKenya">projKenya</a></code>. Check https://epsg.io/ for example for best projection EPSG codes
for specific countries</p>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_area.map.dat">area.map.dat</code></td>
<td>
<p>SpatialPolygonsDataFrame object with area level map information</p>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_subarea.map.dat">subarea.map.dat</code></td>
<td>
<p>SpatialPolygonsDataFrame object with subarea level map information</p>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_areanamevar">areaNameVar</code></td>
<td>
<p>The name of the area variable associated with <code>area.map.dat@data</code>
and <code>subarea.map.dat@data</code></p>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_subareanamevar">subareaNameVar</code></td>
<td>
<p>The name of the subarea variable associated with <code>subarea.map.dat@data</code></p>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_poppa">poppa</code></td>
<td>
<p>data.frame of population per area separated by urban/rural. If <code>poppsub</code>
is not included, this is used for normalization of populations associated with
population integration points. Contains variables:
</p>

<dl>
<dt>area</dt><dd><p>name of area</p>
</dd>
<dt>popUrb</dt><dd><p>total urban (general) population of area</p>
</dd>
<dt>popRur</dt><dd><p>total rural (general) population of area</p>
</dd>
<dt>popTotal</dt><dd><p>total (general) population of area</p>
</dd>
<dt>pctUrb</dt><dd><p>percentage of population in the area that is urban (between 0 and 100)</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_poppsub">poppsub</code></td>
<td>
<p>data.frame of population per subarea separated by
urban/rural using for population normalization or urbanicity
classification. Often based on extra fine scale population density grid.
Has variables:
</p>

<dl>
<dt>subarea</dt><dd><p>name of subarea</p>
</dd>
<dt>area</dt><dd><p>name of area</p>
</dd>
<dt>popUrb</dt><dd><p>total urban (general) population of subarea</p>
</dd>
<dt>popRur</dt><dd><p>total rural (general) population of subarea</p>
</dd>
<dt>popTotal</dt><dd><p>total (general) population of subarea</p>
</dd>
<dt>pctUrb</dt><dd><p>percentage of population in the subarea that is urban (between 0 and 100)</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_stratify.by.urban">stratify.by.urban</code></td>
<td>
<p>Whether to stratify the pixellated grid by urban/rural. If TRUE,
renormalizes population densities within areas or subareas crossed with urban/rural</p>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_areapa">areapa</code></td>
<td>
<p>A list with variables:
</p>

<dl>
<dt>area</dt><dd><p>name of area</p>
</dd>
<dt>spatialArea</dt><dd><p>spatial area of the subarea (e.g. in km^2)</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_areapsub">areapsub</code></td>
<td>
<p>A list with variables:
</p>

<dl>
<dt>subarea</dt><dd><p>name of subarea</p>
</dd>
<dt>spatialArea</dt><dd><p>spatial area of the subarea (e.g. in km^2)</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_custom.subset.polygons">custom.subset.polygons</code></td>
<td>
<p>'SpatialPolygonsDataFrame' or 'SpatialPolygons' object to subset
the grid over. This option can help reduce computation time relative to
constructing the whole grid and subsetting afterwards. <code>area.polygon.subset.I</code> or
<code>subarea.polygon.subset.I</code> can be used when subsetting by areas or subareas in
<code>area.map.dat</code> or <code>subarea.map.dat</code>. Must be in latitude/longitude projection &quot;EPSG:4326&quot;</p>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_area.polygon.subset.i">area.polygon.subset.I</code></td>
<td>
<p>Index in area.map.dat for a specific area to subset the grid over. This
option can help reduce computation time relative to constructing the whole grid
and subsetting afterwards</p>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_subarea.polygon.subset.i">subarea.polygon.subset.I</code></td>
<td>
<p>FOR EXPERIMENTAL PURPOSES ONLY. Index in subarea.map.dat for a
specific area to subset the grid over. This
option can help reduce computation time relative to constructing the whole grid
and subsetting afterwards</p>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_mean.neighbor">mean.neighbor</code></td>
<td>
<p>For determining what area or subarea points are nearest to if they do not
directly fall into an area. See <code><a href="fields.html#topic+fields.rdist.near">fields.rdist.near</a></code> for details.</p>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_delta">delta</code></td>
<td>
<p>For determining what area or subarea points are nearest to if they do not
directly fall into an area. See <code><a href="fields.html#topic+fields.rdist.near">fields.rdist.near</a></code> for details.</p>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_return.popp.tables">return.popp.tables</code></td>
<td>
<p>If TRUE, poppa and poppsub will be calculated based on the generated
population integration matrix and input area/subarea map data</p>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_set.na.to.zero">set.na.to.zero</code></td>
<td>
<p>If TRUE, sets NA populations to 0.</p>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_fix.zero.pop.density.subareas">fix.zero.pop.density.subareas</code></td>
<td>
<p>If TRUE, if population density in a subarea is estimated to be
zero, but the total population in the subarea is nonzero, population is filled into the
area uniformly</p>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_extract.method">extract.method</code></td>
<td>
<p>Either 'bilinear' or 'simple'. see <code>method</code> from
<code><a href="terra.html#topic+extract">extract</a></code></p>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_pop.mat">pop.mat</code></td>
<td>
<p>Pixellated grid data frame with variables <code>area</code> and <code>pop</code> such as that
generated by <code><a href="#topic+makePopIntegrationTab">makePopIntegrationTab</a></code></p>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_poppa.target">poppa.target</code></td>
<td>
<p>Target population per area stratified by urban rural. Same format as poppa</p>
</td></tr>
<tr><td><code id="makePopIntegrationTab_+3A_adjust.by">adjust.by</code></td>
<td>
<p>Whether to adjust population density by the <code>area</code> or <code>subarea</code> level</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Functions for generating pixellated population information and
population frames at the <code>area</code> and <code>subarea</code> levels.
The <code>area</code> and <code>subarea</code> levels can be thought of as big
regions and little regions, where areas can be partitioned into
unique sets of subareas. For example, Admin-1 and Admin-2
areas might be areas and subareas respectively. The population totals are either
tabulated at the area x urban/rural level, the subarea x urban/rural
level, or at the pixel level of a specified resolution. Totals
are calculated using population density information, shapefiles,
and, possibly, preexisting population frames at different
areal levels. Note that area names should each be unique, and similarly for
subarea names.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>makePopIntegrationTab()</code>: Generate pixellated <code>grid</code> of coordinates (both longitude/latitude and east/north)
over spatial domain of the given resolution with associated population totals, areas, subareas,
and urban/rural levels. For very small areas that might not
otherwise have a grid point in them, a custom integration point is added at their
centroid. Sets urbanicity classifications by thresholding input population density raster
using area and subarea population tables, and generates area and subarea population
tables from population density information if not already given. Can be used for integrating
predictions from the given coordinates to area and subarea levels using population weights.
</p>
</li>
<li> <p><code>getPoppsub()</code>: Generate table of estimates of population
totals per subarea x urban/rural combination based on population density
raster at <code>kmres</code> resolution &quot;grid&quot;, including custom integration points
for any subarea too small to include grid points at their centroids.
</p>
</li>
<li> <p><code>adjustPopMat()</code>: Adjust population densities in grid based on a population frame.
</p>
</li></ul>


<h3>Author(s)</h3>

<p>John Paige
</p>


<h3>See Also</h3>

<p><code><a href="#topic+setThresholdsByRegion">setThresholdsByRegion</a></code>, <code><a href="#topic+poppRegionFromPopMat">poppRegionFromPopMat</a></code>, <code><a href="#topic+simPopSPDE">simPopSPDE</a></code>, <code><a href="#topic+simPopCustom">simPopCustom</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

library(sp)
library(sf)
# download Kenya GADM shapefiles from SUMMERdata github repository
githubURL &lt;- paste0("https://github.com/paigejo/SUMMERdata/blob/main/data/", 
                    "kenyaMaps.rda?raw=true")
tempDirectory = "~/"
mapsFilename = paste0(tempDirectory, "/kenyaMaps.rda")
if(!file.exists(mapsFilename)) {
  download.file(githubURL,mapsFilename)
}

# load it in
out = load(mapsFilename)
out
adm1@data$NAME_1 = as.character(adm1@data$NAME_1)
adm1@data$NAME_1[adm1@data$NAME_1 == "Trans Nzoia"] = "Trans-Nzoia"
adm1@data$NAME_1[adm1@data$NAME_1 == "Elgeyo-Marakwet"] = "Elgeyo Marakwet"
adm2@data$NAME_1 = as.character(adm2@data$NAME_1)
adm2@data$NAME_1[adm2@data$NAME_1 == "Trans Nzoia"] = "Trans-Nzoia"
adm2@data$NAME_1[adm2@data$NAME_1 == "Elgeyo-Marakwet"] = "Elgeyo Marakwet"

# some Admin-2 areas have the same name
adm2@data$NAME_2 = as.character(adm2@data$NAME_2)
adm2@data$NAME_2[(adm2@data$NAME_1 == "Bungoma") &amp; 
                   (adm2@data$NAME_2 == "Lugari")] = "Lugari, Bungoma"
adm2@data$NAME_2[(adm2@data$NAME_1 == "Kakamega") &amp; 
                   (adm2@data$NAME_2 == "Lugari")] = "Lugari, Kakamega"
adm2@data$NAME_2[(adm2@data$NAME_1 == "Meru") &amp; 
                   (adm2@data$NAME_2 == "Igembe South")] = "Igembe South, Meru"
adm2@data$NAME_2[(adm2@data$NAME_1 == "Tharaka-Nithi") &amp; 
                   (adm2@data$NAME_2 == "Igembe South")] = "Igembe South, Tharaka-Nithi"

# The spatial area of unknown 8 is so small, it causes problems unless its removed or 
# unioned with another subarea. Union it with neighboring Kakeguria:
newadm2 = adm2
unknown8I = which(newadm2$NAME_2 == "unknown 8")
newadm2$NAME_2[newadm2$NAME_2 %in% c("unknown 8", "Kapenguria")] &lt;- 
  "Kapenguria + unknown 8"
admin2.IDs &lt;- newadm2$NAME_2

newadm2@data = cbind(newadm2@data, NAME_2OLD = newadm2@data$NAME_2)
newadm2@data$NAME_2OLD = newadm2@data$NAME_2
newadm2@data$NAME_2 = admin2.IDs
newadm2$NAME_2 = admin2.IDs
temp &lt;- terra::aggregate(as(newadm2, "SpatVector"), by="NAME_2")

temp &lt;- sf::st_as_sf(temp)
temp &lt;- sf::as_Spatial(temp)

tempData = newadm2@data[-unknown8I,]
tempData = tempData[order(tempData$NAME_2),]
newadm2 &lt;- sp::SpatialPolygonsDataFrame(temp, tempData, match.ID = F)
adm2 = newadm2

# download 2014 Kenya population density TIF file

githubURL &lt;- paste0("https://github.com/paigejo/SUMMERdata/blob/main/data/", 
                    "Kenya2014Pop/worldpop_total_1y_2014_00_00.tif?raw=true")
popTIFFilename = paste0(tempDirectory, "/worldpop_total_1y_2014_00_00.tif")
if(!file.exists(popTIFFilename)) {
  download.file(githubURL,popTIFFilename)
}

# load it in
pop = terra::rast(popTIFFilename)

east.lim = c(-110.6405, 832.4544)
north.lim = c(-555.1739, 608.7130)

## Construct poppsubKenya, a table of urban/rural general population totals 
## in each subarea. Technically, this is not necessary since we can load in 
## poppsubKenya via data(kenyaPopulationData). First, we will need to calculate 
## the areas in km^2 of the areas and subareas


# use Lambert equal area projection of areas (Admin-1) and subareas (Admin-2)
midLon = mean(adm1@bbox[1,])
midLat = mean(adm1@bbox[2,])
p4s = paste0("+proj=laea +x_0=0 +y_0=0 +lon_0=", midLon, 
             " +lat_0=", midLat, " +units=km")

adm1_sf = st_as_sf(adm1)
adm1proj_sf = st_transform(adm1_sf, p4s)
adm1proj = as(adm1proj_sf, "Spatial")

adm2_sf = st_as_sf(adm2)
adm2proj_sf = st_transform(adm2_sf, p4s)
adm2proj = as(adm2proj_sf, "Spatial")

# now calculate spatial area in km^2
admin1Areas = as.numeric(st_area(adm1proj_sf))
admin2Areas = as.numeric(st_area(adm2proj_sf))

areapaKenya = data.frame(area=adm1proj@data$NAME_1, spatialArea=admin1Areas)
areapsubKenya = data.frame(area=adm2proj@data$NAME_1, subarea=adm2proj@data$NAME_2, 
                           spatialArea=admin2Areas)

# Calculate general population totals at the subarea (Admin-2) x urban/rural 
# level and using 1km resolution population grid. Assign urbanicity by 
# thresholding population density based on estimated proportion population 
# urban/rural, making sure total area (Admin-1) urban/rural populations in 
# each area matches poppaKenya.
require(fields)
# NOTE: the following function will typically take ~15-20 minutes. Can speed up 
#       by setting km.res to be higher, but we recommend fine resolution for 
#       this step, since it only needs to be done once. Instead of running 
#       the code in the following if(FALSE) section, 
#       you can simply run data(kenyaPopulationData)
if(FALSE){
  system.time(poppsubKenya &lt;- getPoppsub(
    km.res=1, pop=pop, domain.map.dat=adm0,
    east.lim=east.lim, north.lim=north.lim, map.projection=projKenya,
    poppa = poppaKenya, areapa=areapaKenya, areapsub=areapsubKenya, 
    area.map.dat=adm1, subarea.map.dat=adm2, 
    areaNameVar = "NAME_1", subareaNameVar="NAME_2"))
}
data(kenyaPopulationData)

# Now generate a general population integration table at 5km resolution, 
# based on subarea (Admin-2) x urban/rural population totals. This takes 
# ~1 minute
system.time(pop.matKenya &lt;- makePopIntegrationTab(
  km.res=5, pop=pop, domain.map.dat=adm0,
  east.lim=east.lim, north.lim=north.lim, map.projection=projKenya,
  poppa = poppaKenya, poppsub=poppsubKenya, 
  area.map.dat = adm1, subarea.map.dat = adm2,
  areaNameVar = "NAME_1", subareaNameVar="NAME_2"))

## Adjust pop.mat to be target (neonatal) rather than general population density. First
## create the target population frame
## (these numbers are based on IPUMS microcensus data)
mothersPerHouseholdUrb = 0.3497151
childrenPerMotherUrb = 1.295917
mothersPerHouseholdRur = 0.4787696
childrenPerMotherRur = 1.455222
targetPopPerStratumUrban = easpaKenya$HHUrb * mothersPerHouseholdUrb * childrenPerMotherUrb
targetPopPerStratumRural = easpaKenya$HHRur * mothersPerHouseholdRur * childrenPerMotherRur
easpaKenyaNeonatal = easpaKenya
easpaKenyaNeonatal$popUrb = targetPopPerStratumUrban
easpaKenyaNeonatal$popRur = targetPopPerStratumRural
easpaKenyaNeonatal$popTotal = easpaKenyaNeonatal$popUrb + easpaKenyaNeonatal$popRur
easpaKenyaNeonatal$pctUrb = 100 * easpaKenyaNeonatal$popUrb / easpaKenyaNeonatal$popTotal
easpaKenyaNeonatal$pctTotal = 
  100 * easpaKenyaNeonatal$popTotal / sum(easpaKenyaNeonatal$popTotal)

# Generate the target population density by scaling the current population density grid 
# at the Admin1 x urban/rural level
pop.matKenyaNeonatal = adjustPopMat(pop.matKenya, easpaKenyaNeonatal)

# Generate neonatal population table from the neonatal population integration matrix.
# This is technically not necessary for population simulation purposes, but is here 
# for illustrative purposes
poppsubKenyaNeonatal = poppRegionFromPopMat(pop.matKenyaNeonatal, pop.matKenyaNeonatal$subarea)
poppsubKenyaNeonatal = cbind(subarea=poppsubKenyaNeonatal$region, 
                             area=adm2@data$NAME_1[match(poppsubKenyaNeonatal$region, 
                               adm2@data$NAME_2)], 
                             poppsubKenyaNeonatal[,-1])
print(head(poppsubKenyaNeonatal))

## End(Not run)
</code></pre>

<hr>
<h2 id='MalawiData'>Auxiliary data for Malawi 2000, 2004, 2010, and 2015 DHS.</h2><span id='topic+MalawiData'></span>

<h3>Description</h3>

<p>The list contains several data frames.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(MalawiData)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 4.
</p>


<h3>Details</h3>


<ul>
<li><p> HIV, a data frame with three columns: years (in five year periods),  survey, and the estimated bias of the reported U5MR due to HIV for each 5 year period. The bias is represented as the ratio of the reported U5MR to the true U5MR.
</p>
</li>
<li><p> HIV.yearly, a data frame with three columns: years (in one year interval),  survey, and the estimated bias of the reported U5MR due to HIV for each year. The bias is represented as the ratio of the reported U5MR to the true U5MR.
</p>
</li>
<li><p> IGME2019. Yearly Estimates of national under-5 child mortality in Malawi from the 2019 UN-IGME estimates.
</p>
</li>
<li><p> IGME2019.nmr. Yearly Estimates of national neonatal mortality in Malawi from the 2019 UN-IGME estimates.
</p>
</li></ul>



<h3>References</h3>

<p>Neff Walker, Kenneth Hill, and Fengmin Zhao (2012) <em>Child mortality estimation: methods used to adjust for bias due to aids in estimating trends in under-five mortality.</em>, <br /> <em>PLoS Medicine, 9(8):e1001298</em>.
</p>

<hr>
<h2 id='MalawiMap'>Malawi Admin-2 map</h2><span id='topic+MalawiMap'></span>

<h3>Description</h3>

<p>SpatialPolygonsDataFrame objects that reflect the Admin 2 regions in Malawi, including the Likoma island. The Admin 2 region names are in the ADM2_EN field.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(MalawiMap)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>SpatialPolygonsDataFrame</code> with 28 rows and 14 columns.
</p>

<hr>
<h2 id='mapEstimates'>Mapping estimates for svysae object</h2><span id='topic+mapEstimates'></span>

<h3>Description</h3>

<p>Mapping estimates for svysae object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mapEstimates(x, geo.data, variable, viridis.option = "viridis")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mapEstimates_+3A_x">x</code></td>
<td>
<p>syvsae object</p>
</td></tr>
<tr><td><code id="mapEstimates_+3A_geo.data">geo.data</code></td>
<td>
<p>sf object containing polygon data for the small areas. One of the columns should be named domain and contain the domain labels.</p>
</td></tr>
<tr><td><code id="mapEstimates_+3A_variable">variable</code></td>
<td>
<p>The posterior summary variable to plot. May be one of &quot;median&quot;, &quot;mean&quot;, or &quot;var&quot;.</p>
</td></tr>
<tr><td><code id="mapEstimates_+3A_viridis.option">viridis.option</code></td>
<td>
<p>viridis color scheme</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot containing map of small area posterior summary statistics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(DemoData2)
data(DemoMap2)
library(survey)
des0 &lt;- svydesign(ids = ~clustid+id, strata = ~strata,
                  weights = ~weights, data = DemoData2, nest = TRUE)
Xmat &lt;- aggregate(age~region, data = DemoData2, FUN = mean)
geo.data &lt;- sf::st_as_sf(DemoMap2$geo)
geo.data$domain &lt;- geo.data$REGNAME
cts.res &lt;- smoothArea(tobacco.use ~ 1,
                      domain = ~region,
                      design = des0,
                      adj.mat = DemoMap2$Amat, 
                      pc.u = 1,
                      pc.alpha = 0.01,
                      pc.u.phi = 0.5,
                      pc.alpha.phi = 2/3,
                      return.samples = TRUE)
mapEstimates(cts.res, geo.data = geo.data, variable = "median")
mapEstimates(cts.res, geo.data = geo.data, variable = "var")

## End(Not run)
</code></pre>

<hr>
<h2 id='mapPlot'>Plot region-level variables on a map</h2><span id='topic+mapPlot'></span>

<h3>Description</h3>

<p>This function visualizes the map with different variables. The input data frame can be either the long or wide format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mapPlot(
  data = NULL,
  variables,
  values = NULL,
  labels = NULL,
  geo,
  by.data,
  by.geo,
  is.long = FALSE,
  size = 0.5,
  removetab = FALSE,
  border = "gray20",
  ncol = NULL,
  ylim = NULL,
  legend.label = NULL,
  per1000 = FALSE,
  clean = TRUE,
  size.label = 2,
  add.adj = FALSE,
  color.adj = "red",
  alpha.adj = 0.85,
  direction = 1,
  cut = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mapPlot_+3A_data">data</code></td>
<td>
<p>a data frame with variables to be plotted. When it is null, a map is produced.</p>
</td></tr>
<tr><td><code id="mapPlot_+3A_variables">variables</code></td>
<td>
<p>vector of variables to be plotted. If long format of data is used, only one variable can be selected</p>
</td></tr>
<tr><td><code id="mapPlot_+3A_values">values</code></td>
<td>
<p>the column corresponding to the values to be plotted, only used when long format of data is used</p>
</td></tr>
<tr><td><code id="mapPlot_+3A_labels">labels</code></td>
<td>
<p>vector of labels to use for each variable, only used when wide format of data is used</p>
</td></tr>
<tr><td><code id="mapPlot_+3A_geo">geo</code></td>
<td>
<p>SpatialPolygonsDataFrame object for the map</p>
</td></tr>
<tr><td><code id="mapPlot_+3A_by.data">by.data</code></td>
<td>
<p>column name specifying region names in the data</p>
</td></tr>
<tr><td><code id="mapPlot_+3A_by.geo">by.geo</code></td>
<td>
<p>variable name specifying region names in the data</p>
</td></tr>
<tr><td><code id="mapPlot_+3A_is.long">is.long</code></td>
<td>
<p>logical indicator of whether the data is in the long format, default to FALSE</p>
</td></tr>
<tr><td><code id="mapPlot_+3A_size">size</code></td>
<td>
<p>size of the border</p>
</td></tr>
<tr><td><code id="mapPlot_+3A_removetab">removetab</code></td>
<td>
<p>logical indicator to not show the tab label, only applicable when only one tab is present.</p>
</td></tr>
<tr><td><code id="mapPlot_+3A_border">border</code></td>
<td>
<p>color of the border</p>
</td></tr>
<tr><td><code id="mapPlot_+3A_ncol">ncol</code></td>
<td>
<p>number of columns for the output tabs</p>
</td></tr>
<tr><td><code id="mapPlot_+3A_ylim">ylim</code></td>
<td>
<p>range of the values to be plotted.</p>
</td></tr>
<tr><td><code id="mapPlot_+3A_legend.label">legend.label</code></td>
<td>
<p>Label for the color legend.</p>
</td></tr>
<tr><td><code id="mapPlot_+3A_per1000">per1000</code></td>
<td>
<p>logical indicator to plot mortality rates as rates per 1,000 live births. Note that the added comparison data should always be in the probability scale.</p>
</td></tr>
<tr><td><code id="mapPlot_+3A_clean">clean</code></td>
<td>
<p>remove all coordinates for a cleaner layout, default to TRUE.</p>
</td></tr>
<tr><td><code id="mapPlot_+3A_size.label">size.label</code></td>
<td>
<p>size of the label of the regions.</p>
</td></tr>
<tr><td><code id="mapPlot_+3A_add.adj">add.adj</code></td>
<td>
<p>logical indicator to add edges between connected regions.</p>
</td></tr>
<tr><td><code id="mapPlot_+3A_color.adj">color.adj</code></td>
<td>
<p>color of the adjacency matrix edges.</p>
</td></tr>
<tr><td><code id="mapPlot_+3A_alpha.adj">alpha.adj</code></td>
<td>
<p>alpha level (transparency) of the adjacency matrix edges.</p>
</td></tr>
<tr><td><code id="mapPlot_+3A_direction">direction</code></td>
<td>
<p>Direction of the color scheme. It can be either 1 (smaller values are darker) or -1 (higher values are darker). Default is set to 1.</p>
</td></tr>
<tr><td><code id="mapPlot_+3A_cut">cut</code></td>
<td>
<p>a vector of values to cut the continuous scale color to discrete intervals.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zehang Richard Li
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(DemoMap)
# Plotting data in the long format
dat &lt;- data.frame(region = rep(c("central",  "eastern", "northern", "western"), 3),
year = rep(c(1980, 1990, 2000), each = 4),
values = stats::rnorm(12))
utils::head(dat)
mapPlot(dat, variables = "year", values = "values",
by.data = "region", geo = DemoMap$geo,
by.geo = "NAME_final", is.long = TRUE)
dat &lt;- data.frame(region = c("central",  "eastern", "northern", "western"),
Year1 = stats::rnorm(4), Year2 = stats::rnorm(4),
Year3 = stats::rnorm(4))
utils::head(dat)
mapPlot(dat, variables = c("Year1", "Year2", "Year3"),
 labels = c(1980, 1990, 2000),
by.data = "region", geo = DemoMap$geo,
by.geo = "NAME_final", is.long = FALSE)


## End(Not run)

</code></pre>

<hr>
<h2 id='mapPoints'>Map GPS points to polygon regions</h2><span id='topic+mapPoints'></span>

<h3>Description</h3>

<p>Map GPS points to polygon regions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mapPoints(data, geo, long, lat, names)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mapPoints_+3A_data">data</code></td>
<td>
<p>point data with two columns of GPS locations.</p>
</td></tr>
<tr><td><code id="mapPoints_+3A_geo">geo</code></td>
<td>
<p>SpatialPolygonsDataFrame of the map</p>
</td></tr>
<tr><td><code id="mapPoints_+3A_long">long</code></td>
<td>
<p>column name for longitudinal coordinate in the data</p>
</td></tr>
<tr><td><code id="mapPoints_+3A_lat">lat</code></td>
<td>
<p>column name for latitude coordinate in the data</p>
</td></tr>
<tr><td><code id="mapPoints_+3A_names">names</code></td>
<td>
<p>character vector of region ids to be added to the neighbours list</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Spatial djacency matrix.
</p>


<h3>Author(s)</h3>

<p>Zehang Richard Li
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(DemoMap) 
dat &lt;- data.frame(ID = c(1,2,3), lon = c(32.2, 33.7, 33), lat = c(0.1, 0.9, 2.8))
dat2 &lt;- mapPoints(dat, DemoMap$geo, long = "lon", lat = "lat", names = "REGNAME")
dat2
 
</code></pre>

<hr>
<h2 id='plot.SUMMERproj'>Plot projection output.</h2><span id='topic+plot.SUMMERproj'></span>

<h3>Description</h3>

<p>Plot projection output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SUMMERproj'
plot(
  x,
  year.label = c("85-89", "90-94", "95-99", "00-04", "05-09", "10-14", "15-19"),
  year_label = deprecated(),
  year.med = c(1987, 1992, 1997, 2002, 2007, 2012, 2017),
  year_med = deprecated(),
  is.subnational = TRUE,
  year.proj = 2015,
  proj_year = deprecated(),
  data.add = NULL,
  option.add = list(point = NULL, lower = NULL, upper = NULL, by = NULL),
  color.add = "black",
  label.add = NULL,
  dodge.width = 0.5,
  plot.CI = NULL,
  per1000 = FALSE,
  color.CI = NULL,
  alpha.CI = 0.5,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.SUMMERproj_+3A_x">x</code></td>
<td>
<p>output from <code><a href="#topic+getSmoothed">getSmoothed</a></code></p>
</td></tr>
<tr><td><code id="plot.SUMMERproj_+3A_year.label">year.label</code></td>
<td>
<p>labels for the periods</p>
</td></tr>
<tr><td><code id="plot.SUMMERproj_+3A_year_label">year_label</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> replaced by year.label</p>
</td></tr>
<tr><td><code id="plot.SUMMERproj_+3A_year.med">year.med</code></td>
<td>
<p>labels for the middle years in each period, only used when both yearly and period estimates are plotted. In that case, <code>year.med</code> specifies where each period estimates are aligned.</p>
</td></tr>
<tr><td><code id="plot.SUMMERproj_+3A_year_med">year_med</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> replaced by year.med</p>
</td></tr>
<tr><td><code id="plot.SUMMERproj_+3A_is.subnational">is.subnational</code></td>
<td>
<p>logical indicator of whether the data contains subnational estimates</p>
</td></tr>
<tr><td><code id="plot.SUMMERproj_+3A_year.proj">year.proj</code></td>
<td>
<p>the first year where projections are made, i.e., where no data are available.</p>
</td></tr>
<tr><td><code id="plot.SUMMERproj_+3A_proj_year">proj_year</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> replaced by year.proj</p>
</td></tr>
<tr><td><code id="plot.SUMMERproj_+3A_data.add">data.add</code></td>
<td>
<p>data frame for the Comparisons data points to add to the graph. This can be, for example, the raw direct estimates. This data frame is merged to the projections by column 'region' and 'years'. Except for these two columns, this dataset should not have Comparisons columns with names overlapping the getSmoothed output.</p>
</td></tr>
<tr><td><code id="plot.SUMMERproj_+3A_option.add">option.add</code></td>
<td>
<p>list of options specifying the variable names for the points to plot, lower and upper bounds, and the grouping variable. This is intended to be used to add Comparisons estimates on the same plot as the smoothed estimates. See examples for details.</p>
</td></tr>
<tr><td><code id="plot.SUMMERproj_+3A_color.add">color.add</code></td>
<td>
<p>the color of the Comparisons data points to plot.</p>
</td></tr>
<tr><td><code id="plot.SUMMERproj_+3A_label.add">label.add</code></td>
<td>
<p>the label of the Comparisons data points in the legend.</p>
</td></tr>
<tr><td><code id="plot.SUMMERproj_+3A_dodge.width">dodge.width</code></td>
<td>
<p>the amount to add to data points at the same year to avoid overlap. Default to be 0.5.</p>
</td></tr>
<tr><td><code id="plot.SUMMERproj_+3A_plot.ci">plot.CI</code></td>
<td>
<p>logical indicator of whether to plot the error bars.</p>
</td></tr>
<tr><td><code id="plot.SUMMERproj_+3A_per1000">per1000</code></td>
<td>
<p>logical indicator to plot mortality rates as rates per 1,000 live births. Note that the added comparison data should always be in the probability scale.</p>
</td></tr>
<tr><td><code id="plot.SUMMERproj_+3A_color.ci">color.CI</code></td>
<td>
<p>the color of the error bars of the credible interval.</p>
</td></tr>
<tr><td><code id="plot.SUMMERproj_+3A_alpha.ci">alpha.CI</code></td>
<td>
<p>the alpha (transparency) of the error bars of the credible interval.</p>
</td></tr>
<tr><td><code id="plot.SUMMERproj_+3A_...">...</code></td>
<td>
<p>optional arguments, see details</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zehang Richard Li
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getSmoothed">getSmoothed</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
years &lt;- levels(DemoData[[1]]$time)

# obtain direct estimates
data &lt;- getDirectList(births = DemoData, 
years = years,  
regionVar = "region", timeVar = "time", 
clusterVar = "~clustid+id", 
ageVar = "age", weightsVar = "weights", 
geo.recode = NULL)
# obtain direct estimates
data_multi &lt;- getDirectList(births = DemoData, years = years,
  regionVar = "region",  timeVar = "time", clusterVar = "~clustid+id",
  ageVar = "age", weightsVar = "weights", geo.recode = NULL)
data &lt;- aggregateSurvey(data_multi)

#  national model
years.all &lt;- c(years, "15-19")
fit1 &lt;- smoothDirect(data = data, geo = NULL, Amat = NULL, 
  year.label = years.all, year.range = c(1985, 2019), 
  rw = 2, is.yearly=FALSE, m = 5)
out1 &lt;- getSmoothed(fit1)
plot(out1, is.subnational=FALSE)

#  subnational model
fit2 &lt;- smoothDirect(data = data, geo = geo, Amat = mat, 
  year.label = years.all, year.range = c(1985, 2019), 
  rw = 2, is.yearly=TRUE, m = 5, type.st = 4)
out2 &lt;- getSmoothed(fit2)
plot(out2, is.yearly=TRUE, is.subnational=TRUE)



## End(Not run)

</code></pre>

<hr>
<h2 id='poppRegionFromPopMat'>Generate a population frame of a similar format to poppa argument of <code><a href="#topic+simPopCustom">simPopCustom</a></code> with a custom set of regions</h2><span id='topic+poppRegionFromPopMat'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>poppRegionFromPopMat(pop.mat, regions)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="poppRegionFromPopMat_+3A_pop.mat">pop.mat</code></td>
<td>
<p>Pixellated grid data frame with variables <code>area</code> and <code>pop</code>. Assumed to be stratified by urban/rural</p>
</td></tr>
<tr><td><code id="poppRegionFromPopMat_+3A_regions">regions</code></td>
<td>
<p>character vector of length nPixels giving a custom set of regions for which to generate
a population frame using population density</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Urbanicity thresholds are set based on that region's percent population
urban. Intended as a helper function of <code><a href="#topic+getPoppsub">getPoppsub</a></code>, but
can also be used for custom sets of regions (i.e. more than just 2
areal levels: area and subarea).
</p>


<h3>Value</h3>

<p>A table of population totals by region
</p>


<h3>Author(s)</h3>

<p>John Paige
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getPoppsub">getPoppsub</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(kenyaPopulationData)

#' # download Kenya GADM shapefiles from SUMMERdata github repository
githubURL &lt;- "https://github.com/paigejo/SUMMERdata/blob/main/data/kenyaMaps.rda?raw=true"
tempDirectory = "~/"
mapsFilename = paste0(tempDirectory, "/kenyaMaps.rda")
if(!file.exists(mapsFilename)) {
  download.file(githubURL,mapsFilename)
}

# load it in
out = load(mapsFilename)
out
kenyaMesh &lt;- fmesher::fm_as_fm(kenyaMesh)
adm1@data$NAME_1 = as.character(adm1@data$NAME_1)
adm1@data$NAME_1[adm1@data$NAME_1 == "Trans Nzoia"] = "Trans-Nzoia"
adm1@data$NAME_1[adm1@data$NAME_1 == "Elgeyo-Marakwet"] = "Elgeyo Marakwet"
adm2@data$NAME_1 = as.character(adm2@data$NAME_1)
adm2@data$NAME_1[adm2@data$NAME_1 == "Trans Nzoia"] = "Trans-Nzoia"
adm2@data$NAME_1[adm2@data$NAME_1 == "Elgeyo-Marakwet"] = "Elgeyo Marakwet"

# some Admin-2 areas have the same name
adm2@data$NAME_2 = as.character(adm2@data$NAME_2)
adm2@data$NAME_2[(adm2@data$NAME_1 == "Bungoma") &amp; 
  (adm2@data$NAME_2 == "Lugari")] = "Lugari, Bungoma"
adm2@data$NAME_2[(adm2@data$NAME_1 == "Kakamega") &amp; 
  (adm2@data$NAME_2 == "Lugari")] = "Lugari, Kakamega"
adm2@data$NAME_2[(adm2@data$NAME_1 == "Meru") &amp; 
  (adm2@data$NAME_2 == "Igembe South")] = "Igembe South, Meru"
adm2@data$NAME_2[(adm2@data$NAME_1 == "Tharaka-Nithi") &amp; 
  (adm2@data$NAME_2 == "Igembe South")] = "Igembe South, Tharaka-Nithi"

# The spatial area of unknown 8 is so small, it causes problems unless 
# its removed or unioned with another subarea. Union it with neighboring 
# Kakeguria:
newadm2 = adm2
unknown8I = which(newadm2$NAME_2 == "unknown 8")
newadm2$NAME_2[newadm2$NAME_2 %in% c("unknown 8", "Kapenguria")] &lt;- "Kapenguria + unknown 8"
admin2.IDs &lt;- newadm2$NAME_2

newadm2@data = cbind(newadm2@data, NAME_2OLD = newadm2@data$NAME_2)
newadm2@data$NAME_2OLD = newadm2@data$NAME_2
newadm2@data$NAME_2 = admin2.IDs
newadm2$NAME_2 = admin2.IDs
temp &lt;- terra::aggregate(as(newadm2, "SpatVector"), by="NAME_2")

library(sf)
temp &lt;- sf::st_as_sf(temp)
temp &lt;- sf::as_Spatial(temp)

tempData = newadm2@data[-unknown8I,]
tempData = tempData[order(tempData$NAME_2),]
newadm2 &lt;- SpatialPolygonsDataFrame(temp, tempData, match.ID = F)
adm2 = newadm2

# download 2014 Kenya population density TIF file

githubURL &lt;- paste0("https://github.com/paigejo/SUMMERdata/blob/main/data/", 
                    "Kenya2014Pop/worldpop_total_1y_2014_00_00.tif?raw=true")
popTIFFilename = paste0(tempDirectory, "/worldpop_total_1y_2014_00_00.tif")
if(!file.exists(popTIFFilename)) {
  download.file(githubURL,popTIFFilename)
}

# load it in
pop = terra::rast(popTIFFilename)

east.lim = c(-110.6405, 832.4544)
north.lim = c(-555.1739, 608.7130)

require(fields)
#' 
# Now generate a general population integration table at 5km resolution, 
# based on subarea (Admin-2) x urban/rural population totals. This takes 
# ~1 minute
pop.matKenya &lt;- makePopIntegrationTab(
  km.res=5, pop=pop, domain.map.dat=adm0,
  east.lim=east.lim, north.lim=north.lim, map.projection=projKenya,
  poppa = poppaKenya, poppsub=poppsubKenya, 
  area.map.dat = adm1, subarea.map.dat = adm2,
  areaNameVar = "NAME_1", subareaNameVar="NAME_2")
  
out = poppRegionFromPopMat(pop.matKenya, pop.matKenya$area)
out
poppaKenya

out = poppRegionFromPopMat(pop.matKenya, pop.matKenya$subarea)
out
poppsubKenya

pop.matKenyaUnstratified = pop.matKenya
pop.matKenyaUnstratified$urban = NULL
out = poppRegionFromPopMat(pop.matKenyaUnstratified, pop.matKenyaUnstratified$area)
out
poppaKenya

## End(Not run)
</code></pre>

<hr>
<h2 id='print.SUMMERmodel'>Print method for the smoothing models.</h2><span id='topic+print.SUMMERmodel'></span>

<h3>Description</h3>

<p>This function is the print method for class <code>SUMMERmodel</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SUMMERmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.SUMMERmodel_+3A_x">x</code></td>
<td>
<p>output from <code><a href="#topic+smoothDirect">smoothDirect</a></code> or <code><a href="#topic+smoothCluster">smoothCluster</a></code></p>
</td></tr>
<tr><td><code id="print.SUMMERmodel_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zehang Li
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.SUMMERmodel">summary.SUMMERmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  library(SUMMER)
  library(dplyr)
  data(DemoData)

  # Smooth Direct Model
  years &lt;- levels(DemoData[[1]]$time)
  # obtain direct estimates
  data_multi &lt;- getDirectList(births = DemoData, years = years,
  regionVar = "region",  timeVar = "time", clusterVar = "~clustid+id",
  ageVar = "age", weightsVar = "weights", geo.recode = NULL)
  data &lt;- aggregateSurvey(data_multi)
  
  years.all &lt;- c(years, "15-19")
  fit &lt;- smoothDirect(data = data, Amat = NULL, 
  year.label = years.all, year.range = c(1985, 2019), 
  time.model = 'rw2', is.yearly=FALSE, m = 5)
  fit

  # Cluster-level Model
  counts.all &lt;- NULL
  for(i in 1:length(DemoData)){
  counts &lt;- getCounts(DemoData[[i]][, c("clustid", "time", "age", "died",
                                       "region", "strata")],
           variables = 'died', by = c("age", "clustid", "region", 
                                        "time", "strata"))
  counts &lt;- counts %&gt;% mutate(cluster = clustid, years = time, Y=died)
  counts$strata &lt;- gsub(".*\\.","",counts$strata)
  counts$survey &lt;- names(DemoData)[i] 
  counts.all &lt;- rbind(counts.all, counts)
  }
  
  # fit cluster-level model on the periods
  periods &lt;- levels(DemoData[[1]]$time)
  fit &lt;- smoothCluster(data = counts.all, 
     Amat = DemoMap$Amat, 
     time.model = "rw2", 
     st.time.model = "rw1",
     strata.time.effect =  TRUE, 
     survey.effect = TRUE,
     family = "betabinomial",
     year.label = c(periods, "15-19"))
  fit

## End(Not run)
</code></pre>

<hr>
<h2 id='print.SUMMERmodel.svy'>Print method for the smoothing models from <code>smoothSurvey</code>.</h2><span id='topic+print.SUMMERmodel.svy'></span>

<h3>Description</h3>

<p>This function is the print method for class <code>SUMMERmodel.svy</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SUMMERmodel.svy'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.SUMMERmodel.svy_+3A_x">x</code></td>
<td>
<p>output from <code><a href="#topic+smoothSurvey">smoothSurvey</a></code>.</p>
</td></tr>
<tr><td><code id="print.SUMMERmodel.svy_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zehang Li
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.SUMMERmodel.svy">summary.SUMMERmodel.svy</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(DemoData2)
data(DemoMap2)
fit0 &lt;- smoothSurvey(data=DemoData2,  
Amat=DemoMap2$Amat, responseType="binary", 
responseVar="tobacco.use", strataVar="strata", 
weightVar="weights", regionVar="region", 
clusterVar = "~clustid+id", CI = 0.95)
fit0

## End(Not run)
</code></pre>

<hr>
<h2 id='print.SUMMERprojlist'>Print method for the combined projection output.</h2><span id='topic+print.SUMMERprojlist'></span>

<h3>Description</h3>

<p>This function is the print method for class <code>SUMMERprojlist</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SUMMERprojlist'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.SUMMERprojlist_+3A_x">x</code></td>
<td>
<p>output from <code><a href="#topic+getSmoothed">getSmoothed</a></code></p>
</td></tr>
<tr><td><code id="print.SUMMERprojlist_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zehang Li
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
 library(SUMMER)
 library(dplyr)
 data(DemoData)
 # Create dataset of counts
 counts.all &lt;- NULL
 for(i in 1:length(DemoData)){
 counts &lt;- getCounts(DemoData[[i]][, c("clustid", "time", "age", "died",
                                      "region", "strata")],
          variables = 'died', by = c("age", "clustid", "region", 
                                       "time", "strata"))
 counts &lt;- counts %&gt;% mutate(cluster = clustid, years = time, Y=died)
 counts$strata &lt;- gsub(".*\\.","",counts$strata)
 counts$survey &lt;- names(DemoData)[i] 
 counts.all &lt;- rbind(counts.all, counts)
 }
 
 # fit cluster-level model on the periods
 periods &lt;- levels(DemoData[[1]]$time)
 fit &lt;- smoothCluster(data = counts.all, 
    Amat = DemoMap$Amat, 
    time.model = "rw2", 
    st.time.model = "rw1",
    strata.time.effect =  TRUE, 
    survey.effect = TRUE,
    family = "betabinomial",
    year.label = c(periods, "15-19"))
 summary(fit)
 est &lt;- getSmoothed(fit, nsim = 1000)

## End(Not run)
</code></pre>

<hr>
<h2 id='projKenya'>Map projection for Kenya</h2><span id='topic+projKenya'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>projKenya(lon, lat = NULL, inverse = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="projKenya_+3A_lon">lon</code></td>
<td>
<p>either longitude or, if inverse == TRUE, easting in km</p>
</td></tr>
<tr><td><code id="projKenya_+3A_lat">lat</code></td>
<td>
<p>either latitude or, if inverse == TRUE, northing in km</p>
</td></tr>
<tr><td><code id="projKenya_+3A_inverse">inverse</code></td>
<td>
<p>if FALSE, projects from lon/lat to easting/northing.  Else from easting/northing to lon/lat</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Projection specifically chosen for Kenya. Project from lat/lon to northing/easting
in kilometers.  Uses epsg=21097 with km units. May not work on all systems due to
differences in the behavior between different PROJ and GDAL versions.
</p>


<h3>Value</h3>

<p>A 2 column matrix of easting/northing coordinates in km if inverse == FALSE. Otherwise, a 2 column matrix of longitude/latitude coordinates.
</p>


<h3>Author(s)</h3>

<p>John Paige
</p>


<h3>Examples</h3>

<pre><code class='language-R'>eastLim = c(-110.6405, 832.4544)
northLim = c(-555.1739, 608.7130)
coordMatrixEN = cbind(eastLim, northLim)
coordMatrixLL = projKenya(coordMatrixEN, inverse=TRUE)

coordMatrixLL
# if the coordMatrixLL isn't the following, projKenya may not support 
# your installation of GDAL and/or PROJ:
#      east north
# [1,] 33.5  -5.0
# [2,] 42.0   5.5

projKenya(coordMatrixLL, inverse=FALSE)
# regardless of your PROJ/GDAL installations, the result of the 
# above line of could should be:
#            lon       lat
# [1,] -110.6405 -555.1739
# [2,]  832.4544  608.7130

</code></pre>

<hr>
<h2 id='ridgePlot'>Calculate and plot posterior densities of the projected estimates</h2><span id='topic+ridgePlot'></span>

<h3>Description</h3>

<p>The function <code>ridgePlot</code> replaces the previous function name <code>getSmoothedDensity</code> (before version 1.0.0).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ridgePlot(
  x = NULL,
  nsim = 1000,
  draws = NULL,
  year.plot = NULL,
  year_plot = deprecated(),
  strata.plot = NULL,
  strata_plot = deprecated(),
  by.year = TRUE,
  ncol = 4,
  scale = 2,
  per1000 = FALSE,
  order = 0,
  direction = 1,
  linewidth = 0.5,
  results = NULL,
  save.density = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ridgePlot_+3A_x">x</code></td>
<td>
<p>output from <code><a href="#topic+smoothDirect">smoothDirect</a></code> for the smoothed direct estimates, or <code><a href="#topic+smoothCluster">smoothCluster</a></code> for the cluster-level estimates.</p>
</td></tr>
<tr><td><code id="ridgePlot_+3A_nsim">nsim</code></td>
<td>
<p>number of posterior draws to take. Only used for cluster-level models when <code>draws</code> is NULL. Otherwise the posterior draws in <code>draws</code> will be used instead without resampling.</p>
</td></tr>
<tr><td><code id="ridgePlot_+3A_draws">draws</code></td>
<td>
<p>Output of <code><a href="#topic+getSmoothed">getSmoothed</a></code> with <code>save.draws</code> set to TRUE. This argument allows the previously sampled draws (by setting <code>save.draws</code> to be TRUE) be used in new aggregation tasks. This argument is only used for cluster-level models.</p>
</td></tr>
<tr><td><code id="ridgePlot_+3A_year.plot">year.plot</code></td>
<td>
<p>A vector indicate which years to plot</p>
</td></tr>
<tr><td><code id="ridgePlot_+3A_year_plot">year_plot</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> replaced by year.plot</p>
</td></tr>
<tr><td><code id="ridgePlot_+3A_strata.plot">strata.plot</code></td>
<td>
<p>Name of the strata to plot. If not specified, the overall is plotted.</p>
</td></tr>
<tr><td><code id="ridgePlot_+3A_strata_plot">strata_plot</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> replaced by strata.plot</p>
</td></tr>
<tr><td><code id="ridgePlot_+3A_by.year">by.year</code></td>
<td>
<p>logical indicator for whether the output uses years as facets.</p>
</td></tr>
<tr><td><code id="ridgePlot_+3A_ncol">ncol</code></td>
<td>
<p>number of columns in the output figure.</p>
</td></tr>
<tr><td><code id="ridgePlot_+3A_scale">scale</code></td>
<td>
<p>numerical value controlling the height of the density plots.</p>
</td></tr>
<tr><td><code id="ridgePlot_+3A_per1000">per1000</code></td>
<td>
<p>logical indicator to multiply results by 1000.</p>
</td></tr>
<tr><td><code id="ridgePlot_+3A_order">order</code></td>
<td>
<p>order of regions when by.year is set to TRUE. Negative values indicate regions are ordered from high to low posterior medians from top to bottom. Positive values indicate from low to high. 0 indicate alphabetic orders.</p>
</td></tr>
<tr><td><code id="ridgePlot_+3A_direction">direction</code></td>
<td>
<p>Direction of the color scheme. It can be either 1 (smaller values are darker) or -1 (higher values are darker). Default is set to 1.</p>
</td></tr>
<tr><td><code id="ridgePlot_+3A_linewidth">linewidth</code></td>
<td>
<p>width of the ridgeline.</p>
</td></tr>
<tr><td><code id="ridgePlot_+3A_results">results</code></td>
<td>
<p>output from <code><a href="#topic+ridgePlot">ridgePlot</a></code> returned object with <code>save.density = TRUE</code>. This argument can be specified to avoid calculating densities again when only the visualization changes.</p>
</td></tr>
<tr><td><code id="ridgePlot_+3A_save.density">save.density</code></td>
<td>
<p>Logical indicator of whether the densities will be returned with the ggplot object. If set to TRUE, the output will be a list consisting of (1) a data frame of computed densities and (2) a ggplot object of the plot.</p>
</td></tr>
<tr><td><code id="ridgePlot_+3A_...">...</code></td>
<td>
<p>additional configurations passed to inla.posterior.sample.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ridge plot of the density, and  if <code>save.density = TRUE</code>, also a data frame of the calculated densities
</p>


<h3>Author(s)</h3>

<p>Zehang Richard Li
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.SUMMERproj">plot.SUMMERproj</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
years &lt;- levels(DemoData[[1]]$time)

data &lt;- getDirectList(births = DemoData, 
years = years,  
regionVar = "region", timeVar = "time", 
clusterVar = "~clustid+id", 
ageVar = "age", weightsVar = "weights", 
geo.recode = NULL)
# obtain direct estimates
data_multi &lt;- getDirectList(births = DemoData, years = years,
  regionVar = "region",  timeVar = "time", clusterVar = "~clustid+id",
  ageVar = "age", weightsVar = "weights", geo.recode = NULL)
data &lt;- aggregateSurvey(data_multi)

#  national model
years.all &lt;- c(years, "15-19")
fit1 &lt;- smoothDirect(data = data, geo = NULL, Amat = NULL, 
  year.label = years.all, year.range = c(1985, 2019), 
  rw = 2, m = 5)
## Plot marginal posterior densities over time
ridgePlot(fit1, year.plot = years.all, 
          ncol = 4, by.year = FALSE)

#  subnational model
fit2 &lt;- smoothDirect(data = data, geo = DemoMap$geo, Amat = DemoMap$Amat, 
  year.label = years.all, year.range = c(1985, 2019), 
  rw = 2, m = 5, type.st = 1)

# Plot marginal posterior densities over time (regions are ordered alphabetically)
ridgePlot(fit2, year.plot = years.all, ncol = 4)

# Re-order the regions and save the density to avoid re-compute later
density &lt;- ridgePlot(fit2, year.plot = years.all,
 ncol = 4, per1000 = TRUE, order = -1, save.density = TRUE)
density$g

# Show each region (instead of each year) in a panel 
## Instead of recalculate the posteriors, we can use previously calculated densities as input 
ridgePlot(results = density, year.plot = years.all, 
ncol = 4, by.year=FALSE, per1000 = TRUE)

# Show more years
ridgePlot(results = density, year.plot = c(1990:2019), 
ncol = 4, by.year=FALSE, per1000 = TRUE)


# Example using surveyPrev package output

library(surveyPrev)
dhsData &lt;- getDHSdata(country = "Rwanda", indicator = "nmr", year = 2019)
data &lt;- getDHSindicator(dhsData, indicator = "nmr")
geo &lt;- getDHSgeo(country = "Rwanda", year = 2019)
poly.adm1 &lt;- geodata::gadm(country="RWA", level=1, path=tempdir())
poly.adm1 &lt;- sf::st_as_sf(poly.adm1)
poly.adm2 &lt;- geodata::gadm(country="RWA", level=2, path=tempdir())
poly.adm2 &lt;- sf::st_as_sf(poly.adm2)
cluster.info &lt;- clusterInfo(geo = geo, 
              poly.adm1 = poly.adm1, 
              poly.adm2 = poly.adm2,
                            by.adm1 = "NAME_1", 
                            by.adm2 = "NAME_2")

fit1 &lt;- directEST(data = data, cluster.info = cluster.info,  admin = 1)
fit2 &lt;- directEST(data = data, cluster.info = cluster.info,  admin = 2) 
ridgePlot(fit1, direction = -1)
ridgePlot(fit2, direction = -1)


## End(Not run)

</code></pre>

<hr>
<h2 id='rst'>Simulate spatial and temporal random effects</h2><span id='topic+rst'></span>

<h3>Description</h3>

<p>This function simulates spatial and temporal random effects with mean zero. The method is described in Algorithm 3.1 of Rue &amp; Held 2015.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rst(
  n = 1,
  type = c("s", "t", "st")[1],
  type.s = "ICAR",
  type.t = c("RW1", "RW2")[2],
  Amat = NULL,
  n.t = NULL,
  scale.model = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rst_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="rst_+3A_type">type</code></td>
<td>
<p>type of random effects: temporal (t), spatial (s), or spatial-temporal (st)</p>
</td></tr>
<tr><td><code id="rst_+3A_type.s">type.s</code></td>
<td>
<p>type of spatial random effect, currently only ICAR is available</p>
</td></tr>
<tr><td><code id="rst_+3A_type.t">type.t</code></td>
<td>
<p>type of temporal random effect, currently only RW1 and RW2 are available</p>
</td></tr>
<tr><td><code id="rst_+3A_amat">Amat</code></td>
<td>
<p>adjacency matrix for the spatial regions</p>
</td></tr>
<tr><td><code id="rst_+3A_n.t">n.t</code></td>
<td>
<p>number of time points for the temporal random effect</p>
</td></tr>
<tr><td><code id="rst_+3A_scale.model">scale.model</code></td>
<td>
<p>logical indicator of whether to scale the random effects to have unit generalized variance. See Sørbye 2013 for more details</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix (for spatial or temporal) or a three-dimensional array (for spatial-temporal) of the random effects.
</p>


<h3>Author(s)</h3>

<p>Zehang Richard Li
</p>


<h3>References</h3>

<p>Rue, H., &amp; Held, L. (2005). <em>Gaussian Markov random fields: theory and applications</em>. CRC press.
</p>
<p>Sørbye, S. H. (2013). <em>Tutorial: Scaling IGMRF-models in R-INLA</em>. Department of Mathematics and Statistics, University of Tromsø.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(DemoMap)
## Spatial random effects 
out &lt;- rst(n=10000, type = "s", Amat = DemoMap$Amat)
# To verify the mean under the conditional specification
mean(out[,1] - apply(out[,c(2,3,4)], 1, mean))  
mean(out[,2] - apply(out[,c(1,3)], 1, mean)) 
mean(out[,3] - apply(out[,c(1,2,4)], 1, mean))  
mean(out[,4] - apply(out[,c(1,3)], 1, mean)) 

## Temporal random effects (RW1)
out &lt;- rst(n=1, type = "t", type.t = "RW1", n.t = 200, scale.model = FALSE)
par(mfrow = c(1,2))
plot(1:dim(out)[2], out, col = 1, type = "l", xlab = "Time", ylab = "Random effects")
# verify the first order difference is normally distributed
first_diff &lt;- diff(as.numeric(out[1,]))
qqnorm(first_diff )	
abline(c(0,1))

## Temporal random effects (RW2)
out &lt;- rst(n=1, type = "t", type.t = "RW2", n.t = 200, scale.model = FALSE)
par(mfrow = c(1,2))
plot(1:dim(out)[2], out, col = 1, type = "l", xlab = "Time", ylab = "Random effects")
# verify the second order difference is normally distributed
first_diff &lt;- diff(as.numeric(out[1,]))
second_diff &lt;- diff(first_diff)
qqnorm(second_diff)	
abline(c(0,1))

## Spatial-temporal random effects
out &lt;- rst(n=1, type = "st", type.t = "RW2", Amat = DemoMap$Amat, n.t = 50)
dimnames(out)
par(mfrow = c(1,1))
plot(1:dim(out)[3], out[1,1,], col = 1,
 type = "l", ylim = range(out), xlab = "Time", ylab = "Random effects")
for(i in 2:4) lines(1:dim(out)[3], out[1,i,], col = i)
legend("bottomright", colnames(DemoMap$Amat), col = c(1:4), lty = rep(1,4))

## End(Not run)

</code></pre>

<hr>
<h2 id='rw.new'>New random walk 1 and 2 models for m-year to period random effects</h2><span id='topic+rw.new'></span>

<h3>Description</h3>

<p>New random walk 1 and 2 models for m-year to period random effects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rw.new(
  cmd = c("graph", "Q", "mu", "initial", "log.norm.const", "log.prior", "quit"),
  theta = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rw.new_+3A_cmd">cmd</code></td>
<td>
<p>list of model components</p>
</td></tr>
<tr><td><code id="rw.new_+3A_theta">theta</code></td>
<td>
<p>log precision</p>
</td></tr>
</table>

<hr>
<h2 id='rw.new.pc'>New random walk 1 and 2 models for m-year to period random effects</h2><span id='topic+rw.new.pc'></span>

<h3>Description</h3>

<p>New random walk 1 and 2 models for m-year to period random effects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rw.new.pc(
  cmd = c("graph", "Q", "mu", "initial", "log.norm.const", "log.prior", "quit"),
  theta = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rw.new.pc_+3A_cmd">cmd</code></td>
<td>
<p>list of model components</p>
</td></tr>
<tr><td><code id="rw.new.pc_+3A_theta">theta</code></td>
<td>
<p>log precision</p>
</td></tr>
</table>

<hr>
<h2 id='setThresholdsByRegion'><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a></h2><span id='topic+setThresholdsByRegion'></span>

<h3>Description</h3>

<p>Set thresholds of population density for urbanicity classifications
within each region of the given type
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setThresholdsByRegion(pop.mat, poppr, region.type = "area")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="setThresholdsByRegion_+3A_pop.mat">pop.mat</code></td>
<td>
<p>pixellated population density data frame with variables
region.type and <code>pop</code></p>
</td></tr>
<tr><td><code id="setThresholdsByRegion_+3A_poppr">poppr</code></td>
<td>
<p>A table with population totals by region of the given type
(e.g. poppa or poppsub from <code><a href="#topic+makePopIntegrationTab">makePopIntegrationTab</a></code>)</p>
</td></tr>
<tr><td><code id="setThresholdsByRegion_+3A_region.type">region.type</code></td>
<td>
<p>The variable name from poppr giving the region names.
Defaults to &quot;area&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Thresholds are set based on that region's percent population
urban. Intended as a helper function of <code><a href="#topic+makePopIntegrationTab">makePopIntegrationTab</a></code>.
</p>


<h3>Value</h3>

<p>A list of region names and their urbanicity thresholds in population density
</p>


<h3>Author(s)</h3>

<p>John Paige
</p>


<h3>See Also</h3>

<p><code><a href="#topic+makePopIntegrationTab">makePopIntegrationTab</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(kenyaPopulationData)

#' # download Kenya GADM shapefiles from SUMMERdata github repository
githubURL &lt;- "https://github.com/paigejo/SUMMERdata/blob/main/data/kenyaMaps.rda?raw=true"
tempDirectory = "~/"
mapsFilename = paste0(tempDirectory, "/kenyaMaps.rda")
if(!file.exists(mapsFilename)) {
  download.file(githubURL,mapsFilename)
}

# load it in
out = load(mapsFilename)
out
kenyaMesh &lt;- fmesher::fm_as_fm(kenyaMesh)
adm1@data$NAME_1 = as.character(adm1@data$NAME_1)
adm1@data$NAME_1[adm1@data$NAME_1 == "Trans Nzoia"] = "Trans-Nzoia"
adm1@data$NAME_1[adm1@data$NAME_1 == "Elgeyo-Marakwet"] = "Elgeyo Marakwet"
adm2@data$NAME_1 = as.character(adm2@data$NAME_1)
adm2@data$NAME_1[adm2@data$NAME_1 == "Trans Nzoia"] = "Trans-Nzoia"
adm2@data$NAME_1[adm2@data$NAME_1 == "Elgeyo-Marakwet"] = "Elgeyo Marakwet"

# some Admin-2 areas have the same name
adm2@data$NAME_2 = as.character(adm2@data$NAME_2)
adm2@data$NAME_2[(adm2@data$NAME_1 == "Bungoma") &amp; 
  (adm2@data$NAME_2 == "Lugari")] = "Lugari, Bungoma"
adm2@data$NAME_2[(adm2@data$NAME_1 == "Kakamega") &amp; 
  (adm2@data$NAME_2 == "Lugari")] = "Lugari, Kakamega"
adm2@data$NAME_2[(adm2@data$NAME_1 == "Meru") &amp; 
  (adm2@data$NAME_2 == "Igembe South")] = "Igembe South, Meru"
adm2@data$NAME_2[(adm2@data$NAME_1 == "Tharaka-Nithi") &amp; 
  (adm2@data$NAME_2 == "Igembe South")] = "Igembe South, Tharaka-Nithi"

# The spatial area of unknown 8 is so small, it causes problems unless 
# its removed or unioned with another subarea. Union it with neighboring 
# Kakeguria:
newadm2 = adm2
unknown8I = which(newadm2$NAME_2 == "unknown 8")
newadm2$NAME_2[newadm2$NAME_2 %in% c("unknown 8", "Kapenguria")] &lt;- "Kapenguria + unknown 8"
admin2.IDs &lt;- newadm2$NAME_2

newadm2@data = cbind(newadm2@data, NAME_2OLD = newadm2@data$NAME_2)
newadm2@data$NAME_2OLD = newadm2@data$NAME_2
newadm2@data$NAME_2 = admin2.IDs
newadm2$NAME_2 = admin2.IDs
temp &lt;- terra::aggregate(as(newadm2, "SpatVector"), by="NAME_2")

library(sf)
temp &lt;- sf::st_as_sf(temp)
temp &lt;- sf::as_Spatial(temp)

tempData = newadm2@data[-unknown8I,]
tempData = tempData[order(tempData$NAME_2),]
newadm2 &lt;- sp::SpatialPolygonsDataFrame(temp, tempData, match.ID = F)
adm2 = newadm2

# download 2014 Kenya population density TIF file

githubURL &lt;- paste0("https://github.com/paigejo/SUMMERdata/blob/main/data/", 
                    "Kenya2014Pop/worldpop_total_1y_2014_00_00.tif?raw=true")
popTIFFilename = paste0(tempDirectory, "/worldpop_total_1y_2014_00_00.tif")
if(!file.exists(popTIFFilename)) {
  download.file(githubURL,popTIFFilename)
}

# load it in
pop = terra::rast(popTIFFilename)

east.lim = c(-110.6405, 832.4544)
north.lim = c(-555.1739, 608.7130)

require(fields)

data(kenyaPopulationData)

# Now generate a general population integration table at 5km resolution, 
# based on subarea (Admin-2) x urban/rural population totals. This takes 
# ~1 minute
pop.matKenya &lt;- makePopIntegrationTab(
  km.res=5, pop=pop, domain.map.dat=adm0,
  east.lim=east.lim, north.lim=north.lim, map.projection=projKenya,
  poppa = poppaKenya, poppsub=poppsubKenya, 
  area.map.dat = adm1, subarea.map.dat = adm2,
  areaNameVar = "NAME_1", subareaNameVar="NAME_2")

out = setThresholdsByRegion(pop.matKenya, poppaKenya)
out

out = setThresholdsByRegion(pop.matKenya, poppsubKenya, region.type="subarea")
out

## End(Not run)

</code></pre>

<hr>
<h2 id='simhyper'>Simulate hyperpriors from an GMRF</h2><span id='topic+simhyper'></span>

<h3>Description</h3>

<p>Simulate hyperpriors from an GMRF
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simhyper(
  R = 2,
  nsamp = 1e+05,
  nsamp.check = 5000,
  Amat = NULL,
  nperiod = 6,
  only.iid = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simhyper_+3A_r">R</code></td>
<td>
<p>Desired prior odds ratio. Default to 2, i.e., a 95% prior interval for the residual odds ratios lies in the interval (R, 1/R).</p>
</td></tr>
<tr><td><code id="simhyper_+3A_nsamp">nsamp</code></td>
<td>
<p>Sample to simulate for scaling factor</p>
</td></tr>
<tr><td><code id="simhyper_+3A_nsamp.check">nsamp.check</code></td>
<td>
<p>Sample to simulate for checking range</p>
</td></tr>
<tr><td><code id="simhyper_+3A_amat">Amat</code></td>
<td>
<p>Adjacency matrix of the areas in the data.</p>
</td></tr>
<tr><td><code id="simhyper_+3A_nperiod">nperiod</code></td>
<td>
<p>numerical value of how many time periods in the data</p>
</td></tr>
<tr><td><code id="simhyper_+3A_only.iid">only.iid</code></td>
<td>
<p>Indicator for whether or not only IID hyperpriors are simulated</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zehang Richard Li, Laina Mercer
</p>


<h3>References</h3>

<p>Wakefield, J. Multi-level modelling, the ecologic fallacy, and hybrid study designs. <em>International Journal of Epidemiology</em>, 2009, vol. 38 (pg. 330-336).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(DemoMap)
mat &lt;- DemoMap$Amat
priors &lt;- simhyper(R = 2, nsamp = 1e+05, nsamp.check = 5000, Amat = mat)

## End(Not run)
</code></pre>

<hr>
<h2 id='simPop'>Simulate populations and areal prevalences</h2><span id='topic+simPop'></span><span id='topic+simPopSPDE'></span><span id='topic+simPopCustom'></span>

<h3>Description</h3>

<p>Given a spatial risk model, simulate populations and population prevalences at the
enumeration area level (represented as points), and aggregate to the pixel and
administrative areal level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simPopSPDE(
  nsim = 1,
  easpa,
  pop.mat,
  target.pop.mat,
  poppsub,
  spde.mesh,
  marg.var = 0.243,
  sigma.epsilon = sqrt(0.463),
  gamma = 0.009,
  eff.range = 406.51,
  beta0 = -3.922,
  seed = NULL,
  inla.seed = -1L,
  n.HH.sampled = 25,
  stratify.by.urban = TRUE,
  subarea.level = TRUE,
  do.fine.scale.risk = FALSE,
  do.smooth.risk = FALSE,
  do.smooth.risk.logistic.approx = FALSE,
  min1.per.subarea = TRUE
)

simPopCustom(
  logit.risk.draws,
  sigma.epsilon.draws,
  easpa,
  pop.mat,
  target.pop.mat,
  stratify.by.urban = TRUE,
  validation.pixel.I = NULL,
  validation.cluster.I = NULL,
  clusters.per.pixel = NULL,
  do.fine.scale.risk = FALSE,
  do.smooth.risk = FALSE,
  do.smooth.risk.logistic.approx = FALSE,
  poppsub = NULL,
  subarea.level = FALSE,
  min1.per.subarea = TRUE,
  return.EA.info = FALSE,
  epsc = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simPop_+3A_nsim">nsim</code></td>
<td>
<p>Number of simulations</p>
</td></tr>
<tr><td><code id="simPop_+3A_easpa">easpa</code></td>
<td>
<p>data.frame of enumeration area, households, and target population per area stratified by urban/rural with variables:
</p>

<dl>
<dt>area</dt><dd><p>name of area</p>
</dd>
<dt>EAUrb</dt><dd><p>number of urban enumeration areas in the area</p>
</dd>
<dt>EARur</dt><dd><p>number of rural enumeration areas in the area</p>
</dd>
<dt>EATotal</dt><dd><p>total number of enumeration areas in the area</p>
</dd>
<dt>HHUrb</dt><dd><p>number of urban households in the area</p>
</dd>
<dt>HHRur</dt><dd><p>number of rural households in the area</p>
</dd>
<dt>HHTotal</dt><dd><p>total number of households in the area</p>
</dd>
<dt>popUrb</dt><dd><p>total urban (target) population of area</p>
</dd>
<dt>popRur</dt><dd><p>total rural (target) population of area</p>
</dd>
<dt>popTotal</dt><dd><p>total (general) population of area</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="simPop_+3A_pop.mat">pop.mat</code></td>
<td>
<p>Pixellated grid data frame with variables <code>lon</code>, <code>lat</code>, <code>pop</code>, <code>area</code>, <code>subareas</code> (if subarea.level is TRUE), <code>urban</code> (if stratify.by.urban is TRUE), <code>east</code>, and <code>north</code></p>
</td></tr>
<tr><td><code id="simPop_+3A_target.pop.mat">target.pop.mat</code></td>
<td>
<p>Same as pop.mat, but <code>pop</code> variable gives target rather than general population</p>
</td></tr>
<tr><td><code id="simPop_+3A_poppsub">poppsub</code></td>
<td>
<p>data.frame of population per subarea separated by
urban/rural using for population density grid normalization or urbanicity
classification. Often based on extra fine scale population density grid. Has variables:</p>
</td></tr>
<tr><td><code id="simPop_+3A_spde.mesh">spde.mesh</code></td>
<td>
<p>Triangular mesh for the SPDE</p>
</td></tr>
<tr><td><code id="simPop_+3A_marg.var">marg.var</code></td>
<td>
<p>Marginal variance of the spatial process, excluding cluster effects.
If 0, no spatial component is included</p>
</td></tr>
<tr><td><code id="simPop_+3A_sigma.epsilon">sigma.epsilon</code></td>
<td>
<p>Standard deviation on the logit scale for iid Gaussian EA level random effects in the risk model</p>
</td></tr>
<tr><td><code id="simPop_+3A_gamma">gamma</code></td>
<td>
<p>Effect of urban on logit scale for logit model for risk</p>
</td></tr>
<tr><td><code id="simPop_+3A_eff.range">eff.range</code></td>
<td>
<p>Effective spatial range for the SPDE model</p>
</td></tr>
<tr><td><code id="simPop_+3A_beta0">beta0</code></td>
<td>
<p>Intercept of logit model for risk</p>
</td></tr>
<tr><td><code id="simPop_+3A_seed">seed</code></td>
<td>
<p>Random number generator seed</p>
</td></tr>
<tr><td><code id="simPop_+3A_inla.seed">inla.seed</code></td>
<td>
<p>Seed input to inla.qsample. 0L sets seed intelligently,
&gt; 0 sets a specific seed, &lt; 0 keeps existing RNG</p>
</td></tr>
<tr><td><code id="simPop_+3A_n.hh.sampled">n.HH.sampled</code></td>
<td>
<p>Number of households sampled per enumeration area. Default is 25 to match DHS surveys</p>
</td></tr>
<tr><td><code id="simPop_+3A_stratify.by.urban">stratify.by.urban</code></td>
<td>
<p>Whether or not to stratify simulations by urban/rural classification</p>
</td></tr>
<tr><td><code id="simPop_+3A_subarea.level">subarea.level</code></td>
<td>
<p>Whether or not to aggregate the population by subarea</p>
</td></tr>
<tr><td><code id="simPop_+3A_do.fine.scale.risk">do.fine.scale.risk</code></td>
<td>
<p>Whether or not to calculate the fine scale risk at each aggregation level in addition to the prevalence</p>
</td></tr>
<tr><td><code id="simPop_+3A_do.smooth.risk">do.smooth.risk</code></td>
<td>
<p>Whether or not to calculate the smooth risk at each aggregation level in addition to the prevalence</p>
</td></tr>
<tr><td><code id="simPop_+3A_do.smooth.risk.logistic.approx">do.smooth.risk.logistic.approx</code></td>
<td>
<p>Whether to use logistic approximation when calculating smooth risk. See
<code><a href="#topic+logitNormMean">logitNormMean</a></code> for details.</p>
</td></tr>
<tr><td><code id="simPop_+3A_min1.per.subarea">min1.per.subarea</code></td>
<td>
<p>If TRUE, ensures there is at least 1 EA per subarea. If subareas are particularly unlikely to
have enumeration areas since they have a very low proportion of the population in an area, then setting this to TRUE may be
computationally intensive.</p>
</td></tr>
<tr><td><code id="simPop_+3A_logit.risk.draws">logit.risk.draws</code></td>
<td>
<p>nIntegrationPoints x nsim dimension matrix of draws from the pixel leve risk field on logit scale, leaving out
potential nugget/cluster/EA level effects.</p>
</td></tr>
<tr><td><code id="simPop_+3A_sigma.epsilon.draws">sigma.epsilon.draws</code></td>
<td>
<p>nsim length vector of draws of cluster effect logit scale SD (joint draws with logit.risk.draws)</p>
</td></tr>
<tr><td><code id="simPop_+3A_validation.pixel.i">validation.pixel.I</code></td>
<td>
<p>CURRENTLY FOR TESTING PURPOSES ONLY a set of indices of pixels for which we want to simulate populations (used for pixel level validation)</p>
</td></tr>
<tr><td><code id="simPop_+3A_validation.cluster.i">validation.cluster.I</code></td>
<td>
<p>CURRENTLY FOR TESTING PURPOSES ONLY a set of indices of cluster for which we want to simulate populations (used for cluster level validation)</p>
</td></tr>
<tr><td><code id="simPop_+3A_clusters.per.pixel">clusters.per.pixel</code></td>
<td>
<p>CURRENTLY FOR TESTING PURPOSES ONLY Used for pixel level validation. Fixes the number of EAs per pixel.</p>
</td></tr>
<tr><td><code id="simPop_+3A_return.ea.info">return.EA.info</code></td>
<td>
<p>If TRUE, returns information on every individual EA (BAU) for each simulated population</p>
</td></tr>
<tr><td><code id="simPop_+3A_epsc">epsc</code></td>
<td>
<p>nEAs x nsim matrix of simulated EA (BAU) level iid effects representing fine scale variation in
risk. If NULL, they are simulated as iid Gaussian on a logit scale with
SD given by sigma.epsilon.draws
list(pixelPop=outPixelLevel, subareaPop=outSubareaLevel, areaPop=outAreaLevel, logit.risk.draws=logit.risk.draws)</p>
</td></tr>
</table>


<h3>Details</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a>
</p>
<p>For population simulation and aggregation, we consider three models: smooth
risk, fine scale risk, and the fine scale prevalence. All will be described in detail
in a paper in preparation. In the smooth risk model, pixel level risks are integrated
with respect to target population density when producing areal estimates on a prespecified
set of integration points. The target population may be, for example, neonatals rather
than the general population. In the fine scale models, enumeration areas (EAs) are simulated as
point locations and iid random effects in the EA level risk are allowed. EAs and populations are dispersed conditional on the (possibly
approximately) known number of EAs, households, and target population at a particular
areal level (these we call <code>areas</code>) using multilevel multinomial sampling, first
sampling the EAs, then distributing households among the EAs, then the target population
among the households. Any areal level below the <code>areas</code> we call <code>subareas</code>. For instance,
the <code>areas</code> might be Admin-1 if that is the smallest level at which the number of EAs,
households, and people is known, and the <code>subareas</code> might be Admin-2. The multilevel
multinomial sampling may be stratified by urban/rural within the areas if the number of
EAs, households, and people is also approximately known at that level.
</p>
<p>Within each EA we assume a fixed probability of an event occurring, which is the fine scale <code>risk</code>.
The fine scale <code>prevalence</code> is the empirical proportion of events within that EA. We assume EA
level logit scale iid N(0, sigma.epsilon^2) random effects in the risk model. When averaged
with equal weights over all EAs in an areal unit, this forms the fine scale risk. When
instead the population numerators and denominators are aggregated, and are used to
calculate the empirical proportion of events occurring in an areal unit, the resulting
quantity is the fine scale prevalence in that areal unit.
</p>
<p>Note that these functions can be used for either simulating populations for simulation
studies, or for generating predictions accounting for uncertainty in EA locations
and fine scale variation occurring at the EA level due to EA level iid random effects.
Required, however, is a separately fit EA level spatial risk model
and information on the spatial population density and the population frame.
</p>


<h3>Value</h3>

<p>The simulated population aggregated to the enumeration area,
pixel, subarea (generally Admin2), and area (generally Admin1) levels. Output includes:
</p>
<table role = "presentation">
<tr><td><code>pixelPop</code></td>
<td>
<p>A list of pixel level population aggregates</p>
</td></tr>
<tr><td><code>subareaPop</code></td>
<td>
<p>A list of <code>subarea</code> level population aggregates</p>
</td></tr>
<tr><td><code>areaPop</code></td>
<td>
<p>A list of <code>area</code> level population aggregates</p>
</td></tr>
</table>
<p>Each of these contains population numerator and denominator as well as prevalence and risk
information aggregated to the appropriate level.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>simPopSPDE()</code>: Simulate populations and population prevalences given census frame and population density
information. Uses SPDE model for generating spatial risk and can include iid cluster
level effect.
</p>
</li>
<li> <p><code>simPopCustom()</code>: Simulate populations and population prevalences given census frame and population density
information. Uses custom spatial logit risk function and can include iid cluster
level effect.
</p>
</li></ul>


<h3>Author(s)</h3>

<p>John Paige
</p>


<h3>References</h3>

<p>Paige, John, Geir-Arne Fuglstad, Andrea Riebler, and Jon Wakefield. &quot;Spatial aggregation with respect to a population distribution: Impact on inference.&quot; Spatial Statistics 52 (2022): 100714.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+simPopCustom">simPopCustom</a></code>, <code><a href="#topic+makePopIntegrationTab">makePopIntegrationTab</a></code>, <code><a href="#topic+adjustPopMat">adjustPopMat</a></code>, <code><a href="#topic+simSPDE">simSPDE</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## In this script we will create 5km resolution pixellated grid over Kenya, 
## and generate tables of estimated (both target and general) population 
## totals at the area (e.g. Admin-1) and subarea (e.g. Admin-2) levels. Then 
## we will use that to simulate populations of 

# download Kenya GADM shapefiles from SUMMERdata github repository
githubURL &lt;- paste0("https://github.com/paigejo/SUMMERdata/blob/main/data/", 
                    "kenyaMaps.rda?raw=true")
tempDirectory = "~/"
mapsFilename = paste0(tempDirectory, "/kenyaMaps.rda")
if(!file.exists(mapsFilename)) {
  download.file(githubURL,mapsFilename)
}

# load it in
out = load(mapsFilename)
out
kenyaMesh &lt;- fmesher::fm_as_fm(kenyaMesh)
adm1@data$NAME_1 = as.character(adm1@data$NAME_1)
adm1@data$NAME_1[adm1@data$NAME_1 == "Trans Nzoia"] = "Trans-Nzoia"
adm1@data$NAME_1[adm1@data$NAME_1 == "Elgeyo-Marakwet"] = "Elgeyo Marakwet"
adm2@data$NAME_1 = as.character(adm2@data$NAME_1)
adm2@data$NAME_1[adm2@data$NAME_1 == "Trans Nzoia"] = "Trans-Nzoia"
adm2@data$NAME_1[adm2@data$NAME_1 == "Elgeyo-Marakwet"] = "Elgeyo Marakwet"

# some Admin-2 areas have the same name
adm2@data$NAME_2 = as.character(adm2@data$NAME_2)
adm2@data$NAME_2[(adm2@data$NAME_1 == "Bungoma") &amp; 
                   (adm2@data$NAME_2 == "Lugari")] = "Lugari, Bungoma"
adm2@data$NAME_2[(adm2@data$NAME_1 == "Kakamega") &amp; 
                   (adm2@data$NAME_2 == "Lugari")] = "Lugari, Kakamega"
adm2@data$NAME_2[(adm2@data$NAME_1 == "Meru") &amp; 
                   (adm2@data$NAME_2 == "Igembe South")] = "Igembe South, Meru"
adm2@data$NAME_2[(adm2@data$NAME_1 == "Tharaka-Nithi") &amp; 
                   (adm2@data$NAME_2 == "Igembe South")] = "Igembe South, Tharaka-Nithi"

# The spatial area of unknown 8 is so small, it causes problems unless its removed or 
# unioned with another subarea. Union it with neighboring Kakeguria:
newadm2 = adm2
unknown8I = which(newadm2$NAME_2 == "unknown 8")
newadm2$NAME_2[newadm2$NAME_2 %in% c("unknown 8", "Kapenguria")] &lt;- 
  "Kapenguria + unknown 8"
admin2.IDs &lt;- newadm2$NAME_2

newadm2@data = cbind(newadm2@data, NAME_2OLD = newadm2@data$NAME_2)
newadm2@data$NAME_2OLD = newadm2@data$NAME_2
newadm2@data$NAME_2 = admin2.IDs
newadm2$NAME_2 = admin2.IDs
temp &lt;- terra::aggregate(as(newadm2, "SpatVector"), by="NAME_2")

library(sf)
temp &lt;- sf::st_as_sf(temp)
temp &lt;- sf::as_Spatial(temp)

tempData = newadm2@data[-unknown8I,]
tempData = tempData[order(tempData$NAME_2),]
newadm2 &lt;- sp::SpatialPolygonsDataFrame(temp, tempData, match.ID = F)
adm2 = newadm2

# download 2014 Kenya population density TIF file

githubURL &lt;- paste0("https://github.com/paigejo/SUMMERdata/blob/main/data/", 
                    "Kenya2014Pop/worldpop_total_1y_2014_00_00.tif?raw=true")
popTIFFilename = paste0(tempDirectory, "/worldpop_total_1y_2014_00_00.tif")
if(!file.exists(popTIFFilename)) {
  download.file(githubURL,popTIFFilename)
}

# load it in
pop = terra::rast(popTIFFilename)

east.lim = c(-110.6405, 832.4544)
north.lim = c(-555.1739, 608.7130)

## Construct poppsubKenya, a table of urban/rural general population totals 
## in each subarea. Technically, this is not necessary since we can load in 
## poppsubKenya via data(kenyaPopulationData). First, we will need to calculate 
## the areas in km^2 of the areas and subareas

# use Lambert equal area projection of areas (Admin-1) and subareas (Admin-2)
midLon = mean(adm1@bbox[1,])
midLat = mean(adm1@bbox[2,])
p4s = paste0("+proj=laea +x_0=0 +y_0=0 +lon_0=", midLon, 
             " +lat_0=", midLat, " +units=km")

adm1_sf = st_as_sf(adm1)
adm1proj_sf = st_transform(adm1_sf, p4s)
adm1proj = as(adm1proj_sf, "Spatial")

adm2_sf = st_as_sf(adm2)
adm2proj_sf = st_transform(adm2_sf, p4s)
adm2proj = as(adm2proj_sf, "Spatial")

# now calculate spatial area in km^2
admin1Areas = as.numeric(st_area(adm1proj_sf))
admin2Areas = as.numeric(st_area(adm2proj_sf))

areapaKenya = data.frame(area=adm1proj@data$NAME_1, spatialArea=admin1Areas)
areapsubKenya = data.frame(area=adm2proj@data$NAME_1, subarea=adm2proj@data$NAME_2, 
                           spatialArea=admin2Areas)

# Calculate general population totals at the subarea (Admin-2) x urban/rural 
# level and using 1km resolution population grid. Assign urbanicity by 
# thresholding population density based on estimated proportion population 
# urban/rural, making sure total area (Admin-1) urban/rural populations in 
# each area matches poppaKenya.

# NOTE: the following function will typically take ~15-20 minutes. Can speed up 
#       by setting km.res to be higher, but we recommend fine resolution for 
#       this step, since it only needs to be done once. Instead of running 
#       the code in the following if(FALSE) section, 
#       you can simply run data(kenyaPopulationData)
if(FALSE){
  system.time(poppsubKenya &lt;- getPoppsub(
    km.res=1, pop=pop, domain.map.dat=adm0,
    east.lim=east.lim, north.lim=north.lim, map.projection=projKenya,
    poppa = poppaKenya, areapa=areapaKenya, areapsub=areapsubKenya, 
    area.map.dat=adm1, subarea.map.dat=adm2, 
    areaNameVar = "NAME_1", subareaNameVar="NAME_2"))
}
data(kenyaPopulationData)

# Now generate a general population integration table at 5km resolution, 
# based on subarea (Admin-2) x urban/rural population totals. This takes 
# ~1 minute
pop.matKenya &lt;- makePopIntegrationTab(
  km.res=5, pop=pop, domain.map.dat=adm0,
  east.lim=east.lim, north.lim=north.lim, map.projection=projKenya,
  poppa = poppaKenya, poppsub=poppsubKenya, 
  area.map.dat = adm1, subarea.map.dat = adm2,
  areaNameVar = "NAME_1", subareaNameVar="NAME_2")

## Adjust pop.mat to be target (neonatal) rather than general population 
## density. First create the target population frame
## (these numbers are based on IPUMS microcensus data)
mothersPerHouseholdUrb = 0.3497151
childrenPerMotherUrb = 1.295917
mothersPerHouseholdRur = 0.4787696
childrenPerMotherRur = 1.455222
targetPopPerStratumUrban = easpaKenya$HHUrb * mothersPerHouseholdUrb * 
  childrenPerMotherUrb
targetPopPerStratumRural = easpaKenya$HHRur * mothersPerHouseholdRur * 
  childrenPerMotherRur
easpaKenyaNeonatal = easpaKenya
easpaKenyaNeonatal$popUrb = targetPopPerStratumUrban
easpaKenyaNeonatal$popRur = targetPopPerStratumRural
easpaKenyaNeonatal$popTotal = easpaKenyaNeonatal$popUrb + 
  easpaKenyaNeonatal$popRur
easpaKenyaNeonatal$pctUrb = 100 * easpaKenyaNeonatal$popUrb / 
  easpaKenyaNeonatal$popTotal
easpaKenyaNeonatal$pctTotal = 
  100 * easpaKenyaNeonatal$popTotal / sum(easpaKenyaNeonatal$popTotal)

# Generate the target population density by scaling the current 
# population density grid at the Admin1 x urban/rural level
pop.matKenyaNeonatal = adjustPopMat(pop.matKenya, easpaKenyaNeonatal)

# Generate neonatal population table from the neonatal population integration 
# matrix. This is technically not necessary for population simulation purposes, 
# but is here for illustrative purposes
poppsubKenyaNeonatal = poppRegionFromPopMat(pop.matKenyaNeonatal, 
                                            pop.matKenyaNeonatal$subarea)
poppsubKenyaNeonatal = 
  cbind(subarea=poppsubKenyaNeonatal$region, 
        area=adm2@data$NAME_1[match(poppsubKenyaNeonatal$region, adm2@data$NAME_2)], 
        poppsubKenyaNeonatal[,-1])
print(head(poppsubKenyaNeonatal))

## Now we're ready to simulate neonatal populations along with neonatal 
## mortality risks and prevalences

# use the following model to simulate the neonatal population based roughly 
# on Paige et al. (2020) neonatal mortality modeling for Kenya.
beta0=-2.9 # intercept
gamma=-1 # urban effect
rho=(1/3)^2 # spatial variance
eff.range = 400 # effective spatial range in km
sigma.epsilon=sqrt(1/2.5) # cluster (nugget) effect standard deviation

# Run a simulation! This produces multiple dense nEA x nsim and nPixel x nsim 
# matrices. In the future sparse matrices and chunk by chunk computations 
# may be incorporated.
simPop = simPopSPDE(nsim=1, easpa=easpaKenyaNeonatal, 
                    pop.mat=pop.matKenya, target.pop.mat=pop.matKenyaNeonatal, 
                    poppsub=poppsubKenya, spde.mesh=kenyaMesh, 
                    marg.var=rho, sigma.epsilon=sigma.epsilon, 
                    gamma=gamma, eff.range=eff.range, beta0=beta0, 
                    seed=12, inla.seed=12, n.HH.sampled=25, 
                    stratify.by.urban=TRUE, subarea.level=TRUE, 
                    do.fine.scale.risk=TRUE, do.smooth.risk=TRUE, 
                    min1.per.subarea=TRUE)

# get average absolute percent error relative to fine scale prevalence at Admin-2 level
tempDat = simPop$subareaPop$aggregationResults[c("region", "pFineScalePrevalence", 
                                                  "pFineScaleRisk", "pSmoothRisk")]
100*mean(abs(tempDat$pFineScalePrevalence - tempDat$pFineScaleRisk) / 
           tempDat$pFineScalePrevalence)
100*mean(abs(tempDat$pFineScalePrevalence - tempDat$pSmoothRisk) / 
           tempDat$pFineScalePrevalence)
100*mean(abs(tempDat$pFineScaleRisk - tempDat$pSmoothRisk) / 
           tempDat$pFineScalePrevalence)

# verify number of EAs per area and subarea
cbind(aggregate(simPop$eaPop$ea.samples[,1], by=list(area=pop.matKenya$area), FUN=sum), 
      trueNumEAs=easpaKenya$EATotal[order(easpaKenya$area)])
aggregate(simPop$eaPop$ea.samples[,1], by=list(area=pop.matKenya$subarea), FUN=sum)

## plot simulated population
# directory for plotting 
# (mapPlot takes longer when it doesn't save to a file)
tempDirectory = "~/"

# pixel level plots. Some pixels have no simulated EAs, in which case they will be 
# plotted as white. Expected noisy looking plots of fine scale risk and prevalence 
# due to EAs being discrete, as compared to a very smooth plot of smooth risk.
zlim = c(0, quantile(probs=.995, c(simPop$pixelPop$pFineScalePrevalence, 
                                   simPop$pixelPop$pFineScaleRisk, 
                                   simPop$pixelPop$pSmoothRisk), na.rm=TRUE))
par(mfrow=c(2,2))
plot(adm2, asp=1)
points(simPop$eaPop$eaDatList[[1]]$lon, simPop$eaPop$eaDatList[[1]]$lat, pch=".", col="blue")
plot(adm2, asp=1)
fields::quilt.plot(pop.matKenya$lon, pop.matKenya$lat, simPop$pixelPop$pFineScalePrevalence, 
           zlim=zlim, add=TRUE, FUN=function(x) {mean(x, na.rm=TRUE)})
plot(adm2, asp=1)
fields::quilt.plot(pop.matKenya$lon, pop.matKenya$lat, simPop$pixelPop$pFineScaleRisk, 
           zlim=zlim, add=TRUE, FUN=function(x) {mean(x, na.rm=TRUE)})
fields::quilt.plot(pop.matKenya$lon, pop.matKenya$lat, simPop$pixelPop$pSmoothRisk, 
           zlim=zlim, FUN=function(x) {mean(x, na.rm=TRUE)}, asp=1)
plot(adm2, add=TRUE)

range(simPop$eaPop$eaDatList[[1]]$N)

# areal (Admin-1) level: these results should look essentially identical

tempDat = simPop$areaPop$aggregationResults[c("region", "pFineScalePrevalence", 
                                               "pFineScaleRisk", "pSmoothRisk")]
mapPlot(tempDat, 
        variables=c("pFineScalePrevalence", "pFineScaleRisk", "pSmoothRisk"), 
        geo=adm1, by.geo="NAME_1", by.data="region", is.long=FALSE)

# subareal (Admin-2) level: these results should look subtley different 
# depending on the type of prevalence/risk considered
tempDat = simPop$subareaPop$aggregationResults[c("region", "pFineScalePrevalence", 
                                                  "pFineScaleRisk", "pSmoothRisk")]
mapPlot(tempDat, 
        variables=c("pFineScalePrevalence", "pFineScaleRisk", "pSmoothRisk"), 
        geo=adm2, by.geo="NAME_2", by.data="region", is.long=FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='simPopInternal'>Internal functions for population simulation</h2><span id='topic+simPopInternal'></span><span id='topic+getExpectedNperEA'></span><span id='topic+getSortIndices'></span><span id='topic+rStratifiedMultnomial'></span><span id='topic+rStratifiedMultnomialBySubarea'></span><span id='topic+rMyMultinomial'></span><span id='topic+rMyMultinomialSubarea'></span><span id='topic+rmultinom1'></span><span id='topic+sampleNMultilevelMultinomial'></span><span id='topic+sampleNMultilevelMultinomialFixed'></span>

<h3>Description</h3>

<p>Functions for calculating valuable quantities and for drawing from important
distributions for population simulation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getExpectedNperEA(
  easpa,
  pop.mat,
  level = c("grid", "EA"),
  pixel.index.mat = NULL
)

getSortIndices(
  i,
  urban = TRUE,
  pop.mat,
  stratify.by.urban = TRUE,
  validation.pixel.I = NULL
)

rStratifiedMultnomial(n, pop.mat, easpa, stratify.by.urban = TRUE)

rStratifiedMultnomialBySubarea(
  n,
  pop.mat,
  easpa,
  stratify.by.urban = TRUE,
  poppsub = NULL,
  min1.per.subarea = TRUE,
  min.sample = 1
)

rMyMultinomial(
  n,
  i,
  stratify.by.urban = TRUE,
  urban = TRUE,
  pop.mat = NULL,
  easpa = NULL,
  min1.per.subarea = FALSE,
  method = c("mult1", "mult", "indepMH"),
  min.sample = 1
)

rMyMultinomialSubarea(
  n,
  i,
  easpsub,
  stratify.by.urban = TRUE,
  urban = TRUE,
  pop.mat = NULL
)

rmultinom1(
  n = 1,
  size,
  prob,
  max.size = 8000 * 8000,
  method = c("mult1", "mult", "indepMH"),
  verbose = FALSE,
  min.sample = 100,
  max.expected.size.before.switch = 1000 * 1e+07,
  init = NULL,
  burnin = floor(n/4),
  filter.every = 10,
  zero.prob.zero.samples = TRUE,
  allow.size.less.than.K = FALSE
)

sampleNMultilevelMultinomial(
  ndraws = ncol(pixel.index.mat),
  pixel.index.mat = NULL,
  urban.mat = NULL,
  area.mat = NULL,
  easpa.list,
  pop.mat,
  stratify.by.urban = TRUE,
  verbose = TRUE,
  return.EA.info = FALSE,
  min.HH.per.EA = 25,
  fix.HH.per.EA = NULL,
  fix.pop.per.HH = NULL
)

sampleNMultilevelMultinomialFixed(
  clusters.per.pixel,
  ndraws = ncol(pixel.indices),
  pixel.indices = NULL,
  urbanVals = NULL,
  areaVals = NULL,
  easpa,
  pop.mat,
  stratify.by.urban = TRUE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simPopInternal_+3A_easpa">easpa</code></td>
<td>
<p>Census frame. See <code><a href="#topic+simPopCustom">simPopCustom</a></code> for details</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_pop.mat">pop.mat</code></td>
<td>
<p>data.frame of pixellated grid of population densities. See <code><a href="#topic+simPopCustom">simPopCustom</a></code> for details</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_level">level</code></td>
<td>
<p>Whether to calculate results at the integration grid or EA level</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_pixel.index.mat">pixel.index.mat</code></td>
<td>
<p>Matrix of pixel indices associated with each EA and draw. Not
required by getExpectedNperEA unless level == &quot;EA&quot;</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_i">i</code></td>
<td>
<p>Index</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_urban">urban</code></td>
<td>
<p>If TRUE, calculate only for urban part of the area. If FALSE, for only rural part</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_stratify.by.urban">stratify.by.urban</code></td>
<td>
<p>whether or not to stratify calculations by urban/rural classification</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_validation.pixel.i">validation.pixel.I</code></td>
<td>
<p>CURRENTLY FOR TESTING PURPOSES ONLY a set of indices of pixels for which we want to simulate populations (used for pixel level validation)</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_n">n</code></td>
<td>
<p>Number of samples</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_poppsub">poppsub</code></td>
<td>
<p>Population per subarea. See <code><a href="#topic+simPopCustom">simPopCustom</a></code> for details</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_min1.per.subarea">min1.per.subarea</code></td>
<td>
<p>Whether or not to ensure there is at least 1 EA per subarea. See <code><a href="#topic+simPopCustom">simPopCustom</a></code> for details</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_min.sample">min.sample</code></td>
<td>
<p>The minimum number of samples per <code>chunk</code> of samples for truncated multinomial sampling. Defaults to 1</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_method">method</code></td>
<td>
<p>If min1.per.subarea is TRUE, the sampling method for the truncated multinomial to use with rmulitnom1. rmultinom1 automatically
switches between them depending on the number of expected samples. The methods are:
</p>

<dl>
<dt>mult1</dt><dd><p>rejection sampling from multinomial plus 1 in each category</p>
</dd>
<dt>mult</dt><dd><p>rejection sampling from multinomial if any category has zero count</p>
</dd>
<dt>indepMH</dt><dd><p>independent Metropolis-Hastings using multinomial plus 1 distribution as proposal</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="simPopInternal_+3A_easpsub">easpsub</code></td>
<td>
<p>This could either be total EAs per subarea, or subarea crossed with urban or
rural if stratify.by.urban is TRUE</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_size">size</code></td>
<td>
<p>Multinomial size parameter. See <code><a href="stats.html#topic+rmultinom">rmultinom</a></code></p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_prob">prob</code></td>
<td>
<p>Multinomial probability vector parameter. See <code><a href="stats.html#topic+rmultinom">rmultinom</a></code></p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_max.size">max.size</code></td>
<td>
<p>The maximum number of elements in a matrix drawn from the proposal distribution per sample chunk.</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_verbose">verbose</code></td>
<td>
<p>Whether to print progress as the function proceeds</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_max.expected.size.before.switch">max.expected.size.before.switch</code></td>
<td>
<p>Max expected number of samples / k, the number of categories, before switching method</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_init">init</code></td>
<td>
<p>Initial sample if method is <code>indepMH</code></p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_burnin">burnin</code></td>
<td>
<p>Number of initial samples before samples are collected if method is <code>indepMH</code></p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_filter.every">filter.every</code></td>
<td>
<p>Store only every filter.every samples if method is i<code>indepMH</code></p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_zero.prob.zero.samples">zero.prob.zero.samples</code></td>
<td>
<p>If TRUE, set samples for parts of prob vector that are zero to zero. Otherwise they are set to one.</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_allow.size.less.than.k">allow.size.less.than.K</code></td>
<td>
<p>If TRUE, then if size &lt; the number of categories (k), returns matrix where each
column is vector of size ones and k - size zeros. If FALSE, throws an error if size &lt; k</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_ndraws">ndraws</code></td>
<td>
<p>Number of draws</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_urban.mat">urban.mat</code></td>
<td>
<p>Matrix of urbanicities associated with each EA and draw</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_area.mat">area.mat</code></td>
<td>
<p>Matrix of areas associated with each EA and draw</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_easpa.list">easpa.list</code></td>
<td>
<p>A list of length n with each element being of the format of easpa
giving the number of households and EAs
per stratum. It is assumed that the number of EAs per stratum is
the same in each list element. If easpa.list is a data frame,
number of households per stratum is assumed constant</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_return.ea.info">return.EA.info</code></td>
<td>
<p>Whether a data frame at the EA level is desired</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_min.hh.per.ea">min.HH.per.EA</code></td>
<td>
<p>The minimum number of households per EA (defaults to 25, since
that is the number of households sampled per DHS cluster)</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_fix.hh.per.ea">fix.HH.per.EA</code></td>
<td>
<p>If not NULL, the fixed number of households per EA</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_fix.pop.per.hh">fix.pop.per.HH</code></td>
<td>
<p>If not NULL, the fixed target population per household</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_clusters.per.pixel">clusters.per.pixel</code></td>
<td>
<p>CURRENTLY FOR TESTING PURPOSES ONLY a vector of length nIntegrationPoints specifying the number of clusters per pixel if they are fixed</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_pixel.indices">pixel.indices</code></td>
<td>
<p>A nEA x n matrix of pixel indices associated with each EA per simulation/draw</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_urbanvals">urbanVals</code></td>
<td>
<p>A nEA x n matrix of urbanicities associated with each EA per simulation/draw</p>
</td></tr>
<tr><td><code id="simPopInternal_+3A_areavals">areaVals</code></td>
<td>
<p>A nEA x n matrix of area names associated with each EA per simulation/draw</p>
</td></tr>
</table>


<h3>Details</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a>
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>getExpectedNperEA()</code>: Calculates expected denominator per enumeration area.
</p>
</li>
<li> <p><code>getSortIndices()</code>: For recombining separate multinomials into the draws over all grid points
</p>
</li>
<li> <p><code>rStratifiedMultnomial()</code>: Gives nIntegrationPoints x n matrix of draws from the stratified multinomial with values
corresponding to the value of |C^g| for each pixel, g (the number of EAs/pixel)
</p>
</li>
<li> <p><code>rStratifiedMultnomialBySubarea()</code>: Gives nIntegrationPoints x n matrix of draws from the stratified multinomial with values
</p>
</li>
<li> <p><code>rMyMultinomial()</code>: 
</p>
</li>
<li> <p><code>rMyMultinomialSubarea()</code>: 
</p>
</li>
<li> <p><code>rmultinom1()</code>: Random (truncated) multinomial draws conditional on the number of each type being at least one
</p>
</li>
<li> <p><code>sampleNMultilevelMultinomial()</code>: Take multilevel multinomial draws first from joint distribution of
number of households per EA given the total per stratum, and then from the joint
distribution of the total target population per household given
the total per stratum
</p>
</li>
<li> <p><code>sampleNMultilevelMultinomialFixed()</code>: Same as sampleNMultilevelMultinomial, except the number of EAs per pixel is fixed
</p>
</li></ul>

<hr>
<h2 id='simSPDE'>Simulate from the SPDE spatial model</h2><span id='topic+simSPDE'></span>

<h3>Description</h3>

<p>Generates nCoords x nsim matrix of simulated
values of the SPDE spatial process
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simSPDE(
  coords,
  nsim = 1,
  mesh,
  eff.range = (max(coords[, 1]) - min(coords[, 1]))/3,
  marg.var = 1,
  inla.seed = 0L
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simSPDE_+3A_coords">coords</code></td>
<td>
<p>2 column matrix of spatial coordinates at which to simulate the spatial process</p>
</td></tr>
<tr><td><code id="simSPDE_+3A_nsim">nsim</code></td>
<td>
<p>number of draws from the SPDE model</p>
</td></tr>
<tr><td><code id="simSPDE_+3A_mesh">mesh</code></td>
<td>
<p>SPDE mesh</p>
</td></tr>
<tr><td><code id="simSPDE_+3A_eff.range">eff.range</code></td>
<td>
<p>effective spatial range</p>
</td></tr>
<tr><td><code id="simSPDE_+3A_marg.var">marg.var</code></td>
<td>
<p>marginal variance of the spatial process</p>
</td></tr>
<tr><td><code id="simSPDE_+3A_inla.seed">inla.seed</code></td>
<td>
<p>seed input to inla.qsample. 0L sets seed intelligently, positive value sets a specific seed, negative value keeps existing RNG</p>
</td></tr>
</table>


<h3>Details</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a>
</p>


<h3>Author(s)</h3>

<p>John Paige
</p>


<h3>References</h3>

<p>Lindgren, F., Rue, H., Lindström, J., 2011. An explicit link between Gaussian fields and Gaussian Markov random fields: the stochastic differential equation approach (with discussion). Journal of the Royal Statistical Society, Series B 73, 423–498.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(123)
require(INLA)
coords = matrix(runif(10*2), ncol=2)
mesh = inla.mesh.2d(loc.domain=cbind(c(0, 0, 1, 1), c(0, 1, 0, 1)), 
  n=3000, max.n=5000, max.edge=c(.01, .05), offset=-.1)
simVals = simSPDE(coords, nsim=1, mesh, eff.range=.2, inla.seed=1L)

## End(Not run)

</code></pre>

<hr>
<h2 id='smoothArea'>Small area estimation via basic area level model</h2><span id='topic+smoothArea'></span>

<h3>Description</h3>

<p>Generates small area estimates  by smoothing direct estimates using an
area level model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smoothArea(
  formula,
  domain,
  design = NULL,
  adj.mat = NULL,
  X.domain = NULL,
  direct.est = NULL,
  domain.size = NULL,
  transform = c("identity", "logit", "log"),
  pc.u = 1,
  pc.alpha = 0.01,
  pc.u.phi = 0.5,
  pc.alpha.phi = 2/3,
  level = 0.95,
  n.sample = 250,
  var.tol = 1e-10,
  return.samples = F
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="smoothArea_+3A_formula">formula</code></td>
<td>
<p>An object of class 'formula' describing the model to be fitted.
If direct.est is specified, the right hand side of the formula is not necessary.</p>
</td></tr>
<tr><td><code id="smoothArea_+3A_domain">domain</code></td>
<td>
<p>One-sided formula specifying factors containing domain labels</p>
</td></tr>
<tr><td><code id="smoothArea_+3A_design">design</code></td>
<td>
<p>An object of class &quot;svydesign&quot; containing the data for the model</p>
</td></tr>
<tr><td><code id="smoothArea_+3A_adj.mat">adj.mat</code></td>
<td>
<p>Adjacency matrix with rownames matching the domain labels. If set to NULL, the IID spatial effect will be used.</p>
</td></tr>
<tr><td><code id="smoothArea_+3A_x.domain">X.domain</code></td>
<td>
<p>Data frame of areal covariates. One of the column names needs to match the name of the domain variable, in order to be linked to the data input. Currently only supporting time-invariant covariates.</p>
</td></tr>
<tr><td><code id="smoothArea_+3A_direct.est">direct.est</code></td>
<td>
<p>Data frame of direct estimates, with first column containing the domain variable, second column containing direct estimate, and third column containing the variance of direct estimate.</p>
</td></tr>
<tr><td><code id="smoothArea_+3A_domain.size">domain.size</code></td>
<td>
<p>Data frame of domain sizes. One of the column names needs to match the name of the domain variable, in order to be linked to the data input and there must be a column names 'size' containing domain sizes.</p>
</td></tr>
<tr><td><code id="smoothArea_+3A_transform">transform</code></td>
<td>
<p>Optional transformation applied to the direct estimates before fitting area level model. The default option is no transformation, but logit and log are implemented.</p>
</td></tr>
<tr><td><code id="smoothArea_+3A_pc.u">pc.u</code></td>
<td>
<p>Hyperparameter U for the PC prior on precisions. See the INLA documentation for more details on the parameterization.</p>
</td></tr>
<tr><td><code id="smoothArea_+3A_pc.alpha">pc.alpha</code></td>
<td>
<p>Hyperparameter alpha for the PC prior on precisions.</p>
</td></tr>
<tr><td><code id="smoothArea_+3A_pc.u.phi">pc.u.phi</code></td>
<td>
<p>Hyperparameter U for the PC prior on the mixture probability phi in BYM2 model.</p>
</td></tr>
<tr><td><code id="smoothArea_+3A_pc.alpha.phi">pc.alpha.phi</code></td>
<td>
<p>Hyperparameter alpha for the PC prior on the mixture probability phi in BYM2 model.</p>
</td></tr>
<tr><td><code id="smoothArea_+3A_level">level</code></td>
<td>
<p>The specified level for the posterior credible intervals</p>
</td></tr>
<tr><td><code id="smoothArea_+3A_n.sample">n.sample</code></td>
<td>
<p>Number of draws from posterior used to compute summaries</p>
</td></tr>
<tr><td><code id="smoothArea_+3A_var.tol">var.tol</code></td>
<td>
<p>Tolerance parameter; if variance of an area's direct estimator is below this value, that direct estimator is dropped from model</p>
</td></tr>
<tr><td><code id="smoothArea_+3A_return.samples">return.samples</code></td>
<td>
<p>If TRUE, return matrix of posterior samples of area level quantities</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A svysae object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(DemoData2)
data(DemoMap2)
library(survey)
des0 &lt;- svydesign(ids = ~clustid+id, strata = ~strata,
                  weights = ~weights, data = DemoData2, nest = TRUE)
Xmat &lt;- aggregate(age~region, data = DemoData2, FUN = mean)

# EXAMPLE 1: Continuous response model
cts.res &lt;- smoothArea(tobacco.use ~ 1,
                      domain = ~region,
                      design = des0,
                      adj.mat = DemoMap2$Amat, 
                      pc.u = 1,
                      pc.alpha = 0.01,
                      pc.u.phi = 0.5,
                      pc.alpha.phi = 2/3)

# EXAMPLE 2: Including area level covariates
cts.cov.res &lt;- smoothArea(tobacco.use ~ age, 
                          domain = ~region,
                          design = des0,
                          adj.mat = DemoMap2$Amat, 
                          X.domain = Xmat,
                          pc.u = 1,
                          pc.alpha = 0.01,
                          pc.u.phi = 0.5,
                          pc.alpha.phi = 2/3)

# EXAMPLE 3: Binary response model
bin.res &lt;- smoothArea(tobacco.use ~ 1, 
                      domain = ~region,
                      design = des0,
                      adj.mat = DemoMap2$Amat, 
                      transform = "logit",
                      pc.u = 1,
                      pc.alpha = 0.01,
                      pc.u.phi = 0.5,
                      pc.alpha.phi = 2/3)

# EXAMPLE 4: Including area level covariates in binary response model
bin.cov.res &lt;- smoothArea(tobacco.use ~ age, 
                          domain = ~region,
                          design = des0,
                          adj.mat = DemoMap2$Amat, 
                          transform = "logit",
                          X.domain = Xmat,
                          pc.u = 1,
                          pc.alpha = 0.01,
                          pc.u.phi = 0.5,
                          pc.alpha.phi = 2/3)

## End(Not run)
</code></pre>

<hr>
<h2 id='smoothCluster'>Cluster-level space-time smoothing models for mortality rates</h2><span id='topic+smoothCluster'></span>

<h3>Description</h3>

<p>The function <code>smoothCluster</code> replace the previous function name <code>fitINLA2</code> (before version 1.0.0).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smoothCluster(
  data,
  X = NULL,
  family = c("betabinomial", "binomial")[1],
  age.group = c("0", "1-11", "12-23", "24-35", "36-47", "48-59"),
  age.groups = deprecated(),
  age.n = c(1, 11, 12, 12, 12, 12),
  age.time.group = c(1, 2, 3, 3, 3, 3),
  age.strata.fixed.group = c(1, 2, 3, 4, 5, 6),
  time.model = c("rw1", "rw2", "ar1")[2],
  st.time.model = NULL,
  Amat,
  bias.adj = NULL,
  bias.adj.by = NULL,
  formula = NULL,
  year.label,
  year_label = deprecated(),
  type.st = 4,
  survey.effect = FALSE,
  linear.trend = TRUE,
  common.trend = FALSE,
  strata.time.effect = FALSE,
  hyper = "pc",
  pc.u = 1,
  pc.alpha = 0.01,
  pc.u.phi = 0.5,
  pc.alpha.phi = 2/3,
  pc.u.cor = 0.7,
  pc.alpha.cor = 0.9,
  pc.st.u = NA,
  pc.st.alpha = NA,
  pc.st.slope.u = NA,
  pc.st.slope.alpha = NA,
  overdisp.mean = 0,
  overdisp.prec = 0.4,
  options = list(config = TRUE),
  control.inla = list(strategy = "adaptive", int.strategy = "auto"),
  control.fixed = list(),
  verbose = FALSE,
  geo = NULL,
  rw = NULL,
  ar = NULL,
  st.rw = NULL,
  age.rw.group = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="smoothCluster_+3A_data">data</code></td>
<td>
<p>count data of person-months with the following columns
</p>

<ul>
<li><p> cluster: cluster ID
</p>
</li>
<li><p> years: time period
</p>
</li>
<li><p> region: region of the cluster
</p>
</li>
<li><p> strata: stratum of the cluster
</p>
</li>
<li><p> age: age group corresponding to the row
</p>
</li>
<li><p> total: total number of person-month in this age group, stratum, cluster, and period
</p>
</li>
<li><p> Y: total number of deaths in this age group, stratum, cluster, and period
</p>
</li></ul>
</td></tr>
<tr><td><code id="smoothCluster_+3A_x">X</code></td>
<td>
<p>Covariate matrix. It must contain either a column with name &quot;region&quot;, or a column with name &quot;years&quot;, or both. The covariates must not have missing values for all regions (if varying in space) and all time periods (if varying in time). The rest of the columns are treated as covariates in the mean model.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_family">family</code></td>
<td>
<p>family of the model. This can be either binomial (with logistic normal prior), betabiniomial.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_age.group">age.group</code></td>
<td>
<p>a character vector of age groups in increasing order.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_age.groups">age.groups</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> replaced by <code>age.group</code></p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_age.n">age.n</code></td>
<td>
<p>number of months in each age groups in the same order.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_age.time.group">age.time.group</code></td>
<td>
<p>vector indicating grouping of the ages groups in the temporal model. For example, if each age group is assigned a different temporal component, then set age.rw.group to c(1:length(age.group)); if all age groups share the same random walk component, then set age.rw.group to a rep(1, length(age.group)). The default for 6 age groups is c(1,2,3,3,3,3), which assigns a separate temporal trend to the first two groups and a common random walk for the rest of the age groups. The vector should contain values starting from 1. This argument replaces the previous <code>age.rw.group</code> argument.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_age.strata.fixed.group">age.strata.fixed.group</code></td>
<td>
<p>vector indicating grouping of the ages groups for different strata in the intercept. The default is c(1:length(age.group)), which correspond to each age group within each stratum receives a separate intercept. If several age groups are specified to be the same value in this vector, the stratum specific deviation from the baseline is assumed to be the same for these age groups. For example, if <code>age.strata.fixed.group = c(1, 2, 3, 3, 3, 3)</code>, then the intercept part of the linear predictor consists of 6 overall age-specific intercepts and 3 set of strata effects (where a base stratum is chosen internally), for age groups 1, 2, and the rest respectively. Notice that this argument does not control the linear temporal trends (which is also parameterized as fixed effect, but determined by the <code>age.rw.group</code> argument). The vector should contain values starting from 1.
</p>
<p>More specific examples: (1) if each age group is assigned a different intercept, then set age.strata.fixed.group to c(1:length(age.group)) (2) if all age groups share the same intercept, then set age.strata.fixed.group to a rep(1, length(age.group)). The default for 6 age groups is the former. (3) If each temporal trend is associated with its own intercept, set it to be the same as <code>age.rw.group</code>.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_time.model">time.model</code></td>
<td>
<p>Model for the main temporal trend, can be rw1, rw2, ar1, or NULL (for spatial-only smoothing). Default to be rw2. For ar1 main effect, a linear slope is also added with time scaled to be between -0.5 to 0.5, i.e., the slope coefficient represents the total change between the first year and the last year in the projection period on the logit scale.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_st.time.model">st.time.model</code></td>
<td>
<p>Temporal component model for the interaction term, can be rw1, rw2, or ar1. Default to be the same as time.model unless specified otherwise. The default does not include region-specific random slopes. They can be added to the interaction term by specifying <code>pc.st.slope.u</code> and <code>pc.st.slope.alpha</code>.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_amat">Amat</code></td>
<td>
<p>Adjacency matrix for the regions</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_bias.adj">bias.adj</code></td>
<td>
<p>the ratio of unadjusted mortality rates or age-group-specific hazards to the true rates or hazards. It needs to be a data frame that can be merged to thee outcome, i.e., with the same column names for time periods (for national adjustment), or time periods and region (for subnational adjustment). The column specifying the adjustment ratio should be named &quot;ratio&quot;.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_bias.adj.by">bias.adj.by</code></td>
<td>
<p>vector of the column names specifying how to merge the bias adjustment to the count data. For example, if bias adjustment factor is provided in bias.adj for each region and time, then bias.adj.by should be <code>c("region", "time")</code>.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_formula">formula</code></td>
<td>
<p>INLA formula.  See vignette for example of using customized formula.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_year.label">year.label</code></td>
<td>
<p>string vector of year names</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_year_label">year_label</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> replaced by year.label</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_type.st">type.st</code></td>
<td>
<p>type for space-time interaction</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_survey.effect">survey.effect</code></td>
<td>
<p>logical indicator whether to include a survey fixed effect. If this is set to TRUE, there needs to be a column named 'survey' in the input data frame. In prediction, this effect term will be set to 0.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_linear.trend">linear.trend</code></td>
<td>
<p>logical indicator whether a linear trend is added to the temporal main effect. If the temporal main effect is RW2, then it will be forced to FALSE. Default is TRUE.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_common.trend">common.trend</code></td>
<td>
<p>logical indicator whether all age groups and strata share the same linear trend in the temporal main effect.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_strata.time.effect">strata.time.effect</code></td>
<td>
<p>logical indicator whether to include strata specific temporal trends.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_hyper">hyper</code></td>
<td>
<p>Deprecated. which hyperpriors to use. Only supports PC prior (&quot;pc&quot;).</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_pc.u">pc.u</code></td>
<td>
<p>hyperparameter U for the PC prior on precisions.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_pc.alpha">pc.alpha</code></td>
<td>
<p>hyperparameter alpha for the PC prior on precisions.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_pc.u.phi">pc.u.phi</code></td>
<td>
<p>hyperparameter U for the PC prior on the mixture probability phi in BYM2 model.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_pc.alpha.phi">pc.alpha.phi</code></td>
<td>
<p>hyperparameter alpha for the PC prior on the mixture probability phi in BYM2 model.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_pc.u.cor">pc.u.cor</code></td>
<td>
<p>hyperparameter U for the PC prior on the autocorrelation parameter in the AR prior, i.e. Prob(cor &gt; pc.u.cor) = pc.alpha.cor.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_pc.alpha.cor">pc.alpha.cor</code></td>
<td>
<p>hyperparameter alpha for the PC prior on the autocorrelation parameter in the AR prior.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_pc.st.u">pc.st.u</code></td>
<td>
<p>hyperparameter U for the PC prior on precisions for the interaction term.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_pc.st.alpha">pc.st.alpha</code></td>
<td>
<p>hyperparameter alpha for the PC prior on precisions for the interaction term.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_pc.st.slope.u">pc.st.slope.u</code></td>
<td>
<p>hyperparameter U for the PC prior on precisions for the area-level random slope. If both pc.st.slope.u and pc.st.slope.alpha are not NA, an area-level random slope with iid prior will be added to the model. The parameterization of the random slope is so that Prob(|beta| &gt; pc.st.slope.u) = pc.st.slope.alpha, where time covariate is rescaled to be -0.5 to 0.5, so that the random slope can be interpreted as the total deviation from the main trend from the first year to the last year to be projected, on the logit scale.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_pc.st.slope.alpha">pc.st.slope.alpha</code></td>
<td>
<p>hyperparameter alpha for the PC prior on precisions for the area-level random slope. See above for the parameterization.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_overdisp.mean">overdisp.mean</code></td>
<td>
<p>hyperparameter for the betabinomial likelihood. Mean of the over-dispersion parameter on the logit scale.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_overdisp.prec">overdisp.prec</code></td>
<td>
<p>hyperparameter for the betabinomial likelihood. Precision of the over-dispersion parameter on the logit scale.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_options">options</code></td>
<td>
<p>list of options to be passed to control.compute() in the inla() function.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_control.inla">control.inla</code></td>
<td>
<p>list of options to be passed to control.inla() in the inla() function. Default to the &quot;adaptive&quot; integration strategy.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_control.fixed">control.fixed</code></td>
<td>
<p>list of options to be passed to control.fixed() in the inla() function.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_verbose">verbose</code></td>
<td>
<p>logical indicator to print out detailed inla() intermediate steps.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_geo">geo</code></td>
<td>
<p>Deprecated. Spatial polygon file, legacy parameter from previous versions of the package.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_rw">rw</code></td>
<td>
<p>Deprecated. Take values 0, 1 or 2, indicating the order of random walk. If rw = 0, the autoregressive process is used instead of the random walk in the main trend. See the description of the argument ar for details.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_ar">ar</code></td>
<td>
<p>Deprecated. Order of the autoregressive component. If ar is specified to be positive integer, the random walk components will be replaced by AR(p) terms in the interaction part. The main temporal trend remains to be random walk of order rw unless rw = 0.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_st.rw">st.rw</code></td>
<td>
<p>Deprecated. Take values 1 or 2, indicating the order of random walk for the interaction term. If not specified, it will take the same order as the argument rw in the main effect. Notice that this argument is only used if ar is set to 0.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_age.rw.group">age.rw.group</code></td>
<td>
<p>Deprecated. Legacy parameter replaced by <code>age.time.group</code>.</p>
</td></tr>
<tr><td><code id="smoothCluster_+3A_...">...</code></td>
<td>
<p>arguments to be passed to the inla() function call.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>INLA model fit using the provided formula, country summary data, and geographic data
</p>


<h3>Author(s)</h3>

<p>Zehang Richard Li
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getDirect">getDirect</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(dplyr)
data(DemoData)
# Create dataset of counts
counts.all &lt;- NULL
for(i in 1:length(DemoData)){
  counts &lt;- getCounts(DemoData[[i]][, c("clustid", "time", "age", "died",
                                        "region", "strata")],
            variables = 'died', by = c("age", "clustid", "region", 
                                         "time", "strata"))
  counts &lt;- counts %&gt;% mutate(cluster = clustid, years = time, Y=died)
  counts$strata &lt;- gsub(".*\\.","",counts$strata)
  counts$survey &lt;- names(DemoData)[i] 
  counts.all &lt;- rbind(counts.all, counts)
}

# fit cluster-level model on the periods
periods &lt;- levels(DemoData[[1]]$time)
fit &lt;- smoothCluster(data = counts.all, 
     Amat = DemoMap$Amat, 
     time.model = "rw2", 
     st.time.model = "rw1",
     strata.time.effect =  TRUE, 
     survey.effect = TRUE,
     family = "betabinomial",
     year.label = c(periods, "15-19"))
summary(fit)
est &lt;- getSmoothed(fit, nsim = 1000)
plot(est$stratified, plot.CI=TRUE) + ggplot2::facet_wrap(~strata) 

# fit cluster-level space-time model with covariate
# notice without projected covariates, we use periods up to 10-14 only
# construct a random covariate matrix for illustration
periods &lt;- levels(DemoData[[1]]$time)
X &lt;- expand.grid(years = periods, 
       region = unique(counts.all$region))
X$X1 &lt;- rnorm(dim(X)[1])
X$X2 &lt;- rnorm(dim(X)[1])
fit.covariate &lt;- smoothCluster(data = counts.all, 
   X = X,
     Amat = DemoMap$Amat, 
     time.model = "rw2", 
     st.time.model = "rw1",
     strata.time.effect =  TRUE, 
     survey.effect = TRUE,
     family = "betabinomial",
     year.label = c(periods))
est &lt;- getSmoothed(fit.covariate, nsim = 1000)

# fit cluster-level model for one time point only
# i.e., space-only model
fit.sp &lt;- smoothCluster(data = subset(counts.all, time == "10-14"), 
     Amat = DemoMap$Amat, 
     time.model = NULL, 
     survey.effect = TRUE,
     family = "betabinomial")
summary(fit.sp)
est &lt;- getSmoothed(fit.sp, nsim = 1000)
plot(est$stratified, plot.CI = TRUE) + ggplot2::facet_wrap(~strata) 

# fit cluster-level model for one time point and covariate
# construct a random covariate matrix for illustration
X &lt;- data.frame(region = unique(counts.all$region),
      X1 = c(1, 2, 2, 1), 
      X2 = c(1, 1, 1, 2))
fit.sp.covariate &lt;- smoothCluster(data = subset(counts.all, time == "10-14"), 
     X = X, 
     Amat = DemoMap$Amat, 
     time.model = NULL, 
     survey.effect = TRUE,
     family = "betabinomial")
summary(fit.sp.covariate)
est &lt;- getSmoothed(fit.sp.covariate, nsim = 1000)

## End(Not run)

</code></pre>

<hr>
<h2 id='smoothDirect'>Smoothed direct estimates for mortality rates</h2><span id='topic+smoothDirect'></span>

<h3>Description</h3>

<p>The function <code>smoothDirect</code> replaces the previous function name <code>fitINLA</code> (before version 1.0.0).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smoothDirect(
  data,
  Amat,
  formula = NULL,
  time.model = c("rw1", "rw2", "ar1")[2],
  st.time.model = NULL,
  year.label,
  year_label = deprecated(),
  year.range = c(1980, 2014),
  year_range = deprecated(),
  is.yearly = TRUE,
  m = 5,
  type.st = 1,
  survey.effect = FALSE,
  hyper = c("pc", "gamma")[1],
  pc.u = 1,
  pc.alpha = 0.01,
  pc.u.phi = 0.5,
  pc.alpha.phi = 2/3,
  pc.u.cor = 0.7,
  pc.alpha.cor = 0.9,
  pc.st.u = NA,
  pc.st.alpha = NA,
  control.compute = list(dic = TRUE, mlik = TRUE, cpo = TRUE, openmp.strategy =
    "default", config = TRUE),
  control.inla = list(strategy = "adaptive", int.strategy = "auto"),
  control.fixed = list(),
  verbose = FALSE,
  geo = NULL,
  rw = NULL,
  ar = NULL,
  options = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="smoothDirect_+3A_data">data</code></td>
<td>
<p>Combined dataset</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_amat">Amat</code></td>
<td>
<p>Adjacency matrix for the regions</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_formula">formula</code></td>
<td>
<p>INLA formula. See vignette for example of using customized formula.</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_time.model">time.model</code></td>
<td>
<p>Model for the main temporal trend, can be rw1, rw2, or ar1. ar1 is not implemented for yearly model with period data input. Default to be rw2. For ar1 main effect, a linear slope is also added with time scaled to be between -0.5 to 0.5, i.e., the slope coefficient represents the total change between the first year and the last year in the projection period on the logit scale.</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_st.time.model">st.time.model</code></td>
<td>
<p>Temporal component model for the interaction term, can be rw1, rw2, or ar1. ar1 is not implemented for yearly model with period data input. Default to be the same as time.model unless specified otherwise. For ar1 interaction model, region-specific random slopes are currently not implemented.</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_year.label">year.label</code></td>
<td>
<p>string vector of year names</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_year_label">year_label</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> replaced by year.label</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_year.range">year.range</code></td>
<td>
<p>Entire range of the years (inclusive) defined in year.label.</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_year_range">year_range</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> replaced by year.range</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_is.yearly">is.yearly</code></td>
<td>
<p>Logical indicator for fitting yearly or period model.</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_m">m</code></td>
<td>
<p>Number of years in each period.</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_type.st">type.st</code></td>
<td>
<p>type for space-time interaction</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_survey.effect">survey.effect</code></td>
<td>
<p>logical indicator whether to include a survey iid random effect. If this is set to TRUE, there needs to be a column named 'survey' in the input data frame. In prediction, this random effect term will be set to 0. Notice this survey effect is implemented according to the Merter et al. (2015) model, and differently compared to the smoothCluster() function.</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_hyper">hyper</code></td>
<td>
<p>which hyperpriors to use. Default to be using the PC prior (&quot;pc&quot;).</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_pc.u">pc.u</code></td>
<td>
<p>hyperparameter U for the PC prior on precisions.</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_pc.alpha">pc.alpha</code></td>
<td>
<p>hyperparameter alpha for the PC prior on precisions.</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_pc.u.phi">pc.u.phi</code></td>
<td>
<p>hyperparameter U for the PC prior on the mixture probability phi in BYM2 model.</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_pc.alpha.phi">pc.alpha.phi</code></td>
<td>
<p>hyperparameter alpha for the PC prior on the mixture probability phi in BYM2 model.</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_pc.u.cor">pc.u.cor</code></td>
<td>
<p>hyperparameter U for the PC prior on the autocorrelation parameter in the AR prior, i.e. Prob(cor &gt; pc.u.cor) = pc.alpha.cor.</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_pc.alpha.cor">pc.alpha.cor</code></td>
<td>
<p>hyperparameter alpha for the PC prior on the autocorrelation parameter in the AR prior.</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_pc.st.u">pc.st.u</code></td>
<td>
<p>hyperparameter U for the PC prior on precisions for the interaction term.</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_pc.st.alpha">pc.st.alpha</code></td>
<td>
<p>hyperparameter alpha for the PC prior on precisions for the interaction term.</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_control.compute">control.compute</code></td>
<td>
<p>list of options to be passed to control.compute() in the inla() function. The default argument saves the internal objects created by INLA for posterior sampling later. If the fitted object is too large in size and there is no need to perform joint posterior sampling from the model (only used in benchmarking), this argument can be set to <code>control.compute = list(config = FALSE)</code> to reduce the size of the fitted object.</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_control.inla">control.inla</code></td>
<td>
<p>list of options to be passed to control.inla() in the inla() function. Default to the &quot;adaptive&quot; integration strategy.</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_control.fixed">control.fixed</code></td>
<td>
<p>list of options to be passed to control.fixed() in the inla() function.</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_verbose">verbose</code></td>
<td>
<p>logical indicator to print out detailed inla() intermediate steps.</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_geo">geo</code></td>
<td>
<p>Deprecated.</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_rw">rw</code></td>
<td>
<p>Deprecated.</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_ar">ar</code></td>
<td>
<p>Deprecated.</p>
</td></tr>
<tr><td><code id="smoothDirect_+3A_options">options</code></td>
<td>
<p>Deprecated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of fitted object
</p>


<h3>Author(s)</h3>

<p>Zehang Richard Li
</p>


<h3>References</h3>

<p>Li, Z., Hsiao, Y., Godwin, J., Martin, B. D., Wakefield, J., Clark, S. J., &amp; with support from the United Nations Inter-agency Group for Child Mortality Estimation and its technical advisory group. (2019). <em>Changes in the spatial distribution of the under-five mortality rate: Small-area analysis of 122 DHS surveys in 262 subregions of 35 countries in Africa.</em> PloS one, 14(1), e0210645.
</p>
<p>Mercer, L. D., Wakefield, J., Pantazis, A., Lutambi, A. M., Masanja, H., &amp; Clark, S. (2015). <em>Space-time smoothing of complex survey data: small area estimation for child mortality.</em> The annals of applied statistics, 9(4), 1889.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getDirect">getDirect</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  years &lt;- levels(DemoData[[1]]$time)
  # obtain direct estimates
  data_multi &lt;- getDirectList(births = DemoData, years = years,
  regionVar = "region",  timeVar = "time", clusterVar = "~clustid+id",
  ageVar = "age", weightsVar = "weights", geo.recode = NULL)
  data &lt;- aggregateSurvey(data_multi)
  
  #  national model
  years.all &lt;- c(years, "15-19")
  fit1 &lt;- smoothDirect(data = data, Amat = NULL, 
  year.label = years.all, year.range = c(1985, 2019), 
  time.model = 'rw2', m = 5, control.compute = list(config =TRUE))
  out1 &lt;- getSmoothed(fit1)
  plot(out1)
  
  #  subnational model
  fit2 &lt;- smoothDirect(data = data, Amat = DemoMap$Amat, 
  year.label = years.all, year.range = c(1985, 2019), 
  time.model = 'rw2', m = 5, type.st = 4)
  out2 &lt;- getSmoothed(fit2)
  plot(out2)
  
  #  subnational space-only model for one period
  fit3 &lt;- smoothDirect(data = subset(data, years == "10-14"), 
           time.model = NULL, Amat = DemoMap$Amat)
  out3 &lt;- getSmoothed(fit3)
  plot(out3, plot.CI = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='smoothSurvey'>Fit space-time smoothing models for a binary outcome from complex surveys.</h2><span id='topic+smoothSurvey'></span>

<h3>Description</h3>

<p>This function calculates the direct estimates by region and fit a simple spatial smoothing model to the direct estimates adjusting for survey design.
Normal or binary variables are currently supported. For binary variables, the logit transformation is performed on the direct estimates of probabilities, and a Gaussian additive model is fitted on the logit scale using INLA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smoothSurvey(
  data,
  geo = NULL,
  Amat = NULL,
  region.list = NULL,
  X = NULL,
  X.unit = NULL,
  responseType = deprecated(),
  response.type = c("binary", "gaussian")[1],
  responseVar,
  strataVar = "strata",
  weightVar = "weights",
  regionVar = "region",
  clusterVar = "~v001+v002",
  pc.u = 1,
  pc.alpha = 0.01,
  pc.u.phi = 0.5,
  pc.alpha.phi = 2/3,
  CI = 0.95,
  formula = NULL,
  timeVar = NULL,
  time.model = c("rw1", "rw2")[1],
  include_time_unstruct = deprecated(),
  include.time.unstruct = FALSE,
  type.st = 1,
  direct.est = NULL,
  direct.est.var = NULL,
  is.unit.level = FALSE,
  is.agg = FALSE,
  strataVar.within = NULL,
  totalVar = NULL,
  weight.strata = NULL,
  nsim = 1000,
  save.draws = FALSE,
  smooth = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="smoothSurvey_+3A_data">data</code></td>
<td>
<p>The input data frame. The input data  with column of the response variable (<code>responseVar</code>), region ID (<code>regionVar</code>), stratification within region (<code>strataVar</code>), and cluster ID (<code>clusterVar</code>).
</p>

<ul>
<li><p> For area-level model, the data frame consist of survey observations and corresponding survey weights (<code>weightVar</code>).
</p>
</li>
<li><p> For unit-level model and <code>is.agg = FALSE</code>, the data frame should consist of aggregated counts by clusters (for binary responses), or any cluster-level response (for continuous response). For binary response (<code>response.type = 'binary'</code>), the beta-binomial model will be fitted for cluster-level counts. For continuous response (<code>response.type = 'gaussian'</code>), a Gaussian smoothing model will be fitted on the cluster-level response.
</p>
</li>
<li><p> For unit-level model and <code>is.agg = TRUE</code>, the data frame should be the same as in the area-level model. For binary response (<code>response.type = 'binary'</code>), the beta-binomial model will be fitted for cluster-level counts aggregated internally. For continuous response (<code>response.type = 'gaussian'</code>), the nested error model will be fitted on unit-level response.
</p>
</li></ul>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_geo">geo</code></td>
<td>
<p>Deprecated argument from early versions.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_amat">Amat</code></td>
<td>
<p>Adjacency matrix for the regions. If set to NULL, the IID spatial effect will be used.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_region.list">region.list</code></td>
<td>
<p>a vector of region names. Only used when IID model is used and the adjacency matrix not specified. This allows the output to include regions with no sample in the data. When the spatial adjacency matrix is specified, the column names of the adjacency matrix will be used to determine region.list. If set to NULL, all regions in the data are used.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_x">X</code></td>
<td>
<p>Areal covariates data frame. One of the column name needs to match the <code>regionVar</code> specified in the function call, in order to be linked to the data input. Currently only supporting time-invariant region-level covariates.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_x.unit">X.unit</code></td>
<td>
<p>Column names of unit-level covariates. When <code>X.unit</code> is specified, a nested error model will be fitted with unit-level IID noise, and area-level predictions are produced by plugging in the covariate specified in the <code>X</code> argument. When <code>X</code> is not specified, the empirical mean of each covariate will be used. This is only implemented for continuous response with the Gaussian likelihood model and unit-level model.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_responsetype">responseType</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> The argument has been renamed into <code>response.type</code>.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_response.type">response.type</code></td>
<td>
<p>Type of the response variable, currently supports 'binary' (default with logit link function) or 'gaussian'.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_responsevar">responseVar</code></td>
<td>
<p>the response variable</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_stratavar">strataVar</code></td>
<td>
<p>the strata variable used in the area-level model.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_weightvar">weightVar</code></td>
<td>
<p>the weights variable</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_regionvar">regionVar</code></td>
<td>
<p>Variable name for region.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_clustervar">clusterVar</code></td>
<td>
<p>Variable name for cluster. For area-level model, this should be a formula for cluster in survey design object, e.g., '~clusterID + householdID'. For unit-level model, this should be the variable name for cluster unit.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_pc.u">pc.u</code></td>
<td>
<p>hyperparameter U for the PC prior on precisions.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_pc.alpha">pc.alpha</code></td>
<td>
<p>hyperparameter alpha for the PC prior on precisions.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_pc.u.phi">pc.u.phi</code></td>
<td>
<p>hyperparameter U for the PC prior on the mixture probability phi in BYM2 model.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_pc.alpha.phi">pc.alpha.phi</code></td>
<td>
<p>hyperparameter alpha for the PC prior on the mixture probability phi in BYM2 model.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_ci">CI</code></td>
<td>
<p>the desired posterior credible interval to calculate</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_formula">formula</code></td>
<td>
<p>a string of user-specified random effects model to be used in the INLA call</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_timevar">timeVar</code></td>
<td>
<p>The variable indicating time period. If set to NULL then the temporal model and space-time interaction model are ignored.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_time.model">time.model</code></td>
<td>
<p>the model for temporal trends and interactions. It can be either &quot;rw1&quot; or &quot;rw2&quot;.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_include_time_unstruct">include_time_unstruct</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> The argument has been renamed into <code>include.time.unstruct</code>.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_include.time.unstruct">include.time.unstruct</code></td>
<td>
<p>Indicator whether to include the temporal unstructured effects (i.e., shocks) in the smoothed estimates from cluster-level model. The argument only applies to the unit-level models. Default is FALSE which excludes all unstructured temporal components. If set to TRUE all  the unstructured temporal random effects will be included.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_type.st">type.st</code></td>
<td>
<p>can take values 0 (no interaction), or 1 to 4, corresponding to the type I to IV space-time interaction.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_direct.est">direct.est</code></td>
<td>
<p>data frame of direct estimates, with column names of response and region specified by <code>responseVar</code>, <code>regionVar</code>, and <code>timeVar</code>.  When <code>direct.est</code> is specified, it overwrites the <code>data</code> input.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_direct.est.var">direct.est.var</code></td>
<td>
<p>the column name corresponding to the variance of direct estimates.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_is.unit.level">is.unit.level</code></td>
<td>
<p>logical indicator of whether unit-level model is fitted instead of area-level model.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_is.agg">is.agg</code></td>
<td>
<p>logical indicator of whether the input is at the aggregated counts by cluster. Only used for unit-level model and binary response variable.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_stratavar.within">strataVar.within</code></td>
<td>
<p>the variable specifying within region stratification variable. This is only used for the unit-level model.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_totalvar">totalVar</code></td>
<td>
<p>the variable specifying total observations in <code>counts</code>. This is only used for the unit-level model when <code>counts</code> is specified.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_weight.strata">weight.strata</code></td>
<td>
<p>a data frame with one column corresponding to <code>regionVar</code>, and columns specifying proportion of each strata for each region. This argument specifies the weights for strata-specific estimates. This is only used for the unit-level model.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_nsim">nsim</code></td>
<td>
<p>number of posterior draws to take. This is only used for the unit-level model when <code>weight.strata</code> is provided.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_save.draws">save.draws</code></td>
<td>
<p>logical indicator of whether to save the full posterior draws.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_smooth">smooth</code></td>
<td>
<p>logical indicator of whether to perform smoothing. If set to FALSE, a data frame of direct estimate is returned. Only used when <code>is.unit.level</code> is FALSE.</p>
</td></tr>
<tr><td><code id="smoothSurvey_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>svydesign</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>smoothSurvey</code> replaces the previous function name <code>fitGeneric</code> (before version 1.0.0).
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>HT</code></td>
<td>
<p>Direct estimates</p>
</td></tr>
<tr><td><code>smooth</code></td>
<td>
<p>Smoothed direct estimates</p>
</td></tr>
<tr><td><code>fit</code></td>
<td>
<p>a fitted INLA object</p>
</td></tr>
<tr><td><code>CI</code></td>
<td>
<p>input argument</p>
</td></tr>
<tr><td><code>Amat</code></td>
<td>
<p>input argument</p>
</td></tr>
<tr><td><code>response.type</code></td>
<td>
<p>input argument</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>INLA formula</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zehang Richard Li
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getDirectList">getDirectList</a></code>, <code><a href="#topic+smoothDirect">smoothDirect</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
##
## 1. Area-level model with binary response
##

data(DemoData2)
data(DemoMap2)
fit0 &lt;- smoothSurvey(data=DemoData2,  
Amat=DemoMap2$Amat, response.type="binary", 
responseVar="tobacco.use", strataVar="strata", 
weightVar="weights", regionVar="region", 
clusterVar = "~clustid+id", CI = 0.95)
summary(fit0)

# if only direct estimates without smoothing is of interest
fit0.dir &lt;- smoothSurvey(data=DemoData2,  
Amat=DemoMap2$Amat, response.type="binary", 
responseVar="tobacco.use", strataVar="strata", 
weightVar="weights", regionVar="region", 
clusterVar = "~clustid+id", CI = 0.95, smooth = FALSE)

# posterior draws can be returned with save.draws = TRUE
fit0.draws &lt;- smoothSurvey(data=DemoData2,  
Amat=DemoMap2$Amat, response.type="binary", 
responseVar="tobacco.use", strataVar="strata", 
weightVar="weights", regionVar="region", 
clusterVar = "~clustid+id", CI = 0.95, save.draws = TRUE)
# notice the posterior draws are on the latent scale
head(fit0.draws$draws.est[, 1:10]) 

# Example with region-level covariates
 Xmat &lt;- aggregate(age~region, data = DemoData2, 
						FUN = function(x) mean(x))
 fit1 &lt;- smoothSurvey(data=DemoData2,  
  Amat=DemoMap2$Amat, response.type="binary", 
  X = Xmat,
  responseVar="tobacco.use", strataVar="strata", 
  weightVar="weights", regionVar="region", 
  clusterVar = "~clustid+id", CI = 0.95)

# Example with using only direct estimates as input instead of the full data
direct &lt;- fit0$direct[, c("region", "direct.est", "direct.var")]
fit2 &lt;- smoothSurvey(data=NULL, direct.est = direct, 
                    Amat=DemoMap2$Amat, regionVar="region",
                    responseVar="direct.est", direct.est.var = "direct.var", 
                    response.type = "binary")
# Check it is the same as fit0
plot(fit2$smooth$mean, fit0$smooth$mean)

# Example with using only direct estimates as input, 
#   and after transformation into a Gaussian smoothing model
# Notice: the output are on the same scale as the input 
#   and in this case, the logit estimates.    
direct.logit &lt;- fit0$direct[, c("region", "direct.logit.est", "direct.logit.var")]
fit3 &lt;- smoothSurvey(data=NULL, direct.est = direct.logit, 
               Amat=DemoMap2$Amat, regionVar="region",
               responseVar="direct.logit.est", direct.est.var = "direct.logit.var",
               response.type = "gaussian")
# Check it is the same as fit0
plot(fit3$smooth$mean, fit0$smooth$logit.mean)

# Example with non-spatial smoothing using IID random effects
fit4 &lt;- smoothSurvey(data=DemoData2, response.type="binary", 
       responseVar="tobacco.use", strataVar="strata", 
       weightVar="weights", regionVar="region", 
       clusterVar = "~clustid+id", CI = 0.95)

# Example with missing regions in the raw input
DemoData2.sub &lt;- subset(DemoData2, region != "central")
fit.without.central &lt;- smoothSurvey(data=DemoData2.sub,  
                         Amat=NULL, response.type="binary", 
                         responseVar="tobacco.use", strataVar="strata", 
                         weightVar="weights", regionVar="region", 
                         clusterVar = "~clustid+id", CI = 0.95)
fit.without.central$direct
fit.without.central$smooth

fit.with.central &lt;- smoothSurvey(data=DemoData2.sub,  
                         Amat=NULL, region.list = unique(DemoData2$region),
                         response.type="binary", 
                         responseVar="tobacco.use", strataVar="strata", 
                         weightVar="weights", regionVar="region", 
                         clusterVar = "~clustid+id", CI = 0.95)
fit.with.central$direct
fit.with.central$smooth

# Using the formula argument, further customizations can be added to the 
#  model fitted. For example, we can fit the Fay-Harriot model with 
#  IID effect instead of the BYM2 random effect as follows.
#  The "region.struct" and "hyperpc1" are picked to match internal object 
#  names. Other object names can be inspected from the source of smoothSurvey.
fit5 &lt;- smoothSurvey(data=DemoData2,  
       Amat=DemoMap2$Amat, response.type="binary", 
       formula = "f(region.struct, model = 'iid', hyper = hyperpc1)",
       pc.u = 1, pc.alpha = 0.01,
       responseVar="tobacco.use", strataVar="strata", 
       weightVar="weights", regionVar="region", 
       clusterVar = "~clustid+id", CI = 0.95)
# Check it is the same as fit4, notice the region order may be different
regions &lt;- fit5$smooth$region
plot(fit4$smooth[match(regions, fit4$smooth$region),]$logit.mean, fit5$smooth$logit.mean)

##
## 2. Unit-level model with binary response  
##

# For unit-level models, we need to create stratification variable within regions
data &lt;- DemoData2
data$urbanicity &lt;- "rural"
data$urbanicity[grep("urban", data$strata)] &lt;- "urban"

# Beta-binomial likelihood is used in this model
fit6 &lt;- smoothSurvey(data=data, 
  Amat=DemoMap2$Amat, response.type="binary", 
  X = Xmat, is.unit.level = TRUE,
  responseVar="tobacco.use", strataVar.within = "urbanicity", 
  regionVar="region", clusterVar = "clustid", CI = 0.95)

# We may use aggregated PSU-level counts as input as well
#    in the case of modeling a binary outcome 
data.agg &lt;- aggregate(tobacco.use~region + urbanicity + clustid, 
                      data = data, FUN = sum)
data.agg.total &lt;- aggregate(tobacco.use~region + urbanicity + clustid, 
                      data = data, FUN = length)
colnames(data.agg.total)[4] &lt;- "total"
data.agg &lt;- merge(data.agg, data.agg.total)
head(data.agg)

fit7 &lt;- smoothSurvey(data=data.agg, 
  Amat=DemoMap2$Amat, response.type="binary", 
  X = Xmat, is.unit.level = TRUE, is.agg = TRUE,
  responseVar = "tobacco.use", strataVar.within = "urbanicity", 
  totalVar = "total", regionVar="region", clusterVar = "clustid", CI = 0.95)

# Check it is the same as fit6
plot(fit6$smooth$mean, fit7$smooth$mean)  

##
## 3. Area-level model with continuous response
##

# The smoothing model is the same as area-level model with binary response
#  the continuous direct estimates are smoothed instead of 
#  their logit-transformed versions for binary response.
fit8 &lt;- smoothSurvey(data=DemoData2, Amat=DemoMap2$Amat, 
       response.type="gaussian", responseVar="age", strataVar="strata", 
       weightVar="weights", regionVar="region", 
       pc.u.phi = 0.5, pc.alpha.phi = 0.5,
       clusterVar = "~clustid+id", CI = 0.95)

##
## 4. Unit-level model with continuous response  
##    (or nested error models)

# The unit-level model assumes for each of the i-th unit,
#    Y_{i} ~ intercept + region_effect + IID_i
#    where IID_i is the error term specific to i-th unit

# When more than one level of cluster sampling is carried out, 
#   they are ignored here. Only the input unit is considered.
#   So here we do not need to specify clusterVar any more. 
fit9 &lt;- smoothSurvey(data= data, 
  Amat=DemoMap2$Amat, response.type="gaussian", 
  is.unit.level = TRUE, responseVar="age", strataVar.within = NULL,
  regionVar="region", clusterVar = NULL, CI = 0.95)

# To compare, we may also model PSU-level responses. As an illustration, 
data.median &lt;- aggregate(age~region + urbanicity + clustid, 
                      data = data, FUN = median)

fit10 &lt;- smoothSurvey(data= data.median, 
  Amat=DemoMap2$Amat, response.type="gaussian", 
  is.unit.level = TRUE, responseVar="age", strataVar.within = NULL,
  regionVar="region", clusterVar = "clustid", CI = 0.95)


# To further incorporate within-area stratification

fit11 &lt;- smoothSurvey(data = data, 
  Amat = DemoMap2$Amat, response.type = "gaussian", 
  is.unit.level = TRUE, responseVar="age", strataVar.within = "urbanicity",
  regionVar = "region", clusterVar = NULL, CI = 0.95)  

# Notice the usual output is now stratified within each region
# The aggregated estimates require strata proportions for each region
# For illustration, we set strata population proportions below
prop &lt;- data.frame(region = unique(data$region), 
                            urban = 0.3, 
                            rural = 0.7)
fit12 &lt;- smoothSurvey(data=data, 
  Amat=DemoMap2$Amat, response.type="gaussian", 
  is.unit.level = TRUE, responseVar="age", strataVar.within = "urbanicity",
  regionVar="region", clusterVar = NULL, CI = 0.95,
  weight.strata = prop)  

# aggregated outcome
head(fit12$smooth.overall)

# Compare aggregated outcome with direct aggregating posterior means. 
# There could be small differences if only 1000 posterior draws are taken.
est.urb &lt;- subset(fit11$smooth, strata == "urban")
est.rural &lt;- subset(fit11$smooth, strata == "rural")
est.mean.post &lt;- est.urb$mean * 0.3 + est.rural$mean * 0.7
plot(fit12$smooth.overall$mean, est.mean.post)


##
## 6. Unit-level model with continuous response and unit-level covariate 
## 

# For area-level prediction, area-level covariate mean needs to be  
#   specified in X argument. And unit-level covariate names are specified
#   in X.unit argument.

set.seed(1)
sim &lt;- data.frame(region = rep(c(1, 2, 3, 4), 1000),
                   X1 = rnorm(4000), X2 = rnorm(4000))
Xmean &lt;- aggregate(.~region, data = sim, FUN = sum)
sim$Y &lt;- rnorm(4000, mean = sim$X1 + 0.3 * sim$X2 + sim$region)
samp &lt;- sim[sample(1:4000, 20), ]
fit.sim &lt;- smoothSurvey(data=samp , 
                  X.unit = c("X1", "X2"),
                  X = Xmean, Amat=NULL, response.type="gaussian", 
                  is.unit.level = TRUE, responseVar="Y", regionVar = "region",  
                  pc.u = 1, pc.alpha = 0.01, CI = 0.95) 


## End(Not run)
</code></pre>

<hr>
<h2 id='smoothUnit'>Smooth via basic unit level model</h2><span id='topic+smoothUnit'></span>

<h3>Description</h3>

<p>Generates small area estimates by smoothing direct estimates using a basic
unit level model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smoothUnit(
  formula,
  domain,
  design,
  family = c("gaussian", "binomial")[1],
  X.pop = NULL,
  adj.mat = NULL,
  domain.size = NULL,
  pc.u = 1,
  pc.alpha = 0.01,
  pc.u.phi = 0.5,
  pc.alpha.phi = 2/3,
  level = 0.95,
  n.sample = 250,
  return.samples = F,
  X.pop.weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="smoothUnit_+3A_formula">formula</code></td>
<td>
<p>An object of class 'formula' describing the model to be fitted.</p>
</td></tr>
<tr><td><code id="smoothUnit_+3A_domain">domain</code></td>
<td>
<p>One-sided formula specifying factors containing domain labels</p>
</td></tr>
<tr><td><code id="smoothUnit_+3A_design">design</code></td>
<td>
<p>An object of class &quot;svydesign&quot; containing the data for the model</p>
</td></tr>
<tr><td><code id="smoothUnit_+3A_family">family</code></td>
<td>
<p>of the response variable, currently supports 'binomial' (default with logit link function) or 'gaussian'.</p>
</td></tr>
<tr><td><code id="smoothUnit_+3A_x.pop">X.pop</code></td>
<td>
<p>Data frame of population unit-level covariates. One of the column name needs to match the domain specified, in order to be linked to the data input. Currently only supporting time-invariant covariates.</p>
</td></tr>
<tr><td><code id="smoothUnit_+3A_adj.mat">adj.mat</code></td>
<td>
<p>Adjacency matrix with rownames matching the domain labels. If set to NULL, the IID spatial effect will be used.</p>
</td></tr>
<tr><td><code id="smoothUnit_+3A_domain.size">domain.size</code></td>
<td>
<p>Data frame of domain sizes. One of the column names needs to match the name of the domain variable, in order to be linked to the data input and there must be a column names 'size' containing domain sizes. The default option is no transformation, but logit and log are implemented.</p>
</td></tr>
<tr><td><code id="smoothUnit_+3A_pc.u">pc.u</code></td>
<td>
<p>Hyperparameter U for the PC prior on precisions. See the INLA documentation for more details on the parameterization.</p>
</td></tr>
<tr><td><code id="smoothUnit_+3A_pc.alpha">pc.alpha</code></td>
<td>
<p>Hyperparameter alpha for the PC prior on precisions.</p>
</td></tr>
<tr><td><code id="smoothUnit_+3A_pc.u.phi">pc.u.phi</code></td>
<td>
<p>Hyperparameter U for the PC prior on the mixture probability phi in BYM2 model.</p>
</td></tr>
<tr><td><code id="smoothUnit_+3A_pc.alpha.phi">pc.alpha.phi</code></td>
<td>
<p>Hyperparameter alpha for the PC prior on the mixture probability phi in BYM2 model.</p>
</td></tr>
<tr><td><code id="smoothUnit_+3A_level">level</code></td>
<td>
<p>The specified level for the posterior credible intervals</p>
</td></tr>
<tr><td><code id="smoothUnit_+3A_n.sample">n.sample</code></td>
<td>
<p>Number of draws from posterior used to compute summaries</p>
</td></tr>
<tr><td><code id="smoothUnit_+3A_return.samples">return.samples</code></td>
<td>
<p>If TRUE, return matrix of posterior samples of area level quantities</p>
</td></tr>
<tr><td><code id="smoothUnit_+3A_x.pop.weights">X.pop.weights</code></td>
<td>
<p>Optional vector of weights to use when aggregating unit level predictions</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A svysae object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(DemoData2)
data(DemoMap2)
library(survey)
des0 &lt;- svydesign(ids = ~clustid+id, strata = ~strata,
                 weights = ~weights, data = DemoData2, nest = TRUE)
                 
# EXAMPLE 1: Continuous response model
cts.res &lt;- smoothUnit(formula = tobacco.use ~ 1,
                      domain = ~region,
                      design = des0, X.pop = DemoData2)
                      
# EXAMPLE 2: Binary response model
bin.res &lt;- smoothUnit(formula = tobacco.use ~ 1,
                      family = "binomial",
                      domain = ~region,
                      design = des0, X.pop = DemoData2)

## End(Not run)
</code></pre>

<hr>
<h2 id='st.new'>New Type I to IV space time interaction models for m-year to period random effects</h2><span id='topic+st.new'></span>

<h3>Description</h3>

<p>New Type I to IV space time interaction models for m-year to period random effects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>st.new(
  cmd = c("graph", "Q", "mu", "initial", "log.norm.const", "log.prior", "quit"),
  theta = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="st.new_+3A_cmd">cmd</code></td>
<td>
<p>list of model components</p>
</td></tr>
<tr><td><code id="st.new_+3A_theta">theta</code></td>
<td>
<p>log precision</p>
</td></tr>
</table>

<hr>
<h2 id='st.new.pc'>New Type I to IV space time interaction models for m-year to period random effects</h2><span id='topic+st.new.pc'></span>

<h3>Description</h3>

<p>New Type I to IV space time interaction models for m-year to period random effects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>st.new.pc(
  cmd = c("graph", "Q", "mu", "initial", "log.norm.const", "log.prior", "quit"),
  theta = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="st.new.pc_+3A_cmd">cmd</code></td>
<td>
<p>list of model components</p>
</td></tr>
<tr><td><code id="st.new.pc_+3A_theta">theta</code></td>
<td>
<p>log precision</p>
</td></tr>
</table>

<hr>
<h2 id='summary.SUMMERmodel'>Summary method for the smoothing models.</h2><span id='topic+summary.SUMMERmodel'></span>

<h3>Description</h3>

<p>This function is the summary method for class <code>SUMMERmodel</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SUMMERmodel'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.SUMMERmodel_+3A_object">object</code></td>
<td>
<p>output from <code><a href="#topic+smoothDirect">smoothDirect</a></code> or <code><a href="#topic+smoothCluster">smoothCluster</a></code></p>
</td></tr>
<tr><td><code id="summary.SUMMERmodel_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zehang Li
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.SUMMERmodel">summary.SUMMERmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  library(SUMMER)
  library(dplyr)
  data(DemoData)

  # Smooth Direct Model
  years &lt;- levels(DemoData[[1]]$time)
  # obtain direct estimates
  data_multi &lt;- getDirectList(births = DemoData, years = years,
  regionVar = "region",  timeVar = "time", clusterVar = "~clustid+id",
  ageVar = "age", weightsVar = "weights", geo.recode = NULL)
  data &lt;- aggregateSurvey(data_multi)
  
  years.all &lt;- c(years, "15-19")
  fit &lt;- smoothDirect(data = data, Amat = NULL, 
  year.label = years.all, year.range = c(1985, 2019), 
  time.model = 'rw2', is.yearly=FALSE, m = 5)
  summary(fit)

  # Cluster-level Model
  counts.all &lt;- NULL
  for(i in 1:length(DemoData)){
  counts &lt;- getCounts(DemoData[[i]][, c("clustid", "time", "age", "died",
                                       "region", "strata")],
           variables = 'died', by = c("age", "clustid", "region", 
                                        "time", "strata"))
  counts &lt;- counts %&gt;% mutate(cluster = clustid, years = time, Y=died)
  counts$strata &lt;- gsub(".*\\.","",counts$strata)
  counts$survey &lt;- names(DemoData)[i] 
  counts.all &lt;- rbind(counts.all, counts)
  }
  
  # fit cluster-level model on the periods
  periods &lt;- levels(DemoData[[1]]$time)
  fit &lt;- smoothCluster(data = counts.all, 
     Amat = DemoMap$Amat, 
     time.model = "rw2", 
     st.time.model = "rw1",
     strata.time.effect =  TRUE, 
     survey.effect = TRUE,
     family = "betabinomial",
     year.label = c(periods, "15-19"))
  summary(fit) 

## End(Not run)
</code></pre>

<hr>
<h2 id='summary.SUMMERmodel.svy'>Summary method for the smoothing model and output from <code>smoothSurvey</code>.</h2><span id='topic+summary.SUMMERmodel.svy'></span>

<h3>Description</h3>

<p>This function is the summary method for class <code>SUMMERmodel.svy</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SUMMERmodel.svy'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.SUMMERmodel.svy_+3A_object">object</code></td>
<td>
<p>output from <code><a href="#topic+smoothSurvey">smoothSurvey</a></code></p>
</td></tr>
<tr><td><code id="summary.SUMMERmodel.svy_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zehang Li
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.SUMMERmodel.svy">summary.SUMMERmodel.svy</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(DemoData2)
data(DemoMap2)
fit0 &lt;- smoothSurvey(data=DemoData2,  
Amat=DemoMap2$Amat, responseType="binary", 
responseVar="tobacco.use", strataVar="strata", 
weightVar="weights", regionVar="region", 
clusterVar = "~clustid+id", CI = 0.95)
summary(fit0)

## End(Not run)
</code></pre>

<hr>
<h2 id='summary.SUMMERprojlist'>Summary method for the combined projection output.
This function is the print method for class <code>SUMMERprojlist</code>.</h2><span id='topic+summary.SUMMERprojlist'></span>

<h3>Description</h3>

<p>Summary method for the combined projection output.
This function is the print method for class <code>SUMMERprojlist</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SUMMERprojlist'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.SUMMERprojlist_+3A_object">object</code></td>
<td>
<p>output from <code><a href="#topic+getSmoothed">getSmoothed</a></code></p>
</td></tr>
<tr><td><code id="summary.SUMMERprojlist_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zehang Li
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
 library(SUMMER)
 library(dplyr)
 data(DemoData)
 # Create dataset of counts
 counts.all &lt;- NULL
 for(i in 1:length(DemoData)){
 counts &lt;- getCounts(DemoData[[i]][, c("clustid", "time", "age", "died",
                                      "region", "strata")],
          variables = 'died', by = c("age", "clustid", "region", 
                                       "time", "strata"))
 counts &lt;- counts %&gt;% mutate(cluster = clustid, years = time, Y=died)
 counts$strata &lt;- gsub(".*\\.","",counts$strata)
 counts$survey &lt;- names(DemoData)[i] 
 counts.all &lt;- rbind(counts.all, counts)
 }
 
 # fit cluster-level model on the periods
 periods &lt;- levels(DemoData[[1]]$time)
 fit &lt;- smoothCluster(data = counts.all, 
    Amat = DemoMap$Amat, 
    time.model = "rw2", 
    st.time.model = "rw1",
    strata.time.effect =  TRUE, 
    survey.effect = TRUE,
    family = "betabinomial",
    year.label = c(periods, "15-19"))
 summary(fit)
 est &lt;- getSmoothed(fit, nsim = 1000)

## End(Not run)
</code></pre>

<hr>
<h2 id='tcpPlot'>Discrete-color maps based on the True Classification Probabilities</h2><span id='topic+tcpPlot'></span>

<h3>Description</h3>

<p>Discrete-color maps based on the True Classification Probabilities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tcpPlot(
  draws,
  geo,
  by.geo = NULL,
  year.plot = NULL,
  year_plot = deprecated(),
  ncol = 4,
  per1000 = FALSE,
  thresholds = NULL,
  intervals = 3,
  size.title = 0.7,
  legend.label = NULL,
  border = "gray20",
  size = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tcpPlot_+3A_draws">draws</code></td>
<td>
<p>a posterior draw object from <code><a href="#topic+getSmoothed">getSmoothed</a></code></p>
</td></tr>
<tr><td><code id="tcpPlot_+3A_geo">geo</code></td>
<td>
<p>SpatialPolygonsDataFrame object for the map</p>
</td></tr>
<tr><td><code id="tcpPlot_+3A_by.geo">by.geo</code></td>
<td>
<p>variable name specifying region names in geo</p>
</td></tr>
<tr><td><code id="tcpPlot_+3A_year.plot">year.plot</code></td>
<td>
<p>vector of year string vector to be plotted.</p>
</td></tr>
<tr><td><code id="tcpPlot_+3A_year_plot">year_plot</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> replaced by year.plot</p>
</td></tr>
<tr><td><code id="tcpPlot_+3A_ncol">ncol</code></td>
<td>
<p>number of columns in the output figure.</p>
</td></tr>
<tr><td><code id="tcpPlot_+3A_per1000">per1000</code></td>
<td>
<p>logical indicator to multiply results by 1000.</p>
</td></tr>
<tr><td><code id="tcpPlot_+3A_thresholds">thresholds</code></td>
<td>
<p>a vector of thresholds (on the mortality scale) defining the discrete color scale of the maps.</p>
</td></tr>
<tr><td><code id="tcpPlot_+3A_intervals">intervals</code></td>
<td>
<p>number of quantile intervals defining the discrete color scale of the maps. Required when thresholds are not specified.</p>
</td></tr>
<tr><td><code id="tcpPlot_+3A_size.title">size.title</code></td>
<td>
<p>a numerical value giving the amount by which the plot title should be magnified relative to the default.</p>
</td></tr>
<tr><td><code id="tcpPlot_+3A_legend.label">legend.label</code></td>
<td>
<p>Label for the color legend.</p>
</td></tr>
<tr><td><code id="tcpPlot_+3A_border">border</code></td>
<td>
<p>color of the border</p>
</td></tr>
<tr><td><code id="tcpPlot_+3A_size">size</code></td>
<td>
<p>size of the border</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of True Classification Probability (TCP) tables, a list of individual spplot maps, and a gridded array of all maps.
</p>


<h3>Author(s)</h3>

<p>Tracy Qi Dong, Zehang Richard Li
</p>


<h3>References</h3>

<p>Tracy Qi Dong, and Jon Wakefield. (2020) <em>Modeling and presentation of vaccination coverage estimates using data from household surveys.</em> arXiv preprint arXiv:2004.03127.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(dplyr)
data(DemoData)
# Create dataset of counts, unstratified
counts.all &lt;- NULL
for(i in 1:length(DemoData)){
  counts &lt;- getCounts(DemoData[[i]][, c("clustid", "time", "age", "died",
                                        "region")],
            variables = 'died', by = c("age", "clustid", "region", 
                                         "time"))
  counts &lt;- counts %&gt;% mutate(cluster = clustid, years = time, Y=died)
  counts$strata &lt;- NA
  counts$survey &lt;- names(DemoData)[i] 
  counts.all &lt;- rbind(counts.all, counts)
}

# fit cluster-level model on the periods
periods &lt;- levels(DemoData[[1]]$time)
fit &lt;- smoothCluster(data = counts.all, 
      Amat = DemoMap$Amat, 
      time.model = "rw2", 
      st.time.model = "rw1",
      strata.time.effect =  TRUE, 
      survey.effect = TRUE,
      family = "betabinomial",
      year.label = c(periods, "15-19"))
est &lt;- getSmoothed(fit, nsim = 1000, save.draws=TRUE)

tcp &lt;- tcpPlot(est, DemoMap$geo, by.geo = "REGNAME", interval = 3, year.plot = periods) 
tcp$g

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
