<!DOCTYPE html><html><head><title>Help for package tgp</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {tgp}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#tgp-package'>
<p>The Treed Gaussian Process Model Package</p></a></li>
<li><a href='#btgp'><p>Bayesian Nonparametric &amp; Nonstationary Regression Models</p></a></li>
<li><a href='#default.itemps'><p> Default Sigmoidal, Harmonic and Geometric Temperature Ladders</p></a></li>
<li><a href='#dopt.gp'><p>Sequential D-Optimal Design for a Stationary Gaussian Process</p></a></li>
<li><a href='#exp2d'><p> 2-d Exponential Data</p></a></li>
<li><a href='#exp2d.rand'><p> Random 2-d Exponential Data</p></a></li>
<li><a href='#exp2d.Z'><p> Random Z-values for 2-d Exponential Data</p></a></li>
<li><a href='#friedman.1.data'><p> First Friedman Dataset and a variation</p></a></li>
<li><a href='#interp.loess'><p> Lowess 2-d interpolation onto a uniform grid</p></a></li>
<li><a href='#itemps'><p> Functions to plot summary information about</p>
the sampled inverse temperatures, tree heights, etc., stored in the
traces of a &quot;tgp&quot;-class object</a></li>
<li><a href='#lhs'><p>Latin Hypercube sampling</p></a></li>
<li><a href='#mapT'><p> Plot the MAP partition, or add one to an existing plot</p></a></li>
<li><a href='#optim.tgp'><p> Surrogate-based optimization of noisy black-box function</p></a></li>
<li><a href='#partition'><p> Partition data according to the MAP tree</p></a></li>
<li><a href='#plot.tgp'><p> Plotting for Treed Gaussian Process Models</p></a></li>
<li><a href='#predict.tgp'><p> Predict method for Treed Gaussian process models</p></a></li>
<li><a href='#sens'><p>Monte Carlo Bayesian Sensitivity Analysis</p></a></li>
<li><a href='#tgp-internal'><p>Internal Treed Gaussian Process Model Functions</p></a></li>
<li><a href='#tgp.default.params'><p> Default Treed Gaussian Process Model Parameters</p></a></li>
<li><a href='#tgp.design'><p> Sequential Treed D-Optimal Design for Treed Gaussian Process Models</p></a></li>
<li><a href='#tgp.trees'><p> Plot the MAP Tree for each height encountered by the Markov Chain</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Bayesian Treed Gaussian Process Models</td>
</tr>
<tr>
<td>Version:</td>
<td>2.4-22</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-11-27</td>
</tr>
<tr>
<td>Author:</td>
<td>Robert B. Gramacy &lt;rbg@vt.edu&gt; and Matt A. Taddy</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.14.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>maptree</td>
</tr>
<tr>
<td>Suggests:</td>
<td>MASS</td>
</tr>
<tr>
<td>Description:</td>
<td>Bayesian nonstationary, semiparametric nonlinear regression 
 and design by treed Gaussian processes (GPs) with jumps to the limiting 
 linear model (LLM).  Special cases also implemented include Bayesian 
 linear models, CART, treed linear models, stationary separable and 
 isotropic GPs, and GP single-index models.  Provides 1-d and 2-d plotting functions 
 (with projection and slice capabilities) and tree drawing, designed for 
 visualization of tgp-class output.  Sensitivity analysis and 
 multi-resolution models are supported. Sequential experimental 
 design and adaptive sampling functions are also provided, including ALM, 
 ALC, and expected improvement.  The latter supports derivative-free
 optimization of noisy black-box functions.  For details and tutorials, 
 see Gramacy (2007) &lt;<a href="https://doi.org/10.18637%2Fjss.v019.i09">doi:10.18637/jss.v019.i09</a>&gt; and Gramacy &amp; Taddy (2010) 
 &lt;<a href="https://doi.org/10.18637%2Fjss.v033.i06">doi:10.18637/jss.v033.i06</a>&gt;.  </td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Robert B. Gramacy  &lt;rbg@vt.edu&gt;</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/LGPL-2">LGPL-2</a> | <a href="https://www.r-project.org/Licenses/LGPL-2.1">LGPL-2.1</a> | <a href="https://www.r-project.org/Licenses/LGPL-3">LGPL-3</a> [expanded from: LGPL]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://bobby.gramacy.com/r_packages/tgp/">https://bobby.gramacy.com/r_packages/tgp/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-27 20:54:05 UTC; bobby</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-28 16:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='tgp-package'>
The Treed Gaussian Process Model Package
</h2><span id='topic+tgp-package'></span>

<h3>Description</h3>

<p>A Bayesian nonstationary nonparametric regression and design package 
implementing an array of models of varying flexibility and complexity.
</p>


<h3>Details</h3>

<p>This package implements Bayesian nonstationary, semiparametric nonlinear
regression with &ldquo;treed Gaussian process models&rdquo; with jumps to the
limiting linear model (LLM).  The package contains functions which facilitate
inference for seven regression models of varying complexity using Markov chain
Monte Carlo (MCMC): linear model, CART (Classification and Regression
Tree), treed linear model, Gaussian process (GP),  GP with jumps to the LLM, 
GP single-index models, treed GPs, treed GP LLMs, and treed GP single-index
models.  R provides an interface to the C/C++ backbone, 
and a serves as mechanism for graphically visualizing the results of inference 
and posterior predictive surfaces under the models.  A Bayesian Monte Carlo
based sensitivity analysis is implemented, and multi-resolution models are
also supported.  Sequential experimental design and adaptive sampling 
functions are also provided, including ALM, ALC, and expected improvement.  
The latter supports derivative-free optimization of noisy black-box functions.
</p>
<p>For a fuller overview including a complete list of functions, demos and
vignettes, please use <code>help(package="tgp")</code>.
</p>


<h3>Author(s)</h3>

 
<p>Robert B. Gramacy, <a href="mailto:rbg@vt.edu">rbg@vt.edu</a>, and
Matt Taddy, <a href="mailto:mataddy@amazon.com">mataddy@amazon.com</a>
</p>


<h3>References</h3>

<p>Gramacy, R. B. (2020) <em>Surrogates: Gaussian Process Modeling,
Design and Optimization for the Applied Sciences</em>. Boca Raton,
Florida: Chapman Hall/CRC.  (See Chapter 9.)
<a href="https://bobby.gramacy.com/surrogates/">https://bobby.gramacy.com/surrogates/</a>
</p>
<p>Gramacy, R. B. (2007). <em><span class="pkg">tgp</span>: An <span class="rlang"><b>R</b></span> Package for
Bayesian Nonstationary, Semiparametric Nonlinear Regression
and Design by Treed Gaussian Process Models.</em>
Journal of Statistical Software, <b>19</b>(9).
<a href="https://www.jstatsoft.org/v19/i09">https://www.jstatsoft.org/v19/i09</a>
<a href="https://doi.org/10.18637/jss.v019.i09">doi:10.18637/jss.v019.i09</a>
</p>
<p>Robert B. Gramacy, Matthew Taddy (2010). <em>Categorical Inputs,
Sensitivity Analysis, Optimization and Importance Tempering with <span class="pkg">tgp</span>
Version 2, an <span class="rlang"><b>R</b></span> Package for Treed Gaussian Process Models.</em>
Journal of Statistical Software, <b>33</b>(6), 1&ndash;48.
<a href="https://www.jstatsoft.org/v33/i06/">https://www.jstatsoft.org/v33/i06/</a>
<a href="https://doi.org/10.18637/jss.v033.i06">doi:10.18637/jss.v033.i06</a>
</p>
<p>Gramacy, R. B., Lee, H. K. H. (2008).
<em>Bayesian treed Gaussian process models with an application
to computer modeling</em>. Journal of the American Statistical Association, 
103(483), pp. 1119-1130.  Also available as ArXiv article 0710.4536 
<a href="https://arxiv.org/abs/0710.4536">https://arxiv.org/abs/0710.4536</a>
</p>
<p>Robert B. Gramacy, Heng Lian (2011).
<em>Gaussian process single-index models as emulators for computer
experiments</em>.  Available as ArXiv article 1009.4241
<a href="https://arxiv.org/abs/1009.4241">https://arxiv.org/abs/1009.4241</a>
</p>
<p>Gramacy, R. B., Lee, H. K. H. (2006).
<em>Adaptive design of supercomputer experiments.</em>
Available as UCSC Technical Report ams2006-02. 
</p>
<p>Gramacy, R.B., Samworth, R.J., and King, R. (2007)
<em>Importance Tempering.</em> ArXiV article 0707.4242
<a href="https://arxiv.org/abs/0707.4242">https://arxiv.org/abs/0707.4242</a>
</p>
<p>Gray, G.A., Martinez-Canales, M., Taddy, M.A., Lee, H.K.H., and
Gramacy, R.B. (2007) <em>Enhancing Parallel Pattern Search Optimization with
a Gaussian Process Oracle</em>, SAND2006-7946C, Proceedings of the NECDC
</p>
<p><a href="https://bobby.gramacy.com/r_packages/tgp/">https://bobby.gramacy.com/r_packages/tgp/</a>
</p>

<hr>
<h2 id='btgp'>Bayesian Nonparametric &amp; Nonstationary Regression Models</h2><span id='topic+blm'></span><span id='topic+btlm'></span><span id='topic+bcart'></span><span id='topic+bgp'></span><span id='topic+bgpllm'></span><span id='topic+btgp'></span><span id='topic+btgpllm'></span>

<h3>Description</h3>

<p> The seven functions described below implement Bayesian
regression models of varying complexity: linear model, linear CART,
Gaussian process (GP), GP with jumps to the limiting linear model
(LLM), treed GP, and treed GP LLM. </p>


<h3>Usage</h3>

<pre><code class='language-R'>blm(X, Z, XX = NULL, meanfn = "linear", bprior = "bflat",
        BTE = c(1000, 4000, 3), R = 1, m0r1 = TRUE, itemps = NULL,
        pred.n = TRUE, krige = TRUE, zcov = FALSE, Ds2x = FALSE,
        improv = FALSE, sens.p = NULL, trace = FALSE, verb = 1, ...)
btlm(X, Z, XX = NULL, meanfn = "linear", bprior = "bflat",
        tree = c(0.5, 2), BTE = c(2000, 7000, 2), R = 1, m0r1 = TRUE, 
	itemps = NULL, pred.n = TRUE, krige = TRUE, zcov = FALSE,
        Ds2x = FALSE, improv = FALSE, sens.p = NULL, trace = FALSE,
        verb = 1, ...)
bcart(X, Z, XX = NULL, bprior = "bflat", tree = c(0.5, 2),
        BTE = c(2000, 7000, 2), R = 1, m0r1 = TRUE, itemps = NULL,
        pred.n = TRUE, krige = TRUE, zcov = FALSE, Ds2x = FALSE,
        improv=FALSE, sens.p = NULL, trace = FALSE, verb = 1, ...)
bgp(X, Z, XX = NULL, meanfn = "linear", bprior = "bflat",
        corr = "expsep", BTE = c(1000, 4000, 2), R = 1, m0r1 = TRUE, 
	itemps = NULL, pred.n = TRUE, krige = TRUE, zcov = FALSE,
        Ds2x = FALSE, improv = FALSE, sens.p = NULL, nu = 1.5,
        trace = FALSE, verb = 1, ...)
bgpllm(X, Z, XX = NULL, meanfn = "linear", bprior = "bflat",
        corr = "expsep", gamma=c(10,0.2,0.7), BTE = c(1000, 4000, 2),
        R = 1, m0r1 = TRUE, itemps = NULL, pred.n = TRUE,
        krige = TRUE, zcov = FALSE, Ds2x = FALSE, improv = FALSE,
        sens.p = NULL, nu = 1.5, trace = FALSE, verb = 1, ...)
btgp(X, Z, XX = NULL, meanfn = "linear", bprior = "bflat",
        corr = "expsep", tree = c(0.5, 2), BTE = c(2000, 7000, 2),
        R = 1, m0r1 = TRUE, linburn = FALSE, itemps = NULL, 
	pred.n = TRUE, krige = TRUE, zcov = FALSE, Ds2x = FALSE,
        improv = FALSE, sens.p = NULL, nu = 1.5, trace = FALSE,
        verb = 1, ...)
btgpllm(X, Z, XX = NULL, meanfn = "linear", bprior = "bflat",
        corr = "expsep", tree = c(0.5, 2), gamma=c(10,0.2,0.7), 
	BTE = c(2000, 7000, 2), R = 1, m0r1 = TRUE, linburn = FALSE,
        itemps = NULL, pred.n = TRUE, krige = TRUE, zcov = FALSE,
        Ds2x = FALSE, improv = FALSE, sens.p = NULL, nu = 1.5,
        trace = FALSE, verb = 1, ...)
</code></pre>


<h3>Arguments</h3>

<p>Each of the above functions takes some subset of the following arguments...
</p>
<table>
<tr><td><code id="btgp_+3A_x">X</code></td>
<td>
<p><code>data.frame</code>, <code>matrix</code>, or vector of inputs <code>X</code> </p>
</td></tr>
<tr><td><code id="btgp_+3A_z">Z</code></td>
<td>
<p> Vector of output responses <code>Z</code> of length equal to the
leading dimension (rows) of <code>X</code>, i.e., <code>length(Z) == nrow(X)</code></p>
</td></tr>
<tr><td><code id="btgp_+3A_xx">XX</code></td>
<td>
<p> Optional <code>data.frame</code>, <code>matrix</code>,
or vector of predictive input locations 
with the same number of columns as <code>X</code>, i.e.,
<code>ncol(XX) == ncol(X)</code></p>
</td></tr>
<tr><td><code id="btgp_+3A_meanfn">meanfn</code></td>
<td>
<p> A choice of mean function for the process.  When
<code>meanfn = "linear"</code> (default), then we have the process
</p>
<p style="text-align: center;"><code class="reqn">Z = (\mathbf{1}  \;\; \mathbf{X}) \beta + W(\mathbf{X})</code>
</p>

<p>where <code class="reqn">W(\mathbf{X})</code> represents the Gaussian process
part of the model (if present).  Otherwise, when
<code>meanfn = "constant"</code>, then </p>
<p style="text-align: center;"><code class="reqn">Z = \beta_0 + W(\mathbf{X})</code>
</p>
</td></tr>
<tr><td><code id="btgp_+3A_bprior">bprior</code></td>
<td>
<p>Linear (beta) prior, default is <code>"bflat"</code>;
alternates include <code>"b0"</code> hierarchical Normal prior,
<code>"bmle"</code> empirical Bayes Normal prior, <code>"b0not"</code> Bayesian
treed LM-style prior from Chipman et al. (same as <code>"b0"</code> but
without <code>tau2</code>), <code>"bmzt"</code> a independent Normal
prior (mean zero) with inverse-gamma variance (<code>tau2</code>),
and <code>"bmznot"</code> is the same as <code>"bmznot"</code> without <code>tau2</code>.
The default <code>"bflat"</code> gives
an &ldquo;improper&rdquo; prior which can perform badly when the
signal-to-noise ratio is low.  In these cases the &ldquo;proper&rdquo; hierarchical
specification <code>"b0"</code> or independent <code>"bmzt"</code> or <code>"bmznot"</code>
priors may perform better</p>
</td></tr>
<tr><td><code id="btgp_+3A_tree">tree</code></td>
<td>
<p> a 2-vector containing the tree process prior parameterization
<code>c(alpha, beta)</code> specifying
</p>
<p style="text-align: center;"><code class="reqn">p_{\mbox{\tiny split}}(\eta, \mathcal{T}) =
      \alpha*(1+\eta)^\beta</code>
</p>

<p>automatically giving zero probability to trees
with partitions containing less than <code>min(c(10,nrow(X)+1))</code>
data points.  You may also specify a longer vector, writing over
more of the components of the <code>$tree</code> output from <code><a href="#topic+tgp.default.params">tgp.default.params</a></code></p>
</td></tr>
<tr><td><code id="btgp_+3A_gamma">gamma</code></td>
<td>
<p>Limiting linear model parameters <code>c(g, t1, t2)</code>,
with growth parameter <code>g &gt; 0</code>
minimum parameter <code>t1 &gt;= 0</code> and maximum parameter <code>t1 &gt;= 0</code>, where
<code>t1 + t2 &lt;= 1</code> specifies
</p>
<p style="text-align: center;"><code class="reqn">p(b|d)=t_1 +\exp\left\{\frac{-g(t_2-t_1)}{d-0.5}\right\}</code>
</p>
</td></tr>
<tr><td><code id="btgp_+3A_corr">corr</code></td>
<td>
<p> Gaussian process correlation model. Choose between the isotropic
power exponential family (<code>"exp"</code>) or the separable power exponential 
family (<code>"expsep"</code>, default); the current version also supports 
the isotropic Matern (<code>"matern"</code>) and single-index Model (<code>"sim"</code>) 
as &ldquo;beta&rdquo; functionality.  
</p>
</td></tr>
<tr><td><code id="btgp_+3A_bte">BTE</code></td>
<td>
<p> 3-vector of Monte-carlo parameters (B)urn in, (T)otal, and
(E)very. Predictive samples are saved every E MCMC rounds starting
at round B, stopping at T. </p>
</td></tr>
<tr><td><code id="btgp_+3A_r">R</code></td>
<td>
<p> Number of repeats or restarts of <code>BTE</code> MCMC rounds,
default <code>R=1</code> is no restarts</p>
</td></tr>
<tr><td><code id="btgp_+3A_m0r1">m0r1</code></td>
<td>
<p>If <code>TRUE</code> (default) the responses <code>Z</code> will be
scaled to have a mean of zero and a range of 1</p>
</td></tr>
<tr><td><code id="btgp_+3A_linburn">linburn</code></td>
<td>
<p>If <code>TRUE</code> initializes MCMC with <code>B</code> (additional) 
rounds of Bayesian Linear CART (<code>btlm</code>); default is <code>FALSE</code> </p>
</td></tr>
<tr><td><code id="btgp_+3A_itemps">itemps</code></td>
<td>
<p> Importance tempering (IT) inverse temperature ladder, 
or powers to improve mixing.  See <code><a href="#topic+default.itemps">default.itemps</a></code>.
The default is no IT <code>itemps = NULL</code></p>
</td></tr>
<tr><td><code id="btgp_+3A_pred.n">pred.n</code></td>
<td>
<p><code>TRUE</code> (default) value results in prediction at
the inputs <code>X</code>; <code>FALSE</code> 
skips prediction at <code>X</code> resulting in a faster
implementation</p>
</td></tr>
<tr><td><code id="btgp_+3A_krige">krige</code></td>
<td>
<p><code>TRUE</code> (default) value results in collection of kriging
means and variances at predictive (and/or data) locations; <code>FALSE</code> 
skips the gathering of kriging statistics giving a savings in
storage</p>
</td></tr>
<tr><td><code id="btgp_+3A_zcov">zcov</code></td>
<td>
<p>If <code>TRUE</code> then the predictive covariance matrix is
calculated&ndash; can be computationally (and memory) intensive if
<code>X</code> or <code>XX</code> is large.  Otherwise only the variances
(diagonal of covariance matrices) are calculated (default).  See
outputs <code>Zp.s2</code>, <code>ZZ.s2</code>, etc., below</p>
</td></tr>
<tr><td><code id="btgp_+3A_ds2x">Ds2x</code></td>
<td>
<p><code>TRUE</code> results in ALC (Active Learning&ndash;Cohn)
computation of expected reduction in uncertainty calculations at the
<code>XX</code> locations, which can be used for adaptive sampling;
<code>FALSE</code> (default) skips this computation, resulting in
a faster implementation</p>
</td></tr>
<tr><td><code id="btgp_+3A_improv">improv</code></td>
<td>
<p><code>TRUE</code> results in samples from the
improvement at locations <code>XX</code> with respect to the observed
data minimum. These samples are used to calculate the expected
improvement over <code>XX</code>, as well as to rank all of the points in
<code>XX</code> in the order that they should be sampled to minimize the
expected multivariate improvement (refer to Schonlau et al, 1998).
Alternatively, <code>improv</code> can be set to any positive integer 'g',
in which case the ranking is performed with respect to the expectation
for improvement raised to the power 'g'. Increasing 'g' leads to
rankings that are more oriented towards a global optimization.
The option <code>FALSE</code> (default) skips these computations,
resulting in a faster implementation.  Optionally, a two-vector
can be supplied where <code>improv[2]</code> is interpreted as the 
(maximum) number of points to rank by improvement.  See the note below.
If not specified, the entire <code>XX</code> matrix is ranked. </p>
</td></tr>
<tr><td><code id="btgp_+3A_sens.p">sens.p</code></td>
<td>
<p> Either <code>NULL</code> or a vector of parameters for
sensitivity analysis, built by the function <code><a href="#topic+sens">sens</a></code>.
Refer there for details</p>
</td></tr>
<tr><td><code id="btgp_+3A_nu">nu</code></td>
<td>
 <p>&ldquo;beta&rdquo; functionality: fixed smoothness parameter for
the Matern correlation function; <code>nu + 0.5</code> times differentiable
predictive surfaces result</p>
</td></tr>
<tr><td><code id="btgp_+3A_trace">trace</code></td>
<td>
 <p><code>TRUE</code> results in a saving of samples from the
posterior distribution for most of the parameters in the model.  The
default is <code>FALSE</code> for speed/storage reasons. See note below </p>
</td></tr>
<tr><td><code id="btgp_+3A_verb">verb</code></td>
<td>
<p> Level of verbosity of R-console print statements: from 0
(none); 1 (default) which shows the &ldquo;progress meter&rdquo;; 2
includes an echo of initialization parameters; up to 3 and 4 (max)
with more info about successful tree operations</p>
</td></tr>
<tr><td><code id="btgp_+3A_...">...</code></td>
<td>
<p> These ellipses arguments are interpreted as augmentations
to the prior specification generated by
</p>
<p><code>params &lt;- <a href="#topic+tgp.default.params">tgp.default.params</a>(ncol(X)+1)</code>.
</p>
<p>You may use these to specify a custom setting of any of default
parameters in the output list <code>params</code>
except those for which a specific argument is already provided
(e.g., <code>params$corr</code> or <code>params$bprior</code>) or those which contradict
the type of <code>b*</code> function being called (e.g.,
<code>params$tree</code> or <code>params$gamma</code>); these redundant or
possibly conflicting specifications will be ignored.  Refer to
<code>tgp.default.params</code> for details on the prior specification</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions and their arguments can be categorized by whether or not
they use treed partitioning (T), GP models, and jumps to the LLM (or LM)
</p>

<table>
<tr>
 <td style="text-align: left;">
  blm </td><td style="text-align: left;"> LM </td><td style="text-align: left;"> Linear Model </td>
</tr>
<tr>
 <td style="text-align: left;">
  btlm </td><td style="text-align: left;"> T, LM </td><td style="text-align: left;"> Treed Linear Model </td>
</tr>
<tr>
 <td style="text-align: left;">
  bcart </td><td style="text-align: left;"> T </td><td style="text-align: left;"> Treed Constant Model </td>
</tr>
<tr>
 <td style="text-align: left;">
  bgp </td><td style="text-align: left;"> GP </td><td style="text-align: left;"> GP Regression </td>
</tr>
<tr>
 <td style="text-align: left;">
  bgpllm </td><td style="text-align: left;"> GP, LLM </td><td style="text-align: left;"> GP with jumps to the LLM </td>
</tr>
<tr>
 <td style="text-align: left;">
  btgp </td><td style="text-align: left;"> T, GP </td><td style="text-align: left;"> treed GP Regression </td>
</tr>
<tr>
 <td style="text-align: left;">
  btgpllm </td><td style="text-align: left;"> T, GP, LLM </td><td style="text-align: left;"> treed GP with jumps to the LLM
  </td>
</tr>

</table>

<p>Each function implements a special case of the generic function 
<code>tgp</code> which is an interface to C/C++ code for treed Gaussian process 
modeling of varying parameterization.  Documentation for <code>tgp</code>
has been declared redundant, and has subsequently been removed.  To see
how the <code>b*</code> functions use <code>tgp</code> simply examine the
function.  In the latest version, with the addition of the ellipses
&ldquo;...&rdquo; argument, there is nothing that can be done
with the direct <code>tgp</code> function that cannot also be done with a
<code>b*</code> function
</p>
<p>Only functions in the T (tree) category take the <code>tree</code> argument;
GP category functions take the <code>corr</code> argument; and LLM category
functions take the <code>gamma</code> argument.  Non-tree class functions omit
the <code>parts</code> output, see below
</p>
<p><code>bcart</code> is the same as <code>btlm</code> except that only the
intercept term in the LM is estimated; the others are zero, thereby
implementing a Bayesian version of the original CART model
</p>
<p>The <code>sens.p</code> argument contains a vector of parameters for 
sensitivity analysis.  It should be <code>NULL</code> unless created by the 
<code>sens</code> function.  Refer to <code>help(sens)</code> for details.
</p>

















<p>If <code>itemps =! NULL</code> then importance tempering (IT) is performed
to get better mixing.  After each restart (when <code>R &gt; 1</code>) the
observation counts are used to update the pseudo-prior.  Stochastic
approximation is performed in the first burn-in rounds (for <code>B-T</code>
rounds, not <code>B</code>) when <code>c0</code> and <code>n0</code> are positive.
Every subsequent burn-in after the first restart is for <code>B</code>
rounds in order to settle-in after using the observation counts.  See
<code><a href="#topic+default.itemps">default.itemps</a></code> for more details and an example
</p>
<p>Please see <code>vignette("tgp")</code> for a detailed illustration
</p>


<h3>Value</h3>

<p><code>bgp</code> returns an object of class <code>"tgp"</code>.
The function <code><a href="#topic+plot.tgp">plot.tgp</a></code>
can be used to help visualize results.
</p>
<p>An object of class <code>"tgp"</code> is a list containing at least the
following components...  The <code>parts</code> output is unique to the T
(tree) category functions. Tree viewing is supported by
<code><a href="#topic+tgp.trees">tgp.trees</a></code>
</p>
<table>
<tr><td><code>X</code></td>
<td>
<p>Input argument: <code>data.frame</code> of inputs <code>X</code></p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>Number of rows in <code>X</code>, i.e., <code>nrow(X)</code></p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>Number of cols in <code>X</code>, i.e., <code>ncol(X)</code></p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p>Vector of output responses <code>Z</code></p>
</td></tr>
<tr><td><code>XX</code></td>
<td>
<p>Input argument: <code>data.frame</code> of predictive locations <code>XX</code></p>
</td></tr>
<tr><td><code>nn</code></td>
<td>
<p>Number of rows in <code>XX</code>, i.e., <code>nrow(XX)</code></p>
</td></tr>
<tr><td><code>BTE</code></td>
<td>
<p>Input argument: Monte-carlo parameters</p>
</td></tr>
<tr><td><code>R</code></td>
<td>
<p>Input argument: restarts</p>
</td></tr>
<tr><td><code>linburn</code></td>
<td>
<p>Input argument: initialize MCMC with linear CART</p>
</td></tr>
<tr><td><code>params</code></td>
<td>
<p><code>list</code> of model parameters generated by 
<code><a href="#topic+tgp.default.params">tgp.default.params</a></code> and subsequently modified according
to the calling <code>b*</code> function and its arguments</p>
</td></tr>
<tr><td><code>dparams</code></td>
<td>
<p>Double-representation of model input parameters used by the C-code</p>
</td></tr>
<tr><td><code>itemps</code></td>
<td>
<p><code>data.frame</code> containing the importance tempering
ladders and pseudo-prior: <code>$k</code> has inverse
inverse temperatures (from the input argument), <code>$k</code> has an
<em>updated</em> pseudo-prior based on observation
counts and (possibly) stochastic approximation during burn-in
and (input) stochastic approximation parameters <code class="reqn">c_0</code> and
<code class="reqn">n_0</code>.  See <code><a href="#topic+default.itemps">default.itemps</a></code> for more info</p>
</td></tr>
<tr><td><code>Zp.mean</code></td>
<td>
<p>Vector of mean predictive estimates at <code>X</code> locations</p>
</td></tr>
<tr><td><code>Zp.q1</code></td>
<td>
<p>Vector of 5% predictive quantiles at <code>X</code> locations</p>
</td></tr>
<tr><td><code>Zp.q2</code></td>
<td>
<p>Vector of 95% predictive quantiles at <code>X</code> locations</p>
</td></tr>
<tr><td><code>Zp.q</code></td>
<td>
<p>Vector of quantile norms <code>Zp.q2-Zp.q1</code></p>
</td></tr>
<tr><td><code>Zp.s2</code></td>
<td>
<p>If input <code>zcov = TRUE</code>, then this is a predictive
covariance matrix for the inputs at locations <code>X</code>;  otherwise
then this is a vector of predictive variances at the <code>X</code>
locations (diagonal of the predictive covariance matrix).  Only
appears when input <code>pred.n = TRUE</code></p>
</td></tr>
<tr><td><code>Zp.km</code></td>
<td>
<p>Vector of (expected) kriging means at <code>X</code> locations</p>
</td></tr>
<tr><td><code>Zp.vark</code></td>
<td>
<p>Vector of posterior variance for kriging surface (no additive noise) at <code>X</code> locations</p>
</td></tr>
<tr><td><code>Zp.ks2</code></td>
<td>
<p>Vector of (expected) predictive kriging variances at <code>X</code> locations</p>
</td></tr>
<tr><td><code>ZZ.mean</code></td>
<td>
<p>Vector of mean predictive estimates at <code>XX</code> locations</p>
</td></tr>
<tr><td><code>ZZ.q1</code></td>
<td>
<p>Vector of 5% predictive quantiles at <code>XX</code> locations</p>
</td></tr>
<tr><td><code>ZZ.q2</code></td>
<td>
<p>Vector of 95% predictive quantiles at <code>XX</code> locations</p>
</td></tr>
<tr><td><code>ZZ.q</code></td>
<td>
<p>Vector of quantile norms <code>ZZ.q2-ZZ.q1</code>, used by the 
ALM adaptive sampling algorithm</p>
</td></tr>
<tr><td><code>ZZ.s2</code></td>
<td>
<p>If input <code>zcov = TRUE</code>, then this is a predictive
covariance matrix for predictive locations <code>XX</code>;  otherwise
then this is a vector of predictive variances at the <code>XX</code>
locations (diagonal of the predictive covariance matrix).  Only
appears when input <code>XX != NULL</code></p>
</td></tr>
<tr><td><code>ZpZZ.s2</code></td>
<td>
<p>If input <code>zcov = TRUE</code>, then this is a predictive
<code>n * nn</code> covariance matrix between locations in <code>X</code> and
<code>XX</code>; Only appears when <code>zcov = TRUE</code> and both
<code>pred.n = TRUE</code> and <code>XX != NULL</code></p>
</td></tr>
<tr><td><code>ZZ.km</code></td>
<td>
<p>Vector of (expected) kriging means at <code>XX</code> locations</p>
</td></tr>
<tr><td><code>ZZ.vark</code></td>
<td>
<p>Vector of posterior variance for kriging surface (no additive noise) at <code>XX</code> locations</p>
</td></tr>
<tr><td><code>ZZ.ks2</code></td>
<td>
<p>Vector of (expected) predictive kriging variances at <code>XX</code> locations</p>
</td></tr>
<tr><td><code>Ds2x</code></td>
<td>
<p>If argument <code>Ds2x=TRUE</code>, this vector contains ALC
statistics for <code>XX</code> locations</p>
</td></tr>
<tr><td><code>improv</code></td>
<td>
<p>If argument <code>improv</code> is <code>TRUE</code> or a
positive integer, this is a 'matrix' with first column set to the expected
improvement statistics for <code>XX</code> locations, and the second
column set to a ranking in the order that they should be sampled to
minimize the expected multivariate improvement raised to a power
determined by the argument <code>improv</code></p>
</td></tr>
<tr><td><code>response</code></td>
<td>
<p>Name of response <code>Z</code> if supplied by <code>data.frame</code> 
in argument, or &quot;z&quot; if none provided</p>
</td></tr>
<tr><td><code>parts</code></td>
<td>
<p>Internal representation of the regions depicted by partitions of
the maximum a' posteriori (MAP) tree</p>
</td></tr>
<tr><td><code>trees</code></td>
<td>
<p><code>list</code> of trees (<span class="pkg">maptree</span> representation) which
were MAP as a function
of each tree height sampled between MCMC rounds <code>B</code> and
<code>T</code></p>
</td></tr>
<tr><td><code>trace</code></td>
<td>
<p>If <code>trace==TRUE</code>, this <code>list</code>
contains traces of most of the model parameters and posterior
predictive distributions at input locations
<code>XX</code>.  Otherwise the entry is <code>FALSE</code>.  See note below</p>
</td></tr>
<tr><td><code>ess</code></td>
<td>
<p>Importance tempering effective sample size (ESS).  If
<code>itemps==NULL</code> this corresponds to the total number of
samples collected, i.e..
</p>
<p><code>R*(BTE[2]-BTE[1])/BTE[3]</code>.
</p>
<p>Otherwise the ESS will be lower due to a non-zero coefficient of
variation of the calculated importance tempering weights</p>
</td></tr>
<tr><td><code>sens</code></td>
<td>
<p> See <code><a href="#topic+sens">sens</a></code> documentation for more details</p>
</td></tr>
</table>


<h3>Note</h3>

<p> Inputs <code>X, XX, Z</code> containing <code>NaN, NA</code>, or <code>Inf</code> are
discarded with non-fatal warnings
</p>
<p>Upon execution, MCMC reports are made every 1,000 rounds to indicate
progress
</p>
<p>Stationary (non-treed) processes on larger inputs (e.g., <code>X,Z</code>) 
of size greater than 500, *might* be slow in execution, especially on
older machines. Once the C code starts executing, it can be interrupted
in the usual way: either via Ctrl-C (Unix-alikes) or pressing the Stop
button in the <span class="rlang"><b>R</b></span>-GUI.  When this happens, interrupt messages will
indicate which required cleanup measures completed before returning
control to <span class="rlang"><b>R</b></span>.
</p>
<p>Whereas most of the <span class="pkg">tgp</span> models will work reasonably well with
little or no change to the default prior specification, GP's with the
<code>"mrexpsep"</code> correlation imply a very specific relationship between
fine and coarse data, and a careful prior specification is usually
required.
</p>
<p>The ranks provided in the second column of the <code>improv</code> field
of a <code>tgp</code> object are based on the expectation of a multivariate
improvement that may or may not be raised to a positive integer power.
They can thus differ significantly from a simple ranking of the first
column of expected univariate improvement values.
</p>
<p>Regarding <code>trace=TRUE</code>: Samples from the posterior will be
collected for all parameters in the model.  GP parameters are collected
with reference to the locations in <code>XX</code>, resulting
<code>nn=nrow{XX}</code> traces of <code>d,g,s2,tau2</code>, etc.  Therefore, it
is recommended that <code>nn</code> is chosen to be a small, representative,
set of input locations.  Besides GP parameters, traces are saved for
the tree partitions, areas under the LLM, log posterior (as a function
of tree height), and samples from the posterior predictive
distributions. Note that since some traces are stored in
files, multiple <code>tgp</code>/<span class="rlang"><b>R</b></span> sessions in the same working
directory can clobber the trace files of other sessions
</p>


<h3>Author(s)</h3>

 
<p>Robert B. Gramacy, <a href="mailto:rbg@vt.edu">rbg@vt.edu</a>, and
Matt Taddy, <a href="mailto:mataddy@amazon.com">mataddy@amazon.com</a>
</p>


<h3>References</h3>

<p>Gramacy, R. B. (2020) <em>Surrogates: Gaussian Process Modeling, 
Design and Optimization for the Applied Sciences</em>. Boca Raton, 
Florida: Chapman Hall/CRC.  (See Chapter 9.)
<a href="https://bobby.gramacy.com/surrogates/">https://bobby.gramacy.com/surrogates/</a>
</p>
<p>Gramacy, R. B. (2007). <em><span class="pkg">tgp</span>: An <span class="rlang"><b>R</b></span> Package for
Bayesian Nonstationary, Semiparametric Nonlinear Regression
and Design by Treed Gaussian Process Models.</em>
Journal of Statistical Software, <b>19</b>(9).
<a href="https://www.jstatsoft.org/v19/i09">https://www.jstatsoft.org/v19/i09</a>
<a href="https://doi.org/10.18637/jss.v019.i09">doi:10.18637/jss.v019.i09</a>
</p>
<p>Robert B. Gramacy, Matthew Taddy (2010). <em>Categorical Inputs,
Sensitivity Analysis, Optimization and Importance Tempering with <span class="pkg">tgp</span>
Version 2, an <span class="rlang"><b>R</b></span> Package for Treed Gaussian Process Models.</em>
Journal of Statistical Software, <b>33</b>(6), 1&ndash;48.
<a href="https://www.jstatsoft.org/v33/i06/">https://www.jstatsoft.org/v33/i06/</a>
<a href="https://doi.org/10.18637/jss.v033.i06">doi:10.18637/jss.v033.i06</a>
</p>
<p>Gramacy, R. B., Lee, H. K. H. (2007).
<em>Bayesian treed Gaussian process models with an application
to computer modeling</em>. Journal of the American Statistical Association, 
103(483), pp. 1119-1130.  Also available as ArXiv article 0710.4536 
<a href="https://arxiv.org/abs/0710.4536">https://arxiv.org/abs/0710.4536</a>
</p>
<p>Gramacy, R. B. and Lee, K.H. (2008). <em>Gaussian Processes and
Limiting Linear Models.</em>
Computational Statistics and Data Analysis, 53, pp. 123-136.
Also available as ArXiv article 0804.4685
<a href="https://arxiv.org/abs/0804.4685">https://arxiv.org/abs/0804.4685</a>
</p>
<p>Gramacy, R. B., Lee, H. K. H. (2009).
<em>Adaptive design and analysis of supercomputer experiments.</em>
Technometrics, 51(2), pp. 130-145. 
Also avaliable on ArXiv article 0805.4359
<a href="https://arxiv.org/abs/0805.4359">https://arxiv.org/abs/0805.4359</a>
</p>
<p>Robert B. Gramacy, Heng Lian (2011).
<em>Gaussian process single-index models as emulators for computer
experiments</em>.  Available as ArXiv article 1009.4241
<a href="https://arxiv.org/abs/1009.4241">https://arxiv.org/abs/1009.4241</a>
</p>
<p>Chipman, H., George, E., &amp; McCulloch, R. (1998).
<em>Bayesian CART model search (with discussion).</em>
Journal of the American Statistical Association, <b>93</b>,
935&ndash;960.
</p>
<p>Chipman, H., George, E., &amp; McCulloch, R. (2002).
<em>Bayesian treed models.</em>
Machine Learning, <b>48</b>, 303&ndash;324.
</p>
<p>M. Schonlau and Jones, D.R. and Welch, W.J. (1998).
<em>Global versus local search in constrained optimization of
computer models.</em>
In &quot;New Developments and applications in experimental design&quot;, 
IMS Lecture Notes - Monograph Series 34.  11&ndash;25.
</p>
<p><a href="https://bobby.gramacy.com/r_packages/tgp/">https://bobby.gramacy.com/r_packages/tgp/</a>
</p>


<h3>See Also</h3>

  <p><code><a href="#topic+plot.tgp">plot.tgp</a></code>,  <code><a href="#topic+tgp.trees">tgp.trees</a></code>,
<code><a href="#topic+predict.tgp">predict.tgp</a></code>, <code><a href="#topic+sens">sens</a></code>, <code><a href="#topic+default.itemps">default.itemps</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
##
## Many of the examples below illustrate the above 
## function(s) on random data.  Thus it can be fun
## (and informative) to run them several times.
##

# 
# simple linear response
#

# input and predictive data
X &lt;- seq(0,1,length=50)
XX &lt;- seq(0,1,length=99)
Z &lt;- 1 + 2*X + rnorm(length(X),sd=0.25)

out &lt;- blm(X=X, Z=Z, XX=XX)	# try Linear Model
plot(out)			# plot the surface

#
# 1-d Example
# 

# construct some 1-d nonstationary data
X &lt;- seq(0,20,length=100)
XX &lt;- seq(0,20,length=99)
Z &lt;- (sin(pi*X/5) + 0.2*cos(4*pi*X/5)) * (X &lt;= 9.6)
lin &lt;- X&gt;9.6; 
Z[lin] &lt;- -1 + X[lin]/10
Z &lt;- Z + rnorm(length(Z), sd=0.1)

out &lt;- btlm(X=X, Z=Z, XX=XX) 	# try Linear CART
plot(out) 			# plot the surface
tgp.trees(out) 		 	# plot the MAP trees

out &lt;- btgp(X=X, Z=Z, XX=XX) 	# use a treed GP
plot(out) 			# plot the surface
tgp.trees(out) 		 	# plot the MAP trees


#
# 2-d example
# (using the isotropic correlation function)
#

# construct some 2-d nonstationary data
exp2d.data &lt;- exp2d.rand()
X &lt;- exp2d.data$X; Z &lt;- exp2d.data$Z
XX &lt;- exp2d.data$XX

# try a GP
out &lt;- bgp(X=X, Z=Z, XX=XX, corr="exp") 	
plot(out) 			# plot the surface

# try a treed GP LLM
out &lt;- btgpllm(X=X, Z=Z, XX=XX, corr="exp") 
plot(out) 			# plot the surface
tgp.trees(out) 		 	# plot the MAP trees

#
# Motorcycle Accident Data
#

# get the data
require(MASS)

# try a GP 
out &lt;- bgp(X=mcycle[,1], Z=mcycle[,2])
plot(out)			# plot the surface

# try a treed GP LLM
# best to use the "b0" beta linear prior to capture common
# common linear process throughout all regions (using the
# ellipses "...") 
out &lt;- btgpllm(X=mcycle[,1], Z=mcycle[,2], bprior="b0")
plot(out)			# plot the surface
tgp.trees(out)		 	# plot the MAP trees

</code></pre>

<hr>
<h2 id='default.itemps'> Default Sigmoidal, Harmonic and Geometric Temperature Ladders </h2><span id='topic+default.itemps'></span>

<h3>Description</h3>

<p>Parameterized by the minimum desired <em>inverse</em> temperature, this
function generates a ladder of inverse temperatures <code>k[1:m]</code>
starting at <code>k[1] = 1</code>, with <code>m</code> steps down to the final
temperature <code>k[m] = k.min</code> progressing sigmoidally,
harmonically or geometrically.
The output is in a format convenient for the <code>b*</code> functions
in the <span class="pkg">tgp</span> package (e.g. <code><a href="#topic+btgp">btgp</a></code>), including
stochastic approximation parameters <code class="reqn">c_0</code> and <code class="reqn">n_0</code>
for tuning the uniform pseudo-prior output by this function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>default.itemps(m = 40, type = c("geometric", "harmonic","sigmoidal"),
               k.min = 0.1, c0n0 = c(100, 1000), lambda = c("opt",
               "naive", "st"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="default.itemps_+3A_m">m</code></td>
<td>
<p> Number of temperatures in the ladder; <code>m=1</code> corresponds
to <em>importance sampling</em> at the temperature specified by
<code>k.min</code> (in this case all other arguments are ignored) </p>
</td></tr>
<tr><td><code id="default.itemps_+3A_type">type</code></td>
<td>
<p> Choose from amongst two common defaults for simulated
tempering and Metropolis-coupled MCMC, i.e., geometric (default)
or harmonic, or a sigmoidal ladder (default) that concentrates
more inverse temperatures near 1</p>
</td></tr>
<tr><td><code id="default.itemps_+3A_k.min">k.min</code></td>
<td>
<p> Minimum inverse temperature desired </p>
</td></tr>
<tr><td><code id="default.itemps_+3A_c0n0">c0n0</code></td>
<td>
<p> Stochastic approximation parameters used to tune
the simulated tempering pseudo-prior (<code>$pk</code>) to get
a uniform posterior over the inverse temperatures; must be
a 2-vector of positive integers <code>c(c0, n0)</code>; see the Geyer &amp;
Thompson reference below </p>
</td></tr>
<tr><td><code id="default.itemps_+3A_lambda">lambda</code></td>
<td>
<p> Method for combining the importance samplers at each
temperature.  Optimal combination (<code>"opt"</code>) is the default,
weighting the IS at each temperature <code class="reqn">k</code> by
</p>
<p style="text-align: center;"><code class="reqn">\lambda_k \propto (\sum_i w_{ki})^2/\sum_i w_{ki}^2.</code>
</p>

<p>Setting <code>lambda = "naive"</code> allows each temperature to
contribute equally (<code class="reqn">\lambda_k \propto 1</code>, or
equivalently ignores delineations due to temperature when using
importance weights.  Setting <code>lambda = "st"</code> allows only the
first (cold) temperature to contribute to the estimator, thereby
implementing <em>simulated tempering</em></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The geometric and harmonic inverse temperature ladders are usually defined
by an index <code class="reqn">i=1,\dots,m</code> and a parameter
<code class="reqn">\Delta_k &gt; 0</code>.  The geometric ladder is defined by
</p>
<p style="text-align: center;"><code class="reqn">k_i = (1+\Delta_k)^{1-i},</code>
</p>

<p>and the harmonic ladder by
</p>
<p style="text-align: center;"><code class="reqn">k_i = (1+\Delta_k(i-1))^{-1}.</code>
</p>

<p>Alternatively, specifying the minimum temperature
<code class="reqn">k_{\mbox{\tiny min}}</code> in the ladder can be used to
uniquely determine <code class="reqn">\Delta_k</code>.  E.g., for the geometric
ladder
</p>
<p style="text-align: center;"><code class="reqn">\Delta_k = k_{\mbox{\tiny min}}^{1/(1-m)}-1,</code>
</p>

<p>and for the harmonic
</p>
<p style="text-align: center;"><code class="reqn">\Delta_k = \frac{k_{\mbox{\tiny min}}^{-1}-1}{m-1}.</code>
</p>

<p>In a similar spirit, the sigmoidal ladder is specified by first
situating <code class="reqn">m</code> indices <code class="reqn">j_i\in \Re</code> so that
<code class="reqn">k_1 = k(j_1) = 1</code>
and
<code class="reqn">k_m = k(j_m) = k_{\mbox{\tiny min}}</code>
under
</p>
<p style="text-align: center;"><code class="reqn">k(j_i) = 1.01 - \frac{1}{1+e^{j_i}}.</code>
</p>

<p>The remaining <code class="reqn">j_i, i=2,\dots,(m-1)</code> are spaced evenly
between <code class="reqn">j_1</code> and <code class="reqn">j_m</code> to fill out the ladder
<code class="reqn">k_i = k(j_i), i=1,\dots,(m-1)</code>.
</p>
<p>For more details, see the <em>Importance tempering</em> paper cited
below and a full demonstration in <code>vignette("tgp2")</code>
</p>


<h3>Value</h3>

<p>The return value is a <code>list</code> which is compatible with the input argument
<code>itemps</code> to the <code>b*</code> functions (e.g. <code><a href="#topic+btgp">btgp</a></code>),
containing the following entries:
</p>
<table>
<tr><td><code>c0n0</code></td>
<td>
<p> A copy of the <code>c0n0</code> input argument </p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p> The generated inverse temperature ladder; a vector
with <code>length(k) = m</code> containing a decreasing sequence from
<code>1</code> down to <code>k.min</code></p>
</td></tr>
<tr><td><code>pk</code></td>
<td>
<p> A vector with <code>length(pk) = m</code> containing  an
initial pseudo-prior for the temperature ladder of <code>1/m</code> for
each inverse temperature</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p> IT method, as specified by the input argument</p>
</td></tr>
</table>


<h3>Author(s)</h3>

 
<p>Robert B. Gramacy, <a href="mailto:rbg@vt.edu">rbg@vt.edu</a>, and
Matt Taddy, <a href="mailto:mataddy@amazon.com">mataddy@amazon.com</a>
</p>


<h3>References</h3>

<p>Gramacy, R.B., Samworth, R.J., and King, R. (2010)
<em>Importance Tempering.</em> ArXiV article 0707.4242
Statistics and Computing, 20(1), pp. 1-7;
<a href="https://arxiv.org/abs/0707.4242">https://arxiv.org/abs/0707.4242</a>. 
</p>
<p>For stochastic approximation and simulated tempering (ST):
</p>
<p>Geyer, C.~and Thompson, E.~(1995).
<em>Annealing Markov chain Monte Carlo with applications to
ancestral inference.</em>
Journal of the American Statistical Association, <b>90</b>,
909&ndash;920.
</p>
<p>For the geometric temperature ladder:
</p>
<p>Neal, R.M.~(2001)
<em>Annealed importance sampling.</em>
Statistics and Computing, <b>11</b>, 125&ndash;129
</p>
<p>Justifying geometric and harmonic defaults:
</p>
<p>Liu, J.S.~(1002)
<em>Monte Carlo Strategies in Scientific Computing.</em>
New York: Springer.  Chapter 10 (pages 213 &amp; 233)
</p>
<p><a href="https://bobby.gramacy.com/r_packages/tgp/">https://bobby.gramacy.com/r_packages/tgp/</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+btgp">btgp</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## comparing the different ladders
geo &lt;- default.itemps(type="geometric")
har &lt;- default.itemps(type="harmonic")
sig &lt;- default.itemps(type="sigmoidal")
par(mfrow=c(2,1))
matplot(cbind(geo$k, har$k, sig$k), pch=21:23,
        main="inv-temp ladders", xlab="indx",
        ylab="itemp")
legend("topright", pch=21:23, 
       c("geometric","harmonic","sigmoidal"), col=1:3)
matplot(log(cbind(sig$k, geo$k, har$k)), pch=21:23,
        main="log(inv-temp) ladders", xlab="indx",
        ylab="itemp")

## Not run: 
## using Importance Tempering (IT) to improve mixing
## on the motorcycle accident dataset
library(MASS)
out.it &lt;- btgpllm(X=mcycle[,1], Z=mcycle[,2], BTE=c(2000,22000,2),
        R=3, itemps=default.itemps(), bprior="b0", trace=TRUE, 
        pred.n=FALSE)

## compare to regular tgp w/o IT
out.reg &lt;- btgpllm(X=mcycle[,1], Z=mcycle[,2], BTE=c(2000,22000,2),
        R=3, bprior="b0", trace=TRUE, pred.n=FALSE)

## compare the heights explored by the three chains:
## REG, combining all temperatures, and IT
p &lt;- out.it$trace$post
L &lt;- length(p$height)
hw &lt;- suppressWarnings(sample(p$height, L, prob=p$wlambda, replace=TRUE))
b &lt;- hist2bar(cbind(out.reg$trace$post$height, p$height, hw))
par(mfrow=c(1,1))
barplot(b, beside=TRUE, xlab="tree height", ylab="counts", col=1:3,
        main="tree heights encountered")
legend("topright", c("reg MCMC", "All Temps", "IT"), fill=1:3)

## End(Not run)
</code></pre>

<hr>
<h2 id='dopt.gp'>Sequential D-Optimal Design for a Stationary Gaussian Process</h2><span id='topic+dopt.gp'></span>

<h3>Description</h3>

<p>Create sequential D-Optimal design for a stationary Gaussian process
model of fixed parameterization by subsampling from a list of 
candidates
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dopt.gp(nn, X=NULL, Xcand, iter=5000, verb=0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dopt.gp_+3A_nn">nn</code></td>
<td>
<p> Number of new points in the design. Must
be less than or equal to the number of candidates contained in
<code>Xcand</code>, i.e., <code>nn &lt;= nrow(Xcand)</code></p>
</td></tr>
<tr><td><code id="dopt.gp_+3A_x">X</code></td>
<td>
 <p><code>data.frame</code>, <code>matrix</code> or vector of input locations
which are forced into (already in) the design</p>
</td></tr>
<tr><td><code id="dopt.gp_+3A_xcand">Xcand</code></td>
<td>
 <p><code>data.frame</code>, <code>matrix</code> or vector of candidates 
from which new design points are subsampled.  Must have the same
dimension as <code>X</code>, i.e.,
</p>
<p><code>ncol(X) == ncol(Xcand)</code></p>
</td></tr>
<tr><td><code id="dopt.gp_+3A_iter">iter</code></td>
<td>
<p>number of iterations of stochastic accent algorithm,
default <code>5000</code></p>
</td></tr>
<tr><td><code id="dopt.gp_+3A_verb">verb</code></td>
<td>
<p>positive integer indicating after how many rounds of
stochastic approximation to print each progress statement;
default <code>verb=0</code> results in no printing</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Design is based on a stationary Gaussian process model with stationary isotropic
exponential correlation function with parameterization fixed as a function
of the dimension of the inputs.  The algorithm implemented is a simple stochastic
ascent which maximizes <code>det(K)</code>&ndash; the covariance matrix constructed
with locations <code>X</code> and a subset of <code>Xcand</code> of size <code>nn</code>.
The selected design is <em>locally</em> optimal
</p>


<h3>Value</h3>

<p>The output is a list which contains the inputs to, and outputs of, the C code
used to find the optimal design.  The chosen design locations can be 
accessed as list members <code>XX</code> or equivalently <code>Xcand[fi,]</code>.
</p>
<table>
<tr><td><code>X</code></td>
<td>
<p>Input argument: <code>data.frame</code> of inputs <code>X</code>, can be <code>NULL</code></p>
</td></tr>
<tr><td><code>nn</code></td>
<td>
<p>Input argument: number new points in the design</p>
</td></tr>
<tr><td><code>Xcand</code></td>
<td>
<p>Input argument: <code>data.frame</code> of candidate locations <code>Xcand</code></p>
</td></tr>
<tr><td><code>ncand</code></td>
<td>
<p>Number of rows in <code>Xcand</code>, i.e., <code>nncand = dim(Xcand)[1]</code></p>
</td></tr>
<tr><td><code>fi</code></td>
<td>
<p>Vector of length <code>nn</code>  describing the selected new design locations
as indices into <code>Xcand</code></p>
</td></tr>
<tr><td><code>XX</code></td>
<td>
<p><code>data.frame</code> of selected new design locations, i.e., 
<code>XX = Xcand[fi,]</code></p>
</td></tr>
</table>


<h3>Note</h3>

<p>Inputs <code>X, Xcand</code> containing <code>NaN, NA, Inf</code> are discarded with non-fatal
warnings.  If <code>nn &gt; dim(Xcand)[1]</code> then a non-fatal warning is displayed 
and execution commences with <code>nn = dim(Xcand)[1]</code>
</p>
<p>In the current version there is no progress indicator.  You will
have to be patient.  Creating D-optimal designs is no speedy task
</p>


<h3>Author(s)</h3>

 
<p>Robert B. Gramacy, <a href="mailto:rbg@vt.edu">rbg@vt.edu</a>, and
Matt Taddy, <a href="mailto:mataddy@amazon.com">mataddy@amazon.com</a>
</p>


<h3>References</h3>

<p>Gramacy, R. B. (2020) <em>Surrogates: Gaussian Process Modeling, 
Design and Optimization for the Applied Sciences</em>. Boca Raton, 
Florida: Chapman Hall/CRC.  (See Chapter 6.)
<a href="https://bobby.gramacy.com/surrogates/">https://bobby.gramacy.com/surrogates/</a>
</p>
<p>Chaloner, K. and Verdinelli, I. (1995).
<em>Bayesian experimental design: A review.</em>
Statist. Sci., 10, (pp. 273&ndash;304).
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+tgp.design">tgp.design</a></code>, <code><a href="#topic+lhs">lhs</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#
# 2-d Exponential data
# (This example is based on random data.  
# It might be fun to run it a few times)
#

# get the data
exp2d.data &lt;- exp2d.rand()
X &lt;- exp2d.data$X; Z &lt;- exp2d.data$Z
Xcand &lt;- exp2d.data$XX

# find a treed sequential D-Optimal design 
# with 10 more points
dgp &lt;- dopt.gp(10, X, Xcand)

# plot the d-optimally chosen locations
# Contrast with locations chosen via
# the tgp.design function
plot(X, pch=19, xlim=c(-2,6), ylim=c(-2,6))
points(dgp$XX)
</code></pre>

<hr>
<h2 id='exp2d'> 2-d Exponential Data </h2><span id='topic+exp2d'></span>

<h3>Description</h3>

<p>A 2-dimensional data set that can be used to validate
non-stationary models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(exp2d)</code></pre>


<h3>Format</h3>

<p>A <code>data frame</code> with 441 observations on the following 4 variables.
</p>

<dl>
<dt><code>X1</code></dt><dd><p>Numeric vector describing the first dimension of <code>X</code> inputs</p>
</dd>
<dt><code>X2</code></dt><dd><p>Numeric vector describing the second dimension of <code>X</code> inputs</p>
</dd>
<dt><code>Z</code></dt><dd><p>Numeric vector describing the response <code>Z(X)+N(0,sd=0.001)</code></p>
</dd>
<dt><code>Ztrue</code></dt><dd><p>Numeric vector describing the true response <code>Z(X)</code>,
without noise</p>
</dd>
</dl>



<h3>Details</h3>

<p>The true response is evaluated as 
</p>
<p style="text-align: center;"><code class="reqn">Z(X)=x_1 * \exp(x_1^2-x_2^2).</code>
</p>

<p>Zero-mean normal noise
with <code>sd=0.001</code> has been added to the true response
</p>


<h3>Note</h3>

<p>This data is used in the examples of the functions listed below in
the &ldquo;See Also&rdquo; section via the <code><a href="#topic+exp2d.rand">exp2d.rand</a></code> function</p>


<h3>Author(s)</h3>

 
<p>Robert B. Gramacy, <a href="mailto:rbg@vt.edu">rbg@vt.edu</a>, and
Matt Taddy, <a href="mailto:mataddy@amazon.com">mataddy@amazon.com</a>
</p>


<h3>References</h3>

<p>Gramacy, R. B. (2020) <em>Surrogates: Gaussian Process Modeling,
Design and Optimization for the Applied Sciences</em>. Boca Raton,
Florida: Chapman Hall/CRC.
<a href="https://bobby.gramacy.com/surrogates/">https://bobby.gramacy.com/surrogates/</a>
</p>
<p>Gramacy, R. B. (2007). <em><span class="pkg">tgp</span>: An <span class="rlang"><b>R</b></span> Package for
Bayesian Nonstationary, Semiparametric Nonlinear Regression
and Design by Treed Gaussian Process Models.</em>
Journal of Statistical Software, <b>19</b>(9).
<a href="https://www.jstatsoft.org/v19/i09">https://www.jstatsoft.org/v19/i09</a>
<a href="https://doi.org/10.18637/jss.v019.i09">doi:10.18637/jss.v019.i09</a>
</p>
<p>Robert B. Gramacy, Matthew Taddy (2010). <em>Categorical Inputs,
Sensitivity Analysis, Optimization and Importance Tempering with <span class="pkg">tgp</span>
Version 2, an <span class="rlang"><b>R</b></span> Package for Treed Gaussian Process Models.</em>
Journal of Statistical Software, <b>33</b>(6), 1&ndash;48.
<a href="https://www.jstatsoft.org/v33/i06/">https://www.jstatsoft.org/v33/i06/</a>.
<a href="https://doi.org/10.18637/jss.v033.i06">doi:10.18637/jss.v033.i06</a>
</p>
<p>Gramacy, R. B., Lee, H. K. H. (2008).
<em>Bayesian treed Gaussian process models with an application
to computer modeling</em>. Journal of the American Statistical Association, 
103(483), pp. 1119-1130.  Also available as ArXiv article 0710.4536 
<a href="https://arxiv.org/abs/0710.4536">https://arxiv.org/abs/0710.4536</a>
</p>
<p><a href="https://bobby.gramacy.com/r_packages/tgp/">https://bobby.gramacy.com/r_packages/tgp/</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+exp2d.rand">exp2d.rand</a></code>, <code><a href="#topic+exp2d.Z">exp2d.Z</a></code>,
<code><a href="#topic+btgp">btgp</a></code>, and other <code>b*</code> functions</p>

<hr>
<h2 id='exp2d.rand'> Random 2-d Exponential Data </h2><span id='topic+exp2d.rand'></span>

<h3>Description</h3>

<p>A Random subsample of <code>data(<a href="#topic+exp2d">exp2d</a>)</code>, or 
Latin Hypercube sampled data evaluated with <code><a href="#topic+exp2d.Z">exp2d.Z</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exp2d.rand(n1 = 50, n2 = 30, lh = NULL, dopt = 1)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exp2d.rand_+3A_n1">n1</code></td>
<td>
<p>Number of samples from the first, interesting, quadrant</p>
</td></tr>
<tr><td><code id="exp2d.rand_+3A_n2">n2</code></td>
<td>
<p>Number of samples from the other three, uninteresting, quadrants</p>
</td></tr>
<tr><td><code id="exp2d.rand_+3A_lh">lh</code></td>
<td>
<p>If <code>!is.null(lh)</code> then Latin Hypercube (LH) sampling
(<code><a href="#topic+lhs">lhs</a></code>) is used instead of subsampling from
<code>data(<a href="#topic+exp2d">exp2d</a>)</code>; <code>lh</code> should be a single nonnegative
integer specifying the desired number of predictive locations,
<code>XX</code>; or, it should be a vector of length 4, specifying the
number of predictive locations desired from each of the four
quadrants (interesting quadrant first, then counter-clockwise)</p>
</td></tr>
<tr><td><code id="exp2d.rand_+3A_dopt">dopt</code></td>
<td>
<p>If <code>dopt &gt;= 2</code> then d-optimal subsampling from LH
candidates of the multiple indicated by the value of
<code>dopt</code> will be used.  This argument only
makes sense when <code>!is.null(lh)</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code>is.null(lh)</code>, data is subsampled without replacement from 
<code>data(<a href="#topic+exp2d">exp2d</a>)</code>. Of the <code>n1 + n2 &lt;= 441</code>
input/response pairs <code>X,Z</code>, there are <code>n1</code> are taken from the
first quadrant, i.e., where the	response is interesting, 
and the remaining <code>n2</code> are taken from the other three
quadrants. The remaining <code>441 - (n1 + n2)</code> are treated as
predictive locations
</p>
<p>Otherwise, when <code>!is.null(lh)</code>, Latin Hypercube Sampling 
(<code><a href="#topic+lhs">lhs</a></code>) is used
</p>
<p>If <code>dopt &gt;= 2</code> then <code>n1*dopt</code> LH candidates are used
for to get a D-optimal subsample of size <code>n1</code> from the
first (interesting) quadrant.  Similarly <code>n2*dopt</code> in the
rest of the un-interesting region.
A total of <code>lh*dopt</code> candidates will be used for sequential D-optimal
subsampling for predictive locations <code>XX</code> in all four
quadrants assuming the already-sampled <code>X</code> locations will
be in the design.
</p>
<p>In all three cases, the response is evaluated as 
</p>
<p style="text-align: center;"><code class="reqn">Z(X)=x_1 * \exp(x_1^2-x_2^2).</code>
</p>

<p>thus creating the outputs <code>Ztrue</code> and <code>ZZtrue</code>.
Zero-mean normal noise with <code>sd=0.001</code> is added to the
responses <code>Z</code> and <code>ZZ</code>
</p>


<h3>Value</h3>

<p>Output is a <code>list</code> with entries:
</p>
<table>
<tr><td><code>X</code></td>
<td>
<p>2-d <code>data.frame</code> with <code>n1 + n2</code> input locations</p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p>Numeric vector describing the responses (with noise) at the
<code>X</code> input locations</p>
</td></tr>
<tr><td><code>Ztrue</code></td>
<td>
<p>Numeric vector describing the true responses (without
noise) at the <code>X</code> input locations</p>
</td></tr>
<tr><td><code>XX</code></td>
<td>
<p>2-d <code>data.frame</code> containing the remaining
<code>441 - (n1 + n2)</code> input locations</p>
</td></tr>
<tr><td><code>ZZ</code></td>
<td>
<p>Numeric vector describing the responses (with noise) at
the <code>XX</code> predictive locations</p>
</td></tr>
<tr><td><code>ZZtrue</code></td>
<td>
<p>Numeric vector describing the responses (without
noise) at the <code>XX</code> predictive locations</p>
</td></tr>
</table>


<h3>Author(s)</h3>

 
<p>Robert B. Gramacy, <a href="mailto:rbg@vt.edu">rbg@vt.edu</a>, and
Matt Taddy, <a href="mailto:mataddy@amazon.com">mataddy@amazon.com</a>
</p>


<h3>References</h3>

<p>Gramacy, R. B. (2007). <em><span class="pkg">tgp</span>: An <span class="rlang"><b>R</b></span> Package for Bayesian 
Nonstationary, Semiparametric Nonlinear Regression and Design by 
Treed Gaussian Process Models.</em>
Journal of Statistical Software, <b>19</b>(9).
<a href="https://www.jstatsoft.org/v19/i09">https://www.jstatsoft.org/v19/i09</a>
<a href="https://doi.org/10.18637/jss.v019.i09">doi:10.18637/jss.v019.i09</a>
</p>
<p>Robert B. Gramacy, Matthew Taddy (2010). <em>Categorical Inputs,
Sensitivity Analysis, Optimization and Importance Tempering with <span class="pkg">tgp</span>
Version 2, an <span class="rlang"><b>R</b></span> Package for Treed Gaussian Process Models.</em>
Journal of Statistical Software, <b>33</b>(6), 1&ndash;48.
<a href="https://www.jstatsoft.org/v33/i06/">https://www.jstatsoft.org/v33/i06/</a>
<a href="https://doi.org/10.18637/jss.v033.i06">doi:10.18637/jss.v033.i06</a>
</p>
<p>Gramacy, R. B., Lee, H. K. H. (2008).
<em>Bayesian treed Gaussian process models with an application
to computer modeling</em>. Journal of the American Statistical Association, 
103(483), pp. 1119-1130.  Also available as ArXiv article 0710.4536 
<a href="https://arxiv.org/abs/0710.4536">https://arxiv.org/abs/0710.4536</a>
</p>
<p><a href="https://bobby.gramacy.com/r_packages/tgp/">https://bobby.gramacy.com/r_packages/tgp/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lhs">lhs</a></code>, <code><a href="#topic+exp2d">exp2d</a></code>, <code><a href="#topic+exp2d.Z">exp2d.Z</a></code>,
<code><a href="#topic+btgp">btgp</a></code>, and other <code>b*</code> functions</p>


<h3>Examples</h3>

<pre><code class='language-R'>## randomly subsampled data
## ------------------------

eds &lt;- exp2d.rand()

# higher span = 0.5 required because the data is sparse
# and was generated randomly
eds.g &lt;- interp.loess(eds$X[,1], eds$X[,2], eds$Z, span=0.5)

# perspective plot, and plot of the input (X &amp; XX) locations
par(mfrow=c(1,2), bty="n")
persp(eds.g, main="loess surface", theta=-30, phi=20,
      xlab="X[,1]", ylab="X[,2]", zlab="Z")
plot(eds$X, main="Randomly Subsampled Inputs")
points(eds$XX, pch=19, cex=0.5)

## Latin Hypercube sampled data
## ----------------------------

edlh &lt;- exp2d.rand(lh=c(20, 15, 10, 5))

# higher span = 0.5 required because the data is sparse
# and was generated randomly
edlh.g &lt;- interp.loess(edlh$X[,1], edlh$X[,2], edlh$Z, span=0.5)

# perspective plot, and plot of the input (X &amp; XX) locations
par(mfrow=c(1,2), bty="n")
persp(edlh.g, main="loess surface", theta=-30, phi=20,
      xlab="X[,1]", ylab="X[,2]", zlab="Z")
plot(edlh$X, main="Latin Hypercube Sampled Inputs")
points(edlh$XX, pch=19, cex=0.5)

# show the quadrants
abline(h=2, col=2, lty=2, lwd=2)
abline(v=2, col=2, lty=2, lwd=2)


## Not run: 
## D-optimal subsample with a factor of 10 (more) candidates
## ---------------------------------------------------------

edlhd &lt;- exp2d.rand(lh=c(20, 15, 10, 5), dopt=10)

# higher span = 0.5 required because the data is sparse
# and was generated randomly
edlhd.g &lt;- interp.loess(edlhd$X[,1], edlhd$X[,2], edlhd$Z, span=0.5)

# perspective plot, and plot of the input (X &amp; XX) locations
par(mfrow=c(1,2), bty="n")
persp(edlhd.g, main="loess surface", theta=-30, phi=20,
      xlab="X[,1]", ylab="X[,2]", zlab="Z")
plot(edlhd$X, main="D-optimally Sampled Inputs")
points(edlhd$XX, pch=19, cex=0.5)

# show the quadrants
abline(h=2, col=2, lty=2, lwd=2)
abline(v=2, col=2, lty=2, lwd=2)

## End(Not run)
</code></pre>

<hr>
<h2 id='exp2d.Z'> Random Z-values for 2-d Exponential Data </h2><span id='topic+exp2d.Z'></span>

<h3>Description</h3>

<p> Evaluate the functional (mean) response for the 2-d
exponential data (truth) at the <code>X</code> inputs, and randomly
sample noisy <code>Z</code>&ndash;values having normal error with standard
deviation provided.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>exp2d.Z(X, sd=0.001)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exp2d.Z_+3A_x">X</code></td>
<td>
<p>Must be a <code>matrix</code> or a <code>data.frame</code> with two columns
describing input locations</p>
</td></tr>
<tr><td><code id="exp2d.Z_+3A_sd">sd</code></td>
<td>
<p>Standard deviation of iid normal noise added to the
responses</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The response is evaluated as 
</p>
<p style="text-align: center;"><code class="reqn">Z(X)=x_1 * \exp(x_1^2-x_2^2).</code>
</p>

<p>thus creating the outputs <code>Z</code> and <code>Ztrue</code>.
Zero-mean normal noise with <code>sd=0.001</code> is added to the
responses <code>Z</code> and <code>ZZ</code>
</p>


<h3>Value</h3>

<p>Output is a <code>data.frame</code> with columns:
</p>
<table>
<tr><td><code>Z</code></td>
<td>
<p>Numeric vector describing the responses (with noise) at the
<code>X</code> input locations</p>
</td></tr>
<tr><td><code>Ztrue</code></td>
<td>
<p>Numeric vector describing the true responses (without
noise) at the <code>X</code> input locations</p>
</td></tr>
</table>


<h3>Author(s)</h3>

 
<p>Robert B. Gramacy, <a href="mailto:rbg@vt.edu">rbg@vt.edu</a>, and
Matt Taddy, <a href="mailto:mataddy@amazon.com">mataddy@amazon.com</a>
</p>


<h3>References</h3>

<p>Gramacy, R. B. (2020) <em>Surrogates: Gaussian Process Modeling,
Design and Optimization for the Applied Sciences</em>. Boca Raton,
Florida: Chapman Hall/CRC.
<a href="https://bobby.gramacy.com/surrogates/">https://bobby.gramacy.com/surrogates/</a>
</p>
<p>Gramacy, R. B. (2007). <em><span class="pkg">tgp</span>: An <span class="rlang"><b>R</b></span> Package for Bayesian 
Nonstationary, Semiparametric Nonlinear Regression and Design by 
Treed Gaussian Process Models.</em>
Journal of Statistical Software, <b>19</b>(9).
<a href="https://www.jstatsoft.org/v19/i09">https://www.jstatsoft.org/v19/i09</a>
<a href="https://doi.org/10.18637/jss.v019.i09">doi:10.18637/jss.v019.i09</a>
</p>
<p>Robert B. Gramacy, Matthew Taddy (2010). <em>Categorical Inputs,
Sensitivity Analysis, Optimization and Importance Tempering with <span class="pkg">tgp</span>
Version 2, an <span class="rlang"><b>R</b></span> Package for Treed Gaussian Process Models.</em>
Journal of Statistical Software, <b>33</b>(6), 1&ndash;48.
<a href="https://www.jstatsoft.org/v33/i06/">https://www.jstatsoft.org/v33/i06/</a>
<a href="https://doi.org/10.18637/jss.v033.i06">doi:10.18637/jss.v033.i06</a>
</p>
<p>Gramacy, R. B., Lee, H. K. H. (2008).
<em>Bayesian treed Gaussian process models with an application
to computer modeling</em>. Journal of the American Statistical Association, 
103(483), pp. 1119-1130.  Also available as ArXiv article 0710.4536 
<a href="https://arxiv.org/abs/0710.4536">https://arxiv.org/abs/0710.4536</a>
</p>
<p><a href="https://bobby.gramacy.com/r_packages/tgp/">https://bobby.gramacy.com/r_packages/tgp/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+exp2d">exp2d</a></code>, <code><a href="#topic+exp2d.rand">exp2d.rand</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>N &lt;- 20
x &lt;- seq(-2,6,length=N)
X &lt;- expand.grid(x, x)
Zdata &lt;- exp2d.Z(X)
persp(x,x,matrix(Zdata$Ztrue, nrow=N), theta=-30, phi=20,
      main="Z true", xlab="x1", ylab="x2", zlab="Ztrue")
</code></pre>

<hr>
<h2 id='friedman.1.data'> First Friedman Dataset and a variation </h2><span id='topic+friedman.1.data'></span><span id='topic+fried.bool'></span>

<h3>Description</h3>

<p>Generate X and Y values from the 10-dim &ldquo;first&rdquo;
Friedman data set used to validate the Multivariate Adaptive 
Regression Splines (MARS) model, and a variation involving
boolean indicators.  This test function has
three non-linear and interacting variables, 
along with two linear, and five which are irrelevant.
The version with indicators has parts of the response
turned on based on the setting of the indicators
</p>


<h3>Usage</h3>

<pre><code class='language-R'>friedman.1.data(n = 100)
fried.bool(n = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="friedman.1.data_+3A_n">n</code></td>
<td>
<p>Number of samples desired</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the original formulation, as implemented by <code>friedman.1.data</code>
the function has 10-dim inputs <code>X</code> are drawn from Unif(0,1), and responses
are <code class="reqn">N(m(X),1)</code> where
<code class="reqn">m(\mathbf{x}) = E[f(\mathbf{x})]</code> and
</p>
<p style="text-align: center;"><code class="reqn">m(\mathbf{x}) = 10\sin(\pi x_1 x_2) + 20(x_3-0.5)^2 + 10x_4 + 5x_5</code>
</p>

<p>The variation <code>fried.bool</code> uses indicators
<code class="reqn">I\in \{1,2,3,4\}</code>.  The function also has 10-dim
inputs <code>X</code> with columns distributed as Unif(0,1) and responses
are <code class="reqn">N(m(\mathbf{x},I), 1)</code> where
<code class="reqn">m(\mathbf{x},I) = E(f(\mathbf{x},I)</code> and
</p>
<p style="text-align: center;"><code class="reqn">m(\mathbf{x},I) = f_1(\mathbf{x})_{[I=1]} + f_2(\mathbf{x})_{[I=2]} + f_3(\mathbf{x})_{[I=3]} + m([x_{10},\cdots,x_1])_{[I=4]}</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">f_1(\mathbf{x}) = 10\sin(\pi x_1 x_2), \; f_2(\mathbf{x}) = 20(x_3-0.5)^2, \; \mbox{and } f_3(\mathbf{x}) = 10x_4 + 5x_5.</code>
</p>

<p>The indicator I is coded in binary in the output data frame as:
<code>c(0,0,0)</code> for <code>I=1</code>,
<code>c(0,0,1)</code> for <code>I=2</code>,
<code>c(0,1,0)</code> for <code>I=3</code>, and
<code>c(1,0,0)</code> for <code>I=4</code>.
</p>


<h3>Value</h3>

<p>Output is a <code>data.frame</code> with columns
</p>
<table>
<tr><td><code>X.1</code>, <code>...</code>, <code>X.10</code></td>
<td>
<p>describing the 10-d randomly sampled inputs</p>
</td></tr>
<tr><td><code>I.1</code>, <code>...</code>, <code>I.3</code></td>
<td>
<p>boolean version of the indicators provided only
for <code>fried.bool</code>, as described above</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>sample responses (with N(0,1) noise)</p>
</td></tr>
<tr><td><code>Ytrue</code></td>
<td>
<p>true responses (without noise)</p>
</td></tr>
</table>


<h3>Note</h3>

<p>An example using the original version of the data
(<code>friedman.1.data</code>) is contained in the first package vignette:
<code>vignette("tgp")</code>.  The boolean version <code>fried.bool</code>
is used in second vignette <code>vignette("tgp2")</code> </p>


<h3>Author(s)</h3>

 
<p>Robert B. Gramacy, <a href="mailto:rbg@vt.edu">rbg@vt.edu</a>, and
Matt Taddy, <a href="mailto:mataddy@amazon.com">mataddy@amazon.com</a>
</p>


<h3>References</h3>

 
<p>Gramacy, R. B. (2007). <em><span class="pkg">tgp</span>: An <span class="rlang"><b>R</b></span> Package for
Bayesian Nonstationary, Semiparametric Nonlinear Regression
and Design by Treed Gaussian Process Models.</em>
Journal of Statistical Software, <b>19</b>(9).
<a href="https://www.jstatsoft.org/v19/i09">https://www.jstatsoft.org/v19/i09</a>
<a href="https://doi.org/10.18637/jss.v019.i09">doi:10.18637/jss.v019.i09</a>
</p>
<p>Robert B. Gramacy, Matthew Taddy (2010). <em>Categorical Inputs,
Sensitivity Analysis, Optimization and Importance Tempering with <span class="pkg">tgp</span>
Version 2, an <span class="rlang"><b>R</b></span> Package for Treed Gaussian Process Models.</em>
Journal of Statistical Software, <b>33</b>(6), 1&ndash;48.
<a href="https://www.jstatsoft.org/v33/i06/">https://www.jstatsoft.org/v33/i06/</a>.
<a href="https://doi.org/10.18637/jss.v033.i06">doi:10.18637/jss.v033.i06</a>
</p>
<p>Friedman, J. H. (1991).
<em>Multivariate adaptive regression splines.</em>
&ldquo;Annals of Statistics&rdquo;, <b>19</b>, No. 1, 1&ndash;67.
</p>
<p>Gramacy, R. B., Lee, H. K. H. (2008).
<em>Bayesian treed Gaussian process models with an application
to computer modeling</em>. Journal of the American Statistical Association, 
103(483), pp. 1119-1130.  Also available as ArXiv article 0710.4536 
<a href="https://arxiv.org/abs/0710.4536">https://arxiv.org/abs/0710.4536</a>
</p>
<p>Chipman, H., George, E., &amp; McCulloch, R. (2002).
<em>Bayesian treed models.</em>
Machine Learning, <b>48</b>, 303&ndash;324.
</p>
<p><a href="https://bobby.gramacy.com/r_packages/tgp/">https://bobby.gramacy.com/r_packages/tgp/</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+bgpllm">bgpllm</a></code>, <code><a href="#topic+btlm">btlm</a></code>, 
<code><a href="#topic+blm">blm</a></code>, <code><a href="#topic+bgp">bgp</a></code>, <code><a href="#topic+btgpllm">btgpllm</a></code>, <code><a href="#topic+bgp">bgp</a></code></p>

<hr>
<h2 id='interp.loess'> Lowess 2-d interpolation onto a uniform grid </h2><span id='topic+interp.loess'></span>

<h3>Description</h3>

<p>Use the <code><a href="stats.html#topic+loess">loess</a></code> function to interpolate the
two-dimensional <code>x</code>, <code>y</code>, and <code>z</code> data onto a uniform grid.  The output
produced is an object directly usable by the plotting functions
<code><a href="graphics.html#topic+persp">persp</a></code>, <code><a href="graphics.html#topic+image">image</a></code>,
and <code><a href="graphics.html#topic+contour">contour</a></code>, etc.
</p>
<p>This function is designed as an alternative to the
<code><a href="akima.html#topic+interp">interp</a></code> functions from the <span class="pkg">akima</span>
library.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interp.loess(x, y, z, gridlen = c(40,40), span = 0.1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="interp.loess_+3A_x">x</code></td>
<td>
<p> Vector of <code>X</code> spatial input locations </p>
</td></tr>
<tr><td><code id="interp.loess_+3A_y">y</code></td>
<td>
<p> Vector of <code>Y</code> spatial input locations </p>
</td></tr>
<tr><td><code id="interp.loess_+3A_z">z</code></td>
<td>
<p> Vector of <code>Z</code> responses interpreted as
<code>Z = f(X,Y)</code></p>
</td></tr>
<tr><td><code id="interp.loess_+3A_gridlen">gridlen</code></td>
<td>
<p> Size of the interpolated grid to be produced in x and y.
The default of <code>gridlen = c(40,40)</code> causes a <code>40 * 40</code>
grid of <code>X</code>, <code>Y</code>, and <code>Z</code> values to be computed.</p>
</td></tr>
<tr><td><code id="interp.loess_+3A_span">span</code></td>
<td>
<p> Kernel span argument to the <code><a href="stats.html#topic+loess">loess</a></code>
function with default setting <code>span = 0.1</code> set significantly lower than the
the <code><a href="stats.html#topic+loess">loess</a></code> default &ndash; see note below.  </p>
</td></tr>
<tr><td><code id="interp.loess_+3A_...">...</code></td>
<td>
<p> Further arguments to be passed to the
<code><a href="stats.html#topic+loess">loess</a></code> function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses <code><a href="base.html#topic+expand.grid">expand.grid</a></code> function to produce a uniform
grid of size <code>gridlen</code> with domain equal to the rectangle implied
by <code>X</code> and <code>Y</code>.  Then, a <code><a href="stats.html#topic+loess">loess</a></code> a smoother
is fit to the data <code>Z = f(X,Y)</code>.  Finally,
<code><a href="stats.html#topic+predict.loess">predict.loess</a></code> is used to  predict onto the grid.
</p>


<h3>Value</h3>

<p>The output is a list compatible with the 2-d plotting functions
<code><a href="graphics.html#topic+persp">persp</a></code>, <code><a href="graphics.html#topic+image">image</a></code>,
and <code><a href="graphics.html#topic+contour">contour</a></code>, etc.
</p>
<p>The list contains...
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>Vector of with <code>length(x) == gridlen</code> of increasing
<code>X</code> grid locations</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>Vector of with <code>length(y) == gridlen</code> of increasing
<code>Y</code> grid locations</p>
</td></tr>
<tr><td><code>z</code></td>
<td>
<p><code>matrix</code> of interpolated responses <code>Z = f(X,Y)</code>
where <code>z[i,j]</code> contains an estimate of <code>f(x[i],y[j])</code></p>
</td></tr>
</table>


<h3>Note</h3>

 
<p>As mentioned above, the default <code>span = 0.1</code> parameter is 
significantly smaller that the default <code><a href="stats.html#topic+loess">loess</a></code> setting.
This asserts a tacit assumption that
the input is densely packed and that the noise in <code>z</code>'s is small.  
Such should be the case when the data are output from a <span class="pkg">tgp</span> regression &ndash;
this function was designed specifically for this situation.
For data that is random or sparse, simply choose higher setting,
e.g., the default <code><a href="stats.html#topic+loess">loess</a></code> setting of <code>span =
  0.75</code>, or a more intermediate setting of <code>span = 0.5</code> as in the example below</p>


<h3>Author(s)</h3>

 
<p>Robert B. Gramacy, <a href="mailto:rbg@vt.edu">rbg@vt.edu</a>, and
Matt Taddy, <a href="mailto:mataddy@amazon.com">mataddy@amazon.com</a>
</p>


<h3>References</h3>

<p><a href="https://bobby.gramacy.com/r_packages/tgp/">https://bobby.gramacy.com/r_packages/tgp/</a>
</p>


<h3>See Also</h3>

 <p><code><a href="akima.html#topic+interp">interp</a></code>, <code><a href="stats.html#topic+loess">loess</a></code>,
<code><a href="graphics.html#topic+persp">persp</a></code>, <code><a href="Matrix.html#topic+image">image</a></code>, <code><a href="graphics.html#topic+contour">contour</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># random data
ed &lt;- exp2d.rand()

# higher span = 0.5 required because the data is sparse
# and was generated randomly
ed.g &lt;- interp.loess(ed$X[,1], ed$X[,2], ed$Z, span=0.5)

# perspective plot
persp(ed.g)
</code></pre>

<hr>
<h2 id='itemps'> Functions to plot summary information about 
the sampled inverse temperatures, tree heights, etc., stored in the
traces of a &quot;tgp&quot;-class object</h2><span id='topic+itemps.barplot'></span><span id='topic+hist2bar'></span>

<h3>Description</h3>

<p>Functions for making barplots summarizing the progress of
importance tempering.  The <code>itemps.barplot</code> function can be
used to make a histogram of the inverse temperatures visited
in the trans-temporal Markov chain.  The <code>hist2bar</code> function
is useful for making a histogram of integer-valued samples
(e.g., tree heights) encountered in one or several Markov chains
</p>


<h3>Usage</h3>

<pre><code class='language-R'>itemps.barplot(obj, main = NULL, xlab = "itemps", 
               ylab = "counts", plot.it = TRUE, ...)
hist2bar(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="itemps_+3A_obj">obj</code></td>
<td>
 <p><code>"tgp"</code>-class object </p>
</td></tr>
<tr><td><code id="itemps_+3A_main">main</code></td>
<td>
<p> Main plot label to be augmented by <code>itemps.barplot</code> </p>
</td></tr>
<tr><td><code id="itemps_+3A_xlab">xlab</code></td>
<td>
<p> Label for the x-axis </p>
</td></tr>
<tr><td><code id="itemps_+3A_ylab">ylab</code></td>
<td>
<p> Label for the y-axis </p>
</td></tr>
<tr><td><code id="itemps_+3A_plot.it">plot.it</code></td>
<td>
<p> whether to plot the <code><a href="graphics.html#topic+barplot">barplot</a></code> 
in addition to returning the <code>data.frame</code> for later use
in a <code><a href="graphics.html#topic+barplot">barplot</a></code> call </p>
</td></tr>
<tr><td><code id="itemps_+3A_...">...</code></td>
<td>
<p> other arguments passed to <code><a href="graphics.html#topic+barplot">barplot</a></code> if
<code>plot.it = TRUE</code> </p>
</td></tr>
<tr><td><code id="itemps_+3A_x">x</code></td>
<td>
 <p><code>matrix</code> of integers whose columns are treated as
different realizations of similar processes producing where each
row represents a sample (e.g., tree height) under that process </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>itemps.barplot</code> specifically works with the <code>$trace</code>
field of a <code>"tgp"</code>-class object.  An error will be produced
if this field is <code>NULL</code>, i.e., if the <code>b*</code> function used
the create the object was not run with the argument <code>trace=TRUE</code>
</p>
<p>The <code>hist2bar</code> function can be used on any integer (or discrete)
valued matrix.  The columns are interpreted as different realizations
of similar processes for comparison with one another via a histogram.
</p>
<p>The histogram is obtained with the <code><a href="graphics.html#topic+barplot">barplot</a></code> command used
with the argument <code>beside=TRUE</code>.  See the examples section of
<code><a href="#topic+default.itemps">default.itemps</a></code>
</p>


<h3>Value</h3>

<p>Both functions return a <code>data.frame</code> that can be used
within the <code><a href="graphics.html#topic+barplot">barplot</a></code> function with argument
<code>beside=TRUE</code>
</p>


<h3>Author(s)</h3>

<p>Robert B. Gramacy, <a href="mailto:rbg@vt.edu">rbg@vt.edu</a>, and
Matt Taddy, <a href="mailto:mataddy@amazon.com">mataddy@amazon.com</a>
</p>


<h3>References</h3>

 
<p>Gramacy, R.B., Samworth, R.J., and King, R. (2007)
<em>Importance Tempering.</em> ArXiv article 0707.4242
<a href="https://arxiv.org/abs/0707.4242">https://arxiv.org/abs/0707.4242</a>
</p>
<p><a href="https://bobby.gramacy.com/r_packages/tgp/">https://bobby.gramacy.com/r_packages/tgp/</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+default.itemps">default.itemps</a></code>, <code>vignette(tgp2)</code>, 
<code><a href="graphics.html#topic+barplot">barplot</a></code> </p>

<hr>
<h2 id='lhs'>Latin Hypercube sampling</h2><span id='topic+lhs'></span>

<h3>Description</h3>

<p>Draw a (random) Latin Hypercube (LH) sample of size <code>n</code> from in
the region outlined by the provided rectangle
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lhs(n, rect, shape=NULL, mode=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lhs_+3A_n">n</code></td>
<td>
<p> Size of the LH sample </p>
</td></tr>
<tr><td><code id="lhs_+3A_rect">rect</code></td>
<td>
<p> Rectangle describing the domain from which the LH sample
is to be taken.  The rectangle should be a <code>matrix</code> or
<code>data.frame</code> with <code>ncol(rect) = 2</code>, and number of rows equal to the
dimension of the domain.  For 1-d data, a vector of length 2
is allowed</p>
</td></tr>
<tr><td><code id="lhs_+3A_shape">shape</code></td>
<td>
<p> Optional vector of shape parameters for the Beta distribution.
Vector of length equal to the dimension of the domain, with elements &gt; 1.
If this is specified, the LH sample is proportional to a joint pdf formed by
independent Beta distributions in each dimension of the domain,
scaled and shifted to have support defined by <code>rect</code>.
Only concave Beta distributions with <code>shape</code> &gt; 1 are supported. </p>
</td></tr>
<tr><td><code id="lhs_+3A_mode">mode</code></td>
<td>
<p> Optional vector of mode values for the Beta distribution.
Vector of length equal to the dimension of the domain, with elements within
the support defined by <code>rect</code>.  If <code>shape</code> is specified,
but this is not, then the scaled Beta distributions will be symmetric </p>
</td></tr>
</table>


<h3>Value</h3>

<p>The output is a <code>matrix</code> with <code>n</code> rows and
<code>nrow(rect)</code> columns.  Each of the <code>n</code> rows represents
a sample point.
</p>


<h3>Note</h3>

<p>The domain bounds specified by the rows of <code>rect</code> can
be specified backwards with no change in effect.</p>


<h3>Author(s)</h3>

 
<p>Robert B. Gramacy, <a href="mailto:rbg@vt.edu">rbg@vt.edu</a>, and
Matt Taddy, <a href="mailto:mataddy@amazon.com">mataddy@amazon.com</a>
</p>


<h3>References</h3>

 
<p>Gramacy, R. B. (2020) <em>Surrogates: Gaussian Process Modeling,
Design and Optimization for the Applied Sciences</em>. Boca Raton,
Florida: Chapman Hall/CRC.  (See Chapter 4.)
<a href="https://bobby.gramacy.com/surrogates/">https://bobby.gramacy.com/surrogates/</a>
</p>
<p>McKay, M. D., W. J. Conover and R. J. Beckman. (1979).
<em>A Comparison of Three Methods for Selecting Values of Input
Variables in the Analysis of Output from a Computer Code</em>,
Technometrics 21: (pp. 239&ndash;245).
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+tgp.design">tgp.design</a></code>, <code><a href="#topic+dopt.gp">dopt.gp</a></code>,
<code><a href="#topic+sens">sens</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># get and plot a 2-d LH design
s1 &lt;- lhs(10, rbind(c(-2,3), c(0.5, 0.8)))
plot(s1)

# plot a grid to show that there is one sample
# in each grid location
abline(v=seq(-2,3,length=11), lty=2, col=3)
abline(h=seq(0.5,0.8,length=11), lty=2, col=3)
</code></pre>

<hr>
<h2 id='mapT'> Plot the MAP partition, or add one to an existing plot </h2><span id='topic+mapT'></span>

<h3>Description</h3>

<p>Plot the maximum a' posteriori (MAP) tree from a <code>"tgp"</code>-class
object, or add one on top of an existing plot.  Like <code>plot.tgp</code>,
projections and slices of trees can be plotted as specified
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mapT(out, proj = NULL, slice = NULL, add = FALSE, lwd = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mapT_+3A_out">out</code></td>
<td>
 <p><code>"tgp"</code>-class object which is the output of one
the model functions with tree support (e.g. <code><a href="#topic+btgpllm">btgpllm</a></code>)</p>
</td></tr>
<tr><td><code id="mapT_+3A_proj">proj</code></td>
<td>
<p>1-or-2-Vector describing the dimensions to be shown in a
projection. The argument is ignored for 1-d data, i.e., if <code>x$d
      == 1</code>. For 2-d data, no projection needs to be specified&mdash; the
default argument (<code>proj = NULL</code>) will result in a 2-d plot.
1-d projections of 2-d or higher trees are are
supported, e.g., <code>proj = c(2)</code> would show the second variable
projection. For 3-d data or higher, <code>proj=NULL</code> defaults to
<code>proj = c(1,2)</code> which plots a 2-d projection of the trees
for the first two variables.  Slices have priority over projections&mdash;
see next argument (<code>slice</code>)&mdash; when non-null arguments are
provided for both.</p>
</td></tr>
<tr><td><code id="mapT_+3A_slice">slice</code></td>
<td>
<p><code>list</code> object with <code>x</code> and <code>z</code> fields, which
are vectors of equal length describing the slice to be plotted, i.e.,
which z-values of the treed partitions in the <code>x$d - 2</code> inputs
<code>x$X</code> and <code>x$XX</code> should be fixed to in order to obtain a
2-d visualization.
For example, for 4-d data, <code>slice = list(x=(2,4), z=c(0.2, 1.5)</code> will
result in a 2-d plot of the first and third dimensions which have
the second and fourth slice fixed at 0.5 and 1.5.  The default is
<code>NULL</code>, yielding to the <code>proj</code> argument.  Argument is
ignored for 1-d data, i.e., if <code>x$d == 1</code></p>
</td></tr>
<tr><td><code id="mapT_+3A_add">add</code></td>
<td>
<p> Specify whether the to add partitions to an existing plot
(<code>add = TRUE</code>) or to make a new plot showing the data
<code>out$X</code> along with the partitions (default <code>add = FALSE</code>)</p>
</td></tr>
<tr><td><code id="mapT_+3A_lwd">lwd</code></td>
<td>
<p> Plotting argument specifying the width of the lines used
to depict the partitions</p>
</td></tr>
<tr><td><code id="mapT_+3A_...">...</code></td>
<td>
<p> Additional arguments to <code>plot</code> used when <code>add = FALSE</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>The only output of this function is a beautiful region-representation
of the MAP tree.
</p>


<h3>Note</h3>

<p>For examples, see <code>vignette("tgp")</code> and the examples provided 
in the documentation for the <code><a href="#topic+tgp.design">tgp.design</a></code> function
</p>


<h3>Author(s)</h3>

 
<p>Robert B. Gramacy, <a href="mailto:rbg@vt.edu">rbg@vt.edu</a>, and
Matt Taddy, <a href="mailto:mataddy@amazon.com">mataddy@amazon.com</a>
</p>


<h3>References</h3>

<p><a href="https://bobby.gramacy.com/r_packages/tgp/">https://bobby.gramacy.com/r_packages/tgp/</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+plot.tgp">plot.tgp</a></code>, <code><a href="#topic+tgp.trees">tgp.trees</a></code>,
<code><a href="#topic+tgp.design">tgp.design</a></code>, <code>vignette("tgp")</code></p>

<hr>
<h2 id='optim.tgp'> Surrogate-based optimization of noisy black-box function </h2><span id='topic+optim.step.tgp'></span><span id='topic+optim.ptgpf'></span>

<h3>Description</h3>

<p>Optimize (minimize) a noisy black-box function (i.e., a function which
may not be differentiable, and may not execute deterministically).
A <code>b*</code> <span class="pkg">tgp</span> model is used as a surrogate for
adaptive sampling via improvement (and other) statistics.  Note that
this function is intended as a skeleton to be tailored as required
for a particular application
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optim.step.tgp(f, rect, model = btgp, prev = NULL, X = NULL,
     Z = NULL, NN = 20 * length(rect), improv = c(1, 5), cands = c("lhs", "tdopt"),
     method = c("L-BFGS-B", "Nelder-Mead", "BFGS", "CG", "SANN",  "optimize"), ...)
optim.ptgpf(start, rect, tgp.obj,
     method=c("L-BFGS-B", "Nelder-Mead", "BFGS", "CG", "SANN", "optimize"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optim.tgp_+3A_f">f</code></td>
<td>
<p> A function to be optimized, having only one free argument </p>
</td></tr>
<tr><td><code id="optim.tgp_+3A_rect">rect</code></td>
<td>
 <p><code>matrix</code> indicating the domain of the argument of
<code>f</code> over which an optimal should be searched; must have
<code>ncol(rect) = 2</code> and <code>nrow</code> agreeing with the argument
of <code>f</code> indicating the dimension of the data. For 1-d data,
a vector of length 2 is allowed</p>
</td></tr> 
<tr><td><code id="optim.tgp_+3A_model">model</code></td>
<td>
<p> The <code>b*</code> regression model used as a surrogate
for optimization; see <code><a href="#topic+btgp">btgp</a></code>, and others,
for more detail </p>
</td></tr>
<tr><td><code id="optim.tgp_+3A_prev">prev</code></td>
<td>
<p> The output from a previous call to <code>optim.step.tgp</code>;
this should be a <code>list</code> with entries as described the &ldquo;Value&rdquo;
section below </p>
</td></tr>
<tr><td><code id="optim.tgp_+3A_x">X</code></td>
<td>
<p><code>data.frame</code>, <code>matrix</code>, or vector of current
inputs <code>X</code>, to be augmented </p>
</td></tr>
<tr><td><code id="optim.tgp_+3A_z">Z</code></td>
<td>
<p> Vector of current output responses <code>Z</code> of length
equal to the leading dimension (rows) of <code>X</code>, i.e.,
<code>length(Z) ==  nrow(X)</code>, to be augmented</p>
</td></tr>
<tr><td><code id="optim.tgp_+3A_nn">NN</code></td>
<td>
<p> Number of candidate locations (<code>XX</code>) at which to
sample from the improvement statistic </p>
</td></tr>
<tr><td><code id="optim.tgp_+3A_improv">improv</code></td>
<td>
<p> Indicates the <code>improv</code> argument provided
to a <code>b*</code> <code>model</code> function for sampling from the
improvement statistic at the <code>NN</code> candidate locations
(<code>XX</code>); see <code><a href="#topic+btgp">btgp</a></code>, and others, for more detail</p>
</td></tr> 
<tr><td><code id="optim.tgp_+3A_cands">cands</code></td>
<td>
<p> The type of candidates (<code>XX</code>)
at which samples from the improvement statistics are gathered.
The default setting  of <code>"lhs"</code> is recommended.  However,
a sequential treed D-optimal design can be used with <code>"tdopt"</code>
for a more global exploration; see <code><a href="#topic+tgp.design">tgp.design</a></code> for
more details </p>
</td></tr>
<tr><td><code id="optim.tgp_+3A_method">method</code></td>
<td>
<p> A method from <code><a href="stats.html#topic+optim">optim</a></code>, or <code>"optimize"</code>
which uses <code><a href="stats.html#topic+optimize">optimize</a></code> as appropriate (when the
input-space is 1-d)</p>
</td></tr>
<tr><td><code id="optim.tgp_+3A_...">...</code></td>
<td>
<p> Further arguments to the <code>b*</code> <code>model</code>
function</p>
</td></tr>
<tr><td><code id="optim.tgp_+3A_start">start</code></td>
<td>
<p> A starting value for optimization of the MAP predictive
(kriging) surface of a <code>"tgp"</code>-class object.  A good starting
value is the <code>X</code> or <code>XX</code> location found to be a minimum
in the mean predictive surface contained in <code>"tgp"</code>-class
object </p>
</td></tr>
<tr><td><code id="optim.tgp_+3A_tgp.obj">tgp.obj</code></td>
<td>
<p> A <code>"tgp"</code>-class object that is the output of one of
the <code>b*</code> functions: <code><a href="#topic+blm">blm</a></code>, <code><a href="#topic+btlm">btlm</a></code>
<code><a href="#topic+bgp">bgp</a></code>, <code><a href="#topic+bgpllm">bgpllm</a></code>, <code><a href="#topic+btgp">btgp</a></code>, or 
<code><a href="#topic+btgpllm">btgpllm</a></code>, as can be used by <code><a href="#topic+predict.tgp">predict.tgp</a></code>
for optimizing on the MAP predictive (surrogate) kriging surface </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>optim.step.tgp</code> executes one step in a search for the global
optimum (minimum) of a noisy function (<code>Z~f(X)</code>) in a bounded
rectangle (<code>rect</code>). The procedure essentially fits a tgp
<code>model</code> and samples from
the posterior distribution of improvement
statistics at <code>NN+1</code> candidates locations.
<code>NN</code> of the candidates come from
<code>cands</code>, i.e., <code>"lhs"</code> or <code>"tdopt"</code>, plus one which
is the location of the minima found in a previous run via
<code>prev</code> by using <code><a href="stats.html#topic+optim">optim</a></code> (with a particular
<code>method</code> or <code><a href="stats.html#topic+optimize">optimize</a></code> instead) on the MAP
<code>model</code> predictive surface using the <code>"tgp"</code>-class object
contained therein.
The <code>improv[2]</code> with the the highest expected improvement are
recommended for adding into the design on output.
</p>
<p><code>optim.ptgpf</code> is the subroutine used by
<code>optim.step.tgp</code> to find optimize on the MAP (surrogate)
predictive surface for the <code>"tgp"</code>-class object contained in
<code>prev</code>.
</p>
<p>Please see <code>vignette("tgp2")</code> for a detailed illustration
</p>


<h3>Value</h3>

<p>The <code>list</code> return has the following components.
</p>
<table>
<tr><td><code>X</code></td>
<td>
<p> A <code>matrix</code> with <code>nrow(rect)</code> columns whose
rows contain recommendations for input locations to add into
the design </p>
</td></tr>
<tr><td><code>progress</code></td>
<td>
<p> A one-row <code>data.frame</code> indicating the
the <code>X</code>-location and objective value of the current best guess
of the solution to the (kriging) surrogate optimization along with the
maximum values of the improvement statistic </p>
</td></tr>
<tr><td><code>obj</code></td>
<td>
<p> the <code>"tgp"</code>-class object output from the
<code>model</code> function </p>
</td></tr>
</table>


<h3>Note</h3>

<p>The ellipses (<code>...</code>) argument is used differently here, as
compared to <code><a href="stats.html#topic+optim">optim</a></code>, and <code><a href="stats.html#topic+optimize">optimize</a></code>.  It
allows further arguments to be passed to the  <code>b*</code> <code>model</code>
function, whereas for <code><a href="stats.html#topic+optim">optim</a></code> it would describe
further (static) arguments to the function <code>f</code> to be optimized.
If static arguments need to be set for <code>f</code>, then we recommend
setting defaults via the <code><a href="base.html#topic+formals">formals</a></code> of <code>f</code>
</p>


<h3>Author(s)</h3>

 
<p>Robert B. Gramacy, <a href="mailto:rbg@vt.edu">rbg@vt.edu</a>, and
Matt Taddy, <a href="mailto:mataddy@amazon.com">mataddy@amazon.com</a>
</p>


<h3>References</h3>

<p>Gramacy, R. B. (2020) <em>Surrogates: Gaussian Process Modeling,
Design and Optimization for the Applied Sciences</em>. Boca Raton,
Florida: Chapman Hall/CRC.  (See Chapter 7.)
<a href="https://bobby.gramacy.com/surrogates/">https://bobby.gramacy.com/surrogates/</a>
</p>
<p>Matthew Taddy, Herbert K.H. Lee, Genetha A. Gray, and Joshua
D. Griffin. (2009) <em>Bayesian guided pattern search for
robust local optimization.</em>  Technometrics, 51(4), pp. 389-401
</p>
<p><a href="https://bobby.gramacy.com/r_packages/tgp/">https://bobby.gramacy.com/r_packages/tgp/</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+btgp">btgp</a></code>, etc., <code><a href="stats.html#topic+optim">optim</a></code>,
<code><a href="stats.html#topic+optimize">optimize</a></code>, <code><a href="#topic+tgp.design">tgp.design</a></code>,
<code><a href="#topic+predict.tgp">predict.tgp</a></code>, <code><a href="#topic+dopt.gp">dopt.gp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## optimize the simple exponential function 
f &lt;- function(x) { exp2d.Z(x)$Z }

## create the initial design with D-optimal candidates
rect &lt;- rbind(c(-2,6), c(-2,6))
Xcand &lt;- lhs(500, rect)
X &lt;- dopt.gp(50, X=NULL, Xcand)$XX
Z &lt;- f(X)

## do 10 rounds of adaptive sampling
out &lt;- progress &lt;- NULL
for(i in 1:10) {

  ## get recommendations for the next point to sample
  out &lt;- optim.step.tgp(f, X=X, Z=Z, rect=rect, prev=out)

  ## add in the inputs, and newly sampled outputs
  X &lt;- rbind(X, out$X)
  Z &lt;- c(Z, f(out$X))

  ## keep track of progress and best optimum
  progress &lt;- rbind(progress, out$progress)
  print(progress[i,])
}

## plot the progress so far
par(mfrow=c(2,2))
plot(out$obj, layout="surf")
plot(out$obj, layout="as", as="improv")
matplot(progress[,1:nrow(rect)], main="optim results",
        xlab="rounds", ylab="x[,1:2]", type="l", lwd=2)
plot(log(progress$improv), type="l", main="max log improv",
     xlab="rounds", ylab="max log(improv)")

</code></pre>

<hr>
<h2 id='partition'> Partition data according to the MAP tree </h2><span id='topic+partition'></span>

<h3>Description</h3>

<p>Partition data according to the maximum a' posteriori (MAP)
tree contained in a <code>"tgp"</code>-class object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>partition(X, out)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="partition_+3A_x">X</code></td>
<td>
<p><code>data.frame</code>, <code>matrix</code>, or vector of inputs <code>X</code> 
with the same dimension of <code>out$X</code>, i.e., <code>ncol(X) == ncol(out$X)</code></p>
</td></tr>
<tr><td><code id="partition_+3A_out">out</code></td>
<td>
 <p><code>"tgp"</code>-class object which is the output of one
the model functions with tree support (e.g. <code><a href="#topic+btgpllm">btgpllm</a></code>,
<code><a href="#topic+btgp">btgp</a></code>, <code><a href="#topic+btlm">btlm</a></code>) </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Output is a list of <code>data.frame</code>s populated with the inputs
<code>X</code> contained in each region of the partition of the MAP tree
in the <code>"tgp"</code>-class object <code>out</code>
</p>


<h3>Author(s)</h3>

 
<p>Robert B. Gramacy, <a href="mailto:rbg@vt.edu">rbg@vt.edu</a>, and
Matt Taddy, <a href="mailto:mataddy@amazon.com">mataddy@amazon.com</a>
</p>


<h3>References</h3>

<p><a href="https://bobby.gramacy.com/r_packages/tgp/">https://bobby.gramacy.com/r_packages/tgp/</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+tgp.design">tgp.design</a></code>, <code><a href="#topic+tgp.trees">tgp.trees</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#
# 2-d Exponential data
# (This example is based on random data.  
# It might be fun to run it a few times)
#

# get the data
exp2d.data &lt;- exp2d.rand()
X &lt;- exp2d.data$X; Z &lt;- exp2d.data$Z
Xcand &lt;- exp2d.data$XX

# fit treed GP LLM model to data w/o prediction
# basically just to get MAP tree (and plot it)
out &lt;- btgpllm(X=X, Z=Z, pred.n=FALSE, BTE=c(2000,3000,2)) 
tgp.trees(out)

# find a treed sequential D-Optimal design 
# with 10 more points
Xcand.parts &lt;- partition(Xcand, out)
</code></pre>

<hr>
<h2 id='plot.tgp'> Plotting for Treed Gaussian Process Models </h2><span id='topic+plot.tgp'></span>

<h3>Description</h3>

<p>A generic function for plotting of <code>"tgp"</code>-class objects.
1-d posterior mean and error plots, 2-d posterior mean and
error image and perspective plots, and 3+-dimensional mean and error
image and perspective plots are supported via projection
and slicing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tgp'
plot(x, pparts = TRUE, proj = NULL, slice = NULL,
         map = NULL, as = NULL, center = "mean", layout = "both",
         main = NULL, xlab = NULL, ylab = NULL, zlab = NULL, pc = "pc",
         gridlen = c(40,40), span = 0.1, pXX = TRUE,
         legendloc = "topright", maineff = TRUE,  mrlayout="both",
         rankmax = 20, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.tgp_+3A_x">x</code></td>
<td>
 <p><code>"tgp"</code>-class object that is the output of one of
the <code>b*</code> functions: <code><a href="#topic+blm">blm</a></code>, <code><a href="#topic+btlm">btlm</a></code>
<code><a href="#topic+bgp">bgp</a></code>, <code><a href="#topic+bgpllm">bgpllm</a></code>, <code><a href="#topic+btgp">btgp</a></code>, or 
<code><a href="#topic+btgpllm">btgpllm</a></code></p>
</td></tr>
<tr><td><code id="plot.tgp_+3A_pparts">pparts</code></td>
<td>
<p>If <code>TRUE</code>, partition-regions are plotted (default), 
otherwise they are not</p>
</td></tr>
<tr><td><code id="plot.tgp_+3A_proj">proj</code></td>
<td>
<p>1-or-2-Vector describing the dimensions to be shown in a
projection. The argument is ignored for 1-d data, i.e., if <code>x$d
      == 1</code>. For 2-d data, no projection needs be specified&mdash; the
default argument (<code>proj = NULL</code>) will result in a 2-d perspective
or image plot.  1-d projections of 2-d or higher data are are
supported, e.g., <code>proj = c(2)</code> would show the second variable
projection. For 3-d data or higher, <code>proj=NULL</code> defaults to
<code>proj = c(1,2)</code> which plots a 2-d projection for the first two
variables.  Slices have priority over the projections&mdash;
see next argument (<code>slice</code>)&mdash; when non-null arguments are
provided for both.</p>
</td></tr>
<tr><td><code id="plot.tgp_+3A_slice">slice</code></td>
<td>
<p><code>list</code> object with <code>x</code> and <code>z</code> fields, which
are vectors of equal length describing the slice to be plotted, i.e.,
which z-values of the <code>x$d - 2</code> inputs <code>x$X</code> and
<code>x$XX</code> should be fixed to in order to obtain a 2-d visualization.
For example, for 4-d data, <code>slice = list(x=(2,4), z=c(0.2, 1.5)</code> will
result in a 2-d plot of the first and third dimensions which have
the second and fourth slice fixed at 0.5 and 1.5.  The default is
<code>NULL</code>, yielding to the <code>proj</code> argument.  Argument is
ignored for 1-d data, i.e., if <code>x$d == 1</code></p>
</td></tr>
<tr><td><code id="plot.tgp_+3A_map">map</code></td>
<td>
<p>Optional 2-d map (longitude and latitude) 
from <span class="pkg">maps</span> to be shown on top of image plots</p>
</td></tr>
<tr><td><code id="plot.tgp_+3A_center">center</code></td>
<td>
<p>Default <code>center = "mean"</code> causes the posterior
predictive mean to be plotted as the centering statistic.
Otherwise the median can be used with <code>center = "med"</code>, or the
kriging mean with <code>center = "km"</code></p>
</td></tr>
<tr><td><code id="plot.tgp_+3A_as">as</code></td>
<td>
<p>Optional string indicator for plotting of adaptive sampling
statistics: specifying <code>as = "alm"</code> for ALM, <code>as = "s2"</code>
for predictive variance, <code>as = "ks2"</code> for expected kriging
variance, <code>as = "alc"</code> for ALC,
and <code>as = "improv"</code> for expected improvement (about the
minimum, see the <code>rankmax</code> argument below).  
The default <code>as = NULL</code> plots error-bars (1d-plots) or 
error magnitudes (2d-plots), which is essentially the same as 
<code>as = "alm"</code></p>
</td></tr>
<tr><td><code id="plot.tgp_+3A_layout">layout</code></td>
<td>
<p>Specify whether to plot the mean predictive surface
(<code>layout = "surf"</code>), the error or adaptive sampling statistics
(<code>layout = "as"</code>), or default (<code>layout = "both"</code>) which
shows both.  If <code>layout = "sens"</code>, plot the results of a
sensitivity analysis (see <code><a href="#topic+sens">sens</a></code>) in a format determined
by the argument <code>maineff</code> below. </p>
</td></tr>
<tr><td><code id="plot.tgp_+3A_main">main</code></td>
<td>
<p>Optional <code>character</code> string to add to the main title of the plot</p>
</td></tr>
<tr><td><code id="plot.tgp_+3A_xlab">xlab</code></td>
<td>
<p>Optional <code>character</code> string to add to the x label of the plots</p>
</td></tr>
<tr><td><code id="plot.tgp_+3A_ylab">ylab</code></td>
<td>
<p>Optional <code>character</code> string to add to the y label of the plots</p>
</td></tr> 
<tr><td><code id="plot.tgp_+3A_zlab">zlab</code></td>
<td>
<p>Optional <code>character</code> string to add to the z label of the plots;
ignored unless <code>pc = "p"</code></p>
</td></tr>
<tr><td><code id="plot.tgp_+3A_pc">pc</code></td>
<td>
<p> Selects perspective-posterior mean and image-error plots
(<code>pc = "pc"</code>, the default) or a double&ndash;image plot (<code>pc
	  = "c"</code>)</p>
</td></tr></table>
<p> (only valid for 2-d plots)
</p>
<table>
<tr><td><code id="plot.tgp_+3A_gridlen">gridlen</code></td>
<td>
<p> Number of regular grid points for 2-d slices and
projections in x and y.  The default of <code>gridlen = c(40,40)</code>
causes a <code>40 * 40</code>
grid of <code>X</code>, <code>Y</code>, and <code>Z</code> values to be computed.
Ignored for 1-d plots and projections</p>
</td></tr>
<tr><td><code id="plot.tgp_+3A_span">span</code></td>
<td>
<p> Span for <code><a href="stats.html#topic+loess">loess</a></code> kernel. 
The <span class="pkg">tgp</span> package default (<code>span =
      0.1</code>) is set lower than the <code><a href="stats.html#topic+loess">loess</a></code> default.
Smaller spans can lead to warnings from <code><a href="stats.html#topic+loess">loess</a></code>
when the data or predictive locations are sparse and ugly plots may
result.  In this case, try increasing the span</p>
</td></tr>
<tr><td><code id="plot.tgp_+3A_pxx">pXX</code></td>
<td>
<p> scalar logical indicating if <code>XX</code> locations should be
plotted </p>
</td></tr>
<tr><td><code id="plot.tgp_+3A_legendloc">legendloc</code></td>
<td>
<p> Location of the <code><a href="graphics.html#topic+legend">legend</a></code> included in the
plots of sensitivity analyses produced with <code>layout = "sens"</code>,
or 1-d plots of multi-resolution models (with <code>corr = "mrexpsep"</code>)
and option <code>mrlayout = "both"</code>; otherwise the argument is ignored</p>
</td></tr>
<tr><td><code id="plot.tgp_+3A_maineff">maineff</code></td>
<td>
<p> Format for the plots of sensitivity analyses produced
with <code>layout = "sens"</code>; otherwise the argument is ignored.
If <code>maineff=TRUE</code> main effect plots are produced
alongside boxplots for posterior samples of the sensitivity indices,
and if <code>FALSE</code> only the boxplots are produced.  Alternatively,
<code>maineff</code> can be a matrix containing input dimensions in the
configuration that the corresponding main effects are to be plotted;  
that is, <code>mfrow=dim(maineff)</code>. In this case, a 90 percent
interval is plotted with each main effect and the sensitivity index
boxplots are not plotted.</p>
</td></tr>
<tr><td><code id="plot.tgp_+3A_mrlayout">mrlayout</code></td>
<td>
<p> The plot layout for double resolution
tgp objects with <code>params$corr == "mrexpsep"</code>.  For the default
<code>mrlayout="both"</code>, the coarse and fine fidelity are plotted
together, either on the same plot for 1D inputs or through
side-by-side image plots of the predicted <code>center</code> with axis
determined by <code>proj</code> for inputs of greater dimension.  
Note that many of the standard arguments &ndash; such as <code>slice</code>,
<code>pc</code>, and <code>map</code> &ndash;  are either non-applicable or
unsupported for <code>mrlayout="both"</code>. If <code>mrlayout="coarse"</code>
or <code>mrlayout="fine"</code>, prediction for the respective fidelity is 
plotted as usual and all of the standard options apply.</p>
</td></tr>
<tr><td><code id="plot.tgp_+3A_rankmax">rankmax</code></td>
<td>
<p> When <code>as = "improv"</code> is provided, the posterior
expected improvements are plotted according the the first column
of the <code>improv</code> field of the <code>"tgp"</code>-class object.
Text is added to the plot near the <code>XX</code> positions of the first
<code>1:rankmax</code> predictive locations with the highest ranks in the
second column of the <code>improv</code> field. </p>
</td></tr>
<tr><td><code id="plot.tgp_+3A_...">...</code></td>
<td>
<p> Extra arguments to 1-d (<code><a href="graphics.html#topic+plot">plot</a></code>) and 2-d plotting
functions <code>persp</code> and <code>image</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>The only output of this function is beautiful plots
</p>


<h3>Note</h3>

<p> 	This plotting function is provided with the intention that it 
will be used as an aid in the visualization of <code>"tgp"</code>-class
objects.  Users are encouraged to use the source code for 
this function in order to develop custom plotting functions.
</p>
<p>1-d projections for 3-d or higher data are also available
by specifying a 1-d projection argument (e.g. <code>proj=c(1)</code>
for projecting onto the first input variable).
</p>
<p>For examples, see  <code>vignette("tgp")</code> and the 
help files of those functions in &quot;See Also&quot;, below
</p>


<h3>Author(s)</h3>

 
<p>Robert B. Gramacy, <a href="mailto:rbg@vt.edu">rbg@vt.edu</a>, and
Matt Taddy, <a href="mailto:mataddy@amazon.com">mataddy@amazon.com</a>
</p>


<h3>References</h3>

<p><a href="https://bobby.gramacy.com/r_packages/tgp/">https://bobby.gramacy.com/r_packages/tgp/</a>
</p>


<h3>See Also</h3>

 <p><code><a href="graphics.html#topic+plot">plot</a></code>, <code><a href="#topic+bgpllm">bgpllm</a></code>, <code><a href="#topic+btlm">btlm</a></code>, 
<code><a href="#topic+blm">blm</a></code>, <code><a href="#topic+bgp">bgp</a></code>, <code><a href="#topic+btgpllm">btgpllm</a></code>,
<code><a href="#topic+predict.tgp">predict.tgp</a></code>,
<code><a href="#topic+tgp.trees">tgp.trees</a></code>, <code><a href="#topic+mapT">mapT</a></code>, <code><a href="stats.html#topic+loess">loess</a></code>, <code><a href="#topic+sens">sens</a></code></p>

<hr>
<h2 id='predict.tgp'> Predict method for Treed Gaussian process models </h2><span id='topic+predict.tgp'></span>

<h3>Description</h3>

<p>This generic prediction method was designed to obtain samples
from the posterior predictive distribution after the <code>b*</code>
functions have finished.  Samples, or kriging mean and variance
estimates, can be obtained from the MAP model encoded in the
<code>"tgp"</code>-class object, or this parameterization can be used
as a jumping-off point in obtaining further samples from the
joint posterior and posterior predictive distributions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tgp'
predict(object, XX = NULL, BTE = c(0, 1, 1), R = 1,
            MAP = TRUE, pred.n = TRUE, krige = TRUE, zcov = FALSE,
            Ds2x = FALSE, improv = FALSE, sens.p = NULL, trace = FALSE,
            verb = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.tgp_+3A_object">object</code></td>
<td>
 <p><code>"tgp"</code>-class object that is the output of one of
the <code>b*</code> functions: <code><a href="#topic+blm">blm</a></code>, <code><a href="#topic+btlm">btlm</a></code>
<code><a href="#topic+bgp">bgp</a></code>, <code><a href="#topic+bgpllm">bgpllm</a></code>, <code><a href="#topic+btgp">btgp</a></code>, or 
<code><a href="#topic+btgpllm">btgpllm</a></code></p>
</td></tr>
<tr><td><code id="predict.tgp_+3A_xx">XX</code></td>
<td>
<p> Optional <code>data.frame</code>, <code>matrix</code>,
or vector of predictive input locations 
with <code>ncol(XX) == ncol(object$X)</code></p>
</td></tr>
<tr><td><code id="predict.tgp_+3A_bte">BTE</code></td>
<td>
<p> 3-vector of Monte-carlo parameters (B)urn in, (T)otal, and
(E)very. Predictive samples are saved every E MCMC rounds starting
at round B, stopping at T. The default <code>BTE=c(0,1,1)</code> is
specified to give the kriging means and variances as outputs, plus
one sample from the posterior predictive distribution</p>
</td></tr>
<tr><td><code id="predict.tgp_+3A_r">R</code></td>
<td>
<p> Number of repeats or restarts of <code>BTE</code> MCMC rounds,
default <code>R=1</code> is no restarts</p>
</td></tr>
<tr><td><code id="predict.tgp_+3A_map">MAP</code></td>
<td>
<p> When <code>TRUE</code> (default) predictive data (i.e.,
kriging mean and variance estimates, and samples from the
posterior predictive distribution) are obtained for the
<em>fixed</em> MAP model encoded in <code>object</code>.  Otherwise,
when <code>MAP=FALSE</code> sampling from the joint posterior
of the model parameters (i.e., tree and GPs) and the posterior
predictive distribution are obtained starting from the MAP model and
proceeding just as the <code>b*</code> functions</p>
</td></tr>
<tr><td><code id="predict.tgp_+3A_pred.n">pred.n</code></td>
<td>
<p><code>TRUE</code> (default) value results in prediction at
the inputs <code>X</code>; <code>FALSE</code> 
skips prediction at <code>X</code> resulting in a faster
implementation</p>
</td></tr>
<tr><td><code id="predict.tgp_+3A_krige">krige</code></td>
<td>
<p><code>TRUE</code> (default) value results in collection of
kriging means and variances at predictive (and/or data)
locations; <code>FALSE</code> skips the gathering of kriging statistics
giving a savings in storage</p>
</td></tr>
<tr><td><code id="predict.tgp_+3A_zcov">zcov</code></td>
<td>
<p>If <code>TRUE</code> then the predictive covariance matrix is
calculated&ndash; can be computationally (and memory) intensive if
<code>X</code> or <code>XX</code> is large.  Otherwise only the variances
(diagonal of covariance matrices) are calculated (default).  See
outputs <code>Zp.s2</code>, <code>ZZ.s2</code>, etc., below</p>
</td></tr>
<tr><td><code id="predict.tgp_+3A_ds2x">Ds2x</code></td>
<td>
<p><code>TRUE</code> results in ALC (Active Learning&ndash;Cohn)
computation of expected reduction in uncertainty calculations at the
<code>X</code> locations, which can be used for adaptive sampling;
<code>FALSE</code> (default) skips this computation, resulting in
a faster implementation</p>
</td></tr>
<tr><td><code id="predict.tgp_+3A_improv">improv</code></td>
<td>
<p><code>TRUE</code> results in samples from the
improvement at locations <code>XX</code> with respect to the observed
data minimum. These samples are used to calculate the expected
improvement over <code>XX</code>, as well as to rank all of the points in
<code>XX</code> in the order that they should be sampled to minimize the
expected multivariate improvement (refer to Schonlau et al, 1998).
Alternatively, <code>improv</code> can be set to any positive integer 'g',
in which case the ranking is performed with respect to the expectation
for improvement raised to the power 'g'. Increasing 'g' leads to
rankings that are more oriented towards a global optimization.
The option <code>FALSE</code> (default) skips these computations,
resulting in a faster implementation.  Optionally, a two-vector
can be supplied where <code>improv[2]</code> is interpreted as the 
(maximum) number of points to rank by improvement.  
See the note in <code><a href="#topic+btgp">btgp</a></code> documentation.
If not specified, then the larger of 10% of <code>nn = nrow(XX)</code> 
and <code>min(10, nn)</code> is taken by default </p>
</td></tr>
<tr><td><code id="predict.tgp_+3A_sens.p">sens.p</code></td>
<td>
<p> Either <code>NULL</code> or a vector of parameters for
sensitivity analysis, built by the function <code><a href="#topic+sens">sens</a></code>.
Refer there for details</p>
</td></tr>
<tr><td><code id="predict.tgp_+3A_trace">trace</code></td>
<td>
 <p><code>TRUE</code> results in a saving of samples from the
posterior distribution for most of the parameters in the model.  The
default is <code>FALSE</code> for speed/storage reasons. See note below </p>
</td></tr>
<tr><td><code id="predict.tgp_+3A_verb">verb</code></td>
<td>
<p> Level of verbosity of R-console print statements: from 0
(default: none); 1 which shows the &ldquo;progress meter&rdquo;; 2
includes an echo of initialization parameters; up to 3 and 4 (max)
with more info about successful tree operations</p>
</td></tr>
<tr><td><code id="predict.tgp_+3A_...">...</code></td>
<td>
<p> Ellipses are not used in the current version
of <code>predict.tgp</code>.  They are are only included in order to 
maintain S3 generic/method consistency </p>
</td></tr>
</table>


<h3>Details</h3>

<p>While this function was designed with prediction in mind, it is
actually far more general.  It allows a continuation of
MCMC sampling where the <code>b*</code> function left off (when
<code>MAP=FALSE</code>) with a possibly new set of predictive locations
<code>XX</code>.  The intended use of this function is to obtain quick
kriging-style predictions for a previously-fit MAP estimate
(contained in a <code>"tgp"</code>-class object)
on a new set of predictive locations <code>XX</code>.  However,
it can also be used simply to extend the search for an MAP model
when <code>MAP=FALSE</code>, <code>pred.n=FALSE</code>, and <code>XX=NULL</code>
</p>


<h3>Value</h3>

<p>The output is the same, or a subset of, the output produced
by the <code>b*</code> functions, for example see <code><a href="#topic+btgp">btgp</a></code>
</p>


<h3>Note</h3>

<p>It is important to note that this function is not a replacement
for supplying <code>XX</code> to the <code>b*</code> functions, which is the only
way to get fully Bayesian samples from the posterior prediction
at new inputs.  It is only intended as a post-analysis (diagnostic)
tool.
</p>
<p>Inputs <code>XX</code> containing <code>NaN, NA</code>, or <code>Inf</code> are
discarded with non-fatal warnings.  Upon execution, MCMC reports are
made every 1,000 rounds to indicate progress.
</p>
<p>If <code>XX</code>s are provided which fall outside the range of <code>X</code>
inputs provided to the original <code>b*</code> function, then those will
not be extrapolated properly, due to the way that bounding rectangles
are defined in the original run.  For a workaround, supply
<code>out$Xsplit &lt;- rbind(X, XX)</code> before running <code>predict</code> on
<code>out</code>.
</p>
<p>See note for <code><a href="#topic+btgp">btgp</a></code> or another <code>b*</code> function
regarding the handling and appropriate specification of <code>traces</code>.
</p>
<p>The <code>"tgp"</code> class output produced by <code>predict.tgp</code> can
also be used as input to <code>predict.tgp</code>, as well as others (e.g.,
<code><a href="#topic+plot.tgp">plot.tgp</a></code>.
</p>


<h3>Author(s)</h3>

 
<p>Robert B. Gramacy, <a href="mailto:rbg@vt.edu">rbg@vt.edu</a>, and
Matt Taddy, <a href="mailto:mataddy@amazon.com">mataddy@amazon.com</a>
</p>


<h3>References</h3>

<p><a href="https://bobby.gramacy.com/r_packages/tgp/">https://bobby.gramacy.com/r_packages/tgp/</a>
</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+predict">predict</a></code>, <code><a href="#topic+blm">blm</a></code>, <code><a href="#topic+btlm">btlm</a></code>,
<code><a href="#topic+bgp">bgp</a></code>, <code><a href="#topic+btgp">btgp</a></code>, <code><a href="#topic+bgpllm">bgpllm</a></code>,
<code><a href="#topic+btgpllm">btgpllm</a></code>, <code><a href="#topic+plot.tgp">plot.tgp</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
## revisit the Motorcycle data
require(MASS)

## fit a btgpllm without predictive sampling (for speed)
out &lt;- btgpllm(X=mcycle[,1], Z=mcycle[,2], bprior="b0", 
	       pred.n=FALSE)
## nothing to plot here because there is no predictive data

## save the "tgp" class output object for use later and
save(out, file="out.Rsave")

## then remove it (for illustrative purposes)
out &lt;- NULL

## (now imagine emailing the out.Rsave file to a friend who
## then performs the following in order to use your fitted
## tgp model on his/her own predictive locations)

## load in the "tgp" class object we just saved
load("out.Rsave")

## new predictive locations
XX &lt;- seq(2.4, 56.7, length=200)

## now obtain kriging estimates from the MAP model
out.kp &lt;- predict(out, XX=XX, pred.n=FALSE)
plot(out.kp, center="km", as="ks2")

## actually obtain predictive samples from the MAP
out.p &lt;- predict(out, XX=XX, pred.n=FALSE, BTE=c(0,1000,1))
plot(out.p)

## use the MAP as a jumping-off point for more sampling
out2 &lt;- predict(out, XX, pred.n=FALSE, BTE=c(0,2000,2),
                MAP=FALSE, verb=1)
plot(out2)

## (generally you would not want to remove the file)
unlink("out.Rsave")

</code></pre>

<hr>
<h2 id='sens'>Monte Carlo Bayesian Sensitivity Analysis</h2><span id='topic+sens'></span>

<h3>Description</h3>

<p>Fully Bayesian Monte Carlo sensitivity analysis scheme,
based upon any of the regression models contained in the <span class="pkg">tgp</span>
package.  Random Latin hypercube samples are drawn at each MCMC
iteration in order to estimate main effects as well as 1st order
and total sensitivity indices.</p>


<h3>Usage</h3>

<pre><code class='language-R'>sens(X, Z, nn.lhs, model = btgp, ngrid = 100, span = 0.3,
     BTE = c(3000,8000,10), rect = NULL, shape = NULL, mode = NULL,
     ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sens_+3A_x">X</code></td>
<td>
<p><code>data.frame</code>, <code>matrix</code>, or vector of inputs <code>X</code> </p>
</td></tr>
<tr><td><code id="sens_+3A_z">Z</code></td>
<td>
<p> Vector of output responses <code>Z</code> of length equal to the
leading dimension (rows) of <code>X</code>, i.e., <code>length(Z) ==
      nrow(X)</code></p>
</td></tr>
<tr><td><code id="sens_+3A_nn.lhs">nn.lhs</code></td>
<td>
<p>Size of each Latin hypercube drawn for
use in the Monte Carlo integration scheme. Total number of locations
for prediction is <code>nn.lhs*(ncol(X)+2)</code></p>
</td></tr>
<tr><td><code id="sens_+3A_model">model</code></td>
<td>
<p>Either the regression model used for prediction, or
<code>NULL</code>.  If <code>model=NULL</code>, then the function just returns
the <code>sens.p</code> vector of parameters to be passed with a
regression model call.  This can be used to perform sensitivity
analysis through the <code><a href="#topic+predict.tgp">predict.tgp</a></code> framework</p>
</td></tr>
<tr><td><code id="sens_+3A_ngrid">ngrid</code></td>
<td>
<p>The number of grid points in each input dimension upon
which main effects will be estimated.</p>
</td></tr>
<tr><td><code id="sens_+3A_span">span</code></td>
<td>
<p>Smoothing parameter for main effects integration:
the fraction of <code>nn.lhs</code> points that will be included
in a moving average window that is used to estimate main effects
at the <code>ngrid</code> locations in each input dimension.</p>
</td></tr>
<tr><td><code id="sens_+3A_bte">BTE</code></td>
<td>
<p> 3-vector of Monte-Carlo parameters (B)urn in, (T)otal, and
(E)very. Predictive samples are saved every E MCMC rounds starting
at round B, stopping at T </p>
</td></tr>
<tr><td><code id="sens_+3A_rect">rect</code></td>
<td>
<p> Rectangle describing the domain of the uncertainty
distribution with respect to which the sensitivity is to be
determined.  This defines the domain from which the LH sample
is to be taken.  The rectangle should be a <code>matrix</code> or
<code>data.frame</code> with <code>ncol(rect) = 2</code>, and number of rows
equal to the dimension of the domain.  For 1-d data, a vector of
length 2 is allowed.  Defaults to the input data range (<code>X</code>).</p>
</td></tr>
<tr><td><code id="sens_+3A_shape">shape</code></td>
<td>
<p> Optional vector of shape parameters for the Beta
distribution. Vector of length equal to the dimension of the domain,
with elements &gt; 1. If specified, the uncertainty distribution
(i.e. the LH sample) is proportional to a joint pdf formed by
independent Beta distributions in each dimension of the domain,
scaled and shifted to have support defined by <code>rect</code>.
Only concave Beta distributions with <code>shape</code> &gt; 1 are
supported. If unspecified, the uncertainty distribution
is uniform over <code>rect</code>. The specification <code>shape[i]=0</code>
instructs <code>sens</code> to treat the i'th dimension as a binary 
variable. In this case, <code>mode[i]</code> is the probability
parameter for a bernoulli uncertainty distribution, and 
we must also have <code>rect[i,]=c(0,1)</code>.  </p>
</td></tr>
<tr><td><code id="sens_+3A_mode">mode</code></td>
<td>
<p> Optional vector of mode values for the Beta
uncertainty distribution. Vector of length equal to the dimension
of the domain, with elements within the support defined by
<code>rect</code>.  If <code>shape</code> is specified, but this is not,
then the scaled Beta distributions will be symmetric. </p>
</td></tr>
<tr><td><code id="sens_+3A_...">...</code></td>
<td>
<p>Extra arguments to the <span class="pkg">tgp</span> <code>model</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Saltelli (2002) describes a Latin Hypercube sampling based method for
estimation of the 'Sobal' sensitivity indices:
</p>
<p>1st Order for input <code class="reqn">i</code>,
</p>
<p style="text-align: center;"><code class="reqn">S(i) = \mbox{Var}(E[f|x_i])/\mbox{Var}(f),</code>
</p>

<p>where <code class="reqn">x_i</code> is the  <code class="reqn">i</code>-th input.
</p>
<p>Total Effect for input <code class="reqn">i</code>,
</p>
<p style="text-align: center;"><code class="reqn">T(i) = E[\mbox{Var}(f|x_{-i})]/\mbox{Var}(f),</code>
</p>

<p>where <code class="reqn">x_{-i}</code> is all inputs except for the <code class="reqn">i</code>-th.
</p>
<p>All moments are with respect to the appropriate marginals of the
uncertainty distribution <code class="reqn">U</code> &ndash; that is, the probability
distribution on the inputs with respect to which sensitivity is being
investigated.
Under this approach, the integrals involved are approximated through
averages over properly chosen samples based on two LH samples
proportional to U. If <code>nn.lhs</code> is the sample size for the
Monte Carlo estimate, this scheme requires <code>nn.lhs*(ncol(X)+2)</code>
function evaluations.
</p>
<p>The <code>sens</code> function implements the method for unknown functions
<code class="reqn">f</code>, through prediction via one of the <span class="pkg">tgp</span> regression
models conditional on an observed set of <code>X</code> locations.
At each MCMC iteration of the <span class="pkg">tgp</span> model fitting,
the <code>nn.lhs*(ncol(X)+2)</code> locations are drawn randomly from the
LHS scheme and realizations of the sensitivity indices are
calculated. Thus we obtain a posterior sample of the indices,
incorporating variability from both the Monte Carlo estimation and
uncertainty about the function output. Since a subset of the
predictive locations are actually an LHS proportional to the
uncertainty distribution, we can also estimate the main effects
through simple non-parametric regression (a moving average).
</p>
<p>Please see <code>vignette("tgp2")</code> for a detailed illustration
</p>


<h3>Value</h3>

<p>The output is a <code>"tgp"</code>-class object.  The details for <code><a href="#topic+btgp">btgp</a></code>
contain a complete description of this output.  The list entry that
is relevance to sensitivity analysis is <code>sens</code>, which itself has entries:
</p>
<table>
<tr><td><code>par</code></td>
<td>
<p> This contains a <code>list</code> of the input parameters used in the
sensitivity analysis, as outlined above.</p>
</td></tr>
<tr><td><code>Xgrid</code></td>
<td>
<p>A <code>matrix</code> containing a grid in each input dimension (by column)
over which the main effects are estimated.</p>
</td></tr>
<tr><td><code>ZZ.mean</code></td>
<td>
<p>A <code>matrix</code>, where each column contains the mean
main effects over the corresponding column of <code>sens.Xgrid</code>.</p>
</td></tr>
<tr><td><code>ZZ.q1</code></td>
<td>
<p>A <code>matrix</code>, where each column contains the 5th percentile
main effects over the corresponding column of <code>sens.Xgrid</code>.</p>
</td></tr>
<tr><td><code>ZZ.q2</code></td>
<td>
<p>A <code>matrix</code>, where each column contains the 5th percentile
main effects over the corresponding column of <code>sens.Xgrid</code>.</p>
</td></tr>
<tr><td><code>S</code></td>
<td>
<p>A <code>matrix</code>, where each column contains the posterior sample
of 1st order sensitivity indices for the corresponding input dimension.</p>
</td></tr>
<tr><td><code>T</code></td>
<td>
<p>A <code>matrix</code>, where each column contains the posterior sample
of total sensitivity indices for the corresponding input dimension.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The quality of sensitivity analysis is dependent on the size of
the LH samples used for integral approximation; as with any Monte
Carlo integration scheme, the sample size (<code>nn.lhs</code>) must
increase with the dimensionality of the problem.  The total
sensitivity indices <code class="reqn">T</code> are forced non-negative,
and if negative values occur it is necessary to increase
<code>nn.lhs</code>. The <code>plot.tgp</code> function replaces negative values with zero
for illustration.
</p>


<h3>Author(s)</h3>

 
<p>Robert B. Gramacy, <a href="mailto:rbg@vt.edu">rbg@vt.edu</a>, and
Matt Taddy, <a href="mailto:mataddy@amazon.com">mataddy@amazon.com</a>
</p>


<h3>References</h3>

 
<p>Gramacy, R. B. (2020) <em>Surrogates: Gaussian Process Modeling,
Design and Optimization for the Applied Sciences</em>. Boca Raton,
Florida: Chapman Hall/CRC.  (See Chapter 8.)
<a href="https://bobby.gramacy.com/surrogates/">https://bobby.gramacy.com/surrogates/</a>
</p>
<p>R.D. Morris, A. Kottas, M. Taddy, R. Furfaro, and B. Ganapol. (2009)
<em>A statistical framework for the sensitivity analysis of radiative
transfer models.</em> IEEE Transactions on Geoscience and Remote Sensing,
to appear.
</p>
<p>Saltelli, A. (2002) 
<em>Making best use of model evaluations to compute sensitivity indices.</em>
Computer Physics Communications, 145, 280-297.
</p>


<h3>See Also</h3>

  <p><code><a href="#topic+btgp">btgp</a></code>, <code><a href="#topic+plot.tgp">plot.tgp</a></code>,
<code><a href="#topic+predict.tgp">predict.tgp</a></code>, <code><a href="#topic+lhs">lhs</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># Take a look at the air quality in New York: Sensitivity of
# ozone levels with respect to solar radiation, wind, and
# temperature. See help(airquality) for details.  
X &lt;- airquality[,2:4]
Z &lt;- airquality$Ozone

# Uncertainty distribution is the default: uniform over range(X)
# There is missing data, which is removed automatically by tgp
# range(X).

s &lt;- suppressWarnings(sens(X=X, Z=Z, nn.lhs=300, model=btgp,
          ngrid=100, span=0.3, BTE=c(5000,10000,10)))

# plot the results
plot(s, layout="sens", ylab="Ozone", main="main effects") 

# plot only the sensitivity indices
plot(s, layout="sens", ylab="Ozone", maineff=FALSE) 

# plot only the main effects, side by side
plot(s, layout="sens", ylab="Ozone", main="", maineff=t(1:3))


# build a 'sens.p' parameter vector for a data-dependent
# informative uncertainty distribution.  For each variable,
# the input distribution will be a scaled Beta with shape=2,
# and mode equal to the data mean
rect &lt;- t(apply(X, 2, range, na.rm=TRUE))
mode &lt;- apply(X , 2, mean, na.rm=TRUE)
shape &lt;- rep(2,3)

# plot a sample from the marginal uncertainty distribution.
Udraw &lt;- lhs(300, rect=rect, mode=mode, shape=shape)
par(mfrow=c(1,3))
for(i in 1:3) hist(Udraw[,i], breaks=15,xlab=names(X)[i]) 

# build sens.p with the 'sens' function.
sens.p &lt;- suppressWarnings(sens(X=X, Z=Z, nn.lhs=300, model=NULL,
               ngrid=100, rect=rect, shape=shape, mode=mode))

# Use predict.tgp to quickly analyze with respect to this new
# uncertainty distribution without re-running the MCMC, then
# plot the results.

s.new &lt;- predict(s, BTE=c(1,1000,1), sens.p=sens.p, verb=1) 
plot(s.new, layout="sens", ylab="Ozone", main="main effects")

</code></pre>

<hr>
<h2 id='tgp-internal'>Internal Treed Gaussian Process Model Functions</h2><span id='topic+tgp'></span><span id='topic+tree2c'></span><span id='topic+tgp.postprocess'></span><span id='topic+print.tgptraces'></span><span id='topic+tgp.read.XX.traces'></span><span id='topic+tgp.read.traces'></span><span id='topic+tgp.cleanup'></span><span id='topic+tgp.choose.as'></span><span id='topic+tgp.choose.center'></span><span id='topic+tgp.check.params'></span><span id='topic+tgp.partition'></span><span id='topic+tgp.get.trees'></span><span id='topic+tgp.plot.tree'></span><span id='topic+tgp.plot.parts.1d'></span><span id='topic+tgp.plot.parts.2d'></span><span id='topic+tgp.plot.slice'></span><span id='topic+tgp.plot.proj'></span><span id='topic+tgp.cands'></span><span id='topic+framify.X'></span><span id='topic+slice.interp'></span><span id='topic+slice.image'></span><span id='topic+slice.image.contour'></span><span id='topic+slice.contour'></span><span id='topic+slice.persp'></span><span id='topic+mean0.range1'></span><span id='topic+undo.mean0.range1'></span><span id='topic+check.matrix'></span><span id='topic+mr.checkrez'></span><span id='topic+check.itemps'></span><span id='topic+check.slice'></span><span id='topic+check.proj'></span><span id='topic+check.sens'></span><span id='topic+getlocs'></span><span id='topic+print.tgp'></span><span id='topic+sens.plot'></span><span id='topic+mr.plot'></span><span id='topic+mr.checkres'></span><span id='topic+layout.torture'></span>

<h3>Description</h3>

<p>Internal Treed Gaussian Process Model functions
</p>


<h3>Details</h3>

<p>These are not to be called by the user (or in some cases are just
waiting for proper documentation to be written :)).
</p>


<h3>References</h3>

<p><a href="https://bobby.gramacy.com/r_packages/tgp/">https://bobby.gramacy.com/r_packages/tgp/</a>
</p>

<hr>
<h2 id='tgp.default.params'> Default Treed Gaussian Process Model Parameters </h2><span id='topic+tgp.default.params'></span>

<h3>Description</h3>

<p>Construct a default list of parameters to the <code>b*</code> 
functions&ndash; the interfaces to treed Gaussian process
modeling
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tgp.default.params(d, meanfn = c("linear", "constant"),
                   corr = c("expsep", "exp", "mrexpsep", "matern", "sim", "twovar"),
                   splitmin = 1, basemax = d, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tgp.default.params_+3A_d">d</code></td>
<td>
<p> number of input dimensions <code>ncol(X)</code></p>
</td></tr>
<tr><td><code id="tgp.default.params_+3A_meanfn">meanfn</code></td>
<td>
<p> A choice of mean function for the process.  When
<code>meanfn = "linear"</code> (default), then we have the process
</p>
<p style="text-align: center;"><code class="reqn">Z = (\mathbf{1}  \;\; \mathbf{X}) \beta + W(\mathbf{X})</code>
</p>

<p>where <code class="reqn">W(\mathbf{X})</code> represents the Gaussian process
part of the model (if present).  Otherwise, when
<code>meanfn = "constant"</code>, then</p>
<p style="text-align: center;"><code class="reqn">Z = \beta_0 + W(\mathbf{X})</code>
</p>
</td></tr>
<tr><td><code id="tgp.default.params_+3A_corr">corr</code></td>
<td>
<p> Gaussian process correlation model. Choose between the isotropic
power exponential family (<code>"exp"</code>) or the separable power exponential 
family (<code>"expsep"</code>, default); the current version also supports 
the isotropic Matern (<code>"matern"</code>) and single-index model
(<code>"sim"</code>) and <code>"twovar"</code> as &ldquo;beta&rdquo;	functionality.  
The option <code>"mrexpsep"</code> uses a multi-resolution GP model, 
a depricated feature in the package
(docs removed)</p>
</td></tr>
<tr><td><code id="tgp.default.params_+3A_splitmin">splitmin</code></td>
<td>
<p> Indicates which column of the inputs <code>X</code> should
be the first to allow splits via treed partitioning.  This is useful
for excluding certain input directions from the partitioning
mechanism</p>
</td></tr>
<tr><td><code id="tgp.default.params_+3A_basemax">basemax</code></td>
<td>
<p> Indicates which column of the inputs <code>X</code> should
be the last be fit under the base model (e.g., LM or GP).  This is useful
for allowing some input directions (e.g., binary indicators) to only
influence the tree partitioning mechanism, and not the base model(s)
at the leaves of the tree</p>
</td></tr>
<tr><td><code id="tgp.default.params_+3A_...">...</code></td>
<td>
<p> These ellipses arguments are interpreted as augmentations
to the prior specification. You may use these to specify
a custom setting of any of default parameters in the output list 
detailed below</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The output is the following list of <code>params</code>...
</p>
<table>
<tr><td><code>col</code></td>
<td>
<p>dimension of regression coefficients <code class="reqn">
	 \beta</code>: 1 for input <code>meanfn = "constant"</code>, or
<code>ncol(X)+1</code> for <code>meanfn = "linear"</code></p>
</td></tr>
<tr><td><code>meanfn</code></td>
<td>
<p> copied from the inputs </p>
</td></tr>
<tr><td><code>corr</code></td>
<td>
<p> copied from the inputs </p>
</td></tr>
<tr><td><code>bprior</code></td>
<td>
<p>Linear (beta) prior, default is <code>"bflat"</code>
which gives an &ldquo;improper&rdquo; prior which can perform badly 
when the signal-to-noise ratio is low.  In these cases the 
&ldquo;proper&rdquo; hierarchical specification <code>"b0"</code>,
<code>"bmzt"</code>, or <code>"bmznot"</code> prior may perform better
</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p><code>rep(0,col)</code> starting values for beta linear parameters</p>
</td></tr>
<tr><td><code>tree</code></td>
<td>
<p><code>c(0.5,2,max(c(10,col+1)),1,d)</code> indicating the tree prior 
process parameters <code class="reqn">\alpha</code>, <code class="reqn">\beta</code>, <em>minpart</em>,
<em>splitmin</em> and <em>basemax</em>:
</p>
<p style="text-align: center;"><code class="reqn">p_{\mbox{\tiny split}}(\eta, \mathcal{T}) =
       \alpha*(1+\eta)^\beta</code>
</p>

<p>with zero probability given to trees
with partitions containing less than <code>nmin</code> data points;
<em>splitmin</em> indicates the first column of <code>X</code> which 
where treed partitioning is allowed; <em>basemax</em> gives the
last column where the base model is used</p>
</td></tr>
<tr><td><code>s2.p</code></td>
<td>
<p><code>c(5,10)</code> <code class="reqn">\sigma^2</code> inverse-gamma prior
parameters <code>c(a0, g0)</code> where <code>g0</code> is rate parameter</p>
</td></tr>
<tr><td><code>tau2.p</code></td>
<td>
<p><code>c(5,10)</code> <code class="reqn">\tau^2</code> inverse-gamma
prior parameters <code>c(a0, g0)</code> where <code>g0</code> is rate parameter</p>
</td></tr>
<tr><td><code>d.p</code></td>
<td>
<p>c(1.0,20.0,10.0,10.0) Mixture of gamma prior parameter (initial values)
for the range parameter(s) <code>c(a1,g1,a2,g2)</code> where <code>g1</code> and
<code>g2</code> are rate parameters.  If
<code>corr="mrexpsep"</code>, then this is a vector of length 8: The
first four parameters remain the same and correspond to the
&quot;coarse&quot; process, and the
second set of four values, which default to <code>c(1,10,1,10)</code>,
are the equivalent prior parameters for the range parameter(s) in the residual &quot;fine&quot; process.</p>
</td></tr>
<tr><td><code>nug.p</code></td>
<td>
<p><code>c(1,1,1,1)</code> Mixture of gamma prior parameter (initial values)
for the nugget parameter <code>c(a1,g1,a2,g2)</code> where <code>g1</code> and
<code>g2</code> are rate parameters; default reduces to simple exponential prior;
specifying <code>nug.p = 0</code> fixes the nugget parameter to the &ldquo;starting&rdquo; 
value in <code>gd[1]</code>, i.e., it is excluded from the MCMC</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>
<p><code>c(10,0.2,10)</code>
LLM parameters c(g, t1, t2), with growth parameter <code>g &gt; 0</code>
minimum parameter <code>t1 &gt;= 0</code> and maximum parameter <code>t1 &gt;= 0</code>, where
<code>t1 + t2 &lt;= 1</code> specifies </p>
<p style="text-align: center;"><code class="reqn">p(b|d)=t_1 +
	  \exp\left\{\frac{-g(t_2-t_1)}{d-0.5}\right\}</code>
</p>
</td></tr>
<tr><td><code>d.lam</code></td>
<td>
<p><code>"fixed"</code> Hierarchical exponential distribution
parameters to <code>a1</code>, <code>g1</code>, <code>a2</code>, and <code>g2</code>
of the prior distribution for the range parameter <code>d.p</code>;
<code>"fixed"</code> indicates that the hierarchical prior is &ldquo;turned off&rdquo;</p>
</td></tr>
<tr><td><code>nug.lam</code></td>
<td>
<p><code>"fixed"</code> Hierarchical exponential
distribution parameters to <code>a1</code>, <code>g1</code>,
<code>a2</code>, and <code>g2</code> of the prior distribution for the nug
parameter <code>nug.p</code>; <code>"fixed"</code> indicates that the
hierarchical prior is &ldquo;turned off&rdquo;</p>
</td></tr>
<tr><td><code>s2.lam</code></td>
<td>
<p><code>c(0.2,10)</code> Hierarchical exponential distribution prior for 
<code>a0</code> and <code>g0</code> of the prior distribution for the s2
parameter <code>s2.p</code>; <code>"fixed"</code> indicates that the
hierarchical prior is &ldquo;turned off&rdquo;</p>
</td></tr>
<tr><td><code>tau2.lam</code></td>
<td>
<p><code>c(0.2,0.1)</code> Hierarchical exponential distribution prior for 
<code>a0</code> and <code>g0</code> of the prior distribution for the s2
parameter <code>tau2.p</code>; <code>"fixed"</code> indicates that the
hierarchical prior is &ldquo;turned off&rdquo;</p>
</td></tr>
<tr><td><code>delta.p</code></td>
<td>
<p><code>c(1,1,1,1)</code>  Parameters in the mixture of gammas prior
on the delta scaling parameter for <code>corr="mrexpsep"</code>:
<code>c(a1,g1,a2,g2)</code> where <code>g1</code> and
<code>g2</code> are rate parameters; default reduces to simple
exponential prior.  Delta scales the variance of the residual &quot;fine&quot; process with respect to
the variance of the underlying &quot;coarse&quot; process. </p>
</td></tr>
<tr><td><code>nugf.p</code></td>
<td>
<p><code>c(1,1,1,1)</code>  Parameters in the mixture of gammas prior
on the residual &ldquo;fine&rdquo; process nugget parameter for
<code>corr="mrexpsep"</code>: <code>c(a1,g1,a2,g2)</code> where <code>g1</code> and
<code>g2</code> are rate parameters; default reduces to simple
exponential prior.</p>
</td></tr>
<tr><td><code>dp.sim</code></td>
<td>
<p><code>basemax * basemax</code> RW-MVN
proposal covariance matrix for GP-SIM models; only appears when
<code>corr="sim"</code>, the default is <code>diag(rep(0.2, basemax))</code></p>
</td></tr>
</table>


<h3>Note</h3>

<p>Please refer to the examples for the functions in
&quot;See Also&quot; below, <code>vignette("tgp")</code> and <code>vignette(tgp2)</code>
</p>


<h3>Author(s)</h3>

 
<p>Robert B. Gramacy, <a href="mailto:rbg@vt.edu">rbg@vt.edu</a>, and
Matt Taddy, <a href="mailto:mataddy@amazon.com">mataddy@amazon.com</a>
</p>


<h3>References</h3>

<p>Gramacy, R. B. (2007). <em><span class="pkg">tgp</span>: An <span class="rlang"><b>R</b></span> Package for
Bayesian Nonstationary, Semiparametric Nonlinear
Regression and Design by Treed Gaussian Process Models.</em>
Journal of Statistical Software, <b>19</b>(9).
<a href="https://www.jstatsoft.org/v19/i09">https://www.jstatsoft.org/v19/i09</a>
<a href="https://doi.org/10.18637/jss.v019.i09">doi:10.18637/jss.v019.i09</a>
</p>
<p>Robert B. Gramacy, Matthew Taddy (2010). <em>Categorical Inputs,
Sensitivity Analysis, Optimization and Importance Tempering with <span class="pkg">tgp</span>
Version 2, an <span class="rlang"><b>R</b></span> Package for Treed Gaussian Process Models.</em>
Journal of Statistical Software, <b>33</b>(6), 1&ndash;48.
<a href="https://www.jstatsoft.org/v33/i06/">https://www.jstatsoft.org/v33/i06/</a>
<a href="https://doi.org/10.18637/jss.v033.i06">doi:10.18637/jss.v033.i06</a>
</p>
<p>Gramacy, R. B., Lee, H. K. H. (2008).
<em>Bayesian treed Gaussian process models with an application
to computer modeling</em>. Journal of the American Statistical Association, 
103(483), pp. 1119-1130.  Also available as ArXiv article 0710.4536 
<a href="https://arxiv.org/abs/0710.4536">https://arxiv.org/abs/0710.4536</a>
</p>
<p>Robert B. Gramacy, Heng Lian (2011).
<em>Gaussian process single-index models as emulators for computer
experiments</em>.  Available as ArXiv article 1009.4241
<a href="https://arxiv.org/abs/1009.4241">https://arxiv.org/abs/1009.4241</a>
</p>
<p><a href="https://bobby.gramacy.com/r_packages/tgp/">https://bobby.gramacy.com/r_packages/tgp/</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+blm">blm</a></code>, <code><a href="#topic+btlm">btlm</a></code>, <code><a href="#topic+bgp">bgp</a></code>,
<code><a href="#topic+btgp">btgp</a></code>, <code><a href="#topic+bgpllm">bgpllm</a></code>, <code><a href="#topic+btgpllm">btgpllm</a></code> </p>

<hr>
<h2 id='tgp.design'> Sequential Treed D-Optimal Design for Treed Gaussian Process Models </h2><span id='topic+tgp.design'></span>

<h3>Description</h3>

<p>Based on the maximum a' posteriori (MAP)
treed partition extracted from a <code>"tgp"</code>-class object,
calculate independent sequential treed D-Optimal designs in each of the regions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tgp.design(howmany, Xcand, out, iter = 5000, verb = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tgp.design_+3A_howmany">howmany</code></td>
<td>
<p>Number of new points in the design. Must
be less than the number of candidates contained in
<code>Xcand</code>, i.e., <code>howmany &lt;= nrow(Xcand)</code></p>
</td></tr>
<tr><td><code id="tgp.design_+3A_xcand">Xcand</code></td>
<td>
 <p><code>data.frame</code>, <code>matrix</code> or vector of candidates 
from which new design points are subsampled.  Must have
<code>nrow(Xcand) == nrow(out$X)</code> </p>
</td></tr>
<tr><td><code id="tgp.design_+3A_out">out</code></td>
<td>
 <p><code>"tgp"</code>-class object output from one of the
model functions which has tree support, e.g., <code><a href="#topic+btgpllm">btgpllm</a></code>,
<code><a href="#topic+btgp">btgp</a></code>, <code><a href="#topic+btlm">btlm</a></code></p>
</td></tr>
<tr><td><code id="tgp.design_+3A_iter">iter</code></td>
<td>
<p>number of iterations of stochastic accent algorithm,
default <code>5000</code></p>
</td></tr>
<tr><td><code id="tgp.design_+3A_verb">verb</code></td>
<td>
<p>positive integer indicating after how many rounds of
stochastic approximation in <code><a href="#topic+dopt.gp">dopt.gp</a></code>
to print each progress statement;
default <code>verb=0</code> results in no printing</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function partitions <code>Xcand</code> and <code>out$X</code> based on
the MAP tree (obtained on <code>"tgp"</code>-class <code>out</code> with
<code><a href="#topic+partition">partition</a></code>) and calls
<code><a href="#topic+dopt.gp">dopt.gp</a></code> in order to obtain a D-optimal design under
independent stationary Gaussian processes models defined in each
region.  The aim is to obtain a design where new points from <code>Xcand</code>
are spaced out relative to themselves, and relative to
the existing locations (<code>out$X</code>) in the region.
The number of new points from each region of the partition is
proportional to the number of candidates <code>Xcand</code> in the region.
</p>


<h3>Value</h3>

<p>Output is a list of <code>data.frame</code>s containing <code>XX</code> design
points for each region of the MAP tree in <code>out</code>
</p>


<h3>Note</h3>

<p>Input <code>Xcand</code> containing <code>NaN, NA, Inf</code> are discarded with non-fatal
warnings
</p>
<p>D-Optimal computation in each region is preceded by a print statement
indicated the number of new locations to be chosen and the number of candidates
in the region.  Other than that, there are no other indicators of progress.
You will have to be patient.
Creating treed sequential D-optimal designs is no speedy task.  At least it 
faster than the non-treed version (see <code><a href="#topic+dopt.gp">dopt.gp</a></code>).
</p>
<p>The example below is also part of <code>vignette("tgp")</code>.
Please see <code>vignette("tgp2")</code> for a similar example based on
optimization using the <code><a href="#topic+optim.step.tgp">optim.step.tgp</a></code> 
</p>


<h3>Author(s)</h3>

 
<p>Robert B. Gramacy, <a href="mailto:rbg@vt.edu">rbg@vt.edu</a>, and
Matt Taddy, <a href="mailto:mataddy@amazon.com">mataddy@amazon.com</a>
</p>


<h3>References</h3>

<p>Gramacy, R. B. (2020) <em>Surrogates: Gaussian Process Modeling,
Design and Optimization for the Applied Sciences</em>. Boca Raton,
Florida: Chapman Hall/CRC.  (See Chapter 9.)
<a href="https://bobby.gramacy.com/surrogates/">https://bobby.gramacy.com/surrogates/</a>
</p>
<p>Gramacy, R. B. (2007). <em><span class="pkg">tgp</span>: An <span class="rlang"><b>R</b></span> Package for Bayesian
Nonstationary, Semiparametric Nonlinear Regression and Design by
Treed Gaussian Process Models.</em> Journal of Statistical Software, <b>19</b>(9).
<a href="https://www.jstatsoft.org/v19/i09">https://www.jstatsoft.org/v19/i09</a>
<a href="https://doi.org/10.18637/jss.v019.i09">doi:10.18637/jss.v019.i09</a>
</p>
<p>Robert B. Gramacy, Matthew Taddy (2010). <em>Categorical Inputs,
Sensitivity Analysis, Optimization and Importance Tempering with <span class="pkg">tgp</span>
Version 2, an <span class="rlang"><b>R</b></span> Package for Treed Gaussian Process Models.</em>
Journal of Statistical Software, <b>33</b>(6), 1&ndash;48.
<a href="https://www.jstatsoft.org/v33/i06/">https://www.jstatsoft.org/v33/i06/</a>
<a href="https://doi.org/10.18637/jss.v033.i06">doi:10.18637/jss.v033.i06</a>
</p>
<p>Gramacy, R. B., Lee, H. K. H. (2006).
<em>Adaptive design and analysis of supercomputer experiments.</em>
Technometrics, 51(2), pp. 130-145.  Also avaliable on ArXiv article 0805.4359
<a href="https://arxiv.org/abs/0805.4359">https://arxiv.org/abs/0805.4359</a>
</p>
<p>Gramacy, R. B., Lee, H. K. H., &amp; Macready, W. (2004).
<em>Parameter space exploration with Gaussian process trees.</em> 
ICML (pp. 353&ndash;360).  Omnipress &amp; ACM Digital Library.
</p>
<p><a href="https://bobby.gramacy.com/r_packages/tgp/">https://bobby.gramacy.com/r_packages/tgp/</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+bgpllm">bgpllm</a></code>, <code><a href="#topic+btlm">btlm</a></code>, <code><a href="#topic+blm">blm</a></code>, 
<code><a href="#topic+bgp">bgp</a></code>, <code><a href="#topic+btgpllm">btgpllm</a></code>, <code><a href="#topic+plot.tgp">plot.tgp</a></code>, 
<code><a href="#topic+dopt.gp">dopt.gp</a></code>, <code><a href="#topic+lhs">lhs</a></code>,
<code><a href="#topic+partition">partition</a></code>, <code><a href="#topic+optim.step.tgp">optim.step.tgp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
#
# 2-d Exponential data
# (This example is based on random data.  
# It might be fun to run it a few times)
#

# get the data
exp2d.data &lt;- exp2d.rand()
X &lt;- exp2d.data$X; Z &lt;- exp2d.data$Z
Xcand &lt;- exp2d.data$XX

# fit treed GP LLM model to data w/o prediction
# basically just to get MAP tree (and plot it)
out &lt;- btgpllm(X=X, Z=Z, pred.n=FALSE, corr="exp")
tgp.trees(out)

# find a treed sequential D-Optimal design 
# with 10 more points.  It is interesting to 
# contrast this design with one obtained via
# the dopt.gp function
XX &lt;- tgp.design(10, Xcand, out)

# now fit the model again in order to assess
# the predictive surface at those new design points
dout &lt;- btgpllm(X=X, Z=Z, XX=XX, corr="exp")
plot(dout)

</code></pre>

<hr>
<h2 id='tgp.trees'> Plot the MAP Tree for each height encountered by the Markov Chain</h2><span id='topic+tgp.trees'></span>

<h3>Description</h3>

<p>Plot the maximum a' posteriori (MAP) tree as a function of
tree height, and show the log posterior probabilities for 
comparison.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tgp.trees(out, heights = NULL, main = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tgp.trees_+3A_out">out</code></td>
<td>
 <p><code>"tgp"</code>-class object which is the output of one
the model functions with tree support (e.g. <code><a href="#topic+btgpllm">btgpllm</a></code>)</p>
</td></tr>
<tr><td><code id="tgp.trees_+3A_heights">heights</code></td>
<td>
<p> Index vector of length less than <code>length(out$trees)</code>
describing trees to plot by their height.  Default (<code>NULL</code>) is to
plot all trees, one for each height encountered when sampling
from the Markov chain of the tree posterior.  This is equivalent to
<code>heights = out$posts$height</code>.  Specifying <code>heights =
	  "map"</code> causes (only) the maximum a' posteriori (MAP) height
tree to be plotted </p>
</td></tr> 
<tr><td><code id="tgp.trees_+3A_main">main</code></td>
<td>
<p> Optional character string to add to the main title of the plot</p>
</td></tr>
<tr><td><code id="tgp.trees_+3A_...">...</code></td>
<td>
<p> Extra arguments to the <code><a href="maptree.html#topic+draw.tree">draw.tree</a></code>
function from <span class="pkg">maptree</span></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The maximum a' posteriori (MAP) tree encountered at each height
(in the MCMC chain) is plotted, and the log posterior probabilities
are shown for comparison.  The text at the branches in the tree show
the splitting variable and value.  The text at the leaves show the
number of input data points (<code>X</code> and <code>Z</code>) that fall
into the region(s) along with an estimate of the variability therein.
</p>


<h3>Value</h3>

<p>The only output of this function is beautiful tree diagrams.
</p>


<h3>Note</h3>

<p> Plotting trees that the <span class="pkg">maptree</span> library is installed, which
itself requires that the <span class="pkg">combinat</span> library also be installed.
</p>
<p>See <code>vignette("tgp")</code> and the examples sections of the functions
under &ldquo;See Also&rdquo;, below</p>


<h3>Author(s)</h3>

 
<p>Robert B. Gramacy, <a href="mailto:rbg@vt.edu">rbg@vt.edu</a>, and
Matt Taddy, <a href="mailto:mataddy@amazon.com">mataddy@amazon.com</a>
</p>


<h3>References</h3>

<p><a href="https://bobby.gramacy.com/r_packages/tgp/">https://bobby.gramacy.com/r_packages/tgp/</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+bgpllm">bgpllm</a></code>, <code><a href="#topic+btlm">btlm</a></code>, <code><a href="#topic+blm">blm</a></code>, 
<code><a href="#topic+bgp">bgp</a></code>, <code><a href="#topic+btgpllm">btgpllm</a></code>,
<code><a href="#topic+plot.tgp">plot.tgp</a></code>, <code><a href="#topic+mapT">mapT</a></code>, <code>vignette("tgp")</code></p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
