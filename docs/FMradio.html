<!DOCTYPE html><html><head><title>Help for package FMradio</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {FMradio}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#FMradio-package'>
<p>Factor modeling for radiomic data</p></a></li>
<li><a href='#autoFMradio'>
<p>Wrapper for automated workflow</p></a></li>
<li><a href='#dimGB'>
<p>Assess the latent dimensionality using Guttman bounds</p></a></li>
<li><a href='#dimIC'>
<p>Assess the latent dimensionality using information criteria</p></a></li>
<li><a href='#dimLRT'>
<p>Assess the latent dimensionality using a likelihood ratio test</p></a></li>
<li><a href='#dimVAR'>
<p>Assessing variances under factor solutions</p></a></li>
<li><a href='#facScore'>
<p>Compute factor scores</p></a></li>
<li><a href='#facSMC'>
<p>Evaluate the determinacy of factor scores</p></a></li>
<li><a href='#FAsim'>
<p>Simulate data according to the common factor analytic model</p></a></li>
<li><a href='#mlFA'>
<p>Maximum likelihood factor analysis</p></a></li>
<li><a href='#radioHeat'>
<p>Visualize a (correlation) matrix as a heatmap</p></a></li>
<li><a href='#regcor'>
<p>Regularized correlation matrix estimation</p></a></li>
<li><a href='#RF'>
<p>Redundancy filtering of a square (correlation) matrix</p></a></li>
<li><a href='#SA'>
<p>Calculate the KMO measure of feature-sampling adequacy</p></a></li>
<li><a href='#SMC'>
<p>Compare squared multiple correlations with model-based communalities</p></a></li>
<li><a href='#subSet'>
<p>Subset a data matrix or expression set</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Factor Modeling for Radiomics Data</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.1</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Carel F.W. Peeters &lt;cf.peeters@vumc.nl&gt;</td>
</tr>
<tr>
<td>Author:</td>
<td>Carel F.W. Peeters [cre, aut], Caroline Ubelhor [ctb], Kevin Kunzmann [ctb]</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions that support stable prediction and classification with radiomics data through factor-analytic modeling. For details, see Peeters et al. (2019) &lt;<a href="https://doi.org/10.48550/arXiv.1903.11696">doi:10.48550/arXiv.1903.11696</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.15.1)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, ggplot2, reshape, Biobase, graphics, expm, MASS</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>true</td>
</tr>
<tr>
<td>KeepSource:</td>
<td>yes</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>BuildManual:</td>
<td>yes</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/CFWP/FMradio">https://github.com/CFWP/FMradio</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-12-16 11:37:10 UTC; cf.peeters</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-12-16 12:10:04 UTC</td>
</tr>
</table>
<hr>
<h2 id='FMradio-package'>
Factor modeling for radiomic data
</h2><span id='topic+FMradio-package'></span><span id='topic+FMradio'></span>

<h3>Description</h3>

<p>The <code>FMradio</code> package provides a workflow that uses factor modeling to project the high-dimensional and collinear radiomic feature-space onto a lower-dimensional orthogonal meta-feature space that retains most of the information contained in the full data set. 
These projected meta-features can be directly used as robust and stable covariates in any downstream
prediction or classification model.
</p>


<h3>Details</h3>

<p>Radiomics refers to the mining of large numbers of quantitative features from standard-of-care
clinical images.
<code>FMradio</code> aims to provide support for stable prediction and classification modeling with radiomics data, irrespective of imaging modality (such as MRI, PET, or CT).
The workflow has 3 main steps that ultimately enable stable prediction and classification.
</p>
<p><b>Step 1: Regularized correlation matrix estimation.</b>
Radiomic data are often high-dimensional in the sense that there are more features than observations.
Moroever, radiomic data are often highly collinear, in the sense that collections of features may be highly correlated (in the absolute sense).
This results in the correlation matrix on the radiomic features to be ill-conditioned or even singular.
It is also this combination of characteristics that proves difficult to predictive modeling.
As the factor-analytic procedure is based on the modeling of moment structures such as the correlation matrix, the first step is to obtain a regularized, well-conditioned estimate of the correlation matrix.
The following functions are then of use:
</p>

<ul>
<li> <p><code><a href="#topic+radioHeat">radioHeat</a></code>
</p>
</li>
<li> <p><code><a href="#topic+RF">RF</a></code>
</p>
</li>
<li> <p><code><a href="#topic+subSet">subSet</a></code>
</p>
</li>
<li> <p><code><a href="#topic+regcor">regcor</a></code>
</p>
</li></ul>

<p>The <code>radioHeat</code> function can be used to visualize (a possibly regularized) correlation matrix as a heatmap.
It can also be used to visually assess feature-redundancy.
The <code>RF</code> function provides functionality for filtering features that are so collinear that they are deemed redundant.
The <code>suBSet</code> function provides functionality to subset data objects to those features retained after possible filtering.
The <code>regcor</code> function subsequently provides a regularized estimate of the correlation matrix (on the possibly filtered feature set).
</p>
<p><b>Step 2: Factor analytic data compression.</b>
The next step would be to project the collinear and high-dimensional radiomic feature-space onto a lower-dimensional orthogonal meta-feature space.
Factor analysis can be used for this purpose.
The following functions are then of use:
</p>

<ul>
<li> <p><code><a href="#topic+SA">SA</a></code>
</p>
</li>
<li> <p><code><a href="#topic+dimGB">dimGB</a></code>
</p>
</li>
<li> <p><code><a href="#topic+dimVAR">dimVAR</a></code>
</p>
</li>
<li> <p><code><a href="#topic+SMC">SMC</a></code>
</p>
</li>
<li> <p><code><a href="#topic+mlFA">mlFA</a></code>
</p>
</li></ul>

<p>The <code>SA</code> function assesses if performing a factor analysis on the (possibly regularized) correlation matrix would be appropriate.
The <code>dimGB</code> function can be used to determine the number of latent factors (i.e., to determine the intrinsic dimensionality of the meta-feature space).
The <code>dimVAR</code> and <code>dimSMC</code> functions can be used to provide additional decision support with respect to the output of the <code>dimGB</code> function.
The <code>mlFA</code> function then performs a maximum likelihood factor analysis using the (possibly regularized) correlation matrix and the choice of intrinsic dimensionality as inputs.
</p>
<p><b>Step 3: Obtaining factor scores.</b>
The third step would be to use the factor analytic solution to obtain factor scores: the score each object/individual would obtain on each of the latent factors.
The following functions are then of use:
</p>

<ul>
<li> <p><code><a href="#topic+facScore">facScore</a></code>
</p>
</li>
<li> <p><code><a href="#topic+facSMC">facSMC</a></code>
</p>
</li></ul>

<p>The <code>facScore</code> function provides several options for computing factors scores.
The determinacy of these scores can be assessed with the <code>facSMC</code> function.
</p>
<p><b>Step 4: Prediction and classification.</b>
The factor scores obtained with Step 3 can be directly used as (low-dimensional and orthogonal) covariates in any prediction, classification or learning procedure.
One may use the full flexibility provided by the CRAN repository for this step.
<br />
<br />
<em>Additional functionality.</em>
The package also provides additional functionality.
These are contained in the following (convenience) functions:
</p>

<ul>
<li> <p><code><a href="#topic+dimLRT">dimLRT</a></code>
</p>
</li>
<li> <p><code><a href="#topic+dimIC">dimIC</a></code>
</p>
</li>
<li> <p><code><a href="#topic+FAsim">FAsim</a></code>
</p>
</li></ul>

<p>The <code>dimLRT</code> and <code>dimIC</code> functions provide alternative options for assessing the number of latent factors using likelihood ratio testing and information criteria, respectively.
These are only recommended when the sample size is large relative to the number of features.
<code>FAsim</code> provides a flexible function for generating data according to the orthogonal common factor analytic model. 
All these functions may be of use in comparative exercises.
The package also provides a wrapper function that automates the 3 main steps of the workflow:
</p>

<ul>
<li> <p><code><a href="#topic+autoFMradio">autoFMradio</a></code>
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Carel F.W. Peeters [cre, aut]<br />
Caroline Ubelhor [ctb]<br />
Kevin Kunzmann [ctb]
<br />
<br />
<em>Maintainer</em>: Carel F.W. Peeters &lt;cf.peeters@vumc.nl&gt;
</p>


<h3>References</h3>

<p>Peeters, C.F.W. <em>et al.</em> (2019). Stable prediction with radiomics data.
<a href="https://arxiv.org/abs/1903.11696">arXiv:1903.11696 [stat.ML]</a>.
</p>

<hr>
<h2 id='autoFMradio'>
Wrapper for automated workflow
</h2><span id='topic+autoFMradio'></span>

<h3>Description</h3>

<p><code>autoFMradio</code> is a wrapper function that automates the three main steps of the <code>FMradio</code> workflow.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>autoFMradio(X, t = .95, fold = 5, GB = 1, type = "thomson",
            verbose = TRUE, printInfo = TRUE, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="autoFMradio_+3A_x">X</code></td>
<td>

<p>A data <code>matrix</code> or an <code>ExpressionSet</code> object. 
</p>
</td></tr>
<tr><td><code id="autoFMradio_+3A_t">t</code></td>
<td>

<p>A scalar <code>numeric</code> indicating the absolute value for thresholding.
</p>
</td></tr>
<tr><td><code id="autoFMradio_+3A_fold">fold</code></td>
<td>

<p>A <code>numeric</code> integer or <code>integer</code> indicating the number of folds to use in cross-validation.
</p>
</td></tr>
<tr><td><code id="autoFMradio_+3A_gb">GB</code></td>
<td>

<p>A <code>numeric</code> integer or <code>integer</code> indicating which Guttman bound to use for determining the number of latent features to retain.<br />
Must be either 1, 2, or 3.
</p>
</td></tr>
<tr><td><code id="autoFMradio_+3A_type">type</code></td>
<td>

<p>A <code>character</code> indicating the type of factor score to calculate.<br />
Must be one of: &quot;thomson&quot;, &quot;bartlett&quot;, &quot;anderson&quot;.
</p>
</td></tr>
<tr><td><code id="autoFMradio_+3A_verbose">verbose</code></td>
<td>

<p>A <code>logical</code> indicating if function should run silently.<br />
Runs silently when <code>verbose = FALSE</code>.
</p>
</td></tr>
<tr><td><code id="autoFMradio_+3A_printinfo">printInfo</code></td>
<td>

<p>A <code>logical</code> indicating if additional information should be printed on-screen.<br />
Suppresses printing when <code>verbose = FALSE</code>.
</p>
</td></tr>
<tr><td><code id="autoFMradio_+3A_seed">seed</code></td>
<td>

<p>A <code>numeric</code> integer or <code>integer</code> indicating the seed for the random number generator.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>autoFMradio</code> function automates the three main steps of the workflow by providing a wrapper around all core functions.
</p>
<p>Step 1 (regularized correlation matrix estimation) is performed using the <code>X</code>, <code>t</code>, and fold arguments.
The raw correlation matrix based on data <code>X</code> is redundancy-filtered using the threshold provided in <code>t</code>.
Subsequently, a regularized estimate of the correlation matrix (on the possibly filtered feature set) is computed with the optimal penalty value determined by cross-validation.
The number of folds is set by the <code>fold</code> argument.
For more information on Step 1 see <code><a href="#topic+RF">RF</a></code>, <code><a href="#topic+subSet">subSet</a></code>, and <code><a href="#topic+regcor">regcor</a></code>.
</p>
<p>Step 2 (factor analytic data compression) is performed using the <code>GB</code> argument.
With this argument one can use either the first, second, or third Guttman bound to select the intrinsic dimensionality of the latent vector.
This bound, together with the regularized correlation matrix, is used in a maximum likelihood factor analysis with simple-structure rotation.
For more information on Step 2, see <code><a href="#topic+dimGB">dimGB</a></code> and <code><a href="#topic+mlFA">mlFA</a></code>.
</p>
<p>Step 3 (obtaining factor scores) is performed using the <code>type</code> argument.
It determines factor scores: the score each object/individual would obtain on each of the latent factors.
The <code>type</code> argument determines the type of factor score that is calculated.
For more information on Step 3, see <code><a href="#topic+facScore">facScore</a></code>.
</p>
<p>When <code>printInfo = TRUE</code> additional information is printed on-screen after the full procedure has run its course. 
This additional information pertains to each of the steps mentioned above.
For Step 1 it reiterates the thresholding value for redundancy filtering and gives the number of features retained after this filtering.
It also reiterates the number of folds used in determining the optimal penalty value as well as this value itself.
Moreover, it provides the value of the Kaiser-Meyer-Olkin index on the optimal regularized correlation matrix estimate (see <code><a href="#topic+SA">SA</a></code>).
For Step 2 it reiterates which Guttman bound was used in determining the number of latent factors as well as the number of latent factors retained.
It also gives the proportion of explained variance under the factor solution of the chosen latent dimension (see <code><a href="#topic+dimVAR">dimVAR</a></code>).
For step 3 it reiterates the type of factor score that was calculated.
Also, it prints the lowest &lsquo;determinacy score&rsquo; amongst the latent factors (see <code><a href="#topic+facSMC">facSMC</a></code>).
</p>
<p>The factor scores in the <code>$Scores</code> slot of the output (see below) can be directly used as input features in any prediction or classification procedure.
In case of external (rather than internal) validation one can use the parameter matrices in the <code>$Loadings</code> and <code>$Uniqueness</code> slots in combination with fresh data to provide a validation factor projection based on the training solution.
See Peeters <em>et al.</em> (2019).
</p>


<h3>Value</h3>

<p>The function returns an object of class <code>list</code>:
</p>
<table>
<tr><td><code>$Scores</code></td>
<td>
<p>An object of class <code>data.frame</code> containing the factor scores. Observations are represented in the rows. Each column represent a latent factor.</p>
</td></tr>
<tr><td><code>$FilteredData</code></td>
<td>
<p>Subsetted data <code>matrix</code> containing only those features retained after redundancy filtering.</p>
</td></tr>
<tr><td><code>$FilteredCor</code></td>
<td>
<p>A correlation <code>matrix</code> based on the data in the <code>$FilteredData</code> slot.</p>
</td></tr>
<tr><td><code>$optPen</code></td>
<td>
<p>A <code>numeric</code> scalar representing the optimal value for the penalty parameter.</p>
</td></tr>
<tr><td><code>$optCor</code></td>
<td>
<p>A <code>matrix</code> representing the regularized correlation matrix under the optimal penalty-value.</p>
</td></tr>
<tr><td><code>$m</code></td>
<td>
<p>An <code>integer</code> correspond to number of latent factors retained under the chosen Guttman bound.</p>
</td></tr>
<tr><td><code>$Loadings</code></td>
<td>
<p>A matrix of class <code>loadings</code> representing the loadings matrix in which in which each element <code class="reqn">\lambda_{jk}</code> is the loading of the <code class="reqn">j</code>th feature on the <code class="reqn">k</code>th latent factor.</p>
</td></tr>
<tr><td><code>$Uniqueness</code></td>
<td>
<p>A <code>matrix</code> representing the diagonal matrix carrying the unique variances.</p>
</td></tr>
<tr><td><code>$Exvariance</code></td>
<td>
<p>A <code>numeric</code> vector representing the cumulative variance for each respective latent feature.</p>
</td></tr>
<tr><td><code>$determinacy</code></td>
<td>
<p>A <code>numeric</code> vector indicating, for each factor, the squared multiple correlation between the observed features and the common latent factor.</p>
</td></tr>
<tr><td><code>$used.seed</code></td>
<td>
<p>A <code>numeric</code> or <code>integer</code> used as the starting seed in random number generation.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>When <code>seed = NULL</code> the starting seed is determined by drawing a single integer from the integers <code>1:9e5</code>. This non-user-supplied seed is also found in the <code>$used.seed</code> slot of the output.
</p>


<h3>Author(s)</h3>

<p>Carel F.W. Peeters &lt;cf.peeters@vumc.nl&gt;
</p>


<h3>References</h3>

<p>Peeters, C.F.W. <em>et al.</em> (2019). Stable prediction with radiomics data.
<a href="https://arxiv.org/abs/1903.11696">arXiv:1903.11696 [stat.ML]</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RF">RF</a></code>, <code><a href="#topic+subSet">subSet</a></code>, <code><a href="#topic+regcor">regcor</a></code>, <code><a href="#topic+dimGB">dimGB</a></code>, <code><a href="#topic+mlFA">mlFA</a></code>, <code><a href="#topic+facScore">facScore</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simulate some data according to a factor model with 3 latent factors
simDAT &lt;- FAsim(p = 24, m = 3, n = 40, loadingvalue = .9)
X &lt;- simDAT$data

## Perform the lot
FullMonty &lt;- autoFMradio(X, GB = 1, seed = 303)
</code></pre>

<hr>
<h2 id='dimGB'>
Assess the latent dimensionality using Guttman bounds
</h2><span id='topic+dimGB'></span>

<h3>Description</h3>

<p><code>dimGB</code> is a function that calculates the first, second, and third Guttman (lower-)bounds to the dimensionality of the latent vector.
These can be used to choose the number of latent factors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dimGB(R, graph = TRUE, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dimGB_+3A_r">R</code></td>
<td>

<p>(Regularized) correlation <code>matrix</code>.
</p>
</td></tr>
<tr><td><code id="dimGB_+3A_graph">graph</code></td>
<td>

<p>A <code>logical</code> indicating if the results should be visualized.
</p>
</td></tr>
<tr><td><code id="dimGB_+3A_verbose">verbose</code></td>
<td>

<p>A <code>logical</code> indicating if the function should run silently.<br />
Runs silently when <code>verbose = FALSE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The communality in factor analysis refers to the amount of variance (of feature <code class="reqn">j</code>) explained by the latent features.
The correlation of any feature with itself can then be decomposed into common variance (the communality) and unique variance.
This implies that unity (1) minus the unique variance for feature <code class="reqn">j</code> equals the communality for feature <code class="reqn">j</code>.
From the matrix perspective one can then construct a reduced correlation matrix: the correlation matrix with communalities in the diagonal.
This reduced correlation matrix is, by the assumptions on the factor model, Gramian and of rank <code class="reqn">m</code>, with <code class="reqn">m</code> indicating the intrinsic dimensionality of the latent vector.
The dimension of the latent vector (i.e., the number of common factors) can then be assessed by evaluating the rank of the sample correlation matrix in which the diagonal elements are replaced with appropriate communality estimates.
</p>
<p>In our case, which is often high-dimensional, we use the regularized correlation matrix as our sample-representation of the population correlation matrix.
The diagonal elements are then replaced with Guttman's lower-bound estimates for the communalities (Guttman, 1956).
Guttman (1956) gives 3 (ordered) lower-bound estimates.
The first estimate is the most conservative, using 0 as a lower-bound estimate of the communalities.
From this perspective, every positive eigenvalue of the reduced sample correlation matrix is indicative of a latent factor whose contribution to variance-explanation is above and beyond mere unique variance. 
The decisonal approach would then be to retain all such factors.
See Peeters <em>et al.</em> (2019) for additional detail.
</p>
<p>The Guttman approach has historically been used as a lower-bound estimate of the latent dimensionality.
We consider the decisional approach stated above to give an upper-bound.
Peeters <em>et al.</em> (2019) contains an extensive simulation study showing that in high-dimensional situations this decisional approach provides a reliable upper-bound.
The choice of the number of factors can be further assessed with the <code><a href="#topic+SMC">SMC</a></code> and <code><a href="#topic+dimVAR">dimVAR</a></code> functions.
Assessments provided by these latter functions may inform if the result of the decisional rule above should be accepted or be treated as an upper-bound.
</p>
<p>When <code>graph = TRUE</code> the Guttman bounds are visualized. 
It plots the consecutive eigenvalues for each of the reduced correlation matrices.
The number of positive eigenvalues for each respective reduced correlation matrix then corresponds to each of the respective Guttman bounds.
The visualization may be of limited value when the feature-dimension gets (very) large.
</p>


<h3>Value</h3>

<p>The function returns an object of class <code>table</code>.
The entries correspond to the first, second, and third Guttman bounds.
</p>


<h3>Note</h3>


<ul>
<li><p> Again, from a historical perspective, the decisional rule would have been used as a lower-bound to the question of the number of latent common factors. In high-dimensional situations we recommend to use it as an upper-bound.
</p>
</li>
<li><p> Other functions for factor analytic dimensionality assessment are <code><a href="#topic+dimIC">dimIC</a></code> and <code><a href="#topic+dimLRT">dimLRT</a></code>. In high-dimensional situations usage of <code>dimGB</code> is recommended over these other functions.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Carel F.W. Peeters &lt;cf.peeters@vumc.nl&gt;
</p>


<h3>References</h3>

<p>Guttman, L. (1956). Best possible systematic estimates of communalities. Psychometrika, 21:273&ndash;285.
</p>
<p>Peeters, C.F.W. <em>et al.</em> (2019). Stable prediction with radiomics data.
<a href="https://arxiv.org/abs/1903.11696">arXiv:1903.11696 [stat.ML]</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SMC">SMC</a></code>, <code><a href="#topic+dimVAR">dimVAR</a></code>, <code><a href="#topic+FAsim">FAsim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simulate some data according to a factor model with 5 latent factors
## $cormatrix gives the correlation matrix on the generated data
simDAT &lt;- FAsim(p = 50, m = 5, n = 100)
simDAT$cormatrix

## Evaluate the Guttman bounds
## First Guttman bound indicates to retain 5 latent factors
GB &lt;- dimGB(simDAT$cormatrix)
print(GB)
</code></pre>

<hr>
<h2 id='dimIC'>
Assess the latent dimensionality using information criteria
</h2><span id='topic+dimIC'></span>

<h3>Description</h3>

<p>A function that calculates either the AIC or the BIC on the factor model.
These can be used to choose the number of latent factors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dimIC(R, n, maxdim, Type = "BIC", graph = TRUE, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dimIC_+3A_r">R</code></td>
<td>

<p>(Regularized) correlation <code>matrix</code>.
</p>
</td></tr>
<tr><td><code id="dimIC_+3A_n">n</code></td>
<td>

<p>A <code>numeric</code> scalar representing the sample size.
</p>
</td></tr>
<tr><td><code id="dimIC_+3A_maxdim">maxdim</code></td>
<td>

<p>A <code>numeric</code> integer or <code>integer</code> indicating the maximum factor dimension to be assessed.
</p>
</td></tr>
<tr><td><code id="dimIC_+3A_type">Type</code></td>
<td>

<p>A <code>character</code> indicating the type of IC to be calculated.<br />
Must be one of: &quot;AIC&quot;, &quot;BIC&quot;.
</p>
</td></tr>
<tr><td><code id="dimIC_+3A_graph">graph</code></td>
<td>

<p>A <code>logical</code> indicating if the results should be visualized.
</p>
</td></tr>
<tr><td><code id="dimIC_+3A_verbose">verbose</code></td>
<td>

<p>A <code>logical</code> indicating if the function should run silently.<br />
Runs silently when <code>verbose = FALSE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Information criteria (IC) are often used in selecting the number of latent factor to retain.
IC aim to balance model fit with model complexity. 
They evaluate (minus 2 times) the maximized value of the (model-dependent) likelihood function weighed with a penalty function that is dependent on the free parameters in the model. 
Different penalizations define the different types of IC.
The strategy would be to determine IC scores for a range of consecutive values of the latent factor dimension.
This function then determines scores for factor solutions ranging from 1 to <code>maxdim</code> latent factors.
The solution with the lowest IC score is deemed optimal.
The function allows for the calculation of either the Akaike information criterion (AIC; Akaike, 1973) or the Bayesian information criterion (BIC; Schwarz, 1978).
Also see the Supplementary Material of Peeters <em>et al.</em> (2019) for additional detail.
</p>
<p>When <code>graph = TRUE</code> the IC scores are visualized. 
The graph plots the IC score against the consecutive dimensions of the factor solution.
</p>


<h3>Value</h3>

<p>The function returns an object of class <code>data.frame</code>.
The first column represents the assessed dimensions running from 1 to <code>maxdim</code>.
The second column represents the corresponding values of the chosen information criterion.
</p>


<h3>Note</h3>


<ul>
<li><p> The argument <code>maxdim</code> cannot exceed the Ledermann-bound (Ledermann, 1937): <code class="reqn">\lfloor [2p + 1 - (8p + 1)^{1/2}]/2\rfloor</code>, where <code class="reqn">p</code> indicates the observed-feature dimension.
Usually, one wants to set <code>maxdim</code> much lower than this bound.
</p>
</li>
<li><p> Other functions for factor analytic dimensionality assessment are <code><a href="#topic+dimGB">dimGB</a></code> and <code><a href="#topic+dimLRT">dimLRT</a></code>. In high-dimensional situations usage of <code><a href="#topic+dimGB">dimGB</a></code> on the regularized correlation matrix is recommended.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Carel F.W. Peeters &lt;cf.peeters@vumc.nl&gt;
</p>


<h3>References</h3>

<p>Akaike, H. (1973). Information theory and an extension of the maximum likelihood principle. In: B. N. Petrov and F. Csaki (Eds.) Second International Symposium on Information Theory, pages 267&ndash;281. Budapest: Akademiai Kaido.
</p>
<p>Ledermann, W. (1937). On the rank of the reduced correlational matrix in multiple factor analysis. Psychometrika, 2:85&ndash;93.
</p>
<p>Peeters, C.F.W. <em>et al.</em> (2019). Stable prediction with radiomics data.
<a href="https://arxiv.org/abs/1903.11696">arXiv:1903.11696 [stat.ML]</a>.
</p>
<p>Schwarz, G.E. (1978). Estimating the dimension of a model. Annals of Statistics, 6:461&ndash;464.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dimGB">dimGB</a></code>, <code><a href="#topic+FAsim">FAsim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simulate some data according to the factor model
## $cormatrix gives the correlation matrix on the generated data
simDAT &lt;- FAsim(p = 50, m = 5, n = 100)
simDAT$cormatrix

## Calculate the AIC for models of factor dimension 1 to 20
AIC &lt;- dimIC(simDAT$cormatrix, n = 100, Type = "AIC", maxdim = 20)
print(AIC)

## Calculate the BIC for models of factor dimension 1 to 20
BIC &lt;- dimIC(simDAT$cormatrix, n = 100, Type = "BIC", maxdim = 20)
print(BIC)
</code></pre>

<hr>
<h2 id='dimLRT'>
Assess the latent dimensionality using a likelihood ratio test
</h2><span id='topic+dimLRT'></span>

<h3>Description</h3>

<p><code>dimLRT</code> is a function that evaluates a likelihood ratio test on the factor model.
It can be used to choose the number of latent factors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dimLRT(R, X, maxdim, rankDOF = TRUE, graph = TRUE, 
       alpha = .05, Bartlett = FALSE, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dimLRT_+3A_r">R</code></td>
<td>

<p>(Regularized) correlation <code>matrix</code>.
</p>
</td></tr>
<tr><td><code id="dimLRT_+3A_x">X</code></td>
<td>

<p>A (possibly centered and scaled and possibly subsetted) data <code>matrix</code>.
</p>
</td></tr>
<tr><td><code id="dimLRT_+3A_maxdim">maxdim</code></td>
<td>

<p>A <code>numeric</code> integer or <code>integer</code> indicating the maximum factor dimension to be assessed.
</p>
</td></tr>
<tr><td><code id="dimLRT_+3A_rankdof">rankDOF</code></td>
<td>

<p>A <code>logical</code> indicating if the degrees of freedom should be based on the rank of the raw correlation matrix.
</p>
</td></tr>
<tr><td><code id="dimLRT_+3A_graph">graph</code></td>
<td>

<p>A <code>logical</code> indicating if the results should be visualized.
</p>
</td></tr>
<tr><td><code id="dimLRT_+3A_alpha">alpha</code></td>
<td>

<p>A <code>numeric</code> scalar representing the alpha level. Only used when <code>graph = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="dimLRT_+3A_bartlett">Bartlett</code></td>
<td>

<p>A <code>logical</code> indicating if the Bartlett correction should be applied.
</p>
</td></tr>
<tr><td><code id="dimLRT_+3A_verbose">verbose</code></td>
<td>

<p>A <code>logical</code> indicating if the function should run silently.<br />
Runs silently when <code>verbose = FALSE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The most formal approach to factor analytic dimensionality assessment is through likelihood ratio (LR) testing.
The basic idea is to test the <code class="reqn">m</code>-factor model against the saturated model.
The corresponding LR criterion then converges, under the standard correlation matrix and corresponding parameter estimates under <code class="reqn">m</code>-factors, to <code class="reqn">(n - 1)</code> times a certain discrepancy function evaluated at the maximum-likelihood-parameters under the <code class="reqn">m</code>-factor model.
This quantity is approximately <code class="reqn">\chi^{2}</code>-distributed under certain regularity conditions (Amemiya &amp; Anderson, 1990).
The general strategy would then be to sequentially test solutions of increasing dimensionality <code class="reqn">m = 1, \ldots, \mbox{maxdim}</code> until the null hypothesis (stating that the <code class="reqn">m</code>-factor model holds) is <em>not</em> rejected at Type-I error level <code>alpha</code>.
</p>
<p>The degrees of freedom for the LRT under the <code class="reqn">m</code>-factor model equals the number of parameters in the saturated model (i.e., the unstructured sample correlation) minus the number of freely estimable parameters in the <code class="reqn">m</code>-factor model.
Note that the general stategy above makes use of asymptotic results.
In our setting, however, the observation dimension (<code class="reqn">n</code>) is usually small relative to the feature dimension (<code class="reqn">p</code>).
Hence, the standard test will in a sense overestimate the degrees of freedom.
One simple option dealing with this observation would be to adapt the degrees of freedom to incorporate the rank deficiency of <code>R</code>.
This road is taken when <code>rankDOF = TRUE</code>.
Bartlett (1950) proposed a correction factor when the sample size is small to make the test statistic behave more <code class="reqn">\chi^{2}</code>-like.
This correction factor is used when <code>Bartlett = TRUE</code>.
</p>
<p>When <code>graph = TRUE</code> the LRT results are visualized. 
The graph plots the LRT <code class="reqn">p</code>-values against the consecutive dimensions of the factor solution.
A horizontal line is plotted at the value provided in the <code>alpha</code> argument.
</p>
<p>Unless the number of observations is much larger than the number of features, the LRT is not recommended for inference in general.
In Peeters <em>et al.</em> (2019) the LRT was assessed in a comparative setting inviolving high-dimensional factor models.
</p>


<h3>Value</h3>

<p>The function returns an object of class <code>data.frame</code>.
The first column represents the assessed dimensions running from 1 to <code>maxdim</code>.
The second column represents the observed values of the LRT statistic.
The third column represents the corresponding <code class="reqn">p</code>-values.
</p>


<h3>Note</h3>


<ul>
<li><p> Note that, for argument <code>X</code>, the observations are expected to be in the rows and the features are expected to be in the columns.
</p>
</li>
<li><p> The argument <code>maxdim</code> cannot exceed the Ledermann-bound (Ledermann, 1937): <code class="reqn">\lfloor [2p + 1 - (8p + 1)^{1/2}]/2\rfloor</code>, where <code class="reqn">p</code> indicates the observed-feature dimension.
Usually, one wants to set <code>maxdim</code> much lower than this bound.
</p>
</li>
<li><p> note that, if <code class="reqn">p &gt; n</code>, then the maximum rank of the raw correlation matrix is <code class="reqn">n - 1</code>. In this case there is an alternative Ledermann-bound when <code>rankDOF = TRUE</code>. The number of information points in the correlation matrix is then given as <code class="reqn">n\times (n-1)/2</code> and this number must exceed <code class="reqn">p\times \mbox{maxdim} + p - (\mbox{maxdim} \times (\mbox{maxdim} - 1))/2</code>, putting more restrictions on <code>maxdim</code>.
</p>
</li>
<li><p> Other functions for factor analytic dimensionality assessment are <code><a href="#topic+dimGB">dimGB</a></code> and <code><a href="#topic+dimIC">dimIC</a></code>. In high-dimensional situations usage of <code><a href="#topic+dimGB">dimGB</a></code> on the regularized correlation matrix is recommended.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Carel F.W. Peeters &lt;cf.peeters@vumc.nl&gt;, Caroline Ubelhor
</p>


<h3>References</h3>

<p>Amemiya, Y., &amp; Anderson, T.W. (1990). Asymptotic chi-square tests for a large class of factor
analysis models. The Annals of Statistics, 18:1453&ndash;1463.
</p>
<p>Bartlett, M.S. (1950). Tests of significance in factor analysis. British Journal of Psychology (Statistics Section), 3:77&ndash;85.
</p>
<p>Ledermann, W. (1937). On the rank of the reduced correlational matrix in multiple factor analysis. Psychometrika, 2:85&ndash;93.
</p>
<p>Peeters, C.F.W. <em>et al.</em> (2019). Stable prediction with radiomics data.
<a href="https://arxiv.org/abs/1903.11696">arXiv:1903.11696 [stat.ML]</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dimGB">dimGB</a></code>, <code><a href="#topic+FAsim">FAsim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simulate some data according to the factor model
## $cormatrix gives the correlation matrix on the generated data
simDAT &lt;- FAsim(p = 50, m = 5, n = 500)
simDAT$cormatrix

## Calculate the LRT for models of factor dimension 1 to 20
LRT &lt;- dimLRT(simDAT$cormatrix, simDAT$data, maxdim = 20, rankDOF = FALSE)
print(LRT)
</code></pre>

<hr>
<h2 id='dimVAR'>
Assessing variances under factor solutions
</h2><span id='topic+dimVAR'></span>

<h3>Description</h3>

<p><code>dimVAR</code> is a support function that assesses the proportion of and cumulative variances for a 
range of factor solutions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dimVAR(R, maxdim, graph = TRUE, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dimVAR_+3A_r">R</code></td>
<td>

<p>(Regularized) correlation <code>matrix</code>.
</p>
</td></tr>
<tr><td><code id="dimVAR_+3A_maxdim">maxdim</code></td>
<td>

<p>A <code>numeric</code> integer or <code>integer</code> indicating the maximum factor dimension to be assessed.
</p>
</td></tr>
<tr><td><code id="dimVAR_+3A_graph">graph</code></td>
<td>

<p>A <code>logical</code> indicating if the results should be visualized.
</p>
</td></tr>
<tr><td><code id="dimVAR_+3A_verbose">verbose</code></td>
<td>

<p>A <code>logical</code> indicating if the function should run silently.<br />
Runs silently when <code>verbose = FALSE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To assess a factor solution under <code class="reqn">m</code> factors one might look at the proportion of explained variance.
The <code>dimVAR</code> function calculates the proportion of variance explained by any factor as well as 
the proportion of variance explained by all factors for each factor solution raging from 1 to <code>maxdim</code>.
Qualitatively, we want the proportion of variance explained by all factors to be appreciable (rules of thumb would say in excess of 70%).
Moreover, one would want the proportion of variance explained by the <code class="reqn">k</code>th factor in relation to the <code class="reqn">(k - 1)</code>th factor to be appreciable and the proportion of variance of the <code class="reqn">(k + 1)</code>th factor in relation to the <code class="reqn">k</code>th factor to be negligible.
</p>
<p>When <code>graph = TRUE</code> also a graph is returned visualizing the total cumulative variance against the dimension of the factor solution.
Hence, it plots the total cumulative variances against the respective factor solutions ranging from 1 to <code>maxdim</code>.
The point at which the graph flattens out is indicative of a formative number of latent factors.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>list</code>.
</p>
<table>
<tr><td><code>$CumVar</code></td>
<td>
<p>Contains a <code>numeric</code> vector with the cumulative variances explained for each factor solution from 1 to <code>maxdim</code>.</p>
</td></tr>
<tr><td><code>$varianceTables</code></td>
<td>
<p>This slot is itself a <code>list</code>. It contains, for each factor solution, a matrix with the sum of squares (SS), proportion variance (PV), and cumulative variance (CV) for each respective latent feature. Say one wants to access the variance table for a solution under 5-factors. Then one can call <code>$varianceTables$`dimension = 5`</code>. Similar calls are made to retrieve the variance table for other factor solutions.</p>
</td></tr>
</table>


<h3>Note</h3>


<ul>
<li><p> The argument <code>maxdim</code> cannot exceed the Ledermann-bound (Ledermann, 1937): <code class="reqn">\lfloor [2p + 1 - (8p + 1)^{1/2}]/2\rfloor</code>, where <code class="reqn">p</code> indicates the observed-feature dimension.
Usually, one wants to set <code>maxdim</code> much lower than this bound.
</p>
</li>
<li><p> The tabulations in the <code>$varianceTables</code> slot are based on unrotated maxmimum likelihood factor solutions. Note that the total cumulative variance does not depend on the choice of (orthogonal) rotation.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Carel F.W. Peeters &lt;cf.peeters@vumc.nl&gt;
</p>


<h3>References</h3>

<p>Ledermann, W. (1937). On the rank of the reduced correlational matrix in multiple factor analysis. Psychometrika, 2:85&ndash;93.
</p>
<p>Peeters, C.F.W. <em>et al.</em> (2019). Stable prediction with radiomics data.
<a href="https://arxiv.org/abs/1903.11696">arXiv:1903.11696 [stat.ML]</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dimGB">dimGB</a></code>, <code><a href="#topic+FAsim">FAsim</a></code>, <code><a href="#topic+mlFA">mlFA</a></code>, <code><a href="#topic+SMC">SMC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simulate some high-dimensional data according to the factor model
simDAT &lt;- FAsim(p = 50, m = 5, n = 40)

## Regularize the correlation matrix
RegR &lt;- regcor(simDAT$data)

## Assess proportion and cumulative variances for a range of factor solutions
## Inspect, for example, the variance table for the 5-factor solution
V &lt;- dimVAR(RegR$optCor, maxdim = 20)
V$varianceTables$`dimension = 5`
</code></pre>

<hr>
<h2 id='facScore'>
Compute factor scores
</h2><span id='topic+facScore'></span>

<h3>Description</h3>

<p><code>facScore</code> is a function that computes factor scores, the score each person/object attains on each latent factor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>facScore(X, LM, UM, type = "thomson")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="facScore_+3A_x">X</code></td>
<td>

<p>A (scaled and possibly subsetted) data <code>matrix</code>.
</p>
</td></tr>
<tr><td><code id="facScore_+3A_lm">LM</code></td>
<td>

<p>A (rotated) loadings <code>matrix</code>. Usually the <code>$Loadings</code>-slot object from the <code><a href="#topic+mlFA">mlFA</a></code> function output.
</p>
</td></tr>
<tr><td><code id="facScore_+3A_um">UM</code></td>
<td>

<p>A diagonal uniquenesses <code>matrix</code>. Usually the <code>$Uniqueness</code>-slot object from the <code><a href="#topic+mlFA">mlFA</a></code> function output.
</p>
</td></tr>
<tr><td><code id="facScore_+3A_type">type</code></td>
<td>

<p>A <code>character</code> indicating the type of factor score to calculate.<br />
Must be one of: &quot;thomson&quot;, &quot;bartlett&quot;, &quot;anderson&quot;.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Once a factor model is fitted one may desire an estimate of the score each object/individual would obtain on each of the latent factors.
Such scores are referred to as factor scores.
The <code>facScore</code> function provides several types of factor score estimates.
The default are Thomson-type scores (Thomson, 1939).
These may be viewed as (empirical) Bayesian-type scores.
Bartlett-type scores (Bartlett, 1937) are unbiased but less efficient in terms of mean-squared error.
Under the orthogonal model the latent factors are orthogonal in
the population and, hence, the Thomson and Bartlett-type factor scores will be near orthogonal
in the sample. 
Anderson and Rubin (1956) constructed an alternative estimator for the factor
scores that enforces their orthogonality in the sample.
</p>


<h3>Value</h3>

<p>The function returns an object of class <code>data.frame</code>.
Observations are represented in the rows.
Each column represent a latent factor.
</p>


<h3>Note</h3>

<p>The input data (argument <code>X</code>) are assumed to be scaled (or at least centered).
The <code>UM</code> matrix is assumed to be positive definite.
The <code>LM</code> matrix is assumed to be of full column rank.
</p>


<h3>Author(s)</h3>

<p>Carel F.W. Peeters &lt;cf.peeters@vumc.nl&gt;
</p>


<h3>References</h3>

<p>Anderson, T.W., &amp; Rubin, H. (1956). Statistical inference in factor analysis. In Proceedings
of the Third Berkeley Symposium on Mathematical Statistics and Probability, volume 5:
Contributions to Econometrics, Industrial Research, and Psychometry, pages 111&ndash;150.
Berkeley, CA: University of California Press.
</p>
<p>Bartlett, M.S. (1937). The statistical conception of mental factors. British Journal of Psychology,
28:97&ndash;104.
</p>
<p>Peeters, C.F.W. <em>et al.</em> (2019). Stable prediction with radiomics data.
<a href="https://arxiv.org/abs/1903.11696">arXiv:1903.11696 [stat.ML]</a>.
</p>
<p>Thomson, G. (1939). The Factorial Analysis of Human Ability. London: University of Londen
Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dimGB">dimGB</a></code>, <code><a href="#topic+mlFA">mlFA</a></code>, <code><a href="#topic+facSMC">facSMC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simulate some data according to a factor model with 5 latent factors
## Simulate high-dimensional situation in the sense that p &gt; n
## $cormatrix gives the correlation matrix on the generated data
simDAT &lt;- FAsim(p = 50, m = 5, n = 40, loadingvalue = .9)
simDAT$cormatrix

## Regularize the correlation matrix
RegR &lt;- regcor(simDAT$data)

## Evaluate the Guttman bounds
## First Guttman bound indicates to retain 5 latent factors
GB &lt;- dimGB(RegR$optCor)
print(GB)

## Produce ML factor solution under 5 factors
## Print loadings structure of this solution
fit &lt;- mlFA(RegR$optCor, 5)
print(fit$Loadings, digits = 2, cutoff = .3, sort = TRUE)

## Obtain factor-scores
scores &lt;- facScore(scale(simDAT$data), fit$Loadings, fit$Uniqueness)
print(scores)
</code></pre>

<hr>
<h2 id='facSMC'>
Evaluate the determinacy of factor scores
</h2><span id='topic+facSMC'></span>

<h3>Description</h3>

<p><code>facSMC</code> is a function with which one may evaluate the determinacy of factor scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>facSMC(R, LM)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="facSMC_+3A_r">R</code></td>
<td>

<p>(Regularized) correlation <code>matrix</code>.
</p>
</td></tr>
<tr><td><code id="facSMC_+3A_lm">LM</code></td>
<td>

<p>A (rotated) loadings <code>matrix</code>. Usually the <code>$Loadings</code>-slot object from the <code><a href="#topic+mlFA">mlFA</a></code> function output.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>facSMC</code> function calculates the squared multiple correlations between the observed features and the common latent factors.
The closer to unity, the lesser the problem of factor-score indeterminacy and the better one is able to uniquely determine the  factor scores.
In practice, a squared multiple correlation equalling or exceeding .9 would be considered adequate.
See Mulaik (2010, Chapter 13) and Peeters <em>et al.</em> (2019, Supplementary Materials) for further details.
</p>


<h3>Value</h3>

<p>The function returns a <code>numeric</code> vector indicating, for each factor, the squared multiple correlation between the observed features and the common latent factor.
</p>


<h3>Note</h3>

<p>Note that the computations assume an orthogonal factor model.
Hence, only orthogonal rotations of the loadings matrix should be used (or no rotation at all).
</p>


<h3>Author(s)</h3>

<p>Carel F.W. Peeters &lt;cf.peeters@vumc.nl&gt;
</p>


<h3>References</h3>

<p>Mulaik, S.A. (2010). Foundations of Factor Analysis. Boca Raton: Chapman &amp; Hall/CRC, 2nd
edition.
</p>
<p>Peeters, C.F.W. <em>et al.</em> (2019). Stable prediction with radiomics data.
<a href="https://arxiv.org/abs/1903.11696">arXiv:1903.11696 [stat.ML]</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+facScore">facScore</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simulate some data according to a factor model with 5 latent factors
## Simulate high-dimensional situation in the sense that p &gt; n
## $cormatrix gives the correlation matrix on the generated data
simDAT &lt;- FAsim(p = 50, m = 5, n = 40, loadingvalue = .9)
simDAT$cormatrix

## Regularize the correlation matrix
RegR &lt;- regcor(simDAT$data)

## Evaluate the Guttman bounds
## First Guttman bound indicates to retain 5 latent factors
GB &lt;- dimGB(RegR$optCor)
print(GB)

## Produce ML factor solution under 5 factors
## Print loadings structure of this solution
fit &lt;- mlFA(RegR$optCor, 5)
print(fit$Loadings, digits = 2, cutoff = .3, sort = TRUE)

## Obtain factor-scores
scores &lt;- facScore(scale(simDAT$data), fit$Loadings, fit$Uniqueness)
print(scores)

## Evaluate determinacy of factor scores
fd &lt;- facSMC(RegR$optCor, fit$Loadings)
print(fd)
</code></pre>

<hr>
<h2 id='FAsim'>
Simulate data according to the common factor analytic model
</h2><span id='topic+FAsim'></span>

<h3>Description</h3>

<p><code>FAsim</code> is a function that enables the simulation of data according to the common factor analytic model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FAsim(p, m, n, simplestructure = TRUE, balanced = TRUE,
      loadingfix = TRUE, loadingnegative = TRUE,
      loadingvalue = .8, loadingvaluelow = .2, numloadings,
      loadinglowerH = .7, loadingupperH = .9, 
      loadinglowerL = .1, loadingupperL = .3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FAsim_+3A_p">p</code></td>
<td>

<p>A <code>numeric</code> integer or <code>integer</code> indicating the number of observed features.
</p>
</td></tr>
<tr><td><code id="FAsim_+3A_m">m</code></td>
<td>

<p>A <code>numeric</code> integer or <code>integer</code> indicating the latent dimension of the factor solution (i.e., the number of factors).
</p>
</td></tr>
<tr><td><code id="FAsim_+3A_n">n</code></td>
<td>

<p>A <code>numeric</code> integer or <code>integer</code> indicating the number of samples.
</p>
</td></tr>
<tr><td><code id="FAsim_+3A_simplestructure">simplestructure</code></td>
<td>

<p>A <code>logical</code> indicating if the generating factor structure should be factorially pure.
</p>
</td></tr>
<tr><td><code id="FAsim_+3A_balanced">balanced</code></td>
<td>

<p>A <code>logical</code> indicating if the high (i.e., qualitatively 'significant') loadings should be divided evenly over the respective factors.
</p>
</td></tr>
<tr><td><code id="FAsim_+3A_loadingfix">loadingfix</code></td>
<td>

<p>A <code>logical</code> indicating if the loadings should have a fixed value.
</p>
</td></tr>
<tr><td><code id="FAsim_+3A_loadingnegative">loadingnegative</code></td>
<td>

<p>A <code>logical</code> indicating if, next to positive, also negative loadings should be present.
</p>
</td></tr>
<tr><td><code id="FAsim_+3A_loadingvalue">loadingvalue</code></td>
<td>

<p>A <code>numeric</code> indicating the value for high (i.e., qualitatively 'significant') loadings. Used when <code>loadingfix = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="FAsim_+3A_loadingvaluelow">loadingvaluelow</code></td>
<td>

<p>A <code>numeric</code> indicating the value for low loadings. Used when <code>loadingfix = TRUE</code> &amp; <code>simplestructure = FALSE</code>.
</p>
</td></tr>
<tr><td><code id="FAsim_+3A_numloadings">numloadings</code></td>
<td>

<p>A <code>numeric</code> vector with length equalling argument <code>m</code>, indicating the number of high (i.e., qualitatively 'significant') loadings per factor.<br /> 
Used when <code>balanced = FALSE</code>.
</p>
</td></tr>
<tr><td><code id="FAsim_+3A_loadinglowerh">loadinglowerH</code></td>
<td>

<p>A <code>numeric</code> indicating the lower-bound of high (i.e., qualitatively 'significant') loadings. Used when <code>loadingfix = FALSE</code>.
</p>
</td></tr>
<tr><td><code id="FAsim_+3A_loadingupperh">loadingupperH</code></td>
<td>

<p>A <code>numeric</code> indicating the upper-bound of high (i.e., qualitatively 'significant') loadings. Used when <code>loadingfix = FALSE</code>.
</p>
</td></tr>
<tr><td><code id="FAsim_+3A_loadinglowerl">loadinglowerL</code></td>
<td>

<p>A <code>numeric</code> indicating the lower-bound of low (i.e., qualitatively 'non-significant') loadings. Used when <code>loadingfix = FALSE</code> &amp; <code>simplestructure = FALSE</code>.
</p>
</td></tr>
<tr><td><code id="FAsim_+3A_loadingupperl">loadingupperL</code></td>
<td>

<p>A <code>numeric</code> indicating the upper-bound of low (i.e., qualitatively 'non-significant') loadings. Used when <code>loadingfix = FALSE</code> &amp; <code>simplestructure = FALSE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>FAsim</code> provides certain flexibility when generating data according to an orthogonal common factor-analytic model.
It can produce data according to, for example, (i) factorially pure loadings structures, (ii) loadings-structures with only positive entries or both positive and negative loadings, (iii) loadings-structures with fixed values or varying values, (iv) balanced and unbalanced loadings-structures.
</p>


<h3>Value</h3>

<p>The function returns an object of class <code>list</code>:
</p>
<table>
<tr><td><code>$data</code></td>
<td>
<p>A standardized data <code>matrix</code> of size <code class="reqn">n \times p</code>.</p>
</td></tr>
<tr><td><code>$loadings</code></td>
<td>
<p>Loadings <code>matrix</code> of size <code class="reqn">p \times m</code> on which the data-generation was based.</p>
</td></tr>
<tr><td><code>$Uniqueness</code></td>
<td>
<p>A <code>numeric</code> vector of size <code class="reqn">p</code> representing the uniquenesses on which the data-generation was based.</p>
</td></tr>
<tr><td><code>$cormatrix</code></td>
<td>
<p>A <code class="reqn">p \times p</code> correlation <code>matrix</code> based on the generated data in slot <code>$data</code>.</p>
</td></tr>
</table>


<h3>Note</h3>


<ul>
<li><p> A uniform distribution is assumed when generating draws between <code>loadinglowerH</code> and <code>loadingupperH</code>.
</p>
</li>
<li><p> A uniform distribution is assumed when generating draws between <code>loadinglowerL</code> and <code>loadingupperL</code>.
</p>
</li>
<li><p> The argument <code>m</code> cannot exceed the Ledermann-bound (Ledermann, 1937): <code class="reqn">\lfloor [2p + 1 - (8p + 1)^{1/2}]/2\rfloor</code>, where <code class="reqn">p</code> indicates the observed-feature dimension.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Carel F.W. Peeters &lt;cf.peeters@vumc.nl&gt;
</p>


<h3>References</h3>

<p>Ledermann, W. (1937). On the rank of the reduced correlational matrix in multiple factor analysis. Psychometrika, 2:85&ndash;93.
</p>
<p>Peeters, C.F.W. <em>et al.</em> (2019). Stable prediction with radiomics data.
<a href="https://arxiv.org/abs/1903.11696">arXiv:1903.11696 [stat.ML]</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dimGB">dimGB</a></code>, <code><a href="#topic+mlFA">mlFA</a></code>, <code><a href="#topic+facScore">facScore</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simulate some data according to a factor model with 3 latent factors
## Balanced and factorially pure loadings structure
simDAT &lt;- FAsim(p = 24, m = 3, n = 40, loadingvalue = .9)
simDAT$loadings

## Simulate some data according to a factor model with 3 latent factors
## Unbalanced and factorially pure loadings structure
simDAT &lt;- FAsim(p = 24, m = 3, n = 40, loadingvalue = .9,
                balanced = FALSE, numloadings = c(10,10,4))
simDAT$loadings

## Simulate some data according to a factor model with 3 latent factors
## Unbalanced and factorially non-pure loadings structure
simDAT &lt;- FAsim(p = 24, m = 3, n = 40, loadingvalue = .9,
                balanced = FALSE, numloadings = c(10,10,4),
                simplestructure = FALSE)
simDAT$loadings

## Simulate some data according to a factor model with 3 latent factors
## Unbalanced and factorially non-pure loadings structure
## Non-fixed high and low loadings
simDAT &lt;- FAsim(p = 24, m = 3, n = 40, loadingvalue = .9,
                balanced = FALSE, numloadings = c(10,10,4),
                simplestructure = FALSE, loadingfix = FALSE)
simDAT$loadings
</code></pre>

<hr>
<h2 id='mlFA'>
Maximum likelihood factor analysis
</h2><span id='topic+mlFA'></span>

<h3>Description</h3>

<p><code>mlFA</code> is a function that performs a maximum likelihood factor analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlFA(R, m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlFA_+3A_r">R</code></td>
<td>

<p>(Regularized) correlation <code>matrix</code>.
</p>
</td></tr>
<tr><td><code id="mlFA_+3A_m">m</code></td>
<td>

<p>A <code>numeric</code> integer or <code>integer</code> indicating the latent dimension of the factor solution (i.e., the number of factors).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is basically a wrapper around the 
<a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/factanal.html">factanal</a> function from the <a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/stats-package.html">stats</a> package.
Its purpose is to produce a factor solution of the chosen dimension (argument <code>m</code>) by a maximum likelihood estimation procedure (Joreskog, 1967).
The wrapper ensures that the model is fitted under the same circumstances under which latent dimensionality is assessed with functions such as <code><a href="#topic+dimLRT">dimLRT</a></code> and <code><a href="#topic+dimIC">dimIC</a></code>.
The function produces a Varimax rotated (Kaiser, 1958) factor solution.
The output can be used to produce factor scores by the <code><a href="#topic+facScore">facScore</a></code> function.
</p>


<h3>Value</h3>

<p>The function returns an object of class <code>list</code>:
</p>
<table>
<tr><td><code>$Loadings</code></td>
<td>
<p>A matrix of class <code>loadings</code> representing the loadings matrix in which in which each element <code class="reqn">\lambda_{jk}</code> is the loading of the <code class="reqn">j</code>th feature on the <code class="reqn">k</code>th latent factor.</p>
</td></tr>
<tr><td><code>$Uniqueness</code></td>
<td>
<p>A <code>matrix</code> representing the diagonal matrix carrying the unique variances.</p>
</td></tr>
<tr><td><code>$rotmatrix</code></td>
<td>
<p>A <code>matrix</code> representing the Varimax rotation matrix.</p>
</td></tr>
</table>


<h3>Note</h3>


<ul>
<li><p> Note that the order of the features in the <code>$Loadings</code> and <code>$Uniqueness</code> slots of the output is determined by the order of the features for the input argument <code>R</code>. As the <code>$Loadings</code> slot gives an object of class &quot;loadings&quot; it can be subjected to the <code>print</code> function, which sorts the output to emphasize the loadings structure when calling <code>sort = TRUE</code>.
</p>
</li>
<li><p> Note that the maximum likelihood procedure is stable when a regularized correlation matrix is used as the input for argument <code>R</code>.
</p>
</li>
<li><p> In high-dimensional situations usage of <code><a href="#topic+dimGB">dimGB</a></code> on the regularized correlation matrix is recommended to determine the value for argument <code>m</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Carel F.W. Peeters &lt;cf.peeters@vumc.nl&gt;
</p>


<h3>References</h3>

<p>Joreskog, K.G (1967). Some contributions to maximum likelihood factor analysis. Psychometrika,
32:443&ndash;482.
</p>
<p>Kaiser, H.F. (1958). The varimax criterion for analytic rotation in factor analysis. Psychometrika,
23:187&ndash;200.
</p>
<p>Peeters, C.F.W. <em>et al.</em> (2019). Stable prediction with radiomics data.
<a href="https://arxiv.org/abs/1903.11696">arXiv:1903.11696 [stat.ML]</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dimGB">dimGB</a></code>, <code><a href="#topic+facScore">facScore</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simulate some data according to a factor model with 5 latent factors
## Simulate high-dimensional situation in the sense that p &gt; n
## $cormatrix gives the correlation matrix on the generated data
simDAT &lt;- FAsim(p = 50, m = 5, n = 40, loadingvalue = .9)
simDAT$cormatrix

## Regularize the correlation matrix
RegR &lt;- regcor(simDAT$data)

## Evaluate the Guttman bounds
## First Guttman bound indicates to retain 5 latent factors
GB &lt;- dimGB(RegR$optCor)
print(GB)

## Produce ML factor solution under 5 factors
## Print loadings structure of this solution
fit &lt;- mlFA(RegR$optCor, 5)
print(fit$Loadings, digits = 2, cutoff = .3, sort = TRUE)
</code></pre>

<hr>
<h2 id='radioHeat'>
Visualize a (correlation) matrix as a heatmap
</h2><span id='topic+radioHeat'></span>

<h3>Description</h3>

<p><code>radioHeat</code> is a function that provides dedicated heatmapping of a radiomics-based correlation matrix
It can be used to visually assess the elements of a (possibly thresholded) matrix.
It also supports the assessment of collinearity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>radioHeat(R, lowColor = "blue", highColor = "red", labelsize = 10,
          diag = TRUE, threshold = FALSE, threshvalue = .95,
          values = FALSE, textsize = 10, legend = TRUE, main = "")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="radioHeat_+3A_r">R</code></td>
<td>

<p>(regularized) correlation <code>matrix</code>
</p>
</td></tr>
<tr><td><code id="radioHeat_+3A_lowcolor">lowColor</code></td>
<td>

<p>A <code>character</code> that determines the color scale in the negative range.
</p>
</td></tr>
<tr><td><code id="radioHeat_+3A_highcolor">highColor</code></td>
<td>

<p>A <code>character</code> that determines the color scale in the positive range.
</p>
</td></tr>
<tr><td><code id="radioHeat_+3A_labelsize">labelsize</code></td>
<td>

<p>A <code>numeric</code> that sets the textsize of row and column labels.
</p>
</td></tr>
<tr><td><code id="radioHeat_+3A_diag">diag</code></td>
<td>

<p>A <code>logical</code> determining if the diagonal elements of the matrix should be included in the
color scaling. 
This argument is only used when <code>R</code> is a square <code>matrix</code>.
</p>
</td></tr>
<tr><td><code id="radioHeat_+3A_threshold">threshold</code></td>
<td>

<p>A <code>logical</code> determining if only values above a certain (absolute) threshold should be
visualized. 
</p>
</td></tr>
<tr><td><code id="radioHeat_+3A_threshvalue">threshvalue</code></td>
<td>

<p>A <code>numeric</code> indicating the absolute thresholding value when <code>threshold = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="radioHeat_+3A_values">values</code></td>
<td>

<p>A <code>logical</code> determining the optional inclusion of cell-values.
</p>
</td></tr>
<tr><td><code id="radioHeat_+3A_textsize">textsize</code></td>
<td>

<p>A <code>numeric</code> indicating the textsize of the cell-values when <code>values = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="radioHeat_+3A_legend">legend</code></td>
<td>

<p>A <code>logical</code> indicating whether a color legend should be included.
</p>
</td></tr>
<tr><td><code id="radioHeat_+3A_main">main</code></td>
<td>

<p>A <code>character</code> giving the main figure title.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function utilizes <a href="https://cran.r-project.org/package=ggplot2">ggplot2</a> (Wickham, 2009) to visualize a matrix as a heatmap: a false color plot in which the individual matrix entries are represented by colors. 
<code>lowColor</code> determines the color scale for matrix entries in the negative range.
<code>highColor</code> determines the color scale for matrix entries in the positive range. 
For the colors supported by the arguments <code>lowColor</code> and <code>highColor</code>, see <a href="https://stat.columbia.edu/~tzheng/files/Rcolor.pdf">https://stat.columbia.edu/~tzheng/files/Rcolor.pdf</a>. 
White entries in the plot represent the midscale value of 0. 
One can opt to set the diagonal entries to the midscale color of white when one is interested in (heatmapping) the off-diagonal elements only. 
To achieve this, set <code>diag = FALSE</code>. 
Naturally, the <code>diag</code> argument is only used when the input matrix <code>M</code> is a square matrix.
</p>
<p>The intended usage is to visualize a correlation matrix on radiomic features as a heatmap.
Such a heatmap may be used to support the assessment of strong collinearity or even redundancy amongst the features.
To this end, it is also possible to visualize a thresholded correlation matrix when <code>threshold = TRUE</code> based on the absolute thresholding value given in the <code>threshvalue</code> argument (hence the thresholding is done internally).
This enables easier visual access to (blocks of) collinearity in radiomic-feature-based correlation matrices. 
</p>


<h3>Note</h3>


<ul>
<li><p> While geared towards the visualization of correlation matrices, the function is quite general, in the sense that it can represent any <code>matrix</code> as a heatmap.
</p>
</li>
<li><p> When <code>values = TRUE</code> and <code>threshold = TRUE</code> the cell-values are those of the thresholded matrix.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Carel F.W. Peeters &lt;cf.peeters@vumc.nl&gt;
</p>


<h3>References</h3>

<p>Wickham, H. (2009). ggplot2: elegant graphics for data analysis. New York: Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RF">RF</a></code>, <code><a href="#topic+regcor">regcor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate some (high-dimensional) data
p = 25
n = 10
set.seed(333)
X = matrix(rnorm(n*p), nrow = n, ncol = p)
colnames(X)[1:25] = letters[1:25]
R &lt;- cor(X)

## Visualize the correlation matrix as a heatmap
radioHeat(R)

## Remove diagonal entries from visualization
radioHeat(R, diag = FALSE)

## Additionally, visualize only those entries whose absolute value exceed .5
radioHeat(R, diag = FALSE, threshold = TRUE, threshvalue = .5)

## Additionally, include cell values
radioHeat(R, diag = FALSE, threshold = TRUE, threshvalue = .5, 
          values = TRUE, textsize = 3)
</code></pre>

<hr>
<h2 id='regcor'>
Regularized correlation matrix estimation
</h2><span id='topic+regcor'></span>

<h3>Description</h3>

<p><code>regcor</code> is a function that determines the optimal penalty value and, subsequently, the optimal Ledoit-Wolf type regularized correlation matrix using K-fold cross validation of the negative log-likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regcor(X, fold = 5, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regcor_+3A_x">X</code></td>
<td>

<p>A (possibly centered and scaled and possibly subsetted) data <code>matrix</code>.
</p>
</td></tr>
<tr><td><code id="regcor_+3A_fold">fold</code></td>
<td>

<p>A <code>numeric</code> integer or <code>integer</code> indicating the number of folds to use in cross-validation.
</p>
</td></tr>
<tr><td><code id="regcor_+3A_verbose">verbose</code></td>
<td>

<p>A <code>logical</code> indicating if function should run silently.<br />
Runs silently when <code>verbose = FALSE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function estimates a Ledoit-Wolf-type (Ledoit &amp; Wolf, 2004) regularized correlation matrix.
The optimal penalty-value is determined internally by <em>K</em>-fold cross-validation of the of the negative log-likelihood function.
The procedure is efficient as it makes use of the Brent root-finding procedure (Brent, 1971).
The value at which the <em>K</em>-fold cross-validated negative log-likelihood score is minimized is deemed optimal. 
The function employs the Brent algorithm as implemented in the <a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/optim.html">optim</a> function.
It outputs the optimal value for the penalty parameter and the regularized correlation matrix under this optimal penalty value.
See Peeters <em>et al.</em> (2019) for further details.
</p>
<p>The optimal penalty-value can be used to assess the conditioning of the estimated regularized correlation matrix using, for example, a condition number plot (Peeters, van de Wiel, van Wieringen, 2016). 
The regularized correlation matrix under the optimal penalty can serve as the input to functions that assess factorability (<code><a href="#topic+SA">SA</a></code>), evaluate optimal choices of the latent common factor dimensionality (e.g., <code><a href="#topic+dimGB">dimGB</a></code>), and perform maximum likelihood factor analysis (<code><a href="#topic+mlFA">mlFA</a></code>).
</p>


<h3>Value</h3>

<p>The function returns an object of class <code>list</code>:
</p>
<table>
<tr><td><code>$optPen</code></td>
<td>
<p>A <code>numeric</code> scalar representing the optimal value for the penalty parameter.</p>
</td></tr>
<tr><td><code>$optCor</code></td>
<td>
<p>A <code>matrix</code> representing the regularized correlation matrix under the optimal penalty-value.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Note that, for argument <code>X</code>, the observations are expected to be in the rows and the features are expected to be in the columns.
</p>


<h3>Author(s)</h3>

<p>Carel F.W. Peeters &lt;cf.peeters@vumc.nl&gt;
</p>


<h3>References</h3>

<p>Brent, R.P. (1971). An Algorithm with Guaranteed Convergence for Finding a Zero of a Function. Computer Journal 14: 422&ndash;425.
</p>
<p>Ledoit, O, &amp; Wolf, M. (2004). A well-conditioned estimator for large-dimensional covariance matrices. Journal of Multivariate Analysis, 88:365&ndash;411.
</p>
<p>Peeters, C.F.W. <em>et al.</em> (2019). Stable prediction with radiomics data.
<a href="https://arxiv.org/abs/1903.11696">arXiv:1903.11696 [stat.ML]</a>.
</p>
<p>Peeters, C.F.W., van de Wiel, M.A., &amp; van Wieringen, W.N. (2016). The spectral condition number plot for regularization parameter determination, arXiv:1608.04123v1 [stat.CO].
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RF">RF</a></code>, <code><a href="#topic+subSet">subSet</a></code>, <code><a href="#topic+SA">SA</a></code>, <code><a href="#topic+dimGB">dimGB</a></code>, <code><a href="#topic+mlFA">mlFA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate some (high-dimensional) data
## Get correlation matrix
p = 25
n = 10
set.seed(333)
X = matrix(rnorm(n*p), nrow = n, ncol = p)
colnames(X)[1:25] = letters[1:25]
R &lt;- cor(X)

## Redundancy visualization, at threshold value .9
radioHeat(R, diag = FALSE, threshold = TRUE, threshvalue = .9)

## Redundancy-filtering of correlation matrix
Rfilter &lt;- RF(R, t = .9)
dim(Rfilter)

## Subsetting data
DataSubset &lt;- subSet(X, Rfilter)
dim(DataSubset)

## Obtain regularized correlation matrix
RegR &lt;- regcor(DataSubset, fold = 5, verbose = TRUE)
RegR$optPen  ## optimal penalty-value
</code></pre>

<hr>
<h2 id='RF'>
Redundancy filtering of a square (correlation) matrix
</h2><span id='topic+RF'></span>

<h3>Description</h3>

<p><code>RF</code> is a function that performs redundancy filtering (RF) of a square (correlation) matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RF(R, t = .95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RF_+3A_r">R</code></td>
<td>

<p>Square (correlation) <code>matrix</code>.
</p>
</td></tr>
<tr><td><code id="RF_+3A_t">t</code></td>
<td>

<p>A scalar <code>numeric</code> indicating the absolute value for thresholding.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Radiomic features can be very strongly correlated.
The sample correlation matrix on extracted radiomic features will then often display strong collinearity.
The collinearity may be so strong as to imply redundant information, in the sense that some entries will approach perfect (negative) correlation. 
Hence, one may wish to perform redundancy-filtering on the raw sample correlation matrix in such situations.
</p>
<p>The <code>RF</code> function uses an Algorithm from Peeters <em>et al.</em> (2019) to remove the minimal number of redundant features under absolute marginal correlation threshold <code>t</code>.
We recommend setting <code class="reqn">\mathrm{t} \in [.9,.95]</code>.
Details of the algorithm can be found in Peeters <em>et al.</em> (2019).
</p>
<p>The function returns a redundancy-filtered correlation <code>matrix</code>.
This return output may subsequently be used in the <code><a href="#topic+subSet">subSet</a></code> function.
This is a convenience function that subsets a dataset to the features retained after redundancy-filtering.
</p>


<h3>Value</h3>

<p>Returns a redundancy-filtered <code>matrix</code>.
</p>


<h3>Note</h3>


<ul>
<li><p> While geared towards the redundancy filtering of correlation matrices, the function is quite general, in the sense that it can be used to filter any square <code>matrix</code>.
</p>
</li>
<li><p> When the input matrix <code>R</code> is a correlation matrix, then argument <code>t</code> should satisfy <code class="reqn">-1 &lt; \mathrm{t} &lt; 1</code>, for the return matrix to be sensical for further analysis.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Carel F.W. Peeters &lt;cf.peeters@vumc.nl&gt;
</p>


<h3>References</h3>

<p>Peeters, C.F.W. <em>et al.</em> (2019). Stable prediction with radiomics data.
<a href="https://arxiv.org/abs/1903.11696">arXiv:1903.11696 [stat.ML]</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+subSet">subSet</a></code>, <code><a href="#topic+regcor">regcor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate some (high-dimensional) data
## Get correlation matrix
p = 25
n = 10
set.seed(333)
X = matrix(rnorm(n*p), nrow = n, ncol = p)
colnames(X)[1:25] = letters[1:25]
R &lt;- cor(X)

## Redundancy visualization, at threshold value .9
radioHeat(R, diag = FALSE, threshold = TRUE, threshvalue = .9)

## Redundancy-filtering of correlation matrix
Rfilter &lt;- RF(R, t = .9)
dim(Rfilter)
</code></pre>

<hr>
<h2 id='SA'>
Calculate the KMO measure of feature-sampling adequacy
</h2><span id='topic+SA'></span>

<h3>Description</h3>

<p><code>SA</code> is a function that calculates the Kaiser-Meyer-Olkin (KMO) measure of sampling adequacy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SA(R)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SA_+3A_r">R</code></td>
<td>

<p>(Regularized) covariance or correlation <code>matrix</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>SA</code> function calculates the Kaiser-Meyer-Olkin (KMO) measure of feature-sampling adequacy (Kaiser &amp; Rice, 1974).
It provides a practical option for the assessment of factorability.
Factorability refers to the assessment of the ability to identify coherent common latent factors from a given correlation matrix.
In common factor analysis the observed features are assumed to be independent <em>given</em> the common latent features.
Under this crucial model assumption, the inverse of the population correlation matrix is diagonal.
Hence, to assess factorability one could assess if the inverse of the sample correlation matrix is near-diagonal.
The KMO index provides for such an assessment by &quot;comparing the sizes of the off-diagonal entries of the regularized correlation matrix to the sizes of the off-diagonal entries of its scaled inverse&quot; (Peeters <em>et al.</em>, 2019). 
It takes values in <code class="reqn">[0,1]</code> and larger values are preferred.
A KMO index between .9 and 1 would be considered to be indicative of great factorability.
For rules of thumb regarding interpretation of KMO index value, see Kaiser (1970).
The <code>SA</code> function calculates an overall KMO index as well as the KMO index per observed feature.
</p>
<p>The intended usage of the <code>SA</code> function is to assess if performing a factor analysis on a given (regularized) correlation matrix can be considered appropriate. As such, it succeeds usage of the <code><a href="#topic+regcor">regcor</a></code> function (for high-dimensional and/or strongly collinear settings) and precedes 
usage of the <code><a href="#topic+dimGB">dimGB</a></code> and <code><a href="#topic+mlFA">mlFA</a></code> functions.
</p>


<h3>Value</h3>

<p>The function returns an object of class <code>list</code>:
</p>
<table>
<tr><td><code>$KMO</code></td>
<td>
<p>A <code>numeric</code> scalar representing the overall KMO index.</p>
</td></tr>
<tr><td><code>$KMOfeature</code></td>
<td>
<p>A <code>numeric</code> vector giving the KMO index per feature.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The input <code>matrix</code> <code>R</code> should be nonsingular for the KMO to be computed.
When <code>R</code> is singular one may regularize it using the <code><a href="#topic+regcor">regcor</a></code> function.
</p>


<h3>Author(s)</h3>

<p>Carel F.W. Peeters &lt;cf.peeters@vumc.nl&gt;
</p>


<h3>References</h3>

<p>Kaiser, H.F. (1970). A second-generation little jiffy. Psychometrika, 35:401&ndash;415.
</p>
<p>Kaiser, H.F., &amp; Rice., J. (1974). Little jiffy, mark IV. Educational and Pscyhological Measurement,
34:111&ndash;117.
</p>
<p>Peeters, C.F.W. <em>et al.</em> (2019). Stable prediction with radiomics data.
<a href="https://arxiv.org/abs/1903.11696">arXiv:1903.11696 [stat.ML]</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+regcor">regcor</a></code>, <code><a href="#topic+dimGB">dimGB</a></code>, <code><a href="#topic+mlFA">mlFA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate some (high-dimensional) data
p = 25
n = 10
set.seed(333)
X = matrix(rnorm(n*p), nrow = n, ncol = p)
colnames(X)[1:25] = letters[1:25]

## Obtain regularized correlation matrix
RegR &lt;- regcor(X, fold = 5, verbose = TRUE)

## Assess factorability through the KMO index
factorable &lt;- SA(RegR$optCor)
factorable$KMO
factorable$KMOfeature
</code></pre>

<hr>
<h2 id='SMC'>
Compare squared multiple correlations with model-based communalities
</h2><span id='topic+SMC'></span>

<h3>Description</h3>

<p><code>SMC</code> is a function that compares the best lower-bound estimates to the communalities with the model-based communalities implied by a factor solution of dimension <code class="reqn">m</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SMC(R, LM)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SMC_+3A_r">R</code></td>
<td>

<p>(Regularized) correlation <code>matrix</code>.
</p>
</td></tr>
<tr><td><code id="SMC_+3A_lm">LM</code></td>
<td>

<p>(Rotated) factor loadings <code>matrix</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function can be used to qualitatively assess the choice of dimensionality (as well as the fit) in the <code class="reqn">m</code>-factor model.
This is done using the concept of communalities.
The communality refers to the amount of variance of feature <code class="reqn">j</code> explained by the latent features.
It is then of interest to compare lower-bound estimates of the (population) communalities to the extracted communalities under the <code class="reqn">m</code>-factor model.
</p>
<p>Guttman (1956) gave the best possible lower-bound estimates to the communalities, which can essentially be considered squared multiple correlations: the proportion of variance in feature <code class="reqn">j</code> that is explained by the remaining <code class="reqn">p - 1</code> features.
To assess a factor model, these might be compared to the retrieved estimated communalities under the <code class="reqn">m</code>-factor model.
When the chosen latent dimensionality is sufficient then one would expect that, for almost all features, the retrieved communality approximately equals or exceeds its corresponding lower-bound estimate.
If this is not the case then one might have extracted too few factors.
</p>


<h3>Value</h3>

<p>The function returns a <code>matrix</code>.
The first column (labeled 'SMC') contains the lower-bound estimates to the communalities.
The second column (labeled 'Communalities') contains the retrieved estimated communalities under the <code class="reqn">m</code>-factor model.
</p>


<h3>Note</h3>

<p>Note that the choice of orthogonal rotation does not affect the model-implied communality estimates.
</p>


<h3>Author(s)</h3>

<p>Carel F.W. Peeters &lt;cf.peeters@vumc.nl&gt;
</p>


<h3>References</h3>

<p>Guttman, L. (1956). Best possible systematic estimates of communalities. Psychometrika, 21:273&ndash;285.
</p>
<p>Peeters, C.F.W. <em>et al.</em> (2019). Stable prediction with radiomics data.
<a href="https://arxiv.org/abs/1903.11696">arXiv:1903.11696 [stat.ML]</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dimGB">dimGB</a></code>, <code><a href="#topic+FAsim">FAsim</a></code>, <code><a href="#topic+mlFA">mlFA</a></code>, <code><a href="#topic+dimVAR">dimVAR</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simulate some high-dimensional data according to the factor model
simDAT &lt;- FAsim(p = 50, m = 5, n = 40)

## Regularize the correlation matrix
RegR &lt;- regcor(simDAT$data)

## Fit 5-factor model to the regularized correlation matrix
fit &lt;- mlFA(RegR$optCor, m = 5)

## Compare lower-bound estimates to communalities with model-implied ones
C &lt;- SMC(RegR$optCor, fit$Loadings)
print(C)
</code></pre>

<hr>
<h2 id='subSet'>
Subset a data matrix or expression set
</h2><span id='topic+subSet'></span>

<h3>Description</h3>

<p><code>subSet</code> is a convenience function that subsets a data <code>matrix</code> or an <code>ExpressionSet</code> object. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>subSet(X, Rf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subSet_+3A_x">X</code></td>
<td>

<p>A data <code>matrix</code> or an <code>ExpressionSet</code> object. 
</p>
</td></tr>
<tr><td><code id="subSet_+3A_rf">Rf</code></td>
<td>

<p>A filtered (correlation) <code>matrix</code> (as returned by the <code><a href="#topic+RF">RF</a></code> function).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>subSet</code> convenience function may directly follow usage of the <code><a href="#topic+RF">RF</a></code> in the sense that the latters return-value can be used as the <code>Rf</code> argument.
It then subsets a data <code>matrix</code> or an <code>ExpressionSet</code> object to those features retained by the redundancy-filtering.
The function returns a subsetted <code>matrix</code> or <code>ExpressionSet</code> (depending on the class of the <code>X</code> argument).
The subsetted data can then be used for penalty-parameter selection and regularized correlation matrix estimation provided by the <code><a href="#topic+regcor">regcor</a></code> function.
</p>


<h3>Value</h3>

<p>Returns a subsetted data <code>matrix</code> or <code>ExpressionSet</code>.
</p>


<h3>Note</h3>

<p>If argument <code>X</code> is a <code>matrix</code>, the observations are expected to be in the rows and the features are expected to be in the columns.
</p>


<h3>Author(s)</h3>

<p>Carel F.W. Peeters &lt;cf.peeters@vumc.nl&gt;
</p>


<h3>References</h3>

<p>Peeters, C.F.W. <em>et al.</em> (2019). Stable prediction with radiomics data.
<a href="https://arxiv.org/abs/1903.11696">arXiv:1903.11696 [stat.ML]</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+regcor">regcor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate some (high-dimensional) data
## Get correlation matrix
p = 25
n = 10
set.seed(333)
X = matrix(rnorm(n*p), nrow = n, ncol = p)
colnames(X)[1:25] = letters[1:25]
R &lt;- cor(X)

## Redundancy visualization, at threshold value .9
radioHeat(R, diag = FALSE, threshold = TRUE, threshvalue = .9)

## Redundancy-filtering of correlation matrix
Rfilter &lt;- RF(R, t = .9)
dim(Rfilter)

## Subsetting data
DataSubset &lt;- subSet(X, Rfilter)
dim(DataSubset)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
