<!DOCTYPE html><html lang="en"><head><title>Help for package RcmdrPlugin.temis</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {RcmdrPlugin.temis}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#caTools'><p>Correspondence analysis helper functions</p></a></li>
<li><a href='#cooccurrentTerms'><p>Show terms co-occurrences</p></a></li>
<li><a href='#corpusCaDlg'><p>Correspondence analysis from a tm corpus</p></a></li>
<li><a href='#corpusClustDlg'><p>Hierarchical clustering of a tm corpus</p></a></li>
<li><a href='#corpusDissimilarity'><p>Cross-Dissimilarity Table</p></a></li>
<li><a href='#createClustersDlg'><p>Cut hierarchical clustering tree into clusters</p></a></li>
<li><a href='#dissimilarityTableDlg'><p>Documents/Variables Dissimilarity Table</p></a></li>
<li><a href='#freqTermsDlg'><p>List most frequent terms of a corpus</p></a></li>
<li><a href='#frequentTerms'><p>List most frequent terms of a corpus</p></a></li>
<li><a href='#GDf-class'><p>Class <code>"GDf"</code></p></a></li>
<li><a href='#importCorpusDlg'><p>Import a corpus and process it</p></a></li>
<li><a href='#inspectCorpus'><p>Inspect corpus</p></a></li>
<li><a href='#output'><p>Output results to HTML file</p></a></li>
<li><a href='#plotCorpusCa'><p>Plotting 2D maps in correspondence analysis of corpus</p></a></li>
<li><a href='#recodeTimeVarDlg'><p>Recode Date/Time Variable</p></a></li>
<li><a href='#restrictTermsDlg'><p>Select or exclude terms</p></a></li>
<li><a href='#runCorpusCa'><p>Correspondence analysis from a tm corpus</p></a></li>
<li><a href='#setCorpusVariables'><p>Set corpus variables</p></a></li>
<li><a href='#setLastTable'><p>Save the name of last table and give a title</p></a></li>
<li><a href='#showCorpusCaDlg'><p>Show a correspondence analysis from a tm corpus</p></a></li>
<li><a href='#specificTerms'><p>List terms specific of a document or level</p></a></li>
<li><a href='#specificTermsDlg'><p>List terms specific of a document or level</p></a></li>
<li><a href='#subsetCorpusByTermsDlg'><p>Subset Corpus by Terms</p></a></li>
<li><a href='#subsetCorpusByVarDlg'><p>Subset Corpus by Levels of a Variable</p></a></li>
<li><a href='#termCoocDlg'><p>Show co-occurrent terms</p></a></li>
<li><a href='#termFreqDlg'><p>Term frequencies in the corpus</p></a></li>
<li><a href='#termFrequencies'><p>Frequency of chosen terms in the corpus</p></a></li>
<li><a href='#termsDictionary'><p>Dictionary of terms found in a corpus</p></a></li>
<li><a href='#termTimeSeriesDlg'><p>Temporal Evolution of Occurrences</p></a></li>
<li><a href='#varCrossTableDlg'><p>Two-way table of corpus meta-data variables</p></a></li>
<li><a href='#varTableDlg'><p>One-way table of a corpus meta-data variable</p></a></li>
<li><a href='#varTimeSeriesDlg'><p>Corpus Temporal Evolution</p></a></li>
<li><a href='#vocabularyDlg'><p>Vocabulary Summary</p></a></li>
<li><a href='#vocabularyTable'><p>Vocabulary summary table</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Graphical Integrated Text Mining Solution</td>
</tr>
<tr>
<td>Version:</td>
<td>0.7.10</td>
</tr>
<tr>
<td>Date:</td>
<td>2018-06-22</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcmdr (&ge; 2.1-1), tcltk, tcltk2, utils, ca, R2HTML (&ge; 2.3.0),
RColorBrewer, latticeExtra, stringi</td>
</tr>
<tr>
<td>Depends:</td>
<td>methods, tm (&ge; 0.6), NLP, slam, zoo, lattice</td>
</tr>
<tr>
<td>Suggests:</td>
<td>SnowballC, ROpenOffice, RODBC, tm.plugin.factiva (&ge; 1.4),
tm.plugin.lexisnexis (&ge; 1.1), tm.plugin.europresse (&ge; 1.1),
tm.plugin.alceste (&ge; 1.1), twitteR</td>
</tr>
<tr>
<td>Additional_repositories:</td>
<td><a href="http://www.omegahat.net/R">http://www.omegahat.net/R</a></td>
</tr>
<tr>
<td>Description:</td>
<td>An 'R Commander' plug-in providing an integrated solution to perform
    a series of text mining tasks such as importing and cleaning a corpus, and
    analyses like terms and documents counts, vocabulary tables, terms
    co-occurrences and documents similarity measures, time series analysis,
    correspondence analysis and hierarchical clustering. Corpora can be imported
    from spreadsheet-like files, directories of raw text files, 'Twitter' queries,
    as well as from 'Dow Jones Factiva', 'LexisNexis', 'Europresse' and 'Alceste' files.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/nalimilan/R.TeMiS">https://github.com/nalimilan/R.TeMiS</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/nalimilan/R.TeMiS/issues">https://github.com/nalimilan/R.TeMiS/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-06-22 12:08:42 UTC; milan</td>
</tr>
<tr>
<td>Author:</td>
<td>Milan Bouchet-Valat [aut, cre],
  Gilles Bastin [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Milan Bouchet-Valat &lt;nalimilan@club.fr&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-06-22 13:51:28 UTC</td>
</tr>
</table>
<hr>
<h2 id='caTools'>Correspondence analysis helper functions</h2><span id='topic+rowSubsetCa'></span><span id='topic+colSubsetCa'></span><span id='topic+rowCtr'></span><span id='topic+colCtr'></span>

<h3>Description</h3>

<p>Restrict a correspondence analysis object to some rows or columns, and get row and
column contributions.</p>


<h3>Usage</h3>

<pre><code class='language-R'>rowSubsetCa(obj, indices)
colSubsetCa(obj, indices)
rowCtr(obj, dim)
colCtr(obj, dim)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="caTools_+3A_obj">obj</code></td>
<td>
<p>A correspondence analysis object as returned by <code>link{ca}</code>.</p>
</td></tr>
<tr><td><code id="caTools_+3A_indices">indices</code></td>
<td>
<p>An integer vector of indices of rows/columns to be kept.</p>
</td></tr>
<tr><td><code id="caTools_+3A_dim">dim</code></td>
<td>
<p>An integer vector of dimensions to which point contributions should be computed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions are used to extend the features of the <code>ca</code> package.
</p>
<p><code>rowSubsetCa</code> and <code>colSubsetCa</code> take a <code>link{ca}</code> object and return it, keeping
only the rows/columns that were specified. These objects are only meant for direct plotting,
as they do not contain the full CA results: using them for detailed analysis would be
misleading.
</p>
<p><code>rowCtr</code> and <code>colCtr</code> return the absolute contributions of all rows/columns to the
specified axes of the CA. If several dimensions are passed, the result is the sum of the
contributions to each axis.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+showCorpusCaDlg">showCorpusCaDlg</a></code>, <code><a href="#topic+plotCorpusCa">plotCorpusCa</a></code>, <code><a href="ca.html#topic+plot.ca">plot.ca</a></code>,
<code><a href="ca.html#topic+ca">ca</a></code></p>

<hr>
<h2 id='cooccurrentTerms'>Show terms co-occurrences</h2><span id='topic+cooccurrentTerms'></span>

<h3>Description</h3>

<p>Show terms that are the most associated with one or several reference terms.</p>


<h3>Usage</h3>

<pre><code class='language-R'>cooccurrentTerms(term, dtm, variable = NULL, p = 0.1, n.max = 25,
                 sparsity = 0.95, min.occ = 2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cooccurrentTerms_+3A_dtm">dtm</code></td>
<td>
<p>A document-term matrix.</p>
</td></tr>
<tr><td><code id="cooccurrentTerms_+3A_term">term</code></td>
<td>
<p>A character vector of length 1 corresponding to the name of a column of <code>dtm</code>.</p>
</td></tr>
<tr><td><code id="cooccurrentTerms_+3A_variable">variable</code></td>
<td>
<p>An optional vector of the same length as the number of rows in <code>dtm</code>, giving
the levels by which results should be reported.</p>
</td></tr>
<tr><td><code id="cooccurrentTerms_+3A_p">p</code></td>
<td>
<p>the maximum probability up to which terms should be reported.</p>
</td></tr>
<tr><td><code id="cooccurrentTerms_+3A_n.max">n.max</code></td>
<td>
<p>the maximum number of terms to report for each level.</p>
</td></tr>
<tr><td><code id="cooccurrentTerms_+3A_sparsity">sparsity</code></td>
<td>
<p>Optional sparsity threshold (between 0 and 1) below which terms should be
skipped. See <code><a href="tm.html#topic+removeSparseTerms">removeSparseTerms</a></code> from tm.</p>
</td></tr>
<tr><td><code id="cooccurrentTerms_+3A_min.occ">min.occ</code></td>
<td>
<p>the minimum number of occurrences in the whole <code>dtm</code> below which
terms should be skipped.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function allows printing the terms that are most associated with one or several
given terms, according to the document-term matrix of the corpus. Co-occurrent terms
are those which are specific to documents which contain the given term(s). The output
is the same as that returned by the &ldquo;Terms specific of levels...&rdquo; dialog
(see <code><a href="#topic+specificTermsDlg">specificTermsDlg</a></code>), using a dummy variable indicating whether the term
is present or not in each document.
</p>
<p>When a variable is selected, the operation is run separately on each sub-matrix constituted
by the documents that are members of the variable level. If the term does not appear in a
level, <code>NA</code> is returned.
</p>


<h3>Value</h3>

<p>The result is either a matrix (when <code>variable = NULL</code>) or a list of matrices,
one for each level of the chosen variable, with seven columns:
</p>

<dl>
<dt>&ldquo;% Term/Cooc.&rdquo;:</dt><dd><p>the percent of the term's occurrences in all terms occurrences
in documents where the chosen term is also present.</p>
</dd>
<dt>&ldquo;% Cooc./Term&rdquo;:</dt><dd><p>the percent of the term's occurrences that appear in documents
where the chosen term is also present (rather than in documents where it does not appear),
i.e. the percent of cooccurrences for the term.</p>
</dd>
<dt>&ldquo;Global %&rdquo; or &ldquo;Level %&rdquo;:</dt><dd><p>the percent of the term's occurrences
in all terms occurrences in the corpus (or in the subset of the corpus
corresponding to the variable level).</p>
</dd>
<dt>&ldquo;Cooc.&rdquo;:</dt><dd><p>the number of cooccurrences of the term.</p>
</dd>
<dt>&ldquo;Global&rdquo; or &ldquo;Level&rdquo;:</dt><dd><p>the number of occurrences of the term in the corpus
(or in the subset of the corpus corresponding to the variable level).</p>
</dd>
<dt>&ldquo;t value&rdquo;:</dt><dd><p>the quantile of a normal distribution corresponding the probability &ldquo;Prob.&rdquo;.</p>
</dd>
<dt>&ldquo;Prob.&rdquo;:</dt><dd><p>the probability of observing such an extreme (high or low) number of occurrences of
the term in documents where the chosen term is also present, under an hypergeometric distribution.</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+termCoocDlg">termCoocDlg</a></code>, <code><a href="#topic+specificTerms">specificTerms</a></code>, <code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>,
<code><a href="#topic+restrictTermsDlg">restrictTermsDlg</a></code>, <code><a href="#topic+termsDictionary">termsDictionary</a></code>, <code><a href="#topic+freqTermsDlg">freqTermsDlg</a></code> </p>

<hr>
<h2 id='corpusCaDlg'>Correspondence analysis from a tm corpus</h2><span id='topic+corpusCaDlg'></span>

<h3>Description</h3>

<p>Compute a simple correspondence analysis on the document-term matrix of a tm corpus.</p>


<h3>Details</h3>

<p>This dialog wraps the <code><a href="#topic+runCorpusCa">runCorpusCa</a></code> function. The function <code>runCorpusCa</code>
runs a correspondence analysis (CA) on the  document-term matrix.
</p>
<p>If no variable is selected in the list (the default), a CA is run on the full document-term
matrix (possibly skipping sparse terms, see below). If one or more variables are chosen,
the CA will be based on a stacked table whose rows correspond to the levels of the variable:
each cell contains the sum of occurrences of a given term in all the documents of the level.
Documents that contain a <code>NA</code> are skipped for this variable, but taken into account for
the others, if any.
</p>
<p>In all cases, variables that have not been selected are added as supplementary rows. If at least one
variable is selected, documents are also supplementary rows, while they are active otherwise.
</p>
<p>The first slider ('sparsity') allows skipping less significant terms to use less memory, especially
with large corpora. The second slider ('dimensions to retain') allows choosing the number of
dimensions that will be printed, but has no effect on the computation of the correspondance analysis.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+runCorpusCa">runCorpusCa</a></code>, <code><a href="ca.html#topic+ca">ca</a></code>, <code><a href="tm.html#topic+meta">meta</a></code>, <code><a href="tm.html#topic+removeSparseTerms">removeSparseTerms</a></code>,
<code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code> </p>

<hr>
<h2 id='corpusClustDlg'>Hierarchical clustering of a tm corpus</h2><span id='topic+corpusClustDlg'></span>

<h3>Description</h3>

<p>Hierarchical clustering of the documents of a tm corpus.</p>


<h3>Details</h3>

<p>This dialog allows creating a tree of the documents present in a <span class="pkg">tm</span> corpus
either based on its document-term matrix, or on selected dimensions of a previously
run correspondence analysis (if no correspondence analysis has been performed, the
relevant widgets are not available). With both methods, the dendrogram starts with
all separate documents at the bottom, and progressively merges them into clusters
until reaching a single group at the top.
</p>
<p>Technically, Ward's minimum variance method is used with a Chi-squared distance: see
<code><a href="stats.html#topic+hclust">hclust</a></code> for details about the clustering process.
</p>
<p>The first slider allows skipping less significant terms to use less memory with large
corpora. The second allows choosing what dimensions of the correspondence analysis
should be used, which helps removing noise to concentrate on identified caracteristics
of the corpus.
</p>
<p>Since the clustering by itself only returns a tree, cutting it at a given size is
needed to create classes of documents: this is offered automatically after the dendrogram
has been computed, and can be achieved as many times as needed thanks to the Text
Mining-&gt;Hierarchical clustering-&gt;Create clusters... dialog.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+hclust">hclust</a></code>, <code><a href="stats.html#topic+dist">dist</a></code>, <code><a href="#topic+corpusCaDlg">corpusCaDlg</a></code>, <code><a href="tm.html#topic+removeSparseTerms">removeSparseTerms</a></code>,
<code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>, <code><a href="#topic+createClustersDlg">createClustersDlg</a></code> </p>

<hr>
<h2 id='corpusDissimilarity'>Cross-Dissimilarity Table</h2><span id='topic+corpusDissimilarity'></span>

<h3>Description</h3>

<p>Build a cross-dissimilarity table reporting Chi-squared distances from two document-term
matrices of the same corpus.</p>


<h3>Usage</h3>

<pre><code class='language-R'>corpusDissimilarity(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="corpusDissimilarity_+3A_x">x</code></td>
<td>
<p>a document-term matrix</p>
</td></tr>
<tr><td><code id="corpusDissimilarity_+3A_y">y</code></td>
<td>
<p>a document-term matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function can be used to build a cross-dissimilarity table from two different variables
of a corpus. It takes two versions of a document-term matrix, aggregated in different ways,
and returns the Chi-squared distance between each combination of the tow matrices' rows. Thus,
the resulting table has rows of <code>x</code> for rows, and rows of <code>y</code> for columns.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dissimilarityTableDlg">dissimilarityTableDlg</a></code>, <code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>, <code><a href="stats.html#topic+dist">dist</a></code> </p>

<hr>
<h2 id='createClustersDlg'>Cut hierarchical clustering tree into clusters</h2><span id='topic+createClustersDlg'></span><span id='topic+showCorpusClustering'></span>

<h3>Description</h3>

<p>Cut a hierarchical clustering tree into clusters of documents.</p>


<h3>Details</h3>

<p>This dialog allows grouping the documents present in a <span class="pkg">tm</span> corpus
according to a previously computed hierarchical clustering tree (see
<code><a href="#topic+corpusClustDlg">corpusClustDlg</a></code>). It adds a new meta-data variable to the corpus,
each number corresponding to a cluster; this variable is also added to the corpusMetaData
data set. If clusters were already created before, they are simply replaced.
</p>
<p>Clusters will be created by starting from the top of the dendrogram, and going through
the merge points with the highest position until the requested number of branches is reached.
</p>
<p>A window opens to summarize created clusters, providing information about specific documents
and terms for each cluster. Specific terms are those whose observed frequency in the document or level
has the lowest probability under an hypergeometric distribution, based on their global frequencies
in the corpus and on the number of occurrences of all terms in the considered cluster.
All terms with a probability below the value chosen using the third slider are reported, ignoring
terms with fewer occurrences in the whole corpus than the value of the fourth slider (these terms
can often have a low probability but are too rare to be of interest). The last slider allows limiting
the number of terms that will be shown for each cluster.
</p>
<p>The positive or negative character of the association is visible from the sign of the t value,
or by comparing the value of the &ldquo;% Term/Level&rdquo; column with that of the &ldquo;Global %&rdquo;
column. The definition of columns is:
</p>

<dl>
<dt>&ldquo;% Term/Level&rdquo;:</dt><dd><p>the percent of the term's occurrences in all terms occurrences in the level.</p>
</dd>
<dt>&ldquo;% Level/Term&rdquo;:</dt><dd><p>the percent of the term's occurrences that appear in the level
(rather than in other levels).</p>
</dd>
<dt>&ldquo;Global %&rdquo;:</dt><dd><p>the percent of the term's occurrences in all terms occurrences in the corpus.</p>
</dd>
<dt>&ldquo;Level&rdquo;:</dt><dd><p>the number of occurrences of the term in the level (&ldquo;internal&rdquo;).</p>
</dd>
<dt>&ldquo;Global&rdquo;:</dt><dd><p>the number of occurrences of the term in the corpus.</p>
</dd>
<dt>&ldquo;t value&rdquo;:</dt><dd><p>the quantile of a normal distribution corresponding the probability &ldquo;Prob.&rdquo;.</p>
</dd>
<dt>&ldquo;Prob.&rdquo;:</dt><dd><p>the probability of observing such an extreme (high or low) number of occurrences of
the term in the level, under an hypergeometric distribution.</p>
</dd>
</dl>

<p>Specific documents are selected using a different criterion than terms: documents with the smaller
Chi-squared distance to the average vocabulary of the cluster are shown. This is a euclidean distance,
but weighted by the inverse of the prevalence of each term in the whole corpus, and controlling for
the documents' different lengths.
</p>
<p>This dialog can only be used after having created a tree, which is done via the Text
Mining-&gt;Hierarchical clustering-&gt;Create dendrogram... dialog.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+corpusClustDlg">corpusClustDlg</a></code>, <code><a href="stats.html#topic+cutree">cutree</a></code>, <code><a href="stats.html#topic+hclust">hclust</a></code>, <code><a href="stats.html#topic+dendrogram">dendrogram</a></code> </p>

<hr>
<h2 id='dissimilarityTableDlg'>Documents/Variables Dissimilarity Table</h2><span id='topic+dissimilarityTableDlg'></span>

<h3>Description</h3>

<p>Build a dissimilarity table reporting Chi-squared distances between documents and/or
levels of a variable.</p>


<h3>Details</h3>

<p>This dialog can be used in two main ways. If &quot;Document&quot; or one variable is
selected for both rows and columns, the one-to-one dissimilarity between all documents
or levels of the variable will be reported. If a different variables are chosen for
rows and for columns, a cross-dissimilarity table will be created; such a table can be
used to assess whether a document or variable level is closer to another variable level.
</p>
<p>In all cases, the reported value is the Chi-squared distance between the two documents or
variable levels, computed from the total document-term matrix (aggregated for variables).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+corpusDissimilarity">corpusDissimilarity</a></code>, <code><a href="#topic+setCorpusVariables">setCorpusVariables</a></code>, <code><a href="tm.html#topic+meta">meta</a></code>,
<code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>, <code><a href="stats.html#topic+dist">dist</a></code> </p>

<hr>
<h2 id='freqTermsDlg'>List most frequent terms of a corpus</h2><span id='topic+freqTermsDlg'></span>

<h3>Description</h3>

<p>List terms with the highest number of occurrences in the document-term matrix of a corpus.</p>


<h3>Details</h3>

<p>This dialog allows printing the most frequent terms of the corpus. If a variable is chosen,
the returned terms correspond to those with the highest total among the documents within each level
of the variable. If &ldquo;None (whole corpus)&rdquo; is selected,
the absolute frequency of the chosen terms and their percents in occurrences of all terms
in the whole corpus are returned. If &ldquo;Document&rdquo; or a variable is chosen, details about the
association of the term with documents or levels are shown:
</p>

<dl>
<dt>&ldquo;% Term/Level&rdquo;:</dt><dd><p>the percent of the term's occurrences in all terms occurrences in the level.</p>
</dd>
<dt>&ldquo;% Level/Term&rdquo;:</dt><dd><p>the percent of the term's occurrences that appear in the level
(rather than in other levels).</p>
</dd>
<dt>&ldquo;Global %&rdquo;:</dt><dd><p>the percent of the term's occurrences in all terms occurrences in the corpus.</p>
</dd>
<dt>&ldquo;Level&rdquo;:</dt><dd><p>the number of occurrences of the term in the level (&ldquo;internal&rdquo;).</p>
</dd>
<dt>&ldquo;Global&rdquo;:</dt><dd><p>the number of occurrences of the term in the corpus.</p>
</dd>
<dt>&ldquo;t value&rdquo;:</dt><dd><p>the quantile of a normal distribution corresponding the probability &ldquo;Prob.&rdquo;.</p>
</dd>
<dt>&ldquo;Prob.&rdquo;:</dt><dd><p>the probability of observing such an extreme (high or low) number of occurrences of
the term in the level, under an hypergeometric distribution.</p>
</dd>
</dl>

<p>The probability is that of observing such extreme frequencies of the considered term in the level,
under an hypergeometric distribution based on its global frequency in the corpus and on the
number of occurrences of all terms in the document or variable level considered.
The positive or negative character of the association is visible from the sign of the t value,
or by comparing the value of the &ldquo;% Term/Level&rdquo; column with that of the &ldquo;Global %&rdquo;
column.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+frequentTerms">frequentTerms</a></code>, <code><a href="#topic+setCorpusVariables">setCorpusVariables</a></code>, <code><a href="tm.html#topic+meta">meta</a></code>,
<code><a href="#topic+restrictTermsDlg">restrictTermsDlg</a></code>, <code><a href="#topic+termsDictionary">termsDictionary</a></code> </p>

<hr>
<h2 id='frequentTerms'>List most frequent terms of a corpus</h2><span id='topic+frequentTerms'></span>

<h3>Description</h3>

<p>List terms with the highest number of occurrences in the document-term matrix of a corpus,
possibly grouped by the levels of a variable.</p>


<h3>Usage</h3>

<pre><code class='language-R'>frequentTerms(dtm, variable = NULL, n = 25)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="frequentTerms_+3A_dtm">dtm</code></td>
<td>
<p>a document-term matrix.</p>
</td></tr>
<tr><td><code id="frequentTerms_+3A_variable">variable</code></td>
<td>
<p>a vector whose length is the number of rows of <code>dtm</code>, or <code>NULL</code> to report most
frequent terms by document; use <code>NA</code> to report most frequent terms in the whole corpus.</p>
</td></tr>
<tr><td><code id="frequentTerms_+3A_n">n</code></td>
<td>
<p>the number of terms to report for each level.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability is that of observing such extreme frequencies of the considered term in the level,
under an hypergeometric distribution based on its global frequency in the corpus and on the
number of occurrences of all terms in the document or variable level considered.
The positive or negative character of the association is visible from the sign of the t value,
or by comparing the value of the &ldquo;% Term/Level&rdquo; column with that of the &ldquo;Global %&rdquo;
column.
</p>


<h3>Value</h3>

<p>If <code>variable = NA</code>, one matrix with columns &ldquo;Global&rdquo; and <code>Global %</code> (see below).
Else, a list of matrices, one for each level of the variable, with seven columns:
</p>
<table role = "presentation">
<tr><td><code>\dQuote{% Term/Level}</code></td>
<td>
<p>the percent of the term's occurrences in all terms occurrences in the level.</p>
</td></tr>
<tr><td><code>\dQuote{% Level/Term}</code></td>
<td>
<p>the percent of the term's occurrences that appear in the level
(rather than in other levels).</p>
</td></tr>
<tr><td><code>\dQuote{Global %}</code></td>
<td>
<p>the percent of the term's occurrences in all terms occurrences in the corpus.</p>
</td></tr>
<tr><td><code>\dQuote{Level}</code></td>
<td>
<p>the number of occurrences of the term in the level (&ldquo;internal&rdquo;).</p>
</td></tr>
<tr><td><code>\dQuote{Global}</code></td>
<td>
<p>the number of occurrences of the term in the corpus.</p>
</td></tr>
<tr><td><code>\dQuote{t value}</code></td>
<td>
<p>the quantile of a normal distribution corresponding the probability &ldquo;Prob.&rdquo;.</p>
</td></tr>
<tr><td><code>\dQuote{Prob.}</code></td>
<td>
<p>the probability of observing such an extreme (high or low) number of occurrences of the
term in the level, under an hypergeometric distribution.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Milan Bouchet-Valat</p>


<h3>See Also</h3>

<p><code><a href="#topic+specificTerms">specificTerms</a></code>, <code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code></p>

<hr>
<h2 id='GDf-class'>Class <code>"GDf"</code></h2><span id='topic+GDf-class'></span>

<h3>Description</h3>

<p>GUI editor for data frames</p>


<h3>Fields</h3>


<dl>
<dt><code>widget</code>:</dt><dd><p>Object of class <code>ANY</code>.</p>
</dd>
<dt><code>block</code>:</dt><dd><p>Object of class <code>ANY</code>.</p>
</dd>
<dt><code>head</code>:</dt><dd><p>Object of class <code>ANY</code>.</p>
</dd>
</dl>



<h3>Methods</h3>


<dl>
<dt><code>get_length()</code>:</dt><dd><p>Get the number of columns in the data frames.</p>
</dd>
<dt><code>set_names(values, ...)</code>:</dt><dd><p>Set column names.</p>
</dd>
<dt><code>focus_cell(i, j)</code>:</dt><dd><p>Give focus to a given cell.</p>
</dd>
<dt><code>hide_row(i, hide)</code>:</dt><dd><p>Hide a given row.</p>
</dd>
<dt><code>hide_column(j, hide)</code>:</dt><dd><p>Hide a given column.</p>
</dd>
<dt><code>initialize(parent, items, ...)</code>:</dt><dd><p>Initialize the widget with items.</p>
</dd>
<dt><code>set_items(value, i, j, ...)</code>:</dt><dd><p>Set the value of cells.</p>
</dd>
<dt><code>get_names()</code>:</dt><dd><p>Get column names.</p>
</dd>
<dt><code>init_widget(parent)</code>:</dt><dd><p>Initialize the widget.</p>
</dd>
<dt><code>set_editable(j, value)</code>:</dt><dd><p>Set whether a column can be edited.</p>
</dd>
<dt><code>sort_bycolumn(j, decreasing)</code>:</dt><dd><p>Set the sorting column.</p>
</dd>
<dt><code>save_data(nm, where)</code>:</dt><dd><p>Save contents to a data frame.</p>
</dd>
</dl>


<hr>
<h2 id='importCorpusDlg'>Import a corpus and process it</h2><span id='topic+importCorpusDlg'></span><span id='topic+importCorpusFromDir'></span><span id='topic+importCorpusFromFile'></span><span id='topic+importCorpusFromFactiva'></span><span id='topic+importCorpusFromLexisNexis'></span><span id='topic+importCorpusFromEuropresse'></span><span id='topic+importCorpusFromAlceste'></span><span id='topic+importCorpusFromTwitter'></span><span id='topic+editDictionary'></span><span id='topic+splitTexts'></span><span id='topic+extractMetadata'></span>

<h3>Description</h3>

<p>Import a corpus, process it and extract a document-term matrix.</p>


<h3>Details</h3>

<p>This dialog allows creating a <span class="pkg">tm</span> corpus from various sources. Once the
documents have been loaded, they are processed according to the chosen settings,
and a document-term matrix is extracted.
</p>
<p>The first source, &ldquo;Directory containing plain text files&rdquo;, creates one
document for each .txt file found in the specified directory. The documents
are named according to the name of the file they were loaded from. When choosing
the directoty where the .txt files can be found, please note that files are not
listed in the file browser, only directories, but they will be loaded nevertheless.
</p>
<p>The second source, &ldquo;Spreadsheet file&rdquo;, creates one document for each row
of a file containg tabular data, typically an Excel (.xls) or Open Document
Spreadsheet (.ods), comma-separated values (.csv) or tab-separated values (.tsv, .txt,
.dat) file. One column must be specified as containing the text of the document, while the
remaining columns are added as variables describing each document. For the CSV format,
&ldquo;,&rdquo; or &ldquo;;&rdquo; is used as separator, whichever is the most frequent in the
50 first lines of the file.
</p>
<p>The third, fourth and fifth sources, &ldquo;Factiva XML or HTML file(s)&rdquo;,
&ldquo;LexisNexis HTML file(s)&rdquo; and &ldquo;Europresse HTML file(s)&rdquo;, load articles
exported from the corresponding website in the <abbr><span class="acronym">XML</span></abbr> or <abbr><span class="acronym">HTML</span></abbr> formats
(for Factiva, the former is recommended if you can choose it). Various meta-data variables
describing the articles are automatically extracted. If the corpus is split into several .xml
or .html files, you  can put them in the same directory and select them by holding the Ctrl
key to concatenate them into a single corpus. Please note that some articles from Factiva
are known to contain invalid character that trigger an error when loading. If this problem
happens to you, please try to identify the problematic article, for example by removing half
of the documents and retrying, until only one document is left in the corpus; then, report
the problem to the Factiva Customer Service, or ask for help to the maintainers of the
present package.
</p>
<p>The sixth source, &ldquo;Alceste file(s)&rdquo;, loads texts and variables from a single file
in the Alceste format, which uses asterisks to separate texts and code variables.
</p>
<p>The seventh source, &ldquo;Twitter search&rdquo;, retrieves most recent tweets matching the search
query and written in the specified language, up to the chosen maximum number of messages.
Please note that you need to register a custom application and fill in the needed information
to authenticate with the Twitter API (see <code>vignette("twitteR")</code> about OAuth authentication
and <a href="https://apps.twitter.com">https://apps.twitter.com</a> to register a new application).
Due to limitations imposed by Twitter, only tweets published up to 6 or 9 days ago can be
downloaded, and up to a maximum number of 1500 tweets. Search queries can notably include
one or more terms that must be present together for a tweet to match the query, and/or of
hashtags  starting with &ldquo;#&rdquo;; see <a href="https://developer.twitter.com/en/docs/tweets/search/overview/premium">https://developer.twitter.com/en/docs/tweets/search/overview/premium</a>
if you need more complex search strings. User names, hashtags, URLs and &ldquo;RT&rdquo; (re-tweet)
mentions are automatically removed from the corpus when computing the document-term matrix
as they generally disturb the analysis. If the option to remove user names and hashtags is
disabled, they will be included as standard text, i.e. &ldquo;#&rdquo; and &ldquo;@&rdquo; will be
removed if the punctuation removal processing option has been enabled. The &ldquo;Exclude
retweets&rdquo; option works by identifying tweets that contain &ldquo;RT&rdquo; as a separate expression;
this operation can also be carried out manually later by using the &ldquo;Retweet&rdquo; corpus
variable that is created automatically at import time.
</p>
<p>The original texts can optionally be split into smaller chunks, which will then be
considered as the real unit (called &lsquo;documents&rsquo;) for all analyses. In order
to get meaningful chunks, texts are only splitted into paragraphs. These are defined
by the import filter: when importing a directory of text files, a new paragraph
starts with a line break; when importing a Factiva files, paragraphs are defined
by the content provider itself, so may vary in size (heading is always a separate
paragraph); splitting has no effect when importing from a spreadsheet file. A corpus
variable called &ldquo;Document&rdquo; is created, which identifies the original text
the chunk comes from.
</p>
<p>For all sources, a data set called <code>corpusVariables</code> is created, with one row
for each document in the corpus: it contains meta-data that could be extracted from
the source, if any, and can be used to enter further meta-data about the corpus.
This can also be done by importing an existing data set via the
Data-&gt;Load data set or Data-&gt;Import data menus. Whatever way you choose, use the
Text mining-&gt;Set corpus meta-data command after that to set or update the corpus's
meta-data that will be used by later analyses (see <code><a href="#topic+setCorpusVariables">setCorpusVariables</a></code>).
</p>
<p>The dialog also provides a few processing options that will most likely be
all run in order to get a meaningful set of terms from a text corpus.
Among them, stopwords removal and stemming require you to select the
language used in the corpus. If you tick &ldquo;Edit stemming manually&rdquo;,
enabled processing steps will be applied to the terms before presenting you with
a list of all words originally found in the corpus, together with their stemmed forms.
Terms with an empty stemmed form will be excluded from the document-term matrix;
the &ldquo;Stopword&rdquo; column is only presented as an indication, it is not taken into
account when deciding whether to keep a term.
</p>
<p>By default, the program tries to detect the encoding used by plain text (usually .txt)
and comma/tab-separated values files (.csv, .tsv, .dat...). If importation fails or
the imported texts contain strange characters, specify the encoding manually (a tooltip
gives suggestions based on the selected language).
</p>
<p>Once the corpus has been imported, its document-term matrix is extracted.
</p>


<h3>References</h3>

<p>Ingo Feinerer, Kurt Hornik, and David Meyer. Text mining infrastructure in R. Journal of Statistical Software, 25(5):1-54, March 2008. Available at <a href="https://www.jstatsoft.org/v25/i05">https://www.jstatsoft.org/v25/i05</a>.<br /><br />
Ingo Feinerer. An introduction to text mining in R. R News, 8(2):19-22, October 2008. Available at <a href="https://cran.r-project.org/doc/Rnews/Rnews_2008-2.pdf">https://cran.r-project.org/doc/Rnews/Rnews_2008-2.pdf</a></p>


<h3>See Also</h3>

<p><code><a href="tm.html#topic+Corpus">Corpus</a></code>, <code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>, <code><a href="#topic+restrictTermsDlg">restrictTermsDlg</a></code>,
<code><a href="#topic+setCorpusVariables">setCorpusVariables</a></code>, <code><a href="base.html#topic+tolower">tolower</a></code>, <code><a href="tm.html#topic+removePunctuation">removePunctuation</a></code>,
<code><a href="tm.html#topic+removeNumbers">removeNumbers</a></code>, <code><a href="tm.html#topic+stopwords">stopwords</a></code>,  <code><a href="tm.html#topic+stemDocument">stemDocument</a></code>,
<code><a href="tm.html#topic+tm_map">tm_map</a></code> </p>

<hr>
<h2 id='inspectCorpus'>Inspect corpus</h2><span id='topic+inspectCorpus'></span>

<h3>Description</h3>

<p>See contents of all documents in the corpus.</p>


<h3>Details</h3>

<p>This function opens a window with the contents of all documents in the current
corpus. Note that the texts are shown as they were on import, i.e. before
the processing steps (removing case, punctuation, numbers and stopwords, or
stemming), which make the texts hard to read. Though, if the corpus was split,
created chunks are shown separately.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+importCorpusDlg">importCorpusDlg</a></code> </p>

<hr>
<h2 id='output'>Output results to HTML file</h2><span id='topic+setOutputFile'></span><span id='topic+initOutputFile'></span><span id='topic+openOutputFile'></span><span id='topic+copyTableToOutput'></span><span id='topic+copyPlotToOutput'></span><span id='topic+enableBlackAndWhite'></span><span id='topic+disableBlackAndWhite'></span><span id='topic+HTML.list'></span><span id='topic+HTML.ca'></span><span id='topic+summary.ca'></span>

<h3>Description</h3>

<p>Functions to output tables and plots resulting from analysis of the corpus to an
<abbr><span class="acronym">HTML file</span></abbr>.</p>


<h3>Details</h3>

<p><code>setOutputFile</code> is automatically called the first time an attempt to save a result
to the output file happens. It can also be called from the &ldquo;Export results to report&rdquo;
menu.
</p>
<p><code>openOutputFile</code> launches the configured web browser (see <code><a href="utils.html#topic+browseURL">browseURL</a></code>) to
open the current output file. It is automatically called the first time a new output file is
set (i.e. when <code>setOutputFile</code> is run).
</p>
<p><code>copyTableToOutput</code> and <code>copyPlotToOutput</code> export objects to the select output
<abbr><span class="acronym">HTML</span></abbr> file, using the titles that were configured when the objects where created.
For plots, a plotting device must be currently open. The graph is saved in the <abbr><span class="acronym">PNG</span></abbr>
format with a reasonably high quality. For tables, the last created table is used.
</p>
<p><code>enableBlackAndWhite</code> and <code>disableBlackAndWhite</code> functions can be used to produce
black and white only graphics adapted for printing and publication. They affect the on-screen
device as well as the plot copied to the output file, so that the plot can be checked for
readability before exporting it.
</p>
<p><code>HTML.list</code> outputs a list to the HTML report, printing each element of the list right after
its name. <code>HTML.ca</code> outputs a correspondence analysis object of class <code>ca</code> to the HTML
report. <code>summary.ca</code> is a slightly modified version of <code><a href="ca.html#topic+summary.ca">summary.ca</a></code> from the
&ldquo;ca&rdquo; package to accept non-ASCII characters and not abbreviate document names and terms;
it is used by <code>HTML.ca</code> internally.
</p>

<hr>
<h2 id='plotCorpusCa'>Plotting 2D maps in correspondence analysis of corpus</h2><span id='topic+plotCorpusCa'></span>

<h3>Description</h3>

<p>Graphical display of correspondence analysis of a corpus in two dimensions</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotCorpusCa(x, dim = c(1,2), map = "symmetric", what = c("all", "all"), 
             mass = c(FALSE, FALSE), contrib = c("none", "none"), 
             col = c("blue", "red"),
             col.text = c("black", "blue", "black", "red"),
             font = c(3, 4, 1, 2), pch = c(16, 1, 17, 24), 
             labels = c(2, 2), arrows = c(FALSE, FALSE),
             cex = 0.75,
             xlab = paste("Dimension", dim[1]),
             ylab = paste("Dimension", dim[2]), ...) </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotCorpusCa_+3A_x">x</code></td>
<td>
<p>Simple correspondence analysis object returned by <code><a href="#topic+runCorpusCa">runCorpusCa</a></code></p>
</td></tr>
<tr><td><code id="plotCorpusCa_+3A_dim">dim</code></td>
<td>
<p>Numerical vector of length 2 indicating the dimensions to plot on horizontal and vertical axes respectively; default is first dimension horizontal and second dimension vertical.</p>
</td></tr>
<tr><td><code id="plotCorpusCa_+3A_map">map</code></td>
<td>
<p>Character string specifying the map type. Allowed options include <br />
<kbd>"symmetric"</kbd> (default) <br />
<kbd>"rowprincipal"</kbd> <br />
<kbd>"colprincipal"</kbd> <br />
<kbd>"symbiplot"</kbd> <br />
<kbd>"rowgab"</kbd> <br />
<kbd>"colgab"</kbd> <br />
<kbd>"rowgreen"</kbd> <br />
<kbd>"colgreen"</kbd>
</p>
</td></tr>
<tr><td><code id="plotCorpusCa_+3A_what">what</code></td>
<td>
<p>Vector of two character strings specifying the contents of the plot. First entry sets the rows and the second entry the columns. Allowed values are <br />
<kbd>"all"</kbd> (all available points, default) <br />
<kbd>"active"</kbd> (only active points are displayed) <br />
<kbd>"passive"</kbd> (only supplementary points are displayed) <br />
<kbd>"none"</kbd> (no points are displayed) <br />
The status (active or supplementary) of rows and columns is set in <code><a href="#topic+runCorpusCa">runCorpusCa</a></code> using the options <code>suprow</code> and <code>supcol</code>.</p>
</td></tr>
<tr><td><code id="plotCorpusCa_+3A_mass">mass</code></td>
<td>
<p>Vector of two logicals specifying if the mass should be represented by the area of the point symbols (first entry for rows, second one for columns)</p>
</td></tr>
<tr><td><code id="plotCorpusCa_+3A_contrib">contrib</code></td>
<td>
<p>Vector of two character strings specifying if contributions (relative or absolute) should be represented by different colour intensities. Available options are<br />
<kbd>"none"</kbd> (contributions are not indicated in the plot).<br />
<kbd>"absolute"</kbd> (absolute contributions are indicated by colour intensities).<br />
<kbd>"relative"</kbd> (relative contributions are indicated by colour intensities).<br />
If set to <kbd>"absolute"</kbd> or <kbd>"relative"</kbd>, points with zero contribution are displayed in white. The higher the contribution of a point, the closer the corresponding colour to the one specified by the <code>col</code> option.</p>
</td></tr>
<tr><td><code id="plotCorpusCa_+3A_col">col</code></td>
<td>
<p>Vector of length 2 specifying the colours of row and column point symbols, by default blue for rows and red for columns. Colours can be entered in hexadecimal (e.g. <kbd>"\#FF0000"</kbd>), rgb (e.g. <kbd>rgb(1,0,0)</kbd>) values or by R-name (e.g. <kbd>"red"</kbd>). </p>
</td></tr>
<tr><td><code id="plotCorpusCa_+3A_col.text">col.text</code></td>
<td>
<p>Vector of length 4 giving the color to be used for text of labels for row active and supplementary, column active and supplementary points. Colours can be entered in hexadecimal (e.g. <kbd>"\#FF0000"</kbd>), rgb (e.g. <kbd>rgb(1,0,0)</kbd>) values or by R-name (e.g. <kbd>"red"</kbd>).</p>
</td></tr>
<tr><td><code id="plotCorpusCa_+3A_font">font</code></td>
<td>
<p>Vector of length 4 giving the font to be used for text labels for row active and supplementary, column active and supplementary points. See <code><a href="graphics.html#topic+par">par</a></code> for a list possible values.</p>
</td></tr>
<tr><td><code id="plotCorpusCa_+3A_pch">pch</code></td>
<td>
<p>Vector of length 4 giving the type of points to be used for row active and supplementary, column active and supplementary points. See <code><a href="ca.html#topic+pchlist">pchlist</a></code> for a list of symbols.</p>
</td></tr>
<tr><td><code id="plotCorpusCa_+3A_labels">labels</code></td>
<td>
<p>Vector of length two specifying if the plot should contain symbols only (<kbd>0</kbd>), labels only (<kbd>1</kbd>) or both symbols and labels (<kbd>2</kbd>). Setting <code>labels</code> to <kbd>2</kbd> results in the symbols being plotted at the coordinates and the labels with an offset.</p>
</td></tr>
<tr><td><code id="plotCorpusCa_+3A_arrows">arrows</code></td>
<td>
<p>Vector of two logicals specifying if the plot should contain points (<kbd>FALSE</kbd>, default) or arrows (<kbd>TRUE</kbd>). First value sets the rows and the second value sets the columns.</p>
</td></tr>
<tr><td><code id="plotCorpusCa_+3A_cex">cex</code></td>
<td>
<p>Numeric value indicating the size of the labels text.</p>
</td></tr>
<tr><td><code id="plotCorpusCa_+3A_xlab">xlab</code></td>
<td>
<p>Title for the x axis: see <code><a href="graphics.html#topic+title">title</a></code>.</p>
</td></tr>
<tr><td><code id="plotCorpusCa_+3A_ylab">ylab</code></td>
<td>
<p>Title for the y axis: see <code><a href="graphics.html#topic+title">title</a></code>.</p>
</td></tr>
<tr><td><code id="plotCorpusCa_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <code><a href="base.html#topic+plot">plot</a></code>, to <code><a href="graphics.html#topic+points">points</a></code> and to <code><a href="graphics.html#topic+text">text</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>plotCorpusCa</code> makes a two-dimensional map of the object created by <code>runCorpusCa</code> with respect to two selected dimensions.  By default the scaling option of the map is <kbd>"symmetric"</kbd>, that is the so-called <em>symmetric map</em>. In this map both the row and column points are scaled to have inertias (weighted variances) equal to the principal inertia (eigenvalue or squared singular value) along the principal axes, that is both rows and columns are in pricipal coordinates. Other options are as follows:  
</p>

<ul>
<li><p>-<kbd>"rowprincipal"</kbd> or <kbd>"colprincipal"</kbd> - these are the so-called <em>asymmetric maps</em>, with either rows in principal coordinates and columns in standard coordinates, or vice versa (also known as row-metric-preserving or column-metric-preserving respectively). These maps are biplots;
</p>
</li></ul>


<ul>
<li><p>-<kbd>"symbiplot"</kbd> - this scales both rows and columns to have variances equal to the singular values (square roots of eigenvalues), which gives a symmetric biplot but does not preserve row or column metrics;
</p>
</li></ul>


<ul>
<li><p>-<kbd>"rowgab"</kbd> or <kbd>"colgab"</kbd> - these are asymmetric maps (see above) with rows (respectively, columns) in principal coordinates and columns (respectively, rows) in standard coordinates multiplied by the mass of the corresponding point. These are also biplots and were proposed by Gabriel &amp; Odoroff (1990);
</p>
</li></ul>


<ul>
<li><p>-<kbd>"rowgreen"</kbd> or <kbd>"colgreen"</kbd> - these are similar to <kbd>"rowgab"</kbd> and <kbd>"colgab"</kbd> except that the points in standard coordinates are multiplied by the square root of the corresponding masses, giving reconstructions of the standardized residuals.
</p>
</li></ul>

<p>This function has options for sizing and shading the points.  If the option <code>mass</code> is <kbd>TRUE</kbd> for a set of points, the size of the point symbol is proportional to the relative frequency (mass) of each point.  If the option <code>contrib</code> is <kbd>"absolute"</kbd> or <kbd>"relative"</kbd> for a set of points, the colour intensity of the point symbol is proportional  to the absolute contribution of the points to the planar display or, respectively, the quality of representation of the points in the display.
</p>


<h3>Author(s)</h3>

<p>Oleg Nenadic (adapted from <code>link{plot.ca}</code> by Milan Bouchet-Valat)</p>


<h3>References</h3>

<p>Gabriel, K.R. and Odoroff, C. (1990). Biplots in biomedical research. <em>Statistics in Medicine</em>, 9, pp. 469-485. <br />
Greenacre, M.J. (1993) <em>Correspondence Analysis in Practice</em>.  Academic Press, London. <br />
Greenacre, M.J. (1993) Biplots in correspondence Analysis, <em>Journal of Applied Statistics</em>, 20, pp. 251 - 269.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+runCorpusCa">runCorpusCa</a></code>, <code><a href="#topic+corpusCaDlg">corpusCaDlg</a></code>, <code><a href="#topic+summary.ca">summary.ca</a></code>, <code><a href="ca.html#topic+print.ca">print.ca</a></code>, <code><a href="ca.html#topic+plot3d.ca">plot3d.ca</a></code>, <code><a href="ca.html#topic+pchlist">pchlist</a></code></p>

<hr>
<h2 id='recodeTimeVarDlg'>Recode Date/Time Variable</h2><span id='topic+recodeTimeVarDlg'></span>

<h3>Description</h3>

<p>Recode a date or time meta-data variable to create a new variable, for example
in order to use larger time units (month, week...).</p>


<h3>Details</h3>

<p>This dialog allows creating a new variable from a date or time variable, by specifying
a new time format in which the values of the new variable will be expressed.
</p>
<p>Typical use cases include:
</p>

<ul>
<li><p>Create a month variable from a full date: Use format &ldquo;%Y-%m&rdquo; to get
four-digit year and two-digit month; or &ldquo;%y %B&rdquo; to get two-digits
year and full month name.
</p>
</li>
<li><p>Create a week variable from a full date: Use format &ldquo;%U&rdquo; to get
the week number in the year starting on Sunday, or &ldquo;%W&rdquo; for the
week number in the year starting on Monday.
</p>
</li>
<li><p>Create a date variable from a time variable: Use format &ldquo;%Y-%m-%d&rdquo;
to get four-digit year, two-digit month and two-digit day.
</p>
</li></ul>

<p>The format codes allowed are those recognized by <code><a href="base.html#topic+strptime">strptime</a></code>
(see <code>?strptime</code>), in particular:
</p>

<dl>
<dt>&lsquo;%a&rsquo;</dt><dd><p>Abbreviated weekday name in the current locale. (Also
matches full name.)</p>
</dd>
<dt>&lsquo;%A&rsquo;</dt><dd><p>Full weekday name in the current locale. (Also matches
abbreviated name.)</p>
</dd>
<dt>&lsquo;%b&rsquo;</dt><dd><p>Abbreviated month name in the current locale. (Also matches
full name.)</p>
</dd>
<dt>&lsquo;%B&rsquo;</dt><dd><p>Full month name in the current locale. (Also matches
abbreviated name.)</p>
</dd>
<dt>&lsquo;%d&rsquo;</dt><dd><p>Day of the month as decimal number (01-31).</p>
</dd>
<dt>&lsquo;%H&rsquo;</dt><dd><p>Hours as decimal number (00-23).</p>
</dd>
<dt>&lsquo;%I&rsquo;</dt><dd><p>Hours as decimal number (01-12).</p>
</dd>
<dt>&lsquo;%m&rsquo;</dt><dd><p>Month as decimal number (01-12).</p>
</dd>
<dt>&lsquo;%M&rsquo;</dt><dd><p>Minute as decimal number (00-59).</p>
</dd>
<dt>&lsquo;%U&rsquo;</dt><dd><p>Week of the year as decimal number (00-53) using Sunday as
the first day 1 of the week (and typically with the first
Sunday of the year as day 1 of week 1).  The US convention.</p>
</dd>
<dt>&lsquo;%W&rsquo;</dt><dd><p>Week of the year as decimal number (00-53) using Monday as
the first day 1 of the week (and typically with the first
Monday of the year as day 1 of week 1).  The UK convention.</p>
</dd>
<dt>&lsquo;%p&rsquo;</dt><dd><p>AM/PM indicator in the locale.  Used in conjunction with &lsquo;%I&rsquo;
and not with &lsquo;%H&rsquo;.</p>
</dd>
<dt>&lsquo;%S&rsquo;</dt><dd><p>Second as decimal number (00-61).</p>
</dd>
<dt>&lsquo;%y&rsquo;</dt><dd><p>Year without century (00-99).</p>
</dd>
<dt>&lsquo;%Y&rsquo;</dt><dd><p>Year with century.</p>
</dd>
</dl>

<p>&ldquo;Time units&rdquo; are chosen automatically according to the values of the time variable:
it is set to the smallest unit in which all time values can be uniquely expressed.
For example, if free dates are entered, the unit will be days; if times are entered but minutes
are always 0, hours will be used; finally, if times are fully specified, seconds will be used as
the time unit. The chosen unit appears in the vertical axis label of the plot.
</p>
<p>Three measures of term occurrences are provided (when no variable is selected, &ldquo;category&rdquo;
below corresponds to the whole corpus):<br />
</p>

<ul>
<li><p>Row percent corresponds to the part of chosen term's occurrences over all terms
found in a given category (i.e., the sum of word counts of all documents from the category 
after processing) at each time point. This conceptually corresponds to line percents,
except that only the columns of the document-term matrix that match the given terms are shown.
</p>
</li>
<li><p>Column percent corresponds to the part of the chosen term's occurrences that
appear in each of the documents from a given category at each time point. This measure
corresponds to the strict definition of column percents.
</p>
</li>
<li><p>Absolute counts returns the relevant part of the document-term matrix, but summed
for a given time point, and after grouping documents according to their category.
</p>
</li></ul>

<p>The rolling mean is left-aligned, meaning that the number of documents reported for a
point reflects the average of the values of the points occurring <em>after</em> it. When percents
of occurrences are plotted, time units with no occurrence in the corpus are not plotted, since they
have no defined value (0/0, reported as <code>NaN</code>); when a rolling mean is applied, the values
are simply ignored, i.e. the mean is computed over the chosen window without the missing points.</p>


<h3>See Also</h3>

<p><code><a href="#topic+setCorpusVariables">setCorpusVariables</a></code>, <code><a href="tm.html#topic+meta">meta</a></code>, <code><a href="zoo.html#topic+zoo">zoo</a></code>, <code><a href="lattice.html#topic+xyplot">xyplot</a></code>,
<code><a href="#topic+varTimeSeriesDlg">varTimeSeriesDlg</a></code>, <code><a href="#topic+recodeTimeVarDlg">recodeTimeVarDlg</a></code> </p>

<hr>
<h2 id='restrictTermsDlg'>Select or exclude terms</h2><span id='topic+restrictTermsDlg'></span>

<h3>Description</h3>

<p>Remove terms from the document-term matrix of a corpus to exclude them from further analyses.</p>


<h3>Details</h3>

<p>This dialog allows to only retain specified terms when you want to concentrate your analysis on an
identified vocabulary, or to exclude a few terms that are known to interfere with the analysis.
</p>
<p>Terms that are not retained or that are excluded are removed from the document-term matrix, and are
thus no longer taken into account by any operations run later, like listing terms of the corpus or
computing a correspondence analysis. They are not removed from the corpus's documents.
</p>


<h3>See Also</h3>

<p><code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>,
<code><a href="#topic+termsDictionary">termsDictionary</a></code>, <code><a href="#topic+freqTermsDlg">freqTermsDlg</a></code> </p>

<hr>
<h2 id='runCorpusCa'>Correspondence analysis from a tm corpus</h2><span id='topic+runCorpusCa'></span>

<h3>Description</h3>

<p>Compute a simple correspondence analysis on the document-term matrix of a tm corpus.</p>


<h3>Usage</h3>

<pre><code class='language-R'>runCorpusCa(corpus, dtm = NULL, variables = NULL, sparsity = 0.9, ...)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="runCorpusCa_+3A_corpus">corpus</code></td>
<td>
<p>A <span class="pkg">tm</span> corpus.</p>
</td></tr>
<tr><td><code id="runCorpusCa_+3A_dtm">dtm</code></td>
<td>
<p>an optional document-term matrix to use; if missing, <code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>
will be called on <code>corpus</code> to create it.</p>
</td></tr>
<tr><td><code id="runCorpusCa_+3A_variables">variables</code></td>
<td>
<p>a character vector giving the names of meta-data variables to aggregate the
document-term matrix (see &ldquo;Details&rdquo; below).</p>
</td></tr>
<tr><td><code id="runCorpusCa_+3A_sparsity">sparsity</code></td>
<td>
<p>Optional sparsity threshold (between 0 and 1) below which terms should be
skipped. See <code><a href="tm.html#topic+removeSparseTerms">removeSparseTerms</a></code> from tm.</p>
</td></tr>
<tr><td><code id="runCorpusCa_+3A_...">...</code></td>
<td>
<p>Additional parameters passed to <code><a href="ca.html#topic+ca">ca</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>runCorpusCa</code> runs a correspondence analysis (CA) on the
document-term matrix that can be extracted from a <span class="pkg">tm</span> corpus by calling
the <code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code> function, or directly from the <code>dtm</code>
object if present.
</p>
<p>If no variable is passed via the <code>variables</code> argument, a CA is run on the
full document-term matrix (possibly skipping sparse terms, see below). If one or more
variables are chosen, the CA will be based on a stacked table whose rows correspond to
the levels of the variables: each cell contains the sum of occurrences of a given term in
all the documents of the level. Documents that contain a <code>NA</code> are skipped for this
variable, but taken into account for the others, if any.
</p>
<p>In all cases, variables that have not been selected are added as supplementary rows. If at least
one variable is passed, documents are also supplementary rows, while they are active otherwise.
</p>
<p>The <code>sparsity</code> argument is passed to <code><a href="tm.html#topic+removeSparseTerms">removeSparseTerms</a></code>
to remove less significant terms from the document-term matrix. This is
especially useful for big corpora, which matrices can grow very large, prompting
<code>ca</code> to take up too much memory.</p>


<h3>Value</h3>

<p>A <code>ca</code> object as returned by the <code><a href="ca.html#topic+ca">ca</a></code> function.</p>


<h3>See Also</h3>

<p><code><a href="ca.html#topic+ca">ca</a></code>, <code><a href="tm.html#topic+meta">meta</a></code>, <code><a href="tm.html#topic+removeSparseTerms">removeSparseTerms</a></code>,
<code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code> </p>

<hr>
<h2 id='setCorpusVariables'>Set corpus variables</h2><span id='topic+setCorpusVariables'></span><span id='topic+doSetCorpusVariables'></span>

<h3>Description</h3>

<p>Set corpus meta-data variables from the active data set.</p>


<h3>Details</h3>

<p>This command creates one corpus meta-data variable from each column
of the active data set. Before doing so, it erases the previously
set meta-data.
</p>
<p>The active data set may contain as many variables (columns) as needed,
but must contain exactly one row for each document in the corpus, as
reported at import time. For convenience, a data set containing one example
variable and as many rows as required, called <code>corpusMetaData</code> is
created after importing the corpus, and defined as the active data set.
It is meant to ease entering information about the documents, but has no
special meaning: the <code>setCorpusVariables</code> command only uses the active
data set, even if it is different from this <code>corpusMetaData</code> stub.
</p>
<p>All analyses performed on the corpus are based on these variables, and never
on the active data set. Thus, you need to call this function every time
you want to take into account changes made to the data set.
</p>


<h3>See Also</h3>

<p><code><a href="tm.html#topic+meta">meta</a></code>, <code><a href="#topic+importCorpusDlg">importCorpusDlg</a></code></p>

<hr>
<h2 id='setLastTable'>Save the name of last table and give a title
</h2><span id='topic+setLastTable'></span>

<h3>Description</h3>

<p>This function saves the name of the last created table to allow copying it
to the HTML report using the &ldquo;Export results to report&rdquo; menu, or
directly using the <code><a href="#topic+copyTableToOutput">copyTableToOutput</a></code> function.</p>


<h3>Usage</h3>

<pre><code class='language-R'>setLastTable(name, title = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="setLastTable_+3A_name">name</code></td>
<td>
<p>The name of the table, which must correspond to an object in the global
environment.</p>
</td></tr>
<tr><td><code id="setLastTable_+3A_title">title</code></td>
<td>
<p>The title to give to the table, which will be displayed in the report,
or <code>NULL</code> for none.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The title is saved as the &ldquo;title&rdquo; attribute of the object called as
<code>name</code> in the global environment. You may need to call <code>activateMenus</code>
so that the relevant menus are enabled.</p>


<h3>Author(s)</h3>

<p>Milan Bouchet-Valat</p>


<h3>See Also</h3>

<p><code><a href="#topic+copyTableToOutput">copyTableToOutput</a></code></p>

<hr>
<h2 id='showCorpusCaDlg'>Show a correspondence analysis from a tm corpus</h2><span id='topic+showCorpusCaDlg'></span><span id='topic+showCorpusCa'></span>

<h3>Description</h3>

<p>Displays a correspondence analysis previously computed from a tm corpus.</p>


<h3>Details</h3>

<p>This dialog allows plotting and showing most contributive terms and documents from a
previously computed correspondence analysis (see <code><a href="#topic+corpusCaDlg">corpusCaDlg</a></code>).
It allows plotting any dimensions of the CA together, showing either documents, terms,
or variables set on the corpus using the Text mining-&gt;Manage corpus-&gt;Set corpus variables menu.
</p>
<p>Compared with most correpondence analyses, CAs of a corpus tend to have many points to show
Thus, the dialog provides two sliders (&ldquo;Number of items to plot&rdquo;) allowing to show only
a subset of terms, documents, the most contributive to the chosen dimension. These items are the most
useful to interpret the axes.
</p>
<p>The text window shows the active items most contributive to the chosen axis, together with
their position, their contribution to the inertia of the axis (&ldquo;Contribution&rdquo;), and the contribution
of the axis to their inertia (&ldquo;Quality of Representation&rdquo;). (For supplementary variables or documents,
depending on the parameters chosen for the CA, absolute contributions are not reported as they do not exist
by definition.) The part of total inertia represented by each axis is shown first, but the rest of the window
only deals with the selected axis (horizontal or vertical).
</p>
<p>The 'Draw point symbols for' checkboxes allow representing documents, terms and variables masses (corresponding
to the size of the symbols) and relative contributions (corresponding to the color intensities). See
the <code>contrib</code> argument to <code><a href="#topic+plotCorpusCa">plotCorpusCa</a></code> for details.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+corpusCaDlg">corpusCaDlg</a></code>, <code><a href="#topic+plotCorpusCa">plotCorpusCa</a></code>, <code><a href="#topic+runCorpusCa">runCorpusCa</a></code>, <code><a href="ca.html#topic+ca">ca</a></code> </p>

<hr>
<h2 id='specificTerms'>List terms specific of a document or level</h2><span id='topic+specificTerms'></span>

<h3>Description</h3>

<p>List terms most associated (positively or negatively) with each document or each
of a variable's levels.</p>


<h3>Usage</h3>

<pre><code class='language-R'>specificTerms(dtm, variable, p = 0.1, n.max = 25, sparsity = 0.95, min.occ = 2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="specificTerms_+3A_dtm">dtm</code></td>
<td>
<p>a document-term matrix.</p>
</td></tr>
<tr><td><code id="specificTerms_+3A_variable">variable</code></td>
<td>
<p>a vector whose length is the number of rows of <code>dtm</code>, or <code>NULL</code> to report specific
terms by document.</p>
</td></tr>
<tr><td><code id="specificTerms_+3A_p">p</code></td>
<td>
<p>the maximum probability up to which terms should be reported.</p>
</td></tr>
<tr><td><code id="specificTerms_+3A_n.max">n.max</code></td>
<td>
<p>the maximum number of terms to report for each level.</p>
</td></tr>
<tr><td><code id="specificTerms_+3A_sparsity">sparsity</code></td>
<td>
<p>Optional sparsity threshold (between 0 and 1) below which terms should be
skipped. See <code><a href="tm.html#topic+removeSparseTerms">removeSparseTerms</a></code> from tm.</p>
</td></tr>
<tr><td><code id="specificTerms_+3A_min.occ">min.occ</code></td>
<td>
<p>the minimum number of occurrences in the whole <code>dtm</code> below which
terms should be skipped.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Specific terms reported here are those whose observed frequency in the document or level has
the lowest probability under an hypergeometric distribution, based on their global frequencies
in the corpus and on the number of occurrences of all terms in the document or variable level considered.
The positive or negative character of the association is visible from the sign of the t value,
or by comparing the value of the &ldquo;% Term/Level&rdquo; column with that of the &ldquo;Global %&rdquo;
column.
</p>
<p>All terms with a probability below <code>p</code> are reported, up to <code>n.max</code> terms for each category.
</p>


<h3>Value</h3>

<p>A list of matrices, one for each level of the variable, with seven columns:
</p>
<table role = "presentation">
<tr><td><code>\dQuote{% Term/Level}</code></td>
<td>
<p>the percent of the term's occurrences in all terms occurrences in the level.</p>
</td></tr>
<tr><td><code>\dQuote{% Level/Term}</code></td>
<td>
<p>the percent of the term's occurrences that appear in the level
(rather than in other levels).</p>
</td></tr>
<tr><td><code>\dQuote{Global %}</code></td>
<td>
<p>the percent of the term's occurrences in all terms occurrences in the corpus.</p>
</td></tr>
<tr><td><code>\dQuote{Level}</code></td>
<td>
<p>the number of occurrences of the term in the level (&ldquo;internal&rdquo;).</p>
</td></tr>
<tr><td><code>\dQuote{Global}</code></td>
<td>
<p>the number of occurrences of the term in the corpus.</p>
</td></tr>
<tr><td><code>\dQuote{t value}</code></td>
<td>
<p>the quantile of a normal distribution corresponding the probability &ldquo;Prob.&rdquo;.</p>
</td></tr>
<tr><td><code>\dQuote{Prob.}</code></td>
<td>
<p>the probability of observing such an extreme (high or low) number of occurrences of the
term in the level, under an hypergeometric distribution.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Milan Bouchet-Valat</p>


<h3>See Also</h3>

<p><code><a href="#topic+frequentTerms">frequentTerms</a></code>, <code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>, <code><a href="tm.html#topic+removeSparseTerms">removeSparseTerms</a></code></p>

<hr>
<h2 id='specificTermsDlg'>List terms specific of a document or level</h2><span id='topic+specificTermsDlg'></span>

<h3>Description</h3>

<p>List terms most associated (positively or negatively) with each document or each
of a variable's levels.</p>


<h3>Details</h3>

<p>Specific terms reported here are those whose observed frequency in the document or level has
the lowest probability under an hypergeometric distribution, based on their global frequencies
in the corpus and on the number of occurrences in the document or variable level considered.
The positive or negative character of the association is visible from the sign of the t value,
or by comparing the value of the &ldquo;% Term/Level&rdquo; column with that of the &ldquo;Global %&rdquo;
column.
</p>
<p>All terms with a probability below the value chosen using the first slider are reported, ignoring
terms with fewer occurrences in the whole corpus than the value of the second slider (these terms
can often have a low probability but are too rare to be of interest). The last slider allows limiting
the number of terms that will be shown for each level.
</p>
<p>The result is a list of matrices, one for each level of the chosen variable, with seven columns:
</p>

<dl>
<dt>&ldquo;% Term/Level&rdquo;:</dt><dd><p>the percent of the term's occurrences in all terms occurrences in the level.</p>
</dd>
<dt>&ldquo;% Level/Term&rdquo;:</dt><dd><p>the percent of the term's occurrences that appear in the level
(rather than in other levels).</p>
</dd>
<dt>&ldquo;Global %&rdquo;:</dt><dd><p>the percent of the term's occurrences in all terms occurrences in the corpus.</p>
</dd>
<dt>&ldquo;Level&rdquo;:</dt><dd><p>the number of occurrences of the term in the level (&ldquo;internal&rdquo;).</p>
</dd>
<dt>&ldquo;Global&rdquo;:</dt><dd><p>the number of occurrences of the term in the corpus.</p>
</dd>
<dt>&ldquo;t value&rdquo;:</dt><dd><p>the quantile of a normal distribution corresponding the probability &ldquo;Prob.&rdquo;.</p>
</dd>
<dt>&ldquo;Prob.&rdquo;:</dt><dd><p>the probability of observing such an extreme (high or low) number of occurrences of
the term in the level, under an hypergeometric distribution.</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+specificTerms">specificTerms</a></code>, <code><a href="#topic+setCorpusVariables">setCorpusVariables</a></code>, <code><a href="tm.html#topic+meta">meta</a></code>,
<code><a href="#topic+restrictTermsDlg">restrictTermsDlg</a></code>, <code><a href="#topic+termsDictionary">termsDictionary</a></code> </p>

<hr>
<h2 id='subsetCorpusByTermsDlg'>Subset Corpus by Terms</h2><span id='topic+subsetCorpusByTermsDlg'></span><span id='topic+restoreCorpus'></span>

<h3>Description</h3>

<p>Create a subset of the corpus by retaining only the documents which contain (or not)
specified terms.</p>


<h3>Details</h3>

<p>This operation will restrict the corpus, document-term matrix and the &ldquo;corpusVars&rdquo;
data set so that they only contain documents with at least the chosen number of occurrences
of at least one term from the first list (occurrences are for each term separately),
<em>and</em> with less than the chosen number of occurrences of each of the terms from the
second list. Both conditions must be fulfilled for a document to be retained. Previously
run analyses like correspondence analysis or hierarchical clustering are removed to prevent
confusion.
</p>
<p>If you choose to save the original corpus, you will be able to restore it later from the
Text mining -&gt; Subset corpus -&gt; Restore original corpus menu. Warning: checking this option
will erase an existing backup if present. Like subsetting, restoring the original corpus
removes existing correspondence analysis and hierarchical clustering objects.
</p>
<p>If you specify both terms that should and terms that should not be present, or if all documents
contain a term that should be excluded, it is possible that no document matches this condition,
in which case an error is produced before subsetting the corpus.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+setCorpusVariables">setCorpusVariables</a></code>, <code><a href="tm.html#topic+meta">meta</a></code>, <code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code></p>

<hr>
<h2 id='subsetCorpusByVarDlg'>Subset Corpus by Levels of a Variable</h2><span id='topic+subsetCorpusByVarDlg'></span>

<h3>Description</h3>

<p>Create a subset of the corpus by retaining only the documents for which the chosen
variable is equal to specified levels.</p>


<h3>Details</h3>

<p>This operation will restrict the corpus, document-term matrix and the &ldquo;corpusVars&rdquo;
data set so that they only contain documents with or without specified terms.
Previously run analyses like correspondence analysis or hierarchical clustering will be
removed to prevent confusion.
</p>
<p>If you choose to save the original corpus, you will be able to restore it later from the
Text mining -&gt; Subset corpus -&gt; Restore original corpus menu. Warning: checking this option
will erase an existing backup if present. Like subsetting, restoring the original corpus
removes existing correspondence analysis and hierarchical clustering objects.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+setCorpusVariables">setCorpusVariables</a></code>, <code><a href="tm.html#topic+meta">meta</a></code>, <code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code></p>

<hr>
<h2 id='termCoocDlg'>Show co-occurrent terms</h2><span id='topic+termCoocDlg'></span>

<h3>Description</h3>

<p>Show terms that are the most associated with one or several reference terms.</p>


<h3>Details</h3>

<p>This dialog allows printing the terms that are most associated with one or several
given terms, according to the document-term matrix of the corpus. Co-occurrent terms
are those which are specific to documents which contain the given term(s). The output
is the same as that returned by the &ldquo;Terms specific of levels...&rdquo; dialog
(see <code><a href="#topic+specificTermsDlg">specificTermsDlg</a></code>), using a dummy variable indicating whether the term
is present or not in each document.
</p>
<p>When a variable is selected, the operation is run separately on each sub-matrix constituted
by the documents that are members of the variable level. If the term does not appear in a
level, <code>NA</code> is returned.
</p>
<p>When several terms are entered, the operation is simply run several times separately.
</p>
<p>The result is either a matrix (when <code>variable = NULL</code>) or a list of matrices,
one for each level of the chosen variable, with seven columns:
</p>

<dl>
<dt>&ldquo;% Term/Cooc.&rdquo;:</dt><dd><p>the percent of the term's occurrences in all terms occurrences
in documents where the chosen term is also present.</p>
</dd>
<dt>&ldquo;% Cooc./Term&rdquo;:</dt><dd><p>the percent of the term's occurrences that appear in documents
where the chosen term is also present (rather than in documents where it does not appear),
i.e. the percent of cooccurrences for the term.</p>
</dd>
<dt>&ldquo;Global %&rdquo; or &ldquo;Level %&rdquo;:</dt><dd><p>the percent of the term's occurrences
in all terms occurrences in the corpus (or in the subset of the corpus
corresponding to the variable level).</p>
</dd>
<dt>&ldquo;Cooc.&rdquo;:</dt><dd><p>the number of cooccurrences of the term.</p>
</dd>
<dt>&ldquo;Global&rdquo; or &ldquo;Level&rdquo;:</dt><dd><p>the number of occurrences of the term in the corpus
(or in the subset of the corpus corresponding to the variable level).</p>
</dd>
<dt>&ldquo;t value&rdquo;:</dt><dd><p>the quantile of a normal distribution corresponding the probability &ldquo;Prob.&rdquo;.</p>
</dd>
<dt>&ldquo;Prob.&rdquo;:</dt><dd><p>the probability of observing such an extreme (high or low) number of occurrences of
the term in documents where the chosen term is also present, under an hypergeometric distribution.</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+specificTermsDlg">specificTermsDlg</a></code>, <code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>,
<code><a href="#topic+restrictTermsDlg">restrictTermsDlg</a></code>, <code><a href="#topic+termsDictionary">termsDictionary</a></code>,
<code><a href="#topic+freqTermsDlg">freqTermsDlg</a></code> </p>

<hr>
<h2 id='termFreqDlg'>Term frequencies in the corpus</h2><span id='topic+termFreqDlg'></span>

<h3>Description</h3>

<p>Study frequencies of chosen terms in the corpus, among documents, or among levels of
a variable.</p>


<h3>Details</h3>

<p>This dialog allows creating a table providing information about the frequency of chosen
terms among documents or levels of a variable. If &ldquo;None (whole corpus)&rdquo; is selected,
the absolute frequency of the chosen terms and their percents in occurrences of all terms
in the corpus are returned. If &ldquo;Document&rdquo; or a variable is chosen, details about the
association of the term with documents or levels are shown:
</p>

<dl>
<dt>&ldquo;% Term/Level&rdquo;:</dt><dd><p>the percent of the term's occurrences in all terms occurrences in the level.</p>
</dd>
<dt>&ldquo;% Level/Term&rdquo;:</dt><dd><p>the percent of the term's occurrences that appear in the level
(rather than in other levels).</p>
</dd>
<dt>&ldquo;Global %&rdquo;:</dt><dd><p>the percent of the term's occurrences in all terms occurrences in the corpus.</p>
</dd>
<dt>&ldquo;Level&rdquo;:</dt><dd><p>the number of occurrences of the term in the level (&ldquo;internal&rdquo;).</p>
</dd>
<dt>&ldquo;Global&rdquo;:</dt><dd><p>the number of occurrences of the term in the corpus.</p>
</dd>
<dt>&ldquo;t value&rdquo;:</dt><dd><p>the quantile of a normal distribution corresponding the probability &ldquo;Prob.&rdquo;.</p>
</dd>
<dt>&ldquo;Prob.&rdquo;:</dt><dd><p>the probability of observing such an extreme (high or low) number of occurrences of
the term in the level, under an hypergeometric distribution.</p>
</dd>
</dl>

<p>The probability is that of observing such extreme frequencies of the considered term in the level,
under an hypergeometric distribution based on its global frequency in the corpus and on the
number of occurrences of all terms in the document or variable level considered.
The positive or negative character of the association is visible from the sign of the t value,
or by comparing the value of the &ldquo;% Term/Level&rdquo; column with that of the &ldquo;Global %&rdquo;
column.
</p>
<p>The kind of plot to be drawn is automatically chosen from the selected measure. Row
percents lead to bar plots, since the total sum of shown columns (terms) doesn't add up
to 100
to be drawn. Absolute counts are also represented with bar plots, so that the vertical
axis reports number of occurrences.
</p>
<p>When either several pie charts are drawn for each word, or a single word has been entered,
the string &ldquo;%T&rdquo; in the plot title will be replaced with the name of the term.
In all cases, the string &ldquo;%V&rdquo; will be replaced with the name of the selected variable.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+termFrequencies">termFrequencies</a></code>, <code><a href="#topic+setCorpusVariables">setCorpusVariables</a></code>, <code><a href="tm.html#topic+meta">meta</a></code>,
<code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>, <code><a href="lattice.html#topic+barchart">barchart</a></code>, <code><a href="graphics.html#topic+pie">pie</a></code> </p>

<hr>
<h2 id='termFrequencies'>Frequency of chosen terms in the corpus</h2><span id='topic+termFrequencies'></span>

<h3>Description</h3>

<p>List terms with the highest number of occurrences in the document-term matrix of a corpus,
possibly grouped by the levels of a variable.</p>


<h3>Usage</h3>

<pre><code class='language-R'>termFrequencies(dtm, terms, variable = NULL, n = 25, by.term = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="termFrequencies_+3A_dtm">dtm</code></td>
<td>
<p>a document-term matrix.</p>
</td></tr>
<tr><td><code id="termFrequencies_+3A_terms">terms</code></td>
<td>
<p>one or more terms, i.e. column names of <code>dtm</code>.</p>
</td></tr>
<tr><td><code id="termFrequencies_+3A_variable">variable</code></td>
<td>
<p>a vector whose length is the number of rows of <code>dtm</code>, or <code>NULL</code> to report most
frequent terms by document; use <code>NA</code> to report most frequent terms in the whole corpus.</p>
</td></tr>
<tr><td><code id="termFrequencies_+3A_n">n</code></td>
<td>
<p>the number of terms to report for each level.</p>
</td></tr>
<tr><td><code id="termFrequencies_+3A_by.term">by.term</code></td>
<td>
<p>whether the third dimension of the array should be terms instead of levels.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability is that of observing such extreme frequencies of the considered term in the level,
under an hypergeometric distribution based on its global frequency in the corpus and on the
number of occurrences of all terms in the document or variable level considered.
The positive or negative character of the association is visible from the sign of the t value,
or by comparing the value of the &ldquo;% Term/Level&rdquo; column with that of the &ldquo;Global %&rdquo;
column.
</p>


<h3>Value</h3>

<p>If <code>variable = NA</code>, one matrix with columns &ldquo;Global&rdquo; and <code>Global %</code> (see below).
Else, an array with seven columns:
</p>
<table role = "presentation">
<tr><td><code>\dQuote{% Term/Level}</code></td>
<td>
<p>the percent of the term's occurrences in all terms occurrences in the level.</p>
</td></tr>
<tr><td><code>\dQuote{% Level/Term}</code></td>
<td>
<p>the percent of the term's occurrences that appear in the level
(rather than in other levels).</p>
</td></tr>
<tr><td><code>\dQuote{Global %}</code></td>
<td>
<p>the percent of the term's occurrences in all terms occurrences in the corpus.</p>
</td></tr>
<tr><td><code>\dQuote{Global}</code></td>
<td>
<p>the number of occurrences of the term in the corpus.</p>
</td></tr>
<tr><td><code>\dQuote{Level}</code></td>
<td>
<p>the number of occurrences of the term (&ldquo;internal&rdquo;).</p>
</td></tr>
<tr><td><code>\dQuote{t value}</code></td>
<td>
<p>the quantile of a normal distribution corresponding the probability &ldquo;Prob.&rdquo;.</p>
</td></tr>
<tr><td><code>\dQuote{Prob.}</code></td>
<td>
<p>the probability of observing such an extreme (high or low) number of occurrences of the
term in the level, under an hypergeometric distribution.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Milan Bouchet-Valat</p>


<h3>See Also</h3>

<p><code><a href="#topic+specificTerms">specificTerms</a></code>, <code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code></p>

<hr>
<h2 id='termsDictionary'>Dictionary of terms found in a corpus</h2><span id='topic+termsDictionary'></span><span id='topic+termsDictionaryAlpha'></span><span id='topic+termsDictionaryOcc'></span>

<h3>Description</h3>

<p>List all of the words that were found in the corpus, and stemmed terms present
in the document-term matrix, together with their number of occurrences.</p>


<h3>Usage</h3>

<pre><code class='language-R'>termsDictionary(dtm, order = c("alphabetic", "occurrences"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="termsDictionary_+3A_dtm">dtm</code></td>
<td>
<p>a document-term matrix.</p>
</td></tr>
<tr><td><code id="termsDictionary_+3A_order">order</code></td>
<td>
<p>whether to sort words alphabetically, or by number of (stemmed) occurrences.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Words found in the corpus before stopwords removal and stemming are printed, together with
the corresponding stemmed term that was eventually added to the document-term matrix, if stemming
was enabled. Occurrences found before and after stemming are also shown.
</p>
<p>The column &ldquo;Stopword?&rdquo; indicates whether the corresponding word is present in the list
of stopwords for the corpus language. Words that were actually removed, either automatically by
stopwords removal at import time, or manually via the Text mining-&gt;Terms-&gt;Exclude terms from analysis...
menu, are signalled in the &ldquo;Removed?&rdquo; column. All other words are present in the final
document-term matrix, in their original or in their stemmed form.
</p>


<h3>See Also</h3>

<p><code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>, <code><a href="#topic+restrictTermsDlg">restrictTermsDlg</a></code>, <code><a href="#topic+freqTermsDlg">freqTermsDlg</a></code>,
<code><a href="#topic+termCoocDlg">termCoocDlg</a></code> </p>

<hr>
<h2 id='termTimeSeriesDlg'>Temporal Evolution of Occurrences</h2><span id='topic+termTimeSeriesDlg'></span>

<h3>Description</h3>

<p>Variation over time of frequencies of one or several terms in the corpus, or of one
term by levels of a variable.</p>


<h3>Details</h3>

<p>This dialog allows computing and plotting the absolute number or row/column percent 
of occurrences of terms over a time  variable, or of one term by levels of a variable.
The format used by the chosen time variable has to be specified so that it is handled
correctly. The format codes allowed are those recognized  by <code><a href="base.html#topic+strptime">strptime</a></code>
(see <code>?strptime</code>), in particular:
</p>

<dl>
<dt>&lsquo;%a&rsquo;</dt><dd><p>Abbreviated weekday name in the current locale. (Also
matches full name.)</p>
</dd>
<dt>&lsquo;%A&rsquo;</dt><dd><p>Full weekday name in the current locale. (Also matches
abbreviated name.)</p>
</dd>
<dt>&lsquo;%b&rsquo;</dt><dd><p>Abbreviated month name in the current locale. (Also matches
full name.)</p>
</dd>
<dt>&lsquo;%B&rsquo;</dt><dd><p>Full month name in the current locale. (Also matches
abbreviated name.)</p>
</dd>
<dt>&lsquo;%d&rsquo;</dt><dd><p>Day of the month as decimal number (01-31).</p>
</dd>
<dt>&lsquo;%H&rsquo;</dt><dd><p>Hours as decimal number (00-23).</p>
</dd>
<dt>&lsquo;%I&rsquo;</dt><dd><p>Hours as decimal number (01-12).</p>
</dd>
<dt>&lsquo;%m&rsquo;</dt><dd><p>Month as decimal number (01-12).</p>
</dd>
<dt>&lsquo;%M&rsquo;</dt><dd><p>Minute as decimal number (00-59).</p>
</dd>
<dt>&lsquo;%U&rsquo;</dt><dd><p>Week of the year as decimal number (00-53) using Sunday as
the first day 1 of the week (and typically with the first
Sunday of the year as day 1 of week 1).  The US convention.</p>
</dd>
<dt>&lsquo;%W&rsquo;</dt><dd><p>Week of the year as decimal number (00-53) using Monday as
the first day 1 of the week (and typically with the first
Monday of the year as day 1 of week 1).  The UK convention.</p>
</dd>
<dt>&lsquo;%p&rsquo;</dt><dd><p>AM/PM indicator in the locale.  Used in conjunction with &lsquo;%I&rsquo;
and not with &lsquo;%H&rsquo;.</p>
</dd>
<dt>&lsquo;%S&rsquo;</dt><dd><p>Second as decimal number (00-61).</p>
</dd>
<dt>&lsquo;%y&rsquo;</dt><dd><p>Year without century (00-99).</p>
</dd>
<dt>&lsquo;%Y&rsquo;</dt><dd><p>Year with century.</p>
</dd>
</dl>

<p>&ldquo;Time units&rdquo; are chosen automatically according to the values of the time variable:
it is set to the smallest unit in which all time values can be uniquely expressed.
For example, if free dates are entered, the unit will be days; if times are entered but minutes
are always 0, hours will be used; finally, if times are fully specified, seconds will be used as
the time unit. The chosen unit appears in the vertical axis label of the plot.
</p>
<p>Three measures of term occurrences are provided (when no variable is selected, &ldquo;category&rdquo;
below corresponds to the whole corpus):<br />
</p>

<ul>
<li><p>Row percent corresponds to the part of chosen term's occurrences over all terms
found in a given category (i.e., the sum of word counts of all documents from the category 
after processing) at each time point. This conceptually corresponds to line percents,
except that only the columns of the document-term matrix that match the given terms are shown.
</p>
</li>
<li><p>Column percent corresponds to the part of the chosen term's occurrences that
appear in each of the documents from a given category at each time point. This measure
corresponds to the strict definition of column percents.
</p>
</li>
<li><p>Absolute counts returns the relevant part of the document-term matrix, but summed
after grouping documents according to their category.
</p>
</li></ul>

<p>The rolling mean is left-aligned, meaning that the number of documents reported for a
point reflects the average of the values of the points occurring <em>after</em> it. When percents
of occurrences are plotted, time units with no occurrence in the corpus are not plotted, since they
have no defined value (0/0, reported as <code>NaN</code>); when a rolling mean is applied, the values
are simply ignored, i.e. the mean is computed over the chosen window without the missing points.</p>


<h3>See Also</h3>

<p><code><a href="#topic+setCorpusVariables">setCorpusVariables</a></code>, <code><a href="tm.html#topic+meta">meta</a></code>, <code><a href="zoo.html#topic+zoo">zoo</a></code>, <code><a href="lattice.html#topic+xyplot">xyplot</a></code>,
<code><a href="#topic+varTimeSeriesDlg">varTimeSeriesDlg</a></code>, <code><a href="#topic+recodeTimeVarDlg">recodeTimeVarDlg</a></code> </p>

<hr>
<h2 id='varCrossTableDlg'>Two-way table of corpus meta-data variables</h2><span id='topic+varCrossTableDlg'></span>

<h3>Description</h3>

<p>Build a two-way contingency table from a corpus's meta-data variables,
optionally plotting the result.</p>


<h3>Details</h3>

<p>This dialog provides a simple way of computing frequencies from a single meta-data
variable of a <span class="pkg">tm</span> corpus. It is merely a wrapper around different steps available from
the Statistics and Plot menus, but operating on the corpus meta-data instead of the active
data set.
</p>
<p>Plots are grouped according to the variable over which percentages are built (the first one
for row percent, the second one for column percent), or according to the first variable if absolute counts
are plotted. Thus, one can tweak grouping by changing either the order of the variables, or
the type of computed percent.</p>


<h3>See Also</h3>

<p><code><a href="#topic+setCorpusVariables">setCorpusVariables</a></code>, <code><a href="tm.html#topic+meta">meta</a></code>, <code><a href="base.html#topic+table">table</a></code>,
<code><a href="lattice.html#topic+barchart">barchart</a></code></p>

<hr>
<h2 id='varTableDlg'>One-way table of a corpus meta-data variable</h2><span id='topic+varTableDlg'></span>

<h3>Description</h3>

<p>Build a one-way contingency table from a corpus's meta-data variable,
optionally plotting the result.</p>


<h3>Details</h3>

<p>This dialog provides a simple way of computing frequencies from a single meta-data
variable of a <span class="pkg">tm</span> corpus. It is merely a wrapper around different steps available from
the Statistics and Plot menus, but operating on the corpus meta-data instead of the active
data set.</p>


<h3>See Also</h3>

<p><code><a href="#topic+setCorpusVariables">setCorpusVariables</a></code>, <code><a href="tm.html#topic+meta">meta</a></code>, <code><a href="base.html#topic+table">table</a></code>,
<code><a href="lattice.html#topic+barchart">barchart</a></code> </p>

<hr>
<h2 id='varTimeSeriesDlg'>Corpus Temporal Evolution</h2><span id='topic+varTimeSeriesDlg'></span>

<h3>Description</h3>

<p>Variation of the number of documents in the corpus over time, possibly grouped
by variable.</p>


<h3>Details</h3>

<p>This dialog allows computing and plotting the number of documents over a time variable.
The format used by the chosen time variable has to be specified so that it is handled
correctly. The format codes allowed are those recognized  by <code><a href="base.html#topic+strptime">strptime</a></code>
(see <code>?strptime</code>), in particular:
</p>

<dl>
<dt>&lsquo;%a&rsquo;</dt><dd><p>Abbreviated weekday name in the current locale. (Also
matches full name.)</p>
</dd>
<dt>&lsquo;%A&rsquo;</dt><dd><p>Full weekday name in the current locale. (Also matches
abbreviated name.)</p>
</dd>
<dt>&lsquo;%b&rsquo;</dt><dd><p>Abbreviated month name in the current locale. (Also matches
full name.)</p>
</dd>
<dt>&lsquo;%B&rsquo;</dt><dd><p>Full month name in the current locale. (Also matches
abbreviated name.)</p>
</dd>
<dt>&lsquo;%d&rsquo;</dt><dd><p>Day of the month as decimal number (01-31).</p>
</dd>
<dt>&lsquo;%H&rsquo;</dt><dd><p>Hours as decimal number (00-23).</p>
</dd>
<dt>&lsquo;%I&rsquo;</dt><dd><p>Hours as decimal number (01-12).</p>
</dd>
<dt>&lsquo;%m&rsquo;</dt><dd><p>Month as decimal number (01-12).</p>
</dd>
<dt>&lsquo;%M&rsquo;</dt><dd><p>Minute as decimal number (00-59).</p>
</dd>
<dt>&lsquo;%U&rsquo;</dt><dd><p>Week of the year as decimal number (00-53) using Sunday as
the first day 1 of the week (and typically with the first
Sunday of the year as day 1 of week 1).  The US convention.</p>
</dd>
<dt>&lsquo;%W&rsquo;</dt><dd><p>Week of the year as decimal number (00-53) using Monday as
the first day 1 of the week (and typically with the first
Monday of the year as day 1 of week 1).  The UK convention.</p>
</dd>
<dt>&lsquo;%p&rsquo;</dt><dd><p>AM/PM indicator in the locale.  Used in conjunction with &lsquo;%I&rsquo;
and not with &lsquo;%H&rsquo;.</p>
</dd>
<dt>&lsquo;%S&rsquo;</dt><dd><p>Second as decimal number (00-61).</p>
</dd>
<dt>&lsquo;%y&rsquo;</dt><dd><p>Year without century (00-99).</p>
</dd>
<dt>&lsquo;%Y&rsquo;</dt><dd><p>Year with century.</p>
</dd>
</dl>

<p>&ldquo;Time units&rdquo; are chosen automatically according to the values of the time variable:
it is set to the smallest unit in which all time values can be uniquely expressed.
For example, if free dates are entered, the unit will be days; if times are entered but minutes
are always 0, hours will be used; finally, if times are fully specified, seconds will be used as
the time unit. The chosen unit appears in the vertical axis label of the plot.
</p>
<p>The rolling mean is left-aligned, meaning that the number of documents reported for a
point reflects the average of the values of the points occurring <em>after</em> it. When percents
of documents are plotted, time units with no document in the corpus are not plotted, since they
have no defined value (0/0, reported as <code>NaN</code>); when a rolling mean is applied, the values
are simply ignored, i.e. the mean is computed over the chosen window without the missing points.</p>


<h3>See Also</h3>

<p><code><a href="#topic+setCorpusVariables">setCorpusVariables</a></code>, <code><a href="tm.html#topic+meta">meta</a></code>, <code><a href="zoo.html#topic+zoo">zoo</a></code>, <code><a href="lattice.html#topic+xyplot">xyplot</a></code>,
<code><a href="#topic+varTimeSeriesDlg">varTimeSeriesDlg</a></code>, <code><a href="#topic+recodeTimeVarDlg">recodeTimeVarDlg</a></code> </p>

<hr>
<h2 id='vocabularyDlg'>Vocabulary Summary</h2><span id='topic+vocabularyDlg'></span>

<h3>Description</h3>

<p>Build vocabulary summary table over documents or a meta-data variable of a corpus.</p>


<h3>Details</h3>

<p>This dialog allows creating tables providing several vocabulary measures
for each document of a corpus, or each of the categories of a corpus variable:
</p>

<ul>
<li><p>total number of terms
</p>
</li>
<li><p>number and percent of unique words, i.e. of words appearing at least once
</p>
</li>
<li><p>number and percent of hapax legomena, i.e. terms appearing once and only once
</p>
</li>
<li><p>total number of words
</p>
</li>
<li><p>number and percent of long words (&ldquo;long&rdquo; being defined as &ldquo;at
least 7 characters&rdquo;
</p>
</li>
<li><p>number and percent of very long words (&ldquo;very long&rdquo; being defined as
&lsquo;at least 10 characters&rsquo;
</p>
</li>
<li><p>average word length
</p>
</li></ul>

<p><em>Words</em> are defined as the forms of two or more characters present in the texts
before stemming and stopword removal. On the contrary, unique <em>terms</em> are extracted
from the global document-term matrix, which means they do not include words that were
removed by treatments ran at the import step, and that words different in the original
text might become identical terms if stemming was performed. This can be considered the
&ldquo;correct&rdquo; measure, since the purpose of corpus processing is exactly that: mark
different forms of the same term as similar to allow for statistical analyses.
</p>
<p>Two different units can be selected for the analysis. If &ldquo;Document&rdquo; is selected, values
reported for each level correspond to the mean of the values for each of its documents;
a mean column for the whole corpus is also provided. If &ldquo;Level&rdquo; is selected, these values
correspond to the sum of the number of terms for each of the categories' documents,
to the percentage of terms (ratio of the summed numbers of terms) and the average word
length of the level when taken as a single document. Both versions of this measure are
legitimate, but prompt different interpretations that should not be confused; on the contrary,
interpretation of the summed or mean number of (long) terms is immediate.
</p>
<p>This distinction does not make sense when documents (not levels of a variable) are used as the
unit of analysis: in this case, &ldquo;level&rdquo; in the above explanation corresponds to
&ldquo;document&rdquo;, and two columns are provided about the whole corpus. &ldquo;Corpus mean&rdquo;
is simply the average value of measures over all documents; &ldquo;Corpus total&rdquo; is the sum
of the number of terms, the percentage of terms  (ratio of the summed numbers of terms)
and the average word length in the corpus when taken as a single document. See
<code><a href="#topic+vocabularyTable">vocabularyTable</a></code> for more details.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vocabularyTable">vocabularyTable</a></code>, <code><a href="#topic+setCorpusVariables">setCorpusVariables</a></code>,
<code><a href="tm.html#topic+meta">meta</a></code>, <code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>, <code><a href="base.html#topic+table">table</a></code>,
<code><a href="lattice.html#topic+barchart">barchart</a></code> </p>

<hr>
<h2 id='vocabularyTable'>Vocabulary summary table</h2><span id='topic+vocabularyTable'></span>

<h3>Description</h3>

<p>Build a table summarizing vocabulary, optionally over a variable.</p>


<h3>Usage</h3>

<pre><code class='language-R'>vocabularyTable(termsDtm, wordsDtm, variable = NULL, unit = c("document", "global"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vocabularyTable_+3A_termsdtm">termsDtm</code></td>
<td>
<p>A document-term matrix containing terms (i.e. extracted from a possibly stemmed corpus).</p>
</td></tr>
<tr><td><code id="vocabularyTable_+3A_wordsdtm">wordsDtm</code></td>
<td>
<p>A document-term matrix contaning words (i.e. extracted from a plain corpus).</p>
</td></tr>
<tr><td><code id="vocabularyTable_+3A_variable">variable</code></td>
<td>
<p>A vector of the same length as <code>lengthDtm</code> giving indexes according
to which categories should be defined. If <code>NULL</code>, per-document measures
are returned.</p>
</td></tr>
<tr><td><code id="vocabularyTable_+3A_unit">unit</code></td>
<td>
<p>When <code>variable</code> is not <code>NULL</code>, defines the way measures are aggregated
(see below).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This dialog allows creating tables providing several vocabulary measures
for each document or each category of documents in the corpus:
</p>

<ul>
<li><p>total number of terms
</p>
</li>
<li><p>number and percent of unique terms (i.e. appearing at least once)
</p>
</li>
<li><p>number and percent of hapax legomena (i.e. terms appearing once and only once)
</p>
</li>
<li><p>total number of words
</p>
</li>
<li><p>number and percent of long words (&ldquo;long&rdquo; being defined as &ldquo;at
least seven characters&rdquo;
</p>
</li>
<li><p>number and percent of very long words (&ldquo;very long&rdquo; being defined as
&ldquo;at least ten characters&rdquo;
</p>
</li>
<li><p>average word length
</p>
</li></ul>

<p><em>Words</em> are defined as the forms of two or more characters present in the texts
before stemming and stopword removal. On the contrary, unique <em>terms</em> are extracted
from the global document-term matrix, which means they do not include words that were
removed by treatments ran at the import step, and that words different in the original
text might become identical terms if stemming was performed. This can be considered the
&ldquo;correct&rdquo; measure, since the purpose of corpus processing is exactly that: mark
different forms of the same term as similar to allow for statistical analyses.
</p>
<p>Please note that percentages for <em>terms</em> and <em>words</em> are computed with regard
respectively to the total number of terms and of words, so the denominators are not the
same for all measures. See <code><a href="#topic+vocabularyDlg">vocabularyDlg</a></code>.
</p>
<p>When <code>variable</code> is not <code>NULL</code>, <code>unit</code> defines two different ways of
aggregating per-document statistics into per-category measures:
</p>

<ul>
<li><p><code>document</code>: Values computed for each document are simply averaged for
each category.
</p>
</li>
<li><p><code>global</code>: Values are computed for each category taken as a whole: word
counts are summed for each category, and ratios and average
are calculated for this level only, from the summed counts.
</p>
</li></ul>

<p>In both cases, the &ldquo;Corpus&rdquo; column follows the above definition.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vocabularyDlg">vocabularyDlg</a></code>, code<a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a>, <code><a href="base.html#topic+table">table</a></code>, </p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
