<!DOCTYPE html><html lang="en"><head><title>Help for package nzilbb.vowels</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {nzilbb.vowels}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#nzilbb.vowels-package'><p>nzilbb.vowels: Vowel Covariation Tools</p></a></li>
<li><a href='#correlation_test'><p>Permutation test of pairwise correlations</p></a></li>
<li><a href='#lobanov_2'><p>Apply Lobanov 2.0 normalisation</p></a></li>
<li><a href='#mds_test'><p>Test optimal number of MDS dimensions.</p></a></li>
<li><a href='#onze_intercepts'><p>Speaker random intercepts from GAMMs for 100 ONZE speakers</p></a></li>
<li><a href='#onze_intercepts_full'><p>Speaker random intercepts for 418 ONZE speakers</p></a></li>
<li><a href='#onze_vowels'><p>Monophthong data for random sample of speakers from the ONZE corpus</p></a></li>
<li><a href='#onze_vowels_full'><p>Monophthong data for speakers from the ONZE corpus</p></a></li>
<li><a href='#pc_flip'><p>Flip PC loadings</p></a></li>
<li><a href='#pca_contrib_plot'><p>PCA contribution plots</p></a></li>
<li><a href='#pca_test'><p>PCA with confidence intervals and null distributions</p></a></li>
<li><a href='#permutation_test'><p>Run permutation test on PCA analysis.</p></a></li>
<li><a href='#plot_correlation_counts'><p>Plot of correlation counts from <code>correlation_test</code> object</p></a></li>
<li><a href='#plot_correlation_magnitudes'><p>Plot distribution of correlations from <code>correlation_test</code> object</p></a></li>
<li><a href='#plot_loadings'><p>Plot PC index loadings from <code>pca_test</code> object.</p></a></li>
<li><a href='#plot_mds_test'><p>Plot <code>mds_test()</code> results</p></a></li>
<li><a href='#plot_pc_input'><p>Plot Scores from Significant PCs Against PCA Input</p></a></li>
<li><a href='#plot_pc_vs'><p>Plot PC loadings in vowel space</p></a></li>
<li><a href='#plot_permutation_test'><p>Create plot from <code>permutation_test()</code>.</p></a></li>
<li><a href='#plot_variance_explained'><p>Create plot of variances explained from <code>pca_test</code> object</p></a></li>
<li><a href='#plot_vowel_space'><p>Plot vowel space for speaker or speakers.</p></a></li>
<li><a href='#qb_intervals'><p>Formant and amplitude for intervals of QuakeBox monologues</p></a></li>
<li><a href='#qb_vowels'><p>Formants from QuakeBox 1</p></a></li>
<li><a href='#sim_matrix'><p>Similarity matrix from online perception test.</p></a></li>
<li><a href='#summary.correlation_test'><p>Summary function for correlation test object. Set alpha to change</p>
significance level.</a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Vowel Covariation Tools</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Tools to support research on vowel covariation. Methods are provided to
    support Principal Component Analysis workflows (as in Brand et al. (2021) 
    &lt;<a href="https://doi.org/10.1016%2Fj.wocn.2021.101096">doi:10.1016/j.wocn.2021.101096</a>&gt; and Wilson Black et al. (2023) 
    &lt;<a href="https://doi.org/10.1515%2Flingvan-2022-0086">doi:10.1515/lingvan-2022-0086</a>&gt;).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1), patchwork</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2.9000</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat (&ge; 3.0.0), vdiffr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, ggplot2, magrittr, rlang, rstudioapi, tibble, tidyr,
forcats, glue, purrr, tidyselect, rsample, stringr, ggrepel,
gghalves, smacof, Rdpack, lifecycle</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://nzilbb.github.io/nzilbb_vowels/">https://nzilbb.github.io/nzilbb_vowels/</a>,
<a href="https://github.com/nzilbb/nzilbb_vowels">https://github.com/nzilbb/nzilbb_vowels</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/nzilbb/nzilbb_vowels/issues/">https://github.com/nzilbb/nzilbb_vowels/issues/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-11-28 21:13:09 UTC; jbl91</td>
</tr>
<tr>
<td>Author:</td>
<td>Joshua Wilson Black
    <a href="https://orcid.org/0000-0002-8272-5763"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre,
    cph],
  James Brand <a href="https://orcid.org/0000-0002-2853-9169"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Joshua Wilson Black &lt;joshua@wilsonblack.nz&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-11-29 09:40:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='nzilbb.vowels-package'>nzilbb.vowels: Vowel Covariation Tools</h2><span id='topic+nzilbb.vowels'></span><span id='topic+nzilbb.vowels-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>Tools to support research on vowel covariation. Methods are provided to support Principal Component Analysis workflows (as in Brand et al. (2021) <a href="https://doi.org/10.1016/j.wocn.2021.101096">doi:10.1016/j.wocn.2021.101096</a> and Wilson Black et al. (2023) <a href="https://doi.org/10.1515/lingvan-2022-0086">doi:10.1515/lingvan-2022-0086</a>).
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Joshua Wilson Black <a href="mailto:joshua@wilsonblack.nz">joshua@wilsonblack.nz</a> (<a href="https://orcid.org/0000-0002-8272-5763">ORCID</a>) [copyright holder]
</p>
<p>Authors:
</p>

<ul>
<li><p> James Brand <a href="mailto:james.brand.ac@gmail.com">james.brand.ac@gmail.com</a> (<a href="https://orcid.org/0000-0002-2853-9169">ORCID</a>)
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://nzilbb.github.io/nzilbb_vowels/">https://nzilbb.github.io/nzilbb_vowels/</a>
</p>
</li>
<li> <p><a href="https://github.com/nzilbb/nzilbb_vowels">https://github.com/nzilbb/nzilbb_vowels</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/nzilbb/nzilbb_vowels/issues/">https://github.com/nzilbb/nzilbb_vowels/issues/</a>
</p>
</li></ul>


<hr>
<h2 id='correlation_test'>Permutation test of pairwise correlations</h2><span id='topic+correlation_test'></span>

<h3>Description</h3>

<p>Permute data a given number (n) of times, collecting pairwise correlations
and testing them for significance. See <code><a href="#topic+plot_correlation_magnitudes">plot_correlation_magnitudes()</a></code> and
<code><a href="#topic+plot_correlation_counts">plot_correlation_counts()</a></code> for plotting functions which take the output of
this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>correlation_test(pca_data, n = 100, cor.method = "pearson")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="correlation_test_+3A_pca_data">pca_data</code></td>
<td>
<p>dataframe or matrix containing only continuous variables.
(as accepted by the <code>prcomp</code> function.)</p>
</td></tr>
<tr><td><code id="correlation_test_+3A_n">n</code></td>
<td>
<p>the number of times (integer) to permute that data. <strong>Warning:</strong>
high values will take a long time to compute. Default: 100.</p>
</td></tr>
<tr><td><code id="correlation_test_+3A_cor.method">cor.method</code></td>
<td>
<p>method to use for correlations (default = &quot;pearson&quot;).
Alternative is &quot;spearman&quot; (see <code>?cor.test</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>object of class <code>correlation_test</code>, with attributes:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;$permuted_correlations&#8288;</code> A tibble of length n of pairs from the original
data, their correlations, and the significance of each correlation (as
p-values).
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$actual_correlations&#8288;</code> the correlations of each pair of variables
in the original data and their significance (as p-values).
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$iterations&#8288;</code> the number of permutations carried out.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$cor_method&#8288;</code> the form of correlation used.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>  # get a small sample of random intercepts.
  pca_data &lt;- onze_intercepts |&gt;
    dplyr::select(-speaker) |&gt;
    dplyr::slice_sample(n=10)

  # apply correlation test with 10 permutations.
  # actual use requires at least 100.
  cor_test &lt;- correlation_test(pca_data, n = 10, cor.method = 'pearson')
  # Return summary of significant correlations
  summary(cor_test)

  # use spearman correlation instead.
  cor_test_spear &lt;- correlation_test(pca_data, n = 10, cor.method = 'spearman')
</code></pre>

<hr>
<h2 id='lobanov_2'>Apply Lobanov 2.0 normalisation</h2><span id='topic+lobanov_2'></span>

<h3>Description</h3>

<p><code>lobanov_2()</code> takes a data frame where the first four columns are:
</p>

<ol>
<li><p> speaker identifiers,
</p>
</li>
<li><p> vowel identifiers,
</p>
</li>
<li><p> first formant values in Hertz,
</p>
</li>
<li><p> second formant values in Hertz.
</p>
</li></ol>

<p>It returns a dataframe with two additional columns, <code>F1_lob2</code> and <code>F2_lob2</code>,
containing normalised formant values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lobanov_2(vowel_data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lobanov_2_+3A_vowel_data">vowel_data</code></td>
<td>
<p>a dataframe whose first four columns are speaker ids,
vowel ids, F1 values, and F2 values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This functions applies Lobanov 2.0 normalisation presented in
Brand et al. (2021). This variant
of Lobanov normalisation is designed to work for datasets whether the vowel
types have different token counts from one
another. The Lobanov 2.0 value for a vowel is given by </p>
<p style="text-align: center;"><code class="reqn">F_{lobanov2.0_i}
= \frac{F_{raw_i} - \mu(\mu_{vowel_1}, \ldots,
\mu_{vowel_n})}{\sigma(\mu_{vowel_1}, \ldots, \mu_{vowel_n})}</code>
</p>
<p> where, for
ease of notation, we assume all values are from a single speaker. We signify
the n vowel types as vowel_1, ..., vowel_2, while i indicates the formant
number. We implement the function for F1 and F2.
</p>


<h3>Value</h3>

<p>a dataframe matching the input dataframe with additional columns
<code>F1_lob2</code> and <code>F2_lob2</code>, containing the lobanov normalised F1 and F2 values
respectively.
</p>


<h3>References</h3>

<p>Brand, James, Jen Hay, Lynn Clark, Kevin Watson &amp; Márton Sóskuthy (2021):
Systematic co-variation of monophthongs across speakers of New Zealand
English. Journal of Phonetics. Elsevier. 88. 101096.
doi:10.1016/j.wocn.2021.101096
</p>


<h3>Examples</h3>

<pre><code class='language-R'>normed_vowels &lt;- lobanov_2(onze_vowels)
head(normed_vowels)

</code></pre>

<hr>
<h2 id='mds_test'>Test optimal number of MDS dimensions.</h2><span id='topic+mds_test'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> Generate bootstrapped confidence intervals and permutation based null
distribution for MDS analysis. Output shows how much stress is reduced by
adding an additional dimension to the MDS analysis of <code>similarity_matrix</code>,
and bootstrapped iterations of <code>similarity_matrix</code>,
compared with the stress reduction expected from a matrix with no meaningful
structure. This function is inspired by <code><a href="#topic+pca_test">pca_test()</a></code>, but is less connected
with statistical literature than that function. We currently reject
additional dimensions is they reduce less stress than we would expect by
chance. That is, when the distribution from the boostrapped analyses sits
notably lower than the permuted distribution when plotted by <code><a href="#topic+plot_mds_test">plot_mds_test()</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mds_test(
  similarity_matrix,
  n_boots = 50,
  n_perms = 50,
  test_dimensions = 5,
  principal = TRUE,
  mds_type = "ordinal",
  spline_degree = 2,
  spline_int_knots = 2
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mds_test_+3A_similarity_matrix">similarity_matrix</code></td>
<td>
<p>Square matrix of speaker similarity scores.</p>
</td></tr>
<tr><td><code id="mds_test_+3A_n_boots">n_boots</code></td>
<td>
<p>Number of bootstrapping iterations (default: 25).</p>
</td></tr>
<tr><td><code id="mds_test_+3A_n_perms">n_perms</code></td>
<td>
<p>Number of permutations (default: 25).</p>
</td></tr>
<tr><td><code id="mds_test_+3A_test_dimensions">test_dimensions</code></td>
<td>
<p>Number of MDS dimensions to test for stress reduction (default: 5).</p>
</td></tr>
<tr><td><code id="mds_test_+3A_principal">principal</code></td>
<td>
<p>Whether to apply principal axis transform to MDS (default: TRUE)</p>
</td></tr>
<tr><td><code id="mds_test_+3A_mds_type">mds_type</code></td>
<td>
<p>What kind of MDS to apply, see <code><a href="smacof.html#topic+smacofSym">smacof::smacofSym()</a></code> (default: 'ordinal')</p>
</td></tr>
<tr><td><code id="mds_test_+3A_spline_degree">spline_degree</code></td>
<td>
<p>How many spline degrees when <code>type</code> is 'mspline' (default: 2)</p>
</td></tr>
<tr><td><code id="mds_test_+3A_spline_int_knots">spline_int_knots</code></td>
<td>
<p>How many internal knots when <code>type</code> is 'mspline' (default: 2)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>object of class <code>mds_test_results</code>, containing:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;$stress_reduction&#8288;</code> a tibble containing
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$n_boots&#8288;</code> Number of bootstrapping iterations.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$n_perms&#8288;</code> Number of permutation iterations
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$mds_type&#8288;</code> Type of MDS analysis (<code>type</code> argument passed to
<code><a href="smacof.html#topic+smacofSym">smacof::smacofSym()</a></code>)
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$principal&#8288;</code> Whether principal axis transformation is applied (passed to
<code><a href="smacof.html#topic+smacofSym">smacof::smacofSym()</a></code>)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Apply interval MDS to `sim_matrix`, with 5 permutations and bootstraps
# testing up to 3 dimensions. In real usage, increase `n_boots` and `n_perms`
# to at least 50.
mds_test(
 sim_matrix,
 n_boots = 5,
 n_perms = 5,
 test_dimensions = 3,
 mds_type = 'interval'
)

</code></pre>

<hr>
<h2 id='onze_intercepts'>Speaker random intercepts from GAMMs for 100 ONZE speakers</h2><span id='topic+onze_intercepts'></span>

<h3>Description</h3>

<p>A dataset containing the speaker intercepts extracted from GAMM models fit in
Brand et al. (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>onze_intercepts
</code></pre>


<h3>Format</h3>

<p>A data frame with 100 rows and 21 variables: </p>

<dl>
<dt>speaker</dt><dd><p>Anonymised speaker code (character).</p>
</dd>
<dt>F1_DRESS</dt><dd><p>Speaker intercept from GAMM model of DRESS F1.</p>
</dd>
<dt>F2_DRESS</dt><dd><p>Speaker intercept from GAMM model of DRESS F2.</p>
</dd>
<dt>F1_FLEECE</dt><dd><p>Speaker intercept from GAMM model of FLEECE F1.</p>
</dd>
<dt>F2_FLEECE</dt><dd><p>Speaker intercept from GAMM model of FLEECE F2.</p>
</dd>
<dt>F1_GOOSE</dt><dd><p>Speaker intercept from GAMM model of GOOSE F1.</p>
</dd>
<dt>F2_GOOSE</dt><dd><p>Speaker intercept from GAMM model of GOOSE F2.</p>
</dd>
<dt>F1_KIT</dt><dd><p>Speaker intercept from GAMM model of KIT F1.</p>
</dd>
<dt>F2_KIT</dt><dd><p>Speaker intercept from GAMM model of KIT F2.</p>
</dd>
<dt>F1_LOT</dt><dd><p>Speaker intercept from GAMM model of LOT F1.</p>
</dd>
<dt>F2_LOT</dt><dd><p>Speaker intercept from GAMM model of LOT F2.</p>
</dd>
<dt>F1_NURSE</dt><dd><p>Speaker intercept from GAMM model of NURSE F1.</p>
</dd>
<dt>F2_NURSE</dt><dd><p>Speaker intercept from GAMM model of NURSE F2.</p>
</dd>
<dt>F1_START</dt><dd><p>Speaker intercept from GAMM model of START F1.</p>
</dd>
<dt>F2_START</dt><dd><p>Speaker intercept from GAMM model of START F2.</p>
</dd>
<dt>F1_STRUT</dt><dd><p>Speaker intercept from GAMM model of STRUT F1.</p>
</dd>
<dt>F2_STRUT</dt><dd><p>Speaker intercept from GAMM model of STRUT F2.</p>
</dd>
<dt>F1_THOUGHT</dt><dd><p>Speaker intercept from GAMM model of THOUGHT F1.</p>
</dd>
<dt>F2_THOUGHT</dt><dd><p>Speaker intercept from GAMM model of THOUGHT F2.</p>
</dd>
<dt>F1_TRAP</dt><dd><p>Speaker intercept from GAMM model of TRAP F1.</p>
</dd>
<dt>F2_TRAP</dt><dd><p>Speaker intercept from GAMM model of TRAP F2.</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://osf.io/q4j29/">https://osf.io/q4j29/</a>
</p>


<h3>References</h3>

<p>Brand, James, Jen Hay, Lynn Clark, Kevin Watson &amp; Márton Sóskuthy (2021):
Systematic co-variation of monophthongs across speakers of New Zealand
English. Journal of Phonetics. Elsevier. 88. 101096.
doi:10.1016/j.wocn.2021.101096
</p>

<hr>
<h2 id='onze_intercepts_full'>Speaker random intercepts for 418 ONZE speakers</h2><span id='topic+onze_intercepts_full'></span>

<h3>Description</h3>

<p>A dataset containing the speaker intercepts extracted from GAMM models fit in
Brand et al. (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>onze_intercepts_full
</code></pre>


<h3>Format</h3>

<p>A data frame with 481 rows and 21 variables: </p>

<dl>
<dt>speaker</dt><dd><p>Anonymised speaker code.</p>
</dd>
<dt>F1_DRESS</dt><dd><p>Speaker intercept from GAMM model of DRESS F1.</p>
</dd>
<dt>F2_DRESS</dt><dd><p>Speaker intercept from GAMM model of DRESS F2.</p>
</dd>
<dt>F1_FLEECE</dt><dd><p>Speaker intercept from GAMM model of FLEECE F1.</p>
</dd>
<dt>F2_FLEECE</dt><dd><p>Speaker intercept from GAMM model of FLEECE F2.</p>
</dd>
<dt>F1_GOOSE</dt><dd><p>Speaker intercept from GAMM model of GOOSE F1.</p>
</dd>
<dt>F2_GOOSE</dt><dd><p>Speaker intercept from GAMM model of GOOSE F2.</p>
</dd>
<dt>F1_KIT</dt><dd><p>Speaker intercept from GAMM model of KIT F1.</p>
</dd>
<dt>F2_KIT</dt><dd><p>Speaker intercept from GAMM model of KIT F2.</p>
</dd>
<dt>F1_LOT</dt><dd><p>Speaker intercept from GAMM model of LOT F1.</p>
</dd>
<dt>F2_LOT</dt><dd><p>Speaker intercept from GAMM model of LOT F2.</p>
</dd>
<dt>F1_NURSE</dt><dd><p>Speaker intercept from GAMM model of NURSE F1.</p>
</dd>
<dt>F2_NURSE</dt><dd><p>Speaker intercept from GAMM model of NURSE F2.</p>
</dd>
<dt>F1_START</dt><dd><p>Speaker intercept from GAMM model of START F1.</p>
</dd>
<dt>F2_START</dt><dd><p>Speaker intercept from GAMM model of START F2.</p>
</dd>
<dt>F1_STRUT</dt><dd><p>Speaker intercept from GAMM model of STRUT F1.</p>
</dd>
<dt>F2_STRUT</dt><dd><p>Speaker intercept from GAMM model of STRUT F2.</p>
</dd>
<dt>F1_THOUGHT</dt><dd><p>Speaker intercept from GAMM model of THOUGHT F1.</p>
</dd>
<dt>F2_THOUGHT</dt><dd><p>Speaker intercept from GAMM model of THOUGHT F2.</p>
</dd>
<dt>F1_TRAP</dt><dd><p>Speaker intercept from GAMM model of TRAP F1.</p>
</dd>
<dt>F2_TRAP</dt><dd><p>Speaker intercept from GAMM model of TRAP F2.</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://osf.io/q4j29/">https://osf.io/q4j29/</a>
</p>


<h3>References</h3>

<p>Brand, James, Jen Hay, Lynn Clark, Kevin Watson &amp; Márton Sóskuthy (2021):
Systematic co-variation of monophthongs across speakers of New Zealand
English. Journal of Phonetics. Elsevier. 88. 101096.
doi:10.1016/j.wocn.2021.101096
</p>

<hr>
<h2 id='onze_vowels'>Monophthong data for random sample of speakers from the ONZE corpus</h2><span id='topic+onze_vowels'></span>

<h3>Description</h3>

<p>A dataset containing the the first and second formants, speech rate,
gender, and year of birth for 100 random speakers from the ONZE corpus.
50 speakers are sampled with birth years before 1900 and 50 sampled with
birth years on or after 1900 to ensure a full span of the time period. Data
is present for the following NZE monophthongs, represented by Wells lexical
sets: DRESS, FLEECE, GOOSE, KIT, LOT, NURSE, START, STRUT, THOUGHT, TRAP. Data
for FOOT is excluded due to low token counts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>onze_vowels
</code></pre>


<h3>Format</h3>

<p>A dataframe with 101572 rows and 8 variables:
</p>

<dl>
<dt>speaker</dt><dd><p>Anonymised speaker code (factor).</p>
</dd>
<dt>vowel</dt><dd><p>Variable with Wells lexical sets for 10 NZE monophthongs. Levels:  DRESS, FLEECE, GOOSE, KIT, LOT, NURSE, START, STRUT, THOUGHT, TRAP (factor).</p>
</dd>
<dt>F1_50</dt><dd><p>First formant, extracted from vowel mid-point using LaBB-CAT interface with Praat.</p>
</dd>
<dt>F2_50</dt><dd><p>Second formant, extracted from vowel mid-point using LaBB-CAT interface with Praat.</p>
</dd>
<dt>speech_rate</dt><dd><p>Average speaker speech rate for whole recording.</p>
</dd>
<dt>gender</dt><dd><p>Gender of speaker, two levels: &quot;M&quot;, &quot;F&quot; (factor).</p>
</dd>
<dt>yob</dt><dd><p>Year of birth of speaker.</p>
</dd>
<dt>word</dt><dd><p>Anonymised word code (factor).</p>
</dd>
</dl>



<h3>Details</h3>

<p>This dataset is derived from the data made available in the supplementary
materials of Brand et al. (2021).
</p>


<h3>Source</h3>

<p><a href="https://osf.io/q4j29/">https://osf.io/q4j29/</a>
</p>


<h3>References</h3>

<p>Brand, James, Jen Hay, Lynn Clark, Kevin Watson &amp; Márton Sóskuthy (2021):
Systematic co-variation of monophthongs across speakers of New Zealand
English. Journal of Phonetics. Elsevier. 88. 101096.
doi:10.1016/j.wocn.2021.101096
</p>

<hr>
<h2 id='onze_vowels_full'>Monophthong data for speakers from the ONZE corpus</h2><span id='topic+onze_vowels_full'></span>

<h3>Description</h3>

<p>A dataset containing the the first and second formants, speech rate,
gender, and year of birth for 481 speakers from the ONZE corpus.
50 speakers are sampled with birth years before 1900 and 50 sampled with
birth years on or after 1900 to ensure a full span of the time period. Data
is present for the following NZE monophthongs, represented by Wells lexical
sets: DRESS, FLEECE, GOOSE, KIT, LOT, NURSE, START, STRUT, THOUGHT, TRAP. Data
for FOOT is excluded due to low token counts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>onze_vowels_full
</code></pre>


<h3>Format</h3>

<p>A data frame with 414679 rows and 8 variables:
</p>

<dl>
<dt>speaker</dt><dd><p>Anonymised speaker code (factor).</p>
</dd>
<dt>vowel</dt><dd><p>Variable with Wells lexical sets for 10 NZE monophthongs. Levels:  DRESS, FLEECE, GOOSE, KIT, LOT, NURSE, START, STRUT, THOUGHT, TRAP (factor).</p>
</dd>
<dt>F1_50</dt><dd><p>First formant, extracted from vowel mid-point using LaBB-CAT interface with Praat.</p>
</dd>
<dt>F2_50</dt><dd><p>Second formant, extracted from vowel mid-point using LaBB-CAT interface with Praat.</p>
</dd>
<dt>speech_rate</dt><dd><p>Average speaker speech rate for whole recording.</p>
</dd>
<dt>gender</dt><dd><p>Gender of speaker, two levels: &quot;M&quot;, &quot;F&quot; (factor).</p>
</dd>
<dt>yob</dt><dd><p>Year of birth of speaker.</p>
</dd>
<dt>word</dt><dd><p>Anonymised word code (factor).</p>
</dd>
</dl>



<h3>Details</h3>

<p>This dataset is derived from the data made available in the supplementary
materials of Brand et al. (2021).
</p>


<h3>Source</h3>

<p><a href="https://osf.io/q4j29/">https://osf.io/q4j29/</a>
</p>


<h3>References</h3>

<p>Brand, James, Jen Hay, Lynn Clark, Kevin Watson &amp; Márton Sóskuthy (2021):
Systematic co-variation of monophthongs across speakers of New Zealand
English. Journal of Phonetics. Elsevier. 88. 101096.
doi:10.1016/j.wocn.2021.101096
</p>

<hr>
<h2 id='pc_flip'>Flip PC loadings</h2><span id='topic+pc_flip'></span>

<h3>Description</h3>

<p>The sign of the loadings and scores generated by PCA is arbitrary. Sometimes
it is convenient to flip them so that all positive loadings/scores become
negative (and vice versa). Sometimes one direction leads to a more natural
interpretation. It is also useful when comparing the results of PCA across
multiple data sets. This function will flip loadings and scores for PCA
analyses carried out by the base R <code><a href="stats.html#topic+prcomp">prcomp()</a></code> and <code><a href="stats.html#topic+princomp">princomp()</a></code> functions and
for the <code><a href="#topic+pca_test">pca_test()</a></code> function from this package. If you specify only <code>pc_no</code>
you will flip the loadings and scores for that PC. You can also specify a
variable which you would like to have a positive loading in the resulting
PCA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pc_flip(pca_obj, pc_no, flip_var = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pc_flip_+3A_pca_obj">pca_obj</code></td>
<td>
<p>The result of a call to <code>prcomp()</code>, <code>princomp()</code> or <code>pca_test</code>.</p>
</td></tr>
<tr><td><code id="pc_flip_+3A_pc_no">pc_no</code></td>
<td>
<p>An integer, indicating which PC is to be flipped.</p>
</td></tr>
<tr><td><code id="pc_flip_+3A_flip_var">flip_var</code></td>
<td>
<p>An optional name of a variable which will become positive
in the PC indicated by <code>pc_no</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object matching the class of <code>pca_obj</code> with relevant PC modified.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  pca_obj &lt;- prcomp(onze_intercepts |&gt; dplyr::select(-speaker), scale=TRUE)

  # flip the second PC
  flipped_pca &lt;- pc_flip(pca_obj, pc_no = 2)

  # flip (if necessary) the third PC, so that the "F1_GOOSE" variable has
  # a positive loading
  flipped_pca &lt;- pc_flip(pca_obj, pc_no = 3, flip_var = "F1_GOOSE")
</code></pre>

<hr>
<h2 id='pca_contrib_plot'>PCA contribution plots</h2><span id='topic+pca_contrib_plot'></span>

<h3>Description</h3>

<p>Plot the contribution of each variable in a data set to a given Principal
Component (PC). Variables are arranged by ascending contribution to the PC,
where contribution is the squared loading for the variable expressed as a
percentage. These plots match those given in supplementary material for
Brand et al. (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pca_contrib_plot(pca_object, pc_no = 1, cutoff = 50)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pca_contrib_plot_+3A_pca_object">pca_object</code></td>
<td>
<p>a pca object generated by <code>prcomp</code> or <code>princomp</code>.</p>
</td></tr>
<tr><td><code id="pca_contrib_plot_+3A_pc_no">pc_no</code></td>
<td>
<p>the PC to be visualised. Default value is 1.</p>
</td></tr>
<tr><td><code id="pca_contrib_plot_+3A_cutoff">cutoff</code></td>
<td>
<p>the cutoff value for interpretation of the PC. Determines what
total percentage contribution we want from the variables we select for
interpretation. The default of 50 means that we pick the variables with the
highest contribution to the PC until we have accounted for 50% of the total
contributions to the PC. Can be set to <code>NULL</code> in which case, no cutoff value
is plotted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As with the other plotting functions in this package, the result is a
<code>ggplot2</code> plot. It can be modified using <code>ggplot2</code> functions (see, e.g.,
<code><a href="#topic+plot_correlation_magnitudes">plot_correlation_magnitudes()</a></code>.
</p>


<h3>Value</h3>

<p><code>ggplot</code> object.
</p>


<h3>References</h3>

<p>Brand, James, Jen Hay, Lynn Clark, Kevin Watson &amp; Márton Sóskuthy (2021):
Systematic co-variation of monophthongs across speakers of New Zealand
English. Journal of Phonetics. Elsevier. 88. 101096.
doi:10.1016/j.wocn.2021.101096
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  onze_pca &lt;- prcomp(onze_intercepts |&gt; dplyr::select(-speaker), scale = TRUE)

  # Plot PC1 with a cutoff value of 60%
  pca_contrib_plot(onze_pca, pc_no = 1, cutoff = 60)

  # Plot PC2 with no cutoff value.
  pca_contrib_plot(onze_pca, pc_no = 2, cutoff = NULL)

</code></pre>

<hr>
<h2 id='pca_test'>PCA with confidence intervals and null distributions</h2><span id='topic+pca_test'></span>

<h3>Description</h3>

<p>Permute and bootstrap data fed to PCA <code>n</code> times. Bootstrapped data is used to
estimate confidence bands for variance explained by each PC and for each
loading. Squared loadings are multiplied by the squared eigenvalue of the
relevant PC. This ranks the loadings of PCs which explain a lot of variance
higher than those from PCs which explain less. This approach to PCA testing
follows Carmago (2022) and Vieria (2012). This approach differs from
Carmago's PCAtest package by separating data generation and plotting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pca_test(
  pca_data,
  n = 100,
  scale = TRUE,
  variance_confint = 0.95,
  loadings_confint = 0.9
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pca_test_+3A_pca_data">pca_data</code></td>
<td>
<p>data fed to the <code>prcomp</code> function.</p>
</td></tr>
<tr><td><code id="pca_test_+3A_n">n</code></td>
<td>
<p>the number of times to permute and bootstrap that data. <strong>Warning:</strong> high values
will take a long time to compute.</p>
</td></tr>
<tr><td><code id="pca_test_+3A_scale">scale</code></td>
<td>
<p>whether the PCA variables should be scaled (default: TRUE).</p>
</td></tr>
<tr><td><code id="pca_test_+3A_variance_confint">variance_confint</code></td>
<td>
<p>size of confidence intervals for variance explained
(default: 0.95).</p>
</td></tr>
<tr><td><code id="pca_test_+3A_loadings_confint">loadings_confint</code></td>
<td>
<p>size of confidence intervals for index loadings
(default: 0.9).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Default confidence bands on variance explained at 0.95 (i.e. alpha of 0.05).
In line with Vieria (2012), the default confidence bands on the index
loadings are at 0.9.
</p>
<p>See <code><a href="#topic+plot_loadings">plot_loadings()</a></code> and <code><a href="#topic+plot_variance_explained">plot_variance_explained()</a></code> for useful plotting
functions.
</p>


<h3>Value</h3>

<p>object of class <code>pca_test_results</code>, containing:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;$variance&#8288;</code> a tibble containing the variances explained and confidence
intervals for each PC.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$loadings&#8288;</code> a tibble containing the index loadings and confidence intervals
for each variable and PC.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$raw_data&#8288;</code> a tibble containing the variance explained and loadings for
each bootstrapped and permuted analysis.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$variance_confint&#8288;</code> confidence intervals applied to variance explained.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$loadings_confint&#8288;</code> confidence interval applied to loadings.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$n&#8288;</code> the number of iterations of both permutation and bootstrapping.
</p>
</li></ul>



<h3>References</h3>

<p>Camargo, Arley (2022),
PCAtest: testing the statistical significance of Principal Component
Analysis in R. <em>PeerJ</em> 10. e12967.
doi:10.7717/peerj.12967
</p>
<p>Vieira, Vasco (2012): Permutation tests to estimate significances on
Principal Components Analysis. <em>Computational Ecology and Software</em> 2.
103–123.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>onze_pca &lt;- pca_test(
  onze_intercepts |&gt; dplyr::select(-speaker),
  n = 10,
  scale = TRUE
)
summary(onze_pca)
</code></pre>

<hr>
<h2 id='permutation_test'>Run permutation test on PCA analysis.</h2><span id='topic+permutation_test'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#superseded"><img src="../help/figures/lifecycle-superseded.svg" alt='[Superseded]' /></a> Permute data fed to PCA a given number of times, collecting the number of
significant pairwise correlations in the permuted data and the variances
explained for a given number of PCs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>permutation_test(
  pca_data,
  pc_n = 5,
  n = 100,
  scale = TRUE,
  cor.method = "pearson"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="permutation_test_+3A_pca_data">pca_data</code></td>
<td>
<p>data fed to the <code>prcomp</code> function. Remove non-continuous variables.</p>
</td></tr>
<tr><td><code id="permutation_test_+3A_pc_n">pc_n</code></td>
<td>
<p>the number of PCs to collect variance explained from.</p>
</td></tr>
<tr><td><code id="permutation_test_+3A_n">n</code></td>
<td>
<p>the number of times to permute that data. <strong>Warning:</strong> high values
will take a long time to compute.</p>
</td></tr>
<tr><td><code id="permutation_test_+3A_scale">scale</code></td>
<td>
<p>whether the PCA variables should be scaled (default = TRUE).</p>
</td></tr>
<tr><td><code id="permutation_test_+3A_cor.method">cor.method</code></td>
<td>
<p>method to use for correlations (default = &quot;pearson&quot;).
Alternative is &quot;spearman&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is now superseded. Use <code><a href="#topic+correlation_test">correlation_test()</a></code> for pairwise
correlations and <code><a href="#topic+pca_test">pca_test()</a></code> for variance explained and loadings.
</p>


<h3>Value</h3>

<p>object of class <code>permutation_test</code>
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;$permuted_variances&#8288;</code> n x pc_no matrix of variances explained by first
pc_no PCs in n permutations of original data.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$permuted_correlations&#8288;</code> list of length n of significant pairwise
correlations in n permutations of the data (&lt;= 0.05).
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$actual_variances&#8288;</code> pc_n x 2 tibble of variances explained by first pc_n
PCs with original data.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$actual_correlations&#8288;</code> the number of significant pairwise correlations (&lt;=
0.05) in the original data.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>permutation_test(
  onze_intercepts |&gt; dplyr::select(-speaker),
  pc_n = 5,
  n = 10,
  scale = TRUE,
  cor.method = 'pearson'
 )

</code></pre>

<hr>
<h2 id='plot_correlation_counts'>Plot of correlation counts from <code>correlation_test</code> object</h2><span id='topic+plot_correlation_counts'></span>

<h3>Description</h3>

<p>Plot the number of statistically significant pairwise correlations in a data
set given an alpha value against the distribution of counts of statistically
significant pairwise correlations in permuted data. This is an informal test
which is useful to convincing yourself that there is structure in your data
which PCA might be able to uncover.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_correlation_counts(cor_test, alpha = 0.05, half_violin = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_correlation_counts_+3A_cor_test">cor_test</code></td>
<td>
<p>an object of class <code>correlation_test</code> generated by
<code>correlation_test</code>.</p>
</td></tr>
<tr><td><code id="plot_correlation_counts_+3A_alpha">alpha</code></td>
<td>
<p>significance level for counting correlation as significant.</p>
</td></tr>
<tr><td><code id="plot_correlation_counts_+3A_half_violin">half_violin</code></td>
<td>
<p>Plot correlation counts using a half violin plot and half
point plot. Quantiles are not currently supported.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The resulting plot presents the distribution of <em>counts</em> of statistically
significant correlations at a given alpha level in the permuted data and the
count of statistically significant correlations in the original data. If the
red dot is above the uppermost line inside the blue violin plot, we say the
number of statistically significant correlations in the real data is itself
statistically significant. Usually this is used as a rough sanity check in
the course of a PCA workflow and we want to see the red dot well above the
violin (as in the example below).
</p>
<p>The resulting plot is a <code>ggplot2</code> plot and can be modified using functions
from that package. For instance, titles can be removed using the <code><a href="ggplot2.html#topic+labs">ggplot2::labs()</a></code>
function (as in the examples below).
</p>


<h3>Value</h3>

<p><code>ggplot</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # Test correlations (use at least n = 100)
  cor_test &lt;- correlation_test(onze_intercepts |&gt;
    dplyr::select(-speaker), n = 10)
  cor_plot &lt;- plot_correlation_counts(cor_test)
  cor_plot

  # make statistical test more strict by reducing the alpha.
  cor_plot_strict &lt;- plot_correlation_counts(cor_test, alpha = 0.01)

  # modify plot using `ggplot2` functions, e.g.
  cor_plot_strict +
    ggplot2::labs(title = NULL) +
    ggplot2::theme_bw()
</code></pre>

<hr>
<h2 id='plot_correlation_magnitudes'>Plot distribution of correlations from <code>correlation_test</code> object</h2><span id='topic+plot_correlation_magnitudes'></span>

<h3>Description</h3>

<p>This plot type is used in
Brand et al. (2021).
It presents the magnitudes of the correlations from the real data as a solid
red line, and the correlations from each iteration of the permutation test as
light blue lines. This gives a visual sense of the distribution of random
correlations compared with those in the actual data. If there are significant
pairwise correlations in the data, the thick red line should be visually
lower and wider across the plot than the thinner blue lines. If there are no
significant pairwise correlations, then the thick red line will have the
same shape as the blue lines.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_correlation_magnitudes(cor_test)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_correlation_magnitudes_+3A_cor_test">cor_test</code></td>
<td>
<p>an object of class <code>correlation_test</code> generated by
<code>correlation_test</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>ggplot</code> object.
</p>


<h3>References</h3>

<p>Brand, James, Jen Hay, Lynn Clark, Kevin Watson &amp; Márton Sóskuthy (2021):
Systematic co-variation of monophthongs across speakers of New Zealand
English. Journal of Phonetics. Elsevier. 88. 101096.
doi:10.1016/j.wocn.2021.101096
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # Test correlations (use at least n = 100)
  cor_test &lt;- correlation_test(onze_intercepts |&gt;
    dplyr::select(-speaker), n = 10)
  cor_plot &lt;- plot_correlation_magnitudes(cor_test)
  cor_plot

  # modify plot using `ggplot2` functions, e.g.
  cor_plot +
    ggplot2::labs(title = NULL) +
    ggplot2::theme_bw()
</code></pre>

<hr>
<h2 id='plot_loadings'>Plot PC index loadings from <code>pca_test</code> object.</h2><span id='topic+plot_loadings'></span>

<h3>Description</h3>

<p>Index loadings (Vieira 2012) are presented with confidence intervals on the
sampling distribution generated by bootstrapping and a null distribution
generated by permutation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_loadings(
  pca_test,
  pc_no = 1,
  violin = FALSE,
  filter_boots = FALSE,
  quantile_threshold = 0.25
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_loadings_+3A_pca_test">pca_test</code></td>
<td>
<p>an object of class pca_test_results generated by <code>pca_test</code>.</p>
</td></tr>
<tr><td><code id="plot_loadings_+3A_pc_no">pc_no</code></td>
<td>
<p>An integer indicating which PC to plot.</p>
</td></tr>
<tr><td><code id="plot_loadings_+3A_violin">violin</code></td>
<td>
<p>If TRUE, violin plots are added for the confidence intervals of
the sampling distribution.</p>
</td></tr>
<tr><td><code id="plot_loadings_+3A_filter_boots">filter_boots</code></td>
<td>
<p>if TRUE, only bootstrap iterations in which the variable
with the highest median loading is above <code>quantile_threshold</code>.</p>
</td></tr>
<tr><td><code id="plot_loadings_+3A_quantile_threshold">quantile_threshold</code></td>
<td>
<p>a real value between 0 and 1. Use this to change
the threshold used for filtering bootstrap iterations. The default is 0.25.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If PCs are unstable, there is an option (<code>filter_boots</code>) to take only the
bootstrap iterations in which the variable with the highest median loading
across all iterations is above <code>quantile_threshold</code> (default: 0.25). This
helps to reveal reliable connections of this variable with other variables in
the data set.
</p>


<h3>Value</h3>

<p><code>ggplot</code> object.
</p>


<h3>References</h3>

<p>Vieira, Vasco (2012): Permutation tests to estimate significances on
Principal Components Analysis. <em>Computational Ecology and Software</em> 2.
103–123.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  onze_pca &lt;- pca_test(onze_intercepts |&gt; dplyr::select(-speaker), n = 10)
  # Plot PC1
  plot_loadings(onze_pca, pc_no=1)
  # Plot PC2 with violins (not particularly useful in this case!)
  plot_loadings(onze_pca, pc_no=2, violin = TRUE)
</code></pre>

<hr>
<h2 id='plot_mds_test'>Plot <code><a href="#topic+mds_test">mds_test()</a></code> results</h2><span id='topic+plot_mds_test'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a>  Plot output from <code><a href="#topic+mds_test">mds_test()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_mds_test(mds_test)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_mds_test_+3A_mds_test">mds_test</code></td>
<td>
<p>Object of class <code>mds_test_results</code> (generated by <code><a href="#topic+mds_test">mds_test()</a></code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>ggplot</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mds_result &lt;- mds_test(
    sim_matrix,
    n_boots = 10,
    n_perms = 10,
    test_dimensions = 3,
    mds_type = 'interval'
 )
 plot_mds_test(mds_result)
</code></pre>

<hr>
<h2 id='plot_pc_input'>Plot Scores from Significant PCs Against PCA Input</h2><span id='topic+plot_pc_input'></span>

<h3>Description</h3>

<p>It is sometimes useful to see the relationship between PCs and the raw values
of the input data fed into PCA. This function takes the results of running
<code>pca_test</code>, the scores for each speaker from the pca object, and the raw data
fed into the PCA analysis. In the usual model-to-pca analysis pipeline, the
resulting plot depicts by-speaker random intercepts for each vowel and an
indication of which variables are significantly loaded onto the PCs. It
allows the researcher to visualise the strength of the relationship between
intercepts and PC scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_pc_input(pca_object, pca_data, pca_test)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_pc_input_+3A_pca_object">pca_object</code></td>
<td>
<p>Output of <code>prcomp</code>.</p>
</td></tr>
<tr><td><code id="plot_pc_input_+3A_pca_data">pca_data</code></td>
<td>
<p>Data fed into <code>prcomp</code>. This should not include speaker identifiers.</p>
</td></tr>
<tr><td><code id="plot_pc_input_+3A_pca_test">pca_test</code></td>
<td>
<p>Output of <code>pca_test</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>ggplot</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pca_data &lt;- onze_intercepts |&gt; dplyr::select(-speaker)
onze_pca &lt;- prcomp(pca_data, scale = TRUE)
onze_pca_test &lt;- pca_test(pca_data, n = 10)
plot_pc_input(onze_pca, pca_data, onze_pca_test)

</code></pre>

<hr>
<h2 id='plot_pc_vs'>Plot PC loadings in vowel space</h2><span id='topic+plot_pc_vs'></span>

<h3>Description</h3>

<p>Plot loadings from a PCA analysis carried out on vocalic data. Vowel
positions mean values are at the mean with arrows indicating loadings.
Loadings are
multiplied by the standard deviation, by vowel, of the initial input data.
This is OK for getting a quick, intuitive, interpretation of what the PCs
mean in the vowel space. When using a model-to-PCA pipeline, it is not
recommended to use these plots directly in publications as the models should
more reliably control variation in vocalic readings than taking the standard
mean and standard deviation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_pc_vs(vowel_data, pca_obj, pc_no = 1, is_sig = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_pc_vs_+3A_vowel_data">vowel_data</code></td>
<td>
<p>A dataframe whose first four columns are speaker ids,
vowel ids, F1 values, and F2 values.</p>
</td></tr>
<tr><td><code id="plot_pc_vs_+3A_pca_obj">pca_obj</code></td>
<td>
<p>The result of a call to <code>prcomp()</code>, <code>princomp()</code> or <code>pca_test()</code>.</p>
</td></tr>
<tr><td><code id="plot_pc_vs_+3A_pc_no">pc_no</code></td>
<td>
<p>An integer, indicating which PC to plot (default is PC1).</p>
</td></tr>
<tr><td><code id="plot_pc_vs_+3A_is_sig">is_sig</code></td>
<td>
<p>A boolean, indicating whether only 'significant' loadings,
according to <code>pca_test</code> should be plotted (only works with objects of class
<code>pca_test_results</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>ggplot</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  onze_pca &lt;- prcomp(onze_intercepts |&gt; dplyr::select(-speaker), scale=TRUE)
  # Default is to plot PC1
  plot_pc_vs(onze_vowels, onze_pca)
  # Or plot another PC with `pc_no`
  plot_pc_vs(onze_vowels, onze_pca, pc_no = 3)
</code></pre>

<hr>
<h2 id='plot_permutation_test'>Create plot from <code><a href="#topic+permutation_test">permutation_test()</a></code>.</h2><span id='topic+plot_permutation_test'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#superseded"><img src="../help/figures/lifecycle-superseded.svg" alt='[Superseded]' /></a> Plots results of a permutation test
carried out with the <code><a href="#topic+permutation_test">permutation_test()</a></code> function. Now use either
<code><a href="#topic+correlation_test">correlation_test()</a></code> or <code><a href="#topic+pca_test">pca_test()</a></code> and the associated plotting functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_permutation_test(permutation_results, violin = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_permutation_test_+3A_permutation_results">permutation_results</code></td>
<td>
<p>object of class <code>permutation_results</code>.</p>
</td></tr>
<tr><td><code id="plot_permutation_test_+3A_violin">violin</code></td>
<td>
<p>Determines whether the variances explained are depicted by
distinct violin plots for each PC or by connected lines. the advantage of
lines is that they correctly indicate that values for each PC depend on one
another within a given permutation. That is, if an earlier PC soaks up a
lot of the variation in a data set, then there is less variation left to
explain by subsequent PCs. Default value is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>ggplot</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>onze_perm &lt;- permutation_test(
  onze_intercepts |&gt; dplyr::select(-speaker),
  pc_n = 5,
  n = 10,
  scale = TRUE,
  cor.method = 'pearson'
 )
plot_permutation_test(onze_perm)
</code></pre>

<hr>
<h2 id='plot_variance_explained'>Create plot of variances explained from <code>pca_test</code> object</h2><span id='topic+plot_variance_explained'></span>

<h3>Description</h3>

<p>The variance explained by each PC in a dataset is plotted with confidence
intervals generated by bootstrapping and a null distribution generated by
permutation. The function accepts the result of calling the <code>pca_test</code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_variance_explained(pca_test, pc_max = NA, percent = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_variance_explained_+3A_pca_test">pca_test</code></td>
<td>
<p>an object of class pca_test_results generated by <code>pca_test</code>.</p>
</td></tr>
<tr><td><code id="plot_variance_explained_+3A_pc_max">pc_max</code></td>
<td>
<p>the maximum number of PCs to plot. If NA, plot all PCs.</p>
</td></tr>
<tr><td><code id="plot_variance_explained_+3A_percent">percent</code></td>
<td>
<p>if TRUE, represent variance explained as a percentage. If
FALSE, represent as eigenvalues.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, variance explained is represented as a percentage. If the
argument <code>percent</code> is set to FALSE, then the variance explained is
represented by the eigenvalues corresponding to each PC.
</p>


<h3>Value</h3>

<p><code>ggplot</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  onze_pca &lt;- pca_test(onze_intercepts |&gt; dplyr::select(-speaker), n = 10)
  # Plot with percentages
  plot_variance_explained(onze_pca)
  # Plot with eigenvalues and only the first 5 PCs.
  plot_variance_explained(onze_pca, pc_max = 5, percent = FALSE)
</code></pre>

<hr>
<h2 id='plot_vowel_space'>Plot vowel space for speaker or speakers.</h2><span id='topic+plot_vowel_space'></span>

<h3>Description</h3>

<p>Given vowel data with the first column identifying speakers, the second
identifying vowels, the third containing F1 and the fourth containing F2
values, plot a vowel space using the speaker's mean values for each vowel.
Typically it is best to produce a plot from scratch. The primary purpose of
this function is to generate quick plots for interactive use, rather than to
produce plots for publication.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_vowel_space(
  vowel_data,
  speakers = NULL,
  vowel_colours = NULL,
  label_size = 4,
  means_only = TRUE,
  ellipses = FALSE,
  point_alpha = 0.1,
  facet = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_vowel_space_+3A_vowel_data">vowel_data</code></td>
<td>
<p>data frame of vowel tokens as described above.</p>
</td></tr>
<tr><td><code id="plot_vowel_space_+3A_speakers">speakers</code></td>
<td>
<p>list of speaker identifiers for speaker whose vowel space
is to be plotted.</p>
</td></tr>
<tr><td><code id="plot_vowel_space_+3A_vowel_colours">vowel_colours</code></td>
<td>
<p>a named list of vowel = colour entries to indicate
which colour to plot each vowel.</p>
</td></tr>
<tr><td><code id="plot_vowel_space_+3A_label_size">label_size</code></td>
<td>
<p>It is often convenient to adjust the size of the labels (in
pts). Default is 4.</p>
</td></tr>
<tr><td><code id="plot_vowel_space_+3A_means_only">means_only</code></td>
<td>
<p>whether to plot means only or all data points. Default:
TRUE.</p>
</td></tr>
<tr><td><code id="plot_vowel_space_+3A_ellipses">ellipses</code></td>
<td>
<p>whether to 95% confidence ellipses. Only works if means_only
is FALSE. Default is FALSE.</p>
</td></tr>
<tr><td><code id="plot_vowel_space_+3A_point_alpha">point_alpha</code></td>
<td>
<p>alpha value for data points if means_only is FALSE.</p>
</td></tr>
<tr><td><code id="plot_vowel_space_+3A_facet">facet</code></td>
<td>
<p>whether to plot distinct speakers in distinct facets. Default is
TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>ggplot</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Plot mean vowel space across
plot_vowel_space(
  onze_vowels,
  speakers = NULL,
  vowel_colours = NULL,
  label_size = 4,
  means_only = TRUE,
  ellipses = FALSE,
  point_alpha = 0.1,
  facet = FALSE
 )
</code></pre>

<hr>
<h2 id='qb_intervals'>Formant and amplitude for intervals of QuakeBox monologues</h2><span id='topic+qb_intervals'></span>

<h3>Description</h3>

<p>QuakeBox monologues are divided into intervals of fixed length within mean
values are calcualted for formants, amplitude, and articulation rate. Data
from 77 speakers is provide (the same sample as <code>qb_vowels</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qb_intervals
</code></pre>


<h3>Format</h3>

<p>A data frame with 53940 rows and 10 variables:
</p>

<dl>
<dt>interval_length</dt><dd><p>Length of interval in seconds.</p>
</dd>
<dt>speaker</dt><dd><p>Anonymised speaker code (char).</p>
</dd>
<dt>interval</dt><dd><p>Time in seconds at which interval ends.</p>
</dd>
<dt>articulation_rate</dt><dd><p>Mean articulation rate within interval.</p>
</dd>
<dt>amplitude</dt><dd><p>Mean maximum amplitude within interval.</p>
</dd>
<dt>DRESS_F1</dt><dd><p>Speaker intercept from GAMM model of DRESS F1.</p>
</dd>
<dt>DRESS_F2</dt><dd><p>Speaker intercept from GAMM model of DRESS F2.</p>
</dd>
<dt>FLEECE_F1</dt><dd><p>Speaker intercept from GAMM model of FLEECE F1.</p>
</dd>
<dt>FLEECE_F2</dt><dd><p>Speaker intercept from GAMM model of FLEECE F2.</p>
</dd>
<dt>GOOSE_F1</dt><dd><p>Speaker intercept from GAMM model of GOOSE F1.</p>
</dd>
<dt>GOOSE_F2</dt><dd><p>Speaker intercept from GAMM model of GOOSE F2.</p>
</dd>
<dt>KIT_F1</dt><dd><p>Speaker intercept from GAMM model of KIT F1.</p>
</dd>
<dt>KIT_F2</dt><dd><p>Speaker intercept from GAMM model of KIT F2.</p>
</dd>
<dt>LOT_F1</dt><dd><p>Speaker intercept from GAMM model of LOT F1.</p>
</dd>
<dt>LOT_F2</dt><dd><p>Speaker intercept from GAMM model of LOT F2.</p>
</dd>
<dt>NURSE_F1</dt><dd><p>Speaker intercept from GAMM model of NURSE F1.</p>
</dd>
<dt>NURSE_F2</dt><dd><p>Speaker intercept from GAMM model of NURSE F2.</p>
</dd>
<dt>START_F1</dt><dd><p>Speaker intercept from GAMM model of START F1.</p>
</dd>
<dt>START_F2</dt><dd><p>Speaker intercept from GAMM model of START F2.</p>
</dd>
<dt>STRUT_F1</dt><dd><p>Speaker intercept from GAMM model of STRUT F1.</p>
</dd>
<dt>STRUT_F2</dt><dd><p>Speaker intercept from GAMM model of STRUT F2.</p>
</dd>
<dt>THOUGHT_F1</dt><dd><p>Speaker intercept from GAMM model of THOUGHT F1.</p>
</dd>
<dt>THOUGHT_F2</dt><dd><p>Speaker intercept from GAMM model of THOUGHT F2.</p>
</dd>
<dt>TRAP_F1</dt><dd><p>Speaker intercept from GAMM model of TRAP F1.</p>
</dd>
<dt>TRAP_F2</dt><dd><p>Speaker intercept from GAMM model of TRAP F2.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Two interval lengths are given: 60 seconds and 240 seconds.
</p>
<p>Formant data is z-scored by speaker and vowel, while the amplitude and
articulation rate are z-scored by speaker.
</p>
<p>Original data was generated for Wilson Black et al. (2023).
</p>


<h3>Source</h3>

<p><a href="https://osf.io/m8nkh/">https://osf.io/m8nkh/</a>
</p>


<h3>References</h3>

<p>Wilson Black, Joshua, Jennifer Hay, Lynn Clark &amp; James Brand (2023): The
overlooked effect of amplitude on within-speaker vowel variation.
Linguistics Vanguard. Walter de Gruyter GmbH. 9(1). 173–189.
doi:10.1515/lingvan-2022-0086
</p>

<hr>
<h2 id='qb_vowels'>Formants from QuakeBox 1</h2><span id='topic+qb_vowels'></span>

<h3>Description</h3>

<p>A dataset containing formant values, amplitude, articulation rate, and
following segment data for 10 New Zealand English monophthongs, along with
participant demographics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qb_vowels
</code></pre>


<h3>Format</h3>

<p>A data frame with 26331 rows and 14 variables:
</p>

<dl>
<dt>speaker</dt><dd><p>Anonymised speaker code (char).</p>
</dd>
<dt>vowel</dt><dd><p>Wells lexical sets for 10 NZE monophthongs. Levels:  DRESS, FLEECE, GOOSE, KIT, LOT, NURSE, START, STRUT, THOUGHT, TRAP, FOOT (char).</p>
</dd>
<dt>F1_50</dt><dd><p>First formant in Hz, extracted from vowel mid-point using LaBB-CAT interface with Praat.</p>
</dd>
<dt>F2_50</dt><dd><p>Second formant in Hz, extracted from vowel mid-point using LaBB-CAT interface with Praat.</p>
</dd>
<dt>participant_age_category</dt><dd><p>Age category of speaker. Values: 18-25, 26-35, 36-45, ..., 76-85 (char).</p>
</dd>
<dt>participant_gender</dt><dd><p>Gender of participant. Values: M, F (char).</p>
</dd>
<dt>participant_nz_ethnic</dt><dd><p>New Zealand ethnic category of participant. Values: NZ mixed ethnicity, NZ European, Other (char).</p>
</dd>
<dt>word_freq</dt><dd><p>Frequency of word from which vowel token is taken in CELEX.</p>
</dd>
<dt>word</dt><dd><p>Anonymised word id (char).</p>
</dd>
<dt>time</dt><dd><p>Time in seconds at which vowel segment starts.</p>
</dd>
<dt>vowel_duration</dt><dd><p>Length of vowel in seconds.</p>
</dd>
<dt>articulation_rate</dt><dd><p>Articulation rate of utterance from which token is taken.</p>
</dd>
<dt>following_segment_category</dt><dd><p>Category of following segment. NB: liquids have already been removed. Levels: labial, velar, other (factor).</p>
</dd>
<dt>amplitude</dt><dd><p>Maximum amplitude of word from which vowel token is taken, generated by LaBB-CAT interface with Praat.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Original data was generated for Wilson Black et al. (2023).
</p>


<h3>Source</h3>

<p><a href="https://osf.io/m8nkh/">https://osf.io/m8nkh/</a>
</p>


<h3>References</h3>

<p>Wilson Black, Joshua, Jennifer Hay, Lynn Clark &amp; James Brand (2023): The
overlooked effect of amplitude on within-speaker vowel variation.
Linguistics Vanguard. Walter de Gruyter GmbH. 9(1). 173–189.
doi:10.1515/lingvan-2022-0086
</p>

<hr>
<h2 id='sim_matrix'>Similarity matrix from online perception test.</h2><span id='topic+sim_matrix'></span>

<h3>Description</h3>

<p>Mean similarity ratings for 38 QuakeBox speakers from an online pairwise
similarity task. Random noise added.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_matrix
</code></pre>


<h3>Format</h3>

<p>A 38x38 matrix
</p>

<hr>
<h2 id='summary.correlation_test'>Summary function for correlation test object. Set alpha to change
significance level.</h2><span id='topic+summary.correlation_test'></span>

<h3>Description</h3>

<p>Set alpha to change significance level and n_cors to change number of pairwise
correlations given.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'correlation_test'
summary(object, alpha = 0.05, n_cors = 5, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.correlation_test_+3A_object">object</code></td>
<td>
<p>object of class <code style="white-space: pre;">&#8288;correlation test&#8288;</code>,</p>
</td></tr>
<tr><td><code id="summary.correlation_test_+3A_alpha">alpha</code></td>
<td>
<p>significance level for counting correlation as significant.</p>
</td></tr>
<tr><td><code id="summary.correlation_test_+3A_n_cors">n_cors</code></td>
<td>
<p>number of pairwise correlations to list.</p>
</td></tr>
<tr><td><code id="summary.correlation_test_+3A_...">...</code></td>
<td>
<p>additional arguments affecting the summary produced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>glue</code> object.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
