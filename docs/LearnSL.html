<!DOCTYPE html><html><head><title>Help for package LearnSL</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {LearnSL}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#act_method'><p>Activation Function</p></a></li>
<li><a href='#db_flowers'><p>Test Database 5</p></a></li>
<li><a href='#db_per_and'><p>Test Database 2</p></a></li>
<li><a href='#db_per_or'><p>Test Database 3</p></a></li>
<li><a href='#db_per_xor'><p>Test Database 4</p></a></li>
<li><a href='#db_tree_struct'><p>Test Database 8</p></a></li>
<li><a href='#db1rl'><p>Test Database 1</p></a></li>
<li><a href='#db2'><p>Test Database 6</p></a></li>
<li><a href='#db3'><p>Test Database 7</p></a></li>
<li><a href='#decision_tree'><p>Decision Tree</p></a></li>
<li><a href='#knn'><p>K-Nearest Neighbors</p></a></li>
<li><a href='#multivariate_linear_regression'><p>Multivariate Linear Regression</p></a></li>
<li><a href='#perceptron'><p>Perceptron</p></a></li>
<li><a href='#polynomial_regression'><p>Multivariate Polynomial Regression</p></a></li>
<li><a href='#print.tree_struct'><p>Print Tree Structure</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Learn Supervised Classification Methods Through Examples and
Code</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Supervised classification methods, which (if asked) can provide
    step-by-step explanations of the algorithms used, as described in
    PK Josephine et. al., (2021) &lt;<a href="https://doi.org/10.59176%2Fkjcs.v1i1.1259">doi:10.59176/kjcs.v1i1.1259</a>&gt;; and datasets to
    test them on, which highlight the strengths and weaknesses of each technique.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/ComiSeng/LearnSL">https://github.com/ComiSeng/LearnSL</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/ComiSeng/LearnSL/issues">https://github.com/ComiSeng/LearnSL/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.3.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>cli (&ge; 3.6.1)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-09-16 17:10:46 UTC; vicam</td>
</tr>
<tr>
<td>Author:</td>
<td>Víctor Amador Padilla [aut, cre],
  Juan Jose Cuadrado Gallego
    <a href="https://orcid.org/0000-0001-8178-5556"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb],
  Universidad de Alcala [cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Víctor Amador Padilla &lt;victor.amador@edu.uah.es&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-09-19 14:30:04 UTC</td>
</tr>
</table>
<hr>
<h2 id='act_method'>Activation Function</h2><span id='topic+act_method'></span>

<h3>Description</h3>

<p>Upon a received input, calculates the output based on the
selected activation function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>act_method(method, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="act_method_+3A_method">method</code></td>
<td>
<p>Activation function to be used. It must be one of
<code>"step"</code>, <code>"sine"</code>, <code>"tangent"</code>, <code>"linear"</code>, <code>"relu"</code>,
<code>"gelu"</code> or <code>"swish"</code>.</p>
</td></tr>
<tr><td><code id="act_method_+3A_x">x</code></td>
<td>
<p>Input value to be used in the activation function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Formulae used:
</p>

<dl>
<dt><em>step</em></dt><dd>
<p style="text-align: center;"><code class="reqn">f(x) = \begin{cases}
     0 &amp; \text{if } x &lt; \text{threshold} \\
     1 &amp; \text{if } x \geq \text{threshold}
   \end{cases}</code>
</p>
</dd>
<dt><em>sine</em></dt><dd><p style="text-align: center;"><code class="reqn">f(x) = \sinh(x)</code>
</p>
</dd>
<dt><em>tangent</em></dt><dd><p style="text-align: center;"><code class="reqn">f(x) = \tanh(x)</code>
</p>
</dd>
<dt><em>linear</em></dt><dd><p style="text-align: center;"><code class="reqn">x</code>
</p>
</dd>
<dt><em>relu</em></dt><dd>
<p style="text-align: center;"><code class="reqn">f(x) = \begin{cases}
     x &amp; \text{if } x &gt; 0 \\
     0 &amp; \text{if } x \leq 0
   \end{cases}</code>
</p>
</dd>
<dt><em>gelu</em></dt><dd><p style="text-align: center;"><code class="reqn">f(x) = \frac{1}{2} \cdot x \cdot \left(1 + \tanh\left(\sqrt{\frac{2}{\pi}} \cdot (x + 0.044715 \cdot x^3)\right)\right)</code>
</p>
</dd>
<dt><em>swish</em></dt><dd><p style="text-align: center;"><code class="reqn">f(x) = \frac{x}{1 + e^{-x}}</code>
</p>
</dd>
</dl>



<h3>Value</h3>

<p>List with the weights of the inputs.
</p>


<h3>Author(s)</h3>

<p>Víctor Amador Padilla, <a href="mailto:victor.amador@edu.uah.es">victor.amador@edu.uah.es</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example code
act_method("step", 0.3)
act_method("gelu", 0.7)

</code></pre>

<hr>
<h2 id='db_flowers'>Test Database 5</h2><span id='topic+db_flowers'></span>

<h3>Description</h3>

<p>Test Database 5
</p>


<h3>Usage</h3>

<pre><code class='language-R'>db_flowers
</code></pre>


<h3>Format</h3>



<h4><code>db_flowers</code></h4>

<p>A data frame representing features of flowers. It has 4 independent variables (first 4 columns) and one independent variable (last column).
</p>


<hr>
<h2 id='db_per_and'>Test Database 2</h2><span id='topic+db_per_and'></span>

<h3>Description</h3>

<p>Test Database 2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>db_per_and
</code></pre>


<h3>Format</h3>



<h4><code>db_per_and</code></h4>

<p>A data frame with 3 independent variables (first 3 columns) and one independent variable (last column).
It represents a 3 input &quot;AND&quot; logic gate.
</p>


<hr>
<h2 id='db_per_or'>Test Database 3</h2><span id='topic+db_per_or'></span>

<h3>Description</h3>

<p>Test Database 3
</p>


<h3>Usage</h3>

<pre><code class='language-R'>db_per_or
</code></pre>


<h3>Format</h3>



<h4><code>db_per_or</code></h4>

<p>A data frame with 3 independent variables (first 3 columns) and one independent variable (last column).
It represents a 3 input &quot;OR&quot; logic gate.
</p>


<hr>
<h2 id='db_per_xor'>Test Database 4</h2><span id='topic+db_per_xor'></span>

<h3>Description</h3>

<p>Test Database 4
</p>


<h3>Usage</h3>

<pre><code class='language-R'>db_per_xor
</code></pre>


<h3>Format</h3>



<h4><code>db_per_xor</code></h4>

<p>A data frame with 3 independent variables (first 3 columns) and one independent variable (last column).
It represents a 3 input &quot;XOR&quot; logic gate.
</p>


<hr>
<h2 id='db_tree_struct'>Test Database 8</h2><span id='topic+db_tree_struct'></span>

<h3>Description</h3>

<p>Test Database 8
</p>


<h3>Usage</h3>

<pre><code class='language-R'>db_tree_struct
</code></pre>


<h3>Format</h3>



<h4><code>db_tree_struct</code></h4>

<p>Decision tree structure. output of the decision_tree() function &quot;decision_tree(db2, &quot;VehicleType&quot;, 4, &quot;gini&quot;)&quot;
</p>


<hr>
<h2 id='db1rl'>Test Database 1</h2><span id='topic+db1rl'></span>

<h3>Description</h3>

<p>Test Database 1
</p>


<h3>Usage</h3>

<pre><code class='language-R'>db1rl
</code></pre>


<h3>Format</h3>



<h4><code>db1rl</code></h4>

<p>A data frame with 4 independent variables (first 4 columns, representing different line types).
The last column is the independent variable.
</p>


<hr>
<h2 id='db2'>Test Database 6</h2><span id='topic+db2'></span>

<h3>Description</h3>

<p>Test Database 6
</p>


<h3>Usage</h3>

<pre><code class='language-R'>db2
</code></pre>


<h3>Format</h3>



<h4><code>db2</code></h4>

<p>A data frame with 3 independent variables (first 3 columns) and one independent variable (last column).
It has information about vehicles.
</p>


<hr>
<h2 id='db3'>Test Database 7</h2><span id='topic+db3'></span>

<h3>Description</h3>

<p>Test Database 7
</p>


<h3>Usage</h3>

<pre><code class='language-R'>db3
</code></pre>


<h3>Format</h3>



<h4><code>db3</code></h4>

<p>A data frame with 3 independent variables (first 3 columns) and one independent variable (last column).
It has information about vehicles. Similar to db2 but a little bit more complex.
</p>


<hr>
<h2 id='decision_tree'>Decision Tree</h2><span id='topic+decision_tree'></span>

<h3>Description</h3>

<p>This function creates a decision tree based of an example dataset,
calculating the best classifier possible in each step. Only creates perfect
divisions, this means, if the rule doesn't create a classified group, it is
not considered. It is specifically designed for categorical values. Continues values
are not recommended as they will be treated as categorical ones.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decision_tree(
  data,
  classy,
  m,
  method = "entropy",
  details = FALSE,
  waiting = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decision_tree_+3A_data">data</code></td>
<td>
<p>A data frame with already classified observations. Each column
represents a parameter of the value. Each row is a different observation.
The column names in the parameter &quot;data&quot; must not contain the
sequence of characters &quot; or &quot;.
As this is supposed to be a binary decision rules generator and not a binary
decision tree generator, no tree structures are used, except for the
information gain formulas.</p>
</td></tr>
<tr><td><code id="decision_tree_+3A_classy">classy</code></td>
<td>
<p>Name of the column we want the data to be classified by.
the set of rules obtained will be calculated according to this.</p>
</td></tr>
<tr><td><code id="decision_tree_+3A_m">m</code></td>
<td>
<p>Maximum numbers of child nodes each node can have.</p>
</td></tr>
<tr><td><code id="decision_tree_+3A_method">method</code></td>
<td>
<p>The definition of Gain. It must be one of
<code>"Entropy"</code>, <code>"Gini"</code>or <code>"Error"</code>.</p>
</td></tr>
<tr><td><code id="decision_tree_+3A_details">details</code></td>
<td>
<p>Boolean value. If it is set to &quot;TRUE&quot; multiple clarifications
and explanations are printed along the code</p>
</td></tr>
<tr><td><code id="decision_tree_+3A_waiting">waiting</code></td>
<td>
<p>If TRUE while <code>details</code> = TRUE. The code will stop in each
&quot;block&quot; of code and wait for the user to press &quot;enter&quot; to continue.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>data</code> is not perfectly classifiable, the code will not finish.
</p>
<p>Available information gain methods are:
</p>

<dl>
<dt><em>Entropy</em></dt><dd><p>The formula to calculate the entropy
works as follows:<code class="reqn">p_{i} = -\sum{f_{i} p_{i} \cdot \log2 p_{i}}</code></p>
</dd>
<dt><em>Gini</em></dt><dd><p>The formula to calculate gini
works as follows:<code class="reqn">p_{i} = 1 -\sum{f_{i} p_{i}^{2}}</code></p>
</dd>
<dt><em>Error</em></dt><dd><p>The formula to calculate error
works as follows:<code class="reqn">p_{i} = 1 -\max{(f_{i} p_{i}})</code></p>
</dd>
</dl>

<p>Once the impurity is calculated, the information gain is calculated as follows:
</p>
<p style="text-align: center;"><code class="reqn">IG = I_{father} - \sum{\frac{count(sonvalues)}{count(fathervalues)} \cdot I_{son}}</code>
</p>



<h3>Value</h3>

<p>Structure of the tree. List with a list per tree level. Each of these
contains a list per level node, each of these contains a list with the node's
filtered data, the node's id, the father's node id, the height that node is at,
the variable it filters by, the value that variable is filtered by and the information gain of the division
</p>


<h3>Author(s)</h3>

<p>Víctor Amador Padilla, <a href="mailto:victor.amador@edu.uah.es">victor.amador@edu.uah.es</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example code
decision_tree(db3, "VehicleType", 5, "entropy", details = TRUE, waiting = FALSE)
decision_tree(db2, "VehicleType", 4, "gini")

</code></pre>

<hr>
<h2 id='knn'>K-Nearest Neighbors</h2><span id='topic+knn'></span>

<h3>Description</h3>

<p>This function applies knn algorithm to classify data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>knn(
  data,
  ClassLabel,
  p1,
  d_method = "euclidean",
  k,
  p = 3,
  details = FALSE,
  waiting = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="knn_+3A_data">data</code></td>
<td>
<p>Data frame with already classified observations. Each
column represents a parameter of the values. The last column contains the
output, this means, the expected output when the other column values are
inputs. Each row is a different observation.</p>
</td></tr>
<tr><td><code id="knn_+3A_classlabel">ClassLabel</code></td>
<td>
<p>String containing the name of the column of the classes we want to classify</p>
</td></tr>
<tr><td><code id="knn_+3A_p1">p1</code></td>
<td>
<p>Vector containing the parameters of the new value that we want to
classify.</p>
</td></tr>
<tr><td><code id="knn_+3A_d_method">d_method</code></td>
<td>
<p>String with the name of the distance method that will
be used. It must be one of <code>"Euclidean"</code>, <code>"Manhattan"</code>,
<code>"Cosine"</code>, <code>"Chebyshev"</code>, <code>"Minkowski"</code>, <code>"Canberra"</code>,
<code>"Octile"</code>, <code>"Hamming"</code>, <code>"Binary"</code>or <code>"Jaccard"</code>. Where
both <code>"Hamming"</code> and <code>"Binary"</code> use the same method, as it is known
by both names.</p>
</td></tr>
<tr><td><code id="knn_+3A_k">k</code></td>
<td>
<p>Number of closest values that will be considered in order to classify
the new value (&quot;p1&quot;).</p>
</td></tr>
<tr><td><code id="knn_+3A_p">p</code></td>
<td>
<p>Exponent used in the <code>Minkowski distance</code>. 3 by default,
otherwise if specified.</p>
</td></tr>
<tr><td><code id="knn_+3A_details">details</code></td>
<td>
<p>Boolean value. If it is set to &quot;TRUE&quot; multiple clarifications
and explanations are printed along the code</p>
</td></tr>
<tr><td><code id="knn_+3A_waiting">waiting</code></td>
<td>
<p>If TRUE while <code>details</code> = TRUE. The code will stop in each
&quot;block&quot; of code and wait for the user to press &quot;enter&quot; to continue.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value of the new classified example.
</p>


<h3>Author(s)</h3>

<p>Víctor Amador Padilla, <a href="mailto:victor.amador@edu.uah.es">victor.amador@edu.uah.es</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example code
knn(db_flowers,"ClassLabel", c(4.7, 1.2, 5.3, 2.1), "chebyshev", 4)
knn(db_flowers,"ClassLabel", c(4.7, 1.5, 5.3, 2.1), "chebyshev", 5)
knn(db_flowers,"ClassLabel", c(6.7, 1.5, 5.3, 2.1), "Euclidean", 2, details = TRUE, waiting = FALSE)
knn(db_per_or,"y", c(1,1,1), "Hamming", 3, details = TRUE, waiting = FALSE)

</code></pre>

<hr>
<h2 id='multivariate_linear_regression'>Multivariate Linear Regression</h2><span id='topic+multivariate_linear_regression'></span>

<h3>Description</h3>

<p>Calculates and plots the linear regression of a given set of values.
Being all of them independent values but one, which is the dependent value.
It provides information about the process and intermediate values used to calculate the line equation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multivariate_linear_regression(data, details = FALSE, waiting = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multivariate_linear_regression_+3A_data">data</code></td>
<td>
<p>x*y data frame with already classified observations. Each column
represents a parameter of the values (independent variable). The last column
represents the classification value (dependent variable). Each row is a different observation.</p>
</td></tr>
<tr><td><code id="multivariate_linear_regression_+3A_details">details</code></td>
<td>
<p>Boolean value. If it is set to &quot;TRUE&quot; multiple clarifications
and explanations are printed along the code</p>
</td></tr>
<tr><td><code id="multivariate_linear_regression_+3A_waiting">waiting</code></td>
<td>
<p>If TRUE while <code>details</code> = TRUE. The code will stop in each
&quot;block&quot; of code and wait for the user to press &quot;enter&quot; to continue.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List containing a list for each independent variable,
each one contains, the variable name, the intercept and the slope.
</p>


<h3>Author(s)</h3>

<p>Víctor Amador Padilla, <a href="mailto:victor.amador@edu.uah.es">victor.amador@edu.uah.es</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example code
multivariate_linear_regression(db1rl)

</code></pre>

<hr>
<h2 id='perceptron'>Perceptron</h2><span id='topic+perceptron'></span>

<h3>Description</h3>

<p>Binary classification algorithm that learns to separate
two classes of data points by finding an optimal
decision boundary (hyper plane) in the feature space.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>perceptron(
  training_data,
  to_clasify,
  activation_method,
  max_iter,
  learning_rate,
  details = FALSE,
  waiting = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="perceptron_+3A_training_data">training_data</code></td>
<td>
<p>Data frame with already classified observations. Each
column represents a parameter of the values. The last column contains the
output, this means, the expected output when the other column values are
inputs. Each row is a different observation. It works as training data.</p>
</td></tr>
<tr><td><code id="perceptron_+3A_to_clasify">to_clasify</code></td>
<td>
<p>Vector containing the parameters of the new value that we want to
classify.</p>
</td></tr>
<tr><td><code id="perceptron_+3A_activation_method">activation_method</code></td>
<td>
<p>Activation function to be used. It must be one of
<code>"step"</code>, <code>"sine"</code>, <code>"tangent"</code>, <code>"linear"</code>, <code>"relu"</code>,
<code>"gelu"</code> or <code>"swish"</code>.</p>
</td></tr>
<tr><td><code id="perceptron_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum epoch during the training phase.</p>
</td></tr>
<tr><td><code id="perceptron_+3A_learning_rate">learning_rate</code></td>
<td>
<p>Value at which the perceptron will learn from previous epochs mistakes.</p>
</td></tr>
<tr><td><code id="perceptron_+3A_details">details</code></td>
<td>
<p>Boolean value. If it is set to &quot;TRUE&quot; multiple clarifications
and explanations are printed along the code</p>
</td></tr>
<tr><td><code id="perceptron_+3A_waiting">waiting</code></td>
<td>
<p>If TRUE while <code>details</code> = TRUE. The code will stop in each
&quot;block&quot; of code and wait for the user to press &quot;enter&quot; to continue.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Functioning:
</p>

<dl>
<dt><em>Step 1</em></dt><dd><p>Generate a random weight for each independent variable.</p>
</dd>
<dt><em>Step 2</em></dt><dd><p>Check if the weights classify correctly. If they do, go to step 4</p>
</dd>
<dt><em>Step 3</em></dt><dd><p>Adjust weights based on the error between the expected output and the real output.
If max_iter is reached go to step 4. If not, go to step 2.</p>
</dd>
<dt><em>Step 4</em></dt><dd><p>Return the weights and use them to classify the new value</p>
</dd>
</dl>



<h3>Value</h3>

<p>List with the weights of the inputs.
</p>


<h3>Author(s)</h3>

<p>Víctor Amador Padilla, <a href="mailto:victor.amador@edu.uah.es">victor.amador@edu.uah.es</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example code
perceptron(db_per_or, c(1, 1, 1), "gelu", 1000, 0.1)
perceptron(db_per_and, c(0,0,1), "swish", 1000, 0.1, TRUE, FALSE)

</code></pre>

<hr>
<h2 id='polynomial_regression'>Multivariate Polynomial Regression</h2><span id='topic+polynomial_regression'></span>

<h3>Description</h3>

<p>Calculates and plots the polynomial regression of a given set of values.
Being all of them independent values but one, which is the dependent value.
It provides (if asked) information about the process and intermediate values used to calculate the line equation.
The approximation depends entirely in the <code>degree</code> of the equations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polynomial_regression(data, degree, details = FALSE, waiting = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polynomial_regression_+3A_data">data</code></td>
<td>
<p>x*y data frame with already classified observations. Each column
represents a parameter of the values (independent variable). The last column
represents the classification value (dependent variable). Each row is a different observation.</p>
</td></tr>
<tr><td><code id="polynomial_regression_+3A_degree">degree</code></td>
<td>
<p>Degree of the equations approximation.</p>
</td></tr>
<tr><td><code id="polynomial_regression_+3A_details">details</code></td>
<td>
<p>Boolean value. If it is set to &quot;TRUE&quot; multiple clarifications
and explanations are printed along the code</p>
</td></tr>
<tr><td><code id="polynomial_regression_+3A_waiting">waiting</code></td>
<td>
<p>If TRUE while <code>details</code> = TRUE. The code will stop in each
&quot;block&quot; of code and wait for the user to press &quot;enter&quot; to continue.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List containing a list for each independent variable,
each one contains the equation coefficients.
</p>


<h3>Author(s)</h3>

<p>Víctor Amador Padilla, <a href="mailto:victor.amador@edu.uah.es">victor.amador@edu.uah.es</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example code
polynomial_regression(db1rl,4, TRUE, FALSE)
polynomial_regression(db1rl,6)

</code></pre>

<hr>
<h2 id='print.tree_struct'>Print Tree Structure</h2><span id='topic+print.tree_struct'></span>

<h3>Description</h3>

<p>This function prints the structure of a tree, generated by the
<code>decision_tree</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tree_struct'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.tree_struct_+3A_x">x</code></td>
<td>
<p>The tree structure.</p>
</td></tr>
<tr><td><code id="print.tree_struct_+3A_...">...</code></td>
<td>
<p>Extra useless parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It must receive a <code>tree_struct</code> data type.
</p>


<h3>Value</h3>

<p>nothing.
</p>


<h3>Author(s)</h3>

<p>Víctor Amador Padilla, <a href="mailto:victor.amador@edu.uah.es">victor.amador@edu.uah.es</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example code
print(db_tree_struct)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
