<!DOCTYPE html><html lang="en"><head><title>Help for package gemini.R</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {gemini.R}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#addHistory'><p>Add history for chating context</p></a></li>
<li><a href='#countTokens'><p>Count Tokens for Gemini Content (Including Images)</p></a></li>
<li><a href='#gemini'><p>Generate text from text with Gemini</p></a></li>
<li><a href='#gemini_audio'><p>Analyze audio using Gemini</p></a></li>
<li><a href='#gemini_audio.vertex'><p>Analyze Audio using Gemini Vertex API</p></a></li>
<li><a href='#gemini_chat'><p>Multi-turn conversations (chat)</p></a></li>
<li><a href='#gemini_image'><p>Generate text from text and image with Gemini</p></a></li>
<li><a href='#gemini_image.vertex'><p>Generate text from text and image with Gemini Vertex API</p></a></li>
<li><a href='#gemini.vertex'><p>Generate text from text with Gemini Vertex API</p></a></li>
<li><a href='#gen_docs'><p>Generate Roxygen Documentation</p></a></li>
<li><a href='#gen_tests'><p>Generates unit test code for an R function.</p></a></li>
<li><a href='#setAPI'><p>Set API key</p></a></li>
<li><a href='#setEnv'><p>Store API key in local environment file</p></a></li>
<li><a href='#token.vertex'><p>Generate Gemini Access Token and Endpoint URL</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Interface for 'Google Gemini' API</td>
</tr>
<tr>
<td>Version:</td>
<td>0.10.1</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jinhwan Kim &lt;hwanistic@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides a comprehensive interface for Google Gemini API,
  enabling users to access and utilize Gemini Large Language Model (LLM) functionalities directly from R.
  This package facilitates seamless integration with Google Gemini, allowing for advanced language processing,
  text generation, and other AI-driven capabilities within the R environment.
  For more information, please visit <a href="https://ai.google.dev/docs/gemini_api_overview">https://ai.google.dev/docs/gemini_api_overview</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1.0)</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/jhk0530/gemini.R">https://github.com/jhk0530/gemini.R</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/jhk0530/gemini.R/issues">https://github.com/jhk0530/gemini.R/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>base64enc, cli, httr2, jsonlite, rstudioapi, tools</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Config/Needs/website:</td>
<td>rmarkdown</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-19 04:42:36 UTC; jinhwan</td>
</tr>
<tr>
<td>Author:</td>
<td>Jinhwan Kim <a href="https://orcid.org/0009-0009-3217-2417"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre, cph],
  Maciej Nasinski [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-19 05:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='addHistory'>Add history for chating context</h2><span id='topic+addHistory'></span>

<h3>Description</h3>

<p>Add history for chating context
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addHistory(history, role = NULL, item = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="addHistory_+3A_history">history</code></td>
<td>
<p>The history of chat</p>
</td></tr>
<tr><td><code id="addHistory_+3A_role">role</code></td>
<td>
<p>The role of chat: &quot;user&quot; or &quot;model&quot;</p>
</td></tr>
<tr><td><code id="addHistory_+3A_item">item</code></td>
<td>
<p>The item of chat: &quot;prompt&quot; or &quot;output&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The history of chat
</p>

<hr>
<h2 id='countTokens'>Count Tokens for Gemini Content (Including Images)</h2><span id='topic+countTokens'></span>

<h3>Description</h3>

<p>Calculates the token count for a given content, including text and image data, using the Vertex AI Gemini API.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>countTokens(
  jsonkey = NULL,
  model_id = NULL,
  content = NULL,
  region = "us-central1"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="countTokens_+3A_jsonkey">jsonkey</code></td>
<td>
<p>A path to JSON file containing the service account key from Vertex AI.</p>
</td></tr>
<tr><td><code id="countTokens_+3A_model_id">model_id</code></td>
<td>
<p>The ID of the Gemini model.</p>
</td></tr>
<tr><td><code id="countTokens_+3A_content">content</code></td>
<td>
<p>The content (text, image, or list of text/image parts) for which to count tokens.
</p>

<ul>
<li><p> For text, provide a string.
</p>
</li>
<li><p> For images, provide a list with <code>data</code> (base64 encoded image) and <code>mimeType</code> (e.g., &quot;image/png&quot;, &quot;image/jpeg&quot;).
</p>
</li>
<li><p> For multiple content parts, provide a list where each element is either a text string or an image list.
</p>
</li></ul>
</td></tr>
<tr><td><code id="countTokens_+3A_region">region</code></td>
<td>
<p>The Google Cloud region where your Vertex AI resources are located (default is &quot;us-central1&quot;).
See https://cloud.google.com/vertex-ai/docs/regions for available regions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value representing the token count of the content.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(gemini.R)

# For text content
key_file &lt;- "YOURAPIKEY.json"
model &lt;- "2.0-flash"
token_count_text &lt;- countTokens(
  jsonkey = key_file, 
  model_id = model, 
  content = "Hello, world!"
)
print(token_count_text)

# For image content (assuming 'image.jpg' is in your working directory)
image_data &lt;- base64enc::base64encode("image.jpg")
image_content &lt;- list(data = image_data, mimeType = "image/jpeg")
token_count_image &lt;- countTokens(
  jsonkey = key_file,
  model_id = model,
  content = image_content
)
print(token_count_image)

# For multiple content parts (text and image)
content_parts &lt;- list(
  list(text = "This is the first part."),
  list(data = image_data, mimeType = "image/jpeg"),
  list(text = "This is the last part")
)
token_count_parts &lt;- countTokens(
  jsonkey = key_file,
  model_id = model,
  content = content_parts
)
print(token_count_parts)

## End(Not run)

</code></pre>

<hr>
<h2 id='gemini'>Generate text from text with Gemini</h2><span id='topic+gemini'></span>

<h3>Description</h3>

<p>Generate text from text with Gemini
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gemini(
  prompt,
  model = "2.0-flash",
  temperature = 1,
  maxOutputTokens = 8192,
  topK = 40,
  topP = 0.95,
  seed = 1234
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gemini_+3A_prompt">prompt</code></td>
<td>
<p>The prompt to generate text from</p>
</td></tr>
<tr><td><code id="gemini_+3A_model">model</code></td>
<td>
<p>The model to use. Options are &quot;2.0-flash&quot;, &quot;2.0-flash-lite&quot;, &quot;2.0-pro-exp-02-05&quot;. Default is '2.0-flash'.
see https://ai.google.dev/gemini-api/docs/models/gemini</p>
</td></tr>
<tr><td><code id="gemini_+3A_temperature">temperature</code></td>
<td>
<p>The temperature to use. Default is 1 value should be between 0 and 2
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
<tr><td><code id="gemini_+3A_maxoutputtokens">maxOutputTokens</code></td>
<td>
<p>The maximum number of tokens to generate.
Default is 8192 and 100 tokens correspond to roughly 60-80 words.</p>
</td></tr>
<tr><td><code id="gemini_+3A_topk">topK</code></td>
<td>
<p>The top-k value to use. Default is 40 value should be between 0 and 100
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
<tr><td><code id="gemini_+3A_topp">topP</code></td>
<td>
<p>The top-p value to use. Default is 0.95 value should be between 0 and 1
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
<tr><td><code id="gemini_+3A_seed">seed</code></td>
<td>
<p>The seed to use. Default is 1234 value should be integer
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Generated text
</p>


<h3>See Also</h3>

<p>https://ai.google.dev/docs/gemini_api_overview#text_input
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(gemini.R)
setAPI("YOUR_API_KEY")
gemini("Explain dplyr's mutate function")

## End(Not run)
</code></pre>

<hr>
<h2 id='gemini_audio'>Analyze audio using Gemini</h2><span id='topic+gemini_audio'></span>

<h3>Description</h3>

<p>This function sends audio to the Gemini API and returns a text description.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gemini_audio(
  audio = NULL,
  prompt = "Describe this audio",
  model = "2.0-flash",
  temperature = 1,
  maxOutputTokens = 8192,
  topK = 40,
  topP = 0.95,
  seed = 1234
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gemini_audio_+3A_audio">audio</code></td>
<td>
<p>Path to the audio file (default: uses a sample file). Must be an MP3.</p>
</td></tr>
<tr><td><code id="gemini_audio_+3A_prompt">prompt</code></td>
<td>
<p>A string describing what to do with the audio.</p>
</td></tr>
<tr><td><code id="gemini_audio_+3A_model">model</code></td>
<td>
<p>The model to use. Options are &quot;2.0-flash&quot;, &quot;2.0-flash-lite&quot;, &quot;2.0-pro-exp-02-05&quot;. Default is '2.0-flash'
see https://ai.google.dev/gemini-api/docs/models/gemini</p>
</td></tr>
<tr><td><code id="gemini_audio_+3A_temperature">temperature</code></td>
<td>
<p>The temperature to use. Default is 1 value should be between 0 and 2
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
<tr><td><code id="gemini_audio_+3A_maxoutputtokens">maxOutputTokens</code></td>
<td>
<p>The maximum number of tokens to generate.
Default is 8192 and 100 tokens correspond to roughly 60-80 words.</p>
</td></tr>
<tr><td><code id="gemini_audio_+3A_topk">topK</code></td>
<td>
<p>The top-k value to use. Default is 40 value should be between 0 and 100
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
<tr><td><code id="gemini_audio_+3A_topp">topP</code></td>
<td>
<p>The top-p value to use. Default is 0.95 value should be between 0 and 1
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
<tr><td><code id="gemini_audio_+3A_seed">seed</code></td>
<td>
<p>The seed to use. Default is 1234 value should be integer
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character vector containing the Gemini API's response.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(gemini.R)
setAPI("YOUR_API_KEY")
gemini_audio(audio = system.file("docs/reference/helloworld.mp3", package = "gemini.R"))

## End(Not run)

</code></pre>

<hr>
<h2 id='gemini_audio.vertex'>Analyze Audio using Gemini Vertex API</h2><span id='topic+gemini_audio.vertex'></span>

<h3>Description</h3>

<p>This function sends audio to the Gemini API and returns a text description.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gemini_audio.vertex(
  audio = NULL,
  prompt = "Describe this audio",
  tokens = NULL,
  temperature = 1,
  maxOutputTokens = 8192,
  topK = 40,
  topP = 0.95,
  seed = 1234
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gemini_audio.vertex_+3A_audio">audio</code></td>
<td>
<p>Path to the audio file (character string). only supports &quot;mp3&quot;.</p>
</td></tr>
<tr><td><code id="gemini_audio.vertex_+3A_prompt">prompt</code></td>
<td>
<p>A prompt to guide the Gemini API's analysis (character string, defaults to &quot;Describe this audio&quot;).</p>
</td></tr>
<tr><td><code id="gemini_audio.vertex_+3A_tokens">tokens</code></td>
<td>
<p>A list containing the API URL and key from token.vertex() function.</p>
</td></tr>
<tr><td><code id="gemini_audio.vertex_+3A_temperature">temperature</code></td>
<td>
<p>The temperature to use. Default is 1 value should be between 0 and 2
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
<tr><td><code id="gemini_audio.vertex_+3A_maxoutputtokens">maxOutputTokens</code></td>
<td>
<p>The maximum number of tokens to generate.
Default is 8192 and 100 tokens correspond to roughly 60-80 words.</p>
</td></tr>
<tr><td><code id="gemini_audio.vertex_+3A_topk">topK</code></td>
<td>
<p>The top-k value to use. Default is 40 value should be between 0 and 100
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
<tr><td><code id="gemini_audio.vertex_+3A_topp">topP</code></td>
<td>
<p>The top-p value to use. Default is 0.95 value should be between 0 and 1
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
<tr><td><code id="gemini_audio.vertex_+3A_seed">seed</code></td>
<td>
<p>The seed to use. Default is 1234 value should be integer
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character vector containing the Gemini API's description of the audio.
</p>

<hr>
<h2 id='gemini_chat'>Multi-turn conversations (chat)</h2><span id='topic+gemini_chat'></span>

<h3>Description</h3>

<p>Generate text from text with Gemini
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gemini_chat(
  prompt,
  history = list(),
  model = "2.0-flash",
  temperature = 1,
  maxOutputTokens = 8192,
  topK = 40,
  topP = 0.95,
  seed = 1234
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gemini_chat_+3A_prompt">prompt</code></td>
<td>
<p>The prompt to generate text from</p>
</td></tr>
<tr><td><code id="gemini_chat_+3A_history">history</code></td>
<td>
<p>history object to keep track of the conversation</p>
</td></tr>
<tr><td><code id="gemini_chat_+3A_model">model</code></td>
<td>
<p>The model to use. Options are &quot;2.0-flash&quot;, &quot;2.0-flash-lite&quot;, &quot;2.0-pro-exp-02-05&quot;. Default is '2.0-flash'
see https://ai.google.dev/gemini-api/docs/models/gemini</p>
</td></tr>
<tr><td><code id="gemini_chat_+3A_temperature">temperature</code></td>
<td>
<p>The temperature to use. Default is 1 value should be between 0 and 2
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
<tr><td><code id="gemini_chat_+3A_maxoutputtokens">maxOutputTokens</code></td>
<td>
<p>The maximum number of tokens to generate.
Default is 8192 and 100 tokens correspond to roughly 60-80 words.</p>
</td></tr>
<tr><td><code id="gemini_chat_+3A_topk">topK</code></td>
<td>
<p>The top-k value to use. Default is 40 value should be between 0 and 100
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
<tr><td><code id="gemini_chat_+3A_topp">topP</code></td>
<td>
<p>The top-p value to use. Default is 0.95 value should be between 0 and 1
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
<tr><td><code id="gemini_chat_+3A_seed">seed</code></td>
<td>
<p>The seed to use. Default is 1234 value should be integer
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Generated text
</p>


<h3>See Also</h3>

<p>https://ai.google.dev/docs/gemini_api_overview#chat
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(gemini.R)
setAPI("YOUR_API_KEY")

chats &lt;- gemini_chat("Pretend you're a snowman and stay in character for each")
print(chats$outputs)

chats &lt;- gemini_chat("What's your favorite season of the year?", chats$history)
print(chats$outputs)

chats &lt;- gemini_chat("How do you think about summer?", chats$history)
print(chats$outputs)

## End(Not run)
</code></pre>

<hr>
<h2 id='gemini_image'>Generate text from text and image with Gemini</h2><span id='topic+gemini_image'></span>

<h3>Description</h3>

<p>Generate text from text and image with Gemini
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gemini_image(
  image = NULL,
  prompt = "Explain this image",
  model = "2.0-flash",
  temperature = 1,
  maxOutputTokens = 8192,
  topK = 40,
  topP = 0.95,
  seed = 1234,
  type = "png"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gemini_image_+3A_image">image</code></td>
<td>
<p>The image to generate text</p>
</td></tr>
<tr><td><code id="gemini_image_+3A_prompt">prompt</code></td>
<td>
<p>The prompt to generate text, Default is &quot;Explain this image&quot;</p>
</td></tr>
<tr><td><code id="gemini_image_+3A_model">model</code></td>
<td>
<p>The model to use. Options are &quot;2.0-flash&quot;, &quot;2.0-flash-lite&quot;, &quot;2.0-pro-exp-02-05&quot;. Default is '2.0-flash'
see https://ai.google.dev/gemini-api/docs/models/gemini</p>
</td></tr>
<tr><td><code id="gemini_image_+3A_temperature">temperature</code></td>
<td>
<p>The temperature to use. Default is 1 value should be between 0 and 2
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
<tr><td><code id="gemini_image_+3A_maxoutputtokens">maxOutputTokens</code></td>
<td>
<p>The maximum number of tokens to generate.
Default is 8192 and 100 tokens correspond to roughly 60-80 words.</p>
</td></tr>
<tr><td><code id="gemini_image_+3A_topk">topK</code></td>
<td>
<p>The top-k value to use. Default is 40 value should be between 0 and 100
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
<tr><td><code id="gemini_image_+3A_topp">topP</code></td>
<td>
<p>The top-p value to use. Default is 0.95 value should be between 0 and 1
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
<tr><td><code id="gemini_image_+3A_seed">seed</code></td>
<td>
<p>The seed to use. Default is 1234 value should be integer
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
<tr><td><code id="gemini_image_+3A_type">type</code></td>
<td>
<p>The type of image. Options are 'png', 'jpeg', 'webp', 'heic', 'heif'. Default is 'png'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Generated text
</p>


<h3>See Also</h3>

<p>https://ai.google.dev/docs/gemini_api_overview#text_image_input
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(gemini.R)
setAPI("YOUR_API_KEY")
gemini_image(image = system.file("docs/reference/figures/image.png", package = "gemini.R"))

## End(Not run)

</code></pre>

<hr>
<h2 id='gemini_image.vertex'>Generate text from text and image with Gemini Vertex API</h2><span id='topic+gemini_image.vertex'></span>

<h3>Description</h3>

<p>Generate text from text and image with Gemini Vertex API
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gemini_image.vertex(
  image = NULL,
  prompt = "Explain this image",
  type = "png",
  tokens = NULL,
  temperature = 1,
  maxOutputTokens = 8192,
  topK = 40,
  topP = 0.95,
  seed = 1234
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gemini_image.vertex_+3A_image">image</code></td>
<td>
<p>The image to generate text</p>
</td></tr>
<tr><td><code id="gemini_image.vertex_+3A_prompt">prompt</code></td>
<td>
<p>A character string specifying the prompt to use with the image. Defaults to &quot;Explain this image&quot;.</p>
</td></tr>
<tr><td><code id="gemini_image.vertex_+3A_type">type</code></td>
<td>
<p>A character string specifying the image type (&quot;png&quot;, &quot;jpeg&quot;, &quot;webp&quot;, &quot;heic&quot;, &quot;heif&quot;). Defaults to &quot;png&quot;.</p>
</td></tr>
<tr><td><code id="gemini_image.vertex_+3A_tokens">tokens</code></td>
<td>
<p>A list containing the API URL and key from token.vertex() function.</p>
</td></tr>
<tr><td><code id="gemini_image.vertex_+3A_temperature">temperature</code></td>
<td>
<p>The temperature to use. Default is 1 value should be between 0 and 2
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
<tr><td><code id="gemini_image.vertex_+3A_maxoutputtokens">maxOutputTokens</code></td>
<td>
<p>The maximum number of tokens to generate.
Default is 8192 and 100 tokens correspond to roughly 60-80 words.</p>
</td></tr>
<tr><td><code id="gemini_image.vertex_+3A_topk">topK</code></td>
<td>
<p>The top-k value to use. Default is 40 value should be between 0 and 100
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
<tr><td><code id="gemini_image.vertex_+3A_topp">topP</code></td>
<td>
<p>The top-p value to use. Default is 0.95 value should be between 0 and 1
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
<tr><td><code id="gemini_image.vertex_+3A_seed">seed</code></td>
<td>
<p>The seed to use. Default is 1234 value should be integer
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character string containing Gemini's description of the image.
</p>

<hr>
<h2 id='gemini.vertex'>Generate text from text with Gemini Vertex API</h2><span id='topic+gemini.vertex'></span>

<h3>Description</h3>

<p>Generate text from text with Gemini Vertex API
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gemini.vertex(
  prompt = NULL,
  tokens = NULL,
  temperature = 1,
  maxOutputTokens = 8192,
  topK = 40,
  topP = 0.95,
  seed = 1234
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gemini.vertex_+3A_prompt">prompt</code></td>
<td>
<p>A character string containing the prompt for the Gemini model.</p>
</td></tr>
<tr><td><code id="gemini.vertex_+3A_tokens">tokens</code></td>
<td>
<p>A list containing the API URL and key from token.vertex() function.</p>
</td></tr>
<tr><td><code id="gemini.vertex_+3A_temperature">temperature</code></td>
<td>
<p>The temperature to use. Default is 1 value should be between 0 and 2
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
<tr><td><code id="gemini.vertex_+3A_maxoutputtokens">maxOutputTokens</code></td>
<td>
<p>The maximum number of tokens to generate.
Default is 8192 and 100 tokens correspond to roughly 60-80 words.</p>
</td></tr>
<tr><td><code id="gemini.vertex_+3A_topk">topK</code></td>
<td>
<p>The top-k value to use. Default is 40 value should be between 0 and 100
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
<tr><td><code id="gemini.vertex_+3A_topp">topP</code></td>
<td>
<p>The top-p value to use. Default is 0.95 value should be between 0 and 1
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
<tr><td><code id="gemini.vertex_+3A_seed">seed</code></td>
<td>
<p>The seed to use. Default is 1234 value should be integer
see https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character string containing the generated text.
</p>


<h3>See Also</h3>

<p>https://ai.google.dev/docs/gemini_api_overview#text_input
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# token should be created before this. using the token.vertex() function
prompt &lt;- "What is sachins Jersey number?"
gemini.vertex(prompt, tokens)

## End(Not run)

</code></pre>

<hr>
<h2 id='gen_docs'>Generate Roxygen Documentation</h2><span id='topic+gen_docs'></span>

<h3>Description</h3>

<p>Generates Roxygen2 documentation for an R function based on the currently selected code.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen_docs(prompt = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gen_docs_+3A_prompt">prompt</code></td>
<td>
<p>A character string specifying additional instructions for the LLM.  Defaults to a prompt requesting Roxygen2 documentation without the original code.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character string containing the generated Roxygen2 documentation.
</p>

<hr>
<h2 id='gen_tests'>Generates unit test code for an R function.</h2><span id='topic+gen_tests'></span>

<h3>Description</h3>

<p>Generates unit test code for an R function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen_tests(prompt = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gen_tests_+3A_prompt">prompt</code></td>
<td>
<p>A character string specifying the prompt for the Gemini model.  If NULL, a default prompt is used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>#' A character string containing the generated unit test code.
</p>

<hr>
<h2 id='setAPI'>Set API key</h2><span id='topic+setAPI'></span>

<h3>Description</h3>

<p>Set API key as an environment variable
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setAPI(api_key)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="setAPI_+3A_api_key">api_key</code></td>
<td>
<p>The API key to set</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.
</p>


<h3>Note</h3>

<p>Please be aware you have to agree to the terms of service of the API provider.
Any app that uses the API key is subject to the terms of service.
Also, please be aware that the API key is a sensitive information.
</p>


<h3>See Also</h3>

<p>https://makersuite.google.com/app/apikey
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
setAPI("my_api_key")

## End(Not run)
</code></pre>

<hr>
<h2 id='setEnv'>Store API key in local environment file</h2><span id='topic+setEnv'></span>

<h3>Description</h3>

<p>Saves the API key to a local .Renviron file for persistent access across R sessions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setEnv(api_key, overwrite = TRUE, install_message = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="setEnv_+3A_api_key">api_key</code></td>
<td>
<p>The API key to store</p>
</td></tr>
<tr><td><code id="setEnv_+3A_overwrite">overwrite</code></td>
<td>
<p>Whether to overwrite the existing API key if already present in .Renviron (default: TRUE)</p>
</td></tr>
<tr><td><code id="setEnv_+3A_install_message">install_message</code></td>
<td>
<p>Whether to display a message about how to use the API (default: TRUE)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+setAPI">setAPI</a></code> which sets the API key for the current session only
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
setEnv("your_api_key")

## End(Not run)

</code></pre>

<hr>
<h2 id='token.vertex'>Generate Gemini Access Token and Endpoint URL</h2><span id='topic+token.vertex'></span>

<h3>Description</h3>

<p>Generates an access token for the Gemini model and constructs the corresponding endpoint URL.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>token.vertex(
  jsonkey = NULL,
  model_id = NULL,
  expTime = 3600,
  region = "us-central1"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="token.vertex_+3A_jsonkey">jsonkey</code></td>
<td>
<p>A path to JSON file containing the service account key from Vertex AI.</p>
</td></tr>
<tr><td><code id="token.vertex_+3A_model_id">model_id</code></td>
<td>
<p>The ID of the Gemini model. This will be prepended with &quot;gemini-&quot;.</p>
</td></tr>
<tr><td><code id="token.vertex_+3A_exptime">expTime</code></td>
<td>
<p>The expiration time of the access token in seconds (default is 3600 seconds, or 1 hour).</p>
</td></tr>
<tr><td><code id="token.vertex_+3A_region">region</code></td>
<td>
<p>The Google Cloud region where your Vertex AI resources are located (default is &quot;us-central1&quot;).
See https://cloud.google.com/vertex-ai/docs/general/locations for available regions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing:
</p>
<table role = "presentation">
<tr><td><code>key</code></td>
<td>
<p>The generated access token.</p>
</td></tr>
<tr><td><code>url</code></td>
<td>
<p>The endpoint URL for the Gemini model.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(gemini.R)
tokens &lt;- token.vertex(jsonkey = "YOURAPIKEY.json", model_id = "1.5-flash")

# Specify a different region
tokens &lt;- token.vertex(jsonkey = "YOURAPIKEY.json", model_id = "1.5-flash", region = "europe-west4")

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
