<!DOCTYPE html><html><head><title>Help for package NPHazardRate</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {NPHazardRate}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cvfunction'><p>Cross Validation for Histogram Hazard Rate Estimator</p></a></li>
<li><a href='#DefVarBandRule'><p>Default adaptive bandwidth rule</p></a></li>
<li><a href='#DiscretizeData'><p>Discretize the available data set</p></a></li>
<li><a href='#HazardHistogram'><p>Histogram Hazard Rate Estimator</p></a></li>
<li><a href='#HazardRateEst'><p>Kernel Hazard Rate Estimation</p></a></li>
<li><a href='#HRSurv'><p>Estimate of the constant in the optimal AMISE expression</p></a></li>
<li><a href='#iHazardRateEst'><p>Kernel Integrated Hazard Rate Estimation</p></a></li>
<li><a href='#Kernels'><p>Kernel functions</p></a></li>
<li><a href='#KMest'><p>Kaplan-Meier Estimate</p></a></li>
<li><a href='#l1-l4, lw, lwF, gx'><p>Weibull hazard rate functionals</p></a></li>
<li><a href='#lambdahat'><p>Discrete non parametric mle hazard rate estimator</p></a></li>
<li><a href='#LLHRPlugInBand'><p>Simple Plug in badnwidth selector</p></a></li>
<li><a href='#LocLinEst'><p>Local Linear Hazard Rate Estimator</p></a></li>
<li><a href='#NP.M.Estimate'><p>Estimate of bandwidth constant</p></a></li>
<li><a href='#nsf, Tm, CparamCalculation, power.matrix, base, SmoothedEstimate'><p>Auxiliary functions for discrete hazard rate estimators</p></a></li>
<li><a href='#PlugInBand'><p>Simple Plug in badnwidth selector</p></a></li>
<li><a href='#RdistSwitch, PdfSwitch, CdfSwitch, HazardRate'><p>User driven input for random number generation and pdf, survival and hazard rate function calculation</p></a></li>
<li><a href='#SDHazardRateEst'><p>Kernel Second Derivative Hazard Rate Estimation</p></a></li>
<li><a href='#SemiparamEst'><p>Discrete hazard rate estimator</p></a></li>
<li><a href='#SimpsonInt'><p>Simpson numerical integration</p></a></li>
<li><a href='#sn.i, tn.i'><p>Local kernel weights</p></a></li>
<li><a href='#TransHazRateEst'><p>Transformation Based Hazard Rate Estimator</p></a></li>
<li><a href='#TutzPritscher'><p>Discrete non parametric kernel hazard rate estimator</p></a></li>
<li><a href='#VarBandHazEst'><p>Variable Bandwidth Hazard Rate Estimator</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Nonparametric Hazard Rate Estimation</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2018-10-13</td>
</tr>
<tr>
<td>Author:</td>
<td>Dimitrios Bagkavos [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Dimitrios Bagkavos &lt;dimitrios.bagkavos@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, survival</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides functions and examples for histogram, kernel (classical, variable bandwidth and transformations based), discrete and semiparametric hazard rate estimators.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.0</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-10-28 21:38:17 UTC; dimitris</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-11-02 18:10:18 UTC</td>
</tr>
</table>
<hr>
<h2 id='cvfunction'>Cross Validation for Histogram Hazard Rate Estimator</h2><span id='topic+cvfunction'></span>

<h3>Description</h3>

<p>Implements the cross validation function for determining the optimal number of bins for the histogram hazard rate estimator of <a href="https://www.jstor.org/stable/42003749"> Patil and Bagkavos (2012)</a>. It is used as input in   <code><a href="#topic+HazardHistogram">HazardHistogram</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvfunction(h, xin, xout, cens)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvfunction_+3A_h">h</code></td>
<td>
<p>Target number of bins.</p>
</td></tr>
<tr><td><code id="cvfunction_+3A_xin">xin</code></td>
<td>
<p> A vector of data points.  Missing values not allowed.</p>
</td></tr>
<tr><td><code id="cvfunction_+3A_xout">xout</code></td>
<td>
<p> A vector of grid points at which the histogram will be calculated.</p>
</td></tr>
<tr><td><code id="cvfunction_+3A_cens">cens</code></td>
<td>
<p> A vector of 1s and zeros, 1's indicate uncensored observations, 0's correspond to censored obs. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The least square cross validation criterion, defined in (12), <a href="https://www.jstor.org/stable/42003749">Patil and Bagkavos (2012)</a> is
</p>
<p style="text-align: center;"><code class="reqn">
CV (h) = \frac{1}{h}\sum_k \big\{(2 f^0_k - f^{0^2}_k)[\bar F_k (\bar F_k +1)]^{-1} - f^{0^2}_k[\bar F_k (\bar F_k +1)^2]^{-1}\big\}.
</code>
</p>

<p>Optimization of the criterion is done through a nonlinear optimization function such as <code><a href="stats.html#topic+nlminb">nlminb</a></code> as illustrated also in the example of <code><a href="#topic+HazardHistogram">HazardHistogram</a></code>.
</p>


<h3>Value</h3>

<p>Returns the optimal number of bins.
</p>


<h3>References</h3>

<p><a href="https://www.jstor.org/stable/42003749">Patil and Bagkavos (2012), Histogram for hazard rate estimation,  pp. 286-301, Sankhya, B.</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+HazardHistogram">HazardHistogram</a>
</code>
</p>

<hr>
<h2 id='DefVarBandRule'>Default adaptive bandwidth rule</h2><span id='topic+DefVarBandRule'></span>

<h3>Description</h3>

<p>Implements an adaptive variable bandwidth hazard rate rule for use with the <code><a href="#topic+VarBandHazEst">VarBandHazEst</a></code> based on the Weibull distribution, with parameters estimated by maximum likelihood
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DefVarBandRule(xin, cens)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DefVarBandRule_+3A_xin">xin</code></td>
<td>
<p>A vector of data points.  Missing values not allowed.</p>
</td></tr>
<tr><td><code id="DefVarBandRule_+3A_cens">cens</code></td>
<td>
<p>A vector of censoring indicators: 1's  indicate uncensored observations, 0's correspond to censored obs.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The adaptive AMISE optimal bandwidth for the variable bandwidth hazard rate estimator <code><a href="#topic+VarBandHazEst">VarBandHazEst</a></code> is given by
</p>
<p style="text-align: center;"><code class="reqn"> h_2 =  \left [ \frac{R(K) M_2}{8n\mu_4^2(K) R(g)} \right ]^{1/14}</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn"> M_2 =   \int \frac{\lambda^{3/2}(x)}{1-F(x)} \,dx</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn"> g(x)=\frac{1}{24\lambda(x)^5} \Bigl (24{\lambda'(x)}^4-36{\lambda'(x)}^2{\lambda''(x)}^2\lambda(x)+6{\lambda''(x)}^2\lambda^2(x)
+ 8\lambda'(x)\lambda'''(x)\lambda^2(x) -\lambda^{(4)}(x)\lambda^3(x)\Bigr ) </code>
</p>



<h3>Value</h3>

<p>the value of the adaptive bandwidth
</p>


<h3>References</h3>

<p><a href="http://dx.doi.org/10.1080/03610920802364088">Bagkavos and Patil (2009), Variable Bandwidths for Nonparametric Hazard Rate Estimation, Communications in Statistics - Theory and Methods, 38:7, 1055-1078</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+HazardRateEst">HazardRateEst</a>, <a href="#topic+TransHazRateEst">TransHazRateEst</a>, <a href="#topic+PlugInBand">PlugInBand</a> </code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>library(survival)
x&lt;-seq(0, 5,length=100) #design points where the estimate will be calculated

SampleSize &lt;- 100

ti&lt;- rweibull(SampleSize, .6, 1)#draw a random sample from the actual distribution
ui&lt;-rexp(SampleSize, .05)       #draw a random sample from the censoring distribution
cat("\n AMOUNT OF CENSORING: ", length(which(ti&gt;ui))/length(ti)*100, "\n")
x1&lt;-pmin(ti,ui)                 #this is the observed sample
cen&lt;-rep.int(1, SampleSize)     #censoring indicators
cen[which(ti&gt;ui)]&lt;-0            #censored values correspond to zero

h2&lt;-DefVarBandRule(ti, cen)     #Deafult Band. Rule - Weibull Reference
</code></pre>

<hr>
<h2 id='DiscretizeData'>Discretize the available data set</h2><span id='topic+DiscretizeData'></span>

<h3>Description</h3>

<p>Defines equispaced disjoint intervals based on the range of the sample and calculates empirical hazard rate estimates at each interval center
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DiscretizeData(xin, xout)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DiscretizeData_+3A_xin">xin</code></td>
<td>
<p>A vector of input values</p>
</td></tr>
<tr><td><code id="DiscretizeData_+3A_xout">xout</code></td>
<td>
<p>Grid points where the function will be evaluated</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function defines the subinterval length <code class="reqn">\Delta = (0.8\max(X_i) - \min(X_i))/N</code> where <code class="reqn">N</code> is the sample size. Then at each bin (subinterval) center, the empirical hazard rate estimate is calculated by
</p>
<p style="text-align: center;"><code class="reqn">
c_i = \frac{f_i}{\Delta(N-F_i +1) }
</code>
</p>

<p>where <code class="reqn">f_i</code> is the frequency of observations in the ith bin and <code class="reqn">F_i = \sum_{j\leq i} f_j</code> is the empirical cummulative distribution estimate.
</p>


<h3>Value</h3>

<p>A vector with the values of the function at the designated points xout or the random numbers drawn.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-seq(0, 5,length=100) #design points where the estimate will be calculated
SampleSize&lt;-100 #amount of data to be generated
ti&lt;- rweibull(SampleSize, .6, 1) # draw a random sample
ui&lt;-rexp(SampleSize, .2)         # censoring sample
cat("\n AMOUNT OF CENSORING: ", length(which(ti&gt;ui))/length(ti)*100, "\n")
x1&lt;-pmin(ti,ui)                  # observed data
cen&lt;-rep.int(1, SampleSize)      # initialize censoring indicators
cen[which(ti&gt;ui)]&lt;-0             # 0's correspond to censored indicators

a.use&lt;-DiscretizeData(ti, x)     # discretize the data
BinCenters&lt;-a.use$BinCenters     # get the data centers
ci&lt;-a.use$ci                     # get empircal hazard rate estimates
Delta=a.use$Delta                # Binning range


</code></pre>

<hr>
<h2 id='HazardHistogram'>Histogram Hazard Rate Estimator</h2><span id='topic+HazardHistogram'></span>

<h3>Description</h3>

<p>Implements the histogram hazard rate estimator of <a href="https://www.jstor.org/stable/42003749">Patil and Bagkavos (2012)</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HazardHistogram(xin, xout, cens, bin)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HazardHistogram_+3A_xin">xin</code></td>
<td>
<p> A vector of data points.  Missing values not allowed.</p>
</td></tr>
<tr><td><code id="HazardHistogram_+3A_xout">xout</code></td>
<td>
<p>A vector of grid points at which the histogram will be calculated.</p>
</td></tr>
<tr><td><code id="HazardHistogram_+3A_cens">cens</code></td>
<td>
<p> A vector of 1s and zeros, 1's indicate uncensored observations, 0's correspond to censored obs. </p>
</td></tr>
<tr><td><code id="HazardHistogram_+3A_bin">bin</code></td>
<td>
<p> Number of bins to use in construction of the histogram.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The histogram hazard rate estimator is defined in (1), <a href="https://www.jstor.org/stable/42003749">Patil and Bagkavos (2012)</a> by
</p>
<p style="text-align: center;"><code class="reqn">
\hat \lambda (x) = h_n^{-1} C_{i_{(x)}} = h_n^{-1}f_{i_{(x)}}^0(\bar F_{i_{(x)}}+1)^{-1}.
</code>
</p>


<h3>Value</h3>

<p>A vector with the values of the histogram estimate at each bin.
</p>


<h3>References</h3>

<p><a href="https://www.jstor.org/stable/42003749">Patil and Bagkavos (2012), Histogram for hazard rate estimation,  pp. 286-301, Sankhya, B.</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>SampleSize &lt;-400
ti&lt;-rweibull(SampleSize,0.5,0.8)
xout&lt;-seq(0.02, 3.5, length=80)
true.hazard&lt;-dweibull(xout,0.5, 0.8)/(1-pweibull(xout, 0.5, 0.8))
cen&lt;-rep.int(1, SampleSize)
cen[sample(1:SampleSize, SampleSize/10)]&lt;-0

band&lt;-nlminb(start= 2, obj=cvfunction, control = list(iter.max = 100, x.tol = .001)
            ,xin=ti, xout= xout, cens = cen, 	lower=.01, upper=max(xout))
bin&lt;- 3.49 * sd(ti)^2 * SampleSize^(-1/3) /50 #Scott 1979 Biometrika default rule
bin&lt;-unlist(band[1])
histest&lt;- HazardHistogram(ti,xout, cen, bin+0.013 )

plot(xout, true.hazard, type="l")
lines(histest[,1], histest[,2], col=2, type="s")
barplot( histest[,2], rep(bin, times=length(histest[,2])))
lines(xout, true.hazard, type="l", lwd=2, col=2)
</code></pre>

<hr>
<h2 id='HazardRateEst'>Kernel Hazard Rate Estimation</h2><span id='topic+HazardRateEst'></span>

<h3>Description</h3>

<p>Implements the (classical) kernel hazard rate estimator for right censored data defined in <a href="https://projecteuclid.org/download/pdf_1/euclid.aos/1176346265">Tanner and Wong (1983)</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HazardRateEst(xin, xout, kfun, h, ci)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HazardRateEst_+3A_xin">xin</code></td>
<td>
<p>A vector of data points.  Missing values not allowed.</p>
</td></tr>
<tr><td><code id="HazardRateEst_+3A_xout">xout</code></td>
<td>
<p>A vector of grid points at which the estimate will be calculated. </p>
</td></tr>
<tr><td><code id="HazardRateEst_+3A_kfun">kfun</code></td>
<td>
<p>Kernel function to use. Supported kernels: Epanechnikov, Biweight, Gaussian, Rectangular, Triangular, HigherOrder. </p>
</td></tr>
<tr><td><code id="HazardRateEst_+3A_h">h</code></td>
<td>
<p>A scalar, the bandwidth to use in the estimate. </p>
</td></tr>
<tr><td><code id="HazardRateEst_+3A_ci">ci</code></td>
<td>
<p>A vector of censoring indicators: 1's indicate uncensored observations, 0's correspond to censored obs.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The kernel hazard rate estimator of <a href="https://projecteuclid.org/download/pdf_1/euclid.aos/1176346265">Tanner and Wong (1983)</a> is given by
</p>
<p style="text-align: center;"><code class="reqn">\hat \lambda(x;h) = \sum_{i=1}^n \frac{K_h(x-X_{(i)})\delta_{(i)}}{n-i+1}</code>
</p>

<p><code class="reqn">h</code> is determined by  a bandwidth rule such as <code><a href="#topic+PlugInBand">PlugInBand</a></code>. <code><a href="#topic+HazardRateEst">HazardRateEst</a></code> is also used as a pilot estimate in the implementation of both the variable bandwidth estimate <code><a href="#topic+VarBandHazEst">VarBandHazEst</a></code> and the transformed hazard rate estimate  <code><a href="#topic+TransHazRateEst">TransHazRateEst</a></code>.
</p>


<h3>Value</h3>

<p>A vector with the hazard rate estimates at the designated points xout.
</p>


<h3>References</h3>

<p><a href="https://projecteuclid.org/download/pdf_1/euclid.aos/1176346265">Tanner and Wong (1983), The Estimation Of The Hazard Function From Randomly Censored Data By The Kernel Method, Annals of Statistics,  3, pp. 989-993.</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+VarBandHazEst">VarBandHazEst</a>, <a href="#topic+TransHazRateEst">TransHazRateEst</a>, <a href="#topic+PlugInBand">PlugInBand</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-seq(0, 5,length=100) #design points where the estimate will be calculated
plot(x, HazardRate(x, "weibull", .6, 1),  type="l", xlab = "x",
                   ylab="Hazard rate") #plot true hazard rate function
SampleSize &lt;- 100
ti&lt;- rweibull(SampleSize, .6, 1)  #draw a random sample from the actual distribution
ui&lt;-rexp(SampleSize, .2)  #draw a random sample from the censoring distribution
cat("\n AMOUNT OF CENSORING: ", length(which(ti&gt;ui))/length(ti)*100, "\n")
x1&lt;-pmin(ti,ui)             #this is the observed sample
cen&lt;-rep.int(1, SampleSize) #censoring indicators
cen[which(ti&gt;ui)]&lt;-0        #censored values correspond to zero
huse&lt;-PlugInBand(x1, x,   cen, Biweight)
arg2&lt;-HazardRateEst(x1, x, Epanechnikov, huse, cen) #Calculate the estimate
lines(x, arg2, lty=2)       #draw the result on the graphics device.
</code></pre>

<hr>
<h2 id='HRSurv'>Estimate of the constant in the optimal AMISE expression</h2><span id='topic+HRSurv'></span>

<h3>Description</h3>

<p>Calculation of the integrand of the contant term in the AMISE plugin bandwidth rule implemented in <code><a href="#topic+PlugInBand">PlugInBand</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HRSurv(x, xin, cens, h, kfun) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HRSurv_+3A_xin">xin</code></td>
<td>
<p> A vector of data points</p>
</td></tr>
<tr><td><code id="HRSurv_+3A_x">x</code></td>
<td>
<p> The point at which the estimates should be calculated.</p>
</td></tr>
<tr><td><code id="HRSurv_+3A_cens">cens</code></td>
<td>
<p> Censoring Indicators.</p>
</td></tr>
<tr><td><code id="HRSurv_+3A_h">h</code></td>
<td>
<p> bandwidth to use.</p>
</td></tr>
<tr><td><code id="HRSurv_+3A_kfun">kfun</code></td>
<td>
<p> The kernel function to use.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates the term
</p>
<p style="text-align: center;"><code class="reqn">  \frac{\lambda_T(x)}{1-F(x)}\,dx </code>
</p>

<p>which is passed then as argument to the function  <code><a href="#topic+NP.M.Estimate">NP.M.Estimate</a></code> for numerical integtaion. Currrently the fraction is estimated by
</p>
<p style="text-align: center;"><code class="reqn">\frac{\hat \lambda(x;b)}{1-\hat F(x)}</code>
</p>

<p>where <code class="reqn">\hat \lambda(x;b)</code> is implemented by <code><a href="#topic+HazardRateEst">HazardRateEst</a></code> using bandwidth <code>bw.nrd{xin}</code>. For <code class="reqn">1-\hat F(x)</code> the Kaplan-Meier estimate <code><a href="#topic+KMest">KMest</a></code> is used.
</p>


<h3>Value</h3>

<p>A vector with the value of the fraction.
</p>


<h3>References</h3>

<p><a href="https://onlinelibrary.wiley.com/doi/full/10.1111/anzs.12224">Hua, Patil and Bagkavos, An $L_1$ analysis of a kernel-based hazard rate estimator, Australian and New Zealand J. Statist., (60), 43-64, (2018).</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+PlugInBand">PlugInBand</a>, <a href="#topic+NP.M.Estimate">NP.M.Estimate</a> </code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-seq(0, 5,length=100) #design points where the estimate will be calculated
SampleSize&lt;-100 #amount of data to be generated
ti&lt;- rweibull(SampleSize, .6, 1) # draw a random sample
ui&lt;-rexp(SampleSize, .2)         # censoring sample
cat("\n AMOUNT OF CENSORING: ", length(which(ti&gt;ui))/length(ti)*100, "\n")
x1&lt;-pmin(ti,ui)                  # observed data
cen&lt;-rep.int(1, SampleSize)      # initialize censoring indicators
cen[which(ti&gt;ui)]&lt;-0             # 0's correspond to censored indicators

HRSurv(x, x1, cen, bw.nrd(x1), Biweight)
</code></pre>

<hr>
<h2 id='iHazardRateEst'>Kernel Integrated Hazard Rate Estimation</h2><span id='topic+iHazardRateEst'></span>

<h3>Description</h3>

<p>Implements the integrated kernel hazard rate estimator for right censored data, i.e. a kernel estimate of the cummulative hazard function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iHazardRateEst(xin, xout, ikfun, h, ci)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="iHazardRateEst_+3A_xin">xin</code></td>
<td>
<p>A vector of data points.  Missing values not allowed.</p>
</td></tr>
<tr><td><code id="iHazardRateEst_+3A_xout">xout</code></td>
<td>
<p>A vector of grid points at which the estimates will be calculated. </p>
</td></tr>
<tr><td><code id="iHazardRateEst_+3A_ikfun">ikfun</code></td>
<td>
<p>Integrated kernel function to use</p>
</td></tr>
<tr><td><code id="iHazardRateEst_+3A_h">h</code></td>
<td>
<p>A scalar, the bandwidth to use in the estimate. </p>
</td></tr>
<tr><td><code id="iHazardRateEst_+3A_ci">ci</code></td>
<td>
<p>A vector of censoring indicators: 1's indicate uncensored observations, 0's correspond to censored obs.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code><a href="#topic+iHazardRateEst">iHazardRateEst</a></code> implements the cummulative hazard rate estimator <code class="reqn">\hat \Lambda(x; h_1)</code> given by
</p>
<p style="text-align: center;"><code class="reqn">\hat \Lambda(x; h_1) =   \sum_{i=1}^n \frac{k\left \{(x-X_{(i)})h_1^{-1}\right \}\delta_{(i)}}{n-i+1}</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">k(x) = \int_{-\infty}^x K(y)\,dy</code>
</p>

<p>Note that  <code><a href="#topic+iHazardRateEst">iHazardRateEst</a></code> is used in the implementation of the transformed hazard rate estimate  <code><a href="#topic+TransHazRateEst">TransHazRateEst</a></code>.
</p>


<h3>Value</h3>

<p>A vector with the cummulative hazard rate estimates at the designated points xout.
</p>


<h3>References</h3>

<p><a href="https://projecteuclid.org/download/pdf_1/euclid.aos/1176346265">Tanner and Wong (1983), The Estimation Of The Hazard Function From Randomly Censored Data By The Kernel Method, Annals of Statistics,  3, pp. 989-993.</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+VarBandHazEst">VarBandHazEst</a>, <a href="#topic+TransHazRateEst">TransHazRateEst</a>, <a href="#topic+PlugInBand">PlugInBand</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-seq(0, 5,length=100) #design points where the estimate will be calculated

SampleSize &lt;- 100
ti&lt;- rweibull(SampleSize, .6, 1)  #draw a random sample from the actual distribution
ui&lt;-rexp(SampleSize, .2)  #draw a random sample from the censoring distribution
cat("\n AMOUNT OF CENSORING: ", length(which(ti&gt;ui))/length(ti)*100, "\n")
x1&lt;-pmin(ti,ui)             #this is the observed sample
cen&lt;-rep.int(1, SampleSize) #censoring indicators
cen[which(ti&gt;ui)]&lt;-0        #censored values correspond to zero
huse&lt;-PlugInBand(x1, x,   cen, Biweight)
arg2&lt;-iHazardRateEst(x1, x, IntEpanechnikov, huse, cen) #Calculate the estimate
</code></pre>

<hr>
<h2 id='Kernels'>Kernel functions</h2><span id='topic+Biweight'></span><span id='topic+Epanechnikov'></span><span id='topic+Triangular'></span><span id='topic+Gaussian'></span><span id='topic+HigherOrder'></span><span id='topic+Rectangular'></span><span id='topic+IntBiweight'></span><span id='topic+IntEpanechnikov'></span><span id='topic+IntRectangular'></span><span id='topic+IntTriangular'></span><span id='topic+IntGaussian'></span><span id='topic+SDBiweight'></span><span id='topic+a0'></span><span id='topic+a1'></span><span id='topic+a2'></span><span id='topic+BoundaryBiweight'></span><span id='topic+b0'></span><span id='topic+b1'></span><span id='topic+b2'></span><span id='topic+BoundaryEpanechnikov'></span><span id='topic+Habbema'></span>

<h3>Description</h3>

<p>Implements various kernel functions, including boundary, integrated and discrete kernels for use in the definition of the nonparametric estimates
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Biweight(x, ...)
Epanechnikov(x, ...)
Triangular(x, ...)
Gaussian(x, ...)
HigherOrder(x, ...)
Rectangular(x, ...)
IntBiweight(x)
IntEpanechnikov(x)
IntRectangular(x)
IntTriangular(x)
IntGaussian(x)
SDBiweight(x)
a0(x,h)
a1(x,h)
a2(x,h)
BoundaryBiweight(x, h)
b0(x,h)
b1(x,h)
b2(x,h)
BoundaryEpanechnikov(x, h)
Habbema(xin, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Kernels_+3A_x">x</code></td>
<td>
<p> A vector of data points where the kernel will be evaluated.</p>
</td></tr>
<tr><td><code id="Kernels_+3A_h">h</code></td>
<td>
<p>A scalar.</p>
</td></tr>
<tr><td><code id="Kernels_+3A_xin">xin</code></td>
<td>
<p>Discrete data inputs especially for the Habbema discrete kernel.</p>
</td></tr>
<tr><td><code id="Kernels_+3A_...">...</code></td>
<td>
<p>Further arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Implements the Biweight, Second Derivative Biweight,  Epanechnikov, Triangular, Guassian, Rectangular, the Boundary adjusted Biweight and Epanechnikov kernels. It also provides the kernel distribution functions for the Biweight, Epanechnikov, Rectangular, Triangular and Guassian kernels. Additionally it implements the discrete kernel Habbema.
</p>


<h3>Value</h3>

<p>The value of the kernel at <code class="reqn">x</code>
</p>


<h3>References</h3>


<ol>
<li> <p><a href="https://ieeexplore.ieee.org/document/4385743">Bagkavos and Patil, Local Polynomial Fitting in Failure Rate Estimation, IEEE Transactions on Reliability, 57, (2008)</a>,
</p>
</li>
<li> <p><a href="https://link.springer.com/article/10.1007/s10463-010-0277-6">Bagkavos (2011),  Annals of the Institute of Statistical Mathematics, 63(5), 1019-1046</a>,
</p>
</li></ol>


<hr>
<h2 id='KMest'>Kaplan-Meier Estimate</h2><span id='topic+KMest'></span>

<h3>Description</h3>

<p>Custom implementation of the Kaplan Meier estimate. The major difference with existing implementations is that the user can specify exactly the grid points where the estimate is calculated. The implementation corresponds to <code class="reqn">1-\hat H(x)</code> of <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/anzs.12224">Hua, Patil and Bagkavos (2018)</a>, and is used mainly for estimation of the censoring distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KMest(xin, cens, xout) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KMest_+3A_xin">xin</code></td>
<td>
<p> A vector of data points</p>
</td></tr>
<tr><td><code id="KMest_+3A_xout">xout</code></td>
<td>
<p> The point at which the estimates should be calculated.</p>
</td></tr>
<tr><td><code id="KMest_+3A_cens">cens</code></td>
<td>
<p> Censoring Indicators.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates the well known Kaplan-Meier estimate
</p>
<p style="text-align: center;"><code class="reqn">1-\hat H(x) =  1,   0 \leq x \leq X_{(1)}</code>
</p>
<p> or
</p>
<p style="text-align: center;"><code class="reqn">
1-\hat H(x) = \prod_{i=1}^{k-1} \left ( \frac{n-i+1}{n-i+2} \right )^{1-\delta_{(i)}},   X_{(k-1)} &lt;x \leq X_{(k)}, k=2,\dots,n </code>
</p>
<p> or
</p>
<p style="text-align: center;"><code class="reqn">
1-\hat H(x) = \prod_{i=1}^{n} \left ( \frac{n-i+1}{n-i+2} \right )^{1-\delta_{(i)}},  X_{(n)}&lt;x.</code>
</p>

<p>The implementation is mainly for estimating the censoring distribution of the available sample.
</p>


<h3>Value</h3>

<p>A vector with the Kaplan-Meier estimate at xout.
</p>


<h3>References</h3>

<p><a href="https://www.jstor.org/stable/2281868">Kaplan, E. L., and Paul Meier. Nonparametric Estimation from Incomplete Observations., J. of the American Statist. Association 53, (1958): 457-81.</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-seq(0, 5,length=100) #design points where the estimate will be calculated
SampleSize&lt;-100 #amount of data to be generated
ti&lt;- rweibull(SampleSize, .6, 1) # draw a random sample
ui&lt;-rexp(SampleSize, .2)         # censoring sample
cat("\n AMOUNT OF CENSORING: ", length(which(ti&gt;ui))/length(ti)*100, "\n")
x1&lt;-pmin(ti,ui)                  # observed data
cen&lt;-rep.int(1, SampleSize)      # initialize censoring indicators
cen[which(ti&gt;ui)]&lt;-0             # 0's correspond to censored indicators

arg1&lt;- KMest(x1, cen, x)
plot(x, arg1, type="l")
</code></pre>

<hr>
<h2 id='l1-l4+2C+20lw+2C+20lwF+2C+20gx'>Weibull hazard rate functionals</h2><span id='topic+l1'></span><span id='topic+l2'></span><span id='topic+l3'></span><span id='topic+l4'></span><span id='topic+lw'></span><span id='topic+lwF'></span><span id='topic+gx'></span>

<h3>Description</h3>

<p>Privides the various hazard rate function derivatives and related functionals with reference to the Weibull function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>l1(x,p,l)
l2(x,p,l)
l3(x,p,l)
l4(x,p,l)
lw(x,p,l)
lwF(x,p,l)
gx(x,p,l)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="l1-l4+2B2C+2B20lw+2B2C+2B20lwF+2B2C+2B20gx_+3A_x">x</code></td>
<td>
<p>A vector of points at which the hazard rate function will be estimated. </p>
</td></tr>
<tr><td><code id="l1-l4+2B2C+2B20lw+2B2C+2B20lwF+2B2C+2B20gx_+3A_p">p</code></td>
<td>
<p>MLE estimate of the shape parameter</p>
</td></tr>
<tr><td><code id="l1-l4+2B2C+2B20lw+2B2C+2B20lwF+2B2C+2B20gx_+3A_l">l</code></td>
<td>
<p>MLE estimate of the scale parameter</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Implements the necessary functions for calculating the squared bias term of the variable bandwidth estimate.
</p>


<h3>Value</h3>

<p>A vector with the values of the function at the designated points x.
</p>


<h3>References</h3>

<p><a href="http://dx.doi.org/10.1080/03610920802364088">Bagkavos and Patil (2009), Variable Bandwidths for Nonparametric Hazard Rate Estimation, Communications in Statistics - Theory and Methods, 38:7, 1055-1078</a>
</p>

<hr>
<h2 id='lambdahat'>Discrete non parametric mle hazard rate estimator</h2><span id='topic+lambdahat'></span>

<h3>Description</h3>

<p>Implementation of the purely nonparametric discrete hazard rate estimator <code>lambdahat</code> discussed among others in <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.201100058">Patil and Bagkavos (2012)</a>.  <code>lambdahat</code> is also used as the nonparametric component in the implementation of <code><a href="#topic+SemiparamEst">SemiparamEst</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> lambdahat(xin, cens, xout)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lambdahat_+3A_xin">xin</code></td>
<td>
<p>A vector of data points.  Missing values not allowed.</p>
</td></tr>
<tr><td><code id="lambdahat_+3A_cens">cens</code></td>
<td>
<p>Censoring indicators as a vector of 1s and zeros, 1's indicate uncensored observations, 0's correspond to censored obs.</p>
</td></tr>
<tr><td><code id="lambdahat_+3A_xout">xout</code></td>
<td>
<p>The grid points where the estimates will be calculated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The discrete - crude - hazard rate estimator (NPMLE) in <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.201100058">Patil and Bagkavos (2012)</a> is given by
</p>
<p style="text-align: center;"><code class="reqn">\hat \lambda(t_k) =   \frac{n^0_k}{m_k+1} </code>
</p>



<h3>Value</h3>

<p>Returns a vector with the values of the hazard rate estimates at <code class="reqn">x=xout</code>.
</p>


<h3>References</h3>

<p><a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.201100058">Patil and Bagkavos (2012), Semiparametric smoothing of discrete failure time data,  Biometrical Journal, 54, (2012), 5&ndash;19.</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SemiparamEst">SemiparamEst</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>options(echo=FALSE)
xin&lt;-c(7,34,42,63,64, 74, 83, 84, 91, 108, 112,129, 133,133,139,140,140,146,
      149,154,157,160,160,165,173,176,185, 218,225,241, 248,273,277,279,297,
      319,405,417,420,440, 523,523,583, 594, 1101, 1116, 1146, 1226, 1349,
      1412, 1417)
cens&lt;-c(1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,
        0,1,0,1,1,1,1,1,0,1,1,1,0,1)
xin&lt;-xin/30.438    #Adjust the data
storage.mode(xin)&lt;-"integer"  # turn the data to integers
xout&lt;-seq(1,47, by=1)  # define the grid points to evaluate the estimate
arg&lt;-TutzPritscher(xin,cens,xout)   #Discrete kernel estimate
plot(xout, arg, type="l", ylim=c(0, .35), lty=2,  col=6) # plot the estimate
argSM&lt;-lambdahat(xin, cens, xout)  #crude nonparametric estimate
lines(xout, argSM, lty=3, col=5) # plot the crude estimate
</code></pre>

<hr>
<h2 id='LLHRPlugInBand'>Simple Plug in badnwidth selector</h2><span id='topic+LLHRPlugInBand'></span>

<h3>Description</h3>

<p>Provides  the asymptotic MISE optimal plug-in bandwidth for the local linear hazard rate estimator <code><a href="#topic+LocLinEst">LocLinEst</a></code>, defined in (4),  <a href="https://link.springer.com/article/10.1007/s10463-010-0277-6">Bagkavos (2011)</a>. This is the binned data version of the <code><a href="#topic+PlugInBand">PlugInBand</a></code> AMISE optimal bandwidth rule.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LLHRPlugInBand(BinCenters, h, kfun, Delta, xin, xout, IntKfun, ci, cens)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LLHRPlugInBand_+3A_bincenters">BinCenters</code></td>
<td>
<p> A vector of data points, the centers of the bins resulting from the discretization of the data.</p>
</td></tr>
<tr><td><code id="LLHRPlugInBand_+3A_h">h</code></td>
<td>
<p> Bandwidth for the estimate of the distribution function. </p>
</td></tr>
<tr><td><code id="LLHRPlugInBand_+3A_kfun">kfun</code></td>
<td>
<p> A kernel function. </p>
</td></tr>
<tr><td><code id="LLHRPlugInBand_+3A_delta">Delta</code></td>
<td>
<p>A scalar. The length of the bins. </p>
</td></tr>
<tr><td><code id="LLHRPlugInBand_+3A_xin">xin</code></td>
<td>
<p> A vector of data points</p>
</td></tr>
<tr><td><code id="LLHRPlugInBand_+3A_xout">xout</code></td>
<td>
<p> The point at which the estimates should be calculated.</p>
</td></tr>
<tr><td><code id="LLHRPlugInBand_+3A_intkfun">IntKfun</code></td>
<td>
<p> The integrated kernel function.</p>
</td></tr>
<tr><td><code id="LLHRPlugInBand_+3A_ci">ci</code></td>
<td>
<p> Crude hazard rate estimates.</p>
</td></tr>
<tr><td><code id="LLHRPlugInBand_+3A_cens">cens</code></td>
<td>
<p> Censoring Indicators.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The bandwidth selector requires binned data, i.e. data in the form <code class="reqn">(x_i, y_i)</code> where <code class="reqn">x_i</code> are the bin centers and <code class="reqn">y_i</code> are empirircal hazard rate estimates at each <code class="reqn">x_i</code>. This is achieved  via  the <code><a href="#topic+DiscretizeData">DiscretizeData</a></code> function. As it can be seen from (4) in <a href="https://link.springer.com/article/10.1007/s10463-010-0277-6">Bagkavos (2011)</a>, the bandwidth selector also requires an estimate of the functional
</p>
<p style="text-align: center;"><code class="reqn">
\int \left \{ \lambda^{(2)}(x) \right \}^2 \,dx
</code>
</p>

<p>which is readily implemented in <code><a href="#topic+PlugInBand">PlugInBand</a></code>. It also requires an estimate of the constant
</p>
<p style="text-align: center;"><code class="reqn">
\int \frac{\lambda(x)}{1-F(x)} \,dx
</code>
</p>

<p>For this reason additionally the  plug in bandwidth rule is also used, as it is implemented in the  <code><a href="stats.html#topic+bw.nrd">bw.nrd</a></code> distribution function default bandwidth rule of <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9469.2005.00472.x">Swanepoel and Van Graan (2005)</a>. The constants <code class="reqn">R(K)</code> and <code class="reqn">\mu_2^2(K)</code> are deterministic and specific to the kernel used in the implementation hence can be claculated precisely.
</p>


<h3>Value</h3>

<p>A scalar with the value of the suggested bandwidth.
</p>


<h3>References</h3>

<p><a href="https://link.springer.com/article/10.1007/s10463-010-0277-6">Bagkavos (2011), Annals of the Institute of Statistical Mathematics, 63(5), 1019-1046.</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+PlugInBand">PlugInBand</a> </code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-seq(0, 5,length=100) #design points where the estimate will be calculated
SampleSize&lt;-100 #amount of data to be generated
ti&lt;- rweibull(SampleSize, .6, 1) # draw a random sample
ui&lt;-rexp(SampleSize, .2)         # censoring sample
cat("\n AMOUNT OF CENSORING: ", length(which(ti&gt;ui))/length(ti)*100, "\n")
x1&lt;-pmin(ti,ui)                  # observed data
cen&lt;-rep.int(1, SampleSize)      # initialize censoring indicators
cen[which(ti&gt;ui)]&lt;-0             # 0's correspond to censored indicators

a.use&lt;-DiscretizeData(ti, x)     # discretize the data
BinCenters&lt;-a.use$BinCenters     # get the data centers
ci&lt;-a.use$ci                     # get empircal hazard rate estimates
Delta=a.use$Delta                # Binning range
h2&lt;-bw.nrd(ti)                   # Bandwidth to use in constant est. of the plug in rule
h.use&lt;-h2                        # the first element is the band to use

huse1&lt;- LLHRPlugInBand(BinCenters,h.use,Epanechnikov,Delta,ti,x,IntEpanechnikov,ci,cen)
huse1


</code></pre>

<hr>
<h2 id='LocLinEst'>Local Linear Hazard Rate Estimator</h2><span id='topic+LocLinEst'></span>

<h3>Description</h3>

<p>Implements the local linear kernel hazard rate estimate of <a href="https://ieeexplore.ieee.org/document/4385743">Bagkavos and Patil (2008)</a> and <a href="https://link.springer.com/article/10.1007/s10463-010-0277-6">Bagkavos (2011)</a>. The estimate assumes binned data (fixed design), of the form <code class="reqn">(x_i, y_i)</code> where <code class="reqn">x_i</code> are the bin centers and <code class="reqn">y_i</code> are empirircal hazard rate estimates at each <code class="reqn">x_i</code>. These are calculated  via  the <code><a href="#topic+DiscretizeData">DiscretizeData</a></code> function. The estimate then smooths the empircal hazard rate estimates and achieves  automatic  boundary adjustments through approrpiately defined kernel weights. The user is able to supply their own bandwidth values through the <code class="reqn">h</code> argument.
</p>
<p>Currently only the <code><a href="#topic+LLHRPlugInBand">LLHRPlugInBand</a></code> bandwidth selector is provided which itself it depends on the <code><a href="stats.html#topic+bw.nrd">bw.nrd</a></code> distribution function default bandwidth rule of <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9469.2005.00472.x">Swanepoel and Van Graan (2005)</a> for the constant estimate.
</p>

<ul>
<li><p> TO DO: In future implementations the EBBS (empirical bias bandwidth) and AIC based bandwidth methods (see <a href="https://link.springer.com/article/10.1007/s10463-010-0277-6">Bagkavos (2011)</a>) will be added to the package</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>LocLinEst(BinCenters, xout, h, kfun, ci)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LocLinEst_+3A_bincenters">BinCenters</code></td>
<td>
<p> A vector with the bin centers of the discretized data.</p>
</td></tr>
<tr><td><code id="LocLinEst_+3A_xout">xout</code></td>
<td>
<p> A vector of points at which the hazard rate function will be estimated. </p>
</td></tr>
<tr><td><code id="LocLinEst_+3A_h">h</code></td>
<td>
<p> A scalar, the bandwidth to use in the estimate. </p>
</td></tr>
<tr><td><code id="LocLinEst_+3A_kfun">kfun</code></td>
<td>
<p> Kernel function to use. Supported kernels: Epanechnikov, Biweight, Gaussian, Rectangular, Triangular</p>
</td></tr>
<tr><td><code id="LocLinEst_+3A_ci">ci</code></td>
<td>
<p> Empirical hazard rate estimates.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The estimate in both <a href="https://ieeexplore.ieee.org/document/4385743">Bagkavos and Patil (2008)</a> and <a href="https://link.springer.com/article/10.1007/s10463-010-0277-6">Bagkavos (2011)</a> is given by
</p>
<p style="text-align: center;"><code class="reqn">
 \hat \lambda_L(x)= \frac{T_{n,1}(x) S_{n,1}(x) - T_{n,0}(x) S_{n,2}(x)}{S_{n,1}(x)S_{n,1}(x)-S_{n,0}(x)S_{n,2}(x)}.
</code>
</p>

<p>The difference between the censored and the uncensored cased is only on the calculation of the empirical hazard rate estimates.
</p>


<h3>Value</h3>

<p>A vector with the values of the function at the designated points xout.
</p>


<h3>References</h3>


<ol>
<li> <p><a href="https://ieeexplore.ieee.org/document/4385743">Bagkavos and Patil, Local Polynomial Fitting in Failure Rate Estimation, IEEE Transactions on Reliability, 57, (2008)</a>,
</p>
</li>
<li> <p><a href="https://link.springer.com/article/10.1007/s10463-010-0277-6">Bagkavos (2011),  Annals of the Institute of Statistical Mathematics, 63(5), 1019-1046</a>,
</p>
</li></ol>



<h3>See Also</h3>

 <p><code><a href="#topic+HazardRateEst">HazardRateEst</a>, <a href="#topic+LLHRPlugInBand">LLHRPlugInBand</a> </code></p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-seq(0.05, 5,length=80) #grid points to calculate the estimates
plot(x, HazardRate(x,"weibull", .6, 1),type="l", xlab = "x",ylab="Hazard rate")

SampleSize = 100                 #select sample size
ti&lt;- rweibull(SampleSize, .6, 1) # draw a random sample
ui&lt;-rexp(SampleSize, .2)         # censoring sample
cat("\n AMOUNT OF CENSORING: ", length(which(ti&gt;ui))/length(ti)*100, "\n")
x1&lt;-pmin(ti,ui)                  # observed data
cen&lt;-rep.int(1, SampleSize)      # initialize censoring indicators
cen[which(ti&gt;ui)]&lt;-0             # 0's correspond to censored indicators

a.use&lt;-DiscretizeData(ti, x)     # discretize the data
BinCenters&lt;-a.use$BinCenters     # get the data centers
ci&lt;-a.use$ci                     # get empircal hazard rate estimates
Delta=a.use$Delta                # Binning range
h2&lt;-bw.nrd(ti)                   # Bandwidth to use in constant est. of the plug in rule
h.use&lt;-h2                        # the first element is the band to use

# Calcaculate the plug-in bandwidth:
huse1&lt;- LLHRPlugInBand(BinCenters,h.use,Epanechnikov,Delta,ti,x,IntEpanechnikov,ci, cen)
arg2&lt;-HazardRateEst(x1,x,Epanechnikov, huse1, cen)      # Tanner-Wong Estimate
lines(x, arg2, lty=2) # draw the Tanner-Wong   estimate # Draw TW estimate
arg5&lt;-HazardRateEst(x1,x,BoundaryBiweight,huse1,cen)    # Boundary adjusted TW est
lines(x, arg5, lty=2, col=4) # draw the variable bandwidth # Draw the estimate
arg6&lt;-LocLinEst(BinCenters ,x, huse1, Epanechnikov, ci) # Local linear est.
lines(x, arg6, lty=5, col=5)                             # Draw the estimate
legend("topright", c("Tanner-Wong",  "TW - Boundary Corrected", "Local Linear"),
          lty=c(2,2, 5), col=c(1,4, 5)) # add legend
</code></pre>

<hr>
<h2 id='NP.M.Estimate'>Estimate of bandwidth constant</h2><span id='topic+NP.M.Estimate'></span>

<h3>Description</h3>

<p>Calculation of the contant term in the AMISE plugin bandwidth rule <code><a href="#topic+PlugInBand">PlugInBand</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NP.M.Estimate(xin, cens, xout) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NP.M.Estimate_+3A_xin">xin</code></td>
<td>
<p> A vector of data points</p>
</td></tr>
<tr><td><code id="NP.M.Estimate_+3A_xout">xout</code></td>
<td>
<p> The point at which the estimates should be calculated.</p>
</td></tr>
<tr><td><code id="NP.M.Estimate_+3A_cens">cens</code></td>
<td>
<p> Censoring Indicators.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Approximates the term
</p>
<p style="text-align: center;"><code class="reqn">
 M = \int_0^T  \frac{ \lambda_T(x)  }{1-F(x)} \,dx
</code>
</p>

<p>which is needed in the optimal AMISE bandwidth expression of <code><a href="#topic+PlugInBand">PlugInBand</a></code>. The integrand
</p>
<p style="text-align: center;"><code class="reqn">  \frac{\lambda_T(x)}{1-F(x)}\,dx </code>
</p>

<p>is calculated by <code><a href="#topic+HRSurv">HRSurv</a></code> and integration is performed via the extended Simpson's numerical integration rule (<code><a href="#topic+SimpsonInt">SimpsonInt</a></code>).
</p>


<h3>Value</h3>

<p>A scalar with the value of the constant.
</p>


<h3>References</h3>

<p><a href="https://onlinelibrary.wiley.com/doi/full/10.1111/anzs.12224">Hua, Patil and Bagkavos, An $L_1$ analysis of a kernel-based hazard rate estimator, Australian and New Zealand J. Statist., (60), 43-64, (2018).</a>
</p>

<hr>
<h2 id='nsf+2C+20Tm+2C+20CparamCalculation+2C+20power.matrix+2C+20base+2C+20SmoothedEstimate'>Auxiliary functions for discrete hazard rate estimators</h2><span id='topic+nsf'></span><span id='topic+Tm'></span><span id='topic+CparamCalculation'></span><span id='topic+power.matrix'></span><span id='topic+base'></span><span id='topic+SmoothedEstimate'></span>

<h3>Description</h3>

<p>Auxiliary functions for discrete semiparametric and kernel smooth hazard rate estimation
</p>


<h3>Usage</h3>

<pre><code class='language-R'> nsf(xin, cens, xout)
 Tm(tk, xout, distribution, par1, par2)
 CparamCalculation(gamparam, VehHazard)
 power.matrix(M, n)
 base(m, b)
 SmoothedEstimate(NonParEst, VehHazard, gammapar, SCproduct, Cpar)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nsf+2B2C+2B20Tm+2B2C+2B20CparamCalculation+2B2C+2B20power.matrix+2B2C+2B20base+2B2C+2B20SmoothedEstimate_+3A_xin">xin</code></td>
<td>
<p>A vector of data points.  Missing values not allowed.</p>
</td></tr>
<tr><td><code id="nsf+2B2C+2B20Tm+2B2C+2B20CparamCalculation+2B2C+2B20power.matrix+2B2C+2B20base+2B2C+2B20SmoothedEstimate_+3A_cens">cens</code></td>
<td>
<p>A vector of 1s and zeros, 1's indicate uncensored observations, 0's correspond to censored obs. </p>
</td></tr>
<tr><td><code id="nsf+2B2C+2B20Tm+2B2C+2B20CparamCalculation+2B2C+2B20power.matrix+2B2C+2B20base+2B2C+2B20SmoothedEstimate_+3A_xout">xout</code></td>
<td>
<p>The points where the estimate should be calculated.</p>
</td></tr>
<tr><td><code id="nsf+2B2C+2B20Tm+2B2C+2B20CparamCalculation+2B2C+2B20power.matrix+2B2C+2B20base+2B2C+2B20SmoothedEstimate_+3A_tk">tk</code></td>
<td>
<p>desing points for the NPMLE estimate.</p>
</td></tr>
<tr><td><code id="nsf+2B2C+2B20Tm+2B2C+2B20CparamCalculation+2B2C+2B20power.matrix+2B2C+2B20base+2B2C+2B20SmoothedEstimate_+3A_distribution">distribution</code></td>
<td>
<p>which distribution to use?</p>
</td></tr>
<tr><td><code id="nsf+2B2C+2B20Tm+2B2C+2B20CparamCalculation+2B2C+2B20power.matrix+2B2C+2B20base+2B2C+2B20SmoothedEstimate_+3A_par1">par1</code></td>
<td>
<p>distribution parameter 1</p>
</td></tr>
<tr><td><code id="nsf+2B2C+2B20Tm+2B2C+2B20CparamCalculation+2B2C+2B20power.matrix+2B2C+2B20base+2B2C+2B20SmoothedEstimate_+3A_par2">par2</code></td>
<td>
<p>distribution parameter 2</p>
</td></tr>
<tr><td><code id="nsf+2B2C+2B20Tm+2B2C+2B20CparamCalculation+2B2C+2B20power.matrix+2B2C+2B20base+2B2C+2B20SmoothedEstimate_+3A_gamparam">gamparam</code></td>
<td>
<p>gamma parameter</p>
</td></tr>
<tr><td><code id="nsf+2B2C+2B20Tm+2B2C+2B20CparamCalculation+2B2C+2B20power.matrix+2B2C+2B20base+2B2C+2B20SmoothedEstimate_+3A_m">M</code></td>
<td>
<p>a matrix to be raised to a power</p>
</td></tr>
<tr><td><code id="nsf+2B2C+2B20Tm+2B2C+2B20CparamCalculation+2B2C+2B20power.matrix+2B2C+2B20base+2B2C+2B20SmoothedEstimate_+3A_n">n</code></td>
<td>
<p>the power the matrix will be raised at</p>
</td></tr>
<tr><td><code id="nsf+2B2C+2B20Tm+2B2C+2B20CparamCalculation+2B2C+2B20power.matrix+2B2C+2B20base+2B2C+2B20SmoothedEstimate_+3A_m">m</code></td>
<td>
<p>express m as a power of b</p>
</td></tr>
<tr><td><code id="nsf+2B2C+2B20Tm+2B2C+2B20CparamCalculation+2B2C+2B20power.matrix+2B2C+2B20base+2B2C+2B20SmoothedEstimate_+3A_b">b</code></td>
<td>
<p>express m as a power of b</p>
</td></tr>
<tr><td><code id="nsf+2B2C+2B20Tm+2B2C+2B20CparamCalculation+2B2C+2B20power.matrix+2B2C+2B20base+2B2C+2B20SmoothedEstimate_+3A_nonparest">NonParEst</code></td>
<td>
<p>The crude nonparametric hazard rate estimate.</p>
</td></tr>
<tr><td><code id="nsf+2B2C+2B20Tm+2B2C+2B20CparamCalculation+2B2C+2B20power.matrix+2B2C+2B20base+2B2C+2B20SmoothedEstimate_+3A_vehhazard">VehHazard</code></td>
<td>
<p>Vehicle hazard rate</p>
</td></tr>
<tr><td><code id="nsf+2B2C+2B20Tm+2B2C+2B20CparamCalculation+2B2C+2B20power.matrix+2B2C+2B20base+2B2C+2B20SmoothedEstimate_+3A_gammapar">gammapar</code></td>
<td>
<p>gamma parameter </p>
</td></tr>
<tr><td><code id="nsf+2B2C+2B20Tm+2B2C+2B20CparamCalculation+2B2C+2B20power.matrix+2B2C+2B20base+2B2C+2B20SmoothedEstimate_+3A_scproduct">SCproduct</code></td>
<td>
<p>SC product, the result of DetermineSCprod</p>
</td></tr>
<tr><td><code id="nsf+2B2C+2B20Tm+2B2C+2B20CparamCalculation+2B2C+2B20power.matrix+2B2C+2B20base+2B2C+2B20SmoothedEstimate_+3A_cpar">Cpar</code></td>
<td>
<p>C parameter, the result of CparamCalculation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Auxiliary functions for discrete hazard rate estimators. The function <code>nsf</code> is used for the kernel smooth estimate <code><a href="#topic+TutzPritscher">TutzPritscher</a></code>.
</p>

<ul>
<li><p>Tm used to calculate <code class="reqn">\max(t_k; 1-\sum_{l=0}^k \eta_l &gt; \epsilon), \epsilon&gt;0</code> in the implementation of the semiparametric estimate
</p>
</li>
<li><p>CparamCalculationreturns the C smoothing parameter calculated as <code class="reqn">C= \gamma/\max_{k \geq 0} ( \lambda(t_{k-1}) + \lambda(t_k) + \lambda(t_{k+1}) )</code>
</p>
</li>
<li><p>DetermineSCprodthis finds <code class="reqn">SC = \gamma((n+1) \hat B_1)^{-1} \hat V_1</code>  n = number of obs, gammapar = sum of vehicle haz at xout (computed elsewhere)
</p>
</li></ul>



<h3>Value</h3>

<p>A vector with the values of the hazard rate estimates.
</p>


<h3>References</h3>


<ol>
<li> <p><a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.201100058">Patil and Bagkavos (2012), Semiparametric smoothing of discrete failure time data,  Biometrical Journal, 54, (2012), 5&ndash;19.</a>
</p>
</li>
<li><p><a href="https://doi.org/10.1007/BF00128979">Tutz, G. and Pritscher, L. Nonparametric Estimation of Discrete Hazard Functions, Lifetime Data Anal, 2, 291-308 (1996)</a>
</p>
</li></ol>


<hr>
<h2 id='PlugInBand'>Simple Plug in badnwidth selector</h2><span id='topic+PlugInBand'></span>

<h3>Description</h3>

<p>Provides  the asymptotic MISE optimal plug-in bandwidth for the hazard rate estimator <code><a href="#topic+HazardRateEst">HazardRateEst</a></code>, see <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/anzs.12224">Hua, Patil and Bagkavos (2018).</a>  The bandwidth is also suitable for use   as a pilot bandwidth in  <code><a href="#topic+TransHazRateEst">TransHazRateEst</a> </code> and <code><a href="#topic+VarBandHazEst">VarBandHazEst</a></code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlugInBand(xin, xout,   cens, kfun ) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlugInBand_+3A_xin">xin</code></td>
<td>
<p> A vector of data points</p>
</td></tr>
<tr><td><code id="PlugInBand_+3A_xout">xout</code></td>
<td>
<p> The point at which the estimates should be calculated.</p>
</td></tr>
<tr><td><code id="PlugInBand_+3A_cens">cens</code></td>
<td>
<p> Censoring Indicators.</p>
</td></tr>
<tr><td><code id="PlugInBand_+3A_kfun">kfun</code></td>
<td>
<p> A kernel function. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The asymptotic MISE optimal plug-in bandwidth selector for <code><a href="#topic+HazardRateEst">HazardRateEst</a></code> is defined by
</p>
<p style="text-align: center;"><code class="reqn">h_{ opt} = \left[\frac{R(K)}{nR(\lambda_T'')\mu_{2,K}^2}\int \frac{\lambda_T(x)}{1-F(x)}\,dx \right]^{1/5} </code>
</p>

<p>see (9) in <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/anzs.12224">Hua, Patil and Bagkavos (2018)</a>. The   estimate of <code class="reqn">R(\lambda_T'')</code> to be used in <code class="reqn">h_{opt}</code> is
</p>
<p style="text-align: center;"><code class="reqn">
R(\hat \lambda_T'') = \int_0^\xi \left (\hat \lambda_T''(x|\hat b_n^\ast) \right )^2\,dx.
 </code>
</p>

<p>Also,
</p>
<p style="text-align: center;"><code class="reqn"> \int_0^T \frac{\lambda_T(x)}{1-F(x)}\,dx </code>
</p>

<p>is estimated by applying the extended Simpson's numerical integration rule, <code><a href="#topic+SimpsonInt">SimpsonInt</a></code>, on
</p>
<p style="text-align: center;"><code class="reqn">
 \frac{\hat \lambda_T(x|\hat b_n^\ast)  }{1-F(x)}
 </code>
</p>

<p>where <code class="reqn">1-F(x)</code> is estimated by <code><a href="#topic+KMest">KMest</a></code>. The estimation is implemented in the <code><a href="#topic+NP.M.Estimate">NP.M.Estimate</a></code> function.
</p>
<p>Currently <code class="reqn">b_n^\ast</code> is estimated by <code><a href="stats.html#topic+bw.nrd">bw.nrd</a></code>. However according to (11) in <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/anzs.12224">Hua, Patil and Bagkavos (2018).</a>, in future versions this package will support
</p>
<p style="text-align: center;"><code class="reqn">
b_n^\ast = \left \{ \frac{5R(K'')}{n \mu_{2,K}^2 R(\lambda_T^{(4)})} \int \frac{\lambda_T(x)}{1-F(x)}\,dx  \right \}^{1/9}.</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">
R(\hat  \lambda_T^{(4)}) =  \frac{(\hat a(\hat a-1)(\hat a-2)(\hat a-3)(\hat a-4))^2}{(2\hat a-9){\hat{b}}^{2\hat a} } (\xi^{2\hat a-9} - {p_\alpha}^{2\hat a-9}), \hat a\neq 9/2
</code>
</p>

<p>and <code class="reqn">\hat M</code> is already estimated by <code><a href="#topic+NP.M.Estimate">NP.M.Estimate</a></code> as expalined above (it will be much more stable than using a Weibull reference model).
</p>


<h3>Value</h3>

<p>A scalar with the value of the suggested bandwidth.
</p>


<h3>References</h3>

<p><a href="https://onlinelibrary.wiley.com/doi/full/10.1111/anzs.12224">Hua, Patil and Bagkavos, An $L_1$ analysis of a kernel-based hazard rate estimator, Australian and New Zealand J. Statist., (60), 43-64, (2018).</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+HazardRateEst">HazardRateEst</a>, <a href="#topic+LLHRPlugInBand">LLHRPlugInBand</a> </code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-seq(0, 5,length=100) #design points where the estimate will be calculated
SampleSize&lt;-100 #amount of data to be generated
ti&lt;- rweibull(SampleSize, .6, 1) # draw a random sample
ui&lt;-rexp(SampleSize, .2)         # censoring sample
cat("\n AMOUNT OF CENSORING: ", length(which(ti&gt;ui))/length(ti)*100, "\n")
x1&lt;-pmin(ti,ui)                  # observed data
cen&lt;-rep.int(1, SampleSize)      # initialize censoring indicators
cen[which(ti&gt;ui)]&lt;-0             # 0's correspond to censored indicators

huse1&lt;- PlugInBand(x1, x, cen, Biweight)
huse1


</code></pre>

<hr>
<h2 id='RdistSwitch+2C+20PdfSwitch+2C+20CdfSwitch+2C+20HazardRate'>User driven input for random number generation and pdf, survival and hazard rate function calculation</h2><span id='topic+RdistSwitch'></span><span id='topic+PdfSwitch'></span><span id='topic+CdfSwitch'></span><span id='topic+HazardRate'></span>

<h3>Description</h3>

<p>Auxiliary functions that help automate the process of random number generation or pdf, survival function or hazard rate functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RdistSwitch(dist, SampleSize, par1, par2)
PdfSwitch(xout, dist, par1, par2)
CdfSwitch(xout, dist, par1, par2)
HazardRate(xout, dist, par1, par2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RdistSwitch+2B2C+2B20PdfSwitch+2B2C+2B20CdfSwitch+2B2C+2B20HazardRate_+3A_dist">dist</code></td>
<td>
<p>A string. Corresponds to one of weibull, lognorm, chisquare, exponential, binomial, geometric, poisson, negativebinomial, uniform</p>
</td></tr>
<tr><td><code id="RdistSwitch+2B2C+2B20PdfSwitch+2B2C+2B20CdfSwitch+2B2C+2B20HazardRate_+3A_samplesize">SampleSize</code></td>
<td>
<p>The size of the random sample to be drawn</p>
</td></tr>
<tr><td><code id="RdistSwitch+2B2C+2B20PdfSwitch+2B2C+2B20CdfSwitch+2B2C+2B20HazardRate_+3A_xout">xout</code></td>
<td>
<p>Grid points where the function will be evaluated</p>
</td></tr>
<tr><td><code id="RdistSwitch+2B2C+2B20PdfSwitch+2B2C+2B20CdfSwitch+2B2C+2B20HazardRate_+3A_par1">par1</code></td>
<td>
<p>parameter 1 of the distirbution</p>
</td></tr>
<tr><td><code id="RdistSwitch+2B2C+2B20PdfSwitch+2B2C+2B20CdfSwitch+2B2C+2B20HazardRate_+3A_par2">par2</code></td>
<td>
<p>parameter 2 of the distirbution</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Implements random number generation and density, survival and hazard rate estimates for several distributions. These functions are mainly used when simulating the mean square error etc from known distributions.</p>


<h3>Value</h3>

<p>A vector with the values of the function at the designated points xout or the random numbers drawn.
</p>

<hr>
<h2 id='SDHazardRateEst'>Kernel Second Derivative Hazard Rate Estimation</h2><span id='topic+SDHazardRateEst'></span>

<h3>Description</h3>

<p>Implements the kernel estimate of the second derivative of the hazard rate for right censored data defined - based on the estimate of <a href="https://projecteuclid.org/download/pdf_1/euclid.aos/1176346265">Tanner and Wong (1983)</a>. The implementation is based on the second derivative of the Biweight Kernel.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SDHazardRateEst(xin, xout, h, ci)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SDHazardRateEst_+3A_xin">xin</code></td>
<td>
<p>A vector of data points.  Missing values not allowed.</p>
</td></tr>
<tr><td><code id="SDHazardRateEst_+3A_xout">xout</code></td>
<td>
<p>A vector of grid points at which the estimates will be calculated. </p>
</td></tr>
<tr><td><code id="SDHazardRateEst_+3A_h">h</code></td>
<td>
<p>A scalar, the bandwidth to use in the estimate. </p>
</td></tr>
<tr><td><code id="SDHazardRateEst_+3A_ci">ci</code></td>
<td>
<p>A vector of censoring indicators: 1's indicate uncensored observations, 0's correspond to censored obs.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code><a href="#topic+SDHazardRateEst">SDHazardRateEst</a></code> implements the kernel estimate of the second derivative of the hazard rate estimator, given by
</p>
<p style="text-align: center;"><code class="reqn">\hat \lambda_2(x;h) = \sum_{i=1}^n \frac{K_h''(x-X_{(i)})\delta_{(i)}}{n-i+1}</code>
</p>

<p>where <code class="reqn">K</code> is taken to be the <code><a href="#topic+Biweight">Biweight</a></code> kernel. The function is used for estimation of the functional <code class="reqn">R(\lambda'')</code> in <code><a href="#topic+PlugInBand">PlugInBand</a></code> so a default bandwidth rule is used for <code class="reqn">h</code> provided in (16), <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/anzs.12224">Hua, Patil and Bagkavos (2018)</a>.
</p>


<h3>Value</h3>

<p>A vector with the second derivative of the hazard rate at the designated points xout.
</p>


<h3>References</h3>


<ol>
<li> <p><a href="https://projecteuclid.org/download/pdf_1/euclid.aos/1176346265">Tanner and Wong (1983), The Estimation Of The Hazard Function From Randomly Censored Data By The Kernel Method, Annals of Statistics,  3, pp. 989-993.</a>
</p>
</li>
<li> <p><a href="https://onlinelibrary.wiley.com/doi/full/10.1111/anzs.12224">Hua, Patil and Bagkavos, An $L_1$ analysis of a kernel-based hazard rate estimator, Australian and New Zealand J. Statist., (60), 43-64, (2018).</a>
</p>
</li></ol>


<hr>
<h2 id='SemiparamEst'>Discrete hazard rate estimator</h2><span id='topic+SemiparamEst'></span>

<h3>Description</h3>

<p>Implements the semiparametric hazard rate estimator for discrete data developed in <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.201100058">Patil and Bagkavos (2012)</a>. The estimate is obtained by semiparametric smoothing of the (nonsmooth) nonparametric maximum likelihood estimator, which is achieved by repeated multiplication of a Markov chain transition-type matrix. This matrix is constructed with basis
a parametric discrete hazard rate model (vehicle model). </p>


<h3>Usage</h3>

<pre><code class='language-R'>SemiparamEst(xin, cens, xout, Xdistr, Udistr, vehicledistr, Xpar1=1, Xpar2=0.5,
              Upar1=1, Upar2=0.5, vdparam1=1, vdparam2=0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SemiparamEst_+3A_xin">xin</code></td>
<td>
<p>A vector of data points.  Missing values not allowed.</p>
</td></tr>
<tr><td><code id="SemiparamEst_+3A_cens">cens</code></td>
<td>
<p>Censoring indicators as a vector of 1s and zeros, 1's indicate uncensored observations, 0's correspond to censored obs. </p>
</td></tr>
<tr><td><code id="SemiparamEst_+3A_xout">xout</code></td>
<td>
<p>Design points where the estimate will be calculated.</p>
</td></tr>
<tr><td><code id="SemiparamEst_+3A_xdistr">Xdistr</code></td>
<td>
<p>The distribution where the data are coming from, currently ignored</p>
</td></tr>
<tr><td><code id="SemiparamEst_+3A_udistr">Udistr</code></td>
<td>
<p>Censoring distribution, currently ignored</p>
</td></tr>
<tr><td><code id="SemiparamEst_+3A_vehicledistr">vehicledistr</code></td>
<td>
<p>String specifying the vehicle hazard rate (the assumed parametric model)</p>
</td></tr>
<tr><td><code id="SemiparamEst_+3A_xpar1">Xpar1</code></td>
<td>
<p>Parameter 1 for the X distr, currently ignored</p>
</td></tr>
<tr><td><code id="SemiparamEst_+3A_xpar2">Xpar2</code></td>
<td>
<p>Parameter 2 for the X distr, currently ignored</p>
</td></tr>
<tr><td><code id="SemiparamEst_+3A_upar1">Upar1</code></td>
<td>
<p>Parameter 1 for the Cens. distr., currently ignored</p>
</td></tr>
<tr><td><code id="SemiparamEst_+3A_upar2">Upar2</code></td>
<td>
<p>Parameter 2 for the Cens. distr., currently ignored</p>
</td></tr>
<tr><td><code id="SemiparamEst_+3A_vdparam1">vdparam1</code></td>
<td>
<p>Parameter 1 for the vehicle hazard rate. </p>
</td></tr>
<tr><td><code id="SemiparamEst_+3A_vdparam2">vdparam2</code></td>
<td>
<p>Parameter 2 for the vehicle hazard rate.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The semiparmaetric estimator implemented is defined in (1) in <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.201100058">Patil and Bagkavos (2012)</a> by
</p>
<p style="text-align: center;"><code class="reqn">\tilde \lambda  = \hat \lambda \Gamma^S</code>
</p>

<p>where <code class="reqn">S</code> determines the number of repetions and hence the amount of smoothing applied to the estimate. For <code class="reqn">S=0</code> the semiparametric estimate equals the nonparmaetric estimate <code><a href="#topic+lambdahat">lambdahat</a></code>. On the other hand, if the true unknown underlying probability model is known (up to an unknown constant or constants) then, the greater the <code class="reqn">S</code>, the closer the semiparmaetric estimate to the vehicle hazard rate model.
</p>

<ul>
<li><p>  TO DO: The extension to hazard rate estimation with covariates will be added in a future release.
</p>
</li>
<li><p> TO DO: Also, the data driven estimation of the parameter <code class="reqn">S</code> will be also added in a future release; this will inlcude the <code class="reqn">SC</code> product and <code class="reqn">C</code> and <code class="reqn">\gamma</code> parameter calculations.
</p>
</li></ul>



<h3>Value</h3>

<p>A vector with the values of the discrete hazard rate estimate, calculated at <code class="reqn">x=xout</code>.
</p>


<h3>References</h3>

<p><a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.201100058">Patil and Bagkavos (2012), Semiparametric smoothing of discrete failure time data,  Biometrical Journal, 54, (2012), 5-19</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lambdahat">lambdahat</a>, <a href="#topic+TutzPritscher">TutzPritscher</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>options(echo=FALSE)
xin&lt;-c(7,34,42,63,64, 74, 83, 84, 91, 108, 112,129, 133,133,139,140,140,146,
      149,154,157,160,160,165,173,176,185, 218,225,241, 248,273,277,279,297,
      319,405,417,420,440, 523,523,583, 594, 1101, 1116, 1146, 1226, 1349,
      1412, 1417) #head and neck data set
cens&lt;-c(1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,
        1,0,1,1,1,1,1,1,0,1,0,1,1,1,1,1,0,1,1,1,0,1) #censoring indicators
xin&lt;-xin/30.438 #mean adjust the data
storage.mode(xin)&lt;-"integer"  # turn the data to integers
xout&lt;-seq(1,47, by=1) #design points where to calculate the estimate
arg&lt;-TutzPritscher(xin,cens,xout) #Kernel smooth estimate
plot(xout, arg, type="l", ylim=c(0, .35), lty=2,  col=6)
argSM&lt;-SemiparamEst(xin, cens, xout, "geometric", "uniform",
                    "geometric", 0.2, .6, 0, 90, .25, .9) #semipar. est.
lines(xout, argSM[,2], lty=3, col=5) #add tilde lambda to the plot
</code></pre>

<hr>
<h2 id='SimpsonInt'>Simpson numerical integration</h2><span id='topic+SimpsonInt'></span>

<h3>Description</h3>

<p>Implements Simpson's extended numerical integration rule
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SimpsonInt(xin, h)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SimpsonInt_+3A_xin">xin</code></td>
<td>
<p> A vector of data points</p>
</td></tr>
<tr><td><code id="SimpsonInt_+3A_h">h</code></td>
<td>
<p> grid length</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extended numerical integration rule is given by
</p>
<p style="text-align: center;"><code class="reqn">
\int_0^{x_{2n}} f(x)\,dx = \frac{h}{3}(f(x_0) + 4\{f(x_1) + \dots f(x_{2n-1}) \}
      +2 \{f(x_2) + f(x_4) + \dots f(x_{2n-2})\} + f(x_{2n})) -R_n
</code>
</p>



<h3>Value</h3>

<p>returns the approximate integral value
</p>


<h3>References</h3>

<p><a href="http://mathworld.wolfram.com/SimpsonsRule.html">Weisstein, Eric W. &quot;Simpson's Rule.&quot; From MathWorld&ndash;A Wolfram Web Resource</a>
</p>

<hr>
<h2 id='sn.i+2C+20tn.i'>Local kernel weights</h2><span id='topic+sn.0'></span><span id='topic+sn.1'></span><span id='topic+sn.2'></span><span id='topic+sn.3'></span><span id='topic+sn.4'></span><span id='topic+sn.5'></span><span id='topic+sn.6'></span><span id='topic+tn.0'></span><span id='topic+tn.1'></span><span id='topic+tn.2'></span><span id='topic+tn.3'></span>

<h3>Description</h3>

<p>Implements the local kernel weights which are used in the implementation of <code><a href="#topic+LocLinEst">LocLinEst</a></code> and the second derivative estimate used in <code><a href="#topic+PlugInBand">PlugInBand</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sn.0(xin, xout, h, kfun)
sn.1(xin, xout, h, kfun)
sn.2(xin, xout, h, kfun)
sn.3(xin, xout, h, kfun)
sn.4(xin, xout, h, kfun)
sn.5(xin, xout, h, kfun)
sn.6(xin, xout, h, kfun)
tn.0(xin, xout, h, kfun, Y)
tn.1(xin, xout, h, kfun, Y)
tn.2(xin, xout, h, kfun, Y)
tn.3(xin, xout, h, kfun, Y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sn.i+2B2C+2B20tn.i_+3A_xin">xin</code></td>
<td>
<p> A vector of data points, typicaly these are the bin centers.  Missing values not allowed.</p>
</td></tr>
<tr><td><code id="sn.i+2B2C+2B20tn.i_+3A_xout">xout</code></td>
<td>
<p> A vector of data points where the estimate will be evaluated.</p>
</td></tr>
<tr><td><code id="sn.i+2B2C+2B20tn.i_+3A_h">h</code></td>
<td>
<p>A scalar. The bandwidth to use.</p>
</td></tr>
<tr><td><code id="sn.i+2B2C+2B20tn.i_+3A_kfun">kfun</code></td>
<td>
<p>The kernel function to use.</p>
</td></tr>
<tr><td><code id="sn.i+2B2C+2B20tn.i_+3A_y">Y</code></td>
<td>
<p>Empirical hazard rate estimates.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions calculate the quantities
</p>
<p style="text-align: center;"><code class="reqn">S_{n,l}(x) = \sum_{i=1}^n K \left (\frac{x_i-x}{h}\right ) (x_i-x)^l, l=0,\dots,6 </code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">T_{n,l}(x) = \sum_{i=1}^n K \left (\frac{x_i-x}{h}\right ) (x_i-x)^l Y_i, l=0,\dots,3</code>
</p>

<p>These qunatities are used to adjust the hazard rate estimate and its second derivative in the boundary.
</p>


<h3>Value</h3>

<p>The weight of the functional at <code class="reqn">x</code>
</p>


<h3>References</h3>


<ol>
<li> <p><a href="https://ieeexplore.ieee.org/document/4385743">Bagkavos and Patil, Local Polynomial Fitting in Failure Rate Estimation, IEEE Transactions on Reliability, 57, (2008)</a>,
</p>
</li>
<li> <p><a href="https://link.springer.com/article/10.1007/s10463-010-0277-6">Bagkavos (2011),  Annals of the Institute of Statistical Mathematics, 63(5), 1019-1046</a>.
</p>
</li></ol>


<hr>
<h2 id='TransHazRateEst'>Transformation Based Hazard Rate Estimator</h2><span id='topic+TransHazRateEst'></span>

<h3>Description</h3>

<p>Implements the transformated kernel hazard rate estimator of <a href="http://dx.doi.org/10.1080/10485250802440184">Bagkavos (2008)</a>. The estimate is expected to have less bias compared to the ordinary kernel estimate <code><a href="#topic+HazardRateEst">HazardRateEst</a></code>. The estimate results by first transforming the data to a sample from the exponential distribution through the integrated hazard rate function, estimated by <code><a href="#topic+iHazardRateEst">iHazardRateEst</a></code> and uses the result as input to the classical kernel hazard rate estimate  <code><a href="#topic+HazardRateEst">HazardRateEst</a></code>. An inverse transform turn the estimate to a hazard rate estimate of the original sample. See section &quot;Details&quot; below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TransHazRateEst(xin, xout, kfun, ikfun, h1, h2, ci)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TransHazRateEst_+3A_xin">xin</code></td>
<td>
<p>A vector of data points.  Missing values not allowed.</p>
</td></tr>
<tr><td><code id="TransHazRateEst_+3A_xout">xout</code></td>
<td>
<p>A vector of points at which the hazard rate function will be estimated. </p>
</td></tr>
<tr><td><code id="TransHazRateEst_+3A_kfun">kfun</code></td>
<td>
<p>Kernel function to use. Supported kernels: Epanechnikov, Biweight, Gaussian, Rectangular, Triangular, HigherOrder.</p>
</td></tr>
<tr><td><code id="TransHazRateEst_+3A_ikfun">ikfun</code></td>
<td>
<p>An integrated kernel function to use. Supported kernels: Epanechnikov, Biweight, Gaussian, Rectangular, Triangular, HigherOrder.</p>
</td></tr>
<tr><td><code id="TransHazRateEst_+3A_h1">h1</code></td>
<td>
<p>A scalar, pilot bandwidth.</p>
</td></tr>
<tr><td><code id="TransHazRateEst_+3A_h2">h2</code></td>
<td>
<p>A scalar, transformed kernel bandwidth.</p>
</td></tr>
<tr><td><code id="TransHazRateEst_+3A_ci">ci</code></td>
<td>
<p>A vector of censoring indicators: 1's indicate uncensored observations, 0's correspond to censored obs. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The transformed kernel hazard rate estimate of <a href="http://dx.doi.org/10.1080/10485250802440184">Bagkavos (2008)</a> is given by
</p>
<p style="text-align: center;"><code class="reqn">\hat \lambda_t(x;h_1, h_2) = \sum_{i=1}^n  \frac{K_{h_2}\left \{ (\hat \Lambda(x;h_1 ) - \hat \Lambda(X_{(i)};h_1 ) ) \right \}\delta_{(i)}}{n-i+1}\hat \lambda(x;h_1 ).</code>
</p>

<p>The estimate uses the classical kernel hazard rate estimate <code class="reqn">\lambda(x; h_1)</code> implemented in <code><a href="#topic+HazardRateEst">HazardRateEst</a></code> and its integrated version
</p>
<p style="text-align: center;"><code class="reqn">\hat \Lambda(x; h_1) =  \sum_{i=1}^n \frac{k\left \{(x-X_{(i)})h_1^{-1}\right \}\delta_{(i)}}{n-i+1}</code>
</p>

<p>where
<code class="reqn">k(x) = \int_{-\infty}^x K(y)\,dy</code>
implemented in <code><a href="#topic+iHazardRateEst">iHazardRateEst</a></code>. The pilot bandwidth <code class="reqn">h_1</code> is determined by an optimal bandwidth rule such as <code><a href="#topic+PlugInBand">PlugInBand</a></code>.
</p>

<ul>
<li><p> TO DO: Insert a  rule for the adaptive bandwidth  <code class="reqn">h_2</code>. </p>
</li></ul>



<h3>Value</h3>

<p>A vector with the values of the function at the designated points xout.
</p>


<h3>References</h3>

<p><a href="http://dx.doi.org/10.1080/10485250802440184">Bagkavos (2008), Transformations in hazard rate estimation, J. Nonparam. Statist., 20, 721-738</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+VarBandHazEst">VarBandHazEst</a>, <a href="#topic+HazardRateEst">HazardRateEst</a>, <a href="#topic+PlugInBand">PlugInBand</a> </code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-seq(0, 5,length=100) #design points where the estimate will be calculated
plot(x, HazardRate(x, "weibull", .6, 1),  type="l",
                   xlab = "x", ylab="Hazard rate") #plot true hazard rate function
SampleSize &lt;- 100
mat&lt;-matrix(nrow=SampleSize, ncol=20)
for(i in 1:20)
{ #Calculate the average of 20 estimates and draw on the screen
 ti&lt;- rweibull(SampleSize, .6, 1)  #draw a random sample from the actual distribution
 ui&lt;-rexp(SampleSize, .05)          #draw a random sample from the censoring distribution
 cat("\n AMOUNT OF CENSORING: ", length(which(ti&gt;ui))/length(ti)*100, "\n")
 x1&lt;-pmin(ti,ui)                   #this is the observed sample
 cen&lt;-rep.int(1, SampleSize)       #censoring indicators
 cen[which(ti&gt;ui)]&lt;-0              #censored values correspond to zero

 h2&lt;-DefVarBandRule(ti, cen)     #Deafult Band. Rule - Weibull Reference
 huse1&lt;- PlugInBand(x1, x,   cen, Biweight) #
 mat[,i]&lt;-TransHazRateEst(x1,x,Epanechnikov,IntEpanechnikov,huse1,h2,cen)
}
lines(x, rowMeans(mat) , lty=2) #draw the average transformed estimate
</code></pre>

<hr>
<h2 id='TutzPritscher'>Discrete non parametric kernel hazard rate estimator</h2><span id='topic+TutzPritscher'></span>

<h3>Description</h3>

<p>Implementation of the kernel discrete hazard rate estimator of <a href="https://doi.org/10.1007/BF00128979">Tutz and Pritscher (1996)</a> based on the discrete <code><a href="#topic+Habbema">Habbema</a></code> kernel. The estimate is used for comparison with the semiparametric estimate deveoped in <a href="https://doi.org/10.1007/BF00128979">Tutz and Pritscher (1996)</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> TutzPritscher(xin, cens, xout)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TutzPritscher_+3A_xin">xin</code></td>
<td>
<p>A vector of data points.  Missing values not allowed.</p>
</td></tr>
<tr><td><code id="TutzPritscher_+3A_cens">cens</code></td>
<td>
<p>Censoring indicators as a vector of 1s and zeros, 1's indicate uncensored observations, 0's correspond to censored obs.</p>
</td></tr>
<tr><td><code id="TutzPritscher_+3A_xout">xout</code></td>
<td>
<p>The grid points where the estimates will be calculated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The discrete kernel estimate of <a href="https://doi.org/10.1007/BF00128979">Tutz and Pritscher (1996)</a> is defined by
</p>
<p style="text-align: center;"><code class="reqn">\hat \lambda(t_m|v) = \sum_{s=1}^q \sum_{i=1}^{m_s} w_m \left ( (t,x), (s, x_{is}) \right )\tilde \lambda(s|x_{is})</code>
</p>

<p>where <code class="reqn">w_m</code> is the discrete Habbema kernel.
</p>


<h3>Value</h3>

<p>Returns a vector with the values of the hazard rate estimates at <code class="reqn">x=xout</code>.
</p>


<h3>References</h3>

<p><a href="https://doi.org/10.1007/BF00128979">Tutz, G. and Pritscher, L. Nonparametric Estimation of Discrete Hazard Functions, Lifetime Data Anal, 2, 291-308 (1996)</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SemiparamEst">SemiparamEst</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>options(echo=FALSE)
xin&lt;-c(7,34,42,63,64, 74, 83, 84, 91, 108, 112,129, 133,133,139,140,140,146,
      149,154,157,160,160,165,173,176,185, 218,225,241, 248,273,277,279,297,
      319,405,417,420,440, 523,523,583, 594, 1101, 1116, 1146, 1226, 1349,
      1412, 1417)
cens&lt;-c(1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,
        0,1,0,1,1,1,1,1,0,1,1,1,0,1)
xin&lt;-xin/30.438    #Adjust the data
storage.mode(xin)&lt;-"integer"  # turn the data to integers
xout&lt;-seq(1,47, by=1)  # define the grid points to evaluate the estimate
arg&lt;-TutzPritscher(xin,cens,xout)   #Discrete kernel estimate
plot(xout, arg, type="l", ylim=c(0, .35), lty=2,  col=6) # plot the estimate
argSM&lt;-lambdahat(xin, cens, xout)  #crude nonparametric estimate
lines(xout, argSM, lty=3, col=5) # plot the crude estimate
</code></pre>

<hr>
<h2 id='VarBandHazEst'>Variable Bandwidth Hazard Rate Estimator</h2><span id='topic+VarBandHazEst'></span>

<h3>Description</h3>

<p>Implements the adaptive variable bandwidth hazard rate estimator of <a href="http://dx.doi.org/10.1080/03610920802364088">Bagkavos and Patil (2009)</a>. The estimate itself is an extension of the classical kernel hazard rate estimator of <a href="https://projecteuclid.org/download/pdf_1/euclid.aos/1176346265">Tanner and Wong (1983)</a> implemented in <code><a href="#topic+HazardRateEst">HazardRateEst</a></code>. The difference is that instead of <code class="reqn">h</code>, the variable bandwidth estimate uses bandwidth <code class="reqn">h \lambda(X_i)^{-1/2}</code>. This particular choice cancels the second order term in the bias expansion of the hazard rate estimate and thus it is expected to result in a more precise estimation compared to <code><a href="#topic+HazardRateEst">HazardRateEst</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VarBandHazEst(xin, xout, kfun, h1, h2, ci)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VarBandHazEst_+3A_xin">xin</code></td>
<td>
<p>A vector of data points.  Missing values not allowed.</p>
</td></tr>
<tr><td><code id="VarBandHazEst_+3A_xout">xout</code></td>
<td>
<p>A vector of points at which the hazard rate function will be estimated. </p>
</td></tr>
<tr><td><code id="VarBandHazEst_+3A_kfun">kfun</code></td>
<td>
<p>Kernel function to use. Supported kernels: Epanechnikov, Biweight, Gaussian, Rectangular, Triangular, HigherOrder</p>
</td></tr>
<tr><td><code id="VarBandHazEst_+3A_h1">h1</code></td>
<td>
<p>A scalar, pilot bandwidth. </p>
</td></tr>
<tr><td><code id="VarBandHazEst_+3A_h2">h2</code></td>
<td>
<p>A scalar, variable kernel (adaptive) bandwidth.</p>
</td></tr>
<tr><td><code id="VarBandHazEst_+3A_ci">ci</code></td>
<td>
<p>A vector of censoring indicators: 1's  indicate uncensored observations, 0's correspond to censored obs.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Implements the adaptive variable bandwidth hazard rate estimator of Bagkavos and Patil (2009), Comm. Statist. Theory and Methods.
</p>
<p style="text-align: center;"><code class="reqn">\hat \lambda_v(x;h_1, h_2) = \sum_{i=1}^n \hat \lambda^{-1/2}(x;h_1 ) \frac{K_{h_2}\left \{ (x-X_{(i)})\hat \lambda^{-1/2}(x;h_1 ) \right \}\delta_{(i)}}{n-i+1}</code>
</p>

<p>The pilot bandwidth <code class="reqn">h_1</code> is determined by an optimal bandwidth rule such as <code><a href="#topic+PlugInBand">PlugInBand</a></code>. and used as input to the pilot kernel estimate, implemented by <code><a href="#topic+HazardRateEst">HazardRateEst</a></code>.
</p>

<ul>
<li><p> TO DO: Insert a  rule for the adaptive bandwidth  <code class="reqn">h_2</code>. </p>
</li></ul>



<h3>Value</h3>

<p>A vector with the values of the function at the designated points xout.
</p>


<h3>References</h3>

<p><a href="http://dx.doi.org/10.1080/03610920802364088">Bagkavos and Patil (2009), Variable Bandwidths for Nonparametric Hazard Rate Estimation, Communications in Statistics - Theory and Methods, 38:7, 1055-1078</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+HazardRateEst">HazardRateEst</a>, <a href="#topic+TransHazRateEst">TransHazRateEst</a>, <a href="#topic+PlugInBand">PlugInBand</a> </code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-seq(0, 5,length=100) #design points where the estimate will be calculated
plot(x, HazardRate(x, "weibull", .6, 1),  type="l",
     xlab = "x", ylab="Hazard rate") #plot true hazard rate function
SampleSize &lt;- 100
mat&lt;-matrix(nrow=SampleSize, ncol=20)
for(i in 1:20)
{
  ti&lt;- rweibull(SampleSize, .6, 1)#draw a random sample from the actual distribution
  ui&lt;-rexp(SampleSize, .05)       #draw a random sample from the censoring distribution
  cat("\n AMOUNT OF CENSORING: ", length(which(ti&gt;ui))/length(ti)*100, "\n")
  x1&lt;-pmin(ti,ui)                 #this is the observed sample
  cen&lt;-rep.int(1, SampleSize)     #censoring indicators
  cen[which(ti&gt;ui)]&lt;-0            #censored values correspond to zero

  h2&lt;-DefVarBandRule(ti, cen)     #Deafult Band. Rule - Weibull Reference
  huse1&lt;-  PlugInBand(x1, x,   cen, Biweight)
  mat[,i]&lt;- VarBandHazEst(x1, x, Epanechnikov, huse1,h2, cen) #Var. bandwidth est.
}
lines(x, rowMeans(mat) , lty=2)   #draw the average  vb estimate
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
