<!DOCTYPE html><html lang="en"><head><title>Help for package rcccd</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {rcccd}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#pcccd_classifier'><p>Pure and Proper Class Cover Catch Digraph Classifier</p></a></li>
<li><a href='#predict.pcccd_classifier'><p>Pure and Proper Class Cover Catch Digraph Prediction</p></a></li>
<li><a href='#predict.rwcccd_classifier'><p>Random Walk Class Cover Catch Digraph Prediction</p></a></li>
<li><a href='#rwcccd_classifier'><p>Random Walk Class Cover Catch Digraph Classifier</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Class Cover Catch Digraph Classification</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.2</td>
</tr>
<tr>
<td>Description:</td>
<td>Fit Class Cover Catch Digraph Classification models that can be 
    used in machine learning. Pure and proper and random walk approaches are 
    available. Methods are explained in Priebe et al. (2001) 
    &lt;<a href="https://doi.org/10.1016%2FS0167-7152%2801%2900129-8">doi:10.1016/S0167-7152(01)00129-8</a>&gt;, Priebe et al. (2003) 
    &lt;<a href="https://doi.org/10.1007%2Fs00357-003-0003-7">doi:10.1007/s00357-003-0003-7</a>&gt;, and Manukyan and Ceyhan (2016) 
    &lt;<a href="https://doi.org/10.48550%2FarXiv.1904.04564">doi:10.48550/arXiv.1904.04564</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.2)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, RANN, Rfast, proxy</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-04-22 15:24:40 UTC; Fatih</td>
</tr>
<tr>
<td>Author:</td>
<td>Fatih Saglam <a href="https://orcid.org/0000-0002-2084-2008"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Fatih Saglam &lt;saglamf89@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-04-24 09:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='pcccd_classifier'>Pure and Proper Class Cover Catch Digraph Classifier</h2><span id='topic+pcccd_classifier'></span>

<h3>Description</h3>

<p><code>pcccd_classifier</code> fits a Pure and Proper Class Cover Catch
Digraph (PCCCD) classification model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcccd_classifier(x, y, proportion = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pcccd_classifier_+3A_x">x</code></td>
<td>
<p>feature matrix or dataframe.</p>
</td></tr>
<tr><td><code id="pcccd_classifier_+3A_y">y</code></td>
<td>
<p>class factor variable.</p>
</td></tr>
<tr><td><code id="pcccd_classifier_+3A_proportion">proportion</code></td>
<td>
<p>proportion of covered samples. A real number between <code class="reqn">(0,1]</code>.
1 by default. Smaller numbers results in less dominant samples.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Multiclass framework for PCCCD. PCCCD determines target class dominant points
set <code class="reqn">S</code> and their circular cover area by determining balls
<code class="reqn">B(x^{\text{target}}, r_{i})</code> with radii r using minimum amount of
dominant point which satisfies <code class="reqn">X^{\text{non-target}}\cap \bigcup_{i}
B_{i} = \varnothing</code> (pure) and <code class="reqn">X^{\text{target}}\subset \bigcup_{i}
B_{i}</code> (proper).
</p>
<p>This guarantees that balls of target class never covers any non-target
samples (pure) and balls cover all target samples (proper).
</p>
<p>For detail, please refer to Priebe et al. (2001), Priebe et al. (2003),
and Manukyan and Ceyhan (2016).
</p>
<p>Note: Much faster than <code>cccd</code> package.
</p>


<h3>Value</h3>

<p>an object of &quot;cccd_classifier&quot; which includes:
</p>
<table role = "presentation">
<tr><td><code>i_dominant_list</code></td>
<td>
<p>dominant sample indexes.</p>
</td></tr>
<tr><td><code>x_dominant_list</code></td>
<td>
<p>dominant samples from feature matrix, x</p>
</td></tr>
<tr><td><code>radii_dominant_list</code></td>
<td>
<p>Radiuses of the circle for dominant samples</p>
</td></tr>
<tr><td><code>class_names</code></td>
<td>
<p>class names</p>
</td></tr>
<tr><td><code>k_class</code></td>
<td>
<p>number of classes</p>
</td></tr>
<tr><td><code>proportions</code></td>
<td>
<p>proportions each class covered</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Fatih Saglam, saglamf89@gmail.com
</p>


<h3>References</h3>

<p>Priebe, C. E., DeVinney, J., &amp; Marchette, D. J. (2001). On the distribution
of the domination number for random class cover catch digraphs. Statistics &amp;
Probability Letters, 55(3), 239–246. https://doi.org/10.1016/s0167-7152(01)00129-8
</p>
<p>Priebe, C. E., Marchette, D. J., DeVinney, J., &amp; Socolinsky, D. A. (2003).
Classification Using Class Cover Catch Digraphs. Journal of Classification,
20(1), 3–23. https://doi.org/10.1007/s00357-003-0003-7
</p>
<p>Manukyan, A., &amp; Ceyhan, E. (2016). Classification of imbalanced data with a
geometric digraph family. Journal of Machine Learning Research, 17(1),
6504–6543. https://jmlr.org/papers/volume17/15-604/15-604.pdf
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 1000
x1 &lt;- runif(n, 1, 10)
x2 &lt;- runif(n, 1, 10)
x &lt;- cbind(x1, x2)
y &lt;- as.factor(ifelse(3 &lt; x1 &amp; x1 &lt; 7 &amp; 3 &lt; x2 &amp; x2 &lt; 7, "A", "B"))

m_pcccd &lt;- pcccd_classifier(x = x, y = y)

# dataset
plot(x, col = y, asp = 1)

# dominant samples of first class
x_center &lt;- m_pcccd$x_dominant_list[[1]]

# radii of balls for first class
radii &lt;- m_pcccd$radii_dominant_list[[1]]

# balls
for (i in 1:nrow(x_center)) {
xx &lt;- x_center[i, 1]
yy &lt;- x_center[i, 2]
r &lt;- radii[i]
theta &lt;- seq(0, 2*pi, length.out = 100)
xx &lt;- xx + r*cos(theta)
yy &lt;- yy + r*sin(theta)
lines(xx, yy, type = "l", col = "green")
}

# testing the performance
i_train &lt;- sample(1:n, round(n*0.8))

x_train &lt;- x[i_train,]
y_train &lt;- y[i_train]

x_test &lt;- x[-i_train,]
y_test &lt;- y[-i_train]

m_pcccd &lt;- pcccd_classifier(x = x_train, y = y_train)
pred &lt;- predict(object = m_pcccd, newdata = x_test)

# confusion matrix
table(y_test, pred)

# test accuracy
sum(y_test == pred)/nrow(x_test)

</code></pre>

<hr>
<h2 id='predict.pcccd_classifier'>Pure and Proper Class Cover Catch Digraph Prediction</h2><span id='topic+predict.pcccd_classifier'></span>

<h3>Description</h3>

<p><code>predict.pcccd_classifier</code> makes prediction using <code>pcccd_classifier</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pcccd_classifier'
predict(object, newdata, type = "pred", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.pcccd_classifier_+3A_object">object</code></td>
<td>
<p>a <code>pcccd_classifier</code> object</p>
</td></tr>
<tr><td><code id="predict.pcccd_classifier_+3A_newdata">newdata</code></td>
<td>
<p>newdata as matrix or dataframe.</p>
</td></tr>
<tr><td><code id="predict.pcccd_classifier_+3A_type">type</code></td>
<td>
<p>&quot;pred&quot; or &quot;prob&quot;. Default is &quot;pred&quot;. &quot;pred&quot; is class estimations,
&quot;prob&quot; is <code class="reqn">n\times k</code> matrix of class probabilities.</p>
</td></tr>
<tr><td><code id="predict.pcccd_classifier_+3A_...">...</code></td>
<td>
<p>not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimations are based on nearest dominant neighbor in radius unit.
</p>
<p>For detail, please refer to Priebe et al. (2001), Priebe et al. (2003),
and Manukyan and Ceyhan (2016).
</p>


<h3>Value</h3>

<p>a vector of class predictions (if type is &quot;pred&quot;) or a <code class="reqn">n\times p</code>
matrix of class probabilities (if type is &quot;prob&quot;).
</p>


<h3>Author(s)</h3>

<p>Fatih Saglam, saglamf89@gmail.com
</p>


<h3>References</h3>

<p>Priebe, C. E., DeVinney, J., &amp; Marchette, D. J. (2001). On the distribution
of the domination number for random class cover catch digraphs. Statistics &amp;
Probability Letters, 55(3), 239–246. https://doi.org/10.1016/s0167-7152(01)00129-8
</p>
<p>Priebe, C. E., Marchette, D. J., DeVinney, J., &amp; Socolinsky, D. A. (2003).
Classification Using Class Cover Catch Digraphs. Journal of Classification,
20(1), 3–23. https://doi.org/10.1007/s00357-003-0003-7
</p>
<p>Manukyan, A., &amp; Ceyhan, E. (2016). Classification of imbalanced data with a
geometric digraph family. Journal of Machine Learning Research, 17(1),
6504–6543. https://jmlr.org/papers/volume17/15-604/15-604.pdf
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 1000
x1 &lt;- runif(n, 1, 10)
x2 &lt;- runif(n, 1, 10)
x &lt;- cbind(x1, x2)
y &lt;- as.factor(ifelse(3 &lt; x1 &amp; x1 &lt; 7 &amp; 3 &lt; x2 &amp; x2 &lt; 7, "A", "B"))

# testing the performance
i_train &lt;- sample(1:n, round(n*0.8))

x_train &lt;- x[i_train,]
y_train &lt;- y[i_train]

x_test &lt;- x[-i_train,]
y_test &lt;- y[-i_train]

m_pcccd &lt;- pcccd_classifier(x = x_train, y = y_train)
pred &lt;- predict(object = m_pcccd, newdata = x_test)

# confusion matrix
table(y_test, pred)

# test accuracy
sum(y_test == pred)/nrow(x_test)

</code></pre>

<hr>
<h2 id='predict.rwcccd_classifier'>Random Walk Class Cover Catch Digraph Prediction</h2><span id='topic+predict.rwcccd_classifier'></span>

<h3>Description</h3>

<p><code>predict.rwcccd_classifier</code> makes prediction using
<code>rwcccd_classifier</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rwcccd_classifier'
predict(object, newdata, type = "pred", e = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.rwcccd_classifier_+3A_object">object</code></td>
<td>
<p>a <code>rwcccd_classifier</code> object</p>
</td></tr>
<tr><td><code id="predict.rwcccd_classifier_+3A_newdata">newdata</code></td>
<td>
<p>newdata as matrix or dataframe.</p>
</td></tr>
<tr><td><code id="predict.rwcccd_classifier_+3A_type">type</code></td>
<td>
<p>&quot;pred&quot; or &quot;prob&quot;. Default is &quot;pred&quot;. &quot;pred&quot; is class estimations,
&quot;prob&quot; is <code class="reqn">n\times k</code> matrix of class probabilities.</p>
</td></tr>
<tr><td><code id="predict.rwcccd_classifier_+3A_e">e</code></td>
<td>
<p>0 or 1. Default is 0. Penalty based on <code class="reqn">T</code> scores in
<code>rwcccd_classifier</code> object.</p>
</td></tr>
<tr><td><code id="predict.rwcccd_classifier_+3A_...">...</code></td>
<td>
<p>not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimations are based on nearest dominant neighbor in radius unit.
<code>e</code> argument is used to penalize estimations based on <code class="reqn">T</code> scores in
<code>rwcccd_classifier</code> object.
</p>
<p>For detail, please refer to Priebe et al. (2001), Priebe et al. (2003),
and Manukyan and Ceyhan (2016).
</p>


<h3>Value</h3>

<p>a vector of class predictions (if type is &quot;pred&quot;) or a <code class="reqn">n\times p</code>
matrix of class probabilities (if type is &quot;prob&quot;).
</p>


<h3>Author(s)</h3>

<p>Fatih Saglam, saglamf89@gmail.com
</p>


<h3>References</h3>

<p>Priebe, C. E., DeVinney, J., &amp; Marchette, D. J. (2001). On the distribution
of the domination number for random class cover catch digraphs. Statistics &amp;
Probability Letters, 55(3), 239–246. https://doi.org/10.1016/s0167-7152(01)00129-8
</p>
<p>Priebe, C. E., Marchette, D. J., DeVinney, J., &amp; Socolinsky, D. A. (2003).
Classification Using Class Cover Catch Digraphs. Journal of Classification,
20(1), 3–23. https://doi.org/10.1007/s00357-003-0003-7
</p>
<p>Manukyan, A., &amp; Ceyhan, E. (2016). Classification of imbalanced data with a
geometric digraph family. Journal of Machine Learning Research, 17(1),
6504–6543. https://jmlr.org/papers/volume17/15-604/15-604.pdf
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 1000
x1 &lt;- runif(n, 1, 10)
x2 &lt;- runif(n, 1, 10)
x &lt;- cbind(x1, x2)
y &lt;- as.factor(ifelse(3 &lt; x1 &amp; x1 &lt; 7 &amp; 3 &lt; x2 &amp; x2 &lt; 7, "A", "B"))

# testing the performance
i_train &lt;- sample(1:n, round(n*0.8))

x_train &lt;- x[i_train,]
y_train &lt;- y[i_train]

x_test &lt;- x[-i_train,]
y_test &lt;- y[-i_train]

m_rwcccd &lt;- rwcccd_classifier(x = x_train, y = y_train)
pred &lt;- predict(object = m_rwcccd, newdata = x_test, e = 0)

# confusion matrix
table(y_test, pred)

# test accuracy
sum(y_test == pred)/nrow(x_test)

</code></pre>

<hr>
<h2 id='rwcccd_classifier'>Random Walk Class Cover Catch Digraph Classifier</h2><span id='topic+rwcccd_classifier'></span><span id='topic+rwcccd_classifier_2'></span>

<h3>Description</h3>

<p><code>rwcccd_classifier</code> and <code>rwcccd_classifier_2</code> fits a
Random Walk Class Cover Catch Digraph (RWCCCD) classification model.
<code>rwcccd_classifier</code> uses C++ for speed and <code>rwcccd_classifier_2</code>
uses R language to determine balls.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rwcccd_classifier(x, y, method = "default", m = 1, proportion = 0.99)

rwcccd_classifier_2(
  x,
  y,
  method = "default",
  m = 1,
  proportion = 0.99,
  partial_ordering = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rwcccd_classifier_+3A_x">x</code></td>
<td>
<p>feature matrix or dataframe.</p>
</td></tr>
<tr><td><code id="rwcccd_classifier_+3A_y">y</code></td>
<td>
<p>class factor variable.</p>
</td></tr>
<tr><td><code id="rwcccd_classifier_+3A_method">method</code></td>
<td>
<p>&quot;default&quot; or &quot;balanced&quot;.</p>
</td></tr>
<tr><td><code id="rwcccd_classifier_+3A_m">m</code></td>
<td>
<p>penalization parameter. Takes value in <code class="reqn">[0,\infty)</code>.</p>
</td></tr>
<tr><td><code id="rwcccd_classifier_+3A_proportion">proportion</code></td>
<td>
<p>proportion of covered samples. A real number between <code class="reqn">(0,1]</code>.</p>
</td></tr>
<tr><td><code id="rwcccd_classifier_+3A_partial_ordering">partial_ordering</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> Default is <code>FALSE</code> <code>TRUE</code> uses partial
ordering in determining dominant points. It orders incompletely but faster.
Only for <code>rwcccd_classifier_2</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Random Walk Class Cover Catch Digraphs (RWCCD) are determined by calculating
<code class="reqn">T_{\text{target}}</code> score for each class as target class as
</p>
<p style="text-align: center;"><code class="reqn">
T_{\text{target}}=R_{\text{target}}(r_{\text{target}})-\frac{r_{\text{target}}n_u}{2d_m(x)}.
</code>
</p>

<p>Here, <code class="reqn">r_{\text{target}}</code> is radius and determined by maximum
<code class="reqn">R_{\text{target}}(r) - P_{\text{target}}(r)</code> calculated for each target sample.
<code class="reqn">R_{\text{target}}(r)</code> is
</p>
<p style="text-align: center;"><code class="reqn">
  R_{\text{target}}(r):=
  w_{target}|{z\in X^{\text{target}}_{n_{\text{target}}}:d(x^{\text{target}},z)\leq r}| -
  w_{non-target}|{z\in X^{\text{non-target}}_{n_{\text{non-target}}}:d(x^{\text{target}},z)\leq r}|
</code>
</p>

<p>and <code class="reqn">P_{\text{target}}(r)</code> is
</p>
<p style="text-align: center;"><code class="reqn">
  P_{\text{target}}(r) = m\times d(x^{\text{target}},z)^p.
</code>
</p>

<p><code class="reqn">m=0</code> removes penalty. <code class="reqn">w_{target}=1</code> for default and
<code class="reqn">w_{target}=n_{\text{target}/n_{\text{non-target}}}</code> for balanced method.
<code class="reqn">n_u</code> is the number of uncovered samples in the current iteration and
<code class="reqn">d_m(x)</code> is <code class="reqn">\max{d(x^{\text{target}},x^{\text{uncovered}})}</code>.
</p>
<p>This method is more robust to noise compared to PCCCD However, balls covers
classes improperly and <code class="reqn">r = 0</code> can be selected.
</p>
<p>For detail, please refer to Priebe et al. (2001), Priebe et al. (2003),
and Manukyan and Ceyhan (2016).
</p>


<h3>Value</h3>

<p>a rwcccd_classifier object
</p>
<table role = "presentation">
<tr><td><code>i_dominant_list</code></td>
<td>
<p>dominant sample indexes.</p>
</td></tr>
<tr><td><code>x_dominant_list</code></td>
<td>
<p>dominant samples from feature matrix, x</p>
</td></tr>
<tr><td><code>radii_dominant_list</code></td>
<td>
<p>Radiuses of the circle for dominant samples</p>
</td></tr>
<tr><td><code>class_names</code></td>
<td>
<p>class names</p>
</td></tr>
<tr><td><code>k_class</code></td>
<td>
<p>number of classes</p>
</td></tr>
<tr><td><code>proportions</code></td>
<td>
<p>proportions each class covered</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Fatih Saglam, saglamf89@gmail.com
</p>


<h3>References</h3>

<p>Priebe, C. E., DeVinney, J., &amp; Marchette, D. J. (2001). On the distribution
of the domination number for random class cover catch digraphs. Statistics &amp;
Probability Letters, 55(3), 239–246. https://doi.org/10.1016/s0167-7152(01)00129-8
</p>
<p>Priebe, C. E., Marchette, D. J., DeVinney, J., &amp; Socolinsky, D. A. (2003).
Classification Using Class Cover Catch Digraphs. Journal of Classification,
20(1), 3–23. https://doi.org/10.1007/s00357-003-0003-7
</p>
<p>Manukyan, A., &amp; Ceyhan, E. (2016). Classification of imbalanced data with a
geometric digraph family. Journal of Machine Learning Research, 17(1),
6504–6543. https://jmlr.org/papers/volume17/15-604/15-604.pdf
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 500
x1 &lt;- runif(n, 1, 10)
x2 &lt;- runif(n, 1, 10)
x &lt;- cbind(x1, x2)
y &lt;- as.factor(ifelse(3 &lt; x1 &amp; x1 &lt; 7 &amp; 3 &lt; x2 &amp; x2 &lt; 7, "A", "B"))

# dataset
m_rwcccd_1 &lt;- rwcccd_classifier(x = x, y = y, method = "default", m = 1)

plot(x, col = y, asp = 1, main = "default")
# dominant samples of second class
x_center &lt;- m_rwcccd_1$x_dominant_list[[2]]
# radii of balls for second class
radii &lt;- m_rwcccd_1$radii_dominant_list[[2]]

# balls
for (i in 1:nrow(x_center)) {
  xx &lt;- x_center[i, 1]
  yy &lt;- x_center[i, 2]
  r &lt;- radii[i]
  theta &lt;- seq(0, 2*pi, length.out = 100)
  xx &lt;- xx + r*cos(theta)
  yy &lt;- yy + r*sin(theta)
  lines(xx, yy, type = "l", col = "green")
}

# dataset
m_rwcccd_2 &lt;- rwcccd_classifier_2(x = x, y = y, method = "default", m = 1, partial_ordering = TRUE)

plot(x, col = y, asp = 1, main = "default, prartial_ordering = TRUE")
# dominant samples of second class
x_center &lt;- m_rwcccd_2$x_dominant_list[[2]]
# radii of balls for second class
radii &lt;- m_rwcccd_2$radii_dominant_list[[2]]

# balls
for (i in 1:nrow(x_center)) {
  xx &lt;- x_center[i, 1]
  yy &lt;- x_center[i, 2]
  r &lt;- radii[i]
  theta &lt;- seq(0, 2*pi, length.out = 100)
  xx &lt;- xx + r*cos(theta)
  yy &lt;- yy + r*sin(theta)
  lines(xx, yy, type = "l", col = "green")
}

# dataset
m_rwcccd_3 &lt;- rwcccd_classifier(x = x, y = y, method = "balanced", m = 1, proportion = 0.5)

plot(x, col = y, asp = 1, main = "balanced, proportion = 0.5")
# dominant samples of second class
x_center &lt;- m_rwcccd_3$x_dominant_list[[2]]
# radii of balls for second class
radii &lt;- m_rwcccd_3$radii_dominant_list[[2]]

# balls
for (i in 1:nrow(x_center)) {
  xx &lt;- x_center[i, 1]
  yy &lt;- x_center[i, 2]
  r &lt;- radii[i]
  theta &lt;- seq(0, 2*pi, length.out = 100)
  xx &lt;- xx + r*cos(theta)
  yy &lt;- yy + r*sin(theta)
  lines(xx, yy, type = "l", col = "green")
}

# testing the performance
i_train &lt;- sample(1:n, round(n*0.8))

x_train &lt;- x[i_train,]
y_train &lt;- y[i_train]

x_test &lt;- x[-i_train,]
y_test &lt;- y[-i_train]

m_rwcccd &lt;- rwcccd_classifier(x = x_train, y = y_train, method = "balanced")
pred &lt;- predict(object = m_rwcccd, newdata = x_test)

# confusion matrix
table(y_test, pred)

# accuracy
sum(y_test == pred)/nrow(x_test)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
