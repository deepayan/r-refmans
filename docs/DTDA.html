<!DOCTYPE html><html><head><title>Help for package DTDA</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {DTDA}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ACS'>
<p>Acute Coronary Syndrome data</p></a></li>
<li><a href='#ACSred'>
<p>Acute Coronary Syndrome reduced data</p></a></li>
<li><a href='#AIDS'><p> AIDS Blood Transfusion Data, right truncated</p></a></li>
<li><a href='#AIDS.DT'>
<p>AIDS Blood Transfusion Data, doubly truncated</p></a></li>
<li><a href='#ChildCancer'>
<p>Childhood Cancer Data</p></a></li>
<li><a href='#densityDT'>
<p>Estimation of a kernel density function under random double truncation</p></a></li>
<li><a href='#efron.petrosian'><p> NPMLE computation with the first Efron-Petrosian algorithm</p></a></li>
<li><a href='#EqSRounded'>
<p>Equipment-S Rounded Failure Time Data</p></a></li>
<li><a href='#hazardDT'>
<p>Estimation of the kernel hazard function under random double truncation</p></a></li>
<li><a href='#lynden'><p> NPMLE computation with the second Efron-Petrosian algorithm</p></a></li>
<li><a href='#PDearly'>
<p>Parkinson's Disease Data: early onset</p></a></li>
<li><a href='#PDlate'>
<p>Parkinson's Disease Data: late onset</p></a></li>
<li><a href='#Quasars'><p> Quasars Data</p></a></li>
<li><a href='#rsim.DT'>
<p>Random generation functions of doubly truncated data</p></a></li>
<li><a href='#shen'><p> NPMLE computation with Shen algorithm</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Doubly Truncated Data Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>3.0.1</td>
</tr>
<tr>
<td>Author:</td>
<td>Carla Moreira, Jacobo de Uña-Álvarez and Rosa Crujeiras</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Carla Moreira &lt;carlamgmm@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementation of different algorithms for analyzing
        randomly truncated data, one-sided and two-sided (i.e. doubly)
        truncated data. It serves to compute empirical cumulative 
        distributions and also kernel density and hazard functions 
        using different bandwidth selectors.
      Several real data sets are included.</td>
</tr>
<tr>
<td>Imports:</td>
<td>doParallel, foreach</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-01-12 16:28:54 UTC; Carla Moreira</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-01-12 17:12:43 UTC</td>
</tr>
</table>
<hr>
<h2 id='ACS'>
Acute Coronary Syndrome data
</h2><span id='topic+ACS'></span>

<h3>Description</h3>

<p>The data include information of 939 patients with confirmed diagnosis of type 1 (primary spontaneous) acute coronary syndrome (ACS). Patientes  were consecutively admitted to the Cardiology Department of two tertiary hospitals in Portugal between August 2013 and December 2014. The age at diagnosis is doubly truncated because of the interval sampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ACS)</code></pre>


<h3>Format</h3>

<p>A data frame with 939 observations on the following 5 variables.
</p>

<dl>
<dt><code>X</code></dt><dd><p>a numeric vector, age at diagnosis (in years).</p>
</dd>
<dt><code>U</code></dt><dd><p>a numeric vector, the elapsed time
(in years) between birth and the beggining of the study (August
2013).</p>
</dd>
<dt><code>V</code></dt><dd><p>a numeric vector, the elapsed time
(in years) between birth and end of the study (December
2014).</p>
</dd>
<dt><code>Sex</code></dt><dd><p>a numeric vector, sex of the participants (0 = female, 1 = male).</p>
</dd>
<dt><code>diagnosis</code></dt><dd><p>a numeric vector, type of diagnosis at discharge	1 - STEMI (ST elevation myocardial infarction) and 2 - NSTEACS (all others diagnoses).</p>
</dd>
</dl>



<h3>Details</h3>

<p>The age at diagnosis <code>X</code> is doubly truncated due to the interval sampling. The length of the sampling interval (<code>V</code>-<code>U</code>) is 1.42 years. The NPMLE of the cumulative distribution function of <code>X</code>  does not exist or is not unique for this dataset. The  necessary and sufficient graphical condition presented by <cite>Xiao and Hudgens (2020)</cite> to determine the existence and uniqueness of the NPMLE is not satisfied.
</p>


<h3>References</h3>

<p>Araújo C, Laszczyska O, Viana M, Melão F, Henriques A,  Borges A,  Severo M, Maciel MJ, Moreira I, Azevedo A (2018) Sex differences in presenting symptoms of acute coronary syndrome: the EPIHeart cohort study. <em>BMJ Open </em> <b>8</b>.
</p>
<p>Xiao J and  Hudgens MG (2020) On nonparametric maximum likelihood estimation with double truncation. <em>Biometrika</em> <b>106</b>, 989-996.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ACSred">ACSred</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ACS)
str(ACS)
</code></pre>

<hr>
<h2 id='ACSred'>
Acute Coronary Syndrome reduced data
</h2><span id='topic+ACSred'></span>

<h3>Description</h3>

<p>The data include information of 917 patients with confirmed diagnosis of type 1 (primary spontaneous) acute coronary syndrome (ACS). Patients were consecutively admitted to the Cardiology Department of two tertiary hospitals in Portugal between August 2013 and December 2014. The age at diagnosis is doubly truncated because of the interval sampling. This dataset is a reduced sample of the original ACS data, guaranteeing the existence and uniqueness of the NPMLE, according to <cite>Xiao and Hudgens (2020)
</cite></p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ACSred)</code></pre>


<h3>Format</h3>

<p>A data frame with 917 observations on the following 5 variables.
</p>

<dl>
<dt><code>X</code></dt><dd><p>a numeric vector, age at diagnosis (in years).</p>
</dd>
<dt><code>U</code></dt><dd><p>a numeric vector, the elapsed time
(in years) between birth and the beggining of the study (August
2013).</p>
</dd>
<dt><code>V</code></dt><dd><p>a numeric vector, the elapsed time
(in years) between birth and end of the study (December
2014).</p>
</dd>
<dt><code>Sex</code></dt><dd><p>a numeric vector, sex of the participants (0 = female, 1 = male).</p>
</dd>
<dt><code>diagnosis</code></dt><dd><p>a numeric vector, type of diagnosis at discharge	1 - STEMI (ST elevation myocardial infarction ) and 2 - NSTEACS (all others diagnoses).</p>
</dd>
</dl>



<h3>Details</h3>

<p>The age at diagnosis <code>X</code> is doubly truncated   due to the interval sampling. The length of the sampling interval (<code>V</code>-<code>U</code>) is 1.42 years. The NPMLE of the cumulative distribution function of <code>X</code> for the complete data does not exist or is not unique for this dataset.

</p>


<h3>References</h3>

<p>Araújo C, Laszczynska O, Viana M, Melão F, Henriques A,  Borges A,  Severo M, Maciel MJ, Moreira I, Azevedo A (2018) Sex differences in presenting symptoms of acute coronary syndrome: the EPIHeart cohort study. <em>BMJ Open </em> <b>8</b>.
</p>
<p>Moreira C, de Uña-Álvarez J, Santos AC and Barros H (2021) Smoothing Methods to estimate the hazard rate under double truncation. <a href="https://arxiv.org/abs/2103.14153">https://arxiv.org/abs/2103.14153</a>.
</p>
<p>Xiao J and  Hudgens MG (2020) On nonparametric maximum likelihood estimation with double truncation. <em>Biometrika</em> <b>106</b>, 989-996.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ACS">ACS</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ACSred)
str(ACSred)
</code></pre>

<hr>
<h2 id='AIDS'> AIDS Blood Transfusion Data, right truncated
</h2><span id='topic+AIDS'></span>

<h3>Description</h3>

<p>The data
include information on the infection and induction times for 258 adults who
were infected with HIV virus and developed AIDS by June 30, 1996. The data consist on the time in years, measured from April 1, 1978, when adults were infected by the virus from a contaminated blood transfusion, and the waiting time to development of AIDS, measured
from the date of infection. The induction times are right-truncated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(AIDS)</code></pre>


<h3>Format</h3>

<p>A data frame with 258 observations on the following 3 variables.
</p>

<dl>
<dt><code>INFTime</code></dt><dd><p>a numeric vector, the infection time (years).</p>
</dd>
<dt><code>INDTime</code></dt><dd><p>a numeric vector, the induction time (years).</p>
</dd>
<dt><code>V</code></dt><dd><p>a numeric vector, the time from HIV infection to the end of the study (years).</p>
</dd>
</dl>



<h3>Source</h3>


<p>Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data.
Springer.
</p>


<h3>References</h3>

<p>Lagakos SW and Barraj LM and de Gruttola V (1988) Nonparametric Analysis of Truncated Survival
Data, with Applications to AIDS. <em>Biometrika</em> <b>75</b>, 515&ndash;523.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(AIDS)
str(AIDS)
</code></pre>

<hr>
<h2 id='AIDS.DT'>
AIDS Blood Transfusion Data, doubly truncated
</h2><span id='topic+AIDS.DT'></span>

<h3>Description</h3>

<p>The data include information of transfusions cases of transfusion-related AIDS, corresponding to individuals diagnosed prior to July 1, 1986.  Only 295 patients with consistent data, for which the infection could be attributed to
a single transfusion or short series were included. Since HIV was unknown before 1982, this implies that cases developing AIDS prior to this date were not reported, leading to a doubly truncated data. The incubation time is doubly truncated due to the interval sampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(AIDS.DT)</code></pre>


<h3>Format</h3>

<p>A data frame with 295 observations on the following 4 variables.
</p>

<dl>
<dt><code>X</code></dt><dd><p>a numeric vector, the induction or incubation time: time elapsed from HIV infection to AIDS (in months).</p>
</dd>
<dt><code>U</code></dt><dd><p>a numeric vector, time from 1982 to HIV infection (in months). </p>
</dd>
<dt><code>V</code></dt><dd><p>a numeric vector,time from HIV infection to July 1, 1986 (in months).</p>
</dd>
<dt><code>AGE</code></dt><dd><p>a numeric vector, age of the individual at infection (in years).</p>
</dd>
</dl>



<h3>References</h3>

<p>Kalbfleisch JD and Lawless JF (1989) Inference based on retrospective ascertainment: An analysis of the data on transfusion-related AIDS. <em>Journal of the American Statistical Association</em> <b>84</b>, 360&ndash;372.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(AIDS.DT)
str(AIDS.DT)
</code></pre>

<hr>
<h2 id='ChildCancer'>
Childhood Cancer Data
</h2><span id='topic+ChildCancer'></span>

<h3>Description</h3>

<p>This dataset corresponds to all children diagnosed from cancer between January
1, 1999  and December 31, 2003  in the region of North Portugal. The database includes information of 406 children with complete records on the age at diagnosis. Because of the interval sampling, the age at diagnosis is doubly truncated by the time  from birth to the end of the study, and time from birth to the beggining of the study.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("ChildCancer")</code></pre>


<h3>Format</h3>

<p>A data frame with 406 observations on the following 8 variables.
</p>

<dl>
<dt><code>X</code></dt><dd><p>a numeric vector, age at diagnosis (time in days).</p>
</dd>
<dt><code>U</code></dt><dd><p>a numeric vector, time from birth to the beggining of the study (time in days).</p>
</dd>
<dt><code>V</code></dt><dd><p>a numeric vector, time from birth to the end of the study (time in days).</p>
</dd>
<dt><code>ICCGroup</code></dt><dd><p>a numeric vector,  cancer types
identified according to the International Classification of Childhood Cancer
(ICCC). 1=Leukaemias, 2=Limphoma, 3=Nervous System Tumour, 4=Neuroblastoma, 5=Retinoblastoma, 6=Renal, 7=Hepatic, 8=Bone, 9=Soft Tissues, 10=Germ Cell, 11=Melanoma and other epitelial tumours, 12=Other Tumours.</p>
</dd>
<dt><code>Status</code></dt><dd><p>a numeric vector,  the status indicator at the end of the study:  0=alive, 1=dead.</p>
</dd>
<dt><code>SurvTime</code></dt><dd><p>a numeric vector,  the survival time (time from birth to death or end of the study.</p>
</dd>
<dt><code>Residence</code></dt><dd><p>a numeric vector,  districts of residence. 1=Braga, 2=Bragança,3=Porto,4=Viana do Castelo, 5=Vila Real.</p>
</dd>
<dt><code>Sex</code></dt><dd><p>a numeric vector, sex of the participants (1 = female, 2 = male).</p>
</dd>
</dl>



<h3>Source</h3>

<p>The childhood cancer data were gathered from the IPO (Registo Oncológico do Norte) service, kindly provided by Doctor Maria José Bento.
</p>


<h3>References</h3>

<p>Mandel M, de Uña-Álvarez J,  Simon DK and Betensky R (2018). Inverse Probability Weighted Cox Regression for Doubly Truncated Data. <em>Biometrics</em> <b>74</b>, 481-487.
</p>
<p>Moreira C and  de Uña-Álvarez J (2010) Bootstrapping the NPMLE for doubly truncated data. <em>Journal of Nonparametric Statistics</em> <b>22</b>, 567-583.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ChildCancer)
str(ChildCancer)
</code></pre>

<hr>
<h2 id='densityDT'>
Estimation of a kernel density function under random double truncation
</h2><span id='topic+densityDT'></span>

<h3>Description</h3>

<p>This function provides the nonparametric kernel density estimation of a doubly truncated random variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>densityDT(X, U, V, bw = "DPI2", from, to, n, wg = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="densityDT_+3A_x">X</code></td>
<td>

<p>numeric vector with the values of the target variable.
</p>
</td></tr>
<tr><td><code id="densityDT_+3A_u">U</code></td>
<td>

<p>numeric vector with the values of the left truncation variable.
</p>
</td></tr>
<tr><td><code id="densityDT_+3A_v">V</code></td>
<td>

<p>numeric vector with the values of the rigth truncation variable.
</p>
</td></tr>
<tr><td><code id="densityDT_+3A_bw">bw</code></td>
<td>

<p>The smoothing bandwidth to be used, but can also be a character string giving a rule to choose the bandwidth. This must be one of <code>"NR"</code>, <code>"DPI1"</code>, <code>"DPI2"</code>, <code>"LSCV"</code> or <code>"SBoot"</code> with default <code>"DPI2"</code>.
</p>
</td></tr>
<tr><td><code id="densityDT_+3A_from">from</code></td>
<td>

<p>the left  point of the grid at which the density is to be estimated. The default is min(X)+1e-04.
</p>
</td></tr>
<tr><td><code id="densityDT_+3A_to">to</code></td>
<td>

<p>the rigth  point of the grid at which the density is to be estimated. The default is max(X)-1e-04.
</p>
</td></tr>
<tr><td><code id="densityDT_+3A_n">n</code></td>
<td>

<p>number of evaluation points on a equally spaced grid.
</p>
</td></tr>
<tr><td><code id="densityDT_+3A_wg">wg</code></td>
<td>

<p>Numeric vector of random weights to correct for double truncation. Default weights correspond to the Efron-Petrosian NPMLE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The nonparametric kernel density estimation for a variable which is observed under random double truncation is computed  as proposed in <cite>Moreira and de Uña-Álvarez (2012)</cite>. As usual in kernel smoothing, the estimator is  obtained as a convolution between a kernel function and an appropriate  estimator of the cumulative df. Gaussian kernel is used.
The automatic bandwidth selection procedures for the kernel density
estimator are those proposed in <cite>Moreira and Van Keilegom (2013)</cite>. The automatic bandwidth selection alternatives are appropriate modifications, i.e, taking into account the double truncation issue,  of the
normal reference rule, two types of plug-in procedures, the least squares cross-validation and a bootstrap based method proposed in <cite>Cao et al. (1994)</cite> and <cite>Sheater and Jones (1991)</cite> for the complete data.
</p>


<h3>Value</h3>

<p>A list containing the following values:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>the n coordinates of the points where the density is estimated. </p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>the estimated density values.</p>
</td></tr>
<tr><td><code>bw</code></td>
<td>
<p>the bandwidth used.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Carla Moreira, de Uña-Álvarez and Rosa Crujeiras </p>


<h3>References</h3>

<p>Cao R, Cuevas A and González-Manteiga W (1994). A comparative study of several smoothing methods in density estimation. <em>Computational Statistics and Data
Analysis</em> <b>17</b>, 153-176.
</p>
<p>Moreira C and de Uña-Álvarez J (2012) Kernel density estimation with doubly
truncated data. <em>Electronic Journal of Statistics</em> <b>6</b>, 501-521.
</p>
<p>Moreira C and Van Keilegom I (2013) Bandwidth selection for kernel density estimation with
doubly truncated data. <em>Computational Statistics and Data Analysis</em> <b>61</b>, 107-123.
</p>
<p>Sheather S and Jones M (1991) A reliable data-based bandwidth selection method for kernel density estimation. <em>Journal of the Royal Statistical Society: Series
B</em> <b>53</b>, 683-690.
</p>
<p>Silverman BW (1986) Density Estimation. London: Chapman and Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hazardDT">hazardDT</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(4321)

n&lt;-50
X &lt;- runif(n, 0, 1)
U &lt;- runif(n,-1/3, 1)
V &lt;- U + 1/3
for (i in 1:n){

	while (U[i] &gt; X[i] | V[i] &lt; X[i]){
	X[i] &lt;- runif(1, 0, 1)
  U[i] &lt;- runif(1, -1/3, 1)
	V[i] &lt;- U[i] + 1/3
	}

}


vxDens1&lt;-densityDT(X,U,V,bw="DPI1",0,1,500)
plot(vxDens1, type = "l")
vxDens2&lt;-densityDT(X,U,V,bw="DPI2",0,1,500)
vxDens3&lt;-densityDT(X,U,V, bw=0.5,0,1,500)
vxDens4&lt;-densityDT(X,U,V,bw="LSCV",0,1,500)


data(Quasars)
densityDT(Quasars[,1],Quasars[,2],Quasars[,3],bw="DPI1",-2.5,2.2,500)
densityDT(Quasars[,1],Quasars[,2],Quasars[,3], bw=0.5,500)

</code></pre>

<hr>
<h2 id='efron.petrosian'> NPMLE computation with the first Efron-Petrosian algorithm </h2><span id='topic+efron.petrosian'></span>

<h3>Description</h3>

<p>This function computes the NPMLE for the cumulative distribution function of  <code>X</code> observed under one-sided (right or left) and two-sided (double) truncation.
It provides simple bootstrap pointwise confidence limits too.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>efron.petrosian(X, U = NA, V = NA, wt = NA, error = NA,
		 nmaxit = NA, boot = TRUE, B = NA, alpha = NA,
			 display.F = FALSE, display.S = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="efron.petrosian_+3A_x">X</code></td>
<td>
<p> Numeric vector with the values of the target variable.</p>
</td></tr>
<tr><td><code id="efron.petrosian_+3A_u">U</code></td>
<td>
<p>Numeric vector with the values of the left truncation variable. If there are no truncation values from the left, put <code>U</code>=<code>NA</code>.</p>
</td></tr>
<tr><td><code id="efron.petrosian_+3A_v">V</code></td>
<td>
<p> Numeric vector with the values of the right truncation variable. If there are no truncation values from the right, put <code>V</code>=<code>NA</code>.</p>
</td></tr>
<tr><td><code id="efron.petrosian_+3A_wt">wt</code></td>
<td>
<p> Numeric vector of non-negative initial solution, with the same length as <code>X</code>. Default value is set to 1/n, being n the length of <code>X</code>. </p>
</td></tr>
<tr><td><code id="efron.petrosian_+3A_error">error</code></td>
<td>
<p> Numeric value. Maximum pointwise error when estimating the density associated to X (f) in two consecutive steps. If this is missing, it is $1e-06$.</p>
</td></tr>
<tr><td><code id="efron.petrosian_+3A_nmaxit">nmaxit</code></td>
<td>
<p> Numeric value. Maximum number of iterations. If this is missing, it is set to <code>nmaxit</code> =100 . </p>
</td></tr>
<tr><td><code id="efron.petrosian_+3A_boot">boot</code></td>
<td>
<p> Logical. If TRUE (default), the simple bootstrap method is applied to lifetime distribution estimation.
Pointwise confidence bands are provided. </p>
</td></tr>
<tr><td><code id="efron.petrosian_+3A_b">B</code></td>
<td>
<p> Numeric value. Number of bootstrap resamples . The default <code>NA</code> is equivalent to <code>B</code> =500 . </p>
</td></tr>
<tr><td><code id="efron.petrosian_+3A_alpha">alpha</code></td>
<td>
<p> Numeric value. (1-<code>alpha</code>) is the nominal coverage for the pointwise confidence intervals. </p>
</td></tr>
<tr><td><code id="efron.petrosian_+3A_display.f">display.F</code></td>
<td>
<p> Logical. Default is FALSE. If TRUE, the estimated cumulative distribution function associated to <code>X</code>, (F) is plotted. </p>
</td></tr>
<tr><td><code id="efron.petrosian_+3A_display.s">display.S</code></td>
<td>
<p> Logical. Default is FALSE. If TRUE, the estimated survival function associated to <code>X</code>, (S) is plotted. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The NPMLE for the cumulative distribution function is computed by the first algorithm proposed in <cite>Efron and Petrosian (1999)</cite>. This is an iterative algorithm which converges to the
NMPLE after a number of iterations.
If the second (respectively third) argument is missing, computation of the Lynden-Bell estimator for right-truncated (respectively left-truncated)
data is obtained.
Note that individuals with NAs in the three first arguments will be automatically excluded.
</p>


<h3>Value</h3>

<p>A list containing the following values:
</p>
<table>
<tr><td><code>time</code></td>
<td>
<p>The timepoint on the curve. </p>
</td></tr>
<tr><td><code>n.event</code></td>
<td>
<p>The number of events that ocurred at time <code>t</code>. </p>
</td></tr>
<tr><td><code>events</code></td>
<td>
<p>The total number of events. </p>
</td></tr>
<tr><td><code>density</code></td>
<td>
<p>The estimated density values. </p>
</td></tr>
<tr><td><code>cumulative.df</code></td>
<td>
<p>The estimated cumulative distribution values. </p>
</td></tr>
<tr><td><code>truncation.probs</code></td>
<td>
<p>The probability of <code>X</code> falling into each truncation interval.</p>
</td></tr>
<tr><td><code>S0</code></td>
<td>
 <p><code>error</code> reached in the algorithm. </p>
</td></tr>
<tr><td><code>Survival</code></td>
<td>
<p>The estimated survival values. </p>
</td></tr>
<tr><td><code>n.iterations</code></td>
<td>
<p>The number of iterations used by this algorithm. </p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>Number of bootstrap resamples computed. </p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The nominal level used to construct the confidence intervals. </p>
</td></tr>
<tr><td><code>upper.df</code></td>
<td>
<p>The estimated upper limits of the confidence intervals for F. </p>
</td></tr>
<tr><td><code>lower.df</code></td>
<td>
<p>The estimated lower limits of the confidence intervals for F. </p>
</td></tr>
<tr><td><code>upper.Sob</code></td>
<td>
<p>The estimated upper limits of the confidence intervals for S. </p>
</td></tr>
<tr><td><code>lower.Sob</code></td>
<td>
<p>The estimated lower limits of the confidence intervals for S. </p>
</td></tr>
<tr><td><code>sd.boot</code></td>
<td>
<p>The bootstrap standard deviation of F estimator. </p>
</td></tr>
<tr><td><code>boot.repeat</code></td>
<td>
<p>The number of resamples done in each bootstrap call to ensure the existence and uniqueness of the bootstrap NPMLE. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Carla Moreira, Jacobo de Uña-Álvarez and Rosa Crujeiras </p>


<h3>References</h3>

<p> Efron B and Petrosian V (1999) Nonparametric methods for doubly truncated data. <em>Journal of the American Statistical Association</em> <b>94</b>, 824-834.
</p>
<p>Lynden-Bell D (1971) A method of allowing for known observational selection in small samples applied to 3CR quasars. <em>Monograph National Royal Astronomical Society</em> <b>155</b>, 95-118.
</p>
<p>Xiao J and  Hudgens MG (2020) On nonparametric maximum likelihood estimation with double truncation. <em>Biometrika</em> <b>106</b>, 989-996.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lynden">lynden</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Generating data which are doubly truncated

set.seed(4321)

n&lt;-25
X&lt;-runif(n,0,1)
U&lt;-runif(n,0,0.5)
V&lt;-runif(n,0.5,1)

for (i in 1:n){
	while (X[i]&lt;U[i]|X[i]&gt;V[i]){
	U[i]&lt;-runif(1,0,0.5)
	X[i]&lt;-runif(1,0,1)
	V[i]&lt;-runif(1,0.5,1)
					   }
		 }
efron.petrosian(X=X,U=U,V=V,boot=FALSE,display.F=TRUE,display.S=TRUE)


</code></pre>

<hr>
<h2 id='EqSRounded'>
Equipment-S Rounded Failure Time Data
</h2><span id='topic+EqSRounded'></span>

<h3>Description</h3>

<p>Digitized data from Figure 2 in <cite>Ye and Tang 2016</cite>. The dataset contains (rounded) observations of 174 failure times of certain devices, observed under interval sampling. Right-runcation is years between installation and 2011 and left truncation corresponds to right-truncation time minus 15 years. The failure time is doubly truncated due to the interval sampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("EqSRounded")</code></pre>


<h3>Format</h3>

<p>A data frame with 174 observations on the following 3 variables.
</p>

<dl>
<dt><code>X</code></dt><dd><p>a numeric vector, time to failure in years.</p>
</dd>
<dt><code>U</code></dt><dd><p>a numeric vector, the number of years between installation and 2011 minus 15 years.</p>
</dd>
<dt><code>V</code></dt><dd><p>a numeric vector, the number of years between installation and 2011.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Digitalization of the data plot in the original paper of <cite>Ye and Tang 2016</cite>.
</p>


<h3>References</h3>

<p>Ye ZS and Tang LC (2016) Augmenting the unreturned for field data with information on returned failures only. <em>Technometrics</em> <b>58</b>, 513-523.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(EqSRounded)
str(EqSRounded)
</code></pre>

<hr>
<h2 id='hazardDT'>
Estimation of the kernel hazard function under random double truncation
</h2><span id='topic+hazardDT'></span>

<h3>Description</h3>

<p>This function provides the nonparametric kernel hazard estimation for a variable which is observed under random double truncation, which is defined as a convolution of a kernel function with the NPMLE of the cumulative hazard. Least square cross validation bandwidth selection procedure is implemented too.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hazardDT(X, U, V, bw = "LSCV", from, to, n, wg = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hazardDT_+3A_x">X</code></td>
<td>

<p>Numeric vector with the values of the target variable.
</p>
</td></tr>
<tr><td><code id="hazardDT_+3A_u">U</code></td>
<td>

<p>Numeric vector with the values of the left truncation variable.
</p>
</td></tr>
<tr><td><code id="hazardDT_+3A_v">V</code></td>
<td>

<p>Numeric vector with the values of the rigth truncation variable.
</p>
</td></tr>
<tr><td><code id="hazardDT_+3A_bw">bw</code></td>
<td>

<p>The smoothing bandwidth to be used, but can also be a character string giving a rule to choose the bandwidth. This must be  <code>"LSCV"</code>.
</p>
</td></tr>
<tr><td><code id="hazardDT_+3A_from">from</code></td>
<td>

<p>the left  point of the grid at which the density is to be estimated. The default is min(X)+1e-04.
</p>
</td></tr>
<tr><td><code id="hazardDT_+3A_to">to</code></td>
<td>

<p>the rigth  point of the grid at which the density is to be estimated. The default is max(X)-1e-04.
</p>
</td></tr>
<tr><td><code id="hazardDT_+3A_n">n</code></td>
<td>

<p>number of evaluation points on a equally spaced grid.
</p>
</td></tr>
<tr><td><code id="hazardDT_+3A_wg">wg</code></td>
<td>

<p>Numeric vector of random weights to correct for double truncation. Default weights correspond to the Efron-Petrosian NPMLE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The nonparametric kernel density estimation for a variable which is observed under random double truncation is computed  as proposed in <cite>Moreira et al.(2021)</cite>. As usual in kernel smoothing, the estimator is  obtained as a convolution between a kernel function and an appropriate  estimator of the cumulative hazard. Gaussian kernel is used.
The automatic bandwidth selection procedures for the kernel hazard estimator is the least square cross validation, presented in <cite>Moreira et al. (2021)</cite>.
</p>


<h3>Value</h3>

<p>A list containing the following values:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>the n coordinates of the points where the hazard is estimated. </p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>the estimated hazard values.</p>
</td></tr>
<tr><td><code>bw</code></td>
<td>
<p>the bandwidth used.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Carla Moreira, Jacobo de Uña-Álvarez and Rosa Crujeiras </p>


<h3>References</h3>

<p>Moreira C, de Uña-Álvarez J, Santos AC and Barros H (2021) Smoothing Methods to estimate the hazard rate under double truncation. <a href="https://arxiv.org/abs/2103.14153">https://arxiv.org/abs/2103.14153</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+densityDT">densityDT</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(4321)

n&lt;-100
X &lt;- runif(n, 0, 1)
U &lt;- runif(n,-1/3, 1)
V &lt;- U + 1/3
for (i in 1:n){

	while (U[i] &gt; X[i] | V[i] &lt; X[i]){
	X[i] &lt;- runif(1, 0, 1)
  U[i] &lt;- runif(1, -1/3, 1)
	V[i] &lt;- U[i] + 1/3
	}

}


vxhazard1&lt;-hazardDT(X,U,V,bw=0.3,0,1,500)
vxhazard2&lt;-hazardDT(X,U,V,bw="LSCV",0,1,500)
</code></pre>

<hr>
<h2 id='lynden'> NPMLE computation with the second Efron-Petrosian algorithm </h2><span id='topic+lynden'></span>

<h3>Description</h3>

<p>This function computes the NPMLE for the cumulative distribution function of  <code>X</code> observed under one-sided (right or left) and two-sided (double) truncation.
It provides simple bootstrap pointwise confidence limits too. This function allows for ties in the samples of <code>X</code>, <code>U</code> and <code>V</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lynden(X, U = NA, V = NA, error = NA, nmaxit = NA,
		 boot = TRUE, B = NA, alpha = NA,
			display.F = FALSE, display.S = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lynden_+3A_x">X</code></td>
<td>
<p> Numeric vector with the values of the target variable.</p>
</td></tr>
<tr><td><code id="lynden_+3A_u">U</code></td>
<td>
<p>Numeric vector with the values of the left truncation variable. If there are no truncation values from the left, put <code>U</code>=<code>NA</code>.</p>
</td></tr>
<tr><td><code id="lynden_+3A_v">V</code></td>
<td>
<p> Numeric vector with the values of the right truncation variable. If there are no truncation values from the right, put <code>V</code>=<code>NA</code>.</p>
</td></tr>
<tr><td><code id="lynden_+3A_error">error</code></td>
<td>
<p> Numeric value. Maximum pointwise error when estimating the density associated to X (f) in two consecutive steps. If this is missing, it is $1e-06$.</p>
</td></tr>
<tr><td><code id="lynden_+3A_nmaxit">nmaxit</code></td>
<td>
<p> Numeric value. Maximum number of iterations. If this is missing, it is set to <code>nmaxit</code> =100 . </p>
</td></tr>
<tr><td><code id="lynden_+3A_boot">boot</code></td>
<td>
<p> Logical. If TRUE (default), the simple bootstrap method is applied to lifetime distribution estimation.
Pointwise confidence bands are provided. </p>
</td></tr>
<tr><td><code id="lynden_+3A_b">B</code></td>
<td>
<p> Numeric value. Number of bootstrap resamples . The default <code>NA</code> is equivalent to <code>B</code> =500 . </p>
</td></tr>
<tr><td><code id="lynden_+3A_alpha">alpha</code></td>
<td>
<p> Numeric value. (1-<code>alpha</code>) is the nominal coverage for the pointwise confidence intervals. </p>
</td></tr>
<tr><td><code id="lynden_+3A_display.f">display.F</code></td>
<td>
<p> Logical. Default is FALSE. If TRUE, the estimated cumulative distribution function associated to <code>X</code>, (F) is plotted. </p>
</td></tr>
<tr><td><code id="lynden_+3A_display.s">display.S</code></td>
<td>
<p> Logical. Default is FALSE. If TRUE, the estimated survival function associated to <code>X</code>, (S) is plotted. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The NPMLE for the cumulative distribution function is computed by the second algorithm proposed in <cite>Efron and Petrosian (1999)</cite>. This is an iterative algorithm which converges to the
NMPLE after a number of iterations.
If the second (respectively third) argument is missing, the Lynden-Bell estimator for right-truncated (respectively left-truncated)
data is obtained.
Note that individuals with NAs in the three first arguments will be automatically excluded.
</p>


<h3>Value</h3>

<p>A list containing the following values:
</p>
<table>
<tr><td><code>time</code></td>
<td>
<p>The timepoint on the curve. </p>
</td></tr>
<tr><td><code>n.event</code></td>
<td>
<p>The number of events that ocurred at time <code>t</code>. </p>
</td></tr>
<tr><td><code>events</code></td>
<td>
<p>The total number of events. </p>
</td></tr>
<tr><td><code>NJ</code></td>
<td>
<p>The number of individuals in risk considering the left truncation times. </p>
</td></tr>
<tr><td><code>density</code></td>
<td>
<p>The estimated density values. </p>
</td></tr>
<tr><td><code>cumulative.df</code></td>
<td>
<p>The estimated cumulative distribution values. </p>
</td></tr>
<tr><td><code>truncation.probs</code></td>
<td>
<p>The probability of <code>X</code> falling into each truncation interval. </p>
</td></tr>
<tr><td><code>hazard</code></td>
<td>
<p>The estimated hazard values. </p>
</td></tr>
<tr><td><code>S0</code></td>
<td>
<p><code>error</code> reached in the algorithm. </p>
</td></tr>
<tr><td><code>Survival</code></td>
<td>
<p>The estimated survival values. </p>
</td></tr>
<tr><td><code>n.iterations</code></td>
<td>
<p>The number of iterations used by this algorithm. </p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>Number of bootstrap resamples computed. </p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The nominal level used to construct the confidence intervals. </p>
</td></tr>
<tr><td><code>upper.df</code></td>
<td>
<p>The estimated upper limits of the confidence intervals for F. </p>
</td></tr>
<tr><td><code>lower.df</code></td>
<td>
<p>The estimated lower limits of the confidence intervals for F. </p>
</td></tr>
<tr><td><code>upper.Sob</code></td>
<td>
<p>The estimated upper limits of the confidence intervals for S. </p>
</td></tr>
<tr><td><code>lower.Sob</code></td>
<td>
<p>The estimated lower limits of the confidence intervals for S. </p>
</td></tr>
<tr><td><code>sd.boot</code></td>
<td>
<p>The bootstrap standard deviation of F estimator.</p>
</td></tr>
<tr><td><code>boot.repeat</code></td>
<td>
<p>The number of resamples done in each bootstrap call to ensure the existence and uniqueness of the bootstrap NPMLE. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Carla Moreira, Jacobo de Uña-Álvarez and Rosa Crujeiras </p>


<h3>References</h3>

<p> Efron B and Petrosian V (1999) Nonparametric methods for doubly truncated data. <em>Journal of the American Statistical Association</em> <b>94</b>, 824-834.
</p>
<p>Lynden-Bell D (1971) A method of allowing for known observational selection in small samples applied to 3CR quasars. <em>Monograph National Royal Astronomical Society</em> <b>155</b>, 95-118.</p>


<h3>See Also</h3>

<p><code><a href="#topic+efron.petrosian">efron.petrosian</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
#  Generating data which are doubly truncated

set.seed(4321)

n&lt;-25
X&lt;-runif(n,0,1)
U&lt;-runif(n,0,0.25)
V&lt;-runif(n,0.75,1)

for (i in 1:n){
	while (X[i]&lt;U[i]|X[i]&gt;V[i]){
	U[i]&lt;-runif(1,0,0.25)
	X[i]&lt;-runif(1,0,1)
	V[i]&lt;-runif(1,0.75,1)
					   }
		 }
res&lt;-lynden(X=X, U=U, V=V, boot=FALSE, display.F=TRUE, display.S=TRUE)

# Generating data which are right truncated

set.seed(4321)

n&lt;-25
X&lt;-runif(n,0,1)
V&lt;-runif(n,0.75,1)

for (i in 1:n){
	while (X[i]&gt;V[i]){
	X[i]&lt;-runif(1,0,1)
	V[i]&lt;-runif(1,0.75,1)
			     }
		 }
res&lt;-lynden(X=X,U=NA, V=V, boot=FALSE)


</code></pre>

<hr>
<h2 id='PDearly'>
Parkinson's Disease Data: early onset
</h2><span id='topic+PDearly'></span>

<h3>Description</h3>

<p>The sample consists of DNA from 99 Caucasian Parkinson's Disease (PD) patients with earlier onset PD (age 35-55 years).   To remove the selection bias related to survival, the study was limited to patients diagnosed from PD who had their DNA sample taken within eight years after onset. Consequently, the age of onset is doubly truncated by the age at blood sampling and this time minus 8 years. This is a situation of interval sampling, the sampling interval being subject-specific.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("PDearly")</code></pre>


<h3>Format</h3>

<p>A data frame with 99 observations on the following 5 variables.
</p>

<dl>
<dt><code>X</code></dt><dd><p>a numeric vector, age at onset of PD (in years).</p>
</dd>
<dt><code>U</code></dt><dd><p>a numeric vector, age at blood sampling minus 8 years. </p>
</dd>
<dt><code>V</code></dt><dd><p>a numeric vector,  age at blood sampling.</p>
</dd>
<dt><code>SNP_A10398G</code></dt><dd><p>a factor with allels levels <code>A</code> and <code>G</code>.</p>
</dd>
<dt><code>SNP_PGC1a</code></dt><dd><p>a factor with allels levels <code>A</code>, <code>AG</code> and <code>G</code>.</p>
</dd>
</dl>



<h3>Details</h3>

<p><cite>Clark et al., 2011</cite> hypothesized that the rs8192678 PGC-1a single nucleotide polymorphism (SNP) and the A10398G mitochondrial SNP may influence risk or age of onset of PD. To test these hypotheses, genomic DNA samples from human blood samples were obtained from the National Institute of Neurological Disorders and Stroke(NINDS) Human Genetics DNA and Cell Line Repositoryat the Coriell Institute for Medical Research (Camden, NewJersey).
</p>


<h3>Source</h3>

<p>Mandel M, de Uña-Álvarez J,  Simon DK and Betensky R (2018). Inverse Probability Weighted Cox Regression for Doubly Truncated Data. <em>Biometrics</em> <b>74</b>, 481-487.
</p>


<h3>References</h3>

<p>Clark J, Reddy S,  Zheng K,  Betensky RA and Simon DK (2011) Association of PGC-1alphapolymorphisms with age of onset and risk of Parkinson's disease. <em>BMC Medical Genetics</em> <b>12</b>, 69.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PDlate">PDlate</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(PDearly)
str(PDearly)
</code></pre>

<hr>
<h2 id='PDlate'>
Parkinson's Disease Data: late onset
</h2><span id='topic+PDlate'></span>

<h3>Description</h3>

<p>The sample consists of DNA from 100 Caucasian Parkinson's Disease (PD) patients with late onset PD (age 63-87 years).  To remove the selection bias related to survival, the study was limited to patients diagnosed from PD who had their DNA sample taken within eight years after onset. Consequently, the age of onset is doubly truncated by the age at blood sampling and this time minus 8 years. This is a situation of interval sampling, the sampling interval being subject-specific.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("PDlate")</code></pre>


<h3>Format</h3>

<p>A data frame with 100 observations on the following 5 variables.
</p>

<dl>
<dt><code>X</code></dt><dd><p>a numeric vector, age at onset of PD (in years).</p>
</dd>
<dt><code>U</code></dt><dd><p>a numeric vector, age at blood sampling minus 8 years. </p>
</dd>
<dt><code>V</code></dt><dd><p>a numeric vector, age at blood sampling.</p>
</dd>
<dt><code>SNP_A10398G</code></dt><dd><p>a factor with allels levels <code>A</code> and <code>G</code>.</p>
</dd>
<dt><code>SNP_PGC1a</code></dt><dd><p>a factor with allels levels <code>A</code>, <code>AG</code> and <code>G</code>.</p>
</dd>
</dl>



<h3>Details</h3>

<p><cite>Clark et al., 2011</cite> hypothesized that the rs8192678 PGC-1a single nucleotide polymorphism (SNP) and the A10398G mitochondrial SNP may influence risk or age of onset of PD. To test these hypotheses, genomic DNA samples from human blood samples were obtained from the National Institute of Neurological Disorders and Stroke(NINDS) Human Genetics DNA and Cell Line Repositoryat the Coriell Institute for Medical Research (Camden, NewJersey).
</p>


<h3>Source</h3>

<p>Mandel M, de Uña-Álvarez J,  Simon DK and Betensky R (2018). Inverse Probability Weighted Cox Regression for Doubly Truncated Data. <em>Biometrics</em> <b>74</b>, 481-487.
</p>


<h3>References</h3>

<p>Clark J, Reddy S,  Zheng K,  Betensky RA and Simon DK (2011) Association of PGC-1alphapolymorphisms with age of onset and risk of Parkinson's disease. <em>BMC Medical Genetics</em> <b>12</b>, 69.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PDearly">PDearly</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(PDlate)
str(PDlate)
</code></pre>

<hr>
<h2 id='Quasars'> Quasars Data
</h2><span id='topic+Quasars'></span>

<h3>Description</h3>

<p>The original dataset studied by Efron and Petrosian (1999) comprised independlently collected quadruplets of the redshift and the apparent magnitude of a quasar object. Due to experiemtnal constraints, the distribution of each luminosity in a log-scale is truncated to a known interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Quasars)</code></pre>


<h3>Format</h3>

<p>A data frame with 210 observations on the following 3 variables.
</p>

<dl>
<dt><code>y (adj lum)</code></dt><dd><p>a numeric vector, the log lominosity values.</p>
</dd>
<dt><code>u (lower)</code></dt><dd><p>a numeric vector, lower truncation limits.</p>
</dd>
<dt><code>v (upper)</code></dt><dd><p>a numeric vector, upper truncation limits.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Quadruplets in the original data set studied by <cite>Efron and Petrosian (1999)</cite> are of the form <code class="reqn">(z_i;m_i; a_i; b_i), i = 1, \ldots n</code>, where <code class="reqn">z_i</code> is the redshift of the ith quasar and
<code class="reqn">m_i</code> is the apparent magnitude. Due to experimental constraints, the distribution of each luminosity in the log-scale <code class="reqn">(y_i = t(z_i, m_i))</code> is truncated to a known interval <code class="reqn">[a_i; b_i]</code>, where <code class="reqn">t</code>
represents a transformation which depends on the cosmological model assumed (see <cite>Efron
and Petrosian (1999)</cite> for details). Quasars with apparent magnitude above <code class="reqn">b_i</code> were too dim to yield dependent redshifts, and hence they were excluded from the study. The lower limit <code class="reqn">a_i</code>
was used to avoid confusion with non quasar stellar objects.
</p>


<h3>Source</h3>

<p>Vahé Petrosian and Bradley Efron.
</p>


<h3>References</h3>

<p>Boyle BJ,  Fong R, Shanks, T and Peterson, BA (1990) A catalogue of faint, UV-excess objects. <em>Monograph National Royal Astronomical Society</em> <b>243</b>, 1-56.
</p>
<p>Efron B and Petrosian V (1999) Nonparametric methods for doubly truncated data. <em>Journal of the American Statistical Association</em> <b>94</b>, 824-834.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Quasars)
 str(Quasars)
</code></pre>

<hr>
<h2 id='rsim.DT'>
Random generation functions of doubly truncated data
</h2><span id='topic+rsim.DT'></span>

<h3>Description</h3>

<p>Random generation functions of doubly truncated data with two different patterns of observational bias.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rsim.DT(n,tau, model=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rsim.DT_+3A_n">n</code></td>
<td>
<p> number of observations to generate.</p>
</td></tr>
<tr><td><code id="rsim.DT_+3A_tau">tau</code></td>
<td>
<p> length of the observational window.</p>
</td></tr>
<tr><td><code id="rsim.DT_+3A_model">model</code></td>
<td>
<p>model to be simulated. Number 1 or 2 corresponding to different patterns of observacional bias.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>model</code>=1, <code class="reqn">U\sim Unif(-\code{tau},1)</code> and V= U+ <code>tau</code>. If <code>model</code>=2, <code class="reqn">U \sim Unif(0,1)^2\times (\code{tau}+1)-\code{tau}</code> and V= U+ <code>tau</code>. In <code>model</code>=1 there is no observational bias due double truncation while in <code>model</code>=2 double truncation induces observational bias.
</p>


<h3>Value</h3>

<p>A matrix with <code>n</code> unit length rows representing the generated values from a doubly truncated data with triplets <code class="reqn">(X, U and V)</code>, in which <code class="reqn">(U \leq X \leq V)</code>.




</p>


<h3>Author(s)</h3>

<p> Carla Moreira, Jacobo de Uña-Álvarez and Rosa Crujeiras
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(4321)
rsim.DT(500,1/2, model=2)
</code></pre>

<hr>
<h2 id='shen'> NPMLE computation with Shen algorithm</h2><span id='topic+shen'></span>

<h3>Description</h3>

<p>This function computes the NPMLE for the cumulative distribution function of  <code>X</code> observed under one-sided (right or left) and two-sided (double) truncation.
The NPMLE of the joint distribution of the truncation times along with its marginal distributions are also computed.
It provides bootstrap pointwise confidence limits too.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shen(X, U = NA, V = NA, wt = NA, error = NA,
	 nmaxit = NA, boot = TRUE, boot.type = "simple",
		 B = NA, alpha = NA, display.FS = FALSE,
			display.UV = FALSE, plot.joint = FALSE, plot.type = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="shen_+3A_x">X</code></td>
<td>
<p> Numeric vector with the values of the target variable.</p>
</td></tr>
<tr><td><code id="shen_+3A_u">U</code></td>
<td>
<p>Numeric vector with the values of the left truncation variable. If there are no truncation values from the left, put <code>U</code>=<code>NA</code>.</p>
</td></tr>
<tr><td><code id="shen_+3A_v">V</code></td>
<td>
<p> Numeric vector with the values of the right truncation variable. If there are no truncation values from the right, put <code>V</code>=<code>NA</code>.</p>
</td></tr>
<tr><td><code id="shen_+3A_wt">wt</code></td>
<td>
<p> Numeric vector of non-negative initial solution, with the same length as <code>X</code>. Default value is set to 1/n, being n the length of <code>X</code>. </p>
</td></tr>
<tr><td><code id="shen_+3A_error">error</code></td>
<td>
<p> Numeric value. Maximum pointwise error when estimating the density associated to X (f) in two consecutive steps. If this is missing, it is $1e-06$.</p>
</td></tr>
<tr><td><code id="shen_+3A_nmaxit">nmaxit</code></td>
<td>
<p> Numeric value. Maximum number of iterations. If this is missing, it is set to <code>nmaxit</code> =100 . </p>
</td></tr>
<tr><td><code id="shen_+3A_boot">boot</code></td>
<td>
<p> Logical. If TRUE (default), the simple bootstrap method is applied to lifetime and truncation times distributions estimation.
Pointwise confidence bands are provided. </p>
</td></tr>
<tr><td><code id="shen_+3A_boot.type">boot.type</code></td>
<td>
<p> A character string giving the bootstrap type to be used. This must be one of <code>"simple"</code> or <code>"obvious"</code>, with default <code>"simple"</code>.   </p>
</td></tr>
<tr><td><code id="shen_+3A_b">B</code></td>
<td>
<p> Numeric value. Number of bootstrap resamples . The default <code>NA</code> is equivalent to <code>B</code> =500 . </p>
</td></tr>
<tr><td><code id="shen_+3A_alpha">alpha</code></td>
<td>
<p> Numeric value. (1-<code>alpha</code>) is the nominal coverage for the pointwise confidence intervals. </p>
</td></tr>
<tr><td><code id="shen_+3A_display.fs">display.FS</code></td>
<td>
<p> Logical. Default is FALSE. If TRUE, the estimated cumulative distribution function and the estimated survival function associated to <code>X</code>, (F) and (S) respectively, are plotted.   </p>
</td></tr>
<tr><td><code id="shen_+3A_display.uv">display.UV</code></td>
<td>
<p> Logical. Default is FALSE. If TRUE, the marginal distributions of <code>U</code> <code>(fU)</code> and <code>V</code> <code>(fV)</code>, are plotted.</p>
</td></tr>
<tr><td><code id="shen_+3A_plot.joint">plot.joint</code></td>
<td>
<p> Logical. Default is FALSE. If TRUE, the joint distribution of the truncation times is plotted. </p>
</td></tr>
<tr><td><code id="shen_+3A_plot.type">plot.type</code></td>
<td>
<p> A character string giving the plot type to be used to represent the joint distribution of the truncation times.
This must be one of &quot;image&quot; or &quot;persp&quot;, with default <code>NULL</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The NPMLE for the cumulative distribution function is computed by a single algorithm proposed in <cite>Shen (2010)</cite>. This is an iterative algorithm which converges to the
NMPLE after a number of iterations. Initial solutions are given by the ordinary empirical distribution functions.
If the second (respectively third) argument is missing, computation of the Lynden-Bell estimator for right-truncated (respectively left-truncated)
data is obtained.
Note that individuals with NAs in the three first arguments will be automatically excluded.
</p>


<h3>Value</h3>

<p>A list containing the following values:
</p>
<table>
<tr><td><code>time</code></td>
<td>
<p>The timepoint on the curve. </p>
</td></tr>
<tr><td><code>n.event</code></td>
<td>
<p>The number of events that ocurred at time <code>t</code>. </p>
</td></tr>
<tr><td><code>events</code></td>
<td>
<p>The total number of events. </p>
</td></tr>
<tr><td><code>density</code></td>
<td>
<p>The estimated density values associated to <code>X</code>. </p>
</td></tr>
<tr><td><code>cumulative.df</code></td>
<td>
<p>The estimated cumulative distribution values of <code>X</code>. </p>
</td></tr>
<tr><td><code>truncation.probs</code></td>
<td>
<p>The probability of <code>X</code> falling into each truncation interval.</p>
</td></tr>
<tr><td><code>S0</code></td>
<td>
 <p><code>error</code> reached in the algorithm. </p>
</td></tr>
<tr><td><code>Survival</code></td>
<td>
<p>The estimated survival values. </p>
</td></tr>
<tr><td><code>density.joint</code></td>
<td>
<p>The estimated joint densities values associated to <code>(U,V</code>).  </p>
</td></tr>
<tr><td><code>marginal.U</code></td>
<td>
<p>The estimated cumulative univariate marginal values of the <code>U</code>. </p>
</td></tr>
<tr><td><code>marginal.V</code></td>
<td>
<p>The estimated cumulative univariate marginal values of the <code>V</code>. </p>
</td></tr>
<tr><td><code>cumulative.joint</code></td>
<td>
<p>The estimated joint cumulative distribution values. </p>
</td></tr>
<tr><td><code>n.iterations</code></td>
<td>
<p>The number of iterations used by this algorithm. </p>
</td></tr>
<tr><td><code>biasf</code></td>
<td>
<p>The estimated probabilities of observing the lifetimes.</p>
</td></tr>
<tr><td><code>Boot</code></td>
<td>
<p>The type of bootstrap method applied. </p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>Number of bootstrap resamples computed. </p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The nominal level used to construct the confidence intervals. </p>
</td></tr>
<tr><td><code>upper.df</code></td>
<td>
<p>The estimated upper limits of the confidence intervals for F. </p>
</td></tr>
<tr><td><code>lower.df</code></td>
<td>
<p>The estimated lower limits of the confidence intervals for F. </p>
</td></tr>
<tr><td><code>upper.Sob</code></td>
<td>
<p>The estimated upper limits of the confidence intervals for S. </p>
</td></tr>
<tr><td><code>lower.Sob</code></td>
<td>
<p>The estimated lower limits of the confidence intervals for S. </p>
</td></tr>
<tr><td><code>upper.fU</code></td>
<td>
<p>The estimated upper limits of the confidence intervals for <code>fU</code>. </p>
</td></tr>
<tr><td><code>lower.fU</code></td>
<td>
<p>The estimated lower limits of the confidence intervals for <code>fU</code>. </p>
</td></tr>
<tr><td><code>upper.fV</code></td>
<td>
<p>The estimated upper limits of the confidence intervals for <code>fV</code>. </p>
</td></tr>
<tr><td><code>lower.fV</code></td>
<td>
<p>The estimated lower limits of the confidence intervals for <code>fV</code>. </p>
</td></tr>
<tr><td><code>sd.boot</code></td>
<td>
<p>The bootstrap standard deviation of F estimator.</p>
</td></tr>
<tr><td><code>boot.repeat</code></td>
<td>
<p>The number of resamples done in each bootstrap call to ensure the existence and uniqueness of the bootstrap NPMLE. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Carla Moreira, Jacobo de Uña-Álvarez and Rosa Crujeiras </p>


<h3>References</h3>

<p> Lynden-Bell D (1971) A method of allowing for known observational selection in small samples applied to 3CR quasars. <em>Monograph National Royal Astronomical Society</em> <b>155</b>, 95-118.
</p>
<p>Shen P-S (2010) Nonparametric analysis of doubly truncated data. <em>Annals of the Institute of Statistical Mathematics</em> <b>62</b>, 835-853.
</p>
<p>Xiao J,  Hudgens MG (2020) On nonparametric maximum likelihood estimation with double truncation. <em>Biometrika</em> <b>106</b>, 989-996.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lynden">lynden</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
##  Generating data which are doubly truncated

set.seed(4321)
n&lt;-100
X&lt;-runif(n,0,1)
U&lt;-runif(n,0,0.67)
V&lt;-runif(n,0.33,1)
for (i in 1:n){
	while (X[i]&lt;U[i]|X[i]&gt;V[i]){
	U[i]&lt;-runif(1,0,0.67)
	X[i]&lt;-runif(1,0,1)
	V[i]&lt;-runif(1,0.33,1)
					}
		}

res&lt;-shen(X,U,V,boot=FALSE, plot.joint=TRUE, plot.type="persp")

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
