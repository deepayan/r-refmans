<!DOCTYPE html><html><head><title>Help for package MoTBFs</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {MoTBFs}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#as.function.jointmotbf'><p>Coerce a <code>"jointmotbf"</code> Object to a Function</p></a></li>
<li><a href='#as.function.motbf'><p>Coerce an <code>"motbf"</code> object to a Function</p></a></li>
<li><a href='#asMOPString'><p>Parameters to MOP String</p></a></li>
<li><a href='#asMTEString'><p>Converting MTEs to strings</p></a></li>
<li><a href='#BICMoTBF'><p>Computing the BIC score of an MoTBF function</p></a></li>
<li><a href='#BICMultiFunctions'><p>BIC score for multiple functions</p></a></li>
<li><a href='#Class-JointMoTBF'><p>Class <code>"jointmotbf"</code></p></a></li>
<li><a href='#Class-MoTBF'><p>Class <code>"motbf"</code></p></a></li>
<li><a href='#clean'><p>Remove Objects from Memory</p></a></li>
<li><a href='#coef.jointmotbf'><p>Coefficients of a <code>"jointmotbf"</code> object</p></a></li>
<li><a href='#coef.mop'><p>Extract coefficients from MOPs</p></a></li>
<li><a href='#coef.motbf'><p>Extract the coefficients of an MoTBF</p></a></li>
<li><a href='#coef.mte'><p>Extracting the coefficients of an MTE</p></a></li>
<li><a href='#coefExpJointCDF'><p>Degree Function</p></a></li>
<li><a href='#conditionalmotbf.learning'><p>Learning conditional MoTBF densities</p></a></li>
<li><a href='#dataMining'><p>Data pre-processing utilities</p></a></li>
<li><a href='#derivMOP'><p>Derivative of a MOP</p></a></li>
<li><a href='#derivMoTBF'><p>Derivating MoTBFs</p></a></li>
<li><a href='#derivMTE'><p>Derivating MTEs</p></a></li>
<li><a href='#dimensionFunction'><p>Dimension of MoTBFs</p></a></li>
<li><a href='#discreteStatesFromBN'><p>Get the states of all discrete nodes from a MoTFB-BN</p></a></li>
<li><a href='#ecoli'><p>Data set Ecoli: Protein Localization Sites</p></a></li>
<li><a href='#evalJointFunction'><p>Evaluation of joint MoTBFs</p></a></li>
<li><a href='#findConditional'><p>Find fitted conditional MoTBFs</p></a></li>
<li><a href='#forward_sampling'><p>Forward Sampling</p></a></li>
<li><a href='#generateNormalPriorData'><p>Prior data generation</p></a></li>
<li><a href='#getChildParentsFromGraph'><p>Get the list of relations in a graph</p></a></li>
<li><a href='#getCoefficients'><p>Get the coefficients</p></a></li>
<li><a href='#getNonNormalisedRandomMoTBF'><p>Ramdom MoTBF</p></a></li>
<li><a href='#goodnessDiscreteVariables'><p>BIC scxore and log-likelihood</p></a></li>
<li><a href='#goodnessMoTBFBN'><p>BIC of a hybrid BN</p></a></li>
<li><a href='#integralJointMoTBF'><p>Integration with MoTBFs</p></a></li>
<li><a href='#integralMOP'><p>Integration of MOPs</p></a></li>
<li><a href='#integralMoTBF'><p>Integrating MoTBFs</p></a></li>
<li><a href='#integralMTE'><p>Integrating MTEs</p></a></li>
<li><a href='#is.discrete'><p>Check discreteness of a node</p></a></li>
<li><a href='#is.observed'><p>Observed Node</p></a></li>
<li><a href='#is.root'><p>Root nodes</p></a></li>
<li><a href='#jointCDF'><p>Joint MoTBFs CDFs</p></a></li>
<li><a href='#jointmotbf.learning'><p>Joint MoTBF density learning</p></a></li>
<li><a href='#LearningHC'><p>Score-based hybrid Bayesian Network structure learning</p></a></li>
<li><a href='#learnMoTBFpriorInformation'><p>Incorporating prior knowledge in the estimation process</p></a></li>
<li><a href='#marginalJointMoTBF'><p>Marginalization of MoTBFs</p></a></li>
<li><a href='#mop.learning'><p>Fitting mixtures of polynomials</p></a></li>
<li><a href='#motbf_type'><p>Type of MoTBF</p></a></li>
<li><a href='#MoTBF-Distribution'><p>Random generation for MoTBF distributions</p></a></li>
<li><a href='#MoTBFs_Learning'><p>Learning hybrid BNs with MoTBFs</p></a></li>
<li><a href='#mte.learning'><p>Fitting mixtures of truncated exponentials.</p></a></li>
<li><a href='#newRangePriorData'><p>Redefining the Domain</p></a></li>
<li><a href='#nVariables'><p>Number of Variables in a Joint Function</p></a></li>
<li><a href='#parentValues'><p>Value of parent nodes</p></a></li>
<li><a href='#plot.jointmotbf'><p>Bidimensional plots for <code>'jointmotbf'</code> objects</p></a></li>
<li><a href='#plot.motbf'><p>Plots for <code>'motbf'</code> objects</p></a></li>
<li><a href='#plotConditional'><p>Plot Conditional Functions</p></a></li>
<li><a href='#preprocessedData'><p>Data cleaning</p></a></li>
<li><a href='#printBN'><p>BN printing</p></a></li>
<li><a href='#printConditional'><p>Summary of conditional MoTBF densities</p></a></li>
<li><a href='#printDiscreteBN'><p>Printing discrete Bayesian networks</p></a></li>
<li><a href='#probDiscreteVariable'><p>Probability distribution of discrete variables</p></a></li>
<li><a href='#r.data.frame'><p>Data frame initialization for forward sampling</p></a></li>
<li><a href='#rescaledFunctions'><p>Rescaling MoTBF functions</p></a></li>
<li><a href='#rnormMultiv'><p>Multivariate Normal sampling</p></a></li>
<li><a href='#sample_MoTBFs'><p>Sample generation from conditional MoTBFs</p></a></li>
<li><a href='#Subclass-MoTBF'><p>Subclass <code>"motbf"</code> Functions</p></a></li>
<li><a href='#subsetData'><p>Dataset subsetting</p></a></li>
<li><a href='#summary.jointmotbf'><p>Summary of a <code>"jointmotbf"</code> object</p></a></li>
<li><a href='#summary.motbf'><p>Summary of an <code>"motbf"</code> object</p></a></li>
<li><a href='#thyroid'><p>Data set Thyroid Disease (thyroid0387)</p></a></li>
<li><a href='#univMoTBF'><p>Fitting MoTBFs</p></a></li>
<li><a href='#UpperBoundLogLikelihood'><p>Upper bound of the loglikelihood</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Learning Hybrid Bayesian Networks using Mixtures of Truncated
Basis Functions</td>
</tr>
<tr>
<td>Version:</td>
<td>1.4.1</td>
</tr>
<tr>
<td>Author:</td>
<td>Inmaculada Pérez-Bernabé, Antonio Salmerón, Thomas D. Nielsen, Ana D. Maldonado</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ana D. Maldonado &lt;ana.d.maldonado@ual.es&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Learning, manipulation and  evaluation of mixtures of  truncated basis  functions 
  (MoTBFs),  which include mixtures of  polynomials (MOPs) and  mixtures of truncated 
  exponentials (MTEs). MoTBFs are a flexible framework for modelling hybrid Bayesian
  networks (I. Pérez-Bernabé, A. Salmerón, H. Langseth (2015) &lt;<a href="https://doi.org/10.1007%2F978-3-319-20807-7_36">doi:10.1007/978-3-319-20807-7_36</a>&gt;; H. Langseth, T.D. Nielsen, I. Pérez-Bernabé, A. Salmerón (2014) &lt;<a href="https://doi.org/10.1016%2Fj.ijar.2013.09.012">doi:10.1016/j.ijar.2013.09.012</a>&gt;; I. Pérez-Bernabé, A. Fernández, R. Rumí, A. Salmerón (2016) &lt;<a href="https://doi.org/10.1007%2Fs10618-015-0429-7">doi:10.1007/s10618-015-0429-7</a>&gt;). The  package provides  functionality for learning  univariate, multivariate and
  conditional  densities, with the  possibility of incorporating prior  knowledge. Structural
  learning of hybrid Bayesian  networks is also provided. A set of useful tools is provided,
  including  plotting, printing  and likelihood  evaluation. This  package  makes use of  S3 
  objects, with two new classes called 'motbf' and 'jointmotbf'.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>quadprog, lpSolve, bnlearn, methods, ggm, Matrix</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/LGPL-3">LGPL-3</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-04-18 13:15:36 UTC; amaldonado</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-04-18 16:34:30 UTC</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
</table>
<hr>
<h2 id='as.function.jointmotbf'>Coerce a <code>"jointmotbf"</code> Object to a Function</h2><span id='topic+as.function.jointmotbf'></span>

<h3>Description</h3>

<p>Takes a <code>"jointmotbf"</code> object and contructs an <span class="rlang"><b>R</b></span> function to evaluate it at multidimensional points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'jointmotbf'
as.function(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.function.jointmotbf_+3A_x">x</code></td>
<td>
<p>An object of class <code>"joinmotbf"</code>.</p>
</td></tr>
<tr><td><code id="as.function.jointmotbf_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to or from the method. Not necessary for this method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is an <code>S3</code> method for the generic function <a href="base.html#topic+as.function">as.function</a>.
</p>


<h3>Value</h3>

<p>It returns a function to evaluate an object of class <code>"jointmotbf"</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+parametersJointMoTBF">parametersJointMoTBF</a> and <a href="#topic+jointMoTBF">jointMoTBF</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 1.EXAMPLE
## Dataset
data &lt;- data.frame(X = rnorm(100), Y = rexp(100))

## Joint function
dim &lt;- c(3,2)
param &lt;- parametersJointMoTBF(data, dimensions = dim)
P &lt;- jointMoTBF(param)
density &lt;- as.function(P)(data[,1], data[,2])
density

## Log-likelihood
sum(log(density))

#############################################################################
## MORE EXAMPLES ############################################################
#############################################################################

## Dataset
data &lt;- data.frame(X = rnorm(100), Y = rexp(100), Z = rnorm(100))

## Joint function
dim &lt;- c(2,3,4)
param &lt;- parametersJointMoTBF(data, dimensions = dim)
P &lt;- jointMoTBF(param)
density &lt;- as.function(P)(data[,1], data[,2], data[,3])
density

## Log-likelihood
sum(log(density))

</code></pre>

<hr>
<h2 id='as.function.motbf'>Coerce an <code>"motbf"</code> object to a Function</h2><span id='topic+as.function.motbf'></span>

<h3>Description</h3>

<p>Takes an <code>"motbf"</code> object and contructs an <span class="rlang"><b>R</b></span> function to evaluate it at points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'motbf'
as.function(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.function.motbf_+3A_x">x</code></td>
<td>
<p>An object of class <code>"motbf"</code>.</p>
</td></tr>
<tr><td><code id="as.function.motbf_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to or from the method. Not necessary for this method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is an <code>S3</code> method for the generic function <a href="base.html#topic+as.function">as.function</a>.
</p>


<h3>Value</h3>

<p>It returns a function to evaluate an object of class <code>"motbf"</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Data
X &lt;- rchisq(5000, df = 3)

## Learning
P &lt;- univMoTBF(X, POTENTIAL_TYPE = "MOP"); P

## Evaluation
as.function(P)(min(X))
as.function(P)(max(X))
as.function(P)(10)
density &lt;- as.function(P)(X)

## Plot
hist(X, prob = TRUE, main = "")
points(X, density, col=4, pch=16)

</code></pre>

<hr>
<h2 id='asMOPString'>Parameters to MOP String</h2><span id='topic+asMOPString'></span>

<h3>Description</h3>

<p>This function builds a string with the structure of a <code>'mop'</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>asMOPString(parameters)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="asMOPString_+3A_parameters">parameters</code></td>
<td>
<p>A <code>"numeric"</code> vector containing the coefficients.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>"character"</code> string with a <code>'mop'</code> structure.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
param &lt;- c(1,2,3,4)
asMOPString(param)

param &lt;- 3.4
asMOPString(param)

</code></pre>

<hr>
<h2 id='asMTEString'>Converting MTEs to strings</h2><span id='topic+asMTEString'></span>

<h3>Description</h3>

<p>This function builds a string with the structure of an <code>'mte'</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>asMTEString(parameters, num = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="asMTEString_+3A_parameters">parameters</code></td>
<td>
<p>A <code>"numeric"</code> vector containing the coefficients.</p>
</td></tr>
<tr><td><code id="asMTEString_+3A_num">num</code></td>
<td>
<p>A <code>"numeric"</code> value which contains the denominator of the coefficient
in the exponential.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>"character"</code> string with an <code>'mte'</code> structure.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
param &lt;- -5.8
asMTEString(param)

param &lt;- c(5.2,0.3,-3,4)
asMTEString(param)
 
</code></pre>

<hr>
<h2 id='BICMoTBF'>Computing the BIC score of an MoTBF function</h2><span id='topic+BICMoTBF'></span>

<h3>Description</h3>

<p>Computes the Bayesian information criterion value (BIC) of a 
mixture of truncated basis functions. The BIC score is the log likelihood 
penalized by the number of parameters of the function and the number of
records of the evaluated data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BICMoTBF(Px, X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BICMoTBF_+3A_px">Px</code></td>
<td>
<p>A function of class <code>"motbf"</code>.</p>
</td></tr>
<tr><td><code id="BICMoTBF_+3A_x">X</code></td>
<td>
<p>A <code>"numeric"</code> vector with the data to evaluate.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>"numeric"</code> value corresponding to the BIC score.
</p>


<h3>See Also</h3>

<p><a href="#topic+univMoTBF">univMoTBF</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Data
X &lt;- rexp(10000)

## Data test
Xtest &lt;- rexp(1000)
Xtest &lt;- Xtest[Xtest&gt;=min(X) &amp; Xtest&lt;=max(X)]

## Learning
f1 &lt;- univMoTBF(X, POTENTIAL_TYPE = "MOP", nparam = 10); f1
f2 &lt;- univMoTBF(X, POTENTIAL_TYPE = "MTE", maxParam = 11); f2

## BIC values
BICMoTBF(Px = f1, X = Xtest)
BICMoTBF(Px = f2, X = Xtest)


</code></pre>

<hr>
<h2 id='BICMultiFunctions'>BIC score for multiple functions</h2><span id='topic+BICMultiFunctions'></span>

<h3>Description</h3>

<p>Compute the BIC score using more than one probability functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BICMultiFunctions(Px, X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BICMultiFunctions_+3A_px">Px</code></td>
<td>
<p>A list of objects of class <code>"motbf"</code>.</p>
</td></tr>
<tr><td><code id="BICMultiFunctions_+3A_x">X</code></td>
<td>
<p>A list with as many <code>"numeric"</code> vectors as densities in <code>Px</code>,
used to compute the BIC score for each density.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>"numeric"</code> BIC value.
</p>


<h3>See Also</h3>

<p><a href="#topic+univMoTBF">univMoTBF</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Data
X &lt;- rnorm(500)
Y &lt;- rnorm(500, mean=1)
data &lt;- data.frame(X=X, Y=Y)
## Data as a "list"
Xlist &lt;- sapply(data, list)

## Learning as a "list"
Plist &lt;- lapply(data, univMoTBF, POTENTIAL_TYPE="MOP")
Plist

## BIC value
BICMultiFunctions(Px=Plist, X=Xlist)

</code></pre>

<hr>
<h2 id='Class-JointMoTBF'>Class <code>"jointmotbf"</code></h2><span id='topic+Class-JointMoTBF'></span><span id='topic+jointmotbf'></span><span id='topic+print.jointmotbf'></span><span id='topic+as.character.jointmotbf'></span><span id='topic+as.list.jointmotbf'></span><span id='topic+is.jointmotbf'></span>

<h3>Description</h3>

<p>Defines an object of class <code>"jointmotbf"</code> and other basic functions for 
manipulating <code>"jointmotbf"</code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jointmotbf(x = 0)

## S3 method for class 'jointmotbf'
print(x, ...)

## S3 method for class 'jointmotbf'
as.character(x, ...)

## S3 method for class 'jointmotbf'
as.list(x, ...)

is.jointmotbf(x, class = "jointmotbf")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Class-JointMoTBF_+3A_x">x</code></td>
<td>
<p>Preferably, a list containing an expression
and other posibles elements like a <code>"numeric"</code> matrix with the domain of the variables, 
the dimension of the variables, the number of iterations needed to solve the optimization problem,
among others. Any <span class="rlang"><b>R</b></span> object can be entered, but the utility of this function is not to transform
objects of other classes into objects of class <code>"jointmotbf"</code>.</p>
</td></tr>
<tr><td><code id="Class-JointMoTBF_+3A_...">...</code></td>
<td>
<p>Additional arguments, not needed by these methods.</p>
</td></tr>
<tr><td><code id="Class-JointMoTBF_+3A_class">class</code></td>
<td>
<p>By default is <code>"jointmotbf"</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><a href="#topic+jointMoTBF">jointMoTBF</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## n.parameters is the product of the dimensions
dim &lt;- c(3,3)
param &lt;- seq(1,prod(dim), by=1)
## Joint Function 
f &lt;- list(Parameters=param, Dimensions=dim)
jointF &lt;- jointMoTBF(f)

print(jointF) ## jointF
as.character(jointF)
as.list(jointF)
is(jointF)
is.jointmotbf(jointF)
</code></pre>

<hr>
<h2 id='Class-MoTBF'>Class <code>"motbf"</code></h2><span id='topic+Class-MoTBF'></span><span id='topic+motbf'></span><span id='topic+print.motbf'></span><span id='topic+as.character.motbf'></span><span id='topic+as.list.motbf'></span><span id='topic+is.motbf'></span>

<h3>Description</h3>

<p>Defines an object of class <code>"motbf"</code> and other basic functions for manipulating 
<code>"motbf"</code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>motbf(x = 0)

## S3 method for class 'motbf'
print(x, ...)

## S3 method for class 'motbf'
as.character(x, ...)

## S3 method for class 'motbf'
as.list(x, ...)

is.motbf(x, class = "motbf")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Class-MoTBF_+3A_x">x</code></td>
<td>
<p>Preferably, a list containing an <code>'mte'</code> or <code>'mop'</code> univariate expression
and other posibles elements like a <code>"numeric"</code> vector with the domain of the variable, 
the number of iterations needed to solve the optimization problem, among others.
Any <span class="rlang"><b>R</b></span> object can be entered, but the utility of this function is not to transform
objects of other classes into objects of class <code>"motbf"</code>.</p>
</td></tr>
<tr><td><code id="Class-MoTBF_+3A_...">...</code></td>
<td>
<p>Additional arguments, not needed for these methods.</p>
</td></tr>
<tr><td><code id="Class-MoTBF_+3A_class">class</code></td>
<td>
<p>By default is <code>"motbf"</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><a href="#topic+asMOPString">asMOPString</a> and <a href="#topic+asMTEString">asMTEString</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Subclass 'MOP'
param &lt;- c(1,2,3,4,5)
MOPString &lt;- asMOPString(param)
fMOP &lt;- motbf(MOPString)
print(fMOP) ## fMOP
as.character(fMOP)
as.list(fMOP)
is(fMOP) 
is.motbf(fMOP)

## Subclass 'MTE'
param &lt;- c(6,7,8,9,10)
MTEString &lt;- asMTEString(param)
fMTE &lt;- motbf(MTEString)
print(fMTE) ## MTE
as.character(fMTE)
as.list(fMTE)
is(fMTE) 
is.motbf(fMTE)
</code></pre>

<hr>
<h2 id='clean'>Remove Objects from Memory</h2><span id='topic+clean'></span>

<h3>Description</h3>

<p>Clean the memory. Delete all the objects in memory and a garbage collection
takes place.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clean(envir = globalenv(), n = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clean_+3A_envir">envir</code></td>
<td>
<p>The currently active environment; by default It is the gloval environment.</p>
</td></tr>
<tr><td><code id="clean_+3A_n">n</code></td>
<td>
<p>Number of garbage collection repetitions; by default <code>n = 2</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Run to clean the environment
clean()
clean(n=2)
</code></pre>

<hr>
<h2 id='coef.jointmotbf'>Coefficients of a <code>"jointmotbf"</code> object</h2><span id='topic+coef.jointmotbf'></span>

<h3>Description</h3>

<p>Extracts the parameters of a joint MoTBF density.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'jointmotbf'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.jointmotbf_+3A_object">object</code></td>
<td>
<p>An MoTBF function.</p>
</td></tr>
<tr><td><code id="coef.jointmotbf_+3A_...">...</code></td>
<td>
<p>Other arguments, unnecessary for this function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>"numeric"</code> vector with the parameters of the function.
</p>


<h3>See Also</h3>

<p><a href="#topic+parametersJointMoTBF">parametersJointMoTBF</a> and <a href="#topic+jointMoTBF">jointMoTBF</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate a dataset
data &lt;- data.frame(X1 = rnorm(100), X2 = rnorm(100))

## Joint function
dim &lt;-c(2,4)
param &lt;- parametersJointMoTBF(data, dimensions = dim)
P &lt;- jointMoTBF(param)
P$Time

## Coefficients
coef(P)

#############################################################################
## MORE EXAMPLES ############################################################
#############################################################################

## Generate a dataset
data &lt;- data.frame(X1 = rnorm(100), X2 = rnorm(100), X3 = rnorm(100))
 
## Joint function
dim &lt;-c(2,4,3)
param &lt;- parametersJointMoTBF(data, dimensions = dim)
P &lt;- jointMoTBF(param)
P$Time

## Coefficients
coef(P)

</code></pre>

<hr>
<h2 id='coef.mop'>Extract coefficients from MOPs</h2><span id='topic+coef.mop'></span><span id='topic+coeffMOP'></span><span id='topic+coeffPol'></span>

<h3>Description</h3>

<p>It extracts the parameters of the learned mixtures of polynomial models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coeffMOP(fx)

coeffPol(fx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.mop_+3A_fx">fx</code></td>
<td>
<p>An <code>"motbf"</code> function of subclass <code>'mop'</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>coeffMOP()</code> return the coefficients of the terms in the function.
</p>
<p><code>coeffPol()</code> returns the coefficients of the potential of the polynomial basis in the function.
</p>


<h3>Value</h3>

<p>An array with the parameters of the function.
</p>


<h3>See Also</h3>

<p><a href="#topic+coef.motbf">coef.motbf</a> and <a href="#topic+univMoTBF">univMoTBF</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## 1. EXAMPLE
data &lt;- rchisq(1000, df=5)
fx1 &lt;- univMoTBF(data, POTENTIAL_TYPE = "MOP")
hist(data, prob=TRUE, main="")
plot(fx1, xlim=range(data), col="red", add=TRUE)
coeffMOP(fx1) ## coef(fx1)
coeffPol(fx1)

## 2. EXAMPLE
data &lt;- rexp(1000, rate=1/2)
fx2 &lt;- univMoTBF(data, POTENTIAL_TYPE = "MOP")
hist(data, prob=TRUE, main="")
plot(fx2, xlim=range(data), col="red", add=TRUE)
coeffMOP(fx2) ## coef(fx2)
coeffPol(fx2)
</code></pre>

<hr>
<h2 id='coef.motbf'>Extract the coefficients of an MoTBF</h2><span id='topic+coef.motbf'></span>

<h3>Description</h3>

<p>Extracts the parameters of the learned mixtures of truncated basis
functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'motbf'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.motbf_+3A_object">object</code></td>
<td>
<p>An object of class <code>motbf</code>.</p>
</td></tr>
<tr><td><code id="coef.motbf_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector with the parameters of the function.
</p>


<h3>See Also</h3>

<p><a href="#topic+univMoTBF">univMoTBF</a>, <a href="#topic+coeffMOP">coeffMOP</a> and <a href="#topic+coeffMTE">coeffMTE</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Data
X &lt;- rchisq(2000, df = 5)

## Learning
f1 &lt;- univMoTBF(X, POTENTIAL_TYPE = "MOP"); f1
## Coefficients
coef(f1)

## Learning
f2 &lt;- univMoTBF(X, POTENTIAL_TYPE = "MTE", maxParam = 10); f2
## Coefficients
coef(f2)

## Learning
f3 &lt;- univMoTBF(X, POTENTIAL_TYPE = "MOP", nparam=10); f3
## Coefficients
coef(f3)

## Plots
plot(NULL, xlim = range(X), ylim = c(0,0.2), xlab="X", ylab="density")
plot(f1, xlim = range(X), col = 1, add = TRUE)
plot(f2, xlim = range(X), col = 2, add = TRUE)
plot(f3, xlim = range(X), col = 3, add = TRUE)
hist(X, prob = TRUE, add= TRUE)

</code></pre>

<hr>
<h2 id='coef.mte'>Extracting the coefficients of an MTE</h2><span id='topic+coef.mte'></span><span id='topic+coeffMTE'></span><span id='topic+coeffExp'></span>

<h3>Description</h3>

<p>It extracts the parameters of the learned mixtures of truncated exponential models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coeffMTE(fx)

coeffExp(fx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.mte_+3A_fx">fx</code></td>
<td>
<p>An <code>"motbf"</code> function of subclass <code>'mte'</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>coeffMOP()</code> return the coefficients of the terms in the function.
</p>
<p><code>coeffPol()</code> returns the coefficients of the potential of the exponential basis in the function.
</p>


<h3>Value</h3>

<p>An array with the parameters of the function.
</p>


<h3>See Also</h3>

<p><a href="#topic+coef.motbf">coef.motbf</a> and <a href="#topic+univMoTBF">univMoTBF</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## 1. EXAMPLE
data &lt;- rnorm(1000, mean=5)
fx1 &lt;- univMoTBF(data, POTENTIAL_TYPE = "MTE")
hist(data, prob=TRUE, main="")
plot(fx1, xlim=range(data), col="red", add=TRUE)
coeffMTE(fx1) ## coef(fx1)
coeffExp(fx1)

## 2. EXAMPLE
data &lt;- rexp(1000, rate=1/2)
fx2 &lt;- univMoTBF(data, POTENTIAL_TYPE = "MTE")
hist(data, prob=TRUE, main="")
plot(fx2, xlim=range(data), col="red", add=TRUE)
coeffMTE(fx2) ## coef(fx2)
coeffExp(fx2)
 
</code></pre>

<hr>
<h2 id='coefExpJointCDF'>Degree Function</h2><span id='topic+coefExpJointCDF'></span>

<h3>Description</h3>

<p>Compute the degree for each term of a joint CDF.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coefExpJointCDF(dimensions)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coefExpJointCDF_+3A_dimensions">dimensions</code></td>
<td>
<p>A <code>"numeric"</code> vector including the number of parameters of each variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with n element. Each element contains a <code>numeric</code> vector with the degree for 
each variable and each term of the joint CDF.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Dimension of the joint PDF of 2 variables
dim &lt;- c(4,5) 
## Potentials of each term of the CDF
c &lt;- coefExpJointCDF(dim)
length(c) + 1 ## plus 1 because of the constant coefficient

## Dimension of the joint density function of 2 variables
dim &lt;- c(5,5,3)
## Potentials of the cumulative function
coefExpJointCDF(dim)

</code></pre>

<hr>
<h2 id='conditionalmotbf.learning'>Learning conditional MoTBF densities</h2><span id='topic+conditionalmotbf.learning'></span><span id='topic+conditionalMethod'></span><span id='topic+conditional'></span><span id='topic+select'></span><span id='topic+learn.tree.Intervals'></span><span id='topic+BICscoreMoTBF'></span>

<h3>Description</h3>

<p>Collection of functions used for learning conditional MoTBFs,
computing the internal BIC, selecting the parents that get 
the best BIC value, and other internal functions required to learn the
conditional densities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>conditionalMethod(
  data,
  nameParents,
  nameChild,
  numIntervals,
  POTENTIAL_TYPE,
  maxParam = NULL,
  s = NULL,
  priorData = NULL
)

conditional(
  data,
  nameParents,
  nameChild,
  domainChild,
  domainParents,
  numIntervals,
  mm,
  POTENTIAL_TYPE,
  maxParam = NULL,
  s = NULL,
  priorData = NULL
)

select(
  data,
  nameParents,
  nameChild,
  domainChild,
  domainParents,
  numIntervals,
  POTENTIAL_TYPE,
  maxParam = NULL,
  s = NULL,
  priorData = NULL
)

learn.tree.Intervals(
  data,
  nameParents,
  nameChild,
  domainParents,
  domainChild,
  numIntervals,
  POTENTIAL_TYPE,
  maxParam = NULL,
  s = NULL,
  priorData = NULL
)

BICscoreMoTBF(conditionalfunction, data, nameParents, nameChild)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="conditionalmotbf.learning_+3A_data">data</code></td>
<td>
<p>An object of class <code>"data.frame"</code>.</p>
</td></tr>
<tr><td><code id="conditionalmotbf.learning_+3A_nameparents">nameParents</code></td>
<td>
<p>A <code>"character"</code> vector containing the names of the parent variables.</p>
</td></tr>
<tr><td><code id="conditionalmotbf.learning_+3A_namechild">nameChild</code></td>
<td>
<p>A <code>"character"</code> string containing the name of the child variable.</p>
</td></tr>
<tr><td><code id="conditionalmotbf.learning_+3A_numintervals">numIntervals</code></td>
<td>
<p>A positive integer indicating the maximum number of intervals 
for splitting the domain of the parent variables.</p>
</td></tr>
<tr><td><code id="conditionalmotbf.learning_+3A_potential_type">POTENTIAL_TYPE</code></td>
<td>
<p>A <code>"character"</code> string, either <em>MOP</em> or <em>MTE</em>, corresponding 
to the type of basis function.</p>
</td></tr>
<tr><td><code id="conditionalmotbf.learning_+3A_maxparam">maxParam</code></td>
<td>
<p>A positive integer which indicates the maximum number of coefficients in the 
function. If specified, the output is the function which gets the best BIC with, at most, 
this number of parameters. By default, it is set to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="conditionalmotbf.learning_+3A_s">s</code></td>
<td>
<p>A <code>"numeric"</code> value indicating the expert's confidence in the prior knowledge. 
This argument takes values on the interval <em>[0, N]</em>, where <em>N</em> is the sample size, and is used
to synchronize the support of the prior knowledge and the sample.
By default, it is <code>NULL</code>, and must be modified only if prior information is to be 
incorporated in the learning process.</p>
</td></tr>
<tr><td><code id="conditionalmotbf.learning_+3A_priordata">priorData</code></td>
<td>
<p>An object of class <code>"data.frame"</code>, corresponding to the prior information.</p>
</td></tr>
<tr><td><code id="conditionalmotbf.learning_+3A_domainchild">domainChild</code></td>
<td>
<p>A <code>"numeric"</code> vector with the range of the child variable.</p>
</td></tr>
<tr><td><code id="conditionalmotbf.learning_+3A_domainparents">domainParents</code></td>
<td>
<p>An object of class <code>"matrix"</code> with the range of the parent 
variables, or a <code>"numeric"</code> vector if there is only one parent.</p>
</td></tr>
<tr><td><code id="conditionalmotbf.learning_+3A_mm">mm</code></td>
<td>
<p>One of the inputs and the output of the recursive internal function <code>"conditional"</code>.</p>
</td></tr>
<tr><td><code id="conditionalmotbf.learning_+3A_conditionalfunction">conditionalfunction</code></td>
<td>
<p>The output of the internal function <code>learn.tree.Intervals</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The main function, <code>conditionalMethod()</code>, fits truncated basis functions for the conditioned variable 
for each configuration of splits of the parent variables. The domain of the parent variables is splitted
in different intervals and univariate functions are fitted in these 
ranges. The remaining above described functions are internal to the main function.
</p>


<h3>Value</h3>

<p>The main function <code>conditionalMethod</code> returns a list with the name of the parents, 
the different intervals and the fitted densities
</p>


<h3>See Also</h3>

<p><a href="#topic+printConditional">printConditional</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Dataset
X &lt;- rnorm(1000)
Y &lt;- rbeta(1000, shape1 = abs(X)/2, shape2 = abs(X)/2)
Z &lt;- rnorm(1000, mean = Y)
data &lt;- data.frame(X = X, Y = Y, Z = Z)

## Conditional Method
parents &lt;- c("X","Y")
child &lt;- "Z"
intervals &lt;- 2

potential &lt;- "MTE"
fMTE &lt;- conditionalMethod(data, nameParents = parents, nameChild = child, 
numIntervals = intervals, POTENTIAL_TYPE = potential)
printConditional(fMTE)

##############################################################################

potential &lt;- "MOP"
fMOP &lt;- conditionalMethod(data, nameParents = parents, nameChild = child,
numIntervals = intervals, POTENTIAL_TYPE = potential, maxParam = 15)
printConditional(fMOP)

##############################################################################

##############################################################################
## Internal functions: Not needed to run #####################################
##############################################################################

domainP &lt;- range(data[,parents])
domainC &lt;- range(data[, child])
t &lt;- conditional(data, nameParents = parents, nameChild = child,
domainParents = domainP, domainChild = domainC, numIntervals = intervals,
mm = NULL, POTENTIAL_TYPE = potential)
printConditional(t)
selection &lt;- select(data, nameParents = parents, nameChild = child,
domainParents = domainP, domainChild = domainC, numIntervals = intervals,
POTENTIAL_TYPE = potential)
parent1 &lt;- selection$parent; parent1
domainParent1 &lt;- range(data[,parent1])
treeParent1 &lt;- learn.tree.Intervals(data, nameParents = parent1,
nameChild = child, domainParents = domainParent1, domainChild = domainC,
numIntervals = intervals, POTENTIAL_TYPE = potential)
BICscoreMoTBF(treeParent1, data, nameParents = parent1, nameChild = child)

###############################################################################
###############################################################################
</code></pre>

<hr>
<h2 id='dataMining'>Data pre-processing utilities</h2><span id='topic+dataMining'></span><span id='topic+whichDiscrete'></span><span id='topic+discreteVariables_as.character'></span><span id='topic+standardizeDataset'></span><span id='topic+discretizeVariablesEWdis'></span><span id='topic+discreteVariablesStates'></span><span id='topic+nstates'></span><span id='topic+quantileIntervals'></span><span id='topic+scaleData'></span>

<h3>Description</h3>

<p>Collection of functions for discretizing, standardizing, converting factors to 
characters and other usufull methods for pre-processing datasets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>whichDiscrete(dataset, discreteVariables)

discreteVariables_as.character(dataset, discreteVariables)

standardizeDataset(dataset)

discretizeVariablesEWdis(dataset, numIntervals, factor = FALSE, binary = FALSE)

discreteVariablesStates(namevariables, discreteData)

nstates(DiscreteVariablesStates)

quantileIntervals(X, numIntervals)

scaleData(dataset, scale)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dataMining_+3A_dataset">dataset</code></td>
<td>
<p>A dataset of class <code>"data.frame"</code>. Tha variables of the dataset can be discrete and continuous.</p>
</td></tr>
<tr><td><code id="dataMining_+3A_discretevariables">discreteVariables</code></td>
<td>
<p>A <code>"character"</code> array with the names of the discrete variables.</p>
</td></tr>
<tr><td><code id="dataMining_+3A_numintervals">numIntervals</code></td>
<td>
<p>Number of bins used to discretize the continuous variables.</p>
</td></tr>
<tr><td><code id="dataMining_+3A_factor">factor</code></td>
<td>
<p>A boolean value indicating if the variables should be considered as
<code>"factor"</code> or as <code>"character"</code>. By default it is set to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="dataMining_+3A_binary">binary</code></td>
<td>
<p>By default it is set to <code>FALSE</code>, indicating that only binary entries are 
used for continuous variables; a <code>TRUE</code> value means that binary entries are used to 
discretize the full dataset taking into account the states the discrete variables.</p>
</td></tr>
<tr><td><code id="dataMining_+3A_namevariables">namevariables</code></td>
<td>
<p>an array with the names of the varibles.</p>
</td></tr>
<tr><td><code id="dataMining_+3A_discretedata">discreteData</code></td>
<td>
<p>A discretized dataset of class <code>"data.frame"</code>.</p>
</td></tr>
<tr><td><code id="dataMining_+3A_discretevariablesstates">DiscreteVariablesStates</code></td>
<td>
<p>The output of the function <code>discreteVariablesStates</code>.</p>
</td></tr>
<tr><td><code id="dataMining_+3A_x">X</code></td>
<td>
<p>A <code>"numeric"</code> vector with the data values of a continuous variable.</p>
</td></tr>
<tr><td><code id="dataMining_+3A_scale">scale</code></td>
<td>
<p>A <code>"numeric"</code> vector (when it refers to a single variable) or a <code>"list"</code> 
containing the name(s) of the variable(s) and the scale value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>whichDiscrete()</code> selects the position of the discrete variables.
</p>
<p><code>discreteVariables_as.character()</code> transforms the values of the discrete variables into character values.
</p>
<p><code>standardizeDataset()</code> standardizes all the variables in a data set.
</p>
<p><code>discretizeVariablesEWdis()</code> discretizes the continuous variables in a dataset using 
equal width binning.
</p>
<p><code>discreteVariablesStates()</code> extracts the states of the qualitative variables.
</p>
<p><code>nstates()</code> computes the number of different values of the discrete variables.
</p>
<p><code>quantileIntervals()</code> gets the quantiles of a variable taking into account the number of intervals
into which its domain is splitted.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## dataset: 2 continuous variables, 1 discrete variable.
data &lt;- data.frame(X = rnorm(100),Y = rexp(100,1/2), Z = as.factor(rep(c("s","a"), 50)))
disVar &lt;- "Z" ## Discrete variable
class(data[,disVar]) ## factor

data &lt;- discreteVariables_as.character(dataset = data, discreteVariables = disVar)
class(data[,disVar]) ## character

whichDiscrete(dataset = data, discreteVariables = "Z")

standData &lt;- standardizeDataset(dataset = data)

disData &lt;- discretizeVariablesEWdis(dataset = data, numIntervals = 3)

l &lt;- discreteVariablesStates(namevariables = names(data), discreteData = disData)

nstates(DiscreteVariablesStates = l)

## Continuous variables
quantileIntervals(X = data[,1], numIntervals = 4)
quantileIntervals(X = data[,2], numIntervals = 10)
</code></pre>

<hr>
<h2 id='derivMOP'>Derivative of a MOP</h2><span id='topic+derivMOP'></span>

<h3>Description</h3>

<p>Compute the derivative of an <code>"motbf"</code> object with <code>'mop'</code> subclass.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>derivMOP(fx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="derivMOP_+3A_fx">fx</code></td>
<td>
<p>An <code>"motbf"</code> object of the <code>'mop'</code> subclass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The derivative which is also an <code>"motbf"</code> function.
</p>


<h3>See Also</h3>

<p><a href="#topic+univMoTBF">univMoTBF</a> for learning and <a href="#topic+derivMoTBF">derivMoTBF</a> for 
general <code>"motbf"</code> models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## 1. EXAMPLE
X &lt;- rexp(1000)
Px &lt;- univMoTBF(X, POTENTIAL_TYPE="MOP")
derivMOP(Px)

## 2. EXAMPLE
X &lt;- rnorm(1000)
Px &lt;- univMoTBF(X, POTENTIAL_TYPE="MOP")
derivMOP(Px)

## Not run: 
## 3. EXAMPLE
X &lt;- rnorm(1000)
Px &lt;- univMoTBF(X, POTENTIAL_TYPE="MTE")
derivMOP(Px)
## Error in derivMOP(Px): fx is an 'motbf' function but not 'mop' subclass.
class(Px)
subclass(Px)

## End(Not run)
</code></pre>

<hr>
<h2 id='derivMoTBF'>Derivating MoTBFs</h2><span id='topic+derivMoTBF'></span>

<h3>Description</h3>

<p>Compute the derivative of a one-dimensional mixture of truncated basis function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>derivMoTBF(fx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="derivMoTBF_+3A_fx">fx</code></td>
<td>
<p>An object of class <code>"motbf"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The derivative of the MoTBF function, which is also 
an object of class <code>"motbf"</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+univMoTBF">univMoTBF</a>, <a href="#topic+derivMOP">derivMOP</a> and <a href="#topic+derivMTE">derivMTE</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## 1. EXAMPLE
X &lt;- rexp(1000)
Px &lt;- univMoTBF(X, POTENTIAL_TYPE="MOP")
derivMoTBF(Px)

## 2. EXAMPLE
X &lt;- rnorm(1000)
Px &lt;- univMoTBF(X, POTENTIAL_TYPE="MOP")
derivMoTBF(Px)

## 3. EXAMPLE
X &lt;- rchisq(1000, df = 3)
Px &lt;- univMoTBF(X, POTENTIAL_TYPE="MTE")
derivMoTBF(Px)

## Not run: 
## 4. EXAMPLE
Px &lt;- "x+2"
class(Px)
derivMoTBF(Px)
## Error in derivMoTBF(Px): "fx is not an 'motbf' function."

## End(Not run)
</code></pre>

<hr>
<h2 id='derivMTE'>Derivating MTEs</h2><span id='topic+derivMTE'></span>

<h3>Description</h3>

<p>Compute the derivative of an <code>"motbf"</code> object with <code>'mte'</code> subclass.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>derivMTE(fx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="derivMTE_+3A_fx">fx</code></td>
<td>
<p>An <code>"motbf"</code> object of the <code>'mte'</code> subclass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The derivative which is also an <code>"motbf"</code> function.
</p>


<h3>See Also</h3>

<p><a href="#topic+univMoTBF">univMoTBF</a> for learning and <a href="#topic+derivMoTBF">derivMoTBF</a> for 
general <code>"motbf"</code> models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## 1. EXAMPLE
X &lt;- rexp(1000)
Px &lt;- univMoTBF(X, POTENTIAL_TYPE="MTE")
derivMTE(Px)

## 2. EXAMPLE
X &lt;- rnorm(1000)
Px &lt;- univMoTBF(X, POTENTIAL_TYPE="MTE")
derivMTE(Px)

## Not run: 
## 3. EXAMPLE
X &lt;- rnorm(1000)
Px &lt;- univMoTBF(X, POTENTIAL_TYPE="MOP")
derivMTE(Px)
## Error in derivMTE(Px): fx is an 'motbf' function but not 'mte' subclass.
class(Px)
subclass(Px)

## End(Not run)
</code></pre>

<hr>
<h2 id='dimensionFunction'>Dimension of MoTBFs</h2><span id='topic+dimensionFunction'></span>

<h3>Description</h3>

<p>Get the dimension of <code>"motbf"</code> and <code>"jointmotbf"</code> densities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dimensionFunction(P)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dimensionFunction_+3A_p">P</code></td>
<td>
<p>An object of class <code>"motbf"</code> and subclass 'mop' or <code>"jointmotbf"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Dimension of the function.
</p>


<h3>See Also</h3>

<p><a href="#topic+univMoTBF">univMoTBF</a> and <a href="#topic+jointMoTBF">jointMoTBF</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 1. EXAMPLE 
## Data
X &lt;- rnorm(2000)

## Univariate function
subclass &lt;- "MOP"
f &lt;- univMoTBF(X, POTENTIAL_TYPE = subclass)
dimensionFunction(f)

## 2. EXAMPLE 
## Dataset with 2 variables
X &lt;- data.frame(rnorm(100), rnorm(100))

## Joint function
dim &lt;- c(2,3)
param &lt;- parametersJointMoTBF(X, dimensions = dim)
P &lt;- jointMoTBF(param)

## Dimension of the joint function
dimensionFunction(P)

</code></pre>

<hr>
<h2 id='discreteStatesFromBN'>Get the states of all discrete nodes from a MoTFB-BN</h2><span id='topic+discreteStatesFromBN'></span>

<h3>Description</h3>

<p>This function returns the states of all discrete nodes from a list obtained from <a href="#topic+MoTBFs_Learning">MoTBFs_Learning</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>discreteStatesFromBN(bn, dag)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="discreteStatesFromBN_+3A_bn">bn</code></td>
<td>
<p>A list of lists obtained from <a href="#topic+MoTBFs_Learning">MoTBFs_Learning</a>.</p>
</td></tr>
<tr><td><code id="discreteStatesFromBN_+3A_dag">dag</code></td>
<td>
<p>A network of class <code>"bn"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>discreteStatesFromBN</code> returns a list of length equal to the number of discrete nodes in the network. Each element of the list corresponds to a node and contains a character vector indicating the states of the node.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Create a dataset
  # Continuous variables
  x &lt;- rnorm(100)
  y &lt;- rnorm(100)
  
  # Discrete variable
  z &lt;- sample(letters[1:2],size = 100, replace = TRUE)
  
  data &lt;- data.frame(C1 = x, C2 = y, D1 = z, stringsAsFactors = FALSE)
  
## Get DAG
  dag &lt;- LearningHC(data)

## Learn a BN
  bn &lt;- MoTBFs_Learning(dag, data, POTENTIAL_TYPE = "MTE")

## Get the states of the discrete nodes

  discreteStatesFromBN(bn, dag)
</code></pre>

<hr>
<h2 id='ecoli'>Data set Ecoli: Protein Localization Sites</h2><span id='topic+ecoli'></span>

<h3>Description</h3>

<p>This data set contains information of Escherichia coli. It is a 
bacterium of the genus Escherichia that is commonly found in the 
lower intestine of warm-blooded organism.
</p>


<h3>Format</h3>

<p>A data frame with 336 rows, 8 variables and the class.
</p>


<h3>Details</h3>


<dl>
<dt>Sequence Name</dt><dd><p>Accession number for the SWISS-PROT database.</p>
</dd>
<dt>mcg</dt><dd><p>McGeoch's method for signal sequence recognition.</p>
</dd> 
<dt>gvh</dt><dd><p>Von Heijne's method for signal sequence recognition.</p>
</dd> 
<dt>lip</dt><dd><p>Von Heijne's Signal Peptidase II consensus sequence score. Binary attribute.</p>
</dd>
<dt>chg</dt><dd><p>Presence of charge on N-terminus of predicted lipoproteins. Binary attribute.</p>
</dd>
<dt>aac</dt><dd><p>Score of discriminant analysis of the amino acid content of outer membrane and periplasmic proteins.</p>
</dd>
<dt>alm1</dt><dd><p>Score of the ALOM membrane spanning region prediction program.</p>
</dd>
<dt>alm2</dt><dd><p>Score of ALOM program after excluding putative cleavable signal regions from the sequence.</p>
</dd>
<dt>Class</dt><dd><p>Class variable. 8 possibles states.</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="http://archive.ics.uci.edu/ml/datasets/Ecoli">http://archive.ics.uci.edu/ml/datasets/Ecoli</a>
</p>

<hr>
<h2 id='evalJointFunction'>Evaluation of joint MoTBFs</h2><span id='topic+evalJointFunction'></span>

<h3>Description</h3>

<p>Evaluates a <code>"jointmotbf"</code> object at a specific point.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evalJointFunction(P, values)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evalJointFunction_+3A_p">P</code></td>
<td>
<p>A <code>"jointmotbf"</code> object.</p>
</td></tr>
<tr><td><code id="evalJointFunction_+3A_values">values</code></td>
<td>
<p>A list with the name of the variables equal to the values to be evaluated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If all the variables in the equation are evaluated then a <code>"numeric"</code> value
is returned. Otherwise, an <code>"motbf"</code> object or a <code>"jointmotbf"</code> object is returned.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#' ## 1. EXAMPLE
## Dataset with 2 variables
X &lt;- data.frame(rnorm(100), rexp(100))

## Joint function
dim &lt;- c(3,3) # dim &lt;- c(5,4)
param &lt;- parametersJointMoTBF(X, dimensions = dim)
P &lt;- jointMoTBF(param)
P

## Evaluation
nVariables(P)
val &lt;- list(x = -1.5, y = 3)
evalJointFunction(P, values = val)
val &lt;- list(x = -1.5)
evalJointFunction(P, values = val)
val &lt;- list(y = 3)
evalJointFunction(P, values = val)

##############################################################################
## MORE EXAMPLES #############################################################
############################################################################## 

## Dataset with 3 variables
X &lt;- data.frame(rnorm(100), rexp(100), rnorm(100, 1))

## Joint function
dim &lt;- c(2,1,3)
param &lt;- parametersJointMoTBF(X, dimensions = dim)
P &lt;- jointMoTBF(param)
P

## Evaluation
nVariables(P)
val &lt;- list(x = 0.8, y = -2.1, z = 1.2)
evalJointFunction(P, values = val)
val &lt;- list(x = 0.8, z = 1.2)
evalJointFunction(P, values = val)
val &lt;- list(y = -2.1)
evalJointFunction(P, values = val)
val &lt;- list(y = -2.1)
evalJointFunction(P, values = val)

</code></pre>

<hr>
<h2 id='findConditional'>Find fitted conditional MoTBFs</h2><span id='topic+findConditional'></span>

<h3>Description</h3>

<p>This function returns the conditional probability function of a node given an MoTBF-bayesian network and the value of its parents.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findConditional(node, bn, evi = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findConditional_+3A_node">node</code></td>
<td>
<p>A <code>character</code> string, representing the tardet variable.</p>
</td></tr>
<tr><td><code id="findConditional_+3A_bn">bn</code></td>
<td>
<p>A list of lists obtained from <a href="#topic+MoTBFs_Learning">MoTBFs_Learning</a>, containing the conditional functions.</p>
</td></tr>
<tr><td><code id="findConditional_+3A_evi">evi</code></td>
<td>
<p>A <code>data.frame</code> of dimension '1xn' that contains the values of the 'n' parents of the target node. 
This argument can be <code>NULL</code> if <code>"node"</code> is a root node.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the conditional distribution of the target variable.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Dataset
  data("ecoli", package = "MoTBFs")
  data &lt;- ecoli[,-c(1,9)]

## Get directed acyclic graph
  dag &lt;- LearningHC(data)
  
## Learn bayesian network
  bn &lt;- MoTBFs_Learning(dag, data = data, numIntervals = 4, POTENTIAL_TYPE = "MTE")
  
## Specify the evidence set and node of interest
  evi &lt;- data.frame(lip = "0.48", alm1 = 0.55, gvh = 1, stringsAsFactors=FALSE)
  node = "alm2"
  
## Get the conditional distribution
  findConditional(node, bn, evi)

</code></pre>

<hr>
<h2 id='forward_sampling'>Forward Sampling</h2><span id='topic+forward_sampling'></span>

<h3>Description</h3>

<p><code>forward_sampling()</code> returns the conditional distribution of a target variable given a set of oberved variables.
The forward sampling algorithm approximates the conditional distribution from a random sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forward_sampling(bn, dag, target, evi, size, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="forward_sampling_+3A_bn">bn</code></td>
<td>
<p>A list of lists obtained from the function <a href="#topic+MoTBFs_Learning">MoTBFs_Learning</a>.</p>
</td></tr>
<tr><td><code id="forward_sampling_+3A_dag">dag</code></td>
<td>
<p>An object of class <code>"bn"</code>, representing the directed acyclic graph.</p>
</td></tr>
<tr><td><code id="forward_sampling_+3A_target">target</code></td>
<td>
<p>A character string equal to the name of the variable of interest.</p>
</td></tr>
<tr><td><code id="forward_sampling_+3A_evi">evi</code></td>
<td>
<p>A <code>data.frame</code> containing the observed variables.</p>
</td></tr>
<tr><td><code id="forward_sampling_+3A_size">size</code></td>
<td>
<p>A positive integer giving the number of instances to be generated.</p>
</td></tr>
<tr><td><code id="forward_sampling_+3A_...">...</code></td>
<td>
<p>Optional arguments passed on to the <code><a href="#topic+univMoTBF">univMoTBF</a></code> function. <code>evalRange</code>, <code>nparam</code> and <code>maxParam</code> can be specified. <code>POTENTIAL_TYPE</code> is taken from the 'bn' object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the conditional distribution of the target variable and a data.frame with the generated sample.
</p>


<h3>References</h3>

<p>Henrion, M. (1988). Propagating uncertainty in Bayesian networks by probabilistic logic sampling. In Machine Intelligence and Pattern Recognition (Vol. 5, pp. 149-163). North-Holland.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Dataset
  data("ecoli", package = "MoTBFs")
  data &lt;- ecoli[,-c(1,9)]

## Get directed acyclic graph
  dag &lt;- LearningHC(data)
  
## Learn bayesian network
  bn &lt;- MoTBFs_Learning(dag, data = data, numIntervals = 4, POTENTIAL_TYPE = "MTE")
  
## Specify the evidence set and target variable
  obs &lt;- data.frame(lip = "0.48", alm1 = 0.55, gvh = 1, stringsAsFactors=FALSE)
  node &lt;- "alm2"
  
## Get the conditional distribution of 'node' and the generated sample
  forward_sampling(bn, dag, target = node, evi = obs, size = 10, maxParam = 15)
  
</code></pre>

<hr>
<h2 id='generateNormalPriorData'>Prior data generation</h2><span id='topic+generateNormalPriorData'></span>

<h3>Description</h3>

<p>Generate a prior dataset taking in to account the relationships
between the varibles in a given network.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateNormalPriorData(graph, data, size, means, deviations = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generateNormalPriorData_+3A_graph">graph</code></td>
<td>
<p>A network of the class <code>"bn"</code>, <code>"graphNEL"</code> or <code>"network"</code>.</p>
</td></tr>
<tr><td><code id="generateNormalPriorData_+3A_data">data</code></td>
<td>
<p>An object of class <code>"data.frame"</code> containing the continuous variables in the dataset.</p>
</td></tr>
<tr><td><code id="generateNormalPriorData_+3A_size">size</code></td>
<td>
<p>A positive integer indicating the number of records to generate for each variable in the dataset.</p>
</td></tr>
<tr><td><code id="generateNormalPriorData_+3A_means">means</code></td>
<td>
<p>A <code>"numeric"</code> vector with the average of the variables whose prior information is available. 
The names in the vector must be the same as the names of the variables in the data.frame.</p>
</td></tr>
<tr><td><code id="generateNormalPriorData_+3A_deviations">deviations</code></td>
<td>
<p>A <code>"numeric"</code> vector with the standard deviations of the variables whose prior information is available. 
The names of the vector must be the same as the names of the variables in the data.frame. 
If not specified, the standard deviation of each variable is computed from 'data'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A normal prior data set of class <code>"data.frame"</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+rnormMultiv">rnormMultiv</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Data
data(ecoli)
data &lt;- ecoli[,-c(1,9)] ## remove sequece.name and class
X &lt;- TrainingandTestData(data, percentage_test = 0.95)
Xtraining &lt;- X$Training
Xtest &lt;- X$Test

## DAG
dag &lt;- LearningHC(data)
plot(dag)

## Means and desviations
colnames(data)

m &lt;- sapply(data, function(x){ifelse(is.numeric(x), mean(x),NA)})
d &lt;- sapply(data, function(x){ifelse(is.numeric(x), sd(x),NA)})


## Prior Dataset
n &lt;- 5600
priorData &lt;- generateNormalPriorData(dag, data = Xtraining, size = n, means = m)
summary(priorData)
ncol(priorData)
nrow(priorData)
class(priorData)

</code></pre>

<hr>
<h2 id='getChildParentsFromGraph'>Get the list of relations in a graph</h2><span id='topic+getChildParentsFromGraph'></span>

<h3>Description</h3>

<p>Compute the parents of each variable in the graph.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getChildParentsFromGraph(graph, nameVars = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getChildParentsFromGraph_+3A_graph">graph</code></td>
<td>
<p>A directed acyclic graph of the class <code>"graphNEL"</code>,
<code>"network"</code> or <code>"bn"</code>.</p>
</td></tr>
<tr><td><code id="getChildParentsFromGraph_+3A_namevars">nameVars</code></td>
<td>
<p>A character array containing the names of the variables in the graph. 
This parameter is only used when <code>graph</code> is of class <code>"network"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list where each element is a vector containing the name of a variable 
and its parents in the graph.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Data
data(ecoli)
ecoli &lt;- ecoli[,-1] ## Sequence Name

## DAG1
dag1 &lt;- LearningHC(ecoli)
dag1
plot(dag1)
getChildParentsFromGraph(dag1)

## DAG2
dag2 &lt;- LearningHC(ecoli, numIntervals = 10)
dag2
plot(dag2)
getChildParentsFromGraph(dag2)

</code></pre>

<hr>
<h2 id='getCoefficients'>Get the coefficients</h2><span id='topic+getCoefficients'></span>

<h3>Description</h3>

<p>Compute the coefficients for the linear opinion pool
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getCoefficients(fPI, rangeNewPriorData, fD, data, domain, coeffversion)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getCoefficients_+3A_fpi">fPI</code></td>
<td>
<p>The function fitted to the prior data, of class <code>"motbf"</code>.</p>
</td></tr>
<tr><td><code id="getCoefficients_+3A_rangenewpriordata">rangeNewPriorData</code></td>
<td>
<p>An array of length 2 with the new domain of the prior function.</p>
</td></tr>
<tr><td><code id="getCoefficients_+3A_fd">fD</code></td>
<td>
<p>The function fitted to the original data, of class <code>"motbf"</code>.</p>
</td></tr>
<tr><td><code id="getCoefficients_+3A_data">data</code></td>
<td>
<p>A <code>"numeric"</code> array which contains the sample.</p>
</td></tr>
<tr><td><code id="getCoefficients_+3A_domain">domain</code></td>
<td>
<p>A <code>"numeric"</code> array with the domain of the data density function.</p>
</td></tr>
<tr><td><code id="getCoefficients_+3A_coeffversion">coeffversion</code></td>
<td>
<p>A <code>"numeric"</code> value between <code>1--4</code> which contains the used version for computing the coefficients in the linear 
opinion pool to combine the prior function and the data function. By default <code>coeffversion = "4"</code> is used, so the combination
depends on the goodness of the model versus another random positive MoTBF model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>coeffversion</code> can be:
<code>"1"</code> coef1 and coef2 are the sum of the probabilities of one of the function over the sum of all probabilities, respectively;
<code>"2"</code> coef1 and coef2 are the solution of a linear optimization problem which tries to maximize the sum 1 for each row of probabilities;
<code>"3"</code> coef1 and coef2 are the difference of the log-likelihood of the evaluated model and a random uniform model over the sum of both differences, respectively;
<code>"4"</code> coef1 and coef2 are the difference of the log-likelihood of the evaluated model and a ramdom positive MoTBF model over the sum of both differences, respectively.
</p>


<h3>Value</h3>

<p>A <code>"numeric"</code> value of length 2 giving the coefficients which are the weigth of the two function to combine.
</p>


<h3>See Also</h3>

<p><a href="#topic+learnMoTBFpriorInformation">learnMoTBFpriorInformation</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Data
X &lt;- rnorm(15)

## Prior Data
priordata &lt;- rnorm(5000)

## Learning
confident &lt;- 5
type &lt;- "MOP"
f &lt;- learnMoTBFpriorInformation(priorData = priordata, data = X, s = confident,
POTENTIAL_TYPE = type)
attributes(f)
 
## Coefficients: linear opinion pool
getCoefficients(fPI = f$priorFunction, rangeNewPriorData = f$domain, fD = f$dataFunction, 
data = X, domain = range(X), coeffversion = 4)

getCoefficients(fPI = f$priorFunction, rangeNewPriorData = f$domain, fD = f$dataFunction, 
data = X, domain = range(X), coeffversion = 1)

getCoefficients(fPI = f$priorFunction, rangeNewPriorData = f$domain, fD = f$dataFunction, 
data = X, domain = range(X), coeffversion = 3)

getCoefficients(fPI = f$priorFunction, rangeNewPriorData = f$domain, fD = f$dataFunction, 
data = X, domain = range(X), coeffversion = 2)

</code></pre>

<hr>
<h2 id='getNonNormalisedRandomMoTBF'>Ramdom MoTBF</h2><span id='topic+getNonNormalisedRandomMoTBF'></span>

<h3>Description</h3>

<p>Generates a non normalized (i.e. not integrating to 1) positive MoTBF function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getNonNormalisedRandomMoTBF(degree, POTENTIAL_TYPE = "MOP")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getNonNormalisedRandomMoTBF_+3A_degree">degree</code></td>
<td>
<p>A <code>"numeric"</code> value containing the degree of the random function.</p>
</td></tr>
<tr><td><code id="getNonNormalisedRandomMoTBF_+3A_potential_type">POTENTIAL_TYPE</code></td>
<td>
<p>A <code>"character"</code> string specifying the posibles potential
types, must be one of <code>"MOP"</code> or <code>"MTE"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>"numeric"</code> vector of length 2 giving the coefficients.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
getNonNormalisedRandomMoTBF(8, POTENTIAL_TYPE = "MOP")
getNonNormalisedRandomMoTBF(11, POTENTIAL_TYPE = "MTE")

</code></pre>

<hr>
<h2 id='goodnessDiscreteVariables'>BIC scxore and log-likelihood</h2><span id='topic+goodnessDiscreteVariables'></span><span id='topic+getlogLikelihoodDiscreteBN'></span><span id='topic+getBICDiscreteBN'></span>

<h3>Description</h3>

<p>Compute the loglikelihood and the BIC score for discrete models, i.e multinomial Bayesian Networks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getlogLikelihoodDiscreteBN(discreteBN)

getBICDiscreteBN(discreteBN, sameData = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="goodnessDiscreteVariables_+3A_discretebn">discreteBN</code></td>
<td>
<p>A list of multiples lists. Each list contains two entries,
the probabilities and the size of the data which is in each leaf of the discrete tree.</p>
</td></tr>
<tr><td><code id="goodnessDiscreteVariables_+3A_samedata">sameData</code></td>
<td>
<p>A logical argument; <code>FALSE</code> means that different datasets were used for learning.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The loglikelihood and the BIC score of the discrete network.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 1. EXAMPLE 
## Discrete data
X &lt;- rep(c("yes", "no", "maybe"), 500)
Y &lt;- rep(c("M", "F"), 750)
data &lt;- data.frame(X=X, Y=Y)
disVar &lt;- c("X","Y")
data &lt;- discreteVariables_as.character(data, discreteVariables=disVar)
n &lt;- nrow(data)

## Probabilities
s &lt;- discreteVariablesStates(namevariables=disVar, discreteData=data)
p &lt;- lapply(1:length(s), function(i) probDiscreteVariable(stateNames=
s[[i]]$states, Variable=data[,i]))

## Log-likelihood
getlogLikelihoodDiscreteBN(p)

## BIC
getBICDiscreteBN(p, sameData = TRUE)

## 2. EXAMPLE 
## Discrete variables
X &lt;- rep(c("1", "2", "3"), 500)
data &lt;- data.frame(X=as.character(X))
s &lt;- discreteVariablesStates(namevariables="X", discreteData=data)
p1 &lt;- probDiscreteVariable(stateNames = s[[1]]$states, Variable = data[,1])

Y &lt;- rep(c("YES", "NO"), 100)
data &lt;- data.frame(Y = as.character(Y))
s &lt;- discreteVariablesStates(namevariables = "Y", discreteData = data)
p2 &lt;- probDiscreteVariable(stateNames = s[[1]]$states, Variable = data[,1])
## Probabilities
P &lt;- list(p1,p2)

## Log-likelihood
getlogLikelihoodDiscreteBN(P)

## BIC
getBICDiscreteBN(P, sameData = TRUE)
</code></pre>

<hr>
<h2 id='goodnessMoTBFBN'>BIC of a hybrid BN</h2><span id='topic+goodnessMoTBFBN'></span><span id='topic+logLikelihood.MoTBFBN'></span><span id='topic+BiC.MoTBFBN'></span>

<h3>Description</h3>

<p>Compute the BIC score and the loglikelihood from the fitted MoTBFs functions 
in a hybrid Bayesian network.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logLikelihood.MoTBFBN(MoTBF.BN, data)

BiC.MoTBFBN(MoTBF.BN, data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="goodnessMoTBFBN_+3A_motbf.bn">MoTBF.BN</code></td>
<td>
<p>The output of the 'MoTBF_Learning' method.</p>
</td></tr>
<tr><td><code id="goodnessMoTBFBN_+3A_data">data</code></td>
<td>
<p>The dataset of class <code>data.frame</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value giving the log-likelihood of the BN.
</p>


<h3>See Also</h3>

<p><a href="#topic+MoTBFs_Learning">MoTBFs_Learning</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Dataset Ecoli
require(MoTBFs)
data(ecoli)
data &lt;- ecoli[,-c(1)] ## remove variable sequence

## Directed acyclic graph
dag &lt;- LearningHC(data)

## Learning BN
intervals &lt;- 3
potential &lt;- "MOP"
P1 &lt;- MoTBFs_Learning(graph = dag, data = data, POTENTIAL_TYPE=potential,
numIntervals = intervals, maxParam = 5)
logLikelihood.MoTBFBN(P1, data) ##BIC$LogLikelihood
BIC &lt;- BiC.MoTBFBN(P1, data)
BIC$BIC

## Learning BN
intervals &lt;- 2
potential &lt;- "MTE"
P2 &lt;- MoTBFs_Learning(graph = dag, data = data, POTENTIAL_TYPE=potential,
numIntervals = intervals, maxParam = 10)
logLikelihood.MoTBFBN(P2, data) ##BIC$LogLikelihood
BIC &lt;- BiC.MoTBFBN(P2, data)
BIC$BIC 
</code></pre>

<hr>
<h2 id='integralJointMoTBF'>Integration with MoTBFs</h2><span id='topic+integralJointMoTBF'></span>

<h3>Description</h3>

<p>Integrate a <code>"jointmotbf"</code> object over an non defined domain. It is able to
get the integral of a joint function over a set of variables or over all
the variables in the function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>integralJointMoTBF(P, var = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="integralJointMoTBF_+3A_p">P</code></td>
<td>
<p>A <code>"jointmotbf"</code> object.</p>
</td></tr>
<tr><td><code id="integralJointMoTBF_+3A_var">var</code></td>
<td>
<p>A <code>"character"</code> vector containing the name of the variables that will be integrated out.
Instead of the names, the position of the variables can be given.
By default it's <code>NULL</code> then all the variables are integrated out.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A multiintegral of a joint function of class <code>"jointmotbf"</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 1. EXAMPLE
## Dataset with 2 variables
X &lt;- data.frame(rnorm(100), rnorm(100))

## Joint function
dim &lt;- c(2,3)
param &lt;- parametersJointMoTBF(X, dimensions = dim)
P &lt;- jointMoTBF(param)

## Integral
integralJointMoTBF(P)
integralJointMoTBF(P, var="x")
integralJointMoTBF(P, var="y")

##############################################################################
## MORE EXAMPLES #############################################################
##############################################################################

## Dataset with 3 variables
X &lt;- data.frame(rnorm(50), rnorm(50), rnorm(50))

## Joint function
dim &lt;- c(2,1,3)
param &lt;- parametersJointMoTBF(X, dimensions = dim)
P &lt;- jointMoTBF(param)
 
## Integral
integralJointMoTBF(P)
integralJointMoTBF(P, var="x")
integralJointMoTBF(P, var="y")
integralJointMoTBF(P, var="z")
integralJointMoTBF(P, var=c("x","z"))

</code></pre>

<hr>
<h2 id='integralMOP'>Integration of MOPs</h2><span id='topic+integralMOP'></span>

<h3>Description</h3>

<p>Method to calculate the non-defined integral of an <code>"motbf"</code> object of <code>'mte'</code> subclass.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>integralMOP(fx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="integralMOP_+3A_fx">fx</code></td>
<td>
<p>An <code>"motbf"</code> object of subclass <code>'mop'</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The non-defined integral of the function.
</p>


<h3>See Also</h3>

<p><a href="#topic+univMoTBF">univMoTBF</a> for learning and <a href="#topic+integralMoTBF">integralMoTBF</a> 
for a more complete function to get defined and non-defined integrals
of class <code>"motbf"</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## 1. EXAMPLE
X &lt;- rexp(1000)
Px &lt;- univMoTBF(X, POTENTIAL_TYPE="MOP")
integralMOP(Px)

## 2. EXAMPLE
X &lt;- rnorm(1000)
Px &lt;- univMoTBF(X, POTENTIAL_TYPE="MOP")
integralMOP(Px)

## Not run: 
## 3. EXAMPLE
X &lt;- rnorm(1000)
Px &lt;- univMoTBF(X, POTENTIAL_TYPE="MTE")
integralMOP(Px)
## Error in integralMOP(Px): fx is an 'motbf' function but not 'mop' subclass.
class(Px)
subclass(Px)

## End(Not run)
</code></pre>

<hr>
<h2 id='integralMoTBF'>Integrating MoTBFs</h2><span id='topic+integralMoTBF'></span>

<h3>Description</h3>

<p>Compute the integral of a one-dimensional mixture of truncated basis function 
over a bounded or unbounded interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>integralMoTBF(fx, min = NULL, max = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="integralMoTBF_+3A_fx">fx</code></td>
<td>
<p>An object of class <code>"motbf"</code>.</p>
</td></tr>
<tr><td><code id="integralMoTBF_+3A_min">min</code></td>
<td>
<p>The lower integration limit. By default it is NULL.</p>
</td></tr>
<tr><td><code id="integralMoTBF_+3A_max">max</code></td>
<td>
<p>The upper integration limit. By default it is NULL.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the limits of the interval, min and max are NULL, then the output is
the expression of the indefinite integral. If only 'min' contains a numeric value,
then the expression of the integral is evaluated at this point.
</p>


<h3>Value</h3>

<p><code>integralMoTBF()</code> returns either the indefinite integral of the MoTBF 
function, which is also an object of class <code>"motbf"</code>, or the definite integral, 
wich is a <code>"numeric"</code> value.
</p>


<h3>See Also</h3>

<p><a href="#topic+univMoTBF">univMoTBF</a>, <a href="#topic+integralMOP">integralMOP</a> and <a href="#topic+integralMTE">integralMTE</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## 1. EXAMPLE
X &lt;- rexp(1000)
Px &lt;- univMoTBF(X, POTENTIAL_TYPE="MOP")
integralMoTBF(Px)
integralMoTBF(Px, 1.2)
integralMoTBF(Px, min(X), max(X))

## 2. EXAMPLE
X &lt;- rnorm(1000)
Px &lt;- univMoTBF(X, POTENTIAL_TYPE="MOP")
iP &lt;- integralMoTBF(Px); iP
plot(iP, xlim=range(X))
integralMoTBF(Px, 0.2)
integralMoTBF(Px, min(X), max(X))

## 3. EXAMPLE
X &lt;- rchisq(1000, df = 3)
Px &lt;- univMoTBF(X, POTENTIAL_TYPE="MTE")
integralMoTBF(Px)
integralMoTBF(Px, 1)
integralMoTBF(Px, min(X), max(X))

## Not run: 
## 4. EXAMPLE
Px &lt;- "1+x+5"
class(Px)
integralMoTBF(Px)
## Error in integralMoTBF(Px): "fx is not an 'motbf' function."

## End(Not run)
</code></pre>

<hr>
<h2 id='integralMTE'>Integrating MTEs</h2><span id='topic+integralMTE'></span>

<h3>Description</h3>

<p>Method to calculate the non-defined integral of an <code>"motbf"</code> object of <code>'mte'</code> 
subclass.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>integralMTE(fx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="integralMTE_+3A_fx">fx</code></td>
<td>
<p>An <code>"motbf"</code> object of subclass <code>'mte'</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The non-defined integral of the function.
</p>


<h3>See Also</h3>

<p><a href="#topic+univMoTBF">univMoTBF</a> for learning and <a href="#topic+integralMoTBF">integralMoTBF</a> 
for a more complete function to get defined and non-defined integrals
of class <code>"motbf"</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## 1. EXAMPLE
X &lt;- rexp(1000)
Px &lt;- univMoTBF(X, POTENTIAL_TYPE="MTE")
integralMTE(Px)

## 2. EXAMPLE
X &lt;- rnorm(1000)
Px &lt;- univMoTBF(X, POTENTIAL_TYPE="MTE")
integralMTE(Px)

## Not run: 
## 3. EXAMPLE
X &lt;- rnorm(1000)
Px &lt;- univMoTBF(X, POTENTIAL_TYPE="MOP")
integralMTE(Px)
## Error in integralMTE(Px): fx is an 'motbf' function but not 'mte' subclass.
class(Px)
subclass(Px)

## End(Not run)
</code></pre>

<hr>
<h2 id='is.discrete'>Check discreteness of a node</h2><span id='topic+is.discrete'></span>

<h3>Description</h3>

<p>This function allows to check whether a node is discrete or not
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.discrete(node, bn)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.discrete_+3A_node">node</code></td>
<td>
<p>A character (name of node) or numeric (index of node in the bn list) input.</p>
</td></tr>
<tr><td><code id="is.discrete_+3A_bn">bn</code></td>
<td>
<p>A list of lists obtained from <a href="#topic+MoTBFs_Learning">MoTBFs_Learning</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>is.discrete</code> returns <code>TRUE</code> or <code>FALSE</code> depending on whether the node is discrete or not.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 

## Create a dataset
  # Continuous variables
  x &lt;- rnorm(100)
  y &lt;- rnorm(100)
  
  # Discrete variable
  z &lt;- sample(letters[1:2],size = 100, replace = TRUE)
  
  data &lt;- data.frame(C1 = x, C2 = y, D1 = z, stringsAsFactors = FALSE)
  
## Get DAG
  dag &lt;- LearningHC(data)

## Learn BN
  bn &lt;- MoTBFs_Learning(dag, data, POTENTIAL_TYPE = "MTE")

## Check wheter a node is discrete or not

  # Using its name
  is.discrete("D1", bn)
  
  # Using its index position
  is.discrete(3, bn)  
</code></pre>

<hr>
<h2 id='is.observed'>Observed Node</h2><span id='topic+is.observed'></span>

<h3>Description</h3>

<p><code>is.observed()</code> checks whether a node belongs to the evidence set or not.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.observed(node, evi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.observed_+3A_node">node</code></td>
<td>
<p>A <code>character</code> string, matching the node's name.</p>
</td></tr>
<tr><td><code id="is.observed_+3A_evi">evi</code></td>
<td>
<p>A <code>data.frame</code> of the evidence set.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns TRUE if &quot;node&quot; is included in &quot;evi&quot;, or, otherwise, FALSE.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Data frame of the evidence set
  obs &lt;- data.frame(lip = "1", alm2 = 0.5, stringsAsFactors=FALSE)
  
## Check if x is in obs
  is.observed("x", obs)
</code></pre>

<hr>
<h2 id='is.root'>Root nodes</h2><span id='topic+is.root'></span>

<h3>Description</h3>

<p><code>is.root</code> checks whether a node has parents or not.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.root(node, dag)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.root_+3A_node">node</code></td>
<td>
<p>A character string indicating the name of the node.</p>
</td></tr>
<tr><td><code id="is.root_+3A_dag">dag</code></td>
<td>
<p>An object of class <code>"bn"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>is.root</code> returns <code>TRUE</code> or <code>FALSE</code> depending on whether the node is root or not.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Create a dataset
  # Continuous variables
  x &lt;- rnorm(100)
  y &lt;- rnorm(100)
  
  # Discrete variable
  z &lt;- sample(letters[1:2],size = 100, replace = TRUE)
  
  data &lt;- data.frame(C1 = x, C2 = y, D1 = z, stringsAsFactors = FALSE)
  
## Get DAG
  dag &lt;- LearningHC(data)
  
## Check if a node is root
 is.root("C1", dag)
</code></pre>

<hr>
<h2 id='jointCDF'>Joint MoTBFs CDFs</h2><span id='topic+jointCDF'></span>

<h3>Description</h3>

<p>Function to compute multivariate CDFs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jointCDF(df, grid)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jointCDF_+3A_df">df</code></td>
<td>
<p>The dataset as an object of class <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="jointCDF_+3A_grid">grid</code></td>
<td>
<p>a <code>data.frame</code> with the selected data points where the objective function
will be evaluated when optimizing the parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>jointCDF()</code> returns a vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Create dataset with 2 variables
n = 2
size = 50
df &lt;- as.data.frame(matrix(round(rnorm(size*n),2), ncol = n))

## Create grid dataset
npointsgrid &lt;- 10
ranges &lt;- sapply(df, range)
eg &lt;- list()
for(i in 1: ncol(df)){
  eg[[i]] &lt;- seq(ranges[1,i], ranges[2,i], length.out = npointsgrid)
}

x &lt;- expand.grid(eg)

## Joint cumulative values
jointCDF(df = df, grid = x)

</code></pre>

<hr>
<h2 id='jointmotbf.learning'>Joint MoTBF density learning</h2><span id='topic+jointmotbf.learning'></span><span id='topic+parametersJointMoTBF'></span><span id='topic+jointMoTBF'></span>

<h3>Description</h3>

<p>Two functions for learning joint MoTBFs. The first one, <code>parametersJointMoTBF()</code>,
gets the parameters by solving a quadratic optimization problem, minimizing
the mean squared error between the empirical joint CDF and the estimated CDF.
The density is obtained as the derivative od the estimated CDF.
The second one, <code>jointMoTBF()</code>, fixes the equation of the joint function using 
the previously learned parameters and converting this <code>"character"</code> string into an 
object of class <code>"jointmotbf"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parametersJointMoTBF(X, ranges = NULL, dimensions = NULL)

jointMoTBF(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jointmotbf.learning_+3A_x">X</code></td>
<td>
<p>A dataset of class <code>"data.frame"</code>.</p>
</td></tr>
<tr><td><code id="jointmotbf.learning_+3A_ranges">ranges</code></td>
<td>
<p>A <code>"numeric"</code> matrix containing the range of the varibles used to fit the function, 
where each column corresponds to a variable. If not specified, the range of each variable is computed from the data.</p>
</td></tr>
<tr><td><code id="jointmotbf.learning_+3A_dimensions">dimensions</code></td>
<td>
<p>A <code>"numeric"</code> vector containing the number of parameters of each varible.</p>
</td></tr>
<tr><td><code id="jointmotbf.learning_+3A_object">object</code></td>
<td>
<p>A list with the output of the function <code>parametersJointMoTBF()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>parametersJointMoTBF()</code> returns a list with the following elements: 
<b>Parameters</b>, which contains the computed coefficients of the resulting function; 
<b>Dimension</b>, which is a <code>"numeric"</code> vector containing the number 
of coefficients used for each variable; 
<b>Range</b> contains a <code>"numeric"</code> matrix with the domain of each variable, by columns;
<b>Iterations</b> contains the number of iterations needed to solve the problem;
<b>Time</b> contains the execution time.
</p>
<p><code>jointMoTBF()</code> returns an object of class <code>"jointmotbf"</code>, which is a list whose only visible element
is the analytical expression of the learned density. It also contains the other aforementioned elements, 
which can be retrieved using <code>attributes()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 1. EXAMPLE 
## Generate a multinormal dataset
data &lt;- data.frame(X1 = rnorm(100), X2 = rnorm(100))

## Joint learnings
dim &lt;- c(2,3)
param &lt;- parametersJointMoTBF(X = data, dimensions = dim)

param$Parameters
length(param$Parameters)
param$Dimension
param$Range

P &lt;- jointMoTBF(param)
P
attributes(P)
class(P)

###############################################################################
## MORE EXAMPLES ##############################################################
###############################################################################

## Generate a dataset
data &lt;- data.frame(X1 = rnorm(100), X2 = rnorm(100), X3 = rnorm(100))

## Joint learnings
dim &lt;- c(3,2,3)
param &lt;- parametersJointMoTBF(X = data, dimensions = dim)

param$Parameters
length(param$Parameters) ## prod(dim)
param$Dimension
param$Range
param$Time

P &lt;- jointMoTBF(param)
P
attributes(P)
class(P)

</code></pre>

<hr>
<h2 id='LearningHC'>Score-based hybrid Bayesian Network structure learning</h2><span id='topic+LearningHC'></span>

<h3>Description</h3>

<p>Learn the structure of a hybrid Bayesian network using the <b>hill climbing</b>
local search method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LearningHC(dataset, numIntervals = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LearningHC_+3A_dataset">dataset</code></td>
<td>
<p>A dataset with discrete and continuous variables. If the discrete
variables are not of class <code>"factor"</code>, they are automatically converted.</p>
</td></tr>
<tr><td><code id="LearningHC_+3A_numintervals">numIntervals</code></td>
<td>
<p>A <code>"numeric"</code> value indicating the number of categories 
used when discretizing a continuous variable, corresponding to intervals of
equal width. By default it is <code>NULL</code>, meaning that the continuous variables
are not discretized.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>LearningHC()</code> automatically converts non-numeric variables into factors
before calling function <code>hc()</code> from the <code>bnlearn</code> package. <code>LearningHC()</code> can also 
be used to discretize the dataset, using the equal width method, before calling <code>hc()</code>.
</p>


<h3>Value</h3>

<p>The output is a <code>"bn"</code> object containing the learned graph.
</p>


<h3>See Also</h3>

<p>hc
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Data
data(ecoli)
ecoli &lt;- ecoli[,-1] ## Sequence Name

## DAG1
dag1 &lt;- LearningHC(ecoli)
dag1
plot(dag1)

## DAG2
dag2 &lt;- LearningHC(ecoli, numIntervals = 10)
dag2
plot(dag2)


</code></pre>

<hr>
<h2 id='learnMoTBFpriorInformation'>Incorporating prior knowledge in the estimation process</h2><span id='topic+learnMoTBFpriorInformation'></span>

<h3>Description</h3>

<p>Learns a univariate MoTBF function using prior information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>learnMoTBFpriorInformation(
  priorData,
  data,
  s,
  POTENTIAL_TYPE,
  domain = range(data),
  coeffversion = 4,
  restrictDomain = TRUE,
  maxParam = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="learnMoTBFpriorInformation_+3A_priordata">priorData</code></td>
<td>
<p>A <code>"numeric"</code> vector which contains the prior information.</p>
</td></tr>
<tr><td><code id="learnMoTBFpriorInformation_+3A_data">data</code></td>
<td>
<p>A <code>"numeric"</code> vector containing the observed data.</p>
</td></tr>
<tr><td><code id="learnMoTBFpriorInformation_+3A_s">s</code></td>
<td>
<p>A <code>"numeric"</code> value which specifies the expert confidence in the prior knowledge. 
This argument takes values on the interval <em>[0, N]</em>, where <em>N</em> is the sample size, and is used
to synchronize the support of the prior knowledge and the sample.</p>
</td></tr>
<tr><td><code id="learnMoTBFpriorInformation_+3A_potential_type">POTENTIAL_TYPE</code></td>
<td>
<p>A <code>"character"</code> string, either <em>MOP</em> or <em>MTE</em>, corresponding to the type of basis function.</p>
</td></tr>
<tr><td><code id="learnMoTBFpriorInformation_+3A_domain">domain</code></td>
<td>
<p>A <code>"numeric"</code> vector which contains the bounding values to fit the function.
By default, it is the range of the data.</p>
</td></tr>
<tr><td><code id="learnMoTBFpriorInformation_+3A_coeffversion">coeffversion</code></td>
<td>
<p>A <code>"numeric"</code> value between <code>1--4</code> which contains the used version for computing 
the coefficients of the linear opinion pool to combine the prior function and the data function. 
By default, <code>coeffversion = "4"</code> is used, so the combination
depends on the goodness of the model versus another random model.</p>
</td></tr>
<tr><td><code id="learnMoTBFpriorInformation_+3A_restrictdomain">restrictDomain</code></td>
<td>
<p>A logical value. This argument allows to choose if the domain is used joining both domains,
the prior one and the data domain or trimming them. By default, <code>TRUE</code> is used, so 
the domain will be trimmed.</p>
</td></tr>
<tr><td><code id="learnMoTBFpriorInformation_+3A_maxparam">maxParam</code></td>
<td>
<p>A positive integer which indicates the maximum number of coefficients in the function. 
If specified, the output is the function which gets the best BIC with, at most, this number of parameters.
By default, it is set to <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the elements
</p>
<table>
<tr><td><code>coeffs</code></td>
<td>
<p>An <code>"numeric"</code> vector with the two coefficients of the linear opinion pool</p>
</td></tr>
<tr><td><code>posteriorFunction</code></td>
<td>
<p>The final function after combining.</p>
</td></tr>
<tr><td><code>priorFunction</code></td>
<td>
<p>The fit of the prior data.</p>
</td></tr>
<tr><td><code>dataFunction</code></td>
<td>
<p>The fit of the original data.</p>
</td></tr>
<tr><td><code>rangeNewPriorData</code></td>
<td>
<p>A <code>"numeric"</code> vector which contains the final domain where the functions are defined.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><a href="#topic+getCoefficients">getCoefficients</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Data
X &lt;- rnorm(15)

## Prior Data
priordata &lt;- rnorm(5000)

## Test data
test &lt;- rnorm(1000)
testData &lt;- test[test&gt;=min(X)&amp;test&lt;=max(X)]

## Learning
type &lt;- "MOP" 
confident &lt;- 3 ## confident &lt;- 1,2,...,length(X)
f &lt;- learnMoTBFpriorInformation(priorData = priordata, data = X, s = confident,
POTENTIAL_TYPE = type)
attributes(f)

## Log-likelihood
sum(log(as.function(f$dataFunction)(testData)))
sum(log(as.function(f$posteriorFunction)(testData))) ## best loglikelihood


</code></pre>

<hr>
<h2 id='marginalJointMoTBF'>Marginalization of MoTBFs</h2><span id='topic+marginalJointMoTBF'></span>

<h3>Description</h3>

<p>Computes the marginal densities from a <code>"jointmotbf"</code>
object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>marginalJointMoTBF(P, var)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="marginalJointMoTBF_+3A_p">P</code></td>
<td>
<p>An object of class <code>"jointmotbf"</code>, i.e., the joint density function.</p>
</td></tr>
<tr><td><code id="marginalJointMoTBF_+3A_var">var</code></td>
<td>
<p>The <code>"numeric"</code> position or the <code>"character"</code> name of the marginal variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The marginal of a <code>"jointmotbf"</code> function. The result is an object of class <code>"motbf"</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+jointMoTBF">jointMoTBF</a> and <a href="#topic+evalJointFunction">evalJointFunction</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 1. EXAMPLE 
## Dataset with 2 variables
X &lt;- data.frame(rnorm(100), rnorm(100))

## Joint function
dim &lt;- c(4,3)
param &lt;- parametersJointMoTBF(X, dimensions = dim)
P &lt;- jointMoTBF(param)
P

## Marginal
marginalJointMoTBF(P, var = "x")
marginalJointMoTBF(P, var = 2)

##############################################################################
## MORE EXAMPLES #############################################################
##############################################################################

## Generate a dataset with 3 variables
data &lt;- data.frame(rnorm(100), rnorm(100), rnorm(100))

## Joint function
dim &lt;- c(2,1,3)
param &lt;- parametersJointMoTBF(data, dimensions = dim)
P &lt;- jointMoTBF(param)
nVariables(P)

## Marginal
marginalJointMoTBF(P, var="x")
marginalJointMoTBF(P, var="y")
marginalJointMoTBF(P, var="z")

</code></pre>

<hr>
<h2 id='mop.learning'>Fitting mixtures of polynomials</h2><span id='topic+mop.learning'></span><span id='topic+bestMOP'></span>

<h3>Description</h3>

<p>These functions fit mixtures of polynomials (MOPs).  
Least square optimization is used to  
minimize the quadratic error between the empirical 
cumulative distribution and the estimated one.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mop.learning(X, nparam, domain)

bestMOP(X, domain, maxParam = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mop.learning_+3A_x">X</code></td>
<td>
<p>A <code>"numeric"</code> data vector.</p>
</td></tr>
<tr><td><code id="mop.learning_+3A_nparam">nparam</code></td>
<td>
<p>Number of parameters of the function.</p>
</td></tr>
<tr><td><code id="mop.learning_+3A_domain">domain</code></td>
<td>
<p>A <code>"numeric"</code> containing the interval over which the function is defined.</p>
</td></tr>
<tr><td><code id="mop.learning_+3A_maxparam">maxParam</code></td>
<td>
<p>A <code>"numeric"</code> value indicating the maximum number of coefficients in the function. By default it is <code>NULL</code>,
which means that the number of parameter is not limited. The output is the function which gets 
the best BIC (with at most<code>maxParam</code> parameters if not NULL).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>mop.learning()</code>:
The returned value <code>$Function</code> is the only visible element which contains the algebraic expression. 
Using <a href="base.html#topic+attributes">attributes</a> the name of the others elements are shown and also they can be extracted with <code>$</code>.
The <a href="base.html#topic+summary">summary</a> of the function also shows all these elements.
</p>
<p><code>bestMOP()</code>:
The first returned value <code>$bestPx</code> contains the output of the <code>mop.learning()</code> function
with the number of parameters which gets the best BIC values, taking into account the  
BIC score to penalize the functions. It evaluates the two next functions,
if the BIC score does not improve then the function with the last best BIC is returned.
</p>


<h3>Value</h3>

<p><code>mop.lerning()</code> returns a list of n elements:
</p>
<table>
<tr><td><code>Function</code></td>
<td>
<p>An <code>"motbf"</code> object of the <code>'mop'</code> subclass.</p>
</td></tr>
<tr><td><code>Subclass</code></td>
<td>
<p><code>'mop'</code>.</p>
</td></tr>
<tr><td><code>Domain</code></td>
<td>
<p>The range where the function is defined to be a legal density function.</p>
</td></tr>
<tr><td><code>Iterations</code></td>
<td>
<p>The number of iterations that the optimization problem takes to minimize
the errors.</p>
</td></tr>
<tr><td><code>Time</code></td>
<td>
<p>The CPU time employed.</p>
</td></tr>
</table>
<p><code>bestMOP()</code> returns a list including the polynomial function with the best BIC score, 
the number of parameters and an array with 
the BIC values of the evaluated functions.
</p>


<h3>See Also</h3>

<p><a href="#topic+univMoTBF">univMoTBF</a> A complete function for learning MOPs which includes extra options.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 1. EXAMPLE 
data &lt;- rnorm(1000)

## MOP with fix number of degrees
fx &lt;- mop.learning(data, nparam=7, domain=range(data))
fx
hist(data, prob=TRUE, main="")
plot(fx, col=2, xlim=range(data), add=TRUE)

## Best MOP in terms of BIC
fMOP &lt;- bestMOP(data, domain=range(data))
attributes(fMOP)
fMOP$bestPx
hist(data, prob=TRUE, main="")
plot(fMOP$bestPx, col=2, xlim=range(data), add=TRUE)

## 2. EXAMPLE
data &lt;- rbeta(4000, shape1=1/2, shape2=1/2)

## MOP with fix number of degrees 
fx &lt;- mop.learning(data, nparam=6, domain=range(data))
fx
hist(data, prob=TRUE, main="")
plot(fx, col=2, xlim=range(data), add=TRUE)

## Best MOP in terms of BIC
fMOP &lt;- bestMOP(data, domain=range(data), maxParam=6)
attributes(fMOP)
fMOP$bestPx
attributes(fMOP$bestPx)
hist(data, prob=TRUE, main="")
plot(fMOP$bestPx, col=2, xlim=range(data), add=TRUE)
</code></pre>

<hr>
<h2 id='motbf_type'>Type of MoTBF</h2><span id='topic+motbf_type'></span>

<h3>Description</h3>

<p>This function checks whether the density functions of a MoTBF-BN are of type MTE or MOP.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>motbf_type(bn)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="motbf_type_+3A_bn">bn</code></td>
<td>
<p>A list of lists obtained from the function <a href="#topic+MoTBFs_Learning">MoTBFs_Learning</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character string, specifying the subclass of MoTBF, i.e., either MTE or MOP.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Dataset
  data("ecoli", package = "MoTBFs")
  data &lt;- ecoli[,-c(1,9)]

## Get directed acyclic graph
  dag &lt;- LearningHC(data)
  
## Learn bayesian network
  bn &lt;- MoTBFs_Learning(dag, data = data, numIntervals = 4, POTENTIAL_TYPE = "MTE") 
  
## Get MoTBF sub-class
  motbf_type(bn)
</code></pre>

<hr>
<h2 id='MoTBF-Distribution'>Random generation for MoTBF distributions</h2><span id='topic+MoTBF-Distribution'></span><span id='topic+rMoTBF'></span><span id='topic+inversionMethod'></span>

<h3>Description</h3>

<p>Random generation for mixtures of truncated basis functions defined in a specific domain.
The inverse transform method is used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rMoTBF(size, fx, domain = NULL)

inversionMethod(size, fx, domain = NULL, data = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MoTBF-Distribution_+3A_size">size</code></td>
<td>
<p>A non-negative integer indicating the number of records to generate.</p>
</td></tr>
<tr><td><code id="MoTBF-Distribution_+3A_fx">fx</code></td>
<td>
<p>An object of class <code>"motbf"</code>.</p>
</td></tr>
<tr><td><code id="MoTBF-Distribution_+3A_domain">domain</code></td>
<td>
<p>A <code>"numeric"</code> vector indicating the lower and upper limits to sample from.
If not specified, the range is taken from the object <code>fx</code>.</p>
</td></tr>
<tr><td><code id="MoTBF-Distribution_+3A_data">data</code></td>
<td>
<p>A <code>"numeric"</code> vector to be compared with the simulated sample. 
By default, it is <code>NULL</code>; otherwise, the empirical cumulative distributions of both 
the data and the simulated sample are plotted and the Kolmogorov Smirnov test 
is used to test whether or not both samples can be considered to be drawn from the same distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>rMoTBF()</code> returns a <code>"numeric"</code> vector containing the simulated values. 
<code>inversionMethod()</code> returns a list with the simulated values and the results 
of the two-sample Kolmogorov-Smirnov test, as well as the plot of the CDFs of the 
original and simulated data.
</p>


<h3>See Also</h3>

<p><a href="#topic+integralMoTBF">integralMoTBF</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## 1. EXAMPLE
## Data
X &lt;- rnorm(1000, mean = 5, sd = 3)

## Learning
f &lt;- univMoTBF(X, POTENTIAL_TYPE="MOP", nparam=10)
plot(f, xlim = f$Domain)

## Random sample
Y &lt;- rMoTBF(size = 500, fx = f)
ks.test(X,Y)

## Plots
hist(Y, prob = TRUE, add = TRUE)

## 2. EXAMPLE 
## Data
X &lt;- rweibull(5000, shape=2)

## Learning
f &lt;- univMoTBF(X, POTENTIAL_TYPE="MOP", nparam=10)
plot(f, xlim = f$Domain)

## Random sample
inv &lt;- inversionMethod(size = 500, fx = f, data = X)
attributes(inv)
inv$test
Y &lt;- inv$sample 

## Plots
plot(f, xlim = f$Domain)
hist(Y, prob = TRUE, add = TRUE)

</code></pre>

<hr>
<h2 id='MoTBFs_Learning'>Learning hybrid BNs with MoTBFs</h2><span id='topic+MoTBFs_Learning'></span>

<h3>Description</h3>

<p>Learn mixtures of truncated basis functions in a full hybrid network.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MoTBFs_Learning(
  graph,
  data,
  numIntervals,
  POTENTIAL_TYPE,
  maxParam = NULL,
  s = NULL,
  priorData = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MoTBFs_Learning_+3A_graph">graph</code></td>
<td>
<p>A network of the class <code>"bn"</code>, <code>"graphNEL"</code> or <code>"network"</code>.</p>
</td></tr>
<tr><td><code id="MoTBFs_Learning_+3A_data">data</code></td>
<td>
<p>An object of class <code>"data.frame"</code>; it can contain continuous and discrete variables.</p>
</td></tr>
<tr><td><code id="MoTBFs_Learning_+3A_numintervals">numIntervals</code></td>
<td>
<p>A positive integer indicating the maximum number of intervals 
for splitting the domain of the continuous parent variables.</p>
</td></tr>
<tr><td><code id="MoTBFs_Learning_+3A_potential_type">POTENTIAL_TYPE</code></td>
<td>
<p>A <code>"character"</code> string, either <em>MOP</em> or <em>MTE</em>, 
corresponding to the type of basis function.</p>
</td></tr>
<tr><td><code id="MoTBFs_Learning_+3A_maxparam">maxParam</code></td>
<td>
<p>A positive integer which indicates the maximum number of coefficients in the function. 
If specified, the output is the function which gets the best BIC with, at most, this number of parameters.
By default, it is set to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="MoTBFs_Learning_+3A_s">s</code></td>
<td>
<p>A <code>"numeric"</code> value which specifies the expert confidence in the prior knowledge. 
This argument takes values on the interval <em>[0, N]</em>, where <em>N</em> is the sample size, and is used
to synchronize the support of the prior knowledge and the sample.
By default, it is <code>NULL</code>, and must be modified only if prior information is to be incorporated to the fits.</p>
</td></tr>
<tr><td><code id="MoTBFs_Learning_+3A_priordata">priorData</code></td>
<td>
<p>An object of class <code>"data.frame"</code>, corresponding to the prior information.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the variable is discrete then it computes the probabilities and the size of each leaf. 
Children that have discrete parents have as many functions as configurations of the parents. 
Children that have continuous parents have as many functions as the number indicated in the 
argument <code>"numIntervals"</code> for each parent. Children that have mixed parents, combine both methods.
The BIC criterion is used to decide the number of splitting points of the parent domains and to choose
the number of basis functions used.
</p>


<h3>Value</h3>

<p>A list of lists. Each list contains two elements
</p>
<table>
<tr><td><code>Child</code></td>
<td>
<p>A <code>"charater"</code> string which contains the name of the child variable.</p>
</td></tr>
<tr><td><code>functions</code></td>
<td>
<p>A list of three elements: the name of the parents; a <code>"numeric"</code> vector
indicating the interval of the parent; and the fitted function in this interval.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><a href="#topic+printBN">printBN</a> and <a href="#topic+ecoli">ecoli</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Dataset Ecoli
require(MoTBFs)
data(ecoli)
data &lt;- ecoli[,-c(1)] ## remove variable sequence

## Directed acyclic graph
dag &lt;- LearningHC(data)

## Learning BN
intervals &lt;- 3
potential &lt;- "MOP"
P1 &lt;- MoTBFs_Learning(graph = dag, data = data, numIntervals = intervals, POTENTIAL_TYPE=potential,
maxParam = 5)
printBN(P1)

 ## Learning BN
intervals &lt;- 4
potential &lt;- "MTE"
P2 &lt;- MoTBFs_Learning(graph = dag, data = data, numIntervals = intervals, POTENTIAL_TYPE=potential,
maxParam = 15)
printBN(P2)


</code></pre>

<hr>
<h2 id='mte.learning'>Fitting mixtures of truncated exponentials.</h2><span id='topic+mte.learning'></span><span id='topic+bestMTE'></span>

<h3>Description</h3>

<p>These functions fit mixtures of truncated exponentials (MTEs). 
Least square optimization is used to  
minimize the quadratic error between the empirical 
cumulative distribution function and the estimated one.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mte.learning(X, nparam, domain)

bestMTE(X, domain, maxParam = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mte.learning_+3A_x">X</code></td>
<td>
<p>A <code>"numeric"</code> data vector.</p>
</td></tr>
<tr><td><code id="mte.learning_+3A_nparam">nparam</code></td>
<td>
<p>Number of parameters of the resulting density function.</p>
</td></tr>
<tr><td><code id="mte.learning_+3A_domain">domain</code></td>
<td>
<p>A <code>"numeric"</code> containing the domain if the function to estimate.</p>
</td></tr>
<tr><td><code id="mte.learning_+3A_maxparam">maxParam</code></td>
<td>
<p>A <code>"numeric"</code> value indicating the maximum number of coefficients in the function. By default it is <code>NULL</code>; 
otherwise, the output is the function which gets the best BIC with at most this number of parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>mte.learning()</code>:
The returned value <code>$Function</code> is the only visible element which contains the algebraic expression. 
Using <a href="base.html#topic+attributes">attributes</a> the name of the others elements are shown and also they can be abstract with <code>$</code>.
The <a href="base.html#topic+summary">summary</a> of the function also shows all this elements.
</p>
<p><code>bestMTE()</code>:
The first returned value <code>$bestPx</code> contains the output of the <code>mte.learning()</code> function
with the number of parameters which gets the best BIC value, taking into account the  
Bayesian information criterion (BIC) to penalize the functions. It evaluates the two next functions,
if the BIC doesn't improve then the function with the last best BIC is returned.
</p>


<h3>Value</h3>

<p><code>mte.lerning()</code> returns a list of n elements:
</p>
<table>
<tr><td><code>Function</code></td>
<td>
<p>An <code>"motbf"</code> object of the <code>'mte'</code> subclass.</p>
</td></tr>
<tr><td><code>Subclass</code></td>
<td>
<p><code>'mte'</code>.</p>
</td></tr>
<tr><td><code>Domain</code></td>
<td>
<p>The range where the function is defined to be a legal density function.</p>
</td></tr>
<tr><td><code>Iterations</code></td>
<td>
<p>The number of iterations that the optimization problem employed to minimize
the errors.</p>
</td></tr>
<tr><td><code>Time</code></td>
<td>
<p>The CPU time consumed.</p>
</td></tr>
</table>
<p><code>bestMTE()</code> returns a list including the MTE function with the best BIC score, 
the number of parameters, the best BIC value and an array contained 
the BIC values of the evaluated functions.
</p>


<h3>See Also</h3>

<p><a href="#topic+univMoTBF">univMoTBF</a> A complete function for learning MoTBFs which includes extra options.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## 1. EXAMPLE
data &lt;- rchisq(1000, df=3)

## MTE with fix number of parameters
fx &lt;- mte.learning(data, nparam=7, domain=range(data))
hist(data, prob=TRUE, main="")
plot(fx, col=2, xlim=range(data), add=TRUE)

## Best MTE in terms of BIC
fMTE &lt;- bestMTE(data, domain=range(data))
attributes(fMTE)
fMTE$bestPx
hist(data, prob=TRUE, main="")
plot(fMTE$bestPx, col=2, xlim=range(data), add=TRUE)

## 2. EXAMPLE
data &lt;- rexp(1000, rate=1/3)

 ## MTE with fix number of parameters
fx &lt;- mte.learning(data, nparam=8, domain=range(data))
## Message: The nearest function with odd number of coefficients 
hist(data, prob=TRUE, main="")
plot(fx, col=2, xlim=range(data), add=TRUE)

## Best MTE in terms of BIC
fMTE &lt;- bestMTE(data, domain=range(data), maxParam=10)
attributes(fMTE)
fMTE$bestPx
attributes(fMTE$bestPx)
hist(data, prob=TRUE, main="")
plot(fMTE$bestPx, col=2, xlim=range(data), add=TRUE)
</code></pre>

<hr>
<h2 id='newRangePriorData'>Redefining the Domain</h2><span id='topic+newRangePriorData'></span>

<h3>Description</h3>

<p>Computes the new domain of two datasets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>newRangePriorData(fPI, priorData, N, domain, s, POTENTIAL_TYPE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="newRangePriorData_+3A_fpi">fPI</code></td>
<td>
<p>The function fitted to the prior data, of class <code>"motbf"</code>.</p>
</td></tr>
<tr><td><code id="newRangePriorData_+3A_priordata">priorData</code></td>
<td>
<p>A <code>"numeric"</code> array with the values to be included as prior information.</p>
</td></tr>
<tr><td><code id="newRangePriorData_+3A_n">N</code></td>
<td>
<p>A <code>"numeric"</code> value equal to the data size.</p>
</td></tr>
<tr><td><code id="newRangePriorData_+3A_domain">domain</code></td>
<td>
<p>A <code>"numeric"</code> array with the domain of the data density.</p>
</td></tr>
<tr><td><code id="newRangePriorData_+3A_s">s</code></td>
<td>
<p>A <code>"numeric"</code> value which is the expert's confidence on the prior information. It is a number between 0 and the data size.</p>
</td></tr>
<tr><td><code id="newRangePriorData_+3A_potential_type">POTENTIAL_TYPE</code></td>
<td>
<p>A <code>"character"</code> string giving the potential of the model, i.e. <code>"MOP"</code> if the basis functions are polynomials,
or <code>"MTE"</code> if they are exponentials.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>"numeric"</code> array which contains the new domain of the prior function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Data
X &lt;- rnorm(15)

## Prior Data
priordata &lt;- rnorm(5000)

## Learning
type = "MTE" 
fPrior &lt;- univMoTBF(priordata, POTENTIAL_TYPE = type)

## New range
confident &lt;- 5 ## confident &lt;- 1,2,...,length(X)
domain &lt;- range(X)
N &lt;- length(X)
newRange &lt;- newRangePriorData(fPrior, priorData = priordata, N = N,
domain = domain, s = confident, POTENTIAL_TYPE = type)
newRange

</code></pre>

<hr>
<h2 id='nVariables'>Number of Variables in a Joint Function</h2><span id='topic+nVariables'></span>

<h3>Description</h3>

<p>Compute the number of variables which are in a <code>jointmotbf</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nVariables(P)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nVariables_+3A_p">P</code></td>
<td>
<p>An <code>"motbf"</code> object or a <code>"jointmotbf"</code> object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>"character"</code> vector with the names of the variables in the function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# 1. EXAMPLE
## Generate a dataset
data &lt;- data.frame(X1 = rnorm(100), X2 = rnorm(100))

## Joint function
dim &lt;-c(3,2)
param &lt;- parametersJointMoTBF(data, dimensions = dim)
P &lt;- jointMoTBF(param)
P

## Variables
nVariables(P)

##############################################################################
## MORE EXAMPLES #############################################################
##############################################################################

## Generate a dataset
data &lt;- data.frame(X1 = rnorm(100), X2 = rnorm(100), X3 = rnorm(100))

## Joint function
dim &lt;- c(2,1,3)
param &lt;- parametersJointMoTBF(data, dimensions = dim)
P &lt;- jointMoTBF(param)

## Variables
nVariables(P)

</code></pre>

<hr>
<h2 id='parentValues'>Value of parent nodes</h2><span id='topic+parentValues'></span>

<h3>Description</h3>

<p>This function returns a <code>data.frame</code> of dimension '1xn' containing the values of the 'n' parents of a 'node' of interest. 
Use this function if you have a random sample and an observed sample with information about the parents.
The values of the parents are obtained from the evidence set unless they are not observed. In this case, the values are taken from the random sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parentValues(node, bn, obs, rdf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parentValues_+3A_node">node</code></td>
<td>
<p>A <code>character</code> string that represents the node's name.</p>
</td></tr>
<tr><td><code id="parentValues_+3A_bn">bn</code></td>
<td>
<p>A list of lists obtained from the function <a href="#topic+MoTBFs_Learning">MoTBFs_Learning</a>. It contains the conditional density functions of the bayesian network.</p>
</td></tr>
<tr><td><code id="parentValues_+3A_obs">obs</code></td>
<td>
<p>A <code>data.frame</code> of dimension '1xm' containing an instance of the 'm' variables that belong to the evidence set.</p>
</td></tr>
<tr><td><code id="parentValues_+3A_rdf">rdf</code></td>
<td>
<p>A <code>data.frame</code> of dimension '1xk' containing an instance of the 'k' variables sampled from the bayesian network.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>data.frame</code> containing the values of the parents of 'node'.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Dataset
  data("ecoli", package = "MoTBFs")
  data &lt;- ecoli[,-c(1,9)]

## Get directed acyclic graph
  dag &lt;- LearningHC(data)
  
## Learn bayesian network
  bn &lt;- MoTBFs_Learning(dag, data = data, numIntervals = 4, POTENTIAL_TYPE = "MTE")
  
## Specify the evidence set
  obs &lt;- data.frame(lip = "1", alm1 = 0.5, stringsAsFactors=FALSE)
  
## Create a random sample
  contData &lt;- data[ ,which(lapply(data, is.numeric) == TRUE)]
  fx &lt;- lapply(contData, univMoTBF, POTENTIAL_TYPE = "MTE")
  disData &lt;- data[ ,which(lapply(data, is.numeric) == FALSE)]
  conSample &lt;- lapply(fx, rMoTBF, size = 1)
  disSample &lt;- lapply(unique(disData), sample, size = 1)
  
  rdf &lt;- as.data.frame(list(conSample,disSample), stringsAsFactors = FALSE)
  
## Get the values of the parents of node "alm2"
  parentValues("alm2", bn, obs, rdf)

</code></pre>

<hr>
<h2 id='plot.jointmotbf'>Bidimensional plots for <code>'jointmotbf'</code> objects</h2><span id='topic+plot.jointmotbf'></span>

<h3>Description</h3>

<p>PLot the perpective and the contour plots for joint MoTBF functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'jointmotbf'
plot(
  x,
  type = "contour",
  ranges = NULL,
  orientation = c(5, -30),
  data = NULL,
  filled = TRUE,
  ticktype = "simple",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.jointmotbf_+3A_x">x</code></td>
<td>
<p>An object of class <code>'jointmotbf'</code>.</p>
</td></tr>
<tr><td><code id="plot.jointmotbf_+3A_type">type</code></td>
<td>
<p>A <code>"character"</code> string, either <em>contour</em> or <em>perspective</em>. It is set to <code>"contour"</code> by default.</p>
</td></tr>
<tr><td><code id="plot.jointmotbf_+3A_ranges">ranges</code></td>
<td>
<p>A <code>"numeric"</code> matrix containing the domain of the variables, by columns, which is used to specify the plotting range.</p>
</td></tr>
<tr><td><code id="plot.jointmotbf_+3A_orientation">orientation</code></td>
<td>
<p>A <code>"numeric"</code> vector indicating the perpective of the plot in degrees.
By default, it is set to <code>(5,-30)</code>.</p>
</td></tr>
<tr><td><code id="plot.jointmotbf_+3A_data">data</code></td>
<td>
<p>An object of class <code>"data.frame"</code> containing two columns only.
This argument is used to draw the points over the main plot. By default, it is set to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plot.jointmotbf_+3A_filled">filled</code></td>
<td>
<p>A logical argument; it is only used if <code>type = "contour"</code>.
is active. By default, it is <code>TRUE</code>, so filled contours are plotted.</p>
</td></tr>
<tr><td><code id="plot.jointmotbf_+3A_ticktype">ticktype</code></td>
<td>
<p>A <code>"character"</code> string, either <em>simple</em> or <em>detailed</em>. By default, it is set to <code>"simple"</code>,
which draws just an arrow parallel to the axis to indicate direction of increase. 
In contrast, <code>"detailed"</code> draws normal ticks. This argument is only used in the <code>"perspective"</code> plot.</p>
</td></tr>
<tr><td><code id="plot.jointmotbf_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to <a href="graphics.html#topic+plot">plot</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot of the joint MoTBF.
</p>


<h3>See Also</h3>

<p><a href="#topic+jointMoTBF">jointMoTBF</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 1 .EXAMPLE
## Dataset
X &lt;- data.frame(rnorm(500), rnorm(500))

## Joint function
dim &lt;- c(3,3) 
param1 &lt;- parametersJointMoTBF(X, dimensions = dim)
P &lt;- jointMoTBF(param1)
P

## Plots
plot(P)
plot(P, type = "perspective", orientation = c(90,0))

#############################################################################
## MORE EXAMPLES ############################################################
#############################################################################

## Dataset
X &lt;- data.frame(rnorm(200,2), rexp(200, 1))

## Joint function
dim &lt;- c(4,5)
param2 &lt;- parametersJointMoTBF(X, dimensions = dim)
P &lt;- jointMoTBF(param2)
P

## Plots
plot(P)
plot(P, filled = FALSE, data = X)
plot(P, type = "perspective", orientation = c(10,180))

</code></pre>

<hr>
<h2 id='plot.motbf'>Plots for <code>'motbf'</code> objects</h2><span id='topic+plot.motbf'></span>

<h3>Description</h3>

<p>Draws an <code>'motbf'</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'motbf'
plot(x, xlim = 0:1, ylim = NULL, type = "l", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.motbf_+3A_x">x</code></td>
<td>
<p>An object of class <code>'motbf'</code>.</p>
</td></tr>
<tr><td><code id="plot.motbf_+3A_xlim">xlim</code></td>
<td>
<p>The range to be encompassed by the x axis; by default <code>0:1</code>.</p>
</td></tr>
<tr><td><code id="plot.motbf_+3A_ylim">ylim</code></td>
<td>
<p>The range of the y axix.</p>
</td></tr>
<tr><td><code id="plot.motbf_+3A_type">type</code></td>
<td>
<p>As for <a href="graphics.html#topic+plot">plot</a>.</p>
</td></tr>
<tr><td><code id="plot.motbf_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed as for <a href="graphics.html#topic+plot">plot</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot of the specificated function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## 1. EXAMPLE 
## Data
X &lt;- rexp(2000)

## Learning
f1 &lt;- univMoTBF(X, POTENTIAL_TYPE = "MOP"); f1
f2 &lt;- univMoTBF(X, POTENTIAL_TYPE = "MTE", maxParam = 10); f2
f3 &lt;- univMoTBF(X, POTENTIAL_TYPE = "MOP", nparam=10); f3
## Plots
plot(NULL, xlim = range(X), ylim = c(0,0.8), xlab="X", ylab="density")
plot(f1, xlim = range(X), col = 1, add = TRUE)
plot(f2, xlim = range(X), col = 2, add = TRUE)
plot(f3, xlim = range(X), col = 3, add = TRUE)
hist(X, prob = TRUE, add= TRUE)

## 2. EXAMPLE 
## Data
X &lt;- c(rnorm(2000, mean = -3),rnorm(2000, mean = 3))

## Learning
f1 &lt;- univMoTBF(X, POTENTIAL_TYPE = "MOP"); f1
f2 &lt;- univMoTBF(X, POTENTIAL_TYPE = "MTE"); f2
## Plots
plot(NULL, xlim = range(X), ylim = c(0,0.20), xlab="X", ylab="density")
plot(f1, xlim = range(X), col = 2, add = TRUE)
plot(f2, xlim = range(X), col = 4, add = TRUE)
hist(X, prob = TRUE, add= TRUE)

</code></pre>

<hr>
<h2 id='plotConditional'>Plot Conditional Functions</h2><span id='topic+plotConditional'></span>

<h3>Description</h3>

<p>Plot conditional MoTBF densities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotConditional(
  conditionalFunction,
  data,
  nameChild = NULL,
  points = FALSE,
  color = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotConditional_+3A_conditionalfunction">conditionalFunction</code></td>
<td>
<p>the output of function <a href="#topic+conditionalMethod">conditionalMethod</a>. 
A list containing the the interval of the parent and the final conditional density (MTE or MOP).</p>
</td></tr>
<tr><td><code id="plotConditional_+3A_data">data</code></td>
<td>
<p>An object of class <code>data.frame</code>, corresponding to the dataset used to fit the conditional density.</p>
</td></tr>
<tr><td><code id="plotConditional_+3A_namechild">nameChild</code></td>
<td>
<p>A <code>character</code> string, corresponding to the name of the child variable in the conditional density. By default, it is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plotConditional_+3A_points">points</code></td>
<td>
<p>A logical value. If <code>TRUE</code>, the sample points are overlaid.</p>
</td></tr>
<tr><td><code id="plotConditional_+3A_color">color</code></td>
<td>
<p>If not specified, a default palette is used.</p>
</td></tr>
<tr><td><code id="plotConditional_+3A_...">...</code></td>
<td>
<p>Additional graphical parameters passed to filled.contour().</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the number of parents is greater than one, then the error message 
&quot;It is not possible to plot the conditional function.&quot; is reported.
</p>


<h3>Value</h3>

<p>A plot of the conditional density function.
</p>


<h3>See Also</h3>

<p><a href="#topic+conditionalMethod">conditionalMethod</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Data
X &lt;- rnorm(1000)
Y &lt;- rnorm(1000, mean=X)
data &lt;- data.frame(X=X,Y=Y)
cov(data)

## Conditional Learning
parent &lt;- "X"
child &lt;- "Y"
intervals &lt;- 5
potential &lt;- "MTE"
P &lt;- conditionalMethod(data, nameParents=parent, nameChild=child, 
numIntervals=intervals, POTENTIAL_TYPE=potential)
plotConditional(conditionalFunction=P, data=data)
plotConditional(conditionalFunction=P, data=data, points=TRUE)

</code></pre>

<hr>
<h2 id='preprocessedData'>Data cleaning</h2><span id='topic+preprocessedData'></span>

<h3>Description</h3>

<p>Delete rows of a dataset wich contains anomalous values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>preprocessedData(data, strangeElements)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="preprocessedData_+3A_data">data</code></td>
<td>
<p>A dataset of class <code>"matrix"</code> or <code>"data.frame"</code>,</p>
</td></tr>
<tr><td><code id="preprocessedData_+3A_strangeelements">strangeElements</code></td>
<td>
<p>A <code>"character"</code> string which contains the elementes to remove.</p>
</td></tr>
</table>

<hr>
<h2 id='printBN'>BN printing</h2><span id='topic+printBN'></span>

<h3>Description</h3>

<p>Prints the content of a hybrid Bayesian network
</p>


<h3>Usage</h3>

<pre><code class='language-R'>printBN(MoTBF.BN)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="printBN_+3A_motbf.bn">MoTBF.BN</code></td>
<td>
<p>The output of the method <code>MoTBFs_Learning()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The results of the fitted functions in the full network.
</p>


<h3>See Also</h3>

<p><a href="#topic+MoTBFs_Learning">MoTBFs_Learning</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Dataset Ecoli
require(MoTBFs)
data(ecoli)
data &lt;- ecoli[,-c(1)] ## remove variable sequence

## Directed acyclic graph
dag &lt;- LearningHC(data)

## Learning BN
intervals &lt;- 3
potential &lt;- "MOP"
P &lt;- MoTBFs_Learning(graph = dag, data = data, numIntervals = intervals, POTENTIAL_TYPE=potential,
maxParam = 15)
printBN(P)

</code></pre>

<hr>
<h2 id='printConditional'>Summary of conditional MoTBF densities</h2><span id='topic+printConditional'></span>

<h3>Description</h3>

<p>Print the description of an MoTBF demnsity for one variable conditional on another variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>printConditional(conditionalFunction)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="printConditional_+3A_conditionalfunction">conditionalFunction</code></td>
<td>
<p>the output of the function <code>conditionalMethod</code>. A list with the interval of the parent
and the final <code>"motbf"</code> density function fitted in each interval.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The results  of the conditional function are shown.
</p>


<h3>See Also</h3>

<p><a href="#topic+conditionalMethod">conditionalMethod</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Data
X &lt;- rexp(500)
Y &lt;- rnorm(500, mean=X)
data &lt;- data.frame(X=X,Y=Y)
cov(data)

## Conditional Learning
parent &lt;- "X"
child &lt;- "Y"
intervals &lt;- 5
potential &lt;- "MOP"
P &lt;- conditionalMethod(data, nameParents=parent, nameChild=child, 
numIntervals=intervals, POTENTIAL_TYPE=potential)
printConditional(P)

</code></pre>

<hr>
<h2 id='printDiscreteBN'>Printing discrete Bayesian networks</h2><span id='topic+printDiscreteBN'></span>

<h3>Description</h3>

<p>Prints the univariate and conditional distributions of a discrete BN.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>printDiscreteBN(BN)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="printDiscreteBN_+3A_bn">BN</code></td>
<td>
<p>A discrete learning.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The results are shown on the screen.
</p>

<hr>
<h2 id='probDiscreteVariable'>Probability distribution of discrete variables</h2><span id='topic+probDiscreteVariable'></span>

<h3>Description</h3>

<p>Compute the probabilities of a discrete variable from a dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>probDiscreteVariable(stateNames, Variable)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="probDiscreteVariable_+3A_statenames">stateNames</code></td>
<td>
<p>A <code>"character"</code> array indicating the states of the variable.</p>
</td></tr>
<tr><td><code id="probDiscreteVariable_+3A_variable">Variable</code></td>
<td>
<p>A <code>"numeric"</code> array containing the records of the variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of  <code>"numeric"</code> arrays:
</p>
<table>
<tr><td><code>coeff</code></td>
<td>
<p>Contains the probabilities.</p>
</td></tr>
<tr><td><code>sizeDataLeaf</code></td>
<td>
<p>Number of records in each leaf of the discrete tree.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><a href="#topic+discreteVariablesStates">discreteVariablesStates</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Discrete Variable
data &lt;- data.frame(X=rep(c("yes", "no", "maybe"), 500))
data &lt;- discreteVariables_as.character(data, "X")
n &lt;- nrow(data)

## Probabilities
s &lt;- discreteVariablesStates(namevariables="X", discreteData=data)
states &lt;- s[[1]]$states
p &lt;- probDiscreteVariable(stateNames=states, Variable=data$X)
p

</code></pre>

<hr>
<h2 id='r.data.frame'>Data frame initialization for forward sampling</h2><span id='topic+r.data.frame'></span>

<h3>Description</h3>

<p>The function <code>r.data.frame()</code> initializes a data frame with as many columns as nodes in the MoTBF-network. It also asings each column its data type, i.e., numeric or character. In the case of character columns, the states of the variable are extracted from the <code>"bn"</code> argument and included as levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>r.data.frame(bn, dag)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="r.data.frame_+3A_bn">bn</code></td>
<td>
<p>A list of lists obtained from the function <a href="#topic+MoTBFs_Learning">MoTBFs_Learning</a>.</p>
</td></tr>
<tr><td><code id="r.data.frame_+3A_dag">dag</code></td>
<td>
<p>An object of class <code>"bn"</code>, representing the graph of the bayesian network.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"data.frame"</code>, which contains the data type of each column and has no rows.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Create a dataset
  # Continuous variables
  x &lt;- rnorm(100)
  y &lt;- rnorm(100)
  
  # Discrete variable
  z &lt;- sample(letters[1:2],size = 100, replace = TRUE)
  
  data &lt;- data.frame(C1 = x, C2 = y, D1 = z, stringsAsFactors = FALSE)
  
## Get DAG
  dag &lt;- LearningHC(data)
  
## Learn a BN
  bn &lt;- MoTBFs_Learning(dag, data, POTENTIAL_TYPE = "MTE")
  
## Initialize a data.frame containing 3 columns (x, y and z) with their attributes.
  r.data.frame(bn, dag)
</code></pre>

<hr>
<h2 id='rescaledFunctions'>Rescaling MoTBF functions</h2><span id='topic+rescaledFunctions'></span><span id='topic+rescaledMoTBFs'></span><span id='topic+rescaledMOP'></span><span id='topic+ToStringRe_MOP'></span><span id='topic+rescaledMTE'></span><span id='topic+ToStringRe_MTE'></span><span id='topic+meanMOP'></span>

<h3>Description</h3>

<p>A collation of function to reescale an MoTBF function
to the original offset and scale. This is useful when data was
standardized previously to learning.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rescaledMoTBFs(fx, data)

rescaledMOP(fx, data)

ToStringRe_MOP(parameters, data)

rescaledMTE(fx, data)

ToStringRe_MTE(parameters, data, num = 5)

meanMOP(fx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rescaledFunctions_+3A_fx">fx</code></td>
<td>
<p>A function of class <code>"motbf"</code> learned from a scaled data.</p>
</td></tr>
<tr><td><code id="rescaledFunctions_+3A_data">data</code></td>
<td>
<p>A <code>"numeric"</code> vector containing the original data (non standardizded).</p>
</td></tr>
<tr><td><code id="rescaledFunctions_+3A_parameters">parameters</code></td>
<td>
<p>A <code>"numeric"</code> vector with the coefficients to create the rescaled MoTBF.</p>
</td></tr>
<tr><td><code id="rescaledFunctions_+3A_num">num</code></td>
<td>
<p>A <code>"numeric"</code> value which contains the denominator of the coefficient
in the exponential. By default it is 5.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <code>"motbf"</code> function of the original data.
</p>


<h3>See Also</h3>

<p><a href="#topic+univMoTBF">univMoTBF</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 1. EXAMPLE
X &lt;- rchisq(1000, df = 8) ## data
modX &lt;- scale(X) ## scale data

## Learning
f &lt;- univMoTBF(modX, POTENTIAL_TYPE = "MOP", nparam=10) 
plot(f, xlim = range(modX), col=2)
hist(modX, prob = TRUE, add = TRUE)

## Rescale
origF &lt;- rescaledMoTBFs(f, X) 
plot(origF, xlim = range(X), col=2)
hist(X, prob = TRUE, add = TRUE)
meanMOP(origF) 
mean(X)

## 2. EXAMPLE 
X &lt;- rweibull(1000, shape = 20, scale= 10) ## data
modX &lt;- as.numeric(scale(X)) ## scale data

## Learning
f &lt;- univMoTBF(modX, POTENTIAL_TYPE = "MTE", nparam = 9) 
plot(f, xlim = range(modX), col=2, main="")
hist(modX, prob = TRUE, add = TRUE)

## Rescale
origF &lt;- rescaledMoTBFs(f, X) 
plot(origF, xlim = range(X), col=2)
hist(X, prob = TRUE, add = TRUE)

</code></pre>

<hr>
<h2 id='rnormMultiv'>Multivariate Normal sampling</h2><span id='topic+rnormMultiv'></span>

<h3>Description</h3>

<p>Generate a multivariate normal data vector taking into account the real data and the 
relationships with other variables in the dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rnormMultiv(n, dataParents, dataChild)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rnormMultiv_+3A_n">n</code></td>
<td>
<p>A <code>"numeric"</code> value which is the size of the prior data to generate.</p>
</td></tr>
<tr><td><code id="rnormMultiv_+3A_dataparents">dataParents</code></td>
<td>
<p>A data set of class <code>"data.frame"</code> giving the data of the set of coditional parent variables.</p>
</td></tr>
<tr><td><code id="rnormMultiv_+3A_datachild">dataChild</code></td>
<td>
<p>A <code>"numeric"</code> vector containing the original data of the child variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>"numeric"</code> vector giving the prior data values.
</p>


<h3>See Also</h3>

<p><a href="#topic+generateNormalPriorData">generateNormalPriorData</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Data
data(ecoli)
data &lt;- ecoli[,-c(1,9)] ## remove sequece.name and class

## DAG
dag &lt;- LearningHC(data)
plot(dag)
getChildParentsFromGraph(dag)

## 1. Random sample
parents &lt;- "mcg"
child &lt;- "alm1"
n &lt;- 1000
rnormMultiv(n, dataParents = data.frame(data[,parents]), dataChild = data[,child])

## 2. Random sample
parents &lt;- "alm1"
child &lt;- "aac"
n &lt;- 256
rnormMultiv(n, dataParents = data.frame(data[,parents]), dataChild = data[,child])

</code></pre>

<hr>
<h2 id='sample_MoTBFs'>Sample generation from conditional MoTBFs</h2><span id='topic+sample_MoTBFs'></span>

<h3>Description</h3>

<p>This function generates a sample from conditional MoTBFs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_MoTBFs(bn, dag, obs = NULL, size, force_size = T)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_MoTBFs_+3A_bn">bn</code></td>
<td>
<p>A list of lists obtained from the function <a href="#topic+MoTBFs_Learning">MoTBFs_Learning</a>.</p>
</td></tr>
<tr><td><code id="sample_MoTBFs_+3A_dag">dag</code></td>
<td>
<p>An object of class <code>"bn"</code>, representing the directed acyclic graph.</p>
</td></tr>
<tr><td><code id="sample_MoTBFs_+3A_obs">obs</code></td>
<td>
<p>A <code>data.frame</code> containing the observed variables. This argument can be omitted if no variable is observed.</p>
</td></tr>
<tr><td><code id="sample_MoTBFs_+3A_size">size</code></td>
<td>
<p>A non-negative integer giving the number of instances to be generated.</p>
</td></tr>
<tr><td><code id="sample_MoTBFs_+3A_force_size">force_size</code></td>
<td>
<p><code>logical</code> indicating if the sample must be of the size indicated. As a default, it is set to TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>data.frame</code> containing the generated sample.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Dataset
  data("ecoli", package = "MoTBFs")
  data &lt;- ecoli[,-c(1,9)]

## Get directed acyclic graph
  dag &lt;- LearningHC(data)
  
## Learn bayesian network
  bn &lt;- MoTBFs_Learning(dag, data = data, numIntervals = 4, POTENTIAL_TYPE = "MTE")
  
## Specify the evidence set 
  obs &lt;- data.frame(lip = "0.48", alm1 = 0.55, gvh = 1, stringsAsFactors=FALSE)
  
## Get the conditional sample
  sample_MoTBFs(bn, dag, obs, size = 10)
  
</code></pre>

<hr>
<h2 id='Subclass-MoTBF'>Subclass <code>"motbf"</code> Functions</h2><span id='topic+Subclass-MoTBF'></span><span id='topic+is.mte'></span><span id='topic+is.mop'></span><span id='topic+subclass'></span>

<h3>Description</h3>

<p>Collection of functions for detecting the subclass of an <code>"motbf"</code>
object. It can be <code>"mop"</code> or <code>"mte"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.mte(fx)

is.mop(fx)

subclass(fx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Subclass-MoTBF_+3A_fx">fx</code></td>
<td>
<p>A function of the class <code>"motbf"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>is.mte</code> and <code>is.mop</code> return a logical value, <code>TRUE</code> if it is an <code>"motbf"</code> object of the subclass
<code>"mte"</code> or <code>"mop"</code>, respectly; or <code>FALSE</code> otherwise. 
<code>subclass</code> returns a <code>"character"</code> string, <code>"mte"</code> or <code>"mop"</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+univMoTBF">univMoTBF</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## MOP Function
X &lt;- rnorm(1000)
P &lt;- univMoTBF(X, POTENTIAL_TYPE="MOP")
is.mop(P)
subclass(P)

## MTE Function
X &lt;- rchisq(1000, df=4)
P &lt;- univMoTBF(X, POTENTIAL_TYPE="MTE")
is.mte(P)
subclass(P)
</code></pre>

<hr>
<h2 id='subsetData'>Dataset subsetting</h2><span id='topic+subsetData'></span><span id='topic+TrainingandTestData'></span><span id='topic+newData'></span><span id='topic+splitdata'></span>

<h3>Description</h3>

<p>Collection of functions for subsetting a <code>"data.frame"</code> by rows or columns, and
to create training and test partitions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TrainingandTestData(data, percentage_test, discreteVariables = NULL)

newData(data, nameX, nameY)

splitdata(data, nameVariable, min, max)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subsetData_+3A_data">data</code></td>
<td>
<p>A dataset of class <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="subsetData_+3A_percentage_test">percentage_test</code></td>
<td>
<p>The proportion of data that goes to the test set (between 0 and 1).</p>
</td></tr>
<tr><td><code id="subsetData_+3A_discretevariables">discreteVariables</code></td>
<td>
<p>A <code>character</code> vector with the name of the discrete variables.</p>
</td></tr>
<tr><td><code id="subsetData_+3A_namex">nameX</code></td>
<td>
<p>A <code>character</code> vector with the name of the child variable in the conditional method.</p>
</td></tr>
<tr><td><code id="subsetData_+3A_namey">nameY</code></td>
<td>
<p>A <code>character</code> vector with the name of the parent variables in the conditional method.</p>
</td></tr>
<tr><td><code id="subsetData_+3A_namevariable">nameVariable</code></td>
<td>
<p>A <code>character</code> vector with the name of the variable to be filtered.</p>
</td></tr>
<tr><td><code id="subsetData_+3A_min">min</code>, <code id="subsetData_+3A_max">max</code></td>
<td>
<p>Boundary values to filter out.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>TrainingandTestData()</code> returns a list of 2 elements containing the train and test datasets. 
<code>newData()</code> and <code>splitdata()</code> return a subset of variables or observations, respectively.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Dataset
X &lt;- rnorm(1000)
Y &lt;- rchisq(1000, df = 8)
Z &lt;- rep(letters[1:10], times = 1000/10)
data &lt;- data.frame(X = X, Y = Y, Z = Z)
data &lt;- discreteVariables_as.character(dataset = data, discreteVariables ="Z")

## Training and Test Datasets
TT &lt;- TrainingandTestData(data, percentage_test = 0.2)
TT$Training
TT$Test

## Subset Dataset
newData(data, nameX = "X", nameY = "Z")
splitdata(data, nameVariable = "X", min = 2, max= 3)

</code></pre>

<hr>
<h2 id='summary.jointmotbf'>Summary of a <code>"jointmotbf"</code> object</h2><span id='topic+summary.jointmotbf'></span><span id='topic+print.summary.jointmotbf'></span>

<h3>Description</h3>

<p>Summarize a <code>"jointmotbf"</code> object by describing its main features.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'jointmotbf'
summary(object, ...)

## S3 method for class 'summary.jointmotbf'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.jointmotbf_+3A_object">object</code></td>
<td>
<p>An object of class <code>"jointmotbf"</code>.</p>
</td></tr>
<tr><td><code id="summary.jointmotbf_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="summary.jointmotbf_+3A_x">x</code></td>
<td>
<p>An object of class <code>"summary.jointmotbf"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The summary of a <code>"jointmotbf"</code> object. It contains a list of
elements with the most important information about the object.
</p>


<h3>See Also</h3>

<p><a href="#topic+parametersJointMoTBF">parametersJointMoTBF</a> and <a href="#topic+jointMoTBF">jointMoTBF</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 1. EXAMPLE
X &lt;- rnorm(100)
Y &lt;- rexp(100)
data &lt;- data.frame(X, Y)
dim &lt;- c(3,4)
param &lt;- parametersJointMoTBF(data, dimensions=dim)
P &lt;- jointMoTBF(param)
summary(P)
attributes(sP &lt;- summary(P))
attributes(sP)
sP$Function
sP$Domain
sP$Iterations

##############################################################################
## MORE EXAMPLES #############################################################
##############################################################################

X &lt;- rnorm(100)
Y &lt;- rexp(100)
Z &lt;- rnorm(100, mean=1)
data &lt;- data.frame(X, Y, Z)
dim &lt;- c(3,2,4)
param &lt;- parametersJointMoTBF(data, dimensions=dim)
P &lt;- jointMoTBF(param)
summary(P)
attributes(sP &lt;- summary(P))
sP$Function
sP$Domain
sP$Iterations

##############################################################################
##############################################################################
</code></pre>

<hr>
<h2 id='summary.motbf'>Summary of an <code>"motbf"</code> object</h2><span id='topic+summary.motbf'></span><span id='topic+print.summary.motbf'></span>

<h3>Description</h3>

<p>Summarize an <code>"motbf"</code> object by describing its main features.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'motbf'
summary(object, ...)

## S3 method for class 'summary.motbf'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.motbf_+3A_object">object</code></td>
<td>
<p>An object of class <code>"motbf"</code>.</p>
</td></tr>
<tr><td><code id="summary.motbf_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="summary.motbf_+3A_x">x</code></td>
<td>
<p>An object of class <code>"summary.motbf"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The summary of an <code>"motbf"</code> object. It contains a list of
elements with the most important information of the object.
</p>


<h3>See Also</h3>

<p><a href="#topic+univMoTBF">univMoTBF</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Subclass 'MOP'
X &lt;- rnorm(1000)
P &lt;- univMoTBF(X, POTENTIAL_TYPE="MOP") ## or POTENTIAL_TYPE="MTE"
summary(P)
attributes(sP &lt;- summary(P))
attributes(sP)
sP$Function
sP$Subclass
sP$Iterations

## Subclass 'MTE'
X &lt;- rnorm(1000)
P &lt;- univMoTBF(X, POTENTIAL_TYPE="MTE")
summary(P)
attributes(sP &lt;- summary(P))
attributes(sP)
sP$Function
sP$Subclass
sP$Iterations
</code></pre>

<hr>
<h2 id='thyroid'>Data set Thyroid Disease (thyroid0387)</h2><span id='topic+thyroid'></span>

<h3>Description</h3>

<p>This data set if one of the several databases about Thyroid avalaible at the UCI repository. 
The task is to detect is a given patient is normal (1) or suffers from hyperthyroidism (2) 
or hypothyroidism (3) .
</p>


<h3>Format</h3>

<p>A data frame with 7200 rows, 21 variables and the class.
</p>


<h3>Details</h3>


<dl>
<dt>Age</dt><dd><p>Age of the patient (0.01&ndash;0.97). Continuous variable.</p>
</dd>
<dt>Sex</dt><dd><p>Sex of the patient, 0 (Male) 1 (Female). Binary variable. </p>
</dd>
<dt>On_thyroxine</dt><dd><p>0 (FALSE) 1 (TRUE). Binary variable.</p>
</dd>
<dt>Query_on_thyroxine</dt><dd><p>0 (FALSE) 1 (TRUE). Binary variable.</p>
</dd>
<dt>On_antithyroid_medication</dt><dd><p>0 (FALSE) 1 (TRUE). Binary variable.</p>
</dd>
<dt>Sick</dt><dd><p>0 (FALSE) 1 (TRUE). Binary variable.</p>
</dd>
<dt>Pregnant</dt><dd><p>0 (FALSE) 1 (TRUE). Binary variable.</p>
</dd>
<dt>Thyroid_surgery</dt><dd><p>0 (FALSE) 1 (TRUE). Binary variable.</p>
</dd>
<dt>I131_treatment</dt><dd><p>0 (FALSE) 1 (TRUE). Binary variable.</p>
</dd>
<dt>Query_hypothyroid</dt><dd><p>0 (FALSE) 1 (TRUE). Binary variable.</p>
</dd>
<dt>Query_hyperthyroid</dt><dd><p>0 (FALSE) 1 (TRUE). Binary variable.</p>
</dd>
<dt>Lithium</dt><dd><p>0 (FALSE) 1 (TRUE). Binary variable.</p>
</dd>
<dt>Goitre</dt><dd><p>0 (FALSE) 1 (TRUE). Binary variable.</p>
</dd>
<dt>Tumor</dt><dd><p>0 (FALSE) 1 (TRUE). Binary variable.</p>
</dd>
<dt>Hypopituitary</dt><dd><p>0 (FALSE) 1 (TRUE). Binary variable.</p>
</dd>
<dt>Psych</dt><dd><p>0 (FALSE) 1 (TRUE). Binary variable.</p>
</dd>
<dt>TSH</dt><dd><p>amount of TSH (0.0&ndash;0.53). Continuous variable.</p>
</dd>
<dt>T3</dt><dd><p>amount of T3 (0.0005&ndash;0.18). Continuous variable.</p>
</dd>
<dt>TT4</dt><dd><p>amount of TT4 (0.002&ndash;0.6). Continuous variable.</p>
</dd>
<dt>T4U</dt><dd><p>amount of T4U (0.017&ndash;0.233). Continuous variable.</p>
</dd>
<dt>FTI</dt><dd><p>amount of FTI (0.002&ndash;0.642). Continuous variable.</p>
</dd>
<dt>Class</dt><dd><p>1 (normal) 2 (hyperthyroidism) 3 (hypothyroidism). Class variable.</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="http://archive.ics.uci.edu/ml/datasets/Thyroid+Disease">http://archive.ics.uci.edu/ml/datasets/Thyroid+Disease</a>
</p>

<hr>
<h2 id='univMoTBF'>Fitting MoTBFs</h2><span id='topic+univMoTBF'></span>

<h3>Description</h3>

<p>Function for fitting univariate mixture of truncated basis functions.
Least square optimization is used to minimize the quadratic 
error between the empirical cumulative distribution and the estimated one.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>univMoTBF(
  data,
  POTENTIAL_TYPE,
  evalRange = NULL,
  nparam = NULL,
  maxParam = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="univMoTBF_+3A_data">data</code></td>
<td>
<p>A <code>"numeric"</code> vector.</p>
</td></tr>
<tr><td><code id="univMoTBF_+3A_potential_type">POTENTIAL_TYPE</code></td>
<td>
<p>A <code>"character"</code> string specifying the potential
type, must be either <code>"MOP"</code> or <code>"MTE"</code>.</p>
</td></tr>
<tr><td><code id="univMoTBF_+3A_evalrange">evalRange</code></td>
<td>
<p>A <code>"numeric"</code> vector that specifies the domain over
which the model will be fitted. By default, it is <code>NULL</code> and the function is defined
over the complete data range.</p>
</td></tr>
<tr><td><code id="univMoTBF_+3A_nparam">nparam</code></td>
<td>
<p>The exact number of basis functions to be used. By default, it is <code>NULL</code>
and the best MoTBF is fitted taking into account the Bayesian information
criterion (BIC) to score and select the functions. It evaluates the next two functions and,
if the BIC value does not improve, the function with the best BIC score so far is returned.</p>
</td></tr>
<tr><td><code id="univMoTBF_+3A_maxparam">maxParam</code></td>
<td>
<p>A <code>"numeric"</code> value which indicates the maximum number of coefficients in the function. 
By default, it is <code>NULL</code>; otherwise, the function which gets the best BIC score
with at most this number of parameters is returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>univMoTBF()</code> returns an object of class <code>"motbf"</code>. This object is a list containing several elements, 
including its mathematical expression and other hidden elements related to the learning task. 
The processing time is one of the values returned by this function and it can be extracted by $Time. 
Although the learning process is always the same for a particular data sample, 
the processing can vary inasmuch as it depends on the CPU.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 1. EXAMPLE
## Data
X &lt;- rnorm(5000)

## Learning
f1 &lt;- univMoTBF(X, POTENTIAL_TYPE = "MTE"); f1
f2 &lt;- univMoTBF(X, POTENTIAL_TYPE = "MOP"); f2

## Plots
hist(X, prob = TRUE, main = "")
plot(f1, xlim = range(X), col = 1, add = TRUE)
plot(f2, xlim = range(X), col = 2, add = TRUE)

## Data test
Xtest &lt;- rnorm(1000)
## Filtered data test
Xtest &lt;- Xtest[Xtest&gt;=min(X) &amp; Xtest&lt;=max(X)]

## Log-likelihood
sum(log(as.function(f1)(Xtest)))
sum(log(as.function(f2)(Xtest)))

## 2. EXAMPLE
## Data
X &lt;- rchisq(5000, df = 5)

## Learning
f1 &lt;- univMoTBF(X, POTENTIAL_TYPE = "MTE", nparam = 11); f1
f2 &lt;- univMoTBF(X, POTENTIAL_TYPE = "MOP", maxParam = 10); f2

## Plots
hist(X, prob = TRUE, main = "")
plot(f1, xlim = range(X), col = 3, add = TRUE)
plot(f2, xlim = range(X), col = 4, add = TRUE)

## Data test
Xtest &lt;- rchisq(1000, df = 5)
## Filtered data test
Xtest &lt;- Xtest[Xtest&gt;=min(X) &amp; Xtest&lt;=max(X)]

## Log-likelihood
sum(log(as.function(f1)(Xtest)))
sum(log(as.function(f2)(Xtest)))

</code></pre>

<hr>
<h2 id='UpperBoundLogLikelihood'>Upper bound of the loglikelihood</h2><span id='topic+UpperBoundLogLikelihood'></span>

<h3>Description</h3>

<p>Computes an upper bound of the expected loglikelihood of a dataset given a randomly 
generated MoTBF density.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UpperBoundLogLikelihood(f, data, min, max)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="UpperBoundLogLikelihood_+3A_f">f</code></td>
<td>
<p>A function to evaluate of class <code>"character"</code>, <code>"motbf"</code> or others.</p>
</td></tr>
<tr><td><code id="UpperBoundLogLikelihood_+3A_data">data</code></td>
<td>
<p>A <code>"numeric"</code> array which contains the values to evaluate.</p>
</td></tr>
<tr><td><code id="UpperBoundLogLikelihood_+3A_min">min</code></td>
<td>
<p>A <code>"numeric"</code> value giving the lower limit of the domain.</p>
</td></tr>
<tr><td><code id="UpperBoundLogLikelihood_+3A_max">max</code></td>
<td>
<p>A <code>"numeric"</code> value giving the upper limit of the domain.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>"numeric"</code> value which is the log-likelihood of the evaluated ramdom function.
</p>


<h3>See Also</h3>

<p><a href="#topic+getNonNormalisedRandomMoTBF">getNonNormalisedRandomMoTBF</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data &lt;- rnorm(20)
f &lt;- getNonNormalisedRandomMoTBF(degree = 8, POTENTIAL_TYPE = "MOP")
UpperBoundLogLikelihood(f, data, min = -2.5, max = 3.2)

data &lt;- rexp(20)
f &lt;- getNonNormalisedRandomMoTBF(degree = 8, POTENTIAL_TYPE = "MTE")
UpperBoundLogLikelihood(f, data, min = 0, max = 5)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
