<!DOCTYPE html><html><head><title>Help for package bigstatsr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {bigstatsr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#as_scaling_fun'><p>Scaling function creator</p></a></li>
<li><a href='#asPlotlyText'><p>Plotly text</p></a></li>
<li><a href='#AUC'><p>AUC</p></a></li>
<li><a href='#big_apply'><p>Split-Apply-Combine</p></a></li>
<li><a href='#big_attach'><p>Attach a Filebacked Big Matrix</p></a></li>
<li><a href='#big_colstats'><p>Standard univariate statistics</p></a></li>
<li><a href='#big_copy'><p>Copy as a Filebacked Big Matrix</p></a></li>
<li><a href='#big_cor'><p>Correlation</p></a></li>
<li><a href='#big_counts'><p>Counts for class FBM.code256</p></a></li>
<li><a href='#big_cprodMat'><p>Cross-product with a matrix</p></a></li>
<li><a href='#big_cprodVec'><p>Cross-product with a vector</p></a></li>
<li><a href='#big_crossprodSelf'><p>Crossprod</p></a></li>
<li><a href='#big_increment'><p>Increment an FBM</p></a></li>
<li><a href='#big_parallelize'><p>Split-parApply-Combine</p></a></li>
<li><a href='#big_prodMat'><p>Product with a matrix</p></a></li>
<li><a href='#big_prodVec'><p>Product with a vector</p></a></li>
<li><a href='#big_randomSVD'><p>Randomized partial SVD</p></a></li>
<li><a href='#big_read'><p>Read a file as FBM</p></a></li>
<li><a href='#big_scale'><p>Some scaling functions</p></a></li>
<li><a href='#big_spLinReg'><p>Sparse linear regression</p></a></li>
<li><a href='#big_spLogReg'><p>Sparse logistic regression</p></a></li>
<li><a href='#big_SVD'><p>Partial SVD</p></a></li>
<li><a href='#big_tcrossprodSelf'><p>Tcrossprod</p></a></li>
<li><a href='#big_transpose'><p>Transpose an FBM</p></a></li>
<li><a href='#big_univLinReg'><p>Column-wise linear regression</p></a></li>
<li><a href='#big_univLogReg'><p>Column-wise logistic regression</p></a></li>
<li><a href='#big_write'><p>Write an FBM to a file</p></a></li>
<li><a href='#bigstatsr-package'><p>bigstatsr: Statistical Tools for Filebacked Big Matrices</p></a></li>
<li><a href='#block_size'><p>Determine a correct value for the block.size parameter</p></a></li>
<li><a href='#COPY_biglasso_main'><p>Sparse regression path</p></a></li>
<li><a href='#COPY_biglasso_part'><p>Train one model</p></a></li>
<li><a href='#covar_from_df'><p>Numeric matrix from data frame</p></a></li>
<li><a href='#Extract'><p>Create an Implementation of [ For Custom Matrix-Like Types</p></a></li>
<li><a href='#FBM-class'><p>Class FBM</p></a></li>
<li><a href='#FBM-methods'><p>Methods for the FBM class</p></a></li>
<li><a href='#FBM.code256-class'><p>Class FBM.code256</p></a></li>
<li><a href='#get_beta'><p>Combine sets of coefficients</p></a></li>
<li><a href='#pasteLoc'><p>Get coordinates on plot</p></a></li>
<li><a href='#pcor'><p>Partial correlation</p></a></li>
<li><a href='#plot.big_sp_list'><p>Plot method</p></a></li>
<li><a href='#plot.big_SVD'><p>Plot method</p></a></li>
<li><a href='#plot.mhtest'><p>Plot method</p></a></li>
<li><a href='#predict.big_sp'><p>Predict method</p></a></li>
<li><a href='#predict.big_sp_list'><p>Predict method</p></a></li>
<li><a href='#predict.big_SVD'><p>Scores of PCA</p></a></li>
<li><a href='#predict.mhtest'><p>Predict method</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#Replace'><p>Create an Implementation of [&lt;- For Custom Matrix-Like Types</p></a></li>
<li><a href='#sub_bk'><p>Replace extension '.bk'</p></a></li>
<li><a href='#summary.big_sp_list'><p>Summary method</p></a></li>
<li><a href='#theme_bigstatsr'><p>Theme ggplot2</p></a></li>
<li><a href='#without_downcast_warning'><p>Temporarily disable downcast warning</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Statistical Tools for Filebacked Big Matrices</td>
</tr>
<tr>
<td>Version:</td>
<td>1.5.12</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-10-11</td>
</tr>
<tr>
<td>Description:</td>
<td>Easy-to-use, efficient, flexible and scalable statistical tools.
  Package bigstatsr provides and uses Filebacked Big Matrices via memory-mapping.
  It provides for instance matrix operations, Principal Component Analysis,
  sparse linear supervised models, utility functions and more
  &lt;<a href="https://doi.org/10.1093%2Fbioinformatics%2Fbty185">doi:10.1093/bioinformatics/bty185</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4)</td>
</tr>
<tr>
<td>Imports:</td>
<td>bigassertr (&ge; 0.1.1), bigparallelr (&ge; 0.2.3), cowplot,
foreach, ggplot2 (&ge; 3.0), graphics, methods, ps (&ge; 1.4),
Rcpp, rmio (&ge; 0.4), RSpectra, stats, tibble, utils</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo, rmio</td>
</tr>
<tr>
<td>Suggests:</td>
<td>bigmemory (&ge; 4.5.33), bigreadr (&ge; 0.2), covr, data.table,
dplyr, glmnet, hexbin, memuse, ModelMetrics, plotly, ppcor,
RhpcBLASctl, spelling (&ge; 1.2), testthat</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://privefl.github.io/bigstatsr/">https://privefl.github.io/bigstatsr/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/privefl/bigstatsr/issues">https://github.com/privefl/bigstatsr/issues</a></td>
</tr>
<tr>
<td>Collate:</td>
<td>'AUC.R' 'FBM-attach.R' 'crochet.R' 'FBM.R' 'FBM-code256.R'
'FBM-copy.R' 'RcppExports.R' 'SVD.R' 'apply-parallelize.R'
'biglasso.R' 'bigstatsr-package.R' 'colstats.R'
'crossprodSelf.R' 'mult-mat.R' 'mult-vec.R' 'pcor.R' 'plot.R'
'predict.R' 'randomSVD.R' 'read-write.R' 'scaling.R'
'summary.R' 'tcrossprodSelf.R' 'transpose.R' 'univLinReg.R'
'univLogReg.R' 'utils-assert.R' 'utils.R' 'zzz.R'</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-10-14 07:29:56 UTC; au639593</td>
</tr>
<tr>
<td>Author:</td>
<td>Florian Privé [aut, cre],
  Michael Blum [ths],
  Hugues Aschard [ths]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Florian Privé &lt;florian.prive.21@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-10-14 08:32:38 UTC</td>
</tr>
</table>
<hr>
<h2 id='as_scaling_fun'>Scaling function creator</h2><span id='topic+as_scaling_fun'></span>

<h3>Description</h3>

<p>Convenience function to create a function to be used as parameter <code>fun.scaling</code>
when you want to use your own precomputed center and scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_scaling_fun(center.col, scale.col, ind.col = seq_along(center.col))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_scaling_fun_+3A_center.col">center.col</code></td>
<td>
<p>Vector of centers corresponding to <code>ind.col</code>.</p>
</td></tr>
<tr><td><code id="as_scaling_fun_+3A_scale.col">scale.col</code></td>
<td>
<p>Vector of scales corresponding to <code>ind.col</code>.</p>
</td></tr>
<tr><td><code id="as_scaling_fun_+3A_ind.col">ind.col</code></td>
<td>
<p>Column indices for which these are provided.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A function to be used as parameter <code>fun.scaling</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fun.scaling &lt;- as_scaling_fun(1:6, 2:7)
fun.scaling(NULL, NULL, 1:3)  # first two parameters X and ind.row are not used here
fun.scaling2 &lt;- as_scaling_fun(1:6, 2:7, ind.col = 6:1)
fun.scaling2(NULL, NULL, 1:3)


X &lt;- big_attachExtdata()
sc &lt;- big_scale()(X)
fun &lt;- as_scaling_fun(center = sc$center, scale = sc$scale)
obj.svd &lt;- big_randomSVD(X, fun.scaling = fun)
obj.svd2 &lt;- big_randomSVD(X, fun.scaling = big_scale())
all.equal(obj.svd, obj.svd2)

</code></pre>

<hr>
<h2 id='asPlotlyText'>Plotly text</h2><span id='topic+asPlotlyText'></span>

<h3>Description</h3>

<p>Convert a data.frame to plotly text
</p>


<h3>Usage</h3>

<pre><code class='language-R'>asPlotlyText(df)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="asPlotlyText_+3A_df">df</code></td>
<td>
<p>A data.frame</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character vector of the length of <code>df</code>'s number of rows.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)

X &lt;- big_attachExtdata()
svd &lt;- big_SVD(X, big_scale(), k = 10)

p &lt;- plot(svd, type = "scores")

pop &lt;- rep(c("POP1", "POP2", "POP3"), c(143, 167, 207))
df &lt;- data.frame(Population = pop, Index = 1:517)

plot(p2 &lt;- p + ggplot2::aes(text = asPlotlyText(df)))
## Not run: plotly::ggplotly(p2, tooltip = "text")
</code></pre>

<hr>
<h2 id='AUC'>AUC</h2><span id='topic+AUC'></span><span id='topic+AUCBoot'></span>

<h3>Description</h3>

<p>Compute the Area Under the ROC Curve (AUC) of a predictor
and possibly its 95% confidence interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AUC(pred, target, digits = NULL)

AUCBoot(pred, target, nboot = 10000, seed = NA, digits = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AUC_+3A_pred">pred</code></td>
<td>
<p>Vector of predictions.</p>
</td></tr>
<tr><td><code id="AUC_+3A_target">target</code></td>
<td>
<p>Vector of true labels (must have exactly two levels,
no missing values).</p>
</td></tr>
<tr><td><code id="AUC_+3A_digits">digits</code></td>
<td>
<p>See <a href="base.html#topic+round">round</a>. Default doesn't use rounding.</p>
</td></tr>
<tr><td><code id="AUC_+3A_nboot">nboot</code></td>
<td>
<p>Number of bootstrap samples used to evaluate the 95% CI.
Default is <code>1e4</code>.</p>
</td></tr>
<tr><td><code id="AUC_+3A_seed">seed</code></td>
<td>
<p>See <a href="base.html#topic+set.seed">set.seed</a>. Use it for reproducibility.
Default doesn't set any seed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Other packages provide ways to compute the AUC (see this
<a href="https://stats.stackexchange.com/a/146174/135793">answer</a>).
I chose to compute the AUC through its statistical definition as a
probability: </p>
<p style="text-align: center;"><code class="reqn">P(score(x_{case}) &gt; score(x_{control})).</code>
</p>

<p>Note that I consider equality between scores as a 50%-probability of
one being greater than the other.
</p>


<h3>Value</h3>

<p>The AUC, a probability, and possibly its 2.5% and 97.5% quantiles
(95% CI).
</p>


<h3>See Also</h3>

<p><a href="stats.html#topic+wilcox.test">wilcox.test</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)

AUC(c(0, 0), 0:1) # Equality of scores
AUC(c(0.2, 0.1, 1), c(0, 0, 1)) # Perfect AUC
x &lt;- rnorm(100)
z &lt;- rnorm(length(x), x, abs(x))
y &lt;- as.numeric(z &gt; 0)
print(AUC(x, y))
print(AUCBoot(x, y))

# Partial AUC
pAUC &lt;- function(pred, target, p = 0.1) {
  val.min &lt;- min(target)
  q &lt;- quantile(pred[target == val.min], probs = 1 - p)
  ind &lt;- (target != val.min) | (pred &gt; q)
  bigstatsr::AUC(pred[ind], target[ind]) * p
}
pAUC(x, y)
pAUC(x, y, 0.2)
</code></pre>

<hr>
<h2 id='big_apply'>Split-Apply-Combine</h2><span id='topic+big_apply'></span>

<h3>Description</h3>

<p>A Split-Apply-Combine strategy to apply common R functions to a
Filebacked Big Matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_apply(
  X,
  a.FUN,
  a.combine = NULL,
  ind = cols_along(X),
  ncores = 1,
  block.size = block_size(nrow(X), ncores),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big_apply_+3A_x">X</code></td>
<td>
<p>An object of class <a href="#topic+FBM-class">FBM</a>.</p>
</td></tr>
<tr><td><code id="big_apply_+3A_a.fun">a.FUN</code></td>
<td>
<p>The function to be applied to each subset matrix.
It must take a <a href="#topic+FBM-class">Filebacked Big Matrix</a> as first argument and
<code>ind</code>, a vector of indices, which are used to split the data.
For example, if you want to apply a function to <code>X[ind.row, ind.col]</code>,
you may use <code>X[ind.row, ind.col[ind]]</code> in <code>a.FUN</code>.</p>
</td></tr>
<tr><td><code id="big_apply_+3A_a.combine">a.combine</code></td>
<td>
<p>Function to combine the results with <code>do.call</code>.
This function should accept multiple arguments (<code>...</code>). For example, you
can use <code>c</code>, <code>cbind</code>, <code>rbind</code>. This package also provides function <code>plus</code>
to add multiple arguments together. The default is <code>NULL</code>, in which case
the results are not combined and are returned as a list, each element being
the result of a block.</p>
</td></tr>
<tr><td><code id="big_apply_+3A_ind">ind</code></td>
<td>
<p>Initial vector of subsetting indices.
Default is the vector of all column indices.</p>
</td></tr>
<tr><td><code id="big_apply_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use <a href="#topic+nb_cores">nb_cores</a>.</p>
</td></tr>
<tr><td><code id="big_apply_+3A_block.size">block.size</code></td>
<td>
<p>Maximum number of columns (or rows, depending on how you
use <code>ind</code> for subsetting) read at once. Default uses <a href="#topic+block_size">block_size</a>.</p>
</td></tr>
<tr><td><code id="big_apply_+3A_...">...</code></td>
<td>
<p>Extra arguments to be passed to <code>a.FUN</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function splits indices in parts, then apply a given function to each
subset matrix and finally combine the results. If parallelization is used,
this function splits indices in parts for parallelization, then split again
them on each core, apply a given function to each part and finally combine
the results (on each cluster and then from each cluster).
See also <a href="https://privefl.github.io/bigstatsr/articles/big-apply.html">the corresponding vignette</a>.
</p>


<h3>See Also</h3>

<p><a href="#topic+big_parallelize">big_parallelize</a> <a href="bigparallelr.html#topic+split_parapply">bigparallelr::split_parapply</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- big_attachExtdata()

# get the means of each column
colMeans_sub &lt;- function(X, ind) colMeans(X[, ind])
str(colmeans &lt;- big_apply(X, a.FUN = colMeans_sub, a.combine = 'c'))

# get the norms of each column
colNorms_sub &lt;- function(X, ind) sqrt(colSums(X[, ind]^2))
str(colnorms &lt;- big_apply(X, colNorms_sub, a.combine = 'c'))

# get the sums of each row
# split along rows: need to change the "complete" `ind` parameter
str(rowsums &lt;- big_apply(X, a.FUN = function(X, ind) rowSums(X[ind, ]),
                         ind = rows_along(X), a.combine = 'c',
                         block.size = 100))
# it is usually preferred to split along columns
# because matrices are stored by column.
str(rowsums2 &lt;- big_apply(X, a.FUN = function(X, ind) rowSums(X[, ind]),
                          a.combine = 'plus'))
</code></pre>

<hr>
<h2 id='big_attach'>Attach a Filebacked Big Matrix</h2><span id='topic+big_attach'></span><span id='topic+big_attachExtdata'></span>

<h3>Description</h3>

<p>Attach a Filebacked Big Matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_attach(rdsfile)

big_attachExtdata()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big_attach_+3A_rdsfile">rdsfile</code></td>
<td>
<p>Path to a &quot;.rds&quot; file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <a href="#topic+FBM">FBM</a> object stored in the rdsfile.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># temporary FBM
X &lt;- FBM(10, 10)$save()

rdsfile &lt;- sub_bk(X$backingfile, ".rds")
X2 &lt;- big_attach(rdsfile)

all.equal(X[], X2[])
</code></pre>

<hr>
<h2 id='big_colstats'>Standard univariate statistics</h2><span id='topic+big_colstats'></span>

<h3>Description</h3>

<p>Standard <strong>univariate statistics</strong> for columns of a Filebacked Big Matrix.
For now, the <code>sum</code> and <code>var</code> are implemented
(the <code>mean</code> and <code>sd</code> can easily be deduced, see examples).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_colstats(X, ind.row = rows_along(X), ind.col = cols_along(X), ncores = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big_colstats_+3A_x">X</code></td>
<td>
<p>An object of class <a href="#topic+FBM-class">FBM</a>.</p>
</td></tr>
<tr><td><code id="big_colstats_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices that are used.
If not specified, all rows are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_colstats_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices that are used.
If not specified, all columns are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_colstats_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use <a href="#topic+nb_cores">nb_cores</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data.frame of two numeric vectors <code>sum</code> and <code>var</code> with the
corresponding column statistics.
</p>


<h3>See Also</h3>

<p><a href="Matrix.html#topic+colSums">colSums</a> <a href="base.html#topic+apply">apply</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)

X &lt;- big_attachExtdata()

# Check the results
str(test &lt;- big_colstats(X))

# Only with the first 100 rows
ind &lt;- 1:100
str(test2 &lt;- big_colstats(X, ind.row = ind))
plot(test$sum, test2$sum)
abline(lm(test2$sum ~ test$sum), col = "red", lwd = 2)

X.ind &lt;- X[ind, ]
all.equal(test2$sum, colSums(X.ind))
all.equal(test2$var, apply(X.ind, 2, var))

# deduce mean and sd
# note that the are also implemented in big_scale()
means &lt;- test2$sum / length(ind) # if using all rows,
                                 # divide by nrow(X) instead
all.equal(means, colMeans(X.ind))
sds &lt;- sqrt(test2$var)
all.equal(sds, apply(X.ind, 2, sd))
</code></pre>

<hr>
<h2 id='big_copy'>Copy as a Filebacked Big Matrix</h2><span id='topic+big_copy'></span>

<h3>Description</h3>

<p>Deep copy of a Filebacked Big Matrix with possible subsetting.
This should also work for any matrix-like object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_copy(
  X,
  ind.row = rows_along(X),
  ind.col = cols_along(X),
  type = typeof(X),
  backingfile = tempfile(tmpdir = getOption("FBM.dir")),
  block.size = block_size(length(ind.row)),
  is_read_only = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big_copy_+3A_x">X</code></td>
<td>
<p>Could be any matrix-like object.</p>
</td></tr>
<tr><td><code id="big_copy_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices that are used.
If not specified, all rows are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_copy_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices that are used.
If not specified, all columns are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_copy_+3A_type">type</code></td>
<td>
<p>Type of the Filebacked Big Matrix (default is <code>double</code>). Either
</p>

<ul>
<li> <p><code>"double"</code> (double precision &ndash; 64 bits)
</p>
</li>
<li> <p><code>"float"</code> (single precision &ndash; 32 bits)
</p>
</li>
<li> <p><code>"integer"</code>
</p>
</li>
<li> <p><code>"unsigned short"</code>: can store integer values from 0 to 65535.
It has vocation to become the basis for a <code>FBM.code65536</code>.
</p>
</li>
<li> <p><code>"raw"</code> or <code>"unsigned char"</code>: can store integer values from 0 to 255.
It is the basis for class <a href="#topic+FBM.code256-class">FBM.code256</a> in order to
access 256 arbitrary different numeric values.
It is used in <a href="https://goo.gl/pHCCmo">package <strong>bigsnpr</strong></a>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="big_copy_+3A_backingfile">backingfile</code></td>
<td>
<p>Path to the file storing the Big Matrix on disk.
<strong>An extension &quot;.bk&quot; will be automatically added.</strong>
Default stores in the temporary directory.</p>
</td></tr>
<tr><td><code id="big_copy_+3A_block.size">block.size</code></td>
<td>
<p>Maximum number of columns read at once.
Default uses <a href="#topic+block_size">block_size</a>.</p>
</td></tr>
<tr><td><code id="big_copy_+3A_is_read_only">is_read_only</code></td>
<td>
<p>Whether the FBM is read-only? Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A copy of <code>X</code> as a new <a href="#topic+FBM-class">FBM</a> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- FBM(10, 10, init = 1:100)
X[]
X2 &lt;- big_copy(X, ind.row = 1:5)
X2[]

mat &lt;- matrix(101:200, 10)
X3 &lt;- big_copy(mat, type = "double")  # as_FBM() would be faster here
X3[]

X.code &lt;- big_attachExtdata()
class(X.code)
X2.code &lt;- big_copy(X.code)
class(X2.code)
all.equal(X.code[], X2.code[])

</code></pre>

<hr>
<h2 id='big_cor'>Correlation</h2><span id='topic+big_cor'></span>

<h3>Description</h3>

<p>Compute the (Pearson) correlation matrix of a Filebacked Big Matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_cor(
  X,
  ind.row = rows_along(X),
  ind.col = cols_along(X),
  block.size = block_size(nrow(X))
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big_cor_+3A_x">X</code></td>
<td>
<p>An object of class <a href="#topic+FBM-class">FBM</a>.</p>
</td></tr>
<tr><td><code id="big_cor_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices that are used.
If not specified, all rows are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_cor_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices that are used.
If not specified, all columns are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_cor_+3A_block.size">block.size</code></td>
<td>
<p>Maximum number of columns read at once.
Default uses <a href="#topic+block_size">block_size</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A temporary <a href="#topic+FBM-class">FBM</a>, with the following two attributes:
</p>

<ul>
<li><p> a numeric vector <code>center</code> of column scaling,
</p>
</li>
<li><p> a numeric vector <code>scale</code> of column scaling.
</p>
</li></ul>



<h3>Matrix parallelization</h3>

<p>Large matrix computations are made block-wise and won't be parallelized
in order to not have to reduce the size of these blocks.
Instead, you may use <a href="https://mran.microsoft.com/open/">Microsoft R Open</a>
or OpenBLAS in order to accelerate these block matrix computations.
You can also control the number of cores used with
<code>bigparallelr::set_blas_ncores()</code>.
</p>


<h3>See Also</h3>

<p><a href="stats.html#topic+cor">cor</a> <a href="#topic+big_crossprodSelf">big_crossprodSelf</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- FBM(13, 17, init = rnorm(221))

# Comparing with cor
K &lt;- big_cor(X)
class(K)
dim(K)
K$backingfile

true &lt;- cor(X[])
all.equal(K[], true)

# Using only half of the data
n &lt;- nrow(X)
ind &lt;- sort(sample(n, n/2))
K2 &lt;- big_cor(X, ind.row = ind)

true2 &lt;- cor(X[ind, ])
all.equal(K2[], true2)
</code></pre>

<hr>
<h2 id='big_counts'>Counts for class FBM.code256</h2><span id='topic+big_counts'></span>

<h3>Description</h3>

<p>Counts by columns (or rows) the number of each unique element of a
<code>FBM.code256</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_counts(
  X.code,
  ind.row = rows_along(X.code),
  ind.col = cols_along(X.code),
  byrow = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big_counts_+3A_x.code">X.code</code></td>
<td>
<p>An object of class <a href="#topic+FBM.code256-class">FBM.code256</a>.</p>
</td></tr>
<tr><td><code id="big_counts_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices that are used.
If not specified, all rows are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_counts_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices that are used.
If not specified, all columns are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_counts_+3A_byrow">byrow</code></td>
<td>
<p>Count by rows rather than by columns?
Default is <code>FALSE</code> (count by columns).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of counts of K x m (or n) elements, where
</p>

<ul>
<li><p> K is the number of unique elements of the <code>BM.code</code>,
</p>
</li>
<li><p> n is its number of rows,
</p>
</li>
<li><p> m is its number of columns.
</p>
</li></ul>

<p><strong>Beware that K is up to 256. So, if you apply this on a Filebacked Big
Matrix of one million columns, you will create a matrix of nearly 1GB!</strong>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- big_attachExtdata()
class(X)  # big_counts() is available for class FBM.code256 only
X[1:5, 1:8]

# by columns
big_counts(X, ind.row = 1:5, ind.col = 1:8)

# by rows
big_counts(X, ind.row = 1:5, ind.col = 1:8, byrow = TRUE)

</code></pre>

<hr>
<h2 id='big_cprodMat'>Cross-product with a matrix</h2><span id='topic+big_cprodMat'></span><span id='topic+crossprod+2CFBM+2Cmatrix-method'></span><span id='topic+tcrossprod+2CFBM+2Cmatrix-method'></span><span id='topic+crossprod+2Cmatrix+2CFBM-method'></span><span id='topic+tcrossprod+2Cmatrix+2CFBM-method'></span>

<h3>Description</h3>

<p>Cross-product between a Filebacked Big Matrix and a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_cprodMat(
  X,
  A.row,
  ind.row = rows_along(X),
  ind.col = cols_along(X),
  ncores = 1,
  block.size = block_size(nrow(X), ncores),
  center = NULL,
  scale = NULL
)

## S4 method for signature 'FBM,matrix'
crossprod(x, y)

## S4 method for signature 'FBM,matrix'
tcrossprod(x, y)

## S4 method for signature 'matrix,FBM'
crossprod(x, y)

## S4 method for signature 'matrix,FBM'
tcrossprod(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big_cprodMat_+3A_x">X</code></td>
<td>
<p>An object of class <a href="#topic+FBM-class">FBM</a>.</p>
</td></tr>
<tr><td><code id="big_cprodMat_+3A_a.row">A.row</code></td>
<td>
<p>A matrix with <code>length(ind.row)</code> rows.</p>
</td></tr>
<tr><td><code id="big_cprodMat_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices that are used.
If not specified, all rows are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_cprodMat_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices that are used.
If not specified, all columns are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_cprodMat_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use <a href="#topic+nb_cores">nb_cores</a>.</p>
</td></tr>
<tr><td><code id="big_cprodMat_+3A_block.size">block.size</code></td>
<td>
<p>Maximum number of columns read at once.
Default uses <a href="#topic+block_size">block_size</a>.</p>
</td></tr>
<tr><td><code id="big_cprodMat_+3A_center">center</code></td>
<td>
<p>Vector of same length of <code>ind.col</code> to subtract from columns of <code>X</code>.</p>
</td></tr>
<tr><td><code id="big_cprodMat_+3A_scale">scale</code></td>
<td>
<p>Vector of same length of <code>ind.col</code> to divide from columns of <code>X</code>.</p>
</td></tr>
<tr><td><code id="big_cprodMat_+3A_x">x</code></td>
<td>
<p>A 'double' FBM or a matrix.</p>
</td></tr>
<tr><td><code id="big_cprodMat_+3A_y">y</code></td>
<td>
<p>A 'double' FBM or a matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code class="reqn">X^T \cdot A</code>.
</p>


<h3>Matrix parallelization</h3>

<p>Large matrix computations are made block-wise and won't be parallelized
in order to not have to reduce the size of these blocks.
Instead, you may use <a href="https://mran.microsoft.com/open/">Microsoft R Open</a>
or OpenBLAS in order to accelerate these block matrix computations.
You can also control the number of cores used with
<code>bigparallelr::set_blas_ncores()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- big_attachExtdata()
n &lt;- nrow(X)
m &lt;- ncol(X)
A &lt;- matrix(0, n, 10); A[] &lt;- rnorm(length(A))

test &lt;- big_cprodMat(X, A)
true &lt;- crossprod(X[], A)
all.equal(test, true)

X2 &lt;- big_copy(X, type = "double")
all.equal(crossprod(X2, A), true)

# subsetting
ind.row &lt;- sample(n, n/2)
ind.col &lt;- sample(m, m/2)

tryCatch(test2 &lt;- big_cprodMat(X, A, ind.row, ind.col),
         error = function(e) print(e))
# returns an error. You need to use the subset of A:
test2 &lt;- big_cprodMat(X, A[ind.row, ], ind.row, ind.col)
true2 &lt;- crossprod(X[ind.row, ind.col], A[ind.row, ])
all.equal(test2, true2)

</code></pre>

<hr>
<h2 id='big_cprodVec'>Cross-product with a vector</h2><span id='topic+big_cprodVec'></span>

<h3>Description</h3>

<p>Cross-product between a Filebacked Big Matrix and a vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_cprodVec(
  X,
  y.row,
  ind.row = rows_along(X),
  ind.col = cols_along(X),
  center = NULL,
  scale = NULL,
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big_cprodVec_+3A_x">X</code></td>
<td>
<p>An object of class <a href="#topic+FBM-class">FBM</a>.</p>
</td></tr>
<tr><td><code id="big_cprodVec_+3A_y.row">y.row</code></td>
<td>
<p>A vector of same size as <code>ind.row</code>.</p>
</td></tr>
<tr><td><code id="big_cprodVec_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices that are used.
If not specified, all rows are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_cprodVec_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices that are used.
If not specified, all columns are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_cprodVec_+3A_center">center</code></td>
<td>
<p>Vector of same length of <code>ind.col</code> to subtract from columns of <code>X</code>.</p>
</td></tr>
<tr><td><code id="big_cprodVec_+3A_scale">scale</code></td>
<td>
<p>Vector of same length of <code>ind.col</code> to divide from columns of <code>X</code>.</p>
</td></tr>
<tr><td><code id="big_cprodVec_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use <a href="#topic+nb_cores">nb_cores</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code class="reqn">X^T \cdot y</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- big_attachExtdata()
n &lt;- nrow(X)
m &lt;- ncol(X)
y &lt;- rnorm(n)

test &lt;- big_cprodVec(X, y)             # vector
true &lt;- crossprod(X[], y)  # one-column matrix
all.equal(test, as.numeric(true))

# subsetting
ind.row &lt;- sample(n, n/2)
ind.col &lt;- sample(m, m/2)

tryCatch(test2 &lt;- big_cprodVec(X, y, ind.row, ind.col),
         error = function(e) print(e))
# returns an error. You need to use the subset of y:
test2 &lt;- big_cprodVec(X, y[ind.row], ind.row, ind.col)
true2 &lt;- crossprod(X[ind.row, ind.col], y[ind.row])
all.equal(test2, as.numeric(true2))

</code></pre>

<hr>
<h2 id='big_crossprodSelf'>Crossprod</h2><span id='topic+big_crossprodSelf'></span><span id='topic+crossprod+2CFBM+2Cmissing-method'></span>

<h3>Description</h3>

<p>Compute <code class="reqn">X.row^T X.row</code> for a Filebacked Big Matrix <code>X</code>
after applying a particular scaling to it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_crossprodSelf(
  X,
  fun.scaling = big_scale(center = FALSE, scale = FALSE),
  ind.row = rows_along(X),
  ind.col = cols_along(X),
  block.size = block_size(nrow(X))
)

## S4 method for signature 'FBM,missing'
crossprod(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big_crossprodSelf_+3A_x">X</code></td>
<td>
<p>An object of class <a href="#topic+FBM-class">FBM</a>.</p>
</td></tr>
<tr><td><code id="big_crossprodSelf_+3A_fun.scaling">fun.scaling</code></td>
<td>
<p>A function with parameters <code>X</code>, <code>ind.row</code> and <code>ind.col</code>,
and that returns a data.frame with <code style="white-space: pre;">&#8288;$center&#8288;</code> and <code style="white-space: pre;">&#8288;$scale&#8288;</code> for the columns
corresponding to <code>ind.col</code>, to scale each of their elements such as followed:
</p>
<p style="text-align: center;"><code class="reqn">\frac{X_{i,j} - center_j}{scale_j}.</code>
</p>
<p> Default doesn't use any scaling.
You can also provide your own <code>center</code> and <code>scale</code> by using <code><a href="#topic+as_scaling_fun">as_scaling_fun()</a></code>.</p>
</td></tr>
<tr><td><code id="big_crossprodSelf_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices that are used.
If not specified, all rows are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_crossprodSelf_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices that are used.
If not specified, all columns are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_crossprodSelf_+3A_block.size">block.size</code></td>
<td>
<p>Maximum number of columns read at once.
Default uses <a href="#topic+block_size">block_size</a>.</p>
</td></tr>
<tr><td><code id="big_crossprodSelf_+3A_x">x</code></td>
<td>
<p>A 'double' FBM.</p>
</td></tr>
<tr><td><code id="big_crossprodSelf_+3A_y">y</code></td>
<td>
<p>Missing.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A temporary <a href="#topic+FBM-class">FBM</a>, with the following two attributes:
</p>

<ul>
<li><p> a numeric vector <code>center</code> of column scaling,
</p>
</li>
<li><p> a numeric vector <code>scale</code> of column scaling.
</p>
</li></ul>



<h3>Matrix parallelization</h3>

<p>Large matrix computations are made block-wise and won't be parallelized
in order to not have to reduce the size of these blocks.
Instead, you may use <a href="https://mran.microsoft.com/open/">Microsoft R Open</a>
or OpenBLAS in order to accelerate these block matrix computations.
You can also control the number of cores used with
<code>bigparallelr::set_blas_ncores()</code>.
</p>


<h3>See Also</h3>

<p><a href="Matrix.html#topic+crossprod">crossprod</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- FBM(13, 17, init = rnorm(221))
true &lt;- crossprod(X[])

# No scaling
K1 &lt;- crossprod(X)
class(K1)
all.equal(K1, true)

K2 &lt;- big_crossprodSelf(X)
class(K2)
K2$backingfile
all.equal(K2[], true)

# big_crossprodSelf() provides some scaling and subsetting
# Example using only half of the data:
n &lt;- nrow(X)
ind &lt;- sort(sample(n, n/2))
K3 &lt;- big_crossprodSelf(X, fun.scaling = big_scale(), ind.row = ind)
true2 &lt;- crossprod(scale(X[ind, ]))
all.equal(K3[], true2)
</code></pre>

<hr>
<h2 id='big_increment'>Increment an FBM</h2><span id='topic+big_increment'></span>

<h3>Description</h3>

<p>Increment an FBM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_increment(X, add, use_lock = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big_increment_+3A_x">X</code></td>
<td>
<p>An <code>FBM</code> (of type double) to increment.</p>
</td></tr>
<tr><td><code id="big_increment_+3A_add">add</code></td>
<td>
<p>A matrix of same dimensions as <code>X</code>. Or a vector of same size.</p>
</td></tr>
<tr><td><code id="big_increment_+3A_use_lock">use_lock</code></td>
<td>
<p>Whether to use locks when incrementing. Default is <code>FALSE</code>.
This is useful when incrementing in parallel.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns nothing (<code>NULL</code>, invisibly).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- FBM(10, 10, init = 0)
mat &lt;- matrix(rnorm(100), 10, 10)

big_increment(X, mat)
all.equal(X[], mat)

big_increment(X, mat)
all.equal(X[], 2 * mat)

</code></pre>

<hr>
<h2 id='big_parallelize'>Split-parApply-Combine</h2><span id='topic+big_parallelize'></span>

<h3>Description</h3>

<p>A Split-Apply-Combine strategy to parallelize the evaluation of a function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_parallelize(
  X,
  p.FUN,
  p.combine = NULL,
  ind = cols_along(X),
  ncores = nb_cores(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big_parallelize_+3A_x">X</code></td>
<td>
<p>An object of class <a href="#topic+FBM-class">FBM</a>.</p>
</td></tr>
<tr><td><code id="big_parallelize_+3A_p.fun">p.FUN</code></td>
<td>
<p>The function to be applied to each subset matrix.
It must take a <a href="#topic+FBM-class">Filebacked Big Matrix</a> as first argument and
<code>ind</code>, a vector of indices, which are used to split the data.
For example, if you want to apply a function to <code>X[ind.row, ind.col]</code>,
you may use <code>X[ind.row, ind.col[ind]]</code> in <code>a.FUN</code>.</p>
</td></tr>
<tr><td><code id="big_parallelize_+3A_p.combine">p.combine</code></td>
<td>
<p>Function to combine the results with <code>do.call</code>.
This function should accept multiple arguments (<code>...</code>). For example, you
can use <code>c</code>, <code>cbind</code>, <code>rbind</code>. This package also provides function <code>plus</code>
to add multiple arguments together. The default is <code>NULL</code>, in which case
the results are not combined and are returned as a list, each element being
the result of a block.</p>
</td></tr>
<tr><td><code id="big_parallelize_+3A_ind">ind</code></td>
<td>
<p>Initial vector of subsetting indices.
Default is the vector of all column indices.</p>
</td></tr>
<tr><td><code id="big_parallelize_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use <a href="#topic+nb_cores">nb_cores</a>.</p>
</td></tr>
<tr><td><code id="big_parallelize_+3A_...">...</code></td>
<td>
<p>Extra arguments to be passed to <code>p.FUN</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function splits indices in parts, then apply a given function to each
part and finally combine the results.
</p>


<h3>Value</h3>

<p>Return a list of <code>ncores</code> elements, each element being the result of
one of the cores, computed on a block. The elements of this list are then
combined with <code>do.call(p.combine, .)</code> if <code>p.combined</code> is given.
</p>


<h3>See Also</h3>

<p><a href="#topic+big_apply">big_apply</a> <a href="bigparallelr.html#topic+split_parapply">bigparallelr::split_parapply</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  # CRAN is super slow when parallelism.
  X &lt;- big_attachExtdata()

  ### Computation on all the matrix
  true &lt;- big_colstats(X)

  big_colstats_sub &lt;- function(X, ind) {
    big_colstats(X, ind.col = ind)
  }
  # 1. the computation is split along all the columns
  # 2. for each part the computation is done, using `big_colstats`
  # 3. the results (data.frames) are combined via `rbind`.
  test &lt;- big_parallelize(X, p.FUN = big_colstats_sub,
                          p.combine = 'rbind', ncores = 2)
  all.equal(test, true)

  ### Computation on a part of the matrix
  n &lt;- nrow(X)
  m &lt;- ncol(X)
  rows &lt;- sort(sample(n, n/2)) # sort to provide some locality in accesses
  cols &lt;- sort(sample(m, m/2)) # idem

  true2 &lt;- big_colstats(X, ind.row = rows, ind.col = cols)

  big_colstats_sub2 &lt;- function(X, ind, rows, cols) {
    big_colstats(X, ind.row = rows, ind.col = cols[ind])
  }
  # This doesn't work because, by default, the computation is spread
  # along all columns. We must explictly specify the `ind` parameter.
  tryCatch(big_parallelize(X, p.FUN = big_colstats_sub2,
                           p.combine = 'rbind', ncores = 2,
                           rows = rows, cols = cols),
           error = function(e) message(e))

  # This now works, using `ind = seq_along(cols)`.
  test2 &lt;- big_parallelize(X, p.FUN = big_colstats_sub2,
                           p.combine = 'rbind', ncores = 2,
                           ind = seq_along(cols),
                           rows = rows, cols = cols)
  all.equal(test2, true2)


## End(Not run)
</code></pre>

<hr>
<h2 id='big_prodMat'>Product with a matrix</h2><span id='topic+big_prodMat'></span><span id='topic++25+2A+25+2CFBM+2Cmatrix-method'></span><span id='topic++25+2A+25+2Cmatrix+2CFBM-method'></span>

<h3>Description</h3>

<p>Product between a Filebacked Big Matrix and a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_prodMat(
  X,
  A.col,
  ind.row = rows_along(X),
  ind.col = cols_along(X),
  ncores = 1,
  block.size = block_size(nrow(X), ncores),
  center = NULL,
  scale = NULL
)

## S4 method for signature 'FBM,matrix'
x %*% y

## S4 method for signature 'matrix,FBM'
x %*% y
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big_prodMat_+3A_x">X</code></td>
<td>
<p>An object of class <a href="#topic+FBM-class">FBM</a>.</p>
</td></tr>
<tr><td><code id="big_prodMat_+3A_a.col">A.col</code></td>
<td>
<p>A matrix with <code>length(ind.col)</code> rows.</p>
</td></tr>
<tr><td><code id="big_prodMat_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices that are used.
If not specified, all rows are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_prodMat_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices that are used.
If not specified, all columns are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_prodMat_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use <a href="#topic+nb_cores">nb_cores</a>.</p>
</td></tr>
<tr><td><code id="big_prodMat_+3A_block.size">block.size</code></td>
<td>
<p>Maximum number of columns read at once.
Default uses <a href="#topic+block_size">block_size</a>.</p>
</td></tr>
<tr><td><code id="big_prodMat_+3A_center">center</code></td>
<td>
<p>Vector of same length of <code>ind.col</code> to subtract from columns of <code>X</code>.</p>
</td></tr>
<tr><td><code id="big_prodMat_+3A_scale">scale</code></td>
<td>
<p>Vector of same length of <code>ind.col</code> to divide from columns of <code>X</code>.</p>
</td></tr>
<tr><td><code id="big_prodMat_+3A_x">x</code></td>
<td>
<p>A 'double' FBM or a matrix.</p>
</td></tr>
<tr><td><code id="big_prodMat_+3A_y">y</code></td>
<td>
<p>A 'double' FBM or a matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code class="reqn">X \cdot A</code>.
</p>


<h3>Matrix parallelization</h3>

<p>Large matrix computations are made block-wise and won't be parallelized
in order to not have to reduce the size of these blocks.
Instead, you may use <a href="https://mran.microsoft.com/open/">Microsoft R Open</a>
or OpenBLAS in order to accelerate these block matrix computations.
You can also control the number of cores used with
<code>bigparallelr::set_blas_ncores()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- big_attachExtdata()
n &lt;- nrow(X)
m &lt;- ncol(X)
A &lt;- matrix(0, m, 10); A[] &lt;- rnorm(length(A))

test &lt;- big_prodMat(X, A)
true &lt;- X[] %*% A
all.equal(test, true)

X2 &lt;- big_copy(X, type = "double")
all.equal(X2 %*% A, true)

# subsetting
ind.row &lt;- sample(n, n/2)
ind.col &lt;- sample(m, m/2)

tryCatch(test2 &lt;- big_prodMat(X, A, ind.row, ind.col),
         error = function(e) print(e))
# returns an error. You need to use the subset of A:
test2 &lt;- big_prodMat(X, A[ind.col, ], ind.row, ind.col)
true2 &lt;- X[ind.row, ind.col] %*% A[ind.col, ]
all.equal(test2, true2)

</code></pre>

<hr>
<h2 id='big_prodVec'>Product with a vector</h2><span id='topic+big_prodVec'></span>

<h3>Description</h3>

<p>Product between a Filebacked Big Matrix and a vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_prodVec(
  X,
  y.col,
  ind.row = rows_along(X),
  ind.col = cols_along(X),
  center = NULL,
  scale = NULL,
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big_prodVec_+3A_x">X</code></td>
<td>
<p>An object of class <a href="#topic+FBM-class">FBM</a>.</p>
</td></tr>
<tr><td><code id="big_prodVec_+3A_y.col">y.col</code></td>
<td>
<p>A vector of same size as <code>ind.col</code>.</p>
</td></tr>
<tr><td><code id="big_prodVec_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices that are used.
If not specified, all rows are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_prodVec_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices that are used.
If not specified, all columns are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_prodVec_+3A_center">center</code></td>
<td>
<p>Vector of same length of <code>ind.col</code> to subtract from columns of <code>X</code>.</p>
</td></tr>
<tr><td><code id="big_prodVec_+3A_scale">scale</code></td>
<td>
<p>Vector of same length of <code>ind.col</code> to divide from columns of <code>X</code>.</p>
</td></tr>
<tr><td><code id="big_prodVec_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use <a href="#topic+nb_cores">nb_cores</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code class="reqn">X \cdot y</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- big_attachExtdata()
n &lt;- nrow(X)
m &lt;- ncol(X)
y &lt;- rnorm(m)

test &lt;- big_prodVec(X, y)      # vector
true &lt;- X[] %*% y  # one-column matrix
all.equal(test, as.numeric(true))

# subsetting
ind.row &lt;- sample(n, n/2)
ind.col &lt;- sample(m, m/2)

tryCatch(test2 &lt;- big_prodVec(X, y, ind.row, ind.col),
         error = function(e) print(e))
# returns an error. You need to use the subset of y:
test2 &lt;- big_prodVec(X, y[ind.col], ind.row, ind.col)
true2 &lt;- X[ind.row, ind.col] %*% y[ind.col]
all.equal(test2, as.numeric(true2))

</code></pre>

<hr>
<h2 id='big_randomSVD'>Randomized partial SVD</h2><span id='topic+big_randomSVD'></span>

<h3>Description</h3>

<p>An algorithm for partial SVD (or PCA) of a Filebacked Big Matrix based on the
algorithm in RSpectra (by Yixuan Qiu and Jiali Mei).<br />
This algorithm is linear in time in all dimensions and is very
memory-efficient. Thus, it can be used on very large big.matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_randomSVD(
  X,
  fun.scaling = big_scale(center = FALSE, scale = FALSE),
  ind.row = rows_along(X),
  ind.col = cols_along(X),
  k = 10,
  tol = 1e-04,
  verbose = FALSE,
  ncores = 1,
  fun.prod = big_prodVec,
  fun.cprod = big_cprodVec
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big_randomSVD_+3A_x">X</code></td>
<td>
<p>An object of class <a href="#topic+FBM-class">FBM</a>.</p>
</td></tr>
<tr><td><code id="big_randomSVD_+3A_fun.scaling">fun.scaling</code></td>
<td>
<p>A function with parameters <code>X</code>, <code>ind.row</code> and <code>ind.col</code>,
and that returns a data.frame with <code style="white-space: pre;">&#8288;$center&#8288;</code> and <code style="white-space: pre;">&#8288;$scale&#8288;</code> for the columns
corresponding to <code>ind.col</code>, to scale each of their elements such as followed:
</p>
<p style="text-align: center;"><code class="reqn">\frac{X_{i,j} - center_j}{scale_j}.</code>
</p>
<p> Default doesn't use any scaling.
You can also provide your own <code>center</code> and <code>scale</code> by using <code><a href="#topic+as_scaling_fun">as_scaling_fun()</a></code>.</p>
</td></tr>
<tr><td><code id="big_randomSVD_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices that are used.
If not specified, all rows are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_randomSVD_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices that are used.
If not specified, all columns are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_randomSVD_+3A_k">k</code></td>
<td>
<p>Number of singular vectors/values to compute. Default is <code>10</code>.
<strong>This algorithm should be used to compute only a few singular vectors/values.</strong></p>
</td></tr>
<tr><td><code id="big_randomSVD_+3A_tol">tol</code></td>
<td>
<p>Precision parameter of <a href="RSpectra.html#topic+svds">svds</a>. Default is <code>1e-4</code>.</p>
</td></tr>
<tr><td><code id="big_randomSVD_+3A_verbose">verbose</code></td>
<td>
<p>Should some progress be printed? Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="big_randomSVD_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use <a href="#topic+nb_cores">nb_cores</a>.</p>
</td></tr>
<tr><td><code id="big_randomSVD_+3A_fun.prod">fun.prod</code></td>
<td>
<p>Function that takes 6 arguments (in this order):
</p>

<ul>
<li><p> a matrix-like object <code>X</code>,
</p>
</li>
<li><p> a vector <code>x</code>,
</p>
</li>
<li><p> a vector of row indices <code>ind.row</code> of <code>X</code>,
</p>
</li>
<li><p> a vector of column indices <code>ind.col</code> of <code>X</code>,
</p>
</li>
<li><p> a vector of column centers (corresponding to <code>ind.col</code>),
</p>
</li>
<li><p> a vector of column scales (corresponding to <code>ind.col</code>),
and compute the product of <code>X</code> (subsetted and scaled) with <code>x</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="big_randomSVD_+3A_fun.cprod">fun.cprod</code></td>
<td>
<p>Same as <code>fun.prod</code>, but for the <em>transpose</em> of <code>X</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list (an S3 class &quot;big_SVD&quot;) of
</p>

<ul>
<li> <p><code>d</code>, the singular values,
</p>
</li>
<li> <p><code>u</code>, the left singular vectors,
</p>
</li>
<li> <p><code>v</code>, the right singular vectors,
</p>
</li>
<li> <p><code>niter</code>, the number of the iteration of the algorithm,
</p>
</li>
<li> <p><code>nops</code>, number of Matrix-Vector multiplications used,
</p>
</li>
<li> <p><code>center</code>, the centering vector,
</p>
</li>
<li> <p><code>scale</code>, the scaling vector.
</p>
</li></ul>

<p>Note that to obtain the Principal Components, you must use
<a href="#topic+predict.big_SVD">predict</a> on the result. See examples.
</p>


<h3>Note</h3>

<p>The idea of using this Implicitly Restarted Arnoldi Method algorithm
comes from G. Abraham, Y. Qiu, and M. Inouye,
FlashPCA2: principal component analysis of biobank-scale genotype datasets,
bioRxiv: doi: <a href="https://doi.org/10.1101/094714">10.1101/094714</a>.
<br />
It proved to be faster than our implementation of the &quot;blanczos&quot; algorithm
in Rokhlin, V., Szlam, A., &amp; Tygert, M. (2010).
A Randomized Algorithm for Principal Component Analysis.
SIAM Journal on Matrix Analysis and Applications, 31(3), 1100-1124.
doi: <a href="https://doi.org/10.1137/080736417">10.1137/080736417</a>.
</p>


<h3>See Also</h3>

<p><a href="RSpectra.html#topic+svds">svds</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)

X &lt;- big_attachExtdata()
K &lt;- 10

# Using only half of the data for "training"
n &lt;- nrow(X)
ind &lt;- sort(sample(n, n/2))
test &lt;- big_randomSVD(X, fun.scaling = big_scale(), ind.row = ind, k = K)
str(test)

pca &lt;- prcomp(X[ind, ], center = TRUE, scale. = TRUE)

# same scaling
all.equal(test$center, pca$center)
all.equal(test$scale,  pca$scale)

# use this function to predict scores
class(test)
scores &lt;- predict(test)
# scores and loadings are the same or opposite
plot(scores, pca$x[, 1:K])
plot(test$v, pca$rotation[, 1:K])
plot(test$u)
plot(test, type = "scores")

# projecting on new data
ind2 &lt;- setdiff(rows_along(X), ind)
scores.test2 &lt;- predict(test, X, ind.row = ind2)
scores.test3 &lt;- predict(pca, X[-ind, ])
plot(scores.test2, scores.test3[, 1:K])

</code></pre>

<hr>
<h2 id='big_read'>Read a file as FBM</h2><span id='topic+big_read'></span>

<h3>Description</h3>

<p>Read a file as a Filebacked Big Matrix by using package bigreadr.
For a mini-tutorial, please see <a href="https://goo.gl/91oNxU">this vignette</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_read(
  file,
  select,
  filter = NULL,
  type = c("double", "float", "integer", "unsigned short", "unsigned char", "raw"),
  backingfile = drop_ext(file),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big_read_+3A_file">file</code></td>
<td>
<p>File to read.</p>
</td></tr>
<tr><td><code id="big_read_+3A_select">select</code></td>
<td>
<p>Indices of columns to read (sorted).
The length of <code>select</code> will be the number of columns of the resulting FBM.</p>
</td></tr>
<tr><td><code id="big_read_+3A_filter">filter</code></td>
<td>
<p>Vector used to subset the rows of each data frame.</p>
</td></tr>
<tr><td><code id="big_read_+3A_type">type</code></td>
<td>
<p>Type of the Filebacked Big Matrix (default is <code>double</code>). Either
</p>

<ul>
<li> <p><code>"double"</code> (double precision &ndash; 64 bits)
</p>
</li>
<li> <p><code>"float"</code> (single precision &ndash; 32 bits)
</p>
</li>
<li> <p><code>"integer"</code>
</p>
</li>
<li> <p><code>"unsigned short"</code>: can store integer values from 0 to 65535.
It has vocation to become the basis for a <code>FBM.code65536</code>.
</p>
</li>
<li> <p><code>"raw"</code> or <code>"unsigned char"</code>: can store integer values from 0 to 255.
It is the basis for class <a href="#topic+FBM.code256-class">FBM.code256</a> in order to
access 256 arbitrary different numeric values.
It is used in <a href="https://goo.gl/pHCCmo">package <strong>bigsnpr</strong></a>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="big_read_+3A_backingfile">backingfile</code></td>
<td>
<p>Path to the file storing the FBM data on disk.
An extension &quot;.bk&quot; will be automatically added.
Default uses <code>file</code> without its extension.</p>
</td></tr>
<tr><td><code id="big_read_+3A_...">...</code></td>
<td>

<p>Arguments passed on to <code><a href="bigreadr.html#topic+big_fread2">bigreadr::big_fread2</a></code>
</p>

<dl>
<dt><code>nb_parts</code></dt><dd><p>Number of parts in which to split reading (and transforming).
Parts are referring to blocks of selected columns.
Default uses <code>part_size</code> to set a good value.</p>
</dd>
<dt><code>skip</code></dt><dd><p>Number of lines to skip at the beginning of <code>file</code>.</p>
</dd>
<dt><code>progress</code></dt><dd><p>Show progress? Default is <code>FALSE</code>.</p>
</dd>
<dt><code>part_size</code></dt><dd><p>Size of the parts if <code>nb_parts</code> is not supplied.
Default is <code>500 * 1024^2</code> (500 MB).</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>A Filebacked Big Matrix of type <code>type</code> with <code>length(select)</code> columns.
</p>

<hr>
<h2 id='big_scale'>Some scaling functions</h2><span id='topic+big_scale'></span>

<h3>Description</h3>

<p>Some scaling functions for a Filebacked Big Matrix to be used as
the <strong><code>fun.scaling</code></strong> parameter of some functions of this package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_scale(center = TRUE, scale = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big_scale_+3A_center">center</code></td>
<td>
<p>A logical value: whether to return means or 0s.</p>
</td></tr>
<tr><td><code id="big_scale_+3A_scale">scale</code></td>
<td>
<p>A logical value: whether to return standard deviations or 1s.
<strong>You can't use scale without using center.</strong></p>
</td></tr>
</table>


<h3>Details</h3>

<p>One could think about less common scalings, such as for example the
&quot;y-aware&quot; scaling which uses the inverse of betas of column-wise linear
regression as scaling. See <a href="https://goo.gl/8G8WMa">this post</a> for details.
It would be easy to implement it using <code>big_colstats</code> to get column means
and <code>big_univLinReg</code> to get betas (and then inverse them).
</p>


<h3>Value</h3>

<p>A new <strong>function</strong> that returns a data.frame of two vectors
&quot;center&quot; and &quot;scale&quot; which are of the length of <code>ind.col</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+as_scaling_fun">as_scaling_fun</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- big_attachExtdata()

# No scaling
big_noscale &lt;- big_scale(center = FALSE, scale = FALSE)
class(big_noscale) # big_scale returns a new function
str(big_noscale(X))
big_noscale2 &lt;- big_scale(center = FALSE)
str(big_noscale2(X)) # you can't scale without centering

# Centering
big_center &lt;- big_scale(scale = FALSE)
str(big_center(X))
# + scaling
str(big_scale()(X))
</code></pre>

<hr>
<h2 id='big_spLinReg'>Sparse linear regression</h2><span id='topic+big_spLinReg'></span>

<h3>Description</h3>

<p>Fit lasso (or elastic-net) penalized linear regression for a Filebacked
Big Matrix. Covariables can be added (/!\ penalized by default /!\).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_spLinReg(
  X,
  y.train,
  ind.train = rows_along(X),
  ind.col = cols_along(X),
  covar.train = NULL,
  base.train = NULL,
  pf.X = NULL,
  pf.covar = NULL,
  alphas = 1,
  power_scale = 1,
  power_adaptive = 0,
  K = 10,
  ind.sets = NULL,
  nlambda = 200,
  nlam.min = 50,
  n.abort = 10,
  dfmax = 50000,
  warn = TRUE,
  ncores = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big_spLinReg_+3A_x">X</code></td>
<td>
<p>An object of class <a href="#topic+FBM-class">FBM</a>.</p>
</td></tr>
<tr><td><code id="big_spLinReg_+3A_y.train">y.train</code></td>
<td>
<p>Vector of responses, corresponding to <code>ind.train</code>.</p>
</td></tr>
<tr><td><code id="big_spLinReg_+3A_ind.train">ind.train</code></td>
<td>
<p>An optional vector of the row indices that are used,
for the training part. If not specified, all rows are used.
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_spLinReg_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices that are used.
If not specified, all columns are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_spLinReg_+3A_covar.train">covar.train</code></td>
<td>
<p>Matrix of covariables to be added in each model to correct
for confounders (e.g. the scores of PCA), corresponding to <code>ind.train</code>.
Default is <code>NULL</code> and corresponds to only adding an intercept to each model.
You can use <code><a href="#topic+covar_from_df">covar_from_df()</a></code> to convert from a data frame.</p>
</td></tr>
<tr><td><code id="big_spLinReg_+3A_base.train">base.train</code></td>
<td>
<p>Vector of base predictions. Model will be learned starting
from these predictions. This can be useful if you want to previously fit
a model with large-effect variables that you don't want to penalize.</p>
</td></tr>
<tr><td><code id="big_spLinReg_+3A_pf.x">pf.X</code></td>
<td>
<p>A multiplicative factor for the penalty applied to each coefficient.
If supplied, <code>pf.X</code> must be a numeric vector of the same length as <code>ind.col</code>.
Default is all <code>1</code>. The purpose of <code>pf.X</code> is to apply differential
penalization if some coefficients are thought to be more likely than others
to be in the model. Setting SOME to 0 allows to have unpenalized coefficients.</p>
</td></tr>
<tr><td><code id="big_spLinReg_+3A_pf.covar">pf.covar</code></td>
<td>
<p>Same as <code>pf.X</code>, but for <code>covar.train</code>.
You might want to set some to 0 as variables with large effects can mask
small effects in penalized regression.</p>
</td></tr>
<tr><td><code id="big_spLinReg_+3A_alphas">alphas</code></td>
<td>
<p>The elastic-net mixing parameter that controls the relative
contribution from the lasso (l1) and the ridge (l2) penalty. The penalty is
defined as </p>
<p style="text-align: center;"><code class="reqn"> \alpha||\beta||_1 + (1-\alpha)/2||\beta||_2^2.</code>
</p>

<p><code>alpha = 1</code> is the lasso penalty and <code>alpha</code> in between <code>0</code>
(<code>1e-4</code>) and <code>1</code> is the elastic-net penalty. Default is <code>1</code>. <strong>You can
pass multiple values, and only one will be used (optimized by grid-search).</strong></p>
</td></tr>
<tr><td><code id="big_spLinReg_+3A_power_scale">power_scale</code></td>
<td>
<p>When using lasso (alpha = 1), penalization to apply that
is equivalent to scaling genotypes dividing by (standard deviation)^power_scale.
Default is 1 and corresponding to standard scaling. Using 0 would correspond
to using unscaled variables and using 0.5 is Pareto scaling. If you e.g. use
<code>power_scale = c(0, 0.5, 1)</code>, the best value in CMSA will be used
(just like with <code>alphas</code>).</p>
</td></tr>
<tr><td><code id="big_spLinReg_+3A_power_adaptive">power_adaptive</code></td>
<td>
<p>Multiplicative penalty factor to apply to variables
in the form of 1 / m_j^power_adaptive, where m_j is the marginal statistic
for variable j. Default is 0, which effectively disables this option.
If you e.g. use <code>power_adaptive = c(0, 0.5, 1.5)</code>, the best value in CMSA
will be used (just like with <code>alphas</code>).</p>
</td></tr>
<tr><td><code id="big_spLinReg_+3A_k">K</code></td>
<td>
<p>Number of sets used in the Cross-Model Selection and Averaging
(CMSA) procedure. Default is <code>10</code>.</p>
</td></tr>
<tr><td><code id="big_spLinReg_+3A_ind.sets">ind.sets</code></td>
<td>
<p>Integer vectors of values between <code>1</code> and <code>K</code> specifying
which set each index of the training set is in. Default randomly assigns
these values but it can be useful to set this vector for reproducibility,
or if you want to refine the grid-search over <code>alphas</code> using the same sets.</p>
</td></tr>
<tr><td><code id="big_spLinReg_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of lambda values. Default is <code>200</code>.</p>
</td></tr>
<tr><td><code id="big_spLinReg_+3A_nlam.min">nlam.min</code></td>
<td>
<p>Minimum number of lambda values to investigate. Default is <code>50</code>.</p>
</td></tr>
<tr><td><code id="big_spLinReg_+3A_n.abort">n.abort</code></td>
<td>
<p>Number of lambda values for which prediction on the validation
set must decrease before stopping. Default is <code>10</code>.</p>
</td></tr>
<tr><td><code id="big_spLinReg_+3A_dfmax">dfmax</code></td>
<td>
<p>Upper bound for the number of nonzero coefficients. Default is
<code>50e3</code> because, for large data sets, computational burden may be
heavy for models with a large number of nonzero coefficients.</p>
</td></tr>
<tr><td><code id="big_spLinReg_+3A_warn">warn</code></td>
<td>
<p>Whether to warn if some models may not have reached a minimum.
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="big_spLinReg_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use <a href="#topic+nb_cores">nb_cores</a>.</p>
</td></tr>
<tr><td><code id="big_spLinReg_+3A_...">...</code></td>
<td>

<p>Arguments passed on to <code><a href="#topic+COPY_biglasso_main">COPY_biglasso_main</a></code>
</p>

<dl>
<dt><code>lambda.min.ratio</code></dt><dd><p>The smallest value for lambda, <strong>as a fraction of
lambda.max</strong>. Default is <code>.0001</code> if the number of observations is larger than
the number of variables and <code>.001</code> otherwise.</p>
</dd>
<dt><code>eps</code></dt><dd><p>Convergence threshold for inner coordinate descent.
The algorithm iterates until the maximum change in the objective after any
coefficient update is less than <code>eps</code> times the null deviance.
Default value is <code>1e-5</code>.</p>
</dd>
<dt><code>max.iter</code></dt><dd><p>Maximum number of iterations. Default is <code>1000</code>.</p>
</dd>
<dt><code>return.all</code></dt><dd><p>Deprecated. Now always return all models.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>This is a modified version of one function of
<a href="https://github.com/YaohuiZeng/biglasso">package biglasso</a></strong>.
It adds the possibility to train models with covariables and use many
types of <code>FBM</code> (not only <code>double</code> ones).
Yet, it only corresponds to <code>screen = "SSR"</code> (Sequential Strong Rules).
</p>
<p>Also, to remove the choice of the lambda parameter, we introduce the
Cross-Model Selection and Averaging (CMSA) procedure:
</p>

<ol>
<li><p> This function separates the training set in <code>K</code> folds (e.g. 10).
</p>
</li>
<li> <p><strong>In turn</strong>,
</p>

<ul>
<li><p> each fold is considered as an inner validation set and the others
(K - 1) folds form an inner training set,
</p>
</li>
<li><p> the model is trained on the inner training set and the corresponding
predictions (scores) for the inner validation set are computed,
</p>
</li>
<li><p> the vector of scores which maximizes log-likelihood is determined,
</p>
</li>
<li><p> the vector of coefficients corresponding to the previous vector of
scores is chosen.
</p>
</li></ul>

</li>
<li><p> The <code>K</code> resulting vectors of coefficients are then averaged into one final
vector of coefficients.
</p>
</li></ol>



<h3>Value</h3>

<p>Return an object of class <code>big_sp_list</code> (a list of <code>length(alphas)</code>
x <code>K</code>) that has 3 methods <code>predict</code>, <code>summary</code> and <code>plot</code>.
</p>


<h3>References</h3>

<p>Tibshirani, R., Bien, J., Friedman, J., Hastie, T.,
Simon, N., Taylor, J. and Tibshirani, R. J. (2012),
Strong rules for discarding predictors in lasso-type problems.
Journal of the Royal Statistical Society:
Series B (Statistical Methodology), 74: 245-266.
doi: <a href="https://doi.org/10.1111/j.1467-9868.2011.01004.x">10.1111/j.1467-9868.2011.01004.x</a>.
</p>
<p>Zeng, Y., and Breheny, P. (2017). The biglasso Package: A Memory- and
Computation-Efficient Solver for Lasso Model Fitting with Big Data in R.
doi: <a href="https://doi.org/10.32614/RJ-2021-001">10.32614/RJ-2021-001</a>.
</p>
<p>Privé, F., Aschard, H., and Blum, M. G.B. (2019). Efficient implementation of
penalized regression for genetic risk prediction. Genetics, 212: 65-74.
doi: <a href="https://doi.org/10.1534/genetics.119.302019">10.1534/genetics.119.302019</a>.
</p>


<h3>See Also</h3>

<p><a href="glmnet.html#topic+glmnet">glmnet</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)

# simulating some data
N &lt;- 230
M &lt;- 730
X &lt;- FBM(N, M, init = rnorm(N * M, sd = 5))
y &lt;- rowSums(X[, 1:10]) + rnorm(N)
covar &lt;- matrix(rnorm(N * 3), N)

ind.train &lt;- sort(sample(nrow(X), 150))
ind.test &lt;- setdiff(rows_along(X), ind.train)

# fitting model for multiple lambdas and alphas
test &lt;- big_spLinReg(X, y[ind.train], ind.train = ind.train,
                     covar.train = covar[ind.train, ],
                     alphas = c(1, 0.1), K = 3, warn = FALSE)

# peek at the models
plot(test)
summary(test, sort = TRUE)
summary(test, sort = TRUE)$message

# prediction for other data -&gt; only the best alpha is used
summary(test, best.only = TRUE)
pred &lt;- predict(test, X, ind.row = ind.test, covar.row = covar[ind.test, ])
plot(pred, y[ind.test], pch = 20); abline(0, 1, col = "red")
</code></pre>

<hr>
<h2 id='big_spLogReg'>Sparse logistic regression</h2><span id='topic+big_spLogReg'></span>

<h3>Description</h3>

<p>Fit lasso (or elastic-net) penalized logistic regression for a Filebacked
Big Matrix. Covariables can be added (/!\ penalized by default /!\).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_spLogReg(
  X,
  y01.train,
  ind.train = rows_along(X),
  ind.col = cols_along(X),
  covar.train = NULL,
  base.train = NULL,
  pf.X = NULL,
  pf.covar = NULL,
  alphas = 1,
  power_scale = 1,
  power_adaptive = 0,
  K = 10,
  ind.sets = NULL,
  nlambda = 200,
  nlam.min = 50,
  n.abort = 10,
  dfmax = 50000,
  warn = TRUE,
  ncores = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big_spLogReg_+3A_x">X</code></td>
<td>
<p>An object of class <a href="#topic+FBM-class">FBM</a>.</p>
</td></tr>
<tr><td><code id="big_spLogReg_+3A_y01.train">y01.train</code></td>
<td>
<p>Vector of responses, corresponding to <code>ind.train</code>.
<strong>Must be only 0s and 1s.</strong></p>
</td></tr>
<tr><td><code id="big_spLogReg_+3A_ind.train">ind.train</code></td>
<td>
<p>An optional vector of the row indices that are used,
for the training part. If not specified, all rows are used.
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_spLogReg_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices that are used.
If not specified, all columns are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_spLogReg_+3A_covar.train">covar.train</code></td>
<td>
<p>Matrix of covariables to be added in each model to correct
for confounders (e.g. the scores of PCA), corresponding to <code>ind.train</code>.
Default is <code>NULL</code> and corresponds to only adding an intercept to each model.
You can use <code><a href="#topic+covar_from_df">covar_from_df()</a></code> to convert from a data frame.</p>
</td></tr>
<tr><td><code id="big_spLogReg_+3A_base.train">base.train</code></td>
<td>
<p>Vector of base predictions. Model will be learned starting
from these predictions. This can be useful if you want to previously fit
a model with large-effect variables that you don't want to penalize.</p>
</td></tr>
<tr><td><code id="big_spLogReg_+3A_pf.x">pf.X</code></td>
<td>
<p>A multiplicative factor for the penalty applied to each coefficient.
If supplied, <code>pf.X</code> must be a numeric vector of the same length as <code>ind.col</code>.
Default is all <code>1</code>. The purpose of <code>pf.X</code> is to apply differential
penalization if some coefficients are thought to be more likely than others
to be in the model. Setting SOME to 0 allows to have unpenalized coefficients.</p>
</td></tr>
<tr><td><code id="big_spLogReg_+3A_pf.covar">pf.covar</code></td>
<td>
<p>Same as <code>pf.X</code>, but for <code>covar.train</code>.
You might want to set some to 0 as variables with large effects can mask
small effects in penalized regression.</p>
</td></tr>
<tr><td><code id="big_spLogReg_+3A_alphas">alphas</code></td>
<td>
<p>The elastic-net mixing parameter that controls the relative
contribution from the lasso (l1) and the ridge (l2) penalty. The penalty is
defined as </p>
<p style="text-align: center;"><code class="reqn"> \alpha||\beta||_1 + (1-\alpha)/2||\beta||_2^2.</code>
</p>

<p><code>alpha = 1</code> is the lasso penalty and <code>alpha</code> in between <code>0</code>
(<code>1e-4</code>) and <code>1</code> is the elastic-net penalty. Default is <code>1</code>. <strong>You can
pass multiple values, and only one will be used (optimized by grid-search).</strong></p>
</td></tr>
<tr><td><code id="big_spLogReg_+3A_power_scale">power_scale</code></td>
<td>
<p>When using lasso (alpha = 1), penalization to apply that
is equivalent to scaling genotypes dividing by (standard deviation)^power_scale.
Default is 1 and corresponding to standard scaling. Using 0 would correspond
to using unscaled variables and using 0.5 is Pareto scaling. If you e.g. use
<code>power_scale = c(0, 0.5, 1)</code>, the best value in CMSA will be used
(just like with <code>alphas</code>).</p>
</td></tr>
<tr><td><code id="big_spLogReg_+3A_power_adaptive">power_adaptive</code></td>
<td>
<p>Multiplicative penalty factor to apply to variables
in the form of 1 / m_j^power_adaptive, where m_j is the marginal statistic
for variable j. Default is 0, which effectively disables this option.
If you e.g. use <code>power_adaptive = c(0, 0.5, 1.5)</code>, the best value in CMSA
will be used (just like with <code>alphas</code>).</p>
</td></tr>
<tr><td><code id="big_spLogReg_+3A_k">K</code></td>
<td>
<p>Number of sets used in the Cross-Model Selection and Averaging
(CMSA) procedure. Default is <code>10</code>.</p>
</td></tr>
<tr><td><code id="big_spLogReg_+3A_ind.sets">ind.sets</code></td>
<td>
<p>Integer vectors of values between <code>1</code> and <code>K</code> specifying
which set each index of the training set is in. Default randomly assigns
these values but it can be useful to set this vector for reproducibility,
or if you want to refine the grid-search over <code>alphas</code> using the same sets.</p>
</td></tr>
<tr><td><code id="big_spLogReg_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of lambda values. Default is <code>200</code>.</p>
</td></tr>
<tr><td><code id="big_spLogReg_+3A_nlam.min">nlam.min</code></td>
<td>
<p>Minimum number of lambda values to investigate. Default is <code>50</code>.</p>
</td></tr>
<tr><td><code id="big_spLogReg_+3A_n.abort">n.abort</code></td>
<td>
<p>Number of lambda values for which prediction on the validation
set must decrease before stopping. Default is <code>10</code>.</p>
</td></tr>
<tr><td><code id="big_spLogReg_+3A_dfmax">dfmax</code></td>
<td>
<p>Upper bound for the number of nonzero coefficients. Default is
<code>50e3</code> because, for large data sets, computational burden may be
heavy for models with a large number of nonzero coefficients.</p>
</td></tr>
<tr><td><code id="big_spLogReg_+3A_warn">warn</code></td>
<td>
<p>Whether to warn if some models may not have reached a minimum.
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="big_spLogReg_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use <a href="#topic+nb_cores">nb_cores</a>.</p>
</td></tr>
<tr><td><code id="big_spLogReg_+3A_...">...</code></td>
<td>

<p>Arguments passed on to <code><a href="#topic+COPY_biglasso_main">COPY_biglasso_main</a></code>
</p>

<dl>
<dt><code>lambda.min.ratio</code></dt><dd><p>The smallest value for lambda, <strong>as a fraction of
lambda.max</strong>. Default is <code>.0001</code> if the number of observations is larger than
the number of variables and <code>.001</code> otherwise.</p>
</dd>
<dt><code>eps</code></dt><dd><p>Convergence threshold for inner coordinate descent.
The algorithm iterates until the maximum change in the objective after any
coefficient update is less than <code>eps</code> times the null deviance.
Default value is <code>1e-5</code>.</p>
</dd>
<dt><code>max.iter</code></dt><dd><p>Maximum number of iterations. Default is <code>1000</code>.</p>
</dd>
<dt><code>return.all</code></dt><dd><p>Deprecated. Now always return all models.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>This is a modified version of one function of
<a href="https://github.com/YaohuiZeng/biglasso">package biglasso</a></strong>.
It adds the possibility to train models with covariables and use many
types of <code>FBM</code> (not only <code>double</code> ones).
Yet, it only corresponds to <code>screen = "SSR"</code> (Sequential Strong Rules).
</p>
<p>Also, to remove the choice of the lambda parameter, we introduce the
Cross-Model Selection and Averaging (CMSA) procedure:
</p>

<ol>
<li><p> This function separates the training set in <code>K</code> folds (e.g. 10).
</p>
</li>
<li> <p><strong>In turn</strong>,
</p>

<ul>
<li><p> each fold is considered as an inner validation set and the others
(K - 1) folds form an inner training set,
</p>
</li>
<li><p> the model is trained on the inner training set and the corresponding
predictions (scores) for the inner validation set are computed,
</p>
</li>
<li><p> the vector of scores which maximizes log-likelihood is determined,
</p>
</li>
<li><p> the vector of coefficients corresponding to the previous vector of
scores is chosen.
</p>
</li></ul>

</li>
<li><p> The <code>K</code> resulting vectors of coefficients are then averaged into one final
vector of coefficients.
</p>
</li></ol>



<h3>Value</h3>

<p>Return an object of class <code>big_sp_list</code> (a list of <code>length(alphas)</code>
x <code>K</code>) that has 3 methods <code>predict</code>, <code>summary</code> and <code>plot</code>.
</p>


<h3>References</h3>

<p>Tibshirani, R., Bien, J., Friedman, J., Hastie, T.,
Simon, N., Taylor, J. and Tibshirani, R. J. (2012),
Strong rules for discarding predictors in lasso-type problems.
Journal of the Royal Statistical Society:
Series B (Statistical Methodology), 74: 245-266.
doi: <a href="https://doi.org/10.1111/j.1467-9868.2011.01004.x">10.1111/j.1467-9868.2011.01004.x</a>.
</p>
<p>Zeng, Y., and Breheny, P. (2017). The biglasso Package: A Memory- and
Computation-Efficient Solver for Lasso Model Fitting with Big Data in R.
doi: <a href="https://doi.org/10.32614/RJ-2021-001">10.32614/RJ-2021-001</a>.
</p>
<p>Privé, F., Aschard, H., and Blum, M. G.B. (2019). Efficient implementation of
penalized regression for genetic risk prediction. Genetics, 212: 65-74.
doi: <a href="https://doi.org/10.1534/genetics.119.302019">10.1534/genetics.119.302019</a>.
</p>


<h3>See Also</h3>

<p><a href="glmnet.html#topic+glmnet">glmnet</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2)

# simulating some data
N &lt;- 230
M &lt;- 730
X &lt;- FBM(N, M, init = rnorm(N * M, sd = 5))
y01 &lt;- as.numeric((rowSums(X[, 1:10]) + 2 * rnorm(N)) &gt; 0)
covar &lt;- matrix(rnorm(N * 3), N)

ind.train &lt;- sort(sample(nrow(X), 150))
ind.test &lt;- setdiff(rows_along(X), ind.train)

# fitting model for multiple lambdas and alphas
test &lt;- big_spLogReg(X, y01[ind.train], ind.train = ind.train,
                     covar.train = covar[ind.train, ],
                     alphas = c(1, 0.1), K = 3, warn = FALSE)

# peek at the models
plot(test)
summary(test, sort = TRUE)
summary(test, sort = TRUE)$message

# prediction for other data -&gt; only the best alpha is used
summary(test, best.only = TRUE)
pred &lt;- predict(test, X, ind.row = ind.test, covar.row = covar[ind.test, ])
AUC(pred, y01[ind.test])
library(ggplot2)
qplot(pred, fill = as.logical(y01[ind.test]),
      geom = "density", alpha = I(0.4)) +
  labs(fill = "Case?") +
  theme_bigstatsr() +
  theme(legend.position = c(0.52, 0.8))
</code></pre>

<hr>
<h2 id='big_SVD'>Partial SVD</h2><span id='topic+big_SVD'></span>

<h3>Description</h3>

<p>An algorithm for partial SVD (or PCA) of a Filebacked Big Matrix through the
eigen decomposition of the covariance between variables (primal)
or observations (dual). <strong>Use this algorithm only if there is one dimension
that is much smaller than the other. Otherwise use <a href="#topic+big_randomSVD">big_randomSVD</a>.</strong>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_SVD(
  X,
  fun.scaling = big_scale(center = FALSE, scale = FALSE),
  ind.row = rows_along(X),
  ind.col = cols_along(X),
  k = 10,
  block.size = block_size(nrow(X))
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big_SVD_+3A_x">X</code></td>
<td>
<p>An object of class <a href="#topic+FBM-class">FBM</a>.</p>
</td></tr>
<tr><td><code id="big_SVD_+3A_fun.scaling">fun.scaling</code></td>
<td>
<p>A function with parameters <code>X</code>, <code>ind.row</code> and <code>ind.col</code>,
and that returns a data.frame with <code style="white-space: pre;">&#8288;$center&#8288;</code> and <code style="white-space: pre;">&#8288;$scale&#8288;</code> for the columns
corresponding to <code>ind.col</code>, to scale each of their elements such as followed:
</p>
<p style="text-align: center;"><code class="reqn">\frac{X_{i,j} - center_j}{scale_j}.</code>
</p>
<p> Default doesn't use any scaling.
You can also provide your own <code>center</code> and <code>scale</code> by using <code><a href="#topic+as_scaling_fun">as_scaling_fun()</a></code>.</p>
</td></tr>
<tr><td><code id="big_SVD_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices that are used.
If not specified, all rows are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_SVD_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices that are used.
If not specified, all columns are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_SVD_+3A_k">k</code></td>
<td>
<p>Number of singular vectors/values to compute. Default is <code>10</code>.
<strong>This algorithm should be used to compute only a few singular vectors/values.</strong>
If more is needed, have a look at https://stackoverflow.com/a/46380540/6103040.</p>
</td></tr>
<tr><td><code id="big_SVD_+3A_block.size">block.size</code></td>
<td>
<p>Maximum number of columns read at once.
Default uses <a href="#topic+block_size">block_size</a>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To get <code class="reqn">X = U \cdot D \cdot V^T</code>,
</p>

<ul>
<li><p> if the number of observations is small, this function computes
<code class="reqn">K_(2) = X \cdot X^T \approx U \cdot D^2 \cdot U^T</code> and then
<code class="reqn">V = X^T \cdot U \cdot D^{-1}</code>,
</p>
</li>
<li><p> if the number of variable is small, this function computes
<code class="reqn">K_(1) = X^T \cdot X \approx V \cdot D^2 \cdot V^T</code> and then
<code class="reqn">U = X \cdot V \cdot D^{-1}</code>,
</p>
</li>
<li><p> if both dimensions are large, use <a href="#topic+big_randomSVD">big_randomSVD</a> instead.
</p>
</li></ul>



<h3>Value</h3>

<p>A named list (an S3 class &quot;big_SVD&quot;) of
</p>

<ul>
<li> <p><code>d</code>, the singular values,
</p>
</li>
<li> <p><code>u</code>, the left singular vectors,
</p>
</li>
<li> <p><code>v</code>, the right singular vectors,
</p>
</li>
<li> <p><code>center</code>, the centering vector,
</p>
</li>
<li> <p><code>scale</code>, the scaling vector.
</p>
</li></ul>

<p>Note that to obtain the Principal Components, you must use
<a href="#topic+predict.big_SVD">predict</a> on the result. See examples.
</p>


<h3>Matrix parallelization</h3>

<p>Large matrix computations are made block-wise and won't be parallelized
in order to not have to reduce the size of these blocks.
Instead, you may use <a href="https://mran.microsoft.com/open/">Microsoft R Open</a>
or OpenBLAS in order to accelerate these block matrix computations.
You can also control the number of cores used with
<code>bigparallelr::set_blas_ncores()</code>.
</p>


<h3>See Also</h3>

<p><a href="stats.html#topic+prcomp">prcomp</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)

X &lt;- big_attachExtdata()
n &lt;- nrow(X)

# Using only half of the data
ind &lt;- sort(sample(n, n/2))

test &lt;- big_SVD(X, fun.scaling = big_scale(), ind.row = ind)
str(test)
plot(test$u)

pca &lt;- prcomp(X[ind, ], center = TRUE, scale. = TRUE)

# same scaling
all.equal(test$center, pca$center)
all.equal(test$scale,  pca$scale)

# scores and loadings are the same or opposite
# except for last eigenvalue which is equal to 0
# due to centering of columns
scores &lt;- test$u %*% diag(test$d)
class(test)
scores2 &lt;- predict(test) # use this function to predict scores
all.equal(scores, scores2)
dim(scores)
dim(pca$x)
tail(pca$sdev)
plot(scores2, pca$x[, 1:ncol(scores2)])
plot(test$v[1:100, ], pca$rotation[1:100, 1:ncol(scores2)])

# projecting on new data
X2 &lt;- sweep(sweep(X[-ind, ], 2, test$center, '-'), 2, test$scale, '/')
scores.test &lt;- X2 %*% test$v
ind2 &lt;- setdiff(rows_along(X), ind)
scores.test2 &lt;- predict(test, X, ind.row = ind2) # use this
all.equal(scores.test, scores.test2)
scores.test3 &lt;- predict(pca, X[-ind, ])
plot(scores.test2, scores.test3[, 1:ncol(scores.test2)])
</code></pre>

<hr>
<h2 id='big_tcrossprodSelf'>Tcrossprod</h2><span id='topic+big_tcrossprodSelf'></span><span id='topic+tcrossprod+2CFBM+2Cmissing-method'></span>

<h3>Description</h3>

<p>Compute <code class="reqn">X.row X.row^T</code> for a Filebacked Big Matrix <code>X</code>
after applying a particular scaling to it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_tcrossprodSelf(
  X,
  fun.scaling = big_scale(center = FALSE, scale = FALSE),
  ind.row = rows_along(X),
  ind.col = cols_along(X),
  block.size = block_size(nrow(X))
)

## S4 method for signature 'FBM,missing'
tcrossprod(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big_tcrossprodSelf_+3A_x">X</code></td>
<td>
<p>An object of class <a href="#topic+FBM-class">FBM</a>.</p>
</td></tr>
<tr><td><code id="big_tcrossprodSelf_+3A_fun.scaling">fun.scaling</code></td>
<td>
<p>A function with parameters <code>X</code>, <code>ind.row</code> and <code>ind.col</code>,
and that returns a data.frame with <code style="white-space: pre;">&#8288;$center&#8288;</code> and <code style="white-space: pre;">&#8288;$scale&#8288;</code> for the columns
corresponding to <code>ind.col</code>, to scale each of their elements such as followed:
</p>
<p style="text-align: center;"><code class="reqn">\frac{X_{i,j} - center_j}{scale_j}.</code>
</p>
<p> Default doesn't use any scaling.
You can also provide your own <code>center</code> and <code>scale</code> by using <code><a href="#topic+as_scaling_fun">as_scaling_fun()</a></code>.</p>
</td></tr>
<tr><td><code id="big_tcrossprodSelf_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices that are used.
If not specified, all rows are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_tcrossprodSelf_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices that are used.
If not specified, all columns are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_tcrossprodSelf_+3A_block.size">block.size</code></td>
<td>
<p>Maximum number of columns read at once.
Default uses <a href="#topic+block_size">block_size</a>.</p>
</td></tr>
<tr><td><code id="big_tcrossprodSelf_+3A_x">x</code></td>
<td>
<p>A 'double' FBM.</p>
</td></tr>
<tr><td><code id="big_tcrossprodSelf_+3A_y">y</code></td>
<td>
<p>Missing.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A temporary <a href="#topic+FBM-class">FBM</a>, with the following two attributes:
</p>

<ul>
<li><p> a numeric vector <code>center</code> of column scaling,
</p>
</li>
<li><p> a numeric vector <code>scale</code> of column scaling.
</p>
</li></ul>



<h3>Matrix parallelization</h3>

<p>Large matrix computations are made block-wise and won't be parallelized
in order to not have to reduce the size of these blocks.
Instead, you may use <a href="https://mran.microsoft.com/open/">Microsoft R Open</a>
or OpenBLAS in order to accelerate these block matrix computations.
You can also control the number of cores used with
<code>bigparallelr::set_blas_ncores()</code>.
</p>


<h3>See Also</h3>

<p><a href="Matrix.html#topic+tcrossprod">tcrossprod</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- FBM(13, 17, init = rnorm(221))
true &lt;- tcrossprod(X[])

# No scaling
K1 &lt;- tcrossprod(X)
class(K1)
all.equal(K1, true)

K2 &lt;- big_tcrossprodSelf(X)
class(K2)
K2$backingfile
all.equal(K2[], true)

# big_tcrossprodSelf() provides some scaling and subsetting
# Example using only half of the data:
n &lt;- nrow(X)
ind &lt;- sort(sample(n, n/2))
K3 &lt;- big_tcrossprodSelf(X, fun.scaling = big_scale(), ind.row = ind)
true2 &lt;- tcrossprod(scale(X[ind, ]))
all.equal(K3[], true2)
</code></pre>

<hr>
<h2 id='big_transpose'>Transpose an FBM</h2><span id='topic+big_transpose'></span>

<h3>Description</h3>

<p>This function implements a simple cache-oblivious algorithm for
the transposition of a Filebacked Big Matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_transpose(X, backingfile = tempfile(tmpdir = getOption("FBM.dir")))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big_transpose_+3A_x">X</code></td>
<td>
<p>An object of class <a href="#topic+FBM-class">FBM</a>.</p>
</td></tr>
<tr><td><code id="big_transpose_+3A_backingfile">backingfile</code></td>
<td>
<p>Path to the file storing the Big Matrix on disk.
<strong>An extension &quot;.bk&quot; will be automatically added.</strong>
Default stores in the temporary directory.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The new transposed FBM. Dimensions and type are automatically
determined from the input FBM.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- FBM(6, 5, init = rnorm(30))
X[]
Xt &lt;- big_transpose(X)
identical(t(X[]), Xt[])

</code></pre>

<hr>
<h2 id='big_univLinReg'>Column-wise linear regression</h2><span id='topic+big_univLinReg'></span>

<h3>Description</h3>

<p>Slopes of column-wise linear regressions of each column
of a Filebacked Big Matrix, with some other associated statistics.
Covariates can be added to correct for confounders.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_univLinReg(
  X,
  y.train,
  ind.train = rows_along(X),
  ind.col = cols_along(X),
  covar.train = NULL,
  thr.eigval = 1e-04,
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big_univLinReg_+3A_x">X</code></td>
<td>
<p>An object of class <a href="#topic+FBM-class">FBM</a>.</p>
</td></tr>
<tr><td><code id="big_univLinReg_+3A_y.train">y.train</code></td>
<td>
<p>Vector of responses, corresponding to <code>ind.train</code>.</p>
</td></tr>
<tr><td><code id="big_univLinReg_+3A_ind.train">ind.train</code></td>
<td>
<p>An optional vector of the row indices that are used,
for the training part. If not specified, all rows are used.
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_univLinReg_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices that are used.
If not specified, all columns are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_univLinReg_+3A_covar.train">covar.train</code></td>
<td>
<p>Matrix of covariables to be added in each model to correct
for confounders (e.g. the scores of PCA), corresponding to <code>ind.train</code>.
Default is <code>NULL</code> and corresponds to only adding an intercept to each model.
You can use <code><a href="#topic+covar_from_df">covar_from_df()</a></code> to convert from a data frame.</p>
</td></tr>
<tr><td><code id="big_univLinReg_+3A_thr.eigval">thr.eigval</code></td>
<td>
<p>Threshold to remove &quot;insignificant&quot; singular vectors.
Default is <code>1e-4</code>.</p>
</td></tr>
<tr><td><code id="big_univLinReg_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use <a href="#topic+nb_cores">nb_cores</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame with 3 elements:
</p>

<ol>
<li><p> the slopes of each regression,
</p>
</li>
<li><p> the standard errors of each slope,
</p>
</li>
<li><p> the t-scores associated with each slope.
This is also an object of class <code>mhtest</code>. See <code>methods(class = "mhtest")</code>.
</p>
</li></ol>



<h3>See Also</h3>

<p><a href="stats.html#topic+lm">lm</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)

X &lt;- big_attachExtdata()
n &lt;- nrow(X)
y &lt;- rnorm(n)
covar &lt;- matrix(rnorm(n * 3), n)

X1 &lt;- X[, 1] # only first column of the Filebacked Big Matrix

# Without covar
test &lt;- big_univLinReg(X, y)
## New class `mhtest`
class(test)
attr(test, "transfo")
attr(test, "predict")
## plot results
plot(test)
plot(test, type = "Volcano")
## To get p-values associated with the test
test$p.value &lt;- predict(test, log10 = FALSE)
str(test)
summary(lm(y ~ X1))$coefficients[2, ]

# With all data
str(big_univLinReg(X, y, covar = covar))
summary(lm(y ~ X1 + covar))$coefficients[2, ]

# With only half of the data
ind.train &lt;- sort(sample(n, n/2))
str(big_univLinReg(X, y[ind.train],
                   covar.train = covar[ind.train, ],
                   ind.train = ind.train))
summary(lm(y ~ X1 + covar, subset = ind.train))$coefficients[2, ]
</code></pre>

<hr>
<h2 id='big_univLogReg'>Column-wise logistic regression</h2><span id='topic+big_univLogReg'></span>

<h3>Description</h3>

<p>Slopes of column-wise logistic regressions of each column
of a Filebacked Big Matrix, with some other associated statistics.
Covariates can be added to correct for confounders.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_univLogReg(
  X,
  y01.train,
  ind.train = rows_along(X),
  ind.col = cols_along(X),
  covar.train = NULL,
  tol = 1e-08,
  maxiter = 20,
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big_univLogReg_+3A_x">X</code></td>
<td>
<p>An object of class <a href="#topic+FBM-class">FBM</a>.</p>
</td></tr>
<tr><td><code id="big_univLogReg_+3A_y01.train">y01.train</code></td>
<td>
<p>Vector of responses, corresponding to <code>ind.train</code>.
<strong>Must be only 0s and 1s.</strong></p>
</td></tr>
<tr><td><code id="big_univLogReg_+3A_ind.train">ind.train</code></td>
<td>
<p>An optional vector of the row indices that are used,
for the training part. If not specified, all rows are used.
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_univLogReg_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices that are used.
If not specified, all columns are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_univLogReg_+3A_covar.train">covar.train</code></td>
<td>
<p>Matrix of covariables to be added in each model to correct
for confounders (e.g. the scores of PCA), corresponding to <code>ind.train</code>.
Default is <code>NULL</code> and corresponds to only adding an intercept to each model.
You can use <code><a href="#topic+covar_from_df">covar_from_df()</a></code> to convert from a data frame.</p>
</td></tr>
<tr><td><code id="big_univLogReg_+3A_tol">tol</code></td>
<td>
<p>Relative tolerance to assess convergence of the coefficient.
Default is <code>1e-8</code>.</p>
</td></tr>
<tr><td><code id="big_univLogReg_+3A_maxiter">maxiter</code></td>
<td>
<p>Maximum number of iterations before giving up.
Default is <code>20</code>. Usually, convergence is reached within 3 or 4 iterations.
If there is not convergence,
<a href="stats.html#topic+glm">glm</a> is used instead for the corresponding column.</p>
</td></tr>
<tr><td><code id="big_univLogReg_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use <a href="#topic+nb_cores">nb_cores</a>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If convergence is not reached by the main algorithm for some columns,
the corresponding <code>niter</code> element is set to <code>NA</code> and a message is given.
Then, <a href="stats.html#topic+glm">glm</a> is used instead for the corresponding column.
If it can't converge either, all corresponding estimations are set to <code>NA</code>.
</p>


<h3>Value</h3>

<p>A data.frame with 4 elements:
</p>

<ol>
<li><p> the slopes of each regression,
</p>
</li>
<li><p> the standard errors of each slope,
</p>
</li>
<li><p> the number of iteration for each slope. If is <code>NA</code>, this means that the
algorithm didn't converge, and <a href="stats.html#topic+glm">glm</a> was used instead.
</p>
</li>
<li><p> the z-scores associated with each slope.
This is also an object of class <code>mhtest</code>. See <code>methods(class = "mhtest")</code>.
</p>
</li></ol>



<h3>See Also</h3>

<p><a href="stats.html#topic+glm">glm</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)

X &lt;- big_attachExtdata()
n &lt;- nrow(X)
y01 &lt;- sample(0:1, size = n, replace = TRUE)
covar &lt;- matrix(rnorm(n * 3), n)

X1 &lt;- X[, 1] # only first column of the Filebacked Big Matrix

# Without covar
test &lt;- big_univLogReg(X, y01)
## new class `mhtest`
class(test)
attr(test, "transfo")
attr(test, "predict")
## plot results
plot(test)
plot(test, type = "Volcano")
## To get p-values associated with the test
test$p.value &lt;- predict(test, log10 = FALSE)
str(test)
summary(glm(y01 ~ X1, family = "binomial"))$coefficients[2, ]

# With all data
str(big_univLogReg(X, y01, covar.train = covar))
summary(glm(y01 ~ X1 + covar, family = "binomial"))$coefficients[2, ]

# With only half of the data
ind.train &lt;- sort(sample(n, n/2))
str(big_univLogReg(X, y01[ind.train],
                   covar.train = covar[ind.train, ],
                   ind.train = ind.train))
summary(glm(y01 ~ X1 + covar, family = "binomial",
            subset = ind.train))$coefficients[2, ]
</code></pre>

<hr>
<h2 id='big_write'>Write an FBM to a file</h2><span id='topic+big_write'></span>

<h3>Description</h3>

<p>Write a file from a Filebacked Big Matrix (by parts).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_write(
  X,
  file,
  every_nrow,
  ...,
  ind.row = rows_along(X),
  ind.col = cols_along(X),
  progress = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big_write_+3A_x">X</code></td>
<td>
<p>An object of class <a href="#topic+FBM-class">FBM</a>.</p>
</td></tr>
<tr><td><code id="big_write_+3A_file">file</code></td>
<td>
<p>File to write to.</p>
</td></tr>
<tr><td><code id="big_write_+3A_every_nrow">every_nrow</code></td>
<td>
<p>Number of rows to write at once.</p>
</td></tr>
<tr><td><code id="big_write_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to <a href="data.table.html#topic+fwrite">data.table::fwrite</a>,
except <code>x</code>, <code>file</code>, <code>append</code>, <code>row.names</code>, <code>col.names</code> and <code>showProgress</code>.</p>
</td></tr>
<tr><td><code id="big_write_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices that are used.
If not specified, all rows are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_write_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices that are used.
If not specified, all columns are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="big_write_+3A_progress">progress</code></td>
<td>
<p>Show progress? Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Input parameter <code>file</code>, invisibly.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- big_attachExtdata()
csv &lt;- big_write(X, tempfile(), every_nrow = 100, progress = interactive())

</code></pre>

<hr>
<h2 id='bigstatsr-package'>bigstatsr: Statistical Tools for Filebacked Big Matrices</h2><span id='topic+bigstatsr'></span><span id='topic+bigstatsr-package'></span>

<h3>Description</h3>

<p>Easy-to-use, efficient, flexible and scalable statistical tools. Package bigstatsr provides and uses Filebacked Big Matrices via memory-mapping. It provides for instance matrix operations, Principal Component Analysis, sparse linear supervised models, utility functions and more &lt;doi:10.1093/bioinformatics/bty185&gt;.
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="bigstatsr-package_+3A_x">X</code></td>
<td>
<p>An object of class <a href="#topic+FBM-class">FBM</a>.</p>
</td></tr>
<tr><td><code id="bigstatsr-package_+3A_x.code">X.code</code></td>
<td>
<p>An object of class <a href="#topic+FBM.code256-class">FBM.code256</a>.</p>
</td></tr>
<tr><td><code id="bigstatsr-package_+3A_y.train">y.train</code></td>
<td>
<p>Vector of responses, corresponding to <code>ind.train</code>.</p>
</td></tr>
<tr><td><code id="bigstatsr-package_+3A_y01.train">y01.train</code></td>
<td>
<p>Vector of responses, corresponding to <code>ind.train</code>.
<strong>Must be only 0s and 1s.</strong></p>
</td></tr>
<tr><td><code id="bigstatsr-package_+3A_ind.train">ind.train</code></td>
<td>
<p>An optional vector of the row indices that are used,
for the training part. If not specified, all rows are used.
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="bigstatsr-package_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices that are used.
If not specified, all rows are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="bigstatsr-package_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices that are used.
If not specified, all columns are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="bigstatsr-package_+3A_block.size">block.size</code></td>
<td>
<p>Maximum number of columns read at once.
Default uses <a href="#topic+block_size">block_size</a>.</p>
</td></tr>
<tr><td><code id="bigstatsr-package_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use <a href="#topic+nb_cores">nb_cores</a>.</p>
</td></tr>
<tr><td><code id="bigstatsr-package_+3A_fun.scaling">fun.scaling</code></td>
<td>
<p>A function with parameters <code>X</code>, <code>ind.row</code> and <code>ind.col</code>,
and that returns a data.frame with <code style="white-space: pre;">&#8288;$center&#8288;</code> and <code style="white-space: pre;">&#8288;$scale&#8288;</code> for the columns
corresponding to <code>ind.col</code>, to scale each of their elements such as followed:
</p>
<p style="text-align: center;"><code class="reqn">\frac{X_{i,j} - center_j}{scale_j}.</code>
</p>
<p> Default doesn't use any scaling.
You can also provide your own <code>center</code> and <code>scale</code> by using <code><a href="#topic+as_scaling_fun">as_scaling_fun()</a></code>.</p>
</td></tr>
<tr><td><code id="bigstatsr-package_+3A_covar.train">covar.train</code></td>
<td>
<p>Matrix of covariables to be added in each model to correct
for confounders (e.g. the scores of PCA), corresponding to <code>ind.train</code>.
Default is <code>NULL</code> and corresponds to only adding an intercept to each model.
You can use <code><a href="#topic+covar_from_df">covar_from_df()</a></code> to convert from a data frame.</p>
</td></tr>
<tr><td><code id="bigstatsr-package_+3A_covar.row">covar.row</code></td>
<td>
<p>Matrix of covariables to be added in each model to correct
for confounders (e.g. the scores of PCA), corresponding to <code>ind.row</code>.
Default is <code>NULL</code> and corresponds to only adding an intercept to each model.
You can use <code><a href="#topic+covar_from_df">covar_from_df()</a></code> to convert from a data frame.</p>
</td></tr>
<tr><td><code id="bigstatsr-package_+3A_center">center</code></td>
<td>
<p>Vector of same length of <code>ind.col</code> to subtract from columns of <code>X</code>.</p>
</td></tr>
<tr><td><code id="bigstatsr-package_+3A_scale">scale</code></td>
<td>
<p>Vector of same length of <code>ind.col</code> to divide from columns of <code>X</code>.</p>
</td></tr>
</table>


<h3>Matrix parallelization</h3>

<p>Large matrix computations are made block-wise and won't be parallelized
in order to not have to reduce the size of these blocks.
Instead, you may use <a href="https://mran.microsoft.com/open/">Microsoft R Open</a>
or OpenBLAS in order to accelerate these block matrix computations.
You can also control the number of cores used with
<code>bigparallelr::set_blas_ncores()</code>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Florian Privé <a href="mailto:florian.prive.21@gmail.com">florian.prive.21@gmail.com</a>
</p>
<p>Other contributors:
</p>

<ul>
<li><p> Michael Blum [thesis advisor]
</p>
</li>
<li><p> Hugues Aschard <a href="mailto:hugues.aschard@pasteur.fr">hugues.aschard@pasteur.fr</a> [thesis advisor]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://privefl.github.io/bigstatsr/">https://privefl.github.io/bigstatsr/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/privefl/bigstatsr/issues">https://github.com/privefl/bigstatsr/issues</a>
</p>
</li></ul>


<hr>
<h2 id='block_size'>Determine a correct value for the block.size parameter</h2><span id='topic+block_size'></span>

<h3>Description</h3>

<p>It determines the value of <code>block.size</code> such that a matrix of doubles of
size <code>n</code> x <code>block.size</code> takes less memory than
<code>getOption("bigstatsr.block.sizeGB")</code> GigaBytes (default is 1GB).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>block_size(n, ncores = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="block_size_+3A_n">n</code></td>
<td>
<p>The number of rows.</p>
</td></tr>
<tr><td><code id="block_size_+3A_ncores">ncores</code></td>
<td>
<p>The number of cores.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An integer &gt;= 1.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>block_size(1e3)
block_size(1e6)
block_size(1e6, 6)
</code></pre>

<hr>
<h2 id='COPY_biglasso_main'>Sparse regression path</h2><span id='topic+COPY_biglasso_main'></span>

<h3>Description</h3>

<p>Fit solution paths for linear or logistic regression models penalized by
lasso (alpha = 1) or elastic-net (1e-4 &lt; alpha &lt; 1) over a grid of values
for the regularization parameter lambda.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>COPY_biglasso_main(
  X,
  y.train,
  ind.train,
  ind.col,
  covar.train,
  family = c("gaussian", "binomial"),
  alphas = 1,
  K = 10,
  ind.sets = NULL,
  nlambda = 200,
  lambda.min.ratio = if (n &gt; p) 1e-04 else 0.001,
  nlam.min = 50,
  n.abort = 10,
  base.train = NULL,
  pf.X = NULL,
  pf.covar = NULL,
  eps = 1e-05,
  max.iter = 1000,
  dfmax = 50000,
  lambda.min = if (n &gt; p) 1e-04 else 0.001,
  power_scale = 1,
  power_adaptive = 0,
  return.all = FALSE,
  warn = TRUE,
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="COPY_biglasso_main_+3A_family">family</code></td>
<td>
<p>Either &quot;gaussian&quot; (linear) or &quot;binomial&quot; (logistic).</p>
</td></tr>
<tr><td><code id="COPY_biglasso_main_+3A_alphas">alphas</code></td>
<td>
<p>The elastic-net mixing parameter that controls the relative
contribution from the lasso (l1) and the ridge (l2) penalty. The penalty is
defined as </p>
<p style="text-align: center;"><code class="reqn"> \alpha||\beta||_1 + (1-\alpha)/2||\beta||_2^2.</code>
</p>

<p><code>alpha = 1</code> is the lasso penalty and <code>alpha</code> in between <code>0</code>
(<code>1e-4</code>) and <code>1</code> is the elastic-net penalty. Default is <code>1</code>. <strong>You can
pass multiple values, and only one will be used (optimized by grid-search).</strong></p>
</td></tr>
<tr><td><code id="COPY_biglasso_main_+3A_k">K</code></td>
<td>
<p>Number of sets used in the Cross-Model Selection and Averaging
(CMSA) procedure. Default is <code>10</code>.</p>
</td></tr>
<tr><td><code id="COPY_biglasso_main_+3A_ind.sets">ind.sets</code></td>
<td>
<p>Integer vectors of values between <code>1</code> and <code>K</code> specifying
which set each index of the training set is in. Default randomly assigns
these values but it can be useful to set this vector for reproducibility,
or if you want to refine the grid-search over <code>alphas</code> using the same sets.</p>
</td></tr>
<tr><td><code id="COPY_biglasso_main_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of lambda values. Default is <code>200</code>.</p>
</td></tr>
<tr><td><code id="COPY_biglasso_main_+3A_lambda.min.ratio">lambda.min.ratio</code></td>
<td>
<p>The smallest value for lambda, <strong>as a fraction of
lambda.max</strong>. Default is <code>.0001</code> if the number of observations is larger than
the number of variables and <code>.001</code> otherwise.</p>
</td></tr>
<tr><td><code id="COPY_biglasso_main_+3A_nlam.min">nlam.min</code></td>
<td>
<p>Minimum number of lambda values to investigate. Default is <code>50</code>.</p>
</td></tr>
<tr><td><code id="COPY_biglasso_main_+3A_n.abort">n.abort</code></td>
<td>
<p>Number of lambda values for which prediction on the validation
set must decrease before stopping. Default is <code>10</code>.</p>
</td></tr>
<tr><td><code id="COPY_biglasso_main_+3A_base.train">base.train</code></td>
<td>
<p>Vector of base predictions. Model will be learned starting
from these predictions. This can be useful if you want to previously fit
a model with large-effect variables that you don't want to penalize.</p>
</td></tr>
<tr><td><code id="COPY_biglasso_main_+3A_pf.x">pf.X</code></td>
<td>
<p>A multiplicative factor for the penalty applied to each coefficient.
If supplied, <code>pf.X</code> must be a numeric vector of the same length as <code>ind.col</code>.
Default is all <code>1</code>. The purpose of <code>pf.X</code> is to apply differential
penalization if some coefficients are thought to be more likely than others
to be in the model. Setting SOME to 0 allows to have unpenalized coefficients.</p>
</td></tr>
<tr><td><code id="COPY_biglasso_main_+3A_pf.covar">pf.covar</code></td>
<td>
<p>Same as <code>pf.X</code>, but for <code>covar.train</code>.
You might want to set some to 0 as variables with large effects can mask
small effects in penalized regression.</p>
</td></tr>
<tr><td><code id="COPY_biglasso_main_+3A_eps">eps</code></td>
<td>
<p>Convergence threshold for inner coordinate descent.
The algorithm iterates until the maximum change in the objective after any
coefficient update is less than <code>eps</code> times the null deviance.
Default value is <code>1e-5</code>.</p>
</td></tr>
<tr><td><code id="COPY_biglasso_main_+3A_max.iter">max.iter</code></td>
<td>
<p>Maximum number of iterations. Default is <code>1000</code>.</p>
</td></tr>
<tr><td><code id="COPY_biglasso_main_+3A_dfmax">dfmax</code></td>
<td>
<p>Upper bound for the number of nonzero coefficients. Default is
<code>50e3</code> because, for large data sets, computational burden may be
heavy for models with a large number of nonzero coefficients.</p>
</td></tr>
<tr><td><code id="COPY_biglasso_main_+3A_lambda.min">lambda.min</code></td>
<td>
<p>This parameter has been renamed <code>lambda.min.ratio</code> and is
now deprecated.</p>
</td></tr>
<tr><td><code id="COPY_biglasso_main_+3A_power_scale">power_scale</code></td>
<td>
<p>When using lasso (alpha = 1), penalization to apply that
is equivalent to scaling genotypes dividing by (standard deviation)^power_scale.
Default is 1 and corresponding to standard scaling. Using 0 would correspond
to using unscaled variables and using 0.5 is Pareto scaling. If you e.g. use
<code>power_scale = c(0, 0.5, 1)</code>, the best value in CMSA will be used
(just like with <code>alphas</code>).</p>
</td></tr>
<tr><td><code id="COPY_biglasso_main_+3A_power_adaptive">power_adaptive</code></td>
<td>
<p>Multiplicative penalty factor to apply to variables
in the form of 1 / m_j^power_adaptive, where m_j is the marginal statistic
for variable j. Default is 0, which effectively disables this option.
If you e.g. use <code>power_adaptive = c(0, 0.5, 1.5)</code>, the best value in CMSA
will be used (just like with <code>alphas</code>).</p>
</td></tr>
<tr><td><code id="COPY_biglasso_main_+3A_return.all">return.all</code></td>
<td>
<p>Deprecated. Now always return all models.</p>
</td></tr>
<tr><td><code id="COPY_biglasso_main_+3A_warn">warn</code></td>
<td>
<p>Whether to warn if some models may not have reached a minimum.
Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The objective function for linear regression (<code>family = "gaussian"</code>) is
</p>
<p style="text-align: center;"><code class="reqn">\frac{1}{2n}\textrm{RSS} + \textrm{penalty},</code>
</p>
<p> for logistic regression
(<code>family = "binomial"</code>) it is </p>
<p style="text-align: center;"><code class="reqn">-\frac{1}{n} loglike +
\textrm{penalty}.</code>
</p>


<hr>
<h2 id='COPY_biglasso_part'>Train one model</h2><span id='topic+COPY_biglasso_part'></span>

<h3>Description</h3>

<p>Train one model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>COPY_biglasso_part(
  X,
  y.train,
  ind.train,
  ind.col,
  covar.train,
  family,
  lambda,
  center,
  scale,
  resid,
  alpha,
  eps,
  max.iter,
  dfmax,
  ind.val,
  covar.val,
  y.val,
  n.abort,
  nlam.min,
  base.train,
  base.val,
  pf
)
</code></pre>


<h3>Value</h3>

<p>A named list with following variables:
</p>
<table>
<tr><td><code>intercept</code></td>
<td>
<p>A vector of intercepts, corresponding to each lambda.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>The vector of coefficients that minimized the loss on the
validation set.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>A vector of length <code>nlambda</code> containing the number of
iterations until convergence at each value of <code>lambda</code>.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The sequence of regularization parameter values in the path.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>Input parameter.</p>
</td></tr>
<tr><td><code>loss</code></td>
<td>
<p>A vector containing either the residual sum of squares
(for linear models) or negative log-likelihood (for logistic models)
of the fitted model at each value of <code>lambda</code>.</p>
</td></tr>
<tr><td><code>loss.val</code></td>
<td>
<p>A vector containing the loss for the corresponding
validation set.</p>
</td></tr>
<tr><td><code>message</code></td>
<td>
<p>Reason the fitting has stopped.</p>
</td></tr>
<tr><td><code>nb_active</code></td>
<td>
<p>The number of active (non-zero) variables along the
regularization path.</p>
</td></tr>
<tr><td><code>nb_candidate</code></td>
<td>
<p>The number of candidate variables (used in the gradient
descent) along the regularization path.</p>
</td></tr>
<tr><td><code>ind.train</code></td>
<td>
<p>Indices of training set.</p>
</td></tr>
</table>

<hr>
<h2 id='covar_from_df'>Numeric matrix from data frame</h2><span id='topic+covar_from_df'></span>

<h3>Description</h3>

<p>Transform a data frame to a numeric matrix by one-hot encoding factors.
The last factor value is always omitted to prevent having a singular matrix
when adding a column of 1s (intercept) in models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>covar_from_df(df)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="covar_from_df_+3A_df">df</code></td>
<td>
<p>A data frame.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mat &lt;- covar_from_df(iris)
head(mat)
</code></pre>

<hr>
<h2 id='Extract'>Create an Implementation of [ For Custom Matrix-Like Types</h2><span id='topic+Extract'></span>

<h3>Description</h3>

<p><code>extract</code> is a function that converts different index types such as negative
integer vectors or logical vectors passed to the <code>[</code> function as <code>i</code>
(e.g. <code>X[i]</code>) or <code>i</code> and <code>j</code> (e.g. <code>X[i, j]</code>) into positive
integer vectors. The converted indices are provided as the <code>i</code> parameter of
<code>extract_vector</code> or <code>i</code> and <code>j</code> parameters of <code>extract_matrix</code> to facilitate
implementing the extraction mechanism for custom matrix-like types.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Extract(extract_vector, extract_matrix)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Extract_+3A_extract_vector">extract_vector</code></td>
<td>
<p>A function in the form of <code style="white-space: pre;">&#8288;function(x, i)&#8288;</code> that takes
a subset of <code>x</code> based on a single vector of indices <code>i</code> and returns a vector.</p>
</td></tr>
<tr><td><code id="Extract_+3A_extract_matrix">extract_matrix</code></td>
<td>
<p>A function in the form of <code style="white-space: pre;">&#8288;function(x, i, j)&#8288;</code> that
takes a subset of <code>x</code> based on two vectors of indices <code>i</code> and <code>j</code> and returns
a matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>This idea initially comes from <a href="https://goo.gl/3RDNQG">package crochet</a>.</strong>
</p>


<h3>Value</h3>

<p>A function in the form of <code style="white-space: pre;">&#8288;function(x, i, j, ..., drop = TRUE)&#8288;</code> that
is meant to be used as a method for <code>[</code> for a custom type.
</p>

<hr>
<h2 id='FBM-class'>Class FBM</h2><span id='topic+FBM-class'></span><span id='topic+FBM_RC'></span><span id='topic+FBM'></span><span id='topic+as_FBM'></span>

<h3>Description</h3>

<p>A reference class for storing and accessing matrix-like data stored in files
on disk. This is very similar to Filebacked Big Matrices provided by the
<strong>bigmemory</strong> package (see <a href="https://privefl.github.io/bigstatsr/articles/bigstatsr-and-bigmemory.html">the corresponding vignette</a>).
</p>
<p>Convert a matrix (or a data frame) to an FBM.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FBM(
  nrow,
  ncol,
  type = c("double", "float", "integer", "unsigned short", "unsigned char", "raw"),
  init = NULL,
  backingfile = tempfile(tmpdir = getOption("FBM.dir")),
  create_bk = TRUE,
  is_read_only = FALSE
)

as_FBM(
  x,
  type = c("double", "float", "integer", "unsigned short", "unsigned char", "raw"),
  backingfile = tempfile(tmpdir = getOption("FBM.dir")),
  is_read_only = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FBM-class_+3A_nrow">nrow</code></td>
<td>
<p>Number of rows.</p>
</td></tr>
<tr><td><code id="FBM-class_+3A_ncol">ncol</code></td>
<td>
<p>Number of columns.</p>
</td></tr>
<tr><td><code id="FBM-class_+3A_type">type</code></td>
<td>
<p>Type of the Filebacked Big Matrix (default is <code>double</code>). Either
</p>

<ul>
<li> <p><code>"double"</code> (double precision &ndash; 64 bits)
</p>
</li>
<li> <p><code>"float"</code> (single precision &ndash; 32 bits)
</p>
</li>
<li> <p><code>"integer"</code>
</p>
</li>
<li> <p><code>"unsigned short"</code>: can store integer values from 0 to 65535.
It has vocation to become the basis for a <code>FBM.code65536</code>.
</p>
</li>
<li> <p><code>"raw"</code> or <code>"unsigned char"</code>: can store integer values from 0 to 255.
It is the basis for class <a href="#topic+FBM.code256-class">FBM.code256</a> in order to
access 256 arbitrary different numeric values.
It is used in <a href="https://goo.gl/pHCCmo">package <strong>bigsnpr</strong></a>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="FBM-class_+3A_init">init</code></td>
<td>
<p>Either a single value (e.g. <code>0</code>) or as many value as the number
of elements of the FBM. <strong>Default doesn't initialize the matrix.</strong></p>
</td></tr>
<tr><td><code id="FBM-class_+3A_backingfile">backingfile</code></td>
<td>
<p>Path to the file storing the Big Matrix on disk.
<strong>An extension &quot;.bk&quot; will be automatically added.</strong>
Default stores in the temporary directory.</p>
</td></tr>
<tr><td><code id="FBM-class_+3A_create_bk">create_bk</code></td>
<td>
<p>Whether to create a backingfile (the default) or use an
existing one (which should be named by the <code>backingfile</code> parameter and have
an extension &quot;.bk&quot;). For example, this could be used to convert a
filebacked <code>big.matrix</code> from package <strong>bigmemory</strong> to a <a href="#topic+FBM-class">FBM</a>
(see <a href="https://privefl.github.io/bigstatsr/articles/bigstatsr-and-bigmemory.html">the corresponding vignette</a>).</p>
</td></tr>
<tr><td><code id="FBM-class_+3A_is_read_only">is_read_only</code></td>
<td>
<p>Whether the FBM is read-only? Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="FBM-class_+3A_x">x</code></td>
<td>
<p>A matrix or an data frame (2-dimensional data).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An object of class FBM has many fields:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;$address&#8288;</code>: address of the external pointer containing the underlying
C++ object for read-only mapping, to be used as a <code style="white-space: pre;">&#8288;XPtr&lt;FBM&gt;&#8288;</code> in C++ code
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$extptr&#8288;</code>: (internal) use <code style="white-space: pre;">&#8288;$address&#8288;</code> instead
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$address_rw&#8288;</code>: address of the external pointer containing the underlying
C++ object for read/write mapping, to be used as a <code style="white-space: pre;">&#8288;XPtr&lt;FBM_RW&gt;&#8288;</code> in C++ code
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$extptr_rw&#8288;</code>: (internal) use <code style="white-space: pre;">&#8288;$address_rw&#8288;</code> instead
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$nrow&#8288;</code>: number of rows
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$ncol&#8288;</code>: number of columns
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$type&#8288;</code>: (internal) use <code>type_size</code> or <code>type_chr</code> instead
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$type_chr&#8288;</code>: FBM type as character, e.g. &quot;double&quot;
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$type_size&#8288;</code>: size of FBM type in bytes (e.g. &quot;double&quot; is 8 and &quot;float&quot; is 4)
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$backingfile&#8288;</code> or <code style="white-space: pre;">&#8288;$bk&#8288;</code>: File with extension 'bk' that stores the numeric
data of the FBM
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$rds&#8288;</code>: 'rds' file (that may not exist) corresponding to the 'bk' file
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$is_saved&#8288;</code>: whether this object is stored in <code style="white-space: pre;">&#8288;$rds&#8288;</code>?
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$is_read_only&#8288;</code>: whether it is (not) allowed to modify data?
</p>
</li></ul>

<p>And some methods:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;$save()&#8288;</code>: Save the FBM object in <code style="white-space: pre;">&#8288;$rds&#8288;</code>. Returns the FBM.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;add_columns(&lt;ncol_add&gt;)&#8288;</code>: Add some columns to the FBM by appending the
backingfile with some data. Returns the FBM invisibly.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$bm()&#8288;</code>: Get this object as a <code>filebacked.big.matrix</code>
to be used by package bigmemory.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$bm.desc()&#8288;</code>: Get this object as a <code>filebacked.big.matrix</code> descriptor
to be used by package bigmemory.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$check_write_permissions()&#8288;</code>: Error if the FBM is read-only.
</p>
</li></ul>



<h3>See Also</h3>

<p><a href="#topic+big_attach">big_attach</a> <a href="#topic+big_copy">big_copy</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mat &lt;- matrix(1:4, 2)
X_from_mat &lt;- as_FBM(mat)

## You can save this object in an .rds file to use it in another session
X_from_mat$is_saved
X_from_mat$save()
X_from_mat$is_saved
(rds &lt;- X_from_mat$rds)
## Use big_attach() to load the FBM object in another session
X_from_mat &lt;- big_attach(rds)

## Standard accessors
X &lt;- FBM(10, 10)
typeof(X)
X[] &lt;- rnorm(length(X))
X[, 1:6]
X[] &lt;- 1:100
X[, 1]
X[1, ]  # not recommended for large matrices
X[, -1]
X[, c(TRUE, FALSE)]
X[cbind(1:10, 1:10)] &lt;- NA_real_

X[]  # access as standard R matrix

X &lt;- FBM(150, 5)
X[] &lt;- iris   ## you can replace with a df (but factors -&gt; integers)
X2 &lt;- as_FBM(iris)
identical(X[], X2[])

</code></pre>

<hr>
<h2 id='FBM-methods'>Methods for the FBM class</h2><span id='topic+FBM-methods'></span><span id='topic++5B+2CFBM+2CANY+2CANY+2CANY-method'></span><span id='topic++5B+3C-+2CFBM+2CANY+2CANY+2CANY-method'></span><span id='topic+dim+2CFBM-method'></span><span id='topic+length+2CFBM-method'></span><span id='topic+typeof+2CFBM-method'></span><span id='topic+diag+2CFBM-method'></span>

<h3>Description</h3>

<p>Methods for the FBM class
</p>
<p>Accessor methods for class <code>FBM</code>. You can use positive and negative indices,
logical indices (that are recycled) and also a matrix of indices (but only
positive ones).
</p>
<p>Dimension and type methods for class <code>FBM</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'FBM,ANY,ANY,ANY'
x[i, j, ..., drop = TRUE]

## S4 replacement method for signature 'FBM,ANY,ANY,ANY'
x[i, j, ...] &lt;- value

## S4 method for signature 'FBM'
dim(x)

## S4 method for signature 'FBM'
length(x)

## S4 method for signature 'FBM'
typeof(x)

## S4 method for signature 'FBM'
diag(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FBM-methods_+3A_x">x</code></td>
<td>
<p>A <a href="#topic+FBM-class">FBM</a> object.</p>
</td></tr>
<tr><td><code id="FBM-methods_+3A_i">i</code></td>
<td>
<p>A vector of indices (or nothing). You can use positive and negative
indices, logical indices (that are recycled) and also a matrix of indices
(but only positive ones).</p>
</td></tr>
<tr><td><code id="FBM-methods_+3A_j">j</code></td>
<td>
<p>A vector of indices (or nothing). You can use positive and negative
indices, logical indices (that are recycled).</p>
</td></tr>
<tr><td><code id="FBM-methods_+3A_...">...</code></td>
<td>
<p>Not used. Just to make <a href="base.html#topic+nargs">nargs</a> work.</p>
</td></tr>
<tr><td><code id="FBM-methods_+3A_drop">drop</code></td>
<td>
<p>Whether to delete the dimensions of a matrix which have
one dimension equals to 1.</p>
</td></tr>
<tr><td><code id="FBM-methods_+3A_value">value</code></td>
<td>
<p>The values to replace. Should be of length 1 or of the same
length of the subset to replace.</p>
</td></tr>
</table>

<hr>
<h2 id='FBM.code256-class'>Class FBM.code256</h2><span id='topic+FBM.code256-class'></span><span id='topic+FBM.code256_RC'></span><span id='topic+FBM.code256'></span><span id='topic+add_code256'></span>

<h3>Description</h3>

<p>A reference class for storing and accessing up to 256 arbitrary different
values using a Filebacked Big Matrix of type <code style="white-space: pre;">&#8288;unsigned char&#8288;</code>. Compared to a
<a href="#topic+FBM-class">Filebacked Big Matrix</a>, it adds a slot <code>code</code> which is used as
a lookup table of size 256.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FBM.code256(
  nrow,
  ncol,
  code = rep(NA_real_, 256),
  init = NULL,
  backingfile = tempfile(tmpdir = getOption("FBM.dir")),
  create_bk = TRUE,
  is_read_only = FALSE
)

add_code256(x, code)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FBM.code256-class_+3A_nrow">nrow</code></td>
<td>
<p>Number of rows.</p>
</td></tr>
<tr><td><code id="FBM.code256-class_+3A_ncol">ncol</code></td>
<td>
<p>Number of columns.</p>
</td></tr>
<tr><td><code id="FBM.code256-class_+3A_code">code</code></td>
<td>
<p>A numeric vector (of length 256).
You should construct it with <code>rep(NA_real_, 256)</code> and then replace the values
which are of interest to you.</p>
</td></tr>
<tr><td><code id="FBM.code256-class_+3A_init">init</code></td>
<td>
<p>Either a single value (e.g. <code>0</code>) or as many value as the number
of elements of the FBM. <strong>Default doesn't initialize the matrix.</strong></p>
</td></tr>
<tr><td><code id="FBM.code256-class_+3A_backingfile">backingfile</code></td>
<td>
<p>Path to the file storing the Big Matrix on disk.
<strong>An extension &quot;.bk&quot; will be automatically added.</strong>
Default stores in the temporary directory.</p>
</td></tr>
<tr><td><code id="FBM.code256-class_+3A_create_bk">create_bk</code></td>
<td>
<p>Whether to create a backingfile (the default) or use an
existing one (which should be named by the <code>backingfile</code> parameter and have
an extension &quot;.bk&quot;). For example, this could be used to convert a
filebacked <code>big.matrix</code> from package <strong>bigmemory</strong> to a <a href="#topic+FBM-class">FBM</a>
(see <a href="https://privefl.github.io/bigstatsr/articles/bigstatsr-and-bigmemory.html">the corresponding vignette</a>).</p>
</td></tr>
<tr><td><code id="FBM.code256-class_+3A_is_read_only">is_read_only</code></td>
<td>
<p>Whether the FBM is read-only? Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="FBM.code256-class_+3A_x">x</code></td>
<td>
<p>A <a href="#topic+FBM-class">FBM</a>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- FBM(10, 10, type = "raw")
X[] &lt;- sample(as.raw(0:3), size = length(X), replace = TRUE)
X[]

# From an FBM of type 'raw' ('unsigned char')
code &lt;- rep(NA_real_, 256)
code[1:3] &lt;- c(1, 3, 5)

X.code &lt;- add_code256(X, code)
X.code[]

# Or directly
X.code2 &lt;- FBM.code256(10, 10, code, init = sample(as.raw(0:3), 100, TRUE))
X.code2[]

# Get a new FBM.code256 object with another code (but same underlying data)
X.code3 &lt;- X.code$copy(code = rnorm(256))
all.equal(X.code$code256, code)

</code></pre>

<hr>
<h2 id='get_beta'>Combine sets of coefficients</h2><span id='topic+get_beta'></span>

<h3>Description</h3>

<p>Combine sets of coefficients
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_beta(betas, method = c("geometric-median", "mean-wise", "median-wise"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_beta_+3A_betas">betas</code></td>
<td>
<p>Matrix of coefficient vectors to be combined.</p>
</td></tr>
<tr><td><code id="get_beta_+3A_method">method</code></td>
<td>
<p>Method for combining vectors of coefficients. The default uses
the <a href="https://en.wikipedia.org/wiki/Geometric_median">geometric median</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of resulting coefficients.
</p>

<hr>
<h2 id='pasteLoc'>Get coordinates on plot</h2><span id='topic+pasteLoc'></span>

<h3>Description</h3>

<p>Get coordinates on a plot by mouse-clicking.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pasteLoc(nb, digits = c(3, 3))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pasteLoc_+3A_nb">nb</code></td>
<td>
<p>Number of positions.</p>
</td></tr>
<tr><td><code id="pasteLoc_+3A_digits">digits</code></td>
<td>
<p>2 integer indicating the number of decimal places
(respectively for x and y coordinates).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of coordinates. Note that if you don't put the result in a
variable, it returns as the command text for generating the list. This can
be useful to get coordinates by mouse-clicking once, but then using the code
for convenience and reproducibility.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
plot(runif(20, max = 5000))
# note the negative number for the rounding of $y
coord &lt;- pasteLoc(3, digits = c(2, -1))
text(coord, c("a", "b", "c"))

## End(Not run)
</code></pre>

<hr>
<h2 id='pcor'>Partial correlation</h2><span id='topic+pcor'></span>

<h3>Description</h3>

<p>Partial correlation between x and y, after having adjusted both for z.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcor(x, y, z, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcor_+3A_x">x</code></td>
<td>
<p>A numeric vector.</p>
</td></tr>
<tr><td><code id="pcor_+3A_y">y</code></td>
<td>
<p>A numeric vector.</p>
</td></tr>
<tr><td><code id="pcor_+3A_z">z</code></td>
<td>
<p>A data frame, which can contain characters or factors.</p>
</td></tr>
<tr><td><code id="pcor_+3A_alpha">alpha</code></td>
<td>
<p>Type-I error for the confidence interval (CI).
Default is <code>0.05</code>, corresponding to a 95% CI.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The partial correlation, and the lower and upper bounds of its CI.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pcor(iris[[1]], iris[[2]], iris[-(1:2)])

</code></pre>

<hr>
<h2 id='plot.big_sp_list'>Plot method</h2><span id='topic+plot.big_sp_list'></span>

<h3>Description</h3>

<p>Plot method for class <code>big_sp_list</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'big_sp_list'
plot(x, coeff = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.big_sp_list_+3A_x">x</code></td>
<td>
<p>An object of class <code>big_sp_list</code>.</p>
</td></tr>
<tr><td><code id="plot.big_sp_list_+3A_coeff">coeff</code></td>
<td>
<p>Relative size of text. Default is <code>1</code>.</p>
</td></tr>
<tr><td><code id="plot.big_sp_list_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>ggplot2</code> object. You can plot it using the <code>print</code> method.
You can modify it as you wish by adding layers. You might want to read
<a href="https://r4ds.had.co.nz/data-visualisation.html">this chapter</a>
to get more familiar with the package <strong>ggplot2</strong>.
</p>

<hr>
<h2 id='plot.big_SVD'>Plot method</h2><span id='topic+plot.big_SVD'></span>

<h3>Description</h3>

<p>Plot method for class <code>big_SVD</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'big_SVD'
plot(
  x,
  type = c("screeplot", "scores", "loadings"),
  nval = length(x$d),
  scores = c(1, 2),
  loadings = 1,
  ncol = NULL,
  coeff = 1,
  viridis = TRUE,
  cols = 2,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.big_SVD_+3A_x">x</code></td>
<td>
<p>An object of class <code>big_SVD</code>.</p>
</td></tr>
<tr><td><code id="plot.big_SVD_+3A_type">type</code></td>
<td>
<p>Either
</p>

<ul>
<li><p> &quot;screeplot&quot;: plot of decreasing singular values (the default).
</p>
</li>
<li><p> &quot;scores&quot;: plot of the scores associated with 2 Principal Components.
</p>
</li>
<li><p> &quot;loadings&quot;: plot of loadings associated with 1 Principal Component.
</p>
</li></ul>
</td></tr>
<tr><td><code id="plot.big_SVD_+3A_nval">nval</code></td>
<td>
<p>Number of singular values to plot. Default plots all computed.</p>
</td></tr>
<tr><td><code id="plot.big_SVD_+3A_scores">scores</code></td>
<td>
<p>Vector of indices of the two PCs to plot. Default plots the
first two PCs. If providing more than two, it produces many plots.</p>
</td></tr>
<tr><td><code id="plot.big_SVD_+3A_loadings">loadings</code></td>
<td>
<p>Indices of PC loadings to plot. Default plots the
first vector of loadings.</p>
</td></tr>
<tr><td><code id="plot.big_SVD_+3A_ncol">ncol</code></td>
<td>
<p>If multiple vector of loadings are to be plotted, this defines
the number of columns of the resulting multiplot.</p>
</td></tr>
<tr><td><code id="plot.big_SVD_+3A_coeff">coeff</code></td>
<td>
<p>Relative size of text. Default is <code>1</code>.</p>
</td></tr>
<tr><td><code id="plot.big_SVD_+3A_viridis">viridis</code></td>
<td>
<p>Deprecated argument.</p>
</td></tr>
<tr><td><code id="plot.big_SVD_+3A_cols">cols</code></td>
<td>
<p>Deprecated. Use <code>ncol</code> instead.</p>
</td></tr>
<tr><td><code id="plot.big_SVD_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>ggplot2</code> object. You can plot it using the <code>print</code> method.
You can modify it as you wish by adding layers. You might want to read
<a href="https://r4ds.had.co.nz/data-visualisation.html">this chapter</a>
to get more familiar with the package <strong>ggplot2</strong>.
</p>


<h3>See Also</h3>

<p><a href="#topic+big_SVD">big_SVD</a>, <a href="#topic+big_randomSVD">big_randomSVD</a> and <a href="#topic+asPlotlyText">asPlotlyText</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)

X &lt;- big_attachExtdata()
svd &lt;- big_SVD(X, big_scale(), k = 10)

# screeplots
plot(svd) # 3 PCs seems "significant"
plot(svd, coeff = 1.5) # larger font for papers

# scores plot
plot(svd, type = "scores") # first 2 PCs
plot(svd, type = "scores", scores = c(1, 3))
plot(svd, type = "scores", scores = 1:4, ncol = 2, coeff = 0.7)
## add color (recall that this return a `ggplot2` object)
class(obj &lt;- plot(svd, type = "scores"))
pop &lt;- rep(c("POP1", "POP2", "POP3"), c(143, 167, 207))
library(ggplot2)
print(obj2 &lt;- obj + aes(color = pop) + labs(color = "Population"))
## change the place of the legend
print(obj3 &lt;- obj2 + theme(legend.position = c(0.82, 0.17)))
## change the title and the labels of the axes
obj3 + ggtitle("Yet another title") + xlab("with an other 'x' label")

# loadings
plot(svd, type = "loadings", loadings = 2)
## all loadings
plot(svd, type = "loadings", loadings = 1:2, coeff = 0.7, ncol = 1)

# Percentage of variance explained by the PCs
# See https://github.com/privefl/bigstatsr/issues/83

# dynamic plots, require the package **plotly**
## Not run: plotly::ggplotly(obj3)
</code></pre>

<hr>
<h2 id='plot.mhtest'>Plot method</h2><span id='topic+plot.mhtest'></span>

<h3>Description</h3>

<p>Plot method for class <code>mhtest</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mhtest'
plot(x, type = c("hist", "Manhattan", "Q-Q", "Volcano"), coeff = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.mhtest_+3A_x">x</code></td>
<td>
<p>An object of class <code>mhtest</code>.</p>
</td></tr>
<tr><td><code id="plot.mhtest_+3A_type">type</code></td>
<td>
<p>Either.
</p>

<ul>
<li><p> &quot;hist&quot;: histogram of p-values (the default).
</p>
</li>
<li><p> &quot;Manhattan&quot;: plot of the negative logarithm (in base 10) of p-values.
</p>
</li>
<li><p> &quot;Q-Q&quot;: Q-Q plot.
</p>
</li>
<li><p> &quot;Volcaco&quot;: plot of the negative logarithm of p-values against the
estimation of coefficients (e.g. betas in linear regression)
</p>
</li></ul>
</td></tr>
<tr><td><code id="plot.mhtest_+3A_coeff">coeff</code></td>
<td>
<p>Relative size of text. Default is <code>1</code>.</p>
</td></tr>
<tr><td><code id="plot.mhtest_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>ggplot2</code> object. You can plot it using the <code>print</code> method.
You can modify it as you wish by adding layers. You might want to read
<a href="https://r4ds.had.co.nz/data-visualisation.html">this chapter</a>
to get more familiar with the package <strong>ggplot2</strong>.
</p>


<h3>See Also</h3>

<p><a href="#topic+big_univLinReg">big_univLinReg</a>, <a href="#topic+big_univLogReg">big_univLogReg</a>,
<a href="#topic+plot.big_SVD">plot.big_SVD</a> and <a href="#topic+asPlotlyText">asPlotlyText</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)

X &lt;- big_attachExtdata()
y &lt;- rnorm(nrow(X))
test &lt;- big_univLinReg(X, y)

plot(test)
plot(test, type = "Volcano")
plot(test, type = "Q-Q")
plot(test, type = "Manhattan")
plot(test, type = "Manhattan") + ggplot2::ggtitle(NULL)

</code></pre>

<hr>
<h2 id='predict.big_sp'>Predict method</h2><span id='topic+predict.big_sp'></span>

<h3>Description</h3>

<p>Predict method for class <code>big_sp</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'big_sp'
predict(object, X, ind.row, ind.col, covar.row = NULL, ncores = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.big_sp_+3A_object">object</code></td>
<td>
<p>Object of class <code>big_sp</code>.</p>
</td></tr>
<tr><td><code id="predict.big_sp_+3A_x">X</code></td>
<td>
<p>An object of class <a href="#topic+FBM-class">FBM</a>.</p>
</td></tr>
<tr><td><code id="predict.big_sp_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices that are used.
If not specified, all rows are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="predict.big_sp_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices that are used.
If not specified, all columns are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="predict.big_sp_+3A_covar.row">covar.row</code></td>
<td>
<p>Matrix of covariables to be added in each model to correct
for confounders (e.g. the scores of PCA), corresponding to <code>ind.row</code>.
Default is <code>NULL</code> and corresponds to only adding an intercept to each model.
You can use <code><a href="#topic+covar_from_df">covar_from_df()</a></code> to convert from a data frame.</p>
</td></tr>
<tr><td><code id="predict.big_sp_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use <a href="#topic+nb_cores">nb_cores</a>.</p>
</td></tr>
<tr><td><code id="predict.big_sp_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of scores, corresponding to <code>ind.row</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+big_spLinReg">big_spLinReg</a> and <a href="#topic+big_spLogReg">big_spLogReg</a>.
</p>

<hr>
<h2 id='predict.big_sp_list'>Predict method</h2><span id='topic+predict.big_sp_list'></span>

<h3>Description</h3>

<p>Predict method for class <code>big_sp_list</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'big_sp_list'
predict(
  object,
  X,
  ind.row = rows_along(X),
  ind.col = attr(object, "ind.col"),
  covar.row = NULL,
  proba = (attr(object, "family") == "binomial"),
  base.row = NULL,
  ncores = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.big_sp_list_+3A_object">object</code></td>
<td>
<p>Object of class <code>big_sp_list</code>.</p>
</td></tr>
<tr><td><code id="predict.big_sp_list_+3A_x">X</code></td>
<td>
<p>An object of class <a href="#topic+FBM-class">FBM</a>.</p>
</td></tr>
<tr><td><code id="predict.big_sp_list_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices that are used.
If not specified, all rows are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="predict.big_sp_list_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices that are used.
If not specified, all columns are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="predict.big_sp_list_+3A_covar.row">covar.row</code></td>
<td>
<p>Matrix of covariables to be added in each model to correct
for confounders (e.g. the scores of PCA), corresponding to <code>ind.row</code>.
Default is <code>NULL</code> and corresponds to only adding an intercept to each model.
You can use <code><a href="#topic+covar_from_df">covar_from_df()</a></code> to convert from a data frame.</p>
</td></tr>
<tr><td><code id="predict.big_sp_list_+3A_proba">proba</code></td>
<td>
<p>Whether to return probabilities?</p>
</td></tr>
<tr><td><code id="predict.big_sp_list_+3A_base.row">base.row</code></td>
<td>
<p>Vector of base predictions, corresponding to <code>ind.row</code>.</p>
</td></tr>
<tr><td><code id="predict.big_sp_list_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use <a href="#topic+nb_cores">nb_cores</a>.</p>
</td></tr>
<tr><td><code id="predict.big_sp_list_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of scores, corresponding to <code>ind.row</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+big_spLinReg">big_spLinReg</a> and <a href="#topic+big_spLogReg">big_spLogReg</a>.
</p>

<hr>
<h2 id='predict.big_SVD'>Scores of PCA</h2><span id='topic+predict.big_SVD'></span>

<h3>Description</h3>

<p>Get the scores of PCA associated with an svd decomposition (class <code>big_SVD</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'big_SVD'
predict(
  object,
  X = NULL,
  ind.row = rows_along(X),
  ind.col = cols_along(X),
  block.size = block_size(nrow(X)),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.big_SVD_+3A_object">object</code></td>
<td>
<p>A list returned by <code>big_SVD</code> or <code>big_randomSVD</code>.</p>
</td></tr>
<tr><td><code id="predict.big_SVD_+3A_x">X</code></td>
<td>
<p>An object of class <a href="#topic+FBM-class">FBM</a>.</p>
</td></tr>
<tr><td><code id="predict.big_SVD_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices that are used.
If not specified, all rows are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="predict.big_SVD_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices that are used.
If not specified, all columns are used. <strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="predict.big_SVD_+3A_block.size">block.size</code></td>
<td>
<p>Maximum number of columns read at once.
Default uses <a href="#topic+block_size">block_size</a>.</p>
</td></tr>
<tr><td><code id="predict.big_SVD_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of size <code class="reqn">n \times K</code> where <code>n</code> is the number of samples
corresponding to indices in <code>ind.row</code> and K the number of PCs
computed in <code>object</code>. If <code>X</code> is not specified, this just returns
the scores of the training set of <code>object</code>.
</p>


<h3>See Also</h3>

<p><a href="stats.html#topic+prcomp">predict</a> <a href="#topic+big_SVD">big_SVD</a> <a href="#topic+big_randomSVD">big_randomSVD</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)

X &lt;- big_attachExtdata()
n &lt;- nrow(X)

# Using only half of the data
ind &lt;- sort(sample(n, n/2))

test &lt;- big_SVD(X, fun.scaling = big_scale(), ind.row = ind)
str(test)
plot(test$u)

pca &lt;- prcomp(X[ind, ], center = TRUE, scale. = TRUE)

# same scaling
all.equal(test$center, pca$center)
all.equal(test$scale,  pca$scale)

# scores and loadings are the same or opposite
# except for last eigenvalue which is equal to 0
# due to centering of columns
scores &lt;- test$u %*% diag(test$d)
class(test)
scores2 &lt;- predict(test) # use this function to predict scores
all.equal(scores, scores2)
dim(scores)
dim(pca$x)
tail(pca$sdev)
plot(scores2, pca$x[, 1:ncol(scores2)])
plot(test$v[1:100, ], pca$rotation[1:100, 1:ncol(scores2)])

# projecting on new data
X2 &lt;- sweep(sweep(X[-ind, ], 2, test$center, '-'), 2, test$scale, '/')
scores.test &lt;- X2 %*% test$v
ind2 &lt;- setdiff(rows_along(X), ind)
scores.test2 &lt;- predict(test, X, ind.row = ind2) # use this
all.equal(scores.test, scores.test2)
scores.test3 &lt;- predict(pca, X[-ind, ])
plot(scores.test2, scores.test3[, 1:ncol(scores.test2)])
</code></pre>

<hr>
<h2 id='predict.mhtest'>Predict method</h2><span id='topic+predict.mhtest'></span>

<h3>Description</h3>

<p>Predict method for class <code>mhtest</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mhtest'
predict(object, scores = object$score, log10 = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.mhtest_+3A_object">object</code></td>
<td>
<p>An object of class <code>mhtest</code> from you get the probability
function with possibly pre-transformation of scores.</p>
</td></tr>
<tr><td><code id="predict.mhtest_+3A_scores">scores</code></td>
<td>
<p>Raw scores (before transformation) that you want to transform
to p-values.</p>
</td></tr>
<tr><td><code id="predict.mhtest_+3A_log10">log10</code></td>
<td>
<p>Are p-values returned on the <code>log10</code> scale? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="predict.mhtest_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of <strong><code>log10(p-values)</code></strong> associated with <code>scores</code> and <code>object</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+big_univLinReg">big_univLinReg</a> and <a href="#topic+big_univLogReg">big_univLogReg</a>.
</p>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+nb_cores'></span><span id='topic+plus'></span><span id='topic+plot_grid'></span><span id='topic+rows_along'></span><span id='topic+cols_along'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>bigparallelr</dt><dd><p><code><a href="bigparallelr.html#topic+seq-dim">cols_along</a></code>, <code><a href="bigparallelr.html#topic+nb_cores">nb_cores</a></code>, <code><a href="bigparallelr.html#topic+plus">plus</a></code>, <code><a href="bigparallelr.html#topic+seq-dim">rows_along</a></code></p>
</dd>
<dt>cowplot</dt><dd><p><code><a href="cowplot.html#topic+plot_grid">plot_grid</a></code></p>
</dd>
</dl>

<hr>
<h2 id='Replace'>Create an Implementation of [&lt;- For Custom Matrix-Like Types</h2><span id='topic+Replace'></span>

<h3>Description</h3>

<p><code>replace</code> is a function that converts different index types such as negative
integer vectors or logical vectors passed to the <code style="white-space: pre;">&#8288;[&lt;-&#8288;</code> function as <code>i</code>
(e.g. <code>X[i]</code>) or <code>i</code> and <code>j</code> (e.g. <code>X[i, j]</code>) into positive
integer vectors. The converted indices are provided as the <code>i</code> parameter of
<code>replace_vector</code> or <code>i</code> and <code>j</code> parameters of <code>replace_matrix</code> to facilitate
implementing the replacement mechanism for custom matrix-like types.
Single values are recycled to match the replacement length.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Replace(replace_vector, replace_matrix)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Replace_+3A_replace_vector">replace_vector</code></td>
<td>
<p>A function in the form of <code style="white-space: pre;">&#8288;function(x, i, value)&#8288;</code>
that replaces a vector subset of <code>x</code> based on a single vector of indices <code>i</code>
with the values in <code>value</code> and returns <code>x</code>, invisibly.</p>
</td></tr>
<tr><td><code id="Replace_+3A_replace_matrix">replace_matrix</code></td>
<td>
<p>A function in the form of <code style="white-space: pre;">&#8288;function(x, i, j, value)&#8288;</code>
that replaces a matrix subset of <code>x</code> based on two vectors of indices <code>i</code> and
<code>j</code> with the values in <code>value</code> and returns <code>x</code>, invisibly.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>This idea initially comes from <a href="https://goo.gl/3RDNQG">package crochet</a>.</strong>
</p>


<h3>Value</h3>

<p>A function in the form of <code style="white-space: pre;">&#8288;function(x, i, j, ..., value)&#8288;</code> that is
meant to be used as a method for <code style="white-space: pre;">&#8288;[&lt;-&#8288;</code> for a custom type.
</p>

<hr>
<h2 id='sub_bk'>Replace extension '.bk'</h2><span id='topic+sub_bk'></span>

<h3>Description</h3>

<p>Replace extension '.bk'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sub_bk(path, replacement = "", stop_if_not_ext = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sub_bk_+3A_path">path</code></td>
<td>
<p>String with extension '.bk'.</p>
</td></tr>
<tr><td><code id="sub_bk_+3A_replacement">replacement</code></td>
<td>
<p>Replacement of '.bk'. Default replaces by nothing.</p>
</td></tr>
<tr><td><code id="sub_bk_+3A_stop_if_not_ext">stop_if_not_ext</code></td>
<td>
<p>If <code>replacement != ""</code>, whether to error if
replacement is not an extension (i.e. starting with a dot).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>String with extension '.bk' replaced by <code>replacement</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>path &lt;- "toto.bk"
sub_bk(path)
sub_bk(path, ".rds")
</code></pre>

<hr>
<h2 id='summary.big_sp_list'>Summary method</h2><span id='topic+summary.big_sp_list'></span>

<h3>Description</h3>

<p>Summary method for class <code>big_sp_list</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'big_sp_list'
summary(object, best.only = FALSE, sort = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.big_sp_list_+3A_object">object</code></td>
<td>
<p>An object of class <code>big_sp_list</code>.</p>
</td></tr>
<tr><td><code id="summary.big_sp_list_+3A_best.only">best.only</code></td>
<td>
<p>Whether to return only one row corresponding to the best
model? The best model is the one smallest <code style="white-space: pre;">&#8288;$validation_loss&#8288;</code>.</p>
</td></tr>
<tr><td><code id="summary.big_sp_list_+3A_sort">sort</code></td>
<td>
<p>Whether to sort by <code style="white-space: pre;">&#8288;$validation_loss&#8288;</code>. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summary.big_sp_list_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with, for each <code style="white-space: pre;">&#8288;$alpha&#8288;</code>, a mean <code style="white-space: pre;">&#8288;$validation_loss&#8288;</code>, a mean
vector of coefficients <code style="white-space: pre;">&#8288;$beta&#8288;</code>, the corresponding number of non-zero
coefficients <code style="white-space: pre;">&#8288;$nb_var&#8288;</code>, and the reasons of method completion <code style="white-space: pre;">&#8288;$message&#8288;</code>.
</p>

<hr>
<h2 id='theme_bigstatsr'>Theme ggplot2</h2><span id='topic+theme_bigstatsr'></span>

<h3>Description</h3>

<p>Theme ggplot2 used by this package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>theme_bigstatsr(size.rel = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="theme_bigstatsr_+3A_size.rel">size.rel</code></td>
<td>
<p>Relative size. Default is <code>1</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library(ggplot2)
qplot(y = 1:10)
qplot(y = 1:10) + theme_bw()
qplot(y = 1:10) + theme_bigstatsr()
</code></pre>

<hr>
<h2 id='without_downcast_warning'>Temporarily disable downcast warning</h2><span id='topic+without_downcast_warning'></span>

<h3>Description</h3>

<p>Temporarily disable downcast warning
</p>


<h3>Usage</h3>

<pre><code class='language-R'>without_downcast_warning(expr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="without_downcast_warning_+3A_expr">expr</code></td>
<td>
<p>The expression to evaluate without downcast warning.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The result of the evaluated expression.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>without_downcast_warning(FBM(10, 10, type = "integer", init = 1.5))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
