<!DOCTYPE html><html lang="en"><head><title>Help for package dsld</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {dsld}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#compas1'>
<p>Criminal Offenders Screened in Florida</p></a></li>
<li><a href='#dsldBnlearn'><p>dsldBnlearn</p></a></li>
<li><a href='#dsldCHunting+20and+20dsldOHunting'><p>Confounder and Proxy Hunting</p></a></li>
<li><a href='#dsldConditDisparity'><p>dsldConditDisparity</p></a></li>
<li><a href='#dsldConfounders'><p>dsldConfounders</p></a></li>
<li><a href='#dsldDensityByS'><p>dsldDensityByS</p></a></li>
<li><a href='#dsldEDFFair+20Wrappers'><p>dsldEDFFair Wrappers</p></a></li>
<li><a href='#dsldFairML+20Wrappers'><p>dsldFairML Wrappers</p></a></li>
<li><a href='#dsldFairUtilTrade'><p>dsldFairUtilTrade</p></a></li>
<li><a href='#dsldFreqPCoord'><p>dsldFreqPCoord</p></a></li>
<li><a href='#dsldFrequencyByS'><p>dsldFrequencyByS</p></a></li>
<li><a href='#dsldLinear'><p>dsldLinear</p></a></li>
<li><a href='#dsldLogit'><p>dsldLogit</p></a></li>
<li><a href='#dsldMatchedATE'><p>dsldMatchedATE</p></a></li>
<li><a href='#dsldML'><p>dsldML</p></a></li>
<li><a href='#dsldScatterPlot3D'><p>ScatterPlot3D in dsld</p></a></li>
<li><a href='#dsldTakeALookAround'><p>dsldTakeALookAround</p></a></li>
<li><a href='#lak'>
<p>Labor Market Discrimination</p></a></li>
<li><a href='#mortgageSE'>
<p>Mortgage Denial</p></a></li>
<li><a href='#svcensus'>
<p>Silicon Valley programmers and engineers data</p></a></li>
<li><a href='#utilities'>
<p>Utitlities</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>0.2.2</td>
</tr>
<tr>
<td>Title:</td>
<td>Data Science Looks at Discrimination</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Norm Matloff &lt;nsmatloff@ucdavis.edu&gt;</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Imports:</td>
<td>Kendall, ranger, ggplot2, plotly, freqparcoord,
fairness,sandwich</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), fairml, gtools, regtools,qeML,rmarkdown</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr,bnlearn,Matching,randomForest</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Description:</td>
<td>Statistical and graphical tools for detecting and measuring
   discrimination and bias, be it racial, gender, age or other.
   Detection and remediation of bias in machine learning algorithms.
   'Python' interfaces available.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/matloff/dsld">https://github.com/matloff/dsld</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/matloff/dsld/issues">https://github.com/matloff/dsld/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-09-11 04:08:37 UTC; normanmatloff</td>
</tr>
<tr>
<td>Author:</td>
<td>Norm Matloff <a href="https://orcid.org/0000-0001-9179-6785"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Taha Abdullah [aut],
  Arjun Ashok [aut],
  Shubhada Martha [aut],
  Aditya Mittal [aut],
  Billy Ouattara [aut],
  Jonathan Tran [aut],
  Brandon Zarate Estrada [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-09-13 18:20:09 UTC</td>
</tr>
</table>
<hr>
<h2 id='compas1'>
Criminal Offenders Screened in Florida
</h2><span id='topic+compas1'></span>

<h3>Description</h3>

 
<p>A collection of criminal offenders screened in Florida (US) during 
2013-14. This data was used to predict recidivism. 
</p>
<p>Additional details for this dataset can be found via the <span class="pkg">fairml</span> package. 
</p>

<hr>
<h2 id='dsldBnlearn'>dsldBnlearn</h2><span id='topic+dsldIamb'></span>

<h3>Description</h3>

<p>Wrappers for functions in the <span class="pkg">bnlearn</span> package. (Just 
(Presently, just <code>iamb</code>.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsldIamb(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dsldBnlearn_+3A_data">data</code></td>
<td>

<p>Data frame.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Under very stringent assumptions, <code>dsldIamb</code> performs causal
discovery, i.e. fits a causal model to <code>data</code>.
</p>


<h3>Value</h3>

<p>Object of class 'bn' (<span class="pkg">bnlearn</span> object). The generic <code>plot</code>
function is callable on this object.
</p>


<h3>Author(s)</h3>

<p>N. Matloff
</p>


<h3>Examples</h3>

<pre><code class='language-R'>   
   data(svcensus)
   # iamb does not accept integer data
   svcensus$wkswrkd &lt;- as.numeric(svcensus$wkswrkd)
   svcensus$wageinc &lt;- as.numeric(svcensus$wageinc)
   iambOut &lt;- dsldIamb(svcensus)
   plot(iambOut)
   
</code></pre>

<hr>
<h2 id='dsldCHunting+20and+20dsldOHunting'>Confounder and Proxy Hunting</h2><span id='topic+dsldCHunting'></span><span id='topic+dsldOHunting'></span>

<h3>Description</h3>

 
<p>Confounder hunting:  searches for variables C that predict both Y and
S. Proxy hunting:  searches for variables O that predict S.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsldCHunting(data,yName,sName,intersectDepth=10)
dsldOHunting(data,yName,sName)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dsldCHunting+2B20and+2B20dsldOHunting_+3A_data">data</code></td>
<td>

<p>Data frame.
</p>
</td></tr>
<tr><td><code id="dsldCHunting+2B20and+2B20dsldOHunting_+3A_yname">yName</code></td>
<td>

<p>Name of the response variable column. 
</p>
</td></tr>
<tr><td><code id="dsldCHunting+2B20and+2B20dsldOHunting_+3A_sname">sName</code></td>
<td>

<p>Name of the sensitive attribute column.
</p>
</td></tr>
<tr><td><code id="dsldCHunting+2B20and+2B20dsldOHunting_+3A_intersectdepth">intersectDepth</code></td>
<td>

<p>Maximum size of intersection of the Y predictor set and 
the S predictor set
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>dsldCHunting</code>: The random forests function
<code>qeML:qeRF</code> will be run on the indicated data to indicate feature
importance in prediction of Y (without S) and S (without Y).  Call
these &quot;important predictors&quot; of Y and S.
</p>
<p>Then for each <code>i</code> from 1 to <code>intersectDepth</code>, the
intersection of the top <code>i</code> important predictors of Y and the
the top <code>i</code> important predictors of S will be reported, thus
suggesting possible confounders. Larger values of <code>i</code> will
report more potential confounders, though including progressively
weaker ones. 
</p>
<p>The analyst then may then consider omitting the variables C from
models of the effect of S on Y.
</p>
<p>Note: Run times may be long.
</p>
<p><code>dsldOHunting</code>: Factors, if any, will be converted to dummy
variables, and then the Kendall Tau correlations will be calculated
betwene S and potential proxy variables O, i.e. every column other
than Y and S.  (The Y column itself doesn't enter into computation.)
</p>
<p>In fairness analyses, in which one desires to either eliminate or
reduce the impact of S, one must consider the indirect effect of S
via O. One may wish to eliminate or reduce the role of O.
</p>


<h3>Value</h3>

<p>The function <code>dsldCHunting</code> returns an R list, one component for
each confounder set found.
</p>
<p>The function <code>dsldOHunting</code> returns an R matrix of correlations, 
one row for each level of S.
</p>


<h3>Author(s)</h3>

<p>N. Matloff
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  

data(lsa) 
dsldCHunting(lsa,'bar','race1')
# e.g. suggests confounders 'decile3', 'lsat'
    
data(mortgageSE)
dsldOHunting(mortgageSE,'deny','black')
# e.g. suggests using loan value and condo purchase as proxies

</code></pre>

<hr>
<h2 id='dsldConditDisparity'>dsldConditDisparity</h2><span id='topic+dsldConditDisparity'></span>

<h3>Description</h3>

<p>Plots (estimated) mean Y against X, separately for each level of S,
with restrictions <code>condits</code>. May reveal Simpson's Paradox-like
differences not seen in merely plotting mean Y against X.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsldConditDisparity(data, yName, sName, xName, condits = NULL,
    qeFtn = qeKNN, minS = 50, useLoess = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dsldConditDisparity_+3A_data">data</code></td>
<td>
<p>Data frame or equivalent.</p>
</td></tr>
<tr><td><code id="dsldConditDisparity_+3A_yname">yName</code></td>
<td>
<p>Name of predicted variable Y. Must be numeric 
or dichtomous R factor.</p>
</td></tr>
<tr><td><code id="dsldConditDisparity_+3A_sname">sName</code></td>
<td>
<p>Name of the sensitive variable S, an R factor</p>
</td></tr>
<tr><td><code id="dsldConditDisparity_+3A_xname">xName</code></td>
<td>
<p>Name of a numeric column for the X-axis.</p>
</td></tr>
<tr><td><code id="dsldConditDisparity_+3A_condits">condits</code></td>
<td>
<p>An R vector; each component is a character 
string for an R logical expression representing a desired 
condition involving <code>names(data)</code> other than S and Y.</p>
</td></tr>
<tr><td><code id="dsldConditDisparity_+3A_qeftn">qeFtn</code></td>
<td>
<p><code>qeML</code> predictive function (not quoted;
only default arguments will be used.)</p>
</td></tr>
<tr><td><code id="dsldConditDisparity_+3A_mins">minS</code></td>
<td>
<p>Minimum size for an S group to be retained in the analysis.</p>
</td></tr>
<tr><td><code id="dsldConditDisparity_+3A_useloess">useLoess</code></td>
<td>
<p>If TRUE, do loess smoothing on the fitted regression values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No value; plot.</p>


<h3>Author(s)</h3>

<p>N. Matloff, A. Ashok, S. Martha, A. Mittal
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(compas)
# graph probability of recidivism by race given age, among those with at
# most 4 prior convictions and COMPAS decile score at least 6
compas$two_year_recid &lt;- as.numeric(compas$two_year_recid == "Yes")
dsldConditDisparity(compas,"two_year_recid", "race", "age", 
    c("priors_count &lt;= 4","decile_score&gt;=6"), qeKNN)

dsldConditDisparity(compas,"two_year_recid", "race", "age",
    "priors_count == 0", qeGBoost)

</code></pre>

<hr>
<h2 id='dsldConfounders'>dsldConfounders</h2><span id='topic+dsldConfounders'></span>

<h3>Description</h3>

<p>Plots estimated densities of all continuous features X, conditioned on a
specified categorical feature C. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsldConfounders(data, sName, graphType = "plotly", fill = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dsldConfounders_+3A_data">data</code></td>
<td>
<p>Dataframe, at least 2 columns.</p>
</td></tr>
<tr><td><code id="dsldConfounders_+3A_sname">sName</code></td>
<td>

<p>Name of the categorical column, an R factor.  In discrimination 
contexts, Typically a sensitive variable.
</p>
</td></tr>
<tr><td><code id="dsldConfounders_+3A_graphtype">graphType</code></td>
<td>

<p>Either &quot;plot&quot; or &quot;plotly&quot;, for static or interactive graphs.
The latter requires the <span class="pkg">plotly</span> package.
</p>
</td></tr>
<tr><td><code id="dsldConfounders_+3A_fill">fill</code></td>
<td>

<p>Only applicable to graphType = &quot;plot&quot; case. Setting to true
will color each line down to the x-axis.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No value; plot.</p>


<h3>Author(s)</h3>

<p>N. Matloff, T. Abdullah, A. Ashok, J. Tran
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(svcensus)
dsldConfounders(svcensus, "educ")

</code></pre>

<hr>
<h2 id='dsldDensityByS'>dsldDensityByS</h2><span id='topic+dsldDensityByS'></span>

<h3>Description</h3>

<p>Graphs densities of a response variable, grouped by a sensitive variable. 
Similar to <code>dsldConfounders</code>, but includes sliders to control the 
bandwidth of the density estimate (analogous to controlling the bin
width in a histogram).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsldDensityByS(data, cName, sName, graphType = "plotly", fill = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dsldDensityByS_+3A_data">data</code></td>
<td>

<p>Datasetwith at least 1 numerical column and 1 factor column
</p>
</td></tr>
<tr><td><code id="dsldDensityByS_+3A_cname">cName</code></td>
<td>

<p>Possible confounding variable column, an R numeric
</p>
</td></tr>
<tr><td><code id="dsldDensityByS_+3A_sname">sName</code></td>
<td>

<p>Name of the sensitive variable column, an R factor
</p>
</td></tr>
<tr><td><code id="dsldDensityByS_+3A_graphtype">graphType</code></td>
<td>

<p>Type of graph created. Defaults to &quot;plotly&quot;.
</p>
</td></tr>
<tr><td><code id="dsldDensityByS_+3A_fill">fill</code></td>
<td>

<p>To fill the graph. Defaults to &quot;FALSE&quot;.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No value; plot.</p>


<h3>Author(s)</h3>

<p>N. Matloff, T. Abdullah, A. Ashok, J. Tran
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(svcensus)
dsldDensityByS(svcensus, cName = "wageinc", sName = "educ")
</code></pre>

<hr>
<h2 id='dsldEDFFair+20Wrappers'>dsldEDFFair Wrappers</h2><span id='topic+dsldQeFairKNN'></span><span id='topic+dsldQeFairRF'></span><span id='topic+dsldQeFairRidgeLin'></span><span id='topic+dsldQeFairRidgeLog'></span><span id='topic+predict.dsldQeFair'></span>

<h3>Description</h3>

 
<p>Explicitly Deweighted Features: control the effect of proxies 
related to sensitive variables for prediction. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsldQeFairKNN(data, yName, sNames, deweightPars=NULL, yesYVal=NULL,k=25,
  scaleX=TRUE, holdout=floor(min(1000,0.1*nrow(data))))
dsldQeFairRF(data,yName,sNames,deweightPars=NULL, nTree=500, minNodeSize=10,
  mtry = floor(sqrt(ncol(data))),yesYVal=NULL,
  holdout=floor(min(1000,0.1*nrow(data))))
dsldQeFairRidgeLin(data, yName, sNames, deweightPars = NULL, 
  holdout=floor(min(1000,0.1*nrow(data))))
dsldQeFairRidgeLog(data, yName, sNames, deweightPars = NULL, holdout =
  floor(min(1000, 0.1 * nrow(data))), yesYVal = levels(data[, yName])[2])
## S3 method for class 'dsldQeFair'
predict(object,newx,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dsldEDFFair+2B20Wrappers_+3A_data">data</code></td>
<td>

<p>Dataframe, training set.
</p>
</td></tr>
<tr><td><code id="dsldEDFFair+2B20Wrappers_+3A_yname">yName</code></td>
<td>

<p>Name of the response variable column. 
</p>
</td></tr>
<tr><td><code id="dsldEDFFair+2B20Wrappers_+3A_snames">sNames</code></td>
<td>

<p>Name(s) of the sensitive attribute column(s). 
</p>
</td></tr>
<tr><td><code id="dsldEDFFair+2B20Wrappers_+3A_deweightpars">deweightPars</code></td>
<td>

<p>Values for de-emphasizing variables in a split, e.g. 
'list(age=0.2,gender=0.5)'. In the linear case,
larger values means more deweighting, i.e. less influence of the given 
variable on predictions. For KNN and random forests, smaller
values mean more deweighting.
</p>
</td></tr>
<tr><td><code id="dsldEDFFair+2B20Wrappers_+3A_scalex">scaleX</code></td>
<td>

<p>Scale the features. Defaults to TRUE.
</p>
</td></tr>
<tr><td><code id="dsldEDFFair+2B20Wrappers_+3A_yesyval">yesYVal</code></td>
<td>

<p>Y value to be considered &quot;yes,&quot; to be coded 1 rather than 0.
</p>
</td></tr>
<tr><td><code id="dsldEDFFair+2B20Wrappers_+3A_k">k</code></td>
<td>

<p>Number of nearest neighbors. In functions other than 
<code>dsldQeFairKNN</code> for which this is an argument, 
it is the number of neighbors to use in finding 
conditional probabilities via knnCalib.
</p>
</td></tr> 
<tr><td><code id="dsldEDFFair+2B20Wrappers_+3A_holdout">holdout</code></td>
<td>

<p>How many rows to use as the holdout/testing set. Can be NULL.
The testing set is used to calculate s correlation and test accuracy.
</p>
</td></tr> 
<tr><td><code id="dsldEDFFair+2B20Wrappers_+3A_ntree">nTree</code></td>
<td>

<p>Number of trees.
</p>
</td></tr>
<tr><td><code id="dsldEDFFair+2B20Wrappers_+3A_minnodesize">minNodeSize</code></td>
<td>

<p>Minimum number of data points in a tree node.
</p>
</td></tr>
<tr><td><code id="dsldEDFFair+2B20Wrappers_+3A_mtry">mtry</code></td>
<td>

<p>Number of variables randomly tried at each split.
</p>
</td></tr>
<tr><td><code id="dsldEDFFair+2B20Wrappers_+3A_object">object</code></td>
<td>

<p>An object returned by the dsld-EDFFAIR wrapper.  
</p>
</td></tr>
<tr><td><code id="dsldEDFFair+2B20Wrappers_+3A_newx">newx</code></td>
<td>

<p>New data to be predicted. Must be in the same format as original data.
</p>
</td></tr>
<tr><td><code id="dsldEDFFair+2B20Wrappers_+3A_...">...</code></td>
<td>

<p>Further arguments.
</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>The sensitive variables S are removed entirely, but there is concern
that they still affect prediction indirectly, via a set C of proxy
variables. 
</p>
<p>Linear EDF reduces the impact of the proxies through a shinkage
process similar to that of ridge regression. Specifically, instead
of minimizing the sum of squared errors SSE with respect to a
coefficient vector b, we minimize SSE + the squared norm of Db,
where D is a diagonal matrix with nonzero elements corresponding to
C. Large values penalizing variables in C, thus shrinking them.
</p>
<p>KNN EDF reduces the weights in Euclidean distance for variables in
C.  The random forests version reduces the probabilities that a
proxy will be used in splitting a node.
</p>
<p>By using various values of the deweighting parameters, the user can
choose a desired position in the Fairness-Utility Tradeoff.
</p>
<p>More details can be found in the references. 
</p>


<h3>Value</h3>

<p>The EDF functions return objects of class 'dsldQeFair', which include
components for test and base accuracy, summaries of inputs and so on.
</p>


<h3>Author(s)</h3>

<p>N. Matloff, A. Mittal, J. Tran
</p>


<h3>References</h3>

<p>https://github.com/matloff/EDFfair 
</p>


<h3>See Also</h3>

<p>Matloff, Norman, and Wenxi Zhang. &quot;A novel regularization approach to fair ML.&quot; <br />
<code>arXiv preprint arXiv:2208.06557</code> (2022).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  

data(compas1) 
data(svcensus) 

# dsldQeFairKNN: deweight "decile score" column with "race" as 
# the sensitive variable
knnOut &lt;- dsldQeFairKNN(compas1, "two_year_recid", "race", 
   list(decile_score=0.1), yesYVal = "Yes")
knnOut$testAcc 
knnOut$corrs 
predict(knnOut, compas1[1,-8]) 

# dsldFairRF: deweight "decile score" column with "race" as sensitive variable
rfOut &lt;- dsldQeFairRF(compas1, "two_year_recid", "race", 
   list(decile_score=0.3), yesYVal = "Yes")
rfOut$testAcc
rfOut$corrs 
predict(rfOut, compas1[1,-8]) 

# dsldQeFairRidgeLin: deweight "occupation" and "age" columns
lin &lt;- dsldQeFairRidgeLin(svcensus, "wageinc", "gender", deweightPars = 
  list(occ=.4, age=.2))
lin$testAcc 
lin$corrs 
predict(lin, svcensus[1,-4])

# dsldQeFairRidgeLin: deweight "decile score" column
log &lt;- dsldQeFairRidgeLog(compas1, "two_year_recid", "race", 
  list(decile_score=0.1), yesYVal = "Yes")
log$testAcc 
log$corrs 
predict(log, compas1[1,-8])
</code></pre>

<hr>
<h2 id='dsldFairML+20Wrappers'>dsldFairML Wrappers</h2><span id='topic+dsldFrrm'></span><span id='topic+dsldFgrrm'></span><span id='topic+dsldNclm'></span><span id='topic+dsldZlm'></span><span id='topic+dsldZlrm'></span><span id='topic+predict.dsldFairML'></span><span id='topic+summary.dsldFairML'></span>

<h3>Description</h3>

<p>Fair machine learning models: estimation and prediction. The following 
functions provide wrappers for some functions in the <span class="pkg">fairML</span>
package. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsldFrrm(data, yName, sName, unfairness, definition = "sp-komiyama", 
   lambda = 0, save.auxiliary = FALSE)
dsldFgrrm(data, yName, sName, unfairness, definition = "sp-komiyama", 
   family = "binomial", lambda = 0, save.auxiliary = FALSE)
dsldNclm(data, yName, sName, unfairness, covfun = cov, lambda = 0, 
   save.auxiliary = FALSE)
dsldZlm(data, yName, sName, unfairness)
dsldZlrm(data, yName, sName, unfairness)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dsldFairML+2B20Wrappers_+3A_data">data</code></td>
<td>

<p>Data frame.
</p>
</td></tr>
<tr><td><code id="dsldFairML+2B20Wrappers_+3A_yname">yName</code></td>
<td>

<p>Name of the response variable column. 
</p>
</td></tr>
<tr><td><code id="dsldFairML+2B20Wrappers_+3A_sname">sName</code></td>
<td>

<p>Name(s) of the sensitive attribute column(s). 
</p>
</td></tr>
<tr><td><code id="dsldFairML+2B20Wrappers_+3A_unfairness">unfairness</code></td>
<td>

<p>A number in (0, 1]. Degree of unfairness allowed in
the model.  A value (very near) 0 means the model is completely 
fair, while a value of 1 means the model is not 
constrained to be fair at all.
</p>
</td></tr>
<tr><td><code id="dsldFairML+2B20Wrappers_+3A_covfun">covfun</code></td>
<td>

<p>A function computing covariance matrices. 
</p>
</td></tr>
<tr><td><code id="dsldFairML+2B20Wrappers_+3A_definition">definition</code></td>
<td>

<p>Character string, the label of the definition of fairness.
Currently either 'sp-komiyama', 'eo-komiyama' or 'if-berk'.
</p>
</td></tr>
<tr><td><code id="dsldFairML+2B20Wrappers_+3A_family">family</code></td>
<td>

<p>A character string, either 'gaussian' to fit linear regression, 
'binomial' for logistic regression, 'poisson' for
log-linear regression, 'cox' for Cox proportional 
hazards regression, or 'multinomial' for
multinomial logistic regression.
</p>
</td></tr>
<tr><td><code id="dsldFairML+2B20Wrappers_+3A_lambda">lambda</code></td>
<td>

<p>Non-negative number, a ridge-regression penalty coefficient. 
</p>
</td></tr>
<tr><td><code id="dsldFairML+2B20Wrappers_+3A_save.auxiliary">save.auxiliary</code></td>
<td>

<p>A logical value, whether to save the fitted values and the residuals 
of the auxiliary model that constructs the debiased predictors. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See documentation for the <span class="pkg">fairml</span> package.
</p>


<h3>Value</h3>

<p>An object of class 'dsldFairML', which includes the model 
information, <code>yName</code>, and <code>sName</code>.
</p>


<h3>Author(s)</h3>

<p>S. Martha, A. Mittal, B. Ouattara, B. Zarate, J. Tran
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 

data(svcensus) 
data(compas1)

yName &lt;- "wageinc"
sName &lt;- "age"
frrmOut &lt;- dsldFrrm(svcensus, yName, sName, 0.2, definition = "sp-komiyama") 
summary(frrmOut)
predict(frrmOut, svcensus[1:10,]) 

yName &lt;- "two_year_recid"
sName &lt;- "age"
fgrrmOut &lt;- dsldFgrrm(compas1, yName, sName, 0.2, definition = "sp-komiyama")  
summary(fgrrmOut)
predict(fgrrmOut, compas1[c(1:10),]) 


</code></pre>

<hr>
<h2 id='dsldFairUtilTrade'>dsldFairUtilTrade</h2><span id='topic+dsldFairUtilTrade'></span>

<h3>Description</h3>

 
<p>Exploration of the Fairness-Utility Tradeoff.  Finds predictive accuracy
and correlation between S and predicted Y.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsldFairUtilTrade(data,yName,sName,dsldFtnName,
   unfairness=NULL,deweightPars=NULL,yesYVal=NULL,yesSVal=NULL,
   corrType='kendall', holdout = floor(min(1000, 0.1 * nrow(data))))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dsldFairUtilTrade_+3A_data">data</code></td>
<td>

<p>Data frame. 
</p>
</td></tr>
<tr><td><code id="dsldFairUtilTrade_+3A_yname">yName</code></td>
<td>

<p>Name of the response variable Y column. Y must be numeric or
binary (two-level R factor).
</p>
</td></tr>
<tr><td><code id="dsldFairUtilTrade_+3A_sname">sName</code></td>
<td>

<p>Name of the sensitive attribute S column. S must be numeric or
binary (two-level R factor).
</p>
</td></tr>
<tr><td><code id="dsldFairUtilTrade_+3A_dsldftnname">dsldFtnName</code></td>
<td>

<p>Quoted name of one of the <span class="pkg">fairML</span> or EDF functions.   
</p>
</td></tr>
<tr><td><code id="dsldFairUtilTrade_+3A_unfairness">unfairness</code></td>
<td>

<p>Nonnull for the <span class="pkg">fairML</span> functions.
</p>
</td></tr>
<tr><td><code id="dsldFairUtilTrade_+3A_deweightpars">deweightPars</code></td>
<td>

<p>Nonnull for the EDF functions.
</p>
</td></tr>
<tr><td><code id="dsldFairUtilTrade_+3A_yesyval">yesYVal</code></td>
<td>

<p>Y value to be treated as Y = 1 for binary Y.
</p>
</td></tr>
<tr><td><code id="dsldFairUtilTrade_+3A_yessval">yesSVal</code></td>
<td>

<p>S value to be treated as S = 1 for binary S.
</p>
</td></tr>
<tr><td><code id="dsldFairUtilTrade_+3A_corrtype">corrType</code></td>
<td>

<p>Either 'kendall' or 'probs'.
</p>
</td></tr>
<tr><td><code id="dsldFairUtilTrade_+3A_holdout">holdout</code></td>
<td>

<p>Size of holdout set.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Tool for exploring tradeoff between utility (predictive accuracy, Mean
Absolute Prediction Error or overall probability of misclassification)
and fairness. Roughly speaking, the latter is defined as the strength of
relation between S and predicted Y (the smaller, the better). The main
issue is definition of &quot;relation&quot; in the case of binary Y or S:
</p>
<p>In the 'kendall' case, binary predicted Y or S is recoded to 1s and 0s,
and Kendall correlation is used. In the 'probs' case, binary Y or S is
replaced by P(Y = 1 | X) and P(S = 1 | X); squared Pearson correlation
is then computed.
</p>


<h3>Value</h3>

<p>A two-component vector, consisting of predictive accuracy and strength
of relation between S and predicted Y.
</p>


<h3>Author(s)</h3>

<p>N. Matloff
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  

data(svcensus)
dsldFairUtilTrade(svcensus,'wageinc','gender','dsldFrrm',0.2,yesSVal='male')
data(lsa)
race1 &lt;- lsa$race1
lsabw &lt;- lsa[race1 == 'black' | race1 == 'white',]
# need to get rid of excess levels
race1 &lt;- lsabw$race1
race1 &lt;- as.character(race1)
lsabw$race1 &lt;- as.factor(race1)
dsldFairUtilTrade(lsabw,'bar','race1','dsldQeFairRidgeLog',
   deweightPars=list(fam_inc=0.1),yesYVal='TRUE',yesSVal='white')

</code></pre>

<hr>
<h2 id='dsldFreqPCoord'>dsldFreqPCoord</h2><span id='topic+dsldFreqPCoord'></span>

<h3>Description</h3>

<p>Wrapper for the <code>freqparcoord</code> function from the <span class="pkg">freqparcoord</span> 
package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsldFreqPCoord(data, m, sName = NULL, method
    = "maxdens", faceting = "vert", k = 50, klm = 5 * k, keepidxs = NULL, 
    plotidxs = FALSE, cls = NULL, plot_filename = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dsldFreqPCoord_+3A_data">data</code></td>
<td>

<p>Data frame or matrix.
</p>
</td></tr>
<tr><td><code id="dsldFreqPCoord_+3A_m">m</code></td>
<td>

<p>Number of lines to plot for each group. A negative value in conjunction 
with the method <code>maxdens</code> indicates that the 
lowest-density lines are to be plotted.  If method is <code>locmax</code>,
then <code>m</code> is forced to 1.
</p>
</td></tr>
<tr><td><code id="dsldFreqPCoord_+3A_sname">sName</code></td>
<td>

<p>Column for the grouping variable, if any (if none, all the data 
is treated as a single group); the column must be a vector or factor. 
The column must not be in <code>dispcols</code>. If 
method is <code>locmax</code>, <code>grpvar</code> is forced to NULL
</p>
</td></tr>
<tr><td><code id="dsldFreqPCoord_+3A_method">method</code></td>
<td>

<p>What to display: 'maxdens' for plotting the most
(or least) typical lines, 'locmax' for cluster hunting, or 
'randsamp' for plotting a random sample of lines.
</p>
</td></tr>
<tr><td><code id="dsldFreqPCoord_+3A_faceting">faceting</code></td>
<td>

<p>How to display groups, if present.  Use 'vert' for
vertical stacking of group plots, 'horiz' for horizontal ones, or
'none' to draw all lines in one plot, color-coding by group.
</p>
</td></tr>
<tr><td><code id="dsldFreqPCoord_+3A_k">k</code></td>
<td>

<p>Number of nearest neighbors to use for density estimation.
</p>
</td></tr>
<tr><td><code id="dsldFreqPCoord_+3A_klm">klm</code></td>
<td>

<p>If method is &quot;locmax&quot;, number of nearest neighbors to 
use for finding local maxima for cluster hunting. Generally needs
to be much larger than <code>k</code>, to avoid &quot;noise fitting.&quot;
</p>
</td></tr>
<tr><td><code id="dsldFreqPCoord_+3A_keepidxs">keepidxs</code></td>
<td>

<p>If not NULL, the indices of the rows of <code>data</code> that 
are plotted will be stored in a component <code>idxs</code> of the
return value.  The rows themselves will be in a component
<code>xdisp</code>, ordered by <code>data[,dispcols[1]</code>.
</p>
</td></tr>
<tr><td><code id="dsldFreqPCoord_+3A_plotidxs">plotidxs</code></td>
<td>

<p>If TRUE, lines in the display will be annotated 
with their case numbers, i.e. their row numbers within <code>data</code>.  
Use only with small values of <code>m</code>, as overplotting may occur.
</p>
</td></tr>
<tr><td><code id="dsldFreqPCoord_+3A_cls">cls</code></td>
<td>

<p>Cluster, if any (see the <code>parallel</code> package) for
parallel computation.
</p>
</td></tr>
<tr><td><code id="dsldFreqPCoord_+3A_plot_filename">plot_filename</code></td>
<td>

<p>Name of the file that will hold the saved graph image. 
If NULL, the graph will be generated and displayed without being saved.
</p>
<p>If a filename is provided, the graph will not be displayed, only
saved.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>dsldFreqPCoord</code> function wraps <code>freqparcoord</code>,
which uses a frequency-based parallel coordinates method to 
vizualize multiple variables simultaneously in graph form.
</p>
<p>This is done by plotting either the &quot;most typical&quot; or &quot;least typical&quot;
(i.e. highest or lowest estimated multivariate density values respectively)
cases to discern relations between variables.  
</p>
<p>The Y-axis represents the centered and scaled values of the columns.
</p>


<h3>Value</h3>

<p>Object of type 'gg' (<span class="pkg">ggplot2</span> object), with components <code>idxs</code>
and <code>xdisp</code> added if <code>keepidxs</code> is not NULL (see argument
<code>keepidxs</code> above).
</p>


<h3>Author(s)</h3>

<p>N. Matloff, T. Abdullah, B. Ouattara, J. Tran, B. Zarate
</p>


<h3>References</h3>

<p>https://cran.r-project.org/web/packages/freqparcoord/index.html
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(lsa)
lsa1 &lt;- lsa[,c('fam_inc','ugpa','gender','lsat','race1')]
dsldFreqPCoord(lsa1,75,'race1')
# a number of interesting trends among the most "typical" law students in the
# dataset: remarkably little variation among typical
# African-Americans; typical Hispanic men have low GPAs, poor LSAT
# scores there is more variation; typical Asian and Black students were
# female; Asians and Hispanics have the most variation in family income
# background
</code></pre>

<hr>
<h2 id='dsldFrequencyByS'>dsldFrequencyByS</h2><span id='topic+dsldFrequencyByS'></span>

<h3>Description</h3>

<p>Informal assessment of C as a possible confounder in a relationship between a
sensitive variable S and a variable Y.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsldFrequencyByS(data, cName, sName)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dsldFrequencyByS_+3A_data">data</code></td>
<td>

<p>Data frame or equivalent.
</p>
</td></tr>
<tr><td><code id="dsldFrequencyByS_+3A_cname">cName</code></td>
<td>

<p>Name of the &quot;C&quot; column, an R factor.
</p>
</td></tr>
<tr><td><code id="dsldFrequencyByS_+3A_sname">sName</code></td>
<td>

<p>Name of the sensitive variable column, an R factor
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Essentially an informal assessment of the between S and C.  
</p>
<p>Consider the <code>svcensus</code> dataset.  If for instance we are studying
the effect of gender S on wage income Y, say C is occupation.  If
different genders have different occupation patterns, then C is a
potential confounder.  (Y does not explicitly appear here.)
</p>


<h3>Value</h3>

<p>Data frame, one for each level of the sensitive variable S, and
one column for each level of the confounder C. Each row sums to 1.0.</p>


<h3>Author(s)</h3>

<p>N. Matloff, T. Abdullah, A. Ashok, J. Tran
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(svcensus) 
dsldFrequencyByS(svcensus, cName = "educ", sName = "gender")
# not much difference in education between genders
dsldFrequencyByS(svcensus, cName = "occ", sName = "gender")
# substantial difference in occupation between genders
data(lsa)
lsa$faminc &lt;- as.factor(lsa$fam_inc)
dsldFrequencyByS(lsa,'faminc','race1')
# distribution of family income by race
</code></pre>

<hr>
<h2 id='dsldLinear'>dsldLinear</h2><span id='topic+dsldLinear'></span><span id='topic+predict.dsldLM'></span><span id='topic+coef.dsldLM'></span><span id='topic+vcov.dsldLM'></span><span id='topic+summary.dsldLM'></span>

<h3>Description</h3>

 
<p>Comparison of sensitive groups via linear models, with or
without interactions with the sensitive variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsldLinear(data, yName, sName, interactions = FALSE, sComparisonPts = NULL, 
    useSandwich = FALSE)
## S3 method for class 'dsldLM'
summary(object,...)
## S3 method for class 'dsldLM'
predict(object,xNew,...)
## S3 method for class 'dsldLM'
coef(object,...)
## S3 method for class 'dsldLM'
vcov(object,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dsldLinear_+3A_data">data</code></td>
<td>

<p>Data frame. 
</p>
</td></tr>
<tr><td><code id="dsldLinear_+3A_yname">yName</code></td>
<td>

<p>Name of the response variable Y column. 
</p>
</td></tr>
<tr><td><code id="dsldLinear_+3A_sname">sName</code></td>
<td>

<p>Name of the sensitive attribute S column. 
</p>
</td></tr>
<tr><td><code id="dsldLinear_+3A_interactions">interactions</code></td>
<td>

<p>Logical value indicating whether or not to model interactions with the
sensitive variable S. 
</p>
</td></tr>
<tr><td><code id="dsldLinear_+3A_scomparisonpts">sComparisonPts</code></td>
<td>

<p>If <code>interactions</code> is TRUE, a data frame of new 
cases for which mean Y | X will be compared across
each pair of S levels. Must be in the same 
format as original data.
</p>
</td></tr>
<tr><td><code id="dsldLinear_+3A_usesandwich">useSandwich</code></td>
<td>

<p>If TRUE, use the &quot;sandwich&quot; variance estimator.
</p>
</td></tr>
<tr><td><code id="dsldLinear_+3A_object">object</code></td>
<td>

<p>An object returned by the <code>dsldLinear</code> function.  
</p>
</td></tr>
<tr><td><code id="dsldLinear_+3A_xnew">xNew</code></td>
<td>

<p>New data to be predicted. Must be in the same format as original data.
</p>
</td></tr>
<tr><td><code id="dsldLinear_+3A_...">...</code></td>
<td>

<p>Further arguments.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>dsldLinear</code> function fits a linear model to the response
variable Y using all other variables in <code>data</code>.  The user may
select for interactions with the sensitive variable S. 
</p>
<p>The function produces an instance of the 'dsldLM' class (an S3
object).  Instances of the generic functions <code>summary</code> and
<code>coef</code> are provided.
</p>
<p>If <code>interactions</code> is TRUE, the function will fit m separate
models, where m is the number of levels of S. Then <code>summary</code> 
will contain m+1 data frames; the first m of which will be the
outputs from the individual models.  
</p>
<p>The m+1st data frame will compare the differences
in conditional mean Y|X for each pair of S levels, and for each
value of X in <code>sComparisonPts</code>.
The intention is to allow users to see the comparisons
of conditions for sensitive groups via linear models, with 
interactions with S.
</p>
<p>The <code>dsldDiffS</code> function allows users to compare mean Y at that
X between each pair of S level for additional new unseen data levels
using the model fitted from <code>dsldLinear</code>.
</p>


<h3>Value</h3>

<p>The <code>dsldLinear</code> function returns an S3 object of class 'dsldLM',
with one component for each level of S. Each component includes
information about the fitted model.
</p>


<h3>Author(s)</h3>

<p>N. Matloff, A. Mittal, A. Ashok
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  
data(svcensus) 

newData &lt;- svcensus[c(1, 18), -c(4,6)] 
lin1 &lt;- dsldLinear(svcensus, 'wageinc', 'gender', interactions = TRUE,
    newData)
coef(lin1)
vcov(lin1) 
summary(lin1)
predict(lin1, newData)

lin2 &lt;- dsldLinear(svcensus, 'wageinc', 'gender', interactions = FALSE)
summary(lin2)
</code></pre>

<hr>
<h2 id='dsldLogit'>dsldLogit</h2><span id='topic+dsldLogit'></span><span id='topic+predict.dsldGLM'></span><span id='topic+coef.dsldGLM'></span><span id='topic+vcov.dsldGLM'></span><span id='topic+summary.dsldGLM'></span>

<h3>Description</h3>

 
<p>Comparison of conditions for sensitive groups via logistic regression
models, with or without interactions with the sensitive variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsldLogit(data, yName, sName, sComparisonPts = NULL, interactions = FALSE, 
   yesYVal)
## S3 method for class 'dsldGLM'
summary(object,...)
## S3 method for class 'dsldGLM'
predict(object,xNew,...)
## S3 method for class 'dsldGLM'
coef(object,...)
## S3 method for class 'dsldGLM'
vcov(object,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dsldLogit_+3A_data">data</code></td>
<td>

<p>Data frame used to train the linear model; will be split according to
each level of <code>sName</code> in output if <code>interactions</code> is TRUE. 
</p>
</td></tr>
<tr><td><code id="dsldLogit_+3A_yname">yName</code></td>
<td>

<p>Name of the response variable column. 
</p>
</td></tr>
<tr><td><code id="dsldLogit_+3A_sname">sName</code></td>
<td>

<p>Name of the sensitive attribute column. 
</p>
</td></tr>
<tr><td><code id="dsldLogit_+3A_interactions">interactions</code></td>
<td>

<p>If TRUE, fit interactions with the sensitive variable. 
</p>
</td></tr>
<tr><td><code id="dsldLogit_+3A_scomparisonpts">sComparisonPts</code></td>
<td>

<p>If <code>interactions</code> is TRUE, a
a data frame of new cases (minus Y,S) for which P(Y = 1| X) 
will be compared between each pairs of S levels. Must be
in the same format as the original data. 
</p>
</td></tr>
<tr><td><code id="dsldLogit_+3A_yesyval">yesYVal</code></td>
<td>

<p>Y value to be considered 'yes', to be coded 1 rather than 0.
</p>
</td></tr>
<tr><td><code id="dsldLogit_+3A_object">object</code></td>
<td>

<p>An object returned by <code>dsldLogit</code>. 
</p>
</td></tr>
<tr><td><code id="dsldLogit_+3A_xnew">xNew</code></td>
<td>

<p>Dataframe to predict new cases. Must be in the same format 
as <code>data</code>.
</p>
</td></tr>
<tr><td><code id="dsldLogit_+3A_...">...</code></td>
<td>
<p>Further arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>dsldLogit</code> function fits a logistic 
regression model to the response variable. Interactions are handled
as in <code>dsldLinear</code>.
</p>


<h3>Value</h3>

<p>The <code>dsldLog</code> function returns an S3 object of class 'dsldGLM',
with one component for each level of S. Each component includes
information about the fitted model.
</p>


<h3>Author(s)</h3>

<p>N. Matloff, A. Mittal, A. Ashok
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(lsa)
newData &lt;- lsa[c(2,22,222,2222),-c(8,11)]
log1 &lt;- dsldLogit(lsa,'bar','race1', newData, interactions = TRUE, 'TRUE')

coef(log1)
vcov(log1) 
summary(log1) 
predict(log1, newData)
            
log2 &lt;- dsldLogit(data = lsa,
    yName = 'bar',sName = 'gender', 
    interactions = FALSE, yesYVal = 'TRUE')
summary(log2)
</code></pre>

<hr>
<h2 id='dsldMatchedATE'>dsldMatchedATE</h2><span id='topic+dsldMatchedATE'></span>

<h3>Description</h3>

<p>Causal inference via matching models.
Wrapper for <code>Matching::Match</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsldMatchedATE(data,yName,sName,yesSVal,yesYVal=NULL,
   propensFtn=NULL,k=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dsldMatchedATE_+3A_data">data</code></td>
<td>
<p>Data frame.</p>
</td></tr>
<tr><td><code id="dsldMatchedATE_+3A_yname">yName</code></td>
<td>
<p>Name of the response variable column.</p>
</td></tr>
<tr><td><code id="dsldMatchedATE_+3A_sname">sName</code></td>
<td>
<p> Name of the sensitive attribute column. The
attribute must be dichotomous.</p>
</td></tr>
<tr><td><code id="dsldMatchedATE_+3A_yessval">yesSVal</code></td>
<td>
<p>S value to be considered &quot;yes,&quot; to be coded 
1 rather than 0.</p>
</td></tr>
<tr><td><code id="dsldMatchedATE_+3A_yesyval">yesYVal</code></td>
<td>
<p>Y value to be considered &quot;yes,&quot; to be coded 
1 rather than 0.</p>
</td></tr>
<tr><td><code id="dsldMatchedATE_+3A_propensftn">propensFtn</code></td>
<td>
<p>Either 'glm' (logistic), or 'knn'.</p>
</td></tr>
<tr><td><code id="dsldMatchedATE_+3A_k">k</code></td>
<td>
<p>Number of nearest neighbors if <code>propensFtn='knn'.</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a <span class="pkg">dsld</span> wrapper for <code>Matching::Match</code>. 
</p>
<p>Matched analysis is typically applied to measuring &quot;treatment effects,&quot;
but is often applied in situations in which the &quot;treatment,&quot; S here, is
an immutable attribute such as race or gender. The usual issues
concerning observational studies apply.
</p>
<p>The function <code>dsldMatchedATE</code> finds the estimated mean difference
between the matched Y pairs in the treated/nontreated (exposed and
non-exposed) groups, with covariates X in <code>data</code> other than the
<code>yName</code> and <code>sName</code> columns.
</p>
<p>In the propensity model case, we estimate P(S = 1 | X), either by a logistic
or k-NN model.
</p>


<h3>Value</h3>

<p>Object of class 'Match'. See documentation in the 
<span class="pkg">Matching</span> package.
</p>


<h3>Author(s)</h3>

<p>N. Matloff
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(lalonde,package='Matching')
ll &lt;- lalonde
ll$treat &lt;- as.factor(ll$treat)
ll$re74 &lt;- NULL
ll$re75 &lt;- NULL
summary(dsldMatchedATE(ll,'re78','treat','1')) 
summary(dsldMatchedATE(ll,'re78','treat','1',propensFtn='glm'))
summary(dsldMatchedATE(ll,'re78','treat','1',propensFtn='knn',k=15))
</code></pre>

<hr>
<h2 id='dsldML'>dsldML</h2><span id='topic+dsldML'></span>

<h3>Description</h3>

 
<p>Nonparametric comparison of sensitive groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsldML(data,yName,sName,qeMLftnName,sComparisonPts="rand5",
    opts=NULL,holdout=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dsldML_+3A_data">data</code></td>
<td>

<p>A data frame.
</p>
</td></tr>
<tr><td><code id="dsldML_+3A_yname">yName</code></td>
<td>

<p>Name of the response variable column. 
</p>
</td></tr>
<tr><td><code id="dsldML_+3A_sname">sName</code></td>
<td>

<p>Name(s) of the sensitive attribute column(s).
</p>
</td></tr>
<tr><td><code id="dsldML_+3A_qemlftnname">qeMLftnName</code></td>
<td>

<p>Quoted name of a prediction function in the <code>qeML</code> package.
</p>
</td></tr>
<tr><td><code id="dsldML_+3A_scomparisonpts">sComparisonPts</code></td>
<td>

<p>Data frame of one or more data points at which the regression
function is to be estimated for each level of S.  If this is 
'rand5', then the said data points will consist of five randomly 
chosen rows in the original dataset.
</p>
</td></tr>
<tr><td><code id="dsldML_+3A_opts">opts</code></td>
<td>

<p>An R list specifying arguments for the above <code>qeML</code> function.
</p>
</td></tr>
<tr><td><code id="dsldML_+3A_holdout">holdout</code></td>
<td>

<p>The size of holdout set.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In a linear model with no interactions, one can speak of &quot;the&quot;
difference in mean Y given X across treatments, independent of X. 
In a nonparametric analysis, there is interaction by definition,
and one can only speak of differences across treatments for a
specific X value. Hence the need for the argument
<code>sComparisonPts</code>.
</p>
<p>The specified <code>qeML</code> function will be called on the indicated data once
for each level of the sensitive variable.  For each such level, estimated
regression function values will be obtained for each row in
<code>sComparisonPts</code>.
</p>


<h3>Value</h3>

<p>An R list. The first component consists of the holdout-set prediction
accuracies, while the second is a data frame predicted values for each
sensitive group.
</p>


<h3>Author(s)</h3>

<p>N. Matloff
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  
data(svcensus) 
w &lt;- dsldML(svcensus,'wageinc','gender',qeMLftnName='qeKNN',
   opts=list(k=50))
print(w)
</code></pre>

<hr>
<h2 id='dsldScatterPlot3D'>ScatterPlot3D in dsld</h2><span id='topic+dsldScatterPlot3D'></span>

<h3>Description</h3>

<p> Plotly 3D visualization of  a dataset on 3 axes, 
with points color-coded on a 4th variable.</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsldScatterPlot3D(data, yNames, sName, sGroups = NULL, sortedBy =
  "Name", numGroups = 8, maxPoints = NULL, xlim = NULL,
  ylim = NULL, zlim = NULL, main = NULL, colors =
  "Paired", opacity = 1, pointSize = 8)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dsldScatterPlot3D_+3A_data">data</code></td>
<td>

<p>Data frame with at least 4 columns. 
</p>
</td></tr>
<tr><td><code id="dsldScatterPlot3D_+3A_ynames">yNames</code></td>
<td>

<p>Vector of the indices or names of the columns of the data frame to be 
graphed on the 3 axes. 
</p>
</td></tr>
<tr><td><code id="dsldScatterPlot3D_+3A_sname">sName</code></td>
<td>

<p>Index or name of the column that contains the groups for which the data
will be grouped by. This will affect the colors of the points of the graph. 
This column must be an R factor.
</p>
</td></tr>
<tr><td><code id="dsldScatterPlot3D_+3A_sgroups">sGroups</code></td>
<td>

<p>Vector of the names of the groups for which the data will be grouped by. 
Every value in the vector must exist in the <code>sName</code> column of the data
frame.  If not supplied or is NULL, the function will create this 
automatically according to the <code>sortedby</code> and <code>numgrps</code> parameters.
By default, the function uses the 8 alphabetically first distinct groups 
in the <code>sName</code> column.
</p>
</td></tr>
<tr><td><code id="dsldScatterPlot3D_+3A_sortedby">sortedBy</code></td>
<td>

<p>Controls how <code>sGroups</code> is created automatically. If <code>sGroups</code> 
is supplied, this does nothing. One of three values: &quot;Name&quot;, &quot;Frequency&quot;, 
&quot;Frequency-Descending&quot;. 
</p>
<p>&quot;Name&quot; gets the first values alphabetically.
&quot;Frequency&quot; gets the most frequently occuring values.
&quot;Frequency-Descending&quot; gets the least frequently occuring values.
</p>
</td></tr>
<tr><td><code id="dsldScatterPlot3D_+3A_numgroups">numGroups</code></td>
<td>

<p>Number of  groups to be automatically generated by the function. If 
<code>grpnames</code> is supplied, this does nothing. 
</p>
</td></tr>
<tr><td><code id="dsldScatterPlot3D_+3A_maxpoints">maxPoints</code></td>
<td>

<p>Limit to how many points may be displayed on the graph.
There is no limit by default.
</p>
</td></tr>
<tr><td><code id="dsldScatterPlot3D_+3A_xlim">xlim</code>, <code id="dsldScatterPlot3D_+3A_ylim">ylim</code>, <code id="dsldScatterPlot3D_+3A_zlim">zlim</code></td>
<td>

<p>The x, y and z limits, each a vector with c(min, max).
</p>
</td></tr>
<tr><td><code id="dsldScatterPlot3D_+3A_main">main</code></td>
<td>

<p>The title of the graph. By default, the <code>sName</code> &quot;vs. &quot; 
<code>yNames</code>.
</p>
</td></tr>
<tr><td><code id="dsldScatterPlot3D_+3A_colors">colors</code></td>
<td>

<p>Either a colorbrewer2.org palette name (e.g. &quot;YlOrRd&quot; or &quot;Blues&quot;), 
or a vector of colors to interpolate in hexadecimal   &quot;#RRGGBB&quot; format, 
or a color interpolation function like colorRamp().
</p>
</td></tr>
<tr><td><code id="dsldScatterPlot3D_+3A_opacity">opacity</code></td>
<td>

<p>A value between 0 and 1.
</p>
</td></tr>
<tr><td><code id="dsldScatterPlot3D_+3A_pointsize">pointSize</code></td>
<td>

<p>A value above 1.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An interactive Plotly visualization will be created, with the three
variables specified in <code>yNames</code>.  Points will be color-coded
according to <code>sName</code>. The plot can be rotated etc. using the mouse.
</p>


<h3>Value</h3>

<p>No value, plot.</p>


<h3>Author(s)</h3>

<p>J. Tran and B. Zarate
</p>


<h3>References</h3>

<p>https://plotly.com/r/3d-scatter-plots/
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(lsa)
dsldScatterPlot3D(lsa,sName = "race1", 
   yNames=c("ugpa", "lsat","age"), xlim=c(2,4))
</code></pre>

<hr>
<h2 id='dsldTakeALookAround'>dsldTakeALookAround</h2><span id='topic+dsldTakeALookAround'></span>

<h3>Description</h3>

<p>Evaluate feature sets for predicting Y while considering the
Fairness-Utility Tradeoff.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsldTakeALookAround(data, yName, sName, maxFeatureSetSize = (ncol(data) - 2), 
    holdout = floor(min(1000,0.1*nrow(data))))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dsldTakeALookAround_+3A_data">data</code></td>
<td>

<p>Data frame.
</p>
</td></tr>
<tr><td><code id="dsldTakeALookAround_+3A_yname">yName</code></td>
<td>

<p>Name of the response variable column. 
</p>
</td></tr>
<tr><td><code id="dsldTakeALookAround_+3A_sname">sName</code></td>
<td>

<p>Name of the sensitive attribute column.
</p>
</td></tr>
<tr><td><code id="dsldTakeALookAround_+3A_maxfeaturesetsize">maxFeatureSetSize</code></td>
<td>

<p>Maximum number of combinations of features to be 
included in the data frame. 
</p>
</td></tr>
<tr><td><code id="dsldTakeALookAround_+3A_holdout">holdout</code></td>
<td>

<p>If not NULL, form a holdout set of the specified size. After fitting to the 
remaining data, evaluate accuracy on the test set.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function provides a tool for exploring feature combinations to use
in predicting an outcome Y from features X and a sensitive variable S. 
</p>
<p>The features in X will first be considered singly, then doubly and so
on, up though feature combination size <code>maxFeatureSetSize</code>. Y is
prediction from X either a linear model (numeric Y) or logit
(dichotomous Y).
</p>
<p>The accuracy (based on qeML holdout) will be computed for each of these
cases: (a) Y predicted from the given feature combination C, (b) Y
predicted from the given feature combination C plus S, and (c) S predicted
from C. The difference between columns 'a' and 'b' shows the sacrifice
in utility stemming from not using S in our prediction of Y. (Due to
sampling variation, it is possible for column 'b' to be larger than
'a'.) The value in column 'c' shows fairness, the smaller the fairer.
</p>


<h3>Value</h3>

<p>Data frame whose first column consists of the variable names,
followed by columns 'a', 'b' and 'c' as described in 'details'.</p>


<h3>Author(s)</h3>

<p>N. Matloff, A. Ashok, S. Martha, A. Mittal
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# investigate predictive accuracy for a continuous Y,
# 'wageinc', using the default arguments for maxFeatureSetSize = 4
data(svcensus)
dsldTakeALookAround(svcensus, 'wageinc', 'gender', 4)

# investigate the predictive accuracy for a categorical Y, 
# 'educ', using the default arguments for maxFeatureSetSize = 4
dsldTakeALookAround(svcensus, 'educ', 'gender')
</code></pre>

<hr>
<h2 id='lak'>
Labor Market Discrimination
</h2><span id='topic+lak'></span>

<h3>Description</h3>

<p>Fictional CVs sent to real employers to investigate discrimination via
given names. See Mullainathan and Bertran (2004).
</p>


<h3>References</h3>


<ul>
<li><p> Mullainathan, S. and Bertran, M. (2004). Are Emily and Greg More
Employable Than Lakisha and Jamal? A Field Experiment on 
Labor Market Discrimination. American Economic Review, 94:991-1013
</p>
</li></ul>


<hr>
<h2 id='mortgageSE'>
Mortgage Denial
</h2><span id='topic+mortgageSE'></span>

<h3>Description</h3>

<p>The dataset provides applicant information (including race, income, loan
information, etc.) The response variable indicates whether or not the
applicant was approved for the loan. Additional details can be found in
the <code>SortedEffects</code> package.
</p>

<hr>
<h2 id='svcensus'>
Silicon Valley programmers and engineers data
</h2><span id='topic+svcensus'></span>

<h3>Description</h3>

<p>Via qeML: This data set is adapted from the 2000 Census, 
restricted to programmers and engineers in the Silicon Valley area. 
</p>

<hr>
<h2 id='utilities'>
Utitlities
</h2><span id='topic+getSuggestedLib'></span>

<h3>Description</h3>

<p>Attempts to load the specified package, halting execution upon failure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   getSuggestedLib(pkgName)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="utilities_+3A_pkgname">pkgName</code></td>
<td>
<p>Name of the package to be checked/loaded.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No value, just side effects.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
