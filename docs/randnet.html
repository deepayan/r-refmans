<!DOCTYPE html><html><head><title>Help for package randnet</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {randnet}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#BHMC.estimate'>
<p>Estimates the number of communities under block models by the spectral</p>
methods</a></li>
<li><a href='#BlockModel.Gen'>
<p>Generates networks from degree corrected stochastic block model</p></a></li>
<li><a href='#ConsensusClust'>
<p>clusters nodes by concensus (majority voting) initialized by regularized spectral clustering</p></a></li>
<li><a href='#DCSBM.estimate'>
<p>Estimates DCSBM model</p></a></li>
<li><a href='#ECV.block'>
<p>selecting block models by ECV</p></a></li>
<li><a href='#ECV.nSmooth.lowrank'>
<p>selecting tuning parameter for neighborhood smoothing estimation of</p>
graphon model</a></li>
<li><a href='#ECV.Rank'>
<p>estimates optimal low rank model for a network</p></a></li>
<li><a href='#InformativeCore'>
<p>identify the informative core component of a network</p></a></li>
<li><a href='#LRBIC'>
<p>selecting number of communities by asymptotic likelihood ratio</p></a></li>
<li><a href='#LSM.PGD'>
<p>estimates inner product latent space model by projected gradient descent</p></a></li>
<li><a href='#NCV.select'>
<p>selecting block models by NCV</p></a></li>
<li><a href='#network.mixing'>
<p>estimates network connection probability by network mixing</p></a></li>
<li><a href='#network.mixing.Bfold'>
<p>estimates network connection probability by network mixing with B-fold averaging</p></a></li>
<li><a href='#NMI'>
<p>calculates normalized mutual information</p></a></li>
<li><a href='#NSBM.estimate'>
<p>estimates nomination SBM parameters given community labels by the method of moments</p></a></li>
<li><a href='#NSBM.Gen'>
<p>Generates networks from nomination stochastic block model</p></a></li>
<li><a href='#nSmooth'>
<p>estimates probabilty matrix by neighborhood smoothing</p></a></li>
<li><a href='#randnet-package'>
<p>Statistical modeling of random networks with model estimation, selection and</p>
parameter tuning</a></li>
<li><a href='#RDPG.Gen'>
<p>generates random networks from random dot product graph model</p></a></li>
<li><a href='#reg.SP'>
<p>clusters nodes by regularized spectral clustering</p></a></li>
<li><a href='#reg.SSP'>
<p>detects communities by regularized spherical spectral clustering</p></a></li>
<li><a href='#RightSC'>
<p>clusters nodes in a directed network by regularized spectral clustering on right singular vectors</p></a></li>
<li><a href='#SBM.estimate'>
<p>estimates SBM parameters given community labels</p></a></li>
<li><a href='#smooth.oracle'>
<p>oracle smooth graphon estimation</p></a></li>
<li><a href='#USVT'>
<p>estimates the network probability matrix by the improved universal singular value thresholding</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Random Network Model Estimation, Selection and Parameter Tuning</td>
</tr>
<tr>
<td>Version:</td>
<td>0.7</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-05-11</td>
</tr>
<tr>
<td>Description:</td>
<td>Model selection and parameter tuning procedures for a class of random network models. The model selection can be done by a general cross-validation framework called ECV from Li et. al. (2016) &lt;<a href="https://arxiv.org/abs/1612.04717">arXiv:1612.04717</a>&gt; . Several other model-based and task-specific methods are also included, such as NCV from Chen and Lei (2016) &lt;<a href="https://arxiv.org/abs/1411.1715">arXiv:1411.1715</a>&gt;, likelihood ratio method from Wang and Bickel (2015) &lt;<a href="https://arxiv.org/abs/1502.02069">arXiv:1502.02069</a>&gt;, spectral methods from Le and Levina (2015) &lt;<a href="https://arxiv.org/abs/1507.00827">arXiv:1507.00827</a>&gt;. Many network analysis methods are also implemented, such as the regularized spectral clustering (Amini et. al. 2013 &lt;<a href="https://doi.org/10.1214%2F13-AOS1138">doi:10.1214/13-AOS1138</a>&gt;) and its degree corrected version and graphon neighborhood smoothing (Zhang et. al. 2015 &lt;<a href="https://arxiv.org/abs/1509.08588">arXiv:1509.08588</a>&gt;). It also includes the consensus clustering of Gao et. al. (2014) &lt;<a href="https://arxiv.org/abs/1410.5837">arXiv:1410.5837</a>&gt;, the method of moments estimation of nomination SBM of Li et. al. (2020) &lt;<a href="https://arxiv.org/abs/2008.03652">arXiv:2008.03652</a>&gt;, and the network mixing method of Li and Le (2021) &lt;<a href="https://arxiv.org/abs/2106.02803">arXiv:2106.02803</a>&gt;. It also includes the informative core-periphery data processing method of Miao and Li (2021) &lt;<a href="https://arxiv.org/abs/2101.06388">arXiv:2101.06388</a>&gt;. The work to build and improve this package is partially supported by the NSF grants DMS-2015298 and DMS-2015134.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Depends:</td>
<td>Matrix, entropy, AUC,sparseFLMM, mgcv</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, stats, poweRlaw, RSpectra,
irlba,pracma,nnls,data.table</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-05-20 02:05:10 UTC; tianxili</td>
</tr>
<tr>
<td>Author:</td>
<td>Tianxi Li [aut, cre],
  Elizeveta Levina [aut],
  Ji Zhu [aut],
  Can M. Le [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Tianxi Li &lt;tianxili@virginia.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-05-20 07:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='BHMC.estimate'>
Estimates the number of communities under block models by the spectral
methods
</h2><span id='topic+BHMC.estimate'></span>

<h3>Description</h3>

<p>Estimates the number of communities under block models by using the
spectral properties of network Beth-Hessian matrix with moment correction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BHMC.estimate(A, K.max = 15)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BHMC.estimate_+3A_a">A</code></td>
<td>

<p>adjacency matrix of the network
</p>
</td></tr>
<tr><td><code id="BHMC.estimate_+3A_k.max">K.max</code></td>
<td>

<p>the maximum possible number of communities to check
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the method cannot distinguish SBM and DCSBM. But it works
under either model.
</p>


<h3>Value</h3>

<p>A list of result
</p>
<table>
<tr><td><code>K</code></td>
<td>
<p>Estimated K</p>
</td></tr>
<tr><td><code>values</code></td>
<td>
<p>eigenvalues of the Beth-Hessian matrix</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tianxi Li, Elizaveta Levina, Ji Zhu<br />
Maintainer: Tianxi Li  <a href="mailto:tianxili@virginia.edu">tianxili@virginia.edu</a>
</p>


<h3>References</h3>

<p>C. M. Le and E. Levina. Estimating the number of communities in networks by spectral
methods. arXiv preprint arXiv:1507.00827, 2015.
</p>


<h3>See Also</h3>

<p><code>LRBIC</code>,<code>ECV.Block</code>, <code>NCV.select</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dt &lt;- BlockModel.Gen(30,300,K=3,beta=0.2,rho=0.9,simple=FALSE,power=TRUE)


A &lt;- dt$A


bhmc &lt;- BHMC.estimate(A,15)

bhmc

</code></pre>

<hr>
<h2 id='BlockModel.Gen'>
Generates networks from degree corrected stochastic block model
</h2><span id='topic+BlockModel.Gen'></span>

<h3>Description</h3>

<p>Generates networks from degree corrected stochastic block model, with
various options for node degree distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BlockModel.Gen(lambda, n, beta = 0, K = 3, w = rep(1, K),
 Pi = rep(1, K)/K, rho = 0, simple = TRUE, power = TRUE,
alpha = 5, degree.seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BlockModel.Gen_+3A_lambda">lambda</code></td>
<td>

<p>average node degree
</p>
</td></tr>
<tr><td><code id="BlockModel.Gen_+3A_n">n</code></td>
<td>

<p>size of network
</p>
</td></tr>
<tr><td><code id="BlockModel.Gen_+3A_beta">beta</code></td>
<td>

<p>out-in ratio: the ratio of between-block edges over within-block edges
</p>
</td></tr>
<tr><td><code id="BlockModel.Gen_+3A_k">K</code></td>
<td>

<p>number of communities
</p>
</td></tr>
<tr><td><code id="BlockModel.Gen_+3A_w">w</code></td>
<td>

<p>not effective
</p>
</td></tr>
<tr><td><code id="BlockModel.Gen_+3A_pi">Pi</code></td>
<td>

<p>a vector of community proportion
</p>
</td></tr>
<tr><td><code id="BlockModel.Gen_+3A_rho">rho</code></td>
<td>

<p>proportion of small degrees within each community if the degrees are
from two point mass disbribution. rho &gt;0 gives degree corrected block
model. If rho &gt; 0 and simple=TRUE, then generate the degrees from two
point mass distribution, with rho porition of 0.2 values and 1-rho
proportion of 1 for degree parameters. If rho=0, generate from SBM.
</p>
</td></tr>
<tr><td><code id="BlockModel.Gen_+3A_simple">simple</code></td>
<td>

<p>Indicator of wether two point mass degrees are used, if rho &gt; 0. If
rho=0, this is not effective
</p>
</td></tr>
<tr><td><code id="BlockModel.Gen_+3A_power">power</code></td>
<td>

<p>Whether or not use powerlaw distribution for degrees. If FALSE, generate
from theta from U(0.2,1); if TRUE, generate theta from powerlaw. Only
effective if rho &gt;0, simple=FALSE.
</p>
</td></tr>
<tr><td><code id="BlockModel.Gen_+3A_alpha">alpha</code></td>
<td>

<p>Shape parameter for powerlaw distribution.
</p>
</td></tr>
<tr><td><code id="BlockModel.Gen_+3A_degree.seed">degree.seed</code></td>
<td>

<p>Can be a vector of a prespecified values for theta. Then the function
will do sampling with replacement from the vector to generate theta. It
can be used to control noise level between different configuration settings.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of
</p>
<table>
<tr><td><code>A</code></td>
<td>
<p>the generated network adjacency matrix</p>
</td></tr>
<tr><td><code>g</code></td>
<td>
<p>community membership</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>probability matrix of the network</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>node degree parameter</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tianxi Li, Elizaveta Levina, Ji Zhu<br />
Maintainer: Tianxi Li  <a href="mailto:tianxili@virginia.edu">tianxili@virginia.edu</a>
</p>


<h3>References</h3>

<p>B. Karrer and M. E. Newman. Stochastic blockmodels and community structure in networks.
Physical Review E, 83(1):016107, 2011.
</p>
<p>A. A. Amini, A. Chen, P. J. Bickel, and E. Levina. Pseudo-likelihood
methods for community detection in large sparse networks. The Annals of
Statistics, 41(4):2097-2122, 2013.
</p>
<p>T. Li, E. Levina, and J. Zhu. Network cross-validation by edge sampling. Biometrika, 107(2), pp.257-276, 2020.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dt &lt;- BlockModel.Gen(30,300,K=3,beta=0.2,rho=0.9,simple=FALSE,power=TRUE)



</code></pre>

<hr>
<h2 id='ConsensusClust'>
clusters nodes by concensus (majority voting) initialized by regularized spectral clustering
</h2><span id='topic+ConsensusClust'></span>

<h3>Description</h3>

<p>community detection by concensus (majority voting) initialized by regularized spectral clustering
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ConsensusClust(A,K,tau=0.25,lap=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ConsensusClust_+3A_a">A</code></td>
<td>

<p>adjacency matrix
</p>
</td></tr>
<tr><td><code id="ConsensusClust_+3A_k">K</code></td>
<td>

<p>number of communities
</p>
</td></tr>
<tr><td><code id="ConsensusClust_+3A_tau">tau</code></td>
<td>

<p>reguarlization parameter for regularized spectral clustering. Default value is 0.25. Typically set between 0
and 1. If tau=0, no regularization is applied.
</p>
</td></tr>
<tr><td><code id="ConsensusClust_+3A_lap">lap</code></td>
<td>

<p>indicator. If TRUE, the  Laplacian matrix for initializing clustering. If FALSE, the
adjacency matrix will be used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Community detection algorithm by majority voting algorithm of Gao
et. al. (2016). When initialized by regularized spectral clustering, it
is shown that the clustering accuracy of this algorithm gives minimax
rate under the SBM. However, it can slow compared with spectral clustering.
</p>


<h3>Value</h3>

<p>cluster labels
</p>


<h3>Author(s)</h3>

<p>Tianxi Li, Elizaveta Levina, Ji Zhu<br />
</p>
<p>Maintainer: Tianxi Li &lt;tianxili@virginia.edu&gt;
</p>


<h3>References</h3>

<p>Gao, C.; Ma, Z.; Zhang, A. Y. &amp; Zhou, H. H. Achieving optimal misclassification proportion in stochastic block models The Journal of Machine Learning Research, JMLR. org, 2017, 18, 1980-2024
</p>


<h3>See Also</h3>

<p><code><a href="#topic+reg.SP">reg.SP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

dt &lt;- BlockModel.Gen(15,50,K=2,beta=0.2,rho=0)


A &lt;- dt$A


cc &lt;- ConsensusClust(A,K=2,lap=TRUE)


</code></pre>

<hr>
<h2 id='DCSBM.estimate'>
Estimates DCSBM model
</h2><span id='topic+DCSBM.estimate'></span>

<h3>Description</h3>

<p>Estimates DCSBM model by given community labels
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DCSBM.estimate(A, g)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DCSBM.estimate_+3A_a">A</code></td>
<td>

<p>adjacency matrix
</p>
</td></tr>
<tr><td><code id="DCSBM.estimate_+3A_g">g</code></td>
<td>

<p>vector of community labels for the nodes
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimation is based on maximum likelhood.
</p>


<h3>Value</h3>

<p>A list object of
</p>
<table>
<tr><td><code>Phat</code></td>
<td>
<p>estimated probability matrix</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>the B matrix with block connection probability, up to a
scaling constant</p>
</td></tr>
<tr><td><code>Psi</code></td>
<td>
<p>vector of of degree parameter theta, up to a scaling constant</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tianxi Li, Elizaveta Levina, Ji Zhu<br />
Maintainer: Tianxi Li  <a href="mailto:tianxili@virginia.edu">tianxili@virginia.edu</a>
</p>


<h3>References</h3>

<p>B. Karrer and M. E. Newman. Stochastic blockmodels and community structure in networks.
Physical Review E, 83(1):016107, 2011.
</p>


<h3>See Also</h3>

<p><code>SBM.estimate</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dt &lt;- BlockModel.Gen(30,300,K=3,beta=0.2,rho=0.9,simple=FALSE,power=TRUE)


A &lt;- dt$A


ssc &lt;- reg.SSP(A,K=3,lap=TRUE)

est &lt;- DCSBM.estimate(A,ssc$cluster)

  </code></pre>

<hr>
<h2 id='ECV.block'>
selecting block models by ECV
</h2><span id='topic+ECV.block'></span>

<h3>Description</h3>

<p>Model selection by ECV for SBM and DCSBM. It can be used to select
between the two models or given on model (either SBM or DCSBM) and
select K.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ECV.block(A, max.K, cv = NULL, B = 3, holdout.p = 0.1, tau = 0, dc.est = 2, kappa = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ECV.block_+3A_a">A</code></td>
<td>

<p>adjacency matrix
</p>
</td></tr>
<tr><td><code id="ECV.block_+3A_max.k">max.K</code></td>
<td>

<p>largest possible K for number of communities
</p>
</td></tr>
<tr><td><code id="ECV.block_+3A_cv">cv</code></td>
<td>

<p>cross validation fold. The default value is NULL. We recommend to use
the argument B instead, doing indpendent sampling.
</p>
</td></tr>
<tr><td><code id="ECV.block_+3A_b">B</code></td>
<td>

<p>number of replications
</p>
</td></tr>
<tr><td><code id="ECV.block_+3A_holdout.p">holdout.p</code></td>
<td>

<p>testing set proportion
</p>
</td></tr>
<tr><td><code id="ECV.block_+3A_tau">tau</code></td>
<td>

<p>constant for numerical stability only. Not useful for current version.
</p>
</td></tr>
<tr><td><code id="ECV.block_+3A_dc.est">dc.est</code></td>
<td>

<p>estimation method for DCSBM. By defaulty (dc.est=2), the maximum
likelihood is used. If dc.est=1, the method used by Chen and Lei (2016)
is used, which is less stable according to our observation.
</p>
</td></tr>
<tr><td><code id="ECV.block_+3A_kappa">kappa</code></td>
<td>

<p>constant for numerical stability only. Not useful for current version.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The current version is based on a simple matrix completion procedure,
as described in the paper. The performance can be improved by better
matrix completion method that will be implemented in next
version. Moreover, the current implementation is better in
computational time but less efficient in memory. Another memory
efficient implementation will be added in next version.
</p>


<h3>Value</h3>

<table>
<tr><td><code>impute.err</code></td>
<td>
<p>average validaiton imputation error</p>
</td></tr>
<tr><td><code>l2</code></td>
<td>
<p>average validation L_2 loss under SBM</p>
</td></tr>
<tr><td><code>dev</code></td>
<td>
<p>average validation binomial deviance loss under SBM</p>
</td></tr>
<tr><td><code>auc</code></td>
<td>
<p>average validation AUC</p>
</td></tr>
<tr><td><code>dc.l2</code></td>
<td>
<p>average validation L_2 loss under DCSBM</p>
</td></tr>
<tr><td><code>dc.dev</code></td>
<td>
<p>average validation binomial deviance loss under DCSBM</p>
</td></tr>
<tr><td><code>sse</code></td>
<td>
<p>average validation SSE</p>
</td></tr>
<tr><td><code>l2.model</code></td>
<td>
<p>selected model by L_2 loss</p>
</td></tr>
<tr><td><code>dev.model</code></td>
<td>
<p>selected model by binomial deviance loss</p>
</td></tr>
<tr><td><code>l2.mat</code>, <code>dc.l2.mat</code>, <code>...</code></td>
<td>
<p>cross-validation loss matrix for B replications</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tianxi Li, Elizaveta Levina, Ji Zhu<br />
Maintainer: Tianxi Li  <a href="mailto:tianxili@virginia.edu">tianxili@virginia.edu</a>
</p>


<h3>References</h3>

<p>T. Li, E. Levina, and J. Zhu. Network cross-validation by edge sampling. Biometrika, 107(2), pp.257-276, 2020.
</p>


<h3>See Also</h3>

<p><code>NCV.select</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dt &lt;- BlockModel.Gen(30,300,K=3,beta=0.2,rho=0.9,simple=FALSE,power=TRUE)


A &lt;- dt$A

ecv &lt;- ECV.block(A,6,B=3)

ecv$l2.model
ecv$dev.model


which.min(ecv$l2)
which.min(ecv$dev)

which.min(ecv$dc.l2)
which.min(ecv$dc.dev)

which.max(ecv$auc)
which.min(ecv$sse)

</code></pre>

<hr>
<h2 id='ECV.nSmooth.lowrank'>
selecting tuning parameter for neighborhood smoothing estimation of
graphon model
</h2><span id='topic+ECV.nSmooth.lowrank'></span>

<h3>Description</h3>

<p>selecting tuning parameter for neighborhood smoothing estimation of
graphon model where the tuning parameter is to control estimation smoothness.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ECV.nSmooth.lowrank(A, h.seq, K, cv = NULL, B = 3, holdout.p = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ECV.nSmooth.lowrank_+3A_a">A</code></td>
<td>

<p>adjacency matrix
</p>
</td></tr>
<tr><td><code id="ECV.nSmooth.lowrank_+3A_h.seq">h.seq</code></td>
<td>

<p>a sequence of h values to tune. It is suggested h should be in the order
of sqrt(log(n)/n).
</p>
</td></tr>
<tr><td><code id="ECV.nSmooth.lowrank_+3A_k">K</code></td>
<td>

<p>the optimal rank for approximation. Can be obtained by rank selection of ECV.
</p>
</td></tr>
<tr><td><code id="ECV.nSmooth.lowrank_+3A_cv">cv</code></td>
<td>

<p>cross-validation fold. Recomend to use replication number B instead.
</p>
</td></tr>
<tr><td><code id="ECV.nSmooth.lowrank_+3A_b">B</code></td>
<td>

<p>independent replication number of random splitting
</p>
</td></tr>
<tr><td><code id="ECV.nSmooth.lowrank_+3A_holdout.p">holdout.p</code></td>
<td>

<p>proportion of test sample
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The neighborhood smoothing estimation can be slow, so the ECV may take
long even for moderately large networks.
</p>


<h3>Value</h3>

<p>a list object with
</p>
<table>
<tr><td><code>err</code></td>
<td>
<p>average validation error for h.seq</p>
</td></tr>
<tr><td><code>min.index</code></td>
<td>
<p>index of the minimum error</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tianxi Li, Elizaveta Levina, Ji Zhu<br />
Maintainer: Tianxi Li  <a href="mailto:tianxili@virginia.edu">tianxili@virginia.edu</a>
</p>


<h3>References</h3>

<p>T. Li, E. Levina, and J. Zhu. Network cross-validation by edge sampling. Biometrika, 107(2), pp.257-276, 2020.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(500)
N &lt;- 300

U = matrix(1:N,nrow=1) / (N+1)
V = matrix(1:N,nrow=1) / (N+1)

W = (t(U))^2
W = W/3*cos(1/(W + 1e-7)) + 0.15



upper.index &lt;- which(upper.tri(W))

A &lt;- matrix(0,N,N)


rand.ind &lt;- runif(length(upper.index))

edge.index &lt;- upper.index[rand.ind &lt; W[upper.index]]

A[edge.index] &lt;- 1

A &lt;- A + t(A)
diag(A) &lt;- 0


h.seq &lt;- sqrt(log(N)/N)*seq(0.5,5,by=0.5)


ecv.nsmooth &lt;- ECV.nSmooth.lowrank(A,h.seq,K=2,B=3) 

h &lt;- h.seq[ecv.nsmooth$min.index]


</code></pre>

<hr>
<h2 id='ECV.Rank'>
estimates optimal low rank model for a network
</h2><span id='topic+ECV.Rank'></span>

<h3>Description</h3>

<p>estimates the optimal low rank model for a network
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ECV.Rank(A, max.K, B = 3, holdout.p = 0.1, weighted = TRUE,mode="directed")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ECV.Rank_+3A_a">A</code></td>
<td>

<p>adjacency matrix
</p>
</td></tr>
<tr><td><code id="ECV.Rank_+3A_max.k">max.K</code></td>
<td>

<p>maximum possible rank to check
</p>
</td></tr>
<tr><td><code id="ECV.Rank_+3A_b">B</code></td>
<td>

<p>number of replications in ECV
</p>
</td></tr>
<tr><td><code id="ECV.Rank_+3A_holdout.p">holdout.p</code></td>
<td>

<p>test set proportion
</p>
</td></tr>
<tr><td><code id="ECV.Rank_+3A_weighted">weighted</code></td>
<td>

<p>whether the network is weighted. If TRUE, only sum of squared errors
are computed. If FALSE, then treat the network as
binary and AUC will be computed along with SSE.
</p>
</td></tr>
<tr><td><code id="ECV.Rank_+3A_mode">mode</code></td>
<td>

<p>Selectign the mode of &quot;directed&quot; or &quot;undirected&quot; for cross-validation.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>AUC is believed to be more accurate in
many simulations for binary networks. But the computation of AUC is much
slower than SSE, even slower than matrix completion steps.
</p>
<p>Note that we do not have to assume the true model is low rank. This
function simply finds a best low-rank approximation to the true model.
</p>


<h3>Value</h3>

<p>A list of
</p>
<table>
<tr><td><code>sse.rank</code></td>
<td>
<p>rank selection by SSE loss</p>
</td></tr>
<tr><td><code>auc.rank</code></td>
<td>
<p>rank selection by AUC loss</p>
</td></tr>
<tr><td><code>auc</code></td>
<td>
<p>auc sequence for each rank candidate</p>
</td></tr>
<tr><td><code>sse</code></td>
<td>
<p>sse sequence for each rank candidate</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tianxi Li, Elizaveta Levina, Ji Zhu<br />
Maintainer: Tianxi Li  <a href="mailto:tianxili@virginia.edu">tianxili@virginia.edu</a>
</p>


<h3>References</h3>

<p>T. Li, E. Levina, and J. Zhu. Network cross-validation by edge sampling. Biometrika, 107(2), pp.257-276, 2020.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ECV.block">ECV.block</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dt &lt;- BlockModel.Gen(30,300,K=3,beta=0.2,rho=0.9,simple=FALSE,power=TRUE)


A &lt;- dt$A


ecv.rank &lt;- ECV.Rank(A,6,weighted=FALSE,mode="undirected")

ecv.rank

</code></pre>

<hr>
<h2 id='InformativeCore'>
identify the informative core component of a network
</h2><span id='topic+InformativeCore'></span>

<h3>Description</h3>

<p>identify the informative core component of a network based on the spectral method of Miao and Li (2021). It can be used as a general data processing function for any network modeling purpose. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>InformativeCore(A,r=3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="InformativeCore_+3A_a">A</code></td>
<td>

<p>adjacency matrix. It does not have to be unweighted. 
</p>
</td></tr>
<tr><td><code id="InformativeCore_+3A_r">r</code></td>
<td>

<p>the rank for low-rank denoising. The rank can be selected by ECV or any other methods availale in the package.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function can be used as a general data processing function for any network modeling purpose. It automatically identify an informative core component with interesting connection structure and a noninformative periphery component with uninterestings structures. Depending on the user's preference, the uninteresting structure can be either the Erdos-Renyi type connections or configuration type of connections, both of which are generally regarded as noninformative structures. Including these additional non-informative structures in network models can potentially lower the modeling efficiency. Therefore, it is preferable to remove them and only focus on the core structure. Details can be found in the reference.
</p>


<h3>Value</h3>

<p>A list of
</p>
<table>
<tr><td><code>er.score</code></td>
<td>
<p>A n dimensional vector of informative scores for ER-type periphery. A larger score indicates the corresponding node is more likely to be in the core.</p>
</td></tr>
<tr><td><code>config.score</code></td>
<td>
<p>A n dimensional vector of informative scores for configuration-type periphery. A larger score indicates the corresponding node is more likely to be in the core.</p>
</td></tr>
<tr><td><code>er.theory.core</code></td>
<td>
<p>The indices of identified core structure in the ER-type model based on a theoretical threshold of the scores (for large sample size). </p>
</td></tr>
<tr><td><code>config.theory.core</code></td>
<td>
<p>The indices of identified core structure in the configuration-type model based on a theoretical threshold of the scores (for large sample size). </p>
</td></tr>
<tr><td><code>er.kmeans.core</code></td>
<td>
<p>The indices of identified core structure in the ER-type model based on kmeans clustering of the scores. </p>
</td></tr>
<tr><td><code>config.kmeans.core</code></td>
<td>
<p>The indices of identified core structure in the configuration-type model based on kmeans clustering of the scores (for large sample size). </p>
</td></tr>

</table>


<h3>Author(s)</h3>

<p>Tianxi Li, Elizaveta Levina, Ji Zhu, Can M. Le<br />
Maintainer: Tianxi Li  <a href="mailto:tianxili@virginia.edu">tianxili@virginia.edu</a>
</p>


<h3>References</h3>

<p>R. Miao and T. Li. Informative core identification in complex networks. arXiv preprint arXiv:2101.06388, 2021
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ECV.Rank">ECV.Rank</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(100)
dt &lt;- BlockModel.Gen(60,1000,K=3,beta=0.2,rho=0.9,simple=FALSE,power=TRUE)
### this is not an interesting case -- only for demonstration of the usage. 
### The network has no periphery nodes, all nodes are in the core.

A &lt;- dt$A


core.fit &lt;- InformativeCore(A,r=3)
length(core.fit$er.theory.core)
### essentially all nodes are selected as the core.

</code></pre>

<hr>
<h2 id='LRBIC'>
selecting number of communities by asymptotic likelihood ratio
</h2><span id='topic+LRBIC'></span>

<h3>Description</h3>

<p>selecting number of communities by asymptotic likelihood ratio based
the methdo of Wang and Bickel 2015
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LRBIC(A, Kmax, lambda = NULL, model = "both")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LRBIC_+3A_a">A</code></td>
<td>

<p>adjacency matrix
</p>
</td></tr>
<tr><td><code id="LRBIC_+3A_kmax">Kmax</code></td>
<td>

<p>the largest possible number of communities to check
</p>
</td></tr>
<tr><td><code id="LRBIC_+3A_lambda">lambda</code></td>
<td>

<p>a tuning parameter. By default, will use the number recommended in the paper.
</p>
</td></tr>
<tr><td><code id="LRBIC_+3A_model">model</code></td>
<td>

<p>selecting K under which model. If set to be &quot;SBM&quot;, the
calculation will be done under SBM. If set to be &quot;DCSBM&quot;, the
calculation will be done under DCSBM. The default value is &quot;both&quot; so
will give two selections under SBM and DCSBM respectively.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the method cannot distinguish SBM and DCSBM, though different
calculation is done under the two models. So it is not valid to compare
across models. The theoretical analysis of the method is done under
maximum likelhood and variational EM. But as suggested in the paper,
we use spectral clustering for community detection before fitting
maximum likelhood.
</p>


<h3>Value</h3>

<p>a list of
</p>
<table>
<tr><td><code>SBM.K</code></td>
<td>
<p>estimated number of communities under SBM</p>
</td></tr>
<tr><td><code>DCSBM.K</code></td>
<td>
<p>estimated number of communities under DCSBM</p>
</td></tr>
<tr><td><code>SBM.BIC</code></td>
<td>
<p>the BIC values for the K sequence under SBM</p>
</td></tr>
<tr><td><code>DCSBM.BIC</code></td>
<td>
<p>the BIC values for the K sequence under DCSBM</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tianxi Li, Elizaveta Levina, Ji Zhu<br />
Maintainer: Tianxi Li  <a href="mailto:tianxili@virginia.edu">tianxili@virginia.edu</a>
</p>


<h3>References</h3>

<p>Wang, Y. R. &amp; Bickel, P. J. Likelihood-based model selection for stochastic block models The Annals of Statistics, Institute of Mathematical Statistics, 2017, 45, 500-528
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BHMC.estimate">BHMC.estimate</a></code>, <code><a href="#topic+ECV.block">ECV.block</a></code>, <code><a href="#topic+NCV.select">NCV.select</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

dt &lt;- BlockModel.Gen(30,300,K=3,beta=0.2,rho=0.9,simple=FALSE,power=TRUE)


A &lt;- dt$A


### test LRBIC

lrbic &lt;- LRBIC(A,6,model="both")

lrbic$SBM.K

lrbic$DCSBM.K

</code></pre>

<hr>
<h2 id='LSM.PGD'>
estimates inner product latent space model by projected gradient descent
</h2><span id='topic+LSM.PGD'></span>

<h3>Description</h3>

<p>estimates inner product latent space model by projected gradient descent from the paper of Ma et al. (2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LSM.PGD(A, k,step.size=0.3,niter=500,trace=0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LSM.PGD_+3A_a">A</code></td>
<td>

<p>adjacency matrix
</p>
</td></tr>
<tr><td><code id="LSM.PGD_+3A_k">k</code></td>
<td>

<p>the dimension of the latent position
</p>
</td></tr>
<tr><td><code id="LSM.PGD_+3A_step.size">step.size</code></td>
<td>

<p>step size of gradient descent
</p>
</td></tr>
<tr><td><code id="LSM.PGD_+3A_niter">niter</code></td>
<td>

<p>maximum number of iterations
</p>
</td></tr>
<tr><td><code id="LSM.PGD_+3A_trace">trace</code></td>
<td>

<p>if trace &gt; 0, the objective will be printed out after each iteration
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method is based on the gradient descent of Ma et al (2020), with initialization of the universal singular value thresholding as discussed there. The parameter identifiability constraint is the same as in the paper.
</p>


<h3>Value</h3>

<p>a list of
</p>
<table>
<tr><td><code>Z</code></td>
<td>
<p>latent positions</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>individual parameter alpha as in the paper</p>
</td></tr>
<tr><td><code>Phat</code></td>
<td>
<p>esitmated probability matrix</p>
</td></tr>
<tr><td><code>obj</code></td>
<td>
<p>the objective of the gradient method</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tianxi Li and Can M. Le<br />
Maintainer: Tianxi Li  <a href="mailto:tianxili@virginia.edu">tianxili@virginia.edu</a>
</p>


<h3>References</h3>

<p>Z. Ma, Z. Ma, and H. Yuan. Universal latent space model fitting for large networks with edge
covariates. Journal of Machine Learning Research, 21(4):1-67, 2020.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DCSBM.estimate">DCSBM.estimate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dt &lt;- RDPG.Gen(n=600,K=2,directed=TRUE)


A &lt;- dt$A


fit &lt;- LSM.PGD(A,2,niter=50)

</code></pre>

<hr>
<h2 id='NCV.select'>
selecting block models by NCV
</h2><span id='topic+NCV.select'></span>

<h3>Description</h3>

<p>selecting block models by NCV of Chen and Lei (2016)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NCV.select(A, max.K, cv = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NCV.select_+3A_a">A</code></td>
<td>

<p>adjacency matrix
</p>
</td></tr>
<tr><td><code id="NCV.select_+3A_max.k">max.K</code></td>
<td>

<p>largest number of communities to check
</p>
</td></tr>
<tr><td><code id="NCV.select_+3A_cv">cv</code></td>
<td>

<p>fold of cross-validation
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Spectral clustering is used for fitting the block models
</p>


<h3>Value</h3>

<p>a list of
</p>
<table>
<tr><td><code>dev</code></td>
<td>
<p>the binomial deviance loss under SBM for each K</p>
</td></tr>
<tr><td><code>l2</code></td>
<td>
<p>the L_2 loss under SBM for each K</p>
</td></tr>
<tr><td><code>dc.dev</code></td>
<td>
<p>the binomial deviance loss under DCSBM for each K</p>
</td></tr>
<tr><td><code>dc.l2</code></td>
<td>
<p>the L_2 loss under DCSBM for each K</p>
</td></tr>
<tr><td><code>dev.model</code></td>
<td>
<p>the selected model by deviance loss</p>
</td></tr>
<tr><td><code>l2.model</code></td>
<td>
<p>the selected model by L_2 loss</p>
</td></tr>
<tr><td><code>sbm.l2.mat</code>, <code>sbm.dev.mat</code>, <code>....</code></td>
<td>
<p>the corresponding matrices of loss
for each fold (row) and each K value (column)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tianxi Li, Elizaveta Levina, Ji Zhu<br />
Maintainer: Tianxi Li  <a href="mailto:tianxili@virginia.edu">tianxili@virginia.edu</a>
</p>


<h3>References</h3>

<p>Chen, K. &amp; Lei, J. Network cross-validation for determining the number of communities in network data Journal of the American Statistical Association, Taylor &amp; Francis, 2018, 113, 241-251
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ECV.block">ECV.block</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dt &lt;- BlockModel.Gen(30,300,K=3,beta=0.2,rho=0.9,simple=FALSE,power=TRUE)


A &lt;- dt$A


ncv &lt;- NCV.select(A,6,3)

ncv$l2.model
ncv$dev.model

which.min(ncv$dev)
which.min(ncv$l2)

which.min(ncv$dc.dev)
which.min(ncv$dc.l2)

</code></pre>

<hr>
<h2 id='network.mixing'>
estimates network connection probability by network mixing
</h2><span id='topic+network.mixing'></span>

<h3>Description</h3>

<p>estimates network connection probability by network mixing of Li and Le (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>network.mixing(A,index=NULL,rho = 0.1,max.K=15,dcsbm=TRUE, usvt=TRUE,ns=FALSE,
                           lsm=FALSE,lsm.k=4,trace=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="network.mixing_+3A_a">A</code></td>
<td>

<p>adjacency matrix
</p>
</td></tr>
<tr><td><code id="network.mixing_+3A_index">index</code></td>
<td>

<p>a pre-specified hold-out set. If NULL, the set will be randomly generated according to rho.
</p>
</td></tr>
<tr><td><code id="network.mixing_+3A_rho">rho</code></td>
<td>

<p>hold-out proportion as validation entries. Only effective when index is NULL.
</p>
</td></tr>
<tr><td><code id="network.mixing_+3A_max.k">max.K</code></td>
<td>

<p>the maximum number of blocks used for the block model approximation (see details). 
</p>
</td></tr>
<tr><td><code id="network.mixing_+3A_dcsbm">dcsbm</code></td>
<td>

<p>whether to include the DCSBM as components, up to max.K. By default, the method will include it.
</p>
</td></tr>
<tr><td><code id="network.mixing_+3A_usvt">usvt</code></td>
<td>

<p>whether to include the USVT as a component. By default, the method will include it.
</p>
</td></tr>
<tr><td><code id="network.mixing_+3A_ns">ns</code></td>
<td>

<p>whether to include the neighborhood smoothing as a component. 
</p>
</td></tr>
<tr><td><code id="network.mixing_+3A_lsm">lsm</code></td>
<td>

<p>whether to include the gradient estimator of the latent space model as a component. 
</p>
</td></tr>
<tr><td><code id="network.mixing_+3A_lsm.k">lsm.k</code></td>
<td>

<p>the dimension of the latent space. Only effective if lsm is TRUE.
</p>
</td></tr>
<tr><td><code id="network.mixing_+3A_trace">trace</code></td>
<td>

<p>whether to print the model fitting progress.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The basic version of the mixing estimator will include SBM and DCSBM estimates with the number of blocks from 1 to max.K. Users could also specify whether to include additional USVT, neighborhood smoothing and latent space model estimators. If NNL (non-negative linear), exponential, or ECV is used, the mixing is usually robust for a reasonable range of max.K and whether to include the other models. The linear mixing, however, is vulnerable for a large number of base estimates. The NNL is our recommended method. USVT is also recommended. the neighborhood smoothing and latent space model are slower, so are not suitable for large networks. Details can be found in Li and Le (2021).
</p>


<h3>Value</h3>

<p>a list of
</p>
<table>
<tr><td><code>linear.Phat</code></td>
<td>
<p>estimated probability matrix by linear mixing</p>
</td></tr>
<tr><td><code>linear.weight</code></td>
<td>
<p>the weights of the indivdiual models in linear mixing</p>
</td></tr>
<tr><td><code>nnl.Phat</code></td>
<td>
<p>estimated probability matrix by NNL mixing</p>
</td></tr>
<tr><td><code>nnl.weight</code></td>
<td>
<p>the weights of the indivdiual models in NNL mixing</p>
</td></tr>
<tr><td><code>exp.Phat</code></td>
<td>
<p>estimated probability matrix by exponential mixing</p>
</td></tr>
<tr><td><code>exp.weight</code></td>
<td>
<p>the weights of the indivdiual models in exponential mixing</p>
</td></tr>
<tr><td><code>ecv.Phat</code></td>
<td>
<p>estimated probability matrix by ECV mixing (only one nonzero)</p>
</td></tr>
<tr><td><code>ecv.weight</code></td>
<td>
<p>the weights of the indivdiual models in ECV mixing (only one nonzero)</p>
</td></tr>
<tr><td><code>model.names</code></td>
<td>
<p>the names of all individual models, in the same order as the weights</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tianxi Li and Can M. Le<br />
</p>
<p>Maintainer: Tianxi Li &lt;tianxili@virginia.edu&gt;
</p>


<h3>References</h3>


<p>T. Li and C. M. Le, Network Estimation by Mixing: Adaptivity and More. arXiv preprint
arXiv:2106.02803, 2021.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

dt &lt;- RDPG.Gen(n=500,K=5,directed=TRUE)

A &lt;- dt$A

fit &lt;- network.mixing(A)
fit$model.names

fit$nnl.weight
</code></pre>

<hr>
<h2 id='network.mixing.Bfold'>
estimates network connection probability by network mixing with B-fold averaging
</h2><span id='topic+network.mixing.Bfold'></span>

<h3>Description</h3>

<p>estimates network connection probability by network mixing of Li and Le (2021) with B-fold averaging.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>network.mixing.Bfold(A,B=10,rho = 0.1,max.K=15,dcsbm=TRUE,usvt=TRUE,ns=FALSE,
                       lsm=FALSE,lsm.k=4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="network.mixing.Bfold_+3A_a">A</code></td>
<td>

<p>adjacency matrix
</p>
</td></tr>
<tr><td><code id="network.mixing.Bfold_+3A_b">B</code></td>
<td>

<p>number of random replications to average over
</p>
</td></tr>
<tr><td><code id="network.mixing.Bfold_+3A_rho">rho</code></td>
<td>

<p>hold-out proportion as validation entries. Only effective when index is NULL.
</p>
</td></tr>
<tr><td><code id="network.mixing.Bfold_+3A_max.k">max.K</code></td>
<td>

<p>the maximum number of blocks used for the block model approximation (see details). 
</p>
</td></tr>
<tr><td><code id="network.mixing.Bfold_+3A_dcsbm">dcsbm</code></td>
<td>

<p>whether to include the DCSBM as components, up to max.K. By default, the method will include it.
</p>
</td></tr>
<tr><td><code id="network.mixing.Bfold_+3A_usvt">usvt</code></td>
<td>

<p>whether to include the USVT as a component. By default, the method will include it.
</p>
</td></tr>
<tr><td><code id="network.mixing.Bfold_+3A_ns">ns</code></td>
<td>

<p>whether to include the neighborhood smoothing as a component. 
</p>
</td></tr>
<tr><td><code id="network.mixing.Bfold_+3A_lsm">lsm</code></td>
<td>

<p>whether to include the gradient estimator of the latent space model as a component. 
</p>
</td></tr>
<tr><td><code id="network.mixing.Bfold_+3A_lsm.k">lsm.k</code></td>
<td>

<p>the dimension of the latent space. Only effective if lsm is TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is essentially the same procedure as the network.mixing, but repeat it B times and return the average. Use with cautious. Though it can make the estimate more stable, the procedure would increase the computational cost by a factor of B. Based on our limited experience, this is usually not a great trade-off as the improvement might be marginal. 
</p>


<h3>Value</h3>

<p>a list of
</p>
<table>
<tr><td><code>linear.Phat</code></td>
<td>
<p>estimated probability matrix by linear mixing</p>
</td></tr>
<tr><td><code>nnl.Phat</code></td>
<td>
<p>estimated probability matrix by NNL mixing</p>
</td></tr>
<tr><td><code>exp.Phat</code></td>
<td>
<p>estimated probability matrix by exponential mixing</p>
</td></tr>
<tr><td><code>ecv.Phat</code></td>
<td>
<p>estimated probability matrix by ECV mixing (only one nonzero)</p>
</td></tr>
<tr><td><code>model.names</code></td>
<td>
<p>the names of all individual models, in the same order as the weights</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tianxi Li and Can M. Le<br />
</p>
<p>Maintainer: Tianxi Li &lt;tianxili@virginia.edu&gt;
</p>


<h3>References</h3>

<p>T. Li and C. M. Le, Network Estimation by Mixing: Adaptivity and More. arXiv preprint
arXiv:2106.02803, 2021.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+network.mixing">network.mixing</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

dt &lt;- RDPG.Gen(n=200,K=3,directed=TRUE)
A &lt;- dt$A

fit &lt;- network.mixing.Bfold(A,B=2)
</code></pre>

<hr>
<h2 id='NMI'>
calculates normalized mutual information
</h2><span id='topic+NMI'></span>

<h3>Description</h3>

<p>calculates normalized mutual information, a metric that is commonly
used to compare clustering results
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NMI(g1, g2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NMI_+3A_g1">g1</code></td>
<td>

<p>a vector of cluster labels
</p>
</td></tr>
<tr><td><code id="NMI_+3A_g2">g2</code></td>
<td>

<p>a vector of cluster labels (same length as g1)
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>NMI value
</p>


<h3>Author(s)</h3>

<p>Tianxi Li, Elizaveta Levina, Ji Zhu<br />
Maintainer: Tianxi Li  <a href="mailto:tianxili@virginia.edu">tianxili@virginia.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dt &lt;- BlockModel.Gen(30,300,K=3,beta=0.2,rho=0.9,simple=FALSE,power=TRUE)


A &lt;- dt$A


ssc &lt;- reg.SSP(A,K=3,lap=TRUE)

NMI(ssc$cluster,dt$g)


</code></pre>

<hr>
<h2 id='NSBM.estimate'>
estimates nomination SBM parameters given community labels by the method of moments
</h2><span id='topic+NSBM.estimate'></span>

<h3>Description</h3>

<p>estimates NSBM parameters given community labels
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NSBM.estimate(A,K,g,reg.bound=-Inf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NSBM.estimate_+3A_a">A</code></td>
<td>

<p>adjacency matrix of a directed where Aij = 1 iff i -&gt; j
</p>
</td></tr>
<tr><td><code id="NSBM.estimate_+3A_k">K</code></td>
<td>

<p>number of communities
</p>
</td></tr>
<tr><td><code id="NSBM.estimate_+3A_g">g</code></td>
<td>

<p>a vector of community labels
</p>
</td></tr>
<tr><td><code id="NSBM.estimate_+3A_reg.bound">reg.bound</code></td>
<td>

<p>the regularity lower bound of lambda value. By default, -Inf. That means, no constraints. When the network is sparse, using certain constaints may improve stability.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method of moments is used for estimating the edge nomination SBM, so the strategy can be used for both unweighted and weighted networks. The details can be found in Li et. al. (2020).
</p>


<h3>Value</h3>

<p>a list of
</p>
<table>
<tr><td><code>B</code></td>
<td>
<p>estimated block connection probability matrix</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>estimated lambda values for nomination intensity</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>estimated theta values for nomination preference</p>
</td></tr>
<tr><td><code>P.tilde</code></td>
<td>
<p>estimated composiste probability matrix after nomination</p>
</td></tr>
<tr><td><code>g</code></td>
<td>
<p>community labels</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tianxi Li, Elizaveta Levina, Ji Zhu<br />
Maintainer: Tianxi Li  <a href="mailto:tianxili@virginia.edu">tianxili@virginia.edu</a>
</p>


<h3>References</h3>

<p>T. Li, E. Levina, and J. Zhu. Community models for networks observed through edge nominations. arXiv preprint arXiv:2008.03652 (2020).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SBM.estimate">SBM.estimate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dt &lt;- NSBM.Gen(n=200,K=2,beta=0.2,avg.d=10)


A &lt;- dt$A


sc &lt;- RightSC(A,K=3)
est &lt;- NSBM.estimate(A,K=3,g=sc$cluster)

</code></pre>

<hr>
<h2 id='NSBM.Gen'>
Generates networks from nomination stochastic block model
</h2><span id='topic+NSBM.Gen'></span>

<h3>Description</h3>

<p>Generates networks from nomination stochastic block model for community structure in edge nomination procedures, proposed in Li et. al. (2020)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NSBM.Gen( n, K, avg.d,beta,theta.low=0.1,
    theta.p=0.2,lambda.scale=0.2,lambda.exp=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NSBM.Gen_+3A_n">n</code></td>
<td>

<p>size of network
</p>
</td></tr>
<tr><td><code id="NSBM.Gen_+3A_k">K</code></td>
<td>

<p>number of communities
</p>
</td></tr>
<tr><td><code id="NSBM.Gen_+3A_avg.d">avg.d</code></td>
<td>

<p>expected average degree of the resuling network (after edge nomination)
</p>
</td></tr>
<tr><td><code id="NSBM.Gen_+3A_beta">beta</code></td>
<td>

<p>the out-in ratio of the original SBM
</p>
</td></tr>
<tr><td><code id="NSBM.Gen_+3A_theta.low">theta.low</code></td>
<td>

<p>the lower value of theta's. The theta's are generated as two-point mass at theta.low and 1.
</p>
</td></tr>
<tr><td><code id="NSBM.Gen_+3A_theta.p">theta.p</code></td>
<td>

<p>proportion of lower value of theta's
</p>
</td></tr>
<tr><td><code id="NSBM.Gen_+3A_lambda.scale">lambda.scale</code></td>
<td>

<p>standard deviation of the lambda (before the exponential, see lambda.exp)
</p>
</td></tr>
<tr><td><code id="NSBM.Gen_+3A_lambda.exp">lambda.exp</code></td>
<td>

<p>If TRUE, lambda is generated as exponential of uniformation random randomes. Otherwise, they are normally distributed.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of
</p>
<table>
<tr><td><code>A</code></td>
<td>
<p>the generated network adjacency matrix</p>
</td></tr>
<tr><td><code>g</code></td>
<td>
<p>community membership</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>probability matrix of the orignal SBM network</p>
</td></tr>
<tr><td><code>P.tilde</code></td>
<td>
<p>probability matrix of the observed network after nomination</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>B parameter</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>lambda parameter</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>theta parameter</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tianxi Li, Elizaveta Levina, Ji Zhu<br />
Maintainer: Tianxi Li  <a href="mailto:tianxili@virginia.edu">tianxili@virginia.edu</a>
</p>


<h3>References</h3>

<p>T. Li, E. Levina, and J. Zhu. Community models for networks observed through edge nominations. arXiv preprint arXiv:2008.03652 (2020).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dt &lt;- NSBM.Gen(n=200,K=2,beta=0.2,avg.d=10)



</code></pre>

<hr>
<h2 id='nSmooth'>
estimates probabilty matrix by neighborhood smoothing
</h2><span id='topic+nSmooth'></span>

<h3>Description</h3>

<p>estimates probabilty matrix by neighborhood smoothing of Zhang
et. al. (2017)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nSmooth(A, h = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nSmooth_+3A_a">A</code></td>
<td>

<p>adjacency matrix
</p>
</td></tr>
<tr><td><code id="nSmooth_+3A_h">h</code></td>
<td>

<p>quantile value used for smoothing. Recommended to be in the scale of
sqrt(log(n)/n) where n is the size of the network. The default value
is sqrt(log(n)/n) from the paper.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method assumes a graphon model where the underlying graphon function
is piecewise Lipchitz. However, it may be slow for moderately large
networks, though it is one of the fastest methods for graphon models.
</p>


<h3>Value</h3>

<p>the probability matrix
</p>


<h3>Author(s)</h3>

<p>Tianxi Li, Elizaveta Levina, Ji Zhu<br />
</p>
<p>Maintainer: Tianxi Li &lt;tianxili@virginia.edu&gt;
</p>


<h3>References</h3>

<p>Zhang, Y.; Levina, E. &amp; Zhu, J. Estimating network edge probabilities by neighbourhood smoothing Biometrika, Oxford University Press, 2017, 104, 771-783
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

N &lt;- 100

U = matrix(1:N,nrow=1) / (N+1)
V = matrix(1:N,nrow=1) / (N+1)

W = (t(U))^2
W = W/3*cos(1/(W + 1e-7)) + 0.15

upper.index &lt;- which(upper.tri(W))

A &lt;- matrix(0,N,N)


rand.ind &lt;- runif(length(upper.index))

edge.index &lt;- upper.index[rand.ind &lt; W[upper.index]]

A[edge.index] &lt;- 1

A &lt;- A + t(A)
diag(A) &lt;- 0

What &lt;- nSmooth(A)


</code></pre>

<hr>
<h2 id='randnet-package'>
Statistical modeling of random networks with model estimation, selection and
parameter tuning
</h2><span id='topic+randnet-package'></span><span id='topic+randnet'></span>

<h3>Description</h3>

<p>The package provides model fitting and estimation functions for some
popular random network models. More importantly, it implements a general
cross-validation framework for model selection and parameter tuning
called ECV. Several other model selection methods are also included.
The work to build and improve this package is partially supported by the NSF
grants DMS-2015298 and DMS-2015134.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> randnet</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 0.7</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2023-05-11</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;= 2)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Tianxi Li, Elizaveta Levina, Ji Zhu, Can M. Le<br />
</p>
<p>Maintainer: Tianxi Li &lt;tianxili@virginia.edu&gt;
</p>


<h3>References</h3>

<p>T. Li, E. Levina, and J. Zhu. Network cross-validation by edge
sampling. Biometrika, 107(2), pp.257-276, 2020.
</p>
<p>K. Chen and J. Lei. Network cross-validation for determining the number
of communities in network data. Journal of the American Statistical
Association, 113(521):241-251, 2018.
</p>
<p>K. Rohe, S. Chatterjee, and B. Yu. Spectral clustering and the
high-dimensional stochastic blockmodel. The Annals of Statistics, pages
1878-1915, 2011.
</p>
<p>A. A. Amini, A. Chen, P. J. Bickel, and E. Levina. Pseudo-likelihood
methods for community detection in large sparse networks. The Annals
of Statistics, 41(4):2097-2122, 2013.
</p>
<p>Qin, T. &amp; Rohe, K. Regularized spectral clustering under the degree-corrected stochastic blockmodel Advances in Neural Information Processing Systems, 2013, 3120-3128
</p>
<p>J. Lei and A. Rinaldo. Consistency of spectral clustering in stochastic block models. The
Annals of Statistics, 43(1):215-237, 2014.
</p>
<p>C. M. Le, E. Levina, and R. Vershynin. Concentration and regularization of random graphs.
Random Structures &amp; Algorithms, 2017.
</p>
<p>S. J. Young and E. R. Scheinerman. Random dot product graph models for
social networks. In International Workshop on Algorithms and Models
for the Web-Graph, pages 138-149. Springer, 2007.
</p>
<p>C. M. Le and E. Levina. Estimating the number of communities in networks by spectral
methods. arXiv preprint arXiv:1507.00827, 2015.
</p>
<p>Zhang, Y.; Levina, E. &amp; Zhu, J. Estimating network edge probabilities by neighbourhood smoothing Biometrika, Oxford University Press, 2017, 104, 771-783
</p>
<p>B. Karrer and M. E. Newman. Stochastic blockmodels and community structure in networks.
Physical Review E, 83(1):016107, 2011.
</p>
<p>Wang, Y. R. &amp; Bickel, P. J. Likelihood-based model selection for
stochastic block models The Annals of Statistics, Institute of
Mathematical Statistics, 2017, 45, 500-528
</p>
<p>Gao, C.; Ma, Z.; Zhang, A. Y. &amp; Zhou, H. H. Achieving optimal misclassification proportion in stochastic block models The Journal of Machine Learning Research, JMLR. org, 2017, 18, 1980-2024
</p>
<p>T. Li, E. Levina, and J. Zhu. Community models for networks observed through edge nominations. arXiv preprint arXiv:2008.03652 (2020).
</p>
<p>T. Li and C. M. Le, Network Estimation by Mixing: Adaptivity and More. arXiv preprint
arXiv:2106.02803, 2021.
</p>
<p>R. Miao and T. Li. Informative core identification in complex networks. arXiv preprint arXiv:2101.06388, 2021
</p>
<p>Sischka, B. and Kauermann, G., 2022. EM-based smooth graphon estimation using MCMC and spline-based approaches. Social Networks, 68, pp.279-295.
</p>

<hr>
<h2 id='RDPG.Gen'>
generates random networks from random dot product graph model
</h2><span id='topic+RDPG.Gen'></span>

<h3>Description</h3>

<p>generates random networks from random dot product graph model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RDPG.Gen(n, K, directed = TRUE, avg.d = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RDPG.Gen_+3A_n">n</code></td>
<td>

<p>size of the network
</p>
</td></tr>
<tr><td><code id="RDPG.Gen_+3A_k">K</code></td>
<td>

<p>dimension of latent space
</p>
</td></tr>
<tr><td><code id="RDPG.Gen_+3A_directed">directed</code></td>
<td>

<p>whether the network is directed or not
</p>
</td></tr>
<tr><td><code id="RDPG.Gen_+3A_avg.d">avg.d</code></td>
<td>

<p>average node degree of the network (in expectation)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The network is generated according to special formulation mentioned in
ECV paper.
</p>


<h3>Value</h3>

<p>a list of
</p>
<table>
<tr><td><code>A</code></td>
<td>
<p>the adjacency matrix</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>the probability matrix</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tianxi Li, Elizaveta Levina, Ji Zhu<br />
Maintainer: Tianxi Li  <a href="mailto:tianxili@virginia.edu">tianxili@virginia.edu</a>
</p>


<h3>References</h3>

<p>S. J. Young and E. R. Scheinerman. Random dot product graph models for
social networks. In International Workshop on Algorithms and Models for the Web-Graph, pages 138-149. Springer, 2007.
T. Li, E. Levina, and J. Zhu. Network cross-validation by edge sampling. Biometrika, 107(2), pp.257-276, 2020.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dt &lt;- RDPG.Gen(n=600,K=2,directed=TRUE)

A &lt;- dt$A

</code></pre>

<hr>
<h2 id='reg.SP'>
clusters nodes by regularized spectral clustering
</h2><span id='topic+reg.SP'></span>

<h3>Description</h3>

<p>community detection by regularized spectral clustering
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reg.SP(A, K, tau = 1, lap = FALSE,nstart=30,iter.max=100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reg.SP_+3A_a">A</code></td>
<td>

<p>adjacency matrix
</p>
</td></tr>
<tr><td><code id="reg.SP_+3A_k">K</code></td>
<td>

<p>number of communities
</p>
</td></tr>
<tr><td><code id="reg.SP_+3A_tau">tau</code></td>
<td>

<p>reguarlization parameter. Default value is one. Typically set between 0
and 1. If tau=0, no regularization is applied.
</p>
</td></tr>
<tr><td><code id="reg.SP_+3A_lap">lap</code></td>
<td>

<p>indicator. If TRUE, the  Laplacian matrix for clustering. If FALSE, the
adjacency matrix will be used.
</p>
</td></tr>
<tr><td><code id="reg.SP_+3A_nstart">nstart</code></td>
<td>

<p>number of random initializations for K-means
</p>
</td></tr>
<tr><td><code id="reg.SP_+3A_iter.max">iter.max</code></td>
<td>

<p>maximum number of iterations for K-means
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The regularlization is done by adding a small constant to each element
of the adjacency matrix. It is shown by such perturbation helps
concentration in sparse networks. It is shown to give consistent
clustering under SBM.
</p>


<h3>Value</h3>

<p>a list of
</p>
<table>
<tr><td><code>cluster</code></td>
<td>
<p>cluster labels</p>
</td></tr>
<tr><td><code>loss</code></td>
<td>
<p>the loss of Kmeans algorithm</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tianxi Li, Elizaveta Levina, Ji Zhu<br />
</p>
<p>Maintainer: Tianxi Li &lt;tianxili@virginia.edu&gt;
</p>


<h3>References</h3>

<p>K. Rohe, S. Chatterjee, and B. Yu. Spectral clustering and the
high-dimensional stochastic blockmodel. The Annals of Statistics, pages
1878-1915, 2011.
</p>
<p>A. A. Amini, A. Chen, P. J. Bickel, and E. Levina. Pseudo-likelihood
methods for community detection in large sparse networks. The Annals
of Statistics, 41(4):2097-2122, 2013.
</p>
<p>J. Lei and A. Rinaldo. Consistency of spectral clustering in stochastic block models. The
Annals of Statistics, 43(1):215-237, 2014.
</p>
<p>C. M. Le, E. Levina, and R. Vershynin. Concentration and regularization of random graphs.
Random Structures &amp; Algorithms, 2017.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+reg.SP">reg.SP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

dt &lt;- BlockModel.Gen(30,300,K=3,beta=0.2,rho=0)


A &lt;- dt$A


sc &lt;- reg.SP(A,K=3,lap=TRUE)


NMI(sc$cluster,dt$g)


</code></pre>

<hr>
<h2 id='reg.SSP'>
detects communities by regularized spherical spectral clustering
</h2><span id='topic+reg.SSP'></span>

<h3>Description</h3>

<p>community detection by regularized spherical spectral clustering
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reg.SSP(A, K, tau = 1, lap = FALSE,nstart=30,iter.max=100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reg.SSP_+3A_a">A</code></td>
<td>

<p>adjacency matrix
</p>
</td></tr>
<tr><td><code id="reg.SSP_+3A_k">K</code></td>
<td>

<p>number of communities
</p>
</td></tr>
<tr><td><code id="reg.SSP_+3A_tau">tau</code></td>
<td>

<p>reguarlization parameter. Default value is one. Typically set between 0
and 1. If tau=0, no regularization is applied.
</p>
</td></tr>
<tr><td><code id="reg.SSP_+3A_lap">lap</code></td>
<td>

<p>indicator. If TRUE, the  Laplacian matrix for clustering. If FALSE, the
adjacency matrix will be used.
</p>
</td></tr>
<tr><td><code id="reg.SSP_+3A_nstart">nstart</code></td>
<td>

<p>number of random initializations for K-means
</p>
</td></tr>
<tr><td><code id="reg.SSP_+3A_iter.max">iter.max</code></td>
<td>

<p>maximum number of iterations for K-means
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The regularlization is done by adding a small constant to each element
of the adjacency matrix. It is shown by such perturbation helps
concentration in sparse networks. The difference from spectral
clustering (reg.SP) comes from its extra step to normalize the rows of
spectral vectors. It is proved that it gives consistent clustering under DCSBM.
</p>


<h3>Value</h3>

<p>a list of
</p>
<table>
<tr><td><code>cluster</code></td>
<td>
<p>cluster labels</p>
</td></tr>
<tr><td><code>loss</code></td>
<td>
<p>the loss of Kmeans algorithm</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tianxi Li, Elizaveta Levina, Ji Zhu<br />
</p>
<p>Maintainer: Tianxi Li &lt;tianxili@virginia.edu&gt;
</p>


<h3>References</h3>

<p>T. Qin and K. Rohe. Regularized spectral clustering under the
degree-corrected stochastic blockmodel. In Advances in Neural
Information Processing Systems, pages 3120-3128, 2013.
</p>
<p>J. Lei and A. Rinaldo. Consistency of spectral clustering in stochastic block models. The
Annals of Statistics, 43(1):215-237, 2014.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+reg.SP">reg.SP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

dt &lt;- BlockModel.Gen(30,300,K=3,beta=0.2,rho=0.9,simple=FALSE,power=TRUE)


A &lt;- dt$A

ssc &lt;- reg.SSP(A,K=3,lap=TRUE)

NMI(ssc$cluster,dt$g)

</code></pre>

<hr>
<h2 id='RightSC'>
clusters nodes in a directed network by regularized spectral clustering on right singular vectors
</h2><span id='topic+RightSC'></span>

<h3>Description</h3>

<p>community detection by regularized spectral clustering on right singular vectors
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RightSC(A, K, normal = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RightSC_+3A_a">A</code></td>
<td>

<p>adjacency matrix of a directed adjacecy matrix
</p>
</td></tr>
<tr><td><code id="RightSC_+3A_k">K</code></td>
<td>

<p>number of communities
</p>
</td></tr>
<tr><td><code id="RightSC_+3A_normal">normal</code></td>
<td>

<p>indicator. If TRUE, normalization of singular vector rows will be applied, similar to the spectral spherical clustering.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is essentially the spectral clustering applied on right singular vectors. It can be used to handle directed networks where Aij = 1 if and only if i -&gt; j, and the edges tend to have a missing issue specifically depending on the sender i. More details can be found in Li et. al. (2020).
</p>


<h3>Value</h3>

<p>a list of
</p>
<table>
<tr><td><code>cluster</code></td>
<td>
<p>cluster labels</p>
</td></tr>
<tr><td><code>loss</code></td>
<td>
<p>the loss of Kmeans algorithm</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tianxi Li, Elizaveta Levina, Ji Zhu<br />
</p>
<p>Maintainer: Tianxi Li &lt;tianxili@virginia.edu&gt;
</p>


<h3>References</h3>

<p>T. Li, E. Levina, and J. Zhu. Community models for networks observed through edge nominations. arXiv preprint arXiv:2008.03652 (2020).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+reg.SP">reg.SP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

dt &lt;- BlockModel.Gen(30,300,K=3,beta=0.2,rho=0)


A &lt;- dt$A


sc &lt;- RightSC(A,K=2)


</code></pre>

<hr>
<h2 id='SBM.estimate'>
estimates SBM parameters given community labels
</h2><span id='topic+SBM.estimate'></span>

<h3>Description</h3>

<p>estimates SBM parameters given community labels
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SBM.estimate(A, g)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SBM.estimate_+3A_a">A</code></td>
<td>

<p>adjacency matrix
</p>
</td></tr>
<tr><td><code id="SBM.estimate_+3A_g">g</code></td>
<td>

<p>a vector of community labels
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>maximum likelhood is used
</p>


<h3>Value</h3>

<p>a list of
</p>
<table>
<tr><td><code>B</code></td>
<td>
<p>estimated block connection probability matrix</p>
</td></tr>
<tr><td><code>Phat</code></td>
<td>
<p>estimated probability matrix</p>
</td></tr>
<tr><td><code>g</code></td>
<td>
<p>community labels</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tianxi Li, Elizaveta Levina, Ji Zhu<br />
Maintainer: Tianxi Li  <a href="mailto:tianxili@virginia.edu">tianxili@virginia.edu</a>
</p>


<h3>References</h3>

<p>B. Karrer and M. E. Newman. Stochastic blockmodels and community structure in networks.
Physical Review E, 83(1):016107, 2011.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DCSBM.estimate">DCSBM.estimate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dt &lt;- BlockModel.Gen(30,300,K=3,beta=0.2,rho=0)


A &lt;- dt$A


sc &lt;- reg.SP(A,K=3,lap=TRUE)
sbm &lt;- SBM.estimate(A,sc$cluster)
sbm$B

</code></pre>

<hr>
<h2 id='smooth.oracle'>
oracle smooth graphon estimation
</h2><span id='topic+smooth.oracle'></span>

<h3>Description</h3>

<p>oracle smooth graphon estimation according to given latent positions, based on smooth estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smooth.oracle(Us,A)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smooth.oracle_+3A_us">Us</code></td>
<td>

<p>a vector whose elements are the latent positions of the network nodes under the graphon model. The dimension of the vector equals the number of nodes in the network.
</p>
</td></tr>
<tr><td><code id="smooth.oracle_+3A_a">A</code></td>
<td>

<p>adjacency matrix. It does not have to be unweighted. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the latenet positions are unknown in practice, so this estimation is an oracle estimation mainly for evaluation purpose. However, if the latenet positions can be approximated estimated, this function can also be used for estimating the edge probability matrix. This procedure is the M-step of the algorithm used in Sischka &amp; Kauermann (2022). Our implementation is modified from the contribution of an anonymous reviewer, leveraging the tools of the sparseFLMM package.
</p>


<h3>Value</h3>

<p>The estimated probability matrix.
</p>


<h3>Author(s)</h3>

<p>Tianxi Li, Elizaveta Levina, Ji Zhu, Can M. Le<br />
Maintainer: Tianxi Li  <a href="mailto:tianxili@virginia.edu">tianxili@virginia.edu</a>
</p>


<h3>References</h3>

<p>Sischka, B. and Kauermann, G., 2022. EM-based smooth graphon estimation using MCMC and spline-based approaches. Social Networks, 68, pp.279-295.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(100)
dt &lt;- BlockModel.Gen(10,50,K=2,beta=0.2)

## oracle order
oracle.index &lt;- sort(dt$g,index.return=TRUE)$ix
A &lt;- dt$A[oracle.index,oracle.index]

oracle.est &lt;- smooth.oracle(seq(0,1,length.out=50),A)

</code></pre>

<hr>
<h2 id='USVT'>
estimates the network probability matrix by the improved universal singular value thresholding
</h2><span id='topic+USVT'></span>

<h3>Description</h3>

<p>estimates the network probability matrix by the universal singular value thresholding of Chatterjee (2015), with the improvement mentioned in Zhang et. al. (2017).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>USVT(A)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="USVT_+3A_a">A</code></td>
<td>

<p>adjacency matrix
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Instead of using the original threshold in Chatterjee (2015), the estimate is generated by taking the n^(1/3) leading spectral components. The method was mentioned in Zhang et. al. (2017) and suggested by an anonymous reviewer.
</p>


<h3>Value</h3>

<p>The estimated probability matrix.

</p>


<h3>Author(s)</h3>

<p>Tianxi Li and Can M. Le<br />
Maintainer: Tianxi Li  <a href="mailto:tianxili@virginia.edu">tianxili@virginia.edu</a>
</p>


<h3>References</h3>


<p>S. Chatterjee. Matrix estimation by universal singular value thresholding. The Annals of Statistics,
43(1):177-214, 2015.
Y. Zhang, E. Levina, and J. Zhu. Estimating network edge probabilities by neighbourhood smoothing. Biometrika, 104(4):771-783, 2017.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+LSM.PGD">LSM.PGD</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dt &lt;- RDPG.Gen(n=600,K=2,directed=TRUE)


A &lt;- dt$A


fit &lt;- USVT(A)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
