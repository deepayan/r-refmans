<!DOCTYPE html><html lang="en"><head><title>Help for package veesa</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {veesa}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#align_pcdirs'><p>Obtain PC directions with centered warping functions</p></a></li>
<li><a href='#center_warping_funs'><p>Center warping functions</p></a></li>
<li><a href='#compute_pfi'><p>Compute permutation feature importance (PFI)</p></a></li>
<li><a href='#plot_pc_directions'><p>Plot principal component directions</p></a></li>
<li><a href='#prep_testing_data'><p>Align test data and apply fPCA using elastic method applied to training data</p></a></li>
<li><a href='#prep_training_data'><p>Align training data and apply a method of elastic fPCA</p></a></li>
<li><a href='#shifted_peaks'><p>&quot;Shifted Peaks&quot; Simulated Dataset</p></a></li>
<li><a href='#simulate_functions'><p>Simulate example functional data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Pipeline for Explainable Machine Learning with Functional Data</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.6</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements the Variable importance Explainable Elastic Shape Analysis pipeline for explainable machine learning with functional data inputs. Converts training and testing data functional inputs to elastic shape analysis principal components that account for vertical and/or horizontal variability. Computes feature importance to identify important principal components and visualizes variability captured by functional principal components. See Goode et al. (2025) &lt;<a href="https://doi.org/10.48550%2FarXiv.2501.07602">doi:10.48550/arXiv.2501.07602</a>&gt; for technical details about the methodology.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, fdasrvf, forcats, ggplot2, purrr, stats, stringr, tidyr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>randomForest, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-16 21:07:54 UTC; kjgoode</td>
</tr>
<tr>
<td>Author:</td>
<td>Katherine Goode [cre, aut],
  J. Derek Tucker [aut],
  Sandia National Laboratories [cph, fnd]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Katherine Goode &lt;kjgoode@sandia.gov&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-17 10:10:01 UTC</td>
</tr>
</table>
<hr>
<h2 id='align_pcdirs'>Obtain PC directions with centered warping functions</h2><span id='topic+align_pcdirs'></span>

<h3>Description</h3>

<p>The function 'prep_training_data' does not center the warping functions,
which leads to issues when visualizing joint and horizontal principal
component directions. This function aligns the principal directions for
improved interpretability of the principal directions. Currently, only
alignment for jfPCA has been implemented.
</p>
<p>The function 'prep_training_data' does not center the warping functions,
which leads to issues when visualizing joint and horizontal principal
component directions. This function aligns the principal directions for
improved interpretability of the principal directions. Currently, only
alignment for jfPCA has been implemented.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>align_pcdirs(train_obj)

align_pcdirs(train_obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="align_pcdirs_+3A_train_obj">train_obj</code></td>
<td>
<p>Output object from 'prep_training_data' (jfpca only)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with the same structure as 'prep_training_data', but
the principal directions are replaced with the aligned version and gamI is
included in the fpca_res object.
</p>
<p>List with the same structure as 'prep_training_data', but
the principal directions are replaced with the aligned version and gamI is
included in the fpca_res object.
</p>

<hr>
<h2 id='center_warping_funs'>Center warping functions</h2><span id='topic+center_warping_funs'></span>

<h3>Description</h3>

<p>The function 'prep_training_data' does not center the warping functions. For
visualizing the aligned and warping functions, it can be easier to look at
centered versions. This function centers the warping functions and
corresponding aligned functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>center_warping_funs(train_obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="center_warping_funs_+3A_train_obj">train_obj</code></td>
<td>
<p>Output object from 'prep_training_data'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object with the same structure as 'train_obj' but qn, fn, and gam
have been replaced by centered versions
</p>

<hr>
<h2 id='compute_pfi'>Compute permutation feature importance (PFI)</h2><span id='topic+compute_pfi'></span>

<h3>Description</h3>

<p>Function for computing PFI for a given model and dataset (training or
testing)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_pfi(x, y, f, K, metric, eps = 1e-15)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_pfi_+3A_x">x</code></td>
<td>
<p>Dataset with n observations and p variables (training or testing)</p>
</td></tr>
<tr><td><code id="compute_pfi_+3A_y">y</code></td>
<td>
<p>Response variable (or matrix) associated with x</p>
</td></tr>
<tr><td><code id="compute_pfi_+3A_f">f</code></td>
<td>
<p>Model to explain</p>
</td></tr>
<tr><td><code id="compute_pfi_+3A_k">K</code></td>
<td>
<p>Number of repetitions to perform for PFI</p>
</td></tr>
<tr><td><code id="compute_pfi_+3A_metric">metric</code></td>
<td>
<p>Metric used to compute PFI (choose from &quot;accuracy&quot;, &quot;logloss&quot;,
and &quot;nmse&quot;)</p>
</td></tr>
<tr><td><code id="compute_pfi_+3A_eps">eps</code></td>
<td>
<p>Log loss is undefined for p = 0 or p = 1, so probabilities are</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List containing
</p>

<ul>
<li> <p><code>pfi</code>: Vector of PFI values (averaged over replicates)
</p>
</li>
<li> <p><code>pfi_single_reps</code>: Matrix of containing the feature importance
values from each replicate (rows associated with reps; columns
associated with data observations)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Load packages
library(dplyr)
library(tidyr)
library(randomForest)

# Select a subset of functions from shifted peaks data
sub_ids &lt;-
  shifted_peaks$data |&gt;
  select(data, group, id) |&gt;
  distinct() |&gt;
  group_by(data, group) |&gt;
  slice(1:4) |&gt;
  ungroup()

# Create a smaller version of shifted data
shifted_peaks_sub &lt;-
  shifted_peaks$data |&gt;
  filter(id %in% sub_ids$id)

# Extract times
shifted_peaks_times = unique(shifted_peaks_sub$t)

# Convert training data to matrix
shifted_peaks_train_matrix &lt;-
  shifted_peaks_sub |&gt;
  filter(data == "Training") |&gt;
  select(-t) |&gt;
  mutate(index = paste0("t", index)) |&gt;
  pivot_wider(names_from = index, values_from = y) |&gt;
  select(-data, -id, -group) |&gt;
  as.matrix() |&gt;
  t()

# Obtain veesa pipeline training data
veesa_train &lt;-
  prep_training_data(
    f = shifted_peaks_train_matrix,
    time = shifted_peaks_times,
    fpca_method = "jfpca"
  )

# Obtain response variable values
model_output &lt;-
  shifted_peaks_sub |&gt;
  filter(data == "Training") |&gt;
  select(id, group) |&gt;
  distinct()

# Prepare data for model
model_data &lt;-
  veesa_train$fpca_res$coef |&gt;
  data.frame() |&gt;
  mutate(group = factor(model_output$group))

# Train model
set.seed(20210301)
rf &lt;-
  randomForest(
    formula = group ~ .,
    data = model_data
  )

# Compute feature importance values
pfi &lt;-
  compute_pfi(
    x = model_data |&gt; select(-group),
    y = model_data$group,
    f = rf,
    K = 1,
    metric = "accuracy"
 )
</code></pre>

<hr>
<h2 id='plot_pc_directions'>Plot principal component directions</h2><span id='topic+plot_pc_directions'></span>

<h3>Description</h3>

<p>Function for plotting the functional PC directions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_pc_directions(
  fpcs,
  fdasrvf,
  fpca_method,
  times = NULL,
  digits = 0,
  alpha = 1,
  nrow = 1,
  linesizes = NULL,
  linetype = TRUE,
  freey = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_pc_directions_+3A_fpcs">fpcs</code></td>
<td>
<p>Vector of numbers identifying the PCs to include in the plot</p>
</td></tr>
<tr><td><code id="plot_pc_directions_+3A_fdasrvf">fdasrvf</code></td>
<td>
<p>Object output from jointFPCA, horizFPCA, or vertFPCA</p>
</td></tr>
<tr><td><code id="plot_pc_directions_+3A_fpca_method">fpca_method</code></td>
<td>
<p>Character string specifying the type of elastic fPCA method to use ('jfpca', 'hfpca', or 'vfpca')</p>
</td></tr>
<tr><td><code id="plot_pc_directions_+3A_times">times</code></td>
<td>
<p>Optional vector of times (if not included, times will be represented on the interval from 0 to 1)</p>
</td></tr>
<tr><td><code id="plot_pc_directions_+3A_digits">digits</code></td>
<td>
<p>Number of digits to print in the title for the proportion of variability explained by a PC</p>
</td></tr>
<tr><td><code id="plot_pc_directions_+3A_alpha">alpha</code></td>
<td>
<p>Vector of alpha values associated with lines in plot (length must match number of lines in plot)</p>
</td></tr>
<tr><td><code id="plot_pc_directions_+3A_nrow">nrow</code></td>
<td>
<p>Number of rows to use when creating a grid of plots</p>
</td></tr>
<tr><td><code id="plot_pc_directions_+3A_linesizes">linesizes</code></td>
<td>
<p>Vector of line widths associated with lines in plot (length must match number of lines in plot)</p>
</td></tr>
<tr><td><code id="plot_pc_directions_+3A_linetype">linetype</code></td>
<td>
<p>Vector of line types (e.g., &quot;solid&quot; or &quot;dashed&quot;) associated with lines in plot (length must match number of lines in plot)</p>
</td></tr>
<tr><td><code id="plot_pc_directions_+3A_freey">freey</code></td>
<td>
<p>Indicator for whether y-axis should be freed across facets</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 plot of specified principal component directions
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load packages
library(dplyr)
library(tidyr)

# Select a subset of functions from shifted peaks data
sub_ids &lt;-
  shifted_peaks$data |&gt;
  select(data, group, id) |&gt;
  distinct() |&gt;
  group_by(data, group) |&gt;
  slice(1:4) |&gt;
  ungroup()

# Create a smaller version of shifted data
shifted_peaks_sub &lt;-
  shifted_peaks$data |&gt;
  filter(id %in% sub_ids$id)

# Extract times
shifted_peaks_times = unique(shifted_peaks_sub$t)

# Convert training data to matrix
shifted_peaks_train_matrix &lt;-
  shifted_peaks_sub |&gt;
  filter(data == "Training") |&gt;
  select(-t) |&gt;
  mutate(index = paste0("t", index)) |&gt;
  pivot_wider(names_from = index, values_from = y) |&gt;
  select(-data, -id, -group) |&gt;
  as.matrix() |&gt;
  t()

# Obtain veesa pipeline training data
veesa_train &lt;-
  prep_training_data(
    f = shifted_peaks_train_matrix,
    time = shifted_peaks_times,
    fpca_method = "jfpca"
  )

# Plot principal directions of PC1
plot_pc_directions(
  fpcs = 1,
  fdasrvf = veesa_train$fpca_res,
  fpca_method = "jfpca",
  times = -shifted_peaks_times,
  linesizes = rep(0.75,5),
  alpha = 0.9
 )
</code></pre>

<hr>
<h2 id='prep_testing_data'>Align test data and apply fPCA using elastic method applied to training data</h2><span id='topic+prep_testing_data'></span>

<h3>Description</h3>

<p>Applies steps 2 and 3 of the VEESA pipeline (alignment and elastic fPCA
(jfpca, hfpca, or vfpca)) to the testing data based on the training
data prepared using &quot;prep_training_data&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prep_testing_data(f, time, train_prep, optim_method = "DP")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prep_testing_data_+3A_f">f</code></td>
<td>
<p>Matrix (size M x N) of test data with N functions and M samples.</p>
</td></tr>
<tr><td><code id="prep_testing_data_+3A_time">time</code></td>
<td>
<p>Vector of size M describing the sample points</p>
</td></tr>
<tr><td><code id="prep_testing_data_+3A_train_prep">train_prep</code></td>
<td>
<p>Object returned from applying &quot;prep_training_data&quot; to
training data.</p>
</td></tr>
<tr><td><code id="prep_testing_data_+3A_optim_method">optim_method</code></td>
<td>
<p>Method used for optimization when computing the Karcher
mean. &quot;DP&quot;, &quot;DPo&quot;, and &quot;RBFGS&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List containing (varies slightly based on fpca method used):
</p>

<ul>
<li><p> time: vector of times when functions are observed (length of M)
</p>
</li>
<li><p> f0: original test data functions - matrix (M x N) of N functions
with M samples
</p>
</li>
<li><p> fn: aligned test data functions - similar structure to f0
</p>
</li>
<li><p> q0: original test data SRSFs - similar structure to f0
</p>
</li>
<li><p> qn: aligned test data SRSFs - similar structure to f0
</p>
</li>
<li><p> mqn: training data SRSF mean (test data functions are aligned to
this function)
</p>
</li>
<li><p> gam: test data warping functions - similar structure to f0
</p>
</li>
<li><p> coef: test data principal component coefficients
</p>
</li>
<li><p> psi: test data warping function SRVFs - similar structure to f0
(jfpca and hfpca only)
</p>
</li>
<li><p> nu: test data shooting functions - similar structure to f0 (jfpca
and hfpca only)
</p>
</li>
<li><p> g: test data combination of aligned and shooting functions (jfpca
only)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Load packages
library(dplyr)
library(tidyr)

# Select a subset of functions from shifted peaks data
sub_ids &lt;-
  shifted_peaks$data |&gt;
  select(data, group, id) |&gt;
  distinct() |&gt;
  group_by(data, group) |&gt;
  slice(1:4) |&gt;
  ungroup()

# Create a smaller version of shifted data
shifted_peaks_sub &lt;-
  shifted_peaks$data |&gt;
  filter(id %in% sub_ids$id)

# Extract times
shifted_peaks_times = unique(shifted_peaks_sub$t)

# Convert training data to matrix
shifted_peaks_train_matrix &lt;-
  shifted_peaks_sub |&gt;
  filter(data == "Training") |&gt;
  select(-t) |&gt;
  mutate(index = paste0("t", index)) |&gt;
  pivot_wider(names_from = index, values_from = y) |&gt;
  select(-data, -id, -group) |&gt;
  as.matrix() |&gt;
  t()

# Obtain veesa pipeline training data
veesa_train &lt;-
  prep_training_data(
    f = shifted_peaks_train_matrix,
    time = shifted_peaks_times,
    fpca_method = "jfpca"
  )

# Convert testing data to matrix
shifted_peaks_test_matrix &lt;-
  shifted_peaks_sub |&gt;
  filter(data == "Testing") |&gt;
  select(-t) |&gt;
  mutate(index = paste0("t", index)) |&gt;
  pivot_wider(names_from = index, values_from = y) |&gt;
  select(-data, -id, -group) |&gt;
  as.matrix() |&gt;
  t()

# Obtain veesa pipeline testing data
veesa_test &lt;- prep_testing_data(
  f = shifted_peaks_test_matrix,
  time = shifted_peaks_times,
  train_prep = veesa_train,
  optim_method = "DP"
 )
</code></pre>

<hr>
<h2 id='prep_training_data'>Align training data and apply a method of elastic fPCA</h2><span id='topic+prep_training_data'></span>

<h3>Description</h3>

<p>Applies steps 2 and 3 of the VEESA pipeline (alignment and elastic fPCA) to the training data
in preparation for inputting the data to the model in step 4.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prep_training_data(
  f,
  time,
  fpca_method,
  lambda = 0,
  penalty_method = c("roughness", "geodesic", "norm"),
  centroid_type = c("mean", "median"),
  center_warpings = TRUE,
  parallel = FALSE,
  cores = -1,
  optim_method = c("DP", "DPo", "DP2", "RBFGS"),
  max_iter = 20L,
  id = NULL,
  C = NULL,
  ci = c(-2, -1, 0, 1, 2)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prep_training_data_+3A_f">f</code></td>
<td>
<p>Matrix (size M x N) of training data with N functions and M samples.</p>
</td></tr>
<tr><td><code id="prep_training_data_+3A_time">time</code></td>
<td>
<p>Vector of size M corresponding to the M sample points.</p>
</td></tr>
<tr><td><code id="prep_training_data_+3A_fpca_method">fpca_method</code></td>
<td>
<p>Character string specifying the type of elastic fPCA
method to use. Options are 'jfpca', 'hfpca', or 'vfpca'.</p>
</td></tr>
<tr><td><code id="prep_training_data_+3A_lambda">lambda</code></td>
<td>
<p>Numeric value specifying the elasticity. Default is 0.</p>
</td></tr>
<tr><td><code id="prep_training_data_+3A_penalty_method">penalty_method</code></td>
<td>
<p>String specifying the penalty term used in the
formulation of the cost function to minimize for alignment. Choices
are &quot;roughness&quot; which uses the norm of the second derivative,
&quot;geodesic&quot; which uses the geodesic distance to the identity and
&quot;norm&quot; which uses the Euclidean distance to the identity. Defaults
is &quot;roughness&quot;.</p>
</td></tr>
<tr><td><code id="prep_training_data_+3A_centroid_type">centroid_type</code></td>
<td>
<p>String specifying the type of centroid to align to.
Options are &quot;mean&quot; or &quot;median&quot;. Defaults is &quot;mean&quot;.</p>
</td></tr>
<tr><td><code id="prep_training_data_+3A_center_warpings">center_warpings</code></td>
<td>
<p>Boolean specifying whether to center the estimated
warping functions. Defaults is TRUE.</p>
</td></tr>
<tr><td><code id="prep_training_data_+3A_parallel">parallel</code></td>
<td>
<p>Boolean specifying whether to run calculations in parallel.
Defaults is FALSE.</p>
</td></tr>
<tr><td><code id="prep_training_data_+3A_cores">cores</code></td>
<td>
<p>Integer specifying the number of cores in parallel. Default is
-1, which uses all cores.</p>
</td></tr>
<tr><td><code id="prep_training_data_+3A_optim_method">optim_method</code></td>
<td>
<p>Method used for optimization when computing the Karcher
mean. Options are &quot;DP&quot;, &quot;DPo&quot;, and &quot;RBFGS&quot;.</p>
</td></tr>
<tr><td><code id="prep_training_data_+3A_max_iter">max_iter</code></td>
<td>
<p>An integer value specifying the maximum number of iterations.
Defaults to 20L.</p>
</td></tr>
<tr><td><code id="prep_training_data_+3A_id">id</code></td>
<td>
<p>Integration point for f0. Default is midpoint.</p>
</td></tr>
<tr><td><code id="prep_training_data_+3A_c">C</code></td>
<td>
<p>Balance value. Default = NULL.</p>
</td></tr>
<tr><td><code id="prep_training_data_+3A_ci">ci</code></td>
<td>
<p>Geodesic standard deviations to be computed. Default is
c(-2, -1, 0, 1, 2).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with three objects:
</p>

<ul>
<li><p> alignment: output from fdasrvf::time_warping
</p>
</li>
<li><p> fpca_type: type of elastic FPCA method applied
</p>
</li>
<li><p> fpca_res: output from fdasrvf::jointFPCA, fdasrvf::horizFPCA, or
fdasrvf::vertFPCA (dependent on fpca_type)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Load packages
library(dplyr)
library(tidyr)

# Select a subset of functions from shifted peaks data
sub_ids &lt;-
  shifted_peaks$data |&gt;
  select(data, group, id) |&gt;
  distinct() |&gt;
  group_by(data, group) |&gt;
  slice(1:4) |&gt;
  ungroup()

# Create a smaller version of shifted data
shifted_peaks_sub &lt;-
  shifted_peaks$data |&gt;
  filter(id %in% sub_ids$id)

# Extract times
shifted_peaks_times = unique(shifted_peaks_sub$t)

# Convert training data to matrix
shifted_peaks_train_matrix &lt;-
  shifted_peaks_sub |&gt;
  filter(data == "Training") |&gt;
  select(-t) |&gt;
  mutate(index = paste0("t", index)) |&gt;
  pivot_wider(names_from = index, values_from = y) |&gt;
  select(-data, -id, -group) |&gt;
  as.matrix() |&gt;
  t()

# Obtain veesa pipeline training data
veesa_train &lt;-
  prep_training_data(
    f = shifted_peaks_train_matrix,
    time = shifted_peaks_times,
    fpca_method = "jfpca"
  )
</code></pre>

<hr>
<h2 id='shifted_peaks'>&quot;Shifted Peaks&quot; Simulated Dataset</h2><span id='topic+shifted_peaks'></span>

<h3>Description</h3>

<p>A simulated dataset generated for examples in the veesa pipeline manuscript. 
For the code used to prepare this dataset, see
https://github.com/sandialabs/veesa/inst/data-shifted-peaks.md.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shifted_peaks
</code></pre>


<h3>Format</h3>

<p>A list.
</p>


<h3>Details</h3>

<p>The objects in the list are:
</p>

<table>
<tr>
 <td style="text-align: left;">
   <code>data</code> </td><td style="text-align: left;"> Data frame containing simulated data </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>params</code> </td><td style="text-align: left;"> The parameters used to generate the data </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>true_means</code> </td><td style="text-align: left;"> The true functional means of the shifted peaks groups.
 </td>
</tr>

</table>


<hr>
<h2 id='simulate_functions'>Simulate example functional data</h2><span id='topic+simulate_functions'></span>

<h3>Description</h3>

<p>Function for simulating a set of functional data based on a deterministic function
with covariates that affect the shape of the functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulate_functions(M, N, seed)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulate_functions_+3A_m">M</code></td>
<td>
<p>Number of functions</p>
</td></tr>
<tr><td><code id="simulate_functions_+3A_n">N</code></td>
<td>
<p>Number of samples per function</p>
</td></tr>
<tr><td><code id="simulate_functions_+3A_seed">seed</code></td>
<td>
<p>Seed for reproducibility</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions are generated using the following equation:
</p>
<p>f(t) = (x_1*exp(-((t-0.3)^2)/0.005)) + (x_2(-((t-(0.7+x_3))^2/0.005)))
</p>
<p>where the covariates are generated as follows:
</p>

<ul>
<li><p> x_1 generated from Unif(0.1,1)
</p>
</li>
<li><p> x_2 generated from Unif(0.1,0.5)
</p>
</li>
<li><p> x_3 generated from Unif(-0.1,0.1)
</p>
</li></ul>



<h3>Value</h3>

<p>Data frame with the following columns (where f is the function):
</p>

<ul>
<li><p> t: &quot;time&quot; associated with sample from function where t in [0,1]
</p>
</li>
<li><p> y: f(t) for the particular observation
</p>
</li>
<li><p> x1: covariate 1 for function $f$ (constant across time)
</p>
</li>
<li><p> x2: covariate 2 for function $f$ (constant across time)
</p>
</li>
<li><p> x3: covariate 3 for function $f$ (constant across time)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Simulate data
sim_data = simulate_functions(M = 100, N = 75, seed = 20211130)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
