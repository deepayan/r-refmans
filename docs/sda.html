<!DOCTYPE html><html><head><title>Help for package sda</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {sda}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#catscore'><p>Estimate CAT Scores and t-Scores</p></a></li>
<li><a href='#centroids'><p>Group Centroids and (Pooled) Variances</p></a></li>
<li><a href='#khan2001'><p>Childhood Cancer Study of Khan et al. (2001)</p></a></li>
<li><a href='#predict.sda'><p>Shrinkage Discriminant Analysis 3: Prediction Step</p></a></li>
<li><a href='#sda'><p>Shrinkage Discriminant Analysis 2: Training Step</p></a></li>
<li><a href='#sda-internal'><p>Internal sda functions</p></a></li>
<li><a href='#sda-package'><p>The sda Package</p></a></li>
<li><a href='#sda.ranking'><p>Shrinkage Discriminant Analysis 1: Predictor Ranking</p></a></li>
<li><a href='#singh2002'><p>Prostate Cancer Study of Singh et al. (2002)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.3.8</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-11-21</td>
</tr>
<tr>
<td>Title:</td>
<td>Shrinkage Discriminant Analysis and CAT Score Variable Selection</td>
</tr>
<tr>
<td>Author:</td>
<td>Miika Ahdesmaki, Verena Zuber, Sebastian Gibb, and Korbinian Strimmer</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Korbinian Strimmer &lt;strimmerlab@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.2), entropy (&ge; 1.3.1), corpcor (&ge; 1.6.10), fdrtool
(&ge; 1.2.17)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>crossval</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, stats, utils</td>
</tr>
<tr>
<td>Enhances:</td>
<td>care</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides an efficient framework for 
   high-dimensional linear and diagonal discriminant analysis with 
   variable selection.  The classifier is trained using James-Stein-type 
   shrinkage estimators and predictor variables are ranked using 
   correlation-adjusted t-scores (CAT scores).  Variable selection error 
   is controlled using false non-discovery rates or higher criticism.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://strimmerlab.github.io/software/sda/">https://strimmerlab.github.io/software/sda/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-11-21 17:07:03 UTC; strimmer</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-11-21 17:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='catscore'>Estimate CAT Scores and t-Scores</h2><span id='topic+catscore'></span>

<h3>Description</h3>

<p><code>catscore</code> computes  CAT scores
(correlation-adjusted t-scores)
between the group centroids and the pooled mean. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>catscore(Xtrain, L, lambda, lambda.var, lambda.freqs, diagonal=FALSE, verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="catscore_+3A_xtrain">Xtrain</code></td>
<td>
<p>A matrix  containing the training data set. Note that 
the rows correspond to observations and the columns
to variables.</p>
</td></tr>
<tr><td><code id="catscore_+3A_l">L</code></td>
<td>
<p>A factor with the class labels of the training samples. </p>
</td></tr>
<tr><td><code id="catscore_+3A_lambda">lambda</code></td>
<td>
<p>Shrinkage intensity for the correlation matrix. If not specified it is 
estimated from the data. <code>lambda=0</code> implies no shrinkage
and <code>lambda=1</code> complete shrinkage. </p>
</td></tr>
<tr><td><code id="catscore_+3A_lambda.var">lambda.var</code></td>
<td>
<p>Shrinkage intensity for the variances. If not specified it is 
estimated from the data. <code>lambda.var=0</code> implies no shrinkage
and <code>lambda.var=1</code> complete shrinkage. </p>
</td></tr>
<tr><td><code id="catscore_+3A_lambda.freqs">lambda.freqs</code></td>
<td>
<p>Shrinkage intensity for the frequencies. If not specified it is 
estimated from the data. <code>lambda.freqs=0</code> implies no shrinkage (i.e. empirical frequencies)
and <code>lambda.freqs=1</code> complete shrinkage (i.e. uniform frequencies). </p>
</td></tr>
<tr><td><code id="catscore_+3A_diagonal">diagonal</code></td>
<td>
<p>for <code>diagonal=FALSE</code> (the default) CAT scores are computed;
otherwise with <code>diagonal=TRUE</code> t-scores.</p>
</td></tr>
<tr><td><code id="catscore_+3A_verbose">verbose</code></td>
<td>
<p>Print out some info while computing.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>CAT scores generalize conventional t-scores 
to account for correlation among predictors (Zuber and Strimmer 2009).
If there is no correlation then CAR scores reduce to t-scores.  The squared
CAR scores provide a decomposition of Hotelling's T^2 statistic.
</p>
<p>CAT scores for two classes are described in Zuber and Strimmer (2009),
for the multi-class case see Ahdesm\&quot;aki and Strimmer (2010).
</p>
<p>The scale factors for t-scores and CAT-scores are computed from the estimated frequencies
(for empirical scale factors set  <code>lambda.freqs=0</code>).
</p>


<h3>Value</h3>

<p><code>catscore</code> returns a matrix containing the cat score (or t-score) between 
each group centroid and the pooled mean for each feature. 
</p>


<h3>Author(s)</h3>

<p>Verena Zuber, Miika Ahdesm\&quot;aki and Korbinian Strimmer (<a href="https://strimmerlab.github.io">https://strimmerlab.github.io</a>).
</p>


<h3>References</h3>

<p>Ahdesm\&quot;aki, A., and K. Strimmer. 2010.  Feature selection in omics prediction problems 
using cat scores and false non-discovery rate control. Ann. Appl. Stat. 4: 503-519.
&lt;DOI:10.1214/09-AOAS277&gt;
</p>
<p>Zuber, V., and K. Strimmer. 2009.  Gene ranking and biomarker discovery under correlation.
Bioinformatics 25: 2700-2707.
&lt;DOI:10.1093/bioinformatics/btp460&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sda.ranking">sda.ranking</a></code>, <code><a href="care.html#topic+carscore">carscore</a></code>,.</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sda library
library("sda")

################# 
# training data #
#################

# prostate cancer set
data(singh2002)

# training data
Xtrain = singh2002$x
Ytrain = singh2002$y
dim(Xtrain)


####################################################
# shrinkage t-score (DDA setting - no correlation) #
####################################################

tstat = catscore(Xtrain, Ytrain, diagonal=TRUE)
dim(tstat)
tstat[1:10,]


########################################################
# shrinkage CAT score (LDA setting - with correlation) #
########################################################

cat = catscore(Xtrain, Ytrain, diagonal=FALSE)
dim(cat)
cat[1:10,]

</code></pre>

<hr>
<h2 id='centroids'>Group Centroids and (Pooled) Variances</h2><span id='topic+centroids'></span>

<h3>Description</h3>

<p><code>centroids</code> computes group centroids, the pooled mean 
and pooled variance, and optionally the group specific variances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>centroids(x, L, lambda.var, lambda.freqs, var.groups=FALSE, 
  centered.data=FALSE, verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="centroids_+3A_x">x</code></td>
<td>
<p>A matrix  containing the  data set. Note that 
the rows are sample observations and the columns
are variables.</p>
</td></tr>
<tr><td><code id="centroids_+3A_l">L</code></td>
<td>
<p>A factor with the group labels. </p>
</td></tr>
<tr><td><code id="centroids_+3A_lambda.var">lambda.var</code></td>
<td>
<p>Shrinkage intensity for the variances. If not specified it is 
estimated from the data, see details below. <code>lambda.var=0</code> implies no shrinkage
and <code>lambda.var=1</code> complete shrinkage. </p>
</td></tr>
<tr><td><code id="centroids_+3A_lambda.freqs">lambda.freqs</code></td>
<td>
<p>Shrinkage intensity for the frequencies. If not specified it is 
estimated from the data. <code>lambda.freqs=0</code> implies no shrinkage (i.e. empirical frequencies)
and <code>lambda.freqs=1</code> complete shrinkage (i.e. uniform frequencies). </p>
</td></tr>
<tr><td><code id="centroids_+3A_var.groups">var.groups</code></td>
<td>
<p>Estimate group-specific variances.</p>
</td></tr>
<tr><td><code id="centroids_+3A_centered.data">centered.data</code></td>
<td>
<p>Return column-centered data matrix.</p>
</td></tr>
<tr><td><code id="centroids_+3A_verbose">verbose</code></td>
<td>
<p>Provide some messages while computing.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As estimator of the variance we employ 
<code><a href="corpcor.html#topic+cov.shrink">var.shrink</a></code> as described in Opgen-Rhein and Strimmer (2007).
For the estimates of frequencies we rely on 
<code><a href="entropy.html#topic+freqs.shrink">freqs.shrink</a></code> as described in Hausser and Strimmer (2009).
Note that the pooled mean is computed using the estimated frequencies.
</p>


<h3>Value</h3>

<p><code>centroids</code> returns a list
with the following components:
</p>
<table>
<tr><td><code>samples</code></td>
<td>
<p>a vector containing the samples sizes in each group,</p>
</td></tr>
<tr><td><code>freqs</code></td>
<td>
<p>a vector containing the estimated frequency in each group,</p>
</td></tr>
<tr><td><code>means</code></td>
<td>
<p>the group means and the pooled mean,</p>
</td></tr>
<tr><td><code>variances</code></td>
<td>
<p>the group-specific and the pooled variances, and</p>
</td></tr>
<tr><td><code>centered.data</code></td>
<td>
<p>a matrix containing the centered data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Korbinian Strimmer (<a href="https://strimmerlab.github.io">https://strimmerlab.github.io</a>).
</p>


<h3>See Also</h3>

<p><code><a href="corpcor.html#topic+cov.shrink">var.shrink</a></code>, 
<code><a href="corpcor.html#topic+powcor.shrink">powcor.shrink</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sda library
library("sda")

## prepare data set
data(iris) # good old iris data
X = as.matrix(iris[,1:4])
Y = iris[,5]

## estimate centroids and empirical pooled variances
centroids(X, Y, lambda.var=0)
          
## also compute group-specific variances
centroids(X, Y, var.groups=TRUE, lambda.var=0)
   
## use shrinkage estimator for the variances
centroids(X, Y, var.groups=TRUE)

## return centered data
xc = centroids(X, Y, centered.data=TRUE)$centered.data
apply(xc, 2, mean)

## useful, e.g., to compute the inverse pooled correlation matrix
powcor.shrink(xc, alpha=-1)
</code></pre>

<hr>
<h2 id='khan2001'>Childhood Cancer Study of Khan et al. (2001)</h2><span id='topic+khan2001'></span>

<h3>Description</h3>

<p>Gene expression data (2308 genes for 88 samples) from the
microarray study of Khan et al. (2001).  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(khan2001)
</code></pre>


<h3>Format</h3>

<p><code>khan2001$x</code> is a 88 x 2308 matrix containing the expression levels. Note that
rows correspond to samples, and columns to genes. The row names are the original
image IDs, and the column names the orginal probe labels.
</p>
<p><code>khan2001$y</code> is a factor containing the diagnosis for each sample (&quot;BL&quot;, &quot;EWS&quot;, &quot;NB&quot;, &quot;non-SRBCT&quot;, &quot;RMS&quot;).
</p>
<p><code>khan2001$descr</code> provides some annotation for each gene.
</p>


<h3>Details</h3>

<p> This data set contains measurements of the gene
expression of 2308 genes for 88 observations:  29 cases of Ewing 
sarcoma (EWS), 11 cases of Burkitt lymphoma (BL), 18 cases of 
neuroblastoma (NB), 25 cases of rhabdomyosarcoma (RMS), 
and 5 other (non-SRBCT) samples.
</p>


<h3>Source</h3>

<p>The data are described in Khan et al. (2001). Note that the values in 
<code>khan.data$x</code> are logarithmized (using natural <code><a href="base.html#topic+log">log</a></code>) for normalization.
</p>


<h3>References</h3>

<p>Khan et al. 2001.
Classification and diagnostic prediction of cancers using gene expression 
profiling and artificial neural networks. Nature Medicine 7:673&ndash;679.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sda library
library("sda")

# load full Khan et al (2001) data set
data(khan2001)
dim(khan2001$x) # 88 2308
hist(khan2001$x)
khan2001$y # 5 levels

# data set containing the SRBCT samples
get.srbct = function()
{
  data(khan2001)
  idx = which( khan2001$y == "non-SRBCT" )
  x = khan2001$x[-idx,]
  y = factor(khan2001$y[-idx])
  descr = khan2001$descr[-idx]

  list(x=x, y=y, descr=descr)
}

srbct = get.srbct()
dim(srbct$x)   # 83 2308
hist(srbct$x)
srbct$y # 4 levels
</code></pre>

<hr>
<h2 id='predict.sda'>Shrinkage Discriminant Analysis 3: Prediction Step</h2><span id='topic+predict.sda'></span>

<h3>Description</h3>

<p><code>predict.sda</code> performs class prediction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sda'
predict(object, Xtest, verbose=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.sda_+3A_object">object</code></td>
<td>
<p>An <code>sda</code> fit object obtained from the function <code>sda</code>.</p>
</td></tr>
<tr><td><code id="predict.sda_+3A_xtest">Xtest</code></td>
<td>
<p>A matrix containing the test data set. Note that 
the rows correspond to observations and the columns
to variables.</p>
</td></tr>
<tr><td><code id="predict.sda_+3A_verbose">verbose</code></td>
<td>
<p>Report shrinkage intensities (sda) and number of used features (predict.sda).</p>
</td></tr>
<tr><td><code id="predict.sda_+3A_...">...</code></td>
<td>
<p>Additional arguments for generic predict.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>predict.sda</code> predicts class probabilities for each test sample and returns
a list with two components:
</p>
<table>
<tr><td><code>class</code></td>
<td>
<p>a factor with the most probable class assignment for each test sample, and</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>a matrix containing the respective class posterior probabilities.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Miiika Ahdesm\&quot;aki and Korbinian Strimmer (<a href="https://strimmerlab.github.io">https://strimmerlab.github.io</a>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sda">sda</a></code>, <code><a href="#topic+sda.ranking">sda.ranking</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'># see the examples at the "sda" help page

</code></pre>

<hr>
<h2 id='sda'>Shrinkage Discriminant Analysis 2: Training Step</h2><span id='topic+sda'></span>

<h3>Description</h3>

<p><code>sda</code> trains a LDA or DDA classifier using James-Stein-type shrinkage estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sda(Xtrain, L, lambda, lambda.var, lambda.freqs, diagonal=FALSE, verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sda_+3A_xtrain">Xtrain</code></td>
<td>
<p>A matrix  containing the training data set. Note that 
the rows correspond to observations and the columns
to variables.</p>
</td></tr>
<tr><td><code id="sda_+3A_l">L</code></td>
<td>
<p>A factor with the class labels of the training samples. </p>
</td></tr>
<tr><td><code id="sda_+3A_lambda">lambda</code></td>
<td>
<p>Shrinkage intensity for the correlation matrix. If not specified it is 
estimated from the data. <code>lambda=0</code> implies no shrinkage
and <code>lambda=1</code> complete shrinkage. </p>
</td></tr>
<tr><td><code id="sda_+3A_lambda.var">lambda.var</code></td>
<td>
<p>Shrinkage intensity for the variances. If not specified it is 
estimated from the data. <code>lambda.var=0</code> implies no shrinkage
and <code>lambda.var=1</code> complete shrinkage. </p>
</td></tr>
<tr><td><code id="sda_+3A_lambda.freqs">lambda.freqs</code></td>
<td>
<p>Shrinkage intensity for the frequencies. If not specified it is 
estimated from the data. <code>lambda.freqs=0</code> implies no shrinkage (i.e. empirical frequencies)
and <code>lambda.freqs=1</code> complete shrinkage (i.e. uniform frequencies). </p>
</td></tr>
<tr><td><code id="sda_+3A_diagonal">diagonal</code></td>
<td>
<p>Chooses between LDA (default, <code>diagonal=FALSE</code>) and DDA (<code>diagonal=TRUE</code>).</p>
</td></tr>
<tr><td><code id="sda_+3A_verbose">verbose</code></td>
<td>
<p>Print out some info while computing.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In order to train the LDA or DDA classifier, three separate shrinkage estimators are employed:
</p>

<ul>
<li><p>class frequencies: the  estimator <code><a href="entropy.html#topic+entropy.shrink">freqs.shrink</a></code> 
from   Hausser and Strimmer (2008),
</p>
</li>
<li><p>variances: the estimator <code><a href="corpcor.html#topic+cov.shrink">var.shrink</a></code> from Opgen-Rhein and Strimmer (2007),  
</p>
</li>
<li><p>correlations: the estimator <code><a href="corpcor.html#topic+cov.shrink">cor.shrink</a></code> from Sch\&quot;afer and Strimmer (2005).  
</p>
</li></ul>

<p>Note that the three corresponding regularization parameters
are obtained analytically without resorting to computer intensive resampling.
</p>


<h3>Value</h3>

<p><code>sda</code> trains the classifier and returns an <code>sda</code> object
with the following components needed for the subsequent prediction:
</p>
<table>
<tr><td><code>regularization</code></td>
<td>
<p>a vector containing the three estimated shrinkage intensities,</p>
</td></tr>
<tr><td><code>freqs</code></td>
<td>
<p>the estimated class frequencies,</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>vector containing the intercepts used for prediction,</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>matrix containing the coefficients used for prediction.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Miika Ahdesm\&quot;aki and Korbinian Strimmer (<a href="https://strimmerlab.github.io">https://strimmerlab.github.io</a>).
</p>


<h3>References</h3>

<p>Ahdesm\&quot;aki, A., and K. Strimmer. 2010.  Feature selection in omics prediction problems 
using cat scores and false non-discovery rate control. Ann. Appl. Stat. 4: 503-519.
&lt;DOI:10.1214/09-AOAS277&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.sda">predict.sda</a></code>, <code><a href="#topic+sda.ranking">sda.ranking</a></code>,
<code><a href="entropy.html#topic+entropy.shrink">freqs.shrink</a></code>, 
<code><a href="corpcor.html#topic+cov.shrink">var.shrink</a></code>, 
<code><a href="corpcor.html#topic+invcov.shrink">invcor.shrink</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sda library
library("sda")

########################## 
# training and test data #
##########################

# data set containing the SRBCT samples
get.srbct = function()
{
  data(khan2001)
  idx = which( khan2001$y == "non-SRBCT" )
  x = khan2001$x[-idx,]
  y = factor(khan2001$y[-idx])
  descr = khan2001$descr[-idx]

  list(x=x, y=y, descr=descr)
}
srbct = get.srbct()

# training data
Xtrain = srbct$x[1:63,]
Ytrain = srbct$y[1:63]
Xtest = srbct$x[64:83,]
Ytest = srbct$y[64:83]


###################################################
# classification with correlation (shrinkage LDA) #
###################################################

sda.fit = sda(Xtrain, Ytrain)
ynew = predict(sda.fit, Xtest)$class # using all 2308 features
sum(ynew != Ytest) 

###########################################################
# classification with diagonal covariance (shrinkage DDA) #
###########################################################

sda.fit = sda(Xtrain, Ytrain, diagonal=TRUE)
ynew = predict(sda.fit, Xtest)$class # using all 2308 features
sum(ynew != Ytest) 

#################################################################
# for complete example scripts illustrating classification with #
# feature selection visit https://strimmerlab.github.io/software/sda/  #
#################################################################
</code></pre>

<hr>
<h2 id='sda-internal'>Internal sda functions</h2><span id='topic+max.col.value'></span><span id='topic+pvt.groups'></span>

<h3>Description</h3>

<p>Internal sda functions.
</p>


<h3>Note</h3>

<p>These are not to be called by the user (or in some cases are just
waiting for proper documentation to be written).
</p>

<hr>
<h2 id='sda-package'>The sda Package</h2><span id='topic+sda-package'></span>

<h3>Description</h3>

<p>This package performs linear discriminant analysis (LDA)
and diagonal discriminant analysis (DDA)
with variable selection using correlation-adjusted t (CAT) scores.
</p>
<p>The classifier is trained using James-Stein-type shrinkage estimators.
Variable selection is based on ranking predictors by CAT scores (LDA) 
or t-scores (DDA).  A cutoff is chosen by false non-discovery 
rate (FNDR) or  higher criticism (HC) thresholding.
</p>
<p>This approach is particularly suited for high-dimensional classification
with correlation among predictors.
For details see Zuber and Strimmer (2009) and Ahdesm\&quot;aki and Strimmer (2010).
</p>
<p>Typically the functions in this package are applied in three steps:
</p>

<ul>
<li><p>Step 1:feature selection with <code><a href="#topic+sda.ranking">sda.ranking</a></code>, 
</p>
</li>
<li><p>Step 2:training the classifier with <code><a href="#topic+sda">sda</a></code>, and
</p>
</li>
<li><p>Step 3:classification using <code><a href="#topic+predict.sda">predict.sda</a></code>. 
</p>
</li></ul>

<p>The accompanying web site (see below) provides example R scripts to illustrate
the functionality of this package.
</p>


<h3>Author(s)</h3>

<p>Miika Ahdesm\&quot;aki, Verena Zuber and Korbinian Strimmer (<a href="https://strimmerlab.github.io/">https://strimmerlab.github.io/</a>)</p>


<h3>References</h3>

<p>Ahdesm\&quot;aki, A., and K. Strimmer. 2010.  Feature selection in omics prediction problems 
using cat scores and false non-discovery rate control. Ann. Appl. Stat. 4: 503-519.
&lt;DOI:10.1214/09-AOAS277&gt;
</p>
<p>Zuber, V., and K. Strimmer. 2009.  Gene ranking and biomarker discovery under correlation.
Bioinformatics 25: 2700-2707.
&lt;DOI:10.1093/bioinformatics/btp460&gt;
</p>
<p>See website: <a href="https://strimmerlab.github.io/software/sda/">https://strimmerlab.github.io/software/sda/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+catscore">catscore</a></code>, <code><a href="#topic+sda.ranking">sda.ranking</a></code>, <code><a href="#topic+sda">sda</a></code>, <code><a href="#topic+predict.sda">predict.sda</a></code>. 
</p>

<hr>
<h2 id='sda.ranking'>Shrinkage Discriminant Analysis 1: Predictor Ranking</h2><span id='topic+sda.ranking'></span><span id='topic+plot.sda.ranking'></span>

<h3>Description</h3>

<p><code>sda.ranking</code> determines a ranking of predictors by computing  CAT scores
(correlation-adjusted t-scores)
between the group centroids and the pooled mean.
</p>
<p><code>plot.sda.ranking</code> provides a graphical visualization of the top ranking features.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sda.ranking(Xtrain, L, lambda, lambda.var, lambda.freqs,
  ranking.score=c("entropy", "avg", "max"), 
  diagonal=FALSE, fdr=TRUE, plot.fdr=FALSE, verbose=TRUE)
## S3 method for class 'sda.ranking'
plot(x, top=40, arrow.col="blue", zeroaxis.col="red",
   ylab="Features", main, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sda.ranking_+3A_xtrain">Xtrain</code></td>
<td>
<p>A matrix  containing the training data set. Note that 
the rows correspond to observations and the columns
to variables.</p>
</td></tr>
<tr><td><code id="sda.ranking_+3A_l">L</code></td>
<td>
<p>A factor with the class labels of the training samples. </p>
</td></tr>
<tr><td><code id="sda.ranking_+3A_lambda">lambda</code></td>
<td>
<p>Shrinkage intensity for the correlation matrix. If not specified it is 
estimated from the data. <code>lambda=0</code> implies no shrinkage
and <code>lambda=1</code> complete shrinkage. </p>
</td></tr>
<tr><td><code id="sda.ranking_+3A_lambda.var">lambda.var</code></td>
<td>
<p>Shrinkage intensity for the variances. If not specified it is 
estimated from the data. <code>lambda.var=0</code> implies no shrinkage
and <code>lambda.var=1</code> complete shrinkage. </p>
</td></tr>
<tr><td><code id="sda.ranking_+3A_lambda.freqs">lambda.freqs</code></td>
<td>
<p>Shrinkage intensity for the frequencies. If not specified it is 
estimated from the data. <code>lambda.freqs=0</code> implies no shrinkage (i.e. empirical frequencies)
and <code>lambda.freqs=1</code> complete shrinkage (i.e. uniform frequencies). </p>
</td></tr>
<tr><td><code id="sda.ranking_+3A_diagonal">diagonal</code></td>
<td>
<p>Chooses between LDA (default, <code>diagonal=FALSE</code>) and DDA (<code>diagonal=TRUE</code>).</p>
</td></tr>
<tr><td><code id="sda.ranking_+3A_ranking.score">ranking.score</code></td>
<td>
<p>how to compute the summary score for each variable from the CAT scores of all classes - see Details.</p>
</td></tr>
<tr><td><code id="sda.ranking_+3A_fdr">fdr</code></td>
<td>
<p>compute FDR values and HC scores for each feature.</p>
</td></tr>
<tr><td><code id="sda.ranking_+3A_plot.fdr">plot.fdr</code></td>
<td>
<p>Show plot with estimated FDR values.</p>
</td></tr>
<tr><td><code id="sda.ranking_+3A_verbose">verbose</code></td>
<td>
<p>Print out some info while computing.</p>
</td></tr>
<tr><td><code id="sda.ranking_+3A_x">x</code></td>
<td>
<p>An &quot;sda.ranking&quot; object &ndash; this is produced by the sda.ranking() function.</p>
</td></tr>
<tr><td><code id="sda.ranking_+3A_top">top</code></td>
<td>
<p>The number of top-ranking features shown in the plot (default: 40).</p>
</td></tr>
<tr><td><code id="sda.ranking_+3A_arrow.col">arrow.col</code></td>
<td>
<p>Color of the arrows in the plot (default is <code>"blue"</code>).</p>
</td></tr>
<tr><td><code id="sda.ranking_+3A_zeroaxis.col">zeroaxis.col</code></td>
<td>
<p>Color for the center zero axis (default is <code>"red"</code>).</p>
</td></tr>
<tr><td><code id="sda.ranking_+3A_ylab">ylab</code></td>
<td>
<p>Label written next to feature list (default is <code>"Features"</code>).</p>
</td></tr>
<tr><td><code id="sda.ranking_+3A_main">main</code></td>
<td>
<p>Main title (if missing, <code>"The", top, "Top Ranking Features"</code> is used).</p>
</td></tr>
<tr><td><code id="sda.ranking_+3A_...">...</code></td>
<td>
<p>Other options passed on to generic plot().</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each predictor variable and centroid a shrinkage CAT scores of the mean versus
the pooled mean is computed.   If there are only two classes the CAT score vs. the pooled
mean reduces to the CAT score between the two group means.
Moreover, in the diagonal case (LDA) the (shrinkage) CAT score reduces to the (shrinkage) t-score.
</p>
<p>The overall ranking of a feature is determine by computing a summary score from the CAT scores.
This is controlled by the option <code>ranking.score</code>.  The default setting
(<code>ranking.score="entropy"</code>) uses mutual information
between the response and the respective predictors (<code>ranking.score</code>) for ranking.  This is equivalent to
a weighted sum of squared CAT scores across the classes.  Another possibility is to employ
the average of the squared CAT scores for ranking (as suggested in Ahdesm\&quot;aki and Strimmer 2010) 
by setting <code>ranking.score="avg"</code>.  A third option is to use the maximum of the squared CAT scores across groups (similarly as in the PAM algorithm) via setting <code>ranking.score="max"</code>.
Note that in the case of two classes all three options are equivalent and
lead to identical scores.  Thus, the choice of <code>ranking.score</code> is important only
in the multi-class setting.  In the two-class case the features are simply ranked according to the
(shrinkage) squared CAT-scores (or t-scores, if there is no correlation among predictors).
</p>
<p>The current default approach is to use ranking by mutual information (i.e. relative entropy
between full model vs. model without predictor) and to use shrinkage estimators of frequencies.
In order to reproduce exactly the ranking computed by previous versions (1.1.0 to 1.3.0) of the <code>sda</code> package set the options  <code>ranking.score="avg"</code> and <code>lambda.freqs=0</code>.
</p>
<p>Calling <code>sda.ranking</code> is step 1 in a classification analysis with the
sda package.  Steps 2 and 3 are 
<code><a href="#topic+sda">sda</a></code> and <code><a href="#topic+predict.sda">predict.sda</a></code>
</p>
<p>See Zuber and Strimmer (2009) for CAT scores in general, and 
Ahdesm\&quot;aki and Strimmer (2010) for details on multi-class CAT scores.
For shrinkage t scores see Opgen-Rhein and Strimmer (2007). 
</p>


<h3>Value</h3>

<p><code>sda.ranking</code> returns a matrix with the following columns:
</p>
<table>
<tr><td><code>idx</code></td>
<td>
<p>original feature number</p>
</td></tr>
<tr><td><code>score</code></td>
<td>
<p>sum of the squared CAT scores across groups - this determines the overall ranking of a feature</p>
</td></tr>
<tr><td><code>cat</code></td>
<td>
<p>for each group and feature the cat score of the centroid versus the pooled mean</p>
</td></tr>
</table>
<p>If <code>fdr=TRUE</code> then additionally local false discovery rate (FDR) values 
as well as higher criticism (HC) scores are computed for each feature
(using <code><a href="fdrtool.html#topic+fdrtool">fdrtool</a></code>).
</p>


<h3>Author(s)</h3>

<p>Miika Ahdesm\&quot;aki, Verena Zuber, Sebastian Gibb, and Korbinian Strimmer (<a href="https://strimmerlab.github.io">https://strimmerlab.github.io</a>).
</p>


<h3>References</h3>

<p>Ahdesm\&quot;aki, A., and K. Strimmer. 2010.  Feature selection in omics prediction problems 
using cat scores and false non-discovery rate control. Ann. Appl. Stat. 4: 503-519.
&lt;DOI:10.1214/09-AOAS277&gt;
</p>
<p>Opgen-Rhein, R., and K. Strimmer. 2007. Accurate ranking of differentially expressed 
genes by a distribution-free shrinkage approach.  
Statist. Appl. Genet. Mol. Biol. 6:9.
&lt;DOI:10.2202/1544-6115.1252&gt;
</p>
<p>Zuber, V., and K. Strimmer. 2009.  Gene ranking and biomarker discovery under correlation.
Bioinformatics 25: 2700-2707. &lt;DOI:10.1093/bioinformatics/btp460&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+catscore">catscore</a></code>, <code><a href="#topic+sda">sda</a></code>, <code><a href="#topic+predict.sda">predict.sda</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sda library
library("sda")

################# 
# training data #
#################

# prostate cancer set
data(singh2002)

# training data
Xtrain = singh2002$x
Ytrain = singh2002$y

######################################### 
# feature ranking (diagonal covariance) #
#########################################

# ranking using t-scores (DDA)
ranking.DDA = sda.ranking(Xtrain, Ytrain, diagonal=TRUE)
ranking.DDA[1:10,]

# plot t-scores for the top 40 genes
plot(ranking.DDA, top=40) 

# number of features with local FDR &lt; 0.8 
# (i.e. features useful for prediction)
sum(ranking.DDA[,"lfdr"] &lt; 0.8)

# number of features with local FDR &lt; 0.2 
# (i.e. significant non-null features)
sum(ranking.DDA[,"lfdr"] &lt; 0.2)

# optimal feature set according to HC score
plot(ranking.DDA[,"HC"], type="l")
which.max( ranking.DDA[1:1000,"HC"] ) 


##################################### 
# feature ranking (full covariance) #
#####################################

# ranking using CAT-scores (LDA)
ranking.LDA = sda.ranking(Xtrain, Ytrain, diagonal=FALSE)
ranking.LDA[1:10,]

# plot t-scores for the top 40 genes
plot(ranking.LDA, top=40) 

# number of features with local FDR &lt; 0.8 
# (i.e. features useful for prediction)
sum(ranking.LDA[,"lfdr"] &lt; 0.8)

# number of features with local FDR &lt; 0.2 
# (i.e. significant non-null features)
sum(ranking.LDA[,"lfdr"] &lt; 0.2)

# optimal feature set according to HC score
plot(ranking.LDA[,"HC"], type="l")
which.max( ranking.LDA[1:1000,"HC"] ) 

</code></pre>

<hr>
<h2 id='singh2002'>Prostate Cancer Study of Singh et al. (2002)</h2><span id='topic+singh2002'></span>

<h3>Description</h3>

<p>Gene expression data (6033 genes for 102 samples) from the
microarray study of Singh et al. (2002).  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(singh2002)
</code></pre>


<h3>Format</h3>

<p><code>singh2002$x</code> is a 102 x 6033 matrix containing the expression levels.
The rows contain the samples and the columns the genes.
</p>
<p><code>singh2002$y</code> is a factor containing the diagnosis for each sample (&quot;cancer&quot; or &quot;healthy&quot;).
</p>


<h3>Details</h3>

<p> This data set contains measurements of the gene
expression of 6033 genes for 102 observations:  52 prostate cancer patients
and 50 healty men.
</p>


<h3>Source</h3>

<p>The data are described in Singh et al. (2001) and are provided in exactly the form
as used by Efron (2008). 
</p>


<h3>References</h3>

<p>D. Singh et al. 2002. Gene expression correlates of clinical prostate cancer behavior.
Cancer Cell 1:203&ndash;209.
</p>
<p>Efron, B. 2008. Empirical Bayes estimates for large-scale prediction problems.
Technical Report, Standford University.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sda library
library("sda")

# load Singh et al (2001) data set
data(singh2002)
dim(singh2002$x) # 102 6033
hist(singh2002$x)
singh2002$y # 2 levels
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
