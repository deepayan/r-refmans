<!DOCTYPE html><html><head><title>Help for package approximator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {approximator}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#approximator-package'>
<p>Bayesian approximation of computer models when fast approximations are available</p></a></li>
<li><a href='#Afun'><p>Matrix of correlations between two sets of points</p></a></li>
<li><a href='#as.sublist'><p>Converts a level one design matrix and a subsets object into a</p>
list of design matrices, one for each level</a></li>
<li><a href='#basis.toy'><p>Toy basis functions</p></a></li>
<li><a href='#betahat.app'><p>Estimate for beta</p></a></li>
<li><a href='#c.fun'><p>Correlations between points in parameter space</p></a></li>
<li><a href='#generate.toy.observations'><p>Er, generate toy observations</p></a></li>
<li><a href='#genie'><p>Genie datasets for approximator package</p></a></li>
<li><a href='#H.fun'><p>The H matrix</p></a></li>
<li><a href='#hdash.fun'><p>Hdash</p></a></li>
<li><a href='#hpa.fun.toy'><p>Toy example of a hyperparameter object creation function</p></a></li>
<li><a href='#is.consistent'><p>Checks observational data for consistency with a subsets object</p></a></li>
<li><a href='#mdash.fun'><p>Mean of Gaussian process</p></a></li>
<li><a href='#object'><p>Optimization of posterior likelihood of hyperparameters</p></a></li>
<li><a href='#Pi'><p>Kennedy's Pi notation</p></a></li>
<li><a href='#subset_maker'><p>Create a simple subset object</p></a></li>
<li><a href='#subsets.fun'><p>Generate and test subsets</p></a></li>
<li><a href='#tee.fun'><p>Returns generalized distances</p></a></li>
<li><a href='#toyapps'><p>Toy datasets for approximator package</p></a></li>
<li><a href='#V.fun.app'><p>Variance matrix</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Bayesian Prediction of Complex Computer Codes</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2-8</td>
</tr>
<tr>
<td>Author:</td>
<td>Robin K. S. Hankin</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.0.0), emulator (&ge; 1.2-11)</td>
</tr>
<tr>
<td>Imports:</td>
<td>mvtnorm</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Robin K. S. Hankin &lt;hankin.robin@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs Bayesian prediction of complex computer codes when fast approximations are available.  It uses a hierarchical version of the Gaussian process, originally proposed by Kennedy and O'Hagan (2000), Biometrika 87(1):1.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-24 19:53:26 UTC; rhankin</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-24 22:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='approximator-package'>
Bayesian approximation of computer models when fast approximations are available
</h2><span id='topic+approximator-package'></span><span id='topic+approximator'></span>

<h3>Description</h3>

<p>Implements the ideas of Kennedy and O'Hagan 2000 (see references).
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> approximator</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.0</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2006-01-10</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>This package implements the Bayesian approximation techniques discussed
in Kennedy and O'Hagan 2000.
</p>
<p>In its simplest form, it takes input from a &ldquo;slow&rdquo; but accurate
code and a &ldquo;fast&rdquo; but inaccurate code, each run at different
points in parameter space.  The approximator package then uses both sets
of model runs to infer what the slow code would produce at a given,
untried point in parameter space.
</p>
<p>The package includes functionality to work with a hierarchy of codes
with increasing accuracy.
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin
</p>
<p>Maintainer:  &lt;hankin.robin@gmail.com&gt;
</p>


<h3>References</h3>

<p>R. K. S. Hankin 2005. &ldquo;Introducing BACCO, an R bundle for
Bayesian analysis of computer code output&rdquo;, Journal of Statistical
Software, 14(16)
</p>
<p>M. C. Kennedy and A. O'Hagan 2000. &ldquo;Predicting the output from
a complex computer code when fast approximations are available&rdquo;
Biometrika, 87(1): pp1-13
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toyapps)
mdash.fun(x=1:3, D1=D1.toy, subsets=subsets.toy, hpa=hpa.toy, z=z.toy, basis=basis.toy)
</code></pre>

<hr>
<h2 id='Afun'>Matrix of correlations between two sets of points</h2><span id='topic+Afun'></span>

<h3>Description</h3>

<p>Returns the matrix of correlations of code output at each level
evaluated at points on the design matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Afun(level, Di, Dj, hpa)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Afun_+3A_level">level</code></td>
<td>
<p>The level.  This enters via the correlation scales</p>
</td></tr>
<tr><td><code id="Afun_+3A_di">Di</code></td>
<td>
<p>First set of points</p>
</td></tr>
<tr><td><code id="Afun_+3A_dj">Dj</code></td>
<td>
<p>Second set of points</p>
</td></tr>
<tr><td><code id="Afun_+3A_hpa">hpa</code></td>
<td>
<p>Hyperparameter object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is essentially a convenient wrapper for function
<code>corr.matrix</code>.   It is not really intended for the end user.  
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>

<p>M. C. Kennedy and A. O'Hagan 2000. &ldquo;Predicting the output from
a complex computer code when fast approximations are available&rdquo;
Biometrika, 87(1): pp1-13
</p>


<h3>See Also</h3>

<p><code><a href="emulator.html#topic+corr">corr</a></code>,<code><a href="#topic+c_fun">c_fun</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toyapps)
D2 &lt;-  D1.toy[subsets.toy[[2]],]
D3 &lt;-  D1.toy[subsets.toy[[3]],]

Afun(1,D2,D3,hpa.toy)
Afun(2,D2,D3,hpa.toy)

</code></pre>

<hr>
<h2 id='as.sublist'>Converts a level one design matrix and a subsets object into a
list of design matrices, one for each level</h2><span id='topic+as.sublist'></span>

<h3>Description</h3>

<p>Given a level one design matrix, and a subsets object, convert into a
list of design matrices, each one of which is the design matrix for its
own level
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.sublist(D1, subsets)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.sublist_+3A_d1">D1</code></td>
<td>
<p>Design matrix for level one code</p>
</td></tr>
<tr><td><code id="as.sublist_+3A_subsets">subsets</code></td>
<td>
<p>subsets object</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>

<p>M. C. Kennedy and A. O'Hagan 2000. &ldquo;Predicting the output from
a complex computer code when fast approximations are available&rdquo;
Biometrika, 87(1): pp1-13
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toyapps)
as.sublist(D1=D1.toy , subsets=subsets.toy)
</code></pre>

<hr>
<h2 id='basis.toy'>Toy basis functions</h2><span id='topic+basis.toy'></span>

<h3>Description</h3>

<p>A working example of a basis function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>basis.toy(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="basis.toy_+3A_x">x</code></td>
<td>
<p>Point in parameter space</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>

<p>M. C. Kennedy and A. O'Hagan 2000. &ldquo;Predicting the output from
a complex computer code when fast approximations are available&rdquo;
Biometrika, 87(1): pp1-13
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toyapps)
basis.toy(D1.toy)
</code></pre>

<hr>
<h2 id='betahat.app'>Estimate for beta</h2><span id='topic+betahat.app'></span><span id='topic+betahat.app.H'></span>

<h3>Description</h3>

<p>Returns the estimator for beta; equation 5.  Function
<code>betahat.app()</code> returns the estimate in terms of fundamental
variables; <code>betahat.app.H()</code> requires the <code>H</code> matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betahat.app.H(H, V = NULL, Vinv = NULL, z)
betahat.app(D1, subsets, basis, hpa, z, use.Vinv=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="betahat.app_+3A_h">H</code></td>
<td>
<p>In <code>betahat.app.H()</code>, the H matrix, eg that
returned by <code>H.fun()</code></p>
</td></tr>
<tr><td><code id="betahat.app_+3A_v">V</code></td>
<td>
<p>Variance matrix</p>
</td></tr>
<tr><td><code id="betahat.app_+3A_vinv">Vinv</code></td>
<td>
<p>Inverse of variance matrix.  If not supplied, it is
calculated</p>
</td></tr>
<tr><td><code id="betahat.app_+3A_use.vinv">use.Vinv</code></td>
<td>
<p>In function <code>betahat.app()</code>, a Boolean argument
with default <code>TRUE</code> meaning to calculate the inverse of the
<code>V</code> matrix; and <code>FALSE</code> meaning to use a method which does
not involve calculating the inverse of <code>V</code>.  The default method
seems to be faster; YMMV</p>
</td></tr>
<tr><td><code id="betahat.app_+3A_z">z</code></td>
<td>
<p>vector of observations</p>
</td></tr>
<tr><td><code id="betahat.app_+3A_d1">D1</code></td>
<td>
<p>Design matrix for level 1 code</p>
</td></tr>
<tr><td><code id="betahat.app_+3A_subsets">subsets</code></td>
<td>
<p>Subsets object</p>
</td></tr>
<tr><td><code id="betahat.app_+3A_basis">basis</code></td>
<td>
<p>Basis function</p>
</td></tr>
<tr><td><code id="betahat.app_+3A_hpa">hpa</code></td>
<td>
<p>Hyperparameter object</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>

<p>M. C. Kennedy and A. O'Hagan 2000. &ldquo;Predicting the output from
a complex computer code when fast approximations are available&rdquo;
Biometrika, 87(1): pp1-13
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toyapps)

 betahat.app(D1=D1.toy, subsets=subsets.toy, basis=basis.toy, hpa=hpa.toy, z=z.toy, use.Vinv=TRUE)

 H &lt;- H.fun.app(D1=D1.toy, subsets=subsets.toy, basis=basis.toy,hpa=hpa.toy)
 V &lt;- V.fun.app(D1=D1.toy, subsets=subsets.toy, hpa=hpa.toy)
 betahat.app.H(H=H,V=V,z=z.toy)

</code></pre>

<hr>
<h2 id='c.fun'>Correlations between points in parameter space</h2><span id='topic+c_fun'></span><span id='topic+c.fun'></span><span id='topic+cdash.fun'></span>

<h3>Description</h3>

<p>Correlation matrices between (sets of) points in parameter space, both
prior (<code>c_fun()</code>) and posterior (<code>cdash.fun()</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>c_fun(x, xdash=x, subsets, hpa)
cdash.fun(x, xdash=x, V=NULL, Vinv=NULL, D1, subsets, basis, hpa, method=2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="c.fun_+3A_x">x</code>, <code id="c.fun_+3A_xdash">xdash</code></td>
<td>
<p>Points in parameter space; or, if a matrix,
interpret the rows as points in parameter space.  Note that the
default value of <code>xdash</code> (viz <code>x</code>) will return the
variance-covariance matrix of a set of points</p>
</td></tr>
<tr><td><code id="c.fun_+3A_d1">D1</code></td>
<td>
<p>Design matrix</p>
</td></tr>
<tr><td><code id="c.fun_+3A_subsets">subsets</code></td>
<td>
<p>Subset object</p>
</td></tr>
<tr><td><code id="c.fun_+3A_hpa">hpa</code></td>
<td>
<p>hyperparameter object</p>
</td></tr>
<tr><td><code id="c.fun_+3A_basis">basis</code></td>
<td>
<p>Basis function</p>
</td></tr>
<tr><td><code id="c.fun_+3A_v">V</code>, <code id="c.fun_+3A_vinv">Vinv</code></td>
<td>
<p>In function <code>cdash.fun()</code>, the data covariance
matrix and its inverse.  If
<code>NULL</code>, the matrix will be calculated from scratch.  Supplying
a precalculated value for <code>V</code>, and especially <code>Vinv</code>,
makes for very much faster execution (edepending on <code>method</code>)</p>
</td></tr>
<tr><td><code id="c.fun_+3A_method">method</code></td>
<td>
<p>Integer specifying which of several algebraically
identical methods to use.  See the source code for details, but
default option 2 seems to be the best.  Bear in mind that option 3
does not require inversion of a matrix, but is not faster in
practice</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a matrix of covariances
</p>


<h3>Note</h3>

<p>Do not confuse function <code>c_fun()</code>, which computes <code class="reqn">c(x,x')</code>
defined just below equation 7 on page 4 with <code class="reqn">c_t(x,x')</code> defined
in equation 3 on page 3.
</p>
<p>Consider the example given for two levels on page 4 just after
equation 7:
<code class="reqn">c(x,x')=c_2(x,x')+\rho_1^2c_1(x,x')</code>
is a kind of prior covariance matrix.  Matrix <code class="reqn">c'(x,x')</code> is a
posterior covariance matrix, conditional on the code observations.
</p>
<p>Function <code>Afun()</code> evaluates <code class="reqn">c_t(x,x')</code> in a nice vectorized way.
</p>
<p>Equation 7 of KOH2000 contains a typo.
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>

<p>KOH2000</p>


<h3>See Also</h3>

<p><code><a href="#topic+Afun">Afun</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toyapps)

x &lt;- latin.hypercube(4,3)
rownames(x) &lt;- c("ash" , "elm" , "oak", "pine")
xdash &lt;- latin.hypercube(7,3)
rownames(xdash) &lt;- c("cod","bream","skate","sole","eel","crab","squid")

cdash.fun(x=x,xdash=xdash, D1=D1.toy, basis=basis.toy,subsets=subsets.toy, hpa=hpa.toy)

# Now add a point whose top-level value is known:
x &lt;- rbind(x,D1.toy[subsets.toy[[4]][1],])

cdash.fun(x=x,xdash=xdash, D1=D1.toy, basis=basis.toy,subsets=subsets.toy, hpa=hpa.toy)
# Observe how the bottom row is zero (up to rounding error)
</code></pre>

<hr>
<h2 id='generate.toy.observations'>Er, generate toy observations</h2><span id='topic+generate.toy.observations'></span>

<h3>Description</h3>

<p>Generates toy observations on four levels using either internal
(unknown) parameters and hyperparameters, or user-supplied versions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate.toy.observations(D1, subsets, basis.fun, hpa = NULL, betas = NULL,
export.truth = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generate.toy.observations_+3A_d1">D1</code></td>
<td>
<p>Design matrix for level 1 code</p>
</td></tr>
<tr><td><code id="generate.toy.observations_+3A_subsets">subsets</code></td>
<td>
<p>Subset object</p>
</td></tr>
<tr><td><code id="generate.toy.observations_+3A_basis.fun">basis.fun</code></td>
<td>
<p>Basis function</p>
</td></tr>
<tr><td><code id="generate.toy.observations_+3A_hpa">hpa</code></td>
<td>
<p>Hyperparameter object.  If <code>NULL</code>, use the  internal
(true but unknown) hyperparameter object</p>
</td></tr>
<tr><td><code id="generate.toy.observations_+3A_betas">betas</code></td>
<td>
<p>Regression coefficients.  If <code>NULL</code>, use the  internal
(true but unknown) regression coefficients</p>
</td></tr>
<tr><td><code id="generate.toy.observations_+3A_export.truth">export.truth</code></td>
<td>
<p>Boolean, with default <code>FALSE</code> meaning to
return synthetic observations and <code>TRUE</code> meaning to return the
actual hyperparameters and coefficients.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>

<p>M. C. Kennedy and A. O'Hagan 2000. &ldquo;Predicting the output from
a complex computer code when fast approximations are available&rdquo;
Biometrika, 87(1): pp1-13
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toyapps)
generate.toy.observations(D1=D1.toy, subsets=subsets.toy, basis.fun=basis.toy)
</code></pre>

<hr>
<h2 id='genie'>Genie datasets for approximator package</h2><span id='topic+genie'></span><span id='topic+Genie'></span><span id='topic+D1.genie'></span><span id='topic+hpa.genie'></span><span id='topic+z.genie'></span><span id='topic+subsets.genie'></span><span id='topic+basis.genie'></span><span id='topic+hpa.fun.genie'></span><span id='topic+hpa.genie.start'></span><span id='topic+hpa.genie.optimal'></span>

<h3>Description</h3>

<p>Genie datasets that illustrate the package.
</p>


<h3>Format</h3>

<p>The genie example is a case with three levels.
</p>
<p>The <code>D1.genie</code> matrix is 36 rows of code run points,
corresponding to the observations of the level 1 code.  It has four
columns, one per parameter.
</p>
<p><code>hpa.genie</code> is a hyperparameter object.  
</p>
<p><code>subsets.genie</code> is a list of three elements.  Element <code class="reqn">i</code>
corresponds to the rows of <code>D1.genie</code> at which level <code class="reqn">i</code> has
been observed.
</p>
<p><code>z.genie</code> is a three element list.  Each element is a vector;
element <code class="reqn">i</code> corresponds to observations of level <code class="reqn">i</code>.  The
lengths will match those of <code>subsets.genie</code>.
</p>
<p>Function <code>basis.genie()</code> is a suitable basis function.
</p>
<p>Function <code>hpa.fun.genie()</code> creates a hyperparameter object in a
form suitable for passing to the other functions in the library.
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>

<p>M. C. Kennedy and A. O'Hagan 2000. &ldquo;Predicting the output from
a complex computer code when fast approximations are available&rdquo;
Biometrika, 87(1): pp1-13
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(genie)
z.genie


jj &lt;- list(trace=100,maxit=10)

hpa.genie.level1 &lt;- opt.1(D=D1.genie, z=z.genie,
                          basis=basis.genie, subsets=subsets.genie,
                          hpa.start=hpa.genie.start,control=jj)
 
hpa.genie.level2 &lt;- opt.gt.1(level=2, D=D1.genie, z=z.genie,
                          basis=basis.genie, subsets=subsets.genie,
                          hpa.start=hpa.genie.level1,control=jj)

hpa.genie.level3 &lt;- opt.gt.1(level=3, D=D1.genie, z=z.genie,
                          basis=basis.genie, subsets=subsets.genie,
                          hpa.start=hpa.genie.level2,control=jj) 


</code></pre>

<hr>
<h2 id='H.fun'>The H matrix</h2><span id='topic+H.fun.app'></span>

<h3>Description</h3>

<p>Returns the matrix of bases H.    The &ldquo;app&rdquo; of the function name means
&ldquo;approximator&rdquo;, to distinguish it from function <code>H.fun()</code>
of the calibrator package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>H.fun.app(D1, subsets, basis, hpa)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="H.fun_+3A_d1">D1</code></td>
<td>
<p>Design matrix for level 1 code</p>
</td></tr>
<tr><td><code id="H.fun_+3A_subsets">subsets</code></td>
<td>
<p>Subsets object</p>
</td></tr>
<tr><td><code id="H.fun_+3A_basis">basis</code></td>
<td>
<p>Basis function</p>
</td></tr>
<tr><td><code id="H.fun_+3A_hpa">hpa</code></td>
<td>
<p>Hyperparameter object</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>

<p>M. C. Kennedy and A. O'Hagan 2000. &ldquo;Predicting the output from
a complex computer code when fast approximations are available&rdquo;
Biometrika, 87(1): pp1-13
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toyapps)
H.fun.app(D1.toy , subsets=subsets.toy , basis=basis.toy , hpa=hpa.toy)
</code></pre>

<hr>
<h2 id='hdash.fun'>Hdash</h2><span id='topic+hdash.fun'></span>

<h3>Description</h3>

<p>Returns the thing at the top of page 6
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hdash.fun(x, hpa, basis)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hdash.fun_+3A_x">x</code></td>
<td>
<p>Point in question</p>
</td></tr>
<tr><td><code id="hdash.fun_+3A_hpa">hpa</code></td>
<td>
<p>Hyperparameter object</p>
</td></tr>
<tr><td><code id="hdash.fun_+3A_basis">basis</code></td>
<td>
<p>Basis functions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>

<p>M. C. Kennedy and A. O'Hagan 2000. &ldquo;Predicting the output from
a complex computer code when fast approximations are available&rdquo;
Biometrika, 87(1): pp1-13
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toyapps)
hdash.fun(x=1:3 , hpa=hpa.toy,basis=basis.toy)

uu &lt;- rbind(1:3,1,1:3,3:1)
rownames(uu) &lt;- paste("uu",1:4,sep="_")
hdash.fun(x=uu, hpa=hpa.toy,basis=basis.toy)

</code></pre>

<hr>
<h2 id='hpa.fun.toy'>Toy example of a hyperparameter object creation function</h2><span id='topic+hpa.fun.toy'></span>

<h3>Description</h3>

<p>Creates a hyperparameter object from a vector of length 19.  Intended as
a toy example to be modified for real-world cases.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hpa.fun.toy(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hpa.fun.toy_+3A_x">x</code></td>
<td>
<p>Vector of length 19 that specifies the correlation scales</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Elements 1-4 of x specify the sigmas for each of the four levels in
the toy example.  Elements 5-7 specify the correlation scales for
level 1, elements 8-10 the scales for level 2, and so on.
</p>
<p>Internal function <code>pdm.maker()</code> shows how the B matrix is
obtained from the various elements of input argument <code>x</code>.  Note
how, in this simple example, the B matrices are diagonal, but
generalizing to non-diagonal matrices should be straightforward (if
you can guarantee that they remain positive definite).
</p>


<h3>Value</h3>

<table>
<tr><td><code>sigmas</code></td>
<td>
<p>The four sigmas corresponding to the four levels</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>The four B matrices corresponding to the four levels</p>
</td></tr>
<tr><td><code>rhos</code></td>
<td>
<p>The three (sic) matrices corresponding to levels 1-3</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>

<p>M. C. Kennedy and A. O'Hagan 2000. &ldquo;Predicting the output from
a complex computer code when fast approximations are available&rdquo;
Biometrika, 87(1): pp1-13
</p>


<h3>Examples</h3>

<pre><code class='language-R'>hpa.fun.toy(1:19)
</code></pre>

<hr>
<h2 id='is.consistent'>Checks observational data for consistency with a subsets object</h2><span id='topic+is.consistent'></span>

<h3>Description</h3>

<p>Checks observational data for consistency with a subsets object: the
length of the vectors should match
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.consistent(subsets, z)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.consistent_+3A_subsets">subsets</code></td>
<td>
<p>A subsets object</p>
</td></tr>
<tr><td><code id="is.consistent_+3A_z">z</code></td>
<td>
<p>Data</p>
</td></tr>    
</table>


<h3>Value</h3>

<p>Returns <code>TRUE</code> or <code>FALSE</code> depending on whether z is consistent
with subsets.
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>

<p>M. C. Kennedy and A. O'Hagan 2000. &ldquo;Predicting the output from
a complex computer code when fast approximations are available&rdquo;
Biometrika, 87(1): pp1-13
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.nested">is.nested</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toyapps)
stopifnot(is.consistent(subsets.toy,z.toy))

z.toy[[4]] &lt;- 1:6
is.consistent(subsets.toy,z.toy)
</code></pre>

<hr>
<h2 id='mdash.fun'>Mean of Gaussian process</h2><span id='topic+mdash.fun'></span>

<h3>Description</h3>

<p>Returns the mean of the Gaussian process conditional on the observations
and the hyperparameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mdash.fun(x, D1, subsets, hpa, Vinv = NULL, use.Vinv = TRUE, z, basis)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mdash.fun_+3A_x">x</code></td>
<td>
<p>Point at which mean is desired</p>
</td></tr>
<tr><td><code id="mdash.fun_+3A_d1">D1</code></td>
<td>
<p>Code design matrix for level 1 code</p>
</td></tr>
<tr><td><code id="mdash.fun_+3A_subsets">subsets</code></td>
<td>
<p>subsets object</p>
</td></tr>
<tr><td><code id="mdash.fun_+3A_hpa">hpa</code></td>
<td>
<p>Hyperparameter object</p>
</td></tr>
<tr><td><code id="mdash.fun_+3A_vinv">Vinv</code></td>
<td>
<p>Inverse of the variance matrix; if <code>NULL</code>, the
function will calculate it</p>
</td></tr>
<tr><td><code id="mdash.fun_+3A_use.vinv">use.Vinv</code></td>
<td>
<p>Boolean, with default <code>TRUE</code> meaning to use the
inverse of V and <code>FALSE</code> meaning to use a method that does not
involve inverting V</p>
</td></tr>
<tr><td><code id="mdash.fun_+3A_z">z</code></td>
<td>
<p>observations</p>
</td></tr>
<tr><td><code id="mdash.fun_+3A_basis">basis</code></td>
<td>
<p>Basis functions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>

<p>M. C. Kennedy and A. O'Hagan 2000. &ldquo;Predicting the output from
a complex computer code when fast approximations are available&rdquo;
Biometrika, 87(1): pp1-13
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toyapps)
mdash.fun(x=1:3,D1=D1.toy,subsets=subsets.toy,hpa=hpa.toy,z=z.toy,basis=basis.toy)

uu &lt;- rbind(1:3,1,3:1,1:3)
rownames(uu) &lt;- c("first","second","third","fourth")

mdash.fun(x=uu,D1=D1.toy,subsets=subsets.toy,hpa=hpa.toy,z=z.toy,basis=basis.toy)

</code></pre>

<hr>
<h2 id='object'>Optimization of posterior likelihood of hyperparameters</h2><span id='topic+object'></span><span id='topic+opt.1'></span><span id='topic+opt.gt.1'></span>

<h3>Description</h3>

<p>Returns the likelihood of a set of hyperparameters given the data.
Functions <code>opt1()</code> and <code>opt.gt.1()</code> find hyperparameters
that maximize the relevant likelihood for level 1 and higher levels
respectively.   Function <code>object()</code> returns the expression given
by equation 9 in KOH2000, which is minimized <code>opt1()</code> and
<code>opt.gt.1()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>object(level, D, z, basis, subsets, hpa)
opt.1(D, z, basis, subsets, hpa.start, give.answers=FALSE, ...)
opt.gt.1(level, D, z, basis, subsets, hpa.start, give.answers=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="object_+3A_level">level</code></td>
<td>
<p>level</p>
</td></tr>
<tr><td><code id="object_+3A_d">D</code></td>
<td>
<p>Design matrix for top-level code</p>
</td></tr>
<tr><td><code id="object_+3A_z">z</code></td>
<td>
<p>Data</p>
</td></tr>
<tr><td><code id="object_+3A_basis">basis</code></td>
<td>
<p>Basis function</p>
</td></tr>
<tr><td><code id="object_+3A_subsets">subsets</code></td>
<td>
<p>subsets object</p>
</td></tr>
<tr><td><code id="object_+3A_hpa">hpa</code></td>
<td>
<p>hyperparameter object</p>
</td></tr>
<tr><td><code id="object_+3A_hpa.start">hpa.start</code></td>
<td>
<p>Starting value for hyperparameter object</p>
</td></tr>
<tr><td><code id="object_+3A_give.answers">give.answers</code></td>
<td>
<p>Boolean, with default <code>FALSE</code> meaning to
return just the point estimate, and <code>TRUE</code> meaning to return
extra information from the call  to <code>optim()</code></p>
</td></tr>
<tr><td><code id="object_+3A_...">...</code></td>
<td>
<p>Extra arguments passed to <code>optim()</code>.  A common one
would be <code>control=list(trace=100)</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is the object function used in toy optimizers
<code>optimal.hpa()</code>. 
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>

<p>M. C. Kennedy and A. O'Hagan 2000. &ldquo;Predicting the output from
a complex computer code when fast approximations are available&rdquo;
Biometrika, 87(1): pp1-13
</p>


<h3>See Also</h3>

<p><code><a href="#topic+genie">genie</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toyapps)
object(level=4, D=D1.toy , z=z.toy,basis=basis.toy,
   subsets=subsets.toy, hpa=hpa.fun.toy(1:19))
object(level=4, D=D1.toy , z=z.toy,basis=basis.toy,
   subsets=subsets.toy, hpa=hpa.fun.toy(3+(1:19)))


# Now a little example of finding optimal hyperpameters in the toy case
# (a bigger example is given on the genie help page)
jj &lt;- list(trace=100,maxit=10)

hpa.toy.level1 &lt;- opt.1(D=D1.toy, z=z.toy, basis=basis.toy,
          subsets=subsets.toy, hpa.start=hpa.toy,control=jj)

hpa.toy.level2 &lt;- opt.gt.1(level=2, D=D1.toy, z=z.toy,
           basis=basis.toy, subsets=subsets.toy,
           hpa.start=hpa.toy.level1, control=jj)

hpa.toy.level3 &lt;- opt.gt.1(level=3, D=D1.toy, z=z.toy,
           basis=basis.toy, subsets=subsets.toy,
           hpa.start=hpa.toy.level2, control=jj) 

hpa.toy.level4 &lt;- opt.gt.1(level=4, D=D1.toy, z=z.toy,
           basis=basis.toy, subsets=subsets.toy,
           hpa.start=hpa.toy.level3, control=jj)

</code></pre>

<hr>
<h2 id='Pi'>Kennedy's Pi notation</h2><span id='topic+Pi'></span>

<h3>Description</h3>

<p>Evaluates Kennedy's <code class="reqn">\prod</code> product
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Pi(hpa, i, j)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Pi_+3A_hpa">hpa</code></td>
<td>
<p>Hyperparameter object</p>
</td></tr>
<tr><td><code id="Pi_+3A_i">i</code></td>
<td>
<p>subscript</p>
</td></tr>
<tr><td><code id="Pi_+3A_j">j</code></td>
<td>
<p>superscript</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function evaluates Kennedy's <code class="reqn">\prod</code> product, but with the
additional feature that <code class="reqn">\prod_i^j=0</code> if <code class="reqn">i&gt;j+1</code>.
This seems to work in practice.
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>

<p>M. C. Kennedy and A. O'Hagan 2000. &ldquo;Predicting the output from
a complex computer code when fast approximations are available&rdquo;
Biometrika, 87(1): pp1-13
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toyapps)
Pi(hpa.toy,1,2)
Pi(hpa.toy,2,2)
Pi(hpa.toy,3,2)
Pi(hpa.toy,4,2)
</code></pre>

<hr>
<h2 id='subset_maker'>Create a simple subset object</h2><span id='topic+subset_maker'></span>

<h3>Description</h3>

<p>Given an integer vector whose <code class="reqn">i^\mathrm{th}</code> element is the
number of runs at level <code class="reqn">i</code>, return a subset object in echelon
form. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>subset_maker(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subset_maker_+3A_x">x</code></td>
<td>
<p>A vector of integers</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In this context, <code>x</code> being in &ldquo;echelon form&rdquo; means that
</p>

<ul>
<li> <p><code>x</code> is consistent in the sense of passing
<code>is.consistent()</code>
</p>
</li>
<li><p> For each <code class="reqn">i</code>, <code>x[[i]] = 1:n</code> for some <code class="reqn">n</code>.
</p>
</li></ul>
  


<h3>Value</h3>

<p>A list object suitable for use as a <code>subset</code> object
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.consistent">is.consistent</a></code>, <code><a href="#topic+is.nested">is.nested</a></code>, <code><a href="#topic+is.strict">is.strict</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>subset_maker(c(10,4,3))


is.nested(subset_maker(c(4,9,6))) #should be FALSE
is.nested(subset_maker(c(9,6,4))) #should be TRUE

</code></pre>

<hr>
<h2 id='subsets.fun'>Generate and test subsets</h2><span id='topic+is.nested'></span><span id='topic+is.strict'></span><span id='topic+subsets.fun'></span>

<h3>Description</h3>

<p>Create a list of subsets (<code>subsets.fun()</code>); or, 
given a list of subsets, test for correct inclusion
(<code>is.nested()</code>), or strict inclusion (<code>is.strict()</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.nested(subsets)
is.strict(subsets)
subsets.fun(n, levels = 4, prob = 0.7)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subsets.fun_+3A_subsets">subsets</code></td>
<td>
<p>In <code>is.nested()</code>, a list of subsets to be tested</p>
</td></tr>
<tr><td><code id="subsets.fun_+3A_n">n</code></td>
<td>
<p>Number of observations in the lowest level (ie level 1, the fastest
code)</p>
</td></tr>
<tr><td><code id="subsets.fun_+3A_levels">levels</code></td>
<td>
<p>Number of levels</p>
</td></tr>
<tr><td><code id="subsets.fun_+3A_prob">prob</code></td>
<td>
<p>Probability of choosing an observation at level
<code class="reqn">n+1</code> given that there is one at the same place at level <code class="reqn">n</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin (<code>subsets.fun()</code>); Peter Dalgaard (via R-help)</p>


<h3>References</h3>

<p>M. C. Kennedy and A. O'Hagan 2000. &ldquo;Predicting the output from
a complex computer code when fast approximations are available&rdquo;
Biometrika, 87(1): pp1-13
</p>


<h3>Examples</h3>

<pre><code class='language-R'>is.nested(subsets.fun(20))  # Should be TRUE

data(toyapps)
stopifnot(is.nested(subsets.toy))
</code></pre>

<hr>
<h2 id='tee.fun'>Returns generalized distances</h2><span id='topic+tee.fun'></span>

<h3>Description</h3>

<p>Returns generalized distances from a point to the design matrix as per
equation 10
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tee.fun(x, D1, subsets, hpa)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tee.fun_+3A_x">x</code></td>
<td>
<p>Point in parameter space</p>
</td></tr>
<tr><td><code id="tee.fun_+3A_d1">D1</code></td>
<td>
<p>Design matrix for level 1 code</p>
</td></tr>
<tr><td><code id="tee.fun_+3A_subsets">subsets</code></td>
<td>
<p>subsets object</p>
</td></tr>
<tr><td><code id="tee.fun_+3A_hpa">hpa</code></td>
<td>
<p>Hyperparameter object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See equation 10
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>

<p>M. C. Kennedy and A. O'Hagan 2000. &ldquo;Predicting the output from
a complex computer code when fast approximations are available&rdquo;
Biometrika, 87(1): pp1-13
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(toyapps)
tee.fun(x=1:3, D1=D1.toy, subsets=subsets.toy, hpa=hpa.toy)
</code></pre>

<hr>
<h2 id='toyapps'>Toy datasets for approximator package</h2><span id='topic+D1.toy'></span><span id='topic+hpa.toy'></span><span id='topic+z.toy'></span><span id='topic+subsets.toy'></span><span id='topic+betas.toy'></span>

<h3>Description</h3>

<p>Toy datasets that illustrate the package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  data(toyapps)
</code></pre>


<h3>Format</h3>

<p>The toy example is a case with four levels.
</p>
<p>The <code>D1.toy</code> matrix is 20 rows of code run points, corresponding
to the observations of the level 1 code.  It has three columns, one
per parameter.
</p>
<p><code>hpa.toy</code> is a hyperparameter object.  It is a list of three
elements: <code>sigmas</code>, <code>B</code>, and <code>rhos</code>.
</p>
<p><code>subsets.toy</code> is a list of four elements.  Element <code class="reqn">i</code>
corresponds to the rows of <code>D1.toy</code> at which level <code class="reqn">i</code> has
been observed.
</p>
<p><code>z.toy</code> is a four element list.  Each element is a vector;
element <code class="reqn">i</code> corresponds to obsevations of level <code class="reqn">i</code>.  The
lengths will match those of <code>subsets.toy</code>.
</p>
<p><code>betas.toy</code> is a matrix of coefficients.
</p>
<p><strong>Brief description of toy functions fully documented under their own manpage</strong>
</p>
<p>Function <code>generate.toy.observations()</code> creates new toy datasets
with any number of observations and code runs.
</p>
<p>Function <code>basis.toy()</code> is an example of a basis function
</p>
<p>Function <code>hpa.fun.toy()</code> creates a hyperparameter object such as
<code>phi.toy</code> in a form suitable for passing to the other functions
in the library.
</p>
<p><strong>See the helpfiles listed in the &ldquo;see also&rdquo; section
below</strong>
</p>


<h3>Details</h3>

<p>All toy datasets are documented here.  There are also several toy
functions that are needed for a toy problem; these are documented
separately (they are too diverse to document fully in a single
manpage).  Nevertheless a terse summary  for each toy function
is provided on this page.  All toy functions in the package are listed
under &ldquo;See Also&rdquo;.
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>

<p>M. C. Kennedy and A. O'Hagan 2000. &ldquo;Predicting the output from
a complex computer code when fast approximations are available&rdquo;
Biometrika, 87(1): pp1-13
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toyapps)

is.consistent(subsets.toy , z.toy)

generate.toy.observations(D1.toy, subsets.toy, basis.toy, hpa.toy, betas.toy)

</code></pre>

<hr>
<h2 id='V.fun.app'>Variance matrix</h2><span id='topic+V.fun.app'></span>

<h3>Description</h3>

<p>Given a design matrix, a subsets object and a hyperparameter object,
return the variance matrix.  The &ldquo;app&rdquo; of the function name means
&ldquo;approximator&rdquo;, to distinguish it from function <code>V.fun()</code>
of the calibrator package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>V.fun.app(D1, subsets, hpa)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="V.fun.app_+3A_d1">D1</code></td>
<td>
<p>Design matrix for level 1 code</p>
</td></tr>
<tr><td><code id="V.fun.app_+3A_subsets">subsets</code></td>
<td>
<p>Subsets object</p>
</td></tr>
<tr><td><code id="V.fun.app_+3A_hpa">hpa</code></td>
<td>
<p>Hyperparameter object</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>

<p>M. C. Kennedy and A. O'Hagan 2000. &ldquo;Predicting the output from
a complex computer code when fast approximations are available&rdquo;
Biometrika, 87(1): pp1-13
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toyapps)
V.fun.app(D1.toy,subsets.toy,hpa.toy)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
