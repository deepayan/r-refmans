<!DOCTYPE html><html><head><title>Help for package logistf</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {logistf}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#add1.logistf'><p>Add or Drop All Possible Single Terms to/from a <code>logistf</code> Model</p></a></li>
<li><a href='#anova.logistf'><p>Analysis of Penalized Deviance for <code>logistf</code> Models</p></a></li>
<li><a href='#backward'><p>Backward Elimination/Forward Selection of Model Terms in logistf Models</p></a></li>
<li><a href='#CLIP.confint'><p>Confidence Intervals after Multiple Imputation: Combination of Likelihood Profiles</p></a></li>
<li><a href='#CLIP.profile'><p>Combine Profile Likelihoods from Imputed-Data Model Fits</p></a></li>
<li><a href='#emmeans-logistf'><p>Emmeans support for logistf</p></a></li>
<li><a href='#flac'><p>FLAC - Firth's logistic regression with added covariate</p></a></li>
<li><a href='#flic'><p>FLIC - Firth's logistic regression with intercept correction</p></a></li>
<li><a href='#logistf'><p>Firth's Bias-Reduced Logistic Regression</p></a></li>
<li><a href='#logistf-package'><p>Firth's Bias-Reduced Logistic Regression</p></a></li>
<li><a href='#logistf.control'><p>Control Parameters for <code>logistf</code></p></a></li>
<li><a href='#logistf.mod.control'><p>Controls additional parameters for <code>logistf</code></p></a></li>
<li><a href='#logistftest'><p>Penalized likelihood ratio test</p></a></li>
<li><a href='#logistpl.control'><p>Control Parameters for logistf Profile Likelihood Confidence Interval Estimation</p></a></li>
<li><a href='#plot.logistf.profile'><p><code>plot</code> Method for <code>logistf</code> Likelihood Profiles</p></a></li>
<li><a href='#predict.flac'><p>Predict Method for flac Fits</p></a></li>
<li><a href='#predict.flic'><p>Predict Method for flic Fits</p></a></li>
<li><a href='#predict.logistf'><p>Predict Method for logistf Fits</p></a></li>
<li><a href='#profile.logistf'><p>Compute Profile Penalized Likelihood</p></a></li>
<li><a href='#PVR.confint'><p>Pseudo Variance Modification of Rubin's Rule</p></a></li>
<li><a href='#sex2'><p>Urinary Tract Infection in American College Students</p></a></li>
<li><a href='#sexagg'><p>Urinary Tract Infection in American College Students</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.26.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-08-18</td>
</tr>
<tr>
<td>Title:</td>
<td>Firth's Bias-Reduced Logistic Regression</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>mice, mgcv, formula.tools, Matrix</td>
</tr>
<tr>
<td>Suggests:</td>
<td>emmeans (&ge; 1.4), estimability</td>
</tr>
<tr>
<td>Description:</td>
<td>Fit a logistic regression model using Firth's bias reduction method, equivalent to penalization of the log-likelihood by the Jeffreys 
	prior. Confidence intervals for regression coefficients can be computed by penalized profile likelihood. Firth's method was proposed as ideal
	solution to the problem of separation in logistic regression, see Heinze and Schemper (2002) &lt;<a href="https://doi.org/10.1002%2Fsim.1047">doi:10.1002/sim.1047</a>&gt;. If needed, the bias reduction can be turned off such that ordinary
	maximum likelihood logistic regression is obtained. Two new modifications of Firth's method, FLIC and FLAC, lead to unbiased predictions and are now available
	in the package as well, see Puhr et al (2017) &lt;<a href="https://doi.org/10.1002%2Fsim.7273">doi:10.1002/sim.7273</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://cemsiis.meduniwien.ac.at/en/kb/science-research/software/statistical-software/firth-correction/">https://cemsiis.meduniwien.ac.at/en/kb/science-research/software/statistical-software/firth-correction/</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.2</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/georgheinze/logistf/issues/">https://github.com/georgheinze/logistf/issues/</a></td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-18 08:05:42 UTC; Gregor</td>
</tr>
<tr>
<td>Author:</td>
<td>Georg Heinze [aut, cre],
  Meinhard Ploner [aut],
  Daniela Dunkler [ctb],
  Harry Southworth [ctb],
  Lena Jiricka [aut],
  Gregor Steiner [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Georg Heinze &lt;georg.heinze@meduniwien.ac.at&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-18 09:52:33 UTC</td>
</tr>
</table>
<hr>
<h2 id='add1.logistf'>Add or Drop All Possible Single Terms to/from a <code>logistf</code> Model</h2><span id='topic+add1.logistf'></span>

<h3>Description</h3>

<p>Compute all the single terms in the scope argument that can be added to or dropped
from the model, fit those models and compute a table of the changes in fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'logistf'
add1(object, scope, data, test = "PLR", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add1.logistf_+3A_object">object</code></td>
<td>
<p>A fitted <code>logistf, flic</code> or <code>flac</code> object</p>
</td></tr>
<tr><td><code id="add1.logistf_+3A_scope">scope</code></td>
<td>
<p>The scope of variables considered for adding or dropping. Should be a
vector of variable names. Can be left missing; the method will then use all variables
in the object's data slot which are not identified as the response variable.</p>
</td></tr>
<tr><td><code id="add1.logistf_+3A_data">data</code></td>
<td>
<p>The data frame used to fit the object.</p>
</td></tr>
<tr><td><code id="add1.logistf_+3A_test">test</code></td>
<td>
<p>The type of test statistic. Currently, only the PLR test (penalized likelihood
ratio test) is allowed for logistf fits.</p>
</td></tr>
<tr><td><code id="add1.logistf_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>drop1</code> and <code>add1</code> generate a table where for each variable the penalized
likelihood ratio chi-squared, the degrees of freedom, and the p-value for dropping/adding this variable are given.
</p>


<h3>Value</h3>

<p>A matrix with <code>nvar</code> rows and 3 columns (Chisquared, degrees of freedom, p-value).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sex2) 
fit&lt;-logistf(data=sex2, case~1, pl=FALSE) 
add1(fit, scope=c("dia", "age"), data=sex2)
 
fit2&lt;-logistf(data=sex2, case~age+oc+dia+vic+vicl+vis) 
drop1(fit2, data=sex2)

</code></pre>

<hr>
<h2 id='anova.logistf'>Analysis of Penalized Deviance for <code>logistf</code> Models</h2><span id='topic+anova.logistf'></span>

<h3>Description</h3>

<p>This method compares hierarchical and non-hierarchical logistf models using
penalized likelhood ratio tests. It replaces the function logistftest of former
versions of logistf.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'logistf'
anova(object, fit2, formula, method = "nested", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anova.logistf_+3A_object">object</code></td>
<td>
<p>A fitted <code>logistf</code> model object</p>
</td></tr>
<tr><td><code id="anova.logistf_+3A_fit2">fit2</code></td>
<td>
<p>Another fitted <code>logistf</code> model object, to be compared with <code>object</code></p>
</td></tr>
<tr><td><code id="anova.logistf_+3A_formula">formula</code></td>
<td>
<p>Alternatively to <code>fit2</code>, a formula which specifies terms to omit from the object model fit.</p>
</td></tr>
<tr><td><code id="anova.logistf_+3A_method">method</code></td>
<td>
<p>One of c(&quot;nested&quot;,&quot;PLR&quot;). nested is the default for hierarchically nested
models, and will compare the penalized likelihood ratio statistics (minus twice
the difference between maximized penalized log likelihood and null penalized
log likelihood), where the null penalized log likelihood is computed from the
same, hierarchically superior model. Note that unlike in maximum likelihood
analysis, the null penalized likelihood depends on the penalty (Jeffreys prior)
which itself depends on the scope of variables of the hierarchically superior
model. PLR compares the difference in penalized likelihood ratio between the
two models, where for each model the null penalized likelihood is computed
within the scope of variables in that model. For PLR, the models need not be
hierarchically nested.</p>
</td></tr>
<tr><td><code id="anova.logistf_+3A_...">...</code></td>
<td>
<p>Further arguments passed to the method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Comparing models fitted by penalized methods, one must consider that the penalized likelihoods
are not directly comparable, since a penalty is involved. Or in other words, inserting zero for
some regression coefficients will not lead to the same penalized likelihood as if the corresponding
variables are simply &quot;unknown&quot; to a model. The anova method takes care that the same penalty is
used for two hierarchically nested models, and if the models are not hierarchically nested, it will
first relate each penalized likelihood to its null penalized likelihood, and only compare the resulting
penalized likelihod ratio statistics. The chi-squared approximation for this latter method (PLR) is
considered less accurate than that of the nested method. Nevertheless, it is the only way to go for
comparison of non-nested models.
</p>


<h3>Value</h3>

<p>An object of class <code>anova.logistf</code> with items
</p>
<table>
<tr><td><code>chisq</code></td>
<td>
<p>the chisquared statistic for the model comparison</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>The degrees of freedom</p>
</td></tr>
<tr><td><code>pval</code></td>
<td>
<p>The p-value</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The function call</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>The method of comparison (input)</p>
</td></tr>
<tr><td><code>model1</code></td>
<td>
<p>The first model</p>
</td></tr>
<tr><td><code>model2</code></td>
<td>
<p>The second model which was compared to the first model</p>
</td></tr>
<tr><td><code>PLR1</code></td>
<td>
<p>The PLR statistic of the first model</p>
</td></tr>
<tr><td><code>PLR2</code></td>
<td>
<p>the PLR statistic of the second model; for the nested method, this will be the drop in chi-squared due to setting the coefficients to zero</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(sex2) 
fit&lt;-logistf(data=sex2, case~age+oc+dia+vic+vicl+vis)

#simultaneous test of variables vic, vicl, vis:
anova(fit, formula=~vic+vicl+vis)

#test versus a simpler model
fit2&lt;-logistf(data=sex2, case~age+oc+dia)
# or: fit2&lt;-update(fit, case~age+oc+dia)
anova(fit,fit2)

# comparison of non-nested models (with different df):
fit3&lt;-logistf(data=sex2, case~age+vic+vicl+vis)
anova(fit2,fit3, method="PLR")


</code></pre>

<hr>
<h2 id='backward'>Backward Elimination/Forward Selection of Model Terms in logistf Models</h2><span id='topic+backward'></span><span id='topic+backward.logistf'></span><span id='topic+backward.flic'></span><span id='topic+forward'></span><span id='topic+forward.logistf'></span>

<h3>Description</h3>

<p>These functions provide simple backward elimination/forward selection procedures for logistf models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>backward(object, ...)

## S3 method for class 'logistf'
backward(
  object,
  scope,
  data,
  steps = 1000,
  slstay = 0.05,
  trace = TRUE,
  printwork = FALSE,
  full.penalty = FALSE,
  ...
)

## S3 method for class 'flic'
backward(
  object,
  scope,
  steps = 1000,
  slstay = 0.05,
  trace = TRUE,
  printwork = FALSE,
  full.penalty = FALSE,
  ...
)

forward(object, ...)

## S3 method for class 'logistf'
forward(
  object,
  scope,
  data,
  steps = 1000,
  slentry = 0.05,
  trace = TRUE,
  printwork = FALSE,
  pl = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="backward_+3A_object">object</code></td>
<td>
<p>A fitted logistf model object. To start with an empty model, create a model fit
with a formula= y~1, pl=FALSE. (Replace y by your response variable.)</p>
</td></tr>
<tr><td><code id="backward_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to methods.</p>
</td></tr>
<tr><td><code id="backward_+3A_scope">scope</code></td>
<td>
<p>The scope of variables to add/drop from the model. Can be missing for backward, backward will use
the terms of the object fit. Alternatively, an arbitrary vector of variable names can be given, to allow
that only some of the variables will be competitively selected or dropped. Has to be provided for forward.</p>
</td></tr>
<tr><td><code id="backward_+3A_data">data</code></td>
<td>
<p>The data frame used to fit the object.</p>
</td></tr>
<tr><td><code id="backward_+3A_steps">steps</code></td>
<td>
<p>The number of forward selection/backward elimination steps.</p>
</td></tr>
<tr><td><code id="backward_+3A_slstay">slstay</code></td>
<td>
<p>For <code>backward</code>, the significance level to stay in the model.</p>
</td></tr>
<tr><td><code id="backward_+3A_trace">trace</code></td>
<td>
<p>If <code>TRUE</code>, protocols selection steps.</p>
</td></tr>
<tr><td><code id="backward_+3A_printwork">printwork</code></td>
<td>
<p>If <code>TRUE</code>, prints each working model that is visited by the selection procedure.</p>
</td></tr>
<tr><td><code id="backward_+3A_full.penalty">full.penalty</code></td>
<td>
<p>If <code>TRUE</code> penalty is not taken from current model but from start model.</p>
</td></tr>
<tr><td><code id="backward_+3A_slentry">slentry</code></td>
<td>
<p>For <code>forward</code>, the significance level to enter the model.</p>
</td></tr>
<tr><td><code id="backward_+3A_pl">pl</code></td>
<td>
<p>For forward, computes profile likelihood confidence intervals for the final model if <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The variable selection is simply performed by repeatedly calling add1 or drop1 methods for logistf,
and is based on penalized likelihood ratio test.
</p>
<p>Note that selecting among factor variables is not supported.
One way to use forward or backward with factor variables is to first convert them
into numeric variables (0/1 coded dummy variables, choosing a sensible reference category).
Forward and backward will then perform selection on the dummy variables,
meaning that it will collapse levels of a factor variable with similar outcomes.
</p>


<h3>Value</h3>

<p>An updated <code>logistf, flic</code> or <code>flac</code> fit with the finally selected model.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>forward()</code>: Forward Selection
</p>
</li></ul>


<h3>Examples</h3>

<pre><code class='language-R'>data(sex2) 
fit&lt;-logistf(data=sex2, case~1, pl=FALSE) 
fitf&lt;-forward(fit, scope=c("dia", "age"), data=sex2) 

fit2&lt;-logistf(data=sex2, case~age+oc+vic+vicl+vis+dia) 
fitb&lt;-backward(fit2, data=sex2)

</code></pre>

<hr>
<h2 id='CLIP.confint'>Confidence Intervals after Multiple Imputation: Combination of Likelihood Profiles</h2><span id='topic+CLIP.confint'></span>

<h3>Description</h3>

<p>This function implements the new combination of likelihood profiles (CLIP) method described in
Heinze, Ploner and Beyea (2013). This method is useful for computing confidence intervals for
parameters after multiple imputation of data sets, if the normality assumption on parameter estimates and consequently the validity of applying Rubin's rules (pooling of variances) is in doubt. It
consists of combining the profile likelihoods into a posterior. The function CLIP.confint searches
for those values of a regression coefficient, at which the cumulative distribution function of the
posterior is equal to the values specified in the argument ci.level (usually 0.025 and 0.975). The
search is performed using R's optimize function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CLIP.confint(
  obj = NULL,
  variable = NULL,
  data,
  firth = TRUE,
  weightvar = NULL,
  control = logistf.control(),
  ci.level = c(0.025, 0.975),
  pvalue = TRUE,
  offset = NULL,
  bound.lo = NULL,
  bound.up = NULL,
  legacy = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CLIP.confint_+3A_obj">obj</code></td>
<td>
<p>Either a list of logistf fits (on multiple imputed data sets), or the result of analysis of a <code>mice</code> (multiply imputed) object using <code>with.mids</code></p>
</td></tr>
<tr><td><code id="CLIP.confint_+3A_variable">variable</code></td>
<td>
<p>The variable of interest, for which confidence intervals should be computed. If missing, confidence intervals for all variables will be computed.</p>
</td></tr>
<tr><td><code id="CLIP.confint_+3A_data">data</code></td>
<td>
<p>A list of data set corresponding to the model fits. Can be left blank if obj was obtained with the <code>dataout=TRUE</code> option or if obj was obtained by mice</p>
</td></tr>
<tr><td><code id="CLIP.confint_+3A_firth">firth</code></td>
<td>
<p>If <code>TRUE</code>, applies the Firth correction. Should correspond to the entry in obj.</p>
</td></tr>
<tr><td><code id="CLIP.confint_+3A_weightvar">weightvar</code></td>
<td>
<p>An optional weighting variable for each observation.</p>
</td></tr>
<tr><td><code id="CLIP.confint_+3A_control">control</code></td>
<td>
<p>Control parameters for <code>logistf</code>, usually obtained by <code>logistf.control()</code></p>
</td></tr>
<tr><td><code id="CLIP.confint_+3A_ci.level">ci.level</code></td>
<td>
<p>The two confidence levels for each tail of the posterior distribution.</p>
</td></tr>
<tr><td><code id="CLIP.confint_+3A_pvalue">pvalue</code></td>
<td>
<p>If <code>TRUE</code>, will also compute a P-value from the posterior.</p>
</td></tr>
<tr><td><code id="CLIP.confint_+3A_offset">offset</code></td>
<td>
<p>An optional offset variable</p>
</td></tr>
<tr><td><code id="CLIP.confint_+3A_bound.lo">bound.lo</code></td>
<td>
<p>Bounds (vector of length 2) for the lower limit. Can be left blank. Use only if problems are encountered.</p>
</td></tr>
<tr><td><code id="CLIP.confint_+3A_bound.up">bound.up</code></td>
<td>
<p>Bounds (vector of length 2) for the upper limit. Can be left blank. Use only if problems are encountered.</p>
</td></tr>
<tr><td><code id="CLIP.confint_+3A_legacy">legacy</code></td>
<td>
<p>If <code>TRUE</code>, will use pure R code for all model fitting. Can be slow. Not recommended.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each confidence limit, this function performs a binary search to evaluate the combined posterior,
which is obtained by first transforming the imputed-data likelihood profiles into cumulative distribution functions (CDFs), and then averaging the CDFs to obtain the CDF of the posterior. Usually,
the binary search manages to find the confidence intervals very quickly. The number of iterations
(mean and maximum) will be supplied in the output object. Further details on the method can be
found in Heinze, Ploner and Beyea (2013).
</p>


<h3>Value</h3>

<p>An object of class <code>CLIP.confint</code>, with items:
</p>
<table>
<tr><td><code>variable</code></td>
<td>
<p>The variable(s) which were analyzed</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>The pooled estimate (average over imputations)</p>
</td></tr>
<tr><td><code>ci</code></td>
<td>
<p>The confidence interval(s)</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p>The p-value(s)</p>
</td></tr>
<tr><td><code>imputations</code></td>
<td>
<p>The number of imputed datasets</p>
</td></tr>
<tr><td><code>ci.level</code></td>
<td>
<p>The confidence level (input)</p>
</td></tr>
<tr><td><code>bound.lo</code></td>
<td>
<p>The bounds used for finding the lower confidence limit; usually not of interest. May be useful for error-tracing.</p>
</td></tr>
<tr><td><code>bound.up</code></td>
<td>
<p>The bounds used for finding the upper confidence limit</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>The number of iterations (for each variable and each tail)</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The call object</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Georg Heinze and Meinhard Ploner
</p>


<h3>References</h3>

<p>Heinze G, Ploner M, Beyea J (2013). Confidence intervals after multiple imputation: combining
profile likelihood information from logistic regressions. Statistics in Medicine, to appear.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+logistf">logistf()</a></code> for Firth's bias-Reduced penalized-likelihood logistic regression.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#generate data set with NAs 
freq=c(5,2,2,7,5,4)
y&lt;-c(rep(1,freq[1]+freq[2]), rep(0,freq[3]+freq[4]), rep(1,freq[5]), rep(0,freq[6]))
x&lt;-c(rep(1,freq[1]), rep(0,freq[2]), rep(1,freq[3]), rep(0,freq[4]), 
rep(NA,freq[5]),rep(NA,freq[6]))
toy&lt;-data.frame(x=x,y=y)

# impute data set 5 times
set.seed(169)
toymi&lt;-list(0)
for(i in 1:5){
  toymi[[i]]&lt;-toy
  y1&lt;-toymi[[i]]$y==1 &amp; is.na(toymi[[i]]$x)
  y0&lt;-toymi[[i]]$y==0 &amp; is.na(toymi[[i]]$x) 
  xnew1&lt;-rbinom(sum(y1),1,freq[1]/(freq[1]+freq[2]))
  xnew0&lt;-rbinom(sum(y0),1,freq[3]/(freq[3]+freq[4]))
  toymi[[i]]$x[y1==TRUE]&lt;-xnew1
  toymi[[i]]$x[y0==TRUE]&lt;-xnew0
  }
  
 # logistf analyses of each imputed data set
 fit.list&lt;-lapply(1:5, function(X) logistf(data=toymi[[X]], y~x, pl=TRUE))
  
 # CLIP confidence limits
 CLIP.confint(obj=fit.list, data = toymi)
 
</code></pre>

<hr>
<h2 id='CLIP.profile'>Combine Profile Likelihoods from Imputed-Data Model Fits</h2><span id='topic+CLIP.profile'></span>

<h3>Description</h3>

<p>This function uses CLIP (combination of likelihood profiles)
to compute the pooled profile of the posterior after multiple imputation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CLIP.profile(
  obj = NULL,
  variable,
  data,
  which,
  firth = TRUE,
  weightvar,
  control = logistf.control(),
  offset = NULL,
  from = NULL,
  to = NULL,
  steps = 101,
  legacy = FALSE,
  keep = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CLIP.profile_+3A_obj">obj</code></td>
<td>
<p>Either a list of logistf fits (on multiple imputed data sets), or the result
of analysis of a <code>mice</code> (multiply imputed) object using <code>with.mids</code>.</p>
</td></tr>
<tr><td><code id="CLIP.profile_+3A_variable">variable</code></td>
<td>
<p>The variable of interest, for which confidence intervals should be computed.
If missing, confidence intervals for all variables will be computed.</p>
</td></tr>
<tr><td><code id="CLIP.profile_+3A_data">data</code></td>
<td>
<p>A list of data set corresponding to the model fits. Can be left blank if obj was
obtained with the dataout=TRUE option or if obj was obtained by mice.</p>
</td></tr>
<tr><td><code id="CLIP.profile_+3A_which">which</code></td>
<td>
<p>Alternatively to variable, the argument which allows to specify the variable to
compute the profile for as righthand formula, e.g. which=~X.</p>
</td></tr>
<tr><td><code id="CLIP.profile_+3A_firth">firth</code></td>
<td>
<p>If <code>TRUE</code>, applies the Firth correction. Should correspond to the entry in obj.</p>
</td></tr>
<tr><td><code id="CLIP.profile_+3A_weightvar">weightvar</code></td>
<td>
<p>An optional weighting variable for each observation</p>
</td></tr>
<tr><td><code id="CLIP.profile_+3A_control">control</code></td>
<td>
<p>control parameters for <code>logistf</code>, usually obtained by <code>logistf.control()</code></p>
</td></tr>
<tr><td><code id="CLIP.profile_+3A_offset">offset</code></td>
<td>
<p>An optional offset variable</p>
</td></tr>
<tr><td><code id="CLIP.profile_+3A_from">from</code></td>
<td>
<p>Lowest value for the sequence of values for the regression coefficients for which the profile will be computed. Can be left blank.</p>
</td></tr>
<tr><td><code id="CLIP.profile_+3A_to">to</code></td>
<td>
<p>Highest value for the sequence of values for the regression coefficients for which the profile will be computed. Can be left blank</p>
</td></tr>
<tr><td><code id="CLIP.profile_+3A_steps">steps</code></td>
<td>
<p>Number of steps for the sequence of values for the regression coefficients for which the profile will be computed</p>
</td></tr>
<tr><td><code id="CLIP.profile_+3A_legacy">legacy</code></td>
<td>
<p>If <code>TRUE</code>, only R code will be used. Should be avoided.</p>
</td></tr>
<tr><td><code id="CLIP.profile_+3A_keep">keep</code></td>
<td>
<p>If <code>TRUE</code>, keeps the profiles for each imputed data sets in the output object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>While CLIP.confint iterates to find those values at which the CDF of the
pooled posterior equals the confidence levels, CLIP.profile will evaluate
the whole profile, which enables plotting and evaluating the skewness of the combined and the completed-data profiles. The combined and completeddata profiles are available as cumulative distribution function (CDF) or in the scaling of relative
profile likelihood (minus twice the likelihood ratio statistic compared to the maximum). Using a
plot method, the pooled posterior can also be displayed as a density.
</p>


<h3>Value</h3>

<p>An object of class <code>CLIP.profile</code> with items:
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>The values of the regression coefficient</p>
</td></tr>
<tr><td><code>cdf</code></td>
<td>
<p>The cumulative distribution function of the posterior</p>
</td></tr>
<tr><td><code>profile</code></td>
<td>
<p>The profile of the posterior</p>
</td></tr>
<tr><td><code>cdf.matrix</code></td>
<td>
<p>An imputations x steps matrix with the values of the completed-data CDFs for each beta</p>
</td></tr>
<tr><td><code>profile.matrix</code></td>
<td>
<p>An imputations x steps matrix with the values of the completed-data profiles for each beta</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The function call</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Georg Heinze und Meinhard Plonar
</p>


<h3>References</h3>

<p>Heinze G, Ploner M, Beyea J (2013). Confidence intervals after multiple imputation: combining profile
likelihood information from logistic regressions. Statistics in Medicine, to appear.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#generate data set with NAs 
freq=c(5,2,2,7,5,4)
y&lt;-c(rep(1,freq[1]+freq[2]), rep(0,freq[3]+freq[4]), rep(1,freq[5]), rep(0,freq[6]))
x&lt;-c(rep(1,freq[1]), rep(0,freq[2]), rep(1,freq[3]), rep(0,freq[4]), rep(NA,freq[5]),
rep(NA,freq[6]))
toy&lt;-data.frame(x=x,y=y)

# impute data set 5 times
set.seed(169)
toymi&lt;-list(0)
for(i in 1:5){
  toymi[[i]]&lt;-toy
  y1&lt;-toymi[[i]]$y==1 &amp; is.na(toymi[[i]]$x)
  y0&lt;-toymi[[i]]$y==0 &amp; is.na(toymi[[i]]$x)
  xnew1&lt;-rbinom(sum(y1),1,freq[1]/(freq[1]+freq[2]))
  xnew0&lt;-rbinom(sum(y0),1,freq[3]/(freq[3]+freq[4]))
  toymi[[i]]$x[y1==TRUE]&lt;-xnew1
  toymi[[i]]$x[y0==TRUE]&lt;-xnew0
}

# logistf analyses of each imputed data set
fit.list&lt;-lapply(1:5, function(X) logistf(data=toymi[[X]], y~x, pl=TRUE))

# CLIP profile
xprof&lt;-CLIP.profile(obj=fit.list, variable="x",data =toymi, keep=TRUE)
plot(xprof)

#plot as CDF
plot(xprof, "cdf")

#plot as density
plot(xprof, "density")

</code></pre>

<hr>
<h2 id='emmeans-logistf'>Emmeans support for logistf</h2><span id='topic+emmeans-logistf'></span>

<h3>Description</h3>

<p>Support for the <code>emmeans</code> package is available. See below for an example of using <code>emmeans::emmeans()</code> with a <code>logistf</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(sex2)
fit&lt;-logistf(case ~ age+oc+vic+vicl+vis+dia, data=sex2)

emmeans::emmeans(fit, ~age+dia)

</code></pre>

<hr>
<h2 id='flac'>FLAC - Firth's logistic regression with added covariate</h2><span id='topic+flac'></span><span id='topic+flac.default'></span><span id='topic+flac.logistf'></span>

<h3>Description</h3>

<p><code>flac</code> implements Firth's bias-reduced penalized-likelihood logistic regression with added covariate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flac(...)

## Default S3 method:
flac(
  formula,
  data,
  model = TRUE,
  control,
  modcontrol,
  weights,
  offset,
  na.action,
  pl = TRUE,
  plconf = NULL,
  ...
)

## S3 method for class 'logistf'
flac(lfobject, data, model = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="flac_+3A_...">...</code></td>
<td>
<p>Further arguments passed to the method or <code><a href="#topic+logistf">logistf</a></code>-call.</p>
</td></tr>
<tr><td><code id="flac_+3A_formula">formula</code></td>
<td>
<p>A formula object, with the response on the left of the operator,
and the model terms on the right. The response must be a vector with 0 and 1 or <code>FALSE</code> and
<code>TRUE</code> for the outcome, where the higher value (1 or <code>TRUE</code>) is modeled.</p>
</td></tr>
<tr><td><code id="flac_+3A_data">data</code></td>
<td>
<p>A data frame containing the variables in the model.</p>
</td></tr>
<tr><td><code id="flac_+3A_model">model</code></td>
<td>
<p>If TRUE the corresponding components of the fit are returned.</p>
</td></tr>
<tr><td><code id="flac_+3A_control">control</code></td>
<td>
<p>Controls iteration parameter. Taken from <code>logistf</code>-object when specified. Otherwise default is <code>control= logistf.control()</code>.</p>
</td></tr>
<tr><td><code id="flac_+3A_modcontrol">modcontrol</code></td>
<td>
<p>Controls additional parameter for fitting. Taken from <code>logistf</code>-object when specified. Otherwise default is <code>logistf.mod.control()</code>.</p>
</td></tr>
<tr><td><code id="flac_+3A_weights">weights</code></td>
<td>
<p>specifies case weights. Each line of the input data set is multiplied
by the corresponding element of weights</p>
</td></tr>
<tr><td><code id="flac_+3A_offset">offset</code></td>
<td>
<p>a priori known component to be included in the linear predictor</p>
</td></tr>
<tr><td><code id="flac_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data contain NAs</p>
</td></tr>
<tr><td><code id="flac_+3A_pl">pl</code></td>
<td>
<p>Specifies if confidence intervals and tests should be based on the profile
penalized log likelihood (<code>pl=TRUE</code>, the default) or on the Wald method (<code>pl=FALSE</code>).</p>
</td></tr>
<tr><td><code id="flac_+3A_plconf">plconf</code></td>
<td>
<p>specifies the variables (as vector of their indices) for which profile likelihood
confidence intervals should be computed. Default is to compute for all variables.</p>
</td></tr>
<tr><td><code id="flac_+3A_lfobject">lfobject</code></td>
<td>
<p>A fitted <code><a href="#topic+logistf">logistf</a></code> object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>FLAC is a simple modification of Firth's logistic regression which provides average predicted
probabilities equal to the observed proportion of events, while preserving the ability to deal
with separation. It has been described by Puhr et al (2017).
</p>
<p>The modified score equations to estimate coefficients for Firth's logistic regression can be
interpreted as score equations for ML estimates for an augmented data set. This data set can be
created by complementing each original observation i with two pseudo-observations weighted by
<code class="reqn">h_i/2</code> with unchanged covariate values and with response values set to <code class="reqn">y=0</code> and <code class="reqn">y=1</code>
respectively. The basic idea of FLAC is to discriminate between original and pseudo-observations
in the alternative formulation of Firth's estimation as an iterative data augmentation procedure.
The following generic methods are available for ' <code>flac</code>'s output object: <code>print, summary, coef, confint, anova, extractAIC, add1, drop1, 
profile, terms, nobs, predict</code>. Furthermore, forward and backward functions perform convenient variable selection. Note
that anova, extractAIC, add1, drop1, forward and backward are based on penalized likelihood
ratio tests.
</p>


<h3>Value</h3>

<p>A <code>flac</code> object with components:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>The coefficients of the parameter in the fitted model.</p>
</td></tr>
<tr><td><code>predict</code></td>
<td>
<p>A vector with the predicted probability of each observation</p>
</td></tr>
<tr><td><code>linear.predictors</code></td>
<td>
<p>A vector with the linear predictor of each observation.</p>
</td></tr>
<tr><td><code>prob</code></td>
<td>
<p>The p-values of the specific parameters</p>
</td></tr>
<tr><td><code>ci.lower</code></td>
<td>
<p>The lower confidence limits of the parameter.</p>
</td></tr>
<tr><td><code>ci.upper</code></td>
<td>
<p>The upper confidence limits of the parameter.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The call object.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The significance level: 0.95</p>
</td></tr>
<tr><td><code>var</code></td>
<td>
<p>The variance-covariance-matrix of the parameters.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>A vector of the (penalized) log-likelihood of the restricted and the full models.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>The number of observations.</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>The formula object.</p>
</td></tr>
<tr><td><code>augmented.data</code></td>
<td>
<p>The augmented dataset used</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>The number of degrees of freedom in the model.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>depending on the fitting method 'Penalized ML' or <code style="white-space: pre;">&#8288;Standard ML'.} \item{method.ci}{the method in calculating the confidence intervals, i.e. &#8288;</code>profile likelihood' or &lsquo;Wald&rsquo;, depending on the argument pl and plconf.</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>a copy of the control parameters.</p>
</td></tr>
<tr><td><code>modcontrol</code></td>
<td>
<p>a copy of the modcontrol parameters.</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>the model terms (column names of design matrix).</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>if requested (the default), the model frame used.</p>
</td></tr>
</table>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>flac(default)</code>: With formula and data
</p>
</li>
<li> <p><code>flac(logistf)</code>: With logistf object
</p>
</li></ul>


<h3>References</h3>

<p>Puhr R, Heinze G, Nold M, Lusa L, Geroldinger A (2017). Firth's logistic regression with rare events:
accurate effect estimates and predictions? Statistics in Medicine 36: 2302-2317.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+logistf">logistf()</a></code> for Firth's bias-Reduced penalized-likelihood logistic regression.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#With formula and data:
data(sex2)
flac(case ~ age + oc + vic + vicl + vis + dia, sex2)

#With a logistf object:
lf &lt;- logistf(formula = case ~ age + oc + vic + vicl + vis + dia, data = sex2)
flac(lf, data=sex2)

</code></pre>

<hr>
<h2 id='flic'>FLIC - Firth's logistic regression with intercept correction</h2><span id='topic+flic'></span><span id='topic+flic.default'></span><span id='topic+flic.logistf'></span>

<h3>Description</h3>

<p><code>flic</code> implements Firth's bias-reduced penalized-likelihood logistic regression with intercept correction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flic(...)

## Default S3 method:
flic(
  formula,
  data,
  model = TRUE,
  control,
  modcontrol,
  weights,
  offset,
  na.action,
  ...
)

## S3 method for class 'logistf'
flic(lfobject, model = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="flic_+3A_...">...</code></td>
<td>
<p>Further arguments passed to the method or <code><a href="#topic+logistf">logistf</a></code>-call.</p>
</td></tr>
<tr><td><code id="flic_+3A_formula">formula</code></td>
<td>
<p>A formula object, with the response on the left of the operator,
and the model terms on the right. The response must be a vector with 0 and 1 or <code>FALSE</code> and
<code>TRUE</code> for the outcome, where the higher value (1 or <code>TRUE</code>) is modeled.</p>
</td></tr>
<tr><td><code id="flic_+3A_data">data</code></td>
<td>
<p>If using with formula, a data frame containing the variables in the model.</p>
</td></tr>
<tr><td><code id="flic_+3A_model">model</code></td>
<td>
<p>If TRUE the corresponding components of the fit are returned.</p>
</td></tr>
<tr><td><code id="flic_+3A_control">control</code></td>
<td>
<p>Controls iteration parameter. Taken from <code>logistf</code>-object when specified. Otherwise default is <code>control= logistf.control()</code>.</p>
</td></tr>
<tr><td><code id="flic_+3A_modcontrol">modcontrol</code></td>
<td>
<p>Controls additional parameter for fitting. Taken from <code>logistf</code>-object when specified. Otherwise default is <code>logistf.mod.control()</code>.</p>
</td></tr>
<tr><td><code id="flic_+3A_weights">weights</code></td>
<td>
<p>specifies case weights. Each line of the input data set is multiplied
by the corresponding element of weights</p>
</td></tr>
<tr><td><code id="flic_+3A_offset">offset</code></td>
<td>
<p>a priori known component to be included in the linear predictor</p>
</td></tr>
<tr><td><code id="flic_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data contain NAs</p>
</td></tr>
<tr><td><code id="flic_+3A_lfobject">lfobject</code></td>
<td>
<p>A fitted <code><a href="#topic+logistf">logistf</a></code> object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>FLIC is a simple modification of Firth's logistic regression which provides average predicted
probabilities equal to the observed proportion of events, while preserving the ability to deal
with separation.
</p>
<p>In general the average predicted probability in Firth's logistic regression is not equal to the observed
proportion of events. Because the determinant of the Fisher-Information matrix is maximized
for <code class="reqn">\pi_i = \frac{1}{2}</code> it is concluded that Firth's penalization tends to push the
predicted probabilities towards one-half compared with ML-estimation.
FLIC first applies Firth's logistic regression and then corrects the intercept such that the predicted probabilities become unbiased while keeping
all other coefficients constant.
The following generic methods are available for <code>flic</code>'s output object: <code>print, summary, coef, confint, anova, extractAIC, add1, drop1, 
profile, terms, nobs, predict</code>. Furthermore, forward and backward functions perform convenient variable selection. Note
that anova, extractAIC, add1, drop1, forward and backward are based on penalized likelihood
ratio tests.
</p>


<h3>Value</h3>

<p>A <code>flic</code> object with components:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>The coefficients of the parameter in the fitted model.</p>
</td></tr>
<tr><td><code>predict</code></td>
<td>
<p>A vector with the predicted probability of each observation.</p>
</td></tr>
<tr><td><code>linear.predictors</code></td>
<td>
<p>A vector with the linear predictor of each observation.</p>
</td></tr>
<tr><td><code>var</code></td>
<td>
<p>The variance-covariance-matrix of the parameters.</p>
</td></tr>
<tr><td><code>prob</code></td>
<td>
<p>The p-values of the specific parameters.</p>
</td></tr>
<tr><td><code>ci.lower</code></td>
<td>
<p>The lower confidence limits of the parameter.</p>
</td></tr>
<tr><td><code>ci.upper</code></td>
<td>
<p>The upper confidence limits of the parameter.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The call object.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The significance level: 0.95.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>depending on the fitting method 'Penalized ML' or <code style="white-space: pre;">&#8288;Standard ML'.} \item{method.ci}{the method in calculating the confidence intervals, i.e. &#8288;</code>profile likelihood' or &lsquo;Wald&rsquo;, depending on the argument pl and plconf.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>The number of degrees of freedom in the model.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>A vector of the (penalized) log-likelihood of the restricted and the full models.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>The number of observations.</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>The formula object.</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>a copy of the control parameters.</p>
</td></tr>
<tr><td><code>modcontrol</code></td>
<td>
<p>a copy of the modcontrol parameters.</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>the model terms (column names of design matrix).</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>if requested (the default), the model frame used.</p>
</td></tr>
</table>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>flic(default)</code>: With formula and data
</p>
</li>
<li> <p><code>flic(logistf)</code>: With logistf object
</p>
</li></ul>


<h3>References</h3>

<p>Puhr R, Heinze G, Nold M, Lusa L, Geroldinger A (2017). Firth's logistic regression with rare events:
accurate effect estimates and predictions? Statistics in Medicine 36: 2302-2317.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+logistf">logistf</a></code> for Firth's bias-Reduced penalized-likelihood logistic regression.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#With formula and data:
data(sex2)
flic(case ~ age + oc + vic + vicl + vis + dia, sex2)

#With a logistf object:
lf &lt;- logistf(formula = case ~ age + oc + vic + vicl + vis + dia, data = sex2)
flic(lf)

</code></pre>

<hr>
<h2 id='logistf'>Firth's Bias-Reduced Logistic Regression</h2><span id='topic+logistf'></span>

<h3>Description</h3>

<p>Implements Firth's bias-Reduced penalized-likelihood logistic regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logistf(
  formula,
  data,
  pl = TRUE,
  alpha = 0.05,
  control,
  plcontrol,
  modcontrol,
  firth = TRUE,
  init,
  weights,
  na.action,
  offset,
  plconf = NULL,
  flic = FALSE,
  model = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logistf_+3A_formula">formula</code></td>
<td>
<p>A formula object, with the response on the left of the operator,
and the model terms on the right. The response must be a vector with 0 and 1 or <code>FALSE</code> and
<code>TRUE</code> for the outcome, where the higher value (1 or <code>TRUE</code>) is modeled. It is
possible to include contrasts, interactions, nested effects, cubic or polynomial
splines and all S features as well, e.g. Y ~ X1*X2 + ns(X3, df=4).</p>
</td></tr>
<tr><td><code id="logistf_+3A_data">data</code></td>
<td>
<p>A data.frame where the variables named in the formula can be found,
i. e. the variables containing the binary response and the covariates.</p>
</td></tr>
<tr><td><code id="logistf_+3A_pl">pl</code></td>
<td>
<p>Specifies if confidence intervals and tests should be based on the profile
penalized log likelihood (<code>pl=TRUE</code>, the default) or on the Wald method (<code>pl=FALSE</code>).</p>
</td></tr>
<tr><td><code id="logistf_+3A_alpha">alpha</code></td>
<td>
<p>The significance level (1-<code class="reqn">\alpha</code> the confidence level, 0.05 as default).</p>
</td></tr>
<tr><td><code id="logistf_+3A_control">control</code></td>
<td>
<p>Controls iteration parameter. Default is <code>control= logistf.control()</code></p>
</td></tr>
<tr><td><code id="logistf_+3A_plcontrol">plcontrol</code></td>
<td>
<p>Controls Newton-Raphson iteration for the estimation of the profile
likelihood confidence intervals. Default is <code>plcontrol= logistpl.control()</code></p>
</td></tr>
<tr><td><code id="logistf_+3A_modcontrol">modcontrol</code></td>
<td>
<p>Controls additional parameter for fitting. Default is <code>logistf.mod.control()</code></p>
</td></tr>
<tr><td><code id="logistf_+3A_firth">firth</code></td>
<td>
<p>Use of Firth's penalized maximum likelihood (<code>firth=TRUE</code>, default) or the
standard maximum likelihood method (<code>firth=FALSE</code>) for the logistic regression.
Note that by specifying <code>pl=TRUE</code> and <code>firth=FALSE</code> (and probably a lower number
of iterations) one obtains profile likelihood confidence intervals for maximum likelihood
logistic regression parameters.</p>
</td></tr>
<tr><td><code id="logistf_+3A_init">init</code></td>
<td>
<p>Specifies the initial values of the coefficients for the fitting algorithm</p>
</td></tr>
<tr><td><code id="logistf_+3A_weights">weights</code></td>
<td>
<p>specifies case weights. Each line of the input data set is multiplied
by the corresponding element of weights</p>
</td></tr>
<tr><td><code id="logistf_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data contain NAs</p>
</td></tr>
<tr><td><code id="logistf_+3A_offset">offset</code></td>
<td>
<p>a priori known component to be included in the linear predictor</p>
</td></tr>
<tr><td><code id="logistf_+3A_plconf">plconf</code></td>
<td>
<p>specifies the variables (as vector of their indices) for which profile likelihood
confidence intervals should be computed. Default is to compute for all variables.</p>
</td></tr>
<tr><td><code id="logistf_+3A_flic">flic</code></td>
<td>
<p>If <code>TRUE</code>, intercept is altered such that the predicted probabilities become unbiased while
keeping all other coefficients constant (see Puhr et al, 2017)</p>
</td></tr>
<tr><td><code id="logistf_+3A_model">model</code></td>
<td>
<p>If TRUE the corresponding components of the fit are returned.</p>
</td></tr>
<tr><td><code id="logistf_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to <code>logistf</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>logistf</code> is the main function of the package. It fits a logistic regression
model applying Firth's correction to the likelihood. The following generic methods are available for logistf's output
object: <code>print, summary, coef, vcov, confint, anova, extractAIC, add1, drop1, 
profile, terms, nobs, predict</code>. Furthermore, forward and backward functions perform convenient variable selection. Note
that anova, extractAIC, add1, drop1, forward and backward are based on penalized likelihood
ratios.
</p>


<h3>Value</h3>

<p>The object returned is of the class <code>logistf</code> and has the following attributes:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>the coefficients of the parameter in the fitted model.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>the significance level (1- the confidence level) as specified in the input.</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>the column names of the design matrix</p>
</td></tr>
<tr><td><code>var</code></td>
<td>
<p>the variance-covariance-matrix of the parameters.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>the number of degrees of freedom in the model.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>a vector of the (penalized) log-likelihood of the restricted and the full models.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>A vector of the number of iterations needed in the fitting process for the null and full model.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>the number of observations.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>the response-vector, i. e. 1 for successes (events) and 0 for failures.</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>the formula object.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the call object.</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>the model terms (column names of design matrix).</p>
</td></tr>
<tr><td><code>linear.predictors</code></td>
<td>
<p> a vector with the linear predictor of each observation.</p>
</td></tr>
<tr><td><code>predict</code></td>
<td>
<p>a vector with the predicted probability of each observation.</p>
</td></tr>
<tr><td><code>hat.diag</code></td>
<td>
<p>a vector with the diagonal elements of the Hat Matrix.</p>
</td></tr>
<tr><td><code>conv</code></td>
<td>
<p>the convergence status at last iteration: a vector of length 3 with elements: last change in log likelihood, max(abs(score vector)), max change in beta at last iteration.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>depending on the fitting method 'Penalized ML' or <code style="white-space: pre;">&#8288;Standard ML'.} \item{method.ci}{the method in calculating the confidence intervals, i.e. &#8288;</code>profile likelihood' or &lsquo;Wald&rsquo;, depending on the argument pl and plconf.</p>
</td></tr>
<tr><td><code>ci.lower</code></td>
<td>
<p>the lower confidence limits of the parameter.</p>
</td></tr>
<tr><td><code>ci.upper</code></td>
<td>
<p>the upper confidence limits of the parameter.</p>
</td></tr>
<tr><td><code>prob</code></td>
<td>
<p> the p-values of the specific parameters.</p>
</td></tr>
<tr><td><code>pl.iter</code></td>
<td>
<p>only if pl==TRUE: the number of iterations needed for each confidence limit.</p>
</td></tr>
<tr><td><code>betahist</code></td>
<td>
<p>only if pl==TRUE: the complete history of beta estimates for each confidence limit.</p>
</td></tr>
<tr><td><code>pl.conv</code></td>
<td>
<p>only if pl==TRUE: the convergence status (deviation of log likelihood from target value, last maximum change in beta) for each confidence limit.</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>a copy of the control parameters.</p>
</td></tr>
<tr><td><code>modcontrol</code></td>
<td>
<p>a copy of the modcontrol parameters.</p>
</td></tr>
<tr><td><code>flic</code></td>
<td>
<p>logical, is TRUE  if intercept was altered such that the predicted probabilities become unbiased while
keeping all other coefficients constant. According to input of logistf.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>if requested (the default), the model frame used.</p>
</td></tr>
<tr><td><code>na.action</code></td>
<td>
<p>information returned by model.frame on the special handling of NAs</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Georg Heinze and Meinhard Ploner
</p>


<h3>References</h3>

<p>Firth D (1993). Bias reduction of maximum likelihood estimates. Biometrika 80, 27-38.
Heinze G, Schemper M (2002). A solution to the problem of separation in logistic regression.
Statistics in Medicine 21: 2409-2419.
</p>
<p>Heinze G, Ploner M (2003). Fixing the nonconvergence bug in logistic regression with SPLUS and
SAS. Computer Methods and Programs in Biomedicine 71: 181-187.
</p>
<p>Heinze G, Ploner M (2004). Technical Report 2/2004: A SAS-macro, S-PLUS library and R
package to perform logistic regression without convergence problems. Section of Clinical Biometrics, Department of Medical Computer Sciences, Medical University of Vienna, Vienna, Austria.
http://www.meduniwien.ac.at/user/georg.heinze/techreps/tr2_2004.pdf
</p>
<p>Heinze G (2006). A comparative investigation of methods for logistic regression with separated or
nearly separated data. Statistics in Medicine 25: 4216-4226.
</p>
<p>Puhr R, Heinze G, Nold M, Lusa L, Geroldinger A (2017). Firth's logistic regression with rare events:
accurate effect estimates and predictions? Statistics in Medicine 36: 2302-2317.
</p>
<p>Venzon DJ, Moolgavkar AH (1988). A method for computing profile-likelihood based confidence
intervals. Applied Statistics 37:87-94.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+add1.logistf">add1.logistf()</a></code>, <code><a href="#topic+anova.logistf">anova.logistf()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sex2)
fit&lt;-logistf(case ~ age+oc+vic+vicl+vis+dia, data=sex2)
summary(fit)
nobs(fit)
drop1(fit)
plot(profile(fit,variable="dia"))
extractAIC(fit)

fit1&lt;-update(fit, case ~ age+oc+vic+vicl+vis)
extractAIC(fit1)
anova(fit,fit1)

data(sexagg)
fit2&lt;-logistf(case ~ age+oc+vic+vicl+vis+dia, data=sexagg, weights=COUNT)
summary(fit2)

# simulated SNP example
set.seed(72341)
snpdata&lt;-rbind(
  matrix(rbinom(2000,2,runif(2000)*0.3),100,20),
  matrix(rbinom(2000,2,runif(2000)*0.5),100,20))
colnames(snpdata)&lt;-paste("SNP",1:20,"_",sep="")
snpdata&lt;-as.data.frame(snpdata)
snpdata$case&lt;-c(rep(0,100),rep(1,100))

fitsnp&lt;-logistf(data=snpdata, formula=case~1, pl=FALSE)
add1(fitsnp, scope=paste("SNP",1:20,"_",sep=""), data=snpdata)
fitf&lt;-forward(fitsnp, scope = paste("SNP",1:20,"_",sep=""), data=snpdata)
fitf

</code></pre>

<hr>
<h2 id='logistf-package'>Firth's Bias-Reduced Logistic Regression</h2><span id='topic+logistf-package'></span>

<h3>Description</h3>

<p>Fits a binary logistic regression model using Firth's bias reduction method, and its modifications FLIC and FLAC, which both ensure that the sum of the predicted
probabilities equals the number of events. If needed, the bias reduction can be turned off such that ordinary
maximum likelihood logistic regression is obtained.
</p>


<h3>Details</h3>

<p>The package logistf provides a comprehensive tool to facilitate the application of Firth's correction for
logistic regression analysis, including its modifications FLIC and FLAC.
</p>
<p>The call of the main function of the library follows the structure of the standard functions as lm or glm, requiring a data.frame and a
formula for the model specification.  The resulting object belongs to the new class logistf, which includes penalized maximum likelihood
(<code style="white-space: pre;">&#8288;Firth-Logistic'- or &#8288;</code>FL'-type) logistic regression parameters, standard errors, confidence limits, p-values, the value of the maximized
penalized log likelihood, the linear predictors, the number of iterations needed to arrive at the maximum and much more.  Furthermore,
specific methods for the resulting object are supplied. Additionally, a function to plot profiles of the penalized likelihood function and a
function to perform penalized likelihood ratio tests have been included.
</p>
<p>In explaining the details of the estimation process we follow mainly the description in Heinze &amp; Ploner (2003). In general, maximum likelihood
estimates are often prone to small sample bias. To reduce this bias, Firth (1993) suggested to maximize the penalized log likelihood
<code class="reqn">\log L(\beta)^* = \log L(\beta) + 1/2 \log |I(\beta)|</code>, where <code class="reqn">I(\beta)</code> is the
Fisher information matrix, i. e. minus the second derivative of the log likelihood. Applying this idea to logistic regression, the score
function <code class="reqn">U(\beta)</code> is replaced by the modified score function
<code class="reqn">U(\beta)^* = U(\beta) + a</code>, where <code class="reqn">a</code> has <code class="reqn">r</code>th entry
<code class="reqn">a_r = 0.5tr{I(\beta)^{-1} [dI(\beta)/d\beta_r]}, r = 1,...,k</code>.
Heinze and Schemper (2002) give the explicit formulae for <code class="reqn">I(\beta)</code>
and <code class="reqn">I(\beta)/d \beta_r</code>.
</p>
<p>In our programs estimation of <code class="reqn">\beta</code> can be based on a Newton-Raphson
algorithm or on iteratively reweighted least squares. Parameter values are initialized usually with 0, but in
general the user can specify arbitrary starting values.
</p>
<p>With a starting value of <code class="reqn">\beta^{(0)}</code>, the penalized maximum
likelihood estimate <code class="reqn">\beta</code> is obtained iteratively via Newton-Raphson:
</p>
<p style="text-align: center;"><code class="reqn">\beta^{(s+1)}= \beta^{(s)} + I(\beta^{(s)})^{-1} U(\beta^{(s)})^* </code>
</p>

<p>If the penalized log likelihood evaluated at <code class="reqn">\beta^{(s+1)}</code> is less
than that evaluated at <code class="reqn">\beta^{(s)}</code> , then (<code class="reqn">\beta^{(s+1)}</code> is
recomputed by step-halving. For each entry <code class="reqn">r</code> of <code class="reqn">\beta</code> with
<code class="reqn">r = 1,...,k</code> the absolute step size <code class="reqn">|\beta_r^{(s+1)}-\beta_r^s|</code>
is restricted to a maximal allowed value <code>maxstep</code>. These two means should avoid
numerical problems during estimation. The iterative process is continued
until the parameter estimates converge, i. e., until three criteria are met: the change in log likelihood is less than <code>lconv</code>,
the maximum absolute element of the score vector is less than <code>gconv</code>, the maximum absolute change in beta is less than <code>xconv</code>.
<code>lconv, gconv, xconv</code> can be controlled by <code>control=logistf.control(lconv=...,</code>
<code>gconv=..., xconv=...)</code>.
</p>
<p>Computation of profile penalized likelihood confidence intervals for
parameters (<code>logistpl</code>) follows the algorithm of Venzon and
Moolgavkar (1988). For testing the hypothesis of <code class="reqn">\gamma =
\gamma_0</code>, let the likelihood ratio statistic
</p>
<p style="text-align: center;"><code class="reqn">LR = 2 [ \log L(\gamma, \delta) - \log L(\gamma_0,\delta_{\gamma_0})^*]</code>
</p>

<p>where <code class="reqn">(\gamma, \delta)</code>  is the joint penalized maximum likelihood estimate of <code class="reqn">\beta=
(\gamma,\delta)</code>, and <code class="reqn">\delta_{\gamma_0}</code> is the penalized maximum
likelihood estimate of <code class="reqn">\delta</code> when  <code class="reqn">\gamma= \gamma_0</code>. The
profile penalized likelihood confidence interval is the continuous set
of values <code class="reqn">\gamma_0</code> for which <code class="reqn">LR</code> does not exceed the <code class="reqn">(1 - \alpha)100</code>th
percentile of the <code class="reqn">\chi^2_1</code>-distribution. The
confidence limits can therefore be found iteratively by approximating
the penalized log likelihood function in a neighborhood of <code class="reqn">\beta</code> by
the quadratic function
</p>
<p style="text-align: center;"><code class="reqn"> l(\beta+\delta) = l(\beta) + \delta'U^* - 0.5 \delta' I \delta </code>
</p>

<p>where <code class="reqn">U^* = U(\beta)^*</code> and <code class="reqn">-I = -I(\beta)</code>.
</p>
<p>In some situations computation of profile penalized likelihood
confidence intervals may be time consuming since the iterative procedure
outlined above has to be repeated for the lower and for the upper
confidence limits of each of the k parameters. In other problems one may
not be interested in interval estimation, anyway. In such cases, the
user can request computation of Wald confidence intervals and P-values,
which are based on the normal approximation of the parameter estimates
and do not need any iterative estimation process. Note that from version 1.24.1 on, the variance-covariance matrix
is based on the second derivative of the likelihood of the augmented data rather than the original data, which proved to be a better approximation if
the user chooses to set a higher value for <code class="reqn">\tau</code>, the penalty strength.
</p>
<p>The adequacy of Wald confidence intervals for
parameter estimates can be verified by plotting the profile penalized
log likelihood (PPL) function. A symmetric shape of the PPL function
allows use of Wald intervals, while an asymmetric shape demands profile
penalized likelihood intervals (<cite>Heinze &amp; Schemper (2002)</cite>).  Further documentation
can be found in <cite>Heinze &amp; Ploner (2004)</cite>.
</p>
<p>The package includes functions to work with multiply imputed data sets, such as generated by the <code><a href="mice.html#topic+mice">mice</a></code> package.
Results on individual fits can be pooled to obtain point and interval estimates, as well as profile likelihood confidence intervals and likelihood
profiles in general (Heinze, Ploner and Beyea, 2013).
</p>
<p>Moreover, in the package the modifications FLIC and FLAC have been implemented, which were described in Puhr et al (2017) as solutions to obtain
accurate predicted probabilities.
</p>


<h3>Author(s)</h3>

<p>Georg Heinze <a href="mailto:georg.heinze@meduniwien.ac.at">georg.heinze@meduniwien.ac.at</a>, Meinhard Ploner and Lena Jiricka.
</p>


<h3>References</h3>

<p>Firth D (1993). Bias reduction of maximum likelihood estimates. <em>Biometrika</em> 80, 27&ndash;38.
</p>
<p>Heinze G, Schemper M (2002). A solution to the problem of
separation in logistic regression. <em>Statistics in Medicine</em> 21: 2409-2419.
</p>
<p>Heinze G, Ploner M (2003). Fixing the nonconvergence bug in
logistic regression with SPLUS and SAS. <em>Computer Methods and Programs in Biomedicine</em> 71: 181-187.
</p>
<p>Heinze G, Ploner M (2004). Technical Report 2/2004: A SAS-macro, S-PLUS library and
R package to perform logistic regression without convergence problems. Section of Clinical Biometrics, Department of
Medical Computer Sciences, Medical University of Vienna, Vienna, Austria.
<a href="http://www.meduniwien.ac.at/user/georg.heinze/techreps/tr2_2004.pdf">http://www.meduniwien.ac.at/user/georg.heinze/techreps/tr2_2004.pdf</a>
</p>
<p>Heinze G (2006). A comparative investigation of methods for logistic regression
with separated or nearly separated data. <em>Statistics in Medicine</em> 25: 4216-4226.
</p>
<p>Heinze G, Ploner M, Beyea J (2013). Confidence intervals after multiple imputation: combining profile likelihood information from logistic regressions. <em>Statistics in Medicine</em> 32:5062-5076.
</p>
<p>Puhr R, Heinze G, Nold M, Lusa L, Geroldinger A (2017). Firth's logistic regression with rare events:
accurate effect estimates and predictions? <em>Statistics in Medicine</em> 36: 2302-2317.
</p>
<p>Venzon DJ, Moolgavkar AH (1988). A method for computing profile-likelihood
based confidence intervals. <em>Applied Statistics</em> 37:87-94.
</p>

<hr>
<h2 id='logistf.control'>Control Parameters for <code>logistf</code></h2><span id='topic+logistf.control'></span>

<h3>Description</h3>

<p>Sets parameters for iterations in Firth's penalized-likelihood logistic regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logistf.control(
  maxit = 25,
  maxhs = 0,
  maxstep = 5,
  lconv = 1e-05,
  gconv = 1e-05,
  xconv = 1e-05,
  collapse = TRUE,
  fit = "NR"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logistf.control_+3A_maxit">maxit</code></td>
<td>
<p>The maximum number of iterations</p>
</td></tr>
<tr><td><code id="logistf.control_+3A_maxhs">maxhs</code></td>
<td>
<p>The maximum number of step-halvings in one iteration. The increment of the
beta vector within one iteration is divided by 2 if the new beta leads to a decrease
in log likelihood.</p>
</td></tr>
<tr><td><code id="logistf.control_+3A_maxstep">maxstep</code></td>
<td>
<p>Specifies the maximum step size in the beta vector within one iteration. Set to -1 for infinite stepsize.</p>
</td></tr>
<tr><td><code id="logistf.control_+3A_lconv">lconv</code></td>
<td>
<p>Specifies the convergence criterion for the log likelihood.</p>
</td></tr>
<tr><td><code id="logistf.control_+3A_gconv">gconv</code></td>
<td>
<p>Specifies the convergence criterion for the first derivative of the log likelihood (the score vector).</p>
</td></tr>
<tr><td><code id="logistf.control_+3A_xconv">xconv</code></td>
<td>
<p>Specifies the convergence criterion for the parameter estimates.</p>
</td></tr>
<tr><td><code id="logistf.control_+3A_collapse">collapse</code></td>
<td>
<p>If <code>TRUE</code>, evaluates all unique combinations of x and y and collapses data set.</p>
</td></tr>
<tr><td><code id="logistf.control_+3A_fit">fit</code></td>
<td>
<p>Fitting method used. One of Newton-Raphson: &quot;NR&quot; or Iteratively reweighted least squares: &quot;IRLS&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>logistf.control()</code> is used by <code>logistf</code> and <code>logistftest</code> to set control parameters to default values.
Different values can be specified, e. g., by <code>logistf(..., control= logistf.control(maxstep=1))</code>.
</p>


<h3>Value</h3>

<table>
<tr><td><code>maxit</code></td>
<td>
<p>The maximum number of iterations</p>
</td></tr>
<tr><td><code>maxhs</code></td>
<td>
<p>The maximum number of step-halvings in one iteration. The increment of the
beta vector within one iteration is divided by 2 if the new beta leads to a decrease
in log likelihood.</p>
</td></tr>
<tr><td><code>maxstep</code></td>
<td>
<p>Specifies the maximum step size in the beta vector within one iteration.</p>
</td></tr>
<tr><td><code>lconv</code></td>
<td>
<p>Specifies the convergence criterion for the log likelihood.</p>
</td></tr>
<tr><td><code>gconv</code></td>
<td>
<p>Specifies the convergence criterion for the first derivative of the log likelihood (the score vector).</p>
</td></tr>
<tr><td><code>xconv</code></td>
<td>
<p>Specifies the convergence criterion for the parameter estimates.</p>
</td></tr>
<tr><td><code>collapse</code></td>
<td>
<p>If <code>TRUE</code>, evaluates all unique combinations of x and y and collapses data set.</p>
</td></tr>
<tr><td><code>fit</code></td>
<td>
<p>Fitting method used. One of Newton-Raphson: &quot;NR&quot; or Iteratively reweighted least squares: &quot;IRLS&quot;</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The function call.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(sexagg)
fit2&lt;-logistf(case ~ age+oc+vic+vicl+vis+dia, data=sexagg, weights=COUNT, 
control=logistf.control(maxstep=1))
summary(fit2)

</code></pre>

<hr>
<h2 id='logistf.mod.control'>Controls additional parameters for <code>logistf</code></h2><span id='topic+logistf.mod.control'></span>

<h3>Description</h3>

<p>Sets parameters for <code>logistf</code> calls.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logistf.mod.control(tau = 0.5, terms.fit = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logistf.mod.control_+3A_tau">tau</code></td>
<td>
<p>Penalization parameter (default = 0.5)</p>
</td></tr>
<tr><td><code id="logistf.mod.control_+3A_terms.fit">terms.fit</code></td>
<td>
<p>A numeric vector of terms to fit. Intercept has to be included if needed.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>tau</code></td>
<td>
<p>Penalization parameter (default = 0.5)</p>
</td></tr>
<tr><td><code>terms.fit</code></td>
<td>
<p>A numeric vector of terms to fit. Intercept has to be included if needed.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(sexagg)
fit2&lt;-logistf(case ~ age+oc+vic+vicl+vis+dia, data=sexagg, weights=COUNT, 
modcontrol=logistf.mod.control(terms.fit=c(1,2)))
summary(fit2)

</code></pre>

<hr>
<h2 id='logistftest'>Penalized likelihood ratio test</h2><span id='topic+logistftest'></span>

<h3>Description</h3>

<p>This function performs a penalized likelihood ratio test on some (or all) selected factors.
The resulting object is of the class logistftest and includes the information printed by the
proper print method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logistftest(
  object,
  test,
  values,
  firth = TRUE,
  beta0,
  weights,
  control,
  modcontrol,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logistftest_+3A_object">object</code></td>
<td>
<p>A fitted <code>logistf</code> object</p>
</td></tr>
<tr><td><code id="logistftest_+3A_test">test</code></td>
<td>
<p>righthand formula of parameters to test (e.g. ~ B + D - 1). As default
all parameter apart from the intercept are tested. If the formula includes -1, the
intercept is omitted from testing. As alternative to the formula one can give
the indexes of the ordered effects to test (a vector of integers). To test only the
intercept specify test = ~ - . or test = 1.</p>
</td></tr>
<tr><td><code id="logistftest_+3A_values">values</code></td>
<td>
<p>Null hypothesis values, default values are 0. For testing the specific hypothesis
B1=1, B4=2, B5=0 we specify test= ~B1+B4+B5-1 and values=c(1, 2,0).</p>
</td></tr>
<tr><td><code id="logistftest_+3A_firth">firth</code></td>
<td>
<p>Use of Firth's (1993) penalized maximum likelihood (firth=TRUE, default) or
the standard maximum likelihood method (firth=FALSE) for the logistic regression.
Note that by specifying pl=TRUE and firth=FALSE (and probably lower number of iterations)
one obtains profile likelihood confidence intervals for maximum likelihood logistic
regression parameters.</p>
</td></tr>
<tr><td><code id="logistftest_+3A_beta0">beta0</code></td>
<td>
<p>Specifies the initial values of the coefficients for the fitting algorithm</p>
</td></tr>
<tr><td><code id="logistftest_+3A_weights">weights</code></td>
<td>
<p>Case weights</p>
</td></tr>
<tr><td><code id="logistftest_+3A_control">control</code></td>
<td>
<p>Controls parameters for iterative fitting</p>
</td></tr>
<tr><td><code id="logistftest_+3A_modcontrol">modcontrol</code></td>
<td>
<p>Controls additional parameter for fitting. Default is <code>modcontrol</code> of <code>object</code>.</p>
</td></tr>
<tr><td><code id="logistftest_+3A_...">...</code></td>
<td>
<p>further arguments passed to logistf.fit</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs a penalized likelihood ratio test on some (or all) selected factors. The resulting object is of the class logistftest and includes the information printed by the proper print
method. Further documentation can be found in Heinze &amp; Ploner (2004).
In most cases, the functionality of the logistftest function is replaced by anova.logistf, which
is a more standard way to perform likelihood ratio tests. However, as shown in the example below, logistftest provides some specials such as testing against non-zero values. (By the way,
anova.logistf calls logistftest.
</p>


<h3>Value</h3>

<p>The object returned is of the class logistf and has the following attributes:
</p>
<table>
<tr><td><code>testcov</code></td>
<td>
<p>A vector of the fixed values of each covariate; NA stands for a parameter which is not tested.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>A vector of the (penalized) log-likelihood of the full and the restricted models. If
the argument beta0 not missing, the full model isn't evaluated</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>The number of degrees of freedom in the model</p>
</td></tr>
<tr><td><code>prob</code></td>
<td>
<p>The p-value of the test</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The call object</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Depending on the fitting method 'Penalized ML' or 'Standard ML'</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>The coefficients of the restricted solution</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Georg Heinze
</p>


<h3>References</h3>

<p>Firth D (1993). Bias reduction of maximum likelihood estimates. Biometrika 80, 27-38.
</p>
<p>Heinze G, Ploner M (2004). Technical Report 2/2004: A SAS-macro, S-PLUS library and R
package to perform logistic regression without convergence problems. Section of Clinical Biometrics, Department of Medical Computer Sciences, Medical University of Vienna, Vienna, Austria.
http://www.meduniwien.ac.at/user/georg.heinze/techreps/tr2_2004.pdf
</p>
<p>Heinze G (2006). A comparative investigation of methods for logistic regression with separated or
nearly separated data. Statistics in Medicine 25: 4216-4226
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sex2) 
fit&lt;-logistf(case ~ age+oc+vic+vicl+vis+dia, data=sex2)
logistftest(fit, test = ~ vic + vicl - 1, values = c(2, 0))


</code></pre>

<hr>
<h2 id='logistpl.control'>Control Parameters for logistf Profile Likelihood Confidence Interval Estimation</h2><span id='topic+logistpl.control'></span>

<h3>Description</h3>

<p>Sets parameters for modified Newton-Raphson iteration for finding
profile likelihood confidence intervals in Firth's penalized likelihood logistic regression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logistpl.control(
  maxit = 100,
  maxhs = 0,
  maxstep = 5,
  lconv = 1e-05,
  xconv = 1e-05,
  ortho = FALSE,
  pr = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logistpl.control_+3A_maxit">maxit</code></td>
<td>
<p>The maximum number of iterations</p>
</td></tr>
<tr><td><code id="logistpl.control_+3A_maxhs">maxhs</code></td>
<td>
<p>The maximum number of step-halvings in one iteration. The increment of the
beta vector within one iteration is divided by 2 if the new beta leads to a decrease
in log likelihood.</p>
</td></tr>
<tr><td><code id="logistpl.control_+3A_maxstep">maxstep</code></td>
<td>
<p>Specifies the maximum step size in the beta vector within one iteration. Set to -1 for infinite stepsize.</p>
</td></tr>
<tr><td><code id="logistpl.control_+3A_lconv">lconv</code></td>
<td>
<p>Specifies the convergence criterion for the log likelihood.</p>
</td></tr>
<tr><td><code id="logistpl.control_+3A_xconv">xconv</code></td>
<td>
<p>Specifies the convergence criterion for the parameter estimates.</p>
</td></tr>
<tr><td><code id="logistpl.control_+3A_ortho">ortho</code></td>
<td>
<p>Requests orthogonalization of variable for which confidence intervals are computed with respect to other covariates</p>
</td></tr>
<tr><td><code id="logistpl.control_+3A_pr">pr</code></td>
<td>
<p>Request rotation of the matrix spanned by the covariates</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>logistpl.control()</code> is used by <code>logistf</code> to set control parameters to default values
when computing profile likelihood confidence intervals.
Different values can be specified, e. g., by <code>logistf(..., control= logistf.control(maxstep=1))</code>.
</p>


<h3>Value</h3>

<table>
<tr><td><code>maxit</code></td>
<td>
<p>The maximum number of iterations</p>
</td></tr>
<tr><td><code>maxhs</code></td>
<td>
<p>The maximum number of step-halvings in one iteration. The increment of the
beta vector within one iteration is divided by 2 if the new beta leads to a decrease
in log likelihood.</p>
</td></tr>
<tr><td><code>maxstep</code></td>
<td>
<p>Specifies the maximum step size in the beta vector within one iteration.</p>
</td></tr>
<tr><td><code>lconv</code></td>
<td>
<p>Specifies the convergence criterion for the log likelihood.</p>
</td></tr>
<tr><td><code>xconv</code></td>
<td>
<p>Specifies the convergence criterion for the parameter estimates.</p>
</td></tr>
<tr><td><code>ortho</code></td>
<td>
<p>specifies if orthogonalization is requested.</p>
</td></tr>
<tr><td><code>pr</code></td>
<td>
<p>specifies if rotation is requested</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Georg Heinze
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sexagg)
fit2&lt;-logistf(case ~ age+oc+vic+vicl+vis+dia, data=sexagg, weights=COUNT, 
    plcontrol=logistpl.control(maxstep=1))
summary(fit2)

</code></pre>

<hr>
<h2 id='plot.logistf.profile'><code>plot</code> Method for <code>logistf</code> Likelihood Profiles</h2><span id='topic+plot.logistf.profile'></span>

<h3>Description</h3>

<p>Provides the plot method for objects created by <code>profile.logistf</code> or <code>CLIP.profile</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'logistf.profile'
plot(
  x,
  type = "profile",
  max1 = TRUE,
  colmain = "black",
  colimp = "gray",
  plotmain = T,
  ylim = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.logistf.profile_+3A_x">x</code></td>
<td>
<p>A <code>profile.logistf</code> object</p>
</td></tr>
<tr><td><code id="plot.logistf.profile_+3A_type">type</code></td>
<td>
<p>Type of plot: one of c(&quot;profile&quot;, &quot;cdf&quot;, &quot;density&quot;)</p>
</td></tr>
<tr><td><code id="plot.logistf.profile_+3A_max1">max1</code></td>
<td>
<p>If <code>type="density"</code>, normalizes density to maximum 1</p>
</td></tr>
<tr><td><code id="plot.logistf.profile_+3A_colmain">colmain</code></td>
<td>
<p>Color for main profile line</p>
</td></tr>
<tr><td><code id="plot.logistf.profile_+3A_colimp">colimp</code></td>
<td>
<p>color for completed-data profile lines (for <code>logistf.profile</code> objects that also
carry the <code>CLIP.profile</code> class attribute)</p>
</td></tr>
<tr><td><code id="plot.logistf.profile_+3A_plotmain">plotmain</code></td>
<td>
<p>if <code>FALSE</code>, suppresses the main profile line (for <code>logistf.profile</code> objects that
also carry the <code>CLIP.profile</code> class attribute)</p>
</td></tr>
<tr><td><code id="plot.logistf.profile_+3A_ylim">ylim</code></td>
<td>
<p>Limits for the y-axis</p>
</td></tr>
<tr><td><code id="plot.logistf.profile_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to <code>plot()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The plot method provides three types of plots (profile, CDF, and density representation of a profile
likelihood). For objects generated by CLIP.profile, it also allows to show the completed-data
profiles along with the pooled profile.
</p>


<h3>Value</h3>

<p>The function is called for its side effects
</p>


<h3>Author(s)</h3>

<p>Georg Heinze und Meinhard Ploner
</p>


<h3>References</h3>

<p>Heinze G, Ploner M, Beyea J (2013). Confidence intervals after multiple imputation: combining
profile likelihood information from logistic regressions. Statistics in Medicine, to appear.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(sex2) 
fit&lt;-logistf(case ~ age+oc+vic+vicl+vis+dia, data=sex2)
plot(profile(fit,variable="dia"))
plot(profile(fit,variable="dia"), "cdf")
plot(profile(fit,variable="dia"), "density")

#generate data set with NAs
freq=c(5,2,2,7,5,4)
y&lt;-c(rep(1,freq[1]+freq[2]), rep(0,freq[3]+freq[4]), rep(1,freq[5]), rep(0,freq[6]))
x&lt;-c(rep(1,freq[1]), rep(0,freq[2]), rep(1,freq[3]), rep(0,freq[4]), rep(NA,freq[5]),
   rep(NA,freq[6]))
toy&lt;-data.frame(x=x,y=y)

# impute data set 5 times
set.seed(169)
toymi&lt;-list(0)
for(i in 1:5){
   toymi[[i]]&lt;-toy
   y1&lt;-toymi[[i]]$y==1 &amp; is.na(toymi[[i]]$x)
   y0&lt;-toymi[[i]]$y==0 &amp; is.na(toymi[[i]]$x)
   xnew1&lt;-rbinom(sum(y1),1,freq[1]/(freq[1]+freq[2]))
   xnew0&lt;-rbinom(sum(y0),1,freq[3]/(freq[3]+freq[4]))
   toymi[[i]]$x[y1==TRUE]&lt;-xnew1
   toymi[[i]]$x[y0==TRUE]&lt;-xnew0
 }
 
# logistf analyses of each imputed data set
fit.list&lt;-lapply(1:5, function(X) logistf(data=toymi[[X]], y~x, pl=TRUE))

# CLIP profile 
xprof&lt;-CLIP.profile(obj=fit.list, variable="x", data=toymi, keep=TRUE)
plot(xprof)

#plot as CDF
plot(xprof, "cdf")

#plot as density
plot(xprof, "density")

</code></pre>

<hr>
<h2 id='predict.flac'>Predict Method for flac Fits</h2><span id='topic+predict.flac'></span>

<h3>Description</h3>

<p>Obtains predictions from a fitted <code>flac</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'flac'
predict(
  object,
  newdata,
  type = c("link", "response", "terms"),
  se.fit = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.flac_+3A_object">object</code></td>
<td>
<p>A fitted object of class <code>flac</code>.</p>
</td></tr>
<tr><td><code id="predict.flac_+3A_newdata">newdata</code></td>
<td>
<p>Optionally, a data frame in which to look for variables with which to predict. If omitted, the fitted linear predictors are used.</p>
</td></tr>
<tr><td><code id="predict.flac_+3A_type">type</code></td>
<td>
<p>The type of prediction required. The default is on the scale of the linear predictors.
The alternative <code>response</code> gives the predicted probabilities. Type <code>terms</code> returns a matrix with the fitted
values of each term in the formula on the linear predictor scale.</p>
</td></tr>
<tr><td><code id="predict.flac_+3A_se.fit">se.fit</code></td>
<td>
<p>If <code>TRUE</code>(default = <code>FALSE</code>) standard errors are computed.</p>
</td></tr>
<tr><td><code id="predict.flac_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>newdata</code> is omitted the predictions are based on the data used for the fit.
</p>


<h3>Value</h3>

<p>A vector or matrix of predictions.
</p>

<hr>
<h2 id='predict.flic'>Predict Method for flic Fits</h2><span id='topic+predict.flic'></span>

<h3>Description</h3>

<p>Obtains predictions from a fitted <code>flic</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'flic'
predict(
  object,
  newdata,
  type = c("link", "response", "terms"),
  se.fit = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.flic_+3A_object">object</code></td>
<td>
<p>A fitted object of class <code>flic</code>.</p>
</td></tr>
<tr><td><code id="predict.flic_+3A_newdata">newdata</code></td>
<td>
<p>Optionally, a data frame in which to look for variables with which to predict. If omitted, the fitted linear predictors are used.</p>
</td></tr>
<tr><td><code id="predict.flic_+3A_type">type</code></td>
<td>
<p>The type of prediction required. The default is on the scale of the linear predictors.
The alternative <code>response</code> gives the predicted probabilities. Type <code>terms</code> returns a matrix with the fitted
values of each term in the formula on the linear predictor scale.</p>
</td></tr>
<tr><td><code id="predict.flic_+3A_se.fit">se.fit</code></td>
<td>
<p>If <code>TRUE</code>(default = <code>FALSE</code>) standard errors are computed.</p>
</td></tr>
<tr><td><code id="predict.flic_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>newdata</code> is omitted the predictions are based on the data used for the fit.
</p>


<h3>Value</h3>

<p>A vector or matrix of predictions
</p>

<hr>
<h2 id='predict.logistf'>Predict Method for logistf Fits</h2><span id='topic+predict.logistf'></span>

<h3>Description</h3>

<p>Obtains predictions from a fitted <code>logistf</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'logistf'
predict(
  object,
  newdata,
  type = c("link", "response", "terms"),
  flic = FALSE,
  se.fit = FALSE,
  reference,
  na.action = na.pass,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.logistf_+3A_object">object</code></td>
<td>
<p>A fitted object of class <code>logistf</code>.</p>
</td></tr>
<tr><td><code id="predict.logistf_+3A_newdata">newdata</code></td>
<td>
<p>Optionally, a data frame in which to look for variables with which to predict.
If omitted, the fitted linear predictors are used.</p>
</td></tr>
<tr><td><code id="predict.logistf_+3A_type">type</code></td>
<td>
<p>The type of prediction required. The default is on the scale of the linear predictors.
The alternative <code>response</code> gives the predicted probabilities. Type <code>terms</code> returns a matrix with the fitted
values of each term in the formula on the linear predictor scale.</p>
</td></tr>
<tr><td><code id="predict.logistf_+3A_flic">flic</code></td>
<td>
<p>If <code>TRUE</code>(default = <code>FALSE</code>), predictions are computed with intercept correction.</p>
</td></tr>
<tr><td><code id="predict.logistf_+3A_se.fit">se.fit</code></td>
<td>
<p>If <code>TRUE</code>(default = <code>FALSE</code>) standard errors are computed.</p>
</td></tr>
<tr><td><code id="predict.logistf_+3A_reference">reference</code></td>
<td>
<p>A named vector of reference values for each variable for <code>type="terms"</code>.</p>
</td></tr>
<tr><td><code id="predict.logistf_+3A_na.action">na.action</code></td>
<td>
<p>Function determining what should be done with missing values in newdata. The default is to predict NA.</p>
</td></tr>
<tr><td><code id="predict.logistf_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>newdata</code> is omitted the predictions are based on the data used for the fit.
</p>


<h3>Value</h3>

<p>A vector or matrix of predictions.
</p>

<hr>
<h2 id='profile.logistf'>Compute Profile Penalized Likelihood</h2><span id='topic+profile.logistf'></span>

<h3>Description</h3>

<p>Evaluates the profile penalized likelihood of a variable based on a logistf model fit
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'logistf'
profile(
  fitted,
  which,
  variable,
  steps = 100,
  pitch = 0.05,
  limits,
  alpha = 0.05,
  firth = TRUE,
  legends = TRUE,
  control,
  plcontrol,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="profile.logistf_+3A_fitted">fitted</code></td>
<td>
<p>An object fitted by <code>logistf</code></p>
</td></tr>
<tr><td><code id="profile.logistf_+3A_which">which</code></td>
<td>
<p>A righthand formula to specify the variable for which the profile should be evaluated, e.g., which=~X).</p>
</td></tr>
<tr><td><code id="profile.logistf_+3A_variable">variable</code></td>
<td>
<p>Alternatively to which, a variable name can be given, e.g., variable=&quot;X&quot;</p>
</td></tr>
<tr><td><code id="profile.logistf_+3A_steps">steps</code></td>
<td>
<p>Number of steps in evaluating the profile likelihood</p>
</td></tr>
<tr><td><code id="profile.logistf_+3A_pitch">pitch</code></td>
<td>
<p>Alternatively to steps, one may specify the step width in multiples of standard errors</p>
</td></tr>
<tr><td><code id="profile.logistf_+3A_limits">limits</code></td>
<td>
<p>Lower and upper limits of parameter values at which profile likelihood is to be evaluated</p>
</td></tr>
<tr><td><code id="profile.logistf_+3A_alpha">alpha</code></td>
<td>
<p>The significance level (1-<code class="reqn">\alpha</code> the confidence level, 0.05 as default).</p>
</td></tr>
<tr><td><code id="profile.logistf_+3A_firth">firth</code></td>
<td>
<p>Use of Firth's penalized maximum likelihood (<code>firth=TRUE</code>, default)
or the standard maximum likelihood method (<code>firth=FALSE</code>) for the logistic regression.</p>
</td></tr>
<tr><td><code id="profile.logistf_+3A_legends">legends</code></td>
<td>
<p>legends to be included in the optional plot</p>
</td></tr>
<tr><td><code id="profile.logistf_+3A_control">control</code></td>
<td>
<p>Controls Newton-Raphson iteration. Default is <code>control= logistf.control(maxstep, 
maxit, maxhs, lconv, gconv, xconv)</code></p>
</td></tr>
<tr><td><code id="profile.logistf_+3A_plcontrol">plcontrol</code></td>
<td>
<p>Controls Newton-Raphson iteration for the estimation of the profile likelihood
confidence intervals. Default is <code>plcontrol= logistpl.control(maxstep, maxit, maxhs, lconv, xconv, ortho, pr)</code></p>
</td></tr>
<tr><td><code id="profile.logistf_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>logistf.profile</code> with the following items:
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>Parameter values at which likelihood was evaluated</p>
</td></tr>
<tr><td><code>stdbeta</code></td>
<td>
<p>Parameter values divided by standard error</p>
</td></tr>
<tr><td><code>profile</code></td>
<td>
<p>profile likelihood, standardized to 0 at maximum of likelihood. The values in
profile are given as minus <code class="reqn">\chi^2</code></p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>Unstandardized profile likelihood</p>
</td></tr>
<tr><td><code>signed.root</code></td>
<td>
<p>signed root (z) of <code class="reqn">\chi^2</code> values (negative for values below the maximum likelihood
estimate, positive for values above the maximum likelihood estimate)</p>
</td></tr>
<tr><td><code>cdf</code></td>
<td>
<p>profile likelihood expressed as cumulative distribution function, obtained as
<code class="reqn">\Phi(z)</code>, where <code class="reqn">\Phi</code> denotes the standard normal distribution function.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Heinze G, Ploner M, Beyea J (2013). Confidence intervals after multiple imputation: combining
profile likelihood information from logistic regressions. Statistics in Medicine, to appear.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sex2)
fit&lt;-logistf(case ~ age+oc+vic+vicl+vis+dia, data=sex2)
plot(profile(fit,variable="dia"))
plot(profile(fit,variable="dia"), "cdf")
plot(profile(fit,variable="dia"), "density")

</code></pre>

<hr>
<h2 id='PVR.confint'>Pseudo Variance Modification of Rubin's Rule</h2><span id='topic+PVR.confint'></span>

<h3>Description</h3>

<p>The pseudo-variance modification proposed by Heinze, Ploner and Beyea (2013) provides a quick
way to adapt Rubin's rules to situations of a non-normal distribution of a regression coefficient.
However, the approxiation is less accurate than that of the CLIP method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PVR.confint(obj, variable, skewbeta = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PVR.confint_+3A_obj">obj</code></td>
<td>
<p>A fitted <code>logisf</code> object</p>
</td></tr>
<tr><td><code id="PVR.confint_+3A_variable">variable</code></td>
<td>
<p>The variable(s) to compute the PVR confidence intervals, either provided as names or as numbers</p>
</td></tr>
<tr><td><code id="PVR.confint_+3A_skewbeta">skewbeta</code></td>
<td>
<p>If <code>TRUE</code>, incorporates information on the skewness of the parameter estimates
across the imputed data sets.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The pseudo-variance modification computes a lower and an upper pseudo-variance, which are based
on the distance between profile likelihood limits and the parameter estimates. These are then
plugged into the usual Rubin's rules method of variance combination
</p>


<h3>Value</h3>

<p>An object of class <code>PVR.confint</code> with items:
</p>
<table>
<tr><td><code>estimate</code></td>
<td>
<p>the pooled parameter estimate(s) (the average across completed-data estimates)</p>
</td></tr>
<tr><td><code>ci</code></td>
<td>
<p>the confidence intervals based on the PVR method</p>
</td></tr>
<tr><td><code>lower.var</code></td>
<td>
<p>the lower pseudo-variance(s)</p>
</td></tr>
<tr><td><code>upper.var</code></td>
<td>
<p>the upper pseudo-variance(s)</p>
</td></tr>
<tr><td><code>conflev</code></td>
<td>
<p>the confidence level: this is determined by the confidence level (1-alpha) used in the input fit objects</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call</p>
</td></tr>
<tr><td><code>variable</code></td>
<td>
<p>the variable(s) for which confidence intervals were computed</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Georg Heinze
</p>


<h3>References</h3>

<p>Heinze G, Ploner M, Beyea J (2013). Confidence intervals after multiple imputation: combining
profile likelihood information from logistic regressions. Statistics in Medicine, to appear.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#generate data set with NAs
freq=c(5,2,2,7,5,4)
y&lt;-c(rep(1,freq[1]+freq[2]), rep(0,freq[3]+freq[4]), rep(1,freq[5]), rep(0,freq[6]))
x&lt;-c(rep(1,freq[1]), rep(0,freq[2]), rep(1,freq[3]), rep(0,freq[4]), rep(NA,freq[5]),
   rep(NA,freq[6]))
toy&lt;-data.frame(x=x,y=y)

# impute data set 5 times 
set.seed(169)
toymi&lt;-list(0)
for(i in 1:5){
  toymi[[i]]&lt;-toy
  y1&lt;-toymi[[i]]$y==1 &amp; is.na(toymi[[i]]$x)
  y0&lt;-toymi[[i]]$y==0 &amp; is.na(toymi[[i]]$x)
  xnew1&lt;-rbinom(sum(y1),1,freq[1]/(freq[1]+freq[2]))
  xnew0&lt;-rbinom(sum(y0),1,freq[3]/(freq[3]+freq[4]))
  toymi[[i]]$x[y1==TRUE]&lt;-xnew1
  toymi[[i]]$x[y0==TRUE]&lt;-xnew0
  }
  
# logistf analyses of each imputed data set
fit.list&lt;-lapply(1:5, function(X) logistf(data=toymi[[X]], y~x, pl=TRUE))

# CLIP confidence limits
PVR.confint(obj=fit.list)

</code></pre>

<hr>
<h2 id='sex2'>Urinary Tract Infection in American College Students</h2><span id='topic+sex2'></span>

<h3>Description</h3>

<p>This data set deals with urinary tract infection in sexually active college women,
along with covariate information on age an contraceptive use.
The variables are all binary and coded in 1 (condition is present) and 0 (condition is absent).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sex2
</code></pre>


<h3>Format</h3>

<p>sex2: a data.frame containing 239 observations
</p>

<dl>
<dt>case</dt><dd><p>urinary tract infection, the study outcome variable</p>
</dd>
<dt>age</dt><dd><p>&gt;= 24 years</p>
</dd>
<dt>dia</dt><dd><p>use of diaphragm</p>
</dd>
<dt>oc</dt><dd><p>use of oral contraceptive</p>
</dd>
<dt>vic</dt><dd><p>use of condom</p>
</dd>
<dt>vicl</dt><dd><p>use of lubricated condom</p>
</dd>
<dt>vis</dt><dd><p>use of spermicide</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://www.cytel.com/">https://www.cytel.com/</a>
</p>


<h3>References</h3>

<p>Cytel Inc., (2010) LogXact 9 user manual, Cambridge, MA:Cytel Inc
</p>

<hr>
<h2 id='sexagg'>Urinary Tract Infection in American College Students</h2><span id='topic+sexagg'></span>

<h3>Description</h3>

<p>This data set deals with urinary tract infection in sexually active college women,
along with covariate information on age an contraceptive use.
The variables are all binary and coded in 1 (condition is present) and 0 (condition is absent):
case (urinary tract infection, the study outcome variable), age (&gt;= 24 years),
dia (use of diaphragm), oc (use of oral contraceptive), vic (use of condom),
vicl (use of lubricated condom), and vis (use of spermicide).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sexagg
</code></pre>


<h3>Format</h3>

<p>sexagg: an aggregated data.frame containing 31 observations with case weights (COUNT).
</p>

<dl>
<dt>case</dt><dd><p>urinary tract infection, the study outcome variable</p>
</dd>
<dt>age</dt><dd><p>&gt;= 24 years</p>
</dd>
<dt>dia</dt><dd><p>use of diaphragm</p>
</dd>
<dt>oc</dt><dd><p>use of oral contraceptive</p>
</dd>
<dt>vic</dt><dd><p>use of condom</p>
</dd>
<dt>vicl</dt><dd><p>use of lubricated condom</p>
</dd>
<dt>vis</dt><dd><p>use of spermicide</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://www.cytel.com/">https://www.cytel.com/</a>
</p>


<h3>References</h3>

<p>Cytel Inc., (2010) LogXact 9 user manual, Cambridge, MA:Cytel Inc
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
