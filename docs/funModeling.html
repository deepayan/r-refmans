<!DOCTYPE html><html lang="en"><head><title>Help for package funModeling</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {funModeling}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#funModeling-package'><p>funModeling: Exploratory data analysis, data preparation and model performance</p></a></li>
<li><a href='#auto_grouping'><p>Reduce cardinality in categorical variable by automatic grouping</p></a></li>
<li><a href='#categ_analysis'><p>Profiling analysis of categorical vs. target variable</p></a></li>
<li><a href='#compare_df'><p>Compare two data frames by keys</p></a></li>
<li><a href='#concatenate_n_vars'><p>Concatenate 'N' variables</p></a></li>
<li><a href='#convert_df_to_categoric'><p>Convert every column in a data frame to character</p></a></li>
<li><a href='#coord_plot'><p>Coordinate plot</p></a></li>
<li><a href='#correlation_table'><p>Get correlation against target variable</p></a></li>
<li><a href='#cross_plot'><p>Cross-plotting input variable vs. target variable</p></a></li>
<li><a href='#data_country'><p>People with flu data</p></a></li>
<li><a href='#data_golf'><p>Play golf</p></a></li>
<li><a href='#data_integrity'><p>Data integrity</p></a></li>
<li><a href='#data_integrity_model'><p>Check data integrity model</p></a></li>
<li><a href='#desc_groups'><p>Profiling categorical variable</p></a></li>
<li><a href='#desc_groups_rank'><p>Profiling categorical variable (rank)</p></a></li>
<li><a href='#df_status'><p>Get a summary for the given data frame (o vector).</p></a></li>
<li><a href='#discretize_df'><p>Discretize a data frame</p></a></li>
<li><a href='#discretize_get_bins'><p>Get the data frame thresholds for discretization</p></a></li>
<li><a href='#discretize_rgr'><p>Variable discretization by gain ratio maximization</p></a></li>
<li><a href='#entropy_2'><p>Computes the entropy between two variables</p></a></li>
<li><a href='#equal_freq'><p>Equal frequency binning</p></a></li>
<li><a href='#export_plot'><p>Export plot to jpeg file</p></a></li>
<li><a href='#fibonacci'><p>Fibonacci series</p></a></li>
<li><a href='#freq'><p>Frequency table for categorical variables</p></a></li>
<li><a href='#gain_lift'><p>Generates lift and cumulative gain performance table and plot</p></a></li>
<li><a href='#gain_ratio'><p>Gain ratio</p></a></li>
<li><a href='#get_sample'><p>Sampling training and test data</p></a></li>
<li><a href='#hampel_outlier'><p>Hampel Outlier Threshold</p></a></li>
<li><a href='#heart_disease'><p>Heart Disease Data</p></a></li>
<li><a href='#infor_magic'><p>Computes several information theory metrics between two vectors</p></a></li>
<li><a href='#information_gain'><p>Information gain</p></a></li>
<li><a href='#metadata_models'><p>Metadata models data integrity</p></a></li>
<li><a href='#plot_num'><p>Plotting numerical data</p></a></li>
<li><a href='#plotar'><p>Correlation plots</p></a></li>
<li><a href='#prep_outliers'><p>Outliers Data Preparation</p></a></li>
<li><a href='#profiling_num'><p>Profiling numerical data</p></a></li>
<li><a href='#range01'><p>Transform a variable into the [0-1] range</p></a></li>
<li><a href='#status'><p>Get a summary for the given data frame (o vector).</p></a></li>
<li><a href='#tukey_outlier'><p>Tukey Outlier Threshold</p></a></li>
<li><a href='#v_compare'><p>Compare two vectors</p></a></li>
<li><a href='#var_rank_info'><p>Importance variable ranking based on information theory</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Exploratory Data Analysis and Data Preparation Tool-Box</td>
</tr>
<tr>
<td>Description:</td>
<td>Around 10% of almost any predictive modeling project is spent in predictive modeling, 'funModeling' and the book Data Science Live Book (<a href="https://livebook.datascienceheroes.com/">https://livebook.datascienceheroes.com/</a>) are intended to cover remaining 90%: data preparation, profiling, selecting best variables 'dataViz', assessing model performance and other functions.</td>
</tr>
<tr>
<td>Version:</td>
<td>1.9.5</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-03-30</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Pablo Casas &lt;pcasas.biz@gmail.com&gt;</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/pablo14/funModeling/issues">https://github.com/pablo14/funModeling/issues</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://livebook.datascienceheroes.com">https://livebook.datascienceheroes.com</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>ROCR, ggplot2, gridExtra, pander, reshape2, scales, dplyr,
lazyeval, utils, RColorBrewer, moments, entropy, cli, stringr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4.0), Hmisc (&ge; 3.17.1)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-30 17:57:38 UTC; jausis</td>
</tr>
<tr>
<td>Author:</td>
<td>Pablo Casas [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-04-01 08:00:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='funModeling-package'>funModeling: Exploratory data analysis, data preparation and model performance</h2><span id='topic+funModeling'></span><span id='topic+funModeling-package'></span>

<h3>Description</h3>

<p>funModeling is intimately related to the Data Science Live Book -Open Source- (2017) in the sense that most
of its functionality is used to explain different topics addressed by the book.
</p>


<h3>Details</h3>

<p>To start using funModeling you can start by the vignette:
'browseVignettes(package = &quot;funModeling&quot;)'
</p>
<p>Or you can read the Data Science Live Book, fully accessible at: <a href="https://livebook.datascienceheroes.com">https://livebook.datascienceheroes.com</a>
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Pablo Casas <a href="mailto:pcasas.biz@gmail.com">pcasas.biz@gmail.com</a>
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://livebook.datascienceheroes.com">https://livebook.datascienceheroes.com</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/pablo14/funModeling/issues">https://github.com/pablo14/funModeling/issues</a>
</p>
</li></ul>


<hr>
<h2 id='auto_grouping'>Reduce cardinality in categorical variable by automatic grouping</h2><span id='topic+auto_grouping'></span>

<h3>Description</h3>

<p>Reduce the cardinality of an input variable based on a target -binary by now- variable based on attribitues of accuracy and representativity,
for both input and target variable. It uses a cluster model to create the new groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>auto_grouping(data, input, target, n_groups, model = "kmeans", seed = 999)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="auto_grouping_+3A_data">data</code></td>
<td>
<p>data frame source</p>
</td></tr>
<tr><td><code id="auto_grouping_+3A_input">input</code></td>
<td>
<p>categorical variable indicating</p>
</td></tr>
<tr><td><code id="auto_grouping_+3A_target">target</code></td>
<td>
<p>string of the variable to optimize the re-grouping</p>
</td></tr>
<tr><td><code id="auto_grouping_+3A_n_groups">n_groups</code></td>
<td>
<p>number of groups for the new category based on input, normally between 3 and 10.</p>
</td></tr>
<tr><td><code id="auto_grouping_+3A_model">model</code></td>
<td>
<p>is the clustering model used to create the grouping, supported models: &quot;kmeans&quot; (default) or &quot;hclust&quot; (hierarchical clustering).</p>
</td></tr>
<tr><td><code id="auto_grouping_+3A_seed">seed</code></td>
<td>
<p>optional, random number used internally for the k-means, changing this value will change the model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing 3 elements: recateg_results which contains the description of the target variable with the new groups;
df_equivalence is a data frame containing the input category and the new category; fit_cluster which is the cluster model used to do the re-grouping
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Reducing quantity of countries based on has_flu variable
auto_grouping(data=data_country, input='country', target="has_flu", n_groups=8)

</code></pre>

<hr>
<h2 id='categ_analysis'>Profiling analysis of categorical vs. target variable</h2><span id='topic+categ_analysis'></span>

<h3>Description</h3>

<p>Retrieves a complete summary of the grouped input variable against the target variable. Type of target variable must be binary for now. A positive case will be the less representative one. It returns the total positive cases (sum_target)); pecentage of total positive cases (perc_target) that fell in that category (this column sums 1); likelihood or mean of positive cases (mean_target) measured by the total positive cases over total cases in that category; quantity of rows of that category (q_rows) and in percentage (perc_rows) -this column sums 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>categ_analysis(data, input, target)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="categ_analysis_+3A_data">data</code></td>
<td>
<p>input data containing the variable to describe</p>
</td></tr>
<tr><td><code id="categ_analysis_+3A_input">input</code></td>
<td>
<p>string input variable (if empty, it runs for all categorical variable), it can take a single character value or a character vector.</p>
</td></tr>
<tr><td><code id="categ_analysis_+3A_target">target</code></td>
<td>
<p>string target variable. Binary or two class is only supported by now.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>if input has 1 variable, it retrurns a data frame indicating all the metrics, otherwise prints in console all variable results.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>categ_analysis(data_country, "country", "has_flu")
</code></pre>

<hr>
<h2 id='compare_df'>Compare two data frames by keys</h2><span id='topic+compare_df'></span>

<h3>Description</h3>

<p>Obtain differences between two data frames
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare_df(dfcomp_x, dfcomp_y, keys_x, keys_y = NA, compare_values = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compare_df_+3A_dfcomp_x">dfcomp_x</code></td>
<td>
<p>first data frame to compare</p>
</td></tr>
<tr><td><code id="compare_df_+3A_dfcomp_y">dfcomp_y</code></td>
<td>
<p>second data frame to compare</p>
</td></tr>
<tr><td><code id="compare_df_+3A_keys_x">keys_x</code></td>
<td>
<p>keys of the first dataframe</p>
</td></tr>
<tr><td><code id="compare_df_+3A_keys_y">keys_y</code></td>
<td>
<p>(optional) keys of the second dataframe, if missing both data frames will be compared with the keys_x</p>
</td></tr>
<tr><td><code id="compare_df_+3A_compare_values">compare_values</code></td>
<td>
<p>(optional) if TRUE it will not only compare keys, but also will check if the values of non-key matching columns have the same values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Differences and coincident values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(heart_disease)
a=heart_disease
b=heart_disease
a=subset(a, age &gt;45)
b=subset(b, age &lt;50)
b$gender='male'
b$chest_pain=ifelse(b$chest_pain ==3, 4, b$chest_pain)
res=compare_df(a, b, c('age', 'gender'))
# Print the keys that didn't match
res
# Accessing the keys not present in the first data frame
res[[1]]$rows_not_in_X
# Accessing the keys not present in the second data frame
res[[1]]$rows_not_in_Y
# Accessing the keys which coincide completely
res[[1]]$coincident
# Accessing the rows whose values did not coincide
res[[1]]$different_values
</code></pre>

<hr>
<h2 id='concatenate_n_vars'>Concatenate 'N' variables</h2><span id='topic+concatenate_n_vars'></span>

<h3>Description</h3>

<p>Concatenate 'N' variables using the char pipe: &lt;|&gt;.
This function is used when there is the need of measuring the mutual information and/or the information
gain between 'N' input variables an against a target variable. This function makes sense when it is used based on
categorical data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>concatenate_n_vars(data, vars)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="concatenate_n_vars_+3A_data">data</code></td>
<td>
<p>data frame containing the two variables to concatenate</p>
</td></tr>
<tr><td><code id="concatenate_n_vars_+3A_vars">vars</code></td>
<td>
<p>character vector containing all variables to concatenate</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector containing the concatenated values for the given variables
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
new_variable=concatenate_n_vars(mtcars, c("cyl", "disp"))
# Checking new variable
head(new_variable)

</code></pre>

<hr>
<h2 id='convert_df_to_categoric'>Convert every column in a data frame to character</h2><span id='topic+convert_df_to_categoric'></span>

<h3>Description</h3>

<p>It converts all the variables present in 'data' to character. Criteria conversion is based on
two functions, <code><a href="#topic+discretize_get_bins">discretize_get_bins</a></code> plus <code><a href="#topic+discretize_df">discretize_df</a></code>, which will discretize
all the numerical variables based on equal frequency criteria, with the number of bins equal to 'n_bins'.
This only applies for numerical variables which unique valuesare more than 'n_bins' parameter.
After this step, it may happen that variables remain non-character, so these variables will be converting
directly into character.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convert_df_to_categoric(data, n_bins)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="convert_df_to_categoric_+3A_data">data</code></td>
<td>
<p>input data frame to discretize</p>
</td></tr>
<tr><td><code id="convert_df_to_categoric_+3A_n_bins">n_bins</code></td>
<td>
<p>number of bins/segments for each variable</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame containing all variables as character
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# before
df_status(heart_disease)

# after
new_df=convert_df_to_categoric(data=heart_disease, n_bins=5)
df_status(new_df)

</code></pre>

<hr>
<h2 id='coord_plot'>Coordinate plot</h2><span id='topic+coord_plot'></span>

<h3>Description</h3>

<p>Calculate the means (or other function defined in 'group_func' parameter) per group to analyze how each segment behave. It scales each variable mean inti the 0 to 1 range to easily profile the groups according to its mean. It also calculate the mean regardless the grouping. This function is also useful when you want to profile cluster results in terms of its means.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coord_plot(data, group_var, group_func = mean, print_table = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coord_plot_+3A_data">data</code></td>
<td>
<p>input data source</p>
</td></tr>
<tr><td><code id="coord_plot_+3A_group_var">group_var</code></td>
<td>
<p>variable to make the group by</p>
</td></tr>
<tr><td><code id="coord_plot_+3A_group_func">group_func</code></td>
<td>
<p>the data type of this parameter is a function, not an string, this is the function to be used in the group by, the default value is: mean</p>
</td></tr>
<tr><td><code id="coord_plot_+3A_print_table">print_table</code></td>
<td>
<p>False by default, if true it retrieves the mean table used to generate the plot.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>coordinate plot, if print_table=T it also prints a table with the average per column plus the average of the whole column
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# calculating the differences based on function 'mean'
coord_plot(data=mtcars, group_var="cyl")
# printing the table used to generate the coord_plot
coord_plot(data=mtcars, group_var="cyl", print_table=TRUE)
# printing the table used to generate the coord_plot
coord_plot(data=mtcars, group_var="cyl", group_func=median, print_table=TRUE)

</code></pre>

<hr>
<h2 id='correlation_table'>Get correlation against target variable</h2><span id='topic+correlation_table'></span>

<h3>Description</h3>

<p>Obtain correlation table for all variables against target variable. Only numeric variables are analyzed (factor/character are skippted automatically).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>correlation_table(data, target)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="correlation_table_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="correlation_table_+3A_target">target</code></td>
<td>
<p>string variable to predict</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Correlation index for all data input variable
</p>


<h3>Examples</h3>

<pre><code class='language-R'>correlation_table(data=heart_disease, target="has_heart_disease")
</code></pre>

<hr>
<h2 id='cross_plot'>Cross-plotting input variable vs. target variable</h2><span id='topic+cross_plot'></span>

<h3>Description</h3>

<p>The cross_plot shows how the input variable is correlated with the target variable, getting the likelihood rates for each input's bin/bucket .
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cross_plot(data, input, target, path_out, auto_binning, plot_type = "both")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cross_plot_+3A_data">data</code></td>
<td>
<p>data frame source</p>
</td></tr>
<tr><td><code id="cross_plot_+3A_input">input</code></td>
<td>
<p>input variable name (if empty, it runs for all numeric variable), it can take a single character value or a character vector.</p>
</td></tr>
<tr><td><code id="cross_plot_+3A_target">target</code></td>
<td>
<p>variable name to predict</p>
</td></tr>
<tr><td><code id="cross_plot_+3A_path_out">path_out</code></td>
<td>
<p>path directory, if it has a value the plot is saved</p>
</td></tr>
<tr><td><code id="cross_plot_+3A_auto_binning">auto_binning</code></td>
<td>
<p>indicates the automatic binning of input variable based on equal frequency (function 'equal_freq'), default value=TRUE</p>
</td></tr>
<tr><td><code id="cross_plot_+3A_plot_type">plot_type</code></td>
<td>
<p>indicates if the output is the 'percentual' plot, the 'quantity' or 'both' (default).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>cross plot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Example 1:
cross_plot(data=heart_disease, input="chest_pain", target="has_heart_disease")

## Example 2: Disabling auto_binning:
cross_plot(data=heart_disease, input="oldpeak",
		target="has_heart_disease", auto_binning=FALSE)

## Example 3: Saving the plot into a folder:
#cross_plot(data=heart_disease, input="oldpeak",
#		target="has_heart_disease", path_out = "my_folder")

## Example 4: Running with multiple input variables at the same time:
cross_plot(data=heart_disease, input=c("age", "oldpeak", "max_heart_rate"),
		target="has_heart_disease")

</code></pre>

<hr>
<h2 id='data_country'>People with flu data</h2><span id='topic+data_country'></span>

<h3>Description</h3>

<p>Each row represents a person from different countries indicating if he or she has or not flu.
Colmuns
person: unique id
country: country of the person, 70 different countries
has_flu: character variable with values &quot;yes&quot; or &quot;no&quot; indicating if the person has flu
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_country
</code></pre>


<h3>Format</h3>

<p>A data frame with 910 rows and 3 variables
</p>

<hr>
<h2 id='data_golf'>Play golf</h2><span id='topic+data_golf'></span>

<h3>Description</h3>

<p>This well known small data frame containst 14 cases indicating wheter or not play golf based on wheather conditions. Target variable: 'play_golf.'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_golf
</code></pre>


<h3>Format</h3>

<p>A data frame with 14 rows and 3 variables
</p>

<hr>
<h2 id='data_integrity'>Data integrity</h2><span id='topic+data_integrity'></span>

<h3>Description</h3>

<p>A handy function to return different vectors of variable names aimed to quickly filter NA, categorical (factor / character), numerical and other types (boolean, date, posix).
It also returns a vector of variables which have high cardinality.
It returns an 'integrity' object, which has: 'status_now' (comes from status function), and 'results' list, following elements can be found:
</p>
<p>vars_cat: Vector containing the categorical variables names (factor or character)
</p>
<p>vars_num: Vector containing the numerical variables names
</p>
<p>vars_char: Vector containing the character variables names
</p>
<p>vars_factor: Vector containing the factor variables names
</p>
<p>vars_other: Vector containing the other variables names (date time, posix and boolean)
</p>
<p>vars_num_with_NA: Summary table for numerical variables with NA
</p>
<p>vars_cat_with_NA: Summary table for categorical variables with NA
</p>
<p>vars_cat_high_card: Summary table for  high cardinality variables (where thershold = MAX_UNIQUE parameter)
</p>
<p>vars_one_value: Vector containing the variables names with 1 unique different value
</p>
<p>Explore the NA and high cardinality variables by doing summary(integrity_object), or a full summary by doing print(integrity_object)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_integrity(data, MAX_UNIQUE = 35)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="data_integrity_+3A_data">data</code></td>
<td>
<p>data frame or a single vector</p>
</td></tr>
<tr><td><code id="data_integrity_+3A_max_unique">MAX_UNIQUE</code></td>
<td>
<p>max unique threshold to flag a categorical variable as a high cardinality one. Normally above 35 values it is needed to reduce the number of different values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An 'integrity' object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1:
data_integrity(heart_disease)
# Example 2:
# changing the default minimum threshold to flag a variable as high cardiniality
data_integrity(data=data_country, MAX_UNIQUE=50)
</code></pre>

<hr>
<h2 id='data_integrity_model'>Check data integrity model</h2><span id='topic+data_integrity_model'></span>

<h3>Description</h3>

<p>Given a data frame, we need to create models (xgboost, random forest, regression, etc). Each one of them has its constraints regarding data types. Many errors appear when we are creating models just because of data format.
This function returns, given a certain model, which are the constraints that the data is not satisfying. This way we can anticipate and correct errors before we call for model creation. This function is quite related to <code><a href="#topic+data_integrity">data_integrity</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_integrity_model(data, model_name, MAX_UNIQUE = 35)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="data_integrity_model_+3A_data">data</code></td>
<td>
<p>data frame or a single vector</p>
</td></tr>
<tr><td><code id="data_integrity_model_+3A_model_name">model_name</code></td>
<td>
<p>model name, you can check all the available models by printing 'metadata_models' data frame.</p>
</td></tr>
<tr><td><code id="data_integrity_model_+3A_max_unique">MAX_UNIQUE</code></td>
<td>
<p>max unique threshold to flag a categorical variable as a high cardinality one. Normally above 35 values it is needed to reduce the number of different values.
# Example 1:
data_integrity_model(data=heart_disease, model_name=&quot;pca&quot;)
# Example 2:
# changing the default minimum threshold to flag a variable as high cardiniality
data_integrity_model(data=iris, model_name=&quot;xgboost&quot;, MAX_UNIQUE=50)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an 'integritymodel' object
</p>

<hr>
<h2 id='desc_groups'>Profiling categorical variable</h2><span id='topic+desc_groups'></span>

<h3>Description</h3>

<p>Calculate the means (or other function) per group to analyze how each segment behave. It scales each variable mean inti the 0 to 1 range to easily profile the groups according to its mean. It also calculate the mean regardless the grouping. This function is also useful when you want to profile cluster results in terms of its means. It automatically adds a row representing the sumarization of the column regardless the group_var categories, this is useful to compare each segement with the whole population. It will exclude all factor/character variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>desc_groups(data, group_var, group_func = mean, add_all_data_row = T)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="desc_groups_+3A_data">data</code></td>
<td>
<p>input data source</p>
</td></tr>
<tr><td><code id="desc_groups_+3A_group_var">group_var</code></td>
<td>
<p>variable to make the group by</p>
</td></tr>
<tr><td><code id="desc_groups_+3A_group_func">group_func</code></td>
<td>
<p>the data type of this parameter is a function, not an string, this is the function to be used in the group by, the default value is: mean</p>
</td></tr>
<tr><td><code id="desc_groups_+3A_add_all_data_row">add_all_data_row</code></td>
<td>
<p>flag indicating if final data contains the row: 'All_Data', which is the function applied regardless the grouping. Useful to compare with the rest of the values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>grouped data frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'># default grouping function: mean
desc_groups(data=mtcars, group_var="cyl")

# using the median as the grouping function
desc_groups(data=mtcars, group_var="cyl", group_func=median)

# using the max as the grouping function
desc_groups(data=mtcars, group_var="gear", group_func=max)
</code></pre>

<hr>
<h2 id='desc_groups_rank'>Profiling categorical variable (rank)</h2><span id='topic+desc_groups_rank'></span>

<h3>Description</h3>

<p>Similar to 'desc_groups' function, this one computes the rank of each value in order to quickly know what is the value in each segment that has the highest value (rank=1). 1 represent the highest number. It will exclude all factor/character variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>desc_groups_rank(data, group_var, group_func = mean)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="desc_groups_rank_+3A_data">data</code></td>
<td>
<p>input data source</p>
</td></tr>
<tr><td><code id="desc_groups_rank_+3A_group_var">group_var</code></td>
<td>
<p>variable to make the group by</p>
</td></tr>
<tr><td><code id="desc_groups_rank_+3A_group_func">group_func</code></td>
<td>
<p>the data type of this parameter is a function, not an string, this is the function to be used in the group by, the default value is: mean</p>
</td></tr>
</table>


<h3>Value</h3>

<p>grouped data frame, showing the rank instead of the absolute values/
</p>


<h3>Examples</h3>

<pre><code class='language-R'># default grouping function: mean
desc_groups_rank(data=mtcars, group_var="gear")

# using the median as the grouping function
desc_groups(data=mtcars, group_var="cyl", group_func=median)

# using the max as the grouping function
desc_groups_rank(data=mtcars, group_var="gear", group_func=max)
</code></pre>

<hr>
<h2 id='df_status'>Get a summary for the given data frame (o vector).</h2><span id='topic+df_status'></span>

<h3>Description</h3>

<p>For each variable it returns: Quantity and percentage of zeros (q_zeros and p_zeros respectevly). Same metrics for NA values (q_NA/p_na), and infinite values (q_inf/p_inf). Last two columns indicates data type and quantity of unique values.
This function print and return the results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_status(data, print_results)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="df_status_+3A_data">data</code></td>
<td>
<p>data frame or a single vector</p>
</td></tr>
<tr><td><code id="df_status_+3A_print_results">print_results</code></td>
<td>
<p>if FALSE then there is not a print in the console, TRUE by default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Metrics data frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df_status(heart_disease)
</code></pre>

<hr>
<h2 id='discretize_df'>Discretize a data frame</h2><span id='topic+discretize_df'></span>

<h3>Description</h3>

<p>Converts all numerical variables into factor or character, depending on 'stringsAsFactors' parameter,
based on equal frequency criteria. The thresholds for each segment in each variable are generated based on the
output of <code><a href="#topic+discretize_get_bins">discretize_get_bins</a></code> function, which returns a data frame
containing the threshold for each variable. This result is must be the 'data_bins' parameter input.
Important to note that the returned data frame contains the non-transformed variables plus the transformed ones.
More info about converting numerical into categorical variables
can be found at: <a href="https://livebook.datascienceheroes.com/data-preparation.html#data_types">https://livebook.datascienceheroes.com/data-preparation.html#data_types</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>discretize_df(data, data_bins, stringsAsFactors = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="discretize_df_+3A_data">data</code></td>
<td>
<p>Input data frame</p>
</td></tr>
<tr><td><code id="discretize_df_+3A_data_bins">data_bins</code></td>
<td>
<p>data frame generated by 'discretize_get_bins' function. It contains the variable name and the
thresholds for each bin, or segment.</p>
</td></tr>
<tr><td><code id="discretize_df_+3A_stringsasfactors">stringsAsFactors</code></td>
<td>
<p>Boolean variable which indicates if the discretization result is character or factor.
When TRUE, the segments are ordered. TRUE by default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame with the transformed variables
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Getting the bins thresholds for each. If input is missing, 
# will run for all numerical variables.
d_bins=discretize_get_bins(data=heart_disease,
input=c("resting_blood_pressure", "oldpeak"), n_bins=5)

# Now it can be applied on the same data frame,
# or in a new one (for example in a predictive model that 
# change data over time)
heart_disease_discretized=
discretize_df(data=heart_disease, 
data_bins=d_bins, 
stringsAsFactors=TRUE)


</code></pre>

<hr>
<h2 id='discretize_get_bins'>Get the data frame thresholds for discretization</h2><span id='topic+discretize_get_bins'></span>

<h3>Description</h3>

<p>It takes a data frame and returns another data frame indicating the threshold for each bin (or segment)
in order to discretize the variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>discretize_get_bins(data, n_bins = 5, input = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="discretize_get_bins_+3A_data">data</code></td>
<td>
<p>Data frame source</p>
</td></tr>
<tr><td><code id="discretize_get_bins_+3A_n_bins">n_bins</code></td>
<td>
<p>The number of desired bins (or segments) that each variable will have.</p>
</td></tr>
<tr><td><code id="discretize_get_bins_+3A_input">input</code></td>
<td>
<p>Vector of string containing all the variables that will be processed.
If empty it will run for all numerical variables that match the following condition, the number of unique values
must be higher than the ones defined at 'n_bins' parameter. NAs values are automatically handled by converting
them into another category (more info about it at
<a href="https://livebook.datascienceheroes.com/data-preparation.html#treating-missing-values-in-numerical-variables">https://livebook.datascienceheroes.com/data-preparation.html#treating-missing-values-in-numerical-variables</a>).
This function must be used with <a href="#topic+discretize_df">discretize_df</a>.
If it is needed a different number of bins per variable, then the function must be called more than once.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame containing the thresholds or cuts to bin every variable
</p>

<hr>
<h2 id='discretize_rgr'>Variable discretization by gain ratio maximization</h2><span id='topic+discretize_rgr'></span>

<h3>Description</h3>

<p>Discretize numeric variable by maximizing the gain ratio
between each bucket and the target variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>discretize_rgr(input, target, min_perc_bins = 0.1, max_n_bins = 5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="discretize_rgr_+3A_input">input</code></td>
<td>
<p>numeric input vector to discretize</p>
</td></tr>
<tr><td><code id="discretize_rgr_+3A_target">target</code></td>
<td>
<p>character or factor multi-calss target variable</p>
</td></tr>
<tr><td><code id="discretize_rgr_+3A_min_perc_bins">min_perc_bins</code></td>
<td>
<p>minimum percetange of rows for each split or segment (controls the sample size), 0,1 (or 10 percent) as default</p>
</td></tr>
<tr><td><code id="discretize_rgr_+3A_max_n_bins">max_n_bins</code></td>
<td>
<p>maximum number of bins or segments to split the input variable, 5 bins as default</p>
</td></tr>
</table>


<h3>Value</h3>

<p>discretized variable (factor)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(funModeling)
data=heart_disease
input=data$oldpeak
target=as.character(data$has_heart_disease)

input2=discretize_rgr(input, target)

# checking:
summary(input2)

</code></pre>

<hr>
<h2 id='entropy_2'>Computes the entropy between two variables</h2><span id='topic+entropy_2'></span>

<h3>Description</h3>

<p>It calculates the entropy between two categorical variables using log2.
This log2 is mentioned in most of the Claude Shannon bibliography.
Input/target can be numeric or character.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>entropy_2(input, target)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="entropy_2_+3A_input">input</code></td>
<td>
<p>numeric/character vector</p>
</td></tr>
<tr><td><code id="entropy_2_+3A_target">target</code></td>
<td>
<p>numeric/character vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Entropy measured in bits
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Measuring entropy between input and target variable
entropy_2(input=data_golf$outlook, target=data_golf$play_golf)

</code></pre>

<hr>
<h2 id='equal_freq'>Equal frequency binning</h2><span id='topic+equal_freq'></span>

<h3>Description</h3>

<p>Equal frequency tries to put the same quantity of cases per bin when possible. It's a wrapper of function cut2 from Hmisc package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>equal_freq(var, n_bins)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="equal_freq_+3A_var">var</code></td>
<td>
<p>input variable</p>
</td></tr>
<tr><td><code id="equal_freq_+3A_n_bins">n_bins</code></td>
<td>
<p>number of bins to split 'var' by equal frequency, if it not possible to calculate for the desired bins, it returns the closest number</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The binned variable.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example 1
summary(heart_disease$age)
age_2=equal_freq(var=heart_disease$age, n_bins = 10)
summary(age_2)

## Example 2
age_3=equal_freq(var=heart_disease$age, n_bins = 5)
summary(age_3)
</code></pre>

<hr>
<h2 id='export_plot'>Export plot to jpeg file</h2><span id='topic+export_plot'></span>

<h3>Description</h3>

<p>Export 'object_plot' to jpeg file under the name 'file_name' in the directory 'path_out'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>export_plot(object_plot, path_out, file_name)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="export_plot_+3A_object_plot">object_plot</code></td>
<td>
<p>Object plot to export (like ggplot2)</p>
</td></tr>
<tr><td><code id="export_plot_+3A_path_out">path_out</code></td>
<td>
<p>path directory to export the output, if it has a value the plot is saved,
if the directory doesn't existis it will try to create it. To save in current directory path must be dot: &quot;.&quot;</p>
</td></tr>
<tr><td><code id="export_plot_+3A_file_name">file_name</code></td>
<td>
<p>output file name</p>
</td></tr>
</table>


<h3>Value</h3>

<p>none
</p>

<hr>
<h2 id='fibonacci'>Fibonacci series</h2><span id='topic+fibonacci'></span>

<h3>Description</h3>

<p>It retrieves a vector containing the first N numbers specified in 'length' parameter of the Fibonacci series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fibonacci(length, remove_first = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fibonacci_+3A_length">length</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="fibonacci_+3A_remove_first">remove_first</code></td>
<td>
<p>removes the first value of the series, because first 2 elements are the same (number=1). False by default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Get the first 4 elements of Fibonacci series
fibonacci(4)
</code></pre>

<hr>
<h2 id='freq'>Frequency table for categorical variables</h2><span id='topic+freq'></span>

<h3>Description</h3>

<p>Retrieves the frequency and percentage for input
</p>


<h3>Usage</h3>

<pre><code class='language-R'>freq(data, input = NA, plot = TRUE, na.rm = FALSE, path_out)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="freq_+3A_data">data</code></td>
<td>
<p>input data containing the variable to describe</p>
</td></tr>
<tr><td><code id="freq_+3A_input">input</code></td>
<td>
<p>string input variable (if empty, it runs for all numeric variable), it can take a single character value or a character vector.</p>
</td></tr>
<tr><td><code id="freq_+3A_plot">plot</code></td>
<td>
<p>flag indicating if the plot is desired, TRUE by default</p>
</td></tr>
<tr><td><code id="freq_+3A_na.rm">na.rm</code></td>
<td>
<p>flag indicating if NA values must be included in the analysis, FALSE by default</p>
</td></tr>
<tr><td><code id="freq_+3A_path_out">path_out</code></td>
<td>
<p>path directory, if it has a value the plot is saved</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector with the values scaled into the 0 to 1 range
</p>


<h3>Examples</h3>

<pre><code class='language-R'>freq(data=heart_disease$thal)
freq(data=heart_disease, input = c('thal','chest_pain'))
</code></pre>

<hr>
<h2 id='gain_lift'>Generates lift and cumulative gain performance table and plot</h2><span id='topic+gain_lift'></span>

<h3>Description</h3>

<p>It retrieves the cumulative positive rate -gain curve- and the lift chart &amp; plot when score is divided
in 5, 10 or 20 segments. Both metrics give a quality measure about how well the model predicts.
Higher values at the beginning of the population implies a better model. More info at:
<a href="https://livebook.datascienceheroes.com/model-performance.html#scoring_data">https://livebook.datascienceheroes.com/model-performance.html#scoring_data</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gain_lift(data, score, target, q_segments = 10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gain_lift_+3A_data">data</code></td>
<td>
<p>input data source</p>
</td></tr>
<tr><td><code id="gain_lift_+3A_score">score</code></td>
<td>
<p>the variable which contains the score number, or likelihood of being positive class</p>
</td></tr>
<tr><td><code id="gain_lift_+3A_target">target</code></td>
<td>
<p>target binary variable indicating class label</p>
</td></tr>
<tr><td><code id="gain_lift_+3A_q_segments">q_segments</code></td>
<td>
<p>quantity of segments to split score variable, valid values: 5, 10 or 20</p>
</td></tr>
</table>


<h3>Value</h3>

<p>lift/gain table, column: gain implies how much positive cases are catched if the cut point to define the
positive class is set to the column &quot;Score Point&quot;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit_glm=glm(has_heart_disease ~ age + oldpeak, data=heart_disease, family = binomial)
heart_disease$score=predict(fit_glm, newdata=heart_disease, type='response')
gain_lift(data=heart_disease, score='score', target='has_heart_disease')

</code></pre>

<hr>
<h2 id='gain_ratio'>Gain ratio</h2><span id='topic+gain_ratio'></span>

<h3>Description</h3>

<p>Computes the information gain between an 'input' and 'target' variable (using log2). Similar to information gain but less sensitive to high cardinality variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gain_ratio(input, target)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gain_ratio_+3A_input">input</code></td>
<td>
<p>numeric/character vector</p>
</td></tr>
<tr><td><code id="gain_ratio_+3A_target">target</code></td>
<td>
<p>numeric/character vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>gain ratio
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
gain_ratio(input=data_golf$outlook, target=data_golf$play_golf)

</code></pre>

<hr>
<h2 id='get_sample'>Sampling training and test data</h2><span id='topic+get_sample'></span>

<h3>Description</h3>

<p>Split input data into training and test set, retrieving always same sample by setting the seed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_sample(data, percentage_tr_rows = 0.8, seed = 987)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_sample_+3A_data">data</code></td>
<td>
<p>input data source</p>
</td></tr>
<tr><td><code id="get_sample_+3A_percentage_tr_rows">percentage_tr_rows</code></td>
<td>
<p>percentage of training rows, range value from 0.1 to 0.99, default value=0.8 (80 percent of training data)</p>
</td></tr>
<tr><td><code id="get_sample_+3A_seed">seed</code></td>
<td>
<p>to generate the sample randomly, default value=987</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE/FALSE vector same length as 'data' param. TRUE represents that row position is for training data
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Training and test data. Percentage of training cases default value=80%.
index_sample=get_sample(data=heart_disease, percentage_tr_rows=0.8)
# Generating the samples
data_tr=heart_disease[index_sample,]
data_ts=heart_disease[-index_sample,]
</code></pre>

<hr>
<h2 id='hampel_outlier'>Hampel Outlier Threshold</h2><span id='topic+hampel_outlier'></span>

<h3>Description</h3>

<p>Retrieves the bottom and top boundaries to flag outliers or extreme values, according to the Hampel method. This technique takes into account the median and MAD value, which is a is a robust measure of the variability of a univariate sample of quantitative data (Wikipedia). Similar to standard deviation but less sensitve to outliers.
This function is used in 'prep_outliers' function. All 'NA's values are automatically excluded. More information at: <a href="https://livebook.datascienceheroes.com/data-preparation.html#how_to_deal_with_outliers_in_r">https://livebook.datascienceheroes.com/data-preparation.html#how_to_deal_with_outliers_in_r</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hampel_outlier(input, k_mad_value = 3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hampel_outlier_+3A_input">input</code></td>
<td>
<p>Numeric variable vector</p>
</td></tr>
<tr><td><code id="hampel_outlier_+3A_k_mad_value">k_mad_value</code></td>
<td>
<p>'K' multiplier for the median absolute deviation. The higher the value, the more outliers will be detected. Default value=3 (it's an standad)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A two-item vector, the first value represents the bottom threshold, while the second one is the top threshold
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
hampel_outlier(heart_disease$age)

</code></pre>

<hr>
<h2 id='heart_disease'>Heart Disease Data</h2><span id='topic+heart_disease'></span>

<h3>Description</h3>

<p>There are variables related to patient clinic trial. The variable to predict is 'has_heart_disease'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>heart_disease
</code></pre>


<h3>Format</h3>

<p>A data frame with 303 rows and 16 variables:
</p>

<p><a href="https://archive.ics.uci.edu/ml/datasets/Heart+Disease">https://archive.ics.uci.edu/ml/datasets/Heart+Disease</a>

</p>

<hr>
<h2 id='infor_magic'>Computes several information theory metrics between two vectors</h2><span id='topic+infor_magic'></span>

<h3>Description</h3>

<p>It retrieves the same as <code><a href="#topic+var_rank_info">var_rank_info</a></code> but receiving two vectors.
Metrics are: entropy (en), mutual information (mi), information gain (ig) and gain ratio (gr).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>infor_magic(input, target)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="infor_magic_+3A_input">input</code></td>
<td>
<p>vector to be evaluated against the variable defined in 'target' parameter</p>
</td></tr>
<tr><td><code id="infor_magic_+3A_target">target</code></td>
<td>
<p>vector containing the output variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix of 1 row and 4 columns, where each column represent the mentioned metrics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
infor_magic(data_golf$outlook, data_golf$play_golf)

</code></pre>

<hr>
<h2 id='information_gain'>Information gain</h2><span id='topic+information_gain'></span>

<h3>Description</h3>

<p>Computes the information gain between an 'input' and 'target' variable (using log2). In general terms, the higher the more predictable the input is.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>information_gain(input, target)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="information_gain_+3A_input">input</code></td>
<td>
<p>numeric/character vector</p>
</td></tr>
<tr><td><code id="information_gain_+3A_target">target</code></td>
<td>
<p>numeric/character vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>information gain
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
information_gain(input=data_golf$outlook, target=data_golf$play_golf)

</code></pre>

<hr>
<h2 id='metadata_models'>Metadata models data integrity</h2><span id='topic+metadata_models'></span>

<h3>Description</h3>

<p>Metadata models data integrity
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metadata_models
</code></pre>


<h3>Format</h3>

<p>Tibble
</p>

<hr>
<h2 id='plot_num'>Plotting numerical data</h2><span id='topic+plot_num'></span>

<h3>Description</h3>

<p>Retrieves one plot containing all the histograms for numerical variables. NA values will not be displayed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_num(data, bins = 10, path_out = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_num_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="plot_num_+3A_bins">bins</code></td>
<td>
<p>number of bars (bins) to plot each histogram, 10 by default</p>
</td></tr>
<tr><td><code id="plot_num_+3A_path_out">path_out</code></td>
<td>
<p>path directory to export the output, if it has a value the plot is saved,
if the directory doesn't existis it will try to create it. To save in current directory path must be dot: &quot;.&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>plot containing all numerical variables
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
plot_num(mtcars)
# changing the bins parameter and exporting the plot
# plot_num(data=mtcars, bins=5, path_out="my_folder")

</code></pre>

<hr>
<h2 id='plotar'>Correlation plots</h2><span id='topic+plotar'></span>

<h3>Description</h3>

<p>Visual correlation analysis. Plot different graphs in order to expose the inner information of any numeric variable against the target variable
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotar(data, input, target, plot_type, path_out)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotar_+3A_data">data</code></td>
<td>
<p>data frame source</p>
</td></tr>
<tr><td><code id="plotar_+3A_input">input</code></td>
<td>
<p>string input variable (if empty, it runs for all numeric variable), it can take a single character value or a character vector.</p>
</td></tr>
<tr><td><code id="plotar_+3A_target">target</code></td>
<td>
<p>string of the variable to predict, it supports binary or multinominal values.</p>
</td></tr>
<tr><td><code id="plotar_+3A_plot_type">plot_type</code></td>
<td>
<p>Indicates the type of plot to retrieve, available values: &quot;boxplot&quot; or &quot;histdens&quot;.</p>
</td></tr>
<tr><td><code id="plotar_+3A_path_out">path_out</code></td>
<td>
<p>path directory, if it has a value the plot is saved. To save in current directory path must be dot: &quot;.&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Single or multiple plots specified by 'plot_type' parameter
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## It runs for all numeric variables automatically
plotar(data=heart_disease, target="has_heart_disease", plot_type="histdens")

plotar(heart_disease, input = 'age', target = 'chest_pain', plot_type = "boxplot")

</code></pre>

<hr>
<h2 id='prep_outliers'>Outliers Data Preparation</h2><span id='topic+prep_outliers'></span>

<h3>Description</h3>

<p>Deal with outliers by setting an 'NA value' or by 'stopping' them at a certain.
There are three supported methods to flag the values as outliers: &quot;bottom_top&quot;, &quot;tukey&quot; and &quot;hampel&quot;.
The parameters: 'top_percent' and/or 'bottom_percent' are used only when method=&quot;bottom_top&quot;.
</p>
<p>For a full reference please check the official documentation at: <a href="https://livebook.datascienceheroes.com/data-preparation.html#treatment_outliers">https://livebook.datascienceheroes.com/data-preparation.html#treatment_outliers</a>&gt;
Setting NA is recommended when doing statistical analysis, parameter: type='set_na'.
Stopping is recommended when creating a predictive model without biasing the result due to outliers, parameter: type='stop'.
</p>
<p>The function can take a data frame, and returns the same data plus the transformations specified in the input parameter. Or it can take a single vector (in the same 'data' parameter), and it returns a vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prep_outliers(
  data,
  input = NA,
  type = NA,
  method = NA,
  bottom_percent = NA,
  top_percent = NA,
  k_mad_value = NA
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prep_outliers_+3A_data">data</code></td>
<td>
<p>a data frame or a single vector. If it's a data frame, the function returns a data frame, otherwise it returns a vector.</p>
</td></tr>
<tr><td><code id="prep_outliers_+3A_input">input</code></td>
<td>
<p>string input variable (if empty, it runs for all numeric variable).</p>
</td></tr>
<tr><td><code id="prep_outliers_+3A_type">type</code></td>
<td>
<p>can be 'stop' or 'set_na', in the first case all falling out of the threshold will be converted to the threshold, on the other case all of these values will be set as NA.</p>
</td></tr>
<tr><td><code id="prep_outliers_+3A_method">method</code></td>
<td>
<p>indicates the method used to flag the outliers, it can be: &quot;bottom_top&quot;, &quot;tukey&quot; or &quot;hampel&quot;.</p>
</td></tr>
<tr><td><code id="prep_outliers_+3A_bottom_percent">bottom_percent</code></td>
<td>
<p>value from 0 to 1, represents the lowest X percentage of values to treat. Valid only when method=&quot;bottom_top&quot;.</p>
</td></tr>
<tr><td><code id="prep_outliers_+3A_top_percent">top_percent</code></td>
<td>
<p>value from 0 to 1, represents the highest X percentage of values to treat. Valid only when method=&quot;bottom_top&quot;.</p>
</td></tr>
<tr><td><code id="prep_outliers_+3A_k_mad_value">k_mad_value</code></td>
<td>
<p>only used when method='hampel', 3 by default, might seem quite restrictive. Set a higher number to spot less outliers.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with the desired outlier transformation
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Creating data frame with outliers
set.seed(10)
df=data.frame(var1=rchisq(1000,df = 1), var2=rnorm(1000))
df=rbind(df, 1135, 2432) # forcing outliers
df$id=as.character(seq(1:1002))

# for var1: mean is ~ 4.56, and max 2432
summary(df)

########################################################
### PREPARING OUTLIERS FOR DESCRIPTIVE STATISTICS
########################################################

#### EXAMPLE 1: Removing top 1%% for a single variable
# checking the value for the top 1% of highest values (percentile 0.99), which is ~ 7.05
quantile(df$var1, 0.99)

# Setting type='set_na' sets NA to the highest value specified by top_percent.
# In this case 'data' parameter is single vector, thus it returns a single vector as well.
var1_treated=prep_outliers(data = df$var1, type='set_na', top_percent  = 0.01,method = "bottom_top")

# now the mean (~ 1) is more accurate, and note that: 1st, median and 3rd
#  quartiles remaining very similar to the original variable.
summary(var1_treated)

#### EXAMPLE 2: Removing top and bottom 1% for the specified input variables.
vars_to_process=c('var1', 'var2')
df_treated3=prep_outliers(data = df, input = vars_to_process, type='set_na',
 bottom_percent = 0.01, top_percent  = 0.01, method = "bottom_top")
summary(df_treated3)

########################################################
### PREPARING OUTLIERS FOR PREDICTIVE MODELING
########################################################

data_prep_h=funModeling::prep_outliers(data = heart_disease,
input = c('age','resting_blood_pressure'),
 method = "hampel",  type='stop')

# Using Hampel method to flag outliers:
summary(heart_disease$age);summary(data_prep_h$age)
# it changed from 29 to 29.31, and the max remains the same at 77
hampel_outlier(heart_disease$age) # checking the thresholds

data_prep_a=funModeling::prep_outliers(data = heart_disease,
input = c('age','resting_blood_pressure'),
 method = "tukey",  type='stop')

max(heart_disease$age);max(data_prep_a$age)
# remains the same (77) because the max thers for age is 100
tukey_outlier(heart_disease$age)


</code></pre>

<hr>
<h2 id='profiling_num'>Profiling numerical data</h2><span id='topic+profiling_num'></span>

<h3>Description</h3>

<p>Get a metric table with many indicators for all numerical variables, automatically skipping the non-numerical variables. Current metrics are:
mean, std_dev: standard deviation, all the p_XX: percentile at XX number, skewness, kurtosis, iqr: inter quartile range, variation_coef: the ratio of sd/mean, range_98 is the limit for which the 98
</p>


<h3>Usage</h3>

<pre><code class='language-R'>profiling_num(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="profiling_num_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
</table>


<h3>Value</h3>

<p>metrics table
</p>


<h3>Examples</h3>

<pre><code class='language-R'>profiling_num(mtcars)
</code></pre>

<hr>
<h2 id='range01'>Transform a variable into the [0-1] range</h2><span id='topic+range01'></span>

<h3>Description</h3>

<p>Range a variable into [0-1], assigning 0 to the min and 1 to the max of the input variable. All NA values will be removed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>range01(var)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="range01_+3A_var">var</code></td>
<td>
<p>numeric input vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector with the values scaled into the 0 to 1 range
</p>


<h3>Examples</h3>

<pre><code class='language-R'>range01(mtcars$cyl)
</code></pre>

<hr>
<h2 id='status'>Get a summary for the given data frame (o vector).</h2><span id='topic+status'></span>

<h3>Description</h3>

<p>For each variable it returns: Quantity and percentage of zeros (q_zeros and p_zeros respectevly). Same metrics for NA values (q_NA/p_na), and infinite values (q_inf/p_inf). Last two columns indicates data type and quantity of unique values.
'status' function is the evolution of 'df_status'. Main change is to have the decimal points as it is, except in percentage. For example now p_na=0.04 means 4
This time it's easier to embbed in a data process flow and to take actions based on this number.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>status(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="status_+3A_data">data</code></td>
<td>
<p>data frame, tibble or a single vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tibble with metrics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>status(heart_disease)
</code></pre>

<hr>
<h2 id='tukey_outlier'>Tukey Outlier Threshold</h2><span id='topic+tukey_outlier'></span>

<h3>Description</h3>

<p>Retrieves the bottom and top boundaries to flag outliers or extreme values, according to the Tukey's test. More info at <a href="https://en.wikipedia.org/wiki/Outlier#Tukey.27s_test">https://en.wikipedia.org/wiki/Outlier#Tukey.27s_test</a>
This function is used in 'prep_outliers' function. All 'NA's values are automatically excluded. More information at: <a href="https://livebook.datascienceheroes.com/data-preparation.html#how_to_deal_with_outliers_in_r">https://livebook.datascienceheroes.com/data-preparation.html#how_to_deal_with_outliers_in_r</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tukey_outlier(input)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tukey_outlier_+3A_input">input</code></td>
<td>
<p>Numeric variable vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A two-item vector, the first value represents the bottom threshold, while the second one is the top threshold
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
tukey_outlier(heart_disease$age)

</code></pre>

<hr>
<h2 id='v_compare'>Compare two vectors</h2><span id='topic+v_compare'></span>

<h3>Description</h3>

<p>Obtaing coincident and not coincident elements between two vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>v_compare(vector_x, vector_y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="v_compare_+3A_vector_x">vector_x</code></td>
<td>
<p>1st vector to compare</p>
</td></tr>
<tr><td><code id="v_compare_+3A_vector_y">vector_y</code></td>
<td>
<p>2nd vector to compare</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Correlation index for all data input variable
</p>


<h3>Examples</h3>

<pre><code class='language-R'>v1=c("height","weight","age")
v2=c("height","weight","location","q_visits")
res=v_compare(vector_x=v1, vector_y=v2)
# Print the keys that didn't match
res
# Accessing the keys not present in
</code></pre>

<hr>
<h2 id='var_rank_info'>Importance variable ranking based on information theory</h2><span id='topic+var_rank_info'></span>

<h3>Description</h3>

<p>Retrieves a data frame containing several metrics related to information theory.
Metrics are: entropy (en), mutual information (mi), information gain (ig) and gain ratio (gr).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>var_rank_info(data, target)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="var_rank_info_+3A_data">data</code></td>
<td>
<p>input data frame, all the variables will be evaluated against the variable defined in 'target' parameter</p>
</td></tr>
<tr><td><code id="var_rank_info_+3A_target">target</code></td>
<td>
<p>string variable name containing the output variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame ordered by gain ratio metric
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
var_rank_info(data_golf, "play_golf")

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
