<!DOCTYPE html><html lang="en-US"><head><title>Help for package LSDsensitivity</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {LSDsensitivity}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#LSDsensitivity-package'>
<p>Sensitivity Analysis Tools for LSD Simulations</p></a></li>
<li><a href='#elementary.effects.lsd'>
<p>Elementary effects sensitivity analysis</p></a></li>
<li><a href='#ergod.test.lsd'>
<p>Stationarity and ergodicity tests</p></a></li>
<li><a href='#kriging.model.lsd'>
<p>Fit a Kriging meta-model to a LSD model sample data</p></a></li>
<li><a href='#model.limits.lsd'>
<p>Find maximum and minimum meta-model responses</p></a></li>
<li><a href='#model.optim.lsd'>
<p>Find optimal meta-model factor settings</p></a></li>
<li><a href='#model.pred.lsd'>
<p>Predict meta-model response at given point(s)</p></a></li>
<li><a href='#polynomial.model.lsd'>
<p>Fit a polynomial meta-model to a LSD model sample data</p></a></li>
<li><a href='#read.doe.lsd'>
<p>Read a set of experimental data from a LSD model</p></a></li>
<li><a href='#response.surface.lsd'>
<p>Generate the meta-model 3D response surface data</p></a></li>
<li><a href='#sobol.decomposition.lsd'>
<p>Sobol variance decomposition sensitivity analysis</p></a></li>
<li><a href='#symmet.test.lsd'>
<p>Unimodality and symmetry tests</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Sensitivity Analysis Tools for LSD Simulations</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-9-20</td>
</tr>
<tr>
<td>Description:</td>
<td>Tools for sensitivity analysis of LSD simulation models. Reads object-oriented data produced by LSD simulation models and performs screening and global sensitivity analysis (Sobol decomposition method, Saltelli et al. (2008) ISBN:9780470725177). A Kriging or polynomial meta-model (Kleijnen (2009) &lt;<a href="https://doi.org/10.1016%2Fj.ejor.2007.10.013">doi:10.1016/j.ejor.2007.10.013</a>&gt;) is estimated using the simulation data to provide the data required by the Sobol decomposition. LSD (Laboratory for Simulation Development) is free software developed by Marco Valente and Marcelo C. Pereira (documentation and downloads available at <a href="https://www.labsimdev.org/">https://www.labsimdev.org/</a>).</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>LSDinterface (&ge; 1.2.1), stats, utils, graphics, tseries,
kSamples, diptest, lawstat, abind, sensitivity, car,
randtoolbox, parallel, rgenoud, DiceKriging, XML</td>
</tr>
<tr>
<td>Suggests:</td>
<td>LSDirf, rgl, normalp</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-09-20 19:15:02 UTC; Marcelo</td>
</tr>
<tr>
<td>Author:</td>
<td>Marcelo C. Pereira
    <a href="https://orcid.org/0000-0002-8069-2734"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Marcelo C. Pereira &lt;mcper@unicamp.br&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-09-20 19:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='LSDsensitivity-package'>
Sensitivity Analysis Tools for LSD Simulations
</h2><span id='topic+LSDsensitivity-package'></span><span id='topic+LSDsensitivity'></span>

<h3>Description</h3>

<p>Tools for sensitivity analysis of LSD simulation models. Reads object-oriented data produced by LSD simulation models and performs screening and global sensitivity analysis (Sobol decomposition method, Saltelli et al. (2008) ISBN:9780470725177). A Kriging or polynomial meta-model (Kleijnen (2009) &lt;doi:10.1016/j.ejor.2007.10.013&gt;) is estimated using the simulation data to provide the data required by the Sobol decomposition. LSD (Laboratory for Simulation Development) is free software developed by Marco Valente and Marcelo C. Pereira (documentation and downloads available at &lt;https://www.labsimdev.org/&gt;).
</p>


<h3>Details</h3>

<p>The LSDsensitivity R package provides tools to analyze simulated experiments from <strong>LSD</strong>. LSD offers native tools to sample the configuration (factor) space of a simulation model using different design of experiments (DoE). The produced experimental design data can be transparently imported to R by using the function <code><a href="#topic+read.doe.lsd">read.doe.lsd</a>()</code>.
</p>
<p>The package offers two sensitivity analysis (SA) methods (<code><a href="#topic+elementary.effects.lsd">elementary.effects.lsd</a>()</code> and <code><a href="#topic+sobol.decomposition.lsd">sobol.decomposition.lsd</a>()</code>) pre-configured for application on LSD simulations: Morris Elementary Effects (EE) and Sobol Variance Decomposition (SVD).
</p>
<p>EE (<code><a href="#topic+elementary.effects.lsd">elementary.effects.lsd</a>()</code>) employs a simple one-factor-at-a-time (OAT) SA and is usually applied as an initial screening method while selecting relevant factors to a SVD global SA. EE requires an appropriate set of sample points (the DoE) which can be generated in LSD when &quot;EE Sampling&quot; is selected in the &quot;Data&quot; menu. Please make sure to take note of the DoE parameters used for the sampling, as they will be required for the configuration of the R analysis script.
</p>
<p>Due to its high computational cost, <code><a href="#topic+sobol.decomposition.lsd">sobol.decomposition.lsd</a>()</code> (SVD) is performed over a meta-model fitted from the experimental data produced by the LSD original model. The meta-model can be fitted using different sampling strategies offered by LSD, being &quot;NOLH Sampling&quot; (Near Orthogonal Latin Hypercube) usually the most efficient. Additionally to the set of samples used to fit the meta-model, it is recommended to also generate another set for the (external) validation of the meta-model (&quot;MC Range Sampling&quot; is the recommended option).
</p>
<p>The package offers two meta-modeling (MM) methods for using with SVD: Kriging and polynomial. Kriging (<code><a href="#topic+kriging.model.lsd">kriging.model.lsd</a>()</code>) is offered under five different variance kernels (Matern 5/2, Matern3/2, Gaussian, exponential and power exponential) and two trend models (constant or first order polynomial) to choose, including auto-selection to the best fitting alternative. Polynomial meta-models of first or second order, with or without interactions, and auto-selection are also offered (<code><a href="#topic+polynomial.model.lsd">polynomial.model.lsd</a>()</code>). Kriging is the recommended option in most cases.
</p>
<p>Additionally, the package offers tools for the graphical representation of the meta-models response surfaces (2D and 3D) (<code><a href="#topic+response.surface.lsd">response.surface.lsd</a>()</code>), to predict meta-model response in specific points in the factor space (<code><a href="#topic+model.pred.lsd">model.pred.lsd</a>()</code>), to identify maximum and minimum responses from a set of factors (<code><a href="#topic+model.limits.lsd">model.limits.lsd</a>()</code>), and to find optimal parameter settings using the meta-model (<code><a href="#topic+model.optim.lsd">model.optim.lsd</a>()</code>).
</p>
<p>For a complete list of exported functions, use <code>library(help = "LSDsensitivity")</code>.
</p>
<p><strong>LSD 7.0+</strong> default installation provides <em>example scripts</em> for the usage of the LSDsensitivity package. LSD can be downloaded at <a href="https://github.com/marcov64/Lsd/">https://github.com/marcov64/Lsd/</a>. They can also be retrieved from the package itself using the commands:
</p>
<p><strong>EE example</strong>: <code>file.show(system.file("examples", "elementary-effects-SA.R", package = "LSDsensitivity"))</code>
</p>
<p><strong>Kriging SVD example</strong>: <code>file.show(system.file("examples", "kriging-sobol-SA.R", package = "LSDsensitivity"))</code>
</p>
<p><strong>Polynomial SVD example</strong>: <code>file.show(system.file("examples", "poly-sobol-SA.R", package = "LSDsensitivity"))</code>
</p>
<p><strong>Optimize MM example</strong>: <code>file.show(system.file("examples", "optimize-MM.R", package = "LSDsensitivity"))</code>
</p>


<h3>Note</h3>

<p>Below are the minimum required steps to perform SA on a working LSD model using NOLH sampling, Kriging MM and SVD. The changes to perform an EE or to use a polynomial MM are also indicated, as options.
</p>

<ol>
<li><p> Define the parameters/initial values to be explored in the SA, their max/min ranges and the result variables over which the SA is to be done
</p>
</li>
<li><p> In <code>LMM</code> create a no-window (command prompt) version of your model by selecting menu <code>Model/Create 'No Window' Version</code>
</p>
</li>
<li><p> In <code>LSD Browser</code> make sure that all parameters/initial values are set with the correct calibration/default values (menu <code>Data/Initial Values</code>), the required result variables are being saved (menu <code>Model/Change Element...</code>, click on <code>Save/OK</code> or simply <code>Save</code> in the right mouse button context menu) and the number of MC runs for each SA sample (point) is defined (menu <code>Run/Simulation Settings</code>, <code>Number of simulation runs</code> field, typically set to 10)
</p>
</li>
<li><p> Save your setup in a baseline <code>.lsd</code> configuration file (menu <code>File/Save As...</code>), preferably in a new folder inside your current model configuration folder (you can create a new folder while in the <code>File/Save As...</code> dialog box, if you do not, LSD will create a new folder when saving SA configuration and results files, named as your baseline configuration)
</p>
</li>
<li><p> (Re)load your baseline <code>.lsd</code> configuration if it is not already loaded (menu <code>File/Load...</code>)
</p>
</li>
<li><p> Choose the ranges (max/min) for each parameter/initial value in your SA exploration space by using the <code>Sensitivity Analysis</code> button in the menu <code>Model/Change Element...</code> window or the same option in the context menu (mouse right-button click on the parameter/variable name in the <code>Variables &amp; Parameters</code> list box)
</p>
</li>
<li><p> After choosing all ranges, save your exploration space definition as a <code>.sa</code> sensitivity analysis file using the same base name and folder as your <code>.lsd</code> baseline configuration (menu <code>File/Save Sensitivity...</code>)
</p>
</li>
<li><p> With both the created <code>.lsd</code> and <code>.sa</code> files loaded (use menu <code>File/Load...</code> and <code>File/Load Sensitivity...</code> if required), select <code>Data/Sensitivity Analysis/NOLH Sampling...</code> and accept the defaults (several new <code>.lsd</code> files will be created in your just created baseline configuration folder (or one created by LSD, if you did not), those are the sample points for the meta-model estimation)
</p>

<ol>
<li><p> To perform Elementary Effects (EE) analysis instead of Sobol Variance Decomposition, in the step below select <code>Data/Sensitivity Analysis/EE Sampling...</code> instead (NOLH sampling cannot be used for EE)
</p>
</li>
<li><p> If a polynomial meta-model (MM) is being estimated, sometimes it is preferred to use <code>Data/Sensitivity Analysis/MC Range Sampling...</code> despite not required
</p>
</li></ol>

</li>
<li><p> Immediately after the previous step, select menu <code>Data/Sensitivity Analysis/MC Range Sampling...</code> and accept the defaults (to create the external validation sample, more <code>.lsd</code> files will be created for the additional sampling points)
</p>

<ol>
<li><p> EE analysis does not uses external validation, so skip this step for EE
</p>
</li></ol>

</li>
<li><p> Immediately after the previous step select menu <code>Run/Create/Run Parallel Batch</code>, accept using the just created configuration, adjust the number of cores only if going to run in another machine (8 in a modern PC, 20 in a basic server), and decide if you want to start the (time-consuming) processing right now or later (in the current or in another machine)
</p>
</li>
<li><p> If running later in the same machine, you just have to execute the created script file (<code>.bat</code> or <code>.sh</code>) inside the new folder your baseline <code>.lsd</code> file was created (or the one LSD created if you did not)
</p>
</li>
<li><p> If running in another machine, you have to copy the entire model folder and sub-folders to the new machine (the remaining LSD folders are not required), recompile LSD for the new platform if required and execute the script file (<code>.bat</code> or <code>.sh</code>) in the same folder as your baseline <code>.lsd</code> file
</p>
</li>
<li><p> Open R (or RStudio) and check you have the following packages installed and download them if required (if you install LSDsensitivity from CRAN or another online repository, and not from a file, all other dependency packages should be automatically downloaded):
</p>
<p><code>LSDsensitivity, LSDinterface, abind, tseries, car, minqa, nloptr, Rcpp, RcppEigen, lme4, SparseM, MatrixModels, pbkrtest, quantreg, DiceKriging, kSamples, SuppDists, randtoolbox, rngWELL, rgenoud, sensitivity, xts, TTR, quadprog, zoo, quantmod</code>
</p>
</li>
<li><p> Open the <code>kriging-sobol-SA.R</code> example script (included in your LSD installation folder) in RStudio or your text editor
</p>

<ol>
<li><p> For EE analysis, open <code>elementary-effects-SA.R</code> instead
</p>
</li>
<li><p> For the use of a polynomial MM for the SVD analysis, open <code>poly-sobol-SA.R</code> instead
</p>
</li></ol>

</li>
<li><p> Adjust the vector <code>lsdVars</code> to contain all the LSD saved variables you want to use in your analysis (do not include saved but unused variables, for performance reasons), replacing the dummies <code>varX</code>
</p>
</li>
<li><p> Adjust the vector <code>logVars</code> to contain all LSD variables (included in <code>lsdVars</code>) that require to have the log value used in the analysis (let the vector empty, i.e. <code>c( )</code>, if no log variable is required)
</p>
</li>
<li><p> Include in the vector <code>newVars</code> any new variable (not included in <code>lsdVars</code>) that has to be added to the dataset (let the vector empty, i.e. <code>c( )</code>, if no new variable is required)
</p>
</li>
<li><p> Adapt the <code>eval.vars()</code> function to compute any new variable included in <code>newVars</code> (use the commented example as a reference)
</p>
</li>
<li><p> Adjust the arguments to the function <code><a href="#topic+read.doe.lsd">read.doe.lsd</a>()</code> for the relative folder of LSD data files (default is same as R working directory), the data files base name (the file name chosen for the baseline configuration in step 4 without the <code>.lsd</code> suffix) and the name of the variable to be used as reference for the sensitivity analysis (you have to run the script multiple times if there is more than one)
</p>
</li>
<li><p> Save the modified script, renaming if necessary, and run it in R (or click the <code>Source</code> button in RStudio), redirecting output to a file first if required
</p>
</li></ol>



<h3>Author(s)</h3>

<p>Marcelo C. Pereira [aut, cre] (&lt;https://orcid.org/0000-0002-8069-2734&gt;)
</p>
<p>Maintainer: Marcelo C. Pereira &lt;mcper@unicamp.br&gt;
</p>


<h3>References</h3>

<p>LSD documentation is available at <a href="https://www.labsimdev.org/">https://www.labsimdev.org/</a>
</p>
<p>The latest LSD binaries and source code can be downloaded at <a href="https://github.com/marcov64/Lsd/">https://github.com/marcov64/Lsd/</a>.
</p>
<p>Cioppa T, Lucas T (2007) <em>Efficient nearly orthogonal and space-filling latin hypercubes</em>. Technometrics
49(1):45-55
</p>
<p>Kleijnen JP (2009) <em>Kriging metamodeling in simulation: a review</em>. Eur J Oper Res 192(3):707-716
</p>
<p>Morris MD (1991) <em>Factorial sampling plans for preliminary computational experiments</em>.Technometrics
33(1):161-174
</p>
<p>Rasmussen C, Williams C (2006) <em>Gaussian processes for machine learning</em>. MIT Press, Cambridge
</p>
<p>Roustant O, Ginsbourger D, Deville Y (2012) <em>Dicekriging, diceoptim: two R packages for the analysis of computer experiments by kriging-based metamodeling and optimization</em>. J Stat Softw 51(1):1-55
</p>
<p>Saltelli A, Ratto M, Andres T, Campolongo F, Cariboni J, Gatelli D, Saisana M, Tarantola S (2008) <em>Global sensitivity analysis: the primer</em>. Wiley, New York
</p>
<p>Sekhon JS, Walter RM (1998). <em>Genetic optimization using derivatives: theory and application to nonlinear models</em>. Political Analysis 7:187-210
</p>


<h3>See Also</h3>

<p><a href="LSDinterface.html#topic+LSDinterface-package">LSDinterface-package</a>
</p>

<hr>
<h2 id='elementary.effects.lsd'>
Elementary effects sensitivity analysis
</h2><span id='topic+elementary.effects.lsd'></span>

<h3>Description</h3>

<p>This function performs the an elementary effects sensitivity analysis on the sample data produced by a LSD simulation model using the Morris (1991) one-at-a-time sampling method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>elementary.effects.lsd( data, p = 4, jump = 2 )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="elementary.effects.lsd_+3A_data">data</code></td>
<td>

<p>an object created by a previous call to <code><a href="#topic+read.doe.lsd">read.doe.lsd</a></code> which contains all the required experimental data for the analysis.
</p>
</td></tr>
<tr><td><code id="elementary.effects.lsd_+3A_p">p</code></td>
<td>

<p>integer: the number of levels of the DoE as set in LSD when the DoE was configured. The default is 4 (also the LSD default).
</p>
</td></tr>
<tr><td><code id="elementary.effects.lsd_+3A_jump">jump</code></td>
<td>

<p>integer: the size of the jump (increase/decrease) for each point change in the DoE as set in LSD when the DoE was configured. The default is 2 (also the LSD default).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The elementary effects analysis statistics are only meaningful if the DoE was created using the Morris design, as when LSD <code>EE Sampling...</code> option is used to produce the DoE.
</p>
<p>This function is a wrapper to the function <code><a href="sensitivity.html#topic+morris">morris</a></code> in <code><a href="sensitivity.html#topic+sensitivity-package">sensitivity-package</a></code>.
</p>


<h3>Value</h3>

<p>The function returns an object/list of class <code>morris.lsd</code> containing several items, among them:
</p>
<table role = "presentation">
<tr><td><code>table</code></td>
<td>
<p>the elementary effects sensitivity analysis results data.</p>
</td></tr>
</table>
<p>The returned object can also be directly printed or plotted using <code>plot()</code> or any similar function.  See the class <code><a href="sensitivity.html#topic+morris">morris</a></code> for full details, as this class is equivalent to it.
</p>


<h3>Note</h3>

<p>See the note in <a href="#topic+LSDsensitivity-package">LSDsensitivity-package</a> for step-by-step instructions on how to perform the complete sensitivity analysis process using LSD and R.
</p>


<h3>Author(s)</h3>

<p>Marcelo C. Pereira [aut, cre] (&lt;https://orcid.org/0000-0002-8069-2734&gt;)
</p>


<h3>References</h3>

<p>Morris MD (1991) <em>Factorial sampling plans for preliminary computational experiments</em>.Technometrics 33(1):161-174
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.doe.lsd">read.doe.lsd</a></code>,
</p>
<p><code><a href="sensitivity.html#topic+morris">morris</a></code> in <code><a href="sensitivity.html#topic+sensitivity-package">sensitivity-package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># get the example directory name
path &lt;- system.file( "extdata/ee", package = "LSDsensitivity" )

# Steps to use this function:
# 1. define the variables you want to use in the analysis
# 2. load data from a LSD simulation saved results using read.doe.lsd
# 3. perform the elementary effects analysis applying elementary.effects.lsd

lsdVars &lt;- c( "var1", "var2", "var3" )         # the definition of existing variables

dataSet &lt;- read.doe.lsd( path,                 # data files  folder
                         "Sim2",               # data files base name (same as .lsd file)
                         "var1",               # variable name to perform the sensitivity analysis
                         saveVars = lsdVars )  # LSD variables to keep in dataset

SA &lt;- elementary.effects.lsd( dataSet,         # LSD experimental data set
                              p = 4,           # number of levels of the design (as set in LSD)
                              jump = 2 )       # number of jumps per level (as set in LSD)

print( SA )                                    # show analysis table
plot( SA )                                     # plot analysis chart
</code></pre>

<hr>
<h2 id='ergod.test.lsd'>
Stationarity and ergodicity tests
</h2><span id='topic+ergod.test.lsd'></span>

<h3>Description</h3>

<p>Perform a set of stationarity and ergodicity tests useful for simulation model data from a Monte Carlo experiment time series. The included tests are: Augmented Dickey-Fuller test (ADF), Phillips-Perron test (PP),  Kwiatkowski-Phillips-Schmidt-Shin test (KPSS), Brock-Dechert-Scheinkman test (BDS), Kolmogorov-Smirnov k-sample test (KS), Anderson-Darling k-sample test (AD) and Wald-Wolfowitz k-sample test (WW).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ergod.test.lsd( data, vars = dimnames( data )[[ 2 ]],
                start.period = 0, signif = 0.05, digits = 2,
                ad.method = c( "asymptotic", "simulated", "exact" ) )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ergod.test.lsd_+3A_data">data</code></td>
<td>

<p>a three-dimensional array, as the ones produced by <code><a href="LSDinterface.html#topic+read.3d.lsd">read.3d.lsd</a></code>, organized as (time steps x variables x Monte Carlo instances).
</p>
</td></tr>
<tr><td><code id="ergod.test.lsd_+3A_vars">vars</code></td>
<td>

<p>a vector of the variable names (as strings) contained in <code>data</code> for which the tests will be performed. The default is to test all variables.
</p>
</td></tr>
<tr><td><code id="ergod.test.lsd_+3A_start.period">start.period</code></td>
<td>

<p>integer: the first time step in <code>data</code> to be considered for the tests. The default value is 0 (all time steps considered).
</p>
</td></tr>
<tr><td><code id="ergod.test.lsd_+3A_signif">signif</code></td>
<td>

<p>numeric in [0, 1]: statistical significance to evaluate the tests rejection of the null-hypothesis. The default value is 0.05 (5%).
</p>
</td></tr>
<tr><td><code id="ergod.test.lsd_+3A_digits">digits</code></td>
<td>

<p>integer: the number of significant digits to show in results. The default is 2.
</p>
</td></tr>
<tr><td><code id="ergod.test.lsd_+3A_ad.method">ad.method</code></td>
<td>

<p>a string in <code>c("asymptotic", "simulated", "exact")</code> defining the methods to be used by <code><a href="kSamples.html#topic+ad.test">ad.test</a></code>. The default is <code>"asymptotic"</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a wrapper to the functions <code><a href="tseries.html#topic+adf.test">adf.test</a></code>, <code><a href="tseries.html#topic+kpss.test">kpss.test</a></code> and <code><a href="tseries.html#topic+bds.test">bds.test</a></code> in <code>tseries</code> package, <code><a href="stats.html#topic+PP.test">PP.test</a></code> and <code><a href="stats.html#topic+ks.test">ks.test</a></code> in <code><a href="stats.html#topic+stats-package">stats-package</a></code> and <code><a href="kSamples.html#topic+ad.test">ad.test</a></code> in <code><a href="kSamples.html#topic+kSamples-package">kSamples-package</a></code>.
</p>


<h3>Value</h3>

<p>The function returns a data frame presenting both the average test statistics and the frequency of test null-hypothesis rejections for all the variables selected in <code>vars</code>.
Null hypothesis (H0) for ADF and PP tests is non-stationarity of the time series. Null hypothesis (H0) for KPSS test is stationarity of the time series. Null hypothesis (H0) for BDS test the time series is i.i.d.. Null hypothesis (H0) for KS, AD and WW tests is ergodicity of the time series.
</p>


<h3>Author(s)</h3>

<p>Marcelo C. Pereira [aut, cre] (&lt;https://orcid.org/0000-0002-8069-2734&gt;)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+symmet.test.lsd">symmet.test.lsd</a>()</code>,
</p>
<p><code><a href="LSDinterface.html#topic+list.files.lsd">list.files.lsd</a>()</code>, <code><a href="LSDinterface.html#topic+read.3d.lsd">read.3d.lsd</a>()</code> in <code><a href="LSDinterface.html#topic+LSDinterface-package">LSDinterface-package</a></code>,
</p>
<p><code><a href="tseries.html#topic+adf.test">adf.test</a>()</code>,  <code><a href="tseries.html#topic+bds.test">bds.test</a>()</code>, <code><a href="tseries.html#topic+kpss.test">kpss.test</a>()</code>,
</p>
<p><code><a href="stats.html#topic+PP.test">PP.test</a>()</code>, <code><a href="stats.html#topic+ks.test">ks.test</a>()</code> in <code><a href="stats.html#topic+stats-package">stats-package</a>()</code>,
</p>
<p><code><a href="kSamples.html#topic+ad.test">ad.test</a>()</code> in <code><a href="kSamples.html#topic+kSamples-package">kSamples-package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># get the list of file names of example LSD results
library( LSDinterface )
files &lt;- list.files.lsd( system.file( "extdata", package = "LSDsensitivity" ),
                         "Sim1.lsd", recursive = TRUE )

# Steps to use this function:
# 1. load data from a LSD simulation saved results using a read.xxx.lsd
#    function from LSDinterface package (read.3d.lsd, for instance)
# 2. use ergod.test.lsd to apply the tests on the relevant variables,
#    replacing "var2", "var3" etc. with your data

# read data from Monte Carlo runs
dataSet &lt;- read.3d.lsd( files )

tests &lt;- ergod.test.lsd( dataSet,              # the data set to use
                         c( "var2", "var3" ),  # the variables to test
                         signif = 0.01,        # use 1% significance
                         digits = 4 )          # show results using 4 digits

print( tests )
</code></pre>

<hr>
<h2 id='kriging.model.lsd'>
Fit a Kriging meta-model to a LSD model sample data
</h2><span id='topic+kriging.model.lsd'></span>

<h3>Description</h3>

<p>This function fits a Kriging meta-model (also known as a Gaussian process), using five alternative variance kernels and two trend model options, to the sampled data from a LSD simulation model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kriging.model.lsd( data, ext.wgth = 0.5, trendModel = 0, covModel = 0,
                   digits = 4 )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kriging.model.lsd_+3A_data">data</code></td>
<td>

<p>an object created by a previous call to <code><a href="#topic+read.doe.lsd">read.doe.lsd</a></code> which contains all the required experimental data for the analysis.
</p>
</td></tr>
<tr><td><code id="kriging.model.lsd_+3A_ext.wgth">ext.wgth</code></td>
<td>

<p>numeric in [0, 1]: the weight given to the fitting metrics calculated over the out-of-sample (external) validation sample in regard to the in-sample metrics. The default value is 0.5.
</p>
</td></tr>
<tr><td><code id="kriging.model.lsd_+3A_trendmodel">trendModel</code></td>
<td>

<p>a number corresponding to the trend model: 0 = automatic selection (according to fitting metrics, the default); 1 = constant; 2 = first order polynomial.
</p>
</td></tr>
<tr><td><code id="kriging.model.lsd_+3A_covmodel">covModel</code></td>
<td>

<p>a number corresponding to the covariance model (or kernel): 0 = automatic selection (according to fitting metrics, the default); 1 = Matern 5/2; 2 = Matern 3/2; 3 = Gaussian; 4 = exponential; 5 = power exponential.
</p>
</td></tr>
<tr><td><code id="kriging.model.lsd_+3A_digits">digits</code></td>
<td>

<p>integer: the number of significant digits to show in results. The default is 4.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function fits a universal Kriging meta-model to the experimental data set previously loaded with  <code><a href="#topic+read.doe.lsd">read.doe.lsd</a></code> using the Gaussian process method (Rasmussen &amp; Williams, 2006).
</p>
<p>This function is a wrapper to the function <code><a href="DiceKriging.html#topic+km">km</a></code> in <code><a href="DiceKriging.html#topic+DiceKriging-package">DiceKriging-package</a></code>.
</p>


<h3>Value</h3>

<p>The function returns an object/list of class <code>kriging-model</code> containing several items:
</p>
<table role = "presentation">
<tr><td><code>selected</code></td>
<td>
<p>an object containing the selected estimated meta-model (standardized).</p>
</td></tr>
<tr><td><code>comparison</code></td>
<td>
<p>a print-ready table with all fitting statistics for all fitted meta-model specifications.</p>
</td></tr>
<tr><td><code>Q2</code></td>
<td>
<p>the Q2 in-sample fitting statistic for the selected meta-model.</p>
</td></tr>
<tr><td><code>rmse</code></td>
<td>
<p>the RMSE out-of-sample fitting statistic for the selected meta-model.</p>
</td></tr>
<tr><td><code>mae</code></td>
<td>
<p>the MAE out-of-sample fitting statistic for the selected meta-model.</p>
</td></tr>
<tr><td><code>rma</code></td>
<td>
<p>the RMA out-of-sample fitting statistic for the selected meta-model.</p>
</td></tr>
<tr><td><code>extN</code></td>
<td>
<p>number of out-of-sample observations.</p>
</td></tr>
<tr><td><code>estimation</code></td>
<td>
<p>a print-ready table with the coefficients (hyper-parameters) of the selected estimated meta-model.</p>
</td></tr>
<tr><td><code>estimation.std</code></td>
<td>
<p>a print-ready table with the standardized coefficients (hyper-parameters) of the selected estimated meta-model.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>a vector with the coefficients (hyper-parameters) of the selected estimated meta-model.</p>
</td></tr>
<tr><td><code>coefficients.std</code></td>
<td>
<p>a vector with the standardized coefficients (hyper-parameters) of the selected estimated meta-model.</p>
</td></tr>
<tr><td><code>trend</code></td>
<td>
<p>number of the selected trend model.</p>
</td></tr>
<tr><td><code>trendNames</code></td>
<td>
<p>name of the selected trend model.</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>
<p>number of the selected covariance model (kernel).</p>
</td></tr>
<tr><td><code>covNames</code></td>
<td>
<p>name of the selected covariance model (kernel).</p>
</td></tr>
</table>


<h3>Note</h3>

<p>See the note in <a href="#topic+LSDsensitivity-package">LSDsensitivity-package</a> for step-by-step instructions on how to perform the complete sensitivity analysis process using LSD and R.
</p>


<h3>Author(s)</h3>

<p>Marcelo C. Pereira [aut, cre] (&lt;https://orcid.org/0000-0002-8069-2734&gt;)
</p>


<h3>References</h3>

<p>Kleijnen JP (2009) <em>Kriging metamodeling in simulation: a review</em>. Eur J Oper Res 192(3):707-716
</p>
<p>Rasmussen C, Williams C (2006) <em>Gaussian processes for machine learning</em>. MIT Press, Cambridge
</p>
<p>Roustant O, Ginsbourger D, Deville Y (2012) <em>Dicekriging, diceoptim: two R packages for the analysis of computer experiments by kriging-based metamodeling and optimization</em>. J Stat Softw 51(1):1-55
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.doe.lsd">read.doe.lsd</a>()</code>
</p>
<p><code><a href="DiceKriging.html#topic+km">km</a></code> in <code><a href="DiceKriging.html#topic+DiceKriging-package">DiceKriging-package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># get the example directory name
path &lt;- system.file( "extdata/sobol", package = "LSDsensitivity" )

# Steps to use this function:
# 1. define the variables you want to use in the analysis
# 2. load data from a LSD simulation saved results using read.doe.lsd,
#    preferrably using two sets of sampled data (DoEs), one for model
#    estimation and the other for out-of-sample (external) validation
# 3. fit a Kriging (or polynomial) meta-model using kriging.model.lsd

lsdVars &lt;- c( "var1", "var2", "var3" )         # the definition of existing variables

dataSet &lt;- read.doe.lsd( path,                 # data files folder
                         "Sim3",               # data files base name (same as .lsd file)
                         "var3",               # variable name to perform the sensitivity analysis
                         does = 2,             # number of experiments (data + external validation)
                         saveVars = lsdVars )  # LSD variables to keep in dataset

model &lt;- kriging.model.lsd( dataSet )          # estimate best Kriging meta-model

print( model$comparison )                      # model comparison table
print( model$estimation.std )                  # model estimation (standardized) table
</code></pre>

<hr>
<h2 id='model.limits.lsd'>
Find maximum and minimum meta-model responses
</h2><span id='topic+model.limits.lsd'></span>

<h3>Description</h3>

<p>This function identifies the maximum and minimum meta-model response values when exploring a subset of three meta-model factors (parameters): one at a time and jointly changing the first and the second factors. All the remaining factors are kept at default/calibration values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model.limits.lsd( data, model, sa = NULL, factor1 = 1, factor2 = 2,
                  factor3 = 3, pop.size = 1000, max.generations = 30,
                  wait.generations = 10, precision = 1e-05, nnodes = 1 )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="model.limits.lsd_+3A_data">data</code></td>
<td>

<p>an object created by a previous call to <code><a href="#topic+read.doe.lsd">read.doe.lsd</a></code> which contains all the required experimental data for the analysis.
</p>
</td></tr>
<tr><td><code id="model.limits.lsd_+3A_model">model</code></td>
<td>

<p>an object created by a previous call to <code><a href="#topic+kriging.model.lsd">kriging.model.lsd</a></code> or <code><a href="#topic+polynomial.model.lsd">polynomial.model.lsd</a></code> which contains the meta-model estimated hyper-parameters.
</p>
</td></tr>
<tr><td><code id="model.limits.lsd_+3A_sa">sa</code></td>
<td>

<p>an optional object created by a previous call to <code><a href="#topic+sobol.decomposition.lsd">sobol.decomposition.lsd</a></code> which contains the meta-model factors importance used to select the top 3 most influential ones for the analysis.
</p>
</td></tr>
<tr><td><code id="model.limits.lsd_+3A_factor1">factor1</code></td>
<td>

<p>integer: the index (according to the Sobol index table) to the first factor to be evaluated individually and jointly with the second factor. The default is the first (index order) factor. Not used if a <code>sa</code> object is supplied.
</p>
</td></tr>
<tr><td><code id="model.limits.lsd_+3A_factor2">factor2</code></td>
<td>

<p>integer: the index (according to the Sobol index table) to the second factor to be evaluated individually and jointly with the first factor. The default is the second (index order) factor. Not used if a <code>sa</code> object is supplied.
</p>
</td></tr>
<tr><td><code id="model.limits.lsd_+3A_factor3">factor3</code></td>
<td>

<p>integer: the index (according to the Sobol index table) to the third factor to be evaluated only individually. The default is the third (index order) factor. Not used if a <code>sa</code> object is supplied.
</p>
</td></tr>
<tr><td><code id="model.limits.lsd_+3A_pop.size">pop.size</code></td>
<td>

<p>integer: the number of parallel search paths <code><a href="rgenoud.html#topic+genoud">genoud</a></code> uses to solve the optimization problem. The default is 1000.
</p>
</td></tr>
<tr><td><code id="model.limits.lsd_+3A_max.generations">max.generations</code></td>
<td>

<p>integer: the maximum number of generations that <code><a href="rgenoud.html#topic+genoud">genoud</a></code> will run when attempting to optimize a function. The default is 30.
</p>
</td></tr>
<tr><td><code id="model.limits.lsd_+3A_wait.generations">wait.generations</code></td>
<td>

<p>integer: if there is no improvement in the objective function after this number of generations, <code><a href="rgenoud.html#topic+genoud">genoud</a></code> will accept the optimum. The default is 10.
</p>
</td></tr>
<tr><td><code id="model.limits.lsd_+3A_precision">precision</code></td>
<td>

<p>numeric: the tolerance level used by <code><a href="rgenoud.html#topic+genoud">genoud</a></code>. Numbers within <code>precision</code> are considered to be equal. The default is 1e-5.
</p>
</td></tr>
<tr><td><code id="model.limits.lsd_+3A_nnodes">nnodes</code></td>
<td>

<p>integer: the maximum number of parallel computing nodes (parallel threads) in the current computer to be used for reading the files. The default, <code>nnodes = 1</code>, means single thread processing (no parallel threads). If equal to zero, creates up to one node per CPU (physical) core. Only <code>Fork</code> clusters can be used, because <code>PSOCK</code> clusters are not working now, so this option is not available in Windows. Please note that each node requires its own memory space, so memory usage increases linearly with the number of nodes.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function searches for maximum and minimum response surface values by the application of a genetic algorithm (Sekhon &amp; Walter, 1998).
</p>
<p>This function is a wrapper to the function <code><a href="rgenoud.html#topic+genoud">genoud</a></code> in <code>rgenoud</code> package.
</p>


<h3>Value</h3>

<p>The function returns a data frame containing the found limit values.
</p>


<h3>Author(s)</h3>

<p>Marcelo C. Pereira [aut, cre] (&lt;https://orcid.org/0000-0002-8069-2734&gt;)
</p>


<h3>References</h3>

<p>Sekhon JS, Walter RM (1998). <em>Genetic optimization using derivatives: theory and application to nonlinear models</em>. Political Analysis 7:187-210
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.doe.lsd">read.doe.lsd</a>()</code>,
<code><a href="#topic+kriging.model.lsd">kriging.model.lsd</a>()</code>,
<code><a href="#topic+polynomial.model.lsd">polynomial.model.lsd</a>()</code>
</p>
<p><code><a href="rgenoud.html#topic+genoud">genoud</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># get the example directory name
path &lt;- system.file( "extdata/sobol", package = "LSDsensitivity" )

# Steps to use this function:
# 1. define the variables you want to use in the analysis
# 2. load data from a LSD simulation saved results using read.doe.lsd
# 3. fit a Kriging (or polynomial) meta-model using kriging.model.lsd
# 4. identify the most influential factors applying sobol.decomposition.lsd
# 5. find the maximum and minimum response values for the 3 top-influential
#    factors/parameters using model.limits.lsd
# 6. plot the response surface indicating the limit points found

lsdVars &lt;- c( "var1", "var2", "var3" )          # the definition of existing variables

dataSet &lt;- read.doe.lsd( path,                  # data files folder
                         "Sim3",                # data files base name (same as .lsd file)
                         "var3",                # variable name to perform the sensitivity analysis
                         does = 2,              # number of experiments (data + external validation)
                         saveVars = lsdVars )   # LSD variables to keep in dataset

model &lt;- kriging.model.lsd( dataSet )           # estimate best Kriging meta-model

SA &lt;- sobol.decomposition.lsd( dataSet, model ) # find Sobol indexes

limits &lt;- model.limits.lsd( dataSet,            # LSD experimental data set
                            model,              # estimated meta-model
                            SA )                # use top factors found before

print( limits )                                 # print a table with the limits

resp &lt;- response.surface.lsd( dataSet, model, SA )# prepare surfaces data

# plot the 3D surface (top 2 factors)
theta3d &lt;- 310                                  # horizontal view angle
phi3d &lt;- 30                                     # vertical view angle
grid3d &lt;- 25

zMat &lt;- matrix( resp$calib[[ 2 ]]$mean, grid3d, grid3d, byrow = TRUE )
zlim &lt;- range( zMat, na.rm = TRUE )

vt &lt;- persp( resp$grid[[ 1 ]], resp$grid[[ 2 ]], zMat, col = "gray90",
             xlab = colnames( dataSet$doe )[ SA$topEffect[ 1 ] ], zlim = zlim,
             ylab = colnames( dataSet$doe )[ SA$topEffect[ 2 ] ], zlab = dataSet$saVarName,
             theta = theta3d, phi = phi3d, ticktype = "detailed" )

# plot the max, min and default points as colored markers
points( trans3d( as.numeric( dataSet$facDef[ SA$topEffect[ 1 ] ] ),
                 as.numeric( dataSet$facDef[ SA$topEffect[ 2 ] ] ),
                 resp$default$mean, vt ), col = "red", pch = 19, cex = 1.0 )
points( trans3d( limits[ SA$topEffect[ 1 ], 7 ],
                 limits[ SA$topEffect[ 2 ], 7 ],
                 limits[ "response", 7 ], vt ), col = "green", pch = 18, cex = 1.0 )
points( trans3d( limits[ SA$topEffect[ 1 ], 8 ],
                 limits[ SA$topEffect[ 2 ], 8 ],
                 limits[ "response", 8 ], vt ), col = "blue", pch = 18, cex = 1.0 )

</code></pre>

<hr>
<h2 id='model.optim.lsd'>
Find optimal meta-model factor settings
</h2><span id='topic+model.optim.lsd'></span>

<h3>Description</h3>

<p>This function finds the optimal factor (parameter) settings using the estimated meta-model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model.optim.lsd( model, data = NULL, lower.domain = NULL, upper.domain = NULL,
                 starting.values = NULL, minimize = TRUE, pop.size = 1000,
                 max.generations = 30, wait.generations = 10,
                 precision = 1e-05, nnodes = 1 )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="model.optim.lsd_+3A_model">model</code></td>
<td>

<p>an object created by a previous call to <code><a href="#topic+kriging.model.lsd">kriging.model.lsd</a></code> or <code><a href="#topic+polynomial.model.lsd">polynomial.model.lsd</a></code> which contains the meta-model estimated hyper-parameters.
</p>
</td></tr>
<tr><td><code id="model.optim.lsd_+3A_data">data</code></td>
<td>

<p>an optional object created by a previous call to <code><a href="#topic+read.doe.lsd">read.doe.lsd</a></code> which sets the default values for <code>lower.domain</code>, <code>upper.domain</code> and <code>starting.values</code>.
</p>
</td></tr>
<tr><td><code id="model.optim.lsd_+3A_lower.domain">lower.domain</code></td>
<td>

<p>an optional vector or single-line data frame which contains the minimum values to be considered for all the meta-model factors/variables. If <code>data</code> is not provided, the default values are the lower limit ranges from the <code>.sa</code> file set in LSD.
</p>
</td></tr>
<tr><td><code id="model.optim.lsd_+3A_upper.domain">upper.domain</code></td>
<td>

<p>an optional vector or single-line data frame which contains the maximum values to be considered for all the meta-model factors/variables. If <code>data</code> is not provided, the default values are the upper limit ranges from the <code>.sa</code> file set in LSD.
</p>
</td></tr>
<tr><td><code id="model.optim.lsd_+3A_starting.values">starting.values</code></td>
<td>

<p>an optional vector or single-line data frame which contains the starting values to be used by <code><a href="rgenoud.html#topic+genoud">genoud</a></code> for all the meta-model factors/variables. If <code>data</code> is provided, the default values are the calibration settings from the baseline configuration <code>.lsd</code> file set in LSD.
</p>
</td></tr>
<tr><td><code id="model.optim.lsd_+3A_minimize">minimize</code></td>
<td>

<p>logical: set to FALSE to perform maximization. The default is TRUE (minimization).
</p>
</td></tr>
<tr><td><code id="model.optim.lsd_+3A_pop.size">pop.size</code></td>
<td>

<p>integer: the number of parallel search paths <code><a href="rgenoud.html#topic+genoud">genoud</a></code> uses to solve the optimization problem. The default is 1000.
</p>
</td></tr>
<tr><td><code id="model.optim.lsd_+3A_max.generations">max.generations</code></td>
<td>

<p>integer: the maximum number of generations that <code><a href="rgenoud.html#topic+genoud">genoud</a></code> will run when attempting to optimize a function. The default is 30.
</p>
</td></tr>
<tr><td><code id="model.optim.lsd_+3A_wait.generations">wait.generations</code></td>
<td>

<p>integer: if there is no improvement in the objective function after this number of generations, <code><a href="rgenoud.html#topic+genoud">genoud</a></code> will accept the optimum. The default is 10.
</p>
</td></tr>
<tr><td><code id="model.optim.lsd_+3A_precision">precision</code></td>
<td>

<p>numeric: the tolerance level used by <code><a href="rgenoud.html#topic+genoud">genoud</a></code>. Numbers within <code>precision</code> are considered to be equal. The default is 1e-5.
</p>
</td></tr>
<tr><td><code id="model.optim.lsd_+3A_nnodes">nnodes</code></td>
<td>

<p>integer: the maximum number of parallel computing nodes (parallel threads) in the current computer to be used for reading the files. The default, <code>nnodes = 1</code>, means single thread processing (no parallel threads). If equal to zero, creates up to one node per CPU (physical) core. Only <code>Fork</code> clusters can be used, because <code>PSOCK</code> clusters are not working now, so this option is not available in Windows. Please note that each node requires its own memory space, so memory usage increases linearly with the number of nodes.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function searches for maximum and minimum response surface values by the application of a genetic algorithm (Sekhon &amp; Walter, 1998).
</p>
<p>The function can be used to perform any form of optimization by means the user defines the proper objective function to be maximized (or minimized). Any form of objective function can be easily defined as a new variable to the DoE data set when it is created by <code><a href="#topic+read.doe.lsd">read.doe.lsd</a></code>.
</p>
<p>This function is a wrapper to the function <code><a href="rgenoud.html#topic+genoud">genoud</a></code> in <code>rgenoud</code> package.
</p>


<h3>Value</h3>

<p>The function returns a single-line data frame which contains values (in the rows) for all the meta-model factors/variables (in the columns) or NULL if optimization fails.
</p>


<h3>Author(s)</h3>

<p>Marcelo C. Pereira [aut, cre] (&lt;https://orcid.org/0000-0002-8069-2734&gt;)
</p>


<h3>References</h3>

<p>Sekhon JS, Walter RM (1998). <em>Genetic optimization using derivatives: theory and application to nonlinear models</em>. Political Analysis 7:187-210
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.doe.lsd">read.doe.lsd</a>()</code>,
<code><a href="#topic+kriging.model.lsd">kriging.model.lsd</a>()</code>,
<code><a href="#topic+polynomial.model.lsd">polynomial.model.lsd</a>()</code>
</p>
<p><code><a href="rgenoud.html#topic+genoud">genoud</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># get the example directory name
path &lt;- system.file( "extdata/sobol", package = "LSDsensitivity" )

# Steps to use this function:
# 1. define the variables you want to use in the analysis
# 2. load data from a LSD simulation saved results using read.doe.lsd
# 3. fit a Kriging (or polynomial) meta-model using kriging.model.lsd
# 4. find the factor configuration that produce the minimum (or maximum)
#    value for the analysis variable defined in step 2

lsdVars &lt;- c( "var1", "var2", "var3" )         # the definition of existing variables

dataSet &lt;- read.doe.lsd( path,                 # data files folder
                         "Sim3",               # data files base name (same as .lsd file)
                         "var3",               # variable name to perform the sensitivity analysis
                         does = 2,             # number of experiments (data + external validation)
                         saveVars = lsdVars )  # LSD variables to keep in dataset

model &lt;- kriging.model.lsd( dataSet )          # estimate best Kriging meta-model

config &lt;- model.optim.lsd( model,              # find meta-model configuration for minimum response
                           dataSet )           # use the full range of factors and starting from
                                               # calibration
print( config )

</code></pre>

<hr>
<h2 id='model.pred.lsd'>
Predict meta-model response at given point(s)
</h2><span id='topic+model.pred.lsd'></span>

<h3>Description</h3>

<p>This function predicts the meta-model response at a specific point(s) in the factor (parameter) space and provides a confidence interval for the prediction(s) at 95% confidence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model.pred.lsd( data.point, model )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="model.pred.lsd_+3A_data.point">data.point</code></td>
<td>

<p>a single or multi line data frame which contains values (in the rows) for all the meta-model factors/variables (in the columns).
</p>
</td></tr>
<tr><td><code id="model.pred.lsd_+3A_model">model</code></td>
<td>

<p>an object created by a previous call to <code><a href="#topic+kriging.model.lsd">kriging.model.lsd</a></code> or <code><a href="#topic+polynomial.model.lsd">polynomial.model.lsd</a></code> which contains the meta-model estimated hyper-parameters.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function simply evaluate the meta-model value at the given point. All factor values must be specified. <code>data.point</code> can also be specified as an ordered vector or matrix, following the same order for the factors as defined in the meta-model specification.
</p>
<p>This function is a wrapper to the functions <code><a href="DiceKriging.html#topic+predict.km">predict.km</a></code> in <code><a href="DiceKriging.html#topic+DiceKriging-package">DiceKriging-package</a></code> and <code><a href="stats.html#topic+predict.lm">predict.lm</a></code> in <code><a href="stats.html#topic+stats-package">stats-package</a></code>.
</p>


<h3>Value</h3>

<p>The function returns a list containing the prediction(s) and the confidence bounds. If <code>data.point</code> is a data frame or matrix with more than one line, the list elements are vectors. The list element names are:
</p>
<table role = "presentation">
<tr><td><code>mean</code></td>
<td>
<p>the expected response value.</p>
</td></tr>
<tr><td><code>lower</code></td>
<td>
<p>the lower confidence bound.</p>
</td></tr>
<tr><td><code>upper</code></td>
<td>
<p>the upper confidence bound.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marcelo C. Pereira [aut, cre] (&lt;https://orcid.org/0000-0002-8069-2734&gt;)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kriging.model.lsd">kriging.model.lsd</a>()</code>,
<code><a href="#topic+polynomial.model.lsd">polynomial.model.lsd</a>()</code>
</p>
<p><code><a href="DiceKriging.html#topic+predict.km">predict.km</a></code> in <code><a href="DiceKriging.html#topic+DiceKriging-package">DiceKriging-package</a></code>,
<code><a href="stats.html#topic+predict.lm">predict.lm</a></code> in <code><a href="stats.html#topic+stats-package">stats-package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># get the example directory name
path &lt;- system.file( "extdata/sobol", package = "LSDsensitivity" )

# Steps to use this function:
# 1. define the variables you want to use in the analysis
# 2. load data from a LSD simulation saved results using read.doe.lsd
# 3. fit a Kriging (or polynomial) meta-model using kriging.model.lsd
# 4. estimate the meta-model response at any set of points applying
#    model.pred.lsd

lsdVars &lt;- c( "var1", "var2", "var3" )         # the definition of existing variables

dataSet &lt;- read.doe.lsd( path,                 # data files folder
                         "Sim3",               # data files base name (same as .lsd file)
                         "var3",               # variable name to perform the sensitivity analysis
                         does = 2,             # number of experiments (data + external validation)
                         saveVars = lsdVars )  # LSD variables to keep in dataset

model &lt;- kriging.model.lsd( dataSet )          # estimate best Kriging meta-model

# creates a set of four random points in parameter space
points &lt;- data.frame( par1 = rnorm( 4 ), par2 = rnorm( 4 ), par3 = rnorm( 4 ) )

response &lt;- model.pred.lsd( points, model )    # predict model response at the 3 points

print( points )
print( response )
</code></pre>

<hr>
<h2 id='polynomial.model.lsd'>
Fit a polynomial meta-model to a LSD model sample data
</h2><span id='topic+polynomial.model.lsd'></span>

<h3>Description</h3>

<p>This function fits a Polynomial meta-model of first or second order, with or without interactions, to the sampled data from a LSD simulation model. Polynomial meta-models are usually inadequate to fit nonlinear simulation models, please use the estimated meta-model carefully.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polynomial.model.lsd( data, ext.wgth = 0.5, ols.sig = 0.2,
                      orderModel = 0, interactModel = 0, digits = 4 )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="polynomial.model.lsd_+3A_data">data</code></td>
<td>

<p>an object created by a previous call to <code><a href="#topic+read.doe.lsd">read.doe.lsd</a></code> which contains all the required experimental data for the analysis.
</p>
</td></tr>
<tr><td><code id="polynomial.model.lsd_+3A_ext.wgth">ext.wgth</code></td>
<td>

<p>numeric in [0, 1]: the weight given to the fitting metrics calculated over the out-of-sample (external) validation sample in regard to the in-sample metrics. The default value is 0.5.
</p>
</td></tr>
<tr><td><code id="polynomial.model.lsd_+3A_ols.sig">ols.sig</code></td>
<td>

<p>numeric in [0, 1]: the minimum significance considered in the OLS regression.
</p>
</td></tr>
<tr><td><code id="polynomial.model.lsd_+3A_ordermodel">orderModel</code></td>
<td>

<p>a number corresponding to the polynomial model order: 0 = automatic selection (according to fitting metrics, the default); 1 = first order; 2 = second order.
</p>
</td></tr>
<tr><td><code id="polynomial.model.lsd_+3A_interactmodel">interactModel</code></td>
<td>

<p>a number indicating the presence of interaction terms in the model: 0 = automatic selection (according to fitting metrics, the default); 1 = no , 2 = yes.
</p>
</td></tr>
<tr><td><code id="polynomial.model.lsd_+3A_digits">digits</code></td>
<td>

<p>integer: the number of significant digits to show in results. The default is 4.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function fits a polynomial meta-model to the experimental data set previously loaded with  <code><a href="#topic+read.doe.lsd">read.doe.lsd</a></code> using the ordinary least-squares (OLS) method.
</p>
<p>This function is a wrapper to the function <code><a href="stats.html#topic+lm">lm</a></code> in <code><a href="stats.html#topic+stats-package">stats-package</a></code>.
</p>


<h3>Value</h3>

<p>The function returns an object/list of class <code>polynomial-model</code> containing several items:
</p>
<table role = "presentation">
<tr><td><code>selected</code></td>
<td>
<p>an object containing the selected estimated meta-model.</p>
</td></tr>
<tr><td><code>comparison</code></td>
<td>
<p>a print-ready table with all fitting statistics for all fitted meta-model specifications.</p>
</td></tr>
<tr><td><code>R2</code></td>
<td>
<p>the adjusted R2 in-sample fitting statistic for the selected meta-model.</p>
</td></tr>
<tr><td><code>rmse</code></td>
<td>
<p>the RMSE out-of-sample fitting statistic for the selected meta-model.</p>
</td></tr>
<tr><td><code>mae</code></td>
<td>
<p>the MAE out-of-sample fitting statistic for the selected meta-model.</p>
</td></tr>
<tr><td><code>rma</code></td>
<td>
<p>the RMA out-of-sample fitting statistic for the selected meta-model.</p>
</td></tr>
<tr><td><code>extN</code></td>
<td>
<p>number of out-of-sample observations.</p>
</td></tr>
<tr><td><code>estimation</code></td>
<td>
<p>a print-ready table with the coefficients (hyper-parameters) of the selected estimated meta-model.</p>
</td></tr>
<tr><td><code>estimation.std</code></td>
<td>
<p>a print-ready table with the standardized coefficients (hyper-parameters) of the selected estimated meta-model.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>a vector with the coefficients (hyper-parameters) of the selected estimated meta-model.</p>
</td></tr>
<tr><td><code>coefficients.std</code></td>
<td>
<p>a vector with the standardized coefficients (hyper-parameters) of the selected estimated meta-model.</p>
</td></tr>
<tr><td><code>order</code></td>
<td>
<p>order of the selected polynomial model.</p>
</td></tr>
<tr><td><code>polyNames</code></td>
<td>
<p>name of the selected polynomial model.</p>
</td></tr>
<tr><td><code>interact</code></td>
<td>
<p>number of the selected interaction mode.</p>
</td></tr>
<tr><td><code>interactNames</code></td>
<td>
<p>name of the selected interaction mode.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>See the note in <a href="#topic+LSDsensitivity-package">LSDsensitivity-package</a> for step-by-step instructions on how to perform the complete sensitivity analysis process using LSD and R.
</p>


<h3>Author(s)</h3>

<p>Marcelo C. Pereira [aut, cre] (&lt;https://orcid.org/0000-0002-8069-2734&gt;)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.doe.lsd">read.doe.lsd</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># get the example directory name
path &lt;- system.file( "extdata/sobol", package = "LSDsensitivity" )

# Steps to use this function:
# 1. define the variables you want to use in the analysis
# 2. load data from a LSD simulation saved results using read.doe.lsd,
#    preferrably using two sets of sampled data (DoEs), one for model
#    estimation and the other for out-of-sample (external) validation
# 3. fit the polynomial meta-model using polynomial.model.lsd

lsdVars &lt;- c( "var1", "var2", "var3" )         # the definition of existing variables

dataSet &lt;- read.doe.lsd( path,                 # data files folder
                         "Sim3",               # data files base name (same as .lsd file)
                         "var3",               # variable name to perform the sensitivity analysis
                         does = 2,             # number of experiments (data + external validation)
                         saveVars = lsdVars )  # LSD variables to keep in dataset

model &lt;- polynomial.model.lsd( dataSet )       # estimate best polynomial meta-model
                                               # using defaults (auto model selection)

print( model$comparison )                      # model comparison table
print( model$estimation.std )                  # model estimation (standardized) table
</code></pre>

<hr>
<h2 id='read.doe.lsd'>
Read a set of experimental data from a LSD model
</h2><span id='topic+read.doe.lsd'></span>

<h3>Description</h3>

<p>This function reads the sampling data produced by a LSD model design of experiment (DoE), pre-process it and saves it as a R object that can be used by the other tools provided by the LSDsensitivity package. Optionally, it can be used with a second DoE, on the same simulation model, to allow the out-of-sample (external) validation of the fitted meta-models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.doe.lsd( folder, baseName, outVar = "", does = 1, doeFile = NULL,
              respFile = NULL, validFile = NULL, valRespFile = NULL,
              confFile = NULL, limFile = NULL, iniDrop = 0, nKeep = -1,
              saveVars = NULL, addVars = NULL, eval.vars = NULL,
              eval.run = NULL, eval.stat = c( "mean", "median" ),
              pool = TRUE, na.rm = FALSE, rm.temp = TRUE, rm.outl = FALSE,
              lim.outl = 10, nnodes = 1, quietly = TRUE, instance = 1,
              posit = NULL, posit.match = c( "fixed", "glob", "regex" ) )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read.doe.lsd_+3A_folder">folder</code></td>
<td>

<p>the <em>relative</em> folder path to the LSD DoE data files, using the R working directory as reference (see <code><a href="base.html#topic+getwd">getwd</a>()</code>).
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_basename">baseName</code></td>
<td>

<p>the LSD data files base name, without numbering and extension suffixes (should be the same as the name of the baseline <code>.lsd</code> file, without the extension). If <code>.lsd</code> extension is included, it is automatically removed.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_outvar">outVar</code></td>
<td>

<p>the name of an <em>existing</em> variable to be used as the reference to perform the sensitivity analysis. If no name is supplied, the default is to use the first element of <code>saveVars</code> or <code>addVars</code>.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_does">does</code></td>
<td>

<p>1 or 2: number of experiments to be processed, being 2 only when one additional external validation sample (independent from the main sample) is available (see the required files below). The default is 1.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_doefile">doeFile</code></td>
<td>

<p>the DoE specification file to be used. For the default (NULL), the <code>baseName</code> is used to generate the default LSD generated name.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_respfile">respFile</code></td>
<td>

<p>the DoE response file to be used/created. For the default (NULL), the <code>baseName</code> is used to generate the name.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_validfile">validFile</code></td>
<td>

<p>the external validation DoE specification file to be used. For the default (NULL), the <code>baseName</code> is used to generate the default LSD generated name.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_valrespfile">valRespFile</code></td>
<td>

<p>the external validation DoE response file to be used/created. For the default (NULL), the <code>baseName</code> is used to generate the name.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_conffile">confFile</code></td>
<td>

<p>the LSD baseline <code>.lsd</code> configuration file. The default (NULL) is to use <code>baseName.lsd</code>.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_limfile">limFile</code></td>
<td>

<p>the LSD factor limit ranges <code>.sa</code> file. The default (NULL) is to use <code>baseName.sa</code>.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_inidrop">iniDrop</code></td>
<td>

<p>integer: the number of initial time steps to drop from analysis (from <code>t = 1</code> till <code>t = iniDrop</code>). The default (0) is to remove no time step.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_nkeep">nKeep</code></td>
<td>

<p>integer: the total number of time steps to keep after <code>iniDrop</code>, if simulation length is longer than <code>nKeep</code> discard data from the end of the simulation. The default (-1) is to preserve all data.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_savevars">saveVars</code></td>
<td>

<p>a vector of existing LSD variable names to be kept in the data set. The default (<code>NULL</code>) is to save just <code>outVar</code>, if supplied. At least one existing or new variable (defined by <code>addVars</code>) must exist. <code>saveVars</code> also defines the variables which are available for processing by the function defined by <code>eval.vars</code>, the default <code>saveVars = c()</code> representing all variables in the results files. For large datasets, this parameter allow reducing the memory required by not loading unnecessary data into memory.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_addvars">addVars</code></td>
<td>

<p>a vector of new LSD variable names to be added to the data set. The default (<code>NULL</code>) is to add none. At least one existing or new variable must exist.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_eval.vars">eval.vars</code></td>
<td>

<p>a function to recalculate any item of the imported data set, including added variables. The default (NULL) is to have no function (just use selected existing variables as is). If defined, function must take two arguments: the data set for a specific DoE point (time steps in the rows) and the list of variables (columns) in the data set. The function may change any value within the data set but <em>should not</em> add or remove rows or columns.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_eval.run">eval.run</code></td>
<td>

<p>a function to evaluate the DoE response for each experimental sampling point, attributing an optional value to it. The default (NULL) is to have no function. In this case, the function uses the selected variable Monte Carlo mean and standard deviation, or the median and the median absolute deviation if <code>median = TRUE</code>, to value the point. If defined, function must take four arguments: (a) the data set (a 3-dimensional array of lists, the numbers of the DoE sampling points in the first dimension, variables in the second, and Monte Carlo runs in the in the third, being each list element a vector with all time-step values for that sample/variable/MC run), (b) the number of the DoE sampling point to evaluate, (c) the index to the analysis variable in the data set, and (d) the applicable confidence interval. The function must return a R list containing four values for the selected sampling point/variable pair: (a) the average value for the response, (b) the response standard deviation, (c) the the number of observations used, and (d) the number of observations discarded.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_eval.stat">eval.stat</code></td>
<td>

<p>character: define the statistics to be used to evaluate the DoE response when <code>eval.run = NULL</code>. Options are <code>"mean"</code> to use the mean and the standard deviation (default), or <code>"median"</code>, to use the median and the median absolute deviation (MAD). Names can be abbreviated. If an evaluation function is provided in <code>eval.run</code>, this option is ignored.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_na.rm">na.rm</code></td>
<td>

<p>logical: if TRUE NA values are stripped before the computation proceeds.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_rm.temp">rm.temp</code></td>
<td>

<p>logical: if <code>TRUE</code> (default), remove response and temporary speed up files. If <code>FALSE</code>, do not remove response and temporary speed up files, allowing fast execution of subsequent call to this function. Please note that when set to FALSE, the user <em>must</em> temporary files (extension <code>.Rdata</code>) manually whenever LSD data files are updated, so they are re-read. This can be done by simply turning <code>rm.temp</code> to TRUE once.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_rm.outl">rm.outl</code></td>
<td>

<p>logical: if <code>TRUE</code>, remove outliers from data set. Default is <code>FALSE</code>, no outliers removal.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_lim.outl">lim.outl</code></td>
<td>

<p>numeric: if <code>rm.outl = TRUE</code>, defines the limit for non-outliers deviation in number of standard deviations.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_nnodes">nnodes</code></td>
<td>

<p>integer: the maximum number of parallel computing nodes (parallel threads) in the current computer to be used for reading the files. The default, <code>nnodes = 1</code>, means single thread processing (no parallel threads). If equal to zero, creates up to one node per CPU core. Only <code>PSOCK</code> clusters are used, to ensure compatibility with any platform. Please note that each node requires its own memory space, so memory usage increases linearly with the number of nodes.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_quietly">quietly</code></td>
<td>

<p>logical: if <code>TRUE</code>, no message confirming file reading/information is printed. The default (<code>FALSE</code>) is to show details about each results file read.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_pool">pool</code></td>
<td>

<p>logical: if <code>TRUE</code> (default), create a simpler data array, pooling together only a single instance for each variable. The instance to be considered is provided by <code>instance</code>. If <code>FALSE</code>, use all variable instances, which are treated as a single one (indeed, pooling all values...). More control over which instances are used can be obtained by simultaneously using <code>posit</code>.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_instance">instance</code></td>
<td>

<p>integer: the instance of the variable to be read, for variables that exist in more than one object. This number is based on the relative position (column) of the variable in the results file. The default (1) is to read the first instance. Only a single existing instance at a time can be read for analysis.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_posit">posit</code></td>
<td>

<p>a string, a vector of strings or an integer vector describing the LSD object position of the variable(s) to select. If an integer vector, it should define the position of a SINGLE LSD object. If a string or vector of strings, each element should define one or more different LSD objects, so the returning matrix may contain variables from more than one object. By setting <code>posit.match</code>, globbing (wildcard), and regular expressions can be used to select multiple objects at once; in this case, all matching objects are selected, but only the instance defined by <code>instance</code> is used.
</p>
</td></tr>
<tr><td><code id="read.doe.lsd_+3A_posit.match">posit.match</code></td>
<td>

<p>a string defining how the <code>posit</code> argument, if provided, should be matched against the LSD object positions. If equal to <code>"fixed"</code>, the default, only exact matching is done. <code>"glob"</code> allows using simple wildcard characters ('*' and '?') in <code>posit</code> for matching. If <code>posit.match="regex"</code> interpret <code>posit</code> as POSIX 1003.2 extended regular expression(s). See <code><a href="base.html#topic+regex">regular expressions</a></code> for details of the different types of regular expressions. Options can be abbreviated.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function reuses any existing response file(s) (for the main and the optional external validation DoEs) or try to create it (them) if not existing. The response files can be created in relation to any existing, modified or new variable from any simulated time step, including complex combinations of those. New and modified variables (w.r.t. the ones available from LSD) can be easily created by the definition of a <code>eval.vars(data, varList)</code> function, as shown in the example below. The response values for each sampling point in the DoE(s) can be evaluated using any math/statistical technique over the entire data for each sampled point in every Monte Carlo run by the definition of a <code>eval.run(data, mc.run, var.idx, ci)</code>, as in the example below.
</p>
<p>Each call to the function can process a single variable. If sensitivity analysis is being performed on multiple variables, the function must be called several times. However, if <code>rm.tmp = FALSE</code> the processing time from the second variable is significantly shortened.
</p>
<p>This function requires that the complete set of LSD DoE data files be stored in a single folder/directory. The list of required files is the following (<code>XX</code>, <code>YY</code> and <code>ZZ</code> are sequential control numbers produced by LSD, <code>i = 0, 1,...</code>):
</p>
<pre>
folder/baseName.lsd              : LSD baseline configuration (1 file)
folder/baseName.sa               : factor ranges (1 file)
folder/baseName_XX_YY.csv        : DoE specification (1 file)
folder/baseName_XX+i.res[.gz]]   : DoE data (YY-XX+1 files)
folder/baseName_YY+1_ZZ.csv      : validation specification (optional - 1 file)
folder/baseName_YY+1+i.res[.gz]  : validation data (optional - ZZ-YY+1 files)
</pre>
<p>The function generates the required response files for the selected variable of analysis and produces the following files in the same folder/directory (<code>WWW</code> is the name of the selected analysis variable):
</p>
<pre>
folder/baseName_XX_YY_WWW.csv    : DoE response for the selected variable (1 file)
folder/baseName_YY+1_ZZ_WWW.csv  : validation response for variable (optional - 1 file)
</pre>
<p>When <code>posit</code> is supplied together with <code>col.names</code> or <code>instance</code>, the variable selection process is done in two steps. Firstly, the column names set by <code>saveVars</code> and <code>instance</code> are selected. Secondly, the instances defined by <code>posit</code> are selected from the first selection set. See <code><a href="LSDinterface.html#topic+select.colnames.lsd">select.colnames.lsd</a></code> and <code><a href="LSDinterface.html#topic+select.colattrs.lsd">select.colattrs.lsd</a></code> for examples on how to apply advanced selection options.
</p>


<h3>Value</h3>

<p>The function returns an object/list of class <code>lsd-doe</code> containing all the experimental data and the corresponding results regarding the selected reference variable <code>outVar</code>, including the data for the out-of-sample (external) validation of the produced meta-models, if available, as well the DoE(s) details required by the package meta-modelling tools (<code><a href="#topic+elementary.effects.lsd">elementary.effects.lsd</a></code>, <code><a href="#topic+kriging.model.lsd">kriging.model.lsd</a></code>, and <code><a href="#topic+polynomial.model.lsd">polynomial.model.lsd</a></code>).
</p>
<p>List components:
</p>
<table role = "presentation">
<tr><td><code>doe</code></td>
<td>
<p>the DoE data. Can be a tabular data frame if <code>pool = TRUE</code> or a four-dimensional array otherwise.</p>
</td></tr>
<tr><td><code>resp</code></td>
<td>
<p>the DoE response data table.</p>
</td></tr>
<tr><td><code>valid</code></td>
<td>
<p>the external validation DoE data. Can be a tabular data frame if <code>pool = TRUE</code> or a four-dimensional array otherwise.</p>
</td></tr>
<tr><td><code>valResp</code></td>
<td>
<p>the external validation DoE response data table.</p>
</td></tr>
<tr><td><code>facLim</code></td>
<td>
<p>the factors limit ranges table.</p>
</td></tr>
<tr><td><code>facLimLo</code></td>
<td>
<p>the factors minimum values.</p>
</td></tr>
<tr><td><code>facLimUp</code></td>
<td>
<p>the factors maximum values.</p>
</td></tr>
<tr><td><code>facDef</code></td>
<td>
<p>the factors default/calibration values.</p>
</td></tr>
<tr><td><code>saVarName</code></td>
<td>
<p>the sensitivity analysis reference variable name, as defined by <code>outVar</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>See the note in <a href="#topic+LSDsensitivity-package">LSDsensitivity-package</a> for step-by-step instructions on how to perform the complete sensitivity analysis process using LSD and R.
</p>
<p>Please refer to LSD documentation about the details on the files produced by its sensitivity analysis tools, in particular when using NOLH, Elementary Effects and MC Range Sensitivity Analysis sampling:
</p>
<p>LSD documentation is available at <a href="https://www.labsimdev.org/">https://www.labsimdev.org/</a> and the latest binaries and source code can be downloaded at <a href="https://github.com/marcov64/Lsd/">https://github.com/marcov64/Lsd/</a>.
</p>


<h3>Author(s)</h3>

<p>Marcelo C. Pereira [aut, cre] (&lt;https://orcid.org/0000-0002-8069-2734&gt;)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+elementary.effects.lsd">elementary.effects.lsd</a>()</code>,
<code><a href="#topic+kriging.model.lsd">kriging.model.lsd</a>()</code>,
<code><a href="#topic+polynomial.model.lsd">polynomial.model.lsd</a>()</code>
<code><a href="LSDinterface.html#topic+list.files.lsd">list.files.lsd</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># get the example directory name
path &lt;- system.file( "extdata/sobol", package = "LSDsensitivity" )

# Steps to use this function:
# 1. define the variables you want to use in the analysis
# 2. optionally, define special handling functions (see examples below)
# 3. load data from a LSD simulation saved results using read.doe.lsd
# 4. perform the elementary effects analysis applying elementary.effects.lsd

# the definition of existing, to take log and to be added variables
lsdVars &lt;- c( "var1", "var2", "var3" )
logVars &lt;- c( "var1", "var3" )
newVars &lt;- c( "var4" )

# load data from a LSD simulation baseline configuration named "Sim1.lsd" to
# perform sensitivity analysis on the variable named "var1"
# there are two groups of sampled data (DoEs) created by LSD being read
# just use no handling functions for now, see possible examples below
dataSet &lt;- read.doe.lsd( path,                 # data files folder
                         "Sim3",               # data files base name (same as .lsd file)
                         "var3",               # variable name to perform the sens. analysis
                         does = 2,             # # of experiments (data + external validation)
                         iniDrop = 0,          # initial time steps to drop (0=none)
                         nKeep = -1,           # number of time steps to keep (-1=all)
                         saveVars = lsdVars,   # LSD variables to keep in dataset
                         addVars = newVars,    # new variables to add to the LSD dataset
                         eval.stat = "median", # use median to evaluate runs
                         rm.temp = FALSE,      # reuse temporary speedup files
                         rm.outl = FALSE,      # remove outliers from dataset
                         lim.outl = 10,        # limit non-outliers deviation (# of std. devs.)
                         quietly = FALSE )     # show information during processing
print( dataSet$doe )            # the design of the experiment sample done in LSD
print( dataSet$valid )          # the extenal validation sample
print( dataSet$saVarName )      # the variable for which the response was analyzed
print( dataSet$resp )           # analysis of the response of the selected variable

#### OPTIONAL HANDLING FUNCTION EXAMPLES ####

# eval.vars( ) EXAMPLE 1
# the definition of a function to take the log of the required variables () and
# compute the new ones (for use on pool = TRUE databases)

eval.vars &lt;- function( dataSet, allVars ) {
  tsteps &lt;- nrow( dataSet )        # number of time steps in simulated data set
  nvars &lt;- ncol( dataSet )         # number of variables in data set (including new ones)

  # ---- Recompute values for existing variables ----
  for( var in allVars ) {
    if( var %in% logVars ) {     # take the log values of selected variables
      try( dataSet[ , var ] &lt;- log( dataSet[ , var ] ), silent = TRUE )  # &lt;= 0 as NaN
    }
  }

  # ---- Calculate values of new variables (added to LSD data set) ----
  dataSet[ , "var4" ] &lt;- dataSet[ , "var1" ] + dataSet[ , "var2" ]   # example of new var

  return( dataSet )
}

# load data again, now using new variable v4 for analysis
dataSet &lt;- read.doe.lsd( path,                 # data files folder
                         "Sim3",               # data files base name (same as .lsd file)
                         "var4",               # variable name to perform the sens. analysis
                         does = 2,             # # of experiments (data + external validation)
                         iniDrop = 0,          # initial time steps to drop (0=none)
                         nKeep = -1,           # number of time steps to keep (-1=all)
                         saveVars = lsdVars,   # LSD variables to keep in dataset
                         addVars = newVars,    # new variables to add to the LSD dataset
                         eval.vars = eval.vars,# function to evaluate/adjust/expand the dataset
                         rm.temp = TRUE,       # remove temporary speedup files
                         rm.outl = FALSE,      # remove outliers from dataset
                         lim.outl = 10 )       # limit non-outliers deviation (# of std. devs.)
print( dataSet$doe )            # the design of the experiment sample done in LSD
print( dataSet$valid )          # the external validation sample
print( dataSet$saVarName )      # the variable for which the response was analyzed
print( dataSet$resp )           # analysis of the response of the selected variable

# eval.vars( ) EXAMPLE 2
# the definition of a function to compute the new variables
# (for use on pool = FALSE databases)

# ---- 4D data frame version (when pool = FALSE) ----

eval.vars &lt;- function( data, vars ) {
  tsteps &lt;- length( data [ , 1, 1, 1 ] )
  nvars &lt;- length( data [ 1, , 1, 1 ] )
  insts &lt;- length( data [ 1, 1, , 1 ] )
  samples &lt;- length( data [ 1, 1, 1, ] )

  # ---- Compute values for new variables, preventing infinite values ----
  for( m in 1 : samples )               # for all MC samples (files)
    for( j in 1 : insts )               # all instances
      for( i in 1 : tsteps )            # all time steps
        for( var in vars ) {            # and all variables

          if( var == "var4" ) {
            # Normalization of key variables using the period average size
            mean &lt;- mean( data[ i, "var2", , m ], na.rm = TRUE )
            if( is.finite ( mean ) &amp;&amp; mean != 0 )
              data[ i, var, j, m ] &lt;- data[ i,"var2", j, m ] / mean
            else
              data[ i, var, j, m ] &lt;- NA
          }
        }
  return( data )
}

# load data again, now using new variable var2 for analysis
dataSet &lt;- read.doe.lsd( path,                 # data files folder
                         "Sim3",               # data files base name (same as .lsd file)
                         "var2",               # variable name to perform the sens. analysis
                         does = 2,             # # of experiments (data + external validation)
                         iniDrop = 0,          # initial time steps to drop (0=none)
                         nKeep = -1,           # number of time steps to keep (-1=all)
                         pool = FALSE,         # don't pool MC runs
                         saveVars = lsdVars,   # LSD variables to keep in dataset
                         addVars = newVars,    # new variables to add to the LSD dataset
                         eval.vars = eval.vars,# function to evaluate/adjust/expand the dataset
                         rm.temp = TRUE,       # remove temporary speedup files
                         rm.outl = FALSE,      # remove outliers from dataset
                         lim.outl = 10 )       # limit non-outliers deviation (# of std. devs.)
print( dataSet$doe )            # the design of the experiment sample done in LSD
print( dataSet$valid )          # the external validation sample
print( dataSet$saVarName )      # the variable for which the response was analyzed
print( dataSet$resp )           # analysis of the response of the selected variable

# eval.run( ) EXAMPLE
# the definition of a function to evaluate a point in the DoE, associating a result
# with it (in terms of average result and dispersion/S.D.)
# the example evaluates the fat-taildness of the distribution of the selected
# variable, using the Subbotin distribution b parameter as metric (response)

library( normalp )

eval.run &lt;- function( data, run, varIdx, conf ) {

  obs &lt;- discards &lt;- 0

  # ------ Compute Subbotin fits for each run ------
  bSubbo &lt;- rep( NA, dim( data )[ 3 ] )
  for( i in 1 : dim( data )[ 3 ] ) {
    x &lt;- data[[ run, varIdx, i ]]
    sf &lt;- paramp( x )
    sf$p &lt;- estimatep( x, mu = sf$mean, p = sf$p, method = "inverse" )
    if( sf$p &gt;= 1 ) {
      bSubbo[ i ] &lt;- sf$p
      obs &lt;- obs + 1
    } else {
      bSubbo[ i ] &lt;- NA
      discards &lt;- discards + 1
    }
  }

  return( list( mean( bSubbo, na.rm = TRUE ),
                var( bSubbo, na.rm = TRUE ), obs, discards ) )
}

# load data again, now using the defined evaluation function
dataSet &lt;- read.doe.lsd( path,                 # data files folder
                         "Sim3",               # data files base name (same as .lsd file)
                         "var2",               # variable name to perform the sens. analysis
                         does = 2,             # # of experiments (data + external validation)
                         iniDrop = 0,          # initial time steps to drop (0=none)
                         nKeep = -1,           # number of time steps to keep (-1=all)
                         saveVars = lsdVars,   # LSD variables to keep in dataset
                         addVars = newVars,    # new variables to add to the LSD dataset
                         eval.run = eval.run,  # function to evaluate the DoE point response
                         rm.temp = TRUE,       # remove temporary speedup files
                         rm.outl = FALSE,      # remove outliers from dataset
                         lim.outl = 10 )       # limit non-outliers deviation (# of std. devs.)
print( dataSet$doe )            # the design of the experiment sample done in LSD
print( dataSet$valid )          # the external validation sample
print( dataSet$saVarName )      # the variable for which the response was analyzed
print( dataSet$resp )           # analysis of the response of the selected variable
</code></pre>

<hr>
<h2 id='response.surface.lsd'>
Generate the meta-model 3D response surface data
</h2><span id='topic+response.surface.lsd'></span>

<h3>Description</h3>

<p>This function produces a data object for the three-dimensional graphical representations of the meta-model response surfaces for a set of factors (parameters), including the confidence interval for the surfaces.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>response.surface.lsd( data, model, sa, gridSz = 25, defPos = 2,
                      factor1 = 0, factor2 = 0, factor3 = 0 )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="response.surface.lsd_+3A_data">data</code></td>
<td>

<p>an object created by a previous call to <code><a href="#topic+read.doe.lsd">read.doe.lsd</a></code> which contains all the required experimental data for the analysis.
</p>
</td></tr>
<tr><td><code id="response.surface.lsd_+3A_model">model</code></td>
<td>

<p>an object created by a previous call to <code><a href="#topic+kriging.model.lsd">kriging.model.lsd</a></code> or <code><a href="#topic+polynomial.model.lsd">polynomial.model.lsd</a></code> which contains the meta-model estimated hyper-parameters.
</p>
</td></tr>
<tr><td><code id="response.surface.lsd_+3A_sa">sa</code></td>
<td>

<p>an object created by a previous call to <code><a href="#topic+sobol.decomposition.lsd">sobol.decomposition.lsd</a></code> which contains the estimated total and conditional variances for all the meta-model factors.
</p>
</td></tr>
<tr><td><code id="response.surface.lsd_+3A_gridsz">gridSz</code></td>
<td>

<p>integer: the number of divisions in the 3D wire frame grid. The default is 25.
</p>
</td></tr>
<tr><td><code id="response.surface.lsd_+3A_defpos">defPos</code></td>
<td>

<p>1, 2, 3: the position of the default/calibration configuration on the 3 plot sequence. The default is 2 (center position).
</p>
</td></tr>
<tr><td><code id="response.surface.lsd_+3A_factor1">factor1</code></td>
<td>

<p>integer: the index of the first most-important factor: 0 = automatic selection (according to the Sobol index, the default); any other number = the selected factor index, according to DoE factor order.
</p>
</td></tr>
<tr><td><code id="response.surface.lsd_+3A_factor2">factor2</code></td>
<td>

<p>integer: the index of the second most-important factor: 0 = automatic selection (according to the Sobol index, the default); any other number = the selected factor index, according to DoE factor order.
</p>
</td></tr>
<tr><td><code id="response.surface.lsd_+3A_factor3">factor3</code></td>
<td>

<p>integer: the index of the third most-important factor: 0 = automatic selection (according to the Sobol index, the default); any other number = the selected factor index, according to DoE factor order.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function produces data for three different wire frame 3D plots. In the 3 plots, the x-y plan is defined by the 2 most-important factors (calculated or set by the user in <code><a href="#topic+sobol.decomposition.lsd">sobol.decomposition.lsd</a></code>) and the z axis represents the response variable chosen. The three different plots shows the response surface for three values of the third most-important factor: the minimum, the default/calibration and the maximum. The order the three response surfaces are shown is defined by <code>defPos</code>.
</p>
<p>The automatically set most-important factors can be overridden by any factors chosen by the user by the usage of the arguments <code>factor1</code>, <code>factor2</code> and <code>factor3</code>. This way, the response surfaces can be represented for a combination of any 3 factors (parameters) in the model.
</p>


<h3>Value</h3>

<p>The function returns an object/list of class <code>response</code> containing three similar objects, one for each 3D plot, each of them comprised of:
</p>
<table role = "presentation">
<tr><td><code>calib</code></td>
<td>
<p>the predicted meta-model response values on each point of the 3D grid.</p>
</td></tr>
<tr><td><code>factor</code></td>
<td>
<p>the predicted values for each individual factor.</p>
</td></tr>
<tr><td><code>default</code></td>
<td>
<p>the predicted values for the default/calibration configuration.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>See the note in <a href="#topic+LSDsensitivity-package">LSDsensitivity-package</a> for step-by-step instructions on how to perform the complete sensitivity analysis process using LSD and R.
</p>


<h3>Author(s)</h3>

<p>Marcelo C. Pereira [aut, cre] (&lt;https://orcid.org/0000-0002-8069-2734&gt;)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.doe.lsd">read.doe.lsd</a>()</code>,
<code><a href="#topic+kriging.model.lsd">kriging.model.lsd</a>()</code>,
<code><a href="#topic+polynomial.model.lsd">polynomial.model.lsd</a>()</code>,
<code><a href="#topic+sobol.decomposition.lsd">sobol.decomposition.lsd</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># get the example directory name
path &lt;- system.file( "extdata/sobol", package = "LSDsensitivity" )

# Steps to use this function:
# 1. define the variables you want to use in the analysis
# 2. load data from a LSD simulation saved results using read.doe.lsd
# 3. fit a Kriging (or polynomial) meta-model using kriging.model.lsd
# 4. identify the most influential factors applying sobol.decomposition.lsd
# 5. calculate the response surface for the selected factors using model.limits.lsd
# 6. plot the response surface

lsdVars &lt;- c( "var1", "var2", "var3" )          # the definition of existing variables

dataSet &lt;- read.doe.lsd( path,                  # data files folder
                         "Sim3",                # data files base name (same as .lsd file)
                         "var3",                # variable name to perform the sensitivity analysis
                         does = 2,              # number of experiments (data + external validation)
                         saveVars = lsdVars )   # LSD variables to keep in dataset

model &lt;- kriging.model.lsd( dataSet )           # estimate best Kriging meta-model

SA &lt;- sobol.decomposition.lsd( dataSet, model ) # find Sobol indexes

resp &lt;- response.surface.lsd( dataSet,          # LSD experimental data set
                              model,            # estimated meta-model
                              SA )              # Sobol sensitivity analysis results

theta3d &lt;- 310                                  # horizontal view angle
phi3d &lt;- 30                                     # vertical view angle
grid3d &lt;- 25

for( i in 1 : 3 ) {                             # do for each top factor
                                                # plot 3D grid charts
  zMat &lt;- matrix( resp$calib[[ i ]]$mean, grid3d, grid3d, byrow = TRUE )
  zlim &lt;- range( zMat, na.rm = TRUE )

  vt &lt;- persp( resp$grid[[ 1 ]], resp$grid[[ 2 ]], zMat, col = "gray90",
               xlab = colnames( dataSet$doe )[ SA$topEffect[ 1 ] ], zlim = zlim,
               ylab = colnames( dataSet$doe )[ SA$topEffect[ 2 ] ], zlab = dataSet$saVarName,
               theta = theta3d, phi = phi3d, ticktype = "detailed" )
}
</code></pre>

<hr>
<h2 id='sobol.decomposition.lsd'>
Sobol variance decomposition sensitivity analysis
</h2><span id='topic+sobol.decomposition.lsd'></span>

<h3>Description</h3>

<p>This function performs the global sensitivity analysis of a previously fitted meta-model using the Sobol variance decomposition method (Saltelli et al., 2008). If no model is supplied, uses a B-spline smoothing interpolation model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sobol.decomposition.lsd( data, model = NULL, krig.sa = FALSE, sa.samp = 1000 )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sobol.decomposition.lsd_+3A_data">data</code></td>
<td>

<p>an object created by a previous call to <code><a href="#topic+read.doe.lsd">read.doe.lsd</a></code> which contains all the required experimental data for the analysis.
</p>
</td></tr>
<tr><td><code id="sobol.decomposition.lsd_+3A_model">model</code></td>
<td>

<p>an object created by a previous call to <code><a href="#topic+kriging.model.lsd">kriging.model.lsd</a></code> or <code><a href="#topic+polynomial.model.lsd">polynomial.model.lsd</a></code> which contains the meta-model estimated hyper-parameters. If no model is supplied (the default), performs the decomposition directly over the experimental data assuming a B-spline smoothing interpolation model.
</p>
</td></tr>
<tr><td><code id="sobol.decomposition.lsd_+3A_krig.sa">krig.sa</code></td>
<td>

<p>logical: use alternative Kriging-specific algorithm if TRUE (see <code><a href="sensitivity.html#topic+sobolGP">sobolGP</a></code>). Default is FALSE. Applicable only to Kriging meta-models.
</p>
</td></tr>
<tr><td><code id="sobol.decomposition.lsd_+3A_sa.samp">sa.samp</code></td>
<td>

<p>integer: number of samples to use in sensitivity analysis. The default is 1000.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs the global sensitivity analysis on a meta-model, previously estimated with  <code><a href="#topic+kriging.model.lsd">kriging.model.lsd</a></code> or <code><a href="#topic+polynomial.model.lsd">polynomial.model.lsd</a></code>, using the Sobol variance decomposition method (Saltelli et al., 2008).
</p>
<p>This function is a wrapper to the functions <code><a href="sensitivity.html#topic+fast99">fast99</a></code> and <code><a href="sensitivity.html#topic+sobolGP">sobolGP</a></code> in <code><a href="sensitivity.html#topic+sensitivity-package">sensitivity-package</a></code>.
</p>


<h3>Value</h3>

<p>The function returns an object/list of class <code>kriging-sa</code> or <code>polynomial-sa</code>, according to the input meta-model, containing several items:
</p>
<table role = "presentation">
<tr><td><code>metamodel</code></td>
<td>
<p>an object/list of class <code><a href="sensitivity.html#topic+fast99">fast99</a></code> containing the estimated total and conditional variances for all the meta-model factors.</p>
</td></tr>
<tr><td><code>sa</code></td>
<td>
<p>a print-ready data frame with the Sobol indexes for each factor.</p>
</td></tr>
<tr><td><code>topEffect</code></td>
<td>
<p>a vector containing the indexes to the three most influential factors, automatically calculated (if <code>factorX = 0</code>) or according to the order pre-selected by the user.</p>
</td></tr>
</table>
<p>If no model is supplied and a B-spline smoothing interpolation model cannot be fitted, returns <code>NULL</code>.
</p>


<h3>Note</h3>

<p>See the note in <a href="#topic+LSDsensitivity-package">LSDsensitivity-package</a> for step-by-step instructions on how to perform the complete sensitivity analysis process using LSD and R.
</p>


<h3>Author(s)</h3>

<p>Marcelo C. Pereira [aut, cre] (&lt;https://orcid.org/0000-0002-8069-2734&gt;)
</p>


<h3>References</h3>

<p>Saltelli A, Ratto M, Andres T, Campolongo F, Cariboni J, Gatelli D, Saisana M, Tarantola S (2008) <em>Global sensitivity analysis: the primer</em>. Wiley, New York
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.doe.lsd">read.doe.lsd</a>()</code>,
<code><a href="#topic+kriging.model.lsd">kriging.model.lsd</a>()</code>,
<code><a href="#topic+polynomial.model.lsd">polynomial.model.lsd</a>()</code>
</p>
<p><code><a href="sensitivity.html#topic+fast99">fast99</a>()</code>,
<code><a href="sensitivity.html#topic+sobolGP">sobolGP</a>()</code> in <code><a href="sensitivity.html#topic+sensitivity-package">sensitivity-package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># get the example directory name
path &lt;- system.file( "extdata/sobol", package = "LSDsensitivity" )

# Steps to use this function:
# 1. define the variables you want to use in the analysis
# 2. load data from a LSD simulation saved results using read.doe.lsd
# 3. fit a Kriging (or polynomial) meta-model using kriging.model.lsd
# 4. perform the sensitivity analysis applying sobol.decomposition.lsd

lsdVars &lt;- c( "var1", "var2", "var3" )         # the definition of existing variables

dataSet &lt;- read.doe.lsd( path,                 # data files folder
                         "Sim3",               # data files base name (same as .lsd file)
                         "var3",               # variable name to perform the sensitivity analysis
                         does = 2,             # number of experiments (data + external validation)
                         saveVars = lsdVars )  # LSD variables to keep in dataset

model &lt;- kriging.model.lsd( dataSet )          # estimate best Kriging meta-model

SA &lt;- sobol.decomposition.lsd( dataSet,        # LSD experimental data set
                               model )         # estimated meta-model

print( SA$topEffect )                          # indexes to the top 3 factors
print( SA$sa )                                 # Sobol indexes table
barplot( t( SA$sa ) )                          # plot Sobol indexes chart
</code></pre>

<hr>
<h2 id='symmet.test.lsd'>
Unimodality and symmetry tests
</h2><span id='topic+symmet.test.lsd'></span>

<h3>Description</h3>

<p>Perform a set of unimodality and symmetry tests useful for simulation model data from a Monte Carlo experiment distributions. The included tests are: Hartigans dip test for unimodality (Hdip), and the Cabilio and Masaro (CM), the Mira (M), and the Miao, Gel and Gastwirth tests for symmetry.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>symmet.test.lsd( data, vars = dimnames( data )[[ 2 ]], start.period = 0,
                 signif = 0.05, digits = 2, sym.boot = FALSE )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="symmet.test.lsd_+3A_data">data</code></td>
<td>

<p>a three-dimensional array, as the ones produced by <code><a href="LSDinterface.html#topic+read.3d.lsd">read.3d.lsd</a></code>, organized as (time steps x variables x Monte Carlo instances).
</p>
</td></tr>
<tr><td><code id="symmet.test.lsd_+3A_vars">vars</code></td>
<td>

<p>a vector of the variable names (as strings) contained in <code>data</code> for which the tests will be performed. The default is to test all variables.
</p>
</td></tr>
<tr><td><code id="symmet.test.lsd_+3A_start.period">start.period</code></td>
<td>

<p>integer: the first time step in <code>data</code> to be considered for the tests. The default value is 0 (all time steps considered).
</p>
</td></tr>
<tr><td><code id="symmet.test.lsd_+3A_signif">signif</code></td>
<td>

<p>numeric in [0, 1]: statistical significance to evaluate the tests rejection of the null-hypothesis. The default value is 0.05 (5%).
</p>
</td></tr>
<tr><td><code id="symmet.test.lsd_+3A_digits">digits</code></td>
<td>

<p>integer: the number of significant digits to show in results. The default is 2.
</p>
</td></tr>
<tr><td><code id="symmet.test.lsd_+3A_sym.boot">sym.boot</code></td>
<td>

<p>logical: set to <code>TRUE</code> to use bootstrap to obtain critical values. The default (<code>FALSE</code>) is to use asymptotic distribution of the statistics.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a wrapper to the functions <code><a href="diptest.html#topic+dip.test">dip.test</a></code> in <code>diptest</code> package, and <code><a href="lawstat.html#topic+symmetry.test">symmetry.test</a></code> in <code>lawstat</code> package.
</p>


<h3>Value</h3>

<p>The function returns a data frame presenting both the average test statistics and the frequency of test null-hypothesis rejections for all the variables selected in <code>vars</code>.
Null hypothesis (H0) for Hdip test is an unimodal distribution for the Monte Carlo distribution. Null hypothesis (H0) for CM, M and MGG tests is a symmetric distribution for the Monte Carlo distribution.
</p>


<h3>Author(s)</h3>

<p>Marcelo C. Pereira [aut, cre] (&lt;https://orcid.org/0000-0002-8069-2734&gt;)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ergod.test.lsd">ergod.test.lsd</a>()</code>,
</p>
<p><code><a href="LSDinterface.html#topic+list.files.lsd">list.files.lsd</a>()</code>, <code><a href="LSDinterface.html#topic+read.3d.lsd">read.3d.lsd</a>()</code> in <code><a href="LSDinterface.html#topic+LSDinterface-package">LSDinterface-package</a></code>,
</p>
<p><code><a href="diptest.html#topic+dip.test">dip.test</a>()</code>, <code><a href="lawstat.html#topic+symmetry.test">symmetry.test</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># get the list of file names of example LSD results
library( LSDinterface )
files &lt;- list.files.lsd( system.file( "extdata", package = "LSDsensitivity" ),
                         "Sim1.lsd", recursive = TRUE )

# Steps to use this function:
# 1. load data from a LSD simulation saved results using a read.xxx.lsd
#    function from LSDinterface package (read.3d.lsd, for instance)
# 2. use symmet.test.lsd to apply the tests on the relevant variables,
#    replacing "var1", "var2" etc. with your data

# read data from Monte Carlo runs
dataSet &lt;- read.3d.lsd( files )

# apply tests
tests &lt;- symmet.test.lsd( dataSet,              # the data set to use
                          c( "var2", "var3" ),  # the variables to test
                          signif = 0.01,        # use 1% significance
                          digits = 4,           # show results using 4 digits
                          sym.boot = FALSE )    # use bootstrap for precision
print( tests )
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
