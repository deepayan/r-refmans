<!DOCTYPE html><html><head><title>Help for package conf</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {conf}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#binomTest'><p>Confidence Intervals for Binomial Proportions</p></a></li>
<li><a href='#binomTestCoverage'><p>Actual Coverage Calculation for Binomial Proportions</p></a></li>
<li><a href='#binomTestCoveragePlot'><p>Coverage Plots for Binomial Proportions</p></a></li>
<li><a href='#binomTestEnsemble'><p>Ensemble Confidence Intervals for Binomial Proportions</p></a></li>
<li><a href='#binomTestMSE'><p>RMSE-Minimizing Confidence Intervals for Binomial Proportions</p></a></li>
<li><a href='#conf'><p>conf: Visualization and Analysis of Statistical Measures of Confidence</p></a></li>
<li><a href='#coversim'><p>Confidence Region Coverage</p></a></li>
<li><a href='#crplot'><p>Plotting Two-Dimensional Confidence Regions</p></a></li>
<li><a href='#dinvgauss'><p>The Inverse Gaussian Distribution</p></a></li>
<li><a href='#dllogis'><p>The Log Logistic Distribution</p></a></li>
<li><a href='#gammaMLE'><p>Maximum Likelihood Parameter Estimation of a Gamma Model with Possibly</p>
Censored Data</a></li>
<li><a href='#invgaussMLE'><p>Maximum Likelihood Parameter Estimation of an Inverse Gaussian Model with Possibly</p>
Censored Data</a></li>
<li><a href='#km.outcomes'>
<p>Outcomes for the Kaplan-Meier product-limit estimator</p></a></li>
<li><a href='#km.pmf'>
<p>Probability Mass Function for the support of the Kaplan-Meier product-limit estimator</p></a></li>
<li><a href='#km.support'><p>Support values for the Kaplan-Meier product-limit estimator</p></a></li>
<li><a href='#km.surv'><p>Probability Mass Functions for the support of the</p>
Kaplan-Meier product-limit estimator for various cumulative probabilities associated with <code>X</code></a></li>
<li><a href='#llogisMLE'><p>Maximum Likelihood Parameter Estimation of a Log Logistic Model with Possibly</p>
Censored Data</a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Visualization and Analysis of Statistical Measures of Confidence</td>
</tr>
<tr>
<td>Version:</td>
<td>1.8.3</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Christopher Weld &lt;ceweld241@gmail.com&gt;</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, stats, statmod, fitdistrplus, pracma, rootSolve,
utils</td>
</tr>
<tr>
<td>Description:</td>
<td>Enables: (1) plotting two-dimensional confidence regions, (2) coverage analysis
  of confidence region simulations, (3) calculating confidence intervals and the associated 
  actual coverage for binomial proportions, and (4) calculating the support values and the 
  probability mass function of the Kaplan-Meier product-limit estimator. Each is given in 
  greater detail next. 
  (1) Plots the two-dimensional confidence region for probability distribution parameters 
  (supported distribution suffixes: cauchy, gamma, invgauss, logis, llogis, lnorm, norm, unif, 
  weibull) corresponding to a user-given complete or right-censored dataset and level of 
  significance.  The crplot() algorithm plots more points in areas of greater curvature to 
  ensure a smooth appearance throughout the confidence region boundary.  An alternative 
  heuristic plots a specified number of points at roughly uniform intervals along its boundary. 
  Both heuristics build upon the radial profile log-likelihood ratio technique for plotting 
  confidence regions given by Jaeger (2016) &lt;<a href="https://doi.org/10.1080%2F00031305.2016.1182946">doi:10.1080/00031305.2016.1182946</a>&gt;, and
  are detailed in a publication by Weld et al. (2019) &lt;<a href="https://doi.org/10.1080%2F00031305.2018.1564696">doi:10.1080/00031305.2018.1564696</a>&gt;. 
  (2) Performs confidence region coverage simulations for a random sample drawn from a user-
  specified parametric population distribution, or for a user-specified dataset and point of 
  interest with coversim(). (3) Calculates confidence interval bounds for a binomial proportion 
  with binomTest(), calculates the actual coverage with binomTestCoverage(), and plots the 
  actual coverage with binomTestCoveragePlot(). Calculates confidence interval bounds for the
  binomial proportion using an ensemble of constituent confidence intervals with 
  binomTestEnsemble(). Calculates confidence interval bounds for the binomial proportion using 
  a complete enumeration of all possible transitions from one actual coverage acceptance curve 
  to another which minimizes the root mean square error for n &lt;= 15 and follows the transitions 
  for well-known confidence intervals for n &gt; 15 using binomTestMSE(). (4) The km.support() 
  function calculates the support values of the Kaplan-Meier product-limit estimator for a given 
  sample size n using an induction algorithm described in Qin et al. (2023) 
  &lt;<a href="https://doi.org/10.1080%2F00031305.2022.2070279">doi:10.1080/00031305.2022.2070279</a>&gt;. The km.outcomes() function generates a matrix 
  containing all possible outcomes (all possible sequences of failure times and right-censoring 
  times) of the value of the Kaplan-Meier product-limit estimator for a particular sample size 
  n. The km.pmf() function generates the probability mass function for the support values of 
  the Kaplan-Meier product-limit estimator for a particular sample size n, probability of 
  observing a failure h at the time of interest expressed as the cumulative probability 
  percentile associated with X = min(T, C), where T is the failure time and C is the censoring 
  time under a random-censoring scheme. The km.surv() function generates multiple probability 
  mass functions of the Kaplan-Meier product-limit estimator for the same arguments as those 
  given for km.pmf().</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL (&le; 2)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-09-30 23:28:25 UTC; christopherweld</td>
</tr>
<tr>
<td>Author:</td>
<td>Christopher Weld <a href="https://orcid.org/0000-0001-5902-9738"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Kexin Feng [aut],
  Hayeon Park [aut],
  Yuxin Qin [aut],
  Heather Sasinowska [aut],
  Lawrence Leemis [aut],
  Yuan Chang [ctb],
  Brock Crook [ctb],
  Chris Kuebler [ctb],
  Andrew Loh [ctb],
  Xin Zhang [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-01 00:00:07 UTC</td>
</tr>
</table>
<hr>
<h2 id='binomTest'>Confidence Intervals for Binomial Proportions</h2><span id='topic+binomTest'></span>

<h3>Description</h3>

<p>Generates lower and upper confidence interval limits for a binomial proportion
using different types of confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> binomTest(n, x,
           alpha = 0.05,
           intervalType = "Clopper-Pearson")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="binomTest_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="binomTest_+3A_x">x</code></td>
<td>
<p>number of successes</p>
</td></tr>
<tr><td><code id="binomTest_+3A_alpha">alpha</code></td>
<td>
<p>significance level for confidence interval</p>
</td></tr>
<tr><td><code id="binomTest_+3A_intervaltype">intervalType</code></td>
<td>
<p>type of confidence interval used; either &quot;Clopper-Pearson&quot;, &quot;Wald&quot;, &quot;Wilson-Score&quot;, &quot;Jeffreys&quot;, &quot;Agresti-Coull&quot;, &quot;Arcsine&quot;, or &quot;Blaker&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generates a lower and upper confidence interval limit for a binomial proportion using
</p>

<ul>
<li><p> various types of confidence intervals,
</p>
</li>
<li><p> various sample sizes, and
</p>
</li>
<li><p> various numbers of successes.
</p>
</li></ul>

<p>When the <code>binomTest</code> function is called, it returns a two-element vector in which
</p>

<ul>
<li><p> the first element is the lower bound of the confidence interval, and
</p>
</li>
<li><p> the second element is the upper bound of the confidence interval.
</p>
</li></ul>

<p>This confidence interval is constructed by calculating lower and upper bounds associated with the confidence interval procedure specified by the <code>intervalType</code> argument. Lower bounds that are negative are set to 0 and upper bounds that are greater than 1 are set to 1.
</p>


<h3>Author(s)</h3>

<p>Hayeon Park (<a href="mailto:hpark031@gmail.com">hpark031@gmail.com</a>),
Larry Leemis (<a href="mailto:leemis@math.wm.edu">leemis@math.wm.edu</a>)</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+dbinom">dbinom</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  binomTest(10, 6)
  binomTest(100, 30, intervalType = "Agresti-Coull")
</code></pre>

<hr>
<h2 id='binomTestCoverage'>Actual Coverage Calculation for Binomial Proportions</h2><span id='topic+binomTestCoverage'></span>

<h3>Description</h3>

<p>Calculates the actual coverage of a confidence interval for a
binomial proportion for a particular sample size <code class="reqn">n</code> and
a particular value of the probability of success <code class="reqn">p</code> for several
confidence interval procedures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  binomTestCoverage(n, p,
                    alpha = 0.05,
                    intervalType = "Clopper-Pearson")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="binomTestCoverage_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="binomTestCoverage_+3A_p">p</code></td>
<td>
<p>population probability of success</p>
</td></tr>
<tr><td><code id="binomTestCoverage_+3A_alpha">alpha</code></td>
<td>
<p>significance level for confidence interval</p>
</td></tr>
<tr><td><code id="binomTestCoverage_+3A_intervaltype">intervalType</code></td>
<td>
<p>type of confidence interval used; either &quot;Clopper-Pearson&quot;, &quot;Wald&quot;, &quot;Wilson-Score&quot;, &quot;Jeffreys&quot;, &quot;Agresti-Coull&quot;, &quot;Arcsine&quot;, or &quot;Blaker&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates the actual coverage of a confidence interval
procedure at a particular value of <code class="reqn">p</code> for
</p>

<ul>
<li><p> various types of confidence intervals,
</p>
</li>
<li><p> various probabilities of success <code class="reqn">p</code>, and
</p>
</li>
<li><p> various sample sizes <code class="reqn">n</code>.
</p>
</li></ul>

<p>The actual coverage for a particular value of <code class="reqn">p</code>, the probability of success of interest, is
</p>
<p style="text-align: center;"><code class="reqn">c(p) = \sum_{x=0}^n {I(x,p) {n \choose x} p^x (1-p)^{n-x}},</code>
</p>

<p>where <code class="reqn">I(x,p)</code> is an indicator function that determines whether a confidence interval
covers <code class="reqn">p</code> when <code class="reqn">X = x</code> (see Vollset, 1993).
</p>
<p>The binomial distribution with arguments <code>size</code> = <code class="reqn">n</code> and
<code>prob</code> = <code class="reqn">p</code> has probability mass function
</p>
<p style="text-align: center;"><code class="reqn">p(x) = {n \choose x} p^x (1-p)^{n-x}</code>
</p>

<p>for <code class="reqn">x = 0, 1, 2, \ldots, n</code>.
</p>
<p>The algorithm for computing the actual coverage for a particular probability of
success begins by calculating all possible lower and upper bounds associated
with the confidence interval procedure specified by the <code>intervalType</code> argument.
The appropriate binomial probabilities are summed to determine the actual coverage
at <code class="reqn">p</code>.
</p>


<h3>Author(s)</h3>

<p>Hayeon Park (<a href="mailto:hpark031@gmail.com">hpark031@gmail.com</a>),
Larry Leemis (<a href="mailto:leemis@math.wm.edu">leemis@math.wm.edu</a>)
</p>


<h3>References</h3>

<p>Vollset, S.E. (1993). Confidence Intervals for a Binomial Proportion. Statistics in Medicine, 12, 809-824.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+dbinom">dbinom</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  binomTestCoverage(6, 0.4)
  binomTestCoverage(n = 10, p = 0.3, alpha = 0.01, intervalType = "Wilson-Score")
</code></pre>

<hr>
<h2 id='binomTestCoveragePlot'>Coverage Plots for Binomial Proportions</h2><span id='topic+binomTestCoveragePlot'></span>

<h3>Description</h3>

<p>Generates plots for the actual coverage of a binomial proportion
using various types of confidence intervals. Plots the actual
coverage for a given sample size and stated nominal coverage <code class="reqn">1 -</code> <code>alpha</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  binomTestCoveragePlot(n,
                        alpha = 0.05,
                        intervalType = "Clopper-Pearson",
                        plo = 0,
                        phi = 1,
                        clo = 1 - 2 * alpha,
                        chi = 1,
                        points = 5 + floor(250 / n),
                        showTrueCoverage = TRUE,
                        gridCurves = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="binomTestCoveragePlot_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="binomTestCoveragePlot_+3A_alpha">alpha</code></td>
<td>
<p>significance level for confidence interval</p>
</td></tr>
<tr><td><code id="binomTestCoveragePlot_+3A_intervaltype">intervalType</code></td>
<td>
<p>type of confidence interval used; either &quot;Clopper-Pearson&quot;, &quot;Wald&quot;, &quot;Wilson-Score&quot;, &quot;Jeffreys&quot;, &quot;Agresti-Coull&quot;, &quot;Arcsine&quot;, or &quot;Blaker&quot;</p>
</td></tr>
<tr><td><code id="binomTestCoveragePlot_+3A_plo">plo</code></td>
<td>
<p>lower limit for percentile (horizontal axis)</p>
</td></tr>
<tr><td><code id="binomTestCoveragePlot_+3A_phi">phi</code></td>
<td>
<p>upper limit for percentile (horizontal axis)</p>
</td></tr>
<tr><td><code id="binomTestCoveragePlot_+3A_clo">clo</code></td>
<td>
<p>lower limit for coverage (vertical axis)</p>
</td></tr>
<tr><td><code id="binomTestCoveragePlot_+3A_chi">chi</code></td>
<td>
<p>upper limit for coverage (vertical axis)</p>
</td></tr>
<tr><td><code id="binomTestCoveragePlot_+3A_points">points</code></td>
<td>
<p>number of points plotted in each segment of the plot; if default, varies with 'n' (see above)</p>
</td></tr>
<tr><td><code id="binomTestCoveragePlot_+3A_showtruecoverage">showTrueCoverage</code></td>
<td>
<p>logical; if <code>TRUE</code> (default), a solid red line will appear at <code class="reqn">1 -</code> <code>alpha</code></p>
</td></tr>
<tr><td><code id="binomTestCoveragePlot_+3A_gridcurves">gridCurves</code></td>
<td>
<p>logical; if <code>TRUE</code>, display acceptance curves in gray</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generates an actual coverage plot for binomial proportions using
</p>

<ul>
<li><p> various types of confidence intervals, and
</p>
</li>
<li><p> various sample sizes.
</p>
</li></ul>

<p>When the function is called with default arguments,
</p>

<ul>
<li><p> the horizontal axis is the percentile at which the coverage is evaluated,
</p>
</li>
<li><p> the vertical axis is the actual coverage percentage at each percentile, that is,
the probability that the true value at a percentile is contained in the corresponding
confidence interval, and
</p>
</li>
<li><p> the solid red line is the stated coverage of <code class="reqn">1 -</code> <code>alpha</code>.
</p>
</li></ul>

<p>The actual coverage for a particular value of <code class="reqn">p</code>, the percentile of interest, is
</p>
<p style="text-align: center;"><code class="reqn">c(p) = \sum_{x=0}^n {I(x,p) {n \choose x} p^x (1-p)^{n-x}},</code>
</p>

<p>where <code class="reqn">I(x,p)</code> is an indicator function that determines whether a confidence interval covers <code class="reqn">p</code> when <code class="reqn">X = x</code>
(see Vollset, 1993).
</p>
<p>The binomial distribution with arguments <code>size</code> = <code class="reqn">n</code> and
<code>prob</code> = <code class="reqn">p</code> has probability mass function
</p>
<p style="text-align: center;"><code class="reqn">p(x) = {n \choose x} p^x (1-p)^{n-x}</code>
</p>

<p>for <code class="reqn">x = 0, 1, \ldots, n</code>.
</p>
<p>The algorithm for plotting the actual coverage begins by calculating all possible lower and upper        bounds associated with the confidence interval procedure specified by the <code>intervalType</code> argument.
These values are concatenated into a vector which is sorted. Negative values and values that exceed 1 are removed from this vector. These values are the breakpoints in the actual coverage function. The <code>points</code> argument gives the number of points plotted on each segment of the graph of the actual coverage.
</p>
<p>The <code>plo</code> and <code>phi</code> arguments can be used to expand or compress the plots horizontally.
</p>
<p>The <code>clo</code> and <code>chi</code> arguments can be used to expand or compress the plots vertically.
</p>
<p>By default, the <code>showTrueCoverage</code> argument plots a solid horizontal
red line at the height of the stated coverage. The actual coverage is
plotted with solid black lines for each segment of the actual coverage.
</p>
<p>The <code>gridCurves</code> argument is assigned a logical value which indicates whether the acceptance curves giving all possible actual coverage values should be displayed as gray curves.
</p>


<h3>Author(s)</h3>

<p>Hayeon Park (<a href="mailto:hpark031@gmail.com">hpark031@gmail.com</a>),
Larry Leemis (<a href="mailto:leemis@math.wm.edu">leemis@math.wm.edu</a>)
</p>


<h3>References</h3>

<p>Vollset, S.E. (1993). Confidence Intervals for a Binomial Proportion. Statistics in Medicine, 12, 809&ndash;824.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+dbinom">dbinom</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  binomTestCoveragePlot(6)
  binomTestCoveragePlot(10, intervalType = "Wilson-Score", clo = 0.8)
  binomTestCoveragePlot(n = 100, intervalType = "Wald", clo = 0, chi = 1, points = 30)
  </code></pre>

<hr>
<h2 id='binomTestEnsemble'>Ensemble Confidence Intervals for Binomial Proportions</h2><span id='topic+binomTestEnsemble'></span>

<h3>Description</h3>

<p>Generates lower and upper confidence interval limits for a binomial proportion
using an ensemble of confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  binomTestEnsemble(n, x,
                    alpha = 0.05,
                    CP = TRUE,
                    WS = TRUE,
                    JF = TRUE,
                    AC = TRUE,
                    AR = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="binomTestEnsemble_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="binomTestEnsemble_+3A_x">x</code></td>
<td>
<p>number of successes</p>
</td></tr>
<tr><td><code id="binomTestEnsemble_+3A_alpha">alpha</code></td>
<td>
<p>significance level for confidence interval</p>
</td></tr>
<tr><td><code id="binomTestEnsemble_+3A_cp">CP</code></td>
<td>
<p>logical; if <code>TRUE</code> (default), include Clopper-Pearson confidence interval procedure in the ensemble</p>
</td></tr>
<tr><td><code id="binomTestEnsemble_+3A_ws">WS</code></td>
<td>
<p>logical; if <code>TRUE</code> (default), include Wilson-Score confidence interval procedure in the ensemble</p>
</td></tr>
<tr><td><code id="binomTestEnsemble_+3A_jf">JF</code></td>
<td>
<p>logical; if <code>TRUE</code> (default), include Jeffreys confidence interval procedure in the ensemble</p>
</td></tr>
<tr><td><code id="binomTestEnsemble_+3A_ac">AC</code></td>
<td>
<p>logical; if <code>TRUE</code> (default), include Agresti-Coull confidence interval procedure in the ensemble</p>
</td></tr>
<tr><td><code id="binomTestEnsemble_+3A_ar">AR</code></td>
<td>
<p>logical; if <code>TRUE</code> (default), include Arcsine confidence interval procedure in the ensemble</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generates lower and upper confidence interval limits for a binomial proportions using
</p>

<ul>
<li><p> various sample sizes,
</p>
</li>
<li><p> various numbers of successes, and
</p>
</li>
<li><p> various combinations of confidence intervals.
</p>
</li></ul>

<p>When the <code>binomTestEnsemble</code> function is called, it returns a two-element vector in which
</p>

<ul>
<li><p> the first element is the lower bound of the Ensemble confidence interval, and
</p>
</li>
<li><p> the second element is the upper bound of the Ensemble confidence interval.
</p>
</li></ul>

<p>To construct an Ensemble confidence interval that attains an actual coverage that
is close to the stated coverage, the five constituent confidence interval procedures
can be combined.  Since these intervals vary in width, the lower limits and the actual
coverage of the constituent confidence intervals at the maximum likelihood estimator
are calculated.  Likewise, the upper limits and the actual coverage of the constituent
confidence intervals at the maximum likelihood estimator are calculated.
The centroids of the lower and upper constituent confidence intervals for points falling
below and above the stated coverage are connected with a line segment.  The point of
intersection of these line segments and the stated coverage gives the lower and upper
bound of the Ensemble confidence interval.  Special cases to this approach are given in
the case of (a) the actual coverages all fall above or below the stated coverage, and
(b) the slope of the line connecting the centroids is infinite.
</p>
<p>If only one of the logical arguments is <code>TRUE</code>, the code returns a simple confidence interval of that one procedure.
</p>
<p>The Wald confidence interval is omitted because it degenerates in actual coverage for <code class="reqn">x = 0</code> and <code class="reqn">x = n</code>.
</p>


<h3>Author(s)</h3>

<p>Hayeon Park (<a href="mailto:hpark031@gmail.com">hpark031@gmail.com</a>),
Larry Leemis (<a href="mailto:leemis@math.wm.edu">leemis@math.wm.edu</a>)
</p>


<h3>References</h3>

<p>Park, H., Leemis, L. (2019), &quot;Ensemble Confidence Intervals for Binomial Proportions&quot;, Statistics in Medicine, 38 (18), 3460-3475.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  binomTestEnsemble(10, 3)
  binomTestEnsemble(100, 82, CP = FALSE, AR = FALSE)
  binomTestEnsemble(33, 1, CP = FALSE, JF = FALSE, AC = FALSE, AR = FALSE)
  </code></pre>

<hr>
<h2 id='binomTestMSE'>RMSE-Minimizing Confidence Intervals for Binomial Proportions</h2><span id='topic+binomTestMSE'></span>

<h3>Description</h3>

<p>Generates lower and upper confidence interval limits for a binomial proportion that minimizes
the root mean square error (RMSE) of the actual coverage function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  binomTestMSE(n, x,
               alpha = 0.05,
               smooth = 1,
               showRMSE = TRUE,
               showAll = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="binomTestMSE_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="binomTestMSE_+3A_x">x</code></td>
<td>
<p>number of successes</p>
</td></tr>
<tr><td><code id="binomTestMSE_+3A_alpha">alpha</code></td>
<td>
<p>significance level for confidence interval</p>
</td></tr>
<tr><td><code id="binomTestMSE_+3A_smooth">smooth</code></td>
<td>
<p>smoothness index</p>
</td></tr>
<tr><td><code id="binomTestMSE_+3A_showrmse">showRMSE</code></td>
<td>
<p>a logical variable indicating whether to show the value of RSME</p>
</td></tr>
<tr><td><code id="binomTestMSE_+3A_showall">showAll</code></td>
<td>
<p>a logical variable indicating whether to show confidence intervals of all possible number of successes</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generates lower and upper confidence interval limits for a binomial proportion for
</p>

<ul>
<li><p> various sample sizes,
</p>
</li>
<li><p> various numbers of successes.
</p>
</li></ul>

<p>When the <code>binomTestMSE</code> function is called, it returns a two-element vector in which
</p>

<ul>
<li><p> the first element is the lower bound of the RMSE-minimizing confidence interval, and
</p>
</li>
<li><p> the second element is the upper bound of the RMSE-minimizing confidence interval.
</p>
</li></ul>

<p>An RMSE-minimizing two-sided 100 * (1 - alpha) percent confidence interval
for p is constructed from a random sample of size n from a Bernoulli(p)
population.  The parameter <code>x</code> gives the number of successes in the n
mutually independent Bernoulli trials.  For n &lt;= 15, all possible jumps
between acceptance curves associated with the actual coverage function are
enumerated based on their one-to-one relationship with the symmetric Dyck
paths.  For each sequence of jumps between acceptance curves, the confidence
interval bounds that are returned are associated with discontinuities in the
actual coverage function that together result in the lowest possible RMSE.  A
set of smoothness constraints that build on four existing non-conservative
confidence intervals (Wilson-score, Jeffreys, Arcsine, and Agresti-Coull) is
used if the smoothness index <code>smooth</code> is set to one.  These constraints
ensure that the RMSE-confidence interval achieves smoothness, a preferable
property of the binomial confidence interval that is related to lower bound
differences for adjacent values of <code>x</code>.  There is a trade-off between
the RMSE and the smoothness.  For n &gt; 100, smoothness is required.  The RMSE
usually increases if the smoothness constraints are used.  For n &gt; 15, only
the symmetric Dyck paths associated with the Wilson–score, Jeffreys, Arcsine,
and Agresti–Coull confidence interval procedures are used instead of
enumerating because the computation time increases in a factorial fashion in
n.  The minimal RMSE is not guaranteed for n &gt; 15 because another symmetric
Dyck path other than those associated with the four existing confidence
interval procedures might prove to be optimal.  However, this procedure does
ensure a lower RMSE than any of the four existing confidence intervals for
all n.
</p>


<h3>Author(s)</h3>

<p>Kexin Feng (<a href="mailto:kfeng@caltech.edu">kfeng@caltech.edu</a>),
Larry Leemis (<a href="mailto:leemis@math.wm.edu">leemis@math.wm.edu</a>),
Heather Sasinowska (<a href="mailto:hdsasinowska@wm.edu">hdsasinowska@wm.edu</a>)
</p>


<h3>References</h3>

<p>Feng, K., Sasinowska, H., Leemis, L. (2022), &quot;RMSE-Minimizing Confidence Interval
for the Binomial Parameter&quot;, Computational Statistics, 37 (4), 2022, 1855-1885.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  binomTestMSE(10, 3)
</code></pre>

<hr>
<h2 id='conf'>conf: Visualization and Analysis of Statistical Measures of Confidence</h2><span id='topic+conf'></span><span id='topic+conf-package'></span>

<h3>Description</h3>

<p>Enables:
</p>

<ol>
<li><p> confidence region plots in two-dimensions corresponding to a user given dataset,
level of significance, and parametric probability distribution (supported distribution suffixes:
cauchy, gamma, invgauss, lnorm, llogis, logis, norm, unif, weibull),
</p>
</li>
<li><p> coverage simulations (if a point of interest is within or outside of a confidence region
boundary) for either random samples drawn from a user-specified parametric distribution or for a
user-specified dataset and point of interest,
</p>
</li>
<li><p> calculating confidence intervals and the associated actual coverage for binomial proportions, and
</p>
</li>
<li><p> calculating the support values and the probability mass function of the Kaplan-Meier product-limit
estimator.
</p>
</li></ol>

<p><b>Request from authors</b>:  Please properly cite any use of this package and/or its algorithms,
which are detailed in the corresponding publication by Weld et al. (2018)
&lt;doi:10.1080/00031305.2018.1564696&gt;, Park and Leemis (2019) &lt;doi:10.1002/sim.8189&gt;,
Feng et al. (2022) &lt;doi:10.1007/s00180-021-01183-3&gt;, and Qin et al. (2023)
&lt;doi:10.1080/00031305.2022.2070279&gt;.  Additionally, we welcome and appreciate your feedback and
insights as to how this resource is being leveraged to improve whatever it is you do.  Please
include your name and academic and/or business affiliation in your correspondence.
</p>


<h3>Details</h3>

<p>This package includes the functions:
</p>

<ul>
<li><p> confidence region plots: <code><a href="#topic+crplot">crplot</a></code>,
</p>
</li>
<li><p> confidence region coverage analysis: <code><a href="#topic+coversim">coversim</a></code>,
</p>
</li>
<li><p> confidence intervals for binomial proportions: <code><a href="#topic+binomTest">binomTest</a></code>,
</p>
</li>
<li><p> actual coverage calculation for binomial proportions: <code><a href="#topic+binomTestCoverage">binomTestCoverage</a></code>,
</p>
</li>
<li><p> actual coverage plots for binomial proportions: <code><a href="#topic+binomTestCoveragePlot">binomTestCoveragePlot</a></code>, and
</p>
</li>
<li><p> ensemble confidence intervals for binomial proportions: <code><a href="#topic+binomTestEnsemble">binomTestEnsemble</a></code>.
</p>
</li>
<li><p>  minimum root mean square confidence intervals for binomial proportions: <code><a href="#topic+binomTestMSE">binomTestMSE</a></code>
</p>
</li>
<li><p>  Kaplan-Meier product-limit estimator support values: <code><a href="#topic+km.support">km.support</a></code>
</p>
</li>
<li><p>  enumeration of Kaplan-Meier product-limit estimator outcomes: <code><a href="#topic+km.outcomes">km.outcomes</a></code>
</p>
</li>
<li><p>  probability mass function of the Kaplan-Meier product-limit estimator: <code><a href="#topic+km.pmf">km.pmf</a></code>
</p>
</li>
<li><p>  probability mass functions of the Kaplan-Meier product-limit estimator: <code><a href="#topic+km.surv">km.surv</a></code>
</p>
</li></ul>



<h3>Vignettes</h3>

<p>The CRAN website https://CRAN.R-project.org/package=conf contains links for vignettes on the
<code><a href="#topic+crplot">crplot</a></code>, <code><a href="#topic+coversim">coversim</a></code>, <code><a href="#topic+km.outcomes">km.outcomes</a></code>, <code><a href="#topic+km.pmf">km.pmf</a></code>, <code><a href="#topic+km.support">km.support</a></code>,
and <code><a href="#topic+km.surv">km.surv</a></code> functions.
</p>


<h3>Acknowledgments</h3>

<p>The lead author thanks The Omar Bradley Fellowship for Research in Mathematics for funding that partially
supported this work.
</p>


<h3>Author(s)</h3>

<p>Christopher Weld, Kexin Feng, Hayeon Park, Yuxin Qin, Heather Sasinowska, Larry Leemis
</p>
<p>Maintainer: Christopher Weld &lt;ceweld241@gmail.com&gt;
</p>

<hr>
<h2 id='coversim'>Confidence Region Coverage</h2><span id='topic+coversim'></span>

<h3>Description</h3>

<p>Creates a confidence region and determines coverage results for a corresponding point of interest.
Iterates through a user specified number of trials.
Each trial uses a random dataset with user-specified parameters (default) or a user specified dataset
matrix (<code>'n'</code> samples per column, <code>'iter'</code> columns) and returns the corresponding actual coverage results.
See the CRAN website https://CRAN.R-project.org/package=conf for a link to a <code>coversim</code> vignette.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coversim(alpha, distn,
                n         = NULL,
                iter      = NULL,
                dataset   = NULL,
                point     = NULL,
                seed      = NULL,
                a         = NULL,
                b         = NULL,
                kappa     = NULL,
                lambda    = NULL,
                mu        = NULL,
                s         = NULL,
                sigma     = NULL,
                theta     = NULL,
                heuristic = 1,
                maxdeg    = 5,
                ellipse_n = 4,
                pts       = FALSE,
                mlelab    = TRUE,
                sf        = c(5, 5),
                mar       = c(4, 4.5, 2, 1.5),
                xlab      = "",
                ylab      = "",
                main      = "",
                xlas      = 0,
                ylas      = 0,
                origin    = FALSE,
                xlim      = NULL,
                ylim      = NULL,
                tol       = .Machine$double.eps ^ 1,
                info      = FALSE,
                returnsamp  = FALSE,
                returnquant = FALSE,
                repair    = TRUE,
                exact     = FALSE,
                showplot  = FALSE,
                delay     = 0 )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coversim_+3A_alpha">alpha</code></td>
<td>
<p>significance level; scalar or vector; resulting plot illustrates a 100(1 - <code>alpha</code>)% confidence region.</p>
</td></tr>
<tr><td><code id="coversim_+3A_distn">distn</code></td>
<td>
<p>distribution to fit the dataset to; accepted values: <code>'cauchy'</code>, <code>'gamma'</code>, <code>'invgauss'</code>,
<code>'logis'</code>, <code>'llogis'</code>, <code>'lnorm'</code>, <code>'norm'</code>, <code>'unif'</code>, <code>'weibull'</code>.</p>
</td></tr>
<tr><td><code id="coversim_+3A_n">n</code></td>
<td>
<p>trial sample size (producing each confidence region); scalar or vector; needed if a dataset is not given.</p>
</td></tr>
<tr><td><code id="coversim_+3A_iter">iter</code></td>
<td>
<p>iterations (or replications) of individual trials per parameterization; needed if a dataset is not given.</p>
</td></tr>
<tr><td><code id="coversim_+3A_dataset">dataset</code></td>
<td>
<p>a <code>'n'</code> x <code>'iter'</code> matrix of dataset values, or a vector of length <code>'n'</code> (for a
single iteration).</p>
</td></tr>
<tr><td><code id="coversim_+3A_point">point</code></td>
<td>
<p>coverage is assessed relative to this point.</p>
</td></tr>
<tr><td><code id="coversim_+3A_seed">seed</code></td>
<td>
<p>random number generator seed.</p>
</td></tr>
<tr><td><code id="coversim_+3A_a">a</code></td>
<td>
<p>distribution parameter (when applicable).</p>
</td></tr>
<tr><td><code id="coversim_+3A_b">b</code></td>
<td>
<p>distribution parameter (when applicable).</p>
</td></tr>
<tr><td><code id="coversim_+3A_kappa">kappa</code></td>
<td>
<p>distribution parameter (when applicable).</p>
</td></tr>
<tr><td><code id="coversim_+3A_lambda">lambda</code></td>
<td>
<p>distribution parameter (when applicable).</p>
</td></tr>
<tr><td><code id="coversim_+3A_mu">mu</code></td>
<td>
<p>distribution parameter (when applicable).</p>
</td></tr>
<tr><td><code id="coversim_+3A_s">s</code></td>
<td>
<p>distribution parameter (when applicable).</p>
</td></tr>
<tr><td><code id="coversim_+3A_sigma">sigma</code></td>
<td>
<p>distribution parameter (when applicable).</p>
</td></tr>
<tr><td><code id="coversim_+3A_theta">theta</code></td>
<td>
<p>distribution parameter (when applicable).</p>
</td></tr>
<tr><td><code id="coversim_+3A_heuristic">heuristic</code></td>
<td>
<p>numeric value selecting method for plotting: 0 for elliptic-oriented point distribution, and
1 for smoothing boundary search heuristic.</p>
</td></tr>
<tr><td><code id="coversim_+3A_maxdeg">maxdeg</code></td>
<td>
<p>maximum angle tolerance between consecutive plot segments in degrees.</p>
</td></tr>
<tr><td><code id="coversim_+3A_ellipse_n">ellipse_n</code></td>
<td>
<p>number of roughly equidistant confidence region points to plot using the
elliptic-oriented point distribution (must be a multiple of four because its algorithm
exploits symmetry in the quadrants of an ellipse).</p>
</td></tr>
<tr><td><code id="coversim_+3A_pts">pts</code></td>
<td>
<p>displays confidence region boundary points if <code>TRUE</code> (applies to confidence region plots in which <code>showplot = TRUE</code>).</p>
</td></tr>
<tr><td><code id="coversim_+3A_mlelab">mlelab</code></td>
<td>
<p>logical argument to include the maximum likelihood estimate coordinate point (default is <code>TRUE</code>,
applies to confidence region plots when <code>showplot = TRUE</code>).</p>
</td></tr>
<tr><td><code id="coversim_+3A_sf">sf</code></td>
<td>
<p>significant figures in axes labels specified using sf = c(x, y), where x and y represent the optional digits argument
in the R function <code><a href="base.html#topic+round">round</a></code> as it pertains the horizontal and vertical labels.</p>
</td></tr>
<tr><td><code id="coversim_+3A_mar">mar</code></td>
<td>
<p>specifies margin values for <code>par(mar = c( ))</code> (see <code>mar</code> in <code><a href="graphics.html#topic+par">par</a></code>).</p>
</td></tr>
<tr><td><code id="coversim_+3A_xlab">xlab</code></td>
<td>
<p>string specifying the horizontal axis label (applies to confidence region plots when <code>showplot = TRUE</code>).</p>
</td></tr>
<tr><td><code id="coversim_+3A_ylab">ylab</code></td>
<td>
<p>string specifying the vertical axis label (applies to confidence region plots when <code>showplot = TRUE</code>).</p>
</td></tr>
<tr><td><code id="coversim_+3A_main">main</code></td>
<td>
<p>string specifying the plot title (applies to confidence region plots when <code>showplot = TRUE</code>).</p>
</td></tr>
<tr><td><code id="coversim_+3A_xlas">xlas</code></td>
<td>
<p>numeric in 0, 1, 2, 3 specifying the style of axis labels (see <code>las</code> in <code><a href="graphics.html#topic+par">par</a></code>,
applies to confidence region plots when <code>showplot = TRUE</code>).</p>
</td></tr>
<tr><td><code id="coversim_+3A_ylas">ylas</code></td>
<td>
<p>numeric in 0, 1, 2, 3 specifying the style of axis labels (see <code>las</code> in <code><a href="graphics.html#topic+par">par</a></code>,
applies to confidence region plots when <code>showplot = TRUE</code>).</p>
</td></tr>
<tr><td><code id="coversim_+3A_origin">origin</code></td>
<td>
<p>logical argument to include the plot origin (applies to confidence region plots when <code>showplot = TRUE</code>).</p>
</td></tr>
<tr><td><code id="coversim_+3A_xlim">xlim</code></td>
<td>
<p>two element vector containing horizontal axis minimum and maximum values (applies to confidence region plots
when <code>showplot = TRUE</code>).</p>
</td></tr>
<tr><td><code id="coversim_+3A_ylim">ylim</code></td>
<td>
<p>two element vector containing vertical axis minimum and maximum values (applies to confidence region plots
when <code>showplot = TRUE</code>).</p>
</td></tr>
<tr><td><code id="coversim_+3A_tol">tol</code></td>
<td>
<p>the <code><a href="stats.html#topic+uniroot">uniroot</a></code> parameter specifying its required accuracy.</p>
</td></tr>
<tr><td><code id="coversim_+3A_info">info</code></td>
<td>
<p>logical argument to return coverage information in a list; includes <code>alpha</code> value(s), <code>n</code> value(s), coverage
and error results per iteration, and <code>returnsamp</code> and/or <code>returnquant</code> when requested.</p>
</td></tr>
<tr><td><code id="coversim_+3A_returnsamp">returnsamp</code></td>
<td>
<p>logical argument; if <code>TRUE</code> returns random samples used in a matrix with <code>n</code> rows, <code>iter</code> cols.</p>
</td></tr>
<tr><td><code id="coversim_+3A_returnquant">returnquant</code></td>
<td>
<p>logical argument; if <code>TRUE</code> returns random quantiles used in a matrix with <code>n</code> rows, <code>iter</code> cols.</p>
</td></tr>
<tr><td><code id="coversim_+3A_repair">repair</code></td>
<td>
<p>logical argument to repair regions inaccessible using a radial angle from its MLE (multiple root azimuths).</p>
</td></tr>
<tr><td><code id="coversim_+3A_exact">exact</code></td>
<td>
<p>logical argument specifying if alpha value is adjusted to compensate for negative coverage bias in order to achieve
(1 - alpha) coverage probability using previously recorded Monte Carlo simulation results; available for limited values of
alpha (roughly &lt;= 0.2&ndash;0.3), n (typically n = 4, 5, ..., 50) and distributions (distn suffixes: weibull, llogis, norm).</p>
</td></tr>
<tr><td><code id="coversim_+3A_showplot">showplot</code></td>
<td>
<p>logical argument specifying if each coverage trial produces a plot.</p>
</td></tr>
<tr><td><code id="coversim_+3A_delay">delay</code></td>
<td>
<p>numeric value of delay (in seconds) between trials so its plot can be seen (applies when <code>showplot = TRUE</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Parameterizations for supported distributions are given following
the default axes convention in use by <code>crplot</code> and <code>coversim</code>, which are:
</p>

<table>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: center;"> Horizontal </td><td style="text-align: center;"> Vertical</td>
</tr>
<tr>
 <td style="text-align: left;">
Distribution  </td><td style="text-align: center;">  Axis  </td><td style="text-align: center;"> Axis</td>
</tr>
<tr>
 <td style="text-align: left;">
Cauchy </td><td style="text-align: center;"> <code class="reqn">a</code> </td><td style="text-align: center;"> <code class="reqn">s</code></td>
</tr>
<tr>
 <td style="text-align: left;">
gamma </td><td style="text-align: center;"> <code class="reqn">\theta</code> </td><td style="text-align: center;"> <code class="reqn">\kappa</code></td>
</tr>
<tr>
 <td style="text-align: left;">
inverse Gaussian </td><td style="text-align: center;"> <code class="reqn">\mu</code> </td><td style="text-align: center;"> <code class="reqn">\lambda</code></td>
</tr>
<tr>
 <td style="text-align: left;">
log logistic </td><td style="text-align: center;"> <code class="reqn">\lambda</code> </td><td style="text-align: center;"> <code class="reqn">\kappa</code></td>
</tr>
<tr>
 <td style="text-align: left;">
log normal </td><td style="text-align: center;"> <code class="reqn">\mu</code> </td><td style="text-align: center;"> <code class="reqn">\sigma</code></td>
</tr>
<tr>
 <td style="text-align: left;">
logistic </td><td style="text-align: center;"> <code class="reqn">\mu</code> </td><td style="text-align: center;"> <code class="reqn">\sigma</code></td>
</tr>
<tr>
 <td style="text-align: left;">
normal </td><td style="text-align: center;"> <code class="reqn">\mu</code> </td><td style="text-align: center;"> <code class="reqn">\sigma</code></td>
</tr>
<tr>
 <td style="text-align: left;">
uniform </td><td style="text-align: center;"> <code class="reqn">a</code> </td><td style="text-align: center;"> <code class="reqn">b</code></td>
</tr>
<tr>
 <td style="text-align: left;">
Weibull </td><td style="text-align: center;"> <code class="reqn">\kappa</code> </td><td style="text-align: center;"> <code class="reqn">\lambda</code>
</td>
</tr>

</table>

<p>Each respective distribution is defined below.
</p>

<ul>
<li><p> The Cauchy distribution
for the real-numbered location parameter <code class="reqn">a</code>, scale parameter <code class="reqn">s</code>, and <code class="reqn">x</code> is a real number,
has the probability density function
</p>
<p style="text-align: center;"><code class="reqn">1 / (s \pi (1 + ((x - a) / s) ^ 2)).</code>
</p>

</li>
<li><p> The gamma distribution
for shape parameter <code class="reqn">\kappa &gt; 0</code>, scale parameter <code class="reqn">\theta &gt; 0</code>, and <code class="reqn">x &gt; 0</code>,
has the probability density function
</p>
<p style="text-align: center;"><code class="reqn">1 / (Gamma(\kappa) \theta ^ \kappa) x ^ {(\kappa - 1)} \exp(-x / \theta).</code>
</p>

</li>
<li><p> The inverse Gaussian distribution
for mean <code class="reqn">\mu &gt; 0</code>, shape parameter <code class="reqn">\lambda &gt; 0</code>, and <code class="reqn">x &gt; 0</code>,
has the probability density function
</p>
<p style="text-align: center;"><code class="reqn">\sqrt{(\lambda / (2 \pi x ^ 3))} \exp( - \lambda (x - \mu) ^ 2 / (2 \mu ^ 2 x)).</code>
</p>

</li>
<li><p> The log logistic distribution
for scale parameter <code class="reqn">\lambda &gt; 0</code>, shape parameter <code class="reqn">\kappa &gt; 0</code>, and <code class="reqn">x &gt; 0</code>,
has a probability density function
</p>
<p style="text-align: center;"><code class="reqn">(\kappa \lambda) (x \lambda) ^ {(\kappa - 1)} / (1 + (\lambda x) ^ \kappa) ^ 2.</code>
</p>

</li>
<li><p> The log normal distribution
for the real-numbered mean <code class="reqn">\mu</code> of the logarithm, standard deviation <code class="reqn">\sigma &gt; 0</code>
of the logarithm, and <code class="reqn">x &gt; 0</code>,
has the probability density function
</p>
<p style="text-align: center;"><code class="reqn">1 / (x \sigma \sqrt{2 \pi}) \exp(-(\log x - \mu) ^ 2 / (2 \sigma ^ 2)).</code>
</p>

</li>
<li><p> The logistic distribution
for the real-numbered location parameter <code class="reqn">\mu</code>, scale parameter <code class="reqn">\sigma</code>, and <code class="reqn">x</code> is a real number,
has the probability density function
</p>
<p style="text-align: center;"><code class="reqn">(1 / \sigma) \exp((x - \mu) / \sigma) (1 + \exp((x - \mu) / \sigma)) ^ {-2}</code>
</p>

</li>
<li><p> The normal distribution
for the real-numbered mean <code class="reqn">\mu</code>, standard deviation <code class="reqn">\sigma &gt; 0</code>, and <code class="reqn">x</code> is a real number,
has the probability density function
</p>
<p style="text-align: center;"><code class="reqn">1 / \sqrt{2 \pi \sigma ^ 2} \exp(-(x - \mu) ^ 2 / (2 \sigma ^ 2)).</code>
</p>

</li>
<li><p> The uniform distribution for real-valued parameters <code class="reqn">a</code> and <code class="reqn">b</code> where <code class="reqn">a &lt; b</code>
and <code class="reqn">a \le x \le b</code>,
has the probability density function
</p>
<p style="text-align: center;"><code class="reqn">1 / (b - a).</code>
</p>

</li>
<li><p> The Weibull distribution
for scale parameter <code class="reqn">\lambda &gt; 0</code>, shape parameter <code class="reqn">\kappa &gt; 0</code>, and <code class="reqn">x &gt; 0</code>,
has the probability density function
</p>
<p style="text-align: center;"><code class="reqn">\kappa (\lambda ^ \kappa) x ^ {(\kappa - 1)} \exp(-(\lambda x) ^ \kappa).</code>
</p>

</li></ul>



<h3>Value</h3>

<p>If the optional argument <code>info = TRUE</code> is included then a list of coverage results is returned.  That list
includes <code>alpha</code> value(s), <code>n</code> value(s), coverage and error results per iteration.  Additionally, <code>returnsamp = TRUE</code>
and/or <code>returnquant = TRUE</code> will result in an <code>n</code> row, <code>iter</code> column maxtix of sample and/or sample cdf values.
</p>


<h3>Author(s)</h3>

<p>Christopher Weld (<a href="mailto:ceweld241@gmail.com">ceweld241@gmail.com</a>)
</p>
<p>Lawrence Leemis (<a href="mailto:leemis@math.wm.edu">leemis@math.wm.edu</a>)
</p>


<h3>References</h3>

<p>C. Weld, A. Loh, L. Leemis (2020), &quot;Plotting Two-Dimensional Confidence Regions&quot;,
The American Statistician, Volume 72, Number 2, 156&ndash;168.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+crplot">crplot</a></code>, <code><a href="stats.html#topic+uniroot">uniroot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## assess actual coverage at various alpha = {0.5, 0.1} given n = 30 samples,  completing
## 10 trials per parameterization (iter) for a normal(mean = 2, sd = 3) rv
coversim(alpha = c(0.5, 0.1), "norm", n = 30, iter = 10, mu = 2, sigma = 3)

## show plots for 5 iterations of 30 samples each from a Weibull(2, 3)
coversim(0.5, "weibull", n = 30, iter = 5, lambda = 1.5, kappa = 0.5, showplot = TRUE,
origin = TRUE)

</code></pre>

<hr>
<h2 id='crplot'>Plotting Two-Dimensional Confidence Regions</h2><span id='topic+crplot'></span>

<h3>Description</h3>

<p>Plotting a two-dimensional confidence region for probability distribution parameters (supported distribution
suffixes: cauchy, gamma, invgauss, lnorm, llogis, logis, norm, unif, weibull) corresponding to a user given
complete or right-censored dataset and level of significance.  See the CRAN website
https://CRAN.R-project.org/package=conf for a link to two <code>crplot</code> vignettes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crplot(dataset, alpha, distn,
                cen       = rep(1, length(dataset)),
                heuristic = 1,
                maxdeg    = 5,
                ellipse_n = 4,
                pts       = TRUE,
                mlelab    = TRUE,
                sf        = NULL,
                mar       = c(4, 4.5, 2, 1.5),
                xyswap    = FALSE,
                xlab      = "",
                ylab      = "",
                main      = "",
                xlas      = 0,
                ylas      = 0,
                origin    = FALSE,
                xlim      = NULL,
                ylim      = NULL,
                tol       = .Machine$double.eps ^ 1,
                info      = FALSE,
                maxcount  = 30,
                repair    = TRUE,
                jumpshift = 0.5,
                jumpuphill = min(alpha, 0.01),
                jumpinfo  = FALSE,
                showjump  = FALSE,
                showplot  = TRUE,
                animate   = FALSE,
                delay     = 0.5,
                exact     = FALSE,
                silent    = FALSE )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crplot_+3A_dataset">dataset</code></td>
<td>
<p>a vector of n data values.</p>
</td></tr>
<tr><td><code id="crplot_+3A_alpha">alpha</code></td>
<td>
<p>significance level; resulting plot illustrates a 100(1 - <code>alpha</code>)% confidence region.</p>
</td></tr>
<tr><td><code id="crplot_+3A_distn">distn</code></td>
<td>
<p>distribution to fit the dataset to; accepted values: <code>'cauchy'</code>, <code>'gamma'</code>, <code>'invgauss'</code>,
<code>'logis'</code>, <code>'llogis'</code>, <code>'lnorm'</code>, <code>'norm'</code>, <code>'unif'</code>, <code>'weibull'</code>.</p>
</td></tr>
<tr><td><code id="crplot_+3A_cen">cen</code></td>
<td>
<p>a vector of binary values specifying if the corresponding data values are right-censored (0), or
observed (1, default); its length must match length(dataset).</p>
</td></tr>
<tr><td><code id="crplot_+3A_heuristic">heuristic</code></td>
<td>
<p>numeric value selecting method for plotting: 0 for elliptic-oriented point distribution, and
1 for smoothing boundary search heuristic.</p>
</td></tr>
<tr><td><code id="crplot_+3A_maxdeg">maxdeg</code></td>
<td>
<p>maximum angle tolerance between consecutive plot segments in degrees.</p>
</td></tr>
<tr><td><code id="crplot_+3A_ellipse_n">ellipse_n</code></td>
<td>
<p>number of roughly equidistant confidence region points to plot using the
elliptic-oriented point distribution (must be a multiple of four because its algorithm
exploits symmetry in the quadrants of an ellipse).</p>
</td></tr>
<tr><td><code id="crplot_+3A_pts">pts</code></td>
<td>
<p>displays confidence region boundary points identified if <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="crplot_+3A_mlelab">mlelab</code></td>
<td>
<p>logical argument to include the maximum
likelihood estimate coordinate point (default is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="crplot_+3A_sf">sf</code></td>
<td>
<p>significant figures in axes labels specified using sf = c(x, y), where x and y represent the optional
digits argument in the R function <code><a href="base.html#topic+round">round</a></code> as it pertains to the horizontal and vertical labels.</p>
</td></tr>
<tr><td><code id="crplot_+3A_mar">mar</code></td>
<td>
<p>specifies margin values for <code>par(mar = c( ))</code> (see <code>mar</code> in <code><a href="graphics.html#topic+par">par</a></code>).</p>
</td></tr>
<tr><td><code id="crplot_+3A_xyswap">xyswap</code></td>
<td>
<p>logical argument to switch the axes that the distribution parameter are shown.</p>
</td></tr>
<tr><td><code id="crplot_+3A_xlab">xlab</code></td>
<td>
<p>string specifying the x axis label.</p>
</td></tr>
<tr><td><code id="crplot_+3A_ylab">ylab</code></td>
<td>
<p>string specifying the y axis label.</p>
</td></tr>
<tr><td><code id="crplot_+3A_main">main</code></td>
<td>
<p>string specifying the plot title.</p>
</td></tr>
<tr><td><code id="crplot_+3A_xlas">xlas</code></td>
<td>
<p>numeric in 0, 1, 2, 3 specifying the style of axis labels (see <code>las</code> in <code><a href="graphics.html#topic+par">par</a></code>).</p>
</td></tr>
<tr><td><code id="crplot_+3A_ylas">ylas</code></td>
<td>
<p>numeric in 0, 1, 2, 3 specifying the style of axis labels (see <code>las</code> in <code><a href="graphics.html#topic+par">par</a></code>).</p>
</td></tr>
<tr><td><code id="crplot_+3A_origin">origin</code></td>
<td>
<p>logical argument to include the plot origin (default is <code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="crplot_+3A_xlim">xlim</code></td>
<td>
<p>two-element vector containing horizontal axis minimum and maximum values.</p>
</td></tr>
<tr><td><code id="crplot_+3A_ylim">ylim</code></td>
<td>
<p>two-element vector containing vertical axis minimum and maximum values.</p>
</td></tr>
<tr><td><code id="crplot_+3A_tol">tol</code></td>
<td>
<p>the <code><a href="stats.html#topic+uniroot">uniroot</a></code> parameter specifying its required accuracy.</p>
</td></tr>
<tr><td><code id="crplot_+3A_info">info</code></td>
<td>
<p>logical argument to return plot information: MLE is returned as a list; (x, y) plot point coordinates
and corresponding phi angles (with respect to MLE) are returned as a list.</p>
</td></tr>
<tr><td><code id="crplot_+3A_maxcount">maxcount</code></td>
<td>
<p>integer value specifying the number of smoothing search iterations before terminating with <code>maxdeg</code> not met.</p>
</td></tr>
<tr><td><code id="crplot_+3A_repair">repair</code></td>
<td>
<p>logical argument to repair regions inaccessible using a radial angle from its MLE due to multiple
roots at select <code class="reqn">\phi</code> angles.</p>
</td></tr>
<tr><td><code id="crplot_+3A_jumpshift">jumpshift</code></td>
<td>
<p>see vignette &quot;conf Advanced Options&quot; for details; location (as a fractional value between 0 and 1) along the
vertical or horizontal &quot;gap&quot; (near an uncharted region) to locate a jump-center toward; can be either a scalar value (uniformly
applied to all jump-centers) or vector of length four (with unique values for its respective quadrants, relative to the MLE).</p>
</td></tr>
<tr><td><code id="crplot_+3A_jumpuphill">jumpuphill</code></td>
<td>
<p>see vignette &quot;conf Advanced Options&quot; for details; significance level increase to <code>alpha</code> for the jump-center
(corresponds to an &quot;uphill&quot; location on its likelihood function); can be either a scalar value (uniformly applied to all jump-centers)
or vector of length four (with unique values for its respective quadrants, relative to the MLE).</p>
</td></tr>
<tr><td><code id="crplot_+3A_jumpinfo">jumpinfo</code></td>
<td>
<p>logical argument to return plot info (see <code>info</code> argument) and jump-center info; returned within 'repair'
attribute are <code>jumpuphill</code> value, <code>jumpshift</code> value, &quot;|&quot; or &quot;-&quot; gap type, jump-center(s) coordinates, and coordinates
of points left &amp; right of the inaccessible region.</p>
</td></tr>
<tr><td><code id="crplot_+3A_showjump">showjump</code></td>
<td>
<p>logical argument specifying if jump-center repair reference points appear on the confidence region plot.</p>
</td></tr>
<tr><td><code id="crplot_+3A_showplot">showplot</code></td>
<td>
<p>logical argument specifying if a plot is output; altering from its default of <code>TRUE</code> is
only logical assuming <code>crplot</code> is run for its data only (see the <code>info</code> argument).</p>
</td></tr>
<tr><td><code id="crplot_+3A_animate">animate</code></td>
<td>
<p>logical argument specifying if an animated plot build will display; the annimation sequence is given in successive plots.</p>
</td></tr>
<tr><td><code id="crplot_+3A_delay">delay</code></td>
<td>
<p>numeric value of delay (in seconds) between successive plots when <code>animate = TRUE</code>.</p>
</td></tr>
<tr><td><code id="crplot_+3A_exact">exact</code></td>
<td>
<p>logical argument specifying if alpha value is adjusted to compensate for negative coverage bias to achieve
(1 - alpha) coverage probability using previously recorded Monte Carlo simulation results; available for limited values of
alpha (roughly &lt;= 0.2&ndash;0.3), n (typically n = 4, 5, ..., 50) and distributions (distn suffixes: weibull, llogis, norm).</p>
</td></tr>
<tr><td><code id="crplot_+3A_silent">silent</code></td>
<td>
<p>logical argument specifying if console output should be suppressed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function plots a confidence region for a variety of two-parameter distributions.  It requires:
</p>

<ul>
<li><p> a vector of dataset values,
</p>
</li>
<li><p> the level of significance (alpha), and
</p>
</li>
<li><p> a population distribution to fit the data to.
</p>
</li></ul>

<p>Plots display according to probability density function parameterization given later in this section.
Two heuristics (and their associated combination) are available to plot confidence regions.  Along
with their descriptions, they are:
</p>

<ol>
<li> <p><em>Smoothing Boundary Search Heuristic (default)</em>.  This heuristic plots more points in areas of
greater curvature to ensure a smooth appearance throughout the confidence region boundary.  Its
<code>maxdeg</code> parameter specifies the maximum tolerable angle between three successive points.
Lower values of <code>maxdeg</code> result in smoother plots, and its default value of 5 degrees
provides adequate smoothing in most circumstances.  Values of <code>maxdeg</code> <code class="reqn">\le</code> 3 are not
recommended due to their complicating implications to trigonometric numerical approximations near 0
and 1; their use may result in plot errors.
</p>
</li>
<li> <p><em>Elliptic-Oriented Point Distribution</em>.  This heuristic allows the user to specify
a number of points to plot along the confidence region boundary at roughly uniform intervals.
Its name is derived from the technique it uses to choose these points&mdash;an extension of the Steiner
generation of a non-degenerate conic section, also known as the parallelogram method&mdash;which identifies
points along an ellipse that are approximately equidistant.  To exploit the computational benefits of
ellipse symmetry over its four quadrants, <code>ellipse_n</code> value must be divisible by four.</p>
</li></ol>

<p>By default, <code>crplot</code> implements the smoothing boundary search heuristic.  Alternatively,
the user can plot using the elliptic-oriented point distribution algorithm, or a combination
of them both.  Combining the two techniques initializes the plot using the elliptic-oriented point
distribution algorithm, and then subsequently populates additional points in areas of high curvature
(those outside of the maximum angle tolerance parameterization) in accordance with the smoothing
boundary search heuristic.  This combination results when the smoothing boundary search heuristic
is specified in conjunction with an <code>ellipse_n</code> value greater than four.
</p>
<p>Both of the aforementioned heuristics use a radial profile log likelihood function to identify
points along the confidence region boundary.  It cuts the log likelihood function in a directional
azimuth from its MLE, and locates the associated confidence region boundary point using the
asymptotic results associated with the ratio test statistic <code class="reqn">-2 [\log L(\theta) - \log L(\hat{\theta})]</code>
which converges in distribution to the chi-square distribution with two degrees of freedom (for
a two parameter distribution).
</p>
<p>The default axes convention in use by <code>crplot</code> are
</p>

<table>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: center;"> Horizontal </td><td style="text-align: center;"> Vertical</td>
</tr>
<tr>
 <td style="text-align: left;">
Distribution  </td><td style="text-align: center;">  Axis  </td><td style="text-align: center;"> Axis</td>
</tr>
<tr>
 <td style="text-align: left;">
Cauchy </td><td style="text-align: center;"> <code class="reqn">a</code> </td><td style="text-align: center;"> <code class="reqn">s</code></td>
</tr>
<tr>
 <td style="text-align: left;">
gamma </td><td style="text-align: center;"> <code class="reqn">\theta</code> </td><td style="text-align: center;"> <code class="reqn">\kappa</code></td>
</tr>
<tr>
 <td style="text-align: left;">
inverse Gaussian </td><td style="text-align: center;"> <code class="reqn">\mu</code> </td><td style="text-align: center;"> <code class="reqn">\lambda</code></td>
</tr>
<tr>
 <td style="text-align: left;">
log logistic </td><td style="text-align: center;"> <code class="reqn">\lambda</code> </td><td style="text-align: center;"> <code class="reqn">\kappa</code></td>
</tr>
<tr>
 <td style="text-align: left;">
log normal </td><td style="text-align: center;"> <code class="reqn">\mu</code> </td><td style="text-align: center;"> <code class="reqn">\sigma</code></td>
</tr>
<tr>
 <td style="text-align: left;">
logistic </td><td style="text-align: center;"> <code class="reqn">\mu</code> </td><td style="text-align: center;"> <code class="reqn">\sigma</code></td>
</tr>
<tr>
 <td style="text-align: left;">
normal </td><td style="text-align: center;"> <code class="reqn">\mu</code> </td><td style="text-align: center;"> <code class="reqn">\sigma</code></td>
</tr>
<tr>
 <td style="text-align: left;">
uniform </td><td style="text-align: center;"> <code class="reqn">a</code> </td><td style="text-align: center;"> <code class="reqn">b</code></td>
</tr>
<tr>
 <td style="text-align: left;">
Weibull </td><td style="text-align: center;"> <code class="reqn">\kappa</code> </td><td style="text-align: center;"> <code class="reqn">\lambda</code>
</td>
</tr>

</table>

<p>where each respective distribution is defined below.
</p>

<ul>
<li><p> The Cauchy distribution
for the real-numbered location parameter <code class="reqn">a</code>, scale parameter <code class="reqn">s</code>, and <code class="reqn">x</code> is a real number,
has the probability density function
</p>
<p style="text-align: center;"><code class="reqn">1 / (s \pi (1 + ((x - a) / s) ^ 2)).</code>
</p>

</li>
<li><p> The gamma distribution
for shape parameter <code class="reqn">\kappa &gt; 0</code>, scale parameter <code class="reqn">\theta &gt; 0</code>, and <code class="reqn">x &gt; 0</code>,
has the probability density function
</p>
<p style="text-align: center;"><code class="reqn">1 / (Gamma(\kappa) \theta ^ \kappa) x ^ {(\kappa - 1)} exp(-x / \theta).</code>
</p>

</li>
<li><p> The inverse Gaussian distribution
for mean <code class="reqn">\mu &gt; 0</code>, shape parameter <code class="reqn">\lambda &gt; 0</code>, and <code class="reqn">x &gt; 0</code>,
has the probability density function
</p>
<p style="text-align: center;"><code class="reqn">\sqrt (\lambda / (2 \pi x ^ 3)) exp( - \lambda (x - \mu) ^ 2 / (2 \mu ^ 2 x)).</code>
</p>

</li>
<li><p> The log logistic distribution
for scale parameter <code class="reqn">\lambda &gt; 0</code>, shape parameter <code class="reqn">\kappa &gt; 0</code>, and <code class="reqn">x \ge 0</code>,
has a probability density function
</p>
<p style="text-align: center;"><code class="reqn">(\kappa \lambda) (x \lambda) ^ {(\kappa - 1)} / (1 + (\lambda x) ^ \kappa) ^ 2.</code>
</p>

</li>
<li><p> The log normal distribution
for the real-numbered mean <code class="reqn">\mu</code> of the logarithm, standard deviation <code class="reqn">\sigma &gt; 0</code>
of the logarithm, and <code class="reqn">x &gt; 0</code>,
has the probability density function
</p>
<p style="text-align: center;"><code class="reqn">1 / (x \sigma \sqrt(2 \pi)) exp(-(\log x - \mu) ^ 2 / (2 \sigma ^ 2)).</code>
</p>

</li>
<li><p> The logistic distribution
for the real-numbered location parameter <code class="reqn">\mu</code>, scale parameter <code class="reqn">\sigma</code>, and <code class="reqn">x</code> is a real number,
has the probability density function
</p>
<p style="text-align: center;"><code class="reqn">(1 / \sigma) exp((x - \mu) / \sigma) (1 + exp((x - \mu) / \sigma)) ^ {-2}</code>
</p>

</li>
<li><p> The normal distribution
for the real-numbered mean <code class="reqn">\mu</code>, standard deviation <code class="reqn">\sigma &gt; 0</code>, and <code class="reqn">x</code> is a real number,
has the probability density function
</p>
<p style="text-align: center;"><code class="reqn">1 / \sqrt (2 \pi \sigma ^ 2) exp(-(x - \mu) ^ 2 / (2 \sigma ^ 2)).</code>
</p>

</li>
<li><p> The uniform distribution for real-valued parameters <code class="reqn">a</code> and <code class="reqn">b</code> where <code class="reqn">a &lt; b</code>
and <code class="reqn">a \le x \le b</code>,
has the probability density function
</p>
<p style="text-align: center;"><code class="reqn">1 / (b - a).</code>
</p>

</li>
<li><p> The Weibull distribution
for scale parameter <code class="reqn">\lambda &gt; 0</code>, shape parameter <code class="reqn">\kappa &gt; 0</code>, and <code class="reqn">x &gt; 0</code>,
has the probability density function
</p>
<p style="text-align: center;"><code class="reqn">\kappa (\lambda ^ \kappa) x ^ {(\kappa - 1)} exp(-(\lambda x) ^ \kappa).</code>
</p>

</li></ul>



<h3>Value</h3>

<p>If the optional argument <code>info = TRUE</code> is included then a list is returned with:
</p>

<ul>
<li><p> parm1*: a vector containing the associated confidence region boundary values for parameter 1
</p>
</li>
<li><p> parm2*: a vector containing the associated confidence region boundary values for parameter 2
</p>
</li>
<li><p> phi: a vector containing the angles used
</p>
</li>
<li><p> parm1hat*: the MLE for parameter 1
</p>
</li>
<li><p> parm2hat*: the MLE for parameter 2
</p>
</li></ul>

<p>*Note: &quot;param1&quot; and &quot;param2&quot; are placeholders that will be replaced with the appropriate parameter names
based on the probability distribution.
</p>


<h3>Author(s)</h3>

<p>Christopher Weld (<a href="mailto:ceweld241@gmail.com">ceweld241@gmail.com</a>)
</p>
<p>Lawrence Leemis (<a href="mailto:leemis@math.wm.edu">leemis@math.wm.edu</a>)
</p>


<h3>References</h3>

<p>A. Jaeger (2016), &quot;Computation of Two- and Three-Dimensional Confidence Regions with the Likelihood Ratio&quot;,
The American Statistician, 49, 48&ndash;53.
</p>
<p>C. Weld, A. Loh, L. Leemis (2020), &quot;Plotting Two-Dimensional Confidence Regions&quot;,
The American Statistician, Volume 72, Number 2, 156&ndash;168.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+coversim">coversim</a></code>, <code><a href="stats.html#topic+uniroot">uniroot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## plot the 95% confidence region for Weibull shape and scale parameters
## corresponding to the given ballbearing dataset
ballbearing &lt;- c(17.88, 28.92, 33.00, 41.52, 42.12, 45.60, 48.48, 51.84,
                 51.96, 54.12, 55.56, 67.80, 68.64, 68.64, 68.88, 84.12,
                 93.12, 98.64, 105.12, 105.84, 127.92, 128.04, 173.40)
crplot(dataset = ballbearing, distn = "weibull", alpha = 0.05)

## repeat this plot using the elliptic-oriented point distribution heuristic
crplot(dataset = ballbearing, distn = "weibull", alpha = 0.05,
       heuristic = 0, ellipse_n = 80)

## combine the two heuristics, compensating any elliptic-oriented point verticies whose apparent
## angles &gt; 6 degrees with additional points, and expand the plot area to include the origin
crplot(dataset = ballbearing, distn = "weibull", alpha = 0.05,
       maxdeg = 6, ellipse_n = 80, origin = TRUE)

## next use the inverse Gaussian distribution and show no plot points
crplot(dataset = ballbearing, distn = "invgauss", alpha = 0.05,
       pts = FALSE)
</code></pre>

<hr>
<h2 id='dinvgauss'>The Inverse Gaussian Distribution</h2><span id='topic+dinvgauss'></span><span id='topic+qinvgauss'></span><span id='topic+pinvgauss'></span><span id='topic+rinvgauss'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function,
and random generation for the inverse Gaussian distribution.
The corresponding code for these functions as well as the
manual information included here is attributed to
Christophe Pouzat's STAR Package (archived 2022-05-23).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dinvgauss(x, mu = 1, sigma2 = 1, boundary = NULL, log = FALSE)
pinvgauss(q, mu = 1, sigma2 = 1, boundary = NULL, lower.tail = TRUE, log.p = FALSE)
qinvgauss(p, mu = 1, sigma2 = 1, boundary = NULL)
rinvgauss(n = 1, mu = 1, sigma2 = 1, boundary = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dinvgauss_+3A_x">x</code>, <code id="dinvgauss_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="dinvgauss_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="dinvgauss_+3A_n">n</code></td>
<td>
<p>number of observations. If <code>length(n) &gt; 1</code>, the length is taken to be
the number required.</p>
</td></tr>
<tr><td><code id="dinvgauss_+3A_mu">mu</code></td>
<td>
<p>mean value of the distribution in the default
parameterization, <code>mean value / boundary</code> otherwise. Can also
be viewed as the inverse of the drift of the latent Brownian motion.</p>
</td></tr>
<tr><td><code id="dinvgauss_+3A_sigma2">sigma2</code></td>
<td>
<p>variance of the latent Brownian motion. When this
parameterization is used (the default) the distance between the &quot;starting&quot; point
and the boundary (&quot;absorbing barrier&quot;) is set to 1.</p>
</td></tr>
<tr><td><code id="dinvgauss_+3A_boundary">boundary</code></td>
<td>
<p>distance between the starting point and the &quot;absorbing
barrier&quot; of the latent Brownian motion. When this parameterization is
used, the Brownian motion variance is set to 1.</p>
</td></tr>
<tr><td><code id="dinvgauss_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical; if <code>TRUE</code> (default), probabilities are
<code>P[X &lt;= x]</code>, otherwise, <code>P[X &gt; x]</code>.</p>
</td></tr>
<tr><td><code id="dinvgauss_+3A_log">log</code>, <code id="dinvgauss_+3A_log.p">log.p</code></td>
<td>
<p>logical; if <code>TRUE</code>, probabilities p are given as log(p).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>With the default, <code>"sigma2"</code>, parameterization (<code>mu = m,
    sigma2 = s^2</code>) the inverse
Gaussian distribution has density:
</p>
<p style="text-align: center;"><code class="reqn">%
    f(x)=\frac{1}{\sqrt{2 \, \pi \, \sigma^2 \, x^3}} \, \exp%
    (-\frac{1}{2}\frac{(x-\mu)^2}{x \, \sigma^2 \, \mu^2})
  </code>
</p>

<p>with <code class="reqn">\sigma^2 &gt; 0</code>.
The theoretical mean is: <code class="reqn">\mu</code> and the theoretical variance is:
<code class="reqn">\mu^3 \sigma^2</code>.
With the default, <code>"boundary"</code>, parameterization (<code>mu = m,
   boundary = b</code>), the inverse
Gaussian distribution has density:
</p>
<p style="text-align: center;"><code class="reqn">%
    f(x)=\frac{b}{\sqrt{2 \, \pi \, x^3}} \, \exp%
    (-\frac{1}{2}\frac{(x-b \, \mu)^2}{x \, \mu^2})
  </code>
</p>

<p>with <code class="reqn">\sigma^2 &gt; 0</code>.
The theoretical mean is: <code class="reqn">\mu \, b</code> and the theoretical variance is:
<code class="reqn">\mu^3 \sigma^2</code>.
The latent Brownian motion is described in Lindsey (2004) pp 209-213,
Whitemore and Seshadri (1987), Aalen and Gjessing (2001) and Gerstein
and Mandelbrot (1964).
</p>
<p>The expression for the distribution function is given in Eq. 4 of
Whitemore and Seshadri (1987).
</p>
<p>Initial guesses for the inversion of the distribution function used
in <code>qinvgauss</code> are obtained with the transformation of Whitemore
and Yalovsky (1978).
</p>
<p>Random variates are obtained with the method of Michael et al (1976)
which is also described by Devroye (1986, p 148) and Gentle (2003, p 193).
</p>


<h3>Value</h3>

<p><code>dinvgauss</code> gives the density, <code>pinvgauss</code> gives the
distribution function, <code>qinvgauss</code> gives the quantile function
and <code>rinvgauss</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p>Christophe Pouzat  <a href="mailto:christophe.pouzat@gmail.com">christophe.pouzat@gmail.com</a> </p>


<h3>References</h3>

<p>Gerstein, George L. and Mandelbrot, Benoit (1964) Random Walk Models
for the Spike Activity of a Single Neuron. <em>Biophys J.</em> <b>4</b>:
41&ndash;68.
</p>
<p>Whitmore, G. A. and Yalovsky, M. (1978) A normalizing logarithmic
transformation for inverse Gaussian random
variables. <em>Technometrics</em> <b>20</b>: 207&ndash;208.
</p>
<p>Whitmore, G. A. and Seshadri, V. (1987) A Heuristic
Derivation of the Inverse Gaussian Distribution. <em>The American
Statistician</em> <b>41</b>: 280&ndash;281.
</p>
<p>Aalen, Odd O. and Gjessing, Hakon K. (2001) Understanding the Shape of
the Hazard Rate: A Process Point of View. <em>Statistical Science</em>
<b>16</b>: 1&ndash;14.
</p>
<p>Lindsey, J.K. (2004) <em>Introduction to Applied Statistics: A
Modelling Approach</em>. OUP.
</p>
<p>Michael, J. R., Schucany, W. R. and Haas, R. W. (1976) Generating
random variates using transformations with multiple roots. <em>The
American Statistician</em> <b>30</b>: 88&ndash;90.
</p>
<p>Devroye, L. (1986) <em>Non-Uniform Random Variate
Generation</em>. Springer-Verlag.
</p>
<p>Gentle, J. E. (2003) <em>Random Number Generation and Monte Carlo
Methods</em>. Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+invgaussMLE">invgaussMLE</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Start with the inverse Gauss
## Define standard mu and sigma
mu.true &lt;- 0.075 ## a mean ISI of 75 ms
sigma2.true &lt;- 3
## Define a sequence of points on the time axis
X &lt;- seq(0.001, 0.3, 0.001)
## look at the density
plot(X, dinvgauss(X, mu.true, sigma2.true), type="l", xlab = "ISI (s)",ylab = "Density")

## Generate a sample of 100 ISI from this distribution
sampleSize &lt;- 100
sampIG &lt;- rinvgauss(sampleSize, mu = mu.true, sigma2 = sigma2.true)
## check out the empirical survival function (obtained with the Kaplan-Meier
## estimator) against the true one
library(survival)
sampIG.KMfit &lt;- survfit(Surv(sampIG, 1 + numeric(length(sampIG))) ~1)
plot(sampIG.KMfit, log = TRUE)
lines(X, pinvgauss(X, mu.true, sigma2.true, lower.tail = FALSE), col = 2)

## Get a ML fit
sampIGmleIG &lt;- invgaussMLE(sampIG)
## compare true and estimated parameters
rbind(est = sampIGmleIG$estimate, se = sampIGmleIG$se, true = c(mu.true, sigma2.true))
## plot contours of the log relative likelihood function
Mu &lt;- seq(sampIGmleIG$estimate[1] - 3 * sampIGmleIG$se[1],
          sampIGmleIG$estimate[1] + 3 * sampIGmleIG$se[1],
          sampIGmleIG$se[1] / 10)
Sigma2 &lt;- seq(sampIGmleIG$estimate[2] - 7 * sampIGmleIG$se[2],
              sampIGmleIG$estimate[2] + 7 * sampIGmleIG$se[2],
              sampIGmleIG$se[2] / 10)
sampIGmleIGcontour &lt;- sapply(Mu, function(mu) sapply(Sigma2,
                            function(s2) sampIGmleIG$r(mu, s2)))
contour(Mu, Sigma2, t(sampIGmleIGcontour),
        levels=c(log(c(0.5, 0.1)), -0.5 * qchisq(c(0.95, 0.99), df = 2)),
        labels=c("log(0.5)",
          "log(0.1)",
          "-1/2 * P(Chi2 = 0.95)",
          "-1/2 * P(Chi2 = 0.99)"),
        xlab = expression(mu), ylab = expression(sigma^2))
points(mu.true, sigma2.true, pch = 16,col = 2)
## We can see that the contours are more parabola like on a log scale
contour(log(Mu),log(Sigma2),t(sampIGmleIGcontour),
        levels = c(log(c(0.5, 0.1)), -0.5 * qchisq(c(0.95, 0.99), df = 2)),
        labels = c("log(0.5)",
          "log(0.1)",
          "-1/2 * P(Chi2 = 0.95)",
          "-1/2 * P(Chi2 = 0.99)"),
        xlab = expression(log(mu)), ylab = expression(log(sigma^2)))
points(log(mu.true), log(sigma2.true), pch = 16, col = 2)
## make a deviance test for the true parameters
pchisq(-2 * sampIGmleIG$r(mu.true, sigma2.true), df = 2)
## check fit with a QQ plot
qqDuration(sampIGmleIG, log = "xy")

## Generate a censored sample using an exponential distribution
sampEXP &lt;- rexp(sampleSize, 1/(2 * mu.true))
sampIGtime &lt;- pmin(sampIG,sampEXP)
sampIGstatus &lt;- as.numeric(sampIG &lt;= sampEXP)
## fit the censored sample
sampIG2mleIG &lt;- invgaussMLE(sampIGtime, sampIGstatus)
## look at the results
rbind(est = sampIG2mleIG$estimate,
      se = sampIG2mleIG$se,
      true = c(mu.true,sigma2.true))
pchisq(-2 * sampIG2mleIG$r(mu.true, sigma2.true), df = 2)
## repeat the survival function estimation
sampIG2.KMfit &lt;- survfit(Surv(sampIGtime, sampIGstatus) ~1)
plot(sampIG2.KMfit, log = TRUE)
lines(X, pinvgauss(X, sampIG2mleIG$estimate[1], sampIG2mleIG$estimate[2],
                  lower.tail = FALSE), col = 2)

## End(Not run)
</code></pre>

<hr>
<h2 id='dllogis'>The Log Logistic Distribution</h2><span id='topic+dllogis'></span><span id='topic+pllogis'></span><span id='topic+qllogis'></span><span id='topic+rllogis'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function,
and random generation for the log logistic distribution.
The corresponding code for these functions as well as the
manual information included here is attributed to
Christophe Pouzat's STAR Package (archived 2022-05-23).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dllogis(x, location = 0, scale = 1, log = FALSE)
pllogis(q, location = 0, scale = 1, lower.tail = TRUE, log.p = FALSE)
qllogis(p, location = 0, scale = 1, lower.tail = TRUE, log.p = FALSE)
rllogis(n, location = 0, scale = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dllogis_+3A_x">x</code>, <code id="dllogis_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="dllogis_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="dllogis_+3A_n">n</code></td>
<td>
<p>number of observations. If <code>length(n) &gt; 1</code>, the length
is taken to be the number required.</p>
</td></tr>
<tr><td><code id="dllogis_+3A_location">location</code>, <code id="dllogis_+3A_scale">scale</code></td>
<td>
<p>location and scale parameters (non-negative numeric).</p>
</td></tr>
<tr><td><code id="dllogis_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical; if <code>TRUE</code> (default), probabilities are
<code>P[X &lt;= x]</code>, otherwise, <code>P[X &gt; x]</code>.</p>
</td></tr>
<tr><td><code id="dllogis_+3A_log">log</code>, <code id="dllogis_+3A_log.p">log.p</code></td>
<td>
<p>logical; if <code>TRUE</code>, probabilities p are given as log(p).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>location</code> or <code>scale</code> are omitted, they assume the
default values of 0 and 1 respectively.
</p>
<p>The log-logistic distribution with <code>location = m</code> and <code>scale
    = s</code> has distribution function
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{F}(x) = \frac{1}{1+ \exp(-\frac{\log (x) - m}{s})}</code>
</p>

<p>and density
</p>
<p style="text-align: center;"><code class="reqn">f(x)=\frac{1}{s \, x} \frac{\exp (-\frac{\log (x) - m}{s})}{(1+ \exp(-\frac{\log (x) - m}{s}))^2}</code>
</p>
<p>.
</p>


<h3>Value</h3>

<p><code>dllogis</code> gives the density, <code>pllogis</code> gives the
distribution function, <code>qllogis</code> gives the quantile function
and <code>rllogis</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p>Christophe Pouzat  <a href="mailto:christophe.pouzat@gmail.com">christophe.pouzat@gmail.com</a> </p>


<h3>References</h3>

<p>Lindsey, J.K. (2004) <em>Introduction to Applied Statistics: A
Modelling Approach</em>. OUP.
</p>
<p>Lindsey, J.K. (2004) <em>The Statistical Analysis of Stochastic
Processes in Time</em>. CUP.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+llogisMLE">llogisMLE</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
tSeq &lt;- seq(0.001,0.6,0.001)
location.true &lt;- -2.7
scale.true &lt;- 0.025
Yd &lt;- dllogis(tSeq, location.true, scale.true)
Yh &lt;- hllogis(tSeq, location.true, scale.true)
max.Yd &lt;- max(Yd)
max.Yh &lt;- max(Yh)
Yd &lt;- Yd / max.Yd
Yh &lt;- Yh / max.Yh
oldpar &lt;- par(mar=c(5,4,4,4))
plot(tSeq, Yd, type="n", axes=FALSE, ann=FALSE,
     xlim=c(0,0.6), ylim=c(0,1))
axis(2,at=seq(0,1,0.2),labels=round(seq(0,1,0.2)*max.Yd,digits=2))
mtext("Density (1/s)", side=2, line=3)
axis(1,at=pretty(c(0,0.6)))
mtext("Time (s)", side=1, line=3)
axis(4, at=seq(0,1,0.2), labels=round(seq(0,1,0.2)*max.Yh,digits=2))
mtext("Hazard (1/s)", side=4, line=3, col=2)
mtext("Log Logistic Density and Hazard Functions", side=3, line=2,cex=1.5)
lines(tSeq,Yd)
lines(tSeq,Yh,col=2)
par(oldpar)

## End(Not run)
</code></pre>

<hr>
<h2 id='gammaMLE'>Maximum Likelihood Parameter Estimation of a Gamma Model with Possibly
Censored Data</h2><span id='topic+gammaMLE'></span>

<h3>Description</h3>

<p>Estimate gamma model parameters by the maximum likelihood
method using possibly censored data. Two different parameterizations
of the gamma distribution can be used.
The corresponding code for this function as well as the
manual information included here is attributed to
Christophe Pouzat's STAR Package (archived 2022-05-23).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gammaMLE(yi, ni = numeric(length(yi)) + 1,
         si = numeric(length(yi)) + 1, scale = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gammaMLE_+3A_yi">yi</code></td>
<td>
<p>vector of (possibly binned) observations or a
<code>spikeTrain</code> object.</p>
</td></tr>
<tr><td><code id="gammaMLE_+3A_ni">ni</code></td>
<td>
<p>vector of counts for each value of <code>yi</code>; default: <code>numeric(length(yi))+1</code>.</p>
</td></tr>
<tr><td><code id="gammaMLE_+3A_si">si</code></td>
<td>
<p>vector of counts of <em>uncensored</em> observations for each
value of <code>yi</code>; default: <code>numeric(length(yi))+1</code>.</p>
</td></tr>
<tr><td><code id="gammaMLE_+3A_scale">scale</code></td>
<td>
<p>logical should the scale (<code>TRUE</code>) or the rate
parameterization (<code>FALSE</code>) be used?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There is no closed form expression for the MLE of a gamma distribution. The
numerical method implemented here uses the profile likelihood
described by Monahan (2001) pp 210-216.
</p>
<p>In order to ensure good behavior of the numerical optimization
routines, optimization is performed on the log of the parameters
(<code>shape</code> and <code>scale</code> or <code>rate</code>).
</p>
<p>Standard errors are obtained from the inverse of the observed
information matrix at the MLE. They are transformed to go from the log
scale used by the optimization routine to the parameterization requested.
</p>


<h3>Value</h3>

<p>A list of class <code>durationFit</code> with the following components:
</p>
<table>
<tr><td><code>estimate</code></td>
<td>
<p>the estimated parameters, a named vector.</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>the standard errors, a named vector.</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>the log likelihood at maximum.</p>
</td></tr>
<tr><td><code>r</code></td>
<td>
<p>a function returning the log of the relative likelihood function.</p>
</td></tr>
<tr><td><code>mll</code></td>
<td>
<p>a function returning the opposite of the log likelihood
function using the log of the parameters.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The returned standard errors (component <code>se</code>) are valid in the asymptotic limit. You
should plot contours using function <code>r</code> in the returned list and
check that the contours are reasonably close to ellipses.
</p>


<h3>Author(s)</h3>

<p>Christophe Pouzat  <a href="mailto:christophe.pouzat@gmail.com">christophe.pouzat@gmail.com</a> </p>


<h3>References</h3>

<p>Monahan, J. F. (2001) <em>Numerical Methods of Statistics</em>. CUP.
</p>
<p>Lindsey, J.K. (2004) <em>Introduction to Applied Statistics: A
Modelling Approach</em>. OUP.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+invgaussMLE">invgaussMLE</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Simulate sample of size 100 from a gamma distribution
set.seed(1102006,"Mersenne-Twister")
sampleSize &lt;- 100
shape.true &lt;- 6
scale.true &lt;- 0.012
sampGA &lt;- rgamma(sampleSize,shape=shape.true,scale=scale.true)
sampGAmleGA &lt;- gammaMLE(sampGA)
rbind(est = sampGAmleGA$estimate,se = sampGAmleGA$se,true = c(shape.true,scale.true))

## Estimate the log relative likelihood on a grid to plot contours
Shape &lt;- seq(sampGAmleGA$estimate[1]-4*sampGAmleGA$se[1],
               sampGAmleGA$estimate[1]+4*sampGAmleGA$se[1],
               sampGAmleGA$se[1]/10)
Scale &lt;- seq(sampGAmleGA$estimate[2]-4*sampGAmleGA$se[2],
             sampGAmleGA$estimate[2]+4*sampGAmleGA$se[2],
             sampGAmleGA$se[2]/10)
sampGAmleGAcontour &lt;- sapply(Shape, function(sh) sapply(Scale, function(sc) sampGAmleGA$r(sh,sc)))
## plot contours using a linear scale for the parameters
## draw four contours corresponding to the following likelihood ratios:
##  0.5, 0.1, Chi2 with 2 df and p values of 0.95 and 0.99
X11(width=12,height=6)
layout(matrix(1:2,ncol=2))
contour(Shape,Scale,t(sampGAmleGAcontour),
        levels=c(log(c(0.5,0.1)),-0.5*qchisq(c(0.95,0.99),df=2)),
        labels=c("log(0.5)",
          "log(0.1)",
          "-1/2*P(Chi2=0.95)",
          "-1/2*P(Chi2=0.99)"),
        xlab="shape",ylab="scale",
        main="Log Relative Likelihood Contours"
        )
points(sampGAmleGA$estimate[1],sampGAmleGA$estimate[2],pch=3)
points(shape.true,scale.true,pch=16,col=2)
## The contours are not really symmetrical about the MLE we can try to
## replot them using a log scale for the parameters to see if that improves
## the situation
contour(log(Shape),log(Scale),t(sampGAmleGAcontour),
        levels=c(log(c(0.5,0.1)),-0.5*qchisq(c(0.95,0.99),df=2)),
        labels="",
        xlab="log(shape)",ylab="log(scale)",
        main="Log Relative Likelihood Contours",
        sub="log scale for the parameters")
points(log(sampGAmleGA$estimate[1]),log(sampGAmleGA$estimate[2]),pch=3)
points(log(shape.true),log(scale.true),pch=16,col=2)

## make a parametric boostrap to check the distribution of the deviance
nbReplicate &lt;- 10000
sampleSize &lt;- 100
system.time(
            devianceGA100 &lt;- replicate(nbReplicate,{
                             sampGA &lt;- rgamma(sampleSize,shape=shape.true,scale=scale.true)
                             sampGAmleGA &lt;- gammaMLE(sampGA)
                             -2*sampGAmleGA$r(shape.true,scale.true)
                           }
                                       )
            )[3]

## Get 95 and 99% confidence intervals for the QQ plot
ci &lt;- sapply(1:nbReplicate,
                 function(idx) qchisq(qbeta(c(0.005,0.025,0.975,0.995),
                                            idx,
                                            nbReplicate-idx+1),
                                      df=2)
             )
## make QQ plot
X &lt;- qchisq(ppoints(nbReplicate),df=2)
Y &lt;- sort(devianceGA100)
X11()
plot(X,Y,type="n",
     xlab=expression(paste(chi[2]^2," quantiles")),
     ylab="MC quantiles",
     main="Deviance with true parameters after ML fit of gamma data",
     sub=paste("sample size:", sampleSize,"MC replicates:", nbReplicate)
     )
abline(a=0,b=1)
lines(X,ci[1,],lty=2)
lines(X,ci[2,],lty=2)
lines(X,ci[3,],lty=2)
lines(X,ci[4,],lty=2)
lines(X,Y,col=2)

## End(Not run)
</code></pre>

<hr>
<h2 id='invgaussMLE'>Maximum Likelihood Parameter Estimation of an Inverse Gaussian Model with Possibly
Censored Data</h2><span id='topic+invgaussMLE'></span>

<h3>Description</h3>

<p>Estimate inverse Gaussian model parameters by the maximum likelihood
method using possibly censored data. Two different parameterizations
of the inverse Gaussian distribution can be used.
The corresponding code for this function as well as the
manual information included here is attributed to
Christophe Pouzat's STAR Package (archived 2022-05-23).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>invgaussMLE(yi, ni = numeric(length(yi)) + 1,
            si = numeric(length(yi)) + 1,
            parameterization = "sigma2")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="invgaussMLE_+3A_yi">yi</code></td>
<td>
<p>vector of (possibly binned) observations or a
<code>spikeTrain</code> object.</p>
</td></tr>
<tr><td><code id="invgaussMLE_+3A_ni">ni</code></td>
<td>
<p>vector of counts for each value of <code>yi</code>; default: <code>numeric(length(yi))+1</code>.</p>
</td></tr>
<tr><td><code id="invgaussMLE_+3A_si">si</code></td>
<td>
<p>vector of counts of <em>uncensored</em> observations for each
value of <code>yi</code>; default: <code>numeric(length(yi))+1</code>.</p>
</td></tr>
<tr><td><code id="invgaussMLE_+3A_parameterization">parameterization</code></td>
<td>
<p>parameterization used, <code>"sigma2"</code>
(default) of <code>"boundary"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The two different parameterizations of the inverse Gaussian distribution
are discussed in the manual of <code><a href="#topic+dinvgauss">dinvgauss</a></code>.
</p>
<p>In the absence of censored data the ML estimates are available in
closed form (Lindsey, 2004, p 212) together with the Hessian matrix at
the MLE. In presence of censored data an initial guess for the
parameters is obtained using the uncensored data before maximizing the
likelihood function to the full data set using <code><a href="stats.html#topic+optim">optim</a></code>
with the <code>BFGS</code> method. ML
estimation is always performed with the <code>"sigma2"</code>
parameterization. Parameters and variance-covariance matrix are
transformed at the end if the <code>"boundary"</code> parameterization is
requested.
</p>
<p>In order to ensure good behavior of the numerical optimization
routines, optimization is performed on the log of the parameters
(<code>mu</code> and <code>sigma2</code>).
</p>
<p>Standard errors are obtained from the inverse of the observed
information matrix at the MLE. They are transformed to go from the log
scale used by the optimization routine, when the latter is used (ie,
for censored data) to the parameterization requested.
</p>


<h3>Value</h3>

<p>A list of class <code>durationFit</code> with the following components:
</p>
<table>
<tr><td><code>estimate</code></td>
<td>
<p>the estimated parameters, a named vector.</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>the standard errors, a named vector.</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>the log likelihood at maximum.</p>
</td></tr>
<tr><td><code>r</code></td>
<td>
<p>a function returning the log of the relative likelihood function.</p>
</td></tr>
<tr><td><code>mll</code></td>
<td>
<p>a function returning the opposite of the log likelihood
function using the log of the parameters.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The returned standard errors (component <code>se</code>) are valid in the asymptotic limit. You
should plot contours using function <code>r</code> in the returned list and
check that the contours are reasonably close to ellipses.
</p>


<h3>Author(s)</h3>

<p>Christophe Pouzat  <a href="mailto:christophe.pouzat@gmail.com">christophe.pouzat@gmail.com</a> </p>


<h3>References</h3>

<p>Lindsey, J.K. (2004) <em>Introduction to Applied Statistics: A
Modelling Approach</em>. OUP.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dinvgauss">dinvgauss</a></code>, <code><a href="#topic+gammaMLE">gammaMLE</a></code>, <code><a href="#topic+llogisMLE">llogisMLE</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simulate sample of size 100 from an inverse Gaussian
## distribution
set.seed(1102006,"Mersenne-Twister")
sampleSize &lt;- 100
mu.true &lt;- 0.075
sigma2.true &lt;- 3
sampleSize &lt;- 100
sampIG &lt;- rinvgauss(sampleSize,mu=mu.true,sigma2=sigma2.true)
## Make a maximum likelihood fit
sampIGmleIG &lt;- invgaussMLE(sampIG)
## Compare estimates with actual values
rbind(est = coef(sampIGmleIG),se = sampIGmleIG$se,true = c(mu.true,sigma2.true))
## In the absence of censoring the MLE of the inverse Gaussian is available in a
## closed form together with its variance (ie, the observed information matrix)
## we can check that we did not screw up at that stage by comparing the observed
## information matrix obtained numerically with the analytical one. To do that we
## use the MINUS log likelihood function returned by invgaussMLE to get a numerical
## estimate
detailedFit &lt;- optim(par=as.vector(log(sampIGmleIG$estimate)),
                     fn=sampIGmleIG$mll,
                     method="BFGS",
                     hessian=TRUE)
## We should not forget that the "mll" function uses the log of the parameters while
## the "se" component of sampIGmleIG list is expressed on the linear scale we must therefore
## transform one into the other as follows (Kalbfleisch, 1985, p71):
## if x = exp(u) and y = exp(v) and if we have the information matrix in term of
## u and v (that's the hessian component of list detailedFit above), we create matrix:
##      du/dx du/dy
## Q =
##      dv/dx dv/dy
## and we get I in term of x and y by the following matrix product:
## I(x,y) &lt;- t(Q) %*% I(u,v) %*% Q
## In the present case:
##  du/dx = 1/exp(u), du/dy = 0, dv/dx = 0, dv/dy = 1/exp(v)
## Therefore:
Q &lt;- diag(1/exp(detailedFit$par))
numericalI &lt;- t(Q) %*% detailedFit$hessian %*% Q
seComp &lt;- rbind(sampIGmleIG$se, sqrt(diag(solve(numericalI))))
colnames(seComp) &lt;- c("mu","sigma2")
rownames(seComp) &lt;- c("analytical", "numerical")
seComp
## We can check the relative differences between the 2
apply(seComp,2,function(x) abs(diff(x))/x[1])

## Not run: 
## Estimate the log relative likelihood on a grid to plot contours
Mu &lt;- seq(coef(sampIGmleIG)[1]-4*sampIGmleIG$se[1],
          coef(sampIGmleIG)[1]+4*sampIGmleIG$se[1],
          sampIGmleIG$se[1]/10)
Sigma2 &lt;- seq(coef(sampIGmleIG)[2]-4*sampIGmleIG$se[2],
              coef(sampIGmleIG)[2]+4*sampIGmleIG$se[2],
              sampIGmleIG$se[2]/10)
sampIGmleIGcontour &lt;- sapply(Mu, function(mu) sapply(Sigma2, function(s2) sampIGmleIG$r(mu,s2)))
## plot contours using a linear scale for the parameters
## draw four contours corresponding to the following likelihood ratios:
##  0.5, 0.1, Chi2 with 2 df and p values of 0.95 and 0.99
X11(width=12,height=6)
layout(matrix(1:2,ncol=2))
contour(Mu,Sigma2,t(sampIGmleIGcontour),
        levels=c(log(c(0.5,0.1)),-0.5*qchisq(c(0.95,0.99),df=2)),
        labels=c("log(0.5)",
          "log(0.1)",
          "-1/2*P(Chi2=0.95)",
          "-1/2*P(Chi2=0.99)"),
        xlab=expression(mu),ylab=expression(sigma^2),
        main="Log Relative Likelihood Contours"
        )
points(coef(sampIGmleIG)[1],coef(sampIGmleIG)[2],pch=3)
points(mu.true,sigma2.true,pch=16,col=2)
## The contours are not really symmetrical about the MLE we can try to
## replot them using a log scale for the parameters to see if that improves
## the situation
contour(log(Mu),log(Sigma2),t(sampIGmleIGcontour),
        levels=c(log(c(0.5,0.1)),-0.5*qchisq(c(0.95,0.99),df=2)),
        labels="",
        xlab=expression(log(mu)),ylab=expression(log(sigma^2)),
        main="Log Relative Likelihood Contours",
        sub="log scale for the parameters")
points(log(coef(sampIGmleIG)[1]),log(coef(sampIGmleIG)[2]),pch=3)
points(log(mu.true),log(sigma2.true),pch=16,col=2)

## Even with the log scale the contours are not ellipsoidal, so let us compute profiles
## For that we are going to use the returned MINUS log likelihood function
logMuProfFct &lt;- function(logMu,...) {
  myOpt &lt;- optimise(function(x) sampIGmleIG$mll(c(logMu,x))+logLik(sampIGmleIG),...)
  as.vector(unlist(myOpt[c("objective","minimum")]))
}
logMuProfCI &lt;- function(logMu,
                        CI,
                        a=logS2Seq[1],
                        b=logS2Seq[length(logS2Seq)]) logMuProfFct(logMu,c(a,b))[1] - qchisq(CI,1)/2

logS2ProfFct &lt;- function(logS2,...) {
  myOpt &lt;- optimise(function(x) sampIGmleIG$mll(c(x,logS2))+logLik(sampIGmleIG),...)
  as.vector(unlist(myOpt[c("objective","minimum")]))
}
logS2ProfCI &lt;- function(logS2, CI,
                        a=logMuSeq[1],
                        b=logMuSeq[length(logMuSeq)]) logS2ProfFct(logS2,c(a,b))[1] - qchisq(CI,1)/2


## We compute profiles (on the log scale) eploxing +/- 3 times
## the se about the MLE
logMuSE &lt;- sqrt(diag(solve(detailedFit$hessian)))[1]
logMuSeq &lt;- seq(log(coef(sampIGmleIG)[1])-3*logMuSE,
                log(coef(sampIGmleIG)[1])+3*logMuSE,
                logMuSE/10)
logS2SE &lt;- sqrt(diag(solve(detailedFit$hessian)))[2]
logS2Seq &lt;- seq(log(coef(sampIGmleIG)[2])-3*logS2SE,
                log(coef(sampIGmleIG)[2])+3*logS2SE,
                logS2SE/10)
logMuProf &lt;- sapply(logMuSeq,logMuProfFct,
                    lower=logS2Seq[1],
                    upper=logS2Seq[length(logS2Seq)])
## Get 95
logMuCI95 &lt;- c(uniroot(logMuProfCI,
                       interval=c(logMuSeq[1],log(coef(sampIGmleIG)[1])),
                       CI=0.95)$root,
               uniroot(logMuProfCI,
                       interval=c(log(coef(sampIGmleIG)[1]),logMuSeq[length(logMuSeq)]),
                       CI=0.95)$root
               )
logMuCI99 &lt;- c(uniroot(logMuProfCI,
                       interval=c(logMuSeq[1],log(coef(sampIGmleIG)[1])),
                       CI=0.99)$root,
               uniroot(logMuProfCI,
                       interval=c(log(coef(sampIGmleIG)[1]),logMuSeq[length(logMuSeq)]),
                       CI=0.99)$root
               )

logS2Prof &lt;- sapply(logS2Seq,logS2ProfFct,
                    lower=logMuSeq[1],
                    upper=logMuSeq[length(logMuSeq)])
## Get 95
logS2CI95 &lt;- c(uniroot(logS2ProfCI,
                       interval=c(logS2Seq[1],log(coef(sampIGmleIG)[2])),
                       CI=0.95)$root,
               uniroot(logS2ProfCI,
                       interval=c(log(coef(sampIGmleIG)[2]),logS2Seq[length(logS2Seq)]),
                       CI=0.95)$root
               )
logS2CI99 &lt;- c(uniroot(logS2ProfCI,
                       interval=c(logS2Seq[1],log(coef(sampIGmleIG)[2])),
                       CI=0.99)$root,
               uniroot(logS2ProfCI,
                       interval=c(log(coef(sampIGmleIG)[2]),logS2Seq[length(logS2Seq)]),
                       CI=0.99)$root
               )


## Add profiles to the previous plot
lines(logMuSeq,logMuProf[2,],col=2,lty=2)
lines(logS2Prof[2,],logS2Seq,col=2,lty=2)

## We can now check the deviations of the (profiled) deviances
## from the asymptotic parabolic curves
X11()
layout(matrix(1:4,nrow=2))
oldpar &lt;- par(mar=c(4,4,2,1))
logMuSeqOffset &lt;- logMuSeq-log(coef(sampIGmleIG)[1])
logMuVar &lt;- diag(solve(detailedFit$hessian))[1]
plot(logMuSeq,2*logMuProf[1,],type="l",xlab=expression(log(mu)),ylab="Deviance")
lines(logMuSeq,logMuSeqOffset^2/logMuVar,col=2)
points(log(coef(sampIGmleIG)[1]),0,pch=3)
abline(h=0)
abline(h=qchisq(0.95,1),lty=2)
abline(h=qchisq(0.99,1),lty=2)
lines(rep(logMuCI95[1],2),c(0,qchisq(0.95,1)),lty=2)
lines(rep(logMuCI95[2],2),c(0,qchisq(0.95,1)),lty=2)
lines(rep(logMuCI99[1],2),c(0,qchisq(0.99,1)),lty=2)
lines(rep(logMuCI99[2],2),c(0,qchisq(0.99,1)),lty=2)
## We can also "linearize" this last graph
plot(logMuSeq,
     sqrt(2*logMuProf[1,])*sign(logMuSeqOffset),
     type="l",
     xlab=expression(log(mu)),
     ylab=expression(paste("signed ",sqrt(Deviance)))
     )
lines(logMuSeq,
      sqrt(logMuSeqOffset^2/logMuVar)*sign(logMuSeqOffset),
      col=2)
points(log(coef(sampIGmleIG)[1]),0,pch=3)

logS2SeqOffset &lt;- logS2Seq-log(coef(sampIGmleIG)[2])
logS2Var &lt;- diag(solve(detailedFit$hessian))[2]
plot(logS2Seq,2*logS2Prof[1,],type="l",xlab=expression(log(sigma^2)),ylab="Deviance")
lines(logS2Seq,logS2SeqOffset^2/logS2Var,col=2)
points(log(coef(sampIGmleIG)[2]),0,pch=3)
abline(h=0)
abline(h=qchisq(0.95,1),lty=2)
abline(h=qchisq(0.99,1),lty=2)
lines(rep(logS2CI95[1],2),c(0,qchisq(0.95,1)),lty=2)
lines(rep(logS2CI95[2],2),c(0,qchisq(0.95,1)),lty=2)
lines(rep(logS2CI99[1],2),c(0,qchisq(0.99,1)),lty=2)
lines(rep(logS2CI99[2],2),c(0,qchisq(0.99,1)),lty=2)
## We can also "linearize" this last graph
plot(logS2Seq,
     sqrt(2*logS2Prof[1,])*sign(logS2SeqOffset),
     type="l",
     xlab=expression(log(sigma^2)),
     ylab=expression(paste("signed ",sqrt(Deviance)))
     )
lines(logS2Seq,
      sqrt(logS2SeqOffset^2/logS2Var)*sign(logS2SeqOffset),
      col=2)
points(log(coef(sampIGmleIG)[2]),0,pch=3)
par(oldpar)

## make a parametric boostrap to check the distribution of the deviance
nbReplicate &lt;- 1000 #10000
sampleSize &lt;- 100
system.time(
devianceIG100 &lt;- lapply(1:nbReplicate,
                        function(idx) {
                          if ((idx 
                          sampIG &lt;- rinvgauss(sampleSize,mu=mu.true,sigma2=sigma2.true)
                          sampIGmleIG &lt;- invgaussMLE(sampIG)
                          Deviance &lt;- -2*sampIGmleIG$r(mu.true,sigma2.true)
                          logPara &lt;- log(coef(sampIGmleIG))
                          logParaSE &lt;- sampIGmleIG$se/coef(sampIGmleIG)
                          intervalMu &lt;- function(n) c(-n,n)*logParaSE[1]+logPara[1]
                          intervalS2 &lt;- function(n) c(-n,n)*logParaSE[2]+logPara[2]
                          logMuProfFct &lt;- function(logMu,...) {
                            optimise(function(x)
                                     sampIGmleIG$mll(c(logMu,x))+logLik(sampIGmleIG),...)$objective
                          }
                          logMuProfCI &lt;- function(logMu,
                                                  CI,
                                                  a=intervalS2(4)[1],
                                                  b=intervalS2(4)[2])
                            logMuProfFct(logMu,c(a,b)) - qchisq(CI,1)/2

                          logS2ProfFct &lt;- function(logS2,...) {
                            optimise(function(x)
                                     sampIGmleIG$mll(c(x,logS2))+logLik(sampIGmleIG),...)$objective
                          }
                          logS2ProfCI &lt;- function(logS2, CI,
                                                  a=intervalMu(4)[1],
                                                  b=intervalMu(4)[2])
                            logS2ProfFct(logS2,c(a,b)) - qchisq(CI,1)/2

                          factor &lt;- 4
                          while((logMuProfCI(intervalMu(factor)[2],0.99) *
                                 logMuProfCI(logPara[1],0.99) &gt;= 0) ||
                                (logMuProfCI(intervalMu(factor)[1],0.99) *
                                 logMuProfCI(logPara[1],0.99) &gt;= 0)
                                ) factor &lt;- factor+1
                          ##browser()
                          logMuCI95 &lt;- c(uniroot(logMuProfCI,
                                                 interval=c(intervalMu(factor)[1],logPara[1]),
                                                 CI=0.95)$root,
                                         uniroot(logMuProfCI,
                                                 interval=c(logPara[1],intervalMu(factor)[2]),
                                                 CI=0.95)$root
                                         )
                          logMuCI99 &lt;- c(uniroot(logMuProfCI,
                                                 interval=c(intervalMu(factor)[1],logPara[1]),
                                                 CI=0.99)$root,
                                         uniroot(logMuProfCI,
                                                 interval=c(logPara[1],intervalMu(factor)[2]),
                                                 CI=0.99)$root
                                         )
                          factor &lt;- 4
                          while((logS2ProfCI(intervalS2(factor)[2],0.99) *
                                 logS2ProfCI(logPara[2],0.99) &gt;= 0) ||
                                (logS2ProfCI(intervalS2(factor)[1],0.99) *
                                 logS2ProfCI(logPara[2],0.99) &gt;= 0)
                                ) factor &lt;- factor+1
                          logS2CI95 &lt;- c(uniroot(logS2ProfCI,
                                                 interval=c(intervalS2(factor)[1],logPara[2]),
                                                 CI=0.95)$root,
                                         uniroot(logS2ProfCI,
                                                    interval=c(logPara[2],intervalS2(factor)[2]),
                                                 CI=0.95)$root
                                         )
                          logS2CI99 &lt;- c(uniroot(logS2ProfCI,
                                                 interval=c(intervalS2(factor)[1],logPara[2]),
                                                 CI=0.99)$root,
                                         uniroot(logS2ProfCI,
                                                 interval=c(logPara[2],intervalS2(factor)[2]),
                                                 CI=0.99)$root
                                         )
                          list(deviance=Deviance,
                               logMuCI95=logMuCI95,
                               logMuNorm95=qnorm(c(0.025,0.975),logPara[1],logParaSE[1]),
                               logMuCI99=logMuCI99,
                               logMuNorm99=qnorm(c(0.005,0.995),logPara[1],logParaSE[1]),
                               logS2CI95=logS2CI95,
                               logS2Norm95=qnorm(c(0.025,0.975),logPara[2],logParaSE[2]),
                               logS2CI99=logS2CI99,
                               logS2Norm99=qnorm(c(0.005,0.995),logPara[2],logParaSE[2]))
                        }
                        )
            )[3]
## Find out how many times the true parameters was within the computed CIs
nLogMuCI95 &lt;- sum(sapply(devianceIG100,
                         function(l) l$logMuCI95[1] &lt;= log(mu.true)  &amp;&amp;
                         log(mu.true)&lt;= l$logMuCI95[2]
                         )
                  )
nLogMuNorm95 &lt;- sum(sapply(devianceIG100,
                           function(l) l$logMuNorm95[1] &lt;= log(mu.true)  &amp;&amp;
                           log(mu.true)&lt;= l$logMuNorm95[2]
                           )
                    )
nLogMuCI99 &lt;- sum(sapply(devianceIG100,
                         function(l) l$logMuCI99[1] &lt;= log(mu.true)  &amp;&amp;
                         log(mu.true)&lt;= l$logMuCI99[2]
                         )
                  )
nLogMuNorm99 &lt;- sum(sapply(devianceIG100,
                           function(l) l$logMuNorm99[1] &lt;= log(mu.true)  &amp;&amp;
                           log(mu.true)&lt;= l$logMuNorm99[2]
                           )
                    )
## Check if these counts are compatible with the nominal CIs
c(prof95Mu=nLogMuCI95,norm95Mu=nLogMuNorm95)
qbinom(c(0.005,0.995),nbReplicate,0.95)
c(prof95Mu=nLogMuCI99,norm95Mu=nLogMuNorm99)
qbinom(c(0.005,0.995),nbReplicate,0.99)

nLogS2CI95 &lt;- sum(sapply(devianceIG100,
                         function(l) l$logS2CI95[1] &lt;= log(sigma2.true)  &amp;&amp;
                         log(sigma2.true)&lt;= l$logS2CI95[2]
                         )
                  )
nLogS2Norm95 &lt;- sum(sapply(devianceIG100,
                           function(l) l$logS2Norm95[1] &lt;= log(sigma2.true)  &amp;&amp;
                           log(sigma2.true)&lt;= l$logS2Norm95[2]
                           )
                    )
nLogS2CI99 &lt;- sum(sapply(devianceIG100,
                         function(l) l$logS2CI99[1] &lt;= log(sigma2.true)  &amp;&amp;
                         log(sigma2.true)&lt;= l$logS2CI99[2]
                         )
                  )
nLogS2Norm99 &lt;- sum(sapply(devianceIG100,
                           function(l) l$logS2Norm99[1] &lt;= log(sigma2.true)  &amp;&amp;
                           log(sigma2.true)&lt;= l$logS2Norm99[2]
                           )
                    )
## Check if these counts are compatible with the nominal CIs
c(prof95S2=nLogS2CI95,norm95S2=nLogS2Norm95)
qbinom(c(0.005,0.995),nbReplicate,0.95)
c(prof95S2=nLogS2CI99,norm95S2=nLogS2Norm99)
qbinom(c(0.005,0.995),nbReplicate,0.99)


## Get 95 and 99% confidence intervals for the QQ plot
ci &lt;- sapply(1:nbReplicate,
                 function(idx) qchisq(qbeta(c(0.005,0.025,0.975,0.995),
                                            idx,
                                            nbReplicate-idx+1),
                                      df=2)
             )
## make QQ plot
X &lt;- qchisq(ppoints(nbReplicate),df=2)
Y &lt;- sort(sapply(devianceIG100,function(l) l$deviance))
X11()
plot(X,Y,type="n",
     xlab=expression(paste(chi[2]^2," quantiles")),
     ylab="MC quantiles",
     main="Deviance with true parameters after ML fit of IG data",
     sub=paste("sample size:", sampleSize,"MC replicates:", nbReplicate)
     )
abline(a=0,b=1)
lines(X,ci[1,],lty=2)
lines(X,ci[2,],lty=2)
lines(X,ci[3,],lty=2)
lines(X,ci[4,],lty=2)
lines(X,Y,col=2)

## End(Not run)
</code></pre>

<hr>
<h2 id='km.outcomes'>
Outcomes for the Kaplan-Meier product-limit estimator
</h2><span id='topic+km.outcomes'></span>

<h3>Description</h3>

<p>Generates a matrix containing all possible outcomes (all possible sequences of failure times and right-censoring times) of the value
of the Kaplan-Meier product-limit estimator for a particular sample
size <code>n</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>km.outcomes(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="km.outcomes_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Kaplan-Meier product-limit estimator is used to
estimate the survivor function for a data set of
positive values in the presence of right censoring. 
The <code>km.outcomes</code> function generates a matrix with
all possible combinations of observed failures and
right censored values and the resulting support values
for the Kaplan-Meier product-limit estimator for a sample of
size <code>n</code>.
</p>
<p>The <code>n</code> argument must be a positive integer denoting
the sample size. Allowable limits are from 1 to 24.
Larger values of <code>n</code> are not allowed because of CPU
and memory limitations. 
</p>
<p>In order to keep the support values as exact fractions,
the numerators and denominators are stored separately in
the <code>a</code> matrix in the columns named <code>num</code> and
<code>den</code>. The support values are stored as numeric
values in the column named <code>S(t)</code>.
</p>


<h3>Value</h3>

<p>The <code>km.outcomes</code> function returns a matrix with
2<sup>n+1</sup>-1 rows and n + 4 columns. The location <code>l</code> indicates the position where the time of interest falls within the observed events.
The meaning of the columns is as follows.
</p>

<ul>
<li> <p><code>l</code>: number of observed events (failures times or
censoring times) between times 0 and the observation time;
</p>
</li>
<li> <p><code>d1, d2, ..., dn</code>: equals 0 if the event corresponds
to a censored observation, equals 1 if the event
corresponds to a failure;
</p>
</li>
<li> <p><code>S(t)</code>: numeric value of the associated support value; 
</p>
</li>
<li> <p><code>num</code>: numerator of the support value as a fraction;
</p>
</li>
<li> <p><code>den</code>: denominator of the support value as a fraction.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Yuxin Qin (<a href="mailto:yqin08@wm.edu">yqin08@wm.edu</a>),
Heather Sasinowska (<a href="mailto:hdsasinowska@wm.edu">hdsasinowska@wm.edu</a>),
Larry Leemis (<a href="mailto:leemis@math.wm.edu">leemis@math.wm.edu</a>)
</p>


<h3>References</h3>

<p>Qin, Y., Sasinowska, H., Leemis, L. (2023), &quot;The Probability Mass
Function of the Kaplan-Meier Product-Limit Estimator&quot;,
<code class="reqn">The American Statistician</code>, Volume 77, Number 1, 102-110.
</p>


<h3>See Also</h3>

<p><code><a href="survival.html#topic+survfit">survfit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>km.outcomes(3)
</code></pre>

<hr>
<h2 id='km.pmf'>
Probability Mass Function for the support of the Kaplan-Meier product-limit estimator
</h2><span id='topic+km.pmf'></span>

<h3>Description</h3>

<p>Generates the probability mass function for the support values
of the Kaplan-Meier product-limit estimator for a particular sample
size <code>n</code>, probability of observing a failure <code>h</code> at the time of interest expressed as the cumulative probability <code>perc</code> associated with <code>X = min(T, C)</code>, where <code>T</code> is the failure time and <code>C</code> is the censoring time under a random-censoring scheme.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>km.pmf(n, h, perc, plot, sep, xfrac, cex.lollipop)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="km.pmf_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="km.pmf_+3A_h">h</code></td>
<td>
<p>probability of observing a failure, in other words, <code>P(X = T)</code></p>
</td></tr>
<tr><td><code id="km.pmf_+3A_perc">perc</code></td>
<td>
<p>cumulative probability associated with <code>X = min(T, C)</code></p>
</td></tr>
<tr><td><code id="km.pmf_+3A_plot">plot</code></td>
<td>
<p>option to plot the probability mass function (default is <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="km.pmf_+3A_sep">sep</code></td>
<td>
<p>option to show the breakdown of the probability for each support value (see function <code>km.outcomes</code> for details on the breakdown) (default is <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="km.pmf_+3A_xfrac">xfrac</code></td>
<td>
<p>option to label support values on the x-axis as exact fractions (default is <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="km.pmf_+3A_cex.lollipop">cex.lollipop</code></td>
<td>
<p>size of the dots atop the spikes</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Kaplan-Meier product-limit estimator is used to
estimate the survivor function for a data set of
positive values in the presence of right censoring. 
The <code>km.pmf</code> function generates the probability mass function for the support values
of the Kaplan-Meier product-limit estimator for a particular sample
size <code>n</code>, probability of observing a failure <code>h</code> at the time of interest expressed as the cumulative probability <code>perc</code> associated with <code>X = min(T, C)</code>, where <code>T</code> is the failure time and <code>C</code> is the censoring time under a random-censoring scheme.
</p>
<p>The <code>n</code> argument must be a positive integer denoting
the sample size. Allowable limits are from 1 to 23.
Larger values of <code>n</code> are not allowed because of CPU
and memory limitations. 
</p>
<p>For larger sample size <code>n</code>, it is recommended to set 
<code>sep = FALSE</code>, <code>xfrac = FALSE</code>, and 
<code>cex.lollipop = 0.01</code> for a better visual effect.
</p>


<h3>Value</h3>

<p>The <code>km.pmf</code> function returns a dataframe with
2 columns. The column named <code>S</code> stores all the support 
values for the Kaplan-Meier product-limit estimator 
with sample size <code>n</code>, including <code>NA</code>. The 
column named <code>P</code> stores the associated probabilities.
</p>


<h3>Author(s)</h3>

<p>Yuxin Qin (<a href="mailto:yqin08@wm.edu">yqin08@wm.edu</a>),
Heather Sasinowska (<a href="mailto:hdsasinowska@wm.edu">hdsasinowska@wm.edu</a>),
Larry Leemis (<a href="mailto:leemis@math.wm.edu">leemis@math.wm.edu</a>)
</p>


<h3>References</h3>

<p>Qin, Y., Sasinowska, H., Leemis, L. (2023), &quot;The Probability Mass
Function of the Kaplan-Meier Product-Limit Estimator&quot;,
<code class="reqn">The American Statistician</code>, Volume 77, Number 1, 102-110.
</p>


<h3>See Also</h3>

<p><code><a href="survival.html#topic+survfit">survfit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>km.pmf(4, 1/3, 0.75)

km.pmf(8, 1/2, 0.75, sep = FALSE, xfrac = FALSE, cex.lollipop = 0.01)
</code></pre>

<hr>
<h2 id='km.support'>Support values for the Kaplan-Meier product-limit estimator</h2><span id='topic+km.support'></span>

<h3>Description</h3>

<p>Calculate the support values for the Kaplan-Meier product-limit
estimator for a particular sample size <code>n</code> using an induction
algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>km.support(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="km.support_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Kaplan-Meier product-limit estimator is used to
estimate the survivor function for a data set of
positive values in the presence of right censoring.
The <code>km.support</code> function calculates the support values for the
Kaplan-Meier product-limit estimator for a sample of
size <code>n</code> using an induction algorithm
described in Qin et al. (2023).
</p>
<p>The <code>n</code> argument must be a positive integer denoting
the sample size. Allowable limits are from 1 to 35.
Larger values of <code>n</code> are not allowed because of CPU
and memory limitations.
</p>
<p>The numerators and denominators are temporarily converted to
complex numbers within the <code>km.support</code> function in order to
eliminate duplicate support values using the <code>unique</code> function.
</p>


<h3>Value</h3>

<p>The <code>km.support</code> function returns a list with two components.
</p>

<ul>
<li> <p><code>num</code>: a vector of integers containing the numerators of the
support values
</p>
</li>
<li> <p><code>den</code>: a vector of integers containing the associated
denominators of the support values
</p>
</li></ul>

<p>The support values are not returned in sorted order.
Zero and one, which are always a part of the support,
are given as 0 / 1 and 1 / 1.
</p>


<h3>Author(s)</h3>

<p>Yuxin Qin (<a href="mailto:yqin08@wm.edu">yqin08@wm.edu</a>),
Heather Sasinowska (<a href="mailto:hdsasinowska@wm.edu">hdsasinowska@wm.edu</a>),
Larry Leemis (<a href="mailto:leemis@math.wm.edu">leemis@math.wm.edu</a>)</p>


<h3>References</h3>

<p>Qin, Y., Sasinowska, H., Leemis, L. (2023), &quot;The Probability Mass
Function of the Kaplan-Meier Product-Limit Estimator&quot;,
<code class="reqn">The American Statistician</code>, Volume 77, Number 1,
102-110.
</p>


<h3>See Also</h3>

<p><code><a href="survival.html#topic+survfit">survfit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  #  display unsorted numerators and denominators of support values for n = 4
  km.support(4)
  #  display sorted support values for n = 4 as exact fractions
  n &lt;- 4
  s &lt;- km.support(n)
  i &lt;- order(s$num / s$den)
  m &lt;- length(s$num)
  f &lt;- ""
  for (j in i[2:(m - 1)]) f &lt;- paste(f, s$num[j], "/", s$den[j], ", ", sep = "")
  cat(paste("The ", m, " support values for n = ", n, " are: 0, ", f, "1.\n", sep = ""))
  #  print sorted support values for n = 4 as numerics
  print(s$num[i] / s$den[i])
</code></pre>

<hr>
<h2 id='km.surv'>Probability Mass Functions for the support of the
Kaplan-Meier product-limit estimator for various cumulative probabilities associated with <code>X</code></h2><span id='topic+km.surv'></span>

<h3>Description</h3>

<p>Plot the probability mass functions for the support
values of the Kaplan-Meier product-limit estimator for
a given sample size <code>n</code> with a probability of observing  a failure <code>h</code> at various times of interest expressed as the cumulative probability <code>perc</code> associated with <code>X =  min(T, C)</code>, where <code>T</code> is the failure time and <code>C</code> is the censoring time, under a random-censoring scheme.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>km.surv(n, h, lambda, ev, line, graydots, gray.cex,
        gray.outline, xfrac)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="km.surv_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="km.surv_+3A_h">h</code></td>
<td>
<p>probability of observing a failure</p>
</td></tr>
<tr><td><code id="km.surv_+3A_lambda">lambda</code></td>
<td>
<p>plotting frequency of the probability mass
functions (default is 10)</p>
</td></tr>
<tr><td><code id="km.surv_+3A_ev">ev</code></td>
<td>
<p>option to plot the expected values of the support
values (default is <code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="km.surv_+3A_line">line</code></td>
<td>
<p>option to connect the expected values with
lines (default is <code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="km.surv_+3A_graydots">graydots</code></td>
<td>
<p>option to express the weight of the support
values using grayscale (default is
<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="km.surv_+3A_gray.cex">gray.cex</code></td>
<td>
<p>option to change the size of the gray dots
(default is 1)</p>
</td></tr>
<tr><td><code id="km.surv_+3A_gray.outline">gray.outline</code></td>
<td>
<p>option to display outlines of the
gray dots (default is <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="km.surv_+3A_xfrac">xfrac</code></td>
<td>
<p>option to label support values on the y-axis
as exact fractions (default is <code>TRUE</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Kaplan-Meier product-limit estimator is used to
estimate the survivor function for a data set of
positive values in the presence of right censoring.
The <code>km.surv</code> function plot the probability mass
functions for the support values of the Kaplan-Meier
product-limit estimator for a given sample size <code>n</code>
with a probability of observing  a failure <code>h</code> at
various times of interest expressed as the cumulative
probability <code>perc</code> associated with <code>X =  min(T,
  C)</code>, where <code>T</code> is the failure time and <code>C</code> is the
censoring time, under a random-censoring scheme.
</p>
<p>The <code>n</code> argument must be a positive integer denoting
the sample size. Allowable limits are from 1 to 23.
Larger values of <code>n</code> are not allowed because of CPU
and memory limitations.
</p>
<p>The default method to plot the probability mass functions
uses the area of a dot to indicate the relative probability
of a support value. An alternative is to plot the
probability mass functions using grayscales (by setting
<code>graydots = TRUE</code>). One of the two approaches might
work better in different scenarios.
</p>
<p>The expected values are calculated by removing the
probability of <code>NA</code> and normalizing the rest of the
probabilities.
</p>


<h3>Value</h3>

<p>The <code>km.surv</code> function doesn't return any value.
</p>


<h3>Author(s)</h3>

<p>Yuxin Qin (<a href="mailto:yqin08@wm.edu">yqin08@wm.edu</a>),
Heather Sasinowska (<a href="mailto:hdsasinowska@wm.edu">hdsasinowska@wm.edu</a>),
Larry Leemis (<a href="mailto:leemis@math.wm.edu">leemis@math.wm.edu</a>)</p>


<h3>References</h3>

<p>Qin, Y., Sasinowska, H., Leemis, L. (2023), &quot;The Probability Mass
Function of the Kaplan-Meier Product-Limit Estimator&quot;,
<code class="reqn">The American Statistician</code>, Volume 77, Number 1,
102-110.
</p>


<h3>See Also</h3>

<p><code><a href="survival.html#topic+survfit">survfit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>km.surv(n = 4, h = 2/3, lambda = 100, ev = TRUE, line = TRUE)
km.surv(n = 5, h = 3/4, lambda = 50, graydots = TRUE, gray.cex = 0.6, gray.outline = FALSE)
km.surv(n = 7, h = 1/5, lambda = 30, graydots = TRUE, gray.cex = 0.6, xfrac = FALSE)
</code></pre>

<hr>
<h2 id='llogisMLE'>Maximum Likelihood Parameter Estimation of a Log Logistic Model with Possibly
Censored Data</h2><span id='topic+llogisMLE'></span>

<h3>Description</h3>

<p>Estimate log logistic model parameters by the maximum likelihood
method using possibly censored data. 
The corresponding code for this function as well as the 
manual information included here is attributed to   
Christophe Pouzat's STAR Package (archived 2022-05-23). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>llogisMLE(yi, ni = numeric(length(yi)) + 1,
          si = numeric(length(yi)) + 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="llogisMLE_+3A_yi">yi</code></td>
<td>
<p>vector of (possibly binned) observations or a
<code>spikeTrain</code> object.</p>
</td></tr>
<tr><td><code id="llogisMLE_+3A_ni">ni</code></td>
<td>
<p>vector of counts for each value of <code>yi</code>; default: <code>numeric(length(yi))+1</code>.</p>
</td></tr>
<tr><td><code id="llogisMLE_+3A_si">si</code></td>
<td>
<p>vector of counts of <em>uncensored</em> observations for each
value of <code>yi</code>; default: <code>numeric(length(yi))+1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The MLE for the log logistic is not available in closed formed and
is therefore obtained numerically obtained by calling
<code><a href="stats.html#topic+optim">optim</a></code> with the <code>BFGS</code> method.
</p>
<p>In order to ensure good behavior of the numerical optimization
routines, optimization is performed on the log of parameter
<code>scale</code>.
</p>
<p>Standard errors are obtained from the inverse of the observed
information matrix at the MLE. They are transformed to go from the log
scale used by the optimization routine to the requested parameterization. 
</p>


<h3>Value</h3>

<p>A list of class <code>durationFit</code> with the following components:
</p>
<table>
<tr><td><code>estimate</code></td>
<td>
<p>the estimated parameters, a named vector.</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>the standard errors, a named vector.</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>the log likelihood at maximum.</p>
</td></tr>
<tr><td><code>r</code></td>
<td>
<p>a function returning the log of the relative likelihood function.</p>
</td></tr>
<tr><td><code>mll</code></td>
<td>
<p>a function returning the opposite of the log likelihood
function using the log of parameter <code>sdlog</code>.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The returned standard errors (component <code>se</code>) are valid in the asymptotic limit. You
should plot contours using function <code>r</code> in the returned list and
check that the contours are reasonably close to ellipses.
</p>


<h3>Author(s)</h3>

<p>Christophe Pouzat  <a href="mailto:christophe.pouzat@gmail.com">christophe.pouzat@gmail.com</a> </p>


<h3>References</h3>

<p>Lindsey, J.K. (2004) <em>Introduction to Applied Statistics: A
Modelling Approach</em>. OUP.
</p>
<p>Lindsey, J.K. (2004) <em>The Statistical Analysis of Stochastic
Processes in Time</em>. CUP.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dllogis">dllogis</a></code>,
<code><a href="#topic+invgaussMLE">invgaussMLE</a></code>,
<code><a href="#topic+gammaMLE">gammaMLE</a>.</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Simulate sample of size 100 from a log logisitic
## distribution
set.seed(1102006,"Mersenne-Twister")
sampleSize &lt;- 100
location.true &lt;- -2.7
scale.true &lt;- 0.025
sampLL &lt;- rllogis(sampleSize,location=location.true,scale=scale.true)
sampLLmleLL &lt;- llogisMLE(sampLL)
rbind(est = sampLLmleLL$estimate,se = sampLLmleLL$se,true = c(location.true,scale.true))

## Estimate the log relative likelihood on a grid to plot contours
Loc &lt;- seq(sampLLmleLL$estimate[1]-4*sampLLmleLL$se[1],
               sampLLmleLL$estimate[1]+4*sampLLmleLL$se[1],
               sampLLmleLL$se[1]/10)
Scale &lt;- seq(sampLLmleLL$estimate[2]-4*sampLLmleLL$se[2],
             sampLLmleLL$estimate[2]+4*sampLLmleLL$se[2],
             sampLLmleLL$se[2]/10)
sampLLmleLLcontour &lt;- sapply(Loc, function(m) sapply(Scale, function(s) sampLLmleLL$r(m,s)))
## plot contours using a linear scale for the parameters
## draw four contours corresponding to the following likelihood ratios:
##  0.5, 0.1, Chi2 with 2 df and p values of 0.95 and 0.99
X11(width=12,height=6)
layout(matrix(1:2,ncol=2))
contour(Loc,Scale,t(sampLLmleLLcontour),
        levels=c(log(c(0.5,0.1)),-0.5*qchisq(c(0.95,0.99),df=2)),
        labels=c("log(0.5)",
          "log(0.1)",
          "-1/2*P(Chi2=0.95)",
          "-1/2*P(Chi2=0.99)"),
        xlab="Location",ylab="Scale",
        main="Log Relative Likelihood Contours"
        )
points(sampLLmleLL$estimate[1],sampLLmleLL$estimate[2],pch=3)
points(location.true,scale.true,pch=16,col=2)
## The contours are not really symmetrical about the MLE we can try to
## replot them using a log scale for the parameters to see if that improves
## the situation
contour(Loc,log(Scale),t(sampLLmleLLcontour),
        levels=c(log(c(0.5,0.1)),-0.5*qchisq(c(0.95,0.99),df=2)),
        labels="",
        xlab="log(Location)",ylab="log(Scale)",
        main="Log Relative Likelihood Contours",
        sub="log scale for parameter: scale")
points(sampLLmleLL$estimate[1],log(sampLLmleLL$estimate[2]),pch=3)
points(location.true,log(scale.true),pch=16,col=2)

## make a parametric boostrap to check the distribution of the deviance
nbReplicate &lt;- 10000
sampleSize &lt;- 100
system.time(
            devianceLL100 &lt;- replicate(nbReplicate,{
              sampLL &lt;- rllogis(sampleSize,location=location.true,scale=scale.true)
              sampLLmleLL &lt;- llogisMLE(sampLL)
              -2*sampLLmleLL$r(location.true,scale.true)
            }
                                       )
            )[3]

## Get 95 and 99
ci &lt;- sapply(1:nbReplicate,
                 function(idx) qchisq(qbeta(c(0.005,0.025,0.975,0.995),
                                            idx,
                                            nbReplicate-idx+1),
                                      df=2)
             )
## make QQ plot
X &lt;- qchisq(ppoints(nbReplicate),df=2)
Y &lt;- sort(devianceLL100)
X11()
plot(X,Y,type="n",
     xlab=expression(paste(chi[2]^2," quantiles")),
     ylab="MC quantiles",
     main="Deviance with true parameters after ML fit of log logistic data",
     sub=paste("sample size:", sampleSize,"MC replicates:", nbReplicate)
     )
abline(a=0,b=1)
lines(X,ci[1,],lty=2)
lines(X,ci[2,],lty=2)
lines(X,ci[3,],lty=2)
lines(X,ci[4,],lty=2)
lines(X,Y,col=2)

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
