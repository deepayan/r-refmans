<!DOCTYPE html><html><head><title>Help for package cap</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {cap}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cap-package'><p> Covariate Assisted Principal (CAP) Regression for Covariance Matrix Outcomes</p></a></li>
<li><a href='#cap_beta'><p> Inference of model coefficients</p></a></li>
<li><a href='#capReg'><p> Covariate Assisted Principal Regression for Covariance Matrix Outcomes</p></a></li>
<li><a href='#env.example'><p> Simulated data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Covariate Assisted Principal (CAP) Regression for Covariance
Matrix Outcomes</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2018-09-07</td>
</tr>
<tr>
<td>Author:</td>
<td>Yi Zhao &lt;zhaoyi1026@gmail.com&gt;, 
		Bingkai Wang &lt;bwang51@jhmi.edu&gt;, 
		Stewart Mostofsky &lt;mostofsky@kennedykrieger.org&gt;,
		Brian Caffo &lt;bcaffo@gmail.com&gt;, 
		Xi Luo &lt;xi.rossi.luo@gmail.com&gt; </td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yi Zhao &lt;zhaoyi1026@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs Covariate Assisted Principal (CAP) Regression for covariance matrix outcomes. The method identifies the optimal projection direction which maximizes the log-likelihood function of the log-linear heteroscedastic regression model in the projection space. See Zhao et al. (2018), Covariate Assisted Principal Regression for Covariance Matrix Outcomes, &lt;<a href="https://doi.org/10.1101%2F425033">doi:10.1101/425033</a>&gt; for details.</td>
</tr>
<tr>
<td>Depends:</td>
<td>MASS, multigroup</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-09-26 18:36:36 UTC; yizhao</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-09-30 23:00:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='cap-package'> Covariate Assisted Principal (CAP) Regression for Covariance Matrix Outcomes
</h2><span id='topic+cap-package'></span><span id='topic+cap'></span>

<h3>Description</h3>

<p>cap package performs Covariate Assisted Principal (CAP) Regression for covariance matrix outcomes. The method identifies the optimal projection direction which maximizes the log-likelihood function of the log-linear heteroscedastic regression model in the projection space.
</p>


<h3>Author(s)</h3>

<p>Yi Zhao, Johns Hopkins University, &lt;zhaoyi1026@gmail.com&gt; 
</p>
<p>Bingkai Wang, Johns Hopkins University, &lt;bwang51@jhmi.edu&gt;
</p>
<p>Stewart Mostofsky, Johns Hopkins University, &lt;mostofsky@kennedykrieger.org&gt; 
</p>
<p>Brian Caffo, Johns Hopkins University, &lt;bcaffo@gmail.com&gt; 
</p>
<p>Xi Luo, Brown University, &lt;xi.rossi.luo@gmail.com&gt; 
</p>
<p>Maintainer: Yi Zhao &lt;zhaoyi1026@gmail.com&gt;
</p>


<h3>References</h3>

<p>Zhao et al. (2018) <em>Covariate Assisted Principal Regression for Covariance Matrix Outcomes</em> &lt;doi:10.1101/425033&gt;
</p>

<hr>
<h2 id='cap_beta'> Inference of model coefficients
</h2><span id='topic+cap_beta'></span>

<h3>Description</h3>

<p> This function performs inference on the model coefficient <code class="reqn">\beta</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cap_beta(Y, X, gamma = NULL, beta = NULL, method = c("asmp", "LLR"), 
    boot = FALSE, sims = 1000, boot.ci.type = c("bca", "perc"), 
    conf.level = 0.95, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cap_beta_+3A_y">Y</code></td>
<td>
<p> a data list of length <code class="reqn">n</code>. Each list element is a <code class="reqn">T\times p</code> matrix, the data matrix of <code class="reqn">T</code> observations from <code class="reqn">p</code> features.
</p>
</td></tr>
<tr><td><code id="cap_beta_+3A_x">X</code></td>
<td>
<p> a <code class="reqn">n\times q</code> data matrix, the covariate matrix of <code class="reqn">n</code> subjects with <code class="reqn">q-1</code> predictors. The first column is all ones.
</p>
</td></tr>
<tr><td><code id="cap_beta_+3A_gamma">gamma</code></td>
<td>
<p> a <code class="reqn">p</code>-dimensional vector, the projecting direction <code class="reqn">\gamma</code>. Default is <code>NULL</code>. If <code>gamma = NULL</code>, an error warning will be returned.
</p>
</td></tr>
<tr><td><code id="cap_beta_+3A_beta">beta</code></td>
<td>
<p> a <code class="reqn">q</code>-dimensional vector, the model coefficient <code class="reqn">\beta</code>. Default is <code>NULL</code>. If <code>beta = NULL</code>, when <code>boot = FALSE</code>, <code class="reqn">\beta</code> will be estimated using the provided <code class="reqn">\gamma</code>.
</p>
</td></tr>
<tr><td><code id="cap_beta_+3A_method">method</code></td>
<td>
<p> a character of inference method. If <code>method = "asmp"</code>, the inference is made based on the asymptotic variance; if <code>method = "LLR"</code>, the likelihood ratio test is conducted. When <code>boot = TRUE</code>, this argument is ignored.
</p>
</td></tr>
<tr><td><code id="cap_beta_+3A_boot">boot</code></td>
<td>
<p> a logic variable, whether bootstrap inference is performed.
</p>
</td></tr>
<tr><td><code id="cap_beta_+3A_sims">sims</code></td>
<td>
<p> a numeric value, the number of bootstrap iterations will be performed.
</p>
</td></tr>
<tr><td><code id="cap_beta_+3A_boot.ci.type">boot.ci.type</code></td>
<td>
<p> a character of the way of calculating bootstrap confidence interval. If <code>boot.ci.type = "bca"</code>, the bias corrected confidence interval is returned; if <code>boot.ci.type = "perc"</code>, the percentile confidence interval is returned.
</p>
</td></tr>
<tr><td><code id="cap_beta_+3A_conf.level">conf.level</code></td>
<td>
<p> a numeric value, the designated significance level. Default is <code class="reqn">0.95</code>.
</p>
</td></tr>
<tr><td><code id="cap_beta_+3A_verbose">verbose</code></td>
<td>
<p> a logic variable, whether the bootstrap procedure is printed. Default is <code>TRUE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p> Considering <code class="reqn">y_{it}</code> are <code class="reqn">p</code>-dimensional independent and identically distributed random samples from a multivariate normal distribution with mean zero and covariance matrix <code class="reqn">\Sigma_{i}</code>. We assume there exits a <code class="reqn">p</code>-dimensional vector <code class="reqn">\gamma</code> such that <code class="reqn">z_{it}:=\gamma'y_{it}</code> satisfies the multiplicative heteroscedasticity:
</p>
<p style="text-align: center;"><code class="reqn">\log(\mathrm{Var}(z_{it}))=\log(\gamma'\Sigma_{i}\gamma)=\beta_{0}+x_{i}'\beta_{1},</code>
</p>

<p>where <code class="reqn">x_{i}</code> contains explanatory variables of subject <code class="reqn">i</code>, and <code class="reqn">\beta_{0}</code> and <code class="reqn">\beta_{1}</code> are model coefficients.
</p>
<p>The <code class="reqn">\beta</code> coefficient is estimated by maximizing the likelihood function. The asymptotic variance is obtained based on maximum likelihood estimator theory.
</p>


<h3>Value</h3>

<p> When <code>method = "asmp"</code>, the output is a <code class="reqn">q \times 6</code> data frame containing the estimate of <code class="reqn">\beta</code> coefficient, the asymptotic standard error, the test statistic, the <code class="reqn">p</code>-value, and the lower and upper bound of the confidence interval.
</p>
<p>When <code>method = "LLR"</code>, the output is a <code class="reqn">q \times 3</code> data frame containing the estimate of <code class="reqn">\beta</code> coefficient, the test statistic, and the <code class="reqn">p</code>-value.
</p>
<p>When <code>boot = TRUE</code>,
</p>
<table>
<tr><td><code>Inference</code></td>
<td>
<p>point estimate of the <code class="reqn">\beta</code> coefficient, as well as the corresponding standard error, test statistic, <code class="reqn">p</code>-value, and the lower and upper bound of the confidence interval.</p>
</td></tr>
<tr><td><code>beta.boot</code></td>
<td>
<p>the estimate of the <code class="reqn">\beta</code> coefficient in each iteration.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yi Zhao, Johns Hopkins University, &lt;zhaoyi1026@gmail.com&gt; 
</p>
<p>Bingkai Wang, Johns Hopkins University, &lt;bwang51@jhmi.edu&gt;
</p>
<p>Stewart Mostofsky, Johns Hopkins University, &lt;mostofsky@kennedykrieger.org&gt; 
</p>
<p>Brian Caffo, Johns Hopkins University, &lt;bcaffo@gmail.com&gt; 
</p>
<p>Xi Luo, Brown University, &lt;xi.rossi.luo@gmail.com&gt; 
</p>


<h3>References</h3>

<p>Zhao et al. (2018) <em>Covariate Assisted Principal Regression for Covariance Matrix Outcomes</em> &lt;doi:10.1101/425033&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#############################################
data(env.example)
X&lt;-get("X",env.example)
Y&lt;-get("Y",env.example)
Phi&lt;-get("Phi",env.example)

# asymptotic variance
re1&lt;-cap_beta(Y,X,gamma=Phi[,2],method=c("asmp"),boot=FALSE)

# likelihood ratio test
re2&lt;-cap_beta(Y,X,gamma=Phi[,2],method=c("LLR"),boot=FALSE)

# bootstrap confidence interval

re3&lt;-cap_beta(Y,X,gamma=Phi[,2],boot=TRUE,sims=500,verbose=FALSE)

#############################################
</code></pre>

<hr>
<h2 id='capReg'> Covariate Assisted Principal Regression for Covariance Matrix Outcomes
</h2><span id='topic+capReg'></span>

<h3>Description</h3>

<p> This function identifies the first <code class="reqn">k</code> projection directions that satisfies the log-linear model assumption.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>capReg(Y, X, nD = 1, method = c("CAP", "CAP-C"), CAP.OC = FALSE, 
  max.itr = 1000, tol = 1e-04, trace = FALSE, score.return = TRUE, 
  gamma0.mat = NULL, ninitial = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="capReg_+3A_y">Y</code></td>
<td>
<p> a data list of length <code class="reqn">n</code>. Each list element is a <code class="reqn">T\times p</code> matrix, the data matrix of <code class="reqn">T</code> observations from <code class="reqn">p</code> features.
</p>
</td></tr>
<tr><td><code id="capReg_+3A_x">X</code></td>
<td>
<p> a <code class="reqn">n\times q</code> data matrix, the covariate matrix of <code class="reqn">n</code> subjects with <code class="reqn">q-1</code> predictors. The first column is all ones.
</p>
</td></tr>
<tr><td><code id="capReg_+3A_nd">nD</code></td>
<td>
<p> an integer, the number of directions to be identified. Default is 1.
</p>
</td></tr>
<tr><td><code id="capReg_+3A_method">method</code></td>
<td>
<p> a character of optimization method. <code>method = "CAP"</code> considers a weighted L2-norm on the <code class="reqn">\gamma</code> vector and solve for the optimizer by block coordinated descent; <code>method = "CAP-C"</code> assumes the complete common principal component assumption which identifies the common principal component first and then searches for the optimal PC.
</p>
</td></tr>
<tr><td><code id="capReg_+3A_cap.oc">CAP.OC</code></td>
<td>
<p> a logic variable. Whether the orthogonal constraint is imposed when identifying higher-order PCs. When <code>method = "CAP-C"</code>, this is ignored. Default is <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="capReg_+3A_max.itr">max.itr</code></td>
<td>
<p> an integer, the maximum number of iterations.
</p>
</td></tr>
<tr><td><code id="capReg_+3A_tol">tol</code></td>
<td>
<p> a numeric value of convergence tolerance.
</p>
</td></tr>
<tr><td><code id="capReg_+3A_trace">trace</code></td>
<td>
<p> a logic variable. Whether the solution path is reported. Default is <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="capReg_+3A_score.return">score.return</code></td>
<td>
<p> a logic variable. Whether the log-variance in the transformed space is reported. Default is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="capReg_+3A_gamma0.mat">gamma0.mat</code></td>
<td>
<p> a data matrix, the initial value of <code class="reqn">\gamma</code>. Default is <code>NULL</code>, and initial value is randomly chosen.
</p>
</td></tr>
<tr><td><code id="capReg_+3A_ninitial">ninitial</code></td>
<td>
<p> an integer, the number of different initial value is tested. When it is greater than 1, multiple initial values will be tested, and the one yields the minimum objective function will be reported. Default is <code>NULL</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p> Considering <code class="reqn">y_{it}</code> are <code class="reqn">p</code>-dimensional independent and identically distributed random samples from a multivariate normal distribution with mean zero and covariance matrix <code class="reqn">\Sigma_{i}</code>. We assume there exits a <code class="reqn">p</code>-dimensional vector <code class="reqn">\gamma</code> such that <code class="reqn">z_{it}:=\gamma'y_{it}</code> satisfies the multiplicative heteroscedasticity:
</p>
<p style="text-align: center;"><code class="reqn">\log(\mathrm{Var}(z_{it}))=\log(\gamma'\Sigma_{i}\gamma)=\beta_{0}+x_{i}'\beta_{1}</code>
</p>
<p>,
where <code class="reqn">x_{i}</code> contains explanatory variables of subject <code class="reqn">i</code>, and <code class="reqn">\beta_{0}</code> and <code class="reqn">\beta_{1}</code> are model coefficients.
</p>
<p>Parameters <code class="reqn">\gamma</code> and <code class="reqn">\beta=(\beta_{0},\beta_{1}')'</code> are study of interest, and we propose to estimate them by maximizing the likelihood function,
</p>
<p style="text-align: center;"><code class="reqn">\ell(\beta,\gamma)=-\frac{1}{2}\sum_{i=1}^{n}T_{i}(x_{i}'\beta)-\frac{1}{2}\sum_{i=1}^{n}\exp(-x_{i}'\beta)\gamma'S_{i}\gamma,</code>
</p>

<p>where <code class="reqn">S_{i}=\sum_{t=1}^{T_{i}}y_{it}y_{it}'</code>. To estimate <code class="reqn">\gamma</code>, we impose the following constraint
</p>
<p style="text-align: center;"><code class="reqn">\gamma' H\gamma=1,</code>
</p>

<p>where <code class="reqn">H</code> is a positive definite matrix. In this study, we consider the choice that
</p>
<p style="text-align: center;"><code class="reqn">H=\bar{\Sigma}, \quad \bar{\Sigma}=\frac{1}{n}\sum_{i=1}^{n}\frac{1}{T_{i}}S_{i}.</code>
</p>

<p>For higher order projecting directions, an orthogonal constraint is imposed as well.
</p>


<h3>Value</h3>

<p> When <code>method = "CAP"</code>,
</p>
<table>
<tr><td><code>gamma</code></td>
<td>
<p>the estimate of <code class="reqn">\gamma</code> vectors, which is a <code class="reqn">p\times nD</code> matrix.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>the estimate of <code class="reqn">\beta</code> for each projecting direction, which is a <code class="reqn">q\times nD</code> matrix, where <code class="reqn">q-1</code> is the number of explanatory variables.</p>
</td></tr>
<tr><td><code>orthogonality</code></td>
<td>
<p>an ad hoc checking of the orthogonality between <code class="reqn">\gamma</code> vectors.</p>
</td></tr>
<tr><td><code>DfD</code></td>
<td>
<p>output of both average (geometric mean) and individual level of &ldquo;deviation from diagonality&rdquo;.</p>
</td></tr>
<tr><td><code>score</code></td>
<td>
<p>an output when <code>score.return = TRUE</code>. A <code class="reqn">n\times nD</code> matrix of <code class="reqn">\log(\hat{\gamma}'S_{i}\hat{\gamma})</code> value.</p>
</td></tr>
</table>
<p>When <code>method = "CAP-C"</code>,
</p>
<table>
<tr><td><code>gamma</code></td>
<td>
<p>the estimate of <code class="reqn">\gamma</code> vectors, which is a <code class="reqn">p\times nD</code> matrix.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>the estimate of <code class="reqn">\beta</code> for each projecting direction, which is a <code class="reqn">q\times nD</code> matrix, where <code class="reqn">q-1</code> is the number of explanatory variables.</p>
</td></tr>
<tr><td><code>orthogonality</code></td>
<td>
<p>an ad hoc checking of the orthogonality between <code class="reqn">\gamma</code> vectors.</p>
</td></tr>
<tr><td><code>PC.idx</code></td>
<td>
<p>a vector of length <code>nD</code>, the order index of identified <code class="reqn">\gamma</code> vectors among all the common principal components.</p>
</td></tr>
<tr><td><code>aPC.idx</code></td>
<td>
<p>the order index of all the principal components that satisfy the log-linear model and the eigenvalue condition.</p>
</td></tr>
<tr><td><code>minmax</code></td>
<td>
<p>a logic output, whether the identified <code class="reqn">\gamma</code> vectors are estimated from the minmax approach. If <code>FALSE</code>, indicating the eigenvalue condition is not satisfied for any principal component.</p>
</td></tr>
<tr><td><code>score</code></td>
<td>
<p>an output when <code>score.return = TRUE</code>. A <code class="reqn">n\times nD</code> matrix of <code class="reqn">\log(\hat{\gamma}'S_{i}\hat{\gamma})</code> value.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yi Zhao, Johns Hopkins University, &lt;zhaoyi1026@gmail.com&gt; 
</p>
<p>Bingkai Wang, Johns Hopkins University, &lt;bwang51@jhmi.edu&gt; 
</p>
<p>Stewart Mostofsky, Johns Hopkins University, &lt;mostofsky@kennedykrieger.org&gt;
</p>
<p>Brian Caffo, Johns Hopkins University, &lt;bcaffo@gmail.com&gt; 
</p>
<p>Xi Luo, Brown University, &lt;xi.rossi.luo@gmail.com&gt; 
</p>


<h3>References</h3>

<p>Zhao et al. (2018) <em>Covariate Assisted Principal Regression for Covariance Matrix Outcomes</em> &lt;doi:10.1101/425033&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#############################################
data(env.example)
X&lt;-get("X",env.example)
Y&lt;-get("Y",env.example)

# method = "CAP"
# without orthogonal constraint
re1&lt;-capReg(Y,X,nD=2,method=c("CAP"),CAP.OC=FALSE)
# with orthogonal constraint
re2&lt;-capReg(Y,X,nD=2,method=c("CAP"),CAP.OC=TRUE)

# method = "CAP-C"
re3&lt;-capReg(Y,X,nD=2,method=c("CAP-C"))
#############################################
</code></pre>

<hr>
<h2 id='env.example'> Simulated data
</h2><span id='topic+env.example'></span>

<h3>Description</h3>

<p> &quot;env.example&quot; is an R environment containing the data generated from the proposed model with <code class="reqn">p=2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("env.example")</code></pre>


<h3>Format</h3>

<p> An R environment
</p>

<dl>
<dt><code>X</code></dt><dd><p>a <code class="reqn">n\times q</code> data matrix, the covariate matrix of <code class="reqn">n</code> subjects with <code class="reqn">q-1</code> predictors. The first column is all ones.</p>
</dd>
<dt><code>Y</code></dt><dd><p>a list of length <code class="reqn">n</code>. Each list element is a <code class="reqn">T\times p</code> matrix, the data matrix of <code class="reqn">T</code> observations from <code class="reqn">p</code> features.</p>
</dd>
<dt><code>Phi</code></dt><dd><p>a <code class="reqn">p\times p</code> matrix, the true projection matrix used to generate the data.</p>
</dd>
<dt><code>beta</code></dt><dd><p>a <code class="reqn">q\times p</code> matrix, the true coefficient matrix used to generate the data.</p>
</dd>
<dt><code>Sigma</code></dt><dd><p>a <code class="reqn">p\times p\times n</code> array, the covariance matrix of the <code class="reqn">n</code> subjects.</p>
</dd>
</dl>



<h3>Details</h3>

<p> For subject <code class="reqn">i</code> observation <code class="reqn">t</code> (<code class="reqn">i=1,\dots,n</code>, <code class="reqn">t=1,\dots,T</code>), <code class="reqn">y_{it}=(y_{it1},\dots,y_{itp})</code> was generated from a <code class="reqn">p</code>-dimensional normal distribution with mean zero and covariance <code class="reqn">\Sigma</code>, where 
</p>
<p style="text-align: center;"><code class="reqn">\Sigma=\Phi\Lambda\Phi,</code>
</p>

<p><code class="reqn">\Phi</code> is an orthonormal matrix and <code class="reqn">\Lambda=\mathrm{diag}(\lambda_{1},\dots,\lambda_{p})</code> is a diagonal matrix. The eigenvalues <code class="reqn">\lambda_{ij}</code> (<code class="reqn">j=1,\dots,p</code>) satisfies the following log-linear model
</p>
<p style="text-align: center;"><code class="reqn">log(\lambda_{ij})=x_{i}^\top\beta_{j},</code>
</p>

<p>where <code class="reqn">\beta_{j}</code> is the <code class="reqn">j</code>th column of <code>beta</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(env.example)
X&lt;-get("X",env.example)
Y&lt;-get("Y",env.example)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
