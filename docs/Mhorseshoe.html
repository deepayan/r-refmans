<!DOCTYPE html><html><head><title>Help for package Mhorseshoe</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Mhorseshoe}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Mhorseshoe'><p>Mhorseshoe: Approximate Algorithm for Horseshoe Prior</p></a></li>
<li><a href='#approx_horseshoe'><p>Run approximate MCMC algorithm for horseshoe prior</p></a></li>
<li><a href='#exact_horseshoe'><p>Run exact MCMC algorithm for horseshoe prior</p></a></li>
<li><a href='#rejection_sampler'><p>rejection sampler to update local shrinkage parameters lambda.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Approximate Algorithm for Horseshoe Prior</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.3</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides exact and approximate algorithms for the horseshoe prior
    in linear regression models, which were proposed by Johndrow et al. (2020)
    <a href="https://www.jmlr.org/papers/v21/19-536.html">https://www.jmlr.org/papers/v21/19-536.html</a>.</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, Rcpp (&ge; 1.0.11)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, ggplot2, horseshoe, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-06-27 04:40:21 UTC; rkdal</td>
</tr>
<tr>
<td>Author:</td>
<td>Kang Mingi [aut, cre],
  Lee Kyoungjae [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kang Mingi &lt;leehuimin115@g.skku.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-06-27 04:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='Mhorseshoe'>Mhorseshoe: Approximate Algorithm for Horseshoe Prior</h2><span id='topic+Mhorseshoe-package'></span><span id='topic+Mhorseshoe'></span>

<h3>Description</h3>

<p>Mhorseshoe is a package for a high-dimensional Bayesian linear
modeling algorithm using a horseshoe prior. This package provides two
different algorithm functions : <code><a href="#topic+exact_horseshoe">exact_horseshoe</a></code>,
<code><a href="#topic+approx_horseshoe">approx_horseshoe</a></code>. approx_horseshoe is version that can lower
the computational cost than the existing horseshoe estimator through the
approximate MCMC algorithm in the case of <code class="reqn">p &gt;&gt; N</code> for <code class="reqn">p</code>
predictors and <code class="reqn">N</code> observations. You can see examples of the use of the
two algorithms through the vignette, <code>browseVignettes("Mhorseshoe")</code>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Kang Mingi <a href="mailto:leehuimin115@g.skku.edu">leehuimin115@g.skku.edu</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Lee Kyoungjae <a href="mailto:leekjstat@gmail.com">leekjstat@gmail.com</a>
</p>
</li></ul>


<hr>
<h2 id='approx_horseshoe'>Run approximate MCMC algorithm for horseshoe prior</h2><span id='topic+approx_horseshoe'></span>

<h3>Description</h3>

<p>The approximate MCMC algorithm for the horseshoe prior
</p>


<h3>Usage</h3>

<pre><code class='language-R'>approx_horseshoe(
  y,
  X,
  burn = 1000,
  iter = 5000,
  auto.threshold = TRUE,
  threshold = 0,
  tau = 1,
  s = 0.8,
  sigma2 = 1,
  w = 1,
  alpha = 0.05,
  a = 0.2,
  b = 10,
  t = 10,
  adapt_p0 = 0,
  adapt_p1 = -4.6 * 10^(-4)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="approx_horseshoe_+3A_y">y</code></td>
<td>
<p>Response vector, <code class="reqn">y \in \mathbb{R}^{N}</code>.</p>
</td></tr>
<tr><td><code id="approx_horseshoe_+3A_x">X</code></td>
<td>
<p>Design matrix, <code class="reqn">X \in \mathbb{R}^{N \times p}</code>.</p>
</td></tr>
<tr><td><code id="approx_horseshoe_+3A_burn">burn</code></td>
<td>
<p>Number of burn-in samples. The default is 1000.</p>
</td></tr>
<tr><td><code id="approx_horseshoe_+3A_iter">iter</code></td>
<td>
<p>Number of samples to be drawn from the posterior. The default is
5000.</p>
</td></tr>
<tr><td><code id="approx_horseshoe_+3A_auto.threshold">auto.threshold</code></td>
<td>
<p>Argument for setting whether to use an algorithm that
automatically updates the threshold using adaptive probability.</p>
</td></tr>
<tr><td><code id="approx_horseshoe_+3A_threshold">threshold</code></td>
<td>
<p>Threshold to be used in the approximate MCMC algorithm.
This argument is ignored when auto.threshold=TRUE. If you select
auto.threshold = FALSE and threshold = 0 (This is the default value for the
threshold argument), the threshold is set to
<code class="reqn">\sqrt{p \times min(N, p)}</code> as suggested in Johndrow et al. (2020). Or,
you can set your custom value directly through this argument. For more
information about <code class="reqn">\delta</code>, browseVignettes(&quot;Mhorseshoe&quot;) and 4.1 of
Johndrow et al. (2020).</p>
</td></tr>
<tr><td><code id="approx_horseshoe_+3A_tau">tau</code></td>
<td>
<p>Initial value of the global shrinkage parameter <code class="reqn">\tau</code> when
starting the algorithm. The default is 1.</p>
</td></tr>
<tr><td><code id="approx_horseshoe_+3A_s">s</code></td>
<td>
<p><code class="reqn">s^{2}</code> is the variance of tau's MH proposal distribution.
0.8 is a good default. If set to 0, the algorithm proceeds by fixing the
global shrinkage parameter <code class="reqn">\tau</code> to the initial setting value.</p>
</td></tr>
<tr><td><code id="approx_horseshoe_+3A_sigma2">sigma2</code></td>
<td>
<p>Initial value of error variance <code class="reqn">\sigma^{2}</code>. The default
is 1.</p>
</td></tr>
<tr><td><code id="approx_horseshoe_+3A_w">w</code></td>
<td>
<p>A hyperparameter of gamma prior for <code class="reqn">\sigma^{2}</code>. The default
is 1.</p>
</td></tr>
<tr><td><code id="approx_horseshoe_+3A_alpha">alpha</code></td>
<td>
<p><code class="reqn">100(1-\alpha)\%</code> credible interval setting argument.</p>
</td></tr>
<tr><td><code id="approx_horseshoe_+3A_a">a</code></td>
<td>
<p>A tuning parameter of the rejection sampler, where the default
value is <code class="reqn">a = 1/5</code>.</p>
</td></tr>
<tr><td><code id="approx_horseshoe_+3A_b">b</code></td>
<td>
<p>A tuning parameter of the rejection sampler, where the default
value is <code class="reqn">b = 10</code>.</p>
</td></tr>
<tr><td><code id="approx_horseshoe_+3A_t">t</code></td>
<td>
<p>Threshold update cycle for adaptive probability algorithm when
auto.threshold is set to TRUE. The default is 10.</p>
</td></tr>
<tr><td><code id="approx_horseshoe_+3A_adapt_p0">adapt_p0</code></td>
<td>
<p>A tuning parameter <code class="reqn">p_{0}</code> of the adaptive probability,
<code class="reqn">p(t) = exp[p_{0} + p_{1}t]</code>. The default is <code class="reqn">0</code>.</p>
</td></tr>
<tr><td><code id="approx_horseshoe_+3A_adapt_p1">adapt_p1</code></td>
<td>
<p>A tuning parameter <code class="reqn">a_{1}</code> of the adaptive probability,
<code class="reqn">p(t) = exp[p_{0} + p_{1}t]</code>. The default is <code class="reqn">-4.6 \times 10^{-4}</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements the approximate algorithm introduced in Section
2.2 of Johndrow et al. (2020) and the method proposed in this package, which
improves computation speed when p &gt;&gt; N. The approximate algorithm introduces
a threshold and uses only a portion of the total <code class="reqn">p</code> columns for matrix
multiplication, reducing the computational cost compared to the existing
MCMC algorithms for the horseshoe prior. The &quot;auto.threshold&quot; argument
determines whether the threshold used in the algorithm will be updated by
the adaptive method proposed in this package.
</p>


<h3>Value</h3>

<table>
<tr><td><code>BetaHat</code></td>
<td>
<p>Posterior mean of <code class="reqn">\beta</code>.</p>
</td></tr>
<tr><td><code>LeftCI</code></td>
<td>
<p>Lower bound of <code class="reqn">100(1-\alpha)\%</code> credible interval for
<code class="reqn">\beta</code>.</p>
</td></tr>
<tr><td><code>RightCI</code></td>
<td>
<p>Upper bound of <code class="reqn">100(1-\alpha)\%</code> credible interval for
<code class="reqn">\beta</code>.</p>
</td></tr>
<tr><td><code>Sigma2Hat</code></td>
<td>
<p>Posterior mean of <code class="reqn">\sigma^{2}</code>.</p>
</td></tr>
<tr><td><code>TauHat</code></td>
<td>
<p>Posterior mean of <code class="reqn">\tau</code>.</p>
</td></tr>
<tr><td><code>LambdaHat</code></td>
<td>
<p>Posterior mean of <code class="reqn">\lambda_{j},\ j=1,2,...p.</code>.</p>
</td></tr>
<tr><td><code>ActiveMean</code></td>
<td>
<p>Average number of elements in the active set per iteration
in this algorithm.</p>
</td></tr>
<tr><td><code>BetaSamples</code></td>
<td>
<p>Posterior samples of <code class="reqn">\beta</code>.</p>
</td></tr>
<tr><td><code>LambdaSamples</code></td>
<td>
<p>Posterior samples of local shrinkage parameters.</p>
</td></tr>
<tr><td><code>TauSamples</code></td>
<td>
<p>Posterior samples of global shrinkage parameter.</p>
</td></tr>
<tr><td><code>Sigma2Samples</code></td>
<td>
<p>Posterior samples of <code class="reqn">sigma^{2}</code>.</p>
</td></tr>
<tr><td><code>ActiveSet</code></td>
<td>
<p><code class="reqn">\mathbb{R}^{iter \times p}</code> Matrix indicating active
elements as 1 and non-active elements as 0 per iteration of the MCMC
algorithm.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Johndrow, J., Orenstein, P., &amp; Bhattacharya, A. (2020).
Scalable Approximate MCMC Algorithms for the Horseshoe Prior. In Journal
of Machine Learning Research, 21, 1-61.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Making simulation data.
set.seed(123)
N &lt;- 200
p &lt;- 100
true_beta &lt;- c(rep(1, 10), rep(0, 90))

X &lt;- matrix(1, nrow = N, ncol = p) # Design matrix X.
for (i in 1:p) {
  X[, i] &lt;- stats::rnorm(N, mean = 0, sd = 1)
}

y &lt;- vector(mode = "numeric", length = N) # Response variable y.
e &lt;- rnorm(N, mean = 0, sd = 2) # error term e.
for (i in 1:10) {
  y &lt;- y + true_beta[i] * X[, i]
}
y &lt;- y + e

# Run with auto.threshold set to TRUE
result1 &lt;- approx_horseshoe(y, X, burn = 0, iter = 100,
                            auto.threshold = TRUE)

# Run with fixed custom threshold
result2 &lt;- approx_horseshoe(y, X, burn = 0, iter = 100,
                            auto.threshold = FALSE, threshold = 1/(5 * p))

# posterior mean
betahat &lt;- result1$BetaHat

# Lower bound of the 95% credible interval
leftCI &lt;- result1$LeftCI

# Upper bound of the 95% credible interval
RightCI &lt;- result1$RightCI

</code></pre>

<hr>
<h2 id='exact_horseshoe'>Run exact MCMC algorithm for horseshoe prior</h2><span id='topic+exact_horseshoe'></span>

<h3>Description</h3>

<p>The exact MCMC algorithm for the horseshoe prior introduced in section 2.1
of Johndrow et al. (2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exact_horseshoe(
  y,
  X,
  burn = 1000,
  iter = 5000,
  a = 1/5,
  b = 10,
  s = 0.8,
  tau = 1,
  sigma2 = 1,
  w = 1,
  alpha = 0.05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exact_horseshoe_+3A_y">y</code></td>
<td>
<p>Response vector, <code class="reqn">y \in \mathbb{R}^{N}</code>.</p>
</td></tr>
<tr><td><code id="exact_horseshoe_+3A_x">X</code></td>
<td>
<p>Design matrix, <code class="reqn">X \in \mathbb{R}^{N \times p}</code>.</p>
</td></tr>
<tr><td><code id="exact_horseshoe_+3A_burn">burn</code></td>
<td>
<p>Number of burn-in samples. The default is 1000.</p>
</td></tr>
<tr><td><code id="exact_horseshoe_+3A_iter">iter</code></td>
<td>
<p>Number of samples to be drawn from the posterior. The default is
5000.</p>
</td></tr>
<tr><td><code id="exact_horseshoe_+3A_a">a</code></td>
<td>
<p>A tuning parameter of the rejection sampler, where the default
value is <code class="reqn">a = 1/5</code>.</p>
</td></tr>
<tr><td><code id="exact_horseshoe_+3A_b">b</code></td>
<td>
<p>A tuning parameter of the rejection sampler, where the default
value is <code class="reqn">b = 10</code>.</p>
</td></tr>
<tr><td><code id="exact_horseshoe_+3A_s">s</code></td>
<td>
<p><code class="reqn">s^{2}</code> is the variance of tau's MH proposal distribution.
0.8 is a good default. If set to 0, the algorithm proceeds by fixing the
global shrinkage parameter <code class="reqn">\tau</code> to the initial setting value.</p>
</td></tr>
<tr><td><code id="exact_horseshoe_+3A_tau">tau</code></td>
<td>
<p>Initial value of the global shrinkage parameter <code class="reqn">\tau</code> when
starting the algorithm. The default is 1.</p>
</td></tr>
<tr><td><code id="exact_horseshoe_+3A_sigma2">sigma2</code></td>
<td>
<p>Initial value of error variance <code class="reqn">\sigma^{2}</code>. The default
is 1.</p>
</td></tr>
<tr><td><code id="exact_horseshoe_+3A_w">w</code></td>
<td>
<p>A hyperparameter of gamma prior for <code class="reqn">\sigma^{2}</code>. The default
is 1.</p>
</td></tr>
<tr><td><code id="exact_horseshoe_+3A_alpha">alpha</code></td>
<td>
<p><code class="reqn">100(1-\alpha)\%</code> credible interval setting argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The exact MCMC algorithm introduced in Section 2.1 of Johndrow et al. (2020)
is implemented in this function. This algorithm uses a blocked-Gibbs
sampler for <code class="reqn">(\tau, \beta, \sigma^2)</code>, where the global shrinkage
parameter <code class="reqn">\tau</code> is updated by an Metropolis-Hastings algorithm. The
local shrinkage parameter <code class="reqn">\lambda_{j},\ j = 1,2,...,p</code> is updated by
the rejection sampler.
</p>


<h3>Value</h3>

<table>
<tr><td><code>BetaHat</code></td>
<td>
<p>Posterior mean of <code class="reqn">\beta</code>.</p>
</td></tr>
<tr><td><code>LeftCI</code></td>
<td>
<p>Lower bound of <code class="reqn">100(1-\alpha)\%</code> credible interval for
<code class="reqn">\beta</code>.</p>
</td></tr>
<tr><td><code>RightCI</code></td>
<td>
<p>Upper bound of <code class="reqn">100(1-\alpha)\%</code> credible interval for
<code class="reqn">\beta</code>.</p>
</td></tr>
<tr><td><code>Sigma2Hat</code></td>
<td>
<p>Posterior mean of <code class="reqn">\sigma^{2}</code>.</p>
</td></tr>
<tr><td><code>TauHat</code></td>
<td>
<p>Posterior mean of <code class="reqn">\tau</code>.</p>
</td></tr>
<tr><td><code>LambdaHat</code></td>
<td>
<p>Posterior mean of <code class="reqn">\lambda_{j},\ j=1,2,...p.</code>.</p>
</td></tr>
<tr><td><code>BetaSamples</code></td>
<td>
<p>Samples from the posterior of <code class="reqn">\beta</code>.</p>
</td></tr>
<tr><td><code>LambdaSamples</code></td>
<td>
<p>Lambda samples through rejection sampling.</p>
</td></tr>
<tr><td><code>TauSamples</code></td>
<td>
<p>Tau samples through MH algorithm.</p>
</td></tr>
<tr><td><code>Sigma2Samples</code></td>
<td>
<p>Samples from the posterior of the parameter
<code class="reqn">sigma^{2}</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Johndrow, J., Orenstein, P., &amp; Bhattacharya, A. (2020). Scalable
Approximate MCMC Algorithms for the Horseshoe Prior. In Journal of Machine
Learning Research, 21, 1-61.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Making simulation data.
set.seed(123)
N &lt;- 50
p &lt;- 100
true_beta &lt;- c(rep(1, 10), rep(0, 90))

X &lt;- matrix(1, nrow = N, ncol = p) # Design matrix X.
for (i in 1:p) {
  X[, i] &lt;- stats::rnorm(N, mean = 0, sd = 1)
}

y &lt;- vector(mode = "numeric", length = N) # Response variable y.
e &lt;- rnorm(N, mean = 0, sd = 2) # error term e.
for (i in 1:10) {
  y &lt;- y + true_beta[i] * X[, i]
}
y &lt;- y + e

# Run exact_horseshoe
result &lt;- exact_horseshoe(y, X, burn = 0, iter = 100)

# posterior mean
betahat &lt;- result$BetaHat

# Lower bound of the 95% credible interval
leftCI &lt;- result$LeftCI

# Upper bound of the 95% credible interval
RightCI &lt;- result$RightCI

</code></pre>

<hr>
<h2 id='rejection_sampler'>rejection sampler to update local shrinkage parameters lambda.</h2><span id='topic+rejection_sampler'></span>

<h3>Description</h3>

<p>rejection sampler to update local shrinkage parameters lambda.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rejection_sampler(eps, a, b)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
