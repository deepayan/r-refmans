<!DOCTYPE html><html lang="en"><head><title>Help for package gofIG</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {gofIG}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ABEV1'><p>The first Allison-Betsch-Ebner-Visagie test statistic</p></a></li>
<li><a href='#ABEV2'><p>The second Allison-Betsch-Ebner-Visagie test statistic</p></a></li>
<li><a href='#AD'><p>The Anderson-Darling test statistic</p></a></li>
<li><a href='#BG'><p>The Baringhaus-Gaigall test statistic</p></a></li>
<li><a href='#CM'><p>The Cramer-von Mises test statistic</p></a></li>
<li><a href='#HK1'><p>The first Henze-Klar test statistic</p></a></li>
<li><a href='#HK2'><p>The second Henze-Klar test statistic</p></a></li>
<li><a href='#KS'><p>The Kolmogorov-Smirnov test statistic</p></a></li>
<li><a href='#print.gofIG'><p>Print method for tests of the inverse Gaussian distribution</p></a></li>
<li><a href='#test.ABEV1'><p>The first Allison-Betsch-Ebner-Visagie goodness-of-fit test for the inverse Gaussian family</p></a></li>
<li><a href='#test.ABEV2'><p>The second Allison-Betsch-Ebner-Visagie goodness-of-fit test for the inverse Gaussian family</p></a></li>
<li><a href='#test.AD'><p>The Anderson-Darling goodness-of-fit test for the inverse Gaussian family</p></a></li>
<li><a href='#test.BG'><p>The Baringhaus-Gaigall goodness-of-fit test for the inverse Gaussian family</p></a></li>
<li><a href='#test.CM'><p>The Cramer-von Mises goodness-of-fit test for the inverse Gaussian family</p></a></li>
<li><a href='#test.HK1'><p>The first Henze-Klar goodness-of-fit test for the inverse Gaussian family</p></a></li>
<li><a href='#test.HK2'><p>The second Henze-Klar goodness-of-fit test for the inverse Gaussian family</p></a></li>
<li><a href='#test.KS'><p>The Kolmogorov-Smirnov goodness-of-fit test for the inverse Gaussian family</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Goodness-of-Fit Tests for the Inverse Gaussian Distribution</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Bruno Ebner [aut, cre],
  Jaco Visagie [aut],
  Steffen Betsch [aut],
  James Allison [aut],
  Lucas Iglesias [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Bruno Ebner &lt;bruno.ebner@kit.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>We implement various tests for the composite hypothesis of
    testing the fit to the family of inverse Gaussian distributions. 
    Included are methods presented by Allison, J.S., Betsch, S., Ebner, B., and Visagie, I.J.H. (2022) &lt;<a href="https://doi.org/10.48550%2FarXiv.1910.14119">doi:10.48550/arXiv.1910.14119</a>&gt;, 
    as well as two tests from Henze and Klar (2002) &lt;<a href="https://doi.org/10.1023%2FA%3A1022442506681">doi:10.1023/A:1022442506681</a>&gt;.
    Additionally, the package implements a test proposed by Baringhaus and Gaigall (2015) &lt;<a href="https://doi.org/10.1016%2Fj.jmva.2015.05.013">doi:10.1016/j.jmva.2015.05.013</a>&gt;. 
    For each test a parametric bootstrap procedure is implemented.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://creativecommons.org/licenses/by/4.0">CC BY 4.0</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>pracma, rmutil,</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-10-29 07:57:37 UTC; lucas</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-11-01 14:30:12 UTC</td>
</tr>
</table>
<hr>
<h2 id='ABEV1'>The first Allison-Betsch-Ebner-Visagie test statistic</h2><span id='topic+ABEV1'></span>

<h3>Description</h3>

<p>This function computes the first test statistic of the goodness-of-fit tests for the inverse Gaussian family due to Allison et al. (2022). Two different estimation procedures are implemented, namely the method of moment and the maximum likelihood method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ABEV1(data, a = 10, meth = "MME")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ABEV1_+3A_data">data</code></td>
<td>
<p>a vector of positive numbers.</p>
</td></tr>
<tr><td><code id="ABEV1_+3A_a">a</code></td>
<td>
<p>positive tuning parameter.</p>
</td></tr>
<tr><td><code id="ABEV1_+3A_meth">meth</code></td>
<td>
<p>method of estimation used. Possible values are <code>'MME'</code> for moment estimation and <code>'MLE'</code> for maximum likelihood estimation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The numerically stable test statistic for the first Allison-Betsch-Ebner-Visagie test is defined as:
</p>
<p style="text-align: center;"><code class="reqn">ABEV1_{n,a} = \frac{1}{4n} \sum_{j,k=1}^{n} \left( \hat{\varphi}_n + \frac{3}{Y_{n,j}} - \frac{\hat{\varphi}_n}{Y_{n,j}^2} \right) \left( \hat{\varphi}_n + \frac{3}{Y_{n,k}} - \frac{\hat{\varphi}_n}{Y_{n,k}^2} \right) h_{1,a}(Y_{n,j}, Y_{n,k})</code>
</p>

<p style="text-align: center;"><code class="reqn">- 2 \left( \hat{\varphi}_n + \frac{3}{Y_{n,j}} - \frac{\hat{\varphi}_n}{Y_{n,j}^2} \right) h_{2,a}(Y_{n,j}, Y_{n,k})</code>
</p>

<p style="text-align: center;"><code class="reqn">- 2 \left( \hat{\varphi}_n + \frac{3}{Y_{n,k}} - \frac{\hat{\varphi}_n}{Y_{n,k}^2} \right) h_{2,a}(Y_{n,k}, Y_{n,j})</code>
</p>

<p style="text-align: center;"><code class="reqn">+ \frac{4}{a} e^{-a \max(Y_{n,j}, Y_{n,k})},</code>
</p>

<p>with <code class="reqn">\hat{\varphi}_n = \frac{\hat{\lambda}_n}{\hat{\mu}_n}</code>, where <code class="reqn">\hat{\mu}_n,\hat{\lambda}_n</code> are consistent estimators of <code class="reqn">\mu, \lambda</code>, respectively, the parameters of the inverse Gaussian distribution. Furthermore <code class="reqn">Y_{n,j} = \frac{X_j}{\hat{\mu}_n}</code>, <code class="reqn">j = 1,...,n</code>, for <code class="reqn">(X_j)_{j = 1,...,n}</code>, a sequence of  independent observations of a positive random variable <code class="reqn">X</code>. The functions <code class="reqn">h_{i,a}(s,t)</code>, <code class="reqn">i = 1,2</code>, are defined in Allison et al. (2022), section 5.1.  
The null hypothesis is rejected for large values of the test statistic <code class="reqn">ABEV1_{n,a}</code>.
</p>


<h3>Value</h3>

<p>value of the test statistic.
</p>


<h3>References</h3>

<p>Allison, J.S., Betsch, S., Ebner, B., Visagie, I.J.H. (2022) &quot;On Testing the Adequacy of the Inverse Gaussian Distribution&quot;. <a href="https://www.mdpi.com/2227-7390/10/3/350">LINK</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ABEV1(rmutil::rinvgauss(20,2,1),a=10,meth='MLE')

</code></pre>

<hr>
<h2 id='ABEV2'>The second Allison-Betsch-Ebner-Visagie test statistic</h2><span id='topic+ABEV2'></span>

<h3>Description</h3>

<p>This function computes the second test statistic of the goodness-of-fit tests for the inverse Gaussian family due to Allison et al. (2022). Two different estimation procedures are implemented, namely the method of moment and the maximum likelihood method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ABEV2(data, a = 10, meth = "MME")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ABEV2_+3A_data">data</code></td>
<td>
<p>a vector of positive numbers.</p>
</td></tr>
<tr><td><code id="ABEV2_+3A_a">a</code></td>
<td>
<p>positive tuning parameter.</p>
</td></tr>
<tr><td><code id="ABEV2_+3A_meth">meth</code></td>
<td>
<p>method of estimation used. Possible values are <code>'MME'</code> for moment estimation and <code>'MLE'</code> for maximum likelihood estimation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The numerically stable test statistic for the second Allison-Betsch-Ebner-Visagie test is defined as:
</p>
<p style="text-align: center;"><code class="reqn">ABEV2_{n,a} = \frac{1}{4n} \sum_{j,k=1}^{n} \left( \hat{\varphi}_n + \frac{3}{Y_{n,j}} - \frac{\hat{\varphi}_n}{Y_{n,j}^2} \right) \left( \hat{\varphi}_n + \frac{3}{Y_{n,k}} - \frac{\hat{\varphi}_n}{Y_{n,k}^2} \right) \tilde{h}_{1,a}(Y_{n,j}, Y_{n,k})</code>
</p>

<p style="text-align: center;"><code class="reqn">- 2 \left( \hat{\varphi}_n + \frac{3}{Y_{n,j}} - \frac{\hat{\varphi}_n}{Y_{n,j}^2} \right) \tilde{h}_{2,a}(Y_{n,j}, Y_{n,k})</code>
</p>

<p style="text-align: center;"><code class="reqn">- 2 \left( \hat{\varphi}_n + \frac{3}{Y_{n,k}} - \frac{\hat{\varphi}_n}{Y_{n,k}^2} \right) \tilde{h}_{2,a}(Y_{n,k}, Y_{n,j})</code>
</p>

<p style="text-align: center;"><code class="reqn">+ 4 \frac{\sqrt{\pi}}{a} \Phi \left( - \sqrt{2a} \max(Y_{n,j}, Y_{n,k}) \right),</code>
</p>

<p>with <code class="reqn">\hat{\varphi}_n = \frac{\hat{\lambda}_n}{\hat{\mu}_n}</code>, where <code class="reqn">\hat{\mu}_n,\hat{\lambda}_n</code> are consistent estimators of <code class="reqn">\mu, \lambda</code>, respectively, the parameters of the inverse Gaussian distribution. Furthermore <code class="reqn">Y_{n,j} = \frac{X_j}{\hat{\mu}_n}</code>, <code class="reqn">j = 1,...,n</code>, for <code class="reqn">(X_j)_{j = 1,...,n}</code>, a sequence of  independent observations of a positive random variable <code class="reqn">X</code>. 
The functions <code class="reqn">\tilde{h}_{i,a}(s,t)</code>, <code class="reqn">i = 1,2</code>, are defined in Allison et al. (2022), section 5.1, and <code class="reqn">\Phi</code> denotes the distribution function of the standard normal distribution.
The null hypothesis is rejected for large values of the test statistic <code class="reqn">ABEV2_{n,a}</code>.
</p>


<h3>Value</h3>

<p>value of the test statistic.
</p>


<h3>References</h3>

<p>Allison, J.S., Betsch, S., Ebner, B., Visagie, I.J.H. (2022) &quot;On Testing the Adequacy of the Inverse Gaussian Distribution&quot;. <a href="https://www.mdpi.com/2227-7390/10/3/350">LINK</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ABEV2(rmutil::rinvgauss(20,2,1),a=10,meth='MLE')

</code></pre>

<hr>
<h2 id='AD'>The Anderson-Darling test statistic</h2><span id='topic+AD'></span>

<h3>Description</h3>

<p>This function computes the test statistic of the goodness-of-fit test for the inverse Gaussian family in the spirit of Anderson and Darling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AD(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AD_+3A_data">data</code></td>
<td>
<p>a vector of positive numbers.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">X_{(j)}</code> denote the <code class="reqn">j</code>th order statistic of <code class="reqn">X_1, \ldots, X_n</code>, a sequence of  independent observations of a positive random variable <code class="reqn">X</code>. Furthermore, let <code class="reqn">\hat{F}(x) = F(x; \hat{\mu}_n, \hat{\lambda}_n)</code>, where <code class="reqn">F</code> is the distribution function of the inverse Gaussian distribution. 
Note that  <code class="reqn">\hat{\mu}_n,\hat{\lambda}_n</code> are the maximum likelihood estimators for <code class="reqn">\mu</code> and <code class="reqn">\lambda</code>, respectively, the parameters of the inverse Gaussian distribution.
The null hypothesis is rejected for large values of the test statistic: 
</p>
<p style="text-align: center;"><code class="reqn">AD = -n - \frac{1}{n} \sum_{j=1}^{n} \left[ (2j-1) \log \hat{F}(X_{(j)}) + (2(n-j) + 1) \log \left( 1 - \hat{F}(X_{(j)}) \right) \right].</code>
</p>



<h3>Value</h3>

<p>value of the test statistic.
</p>


<h3>References</h3>

<p>Allison, J.S., Betsch, S., Ebner, B., Visagie, I.J.H. (2022) &quot;On Testing the Adequacy of the Inverse Gaussian Distribution&quot;. <a href="https://www.mdpi.com/2227-7390/10/3/350">LINK</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>AD(rmutil::rinvgauss(20,2,1))

</code></pre>

<hr>
<h2 id='BG'>The Baringhaus-Gaigall test statistic</h2><span id='topic+BG'></span>

<h3>Description</h3>

<p>This function computes the test statistic of the goodness-of-fit test for the inverse Gaussian family due to Baringhaus and Gaigall (2015).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BG(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BG_+3A_data">data</code></td>
<td>
<p>a vector of positive numbers.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test statistic of the Baringhaus-Gaigall test is defined as: 
</p>
<p style="text-align: center;"><code class="reqn">BG_{n} = \frac{n}{(n(n-1))^5} \sum_{\mu, \nu = 1, \mu \neq \nu}^{n} \left( N_1(\mu, \nu)N_4(\mu, \nu) - N_2(\mu, \nu)N_3(\mu, \nu) \right)^2,</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">N_1(\mu, \nu) = \sum_{i,j = 1, i \neq j}^{n} \mathbf{1} \left\{ \tilde{Y}_{i,j} \leq \tilde{Y}_{\mu, \nu}, \tilde{Z}_{i,j} \leq \tilde{Z}_{\mu, \nu} \right\},</code>
</p>

<p style="text-align: center;"><code class="reqn">N_2(\mu, \nu) = \sum_{i,j = 1, i \neq j}^{n} \mathbf{1} \left\{ \tilde{Y}_{i,j} \leq \tilde{Y}_{\mu, \nu}, \tilde{Z}_{i,j} &gt; \tilde{Z}_{\mu, \nu} \right\},</code>
</p>

<p style="text-align: center;"><code class="reqn">N_3(\mu, \nu) = \sum_{i,j = 1, i \neq j}^{n} \mathbf{1} \left\{ \tilde{Y}_{i,j} &gt; \tilde{Y}_{\mu, \nu}, \tilde{Z}_{i,j} \leq \tilde{Z}_{\mu, \nu} \right\},</code>
</p>

<p style="text-align: center;"><code class="reqn">N_4(\mu, \nu) = \sum_{i,j = 1, i \neq j}^{n} \mathbf{1} \left\{ \tilde{Y}_{i,j} &gt; \tilde{Y}_{\mu, \nu}, \tilde{Z}_{i,j} &gt; \tilde{Z}_{\mu, \nu} \right\},</code>
</p>

<p>with <code class="reqn">\mathbf{1}</code> being the indicator function.
Let <code class="reqn">f(X_i,X_j) = (X_i + X_j)/2</code> and <code class="reqn">g(X_i,X_j) = (X_i^{-1} + X_j^{-1})/2 - f(X_i,X_j)^{-1}</code>, with <code class="reqn">X_1,...,X_n</code> positive, independent and identically distributed random variables with finite moments <code class="reqn">\mathbb{E}[X_1^2]</code> and <code class="reqn">\mathbb{E}[X_1^{-1}]</code>. 
Then <code class="reqn">(\tilde{Y}_{i,j}, \tilde{Z}_{i,j}) = (f(X_i,X_j), g(X_i,X_j)), 1 \leq i,j \leq n, i \neq j</code>. Note that <code class="reqn">\tilde{Y}_{i,j}</code> and <code class="reqn">\tilde{Z}_{i,j}</code> are independent if, and only if <code class="reqn">X_1,...,X_n</code> are realized from an inverse Gaussian distribution.
</p>


<h3>Value</h3>

<p>value of the test statistic.
</p>


<h3>References</h3>

<p>Baringhaus, L.  Gaigall, D. (2015). &quot;On an independence test approach to the goodness-of-fit problem&quot;, Journal of Multivariate Analysis, 140, 193-208. <a href="https://doi.org/10.1016/j.jmva.2015.05.013">doi:10.1016/j.jmva.2015.05.013</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>BG(rmutil::rinvgauss(20,2,1))

</code></pre>

<hr>
<h2 id='CM'>The Cramer-von Mises test statistic</h2><span id='topic+CM'></span>

<h3>Description</h3>

<p>This function computes value of the test statistic of the goodness-of-fit test for the inverse Gaussian family in the spirit of Cramer and von Mises. Note that this tests the composite hypothesis of fit to the family of inverse Gaussian distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CM(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CM_+3A_data">data</code></td>
<td>
<p>a vector of positive numbers.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">X_{(j)}</code> denote the <code class="reqn">j</code>th order statistic of <code class="reqn">X_1, \ldots, X_n</code>, a sequence of  independent observations of a positive random variable <code class="reqn">X</code>. Furthermore, let <code class="reqn">\hat{F}(x) = F(x; \hat{\mu}_n, \hat{\lambda}_n)</code>, where <code class="reqn">F</code> is the distribution function of the inverse Gaussian distribution. 
Note that  <code class="reqn">\hat{\mu}_n,\hat{\lambda}_n</code> are the maximum likelihood estimators for <code class="reqn">\mu</code> and <code class="reqn">\lambda</code>, respectively, the parameters of the inverse Gaussian distribution.
The null hypothesis is rejected for large values of the test statistic: 
</p>
<p style="text-align: center;"><code class="reqn">CM = \frac{1}{12n} + \sum_{j=1}^{n} \left( \hat{F}(X_{(j)}) - \frac{2j-1}{2n} \right)^2.</code>
</p>



<h3>Value</h3>

<p>value of the test statistic.
</p>


<h3>References</h3>

<p>Allison, J.S., Betsch, S., Ebner, B., Visagie, I.J.H. (2022) &quot;On Testing the Adequacy of the Inverse Gaussian Distribution&quot;. <a href="https://www.mdpi.com/2227-7390/10/3/350">LINK</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>CM(rmutil::rinvgauss(20,2,1))

</code></pre>

<hr>
<h2 id='HK1'>The first Henze-Klar test statistic</h2><span id='topic+HK1'></span>

<h3>Description</h3>

<p>This function computes the first test statistic of the goodness-of-fit test for the inverse Gaussian family due to Henze and Klar (2002).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HK1(data, a = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="HK1_+3A_data">data</code></td>
<td>
<p>a vector of positive numbers.</p>
</td></tr>
<tr><td><code id="HK1_+3A_a">a</code></td>
<td>
<p>positive tuning parameter.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The representation of the first Henze-Klar test statistic used for computation is given by: 
</p>
<p style="text-align: center;"><code class="reqn">HK_{n,a}^{(1)}= \frac{\hat{\varphi}_n}{n} \sum_{j,k=1}^{n} \hat{Z}_{jk}^{-1} \left\{ 1 - (Y_j + Y_k) \left( 1 + \sqrt{\frac{\pi}{2\hat{Z}_{jk}}} \text{erfce}\left( \sqrt{\frac{\hat{Z}_{jk}}{2}} \right) \right) + \left( 1 + \frac{2}{\hat{Z}_{jk}} \right) Y_j Y_k \right\},</code>
</p>

<p>with <code class="reqn">\hat{\varphi}_n = \frac{\hat{\lambda}_n}{\hat{\mu}_n}</code>, where <code class="reqn">\hat{\mu}_n,\hat{\lambda}_n</code> are the maximum likelihood estimators for <code class="reqn">\mu</code> and <code class="reqn">\lambda</code>, respectively, the parameters of the inverse Gaussian distribution. 
Furthermore <code class="reqn">\hat{Z}_{jk} = \hat{\varphi}_n(Y_j + Y_k +a)</code>, where <code class="reqn">Y_i = \frac{X_i}{\hat{\mu}_n}</code> for <code class="reqn">(X_i)_{i = 1,...,n}</code>, a sequence of  independent observations of a nonnegative random variable <code class="reqn">X</code>.
To ensure numerical stability of the implementation the exponentially scaled complementary error function <code class="reqn">\text{erfce}(x)</code> is used: <code class="reqn">\text{erfce}(x) = \exp{(x^2)}\text{erfc}(x)</code>, with <code class="reqn">\text{erfc}(x) = 2\int_x^\infty \exp{(-t^2)}dt/\pi</code>.
The null hypothesis is rejected for large values of the test statistic <code class="reqn">HK_{n,a}^{(1)}</code>.
</p>


<h3>Value</h3>

<p>value of the test statistic
</p>


<h3>References</h3>

<p>Henze, N. and Klar, B. (2002) &quot;Goodness-of-fit tests for the inverse Gaussian distribution based on the empirical Laplace transform&quot;, Annals of the Institute of Statistical Mathematics, 54(2):425-444. <a href="https://doi.org/10.1023/A%3A1022442506681">doi:10.1023/A:1022442506681</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>HK1(rmutil::rinvgauss(20,2,1))

</code></pre>

<hr>
<h2 id='HK2'>The second Henze-Klar test statistic</h2><span id='topic+HK2'></span>

<h3>Description</h3>

<p>This function computes the test statistic of  the second goodness-of-fit test for the inverse Gaussian family due to Henze and Klar (2002).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HK2(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="HK2_+3A_data">data</code></td>
<td>
<p>a vector of positive numbers.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The representation of the second Henze-Klar test statistic used for computation <code class="reqn">(a = 0)</code> is given by:
</p>
<p style="text-align: center;"><code class="reqn">HK_{n,0}^{(2)} = \frac{1}{n} \sum_{j,k=1}^{n} Z_{jk}^{-1} - 2 \sum_{j=1}^{n} Z_j^{-1} \left\{ 1 - \sqrt{\frac{\pi \hat{\varphi}_n}{2 Z_j}} \, \mathrm{erfce} \left( \frac{\hat{\varphi}_n^{1/2} (Z_j + 1)}{(2 Z_j)^{1/2}} \right) \right\} + n\frac{1 + 2 \hat{\varphi}_n}{4 \hat{\varphi}_n}</code>
</p>

<p>with <code class="reqn">\hat{\varphi}_n = \frac{\hat{\lambda}_n}{\hat{\mu}_n}</code>, where <code class="reqn">\hat{\mu}_n,\hat{\lambda}_n</code> are the maximum likelihood estimators for <code class="reqn">\mu</code> and <code class="reqn">\lambda</code>, respectively, the parameters of the inverse Gaussian distribution. 
Furthermore <code class="reqn">Z_{jk} = (Y_j + Y_k)</code> and <code class="reqn">Z_j = Y_j</code>, where <code class="reqn">Y_i = \frac{X_i}{\hat{\mu}_n}</code> for <code class="reqn">(X_i)_{i = 1,...,n}</code>, a sequence of  independent observations of a nonnegative random variable <code class="reqn">X</code>.
To ensure numerical stability of the implementation the exponentially scaled complementary error function <code class="reqn">\text{erfce}(x)</code> is used: <code class="reqn">\text{erfce}(x) = \exp{(x^2)}\text{erfc}(x)</code>, with <code class="reqn">\text{erfc}(x) = 2\int_x^\infty \exp{(-t^2)}dt/\pi</code>.
The null hypothesis is rejected for large values of the test statistic <code class="reqn">HK_{n,a}^{(2)}</code>.
</p>


<h3>Value</h3>

<p>value of the test statistic.
</p>


<h3>References</h3>

<p>Henze, N. and Klar, B. (2002) &quot;Goodness-of-fit tests for the inverse Gaussian distribution based on the empirical Laplace transform&quot;, Annals of the Institute of Statistical Mathematics, 54(2):425-444. <a href="https://doi.org/10.1023/A%3A1022442506681">doi:10.1023/A:1022442506681</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>HK2(rmutil::rinvgauss(20,2,1))

</code></pre>

<hr>
<h2 id='KS'>The Kolmogorov-Smirnov test statistic</h2><span id='topic+KS'></span>

<h3>Description</h3>

<p>This function computes the test statistic of the goodness-of-fit test for the inverse Gaussian family in the spirit of Kolmogorov and Smirnov. Note that this tests the composite hypothesis of fit to the family of inverse Gaussian distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KS(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="KS_+3A_data">data</code></td>
<td>
<p>a vector of positive numbers.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">X_{(j)}</code> denote the <code class="reqn">j</code>th order statistic of <code class="reqn">X_1, \ldots, X_n</code>, a sequence of  independent observations of a positive random variable <code class="reqn">X</code>. Furthermore, let <code class="reqn">\hat{F}(x) = F(x; \hat{\mu}_n, \hat{\lambda}_n)</code>, where <code class="reqn">F</code> is the distribution function of the inverse Gaussian distribution. 
Note that  <code class="reqn">\hat{\mu}_n,\hat{\lambda}_n</code> are the maximum likelihood estimators for <code class="reqn">\mu</code> and <code class="reqn">\lambda</code>, respectively, the parameters of the inverse Gaussian distribution.
The null hypothesis is rejected for large values of the test statistic: 
</p>
<p style="text-align: center;"><code class="reqn">KS = \max(D^+, D^-),</code>
</p>

<p>where </p>
<p style="text-align: center;"><code class="reqn">D^+ = \max_{j=1,\ldots,n} \left( \frac{j}{n} - \hat{F}(X_{(j)}) \right)</code>
</p>

<p>and </p>
<p style="text-align: center;"><code class="reqn">D^- = \max_{j=1,\ldots,n} \left( \hat{F}(X_{(j)}) - \frac{j-1}{n} \right).</code>
</p>



<h3>Value</h3>

<p>value of the test statistic.
</p>


<h3>References</h3>

<p>Allison, J.S., Betsch, S., Ebner, B., Visagie, I.J.H. (2022) &quot;On Testing the Adequacy of the Inverse Gaussian Distribution&quot;. <a href="https://www.mdpi.com/2227-7390/10/3/350">LINK</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>KS(rmutil::rinvgauss(20,2,1))

</code></pre>

<hr>
<h2 id='print.gofIG'>Print method for tests of the inverse Gaussian distribution</h2><span id='topic+print.gofIG'></span>

<h3>Description</h3>

<p>Printing objects of class &quot;gofIG&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gofIG'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.gofIG_+3A_x">x</code></td>
<td>
<p>object of class &quot;gofIG&quot;.</p>
</td></tr>
<tr><td><code id="print.gofIG_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A <code>gofIG</code> object is a named list of numbers and character string, supplemented with <code>test</code> (the name of the teststatistic). <code>test</code> is displayed as a title.
The remaining elements are given in an aligned &quot;name = value&quot; format.
</p>


<h3>Value</h3>

<p>the argument x, invisibly, as for all <a href="base.html#topic+print">print</a> methods.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>print(test.ABEV1(rgamma(20,1)))

</code></pre>

<hr>
<h2 id='test.ABEV1'>The first Allison-Betsch-Ebner-Visagie goodness-of-fit test for the inverse Gaussian family</h2><span id='topic+test.ABEV1'></span>

<h3>Description</h3>

<p>This function computes the goodness-of-fit test for the inverse Gaussian family due to Allison et al. (2019). Two different estimation procedures are implemented, namely the method of moment and the maximum likelihood method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.ABEV1(data, a = 10, meth = "MME", B = 500)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test.ABEV1_+3A_data">data</code></td>
<td>
<p>a vector of positive numbers.</p>
</td></tr>
<tr><td><code id="test.ABEV1_+3A_a">a</code></td>
<td>
<p>positive tuning parameter.</p>
</td></tr>
<tr><td><code id="test.ABEV1_+3A_meth">meth</code></td>
<td>
<p>method of estimation used. Possible values are <code>'MME'</code> for moment estimation and <code>'MLE'</code> for maximum likelihood estimation.</p>
</td></tr>
<tr><td><code id="test.ABEV1_+3A_b">B</code></td>
<td>
<p>number of bootstrap iterations used to obtain p value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test is of weighted <code class="reqn">L^2</code> type and uses a characterization of the distribution function of the inverse Gaussian distribution. The p value is obtained by a parametric bootstrap procedure.
</p>


<h3>Value</h3>

<p>a list containing the value of the name of the test statistic, the used tuning parameter, the parameter estimation method, the value of the test statistic, the bootstrap p value, the values of the estimators, and the number of bootstrap iterations: <br />
</p>

<dl>
<dt><code>$Test</code></dt><dd><p>the name of the used test statistic.</p>
</dd>
<dt><code>$parameter</code></dt><dd><p>the value of the tuning parameter.</p>
</dd>
<dt><code>$est.method</code></dt><dd><p>the estimation method used.</p>
</dd>
<dt><code>$T.value</code></dt><dd><p>the value of the test statistic.</p>
</dd>
<dt><code>$p.value</code></dt><dd><p>the approximated p value.</p>
</dd>
<dt><code>$par.est</code></dt><dd><p>the estimated parameters.</p>
</dd>
<dt><code>$boot.run</code></dt><dd><p>number of bootstrap iterations.</p>
</dd>
</dl>



<h3>References</h3>

<p>Allison, J.S., Betsch, S., Ebner, B., Visagie, I.J.H. (2019) &quot;New weighted <code class="reqn">L^2</code>-type tests for the inverse Gaussian distribution&quot;, arXiv:1910.14119. <a href="https://arxiv.org/abs/1910.14119">LINK</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test.ABEV1(rmutil::rinvgauss(20,2,1),B=100)

</code></pre>

<hr>
<h2 id='test.ABEV2'>The second Allison-Betsch-Ebner-Visagie goodness-of-fit test for the inverse Gaussian family</h2><span id='topic+test.ABEV2'></span>

<h3>Description</h3>

<p>This function computes the goodness-of-fit test for the inverse Gaussian family due to Allison et al. (2019). Two different estimation procedures are implemented, namely the method of moment and the maximum likelihood method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.ABEV2(data, a = 10, meth = "MME", B = 500)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test.ABEV2_+3A_data">data</code></td>
<td>
<p>a vector of positive numbers.</p>
</td></tr>
<tr><td><code id="test.ABEV2_+3A_a">a</code></td>
<td>
<p>positive tuning parameter.</p>
</td></tr>
<tr><td><code id="test.ABEV2_+3A_meth">meth</code></td>
<td>
<p>method of estimation used. Possible values are <code>'MME'</code> for moment estimation and <code>'MLE'</code> for maximum likelihood estimation.</p>
</td></tr>
<tr><td><code id="test.ABEV2_+3A_b">B</code></td>
<td>
<p>number of bootstrap iterations used to obtain p value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test is of weighted <code class="reqn">L^2</code> type and uses a characterization of the distribution function of the inverse Gaussian distribution. The p value is obtained by a parametric bootstrap procedure.
</p>


<h3>Value</h3>

<p>a list containing the value of the name of the test statistic, the used tuning parameter, the parameter estimation method, the value of the test statistic, the bootstrap p value, the values of the estimators, and the number of bootstrap iterations: <br />
</p>

<dl>
<dt><code>$Test</code></dt><dd><p>the name of the used test statistic.</p>
</dd>
<dt><code>$parameter</code></dt><dd><p>the value of the tuning parameter.</p>
</dd>
<dt><code>$est.method</code></dt><dd><p>the estimation method used.</p>
</dd>
<dt><code>$T.value</code></dt><dd><p>the value of the test statistic.</p>
</dd>
<dt><code>$p.value</code></dt><dd><p>the approximated p value.</p>
</dd>
<dt><code>$par.est</code></dt><dd><p>the estimated parameters.</p>
</dd>
<dt><code>$boot.run</code></dt><dd><p>number of bootstrap iterations.</p>
</dd>
</dl>



<h3>References</h3>

<p>Allison, J.S., Betsch, S., Ebner, B., Visagie, I.J.H. (2019) &quot;New weighted <code class="reqn">L^2</code>-type tests for the inverse Gaussian distribution&quot;, arXiv:1910.14119. <a href="https://arxiv.org/abs/1910.14119">LINK</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test.ABEV2(rmutil::rinvgauss(20,2,1),B=100)

</code></pre>

<hr>
<h2 id='test.AD'>The Anderson-Darling goodness-of-fit test for the inverse Gaussian family</h2><span id='topic+test.AD'></span>

<h3>Description</h3>

<p>This function computes the goodness-of-fit test for the inverse Gaussian family in the spirit of Anderson and Darling. Note that this tests the composite hypothesis of fit to the family of inverse Gaussian distributions, i.e. a bootstrap procedure is implemented to perform the test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.AD(data, B = 500)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test.AD_+3A_data">data</code></td>
<td>
<p>a vector of positive numbers.</p>
</td></tr>
<tr><td><code id="test.AD_+3A_b">B</code></td>
<td>
<p>number of bootstrap iterations used to obtain p value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Anderson-Darling test is computed as described in Allison et. al. (2019). The p value is obtained by a parametric bootstrap procedure.
</p>


<h3>Value</h3>

<p>a list containing the value of the name of the test statistic, the value of the test statistic, the bootstrap p value, the values of the estimators, and the number of bootstrap iterations: <br />
</p>

<dl>
<dt><code>$Test</code></dt><dd><p>the name of the used test statistic.</p>
</dd>
<dt><code>$T.value</code></dt><dd><p>the value of the test statistic.</p>
</dd>
<dt><code>$p.value</code></dt><dd><p>the approximated p value.</p>
</dd>
<dt><code>$par.est</code></dt><dd><p>the estimated parameters.</p>
</dd>
<dt><code>$boot.run</code></dt><dd><p>number of bootstrap iterations.</p>
</dd>
</dl>



<h3>References</h3>

<p>Allison, J.S., Betsch, S., Ebner, B., Visagie, I.J.H. (2019) &quot;New weighted <code class="reqn">L^2</code>-type tests for the inverse Gaussian distribution&quot;, arXiv:1910.14119. <a href="https://arxiv.org/abs/1910.14119">LINK</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test.AD(rmutil::rinvgauss(20,2,1),B=100)

</code></pre>

<hr>
<h2 id='test.BG'>The Baringhaus-Gaigall goodness-of-fit test for the inverse Gaussian family</h2><span id='topic+test.BG'></span>

<h3>Description</h3>

<p>This function computes the goodness-of-fit test for the inverse Gaussian family due to Baringhaus and Gaigall (2015).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.BG(data, B)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test.BG_+3A_data">data</code></td>
<td>
<p>a vector of positive numbers.</p>
</td></tr>
<tr><td><code id="test.BG_+3A_b">B</code></td>
<td>
<p>number of bootstrap iterations used to obtain p value.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing the value of the name of the test statistic, the used tuning parameter, the parameter estimation method, the value of the test statistic, the bootstrap p value, the values of the estimators, and the number of bootstrap iterations: <br />
</p>

<dl>
<dt><code>$Test</code></dt><dd><p>the name of the used test statistic.</p>
</dd>
<dt><code>$T.value</code></dt><dd><p>the value of the test statistic.</p>
</dd>
<dt><code>$p.value</code></dt><dd><p>the approximated p value.</p>
</dd>
<dt><code>$par.est</code></dt><dd><p>the estimated parameters.</p>
</dd>
<dt><code>$boot.run</code></dt><dd><p>number of bootstrap iterations.</p>
</dd>
</dl>



<h3>References</h3>

<p>Baringhaus, L.  Gaigall, D. (2015). &quot;On an independence test approach to the goodness-of-fit problem&quot;, Journal of Multivariate Analysis, 140, 193-208. <a href="https://doi.org/10.1016/j.jmva.2015.05.013">doi:10.1016/j.jmva.2015.05.013</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test.BG(rmutil::rinvgauss(20,2,1),B=100)

</code></pre>

<hr>
<h2 id='test.CM'>The Cramer-von Mises goodness-of-fit test for the inverse Gaussian family</h2><span id='topic+test.CM'></span>

<h3>Description</h3>

<p>This function computes the goodness-of-fit test for the inverse Gaussian family in the spirit of Cramer and von Mises. Note that this tests the composite hypothesis of fit to the family of inverse Gaussian distributions, i.e. a bootstrap procedure is implemented to perform the test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.CM(data, B = 500)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test.CM_+3A_data">data</code></td>
<td>
<p>a vector of positive numbers.</p>
</td></tr>
<tr><td><code id="test.CM_+3A_b">B</code></td>
<td>
<p>number of bootstrap iterations used to obtain p value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Cramer-von Mises test is computed as described in Allison et. al. (2019). The p value is obtained by a parametric bootstrap procedure.
</p>


<h3>Value</h3>

<p>a list containing the value of the name of the test statistic, the value of the test statistic, the bootstrap p value, the values of the estimators, and the number of bootstrap iterations: <br />
</p>

<dl>
<dt><code>$Test</code></dt><dd><p>the name of the used test statistic.</p>
</dd>
<dt><code>$T.value</code></dt><dd><p>the value of the test statistic.</p>
</dd>
<dt><code>$p.value</code></dt><dd><p>the approximated p value.</p>
</dd>
<dt><code>$par.est</code></dt><dd><p>the estimated parameters.</p>
</dd>
<dt><code>$boot.run</code></dt><dd><p>number of bootstrap iterations.</p>
</dd>
</dl>



<h3>References</h3>

<p>Allison, J.S., Betsch, S., Ebner, B., Visagie, I.J.H. (2019) &quot;New weighted <code class="reqn">L^2</code>-type tests for the inverse Gaussian distribution&quot;, arXiv:1910.14119. <a href="https://arxiv.org/abs/1910.14119">LINK</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test.CM(rmutil::rinvgauss(20,2,1),B=100)

</code></pre>

<hr>
<h2 id='test.HK1'>The first Henze-Klar goodness-of-fit test for the inverse Gaussian family</h2><span id='topic+test.HK1'></span>

<h3>Description</h3>

<p>This function computes the goodness-of-fit test for the inverse Gaussian family due to Henze and Klar (2002).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.HK1(data, a = 0, B = 500)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test.HK1_+3A_data">data</code></td>
<td>
<p>a vector of positive numbers.</p>
</td></tr>
<tr><td><code id="test.HK1_+3A_a">a</code></td>
<td>
<p>positive tuning parameter.</p>
</td></tr>
<tr><td><code id="test.HK1_+3A_b">B</code></td>
<td>
<p>number of bootstrap iterations used to obtain p value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test statistics is a weighted integral over the squared modulus of some measure of deviation of the empirical distribution of given data from the family of inverse Gaussian laws, expressed by means of the empirical Laplace transform.
</p>


<h3>Value</h3>

<p>a list containing the value of the name of the test statistic, the used tuning parameter, the parameter estimation method, the value of the test statistic, the bootstrap p value, the values of the estimators, and the number of bootstrap iterations: <br />
</p>

<dl>
<dt><code>$Test</code></dt><dd><p>the name of the used test statistic.</p>
</dd>
<dt><code>$parameter</code></dt><dd><p>the value of the tuning parameter.</p>
</dd>
<dt><code>$T.value</code></dt><dd><p>the value of the test statistic.</p>
</dd>
<dt><code>$p.value</code></dt><dd><p>the approximated p value.</p>
</dd>
<dt><code>$par.est</code></dt><dd><p>the estimated parameters.</p>
</dd>
<dt><code>$boot.run</code></dt><dd><p>number of bootstrap iterations.</p>
</dd>
</dl>



<h3>References</h3>

<p>Henze, N. and Klar, B. (2002) &quot;Goodness-of-fit tests for the inverse Gaussian distribution based on the empirical Laplace transform&quot;, Annals of the Institute of Statistical Mathematics, 54(2):425-444. <a href="https://doi.org/10.1023/A%3A1022442506681">doi:10.1023/A:1022442506681</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test.HK1(rmutil::rinvgauss(20,2,1),B=100)

</code></pre>

<hr>
<h2 id='test.HK2'>The second Henze-Klar goodness-of-fit test for the inverse Gaussian family</h2><span id='topic+test.HK2'></span>

<h3>Description</h3>

<p>This function computes the goodness-of-fit test for the inverse Gaussian family due to Henze and Klar (2002).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.HK2(data, B)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test.HK2_+3A_data">data</code></td>
<td>
<p>a vector of positive numbers.</p>
</td></tr>
<tr><td><code id="test.HK2_+3A_b">B</code></td>
<td>
<p>number of bootstrap iterations used to obtain p value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test statistic is a weighted integral over the squared modulus of some measure of deviation of the empirical distribution of given data from the family of inverse Gaussian laws, expressed by means of the empirical Laplace transform.
</p>


<h3>Value</h3>

<p>a list containing the value of the name of the test statistic, the used tuning parameter, the parameter estimation method, the value of the test statistic, the bootstrap p value, the values of the estimators, and the number of bootstrap iterations: <br />
</p>

<dl>
<dt><code>$Test</code></dt><dd><p>the name of the used test statistic.</p>
</dd>
<dt><code>$T.value</code></dt><dd><p>the value of the test statistic.</p>
</dd>
<dt><code>$p.value</code></dt><dd><p>the approximated p value.</p>
</dd>
<dt><code>$par.est</code></dt><dd><p>the estimated parameters.</p>
</dd>
<dt><code>$boot.run</code></dt><dd><p>number of bootstrap iterations.</p>
</dd>
</dl>



<h3>References</h3>

<p>Henze, N. and Klar, B. (2002) &quot;Goodness-of-fit tests for the inverse Gaussian distribution based on the empirical Laplace transform&quot;, Annals of the Institute of Statistical Mathematics, 54(2):425-444. <a href="https://doi.org/10.1023/A%3A1022442506681">doi:10.1023/A:1022442506681</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test.HK2(rmutil::rinvgauss(20,2,1),B=100)

</code></pre>

<hr>
<h2 id='test.KS'>The Kolmogorov-Smirnov goodness-of-fit test for the inverse Gaussian family</h2><span id='topic+test.KS'></span>

<h3>Description</h3>

<p>This function computes the goodness-of-fit test for the inverse Gaussian family in the spirit of Kolmogorov and Smirnov. Note that this tests the composite hypothesis of fit to the family of inverse Gaussian distributions, i.e. a bootstrap procedure is implemented to perform the test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.KS(data, B = 500)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test.KS_+3A_data">data</code></td>
<td>
<p>a vector of positive numbers.</p>
</td></tr>
<tr><td><code id="test.KS_+3A_b">B</code></td>
<td>
<p>number of bootstrap iterations used to obtain p value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Kolmogorov Smirnov test is computed as described in Allison et. al. (2019). The p value is obtained by a parametric bootstrap procedure.
</p>


<h3>Value</h3>

<p>a list containing the value of the name of the test statistic, the value of the test statistic, the bootstrap p value, the values of the estimators, and the number of bootstrap iterations: <br />
</p>

<dl>
<dt><code>$Test</code></dt><dd><p>the name of the used test statistic.</p>
</dd>
<dt><code>$T.value</code></dt><dd><p>the value of the test statistic.</p>
</dd>
<dt><code>$p.value</code></dt><dd><p>the approximated p value.</p>
</dd>
<dt><code>$par.est</code></dt><dd><p>the estimated parameters.</p>
</dd>
<dt><code>$boot.run</code></dt><dd><p>number of bootstrap iterations.</p>
</dd>
</dl>



<h3>References</h3>

<p>Allison, J.S., Betsch, S., Ebner, B., Visagie, I.J.H. (2019) &quot;New weighted <code class="reqn">L^2</code>-type tests for the inverse Gaussian distribution&quot;, arXiv:1910.14119. <a href="https://arxiv.org/abs/1910.14119">LINK</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test.KS(rmutil::rinvgauss(20,2,1),B=100)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
