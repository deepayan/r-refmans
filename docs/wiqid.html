<!DOCTYPE html><html><head><title>Help for package wiqid</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {wiqid}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#wiqid-package'>
<p>Fast, simple estimation functions for wildlife population models</p></a></li>
<li><a href='#AICc'>
<p>Akaike's Information Criterion with small-sample correction - AICc</p></a></li>
<li><a href='#AICtable'>
<p>Make a table for AIC or other criterion</p></a></li>
<li><a href='#allCombinations'>
<p>Create formulae for all combinations of covariates</p></a></li>
<li><a href='#Bayesian binomial analysis'>
<p>Bayesian analysis of binomial data</p></a></li>
<li><a href='#Bayesian normal estimation'>
<p>Bayesian modelling of a normal (Gaussian) distribution</p></a></li>
<li><a href='#Bayesian Occupancy Single Season'>
<p>Bayesian single-season occupancy modelling</p></a></li>
<li><a href='#Bayesian Poisson analysis'>
<p>Bayesian analysis of count data</p></a></li>
<li><a href='#Bayesian SCR'>
<p>Spatially explicit capture-recapture (secr) density estimation using MCMC</p></a></li>
<li><a href='#BetaDist'>
<p>The Beta Distribution</p></a></li>
<li><a href='#Bwiqid-class'>
<p>Conversion to class Bwiqid (deprecated)</p></a></li>
<li><a href='#Closed Captures'>
<p>Analysis of mark-recapture data for closed populations</p></a></li>
<li><a href='#deprecated'>
<p>Deprecated functions in package wiqid</p></a></li>
<li><a href='#dippers'>
<p>Capture-recapture data for European dippers</p></a></li>
<li><a href='#Distance Measures'>
<p>Plug-in distance-measure functions for <code>distShell</code>.</p></a></li>
<li><a href='#distShell'>
<p>Distance Matrix Computation</p></a></li>
<li><a href='#distTestData'>
<p>An artificial data set to test distance/dissimilarity measures</p></a></li>
<li><a href='#Diversity indices'>
<p>Biodiversity indices</p></a></li>
<li><a href='#GammaDist'>
<p>The Gamma Distribution</p></a></li>
<li><a href='#getMCerror'>
<p>MCMC error using the batch method (deprecated)</p></a></li>
<li><a href='#GrandSkinks'>
<p>Multi-season detection data for grand skinks</p></a></li>
<li><a href='#KanhaTigers'>
<p>Capture history matrix for camera-trapped tigers</p></a></li>
<li><a href='#KillarneyBirds'>
<p>Abundance of woodland birds</p></a></li>
<li><a href='#Links'><p> Logit and probit links for generalised linear modelling</p></a></li>
<li><a href='#MeadowVoles'>
<p>Robust design mark-recapture data for meadow voles</p></a></li>
<li><a href='#occ2sps'>
<p>Single-season two-species occupancy estimation</p></a></li>
<li><a href='#Occupancy Multi-Season'>
<p>Multi-season occupancy estimation</p></a></li>
<li><a href='#Occupancy Single Season'>
<p>Single-season occupancy estimation</p></a></li>
<li><a href='#plot.Bwiqid'>
<p>Plot method for objects of class 'Bwiqid'</p></a></li>
<li><a href='#plotACs'>
<p>Plot Activity Centres from <code>Bsecr0</code> output</p></a></li>
<li><a href='#plotComb'>
<p>Display a posterior probability distribution from the comb method</p></a></li>
<li><a href='#predict.wiqid'>
<p>Predict method for objects of class 'wiqid'</p></a></li>
<li><a href='#predictAvg'>
<p>Predict average values from multiple fitted models</p></a></li>
<li><a href='#print.Bwiqid'>
<p>Print and summary methods for objects of class 'Bwiqid'</p></a></li>
<li><a href='#Priors'><p> Standardisation and priors</p></a></li>
<li><a href='#railSims'>
<p>Simulated detection/non-detection data for two species of rails</p></a></li>
<li><a href='#richCurve'>
<p>Species richness estimates based on accumulation curves</p></a></li>
<li><a href='#richRarefy'>
<p>Sample-based rarefaction curves</p></a></li>
<li><a href='#Royle-Nichols occupancy model'>
<p>Royle-Nichols model for single-season occupancy estimation</p></a></li>
<li><a href='#salamanders'>
<p>Occupancy data for blue ridge salamanders</p></a></li>
<li><a href='#secrFit'>
<p>Spatially Explicit Capture-Recapture</p></a></li>
<li><a href='#seedbank'>
<p>Seed abundances in soil samples</p></a></li>
<li><a href='#showShinyApp'>
<p>Display a 'shiny' application</p></a></li>
<li><a href='#simpleRhat'>
<p>The Brooks-Gelman-Rubin (BGR) convergence diagnostic (deprecated)</p></a></li>
<li><a href='#Species richness estimators'>
<p>Species richness estimators</p></a></li>
<li><a href='#standardize'>
<p>Scaling and centring of vectors, matrices and arrays</p></a></li>
<li><a href='#Survival (CJS)'>
<p>Survival from recapture data with Cormack-Jolly-Seber (CJS) model</p></a></li>
<li><a href='#Survival (RD)'>
<p>Survival from mark-recapture data with robust design</p></a></li>
<li><a href='#TDist'>
<p>The Generalized Student's t Distribution</p></a></li>
<li><a href='#Temburong'>
<p>Tree species count data</p></a></li>
<li><a href='#toves'>
<p>Simulated detection/non-detection data for a fictitious species</p></a></li>
<li><a href='#WAIC'>
<p>Extract the Watanabe-Akaike Information Criterion (WAIC)</p></a></li>
<li><a href='#weta'>
<p>Detection data for weta in gorse bushes</p></a></li>
<li><a href='#wiqid-class'><p> The 'wiqid' S3 class</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Quick and Dirty Estimates for Wildlife Populations</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-11-16</td>
</tr>
<tr>
<td>Depends:</td>
<td>HDInterval, R (&ge; 2.10), mcmcOutput</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, truncnorm, MASS, coda, plotrix</td>
</tr>
<tr>
<td>Suggests:</td>
<td>secr (&ge; 3.0), shiny, rjags</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/mikemeredith/wiqid/issues">https://github.com/mikemeredith/wiqid/issues</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://mmeredith.net/R/wiqid/">https://mmeredith.net/R/wiqid/</a></td>
</tr>
<tr>
<td>Description:</td>
<td>Provides simple, fast functions for maximum likelihood and Bayesian estimates of wildlife population parameters, suitable for use with simulated data or bootstraps. Early versions were indeed quick and dirty, but optional error-checking routines and meaningful error messages have been added. Includes single and multi-season occupancy, closed capture population estimation, survival, species richness and distance measures.</td>
</tr>
<tr>
<td>Language:</td>
<td>en-GB</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-11-16 10:11:22 UTC; User</td>
</tr>
<tr>
<td>Author:</td>
<td>Ngumbang Juat [cre],
  Mike Meredith [aut],
  Jason Bryer [ctb] (showShinyApp),
  John Kruschke [ctb],
  Brian Neelon [ctb] (Bnormal),
  Michael Schaub [ctb] (ch2mArray),
  R Core Team [ctb] (stats::AIC code adapted for AICc)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ngumbang Juat &lt;ngumbangjuat@hotmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-11-17 17:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='wiqid-package'>
Fast, simple estimation functions for wildlife population models
</h2><span id='topic+wiqid-package'></span><span id='topic+wiqid'></span>

<h3>Description</h3>

<p>Quick and dirty functions to estimate occupancy, survival, abundance, species richness and diversity, etc. for wildlife populations.
</p>


<h3>Details</h3>

<p>There are a number of sophisticated programs for the analysis of wildlife data, producing estimates of occupancy, survival, abundance, or density. <span class="pkg">wiqid</span> began as a collection of fast, bare-bones functions which can be run from R suitable for use when you are generating hundreds of simulated data sets. The package takes its name from the quick-and-dirty nature of the original functions.
</p>
<p>We now use <span class="pkg">wiqid</span> in basic wildlife study design and data analysis workshops, and most functions now have options to check the input data and give informative error messages. Workshop participants have used <code>lm</code>, <code>glm</code> and functions in the <code>secr</code> and <code>BEST</code> packages. So  <span class="pkg">wiqid</span> tries to match the look and feel of these functions.
</p>
<p>All functions use standard data frames or matrices for data input. ML estimation functions return objects of class <code>wiqid</code> with parameter estimates on the transformed scale (usually logit functions), variance-covariance matrix, and back-transformed &lsquo;real&rsquo; values; there are <code>print</code>, <code>logLik</code> and <code>predict</code> methods. Bayesian functions (distinguished by an initial &quot;B&quot;) return class <code>mcmcOutput</code> objects.
</p>
<p>Simulations and bootstraps often generate weird data sets, eg. capture histories with no captures. These functions do not throw errors or give warnings if the data are weird, but return NAs if estimates cannot be calculated. Errors may still occur if the data are impossible, eg. 6 detections in 5 occasions.
</p>
<p>Note that in version 0.2.0 the scaling of continuous covariates has changed to SD=1 (previously SD=0.5). This means that beta coefficients will now be exactly half the size, matching the output from other software.
</p>
<p>The functions are listed by topic below.
</p>


<h3>SIMPLE BAYESIAN POSTERIORS</h3>


<table>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+Bbinomial">Bbinomial</a></code> </td><td style="text-align: left;"> generate draws from a conjugate beta posterior distribution </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+Bpoisson">Bpoisson</a></code> </td><td style="text-align: left;"> generate draws from a conjugate gamma posterior distribution </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+Bnormal">Bnormal</a></code> </td><td style="text-align: left;"> fit a basic normal model to data </td>
</tr>

</table>



<h3>OCCUPANCY</h3>

<p><b>Single-season occupancy</b>
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+occSS">occSS</a></code> </td><td style="text-align: left;"> general-purpose ML function; allows site- and survey-specific covariates </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+BoccSS">BoccSS</a></code> </td><td style="text-align: left;"> general-purpose Bayesian implementation of the above </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+occSS0">occSS0</a></code> </td><td style="text-align: left;"> a basic psi(.) p(.) model, faster if this is all you need </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+BoccSS0">BoccSS0</a></code> </td><td style="text-align: left;"> a Bayesian implementation of the psi(.) p(.) model </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+occSSrn">occSSrn</a></code> </td><td style="text-align: left;"> Royle-Nichols method </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+occSStime">occSStime</a></code> </td><td style="text-align: left;"> faster if you have only time effects, also does a plot </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+occSScovSite">occSScovSite</a></code> </td><td style="text-align: left;"> faster if you only have site-specific covariates </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+occ2sps">occ2sps</a></code> </td><td style="text-align: left;"> single-season two-species models   </td>
</tr>

</table>

<p><b>Multi-season occupancy</b>
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+occMS">occMS</a></code> </td><td style="text-align: left;"> general-purpose function; parameters depend on covariates; slow </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+occMScovSite">occMScovSite</a></code> </td><td style="text-align: left;"> smaller range of covariate options </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+occMS0">occMS0</a></code> </td><td style="text-align: left;"> a simple multi-season model with four parameters; faster </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+occMStime">occMStime</a></code> </td><td style="text-align: left;"> parameters vary by season; faster  </td>
</tr>

</table>



<h3>DENSITY from spatial capture-recapture data</h3>

<p>We use the <span class="pkg">secr</span> package for ML estimation of density. For Bayesian estimation, <span class="pkg">wiqid</span> offers:
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+Bsecr0">Bsecr0</a></code> </td><td style="text-align: left;"> a Bayesian implementation of the intercept-only model </td>
</tr>

</table>



<h3>ABUNDANCE from closed-population capture-recapture data</h3>

<p>Although data for genuinely closed populations are rare, this is an important conceptual stepping-stone from CJS models to robust models for survival.
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+closedCapM0">closedCapM0</a></code> </td><td style="text-align: left;"> simple model with constant capture probability </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+closedCapMb">closedCapMb</a></code> </td><td style="text-align: left;"> permanent behavioural response to first capture </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+closedCapMt">closedCapMt</a></code> </td><td style="text-align: left;"> capture probability varies with time </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+closedCapMtcov">closedCapMtcov</a></code> </td><td style="text-align: left;"> allows for time-varying covariates </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+closedCapMh2">closedCapMh2</a></code> </td><td style="text-align: left;"> heterogeneity with 2-mixture model </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+closedCapMhJK">closedCapMhJK</a></code> </td><td style="text-align: left;"> jackknife estimator for heterogeneity  </td>
</tr>

</table>



<h3>SURVIVAL from capture-recapture data</h3>

<p><b>Cormack-Jolly-Seber models</b>
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+survCJS">survCJS</a></code> </td><td style="text-align: left;"> model with time-varying covariates </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+BsurvCJS">BsurvCJS</a></code> </td><td style="text-align: left;"> a Bayesian implementation of the above </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+survCJSaj">survCJSaj</a></code> </td><td style="text-align: left;"> allows for different survival for adults and juveniles </td>
</tr>

</table>

<p><b>Pollock's robust design</b>
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+survRDah">survRDah</a></code> </td><td style="text-align: left;"> 2-stage estimation of survival and recruitment </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+survRD">survRD</a></code> </td><td style="text-align: left;"> single stage maximum likelihood estimation </td>
</tr>

</table>

<p>Note that the RD functions are preliminary attempts at coding these models and have not been fully tested or benchmarked.
</p>


<h3>SPECIES RICHNESS from species x sample matrices</h3>

<p><b>Rarefaction</b>
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+richRarefy">richRarefy</a></code> </td><td style="text-align: left;"> Mao's tau estimator for rarefaction </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+richCurve">richCurve</a></code> </td><td style="text-align: left;"> a shell for plug-in estimators, for example... </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+richSobs">richSobs</a></code> </td><td style="text-align: left;"> the number of species observed </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+richSingle">richSingle</a></code> </td><td style="text-align: left;"> the number of singletons observed </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+richDouble">richDouble</a></code> </td><td style="text-align: left;"> the number of doubletons observed </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+richUnique">richUnique</a></code> </td><td style="text-align: left;"> the number of uniques observed </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+richDuplicate">richDuplicate</a></code> </td><td style="text-align: left;"> the number of duplicates observed </td>
</tr>

</table>

<p><b>Coverage estimators</b>
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+richACE">richACE</a></code> </td><td style="text-align: left;"> Chao's Abundance-based Coverage Estimator </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+richICE">richICE</a></code> </td><td style="text-align: left;"> Chao's Incidence-based Coverage Estimator </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+richChao1">richChao1</a></code> </td><td style="text-align: left;"> Chao1 estimator </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+richChao2">richChao2</a></code> </td><td style="text-align: left;"> Chao2 estimator </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+richJack1">richJack1</a></code> </td><td style="text-align: left;"> first-order jackknife estimator </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+richJack2">richJack2</a></code> </td><td style="text-align: left;"> second-order jackknife estimator </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+richJackA1">richJackA1</a></code> </td><td style="text-align: left;"> abundance-based first-order jackknife estimator </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+richJackA2">richJackA2</a></code> </td><td style="text-align: left;"> abundance-based second-order jackknife estimator </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+richBoot">richBoot</a></code> </td><td style="text-align: left;"> bootstrap estimator </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+richMM">richMM</a></code> </td><td style="text-align: left;"> Michaelis-Menten estimator </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+richRenLau">richRenLau</a></code> </td><td style="text-align: left;"> Rennolls and Laumonier's estimator  </td>
</tr>

</table>



<h3>BIODIVERSITY INDICES</h3>

<p><b>Alpha diversity</b>
</p>
<p>All of these functions express diversity as the number of common species in the assemblage.
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+biodSimpson">biodSimpson</a></code> </td><td style="text-align: left;"> inverse of Simpson's index of dominance </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+biodShannon">biodShannon</a></code> </td><td style="text-align: left;"> exponential form of Shannon's entropy </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+biodBerger">biodBerger</a></code> </td><td style="text-align: left;"> inverse of Berger and Parker's index of dominance </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+biodBrillouin">biodBrillouin</a></code> </td><td style="text-align: left;"> exponential form of Brillouin's index </td>
</tr>

</table>

<p><b>Beta diversity / distance</b>
</p>
<p>All of these functions produce distance measures (not similarity) on a scale of 0 to 1. The function <code><a href="#topic+distShell">distShell</a></code> provides a wrapper to produce a matrix of distance measures across a number of sites.
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+distBrayCurtis">distBrayCurtis</a></code> </td><td style="text-align: left;"> complement of Bray-Curtis index, aka 'quantitative Sorensen' </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+distChaoJaccCorr">distChaoJaccCorr</a></code> </td><td style="text-align: left;"> complement of Chao's Jaccard corrected index </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+distChaoJaccNaive">distChaoJaccNaive</a></code> </td><td style="text-align: left;"> complement of Chao's Jaccard naive index </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+distChaoSorCorr">distChaoSorCorr</a></code> </td><td style="text-align: left;"> complement of Chao's Sorensen corrected index </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+distChaoSorNaive">distChaoSorNaive</a></code> </td><td style="text-align: left;"> complement of Chao's Sorensen naive index </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+distChord">distChord</a></code> </td><td style="text-align: left;"> distance between points on a normalised sphere </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+distJaccard">distJaccard</a></code> </td><td style="text-align: left;"> complement of Jaccard's index of similarity </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+distMorisitaHorn">distMorisitaHorn</a></code> </td><td style="text-align: left;"> complement of the Morisita-Horn index of similarity </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+distOchiai">distOchiai</a></code> </td><td style="text-align: left;"> complement of the Ochiai coefficient of similarity </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+distPreston">distPreston</a></code> </td><td style="text-align: left;"> Preston's coefficient of faunal dissimilarity </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+distRogersTanimoto">distRogersTanimoto</a></code> </td><td style="text-align: left;"> complement of the Rogers and Tanimoto's coefficient of similarity </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+distSimRatio">distSimRatio</a></code> </td><td style="text-align: left;"> complement of the similarity ratio </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+distSorensen">distSorensen</a></code> </td><td style="text-align: left;"> complement of the Sorensen or Dice index of similarity </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+distWhittaker">distWhittaker</a></code> </td><td style="text-align: left;"> Whittaker's index of association </td>
</tr>

</table>



<h3>DATA SETS</h3>


<table>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+dippers">dippers</a></code> </td><td style="text-align: left;"> Capture-recapture data for European dippers </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+distTestData">distTestData</a></code> </td><td style="text-align: left;"> artificial data set for distance measures </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+GrandSkinks">GrandSkinks</a></code> </td><td style="text-align: left;"> multi-season occupancy data </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+KanhaTigers">KanhaTigers</a></code> </td><td style="text-align: left;"> camera-trap data for tigers </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+KillarneyBirds">KillarneyBirds</a></code> </td><td style="text-align: left;"> abundance of birds in Irish woodlands </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+MeadowVoles">MeadowVoles</a></code> </td><td style="text-align: left;"> mark-recapture data from a robust design study </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+railSims">railSims</a></code> </td><td style="text-align: left;"> simulated detection/non-detection data for two species of rails </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+salamanders">salamanders</a></code> </td><td style="text-align: left;"> detection/non-detection data for salamanders </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+seedbank">seedbank</a></code> </td><td style="text-align: left;"> number of seeds germinating from samples of soil </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+Temburong">Temburong</a></code> </td><td style="text-align: left;"> counts of tree species in a 1ha plot in Brunei </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+TemburongBA">TemburongBA</a></code> </td><td style="text-align: left;"> basal area of tree species in a 1ha plot in Brunei </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+weta">weta</a></code> </td><td style="text-align: left;"> detection/non-detection data and covariates for weta </td>
</tr>

</table>



<h3>DISTRIBUTIONS</h3>

<p>These are convenience wrappers for the related d/p/q/r functions in the <code>stats</code> package which allow for parameterisation with mean and sd or (for Beta) mode and concentration.
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+dbeta2">dbeta2</a> etc</code> </td><td style="text-align: left;"> Beta distribution with mean and sd </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+dbeta3">dbeta3</a> etc</code> </td><td style="text-align: left;"> Beta distribution with mode and concentration </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+dgamma2">dgamma2</a> etc</code> </td><td style="text-align: left;"> Gamma distribution with mean and sd </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+dt2">dt2</a> etc</code> </td><td style="text-align: left;"> t-distribution with location, scale and df parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+dt3">dt3</a> etc</code> </td><td style="text-align: left;"> t-distribution with mean, sd and df parameters
  </td>
</tr>

</table>



<h3>UTILITY FUNCTIONS</h3>


<table>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+AICc">AICc</a></code> </td><td style="text-align: left;"> AIC with small-sample correction </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+AICtable">AICtable</a></code> </td><td style="text-align: left;"> tabulate AIC for several models </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+allCombinations">allCombinations</a></code> </td><td style="text-align: left;"> model formulae for combinations of covariates </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+standardize">standardize</a></code> </td><td style="text-align: left;"> a simple alternative to <code><a href="base.html#topic+scale">scale</a></code>.
  </td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Mike Meredith
</p>

<hr>
<h2 id='AICc'>
Akaike's Information Criterion with small-sample correction - AICc
</h2><span id='topic+AICc'></span>

<h3>Description</h3>

<p>Akaike's Information Criterion with small-sample correction - AICc
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AICc(object, ..., nobs, df)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AICc_+3A_object">object</code></td>
<td>

<p>a fitted model object for which there exists a logLik method to extract the corresponding log-likelihood, number of parameters, and number of observations.
</p>
</td></tr>
<tr><td><code id="AICc_+3A_...">...</code></td>
<td>

<p>optionally more fitted model objects.
</p>
</td></tr>
<tr><td><code id="AICc_+3A_nobs">nobs</code></td>
<td>

<p>scalar; the value to use for the effective sample size; overrides the value contained in the model object(s).
</p>
</td></tr>
<tr><td><code id="AICc_+3A_df">df</code></td>
<td>

<p>the value to use for the number of parameters; usually a vector of length = number of models; non-NA elements override the value contained in the corresponding model object.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>AICc is Akaike's information Criterion (AIC) with a small sample correction. It is </p>
<p style="text-align: center;"><code class="reqn">AICc = AIC + 2K(K + 1) / (n - K - 1)</code>
</p>
<p> where <em>K</em> is the number of parameters and <em>n</em> is the number of observations.
</p>
<p>This is an S3 generic, with a default method which calls <code><a href="stats.html#topic+logLik">logLik</a></code>, and should work with any class that has a <code>logLik</code> method.
</p>


<h3>Value</h3>

<p>If just one object is provided, the corresponding AICc.
</p>
<p>If multiple objects are provided, a data frame with rows corresponding to the objects and columns representing the number of parameters in the model (df) and the AICc.
</p>
<p>The result will be <code>Inf</code> for over-parameterised models, ie. when <code>df &gt;= nobs - 1</code>.
</p>


<h3>Note</h3>

<p>For some data types, including occupancy data, there is debate on the appropriate effective sample size to use.
</p>


<h3>Author(s)</h3>

<p>Essentially the same as <code><a href="stats.html#topic+AIC">AIC</a></code> in package <code>stats</code>. Modified to return AICc by Mike Meredith.
</p>


<h3>References</h3>

<p>Burnham, K P; D R Anderson 2002. <em>Model selection and multimodel inference: a practical information-theoretic approach</em>. Springer-Verlag.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+AIC">AIC</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Occupancy models
data(salamanders)
mt &lt;- occSStime(salamanders, p ~ .time, plot=FALSE)
mT &lt;- occSStime(salamanders, p ~ .Time, plot=FALSE)
AIC(mt, mT)
AICc(mt, mT)
# The default sample size = the number of sites
nobs(mt) == nrow(salamanders)
# It is sometimes taken to be the total number of surveys...
AICc(mt, mT, nobs=length(salamanders))
# ... or the minimum of ...
n &lt;- min(sum(rowSums(salamanders) &gt; 0), # sites where species was detected
         sum(rowSums(salamanders) == 0)) # sites where species was not detected
AICc(mt, mT, nobs=n)

# Survival models
data(dippers)
DH &lt;- dippers[1:7]  # Extract the detection histories
null &lt;- survCJS(DH)  # the phi(.) p(.) model
phit &lt;- survCJS(DH, phi ~ .time)  # the phi(t) p(.) model
full &lt;- survCJS(DH, list(phi ~ .time, p ~ .time))  # the phi(t) p(t) model
AICc(null, phit, full)
# for the full model, all 12 parameters cannot be estimated;
#   we can manually set df=11 for this model:
AICc(null, phit, full, df=c(NA, NA, 11))
</code></pre>

<hr>
<h2 id='AICtable'>
Make a table for AIC or other criterion
</h2><span id='topic+AICtable'></span>

<h3>Description</h3>

<p>Takes the output from a call to AIC or AICc returns a data frame with model likelihoods and model weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AICtable(x, digits=3, sort)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AICtable_+3A_x">x</code></td>
<td>

<p>A data frame with the second column being AIC-type values, as returned by <code>AIC</code> or <code>AICc</code>.
</p>
</td></tr>
<tr><td><code id="AICtable_+3A_digits">digits</code></td>
<td>

<p>integer indicating the number of decimal places to retain.
</p>
</td></tr>
<tr><td><code id="AICtable_+3A_sort">sort</code></td>
<td>

<p>logical indicating whether the table should be sorted by AIC; if missing, the rows are sorted if the table has row names.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the original data frame with the following extra columns
</p>
<table>
<tr><td><code>Delta</code></td>
<td>
<p>The difference between each value in x and min(x)</p>
</td></tr>
<tr><td><code>ModelLik</code></td>
<td>
<p>The model likelihood</p>
</td></tr>
<tr><td><code>ModelWt</code></td>
<td>
<p>The model weight</p>
</td></tr>
</table>
<p>If sort = TRUE, the rows will be sorted by increasing values of AIC/AICc.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith
</p>


<h3>References</h3>

<p>Burnham and Anderson (2002) <em>Model selection and multimodel inference: a practical information-theoretic approach</em>, 2 edn. Springer-Verlag.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(KanhaTigers)
mods &lt;- NULL
mods$M0 &lt;- closedCapM0(KanhaTigers)
mods$Mh2 &lt;- closedCapMh2(KanhaTigers)
mods$MhJK &lt;- closedCapMhJK(KanhaTigers)
mods$Mt &lt;- closedCapMt(KanhaTigers)
AICc &lt;- sapply(mods, AICc)
AICtable(AICc)
# MhJK does not use likelihood maximisation
</code></pre>

<hr>
<h2 id='allCombinations'>
Create formulae for all combinations of covariates
</h2><span id='topic+allCombinations'></span>

<h3>Description</h3>

<p>Create formulae for all combinations of covariates, currently main effects only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>allCombinations(response = "", covars, formulae = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="allCombinations_+3A_response">response</code></td>
<td>

<p>a character vector of length 1 specifying the response variable.
</p>
</td></tr>
<tr><td><code id="allCombinations_+3A_covars">covars</code></td>
<td>

<p>a character vector specifying the covariates/predictors.
</p>
</td></tr>
<tr><td><code id="allCombinations_+3A_formulae">formulae</code></td>
<td>

<p>if TRUE, only the formulae are returned; otherwise a TRUE/FALSE matrix is returned, with the formulae as row names.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>formulae = TRUE</code>, returns a character vector with elements corresponding to the formulae for all possible combinations of main effects.
</p>
<p>Otherwise, returns a TRUE/FALSE matrix indicating which covariates are included in each model with the model formulae as the row names.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith
</p>


<h3>Examples</h3>

<pre><code class='language-R'>longNames &lt;- colnames(swiss)
# these would produce formulae too long for the console.
names(swiss) &lt;- abbreviate(longNames)
vars &lt;- colnames(swiss)
vars

# Get the formulae for all combinations of covars:
formulae &lt;- allCombinations(vars[1], vars[-1])
formulae[1:10]

# Run all the models with 'lm', put results into a list:
# lms &lt;- lapply(formulae, lm, data=swiss) # This works, but the call is a mess!
lms &lt;- vector('list', 32)
for(i in 1:32)
  lms[[i]] &lt;- lm(formulae[i], data=swiss)
names(lms) &lt;- formulae

# Extract AICs and look at top model:
AICs &lt;- sapply(lms, AIC)
head(sort(AICs))
lms[[which.min(AICs)]]

# Do a nice table of results:
DeltaAIC &lt;- AICs - min(AICs)
AICllh &lt;- exp(-DeltaAIC/2)
AICwt &lt;- AICllh / sum(AICllh)
order &lt;- order(AICs)
head(round(cbind(AIC=AICs, DeltaAIC, AICllh, AICwt)[order, ], 3))

# Get AIC weights for each of the covars:
is.in &lt;- allCombinations(vars[1], vars[-1], form=FALSE)
head(is.in)   # shows which covars are in each model
covarWts &lt;- AICwt %*% is.in
round(sort(covarWts[1, ], dec=TRUE), 3)
  # the [1, ] is needed because %*% returns a 1-row matrix; 'sort' will coerce
  #   that to a vector but strips out the names in the process.
</code></pre>

<hr>
<h2 id='Bayesian+20binomial+20analysis'>
Bayesian analysis of binomial data
</h2><span id='topic+Bbinom'></span><span id='topic+Bbinomial'></span>

<h3>Description</h3>

<p>Draws random values from the posterior for a binomial likelihood and beta prior. <code>Bbinom</code> is deprecated and will be removed in the next version; use <code>Bbinomial</code> instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Bbinom(...)
Bbinomial(y, n, priors=NULL, draws=100000, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Bayesian+2B20binomial+2B20analysis_+3A_y">y</code></td>
<td>

<p>the number of successes
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20binomial+2B20analysis_+3A_n">n</code></td>
<td>

<p>the number of trials
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20binomial+2B20analysis_+3A_priors">priors</code></td>
<td>

<p>an optional list with elements specifying the priors for the mode and concentration of the beta prior distribution; see Details.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20binomial+2B20analysis_+3A_draws">draws</code></td>
<td>

<p>the number of MCMC draws to be returned.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20binomial+2B20analysis_+3A_...">...</code></td>
<td>

<p>other arguments to pass to the function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function generates a vector of random draws from the posterior distribution of the probability of success. It uses conjugacy to determine the parameters of the posterior beta distribution, and draws independent values from this.
</p>
<p>A prior can be specified with the <code>priors</code> argument. A beta prior is used, specified by mode, <code>mode</code>, and concentration, <code>conc</code>.
</p>
<p>When <code>priors = NULL</code> (the default), a uniform prior corresponding to beta(1, 1) is used.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>mcmcOutput</code>.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate a sample from a binomial distribution, maybe the number of sites
#   where a species was detected:
n &lt;- 10  # number of trials (sites visited)
( y &lt;- rbinom(1, n, 0.75) ) # number of successes (sites where species detected)
Bbinomial(y, n)  # with uniform prior
Bbinomial(y, n, priors=list(mode=0.4, conc=5))  # with informative prior
</code></pre>

<hr>
<h2 id='Bayesian+20normal+20estimation'>
Bayesian modelling of a normal (Gaussian) distribution
</h2><span id='topic+Bnormal'></span><span id='topic+Bnormal2'></span>

<h3>Description</h3>

<p>Bayesian estimation of centre (<code class="reqn">\mu</code>) and scale (spread) (<code class="reqn">\sigma</code>) of a normal distribution based on a sample. <code>Bnormal</code> uses a gamma prior on the precision, <code class="reqn">\tau = 1/\sigma^2</code>, while <code>Bnormal2</code> applies a gamma prior to <code class="reqn">\sigma</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Bnormal(y, priors=NULL,
            chains=3, draws=10000, burnin=100, ...)

Bnormal2(y, priors=NULL,
            chains=3, draws=3e4, burnin=0, thin=1, adapt=1000,
            doPriorsOnly=FALSE, parallel=NULL, seed=NULL, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Bayesian+2B20normal+2B20estimation_+3A_y">y</code></td>
<td>

<p>a vector (length &gt; 1) with observed sample values; missing values not allowed.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20normal+2B20estimation_+3A_priors">priors</code></td>
<td>

<p>an optional list with elements specifying the priors for the centre and scale; see Details.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20normal+2B20estimation_+3A_dopriorsonly">doPriorsOnly</code></td>
<td>

<p>if TRUE, <code>Bnormal2</code> returns MCMC chains representing the prior distributions, <em>not</em> the posterior distributions for your data set.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20normal+2B20estimation_+3A_chains">chains</code></td>
<td>

<p>the number of MCMC chains to run.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20normal+2B20estimation_+3A_draws">draws</code></td>
<td>

<p>the number of MCMC draws per chain to be returned.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20normal+2B20estimation_+3A_thin">thin</code></td>
<td>

<p>thinning rate. If set to n &gt; 1, n steps of the MCMC chain are calculated for each one returned. This is useful if autocorrelation is high.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20normal+2B20estimation_+3A_burnin">burnin</code></td>
<td>

<p>number of steps to discard as burn-in at the beginning of each chain.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20normal+2B20estimation_+3A_adapt">adapt</code></td>
<td>

<p>number of steps for adaptation.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20normal+2B20estimation_+3A_seed">seed</code></td>
<td>

<p>a positive integer (or NULL): the seed for the random number generator, used to obtain reproducible output if required.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20normal+2B20estimation_+3A_parallel">parallel</code></td>
<td>

<p>if NULL or TRUE and &gt; 3 cores are available, the MCMC chains are run in parallel. (If TRUE and &lt; 4 cores are available, a warning is given.)
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20normal+2B20estimation_+3A_...">...</code></td>
<td>

<p>other arguments to pass to the function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function generates vectors of random draws from the posterior distributions of the population centre (<code class="reqn">\mu</code>) and scale (<code class="reqn">\sigma</code>). <code>Bnormal</code> uses a Gibbs sampler implemented in R, while <code>Bnormal2</code> uses JAGS (Plummer 2003).
</p>
<p>Priors for all parameters can be specified by including elements in the <code>priors</code> list. For both functions, <code class="reqn">\mu</code> has a normal prior, with mean <code>muMean</code> and standard deviation <code>muSD</code>. For <code>Bnormal</code>, a gamma prior is used for the precision, <code class="reqn">\tau = 1\\sigma^2</code>, with parameters specified by <code>tauShape</code> and <code>tauRate</code>. For <code>Bnormal2</code>, a gamma prior is placed on <code class="reqn">\sigma</code>, with parameters specified by mode, <code>sigmaMode</code>, and SD, <code>sigmaSD</code>.
</p>
<p>When <code>priors = NULL</code> (the default), <code>Bnormal</code> uses improper flat priors for both <code class="reqn">\mu</code> and <code class="reqn">\tau</code>, while <code>Bnormal2</code> uses a broad normal prior (muMean = mean(y), muSD = sd(y)*5) for <code class="reqn">\mu</code> and a uniform prior on (sd(y) / 1000, sd(y) * 1000) for <code class="reqn">\sigma</code>.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>mcmcOutput</code>.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith, <code>Bnormal</code> based on code by Brian Neelon, <code>Bnormal2</code> adapted from code by John Kruschke.
</p>


<h3>References</h3>

<p>Kruschke, J K. 2013. Bayesian estimation supersedes the <em>t</em> test. <em>Journal of Experimental Psychology: General</em> 142(2):573-603. doi: 10.1037/a0029146
</p>
<p>Plummer, Martyn (2003). JAGS: A Program for Analysis of Bayesian Graphical Models Using Gibbs Sampling, <em>Proceedings of the 3rd International Workshop on Distributed Statistical Computing (DSC 2003)</em>, March 20-22, Vienna, Austria. ISSN 1609-395X
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate a sample from a normal distribution, maybe the head-body length of a
#   carnivore in mm:
HB &lt;- rnorm(10, 900, 15)
Bnormal(HB)  # with improper flat priors for mu and tau
Bnormal(HB, priors=list(muMean=1000, muSD=200))
Bnormal(HB, priors=list(muMean=1, muSD=0.2)) # a silly prior produces a warning.

if(requireNamespace("rjags")) {
  Bnormal2(HB, chains=2)  # with broad normal prior for mu, uniform for sigma
  Bnormal2(HB, chains=2, priors=list(muMean=1000, muSD=200, sigmaMode=20, sigmaSD=10))
}
</code></pre>

<hr>
<h2 id='Bayesian+20Occupancy+20Single+20Season'>
Bayesian single-season occupancy modelling
</h2><span id='topic+BoccSS'></span><span id='topic+BoccSS0'></span>

<h3>Description</h3>

<p>Functions to estimate occupancy from detection/non-detection data for a single season using a Gibbs sampler coded in R or JAGS.
</p>
<p><code>BoccSS0</code> runs a model in R without covariates, and allows priors to be specified as beta distributions for probability of occupancy and probability of detection.
</p>
<p><code>BoccSS</code> runs a model in R allowing for covariates, using a probit link and conjugate normal priors, which can be specified as mean and covariance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BoccSS0(y, n, psiPrior=c(1,1), pPrior=c(1,1),
                    chains=3, draws=30000, burnin=100, ...)

BoccSS(DH, model=NULL, data=NULL, priors=list(),
                    chains=3, draws=30000, burnin=1000, thin=1, parallel,
                    seed=NULL, doWAIC=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Bayesian+2B20Occupancy+2B20Single+2B20Season_+3A_y">y</code></td>
<td>

<p>a vector with the number of detections at each site; or a 1/0/NA matrix (or data frame) of detection histories, sites x occasions.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20Occupancy+2B20Single+2B20Season_+3A_n">n</code></td>
<td>

<p>a scalar or vector with the number of visits (survey occasions) at each site; ignored if <code>y</code> is a matrix or data frame.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20Occupancy+2B20Single+2B20Season_+3A_psiprior">psiPrior</code>, <code id="Bayesian+2B20Occupancy+2B20Single+2B20Season_+3A_pprior">pPrior</code></td>
<td>

<p>parameters for beta distributions to be used as priors for psi and p.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20Occupancy+2B20Single+2B20Season_+3A_dh">DH</code></td>
<td>

<p>a 1/0/NA matrix (or data frame) of detection histories, sites x occasions.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20Occupancy+2B20Single+2B20Season_+3A_model">model</code></td>
<td>

<p>a list of formulae symbolically defining a linear predictor for each parameter in terms of covariates. If NULL, an intercept-only model is used, ie, psi(.) p(.).
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20Occupancy+2B20Single+2B20Season_+3A_data">data</code></td>
<td>

<p>a data frame containing the variables in the model. For <code>occSStime</code>, a data frame with a row for each survey occasion; otherwise, a row for each site. Each site covariate has one column. Each survey covariate has one column for each occasion, and the column name must end with the occasion number (without leading zeros); eg, <code>Cov1, Cov2, ..., Cov15</code>. All covariates should be included in <code>data</code>, otherwise they will be sought in enclosing environments, which may not produce what you want &ndash; and they won't be standardised.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20Occupancy+2B20Single+2B20Season_+3A_priors">priors</code></td>
<td>

<p>a list with elements for prior mean and variance for coefficients; see Details. If NULL, improper flat priors are used.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20Occupancy+2B20Single+2B20Season_+3A_chains">chains</code></td>
<td>

<p>number of MCMC chains to run.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20Occupancy+2B20Single+2B20Season_+3A_draws">draws</code></td>
<td>

<p>minimum number of values to return. The actual number will be a multiple of the number of chains.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20Occupancy+2B20Single+2B20Season_+3A_burnin">burnin</code></td>
<td>

<p>number of iterations per chain to discard as burn-in.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20Occupancy+2B20Single+2B20Season_+3A_thin">thin</code></td>
<td>

<p>the thinning interval between consecutive values in the chain.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20Occupancy+2B20Single+2B20Season_+3A_parallel">parallel</code></td>
<td>

<p>logical; if TRUE <em>and</em> <code>n.chains</code> &gt; 1 <em>and</em> available cores (as returned by <code>parallel::detectCores</code>) &gt; 2, chains will be run in parallel. If missing, chains will be run in parallel if <code>n.chains</code> &lt; available cores.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20Occupancy+2B20Single+2B20Season_+3A_dowaic">doWAIC</code></td>
<td>

<p>logical; if TRUE, the Watanabe-Akaike Information Criterion is calculated. NOTE: THIS FEATURE IS STILL EXPERIMENTAL.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20Occupancy+2B20Single+2B20Season_+3A_seed">seed</code></td>
<td>

<p>for reproducible results; note that parallel and sequential methods use different random number generators, so will give different results with the same seed.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20Occupancy+2B20Single+2B20Season_+3A_...">...</code></td>
<td>

<p>other arguments to pass to the function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>BoccSS0</code> implements a simple model with one parameter for probability of occupancy and one for probability of detection, ie. a <code>psi(.) p(.)</code> model, using a Gibbs sampler implemented in R.
</p>
<p>Independent beta distributions are used as priors for <code>BoccSS0</code>, as specified by <code>psiPrior</code> and <code>pPrior</code>. The defaults, <code>c(1, 1)</code>, correspond to uniform priors on the probabilities of occupancy and detection.
</p>
<p><code>BoccSS</code> uses a probit link to model occupancy and detection as a function of site covariates or survey covariates, as specified by <code>model</code>(Dorazio and Rodriguez 2011). It includes a built in <code>.time</code> covariate which can be used for modelling p with time as a fixed effect, and <code>.Time, .Time2, .Time3</code> for a linear, quadratic or cubic trend. A built-in <code>.b</code> covariate corresponds to a behavioural effect, where detection depends on whether the species was detected on the previous occasion or not.
</p>
<p>Note that most software uses a logistic (logit) link; see <a href="#topic+Links">Links</a>.
Coefficients on the probit scale are about half the size of the equivalent on the logit scale.
</p>
<p>Priors for <code>BoccSS</code> are listed in the <code>priors</code> argument, which may contain elements:
</p>
<p><code>muPsi</code> and <code>muP</code> : the means for occupancy and detection coefficients respectively. This may be a vector with one value for each coefficient, including the intercept, or a scalar, which will be used for all. The default is 0.
</p>
<p><code>sigmaPsi</code> and <code>sigmaP</code> : the (co)variance for occupancy and detection coefficients respectively. This may be (1) a vector with one value for each coefficient, including the intercept, which represents the variance, assuming independence, or (2) a scalar, which will be used for all, or (3) a variance-covariance matrix. The default is 1, which for a probit link and standardized covariates is only mildly informative.
</p>
<p>When specifying priors, note that numerical covariates are standardized internally before fitting the model. For an intercept-only model, a prior of Normal(0, 1) on the probit scale implies a Uniform(0, 1) or Beta(1, 1) prior on the probability scale.
</p>
<p>If you are unsure of the order of predictors, do a short run and check the output, or pass unusable values (eg, <code>muPsi=numeric(100)</code>) and check the error message.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>mcmcOutput</code>.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith. <code>BoccSS</code> uses the Gibbs sampler described by Dorazio and Rodriguez (2012).
</p>


<h3>References</h3>

<p>MacKenzie, D I; J D Nichols; A J Royle; K H Pollock; L L Bailey; J E Hines 2006. <em>Occupancy Estimation and Modeling : Inferring Patterns and Dynamics of Species Occurrence</em>. Elsevier Publishing.
</p>
<p>Dorazio and Rodriguez. 2012. A Gibbs sampler for Bayesian analysis of site-occupancy data. <em>Methods in Ecology and Evolution</em>, 3, 1093-1098
</p>


<h3>See Also</h3>

<p>See the examples for the <code><a href="#topic+weta">weta</a></code> data set.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># The blue ridge salamanders data from MacKenzie et al (2006) p99:
data(salamanders)
y &lt;- rowSums(salamanders)
n &lt;- rowSums(!is.na(salamanders))

tmp &lt;- BoccSS0(y, n)
tmp
occSS0(y, n)  # for comparison
plot(tmp)
</code></pre>

<hr>
<h2 id='Bayesian+20Poisson+20analysis'>
Bayesian analysis of count data
</h2><span id='topic+Bpoisson'></span>

<h3>Description</h3>

<p>Generates random draws from the posterior for a Poisson likelihood and gamma prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Bpoisson(y, n, priors=NULL, draws=10000, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Bayesian+2B20Poisson+2B20analysis_+3A_y">y</code></td>
<td>

<p>the count
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20Poisson+2B20analysis_+3A_n">n</code></td>
<td>

<p>the sample size
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20Poisson+2B20analysis_+3A_priors">priors</code></td>
<td>

<p>an optional list with elements specifying the priors for the mode and SD of the gamma prior distribution; see Details.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20Poisson+2B20analysis_+3A_draws">draws</code></td>
<td>

<p>the number of MCMC draws to be returned.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20Poisson+2B20analysis_+3A_...">...</code></td>
<td>

<p>additional arguments to pass to the function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function generates a vector of random draws from the posterior distribution of the probability of the observed count. It uses conjugacy to determine the parameters of the posterior gamma distribution, and draws independent values from this.
</p>
<p>A prior can be specified with the <code>priors</code> argument. A gamma prior is used, specified by mode, <code>mode</code>, and SD, <code>sd</code>.
</p>
<p>When <code>priors = NULL</code> (the default), a uniform prior corresponding to gamma(1, 0) is used.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>mcmcOutput</code>.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate a sample from a Poisson distribution, maybe the number of ticks
#   observed on a sample of rodents:
n &lt;- 10  # number of trials (rodents examined)
( y &lt;- rpois(n, 1.2) ) # number of ticks on each rodent
Bpoisson(sum(y), n)  # with uniform prior
plot(Bpoisson(sum(y), n))
Bpoisson(sum(y), n, priors=list(mode=1, sd=3))  # with informative prior
plot(Bpoisson(sum(y), n, priors=list(mode=1, sd=3)))
</code></pre>

<hr>
<h2 id='Bayesian+20SCR'>
Spatially explicit capture-recapture (secr) density estimation using MCMC
</h2><span id='topic+Bsecr0'></span>

<h3>Description</h3>

<p>Functions to estimate density from mark-recapture data using MCMC methods and JAGS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Bsecr0(capthist, buffer = 100, start = NULL, nAug = NA, maxSig = 2*buffer,
                    chains=3, draws=1e4, burnin=0, thin=1, adapt=1000,
                    priorOnly=FALSE, parallel=NULL, seed=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Bayesian+2B20SCR_+3A_capthist">capthist</code></td>
<td>

<p>a <code>capthist</code> object as defined in package <code>secr</code> including capture data and detector (trap) layout </p>
</td></tr>
<tr><td><code id="Bayesian+2B20SCR_+3A_buffer">buffer</code></td>
<td>

<p>scalar mask buffer radius (default 100 m)
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20SCR_+3A_start">start</code></td>
<td>

<p>an optional object of class <code>secr</code>, ie, output from the <code>secr.fit</code> function in package <code>secr</code>; objects of other classes are silently ignored.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20SCR_+3A_naug">nAug</code></td>
<td>

<p>number of individuals in the augmented population; if NA, a suitable default is chosen based on the object passed to <code>start</code> or a preliminary run of <code>secr.fit</code>.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20SCR_+3A_maxsig">maxSig</code></td>
<td>

<p>maximum value for the scale parameter of the detection function: the prior is <em>Uniform(0, maxSig)</em>.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20SCR_+3A_chains">chains</code></td>
<td>

<p>the number of Markov chains to run.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20SCR_+3A_draws">draws</code></td>
<td>

<p>the total number of values to return. The number of values calculated per chain is <code>adapt + burnin + ceiling(draws / chains) * thin</code>.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20SCR_+3A_burnin">burnin</code></td>
<td>

<p>the number of values to discard at the beginning of each chain.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20SCR_+3A_thin">thin</code></td>
<td>

<p>the thinning rate. If set to n &gt; 1, n values are calculated for each value returned.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20SCR_+3A_adapt">adapt</code></td>
<td>

<p>the number of iterations to run in the JAGS adaptive phase.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20SCR_+3A_prioronly">priorOnly</code></td>
<td>

<p>if TRUE, the function produces random draws from the appropriate <em>prior</em> distributions, with a warning.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20SCR_+3A_seed">seed</code></td>
<td>

<p>set a seed for the random number generators.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20SCR_+3A_parallel">parallel</code></td>
<td>

<p>if TRUE or NULL and sufficient cores are available, the MCMC chains are run in parallel; if TRUE and insufficient cores are available, a warning is given.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20SCR_+3A_...">...</code></td>
<td>

<p>other arguments to pass to the function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>Bsecr0</code> implements an intercept-only model (D ~ 1, g0 ~ 1, sigma ~ 1).
</p>


<h3>Value</h3>

<p>Returns an object of class <code>Bwiqid</code>, data frame with one column for each parameter, ie. D, lam0 and sigma.
</p>
<p>There are print, plot, and window methods for <code>Bwiqid</code>.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith
</p>


<h3>References</h3>

<p>Borchers &amp; Efford (2008) Spatially explicit maximum likelihood methods for capture-recapture studies <em>Biometrics</em> 64, 377-385
</p>
<p>Royle &amp; Dorazio (2008) <em>Hierarchical Modeling and Inference in Ecology</em>. Academic Press
</p>


<h3>See Also</h3>

<p>The function <code>secr.fit</code> in package <code>secr</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if(requireNamespace("secr") &amp;&amp; requireNamespace("rjags")) {
  # The stoats data set in 'secr'
  data(stoatDNA, package="secr")
  # This takes ca 10 mins on a multicore machine:
  Bout &lt;- Bsecr0(stoatCH, buffer=1000, chains=2) # 2 chains for testing
  summary(Bout)
  plot(Bout)
  # look at diagnostic plots to see if D is constrained by nAug:
  diagPlot(Bout)      # Upper values of D doesn't look constrained.
  plotACs(Bout, 1:20) # Plot the ACs for captured animals
}

</code></pre>

<hr>
<h2 id='BetaDist'>
The Beta Distribution
</h2><span id='topic+BetaDist'></span><span id='topic+dbeta2'></span><span id='topic+pbeta2'></span><span id='topic+qbeta2'></span><span id='topic+rbeta2'></span><span id='topic+getBeta2Par'></span><span id='topic+dbeta3'></span><span id='topic+pbeta3'></span><span id='topic+qbeta3'></span><span id='topic+rbeta3'></span><span id='topic+getBeta3Par'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random generation for the Beta distribution with parameters <code>mean</code> and <code>sd</code> OR <code>mode</code> and <code>concentration</code>. These are wrappers for <code>stats::dbeta</code>, etc. <code>getBeta*Par</code> returns the shape parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbeta2(x, mean, sd)
pbeta2(q, mean, sd, lower.tail=TRUE, log.p=FALSE)
qbeta2(p, mean, sd, lower.tail=TRUE, log.p=FALSE)
rbeta2(n, mean, sd)
getBeta2Par(mean, sd)

dbeta3(x, mode, concentration)
pbeta3(q, mode, concentration, lower.tail=TRUE, log.p=FALSE)
qbeta3(p, mode, concentration, lower.tail=TRUE, log.p=FALSE)
rbeta3(n, mode, concentration)
getBeta3Par(mode, concentration)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BetaDist_+3A_x">x</code></td>
<td>

<p>vector of parameter values
</p>
</td></tr>
<tr><td><code id="BetaDist_+3A_q">q</code></td>
<td>

<p>vector of quantiles
</p>
</td></tr>
<tr><td><code id="BetaDist_+3A_p">p</code></td>
<td>

<p>vector of probabilities
</p>
</td></tr>
<tr><td><code id="BetaDist_+3A_n">n</code></td>
<td>

<p>number of random draws required.
</p>
</td></tr>
<tr><td><code id="BetaDist_+3A_mean">mean</code></td>
<td>

<p>mean of the beta distribution; cannot be 0 or 1.
</p>
</td></tr>
<tr><td><code id="BetaDist_+3A_sd">sd</code></td>
<td>

<p>standard deviation of the beta distribution; this must be less than <code>sqrt(mean * (1-mean))</code>, larger values will return NA, with a warning.
</p>
</td></tr>
<tr><td><code id="BetaDist_+3A_mode">mode</code></td>
<td>

<p>mode of the beta distribution; may be 0 or 1.
</p>
</td></tr>
<tr><td><code id="BetaDist_+3A_concentration">concentration</code></td>
<td>

<p>concentration of the beta distribution; concentration = 2 is uniform, and the distribution becomes narrower as concentration increases. It is sometimes referred to as 'sample size', but best thought of as sample size + 2.
</p>
</td></tr>
<tr><td><code id="BetaDist_+3A_lower.tail">lower.tail</code></td>
<td>

<p>logical; if TRUE (default), cumulative probabilities up to x, otherwise, above x.
</p>
</td></tr>
<tr><td><code id="BetaDist_+3A_log.p">log.p</code></td>
<td>

<p>logical; if TRUE, probabilities p are given as log(p).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>dbeta*</code> gives the density, <code>pbeta*</code> gives the distribution function, <code>qbeta*</code> gives the quantile function, and <code>rbeta*</code> generates random deviates.
</p>
<p><code>getBeta*Par</code> returns a 2-column matrix with the shape parameters corresponding to <code>mean</code> and <code>sd</code> OR <code>mode</code> and <code>concentration</code>.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith
</p>


<h3>See Also</h3>

<p>See the <span class="pkg">stats</span> functions <code><a href="stats.html#topic+dbeta">dbeta</a></code>, <code><a href="stats.html#topic+pbeta">pbeta</a></code>, <code><a href="stats.html#topic+qbeta">qbeta</a></code>, <code><a href="stats.html#topic+rbeta">rbeta</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Plot some curves with dbeta2
xx &lt;- seq(0, 1, length.out=101)
plot(xx, dbeta2(xx, 0.4, 0.12), xlab="x", ylab="Probability density",
  main="Beta curves with mean = 0.4", type='l', lwd=2)
lines(xx, dbeta2(xx, 0.4, 0.24), col='darkgreen', lwd=2)
lines(xx, dbeta2(xx, 0.4, 0.28), col='red', lwd=2)
lines(xx, dbeta2(xx, 0.4, 0.36), col='blue', lwd=2)
abline(v=0.4, lty=3, lwd=2)
legend('topright', paste("sd =", c(0.12,0.24, 0.28, 0.36)), lwd=2,
  col=c('black', 'darkgreen', 'red', 'blue'), bty='n')

# Get shape and rate parameters for mean = 0.4 and sd = c(0.12,0.24, 0.28, 0.36, 0.49)
# The last value for sd is too big and will produce NAs and a warning
getBeta2Par(mean = 0.4, sd = c(0.12,0.24, 0.28, 0.36, 0.49))

# The parameterisation with mean and sd doesn't seem intuitive,
#   let's try mode and concentration.
# This does not allow 'bathtub' curves, which are bimodal.
plot(xx, dbeta3(xx, 0.4, 16), xlab="x", ylab="Probability density",
  main="Beta curves with mode = 0.4", type='l', lwd=2)
lines(xx, dbeta3(xx, 0.4, 8), col='darkgreen', lwd=2)
lines(xx, dbeta3(xx, 0.4, 4), col='red', lwd=2)
lines(xx, dbeta3(xx, 0.4, 2), col='blue', lwd=2)
abline(v=0.4, lty=3, lwd=2)
legend('topright', , lwd=2, paste("concentration =", c(16, 8, 4, 2)),
  col=c('black', 'darkgreen', 'red', 'blue'), bty='n')

# The mode can be at 0 or 1:
plot(xx, dbeta3(xx, 1, 16), xlab="x", ylab="Probability density",
  main="Beta curves with mode = 1", type='l', lwd=2)
lines(xx, dbeta3(xx, 1, 8), col='darkgreen', lwd=2)
lines(xx, dbeta3(xx, 1, 4), col='red', lwd=2)
lines(xx, dbeta3(xx, 1, 2), col='blue', lwd=2)
legend('topleft', paste("concentration =", c(16, 8, 4, 2)), lwd=2,
  col=c('black', 'darkgreen', 'red', 'blue'), bty='n')

# Cumulative plots with pbeta3
plot(xx, pbeta3(xx, 0.4, 16), xlab="x", ylab="Cumulative probability",
  main="Beta curves with mode = 0.4", type='l', lwd=2)
lines(xx, pbeta3(xx, 0.4, 8), col='darkgreen', lwd=2)
lines(xx, pbeta3(xx, 0.4, 4), col='red', lwd=2)
lines(xx, pbeta3(xx, 0.4, 2), col='blue', lwd=2)
abline(v=0.4, lty=3, lwd=2)
legend('topleft', paste("concentration =", c(16, 8, 4, 2)), lwd=2,
  col=c('black', 'darkgreen', 'red', 'blue'), bty='n')

# Generate random draws and plot a histogram
rnd &lt;- rbeta3(1e5, 0.4, 8)
hist(rnd, freq=FALSE)
# Add the curve:
lines(xx, dbeta3(xx, 0.4, 8), col='darkgreen', lwd=2)

# Get shape and rate parameters for mode = 0.4 and concentration = c(2, 4, 8, 16)
getBeta3Par(mode = 0.4, concentration = c(2, 4, 8, 16))

</code></pre>

<hr>
<h2 id='Bwiqid-class'>
Conversion to class Bwiqid (deprecated)
</h2><span id='topic+Bwiqid-class'></span><span id='topic+as.Bwiqid'></span><span id='topic+as.Bwiqid.default'></span>

<h3>Description</h3>

<p>Convert output containing MCMC chains to the class <code>mcmcOutput</code>, with a warning. The class <code>Bwiqid</code> is deprecated, use <code>mcmcOutput</code> instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.Bwiqid(object, ...)

## Default S3 method:
as.Bwiqid(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Bwiqid-class_+3A_object">object</code></td>
<td>

<p>an object containing the MCMC chains; see Details.
</p>
</td></tr>
<tr><td><code id="Bwiqid-class_+3A_...">...</code></td>
<td>

<p>named parameters to be passed to other methods.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>mcmcOutput</code>.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith.
</p>

<hr>
<h2 id='Closed+20Captures'>
Analysis of mark-recapture data for closed populations
</h2><span id='topic+closedCapM0'></span><span id='topic+closedCapMb'></span><span id='topic+closedCapMt'></span><span id='topic+closedCapMtcov'></span><span id='topic+closedCapMh2'></span><span id='topic+closedCapMhJK'></span>

<h3>Description</h3>

<p>Functions to analyse the classical models for closed populations without individual covariates, ie. full likelihood models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>closedCapM0(CH, ci = 0.95, ciType=c("normal", "MARK"), ...)

closedCapMb(CH, ci = 0.95, ciType=c("normal", "MARK"), ...)

closedCapMt(CH, ci = 0.95, ciType=c("normal", "MARK"), ...)

closedCapMtcov(CH, model=list(p~1), data=NULL, ci = 0.95,
    ciType=c("normal", "MARK"), ...)

closedCapMh2(CH, ci = 0.95, ciType=c("normal", "MARK"), ...)

closedCapMhJK(CH, ci = 0.95)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Closed+2B20Captures_+3A_ch">CH</code></td>
<td>

<p>a 0/1 capture history matrix, animals x occasions; NAs not permitted. For functions <code>closedCapM0</code>, <code>closedCapMh2</code> and <code>closedCapMhJK</code>, <code>CH</code> can be a vector of capture frequencies of length equal to the number of occasions - trailing zeros are required.
</p>
</td></tr>
<tr><td><code id="Closed+2B20Captures_+3A_model">model</code></td>
<td>

<p>a list of formulae symbolically defining a linear predictor for p in terms of covariates.
</p>
</td></tr>
<tr><td><code id="Closed+2B20Captures_+3A_data">data</code></td>
<td>

<p>a data frame containing the variables in the model, with one row for each occasion.
</p>
</td></tr>
<tr><td><code id="Closed+2B20Captures_+3A_ci">ci</code></td>
<td>

<p>the required confidence interval.
</p>
</td></tr>
<tr><td><code id="Closed+2B20Captures_+3A_citype">ciType</code></td>
<td>

<p>the method used to calculate the confidence interval for population size (N); see Details.
</p>
</td></tr>
<tr><td><code id="Closed+2B20Captures_+3A_...">...</code></td>
<td>

<p>other arguments passed to <code><a href="stats.html#topic+nlm">nlm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Model M0 assumes all animals have the same capture probability.
</p>
<p>Model Mb allows for a permanent behavioural response: capture probability is different for animals that have already been captured at least once.
</p>
<p>Model Mh2 and the jackknife estimator allow for heterogeneity in capture probability.
</p>
<p>The likelihood maximization routine produces an estimate and standard error for beta = log(<em>f0</em>), where <em>f0</em> is the number of animals never captured. If <code>ciType == "normal"</code>, a confidence interval for beta is calculated as beta +/- crit * SE.beta, where crit is the appropriate multiplier for the confidence interval required, 1.96 for a 95% CI. This confidence interval is then back-transformed to the real scale and added to the number of animals captured (M[t+1]) to give estimates of N.
</p>
<p>If <code>ciType == "MARK"</code>, the method used by MARK to calculate confidence intervals is used (see MARK help page for Closed Capture Models and Burnham et al (1987, p212)).
The beta values are back-transformed with f0.hat = exp(beta) and SE.f0 = SE.beta * f0.hat, and hence CV = SE.f0 / f0.hat. The confidence limits are then
</p>
<p>Lower = f0.hat / C + M[t+1]
</p>
<p>Upper = f0.hat * C + M[t+1]
</p>
<p>where C = exp(crit * sqrt(log(1 + CV^2))).
</p>
<p>Confidence intervals for capture probabilities are always calculated on the logit scale and back-transformed to real values.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>wiqid</code>, which is a list with the following elements:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>The call used to produce the results</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>Values of the coefficients of the terms in the linear predictors, with standard errors and confidence intervals.</p>
</td></tr>
<tr><td><code>beta.vcv</code></td>
<td>
<p>The variance-covariance matrix for the beta estimates.</p>
</td></tr>
<tr><td><code>real</code></td>
<td>
<p>Estimates of population size (N) and probability of detection on the real scale, with confidence intervals.</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>a vector with elements for log(likelihood), number of parameters, and effective sample size. If the variance-covariance matrix cannot be calculated, the second element should be <code>NA</code>.</p>
</td></tr>
</table>
<p>The jackknife estimator does not use likelihood maximisation, so elements <code>beta</code> and <code>beta.vcv</code> are NULL and <code>logLik = NA</code>.
</p>
<p>There are <code>print</code>, <code>logLik</code>, and <code>nobs</code> methods for class <code>wiqid</code>.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith
</p>


<h3>References</h3>

<p>Basic work on mark-recapture for closed populations is in:
</p>
<p>Otis, D L; K P Burnham; G C White; D R Anderson. 1978. Statistical inference from capture data on closed animal populations. <em>Wildlife Monographs</em> 62:1-135.
</p>
<p>White, G C; D R Anderson; K P Burnham; D L Otis. 1982. <em>Capture-recapture and removal methods for sampling closed populations</em>. Los Alamos National Laboratory, Los Alamos NM.
</p>
<p>Calculation of the confidence interval for N is in:
</p>
<p>Burnham, K.P., Anderson, D.R., White, G.C., Brownie, C., &amp; Pollock, K.H. 1987. <em>Design and analysis methods for fish survival experiments based on release-recapture</em>. American Fisheries Society, Bethesda MD.
</p>
<p>The jackknife estimator is described in:
</p>
<p>Burnham, K P; W S Overton. 1979. Robust estimation of population size when capture probabilities vary among animals. <em>Ecology</em> 60:927-936.
</p>
<p>Rexstad, E; K Burnham 1992. <em>User's guide for interactive program CAPTURE</em>. USGS Patuxent.
</p>
<p>Data sets in the examples are from:
</p>
<p>White et al, op. cit.
</p>
<p>Karanth, Nichols, Kumar, Link, Hines (2004) Tigers and their prey: Predicting carnivore densities from prey abundance. PNAS 101:4854-4858
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Data from White et al (1982):
freq1 &lt;- c(50, 46, 35, 24, 14, 5, 0) # there were 7 capture occasions
closedCapM0(freq1)
closedCapM0(freq1, ci=0.8)
closedCapMh2(freq1)
closedCapMhJK(freq1)

# Kanha tiger data from Karanth et al (2004)
data(KanhaTigers)
closedCapM0(KanhaTigers)
closedCapMb(KanhaTigers)
closedCapMh2(KanhaTigers)
closedCapMhJK(KanhaTigers)
closedCapMt(KanhaTigers)
closedCapMtcov(KanhaTigers, p~.Time)
# Generate some mythical covariates:
covars &lt;- data.frame(Temp = runif(ncol(KanhaTigers), 15, 25),
  Cloud = sample(0:8, ncol(KanhaTigers), replace=TRUE))
closedCapMtcov(KanhaTigers, p~Cloud, data=covars)

# Compare the normal (default) and MARK confidence intervals for N:
rbind(closedCapMt(KanhaTigers)$real[1, ],
      closedCapMt(KanhaTigers, ciType="MARK")$real[1, ])
</code></pre>

<hr>
<h2 id='deprecated'>
Deprecated functions in package wiqid
</h2><span id='topic+plotPost'></span>

<h3>Description</h3>

<p>These functions have been replaced by functions in <code>mcmcOutput</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotPost(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="deprecated_+3A_...">...</code></td>
<td>

<p>arguments passed to the new function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>plotPost has been replaced by postPlot.
</p>


<h3>Value</h3>

<p>See help for the new function.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith
</p>

<hr>
<h2 id='dippers'>
Capture-recapture data for European dippers
</h2><span id='topic+dippers'></span>

<h3>Description</h3>

<p>A data set that accompanies Program MARK and is included in the <code>RMark</code> package in a different format under the name <code>dipper</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(dippers)</code></pre>


<h3>Format</h3>

<p>A data frame with 294 observations on the following 8 variables.
</p>

<dl>
<dt>Y1, Y2, Y3, Y4, Y5, Y6, Y7</dt><dd><p>detection histories for 294 dippers over 7 years: '1' if captured, '0' if not captured.</p>
</dd>
<dt>sex</dt><dd><p>sex of each bird captured.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Lebreton, J-D; K P Burnham; J Clobert; D R Anderson. 1992. Modeling survival and testing biological hypotheses using marked animals: a unified approach with case studies. <em>Ecological Monographs</em>, 62, 67-118.
</p>


<h3>References</h3>

<p>Analysis given in many books and papers, notably:
</p>
<p>Cooch, E; G White 2014 (13th edition, but constantly updated). <em>Program MARK: a gentle introduction</em>. Available online in PDF format at:
http://www.phidot.org/software/mark/docs/book/
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dippers)

DH &lt;- dippers[1:7]  # Extract the detection histories
survCJS(DH)  # the phi(.) p(.) model
survCJS(DH, phi ~ .time)  # the phi(t) p(.) model

# Floods affected the 2nd and 3rd intervals
df &lt;- data.frame(flood = c(FALSE, TRUE, TRUE, FALSE, FALSE, FALSE))
survCJS(DH, phi ~ flood, data=df)

# Including a grouping factor:
survCJS(DH, phi ~ flood * group, data=df, group=dippers$sex)

# Bayesian estimation:


if(requireNamespace("rjags")) {
  Bdip &lt;- BsurvCJS(DH, parallel=FALSE)
  plot(Bdip)
  BdipFlood &lt;- BsurvCJS(DH, list(phi ~ flood, p ~ .time), data=df, parallel=FALSE)
  BdipFlood
  op &lt;- par(mfrow=2:1)
  plot(BdipFlood, "phi[1]", xlim=c(0.3, 0.75), main="No flood")
  plot(BdipFlood, "phi[2]", xlim=c(0.3, 0.75), main="Flood")
  par(op)
  ratio &lt;- BdipFlood['phi[2]'] / BdipFlood['phi[1]']
  postPlot(ratio, compVal=1)
}

</code></pre>

<hr>
<h2 id='Distance+20Measures'>
Plug-in distance-measure functions for <code><a href="#topic+distShell">distShell</a></code>.
</h2><span id='topic+Distance+20Measures'></span><span id='topic+distBrayCurtis'></span><span id='topic+distChaoJaccCorr'></span><span id='topic+distChaoJaccNaive'></span><span id='topic+distChaoSorCorr'></span><span id='topic+distChaoSorNaive'></span><span id='topic+distChord'></span><span id='topic+distJaccard'></span><span id='topic+distMatching'></span><span id='topic+distMorisitaHorn'></span><span id='topic+distOchiai'></span><span id='topic+distPreston'></span><span id='topic+distRogersTanimoto'></span><span id='topic+distSimRatio'></span><span id='topic+distSorensen'></span><span id='topic+distWhittaker'></span>

<h3>Description</h3>

<p>Each function takes two (interchangeable) vectors of data and returns a measure of distance between them. Vectors may be just 1/0 values (presence-absence data) or non-negative integers (count data).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>distBrayCurtis(d1, d2)
distChaoJaccCorr(d1, d2)
distChaoJaccNaive(d1, d2)
distChaoSorCorr(d1, d2)
distChaoSorNaive(d1, d2)
distChord(d1, d2)
distJaccard(d1, d2)
distMatching(d1, d2)
distMorisitaHorn(d1, d2)
distOchiai(d1, d2)
distPreston(d1, d2)
distRogersTanimoto(d1, d2)
distSimRatio(d1, d2)
distSorensen(d1, d2)
distWhittaker(d1, d2)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Distance+2B20Measures_+3A_d1">d1</code>, <code id="Distance+2B20Measures_+3A_d2">d2</code></td>
<td>

<p>vectors of equal length, specifying the two cases to be compared.
</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>distBrayCurtis</dt><dd>
<p>Complement of the Bray-Curtis index, see Magurran p.246, where it is referred to as the 'quantitative Sorensen' index. Based on count data.
</p>
</dd>
<dt>distChaoJaccCorr, distChaoJaccNaive, distChaoSorCorr, distChaoSorNaive</dt><dd>
<p>Each is the complement of one of a series of similarity indices which allow for (1) relative abundance of shared species and (2) estimation of number of shared species not detected. Based on count data. See Chao et al. 2005.
</p>
</dd>
<dt>distChord</dt><dd>
<p>Both vectors are normalized so that the sum of squares = 1, ie. they lie on the surface of a sphere of unit radius. The distance measure is the length of the cord joining the two points through the sphere, which is in [0, sqrt(2)], ie. it is sqrt(2) for sites with no species in common. Based on count data. See Zuur et al 2007:166, Legendre &amp; Legendre 1998:279.
</p>
</dd>
<dt>distJaccard</dt><dd>
<p>Complement of the Jaccard index of similarity; also known as &quot;Marczewski-Steinhaus distance&quot;. Based on presence-absence data. No. of shared species / Overall number of species.
</p>
</dd>
<dt>distMatching</dt><dd>
<p>A simple matching index: the proportion of elements which match in two presence-absence vectors (ie. present in both or absent in both). Zuur et al 2007:165.
</p>
</dd>
<dt>distMorisitaHorn</dt><dd>
<p>The complement of the Morisita-Horn index of similarity. Based on count data. See Magurran 2004:246 The Morisita-Horn index is also known as &quot;simplified Morisita&quot;. The &quot;Morisita&quot; and &quot;Horn&quot; indices are different again! See Krebs 1999:470-471.
</p>
</dd>
<dt>distOchiai</dt><dd>
<p>Complement of the Ochiai coefficient of similarity. Based on count data. See Zuur et al 2007:167, Legendre &amp; Legendre 1998:276.
</p>
</dd>
<dt>distPreston</dt><dd>
<p>Preston's coefficient of faunal dissimilarity (z). Based on presence-absence data. See Preston 1962:418.
</p>
</dd>
<dt>distRogersTanimoto</dt><dd>
<p>Complement of Rogers and Tanimoto's coefficient of similarity. Based on presence-absence data. See Zuur et al 2007:165.
</p>
</dd>
<dt>distSimRatio</dt><dd>
<p>Complement of the Similarity Ratio. Based on count data. See Zuur et al 2007:167.
</p>
</dd>
<dt>distSorensen</dt><dd>
<p>Complement of Sorensen (or Dice) index of similarity. Based on presence-absence data. No. of shared species / Average number of species. Same as Whittaker's distance measure for Incidence (presence-absence) data minus one (Magurran 2004:244).
</p>
</dd>
<dt>distWhittaker</dt><dd>
<p>Whittaker's index of association for Abundance (count) data. See Zuur et al 2007:170.
</p>
</dd>
</dl>



<h3>Value</h3>

<p>a scalar, the distance between the two vectors.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith
</p>


<h3>References</h3>


<ul>
<li><p> Chao, A; R L Chazdon; R K Colwell; T-J Shen. 2005. A new statistical
approach for assessing similarity of species composition with incidence
and abundance data. <em>Ecology Letters</em> 8:148-159.
</p>
</li>
<li><p> Krebs, C J 1999. Ecological Methodology. Addison Wesley Longman.
</p>
</li>
<li><p> Magurran, A E 2004. <em>Measuring biological diversity</em>. Blackwell. 
</p>
</li>
<li><p> Preston, F W. 1962. The canonical distribution of commonness and rarity: Part II. <em>Ecology</em> 43:410-432. 
</p>
</li>
<li><p> Zuur, A F; E N Ieno; G M Smith 2007. <em>Analysing ecological data</em>. Springer. 
</p>
</li>
<li><p> Legendre, P; L Legendre 1998. <em>Numerical ecology</em>. Elsevier, Amsterdam NL.
</p>
</li></ul>



<h3>See Also</h3>

<p>The basic distance computation function is <code><a href="stats.html#topic+dist">dist</a></code> in package stats. Other functions are <code>vegan::vegdist</code> and <code>labdsv::dsvdis</code>.
</p>
<p>These functions provide the following distance measures:
</p>

<ul>
<li><p>       binary (in dist) = asymmetric binary = Steinhaus
</p>
</li>
<li><p>       binomial (in vegdist)
</p>
</li>
<li><p>       bray/curtis (in dsvdis) = bray (in vegdist)
</p>
</li>
<li><p>       canberra (in dist and vegdist)
</p>
</li>
<li><p>       chao (in vegdist)
</p>
</li>
<li><p>       chisq  (in dsvdis)
</p>
</li>
<li><p>       euclidean (in dist and vegdist)
</p>
</li>
<li><p>       gower (in vegdist)
</p>
</li>
<li><p>       horn (in vegdist) = Morisita-Horn or simplified Morisita 
</p>
</li>
<li><p>       jaccard (in vegdist)
</p>
</li>
<li><p>       kulczynski (in vegdist)
</p>
</li>
<li><p>       manhattan (in dist and vegdist)
</p>
</li>
<li><p>       maximum (in dist)
</p>
</li>
<li><p>       minkowski (in dist)
</p>
</li>
<li><p>       morisita (not simplified!) (in vegdist)
</p>
</li>
<li><p>       mountford (in vegdist)
</p>
</li>
<li><p>       ochiai (in dsvdis)
</p>
</li>
<li><p>       raup (in vegdist) = Raup-Crick
</p>
</li>
<li><p>       roberts  (in dsvdis)
</p>
</li>
<li><p>       ruzicka (in dsvdis)
</p>
</li>
<li><p>       sorensen  (in dsvdis)
</p>
</li>
<li><p>       steinhaus (in dsvdis)= binary 
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(distTestData)

distShell(distTestData, distJaccard)

distShell(distTestData, distMorisitaHorn)
</code></pre>

<hr>
<h2 id='distShell'>
Distance Matrix Computation
</h2><span id='topic+distShell'></span>

<h3>Description</h3>

<p>Produces a 'dist' object using a user-defined distance measure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>distShell(DATA, FUNC, diag = FALSE, upper = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="distShell_+3A_data">DATA</code></td>
<td>

<p>a matrix-like object with variables in COLUMNS, cases in ROWS.
</p>
</td></tr>
<tr><td><code id="distShell_+3A_func">FUNC</code></td>
<td>

<p>the distance function; takes two vector arguments and returns a single scalar distance measure. See Details.
</p>
</td></tr>
<tr><td><code id="distShell_+3A_diag">diag</code></td>
<td>

<p>logical value indicating whether the diagonal of the distance matrix should be printed by print.dist.
</p>
</td></tr>
<tr><td><code id="distShell_+3A_upper">upper</code></td>
<td>

<p>logical value indicating whether the upper triangle of the distance matrix should be printed by print.dist.
</p>
</td></tr>
<tr><td><code id="distShell_+3A_...">...</code></td>
<td>

<p>further arguments, passed to FUNC.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>FUNC must be a function of the form foo(x1, x2, ...). The first two arguments must be vectors of equal length, specifying the two cases to be compared. It must return a single scalar distance measure. Similarity measures will work, but for consistency stick to distance measures.
</p>
<p>A number of example functions are provided in the package; see <code><a href="#topic+Distance+20Measures">Distance Measures</a></code>.
</p>


<h3>Value</h3>

<p><code>distShell</code> returns an object of class <code>"dist"</code>, including the attribute <code>call</code>. 
</p>
<p>See <code><a href="stats.html#topic+dist">dist</a></code> for details of this class.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith, 10 Dec 2006, updated 1 Sept 2012.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+dist">dist</a></code> in package stats. Also <code>vegan::vegdist</code> and <code>labdsv::dsvdis</code>. See <code><a href="#topic+Distance+20Measures">Distance Measures</a></code> for details of plug-in functions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Use the artificial data set, see ?distTestData
data(distTestData)

# Using distance measure functions in this package:
distShell(distTestData, distSorensen)
distShell(distTestData, distMorisitaHorn)

# Write a customised distance function:
K &lt;- function(a1, a2)  {
  shared &lt;- sum(a1 &gt; 0 &amp; a2 &gt; 0)
  notshared &lt;- sum(xor(a1 &gt; 0, a2 &gt; 0))
  shared / notshared
}
distShell(distTestData, K)
# This returns Inf if the number of species not shared is zero. May not be a good measure!
</code></pre>

<hr>
<h2 id='distTestData'>
An artificial data set to test distance/dissimilarity measures
</h2><span id='topic+distTestData'></span>

<h3>Description</h3>

<p>Artificial data for counts of 32 species at 5 sites.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(distTestData)</code></pre>


<h3>Format</h3>

<p>A matrix with 5 rows (sites), labelled A-B, and 32 columns (species).
</p>


<h3>Details</h3>

<p>Sites A, B and C each have 16 species and 158 individuals.<br />
Sites A and B have the same species, but the numbers of each are different.<br />
Site C has a completely different set of 16 species, but the same number of individuals.<br />
Site D has the same species in the same proportions as A, but twice the number of individuals.<br />
Site E has 32 species and 316 individuals.
</p>


<h3>Source</h3>

<p>Artificial data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(distTestData)
# Display the data:
print(t(distTestData))

distShell(distTestData, distJaccard)
#     A   B   C   D
# B 0.0            
# C 1.0 1.0        
# D 0.0 0.0 1.0    
# E 0.5 0.5 0.5 0.5
# Jaccard index ignores counts, so sees AB, AD and BD as identical (zero distance).

round(distShell(distTestData, distMorisitaHorn), 2)
#      A    B    C    D
# B 0.89               
# C 1.00 1.00          
# D 0.00 0.89 1.00     
# E 0.33 0.93 0.33 0.33
# Morisita-Horn index considers proportions, so AD are identical but not AB or BD.

round(distShell(distTestData, distBrayCurtis), 2)
#      A    B    C    D
# B 0.84               
# C 1.00 1.00          
# D 0.33 0.84 1.00     
# E 0.33 0.89 0.33 0.50
# Bray-Curtis index is affected by abundance as well as proportions, so AD are no longer identical.
# Site C only overlaps with D, so AC, BC and CD are 1.00 for all indices.
# Site E overlaps with all the others, so AE, BE, CE and DE all lie between 0 and 1 for all indices.
</code></pre>

<hr>
<h2 id='Diversity+20indices'>
Biodiversity indices
</h2><span id='topic+Diversity+20indices'></span><span id='topic+biodSimpson'></span><span id='topic+biodShannon'></span><span id='topic+biodBerger'></span><span id='topic+biodBrillouin'></span>

<h3>Description</h3>

<p>Common indices of biodiversity, expressed as the number of common species.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>biodSimpson(abVec, correct = TRUE)
biodShannon(abVec)
biodBerger(abVec)
biodBrillouin(cntVec)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Diversity+2B20indices_+3A_abvec">abVec</code></td>
<td>

<p>a vector of measures of abundance, eg. counts of individuals or biomass, one element per species; or a corresponding matrix or data frame, which will be converted to a vector with <code>rowSums</code>.
</p>
</td></tr>
<tr><td><code id="Diversity+2B20indices_+3A_cntvec">cntVec</code></td>
<td>

<p>a vector (or matrix or data frame) of counts of individuals, one element per species. Non-integers will be rounded without warning.
</p>
</td></tr>
<tr><td><code id="Diversity+2B20indices_+3A_correct">correct</code></td>
<td>

<p>if TRUE, a small sample correction is applied, and in that case <code>abVec</code> should have count data (non-integers will be silently rounded).
</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>biodSimpson</dt><dd>
<p>Inverse of Simpson's (1949) index of dominance. If <code>correct = TRUE</code>, a small-sample correction is applied, giving Hurlbert's (1971) diversity index. Otherwise, the result is equivalent to Hill's (1973) <code class="reqn">N_2</code>.
</p>
</dd>
<dt>biodShannon</dt><dd>
<p>Exponential form of Shannon's (1948) entropy measure, equivalent to Hill's (1973) <code class="reqn">N_1</code>.
</p>
</dd>
<dt>biodBerger</dt><dd>
<p>Inverse of Berger &amp; Parker's (1970) index of dominance, equivalent to Hill's (1973) <code class="reqn">N_Inf</code>.
</p>
</dd>
<dt>biodBrillouin</dt><dd>
<p>Exponential form of Brillouin's index: for small, completely censused populations, Brillouin's index is a more appropriate measure of entropy than Shannon's measure (Maurer &amp; McGill 2011:61).
</p>
</dd>
</dl>



<h3>Value</h3>

<p>The relevant index.
</p>


<h3>Warning</h3>

<p>It is important that the proportions of each species in the <em>sample</em> represent those in the <em>population</em> from which it is drawn. This will not be the case if probability of inclusion varies among species, as often occurs when samples are collected in the field.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith
</p>


<h3>References</h3>

<p>Berger, W H; F L Parker. 1970. Diversity of planktonic Foramenifera in deep sea sediments. <em>Science</em> 168:1345-1347. 
</p>
<p>Hill, M O. 1973. Diversity and evenness: a unifying notation and its consequences. <em>Ecology</em> 54:427-431.
</p>
<p>Hurlbert, S H. 1971. The nonconcept of species diversity: A critique and alternative parameters. <em>Ecology</em> 52:577-586.
</p>
<p>Maurer, B A; B J McGill. 2011. Measurement of species diversity. 55-64 in Magurran, A E, and B J McGill, editors. <em>Biological diversity: frontiers in measurement and assessment.</em> Oxford University Press, Oxford, New York NY
</p>
<p>Shannon, C E. 1948. A mathematical theory of communication. <em>Bell System Technical Journal</em> 27:379-423
</p>
<p>Simpson, E H. 1949. Measurement of diversity. <em>Nature</em> 163:688.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+richSobs">richSobs</a></code> and <a href="#topic+Species+20richness+20estimators">Species richness estimators</a> for alternatives to indices.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(KillarneyBirds)
apply(KillarneyBirds, 2, biodSimpson)

</code></pre>

<hr>
<h2 id='GammaDist'>
The Gamma Distribution
</h2><span id='topic+GammaDist'></span><span id='topic+dgamma2'></span><span id='topic+pgamma2'></span><span id='topic+qgamma2'></span><span id='topic+rgamma2'></span><span id='topic+getGammaPar'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random generation for the Gamma distribution with parameters <code>mean</code> and <code>sd</code>. These are wrappers for <code>stats::dgamma</code>, etc. <code>getGammaPar</code> returns the shape and rate parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgamma2(x, mean, sd)
pgamma2(q, mean, sd, lower.tail=TRUE, log.p=FALSE)
qgamma2(p, mean, sd, lower.tail=TRUE, log.p=FALSE)
rgamma2(n, mean, sd)
getGammaPar(mean, sd)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GammaDist_+3A_x">x</code></td>
<td>

<p>vector of parameter values
</p>
</td></tr>
<tr><td><code id="GammaDist_+3A_q">q</code></td>
<td>

<p>vector of quantiles
</p>
</td></tr>
<tr><td><code id="GammaDist_+3A_p">p</code></td>
<td>

<p>vector of probabilities
</p>
</td></tr>
<tr><td><code id="GammaDist_+3A_n">n</code></td>
<td>

<p>number of random draws required.
</p>
</td></tr>
<tr><td><code id="GammaDist_+3A_mean">mean</code></td>
<td>

<p>mean of the gamma distribution
</p>
</td></tr>
<tr><td><code id="GammaDist_+3A_sd">sd</code></td>
<td>

<p>standard deviation of the gamma distribution
</p>
</td></tr>
<tr><td><code id="GammaDist_+3A_lower.tail">lower.tail</code></td>
<td>

<p>logical; if TRUE (default), cumulative probabilities up to x, otherwise, above x.
</p>
</td></tr>
<tr><td><code id="GammaDist_+3A_log.p">log.p</code></td>
<td>

<p>logical; if TRUE, probabilities p are given as log(p).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>dgamma2</code> gives the density, <code>pgamma2</code> gives the distribution function, <code>qgamma2</code> gives the quantile function, and <code>rgamma2</code> generates random deviates.
</p>
<p><code>getGammaPar</code> returns a 2-column matrix with the shape and rate parameters corresponding to <code>mean</code> and <code>sd</code>. </p>


<h3>Author(s)</h3>

<p>Mike Meredith
</p>


<h3>See Also</h3>

<p>See the <span class="pkg">stats</span> functions <code><a href="stats.html#topic+dgamma">dgamma</a></code>, <code><a href="stats.html#topic+pgamma">pgamma</a></code>, <code><a href="stats.html#topic+qgamma">qgamma</a></code>, <code><a href="stats.html#topic+rgamma">rgamma</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Plot some curves with dgamma2
xx &lt;- seq(0, 20, length.out=101)
plot(xx, dgamma2(xx, 5, 1), xlab="x", ylab="Probability density",
  main="Gamma curves with mean = 5", type='l', lwd=2)
lines(xx, dgamma2(xx, 5, 2), col='darkgreen', lwd=2)
lines(xx, dgamma2(xx, 5, 4), col='red', lwd=2)
lines(xx, dgamma2(xx, 5, 8), col='blue', lwd=2)
abline(v=5, lty=3, lwd=2)
legend('topright', paste("sd =", c(1,2,4,8)), lwd=2,
  col=c('black', 'darkgreen', 'red', 'blue'), bty='n')

# Cumulative plots with pgamma2
plot(xx, pgamma2(xx, 5, 1), xlab="x", ylab="Cumulative probability",
  main="Gamma curves with mean = 5", type='l', lwd=2)
lines(xx, pgamma2(xx, 5, 2), col='darkgreen', lwd=2)
lines(xx, pgamma2(xx, 5, 4), col='red', lwd=2)
lines(xx, pgamma2(xx, 5, 8), col='blue', lwd=2)
abline(v=5, lty=3, lwd=2)
legend('bottomright', paste("sd =", c(1,2,4,8)), lwd=2,
  col=c('black', 'darkgreen', 'red', 'blue'), bty='n')

# Generate random draws and plot a histogram
rnd &lt;- rgamma2(1e5, 5, 2)
hist(rnd, freq=FALSE)
# Add the curve:
lines(xx, dgamma2(xx, 5, 2), col='darkgreen', lwd=2)

# Get shape and rate parameters for mean = 5 and sd = c(1,2,4,8)
getGammaPar(mean = 5, sd = c(1,2,4,8))

</code></pre>

<hr>
<h2 id='getMCerror'>
MCMC error using the batch method (deprecated)
</h2><span id='topic+getMCerror'></span>

<h3>Description</h3>

<p>This is now a wrapper for <code><a href="mcmcOutput.html#topic+getMCE">getMCE</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getMCerror(object, n.chains, SDpc=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getMCerror_+3A_object">object</code></td>
<td>

<p>an object of any class with MCMC output that can be coerced to class mcmcOutput.
</p>
</td></tr>
<tr><td><code id="getMCerror_+3A_n.chains">n.chains</code></td>
<td>

<p>ignored
</p>
</td></tr>
<tr><td><code id="getMCerror_+3A_sdpc">SDpc</code></td>
<td>

<p>if TRUE, the value of the MC error as a percentage of the posterior SD will be returned.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If SDpc is FALSE (the default), a named vector with the estimates of MC error. If TRUE, the MC error as a percentage of the standard deviation of the posterior chain. A value &lt;5% of SD is adequate for most purposes, but &lt;1.5% is needed to properly estimate tail probabilities (Lunn et al 2013, p78-79).
</p>


<h3>Author(s)</h3>

<p>Mike Meredith
</p>


<h3>References</h3>

<p>Lunn, D., Jackson, C., Best, N., Thomas, A., &amp; Spiegelhalter, D. (2013) <em>The BUGS book: a practical introduction to Bayesian analysis</em>, Chapman and Hall.
</p>
<p>Roberts, G.O. (1996). Markov chain concepts related to sampling algorithms. In <em>Markov Chain Monte Carlo in practice</em> (eds W.R. Gilks, D.J. Spiegelhalter &amp; S. Richardson). Chapman &amp; Hall, London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Get some output to use
data(salamanders)
y &lt;- rowSums(salamanders)
( out &lt;- BoccSS0(y, 5) )

getMCerror(out)
getMCerror(out, SDpc=TRUE)
</code></pre>

<hr>
<h2 id='GrandSkinks'>
Multi-season detection data for grand skinks
</h2><span id='topic+GrandSkinks'></span>

<h3>Description</h3>

<p>Results of an occupancy survey of 352 rocky outcrops (&quot;tors&quot;) looking for grand skinks. Tors were surveyed up to 3 times per year for 5 years. The surrounding terrain was characterised as natural grassland or pasture.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(GrandSkinks)</code></pre>


<h3>Format</h3>

<p>A data frame with 352 observations on the following 16 variables.
</p>

<dl>
<dt>A1, A2, A3, B1, B2, B3, C1, C2, C3, D1, D2, D3, E1, E2, E3</dt><dd><p>an array of observations of detection (1) or nondetection (0) of skinks for each of 3 occasions in 5 years. NA indicates occasions when a tor was not visited. </p>
</dd>
<dt>habitat</dt><dd><p>a factor indicating the type of grassland surrounding the tor.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data are provided as a data frame, such as would result from reading in data from a text file. Further formatting is needed before using these for analysis: see the examples. 
</p>


<h3>Source</h3>

<p>Data distributed with PRESENCE.
</p>


<h3>References</h3>

<p>MacKenzie, D I; J D Nichols; A J Royle; K H Pollock; L L Bailey; J E Hines 2006. <em>Occupancy Estimation and Modeling : Inferring Patterns and Dynamics of Species Occurrence</em>. Elsevier Publishing.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(GrandSkinks)

# Extract detection histories:
DH &lt;- GrandSkinks[, 1:15]
occMS0(DH, 3)


</code></pre>

<hr>
<h2 id='KanhaTigers'>
Capture history matrix for camera-trapped tigers
</h2><span id='topic+KanhaTigers'></span>

<h3>Description</h3>

<p>Capture history matrix for camera-trapped tigers
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(KanhaTigers)</code></pre>


<h3>Format</h3>

<p>A matrix with 26 rows for animals trapped and 10 columns for the trapping occasions. KanhaTigers[i, j] = 1 if animal i was trapped on occasion j, zero otherwise.
</p>


<h3>Source</h3>

<p>Karanth, Nichols, Kumar, Link, Hines (2004) Tigers and their prey: Predicting carnivore densities from prey abundance. PNAS 101:4854-4858
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(KanhaTigers)
dim(KanhaTigers)
closedCapMt(KanhaTigers)
</code></pre>

<hr>
<h2 id='KillarneyBirds'>
Abundance of woodland birds
</h2><span id='topic+KillarneyBirds'></span>

<h3>Description</h3>

<p>The number of territories held by breeding males in 9 blocks of woodland habitat in County Killarney, Ireland.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(KillarneyBirds)</code></pre>


<h3>Format</h3>

<p>A data frame with counts for 31 species in 9 blocks of habitat. Row names are the English species names.
</p>

<dl>
<dt><code>Oak1</code></dt><dd><p>first of 3 oak wood sites</p>
</dd>
<dt><code>Oak2</code></dt><dd><p>second of 3 oak wood sites</p>
</dd>
<dt><code>Oak3</code></dt><dd><p>third of 3 oak wood sites</p>
</dd>
<dt><code>Yew</code></dt><dd><p>a mature yew wood</p>
</dd>
<dt><code>Sitka</code></dt><dd><p>a Sitka spruce plantation</p>
</dd>
<dt><code>Norway</code></dt><dd><p>a Norway spruce plantation</p>
</dd>
<dt><code>Mixed</code></dt><dd><p>a mixed broadleaf wood</p>
</dd>
<dt><code>Patchy</code></dt><dd><p>a wood with patches of broadleaf and conifer trees</p>
</dd>
<dt><code>Swampy</code></dt><dd><p>a swampy seasonally-flooded woodland</p>
</dd>
</dl>



<h3>Source</h3>

<p>Batten L. A. (1976) Bird communities of some Killarney woodlands. <em>Proceedings of the Royal Irish Academy</em> 76:285-313.
</p>


<h3>References</h3>

<p>Magurran (2004) <em>Measuring Biological Diversity</em>, p237
</p>
<p>Solow (1993) A simple test for change in community structure.	<em>J Animal Ecology</em> 62:191-193.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(KillarneyBirds)
## number of species in each block of habitat:
colSums(KillarneyBirds &gt; 0)

</code></pre>

<hr>
<h2 id='Links'> Logit and probit links for generalised linear modelling </h2><span id='topic+Links'></span><span id='topic+links'></span><span id='topic+links'></span>

<h3>Description</h3>

<p>Generalised linear models with binomial response variables (&quot;logistic regression&quot;) use a link function to link the response on a (0,1) scale to a linear predictor on (-Inf, Inf). The canonical link is the logistic (&quot;logit&quot;) function, which has some nice theoretical properties and can be interpreted as the log of the odds of success. Other links are available, notably the cumulative standard normal (&quot;probit&quot;) link, which allows for Gibbs sampling with truncated normal distributions. For that reason, several of the Bayesian estimation functions in <span class="pkg">wiqid</span> use the probit link.
</p>
<p>The form of the logit and probit links are shown in the figure below.
</p>
<p><img src="../help/figures/linkFunctions.jpg" alt="linkFunctions.jpg" />
</p>
<p>Both curves are symmetric, with probability = 0.5 when the linear predictor = 0. The probit curve is steeper, so coefficients in a probit regression will be smaller than those in a logit regression (by a factor of about 1.7).
</p>

<hr>
<h2 id='MeadowVoles'>
Robust design mark-recapture data for meadow voles
</h2><span id='topic+MeadowVoles'></span>

<h3>Description</h3>

<p>Data for adult male meadow voles <em>Microtus pennsylvanicus</em> from a live-trapping study at Patuxent Wildlife Research Center (Nichols et al 1984). Trapping was carried out for 5 consecutive nights each month for 6 months (June to December 1981).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(MeadowVoles)</code></pre>


<h3>Format</h3>

<p>A data frame with 171 observations on the following 31 variables.
</p>

<dl>
<dt>A1, A2, A3, A4, A5, B1, B2, B3, B4, B5, C1, C2, C3, C4, C5, D1, D2, D3, D4, D5, E1, E2, E3, E4, E5, F1, F2, F3, F4, F5</dt><dd><p>a 1/0 array of capture data for voles for each of 5 occasions per month for 6 months. </p>
</dd>
<dt>freq</dt><dd><p>a column with -1/1, where -1 indicates that the animal was not released after the last recorded capture.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data are provided as a data frame, such as would result from reading in data from a text file. Further formatting is needed before using these for analysis: see the examples. 
</p>


<h3>Source</h3>

<p>Williams, Nichols, Conroy (2002) <em>Analysis and Management of Animal Populations: Modeling, Estimation, and Decision Making</em> Academic Press, San Diego CA
</p>


<h3>References</h3>

<p>Nichols, Pollock, Hines (1984) The use of a robust capture-recapture design in small mammal population studies: A field example with <em>Microtus pennsylvanicus.</em> <em>Acta Theriologica</em> 29:357-365.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(MeadowVoles)

# Extract detection histories:
DH &lt;- MeadowVoles[, 1:30]
freq &lt;- MeadowVoles$freq

survRD(DH, freq=freq, occsPerSeason=5)

</code></pre>

<hr>
<h2 id='occ2sps'>
Single-season two-species occupancy estimation
</h2><span id='topic+occ2sps'></span>

<h3>Description</h3>

<p>Estimates occupancy and probability of detection for two species, where one (dominant) species affects the occupancy or detection of the other (subordinate) species (see Richmond et al, 2010). The model has the following parameters:
</p>

<table>
<tr>
 <td style="text-align: left;">
  psiA </td><td style="text-align: left;"> probability of occupancy of species A </td>
</tr>
<tr>
 <td style="text-align: left;">
  psiBa </td><td style="text-align: left;"> probability of occupancy of B if A is absent </td>
</tr>
<tr>
 <td style="text-align: left;">
  psiBA </td><td style="text-align: left;"> probability of occupancy of B if A is present </td>
</tr>
<tr>
 <td style="text-align: left;">
  pA </td><td style="text-align: left;"> probability of detection of species A if B is absent </td>
</tr>
<tr>
 <td style="text-align: left;">
  rA </td><td style="text-align: left;"> probability of detection of species A if both are present </td>
</tr>
<tr>
 <td style="text-align: left;">
  pB </td><td style="text-align: left;"> probability of detection of species B if A is absent </td>
</tr>
<tr>
 <td style="text-align: left;">
  rBa </td><td style="text-align: left;"> probability of detection of species B if both are present but A was not detected </td>
</tr>
<tr>
 <td style="text-align: left;">
  rBA </td><td style="text-align: left;"> probability of detection of species B if both are present and A was detected</td>
</tr>

</table>
 

<h3>Usage</h3>

<pre><code class='language-R'>occ2sps(DHA, DHB, model=NULL, data=NULL, ci = 0.95, verify=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="occ2sps_+3A_dha">DHA</code></td>
<td>

<p>a 1/0/NA matrix (or data frame) of detection histories, sites x occasions, for the dominant species.
</p>
</td></tr>
<tr><td><code id="occ2sps_+3A_dhb">DHB</code></td>
<td>

<p>detection histories for the subordinate species in the same format as DHA.
</p>
</td></tr>
<tr><td><code id="occ2sps_+3A_model">model</code></td>
<td>

<p>a list of formulae symbolically defining a linear predictor for any of the parameters in the model. The default, NULL, is equivalent to <code>list(psiA~1, psiBa~1, pA~1, pB~1)</code>; parameters not included in the list are given the following values: <code>psiBA &lt;- psiBa, rA &lt;- pA, rBa &lt;- pB, rBA &lt;- rBa</code>.
</p>
</td></tr>
<tr><td><code id="occ2sps_+3A_data">data</code></td>
<td>

<p>a data frame containing the variables in the model. If <code>data = NULL</code>, a faster algorithm is used, and any covariates in the model will be ignored.
</p>
</td></tr>
<tr><td><code id="occ2sps_+3A_ci">ci</code></td>
<td>

<p>the confidence interval to use.
</p>
</td></tr>
<tr><td><code id="occ2sps_+3A_verify">verify</code></td>
<td>

<p>if TRUE, the data provided will be checked.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>wiqid</code>, see <a href="#topic+wiqid-class">wiqid-class</a> for details.
</p>


<h3>Benchmarks</h3>

<p>Output has been checked against output from PRESENCE (Hines 2006) v.5.5 for the <code><a href="#topic+railSims">railSims</a></code> data set. Real values are  the same to 4 decimal places, and AICs are the same.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith
</p>


<h3>References</h3>

<p>Richmond, Hines, Beissinger (2010) Two-species occupancy models: a new parameterization applied to co-occurrence of secretive rails. <em>Ecological Applications</em> 20(7):2036-2046
</p>
<p>MacKenzie, D I; J D Nichols; A J Royle; K H Pollock; L L Bailey; J E Hines 2006. <em>Occupancy Estimation and Modeling : Inferring Patterns and Dynamics of Species Occurrence</em>. Elsevier Publishing.
</p>


<h3>See Also</h3>

<p>See the example data set <code><a href="#topic+railSims">railSims</a></code>. See <code><a href="#topic+occSS">occSS</a></code> for single-season single-species occupancy estimation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(railSims)
# Extract the two detection histories
DHA &lt;- railSims[, 1:3]
DHB &lt;- railSims[, 4:6]

# Default model (no interaction)
occ2sps(DHA, DHB)

  
# Add a submodel for psiBA, so that psiBA and psiBa are separated:
occ2sps(DHA, DHB, model = psiBA ~ 1)

# Add covariates for psiA and psiBA; only display beta coefficients:
occ2sps(DHA, DHB, model = list(psiA ~ logArea, psiBA ~ reeds), data=railSims)$beta

# Model corresponding to the data generation model
occ2sps(DHA, DHB, list(psiA ~ logArea, psiBA ~ reeds, rBA ~ 1), data=railSims)$beta

</code></pre>

<hr>
<h2 id='Occupancy+20Multi-Season'>
Multi-season occupancy estimation
</h2><span id='topic+occMS0'></span><span id='topic+occMStime'></span><span id='topic+occMS'></span><span id='topic+occMScovSite'></span>

<h3>Description</h3>

<p>Functions to estimate occupancy from detection/non-detection data for multiple seasons. <code>occMS</code> is the general purpose function; it allows for site-, season- and survey-level covariates, but it is slow. <code>occMScovSite</code> excludes survey-level covariates, but is fast. <code>occMStime</code> and <code>occMS0</code> are simpler and faster.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>occMS0(DH, occsPerSeason, ci=0.95, verify=TRUE, ...)

occMStime(DH, occsPerSeason, model=NULL, data=NULL, ci=0.95, verify=TRUE, ...)

occMS(DH, occsPerSeason, model=NULL, data=NULL, ci=0.95, verify=TRUE, ...)
             
occMScovSite(DH, occsPerSeason, model=NULL, data=NULL, ci=0.95, verify=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Occupancy+2B20Multi-Season_+3A_dh">DH</code></td>
<td>

<p>a 1/0/NA matrix (or data frame) of detection histories, sites x occasions. Rows with all NAs are silently removed.
</p>
</td></tr>
<tr><td><code id="Occupancy+2B20Multi-Season_+3A_occsperseason">occsPerSeason</code></td>
<td>

<p>the number of survey occasions per season; either a scalar if the number of surveys is constant, or a vector with one element for each season.
</p>
</td></tr>
<tr><td><code id="Occupancy+2B20Multi-Season_+3A_model">model</code></td>
<td>

<p>a list of formulae symbolically defining a linear predictor for each parameter in terms of covariates. The default corresponds to an intercept-only model.
</p>
</td></tr>
<tr><td><code id="Occupancy+2B20Multi-Season_+3A_data">data</code></td>
<td>

<p>a data frame containing the variables in the model: one row for each season or between-season period for <code>occMStime</code> and one for each site for <code>occMScovSite</code>. Each survey covariate has one column for each occasion, and the column name must end with the occasion number (without leading zeros); eg, <code>Cov1, Cov2, ..., Cov15</code>.
</p>
</td></tr>
<tr><td><code id="Occupancy+2B20Multi-Season_+3A_ci">ci</code></td>
<td>

<p>the confidence interval to use.
</p>
</td></tr>
<tr><td><code id="Occupancy+2B20Multi-Season_+3A_verify">verify</code></td>
<td>

<p>if TRUE, the data provided will be checked.
</p>
</td></tr>
<tr><td><code id="Occupancy+2B20Multi-Season_+3A_...">...</code></td>
<td>

<p>other arguments passed to <code><a href="stats.html#topic+nlm">nlm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>occMS0</code> implements a simple multi-season model with one parameter each for initial occupancy, colonisation, local extinction, and probability of detection, ie. a <code>psi1(.) gamma(.) epsilon(.) p(.)</code> model.
</p>
<p><code>occMStime</code> allows for between-season differences in colonisation, local extinction, and probability of detection, either with covariates given in <code>data</code> or the in-built covariates <code>.interval</code> (for colonisation or extinction, or <code>.season</code> (for detection).
</p>
<p><code>occMScovSite</code> allows for between-season differences in colonisation, local extinction, and probability of detection with the in-built covariate <code>.season</code> and for between-site differences with covariates defined in <code>data</code>.
</p>
<p><code>occMS</code> allows for survey-level covariates in addition to the above, and separate covariates for between-season colonisation and local extinction.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>wiqid</code>, see <a href="#topic+wiqid-class">wiqid-class</a> for details.
</p>


<h3>Benchmarks</h3>

<p>Output has been checked against output from PRESENCE (Hines 2006) v.5.5 for the <code><a href="#topic+GrandSkinks">GrandSkinks</a></code> data set. Real values are mostly the same to 4 decimal places, though there is occasionally a discrepancy of 0.0001. AICs are the same.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith
</p>


<h3>References</h3>

<p>MacKenzie, D I; J D Nichols; G B Lachman; S Droege; J A Royle; C A Langtimm. 2002. Estimating site occupancy rates when detection probabilities are less than one. <em>Ecology</em> 83:2248-2255.
</p>
<p>MacKenzie, D I; J D Nichols; A J Royle; K H Pollock; L L Bailey; J E Hines 2006. <em>Occupancy Estimation and Modeling : Inferring Patterns and Dynamics of Species Occurrence</em>. Elsevier Publishing.
</p>
<p>Hines, J. E. (2006). PRESENCE - Software to estimate patch occupancy and related parameters. SGS-PWRC. http://www.mbr-pwrc.usgs.gov/software/presence.html.
</p>
<p>MacKenzie, D I; J D Nichols; J E Hines; et al 2003. Estimating site occupancy, colonization, and local extinction when a species is imperfectly detected.  <em>Ecology</em> 84, 2200-2207.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(GrandSkinks)
DH &lt;- GrandSkinks[, 1:15]

occMS0(DH, 3)

occMStime(DH, 3, model=list(gamma ~ .interval, epsilon~1, p~.season))
occMScovSite(DH, 3,
   model=list(psi1~habitat, gamma ~ .interval, epsilon~habitat, p~.season),
   data=GrandSkinks)

</code></pre>

<hr>
<h2 id='Occupancy+20Single+20Season'>
Single-season occupancy estimation
</h2><span id='topic+occSS0'></span><span id='topic+occSStime'></span><span id='topic+occSScovSite'></span><span id='topic+occSS'></span>

<h3>Description</h3>

<p>Functions to estimate occupancy from detection/non-detection data for a single season. <code>occSS</code> is the general-purpose function, and <code>occSStime</code> provides plots of detection probability against time. <code>occSS0</code> and <code>occSScovSite</code> are faster functions for simpler models with summarized data. See <code>occSSrn</code> for the Royle-Nichols model for abundance-induced heterogeneity in detection probability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>occSS(DH, model=NULL, data = NULL, ci=0.95, link=c("logit", "probit"), verify=TRUE, ...)

occSStime(DH, model=p~1, data=NULL, ci=0.95, plot=TRUE, link=c("logit", "probit"),
  verify=TRUE, ...)

occSS0(y, n, ci=0.95, link=c("logit", "probit"), ...)

occSScovSite(y, n, model=NULL, data = NULL, ci=0.95, link=c("logit", "probit"), ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Occupancy+2B20Single+2B20Season_+3A_dh">DH</code></td>
<td>

<p>a 1/0/NA matrix (or data frame) of detection histories, sites x occasions.
</p>
</td></tr>
<tr><td><code id="Occupancy+2B20Single+2B20Season_+3A_model">model</code></td>
<td>

<p>a list of formulae symbolically defining a linear predictor for each parameter in terms of covariates. If NULL, an intercept-only model is used, ie, psi(.) p(.).
</p>
</td></tr>
<tr><td><code id="Occupancy+2B20Single+2B20Season_+3A_ci">ci</code></td>
<td>

<p>the confidence interval to use.
</p>
</td></tr>
<tr><td><code id="Occupancy+2B20Single+2B20Season_+3A_data">data</code></td>
<td>

<p>a data frame containing the variables in the model. For <code>occSStime</code>, a data frame with a row for each survey occasion; otherwise, a row for each site. Each site covariate has one column. Each survey covariate has one column for each occasion, and the column name must end with the occasion number (without leading zeros); eg, <code>Cov1, Cov2, ..., Cov15</code>. All covariates should be included in <code>data</code>, otherwise they will be sought in enclosing environments, which may not produce what you want &ndash; and they won't be standardised.
</p>
</td></tr>
<tr><td><code id="Occupancy+2B20Single+2B20Season_+3A_link">link</code></td>
<td>

<p>the link function to use, either logit or probit; see <a href="#topic+Links">Links</a>.
</p>
</td></tr>
<tr><td><code id="Occupancy+2B20Single+2B20Season_+3A_verify">verify</code></td>
<td>

<p>if TRUE, the data provided will be checked.
</p>
</td></tr>
<tr><td><code id="Occupancy+2B20Single+2B20Season_+3A_plot">plot</code></td>
<td>

<p>if TRUE (default), draws a plot of probability of detection vs time.
</p>
</td></tr>
<tr><td><code id="Occupancy+2B20Single+2B20Season_+3A_y">y</code></td>
<td>

<p>a vector with the number of detections at each site.
</p>
</td></tr>
<tr><td><code id="Occupancy+2B20Single+2B20Season_+3A_n">n</code></td>
<td>

<p>a scalar or vector with the number of visits (survey occasions) at each site.
</p>
</td></tr>
<tr><td><code id="Occupancy+2B20Single+2B20Season_+3A_...">...</code></td>
<td>

<p>other arguments passed to <code><a href="stats.html#topic+nlm">nlm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>occSS</code> allows for psi or p to be modelled as a logistic or probit function of site covariates or survey covariates, as specified by <code>model</code>. It includes a built in <code>.time</code> covariate which can be used for modelling p with time as a fixed effect, and <code>.Time, .Time2, .Time3</code> for a linear, quadratic or cubic trend. A built-in <code>.b</code> covariate corresponds to a behavioural effect, where detection depends on whether the species was detected on the previous occasion or not.
</p>
<p><code>occSStime</code> allows for time-varying covariates that are the same across all sites, eg, moon-phase. Time variables are built in, as for <code>occSS</code>. A plot of detection probability vs time is produced if <code>plot=TRUE</code>.
</p>
<p><code>occSS0</code> implements a simple model with one parameter for probability of occupancy and one for probability of detection, ie. a <code>psi(.) p(.)</code> model.
</p>
<p><code>occSScovSite</code> allows for site covariates but not for occasion or survey covariates.
</p>
<p>Numeric covariates in <code>data</code> are standardised to facilitate convergence. This applies to binary covariates coded as 1/0; if this is not what you want, code these as TRUE/FALSE or as factors.
</p>
<p>For speed, use the simplest function which will cope with your model. For example, you can run psi(.) p(.) models in <code>occSScovSite</code> or <code>occSS</code>, but <code>occSS0</code> is much faster.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>wiqid</code>, see <a href="#topic+wiqid-class">wiqid-class</a> for details.
</p>


<h3>Benchmarks</h3>

<p>Output has been checked against output from PRESENCE (Hines 2006) v.5.5 for the <code><a href="#topic+salamanders">salamanders</a></code> and <code><a href="#topic+weta">weta</a></code> data sets. Real values are mostly the same to 4 decimal places, though there is occasionally a discrepancy of 0.0001. AICs are the same.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith
</p>


<h3>References</h3>

<p>MacKenzie, D I; J D Nichols; G B Lachman; S Droege; J A Royle; C A Langtimm. 2002. Estimating site occupancy rates when detection probabilities are less than one. <em>Ecology</em> 83:2248-2255.
</p>
<p>MacKenzie, D I; J D Nichols; A J Royle; K H Pollock; L L Bailey; J E Hines 2006. <em>Occupancy Estimation and Modeling : Inferring Patterns and Dynamics of Species Occurrence</em>. Elsevier Publishing.
</p>
<p>Hines, J. E. (2006). PRESENCE - Software to estimate patch occupancy and related parameters. SGS-PWRC. http://www.mbr-pwrc.usgs.gov/software/presence.html.
</p>


<h3>See Also</h3>

<p>See the examples for the <code><a href="#topic+weta">weta</a></code> data set. See <code><a href="#topic+occ2sps">occ2sps</a></code> for single-season two-species models and <code><a href="#topic+occMS">occMS</a></code> for multi-season models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># The blue ridge salamanders data from MacKenzie et al (2006) p99:
data(salamanders)
occSS(salamanders)
occSStime(salamanders, p ~ .time)  # time as a fixed effect
occSStime(salamanders, p ~ .Time + .Time2)  # a quadratic time effect
occSS(salamanders, p ~ .b)

# or use the fast functions with y, n format:
y &lt;- rowSums(salamanders)
n &lt;- rowSums(!is.na(salamanders))
occSS0(y, n)
occSScovSite(y, n)

</code></pre>

<hr>
<h2 id='plot.Bwiqid'>
Plot method for objects of class 'Bwiqid'
</h2><span id='topic+plot.Bwiqid'></span>

<h3>Description</h3>

<p>Method to display a plot showing the posterior probability distribution of one of the parameters of interest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'Bwiqid'
plot(x, which=NULL, credMass=0.95,
           ROPE=NULL, compVal=NULL, showCurve=FALSE,
           showMode=FALSE, shadeHDI=NULL,  ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.Bwiqid_+3A_x">x</code></td>
<td>

<p>an object of class <code>Bwiqid</code>.
</p>
</td></tr>
<tr><td><code id="plot.Bwiqid_+3A_which">which</code></td>
<td>

<p>character: indicates which parameter to plot. If NULL and <code>x</code> has a <code>defaultPlot</code> attribute, that parameter is plotted; otherwise the parameter in column 1 is plotted.
</p>
</td></tr>
<tr><td><code id="plot.Bwiqid_+3A_credmass">credMass</code></td>
<td>

<p>the probability mass to include in credible intervals; NULL suppresses plotting.
</p>
</td></tr>
<tr><td><code id="plot.Bwiqid_+3A_rope">ROPE</code></td>
<td>

<p>a two element vector, such as <code>c(-1, 1)</code>, specifying the limit of the ROPE on the estimate; see Details.
</p>
</td></tr>
<tr><td><code id="plot.Bwiqid_+3A_compval">compVal</code></td>
<td>

<p>a value for comparison with the parameter.
</p>
</td></tr>
<tr><td><code id="plot.Bwiqid_+3A_showcurve">showCurve</code></td>
<td>

<p>logical: if TRUE, the posterior density will be represented by a kernel density function instead of a histogram.
</p>
</td></tr>
<tr><td><code id="plot.Bwiqid_+3A_showmode">showMode</code></td>
<td>

<p>logical: if TRUE, the mode of the posterior density will be shown instead of the mean.
</p>
</td></tr>
<tr><td><code id="plot.Bwiqid_+3A_shadehdi">shadeHDI</code></td>
<td>

<p>specifies a colour to shade the area under the curve corresponding to the HDI; NULL for no shading. Ignored if <code>showCurve = FALSE</code>. Use<code>colours()</code> to see a list of possible colours.
</p>
</td></tr>
<tr><td><code id="plot.Bwiqid_+3A_...">...</code></td>
<td>

<p>other graphical parameters.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The posterior distribution is shown as a histogram or density curve (if <code>showCurve = TRUE</code>), together with the Highest Density Interval. A ROPE and comparison value are also shown if appropriate.
</p>
<p>The probability that a parameter precisely zero (or has any other point value) is zero. More interesting is the probability that the difference from zero may be too small to matter. We can define a region of practical equivalence (ROPE) around zero, and obtain the posterior probability that the true value lies therein.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>histogram</code> invisibly. Used mainly for the side effect.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith, adapted from code by John Kruschke.
</p>


<h3>References</h3>

<p>Kruschke, J. K. 2013. Bayesian estimation supersedes the <em>t</em> test. <em>Journal of Experimental Psychology: General</em> 142(2):573-603. doi: 10.1037/a0029146
</p>


<h3>See Also</h3>

<p><code><a href="mcmcOutput.html#topic+postPlot">postPlot</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See examples in dippers.
</code></pre>

<hr>
<h2 id='plotACs'>
Plot Activity Centres from <code>Bsecr0</code> output
</h2><span id='topic+plotACs'></span>

<h3>Description</h3>

<p>Plot posterior distributions of Activity Centre (AC) locations using the output from <code><a href="#topic+Bsecr0">Bsecr0</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotACs(object, which=NA, howMany=3000, showLabels=TRUE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotACs_+3A_object">object</code></td>
<td>

<p>a <code>Bwiqid</code> object with ACs attribute</p>
</td></tr>
<tr><td><code id="plotACs_+3A_which">which</code></td>
<td>

<p>a numeric vector indication which ACs to plot, default is to plot all.
</p>
</td></tr>
<tr><td><code id="plotACs_+3A_howmany">howMany</code></td>
<td>

<p>the number of points to plot for each AC</p>
</td></tr>
<tr><td><code id="plotACs_+3A_showlabels">showLabels</code></td>
<td>

<p>if TRUE, point clusters for animals detected will be labelled with the animal ID.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns nothing, used for its plotting side effect.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith
</p>

<hr>
<h2 id='plotComb'>
Display a posterior probability distribution from the comb method
</h2><span id='topic+plotComb'></span>

<h3>Description</h3>

<p>Plot the posterior probability distribution for a single parameter calculated using the comb method described by Kruschke (2015).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotComb(x, y, credMass = 0.95, plot = TRUE, showMode = FALSE, shadeHDI = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotComb_+3A_x">x</code></td>
<td>

<p>A vector of equally-spaced possible values for the parameter. The range should cover all values of the parameter with non-negligible probability. (To restrict the range displayed in the plot, use <code>xlim</code>.)
</p>
</td></tr>
<tr><td><code id="plotComb_+3A_y">y</code></td>
<td>

<p>A vector of probabilities corresponding to the values in <code>x</code>.
</p>
</td></tr>
<tr><td><code id="plotComb_+3A_credmass">credMass</code></td>
<td>

<p>the probability mass to include in credible intervals; set to NULL to suppress plotting of credible intervals.
</p>
</td></tr>
<tr><td><code id="plotComb_+3A_plot">plot</code></td>
<td>

<p>logical: if TRUE, the posterior is plotted.
</p>
</td></tr>
<tr><td><code id="plotComb_+3A_showmode">showMode</code></td>
<td>

<p>logical: if TRUE, the mode is displayed instead of the mean.
</p>
</td></tr>
<tr><td><code id="plotComb_+3A_shadehdi">shadeHDI</code></td>
<td>

<p>specifies a colour to shade the area under the curve corresponding to the HDI; NULL for no shading. Use<code>colours()</code> to see a list of possible colours.
</p>
</td></tr>
<tr><td><code id="plotComb_+3A_...">...</code></td>
<td>

<p>additional graphical parameters.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calculates the Highest Density Interval (HDI). A multi-modal distribution may have a disjoint HDI, in which case the ends of each segment are calculated. No interpolation is done, and the end points correspond to values of the parameter in <code>x</code>; precision will be determined by the resolution of <code>x</code>.
</p>
<p>If <code>plot = TRUE</code>, the probability density is plotted together with either the mean or the mode and the HDI.
</p>
<p><img src="../help/figures/plotPost2.jpg" alt="plotPost2.jpg" />
</p>


<h3>Value</h3>

<p>Returns a matrix with the upper and lower limits of the HDI. If the HDI is disjoint, this matrix will have more than 1 row. It has attributes <code>credMass</code> and <code>height</code>, giving the height of the probability curve corresponding to the ends of the HDI.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith
</p>


<h3>See Also</h3>

<p>For details of the HDI calculation, see <code><a href="HDInterval.html#topic+hdi">hdi</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some data:
N &lt;- 0:100
post &lt;- dpois(N, 25)
# Do the plots:
plotComb(N, post)
plotComb(N, post, showMode=TRUE, shadeHDI='pink', xlim=c(10, 50))

# A bimodal distribution:
post2 &lt;- (dnorm(N, 28, 8) + dnorm(N, 70, 11)) / 2
plotComb(N, post2, credMass=0.99, shade='pink')
plotComb(N, post2, credMass=0.80, shade='grey')

</code></pre>

<hr>
<h2 id='predict.wiqid'>
Predict method for objects of class 'wiqid'
</h2><span id='topic+predict.wiqid'></span>

<h3>Description</h3>

<p>Obtains predictions, with estimates, standard errors and confidence intervals, from a fitted model object of class <code>wiqid</code>, as produced by frequentist estimation functions in the <span class="pkg">wiqid</span> package. Not all functions produce objects that enable predictions to be made; see Details. Please treat this as a 'beta' version and check output carefully.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'wiqid'
predict(object, newdata, parameter, ci, type=c("link", "response"), ...) 
    
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.wiqid_+3A_object">object</code></td>
<td>

<p>an object of class <code>wiqid</code>.
</p>
</td></tr>
<tr><td><code id="predict.wiqid_+3A_newdata">newdata</code></td>
<td>

<p>a data frame with columns for each of the covariates in the model. Unused columns are ignored. Missing values are not allowed. See Details.
</p>
</td></tr>
<tr><td><code id="predict.wiqid_+3A_parameter">parameter</code></td>
<td>

<p>character; the name of the parameter to predict; this will appear on the left hand side of one of the formulae in the model.
</p>
</td></tr>
<tr><td><code id="predict.wiqid_+3A_ci">ci</code></td>
<td>

<p>the confidence interval to use; the default is to use <code>object$ci</code> or, if that is <code>NULL</code>, 0.95.
</p>
</td></tr>
<tr><td><code id="predict.wiqid_+3A_type">type</code></td>
<td>

<p>the type of prediction required. The default is on the scale of the linear predictors; the alternative &quot;response&quot; is on the scale of the response variable. Thus if the parameter is a probability, the default predictions are on the logit or probit scale and <code>type = "response"</code> gives the predicted probabilities. May be abbreviated.
</p>
</td></tr>
<tr><td><code id="predict.wiqid_+3A_...">...</code></td>
<td>

<p>further arguments for other methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Most <span class="pkg">wiqid</span> functions have models with multiple submodels, corresponding to the formulae in the <code>model</code> argument. Check <code>object$formulae</code> for a list of the available submodels.
</p>
<p>The argument <code>newdata</code> is required (even for intercept-only models), and must be a data frame with named columns for each of the covariates in the submodel. For factors, the levels must be (a subset of) the levels in the original data; check <code>object$xlev</code> for possible levels.
</p>
<p><code>predict</code> is not yet implemented for the following functions:
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code>occSStime</code> and <code>occSScovSite</code> </td><td style="text-align: left;"> : use <code>occSS</code> instead.</td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>occMStime</code> and <code>occMScovSite</code> </td><td style="text-align: left;"> : use <code>occMS</code> instead.</td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>closedCap*</code> functions </td><td style="text-align: left;"> : these models have no covariates.</td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>surv*</code> functions </td><td style="text-align: left;"> : these have no covariates.</td>
</tr>

</table>



<h3>Value</h3>

<p>Returns a matrix with four columns (estimate, SE, lower and upper confidence limits) and a row for each row in <code>newdata</code>. If <code>newdata</code> has row names, these will be used for the output. Note that for an intercept-only submodel, all rows will have identical values. Attributes give information on the link used and the confidence level.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some simulated occupancy data for 300 sites:
set.seed(2017)
original.data &lt;- data.frame(
  elev = runif(300, 0, 1000),
  forType = factor(sample(c("dry", "swamp", "mangrove"), size=300, replace=TRUE, prob=3:1)))
modMat &lt;- model.matrix( ~ elev + forType, data = original.data)
psiCoef &lt;- c(3, -0.003, -3, -1) # declines with 'elev'; highest for 'dry', lowest 'mangrove'
psi &lt;- plogis(modMat %*% psiCoef)
hist(psi, breaks=20)
z &lt;- rbinom(300, 1, psi)
mean(z)  # true realized occupancy
# detection history for 3 replicates, constant p = 0.6:
DH &lt;- matrix(rbinom(300*3, 1, 0.6*z), nrow=300)
# fit models
m0 &lt;- occSS(DH)
mE &lt;- occSS(DH, psi ~ elev, data = original.data)
mEF &lt;- occSS(DH, psi ~ elev + forType, data = original.data)

# now try predictions:
newdata &lt;- expand.grid(elev=c(200, 500, 800), forType=c("dry", "swamp"))
predict(mEF, newdata, "psi")
cbind(newdata, predict(mEF, newdata, "psi", type='res'))
cbind(newdata, predict(mE, newdata, "psi", type='res'))
cbind(newdata, predict(m0, newdata, "psi", type='res'))

# do a nice plot
xx &lt;- seq(0, 1000, length=51)
plotdata &lt;- expand.grid(elev=xx, forType=c("dry", "swamp", "mangrove"))
toPlot &lt;- predict(mEF, plotdata, "psi", type='res')
plot(xx, rep(0.5, 51), type='n', las=1, ylim=range(toPlot),
  xlab="Elevation", ylab="Occupancy probability")
ciCols &lt;- adjustcolor(c('lightgreen', 'skyblue', 'pink'), 0.5)
estCols &lt;- c('darkgreen', 'blue', 'red')
for(i in 1:3) {
  this1 &lt;- toPlot[plotdata$forType == levels(plotdata$forType)[i], ]
  polygon(c(xx, rev(xx)), c(this1[, 3], rev(this1[, 4])), col=ciCols[i])
  lines(xx, this1[, 1], col=estCols[i])
}
legend('topright', levels(plotdata$forType), lty=1, col=estCols, bty='n')

# Add a survey-level covariate: observer ID with different detection probabilities
observer &lt;- c(sample(1:2, size=300, replace=TRUE),  # A and B on first survey occasion
              sample(1:3, size=300, replace=TRUE),  # A, B and C for second
              sample(2:3, size=300, replace=TRUE))  # only B and C for third
obsID &lt;- matrix(LETTERS[observer], nrow=300)
colnames(obsID) &lt;- c("obs1", "obs2", "obs3")
original.data &lt;- cbind(original.data, as.data.frame(obsID))
str(original.data)
p &lt;- c(0.4, 0.6, 0.8)[observer]
DH &lt;- matrix(rbinom(300*3, 1, p*z), nrow=300)
mEFO &lt;- occSS(DH, list(psi ~ elev + forType, p ~ obs), data = original.data)
# Check the categorical covariate names and levels:
mEFO$xlev
predict(mEFO, data.frame(obs=c("A", "B", "C")), "p")
predict(mEFO, data.frame(obs=c("A", "B", "C")), "p", type="resp")

</code></pre>

<hr>
<h2 id='predictAvg'>
Predict average values from multiple fitted models
</h2><span id='topic+predictAvg'></span>

<h3>Description</h3>

<p>Produce model-averaged estimates of predictions from multiple models of the same type fitted with a function in the <span class="pkg">wiqid</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictAvg(modList, newdata, parameter, ci=0.95, type=c("link", "response"), IC=AICc)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictAvg_+3A_modlist">modList</code></td>
<td>

<p>a list of fitted model objects of class <code>wiqid</code>.
</p>
</td></tr>
<tr><td><code id="predictAvg_+3A_newdata">newdata</code></td>
<td>

<p>a data frame with columns for each of the covariates in the model. Unused columns are ignored. Missing values are not allowed. See Details.
</p>
</td></tr>
<tr><td><code id="predictAvg_+3A_parameter">parameter</code></td>
<td>

<p>character; the name of the parameter to predict; this will appear on the left hand side of one of the formulae in the model.
</p>
</td></tr>
<tr><td><code id="predictAvg_+3A_ci">ci</code></td>
<td>

<p>the confidence interval to use.
</p>
</td></tr>
<tr><td><code id="predictAvg_+3A_type">type</code></td>
<td>

<p>the type of prediction required. The default is on the scale of the linear predictors; the alternative &quot;response&quot; is on the scale of the response variable. Thus if the parameter is a probability, the default predictions are on the logit or probit scale and <code>type = "response"</code> gives the predicted probabilities. May be abbreviated.
</p>
</td></tr>
<tr><td><code id="predictAvg_+3A_ic">IC</code></td>
<td>

<p>the information criterion function to use to calculate model weights.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calls <code>predict</code> with each of the models in <code>modList</code> in turn to obtain predictions (estimates and SEs). The information criterion specified by <code>IC</code> is applied to each model to get model weights, and these are used to average the estimates.
</p>
<p>The algorithm to calculate the SEs (and hence CIs) of the model-averaged estimates follows Anderson (2008, p.111).
</p>


<h3>Value</h3>

<p>Returns a matrix with four columns (estimate, SE, lower and upper confidence limits) and a row for each row in <code>newdata</code>. If <code>newdata</code> has row names, these will be used for the output. Attributes give information on the link used and the confidence level.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith.
</p>


<h3>References</h3>

<p>Anderson, D.R. (2008) <em>Model based inference in the life sciences: a primer on evidence</em>. Springer Science + Business Media, New York NY.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toves)

# Extract detection histories
DH &lt;- toves[, 1:4]

# Fit some models
m.1 &lt;- occSS(DH, psi ~ x1, data=toves)
m.12 &lt;- occSS(DH, psi ~ x1 + x2, data=toves)
m.13 &lt;- occSS(DH, psi ~ x1 + x3, data=toves)
m.123 &lt;- occSS(DH, psi ~ x1 + x2 + x3, data=toves)
m.23 &lt;- occSS(DH, psi ~ x2 + x3, data=toves)
AICtable(AICc(m.1, m.12, m.13, m.123, m.23))

# Covariate x1 is essential, x3 is unnecessary, and there's
#   doubt about x2, as the difference in AICc between m.1 and m.12
#   is small.
# We'll use m.1 and m.12 to get model-averaged estimates  of 'psi' for
#   the first 10 sites in the data set.

newdata &lt;- toves[1:10, ]

psi.ma &lt;- predictAvg(list(m.1, m.12), newdata, "psi", type="response")

# Get estimates for the individual models and plot
psi.1 &lt;- predict(m.1, newdata, parameter="psi", type="response")
psi.12 &lt;- predict(m.12, newdata, parameter="psi", type="response")

require(graphics)
plot(1:10, psi.ma[,1], xlab="Site number", ylab="psi", pch=16, cex=1.5,
    las=1, ylim=0:1, xlim=c(0.5, 10.5))
arrows(1:10, psi.ma[,3], 1:10, psi.ma[,4], angle=90, length=0.03, code=3, lwd=2)
# Add values from psi.1 and psi.12
points(1:10 - 0.2, psi.1[,1], col='red')
arrows(1:10 - 0.2, psi.1[,3], 1:10 - 0.2, psi.1[,4],
    angle=90, length=0.03, code=3, col='red')
points(1:10 + 0.2, psi.12[,1], pch=2, col='blue')
arrows(1:10 + 0.2, psi.12[,3], 1:10 + 0.2, psi.12[,4],
    angle=90, length=0.03, code=3, col='blue')
</code></pre>

<hr>
<h2 id='print.Bwiqid'>
Print and summary methods for objects of class 'Bwiqid'
</h2><span id='topic+print.Bwiqid'></span><span id='topic+summary.Bwiqid'></span>

<h3>Description</h3>

<p>Both functions print details of the MCMC process to the Console. <code>print</code> also prints a table of summary statistics for the parameters and several MCMC diagnostic measures to the Console, while <code>summary</code> returns invisibly a corresponding data frame, which can be passed to <code>View</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Bwiqid'
print(x, digits=3, ...)

## S3 method for class 'Bwiqid'
summary(object, digits=3, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.Bwiqid_+3A_x">x</code>, <code id="print.Bwiqid_+3A_object">object</code></td>
<td>

<p>an object of class <code>Bwiqid</code>.
</p>
</td></tr>
<tr><td><code id="print.Bwiqid_+3A_digits">digits</code></td>
<td>

<p>the number of digits to print or include in the output.
</p>
</td></tr>
<tr><td><code id="print.Bwiqid_+3A_...">...</code></td>
<td>

<p>further arguments for the print or summary function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>print</code> function prints a table with a row for each parameter <em>after</em> removing duplicated rows. Duplication usually arises because a covariate has only a few unique values.
</p>
<p>There are columns for each of the following summary statistics ...
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code>mean</code> </td><td style="text-align: left;"> the mean of each MCMC chain. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>sd</code> </td><td style="text-align: left;">  the standard deviation of each MCMC chain. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>median</code> </td><td style="text-align: left;"> the median of each MCMC chain. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>HDIlo</code> and <code>HDIup</code> </td><td style="text-align: left;"> the lower and upper values of a 95% Highest Density Interval CrI for each MCMC chain. </td>
</tr>

</table>

<p>... and for some or all of the following diagnostics, depending on the MCMC engine used for fitting the model:
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code>n.eff</code> </td><td style="text-align: left;">  the effective chain length for the parameters adjusted for autocorrelation; for stable estimates of credible intervals this should be at least 10,000. See <code><a href="coda.html#topic+effectiveSize">effectiveSize</a></code>.</td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>MCerror</code> </td><td style="text-align: left;"> the Monte Carlo errors for the parameters, expressed as a percentage of the standard deviation. Values less than 5% are acceptable. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>Rhat</code> </td><td style="text-align: left;"> the with potential scale reduction factors for the parameters, which is 1 on convergence and should be &lt; 1.05 for all parameters. See <code><a href="coda.html#topic+gelman.diag">gelman.diag</a></code>. </td>
</tr>

</table>



<h3>Value</h3>

<p><code>print</code> returns <code>x</code> invisibly. <code>summary</code> returns the table of summary statistics.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See examples for dippers.
</code></pre>

<hr>
<h2 id='Priors'> Standardisation and priors </h2><span id='topic+Priors'></span><span id='topic+Standardisation'></span><span id='topic+Standardization'></span>

<h3>Description</h3>

<p>This page documents the priors used in the Bayesian analysis. For logistic models, sensible priors depend on the range of values and thus on the standardisation scheme used, which is also detailed here.
</p>
<p>At present, this represents good intentions! It has not been implemented in all the functions in <span class="pkg">wiqid</span>.
</p>


<h3>Standardisation</h3>

<p>Continuous variables are standardised to facilitate writing models, and optimisation. Standardisation also means that the size of regression coefficients directly reflect the importance of the corresponding variables.
</p>
<p>Binary variables coded as TRUE/FALSE and dummy variables are not changed. To make continuous variables comparable with these, they are centred by subtracting the mean, and then divided by their standard deviation.
</p>
<p>Update: In versions prior to 0.2.x, continuous variables were centred by subtracting the mean, and then divided by <em>two times</em> their standard deviation (Gelman, 2008). With the new default, beta coefficients will be exactly half the size. There may be some rounding errors in the fourth decimal place for other estimates.
</p>
<p>Note that all numerical inputs (ie, <code>is.numeric == TRUE</code>) that appear in the <code>data</code> argument will be standardised, including binary variables coded as 0/1. Variables coded as TRUE/FALSE or as factors are not affected.
</p>
<p>The same standardisation strategy is used for both Bayesian and maximum likelihood functions.
</p>


<h3>Priors for logistic regression coefficients</h3>

<p>Following Gelman et al (2008), we use independent Cauchy priors with centre 0 and scale 10 for the intercept and scale 2.5 for all other coefficients.
</p>


<h3>Priors for probabilities</h3>

<p>We use independent Uniform(0, 1) priors for probabilities.
</p>


<h3>References</h3>

<p>Gelman, A. (2008) Scaling regression inputs by dividing by two standard deviations. <em>Statistics in Medicine</em>, 27, 2865-2873
</p>
<p>Gelman, Jakulin, Pittau and Su (2008) A weakly informative default prior distribution for logistic and other regression models. <em>Annals of Applied Statistics</em> 2, 1360-1383.
</p>

<hr>
<h2 id='railSims'>
Simulated detection/non-detection data for two species of rails
</h2><span id='topic+railSims'></span>

<h3>Description</h3>

<p>A data set for single-season two-species occupancy modelling. See <code><a href="#topic+occ2sps">occ2sps</a></code> for details of these kinds of models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("railSims")</code></pre>


<h3>Format</h3>

<p>A data frame with detection (1) vs non-detection data for 2 species at 160 sites on three occasions.
</p>

<dl>
<dt>A1, A2, A3</dt><dd><p>detection histories for the dominant species on 3 occasions</p>
</dd>
<dt>B1, B2, B3</dt><dd><p>detection histories for the subordinate species on 3 occasions</p>
</dd>
<dt>logArea</dt><dd><p>a continuous site covariate, standardised to mean 0, sd 1</p>
</dd>
<dt>reeds</dt><dd><p>a logical site covariate.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data come from a simulated scenario with the following parameters:
</p>

<table>
<tr>
 <td style="text-align: left;">
  psiA  </td><td style="text-align: left;"> = plogis(0 + 2*logArea) </td><td style="text-align: left;"> = probability of occupancy of species A </td>
</tr>
<tr>
 <td style="text-align: left;">
  psiBa </td><td style="text-align: left;"> = 0.77 </td><td style="text-align: left;"> = probability of occupancy of B if A is absent </td>
</tr>
<tr>
 <td style="text-align: left;">
  psiBA </td><td style="text-align: left;"> = plogis(-1 + 2*reeds) </td><td style="text-align: left;"> = probability of occupancy of B if A is present </td>
</tr>
<tr>
 <td style="text-align: left;">
  pA </td><td style="text-align: left;"> = 0.75 </td><td style="text-align: left;"> = probability of detection of species A if B is absent </td>
</tr>
<tr>
 <td style="text-align: left;">
  rA </td><td style="text-align: left;"> = pA </td><td style="text-align: left;"> = probability of detection of species A if both are present </td>
</tr>
<tr>
 <td style="text-align: left;">
  pB </td><td style="text-align: left;"> = 0.80 </td><td style="text-align: left;"> = probability of detection of species B if A is absent </td>
</tr>
<tr>
 <td style="text-align: left;">
  rBa </td><td style="text-align: left;"> = pB </td><td style="text-align: left;"> = probability of detection of species B if both are present but A was not detected </td>
</tr>
<tr>
 <td style="text-align: left;">
  rBA </td><td style="text-align: left;"> = 0.40 </td><td style="text-align: left;"> = probability of detection of species B if both are present and A was detected</td>
</tr>

</table>



<h3>Source</h3>

<p>Simulated data
</p>


<h3>References</h3>

<p>Richmond, O.M.W., Hines, J.E., &amp; Beissinger, S.R. (2010) Two-species occupancy models: a new parameterization applied to co-occurrence of secretive rails. Ecological Applications, 20, 2036-2046.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(railSims)
# Separate the two detection histories
DHA &lt;- railSims[, 1:3]
DHB &lt;- railSims[, 4:6]

# Default model (no interaction)
occ2sps(DHA, DHB)


# Model with full interaction
occ2sps(DHA, DHB, list(psiBA ~ 1, rA ~ 1, rBa ~ 1, rBA ~ 1))

# Model corresponding to the data generation model
occ2sps(DHA, DHB, list(psiA ~ logArea, psiBA ~ reeds, rBA ~ 1), data=railSims)

</code></pre>

<hr>
<h2 id='richCurve'>
Species richness estimates based on accumulation curves
</h2><span id='topic+richCurve'></span><span id='topic+richSobs'></span><span id='topic+richSingle'></span><span id='topic+richDouble'></span><span id='topic+richUnique'></span><span id='topic+richDuplicate'></span>

<h3>Description</h3>

<p>Provides a shell into which species richness estimators may be plugged to provide estimates based on species accumulation curves, as provided by EstimateS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>richCurve(obsMat, FUNC, runs = 10, ...)

richSobs(incVec)
richSingle(cntVec)
richDouble(cntVec)
richUnique(incMat)
richDuplicate(incMat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="richCurve_+3A_incvec">incVec</code></td>
<td>

<p>a vector of species incidences (presences) in one or more samples; a vector of counts or a species x sites matrix of incidences or counts may be supplied.
</p>
</td></tr>
<tr><td><code id="richCurve_+3A_cntvec">cntVec</code></td>
<td>

<p>a vector of species counts (abundances); a species x sites matrix of counts may be supplied and will be converted to a vector with <code>rowSums</code>.
</p>
</td></tr>
<tr><td><code id="richCurve_+3A_incmat">incMat</code></td>
<td>

<p>a 1/0 matrix of species incidence (presence), species x sites. A matrix of counts may also be provided.
</p>
</td></tr>
<tr><td><code id="richCurve_+3A_obsmat">obsMat</code></td>
<td>

<p>a matrix of species counts, species x sites; a matrix of incidences will be sufficient if accepted by FUNC.
</p>
</td></tr>
<tr><td><code id="richCurve_+3A_func">FUNC</code></td>
<td>

<p>a function to estimate species richness based on a matrix of observations; see <code><a href="#topic+Species+20richness+20estimators">Species richness estimators</a></code> for examples.
</p>
</td></tr>
<tr><td><code id="richCurve_+3A_runs">runs</code></td>
<td>

<p>the number of randomisations of samples (ie. columns in the input matrix) to perform to calculate mean and standard deviation.
</p>
</td></tr>
<tr><td><code id="richCurve_+3A_...">...</code></td>
<td>

<p>additional arguments passed to FUNC.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The reliability of estimates of species richness depends on the sampling effort. To investigate this effect, and judge whether the current sampling effort is adequate, we calculate richness estimates for subsets of the data. Assuming that the columns of the data matrix are independent samples from the population, <code>richCurve</code> calculates estimates for 1 sample, 2 samples, and so on. This is repeated for many runs, and the mean and standard deviation calculated.
</p>
<p>The other functions documented here are trivial, but useful for plugging into <code>richCurve</code>:
</p>
<p><code>richSobs </code> : the number of species observed.
</p>
<p><code>richSingle </code>: the number of singletons, ie. species represented by just 1 individual in the pooled samples.
</p>
<p><code>richDouble </code> : the number of doubletons, ie. species represented by exactly 2 individuals in the pooled samples.
</p>
<p><code>richUnique </code> : the number of uniques, ie. species represented in just one sample.
</p>
<p><code>richDuplicate </code> : the number of duplicates, ie. species represented in exactly 2 samples.
</p>


<h3>Value</h3>

<p><code>richCurve</code> returns a list with elements:
</p>
<table>
<tr><td><code>mean</code></td>
<td>
<p>A matrix (possibly 1-column) with a row for each sample and a column for each value returned by FUNC.</p>
</td></tr>
<tr><td><code>SD</code></td>
<td>
<p>The corresponding matrix with the standard deviations of the estimates from the runs.</p>
</td></tr>
</table>
<p>The other functions return scalars.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(seedbank)
plot(richCurve(seedbank, richSobs)$mean, type='l', ylim=c(0, 35))
lines(richCurve(seedbank, richSingle)$mean, col='blue')
lines(richCurve(seedbank, richDouble)$mean, col='blue', lty=2)
</code></pre>

<hr>
<h2 id='richRarefy'>
Sample-based rarefaction curves
</h2><span id='topic+richRarefy'></span>

<h3>Description</h3>

<p>Uses Mao's tau estimator (Colwell et al, 2004) to obtain a rarefaction curve indicating the expected number of species observed if fewer samples were collected.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>richRarefy(incmat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="richRarefy_+3A_incmat">incmat</code></td>
<td>

<p>a 1/0 matrix of species incidence (presence), species x sites. A matrix of counts may also be provided.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with columns for the estimate and its standard deviation and rows for the number of samples pooled. Confidence limits may be obtained with estimate +/- 1.96 * SD.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith
</p>


<h3>References</h3>

<p>Colwell, R. K., C. X. Mao, &amp; J. Chang. 2004. Interpolating, extrapolating, and comparing incidence-based species accumulation curves. Ecology 85, 2717-2727. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(seedbank)
plot(richRarefy(seedbank)[, 1], type='l')
</code></pre>

<hr>
<h2 id='Royle-Nichols+20occupancy+20model'>
Royle-Nichols model for single-season occupancy estimation
</h2><span id='topic+occSSrn'></span><span id='topic+occSSrn0'></span><span id='topic+occSSrnSite'></span>

<h3>Description</h3>

<p>These functions implement the Royle-Nichols method (Royle &amp; Nichols 2003) for estimation of site occupancy allowing for abundance-induced heterogeneity in detection probability. Probability of detection is modelled as a function of the number of animals available for detection, <em>n</em>, and the probability of detection of an individual animal, <em>r</em>. Probability of occupancy is derived as the probability that <em>n</em> &gt; 0.
</p>
<p>Function <code>occSSrn</code> allows for site-specific covariates to be included in the model. <code>occSSrnSite</code> and <code>occSSrn0</code> are fast alternatives that do not require a full detection history matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
occSSrn(DH, model=NULL, data = NULL, ci=0.95, link=c("logit", "probit"),
    verify=TRUE, ...)

occSSrn0(y, n, ci=0.95, link=c("logit", "probit"), ...)

occSSrnSite(y, n, model=NULL, data = NULL, ci=0.95, link=c("logit", "probit"), ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Royle-Nichols+2B20occupancy+2B20model_+3A_dh">DH</code></td>
<td>

<p>a 1/0/NA matrix (or data frame) of detection histories, sites x occasions.
</p>
</td></tr>
<tr><td><code id="Royle-Nichols+2B20occupancy+2B20model_+3A_model">model</code></td>
<td>

<p>a list of formulae symbolically defining a linear predictor for each parameter in terms of covariates. If NULL, an intercept-only model is used, ie, lambda(.) r(.).
</p>
</td></tr>
<tr><td><code id="Royle-Nichols+2B20occupancy+2B20model_+3A_data">data</code></td>
<td>

<p>a data frame containing the variables in the model, with a row for each site. Each site covariate has one column. Each survey covariate has one column for each occasion, and the column name must end with the occasion number (without leading zeros); eg, <code>Cov1, Cov2, ..., Cov15</code>. All covariates should be included in <code>data</code>, otherwise they will be sought in enclosing environments, which may not produce what you want &ndash; and they won't be standardised.
</p>
<p>Note: currently only site covariates can be handled.
</p>
</td></tr>
<tr><td><code id="Royle-Nichols+2B20occupancy+2B20model_+3A_ci">ci</code></td>
<td>

<p>the confidence interval to use.
</p>
</td></tr>
<tr><td><code id="Royle-Nichols+2B20occupancy+2B20model_+3A_link">link</code></td>
<td>

<p>the link function to use, either logit or probit; see <a href="#topic+Links">Links</a>.
</p>
</td></tr>
<tr><td><code id="Royle-Nichols+2B20occupancy+2B20model_+3A_verify">verify</code></td>
<td>

<p>if TRUE, the data provided will be checked.
</p>
</td></tr>
<tr><td><code id="Royle-Nichols+2B20occupancy+2B20model_+3A_y">y</code></td>
<td>

<p>a vector with the number of detections at each site.
</p>
</td></tr>
<tr><td><code id="Royle-Nichols+2B20occupancy+2B20model_+3A_n">n</code></td>
<td>

<p>a scalar or vector with the number of visits (survey occasions) at each site.
</p>
</td></tr>
<tr><td><code id="Royle-Nichols+2B20occupancy+2B20model_+3A_...">...</code></td>
<td>

<p>other arguments passed to <code><a href="stats.html#topic+nlm">nlm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Numeric covariates in <code>data</code> are standardised to facilitate convergence. This applies to binary covariates coded as 1/0; if this is not what you want, code these as TRUE/FALSE or as factors.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>wiqid</code>, see <a href="#topic+wiqid-class">wiqid-class</a> for details.
</p>


<h3>Benchmarks</h3>

<p>Output has been checked against output from PRESENCE (Hines 2006) v.6.9 for the <code><a href="#topic+weta">weta</a></code> data set. Real values are mostly the same to 4 decimal places, though there is occasionally a discrepancy of 0.001. AICs are the same.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith
</p>


<h3>References</h3>

<p>MacKenzie, D I; J D Nichols; A J Royle; K H Pollock; L L Bailey; J E Hines 2006. <em>Occupancy Estimation and Modeling : Inferring Patterns and Dynamics of Species Occurrence</em>. Elsevier Publishing.
</p>
<p>Hines, J. E. (2006). PRESENCE - Software to estimate patch occupancy and related parameters. SGS-PWRC. http://www.mbr-pwrc.usgs.gov/software/presence.html.
</p>
<p>Royle, J. A., Nichols, J. D. (2003) Estimating abundance from repeated presence-absence data or point counts. <em>Ecology</em> 84(3) 777-790.
</p>


<h3>See Also</h3>

<p>See the examples for the <code><a href="#topic+weta">weta</a></code> data set. See <code><a href="#topic+occ2sps">occ2sps</a></code> for single-season two-species models and <code><a href="#topic+occMS">occMS</a></code> for multi-season models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># The weta data from MacKenzie et al (2006) p116:
data(weta)
DH &lt;- weta[, 1:5]
occSS(DH) # for comparison
occSSrn(DH)
y &lt;- rowSums(DH, na.rm=TRUE)
n &lt;- rowSums(!is.na(DH))
occSSrnSite(y, n, lambda ~ Browsed, data=weta)

</code></pre>

<hr>
<h2 id='salamanders'>
Occupancy data for blue ridge salamanders
</h2><span id='topic+salamanders'></span>

<h3>Description</h3>

<p>Detection/non-detection data for blue ridge salamanders (Eurycea wilderae) in Great Smoky Mountains National Park.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(salamanders)</code></pre>


<h3>Format</h3>

<p>A matrix with 39 rows corresponding to sites and 5 columns corresponding to survey occasions. 1 means that one or more salamanders were observed at the site/survey, 0 means none were seen.
</p>


<h3>Source</h3>

<p>Described in MacKenzie et al (2006) p99. The data are distributed with the software package PRESENCE.
</p>


<h3>References</h3>

<p>MacKenzie, D I; J D Nichols; A J Royle; K H Pollock; L L Bailey; J E Hines 2006. <em>Occupancy Estimation and Modeling : Inferring Patterns and Dynamics of Species Occurrence</em>. Elsevier Publishing.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(salamanders)

occSStime(salamanders, p ~ .time)
</code></pre>

<hr>
<h2 id='secrFit'>
Spatially Explicit Capture-Recapture
</h2><span id='topic+secrFit'></span>

<h3>Description</h3>

<p>A wrapper for <code>secr::secr.fit</code>. In <code>secr</code> v. 4, <code><a href="secr.html#topic+secr.fit">secr.fit</a></code> gains a new option, <code>fastproximity</code>. If TRUE, some data sets are compressed and reconfigured to run much faster. This cannot be implemented for all models. The default is <code>fastproximity=TRUE</code>. This means that you can have a set of models where some have been reconfigured, others not, and AICs are not comparable across these models. The function <code>secrFit</code> simply calls <code>secr.fit</code> with <code>fastproximity = FALSE</code>, making it easy to run models with consistent settings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>secrFit (capthist, model = list(D~1, g0~1, sigma~1), mask = NULL, buffer = NULL,
    CL = FALSE, detectfn = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="secrFit_+3A_capthist">capthist</code></td>
<td>

<p>a <code>capthist</code> object as defined in package <code>secr</code> including capture data and detector (trap) layout </p>
</td></tr>
<tr><td><code id="secrFit_+3A_model">model</code></td>
<td>

<p>list with optional components each symbolically defining a linear predictor for one real parameter using formula notation
</p>
</td></tr>
<tr><td><code id="secrFit_+3A_mask">mask</code></td>
<td>

<p>a mask object or (for a multi-session analysis) a list of mask objects, one for each session
</p>
</td></tr>
<tr><td><code id="secrFit_+3A_buffer">buffer</code></td>
<td>

<p>scalar mask buffer radius if mask is not specified (default 100 m)
</p>
</td></tr>
<tr><td><code id="secrFit_+3A_cl">CL</code></td>
<td>

<p>logical, if true then the model is fitted by maximizing the conditional likelihood
</p>
</td></tr>
<tr><td><code id="secrFit_+3A_detectfn">detectfn</code></td>
<td>

<p>integer code or character string for shape of detection function 0 = halfnormal, 1 = hazard rate etc. - see <code><a href="secr.html#topic+detectfn">detectfn</a></code>
</p>
</td></tr>
<tr><td><code id="secrFit_+3A_...">...</code></td>
<td>

<p>other arguments to pass to <code>secr.fit</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns an object of class secr representing the fitted SECR model.
</p>


<h3>Author(s)</h3>

<p>This wrapper by Mike Meredith
</p>

<hr>
<h2 id='seedbank'>
Seed abundances in soil samples
</h2><span id='topic+seedbank'></span>

<h3>Description</h3>

<p>Number of seeds of different species germinating from 121 soil samples collected in a tropical secondary forest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(seedbank)</code></pre>


<h3>Format</h3>

<p>A matrix with 34 rows for species and 121 columns corresponding to different soil samples.
</p>


<h3>Source</h3>

<p>Butler &amp; Chazdon 1998. Example data distributed with the EstimateS program (Colwell 2005).
</p>


<h3>References</h3>

<p>Butler, B. J., &amp; R. L. Chazdon. 1998. Species richness, spatial variation, and abundance of the soil seed bank of a secondary tropical rain forest. <em>Biotropica</em> 30:214-222.
</p>
<p>Colwell, R K; J A Coddington. 1994. Estimating terrestrial biodiversity through extrapolation. <em>Philosophical Transactions of the Royal Society of London B</em> 345:101-118.
</p>
<p>Colwell, R. K. 2005. EstimateS: Statistical estimation of species richness and shared species from samples. Version 7.5. User's Guide and application published at: http://purl.oclc.org/estimates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(seedbank)
## 
</code></pre>

<hr>
<h2 id='showShinyApp'>
Display a 'shiny' application
</h2><span id='topic+showShinyApp'></span>

<h3>Description</h3>

<p>Displays one of the built-in interactive 'shiny' applications in the browser. See Details for the apps available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>showShinyApp(topic)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="showShinyApp_+3A_topic">topic</code></td>
<td>

<p>The name of the shiny app to display. If missing, a list of available apps will be returned. Partial matching can be used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Three apps are currently included in the <span class="pkg">wiqid</span> package:
</p>
<p><em>&quot;Beta&quot;</em> displays a beta distribution and sliders which allow you to change the parameters. You can also input binomial data and obtain the conjugate beta posterior distribution.
</p>
<p><em>&quot;Gamma&quot;</em> displays a gamma distribution with variable parameters, and can produce the conjugate gamma posterior for Poisson-distributed count data.
</p>
<p><em>&quot;Quadratic&quot;</em> plots a quadratic relationship with variable parameters, showing how the quadratic term can add a hump or hollow to a relationship.
</p>


<h3>Value</h3>

<p>If <code>topic</code> is missing, a list of available apps. Otherwise, nothing useful; the function is run for its side effect.
</p>


<h3>Author(s)</h3>

<p>A much simplified version of code by Jason Bryer on GitHub at <a href="https://github.com/jbryer/DATA606">https://github.com/jbryer/DATA606</a>, adapted by Mike Meredith.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showShinyApp() # Shows a list of available apps

</code></pre>

<hr>
<h2 id='simpleRhat'>
The Brooks-Gelman-Rubin (BGR) convergence diagnostic (deprecated)
</h2><span id='topic+simpleRhat'></span>

<h3>Description</h3>

<p>This is now a wrapper for  <code><a href="mcmcOutput.html#topic+getRhat">getRhat</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simpleRhat(object, n.chains, burnin=0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simpleRhat_+3A_object">object</code></td>
<td>

<p>an object of any class with MCMC output that can be coerced to class mcmcOutput.
</p>
</td></tr>
<tr><td><code id="simpleRhat_+3A_n.chains">n.chains</code></td>
<td>

<p>ignored
</p>
</td></tr>
<tr><td><code id="simpleRhat_+3A_burnin">burnin</code></td>
<td>

<p>ignored
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named vector with the Rhat values.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith
</p>


<h3>References</h3>

<p>Brooks, S.P. &amp; Gelman, A. (1998) General methods for monitoring convergence of iterative simulations. <em>Journal of Computational and Graphical Statistics</em>, 7, 434-455.
</p>
<p>Spiegelhalter, Thomas, Best &amp; Lunn (2003) WinBUGS User Manual Version 1.4, on line <a href="https://www.mrc-bsu.cam.ac.uk/wp-content/uploads/manual14.pdf">here</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Get some output to use
data(salamanders)
y &lt;- rowSums(salamanders)
( out &lt;- BoccSS0(y, 5) )

simpleRhat(out)
</code></pre>

<hr>
<h2 id='Species+20richness+20estimators'>
Species richness estimators
</h2><span id='topic+Species+20richness+20estimators'></span><span id='topic+richACE'></span><span id='topic+richICE'></span><span id='topic+richChao1'></span><span id='topic+richChao2'></span><span id='topic+richJack1'></span><span id='topic+richJack2'></span><span id='topic+richJackA1'></span><span id='topic+richJackA2'></span><span id='topic+richBoot'></span><span id='topic+richMM'></span><span id='topic+richRenLau'></span>

<h3>Description</h3>

<p>Functions to estimate species richness, based on samples from one or more surveys (quadrats, sites, occasions, ...) as included in EstimateS. See Details for individual estimators.
</p>
<p>EstimateS no longer runs under Windows 10 or later and is effectively defunct. See <a href="https://www.robertkcolwell.org/pages/estimates">https://www.robertkcolwell.org/pages/estimates</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>richACE(cntVec, threshold = 10)
richICE(incMat, threshold = 10)
richChao1(cntVec, correct = FALSE, ci = 0.95)
richChao2(incMat, correct = FALSE, ci = 0.95)
richJack1(incMat)
richJack2(incMat)
richJackA1(cntVec)
richJackA2(cntVec)
richBoot(incMat)
richMM(incMat)
richRenLau(cntVec)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Species+2B20richness+2B20estimators_+3A_cntvec">cntVec</code></td>
<td>

<p>a vector of species counts (abundances) with one element for each species. A matrix of counts, species x sites, may also be provided and will be converted to a vector with <code>rowSums</code>. Zeros are allowed, but not missing values; non-integers are rounded.
</p>
</td></tr>
<tr><td><code id="Species+2B20richness+2B20estimators_+3A_incmat">incMat</code></td>
<td>

<p>a 1/0 matrix of species incidence (presence), species x sites. A matrix of counts may also be provided and will be converted to 1/0 after rounding.
</p>
</td></tr>
<tr><td><code id="Species+2B20richness+2B20estimators_+3A_threshold">threshold</code></td>
<td>

<p>the definition of rare or infrequent species: species with <code>threshold</code> or smaller counts (ACE) or incidences (ICE) are rare or infrequent.
</p>
</td></tr>
<tr><td><code id="Species+2B20richness+2B20estimators_+3A_correct">correct</code></td>
<td>

<p>if TRUE, bias-corrected estimates are calculated.
</p>
</td></tr>
<tr><td><code id="Species+2B20richness+2B20estimators_+3A_ci">ci</code></td>
<td>

<p>the required confidence interval.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>richACE</code> and <code>richICE</code> calculate Anne Chao's Abundance-based and Incidence-based Coverage Estimators of species richness respectively (Chao et al, 2000).
</p>
<p><code>richChao1</code> and <code>richChao2</code> calculate Anne Chao's Chao 1 (abundance-based) and Chao 2 (incidence-based) estimators (Chao 1984, 1987).
</p>
<p><code>richJack1</code> and <code>richJack2</code> calculate first and second order incidence-based jackknife estimators of species richness (Smith &amp; van Belle, 1984).
</p>
<p><code>richBoot</code> calculates a bootstrap estimator of species richness (Smith &amp; van Belle, 1984).
</p>
<p><code>richMM</code> calculates the asymptotic species richness from a Michaelis-Menten curve fitted to the species rarefaction curve (Colwell et al. 2004).
</p>
<p>The following were not included in EstimateS v.8.2:
</p>
<p><code>richJackA1</code> and <code>richJackA2</code> calculate first and second order abundance-based jackknife estimators of species richness (Gotelli &amp; Colwell 2011).
</p>
<p><code>richRenLau</code> calculates Rennolls &amp; Laumonier's (2006) 'shadow species' abundance-based estimator of richness.
</p>


<h3>Value</h3>

<p><code>richChao1</code> and <code>richChao2</code> return a vector with a point estimate, upper and lower confidence limits, and standard deviation.
</p>
<p>The other functions return a scalar.
</p>


<h3>Benchmarks</h3>

<p>Output for estimators included in EstimateS 8.2 has been checked against EstimateS for the <code>seedbank</code> and <code>killarneyBirds</code> data sets. EstimateS results are often 0.01 lower, as EstimateS appears to truncate rather than rounding.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith
</p>


<h3>References</h3>

<p>Chao, A. 1984. Non-parametric estimation of the number of classes in a population. <em>Scandinavian Journal of Statistics</em> 11, 265-270.
</p>
<p>Chao, A. 1987. Estimating the population size for capture-recapture data with unequal capture probabilities. <em>Biometrics</em> 43:783-791.
</p>
<p>Chao, A., W.-H. Hwang, Y.-C. Chen, and C.-Y. Kuo. 2000. Estimating the number of shared species in two communities. <em>Statistica Sinica</em> 10:227-246.
</p>
<p>Colwell, R. K., C. X. Mao, &amp; J. Chang. 2004. Interpolating, extrapolating, and comparing incidence-based species accumulation curves. <em>Ecology</em> 85, 2717-2727.
</p>
<p>Gotelli, N J; R K Colwell. 2011. Estimating species richness. 39-54 in Magurran, A E, and B J McGill, editors. <em>Biological diversity: frontiers in measurement and assessment</em>. Oxford University Press, Oxford, New York NY.
</p>
<p>Rennolls, K; Y Laumonier. 2006. A new local estimator of regional species diversity, in terms of 'shadow species', with a case study from Sumatra. <em>J Tropical Ecology</em> 22:321-329.
</p>
<p>Smith, E.P. &amp; van Belle, G. 1984. Nonparametric estimation of species richness. <em>Biometrics</em> 40, 119-129.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+richRarefy">richRarefy</a></code> for rarefaction curves, and <code><a href="#topic+richCurve">richCurve</a></code> for a function to give richness estimates for sub-sets of samples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(seedbank)

richACE(seedbank)

</code></pre>

<hr>
<h2 id='standardize'>
Scaling and centring of vectors, matrices and arrays
</h2><span id='topic+standardize'></span><span id='topic+standardize2match'></span>

<h3>Description</h3>

<p>Maps a numeric variable to a new object with the same dimensions. <code>standardize</code> is typically used to standardise a covariate to mean 0 and SD 1. <code>standardize2match</code> is used to standardise one object using the mean and SD of another; it is a wrapper for <code>standardize(x, center=mean(y), scale=sd(y))</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standardize(x, center = TRUE, scale = TRUE)
standardize2match(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="standardize_+3A_x">x</code>, <code id="standardize_+3A_y">y</code></td>
<td>

<p>a numeric vector, matrix or multidimensional array; <code>NA</code> and <code>NaN</code> are allowed; <code>Inf</code> and <code>-Inf</code> will produce all-<code>NaN</code> output if either <code>center</code> or <code>scale</code> is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="standardize_+3A_center">center</code></td>
<td>

<p>either a logical or a numeric value of length 1.
</p>
</td></tr>
<tr><td><code id="standardize_+3A_scale">scale</code></td>
<td>

<p>either a logical or a numeric value of length 1.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>standardize</code> differs from <code><a href="base.html#topic+scale">scale</a></code> by (1) accepting multidimensional arrays but not data frames; (2) <em>not</em> standardizing column-wise but using a single value to centre or to scale; (3) if <code>x</code> is a vector, the output will be a vector (not a 1-column matrix). If each column in the matrix represents a different variable, use <code>scale</code> not <code>standardize</code>.
</p>
<p>Centring is performed before scaling.
</p>
<p>If <code>center</code> is numeric, that value will be subtracted from the whole object. If logical and TRUE, the mean of the object (after removing NAs) will be subtracted.
</p>
<p>If <code>scale</code> is numeric, the whole object will be divided by that value. If logical and TRUE, the standard deviation of the object (after removing NAs) will be used; this may not make sense if <code>center = FALSE</code>.
</p>


<h3>Value</h3>

<p>A numeric object of the same dimensions as <code>x</code> with the standardized values. NAs in the input will be preserved in the output.
</p>
<p>For the default arguments, the object returned will have mean approximately zero and SD 1. (The mean is not exactly zero as scaling is performed after centring.)
</p>


<h3>Author(s)</h3>

<p>Mike Meredith, after looking at the code of <code>base::scale</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fake elevation data:
elev &lt;- runif(100, min=100, max=500)
mean(elev) ; sd(elev)
str( e &lt;- standardize(elev) )
mean(e) ; sd(e)

# Standardize so that e=0 corresponds to exactly 300m and +/- 1 to
#   a change of 100m:
e &lt;- standardize(elev, center=300, scale=100)
mean(e)
mean(elev) - 300
range(e)
range(elev) - 300

# Generate data matrix for survey duration for 3 surveys at 10 sites
dur &lt;- matrix(round(runif(30, 20, 60)), nrow=10, ncol=3)
d &lt;- standardize(dur)
mean(d) ; sd(d)

# Standardize new data to match the mean and SD of 'dur'
(new &lt;- seq(20, 60, length.out=11))
standardize2match(new, dur)

# compare with base::scale
dx &lt;- base::scale(dur)
colMeans(dx) ; apply(dx, 2, sd)
colMeans(d) ; apply(d, 2, sd)
# Don't use 'standardize' if the columns in the matrix are different variables!
</code></pre>

<hr>
<h2 id='Survival+20+28CJS+29'>
Survival from recapture data with Cormack-Jolly-Seber (CJS) model
</h2><span id='topic+survCJS'></span><span id='topic+survCJSaj'></span><span id='topic+BsurvCJS'></span>

<h3>Description</h3>

<p>Calculation of apparent survival (accounting for recapture probability) from mark-recapture data, with time-dependent phi or p, possibly with covariates. Function <code>survCHSaj</code> allows for different survival parameters for juveniles and adults; juveniles are assumed to become adults after the first interval. <code>BsurvCJS</code> is a Bayesian version.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>survCJS(DH, model=list(phi~1, p~1), data=NULL, freq=1, group, interval=1,
    ci = 0.95, link=c("logit", "probit"), ...)

survCJSaj(DHj, DHa=NULL, model=list(phiJ~1, phiA~1, p~1), data=NULL,
    freqj=1, freqa=1, ci = 0.95, link=c("logit", "probit"), ...)

BsurvCJS(DH, model=list(phi~1, p~1), data = NULL, freq=1, priors=NULL,
    chains=3, draws=1e4, burnin=1000, thin=1, adapt=1000,
    parallel = NULL, seed=NULL, priorOnly=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Survival+2B20+2B28CJS+2B29_+3A_dh">DH</code></td>
<td>

<p>a 1/0 matrix with detection histories with a row for each animal captured and a column for each capture occasion.
</p>
</td></tr>
<tr><td><code id="Survival+2B20+2B28CJS+2B29_+3A_model">model</code></td>
<td>

<p>a list of formulae symbolically defining a linear predictor for each parameter in terms of covariates.
</p>
</td></tr>
<tr><td><code id="Survival+2B20+2B28CJS+2B29_+3A_data">data</code></td>
<td>

<p>a data frame with a row for each survival interval / recapture occasion and columns for each of the covariates used to estimate phi or p.
</p>
</td></tr>
<tr><td><code id="Survival+2B20+2B28CJS+2B29_+3A_freq">freq</code></td>
<td>

<p>a scalar or a vector of length <code>nrows(DH)</code> with the frequency of each detection history. Negative values indicate trap losses.
</p>
</td></tr>
<tr><td><code id="Survival+2B20+2B28CJS+2B29_+3A_group">group</code></td>
<td>

<p>an optional factor of length <code>nrows(DH)</code>; if provided, <code>group</code> can be included in the model definition, see Examples.
</p>
</td></tr>
<tr><td><code id="Survival+2B20+2B28CJS+2B29_+3A_interval">interval</code></td>
<td>

<p>the time interval between capture occasions; scalar if all intervals are equal or a vector of length <code>ncols(DH) - 1</code>; the units used must be the same as those for the apparent survival estimate, eg, for annual survival use years.
</p>
</td></tr>
<tr><td><code id="Survival+2B20+2B28CJS+2B29_+3A_dhj">DHj</code>, <code id="Survival+2B20+2B28CJS+2B29_+3A_dha">DHa</code></td>
<td>

<p>detection history matrices for animals marked as juveniles and adults respectively; DHa should be NULL if no animals were marked as adults.
</p>
</td></tr>
<tr><td><code id="Survival+2B20+2B28CJS+2B29_+3A_freqj">freqj</code>, <code id="Survival+2B20+2B28CJS+2B29_+3A_freqa">freqa</code></td>
<td>

<p>frequencies of each detection history in DHj and DHa; freqa is ignored if DHa = NULL.
</p>
</td></tr>
<tr><td><code id="Survival+2B20+2B28CJS+2B29_+3A_ci">ci</code></td>
<td>

<p>the required confidence interval.
</p>
</td></tr>
<tr><td><code id="Survival+2B20+2B28CJS+2B29_+3A_link">link</code></td>
<td>

<p>the link function to use, either logit or probit; see <a href="#topic+Links">Links</a>.
</p>
</td></tr>
<tr><td><code id="Survival+2B20+2B28CJS+2B29_+3A_...">...</code></td>
<td>

<p>other arguments passed to <code><a href="stats.html#topic+nlm">nlm</a></code>.
</p>
</td></tr>
<tr><td><code id="Survival+2B20+2B28CJS+2B29_+3A_priors">priors</code></td>
<td>

<p>a list with elements for prior mean and variance for coefficients; see Details.
</p>
</td></tr>
<tr><td><code id="Survival+2B20+2B28CJS+2B29_+3A_chains">chains</code></td>
<td>

<p>the number of Markov chains to run.
</p>
</td></tr>
<tr><td><code id="Survival+2B20+2B28CJS+2B29_+3A_draws">draws</code></td>
<td>

<p>the minimum number of values to return; the actual number returned may be slightly higher, as it will be a multiple of <code>chains</code>.
</p>
</td></tr>
<tr><td><code id="Survival+2B20+2B28CJS+2B29_+3A_burnin">burnin</code></td>
<td>

<p>the number of values to discard at the beginning of each chain.
</p>
</td></tr>
<tr><td><code id="Survival+2B20+2B28CJS+2B29_+3A_thin">thin</code></td>
<td>

<p>the thinning rate. If set to n &gt; 1, n values are calculated for each value returned.
</p>
</td></tr>
<tr><td><code id="Survival+2B20+2B28CJS+2B29_+3A_adapt">adapt</code></td>
<td>

<p>the number of iterations to run in the JAGS adaptive phase.
</p>
</td></tr>
<tr><td><code id="Survival+2B20+2B28CJS+2B29_+3A_prioronly">priorOnly</code></td>
<td>

<p>if TRUE, the function produces random draws from the appropriate <em>prior</em> distributions, with a warning.
</p>
</td></tr>
<tr><td><code id="Survival+2B20+2B28CJS+2B29_+3A_parallel">parallel</code></td>
<td>

<p>if TRUE or NULL and sufficient cores are available, the MCMC chains are run in parallel; if TRUE and insufficient cores are available, a warning is given.
</p>
</td></tr>
<tr><td><code id="Survival+2B20+2B28CJS+2B29_+3A_seed">seed</code></td>
<td>

<p>a positive integer, the seed for the random number generators.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>BsurvCJS</code> uses a probit link to model apparent survival and detection as a function of covariates; most software uses a logistic (logit) link.
See <a href="#topic+Links">Links</a>.
Coefficients on the probit scale are about half the size of the equivalent on the logit scale.
</p>
<p>Priors for <code>BsurvCJS</code> are listed in the <code>priors</code> argument, which may contain elements:
</p>
<p><code>muPhi</code> and <code>muP</code> : the means for apparent survival and detection coefficients respectively. This may be a vector with one value for each coefficient, including the intercept, or a scalar, which will be used for all. The default is 0.
</p>
<p><code>sigmaPhi</code> and <code>sigmaP</code> : the variance for apparent survival and detection coefficients respectively. This may be (1) a vector with one value for each coefficient, including the intercept, which represents the variance, assuming independence, or (2) a scalar, which will be used for all. The function does not currently allow a variance-covariance matrix. The default is 1, which is somewhat informative.
</p>
<p>When specifying priors, note that numerical covariates are standardized internally before fitting the model. For an intercept-only model, a prior of Normal(0, 1) on the probit scale implies a Uniform(0, 1) or Beta(1, 1) prior on the probability scale.
</p>


<h3>Value</h3>

<p><code>survCJS</code> and <code>survCJSaj</code> return an object of class <code>wiqid</code>, a list with elements:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>The call used to produce the results</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>Estimates of the coefficients in the linear predictors for phi and p.</p>
</td></tr>
<tr><td><code>beta.vcv</code></td>
<td>
<p>The variance-covariance matrix for the beta estimates.</p>
</td></tr>
<tr><td><code>real</code></td>
<td>
<p>Back-transformed estimates of phi and p for each interval / occasion. </p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>a vector with elements for log(likelihood), number of parameters, and effective sample size. If the variance-covariance matrix cannot be calculated, the second element should be <code>NA</code>.</p>
</td></tr>
</table>
<p>There are <code>print</code>, <code>logLik</code>, and <code>nobs</code> methods for class <code>wiqid</code>.
</p>
<p><code>BsurvCJS</code> returns an object of class <code>Bwiqid</code>, a data frame with columns for each p and psi value containing the series of MCMC draws, and attributes for details of the MCMC run.
</p>


<h3>Benchmarks</h3>

<p>Output of <code>survCJS</code> has been checked against program MARK with the dipper data set: coefficients are not the same as MARK uses models without an intercept, but the real values agree to 3 decimal places.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith
</p>


<h3>References</h3>

<p>Lebreton, J-D; K P Burnham; J Clobert; D R Anderson. 1992. Modeling survival and testing biological hypotheses using marked animals: a unified approach with case studies. <em>Ecological Monographs</em> 62:67-118.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dippers)

DH &lt;- dippers[1:7]  # Extract the detection histories
survCJS(DH)  # the phi(.) p(.) model
survCJS(DH, phi ~ .time)  # the phi(t) p(.) model
df &lt;- data.frame(flood = c(FALSE, TRUE, TRUE, FALSE, FALSE, FALSE))
survCJS(DH, phi ~ flood, data=df)  # the phi(flood) p(.) model
# Including a grouping factor:
survCJS(DH, phi ~ flood*group, data=df, group=dippers$sex)

# With unequal intervals - suppose no data were collected in year 5:
DH1 &lt;- DH[, -5]
survCJS(DH1, phi ~ .time, interval = c(1, 1, 1, 2, 1))

# See also the examples in the dippers help file.
</code></pre>

<hr>
<h2 id='Survival+20+28RD+29'>
Survival from mark-recapture data with robust design
</h2><span id='topic+survRD'></span><span id='topic+survRDah'></span>

<h3>Description</h3>

<p>Calculation of apparent survival and recruitment rate from data collected using Pollock's robust design, ie, with multiple capture occasions within each season, where the population is closed within each season. 
</p>
<p>Function <code>survRDah</code> implements the second stage of a two-stage analysis, where abundance and recapture probability are estimated using closed-capture function for each season. 
</p>
<p>Function <code>survRD</code> combines the two stages into a single maximum likelihood estimation step, using model M0 for the within-season data.
</p>
<p>NOTE: These are preliminary attempts at coding these models and have not been properly tested or benchmarked.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>survRD(DH, freq=1, occsPerSeason)

survRDah(DH, freq=1, occsPerSeason, N, pStar)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Survival+2B20+2B28RD+2B29_+3A_dh">DH</code></td>
<td>

<p>a 1/0 matrix with detection histories with a row for each animal captured and a column for each capture occasion.
</p>
</td></tr>
<tr><td><code id="Survival+2B20+2B28RD+2B29_+3A_freq">freq</code></td>
<td>

<p>a scalar or a vector of length <code>nrow(DH)</code> with the frequency of each detection history. Negative values indicate trap losses.
</p>
</td></tr>
<tr><td><code id="Survival+2B20+2B28RD+2B29_+3A_occsperseason">occsPerSeason</code></td>
<td>

<p>the number of survey occasions per season; currently this must be scalar and the number of occasions must be the same for all seasons.
</p>
</td></tr>
<tr><td><code id="Survival+2B20+2B28RD+2B29_+3A_n">N</code></td>
<td>

<p>a vector with an element for each season giving the number of animals available for capture as estimated in the first stage of a 2-stage analysis. 
</p>
</td></tr>
<tr><td><code id="Survival+2B20+2B28RD+2B29_+3A_pstar">pStar</code></td>
<td>

<p>a vector with an element for each season giving the probability of recapture as estimated in the first stage of a 2-stage analysis. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with elements:
</p>
<table>
<tr><td><code>phiHat</code></td>
<td>
<p>Estimates of apparent survival for each interval between seasons.</p>
</td></tr>
<tr><td><code>bHat</code></td>
<td>
<p>Estimates of the recruitment rate for each interval.</p>
</td></tr>
<tr><td><code>pStarHat</code></td>
<td>
<p>The estimated probability of capture during each season.</p>
</td></tr>
<tr><td><code>Nhat</code></td>
<td>
<p>The estimated number of animals available for capture during each season.</p>
</td></tr>
<tr><td><code>pHat</code></td>
<td>
<p>The estimated probability of capture on one occasion for each season.</p>
</td></tr>
</table>
<p>For <code>survRDah</code>, the values of <code>pStarHat</code> and <code>Nhat</code> will equal the values of <code>pStar</code> and <code>N</code> input, and <code>pHat</code> with be NULL.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith
</p>


<h3>References</h3>

<p>Kendall, Pollock, and Brownie (1995) A likelihood-based approach to capture-recapture estimation of demographic parameters under the robust design. <em>Biometrics</em> 51:293-308
</p>
<p>Kendall, Nichols, Hines (1997) Estimating temporary emigration using capture-recapture data with Pollock's robust design. <em>Ecology</em> 78(2):563-578 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(MeadowVoles)
# Extract detection histories:
DH &lt;- MeadowVoles[, 1:30]
freq &lt;- MeadowVoles$freq

# With single stage maximum likelihood estimation:
survRD(DH, freq=freq, occsPerSeason=5)

# The 2-stage approach:
# Stage 1 - using the jackknife estimator to estimate N and p for each season:
MhResult &lt;- matrix(NA, 6, 2)
colnames(MhResult) &lt;- c("N", "p")
seasonID &lt;- rep(1:6, each=5)
for(i in 1:6) {
  dh &lt;- DH[, seasonID==i]
  MhResult[i, ] &lt;- closedCapMhJK(dh)$real[, 1]
}
MhResult
# Calculate the probability of being captured at least once in the season:
pStar &lt;- 1 - (1 - MhResult[, "p"])^5

# Stage 2 - pass N and pStar to a modified CJS estimation routine:
survRDah(DH, freq=freq, occsPerSeason=5, N=MhResult[, "N"], pStar=pStar)

</code></pre>

<hr>
<h2 id='TDist'>
The Generalized Student's t Distribution
</h2><span id='topic+TDist'></span><span id='topic+dt2'></span><span id='topic+pt2'></span><span id='topic+qt2'></span><span id='topic+rt2'></span><span id='topic+dt3'></span><span id='topic+pt3'></span><span id='topic+qt3'></span><span id='topic+rt3'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random generation for the generalised t distribution with df degrees of freedom, using location and scale, or mean and sd. These are wrappers for <code>stats::dt</code>, etc.
</p>
<p>Note: In earlier versions of <code>wiqid</code> the <code>scale</code> argument to <code>*t2</code> functions was incorrectly named <code>sd</code>; they are not the same. These function now give a warning with the correct value of the <code>sd</code>. New <code>*t3</code> functions do use <code>sd</code> which is only defined for <code>df &gt; 2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dt2(x, location, scale, df)
pt2(x, location, scale, df, lower.tail=TRUE, log.p=FALSE)
qt2(p, location, scale, df, lower.tail=TRUE, log.p=FALSE)
rt2(n, location, scale, df)

dt3(x, mean, sd, df)
pt3(x, mean, sd, df, lower.tail=TRUE, log.p=FALSE)
qt3(p, mean, sd, df, lower.tail=TRUE, log.p=FALSE)
rt3(n, mean, sd, df)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TDist_+3A_x">x</code></td>
<td>

<p>vector of parameter values
</p>
</td></tr>
<tr><td><code id="TDist_+3A_location">location</code></td>
<td>

<p>location of the t-distribution
</p>
</td></tr>
<tr><td><code id="TDist_+3A_mean">mean</code></td>
<td>

<p>mean of the t-distribution
</p>
</td></tr>
<tr><td><code id="TDist_+3A_scale">scale</code></td>
<td>

<p>scale parameter of the t-distribution
</p>
</td></tr>
<tr><td><code id="TDist_+3A_sd">sd</code></td>
<td>

<p>standard deviation of the t-distribution, only defined for <code>df &gt; 2</code>.
</p>
</td></tr>
<tr><td><code id="TDist_+3A_df">df</code></td>
<td>

<p>degrees of freedom
</p>
</td></tr>
<tr><td><code id="TDist_+3A_lower.tail">lower.tail</code></td>
<td>

<p>logical; if TRUE (default), cumulative probabilities up to x, otherwise, above x.
</p>
</td></tr>
<tr><td><code id="TDist_+3A_log.p">log.p</code></td>
<td>

<p>logical; if TRUE, probabilities p are given as log(p).
</p>
</td></tr>
<tr><td><code id="TDist_+3A_p">p</code></td>
<td>

<p>probability.
</p>
</td></tr>
<tr><td><code id="TDist_+3A_n">n</code></td>
<td>

<p>number of random draws required.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>dtx</code> gives the density, <code>ptx</code> gives the cumulative probability, <code>qtx</code> gives the quantile function, and <code>rtx</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p>Mike Meredith
</p>


<h3>See Also</h3>

<p>See the <span class="pkg">stats</span> functions <code><a href="stats.html#topic+dt">dt</a></code>, <code><a href="stats.html#topic+pt">pt</a></code>, <code><a href="stats.html#topic+qt">qt</a></code>, <code><a href="stats.html#topic+rt">rt</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Plot the t-distribution with varying sd and scale
require(graphics)
xx &lt;- seq(-5, 15, length=201)
density &lt;- dt3(xx, mean=5, sd=1, 4)
plot(xx, density, type='l', lwd=2, main="t-distribution with df = 4")
lines(xx, dt3(xx, 5, 2, 4), lwd=2, col=2)
lines(xx, dt3(xx, 5, 3, 4), lwd=2, col=3)
lines(xx, dt3(xx, 5, 4, 4), lwd=2, col=4)
legend('topleft', paste0("sd = ", 1:4), lwd=2, lty=1, col=1:4,
  bty='n')
lines(xx, dt2(xx, 5, 1, 4), lwd=2, lty=2, col=1)
lines(xx, dt2(xx, 5, 2, 4), lwd=2, lty=2, col=2)
lines(xx, dt2(xx, 5, 3, 4), lwd=2, lty=2, col=3)
lines(xx, dt2(xx, 5, 4, 4), lwd=2, lty=2, col=4)
legend('topright', paste0("scale = ", 1:4), lwd=2, lty=2, col=1:4,
  bty='n')

# Generate random numbers
rand2 &lt;- rt2(1e6, location=5, scale=2, df=4)
mean(rand2)
sd(rand2)  # about 2.83
rand3 &lt;- rt3(1e6, mean=5, sd=2, df=4)
mean(rand3)
sd(rand3)  # close to 2

# check pt* and qt*
prob &lt;- pt2(x=7, location=5, scale=3, df=4)
qt2(p=prob, location=5, scale=3, df=4)
</code></pre>

<hr>
<h2 id='Temburong'>
Tree species count data
</h2><span id='topic+Temburong'></span><span id='topic+TemburongBA'></span>

<h3>Description</h3>

<p>Basal area and number of individual trees &gt;= 5cm dbh of each species in a 1ha plot in Ulu Temburong - Brunei. There were 1012 trees of 276 species.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Temburong)</code></pre>


<h3>Format</h3>

<p>The data set consists of two objects:
</p>
<p><code>Temburong</code> is a vector of length 276, with the counts of each species.
</p>
<p><code>TemburongBA</code> is a similar vector with the basal area (ie. the sum of the cross-sectional area at breast height of all of trees) of each species.
</p>


<h3>Source</h3>

<p>Small, A; T G Martin; R L Kitching; K M Wong. 2004. Contribution of tree species to the biodiversity of a 1 ha Old World rainforest in Brunei, Borneo. <em>Biodiversity and Conservation</em> 13:2067-2088.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Temburong)
richChao1(Temburong)
biodShannon(TemburongBA)
</code></pre>

<hr>
<h2 id='toves'>
Simulated detection/non-detection data for a fictitious species
</h2><span id='topic+toves'></span>

<h3>Description</h3>

<p>A data set for single-season occupancy modelling together with habitat covariates. See <code><a href="#topic+predictAvg">predictAvg</a></code> for an example of its use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("toves")</code></pre>


<h3>Format</h3>

<p>A data frame with detection (1) vs non-detection data for 2 species at 160 sites on three occasions.
</p>

<dl>
<dt>y1, y2, y3, y4</dt><dd><p> detection histories for 4 occasions</p>
</dd>
<dt>x1, x2, x3</dt><dd><p> simulated habitat covariates</p>
</dd>
</dl>



<h3>Source</h3>

<p>Simulated data
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toves)
str(toves)

# Extract detection histories
DH &lt;- toves[, 1:4]

# Fit some models
m.1 &lt;- occSS(DH, psi ~ x1, data=toves)
m.12 &lt;- occSS(DH, psi ~ x1 + x2, data=toves)
m.13 &lt;- occSS(DH, psi ~ x1 + x3, data=toves)
m.123 &lt;- occSS(DH, psi ~ x1 + x2 + x3, data=toves)
m.23 &lt;- occSS(DH, psi ~ x2 + x3, data=toves)
AICtable(AIC(m.1, m.12, m.13, m.123, m.23))
</code></pre>

<hr>
<h2 id='WAIC'>
Extract the Watanabe-Akaike Information Criterion (WAIC)
</h2><span id='topic+WAIC'></span>

<h3>Description</h3>

<p>Extracts the Watanabe-Akaike Information Criterion from objects of class <code>Bwiqid</code> which have a WAIC attribute.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WAIC(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WAIC_+3A_object">object</code></td>
<td>

<p>a fitted model object with an attribute giving the WAIC and pD for the fitted model.
</p>
</td></tr>
<tr><td><code id="WAIC_+3A_...">...</code></td>
<td>

<p>optionally more fitted model objects.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If just one object is provided, the corresponding WAIC.
</p>
<p>If multiple objects are provided, a data frame with rows corresponding to the objects and columns representing the number of parameters in the model (pD) and the WAIC.
</p>


<h3>Note</h3>

<p>The code to produce WAIC is new and not fully tested: it probably harbours bugs!
</p>


<h3>Author(s)</h3>

<p>Mike Meredith. 
</p>


<h3>References</h3>

<p>Burnham, K P; D R Anderson 2002. <em>Model selection and multimodel inference: a practical information-theoretic approach</em>. Springer-Verlag. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## TODO
</code></pre>

<hr>
<h2 id='weta'>
Detection data for weta in gorse bushes
</h2><span id='topic+weta'></span>

<h3>Description</h3>

<p>Results of an occupancy survey to see if presence/absence of weta in 72 gorse bushes is affected by browsing of the bushes by goats. Probability of detection may be different for each observer, and observer ID is also recorded.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(weta)</code></pre>


<h3>Format</h3>

<p>A data frame with 72 observations on the following 11 variables.
</p>

<dl>
<dt>D1, D2, D3, D4, D5</dt><dd><p>a numeric vector for each of 5 daily surveys, showing whether weta were detected (1) or not detected (0); NA if the bush was not surveyed on the relevant day. </p>
</dd>
<dt>Browsed</dt><dd><p>a logical vector indicating whether the bush was browsed (TRUE) or not browsed (FALSE)</p>
</dd>
<dt>ObsD1, ObsD2, ObsD3, ObsD4, ObsD5</dt><dd><p>a factor with levels <code>A</code> <code>B</code> <code>C</code>, indicating which observer carried out each survey.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data are provided as a data frame, such as would result from reading in data from a text file. Further formatting is needed before using these for analysis: see the examples. 
</p>


<h3>Source</h3>

<p>Discussed in MacKenzie et al (2006) p116. Data distributed with PRESENCE.
</p>


<h3>References</h3>

<p>MacKenzie, D I; J D Nichols; A J Royle; K H Pollock; L L Bailey; J E Hines 2006. <em>Occupancy Estimation and Modeling : Inferring Patterns and Dynamics of Species Occurrence</em>. Elsevier Publishing.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(weta)

DH &lt;- weta[, 1:5]  # extract the detection history:
occSS(DH)
occSStime(DH, p~.time)
# With covariates
occSS(DH, list(psi ~ Browsed, p ~ ObsD), data=weta)
occSS(DH, list(psi ~ Browsed, p ~ Browsed), data=weta)

# Bayesian analysis

# Model with separate intercepts for occupancy in Browsed and Unbrowsed
#  bushes, and a time trend for probability of detection; specify uniform
#  priors for probability of occupancy:
Bwet &lt;- BoccSS(DH, model=list(psi~Browsed-1, p~.Time), data=weta,
  priors=list(sigmaPsi=c(1,1)), chains=2)
Bwet
plot(Bwet)
plot(Bwet, "p_.Time")

</code></pre>

<hr>
<h2 id='wiqid-class'> The 'wiqid' S3 class </h2><span id='topic+wiqid-class'></span>

<h3>Description</h3>

<p>All the maximum likelihood functions in the <span class="pkg">wiqid</span> package should produce an object of class <code>wiqid</code>. Bayesian estimation runs produce objects of class <code>Bwiqid</code>.
</p>


<h3>Structure</h3>

<p>A <code>wiqid</code> object is a list with the following elements:
</p>

<dl>
<dt>call </dt><dd><p>The call used to produce the results</p>
</dd>
<dt>link </dt><dd><p>Either a named list with the link functions used, or a single value if the same link is used for all parameters. For probabilities, usually <code>logit</code> or <code>probit</code>.</p>
</dd>
<dt>beta </dt><dd><p>A matrix of values of the coefficients of the terms in the linear predictors, with standard errors and confidence intervals.</p>
</dd>
<dt>beta.vcv </dt><dd><p>The variance-covariance matrix for the beta estimates.</p>
</dd>
<dt>real </dt><dd><p>Estimates of occupancy and probability of detection on the real scale, with confidence intervals.</p>
</dd>
<dt>logLik </dt><dd><p>a vector with elements for <code>log(likelihood)</code>, number of parameters, and effective sample size. If the variance-covariance matrix cannot be calculated, the second element should be <code>NA</code>.</p>
</dd>
<dt>ci </dt><dd><p>intended coverage of the confidence intervals.</p>
</dd>
<dt>formulae </dt><dd><p>a named list with the formulae of each of the submodels.</p>
</dd>
<dt>index </dt><dd><p>a named list indicating which rows of the <code>beta</code> and <code>beta.vcv</code> matrices correspond to each submodel.</p>
</dd>
<dt>xlev </dt><dd><p>a named list of factors included in the original <code>data</code> object with their levels.</p>
</dd>
<dt>scaling </dt><dd><p>a named list of numerical covariates included in the original <code>data</code> object with the values used to standardise them, <code>c(centre, spread)</code>.</p>
</dd>
</dl>



<h3>Methods</h3>

<p>The following methods are available for objects of class <code>wiqid</code>:
</p>
<p><code>print</code>, <code><a href="stats.html#topic+logLik">logLik</a></code>, <code><a href="stats.html#topic+nobs">nobs</a></code>, <code><a href="stats.html#topic+coef">coef</a></code>, <code><a href="stats.html#topic+vcov">vcov</a></code>, <code><a href="#topic+predict.wiqid">predict.wiqid</a></code>.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
