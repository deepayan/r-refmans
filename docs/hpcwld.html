<!DOCTYPE html><html><head><title>Help for package hpcwld</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {hpcwld}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#hpcwld-package'>
<p>Model and data for High Performance Cluster workload</p></a></li>
<li><a href='#ApproxC'><p>Approximate, dynamic iterative computation of the stability constant for a workload of a High Performance Cluster model</p></a></li>
<li><a href='#DataToSWF'><p>Convertor from a dataframe to Standart Workload Format</p></a></li>
<li><a href='#DMC'><p>Distributional Measure of Correlation</p></a></li>
<li><a href='#FromSWF'><p>Convertor to a dataset from a Standart Workload Format</p></a></li>
<li><a href='#HPC_KRC'>
<p>Workload data for High Performance Cluster of High Performance Data Center</p>
of Karelian Research Center, Russian Academy of Sciences.</a></li>
<li><a href='#HPC_KRC2'>
<p>Workload data for High Performance Cluster of High Performance Data Center</p>
of Karelian Research Center, Russian Academy of Sciences.</a></li>
<li><a href='#MaxThroughput2'><p>This function gives the maximal throughput of a two-server supercomputer (Markov) model with various service speeds, various rates of classes and random speed scaling at arrival/depature</p></a></li>
<li><a href='#ToSWF'><p>Convertor from a dataset to Standart Workload Format</p></a></li>
<li><a href='#Wld'><p>Workload of a High Performance Cluster model</p></a></li>
<li><a href='#X'>
<p>Dataset with raw workload data from HPDC KRC RAS</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>0.6-5</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-06-25</td>
</tr>
<tr>
<td>Title:</td>
<td>High Performance Cluster Models Based on Kiefer-Wolfowitz
Recursion</td>
</tr>
<tr>
<td>Author:</td>
<td>Alexander Rumyantsev [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Alexander Rumyantsev &lt;ar0@sampo.ru&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Probabilistic models describing the behavior 
	of workload and queue on a High Performance Cluster and computing GRID 
	under FIFO service discipline basing on modified Kiefer-Wolfowitz 
	recursion. Also sample data for inter-arrival times, service times, 
	number of cores per task and waiting times of HPC of Karelian 
	Research Centre are included, measurements took place from 06/03/2009 to 02/30/2011.
	Functions provided to import/export workload traces in Standard Workload Format (swf).
	Stability condition of the model may be verified either exactly, or approximately.
	Stability analysis: see Rumyantsev and Morozov (2017) &lt;<a href="https://doi.org/10.1007%2Fs10479-015-1917-2">doi:10.1007/s10479-015-1917-2</a>&gt;,
	workload recursion: see Rumyantsev (2014) &lt;<a href="https://doi.org/10.1109%2FPDCAT.2014.36">doi:10.1109/PDCAT.2014.36</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Repository/R-Forge/Project:</td>
<td>hpcwld</td>
</tr>
<tr>
<td>Repository/R-Forge/Revision:</td>
<td>27</td>
</tr>
<tr>
<td>Repository/R-Forge/DateTimeStamp:</td>
<td>2022-06-25 20:09:01</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-06-26 21:20:07 UTC</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-06-25 20:31:06 UTC; rforge</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
</table>
<hr>
<h2 id='hpcwld-package'>
Model and data for High Performance Cluster workload
</h2><span id='topic+hpcwld-package'></span><span id='topic+hpcwld'></span>

<h3>Description</h3>

<p>This package contains several models describing the behavior of workload 
and queue on a High Performance Cluster and computing GRID under FIFO 
service discipline basing on modified Kiefer-Wolfowitz recursion. 
Also sample data for inter-arrival times, service times, number of 
cores per task and waiting times of HPC of Karelian Research Centre 
are included, measurements took place from 06/03/2009 to 02/30/2011.
The stability condition of the model can be verified either exactly,
or approximately.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> hpcwld</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 0.5</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2015-02-14</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GNU GPL</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyLoad: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Alexander Rumyantsev (Institute of Applied Mathematical Research, Karelian Research Centre, RAS)
</p>


<h3>References</h3>

<p>E.V. Morozov, A.Rumyantsev. Stability analysis of a multiprocessor model describing
a high performance cluster. XXIX International Seminar on Stability Problems for Stochastic
Models and V International Workshop &quot;Applied Problems in Theory of Probabilities and 
Mathematical Statistics related to modeling of information systems&quot;. Book of Abstracts. 2011. Pp. 82&ndash;83.
</p>
<p>A. Rumyantsev. Simulating Supercomputer Workload with hpcwld package for R 
// Proceedings of 2014 15th International Conference on Parallel and Distributed Computing, 
Applications and Technologies. IEEE, 2014. P. 138-143. URL: http://conferences.computer.org/pdcat/2014/papers/8334a138.pdf
</p>
<p>A. Rumyantsev. Evaluating the stability of supercomputer workload model 
// Journal on Selected Topics in Nano Electronics and Computing, Vol. 2, No. 2, December 2014. P. 36-39.
</p>
<p><a href="http://cluster.krc.karelia.ru">http://cluster.krc.karelia.ru</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Wld(T=rexp(1000,1), S=rexp(1000,1), round(runif(1000,1,10)), 10)
# returns the workload, delay and total cpus used 
# for a cluster with 10 CPUs and random exponential times
</code></pre>

<hr>
<h2 id='ApproxC'>Approximate, dynamic iterative computation of the stability constant for a workload of a High Performance Cluster model</h2><span id='topic+ApproxC'></span>

<h3>Description</h3>

<p>This function calculates the constant C that is used in the stability criterion
of a supercomputer model, which is basically the following: lambda/mu&lt;C, where lambda
is the task arrivals rate, and mu is the service intensity. The constant depends only on
the number of servers in the model and the distribution of classes of customers,
where class is the number of servers required. This method of calculation allows 
to stop on some depth of dynamics, thus allowing to calculate an approximate value in
faster time. The constant is valid only for the model with simultaneous service.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ApproxC(s, p, depth = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ApproxC_+3A_s">s</code></td>
<td>
<p>number of servers in the model</p>
</td></tr>
<tr><td><code id="ApproxC_+3A_p">p</code></td>
<td>
<p>vector of class distribution</p>
</td></tr>
<tr><td><code id="ApproxC_+3A_depth">depth</code></td>
<td>
<p>By default calculates up to groups of 3 tasks. When depth=s, calculates the exact value. However, depth=s might take a bit more time.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value of a constant C in the relation lambda/mu &lt; C is returned
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ApproxC(s=2,p=c(.5,.5), depth=3)
</code></pre>

<hr>
<h2 id='DataToSWF'>Convertor from a dataframe to Standart Workload Format</h2><span id='topic+DataToSWF'></span>

<h3>Description</h3>

<p>Note that this is only a wrapper for the ToSWF command with a dataframe
argument. It needs a correctly built dataframe and converts it to a Standart Workload
Format used to share the logfiles of High Performance Clusters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DataToSWF(Frame, filename = "output.swf")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DataToSWF_+3A_frame">Frame</code></td>
<td>
<p>A dataframe containing the variables needed by ToSWF function</p>
</td></tr>
<tr><td><code id="DataToSWF_+3A_filename">filename</code></td>
<td>
<p>The file to store the converted workload (output.swf by default)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Standart Workload Format is a single format to store and exchange
high performance cluster logs, that is used in Parallel Workload Archive.
See references for current standard. The SWF format may contain additional
data, but in this package only the 1st to 5th fields are used. One may also
need to manually fill in the header of the file in order to completely
prepare the resulting SWF file.
</p>


<h3>Value</h3>

<p>Nothing is returned, but a file is created in the current working directory
(with default name output.swf) containing the converted data.
</p>


<h3>References</h3>

<p>Feitelson, D.G. and Tsafrir, D. and Krakov D. 2012 Experience with the Parallel Workloads Archive. Technical Report 2012-6, School of Computer Science and Engineering, the Hebrew University April, 2012, Jerusalem, Israel
</p>
<p>https://www.cs.huji.ac.il/labs/parallel/workload/swf.html
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(HPC_KRC)
tmp=data.frame(T=HPC_KRC$interarrival, S=HPC_KRC$service, N=HPC_KRC$cores_used, D=HPC_KRC$delay)
DataToSWF(tmp)

## End(Not run)
</code></pre>

<hr>
<h2 id='DMC'>Distributional Measure of Correlation</h2><span id='topic+DMC'></span>

<h3>Description</h3>

<p>This is a suggested by Dror Feitelson measure of correlation for dependent
variables, that may be successfully used to examine the datasets from a
High Performance Cluster logs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DMC(X, Y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DMC_+3A_x">X</code></td>
<td>
<p>First variable (vector)</p>
</td></tr>
<tr><td><code id="DMC_+3A_y">Y</code></td>
<td>
<p>Second variable (vector)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>One value between -1 and 1, characterizing the dependence between the variables
</p>


<h3>References</h3>

<p>http://interstat.statjournals.net/YEAR/2004/abstracts/0412001.php?Name=412001
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(HPC_KRC)
DMC(HPC_KRC$service[1:1000], HPC_KRC$cores_requested[1:1000])
</code></pre>

<hr>
<h2 id='FromSWF'>Convertor to a dataset from a Standart Workload Format</h2><span id='topic+FromSWF'></span>

<h3>Description</h3>

<p>This is a convertor from a Standart Workload Format (used to share the logfiles 
of High Performance Clusters) to an internally used in a package dataset format
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FromSWF(filename)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FromSWF_+3A_filename">filename</code></td>
<td>
<p>A mandatory field containing the path to SWF file</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Standart Workload Format is a single format to store and exchange
high performance cluster logs, that is used in Parallel Workload Archive.
See references for current standard. The SWF format may contain additional
data, but in this package only the 1st to 5th fields are used. One may also
need to manually fill in the header of the file in order to completely
prepare the resulting SWF file.
</p>


<h3>Value</h3>

<p>A dataset is returned, containing 'delay' as a vector of delays exhibited by
each task, 'total_cores' as the total busy CPUs in time of arrival of each task,
and 'workload' as total work left at each CPU.
</p>


<h3>References</h3>

<p>Feitelson, D.G. and Tsafrir, D. and Krakov D. 2012 Experience with the Parallel Workloads Archive. Technical Report 2012-6, School of Computer Science and Engineering, the Hebrew University April, 2012, Jerusalem, Israel
</p>
<p>https://www.cs.huji.ac.il/labs/parallel/workload/swf.html
</p>

<hr>
<h2 id='HPC_KRC'>
Workload data for High Performance Cluster of High Performance Data Center 
of Karelian Research Center, Russian Academy of Sciences. 
</h2><span id='topic+HPC_KRC'></span>

<h3>Description</h3>

<p>This is a complete data of the tasks which successfully finished executions
at HPC of HPDC KRC RAS for time period 06/03/2009 to 02/04/2011, a total of
8282 tasks. The data contains interarrival times, service times, cores that
tasks requested, cores really used (due to administrative limitations) and
delays excursed by tasks, all in seconds.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(HPC_KRC)</code></pre>


<h3>Format</h3>

<p>A data frame with 8281 observations on the following 5 variables.
</p>

<dl>
<dt><code>interarrival</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>service</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>cores_requested</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>cores_used</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>delays</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>http://cluster.krc.karelia.ru
</p>


<h3>References</h3>

<p>http://cluster.krc.karelia.ru
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(HPC_KRC)
</code></pre>

<hr>
<h2 id='HPC_KRC2'>
Workload data for High Performance Cluster of High Performance Data Center 
of Karelian Research Center, Russian Academy of Sciences. 
</h2><span id='topic+HPC_KRC2'></span>

<h3>Description</h3>

<p>This is a complete data of the tasks which successfully finished executions
at HPC of HPDC KRC RAS for time period 02/04/2011 to 16/04/2012, a total of
9389 tasks. The data contains interarrival times, service times, cores that
tasks used, and delays excursed by tasks, all in seconds.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(HPC_KRC2)</code></pre>


<h3>Format</h3>

<p>A data frame with 9389 observations on the following 3 variables.
</p>

<dl>
<dt><code>interarrival</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>service</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>cores_used</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>delays</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>http://cluster.krc.karelia.ru
</p>


<h3>References</h3>

<p>http://cluster.krc.karelia.ru
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(HPC_KRC2)
</code></pre>

<hr>
<h2 id='MaxThroughput2'>This function gives the maximal throughput of a two-server supercomputer (Markov) model with various service speeds, various rates of classes and random speed scaling at arrival/depature</h2><span id='topic+MaxThroughput2'></span>

<h3>Description</h3>

<p>This function gives the maximal throughput of a two-server supercomputer (Markov) model with various service speeds, various rates of classes and random speed scaling at arrival/depature
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MaxThroughput2(p1, pa, pd, mu1, mu2, f1, f2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MaxThroughput2_+3A_p1">p1</code></td>
<td>
<p>probability of class 1 arrival</p>
</td></tr>
<tr><td><code id="MaxThroughput2_+3A_pa">pa</code></td>
<td>
<p>probability of speed switch from f1 to f2 upon arrival</p>
</td></tr>
<tr><td><code id="MaxThroughput2_+3A_pd">pd</code></td>
<td>
<p>probability of speed switch from f2 to f1 upon departure</p>
</td></tr>
<tr><td><code id="MaxThroughput2_+3A_mu1">mu1</code></td>
<td>
<p>work amount parameter (for exponential distribution) for class 1</p>
</td></tr>
<tr><td><code id="MaxThroughput2_+3A_mu2">mu2</code></td>
<td>
<p>work amount parameter (for exponential distribution) for class 2</p>
</td></tr>
<tr><td><code id="MaxThroughput2_+3A_f1">f1</code></td>
<td>
<p>low speed (workunits per unit time)</p>
</td></tr>
<tr><td><code id="MaxThroughput2_+3A_f2">f2</code></td>
<td>
<p>high speed (workunits per unit time)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>maximal input rate, that is the stability boundary
</p>

<hr>
<h2 id='ToSWF'>Convertor from a dataset to Standart Workload Format</h2><span id='topic+ToSWF'></span>

<h3>Description</h3>

<p>This is a convertor from a correctly built dataset to a Standart Workload Format 
used to share the logfiles of High Performance Clusters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ToSWF(T, S, N, D, filename = "output.swf")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ToSWF_+3A_t">T</code></td>
<td>
<p>Interarrival times of tasks (a vector)</p>
</td></tr>
<tr><td><code id="ToSWF_+3A_s">S</code></td>
<td>
<p>Service times of tasks (a vector)</p>
</td></tr>
<tr><td><code id="ToSWF_+3A_n">N</code></td>
<td>
<p>Number of cores each task needs (a vector)</p>
</td></tr>
<tr><td><code id="ToSWF_+3A_d">D</code></td>
<td>
<p>The delays of tasks in a queue (a vector)</p>
</td></tr>
<tr><td><code id="ToSWF_+3A_filename">filename</code></td>
<td>
<p>The file to store the converted workload (output.swf by default)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Standart Workload Format is a single format to store and exchange
high performance cluster logs, that is used in Parallel Workload Archive.
See references for current standard. The SWF format may contain additional
data, but in this package only the 1st to 5th fields are used. One may also
need to manually fill in the header of the file in order to completely
prepare the resulting SWF file.
</p>


<h3>Value</h3>

<p>Nothing is returned, but a file is created in the current working directory (with default name output.swf) containing the converted data.
</p>


<h3>References</h3>

<p>Feitelson, D.G. and Tsafrir, D. and Krakov D. 2012 Experience with the Parallel Workloads Archive. Technical Report 2012-6, School of Computer Science and Engineering, the Hebrew University April, 2012, Jerusalem, Israel
</p>
<p>https://www.cs.huji.ac.il/labs/parallel/workload/swf.html
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(HPC_KRC)
ToSWF(HPC_KRC$interarrival, HPC_KRC$service, HPC_KRC$cores_requested, HPC_KRC$delay)

## End(Not run)
</code></pre>

<hr>
<h2 id='Wld'>Workload of a High Performance Cluster model</h2><span id='topic+Wld'></span>

<h3>Description</h3>

<p>This function computes the Kiefer-Wolfowitz modified vector for a HPC
model. This vector contains the work left on each of 'm' servers of a cluster
for the time of the arival of a task. Two methods are available, one for the 
case of concurrent server release (all the servers end a single task simultaneously),
other for independent release (service times on each server are independent).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Wld(T, S, N, m, method = "concurrent")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Wld_+3A_t">T</code></td>
<td>
<p>Interarrival times of tasks</p>
</td></tr>
<tr><td><code id="Wld_+3A_s">S</code></td>
<td>
<p>Service times of customers (a vector of length n, or a matrix nrows=n, ncols='m').</p>
</td></tr>
<tr><td><code id="Wld_+3A_n">N</code></td>
<td>
<p>Number of servers each customer needs</p>
</td></tr>
<tr><td><code id="Wld_+3A_m">m</code></td>
<td>
<p>Number of servers for a supercomputer</p>
</td></tr>
<tr><td><code id="Wld_+3A_method">method</code></td>
<td>
<p>Independent or concurrent</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataset is returned, containing 'delay' as a vector of delays exhibited by
each task, 'total_cores' as the total busy CPUs in time of arrival of each task,
and 'workload' as total work left at each CPU.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Wld(T=rexp(1000,1), S=rexp(1000,1), round(runif(1000,1,10)), 10)
</code></pre>

<hr>
<h2 id='X'>
Dataset with raw workload data from HPDC KRC RAS
</h2><span id='topic+X'></span>

<h3>Description</h3>

<p>Source data for workload of HPC of HPDC KRC RAS. More usable dataset
is HPC_KRC. This are raw times in sec. since 1 January 1970, for
tasks arrival times, start of execution times and end times.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(X)</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:8499, 1:3] 1.24e+09 1.24e+09 1.24e+09 1.24e+09 1.24e+09 ...
</p>


<h3>Source</h3>

<p>http://cluster.krc.karelia.ru
</p>


<h3>References</h3>

<p>http://cluster.krc.karelia.ru
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(X)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
