<!DOCTYPE html><html><head><title>Help for package HMTL</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {HMTL}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#HMTL-package'>
<p>Heterogeneous Multi-task Feature Learning</p></a></li>
<li><a href='#mockdata'>
<p>Mock Gene Data</p></a></li>
<li><a href='#MTL_class'><p>Multiple Classification Task Feature Learning</p></a></li>
<li><a href='#MTL_hetero'><p>Heterogeneous Multi-task Feature Learning</p></a></li>
<li><a href='#MTL_reg'><p>Robust Multi-Task Feature Learning</p></a></li>
<li><a href='#plot_HMTL'><p>Plot diagram of the information criterion vs. penalty parameters</p></a></li>
<li><a href='#Selection_HMTL'><p>Model Selection for Multi-task Feature Learning based on Bayesian Information Criterion (BIC)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Heterogeneous Multi-Task Feature Learning</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>The heterogeneous multi-task feature learning is a data integration method to conduct joint feature selection across multiple related data sets with different distributions. The algorithm can combine different types of learning tasks, including linear regression, Huber regression, adaptive Huber, and logistic regression. The modified version of Bayesian Information Criterion (BIC) is produced to measure the model performance. Package is based on Yuan Zhong, Wei Xu, and Xin Gao (2022) <a href="https://www.fields.utoronto.ca/talk-media/1/53/65/slides.pdf">https://www.fields.utoronto.ca/talk-media/1/53/65/slides.pdf</a>.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), stats, graphics, Matrix, pROC</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-05-04 01:46:00 UTC; adamzhong</td>
</tr>
<tr>
<td>Author:</td>
<td>Yuan Zhong [aut, cre],
  Wei Xu [aut],
  Xin Gao [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yuan Zhong &lt;aqua.zhong@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-05-04 19:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='HMTL-package'>
Heterogeneous Multi-task Feature Learning
</h2><span id='topic+HMTL'></span>

<h3>Description</h3>

<p><code>HMTL</code> package implements the block-wise sparse estimation by grouping the coefficients of related predictors across multiple tasks. The tasks can be either regression, Huber regression, adaptive Huber regression, and logistic regression, which provide a wide variety of data types for the integration. The robust methods, such as the Huber regression and adaptive Huber regression, can deal with outlier contamination based on Sun, Q., Zhou, W.-X. and Fan, J. (2020), and Wang, L., Zheng, C., Zhou, W. and Zhou, W.-X. (2021). The model selection applies the modified form of Bayesian information criterion to measure the mdoel performance, which has similar formulation as previous work developed by Gao, X.,  and Carroll, R. J., (2017).
</p>


<h3>Details</h3>

<p>In the context of multi-task learning, there are <code class="reqn">K</code> different data sets obtained from <code class="reqn">K</code> related sources. The data sets can be modeled by different types of learning tasks based on the data distributions.  Let the candidate features be denoted as <code class="reqn">\{M_1,M_2,...,M_j,...,M_p \}</code>. When the integrated data sets have different measurements, we assume the predictors to share some similarities. For example, the <code class="reqn">j</code>th predictors collected as <code class="reqn">M_j = (X_{1j}, X_{2j}, \cdots, X_{Kj})</code> in the table below represent the same type of feature in all related studies. In some cases, the tasks can share same set of predictor, then <code class="reqn">X_{1j} = X_{2j} = \cdots = X_{Kj}</code>.
</p>

<table>
<tr>
 <td style="text-align: left;">
Tasks </td><td style="text-align: left;">  Formula </td><td style="text-align: center;"> <code class="reqn">M_1</code> </td><td style="text-align: center;"> <code class="reqn">M_2</code> </td><td style="text-align: center;"> <code class="reqn">\dots</code> </td><td style="text-align: center;"> <code class="reqn">M_j</code> </td><td style="text-align: center;"> <code class="reqn">\dots</code> </td><td style="text-align: center;"> <code class="reqn">M_p</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
1 </td><td style="text-align: left;"> <code class="reqn">y_1: g_1(\mu_1) \sim</code> </td><td style="text-align: center;"> <code class="reqn">x_{11}\theta_{11}+</code> </td><td style="text-align: center;"> <code class="reqn">x_{12}\theta_{12}+</code> </td><td style="text-align: center;"> <code class="reqn">\dots</code>  </td><td style="text-align: center;"> <code class="reqn">x_{1j}\theta_{1j}+</code> </td><td style="text-align: center;"> <code class="reqn">\dots</code> </td><td style="text-align: center;"> <code class="reqn">x_{1p}\theta_{1p}</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
2 </td><td style="text-align: left;"> <code class="reqn">y_2: g_2(\mu_2) \sim</code> </td><td style="text-align: center;"> <code class="reqn">x_{21}\theta_{21}+</code> </td><td style="text-align: center;"> <code class="reqn">x_{22}\theta_{22}+</code> </td><td style="text-align: center;"> <code class="reqn">\dots</code> </td><td style="text-align: center;"> <code class="reqn">x_{2j}\theta_{2j}+</code> </td><td style="text-align: center;"> <code class="reqn">\dots</code>  </td><td style="text-align: center;"> <code class="reqn">x_{2p}\theta_{2p}</code>  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;">  ... </td><td style="text-align: center;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
K </td><td style="text-align: left;"> <code class="reqn">y_K: g_K(\mu_K) \sim</code> </td><td style="text-align: center;"> <code class="reqn">x_{K1}\theta_{K1}+</code> </td><td style="text-align: center;"> <code class="reqn">x_{K2}\theta_{K2}+</code> </td><td style="text-align: center;"> <code class="reqn">\dots</code> </td><td style="text-align: center;"> <code class="reqn">x_{Kj}\theta_{Kj}+</code> </td><td style="text-align: center;"> <code class="reqn">\dots</code> </td><td style="text-align: center;"> <code class="reqn">x_{Kp}\theta_{Kp}</code>  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>The coefficients can be grouped as the vector <code class="reqn">\theta^{(j)}</code> for the feature <code class="reqn">M_j</code>.
</p>

<table>
<tr>
 <td style="text-align: left;">
Platforms </td><td style="text-align: left;"> <code class="reqn">\bold{M_j}</code> </td><td style="text-align: left;"> </td><td style="text-align: left;"> <code class="reqn">\bold{\theta^{(j)}}</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
1 </td><td style="text-align: left;"> <code class="reqn">x_{1j}</code> </td><td style="text-align: left;"> </td><td style="text-align: left;"> <code class="reqn">\theta_{1j}</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
2 </td><td style="text-align: left;"> <code class="reqn">x_{2j}</code> </td><td style="text-align: left;"> </td><td style="text-align: left;"> <code class="reqn">\theta_{2j}</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
 </td><td style="text-align: left;"> ... </td><td style="text-align: left;"> </td><td style="text-align: left;"> ... </td>
</tr>
<tr>
 <td style="text-align: left;">
k </td><td style="text-align: left;"> <code class="reqn">x_{Kj}</code> </td><td style="text-align: left;"> </td><td style="text-align: left;"> <code class="reqn">\theta_{Kj}</code>
</td>
</tr>

</table>

<p>The heterogeneous multi-task feature learning <code>HMTL</code> can select significant features through the overall objective function:
</p>
<p style="text-align: center;"><code class="reqn">Q(\theta)=  \mathcal{L}(\theta) + \mathcal{R}(\theta).</code>
</p>

<p>The loss function is defined as <code class="reqn">\mathcal{L}(\theta) = \sum_{k=1}^K w_k \ell_k(\theta_k)</code>, which can be the composite quasi-likelihood or the composite form of (adaptive) Huber loss with additional robustification parameter <code class="reqn">\tau_k</code>. The penalty function is the mixed <code class="reqn">\ell_{2,1}</code> regularization, such that <code class="reqn">\mathcal{R}(\theta) =  \lambda \sum_{j=1}^p (\sum_{k=1}^K \theta_{kj}^2)^{1/2}</code>.
</p>
<p>This package also contains functions to provide the Bayesian information criterion:
</p>
<p style="text-align: center;"><code class="reqn">  BIC(s) = 2\mathcal{L}_s(\hat{\theta}) + d_s^{*} \gamma_n </code>
</p>

<p>with <code class="reqn">\mathcal{L}_s(\hat{\theta})</code> denoting the composite quasi-likelihood or adaptive Huber loss, <code class="reqn">d_s^{*}</code> measuring the model complexity and <code class="reqn">\gamma_n</code> being the penalty on the model complexity.
</p>
<p>In this package, the function <code><a href="#topic+MTL_reg">MTL_reg</a></code> deals with regression tasks, which can be outlier contaminated. The function <code><a href="#topic+MTL_class">MTL_class</a></code> is applied to model multiple classification tasks, and the function <code><a href="#topic+MTL_hetero">MTL_hetero</a></code> can integrate different types of tasks together.
</p>


<h3>Author(s)</h3>

<p>Yuan Zhong, Wei Xu, and Xin Gao
</p>
<p>Maintainer: Yuan Zhong &lt;aqua.zhong@gmail.com&gt;
</p>


<h3>References</h3>

<p>Zhong, Y., Xu, W., and Gao X., (2023) Heterogeneous multi-task feature learning with mixed <code class="reqn">\ell_{2,1}</code> regularization. Submitted
</p>
<p>Zhong, Y., Xu, W., and Gao X., (2023) Robust Multi-task Feature Learning. Submitted
</p>
<p>Gao, X.,  and Carroll, R. J., (2017) Data integration with high dimensionality. Biometrika, 104, 2, pp. 251-272
</p>
<p>Huber, P. J. (1964). Robust estimation of a location parameter. Ann. Math. Statist., 35, 73–101.
</p>
<p>Sun, Q., Zhou, W.-X. and Fan, J. (2020). Adaptive Huber regression. J. Amer. Statist. Assoc., 115, 254-265.
</p>
<p>Wang, L., Zheng, C., Zhou, W. and Zhou, W.-X. (2021). A new principle for tuning-free Huber regression. Stat. Sinica, 31, 2153-2177.
</p>

<hr>
<h2 id='mockdata'>
Mock Gene Data
</h2><span id='topic+mockdata1'></span><span id='topic+mockdata2'></span>

<h3>Description</h3>

<p>This data set is a mock version of two related research outcomes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("mockdata1")
data("mockdata2")</code></pre>


<h3>Format</h3>

<p>The <code>mockdata1</code> contains all predictor variables for four data sets, and the <code>mockdata2</code> is the list of four columns of response variables. The sample sizes are <code class="reqn">n_1 = 500, n_2 = 250, n_3 = 250</code>, and <code class="reqn">n_4 = 250</code>.
</p>
<p>The response varibles are heterogeneous, such that the first two columns are continuous data and last two are binary data. The predictors of each data matrix in <code>mockdata1</code> have 500 columns of variables, and the columns in different data matrices are matched. For example, the first column in the first data matrix represents the same type of feature as the first columns in other three data matrices. Among all canadidate predictors, the response variables are set to be associated with the first 22 columns, and the remaining columns are not important predictors.
</p>


<h3>Details</h3>

<p>This data set is used as an example to implement functions in the package.
</p>

<hr>
<h2 id='MTL_class'>Multiple Classification Task Feature Learning</h2><span id='topic+MTL_class'></span>

<h3>Description</h3>

<p><code>MTL_class</code> conducts multi-tasks feature learning to the learning tasks with binary response variables, namely logistic regression. The penalty function applies a mixed <code class="reqn">\ell_{2,1}</code> norm to combine regression coefficients of predictor shared across all tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MTL_class(
  y,
  x,
  lambda,
  Kn,
  p,
  n,
  beta = 0.1,
  import_w = 1,
  tol = 0.05,
  max_iter = 100,
  Complete = "True",
  diagnostics = FALSE,
  gamma = 1,
  alpha = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MTL_class_+3A_y">y</code></td>
<td>
<p>List. A list of binary responses vectors for all tasks.</p>
</td></tr>
<tr><td><code id="MTL_class_+3A_x">x</code></td>
<td>
<p>List. Listing matrices of the predictors for all tasks align with the same order as in y.</p>
</td></tr>
<tr><td><code id="MTL_class_+3A_lambda">lambda</code></td>
<td>
<p>Numeric. The penalty parameter used for block-wise regularization (<code class="reqn">\ell_{2,1}</code> norm).</p>
</td></tr>
<tr><td><code id="MTL_class_+3A_kn">Kn</code></td>
<td>
<p>Numeric. The number of tasks with binary responses.</p>
</td></tr>
<tr><td><code id="MTL_class_+3A_p">p</code></td>
<td>
<p>Numeric. The number of features.</p>
</td></tr>
<tr><td><code id="MTL_class_+3A_n">n</code></td>
<td>
<p>Numeric or vector. If only one numeric value is provided, equal sample size will be assumed for each task. If a vector is provided, then the elements are the sample sizes for all tasks.</p>
</td></tr>
<tr><td><code id="MTL_class_+3A_beta">beta</code></td>
<td>
<p>(<strong>optional</strong>). Numeric or matrix. An initial value or matrix of values <code class="reqn">p</code> by <code class="reqn">K</code> for the estimation. The default value is 0.1.</p>
</td></tr>
<tr><td><code id="MTL_class_+3A_import_w">import_w</code></td>
<td>
<p>Numeric or vector. The weights assigned to different tasks. An equal weight is set as the default.</p>
</td></tr>
<tr><td><code id="MTL_class_+3A_tol">tol</code></td>
<td>
<p>(<strong>optional</strong>). Numeric. The tolerance level of optimation.</p>
</td></tr>
<tr><td><code id="MTL_class_+3A_max_iter">max_iter</code></td>
<td>
<p>(<strong>optional</strong>). Numeric. The maximum number of iteration steps.</p>
</td></tr>
<tr><td><code id="MTL_class_+3A_complete">Complete</code></td>
<td>
<p>Logic input. If the predictors in each task are all measured, set 'Complete == TRUE'; If some predictors in some but not all task are all measured, set'Complete == FALSE', and the missing values are imputed by column mean. The adjustment weights will be assigned based on the completeness of the predictors.</p>
</td></tr>
<tr><td><code id="MTL_class_+3A_diagnostics">diagnostics</code></td>
<td>
<p>Logic input. If 'diagnostics == TRUE', the function provides Bayesian information criterion, and the selected model performance is evalued by the MSE and MAE for tasks with continuous response and the AUC and deviance for tasks with binary responses.</p>
</td></tr>
<tr><td><code id="MTL_class_+3A_gamma">gamma</code></td>
<td>
<p>(<strong>optional</strong>). Numeric. Step size for each inner iteration. The default is equal to 1.</p>
</td></tr>
<tr><td><code id="MTL_class_+3A_alpha">alpha</code></td>
<td>
<p>(<strong>optional</strong>). Numeric. A tuning parameter for BIC penalty. The default is equal to 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including the following terms will be returned:
</p>

<dl>
<dt><code>beta</code></dt><dd><p>A <code class="reqn">p</code> by <code class="reqn">K</code> matrix of estimated sparse parameters.</p>
</dd>
<dt><code>Task type</code></dt><dd><p>The models used in each task.</p>
</dd>
<dt><code>Task weights</code></dt><dd><p>The weights assigned to each task.</p>
</dd>
<dt><code>Selected_List</code></dt><dd><p>The index of non-zero parameters.</p>
</dd>
</dl>

<p>If 'diagnostics = TRUE', the following terms will be returned:
</p>

<dl>
<dt><code>Bayesian_Information</code></dt><dd><p>Table of the information criterion: Composite likelihood, Degree of freedom, and (peudo or robust) Bayesian informtion criterion.</p>
</dd>
<dt><code>Class_Perform</code></dt><dd><p>Table of the model performance for classification tasks: the area under ROC curve (AUC), and the deviance (DEV) estimated by 'glm'.</p>
</dd>
<dt><code>Residuals</code></dt><dd><p>The residuals for all tasks.</p>
</dd>
</dl>



<h3>References</h3>

<p>Zhong, Y., Xu, W., and Gao X., (2023) Heterogeneous multi-task feature learning with mixed <code class="reqn">\ell_{2,1}</code> regularization. Submitted
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x_class &lt;- list(mockdata1[[3]],mockdata1[[4]])
y_class &lt;- list(mockdata2[[3]],mockdata2[[4]])
model &lt;- MTL_class(y_class,x_class, lambda = 2/11 , Kn = 2, p=500,
                  n = 250 ,gamma = 1, Complete = FALSE, diagnostics = TRUE, alpha = 2)
# Selected non-zero coefficients
model$beta[model$Selected_List,]
# Estimated Pseudo-BIC
model$Bayesian_Information
# Classification accuracy
model$Class_Perform
</code></pre>

<hr>
<h2 id='MTL_hetero'>Heterogeneous Multi-task Feature Learning</h2><span id='topic+MTL_hetero'></span>

<h3>Description</h3>

<p><code>MTL_hetero</code> conducts multi-tasks feature learning to different types of learning tasks, including linear regression, Huber regression, adaptive Huber, and logistic regression. The penalty function applies a mixed <code class="reqn">\ell_{2,1}</code> norm to combine regression coefficients of predictor shared across all tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MTL_hetero(
  y,
  x,
  lambda,
  Kn,
  p,
  n,
  beta = 0.1,
  tau = 1.45,
  Cont_Model = "adaptive Huber",
  import_w = 1,
  tol = 0.05,
  max_iter = 100,
  Complete = "True",
  diagnostics = FALSE,
  gamma = 1,
  alpha = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MTL_hetero_+3A_y">y</code></td>
<td>
<p>List. A list of responses vectors for all tasks. The order of the list put the continuous responses before the binary responses.</p>
</td></tr>
<tr><td><code id="MTL_hetero_+3A_x">x</code></td>
<td>
<p>List. Listing matrices of the predictors for all tasks align with the same order as in y.</p>
</td></tr>
<tr><td><code id="MTL_hetero_+3A_lambda">lambda</code></td>
<td>
<p>Numeric. The penalty parameter used for block-wise regularization (<code class="reqn">\ell_{2,1}</code> norm).</p>
</td></tr>
<tr><td><code id="MTL_hetero_+3A_kn">Kn</code></td>
<td>
<p>Vector of two elements. First element is the number of tasks with continuous responses, and the second element is the number of tasks with binary responses.</p>
</td></tr>
<tr><td><code id="MTL_hetero_+3A_p">p</code></td>
<td>
<p>Numeric. The number of features.</p>
</td></tr>
<tr><td><code id="MTL_hetero_+3A_n">n</code></td>
<td>
<p>Numeric or vector. If only one numeric value is provided, equal sample size will be assumed for each task. If a vector is provided, then the elements are the sample sizes for all tasks.</p>
</td></tr>
<tr><td><code id="MTL_hetero_+3A_beta">beta</code></td>
<td>
<p>(<strong>optional</strong>). Numeric or matrix. An initial value or matrix of values <code class="reqn">p</code> by <code class="reqn">K</code> for the estimation. The default value is 0.1.</p>
</td></tr>
<tr><td><code id="MTL_hetero_+3A_tau">tau</code></td>
<td>
<p>Numeric or vector. The robustification parameter used for methods &quot;Huber regression&quot; or &quot;Adaptive Huber&quot;. The default value is 1.45.</p>
</td></tr>
<tr><td><code id="MTL_hetero_+3A_cont_model">Cont_Model</code></td>
<td>
<p>Character(&quot;regression&quot;, &quot;Huber regression&quot;, or &quot;adaptive Huber&quot;). The models used for tasks with continuous responses.</p>
</td></tr>
<tr><td><code id="MTL_hetero_+3A_import_w">import_w</code></td>
<td>
<p>Numeric or vector. The weights assigned to different tasks. An equal weight is set as the default.</p>
</td></tr>
<tr><td><code id="MTL_hetero_+3A_tol">tol</code></td>
<td>
<p>(<strong>optional</strong>). Numeric. The tolerance level of optimation.</p>
</td></tr>
<tr><td><code id="MTL_hetero_+3A_max_iter">max_iter</code></td>
<td>
<p>(<strong>optional</strong>). Numeric. The maximum number of iteration steps.</p>
</td></tr>
<tr><td><code id="MTL_hetero_+3A_complete">Complete</code></td>
<td>
<p>Logic input. If the predictors in each task are all measured, set 'Complete == TRUE'; If some predictors in some but not all task are all measured, set'Complete == FALSE', and the missing values are imputed by column mean. The adjustment weights will be assigned based on the completeness of the predictors.</p>
</td></tr>
<tr><td><code id="MTL_hetero_+3A_diagnostics">diagnostics</code></td>
<td>
<p>Logic input. If 'diagnostics == TRUE', the function provides Bayesian information criterion, and the selected model performance is evalued by the MSE and MAE for tasks with continuous response and the AUC and deviance for tasks with binary responses.</p>
</td></tr>
<tr><td><code id="MTL_hetero_+3A_gamma">gamma</code></td>
<td>
<p>(<strong>optional</strong>). Numeric. Step size for each inner iteration. The default is equal to 1.</p>
</td></tr>
<tr><td><code id="MTL_hetero_+3A_alpha">alpha</code></td>
<td>
<p>(<strong>optional</strong>). Numeric. A tuning parameter for BIC penalty. The default is equal to 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including the following terms will be returned:
</p>

<dl>
<dt><code>beta</code></dt><dd><p>A <code class="reqn">p</code> by <code class="reqn">K</code> matrix of estimated sparse parameters.</p>
</dd>
<dt><code>Task type</code></dt><dd><p>The models used in each task.</p>
</dd>
<dt><code>Task weights</code></dt><dd><p>The weights assigned to each task.</p>
</dd>
<dt><code>Selected_List</code></dt><dd><p>The index of non-zero parameters.</p>
</dd>
</dl>

<p>If 'diagnostics = TRUE', the following terms will be returned:
</p>

<dl>
<dt><code>Bayesian_Information</code></dt><dd><p>Table of the information criterion: Composite likelihood, Degree of freedom, and (peudo or robust) Bayesian informtion criterion.</p>
</dd>
<dt><code>Reg_Error</code></dt><dd><p>Table of the model performance for (Huber) regressions: the mean square error (MSE), and the mean absolute error (MAE).</p>
</dd>
<dt><code>Class_Perform</code></dt><dd><p>Table of the model performance for classification tasks: the area under ROC curve (AUC), and the deviance (DEV) estimated by 'glm'.</p>
</dd>
<dt><code>Residuals</code></dt><dd><p>The residuals for all tasks.</p>
</dd>
</dl>



<h3>Note</h3>

<p>When penalty parameter is too small, the estimated coefficients may have <code class="reqn">p \ge n</code>. The algorithm can provide the estimated values, but the <code>diagnostics</code>'s results will not be given.
</p>


<h3>References</h3>

<p>Zhong, Y., Xu, W., and Gao X., (2023) Heterogeneous multi-task feature learning with mixed <code class="reqn">\ell_{2,1}</code> regularization. Submitted
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- MTL_hetero(mockdata2,mockdata1, lambda =2.5, Kn = c(2,2), p=500,n = c(500,250,250,250),
                    gamma = 2, Complete = FALSE, diagnostics = TRUE, alpha = 2)
# Selected non-zero coefficients
model$beta[model$Selected_List,]
# Estimated Pseudo-BIC
model$Bayesian_Information
# Regression error
model$Reg_Error
# Classification accuracy
model$Class_Perform
</code></pre>

<hr>
<h2 id='MTL_reg'>Robust Multi-Task Feature Learning</h2><span id='topic+MTL_reg'></span>

<h3>Description</h3>

<p><code>MTL_reg</code> conducts multi-tasks feature learning to the learning tasks with continous response variables, such as the linear regression, Huber regression, adaptive Huber. The adaptive Huber method is based on Sun, Q., Zhou, W.-X. and Fan, J. (2020) and Wang, L., Zheng, C., Zhou, W. and Zhou, W.-X. (2021). The penalty function applies a mixed <code class="reqn">\ell_{2,1}</code> norm to combine regression coefficients of predictor shared across all tasks.
The Huber regression and adaptive Huber regression need the robustification parameter <code class="reqn">\tau_k</code> to strike a balance between the unbiasedness and robustness, and the adaptive method can determine this parameter by a tuning-free principle.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MTL_reg(
  y,
  x,
  lambda,
  Kn,
  p,
  n,
  beta = 0.1,
  tau = 1.45,
  Cont_Model = "adaptive Huber",
  import_w = 1,
  tol = 0.05,
  max_iter = 100,
  Complete = "True",
  diagnostics = FALSE,
  gamma = 1,
  alpha = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MTL_reg_+3A_y">y</code></td>
<td>
<p>List. A list of continuous responses vectors for all tasks.</p>
</td></tr>
<tr><td><code id="MTL_reg_+3A_x">x</code></td>
<td>
<p>List. Listing matrices of the predictors for all tasks align with the same order as in y.</p>
</td></tr>
<tr><td><code id="MTL_reg_+3A_lambda">lambda</code></td>
<td>
<p>Numeric. The penalty parameter used for block-wise regularization (<code class="reqn">\ell_{2,1}</code> norm).</p>
</td></tr>
<tr><td><code id="MTL_reg_+3A_kn">Kn</code></td>
<td>
<p>Numeric. The number of tasks with continuous responses.</p>
</td></tr>
<tr><td><code id="MTL_reg_+3A_p">p</code></td>
<td>
<p>Numeric. The number of features.</p>
</td></tr>
<tr><td><code id="MTL_reg_+3A_n">n</code></td>
<td>
<p>Numeric or vector. If only one numeric value is provided, equal sample size will be assumed for each task. If a vector is provided, then the elements are the sample sizes for all tasks.</p>
</td></tr>
<tr><td><code id="MTL_reg_+3A_beta">beta</code></td>
<td>
<p>(<strong>optional</strong>). Numeric or matrix. An initial value or matrix of values <code class="reqn">p</code> by <code class="reqn">K</code> for the estimation. The default value is 0.1.</p>
</td></tr>
<tr><td><code id="MTL_reg_+3A_tau">tau</code></td>
<td>
<p>Numeric or vector. The robustification parameter used for methods &quot;Huber regression&quot; or &quot;Adaptive Huber&quot;. The default value is 1.45.</p>
</td></tr>
<tr><td><code id="MTL_reg_+3A_cont_model">Cont_Model</code></td>
<td>
<p>Character(&quot;regression&quot;, &quot;Huber regression&quot;, or &quot;adaptive Huber&quot;). The models used for tasks with continuous responses.</p>
</td></tr>
<tr><td><code id="MTL_reg_+3A_import_w">import_w</code></td>
<td>
<p>Numeric or vector. The weights assigned to different tasks. An equal weight is set as the default.</p>
</td></tr>
<tr><td><code id="MTL_reg_+3A_tol">tol</code></td>
<td>
<p>(<strong>optional</strong>). Numeric. The tolerance level of optimation.</p>
</td></tr>
<tr><td><code id="MTL_reg_+3A_max_iter">max_iter</code></td>
<td>
<p>(<strong>optional</strong>). Numeric. The maximum number of iteration steps.</p>
</td></tr>
<tr><td><code id="MTL_reg_+3A_complete">Complete</code></td>
<td>
<p>Logic input. If the predictors in each task are all measured, set 'Complete == TRUE'; If some predictors in some but not all task are all measured, set'Complete == FALSE', and the missing values are imputed by column mean. The adjustment weights will be assigned based on the completeness of the predictors.</p>
</td></tr>
<tr><td><code id="MTL_reg_+3A_diagnostics">diagnostics</code></td>
<td>
<p>Logic input. If 'diagnostics == TRUE', the function provides Bayesian information criterion, and the selected model performance is evalued by the MSE and MAE for tasks with continuous response and the AUC and deviance for tasks with binary responses.</p>
</td></tr>
<tr><td><code id="MTL_reg_+3A_gamma">gamma</code></td>
<td>
<p>(<strong>optional</strong>). Numeric. Step size for each inner iteration. The default is equal to 1.</p>
</td></tr>
<tr><td><code id="MTL_reg_+3A_alpha">alpha</code></td>
<td>
<p>(<strong>optional</strong>). Numeric. A tuning parameter for BIC penalty. The default is equal to 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including the following terms will be returned:
</p>

<dl>
<dt><code>beta</code></dt><dd><p>A <code class="reqn">p</code> by <code class="reqn">K</code> matrix of estimated sparse parameters.</p>
</dd>
<dt><code>Task type</code></dt><dd><p>The models used in each task.</p>
</dd>
<dt><code>Task weights</code></dt><dd><p>The weights assigned to each task.</p>
</dd>
<dt><code>Selected_List</code></dt><dd><p>The index of non-zero parameters.</p>
</dd>
</dl>

<p>If 'diagnostics = TRUE', the following terms will be returned:
</p>

<dl>
<dt><code>Bayesian_Information</code></dt><dd><p>Table of the information criterion: Composite likelihood, Degree of freedom, and (peudo or robust) Bayesian informtion criterion.</p>
</dd>
<dt><code>Reg_Error</code></dt><dd><p>Table of the model performance for (Huber) regressions: the mean square error (MSE), and the mean absolute error (MAE).</p>
</dd>
<dt><code>Residuals</code></dt><dd><p>The residuals for all tasks.</p>
</dd>
</dl>



<h3>References</h3>

<p>Huber, P. J. (1964). Robust estimation of a location parameter. Ann. Math. Statist., 35, 73–101.
</p>
<p>Sun, Q., Zhou, W.-X. and Fan, J. (2020). Adaptive Huber regression. J. Amer. Statist. Assoc., 115, 254-265.
</p>
<p>Wang, L., Zheng, C., Zhou, W. and Zhou, W.-X. (2021). A new principle for tuning-free Huber regression. Stat. Sinica, 31, 2153-2177.
</p>
<p>Zhong, Y., Xu, W., and Gao X., (2023) Robust Multi-task Feature Learning. Submitted
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x_reg &lt;- list(mockdata1[[1]],mockdata1[[2]])
y_reg &lt;- list(mockdata2[[1]],mockdata2[[2]])
model &lt;- MTL_reg(y_reg,x_reg, lambda = 2.5  , Kn = 2, p=500,
                n = c(500,250 ),gamma = 2, Complete = FALSE, diagnostics = TRUE, alpha = 2)

# Selected non-zero coefficients
model$beta[model$Selected_List,]
# Estimated Pseudo-BIC
model$Bayesian_Information
# Regression error
model$Reg_Error
</code></pre>

<hr>
<h2 id='plot_HMTL'>Plot diagram of the information criterion vs. penalty parameters</h2><span id='topic+plot_HMTL'></span>

<h3>Description</h3>

<p>Plot a diagram to illustrate the change of Bayesian information criterion with different penalty paameters for model selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_HMTL(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_HMTL_+3A_x">x</code></td>
<td>
<p>Object of class &quot;Model Selection&quot; created by <code>Selection_HMTL</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>X axis represents the value of penalty parameters, and y axis represents the estimated values of the composite likelihood, degree of freedom for model complexity, and the (robust) Bayesian information criterion.
</p>

<hr>
<h2 id='Selection_HMTL'>Model Selection for Multi-task Feature Learning based on Bayesian Information Criterion (BIC)</h2><span id='topic+Selection_HMTL'></span>

<h3>Description</h3>

<p><code>Selection_HMTL</code> can be used to search the optimal candidate model based on Bayesian Information Criterion (BIC).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Selection_HMTL(
  y,
  x,
  lambda,
  Kn,
  p,
  n,
  beta = 0.1,
  tau = 1.45,
  Cont_Model = "adaptive Huber",
  type = "Heterogeneity",
  import_w = 1,
  tol = 0.05,
  max_iter = 100,
  Complete = "True",
  diagnostics = FALSE,
  gamma = 1,
  alpha = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Selection_HMTL_+3A_y">y</code></td>
<td>
<p>List. A list of responses vectors for all tasks. The order of the list put the continuous responses before the binary responses.</p>
</td></tr>
<tr><td><code id="Selection_HMTL_+3A_x">x</code></td>
<td>
<p>List. Listing matrices of the predictors for all tasks align with the same order as in y.</p>
</td></tr>
<tr><td><code id="Selection_HMTL_+3A_lambda">lambda</code></td>
<td>
<p>Numeric. The penalty parameter used for block-wise regularization (<code class="reqn">\ell_{2,1}</code> norm).</p>
</td></tr>
<tr><td><code id="Selection_HMTL_+3A_kn">Kn</code></td>
<td>
<p>Vector of two elements. First element is the number of tasks with continuous responses, and the second element is the number of tasks with binary responses.</p>
</td></tr>
<tr><td><code id="Selection_HMTL_+3A_p">p</code></td>
<td>
<p>Numeric. The number of features.</p>
</td></tr>
<tr><td><code id="Selection_HMTL_+3A_n">n</code></td>
<td>
<p>Numeric or vector. If only one numeric value is provided, equal sample size will be assumed for each task. If a vector is provided, then the elements are the sample sizes for all tasks.</p>
</td></tr>
<tr><td><code id="Selection_HMTL_+3A_beta">beta</code></td>
<td>
<p>(<strong>optional</strong>). Numeric or matrix. An initial value or matrix of values <code class="reqn">p</code> by <code class="reqn">K</code> for the estimation. The default value is 0.1.</p>
</td></tr>
<tr><td><code id="Selection_HMTL_+3A_tau">tau</code></td>
<td>
<p>Numeric or vector. The robustification parameter used for methods &quot;Huber regression&quot; or &quot;Adaptive Huber&quot;. The default value is 1.45.</p>
</td></tr>
<tr><td><code id="Selection_HMTL_+3A_cont_model">Cont_Model</code></td>
<td>
<p>Character(&quot;regression&quot;, &quot;Huber regression&quot;, or &quot;adaptive Huber&quot;). The models used for tasks with continuous responses.</p>
</td></tr>
<tr><td><code id="Selection_HMTL_+3A_type">type</code></td>
<td>
<p>Character(&quot;Heterogeneity&quot;, &quot;Continuous&quot; or &quot;Binary&quot;). <code>type = "Heterogeneity"</code> used for <code> MTL_hetero</code>; <code>type = "Continuous"</code> used for <code> MTL_reg</code>; and <code>type = "Binary"</code> used for <code> MTL_class</code>.</p>
</td></tr>
<tr><td><code id="Selection_HMTL_+3A_import_w">import_w</code></td>
<td>
<p>Numeric or vector. The weights assigned to different tasks. An equal weight is set as the default.</p>
</td></tr>
<tr><td><code id="Selection_HMTL_+3A_tol">tol</code></td>
<td>
<p>(<strong>optional</strong>). Numeric. The tolerance level of optimation.</p>
</td></tr>
<tr><td><code id="Selection_HMTL_+3A_max_iter">max_iter</code></td>
<td>
<p>(<strong>optional</strong>). Numeric. The maximum number of iteration steps.</p>
</td></tr>
<tr><td><code id="Selection_HMTL_+3A_complete">Complete</code></td>
<td>
<p>Logic input. If the predictors in each task are all measured, set 'Complete == TRUE'; If some predictors in some but not all task are all measured, set'Complete == FALSE', and the missing values are imputed by column mean. The adjustment weights will be assigned based on the completeness of the predictors.</p>
</td></tr>
<tr><td><code id="Selection_HMTL_+3A_diagnostics">diagnostics</code></td>
<td>
<p>Logic input. If 'diagnostics == TRUE', the function provides Bayesian information criterion, and the selected model performance is evalued by the MSE and MAE for tasks with continuous response and the AUC and deviance for tasks with binary responses.</p>
</td></tr>
<tr><td><code id="Selection_HMTL_+3A_gamma">gamma</code></td>
<td>
<p>(<strong>optional</strong>). Numeric. Step size for each inner iteration. The default is equal to 1.</p>
</td></tr>
<tr><td><code id="Selection_HMTL_+3A_alpha">alpha</code></td>
<td>
<p>(<strong>optional</strong>). Numeric. A tuning parameter for BIC penalty. The default is equal to 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Bayesian information criterion is given by
</p>
<p style="text-align: center;"><code class="reqn">  BIC(s) = 2\mathcal{L}_s(\hat{\theta}) + d_s^{*} \gamma_n, </code>
</p>

<p>where <code class="reqn">\hat{\theta}</code> is the estimated coefficients and <code class="reqn">s</code> is denoted the selected support set of <code class="reqn">\hat{\theta}</code>.
In addition, <code class="reqn">\mathcal{L}_s(\hat{\theta})</code> denoted the estimated composite quasi-likelihood or adaptive Huber loss evaluated as the <code class="reqn">\hat{\theta}</code>.
The degree of freedom <code class="reqn">d_s^{*}</code> can measure the model complexity, which is estimated by <code class="reqn">tr(H_s^{-1}(\hat{\theta}) J_s(\hat{\theta}) )</code>. The sensitivity matrix and specificity matrix can be given by <code class="reqn">H(\theta) = E(\nabla^2 \mathcal{L}( {\theta}))</code> and <code class="reqn">J(\theta) = -Cov(\nabla \mathcal{L}( {\theta}))</code>.
The penalty term <code class="reqn">\gamma_n</code> can be defined by users.
</p>


<h3>Value</h3>

<p>A table of Bayesian Information Criterion (BIC)
</p>

<dl>
<dt><code>lambda</code></dt><dd><p>A list of penalty parameters.</p>
</dd>
<dt><code>Compo_likelihood</code></dt><dd><p>Sum of empirical loss functions estimated based on the selected parameters .</p>
</dd>
<dt><code>Degree of freedom</code></dt><dd><p>Penalty component based on the selected parameters.</p>
</dd>
<dt><code>Info criterion</code></dt><dd><p>Bayesian Information Criterion (BIC): robust BIC or pseudo BIC.</p>
</dd>
</dl>



<h3>References</h3>

<p>Y. Zhong, W. Xu, and X. Gao (2023) Robust Multi-task Feature Learning. Submitted
</p>
<p>Gao, X and Carroll, R. J. (2017) Data integration with high dimensionality. Biometrika, 104, 2, pp. 251-272
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lambda &lt;- c(1.2, 2.0, 2.3, 2.8)
cv.mtl &lt;- Selection_HMTL(mockdata2,mockdata1, lambda =lambda, Kn = c(2,2), p=500,
               n = c(500,250,250,250),gamma = 2, Complete = FALSE, diagnostics = TRUE, alpha = 2)
plot_HMTL(cv.mtl)
cv.mtl$Selection_Results
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
