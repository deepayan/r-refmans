<!DOCTYPE html><html><head><title>Help for package CSMES</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {CSMES}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#BFP'><p>Business failure prediction demonstration data set</p></a></li>
<li><a href='#brierCurve'><p>Calculates Brier Curve</p></a></li>
<li><a href='#CSMES.ensNomCurve'><p>CSMES Training Stage 2: Extract an ensemble nomination curve (cost curve- or Brier curve-based) from a set of Pareto-optimal ensemble classifiers</p></a></li>
<li><a href='#CSMES.ensSel'><p>CSMES Training Stage 1: Cost-Sensitive Multicriteria Ensemble Selection resulting in a Pareto frontier of candidate ensemble classifiers</p></a></li>
<li><a href='#CSMES.predict'><p>CSMES scoring: generate predictions for the optimal ensemble classifier according to CSMES in function of cost information.</p></a></li>
<li><a href='#CSMES.predictPareto'><p>Generate predictions for all Pareto-optimal ensemble classifier candidates selected through CSMES</p></a></li>
<li><a href='#plotBrierCurve'><p>Plots Brier Curve</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Cost-Sensitive Multi-Criteria Ensemble Selection for Uncertain
Cost Conditions</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.1</td>
</tr>
<tr>
<td>Author:</td>
<td>Koen W. De Bock, Kristof Coussement and Stefan Lessmann</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Koen W. De Bock &lt;kdebock@audencia.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions for cost-sensitive multi-criteria ensemble selection (CSMES) (as described in De bock et al. (2020) &lt;<a href="https://doi.org/10.1016%2Fj.ejor.2020.01.052">doi:10.1016/j.ejor.2020.01.052</a>&gt;) for cost-sensitive learning under unknown cost conditions.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>mco (&ge; 1.0-15.1), ROCR (&ge; 1.0-7), rpart (&ge; 4.1-15), zoo (&ge;
1.8-6), graphics (&ge; 3.5.1), stats (&ge; 3.5.1), caTools (&ge;
1.18.0), data.table (&ge; 1.12.2)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-02-03 13:23:39 UTC; kdebock</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-02-03 14:02:31 UTC</td>
</tr>
</table>
<hr>
<h2 id='BFP'>Business failure prediction demonstration data set</h2><span id='topic+BFP'></span>

<h3>Description</h3>

<p>Business failure prediction demonstration data set. Contains financial ratios and firmographics as independent variables for 522 anonymized European companies. The Class column indicates failure (class 1) or survival (class 0) over a 1-year period.
</p>


<h3>Author(s)</h3>

<p>Koen W. De Bock, <a href="mailto:kdebock@audencia.com">kdebock@audencia.com</a>
</p>


<h3>References</h3>

<p>De Bock, K.W., Lessmann, S. And Coussement, K., Cost-sensitive business failure prediction
when misclassification costs are uncertain: A heterogeneous ensemble selection approach,
European Journal of Operational Research (2020), doi: 10.1016/j.ejor.2020.01.052.
</p>

<hr>
<h2 id='brierCurve'>Calculates Brier Curve</h2><span id='topic+brierCurve'></span>

<h3>Description</h3>

<p>This function calculates the Brier curve (both in terms of cost and skew) based on a set of predictions generated by a binary classifier. Brier curves allow an evaluation of classifier performance in cost space. This code is an adapted version from the authors' original implementation, available through http://dmip.webs.upv.es/BrierCurves/BrierCurves.R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>brierCurve(labels, preds, resolution = 0.001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="brierCurve_+3A_labels">labels</code></td>
<td>
<p>Vector with true class labels</p>
</td></tr>
<tr><td><code id="brierCurve_+3A_preds">preds</code></td>
<td>
<p>Vector with predictions (real-valued or discrete)</p>
</td></tr>
<tr><td><code id="brierCurve_+3A_resolution">resolution</code></td>
<td>
<p>Value for the determination of percentile intervals. Defaults to 1/1000.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>object of the class <code>brierCurve</code> which is a list with the following components:
</p>
<table>
<tr><td><code>brierCurveCost</code></td>
<td>
<p>Cost-based Brier curve, represented as (cost,loss) coordinates</p>
</td></tr>
<tr><td><code>brierCurveSkew</code></td>
<td>
<p>Skew-based Brier curve, represented as (skew,loss) coordinates</p>
</td></tr>
<tr><td><code>auc_brierCurveCost</code></td>
<td>
<p>Area under the cost-based Brier curve.</p>
</td></tr>
<tr><td><code>auc_brierCurveSkew</code></td>
<td>
<p>Area under the skew-based Brier curve.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Koen W. De Bock, <a href="mailto:kdebock@audencia.com">kdebock@audencia.com</a>
</p>


<h3>References</h3>

<p>Hernandez-Orallo, J., Flach, P., &amp; Ferri, C. (2011). Brier Curves: a New Cost-Based Visualisation of Classifier Performance. Proceedings of the 28th International Conference on Machine Learning (ICML-11), 585â€“592.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotBrierCurve">plotBrierCurve</a></code>, <code><a href="#topic+CSMES.ensNomCurve">CSMES.ensNomCurve</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##load data
library(rpart)
data(BFP)
##generate random order vector
BFP_r&lt;-BFP[sample(nrow(BFP),nrow(BFP)),]
size&lt;-nrow(BFP_r)
##size&lt;-300
train&lt;-BFP_r[1:floor(size/3),]
val&lt;-BFP_r[ceiling(size/3):floor(2*size/3),]
test&lt;-BFP_r[ceiling(2*size/3):size,]
##train CART decision tree model
model=rpart(as.formula(Class~.),train,method="class")
##generate predictions for the tes set
preds&lt;-predict(model,newdata=test)[,2]
##calculate brier curve
bc&lt;-brierCurve(test[,"Class"],preds)
</code></pre>

<hr>
<h2 id='CSMES.ensNomCurve'>CSMES Training Stage 2: Extract an ensemble nomination curve (cost curve- or Brier curve-based) from a set of Pareto-optimal ensemble classifiers</h2><span id='topic+CSMES.ensNomCurve'></span>

<h3>Description</h3>

<p>Generates an ensemble nomination curve from a set of Pareto-optimal ensemble definitions as identified through <code>CSMES.ensSel)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CSMES.ensNomCurve(
  ensSelModel,
  memberPreds,
  y,
  curveType = c("costCurve", "brierSkew", "brierCost"),
  method = c("classPreds", "probPreds"),
  plotting = FALSE,
  nrBootstraps = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CSMES.ensNomCurve_+3A_ensselmodel">ensSelModel</code></td>
<td>
<p>ensemble selection model (output of <code>CSMES.ensSel</code>)</p>
</td></tr>
<tr><td><code id="CSMES.ensNomCurve_+3A_memberpreds">memberPreds</code></td>
<td>
<p>matrix containing ensemble member library predictions</p>
</td></tr>
<tr><td><code id="CSMES.ensNomCurve_+3A_y">y</code></td>
<td>
<p>Vector with true class labels. Currently, a dichotomous outcome variable is supported</p>
</td></tr>
<tr><td><code id="CSMES.ensNomCurve_+3A_curvetype">curveType</code></td>
<td>
<p>the type of cost curve used to construct the ensemble nomination curve. Shoul be &quot;brierCost&quot;,&quot;brierSkew&quot; or &quot;costCurve&quot; (default).</p>
</td></tr>
<tr><td><code id="CSMES.ensNomCurve_+3A_method">method</code></td>
<td>
<p>how are candidate ensemble learner predictions used to generate the ensemble nomination front? &quot;classPreds&quot; for class predictions (default), &quot;probPreds&quot; for probability predictions.</p>
</td></tr>
<tr><td><code id="CSMES.ensNomCurve_+3A_plotting">plotting</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code>: Should a plot be generated showing the Brier curve? Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="CSMES.ensNomCurve_+3A_nrbootstraps">nrBootstraps</code></td>
<td>
<p>optionally, the ensemble nomination curve can be generated through bootstrapping. This argument specifies the number of iterations/bootstrap samples. Default is 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class <code>CSMES.ensNomCurve</code> which is a list with the following components:
</p>
<table>
<tr><td><code>nomcurve</code></td>
<td>
<p>the ensemble nomination curve</p>
</td></tr>
<tr><td><code>curves</code></td>
<td>
<p>individual cost curves or brier curves of ensemble members</p>
</td></tr>
<tr><td><code>intervals</code></td>
<td>
<p>resolution of the ensemble nomination curve</p>
</td></tr>
<tr><td><code>incidence</code></td>
<td>
<p>incidence (positive rate) of the outcome variable</p>
</td></tr>
<tr><td><code>area_under_curve</code></td>
<td>
<p>area under the ensemble nomination curve</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>method used to generate the ensemble nomination front:&quot;classPreds&quot; for class predictions (default), &quot;probPreds&quot; for probability predictions</p>
</td></tr>
<tr><td><code>curveType</code></td>
<td>
<p>the type of cost curve used to construct the ensemble nomination curve</p>
</td></tr>
<tr><td><code>nrBootstraps</code></td>
<td>
<p>number of boostrap samples over which the ensemble nomination curve was estimated</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Koen W. De Bock, <a href="mailto:kdebock@audencia.com">kdebock@audencia.com</a>
</p>


<h3>References</h3>

<p>De Bock, K.W., Lessmann, S. And Coussement, K., Cost-sensitive business failure prediction
when misclassification costs are uncertain: A heterogeneous ensemble selection approach,
European Journal of Operational Research (2020), doi: 10.1016/j.ejor.2020.01.052.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CSMES.ensSel">CSMES.ensSel</a></code>, <code><a href="#topic+CSMES.predictPareto">CSMES.predictPareto</a></code>, <code><a href="#topic+CSMES.predict">CSMES.predict</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##load data
library(rpart)
library(zoo)
library(ROCR)
library(mco)
data(BFP)
##generate random order vector
BFP_r&lt;-BFP[sample(nrow(BFP),nrow(BFP)),]
size&lt;-nrow(BFP_r)
##size&lt;-300
train&lt;-BFP_r[1:floor(size/3),]
val&lt;-BFP_r[ceiling(size/3):floor(2*size/3),]
test&lt;-BFP_r[ceiling(2*size/3):size,]
##generate a list containing model specifications for 100 CART decisions trees varying in the cp
##and minsplit parameters, and trained on bootstrap samples (bagging)
rpartSpecs&lt;-list()
for (i in 1:100){
  data&lt;-train[sample(1:ncol(train),size=ncol(train),replace=TRUE),]
  str&lt;-paste("rpartSpecs$rpart",i,"=rpart(as.formula(Class~.),data,method=\"class\",
  control=rpart.control(minsplit=",round(runif(1, min = 1, max = 20)),",cp=",runif(1,
  min = 0.05, max = 0.4),"))",sep="")
  eval(parse(text=str))
}
##generate predictions for these models
hillclimb&lt;-mat.or.vec(nrow(val),100)
for (i in 1:100){
  str&lt;-paste("hillclimb[,",i,"]=predict(rpartSpecs[[i]],newdata=val)[,2]",sep="")
  eval(parse(text=str))
}
##score the validation set used for ensemble selection, to be used for ensemble selection
ESmodel&lt;-CSMES.ensSel(hillclimb,val$Class,obj1="FNR",obj2="FPR",selType="selection",
generations=10,popsize=12,plot=TRUE)
## Create Ensemble nomination curve
enc&lt;-CSMES.ensNomCurve(ESmodel,hillclimb,val$Class,curveType="costCurve",method="classPreds",
plot=FALSE)
</code></pre>

<hr>
<h2 id='CSMES.ensSel'>CSMES Training Stage 1: Cost-Sensitive Multicriteria Ensemble Selection resulting in a Pareto frontier of candidate ensemble classifiers</h2><span id='topic+CSMES.ensSel'></span>

<h3>Description</h3>

<p>This function applies the first stage in the learning process of CSMES: optimizing Cost-Sensitive Multicriteria Ensemble
Selection, resulting in a Pareto frontier of equivalent candidate ensemble classifiers along two objective functions. By default, cost space is optimized
by optimizing false positive and false negative rates simultaneously. This results in a set of optimal ensemble classifiers, varying in the tradeoff between
FNR and FPR. Optionally, other objective metrics can be specified. Currently, only binary classification is supported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CSMES.ensSel(
  memberPreds,
  y,
  obj1 = c("FNR", "AUCC", "MSE", "AUC"),
  obj2 = c("FPR", "ensSize", "ensSizeSq", "clAmb"),
  selType = c("selection", "selectionWeighted", "weighted"),
  plotting = TRUE,
  generations = 30,
  popsize = 100
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CSMES.ensSel_+3A_memberpreds">memberPreds</code></td>
<td>
<p>matrix containing ensemble member library predictions</p>
</td></tr>
<tr><td><code id="CSMES.ensSel_+3A_y">y</code></td>
<td>
<p>Vector with true class labels. Currently, a dichotomous outcome variable is supported</p>
</td></tr>
<tr><td><code id="CSMES.ensSel_+3A_obj1">obj1</code></td>
<td>
<p>Specifies the first objective metric to be minimized</p>
</td></tr>
<tr><td><code id="CSMES.ensSel_+3A_obj2">obj2</code></td>
<td>
<p>Specifies the second objective metric to be minimized</p>
</td></tr>
<tr><td><code id="CSMES.ensSel_+3A_seltype">selType</code></td>
<td>
<p>Specifies the type of ensemble selection to be applied: <code>"selection"</code> for basic selection, <code>"selectionWeighted"</code> for weighted selection, <code>"weighted"</code> for weighted sum</p>
</td></tr>
<tr><td><code id="CSMES.ensSel_+3A_plotting">plotting</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code>: Should a plot be generated showing objective function values throughout the optimization process?</p>
</td></tr>
<tr><td><code id="CSMES.ensSel_+3A_generations">generations</code></td>
<td>
<p>the number of population generations for nsga-II. Default is 30.</p>
</td></tr>
<tr><td><code id="CSMES.ensSel_+3A_popsize">popsize</code></td>
<td>
<p>the population size for nsga-II. Default is 100.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class <code>CSMES.ensSel</code> which is a list with the following components:
</p>
<table>
<tr><td><code>weights</code></td>
<td>
<p>ensemble member weights for all pareto-optimal ensemble classifiers after multicriteria ensemble selection</p>
</td></tr>
<tr><td><code>obj_values</code></td>
<td>
<p>optimization objective values</p>
</td></tr>
<tr><td><code>pareto</code></td>
<td>
<p>overview of pareto-optimal ensemble classifiers</p>
</td></tr>
<tr><td><code>popsize</code></td>
<td>
<p>the population size for nsga-II</p>
</td></tr>
<tr><td><code>generarations</code></td>
<td>
<p>the number of population generations for nsga-II</p>
</td></tr>
<tr><td><code>obj1</code></td>
<td>
<p>Specifies the first objective metric that was minimized</p>
</td></tr>
<tr><td><code>obj2</code></td>
<td>
<p>Specifies the second objective metric that was minimized</p>
</td></tr>
<tr><td><code>selType</code></td>
<td>
<p>the type of ensemble selection that was applied: <code>"selection"</code>, <code>"selectionWeighted"</code> or <code>"weighted"</code></p>
</td></tr>
<tr><td><code>ParetoPredictions_p</code></td>
<td>
<p>probability predictions for pareto-optimal ensemble classifiers</p>
</td></tr>
<tr><td><code>ParetoPredictions_c</code></td>
<td>
<p>class predictions for pareto-optimal ensebmle classifiers</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Koen W. De Bock, <a href="mailto:kdebock@audencia.com">kdebock@audencia.com</a>
</p>


<h3>References</h3>

<p>De Bock, K.W., Lessmann, S. And Coussement, K., Cost-sensitive business failure prediction
when misclassification costs are uncertain: A heterogeneous ensemble selection approach,
European Journal of Operational Research (2020), doi: 10.1016/j.ejor.2020.01.052.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##load data
library(rpart)
library(zoo)
library(ROCR)
library(mco)
data(BFP)
##generate random order vector
BFP_r&lt;-BFP[sample(nrow(BFP),nrow(BFP)),]
size&lt;-nrow(BFP_r)
##size&lt;-300
train&lt;-BFP_r[1:floor(size/3),]
val&lt;-BFP_r[ceiling(size/3):floor(2*size/3),]
test&lt;-BFP_r[ceiling(2*size/3):size,]
##generate a list containing model specifications for 100 CART decisions trees varying in the cp
##and minsplit parameters, and trained on bootstrap samples (bagging)
rpartSpecs&lt;-list()
for (i in 1:100){
  data&lt;-train[sample(1:ncol(train),size=ncol(train),replace=TRUE),]
  str&lt;-paste("rpartSpecs$rpart",i,"=rpart(as.formula(Class~.),data,method=\"class\",
  control=rpart.control(minsplit=",round(runif(1, min = 1, max = 20)),",cp=",runif(1,
  min = 0.05, max = 0.4),"))",sep="")
  eval(parse(text=str))
}
##generate predictions for these models
hillclimb&lt;-mat.or.vec(nrow(val),100)
for (i in 1:100){
  str&lt;-paste("hillclimb[,",i,"]=predict(rpartSpecs[[i]],newdata=val)[,2]",sep="")
  eval(parse(text=str))
}
##score the validation set used for ensemble selection, to be used for ensemble selection
ESmodel&lt;-CSMES.ensSel(hillclimb,val$Class,obj1="FNR",obj2="FPR",selType="selection",
generations=10,popsize=12,plot=TRUE)
## Create Ensemble nomination curve
enc&lt;-CSMES.ensNomCurve(ESmodel,hillclimb,val$Class,curveType="costCurve",method="classPreds",
plot=FALSE)
</code></pre>

<hr>
<h2 id='CSMES.predict'>CSMES scoring: generate predictions for the optimal ensemble classifier according to CSMES in function of cost information.</h2><span id='topic+CSMES.predict'></span>

<h3>Description</h3>

<p>This function generates predictions for a new data set (containing candidate member library predictions) using a CSMES model. Using Pareto-optimal ensemble definitions
generated through <code>CSMES.ensSel</code> and the ensemble nomination front generated using <code>CSMES.EnsNomCurve</code>, final ensemble predictions are generated in function of
cost information known to the user at the time of model scoring. The model allows for three scenarios: (1) the candidate ensemble is nominated in function of a specific cost
ratio, (2) the ensemble is nominated in function of partial AUCC (or a distribution over operating points) and (3) the candidate ensemble that is
optimal over the entire cost space in function of area under the cost or brier curve is chosen.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CSMES.predict(
  ensSelModel,
  ensNomCurve,
  newdata,
  criterion = c("minEMC", "minAUCC", "minPartAUCC"),
  costRatio = 5,
  partAUCC_mu = 0.5,
  partAUCC_sd = 0.1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CSMES.predict_+3A_ensselmodel">ensSelModel</code></td>
<td>
<p>ensemble selection model (output of <code>CSMES.ensSel</code>)</p>
</td></tr>
<tr><td><code id="CSMES.predict_+3A_ensnomcurve">ensNomCurve</code></td>
<td>
<p>ensemble nomination curve object (output of <code>CSMES.ensNomCurve</code>)</p>
</td></tr>
<tr><td><code id="CSMES.predict_+3A_newdata">newdata</code></td>
<td>
<p>matrix containing ensemble library member model predictions for new data set</p>
</td></tr>
<tr><td><code id="CSMES.predict_+3A_criterion">criterion</code></td>
<td>
<p>This argument specifies which criterion determines the selection of the ensemble candidate that delivers predictions. Can be one of three options: &quot;minEMC&quot;, &quot;minAUCC&quot; or &quot;minPartAUCC&quot;.</p>
</td></tr>
<tr><td><code id="CSMES.predict_+3A_costratio">costRatio</code></td>
<td>
<p>Specifies the cost ratio used to determine expected misclassification cost. Only relvant when <code>criterion</code> is &quot;minEMC&quot;.</p>
</td></tr>
<tr><td><code id="CSMES.predict_+3A_partaucc_mu">partAUCC_mu</code></td>
<td>
<p>Desired mean operating condition when <code>criterion</code> is &quot;minPartAUCC&quot; (partial area under the cost/brier curve).</p>
</td></tr>
<tr><td><code id="CSMES.predict_+3A_partaucc_sd">partAUCC_sd</code></td>
<td>
<p>Desired standard deviation when <code>criterion</code> is &quot;minPartAUCC&quot; (partial area under the cost/brier curve).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An list with the following components:
</p>
<table>
<tr><td><code>pred</code></td>
<td>
<p>A matrix with model predictions. Both class and probability predictions are delivered.</p>
</td></tr>
<tr><td><code>criterion</code></td>
<td>
<p>The criterion specified to determine the selection of the ensemble candidate.</p>
</td></tr>
<tr><td><code>costRatio</code></td>
<td>
<p>The cost ratio in function of which the <code>criterion</code> &quot;minEMC&quot; has selected the optimal candidate ensemble that delivered predictions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Koen W. De Bock, <a href="mailto:kdebock@audencia.com">kdebock@audencia.com</a>
</p>


<h3>References</h3>

<p>De Bock, K.W., Lessmann, S. And Coussement, K., Cost-sensitive business failure prediction
when misclassification costs are uncertain: A heterogeneous ensemble selection approach,
European Journal of Operational Research (2020), doi: 10.1016/j.ejor.2020.01.052.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CSMES.ensSel">CSMES.ensSel</a></code>, <code><a href="#topic+CSMES.predictPareto">CSMES.predictPareto</a></code>, <code><a href="#topic+CSMES.ensNomCurve">CSMES.ensNomCurve</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##load data
library(rpart)
library(zoo)
library(ROCR)
library(mco)
data(BFP)
##generate random order vector
BFP_r&lt;-BFP[sample(nrow(BFP),nrow(BFP)),]
size&lt;-nrow(BFP_r)
##size&lt;-300
train&lt;-BFP_r[1:floor(size/3),]
val&lt;-BFP_r[ceiling(size/3):floor(2*size/3),]
test&lt;-BFP_r[ceiling(2*size/3):size,]
##generate a list containing model specifications for 100 CART decisions trees varying in the cp
##and minsplit parameters, and trained on bootstrap samples (bagging)
rpartSpecs&lt;-list()
for (i in 1:100){
  data&lt;-train[sample(1:ncol(train),size=ncol(train),replace=TRUE),]
  str&lt;-paste("rpartSpecs$rpart",i,"=rpart(as.formula(Class~.),data,method=\"class\",
  control=rpart.control(minsplit=",round(runif(1, min = 1, max = 20)),",cp=",runif(1,
  min = 0.05, max = 0.4),"))",sep="")
  eval(parse(text=str))
}
##generate predictions for these models
hillclimb&lt;-mat.or.vec(nrow(val),100)
for (i in 1:100){
  str&lt;-paste("hillclimb[,",i,"]=predict(rpartSpecs[[i]],newdata=val)[,2]",sep="")
  eval(parse(text=str))
}
##score the validation set used for ensemble selection, to be used for ensemble selection
ESmodel&lt;-CSMES.ensSel(hillclimb,val$Class,obj1="FNR",obj2="FPR",selType="selection",
generations=10,popsize=12,plot=TRUE)
## Create Ensemble nomination curve
enc&lt;-CSMES.ensNomCurve(ESmodel,hillclimb,val$Class,curveType="costCurve",method="classPreds",
plot=FALSE)
</code></pre>

<hr>
<h2 id='CSMES.predictPareto'>Generate predictions for all Pareto-optimal ensemble classifier candidates selected through CSMES</h2><span id='topic+CSMES.predictPareto'></span>

<h3>Description</h3>

<p>This function generates predictions for all pareto-optimal ensemble classifier candidates as identified through the first training stage of CSMES (<code>CSMES.ensSel</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CSMES.predictPareto(ensSelModel, newdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CSMES.predictPareto_+3A_ensselmodel">ensSelModel</code></td>
<td>
<p>ensemble selection model (output of <code>CSMES.ensSel</code>)</p>
</td></tr>
<tr><td><code id="CSMES.predictPareto_+3A_newdata">newdata</code></td>
<td>
<p>data.frame or matrix containing data to be scored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class <code>CSMES.predictPareto</code> which is a list with the following two components:
</p>
<table>
<tr><td><code>Pareto_predictions_c</code></td>
<td>
<p>A vector with class predictions.</p>
</td></tr>
<tr><td><code>Paret_predictions_p</code></td>
<td>
<p>A vector with probability predictions.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Koen W. De Bock, <a href="mailto:kdebock@audencia.com">kdebock@audencia.com</a>
</p>


<h3>References</h3>

<p>De Bock, K.W., Lessmann, S. And Coussement, K., Cost-sensitive business failure prediction
when misclassification costs are uncertain: A heterogeneous ensemble selection approach,
European Journal of Operational Research (2020), doi: 10.1016/j.ejor.2020.01.052.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CSMES.ensSel">CSMES.ensSel</a></code>, <code><a href="#topic+CSMES.predict">CSMES.predict</a></code>, <code><a href="#topic+CSMES.ensNomCurve">CSMES.ensNomCurve</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##load data
library(rpart)
library(zoo)
library(ROCR)
library(mco)
data(BFP)
##generate random order vector
BFP_r&lt;-BFP[sample(nrow(BFP),nrow(BFP)),]
size&lt;-nrow(BFP_r)
##size&lt;-300
train&lt;-BFP_r[1:floor(size/3),]
val&lt;-BFP_r[ceiling(size/3):floor(2*size/3),]
test&lt;-BFP_r[ceiling(2*size/3):size,]
##generate a list containing model specifications for 100 CART decisions trees varying in the cp
##and minsplit parameters, and trained on bootstrap samples (bagging)
rpartSpecs&lt;-list()
for (i in 1:100){
  data&lt;-train[sample(1:ncol(train),size=ncol(train),replace=TRUE),]
  str&lt;-paste("rpartSpecs$rpart",i,"=rpart(as.formula(Class~.),data,method=\"class\",
  control=rpart.control(minsplit=",round(runif(1, min = 1, max = 20)),",cp=",runif(1,
  min = 0.05, max = 0.4),"))",sep="")
  eval(parse(text=str))
}
##generate predictions for these models
hillclimb&lt;-mat.or.vec(nrow(val),100)
for (i in 1:100){
  str&lt;-paste("hillclimb[,",i,"]=predict(rpartSpecs[[i]],newdata=val)[,2]",sep="")
  eval(parse(text=str))
}
##score the validation set used for ensemble selection, to be used for ensemble selection
ESmodel&lt;-CSMES.ensSel(hillclimb,val$Class,obj1="FNR",obj2="FPR",selType="selection",
generations=10,popsize=12,plot=TRUE)
## Create Ensemble nomination curve
enc&lt;-CSMES.ensNomCurve(ESmodel,hillclimb,val$Class,curveType="costCurve",method="classPreds",
plot=FALSE)
</code></pre>

<hr>
<h2 id='plotBrierCurve'>Plots Brier Curve</h2><span id='topic+plotBrierCurve'></span>

<h3>Description</h3>

<p>This function plots the brier curve based on a set of predictions generated by a binary classifier. Brier curves allow an evaluation of classifier performance in cost space.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotBrierCurve(bc, curveType = c("brierCost", "brierSkew"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotBrierCurve_+3A_bc">bc</code></td>
<td>
<p>A <code>brierCurve</code> object created by the <code>brierCurve</code> function</p>
</td></tr>
<tr><td><code id="plotBrierCurve_+3A_curvetype">curveType</code></td>
<td>
<p>the type of Brier curve to be plotted. Shoul be &quot;brierCost&quot; or&quot;brierSkew&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Author(s)</h3>

<p>Koen W. De Bock, <a href="mailto:kdebock@audencia.com">kdebock@audencia.com</a>
</p>


<h3>References</h3>

<p>Hernandez-Orallo, J., Flach, P., &amp; Ferri, C. (2011). Brier Curves: a New Cost-Based Visualisation of Classifier Performance. Proceedings of the 28th International Conference on Machine Learning (ICML-11), 585â€“592.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+brierCurve">brierCurve</a></code>, <code><a href="#topic+CSMES.ensNomCurve">CSMES.ensNomCurve</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##load data
library(rpart)
data(BFP)
##generate random order vector
BFP_r&lt;-BFP[sample(nrow(BFP),nrow(BFP)),]
size&lt;-nrow(BFP_r)
##size&lt;-300
train&lt;-BFP_r[1:floor(size/3),]
val&lt;-BFP_r[ceiling(size/3):floor(2*size/3),]
test&lt;-BFP_r[ceiling(2*size/3):size,]
##train CART decision tree model
model=rpart(as.formula(Class~.),train,method="class")
##generate predictions for the tes set
preds&lt;-predict(model,newdata=test)[,2]
##calculate brier curve
bc&lt;-brierCurve(test[,"Class"],preds)
##plot briercurve
plotBrierCurve(bc,curveType="cost")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
