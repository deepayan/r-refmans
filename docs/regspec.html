<!DOCTYPE html><html><head><title>Help for package regspec</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {regspec}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#regspec-package'>
<p>Non-parametric multirate spectral density estimation via linear Bayes.</p></a></li>
<li><a href='#basis'>
<p>Basis maker.</p></a></li>
<li><a href='#Gaussbound'>
<p>Compute the Gauss bounds for a random variable.</p></a></li>
<li><a href='#hindcast'>
<p>Interpolate process values from a set of data, and an expectation and</p>
variance specification for the process's log spectrum.</a></li>
<li><a href='#logspec2cov'>
<p>Compute autocovariance values from the basis coefficients for the log spectrum.</p></a></li>
<li><a href='#regspec'>
<p>Non-parametric Multirate Spectral Density Estimation via Linear Bayes.</p></a></li>
<li><a href='#RSI data'>
<p>Retail Sales Index (RSI) data</p></a></li>
<li><a href='#Synthetic example data'>
<p>Synthetic Data for Testing Functions in the regspec Package.</p></a></li>
<li><a href='#Travel data'>
<p>Visits abroad by UK residents</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Non-Parametric Bayesian Spectrum Estimation for Multirate Data</td>
</tr>
<tr>
<td>Version:</td>
<td>2.7</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-09-20</td>
</tr>
<tr>
<td>Description:</td>
<td>Computes linear Bayesian spectral estimates from multirate	data for second-order stationary time series. Provides credible intervals and methods for plotting various spectral estimates. Please see the paper &lsquo;Should we sample a time series more frequently?&rsquo; (doi below) for a full description of and motivation for the methodology.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://doi.org/10.1111/rssa.12210">https://doi.org/10.1111/rssa.12210</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-09-20 11:56:04 UTC; ben</td>
</tr>
<tr>
<td>Author:</td>
<td>Ben Powell [aut, cre],
  Guy Nason [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ben Powell &lt;ben.powell@york.ac.uk&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-09-20 12:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='regspec-package'>
Non-parametric multirate spectral density estimation via linear Bayes.
</h2><span id='topic+regspec-package'></span>

<h3>Description</h3>

<p>Estimate a spectral density function of a stationary time
series. Produces a linear Bayes estimate with credible intervals.
Can incorporate time series data from multiple realizations with
different sampling rate. Can deal with time series data that has
been filtered with a known filter (e.g. quarterly totals from monthly
values).
</p>


<h3>Details</h3>

<p>Currently, the package's centrepiece is the function <code><a href="#topic+regspec">regspec</a></code>, which implements spectral density estimation from time series data at integer time points.
A novel element of the code is it's ability to assimilate subsampled and filtered data.
</p>
<p>The package's data files, which will be loaded automatically, include synthetic and real examples of time series data that feature in the <code>Examples</code> sections of the functions' help files.
</p>


<h3>Author(s)</h3>

<p>Ben Powell
</p>


<h3>References</h3>

<p>Nason, G.P., Powell, B., Elliott, D. and Smith, P. (2016) 
Should We Sample a Time Series More Frequently? Decision Support
via Multirate Spectrum Estimation.
Journal of the Royal Statistical Society, Series A., 179,
(to appear).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+regspec">regspec</a></code>
</p>

<hr>
<h2 id='basis'>
Basis maker.
</h2><span id='topic+basis'></span>

<h3>Description</h3>

<p>A function for making matrices of sinusoidal basis function values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>basis(x, nb)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="basis_+3A_x">x</code></td>
<td>

<p>The frequencies at which to evaluate the basis functions.
</p>
</td></tr>
<tr><td><code id="basis_+3A_nb">nb</code></td>
<td>

<p>The number of basis functions to include.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix whose rows correspond to input values and whose columns correspond
to particular basis functions.
</p>


<h3>Author(s)</h3>

<p>Ben Powell
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bas.mat&lt;-basis(seq(0,0.5,length=16),22)
</code></pre>

<hr>
<h2 id='Gaussbound'>
Compute the Gauss bounds for a random variable.
</h2><span id='topic+Gaussbound'></span>

<h3>Description</h3>

<p>This is a simple function that computes bounds for a credible interval
according to Gauss's inequality. If a random variable has a Lebesgue density
with a single mode (<code>mode</code>) and a finite expected squared
deviation (<code>tau</code>^2) from this mode,
then Gauss's inequality tells us that at least a
given proportion (<code>prob</code>) of the distribution's mass lies within a
finite symmetric interval centred on the mode.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Gaussbound(mode, tau, prob)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gaussbound_+3A_mode">mode</code></td>
<td>

<p>Numeric. The location of the density's mode.
</p>
</td></tr>
<tr><td><code id="Gaussbound_+3A_tau">tau</code></td>
<td>

<p>Numeric. The square root of the expected squared deviation from the mode.
</p>
</td></tr>
<tr><td><code id="Gaussbound_+3A_prob">prob</code></td>
<td>

<p>Numeric. A lower bound on the probability mass that is contained within the interval
</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>bounds</code></td>
<td>
<p>An ordered vector containing the lower and upper bounds of the interval.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ben Powell
</p>


<h3>References</h3>

<p>Pukelsheim, F. (1994) The Three Sigma Rule. <em>The American Statistician</em>
<b>48</b>, 88-91.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Gaussbound(1,1,0.9)
</code></pre>

<hr>
<h2 id='hindcast'>
Interpolate process values from a set of data, and an expectation and
variance specification for the process's log spectrum.
</h2><span id='topic+hindcast'></span>

<h3>Description</h3>

<p>This function computes an approximate expectation for a
(second-order stationary) process's autocovariance function from the first
two moments of its log-spectrum, as encoded in an expectation vector and
variance matrix for the coefficients of a basis representation.
It then uses this autocovariance to interpolate values of a process
and to calculate variances for them.
</p>
<p>The function is really here to facilitate the reproduction of an example
from Nason, Powell, Elliott and Smith (2016).
It may be studied as an example, but is not recommended for general use.
Instead, custom Kriging-type estimates ought to be produced by manipulating by
hand variance matrices populated with autocovariance function values,
which can be computed with the function <code>logspec2cov</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hindcast(Dhigh, hightimes, Dlow, lowtimes, predtimes, filter=c(1),
    ebeta, vbeta, SARIMA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hindcast_+3A_dhigh">Dhigh</code></td>
<td>
<p>Vector. The high frequency data.</p>
</td></tr>
<tr><td><code id="hindcast_+3A_hightimes">hightimes</code></td>
<td>
<p>Vector. Integer time points at which the high frequency observations are made.</p>
</td></tr>
<tr><td><code id="hindcast_+3A_dlow">Dlow</code></td>
<td>
<p>Vector. The low frequency data.</p>
</td></tr>
<tr><td><code id="hindcast_+3A_lowtimes">lowtimes</code></td>
<td>
<p>Vector. Integer time points at which the low frequency observations are made.</p>
</td></tr>
<tr><td><code id="hindcast_+3A_predtimes">predtimes</code></td>
<td>
<p>Vector. Integer time points at which hindcasts are required.</p>
</td></tr>
<tr><td><code id="hindcast_+3A_filter">filter</code></td>
<td>
<p>Vector. A known vector of filter coefficients arising from the
observation process prior to any subsampling.
The default is <code>NULL</code>, which corresponds to direct observation and
a filter vector of <code>(1,0,0,...)</code>.
If the data are produced by taking a linear combination of the current
and previous process values, for example, one would set this vector
to be <code>(w_{t},w_{t-1})</code>.</p>
</td></tr>
<tr><td><code id="hindcast_+3A_ebeta">ebeta</code></td>
<td>

<p>Vector. Expectations for basis coefficients of the log spectrum.
</p>
</td></tr>
<tr><td><code id="hindcast_+3A_vbeta">vbeta</code></td>
<td>

<p>Vector. The variance for the basis coefficients of the log spectrum.
</p>
</td></tr>
<tr><td><code id="hindcast_+3A_sarima">SARIMA</code></td>
<td>
<p>List. A list encoding the SARIMA model that acts as an intercept,
or base line, for the non-parametric estimate of the log-spectrum.
The default is white noise with variance one.
The log-spectrum basis coefficients parameterize a deviation away
from the SARIMA model's log-spectrum.
The contents of the SARIMA list are formatted in line with the
format used by the package <code>TSA</code>
(see the <code>Examples</code> section for examples).</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>hindcast</code></td>
<td>
<p>A vector of hindcast expectations</p>
</td></tr>
<tr><td><code>var.hindcast</code></td>
<td>
<p>A covariance matrix for the hindcast values.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ben Powell
</p>


<h3>References</h3>

<p>Nason, G.P., Powell, B., Elliott, D. and Smith, P. (2016) 
Should We Sample a Time Series More Frequently? Decision Support
via Multirate Spectrum Estimation.
Journal of the Royal Statistical Society, Series A., 179,
(to appear).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#
# See example in \code{\link{travel}} help file
#
</code></pre>

<hr>
<h2 id='logspec2cov'>
Compute autocovariance values from the basis coefficients for the log spectrum.
</h2><span id='topic+logspec2cov'></span>

<h3>Description</h3>

<p>This function performs a series of integrals of a spectral density
multiplied by sinusoids of increasing frequency in order.
The result is a vector of autocovariances for the process values at
increasing separation.
</p>
<p>The example below shows how this function is useful for informing
estimates of missing values in thinned time series data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logspec2cov(ebeta, vbeta, SARIMA=list(sigma2=1), lags, subdivisions=100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logspec2cov_+3A_ebeta">ebeta</code></td>
<td>

<p>Vector. Expectations for basis coefficients of the log spectrum.
</p>
</td></tr>
<tr><td><code id="logspec2cov_+3A_vbeta">vbeta</code></td>
<td>

<p>Vector. The variance for the basis coefficients of the log spectrum.
</p>
</td></tr>
<tr><td><code id="logspec2cov_+3A_sarima">SARIMA</code></td>
<td>
<p>List. A list encoding the SARIMA model that acts as
the intercept, or base line, for the non-parametric estimate of
the log-spectrum. The default is white noise with variance one.
The log-spectrum basis coefficients parameterize a deviation away from
the SARIMA model's log-spectrum.
The contents of the SARIMA list are formatted in line with the
format used by the package <code>TSA</code> (see the <code>Examples</code>
section for examples).</p>
</td></tr>
<tr><td><code id="logspec2cov_+3A_lags">lags</code></td>
<td>

<p>Integer. The number of lags to which to calculate the autocovariance.
</p>
</td></tr>
<tr><td><code id="logspec2cov_+3A_subdivisions">subdivisions</code></td>
<td>

<p>Integer. This number is passed to the numerical integrator that computes the autocovariances from the exponentiated log-spectrum. It is set to <code>100</code> by default to reduce CPU demand. For rough spectra is may be advisable to specify a larger value.
</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>autocovariances</code></td>
<td>
<p>A vector of approximate expectations for the process's
autocovariances for increasing lags, starting with zero lag
(the process variance).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ben Powell
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#
# Simulate a complete time series.

set.seed(42)
D &lt;- arima.sim(n=150, model=list(ar=c(-0.5,0.4,0.8), ma=0.2))

# Now define indices for a subsampled historical period,
# a fully sampled historical period, and the missing values.

inda &lt;- seq(1, 100, by=3)
indb &lt;- seq(101, 150, by=1)
indc &lt;- (1:150)[-c(inda, indb)]

#
# Adjust our estimate for the spectrum using the two historical periods.
#

adjustment1 &lt;- regspec(D=D[indb], deltat=1, smthpar=0.85,
	plot.spec=FALSE)

adjustment2 &lt;- regspec(D=D[inda], deltat=3, ebeta=adjustment1$ebeta,
	vbeta=adjustment1$vbeta, ylim=c(0,60))

lines(spec.true, col=1, lwd=3, lty=2)

#
# Calculate covariances corresponding to the estimate of the spectrum at
# the data locations.
#

k &lt;- logspec2cov(adjustment2$ebeta, adjustment2$vbeta, lag=150)

#
# Compute linear predictors and variances for the missing data conditional
# on the autocovariances.
#

K &lt;- matrix(0, 150, 150)
K &lt;- matrix(k[1+abs(row(K)-col(K))], 150, 150)
d &lt;- solve(K[c(inda, indb),c(inda, indb)],K[c(inda, indb), indc])
hindcast.exp &lt;- crossprod(d, c(D[inda], D[indb]))
hindcast.var &lt;- K[indc, indc]-crossprod(K[c(inda, indb), indc], d)

#
# Plot the observed historical data and the predictions for the missing data.
#

par(cex=0.7)
plot(NA, NA, xlim=c(0,150), ylim=range(D), xlab="time", ylab="x")

#
#(Observed process values are plotted with black circles.)
#

points(indb, D[indb], type="p", lty=2)
points(c(inda, indb), c(D[inda], D[indb]))

#
# (Hindcasts are plotted with blue circles.)
#
points(indc, hindcast.exp, col=rgb(0.2,0.5,0.7), lwd=2)
for(i in 1:length(indc))	{
	lines(rep(indc[i], 2),
	hindcast.exp[i]+1*c(-1, 1)*hindcast.var[i, i]^0.5,
	col=rgb(0.2,0.5,0.7))
	}

#
# Interpolate the plotted data and predictions.
#

x &lt;- c(inda, indb, indc)
y &lt;- c(D[inda], D[indb], hindcast.exp)
lines(sort(x), y[order(x)], lty=2, col=rgb(0.2,0.5,0.7,0.7))

#
# Reveal the true values.
#

# (The union of observed and unobserved data is plotted with red crosses.)
points(D,col=2,pch=4)
</code></pre>

<hr>
<h2 id='regspec'>
Non-parametric Multirate Spectral Density Estimation via Linear Bayes.
</h2><span id='topic+regspec'></span>

<h3>Description</h3>

<p>This function computes a linear Bayes estimate and approximate credible
interval for the spectral density function
of a realization from a (second-order stationary) time series.
The function also has the
ability to update an existing spectral estimate
using time series data at a (potentially)
different sampling rate, and this can be repeated multiple times. In this way,
the routine can be used to estimate the spectrum, and credible
intervals, from time series data
taken at multiple sampling rates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regspec(D, deltat=1, nb=100, varmult=2, smthpar=0.8, ebeta=NULL,
	vbeta=NULL, filter=NULL, freq.out=seq(0,0.5,length=200),
	plot.spec=TRUE, plot.log=FALSE, plot.pgram=FALSE,
	plot.intervals=TRUE, ylim=NULL, SARIMA=list(sigma2=1),
	centred=FALSE,intname=NULL,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regspec_+3A_d">D</code></td>
<td>
<p>Vector. A time series of observations. If no prior information
is specified (ie &quot;starting case&quot;) then length of series has to
be &gt;= 2</p>
</td></tr>
<tr><td><code id="regspec_+3A_deltat">deltat</code></td>
<td>
<p>Integer. The number of unit time intervals between observations in the data set <code>D</code>.</p>
</td></tr>
<tr><td><code id="regspec_+3A_nb">nb</code></td>
<td>
<p>Integer. The number of basis functions used to describe the spectral density.</p>
</td></tr>
<tr><td><code id="regspec_+3A_varmult">varmult</code></td>
<td>
<p>Scalar. A scaling factor for the variance of the basis coefficients for the log-spectrum.</p>
</td></tr>
<tr><td><code id="regspec_+3A_smthpar">smthpar</code></td>
<td>
<p>Scalar. A roughness parameter between 0 and 1, controlling the exponential decay of the basis coefficient variances. Smaller values correspond to greater preference for smoothness.</p>
</td></tr>
<tr><td><code id="regspec_+3A_ebeta">ebeta</code></td>
<td>
<p>Vector. Prior expectations for the basis coefficients of the log spectrum. Specifying prior moments for the coefficients overrides prior information encoded in <code>forvarest</code>.</p>
</td></tr>
<tr><td><code id="regspec_+3A_vbeta">vbeta</code></td>
<td>
<p>Matrix. Prior covariances for the basis coefficients of the log spectrum.</p>
</td></tr>
<tr><td><code id="regspec_+3A_filter">filter</code></td>
<td>
<p>Vector. A known vector of filter coefficients arising from
the observation process prior to any subsampling.
The default is <code>NULL</code>, which corresponds to direct observation
and a filter vector of <code>(1,0,0,...)</code>.
If the data are produced by taking a linear combination of the
current and previous process values with weights <code>w_t</code>,
for example, one would set this vector to be <code>(w_{t},w_{t-1})</code>.</p>
</td></tr>
<tr><td><code id="regspec_+3A_freq.out">freq.out</code></td>
<td>
<p>Vector. The frequencies at which to evaluate the estimated spectral density.</p>
</td></tr>
<tr><td><code id="regspec_+3A_plot.spec">plot.spec</code></td>
<td>
<p>Logical. If <code>TRUE</code> some kind of spectral plot is
produced. If <code>FALSE</code> then no plot is produced.</p>
</td></tr>
<tr><td><code id="regspec_+3A_plot.log">plot.log</code></td>
<td>
<p>Logical. Should the estimate of the log-spectrum be plotted? Plots the un-logged spectrum if <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="regspec_+3A_plot.pgram">plot.pgram</code></td>
<td>
<p>Logical. Should the periodogram values be plotted on top of the spectrum estimate?</p>
</td></tr>
<tr><td><code id="regspec_+3A_plot.intervals">plot.intervals</code></td>
<td>
<p>Logical. Should the pointwise credible intervals be plotted?</p>
</td></tr>
<tr><td><code id="regspec_+3A_ylim">ylim</code></td>
<td>
<p>The usual limits that specify the range of values on the y-axis</p>
</td></tr>
<tr><td><code id="regspec_+3A_sarima">SARIMA</code></td>
<td>
<p>List. A list encoding the SARIMA model that acts as the intercept, or base line, for the non-parametric estimate of the log-spectrum. The default is white noise with variance one. The log-spectrum basis coefficients parameterize a deviation away from the SARIMA model's log-spectrum. The contents of the SARIMA list are formatted in line with the format used by the package <code>TSA</code> (see the <code>Examples</code> section for examples).</p>
</td></tr>
<tr><td><code id="regspec_+3A_centred">centred</code></td>
<td>
<p>Logical. Has the data been centred? If the data
<code>D</code> has exactly zero mean, then the log-periodogram will
return infinite values. By setting this option to TRUE,
the infinite log-periodogram value is ignored.</p>
</td></tr>
<tr><td><code id="regspec_+3A_intname">intname</code></td>
<td>
<p>Character. A name for the units the time intervals are measured in. This is just used to label the axes.</p>
</td></tr>
<tr><td><code id="regspec_+3A_...">...</code></td>
<td>
<p>Other arguments for call to plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Full technical details of the calculations preformed by
<code>regspec</code> are documented in Nason, Powell, Elliott and Smith (2016)
listed in the references.
</p>
<p>This function can be used to produce an estimate of the spectrum
of a stationary time series realization using linear Bayes
methods. The simplest call just requires the user to specify
<code>D</code> the vector of time series observations.
</p>
<p>More specialised uses of this function are as follows.
1. One can additionally specify the value of the argument
<code>deltat</code> to be the sampling interval of the time series.
E.g. <code>deltat=2</code> means that the time series observations
were sampled every two units of time. With this argument specified
the spectrum is calculated/(depicted if plotted) <em>still</em>
on the frequency scale zero to one half, which is the scale
normally associated with unit interval sampling. However, what changes
is that the spectral estimate is neutrally extended from the
<em>subsampled</em> frequency range to the unit interval range.
For example, if <code>deltat=2</code> then the usual frequency range
assocated with data at this sampling interval would be zero to
one quarter. However, the premise of <code>regspec</code> is that
ultimately the series you obtained came from a unit sampled
series and so the <em>real spectrum</em> you would like to estimate
is one zero to one half. Since we have no information on the higher
frequencies zero to one quarter the code essentially unfolds the
spectrum equally about the line of symmetry at one quarter.
</p>
<p>If <code>deltat=3</code> or other higher values, similar unfoldings occur.
For example, if <code>deltat=4</code> then two unfoldings about
one quarter and then one-eighth and three-eighths are affected.
</p>
<p>Then, subsequent calls to <code>regspec</code> at different sampling
rates can alter the spectrum depending on the information they contain.
</p>
<p>Another key parameter is the <code>smthpar</code> which is set at
0.8 by default which usually gives a nice balance between fidelity
and smoothness. Increasing this parameter results in a less smooth
estimate.
</p>
<p>By default aliasing is assumed to be induced by subsampling.
For example, when <code>deltat=2</code> then it is assumed that the
series you have contains the evenly-indexed observations of some
putative underlying integer sampled series. However, aliasing can
arise in other ways, such as when your unit sampled underlying series
has been filtered. For example, if one observes quarterly totals,
where each total is the result of summing over consecutive three
month periods then the filter is <code>c(1,1,1)</code>.
</p>
<p>A plot of the estimated spectrum is produced automatically unless the argument <code>plot.spec</code> is set to <code>FALSE</code>.
</p>


<h3>Value</h3>

<p>The function's output is a list with the following elements:
</p>
<table>
<tr><td><code>freq.out</code></td>
<td>
<p>Vector. The frequencies at which the estimated spectral density is computed.</p>
</td></tr>
<tr><td><code>spec</code></td>
<td>
<p>Vector. Point estimates of the spectrum values. Each of these is computed by exponentiating the sum of the expectation for the log spectrum and half its variance. This is the expectation consistent with the log-spectrum being normally distributed.</p>
</td></tr>
<tr><td><code>logspec</code></td>
<td>
<p>Vector. Point estimates for the log-spectrum values. These are the adjusted expectations of the log-spectrum.</p>
</td></tr>
<tr><td><code>interval</code></td>
<td>
<p>Matrix. Bounds for the 90 percent credible interval for the the spectral density.</p>
</td></tr>
<tr><td><code>ebeta</code></td>
<td>
<p>Vector. The adjusted expectation for the basis coefficients of the logged spectral density. They contain information on the current estimate
of the spectrum and can be supplied to a further call of <code>regspec</code>
for adjustment by new data.</p>
</td></tr>
<tr><td><code>vbeta</code></td>
<td>
<p>Matrix. The adjusted variance matrix for the basis coefficients of the logged spectral density. Like <code>ebeta</code> this matrix can be resupplied
to a further call to <code>regspec</code> for adjustment.</p>
</td></tr>
<tr><td><code>pgram</code></td>
<td>
<p>List. The periodogram ordinates used in the adjustment.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ben Powell code. Ben Powell and Guy Nason on help.
</p>


<h3>References</h3>

<p>Nason, G.P., Powell, B., Elliott, D. and Smith, P. (2016)
Should We Sample a Time Series More Frequently? Decision Support
via Multirate Spectrum Estimation.
Journal of the Royal Statistical Society, Series A., 179,
(to appear).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The examples here use datasets Dfexample, Dpexample2, Dpexample3 and
## spec.true, which should be loaded automatically with the package.


# FIRST EXAMPLE
# Estimates a spectrum from a time series observed at integer time points.
#
# Plot a 'point' estimate and intervals around it.
# Also plot the true spectrum afterwards with a dashed line
#
adjustment &lt;- regspec(D=Dfexample[1:24], deltat=1, smthpar=0.8,
		ylim=c(0,60), plot.pgram=TRUE)

lines(spec.true, col=1, lwd=3, lty=2)

#
#
# SECOND EXAMPLE
# Does he same except the observations are sampled at every two time units.
#
# Plot a 'point' estimate and intervals around it.

adjustment &lt;- regspec(D=Dpexample2, deltat=2, smthpar=0.8, ylim=c(0,60))

lines(spec.true, col=1, lwd=3, lty=2)

#
# THIRD EXAMPLE
# Now estimate a spectrum from unit sampled data and put answer in the
# object called adjustment1. Then use the estimated quantities in this
# object (notably the ebeta and vbeta components) to update the spectral
# estimate by a second call to regspec using new, data sampled at even time
# points and put the result into the adjustment2 object
#

adjustment1 &lt;- regspec(D=Dfexample[1:24], deltat=1, smthpar=0.8,
	ylim=c(0,60))

lines(spec.true, col=1, lwd=3, lty=2)

adjustment2 &lt;- regspec(D=Dpexample2, deltat=2, ebeta=adjustment1$ebeta,
	vbeta=adjustment1$vbeta, ylim=c(0,60))

lines(spec.true, col=1, lwd=3, lty=2)


# FOURTH EXAMPLE
# Estimate spectrum from series observed at each third integer.
# Plot a 'point' estimate and intervals around it.

adjustment &lt;- regspec(D=Dpexample3, deltat=3, smthpar=0.8, ylim=c(0,60))

lines(spec.true, col=1, lwd=3, lty=2)

# FIFTH EXAMPLE
# Estimate a spectrum from one time series of observations at every
# time point and then update with another at every third time point.
#
# Note how information from the first spectral estimate gets passed to
# the second call of regspec via the ebeta and vbeta components/arguments.
#

adjustment1 &lt;- regspec(D=Dfexample[1:24], deltat=1, smthpar=0.8, ylim=c(0,60))

lines(spec.true, col=1, lwd=3, lty=2)

adjustment2 &lt;- regspec(D=Dpexample3, deltat=3, ebeta=adjustment1$ebeta,
	vbeta=adjustment1$vbeta, ylim=c(0,60))

lines(spec.true, col=1, lwd=3, lty=2)

# SIXTH EXAMPLE
#
# Estimating a spectrum from a time series of filtered observations.

# Filter the example data.

# Create empty vector
Dfexample.filtered &lt;- c()

# Create filter
filter.vect &lt;- 4*runif(5)

# Now produce filtered data
m &lt;- length(filter.vect)-1

for(i in 1:(length(Dfexample)-m)){
	Dfexample.filtered[i] &lt;- crossprod(Dfexample[i+m-0:m],filter.vect)
	}

# Now use filterered data to try and estimate spectrum of original data

adjustment1 &lt;- regspec(D=Dfexample.filtered, smthpar=0.8, filter=filter.vect,
	ylim=c(0,80), plot.pgram=TRUE)

lines(spec.true, col=1, lwd=3, lty=2)

# Note here how the periodogram values do not correspond to the estimated
# spectrum because the periodogram of the  filtered data is computed and
# plotted, but then is used to estimate the spectrum of the un-filtered
# process.


# SEVENTH EXAMPLE
# Estimate spectrum according to its deviation from a known SARIMA model.

# Define a SARIMA model like this one

SARIMA0 &lt;- list(ar=0.3,sigma2=1,seasonal=list(sar=0.5,sma=0,period=12))

# or like this one

SARIMA0 &lt;- list(ar=c(-0.5, 0.4, 0.8), ma=0.2, sigma2=1)

# Then perform adjustments as before

adjustment &lt;- regspec(D=Dfexample[1:16], deltat=1, smthpar=0.8, ylim=c(0,60),
	SARIMA=SARIMA0, plot.pgram=TRUE)

adjustment &lt;- regspec(D=Dpexample2, deltat=2, smthpar=0.8, ylim=c(0,60),
	SARIMA=SARIMA0, plot.pgram=TRUE)

lines(spec.true, col=1, lwd=3, lty=2)

# This is useful for introducing prior beliefs for the structural form of the
# spectrum. Specifically, it is useful for specifying a prior belief in
# seasonality.
</code></pre>

<hr>
<h2 id='RSI+20data'>
Retail Sales Index (RSI) data
</h2><span id='topic+retail'></span>

<h3>Description</h3>

<p>This data frame is taken from the online data resource of the
U.K.'s Office for National Statistics. It contains time-indexed values
of a retail sales index, a figure describing the turnover of retail
businesses as a percentage of a 2010 baseline.
</p>


<h3>Details</h3>

<p>The original data files are no longer hosted on the main ONS webpages but, for the foreseeable future, ought to be accessible via the UK's National Archives <a href="https://webarchive.nationalarchives.gov.uk/ukgwa/20160105160709/http://www.ons.gov.uk/ons/index.html">https://webarchive.nationalarchives.gov.uk/ukgwa/20160105160709/http://www.ons.gov.uk/ons/index.html</a>.
</p>


<h3>References</h3>

<p>Nason, G.P., Powell, B., Elliott, D. and Smith, P. (2016)
Should We Sample a Time Series More Frequently? Decision Support
via Multirate Spectrum Estimation.
Journal of the Royal Statistical Society, Series A., 179,
(to appear).
</p>

<hr>
<h2 id='Synthetic+20example+20data'>
Synthetic Data for Testing Functions in the regspec Package.
</h2><span id='topic+Dfexample'></span><span id='topic+Dpexample2'></span><span id='topic+Dpexample3'></span><span id='topic+spec.true'></span>

<h3>Description</h3>

<p><code>spec.true</code> is a matrix of coordinates for the spectral density of the
ARMA(3,1) model with AR and MA coefficients (-0.5, 0.4, 0.8) and (0.2)
respectively. This was the model used to simulate the example data sets
<code>Dfexample</code>, <code>Dpexample2</code> and <code>Dpexample3</code>,
which consist of observations of the process at every time point,
at every second time point and every third time point, respectively.
</p>


<h3>Details</h3>

<p>See the package <code>TSA</code> for functions to calculate values of the spectral density for different ARMA models, and the function <code>arima.sim</code> for simulating time series from them.
</p>


<h3>References</h3>

<p>Nason, G.P., Powell, B., Elliott, D. and Smith, P. (2016) 
Should We Sample a Time Series More Frequently? Decision Support
via Multirate Spectrum Estimation.
Journal of the Royal Statistical Society, Series A., 179,
(to appear).
</p>

<hr>
<h2 id='Travel+20data'>
Visits abroad by UK residents
</h2><span id='topic+travel'></span><span id='topic+trav.qly'></span><span id='topic+trav.mly'></span>

<h3>Description</h3>

<p>The Travel data in this package comprises of two data frames
<code>trav.qly</code> and <code>trav.mly</code>.
These contain quarterly figures from 2004 to 2010
and monthly figures from 2011 to 2013.
They both show the number of UK residents making visits abroad.
</p>


<h3>Details</h3>

<p>The data have been collected by the U.K.'s Office of National Statisitics (ONS) and are contained in the reference tables: <em>Overseas Travel And Tourism, Q3 2013</em> and <em>Monthly Overseas Travel and Tourism, April 2014</em>. The original data files are no longer hosted on the main ONS webpages but, for the foreseeable future, ought to be accessible via the UK's National Archives <a href="https://webarchive.nationalarchives.gov.uk/ukgwa/20160105160709/http://www.ons.gov.uk/ons/index.html">https://webarchive.nationalarchives.gov.uk/ukgwa/20160105160709/http://www.ons.gov.uk/ons/index.html</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#
# This example estimates monthly values for UK residents leaving the
# country given historical quarterly values and some more recent
# monthly values. The hindcast function is just a wrapper for code that
# computes an approximate autocovariance function for the process and
# performs some matrix calculations to produce Kriging-type estimators.
#
qt &lt;- 1:nrow(trav.qly)*3
mt &lt;- 84+1:nrow(trav.mly)

#
# Approximately centre data
#

Nhigh &lt;- 14
trav.mly2 &lt;- trav.mly[1:Nhigh,3]-5200
mt &lt;- mt[1:Nhigh]
trav.qly2 &lt;- trav.qly[,3]-3*5200
#
# Construct a likely prior model
#
SARIMA0 &lt;- list(ar=0.6, seasonal=list(period=12,sar=0.6), sigma2=60^2)

#
# Learn about the log-spectrum with regspec
#
adj1 &lt;- regspec(D=trav.mly2, deltat=1, plot.log=TRUE, plot.pgram=TRUE,
	varmult=1, smthpar=0.8, SARIMA=SARIMA0, ylim=c(6,20),
	intname=" (months)")

adj2 &lt;- regspec(D=trav.qly2, deltat=3, filter=c(1,1,1), ebeta=adj1$ebeta,
	vbeta=adj1$vbeta, plot.log=TRUE, ylim=c(6,20), SARIMA=SARIMA0,
	plot.pgram=FALSE, intname=" (months)")

#
# Compute a hindcast
#
predtimes &lt;- 1:84

test &lt;- hindcast(Dhigh=trav.mly2, hightimes=mt, Dlow=trav.qly2,
	lowtimes=qt, predtimes=predtimes, filter=c(1,1,1), ebeta=adj2$ebeta,
	vbeta=adj2$vbeta,SARIMA=SARIMA0)

test$hindcast &lt;- test$hindcast+5200

#
# Plot hindcast
#

plot(qt, trav.qly[,3], xlim=range(0,qt,mt), type="o",
	ylim=range(0,trav.mly,trav.qly), xlab="", xaxt="n", ylab="Trips")

axyrs &lt;- 2004:2012
axlabs &lt;- axyrs

for(i in 1:length(axlabs)) {
	axlabs[i]&lt;-paste(axyrs[i])
	}

axis(1, line=0, at=(1:41-1)*3, labels=FALSE)

text((1:length(axlabs)-1)*12, -1800, srt = 45, adj = 1,
	labels = axlabs, xpd = TRUE)

points(mt, trav.mly2+5200, type="o", cex=0.6)

abline(v=84, lty=2)

points(predtimes, test$hindcast, col=rgb(0.2,0.5,0.7),
	type="o", cex=0.6)

for(i in 1:length(predtimes)){
	lines(rep(predtimes[i], 2),
	test$hindcast[i]+3*c(-1,1)*test$var.hindcast[i,i]^0.5,
	col=rgb(0.2,0.5,0.7))
	}
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
