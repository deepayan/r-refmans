<!DOCTYPE html><html lang="en"><head><title>Help for package bayesestdft</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {bayesestdft}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#BayesGA'><p>Estimating the Student's t degrees of freedom (dof) with a Gamma Prior over the dof</p></a></li>
<li><a href='#BayesJeffreys'><p>Estimating the Student's t degrees of freedom (dof) with a Jeffreys Prior over the dof</p></a></li>
<li><a href='#BayesLNP'><p>Estimating the Student's t degrees of freedom (dof) with a Log-normal Prior over the dof</p></a></li>
<li><a href='#index_return'><p>Stock Market Index Return Data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Estimating the Degrees of Freedom of the Student's
t-Distribution under a Bayesian Framework</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Description:</td>
<td>A Bayesian framework to estimate the Student's t-distribution's degrees of freedom is developed. Markov Chain Monte Carlo sampling routines are developed as in &lt;<a href="https://doi.org/10.3390%2Faxioms11090462">doi:10.3390/axioms11090462</a>&gt; to sample from the posterior distribution of the degrees of freedom. A random walk Metropolis algorithm is used for sampling when Jeffrey's and Gamma priors are endowed upon the degrees of freedom. In addition, the Metropolis-adjusted Langevin algorithm for sampling is used under the Jeffrey's prior specification. The Log-normal prior over the degrees of freedom is posed as a viable choice with comparable performance in simulations and real-data application, against other prior choices, where an Elliptical Slice Sampler is used to sample from the concerned posterior.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/Roy-SR-007/bayesestdft">https://github.com/Roy-SR-007/bayesestdft</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/Roy-SR-007/bayesestdft/issues">https://github.com/Roy-SR-007/bayesestdft/issues</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>numDeriv, dplyr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.4)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-09 05:01:34 UTC; somjit</td>
</tr>
<tr>
<td>Author:</td>
<td>Somjit Roy [aut, cre],
  Se Yoon Lee [aut, ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Somjit Roy &lt;sroy_123@tamu.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-09 18:10:01 UTC</td>
</tr>
</table>
<hr>
<h2 id='BayesGA'>Estimating the Student's t degrees of freedom (dof) with a Gamma Prior over the dof</h2><span id='topic+BayesGA'></span>

<h3>Description</h3>

<p><code>BayesGA</code> samples from the posterior distribution of the degrees of freedom (dof) with Gamma prior endowed upon the dof, using a random walk Metropolis (RMW) algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BayesGA(y, ini.nu = 1, S = 1000, delta = 0.001, a = 1, b = 0.1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BayesGA_+3A_y">y</code></td>
<td>
<p>an N-dimensional vector of continuous observations supported on the real-line</p>
</td></tr>
<tr><td><code id="BayesGA_+3A_ini.nu">ini.nu</code></td>
<td>
<p>the initial posterior sample value of the degrees of freedom (default is 1)</p>
</td></tr>
<tr><td><code id="BayesGA_+3A_s">S</code></td>
<td>
<p>the number of posterior samples (default is 1000)</p>
</td></tr>
<tr><td><code id="BayesGA_+3A_delta">delta</code></td>
<td>
<p>the step size for the respective sampling engines (default is 0.001)</p>
</td></tr>
<tr><td><code id="BayesGA_+3A_a">a</code></td>
<td>
<p>rate parameter of Gamma prior (default is 1, corresponds to an Exponential prior)</p>
</td></tr>
<tr><td><code id="BayesGA_+3A_b">b</code></td>
<td>
<p>rate parameter of Gamma prior (default is 0.1)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of posterior sample estimates
</p>
<table role = "presentation">
<tr><td><code>res</code></td>
<td>
<p>an S-dimensional vector with the posterior samples</p>
</td></tr>
</table>


<h3>References</h3>

<p>Lee, S. Y. (2022). &quot;The Use of a Log-Normal Prior for the Student t-Distribution&quot;,
<em>Axioms</em>, <a href="https://doi.org/10.3390/axioms11090462">doi:10.3390/axioms11090462</a>
</p>
<p>Fernández, C., Steel, M. F. (1998). &quot;On Bayesian modeling of fat tails and skewness&quot;,
<em>Journal of the American Statistical Association</em>, <a href="https://doi.org/10.1080/01621459.1998.10474117">doi:10.1080/01621459.1998.10474117</a>
</p>
<p>Juárez, M. A., Steel, M. F. (2010). &quot;Model-Based Clustering of Non-Gaussian Panel Data Based on Skew-t Distributions&quot;,
<em>Journal of Business and Economic Statistics</em>, <a href="https://doi.org/10.1198/jbes.2009.07145">doi:10.1198/jbes.2009.07145</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# data from Student's t-distribution with dof = 0.1
y = rt(n = 100, df = 0.1)

# running the random walk Metropolis algorithm with default settings
nu = BayesGA(y)
# reporting the posterior mean estimate of the dof
mean(nu)

# application to log-return (daily index values) of United States (S&amp;P500)
data(index_return)
# log-returns of United States
index_return_US &lt;- dplyr::filter(index_return, Country == "United States")
y = index_return_US$log_return_rate

# running the random walk Metropolis algorithm with default settings
nu = BayesGA(y)
# reporting the posterior mean estimate of the dof from the log-return data of US
mean(nu)

</code></pre>

<hr>
<h2 id='BayesJeffreys'>Estimating the Student's t degrees of freedom (dof) with a Jeffreys Prior over the dof</h2><span id='topic+BayesJeffreys'></span>

<h3>Description</h3>

<p><code>BayesJeffreys</code> samples from the posterior distribution of the degrees of freedom (dof) with Jeffreys prior endowed upon the dof, using a random walk Metropolis (RMW) algorithm and Metropolis-adjusted Langevin algorithm (MALA).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BayesJeffreys(
  y,
  ini.nu = 1,
  S = 1000,
  delta = 0.001,
  sampling.alg = c("MH", "MALA")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BayesJeffreys_+3A_y">y</code></td>
<td>
<p>an N-dimensional vector of continuous observations supported on the real-line</p>
</td></tr>
<tr><td><code id="BayesJeffreys_+3A_ini.nu">ini.nu</code></td>
<td>
<p>the initial posterior sample value of the degrees of freedom (default is 1)</p>
</td></tr>
<tr><td><code id="BayesJeffreys_+3A_s">S</code></td>
<td>
<p>the number of posterior samples (default is 1000)</p>
</td></tr>
<tr><td><code id="BayesJeffreys_+3A_delta">delta</code></td>
<td>
<p>the step size for the respective sampling engines (default is 0.001)</p>
</td></tr>
<tr><td><code id="BayesJeffreys_+3A_sampling.alg">sampling.alg</code></td>
<td>
<p>takes the choice of the sampling algorithm to be performed, either 'MH' or 'MALA'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of posterior sample estimates
</p>
<table role = "presentation">
<tr><td><code>res</code></td>
<td>
<p>an S-dimensional vector with the posterior samples</p>
</td></tr>
</table>


<h3>References</h3>

<p>Lee, S. Y. (2022). &quot;The Use of a Log-Normal Prior for the Student t-Distribution&quot;,
<em>Axioms</em>, <a href="https://doi.org/10.3390/axioms11090462">doi:10.3390/axioms11090462</a>
</p>
<p>Gustafson, P. (1998). &quot;A guided walk Metropolis algorithm&quot;,
<em>Statistics and Computing</em>, <a href="https://doi.org/10.1023/A%3A1008880707168">doi:10.1023/A:1008880707168</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# data from Student's t-distribution with dof = 0.1
y = rt(n = 100, df = 0.1)

# running the random walk Metropolis algorithm with default settings
nu1 = BayesJeffreys(y, sampling.alg = "MH")
# reporting the posterior mean estimate of the dof
mean(nu1)

# running MALA with default settings
nu2 = BayesJeffreys(y, sampling.alg = "MALA")
# reporting the posterior mean estimate of the dof
mean(nu2)

# application to log-return (daily index values) of United States (S&amp;P500)
data(index_return)
# log-returns of United States
index_return_US &lt;- dplyr::filter(index_return, Country == "United States")
y = index_return_US$log_return_rate

# running the random walk Metropolis algorithm with default settings
nu1 = BayesJeffreys(y, sampling.alg = "MH")
# reporting the posterior mean estimate of the dof from the log-return data of US
mean(nu1)

# running MALA with default settings
nu2 = BayesJeffreys(y, sampling.alg = "MALA")
# reporting the posterior mean estimate of the dof from the log-return data of US
mean(nu2)

</code></pre>

<hr>
<h2 id='BayesLNP'>Estimating the Student's t degrees of freedom (dof) with a Log-normal Prior over the dof</h2><span id='topic+BayesLNP'></span>

<h3>Description</h3>

<p><code>BayesLNP</code> samples from the posterior distribution of the degrees of freedom (dof) with Log-normal prior endowed upon the dof, using an Elliptical Slice Sampler (ESS).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BayesLNP(y, ini.nu = 1, S = 1000, mu = 1, sigma.sq = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BayesLNP_+3A_y">y</code></td>
<td>
<p>an N-dimensional vector of continuous observations supported on the real-line</p>
</td></tr>
<tr><td><code id="BayesLNP_+3A_ini.nu">ini.nu</code></td>
<td>
<p>the initial posterior sample value of the degrees of freedom (default is 1)</p>
</td></tr>
<tr><td><code id="BayesLNP_+3A_s">S</code></td>
<td>
<p>the number of posterior samples (default is 1000)</p>
</td></tr>
<tr><td><code id="BayesLNP_+3A_mu">mu</code></td>
<td>
<p>mean of the Log-normal prior density (default is 1)</p>
</td></tr>
<tr><td><code id="BayesLNP_+3A_sigma.sq">sigma.sq</code></td>
<td>
<p>variance of the Log-normal prior density (default is 1)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of posterior sample estimates
</p>
<table role = "presentation">
<tr><td><code>res</code></td>
<td>
<p>an S-dimensional vector with the posterior samples</p>
</td></tr>
</table>


<h3>References</h3>

<p>Lee, S. Y. (2022). &quot;The Use of a Log-Normal Prior for the Student t-Distribution&quot;,
<em>Axioms</em>, <a href="https://doi.org/10.3390/axioms11090462">doi:10.3390/axioms11090462</a>
</p>
<p>Murray, I., Prescott Adams, R., MacKay, D. J. (2010). &quot;Elliptical slice sampling&quot;,
<em>Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# data from Student's t-distribution with dof = 0.1
y = rt(n = 100, df = 0.1)

# running the Elliptical Slice Sampler (ESS) with default settings
nu = BayesLNP(y)
# reporting the posterior mean estimate of the dof
mean(nu)

# application to log-return (daily index values) of United States (S&amp;P500)
data(index_return)
# log-returns of United States
index_return_US &lt;- dplyr::filter(index_return, Country == "United States")
y = index_return_US$log_return_rate

# running the Elliptical Slice Sampler (ESS) with default settings
nu = BayesLNP(y)
# reporting the posterior mean estimate of the dof from the log-return data of US
mean(nu)

</code></pre>

<hr>
<h2 id='index_return'>Stock Market Index Return Data</h2><span id='topic+index_return'></span>

<h3>Description</h3>

<p>The stock market returns are recorded for four countries viz., United States (S&amp;P500), Japan (NIKKEI225), Germany (DAX Index), and South Korea (KOSPI). Specifically log return rates (as computed in Section 5 of <a href="https://doi.org/10.3390/axioms11090462">doi:10.3390/axioms11090462</a>) are recorded for 5 months in the year 2009 for all the four countries, where these rates are considered to be Student's t-distributed and used for the purpose of estimating the corresponding degrees of freedom using a Bayesian model-based framework, developed in <a href="https://doi.org/10.3390/axioms11090462">doi:10.3390/axioms11090462</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>index_return
</code></pre>


<h3>Format</h3>

<p>A data frame with 4 columns:
</p>

<dl>
<dt>Country</dt><dd><p>name of the country to which the log return rate corresponds to: 'United States', 'Japan', 'Germany', and 'South Korea'</p>
</dd>
<dt>log_return_rate</dt><dd><p>value of the log return rate</p>
</dd>
<dt>time_index</dt><dd><p>an index for the log return rate observations</p>
</dd>
<dt>date</dt><dd><p>the date on which the log return rate was recorded</p>
</dd>
</dl>



<h3>Source</h3>

<p>(Lee, 2022),
<a href="https://doi.org/10.3390/axioms11090462">doi:10.3390/axioms11090462</a>.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
