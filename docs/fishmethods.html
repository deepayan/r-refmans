<!DOCTYPE html><html lang="en"><head><title>Help for package fishmethods</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {fishmethods}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#agesurv'><p>Age-based Survival Estimators</p></a></li>
<li><a href='#agesurvcl'><p>Age-Based Survival and Mortality Estimators for Cluster Sampling</p></a></li>
<li><a href='#alk'><p>Create An Age-Length Key</p></a></li>
<li><a href='#alkD'><p>Sample Size Determination for Age Subsampling Using the D statistic</p></a></li>
<li><a href='#alkdata'><p>Age-Length Key for Gulf of Hauraki snapper, 1992-1993</p></a></li>
<li><a href='#alkprop'><p>Age-Length Key Proportions-At-Age</p></a></li>
<li><a href='#alkss'><p>Sample Size Determination for Age Subsampling</p></a></li>
<li><a href='#astrocalc4r'><p>Solar zenith angles for biological research</p></a></li>
<li><a href='#AtkaMack'><p>Length and Age Data For Male and Female Atka Mackerel</p></a></li>
<li><a href='#bheq'><p>Length-based Beverton-Holt Equilibrium Total Instantaneous Mortality Estimator</p></a></li>
<li><a href='#bhnoneq'><p>Length-based Beverton-Holt Nonequilibrium Z Estimator</p></a></li>
<li><a href='#bonito'><p>Data from an age and growth study of the pacific bonito.</p></a></li>
<li><a href='#bt.log'>
<p>Back-transformation of log-transformed mean and variance</p></a></li>
<li><a href='#buffalo'><p>Life Table Data for African Buffalo</p></a></li>
<li><a href='#catch'><p>Number of cod captured in 10 standardized bottom trawl hauls from Massachusetts, 1985</p></a></li>
<li><a href='#catch.select'><p>Selectivity Ogive from a Catch Curve</p></a></li>
<li><a href='#catchmsy'><p>Estimating MSY from catch and resilience</p></a></li>
<li><a href='#catchsurvey'><p>Catch-Survey Analysis</p></a></li>
<li><a href='#clus.lf'><p>Statistical Comparison of Length Frequencies from Simple Random Cluster Sampling</p></a></li>
<li><a href='#clus.mean'><p>Estimation of Population Attributes and Effective Sample Size</p>
for Fishes Collected Via Cluster Sampling</a></li>
<li><a href='#clus.rho'><p>Intracluster Correlation Coefficients for Clustered Data</p></a></li>
<li><a href='#clus.rho.g'><p>Calculate A Common Intracluster Correlation Coefficient Among Groups</p></a></li>
<li><a href='#clus.str.lf'><p>Statistical Comparison of Length Frequencies from Stratified Random Cluster Sampling</p></a></li>
<li><a href='#clus.t.test'><p>Correcting a Two-Sample Test for Clustering</p></a></li>
<li><a href='#clus.vb.fit'>
<p>Fit a Von Bertalanffy growth equation to clustered data via bootstrapping</p></a></li>
<li><a href='#codcluslen'><p>Lengths of Atlantic cod caught during Massachusetts Division of Marine Fisheries bottom trawl survey, spring 1985.</p></a></li>
<li><a href='#codstrcluslen'><p>Lengths of Atlantic cod caught during Massachusetts Division of Marine Fisheries stratified random bottom trawl survey, spring 1985.</p></a></li>
<li><a href='#combinevar'><p>Combining Mean and Variances from Multiple Samples</p></a></li>
<li><a href='#compare.lrt.plus'><p>Comparison of growthlrt.plus model objects</p></a></li>
<li><a href='#compare2'><p>Comparisons of two age readers or two aging methods</p></a></li>
<li><a href='#convmort'><p>Conversion of Mortality Rates</p></a></li>
<li><a href='#counts'><p>Run size data for alewife (<em>Alosa pseudoharengus</em>)</p></a></li>
<li><a href='#cowcod'><p>Catch data (metric tons) for cowcod Sebastes levis 1900 to 2008</p></a></li>
<li><a href='#cpuekapp'>
<p>Trawl survey based abundance estimation using data sets with unusually large catches</p></a></li>
<li><a href='#darter'><p>Catch Removal Data For Fantail Darter</p></a></li>
<li><a href='#dbsra'><p>Depletion-Based Stock Reduction Analysis</p></a></li>
<li><a href='#deltadist'><p>Delta Distribution Mean and Variance Estimators</p></a></li>
<li><a href='#deplet'><p>Catch-Effort Depletion Methods For a Closed Population</p></a></li>
<li><a href='#dlproj'>
<p>This function performs projections for dbsra and catchmsy objects</p></a></li>
<li><a href='#ep_growth'><p>Fitting the von Bertalanffy growth model to length-stratified age samples</p></a></li>
<li><a href='#ep.data'><p>A sub-sample of data from a simulated population collected via length-stratified age sampling</p></a></li>
<li><a href='#epr'><p>Eggs-Per-Recruit Analysis</p></a></li>
<li><a href='#fm_checkdesign'><p>Check parameter structure of Hightower et al. (2001) models</p></a></li>
<li><a href='#fm_model_avg'><p>Model Averaging for the Telemetry Method of Hightower et al. (2001)</p></a></li>
<li><a href='#fm_telemetry'><p>Estimation of Fishing and Natural Mortality from Telemetry Data</p></a></li>
<li><a href='#fpc'>
<p>Fishing Power Correction Factor from Experimental Fishing</p></a></li>
<li><a href='#gap'>
<p>Tukey's Gapping</p></a></li>
<li><a href='#Gerking'><p>Mark-Recapture Data for Sunfish in an Indiana Lake</p></a></li>
<li><a href='#goosefish'><p>Mean Length and Numbers of Lengths for Northern Goosefish, 1963-2002</p></a></li>
<li><a href='#grotag'>
<p>Maximum likelihood estimation of growth and growth variability from tagging data - Francis (1988)</p></a></li>
<li><a href='#grotagplus'>
<p>Flexible maximum likelihood estimation of growth from multiple tagging datasets.</p></a></li>
<li><a href='#growhamp'>
<p>von Bertalanffy Growth Models for Tagging Data Incorporating Individual Variation</p></a></li>
<li><a href='#growth'><p>Fitting Growth Curves to Length- or Weight-at-Age Data</p></a></li>
<li><a href='#growth_LEP'>
<p>A flexible maximum likelihood approach for fitting growth curves to tag-recapture data</p></a></li>
<li><a href='#growth_sel'>
<p>Fitting a von Bertalanffy curve to length and age data biased by gear selectivity</p></a></li>
<li><a href='#growthlrt'><p>Likelihood Ratio Tests for Comparing Multiple Growth Curves</p></a></li>
<li><a href='#growthlrt.plus'>
<p>Likelihood Methods for Comparing Multiple Growth Curves</p></a></li>
<li><a href='#growthmultifit'><p>Fit a Multi-Group Growth Model</p></a></li>
<li><a href='#growthResid'>
<p>Plot residuals of growth model fitted to tag data</p></a></li>
<li><a href='#growthTraject'>
<p>Plot growth trajectories obtained from tagging data</p></a></li>
<li><a href='#growtrans'>
<p>Growth Transition Matrix for a Size-Structured Population Dynamics Model</p></a></li>
<li><a href='#haddock'><p>Biological data for haddock (Melanogrammus aeglefinus)</p></a></li>
<li><a href='#Hightower'><p>Original data used in Hightower et al. (2001)</p></a></li>
<li><a href='#Hoenig'><p>Tag Data from Hoenig et al. (1998)</p></a></li>
<li><a href='#hohe'><p>age-length key and length frequency data from Hoenig and Heisey (1987)</p></a></li>
<li><a href='#inverse_alk'><p>Inverse Age-Length Key Method of Hoenig and Heisey (1987)</p></a></li>
<li><a href='#irm_cr'><p>Age-Independent Instantaneous Rates Model of Jiang et al. (2007) Incorporating Catch and Release Tag Returns</p></a></li>
<li><a href='#irm_h'><p>Age-Independent Instantaneous Rates Tag Return Model of Hoenig et al. (1998)</p></a></li>
<li><a href='#Jensen'><p>Age Frequency Data for Lake Whitefish By Individual Haul</p></a></li>
<li><a href='#Jiang'><p>Tag Data from Jiang (2005)</p></a></li>
<li><a href='#kappenman'><p>Pacific cod catch per effort from Table 1 in Kappenman (1999)</p></a></li>
<li><a href='#Kimura'><p>Length and Age Data For Male and Female Pacific Hake</p></a></li>
<li><a href='#lepdata'><p>Simulated data based on parameters estimated from corrected 1980s bluefin tuna data used in Laslett et al.(2002)</p></a></li>
<li><a href='#lifetable'><p>Life Table Construction</p></a></li>
<li><a href='#lingcod'><p>Catch data (metric tons) for lingcod 1889 to 2001</p></a></li>
<li><a href='#M.empirical'><p>Estimation of Natural Mortality Rates from Life History Parameters</p></a></li>
<li><a href='#maki'><p>Data from Maki et al. 2001</p></a></li>
<li><a href='#mature'><p>Estimation of proportion mature at age when immature fish are unavailable</p></a></li>
<li><a href='#menhaden'><p>Biological data for menhaden (Brevoortia tyrannus)</p></a></li>
<li><a href='#mort.al'>
<p>Estimation of Mortality using Times-At-Large Data from Tagging</p></a></li>
<li><a href='#mrN.single'><p>Estimate of Population Size from a Single Mark-Recapture Experiment</p></a></li>
<li><a href='#nshrimp'><p>Data for Gulf of Maine northern shrimp</p></a></li>
<li><a href='#opt_slot'><p>Optimum Slot and Trophy Size Limits for Recreational Fisheries</p></a></li>
<li><a href='#opt_trophy'><p>Optimum Trophy Size Limits for Recreational Fisheries</p></a></li>
<li><a href='#P.donacina'><p>Data from a growth study of New Zealand intertidal clams.</p></a></li>
<li><a href='#pgen'><p>Probability of a Management Parameter Exceeding a Reference Point</p></a></li>
<li><a href='#pinfish'><p>Length, age and sex data for pinfish (Lagodon rhomboides) from Tampa Bay, Florida</p></a></li>
<li><a href='#plot.grotagplus'>
<p>Plotting Tagging-Growth Objects</p></a></li>
<li><a href='#powertrend'><p>Power Analysis For Detecting Trends</p></a></li>
<li><a href='#print.grotagplus'>
<p>Printing Tagging-Growth Objects</p></a></li>
<li><a href='#pwpop'><p> Estimate Net Reproductive Rates Over Multiple Periods Of An Abundance Time Series Using Piecewise Regression</p></a></li>
<li><a href='#remp'><p>Random Number Generation from an Empirical Distribution</p></a></li>
<li><a href='#rig'><p>Tagging data from a growth study of rig</p></a></li>
<li><a href='#rockbass'><p>Age Frequency Data for Rock Bass</p></a></li>
<li><a href='#sblen'><p>Total length (inches) of striped bass collected by Massachusetts volunteer anglers in 2014</p></a></li>
<li><a href='#sbotos'><p>Otolith ages of striped bass made by two age readers</p></a></li>
<li><a href='#sbpr'><p>Spawning Stock Biomass-Per-Recruit Analysis</p></a></li>
<li><a href='#schnabel'><p>Population Size Estimates from Repeated Mark-Recapture Experiments</p></a></li>
<li><a href='#Shepherd'><p>Seasonal Length Frequencies for Raja clavata</p></a></li>
<li><a href='#simulus'>
<p>Age and size data for the growth_sel function</p></a></li>
<li><a href='#slca'><p>A Weakly Parametric Method for the Analysis of Length Composition Data</p></a></li>
<li><a href='#sole'><p>Flathead sole CPUEs</p></a></li>
<li><a href='#sr'><p>Estimation and Model Comparison of Stock-Recruitment Relationships</p></a></li>
<li><a href='#striper'><p>Recruitment Numbers and Female Spawning Stock Biomass for Striped Bass</p></a></li>
<li><a href='#surveyfit'><p>Estimating the Relative Abundance of Fish From a Trawl Survey</p></a></li>
<li><a href='#surveyref'><p>Quantitative reference points from stock abundance indices based on research surveys</p></a></li>
<li><a href='#tag_model_avg'><p>Model Averaging for Instantaneous Rates Tag Return Models</p></a></li>
<li><a href='#tanaka'><p>Simulated alfonsino data for Tanaka (2006</p></a></li>
<li><a href='#trout'><p>Mark-recapture data for Kenai River trout trout</p></a></li>
<li><a href='#vbfr'>
<p>Francis' re-parameterization of the von Bertalanffy growth equation for length-age data</p></a></li>
<li><a href='#wolffish'><p>Spring untransformed mean catch per tow for wolffish (Anarhichas lupus)</p></a></li>
<li><a href='#yellowtail'><p>Fall average catch per tow for southern New England yellowtail flounder</p></a></li>
<li><a href='#ypr'><p>Yield-Per-Recruit Analysis</p></a></li>
<li><a href='#zt'><p>Z-transform or center a time series</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Fishery Science Methods and Models</td>
</tr>
<tr>
<td>Version:</td>
<td>1.13-1</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-2-5</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>TMB</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, data.table, MASS, boot, lme4, bootstrap, numDeriv,
TMB</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions for applying a wide range of fisheries stock assessment methods.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.0</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-02-05 13:11:46 UTC; GNelson</td>
</tr>
<tr>
<td>Author:</td>
<td>Gary A. Nelson [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Gary A. Nelson &lt;gary.nelson@mass.gov&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-02-05 13:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='agesurv'>Age-based Survival Estimators</h2><span id='topic+agesurv'></span>

<h3>Description</h3>

<p>Calculates annual survival (S) and instantaneous total mortality rates (Z) from age frequency by using
linear regression (standard and weighted), Heincke, Chapman-Robson, Poisson GLM and GLMER methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>agesurv(type=1, age=NULL, number=NULL, full=NULL, last=NULL, estimate=c("s","z"),
method=c("lr","he","cr","crcb","ripois","wlr","pois"), sign.est=3, sign.se=3, 
 glmer.control=glmerControl(optCtrl=list(maxfun=10000),optimizer="bobyqa"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="agesurv_+3A_type">type</code></td>
<td>
<p> the format of data. 1 = a single vector, each row represents the age of an individual (default), 
2 = summarized, one column of age and one column of numbers-at-age.</p>
</td></tr>
<tr><td><code id="agesurv_+3A_age">age</code></td>
<td>
<p> the vector of ages.</p>
</td></tr>
<tr><td><code id="agesurv_+3A_number">number</code></td>
<td>
<p> if <code>type</code> = 2, a vector of numbers-at-age matching the length of the age vector.</p>
</td></tr>
<tr><td><code id="agesurv_+3A_full">full</code></td>
<td>
<p>the fully-recruited age</p>
</td></tr>
<tr><td><code id="agesurv_+3A_last">last</code></td>
<td>
<p>the maximum age to include in the calculation. If not specified, the oldest age is used.</p>
</td></tr>
<tr><td><code id="agesurv_+3A_estimate">estimate</code></td>
<td>
<p>argument to select estimate type: &quot;s&quot; for annual survival, &quot;z&quot; for instantaneous total mortality.
Default is both.</p>
</td></tr>
<tr><td><code id="agesurv_+3A_method">method</code></td>
<td>
<p>argument to select the estimation method: &quot;lr&quot; for standard linear regression, &quot;he&quot; for Heincke,
&quot;cr&quot; for Chapman-Robson, &quot;crcb&quot; for Chapman-Robson Z estimate with bias-correction (Seber p. 418) and 
over-dispersion correction (Smith et al., 2012), &quot;ripois&quot; for Millar (2015) random-intercept
Poisson mixed model estimator, &quot;wlr&quot; for Maceine-Bettoli weighted regression,
&quot;pois&quot; for Poisson generalized linear model with overdispersion correction.
Default is all.</p>
</td></tr>
<tr><td><code id="agesurv_+3A_sign.est">sign.est</code></td>
<td>
<p>significant digits for survival estimates.</p>
</td></tr>
<tr><td><code id="agesurv_+3A_sign.se">sign.se</code></td>
<td>
<p>significant digits for standard error of survival estimates.</p>
</td></tr>
<tr><td><code id="agesurv_+3A_glmer.control">glmer.control</code></td>
<td>
<p>controls for function <code>glmer</code> used in the random-intercept Poisson mixed model. See
<code>glmerControl</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>type</code> = 1, the individual age data are tabulated. The age data are then subsetted based on the <code>full</code> and <code>last</code> arguments.  
Most calculations follow descriptions in Seber(1982), pages 414-418. If only two ages are present, a warning message 
is generated and the catch curve method is not calculated. Plus groups are not allowed. Any NAs represent no estimates due to some issue with model fit
like convergence. If age samples were collected via a survey using gears such as seines or trawl, or 
were subsampled from catch, the least biased estimators are the &quot;pois&quot; and &quot;crcb&quot; methods (Nelson, 2019). 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>results</code></td>
<td>
<p>list element containing table of parameters and standard errors.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>list element containing the age frequency data used in the analysis.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Seber, G. A. F. 1982. The Estimation of Animal Abundance and Related Parameters, Second Edition. The Blackburn Press,
Caldwell, New Jersey. 654 pages. 
</p>
<p>Maceina, M. J. and P. W. Bettoli. 1998. Variation in largemouth bass recruitment in four mainstream impoundments of the Tennessee River. 
N. Am. J. Fish. Manage. 18: 990-1003.
</p>
<p>Millar, R. B. 2015. A better estimator of mortality rate from age-frequency data. Can. J. Fish. Aquat.
Sci. 72: 364-375.
</p>
<p>Nelson, G. A. 2019. Bias in common catch-curve methods applied to age frequency data from fish surveys. ICES
J. Mar. Sci. doi:10.1093/icesjms/fsz085.
</p>
<p>Quinn, T. J. and R. B. Deriso. 1999. Quantitative Fish Dynamics. Oxford University Press, New York, New York. 542 pages.
</p>
<p>Smith, M. W. and 5 others. 2012. Recommendations for catch-curve analysis. N. Am. J. Fish. Manage. 32: 956-967.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(rockbass)
agesurv(age=rockbass$age,full=6)</code></pre>

<hr>
<h2 id='agesurvcl'>Age-Based Survival and Mortality Estimators for Cluster Sampling</h2><span id='topic+agesurvcl'></span>

<h3>Description</h3>

<p>Calculates the survival and mortality estimators of Jensen (1996) where net hauls are treated as samples
</p>


<h3>Usage</h3>

<pre><code class='language-R'>agesurvcl(age = NULL, group = NULL, full = NULL, last = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="agesurvcl_+3A_age">age</code></td>
<td>
<p>the vector of ages.  Each row represents the age of an individual.</p>
</td></tr>
<tr><td><code id="agesurvcl_+3A_group">group</code></td>
<td>
<p>the vector containing variable used to identify the sampling unit (e.g., haul). Identifier can be numeric or character.</p>
</td></tr>
<tr><td><code id="agesurvcl_+3A_full">full</code></td>
<td>
<p>the fully-recruited age.</p>
</td></tr>
<tr><td><code id="agesurvcl_+3A_last">last</code></td>
<td>
<p>the maximum age to include in the calculation. If not specified, the oldest age is used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The individual age data are tabulated and subsetted based on <code>full</code> and <code>last</code>.  The calculations follow Jensen(1996).
If only two ages are present, a warning message is generated.
</p>


<h3>Value</h3>

<p>Matrix containing estimates of annual mortality (a), annual survival (S), and instantaneous total mortality (Z) and
associated standard errors.
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Jensen, A. L. 1996. <em>Ratio estimation of mortality using catch curves</em>. Fisheries Research 27: 61-67.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+agesurv">agesurv</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Jensen)
agesurvcl(age=Jensen$age,group=Jensen$group,full=0)
</code></pre>

<hr>
<h2 id='alk'>Create An Age-Length Key</h2><span id='topic+alk'></span>

<h3>Description</h3>

<p>Creates an age-length key in numbers or proportions-at-age per size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alk(age=NULL,size=NULL,binsize=NULL,type=1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="alk_+3A_age">age</code></td>
<td>
<p>a vector of individual age data.</p>
</td></tr>
<tr><td><code id="alk_+3A_size">size</code></td>
<td>
<p>a vector of individual size data.</p>
</td></tr>
<tr><td><code id="alk_+3A_binsize">binsize</code></td>
<td>
<p>size of the length class (e.g., 5-cm, 10, cm, etc.) used to group size data.
The formula used to create bins is <code class="reqn">trunc(size/binsize)*binsize+binsize/2</code>. 
If use of the raw length classes is desired, then <code>binsize=0</code>.</p>
</td></tr>
<tr><td><code id="alk_+3A_type">type</code></td>
<td>
<p>If <code>type</code>=1, numbers-at-age per size are produced.  This format is used in
functions <code>alkprop</code>, <code>alkss</code>, and <code>alkD</code>. If <code>type</code>=2,
proportions-at-age per size are produced.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Create age-length keys with either numbers-at-age per size class. Records with missing size values are deleted prior to calculation.
Missing ages are allowed.
</p>


<h3>Value</h3>

<p>A table of size, total numbers at size, and numbers (or proportions)-at-age per size class.</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Quinn, T. J. and R. B. Deriso. 1999. Quantitative Fish Dynamics. Oxford University Press, New York, New York. 542 pages</p>


<h3>See Also</h3>

<p><code><a href="#topic+alkD">alkD</a></code> <code><a href="#topic+alkss">alkss</a></code> <code><a href="#topic+alkprop">alkprop</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Not run: 
  data(pinfish) 
  with(pinfish,alk(age=round(age,0),size=sl,binsize=10))
 
## End(Not run)
</code></pre>

<hr>
<h2 id='alkD'>Sample Size Determination for Age Subsampling Using the D statistic</h2><span id='topic+alkD'></span>

<h3>Description</h3>

<p>Calculates the D statistic (sqrt of accumulated variance among ages; Lai 1987) for a range of age sample sizes using data 
from an age-length key.  Assumes a two-stage random sampling design with proportional or fixed allocation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alkD(x, lss = NULL, minss = NULL, maxss = NULL, sampint = NULL, 
    allocate = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="alkD_+3A_x">x</code></td>
<td>
<p>a data frame containing an age-length key (similar to Table 8.3 on page 307 of Quinn and Deriso (1999)).  
The first column must contain the length intervals as numeric labels (no ranges), the second column must 
contain the number of samples within each length interval (Ll in Q &amp; D), and the third and remaining columns must 
contain the number of samples for each age class within each length interval (one column for each age class).
Column labels are not necessary but are helpful. Columns l and Al in Table 8.3 should not be 
included. Empty cells must contain zeros.
</p>
</td></tr>
<tr><td><code id="alkD_+3A_lss">lss</code></td>
<td>
<p>the sample size for length frequency</p>
</td></tr>
<tr><td><code id="alkD_+3A_minss">minss</code></td>
<td>
<p>the minimum age sample size</p>
</td></tr>
<tr><td><code id="alkD_+3A_maxss">maxss</code></td>
<td>
<p>the maximum age sample size.  Value can not be larger than the sample size for the length frequency(<code>lss</code>)</p>
</td></tr>
<tr><td><code id="alkD_+3A_sampint">sampint</code></td>
<td>
<p>the sample size interval</p>
</td></tr>
<tr><td><code id="alkD_+3A_allocate">allocate</code></td>
<td>
<p>the type of allocation: 1=proportional, 2=fixed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Following Quinn and Deriso (1999:pages 308-309), the function calculates the D statistic (sqrt of 
accumulated variance among ages; Lai 1987) for a range of age sample sizes defined by <code>minss</code>, <code>maxss</code>, and 
<code>sampint</code> at a
given length sample size <code>lss</code>.  The size of an age sample at a desired level of D can be obtained by the comparison. See reference
to Table 8.8, p. 314 in Quinn and Deriso.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>label</code></td>
<td>
<p>list element containing the summary of input criteria</p>
</td></tr>
<tr><td><code>comp2</code></td>
<td>
<p>list element containing the D statistic for each age sample size given lss</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Quinn, T. J. and R. B. Deriso. 1999. Quantitative Fish Dynamics. Oxford University Press, New York, New York. 542 pages
</p>
<p>Lai, H.L. 1987. Optimum allocation for estimating age composition using age-length keys. U.S. Fish. Bull. 85:179-185</p>


<h3>See Also</h3>

<p><code><a href="#topic+alkss">alkss</a></code> <code><a href="#topic+alkprop">alkprop</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(alkdata)
alkD(alkdata,lss=1000,minss=25,maxss=1000,sampint=20,allocate=1)
</code></pre>

<hr>
<h2 id='alkdata'>Age-Length Key for Gulf of Hauraki snapper, 1992-1993</h2><span id='topic+alkdata'></span>

<h3>Description</h3>

<p>The <code>alkdata</code> data frame has 39 rows and 16 columns.
The age-length key for Gulf of Hauraki snapper shown in Table 8.3 of Quinn and Deriso (1999)</p>


<h3>Usage</h3>

<pre><code class='language-R'>alkdata
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>len</dt><dd><p>length interval</p>
</dd>
<dt>nl</dt><dd><p>number measured in length interval</p>
</dd>
<dt>A3</dt><dd><p>number of fish aged in each age class 3 within each length interval</p>
</dd> 
<dt>A4</dt><dd><p>number of fish aged in each age class 4 within each length interval</p>
</dd> 
<dt>A5</dt><dd><p>number of fish aged in each age class 5 within each length interval</p>
</dd> 
<dt>A6</dt><dd><p>number of fish aged in each age class 6 within each length interval</p>
</dd> 
<dt>A7</dt><dd><p>number of fish aged in each age class 7 within each length interval</p>
</dd> 
<dt>A8</dt><dd><p>number of fish aged in each age class 8 within each length interval</p>
</dd> 
<dt>A9</dt><dd><p>number of fish aged in each age class 9 within each length interval</p>
</dd> 
<dt>A10</dt><dd><p>number of fish aged in each age class 10 within each length interval</p>
</dd> 
<dt>A11</dt><dd><p>number of fish aged in each age class 11 within each length interval</p>
</dd> 
<dt>A12</dt><dd><p>number of fish aged in each age class 12 within each length interval</p>
</dd> 
<dt>A13</dt><dd><p>number of fish aged in each age class 13 within each length interval</p>
</dd> 
<dt>A14</dt><dd><p>number of fish aged in each age class 14 within each length interval</p>
</dd> 
<dt>A15</dt><dd><p>number of fish aged in each age class 15 within each length interval</p>
</dd> 
<dt>A16</dt><dd><p>number of fish aged in each age class 16 within each length interval</p>
</dd> 
</dl>



<h3>Source</h3>

<p>Quinn, T. J. and R. B. Deriso. 1999. <em>Quantitative Fish Dynamics</em>.
Oxford University Press, New York, NY. 542 p. 
</p>

<hr>
<h2 id='alkprop'>Age-Length Key Proportions-At-Age</h2><span id='topic+alkprop'></span>

<h3>Description</h3>

<p>Calculates proportions-at-age and standard errors from an age-length key assuming a two-stage random sampling design.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alkprop(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="alkprop_+3A_x">x</code></td>
<td>
<p>a data frame containing an age-length key (similar to Table 8.3 on page 307 of Quinn and Deriso (1999)).  
The first column must contain the length intervals as single numeric labels (no ranges), the second column must 
contain the number of samples within each length interval (Ll in Q &amp; D), and the third and remaining columns must 
contain the number of samples for each age class within each length interval (one column for each age class).
Column labels are not necessary but are helpful. Columns l and Al in Table 8.3 should not be 
included. Empty cells must contain zeros.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If individual fish from catches are sampled randomly for lengths and then are further subsampled 
for age structures, Quinn and Deriso (1999: pages 304-305) showed that the proportions of fish in each age class
and corresponding standard errors can be calculated assuming a two-stage random sampling design. See reference to Table 8.4,
page 308 in Quinn and Deriso.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>results</code></td>
<td>
<p>list element containing a table of proportions, standard errors, and coefficients of variation
for each age class.</p>
</td></tr></table>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Quinn, T. J. and R. B. Deriso. 1999. Quantitative Fish Dynamics. Oxford University Press, New York, New York. 542 pages</p>


<h3>See Also</h3>

<p><code><a href="#topic+alkD">alkD</a></code> <code><a href="#topic+alkss">alkss</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(alkdata) 
alkprop(alkdata)
</code></pre>

<hr>
<h2 id='alkss'>Sample Size Determination for Age Subsampling</h2><span id='topic+alkss'></span>

<h3>Description</h3>

<p>Calculates sample sizes for age subsampling assuming a two-stage random sampling design with
proportional or fixed allocation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alkss(x, lss = NULL, cv = NULL, allocate = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="alkss_+3A_x">x</code></td>
<td>
<p>a data frame containing an age-length key (similar to Table 8.3 on page 307 of Quinn and Deriso (1999)).  
The first column must contain the length intervals as numeric labels (no ranges), the second column must 
contain the number of samples within each length interval (Ll in Q &amp; D), and the third and remaining columns must 
contain the number of samples for each age class within each length interval (one column for each age class).
Column labels are not necessary but are helpful. Columns l and Al in Table 8.3 should not be 
included. Empty cells must contain zeros.
</p>
</td></tr>
<tr><td><code id="alkss_+3A_lss">lss</code></td>
<td>
<p>the sample size for length frequency</p>
</td></tr>
<tr><td><code id="alkss_+3A_cv">cv</code></td>
<td>
<p>the desired coefficient of variation</p>
</td></tr>
<tr><td><code id="alkss_+3A_allocate">allocate</code></td>
<td>
<p>the type of allocation: 1=proportional, 2=fixed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If individual fish from catches are sampled randomly for lengths and then are further subsampled 
for age structures, Quinn and Deriso (1999: pages 306-309) showed that sample sizes for age structures 
can be determined for proportional (the number of fish aged is selected proportional to the length frequencies) and 
fixed (a constant number are aged per length class) allocation assuming a two-stage random sampling design. 
Sample sizes are determined based on the length frequency sample size, a specified 
coefficient of variation, and proportional or fixed allocation.  The number of age classes is calculated internally.
See reference to Table 8.6, p. 312 in Quinn and Deriso.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>label</code></td>
<td>
<p>list element containing the summary of input criteria</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>list element containing the sample size estimates for each age</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Quinn, T. J. and R. B. Deriso. 1999. Quantitative Fish Dynamics. Oxford University Press, New York, New York. 542 pages</p>


<h3>See Also</h3>

<p><code><a href="#topic+alkD">alkD</a></code> <code><a href="#topic+alkprop">alkprop</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(alkdata) 
alkss(alkdata,lss=1000,cv=0.25,allocate=1)
</code></pre>

<hr>
<h2 id='astrocalc4r'>Solar zenith angles for biological research
</h2><span id='topic+astrocalc4r'></span>

<h3>Description</h3>

<p>This function calculates the solar zenith, azimuth and declination angles, time at sunrise, local noon and sunset, day length, 
and PAR (photosynthetically available radiation, 400-700 nm) under clear
skies and average atmospheric conditions
(marine or continental) anywhere on the surface of the earth based on date, time, and location.</p>


<h3>Usage</h3>

<pre><code class='language-R'>astrocalc4r(day, month, year, hour, timezone, lat, lon, 
withinput = FALSE, 
seaorland = "maritime", acknowledgment = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="astrocalc4r_+3A_day">day</code></td>
<td>
<p>day of month in the local time zone (integers). Value is
required. Multiple observations should be
enclosed with the c() function.</p>
</td></tr>
<tr><td><code id="astrocalc4r_+3A_month">month</code></td>
<td>
<p>month of year in the local time zone (integers). Value is
required. Multiple observations should be 
enclosed with the c() function.</p>
</td></tr>
<tr><td><code id="astrocalc4r_+3A_year">year</code></td>
<td>
<p>year in the local time zone (integers).Value is
required. Multiple observations should be
enclosed with the c() function.</p>
</td></tr>
<tr><td><code id="astrocalc4r_+3A_hour">hour</code></td>
<td>
<p>local time for each observation (decimal hours, e.g. 11:30 PM is 23.5, real numbers). Value is required. 
Multiple observations should be enclosed with the c() function.</p>
</td></tr>
<tr><td><code id="astrocalc4r_+3A_timezone">timezone</code></td>
<td>
<p>local time zone in +/- hours relative to GMT to link
local time and GMT. For example, the difference
between Eastern Standard Time and GMT is -5 hours. Value is
required. Multiple observations should be enclosed 
with the c() function. timezone should include any necessary adjustments for daylight savings time.</p>
</td></tr>
<tr><td><code id="astrocalc4r_+3A_lat">lat</code></td>
<td>
<p>Latitude in decimal degrees (0o to 90 o in the northern  hemisphere and -90 o to 0 o degrees in the 
southern hemisphere, real numbers). For example, 42o 30' N is 42.5 o and 42o 30' S is -42.5o. 
Value is required. Multiple observations should be enclosed with the c() function.</p>
</td></tr>
<tr><td><code id="astrocalc4r_+3A_lon">lon</code></td>
<td>
<p>Longitude in decimal degrees (-0 o to 180 o in the western
hemisphere and 0o to 180 o in the eastern hemisphere, real numbers). 
For example, 110o 15' W is -110.25 o and 110o 15' E is 110.25o. Value is required. 
Multiple observations should be enclosed with the c() function.</p>
</td></tr>
<tr><td><code id="astrocalc4r_+3A_withinput">withinput</code></td>
<td>
<p>logical:TRUE to return results in a dataframe with
the input data; otherwise FALSE returns a dataframe with just results. Default is FALSE.</p>
</td></tr>
<tr><td><code id="astrocalc4r_+3A_seaorland">seaorland</code></td>
<td>
<p>text: &quot;maritime&quot; for typical maritime conditions or &quot;continental&quot; for typical continental conditions.
Users must select one option or the other based on proximity to the ocean or other factors.</p>
</td></tr>
<tr><td><code id="astrocalc4r_+3A_acknowledgment">acknowledgment</code></td>
<td>
<p>logical: use TRUE to output acknowledgement. Default is FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Astronomical definitions are based on definitions in Meeus (2009) and Seidelmann (2006).
The solar zenith angle is measured between a line drawn &quot;straight up&quot; from the center of the earth through the 
observer and a line drawn from the observer to the center of the solar disk. 
The zenith angle reaches its lowest daily value at local noon when the sun is highest. It reaches its maximum value at 
night after the sun drops below the horizon.  The zenith angle and all of the solar variables calculated by
<code>astrocalc4r</code> depend on latitude, longitude, date and time of day. For example, solar zenith angles measured 
at the same time of day and two different locations would differ due to
differences in location. Zenith angles at the same location and 
two different dates or times of day also differ.
</p>
<p>Local noon is the time of day when the sun reaches its maximum elevation and minimum solar zenith angle at the observers location. This 
angle occurs when the leading edge of the sun first appears above, or the trailing edge disappears below 
the horizon (0.83o accounts for the radius of the sun when seen from the earth and for refraction by the atmosphere). 
Day length is the time in hours between sunrise and sunset. Solar
declination and azimuth angles describe the exact position of the sun in
the sky relative to an observer based on an equatorial coordinate system (Meeus 2009). Solar declination 
is the angular displacement of the sun above the equatorial plane. The
equation of time accounts for the relative
position of the observer within the time zone and is provided because it
is complicated to calculate. PAR isirradiance in lux (lx, approximately W m-2) at the surface of the 
earth under clear skies calculated based on the solar zenith angle and assumptions about marine or terrestrial atmospheric 
properties. <code>astrocalc4r</code> calculates PAR for wavelengths between 400-700 nm. Calculations for other wavelengths
can be carried out by modifying the code to use parameters from Frouin et al. (1989). Following Frouin et al. (1989), 
PAR is assumed to be zero at solar zenith angles &gt;= 90o although some sunlight may be visible in the sky 
when the solar zenith angle is &lt; 108o. Angles in <code>astrocalc4r</code> output are in degrees although radians are used 
internally for calculations. Time data and results are in decimal hours (e.g. 11:30 pm = 23.5 h) local time but internal
calculations are in Greenwich Mean Time (GMT). The user must specify the local time zone in terms of +/- hours relative to GMT to link 
local time and GMT. For example, the difference between Eastern Standard Time and GMT is -5 hours.
The user must ensure that any adjustments for daylight savings time are included in the timezone value. For example, 
timezone=-6 for Eastern daylight time.
</p>


<h3>Value</h3>

<p>Time of solar noon, sunrise and sunset, angles of azimuth and zenith, eqtime, declination of sun,
daylight length (hours) and PAR.
</p>


<h3>Author(s)</h3>

<p>Larry Jacobson, Alan Seaver, and Jiashen Tang
NOAA National Marine Fisheries Service
Northeast Fisheries Science Center, 166 Water St., Woods Hole, MA 02543
</p>
<p><a href="mailto:larryjacobson6@gmail.com">larryjacobson6@gmail.com</a>
</p>


<h3>References</h3>

<p>Frouin, R., Lingner, D., Gautier, C., Baker, K. and Smith, R. 1989. A simple analytical formula 
to compute total and photosynthetically available solar irradiance at the ocean surface under 
clear skies. J. Geophys. Res. 94: 9731-9742. 
</p>
<p>L. D. Jacobson, L. C. Hendrickson, and J. Tang. 2015. Solar zenith angles for biological research and an expected
catch model for diel vertical migration patterns that affect stock size estimates for longfin inshore squid
(Doryteuthis pealeii). Canadian Journal of Fisheries and Aquatic Sciences 72: 1329-1338.
</p>
<p>Meeus, J. 2009. Astronomical Algorithms, 2nd Edition. Willmann-Bell, Inc., Richmond, VA.
Seidelmann, P.K. 2006. Explanatory Supplement to the Astronomical Almanac. University
Science Books, Sausalito, CA.
</p>
<p>Seidelmann, P.K. 2006. Explanatory Supplement to the Astronomical Almanac. University Science Books, Sausalito, CA. 
This function is an R implementation of: 
</p>
<p>Jacobson L, Seaver A, Tang J. 2011. AstroCalc4R: software to calculate solar zenith angle; 
time at sunrise, local noon and sunset; and photosynthetically available radiation based on date, 
time and location. US Dept Commer, Northeast Fish Sci Cent Ref Doc. 11-14; 10 p.   
</p>


<h3>Examples</h3>

<pre><code class='language-R'>astrocalc4r(day=12,month=9,year=2000,hour=12,timezone=-5,lat=40.9,lon=-110)
</code></pre>

<hr>
<h2 id='AtkaMack'>Length and Age Data For Male and Female Atka Mackerel</h2><span id='topic+AtkaMack'></span>

<h3>Description</h3>

<p>The <code>AtkaMack</code> data frame has 20 rows and 4 columns.
Mean length-at-age data for male and female Atka Mackerel as listed in Table 3 of Kimura (1990) </p>


<h3>Usage</h3>

<pre><code class='language-R'>AtkaMack
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>age</dt><dd><p>fish age</p>
</dd>
<dt>len</dt><dd><p>mean length of fish of <em>age</em> (cm)</p>
</dd>
<dt>sex</dt><dd><p>sex code</p>
</dd>
<dt>m</dt><dd><p>transformed age for SFR parameterization of von Bertalanffy equation</p>
</dd>
<dt>n</dt><dd><p>sample size</p>
</dd>
</dl>



<h3>Source</h3>

<p>Kimura, D. K. 1990. <em>Testing nonlinear regression paramters under heteroscedastic, normally distributed errors</em>. 
Biometrics 46:697-708.
</p>

<hr>
<h2 id='bheq'>Length-based Beverton-Holt Equilibrium Total Instantaneous Mortality Estimator</h2><span id='topic+bheq'></span>

<h3>Description</h3>

<p>Calculate the equilibrium Beverton-Holt estimator of instantaneous total mortality (Z) from length data with bootstrapped standard errors or the same using the Ehrhardt and Ault(1992) bias-correction 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bheq(len, type = c(1,2), K = NULL, Linf = NULL, Lc = NULL, 
La = NULL, nboot = 100)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bheq_+3A_len">len</code></td>
<td>
<p>the vector of length data. Each row represents one record per individual fish.</p>
</td></tr>
<tr><td><code id="bheq_+3A_type">type</code></td>
<td>
<p>numeric indicate which estimation method to use. 1 = Beverton-Holt, 2 = Beverton-Holt with bias correction. Default is both, c(1,2).</p>
</td></tr>
<tr><td><code id="bheq_+3A_k">K</code></td>
<td>
<p>the growth coefficient from a von Bertalanffy growth model.</p>
</td></tr>
<tr><td><code id="bheq_+3A_linf">Linf</code></td>
<td>
<p>the L-infinity coefficient from a von Bertalanffy growth model.</p>
</td></tr>
<tr><td><code id="bheq_+3A_lc">Lc</code></td>
<td>
<p>the length at first capture.</p>
</td></tr>
<tr><td><code id="bheq_+3A_la">La</code></td>
<td>
<p>the largest length of the largest size class.</p>
</td></tr>
<tr><td><code id="bheq_+3A_nboot">nboot</code></td>
<td>
<p>the number of bootstrap runs. Default=100.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The standard Beverton-Holt equilibrium estimator of instantaneous total mortality (Z)
from length data (page 365 in Quinn and Deriso (1999)) is calculated. The mean length 
for lengths &gt;=Lc is calculated automatically. Missing data are removed prior to calculation.
Estimates of standard error are made by bootstrapping length data &gt;=Lc using package <code>boot</code>. 
</p>


<h3>Value</h3>

<p>Dataframe of length 1 containing mean length&gt;=Lc, sample size&gt;=Lc, Z estimate and standard error.
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Ehrhardt, N. M. and J. S. Ault. 1992. Analysis of two length-based mortality models applied to bounded
catch length frequencies. Trans. Am. Fish. Soc. 121:115-122.
</p>
<p>Quinn, T. J. and R. B. Deriso. 1999. Quantitative Fish Dynamics. Oxford University Press, New York, New York. 542 pages.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bhnoneq">bhnoneq</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(pinfish)
bheq(pinfish$sl,type=1,K=0.33,Linf=219.9,Lc=120,nboot=200)
</code></pre>

<hr>
<h2 id='bhnoneq'>Length-based Beverton-Holt Nonequilibrium Z Estimator</h2><span id='topic+bhnoneq'></span>

<h3>Description</h3>

<p>A nonequilibrium Beverton-Holt estimator of instantaneous total mortality (Z) from 
length data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bhnoneq(year=NULL,mlen=NULL, ss=NULL, K = NULL, Linf = NULL, 
Lc = NULL, nbreaks = NULL, styrs = NULL, stZ = NULL, 
graph = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bhnoneq_+3A_year">year</code></td>
<td>
<p>the vector of year values associated with mean length data. The number 
of year values must correspond to the number of length records. Include year value even if mean length and numbers (see below)
are missing.</p>
</td></tr>
<tr><td><code id="bhnoneq_+3A_mlen">mlen</code></td>
<td>
<p>the vector of mean lengths for lengths &gt;=Lc. One record for each year.</p>
</td></tr>
<tr><td><code id="bhnoneq_+3A_ss">ss</code></td>
<td>
<p>the vector of numbers of observations associated with the mean length.</p>
</td></tr>  
<tr><td><code id="bhnoneq_+3A_k">K</code></td>
<td>
<p>the growth coefficient from a von Bertalanffy growth model.</p>
</td></tr>
<tr><td><code id="bhnoneq_+3A_linf">Linf</code></td>
<td>
<p>the L-infinity coefficient from a von Bertalanffy growth model.</p>
</td></tr>
<tr><td><code id="bhnoneq_+3A_lc">Lc</code></td>
<td>
<p>the length at first capture.</p>
</td></tr>
<tr><td><code id="bhnoneq_+3A_nbreaks">nbreaks</code></td>
<td>
<p>the number of times (breaks) mortality is thought to change over the time series. Can be 0 or greater.</p>
</td></tr>
<tr><td><code id="bhnoneq_+3A_styrs">styrs</code></td>
<td>
<p>the starting guess(es) of the year(s) during which mortality is thought to change. 
The number of starting guesses must match the number of mortality breaks, should be separated by
commas within the concatentation function and should be within the range of years present 
in the data. 
</p>
</td></tr>
<tr><td><code id="bhnoneq_+3A_stz">stZ</code></td>
<td>
<p>the starting guesses of Z values enclosed within the concatentation function. There should be <em>nbreaks+1</em> values provided. 
</p>
</td></tr>
<tr><td><code id="bhnoneq_+3A_graph">graph</code></td>
<td>
<p>logical indicating whether the observed vs predicted and residual plots should be drawn. Default=TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mean lengths for each year for lengths&gt;=Lc. Following Gedamke and Hoening(2006), the model estimates <code>nbreaks+1</code> Z values, the year(s) in which the
changes in mortality began, the standard deviation of lengths&gt;=Lc, and standard errors of all parameters. An AIC value is produced for model comparison.
The estimated parameters for the number of <code>nbreaks</code> is equal to <code>2*nbreaks+2</code>.  Problematic parameter estimates may have extremely large t-values or
extremely small standard error. Quang C. Huynh of Virginia Institute of Marine Science revised the function to make estimation more stable. Specifically,
the derivative method BFGS is used in <code>optim</code> which allows more reliable convergence to the global minimum from a given set of starting values,
a function is included to estimate Z assuming equilibrium, sigma is estimated analytically and convergence results .
Use 0 <code>nbreaks</code> to get Z equilibrium.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>summary</code></td>
<td>
<p>list element containing table of parameters with estimates, 
standard errors, and t-values.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>list element specifying if convergence was reached.</p>
</td></tr>
<tr><td><code>hessian</code></td>
<td>
<p>list element specifying if hessian is positive definite</p>
</td></tr>
<tr><td><code>results</code></td>
<td>
<p>list element containing, observed value, predicted values, and residuals from the model fit.</p>
</td></tr>
</table>


<h3>Note</h3>

<p> Todd Gedamke provided the predicted mean length code in C++.
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a>
</p>
<p>Quang C. Huynh of Virginia Institute of Marine Science</p>


<h3>References</h3>

<p>Gedamke, T. and J. M. Hoenig. 2006. Estimating mortality from mean length
data in nonequilibrium situations, with application to the assessment of goosefish. Trans. Am. Fish. Soc. 135:476-487</p>


<h3>See Also</h3>

<p><code><a href="#topic+bheq">bheq</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(goosefish)
bhnoneq(year=goosefish$year,mlen=goosefish$mlen, ss=goosefish$ss,
K=0.108,Linf=126,Lc=30,nbreaks=1,styrs=c(1982),stZ=c(0.1,0.3))
</code></pre>

<hr>
<h2 id='bonito'>Data from an age and growth study of the pacific bonito.</h2><span id='topic+bonito'></span>

<h3>Description</h3>

<p>Growth increment data derived from tagging experiments on Pacific bonito
(Sarda chiliensis) used to illustrate Francis's maximum likelihood
method estimation of growth and growth variability (1988).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bonito</code></pre>


<h3>Format</h3>

<p>A data frame with 138 observations on the following 4 variables.
</p>

<dl>
<dt><code>T1</code></dt><dd><p>a numeric vector describing the release date</p>
</dd>
<dt><code>T2</code></dt><dd><p>a numeric vector describing the recovery date</p>
</dd>
<dt><code>L1</code></dt><dd><p>a numeric vector describing the length at release
in cenitmeters</p>
</dd>
<dt><code>L2</code></dt><dd><p>a numeric vector describing the length at recapture
in centimeters</p>
</dd>
</dl>



<h3>Details</h3>

<p>Note that Francis (1988) has discarded several records from the original
dataset collected by Campbell et al. (1975).
</p>


<h3>Source</h3>

<dl>
<dt>1</dt><dd><p>Francis, R.I.C.C., 1988. Maximum likelihood estimation of growth and growth variability from tagging data. New Zealand Journal of Marine and Freshwater Research, 22, p.42&ndash;51.</p>
</dd>
<dt>2</dt><dd><p>Campbell, G. &amp; Collins, R., 1975. The age and growth of the Pacific bonito, Sarda chiliensis, in the eastern north Pacific. Calif. Dept. Fish Game, 61(4), p.181-200.</p>
</dd>
</dl>


<hr>
<h2 id='bt.log'>
Back-transformation of log-transformed mean and variance
</h2><span id='topic+bt.log'></span>

<h3>Description</h3>

<p>Converts a log-mean and log-variance to the original scale and calculates confidence intervals
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bt.log(meanlog = NULL, sdlog = NULL, n = NULL, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bt.log_+3A_meanlog">meanlog</code></td>
<td>
<p>sample mean of natural log-transformed values</p>
</td></tr>
<tr><td><code id="bt.log_+3A_sdlog">sdlog</code></td>
<td>
<p>sample standard deviation of natural log-transformed values</p>
</td></tr>
<tr><td><code id="bt.log_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="bt.log_+3A_alpha">alpha</code></td>
<td>
<p>alpha-level used to estimate confidence intervals</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are two methods of calcuating the bias-corrected mean on the original scale.
The <code>bt.mean</code> is calculated following equation 14 (the infinite series estimation)
in Finney (1941).  <code>approx.bt.mean</code> is calculated using the commonly known approximation
from Finney (1941): 
</p>
<p><em>mean=exp(meanlog+sdlog^2/2)</em>.  The variance is 
<em>var=exp(2*meanlog)*(Gn(2*sdlog^2)-Gn((n-2)/(n-1)*sdlog^2)</em> 
and standard deviation is <em>sqrt(var)</em>
where Gn is  the infinite series function (equation 10).  The variance and standard deviation of the  
back-transformed mean are <em>var.mean=var/n; sd.mean=sqrt(var.mean)</em>. 
The median is calculated as <em>exp(meanlog)</em>.
Confidence intervals for the back-transformed mean are from the Cox method (Zhou and Gao, 1997) modified
by substituting the z distribution with the t distribution as recommended by Olsson (2005):
</p>
<p><em>LCI=exp(meanlog+sdlog^2/2-t(df,1-alpha/2)*sqrt((sdlog^2/n)+(sdlog^4/(2*(n-1))))</em> and
</p>
<p><em>UCI=exp(meanlog+sdlog^2/2+t(df,1-alpha/2)*sqrt((sdlog^2/n)+(sdlog^4/(2*(n-1))))</em>
</p>
<p>where <em>df=n-1</em>.
</p>


<h3>Value</h3>

<p>A vector containing <code>bt.mean</code>, <code>approx.bt.mean</code>,<code>var</code>, <code>sd</code>, <code>var.mean</code>,<code>sd.mean</code>,
<code>median</code>, LCI (lower confidence interval), and UCI (upper confidence interval).
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a>
</p>


<h3>References</h3>

<p>Finney, D. J. 1941. On the distribution of a variate whose logarithm is normally distributed. Journal
of  the Royal Statistical Society Supplement 7: 155-161.
</p>
<p>Zhou, X-H., and Gao, S. 1997. Confidence intervals for the log-normal mean. Statistics in Medicine 
16:783-790. 
</p>
<p>Olsson, F. 2005. Confidence intervals for the mean of a log-normal distribution. Journal of Statistics 
Education 13(1). www.amstat.org/publications/jse/v13n1/olsson.html
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The example below shows accuracy of the back-transformation
y&lt;-rlnorm(100,meanlog=0.7,sdlog=0.2)
known&lt;-unlist(list(known.mean=mean(y),var=var(y),sd=sd(y),
  var.mean=var(y)/length(y),sd.mean=sqrt(var(y)/length(y))))
est&lt;-bt.log(meanlog=mean(log(y)),sdlog=sd(log(y)),n=length(y))[c(1,3,4,5,6)]
known;est</code></pre>

<hr>
<h2 id='buffalo'>Life Table Data for African Buffalo</h2><span id='topic+buffalo'></span>

<h3>Description</h3>

<p>The <code>buffalo</code> data frame has 20 rows and 3 columns.
Cohort size and deaths for African buffalo from Sinclair (1977) as reported by Krebs (1989) in
Table 12.1, page 415. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>buffalo
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>age</dt><dd><p>age interval</p>
</dd>
<dt>nx</dt><dd><p> number alive at start of each age interval</p>
</dd>
<dt>dx</dt><dd><p>number dying between age interval X and X+1</p>
</dd>
</dl>



<h3>Source</h3>

<p>Krebs, C. J. 1989. <em>Ecological Methodologies</em>. Harper and Row, New York, NY. 654 p.</p>

<hr>
<h2 id='catch'>Number of cod captured in 10 standardized bottom trawl hauls from Massachusetts, 1985</h2><span id='topic+catch'></span>

<h3>Description</h3>

<p>The <code>catch</code> data frame has 10 rows and 1 column.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>catch
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>value</dt><dd><p>catch data</p>
</dd>
</dl>



<h3>Source</h3>

<p>Massachusetts Division of Marine Fisheries</p>

<hr>
<h2 id='catch.select'>Selectivity Ogive from a Catch Curve</h2><span id='topic+catch.select'></span>

<h3>Description</h3>

<p>Estimates selectivity-at-length from catch lengths and von Bertalanffy growth parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>catch.select(len = NULL, lenmin = NULL, binsize = NULL, 
peakplus = 1, Linf = NULL, K = NULL, t0 = NULL, subobs = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="catch.select_+3A_len">len</code></td>
<td>
<p>vector of lengths. One row per individual.</p>
</td></tr>
<tr><td><code id="catch.select_+3A_lenmin">lenmin</code></td>
<td>
<p>the starting length from which to construct length intervals.</p>
</td></tr>
<tr><td><code id="catch.select_+3A_binsize">binsize</code></td>
<td>
<p>the length interval width.  Must be &gt;0. This is used to create the lower length of intervals starting from <code>lenmin</code> to the maximum observed in <code>len</code>. 
</p>
</td></tr>
<tr><td><code id="catch.select_+3A_peakplus">peakplus</code></td>
<td>
<p>numeric. Allows user to specify the number of length intervals following the length interval at the peak log(catch/deltat) to use as the start length interval in the catch curve analysis. Default = 1 based on standard catch curve analysis recommendations of Smith et al. (2012).
</p>
</td></tr>
<tr><td><code id="catch.select_+3A_linf">Linf</code></td>
<td>
<p>numeric. The L-infinity value from a von Bertalanffy growth equation. This is a required value.</p>
</td></tr>
<tr><td><code id="catch.select_+3A_k">K</code></td>
<td>
<p>numeric. The growth coefficient from a von Bertalanffy growth equation. This is a required value.</p>
</td></tr>
<tr><td><code id="catch.select_+3A_t0">t0</code></td>
<td>
<p>numeric. The t-subzero value from a von Bertalanffy growth equation. This is a required value.</p>
</td></tr>
<tr><td><code id="catch.select_+3A_subobs">subobs</code></td>
<td>
<p>logical. If the &quot;observed&quot; selectivity for those under-represented length intervals not used in the catch curve analysis is equal to 1, the inverse logit (used in fit of selectivity ogive) can not be calculated. If <code>subobs</code> is set to TRUE, 1 will be substituted with 0.9999</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function applies the method of Pauly (1984) for calculating the selectivity-at-length from catch lengths and parameters from a von Bertalanffy growth curve. See Sparre and Venema(1998) for a detailed example of the application.
</p>
<p>Length intervals are constructed based on the <code>lenmin</code> and <code>binsize</code> specified, and the maximum length observed in the data vector. Catch-at-length is tabularized using the lower and upper intervals and the data vector of lengths. The inclusion of a length in an interval is determined by lower interval&gt;=length&lt;upper interval. The age corresponding to the interval midpoint (<code>t</code>) is determined using the von Bertalanffy equation applied to the lower and upper bounds of each interval, summing the ages and dividing by 2. <code>deltat</code> is calculated for each interval using the equation: (1/k)*log((Linf-L1)/(Linf-L2)) where L1 and L2 are the lower and upper bounds of the length interval. <code>log(catch/deltat)</code> is the dependent variable and <code>t</code> is the predictor used in linear regression to estimate Z. Using the parameters from the catch curve analysis,  &quot;observed&quot; selectivities (<code>stobs</code>) for the length intervals not included in the catch curve analysis are calculated using the equation: stobs=catch/(deltat*exp(a-Z*t)) where a and Z are the intercept and slope from the linear regression. The <code>stobs</code> values are transformed using an inverse logit (log(1/stobs-1)) and are regressed against <code>t</code> to obtain parameter estimates for the selectivity ogive.  The estimated selectivity ogive (<code>stest</code>) is then calculated as
stest=1/(1+exp(T1-T2*t)) where T1 and T2 are the intercept and slope from the log(1/stobs-1) versus <code>t</code> regression.
</p>


<h3>Value</h3>

<p>list containing a dataframe with the lower and upper length intervals, the mid-point length interval, age corresponding to the interval mid-point, catch of the length interval, log(catch/deltat), the predicted log(catch/deltat) from the catch curve model fit (only for the peakplus interval and greater), the observed selectivities and the estimated selectivity, and two dataframes containing the parameters and their standard errors from the linear regressions for catch curve analysis and the selectivity ogive. 
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Pauly, D. 1984.  Length-converted catch curves. A powerful tool for fisheries research in the tropics (Part III). ICLARM Fishbyte 2(1): 17-19.
</p>
<p>Smith, M. W. and 5 others. 2012. Recommendations for catch-curve analysis. N. Am. J. Fish. Manage. 32: 956-967.
</p>
<p>Sparre, P. and S. C. Venema. 1998. Introduction to tropical fish stock assessment. Part 1. Manual. FAO Fisheries Technical Paper, No. 206.1, Rev. 2. Rome. 407 p. Available on the world-wide web.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sblen)
catch.select(len=sblen$len_inches,binsize=2,lenmin=10,peakplus=1,Linf=47.5,K=0.15, 
t0=-0.3)
</code></pre>

<hr>
<h2 id='catchmsy'>Estimating MSY from catch and resilience
</h2><span id='topic+catchmsy'></span>

<h3>Description</h3>

<p>This function estimates MSY following Martell and Froese(2012).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>catchmsy(year = NULL, catch = NULL, catchCV = NULL, 
catargs = list(dist = "none", low = 0, up = Inf, unit = "MT"), 
l0 = list(low = 0, up = 1, step = 0), lt = list(low = 0, up = 1, 
refyr = NULL), 
sigv = 0, k = list(dist = "unif", low = 0, up = 1, mean = 0, sd = 0), 
r = list(dist = "unif", low = 0, up = 1, mean = 0, sd = 0), 
M = list(dist = "unif", low = 0.2, up = 0.2, mean = 0, sd = 0), 
nsims = 10000, catchout = 0, grout = 1, 
graphs = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), 
grargs = list(lwd = 1, pch = 16, cex = 1, nclasses = 20, mains = " ", 
cex.main = 1, 
cex.axis = 1, cex.lab = 1), 
pstats = list(ol = 1, mlty = 1, mlwd = 1.5, llty = 3, llwd = 1, ulty = 3, 
ulwd = 1), 
grtif = list(zoom = 4, width = 11, height = 13, pointsize = 10))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="catchmsy_+3A_year">year</code></td>
<td>
<p>vector containing the time series of numeric year labels.</p>
</td></tr>
<tr><td><code id="catchmsy_+3A_catch">catch</code></td>
<td>
<p>vector containing the time series of catch data (in weight). Missing values are not
allowed.</p>
</td></tr>
<tr><td><code id="catchmsy_+3A_catchcv">catchCV</code></td>
<td>
<p>vector containing the time series of coefficients of variation associated with catch 
if resampling of catch is desired; otherwise, catchCV = NULL. </p>
</td></tr>
<tr><td><code id="catchmsy_+3A_catargs">catargs</code></td>
<td>
<p>list arguments associated with resampling of catch. <code>dist</code> is the specification 
of the resampling distribution to use (&quot;none&quot; = no resampling, &quot;unif&quot;=uniform, &quot;norm&quot; = normal, 
and &quot;lnorm&quot; =log-normal). If &quot;lnorm&quot; is selected, catch is log transformed and standard deviation
on the log scale is calculated from the specified CVs using the relationship sdlog=sqrt(log(CV^2+1)). 
<code>low</code> and <code>up</code> are the lower and upper limit of distribution (if truncation is desired). 
<code>unit</code> is the weight unit of catch (used in graph labels; default=&quot;MT&quot;). If &quot;unif&quot;, the
<code>catch</code> must be incorporated in <code>low</code> and <code>up</code> arguments.  For instance, if the 
lower limit to sample is the value of <code>catch</code>, specify <code>low</code>=catch. If some maximum 
above catch will be the upper limit, specify <code>up</code>=50*catch.  The limits for each year will 
be applied to catch internally. 
</p>
</td></tr>
<tr><td><code id="catchmsy_+3A_l0">l0</code></td>
<td>
<p>list arguments for the relative biomass in year 1. <code>low</code> and <code>up</code> are the lower 
and upper bounds of the starting value of relative biomass (in relation to k) in year 1. <code>step</code> 
is the step increment to examine.  If <code>step</code>=0, then <code>l0</code> is randomly selected from a
uniform distribution using the lower and upper starting values. If <code>step</code>&gt;0, then step increments
are used (in this case, the number of simulations (<code>nsims</code>) are used for each increment). 
</p>
</td></tr>
<tr><td><code id="catchmsy_+3A_lt">lt</code></td>
<td>
<p>list arguments for the depletion level in the selected reference year (<code>refyr</code>). 
<code>low</code> and <code>up</code> are the lower and upper bounds of depletion level in <code>refyr</code>. 
<code>refyr</code> can range from the first year to the year after the last year of catch (t+1). 
</p>
</td></tr>
<tr><td><code id="catchmsy_+3A_sigv">sigv</code></td>
<td>
<p>standard deviation of the log-normal random process error.  <code>signv</code> = 0 for no 
process error.
</p>
</td></tr>
<tr><td><code id="catchmsy_+3A_k">k</code></td>
<td>
<p>list arguments for the carrying capacity. <code>dist</code> is the statistical distribution name
from which to sample <code>k</code>. <code>low</code> and <code>up</code> are the lower and upper bounds of <code>k</code> 
in the selected distribution. 
<code>mean</code> and <code>sd</code> are the mean and standard deviation for selected distributions. The 
following are valid distributions: &quot;none&quot;, &quot;unif&quot; - uniform, &quot;norm&quot; - normal, &quot;lnorm&quot; - log-normal, 
&quot;gamma&quot; - gamma, and &quot;beta&quot; - beta distributions. &quot;unif&quot; requires non-missing values for <code>low</code> 
and <code>up</code>. &quot;norm&quot;, &quot;lnorm&quot;, &quot;gamma&quot; and &quot;beta&quot;, require non-missing values for 
<code>low</code>,<code>up</code>, <code>mean</code> and <code>sd</code>. If &quot;lnorm&quot; is used, <code>mean</code> and <code>sd</code> 
must be on the natural log scale (keep <code>low</code> and <code>up</code> on the original scale). If 
<code>dist</code> = &quot;none&quot;, the mean is used as a fixed value.
</p>
</td></tr>
<tr><td><code id="catchmsy_+3A_r">r</code></td>
<td>
<p>list arguments for the intrinsic growth rate. <code>dist</code> is the statistical distribution name 
from which to sample <code>r</code>. <code>low</code> and <code>up</code> are the lower and upper bounds of <code>r</code> 
in the selected distribution. <code>mean</code> and <code>sd</code> are the mean and standard deviation for 
selected distributions. Valid distributions are the same as in <code>k</code>. If <code>dist</code> = &quot;none&quot;, 
the mean is used as a fixed value.
</p>
</td></tr>
<tr><td><code id="catchmsy_+3A_m">M</code></td>
<td>
<p>list arguments for natural mortality. <code>dist</code> is the statistical distribution name from 
which to sample <code>M</code>. <code>low</code> and <code>up</code> are the lower and upper bounds of <code>M</code> in the 
selected distribution. <code>mean</code> and <code>sd</code> are the mean and standard deviation for selected 
distributions. Valid distributions are the same as in <code>k</code>. M is used to determine exploitation 
rate (Umsy) at MSY. If <code>dist</code> = &quot;none&quot;, the mean is used as a fixed value.
</p>
</td></tr>
<tr><td><code id="catchmsy_+3A_nsims">nsims</code></td>
<td>
<p>number of Monte Carlos samples.</p>
</td></tr> 
<tr><td><code id="catchmsy_+3A_catchout">catchout</code></td>
<td>
<p>If resampling <code>catch</code>, save catch trajectories from each Monte Carlos simulation 
- 0 = No (default), 1 = Yes.</p>
</td></tr> 
<tr><td><code id="catchmsy_+3A_grout">grout</code></td>
<td>
<p>numeric argument specifying whether graphs should be printed to console only (1) or to 
both the console and TIF graph files (2).Use <code>setwd</code> before running function to direct .tif files
to a specific directory. Each name of each file is automatically determined.</p>
</td></tr> 
<tr><td><code id="catchmsy_+3A_graphs">graphs</code></td>
<td>
<p>vector specifying which graphs should be produced. 1 = line plot of observed catch versus
year,2 = point plot of plausible <code>k</code> versus <code>r</code> values, 3 = histogram of plausible r values, 
4 = histogram of plausible k values,  5 = histogram of M values,
6 = histogram of MSY from plausible values of l0,k,r, and Bmsy/k, 7 = histogram of Bmsy from plausible 
values of l0,k,r, and Bmsy/k, 8 = histogram of Fmsy from plausible values of l0,k,r, and Bmsy/k, 9 = 
histogram of Umsy values from Fmsy and M, 10 = histogram of overfishing limit (OFL) in last year+1 values 
from Umsys, and 11 = line plots of accepted and rejected biomass trajectores with median and 2.5th and 97.5th
percentiles (in red).  Any combinations of graphs can be selected within c().  Default is all.
</p>
</td></tr>
<tr><td><code id="catchmsy_+3A_grargs">grargs</code></td>
<td>
<p>list control arguments for plotting functions. <code>lwd</code> is the line width for graph = 1 and 11, 
<code>pch</code> and <code>cex</code> are the symbol character and character expansion value used in graph = 2, 
<code>nclasses</code> is the nclass argument for the histogram plots (graphs 3-11), <code>mains</code> and 
<code>cex.main</code> are the titles and character expansion values for the graphs, <code>cex.axis</code> is the 
character expansion value(s) for the x and y-axis tick labels and <code>cex.lab</code> is the character 
expansion value(s) for the x and y-axis labels.  Single values of <code>nclasses</code>,<code>mains</code>, 
<code>cex.main</code>,<code>cex.axis</code>, <code>cex.lab</code> are applied to all graphs.  To change arguments for 
specific graphs, enclose arguments within c() in order of the number specified in <code>graphs</code>. 
</p>
</td></tr>
<tr><td><code id="catchmsy_+3A_pstats">pstats</code></td>
<td>
<p>list control arguments for plotting the mean and 95
and management quantities on respective graphs. <code>ol</code> = 0, do not overlay values on plots, 1 = 
overlay values on plots. <code>mlty</code> and <code>mlwd</code> are the line type and line width of the mean value;
<code>llty</code> and <code>llwd</code> are the line type and line wdith of the 2.5
<code>ulwd</code> are the line type and line width of the 97.5
</p>
</td></tr>
<tr><td><code id="catchmsy_+3A_grtif">grtif</code></td>
<td>
<p>list arguments for the .TIF graph files. See <code>tiff</code> help file in R.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The method of Martell and Froese (2012) is used to produce estimates of MSY where only catch and 
information on resilience is known. 
</p>
<p>The Schaefer production model is 
</p>
<p>B[t+1]&lt;-B[t]+r*B[t]*(1-B[t]/k)-catch[t]
</p>
<p>where B is biomass in year t, <code>r</code> is the instrince rate of increase, <code>k</code> is the carrying 
capacity and <code>catch</code> is the catch in year t. Biomass is the first year is calculated by 
B[1]=<code>k</code>*<code>l0</code>. For sigv&gt;0, the production equation is multiplied by exp(rnorm(1,0,sigv)) 
if process error is desired. 
The maximum sustainable yield (MSY) is calculated as
</p>
<p>MSY=r*k/4
</p>
<p>Biomass at MSY is calculated as
</p>
<p>Bmsy=k/2
</p>
<p>Fishing mortality at MSY is calculated as 
</p>
<p>Fmsy=r/2
</p>
<p>Exploitation rate at MSY is calculated as
</p>
<p>Umsy=(Fmsy/(Fmsy+M))*(1-exp(-Fmsy-M))
</p>
<p>The overfishing limit in last year+1  is calculated as
</p>
<p>OFL=B[last year +1]*Umsy
</p>
<p><code>length(year)+1</code> biomass estimates are made for each run.
</p>
<p>If using the R Gui (not Rstudio), run 
</p>
<p>graphics.off()
windows(width=10, height=12,record=TRUE)
.SavedPlots &lt;- NULL
</p>
<p>before running the catchmsy function to recall plots.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Initial</code></td>
<td>
<p>dataframe containing the initial values for each explored parameter.</p>
</td></tr>
<tr><td><code>Parameters</code></td>
<td>
<p>dataframe containing the mean, median, 2.5th and 97.5
plausible (likelihood=1) parameters. </p>
</td></tr>  
<tr><td><code>Estimates</code></td>
<td>
<p>dataframe containing the mean, median, 2.5th and 97.5
of the management quantities (i.e., MSY, Bmsy, etc.) for the plausible parameters 
(likelihood=1)</p>
</td></tr>
<tr><td><code>Values</code></td>
<td>
<p>dataframe containing the values of l0, k, r, Bmsy/k, M and associated management 
quantities for all (likelihood=0 and likelihood=1) random draws.</p>
</td></tr>
<tr><td><code>end1yr</code></td>
<td>
<p>value of the last year of catch data + 1 for use in function <code>dlproj</code>.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>designates the output object as a <code>catchmsy</code> object for use in function <code>dlproj</code>.</p>
</td></tr>  
</table>
<p>The biomass estimates from each simulation are not stored in memory but are automatically 
saved to a .csv file named &quot;Biotraj-cmsy.csv&quot;. Yearly values for each simulation are stored across 
columns.  The first column holds the likelihood values for each simulation (1= accepted, 0 = rejected).  
The number of rows equals the number of simulations (<code>nsims</code>). This file is loaded to plot
graph 11 and it must be present in the default or <code>setwd()</code> directory.  
</p>
<p>When <code>catchout</code>=1,   catch values randomly selected are saved to a .csv file named &quot;Catchtraj-cmsy.csv&quot;. 
Yearly values for each simulation are stored across columns.  The first column holds the likelihood 
values (1= accepted, 0 = rejected).  The number of rows equals the number of simulations (<code>nsims</code>).   
</p>
<p>Use <code>setwd()</code> before running the function to change the directory where .csv files are stored.  
</p>


<h3>Note</h3>

<p>The random distribution function was adapted from Nadarajah, S and S. Kotz. 2006. 
R programs for computing truncated distributions. Journal of Statistical Software 16, 
code snippet 2.
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a>
</p>


<h3>References</h3>

<p>Martell, S. and R. Froese. 2012. A simple method for estimating MSY from catch and resilience.
Fish and Fisheries 14:504-514.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dbsra">dbsra</a></code> <code><a href="#topic+dlproj">dlproj</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## Not run: 
   data(lingcod)
   outpt&lt;-catchmsy(year=lingcod$year,
     catch=lingcod$catch,catchCV=NULL,
     catargs=list(dist="none",low=0,up=Inf,unit="MT"),
    l0=list(low=0.8,up=0.8,step=0),
    lt=list(low=0.01,up=0.25,refyr=2002),sigv=0,
    k=list(dist="unif",low=4333,up=433300,mean=0,sd=0),
    r=list(dist="unif",low=0.015,up=0.1,mean=0,sd=0),
    M=list(dist="unif",low=0.18,up=0.18,mean=0.00,sd=0.00),
    nsims=30000)
 
## End(Not run)
</code></pre>

<hr>
<h2 id='catchsurvey'>Catch-Survey Analysis</h2><span id='topic+catchsurvey'></span>

<h3>Description</h3>

<p>This function applies the catch-survey analysis method of Collie and Kruse (1998) for estimating abundance
from catch and survey indices of relative abundance 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>catchsurvey(year = NULL, catch = NULL, recr = NULL, post = NULL, M = NULL,
 T = NULL, phi = NULL, w = 1, initial = c(NA,NA,NA),uprn = NA, graph = TRUE)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="catchsurvey_+3A_year">year</code></td>
<td>
<p>vector containing the time series of numeric year labels.</p>
</td></tr>
<tr><td><code id="catchsurvey_+3A_catch">catch</code></td>
<td>
<p>vector containing the time series of catch (landings) data.</p>
</td></tr>
<tr><td><code id="catchsurvey_+3A_recr">recr</code></td>
<td>
<p>vector containing the time series of survey indices for recruit individuals.</p>
</td></tr>
<tr><td><code id="catchsurvey_+3A_post">post</code></td>
<td>
<p>vector containing the time series of survey indices for post-recruit individuals.</p>
</td></tr>
<tr><td><code id="catchsurvey_+3A_m">M</code></td>
<td>
<p>instantaneous natural mortality rate. Assumed constant throughout time series</p>
</td></tr>
<tr><td><code id="catchsurvey_+3A_t">T</code></td>
<td>
<p>proportion of year between survey and fishery.</p>
</td></tr>
<tr><td><code id="catchsurvey_+3A_phi">phi</code></td>
<td>
<p>relative recruit catchability.</p>
</td></tr>
<tr><td><code id="catchsurvey_+3A_w">w</code></td>
<td>
<p>recruit sum of squares weight.</p>
</td></tr>
<tr><td><code id="catchsurvey_+3A_initial">initial</code></td>
<td>
<p>initial recruit estimate,initial postrecruit estimate in year 1, and
initial catchability estimate.</p>
</td></tr>
<tr><td><code id="catchsurvey_+3A_uprn">uprn</code></td>
<td>
<p>the upper bound for the recruit and postrecruit estimates.</p>
</td></tr>
<tr><td><code id="catchsurvey_+3A_graph">graph</code></td>
<td>
<p>logical indicating whether observed versus predicted recruit and post-recruit indices,
total abundance and fishing mortality should be plotted. Default=TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Details of the model are given in Collie and Kruse (1998).    
</p>


<h3>Value</h3>

<p>List containing the estimate of catchability, predicted recruit index by year (rest), estimate 
of recruit abundance (R), predicted post-recruit index by year (nest), post-recruit abundance (N), 
total abundance (TA: R+N), total instantaneous mortality (Z), and fishing mortality (Fmort)</p>


<h3>Author(s)</h3>

<p> Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Collie JS and GH Kruse 1998. Estimating king crab (Paralithodes camtschaticus) abundance from
commercial catch and research survey data. In: Jamieson GS, Campbell A, eds. Proceedings of the North Pacific
Symposium on Invertebrate Stock Assessment and Management. Can Spec Publ Fish Aquat Sci. 125; p 73-83.
</p>
<p>See also Collie JS and MP Sissenwine. 1983. Estimating population size from relative abundance data
measured with error. Can J Fish Aquat Sci. 40:1871-1879.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Example takes a bit of time to run
  ## Not run: 
   data(nshrimp)
   catchsurvey(year=nshrimp$year,catch=nshrimp$C,recr=nshrimp$r,post=nshrimp$n,M=0.25,
   T=0.5,phi=0.9,w=1,initial=c(500,500,0.7),uprn=10000)
## End(Not run)
   </code></pre>

<hr>
<h2 id='clus.lf'>Statistical Comparison of Length Frequencies from Simple Random Cluster Sampling</h2><span id='topic+clus.lf'></span>

<h3>Description</h3>

<p>Statistical comparison of length frequencies is performed using the two-sample
Kolmogorov &amp; Smirnov test. Randomization procedures are used to derive the null probability
distribution. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clus.lf(group = NULL, haul = NULL, len = NULL, number= NULL,
 binsize = NULL, resamples = 100)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clus.lf_+3A_group">group</code></td>
<td>
<p> vector containing the identifier used for group membership of length data.  This variable is
used to determine the number of groups and comparisons.  Identifier can be numeric or character.</p>
</td></tr>
<tr><td><code id="clus.lf_+3A_haul">haul</code></td>
<td>
<p>vector containing the variable used to identify the sampling unit (e.g., haul) of length data. Identifier can be numeric or character.</p>
</td></tr>
<tr><td><code id="clus.lf_+3A_len">len</code></td>
<td>
<p>vector containing the length class data. There should be one record for each length class by group and haul. </p>
</td></tr>
<tr><td><code id="clus.lf_+3A_number">number</code></td>
<td>
<p>vector containing the numbers of fish in each length class.</p>
</td></tr>
<tr><td><code id="clus.lf_+3A_binsize">binsize</code></td>
<td>
<p>size of the length class (e.g., 5-cm, 10, cm, etc.) used to construct the cumulative length frequency
from raw length data.  The formula used to create bins is <code class="reqn">trunc(len/binsize)*binsize+binsize/2</code>. 
If use of the raw length classes is desired, then <code>binsize=0</code>.</p>
</td></tr>
<tr><td><code id="clus.lf_+3A_resamples">resamples</code></td>
<td>
<p>number of randomizations. Default = 100.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Length frequency distributions of fishes are commonly tested for differences among groups (e.g., regions, sexes, etc.) using a two-sample Kolmogov-Smirnov test (K-S).  Like most statistical
tests, the K-S test requires that observations are collected at random and are independent of each other to satisfy assumptions. These basic assumptions are
violated when gears (e.g., trawls, haul seines, gillnets, etc.) are used to sample fish because individuals are collected in clusters .  In this case, the &quot;haul&quot;, not the individual fish, is the
primary sampling unit and statistical comparisons must take this into account.  
</p>
<p>To test for difference between length frequency distributions from simple random cluster sampling, a randomization test that uses &quot;hauls&quot; as 
the primary sampling unit can be used to generate the null probability distribution.  In a randomization test, an observed test statistic is compared to an empirical 
probability density distribution of a test statistic under the null hypothesis of no difference.  The observed test statistic
used here is the Kolmogorov-Smirnov statistic (Ds) under a two-tailed test:
</p>
<p style="text-align: center;"><code class="reqn">Ds= max|S1(X)-S2(X)|</code>
</p>

<p>where S1(X) and S2(X) are the observed cumulative length frequency distributions of group 1 and group 2 in the paired comparisons. 
S1(X) and S2(X) are calculated such that <code>S(X)=K/n</code> where K is the number of scores equal to or less
than X and n is the total number of length observations (Seigel, 1956).  
</p>
<p>To generate the empirical probability density function (pdf), haul data are randomly assigned without replacement to the two groups with samples sizes equal to the original number of hauls in each group under comparison.
The K-S statistic is calculated from the cumulative length frequency distributions of the two groups 
of randomized data.  The randomization procedure is repeated <code>resamples</code> times to 
obtain the pdf of D.  To estimate the significance of Ds, the proportion of all randomized D values
that were greater than or equal to Ds is calculated.
</p>
<p>It is assumed all fish caught are measured. If subsampling occurs, the number at length (measured) must be expanded to the total caught.
</p>
<p>Data vectors described in <code>arguments</code> should be aggregated so that each record contains the number of fish in each length class by group and haul identifier. For example,
</p>

<table>
<tr>
 <td style="text-align: right;">
<code>group</code> </td><td style="text-align: right;"> <code>tow</code> </td><td style="text-align: right;"> <code>length</code> </td><td style="text-align: right;"> <code>number</code> </td>
</tr>
<tr>
 <td style="text-align: right;">
North	</td><td style="text-align: right;"> 1 </td><td style="text-align: right;"> 10 </td><td style="text-align: right;"> 2 </td>
</tr>
<tr>
 <td style="text-align: right;">
North	</td><td style="text-align: right;"> 1 </td><td style="text-align: right;"> 12 </td><td style="text-align: right;"> 5 </td>
</tr>
<tr>
 <td style="text-align: right;">
North	</td><td style="text-align: right;"> 2 </td><td style="text-align: right;"> 11 </td><td style="text-align: right;"> 3 </td>
</tr>
<tr>
 <td style="text-align: right;">
North	</td><td style="text-align: right;"> 1 </td><td style="text-align: right;"> 10 </td><td style="text-align: right;"> 17 </td>
</tr>
<tr>
 <td style="text-align: right;">
North	</td><td style="text-align: right;"> 2 </td><td style="text-align: right;"> 14 </td><td style="text-align: right;"> 21 </td>
</tr>
<tr>
 <td style="text-align: right;">
.     </td><td style="text-align: right;"> . </td><td style="text-align: right;"> .  </td><td style="text-align: right;"> . </td>
</tr>
<tr>
 <td style="text-align: right;">
.     </td><td style="text-align: right;"> . </td><td style="text-align: right;"> .  </td><td style="text-align: right;"> . </td>
</tr>
<tr>
 <td style="text-align: right;">
South	</td><td style="text-align: right;"> 1 </td><td style="text-align: right;"> 12 </td><td style="text-align: right;"> 34 </td>
</tr>
<tr>
 <td style="text-align: right;">
South	</td><td style="text-align: right;"> 1 </td><td style="text-align: right;"> 14 </td><td style="text-align: right;"> 3
</td>
</tr>

</table>



<h3>Value</h3>

<table role = "presentation">
<tr><td><code>results</code></td>
<td>
<p>list element containing the Ds statistics from the observed data comparisons and significance probabilities.</p>
</td></tr>
<tr><td><code>obs_prop</code></td>
<td>
<p>list element containing the observed cumulative proportions for each group.</p>
</td></tr>
<tr><td><code>Drandom</code></td>
<td>
<p>list element containing the D statistics from randomization for each comparison.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p> Manly, B. F. J. 1997.  Randomization, Bootstrap and Monte Carlos Methods in Biology.
Chapman and Hall, New York, NY, 399 pp.
</p>
<p>Seigel, S. 1956. Nonparametric Statistics for Behavioral Sciences. McGraw-Hill, New York, NY. 312 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clus.str.lf">clus.str.lf</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(codcluslen)
clus.lf(group=codcluslen$region,haul=c(paste("ST-",codcluslen$tow,sep="")),
 len=codcluslen$length, number=codcluslen$number, 
 binsize=5,resamples=100)
</code></pre>

<hr>
<h2 id='clus.mean'>Estimation of Population Attributes and Effective Sample Size 
for Fishes Collected Via Cluster Sampling</h2><span id='topic+clus.mean'></span>

<h3>Description</h3>

<p>Calculates mean attribute, variance, effective sample size, and degrees of freedom for samples collected 
by simple random cluster sampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clus.mean(popchar = NULL, cluster = NULL, clustotal = NULL, rho = NULL,
 nboot = 1000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clus.mean_+3A_popchar">popchar</code></td>
<td>
<p>vector of population characteristic measurements (e.g., length, weight, etc.). 
One row represents the measurement for an individual. </p>
</td></tr>
<tr><td><code id="clus.mean_+3A_cluster">cluster</code></td>
<td>
<p>vector of numeric or character codes identifying individual clusters (or hauls).</p>
</td></tr>
<tr><td><code id="clus.mean_+3A_clustotal">clustotal</code></td>
<td>
<p>vector of total number of fish caught per cluster.</p>
</td></tr>
<tr><td><code id="clus.mean_+3A_rho">rho</code></td>
<td>
<p>intracluster correlation coefficient for data. If NULL, degrees of freedom are not calculated.</p>
</td></tr>
<tr><td><code id="clus.mean_+3A_nboot">nboot</code></td>
<td>
<p>number of bootstrap samples for calculation of bootstrap variance. Default = 1000</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In fisheries, gears (e.g., trawls, haul seines, gillnets, etc.) are used to collect fishes. Often, estimates of mean population attributes (e.g., mean length) are desired.
The samples of individual fish are not random samples, but cluster samples because the &quot;haul&quot; is the primary sampling unit.  Correct estimation of mean attributes requires 
the use of cluster sampling formulae.  Estimation of the general mean attribute and usual variance approximation follows Pennington et al. (2002). 
Variance of the mean is also estimated using the jackknife and bootstrap methods (Pennington and Volstad, 1994; Pennington et al., 2002).
In addition, the effective sample size (the number of fish that would need to be sampled randomly to obtained the same precision 
as the mean estimate from cluster sampling) is also calculated for the three variance estimates.  The total number of fish caught in a cluster 
(<code>clustotal</code>) allows correct computation for one- and two-stage sampling of individuals from each cluster (haul).
In addition, if rho is specified, degrees of freedom are calculated by using Hedges (2007) for unequal cluster sizes (p. 166-167). 
</p>


<h3>Value</h3>

<p>Matrix table of total number of clusters (n), total number of samples (M), total number of samples
measured (m), the mean attribute (R), usual variance approximation (varU), jackknife variance (varJ), bootstrap variance (varB),
variance of population attribute (s2x), usual variance effective sample size (meffU), jackknife variance effective sample size,
(meffJ), bootstrap variance effective sample size (meffB) and degrees of freedom (df) if applicable. 
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Hedges,L.V. 2007. Correcting a significance test for clustering. Journal of Educational and Behavioral 
Statistics. 32: 151-179.
</p>
<p>Pennington, M. and J. J. Volstad. 1994. Assessing the effect of intra-haul correlation and variable density 
on estimates of population characteristics from marine surveys.  Biometrics 50: 725-732.
</p>
<p>Pennington, M. , L. Burmeister, and V. Hjellvik. 2002. Assessing the precision of frequency distributions estimated 
from trawl-survey samples. Fish. Bull. 100:74-80.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(codcluslen)
temp&lt;-codcluslen[codcluslen$region=="NorthCape" &amp; codcluslen$number&gt;0,]
temp$station&lt;-c(paste(temp$region,"-",temp$tow,sep=""))
total&lt;-aggregate(temp$number,list(temp$station),sum)
names(total)&lt;-c("station","total")
temp&lt;-merge(temp,total,by.x="station",by.y="station")
newdata&lt;-data.frame(NULL)
for(i in 1:as.numeric(length(temp[,1]))){
  for(j in 1:temp$number[i]){
    newdata&lt;-rbind(newdata,temp[i,])
  }
}
clus.mean(popchar=newdata$length,cluster=newdata$station,
         clustotal=newdata$total)
</code></pre>

<hr>
<h2 id='clus.rho'>Intracluster Correlation Coefficients for Clustered Data
</h2><span id='topic+clus.rho'></span>

<h3>Description</h3>

<p>Calculates the intracluster correlation coefficients according to 
Lohr (1999) and Donner (1986) for a single group
</p>


<h3>Usage</h3>

<pre><code class='language-R'> clus.rho(popchar=NULL, cluster = NULL, type = c(1,2,3), est = 0, nboot = 500)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clus.rho_+3A_popchar">popchar</code></td>
<td>
<p>vector containing containing the population characteristic (e.g., length, weight, etc.). 
One line per individual.</p>
</td></tr>
<tr><td><code id="clus.rho_+3A_cluster">cluster</code></td>
<td>
<p>vector containing the variable used to identify the cluster. Identifier can be numeric or character.</p>
</td></tr>
<tr><td><code id="clus.rho_+3A_type">type</code></td>
<td>
<p>method of intracluster correlation calculation. 1 = Equation 5.8 of Lohr (1999),
2 = Equation 5.10 in Lohr (1999) and 3 = ANOVA.  Default = c(1,2,3).</p>
</td></tr>
<tr><td><code id="clus.rho_+3A_est">est</code></td>
<td>
<p>estimate variance and percentiles of intracluster correlation coefficients via boostrapping.
0 = No estimation (Default), 1 = Estimate.</p>
</td></tr>
<tr><td><code id="clus.rho_+3A_nboot">nboot</code></td>
<td>
<p>number of boostrap replicates for estimation of variance. nboot = 500 (Default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The intracluster correlation coefficient (rho) provides a measure of similarity within clusters.
<em>type</em> = 1  is defined to be the Pearson correlation coefficient for NM(M-1)pairs (yij,yik) for i 
between 1 and N and j&lt;&gt;k (see Lohr (1999: p. 139). The average cluster size is used as the equal cluster 
size quantity in Equation 5.8 of Lohr (1999). If the clusters are perfectly homogeneous (total variation is all 
between-cluster variability), then ICC=1.
</p>
<p><em>type</em> = 2 is the adjusted r-square, an alternative quantity following Equation 5.10 in Lohr (1999). It is the
relative amount of variability in the population explained by the cluster means, adjusted for the number 
of degrees of freedom. If the clusters are homogeneous, then the cluster means are highly variable relative 
to variation within clusters, and the r-square will be high.  
</p>
<p><em>type</em> = 3 is calculated using one-way random effects models (Donner, 1986).
The formula is
</p>
<p>rho = (BMS-WMS)/(BMS+(m-1)*WMS)
</p>
<p>where BMS is the mean square between clusters, WMS is the mean square within clusters and m is the
adjusted mean cluster size for clusters with unequal sample size. All clusters with zero elementary 
units should be deleted before calculation. <em>type</em> = 3 can be used with binary data 
(Ridout et al. 1999)
</p>
<p>If <em>est</em>=1, the boostrap mean (value), variance of the mean and 0.025 and 0.975 percentiles are outputted. 
</p>


<h3>Value</h3>

<p>rho values, associated statistics, and bootstrap replicates</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p> Donner, A. 1986. A review of inference procedures for the intraclass correlation coefficient
in the one-way random effects model. International Statistical Review. 54: 67-82.
</p>
<p>Lohr, S. L. Sampling: design and analysis. Duxbury Press,New York, NY. 494 p.
</p>
<p>Ridout, M. S., C. G. B. Demetrio, and D. Firth. 1999. Estimating intraclass correlation for
binary data. Biometrics 55: 137-148.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clus.lf">clus.lf</a> <a href="#topic+clus.str.lf">clus.str.lf</a> <a href="#topic+clus.mean">clus.mean</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(codcluslen)
  tem&lt;-codcluslen[codcluslen[,1]=="NorthCape" &amp; codcluslen[,3]&gt;0,]
  outs&lt;-data.frame(tow=NA,len=NA)
  cnt&lt;-0
  for(i in 1:as.numeric(length(tem$number))){
    for(j in 1:tem$number[i]){
     cnt&lt;-cnt+1
     outs[cnt,1]&lt;-tem$tow[i]
     outs[cnt,2]&lt;-tem$length[i]
   }
 }
 clus.rho(popchar=outs$len,cluster=outs$tow)</code></pre>

<hr>
<h2 id='clus.rho.g'>Calculate A Common Intracluster Correlation Coefficient Among Groups
</h2><span id='topic+clus.rho.g'></span>

<h3>Description</h3>

<p>Calculates a common intracluster correlation coefficients according to 
Donner (1986: 77-79) for two or more groups with unequal cluster sizes, and tests for 
homogeneity of residual error among groups and a common coefficient among groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> clus.rho.g(popchar=NULL, cluster = NULL, group = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clus.rho.g_+3A_popchar">popchar</code></td>
<td>
<p>vector containing containing the population characteristic (e.g., length, weight, etc.). 
One line per individual.</p>
</td></tr>
<tr><td><code id="clus.rho.g_+3A_cluster">cluster</code></td>
<td>
<p>vector containing the variable used to identify the cluster. Identifier can be numeric or character.</p>
</td></tr>
<tr><td><code id="clus.rho.g_+3A_group">group</code></td>
<td>
<p>vector containing the identifier used for group membership of length data.  This variable is
used to determine the number of groups.  Identifier can be numeric or character.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The intracluster correlation coefficient (rho) provides a measure of similarity within clusters.
rho is calculated using a one-way nested random effects model (Donner, 1986: 77-79).
The formula is
</p>
<p>rho = (BMS-WMS)/(BMS+(m-1)*WMS)
</p>
<p>where BMS is the mean square among clusters within groups, WMS is the mean square within clusters and m 
is the adjusted mean cluster size for clusters with unequal sample sizes. All clusters with zero 
elementary units should be deleted before calculation. In addition, approximate 95
are generated and a significance test is performed.
</p>
<p>Bartlett's test is used to determine if mean square errors are constant among groups. If Bartlett's test is
not significant, the test for a common correlation coefficient among groups is valid. 
</p>


<h3>Value</h3>

<p>rho value and associate statistics</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Donner, A. 1986. A review of inference procedures for the intraclass correlation coefficient
in the one-way random effects model. International Statistical Review. 54: 67-82.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clus.str.lf">clus.str.lf</a> <a href="#topic+clus.lf">clus.lf</a> <a href="#topic+clus.mean">clus.mean</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(codcluslen)
   temp&lt;-codcluslen[codcluslen$number&gt;0,]
   temp$station&lt;-c(paste(temp$region,"-",temp$tow,sep=""))
   total&lt;-aggregate(temp$number,list(temp$station),sum)
   names(total)&lt;-c("station","total")
   temp&lt;-merge(temp,total,by.x="station",by.y="station")
   newdata&lt;-data.frame(NULL)
   for(i in 1:as.numeric(length(temp[,1]))){
    for(j in 1:temp$number[i]){
     newdata&lt;-rbind(newdata,temp[i,])
    }
  }
  newdata&lt;-newdata[,-c(5)]
 clus.rho.g(popchar=newdata$length,cluster=newdata$station,group=newdata$region)
</code></pre>

<hr>
<h2 id='clus.str.lf'>Statistical Comparison of Length Frequencies from Stratified Random Cluster Sampling</h2><span id='topic+clus.str.lf'></span>

<h3>Description</h3>

<p>Statistical comparison of length frequencies is performed using the two-sample
Kolmogorov &amp; Smirnov test. Randomization procedures are used to derive the null probability
distribution. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clus.str.lf(group = NULL, strata = NULL, weights = NULL,
 haul = NULL, len = NULL, number = NULL, binsize = NULL,
 resamples = 100)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clus.str.lf_+3A_group">group</code></td>
<td>
<p> vector containing the identifier used for group membership of length data.  This variable is
used to determine the number of groups and comparisons.  Identifier can be numeric or character.</p>
</td></tr>
<tr><td><code id="clus.str.lf_+3A_strata">strata</code></td>
<td>
<p>vector containing the numeric identifier used for strata membership of length data.  
There must be a unique identifier for each stratum regardless of group membership.</p>
</td></tr>
<tr><td><code id="clus.str.lf_+3A_weights">weights</code></td>
<td>
<p>vector containing the strata weights (e.g., area, size, etc.) used to calculate the stratified mean length for a group.  
</p>
</td></tr>
<tr><td><code id="clus.str.lf_+3A_haul">haul</code></td>
<td>
<p>vector containing the variable used to identify the sampling unit (e.g., haul) of length data. Identifier can be numeric or character.</p>
</td></tr>
<tr><td><code id="clus.str.lf_+3A_len">len</code></td>
<td>
<p>vector containing the length class. Each length class record must have associated group, strata, weights, and haul identifiers. </p>
</td></tr>
<tr><td><code id="clus.str.lf_+3A_number">number</code></td>
<td>
<p>vector containing the number of fish in each length class.</p>
</td></tr>
<tr><td><code id="clus.str.lf_+3A_binsize">binsize</code></td>
<td>
<p>size of the length class (e.g., 5-cm, 10, cm, etc.) used to construct the cumulative length frequency
from raw length data.  The formula used to create bins is 
<code class="reqn">trunc(len/binsize)*binsize+binsize/2</code>. If use of the raw length classes is desired, then <code>binsize=0</code>.</p>
</td></tr>
<tr><td><code id="clus.str.lf_+3A_resamples">resamples</code></td>
<td>
<p>number of randomizations. Default = 100.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Length frequency distributions of fishes are commonly tested for differences among groups (e.g., regions, sexes, etc.) using a two-sample Kolmogov-Smirnov test (K-S).  Like most statistical
tests, the K-S test requires that observations are collected at random and are independent of each other to satisfy assumptions. These basic assumptions are
violated when gears (e.g., trawls, haul seines, gillnets, etc.) are used to sample fish because individuals are collected in clusters .  In this case, the &quot;haul&quot;, not the individual fish, is the
primary sampling unit and statistical comparisons must take this into account.  
</p>
<p>To test for difference between length frequency distributions from stratified random cluster sampling, a randomization test that uses &quot;hauls&quot; as 
the primary sampling unit can be used to generate the null probability distribution.  In a randomization test, an observed test statistic is compared to an empirical 
probability density distribution of a test statistic under the null hypothesis of no difference.  The observed test statistic
used here is the Kolmogorov-Smirnov statistic (Ds) under a two-tailed test:
</p>
<p style="text-align: center;"><code class="reqn">Ds= max|S1(X)-S2(X)|</code>
</p>

<p>where S1(X) and S2(X) are the observed cumulative proportions at length for group 1 and group 2 in the paired comparisons.
</p>
<p>Proportion of fish of length class j in strata-set (group variable) used to derive <code>Ds</code> is calculated as
</p>
<p style="text-align: center;"><code class="reqn">p_j=\frac{\sum{A_k\bar{X}}_{jk}}{\sum{A_k\bar{X}}_k}</code>
</p>

<p>where <code class="reqn">A_k</code> is the weight of stratum k, <code class="reqn">\bar{X}_{jk}</code> is the mean number per haul of length class <code>j</code> in stratum <code>k</code>, and
<code class="reqn">\bar{X}_k</code>  is the mean number per haul in stratum <code>k</code>. The numerator and denominator are summed over all <code>k</code>. Before calculation of
cumulative proportions, the length class distributions for each group are corrected for missing lengths and are
constructed so that the range and intervals of each distribution match. 
</p>
<p>It is assumed all fish caught are measured. If subsampling occurs, the numbers at length (measured) must be expanded to the total caught.
</p>
<p>To generate the empirical probability density function (pdf), length data of hauls from all strata are pooled and then hauls are randomly assigned without replacement
to each stratum with haul sizes equal to the original number of stratum hauls.  Cumulative proportions are
then calculated as described above. The K-S statistic is calculated from the cumulative length frequency distributions of the two groups 
of randomized data.  The randomization procedure is repeated <code>resamples</code> times to 
obtain the pdf of D.  To estimate the significance of Ds, the proportion of all randomized D values
that were greater than or equal to Ds is calculated (Manly, 1997).
</p>
<p>Data vectors described in <code>arguments</code> should be aggregated so that each record contains the number of fish in each length class by group, strata, weights, and haul identifier. For example,
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>group</code> </td><td style="text-align: right;"> <code>stratum</code> </td><td style="text-align: right;"> <code>weights</code> </td><td style="text-align: right;"> <code>tow</code> </td><td style="text-align: right;"> <code>length</code> </td><td style="text-align: right;"> <code>number</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
North	</td><td style="text-align: right;"> 10 </td><td style="text-align: right;"> 88 </td><td style="text-align: right;"> 1 </td><td style="text-align: right;"> 10 </td><td style="text-align: right;"> 2 </td>
</tr>
<tr>
 <td style="text-align: left;">
North	</td><td style="text-align: right;"> 10 </td><td style="text-align: right;"> 88 </td><td style="text-align: right;"> 1 </td><td style="text-align: right;"> 12 </td><td style="text-align: right;"> 5 </td>
</tr>
<tr>
 <td style="text-align: left;">
North	</td><td style="text-align: right;"> 10 </td><td style="text-align: right;"> 88 </td><td style="text-align: right;"> 2 </td><td style="text-align: right;"> 11 </td><td style="text-align: right;"> 3 </td>
</tr>
<tr>
 <td style="text-align: left;">
North	</td><td style="text-align: right;"> 11 </td><td style="text-align: right;"> 103 </td><td style="text-align: right;"> 1 </td><td style="text-align: right;"> 10 </td><td style="text-align: right;"> 17 </td>
</tr>
<tr>
 <td style="text-align: left;">
North	</td><td style="text-align: right;"> 11 </td><td style="text-align: right;"> 103 </td><td style="text-align: right;"> 2 </td><td style="text-align: right;"> 14 </td><td style="text-align: right;"> 21 </td>
</tr>
<tr>
 <td style="text-align: left;">
.      </td><td style="text-align: right;"> . </td><td style="text-align: right;"> .  </td><td style="text-align: right;"> . </td><td style="text-align: right;"> .  </td><td style="text-align: right;"> . </td>
</tr>
<tr>
 <td style="text-align: left;">
.      </td><td style="text-align: right;"> . </td><td style="text-align: right;"> .  </td><td style="text-align: right;"> . </td><td style="text-align: right;"> .  </td><td style="text-align: right;"> . </td>
</tr>
<tr>
 <td style="text-align: left;">
South	</td><td style="text-align: right;"> 31 </td><td style="text-align: right;"> 43 </td><td style="text-align: right;"> 1 </td><td style="text-align: right;"> 12 </td><td style="text-align: right;"> 34 </td>
</tr>
<tr>
 <td style="text-align: left;">
South	</td><td style="text-align: right;"> 31 </td><td style="text-align: right;"> 43 </td><td style="text-align: right;"> 1 </td><td style="text-align: right;"> 14 </td><td style="text-align: right;"> 3
</td>
</tr>

</table>

<p>To correctly calculate the stratified mean number per haul, zero tows must be included in the dataset. 
To designate records for zero tows, fill the length class and number at length with zeros.  The first line in
the following table shows the appropriate coding for zero tows:
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>group</code> </td><td style="text-align: right;"> <code>stratum</code> </td><td style="text-align: right;"> <code>weights</code> </td><td style="text-align: right;"> <code>tow</code> </td><td style="text-align: right;"> <code>length</code> </td><td style="text-align: right;"> <code>number</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
North	</td><td style="text-align: right;"> 10 </td><td style="text-align: right;"> 88 </td><td style="text-align: right;"> 1 </td><td style="text-align: right;"> 0 </td><td style="text-align: right;"> 0 </td>
</tr>
<tr>
 <td style="text-align: left;">
North	</td><td style="text-align: right;"> 10 </td><td style="text-align: right;"> 88 </td><td style="text-align: right;"> 2 </td><td style="text-align: right;"> 11 </td><td style="text-align: right;"> 3 </td>
</tr>
<tr>
 <td style="text-align: left;">
North	</td><td style="text-align: right;"> 11 </td><td style="text-align: right;"> 103 </td><td style="text-align: right;"> 1 </td><td style="text-align: right;"> 10 </td><td style="text-align: right;"> 17 </td>
</tr>
<tr>
 <td style="text-align: left;">
North	</td><td style="text-align: right;"> 11 </td><td style="text-align: right;"> 103 </td><td style="text-align: right;"> 2 </td><td style="text-align: right;"> 14 </td><td style="text-align: right;"> 21 </td>
</tr>
<tr>
 <td style="text-align: left;">
.      </td><td style="text-align: right;"> . </td><td style="text-align: right;"> .  </td><td style="text-align: right;"> . </td><td style="text-align: right;"> .  </td><td style="text-align: right;"> . </td>
</tr>
<tr>
 <td style="text-align: left;">
.      </td><td style="text-align: right;"> . </td><td style="text-align: right;"> .  </td><td style="text-align: right;"> . </td><td style="text-align: right;"> .  </td><td style="text-align: right;"> . </td>
</tr>
<tr>
 <td style="text-align: left;">
South	</td><td style="text-align: right;"> 31 </td><td style="text-align: right;"> 43 </td><td style="text-align: right;"> 1 </td><td style="text-align: right;"> 12 </td><td style="text-align: right;"> 34 </td>
</tr>
<tr>
 <td style="text-align: left;">
South	</td><td style="text-align: right;"> 31 </td><td style="text-align: right;"> 43 </td><td style="text-align: right;"> 1 </td><td style="text-align: right;"> 14 </td><td style="text-align: right;"> 3
</td>
</tr>

</table>



<h3>Value</h3>

<table role = "presentation">
<tr><td><code>results</code></td>
<td>
<p>list element containing the Ds statistics from the observed data comparisons and significance probabilities.</p>
</td></tr>
<tr><td><code>obs_prop</code></td>
<td>
<p>list element containing the cumulative proportions from each group.</p>
</td></tr> 
<tr><td><code>Drandom</code></td>
<td>
<p>list element containing the D statistics from randomization for each comparison.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p> Manly, B. F. J. 1997.  Randomization, Bootstrap and Monte Carlos Methods in Biology.
Chapman and Hall, New York, NY, 399 pp.
</p>
<p>Seigel, S. 1956. Nonparametric Statistics for Behavioral Sciences. McGraw-Hill, New York, NY. 312 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clus.lf">clus.lf</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(codstrcluslen)
clus.str.lf(
group=codstrcluslen$region,strata=codstrcluslen$stratum,
 weights=codstrcluslen$weights,haul=codstrcluslen$tow,
 len=codstrcluslen$length,number=codstrcluslen$number,
 binsize=5,resamples=100)
</code></pre>

<hr>
<h2 id='clus.t.test'>Correcting a Two-Sample Test for Clustering</h2><span id='topic+clus.t.test'></span>

<h3>Description</h3>

<p>Calculates Hedges (2007) t-statistic adjustment and degrees of freedom 
for a t-test assuming unequal variances and clustered data with clusters 
of unequal size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clus.t.test(popchar = NULL, cluster = NULL, group = NULL,
      rho = NULL, alpha = 0.05, alternative = c("two.sided"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clus.t.test_+3A_popchar">popchar</code></td>
<td>
<p>vector of population characteristic measurements (e.g., length, weight, etc.). 
One row represents the measurement for an individual.</p>
</td></tr>
<tr><td><code id="clus.t.test_+3A_cluster">cluster</code></td>
<td>
<p>vector of numeric or character codes identifying individual clusters (or hauls).</p>
</td></tr>
<tr><td><code id="clus.t.test_+3A_group">group</code></td>
<td>
<p>vector of group membership identifiers.</p>
</td></tr>
<tr><td><code id="clus.t.test_+3A_rho">rho</code></td>
<td>
<p>common intra-cluster correlation for groups.</p>
</td></tr>
<tr><td><code id="clus.t.test_+3A_alpha">alpha</code></td>
<td>
<p>alpha level used to calculate t critical value. Default=0.05</p>
</td></tr>
<tr><td><code id="clus.t.test_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis, must be 
one of &quot;two.sided&quot; (default), &quot;greater&quot; or &quot;less&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A two-sample t-test with unequal variances (Sokal and Rohlf, 1995) is performed on clustered data. 
The t-statistic and degrees of freedom are corrected for clustering according to 
Hedges (2007). 
</p>


<h3>Value</h3>

<p>List with null hypothesis of test and matrix table with mean of each group, rho, 
ntilda (Equation 14 of Hedges 2007), nu (Equation 15), degrees of freedom (Equation 16), 
uncorrected t-statistic, cu (Equation 18), the t-statistic adjusted for clustering, critical t value for 
degrees of freedom and alpha, and probability of significance.
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Sokal,R.R.and F.J.Rohlf. 1995. Biometry, 3rd Edition. W.H. Freeman and Company, New York, 
NY. 887 p.
</p>
<p>Hedges,L.V. 2007. Correcting a significance test for clustering. Journal of Educational and Behavioral 
Statistics. 32: 151-179.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>   data(codcluslen)
   temp&lt;-codcluslen[codcluslen$number&gt;0,]
   temp$station&lt;-c(paste(temp$region,"-",temp$tow,sep=""))
   total&lt;-aggregate(temp$number,list(temp$station),sum)
   names(total)&lt;-c("station","total")
   temp&lt;-merge(temp,total,by.x="station",by.y="station")
   newdata&lt;-data.frame(NULL)
   for(i in 1:as.numeric(length(temp[,1]))){
    for(j in 1:temp$number[i]){
     newdata&lt;-rbind(newdata,temp[i,])
    }
  }
 newdata&lt;-newdata[,-c(5)]
 clus.t.test(popchar=newdata$length,cluster=newdata$station,
            group=newdata$region,rho=0.72,
            alpha=0.05,alternative="two.sided") 
</code></pre>

<hr>
<h2 id='clus.vb.fit'>
Fit a Von Bertalanffy growth equation to clustered data via bootstrapping </h2><span id='topic+clus.vb.fit'></span>

<h3>Description</h3>

<p>Fits the von Bertalanffy growth equation to clustered length and age  
by using nonlinear least-squares and by bootstrapping clusters</p>


<h3>Usage</h3>

<pre><code class='language-R'>clus.vb.fit(len = NULL, age = NULL, cluster = NULL, nboot = 1000,
sumtype = 1, control = list(maxiter=10000, minFactor=1/1024,tol=1e-5))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clus.vb.fit_+3A_len">len</code></td>
<td>
<p>vector of lengths of individual fish</p>
</td></tr>
<tr><td><code id="clus.vb.fit_+3A_age">age</code></td>
<td>
<p>vector of ages of individual fish</p>
</td></tr>
<tr><td><code id="clus.vb.fit_+3A_cluster">cluster</code></td>
<td>
<p>haul or cluster membership identifier</p>
</td></tr>
<tr><td><code id="clus.vb.fit_+3A_nboot">nboot</code></td>
<td>
<p>number of bootstrap samples</p>
</td></tr>
<tr><td><code id="clus.vb.fit_+3A_sumtype">sumtype</code></td>
<td>
<p>use 1 = mean or 2 = median of bootstrap runs as the parameter and correlation coefficients values.
Default is 1.</p>
</td></tr>
<tr><td><code id="clus.vb.fit_+3A_control">control</code></td>
<td>
<p>see <code>control</code> under function <em>nls</em>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A standard von Bertalanffy growth curve is fitted to length-at-age data of each  <em>nboot</em> sample of clusters
using nonlinear least-squares (function <em>nls</em>).  Standard errors are calculated using function <code>sd</code> applied
to bootstrap parameters.</p>


<h3>Value</h3>

<p>List containing a summary of successful model fits and parameter estimates, standard errors and 
95 percent confidence intervals, and the average correlation matrix.
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## Not run: 
	data(pinfish)
	with(pinfish,clus.vb.fit(len=sl,age=age,cluster=field_no,nboot=100))
  
## End(Not run)
</code></pre>

<hr>
<h2 id='codcluslen'>Lengths of Atlantic cod caught during Massachusetts Division of Marine Fisheries bottom trawl survey, spring 1985.</h2><span id='topic+codcluslen'></span>

<h3>Description</h3>

<p>The <code>codcluslen</code> data frame has 334 rows and 4 columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>codcluslen
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>region</dt><dd><p>NorthCape = North of Cape Cod; SouthCape =South of Cape Cod</p>
</dd>
<dt>tow</dt><dd><p>Tow number</p>
</dd>
<dt>length</dt><dd><p>Length class (total length, cm)</p>
</dd> 
<dt>number</dt><dd><p>Number in length class</p>
</dd> 
</dl>



<h3>Source</h3>

<p>Massachusetts Division of Marine Fisheries</p>

<hr>
<h2 id='codstrcluslen'>Lengths of Atlantic cod caught during Massachusetts Division of Marine Fisheries stratified random bottom trawl survey, spring 1985.</h2><span id='topic+codstrcluslen'></span>

<h3>Description</h3>

<p>The <code>codstrcluslen</code> data frame has 334 rows and 6 columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>codstrcluslen
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>region</dt><dd><p>NorthCape = North of Cape Cod; SouthCape = South of Cape Cod</p>
</dd>
<dt>stratum</dt><dd><p>Stratum number</p>
</dd>
<dt>tow</dt><dd><p>Tow number</p>
</dd>
<dt>weights</dt><dd><p>Stratum area (square nautical-miles)</p>
</dd>
<dt>length</dt><dd><p>Length class (total length cm)</p>
</dd> 
<dt>number</dt><dd><p>Number in length class</p>
</dd>
</dl>



<h3>Source</h3>

<p>Massachusetts Division of Marine Fisheries, 30 Emerson Avenue, Gloucester, MA 01930
</p>

<hr>
<h2 id='combinevar'>Combining Mean and Variances from Multiple Samples</h2><span id='topic+combinevar'></span>

<h3>Description</h3>

<p>This function takes multiple mean and sample variance estimates and combines them. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>combinevar(xbar = NULL, s_squared = NULL, n = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="combinevar_+3A_xbar">xbar</code></td>
<td>
<p>vector of means</p>
</td></tr>
<tr><td><code id="combinevar_+3A_s_squared">s_squared</code></td>
<td>
<p>vector of sample variances</p>
</td></tr>
<tr><td><code id="combinevar_+3A_n">n</code></td>
<td>
<p>vector of number of observations</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If a Monte Carlo simulation is run over 1000 loops and then again over another 1000 loops, one may wish to update 
the mean and variance from the first 1000 loops with the second set of simulation results.
</p>


<h3>Value</h3>

<p>Vector containing the combined mean and sample variance.
</p>


<h3>Author(s)</h3>

<p>John M. Hoenig, Virginia Institute of Marine Science <a href="mailto:hoenig@vims.edu">hoenig@vims.edu</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>xbar &lt;- c(5,5)
s&lt;-c(2,4)
n &lt;- c(10,10)
combinevar(xbar,s,n)
</code></pre>

<hr>
<h2 id='compare.lrt.plus'>Comparison of growthlrt.plus model objects</h2><span id='topic+compare.lrt.plus'></span>

<h3>Description</h3>

<p>Compute likelihood ratio tests for two or more growthlrt.plus model objects via Kimura (1990)</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare.lrt.plus(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compare.lrt.plus_+3A_...">...</code></td>
<td>
<p>growthlrt.plus object names separated by commas</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Likelihood ratio and F tests are computed for models compared against one another in the order specified.
</p>


<h3>Value</h3>

<p>List containing model test statistics 
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

 
<p>Kimura, D. K. 1990. Testing nonlinear reression parameters under heteroscedastic, normally distributed errors.
Biometrics 46: 697-708.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+growthlrt.plus">growthlrt.plus</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## This is a typical specification, not a working example
## Not run: 
compare.lrt.plus(model1,model2)
## End(Not run)
</code></pre>

<hr>
<h2 id='compare2'>Comparisons of two age readers or two aging methods</h2><span id='topic+compare2'></span>

<h3>Description</h3>

<p>Function compares graphically the readings of two age readers and calculates 2 chi-square statistics for 
tests of symmetry.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> compare2(readings, usecols = c(1,2), twovsone = TRUE, plot.summary = TRUE, 
  barplot = TRUE, chi = TRUE, pool.criterion = 1, cont.cor = TRUE, 
  correct = "Yates", first.name = "Reader A",second.name = "Reader B")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compare2_+3A_readings">readings</code></td>
<td>
<p>dataframe or matrix containing the readings by Reader 1 and those by Reader 2.</p>
</td></tr>
<tr><td><code id="compare2_+3A_usecols">usecols</code></td>
<td>
<p>columns of the dataframe or matrix corresponding to the readings of Reader 1 and those of Reader 2.
Default=c(1,2).</p>
</td></tr>
<tr><td><code id="compare2_+3A_twovsone">twovsone</code></td>
<td>
<p>logical for whether first type of graph is produced.</p>
</td></tr>
<tr><td><code id="compare2_+3A_plot.summary">plot.summary</code></td>
<td>
<p>logical for whether summary table is put on first graph.</p>
</td></tr>
<tr><td><code id="compare2_+3A_barplot">barplot</code></td>
<td>
<p>logical for whether barplot of frequency of disagreements is drawn.</p>
</td></tr>
<tr><td><code id="compare2_+3A_chi">chi</code></td>
<td>
<p>logical for whether 2 chi-square tests are performed.</p>
</td></tr>
<tr><td><code id="compare2_+3A_pool.criterion">pool.criterion</code></td>
<td>
<p>used to collapse pairs where the expected number of observations is &lt; pooling
criterion (default is 1).</p>
</td></tr>
<tr><td><code id="compare2_+3A_cont.cor">cont.cor</code></td>
<td>
<p>logical for whether a continuity correction should be used in 1st chisquare test.</p>
</td></tr>
<tr><td><code id="compare2_+3A_correct">correct</code></td>
<td>
<p>character for whether &quot;Yates&quot; or &quot;Edwards&quot; continuity correction should be done (if cont.cor=TRUE).</p>
</td></tr>
<tr><td><code id="compare2_+3A_first.name">first.name</code></td>
<td>
<p>character string describing the first reader or the first aging method. The
default is to specify &quot;Reader A&quot;.</p>
</td></tr>
<tr><td><code id="compare2_+3A_second.name">second.name</code></td>
<td>
<p>character string describing the second reader or the second aging method. The
default is to specify &quot;Reader B&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function can plot the number of readings of age j by reader 2 versus the number of readings of age i by 
reader 1 (if twovsone=TRUE). Optionally, it will add the number of readings above, on, and below the 45 degree 
line (if plot.summary=TRUE). The function can make a histogram of the differences in readings (if barplot=TRUE). 
Finally, the program can calculate 2 chi-square test statistics for tests of the null hypothesis that the two 
readers are interchangeable vs the alternative that there are systematic differences between readers (if chi=TRUE).
The tests are tests of symmetry (Evans and Hoenig, 1998). If cont.cor=T, then correction for continuity is 
applied to the McNemar-like chi-square test statistic; the default is to apply the Yates correction but if 
correct=&quot;Edwards&quot; is specified then the correction for continuity is 1.0 instead of 0.5. 
</p>


<h3>Value</h3>

<p>Separate lists with tables of various statistics associated with the method.  
</p>


<h3>Author(s)</h3>

<p>John Hoenig, Virginia Institute of Marine Science, 18 December 2012. <a href="mailto:hoenig@vims.edu">hoenig@vims.edu</a></p>


<h3>References</h3>

<p>Evans, G.T. and J.M. Hoenig.  1998. Viewing and Testing Symmetry in Contingency Tables, with 
Application to Fish Ages. Biometrics 54:620-629.). 
</p>


<h3>Examples</h3>

<pre><code class='language-R'> data(sbotos)
 compare2(readings=sbotos,usecols=c(1,2),twovsone=TRUE,plot.summary=TRUE,
 barplot=FALSE,chi=TRUE,pool.criterion=1,cont.cor=TRUE,correct="Yates",
 first.name="Reader A",second.name="Reader B")
</code></pre>

<hr>
<h2 id='convmort'>Conversion of Mortality Rates</h2><span id='topic+convmort'></span>

<h3>Description</h3>

<p>Convert instantaneous fishing mortality rate (F) to annual exploitation rate (mu) and vice versa for
Type I and II fisheries.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convmort(value = NULL, fromto = 1, type = 2, M = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="convmort_+3A_value">value</code></td>
<td>
<p>mortality rate</p>
</td></tr>
<tr><td><code id="convmort_+3A_fromto">fromto</code></td>
<td>
<p>conversion direction: 1=from F to mu; 2 = from mu to F.  Default is 1.</p>
</td></tr>
<tr><td><code id="convmort_+3A_type">type</code></td>
<td>
<p>type of fishery following Ricker (1975): 1=Type I; 2=Type II. Default is 2.</p>
</td></tr>
<tr><td><code id="convmort_+3A_m">M</code></td>
<td>
<p>natural mortality rate (for Type II fishery)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Equations 1.6 and 1.11 of Ricker (1975) are used.
</p>


<h3>Value</h3>

<p>A vector of the same length as <code>value</code> containing the converted values.
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Ricker, W. E. 1975. Computation and interpretation of biological statistics of fish populations.
Bull. Fish. Res. Board. Can. 191: 382 p.</p>


<h3>Examples</h3>

<pre><code class='language-R'>convmort(0.3,fromto=1,type=2,M=0.15)
</code></pre>

<hr>
<h2 id='counts'>Run size data for alewife (<em>Alosa pseudoharengus</em>)</h2><span id='topic+counts'></span>

<h3>Description</h3>

<p>The <code>counts</code> data frame has 31 rows and 2 columns.
Run size data of alewife (<em>Alosa pseudoharengus</em>) in Herring River, MA from 1980-2010
</p>


<h3>Usage</h3>

<pre><code class='language-R'>counts
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>year</dt><dd><p>vector of run year</p>
</dd>
<dt>number</dt><dd><p>vector of run counts in number of fish</p>
</dd>
</dl>



<h3>Source</h3>

<p>Massachusetts Division of Marine Fisheries, 30 Emerson Avenue, Gloucester, MA
</p>

<hr>
<h2 id='cowcod'>Catch data (metric tons) for cowcod Sebastes levis 1900 to 2008</h2><span id='topic+cowcod'></span>

<h3>Description</h3>

<p>Cowcod catch data from literature sources in Martell and Froese (2012).  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cowcod</code></pre>


<h3>Format</h3>

<p>A data frame with 109 observations on the following 2 variables.
</p>

<dl>
<dt><code>year</code></dt><dd><p>a numeric vector describing the year of catch</p>
</dd>
<dt><code>catch</code></dt><dd><p>a numeric vector describing the annual catch in metric tons</p>
</dd>
</dl>


<hr>
<h2 id='cpuekapp'>
Trawl survey based abundance estimation using data sets with unusually large catches
</h2><span id='topic+cpuekapp'></span>

<h3>Description</h3>

<p>Calculates the mean cpue after replacing unusually large catches with
expected values using the method of Kappenman (1999) 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cpuekapp(x = NULL, nlarge = NULL, absdif = 0.001)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cpuekapp_+3A_x">x</code></td>
<td>
<p>vector of non-zero trawl catch data.
</p>
</td></tr>
<tr><td><code id="cpuekapp_+3A_nlarge">nlarge</code></td>
<td>
<p>the number of values considered unusually large.
</p>
</td></tr>
<tr><td><code id="cpuekapp_+3A_absdif">absdif</code></td>
<td>
<p>convergence tolerance</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Use function <code>gap</code> to choose the number of unusually large values.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>kappmean</code></td>
<td>
<p>list element containing new arithmetic mean.</p>
</td></tr>
<tr><td><code>expectations</code></td>
<td>
<p>list element containing the original observation(s)
and expected order statistic(s).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a>
</p>


<h3>References</h3>

<p>Kappenman, R. F. 1999. Trawl survey based abundance estimation using data sets with 
unusually large catches. ICES Journal of Marine Science. 56: 28-35.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gap">gap</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Not run: 
  ## Data from Table 1 in Kappenman (1999)
  data(kappenman)
  cpuekapp(kappenman$cpue,1)
 
## End(Not run)
</code></pre>

<hr>
<h2 id='darter'>Catch Removal Data For Fantail Darter</h2><span id='topic+darter'></span>

<h3>Description</h3>

<p>The <code>darter</code> data frame has 7 rows and 2 columns.
Sequence of catch data for the faintail darter from removal experiments by Mahon as reported by
White et al.(1982).  This dataset is often use to test new depletion estimators because the actual abundance is known (N=1151).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>darter
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>catch</dt><dd><p>catch data</p>
</dd>
<dt>effort</dt><dd><p>constant effort data</p>
</dd>
</dl>



<h3>Source</h3>

<p>White, G. C., D. R. Anderson, K. P. Burnham, and D. L. Otis. 1982. <em>Capture-recapture and Removal Methods for Sampling
Closed Populations</em>. Los Alamos National Laboratory LA-8787-NERP. 235 p.
</p>

<hr>
<h2 id='dbsra'>Depletion-Based Stock Reduction Analysis 
</h2><span id='topic+dbsra'></span>

<h3>Description</h3>

<p>This function estimates MSY from catch following Dick and MAcCall (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbsra(year = NULL, catch = NULL, catchCV = NULL, 
catargs = list(dist = "none", low = 0, up = Inf, unit = "MT"), 
agemat = NULL, maxn=25, k = list(low = 0, up = NULL, tol = 0.01, permax = 1000), 
b1k = list(dist = "unif", low = 0, up = 1, mean = 0, sd = 0),
btk = list(dist = "unif", low = 0, up = 1, mean = 0, sd = 0, refyr = NULL), 
fmsym = list(dist = "unif", low = 0, up = 1, mean = 0, sd = 0), 
bmsyk = list(dist = "unif", low = 0, up = 1, mean = 0, sd = 0), 
M = list(dist = "unif", low = 0, up = 1, mean = 0, sd = 0), nsims = 10000, 
catchout = 0, grout = 1, 
graphs = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15), 
grargs = list(lwd = 1, cex = 1, nclasses = 20, mains = " ", cex.main = 1, 
cex.axis = 1, 
cex.lab = 1), pstats = list(ol = 1, mlty = 1, mlwd = 1.5, llty = 3, llwd = 1, 
ulty = 3, ulwd = 1), 
grtif = list(zoom = 4, width = 11, height = 13, pointsize = 10))</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dbsra_+3A_year">year</code></td>
<td>
<p>vector containing the time series of numeric year labels.</p>
</td></tr>
<tr><td><code id="dbsra_+3A_catch">catch</code></td>
<td>
<p>vector containing the time series of catch data (in weight). Missing values are not
allowed.</p>
</td></tr>
<tr><td><code id="dbsra_+3A_catchcv">catchCV</code></td>
<td>
<p>vector containing the time series of coefficients of variation associated with catch 
if resampling of catch is desired; otherwise, catchCV = NULL. </p>
</td></tr>
<tr><td><code id="dbsra_+3A_catargs">catargs</code></td>
<td>
<p>list arguments associated with resampling of catch. <code>dist</code> is the specification 
of the resampling distribution to use (&quot;none&quot; = no resampling, &quot;unif&quot;=uniform, &quot;norm&quot; = normal, 
and &quot;lnorm&quot; =log-normal). If &quot;lnorm&quot; is selected, catch is log transformed and standard deviation
on the log scale is calculated from the specificed CVs using the relationship sdlog=sqrt(log(CV^2+1)). 
<code>low</code> and <code>up</code> are the lower and upper limit of distribution (if truncation is desired). 
<code>unit</code> is the weight unit of catch (used in graph labels; default=&quot;MT&quot;). If &quot;unif&quot;, the
<code>catch</code> must be incorporated in <code>low</code> and <code>up</code> arguments.  For instance, if the 
lower limit to sample is the value of <code>catch</code>, specify <code>low</code>=catch. If some maximum 
above catch will be the upper limit, specify <code>up</code>=50*catch.  The limits for each year will 
be applied to catch internally. 
</p>
</td></tr>
<tr><td><code id="dbsra_+3A_agemat">agemat</code></td>
<td>
<p>median age at entry to the reproductive biomass.</p>
</td></tr>
<tr><td><code id="dbsra_+3A_maxn">maxn</code></td>
<td>
<p>the maximum limit of the Pella-Tomlinson shape parameter that should not be 
exceeded in the rule for accepting a run.</p>
</td></tr>  
<tr><td><code id="dbsra_+3A_k">k</code></td>
<td>
<p>list arguments for estimation of  <code>k</code> (carrying capacity). <code>low</code> and <code>up</code> are 
the lower and upper bounds of the minimization routine and <code>tol</code> is the tolerance level 
for minimization. A simple equation <code>((btk)-(b[refyr]/k))^2</code> is used as
the objective function. R function <code>optimize</code> is used to find <code>k</code>. <code>btk</code> is described 
below. <code>permax</code> is the absolute percent difference between the maximum biomass estimate
and <code>k</code> that should not be exceeded in the rule for accepting a run (see <code>details</code>). 
</p>
</td></tr>
<tr><td><code id="dbsra_+3A_b1k">b1k</code></td>
<td>
<p>list arguments for B1/K, the relative depletive level in the first year. 
<code>dist</code> is the statistical distribution name from which to sample <code>b1k</code>. 
<code>low</code> and <code>up</code> are the lower and upper bounds of <code>b1k</code> 
in the selected distribution.  <code>mean</code> and <code>sd</code> are the mean and standard deviation 
for selected distributions. The following are valid distributions: &quot;none&quot;, &quot;unif&quot; - uniform, 
&quot;norm&quot; - normal, &quot;lnorm&quot; - log-normal, &quot;gamma&quot; - gamma, and &quot;beta&quot; - beta distributions. 
&quot;unif&quot; requires non-missing values for <code>low</code> and <code>up</code>. &quot;norm&quot;, &quot;lnorm&quot;, 
&quot;gamma&quot; and &quot;beta&quot; require non-missing values for <code>low</code>,<code>up</code>, <code>mean</code> and 
<code>sd</code>. If &quot;lnorm&quot; is used, <code>mean</code> and <code>sd</code> must be on the natural log scale
(keep <code>low</code> and <code>up</code> on the original scale). If <code>dist</code>= &quot;none&quot;, the mean is used as
a fixed constant.</p>
</td></tr>
<tr><td><code id="dbsra_+3A_btk">btk</code></td>
<td>
<p>list arguments for Bt/K, the relative depletive level in a specific reference year (<code>refyr</code>). 
<code>dist</code> is the statistical distribution name from which to sample <code>btk</code>. 
<code>low</code> and <code>up</code> are the lower and upper bounds of <code>btk</code> 
in the selected distribution.  <code>mean</code> and <code>sd</code> are the mean and standard deviation 
for selected distributions. The following are valid distributions: &quot;none&quot;, &quot;unif&quot; - uniform, 
&quot;norm&quot; - normal, &quot;lnorm&quot; - log-normal, &quot;gamma&quot; - gamma, and &quot;beta&quot; - beta distributions. 
&quot;unif&quot; requires non-missing values for <code>low</code> and <code>up</code>. &quot;norm&quot;, &quot;lnorm&quot;, 
&quot;gamma&quot; and &quot;beta&quot; require non-missing values for <code>low</code>,<code>up</code>, <code>mean</code> and 
<code>sd</code>. If &quot;lnorm&quot; is used, <code>mean</code> and <code>sd</code> must be on the natural log scale
(keep <code>low</code> and <code>up</code> on the original scale). If <code>dist</code>= &quot;none&quot;, the mean is used as
a fixed constant. <code>refyr</code> is the selected terminal year  and can range from the first year 
to the year after the last year of catch (t+1). 
</p>
</td></tr>
<tr><td><code id="dbsra_+3A_fmsym">fmsym</code></td>
<td>
<p>list arguments for Fmsy/M. <code>dist</code> is the statistical distribution name from which 
to sample <code>Fmsy/M</code>. <code>low</code> and <code>up</code> are the lower and upper bounds of <code>Fmsy/M</code> in
the selected distribution. <code>mean</code> and <code>sd</code> are the mean and standard deviation for selected 
distributions. Valid distributions are the same as in <code>btk</code>. If <code>dist</code>= &quot;none&quot;, the mean is used as
a fixed constant. 
</p>
</td></tr>
<tr><td><code id="dbsra_+3A_bmsyk">bmsyk</code></td>
<td>
<p>list arguments for Bmsy/k. <code>dist</code> is the statistical distribution name from which 
to sample <code>Bmsy/k</code>. <code>low</code> and <code>up</code> are the lower and upper bounds of <code>Bmsy/k</code> in
the selected distribution. <code>mean</code> and <code>sd</code> are the mean and standard deviation for selected 
distributions. Valid distributions are the same as in <code>btk</code>. If <code>dist</code>= &quot;none&quot;, the mean is used as
a fixed constant. 
</p>
</td></tr>
<tr><td><code id="dbsra_+3A_m">M</code></td>
<td>
<p>list arguments for natural mortality. <code>dist</code> is the statistical distribution name from 
which to sample <code>M</code>. <code>low</code> and <code>up</code> are the lower and upper bounds of <code>M</code> in the 
selected distribution. <code>mean</code> and <code>sd</code> are the mean and standard deviation for selected 
distributions. Valid distributions are the same as in <code>btk</code>. If <code>dist</code>= &quot;none&quot;, the mean is used as
a fixed constant. M is used to determine exploitation rate (Umsy) at MSY.
</p>
</td></tr>
<tr><td><code id="dbsra_+3A_nsims">nsims</code></td>
<td>
<p>number of Monte Carlos samples.</p>
</td></tr> 
<tr><td><code id="dbsra_+3A_catchout">catchout</code></td>
<td>
<p>if catch is resampled, output the time series from every MC sample to a .csv file.
0 = no (default), 1 = yes.</p>
</td></tr> 
<tr><td><code id="dbsra_+3A_grout">grout</code></td>
<td>
<p>numeric argument specifying whether graphs should be printed to console only (1) or to 
both the console and TIF graph files (2).Use <code>setwd</code> before running function to direct .tif files
to a specific directory. Each name of each file is automatically determined.</p>
</td></tr> 
<tr><td><code id="dbsra_+3A_graphs">graphs</code></td>
<td>
<p>vector specifying which graphs should be produced. 1 = line plot of observed catch versus
year, 2 = histogram of plausible (accepted) <code>k</code> values, 3 = histogram of plausible Bmsy values, 
4 = histogram of plausible MSY values, 5 = histogram of plausible Fmsy values, 6 = histogram of Umsy values,
7 = histogram of plausible Cmsy , 8 = histogram of Bmsy from plausible M, 9 = histogram of plausible Bt/k values,
10 = histogram of plausible Fmsy/M values, 11 = histogram of plausible Bmsy/k values and 12 = histogram of
plausible biomasses in <code>termyr</code>, 13 = line plots of accepted and rejected biomass trajectores
with median and 2.5th and 97.5th percentiles (in red) and 14 =  stacked histograms of accepted and 
rejected values for each input parameter and resulting estimates and if <code>grout</code>=2,
.tif files are saved with &quot;AR&quot; suffix. Any combination of graphs can be 
selected within c().  Default is all.
</p>
</td></tr>
<tr><td><code id="dbsra_+3A_grargs">grargs</code></td>
<td>
<p>list control arguments for plotting functions. <code>lwd</code> is the line width for graph = 1 and 13, 
<code>nclasses</code> is the nclass argument for the histogram plots (graphs 2-12,14), <code>mains</code> and 
<code>cex.main</code> are the titles and character expansion values for the graphs, <code>cex.axis</code> is the 
character expansion value(s) for the x and y-axis tick labels and <code>cex.lab</code> is the character 
expansion value(s) for the x and y-axis labels.  Single values of <code>nclasses</code>,<code>mains</code>, 
<code>cex.main</code>,<code>cex.axis</code>, <code>cex.lab</code> are applied to all graphs.  To change arguments for 
specific graphs, enclose arguments within c() in order of the number specified in <code>graphs</code>. 
</p>
</td></tr>
<tr><td><code id="dbsra_+3A_pstats">pstats</code></td>
<td>
<p>list control arguments for plotting the median and 2.5
and management quantities on respective graphs. <code>ol</code> = 0, do not overlay values on plots, 1 = 
overlay values on plots. <code>mlty</code> and <code>mlwd</code> are the line type and line width of the median value;
<code>llty</code> and <code>llwd</code> are the line type and line width of the 2.5
<code>ulwd</code> are the line type and line width of the 97.5
</p>
</td></tr>
<tr><td><code id="dbsra_+3A_grtif">grtif</code></td>
<td>
<p>list arguments for the .TIF graph files. See <code>tiff</code> help file in R.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The method of Dick and MAcCall (2011) is used to produce estimates of MSY where only catch and 
information on resilience and current relative depletion is known. 
</p>
<p>The  delay-difference model is used to propogate biomass: 
</p>
<p>B[t+1]&lt;-B[t]+P[Bt-a]-C[t]
</p>
<p>where <code>B[t]</code> is biomass in year t, <code>P[Bt-a]</code> is latent annual production based 
on parental biomass <code>agemat</code> years earlier and <code>C[t]</code> is the catch in year 
t. Biomass in the first year is assumed equal to <code>k</code>.
</p>
<p>If Bmsy/k&gt;=0.5, then P[t] is calculated as
</p>
<p>P[t]&lt;-g*MSY*(B[t-agemat]/k)-g*MSY*(B[t-agemat]/k)^n
</p>
<p>where MSY is k*Bmsy/k*Umsy, n is solved iteratively using the equation, Bmsy/k=n^(1/(1-n)),
and g is (n^(n/(n-1)))/(n-1). Fmsy is calculated as Fmsy=Fmsy/M*M and Umsy is calculated as 
(Fmsy/(Fmsy+M))*(1-exp(-Fmsy-M)).
</p>
<p>If Bsmy/k &lt; 0.5, Bjoin is calculated based on linear rules:
If Bmsy/k&lt;0.3, Bjoin=0.5*Bmsy/k*k
If Bmsy/k&gt;0.3 and Bmsy/k&lt;0.5, Bjoin=(0.75*Bmsy/k-0.075)*k
</p>
<p>If any B[t-a]&lt;Bjoin, then the Schaefer model is used to calculated P:
</p>
<p>P[Bt-agematt&lt;Bjoin]&lt;-B[t-agemat]*(P(Bjoin)/Bjoin+c(B[t-agemat]-Bjoin))
</p>
<p>where c =(1-n)*g*MSY*Bjoin^(n-2)*K^(-n)
</p>
<p>Biomass at MSY is calculated as: Bmsy=(Bmsy/k)*k
</p>
<p>The overfishing limit (OFL) is Umsy*B[termyr].
</p>
<p><code>length(year)+1</code> biomass estimates are made for each run.
</p>
<p>The rule for accepting a run is:
if(min(B)&gt;0 &amp;&amp; max(B)&lt;=k &amp;&amp; 
</p>
<p>(objective function minimum&lt;=tol^2) &amp;&amp; abs(((max(B)-k)/k)*100)&lt;=permax 
&amp;&amp; n&lt;=maxn
</p>
<p>If using the R Gui (not Rstudio), run 
</p>
<p>graphics.off()
windows(width=10, height=12,record=TRUE)
.SavedPlots &lt;- NULL
</p>
<p>before running the dbsra function to recall plots.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Initial</code></td>
<td>
<p>dataframe containing the descriptive statistics for each explored parameter.</p>
</td></tr>
<tr><td><code>Parameters</code></td>
<td>
<p>dataframe containing the mean, median, 2.5th and 97.5
of the plausible (accepted: likelihood(ll)=1) parameters. </p>
</td></tr>  
<tr><td><code>Estimates</code></td>
<td>
<p>dataframe containing the mean, median, 2.5th and 97.5
of the management quantities (i.e., MSY, Bmsy, etc.) from the plausible parameters 
(likelihood=1)</p>
</td></tr>
<tr><td><code>Values</code></td>
<td>
<p>dataframe containing the values of likelihood, k, Bt/k, Bmsy/k, M and associated management 
quantities for all (likelihood=0 and likelihood=1) random draws.</p>
</td></tr>
<tr><td><code>agemat</code></td>
<td>
<p>agemat for use in function <code>dlproj</code>.</p>
</td></tr>
<tr><td><code>end1yr</code></td>
<td>
<p>value of the last year of catch data + 1 for use in function <code>dlproj</code>.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>designates the output object as a <code>catchmsy</code> object for use in function <code>dlproj</code>.</p>
</td></tr>
</table>
<p>The biomass estimates from each simulation are not stored in memory but are automatically 
saved to a .csv file named &quot;Biotraj-dbsra.csv&quot;. Yearly values for each simulation are stored across 
columns.  The first column holds the likelihood values for each simulation (1= accepted, 0 = rejected).  
The number of rows equals the number of simulations (<code>nsims</code>). This file is loaded to plot
graph 13 and it must be present in the default or <code>setwd()</code> directory.  
</p>
<p>When <code>catchout</code>=1,   catch values randomly selected are saved to a .csv file named &quot;Catchtraj-dbsra.csv&quot;. 
Yearly values for each simulation are stored across columns.  The first column holds the likelihood 
values (1= accepted, 0 = rejected).  The number of rows equals the number of simulations (<code>nsims</code>).   
</p>
<p>Use <code>setwd()</code> before running the function to change the directory where .csv files are stored.  
</p>


<h3>Note</h3>

<p>The random distribution function was adapted from Nadarajah, S and S. Kotz. 2006. R 
programs for computing truncated distributions. Journal of Statistical Software 16, code snippet 2.
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a>
</p>


<h3>References</h3>

<p>Dick, E. J. and A. D. MacCall. 2011. Depletion-based stock reduction analysis: a catch-based method for determining
sustainable yield for data-poor fish stocks. Fisheries Research 110: 331-341.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+catchmsy">catchmsy</a></code> <code><a href="#topic+dlproj">dlproj</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Not run: 
  data(cowcod)
  dbsra(year =cowcod$year, catch = cowcod$catch, catchCV = NULL, 
    catargs = list(dist="none",low=0,up=Inf,unit="MT"),
    agemat=11, k = list(low=100,up=15000,tol=0.01,permax=1000), 
    b1k = list(dist="none",low=0.01,up=0.99,mean=1,sd=0.1),
    btk = list(dist="beta",low=0.01,up=0.99,mean=0.4,sd=0.1,refyr=2009),
    fmsym = list(dist="lnorm",low=0.1,up=2,mean=-0.223,sd=0.2),
    bmsyk = list(dist="beta",low=0.05,up=0.95,mean=0.4,sd=0.05),
    M = list(dist="lnorm",low=0.001,up=1,mean=-2.90,sd=0.4),
    nsims = 10000)
 
## End(Not run)
</code></pre>

<hr>
<h2 id='deltadist'>Delta Distribution Mean and Variance Estimators</h2><span id='topic+deltadist'></span>

<h3>Description</h3>

<p>Calculates the mean and variance of a catch series based on the delta distribution described in 
Pennington (1983).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>deltadist(x = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="deltadist_+3A_x">x</code></td>
<td>
<p>vector of catch values, one record for each haul.  Include zero and nonzero catches. Missing values are deleted prior to estimation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Data from marine resources surveys usually contain a large proportion of hauls
with no catches.  Use of the delta-distribution can lead to more efficient estimators of 
the mean and variance because zeros are treated separately.  The methods used here to calculate
the delta distribution mean and variance are given in Pennington (1983).  
</p>


<h3>Value</h3>

<p>vector containing the delta mean and associated variance.
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Pennington, M. 1983. Efficient estimators of abundance for fish and plankton
surveys. Biometrics 39: 281-286.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(catch)
deltadist(catch$value) 
</code></pre>

<hr>
<h2 id='deplet'>Catch-Effort Depletion Methods For a Closed Population</h2><span id='topic+deplet'></span>

<h3>Description</h3>

<p>Variable and constant effort models for the estimation of abundance from catch-effort depletion data assuming a closed population.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>deplet(catch = NULL, effort = NULL, method = c("l", "d", "ml",
 "hosc", "hesc", "hemqle", "wh"), kwh=NULL, nboot = 500, Nstart=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="deplet_+3A_catch">catch</code></td>
<td>
<p>the vector containing catches for each removal period (in sequential order).</p>
</td></tr>
<tr><td><code id="deplet_+3A_effort">effort</code></td>
<td>
<p>the vector containing effort associated with catch for each removal period. Rows must match those of catch.</p>
</td></tr>
<tr><td><code id="deplet_+3A_method">method</code></td>
<td>
<p>the depletion method. <em>Variable Effort Models</em>: <code>l</code>= Leslie estimator, <code>d</code>= effort corrected
Delury estimator, <code>ml</code>= maximum likelihood estimator of Gould and Pollock (1997), <code>hosc</code>= sampling coverage
estimator for homogeneous model of Chao and Chang (1999), <code>hesc</code>= sampling coverage estimator for heterogeneous 
model of Chao and Chang (1999), and <code>hemqle</code>= maximum quasi likelihood estimator for heterogeneous model of
Chao and Chang (1999). <em>Constant Effort Model</em>: <code>wh</code>= the generalized removal method of Otis et al. (1978).
</p>
</td></tr>
<tr><td><code id="deplet_+3A_kwh">kwh</code></td>
<td>
<p>the number of capture parameters (p) to fit in method <code>wh</code>. NULL for all possible capture parameters.</p>
</td></tr>
<tr><td><code id="deplet_+3A_nboot">nboot</code></td>
<td>
<p>the number of bootstrap resamples for estimation of standard errors in the <code>ml</code>,
<code>hosc</code>,<code>hesc</code>, and <code>hemqle</code> methods</p>
</td></tr>
<tr><td><code id="deplet_+3A_nstart">Nstart</code></td>
<td>
<p>starting value for N in method &quot;wh&quot;. If NULL, start value is
automatically determined</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The variable effort models include the Leslie-Davis (<code>l</code>) estimator (Leslie and Davis, 1939), the effort-corrected Delury (<code>d</code>) estimator (Delury,1947; Braaten, 1969),
the maximum likelihood (<code>ml</code>) method of Gould and Pollock (1997), sample coverage estimator for the homogeneous model (<code>hosc</code>) of Chao and Chang (1999), 
sample coverage estimator for the heterogeneous model (<code>hesc</code>) of Chao and Chang (1999), and the maximum quasi-likelihood estimator for the heterogeneous model (<code>hemqle</code>) of Chao and Chang (1999). 
The variable effort models can be applied to constant effort data by simply filling the <code>effort</code> vector with 1s. Three removals are required to use the Leslie, Delury, and Gould
and Pollock methods.  
</p>
<p>The constant effort model is the generalized removal method of Otis et al. 1978 reviewed in White et al. (1982: 109-114).
If only two removals, the two-pass estimator of N in White et al. (1982:105) and the variance estimator of Otis et al. (1978: 108) are used.
</p>
<p>Note: Calculation of the standard error using the <code>ml</code> method may take considerable time.
</p>
<p>For the Delury method, zero catch values are not allowed because the log-transform is used.
</p>
<p>For the generalized removal models, if standard errors appear as <code>NA</code>s but parameter estimates are provided, the inversion of the Hessian failed.
If parameter estimates and standard errors appear as <code>NA</code>s, then model fitting failed.
</p>
<p>For the Chao and Chang models, if the last catch value is zero, it is deleted from the data.  Zero values between positive values are permitted.
</p>


<h3>Value</h3>

<p>Separate output lists with the method name and extension <code>.out</code> are created for each method and contain tables of various statistics associated with the method.  
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Braaten, D. O. 1969. Robustness of the Delury population estimator. J. Fish. Res. Board Can. 26: 339-355.
</p>
<p>Chao, A. and S. Chang. 1999. An estimating function approach to the inference of catch-effort models. Environ. Ecol. Stat. 6: 313-334.
</p>
<p>Delury, D. B. 1947. On the estimation of biological populations. Biometrics 3: 145-167.
</p>
<p>Gould, W. R. and K. H. Pollock. 1997. Catch-effort maximum likelihood estimation of important population parameters. Can. J. Fish. Aquat. Sci 54: 890-897.
</p>
<p>Leslie, P. H. and D. H.S. Davis. 1939. An attempt to determine the absolute number of rats on a given area.  J. Anim. Ecol. 9: 94-113.
</p>
<p>Otis, D. L., K. P. Burnham, G. C. White, and D. R. Anderson. 1978. Statistical inference from capture data on closed animal populations. Wildl. Monogr. 62: 1-135.
</p>
<p>White, G. C., D. R. Anderson, K. P. Burnham, and D. L. Otis. 1982. Capture-recapture and Removal Methods for Sampling
Closed Populations. Los Alamos National Laboratory LA-8787-NERP. 235 p.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(darter)
deplet(catch=darter$catch,effort=darter$effort,method="hosc") 
hosc.out
</code></pre>

<hr>
<h2 id='dlproj'>
This function performs projections for dbsra and catchmsy objects
</h2><span id='topic+dlproj'></span>

<h3>Description</h3>

<p>Make biomass projections by using inputted catch and results of dbsra or catchmsy functions</p>


<h3>Usage</h3>

<pre><code class='language-R'>dlproj(dlobj = NULL, projyears = NULL, projtype = 1, projcatch = NULL, 
grout = 1, grargs = list(lwd = 1, unit = "MT", mains = " ", cex.main = 1, 
cex.axis = 1, cex.lab = 1), grtif = list(zoom = 4, width = 11, height = 13, 
pointsize = 10))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dlproj_+3A_dlobj">dlobj</code></td>
<td>
<p>function dbsra or catchmsy output object</p>
</td></tr>
<tr><td><code id="dlproj_+3A_projyears">projyears</code></td>
<td>
<p>the number of years for projection.  The first year will be the last year of
catch data plus one in the original dbsra or catchmsy run.
</p>
</td></tr>
<tr><td><code id="dlproj_+3A_projtype">projtype</code></td>
<td>
<p>the type of catch input. 0 = use median MSY from dbsra or catchmsy object, 1 = use
mean MSY from dbsra or catchmsy object, 2 = user-inputted catch</p>
</td></tr>
<tr><td><code id="dlproj_+3A_projcatch">projcatch</code></td>
<td>
<p>if projtype = 2, a single catch value used over all projection years or a
vector of catch values (length is equal to <code>projyears</code>).</p>
</td></tr>
<tr><td><code id="dlproj_+3A_grout">grout</code></td>
<td>
<p>numeric argument specifying whether projection graph should be shown on 
the console only (grout=1) or shown on the console and exported to a TIF graph file (grout=2).
No graph (grout== 0). If plotted, the median (solid line), mean (dashed line), and 2.5th and 97.5 
percentiles(dotted lines) are displayed. Use <code>setwd</code> before running function to direct .tif file
to a specific directory. The name of .tif file is automatically determined.</p>
</td></tr> 
<tr><td><code id="dlproj_+3A_grargs">grargs</code></td>
<td>
<p>list control arguments for plotting functions. <code>lwd</code> is the line width, <code>unit</code>
is the biomass unit for the y-axis label,<code>mains</code> and 
<code>cex.main</code> are the title and character expansion value for the graph, <code>cex.axis</code> is the 
character expansion value for the x and y-axis tick labels and <code>cex.lab</code> is the character 
expansion value(s) for the x and y-axis labels. 
</p>
</td></tr>
<tr><td><code id="dlproj_+3A_grtif">grtif</code></td>
<td>
<p>list control arguments for the .TIF graph file. See <code>tiff</code> help file in R.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The biomass estimate of the last year+1 is used as the starting biomass (year 1 in projections)
and leading parameters from each plausible (accepted) run are used to project biomass ahead <code>projyears</code> years
using either the MSY estimate (median or mean) from all plausible runs or inputted catch values.
The biomass estimates are loaded from either the &quot;Biotraj-dbsra.csv&quot; or &quot;Biotroj-cmsy.csv&quot; files that were 
automatically saved in functions &quot;dbsra&quot; and &quot;catchmsy&quot;.
</p>
<p>Use <code>setwd()</code> before running the function to change the directory where .csv files are stored.  
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>type</code></td>
<td>
<p>object projection type</p>
</td></tr>
<tr><td><code>ProjBio</code></td>
<td>
<p>dataframe of biomass projections for each plausible run</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a>
</p>


<h3>References</h3>

<p>Martell, S. and R. Froese. 2012. A simple method for estimating MSY from catch and resilience.
Fish and Fisheries 14:504-514.
</p>
<p>Dick, E. J. and A. D. MacCall. 2011. Depletion-based stock reduction analysis: a catch-based method for determining
sustainable yield for data-poor fish stocks. Fisheries Research 110: 331-341.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+catchmsy">catchmsy</a></code> <code><a href="#topic+dbsra">dbsra</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  data(lingcod)
   outs&lt;-catchmsy(year=lingcod$year,
    catch=lingcod$catch,catchCV=NULL,
    catargs=list(dist="none",low=0,up=Inf,unit="MT"),
    l0=list(low=0.8,up=0.8,step=0),
    lt=list(low=0.01,up=0.25,refyr=2002),sigv=0,
    k=list(dist="unif",low=4333,up=433300,mean=0,sd=0),
    r=list(dist="unif",low=0.015,up=0.5,mean=0,sd=0),
    bk=list(dist="unif",low=0.5,up=0.5,mean=0,sd=0),
    M=list(dist="unif",low=0.24,up=0.24,mean=0.00,sd=0.00),
    nsims=30000)
   outbio&lt;-dlproj(dlobj = outs, projyears = 20, projtype = 0, grout = 1)
 
## End(Not run)
</code></pre>

<hr>
<h2 id='ep_growth'>Fitting the von Bertalanffy growth model to length-stratified age samples</h2><span id='topic+ep_growth'></span>

<h3>Description</h3>

<p>Estimation of von Bertanffy growth parameters based on length-stratified age samples (Perrault et al., 2020)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ep_growth(len=NULL,age=NULL,Nh=NULL,nh=NULL,starts=list(Linf=60,
k=0.1,a0=-0.01,CV=0.5), 
bin_size=2,nlminb.control=list(eval.max=5000, 
iter.max=5000,trace=10),
tmb.control=list(maxit=5000,trace=FALSE),plot=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ep_growth_+3A_len">len</code></td>
<td>
<p>vector of lengths.</p>
</td></tr>
<tr><td><code id="ep_growth_+3A_age">age</code></td>
<td>
<p>the vector of ages associated with the length vector.</p>
</td></tr>
<tr><td><code id="ep_growth_+3A_nh">Nh</code></td>
<td>
<p>the total sample size per bin. Includes the unaged fish.</p>
</td></tr>
<tr><td><code id="ep_growth_+3A_nh">nh</code></td>
<td>
<p>the total aged sample size per bin.</p>
</td></tr>
<tr><td><code id="ep_growth_+3A_starts">starts</code></td>
<td>
<p>the starting values for <em>L-infinity</em>, <em>K</em>, <em>a0</em> and <em>CV</em>. Required.</p>
</td></tr>
<tr><td><code id="ep_growth_+3A_bin_size">bin_size</code></td>
<td>
<p>the bin size (e.g., 2 for 2-cm) of the length stratification.</p>
</td></tr>
<tr><td><code id="ep_growth_+3A_nlminb.control">nlminb.control</code></td>
<td>
<p>controls for the <em>nlminb</em> function. See function <em>nlminb</em> for more information.</p>
</td></tr>
<tr><td><code id="ep_growth_+3A_tmb.control">tmb.control</code></td>
<td>
<p>controls for the <em>TMB</em> function. See package <em>TMB</em> for more information.</p>
</td></tr>
<tr><td><code id="ep_growth_+3A_plot">plot</code></td>
<td>
<p>plot observed and model predicted lengths at age. Default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The von Bertalanffy growth model <em>Lage=Linf*(1-exp(-K*(age-a0))</em> is fitted to length-at-age data 
collected via length-stratified sampling following the EP method of Perreault et al. (2020).
A plot of  model fit is generated unless <em>plot</em>=FALSE. 
</p>


<h3>Value</h3>

<p>List containing list elements of the model convergence, parameter estimates and predicted values.
</p>


<h3>Author(s)</h3>

<p>Andrea Perrault,
Marine Institute of Memorial University of Newfoundland
</p>
<p><a href="mailto:andrea.perrault@mi.mun.ca">andrea.perrault@mi.mun.ca</a>
</p>


<h3>References</h3>

<p>Perrault, A. M. J., N. Zhang and Noel G. Cadigan. 2020. Estimation of growth parameters based on 
length-stratified age samples. Canadian Journal of Fisheries and Aquatic Sciences 77: 439-450. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Not run: 
	data(ep.data)
	ep_growth(len=ep.data$length, age=ep.data$age, Nh=ep.data$Nh, nh=ep.data$nh,
        starts=list(Linf=60,
        k=0.1, CV=0.5 ,a0=-0.01), bin_size=2,
          nlminb.control=list(eval.max=5000, iter.max=5000, trace=10), 
          tmb.control=list(maxit=5000, trace=F),plot=TRUE)
 
## End(Not run)
</code></pre>

<hr>
<h2 id='ep.data'>A sub-sample of data from a simulated population collected via length-stratified age sampling</h2><span id='topic+ep.data'></span>

<h3>Description</h3>

<p>The <code>catch</code> data frame has 1072 rows and 4 columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ep.data
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>length</dt><dd><p>length in cm.</p>
</dd>
<dt>age</dt><dd><p>age of fish (yrs).</p>
</dd>
<dt>Nh</dt><dd><p>the total sample size per bin (includes unaged fish).</p>
</dd>
<dt>nh</dt><dd><p>the total aged sample size per bin.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Andrea Perrault,  Marine Institute of Memorial University of Newfoundland</p>

<hr>
<h2 id='epr'>Eggs-Per-Recruit Analysis</h2><span id='topic+epr'></span>

<h3>Description</h3>

<p>Eggs-per-recruit(EPR) analysis is conducted following Gabriel et al. (1989) except fecundity-at-age is substituted for weight-at-age.  Reference points
of F and EPR for percentage of maximum spawning potential are calculated.</p>


<h3>Usage</h3>

<pre><code class='language-R'>epr(age = NULL, fecund = NULL, partial = NULL, pmat = pmat,
 M = NULL, pF = NULL, pM = NULL, MSP = 40, plus = FALSE,
 oldest = NULL, maxF = 2, incrF = 1e-04)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="epr_+3A_age">age</code></td>
<td>
<p>vector of cohort ages. If the last age is a plus group, do not add a &quot;+&quot; to the age.</p>
</td></tr>
<tr><td><code id="epr_+3A_fecund">fecund</code></td>
<td>
<p>vector of fecundity (number of eggs per individual) for each age. Length of vector must correspond to the length of the age vector.</p>
</td></tr>
<tr><td><code id="epr_+3A_partial">partial</code></td>
<td>
<p>partial recruitment vector applied to fishing mortality (F) to obtain partial F-at-age.  Length of this vector must match length of the age vector. </p>
</td></tr>
<tr><td><code id="epr_+3A_pmat">pmat</code></td>
<td>
<p>proportion of mature fish at each age. Length of this vector must match the length of the age vector.  </p>
</td></tr>
<tr><td><code id="epr_+3A_m">M</code></td>
<td>
<p>vector containing a single natural mortality (M) rate if M is assumed constant over all ages, or a vector of
Ms, one for each age. If the latter, the vector length must match the length of the age vector. </p>
</td></tr>
<tr><td><code id="epr_+3A_pf">pF</code></td>
<td>
<p>the proportion of fishing mortality that occurs before spawning.</p>
</td></tr>
<tr><td><code id="epr_+3A_pm">pM</code></td>
<td>
<p>the proportion of natural mortality that occurs before spawning.</p>
</td></tr>
<tr><td><code id="epr_+3A_msp">MSP</code></td>
<td>
<p>the percentage of maximum spawning potential (percent MSP reference point) for which F and EPR should be calculated.  </p>
</td></tr>
<tr><td><code id="epr_+3A_plus">plus</code></td>
<td>
<p>a logical value indicating whether the last age is a plus-group. Default is FALSE.</p>
</td></tr>
<tr><td><code id="epr_+3A_oldest">oldest</code></td>
<td>
<p>if plus=TRUE, a numeric value indicating the oldest age in the plus group. </p>
</td></tr>
<tr><td><code id="epr_+3A_maxf">maxF</code></td>
<td>
<p>the maximum value of F range over which EPR will be calculated. EPR is calculated for F = 0 to maxF.</p>
</td></tr>
<tr><td><code id="epr_+3A_incrf">incrF</code></td>
<td>
<p>F increment for EPR calculation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Eggs-per-recruit analysis is conducted following Gabriel et al. (1989).  The F and EPR for the percentage maximum spawning potential reference point
are calculated. If the last age is a plus-group, the cohort is expanded to the
<code>oldest</code> age and the <code>fecund</code>, <code>partial</code>, <code>pmat</code>, and <code>M</code> values for the plus age are applied to the expanded cohort ages.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Reference_Points</code></td>
<td>
<p>F and EPR values for the percentage MSP</p>
</td></tr>
<tr><td><code>EPR_vs_F</code></td>
<td>
<p>Eggs-per-recruit values for each F increment</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Gabriel, W. L., M. P. Sissenwine, and W. J. Overholtz. 1989. Analysis of spawning stock biomass per recruit:
an example for Georges Bank haddock. North American Journal of Fisheries Management 9: 383-391.</p>


<h3>See Also</h3>

<p><code><a href="#topic+ypr">ypr</a></code> <code><a href="#topic+sbpr">sbpr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>    data(menhaden)
	epr(age=menhaden$age,fecund=menhaden$fecundity,partial=menhaden$partial,
	pmat=menhaden$pmat,M=menhaden$M,pF=0,pM=0,MSP=40,plus=TRUE,maxF=4,incrF=0.01,oldest=10)
</code></pre>

<hr>
<h2 id='fm_checkdesign'>Check parameter structure of Hightower et al. (2001) models</h2><span id='topic+fm_checkdesign'></span>

<h3>Description</h3>

<p>Check design of parameter structure before use in function <code>fm_telemetry</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fm_checkdesign(occasions = NULL, design = NULL, type = "F" )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fm_checkdesign_+3A_occasions">occasions</code></td>
<td>
<p>total number of occasions that will be modeled in data</p>
</td></tr>
<tr><td><code id="fm_checkdesign_+3A_design">design</code></td>
<td>
<p>vector of characters specifying the occasion parameter structure (see details).</p>
</td></tr>
<tr><td><code id="fm_checkdesign_+3A_type">type</code></td>
<td>
<p>character type of parameter to which design will be applied: F = fishing mortality, M = natural mortality, and P = probability of detection. Default = F.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The program allows the configuration of different parameter structure for the estimation of fishing and natural mortalities, and detection probabilities. These structures are specified in <code>design</code>.  Consider the following examples:
</p>
<p><em>Example 1</em>
</p>
<p>Tags are relocated over seven occasions.  One model structure might be constant fishing mortality estimates over occasions 1-3 and 4-6. To specify this model structure:
<code>design</code> is c(&ldquo;1&rdquo;,&ldquo;4&rdquo;).
</p>
<p>Note: The structures of <code>design</code> must always contain the first occasion for fishing mortality and natural mortality, whereas the structure for the probability of detection must not contain the first occasion. 
</p>
<p><em>Example 2</em>
</p>
<p>Tags are relocated over six occasions.  One model structure might be separate fishing mortality estimates for occasion 1-3 and the same parameter estimates for occasions 4-6. The <code>design</code> is c(&ldquo;1:3*4:6&rdquo;).
</p>
<p>Note: The structures of <code>Fdesign</code> and <code>Mdesign</code> must always start with the first occasion, whereas the structure for <code>Pdesign</code> must always start with the second occasion. 
</p>
<p>Use the multiplication sign to specify occasions whose estimates of F, M or P will be taken from values of other occasions.
</p>
<p><em>Example 3</em>
</p>
<p>Specification of model 3 listed in Table 1 of Hightower et al. (2001) is shown.  Each occasion represented a quarter of the year. The quarter design for F specifies that quarterly estimates are the same in both years. <code>design</code> is c(&ldquo;1*14&rdquo;,&ldquo;4*17&rdquo;,&ldquo;7*20&rdquo;,&ldquo;11*24&rdquo;).
</p>
<p><em>Example 4</em>
</p>
<p>In Hightower et al. (2001), the quarter and year design specifies that estimates are made for each quarter but are different for each year. <code>design</code> is 
</p>
<p>c(&ldquo;1&rdquo;, &ldquo;4&rdquo;, &ldquo;7&rdquo;, &ldquo;11&rdquo;, 
&ldquo;14&rdquo;, &ldquo;17&rdquo;, &ldquo;20&rdquo;, &ldquo;24&rdquo;).
</p>
<p>If the number of occasions to be assigned parameters from other occasions are less than the number of original parameters (e.g., c(&ldquo;11:13*24:25&rdquo;), then only the beginning sequence of original parameters equal to the number of occasions are used. For instance, in c(&ldquo;11:13*24:25&rdquo;), only parameters 11 and 12 would be assigned to occasions 24 and 25.
</p>
<p>If the number of occasions to be assigned parameters from other occasions are greater than the number of original parameters (e.g., c(&ldquo;11:12*24:26&rdquo;)), then the last original parameter is re-cycled. In the example c(&ldquo;11:12*24:26&rdquo;), the parameter for occasion 12 is assigned to occasions 25 <em>and</em> 26.
</p>


<h3>Value</h3>

<p>dataframe containing the parameter order by occasion. 
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+fm_telemetry">fm_telemetry</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>fm_checkdesign(occasions=27, design=c("1*14","4*17","7*20","11*24"),type="F")
</code></pre>

<hr>
<h2 id='fm_model_avg'>Model Averaging for the Telemetry Method of Hightower et al. (2001)</h2><span id='topic+fm_model_avg'></span>

<h3>Description</h3>

<p>Calculates model averaged estimates of instantaneous fishing, natural and probability of detection for telemetry models of Hightower et al. (2001).</p>


<h3>Usage</h3>

<pre><code class='language-R'>fm_model_avg(..., global = NULL, chat = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fm_model_avg_+3A_...">...</code></td>
<td>
<p>model object names separated by commas</p>
</td></tr>
<tr><td><code id="fm_model_avg_+3A_global">global</code></td>
<td>
<p>specify global model name in quotes.  If the global model is the first model included 
in the list of candidate models, this argument can be ignored.</p>
</td></tr>
<tr><td><code id="fm_model_avg_+3A_chat">chat</code></td>
<td>
<p>chat for the global model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Model estimates are generated from function <code>fm_telemetry</code>.
Averaging of model estimates follows the procedures in Burnham and Anderson (2002). Variances of parameters are adjusted for overdispersion using the c-hat estimate from the global model 
: <code>sqrt(var*c-hat)</code>.  If c-hat of the global model is &lt;1, then c-hat is set to 1. The c-hat is used to calculate the quasi-likelihood AIC and AICc 
metrics for each model (see page 69 in Burnham and Anderson(2002)). QAICc differences among models are calculated by
subtracting the QAICc of each model from the model with the smallest QAICc value. These differences are used to calculate 
the Akaike weights for each model following the formula on page 75 of Burnham and Anderson (2002). The Akaike weights are
used to calculate the weighted average and standard error of parameter estimates by summing the product of the model-specific Akaike weight and parameter estimate 
across all models.  An unconditional standard error is also calculated by 
<code>sqrt(sum(QAICc wgt of model i 
* (var of est of model i 
+ (est of model i - avg of all est)^2)))</code>.
</p>


<h3>Value</h3>

<p>List containing model summary statistics, model-averaged estimates of fishing, natural and probability of detections and their weighted and uncondtional standard errors . 
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

 
<p>Burnham, K. P. and D. R. Anderson. 2002. Model selection and multimodel inference : A Practical Information-Theorectic Approach, 2nd edition. Spriner-Verlag, New York, NY. 488 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fm_telemetry">fm_telemetry</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## This is a typical specification, not a working example
## Not run: 
fm_model_avg(model1,model2,model3,model4,model5,model6,model7,global="model7")
## End(Not run)
</code></pre>

<hr>
<h2 id='fm_telemetry'>Estimation of Fishing and Natural Mortality from Telemetry Data
</h2><span id='topic+fm_telemetry'></span>

<h3>Description</h3>

<p>The method of Hightower et al. (2001) is implemented to estimate fishing mortality, natural mortality and probability of detection from telemetry data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fm_telemetry(filetype = c(1), caphistory = NULL, Fdesign = NULL, Mdesign = NULL, 
Pdesign = NULL, whichlivecells =  NULL, 
whichdeadcells = NULL, constant = 1e-14, initial = NULL, 
invtol = 1e-44, control = list(reltol=1e-8,maxit=1000000))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fm_telemetry_+3A_filetype">filetype</code></td>
<td>
<p>type of file to read. 1 = R character vector with individual capture histories (1 history per row), 
or 2 = an external text file with individual capture histories. If <code>filetype</code>=2, then the capture histories 
in the file should not be enclosed in quotes and there 
should not be a column name. 
</p>
</td></tr>
<tr><td><code id="fm_telemetry_+3A_caphistory">caphistory</code></td>
<td>
<p>File or R object with capture histories. If filetype=2, location and filename of text file enclosed in quotes (e.g., &ldquo;C:/temp/data.txt&rdquo;).
</p>
</td></tr>
<tr><td><code id="fm_telemetry_+3A_fdesign">Fdesign</code></td>
<td>
<p>vector of characters specifying the occasion parameter structure for fishing mortality (F). See details.
</p>
</td></tr>
<tr><td><code id="fm_telemetry_+3A_mdesign">Mdesign</code></td>
<td>
<p>vector of characters specifying the occasion parameter structure for natural mortality (M). See details.
</p>
</td></tr>
<tr><td><code id="fm_telemetry_+3A_pdesign">Pdesign</code></td>
<td>
<p>vector of characters specifying the occasion parameter structure for the probability of detection (P). See details.</p>
</td></tr>
<tr><td><code id="fm_telemetry_+3A_whichlivecells">whichlivecells</code></td>
<td>
<p>list containing the structure of occasion live cells to use in each release during the estimation process. Multiple ranges may be specified. 
For each range, specify the first release, last release, and number of observed occasions (cells) enclosed within <code>c()</code>. For example, to use the first 4 cells of releases 1-5, specify <code>c(1,5,4)</code>. <code>whichlivecells</code> is a list object of all ranges (e.g., whichlivecells =list(c(1,5,4),c(6,26,6))). Specify <code>whichlivecells=NULL</code> to use all cells. 
The Hightower et al. (2001) specification is 
<code>whichlivecells</code>=list(c(1,5,4),c(6,6,5),
c(7,26,4)).
</p>
</td></tr> 
<tr><td><code id="fm_telemetry_+3A_whichdeadcells">whichdeadcells</code></td>
<td>
<p>list containing the structure of occasion dead cells to used in each release during the estimation process. Same as <code>whichlivecells</code>. The Hightower et al. (2001) specification is 
<code>whichdeadcells</code>=list(c(1,5,4),c(6,6,6),
c(7,26,4))
</p>
</td></tr>
<tr><td><code id="fm_telemetry_+3A_constant">constant</code></td>
<td>
<p>A small number to use in the multinomial log-likelihood (Obs * 
log(max(constant,
Expected Prob))) to avoid errors if any probability is 0. If the number is too large, it may affect the minimization of the likelihood. Default is 1e-14.
</p>
</td></tr> 
<tr><td><code id="fm_telemetry_+3A_initial">initial</code></td>
<td>
<p>vector of starting values for fishing and natural mortality, and the probability of detection. First position is the starting value for all Fs, the second position is the starting value for all Ms, and the third position is the starting value for all Ps (e.g., c(0.1,0.2,0.8)).
</p>
</td></tr>
<tr><td><code id="fm_telemetry_+3A_invtol">invtol</code></td>
<td>
<p>the tolerance for detecting linear dependencies in the columns of a in <code>solve</code>(the function used to invert the hessian matrix). Adjust this value if errors about tolerance limits arise.
</p>
</td></tr>
<tr><td><code id="fm_telemetry_+3A_control">control</code></td>
<td>
<p>A list of control parameters for <code>optim</code>.     See function <code>optim</code> for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The telemetry method of Hightower et al. (2001) is implemented. Individual capture histories are used in the function.  The function uses complete capture histories (Burnham et al., 1987) and it is the presence of specific codes in the individual capture histories that split the capture histories into live and dead arrays. F and M estimates are needed for occasions 1 to the total number of occasions minus 1 and P estimates are needed for occasions 2 to the total number of occasions.
</p>
<p>Capture histories are coded following Burnham et al. (1987)(i.e., 0 = not relocated, and 1 = relocated) with the following exceptions:
</p>
<p>All live relocations are coded with 1. If a fish is relocated and is dead, then <code>D</code> is used. For example,
</p>
<p><code>101011</code>  - fish released on occasion 1 is relocated alive on occasions 3,5 and 6
</p>
<p><code>10111D</code>  - fish released on occasion 1 is relocated alive on occasions 3,4,and 5 but is relocated dead on occasion 6.
</p>
<p>New releases are allowed to occur on multiple occasions.  The capture history of newly-released individuals should be coded with a zero (0) for the occasions before their release.
</p>
<p><code>100110</code> - fish released on occasion 1 is relocated live on occasion 4 and 5 
</p>
<p><code>101000</code> - fish released on occasion 1 is relocated live on occasion 3
</p>
<p><code>010111</code> - fish released on occasion 2 is relocated live on occasion 4, 5 and 6
</p>
<p><code>011000</code> - fish released on occasion 2 is relocated live on occasion 3
</p>
<p><code>001101</code> - fish released on occasion 3 is relocated live on occasion 4 and 6
</p>
<p><code>00100D</code> - fish released on occasion 3 is relocated dead on occasion 6.
</p>
<p>To censor fish from the analyses, specify <code>E</code> after the last live encounter. For example,
</p>
<p><code>10111E000</code>  - fish released on occasion 1 is relocated alive on occasions 3,4,and 5 but is believed to have emigrated from the area by occasion 6. The capture history before the <code>E</code> will be used, but the fish is not included in the virtual release in occasion 6. 
</p>
<p>All life histories are summarized to reduced m-arrays (Burnham et al. (1987: page 47, Table 1.15). 
</p>
<p>The function <code>optim</code> is used to find F, M and P parameters that minimize the negative log-likelihood. Only cells specified in <code>whichlivecells</code> and <code>whichdeadcells</code> are used in parameter estimation.
</p>
<p>The logit transformation is used in the estimation process to constrain values between 0 and 1. Logit-scale estimated parameters are used to calculate Sf=1/(1+exp(-B)), Sm=1/(1+exp(-C)) and P=1/(1+exp-(D)).  F and M are obtained by -log(Sf) and -log(Sm).
</p>
<p>The standard error of Sfs, Sm, P, F and M are obtained by the delta method: 
</p>
<p>SE(Sf)=sqrt((var(B)*exp(2*B))/(1+exp(B))^4), 
</p>
<p>SE(Sm)=sqrt((var(C)*exp(2*C))/(1+exp(C))^4),
</p>
<p>SE(P)=sqrt((var(D)*exp(2*D))/(1+exp(D))^4),
</p>
<p>SE(F)=sqrt(SE(Sf)^2/Sf^2),
</p>
<p>SE(M)=sqrt(SE(Sm)^2/Sm^2).
</p>
<p>All summary statistics follow Burnham and Anderson (2002).  Model degrees of freedom are calculated as nlive+ndead+nnever-nreleases-1-npar where nlive is the number of <code>whichlivecells</code> cells, ndead is the number of <code>whichdeadcells</code> cells, nnever is the number of never-seen cells, nreleases is the number of releases and npar is the number of estimated parameters. Total chi-square is calculated by summing the cell chi-square values.
</p>
<p>The program allows the configuration of different model structures (biological realistic models) for the estimation of fishing and natural mortalities, and detection probabilities. These structures are specified in <code>Fdesign</code>, <code>Mdesign</code> and <code>Pdesign</code>. Consider the following examples:
</p>
<p><em>Example 1</em>
</p>
<p>Tags are relocated over seven occasions.  One model structure might be constant fishing mortality estimates over occasions 1-3 and 4-6, one constant estimate of natural mortality for the entire sampling period, and one estimate of probability of detection for each occasion. To specify this model structure:
<code>Fdesign</code> is c(&ldquo;1&rdquo;,&ldquo;4&rdquo;), <code>Mdesign</code> is c(&ldquo;1&rdquo;) and the <code>Pdesign</code> is c(&ldquo;2:2&rdquo;).
</p>
<p>Note: The structures of <code>Fdesign</code> and <code>Mdesign</code> must always start with the first occasion, whereas the structure for <code>Pdesign</code> must always start with the second occasion. 
</p>
<p>Use the multiplication sign to specify occasions whose estimates of F, M or P will be taken from values of other occasions.
</p>
<p><em>Example 2</em>
</p>
<p>Tags are relocated over six occasions.  One model structure might be separate fishing mortality estimates for occasions 1-3 but assign the same parameter estimates to occasions 4-6, one constant estimate of natural mortality for occasions 1-5 and 6, and one constant probability of detection over all occasions.   The <code>Fdesign</code> is c(&ldquo;1:3*4:6&rdquo;), the <code>Mdesign</code> is c(&ldquo;1&rdquo;,&ldquo;6&rdquo;) and the <code>Pdesign</code> is c(&ldquo;2&rdquo;).
</p>
<p><em>Example 3</em>
</p>
<p>Specification of model 18 listed in Table 1 of Hightower et al. (2001) is shown.  Each occasion represented a quarter of the year. The quarter-year design for F, M and P specifies that quarterly estimates are made in each year. <code>Fdesign</code> is c(&ldquo;1&rdquo;,&ldquo;4&rdquo;,&ldquo;7&rdquo;,&ldquo;11&rdquo;,&ldquo;14&rdquo;,&ldquo;17&rdquo;, 
&ldquo;20&rdquo;,&ldquo;24&rdquo;). <code>Mdesign</code> is c(&ldquo;1&rdquo;,&ldquo;4&rdquo;,&ldquo;7&rdquo;,&ldquo;11&rdquo;,&ldquo;14&rdquo;,&ldquo;17&rdquo;,&ldquo;20&rdquo;,&ldquo;24&rdquo;) and the <code>Pdesign</code> is c(&ldquo;2&rdquo;,&ldquo;4&rdquo;,&ldquo;7&rdquo;,&ldquo;11&rdquo;,&ldquo;14&rdquo;,&ldquo;17&rdquo;, 
&ldquo;20&rdquo;,
&ldquo;24&rdquo;). 
</p>
<p>If the number of occasions to be assigned parameters from other occasions are less than the number of original parameters (e.g., c(&ldquo;11:13*24:25&rdquo;), then only the beginning sequence of original parameters equal to the number of occasions are used. For instance, in c(&ldquo;11:13*24:25&rdquo;), only parameters 11 and 12 would be assigned to occasions 24 and 25.
</p>
<p>If the number of occasions to be assigned parameters from other occasions are greater than the number of original parameters (e.g., c(&ldquo;11:12*24:26&rdquo;)), then the last original parameter is re-cycled. In the example c(&ldquo;11:12*24:26&rdquo;), the parameter for occasion 12 is assigned to occasions 25 <em>and</em> 26.
</p>
<p>To assist with the parameter structures, function <code>fm_checkdesign</code> may be used to check the desired design before use in this function. 
</p>
<p>If values of standard error are NA in the output, the hessian matrix used to claculate the variance-covariance matrix could not be inverted. If this occurs, try adjusting the <code>reltol</code> argument (for more information, see function <code>optim</code>).
</p>
<p>In this function, the never-seen expected number is calculated by summing the live and dead probabilities, subtracting the number from 1, and then multiplying it by the number of releases. No rounding occurs in this function.
</p>
<p>The multinomial likelihood includes the binomial coefficient.
</p>
<p>Model averaging of model can be accomplished using the function <code>fm_model_avg</code>.
</p>
<p>Note: In Hightower et al.'s original analysis, the cell probability code in SURVIV for the dead relocation in release occasion 6 had an error. The corrected analysis changed the estimates for occasions 11-13 compared to the original published values.
</p>


<h3>Value</h3>

<p>List containing summary statistics for the model fit, model convergence status, parameter estimates estimates of fishing mortality, natural mortality, and probabilties of detection and standard errors by occasion, the parameter structure (Fdeisgn, Mdesign and Pdesign), the m-arrays, the expected (predicted) number of live and dead relocations,  cell chi-square and Pearson values for live and dead relocations,  matrices with the probability of being relocated alive and dead by occasion, the whichlivecells and whichdeadcells structures, and configuration label (type) used in the <code>fm_model_avg</code> function.
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a>
</p>


<h3>References</h3>

 
<p>Burnham, K. P. and D. R. Anderson. 2002. Model selection and multimodel inference : A Practical Information-Theorectic
Approach, 2nd edition. Spriner-Verlag, New York, NY. 488 p.
</p>
<p>Burnham, K. P. D. R. Anderson, G. C. White, C. Brownie, and K. H. Pollock. 1987. Design and analysis methods for fish survival experiments based on release-recapture.  American FIsheries Society Monograph 5, Bethesda, Maryland.
</p>
<p>Hightower, J. E., J. R. Jackson, and K. H. Pollock. 2001. Use of telemetry methods to estimate natural and fishing mortality of striped bass in Lake Gaston, North Carolina. Transactions of the American Fisheries Society 130: 557-567.
</p>


<h3>See Also</h3>

<p><code>fm_model_avg</code>,<code>fm_checkdesign</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Set up for Full model of Hightower et al.(2001)
data(Hightower)
fm_telemetry(filetype=1,caphistory=Hightower$caphistory, Fdesign=c("1:26"),
 Mdesign=c("1:26"),Pdesign = c("2:25"),
whichlivecells=list(c(1,5,4), c(6,6,5),
 c(7,26,4)), 
whichdeadcells=list(c(1,5,4), c(6,6,6),
 c(7,26,4)),
initial=c(0.05,0.02,0.8),
control=list(reltol=1e-5,maxit=1000000))

#Set up for best model F(Qtr,yr), M constant, Pocc
fm_telemetry(filetype=1,caphistory=Hightower$caphistory, Fdesign=c("1", "4", "7", "11",
 "14", "17", "20", "24"), 
Mdesign=c("1"), Pdesign = c("2:27"),
whichlivecells=list(c(1,5,4), c(6,6,5),
 c(7,26,4)),
whichdeadcells=list(c(1,5,4), c(6,6,6),
 c(7,26,4)), 
initial=c(0.05,0.02,0.8),
 control=list(reltol=1e-8,maxit=1000000))

## End(Not run)
</code></pre>

<hr>
<h2 id='fpc'>
Fishing Power Correction Factor from Experimental Fishing
</h2><span id='topic+fpc'></span>

<h3>Description</h3>

<p>Calculates fishing power correction ratios between two vessels or gears
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fpc(cpue1 = NULL, cpue2 = NULL, method = c(1,2,3,4),  deletezerosets = FALSE, 
kapp_zeros = "paired", boot_type = "paired", nboot = 1000, dint = c(1e-9,5),
 rint = c(1e-9, 20), decimals = 2, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fpc_+3A_cpue1">cpue1</code></td>
<td>
<p>vector of CPUEs from vessel or gear considered the standard or baseline</p>
</td></tr>
<tr><td><code id="fpc_+3A_cpue2">cpue2</code></td>
<td>
<p>vector of CPUEs from other vessel or gear</p>
</td></tr>
<tr><td><code id="fpc_+3A_method">method</code></td>
<td>
<p>method(s) to use to estimate fishing power correction. 1 = Ratio of Means, 2 = Randomized Block ANOVA,
3 = Multiplicative Model, 4 = Kappenman 1992. Default = c(1,2,3,4)</p>
</td></tr> 
<tr><td><code id="fpc_+3A_deletezerosets">deletezerosets</code></td>
<td>
<p>if TRUE, paired observations with any CPUE=0 are eliminated prior to estimation. Default = FALSE.</p>
</td></tr>
<tr><td><code id="fpc_+3A_kapp_zeros">kapp_zeros</code></td>
<td>
<p>for method = 4, how CPUE=0 is eliminated. &quot;paired&quot; eliminates the row of paired CPUE observations if CPUE = 0 is present
for any observation within the pair,
&quot;ind&quot; eliminates CPUE = 0 from  the individual CPUE vectors.</p>
</td></tr>
<tr><td><code id="fpc_+3A_boot_type">boot_type</code></td>
<td>
<p>the method for bootstrapping data. &quot;paired&quot; = resample paired CPUE observations, &quot;unpaired&quot; = resample individual CPUE vectors</p>
</td></tr>
<tr><td><code id="fpc_+3A_nboot">nboot</code></td>
<td>
<p>the number of bootstrap replicates. Default = 1000.</p>
</td></tr>
<tr><td><code id="fpc_+3A_dint">dint</code></td>
<td>
<p>the lower and upper limits of the function interval searched by 
function <code>uniroot</code> to solve Kappenman's <em>d</em>.</p>
</td></tr>
<tr><td><code id="fpc_+3A_rint">rint</code></td>
<td>
<p>the lower and upper limits of the function interval searched by 
function <code>optimize</code> to solve Kappenman's <em>r</em>.</p>
</td></tr>
<tr><td><code id="fpc_+3A_decimals">decimals</code></td>
<td>
<p>the number of decimal places for output of estimates.</p>
</td></tr>
<tr><td><code id="fpc_+3A_alpha">alpha</code></td>
<td>
<p>the alpha level used to calculate confidence intervals.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The four methods for estimating fishing power correction factors given in Wilderbuer et al. (1998) are encoded.
</p>
<p>If paired CPUE observations are both zero, the row is automatically eliminated. If <code>deletezerosets</code> = TRUE, the paired
CPUE observations with any CPUE = 0 will be eliminated. 
</p>
<p>Zeroes are allowed in methods 1, 2 and 3. 
</p>
<p>For the Kappenman method (method=4), only non-zero CPUEs are allowed. Use <code>kapp_zeros</code> to select the elimination
method. An unequal number of observations between vessels is allowed in this method and can result using 
<code>kapp_zeros</code> = &quot;ind&quot;.  FPC is derived by using the methodology where r that minimizes the sum of
squares under the first conjecture relative to the second is estimated (Kappenman 1992: 2989; von Szalay and Brown 2001). 
</p>
<p>Standard errors and confidence intervals of FPC estimates are derived for most methods by using an approximation formula (where applicable),
jackknifing and/or bootstrapping. Specify the type of bootstrapping through <code>boot_type</code>. For methods 1-3,
jackknife estimates are provided only when <code>boot_type</code>=&quot;paired&quot;. If method = 4, jackknife estimates are provided only
when <code>boot_type</code>=&quot;paired&quot; and <code>kapp_zeros</code>=&quot;paired&quot;. 
</p>
<p>Confidence intervals are provided for the approximation formulae specified in Wilderbuer et al (1998), the jackknife estimates and bootstrap
estimates. Confidence intervals for the jackknife method are calculated using the standard formula
(estimate+/-z[alpha/2]*jackknife standard error).  Bootstrap confidence intervals are derived using the percentile method 
(Haddon 2001).
</p>


<h3>Value</h3>

<p>A dataframe containing method name, sample size for cpue1 (n1) and cpue2 (n2) ,mean cpue1,
mean cpue2, fishing power correction (FPC), standard error from approximation formulae (U_SE),
standard error from jackknifing (Jack_SE), standard error from bootstrapping (Boot_SE), lower and upper confidence intervals
from approximation formulae (<code>U_X%_LCI</code> and <code>U_X%_UCI</code>),lower and upper confidence intervals
from jackknifing (<code>Jack_X%_LCI</code> and <code>Jack_X%_UCI</code>) and lower and upper confidence intervals
from bootstrapping (<code>Boot_X%_LCI</code> and <code>Boot_X%_UCI</code>).
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a>
</p>


<h3>References</h3>

<p>Haddon, M. 2001. Modelling and Quantitative Methods in Fisheries. Chapman &amp; Hall/CRC Press. Boca Raton, Florida.
</p>
<p>Kappenman, R. F. 1992. Robust estimation of the ratio of scale parameters for positive
random variables. Communications in Statistics, Theory and Methods 21: 2983-2996.
</p>
<p>von Szalay, P. G. and E. Brown. 2001. Trawl comparisons of fishing power differences and
their applicability to National Marine Fisheries Service and Alask Department of Fish
and Game trawl survey gear.  Alaska Fishery Research Bulletin 8(2):85-95.
</p>
<p>Wilderbuer, T. K., R. F. Kappenman and D. R. Gunderson. 1998. Analysis of fishing power correction factor 
estimates from a trawl comparison experiment.  North American Journal of Fisheries Management 18:11-18.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
 #FPC for flathead sole from von Szalay and Brown 2001
   data(sole)
   fpc(cpue1=sole$nmfs,cpue2=sole$adfg,boot_type="unpaired",kapp_zeros="ind",method=c(4),
            alpha=0.05)
## End(Not run)
</code></pre>

<hr>
<h2 id='gap'>
Tukey's Gapping
</h2><span id='topic+gap'></span>

<h3>Description</h3>

<p>This function finds unusual spaces or gaps in a vector of random samples</p>


<h3>Usage</h3>

<pre><code class='language-R'>gap(x = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gap_+3A_x">x</code></td>
<td>

<p>vector of values
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Values (x) are sorted from smallest to largest. Then Z values are calculated as follows:
Zn-i+1=[i*(n-i)(Xn-i+1 - Xn-i)]^0.5
</p>
<p>where n is the sample size 
</p>
<p>for i = 2,...,n calulate the 25 percent trimmed mean and divide into Z.
This standardizes the distribution of the weighted gaps around a middle value of one. Suspiciously large
observations should correspond to large standardized weighted gaps.
</p>


<h3>Value</h3>

<p>vector of standardized weighted gaps </p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Tukey, J. W. 1971. Exploratory data analysis. Addison-Wesley, Reading, MA. 431 pp.</p>


<h3>Examples</h3>

<pre><code class='language-R'> y&lt;-c(rnorm(10,10,2),1000)
 gap(y)
</code></pre>

<hr>
<h2 id='Gerking'>Mark-Recapture Data for Sunfish in an Indiana Lake</h2><span id='topic+Gerking'></span>

<h3>Description</h3>

<p>The <code>Gerking</code> data frame has 14 rows and 3 columns.
Marked and released sunfish in an Indiana lake for 14 days by Gerking (1953) as reported by Krebs (1989, Table 2.1).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Gerking
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>C</dt><dd><p>column of number of captures (column names is unnecessary).</p>
</dd>
<dt>R</dt><dd><p>column of number of recaptures (column name is unnecessary).</p>
</dd>
<dt>nM</dt><dd><p>column of number of newly marked animal (column name is unnecessary).</p>
</dd>
</dl>



<h3>Source</h3>

<p>Krebs, C. J. 1989. <em>Ecological Methodologies</em>. Harper and Row, New York, NY. 654 p.</p>

<hr>
<h2 id='goosefish'>Mean Length and Numbers of Lengths for Northern Goosefish, 1963-2002</h2><span id='topic+goosefish'></span>

<h3>Description</h3>

<p>The <code>goosefish</code> data frame has 40 rows and 3 columns.
The mean lengths (mlen) by year and number (ss) of observations for length&gt;=smallest length at first capture (Lc)
for northern goosefish used in Gedamke and Hoenig (2006)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>goosefish
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>year</dt><dd><p>year code</p>
</dd>
<dt>mlen</dt><dd><p>mean length of goosefish, total length (cm)</p>
</dd>
<dt>ss</dt><dd><p>number of samples used to calculate mean length</p>
</dd>
</dl>



<h3>Source</h3>

<p>Gedamke, T. and J. M. Hoenig. 2006. Estimating mortality from mean length
data in nonequilibrium situations, with application to the assessment of goosefish. Trans. Am. Fish. Soc. 135:476-487</p>

<hr>
<h2 id='grotag'>
Maximum likelihood estimation of growth and growth variability from tagging data - Francis (1988)
</h2><span id='topic+grotag'></span>

<h3>Description</h3>

<p>This function estimates parameters of Francis (1988)'s growth model
using tagging data. The data are fitted using a constrained maximum
likelihood optimization performed by optim using the &quot;L-BFGS-B&quot; method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grotag(L1 = NULL, L2 = NULL, T1 = NULL, T2 = NULL, alpha = NULL, beta = NULL, 
 design = list(nu = 0, m = 0, p = 0, sea = 0), 
 stvalue = list(sigma = 0.9, nu = 0.4, m = -1, p = 0.1, u = 0.4, w = 0.4), 
 upper = list(sigma = 5, nu = 1, m = 2, p = 1, u = 1, w = 1), 
 lower = list(sigma = 0, nu = 0, m = -2, p = 0, u = 0, w = 0), gestimate = TRUE, 
 st.ga = NULL, st.gb = NULL, st.galow = NULL, st.gaup = NULL, st.gblow = NULL,
 st.gbup = NULL, control = list(maxit = 10000))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="grotag_+3A_l1">L1</code></td>
<td>
<p>Vector of length at release of tagged fish</p>
</td></tr>
<tr><td><code id="grotag_+3A_l2">L2</code></td>
<td>
<p>Vector of length at recovery of tagged fish</p>
</td></tr>
<tr><td><code id="grotag_+3A_t1">T1</code></td>
<td>
<p>Vector of julian time at release of tagged fish</p>
</td></tr>
<tr><td><code id="grotag_+3A_t2">T2</code></td>
<td>
<p>Vector of julian time at recovery of tagged fish</p>
</td></tr>
<tr><td><code id="grotag_+3A_alpha">alpha</code></td>
<td>
<p>Numeric value giving an arbitrary length alpha</p>
</td></tr>
<tr><td><code id="grotag_+3A_beta">beta</code></td>
<td>
<p>Numeric value giving an arbitrary length beta (<code>beta</code> &gt; <code>alpha</code>)</p>
</td></tr>
<tr><td><code id="grotag_+3A_design">design</code></td>
<td>
<p>List specifying the design of the model to estimate. Use 1 to designate whether 
a parameter(s) should be estimated. Type of parameters are: nu=growth variability (1 parameter), 
m=bias parameter of measurement error (1 parameter), p=outlier probability (1 parameter), 
and sea=seasonal variation (2 parameters: u and w).  Model 1 of Francis is the default 
settings of 0 for nu, m, p and sea.</p>
</td></tr>
<tr><td><code id="grotag_+3A_stvalue">stvalue</code></td>
<td>
<p>Starting values of sigma (s) and depending on
the design argument, nu, m, p, u, and w used as input in the nonlinear estimation
(function <em>optim</em>) routine.</p>
</td></tr>
<tr><td><code id="grotag_+3A_upper">upper</code></td>
<td>
<p>Upper limit of the model parameters' (nu, m, p, u, and w) region to be investigated.</p>
</td></tr>
<tr><td><code id="grotag_+3A_lower">lower</code></td>
<td>
<p>Lower limit of the model parameters' (nu, m, p, u, and w) region to be investigated.</p>
</td></tr>
<tr><td><code id="grotag_+3A_gestimate">gestimate</code></td>
<td>
<p>Logical specifying whether starting values of ga and gb (growth increments of alpha and beta) 
should be estimated automatically.  Default = TRUE.</p>
</td></tr>
<tr><td><code id="grotag_+3A_st.ga">st.ga</code></td>
<td>
<p>If gestimate=FALSE, user-specified starting value for ga.</p>
</td></tr>
<tr><td><code id="grotag_+3A_st.gb">st.gb</code></td>
<td>
<p>If gestimate=FALSE, user-specified starting value for gb.</p>
</td></tr>
<tr><td><code id="grotag_+3A_st.galow">st.galow</code></td>
<td>
<p>If gestimate=FALSE, user-specified lower limit for st.ga used in optimization.</p>
</td></tr>
<tr><td><code id="grotag_+3A_st.gaup">st.gaup</code></td>
<td>
<p>If gestimate=FALSE, user-specified upper limit for st.ga used in optimization.</p>
</td></tr>
<tr><td><code id="grotag_+3A_st.gblow">st.gblow</code></td>
<td>
<p>If gestimate=FALSE, user-specified lower limit for st.gb used in optimization.</p>
</td></tr>
<tr><td><code id="grotag_+3A_st.gbup">st.gbup</code></td>
<td>
<p>If gestimate=FALSE, user-specified upper limit for st.gb used in optimization.</p>
</td></tr>
<tr><td><code id="grotag_+3A_control">control</code></td>
<td>
<p>Additional controls passed to the optimization function <em>optim</em>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The methods of Francis (1988) are used on tagging data to the estimate of growth and growth variability.  
The estimation of all models discussed is allowed.  The growth variability defined by equation 5 
in the reference is used throughout.  
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>table</code></td>
<td>
<p>list element containing the model output similar to Table 3 of Francis (1988).  
The Akaike's Information Criterion (AIC) is also added to the output.</p>
</td></tr>
<tr><td><code>VBparms</code></td>
<td>
<p>list element containing the conventional paramaters of the von
Bertalanffy model (Linf and K).</p>
</td></tr>  
<tr><td><code>correlation</code></td>
<td>
<p>list element containing the parameter correlation matrix.</p>
</td></tr>
<tr><td><code>predicted</code></td>
<td>
<p>list element containing the predicted values from the model.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>list element containing the residuals of the model fit.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a>
Marco Kienzle <a href="mailto:Marco.Kienzle@gmail.com">Marco.Kienzle@gmail.com</a>
</p>


<h3>References</h3>

<p>Francis, R.I.C.C., 1988. Maximum likelihood estimation of growth and growth variability 
from tagging data. New Zealand Journal of Marine and Freshwater Research, 22, p.42-51. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+grotagplus">grotagplus</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bonito)

#Model 4 of Francis (1988)
with(bonito,
 grotag(L1=L1, L2=L2, T1=T1, T2=T2,alpha=35,beta=55,
 	design=list(nu=1,m=1,p=1,sea=1),
 	stvalue=list(sigma=0.9,nu=0.4,m=-1,p=0.2,u=0.4,w=0.4),
 	upper=list(sigma=5,nu=1,m=2,p=0.5,u=1,w=1),
 	lower=list(sigma=0,nu=0,m=-2,p=0.0,u=0,w=0),control=list(maxit=1e4)))
</code></pre>

<hr>
<h2 id='grotagplus'>
Flexible maximum likelihood estimation of growth from multiple tagging datasets.
</h2><span id='topic+grotagplus'></span>

<h3>Description</h3>

<p>This is an extension of fishmethods function grotag to allow a wider
variety of growth models and also the simultaneous analysis
of multiple tagging datasets with parameter sharing between
datasets (see Details).
</p>
<p>As in grotag, the data are fitted using a constrained maximum
likelihood optimization performed by optim using the &quot;L-BFGS-B&quot; method.
Estimated parameters can include galpha, gbeta (mean annual growth at reference
lengths alpha and beta); b (a curvature parameter for the Schnute
models); Lstar (a transitional length for the asymptotic model); m, s (mean and
s.d. of the measurement error for length increment); nu, t (growth
variability); p (outlier probability); u, w (magnitude and phase of
seasonal growth).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grotagplus(tagdata, dataID=NULL,alpha, beta = NULL,
 model=list(mean="Francis",var="linear",seas="sinusoid"),
 design, stvalue, upper, lower,fixvalue=NULL,
 traj.Linit=c(alpha,beta),control = list(maxit = 10000), debug = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="grotagplus_+3A_tagdata">tagdata</code></td>
<td>
<p>Dataframe with components L1, L2 (lengths at release
and recovery of tagged fish), T1, T2 (julian times (y) at
release and recovery), and (optionally), a numeric or character
vector (named by argument <code>dataID</code>) identifying which
dataset each data record belongs to (with n datasets this must
include n unique values). Other components are ignored, as are any records with missing
values in the required components.</p>
</td></tr>
<tr><td><code id="grotagplus_+3A_dataid">dataID</code></td>
<td>
<p>Name of optional component of tagdata identifying separate
datasets within tagdata.  The default <code>dataID</code>=NULL means
there is no such component (so there is only one dataset).</p>
</td></tr>
<tr><td><code id="grotagplus_+3A_alpha">alpha</code></td>
<td>
<p>Numeric value giving an arbitrary length alpha.</p>
</td></tr>
<tr><td><code id="grotagplus_+3A_beta">beta</code></td>
<td>
<p>Numeric value giving an arbitrary length beta
(must have <code>beta</code> &gt; <code>alpha</code>).</p>
</td></tr>
<tr><td><code id="grotagplus_+3A_model">model</code></td>
<td>
<p>List with components mean, var, seas, specifying which
model equations to use for the mean (or expected) growth,
individual variability in growth, and seasonal variation in
growth (see Details for valid values). The default is that of
model 4 in Francis (1988).</p>
</td></tr>
<tr><td><code id="grotagplus_+3A_design">design</code></td>
<td>
<p>List specifying the design of the estimation: which
parameters are estimated, and whether multiple values are estimated.
There should be one component for each parameter of the model
specified by <code>model</code>.  Each component must be
either 0 (not estimated), 1 (same parameter value estimated for all data),
or, when there are multiple datasets, a list in which each
component is a sub-vector of unique(tagdata[[dataID]]) and all
members of unique(tagdata[[dataID]]) occur in one and only one
component of the list (e.g., galpha=list(&quot;Area2&quot;,c(&quot;Area1&quot;, &quot;Area3&quot;) )
means that two values of galpha are to be estimated: one applying to
the dataset Area2, and the other to datasets Area1 and Area3).</p>
</td></tr>
<tr><td><code id="grotagplus_+3A_stvalue">stvalue</code></td>
<td>
<p>List containing starting values of estimated parameters,
used as input in the nonlinear estimation
(function <em>optim</em>) routine. There should be one component
for each estimated parameter (except, optionally, galpha and gbeta).
Each component should be either a single number or a vector whose
length is the number of separate values of that parameter
(as specified in <code>design</code>). In the latter case,
the order of the parameter values should correspond to that in
<code>design</code> (e.g., if design$galpha is as above and
<code>stvalue</code>$galpha=c(10,15) then 10 will apply to Area2 and
15 to Area1 &amp; Area3).  If galpha or gbeta are omitted from stvalue then
their starting values are calculated from the data.</p>
</td></tr>
<tr><td><code id="grotagplus_+3A_lower">lower</code></td>
<td>
<p>Lists containing lower limits for each parameter,
with structure as for <code>stvalue</code>. galpha and/or gbeta may be omitted
if they don&quot;t appear in <code>stvalue</code>.</p>
</td></tr>
<tr><td><code id="grotagplus_+3A_upper">upper</code></td>
<td>
<p>Lists containing upper limits for each parameter,
with structure as for <code>stvalue</code>. galpha and/or gbeta may be omitted
if they don&quot;t appear in <code>stvalue</code>.</p>
</td></tr>
<tr><td><code id="grotagplus_+3A_fixvalue">fixvalue</code></td>
<td>
<p>Optional list containing fixed values for parameters that
are needed (according to <code>model</code>) but are not being
estimated (according to <code>design</code>) and do not have default
values (the only default parameter values are nu = 0, m = 0, p = 0). 
The list should have one named component for each fixed
parameter.  Usually, each component will be a single number. See
example below for the required format when a fixed parameter
takes  different values for different datasets.</p>
</td></tr>
<tr><td><code id="grotagplus_+3A_traj.linit">traj.Linit</code></td>
<td>
<p>Vector of initial length(s) for output growth trajectories.
Default is c(alpha,beta).</p>
</td></tr>
<tr><td><code id="grotagplus_+3A_control">control</code></td>
<td>
<p>Additional controls passed to the optimization function
<em>optim</em>.</p>
</td></tr>
<tr><td><code id="grotagplus_+3A_debug">debug</code></td>
<td>
<p>output debugging information.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>Valid values of model$mean are
<code>"Francis"</code> as in Francis (1988).
<code>"Schnute"</code> as in Francis (1995).
<code>"Schnute.aeq0"</code> special case of Schnute - see equns (5.3), (5.4)
of Francis (1995).
<code>"asymptotic"</code> as in Cranfield et al. (1996).
</p>
<p>Valid values of model$var are
<code>"linear"</code> as used in the example in Francis(1988) - see equn
(5).
<code>"capped"</code> as in equn (6) of Francis(1988).
<code>"exponential"</code> as in equn (7) of Francis(1988).
</p>
<p><code>"asymptotic"</code> as in equn (8) of Francis(1988).
<code>"least-squares"</code> ignore individual variability and fit data by
least-squares, as in Model 1 of Francis(1988).  
</p>
<p>Valid values of model$seas are
<code>"sinusoid"</code> as in model 4 of Francis(1988).
<code>"switched"</code> as in Francis &amp; Winstanley (1989).
<code>"none"</code> as in all but model 4 of Francis(1988).
</p>
<p>The option of multiple data sets with parameter sharing is intended to
allow for the situation where we wish to estimate different mean
growth for two or more datasets but can reasonably assume that
other parameters (e.g., for growth variability, measurement error,
outlier contamination) are the same for all datasets.
This should produces stronger estimates of these other parameters.
For example, Francis &amp; Francis (1992) allow growth to differ by sex, and
in Francis &amp; Winstanley (1989) it differs by stock and/or habitat.
</p>
<p><code>grotagplus</code> may fail if parameter starting values are too distant from
their true value, or if parameter bounds are too wide.  Try changing
these values.  Sometimes reasonable starting values can be found by
fitting the model with other parameters fixed at plausible values. 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>parest</code></td>
<td>
<p>Parameter estimates and their s.e.s.</p>
</td></tr>
<tr><td><code>parfix</code></td>
<td>
<p>Parameter values, if any, fixed by user.</p>
</td></tr>
<tr><td><code>correlations</code></td>
<td>
<p>Correlations between parameter estimates. When
there are multiple estimates of a parameter these are numbered
by their ordering in argument <code>design</code>, so in example given
above galpha1 would apply to Area1, and galpha2 to Area2 and Area3.</p>
</td></tr>
<tr><td><code>stats</code></td>
<td>
<p>Negative log-likelihood and AIC statistic.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>The three components of the grotagplus argument model.</p>
</td></tr>
<tr><td><code>datasetnames</code></td>
<td>
<p>The dataset names, if there are multiple datasets.</p>
</td></tr>
<tr><td><code>pred</code></td>
<td>
<p>Dataframe of various predicted quantities need for
residual plots - one row per data record.</p>
</td></tr>
<tr><td><code>Linf.k</code></td>
<td>
<p>Values of parameters Linf and k as calculated between
equations (1) and (2) of Francis (1988) (but not possible for the
Schnute model).  These are provided for computational convenience
only; they are not comparable with Linf and k estimated from
age-length data. Comparisons of growth estimates from tagging
and age-length data are better done using output <code>meananngrowth</code>.</p>
</td></tr>
<tr><td><code>meananngrowth</code></td>
<td>
<p>Data for plot of mean annual growth vs length,
as in Fig. 8 of Francis and Francis (1992).</p>
</td></tr>
<tr><td><code>traj</code></td>
<td>
<p>Data for plots of growth trajectories like Fig. 2 of
Francis (1988).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Chris Francis <a href="mailto:chrisfrancis341@gmail.com">chrisfrancis341@gmail.com</a>
</p>
<p>Marco Kienzle <a href="mailto:Marco.Kienzle@gmail.com">Marco.Kienzle@gmail.com</a>
</p>
<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a>
</p>


<h3>References</h3>

 <p><code>1</code> Francis, R.I.C.C., 1988. Maximum likelihood estimation of
growth and growth variability from tagging data.
New Zealand Journal of Marine and Freshwater Research, 22, p.42-51.
</p>
<p><code>2</code> Cranfield, H.J., Michael, K.P., and Francis, R.I.C.C. 1996.
Growth rates of five species of subtidal clam on a beach in the South
Island, New Zealand.  Marine and Freshwater Research 47: 773-784.
</p>
<p><code>3</code> Francis, R.I.C.C. 1995.  An alternative mark-recapture analogue
of Schnute&quot;s growth model.  Fisheries Research 23: 95-111.
</p>
<p><code>4</code> Francis, R.I.C.C. and Winstanley, R.H. 1989. Differences in
growth rates between habitats of southeast Australian snapper
(Chrysophrys auratus). Australian Journal of Marine &amp; Freshwater
Research 40: 703-710.
</p>
<p><code>5</code> Francis, M.P. and Francis, R.I.C.C. 1992.  Growth rate
estimates for New Zealand rig (Mustelus lenticulatus).  Australian
Journal of Marine and Freshwater Research 43: 1157-1176. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.grotagplus">plot.grotagplus</a></code> <code><a href="#topic+print.grotagplus">print.grotagplus</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#Model 4 of Francis (1988)
data(bonito)
grotagplus(bonito,alpha=35,beta=55,
               design=list(galpha=1,gbeta=1,s=1,nu=1,m=1,p=1,u=1,w=1),
               stvalue=list(s=0.81,nu=0.3,m=0,p=0.01,u=0.5,w=0.5),
               upper=list(s=3,nu=1,m=2,p=0.1,u=1,w=1),
               lower=list(s=0.1,nu=0.1,m=-2,p=0,u=0,w=0))

#Model 1 of Francis (1988), using least-squares fit
grotagplus(bonito,alpha=35,beta=55,
               model=list(mean="Francis",var="least-squares",seas="none"),
               design=list(galpha=1,gbeta=1,s=1,p=0),
               stvalue=list(s=1.8),upper=list(s=3),lower=list(s=1))

#Paphies donacina model in Table 4 of Cranfield et al (1996) with
#asymptotic model
data(P.donacina)
grotagplus(P.donacina,alpha=50,beta=80,
       model=list(mean="asymptotic",var="linear",seas="none"),
       design=list(galpha=1,gbeta=1,Lstar=0,s=1,nu=0,m=0,p=0),
       stvalue=list(galpha=10,gbeta=1.5,s=2),
       upper=list(galpha=15,gbeta=2.7,s=4),
       lower=list(galpha=7,gbeta=0.2,s=0.5),
       fixvalue=list(Lstar=80))

#Paphies donacina model in Table 4 of Cranfield et al (1996) with
#asymptotic model
data(P.donacina)
grotagplus(P.donacina,alpha=50,beta=80,
       model=list(mean="asymptotic",var="linear",seas="none"),
       design=list(galpha=1,gbeta=1,Lstar=0,s=1,nu=0,m=0,p=0),
       stvalue=list(galpha=10,gbeta=1.5,s=2),
       upper=list(galpha=15,gbeta=2.7,s=4),
       lower=list(galpha=7,gbeta=0.2,s=0.5),
       fixvalue=list(Lstar=80))

# Model 4 fit from Francis and Francis (1992) with different growth by sex
data(rig)
grotagplus(rig,dataID="Sex",alpha=70,beta=100,
           model=list(mean="Francis",var="linear",seas="none"),
          design=list(galpha=list("F","M"),gbeta=list("F","M"),s=1,nu=1,m=0,p=0),
          stvalue=list(galpha=c(5,4),gbeta=c(3,2),s=2,nu=0.5),
          upper=list(galpha=c(8,6),gbeta=c(5,4),s=4,nu=1),
          lower=list(galpha=c(3,2),gbeta=c(1.5,1),s=0.5,nu=0.2))

#Example where all parameters are fixed 
# to the values estimated values for model 4 of Francis and Francis (1992)]
grotagplus(rig,dataID="Sex",alpha=70,beta=100,
          model=list(mean="Francis",var="linear",seas="none"),
          design=list(galpha=0,gbeta=0,s=0,nu=0,m=0,p=0),
          stvalue=list(),upper=list(),lower=list(),
          fixvalue=list(galpha=list(design=list("F","M"),value=c(5.87,3.67)),
          gbeta=list(design=list("F","M"),value=c(2.52,1.73)),s=1.57,nu=0.58))
</code></pre>

<hr>
<h2 id='growhamp'>
von Bertalanffy Growth Models for Tagging Data Incorporating Individual Variation  
</h2><span id='topic+growhamp'></span>

<h3>Description</h3>

<p>Function fits growth models of Hampton (1991) to length and time-at-large data from tagging studies 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>growhamp(L1 = NULL, L2 = NULL, TAL = NULL, 
models = c(1, 2, 3, 4, 5, 6, 7), 
method = c("Nelder-Mead", "Nelder-Mead", "Nelder-Mead",
 "Nelder-Mead", "Nelder-Mead", "Nelder-Mead", "Nelder-Mead"), 
varcov = c(TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE), 
Linf = list(startLinf = NULL, lowerLinf = NULL, upperLinf = NULL), 
K = list(startK = NULL, lowerK = NULL, upperK = NULL), 
sigma2_error = list(startsigma2 = NULL, lowersigma2 = NULL, uppersigma2 = NULL), 
sigma2_Linf = list(startsigma2 = NULL, lowersigma2 = NULL, uppersigma2 = NULL),
sigma2_K = list(startsigma2 = NULL, lowersigma2 = NULL, uppersigma2 = NULL), 
mu_measure = 0, sigma2_measure = 0, 
control = list(maxit = 1000))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="growhamp_+3A_l1">L1</code></td>
<td>

<p>Vector of release lengths. Each row presents the length of an individual.
</p>
</td></tr>
<tr><td><code id="growhamp_+3A_l2">L2</code></td>
<td>

<p>Vector of recapture lengths.
</p>
</td></tr>
<tr><td><code id="growhamp_+3A_tal">TAL</code></td>
<td>

<p>vector of associated time-at-large data. Calculated as the recapture date minus release date.
</p>
</td></tr>
<tr><td><code id="growhamp_+3A_models">models</code></td>
<td>

<p>The models to fit. 1 = Faber model, 2 = Kirkwood and Somers model, 3 = Kirkwood and Somers model with model error, 4 = Kirkwood and Somers model with model and release-length-measurement error, 5 = Sainsbury model, 6 = Sainsbury model with model error, and 7 = Sainsbury model with model and release-length-measurement error.  Default is all: c(1,2,3,4,5,6,7).
</p>
</td></tr>
<tr><td><code id="growhamp_+3A_method">method</code></td>
<td>

<p>Character vector of optimization methods used in <code>optim</code> to solve parameters for each model. A different method can be selected for each model. Choices are &quot;Nelder-Mead&quot;,&quot;BFGS&quot;,&quot;CG&quot;,&quot;L-BFGS-B&quot; and &quot;SANN&quot;. See help for <code>optim</code>. Default is &quot;Nelder-Mead&quot;. If there are fewer values specified in <code>method</code> than the number specified in <code>models</code>, a warning message is produced and the last value in the <code>method</code> vector is used for the remaining models.  
</p>
</td></tr>
<tr><td><code id="growhamp_+3A_varcov">varcov</code></td>
<td>

<p>Logical vector specifying whether the parameter variance-covariance matrix of each model should be outputted. A different logical can specified for each model. If there are fewer values specified in <code>varcov</code> than the number specified in <code>models</code>, a warning message is produced and the last value in the <code>varcov</code> vector is used for the remaining models.  
</p>
</td></tr>
<tr><td><code id="growhamp_+3A_linf">Linf</code></td>
<td>

<p>A list of starting (startLinf), lower bound (lowerLinf) and upper bound (upperLinf) of Linfinity of the von Bertalanffy equation used in the optimization. The lower and upper bounds are used only with method &quot;L-BFGS-B&quot;.
</p>
</td></tr>
<tr><td><code id="growhamp_+3A_k">K</code></td>
<td>

<p>A list of starting (startK), lower bound (lowerK) and upper bound (upperK) of K (growth coefficient) of the von Bertalanffy equation used in the optimization.
The lower and upper bounds are used only with method &quot;L-BFGS-B&quot;.
</p>
</td></tr>
<tr><td><code id="growhamp_+3A_sigma2_error">sigma2_error</code></td>
<td>

<p>A list of starting (startsigma2), lower bound (lowersigma2) and upper bound (uppersigma2) of the error variance used in the optimization. The lower and upper bounds are used only with method &quot;L-BFGS-B&quot;. This parameter is used in models 1,3,4,6 and 7.
</p>
</td></tr>
<tr><td><code id="growhamp_+3A_sigma2_linf">sigma2_Linf</code></td>
<td>

<p>A list of starting (startsigma2), lower bound (lowersigma2) and upper bound (uppersigma2) of the Linfinity variance used in the optimization. The lower and upper bounds are used only with method &quot;L-BFGS-B&quot;. This parameter is used in models 2,3,4,5,6,and 7.
</p>
</td></tr>
<tr><td><code id="growhamp_+3A_sigma2_k">sigma2_K</code></td>
<td>

<p>A list of starting (startsigma2), lower bound (lowersigma2) and upper bound (uppersigma2) of the K (growth coefficient) variance used in the optimization. The lower and upper bounds are used only with method &quot;L-BFGS-B&quot;. This parameter is used in models 5,6, and 7.
</p>
</td></tr>
<tr><td><code id="growhamp_+3A_mu_measure">mu_measure</code></td>
<td>

<p>Release measurement error. This parameter is used in models 4 and 7.
Default=0.
</p>
</td></tr>
<tr><td><code id="growhamp_+3A_sigma2_measure">sigma2_measure</code></td>
<td>

<p>Variance of release measurement error.  This parameter is used in models 4 and 7.
Default=0.
</p>
</td></tr>
<tr><td><code id="growhamp_+3A_control">control</code></td>
<td>

<p>A list of control parameters for <code>optim</code>. See function <code>optim</code> for details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The seven models are fitted by maximum likelihood using formulae shown in Hampton 1991. Due to the number of parameters estimated, some models can be sensitive to the initial starting values. It is recommended that the starting values are tested for sensitivity to ensure the global minimum has been reached. Sometimes, the hessian matrix, which is inverted to obtain the variance-covariance matrix, will not be positive, definite and therefore will produce an error. Again, try different starting values for parameters and lower and upper bounds if applicable. 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>results</code></td>
<td>
<p>list element containing the parameter estimates in table format for each model. Column names are <code>model</code>, <code>Linf</code>, <code>K</code>, <code>s2Linf</code> (variance of Linf), <code>s2K</code> (variance of K), <code>s2error</code> (error variance), <code>boundary</code> (0 = no issues; 1 = one or more parameter estimates are at constraint boundaries), <code>-Log Likelihood</code>, <code>AIC</code> (Akaike's Information Criterion, and <code>method</code>
</p>
</td></tr>
<tr><td><code>varcov</code></td>
<td>
<p>if varcov=TRUE, list element containing the variance-covariance matrix for each model.</p>
</td></tr>  
<tr><td><code>residuals</code></td>
<td>
<p>list element containing the residuals (observed-predicted values) for each model.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Hampton, J. 1991. Estimation of southern bluefin tuna Thunnus maccoyii growth parameters from tagging data, using von Bertalanffy models incorporating individual variation. U. S. Fishery Bulletin 89: 577-590.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mort.al">mort.al</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Models 1,2 and 3 below are models 1,2, and 4 in Table 4.17 of ##Quinn and Deriso 
data(trout)
growhamp(L1=trout$L1,L2=trout$L2,TAL=trout$dt,models=c(1,2,3),
       method=c("Nelder-Mead","Nelder-Mead","L-BFGS-B"),
       varcov=c(TRUE,TRUE,TRUE),
       Linf=list(startLinf=650,lowerLinf=400,upperLinf=800),       
       K=list(startK=0.30,lowerK=0.01,upperK=1),
       sigma2_error=list(startsigma2=100,lowersigma2=0.1,uppersigma2=10000),
       sigma2_Linf=list(startsigma2=100,lowersigma2=0.1,uppersigma2=100000),	
       sigma2_K=list(startsigma2=0.5,lowersigma2=1e-8,uppersigma2=10))

## End(Not run)
</code></pre>

<hr>
<h2 id='growth'>Fitting Growth Curves to Length- or Weight-at-Age Data</h2><span id='topic+growth'></span>

<h3>Description</h3>

<p>Fits three growth models to length and weight-at-age data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>growth(intype=1,unit=1,size=NULL,age=NULL,calctype=1,wgtby=1,se2=NULL,error=1, 
      specwgt=0.0001,Sinf=NULL,K=NULL,t0=NULL,B=3,graph=TRUE,
         control=list(maxiter=10000,minFactor=1/1024,tol=1e-5))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="growth_+3A_intype">intype</code></td>
<td>
<p>the input format: 1= individual size data; 2 = mean size data. Default intype=1.</p>
</td></tr>
<tr><td><code id="growth_+3A_unit">unit</code></td>
<td>
<p>the size unit: 1= length; 2 = weight. Default unit=1.</p>
</td></tr>
<tr><td><code id="growth_+3A_size">size</code></td>
<td>
<p>the vector of size (length or weight) data.</p>
</td></tr>
<tr><td><code id="growth_+3A_age">age</code></td>
<td>
<p>the vector of ages associated with the size vector.</p>
</td></tr>
<tr><td><code id="growth_+3A_calctype">calctype</code></td>
<td>
<p>if intype=1, 1 = use individual size data; 2 = calculate mean size from individual size data. Default calctype=1.</p>
</td></tr>
<tr><td><code id="growth_+3A_wgtby">wgtby</code></td>
<td>
<p>weighting scheme: 1 = no weighting; 2 = weight means by inverse variance. Weighting of individual data points is not allowed. Default wgtby=1.</p>
</td></tr>
<tr><td><code id="growth_+3A_se2">se2</code></td>
<td>
<p>if intype=2 and wgtby=2, specify vector of variances (SE^2) associated with mean size-at-age data.</p>
</td></tr>
<tr><td><code id="growth_+3A_error">error</code></td>
<td>
<p>the error structure: 1 = additive; 2 = multiplicative. Default error=1.</p>
</td></tr>
<tr><td><code id="growth_+3A_specwgt">specwgt</code></td>
<td>
<p>if <em>intype</em>=1 and <em>wgtby</em>=2, the weight value to use for cases        where var=0 or only one individual is available at a given age.</p>
</td></tr>
<tr><td><code id="growth_+3A_sinf">Sinf</code></td>
<td>
<p>the starting value for <em>L-infinity or W-infinity</em> of the growth models. Required.</p>
</td></tr>
<tr><td><code id="growth_+3A_k">K</code></td>
<td>
<p>the starting value for <em>K</em> of the growth models.</p>
</td></tr>
<tr><td><code id="growth_+3A_t0">t0</code></td>
<td>
<p>the starting value for <em>t0</em> of the growth models.</p>
</td></tr>
<tr><td><code id="growth_+3A_b">B</code></td>
<td>
<p>the length-weight equation exponent used in the von Bertalanffy growth model for weight. Default B=3.</p>
</td></tr>
<tr><td><code id="growth_+3A_graph">graph</code></td>
<td>
<p>logical value specifying if fit and residual plots should be drawn. Default graph = TRUE.</p>
</td></tr>
<tr><td><code id="growth_+3A_control">control</code></td>
<td>
<p>see function <em>nls</em>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Three growth models (von Bertalanffy, Gompert and logistic) are fitted to length- or weight-at-age data using nonlinear least-squares (function <em>nls</em>).
If individual data are provided, mean size data can be calculated by specifying <em>calctype</em>=2. When fitting mean size data, 
observations can be weighted by the inverse sample variance(<em>wgtby</em>=2), resulting in weighted nonlinear least squares. Additive or multiplicative 
error structures are specified via <em>error</em>.  See page 135 in Quinn and Deriso (1999) for more information on error structures. 
</p>
<p>If unit is weight,  
the exponent for the von Bertalanffy growth in weight model is not estimated and must be specified (<em>B</em>).
</p>
<p>Plots of model fit and residuals are generated unless <em>graph</em>=FALSE.   
</p>


<h3>Value</h3>

<p>List containing list elements of the equation/structure and <em>nls</em> output for each model.
Information from <em>nls</em> output can be extracted using standard functions (e.g., <em>summary()</em>).
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Quinn, T. J. and R. B. Deriso. 1999. Quantitative fish dynamics. Oxford University Press. 542 pages. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(pinfish)
growth(intype=1,unit=1,size=pinfish$sl,age=pinfish$age,
        calctype=1,wgtby=1,error=1,Sinf=200,K=0.3,t0=-1)
</code></pre>

<hr>
<h2 id='growth_LEP'>
A flexible maximum likelihood approach for fitting growth curves to tag-recapture data
</h2><span id='topic+growth_LEP'></span>

<h3>Description</h3>

<p>Estimation of von Bertanffy growth parameters from tag-recapture data (Laslett et al. 2002)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>growth_LEP(l1=NULL,l2=NULL,dt=NULL,measurer = NULL,
           gmodel=1,use_parameter_boundaries=T,graphs=T,
           K_start_bounds=list(K1=NULL,lower_K1=0,upper_K1=Inf,
                 K2=NULL,lower_K2=0,upper_K2=Inf), 
           mu_Linf_start_bounds=list(mu_Linf=NULL,lower_mu_Linf=0,upper_mu_Linf=Inf,
                 sigma_mu_Linf=NULL, lower_sigma_mu_Linf=0,upper_sigma_mu_Linf=Inf),
           A_start_bounds=list(mean_age=NULL,lower_mean_age=0,upper_mean_age=Inf,
                 sigma_age=NULL,lower_sigma_age=0,upper_sigma_age=Inf),
           resid_error_start_bounds=list(sigma_resid=NULL,lower_sigma_resid=0,
                  upper_sigma_resid=Inf),
            measurer_error_start_bounds=list(use_measurer=F,sigma_measure=NULL,
                  lower_sigma_measure=0,upper_sigma_measure=Inf),
           vb_log_k_parms=list(alpha=NULL,lower_alpha=0,upper_alpha=Inf,fix_beta=T,
                 beta=NULL,lower_beta=0,upper_beta=Inf),
           nlminb.control=list(eval.max=10000,iter.max=10000,trace=10),
           tmb.control=list(maxit=10000,trace=FALSE))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="growth_LEP_+3A_l1">l1</code></td>
<td>
<p>vector of release lengths of tagged fish.</p>
</td></tr>
<tr><td><code id="growth_LEP_+3A_l2">l2</code></td>
<td>
<p>vector of recapture lengths.</p>
</td></tr>
<tr><td><code id="growth_LEP_+3A_dt">dt</code></td>
<td>
<p>vector of time increment between tagging and recapture.</p>
</td></tr>
<tr><td><code id="growth_LEP_+3A_measurer">measurer</code></td>
<td>
<p>vector of integers specifying the recapturer type for each row: scientist = 0; fisherperson=1). Not required. Default = NULL.</p>
</td></tr>
<tr><td><code id="growth_LEP_+3A_gmodel">gmodel</code></td>
<td>
<p>model to fit. 1 = standard von Bertalannfy growth model; 2 = VB log k model of Laslett et al. (2002). Default=1</p>
</td></tr>
<tr><td><code id="growth_LEP_+3A_use_parameter_boundaries">use_parameter_boundaries</code></td>
<td>
<p>use parameter boundary values (T/F). Applies to all parameters estimated in the model. Default=T.</p>
</td></tr>
<tr><td><code id="growth_LEP_+3A_graphs">graphs</code></td>
<td>
<p>plot the observed values of l1 and l2 and the fitted growth curve model versus <em>Af</em>(the corrected measures of A; Lasett et al. 2004).  Residuals plots (observed versus fitted) are also provided.</p>
</td></tr>
<tr><td><code id="growth_LEP_+3A_k_start_bounds">K_start_bounds</code></td>
<td>
<p>list of starting values (K1 and K2), lower(lower_K1 and lower_K2) and upper (upper_K1 and upper_K2) parameter boundaries for K1 and K2. If gmodel = 1, only K1 values are used.</p>
</td></tr>
<tr><td><code id="growth_LEP_+3A_mu_linf_start_bounds">mu_Linf_start_bounds</code></td>
<td>
<p>list of starting, lower and upper boundary values for estimated parameters <em>mu_Linf</em> and <em>sigma_mu_Linf</em>.</p>
</td></tr>
<tr><td><code id="growth_LEP_+3A_a_start_bounds">A_start_bounds</code></td>
<td>
<p>list of starting, lower and upper boundaries values for estimated <em>mean_age</em>, and starting, lower and upper boundaries values for <em>sigma_age</em>, both used  to define the log-normal random effects distribution of A.</p>
</td></tr>
<tr><td><code id="growth_LEP_+3A_resid_error_start_bounds">resid_error_start_bounds</code></td>
<td>
<p>list of starting, lower and upper boundary values for the estimated residual (measurement) error parameter <em>sigma_resid</em></p>
</td></tr> 
<tr><td><code id="growth_LEP_+3A_measurer_error_start_bounds">measurer_error_start_bounds</code></td>
<td>
<p>list of starting, lower and upper boundary values for the estimated measurer error parameter <em>sigma_measure</em>.  Specify <em>use_measurer</em>=T to estimate the parameter.  Default is F.</p>
</td></tr>
<tr><td><code id="growth_LEP_+3A_vb_log_k_parms">vb_log_k_parms</code></td>
<td>
<p> If gmodel=2, a list of starting, lower and upper values for estimated parameters <em>alpha</em> and <em>beta</em>. To fix beta to a constant value, specify <em>fix_beta</em>=T and enter a fixed value in <em>beta</em></p>
</td></tr> 
<tr><td><code id="growth_LEP_+3A_nlminb.control">nlminb.control</code></td>
<td>
<p>controls for the <em>nlminb</em> function. See function <em>nlminb</em> for more information.</p>
</td></tr>
<tr><td><code id="growth_LEP_+3A_tmb.control">tmb.control</code></td>
<td>
<p>controls for the <em>TMB</em> function. See package <em>TMB</em> for more information.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The von Bertalanffy growth model or the VB log k model of Laslett et al. (2002) is fitted to tag release-capture lengths and times-at-a-large data following Laslett et al. (2002).
The distribution of A is assumed log-normal. 
In addition, adjustments are made to A (age) following Laslett et al. (2004) to correct bias which permits simple graphical checking of the fitted growth curve model. 
If argument <em>graph</em> = TRUE, plots of l1 and l2 observed versus predicted, and residuals are created for checking model fit.
Refer to Laslett et al. (2002) for more details.
</p>


<h3>Value</h3>

<p>List containing the parameter_estimates, AIC, random effects A, the original predicted values, the original model residuals, results of the adjustment of A (Af, predicted and residuals for l1 and l2 used for plotting (see Laslett et al., 2004)),
and convergence statistics (from nlminb; convergence=0 is successful convergence). 
</p>


<h3>Note</h3>

<p>Paige Eveson of CSIRO Marine Research kindly provided the R code for calculating <em>Af</em> based on Lasett et al., 2004.
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a>
</p>


<h3>References</h3>

<p>Lasett, G. M., J. P. Eveson and T. Polacheck. 2002. A flexible maximum likelihood approach for fitting growth curves to tag-recapture data.
Canadian Journal of Fisheries and Aquatic Sciences 59: 976-986.
</p>
<p>Lasett, G. M., J. P. Eveson and T. Polacheck. 2004. Estimating the age at capture in capture-recapture studies of fish growth. Australian and New Zealand Journal of Statistics 46: 59-66.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+growhamp">growhamp</a></code> <code><a href="#topic+grotag">grotag</a></code> <code><a href="#topic+grotagplus">grotagplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Not run: 
	data(lepdata)
  growth_LEP(l1=lepdata$l1,l2=lepdata$l2,dt=lepdata$dt,measurer=NULL,
               gmodel=1,use_parameter_boundaries=T,graphs=T,
               K_start_bounds=list(K1=0.2,lower_K1=0,upper_K1=Inf,K2=0.12,lower_K2=0,
                  upper_K2=Inf), 
               mu_Linf_start_bounds=list(mu_Linf=189.624,lower_mu_Linf=0,upper_mu_Linf=Inf,
                  sigma_mu_Linf=11.032,lower_sigma_mu_Linf=0, upper_sigma_mu_Linf=Inf),
               A_start_bounds=list(mean_age=1.76,lower_mean_age=0,upper_mean_age=Inf,
                   sigma_age=0.165,lower_sigma_age=0,upper_sigma_age=Inf),
               resid_error_start_bounds=list(sigma_resid=3.547,lower_sigma_resid=0,
                    upper_sigma_resid=Inf),
               measurer_error_start_bounds=list(use_measurer=F,sigma_measure=3.547,
                     lower_sigma_measure=0,upper_sigma_measure=Inf),
               vb_log_k_parms=list(alpha=2.955,lower_alpha=0,upper_alpha=Inf,fix_beta=T,
                      beta=30,lower_beta=0,upper_beta=30),
                      nlminb.control=list(eval.max=10000,iter.max=10000,trace=10),
                      tmb.control=list(maxit=10000,trace=FALSE))
 
## End(Not run)
</code></pre>

<hr>
<h2 id='growth_sel'>
Fitting a von Bertalanffy curve to length and age data biased by gear selectivity 
</h2><span id='topic+growth_sel'></span>

<h3>Description</h3>

<p>A von Bertalanffy growth curve is fitted to age and length data corrected for gear selectivity via the method of
Schueller et al. (2014). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>growth_sel(age = NULL, size = NULL, weights = NULL, minlimit = NULL, maxlimit = NULL,
 minmax = NULL, switch_varpar = 1, 
 Linf = list(init = 1000, lb = 100, ub = 2000, prior.mean = 1000, prior.var = -0.5,
 prior.pdf = 1), 
 K = list(init = 0.3, lb = 0.1, ub = 0.9, prior.mean = 0.3, prior.var = -0.05,
 prior.pdf = 1), 
 t0 = list(init = -0.5, lb = -2, ub = -1e-04, prior.mean = -0.5, prior.var = -0.5,
 prior.pdf = 1), 
 varpar = list(init = 50, lb = 10, ub = 100, prior.mean = 5, prior.var = -1,
 prior.pdf = 1),
 tmb.control = list(maxit = 5000, trace = F),
 nlminb.control = list(eval.max = 1e+05, iter.max = 1000),
 species_info = list(species = NULL, size_units = NULL))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="growth_sel_+3A_age">age</code></td>
<td>
<p>a vector of ages.</p>
</td></tr>
<tr><td><code id="growth_sel_+3A_size">size</code></td>
<td>
<p>a vector of body sizes associated with the age data.</p>
</td></tr>
<tr><td><code id="growth_sel_+3A_weights">weights</code></td>
<td>
<p>a vector of observation weights associated with length data and used to produce weighted likelihood. 
Set to 1 for unweighted likelihood.</p>
</td></tr>
<tr><td><code id="growth_sel_+3A_minlimit">minlimit</code></td>
<td>
<p>a single value or vector associated with the length data. If a single value, a vector the length of the age vector is produced.</p>
</td></tr>
<tr><td><code id="growth_sel_+3A_maxlimit">maxlimit</code></td>
<td>
<p>a single value or vector associated with the length data. If a single value, a vector the length of the age vector is produced.</p>
</td></tr>
<tr><td><code id="growth_sel_+3A_minmax">minmax</code></td>
<td>
<p>a vector of 1 and 2s indicating whether the data row is being applied to the minimum (1) or maximum part (2) of the likelihood. 
In general, the break between a 1 and 2 would be the age that has the fullest distribution of length (a well sampled age class where 
no bias correction is expected).</p>
</td></tr>
<tr><td><code id="growth_sel_+3A_switch_varpar">switch_varpar</code></td>
<td>
<p>estimated variance parameter: 1 = standard deviation (sigma),  
2 = CV (sigma / mean), 3 = variance to mean ratio (sigma^2/mean)</p>
</td></tr>
<tr><td><code id="growth_sel_+3A_linf">Linf</code></td>
<td>
<p>list specifying the initial starting value (<em>init</em>) of L-infinity, the parameter's lower (<em>lb</em>) and upper bounds (<em>ul</em>)
for box constraints, prior mean (<em>prior.mean</em>), prior variance (<em>prior.variance</em>) and prior distribution (<em>pdf</em>). 
<em>pdf</em>: 1 = prior not used, 2 = lognormal, 3 = normal, 4 = beta.</p>
</td></tr>
<tr><td><code id="growth_sel_+3A_k">K</code></td>
<td>
<p>list specifying same arguments for <em>K</em> as <em>Linf</em>.</p>
</td></tr>
<tr><td><code id="growth_sel_+3A_t0">t0</code></td>
<td>
<p>list specifying same arguments for <em>t0</em> as <em>Linf</em>.</p>
</td></tr>
<tr><td><code id="growth_sel_+3A_varpar">varpar</code></td>
<td>
<p>list specifying same arguments for the estimated variance parameter (<em>varpar</em>) as <em>Linf</em>.</p>
</td></tr>
<tr><td><code id="growth_sel_+3A_tmb.control">tmb.control</code></td>
<td>
<p>controls for the <em>MakeADFun</em> function. See package <em>TMB</em> for more information.</p>
</td></tr>
<tr><td><code id="growth_sel_+3A_nlminb.control">nlminb.control</code></td>
<td>
<p>controls for the <em>nlminb</em> function. See function <em>nlminb</em> for more information.</p>
</td></tr>
<tr><td><code id="growth_sel_+3A_species_info">species_info</code></td>
<td>
<p>list specifying the species analyzed (<em>species</em>) and units of the size measurements (<em>size_units</em>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The von Bertalanffy growth model <em>Lage=Linf*(1-exp(-K*(age-t0))</em> is fitted to length-at-age data 
adjusted for bias related to selectivity of gears used to collect the length and age samples following the method of Schueller et al. (2014).
</p>


<h3>Value</h3>

<p>List containing list elements of the run information (<em>run_info</em>), filtering indicator (<em>message</em>), convergence information (<em>convergence_info</em>),
parameter estimates with associated standard errors and boundary values (<em>estimates</em>), likelihood values (<em>likelihood</em>) and 
predicted values (<em>predicted</em>).
</p>


<h3>Note</h3>

<p>Amy Schueller provided her AD Model Builder code which was translated to TMB code by Gary Nelson.
</p>


<h3>Author(s)</h3>

<p>Amy M. Schueller, National Marine Fisheries Service, Beaufort, NC <a href="mailto:amy.schueller@noaa.gov">amy.schueller@noaa.gov</a>
</p>


<h3>References</h3>

<p>Schueller, A. M., E. H. Williams and R. T. Cheshire. 2014. A proposed, tested, and applied adjustment to account
for bias in growth parameter estimates due to selectivity. Fisheries Research 158: 26-39.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Not run: 
  data(simulus)
  growth_sel(age=simulus$age,size=simulus$size,weights=simulus$weight,
    minlimit=simulus$minlimit,
    maxlimit=simulus$maxlimit,minmax=simulus$minmax,
    switch_varpar=1,
    Linf=list(init=1000,lb=100,ub=2000,prior.mean=1000,prior.var=-0.5,prior.pdf=1),
    K=list(init=0.3,lb=0.1,ub=0.9,prior.mean=0.3,prior.var=-0.05,prior.pdf=1),
    t0=list(init=-0.5,lb=-4,ub=-0.001,prior.mean=-0.5,prior.var=-0.5,prior.pdf=1),
    varpar=list(init=50.0,lb=10,ub=100,prior.mean=100,prior.var=-1.0,prior.pdf=1),
    tmb.control=list(maxit=5000,trace=F),nlminb.control=list(eval.max=100000,
    iter.max=1000),
    species_info=list(species="gag",size_units="inches"))
 
## End(Not run)
</code></pre>

<hr>
<h2 id='growthlrt'>Likelihood Ratio Tests for Comparing Multiple Growth Curves</h2><span id='topic+growthlrt'></span>

<h3>Description</h3>

<p>Likelihood ratio tests for comparison of two or more growth curves (von Bertalanffy, Gompertz and logistic)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>growthlrt(len = NULL, age = NULL, group = NULL, model = 1, error = 1,
 select = 1, Linf = c(NULL), K = c(NULL), t0 = c(NULL),plottype=0,
control=list(maxiter=10000,minFactor=1/1024,tol=1e-5))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="growthlrt_+3A_len">len</code></td>
<td>
<p>the vector of lengths of individual fish.</p>
</td></tr>
<tr><td><code id="growthlrt_+3A_age">age</code></td>
<td>
<p>the vector of ages associated with the length vector.</p>
</td></tr>
<tr><td><code id="growthlrt_+3A_group">group</code></td>
<td>
<p>the vector of character names specifying group association. The first character in the name must be a letter.</p>
</td></tr>
<tr><td><code id="growthlrt_+3A_model">model</code></td>
<td>
<p>code indicating the growth model to use. 1 = von Bertalanffy, 2= Gompertz and 3= logistic. Default=1.</p>
</td></tr>
<tr><td><code id="growthlrt_+3A_error">error</code></td>
<td>
<p>the error variance assumption.  1= constant variance for all <em>lij</em>s; 2= constant variance for all mean 
lengths at age; 3=var of <em>lij</em> varies with age. See methods a-c in Kimura (1980: pp. 766).  The required statistics 
for each type of error are calculated from the individual length-age observations.</p>
</td></tr>
<tr><td><code id="growthlrt_+3A_select">select</code></td>
<td>
<p>the selection of starting values of <em>L-infinity</em>, <em>K</em>, and <em>t0</em>. 1=automatic selection, 
2=user-specified. If <em>select</em>=1, initial starting values of <em>L-infinity</em>, <em>K</em>, and <em>t0</em> are 
calculated from Walford lines (Everhart et al. 1975), and ages represented as decimal values are truncated to the 
integer before linear regression is applied. If select=2, the user must specify the values of <em>L-infinity</em>, 
<em>K</em>, and <em>t0</em>.</p>
</td></tr>
<tr><td><code id="growthlrt_+3A_linf">Linf</code></td>
<td>
<p>if <em>select</em>=2, the starting values of <em>L-infinity</em> of the von Bertalanffy equation for each group.</p>
</td></tr>
<tr><td><code id="growthlrt_+3A_k">K</code></td>
<td>
<p>if <em>select</em>=2, the starting values of <em>K</em> of the von Bertalanffy equation for each group.</p>
</td></tr>
<tr><td><code id="growthlrt_+3A_t0">t0</code></td>
<td>
<p>if <em>select</em>=2, the starting values of <em>t0</em> of the von Bertalanffy equation for each group.</p>
</td></tr>
<tr><td><code id="growthlrt_+3A_plottype">plottype</code></td>
<td>
<p>the type of plot for each model. 1= observed versus predicted, 2= residuals. Default= 0 (no plot).</p>
</td></tr>
<tr><td><code id="growthlrt_+3A_control">control</code></td>
<td>
<p>see function <em>nls</em>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Following Kimura (1980), the general model (one <em>L-infinity</em>, <em>K</em>, and <em>t0</em> for each group) 
and four sub models are fitted to the length and age data using function <em>nls</em> (nonlinear least squares). For
each general model-sub model comparison,   likelihood ratios are calculated by using the residual sum-of-squares and 
are tested against chi-square statistics with the appropriate degrees of freedom. Individual observations of 
lengths-at-age are required. If error variance assumptions 2 or 3, mean lengths and required statistics are calculated. 
The parameters are fitted using a model.matrix where the 1st column is a row of 1s representing
the parameter estimate of the reference group (lowest alpha-numeric order) and the remaining group columns
have 1 if group identifier is the current group and 0 otherwise. The group number depends on the alph-numeric order.
See function <em>model.matrix</em>.  
</p>
<p>The model choices are: 
</p>
<p>von Bertalanffy
La=Linf(1-exp(-K*(a-t0)))
</p>
<p>Gompertz
La=Linf*exp(-exp(-K*(a-t0)))
</p>
<p>Logisitic
La=Linf/(1+exp(-K*(a-t0)))
</p>
<p>To extract the growth parameters for each group under an hypothesis: 
</p>
<p>x$'model Ho'$coefficients
</p>
<p>x$'model H1'$coefficients
</p>
<p>x$'model H2'$coefficients
</p>
<p>x$'model H3'$coefficients
</p>
<p>x$'model H4'$coefficients
</p>
<p>where <em>x</em> is the output object. 
</p>
<p>As an example, let's say three groups were compared.To get the L-infinity estimates for each groups,
</p>
<p>Linf1&lt;-x$'model Ho'$coefficients[1]
</p>
<p>Linf2&lt;-Linf1+ x$'model Ho'$coefficients[2]
</p>
<p>Linf3&lt;-Linf1+ x$'model Ho'$coefficients[3]
</p>
<p>For models H1, H2, H3 and H4, the parameter L1 or K1 or t01 will be
shared across groups. 
</p>
<p>If RSSHX &gt;RSSH0, less information is accounted for by RSSHX model (where X is hypothesis 1, 2,..etc.).  
If Chi-square is significant, RSSH0 is the better model. If Chi-square is not significant, RSSHX is 
the better model. 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>results</code></td>
<td>
<p>list element with the likelihood ratio tests comparing von Bertalanffy models.</p>
</td></tr>
<tr><td><code>model Ho</code></td>
<td>
<p>list element with the <code>nls</code> fit for the general model.</p>
</td></tr>
<tr><td><code>model H1</code></td>
<td>
<p>list element with the <code>nls</code>  for model H1 (Linf1=Linf2=..=Linfn) where n is the number of groups.</p>
</td></tr>
<tr><td><code>model H2</code></td>
<td>
<p>list element with the <code>nls</code> fit for model H2 (K1=K2=..=Kn).</p>
</td></tr>
<tr><td><code>model H3</code></td>
<td>
<p>list element with the <code>nls</code> fit for model H3 (t01=t02=...=t0n).</p>
</td></tr>
<tr><td><code>model H4</code></td>
<td>
<p>list element with the <code>nls</code> fit for model H4 (Linf1=Linf2=..=Linfn, K1=K2=..=Kn, t01=t02=...=t0n).</p>
</td></tr>
<tr><td><code>rss</code></td>
<td>
<p>list element with the residual sum-of-squares from each model.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>list element with the residuals from each model.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Everhart, W. H., A. W. Eipper, and W. D. Youngs. 1975. Principles of Fishery Science. Cornell 
University Press.
</p>
<p>Kimura, D. K. 1980. Likelihood methods for the von Bertalanffy growth curve. U. S. Fish. Bull. 77(4): 765-776.  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Normally, the length and age data will represent data for individuals.  
## Kimura's data are mean lengths-at-age but are usable because error=2 
## will calculate mean lengths-at-age from individual data. Since only  
## one value is present for each age,the mean length will be calculated
## as the same value.
data(Kimura)
growthlrt(len=Kimura$length,age=Kimura$age,group=Kimura$sex,model=1,error=2,select=1,
plottype=2)
</code></pre>

<hr>
<h2 id='growthlrt.plus'>
Likelihood Methods for Comparing Multiple Growth Curves
</h2><span id='topic+growthlrt.plus'></span>

<h3>Description</h3>

<p>Additional likelihood methods for comparison of two or more curves under heteroscedastic,
normally-distributed errors and 
differing within-group variances based on Kimura (1990).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>growthlrt.plus(model, data, params = NULL, start = NULL, within_grp_var = ~1,
      cfh = NULL, nlminb.control = list(iter.max = 10000, rel.tol = 1e-10),
      optim.control=list(maxit = 10000, reltol = 1e-10))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="growthlrt.plus_+3A_model">model</code></td>
<td>
<p>a two-sided formula object describing the model, with the response on the 
left of a ~ operator and a nonlinear expression involving parameters on the right.</p>
</td></tr>
<tr><td><code id="growthlrt.plus_+3A_data">data</code></td>
<td>
<p>A data frame containing the variables named in <em>model</em>. Rows should represent individual observations.</p>
</td></tr>
<tr><td><code id="growthlrt.plus_+3A_params">params</code></td>
<td>
<p>a two-sided linear formula of the form <code>p1=~1</code> or <code>p1=~group</code> for each parameter estimated in model. 
The <code>p1</code> represents a parameter included on the right hand side of model. A <code>1</code> on the right hand 
side of the formula indicates a single parameter is estimated, whereas a variable name of a group variable 
will estimate as many parameters as there are levels in the group variable.</p>
</td></tr>
<tr><td><code id="growthlrt.plus_+3A_start">start</code></td>
<td>
<p>a required named list with the initial values for the parameters in model. If multiple
estimates for a given parameter are desired, starting values should be enclosed in <code>c()</code>.</p>
</td></tr>
<tr><td><code id="growthlrt.plus_+3A_within_grp_var">within_grp_var</code></td>
<td>
<p>a one-sided formula of the form <code>within_grp_var= ~1</code> or    
<code>within_grp_var= ~group</code>. A <code>1</code> on the right hand side of the formula indicates a 
single within-group variance is estimated for all groups, whereas a variable name 
(same one used in <code>params</code>) will estimate different sigmas for each level under group.
</p>
</td></tr>
<tr><td><code id="growthlrt.plus_+3A_cfh">cfh</code></td>
<td>
<p>NULL or a named list with arguments needed to correct for heterogeneity of variances. 
If the latter, the required arguments are <code>form</code>, <code>value</code>,and <code>fixed</code>. See details for more information.</p>
</td></tr>
<tr><td><code id="growthlrt.plus_+3A_nlminb.control">nlminb.control</code></td>
<td>
<p>Additional controls passed to the optimization function <em>nlminb</em>.</p>
</td></tr>
<tr><td><code id="growthlrt.plus_+3A_optim.control">optim.control</code></td>
<td>
<p>Additional controls passed to the optimization function <em>optim</em>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The likelihood methods of Kimura (1990) are used to fit any nonlinear equation, correct for 
heterogeneity of variances, and estimate common or separate within-group variances depending on
user-specifications. A main assumption is errors are normally-distributed.  
The results of the model fits can then be used in function <em>compare.lrt.plus</em> 
to determine if parameterizations differ significantly from each other by using a likelihood ratio 
and an F test.
</p>
<p>Steps of the modeling process are as follows:
</p>
<p>1) Specify the nonlinear model equation in the same 
formula format as would be done in function <em>nls</em>. For example, the von Bertalanffy growth equation 
is written as:
</p>
<p><code>sl~Linf*(1-exp(-K*(age-t0)))</code>
</p>
<p>where <em>sl</em> is the variable name for length data, <em>age</em> is the variable name for age data,
and <em>Linf</em>, <em>K</em> and <em>t0</em> are parameters to be estimated. 
</p>
<p>2) Specify the parameter formulae under <code>params</code>.  These formulae 
are used to indicate that additional parameters based on some group variable should be estimated. 
For example,
</p>
<p><code>params=list(Linf~1,K~1,t0~1)</code>
</p>
<p>specifies single parameters are estimated for Linf, K and t0.  
</p>
<p><code>params=list(Linf~sex,K~1,t0~1)</code>
</p>
<p>specifies that separate Linfs are to be estimated for each sex and only single estimates
for K and t0.
</p>
<p><code>params=list(Linf~sex,K~sex,t0~sex)</code>
</p>
<p>specifies that separate Linfs, Ks and t0s are to be estimated for each sex.  Different group variables 
for each parameter are not allowed.
</p>
<p>3) Specify start values for all parameters.  For example, if separate Linfs, Ks and t0s for a group
variable like sex (only two-levels: M and F), then 6 starting values must be given.  When parameters are
based on a group variable, then the first estimate of a parameter will be the reference value (labeled as Intercept)
and the remaining parameters will be estimated as a deviation from that reference value. Reference values 
are determined by alphanumeric order of levels within the group variable.
</p>
<p><code>start=list(Linf=c(300,10),K=c(0.3,0.05),t0=c(0,-0.5))</code>
</p>
<p>is an example of the starting values for the 6 parameter model mentioned above. Warning messages are generated
if the number of start values is less than or greater than the number of parameters being estimated. Internally,
code will add (1/10th of first value) or truncate (last number(s) in list) start values in these cases. 
However, the user should specify the appropriate number of values to ensure successful optimization. 
</p>
<p>4) Specify the within-group variance structure.  If the within-group variance is assumed
the same among groups, then 
</p>
<p><code>within_grp_var=~1</code> 
</p>
<p>which is the default specification. If within-group variances are suspected to differ among groups (e.g., sex), then
</p>
<p><code>within_grp_var=~sex</code>
</p>
<p>Separate variances will be estimated for each level of the group variable.  Whether or not better model fits can be 
obtained by estimating separate group variances can be tested using the model comparison methods (see below).
When estimating thetas (correcting for heterogeneity), explore different starting values for the main parameters to 
ensure global convergence.
</p>
<p>5) Specify the correction for heterogenity (<code>cfh</code>) argument(s) if needed.  Initial curve fittings should be performed 
and plots of residuals versus fitted values examined to determine if there is a change in residual variation with 
increasing fitted values. If so, this indicates the presense of heterogeneity in variance which must be corrected to obtain 
unbiased parameters estimates, standard errors, residual sum-of-squares, etc. Kimura (1990) uses the power function (same as the
<em>varPower</em> function in Pinheiro and Bates (2004)) and additional parameters known as <em>theta</em> are estimated.
If <code>cfh</code> is NULL, then homogeneity of variance is assumed. If heterogeneity of variance needs to be accounted for, specify 
<code>cfh</code> as
</p>
<p><code>cfh=list(form=~1,value=0,fixed=NULL)</code>
</p>
<p><code>form</code> is a formula and is 1 if a single theta is assumed equal among groups. If individual thetas are desired for groups (heterogenity is different
for each group), then a group variable is used (e.g.,<em>form</em>=~sex). 
</p>
<p><code>value</code> is the initial starting value(s) for theta(s). If more than 1 theta will
be estimated, provide the same number of starting values  within <em>c()</em> as thetas.
</p>
<p><code>fixed</code> is used to indicate whether the thetas will be estimated (default <em>NULL</em>) or assumed fixed to numeric values specified by the user.
</p>
<p><code>cfh=list(form=~sex,value=0,fixed=c(0.5,0.9))</code>
</p>
<p>indicates that thetas for each sex (two-levels: M and F) will not be estimated, but fixed to values of 0.5 and 0.9
</p>
<p>6) Run the model function.  Parameter estimation is performed intially by using the optimization function <em>nlminb</em>. 
The estimated parameters are then used as starting values and optimization is performed again by 
using function <em>optim</em> to obtain the final parameter estimates and the Hessian matrix from 
which standard errors are derived. Unlike estimation of thetas conducted in function <em>gnls</em> in package <em>nlme</em>, thetas herein
are estimated as parameters, standard errors are generated, and t-tests for significance are conducted. These extra parameters are counted in the
determination of residual and model degrees of freedom.   
</p>
<p>To convert a non-reference level estimate to the same scale as the reference level, the reference value and parameter estimate are added together. 
For example, if estimates of Linf for two groups are 300 and 5, then adding them gives the Linf of 305 for the 
non-reference group.
</p>
<p><em>Model Comparisons</em>
</p>
<p>As in the <em>growthlrt</em> function based on Kimura (1980), growth curves are tested for differences by using likelihood ratio tests.  
These tests assume homogeneity of variances among groups which is why heterogeneity must be corrected before proceeding. Unlike
the <em>growthlrt</em> function, <em>growthlrt.plus</em> does not automatically make the comparisons. The user must develop the model structures,
save each oject, and test for differences using the function <em>compare.lrt.plus</em>.  Examples are provided below.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>model</code></td>
<td>
<p>the fitting method and model.</p>
</td></tr>
<tr><td><code>results</code></td>
<td>
<p>list element containing the parameter estimates, standard errors, tests of differences from zero, estimates of
the maximum likelihood sigma(s), log-likelihood, AIC, BIC, sample sizes, residual degrees of freedom and the residual standard error</p>
</td></tr>  
<tr><td><code>variance.covariance</code></td>
<td>
<p>list element containing the variance covariance matrix.</p>
</td></tr>
<tr><td><code>correlation</code></td>
<td>
<p>list element containing the parameter correlation matrix.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>list element containing the raw and standardized residuals from the model fit.</p>
</td></tr>
<tr><td><code>fitted</code></td>
<td>
<p>list element containing the fitted values from the model fit.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>list element containing convergence information from the <em>optim</em> fit.</p>
</td></tr>
<tr><td><code>model_comp_df</code></td>
<td>
<p>list element containing model degrees of freedom used in model comparison.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>list element containing object type.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a>
</p>


<h3>References</h3>

<p>Kimura, D. K. 1990. Testing nonlinear regression parameters under heteroscedastic,
normally-distributed errors. Biometrics 46: 697-708.
</p>
<p>Pinheiro, J. C. and D. M. Bates. 2004. Mixed-Effects Models in S and S-PLUS. Springer New York, New York. 528 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+growthlrt">growthlrt</a></code> <code><a href="#topic+compare.lrt.plus">compare.lrt.plus</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

#### This example produces the same results as the example in 
#### the \emph{growthlrt} helpfile

data(Kimura)

##H0 Model - Different Linfs, Ks and tos for each sex
Ho&lt;-growthlrt.plus(length~Linf*(1-exp(-K*(age-t0))),data=Kimura,
               params=list(Linf~sex,K~sex,t0~sex),
               start=list(Linf=c(60,10),K=c(0.3,0.1),t0=c(0.5,0.05)))

##H1 Model - Same Linfs
H1&lt;-growthlrt.plus(length~Linf*(1-exp(-K*(age-t0))),data=Kimura,
                   params=list(Linf~1,K~sex,t0~sex),
                   start=list(Linf=c(60),K=c(0.3,0.1),t0=c(0.5,0.05)))

##H2 Model - Same Ks
H2&lt;-growthlrt.plus(length~Linf*(1-exp(-K*(age-t0))),data=Kimura,
                   params=list(Linf~sex,K~1,t0~sex),
                   start=list(Linf=c(60,10),K=c(0.3),t0=c(0.5,0.05)))

##H3 Model - Same t0s
H3&lt;-growthlrt.plus(length~Linf*(1-exp(-K*(age-t0))),data=Kimura,
                   params=list(Linf~sex,K~sex,t0~1),
                   start=list(Linf=c(60,10),K=c(0.3,0.1),t0=c(0.5)))

##H4 Model - Same Linf, K and t0
H4&lt;-growthlrt.plus(length~Linf*(1-exp(-K*(age-t0))),data=Kimura,
                   params=list(Linf~1,K~1,t0~1),
                   start=list(Linf=60,K=0.3,t0=0.5))

compare.lrt.plus(Ho,H1)
compare.lrt.plus(Ho,H2)
compare.lrt.plus(Ho,H3)
compare.lrt.plus(Ho,H4)

####This example is Case 2 from Kimura (1990;page 703) and uses the SFR paramterization of the 
#### von Bertalanffy growth equation.

data(AtkaMack)

alt_hypoth_2&lt;-growthlrt.plus(len~lmin+(lmax-lmin)*((1-k^(m-1))/(1-k^(n-1))), 
                   data=AtkaMack,
                   params=list(lmin~sex,lmax~sex,k~sex),
                   within_grp_var=~sex,
                   start=list(lmin=c(26,-2),lmax=c(41,-2),k=c(0.737,0.05)))

null_hypoth_2&lt;-growthlrt.plus(len~lmin+(lmax-lmin)*((1-k^(m-1))/(1-k^(n-1))),
                   data=AtkaMack,
                   params=list(lmin~1,lmax~1,k~1),
                   within_grp_var=~sex,
                   start=list(lmin=c(26),lmax=c(41),k=c(0.737)))

compare.lrt.plus(alt_hypoth_2,null_hypoth_2)


## End(Not run)
</code></pre>

<hr>
<h2 id='growthmultifit'>Fit a Multi-Group Growth Model</h2><span id='topic+growthmultifit'></span>

<h3>Description</h3>

<p>Fits a von Bertalanffy, Gompertz or logistic growth curve to length and age for two or more groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>growthmultifit(len=NULL,age=NULL,group=NULL,model=1,fixed=c(1,1,1),error=1,
        select=1,Linf=c(NULL),K=c(NULL),t0=c(NULL),plot=FALSE,
                control=list(maxiter=10000,minFactor=1/1024,tol=1e-5))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="growthmultifit_+3A_len">len</code></td>
<td>
<p>the vector of lengths of individual fish.</p>
</td></tr>
<tr><td><code id="growthmultifit_+3A_age">age</code></td>
<td>
<p>the vector of ages associated with the length vector.</p>
</td></tr>
<tr><td><code id="growthmultifit_+3A_group">group</code></td>
<td>
<p>the vector of character names specifying group association. The first character in the name must be a letter.</p>
</td></tr>
<tr><td><code id="growthmultifit_+3A_model">model</code></td>
<td>
<p>which model to fit. 1= von Bertalanffy, 2= Gompertz, and 3 = logistic. 
Default=1.</p>
</td></tr>
<tr><td><code id="growthmultifit_+3A_fixed">fixed</code></td>
<td>
<p>arguments specifying that Linf, K or t0 should be fitted as a constant 
between groups or as separate parameters for each group. 1 = single parameter between 
groups, 2 = separate parameters for each group. The order of <em>fixed</em> is c(Linf,K,t0).</p>
</td></tr> 
<tr><td><code id="growthmultifit_+3A_error">error</code></td>
<td>
<p>the error variance assumption.  1= constant variance for all <em>lij</em>s; 2= constant variance for all mean 
lengths at age; 3=var of <em>lij</em> varies with age. See methods a-c in Kimura (1980: pp. 766).  The required statistics 
for each type of error are calculated from the individual length-age observations.</p>
</td></tr>
<tr><td><code id="growthmultifit_+3A_select">select</code></td>
<td>
<p>the selection of starting values of <em>L-infinity</em>, <em>K</em>, and <em>t0</em>. 1=automatic selection, 
2=user-specified. If <em>select</em>=1, initial starting values of <em>L-infinity</em>, <em>K</em>, and <em>t0</em> are 
calculated from Walford lines (Everhart et al. 1975), and ages represented as decimal values are truncated to the 
integer before linear regression is applied. If select=2, the user must specify values of <em>L-infinity</em>, 
<em>K</em>, and <em>t0</em> for each group.</p>
</td></tr>
<tr><td><code id="growthmultifit_+3A_linf">Linf</code></td>
<td>
<p>if <em>select</em>=2, the starting values for <em>L-infinity</em> of the von Bertalanffy equation, one for each group.</p>
</td></tr>
<tr><td><code id="growthmultifit_+3A_k">K</code></td>
<td>
<p>if <em>select</em>=2, the starting values for <em>K</em> of the von Bertalanffy equation, one for each group.</p>
</td></tr>
<tr><td><code id="growthmultifit_+3A_t0">t0</code></td>
<td>
<p>if <em>select</em>=2, the starting value for <em>t0</em> of the von Bertalanffy equation, one for each group.</p>
</td></tr>
<tr><td><code id="growthmultifit_+3A_plot">plot</code></td>
<td>
<p>logical argument specifying whether observed versus predicted and residuals graphs should be plotted. Default is FALSE.</p>
</td></tr>
<tr><td><code id="growthmultifit_+3A_control">control</code></td>
<td>
<p>see function <em>nls</em>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A von Bertalanffy, Gompertz or logistic model is fitted to the length and age data of two or more groups using function <em>nls</em> (nonlinear least squares). Parameters can be estimated for each group or as constants across groups. Individual observations of lengths-at-age are required. If error variance assumptions 2 or 3, mean lengths and required statistics are calculated. The parameters are fitted using a model.matrix where the 1st column is a row of 1s representing the parameter estimate of the reference group (group with lowest alpha-numeric order) and the remaining group columns have 1 if group identifier is the current group and 0 otherwise. See function <em>model.matrix</em>.  
This is a companion function to function <em>growthlrt</em>. If errors arise using automatic selection, switch to select=2.
</p>
<p>When separate parameters are estimated for each group, estimates for the the non-reference groups would be the reference-group estimated parameters (e.g., Linf1 or K1 or t01) plus the coefficent estimate for the nth group (e.g., group 2: Linf2 or K2, or t02) based on the alpha-numeric order.  If the parameter is assumed constant across groups, then estimates of Linf1 or K1 or t01 is used as the parameter for each group.
The von Bertalanffy equation is Lt=Linf*1-exp(-K*(age-t0)). The Gompertz equation is Lt=exp(-exp(-K*(age-t0))).
The logistic equation is Lt=Linf/(1+exp(-K*(age-t0))). 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>results</code></td>
<td>
<p>list element containing summary statistics of <em>nls</em> fit</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>list element with the residuals from the model.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Everhart, W. H., A. W. Eipper, and W. D. Youngs. 1975. Principles of Fishery Science. Cornell 
University Press.
</p>
<p>Kimura, D. K. 1980. Likelihood methods for the von Bertalanffy growth curve. U. S. Fish. Bull. 77(4): 765-776.  
</p>


<h3>See Also</h3>

<p><code><a href="#topic+growthlrt">growthlrt</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Kimura)
growthmultifit(len=Kimura$length,age=Kimura$age,group=as.character(Kimura$sex),
model=1,fixed=c(2,1,1),
error=1,select=1,Linf=NULL,K=NULL,t0=NULL,plot=FALSE,control=list(maxiter=10000,
minFactor=1/1024,tol=1e-5))
</code></pre>

<hr>
<h2 id='growthResid'>
Plot residuals of growth model fitted to tag data</h2><span id='topic+growthResid'></span>

<h3>Description</h3>

<p>Plot residuals (observed - expected growth increments) vs relative
age at the time of tagging and versus time at liberty.</p>


<h3>Usage</h3>

<pre><code class='language-R'>growthResid(K, Linf, dat, lentag, lenrec, timelib, graph =1, 
           main = "Residuals of growth increments",
           cex.lab=1.5, cex.axis=1.5, cex.main=1,
           xlab1="Relative age, yr", xlab2="Time at liberty, yr",
           ylab="Observed - expected increment",
           xlim1=NULL, xlim2=NULL, ylim=NULL, col=1, returnvec=FALSE, 
           returnlimits=FALSE, warn=TRUE,...) </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="growthResid_+3A_k">K</code></td>
<td>
<p>parameter of the von Bertalanffy growth equation</p>
</td></tr>
<tr><td><code id="growthResid_+3A_linf">Linf</code></td>
<td>
<p>parameter of the von Bertalanffy growth equation</p>
</td></tr>
<tr><td><code id="growthResid_+3A_dat">dat</code></td>
<td>
<p>dataframe containing length at tagging, length at recapture
and time at liberty. These must be named lentag, lenrec
and timelib or else column 1 must contain the length at
tagging, column 2 must contain length at recapture and
column 3 must contain time at liberty</p>
</td></tr>
<tr><td><code id="growthResid_+3A_lentag">lentag</code></td>
<td>
<p>alternative way to pass data to function</p>
</td></tr>
<tr><td><code id="growthResid_+3A_lenrec">lenrec</code></td>
<td>
<p>alternative way to pass data to function</p>
</td></tr>
<tr><td><code id="growthResid_+3A_timelib">timelib</code></td>
<td>
<p>alternative way to pass data to function</p>
</td></tr>
<tr><td><code id="growthResid_+3A_graph">graph</code></td>
<td>
<p>which graph to plot - 1: residuals versus Relative age, 2: residuals versus time-at-liberty</p>
</td></tr>
<tr><td><code id="growthResid_+3A_main">main</code></td>
<td>
<p>an overall title for the plot</p>
</td></tr>
<tr><td><code id="growthResid_+3A_cex.lab">cex.lab</code></td>
<td>
<p>The magnification to be used for x and y labels relative to
the current setting of cex</p>
</td></tr>
<tr><td><code id="growthResid_+3A_cex.axis">cex.axis</code></td>
<td>
<p>The magnification to be used for axis annotation relative to 
the current setting of cex</p>
</td></tr>
<tr><td><code id="growthResid_+3A_cex.main">cex.main</code></td>
<td>
<p>The magnification to be used for main titles relative to 
the current setting of cex</p>
</td></tr>
<tr><td><code id="growthResid_+3A_xlab1">xlab1</code></td>
<td>
<p>a title for the x axis 1</p>
</td></tr>
<tr><td><code id="growthResid_+3A_xlab2">xlab2</code></td>
<td>
<p>a title for the x axis 2</p>
</td></tr>
<tr><td><code id="growthResid_+3A_ylab">ylab</code></td>
<td>
<p>a title for the y axis</p>
</td></tr>
<tr><td><code id="growthResid_+3A_xlim1">xlim1</code></td>
<td>
<p>lower and upper limits of x axis 1 e.g., c(0,100)</p>
</td></tr>
<tr><td><code id="growthResid_+3A_xlim2">xlim2</code></td>
<td>
<p>lower and upper limits of x axis 2 e.g., c(0,100)</p>
</td></tr>
<tr><td><code id="growthResid_+3A_ylim">ylim</code></td>
<td>
<p>lower and upper limits of y axis e.g., c(0,100)</p>
</td></tr>
<tr><td><code id="growthResid_+3A_col">col</code></td>
<td>
<p>color of points in plot</p>
</td></tr>
<tr><td><code id="growthResid_+3A_returnvec">returnvec</code></td>
<td>
<p>logical - if TRUE, function returns a dataframe with the
computed age at tagging and the residual (obs - pred increment)</p>
</td></tr>
<tr><td><code id="growthResid_+3A_returnlimits">returnlimits</code></td>
<td>
<p>logical - if TRUE, function returns the x and y limits for the plot</p>
</td></tr>
<tr><td><code id="growthResid_+3A_warn">warn</code></td>
<td>
<p>logical - if TRUE, function issues a warning if names of variables
in dat do not match the 3 names expected.</p>
</td></tr>
<tr><td><code id="growthResid_+3A_...">...</code></td>
<td>
<p>other arguments to pass to <em>plot</em></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function plots residuals (observed - expected growth increments) vs relative
age at the time of tagging and vs time at liberty from VB growth model fitted 
to tagging data. Relative age is calculated by inverting the von Bertalanffy growth curve. 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>output</code></td>
<td>
<p>If returnvec = TRUE, computed age and residuals. If returnlimits=TRUE, 
x and y limits for plot</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Janos Hoenig Virginia Institute of Marine Science May 2013 <a href="mailto:hoenig@vims.edu">hoenig@vims.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> data(bonito)
 temp&lt;-bonito[c(bonito$T2-bonito$T1)&gt;0,]
 growthResid(0.19,97.5,lentag=temp$L1, lenrec=temp$L2,timelib=c(temp$T2-temp$T1),graph=1)
</code></pre>

<hr>
<h2 id='growthTraject'>
Plot growth trajectories obtained from tagging data
</h2><span id='topic+growthTraject'></span>

<h3>Description</h3>

<p>Age and length coordinates for the time of tagging and time of recapture are plotted as line 
segments overlayed on the von Bertalannfy growth curve</p>


<h3>Usage</h3>

<pre><code class='language-R'>  growthTraject(K, Linf, dat, lentag, lenrec, timelib, subsets=NULL,  
               main = "Growth trajectories &amp; fitted curve",
               cex.lab=1.5, cex.axis=1.5, cex.main=1,
               xlab="Relative age, yr", ylab="Length, cm",
               xlim=NULL, ylim=NULL,ltytraject=1, lwdtraject=1,
               coltraject=1, ltyvonB=1, lwdvonB=2, colvonB="red", 
               returnvec=FALSE, returnlimits=FALSE, warn=TRUE, ...) </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="growthTraject_+3A_k">K</code></td>
<td>
<p>parameter of the von Bertalanffy growth equation</p>
</td></tr>
<tr><td><code id="growthTraject_+3A_linf">Linf</code></td>
<td>
<p>parameter of the von Bertalanffy growth equation</p>
</td></tr>
<tr><td><code id="growthTraject_+3A_dat">dat</code></td>
<td>
<p>dataframe containing length at tagging, length at recapture
and time at liberty. These must be named lentag, lenrec
and timelib or else column 1 must contain the length at
tagging, column 2 must contain length at recapture and
column 3 must contain time at liberty OR the variables must 
be named lentag, lenrec and timelib</p>
</td></tr>
<tr><td><code id="growthTraject_+3A_lentag">lentag</code></td>
<td>
<p>alternative way to pass data to function</p>
</td></tr>
<tr><td><code id="growthTraject_+3A_lenrec">lenrec</code></td>
<td>
<p>alternative way to pass data to function</p>
</td></tr>
<tr><td><code id="growthTraject_+3A_timelib">timelib</code></td>
<td>
<p>alternative way to pass data to function</p>
</td></tr>
<tr><td><code id="growthTraject_+3A_subsets">subsets</code></td>
<td>
<p>factor or integer variable specifying subsets of the data 
to be plotted with separate colors or line types</p>
</td></tr>
<tr><td><code id="growthTraject_+3A_main">main</code></td>
<td>
<p>an overall title for the plot</p>
</td></tr>
<tr><td><code id="growthTraject_+3A_cex.lab">cex.lab</code></td>
<td>
<p>The magnification to be used for x and y labels relative to
the current setting of cex</p>
</td></tr>
<tr><td><code id="growthTraject_+3A_cex.axis">cex.axis</code></td>
<td>
<p>The magnification to be used for axis annotation relative to 
the current setting of cex</p>
</td></tr>
<tr><td><code id="growthTraject_+3A_cex.main">cex.main</code></td>
<td>
<p>The magnification to be used for main titles relative to 
the current setting of cex</p>
</td></tr>
<tr><td><code id="growthTraject_+3A_xlab">xlab</code></td>
<td>
<p>a title for the x axis</p>
</td></tr>
<tr><td><code id="growthTraject_+3A_ylab">ylab</code></td>
<td>
<p>a title for the y axis</p>
</td></tr>
<tr><td><code id="growthTraject_+3A_xlim">xlim</code></td>
<td>
<p>lower and upper limits of x axis e.g., c(0,100)</p>
</td></tr>
<tr><td><code id="growthTraject_+3A_ylim">ylim</code></td>
<td>
<p>lower and upper limits of y axis e.g., c(0,100)</p>
</td></tr>
<tr><td><code id="growthTraject_+3A_ltytraject">ltytraject</code></td>
<td>
<p>line type for the growth trajectories</p>
</td></tr>
<tr><td><code id="growthTraject_+3A_lwdtraject">lwdtraject</code></td>
<td>
<p>line width for the growth trajectories</p>
</td></tr>
<tr><td><code id="growthTraject_+3A_coltraject">coltraject</code></td>
<td>
<p>line color for the growth trajectories</p>
</td></tr>
<tr><td><code id="growthTraject_+3A_ltyvonb">ltyvonB</code></td>
<td>
<p>line type for the fitted von Bertalanffy growth curve</p>
</td></tr>
<tr><td><code id="growthTraject_+3A_lwdvonb">lwdvonB</code></td>
<td>
<p>line width for the fitted von Bertalanffy growth curve</p>
</td></tr>
<tr><td><code id="growthTraject_+3A_colvonb">colvonB</code></td>
<td>
<p>line color for the fitted von B. curve</p>
</td></tr>
<tr><td><code id="growthTraject_+3A_returnvec">returnvec</code></td>
<td>
<p>logical for whether the coordinates of the line
segments should be returned)</p>
</td></tr>
<tr><td><code id="growthTraject_+3A_returnlimits">returnlimits</code></td>
<td>
<p>logical for whether the x-axis and y-axis limits
should be returned</p>
</td></tr>
<tr><td><code id="growthTraject_+3A_warn">warn</code></td>
<td>
<p>logical - if TRUE, function issues a warning if names of variables
in dat do not match the 3 names expected.</p>
</td></tr>
<tr><td><code id="growthTraject_+3A_...">...</code></td>
<td>
<p>other arguments to pass to <em>plot</em></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The relative age at tagging is computed from the inverted von Bertalannfy growth equation (i.e., age expressed as a 
function of length); the age at recapture is taken to be the age at tagging plus the time at liberty. Then 
the (age, length) coordinates for the time of tagging and time of recapture are plotted as a line segment. 
Additional parameters control the format of the plot as follows. A call to plot() sets up the axes. 
Then a call to arrows() draws the line segments. Finally, a call to curve() adds the von Bertalanffy growth curve. 
Specifying additional graphical parameters is permissable but these will be passed only to plot().
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>output</code></td>
<td>
<p>if returnvec = TRUE, coordinates of the line segments are returned.
If returnlimits=TRUE, x and y limits for plot are returned</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Janos Hoenig Virginia Institute of Marine Science May 2013 <a href="mailto:hoenig@vims.edu">hoenig@vims.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> data(bonito)
 temp&lt;-bonito[c(bonito$T2-bonito$T1)&gt;0,]
 growthTraject(0.19,97.5,lentag=temp$L1, lenrec=temp$L2,timelib=c(temp$T2-temp$T1))
</code></pre>

<hr>
<h2 id='growtrans'>
Growth Transition Matrix for a Size-Structured Population Dynamics Model </h2><span id='topic+growtrans'></span>

<h3>Description</h3>

<p>Generates a growth transition matrix from parameters of the von Bertalanffy growth 
equation following Chen et al. (2003)</p>


<h3>Usage</h3>

<pre><code class='language-R'>growtrans(Lmin = NULL, Lmax = NULL, Linc = NULL, Linf = NULL, SELinf = NULL,
          K = NULL, SEK = NULL, rhoLinfK = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="growtrans_+3A_lmin">Lmin</code></td>
<td>
<p>Mid-point of starting size class.</p>
</td></tr>
<tr><td><code id="growtrans_+3A_lmax">Lmax</code></td>
<td>
<p>Mid-point of end size class.  This should be one increment larger than Linf.</p>
</td></tr>
<tr><td><code id="growtrans_+3A_linc">Linc</code></td>
<td>
<p>Size class increment.</p>
</td></tr>
<tr><td><code id="growtrans_+3A_linf">Linf</code></td>
<td>
<p>L-infinity parameter of the von Bertalanffy growth equation.</p>
</td></tr>
<tr><td><code id="growtrans_+3A_selinf">SELinf</code></td>
<td>
<p>Standard error of Linf.</p>
</td></tr>
<tr><td><code id="growtrans_+3A_k">K</code></td>
<td>
<p>Growth parameter of the von Bertalanffy growth equation.</p>
</td></tr>
<tr><td><code id="growtrans_+3A_sek">SEK</code></td>
<td>
<p>Standard error of K.</p>
</td></tr>
<tr><td><code id="growtrans_+3A_rholinfk">rhoLinfK</code></td>
<td>
<p>Correlation between Linf and K. Usually from a parameter correlation matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Transition probabilities are calculated by using formulae 3-9 and procedures 
in Chen et al. (2003). Negative growth increments result if Lmax is beyond 
Linf, so the transition matrix is truncated at Linf. The last size class acts as 
a plus group and has a probability of 1.
</p>


<h3>Value</h3>

<p>A matrix of dimensions n size classes x n size classes.</p>


<h3>Note</h3>

<p>This function is based on an example EXCEL spreadsheet provided by Yong Chen.</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a>
</p>


<h3>References</h3>

<p>Chen, Y., M. Hunter, R. Vadas, and B. Beal. 2003. Developing a growth-transition matrix for stock assessment 
of the green sea urchin (Strongylocentrotus droebachiensis) off Maine. Fish. Bull. 101: 737-744.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># For Chen et al. 2003
growtrans(Lmin=40,Lmax=101,Linc=1,Linf=100,SELinf=15,K=0.100588,SEK=0.04255,rhoLinfK=0.94)
</code></pre>

<hr>
<h2 id='haddock'>Biological data for haddock (Melanogrammus aeglefinus)</h2><span id='topic+haddock'></span>

<h3>Description</h3>

<p>The <code>haddock</code> data frame has 15 rows and 4 columns.
Age, weight at spawning, partial recruitment, and fraction mature data for haddock (Melanogrammus aeglefinus) used by Gabriel et al. (1989) 
to calculate spawning stock biomass-per-recruit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>haddock
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>age</dt><dd><p>vector of ages</p>
</dd>
<dt>ssbwgt</dt><dd><p>vector of weights at spawning for each age</p>
</dd>
<dt>partial</dt><dd><p>partial recruitment vector</p>
</dd>
<dt>pmat</dt><dd><p>vector of fraction of females mature at age</p>
</dd>
</dl>



<h3>Source</h3>

<p>Gabriel, W. L., M. P. Sissenwine, and W. J. Overholtz. 1989. Analysis of spawning stock biomass per recruit:
an example for Georges Bank haddock. North American Journal of Fisheries Management 9: 383-391.
</p>

<hr>
<h2 id='Hightower'>Original data used in Hightower et al. (2001)</h2><span id='topic+Hightower'></span>

<h3>Description</h3>

<p>The <code>Hightower</code> has 51 rows and 1 column.
The complete capture histories of striped bass for Lake Gaston, North Carolina. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Hightower
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>caphistory</dt><dd><p>capture histories of 51 striped bass</p>
</dd>
</dl>



<h3>Source</h3>

<p>Hightower, J. E., J. R. Jackson, and K. H. Pollock. 2001. Use of telemetry methods to estimate natural mortality and fishing mortality of striped bass in Lake Gaston, North Carolina. Trans. Am. Fish. Soc. 130:557-567.
</p>
<p>Thanks to Joe Hightower of NC Cooperative Fish and Wildlife Research Unit for providing his original data.
</p>

<hr>
<h2 id='Hoenig'>Tag Data from Hoenig et al. (1998)</h2><span id='topic+Hoenig'></span>

<h3>Description</h3>

<p>The <code>Hoenig</code> list containing 8 components of data.
Data were obtained from the Hoenig et al.(1998).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Hoenig
</code></pre>


<h3>Format</h3>

<p>This list contains the following components:
</p>

<dl>
<dt>relyrs</dt><dd><p>vector of start and end years of release years</p>
</dd>
<dt>recapyrs</dt><dd><p>vector of start and end years of recapture years</p>
</dd>
<dt>N</dt><dd><p>vector of number of tags released in each release year</p>
</dd>
<dt>recapharv</dt><dd><p>recapture matrix of harvested fish</p>
</dd>
<dt>lambda</dt><dd><p>vector of reporting rates (one for each recapture year)</p>
</dd>
<dt>phi</dt><dd><p>vector of initial tag loss (one for each recapture year)</p>
</dd>
<dt>Fyr</dt><dd><p>vector of years to estimate fishing mortality</p>
</dd>
<dt>Myr</dt><dd><p>vector of years to estimate natural mortality</p>
</dd>
</dl>



<h3>Source</h3>

<p>Hoenig, J. M, N. J. Barrowman, W. S. Hearn, and K. H. Pollock. 1998. Multiyear tagging studies incorporating fishing effort data.  Canadian Journal of Fisheries and Aquatic Sciences 55: 1466-1476.
</p>

<hr>
<h2 id='hohe'>age-length key and length frequency data from Hoenig and Heisey (1987)</h2><span id='topic+hohe'></span>

<h3>Description</h3>

<p>The <code>hohe</code> data list with age-length key matrix with 10 columns and 4 rows, and length frequency vector with 10 observations .
Age-length key and length frequency from Appendix B example in Hoeing and Heisey (1987)</p>


<h3>Usage</h3>

<pre><code class='language-R'>hohe
</code></pre>


<h3>Format</h3>

<p>One matrix and one vector
</p>


<h3>Source</h3>

<p>Hoenig, J. M. and D. M. Heisey. 1987. <em>Use of a log-linear model with the EM algorithm to correct
estimates of stock composition and to convert length to age. Transactions of the American Fisheries Society 116: 232-243.</em>
</p>

<hr>
<h2 id='inverse_alk'>Inverse Age-Length Key Method of Hoenig and Heisey (1987)</h2><span id='topic+inverse_alk'></span>

<h3>Description</h3>

<p>Estimate the age composition of fish from size frequencies with missing age data by using the inverse method of Hoenig and Heisey (1986).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inverse_alk(alk1 = NULL, lf1 = NULL, lf2 = NULL, toler = 0.000001, max.iter = 10000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="inverse_alk_+3A_alk1">alk1</code></td>
<td>
<p>an age-size matrix (numbers) with age as rows and size intervals as columns.</p>
</td></tr>
<tr><td><code id="inverse_alk_+3A_lf1">lf1</code></td>
<td>
<p>an optional vector of number of fish at size that will be used to expand the numbers in <em>alk1</em>
matrix to the numbers in the vector before estimation of age composition of lf2. 
Vector length must match number of columns in <em>alk1</em>. <em>NULL</em> indicates no vector used.</p>
</td></tr>
<tr><td><code id="inverse_alk_+3A_lf2">lf2</code></td>
<td>
<p>a required vector of number of fish at size for which age composition will be estimated. Vector length must 
match number of columns in <em>alk1</em>.</p>
</td></tr>
<tr><td><code id="inverse_alk_+3A_toler">toler</code></td>
<td>
<p>convergence criterion. The iterations end when <em>|L'-L|</em> &lt;= <em>toler</em>. Default = 0.000001.</p>
</td></tr>
<tr><td><code id="inverse_alk_+3A_max.iter">max.iter</code></td>
<td>
<p>additional convergence criterion. The maximum number of iterations allowed. Default =10000.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The inverse age-length key method of Hoenig and Heisey (1987) is used to estimate age composition of a sample of size data with no age data from
an age-length key which may be from a different year/ region. The method estimates the probability of size given age which
is not affected by variability in recruitment and survival (Ailloud and Hoenig, 2019). What does affect the probability of size given
age is spatiotemporal variations of size at age. These could be caused by changes in growth rates, or changes in mean size at age
due to changes in fishing practices, for example. So the inverse key can be applied to samples from populations with differing
age compositions than the population from which it was derived, so long as size at age does not vary considerably among sampling
events (copied from Ailloud and Hoenig, 2019).
</p>


<h3>Value</h3>

<p>list containing observed objects (alk1, lf1, lf2), the estimated alk in numbers for lf2, residuals, 
and the estimated age composition for lf2.</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Ailloud, L. E. and J. M. Hoenig. 2019. A general theory of age-length keys: combining the forward and inverse keys to estimate age composition from
incomplete data. ICES Journal of Marine Science. 76: 1515-1523.
</p>
<p>Hoenig, J. M. and D. M. Heisey. 1987. Use of a log-linear model with the EM 
algorithm to correct estimates of stock composition and to convert length to age.
Transactions of the American Fisheries Society 116: 232-243.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alkD">alkD</a></code> <code><a href="#topic+alkss">alkss</a></code> <code><a href="#topic+alkprop">alkprop</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Not run: 
  data(hohe) 
  inverse_alk(alk1=hohe$alk,lf1=NULL,lf2=hohe$lengths,toler=0.000001,max.iter=100000)
 
## End(Not run)
</code></pre>

<hr>
<h2 id='irm_cr'>Age-Independent Instantaneous Rates Model of Jiang et al. (2007) Incorporating Catch and Release Tag Returns </h2><span id='topic+irm_cr'></span>

<h3>Description</h3>

<p>The age-independent instantaneous rates model of Jiang et al. (2007) for estimating fishing and natural 
mortality from catch-release tag returns is implemented assuming known values of initial tag survival (phi) and 
reporting rate (lambda)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>irm_cr(relyrs = NULL, recapyrs = NULL, N = NULL, recapharv = NULL, 
recaprel = NULL, hlambda = NULL, rlambda = NULL, hphi = NULL, 
rphi = NULL, hmrate = NULL, Fyr = NULL, FAyr = NULL, Myr = NULL,
initial = c(0.1,0.05,0.1), lower = c(0.0001,0.0001,0.0001), 
upper=c(5,5,5),maxiter=500)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="irm_cr_+3A_relyrs">relyrs</code></td>
<td>
<p>vector containing the start and end year of the entire release period (e.g., c(1992, 2006)).</p>
</td></tr>
<tr><td><code id="irm_cr_+3A_recapyrs">recapyrs</code></td>
<td>
<p>vector containing the start year and end year of entire recapture period (e.g., c(1992, 2008)).</p>
</td></tr>
<tr><td><code id="irm_cr_+3A_n">N</code></td>
<td>
<p>vector of total number of tagged fish released in each release year (one value per year).</p>
</td></tr>
<tr><td><code id="irm_cr_+3A_recapharv">recapharv</code></td>
<td>
<p>matrix of the number of tag recoveries of harvested fish by release year (row) and recovery year 
(column). The lower triangle (blank cells) may be filled with -1s as place holders.  Missing values in the upper
triangle (release/recovery cells) are not allowed.</p>
</td></tr>
<tr><td><code id="irm_cr_+3A_recaprel">recaprel</code></td>
<td>
<p>matrix of the number of tag recoveries of fish recaptured and re-released with the tag removed 
by release year (row) and recovery year (column). The lower triangle (blank cells) may be filled with -1s as 
place holders.  Missing values in the upper triangle (release/recovery cells) are not allowed.</p>
</td></tr>
<tr><td><code id="irm_cr_+3A_hlambda">hlambda</code></td>
<td>
<p>vector of reporting rate estimates (lambda) for harvested fish. One value for each recovery year.</p>
</td></tr>
<tr><td><code id="irm_cr_+3A_rlambda">rlambda</code></td>
<td>
<p>vector of reporting rate estimates (lambda) for recaptured fish re-released with tag removed. 
One value for each recovery year.</p>
</td></tr>
<tr><td><code id="irm_cr_+3A_hphi">hphi</code></td>
<td>
<p>vector of initial tag survival estimates (phi) for harvested fish. One value for each recovery year.
1 = no loss</p>
</td></tr>
<tr><td><code id="irm_cr_+3A_rphi">rphi</code></td>
<td>
<p>vector of initial tag survival estimates (phi) for recaptured fish re-released with tag removed fish. 
One value for each recovery year. 1 = no loss</p>
</td></tr>
<tr><td><code id="irm_cr_+3A_hmrate">hmrate</code></td>
<td>
<p>vector of hooking mortality rates. One value for each recovery year.</p>
</td></tr>
<tr><td><code id="irm_cr_+3A_fyr">Fyr</code></td>
<td>
<p>vector of year values representing the beginning year of a period over which to estimate a constant 
fishing mortality rate (F). If estimation of F for each recovery year is desired, enter the year value for each
year. The first year value must be the start year for the recovery period.</p>
</td></tr>
<tr><td><code id="irm_cr_+3A_fayr">FAyr</code></td>
<td>
<p>vector of year values representing the beginning year of a period over which to estimate a constant tag 
mortality rate (FA). If estimation of FA for each recovery year is desired, enter the year value for each year. 
The first year value must be the start year for the recovery period.</p>
</td></tr>
<tr><td><code id="irm_cr_+3A_myr">Myr</code></td>
<td>
<p>vector of year values representing the beginning year of a period over which to estimate a constant natural 
mortality rate (M). If estimation of M for each recovery year is desired, enter the year value for each year. The first 
year value must be the 	start year for the recovery period.</p>
</td></tr>
<tr><td><code id="irm_cr_+3A_initial">initial</code></td>
<td>
<p>vector of starting values for fishing, tag, and 	natural mortality estimates. First position is the 
starting value for all Fs, second position is the starting value for all FAs, and the third position is the starting 
value for all Ms (e.g., c(0.1,0.1,0.2)).</p>
</td></tr>
<tr><td><code id="irm_cr_+3A_lower">lower</code></td>
<td>
<p>vector of lower bounds of F, FA, and M estimates used in optimization routine. First position is the 
lower value for all Fs, second position is the lower value for all FAs, and the third position
is the lower value for all Ms.</p>
</td></tr>
<tr><td><code id="irm_cr_+3A_upper">upper</code></td>
<td>
<p>vector of upper bounds of F, FA, and M estimates used in optimization routine. First position is the 
upper value for all Fs, second position is the upper value for all FAs, and the third position 
is the upper value for all Ms.</p>
</td></tr>
<tr><td><code id="irm_cr_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number iterations used in the optimization routine.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Jiang et al (2007) provides an extension of the Hoenig et al. (1998) instantaneous tag return model to account for 
catch/release of tagged fish. The benefits of this instantaneous rates model are that data from tagged fish that 
are recaptured and released alive are directly incorporated in the estimation of fishing and natural mortality.  
Jiang et al. models mortality of harvested fish and the mortality experienced by the tag because fish are often 
released after the tag has been removed. Therefore, additional tag mortality parameters are estimated in the model. 
The age-independent model of Jiang et al. is implemented here and initial tag loss and reporting rates are assumed 
known.  This model assumes that tagged fish are fully-recruited to the fishery and that fishing took place throughout
the year.  Similar to Hoenig et al. (1998), observed recovery matrices from the harvest and catch/release fish with 
removed tags are compared to expected recovery matrices to estimate model parameters. Asymmetric recovery matrices 
are allowed (recovery years &gt; release years). All summary statistics follow Burnham and Anderson (2002).  Model 
degrees of freedom are calculated as the number of non-zero cells in the harvested and released recapture matrices 
minus the number of estimated parameters. Total chi-square is calculated by summing cell 
chi-square values for all cells of the harvest, released, and not seen matrices. C-hat, a measure 
of overdispersion, is estimated by dividing the total chi-square value by the model degrees of freedom. Pooling 
of cells to achieve an expected cell value of 1 is performed and pooled chi-square and c-hat metrics are 
additionally calculated.Pearson residuals are calculated by subtracting the observed numbers of recoveries in each 
cell from the predicted numbers of recoveries and dividing each cell by the square-root of the predicted cell value. 
The variance of instantaneous total mortality (Z) is calculated by <code>varF + hmrate^2*varFA + varM + 2*sum(cov(F,M)+
hmrate^2*cov(F,FA)+hmrate^2*cov(FA,M))</code>, and the variance of survival (S) is calculated from Z using the delta method.  
The <code>optim</code> routine is used to find the parameters that minimize the -1*negative log-likelihood.
</p>
<p>The program allows the configuration of different model structures (biological realistic models) for the estimation of
fishing, natural, and tag mortalities.  Consider the following examples:
</p>
<p><em>Example 1</em>
</p>
<p>Release years range from 1991 to 2003 and recovery years from 1991 to 2003.  One model structure might be constant 
fishing mortality estimates over the recovery years of 1991-1994 and 1995-2003, one constant estimate of tag mortality 
and one constant estimate of natural mortality for the entire recovery period.  To designate this model structure, 
the beginning year of each interval is assigned to the <code>Fyr</code> vector (e.g.,<code>Fyr&lt;-c(1991, 1995)</code>), and the 
beginning year of the recovery period is assigned to the <code>FAyr</code> vector and the <code>Myr</code> vector 
(e.g., <code>FAyr&lt;-c(1991)</code>; <code>Myr&lt;-c(1991)</code>).  The first value of each vector must always be the beginning year
of the recovery period regardless of the model structure.
</p>
<p><em>Example 2</em>
</p>
<p>Release years range from 1991 to 2003 and recovery years from 1991 to 2003.  One model might be fishing and tag 
mortality estimates for each year of recovery years and two constant estimates of natural mortality for 1991-1996 and
1997-2003.  To designate this model structure, one value for each year is assigned to the Fyr and FAyr 
vectors (e.g., Fyr&lt;-c(1991,1992,1993,1994,1995,1996,1997, 1998,1999,2000,2001,2002,2003 and
FAyr&lt;-c(1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003)), and the 
beginning years of the natural mortality intervals are assigned to the Myr vector (e.g.,Myr&lt;-c(1991,1997)).
</p>
<p>Averaging of model results can be accomplished using the function <code>tag_model_avg</code>.
</p>


<h3>Value</h3>

<p>List containing summary statistics for the model fit, model convergence status, parameter correlation matrix,
estimates of fishing mortality, natural mortality, tag mortality, total instantaneous mortality (Z), and survival (S)
and their variances and standard errors by year, observed and predicted recoveries for harvested, released, and
&quot;not-seen&quot; fish, cell chi-square and Pearson values for harvested, released, and &quot;not seen&quot; fish, and a model 
configuration label (type) used in the <code>tag_model_avg</code> function.
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

 
<p>Burnham, K. P. and D. R. Anderson. 2002. Model selection and multimodel inference : A Practical Information-Theorectic 
Approach, 2nd edition. Spriner-Verlag, New York, NY. 488 p.
</p>
<p>Hoenig, J. M, N. J. Barrowman, W. S. Hearn, and K. H. Pollock. 1998. Multiyear tagging studies incorporating 
fishing effort data.  Canadian Journal of Fisheries and Aquatic Sciences 55: 1466-1476.
</p>
<p>Jiang, H. 2005. Age-dependent tag return models for estimating fishing mortality, natural mortality and selectivity. 
Doctoral dissertation. North Carolina State  University, Raleigh.
</p>
<p>Jiang, H., K. H. Pollock, C. Brownie, J. M. Hoenig, R. J. Latour, B. K. Wells, and J. E. Hightower. 2007.  Tag 
return models allowing for harvest and catch and release: evidence of environmental and management impacts on 
striped bass fishing and natural mortality rates.  North Amercian Journal of Fisheries Management 27:387-396.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+irm_h">irm_h</a></code> <code><a href="#topic+tag_model_avg">tag_model_avg</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Data come from Appendix Table A2 and model structure from model (a) in
## Table 3.2 of Jiang (2005) 
## Example takes a bit of time to run
  ## Not run: 
  data(Jiang)
   model1&lt;-irm_cr(relyrs = Jiang$relyrs, recapyrs = Jiang$recapyrs, 
     N = Jiang$N, recapharv = Jiang$recapharv, recaprel = Jiang$recaprel,
     hlambda = Jiang$hlambda, rlambda = Jiang$rlambda, hphi = Jiang$hphi,
     rphi = Jiang$rphi, hmrate = Jiang$hmrate, Fyr = Jiang$Fyr,
     FAyr = Jiang$FAyr, Myr = Jiang$Myr, initial = c(0.1,0.05,0.1), 
     lower = c(0.0001,0.0001,0.0001), upper=c(5,5,5),maxiter=10000)
  
## End(Not run)
</code></pre>

<hr>
<h2 id='irm_h'>Age-Independent Instantaneous Rates Tag Return Model of Hoenig et al. (1998)</h2><span id='topic+irm_h'></span>

<h3>Description</h3>

<p>The age-independent instantaneous rates model of Hoenig et al. (1998) for estimating fishing and natural 
mortality from tag returns of harvested fish is implemented assuming known values of initial tag survival (phi) and 
reporting rate (lambda)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>irm_h(relyrs = NULL, recapyrs = NULL, N = NULL, recapharv = NULL,
lambda = NULL,phi = NULL, Fyr = NULL, Myr = NULL, initial = NULL,
lower = c(0.0001,0.0001),upper = c(5,5), maxiter = 10000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="irm_h_+3A_relyrs">relyrs</code></td>
<td>
<p>vector containing the start and end year of the entire release period 
(e.g., c(1992, 2006)).</p>
</td></tr>
<tr><td><code id="irm_h_+3A_recapyrs">recapyrs</code></td>
<td>
<p>vector containing the start year and end year of entire recapture period (e.g., c(1992, 2008)).</p>
</td></tr>
<tr><td><code id="irm_h_+3A_n">N</code></td>
<td>
<p>vector of total number of tagged fish released in each release year (one value per year).</p>
</td></tr>
<tr><td><code id="irm_h_+3A_recapharv">recapharv</code></td>
<td>
<p>matrix of the number of tag recoveries of harvested fish by release year (row) and recovery year
(column). The lower triangle (blank cells) may be filled with -1s as place holders.  Missing values in the upper 
triangle (release/recovery cells) are not allowed.</p>
</td></tr>
<tr><td><code id="irm_h_+3A_lambda">lambda</code></td>
<td>
<p>vector of reporting rate estimates for harvested fish. One value for each recovery year.</p>
</td></tr>
<tr><td><code id="irm_h_+3A_phi">phi</code></td>
<td>
<p>vector of initial tag survival estimates (phi) for harvested fish. One value for each recovery year.
1=no loss</p>
</td></tr>
<tr><td><code id="irm_h_+3A_fyr">Fyr</code></td>
<td>
<p>vector of year values representing the beginning year of a period over which to estimate a constant 
fishing mortality rate
(F). If estimation of F for each recovery year is desired, enter the year value for each year. The first year value 
must be the start year for the recovery period.</p>
</td></tr>
<tr><td><code id="irm_h_+3A_myr">Myr</code></td>
<td>
<p>vector of year values representing the beginning year of a period over which to estimate a constant natural 
mortality rate (M). If estimation of M for each recovery year is desired, enter the year value for each year. The first 
year value must be the 	start year for the recovery period.</p>
</td></tr>
<tr><td><code id="irm_h_+3A_initial">initial</code></td>
<td>
<p>vector of starting values for fishing, and	natural mortality estimates. 
First position is the starting value for all Fs and second position is the starting value for all Ms (e.g., c(0.1,0.2)).</p>
</td></tr>
<tr><td><code id="irm_h_+3A_lower">lower</code></td>
<td>
<p>vector of lower bounds of F and M estimates used in optimization routine. 
First position is the lower value for all Fs and second position is the lower value for all Ms. Default = 0.0001.</p>
</td></tr>
<tr><td><code id="irm_h_+3A_upper">upper</code></td>
<td>
<p>vector of upper bounds of F and M estimates used in optimization routine. 
First position is the upper value for all Fs and second position is the upper value for all Ms. Default = 5</p>
</td></tr>
<tr><td><code id="irm_h_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number iterations used in the optimization routine.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The instantaneous tag return model of Hoening et al. (1998) assuming known initial tag loss and reporting rates is
implemented. This model assumes that tagged fish are fully-recruited to the fishery and that fishing took place 
throughout the year.  The observed recovery matrices are compared to expected recovery matrices to estimate model 
parameters. Asymmetric recovery matrices are allowed (recovery years &gt; release years). All summary statistics follow 
Burnham and Anderson (2002).  Model degrees of freedom are calculated as the number of non-zero cells in the 
harvested recovery matrix minus the number of estimated parameters. Total chi-square is calculated by 
summing cell chi-square values for all cells of the harvest, released, and not seen matrices.
C-hat, a measure of overdispersion, is estimated by dividing the total chi-square value by the model degrees of freedom.
Pooling of cells to achieve an expected cell value of 1 is performed and pooled chi-square and c-hat metrics are 
additionally calculated. Pearson residuals are calculated by subtracting the observed numbers of recoveries in each 
cell from the predicted numbers of recoveries and dividing each cell by the square-root of the predicted cell value. 
The <code>optim</code> routine is used to find the parameters that minimize the -1*negative
log-likelihood. The variance of instantaneous total mortality (Z) is calculated by <code>varF + varM + 2cov(F,M)</code>, and
the variance of survival (S) is estimated from the variance of Z using the delta method.
</p>
<p>The program allows the configuration of different model structures (biological realistic models) for the estimation of
fishing and natural mortalities.  Consider the following examples:
</p>
<p><em>Example 1</em>
</p>
<p>Release years range from 1991 to 2003 and recovery years from 1991 to 2003.  One model structure might be constant 
fishing mortality estimates over the recovery years of 1991-1994 and 1995-2003, and one constant estimate of natural
mortality for the entire recovery period.  To specify this model structure, the beginning year of each interval is 
assigned to the <code>Fyr</code> vector (e.g.,Fyr&lt;-c(1991, 1995)), and the beginning year of the recovery period 
is assigned to the <code>Myr</code> vector  (e.g.,Myr&lt;-c(1991)).  The first value of each vector must always be
the beginning year of the recovery period regardless of the model structure.
</p>
<p><em>Example 2</em>
</p>
<p>Release years range from 1991 to 2003 and recovery years from 1991 to 2003.  One model might be fishing mortality 
estimates for each year of recovery years and two constant estimates of natural mortality for 1991-1996 and
1997-2003.  To specify this model structure, one value for each year is assigned to the Fyr vector 
(e.g., Fyr&lt;-c(1991,1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003) and the beginning 
years of the natural mortality intervals are assigned to the Myr vector (e.g.,Myr&lt;-c(1991, 1997)).
</p>
<p>Averaging of model results can be accomplished using the function <code>tag_model_avg</code>.
</p>


<h3>Value</h3>

<p>List containing summary statistics for the model fit, model convergence status, parameter correlation matrix,
estimates of fishing mortality, natural mortality, total instantaneous mortality (Z), and survival (S)
and their variances and standard errors by year, observed and predicted recoveries for harvested, released, and
&quot;not-seen&quot; fish, cell chi-square and Pearson values for harvested, released, and &quot;not seen&quot; fish and a model 
configuration label (type) used in the <code>tag_model_avg</code> function.
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

 
<p>Burnham, K. P. and D. R. Anderson. 2002. Model selection and multimodel inference : A Practical Information-Theorectic
Approach, 2nd edition. Spriner-Verlag, New York, NY. 488 p.
</p>
<p>Hoenig, J. M, N. J. Barrowman, W. S. Hearn, and K. H. Pollock. 1998. Multiyear tagging studies incorporating fishing 
effort data.  Canadian Journal of Fisheries and Aquatic Sciences 55: 1466-1476.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+irm_cr">irm_cr</a></code> <code><a href="#topic+tag_model_avg">tag_model_avg</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Data come from Table 4 and model structure from Table 5 under "year-specific F, 
# constant M" in Hoenig et al. (1998)  
data(Hoenig)
model1&lt;-irm_h(relyrs = Hoenig$relyrs, recapyrs = Hoenig$recapyrs, 
N = Hoenig$N, recapharv = Hoenig$recapharv,lambda = Hoenig$lambda,
phi = Hoenig$phi, Fyr = Hoenig$Fyr, Myr = Hoenig$Myr, initial = c(0.1,0.1), 
lower = c(0.0001,0.0001),upper = c(5,5), maxiter = 10000)
</code></pre>

<hr>
<h2 id='Jensen'>Age Frequency Data for Lake Whitefish By Individual Haul</h2><span id='topic+Jensen'></span>

<h3>Description</h3>

<p>The <code>Jensen</code> data frame has 312 rows and 2 columns.
The age data are from reconstructed catches of lake whitefish reported
by Jensen (1996) in Table 1 and were expanded to individual observations from the age frequency table. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Jensen
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>group</dt><dd><p>net haul label</p>
</dd>
<dt>age</dt><dd><p>age of an individual fish</p>
</dd>
</dl>



<h3>Source</h3>

<p>Jensen, A. L. 1996. <em>Ratio estimation of mortality using catch curves</em>. Fisheries Research 27: 61-67.
</p>

<hr>
<h2 id='Jiang'>Tag Data from Jiang (2005)</h2><span id='topic+Jiang'></span>

<h3>Description</h3>

<p>The <code>Jiang</code> list containing 13 components of data.
Data were obtained from the Jiang (2005).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Jiang
</code></pre>


<h3>Format</h3>

<p>This list contains the following components:
</p>

<dl>
<dt>relyrs</dt><dd><p>vector of start and end years of release years</p>
</dd>
<dt>recapyrs</dt><dd><p>vector of start and end years of recapture years</p>
</dd>
<dt>N</dt><dd><p>vector of number of tags released in each release year</p>
</dd>
<dt>recapharv</dt><dd><p>recapture matrix of harvest fish</p>
</dd>
<dt>recaprel</dt><dd><p>recapture matrix of recaptured and re-released fish with tag removed</p>
</dd>
<dt>hlambda</dt><dd><p>vector of reporting rates of harvested fish (one value for each recapture year)</p>
</dd>
<dt>rlambda</dt><dd><p>vector of reporting rates of recaptured and re-released fish (one value for each recapture year)</p>
</dd>
<dt>hphi</dt><dd><p>vector of initial tag loss of harvested fish (one value for each recapture year)</p>
</dd>
<dt>rphi</dt><dd><p>vector of initial tag loss of harvested fish (one value for each recapture year)</p>
</dd>
<dt>hmrate</dt><dd><p>vector of hooking mortality rates (one value for each recapture year)</p>
</dd>
<dt>Fyr</dt><dd><p>vector of years to estimate fishing mortality</p>
</dd>
<dt>FAyr</dt><dd><p>vector of years to estimate tag mortality</p>
</dd>
<dt>Myr</dt><dd><p>vector of years to estimate natural mortality</p>
</dd>
</dl>



<h3>Source</h3>

<p>Jiang, H. 2005. Age-dependent tag return models for estimating fishing mortality, natural mortality and selectivity. 
Doctoral dissertation. North Carolina State  University, Raleigh.
</p>

<hr>
<h2 id='kappenman'>Pacific cod catch per effort from Table 1 in Kappenman (1999)</h2><span id='topic+kappenman'></span>

<h3>Description</h3>

<p>The <code>kappenman</code> data frame has 55 rows and 1 column.</p>


<h3>Usage</h3>

<pre><code class='language-R'>kappenman
</code></pre>


<h3>Format</h3>

<p>This data frame contains one column:
</p>

<dl>
<dt>cpue</dt><dd><p>Pacific cod cpue from 1994</p>
</dd>
</dl>



<h3>Source</h3>

<p>Kappenman, R. F. 1999. Trawl survey based abundance estimation using data sets 
with unusually large catches. ICES Journal of Marince Science 56: 28-35.
</p>

<hr>
<h2 id='Kimura'>Length and Age Data For Male and Female Pacific Hake</h2><span id='topic+Kimura'></span>

<h3>Description</h3>

<p>The <code>Kimura</code> data frame has 24 rows and 3 columns.
Mean length-at-age data for male and female Pacific hake as reported by Kimura (1980)</p>


<h3>Usage</h3>

<pre><code class='language-R'>Kimura
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>age</dt><dd><p>fish age</p>
</dd>
<dt>length</dt><dd><p>mean length of fish of age <em>age</em></p>
</dd>
<dt>sex</dt><dd><p>sex code</p>
</dd> 
</dl>



<h3>Source</h3>

<p>Kimura, D. K. 1980. <em>Likelihood methods for the von Bertalanffy growth curve</em>. 
U. S. Fishery Bulletin 77:765-776.
</p>

<hr>
<h2 id='lepdata'>Simulated data based on parameters estimated from corrected 1980s bluefin tuna data used in Laslett et al.(2002)</h2><span id='topic+lepdata'></span>

<h3>Description</h3>

<p>The <code>lepdata</code> data frame has 500 rows and 3 columns
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lepdata
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>l1</dt><dd><p>release length</p>
</dd>
<dt>l2</dt><dd><p>reapture length</p>
</dd>
<dt>dt</dt><dd><p>time increment between release and recapture</p>
</dd>
</dl>



<h3>Source</h3>

<p>Original data provided by Paige Eveson of CSIRO Marine Research.
</p>

<hr>
<h2 id='lifetable'>Life Table Construction</h2><span id='topic+lifetable'></span>

<h3>Description</h3>

<p>Life tables are constructed from either numbers of individuals of a cohort alive at the
start of an age interval (nx) or number of individuals of a cohort dying during the age interval (dx).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lifetable(age = NULL, numbers = NULL, r = NULL, type = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lifetable_+3A_age">age</code></td>
<td>
<p> vector of age intervals (e.g., 0 to maximum cohort age).</p>
</td></tr>
<tr><td><code id="lifetable_+3A_numbers">numbers</code></td>
<td>
<p>number of individual alive (nx) or dead (dx) </p>
</td></tr>
<tr><td><code id="lifetable_+3A_r">r</code></td>
<td>
<p>known rate of increase (r) for methods 3 and 4</p>
</td></tr>
<tr><td><code id="lifetable_+3A_type">type</code></td>
<td>
<p>numeric value of method to use to calculate life table.
</p>
<p>1 = Age at death recorded directly and no assumption made about population stability or stability of age structure - Method 1 in Krebs (1989).
2 = Cohort size recorded directly and and no assumption made about population stability or stability of age structure - Method 2 in Krebs (1989).
3 = Ages at death recorded for a population with stable age distribution and known rate of increase - Method 5 in Krebs (1989).
4 = Age distribution recorded for a population with a stable age distribution and known rate of increase - Method 6 in Krebs (1989).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Following Krebs (1989:413-420),  standard life tables are calculated given age intervals and either cohort size or deaths.
X=age interval, nx=number of individuals of a cohort alive at the start of age interval X, lx = proportion of individuals surviving at the start of
age interval X, dx = number of individuals of a cohort dying during the age interval X,
qx=finite rate of mortality during the age interval X to X+1, px=finite rate of survival during the age interval X to X+1,
ex=mean expectation of life for individuals alive at start of age X. 
For method 5, dx is corrected for population growth by <em>dx'=dx*exp(r*x)</em> and in method 6, nx is corrected for the same by <em>nx*e(r*x)</em>.
See Krebs for formulae.
</p>


<h3>Value</h3>

<p>Dataframe containing life table values.
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Krebs, C. J. 1989. <em>Ecological Methodologies</em>. Harper and Row, New York, NY. 654 p.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(buffalo)
lifetable(age=buffalo$age,numbers=buffalo$nx,type=2)
</code></pre>

<hr>
<h2 id='lingcod'>Catch data (metric tons) for lingcod 1889 to 2001</h2><span id='topic+lingcod'></span>

<h3>Description</h3>

<p>Lingcod catch data from literature sources in Martell and Froese (2012).  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lingcod</code></pre>


<h3>Format</h3>

<p>A data frame with 113 observations on the following 2 variables.
</p>

<dl>
<dt><code>year</code></dt><dd><p>a numeric vector describing the year of catch</p>
</dd>
<dt><code>catch</code></dt><dd><p>a numeric vector describing the annual catch in metric tons</p>
</dd>
</dl>



<h3>Details</h3>

<p>Note some data points are not exactly the same as shown in Figure 7 of Martell and Froese 2012.
</p>

<hr>
<h2 id='M.empirical'>Estimation of Natural Mortality Rates from Life History Parameters</h2><span id='topic+M.empirical'></span>

<h3>Description</h3>

<p>The approaches of Pauly (1980), Hoenig (1983), Alverson and Carney (1975), Roff (1984), Gunderson and Dygert (1988),
Petersen and Wroblewski (1984), Lorenzen (1996), Gislason et al. (2010), Then et al. (2015), Brey (1999) and 
Charnov et al. (2013) are encoded for estimation of natural mortality (M).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>M.empirical(Linf = NULL, Winf = NULL, Kl = NULL, Kw = NULL,
 TC = NULL, tmax = NULL, tm = NULL, GSI = NULL, Wdry = NULL,
 Wwet = NULL, Bl = NULL, TK = NULL, BM = NULL, L = NULL, method = c(1, 2, 
3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="M.empirical_+3A_linf">Linf</code></td>
<td>
<p>Length-infinity value from a von Bertalanffy growth curve (total length-cm).</p>
</td></tr>
<tr><td><code id="M.empirical_+3A_winf">Winf</code></td>
<td>
<p>Weight-infinity value from a von Bertalanffy growth curve (wet weight-grams).</p>
</td></tr>
<tr><td><code id="M.empirical_+3A_kl">Kl</code></td>
<td>
<p>Kl is the growth coefficient (per year) from a von Bertalanffy growth curve for length.</p>
</td></tr>
<tr><td><code id="M.empirical_+3A_kw">Kw</code></td>
<td>
<p>Kw is the growth coefficient (per year) from a von Bertalanffy growth curve for weight.</p>
</td></tr>
<tr><td><code id="M.empirical_+3A_tc">TC</code></td>
<td>
<p>the mean water temperature (Celsius) experienced by the stock.</p>
</td></tr>
<tr><td><code id="M.empirical_+3A_tmax">tmax</code></td>
<td>
<p>the oldest age observed for the species.</p>
</td></tr>
<tr><td><code id="M.empirical_+3A_tm">tm</code></td>
<td>
<p>the age at maturity.</p>
</td></tr>
<tr><td><code id="M.empirical_+3A_gsi">GSI</code></td>
<td>
<p>gonadosomatic index (wet ovary weight over wet somatic weight(total-gonad wgt)).</p>
</td></tr>
<tr><td><code id="M.empirical_+3A_wdry">Wdry</code></td>
<td>
<p>total dry weight in grams.</p>
</td></tr>
<tr><td><code id="M.empirical_+3A_wwet">Wwet</code></td>
<td>
<p>total wet weight at mean length in grams.</p>
</td></tr>
<tr><td><code id="M.empirical_+3A_bl">Bl</code></td>
<td>
<p>body length in cm.</p>
</td></tr>
<tr><td><code id="M.empirical_+3A_tk">TK</code></td>
<td>
<p>mean temperature (Kelvin).</p>
</td></tr>
<tr><td><code id="M.empirical_+3A_bm">BM</code></td>
<td>
<p>maximum body mass (kJ - kiloJoules)</p>
</td></tr>
<tr><td><code id="M.empirical_+3A_l">L</code></td>
<td>
<p>fish length along the growth trajectory</p>
</td></tr>
<tr><td><code id="M.empirical_+3A_method">method</code></td>
<td>
<p>vector of method code(s).  Any combination of methods can employed. <code>1</code>= Pauly (1980)
length equation - requires Linf, Kl, and TC; <code>2</code>= Pauly (1980) weight equation - requires Winf, Kw, and TC; 
<code>3</code>= Hoenig (1983) joint equation - requires tmax; <code>4</code>= Alverson and Carney (1975) - requires Kl and tmax; 
<code>5</code>= Roff (1984) - requires Kl and tm; <code>6</code>= Gunderson and Dygert (1988) - requires GSI; <code>7</code>= Peterson
and Wroblewski (1984) - requires Wdry; <code>8</code>= Lorenzen (1996) - requires Wwet;
<code>9</code>= Gislason et al. (2010) - requires Linf, K and Bl; <code>10</code>= Then et al. (2015) tmax - requires tmax;
<code>11</code>= Then et al. (2015) growth  - requires Kl and Linf.
<code>12</code>= Brey (1999) - requires tmax, TK, and BM.
<code>13</code>= Charnov et al (2013) - requires Linf, Kl, and L.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Please read the references below for details about equations. Some estimates of M will not be valid for
certain fish groups.
</p>


<h3>Value</h3>

<p>A matrix of M estimates.
</p>


<h3>Note</h3>

<p>Original functions for the Pauly (1980) length equation and the Hoenig (1983) fish equation were provided by Michael H. Prager, National Marine Fisheries Service, Beaufort, North Carolina.</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Alverson, D. L. and M. J. Carney. 1975. A graphic review of the growth and decay of population cohorts. J. Cons. Int. Explor. Mer 36: 133-143.
</p>
<p>Brey, T. 1999. Growth performance and mortality in aquatic macrobenthic invertebrates. Advances in Marine Biology 35: 155-223.
</p>
<p>Charnov, E. L., H. Gislason, J. G. Pope. 2013. Evolutionary assembly rules for fish life histories. Fish and Fisheries 14: 213-224.
</p>
<p>Gislason, H., N. Daan, J. C. Rice, and J. G. Pope. 2010. Size, growth, temperature and the natural mortality of marine fish. Fish and Fisheries 11: 149-158.
</p>
<p>Gunderson, D. R. and P. H. Dygert. 1988. Reproductive effort as a predictor of natural mortality rate. J. Cons. Int. Explor. Mer 44: 200-209.
</p>
<p>Hoenig, J. M. 1983. Empirical use of longevity data to estimate mortality rates. Fish. Bull. 82: 898-903.
</p>
<p>Lorenzen, K. 1996. The relationship between body weight and natural mortality in juvenile and adult fish: a comparison of natural ecosystems and aquaculture. J. Fish. Biol. 49: 627-647.
</p>
<p>Pauly, D. 1980. On the interrelationships between natural mortality, growth parameters, and mean environmental temperature in 175 fish stocks. J. Cons. Int. Explor. Mer: 175-192.
</p>
<p>Peterson, I. and J. S. Wroblewski. 1984. Mortality rate of fishes in the pelagic ecosystem. Can. J. Fish. Aquat. Sci. 41: 1117-1120.
</p>
<p>Roff, D. A. 1984.  The evolution of life history parameters in teleosts. Can. J. Fish. Aquat. Sci. 41: 989-1000. 
</p>
<p>Then, A. Y., J. M. Hoenig, N. G. Hall, D. A. Hewitt. 2015. Evaluating the predictive performance of empirical estimators of natural mortality rate using information on over 200 fish species. 
ICES J. Mar. Sci. 72: 82-92.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>M.empirical(Linf=30.1,Kl=0.31,TC=24,method=c(1))
</code></pre>

<hr>
<h2 id='maki'>Data from Maki et al. 2001</h2><span id='topic+maki'></span>

<h3>Description</h3>

<p>The <code>maki</code> data frame has 876 rows and 2 columns.
From Table 1 for 3 years combined
</p>


<h3>Usage</h3>

<pre><code class='language-R'>maki
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>capture_age</dt><dd><p>age at capture</p>
</dd>
<dt>age_mature</dt><dd><p>age at first maturity (from spawning checks on scales)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Maki, K. L., J. M. Hoenig and J. E. Olney. 2001. Estimating proportion mature at age 
when immature fish are unavailable for study, with applications to American shad in the York
River, Virginia. North Am. J. Fish. Manage. 21: 703-716.</p>

<hr>
<h2 id='mature'>Estimation of proportion mature at age when immature fish are unavailable</h2><span id='topic+mature'></span>

<h3>Description</h3>

<p>Calculates proportion mature-at-age based on Maki et al. (2001).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mature(cap_age=NULL, mature_age=NULL, age_all_immature=NULL,
age_all_mature=NULL, initial=NULL, nrandoms=1000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mature_+3A_cap_age">cap_age</code></td>
<td>
<p>vector of ages representing age when fish was capture. 
One record per individual.</p>
</td></tr>
<tr><td><code id="mature_+3A_mature_age">mature_age</code></td>
<td>
<p>vector of ages representing age at which individual 
mature.One record per individual.</p>
</td></tr>
<tr><td><code id="mature_+3A_age_all_immature">age_all_immature</code></td>
<td>
<p>age at which all fish are deemed immature. All ages below this age 
are assumed immature also.</p>
</td></tr>
<tr><td><code id="mature_+3A_age_all_mature">age_all_mature</code></td>
<td>
<p>age at which all fish are deemed mature.
All ages above this age are also assumed mature.</p>
</td></tr>
<tr><td><code id="mature_+3A_initial">initial</code></td>
<td>
<p>starting values for proportion estimates. There should be
<em>age_all_mature - age_all_immature-2</em> values. If not, the last value is used for 
missing values or if the vector is too large, the vector is truncated.</p>
</td></tr>
<tr><td><code id="mature_+3A_nrandoms">nrandoms</code></td>
<td>
<p>the number of randomizations used to estimate standard errors.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimation of probability follows Maki et al. (2001).The standard errors of
parameters are estimated via Monte Carlos methods where the number of each maturing age 
for each capture age are randomly draw from a multinomial distribution parameterized with 
probabilities and total sample size of the original data. The methods of Maki et al. (2001)
are applied to the randomized data and the randomization is repeated <em>nrandoms</em> times.
The mean and standard deviation of all runs are treated as the parameter estimates and standard errors. 
</p>


<h3>Value</h3>

<p>a list object containing the estimated proportions-at-age and standard errors,
the original data and expected values
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Maki, K. L., J. M. Hoenig and J. E. Olney. 2001. Estimating proportion mature at age 
when immature fish are unavailable for study, with applications to American shad in the York
River, Virginia. North Am. J. Fish. Manage. 21: 703-716.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## Not run: 
   ## Maki data for 3 years combined
   data(maki)
    mature(cap_age=maki$capture_age,mature_age=maki$age_mature,age_all_immature=2,
                 age_all_mature=8,initial=c(0.1,0.05,0.05,0.05),nrandoms=1000)
  
## End(Not run)

</code></pre>

<hr>
<h2 id='menhaden'>Biological data for menhaden (Brevoortia tyrannus)</h2><span id='topic+menhaden'></span>

<h3>Description</h3>

<p>The <code>menhaden</code> data frame has 15 rows and 4 columns.
Age, fecundity-at-age, partial recruitment, fraction mature, and nautral mortality data for menhaden 
to calculate eggs-per-recruit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>menhaden
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>age</dt><dd><p>vector of ages</p>
</dd>
<dt>fecundity</dt><dd><p>vector of mean eggs per individual for each age</p>
</dd>
<dt>partial</dt><dd><p>partial recruitment vector</p>
</dd>
<dt>pmat</dt><dd><p>vector of fraction of females mature at age</p>
</dd>
<dt>M</dt><dd><p>vector of natural mortality value-at-age</p>
</dd>
</dl>



<h3>Source</h3>

<p>Atlantic State Marine Fisheries Commission. 2010. 2009 stock assessment report for Atlantic menhaden. ASMFC SAR 10-02.
</p>

<hr>
<h2 id='mort.al'>
Estimation of Mortality using Times-At-Large Data from Tagging
</h2><span id='topic+mort.al'></span>

<h3>Description</h3>

<p>Calculates total instantaneous (Z), natural mortality (M) and/or fishing mortality (F) using times-at-large data
and methods of Gulland (1955) and McGarvey et al. (2009).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mort.al(relyr = NULL, tal = NULL, N = NULL, method = c(1, 2, 3), 
np = 0, stper = NULL, nboot = 500)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mort.al_+3A_relyr">relyr</code></td>
<td>
<p>a vector of release year (or cohort) for individual times-at-large observations.</p>
</td></tr>
<tr><td><code id="mort.al_+3A_tal">tal</code></td>
<td>
<p>a vector of individual times-at-large observations.</p>
</td></tr>
<tr><td><code id="mort.al_+3A_n">N</code></td>
<td>
<p>a vector of number of releases for each release year (or cohort). Each individual observation
from a release year should have the same N value.</p>
</td></tr>
<tr><td><code id="mort.al_+3A_method">method</code></td>
<td>
<p>1 = McGarvey et al., 2 = Gulland.  Default is all (i.e., c(1,2)).</p>
</td></tr>
<tr><td><code id="mort.al_+3A_np">np</code></td>
<td>
<p>the number of periods over which to combine data to make period estimates of mortality. Set 
np=0 to estimate mortality for each release year.</p>
</td></tr>
<tr><td><code id="mort.al_+3A_stper">stper</code></td>
<td>
<p>vector of year values representing the beginning year of each period over which 
to estimate mortality. The first year in c() must always be the first release year.</p>
</td></tr>
<tr><td><code id="mort.al_+3A_nboot">nboot</code></td>
<td>
<p>the number of resamples for the Gulland method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The methods of Gulland (1955) and McGarvey et al (2009) are used to estimate Z, F and M (depending
on the method) from tagging times-at-large data.  For the Gulland method,  the standard error of the Z, M, and F 
estimates are made using a parametric bootstrap method similar to Tanaka (2006). When
periods are specified, period-specific mortality estimates and standard errors are derived by
averaging release-year-specific mortality estimates. The standard errors are calculated by taking the square-root of 
the averaged variances of the estimates. To combine data over all years prior to estimation, change all relyr within 
a period to the same year value.
</p>


<h3>Value</h3>

<p>dataframe containing the M, F and Z estimates and associated standard errors by period.</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Gulland, J. A. 1955. On the estimation of population parameters from marked members. Biometrika 42: 269-270.
</p>
<p>McGarvey, R., J. M. Matthews, and J. E. Feenstra. 2009.  Estimating mortality from times-at-large: testing accuracy and precision 
using simulated single tag-recovery data. ICES Journal of Marine Science 66: 573-581.
</p>
<p>Tanaka, E. 2006. Simultaneous estimation of instantaneous mortality coefficients and rate of effective survivors to number of released fish 
using multiple sets of tagging experiments. Fisheries Science 72: 710-718.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Not run: 
  data(tanaka)
  mort.al(relyr = tanaka$relyr, tal = tanaka$tal, N = tanaka$N)
 
## End(Not run)
</code></pre>

<hr>
<h2 id='mrN.single'>Estimate of Population Size from a Single Mark-Recapture Experiment</h2><span id='topic+mrN.single'></span>

<h3>Description</h3>

<p>Estimates population sizes, standard errors, and confidence intervals for 
the bias-corrected Petersen and the Bailey binomial estimators.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mrN.single(M = NULL, C = NULL, R = NULL, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mrN.single_+3A_m">M</code></td>
<td>
<p> Number of marked animals released</p>
</td></tr>
<tr><td><code id="mrN.single_+3A_c">C</code></td>
<td>
<p>Number of animals captured</p>
</td></tr>
<tr><td><code id="mrN.single_+3A_r">R</code></td>
<td>
<p> Number of animals recaptured</p>
</td></tr>
<tr><td><code id="mrN.single_+3A_alpha">alpha</code></td>
<td>
<p> alpha level for confidence intervals</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The  bias-corrected Petersen estimator and its variance (Seber 2002: p.60),  and the Bailey binomial estimator and its variance 
(Seber 2002: p.61) are calculated.  The hypergeometric distribution is used to estimate confidence intervals for the Petersen model 
and the binomial distribution is used to estimate confidence intervals for the Bailey model.  
</p>


<h3>Value</h3>

<p>Dataframe containing the population estimates (N), standard errors of N, the lower confidence limits (LCI),
and the upper confidence limits(UCI).
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p> Seber, G. A. F. 2002. <em>The Estimation of Animal Abundance and Related Parameters, Second Edition</em>. The Blackburn Press,
Caldwell, New Jersey. 654 p.</p>


<h3>Examples</h3>

<pre><code class='language-R'>mrN.single(M=948,C=421,R=167)
</code></pre>

<hr>
<h2 id='nshrimp'>Data for Gulf of Maine northern shrimp</h2><span id='topic+nshrimp'></span>

<h3>Description</h3>

<p>Recruit and postrecruit survey indices and catch data for Gulf of Maine northern shrimp (Pandulus borealis), 1985-2007</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(nshrimp)</code></pre>


<h3>Format</h3>

<p>A data frame with 23 observations on the following 4 variables.
</p>

<dl>
<dt><code>year</code></dt><dd><p>a numeric vector describing the year</p>
</dd>
<dt><code>r</code></dt><dd><p>a numeric vector of the recruit index</p>
</dd>
<dt><code>n</code></dt><dd><p>a numeric vector of the postrecruit index</p>
</dd>
<dt><code>C</code></dt><dd><p>a numeric vector of the landings (in numbers)</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://www.fisheries.noaa.gov/region/new-england-mid-atlantic#science">https://www.fisheries.noaa.gov/region/new-england-mid-atlantic#science</a>
</p>

<hr>
<h2 id='opt_slot'>Optimum Slot and Trophy Size Limits for Recreational Fisheries</h2><span id='topic+opt_slot'></span>

<h3>Description</h3>

<p>Calculates optimum trophy catch given a slot size over a range of F values. Also, finds Fmax for a cohort given age-at-first recruitment,
age-at-first-entry, slot age, and age at which fish are considered trophy size following Jensen (1981).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>opt_slot(M = NULL, N = 1000, recage = NULL, entage = NULL,
 trage = NULL, slage = NULL,  stF = 0, endF = 2, intF = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="opt_slot_+3A_m">M</code></td>
<td>
<p>natural mortality</p>
</td></tr>
<tr><td><code id="opt_slot_+3A_n">N</code></td>
<td>
<p> cohort size</p>
</td></tr>
<tr><td><code id="opt_slot_+3A_recage">recage</code></td>
<td>
<p>age-at-first recruitment</p>
</td></tr>
<tr><td><code id="opt_slot_+3A_entage">entage</code></td>
<td>
<p>age-at-entry into the fishery</p>
</td></tr>
<tr><td><code id="opt_slot_+3A_slage">slage</code></td>
<td>
<p>upper age of slot for legal fish</p>
</td></tr>
<tr><td><code id="opt_slot_+3A_trage">trage</code></td>
<td>
<p>age of fish considered trophy size</p>
</td></tr>
<tr><td><code id="opt_slot_+3A_stf">stF</code></td>
<td>
<p>starting F of range to explore</p>
</td></tr>
<tr><td><code id="opt_slot_+3A_endf">endF</code></td>
<td>
<p>ending F of range to explore</p>
</td></tr>
<tr><td><code id="opt_slot_+3A_intf">intF</code></td>
<td>
<p>increment of F</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculations follow equations given in Jensen (1981).
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Catch</code></td>
<td>
<p>dataframe containing range of Fs and associated total catch, nontrophy, and trophy catch of designated cohort size</p>
</td></tr>
<tr><td><code>Fmax</code></td>
<td>
<p>F at which trophy catch is maximum given slot</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Jense, A. L. 1981. Optimum size limits for trout fisheries. Can. J. Fish. Aquat. Sci. 38: 657-661.</p>


<h3>See Also</h3>

<p><code><a href="#topic+opt_trophy">opt_trophy</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Example from Jensen (1981) page 661
opt_slot(M=0.70,N=1000,recage=1,entage=1,slage=3,trage=4)
</code></pre>

<hr>
<h2 id='opt_trophy'>Optimum Trophy Size Limits for Recreational Fisheries</h2><span id='topic+opt_trophy'></span>

<h3>Description</h3>

<p>Calculates optimum trophy catch over a range of F values and finds Fmax for a cohort given age-at-first recruitment,
age-at-first-entry, and age at which fish are considered trophy size following Jensen (1981).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>opt_trophy(M = NULL, N = 1000, recage = NULL, entage = NULL,
 trage = NULL, stF = 0, endF = 2, intF = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="opt_trophy_+3A_m">M</code></td>
<td>
<p>natural mortality</p>
</td></tr>
<tr><td><code id="opt_trophy_+3A_n">N</code></td>
<td>
<p> cohort size</p>
</td></tr>
<tr><td><code id="opt_trophy_+3A_recage">recage</code></td>
<td>
<p>age-at-first recruitment</p>
</td></tr>
<tr><td><code id="opt_trophy_+3A_entage">entage</code></td>
<td>
<p>age-at-entry into the fishery</p>
</td></tr>
<tr><td><code id="opt_trophy_+3A_trage">trage</code></td>
<td>
<p>age of fish considered trophy size</p>
</td></tr>
<tr><td><code id="opt_trophy_+3A_stf">stF</code></td>
<td>
<p>starting F of range to explore</p>
</td></tr>
<tr><td><code id="opt_trophy_+3A_endf">endF</code></td>
<td>
<p>ending F of range to explore</p>
</td></tr>
<tr><td><code id="opt_trophy_+3A_intf">intF</code></td>
<td>
<p>increment of F</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculations follow equations given in Jensen (1981).
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Catch</code></td>
<td>
<p>dataframe containing range of Fs and associated total catch and trophy catch of designated cohort size</p>
</td></tr>
<tr><td><code>Fmax</code></td>
<td>
<p>F at which trophy catch is maximum</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Jense, A. L. 1981. Optimum size limits for trout fisheries. Can. J. Fish. Aquat. Sci. 38: 657-661.</p>


<h3>See Also</h3>

<p><code><a href="#topic+opt_slot">opt_slot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Example from Jensen (1981) page 659
opt_trophy(M=0.70,N=1000,recage=1,entage=1,trage=4)
</code></pre>

<hr>
<h2 id='P.donacina'>Data from a growth study of New Zealand intertidal clams.</h2><span id='topic+P.donacina'></span>

<h3>Description</h3>

<p>Growth increment data derived from a tagging experiment on Paphis donacina
</p>


<h3>Usage</h3>

<pre><code class='language-R'>P.donacina</code></pre>


<h3>Format</h3>

<p>A data frame with 150 observations on the following 4 variables.
</p>

<dl>
<dt><code>T1</code></dt><dd><p>a numeric vector describing the release date (y)</p>
</dd>
<dt><code>T2</code></dt><dd><p>a numeric vector describing the recovery date (y)</p>
</dd>
<dt><code>L1</code></dt><dd><p>a numeric vector describing the length at release (mm)</p>
</dd>
<dt><code>L2</code></dt><dd><p>a numeric vector describing the length at recapture (mm)</p>
</dd>
</dl>



<h3>Details</h3>

<p>Note that the data have been corrected for measurement bias, as
described by Cranfield et al (1996).</p>


<h3>Source</h3>

<p>Cranfield, H.J., Michael, K.P., and Francis, R.I.C.C. 1996.
Growth rates of five species of subtidal clam on a beach in the South
Island, New Zealand.  Marine and Freshwater Research 47: 773&ndash;784.</p>

<hr>
<h2 id='pgen'>Probability of a Management Parameter Exceeding a Reference Point</h2><span id='topic+pgen'></span>

<h3>Description</h3>

<p>Calculates the probability of a management value exceeding a reference point with or without error
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  pgen(est=NULL,limit=NULL,estSD=0,limSD=0,corr=0,dist=1,comp=1,nreps=10000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pgen_+3A_est">est</code></td>
<td>
<p>management value (mv) or vector containing individual parameter values from, say, bootstrap runs.</p>
</td></tr>
<tr><td><code id="pgen_+3A_limit">limit</code></td>
<td>
<p>reference point (rp) or vector containing individual reference point values from, say, bootstrap runs.</p>
</td></tr>
<tr><td><code id="pgen_+3A_estsd">estSD</code></td>
<td>
<p>standard deviation of management value if a single value is used. Must be &gt;0 if a single value
is used. If a vector of individual values is provided, estSD is not used.</p>
</td></tr>
<tr><td><code id="pgen_+3A_limsd">limSD</code></td>
<td>
<p>standard deviation of reference point if a single value is used. If a vector of individual values is
provided, limSD is not used. limSD = 0 if the reference point is considered a point estimate (no error).</p>
</td></tr>
<tr><td><code id="pgen_+3A_corr">corr</code></td>
<td>
<p>correlation between est and limit.  Only used if est and limit are single values with error.</p>
</td></tr>
<tr><td><code id="pgen_+3A_dist">dist</code></td>
<td>
<p>assumed distribution of est or limit if they are single values with error. 1 = normal; 2 = log-normal.</p>
</td></tr>
<tr><td><code id="pgen_+3A_comp">comp</code></td>
<td>
<p>the direction of comparison:  1: mv &lt; rp, 2: mv &lt;= rp, 3: mv &gt; rp, 4: mv &gt;= rp.</p>
</td></tr>
<tr><td><code id="pgen_+3A_nreps">nreps</code></td>
<td>
<p>the number of samples to draw to create normal or log-normal distributions. User should explore
different sample sizes to determine if the probability obtained is stable.</p>
</td></tr>  
</table>


<h3>Details</h3>

<p>Randomization methods as approximations to Equations 1, 2 and 3 in Shertzer et al. (2008) are used to calculate 
the probability that a management value with error (e.g., fishing mortality) passes a reference point without 
(Eq. 1) or with (Eq. 2) error. Either may be represented by a single value and its associated standard deviations 
or a vector of individual values that represent results from, say, bootstrap runs. If log-normal is assumed, mv and 
rp and associated standard deviations must be in natural log-units (i.e., meanlog and sdlog).
</p>
<p>If the management value and reference point are specified as single values with standard deviations,
samples of size <em>nreps</em> are drawn randomly from the specified distribution parameterized with 
<em>est</em> and <em>limit</em> and associated standard deviations. If <em>corr</em>&gt;0 (Eq. 3), then the <em>est</em> and
<em>limit</em> distributions are drawn from a multivariate normal (function <em>mvrnorm</em>) distribution. If log-normal 
is assumed, function <em>mvrnorm</em> is used with the meanlog and sdlog estimates and then output values are 
bias-corrected and back-transformed.   
</p>
<p>If the management value and the reference point are represented by vectors of individual values, 
the probability is calculated by tallying the number of management values that exceed (or pass) the 
reference points and then dividing by number of est values*number of limit values.  If either the management value 
or reference point is specified as a single value with standard deviation, then a vector of individual values of 
size equal to the size of the other vector is generated by using the <em>rnorm</em> or <em>rlnorm</em> function 
parameterized with the single value and its standard deviation.
</p>


<h3>Value</h3>

<p>probability value of comparison</p>


<h3>Note</h3>

<p>Chris Legault of the National Marine Fisheries Service, Woods Hole, MA provided R code for the randomization method
and Daniel Hennen of the the National Marine Fisheries Service, Woods Hole, MA provided the R code for using 
mvrnorm to obtain log-normal distributions. 
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Shertzer, K. W., M. H. Prager, and E. K. Williams. 2008.  A probability-based approach to setting 
annual catch levels. Fishery Bulletion 106: 225-232.</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## est = 2010 Spawning Stock Biomass of Striped Bass, limit = SSB Reference Point
  pgen(est=50548,limit=36881,estSD=5485,limSD=1901,corr=0.05,dist=1,comp=2,nreps=1000)
</code></pre>

<hr>
<h2 id='pinfish'>Length, age and sex data for pinfish (Lagodon rhomboides) from Tampa Bay, Florida</h2><span id='topic+pinfish'></span>

<h3>Description</h3>

<p>The <code>pinfish</code> data frame has 670 rows and 4 columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pinfish
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>field_no</dt><dd><p>haul identifier</p>
</dd>
<dt>sl</dt><dd><p>standard length (mm) of individual pinfish</p>
</dd>
<dt>age</dt><dd><p>age in year with decimal extention reflecting age past January 1</p>
</dd>
<dt>sex</dt><dd><p>sex of fish. 1=male, 2=female, 0 = unknown</p>
</dd>
</dl>



<h3>Source</h3>

<p>Nelson, G. A.  2002. Age, growth, mortality, and distribution of pinfish (Lagodon rhomboides)
in Tampa Bay and adjacent Gulf of Mexico waters.  Fishery Bulletin 100: 582-592.
</p>

<hr>
<h2 id='plot.grotagplus'>
Plotting Tagging-Growth Objects
</h2><span id='topic+plot.grotagplus'></span>

<h3>Description</h3>

<p>Plotting method for output from function grotagplus, which has
class &quot;grotagplus&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'grotagplus'
plot(x,plot.type="meangrowth",Linitial=NULL,resid.spec=list(Pearson=T,
      x="mean.delL"),xlim=NULL,ylim=NULL,pch=20,leg.loc=NULL,
      age.based.growth=NULL,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.grotagplus_+3A_x">x</code></td>
<td>
<p>Growth-model fit to tagging data as output by function
&quot;grotagplus&quot;.</p>
</td></tr>
<tr><td><code id="plot.grotagplus_+3A_plot.type">plot.type</code></td>
<td>
<p>Character string identifying the type of plot
required: &quot;meangrowth&quot; = mean annual growth vs initial length;
&quot;traj&quot; = one-year growth trajectory of fish of initial
length specified by <code>Linitial</code>; or &quot;resid&quot; = plot of ordinary
or Pearson residuals (plot details specified by <code>resid.spec</code>).</p>
</td></tr>
<tr><td><code id="plot.grotagplus_+3A_linitial">Linitial</code></td>
<td>
<p>Initial length to use for plot of growth trajectory.</p>
</td></tr>
<tr><td><code id="plot.grotagplus_+3A_resid.spec">resid.spec</code></td>
<td>
<p>List, specifying details of a residual plot, with
components &quot;Pearson&quot; (logical, if T [default] plot Pearson residuals, 
otherwise simple residuals) and &quot;x&quot; (the x-variable in the plot - either
&quot;L1&quot;, length at tagging; &quot;delT&quot;, time at liberty; or
&quot;mean.delL&quot;, expected length increment).</p>
</td></tr>
<tr><td><code id="plot.grotagplus_+3A_xlim">xlim</code></td>
<td>
<p>Allow the user to set x-limits for a plot
that differ from those defined by the range of the plotted data.</p>
</td></tr>
<tr><td><code id="plot.grotagplus_+3A_ylim">ylim</code></td>
<td>
<p>Allow the user to set y-limits for a plot
that differ from those defined by the range of the plotted data.</p>
</td></tr>
<tr><td><code id="plot.grotagplus_+3A_pch">pch</code></td>
<td>
<p>Allows the user to change the plotting symbol for residual
plots from the default pch=20.</p>
</td></tr>
<tr><td><code id="plot.grotagplus_+3A_leg.loc">leg.loc</code></td>
<td>
<p>Allows the user to change the legend location
from its default position (&quot;topright&quot; for meangrowth and resid;
&quot;topleft&quot; for traj).  Note that a legend is used only for traj or
for other plots with multiple datasets.</p>
</td></tr>
<tr><td><code id="plot.grotagplus_+3A_age.based.growth">age.based.growth</code></td>
<td>
<p>This argument allows the user to add,
to a meangrowth plot, growth estimates (plotted as dashed lines)
from age-length datasets.  It should be a list of vectors,
each of which contains estimates of mean length corresponding to a
vector of increasing ages whose increments are  always 1 year
(the ages are not included in the argument because they are not used
in the plot, and the age vectors need not be the same in each
component).  If the list is named then the names will be interpreted
as identifying different datasets.  If a name appears in
fit$datasetnames the age-based growth will be plotted with the same
colour as the corresponding tagging growth.  If the list is not
named then it must be of the same length as fit$datasetnames
(or of length 1 if there is only one dataset in the tagging data)
and it will be assumed that the ith component corresponds to the
ith tagging dataset.</p>
</td></tr> 
<tr><td><code id="plot.grotagplus_+3A_...">...</code></td>
<td>
<p>Other graphical parameters. See <code>par</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Examples of the three plot types are given in  Figs 7 &amp; 8 of
Francis and Francis (1992), for &quot;resid&quot; and &quot;meangrowth&quot;,
respectively; and in Fig. 2 of Francis (1988), for &quot;traj&quot;. 
</p>
<p>plot.type=&quot;meangrowth&quot; is the recommended way for plotting growth
rates estimated from tagging data.  Argument age.based.growth allows a
rough comparison between these growth estimates and those from
age-length data (the comparison is between the mean growth at length L
and that at the age for which the mean length is L).
</p>
<p>The traj plot, as well as showing the mean (i.e., expected) growth (solid
line), shows 95
(dashed lines) and with (dotted lines) allowance for measurement
error.
</p>
<p>In residual plots, a dashed lowess line is plotted for each dataset
to indicate any trend and, for Pearson residuals, dotted lines at +/- 2 
indicate approximate 95
</p>
<p>For fits using multiple datasets, colour is used to distinguish the
datasets.  Use &quot;palette&quot; to change the match between colour and
dataset (the ith colour in the palette is associated with the ith
element in fit$datasetnames).
</p>


<h3>Author(s)</h3>

<p>Chris Francis <a href="mailto:chrisfrancis341@gmail.com">chrisfrancis341@gmail.com</a>
</p>
<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@state.ma.us">gary.nelson@state.ma.us</a>
</p>
<p>Marco Kienzle <a href="mailto:Marco.Kienzle@gmail.com">Marco.Kienzle@gmail.com</a>
</p>


<h3>References</h3>

<p><code>1</code> Francis, R.I.C.C., 1988. Maximum likelihood estimation of
growth and growth variability from tagging data.
New Zealand Journal of Marine and Freshwater Research, 22, p.42-51.
</p>
<p><code>2</code> Francis, M.P. and Francis, R.I.C.C. 1992.  Growth rate
estimates for New Zealand rig (Mustelus lenticulatus).  Australian
Journal of Marine and Freshwater Research 43: 1157-1176
</p>


<h3>See Also</h3>

<p><code><a href="#topic+grotagplus">grotagplus</a></code> <code><a href="#topic+print.grotagplus">print.grotagplus</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Plot of mean growth like that in Fig 8. of Francis &amp; Francis (1992)
data(rig)
fit &lt;- grotagplus(rig,dataID="Sex",alpha=70,beta=100,
                  model=list(mean="Francis",var="linear",seas="none"),
                 design=list(galpha=list("F","M"),gbeta=list("F","M"),
                             s=1,nu=1,m=0,p=0),
                  stvalue=list(galpha=c(5,4),gbeta=c(3,2),s=2,nu=0.5),
                  upper=list(galpha=c(8,6),gbeta=c(5,4),s=4,nu=1),
                 lower=list(galpha=c(3,2),gbeta=c(1.5,1),s=0.5,nu=0.2))
mnlenatage &lt;- list(F=90.7*(1-exp(-0.42*(seq(1.5,6.5)-0.77))),
           M= 118.7*(1-exp(-0.16*(seq(4,11)-2.02))),
           PGM=161.1*(1-exp(-0.11*(seq(3.5,10.5)-1.91))))
plot(fit,age.based.growth=mnlenatage)
## Residual plots
fit &lt;- grotagplus(rig,dataID="Sex",alpha=70,beta=100,
                  model=list(mean="Francis",var="linear",seas="none"),
                 design=list(galpha=list("F","M"),gbeta=list("F","M"),
                             s=1,nu=1,m=0,p=0),
                  stvalue=list(galpha=c(5,4),gbeta=c(3,2),s=2,nu=0.5),
                  upper=list(galpha=c(8,6),gbeta=c(5,4),s=4,nu=1),
                 lower=list(galpha=c(3,2),gbeta=c(1.5,1),s=0.5,nu=0.2))
plot(fit,"resid")
plot(fit,"resid",resid.spec=list(Pearson=FALSE,x="L1"))
## Trajectory plot as in Fig. 2 of Francis (1988)
data(bonito)
fit &lt;- grotagplus(bonito,alpha=35,beta=55,
               design=list(galpha=1,gbeta=1,s=1,nu=1,m=1,p=1,u=1,w=1),
               stvalue=list(s=0.81,nu=0.3,m=0,p=0.01,u=0.5,w=0.5),
               upper=list(s=3,nu=1,m=2,p=0.1,u=1,w=1),
               lower=list(s=0.1,nu=0.1,m=-2,p=0,u=0,w=0))
plot(fit,"traj",Linitial=35)
</code></pre>

<hr>
<h2 id='powertrend'>Power Analysis For Detecting Trends</h2><span id='topic+powertrend'></span>

<h3>Description</h3>

<p>Power analysis for detecting trends in linear regression is implemented following procedures in Gerrodette (1987; 1991).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>powertrend(trend = 1, A1 = NULL, PSE = NULL, pserel = 1,
 maxyrs = 3, pR = 100, step = 5, alpha = 0.05, tail = 2, graph = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="powertrend_+3A_trend">trend</code></td>
<td>
<p>1 = Linear, 2 = Exponential. Default = 1.</p>
</td></tr>
<tr><td><code id="powertrend_+3A_a1">A1</code></td>
<td>
<p>the start year abundance.  In actuality, it can be population size, productivity, diversity,
mortality rate, etc.</p>
</td></tr>
<tr><td><code id="powertrend_+3A_pse">PSE</code></td>
<td>
<p> the proportional standard error (SE(A)/A) = CV in Gerrodette (1987;1991).</p>
</td></tr>
<tr><td><code id="powertrend_+3A_pserel">pserel</code></td>
<td>
<p>the relationship between abundance and PSE: 1 = 1/sqrt(A1), 2 = constant, 3 = sqrt(A1). Default = 1.</p>
</td></tr>
<tr><td><code id="powertrend_+3A_maxyrs">maxyrs</code></td>
<td>
<p>the maximum number of samples or years to project start year abundance. Default = 3.</p>
</td></tr>
<tr><td><code id="powertrend_+3A_pr">pR</code></td>
<td>
<p> the highest positive percent change to investigate. Default = 100.</p>
</td></tr>
<tr><td><code id="powertrend_+3A_step">step</code></td>
<td>
<p>the increment of the range of percent change to investigate. Default = 5.</p>
</td></tr>
<tr><td><code id="powertrend_+3A_alpha">alpha</code></td>
<td>
<p>the alpha level (Type I error) to use. Default = 0.05. </p>
</td></tr>
<tr><td><code id="powertrend_+3A_tail">tail</code></td>
<td>
<p>type of tailed test: 1 = one-tailed, 2= two-tailed. Default = 2.</p>
</td></tr>
<tr><td><code id="powertrend_+3A_graph">graph</code></td>
<td>
<p>logical specifying whether a graph of power versus percent change
should be produced. Default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability that an upward or downward trend in abundance (power) will be detected is calculated using linear regression
given number of samples (<code>maxyrs</code>), estimates of sample variability (<code>PSE</code>) and abundance-PSE relationship (<code>pserel</code>),
and percent rate of change.  The program calculates power for each <code>step</code> increment beginning at -100 percent for declining changes 
and ending at <code>pR</code> percent for increasing changes. See Gerrodette (1987;1991)
for full details. It is assumed that time intervals between samplings is equal.
</p>


<h3>Value</h3>

<p>Dataframe containing columns of number of samples (<code>years</code>), trend selected (<code>trend</code>), the PSE (<code>pse</code>), 
alpha level (<code>alpha</code>), tail of test (<code>tail</code>), percent change (<code>R</code>) over <code>maxyrs</code>, and power (<code>power</code>).
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Gerrodette, T. 1987. A power analysis for detecting trends. Ecology. 68(5): 1364-1372.
</p>
<p>Gerrodette, T. 1991. Models for power of detecting trends - a reply to Link and Hatfield. Ecology 72(5): 1889-1892.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>powertrend(A1=1000,PSE=0.1)
</code></pre>

<hr>
<h2 id='print.grotagplus'>
Printing Tagging-Growth Objects
</h2><span id='topic+print.grotagplus'></span>

<h3>Description</h3>

<p>Printing method for output from function grotagplus, which has
class &quot;grotagplus&quot;. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'grotagplus'
print(x,precision=c(est="sig3",stats="dec1",cor="dec2"),...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.grotagplus_+3A_x">x</code></td>
<td>
<p>Growth-model fit to tagging data as output by function
&quot;grotagplus&quot;.</p>
</td></tr>
<tr><td><code id="print.grotagplus_+3A_precision">precision</code></td>
<td>
<p>Named character vector specifying the printing
precision for each of three categories of output: &quot;est&quot; (applies
to fixed and estimated parameters and to Linf.k); &quot;stats&quot; (for
negloglikl and AIC); and &quot;cor&quot; (for the parameter correlation
matrix).  Values should be either &quot;sigx&quot;, for x significant figures, or
&quot;decx&quot; for x decimal places.</p>
</td></tr>
<tr><td><code id="print.grotagplus_+3A_...">...</code></td>
<td>
<p>Other print parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Outputs from grotagplus are produced to a precision which is
usually much greater than is warranted.  To see this full precision
print individual components, e.g., print(fit$parest).
</p>


<h3>Author(s)</h3>

<p>Chris Francis <a href="mailto:chrisfrancis341@gmail.com">chrisfrancis341@gmail.com</a>
</p>
<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@state.ma.us">gary.nelson@state.ma.us</a>
</p>
<p>Marco Kienzle <a href="mailto:Marco.Kienzle@gmail.com">Marco.Kienzle@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+grotagplus">grotagplus</a></code> <code><a href="#topic+plot.grotagplus">plot.grotagplus</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#Model 4 of Francis (1988)
data(bonito)
fit &lt;- grotagplus(bonito,alpha=35,beta=55,
               design=list(galpha=1,gbeta=1,s=1,nu=1,m=1,p=1,u=1,w=1),
               stvalue=list(s=0.81,nu=0.3,m=0,p=0.01,u=0.5,w=0.5),
               upper=list(s=3,nu=1,m=2,p=0.1,u=1,w=1),
               lower=list(s=0.1,nu=0.1,m=-2,p=0,u=0,w=0))
print(fit)
</code></pre>

<hr>
<h2 id='pwpop'> Estimate Net Reproductive Rates Over Multiple Periods Of An Abundance Time Series Using Piecewise Regression</h2><span id='topic+pwpop'></span>

<h3>Description</h3>

<p>Function estimates net reproductive rates for periods of change over a time series of abundance data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwpop(abund = NULL, year = NULL, periods = NULL, Cs = NULL,
 startR = NULL, upperR = NULL, lowerR = NULL, graph = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pwpop_+3A_abund">abund</code></td>
<td>
<p>the vector of time series of abundance data (e.g. run counts, indices of relative abundance, etc.).</p>
</td></tr>
<tr><td><code id="pwpop_+3A_year">year</code></td>
<td>
<p>the vector of years associated with abundance data.</p>
</td></tr>
<tr><td><code id="pwpop_+3A_periods">periods</code></td>
<td>
<p>the number of periods over which to fit the population model.</p>
</td></tr>
<tr><td><code id="pwpop_+3A_cs">Cs</code></td>
<td>
<p>the vector of user-specified initial starting value for year(s) of change - number of values equals <em>periods</em> - 1 (enclose within c()).</p>
</td></tr>
<tr><td><code id="pwpop_+3A_startr">startR</code></td>
<td>
<p>the vector of user-specified initial starting values for R - one value for each period (enclose within c()).</p>
</td></tr>
<tr><td><code id="pwpop_+3A_upperr">upperR</code></td>
<td>
<p>the vector of user-specified upper limits for R (one for each period) used in optimization (enclose within c()).</p>
</td></tr>
<tr><td><code id="pwpop_+3A_lowerr">lowerR</code></td>
<td>
<p>the vector of user-specified lower limits for R (one for each period) used in optimization (enclose within c()).</p>
</td></tr>
<tr><td><code id="pwpop_+3A_graph">graph</code></td>
<td>
<p>Logical specifying whether a graph of observed versus predicted values is plotted. Default=TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A simple population model is fitted to abundance data to estimate the net reproductive rate for specified periods of time.
The model is Nt=N0*R^t where Nt is the abundance at time t, N0 is the estimated initial population size and R is the net
reproductive rate.  R can be used as an indication that the population is stable (R=1), is increasing (R&gt;1) or is declining
(R&lt;1) over a specified time period.  The fitted equation is the linearized form: <em>log(Nt)=log(N0)+log(R)*t</em>, where log is
the natural-log; therefore, zeros are not allowed.  
</p>
<p>To simultaneously estimate the parameters for periods of trends in the abundance data, a piecewise regression approach is
used.  The linearized model is fitted separately to data for each period but models are linked so that the ending
year for the preceding period is also the intercept for the current period. As an example, the models for three 
periods are
</p>
<p>log(N1,t)=log(N1,0)+log(R1)*t for t&lt;C1
</p>
<p>log(N2,t)=log(N1,0)+C1*(log(R1)-log(R2))+log(R2)*t for t&gt;=C1 and t&lt;C2
</p>
<p>log(N3,t)=log(N1,0)+C1*(log(R1)-log(R2))+C2*(log(R2)-log(R3))+log(R3)*t for t&gt;=C2
</p>
<p>The parameters estimated for these models are log(N1,0), log(R1), C1, log(R2), C2, and log(R3). <em>t</em> is time starting at 1 
for the first year of abundance and ending at x for the last year of abundance(year information is still needed for 
plotting). Entered Cs value are converted to the same scale as t. Back-transform the log(R) values using <em>exp</em> 
to obtain the R values for each period. The function <code>optim</code> is used to obtain parameter estimates and associated 
standard errors by minimizing the sum of squares (log(N)-log(pred))^2. Add first year-1 to each C to put estimates on year scale.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Estimates</code></td>
<td>
<p>list element with the parameter estimates and associated standard errors, residual sum of squares, Akaike's
Information Criterion for least squares (AIC), and coefficient of determination (r2).</p>
</td></tr>
<tr><td><code>Data</code></td>
<td>
<p>list element with the abundance data, years, t, log predicted values, and back-transformation predicted values.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Neter, J. , M. H. Kutner, C. J. Nachtsheim, and W. Wasserman.  1996.  Applied Linear Statistical Models.
The Magraw-Hill Companies. 1408 p.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(counts)
pwpop(abund = counts$number, year = counts$year,periods = 3, Cs = c(2000,2005), 
startR = c(0.5,0.5,0.5), 
upperR = c(10,10,10), 
lowerR = c(-10,-10,-10))
</code></pre>

<hr>
<h2 id='remp'>Random Number Generation from an Empirical Distribution</h2><span id='topic+remp'></span>

<h3>Description</h3>

<p>Generates random numbers from a distribution created with empirical data
</p>


<h3>Usage</h3>

<pre><code class='language-R'> remp(n,obs=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="remp_+3A_n">n</code></td>
<td>
<p>number of random observations to generate.</p>
</td></tr>
<tr><td><code id="remp_+3A_obs">obs</code></td>
<td>
<p>vector of empirical observations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An empirical probability distribution is formed from empirical data with each observation 
having 1/T probabililty of selection, where T is the number of data points. The cumulative distribution 
function (cdf) is then created so that cumulative probability of the smallest observation = 0 and the 
largest observation = 1. Random values are generated by applying the probability integral transform to the 
empirical cdf using uniformly distributed random variable (U) on the interval[0,1]. If U corresponds directly to 
the cdf probability of a particular empirical observation, then the actual observation is selected.  If U falls between 
cdf probabilities of empirical observations, then an observation is obtained by linear interpolation.    
</p>


<h3>Value</h3>

<p>random observation(s)</p>


<h3>Note</h3>

<p>Jon Brodziak of the National Marine Fisheries Service, Honolulu, HI described this technique
in his AGEPRO program.
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>Examples</h3>

<pre><code class='language-R'># Striped bass recruits per spawning stock biomass ratios 
# for 2001-2011 from 2013 assessment
ratios&lt;-c(799.22,794.78,969.81,1038.80,1101.45,1117.46,1126.16,
          1647.51,1882.30,1966.13,2189.25)
 # Select new recruits per SSB ratio for projection
 remp(1,ratios)
</code></pre>

<hr>
<h2 id='rig'>Tagging data from a growth study of rig</h2><span id='topic+rig'></span>

<h3>Description</h3>

<p>Tagging growth increment data for New Zealand rig (Mustelus
lenticulatus), after removal of outliers, as analysed in models 2-4 
of Table 6 of Francis and Francis (1992).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rig</code></pre>


<h3>Format</h3>

<p>A data frame with 114 observations and the following components
</p>

<dl>
<dt><code>L1</code></dt><dd><p>Length at release (cm)</p>
</dd>
<dt><code>L2</code></dt><dd><p>Length at recapture (cm)</p>
</dd>
<dt><code>T1</code></dt><dd><p>Time of release (y from 1 January 1981)</p>
</dd>
<dt><code>T2</code></dt><dd><p>Time of recapture (y from 1 January 1981)</p>
</dd>
<dt><code>Sex</code></dt><dd><p>Sex of fish (F or M)</p>
</dd>
</dl>



<h3>Source</h3>

<dl>
<dt>1</dt><dd><p>Francis, M.P. and Francis, R.I.C.C. 1992.  Growth rate
estimates for New Zealand rig (Mustelus lenticulatus).  Australian
Journal of Marine and Freshwater Research 43: 1157&ndash;1176</p>
</dd>
</dl>


<hr>
<h2 id='rockbass'>Age Frequency Data for Rock Bass</h2><span id='topic+rockbass'></span>

<h3>Description</h3>

<p>The <code>rockbass</code> data frame has 243 rows and 1 column.
The age data are from a sample of rock bass trap-netted from Cayuga Lake, New York by Chapman and Robson, as reported
by Seber (2002; page 417) and were expanded to individual observations from the age frequency table. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rockbass
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>age</dt><dd><p>age of individual rock bass in years</p>
</dd>
</dl>



<h3>Source</h3>

<p>Seber, G. A. F. 2002. <em>The Estimation of Animal Abundance and Related Parameters, Second Edition</em>.
The Blackburn Press, Caldwell, New Jersey. 654 p.
</p>

<hr>
<h2 id='sblen'>Total length (inches) of striped bass collected by Massachusetts volunteer anglers in 2014</h2><span id='topic+sblen'></span>

<h3>Description</h3>

<p><code>sblen</code> data frame has 311 rows and 1 columns.
Total length of striped bass
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sblen
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>len_inches</dt><dd><p>vector of lengths</p>
</dd>
</dl>



<h3>Source</h3>

<p>Massachusetts Division of Marine Fisheries, 30 Emerson Avenue, Gloucester, MA
</p>

<hr>
<h2 id='sbotos'>Otolith ages of striped bass made by two age readers</h2><span id='topic+sbotos'></span>

<h3>Description</h3>

<p>The <code>sbotos</code> data frame has 135 rows and 2 columns.
Ages of striped bass interpreted from the same otolith sections by two age readers 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sbotos
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>reader1</dt><dd><p>vector of ages</p>
</dd>
<dt>reader2</dt><dd><p>vector of ages</p>
</dd>
</dl>



<h3>Source</h3>

<p>Massachusetts Division of Marine Fisheries, 30 Emerson Avenue, Gloucester, MA
</p>

<hr>
<h2 id='sbpr'>Spawning Stock Biomass-Per-Recruit Analysis</h2><span id='topic+sbpr'></span>

<h3>Description</h3>

<p>Spawning stock biomass-per-recruit analysis (SSBPR) is conducted following Gabriel et al. (1989).</p>


<h3>Usage</h3>

<pre><code class='language-R'> sbpr(age=NULL,ssbwgt=NULL,partial=NULL,pmat=NULL,M=NULL,pF=NULL,pM=NULL,
               plus=FALSE,oldest=NULL,maxF=2,incrF=0.0001,options=c(1,2,3,4),MSP=NULL,
               SSBPR=NULL,Fsol=NULL,graph=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sbpr_+3A_age">age</code></td>
<td>
<p>a numeric vector of cohort ages. If the last age is a plus group, do not add a &quot;+&quot; to the age.</p>
</td></tr>
<tr><td><code id="sbpr_+3A_ssbwgt">ssbwgt</code></td>
<td>
<p>vector of spawning stock weights for each age. Length of vector must correspond to 
the length of the age vector.</p>
</td></tr>
<tr><td><code id="sbpr_+3A_partial">partial</code></td>
<td>
<p>partial recruitment vector applied to fishing mortality (F) to obtain partial F-at-age.  
Length of this vector must match length of the age vector.</p>
</td></tr>
<tr><td><code id="sbpr_+3A_pmat">pmat</code></td>
<td>
<p>proportion of mature fish at each age. Length of this vector must match the length of the age vector.</p>
</td></tr>
<tr><td><code id="sbpr_+3A_m">M</code></td>
<td>
<p>vector containing a single natural mortality (M) rate if M is assumed constant over all ages, or a vector of
Ms, one for each age. If the latter, the vector length match the length of the age vector.</p>
</td></tr>
<tr><td><code id="sbpr_+3A_pf">pF</code></td>
<td>
<p>the proportion of fishing mortality that occurs before spawning.</p>
</td></tr>
<tr><td><code id="sbpr_+3A_pm">pM</code></td>
<td>
<p>the proportion of natural mortality that occurs before spawning.</p>
</td></tr>
<tr><td><code id="sbpr_+3A_plus">plus</code></td>
<td>
<p>a logical indicating whether the last age is a plus-group. Default=FALSE.</p>
</td></tr>
<tr><td><code id="sbpr_+3A_oldest">oldest</code></td>
<td>
<p>if plus=TRUE, a numeric value indicating the oldest age in the plus group. </p>
</td></tr>
<tr><td><code id="sbpr_+3A_maxf">maxF</code></td>
<td>
<p>the maximum value of F range over which SSBPR will be calculated. SSBPR is calculated for F = 0 to maxF.</p>
</td></tr>
<tr><td><code id="sbpr_+3A_incrf">incrF</code></td>
<td>
<p>F increment for SSBPR calculation.</p>
</td></tr>
<tr><td><code id="sbpr_+3A_options">options</code></td>
<td>
<p>1 = generate spawning stock biomass-per-recruit values for F ranging from 0 to maxF by incrF. 
2 = find a single SSBPR value for a given value of F (Fsol), 3 = find F at a specified percent maximum SSBPR (MSP), 
4 = find F for a given value of SSBPR. Default = c(1,2,3,4).</p>
</td></tr>
<tr><td><code id="sbpr_+3A_fsol">Fsol</code></td>
<td>
<p>F for which to obtain a corresponding spawning biomass-per-recruits value. Default = NULL.</p>
</td></tr>
<tr><td><code id="sbpr_+3A_msp">MSP</code></td>
<td>
<p>the percentage of maximum spawning potential (percent MSP reference point) for which F and SBPR should be 
determined. Default = NULL.</p>
</td></tr>
<tr><td><code id="sbpr_+3A_ssbpr">SSBPR</code></td>
<td>
<p>A spawning biomass-per-recruit value for which to obtain a corresponding F. Default = NULL.</p>
</td></tr>
<tr><td><code id="sbpr_+3A_graph">graph</code></td>
<td>
<p>a logical indicating whether SSBPR versus F should be plotted for options = 1. Default=TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>Spawning stock biomass-per-recruit analysis is conducted following Gabriel et al. (1989). If the last age is a 
plus-group, the cohort is expanded to the <code>oldest</code> age and the <code>ssbwgt</code>, <code>partial</code>, <code>pmat</code>,
and <code>M</code> values for the plus age are applied to the expanded cohort ages. Multiple options are available
to abbreviate calculations.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>SSBPR_vs_F</code></td>
<td>
<p>For option = 1, spawning stock biomass-per-recruit values for each F increment.</p>
</td></tr>
<tr><td><code>SSBPR_at_Fsol</code></td>
<td>
<p>If option = 2, the SSBPR value corresponding to Fsol.</p>
</td></tr>
<tr><td><code>F_at_MSP</code></td>
<td>
<p>If option = 3, the F reference point corresponding to MSP.</p>
</td></tr>
<tr><td><code>F_at_SSBPR</code></td>
<td>
<p>If option = 4, the F corresponding to a given SSBPR.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Gabriel, W. L., M. P. Sissenwine, and W. J. Overholtz. 1989. Analysis of spawning stock biomass 
per recruit: an example for Georges Bank haddock. North American Journal of Fisheries Management 9: 383-391.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ypr">ypr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(haddock)
#Generate SSBPR versus F, and F for MSP reference point
sbpr(age=haddock$age,ssbwgt=haddock$ssbwgt,partial=haddock$partial,
pmat=haddock$pmat,M=0.2,pF=0.2, pM=0.1667,plus=FALSE,maxF=2,
incrF=0.001,MSP=30,options = c(1,3))		
</code></pre>

<hr>
<h2 id='schnabel'>Population Size Estimates from Repeated Mark-Recapture Experiments</h2><span id='topic+schnabel'></span>

<h3>Description</h3>

<p>Estimates of population abundance from Schnabel (1938) and Schumacher and Eschmeyer (1943) are calculated from
repeated mark-recapture experiments following Krebs (1989). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>schnabel(catch = NULL, recaps = NULL, newmarks = NULL,
 alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="schnabel_+3A_catch">catch</code></td>
<td>
<p>A vector containing the number of animal caught in each mark-recapture experiment.</p>
</td></tr>
<tr><td><code id="schnabel_+3A_recaps">recaps</code></td>
<td>
<p>A vector containing the number of animal recaptured in each mark-recapture experiment.</p>
</td></tr>
<tr><td><code id="schnabel_+3A_newmarks">newmarks</code></td>
<td>
<p>A vector containing the newly marked animals in each mark-recapture experiment.</p>
</td></tr>
<tr><td><code id="schnabel_+3A_alpha">alpha</code></td>
<td>
<p>the alpha level for confidence intervals. Default = 0.05</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All computations follow Krebs (1989: p. 30-34). For the Schnabel method, the poisson
distribution is used to set confidence intervals if the sum of all recaptures is &lt;50,and the t distribution is used if the sum of all recaptures is &gt;=50. 
For the Schumacher-Eschmeyer method, the t distribution is used to set confidence intervals.
</p>


<h3>Value</h3>

<p>Dataframe containing the population estimates for the Schnabel and Schumacher &amp; Eschmeyer methods (N),
the inverse standard errors (invSE), lower (LCI) and upper (UCI) confidence intervals,
and the type of distribution used to set confidence intervals (CI Distribution). </p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p> Krebs, C. J. 1989. <em>Ecological Methodologies</em>. Harper and Row, New York, NY. 654 p.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Gerking)
schnabel(catch=Gerking$C,recaps=Gerking$R, newmarks=Gerking$nM,
 alpha=0.10)
</code></pre>

<hr>
<h2 id='Shepherd'>Seasonal Length Frequencies for Raja clavata</h2><span id='topic+Shepherd'></span>

<h3>Description</h3>

<p>The <code>Shepherd</code> data frame has 24 rows and 4 columns.
The seasonal length frequency data of Raja clavata are from Shepherd's working document. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Shepherd
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>length</dt><dd><p>lower limit of length interval </p>
</dd>
<dt>f1</dt><dd><p>length frequency from first sampling event in year.</p>
</dd>
<dt>f2</dt><dd><p>length frequency from second sampling event in year.</p>
</dd>
<dt>f3</dt><dd><p>length frequency from third sampling event in year.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Shepherd, J. G. 1987. <em>A weakly parametric method for the analysis of length composition data</em>. In: D. Pauly and
G. Morgan, (eds). The Theory and Application of Length-Based Methods of Stock Assessment. ICLARM Conf. Ser. Manilla.</p>

<hr>
<h2 id='simulus'>
Age and size data for the growth_sel function
</h2><span id='topic+simulus'></span>

<h3>Description</h3>

<p>Age and size data were derived via simulation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(simulus)</code></pre>


<h3>Format</h3>

<p>A data frame with 1000 observations on the following 6 variables.
</p>

<dl>
<dt><code>age</code></dt><dd><p>a numeric vector of ages</p>
</dd>
<dt><code>size</code></dt><dd><p>a numeric vector of body size</p>
</dd>
<dt><code>weights</code></dt><dd><p>a numeric vector of observation weights for the likelihood function.</p>
</dd>
<dt><code>minlimit</code></dt><dd><p>a numeric vector of the minimum size limit.</p>
</dd>
<dt><code>maxlimit</code></dt><dd><p>a numeric vector of the maximum size limit.</p>
</dd>
<dt><code>minmax</code></dt><dd><p>a numeric vector indicating to which likelihood component (1=minimum, 2=maximum) each row observation is assigned. </p>
</dd>
</dl>



<h3>Source</h3>

<p>Amy M. Schueller, National Marine Fisheries Service, Beaufort, NC <a href="mailto:amy.schueller@noaa.gov">amy.schueller@noaa.gov</a>
</p>

<hr>
<h2 id='slca'>A Weakly Parametric Method for the Analysis of Length Composition Data</h2><span id='topic+slca'></span>

<h3>Description</h3>

<p>Shepherd's method for the decomposition of seasonal length frequencies into age classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>slca(x, type = 1, fryr=NULL, Linf = NULL, K = NULL, t0 = NULL,
 Lrange = NULL, Krange = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="slca_+3A_x">x</code></td>
<td>
<p>the dataframe containing the seasonal length frequencies.  The first column contains the lower limit of the
length bin as a single numeric value, and the second and remaining columns contain the number of fish in each length bin
for each seasonal length frequency.  The increment of length frequencies should be constant, e.g. every 3 cm.  Empty cells
must be coded as zeros.  Column headers are not required.</p>
</td></tr>
<tr><td><code id="slca_+3A_type">type</code></td>
<td>
<p>the analysis to be conducted: 1=<em>explore</em>, 2=<em>evaluate</em>.</p>
</td></tr>
<tr><td><code id="slca_+3A_fryr">fryr</code></td>
<td>
<p>the fraction of the year corresponding to when each seasonal length frequency was collected.
Enter one numeric value for each length frequency separated by commas within the concatentation function, e.g. c(0.2,0.45).
Values must be entered for type=1 and type=2. </p>
</td></tr>
<tr><td><code id="slca_+3A_linf">Linf</code></td>
<td>
<p>the von Bertalanffy L-infinity parameter.  If type=2, then value must be entered.</p>
</td></tr>
<tr><td><code id="slca_+3A_k">K</code></td>
<td>
<p> the von Bertalanffy growth parameter.  If type=2, then value must be entered.</p>
</td></tr>
<tr><td><code id="slca_+3A_t0">t0</code></td>
<td>
<p>the von Bertalanffy t-sub zero parameter.  If type=2, the value must be entered.</p>
</td></tr>
<tr><td><code id="slca_+3A_lrange">Lrange</code></td>
<td>
<p>the L-infinity range (minimum and maximum) and increment to explore. If type=1, then values must by entered. 
The first position is the minimum value, the second position is the maximum value, and the third position is the
increment. Values should be separated by commas within the concatentation function, e.g. c(100,120,10).</p>
</td></tr>
<tr><td><code id="slca_+3A_krange">Krange</code></td>
<td>
<p>the K range and increment to explore. If type=1, then values must by entered. 
The first position is the minimum value, the second position is the maximum value, and the third position is the
increment. Values should be separated by commas within the concatentation function, e.g. c(0.1,0.3,0.02).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are two analytical steps.  In the &quot;explore&quot; analysis, a set of von Bertalanffy parameters that 
best describes the growth of the seasonal length groups is selected from a table of goodness-of-fit measures mapped 
over the range of specified K and L-infinity values.  Once the best K and L-infinity parameters are selected, the corresponding 
t0 value is obtained off the second table. In the &quot;evaluate&quot; analysis, the selected parameters are used to 'slice'
the seasonal length frequencies into age classes.
</p>


<h3>Value</h3>

<p>If type=1, tables of goodness of fit measures versus L-infinity and K parameters, and t0 values versus L-infinity and K parameters.
If type=2, table of age classes produced from slicing the length frequencies.
</p>


<h3>Note</h3>

<p>Shepherd's Fortran code provided in his original working document was translated into R code. 
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p> Shepherd, J. G. 1987. A weakly parametric method for the analysis of length composition data. In: D. Pauly and
G. Morgan, (eds). The Theory and Application of Length-Based Methods of Stock Assessment. ICLARM Conf. Ser. Manilla.</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Data are from Shepherd working document - seasonal length frequencies
# for Raja clavata.
data(Shepherd)

#explore
slca(Shepherd,1,fryr=c(0.2,0.45,0.80),Lrange=c(100,150,10),
Krange=c(0.1,0.3,0.02))

#evaluate
slca(Shepherd,2,fryr=c(0.2,0.45,0.80),Linf=120,K=0.2,t0=0.57)

</code></pre>

<hr>
<h2 id='sole'>Flathead sole CPUEs</h2><span id='topic+sole'></span>

<h3>Description</h3>

<p>Flathead sole CPUEs for a side-by-side trawl calibration study of National Marine Fisheries Service (NMFS) and Alaska Department of Fish and Game (ADFG) vessels</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(sole)</code></pre>


<h3>Format</h3>

<p>A data frame with 33 observations on the following 3 variables.
</p>

<dl>
<dt><code>haul</code></dt><dd><p>a numeric vector of the experimental paired haul number</p>
</dd>
<dt><code>nmfs</code></dt><dd><p>catch-per-unit-effort (kg per km2) for the NMFS vessel Peggy Jo from 33 experimental hauls</p>
</dd>
<dt><code>adfg</code></dt><dd><p>catch-per-unit-effort (kg per km2) for the ADFG vessel Resolution from 33 experimental hauls</p>
</dd>
</dl>



<h3>Source</h3>

<p>von Szalay, P. G. and E. Brown. 2001. Trawl comparisons of fishing power differences and
their applicability to National Marine Fisheries Service and Alask Department of Fish
and Game trawl survey gear.  Alaska Fishery Research Bulletin 8(2):85-95.
</p>
<p>Data were graciously provided by Paul G. von Szalay, National Marine Fisheries Service, Seattle, Washington.
</p>

<hr>
<h2 id='sr'>Estimation and Model Comparison of Stock-Recruitment Relationships</h2><span id='topic+sr'></span>

<h3>Description</h3>

<p>This function fits 14 models of recruitment-stock relationships
to recruitment numbers and spawning stock (e.g., spawning stock biomass or fecundity) data and provides 
model selection statistics for determining the best model fit.</p>


<h3>Usage</h3>

<pre><code class='language-R'>sr(recruits = NULL, stock = NULL, model = c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9,
 10, 11, 12, 13, 14), 
select = 1, initial = list(RA = NULL, RB = NULL, Rrho = NULL, BHA = NULL, 
BHB = NULL, BHrho = NULL,
 SHA = NULL, SHB = NULL, SHC = NULL, DSA = NULL, DSB = NULL, DSC = NULL, 
MYA = NULL, MYB = NULL, 
 MYC = NULL), control = list(maxit = 10000), plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sr_+3A_recruits">recruits</code></td>
<td>
<p>a vector of numbers of recruits</p>
</td></tr>
<tr><td><code id="sr_+3A_stock">stock</code></td>
<td>
<p>any spawning stock quantity (e.g., spawning biomass, numbers, fecundity) corresponding to the
vector of recruits.</p>
</td></tr>
<tr><td><code id="sr_+3A_model">model</code></td>
<td>
<p>the model to fit. Models are
0 = Density-Independent, 1 = Ricker with uncorrelated normal errors (N-U), 2 = Ricker with uncorrelated log-normal errors (L-U),
3 = Ricker with correlated normal errors (N-C), 4 = Ricker with correlated log-normal errors (L-C),
5 = Beverton-Holt with uncorrelated normal errors, 6 = Beverton-Holt with uncorrelated log-normal errors,
7 = Beverton-Holt with correlated normal errors, 8 = Beverton-Holt with correlated log-normal errors,
9 = Shepherd with uncorrelated normal errors, 10 = Shepherd with uncorrelated log-normal errors, 11 = Deriso-Schnute with
uncorrelated normal errors, 12 = Deriso-Schnute with uncorrelated log-normal errors, 12 = Myers depensatory model with 
uncorrelated normal errors, and 14 = Myers depensatory model with uncorrelated log-normal errors. Default is all.
</p>
</td></tr>
<tr><td><code id="sr_+3A_select">select</code></td>
<td>
<p>method used to determine starting values. 1 = automatic, 2 = user-specified. Default=1. Automatic
selection of starting might not always work given the data provided.</p>
</td></tr>
<tr><td><code id="sr_+3A_initial">initial</code></td>
<td>
<p>if select = 2, list of starting values for each equation type. See equation parameter names in <em>Details</em>.</p>
</td></tr>
<tr><td><code id="sr_+3A_control">control</code></td>
<td>
<p>see function <em>optim</em>.</p>
</td></tr>
<tr><td><code id="sr_+3A_plot">plot</code></td>
<td>
<p>logical indicating whether an observed-predicted plot should be produced. Default = FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following equations are fitted:
</p>
<p>Ricker: <code>recruits = RA*stock*exp(-RB*stock)</code>
</p>
<p>Beverton-Holt: <code>recruits = (BHA*stock)/(1+(BHA*stock)/BHB)</code>
</p>
<p>Shepherd: <code>recruits = (SHA*stock)/(1+SHB*stock^SHC)</code>
</p>
<p>Deriso-Schnute: <code>recruits = DSA*stock*(1-DSB*DSC*stock)^(1/DSC)</code>
</p>
<p>Myers: <code>(MYA*datar$stock^MYC)/(1+((datar$stock^MYC)/MYB))</code> 
</p>
<p>Maximum likelihood is used to estimate model parameters. 
</p>
<p>For uncorrelated normal errors, the negative log-likelihood is
</p>
<p><code>n/2*log(2*pi)+n*log(sqrt(sigma2))+1/(2*sigma2)*sum((recruits-predicted)^2)</code>
</p>
<p>where n is the number of observation, sigma2 is the maximum likelihood of residual variance and
predicted is the model predicted recruits.  sigma2 is calculated internally as 
</p>
<p><code>sigma2 = sum((recruits-predicted)^2)/n</code>.
</p>
<p>For uncorrelated log-normal errors, the negative log-likeliood is
</p>
<p><code>n/2*log(2*pi)+n*log(sqrt(lsigma2))+sum(log(recruits))+1/(2*lsigma2)*</code>
</p>
<p><code>sum((log(recruits)-log(predicted)+lsigma2/2)^2)</code>
</p>
<p>lsigma2 is calculated internally as <code>lsigma2 = sum((log(recruits)-log(predicted))^2)/n</code>.
</p>
<p>For correlated normal errors, the negative log-likelihood is
</p>
<p><code>n/2*log(2*pi)+n*log(sqrt(sigma2w))-0.5*log(1-rho^2)+</code> 
</p>
<p><code>1/(2*sigma2w)*sumR+((1-rho^2)/(2*sigma2w))*(datar$recruits[1]-predicted[1])^2</code>
</p>
<p>where rho is the estimated autocorrelation (AR1) parameter, sigma2w is the white noise residual variance, and sumR is calculated as
</p>
<p><code>for(k in 2:n) sumR&lt;-sumR+(recruits[k]-rho*recruits[k-1]-</code>
</p>
<p><code>predicted[k]+rho*predicted[k-1])^2</code>
</p>
<p>sigma2w is calculated internally as
</p>
<p><code>res = recruits - predicted</code>
</p>
<p><code>es = c(res[1:c(length(res)-1)]*rho)</code>
</p>
<p><code>sigma2w = sum((res[-1]-es)^2)/c(n-1)</code>
</p>
<p>For correlated log-normal errors, the negative log-likelihood is 
</p>
<p><code>n/2*log(2*pi)+n*log(sqrt(lsigma2w))+sum(log(recruits))-0.5*log(1-rho^2)+</code>
</p>
<p><code>1/(2*lsigma2w)*lsumR+((1-rho^2)/(2*lsigma2w))*(log(recruits[1])-</code>
</p>
<p><code>log(predicted[1])+lsigma2w/2)^2</code>
</p>
<p>where lsumR is calculated as
</p>
<p><code>for(k in 2:n) lsumR&lt;-lsumR+(log(recruits[k])-pho*log(recruits[k-1])</code>
</p>
<p><code>-log(predicted[k])+rho*log(predicted[k-1])+(1-phi)*lsigma2w/2)^2</code>
</p>
<p>and lsigma2w is calculated as
</p>
<p><code>res = log(recruits)-log(predicted)</code>
</p>
<p><code>es = c(res[1:c(length(res)-1)]*pho)</code>
</p>
<p><code>lsigma2w = sum((res[-1]-es)^2)/c(n-1)</code>.
</p>
<p>Correlated error structures are available for the Ricker and Beverton-Holt model only.  The
names for specification of starting values of the AR1 parameter are <code>Rrho</code> and <code>BHrho</code>.  
</p>
<p>Akaike Information Criterion for small sample sizes (AICc), Akaike weights and evidence ratios (Burham and Anderson 2002)
are provided for each model selected above. 
</p>
<p>This function uses function <em>optim</em> to estimate parameters and function <em>hessian</em> in package <em>numDeriv</em> to calculate the
hessian matrix from which standard errors are derived.
</p>


<h3>Value</h3>

<p>Lists containing estimation results. <em>results</em> contains parameter estimates,
associated standard errors, residual variances, negative log-likelihoods and AICc values for each model.
If the standard errors are <code>NaN</code>, the hessian could not be inverted (i.e., poor model fit). 
<em>evidence_ratios</em> contains Akaike weights and evidence ratios for model selection.
<em>convergence</em> contains convergence criterion: 0 = no problems, &gt;0 = problems (see function <em>optim</em>).
<em>correlations</em> contains the estimated parameter correlations. Correlation will be NA if hessian could not be
inverted. <em>predicted</em> contains the predicted values from each model. <em>residuals</em> contains the residuals from each model.
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Brodziak, J, and C. M. Legault. 2005. Model averaging to estimate rebuilding targets for
overfished stocks. Canadian Journal of Fisheries and Aquatic Sciences 62: 544-562.
</p>
<p>Brodziak, J, and C. M. Legault. 2010. Reference manual for SRFIT version 7. NOAA Fisheries Toolbox.
</p>
<p>Burnham, K. P. and D. R. Anderson. 2002. Model Selection and Multimodel Inference, Second edition.
Springer-Verlag New York, New York.  488 pages.
</p>
<p>Myers, R. A., N. J. Barrowman, J. A. Hutching and A. A. Rosenberg. 1995. Population dynamics
of exploited fish stocks at low population levels. Science 269: 1106-1108.
</p>
<p>Quinn, T. J. and R. B. Deriso. 1999. Quantitative fish dynamics. Oxford University Press. 542 pages. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Not run: 
data(striper)
outs&lt;-sr(recruits=striper$recruits,stock=striper$stock,select=2,model=c(5,6,7,8),
         initial=list(RA=5e3,RB=2e-5,Rrho=0.1,
                      BHA=8e3,BHB=1e8,BHrho=0.1,
                      SHA=1.5e3,SHB=5.6e8,SHC=1,
                      DSA=9e3,DSB=9e-5,DSC=-1.14,
                      MYA=1e6,MYB=1e5,MYC=0.4),plot=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='striper'>Recruitment Numbers and Female Spawning Stock Biomass for Striped Bass</h2><span id='topic+striper'></span>

<h3>Description</h3>

<p>The <code>striper</code> data frame has 34 rows and 2 column.
Estimates of recruits and female spawning stock biomass for striped bass from 
the Atlantic State
Marine Fisheries 2016 stock assessment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>striper
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>recruits</dt><dd><p>number of recruits</p>
</dd>
<dt>stock</dt><dd><p>female spawning stock biomass (metric tons)</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="http://www.asmfc.org">http://www.asmfc.org</a>
</p>

<hr>
<h2 id='surveyfit'>Estimating the Relative Abundance of Fish From a Trawl Survey</h2><span id='topic+surveyfit'></span>

<h3>Description</h3>

<p>This function applies the time series method of Pennington (1986) for estimating relative abundance
to a survey series of catch per tow data 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>surveyfit(year = NULL, index = NULL, logtrans = TRUE, graph = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="surveyfit_+3A_year">year</code></td>
<td>
<p> vector containing the time series of numeric year labels.</p>
</td></tr>
<tr><td><code id="surveyfit_+3A_index">index</code></td>
<td>
<p>vector containing the time series of mean catch per tow data.</p>
</td></tr>
<tr><td><code id="surveyfit_+3A_logtrans">logtrans</code></td>
<td>
<p>a logical value indicating whether the natural log-transform should be applied to the mean catch per tow values.
Default is TRUE.</p>
</td></tr>
<tr><td><code id="surveyfit_+3A_graph">graph</code></td>
<td>
<p>a logical value indicating whether a graph of the observed and model fit
should be drawn. Default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Parameters for a first difference, moving average model of order 1 are estimated from the trawl time series using function <code>arima</code>.
Following Equation 4 in Pennington (1986), fitted values are calculated from the model residuals and the estimate of theta.   
</p>


<h3>Value</h3>

<p>List containing summary statistics (sample size (n), the first three sample autocorrelations (r1-r3) for the first differenced logged series)
and parameter estimates (theta, theta standard error, and sigma2), the observed log-transformed index and fitted values, and the ARIMA function output.</p>


<h3>Author(s)</h3>

<p> Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Pennington, M. P. 1986. Some statistical techniques for estimating abundance indices from trawl surveys. Fishery Bulletin 84(3): 519-525.</p>


<h3>See Also</h3>

<p><code><a href="#topic+surveyref">surveyref</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(yellowtail)
surveyfit(year=yellowtail$year,index=yellowtail$index)
</code></pre>

<hr>
<h2 id='surveyref'>Quantitative reference points from stock abundance indices based on research surveys</h2><span id='topic+surveyref'></span>

<h3>Description</h3>

<p>This function implements the methodology of Helser and Hayes (1995) for generating quantitative reference points from relative 
abundance indices based on research surveys
</p>


<h3>Usage</h3>

<pre><code class='language-R'>surveyref(x = NULL, refpt = 25, compyear = NULL, reffix = FALSE,
 refrange = NULL, nboot = 500, allboots = FALSE, nreps = 10000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="surveyref_+3A_x">x</code></td>
<td>
<p>output object from function <code>surveyfit</code>.</p>
</td></tr>
<tr><td><code id="surveyref_+3A_refpt">refpt</code></td>
<td>
<p>the lower quantile (percentile) of the fitted time series used as the reference point.</p>
</td></tr>
<tr><td><code id="surveyref_+3A_compyear">compyear</code></td>
<td>
<p> the index year to compare to the reference point.  Multiple years can be included in the comparison using the <code>c()</code> function.</p>
</td></tr>
<tr><td><code id="surveyref_+3A_reffix">reffix</code></td>
<td>
<p>a logical value specifying whether the lower quantile should be determined from a fixed set of years.
Default = FALSE.</p>
</td></tr>
<tr><td><code id="surveyref_+3A_refrange">refrange</code></td>
<td>
<p>If <code>reffix</code> = TRUE, the beginning and ending year of the time series to include in 
determination of the lower quantile.  The values should be enclosed within <code>c()</code> (e.g., c(1963,1983)).</p>
</td></tr>
<tr><td><code id="surveyref_+3A_nboot">nboot</code></td>
<td>
<p>the number of bootstrap replicates.</p>
</td></tr>
<tr><td><code id="surveyref_+3A_allboots">allboots</code></td>
<td>
<p>a logical value specifying whether the fitted values for the bootstrap replicates 
should be included in the output. Default = FALSE.</p>
</td></tr>
<tr><td><code id="surveyref_+3A_nreps">nreps</code></td>
<td>
<p>the number of samples to draw  in function <code>pgen</code>. Default = 10000.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Using the output object from function <code>surveyfit</code>, the methodology of Helser and Hayes (1995) is applied to 
generate the probability distribution that the abundance index value for a given year lies below the value of a 
lower quantile (reference point).  The procedure is : 1) add to the original fitted time series residuals randomly selected
with replacement from the Pennington model fit, 2) repeat this <code>nboot</code> times to create new time series, 
3) fit the Pennington model to each new time series using the original theta estimate to get <code>nboot</code> replicates
of new fitted time series, and 4) determine the lower quantile for each new fitted time 
series.  The probability of the abundance index being less than the quartile reference point is calculated using 
function <code>pgen</code> with <code>comp</code>=1. 
</p>
<p>If comparisons between the current year's index and the reference point will be made year-after-year, Helser and Hayes
(1995) recommend using a fixed set of years to select the lower quantile.  This procedure will avoid a change in 
reference point over time as a survey time series is updated. Use arguments <code>reffix</code> and <code>refrange</code> to 
accomplish this.
</p>


<h3>Value</h3>

<p>list containing the lower quantile of the original fitted time series and the mean quantile of the
fitted bootstrap replicates (<code>comp_refpt</code>),  the original fitted time series values versus the mean of the fitted
bootstrap time series values(<code>comp_fitted</code>), the empirical distribution of the selected index (<code>emp_dist_index</code>),
the empirical distribution of the lower quantile (<code>emp_dist_refpt</code>), the probability that the index
value lies below the reference point for a given decision confidence level (<code>prob_index</code>), and, if argument <code>allboots</code> is TRUE, the fitted values
of the bootstrap replicates (<code>boot_runs</code>).
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Helser, T. E. and D. B. Hayes. 1995.  Providing quantitative management advice from stock abundance 
indices based on research surveys. Fishery Bulletin 93: 290-298.</p>


<h3>See Also</h3>

<p><code><a href="#topic+surveyfit">surveyfit</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(wolffish)
out&lt;-surveyfit(year=wolffish$year,index=wolffish$index,logtrans=TRUE)
surveyref(out,refpt=25,compyear=c(1990))
</code></pre>

<hr>
<h2 id='tag_model_avg'>Model Averaging for Instantaneous Rates Tag Return Models</h2><span id='topic+tag_model_avg'></span>

<h3>Description</h3>

<p>Calculates model averaged estimates of instantaneous fishing, natural and total mortality, and survival rates for
instantaneous rates tag return models (Hoenig et al. (1998) and Jiang et al. (2007)).</p>


<h3>Usage</h3>

<pre><code class='language-R'>tag_model_avg(..., global = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tag_model_avg_+3A_...">...</code></td>
<td>
<p>model object names separated by commas</p>
</td></tr>
<tr><td><code id="tag_model_avg_+3A_global">global</code></td>
<td>
<p>specify global model name in quotes.  If the global model is the first model included 
in the list of candidate models, this argument can be ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Model estimates are generated from functions <code>irm_cr</code> and <code>irm_h</code>.
Averaging of model estimates follows the procedures in Burnham and Anderson (2002).
Variances of parameters are adjusted for overdispersion using the c-hat estimate from the global model 
: <code>sqrt(var*c-hat)</code>.  If c-hat of the global model is &lt;1, then c-hat is set to 1. The c-hat is used to calculate the quasi-likelihood AIC and AICc 
metrics for each model (see page 69 in Burnham and Anderson(2002)). QAICc differences among models are calculated by
subtracting the QAICc of each model from the model with the smallest QAICc value. These differences are used to calculate 
the Akaike weights for each model following the formula on page 75 of Burnham and Anderson (2002). The Akaike weights are
used to calculate the weighted average and standard error of parameter estimates by summing the product of the model-specific Akaike weight and parameter estimate 
across all models.  An unconditional standard error is also calculated by 
<code>sqrt(sum(QAICc wgt of model i 
* (var of est of model i 
+ (est of model i - avg of all est)^2)))</code>.
</p>


<h3>Value</h3>

<p>List containing model summary statistics, model-averaged estimates of fishing, natural, tag, and total mortality, and 
survival and their weighted and uncondtional standard errors . 
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

 
<p>Burnham, K. P. and D. R. Anderson. 2002. Model selection and multimodel inference : A Practical Information-Theorectic Approach, 2nd edition. Spriner-Verlag, New York, NY. 488 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+irm_h">irm_h</a></code> <code><a href="#topic+irm_cr">irm_cr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## This is a typical specification, not a working example
## Not run: 
tag_model_avg(model1,model2,model3,model4,model5,model6,model7,global="model7")
## End(Not run)
</code></pre>

<hr>
<h2 id='tanaka'>Simulated alfonsino data for Tanaka (2006</h2><span id='topic+tanaka'></span>

<h3>Description</h3>

<p>The <code>tanaka</code> data frame has  138 rows and 3 columns.
The number of returns and the mean times-at-large from Table 2 of 
Tanaka (2006) were used to generate individual times-at-large data from a random normal distributions
using a CV of 0.1. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tanaka
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>relyr</dt><dd><p>release year (cohort)</p>
</dd>
<dt>tal</dt><dd><p>individual times-at-large (in years)</p>
</dd>
<dt>N</dt><dd><p>Total number of releases for relear year (cohort)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Tanaka, E. 2006. Simultaneous estimation of instantaneous mortality coefficients and rate 
of effective survivors to number of released fish using multiple sets of tagging experiments. 
Fisheries Science 72: 710-718.
</p>

<hr>
<h2 id='trout'>Mark-recapture data for Kenai River trout trout</h2><span id='topic+trout'></span>

<h3>Description</h3>

<p>The <code>trout</code> data frame has 102 rows and 3 columns.
Release lengths, recapture lengths and times-at-large for trout trout in the Kenai River from Table 4.10 of Quinn and Deriso (1999).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trout
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>L1</dt><dd><p>vector of release lengths</p>
</dd>
<dt>L2</dt><dd><p>vector of recapture lengths</p>
</dd>
<dt>dt</dt><dd><p>vector of times-at-large </p>
</dd>
</dl>



<h3>Source</h3>

<p>Quinn, T. J. and R. B. Deriso. 1999. Quantitative Fish Dynamics. Oxford University Press, New York, New York. 542 pages
</p>

<hr>
<h2 id='vbfr'>
Francis' re-parameterization of the von Bertalanffy growth equation for length-age data</h2><span id='topic+vbfr'></span>

<h3>Description</h3>

<p>Fits the re-parameterized von Bertalanffy growth equation of Francis (1988) 
by using nonlinear least-squares</p>


<h3>Usage</h3>

<pre><code class='language-R'>vbfr(age = NULL, L = NULL, agephi = NULL, agepsi = NULL, graph = TRUE, 
gestimate = TRUE, Lphiparms = c(NA, NA, NA), Lchiparms = c(NA, NA, NA), 
Lpsiparms = c(NA, NA, NA),control = list(maxiter = 10000))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vbfr_+3A_age">age</code></td>
<td>
<p>Vector of ages of individual fish.</p>
</td></tr>
<tr><td><code id="vbfr_+3A_l">L</code></td>
<td>
<p>Vector of lengths of individual fish.</p>
</td></tr>
<tr><td><code id="vbfr_+3A_agephi">agephi</code></td>
<td>
<p>Arbitrary reference age phi</p>
</td></tr>
<tr><td><code id="vbfr_+3A_agepsi">agepsi</code></td>
<td>
<p>Arbitrary reference age psi. agepsi&gt;agephi.</p>
</td></tr>
<tr><td><code id="vbfr_+3A_graph">graph</code></td>
<td>
<p>Logical specifiying whether observed versus predicted, and 
residual plots should be drawn. Default=TRUE.</p>
</td></tr>
<tr><td><code id="vbfr_+3A_gestimate">gestimate</code></td>
<td>
<p>Logical specifying whether automatic generation of starting
values of <em>lphi</em>, <em>lchi</em> and <em>lpsi</em> should be used. Default=TRUE. 
If gestimate=FALSE, user-specified starting, lower and upper limits of parameters
must be entered.</p>
</td></tr>
<tr><td><code id="vbfr_+3A_lphiparms">Lphiparms</code></td>
<td>
<p>If gestimate=FALSE, starting value, lower limit and upper limit 
of <em>lphi</em> used in <em>nls</em>.</p>
</td></tr>
<tr><td><code id="vbfr_+3A_lchiparms">Lchiparms</code></td>
<td>
<p>If gestimate=FALSE, starting value, lower limit and upper limit 
of <em>lchi</em> used in <em>nls</em>.</p>
</td></tr>
<tr><td><code id="vbfr_+3A_lpsiparms">Lpsiparms</code></td>
<td>
<p>If gestimate=FALSE, starting value, lower limit and upper limit 
of <em>lpsi</em> used in <em>nls</em>.</p>
</td></tr>
<tr><td><code id="vbfr_+3A_control">control</code></td>
<td>
<p>see <code>control</code> under function <em>nls</em>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Francis (1988) re-parameterized the von Bertalanffy growth equation for age-length 
in order to make equivalent comparison of parameters to parameters of a common model 
used to estimate growth from tagging data.  Three parameters,  <em>lphi</em>, <em>lchi</em> 
and <em>lpsi</em>, are estimated. The re-parameterization also has better 
statistical properties than the original equation.
</p>
<p>The formulae to get the conventional von Bertalanffy parameters are: 
</p>
<p>Linf = lphi + (lpsi-lphi)/(1-r^2) where r = (lpsi-lchi)/(lchi-lphi)
</p>
<p>K = -(2*log(r))/(agepsi-agephi)
</p>
<p>t0 = agephi + (1/K)*log((Linf-lphi)/Linf)
</p>
<p>If gestimate=TRUE, unconstrained nonlinear least-squares (function <em>nls</em>) is used 
to fit the model.  If gestimate=FALSE, constrained nonlinear least-squares 
is used (algorithm &quot;port&quot; in <em>nls</em>). 
</p>


<h3>Value</h3>

<p><em>nls</em> object of model results. Use <em>summary</em> to extract results.
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a>
</p>


<h3>References</h3>

<p>Francis, R. I. C. C. 1988. Are growth parameters estimated from tagging and age-length data comparable?
Can. J. Fish. Aquat. Sci. 45: 936-942.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(pinfish)
with(pinfish,vbfr(age=age,L=sl,agephi=3,agepsi=6))
</code></pre>

<hr>
<h2 id='wolffish'>Spring untransformed mean catch per tow for wolffish (Anarhichas lupus)</h2><span id='topic+wolffish'></span>

<h3>Description</h3>

<p>The <code>wolffish</code> data frame has 25 rows and 2 columns.
The  mean catch per tow values were digitized from Figure 4 of Helser and Hayes (1995) and back-transformed to the original scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wolffish
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>year</dt><dd><p>survey year of catch per tow</p>
</dd>
<dt>index</dt><dd><p>mean catch per tow value (untransformed)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Helser, T. E. and D. B. Hayes. 1995.  Providing quantitative management advice from stock abundance 
indices based on research surveys. Fishery Bulletin 93: 290-298.</p>

<hr>
<h2 id='yellowtail'>Fall average catch per tow for southern New England yellowtail flounder</h2><span id='topic+yellowtail'></span>

<h3>Description</h3>

<p>The <code>yellowtail</code> data frame has 22 rows and 2 columns.
The average catch per tow values were digitized from Figure 4 of Pennington (1986)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>yellowtail
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>year</dt><dd><p>survey year of catch per tow</p>
</dd>
<dt>index</dt><dd><p>average catch per tow value (untransformed)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Pennington, M. P. 1986. Some statistical techniques for estimating abundance indices from trawl surveys. Fishery Bulletin 84(3): 519-525.
</p>

<hr>
<h2 id='ypr'>Yield-Per-Recruit Analysis</h2><span id='topic+ypr'></span>

<h3>Description</h3>

<p>Yield-per-recruit (YPR) analysis is conducted following the modified Thompson-Bell algorithm. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ypr(age = NULL, wgt = NULL, partial = NULL, M = NULL,
 plus = FALSE, oldest = NULL, maxF = 2, incrF = 0.001, options = c(1), Fsol = NULL,
 graph = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ypr_+3A_age">age</code></td>
<td>
<p>the vector of cohort ages, e.g. c(1,2,3,4,5). If the last age is a plus group, 
do not add a &quot;+&quot; to the age.</p>
</td></tr>
<tr><td><code id="ypr_+3A_wgt">wgt</code></td>
<td>
<p>the vector of catch weights for each age, e.g. c(0.2,0.4,0.7,1.0,1.2). Length of vector must correspond to the length of the age vector.</p>
</td></tr>
<tr><td><code id="ypr_+3A_partial">partial</code></td>
<td>
<p>the partial recruitment vector applied to fishing mortality (F) to obtain partial F-at-age.  Length of the partial recruitment vector
must correspond to the length of the age vector. </p>
</td></tr>
<tr><td><code id="ypr_+3A_m">M</code></td>
<td>
<p>vector containing a single natural mortality (M) rate if M is assumed constant over all ages, or a vector of
Ms, one for each age. If the latter, the vector length must correspond to the length of the age vector. </p>
</td></tr>
<tr><td><code id="ypr_+3A_plus">plus</code></td>
<td>
<p>a logical value indicating whether the last age is a plus-group. Default is FALSE.</p>
</td></tr>
<tr><td><code id="ypr_+3A_oldest">oldest</code></td>
<td>
<p>if plus=TRUE, a numeric value indicating the oldest age in the plus group. </p>
</td></tr>
<tr><td><code id="ypr_+3A_maxf">maxF</code></td>
<td>
<p>the maximum value of F range over which YPR will be calculated. YPR is calculated for F = 0 to maxF.</p>
</td></tr>
<tr><td><code id="ypr_+3A_incrf">incrF</code></td>
<td>
<p> F increment for YPR calculation.</p>
</td></tr>
<tr><td><code id="ypr_+3A_options">options</code></td>
<td>
<p>1 = generate yield-per-recruit values for F ranging from 0 to maxF by incrF.
2 =find a single YPR value for a given value of F (Fsol).Default = c(1).</p>
</td></tr>
<tr><td><code id="ypr_+3A_fsol">Fsol</code></td>
<td>
<p>F for which to obtain a corresponding YPR. Default = NULL.</p>
</td></tr>
<tr><td><code id="ypr_+3A_graph">graph</code></td>
<td>
<p>logical indicating whether YPR versus F should be plotted. Default=TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Yield-per-recruit analysis is conducted following the modified Thompson-Bell algorithm.  Reference points
Fmax and F0.1 are calculated. If the last age is a plus-group, the cohort is expanded to the
<code>oldest</code> age and the <code>wgt</code>, <code>partial</code>, and <code>M</code> values for the plus age are applied to the expanded cohort ages.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Reference_Points</code></td>
<td>
<p>If options = 1, F and yield-per-recruit values for Fmax and F0.1</p>
</td></tr>
<tr><td><code>YPR_at_Fsol</code></td>
<td>
<p>If options = 2, YPR at corresponding <code>Fsol</code>.</p>
</td></tr>
<tr><td><code>F_vs_YPR</code></td>
<td>
<p>For options = 1, yield-per-recruit values for each F increment.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>References</h3>

<p>Gabriel, W. L., M. P. Sissenwine, and W. J. Overholtz. 1989. Analysis of spawning stock biomass per recruit:
an example for Georges Bank haddock. North American Journal of Fisheries Management 9: 383-391.</p>


<h3>See Also</h3>

<p><code><a href="#topic+sbpr">sbpr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(haddock)
ypr(age=haddock$age,wgt=haddock$ssbwgt,partial=haddock$partial,M=0.4,
plus=TRUE,oldest=100,Fsol=0.2,maxF=2,incrF=0.01)
</code></pre>

<hr>
<h2 id='zt'>Z-transform or center a time series</h2><span id='topic+zt'></span>

<h3>Description</h3>

<p>Z-transforms observations of a time series or centers observations of a time series to the mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zt(x = NULL, ctype = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="zt_+3A_x">x</code></td>
<td>
<p>vector of observations. Missing values are allowed.</p>
</td></tr>
<tr><td><code id="zt_+3A_ctype">ctype</code></td>
<td>
<p>the type of transformation.  1 = Z transform ((x - mean x)/ sd x); 2 = center (x - mean x). Default = 1</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Z-transforms observations of a time series or centers observations of a time series to the mean.
</p>


<h3>Value</h3>

<p>vector containing the transformed time series.
</p>


<h3>Author(s)</h3>

<p>Gary A. Nelson, Massachusetts Division of Marine Fisheries <a href="mailto:gary.nelson@mass.gov">gary.nelson@mass.gov</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(wolffish)
zt(wolffish$index) 
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
