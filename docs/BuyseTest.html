<!DOCTYPE html><html><head><title>Help for package BuyseTest</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {BuyseTest}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#BuyseTest-package'><p>BuyseTest package: Generalized Pairwise Comparisons</p></a></li>
<li><a href='#.calcIntegralCif_cpp'><p>C++ Function Computing the Integral Terms for the Peron Method in the presence of competing risks (CR).</p></a></li>
<li><a href='#.calcIntegralSurv_cpp'><p>C++ Function Computing the Integral Terms for the Peron Method in the survival case.</p></a></li>
<li><a href='#.colCenter_cpp'><p>Substract a vector of values in each column</p></a></li>
<li><a href='#.colCumSum_cpp'><p>Column-wise cumulative sum</p></a></li>
<li><a href='#.colMultiply_cpp'><p>Multiply by a vector of values in each column</p></a></li>
<li><a href='#.colScale_cpp'><p>Divide by a vector of values in each column</p></a></li>
<li><a href='#.rowCenter_cpp'><p>Substract a vector of values in each row</p></a></li>
<li><a href='#.rowCumProd_cpp'><p>Apply cumprod in each row</p></a></li>
<li><a href='#.rowCumSum_cpp'><p>Row-wise cumulative sum</p></a></li>
<li><a href='#.rowMultiply_cpp'><p>Multiply by a vector of values in each row</p></a></li>
<li><a href='#.rowScale_cpp'><p>Dividy by a vector of values in each row</p></a></li>
<li><a href='#as.data.table.performance'><p>Convert Performance Objet to data.table</p></a></li>
<li><a href='#auc'><p>Estimation of the Area Under the ROC Curve (EXPERIMENTAL)</p></a></li>
<li><a href='#autoplot.S4BuyseTest'><p>Graphical Display for GPC</p></a></li>
<li><a href='#brier'><p>Estimation of the Brier Score (EXPERIMENTAL)</p></a></li>
<li><a href='#BuyseMultComp'><p>Adjustment for Multiple Comparisons</p></a></li>
<li><a href='#BuyseTest'><p>Two-group GPC</p></a></li>
<li><a href='#BuyseTest.options'><p>Global options for BuyseTest package</p></a></li>
<li><a href='#BuyseTest.options-class'><p>Class &quot;BuyseTest.options&quot; (global setting for the BuyseTest package)</p></a></li>
<li><a href='#BuyseTest.options-methods'><p>Methods for the class &quot;BuyseTest.options&quot;</p></a></li>
<li><a href='#BuyseTTEM'><p>Time to Event Model</p></a></li>
<li><a href='#calcIntegralSurv2_cpp'><p>C++ Function pre-computing the Integral Terms for the Peron Method in the survival case.</p></a></li>
<li><a href='#CasinoTest'><p>Multi-group GPC (EXPERIMENTAL)</p></a></li>
<li><a href='#coef.BuyseTestAuc'><p>Extract the AUC Value</p></a></li>
<li><a href='#coef.BuyseTestBrier'><p>Extract the Brier Score</p></a></li>
<li><a href='#confint.BuyseTestAuc'><p>Extract the AUC value with its Confidence Interval</p></a></li>
<li><a href='#confint.BuyseTestBrier'><p>Extract the Brier Score with its Confidence Interval</p></a></li>
<li><a href='#constStrata'><p>Strata creation</p></a></li>
<li><a href='#getCount'><p>Extract the Number of Favorable, Unfavorable, Neutral, Uninformative pairs</p></a></li>
<li><a href='#getIid'><p>Extract the H-decomposition of the Estimator</p></a></li>
<li><a href='#getPairScore'><p>Extract the Score of Each Pair</p></a></li>
<li><a href='#getPseudovalue'><p>Extract the pseudovalues of the Estimator</p></a></li>
<li><a href='#getSurvival'><p>Extract the Survival and Survival Jumps</p></a></li>
<li><a href='#GPC_cpp'><p>C++ function performing the pairwise comparison over several endpoints.</p></a></li>
<li><a href='#iid.BuyseTestAuc'><p>Extract the idd Decomposition for the AUC</p></a></li>
<li><a href='#iid.BuyseTestBrier'><p>Extract the idd Decomposition for the Brier Score</p></a></li>
<li><a href='#iid.prodlim'><p>Extract i.i.d. decomposition from a prodlim model</p></a></li>
<li><a href='#performance'><p>Assess Performance of a Classifier</p></a></li>
<li><a href='#performanceResample'><p>Uncertainty About Performance of a Classifier (EXPERIMENTAL)</p></a></li>
<li><a href='#plot.S3sensitivity'><p>Graphical Display for Sensitivity Analysis</p></a></li>
<li><a href='#powerBuyseTest'><p>Performing simulation studies with BuyseTest</p></a></li>
<li><a href='#predict.BuyseTTEM'><p>Prediction with Time to Event Model</p></a></li>
<li><a href='#rbind.performance'><p>Combine Resampling Results For Performance Objects</p></a></li>
<li><a href='#S4BuysePower-class'><p>Class &quot;S4BuysePower&quot; (output of BuyseTest)</p></a></li>
<li><a href='#S4BuysePower-model.tables'><p>Extract Summary for Class &quot;S4BuysePower&quot;</p></a></li>
<li><a href='#S4BuysePower-nobs'><p>Sample Size for Class &quot;S4BuysePower&quot;</p></a></li>
<li><a href='#S4BuysePower-print'><p>Print Method for Class &quot;S4BuysePower&quot;</p></a></li>
<li><a href='#S4BuysePower-show'><p>Show Method for Class &quot;S4BuysePower&quot;</p></a></li>
<li><a href='#S4BuysePower-summary'><p>Summary Method for Class &quot;S4BuysePower&quot;</p></a></li>
<li><a href='#S4BuyseTest-class'><p>Class &quot;S4BuyseTest&quot; (output of BuyseTest)</p></a></li>
<li><a href='#S4BuyseTest-coef'><p>Extract Summary Statistics from GPC</p></a></li>
<li><a href='#S4BuyseTest-confint'><p>Extract Confidence Interval from GPC</p></a></li>
<li><a href='#S4BuyseTest-model.tables'><p>Extract Summary for Class &quot;S4BuyseTest&quot;</p></a></li>
<li><a href='#S4BuyseTest-nobs'><p>Sample Size for Class &quot;S4BuyseTest&quot;</p></a></li>
<li><a href='#S4BuyseTest-plot'><p>Graphical Display for GPC</p></a></li>
<li><a href='#S4BuyseTest-print'><p>Print Method for Class &quot;S4BuyseTest&quot;</p></a></li>
<li><a href='#S4BuyseTest-summary'><p>Summary Method for Class &quot;S4BuyseTest&quot;</p></a></li>
<li><a href='#sensitivity'><p>Sensitivity Analysis for the Choice of the Thresholds</p></a></li>
<li><a href='#simBuyseTest'><p>Simulation of data for the BuyseTest</p></a></li>
<li><a href='#simCompetingRisks'><p>Simulation of Gompertz competing risks data for the BuyseTest</p></a></li>
<li><a href='#summary.performance'><p>Summary Method for Performance Objects</p></a></li>
<li><a href='#validFCTs'><p>Check Arguments of a function.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Generalized Pairwise Comparisons</td>
</tr>
<tr>
<td>Version:</td>
<td>3.0.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-01-23</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementation of the Generalized Pairwise Comparisons (GPC) as defined in Buyse (2010) &lt;<a href="https://doi.org/10.1002%2Fsim.3923">doi:10.1002/sim.3923</a>&gt; for complete observations, and extended in Peron (2018) &lt;<a href="https://doi.org/10.1177%2F0962280216658320">doi:10.1177/0962280216658320</a>&gt; to deal with right-censoring. GPC compare two groups of observations (intervention vs. control group) regarding several prioritized endpoints to estimate the probability that a random observation drawn from one group performs better than a random observation drawn from the other group (Mann-Whitney parameter). The net benefit and win ratio statistics, i.e. the difference and ratio between the probabilities relative to the intervention and control groups, can then also be estimated. Confidence intervals and p-values are obtained based on asymptotic results (Ozenne 2021 &lt;<a href="https://doi.org/10.1177%2F09622802211037067">doi:10.1177/09622802211037067</a>&gt;), non-parametric bootstrap, or permutations. The software enables the use of thresholds of minimal importance difference, stratification, non-prioritized endpoints (O Brien test), and can handle right-censoring and competing-risks.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/bozenne/BuyseTest">https://github.com/bozenne/BuyseTest</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/bozenne/BuyseTest/issues">https://github.com/bozenne/BuyseTest/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10), Rcpp</td>
</tr>
<tr>
<td>Imports:</td>
<td>data.table, doSNOW, foreach, ggplot2, methods, lava, parallel,
prodlim, riskRegression, rlang, scales, stats, stats4, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>cvAUC, mvtnorm, pbapply, pROC, R.rsp, survival, testthat</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>R.rsp</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Collate:</td>
<td>'0-onLoad.R' '1-setGeneric.R' 'BuyseMultComp.R' 'BuyseTTEM.R'
'BuyseTest-Peron.R' 'BuyseTest-check.R' 'BuyseTest-inference.R'
'BuyseTest-initialization.R' 'BuyseTest-package.R'
'BuyseTest-print.R' 'BuyseTest.R' 'BuyseTest.options.R'
'CasinoTest.R' 'PairScore.R' 'RcppExports.R' 'S4-BuysePower.R'
'S4-BuysePower-model.tables.R' 'S4-BuysePower-nobs.R'
'S4-BuysePower-summary.R' 'S4-BuysePower-print.R'
'S4-BuysePower-show.R' 'S4-BuyseTest.R' 'S4-BuyseTest-coef.R'
'S4-BuyseTest-confint.R' 'S4-BuyseTest-get.R'
'S4-BuyseTest-model.tables.R' 'S4-BuyseTest-nobs.R'
'S4-BuyseTest-plot.R' 'S4-BuyseTest-summary.R'
'S4-BuyseTest-print.R' 'S4-BuyseTest-sensitivity.R'
'S4-BuyseTest-show.R' 'S4-BuyseTest.options.R'
'as.data.table.performance.R' 'auc.R' 'autoplot.S4BuyseTest.R'
'brier.R' 'constStrata.R' 'discreteRoot.R'
'iid.S3sensitivity.R' 'iid.prodlim.R' 'normexp.R'
'performance.R' 'performanceResample.R' 'plot.S3sensitivity.R'
'powerBuyseTest.R' 'predict.logit.R'
'rbind.performanceResample.R' 'simBuyseTest.R'
'simCompetingRisks.R' 'summary.performance.R' 'valid.R'</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-23 14:07:25 UTC; hpl802</td>
</tr>
<tr>
<td>Author:</td>
<td>Brice Ozenne <a href="https://orcid.org/0000-0001-9694-2956"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Julien Peron [ctb],
  Eva Cantagallo [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Brice Ozenne &lt;brice.mh.ozenne@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-23 15:12:56 UTC</td>
</tr>
</table>
<hr>
<h2 id='BuyseTest-package'>BuyseTest package: Generalized Pairwise Comparisons</h2><span id='topic+BuyseTest-package'></span>

<h3>Description</h3>

<p>Implementation of the Generalized Pairwise Comparisons. 
<code><a href="#topic+BuyseTest">BuyseTest</a></code> is the main function of the package. See the vignette of an overview of the functionalities of the package.
Run <code>citation("BuyseTest")</code> in R for how to cite this package in scientific publications.
See the section reference below for examples of application in clinical studies.
</p>
<p>The Generalized Pairwise Comparisons form all possible pairs of observations,
one observation being taken from the intervention group and the other is taken from the control group,
and compare the difference in endpoints (<code class="reqn">Y-X</code>) to the threshold of clinical relevance (<code class="reqn">\tau</code>).
</p>
<p>For a single endpoint,
if the difference is greater or equal than the threshold of clinical relevance (<code class="reqn">Y \ge X + \tau</code>),
the pair is classified as favorable (i.e. win).
If the difference is lower or equal than minus the threshold of clinical relevance (<code class="reqn">X \ge Y + \tau</code>),
the pair is classified as unfavorable (i.e. loss).
Otherwise the pair is classified as neutral. In presence of censoring, it might not be possible to compare the difference to the threshold. In such cases the pair
is classified as uninformative.
</p>
<p>Simultaneously analysis of several endpoints is performed by prioritizing the endpoints, assigning the highest priority to the endpoint considered the most clinically relevant.
The endpoint with highest priority is analyzed first, and neutral and uninformative pair are analyzed regarding endpoint of lower priority.
</p>
<p><strong>Keywords</strong>: documented methods/functions are classified according to the following keywords </p>

<ul>
<li><p> models: function fitting a statistical model/method based on a dataset (e.g. <code><a href="#topic+auc">auc</a></code>, <code><a href="#topic+brier">brier</a></code>, <code><a href="#topic+BuyseTest">BuyseTest</a></code>, <code><a href="#topic+BuyseTTEM">BuyseTTEM</a></code>, <code><a href="#topic+CasinoTest">CasinoTest</a></code>, <code><a href="#topic+performance">performance</a></code>)
</p>
</li>
<li><p> htest: methods performing statistical inference based on an existing model (e.g. <code><a href="#topic+BuyseMultComp">BuyseMultComp</a></code>, <code><a href="#topic+performanceResample">performanceResample</a></code>, <code><a href="#topic+powerBuyseTest">powerBuyseTest</a></code>, <code><a href="#topic+sensitivity">sensitivity</a></code>)
</p>
</li>
<li><p> methods: extractors (e.g. <code><a href="#topic+getCount">getCount</a></code>, <code><a href="#topic+getPairScore">getPairScore</a></code>, <code><a href="#topic+getPseudovalue">getPseudovalue</a></code>, <code><a href="#topic+getSurvival">getSurvival</a></code>, <code><a href="#topic+getIid">getIid</a></code>)
</p>
</li>
<li><p> print: concise display of an object in the console (e.g. <code>print</code>, <code>summary</code>)
</p>
</li>
<li><p> utilities: function used to facilitate user interactions (e.g. <code><a href="#topic+BuyseTest.options">BuyseTest.options</a></code>, <code><a href="#topic+constStrata">constStrata</a></code>)
</p>
</li>
<li><p> hplot: graphical display (e.g. <code><a href="#topic+autoplot.S3sensitivity">autoplot.S3sensitivity</a></code>)
</p>
</li>
<li><p> internal: function used internally but that need to be exported for parallel calculations (e.g. <code><a href="#topic+GPC_cpp">GPC_cpp</a></code>)
</p>
</li>
<li><p> datagen: function for generating data sets (e.g. <code><a href="#topic+simBuyseTest">simBuyseTest</a></code>, <code><a href="#topic+simCompetingRisks">simCompetingRisks</a></code>)
</p>
</li>
<li><p> classes: definition of S4 classes
</p>
</li></ul>



<h3>References</h3>

<p>Method papers on the GPC procedure and its extensions:
On the GPC procedure: Marc Buyse (2010). <b>Generalized pairwise comparisons of prioritized endpoints in the two-sample problem</b>. <em>Statistics in Medicine</em> 29:3245-3257 <br />
On the win ratio: D. Wang, S. Pocock (2016). <b>A win ratio approach to comparing continuous non-normal outcomes in clinical trials</b>. <em>Pharmaceutical Statistics</em> 15:238-245 <br />
On the Peron's scoring rule: J. Peron, M. Buyse, B. Ozenne, L. Roche and P. Roy (2018). <b>An extension of generalized pairwise comparisons for prioritized outcomes in the presence of censoring</b>. <em>Statistical Methods in Medical Research</em> 27: 1230-1239. <br />
On the Gehan's scoring rule: Gehan EA (1965). <b>A generalized two-sample Wilcoxon test for doubly censored data</b>. <em>Biometrika</em>  52(3):650-653 <br />
On inference in GPC using the U-statistic theory: Ozenne B, Budtz-Jorgensen E, Peron J (2021). <b>The asymptotic distribution of the Net Benefit estimator in presence of right-censoring</b>. <em>Statistical Methods in Medical Research</em> 2021 doi:10.1177/09622802211037067 <br />
On how to handle right-censoring: J. Peron, M. Idlhaj, D. Maucort-Boulch, et al. (2021) <b>Correcting the bias of the net benefit estimator due to right-censored observations</b>. <em>Biometrical Journal</em> 63: 893–906. <br />
</p>
<p>Examples of application in clinical studies: <br /> 
J. Peron, P. Roy, K. Ding, W. R. Parulekar, L. Roche, M. Buyse (2015). <b>Assessing the benefit-risk of new treatments using generalized pairwise comparisons: the case of erlotinib in pancreatic cancer</b>. <em>British journal of cancer</em> 112:(6)971-976.  <br />
J. Peron, P. Roy, T. Conroy, F. Desseigne, M. Ychou, S. Gourgou-Bourgade, T. Stanbury, L. Roche, B. Ozenne, M. Buyse (2016). <b>An assessment of the benefit-risk balance of FOLFORINOX in metastatic pancreatic adenocarcinoma</b>. <em>Oncotarget</em> 7:82953-60, 2016. <br />
</p>
<p>Comparison between the net benefit and alternative measures of treatment effect: <br /> 
J. Peron, P. Roy, B. Ozenne, L. Roche, M. Buyse (2016). <b>The net chance of a longer survival as a patient-oriented measure of benefit in randomized clinical trials</b>. <em>JAMA Oncology</em> 2:901-5. <br />
E. D. Saad , J. R. Zalcberg, J. Peron, E. Coart, T. Burzykowski, M. Buyse (2018). <b>Understanding and communicating measures of treatment effect on survival: can we do better?</b>. <em>J Natl Cancer Inst</em>.
</p>

<hr>
<h2 id='.calcIntegralCif_cpp'>C++ Function Computing the Integral Terms for the Peron Method in the presence of competing risks (CR).</h2><span id='topic+.calcIntegralCif_cpp'></span>

<h3>Description</h3>

<p>Compute the integral with respect to the jump in CIF for pairs where both outcomes are censored.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.calcIntegralCif_cpp(
  cifJump,
  start_val,
  stop_val,
  cifTimeT,
  lastCIF,
  type,
  returnDeriv,
  derivSurv,
  derivSurvD
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".calcIntegralCif_cpp_+3A_cifjump">cifJump</code></td>
<td>
<p>[matrix] cif[1] = jump times in control group (event of interest), cif[2-3] = CIF of event of interest in group
T at times - tau and times + tau, cif[4] : jump in cif of control group at times (event of interest).</p>
</td></tr>
<tr><td><code id=".calcIntegralCif_cpp_+3A_start_val">start_val</code></td>
<td>
<p>[numeric] Time at which to start the integral.</p>
</td></tr>
<tr><td><code id=".calcIntegralCif_cpp_+3A_stop_val">stop_val</code></td>
<td>
<p>[numeric] Time at which to stop the integral.</p>
</td></tr>
<tr><td><code id=".calcIntegralCif_cpp_+3A_ciftimet">cifTimeT</code></td>
<td>
<p>[numeric] CIF of event of interest in group T evaluated at observed time of treatment patient.</p>
</td></tr>
<tr><td><code id=".calcIntegralCif_cpp_+3A_lastcif">lastCIF</code></td>
<td>
<p>[numeric, &gt;0] last value of CIF of event type 1 in group T.</p>
</td></tr>
<tr><td><code id=".calcIntegralCif_cpp_+3A_type">type</code></td>
<td>
<p>[numeric] Indicates the type of integral to compute (1 for wins, 2 for losses, 3 for neutral pairs with two
events of interest - integral with t+tau and xi - and 4 for neutral pairs with two events of interest - integral with
t+tau and t-tau).</p>
</td></tr>
<tr><td><code id=".calcIntegralCif_cpp_+3A_returnderiv">returnDeriv</code></td>
<td>
<p>[logical] should the derivative regarding the survival parameters be return.</p>
</td></tr>
<tr><td><code id=".calcIntegralCif_cpp_+3A_derivsurv">derivSurv</code></td>
<td>
<p>[matrix] matrix column filled of 0 whose number of rows is the number of parameters of the survival.</p>
</td></tr>
<tr><td><code id=".calcIntegralCif_cpp_+3A_derivsurvd">derivSurvD</code></td>
<td>
<p>[matrix] matrix column filled of 0 whose number of rows is the number of parameters of the survival used to compute the jumps.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Eva Cantagallo
</p>

<hr>
<h2 id='.calcIntegralSurv_cpp'>C++ Function Computing the Integral Terms for the Peron Method in the survival case.</h2><span id='topic+.calcIntegralSurv_cpp'></span>

<h3>Description</h3>

<p>Compute the integral with respect to the jump in survival for pairs where both outcomes are censored.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.calcIntegralSurv_cpp(
  survival,
  start,
  lastSurv,
  lastdSurv,
  returnDeriv,
  derivSurv,
  derivSurvD
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".calcIntegralSurv_cpp_+3A_survival">survival</code></td>
<td>
<p>[matrix] Contains the jump times in the first column,
the survival in the other arm at times plus threshold in the second column,
and the jump in survival in the third column.</p>
</td></tr>
<tr><td><code id=".calcIntegralSurv_cpp_+3A_start">start</code></td>
<td>
<p>[integer] time at which to start the integral.</p>
</td></tr>
<tr><td><code id=".calcIntegralSurv_cpp_+3A_lastsurv">lastSurv</code></td>
<td>
<p>[numeric,&gt;0] last survival value for the survival function in the second column.</p>
</td></tr>
<tr><td><code id=".calcIntegralSurv_cpp_+3A_lastdsurv">lastdSurv</code></td>
<td>
<p>[numeric,&gt;0] last survival value for the survival function in the third column.</p>
</td></tr>
<tr><td><code id=".calcIntegralSurv_cpp_+3A_returnderiv">returnDeriv</code></td>
<td>
<p>[logical] should the derivative regarding the survival parameters be return.</p>
</td></tr>
<tr><td><code id=".calcIntegralSurv_cpp_+3A_derivsurv">derivSurv</code></td>
<td>
<p>[matrix] matrix column filled of 0 whose number of rows is the number of parameters of the survival.</p>
</td></tr>
<tr><td><code id=".calcIntegralSurv_cpp_+3A_derivsurvd">derivSurvD</code></td>
<td>
<p>[matrix] matrix column filled of 0 whose number of rows is the number of parameters of the survival used to compute the jumps.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Brice Ozenne
</p>

<hr>
<h2 id='.colCenter_cpp'>Substract a vector of values in each column</h2><span id='topic+.colCenter_cpp'></span>

<h3>Description</h3>

<p>Fast computation of sweep(X, FUN = &quot;-&quot;, STATS = center, MARGIN = 1)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.colCenter_cpp(X, center)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".colCenter_cpp_+3A_x">X</code></td>
<td>
<p>A matrix.</p>
</td></tr>
<tr><td><code id=".colCenter_cpp_+3A_center">center</code></td>
<td>
<p>A vector with length the number of rows of X .</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of same size as x.
</p>

<hr>
<h2 id='.colCumSum_cpp'>Column-wise cumulative sum</h2><span id='topic+.colCumSum_cpp'></span>

<h3>Description</h3>

<p>Fast computation of apply(x,2,cumsum)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.colCumSum_cpp(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".colCumSum_cpp_+3A_x">X</code></td>
<td>
<p>A matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of same size as x.
</p>

<hr>
<h2 id='.colMultiply_cpp'>Multiply by a vector of values in each column</h2><span id='topic+.colMultiply_cpp'></span>

<h3>Description</h3>

<p>Fast computation of sweep(X, FUN = &quot;*&quot;, STATS = scale, MARGIN = 1)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.colMultiply_cpp(X, scale)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".colMultiply_cpp_+3A_x">X</code></td>
<td>
<p>A matrix.</p>
</td></tr>
<tr><td><code id=".colMultiply_cpp_+3A_scale">scale</code></td>
<td>
<p>A vector with length the number of rows of X .</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of same size as x.
</p>

<hr>
<h2 id='.colScale_cpp'>Divide by a vector of values in each column</h2><span id='topic+.colScale_cpp'></span>

<h3>Description</h3>

<p>Fast computation of sweep(X, FUN = &quot;/&quot;, STATS = scale, MARGIN = 1)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.colScale_cpp(X, scale)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".colScale_cpp_+3A_x">X</code></td>
<td>
<p>A matrix.</p>
</td></tr>
<tr><td><code id=".colScale_cpp_+3A_scale">scale</code></td>
<td>
<p>A vector with length the number of rows of X .</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of same size as x.
</p>

<hr>
<h2 id='.rowCenter_cpp'>Substract a vector of values in each row</h2><span id='topic+.rowCenter_cpp'></span>

<h3>Description</h3>

<p>Fast computation of sweep(X, FUN = &quot;-&quot;, STATS = center, MARGIN = 2)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rowCenter_cpp(X, center)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".rowCenter_cpp_+3A_x">X</code></td>
<td>
<p>A matrix.</p>
</td></tr>
<tr><td><code id=".rowCenter_cpp_+3A_center">center</code></td>
<td>
<p>A vector with length the number of columns of X.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of same size as x.
</p>

<hr>
<h2 id='.rowCumProd_cpp'>Apply cumprod in each row</h2><span id='topic+.rowCumProd_cpp'></span>

<h3>Description</h3>

<p>Fast computation of t(apply(x,1,cumprod))
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rowCumProd_cpp(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".rowCumProd_cpp_+3A_x">X</code></td>
<td>
<p>A matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of same size as x.
</p>

<hr>
<h2 id='.rowCumSum_cpp'>Row-wise cumulative sum</h2><span id='topic+.rowCumSum_cpp'></span>

<h3>Description</h3>

<p>Fast computation of apply(x,1,cumsum)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rowCumSum_cpp(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".rowCumSum_cpp_+3A_x">X</code></td>
<td>
<p>A matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of same size as x.
</p>

<hr>
<h2 id='.rowMultiply_cpp'>Multiply by a vector of values in each row</h2><span id='topic+.rowMultiply_cpp'></span>

<h3>Description</h3>

<p>Fast computation of sweep(X, FUN = &quot;*&quot;, STATS = center, MARGIN = 2)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rowMultiply_cpp(X, scale)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".rowMultiply_cpp_+3A_x">X</code></td>
<td>
<p>A matrix.</p>
</td></tr>
<tr><td><code id=".rowMultiply_cpp_+3A_scale">scale</code></td>
<td>
<p>A vector with length the number of columns of X.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of same size as x.
</p>

<hr>
<h2 id='.rowScale_cpp'>Dividy by a vector of values in each row</h2><span id='topic+.rowScale_cpp'></span>

<h3>Description</h3>

<p>Fast computation of sweep(X, FUN = &quot;/&quot;, STATS = center, MARGIN = 2)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rowScale_cpp(X, scale)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".rowScale_cpp_+3A_x">X</code></td>
<td>
<p>A matrix.</p>
</td></tr>
<tr><td><code id=".rowScale_cpp_+3A_scale">scale</code></td>
<td>
<p>A vector with length the number of columns of X.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of same size as x.
</p>

<hr>
<h2 id='as.data.table.performance'>Convert Performance Objet to data.table</h2><span id='topic+as.data.table.performance'></span>

<h3>Description</h3>

<p>Extract the AUC/brier score values or the prediction into a data.table format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'performance'
as.data.table(
  x,
  keep.rownames = FALSE,
  type = "performance",
  format = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.data.table.performance_+3A_x">x</code></td>
<td>
<p>object of class <code>"performance"</code>.</p>
</td></tr>
<tr><td><code id="as.data.table.performance_+3A_keep.rownames">keep.rownames</code></td>
<td>
<p>Not used. For compatibility with the generic method.</p>
</td></tr>
<tr><td><code id="as.data.table.performance_+3A_type">type</code></td>
<td>
<p>[character] either <code>"metric"</code> to extract AUC/brier score or <code>"prediction"</code> to extract predictions.</p>
</td></tr>
<tr><td><code id="as.data.table.performance_+3A_format">format</code></td>
<td>
<p>[character] should the result be outcome in the long format (<code>"long"</code>) or in the wide format (<code>"wide"</code>).
Note relevant when using <code>type="metric"</code>.</p>
</td></tr>
<tr><td><code id="as.data.table.performance_+3A_...">...</code></td>
<td>
<p>Not used. For compatibility with the generic method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.table object
</p>

<hr>
<h2 id='auc'>Estimation of the Area Under the ROC Curve (EXPERIMENTAL)</h2><span id='topic+auc'></span>

<h3>Description</h3>

<p>Estimation of the Area Under the ROC curve, possibly after cross validation,
to assess the discriminant ability of a biomarker regarding a disease status.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>auc(
  labels,
  predictions,
  fold = NULL,
  observation = NULL,
  direction = "&gt;",
  add.halfNeutral = TRUE,
  null = 0.5,
  conf.level = 0.95,
  transformation = TRUE,
  order.Hprojection = 2,
  pooling = "mean"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="auc_+3A_labels">labels</code></td>
<td>
<p>[integer/character vector] the disease status (should only take two different values).</p>
</td></tr>
<tr><td><code id="auc_+3A_predictions">predictions</code></td>
<td>
<p>[numeric vector] A vector with the same length as <code>labels</code> containing the biomarker values.</p>
</td></tr>
<tr><td><code id="auc_+3A_fold">fold</code></td>
<td>
<p>[character/integer vector] If using cross validation, the index of the fold. 
Should have the same length as <code>labels</code>.</p>
</td></tr>
<tr><td><code id="auc_+3A_observation">observation</code></td>
<td>
<p>[integer vector] If using cross validation, the index of the corresponding observation in the original dataset.
Necessary to compute the standard error when using cross validation.</p>
</td></tr>
<tr><td><code id="auc_+3A_direction">direction</code></td>
<td>
<p>[character] <code>"&gt;"</code> lead to estimate P[Y&gt;X],
<code>"&lt;"</code> to estimate P[Y&lt;X],
and <code>"auto"</code> to estimate max(P[Y&gt;X],P[Y&lt;X]).</p>
</td></tr>
<tr><td><code id="auc_+3A_add.halfneutral">add.halfNeutral</code></td>
<td>
<p>[logical] should half of the neutral score be added to the favorable and unfavorable scores?
Useful to match the usual definition of the AUC in presence of ties.</p>
</td></tr>
<tr><td><code id="auc_+3A_null">null</code></td>
<td>
<p>[numeric, 0-1] the value against which the AUC should be compared when computing the p-value.</p>
</td></tr>
<tr><td><code id="auc_+3A_conf.level">conf.level</code></td>
<td>
<p>[numeric, 0-1] the confidence level of the confidence intervals.</p>
</td></tr>
<tr><td><code id="auc_+3A_transformation">transformation</code></td>
<td>
<p>[logical] should a log-log transformation be used when computing the confidence intervals and the p-value.</p>
</td></tr>
<tr><td><code id="auc_+3A_order.hprojection">order.Hprojection</code></td>
<td>
<p>[1,2] the order of the H-projection used to linear the statistic when computing the standard error.
2 is involves more calculations but is more accurate in small samples. Only active when the <code>fold</code> argument is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="auc_+3A_pooling">pooling</code></td>
<td>
<p>[character] method used to compute the global AUC from the fold-specific AUC: either an empirical average <code>"mean"</code>
or a weighted average with weights proportional to the number of pairs of observations in each fold <code>"pairs"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The iid decomposition of the AUC is based on a first order decomposition.
So its squared value will not exactly match the square of the standard error estimated with a second order H-projection.
</p>


<h3>Value</h3>

<p>An S3 object of class <code>BuyseTestAUC</code> that inherits from data.frame.
The last line of the object contains the global AUC value with its standard error.
</p>


<h3>References</h3>

<p>Erin LeDell, Maya Petersen, and Mark van der Laan (2015). <b>Computationally efficient confidence intervals for cross-validated area under the ROC curve estimates</b>. <em>Electron J Stat.</em> 9(1):1583–1607. <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(data.table)

n &lt;- 200
set.seed(10)
X &lt;- rnorm(n)
dt &lt;- data.table(Y = as.factor(rbinom(n, size = 1, prob = 1/(1+exp(1/2-X)))),
                 X = X,
                 fold = unlist(lapply(1:10,function(iL){rep(iL,n/10)})))

## compute auc
auc(labels = dt$Y, predictions = dt$X, direction = "&gt;")

## compute auc after 10-fold cross-validation
auc(labels = dt$Y, prediction = dt$X, fold = dt$fold, observation = 1:NROW(dt))

</code></pre>

<hr>
<h2 id='autoplot.S4BuyseTest'>Graphical Display for GPC</h2><span id='topic+autoplot.S4BuyseTest'></span>

<h3>Description</h3>

<p>Graphical display of the percentage of favorable, unfavorable, neutral, and uninformative pairs per endpoint.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'S4BuyseTest'
autoplot(
  object,
  type = "hist",
  strata = "global",
  endpoint = NULL,
  label.strata = NULL,
  label.endpoint = NULL,
  color = c("#7CAE00", "#F8766D", "#C77CFF", "#00BFC4"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="autoplot.S4BuyseTest_+3A_object">object</code></td>
<td>
<p>an <span class="rlang"><b>R</b></span> object of class <code><a href="#topic+S4BuyseTest-class">S4BuyseTest</a></code>, i.e., output of <code><a href="#topic+BuyseTest">BuyseTest</a></code></p>
</td></tr>
<tr><td><code id="autoplot.S4BuyseTest_+3A_type">type</code></td>
<td>
<p>[character] type of plot: histogram (<code>"hist"</code>), pie chart (<code>"pie"</code>), or nested pie charts (<code>"racetrack"</code>).</p>
</td></tr>
<tr><td><code id="autoplot.S4BuyseTest_+3A_strata">strata</code></td>
<td>
<p>[character vector] strata(s) relative to which the percentage should be displayed.</p>
</td></tr>
<tr><td><code id="autoplot.S4BuyseTest_+3A_endpoint">endpoint</code></td>
<td>
<p>[character vector] endpoint(s) relative to which the percentage should be displayed.</p>
</td></tr>
<tr><td><code id="autoplot.S4BuyseTest_+3A_label.strata">label.strata</code></td>
<td>
<p>[character vector] new labels for the strata levels. Should match the length of argument <code>strata</code>.</p>
</td></tr>
<tr><td><code id="autoplot.S4BuyseTest_+3A_label.endpoint">label.endpoint</code></td>
<td>
<p>[character vector] new labels for the endpoints. Should match the length of argument <code>endpoint</code>.</p>
</td></tr>
<tr><td><code id="autoplot.S4BuyseTest_+3A_color">color</code></td>
<td>
<p>[character vector] colors used to display the percentages for each type of pair.</p>
</td></tr>
<tr><td><code id="autoplot.S4BuyseTest_+3A_...">...</code></td>
<td>
<p>not used, for compatibility with the generic function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a ggplot object.
</p>

<hr>
<h2 id='brier'>Estimation of the Brier Score (EXPERIMENTAL)</h2><span id='topic+brier'></span>

<h3>Description</h3>

<p>Estimation of the brier score, possibly after cross validation,
to assess the discriminant ability and calibration of a biomarker regarding a disease status.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>brier(
  labels,
  predictions,
  iid = NULL,
  fold = NULL,
  observation = NULL,
  null = NA,
  conf.level = 0.95,
  transformation = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="brier_+3A_labels">labels</code></td>
<td>
<p>[integer/character vector] the disease status (should only take two different values).</p>
</td></tr>
<tr><td><code id="brier_+3A_predictions">predictions</code></td>
<td>
<p>[numeric vector] A vector with the same length as <code>labels</code> containing the biomarker values.</p>
</td></tr>
<tr><td><code id="brier_+3A_iid">iid</code></td>
<td>
<p>[array, optional] influence function of the prediction. For cross validation (CV) should be a 3 dimensional array (one slice per CV fold).
Otherwise a matrix with as many column as observations and rows as predictions.</p>
</td></tr>
<tr><td><code id="brier_+3A_fold">fold</code></td>
<td>
<p>[character/integer vector] If using cross validation, the index of the fold. 
Should have the same length as <code>labels</code>.</p>
</td></tr>
<tr><td><code id="brier_+3A_observation">observation</code></td>
<td>
<p>[integer vector] If using cross validation, the index of the corresponding observation in the original dataset.
Necessary to compute the standard error when using cross validation.</p>
</td></tr>
<tr><td><code id="brier_+3A_null">null</code></td>
<td>
<p>[numeric, 0-1] the value against which the AUC should be compared when computing the p-value.</p>
</td></tr>
<tr><td><code id="brier_+3A_conf.level">conf.level</code></td>
<td>
<p>[numeric, 0-1] the confidence level of the confidence intervals.</p>
</td></tr>
<tr><td><code id="brier_+3A_transformation">transformation</code></td>
<td>
<p>[logical] should a log-log transformation be used when computing the confidence intervals and the p-value.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An S3 object of class <code>BuyseTestBrier</code> that inherits from data.frame.
</p>

<hr>
<h2 id='BuyseMultComp'>Adjustment for Multiple Comparisons</h2><span id='topic+BuyseMultComp'></span>

<h3>Description</h3>

<p>Adjust p-values and confidence intervals estimated via GPC for multiple comparisons.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BuyseMultComp(
  object,
  cluster = NULL,
  linfct = NULL,
  rhs = NULL,
  endpoint = NULL,
  statistic = NULL,
  cumulative = TRUE,
  conf.level = NULL,
  band = TRUE,
  global = FALSE,
  alternative = NULL,
  transformation = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BuyseMultComp_+3A_object">object</code></td>
<td>
<p>A BuyseTest object or a list of BuyseTest objects. All objects should contain the same endpoints.</p>
</td></tr>
<tr><td><code id="BuyseMultComp_+3A_cluster">cluster</code></td>
<td>
<p>[character] name of the variable identifying the observations in the dataset used by each BuyseTest model.
Only relevant when using a list of BuyseTest objects to correctly combine the influence functions.
If NULL, then it is assumed that the BuyseTest objects correspond to different groups of individuals.</p>
</td></tr>
<tr><td><code id="BuyseMultComp_+3A_linfct">linfct</code></td>
<td>
<p>[numeric matrix] a contrast matrix of size the number of endpoints times the number of BuyseTest models.</p>
</td></tr>
<tr><td><code id="BuyseMultComp_+3A_rhs">rhs</code></td>
<td>
<p>[numeric vector] the values for which the test statistic should be tested against. Should have the same number of rows as <code>linfct</code>.</p>
</td></tr>
<tr><td><code id="BuyseMultComp_+3A_endpoint">endpoint</code></td>
<td>
<p>[character or numeric vector] the endpoint(s) to be considered.</p>
</td></tr>
<tr><td><code id="BuyseMultComp_+3A_statistic">statistic</code></td>
<td>
<p>[character] the statistic summarizing the pairwise comparison:
<code>"netBenefit"</code> displays the net benefit, as described in Buyse (2010) and Peron et al. (2016)),
<code>"winRatio"</code> displays the win ratio, as described in Wang et al. (2016),
<code>"favorable"</code> displays the proportion in favor of the treatment (also called Mann-Whitney parameter), as described in Fay et al. (2018).
<code>"unfavorable"</code> displays the proportion in favor of the control.
Default value read from <code>BuyseTest.options()</code>.</p>
</td></tr>
<tr><td><code id="BuyseMultComp_+3A_cumulative">cumulative</code></td>
<td>
<p>[logical] should the summary statistic be cumulated over endpoints?
Otherwise display the contribution of each endpoint.</p>
</td></tr>
<tr><td><code id="BuyseMultComp_+3A_conf.level">conf.level</code></td>
<td>
<p>[numeric] confidence level for the confidence intervals.
Default value read from <code>BuyseTest.options()</code>.</p>
</td></tr>
<tr><td><code id="BuyseMultComp_+3A_band">band</code></td>
<td>
<p>[logical] Should confidence intervals and p-values adjusted for multiple comparisons be computed.</p>
</td></tr>
<tr><td><code id="BuyseMultComp_+3A_global">global</code></td>
<td>
<p>[logical] Should global test (intersection of all null hypotheses) be made?</p>
</td></tr>
<tr><td><code id="BuyseMultComp_+3A_alternative">alternative</code></td>
<td>
<p>[character] the type of alternative hypothesis: <code>"two.sided"</code>, <code>"greater"</code>, or <code>"less"</code>.
Default value read from <code>BuyseTest.options()</code>.</p>
</td></tr>
<tr><td><code id="BuyseMultComp_+3A_transformation">transformation</code></td>
<td>
<p>[logical]  should the CI be computed on the logit scale / log scale for the net benefit / win ratio and backtransformed.
Otherwise they are computed without any transformation.
Default value read from <code>BuyseTest.options()</code>. Not relevant when using permutations or percentile bootstrap.</p>
</td></tr>
<tr><td><code id="BuyseMultComp_+3A_...">...</code></td>
<td>
<p>argument passsed to the function <code>transformCIBP</code> of the riskRegression package.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Simulateneous confidence intervals and adjusted p-values are computed using a single-step max-test approach via the function <code>transformCIBP</code> of the riskRegression package.
This corresponds to the single-step Dunnett described in Dmitrienko et al (2013) in table 2 and section 7.
</p>


<h3>Value</h3>

<p>An S3 object of class <code>BuyseMultComp</code>.
</p>


<h3>References</h3>

<p>Dmitrienko, A. and D'Agostino, R., Sr (2013), Traditional multiplicity adjustment methods in clinical trials. Statist. Med., 32: 5172-5218. https://doi.org/10.1002/sim.5990
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#### simulate data ####
set.seed(10)
df.data &lt;- simBuyseTest(1e2, n.strata = 3)

#### adjustment for all univariate analyses ####
ff1 &lt;- treatment ~ TTE(eventtime, status = status, threshold = 0.1)
ff2 &lt;- update(ff1, .~. + cont(score, threshold = 1))
BT2 &lt;- BuyseTest(ff2, data= df.data, trace = FALSE)

## (require riskRegression &gt;= 2021.10.04 to match)
confint(BT2, cumulative = FALSE) ## not adjusted
confintAdj &lt;- BuyseMultComp(BT2, cumulative = FALSE, endpoint = 1:2) ## adjusted
confintAdj
if(require(lava)){
cor(lava::iid(confintAdj)) ## correlation between test-statistic
}

#### 2- adjustment for multi-arm trial ####
## case where we have more than two treatment groups
## here strata will represent the treatment groups
df.data$strata &lt;- as.character(df.data$strata)
df.data$id &lt;- paste0("Id",1:NROW(df.data)) ## define id variable

BT1ba &lt;- BuyseTest(strata ~ TTE(eventtime, status = status, threshold = 1),
                   data= df.data[strata %in% c("a","b"),], trace = FALSE)
BT1ca &lt;- BuyseTest(strata ~ TTE(eventtime, status = status, threshold = 0.1),
                   data= df.data[strata %in% c("a","c"),], trace = FALSE)
BT1cb &lt;- BuyseTest(strata ~ TTE(eventtime, status = status, threshold = 0.1),
                   data= df.data[strata %in% c("b","c"),], trace = FALSE)
rbind("b-a" = confint(BT1ba),
      "c-a" = confint(BT1ca),
      "c-b" = confint(BT1cb)) ## not adjusted
confintAdj &lt;- BuyseMultComp(list("b-a" = BT1ba, "c-a" = BT1ca, "c-b" = BT1cb),
                            cluster = "id", global = TRUE)
confintAdj
if(require(lava)){
cor(lava::iid(confintAdj))
}
</code></pre>

<hr>
<h2 id='BuyseTest'>Two-group GPC</h2><span id='topic+BuyseTest'></span>

<h3>Description</h3>

<p>Performs Generalized Pairwise Comparisons (GPC) between two groups.
Can handle one or several binary, continuous and time-to-event endpoints.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BuyseTest(
  formula,
  data,
  scoring.rule = NULL,
  pool.strata = NULL,
  correction.uninf = NULL,
  model.tte = NULL,
  method.inference = NULL,
  n.resampling = NULL,
  strata.resampling = NULL,
  hierarchical = NULL,
  weightEndpoint = NULL,
  weightObs = NULL,
  neutral.as.uninf = NULL,
  add.halfNeutral = NULL,
  keep.pairScore = NULL,
  seed = NULL,
  cpus = NULL,
  trace = NULL,
  treatment = NULL,
  endpoint = NULL,
  type = NULL,
  threshold = NULL,
  status = NULL,
  operator = NULL,
  censoring = NULL,
  restriction = NULL,
  strata = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BuyseTest_+3A_formula">formula</code></td>
<td>
<p>[formula] a symbolic description of the GPC model,
typically <code>treatment ~ type1(endpoint1) + type2(endpoint2, threshold2) + strata</code>.
See Details, section &quot;Specification of the GPC model&quot;.</p>
</td></tr>
<tr><td><code id="BuyseTest_+3A_data">data</code></td>
<td>
<p>[data.frame] dataset.</p>
</td></tr>
<tr><td><code id="BuyseTest_+3A_scoring.rule">scoring.rule</code></td>
<td>
<p>[character] method used to compare the observations of a pair in presence of right censoring (i.e. <code>"timeToEvent"</code> endpoints).
Can be <code>"Gehan"</code> or <code>"Peron"</code>.
See Details, section &quot;Handling missing values&quot;.</p>
</td></tr>
<tr><td><code id="BuyseTest_+3A_pool.strata">pool.strata</code></td>
<td>
<p>[character] weights used to combine estimates across strata. Can be
<code>"Buyse"</code> to weight proportionally to the number of pairs in the strata,
<code>"CMH"</code> to weight proportionally to the ratio between the number of pairs in the strata and the number of observations in the strata.
<code>"equal"</code> to weight equally each strata,
or <code>"var-netBenefit"</code> to weight each strata proportionally to the precision of its estimated net benefit (similar syntax for the win ratio: <code>"var-winRatio"</code>)</p>
</td></tr>
<tr><td><code id="BuyseTest_+3A_correction.uninf">correction.uninf</code></td>
<td>
<p>[integer] should a correction be applied to remove the bias due to the presence of uninformative pairs?
0 indicates no correction, 1 impute the average score of the informative pairs, and 2 performs IPCW.
See Details, section &quot;Handling missing values&quot;.</p>
</td></tr>
<tr><td><code id="BuyseTest_+3A_model.tte">model.tte</code></td>
<td>
<p>[list] optional survival models relative to each time to each time to event endpoint.
Models must <code>prodlim</code> objects and stratified on the treatment and strata variable. When used, the uncertainty from the estimates of these survival models is ignored.</p>
</td></tr>
<tr><td><code id="BuyseTest_+3A_method.inference">method.inference</code></td>
<td>
<p>[character] method used to compute confidence intervals and p-values.
Can be <code>"none"</code>, <code>"u-statistic"</code>, <code>"permutation"</code>, <code>"studentized permutation"</code>, <code>"bootstrap"</code>, <code>"studentized bootstrap"</code>.
See Details, section &quot;Statistical inference&quot;.</p>
</td></tr>
<tr><td><code id="BuyseTest_+3A_n.resampling">n.resampling</code></td>
<td>
<p>[integer] the number of permutations/samples used for computing the confidence intervals and the p.values. 
See Details, section &quot;Statistical inference&quot;.</p>
</td></tr>
<tr><td><code id="BuyseTest_+3A_strata.resampling">strata.resampling</code></td>
<td>
<p>[character] the variable on which the permutation/sampling should be stratified. 
See Details, section &quot;Statistical inference&quot;.</p>
</td></tr>
<tr><td><code id="BuyseTest_+3A_hierarchical">hierarchical</code></td>
<td>
<p>[logical] should only the uninformative pairs be analyzed at the lower priority endpoints (hierarchical GPC)?
Otherwise all pairs will be compaired for all endpoint (full GPC).</p>
</td></tr>
<tr><td><code id="BuyseTest_+3A_weightendpoint">weightEndpoint</code></td>
<td>
<p>[numeric vector] weights used to cumulating the pairwise scores over the endpoints.
Only used when <code>hierarchical=FALSE</code>. Disregarded if the argument <code>formula</code> is defined.</p>
</td></tr>
<tr><td><code id="BuyseTest_+3A_weightobs">weightObs</code></td>
<td>
<p>[character or numeric vector] weights or variable in the dataset containing the weight associated to each observation.
These weights are only considered when performing GPC (but not when fitting surival models).</p>
</td></tr>
<tr><td><code id="BuyseTest_+3A_neutral.as.uninf">neutral.as.uninf</code></td>
<td>
<p>[logical vector] should paired classified as neutral be re-analyzed using endpoints of lower priority (as it is done for uninformative pairs).
See Details, section &quot;Handling missing values&quot;.</p>
</td></tr>
<tr><td><code id="BuyseTest_+3A_add.halfneutral">add.halfNeutral</code></td>
<td>
<p>[logical] should half of the neutral score be added to the favorable and unfavorable scores?</p>
</td></tr>
<tr><td><code id="BuyseTest_+3A_keep.pairscore">keep.pairScore</code></td>
<td>
<p>[logical] should the result of each pairwise comparison be kept?</p>
</td></tr>
<tr><td><code id="BuyseTest_+3A_seed">seed</code></td>
<td>
<p>[integer, &gt;0] Random number generator (RNG) state used when starting resampling.
If <code>NULL</code> no state is set.</p>
</td></tr>
<tr><td><code id="BuyseTest_+3A_cpus">cpus</code></td>
<td>
<p>[integer, &gt;0] the number of CPU to use.
Only the permutation test can use parallel computation.
See Details, section &quot;Statistical inference&quot;.</p>
</td></tr>
<tr><td><code id="BuyseTest_+3A_trace">trace</code></td>
<td>
<p>[integer] should the execution of the function be traced ? <code>0</code> remains silent
and <code>1</code>-<code>3</code> correspond to a more and more verbose output in the console.</p>
</td></tr>
<tr><td><code id="BuyseTest_+3A_treatment">treatment</code>, <code id="BuyseTest_+3A_endpoint">endpoint</code>, <code id="BuyseTest_+3A_type">type</code>, <code id="BuyseTest_+3A_threshold">threshold</code>, <code id="BuyseTest_+3A_status">status</code>, <code id="BuyseTest_+3A_operator">operator</code>, <code id="BuyseTest_+3A_censoring">censoring</code>, <code id="BuyseTest_+3A_restriction">restriction</code>, <code id="BuyseTest_+3A_strata">strata</code></td>
<td>
<p>Alternative to <code>formula</code> for describing the GPC model.
See Details, section &quot;Specification of the GPC model&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>Specification of the GPC model</b> <br />
There are two way to specify the GPC model in <code>BuyseTest</code>.
A <em>Formula interface</em> via the argument <code>formula</code> where the response variable should be a binary variable defining the treatment arms. 
The rest of the formula should indicate the endpoints by order of priority and the strata variables (if any).
A <em>Vector interface</em> using  the following arguments </p>

<ul>
<li> <p><code>treatment</code>: [character] name of the treatment variable identifying the control and the experimental group.
Must have only two levels (e.g. <code>0</code> and <code>1</code>).
</p>
</li>
<li> <p><code>endpoint</code>: [character vector] the name of the endpoint variable(s).
</p>
</li>
<li> <p><code>threshold</code>: [numeric vector] critical values used to compare the pairs (threshold of minimal important difference).
A pair will be classified as neutral if the difference in endpoint is strictly below this threshold.
There must be one threshold for each endpoint variable; it must be <code>NA</code> for binary endpoints and positive for continuous or time to event endpoints. 
</p>
</li>
<li> <p><code>status</code>: [character vector] the name of the binary variable(s) indicating whether the endpoint was observed or censored.
Must value <code>NA</code> when the endpoint is not a time to event.
</p>
</li>
<li> <p><code>operator</code>: [character vector] the sign defining a favorable endpoint.
<code>"&gt;0"</code> indicates that higher values are favorable while &quot;&lt;0&quot; indicates the opposite.
</p>
</li>
<li> <p><code>type</code>: [character vector] indicates whether it is
a binary outcome  (<code>"b"</code>, <code>"bin"</code>, or <code>"binary"</code>),
a continuous outcome  (<code>"c"</code>, <code>"cont"</code>, or <code>"continuous"</code>),
or a time to event outcome  (<code>"t"</code>, <code>"tte"</code>, <code>"time"</code>, or <code>"timetoevent"</code>)
</p>
</li>
<li> <p><code>censoring</code>: [character vector] is the endpoint subject to right or left censoring (<code>"left"</code> or <code>"right"</code>). The default is right-censoring.
</p>
</li>
<li> <p><code>restriction</code>: [numeric vector] value above which any difference is classified as neutral.
</p>
</li>
<li> <p><code>strata</code>: [character vector] if not <code>NULL</code>, the GPC will be applied within each group of patient defined by the strata variable(s).
</p>
</li></ul>

<p>The formula interface can be more concise, especially when considering few outcomes, but may be more difficult to apprehend for new users.
Note that arguments <code>endpoint</code>, <code>threshold</code>, <code>status</code>, <code>operator</code>,  <code>type</code>, and <code>censoring</code> must have the same length. <br /> <br /> <br />
</p>
<p><b>GPC procedure</b> <br />
The GPC procedure form all pairs of observations, one belonging to the experimental group and the other to the control group, and class them in 4 categories: </p>

<ul>
<li> <p><em>Favorable pair</em>: the endpoint is better for the observation in the experimental group.
</p>
</li>
<li> <p><em>Unfavorable pair</em>: the endpoint is better for the observation in the control group.
</p>
</li>
<li> <p><em>Neutral pair</em>: the difference between the endpoints of the two observations is (in absolute value) below the threshold. When <code>threshold=0</code>, neutral pairs correspond to pairs with equal endpoint. Lower-priority outcomes (if any) are then used to classified the pair into favorable/unfavorable.
</p>
</li>
<li> <p><em>Uninformative pair</em>: censoring/missingness prevents from classifying into favorable, unfavorable or neutral.
</p>
</li></ul>

<p>With complete data, pairs can be decidely classified as favorable/unfavorable/neutral.
In presence of missing values, the GPC procedure uses the scoring rule (argument <code>scoring.rule</code>) and the correction for uninformative pairs (argument <code>correction.uninf</code>) to classify the pairs.
The classification may not be 0,1, e.g. the probability that the pair is favorable/unfavorable/neutral with the Peron's scoring rule.
To export the classification of each pair set the argument <code>keep.pairScore</code> to <code>TRUE</code> and call the function <code>getPairScore</code> on the result of the <code>BuyseTest</code> function. <br /> <br /> <br />
</p>
<p><b>Handling missing values</b>
</p>

<ul>
<li> <p><code>scoring.rule</code>: indicates how to handle right-censoring in time to event endpoints using information from the survival curves.
The Gehan's scoring rule (argument <code>scoring.rule="Gehan"</code>) only scores pairs that can be decidedly classified as favorable, unfavorable, or neutral
while the &quot;Peron&quot;'s scoring rule (argument <code>scoring.rule="Peron"</code>) uses the empirical survival curves of each group to also score the pairs that cannot be decidedly classified.
The Peron's scoring rule is the recommanded scoring rule but only handles right-censoring. 
</p>
</li>
<li> <p><code>correction.uninf</code>: indicates how to handle missing values that could not be classified by the scoring rule.  </p>

<dl>
<dt><code>correction.uninf=0</code></dt><dd><p> treat them as uninformative: this is an equivalent to complete case analysis when <code>neutral.as.uninf=FALSE</code>, while when <code>neutral.as.uninf=TRUE</code>, uninformative pairs are treated as neutral, i.e., analyzed at the following endpoint (if any). This approach will (generally) lead to biased estimates for the proportion of favorable, unfavorable, or neutral pairs.</p>
</dd>
<dt><code>correction.uninf=1</code></dt><dd><p> imputes to the uninformative pairs the average score of the informative pairs, i.e. assumes that uninformative pairs would on average behave like informative pairs. This is therefore the recommanded approach when this assumption is resonnable, typically when the the tail of the survival function estimated by the Kaplan–Meier method is close to 0.</p>
</dd>
<dt><code>correction.uninf=2</code></dt><dd><p> uses inverse probability of censoring weights (IPCW), i.e. up-weight informative pairs to represent uninformative pairs. It also assumes that uninformative pairs would on average behave like informative pairs and is only recommanded when the analysis is stopped after the first endpoint with uninformative pairs.</p>
</dd>
</dl>

<p>Note that both corrections will convert the whole proportion of uninformative pairs of a given endpoint into favorable, unfavorable, or neutral pairs. See Peron et al (2021) for further details and recommandations <br /> <br />
</p>
</li></ul>

<p><b>Statistical inference</b> <br />
The argument <code>method.inference</code> defines how to approximate the distribution of the GPC estimators and so how standard errors, confidence intervals, and p-values are computed.
Available methods are:
</p>

<ul>
<li><p> argument <code>method.inference="none"</code>: only the point estimate is computed which makes the execution of the <code>BuyseTest</code> faster than with the other methods.
</p>
</li>
<li><p> argument <code>method.inference="u-statistic"</code>: uses a Gaussian approximation to obtain the distribution of the GPC estimators.
The U-statistic theory indicates that this approximation is asymptotically exact.
The variance is computed using a H-projection of order 1 (default option), which is a consistent but downward biased estimator.
An unbiased estimator can be obtained using a H-projection of order 2 (only available for the uncorrected Gehan's scoring rule, see <code>BuyseTest.options</code>).
<b>WARNING</b>: the current implementation of the H-projection is not valid when using corrections for uninformative pairs (<code>correction.uninf=1</code>, or <code>correction.uninf=2</code>).
</p>
</li>
<li><p> argument <code>method.inference="permutation"</code>: perform a permutation test, estimating in each sample the summary statistics (net benefit, win ratio).
</p>
</li>
<li><p> argument <code>method.inference="studentized permutation"</code>: perform a permutation test, estimating in each sample the summary statistics (net benefit, win ratio) and the variance-covariance matrix of the estimate.
</p>
</li>
<li><p> argument <code>method.inference="bootstrap"</code>: perform a non-parametric boostrap, estimating in each sample the summary statistics (net benefit, win ratio).
</p>
</li>
<li><p> argument <code>method.inference=" studentized bootstrap"</code>: perform a non-parametric boostrap, estimating in each sample the summary statistics (net benefit, win ratio) and the variance-covariance matrix of the estimator.
</p>
</li></ul>

<p>Additional arguments for permutation and bootstrap resampling:
</p>

<ul>
<li> <p><code>strata.resampling</code> If <code>NA</code> or of length 0, the permutation/non-parametric boostrap will be performed by resampling in the whole sample.
Otherwise, the permutation/non-parametric boostrap will be performed separately for each level that the variable defined in <code>strata.resampling</code> take.
</p>
</li>
<li> <p><code>n.resampling</code> set the number of permutations/samples used.
A large number of permutations (e.g. <code>n.resampling=10000</code>) are needed to obtain accurate CI and p.value. See (Buyse et al., 2010) for more details.
</p>
</li>
<li> <p><code>seed</code>: the seed is used to generate one seed per sample. These seeds are the same whether one or several CPUs are used.
</p>
</li>
<li> <p><code>cpus</code> indicates whether the resampling procedure can be splitted on several cpus to save time. Can be set to <code>"all"</code> to use all available cpus.
The detection of the number of cpus relies on the <code>detectCores</code> function from the <em>parallel</em> package. <br /> <br />
</p>
</li></ul>

<p><b>Pooling results across strata</b> <br /> Consider <code class="reqn">K</code> strata and denote by <code class="reqn">m_k</code> and <code class="reqn">n_k</code> the sample size in the control and active arm (respectively) for strata <code class="reqn">k</code>. Let <code class="reqn">\sigma_k</code> be the standard error of the strata-specific summary statistic (e.g. net benefit). The strata specific weights, <code class="reqn">w_k</code>, are given by:
</p>

<ul>
<li> <p><code>"CMH"</code>: <code class="reqn">w_k=\frac{\frac{m_k \times n_k}{m_k + n_k}}{\sum_{l=1}^K \frac{m_l \times n_l}{m_l + n_l}}</code>. Optimal if the if the odds ratios are constant across strata.
</p>
</li>
<li> <p><code>"equal"</code>:  <code class="reqn">w_k=\frac{1}{K}</code>
</p>
</li>
<li> <p><code>"Buyse"</code>:  <code class="reqn">w_k=\frac{m_k \times n_k}{\sum_{l=1}^K m_l \times n_l}</code>. Optimal if the risk difference is constant across strata
</p>
</li>
<li> <p><code>"var-*"</code> (e.g. <code>"var-netBenefit"</code>): . <code class="reqn">w_k=\frac{1/\sigma^2_k}{\sum_{l=1}^K 1/\sigma^2_k}</code><br /> <br />
</p>
</li></ul>

<p><b>Default values</b> <br />
The default of the arguments
<code>scoring.rule</code>, <code>correction.uninf</code>, <code>method.inference</code>, <code>n.resampling</code>,
<code>hierarchical</code>, <code>neutral.as.uninf</code>, <code>keep.pairScore</code>, <code>strata.resampling</code>,
<code>cpus</code>, <code>trace</code> is read from <code>BuyseTest.options()</code>. <br />
Additional (hidden) arguments are </p>

<ul>
<li> <p><code>alternative</code> [character] the alternative hypothesis. Must be one of &quot;two.sided&quot;, &quot;greater&quot; or &quot;less&quot; (used by <code>confint</code>).
</p>
</li>
<li> <p><code>conf.level</code> [numeric] level for the confidence intervals (used by <code>confint</code>).
</p>
</li>
<li> <p><code>keep.survival</code> [logical] export the survival values used by the Peron's scoring rule.
</p>
</li>
<li> <p><code>order.Hprojection</code> [1 or 2] the order of the H-projection used to compute the variance when <code>method.inference="u-statistic"</code>. 
</p>
</li></ul>



<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> object of class <code><a href="#topic+S4BuyseTest-class">S4BuyseTest</a></code>.
</p>


<h3>Author(s)</h3>

<p>Brice Ozenne
</p>


<h3>References</h3>

<p>On the GPC procedure: Marc Buyse (2010). <b>Generalized pairwise comparisons of prioritized endpoints in the two-sample problem</b>. <em>Statistics in Medicine</em> 29:3245-3257 <br />
On the win ratio: D. Wang, S. Pocock (2016). <b>A win ratio approach to comparing continuous non-normal outcomes in clinical trials</b>. <em>Pharmaceutical Statistics</em> 15:238-245 <br />
On the Peron's scoring rule: J. Peron, M. Buyse, B. Ozenne, L. Roche and P. Roy (2018). <b>An extension of generalized pairwise comparisons for prioritized outcomes in the presence of censoring</b>. <em>Statistical Methods in Medical Research</em> 27: 1230-1239. <br />
On the Gehan's scoring rule: Gehan EA (1965). <b>A generalized two-sample Wilcoxon test for doubly censored data</b>. <em>Biometrika</em>  52(3):650-653 <br />
On inference in GPC using the U-statistic theory: Ozenne B, Budtz-Jorgensen E, Peron J (2021). <b>The asymptotic distribution of the Net Benefit estimator in presence of right-censoring</b>. <em>Statistical Methods in Medical Research</em> 2021 doi:10.1177/09622802211037067 <br />
On how to handle right-censoring: J. Peron, M. Idlhaj, D. Maucort-Boulch, et al. (2021) <b>Correcting the bias of the net benefit estimator due to right-censored observations</b>. <em>Biometrical Journal</em> 63: 893–906.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+S4BuyseTest-summary">S4BuyseTest-summary</a></code> for a summary of the results of generalized pairwise comparison. <br />
<code><a href="#topic+S4BuyseTest-confint">S4BuyseTest-confint</a></code> for exporting estimates with confidence intervals and p-values. <br />
<code><a href="#topic+S4BuyseTest-model.tables">S4BuyseTest-model.tables</a></code> for exporting the number or percentage of favorable/unfavorable/neutral/uninformative pairs. <br />
<code><a href="#topic+S4BuyseTest-sensitivity">S4BuyseTest-sensitivity</a></code> for performing a sensitivity analysis on the choice of the threshold(s). <br />
<code><a href="#topic+S4BuyseTest-plot">S4BuyseTest-plot</a></code> for graphical display of the pairs across endpoints. <br />
<code><a href="#topic+S4BuyseTest-getIid">S4BuyseTest-getIid</a></code> for exporting the first order H-decomposition. <br />
<code><a href="#topic+S4BuyseTest-getPairScore">S4BuyseTest-getPairScore</a></code> for exporting the scoring of each pair.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(data.table)

#### simulate some data ####
set.seed(10)
df.data &lt;- simBuyseTest(1e2, n.strata = 2)

## display 
if(require(prodlim)){
   resKM_tempo &lt;- prodlim(Hist(eventtime,status)~treatment, data = df.data)
   plot(resKM_tempo)
}

#### one time to event endpoint ####
BT &lt;- BuyseTest(treatment ~ TTE(eventtime, status = status), data= df.data)

summary(BT) ## net benefit
model.tables(BT) ## export the table at the end of summary
summary(BT, percentage = FALSE)  
summary(BT, statistic = "winRatio") ## win Ratio

## permutation instead of asymptotics to compute the p-value
## Not run: 
    BTperm &lt;- BuyseTest(treatment ~ TTE(eventtime, status = status), data=df.data,
                    method.inference = "permutation", n.resampling = 1e3)

## End(Not run)

summary(BTperm)
summary(BTperm, statistic = "winRatio") 

## same with parallel calculations
## Not run: 
    BTperm &lt;- BuyseTest(treatment ~ TTE(eventtime, status = status), data=df.data,
                    method.inference = "permutation", n.resampling = 1e3, cpus = 8)
    summary(BTperm)

## End(Not run)

## method Gehan is much faster but does not optimally handle censored observations
BT &lt;- BuyseTest(treatment ~ TTE(eventtime, status = status), data=df.data,
                scoring.rule = "Gehan", trace = 0)
summary(BT)

#### one time to event endpoint: only differences in survival over 1 unit ####
BT &lt;- BuyseTest(treatment ~ TTE(eventtime, threshold = 1, status = status), data=df.data)
summary(BT)

#### one time to event endpoint with a strata variable
BTS &lt;- BuyseTest(treatment ~ strata + TTE(eventtime, status = status), data=df.data)
summary(BTS)

#### several endpoints with a strata variable
ff &lt;- treatment ~ strata + T(eventtime, status, 1) + B(toxicity) 
ff &lt;- update(ff, 
            ~. + T(eventtime, status, 0.5) + C(score, 1) + T(eventtime, status, 0.25))

BTM &lt;- BuyseTest(ff, data=df.data)
summary(BTM)
plot(BTM)

#### real example : veteran dataset of the survival package ####
## Only one endpoint. Type = Time-to-event. Thresold = 0. Stratfication by histological subtype
## scoring.rule = "Gehan"

if(require(survival)){
## Not run: 
  data(cancer, package = "survival") ## import veteran
 
  ## scoring.rule = "Gehan"
  BT_Gehan &lt;- BuyseTest(trt ~ celltype + TTE(time,threshold=0,status=status), 
                        data=veteran, scoring.rule="Gehan")
  
  summary_Gehan &lt;- summary(BT_Gehan)
  summary_Gehan &lt;- summary(BT_Gehan, statistic = "winRatio")
  
  ## scoring.rule = "Peron"
  BT_Peron &lt;- BuyseTest(trt ~ celltype + TTE(time,threshold=0,status=status), 
                        data=veteran, scoring.rule="Peron")

  summary(BT_Peron)

## End(Not run)
}
</code></pre>

<hr>
<h2 id='BuyseTest.options'>Global options for BuyseTest package</h2><span id='topic+BuyseTest.options'></span>

<h3>Description</h3>

<p>Update or select global options for the BuyseTest package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BuyseTest.options(..., reinitialise = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BuyseTest.options_+3A_...">...</code></td>
<td>
<p>options to be selected or updated</p>
</td></tr>
<tr><td><code id="BuyseTest.options_+3A_reinitialise">reinitialise</code></td>
<td>
<p>should all the global parameters be set to their default value</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library(data.table)

## see all global parameters
BuyseTest.options()

## see some of the global parameters
BuyseTest.options("n.resampling", "trace")

## update some of the global parameters
BuyseTest.options(n.resampling = 10, trace = 1)
BuyseTest.options("n.resampling", "trace")

## reinitialise all global parameters
BuyseTest.options(reinitialise = TRUE)
</code></pre>

<hr>
<h2 id='BuyseTest.options-class'>Class &quot;BuyseTest.options&quot; (global setting for the BuyseTest package)</h2><span id='topic+BuyseTest.options-class'></span>

<h3>Description</h3>

<p>Class defining the global settings for the BuyseTest package.
</p>


<h3>Author(s)</h3>

<p>Brice Ozenne
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BuyseTest.options">BuyseTest.options</a></code> to select or update global settings.
</p>

<hr>
<h2 id='BuyseTest.options-methods'>Methods for the class &quot;BuyseTest.options&quot;</h2><span id='topic+BuyseTest.options-methods'></span><span id='topic+alloc+2CBuyseTest.options-method'></span><span id='topic+select+2CBuyseTest.options-method'></span>

<h3>Description</h3>

<p>Methods to update or select global settings
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'BuyseTest.options'
alloc(object, field)

## S4 method for signature 'BuyseTest.options'
select(object, name.field)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BuyseTest.options-methods_+3A_object">object</code></td>
<td>
<p>an object of class <code>BuyseTest.options</code>.</p>
</td></tr>
<tr><td><code id="BuyseTest.options-methods_+3A_field">field</code></td>
<td>
<p>a <code>list</code> named with the name of the fields to update and containing the values to assign to these fields</p>
</td></tr>
<tr><td><code id="BuyseTest.options-methods_+3A_name.field">name.field</code></td>
<td>
<p>a <code>character vector</code> containing the names of the field to be selected.</p>
</td></tr>
</table>

<hr>
<h2 id='BuyseTTEM'>Time to Event Model</h2><span id='topic+BuyseTTEM'></span><span id='topic+BuyseTTEM.formula'></span><span id='topic+BuyseTTEM.prodlim'></span><span id='topic+BuyseTTEM.survreg'></span><span id='topic+BuyseTTEM.BuyseTTEM'></span>

<h3>Description</h3>

<p>Pre-compute quantities of a time to event model useful for predictions.
Only does something for prodlim objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BuyseTTEM(object, ...)

## S3 method for class 'formula'
BuyseTTEM(object, treatment, iid, iid.surv = "exp", ...)

## S3 method for class 'prodlim'
BuyseTTEM(object, treatment, iid, iid.surv = "exp", ...)

## S3 method for class 'survreg'
BuyseTTEM(object, treatment, n.grid = 1000, iid, ...)

## S3 method for class 'BuyseTTEM'
BuyseTTEM(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BuyseTTEM_+3A_object">object</code></td>
<td>
<p>time to event model.</p>
</td></tr>
<tr><td><code id="BuyseTTEM_+3A_...">...</code></td>
<td>
<p>additional arguments passed to lower lever methods.</p>
</td></tr>
<tr><td><code id="BuyseTTEM_+3A_treatment">treatment</code></td>
<td>
<p>[character] Name of the treatment variable.</p>
</td></tr>
<tr><td><code id="BuyseTTEM_+3A_iid">iid</code></td>
<td>
<p>[logical] Should the iid decomposition of the predictions be output.</p>
</td></tr>
<tr><td><code id="BuyseTTEM_+3A_iid.surv">iid.surv</code></td>
<td>
<p>[character] Estimator of the survival used when computing the influence function.
Can be the product limit estimator (<code>"prodlim"</code>) or an exponential approximation (<code>"exp"</code>, same as in <code>riskRegression::predictCoxPL</code>).</p>
</td></tr>
<tr><td><code id="BuyseTTEM_+3A_n.grid">n.grid</code></td>
<td>
<p>[integer, &gt;0] Number of timepoints used to discretize the time scale. Not relevant for prodlim objects.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An S3 object of class <code>BuyseTTEM</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(prodlim)
library(data.table)

tau &lt;- seq(0,3,length.out=10)

#### survival case ####
set.seed(10)
df.data &lt;- simBuyseTest(1e2, n.strata = 2)

e.prodlim &lt;- prodlim(Hist(eventtime,status)~treatment+strata, data = df.data)
## plot(e.prodlim)

e.prodlim2 &lt;- BuyseTTEM(e.prodlim, treatment = "treatment", iid = TRUE)

predict(e.prodlim2, time = tau, treatment = "T", strata = "a")
predict(e.prodlim, times = tau, newdata = data.frame(treatment = "T", strata = "a"))

predict(e.prodlim2, time = tau, treatment = "C", strata = "a")
predict(e.prodlim, times = tau, newdata = data.frame(treatment = "C", strata = "a"))

#### competing risk case ####
df.dataCR &lt;- copy(df.data)
df.dataCR$status &lt;- rbinom(NROW(df.dataCR), prob = 0.5, size = 2)

e.prodlimCR &lt;- prodlim(Hist(eventtime,status)~treatment+strata, data = df.dataCR)
## plot(e.prodlimCR)

e.prodlimCR2 &lt;- BuyseTTEM(e.prodlimCR, treatment = "treatment", iid = TRUE)

predict(e.prodlimCR2, time = tau, treatment = "T", strata = "a")
predict(e.prodlimCR, times = tau, newdata = data.frame(treatment = "T", strata = "a"), cause = 1)

predict(e.prodlimCR2, time = tau, treatment = "C", strata = "a")
predict(e.prodlimCR, times = tau, newdata = data.frame(treatment = "C", strata = "a"), cause = 1)
</code></pre>

<hr>
<h2 id='calcIntegralSurv2_cpp'>C++ Function pre-computing the Integral Terms for the Peron Method in the survival case.</h2><span id='topic+calcIntegralSurv2_cpp'></span>

<h3>Description</h3>

<p>Compute the integral with respect to the jump in survival for pairs where both outcomes are censored, i.e. <code class="reqn">\int S1(t+\tau) dS2(t)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcIntegralSurv2_cpp(
  time,
  survival,
  dSurvival,
  index_survival,
  index_dSurvival1,
  index_dSurvival2,
  lastSurv,
  lastdSurv,
  iidNuisance,
  nJump
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calcIntegralSurv2_cpp_+3A_time">time</code></td>
<td>
<p>[numeric vector] vector of jump time for S2.</p>
</td></tr>
<tr><td><code id="calcIntegralSurv2_cpp_+3A_survival">survival</code></td>
<td>
<p>[numeric vector] the survival at each jump time: <code class="reqn">S1(t+\tau)</code>.</p>
</td></tr>
<tr><td><code id="calcIntegralSurv2_cpp_+3A_dsurvival">dSurvival</code></td>
<td>
<p>[numeric vector] the jump in survival at each jump time: <code class="reqn">S2(t+)-S2(t-)</code></p>
</td></tr>
<tr><td><code id="calcIntegralSurv2_cpp_+3A_index_survival">index_survival</code></td>
<td>
<p>[numeric vector] the position of survival parameter <code class="reqn">S1(t+\tau)</code> among all parameters relative to S1.</p>
</td></tr>
<tr><td><code id="calcIntegralSurv2_cpp_+3A_index_dsurvival1">index_dSurvival1</code></td>
<td>
<p>[numeric vector] the position of survival parameter <code class="reqn">S2(t-)</code> among all parameters relative to S2.</p>
</td></tr>
<tr><td><code id="calcIntegralSurv2_cpp_+3A_index_dsurvival2">index_dSurvival2</code></td>
<td>
<p>[numeric vector] the position of survival parameter <code class="reqn">S2(t+)</code> among all parameters relative to S2.</p>
</td></tr>
<tr><td><code id="calcIntegralSurv2_cpp_+3A_lastsurv">lastSurv</code></td>
<td>
<p>[numeric] the value of S2 at the end of the follow-up.</p>
</td></tr>
<tr><td><code id="calcIntegralSurv2_cpp_+3A_iidnuisance">iidNuisance</code></td>
<td>
<p>[logical] should the derivative of the integral relative to the S1 and S2 parameter be output.</p>
</td></tr>
<tr><td><code id="calcIntegralSurv2_cpp_+3A_njump">nJump</code></td>
<td>
<p>[integer] the number of jump times relative to S2.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Brice Ozenne
</p>

<hr>
<h2 id='CasinoTest'>Multi-group GPC (EXPERIMENTAL)</h2><span id='topic+CasinoTest'></span>

<h3>Description</h3>

<p>Perform Generalized Pairwise Comparisons (GPC) for two or more groups.
Can handle one or several binary, continuous and time-to-event endpoints.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CasinoTest(
  formula,
  data,
  type = "unweighted",
  add.halfNeutral = NULL,
  method.inference = "u-statistic",
  conf.level = NULL,
  transformation = NULL,
  alternative = NULL,
  method.multcomp = "none",
  seed = NA
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CasinoTest_+3A_formula">formula</code></td>
<td>
<p>[formula] a symbolic description of the GPC model, see the <code>BuyseTest</code> function</p>
</td></tr>
<tr><td><code id="CasinoTest_+3A_data">data</code></td>
<td>
<p>[data.frame] dataset.</p>
</td></tr>
<tr><td><code id="CasinoTest_+3A_type">type</code></td>
<td>
<p>[character] Type of estimator: can be <code>"unweighted"</code> or <code>"weighted"</code>.</p>
</td></tr>
<tr><td><code id="CasinoTest_+3A_add.halfneutral">add.halfNeutral</code></td>
<td>
<p>[logical] should half of the neutral score be added to the favorable and unfavorable scores?</p>
</td></tr>
<tr><td><code id="CasinoTest_+3A_method.inference">method.inference</code></td>
<td>
<p>[character] method used to compute confidence intervals and p-values.
Can be <code>"none"</code>, <code>"u-statistic"</code>, or <code>"rank"</code>.</p>
</td></tr>
<tr><td><code id="CasinoTest_+3A_conf.level">conf.level</code></td>
<td>
<p>[numeric] confidence level for the confidence intervals.
Default value read from <code>BuyseTest.options()</code>.</p>
</td></tr>
<tr><td><code id="CasinoTest_+3A_transformation">transformation</code></td>
<td>
<p>[logical]  should the CI be computed on the inverse hyperbolic tangent scale / log scale for the net benefit / win ratio and backtransformed.
Otherwise they are computed without any transformation.
Default value read from <code>BuyseTest.options()</code>. Not relevant when using permutations or percentile bootstrap.</p>
</td></tr>
<tr><td><code id="CasinoTest_+3A_alternative">alternative</code></td>
<td>
<p>[character] the type of alternative hypothesis: <code>"two.sided"</code>, <code>"greater"</code>, or <code>"less"</code>.
Default value read from <code>BuyseTest.options()</code>.</p>
</td></tr>
<tr><td><code id="CasinoTest_+3A_method.multcomp">method.multcomp</code></td>
<td>
<p>[character] method used to adjust for multiple comparisons.
Can be any element of ‘p.adjust.methods’ (e.g. &quot;holm&quot;), &quot;maxT-integration&quot;, or &quot;maxT-simulation&quot;.</p>
</td></tr>
<tr><td><code id="CasinoTest_+3A_seed">seed</code></td>
<td>
<p>[integer, &gt;0] Random number generator (RNG) state used when adjusting for multiple comparisons.
If <code>NULL</code> no state is set.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Require to have installed the package riskRegression and BuyseTest
</p>
<p>Setting argument <code>method.inference</code> to <code>"rank"</code> uses a U-statistic approach with a small sample correction to match the variance estimator derived in Result 4.16 page 228 of Brunner (2018).
</p>


<h3>Value</h3>

<p>An S3 object of class <code>CasinoTest</code> that inherits from data.frame.
</p>


<h3>References</h3>

<p>Edgar Brunner, Arne C Bathke, and Frank Konietschke (2018). <b>Rank and pseudo-rank procedures for independent observations in factorial designs</b>. Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(data.table)
library(BuyseTest)

#### simulate data ####
set.seed(11)
n &lt;- 4
dt &lt;- rbind(data.table(score = rnorm(n), group = "A"),
            data.table(score = rnorm(2*n), group = "B"),
            data.table(score = rnorm(3*n), group = "C"))
dt$index &lt;- 1:NROW(dt)

#### estimation ####
score.casino &lt;- dt$score

## naive casino (by hand)
M.score &lt;- outer(dt[group=="A",score],score.casino,function(x,y){x&gt;y+0.5*(x==y)})
mean(M.score)

## naive casino (via BuyseTest)
CasinoTest(group ~ cont(score), data = dt, type = "weighted")

## harmonic casino (by hand)
hweight &lt;- unlist(tapply(dt$group, dt$group, function(x){rep(1/length(x),length(x))}))
M.scoreW &lt;- sweep(M.score, MARGIN = 2, FUN = "*", STATS = NROW(dt)*hweight/3)
mean(M.scoreW)

## harmonic casino (via BuyseTest)
CasinoTest(group ~ cont(score), data = dt, type = "unweighted")

#### Relative liver weights data (Brunner 2018, table 4.1, page 183) ####
liverW &lt;- rbind(
  data.frame(value = c(3.78, 3.40, 3.29, 3.14, 3.55, 3.76, 3.23, 3.31),
             group = "Placebo"),
  data.frame(value = c(3.46,3.98,3.09,3.49,3.31,3.73,3.23),
             group = "Dose 1"),
  data.frame(value = c(3.71, 3.36, 3.38, 3.64, 3.41, 3.29, 3.61, 3.87),
             group = "Dose 2"),
  data.frame(value = c(3.86,3.80,4.14,3.62,3.95,4.12,4.54),
             group = "Dose 3"),
  data.frame(value = c(4.14,4.11,3.89,4.21,4.81,3.91,4.19, 5.05),
             group = "Dose 4")
)
liverW$valueU &lt;- liverW$value + (1:NROW(liverW))/1e6

## same as table 4.1, page 183 in Brunner et al (2018)
CasinoTest(group ~ cont(value), data = liverW, type = "weighted", add.halfNeutral = TRUE)
CasinoTest(group ~ cont(valueU), data = liverW, type = "unweighted", add.halfNeutral = TRUE)
</code></pre>

<hr>
<h2 id='coef.BuyseTestAuc'>Extract the AUC Value</h2><span id='topic+coef.BuyseTestAuc'></span>

<h3>Description</h3>

<p>Extract the AUC value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'BuyseTestAuc'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.BuyseTestAuc_+3A_object">object</code></td>
<td>
<p>object of class <code>BuyseTestAUC</code> (output of the <code>auc</code> function).</p>
</td></tr>
<tr><td><code id="coef.BuyseTestAuc_+3A_...">...</code></td>
<td>
<p>not used. For compatibility with the generic function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Estimated value for the AUC (numeric).
</p>

<hr>
<h2 id='coef.BuyseTestBrier'>Extract the Brier Score</h2><span id='topic+coef.BuyseTestBrier'></span>

<h3>Description</h3>

<p>Extract the Brier score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'BuyseTestBrier'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.BuyseTestBrier_+3A_object">object</code></td>
<td>
<p>object of class <code>BuyseTestBrier</code> (output of the <code>brier</code> function).</p>
</td></tr>
<tr><td><code id="coef.BuyseTestBrier_+3A_...">...</code></td>
<td>
<p>not used. For compatibility with the generic function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Estimated value for Brier score (numeric).
</p>

<hr>
<h2 id='confint.BuyseTestAuc'>Extract the AUC value with its Confidence Interval</h2><span id='topic+confint.BuyseTestAuc'></span>

<h3>Description</h3>

<p>Extract the AUC value with its Confidence Interval and p-value testing whether the AUC equals 0.5.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'BuyseTestAuc'
confint(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confint.BuyseTestAuc_+3A_object">object</code></td>
<td>
<p>object of class <code>BuyseTestAUC</code> (output of the <code>auc</code> function).</p>
</td></tr>
<tr><td><code id="confint.BuyseTestAuc_+3A_...">...</code></td>
<td>
<p>not used. For compatibility with the generic function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Estimated value for the AUC, its standard error, the lower and upper bound of the confidence interval and the p-value.
</p>

<hr>
<h2 id='confint.BuyseTestBrier'>Extract the Brier Score with its Confidence Interval</h2><span id='topic+confint.BuyseTestBrier'></span>

<h3>Description</h3>

<p>Extract the Brier score with its Confidence Interval and possibly a p-value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'BuyseTestBrier'
confint(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confint.BuyseTestBrier_+3A_object">object</code></td>
<td>
<p>object of class <code>BuyseTestBrier</code> (output of the <code>brier</code> function).</p>
</td></tr>
<tr><td><code id="confint.BuyseTestBrier_+3A_...">...</code></td>
<td>
<p>not used. For compatibility with the generic function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Estimated value for the brier score, its standard error, the lower and upper bound of the confidence interval and the p-value.
</p>

<hr>
<h2 id='constStrata'>Strata creation</h2><span id='topic+constStrata'></span>

<h3>Description</h3>

<p>Create strata from several variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>constStrata(
  data,
  strata,
  sep = ".",
  lex.order = FALSE,
  trace = TRUE,
  as.numeric = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="constStrata_+3A_data">data</code></td>
<td>
<p>[data.frame] dataset.</p>
</td></tr>
<tr><td><code id="constStrata_+3A_strata">strata</code></td>
<td>
<p>[character vector] A vector of the variables capturing the stratification factors.</p>
</td></tr>
<tr><td><code id="constStrata_+3A_sep">sep</code></td>
<td>
<p>[character] string to construct the new level labels by joining the constituent ones.</p>
</td></tr>
<tr><td><code id="constStrata_+3A_lex.order">lex.order</code></td>
<td>
<p>[logical] Should the order of factor concatenation be lexically ordered ?</p>
</td></tr>
<tr><td><code id="constStrata_+3A_trace">trace</code></td>
<td>
<p>[logical] Should the execution of the function be traced ?</p>
</td></tr>
<tr><td><code id="constStrata_+3A_as.numeric">as.numeric</code></td>
<td>
<p>[logical] Should the strata be converted from factors to numeric?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses the <code>interaction</code> function from the <em>base</em> package to form the strata.
</p>


<h3>Value</h3>

<p>A <em>factor vector</em> or a <em>numeric vector</em>.
</p>


<h3>Author(s)</h3>

<p>Brice Ozenne
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(data.table)

library(survival) ## import veteran
  
# strata with two variables : celltype and karno
veteran$strata1 &lt;- constStrata(veteran,c("celltype","karno"))
table(veteran$strata1)
  
# strata with three variables : celltype, karno and age dichotomized at 60 years
veteran$age60 &lt;- veteran$age&gt;60
veteran$age60 &lt;- factor(veteran$age60,labels=c("&lt;=60","&gt;60")) # convert to factor with labels
veteran$strata2 &lt;- constStrata(veteran,c("celltype","karno","age60"))
table(veteran$strata2) # factor strata variable 
  
veteran$strata2 &lt;- constStrata(veteran,c("celltype","karno","age60"), as.numeric=TRUE)
table(veteran$strata2) # numeric strata variable

</code></pre>

<hr>
<h2 id='getCount'>Extract the Number of Favorable, Unfavorable, Neutral, Uninformative pairs</h2><span id='topic+getCount'></span><span id='topic+S4BuyseTest-getCount'></span><span id='topic+getCount+2CS4BuyseTest-method'></span>

<h3>Description</h3>

<p>Extract the number of favorable, unfavorable, neutral, uninformative pairs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getCount(object, type)

## S4 method for signature 'S4BuyseTest'
getCount(object, type)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getCount_+3A_object">object</code></td>
<td>
<p>an <span class="rlang"><b>R</b></span> object of class <code><a href="#topic+S4BuyseTest-class">S4BuyseTest</a></code>, i.e., output of <code><a href="#topic+BuyseTest">BuyseTest</a></code></p>
</td></tr>
<tr><td><code id="getCount_+3A_type">type</code></td>
<td>
<p>the type of pairs to be counted. Can be <code>"favorable"</code>, <code>"unfavorable"</code>, <code>neutral</code>, or <code>uninf</code>. Can also be <code>"all"</code> to select all of them.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>"vector"</code> containing the number of pairs
</p>


<h3>Author(s)</h3>

<p>Brice Ozenne
</p>

<hr>
<h2 id='getIid'>Extract the H-decomposition of the Estimator</h2><span id='topic+getIid'></span><span id='topic+S4BuyseTest-getIid'></span><span id='topic+getIid+2CS4BuyseTest-method'></span>

<h3>Description</h3>

<p>Extract the H-decomposition of the GPC estimator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getIid(
  object,
  endpoint = NULL,
  statistic = NULL,
  strata = FALSE,
  cumulative = TRUE,
  center = TRUE,
  scale = TRUE,
  type = "all",
  cluster = NULL,
  simplify = FALSE
)

## S4 method for signature 'S4BuyseTest'
getIid(
  object,
  endpoint = NULL,
  statistic = NULL,
  strata = FALSE,
  cumulative = TRUE,
  center = TRUE,
  scale = TRUE,
  type = "all",
  cluster = NULL,
  simplify = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getIid_+3A_object">object</code></td>
<td>
<p>an <span class="rlang"><b>R</b></span> object of class <code><a href="#topic+S4BuyseTest-class">S4BuyseTest</a></code>, i.e., output of <code><a href="#topic+BuyseTest">BuyseTest</a></code></p>
</td></tr>
<tr><td><code id="getIid_+3A_endpoint">endpoint</code></td>
<td>
<p>[character] for which endpoint(s) the H-decomposition should be output?
If <code>NULL</code> returns the sum of the H-decomposition over all endpoints.</p>
</td></tr>
<tr><td><code id="getIid_+3A_statistic">statistic</code></td>
<td>
<p>[character] statistic relative to which the H-decomposition should be output.</p>
</td></tr>
<tr><td><code id="getIid_+3A_strata">strata</code></td>
<td>
<p>[character vector] the strata relative to which the H-decomposition of the statistic should be output.
Can also be <code>"global"</code> or <code>FALSE</code> to output the H-decompositon of the pooled statistic.
or <code>TRUE</code> to output the H-decompositon of each strata-specific statistic.</p>
</td></tr>
<tr><td><code id="getIid_+3A_cumulative">cumulative</code></td>
<td>
<p>[logical] should the H-decomposition be cumulated over endpoints?
Otherwise display the contribution of each endpoint.</p>
</td></tr>
<tr><td><code id="getIid_+3A_center">center</code></td>
<td>
<p>[logical] if <code>TRUE</code> the H-decomposition is centered around 0 (estimated statistic is substracted).</p>
</td></tr>
<tr><td><code id="getIid_+3A_scale">scale</code></td>
<td>
<p>[logical] if <code>TRUE</code> the H-decomposition is rescaled (by the sample size in the corresponding arm) such that its sums of squares approximate the variance of the estimator.</p>
</td></tr>
<tr><td><code id="getIid_+3A_type">type</code></td>
<td>
<p>[character] type of H-decomposition to be output.
Can be only for the nuisance parameters (<code>"nuisance"</code>),
or for the u-statistic given the nuisance parameters (<code>"u-statistic"</code>),
or both.</p>
</td></tr>
<tr><td><code id="getIid_+3A_cluster">cluster</code></td>
<td>
<p>[numeric vector] return the H-decomposition aggregated by cluster.</p>
</td></tr>
<tr><td><code id="getIid_+3A_simplify">simplify</code></td>
<td>
<p>[logical] should the result be coerced to the lowest possible dimension?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>WARNING: argument <code>scale</code> and <code>center</code> should be used with care as when set to <code>FALSE</code> they may not lead to a meaningful decomposition.
</p>


<h3>Value</h3>

<p>A list of matrices, each element of the list correspond to a statistic (global or strata-specific) and each matrix has as many columns as endpoints and rows as observations.
</p>


<h3>Author(s)</h3>

<p>Brice Ozenne
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BuyseTest">BuyseTest</a></code> for performing a generalized pairwise comparison. <br />
<code><a href="#topic+S4BuyseTest-summary">S4BuyseTest-summary</a></code> for a more detailed presentation of the <code>S4BuyseTest</code> object.
</p>

<hr>
<h2 id='getPairScore'>Extract the Score of Each Pair</h2><span id='topic+getPairScore'></span><span id='topic+S4BuyseTest-getPairScore'></span><span id='topic+getPairScore+2CS4BuyseTest-method'></span>

<h3>Description</h3>

<p>Extract the score of each pair.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPairScore(
  object,
  endpoint = NULL,
  strata = NULL,
  sum = FALSE,
  rm.withinStrata = TRUE,
  rm.strata = is.na(object@strata),
  rm.indexPair = TRUE,
  rm.weight = FALSE,
  rm.corrected = (object@correction.uninf == 0),
  unlist = TRUE,
  trace = 1
)

## S4 method for signature 'S4BuyseTest'
getPairScore(
  object,
  endpoint = NULL,
  strata = NULL,
  sum = FALSE,
  rm.withinStrata = TRUE,
  rm.strata = is.na(object@strata),
  rm.indexPair = TRUE,
  rm.weight = FALSE,
  rm.corrected = (object@correction.uninf == 0),
  unlist = TRUE,
  trace = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getPairScore_+3A_object">object</code></td>
<td>
<p>an <span class="rlang"><b>R</b></span> object of class <code><a href="#topic+S4BuyseTest-class">S4BuyseTest</a></code>, i.e., output of <code><a href="#topic+BuyseTest">BuyseTest</a></code></p>
</td></tr>
<tr><td><code id="getPairScore_+3A_endpoint">endpoint</code></td>
<td>
<p>[integer/character vector] the endpoint for which the scores should be output.</p>
</td></tr>
<tr><td><code id="getPairScore_+3A_strata">strata</code></td>
<td>
<p>[character vector] the strata relative to which the score should be output.</p>
</td></tr>
<tr><td><code id="getPairScore_+3A_sum">sum</code></td>
<td>
<p>[logical] should the scores be cumulated over endpoints?</p>
</td></tr>
<tr><td><code id="getPairScore_+3A_rm.withinstrata">rm.withinStrata</code></td>
<td>
<p>[logical] should the columns indicating the position of each member of the pair
within each treatment group be removed?</p>
</td></tr>
<tr><td><code id="getPairScore_+3A_rm.strata">rm.strata</code></td>
<td>
<p>[logical] should the column containing the level of the strata variable be removed from the output?</p>
</td></tr>
<tr><td><code id="getPairScore_+3A_rm.indexpair">rm.indexPair</code></td>
<td>
<p>[logical] should the column containing the number associated to each pair be removed from the output?</p>
</td></tr>
<tr><td><code id="getPairScore_+3A_rm.weight">rm.weight</code></td>
<td>
<p>[logical] should the column weight be removed from the output?</p>
</td></tr>
<tr><td><code id="getPairScore_+3A_rm.corrected">rm.corrected</code></td>
<td>
<p>[logical] should the columns corresponding to the scores after weighting be removed from the output?</p>
</td></tr>
<tr><td><code id="getPairScore_+3A_unlist">unlist</code></td>
<td>
<p>[logical] should the structure of the output be simplified when possible?</p>
</td></tr>
<tr><td><code id="getPairScore_+3A_trace">trace</code></td>
<td>
<p>[logical] should a message be printed to explain what happened
when the function returned <code>NULL</code>?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The maximal output (i.e. with all columns) contains for each endpoint, a data.table with:
</p>

<ul>
<li> <p><code>"strata"</code>: the name of the strata to which the pair belongs.
</p>
</li>
<li> <p><code>"index.T"</code>: the index of the treatment observation in the pair relative to the original dataset.
</p>
</li>
<li> <p><code>"index.C"</code>: the index of the control observation in the pair relative to the original dataset.
</p>
</li>
<li> <p><code>"indexWithinStrata.T"</code>: the index of the treatment observation in the pair relative to the treatment group and the strata.
</p>
</li>
<li> <p><code>"indexWithinStrata.C"</code>: the index of the control observation in the pair relative to the control group and the strata.
</p>
</li>
<li> <p><code>"favorable"</code>: the probability that the endpoint is better in the treatment arm vs. in the control arm.
</p>
</li>
<li> <p><code>"unfavorable"</code>: the probability that the endpoint is worse in the treatment arm vs. in the control arm.
</p>
</li>
<li> <p><code>"neutral"</code>: the probability that the endpoint is no different in the treatment arm vs. in the control arm.
</p>
</li>
<li> <p><code>"uninformative"</code>: the weight of the pair that cannot be attributed to favorable/unfavorable/neutral.
</p>
</li>
<li> <p><code>"weight"</code>: the residual weight of the pair to be analyzed at the current outcome. Each pair starts with a weight of 1.
</p>
</li>
<li> <p><code>"favorable.corrected"</code>: same as <code>"favorable"</code>  after weighting.
</p>
</li>
<li> <p><code>"unfavorable.corrected"</code>: same as <code>"favorable"</code> after weighting.
</p>
</li>
<li> <p><code>"neutral.corrected"</code>: same as <code>"favorable"</code> after weighting.
</p>
</li>
<li> <p><code>"uninformative.corrected"</code>: same as <code>"favorable"</code> after weighting.
</p>
</li></ul>

<p>Note that the <code>.T</code> and <code>.C</code> may change since they correspond of the label of the treatment and control arms.
The first weighting consists in multiplying the probability by the residual weight of the pair
(i.e. the weight of the pair that was not informative at the previous endpoint). This is always performed.
For time to event endpoint an additional weighting may be performed to avoid a possible bias in presence of censoring.
</p>


<h3>Author(s)</h3>

<p>Brice Ozenne
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(data.table)
library(prodlim)

## run BuyseTest
library(survival) ## import veteran

BT.keep &lt;- BuyseTest(trt ~ tte(time, threshold = 20, status = "status") + cont(karno),
                     data = veteran, keep.pairScore = TRUE, 
                     trace = 0, method.inference = "none")

## Extract scores
pScore &lt;- getPairScore(BT.keep, endpoint = 1)

## look at one pair
indexPair &lt;- intersect(which(pScore$index.1 == 22),
                       which(pScore$index.2 == 71))
pScore[indexPair]

## retrive pair in the original dataset
pVeteran &lt;- veteran[pScore[indexPair,c(index.1,index.2)],]
pVeteran

## the observation from the control group is censored at 97
## the observation from the treatment group has an event at 112
## since the threshold is 20, and (112-20)&lt;97
## we know that the pair is not in favor of the treatment

## the formula for probability in favor of the control is
## Sc(97)/Sc(112+20)
## where Sc(t) is the survival at time t in the control arm.

## we first estimate the survival in each arm
e.KM &lt;- prodlim(Hist(time,status)~trt, data = veteran)

## and compute the survival
iSurv &lt;- predict(e.KM, times =  c(97,112+20),
                 newdata = data.frame(trt = 1, stringsAsFactors = FALSE))[[1]]

## the probability in favor of the control is then
pUF &lt;- iSurv[2]/iSurv[1]
pUF
## and the complement to one of that is the probability of being neutral
pN &lt;- 1 - pUF
pN

if(require(testthat)){
   testthat::expect_equal(pUF, pScore[indexPair, unfavorable])
   testthat::expect_equal(pN, pScore[indexPair, neutral])
}
</code></pre>

<hr>
<h2 id='getPseudovalue'>Extract the pseudovalues of the Estimator</h2><span id='topic+getPseudovalue'></span><span id='topic+S4BuyseTest-getPseudovalue'></span><span id='topic+getPseudovalue+2CS4BuyseTest-method'></span>

<h3>Description</h3>

<p>Extract the pseudovalues of the estimator.
The average of the pseudovalues is the estimate and their standard deviation the standard error of the estimate times a factor n
(i.e. a t-test on their mean will give asymptotically valid confidence intervals and p-values).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPseudovalue(object, statistic = NULL, endpoint = NULL)

## S4 method for signature 'S4BuyseTest'
getPseudovalue(object, statistic = NULL, endpoint = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getPseudovalue_+3A_object">object</code></td>
<td>
<p>an <span class="rlang"><b>R</b></span> object of class <code><a href="#topic+S4BuyseTest-class">S4BuyseTest</a></code>, i.e., output of <code><a href="#topic+BuyseTest">BuyseTest</a></code></p>
</td></tr>
<tr><td><code id="getPseudovalue_+3A_statistic">statistic</code></td>
<td>
<p>[character] the type of statistic relative to which the pseudovalues should be computed.
Can be <code>"netBenefit"</code>, <code>"winRatio"</code>, <code>"favorable"</code>, or <code>"unfavorable"</code>.</p>
</td></tr>
<tr><td><code id="getPseudovalue_+3A_endpoint">endpoint</code></td>
<td>
<p>[character] for which endpoint(s) the pseudovalues should be output?
If <code>NULL</code> returns the sum of the H-decomposition over all endpoints.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Brice Ozenne
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BuyseTest">BuyseTest</a></code> for performing a generalized pairwise comparison. <br />
<code><a href="#topic+S4BuyseTest-summary">S4BuyseTest-summary</a></code> for a more detailed presentation of the <code>S4BuyseTest</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(10)
n &lt;- 250
d &lt;- simBuyseTest(n)

e.BT &lt;- BuyseTest(treatment ~ tte(eventtime,status,2) + bin(toxicity),
                 data = d, trace = 0)

#### net Benefit
pseudo &lt;- getPseudovalue(e.BT)
summary(lm(pseudo~1))$coef
## asymptotically equivalent to
confint(e.BT, transformation = TRUE)
## (small differences: small sample corrections)

summary(lm(getPseudovalue(e.BT, endpoint = 1)~1))$coef

#### win Ratio
pseudo &lt;- getPseudovalue(e.BT, statistic = "winRatio")
summary(lm(pseudo~1))$coef ## wrong p-value (should compare to 1 instead of 0)
## asymptotically equivalent to
confint(e.BT, statistic = "winRatio", transformation = TRUE)

#### favorable
pseudo &lt;- getPseudovalue(e.BT, statistic = "favorable")
summary(lm(pseudo~1))$coef ## wrong p-value (should compare to 1/2 instead of 0)
## asymptotically equivalent to
confint(e.BT, statistic = "favorable", transformation = TRUE)

#### unfavorable
pseudo &lt;- getPseudovalue(e.BT, statistic = "unfavorable")
summary(lm(pseudo~1))$coef ## wrong p-value (should compare to 1/2 instead of 0)
## asymptotically equivalent to
confint(e.BT, statistic = "unfavorable", transformation = TRUE)
</code></pre>

<hr>
<h2 id='getSurvival'>Extract the Survival and Survival Jumps</h2><span id='topic+getSurvival'></span><span id='topic+S4BuyseTest-getSurvival'></span><span id='topic+getSurvival+2CS4BuyseTest-method'></span>

<h3>Description</h3>

<p>Extract the survival and survival jumps.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getSurvival(
  object,
  type = NULL,
  endpoint = NULL,
  strata = NULL,
  unlist = TRUE,
  trace = TRUE
)

## S4 method for signature 'S4BuyseTest'
getSurvival(
  object,
  type = NULL,
  endpoint = NULL,
  strata = NULL,
  unlist = TRUE,
  trace = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getSurvival_+3A_object">object</code></td>
<td>
<p>an <span class="rlang"><b>R</b></span> object of class <code><a href="#topic+S4BuyseTest-class">S4BuyseTest</a></code>, i.e., output of <code><a href="#topic+BuyseTest">BuyseTest</a></code></p>
</td></tr>
<tr><td><code id="getSurvival_+3A_type">type</code></td>
<td>
<p>[character vector] the type of survival to be output. See details.</p>
</td></tr>
<tr><td><code id="getSurvival_+3A_endpoint">endpoint</code></td>
<td>
<p>[integer/character vector] the endpoint for which the survival should be output.</p>
</td></tr>
<tr><td><code id="getSurvival_+3A_strata">strata</code></td>
<td>
<p>[integer/character vector] the strata relative to which the survival should be output.</p>
</td></tr>
<tr><td><code id="getSurvival_+3A_unlist">unlist</code></td>
<td>
<p>[logical] should the structure of the output be simplified when possible.</p>
</td></tr>
<tr><td><code id="getSurvival_+3A_trace">trace</code></td>
<td>
<p>[logical] should a message be printed to explain what happened
when the function returned <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The argument <code>type</code> can take any of the following values:
</p>

<ul>
<li> <p><code>"survTimeC"</code>: survival at the event times for the observations of the control arm.
</p>
</li>
<li> <p><code>"survTimeT"</code>: survival at the event times for the observations of the treatment arm.
</p>
</li>
<li> <p><code>"survJumpC"</code>: survival at the jump times for the survival model in the control arm.
</p>
</li>
<li> <p><code>"survJumpT"</code>: survival at the time times for the survival model in the treatment arm.
</p>
</li>
<li> <p><code>"lastSurv"</code>: survival at the last event time.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Brice Ozenne
</p>

<hr>
<h2 id='GPC_cpp'>C++ function performing the pairwise comparison over several endpoints.</h2><span id='topic+GPC_cpp'></span><span id='topic+GPC2_cpp'></span>

<h3>Description</h3>

<p><code>GPC_cpp</code> call for each endpoint and each strata the pairwise comparison function suited to the type of endpoint and store the results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GPC_cpp(
  endpoint,
  status,
  indexC,
  posC,
  indexT,
  posT,
  threshold,
  restriction,
  weightEndpoint,
  weightObs,
  method,
  pool,
  op,
  D,
  D_UTTE,
  n_strata,
  nUTTE_analyzedPeron_M1,
  index_endpoint,
  index_status,
  index_UTTE,
  list_survTimeC,
  list_survTimeT,
  list_survJumpC,
  list_survJumpT,
  list_lastSurv,
  p_C,
  p_T,
  iid_survJumpC,
  iid_survJumpT,
  zeroPlus,
  correctionUninf,
  hierarchical,
  hprojection,
  neutralAsUninf,
  addHalfNeutral,
  keepScore,
  precompute,
  paired,
  returnIID,
  debug
)

GPC2_cpp(
  endpoint,
  status,
  indexC,
  posC,
  indexT,
  posT,
  threshold,
  restriction,
  weightEndpoint,
  weightObs,
  method,
  pool,
  op,
  D,
  D_UTTE,
  n_strata,
  nUTTE_analyzedPeron_M1,
  index_endpoint,
  index_status,
  index_UTTE,
  list_survTimeC,
  list_survTimeT,
  list_survJumpC,
  list_survJumpT,
  list_lastSurv,
  p_C,
  p_T,
  iid_survJumpC,
  iid_survJumpT,
  zeroPlus,
  correctionUninf,
  hierarchical,
  hprojection,
  neutralAsUninf,
  addHalfNeutral,
  keepScore,
  precompute,
  paired,
  returnIID,
  debug
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GPC_cpp_+3A_endpoint">endpoint</code></td>
<td>
<p>A matrix containing the values of each endpoint (in columns) for each observation (in rows).</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_status">status</code></td>
<td>
<p>A matrix containing the values of the status variables relative to each endpoint (in columns) for each observation (in rows).</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_indexc">indexC</code></td>
<td>
<p>A list containing, for each strata, which rows of the endpoint and status matrices corresponds to the control observations. Not unique when bootstraping.</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_posc">posC</code></td>
<td>
<p>A list containing, for each strata, the unique identifier of each control observations.</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_indext">indexT</code></td>
<td>
<p>A list containing, for each strata, which rows of the endpoint and status matrices corresponds to the treatment observations. Not unique when bootstraping.</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_post">posT</code></td>
<td>
<p>A list containing, for each strata, the unique identifier of each treatment observations.</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_threshold">threshold</code></td>
<td>
<p>Store the thresholds associated to each endpoint. Must have length D. The threshold is ignored for binary endpoints.</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_restriction">restriction</code></td>
<td>
<p>Store the restriction time associated to each endpoint. Must have length D.</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_weightendpoint">weightEndpoint</code></td>
<td>
<p>Store the weight associated to each endpoint. Must have length D.</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_weightobs">weightObs</code></td>
<td>
<p>A vector containing the weight associated to each observation.</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_method">method</code></td>
<td>
<p>The index of the method used to score the pairs. Must have length D. 1 for binary/continuous, 2 for Gaussian, 3/4 for Gehan (left or right-censoring), and 5/6 for Peron (right-censoring survival or competing risks).</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_pool">pool</code></td>
<td>
<p>The index of the method used to pool results across strata. Can be 0 (weight inversely proportional to the sample size), 1 (Mantel Haenszel weights), 2 (equal weights), 3 (precision weights)</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_op">op</code></td>
<td>
<p>The index of the operator used to score the pairs. Must have length D. 1 for larger is beter, -1 for smaller is better.</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_d">D</code></td>
<td>
<p>The number of endpoints.</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_d_utte">D_UTTE</code></td>
<td>
<p>The number of distinct time to event endpoints.</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_n_strata">n_strata</code></td>
<td>
<p>The number of strata.</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_nutte_analyzedperon_m1">nUTTE_analyzedPeron_M1</code></td>
<td>
<p>The number of unique time-to-event endpoints that have been analyzed the Peron scoring rule before the current endpoint. Must have length D.</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_index_endpoint">index_endpoint</code></td>
<td>
<p>The position of the endpoint at each priority in the argument endpoint. Must have length D.</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_index_status">index_status</code></td>
<td>
<p>The position of the status at each priority in the argument status. Must have length D.</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_index_utte">index_UTTE</code></td>
<td>
<p>The position, among all the unique tte endpoints, of the TTE endpoints. Equals -1 for non tte endpoints. Must have length n_TTE.</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_list_survtimec">list_survTimeC</code></td>
<td>
<p>A list of matrix containing the survival estimates (-threshold, 0, +threshold ...) for each event of the control group (in rows).</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_list_survtimet">list_survTimeT</code></td>
<td>
<p>A list of matrix containing the survival estimates (-threshold, 0, +threshold ...) for each event of the treatment group (in rows).</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_list_survjumpc">list_survJumpC</code></td>
<td>
<p>A list of matrix containing the survival estimates and survival jumps when the survival for the control arm jumps.</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_list_survjumpt">list_survJumpT</code></td>
<td>
<p>A list of matrix containing the survival estimates and survival jumps when the survival for the treatment arm jumps.</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_list_lastsurv">list_lastSurv</code></td>
<td>
<p>A list of matrix containing the last survival estimate in each strata (rows) and treatment group (columns).</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_p_c">p_C</code></td>
<td>
<p>Number of nuisance parameter in the survival model for the control group, for each endpoint and strata</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_p_t">p_T</code></td>
<td>
<p>Number of nuisance parameter in the survival model for the treatment group, for each endpoint and strata</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_iid_survjumpc">iid_survJumpC</code></td>
<td>
<p>A list of matrix containing the iid of the survival estimates in the control group.</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_iid_survjumpt">iid_survJumpT</code></td>
<td>
<p>A list of matrix containing the iid of the survival estimates in the treatment group.</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_zeroplus">zeroPlus</code></td>
<td>
<p>Value under which doubles are considered 0?</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_correctionuninf">correctionUninf</code></td>
<td>
<p>Should the uninformative weight be re-distributed to favorable and unfavorable?</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_hierarchical">hierarchical</code></td>
<td>
<p>Should only the uninformative pairs be analyzed at the lower priority endpoints (hierarchical GPC)? Otherwise all pairs will be compaired for all endpoint (full GPC).</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_hprojection">hprojection</code></td>
<td>
<p>Order of the H-projection used to compute the variance.</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_neutralasuninf">neutralAsUninf</code></td>
<td>
<p>Should paired classified as neutral be re-analyzed using endpoints of lower priority?</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_addhalfneutral">addHalfNeutral</code></td>
<td>
<p>Should half of the neutral score be added to the favorable and unfavorable scores?</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_keepscore">keepScore</code></td>
<td>
<p>Should the result of each pairwise comparison be kept?</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_precompute">precompute</code></td>
<td>
<p>Have the integrals relative to the survival be already computed and stored in list_survTimeC/list_survTimeT and list_survJumpC/list_survJumpT (derivatives)</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_paired">paired</code></td>
<td>
<p>In case of paired data, the variance of the summary statistic across strata will be added to the variance of the pooled statistic.</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_returniid">returnIID</code></td>
<td>
<p>Should the iid be computed? Second element: is there any nuisance parameter?</p>
</td></tr>
<tr><td><code id="GPC_cpp_+3A_debug">debug</code></td>
<td>
<p>Print messages tracing the execution of the function to help debugging. The amount of messages increase with the value of debug (0-5).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>GPC_cpp implements GPC looping first over endpoints and then over pairs.
To handle multiple endpoints, it stores some of the results which can be memory demanding when considering large sample - especially when computing the iid decomposition.
GPC2_cpp implements GPC looping first over pairs and then over endpoints. It has rather minimal memory requirement but does not handle correction for uninformative pairs.
</p>


<h3>Author(s)</h3>

<p>Brice Ozenne
</p>

<hr>
<h2 id='iid.BuyseTestAuc'>Extract the idd Decomposition for the AUC</h2><span id='topic+iid.BuyseTestAuc'></span>

<h3>Description</h3>

<p>Extract the iid decompotion relative to AUC estimate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'BuyseTestAuc'
iid(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="iid.BuyseTestAuc_+3A_x">x</code></td>
<td>
<p>object of class <code>BuyseTestAUC</code> (output of the <code>auc</code> function).</p>
</td></tr>
<tr><td><code id="iid.BuyseTestAuc_+3A_...">...</code></td>
<td>
<p>not used. For compatibility with the generic function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A column vector.
</p>

<hr>
<h2 id='iid.BuyseTestBrier'>Extract the idd Decomposition for the Brier Score</h2><span id='topic+iid.BuyseTestBrier'></span>

<h3>Description</h3>

<p>Extract the iid decompotion relative to Brier score estimate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'BuyseTestBrier'
iid(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="iid.BuyseTestBrier_+3A_x">x</code></td>
<td>
<p>object of class <code>BuyseTestBrier</code> (output of the <code>brier</code> function).</p>
</td></tr>
<tr><td><code id="iid.BuyseTestBrier_+3A_...">...</code></td>
<td>
<p>not used. For compatibility with the generic function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A column vector.
</p>

<hr>
<h2 id='iid.prodlim'>Extract i.i.d. decomposition from a prodlim model</h2><span id='topic+iid.prodlim'></span>

<h3>Description</h3>

<p>Compute the influence function for each observation used to estimate the model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'prodlim'
iid(x, add0 = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="iid.prodlim_+3A_x">x</code></td>
<td>
<p>A prodlim object.</p>
</td></tr>
<tr><td><code id="iid.prodlim_+3A_add0">add0</code></td>
<td>
<p>[logical] add the 0 to vector of relevant times.</p>
</td></tr>
<tr><td><code id="iid.prodlim_+3A_...">...</code></td>
<td>
<p>not used. For compatibility with the generic method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a simplified version of the iidCox function of the riskRegression package.
Formula for the influence function can be found in (Ozenne et al., 2017).
</p>


<h3>Value</h3>

<p>A list containing:
</p>

<ul>
<li><p> IFbeta: Influence function for the regression coefficient.
</p>
</li>
<li><p> IFhazard: Time differential of the influence function of the hazard.
</p>
</li>
<li><p> IFcumhazard: Influence function of the cumulative hazard.
</p>
</li>
<li><p> time: Times at which the influence function has been evaluated.
</p>
</li>
<li><p> etime.max: Last observation time (i.e. jump or censoring) in each strata.
</p>
</li>
<li><p> label.strata: Strata to which each observation belong.
</p>
</li>
<li><p> X: Design matrix.
</p>
</li>
<li><p> table: Hazard at each time for each strata.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Brice Ozenne
</p>


<h3>References</h3>

<p>Brice Ozenne, Anne Lyngholm Sorensen, Thomas Scheike, Christian Torp-Pedersen and Thomas Alexander Gerds.
riskRegression: Predicting the Risk of an Event using Cox Regression Models.
The R Journal (2017) 9:2, pages 440-460.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(data.table)
library(prodlim)

set.seed(10)
dt &lt;- simBuyseTest(10)
setkeyv(dt, "treatment")

e.KM &lt;- prodlim(Hist(eventtime,status)~treatment, data = dt)
lava::iid(e.KM)
</code></pre>

<hr>
<h2 id='performance'>Assess Performance of a Classifier</h2><span id='topic+performance'></span>

<h3>Description</h3>

<p>Assess the performance in term of AUC and brier score of one or several binary classifiers.
Currently limited to logistic regressions and random forest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>performance(
  object,
  data = NULL,
  newdata = NA,
  individual.fit = FALSE,
  impute = "none",
  name.response = NULL,
  fold.size = 1/10,
  fold.repetition = 0,
  fold.balance = FALSE,
  null = c(brier = NA, AUC = 0.5),
  conf.level = 0.95,
  se = TRUE,
  transformation = TRUE,
  auc.type = "classical",
  simplify = TRUE,
  trace = TRUE,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="performance_+3A_object">object</code></td>
<td>
<p>a <code>glm</code> or <code>range</code> object, or a list of such object.</p>
</td></tr>
<tr><td><code id="performance_+3A_data">data</code></td>
<td>
<p>[data.frame] the training data.</p>
</td></tr>
<tr><td><code id="performance_+3A_newdata">newdata</code></td>
<td>
<p>[data.frame] an external data used to assess the performance.</p>
</td></tr>
<tr><td><code id="performance_+3A_individual.fit">individual.fit</code></td>
<td>
<p>[logical] if <code>TRUE</code> the predictive model is refit for each individual using only the predictors with non missing values.</p>
</td></tr>
<tr><td><code id="performance_+3A_impute">impute</code></td>
<td>
<p>[character] in presence of missing value in the regressors of the training dataset, should a complete case analysis be performed (<code>"none"</code>)
or should the median/mean (<code>"median"</code>/<code>"mean"</code>) value be imputed. For categorical variables, the most frequent value is imputed.</p>
</td></tr>
<tr><td><code id="performance_+3A_name.response">name.response</code></td>
<td>
<p>[character] the name of the response variable (i.e. the one containing the categories).</p>
</td></tr>
<tr><td><code id="performance_+3A_fold.size">fold.size</code></td>
<td>
<p>[double, &gt;0] either the size of the test dataset (when &gt;1) or the fraction of the dataset (when &lt;1) to be used for testing when using cross-validation.</p>
</td></tr>
<tr><td><code id="performance_+3A_fold.repetition">fold.repetition</code></td>
<td>
<p>[integer] when strictly positive, the number of folds used in the cross-validation. If 0 then no cross validation is performed.</p>
</td></tr>
<tr><td><code id="performance_+3A_fold.balance">fold.balance</code></td>
<td>
<p>[logical] should the outcome distribution in the folds of the cross-validation be similar to the one of the original dataset?</p>
</td></tr>
<tr><td><code id="performance_+3A_null">null</code></td>
<td>
<p>[numeric vector of length 2] the right-hand side of the null hypothesis relative to each metric.</p>
</td></tr>
<tr><td><code id="performance_+3A_conf.level">conf.level</code></td>
<td>
<p>[numeric] confidence level for the confidence intervals.</p>
</td></tr>
<tr><td><code id="performance_+3A_se">se</code></td>
<td>
<p>[logical] should the uncertainty about AUC/brier be computed?
When <code>TRUE</code> adapt the method of LeDell et al. (2015) to repeated cross-validation for the AUC and the brier score.</p>
</td></tr>
<tr><td><code id="performance_+3A_transformation">transformation</code></td>
<td>
<p>[logical]  should the CI be computed on the logit scale / log scale for the net benefit / win ratio and backtransformed.
Otherwise they are computed without any transformation.</p>
</td></tr>
<tr><td><code id="performance_+3A_auc.type">auc.type</code></td>
<td>
<p>[character] should the auc be computed approximating the predicted probability by a dirac (<code>"classical"</code>, usual AUC formula)
or approximating the predicted probability by a normal distribution.</p>
</td></tr>
<tr><td><code id="performance_+3A_simplify">simplify</code></td>
<td>
<p>[logical] should the number of fold and the size of the fold used for the cross validation be removed from the output?</p>
</td></tr>
<tr><td><code id="performance_+3A_trace">trace</code></td>
<td>
<p>[logical] Should the execution of the function be traced.</p>
</td></tr>
<tr><td><code id="performance_+3A_seed">seed</code></td>
<td>
<p>[integer, &gt;0] Random number generator (RNG) state used when starting data spliting.
If <code>NULL</code> no state is set.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An S3 object of class <code>performance</code>.
</p>


<h3>References</h3>

<p>LeDell E, Petersen M, van der Laan M. Computationally efficient confidence intervals for cross-validated area under the ROC curve estimates. Electron J Stat. 2015;9(1):1583-1607. doi:10.1214/15-EJS1035
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simulate data
set.seed(10)
n &lt;- 100
df.train &lt;- data.frame(Y = rbinom(n, prob = 0.5, size = 1), X1 = rnorm(n), X2 = rnorm(n))
df.test &lt;- data.frame(Y = rbinom(n, prob = 0.5, size = 1), X1 = rnorm(n), X2 = rnorm(n))

## fit logistic model
e.null &lt;- glm(Y~1, data = df.train, family = binomial(link="logit"))
e.logit1 &lt;- glm(Y~X1, data = df.train, family = binomial(link="logit"))
e.logit2 &lt;- glm(Y~X1+X2, data = df.train, family = binomial(link="logit"))

## assess performance on the training set (biased)
## and external dataset
performance(e.logit1, newdata = df.test)
e.perf &lt;- performance(list(null = e.null, p1 = e.logit1, p2 = e.logit2),
                      newdata = df.test)
e.perf
summary(e.perf, order.model = c("null","p2","p1"))

## assess performance using cross validation
## Not run: 
set.seed(10)
performance(e.logit1, fold.repetition = 10, se = FALSE)
set.seed(10)
performance(list(null = e.null, prop = e.logit1), fold.repetition = 10)
performance(e.logit1, fold.repetition = c(50,20,10))

## End(Not run)
</code></pre>

<hr>
<h2 id='performanceResample'>Uncertainty About Performance of a Classifier (EXPERIMENTAL)</h2><span id='topic+performanceResample'></span>

<h3>Description</h3>

<p>Use resampling to quantify uncertainties about the performance of one or several binary classifiers evaluated via cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>performanceResample(
  object,
  data = NULL,
  name.response = NULL,
  type.resampling = "permutation",
  n.resampling = 1000,
  fold.repetition = 0,
  conf.level = 0.95,
  cpus = 1,
  seed = NULL,
  trace = TRUE,
  filename = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="performanceResample_+3A_object">object</code></td>
<td>
<p>a <code>glm</code> or <code>range</code> object, or a list of such object.</p>
</td></tr>
<tr><td><code id="performanceResample_+3A_data">data</code></td>
<td>
<p>[data.frame] the training data.</p>
</td></tr>
<tr><td><code id="performanceResample_+3A_name.response">name.response</code></td>
<td>
<p>[character] The name of the response variable (i.e. the one containing the categories).</p>
</td></tr>
<tr><td><code id="performanceResample_+3A_type.resampling">type.resampling</code></td>
<td>
<p>[character] Should non-parametric bootstrap (<code>"bootstrap"</code>) or permutation of the outcome (<code>"permutation"</code>) be used.</p>
</td></tr>
<tr><td><code id="performanceResample_+3A_n.resampling">n.resampling</code></td>
<td>
<p>[integer,&gt;0] Number of bootstrap samples or permutations.</p>
</td></tr>
<tr><td><code id="performanceResample_+3A_fold.repetition">fold.repetition</code></td>
<td>
<p>[integer,&gt;0] Nnumber of folds used in the cross-validation. Should be strictly positive.</p>
</td></tr>
<tr><td><code id="performanceResample_+3A_conf.level">conf.level</code></td>
<td>
<p>[numeric, 0-1] confidence level for the confidence intervals.</p>
</td></tr>
<tr><td><code id="performanceResample_+3A_cpus">cpus</code></td>
<td>
<p>[integer, &gt;0] the number of CPU to use. If strictly greater than 1, resampling is perform in parallel.</p>
</td></tr>
<tr><td><code id="performanceResample_+3A_seed">seed</code></td>
<td>
<p>[integer, &gt;0] Random number generator (RNG) state used when starting resampling.
If <code>NULL</code> no state is set.</p>
</td></tr>
<tr><td><code id="performanceResample_+3A_trace">trace</code></td>
<td>
<p>[logical] Should the execution of the function be traced.</p>
</td></tr>
<tr><td><code id="performanceResample_+3A_filename">filename</code></td>
<td>
<p>[character] Prefix for the files containing each result.</p>
</td></tr>
<tr><td><code id="performanceResample_+3A_...">...</code></td>
<td>
<p>arguments passed to <code><a href="#topic+performance">performance</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>WARNING: using bootstrap after cross-validation may not provide valid variance/CI/p-value estimates.
</p>


<h3>Value</h3>

<p>An S3 object of class <code>performance</code>.
</p>

<hr>
<h2 id='plot.S3sensitivity'>Graphical Display for Sensitivity Analysis</h2><span id='topic+plot.S3sensitivity'></span><span id='topic+autoplot.S3sensitivity'></span>

<h3>Description</h3>

<p>Display the statistic of interest across various threshold values, possibly with confidence intervals.
Currently only works when varying thresholds relative to one or two variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'S3sensitivity'
plot(x, plot = TRUE, ...)

## S3 method for class 'S3sensitivity'
autoplot(
  object,
  col = NULL,
  ci = TRUE,
  band = TRUE,
  label = "Threshold for",
  position = NULL,
  size.line = 1,
  size.point = 1.75,
  size.ci = 0.5,
  alpha = 0.1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.S3sensitivity_+3A_plot">plot</code></td>
<td>
<p>[logical] should the graph be displayed in a graphical window</p>
</td></tr>
<tr><td><code id="plot.S3sensitivity_+3A_...">...</code></td>
<td>
<p>not used. For compatibility with the generic method.</p>
</td></tr>
<tr><td><code id="plot.S3sensitivity_+3A_object">object</code>, <code id="plot.S3sensitivity_+3A_x">x</code></td>
<td>
<p>output of the sensitivity method</p>
</td></tr>
<tr><td><code id="plot.S3sensitivity_+3A_col">col</code></td>
<td>
<p>[character vector] color used to identify the thresholds relative to a second variable.</p>
</td></tr>
<tr><td><code id="plot.S3sensitivity_+3A_ci">ci</code></td>
<td>
<p>[logical] should the confidence intervals be displayed?</p>
</td></tr>
<tr><td><code id="plot.S3sensitivity_+3A_band">band</code></td>
<td>
<p>[logical] should the simulatenous confidence intervals be displayed?</p>
</td></tr>
<tr><td><code id="plot.S3sensitivity_+3A_label">label</code></td>
<td>
<p>[character] text used before the name of the variables in the legend.</p>
</td></tr>
<tr><td><code id="plot.S3sensitivity_+3A_position">position</code></td>
<td>
<p>relative position of the error bars for a given x value. Can for instance be <code>position_dodge(width = 5)</code>.</p>
</td></tr>
<tr><td><code id="plot.S3sensitivity_+3A_size.line">size.line</code></td>
<td>
<p>[numeric] width of the line connecting the point estimates.</p>
</td></tr>
<tr><td><code id="plot.S3sensitivity_+3A_size.point">size.point</code></td>
<td>
<p>[numeric] size of the point representing the point estimates.</p>
</td></tr>
<tr><td><code id="plot.S3sensitivity_+3A_size.ci">size.ci</code></td>
<td>
<p>[numeric] width of the lines representing the confidence intervals.</p>
</td></tr>
<tr><td><code id="plot.S3sensitivity_+3A_alpha">alpha</code></td>
<td>
<p>[numeric] transparency for the area representing the simultaneous confidence intervals.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>autoplot</code> and <code>plot</code> methods are very similar. The main difference is that the former returns a ggplot2 object whereas the later automatically display the figure in a graphical window and returns an (invible) list with the plot and the data.
</p>


<h3>Value</h3>

<p>a ggplot2 object
</p>

<hr>
<h2 id='powerBuyseTest'>Performing simulation studies with BuyseTest</h2><span id='topic+powerBuyseTest'></span>

<h3>Description</h3>

<p>Performs a simulation studies for several sample sizes.
Returns estimates, their standard deviation, the average estimated standard error, and the rejection rate.
Can also be use for power calculation or to approximate the sample size needed to reach a specific power.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>powerBuyseTest(
  sim,
  sample.size,
  n.rep = c(1000, 10),
  null = c(netBenefit = 0),
  cpus = 1,
  export.cpus = NULL,
  seed = NULL,
  conf.level = NULL,
  power = NULL,
  max.sample.size = 2000,
  alternative = NULL,
  order.Hprojection = NULL,
  transformation = NULL,
  trace = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="powerBuyseTest_+3A_sim">sim</code></td>
<td>
<p>[function] take two arguments:
the sample size in the control group (<code>n.C</code>) and the sample size in the treatment group (<code>n.C</code>)
and generate datasets. The datasets must be data.frame objects or inherits from data.frame.</p>
</td></tr>
<tr><td><code id="powerBuyseTest_+3A_sample.size">sample.size</code></td>
<td>
<p>[integer vector or matrix, &gt;0] the group specific sample sizes relative to which the simulations should be perform.
When a vector, the same sample size is used for each group. Alternatively can be a matrix with two columns, one for each group (respectively T and C).</p>
</td></tr>
<tr><td><code id="powerBuyseTest_+3A_n.rep">n.rep</code></td>
<td>
<p>[integer, &gt;0] the number of simulations.
When specifying the power instead of the sample size, should be a vector of length 2 where the second element indicates the number of simulations used to identify the sample size.</p>
</td></tr>
<tr><td><code id="powerBuyseTest_+3A_null">null</code></td>
<td>
<p>[numeric vector] For each statistic of interest, the null hypothesis to be tested.
The vector should be named with the names of the statistics.</p>
</td></tr>
<tr><td><code id="powerBuyseTest_+3A_cpus">cpus</code></td>
<td>
<p>[integer, &gt;0] the number of CPU to use. Default value is 1.</p>
</td></tr>
<tr><td><code id="powerBuyseTest_+3A_export.cpus">export.cpus</code></td>
<td>
<p>[character vector] name of the variables to export to each cluster.</p>
</td></tr>
<tr><td><code id="powerBuyseTest_+3A_seed">seed</code></td>
<td>
<p>[integer, &gt;0] Random number generator (RNG) state used when starting the simulation study.
If <code>NULL</code> no state is set.</p>
</td></tr>
<tr><td><code id="powerBuyseTest_+3A_conf.level">conf.level</code></td>
<td>
<p>[numeric, 0-1] type 1 error level.
Default value read from <code>BuyseTest.options()</code>.</p>
</td></tr>
<tr><td><code id="powerBuyseTest_+3A_power">power</code></td>
<td>
<p>[numeric, 0-1] type 2 error level used to determine the sample size. Only relevant when <code>sample.size</code> is not given. See details.</p>
</td></tr>
<tr><td><code id="powerBuyseTest_+3A_max.sample.size">max.sample.size</code></td>
<td>
<p>[interger, 0-1] sample size used to approximate the sample size achieving the requested type 1 and type 2 error (see details).
Can have length 2 to indicate the sample in each group (respectively T and C) when the groups have unequal sample size.</p>
</td></tr>
<tr><td><code id="powerBuyseTest_+3A_alternative">alternative</code></td>
<td>
<p>[character] the type of alternative hypothesis: <code>"two.sided"</code>, <code>"greater"</code>, or <code>"less"</code>.
Default value read from <code>BuyseTest.options()</code>.</p>
</td></tr>
<tr><td><code id="powerBuyseTest_+3A_order.hprojection">order.Hprojection</code></td>
<td>
<p>[integer 1,2] the order of the H-project to be used to compute the variance of the net benefit/win ratio.
Default value read from <code>BuyseTest.options()</code>.</p>
</td></tr>
<tr><td><code id="powerBuyseTest_+3A_transformation">transformation</code></td>
<td>
<p>[logical] should the CI be computed on the logit scale / log scale for the net benefit / win ratio and backtransformed.
Otherwise they are computed without any transformation.
Default value read from <code>BuyseTest.options()</code>.</p>
</td></tr>
<tr><td><code id="powerBuyseTest_+3A_trace">trace</code></td>
<td>
<p>[integer] should the execution of the function be traced?</p>
</td></tr>
<tr><td><code id="powerBuyseTest_+3A_...">...</code></td>
<td>
<p>other arguments (e.g. <code>scoring.rule</code>, <code>method.inference</code>) to be passed to <code>initializeArgs</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>Sample size calculation</b>: to approximate the sample size achieving the requested type 1 (<code class="reqn">\alpha</code>) and type 2 error (<code class="reqn">\beta</code>),
GPC are applied on a large sample (as defined by the argument <code>max.sample.size</code>): <code class="reqn">N^*=m^*+n^*</code> where <code class="reqn">m^*</code> is the sample size in the control group and <code class="reqn">n^*</code> is the sample size in the active group.
Then the effect (<code class="reqn">\delta</code>) and the asymptotic variance of the estimator (<code class="reqn">\sigma^2</code>) are estimated. The total sample size is then deduced as (two-sided case):
</p>
<p style="text-align: center;"><code class="reqn">\hat{N} = \hat{\sigma}^2\frac{(u_{1-\alpha/2}+u_{1-\beta})^2}{\hat{\delta}^2}</code>
</p>
<p> from which the group specific sample sizes are deduced: <code class="reqn">\hat{m}=\hat{N}\frac{m^*}{N^*}</code> and <code class="reqn">\hat{n}=\hat{N}\frac{n^*}{N^*}</code>. Here <code class="reqn">u_x</code> denotes the x-quantile of the normal distribution. <br />
This approximation can be improved by increasing the sample size (argument <code>max.sample.size</code>) and/or by performing it multiple times based on a different dataset and average estimated sample size per group (second element of argument <code>n.rep</code>). <br />
To evaluate the approximation, a simulation study is then performed with the estimated sample size. It will not exactly match the requested power but should provide a reasonnable guess which can be refined with further simulation studies. The larger the sample size (and/or number of CPUs) the more accurate the approximation.
</p>
<p><b>seed</b>: the seed is used to generate one seed per simulation. These simulation seeds are the same whether one or several CPUs are used.
</p>


<h3>Value</h3>

<p>An S4 object of class  <code><a href="#topic+S4BuysePower-class">S4BuysePower</a></code>.
</p>


<h3>Author(s)</h3>

<p>Brice Ozenne
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(data.table)

#### Using simBuyseTest ####
## only point estimate
## Not run: 
pBT &lt;- powerBuyseTest(sim = simBuyseTest, sample.size = c(10, 25, 50, 75, 100), 
                  formula = treatment ~ bin(toxicity), seed = 10, n.rep = 1000,
                  method.inference = "none", keep.pairScore = FALSE, cpus = 5)
summary(pBT)
model.tables(pBT)

## End(Not run)

## point estimate with rejection rate

## Not run: 
powerBuyseTest(sim = simBuyseTest, sample.size = c(10, 50, 100), 
               formula = treatment ~ bin(toxicity), seed = 10, n.rep = 1000,
               method.inference = "u-statistic", trace = 4)

## End(Not run)

#### Using user defined simulation function ####
## power calculation for Wilcoxon test
simFCT &lt;- function(n.C, n.T){
    out &lt;- rbind(cbind(Y=stats::rt(n.C, df = 5), group=0),
                 cbind(Y=stats::rt(n.T, df = 5), group=1) + 1)
    return(data.table::as.data.table(out))
}
simFCT2 &lt;- function(n.C, n.T){
    out &lt;- rbind(cbind(Y=stats::rt(n.C, df = 5), group=0),
                 cbind(Y=stats::rt(n.T, df = 5), group=1) + 0.25)
    return(data.table::as.data.table(out))
}


## Not run: 
powerW &lt;- powerBuyseTest(sim = simFCT, sample.size = c(5,10,20,30,50,100),
                         n.rep = 1000, formula = group ~ cont(Y), cpus = "all")
summary(powerW)

## End(Not run) 

## sample size needed to reach (approximately) a power
## based on summary statistics obtained on a large sample 
## Not run: 
sampleW &lt;- powerBuyseTest(sim = simFCT, power = 0.8, formula = group ~ cont(Y), 
                         n.rep = c(1000,10), max.sample.size = 2000, cpus = 5,
                         seed = 10)
nobs(sampleW)
summary(sampleW) ## not very accurate but gives an order of magnitude

sampleW2 &lt;- powerBuyseTest(sim = simFCT2, power = 0.8, formula = group ~ cont(Y), 
                         n.rep = c(1000,10), max.sample.size = 2000, cpus = 5,
                         seed = 10)
summary(sampleW2) ## more accurate when the sample size needed is not too small

## End(Not run)

</code></pre>

<hr>
<h2 id='predict.BuyseTTEM'>Prediction with Time to Event Model</h2><span id='topic+predict.BuyseTTEM'></span>

<h3>Description</h3>

<p>Evaluate the cumulative incidence function (cif) / survival in one of the treatment groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'BuyseTTEM'
predict(object, time, treatment, strata, cause = 1, iid = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.BuyseTTEM_+3A_object">object</code></td>
<td>
<p>time to event model.</p>
</td></tr>
<tr><td><code id="predict.BuyseTTEM_+3A_time">time</code></td>
<td>
<p>[numeric vector] time at which to evaluate the cif/survival.</p>
</td></tr>
<tr><td><code id="predict.BuyseTTEM_+3A_treatment">treatment</code></td>
<td>
<p>[character/integer] Treatment or index of the treatment group.</p>
</td></tr>
<tr><td><code id="predict.BuyseTTEM_+3A_strata">strata</code></td>
<td>
<p>[character/integer] Strata or index of the strata.</p>
</td></tr>
<tr><td><code id="predict.BuyseTTEM_+3A_cause">cause</code></td>
<td>
<p>[integer] The cause relative to which the cif will be evaluated.</p>
</td></tr>
<tr><td><code id="predict.BuyseTTEM_+3A_iid">iid</code></td>
<td>
<p>[logical] Should the influence function associated with the cif/survival be output?</p>
</td></tr>
<tr><td><code id="predict.BuyseTTEM_+3A_...">...</code></td>
<td>
<p>not used, for compatibility with the generic method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing the survival (element <code>survival</code>) or the cumulative incidence function (element <code>cif</code>),
and possible standard errors (element <code>.se</code>) and influence function (element <code>.iid</code>).
</p>

<hr>
<h2 id='rbind.performance'>Combine Resampling Results For Performance Objects</h2><span id='topic+rbind.performance'></span>

<h3>Description</h3>

<p>Combine permutation or bootstrap samples.
Useful to run parallel calculations (see example below).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'performance'
rbind(..., tolerance = 1e-05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rbind.performance_+3A_...">...</code></td>
<td>
<p>performance objects.</p>
</td></tr>
<tr><td><code id="rbind.performance_+3A_tolerance">tolerance</code></td>
<td>
<p>[numeric] maximum acceptable difference between the point estimates.
Can be <code>NA</code> to skip this sanity check.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>if(FALSE){

#### simulate data ####
set.seed(10)
n &lt;- 100
df.train &lt;- data.frame(Y = rbinom(n, prob = 0.5, size = 1),
                       X1 = rnorm(n), X2 = rnorm(n), X3 = rnorm(n), X4 = rnorm(n),
                       X5 = rnorm(n), X6 = rnorm(n), X7 = rnorm(n), X8 = rnorm(n),
                       X9 = rnorm(n), X10 = rnorm(n))
df.train$Y &lt;- rbinom(n, size = 1,
                     prob = 1/(1+exp(-df.train$X5 - df.train$X6 - df.train$X7)))

#### fit models ####
e.null &lt;- glm(Y~1, data = df.train, family = binomial(link="logit"))
e.logit &lt;- glm(Y~X1+X2, data = df.train, family = binomial(link="logit"))
e.logit2 &lt;- glm(Y~X1+X2+X3+X4+X5+X6+X7+X8+X9+X10, data = df.train,
               family = binomial(link="logit"))

#### evaluate model (same seed) ####
fold.repetition &lt;- 5 ## 0: internal perf (fast)
                     ## &gt;0: 10 fold CV repeated (slow)
test &lt;- performanceResample(list(e.logit,e.logit2), seed = 10,
                             fold.repetition = fold.repetition, n.resampling = 100)
test.1 &lt;- performanceResample(list(e.logit,e.logit2), seed = 10,
                             fold.repetition = fold.repetition, n.resampling = 1:50)
test.2 &lt;- performanceResample(list(e.logit,e.logit2), seed = 10,
                             fold.repetition = fold.repetition, n.resampling = 51:100)
rbind(test.1,test.2)
test

## Note: when the prediction model call RNG then test.1 and test.2 may not give test 

#### evaluate model (different seed) ####
test.3 &lt;- performanceResample(list(e.logit,e.logit2), seed = 11,
                             fold.repetition = fold.repetition, n.resampling = 1:50)
test.4 &lt;- performanceResample(list(e.logit,e.logit2), seed = 12,
                             fold.repetition = fold.repetition, n.resampling = 51:100)
rbind(test.3,test.4, tolerance = NA) ## does not check equality of the point estimate
                                     ## between test.3 and test.4
test
}
</code></pre>

<hr>
<h2 id='S4BuysePower-class'>Class &quot;S4BuysePower&quot; (output of BuyseTest)</h2><span id='topic+S4BuysePower-class'></span>

<h3>Description</h3>

<p>A <code><a href="#topic+powerBuyseTest">powerBuyseTest</a></code> output is reported in a <code>S4BuysePower</code> object.
</p>


<h3>Author(s)</h3>

<p>Brice Ozenne
</p>


<h3>See Also</h3>

<p><code><a href="#topic+powerBuyseTest">powerBuyseTest</a></code> for the function computing generalized pairwise comparisons. <br />
<code><a href="#topic+S4BuysePower-summary">S4BuysePower-summary</a></code> for the summary of the BuyseTest function results
</p>

<hr>
<h2 id='S4BuysePower-model.tables'>Extract Summary for Class &quot;S4BuysePower&quot;</h2><span id='topic+S4BuysePower-model.tables'></span><span id='topic+model.tables+2CS4BuysePower-method'></span>

<h3>Description</h3>

<p>Extract a summary of the results from the <code><a href="#topic+powerBuyseTest">powerBuyseTest</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'S4BuysePower'
model.tables(
  x,
  type = "summary",
  statistic = NULL,
  endpoint = NULL,
  order.Hprojection = NULL,
  transformation = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="S4BuysePower-model.tables_+3A_x">x</code></td>
<td>
<p>output of <code><a href="#topic+powerBuyseTest">powerBuyseTest</a></code></p>
</td></tr>
<tr><td><code id="S4BuysePower-model.tables_+3A_type">type</code></td>
<td>
<p>[character] should a summary of the results (<code>"summary"</code>) or the raw results (<code>"raw"</code>) be output?</p>
</td></tr>
<tr><td><code id="S4BuysePower-model.tables_+3A_statistic">statistic</code></td>
<td>
<p>[character] statistic relative to which the power should be computed:
<code>"netBenefit"</code> displays the net benefit, as described in Buyse (2010) and Peron et al. (2016)),
<code>"winRatio"</code> displays the win ratio, as described in Wang et al. (2016),
<code>"mannWhitney"</code> displays the proportion in favor of the treatment (also called Mann-Whitney parameter), as described in Fay et al. (2018).
Default value read from <code>BuyseTest.options()</code>.</p>
</td></tr>
<tr><td><code id="S4BuysePower-model.tables_+3A_endpoint">endpoint</code></td>
<td>
<p>[character vector] the endpoints to be displayed: must be the name of the endpoint followed by an underscore and then by the threshold.</p>
</td></tr>
<tr><td><code id="S4BuysePower-model.tables_+3A_order.hprojection">order.Hprojection</code></td>
<td>
<p>[integer 1,2] the order of the H-project to be used to compute the variance of the net benefit/win ratio.</p>
</td></tr>
<tr><td><code id="S4BuysePower-model.tables_+3A_transformation">transformation</code></td>
<td>
<p>[logical] should the CI be computed on the logit scale / log scale for the net benefit / win ratio and backtransformed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame
</p>


<h3>Author(s)</h3>

<p>Brice Ozenne
</p>


<h3>See Also</h3>

<p><code><a href="#topic+powerBuyseTest">powerBuyseTest</a></code> for performing a simulation study for generalized pairwise comparison. <br />
</p>

<hr>
<h2 id='S4BuysePower-nobs'>Sample Size for Class &quot;S4BuysePower&quot;</h2><span id='topic+S4BuysePower-nobs'></span><span id='topic+nobs+2CS4BuysePower-method'></span>

<h3>Description</h3>

<p>Display the sample size in each treatmnet arm as well as the number of pairs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'S4BuysePower'
nobs(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="S4BuysePower-nobs_+3A_object">object</code></td>
<td>
<p>an <span class="rlang"><b>R</b></span> object of class <code>S4BuysePower</code>, i.e., output of <code><a href="#topic+powerBuyseTest">powerBuyseTest</a></code></p>
</td></tr>
<tr><td><code id="S4BuysePower-nobs_+3A_...">...</code></td>
<td>
<p>no used, for compatibility with the generic method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame with two colunms, one for each treatment group, and as many rows as sample sizes used for the simulation.
</p>


<h3>Author(s)</h3>

<p>Brice Ozenne
</p>

<hr>
<h2 id='S4BuysePower-print'>Print Method for Class &quot;S4BuysePower&quot;</h2><span id='topic+S4BuysePower-print'></span><span id='topic+print+2CS4BuysePower-method'></span>

<h3>Description</h3>

<p>Display the main results stored in a <code>S4BuysePower</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'S4BuysePower'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="S4BuysePower-print_+3A_x">x</code></td>
<td>
<p>an <span class="rlang"><b>R</b></span> object of class <code>S4BuysePower</code>, i.e., output of <code><a href="#topic+powerBuyseTest">powerBuyseTest</a></code></p>
</td></tr>
<tr><td><code id="S4BuysePower-print_+3A_...">...</code></td>
<td>
<p>additional arguments passed to the summary method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>invisible table
</p>


<h3>Author(s)</h3>

<p>Brice Ozenne
</p>


<h3>See Also</h3>

<p><code><a href="#topic+powerBuyseTest">powerBuyseTest</a></code> for performing power calculation based on GPC. <br />
<code><a href="#topic+S4BuysePower-summary">S4BuysePower-summary</a></code> for a more detailed presentation of the <code>S4BuysePower</code> object.
</p>

<hr>
<h2 id='S4BuysePower-show'>Show Method for Class &quot;S4BuysePower&quot;</h2><span id='topic+S4BuysePower-show'></span><span id='topic+show+2CS4BuysePower-method'></span><span id='topic+S4BuyseTest-show'></span><span id='topic+show+2CS4BuyseTest-method'></span>

<h3>Description</h3>

<p>Display the main results stored in a <code>S4BuysePower</code> object.
</p>
<p>Display the main results stored in a <code>S4BuyseTest</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'S4BuysePower'
show(object)

## S4 method for signature 'S4BuyseTest'
show(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="S4BuysePower-show_+3A_object">object</code></td>
<td>
<p>an <span class="rlang"><b>R</b></span> object of class <code>S4BuyseTest</code>, i.e., output of <code><a href="#topic+BuyseTest">BuyseTest</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>invisible <code>NULL</code>
</p>


<h3>Author(s)</h3>

<p>Brice Ozenne
</p>


<h3>See Also</h3>

<p><code><a href="#topic+powerBuyseTest">powerBuyseTest</a></code> for performing power calculation based on GPC. <br />
<code><a href="#topic+S4BuysePower-summary">S4BuysePower-summary</a></code> for a more detailed presentation of the <code>S4BuysePower</code> object.
</p>
<p><code><a href="#topic+BuyseTest">BuyseTest</a></code> for performing a generalized pairwise comparison. <br />
<code><a href="#topic+S4BuyseTest-summary">S4BuyseTest-summary</a></code> for a more detailed presentation of the <code>S4BuyseTest</code> object.
</p>

<hr>
<h2 id='S4BuysePower-summary'>Summary Method for Class &quot;S4BuysePower&quot;</h2><span id='topic+S4BuysePower-summary'></span><span id='topic+summary+2CS4BuysePower-method'></span>

<h3>Description</h3>

<p>Summarize the results from the <code><a href="#topic+powerBuyseTest">powerBuyseTest</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'S4BuysePower'
summary(
  object,
  statistic = NULL,
  endpoint = NULL,
  order.Hprojection = NULL,
  transformation = NULL,
  print = TRUE,
  legend = TRUE,
  col.rep = FALSE,
  digit = 4,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="S4BuysePower-summary_+3A_object">object</code></td>
<td>
<p>output of <code><a href="#topic+powerBuyseTest">powerBuyseTest</a></code></p>
</td></tr>
<tr><td><code id="S4BuysePower-summary_+3A_statistic">statistic</code></td>
<td>
<p>[character] statistic relative to which the power should be computed:
<code>"netBenefit"</code> displays the net benefit, as described in Buyse (2010) and Peron et al. (2016)),
<code>"winRatio"</code> displays the win ratio, as described in Wang et al. (2016),
<code>"mannWhitney"</code> displays the proportion in favor of the treatment (also called Mann-Whitney parameter), as described in Fay et al. (2018).
Default value read from <code>BuyseTest.options()</code>.</p>
</td></tr>
<tr><td><code id="S4BuysePower-summary_+3A_endpoint">endpoint</code></td>
<td>
<p>[character vector] the endpoints to be displayed: must be the name of the endpoint followed by an underscore and then by the threshold.</p>
</td></tr>
<tr><td><code id="S4BuysePower-summary_+3A_order.hprojection">order.Hprojection</code></td>
<td>
<p>[integer 1,2] the order of the H-project to be used to compute the variance of the net benefit/win ratio.</p>
</td></tr>
<tr><td><code id="S4BuysePower-summary_+3A_transformation">transformation</code></td>
<td>
<p>[logical] should the CI be computed on the logit scale / log scale for the net benefit / win ratio and backtransformed.</p>
</td></tr>
<tr><td><code id="S4BuysePower-summary_+3A_print">print</code></td>
<td>
<p>[logical] Should the table be displayed?.</p>
</td></tr>
<tr><td><code id="S4BuysePower-summary_+3A_legend">legend</code></td>
<td>
<p>[logical] should explainations about the content of each column be displayed?</p>
</td></tr>
<tr><td><code id="S4BuysePower-summary_+3A_col.rep">col.rep</code></td>
<td>
<p>[logical] should the number of successful simulations be displayed?</p>
</td></tr>
<tr><td><code id="S4BuysePower-summary_+3A_digit">digit</code></td>
<td>
<p>[integer vector] the number of digit to use for printing the counts and the delta.</p>
</td></tr>
<tr><td><code id="S4BuysePower-summary_+3A_...">...</code></td>
<td>
<p>Not used. For compatibility with the generic method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame
</p>


<h3>Author(s)</h3>

<p>Brice Ozenne
</p>


<h3>See Also</h3>

<p><code><a href="#topic+powerBuyseTest">powerBuyseTest</a></code> for performing a simulation study for generalized pairwise comparison. <br />
</p>

<hr>
<h2 id='S4BuyseTest-class'>Class &quot;S4BuyseTest&quot; (output of BuyseTest)</h2><span id='topic+S4BuyseTest-class'></span>

<h3>Description</h3>

<p>A <code><a href="#topic+BuyseTest">BuyseTest</a></code> output is reported in a <code>S4BuyseTest</code> object.
</p>


<h3>Author(s)</h3>

<p>Brice Ozenne
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BuyseTest">BuyseTest</a></code> for the function computing generalized pairwise comparisons. <br />
<code><a href="#topic+S4BuyseTest-summary">S4BuyseTest-summary</a></code> for the summary of the BuyseTest function results
</p>

<hr>
<h2 id='S4BuyseTest-coef'>Extract Summary Statistics from GPC</h2><span id='topic+S4BuyseTest-coef'></span><span id='topic+coef+2CS4BuyseTest-method'></span>

<h3>Description</h3>

<p>Extract summary statistics (net benefit, win ratio, ...) from GPC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'S4BuyseTest'
coef(
  object,
  endpoint = NULL,
  statistic = NULL,
  strata = FALSE,
  cumulative = NULL,
  resampling = FALSE,
  simplify = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="S4BuyseTest-coef_+3A_object">object</code></td>
<td>
<p>a <code>S4BuyseTest</code> object, output of <code><a href="#topic+BuyseTest">BuyseTest</a></code>.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-coef_+3A_endpoint">endpoint</code></td>
<td>
<p>[character] for which endpoint(s) the summary statistic should be output?
If <code>NULL</code> returns the summary statistic for all endpoints.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-coef_+3A_statistic">statistic</code></td>
<td>
<p>[character] the type of summary statistic. See the detail section.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-coef_+3A_strata">strata</code></td>
<td>
<p>[character vector] the strata relative to which the statistic should be output.
Can also be <code>"global"</code> or <code>FALSE</code> to output the statistic pooled over all strata,
or <code>TRUE</code> to output each strata-specific statistic.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-coef_+3A_cumulative">cumulative</code></td>
<td>
<p>[logical] should the summary statistic be cumulated over endpoints?
Otherwise display the contribution of each endpoint.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-coef_+3A_resampling">resampling</code></td>
<td>
<p>[logical] should the summary statistic obtained by resampling be output?</p>
</td></tr>
<tr><td><code id="S4BuyseTest-coef_+3A_simplify">simplify</code></td>
<td>
<p>[logical] should the result be coerced to the lowest possible dimension?</p>
</td></tr>
<tr><td><code id="S4BuyseTest-coef_+3A_...">...</code></td>
<td>
<p>ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>One of the following statistic can be specified:
</p>

<ul>
<li> <p><code>"netBenefit"</code>: returns the net benefit.
</p>
</li>
<li> <p><code>"winRatio"</code>: returns the win ratio.
</p>
</li>
<li> <p><code>"favorable"</code>: returns the proportion in favor of the treatment (also called Mann-Whitney parameter).
</p>
</li>
<li> <p><code>"unfavorable"</code>: returns the proportion in favor of the control.
</p>
</li>
<li> <p><code>"unfavorable"</code>: returns the proportion of neutral pairs.
</p>
</li>
<li> <p><code>"unfavorable"</code>: returns the proportion of uninformative pairs.
</p>
</li>
<li> <p><code>"count.favorable"</code>: returns the number of pairs in favor of the treatment.
</p>
</li>
<li> <p><code>"count.unfavorable"</code>: returns the number of pairs in favor of the control.
</p>
</li>
<li> <p><code>"count.neutral"</code>: returns the number of neutral pairs.
</p>
</li>
<li> <p><code>"count.uninf"</code>: returns the number of uninformative pairs.
</p>
</li></ul>



<h3>Value</h3>

<p>When <code>resampling=FALSE</code> and <code>simplify=FALSE</code>, a matrix (strata, endpoint).
When <code>resampling=FALSE</code> and <code>simplify=FALSE</code>, an array (sample, strata, endpoint).
</p>


<h3>Author(s)</h3>

<p>Brice Ozenne
</p>

<hr>
<h2 id='S4BuyseTest-confint'>Extract Confidence Interval from GPC</h2><span id='topic+S4BuyseTest-confint'></span><span id='topic+confint+2CS4BuyseTest-method'></span>

<h3>Description</h3>

<p>Extract confidence intervals for summary statistics (net benefit, win ratio, ...) estimated by GPC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'S4BuyseTest'
confint(
  object,
  endpoint = NULL,
  statistic = NULL,
  strata = FALSE,
  cumulative = TRUE,
  null = NULL,
  conf.level = NULL,
  alternative = NULL,
  method.ci.resampling = NULL,
  order.Hprojection = NULL,
  transformation = NULL,
  cluster = NULL,
  sep = "."
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="S4BuyseTest-confint_+3A_object">object</code></td>
<td>
<p>an <span class="rlang"><b>R</b></span> object of class <code><a href="#topic+S4BuyseTest-class">S4BuyseTest</a></code>, i.e., output of <code><a href="#topic+BuyseTest">BuyseTest</a></code></p>
</td></tr>
<tr><td><code id="S4BuyseTest-confint_+3A_endpoint">endpoint</code></td>
<td>
<p>[character] for which endpoint(s) the confidence intervals should be output?
If <code>NULL</code> returns the confidence intervals for all endpoints.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-confint_+3A_statistic">statistic</code></td>
<td>
<p>[character] the statistic summarizing the pairwise comparison:
<code>"netBenefit"</code> displays the net benefit, as described in Buyse (2010) and Peron et al. (2016)),
<code>"winRatio"</code> displays the win ratio, as described in Wang et al. (2016),
<code>"favorable"</code> displays the proportion in favor of the treatment (also called Mann-Whitney parameter), as described in Fay et al. (2018).
<code>"unfavorable"</code> displays the proportion in favor of the control.
Default value read from <code>BuyseTest.options()</code>.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-confint_+3A_strata">strata</code></td>
<td>
<p>[character] the strata relative to which the statistic should be output.
Can also be <code>"global"</code> or <code>FALSE</code> to output the statistic pooled over all strata,
or <code>TRUE</code> to output each strata-specific statistic.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-confint_+3A_cumulative">cumulative</code></td>
<td>
<p>[logical] should the summary statistic be cumulated over endpoints?
Otherwise display the contribution of each endpoint.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-confint_+3A_null">null</code></td>
<td>
<p>[numeric] right hand side of the null hypothesis (used for the computation of the p-value).</p>
</td></tr>
<tr><td><code id="S4BuyseTest-confint_+3A_conf.level">conf.level</code></td>
<td>
<p>[numeric] confidence level for the confidence intervals.
Default value read from <code>BuyseTest.options()</code>.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-confint_+3A_alternative">alternative</code></td>
<td>
<p>[character] the type of alternative hypothesis: <code>"two.sided"</code>, <code>"greater"</code>, or <code>"less"</code>.
Default value read from <code>BuyseTest.options()</code>.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-confint_+3A_method.ci.resampling">method.ci.resampling</code></td>
<td>
<p>[character] the method used to compute the confidence intervals and p-values when using bootstrap or permutation (<code>"percentile"</code>, <code>"gaussian"</code>, <code>"student"</code>).
See the details section.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-confint_+3A_order.hprojection">order.Hprojection</code></td>
<td>
<p>[integer, 1-2] order of the H-decomposition used to compute the variance.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-confint_+3A_transformation">transformation</code></td>
<td>
<p>[logical]  should the CI be computed on the inverse hyperbolic tangent scale / log scale for the net benefit / win ratio and backtransformed.
Otherwise they are computed without any transformation.
Default value read from <code>BuyseTest.options()</code>. Not relevant when using permutations or percentile bootstrap.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-confint_+3A_cluster">cluster</code></td>
<td>
<p>[numeric vector] Group of observations for which the iid assumption holds .</p>
</td></tr>
<tr><td><code id="S4BuyseTest-confint_+3A_sep">sep</code></td>
<td>
<p>[character] character string used to separate the endpoint and the strata when naming the statistics.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>statistic</b>: when considering a single endpoint and denoting
<code class="reqn">Y</code> the endpoint in the treatment group,
<code class="reqn">X</code> the endpoint in the control group,
and <code class="reqn">\tau</code> the threshold of clinical relevance,
the net benefit is <code class="reqn">P[Y \ge X + \tau] - P[X \ge Y + \tau]</code>,
the win ratio is <code class="reqn">\frac{P[Y \ge X + \tau]}{P[X \ge Y + \tau]}</code>,
the proportion in favor of treatment is <code class="reqn">P[Y \ge X + \tau]</code>,
the proportion in favor of control is <code class="reqn">P[X \ge Y + \tau]</code>.
</p>
<p><b>method.ci.resampling</b>: when using bootstrap/permutation, p-values and confidence intervals are computing as follow: </p>

<ul>
<li> <p><code>percentile</code> (bootstrap): compute the confidence interval using the quantiles of the bootstrap estimates.
Compute the p-value by finding the confidence level at which a bound of the confidence interval equals the null hypothesis.
</p>
</li>
<li> <p><code>percentile</code> (permutation): apply the selected transformation to the estimate and permutation estimates.
Compute the confidence interval by (i) shfiting the estimate by the quantiles of the centered permutation estimates and (ii) back-transforming .
Compute the p-value as the relative frequency at which the estimate are less extreme than the permutation estimates.
</p>
</li>
<li> <p><code>gaussian</code> (bootstrap and permutation): apply the selected transformation to the estimate and bootstrap/permutation estimates.
Estimate the variance of the estimator using the empirical variance of the transformed boostrap/permutation estimates.
Compute confidence intervals and p-values under the normality assumption and back-transform the confidence intervals.
</p>
</li>
<li> <p><code>student</code> (bootstrap): apply the selected transformation to the estimate, its standard error, the bootstrap estimates, and their standard error.
Compute the studentized bootstrap estimates by dividing the centered bootstrap estimates by their standard error. 
Compute the confidence interval based on the standard error of the estimate and the quantiles of the studentized bootstrap estimates, and back-transform.
Compute the p-value by finding the confidence level at which a bound of the confidence interval equals the null hypothesis.
</p>
</li>
<li> <p><code>student</code> (permutation): apply the selected transformation to the estimate, its standard error, the permutation estimates, and their standard error.
Compute the studentized permutation estimates by dividing the centered permutation estimates by their standard error.
Compute the confidence interval based on the standard error of the estimate and the quantiles of the studentized permutation estimates, and back-transform.
Compute the p-value as the relative frequency at which the studentized estimate are less extreme than the permutation studentized estimates.
</p>
</li></ul>

<p><b>WARNING</b>: when using a permutation test, the uncertainty associated with the estimator is computed under the null hypothesis.
Thus the confidence interval may not be valid if the null hypothesis is false. <br />
</p>


<h3>Value</h3>

<p>A matrix containing a column for the estimated statistic (over all strata),
the lower bound and upper bound of the confidence intervals, and the associated p-values.
When using resampling methods:
</p>

<ul>
<li><p> an attribute <code>n.resampling</code> specified how many samples have been used to compute the confidence intervals and the p-values.
</p>
</li>
<li><p> an attribute <code>method.ci.resampling</code> method used to compute the confidence intervals and p-values. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Brice Ozenne
</p>


<h3>References</h3>

<p>On the GPC procedure: Marc Buyse (2010). <b>Generalized pairwise comparisons of prioritized endpoints in the two-sample problem</b>. <em>Statistics in Medicine</em> 29:3245-3257 <br />
On the win ratio: D. Wang, S. Pocock (2016). <b>A win ratio approach to comparing continuous non-normal outcomes in clinical trials</b>. <em>Pharmaceutical Statistics</em> 15:238-245 <br />
On the Mann-Whitney parameter: Fay, Michael P. et al (2018). <b>Causal estimands and confidence intervals asscoaited with Wilcoxon-Mann-Whitney tests in randomized experiments</b>. <em>Statistics in Medicine</em> 37:2923-2937 <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BuyseTest">BuyseTest</a></code> for performing a generalized pairwise comparison. <br />
<code><a href="#topic+S4BuyseTest-summary">S4BuyseTest-summary</a></code> for a more detailed presentation of the <code>S4BuyseTest</code> object.
</p>

<hr>
<h2 id='S4BuyseTest-model.tables'>Extract Summary for Class &quot;S4BuyseTest&quot;</h2><span id='topic+S4BuyseTest-model.tables'></span><span id='topic+model.tables+2CS4BuyseTest-method'></span>

<h3>Description</h3>

<p>Extract a summary of the results from the <code><a href="#topic+BuyseTest">BuyseTest</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'S4BuyseTest'
model.tables(
  x,
  percentage = TRUE,
  statistic = NULL,
  conf.level = NULL,
  strata = NULL,
  columns = "summary",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="S4BuyseTest-model.tables_+3A_x">x</code></td>
<td>
<p>output of <code><a href="#topic+BuyseTest">BuyseTest</a></code></p>
</td></tr>
<tr><td><code id="S4BuyseTest-model.tables_+3A_percentage">percentage</code></td>
<td>
<p>[logical] Should the percentage of pairs of each type be displayed ? Otherwise the number of pairs is displayed.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-model.tables_+3A_statistic">statistic</code></td>
<td>
<p>[character] the statistic summarizing the pairwise comparison:
<code>"netBenefit"</code> displays the net benefit, as described in Buyse (2010) and Peron et al. (2016)),
<code>"winRatio"</code> displays the win ratio, as described in Wang et al. (2016),
<code>"favorable"</code> displays the proportion in favor of the treatment (also called Mann-Whitney parameter), as described in Fay et al. (2018).
<code>"unfavorable"</code> displays the proportion in favor of the control.
Default value read from <code>BuyseTest.options()</code>.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-model.tables_+3A_conf.level">conf.level</code></td>
<td>
<p>[numeric] confidence level for the confidence intervals.
Default value read from <code>BuyseTest.options()</code>.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-model.tables_+3A_strata">strata</code></td>
<td>
<p>[logical] should the strata-specific results be displayed or the results pooled across strata?
Can also be <code>NULL</code> to display both.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-model.tables_+3A_columns">columns</code></td>
<td>
<p>[character vector] subset of columns to be output (e.g. <code>"endpoint"</code>, <code>"favorable"</code>, ...).
Can also be <code>"summary"</code> or <code>"print"</code> to only select columns displayed in the summary or print. <code>NULL</code> will select all columns.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-model.tables_+3A_...">...</code></td>
<td>
<p>arguments to be passed to <code><a href="#topic+S4BuyseTest-confint">S4BuyseTest-confint</a></code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Brice Ozenne
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BuyseTest">BuyseTest</a></code> for performing a generalized pairwise comparison. <br />
<code><a href="#topic+S4BuyseTest-class">S4BuyseTest-class</a></code> for a presentation of the <code>S4BuyseTest</code> object. <br />
<code><a href="#topic+S4BuyseTest-confint">S4BuyseTest-confint</a></code> to output confidence interval and p-values in a matrix format.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(data.table)

dt &lt;- simBuyseTest(1e2, n.strata = 3)

 ## Not run: 
 BT &lt;- BuyseTest(treatment ~ TTE(eventtime, status = status) + Bin(toxicity), data=dt)
 
## End(Not run)
 
 model.tables(BT)
 model.tables(BT, percentage = FALSE)
 model.tables(BT, statistic = "winRatio")

</code></pre>

<hr>
<h2 id='S4BuyseTest-nobs'>Sample Size for Class &quot;S4BuyseTest&quot;</h2><span id='topic+S4BuyseTest-nobs'></span><span id='topic+nobs+2CS4BuyseTest-method'></span>

<h3>Description</h3>

<p>Display the sample size in each treatmnet arm as well as the number of pairs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'S4BuyseTest'
nobs(object, strata = FALSE, simplify = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="S4BuyseTest-nobs_+3A_object">object</code></td>
<td>
<p>an <span class="rlang"><b>R</b></span> object of class <code>S4BuyseTest</code>, i.e., output of <code><a href="#topic+BuyseTest">BuyseTest</a></code></p>
</td></tr>
<tr><td><code id="S4BuyseTest-nobs_+3A_strata">strata</code></td>
<td>
<p>[character vector] the strata relative to which the number of pairs should be output.
Can also be <code>"global"</code> or <code>FALSE</code> to output the total number of pairs (i.e. across all strata),
or <code>TRUE</code> to output each strata-specific number of pairs.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-nobs_+3A_simplify">simplify</code></td>
<td>
<p>[logical] should the result be coerced to the lowest possible dimension?</p>
</td></tr>
<tr><td><code id="S4BuyseTest-nobs_+3A_...">...</code></td>
<td>
<p>no used, for compatibility with the generic method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector (when argument <code>strata</code> is <code>FALSE</code>) or a matrix (when argument <code>strata</code> is <code>TRUE</code>). In the latter case each line correspond to a strata.
</p>


<h3>Author(s)</h3>

<p>Brice Ozenne
</p>

<hr>
<h2 id='S4BuyseTest-plot'>Graphical Display for GPC</h2><span id='topic+S4BuyseTest-plot'></span><span id='topic+plot+2CS4BuyseTest+2CANY-method'></span>

<h3>Description</h3>

<p>Graphical display of the percentage of favorable, unfavorable, neutral, and uninformative pairs per endpoint.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'S4BuyseTest,ANY'
plot(
  x,
  type = "hist",
  strata = "global",
  endpoint = NULL,
  label.strata = NULL,
  label.endpoint = NULL,
  plot = TRUE,
  color = c("#7CAE00", "#F8766D", "#C77CFF", "#00BFC4"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="S4BuyseTest-plot_+3A_x">x</code></td>
<td>
<p>an <span class="rlang"><b>R</b></span> object of class <code><a href="#topic+S4BuyseTest-class">S4BuyseTest</a></code>, i.e., output of <code><a href="#topic+BuyseTest">BuyseTest</a></code></p>
</td></tr>
<tr><td><code id="S4BuyseTest-plot_+3A_type">type</code></td>
<td>
<p>[character] type of plot: histogram (<code>"hist"</code>), pie chart (<code>"pie"</code>), or nested pie charts (<code>"racetrack"</code>).</p>
</td></tr>
<tr><td><code id="S4BuyseTest-plot_+3A_strata">strata</code></td>
<td>
<p>[character vector] strata(s) relative to which the percentage should be displayed.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-plot_+3A_endpoint">endpoint</code></td>
<td>
<p>[character vector] endpoint(s) relative to which the percentage should be displayed.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-plot_+3A_label.strata">label.strata</code></td>
<td>
<p>[character vector] new labels for the strata levels. Should match the length of argument <code>strata</code>.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-plot_+3A_label.endpoint">label.endpoint</code></td>
<td>
<p>[character vector] new labels for the endpoints. Should match the length of argument <code>endpoint</code>.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-plot_+3A_plot">plot</code></td>
<td>
<p>[logical] should the graphic be displayed in a graphical window.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-plot_+3A_color">color</code></td>
<td>
<p>[character vector] colors used to display the percentages for each type of pair.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-plot_+3A_...">...</code></td>
<td>
<p>not used, for compatibility with the generic function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an invisible list containing the data and the ggplot object used for graphical display.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(require(ggplot2)){

## simulate data
set.seed(10)
df.data &lt;- simBuyseTest(1e2, n.strata = 2)

ff1 &lt;- treatment ~ bin(toxicity) + TTE(eventtime, status = status,
                                      restriction = 1, threshold = 0.5)
BT1 &lt;- BuyseTest(ff1, data= df.data)
plot(BT1, type = "hist")
plot(BT1, type = "pie")
plot(BT1, type = "racetrack")

ff2 &lt;- update(ff1, ~.+cont(score))
BT2 &lt;- BuyseTest(ff2, data= df.data)
plot(BT2, type = "hist")
plot(BT2, type = "pie")
plot(BT2, type = "racetrack")

}
</code></pre>

<hr>
<h2 id='S4BuyseTest-print'>Print Method for Class &quot;S4BuyseTest&quot;</h2><span id='topic+S4BuyseTest-print'></span><span id='topic+print+2CS4BuyseTest-method'></span>

<h3>Description</h3>

<p>Display the main results stored in a <code>S4BuyseTest</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'S4BuyseTest'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="S4BuyseTest-print_+3A_x">x</code></td>
<td>
<p>an <span class="rlang"><b>R</b></span> object of class <code>S4BuyseTest</code>, i.e., output of <code><a href="#topic+BuyseTest">BuyseTest</a></code></p>
</td></tr>
<tr><td><code id="S4BuyseTest-print_+3A_...">...</code></td>
<td>
<p>additional arguments passed to the summary method.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Brice Ozenne
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BuyseTest">BuyseTest</a></code> for performing a generalized pairwise comparison. <br />
<code><a href="#topic+S4BuyseTest-summary">S4BuyseTest-summary</a></code> for a more detailed presentation of the <code>S4BuyseTest</code> object.
</p>

<hr>
<h2 id='S4BuyseTest-summary'>Summary Method for Class &quot;S4BuyseTest&quot;</h2><span id='topic+S4BuyseTest-summary'></span><span id='topic+summary+2CS4BuyseTest-method'></span>

<h3>Description</h3>

<p>Summarize the results from the <code><a href="#topic+BuyseTest">BuyseTest</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'S4BuyseTest'
summary(
  object,
  print = TRUE,
  percentage = TRUE,
  statistic = NULL,
  conf.level = NULL,
  strata = NULL,
  type.display = 1,
  digit = c(2, 4, 5),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="S4BuyseTest-summary_+3A_object">object</code></td>
<td>
<p>output of <code><a href="#topic+BuyseTest">BuyseTest</a></code></p>
</td></tr>
<tr><td><code id="S4BuyseTest-summary_+3A_print">print</code></td>
<td>
<p>[logical] Should the results be displayed in the console?</p>
</td></tr>
<tr><td><code id="S4BuyseTest-summary_+3A_percentage">percentage</code></td>
<td>
<p>[logical] Should the percentage of pairs of each type be displayed ? Otherwise the number of pairs is displayed.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-summary_+3A_statistic">statistic</code></td>
<td>
<p>[character] the statistic summarizing the pairwise comparison:
<code>"netBenefit"</code> displays the net benefit, as described in Buyse (2010) and Peron et al. (2016)),
<code>"winRatio"</code> displays the win ratio, as described in Wang et al. (2016),
<code>"favorable"</code> displays the proportion in favor of the treatment (also called Mann-Whitney parameter), as described in Fay et al. (2018).
<code>"unfavorable"</code> displays the proportion in favor of the control.
Default value read from <code>BuyseTest.options()</code>.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-summary_+3A_conf.level">conf.level</code></td>
<td>
<p>[numeric] confidence level for the confidence intervals.
Default value read from <code>BuyseTest.options()</code>.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-summary_+3A_strata">strata</code></td>
<td>
<p>[logical] should the strata-specific results be displayed or the results pooled across strata?
Can also be <code>NULL</code> to display both.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-summary_+3A_type.display">type.display</code></td>
<td>
<p>[numeric or character] the results/summary statistics to be displayed.
Either an integer indicating refering to a type of display in <code>BuyseTest.options()</code>
or the name of the column to be output (e.g. <code>c("strata","Delta","p.value")</code>).</p>
</td></tr>
<tr><td><code id="S4BuyseTest-summary_+3A_digit">digit</code></td>
<td>
<p>[integer vector] the number of digit to use for printing the counts and the delta.</p>
</td></tr>
<tr><td><code id="S4BuyseTest-summary_+3A_...">...</code></td>
<td>
<p>arguments to be passed to <code><a href="#topic+S4BuyseTest-confint">S4BuyseTest-confint</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>Content of the output</b> <br />
The &quot;results&quot; table in the output show the result of the GPC at each endpoint, as well as its contribution to the global statistics.
More precisely, the column:
</p>

<ul>
<li> <p><code>endpoint</code> lists the endpoints, by order of priority.
</p>
</li>
<li> <p><code>threshold</code> lists the threshold associated to each endpoint.
</p>
</li>
<li> <p><b>weight:</b> lists the weight of each priority.
</p>
</li>
<li> <p><b>strata:</b> list the strata relative to which the results of the priority are displayed. If <code>"global"</code>, then the results are over all strata at a given priority.
</p>
</li>
<li> <p><code>total</code> (or <code>total(%)</code>) lists the number (or percentage) of pairs to be analyzed at the current priority (or strata).
</p>
</li>
<li> <p><code>favorable</code> (or <code>favorable(%)</code>) lists the number (or percentage) of pairs classified in favor of the treatment group at the current priority (or strata).
</p>
</li>
<li> <p><code>unfavorable</code> (or <code>unfavorable(%)</code>) lists the number (or percentage) of pairs classified in favor of the control group at the current priority (or strata).
</p>
</li>
<li> <p><code>neutral</code> (or <code>neutral(%)</code>) lists the number (or percentage) of pairs classified as neither in favor of the treatment group nor in favor of the control group at the current priority (or strata).
</p>
</li>
<li> <p><code>uninf</code> (or <code>uninf(%)</code>) lists the number (or percentage) of pairs that could not be classified at the current priority (or strata) due to missing values/censoring.
</p>
</li>
<li> <p><code>delta</code> lists the value of the priority-specific statistic (e.g. net benefit or win ratio), i.e. computed on the pairs analyzed at the current priority only.
</p>
</li>
<li> <p><code>Delta</code> lists the value of the cumulative statistic (e.g. net benefit or win ratio), i.e. computed on all the pairs analyzed up to the current priority.
</p>
</li>
<li> <p><code>Delta(%)</code> lists the relative statistic (i.e. statistic up to the current priority divided by the final statistic).
</p>
</li>
<li> <p><code>information(%)</code> lists the information fraction (i.e. number of favorable and unfavorable pairs up to the current priority divided by the final number of favorable and unfavorable pairs).
</p>
</li>
<li> <p><code>CI</code> lists the confidence intervals for <code>Delta</code> (not adjusted for multiple comparison).
</p>
</li>
<li> <p><code>null</code> lists the null hypothesis (<code>Delta=null</code>).
</p>
</li>
<li> <p><code>p.value</code> p-value relative to the null hypothesis (not adjusted for multiple comparison).
</p>
</li>
<li> <p><code>resampling</code> number of samples used to compute the confidence intervals or p-values from permutations or bootstrap samples.
Only displayed if some bootstrap samples have been discarded, for example, they did not lead to sample any case or control.
</p>
</li></ul>

<p>Note: when using the Peron scoring rule or a correction for uninformative pairs, the columns <code>total</code>, <code>favorable</code>, <code>unfavorable</code>, <code>neutral</code>, and <code>uninf</code> are computing by summing the contribution of the pairs. This may lead to a decimal value.
</p>
<p><b>Statistic</b>: when considering a single endpoint and denoting
<code class="reqn">Y</code> the endpoint in the treatment group,
<code class="reqn">X</code> the endpoint in the control group,
and <code class="reqn">\tau</code> the threshold of clinical relevance,
the net benefit is <code class="reqn">P[Y \ge X + \tau] - P[X \ge Y + \tau]</code>,
the win ratio is <code class="reqn">\frac{P[Y \ge X + \tau]}{P[X \ge Y + \tau]}</code>,
the proportion in favor of treatment is <code class="reqn">P[Y \ge X + \tau]</code>,
the proportion in favor of control is <code class="reqn">P[X \ge Y + \tau]</code>.
</p>
<p><b>Statistical inference</b> <br />
When the interest is in obtaining p-values, we recommand the use of a permutation test.
However, when using a permutation test confidence intervals are not displayed in the summary.
This is because there is no (to the best of our knowledge) straightforward way to obtain good confidence intervals with permutations. 
An easy way consist in using the quantiles of the permutation distribution and then shift by the point estimate of the statistic.
This is what is output by <code><a href="#topic+S4BuyseTest-confint">S4BuyseTest-confint</a></code>.
However this approach leads to a much too high coverage when the null hypothesis is false.
The limits of the confidence interval can also end up being outside of the interval of definition of the statistic
(e.g. outside [-1,1] for the proportion in favor of treatment).
Therefore, for obtaining confidence intervals, we recommand the boostrap method or the u-statistic method.
</p>
<p><b>Win ratio</b> <br />
For the win ratio, the proposed implementation enables the use of thresholds and endpoints that are not time to events
as well as the correction proposed in Peron et al. (2016) to account for censoring. 
These development have not been examined by Wang et al. (2016), or in other papers (to the best of our knowledge).
They are only provided here by implementation convenience.
</p>
<p><b>Competing risks</b> <br />
In presence of competing risks, looking at the net benefit/win ratio computed with respect to the event of interest
will likely not give a full picture of the difference between the two groups.
For instance a treatment may decrease the risk of the event of interest (i.e. increase the net benefit for this event)
by increasing the risk of the competing event. If the competing event is death, this is not desirable. It is therefore advised to
taking into consideration the risk of the competing event, e.g. by re-running BuyseTest where cause 1 and 2 have been inverted.
</p>


<h3>Author(s)</h3>

<p>Brice Ozenne
</p>


<h3>References</h3>

<p>On the GPC procedure: Marc Buyse (2010). <b>Generalized pairwise comparisons of prioritized endpoints in the two-sample problem</b>. <em>Statistics in Medicine</em> 29:3245-3257 <br />
On the win ratio: D. Wang, S. Pocock (2016). <b>A win ratio approach to comparing continuous non-normal outcomes in clinical trials</b>. <em>Pharmaceutical Statistics</em> 15:238-245 <br />
On the Mann-Whitney parameter: Fay, Michael P. et al (2018). <b>Causal estimands and confidence intervals asscoaited with Wilcoxon-Mann-Whitney tests in randomized experiments</b>. <em>Statistics in Medicine</em> 37:2923-2937.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BuyseTest">BuyseTest</a></code> for performing a generalized pairwise comparison. <br />
<code><a href="#topic+S4BuyseTest-model.tables">S4BuyseTest-model.tables</a></code> to obtain the table displayed at the end of the summary method in a <code>data.frame</code> format.
<code><a href="#topic+S4BuyseTest-confint">S4BuyseTest-confint</a></code> to output estimate, standard errors, confidence interval and p-values.
<code><a href="#topic+S4BuyseTest-plot">S4BuyseTest-plot</a></code> for a graphical display of the scoring of the pairs.
<code><a href="#topic+BuyseMultComp">BuyseMultComp</a></code> for efficient adjustment for multiple comparisons.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(data.table)

dt &lt;- simBuyseTest(1e2, n.strata = 3)

 ## Not run: 
 BT &lt;- BuyseTest(treatment ~ TTE(eventtime, status = status) + Bin(toxicity), data=dt)
 
## End(Not run)
 
 summary(BT)
 summary(BT, percentage = FALSE)
 summary(BT, statistic = "winRatio")

</code></pre>

<hr>
<h2 id='sensitivity'>Sensitivity Analysis for the Choice of the Thresholds</h2><span id='topic+sensitivity'></span><span id='topic+S4BuyseTest-sensitivity'></span><span id='topic+sensitivity+2CS4BuyseTest-method'></span>

<h3>Description</h3>

<p>Evaluate a summary statistic (net benefit, win ratio, ...) using GPC along various thresholds of clinical relevance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sensitivity(object, ...)

## S4 method for signature 'S4BuyseTest'
sensitivity(
  object,
  threshold,
  statistic = NULL,
  band = FALSE,
  conf.level = NULL,
  null = NULL,
  transformation = NULL,
  alternative = NULL,
  adj.p.value = FALSE,
  trace = TRUE,
  cpus = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sensitivity_+3A_object">object</code></td>
<td>
<p>an <span class="rlang"><b>R</b></span> object of class <code><a href="#topic+S4BuyseTest-class">S4BuyseTest</a></code>, i.e., output of <code><a href="#topic+BuyseTest">BuyseTest</a></code></p>
</td></tr>
<tr><td><code id="sensitivity_+3A_...">...</code></td>
<td>
<p>argument passsed to the function <code>transformCIBP</code> of the riskRegression package.</p>
</td></tr>
<tr><td><code id="sensitivity_+3A_threshold">threshold</code></td>
<td>
<p>[list] a list containing for each endpoint the thresholds to be considered.</p>
</td></tr>
<tr><td><code id="sensitivity_+3A_statistic">statistic</code></td>
<td>
<p>[character] the statistic summarizing the pairwise comparison:
<code>"netBenefit"</code> displays the net benefit, as described in Buyse (2010) and Peron et al. (2016)),
<code>"winRatio"</code> displays the win ratio, as described in Wang et al. (2016),
<code>"favorable"</code> displays the proportion in favor of the treatment (also called Mann-Whitney parameter), as described in Fay et al. (2018).
<code>"unfavorable"</code> displays the proportion in favor of the control.
Default value read from <code>BuyseTest.options()</code>.</p>
</td></tr>
<tr><td><code id="sensitivity_+3A_band">band</code></td>
<td>
<p>[logical] should simulateneous confidence intervals be computed?</p>
</td></tr>
<tr><td><code id="sensitivity_+3A_conf.level">conf.level</code></td>
<td>
<p>[numeric] confidence level for the confidence intervals.
Default value read from <code>BuyseTest.options()</code>.</p>
</td></tr>
<tr><td><code id="sensitivity_+3A_null">null</code></td>
<td>
<p>[numeric] right hand side of the null hypothesis (used for the computation of the p-value).</p>
</td></tr>
<tr><td><code id="sensitivity_+3A_transformation">transformation</code></td>
<td>
<p>[logical]  should the CI be computed on the logit scale / log scale for the net benefit / win ratio and backtransformed.
Otherwise they are computed without any transformation.
Default value read from <code>BuyseTest.options()</code>. Not relevant when using permutations or percentile bootstrap.</p>
</td></tr>
<tr><td><code id="sensitivity_+3A_alternative">alternative</code></td>
<td>
<p>[character] the type of alternative hypothesis: <code>"two.sided"</code>, <code>"greater"</code>, or <code>"less"</code>.
Default value read from <code>BuyseTest.options()</code>.</p>
</td></tr>
<tr><td><code id="sensitivity_+3A_adj.p.value">adj.p.value</code></td>
<td>
<p>[logical] should p-value adjusted for multiple comparisons be computed?</p>
</td></tr>
<tr><td><code id="sensitivity_+3A_trace">trace</code></td>
<td>
<p>[logical] Should the execution of the function be traced?</p>
</td></tr>
<tr><td><code id="sensitivity_+3A_cpus">cpus</code></td>
<td>
<p>[integer, &gt;0] the number of CPU to use. Default value is 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Simulateneous confidence intervals and adjusted p-values are computed using a single-step max-test approach via the function <code>transformCIBP</code> of the riskRegression package.
</p>


<h3>Value</h3>

<p>An S3 object of class <code>S3sensitivity</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
require(ggplot2)

## simulate data
set.seed(10)
df.data &lt;- simBuyseTest(1e2, n.strata = 2)

## with one endpoint
ff1 &lt;- treatment ~ TTE(eventtime, status = status, threshold = 0.1)
BT1 &lt;- BuyseTest(ff1, data= df.data)
se.BT1 &lt;- sensitivity(BT1, threshold = seq(0,2,0.25), band = TRUE)
plot(se.BT1)

## with two endpoints
ff2 &lt;- update(ff1, .~. + cont(score, threshold = 1))
BT2 &lt;- BuyseTest(ff2, data= df.data)
se.BT2 &lt;- sensitivity(BT2, threshold = list(eventtime = seq(0,2,0.25), score = 0:2),
                      band = TRUE)
plot(se.BT2)
plot(se.BT2, col = NA)

## End(Not run)
</code></pre>

<hr>
<h2 id='simBuyseTest'>Simulation of data for the BuyseTest</h2><span id='topic+simBuyseTest'></span>

<h3>Description</h3>

<p>Simulate categorical, continuous or time to event endpoints, possibly along with a strata variable.
Categorical endpoints are simulated by thresholding a latent Gaussian variable (tobit model),
continuous endpoints are simulated using a Gaussian distribution,
and time to event endpoints are simulated using Weibull distributions for the event of interest, competing events, and censoring.
This function is built upon the <code>lvm</code> and <code>sim</code> functions from the lava package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simBuyseTest(
  n.T,
  n.C = NULL,
  argsBin = list(),
  argsCont = list(),
  argsTTE = list(),
  names.strata = NULL,
  level.strata = NULL,
  n.strata = NULL,
  name.cluster = "id",
  prefix.cluster = NULL,
  name.treatment = "treatment",
  level.treatment = c("C", "T"),
  format = "data.table",
  latent = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simBuyseTest_+3A_n.t">n.T</code></td>
<td>
<p>[integer, &gt;0] number of patients in the treatment arm</p>
</td></tr>
<tr><td><code id="simBuyseTest_+3A_n.c">n.C</code></td>
<td>
<p>[integer, &gt;0] number of patients in the control arm</p>
</td></tr>
<tr><td><code id="simBuyseTest_+3A_argsbin">argsBin</code></td>
<td>
<p>[list] arguments to be passed to <code>simBuyseTest_bin</code>. They specify the distribution parameters of the categorical endpoints.</p>
</td></tr>
<tr><td><code id="simBuyseTest_+3A_argscont">argsCont</code></td>
<td>
<p>[list] arguments to be passed to <code>simBuyseTest_continuous</code>. They specify the distribution parameters of the continuous endpoints.</p>
</td></tr>
<tr><td><code id="simBuyseTest_+3A_argstte">argsTTE</code></td>
<td>
<p>[list]  arguments to be passed to <code>simBuyseTest_TTE</code>. They specify the distribution parameters of the time to event endpoints.</p>
</td></tr>
<tr><td><code id="simBuyseTest_+3A_names.strata">names.strata</code></td>
<td>
<p>[character vector] name of the strata variables. Must have same length as <code>n.strata</code>.</p>
</td></tr>
<tr><td><code id="simBuyseTest_+3A_level.strata">level.strata</code></td>
<td>
<p>[list of character vector] value associated to each strata. Must have same length as <code>n.strata</code>.</p>
</td></tr>
<tr><td><code id="simBuyseTest_+3A_n.strata">n.strata</code></td>
<td>
<p>[integer, &gt;0] number of strata. <code>NULL</code> indicates no strata.</p>
</td></tr>
<tr><td><code id="simBuyseTest_+3A_name.cluster">name.cluster</code></td>
<td>
<p>[character] name of the cluster variable. If <code>NULL</code> no cluster variable is created.</p>
</td></tr>
<tr><td><code id="simBuyseTest_+3A_prefix.cluster">prefix.cluster</code></td>
<td>
<p>[character] character string to be added to the cluster index.</p>
</td></tr>
<tr><td><code id="simBuyseTest_+3A_name.treatment">name.treatment</code></td>
<td>
<p>[character] name of the treatment variable.</p>
</td></tr>
<tr><td><code id="simBuyseTest_+3A_level.treatment">level.treatment</code></td>
<td>
<p>[character vector of length 2] levels of the treatment variable.</p>
</td></tr>
<tr><td><code id="simBuyseTest_+3A_format">format</code></td>
<td>
<p>[character] the format of the output. Can be <code>"data.table"</code>, <code>"data.frame"</code> or <code>"matrix"</code>.</p>
</td></tr>
<tr><td><code id="simBuyseTest_+3A_latent">latent</code></td>
<td>
<p>[logical] If <code>TRUE</code> also export the latent variables (e.g. censoring times or event times).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Endpoints are simulated independently of the strata variable and independently of each other,
with the exception of categorical endpoint and the time to event endpoints that can be correlated
by specifying a non-0 value for the <code>rho.T</code> and <code>rho.C</code> elements of the argument <code>argsBin</code>.
</p>
<p>Arguments in the list <code>argsBin</code>:
</p>

<ul>
<li><p><code>p.T</code> list of probabilities for the values taken by each endpoint (categorical endpoint, treatment group). 
</p>
</li>
<li><p><code>p.C</code> same as <code>p.T</code> but for the control group. 
</p>
</li>
<li><p><code>rho.T</code> value of the regression coefficient between the underlying latent variable and the survival time.
Only implemented for weibull distributed survival times.
</p>
</li>
<li><p><code>rho.C</code> same as <code>rho.T</code> but for the control group. 
</p>
</li>
<li><p><code>name</code> names of the binary variables.
</p>
</li></ul>

<p>Arguments in the list <code>argsCont</code>:
</p>

<ul>
<li><p><code>mu.T</code> expected value of each endpoint (continuous endpoint, treatment group). 
</p>
</li>
<li><p><code>mu.C</code> same as <code>mu.C</code> but for the control group. 
</p>
</li>
<li><p><code>sigma.T</code> standard deviation of the values of each endpoint (continuous endpoint, treatment group). 
</p>
</li>
<li><p><code>sigma.C</code> same as <code>sigma.T</code> but for the control group. 
</p>
</li>
<li><p><code>name</code> names of the continuous variables.
</p>
</li></ul>

<p>Arguments in the list <code>argsTTE</code>:
</p>

<ul>
<li><p><code>CR</code> should competing risks be simulated? 
</p>
</li>
<li><p><code>scale.T,scale.C,scale.CR,scale.censoring.T,scale.censoring.C</code> scale parameter of the Weibull distribution for, respectively,
the event of interest in the treatment group,
the event of interest in the control group,
the competing event in both groups,
the censoring mechanism in the treatment group,
the censoring mechanism in the control group
</p>
</li>
<li><p><code>shape.T,shape.C,shape.CR,shape.censoring.T,shape.censoring.C</code> shape parameter of the Weibull distribution for, respectively,
the event of interest in the treatment group,
the event of interest in the control group,
the competing event in both groups,
the censoring mechanism in the treatment group,
the censoring mechanism in the control group
</p>
</li>
<li><p><code>dist.T,dist.C,dist.CR,dist.censoring.T,dist.censoring.C</code> type of distribution (<code>"weibull"</code>, <code>"uniform"</code>, <code>"piecewiseExp"</code>) for, respectively,
the event of interest in the treatment group,
the event of interest in the control group,
the competing event in both groups,
the censoring mechanism in the treatment group,
the censoring mechanism in the control group.
For uniform distirbutions the (scale,shape) parameters becomes the support (min, max) of the censoring distribution.
For piecewise exponential distributions the (scale,shape) should be lists of numeric (see example)
and the shape parameters becomes the time parameters (first element should be 0).
</p>
</li>
<li><p><code>name</code> names of the time to event variables. 
</p>
</li>
<li><p><code>name.censoring</code> names of the event type indicators. #'      
</p>
</li></ul>



<h3>Value</h3>

<p>A data.frame, data.table, or matrix depending of the argument <code>format</code>.
</p>


<h3>Author(s)</h3>

<p>Brice Ozenne
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(data.table)

n &lt;- 1e2

#### by default ####
simBuyseTest(n)

## with a strata variable having 5 levels
simBuyseTest(n, n.strata = 5)
## with a strata variable named grade
simBuyseTest(n, n.strata = 5, names.strata = "grade")
## several strata variables
simBuyseTest(1e3, n.strata = c(2,4), names.strata = c("Gender","AgeCategory"))

#### only categorical endpoints ####
args &lt;- list(p.T = list(c(low=0.1,moderate=0.5,high=0.4)))
dt.bin &lt;- simBuyseTest(n, argsBin = args, argsCont = NULL, argsTTE = NULL)
table(dt.bin$toxicity)/NROW(dt.bin)

args &lt;- list(p.T = list(c(low=0.1,moderate=0.5,high=0.4), c(0.1,0.9)))
dt.bin &lt;- simBuyseTest(n, argsBin = args, argsCont = NULL, argsTTE = NULL)
table(dt.bin$toxicity1)/NROW(dt.bin)
table(dt.bin$toxicity2)/NROW(dt.bin)

#### only continuous endpoints ####
args &lt;- list(mu.T = c(3:5/10), sigma.T = rep(1,3))
dt.cont &lt;- simBuyseTest(n, argsBin = NULL, argsCont = args, argsTTE = NULL)
c(mean(dt.cont$score1), mean(dt.cont$score2), mean(dt.cont$score3))
c(sd(dt.cont$score1), sd(dt.cont$score2), sd(dt.cont$score3))

#### only TTE endpoints ####
## weibull distributed
args &lt;- list(scale.T = c(3:5/10), scale.censoring.T = rep(1,3))
dt.tte &lt;- simBuyseTest(n, argsBin = NULL, argsCont = NULL, argsTTE = args)
1/c(sum(dt.tte$eventtime1)/sum(dt.tte$status1),
  sum(dt.tte$eventtime2)/sum(dt.tte$status2),
  sum(dt.tte$eventtime3)/sum(dt.tte$status3))
        
1/c(sum(dt.tte$eventtime1)/sum(dt.tte$status1==0),
  sum(dt.tte$eventtime2)/sum(dt.tte$status2==0),
  sum(dt.tte$eventtime3)/sum(dt.tte$status3==0))

hist(dt.tte$eventtime1)

## uniform distributed
args &lt;- list(scale.T = 0, shape.T = 1, dist.T = "uniform", scale.censoring.T = 1e5,
             scale.C = 0, shape.C = 2, dist.C = "uniform", scale.censoring.C = 1e5)
dt.tte &lt;- simBuyseTest(n, argsBin = NULL, argsCont = NULL, argsTTE = args)

par(mfrow=c(1,2))
hist(dt.tte$eventtime[dt.tte$treatment=="C"])
hist(dt.tte$eventtime[dt.tte$treatment=="T"])

## piecewise constant exponential distributed
## time [0;4]: scale parameter 10
## time [4;12]: scale parameter 13
## time [12;18.]: scale parameter 18
## time [18.5;36]: scale parameter 31
## after that: scale parameter 37
vec.scale &lt;- list(c(10,13,18,31,100))
vec.time &lt;- list(c(0,4,12,18.5,36))
args &lt;- list(scale.T = vec.scale, shape.T = vec.time, dist.T = "piecewiseExp",
             scale.C = 10, shape.C = 1, dist.C = "weibull",
             scale.censoring.T = 1e5)
dt.tte &lt;- simBuyseTest(n, argsBin = NULL, argsCont = NULL, argsTTE = args)

if(require(prodlim)){
plot(prodlim(Hist(eventtime,status)~treatment, data = dt.tte))
}

#### correlated categorical / time to event endpoint ####
## WARNING: only for weibull distributed time to event endpoint
args.bin &lt;- list(p.T = list(c(low=0.1,moderate=0.5,high=0.4)), rho.T = 1)
args.tte &lt;- list(scale.T = 2, scale.censoring.T = 1)
dt.corr &lt;- simBuyseTest(n, argsBin = args.bin, argsCont = NULL, argsTTE = args.tte)

1/(sum(dt.corr$eventtime)/sum(dt.corr$status))
1/(sum(dt.corr$eventtime)/sum(dt.corr$status==0))
table(dt.corr$toxicity)/NROW(dt.corr)

boxplot(eventtime ~ toxicity, data = dt.corr)

</code></pre>

<hr>
<h2 id='simCompetingRisks'>Simulation of Gompertz competing risks data for the BuyseTest</h2><span id='topic+simCompetingRisks'></span>

<h3>Description</h3>

<p>Simulate Gompertz competing risks data with proportional (via prespecified sub-distribution hazard ratio) or
non-proportional sub-distribution hazards. A treatment variable with two groups (treatment and control) is created.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simCompetingRisks(
  n.T,
  n.C,
  p.1C = NULL,
  v.1C,
  v.1T,
  v.2C,
  v.2T,
  sHR = NULL,
  b.1T = NULL,
  b.1C = NULL,
  b.2T = NULL,
  b.2C = NULL,
  cens.distrib = NULL,
  param.cens = NULL,
  latent = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simCompetingRisks_+3A_n.t">n.T</code></td>
<td>
<p>[integer, &gt;0] number of patients in the treatment arm</p>
</td></tr>
<tr><td><code id="simCompetingRisks_+3A_n.c">n.C</code></td>
<td>
<p>[integer, &gt;0] number of patients in the control arm</p>
</td></tr>
<tr><td><code id="simCompetingRisks_+3A_p.1c">p.1C</code></td>
<td>
<p>[integer, &gt;0] proportion of events of interest in the control group. Can be NULL if and only if <code>(b.1T, b.1C, b.2T, b.2C)</code>
are provided.</p>
</td></tr>
<tr><td><code id="simCompetingRisks_+3A_v.1c">v.1C</code>, <code id="simCompetingRisks_+3A_v.1t">v.1T</code>, <code id="simCompetingRisks_+3A_v.2c">v.2C</code>, <code id="simCompetingRisks_+3A_v.2t">v.2T</code></td>
<td>
<p>[double, &lt;0] shape parameters for Gompertz distribution of time to event of interest in control/treatment (C/T) 
group and of time to competing event in control/treatment (C/T) group respectively</p>
</td></tr>
<tr><td><code id="simCompetingRisks_+3A_shr">sHR</code></td>
<td>
<p>[double, &gt;0] pre-specified sub-distribution hazard ratio for event of interest. Can be NULL if and only if 
<code>(b.1T, b.1C, b.2T, b.2C)</code> are provided.</p>
</td></tr>
<tr><td><code id="simCompetingRisks_+3A_b.1c">b.1C</code>, <code id="simCompetingRisks_+3A_b.1t">b.1T</code>, <code id="simCompetingRisks_+3A_b.2c">b.2C</code>, <code id="simCompetingRisks_+3A_b.2t">b.2T</code></td>
<td>
<p>[double, &gt;0] rate parameters for Gompertz distribution of time to event of interest in control/treatment (C/T) 
group and of time to competing event in control/treatment (C/T) group respectively. Can be NULL if and only if <code>(p.1C, sHR)</code> are 
provided.</p>
</td></tr>
<tr><td><code id="simCompetingRisks_+3A_cens.distrib">cens.distrib</code></td>
<td>
<p>[character] censoring distribution. Can be <code>"exponential"</code> for exponential censoring or <code>"uniform"</code> for
uniform censoring. NULL means no censoring.</p>
</td></tr>
<tr><td><code id="simCompetingRisks_+3A_param.cens">param.cens</code></td>
<td>
<p>[&gt;0] parameter for censoring distribution. Should be a double for rate parameter of exponential censoring distribution 
or a vector of doubles for lower and upper bounds of uniform censoring distribution. NULL means no censoring</p>
</td></tr>
<tr><td><code id="simCompetingRisks_+3A_latent">latent</code></td>
<td>
<p>[logical] If <code>TRUE</code>, also export the latent variables (e.g. true event times, true event types and censoring times). 
NULL sets this parameter to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The times to the event of interest and to the competing event in each group follow an improper Gompertz distribution 
(see Jeong and Fine, 2006), whose cumulative distribution function is 
</p>
<p>F(t; b, v) = 1 - exp(b (1 - exp (v t)) / v) <br /> 
</p>
<p>and hazard functions is
</p>
<p>h(t; b, v) = b exp(v t)<br /> 
</p>
<p>The shape parameters must be negative to have improper distributions for the times to the two events in each group. Note however that 
in each group, the overall cumulative incidence function must be proper (i.e. the maximum values of the cumulative incidence of each 
event type sum up to 1 in each group). When only providing the shape parameters, the rate parameters are
computed to fulfill this condition. In case you whish to provide the rate parameters too, make sure that the condition is met.
</p>


<h3>Value</h3>

<p>A data.frame
</p>


<h3>Author(s)</h3>

<p>Eva Cantagallo
</p>


<h3>References</h3>

<p>Jeong J-H. and Fine J. (2006) <b>Direct parametric inference for the cumulative incidence function</b>. <em>Journal of the Royal Statistical
Society</em> 55: 187-200 <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#### Providing p.1C and sHR ####
d &lt;- simCompetingRisks(n.T = 100, n.C = 100, p.1C = 0.55, v.1C = -0.30, 
v.1T = -0.30, v.2C = -0.30, v.2T = -0.30, sHR = 0.5, b.1T = NULL, 
b.1C = NULL, b.2T = NULL, b.2C = NULL)

#### Providing the rate parameters ####
d &lt;- simCompetingRisks(n.T = 100, n.C = 100, p.1C = NULL, v.1C = -0.30, 
v.1T = -0.30, v.2C = -0.30, v.2T = -0.30, sHR = NULL, b.1T = 0.12, 
b.1C = 0.24, b.2T = 0.33, b.2C = 0.18)

#### With exponential censoring ####
d &lt;- simCompetingRisks(n.T = 100, n.C = 100, p.1C = 0.55, v.1C = -0.30, 
v.1T = -0.30, v.2C = -0.30, v.2T = -0.30, sHR = 0.5, b.1T = NULL, 
b.1C = NULL, b.2T = NULL, b.2C = NULL, cens.distrib = "exponential", 
param.cens = 0.8, latent = TRUE)

### With uniform censoring ####
d &lt;- simCompetingRisks(n.T = 100, n.C = 100, p.1C = 0.55, v.1C = -0.30, 
v.1T = -0.30, v.2C = -0.30, v.2T = -0.30, sHR = 0.5, b.1T = NULL, 
b.1C = NULL, b.2T = NULL, b.2C = NULL, cens.distrib = "uniform", 
param.cens = c(0, 7), latent=TRUE)        

</code></pre>

<hr>
<h2 id='summary.performance'>Summary Method for Performance Objects</h2><span id='topic+summary.performance'></span>

<h3>Description</h3>

<p>Summary of the performance of binary classifiers
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'performance'
summary(object, order.model = NULL, digits = c(3, 3), print = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.performance_+3A_object">object</code></td>
<td>
<p>output of performance.</p>
</td></tr>
<tr><td><code id="summary.performance_+3A_order.model">order.model</code></td>
<td>
<p>[character vector] ordering of the models.</p>
</td></tr>
<tr><td><code id="summary.performance_+3A_digits">digits</code></td>
<td>
<p>[numeric vector of length 2] number of digits used for the estimates and p-values.</p>
</td></tr>
<tr><td><code id="summary.performance_+3A_print">print</code></td>
<td>
<p>[logical] should the performance be printed in the console.</p>
</td></tr>
<tr><td><code id="summary.performance_+3A_...">...</code></td>
<td>
<p>not used.</p>
</td></tr>
</table>

<hr>
<h2 id='validFCTs'>Check Arguments of a function.</h2><span id='topic+validFCTs'></span><span id='topic+validCharacter'></span><span id='topic+validClass'></span><span id='topic+validDimension'></span><span id='topic+validInteger'></span><span id='topic+validLogical'></span><span id='topic+validNames'></span><span id='topic+validNumeric'></span><span id='topic+validPath'></span>

<h3>Description</h3>

<p>Check the validity of the arguments in functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validCharacter(
  value1,
  name1 = as.character(substitute(value1)),
  valid.length,
  valid.values = "character",
  refuse.NULL = TRUE,
  refuse.duplicates = FALSE,
  method = NULL,
  addPP = TRUE
)

validClass(
  value1,
  name1 = as.character(substitute(value1)),
  valid.class,
  type = "inherits",
  method = NULL,
  addPP = TRUE
)

validDimension(
  value1,
  value2 = NULL,
  name1 = as.character(substitute(value1)),
  name2 = as.character(substitute(value2)),
  valid.dimension = NULL,
  type = c("NROW", "NCOL"),
  method = NULL,
  addPP = TRUE
)

validInteger(
  value1,
  name1 = as.character(substitute(value1)),
  valid.length,
  min = NULL,
  max = NULL,
  refuse.NA = TRUE,
  refuse.NULL = TRUE,
  refuse.duplicates = FALSE,
  method = NULL,
  addPP = TRUE
)

validLogical(
  value1,
  name1 = as.character(substitute(value1)),
  valid.length,
  refuse.NULL = TRUE,
  refuse.NA = TRUE,
  method = NULL,
  addPP = TRUE
)

validNames(
  value1,
  name1 = as.character(substitute(value1)),
  refuse.NULL = TRUE,
  valid.length = NULL,
  valid.values = NULL,
  required.values = NULL,
  refuse.values = NULL,
  method = NULL,
  addPP = TRUE
)

validNumeric(
  value1,
  name1 = as.character(substitute(value1)),
  valid.length,
  valid.values = NULL,
  min = NULL,
  max = NULL,
  refuse.NA = TRUE,
  refuse.NULL = TRUE,
  refuse.duplicates = FALSE,
  method = NULL,
  addPP = TRUE,
  unlist = FALSE
)

validPath(
  value1,
  name1 = as.character(substitute(value1)),
  type,
  method = NULL,
  addPP = TRUE,
  extension = NULL,
  check.fsep = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validFCTs_+3A_value1">value1</code></td>
<td>
<p>the value of the (first) argument to be checked</p>
</td></tr>
<tr><td><code id="validFCTs_+3A_name1">name1</code></td>
<td>
<p>the name of the (first) argument.</p>
</td></tr>
<tr><td><code id="validFCTs_+3A_valid.length">valid.length</code></td>
<td>
<p>the acceptable length(s) for the argument. If <code>NULL</code> no test is performed.</p>
</td></tr>
<tr><td><code id="validFCTs_+3A_valid.values">valid.values</code></td>
<td>
<p>the acceptable value(s) for the argument. If <code>NULL</code> no test is performed. Can also be &quot;character&quot; or &quot;character_or_logical&quot;.</p>
</td></tr>
<tr><td><code id="validFCTs_+3A_refuse.null">refuse.NULL</code></td>
<td>
<p>should an error be output if value is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="validFCTs_+3A_refuse.duplicates">refuse.duplicates</code></td>
<td>
<p>should an error be output if value contains duplicated values.</p>
</td></tr>
<tr><td><code id="validFCTs_+3A_method">method</code></td>
<td>
<p>the name of the function using the argument.</p>
</td></tr>
<tr><td><code id="validFCTs_+3A_addpp">addPP</code></td>
<td>
<p>add &quot;: &quot; after the name of the function in the error message.</p>
</td></tr>
<tr><td><code id="validFCTs_+3A_type">type</code></td>
<td>
<p>For <code>validDimension</code>: the type of operator used to check the dimensions. For <code>validPath</code> either &quot;dir&quot; or &quot;file&quot; to check whether to path points to an existing directory or file.</p>
</td></tr>
<tr><td><code id="validFCTs_+3A_value2">value2</code></td>
<td>
<p>the second value of a second argument whose dimensions should be consistent with the first one</p>
</td></tr>
<tr><td><code id="validFCTs_+3A_name2">name2</code></td>
<td>
<p>the name of the second argument.</p>
</td></tr>
<tr><td><code id="validFCTs_+3A_min">min</code></td>
<td>
<p>the minimum acceptable value</p>
</td></tr>
<tr><td><code id="validFCTs_+3A_max">max</code></td>
<td>
<p>the maximum acceptable value</p>
</td></tr>
<tr><td><code id="validFCTs_+3A_refuse.na">refuse.NA</code></td>
<td>
<p>should an error be output if value contains <code>NA</code>.</p>
</td></tr>
<tr><td><code id="validFCTs_+3A_required.values">required.values</code></td>
<td>
<p>values that must appear in the argument</p>
</td></tr>
<tr><td><code id="validFCTs_+3A_refuse.values">refuse.values</code></td>
<td>
<p>values that must not appear in the argument</p>
</td></tr>
<tr><td><code id="validFCTs_+3A_unlist">unlist</code></td>
<td>
<p>[logical] flatten argument before check.</p>
</td></tr>
<tr><td><code id="validFCTs_+3A_extension">extension</code></td>
<td>
<p>filter the files by the type of extension.</p>
</td></tr>
<tr><td><code id="validFCTs_+3A_check.fsep">check.fsep</code></td>
<td>
<p>display a warning when the separator is not correctly specified in</p>
</td></tr>
<tr><td><code id="validFCTs_+3A_validclass">validClass</code></td>
<td>
<p>the acceptable classes(s) for the argument.</p>
</td></tr>
<tr><td><code id="validFCTs_+3A_validdimension">validDimension</code></td>
<td>
<p>the acceptable dimension for the argument. If <code>NULL</code> then name2 is used as a reference.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An invisible <code>TRUE</code> or an error message.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
