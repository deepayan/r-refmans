<!DOCTYPE html><html><head><title>Help for package pathling</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {pathling}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#conditions'><p>Synthetic conditions data</p></a></li>
<li><a href='#ds_aggregate'><p>Execute an aggregate query</p></a></li>
<li><a href='#ds_extract'><p>Execute an extract query</p></a></li>
<li><a href='#ds_read'><p>Get data for a resource type from a data source</p></a></li>
<li><a href='#ds_write_delta'><p>Write FHIR data to Delta files</p></a></li>
<li><a href='#ds_write_ndjson'><p>Write FHIR data to NDJSON files</p></a></li>
<li><a href='#ds_write_parquet'><p>Write FHIR data to Parquet files</p></a></li>
<li><a href='#ds_write_tables'><p>Write FHIR data to managed tables</p></a></li>
<li><a href='#Equivalence'><p>Concept map equivalence types</p></a></li>
<li><a href='#ImportMode'><p>ImportMode</p></a></li>
<li><a href='#LOINC_URI'><p>LOINC system URI</p></a></li>
<li><a href='#MimeType'><p>FHIR MIME types</p></a></li>
<li><a href='#pathling_connect'><p>Create or retrieve the Pathling context</p></a></li>
<li><a href='#pathling_disconnect'><p>Disconnect from the Spark session</p></a></li>
<li><a href='#pathling_disconnect_all'><p>Disconnect all Spark connections</p></a></li>
<li><a href='#pathling_encode'><p>Encode FHIR JSON or XML to a dataframe</p></a></li>
<li><a href='#pathling_encode_bundle'><p>Encode FHIR Bundles to a dataframe</p></a></li>
<li><a href='#pathling_example_resource'><p>Read resource from Pathling example data</p></a></li>
<li><a href='#pathling_examples'><p>Get path to Pathling example data</p></a></li>
<li><a href='#pathling_install_spark'><p>Install Spark</p></a></li>
<li><a href='#pathling_is_spark_installed'><p>Check if Spark is installed</p></a></li>
<li><a href='#pathling_read_bundles'><p>Create a data source from FHIR bundles</p></a></li>
<li><a href='#pathling_read_datasets'><p>Create a data source from datasets</p></a></li>
<li><a href='#pathling_read_delta'><p>Create a data source from Delta tables</p></a></li>
<li><a href='#pathling_read_ndjson'><p>Create a data source from NDJSON</p></a></li>
<li><a href='#pathling_read_parquet'><p>Create a data source from Parquet tables</p></a></li>
<li><a href='#pathling_read_tables'><p>Create a data source from managed tables</p></a></li>
<li><a href='#pathling_spark'><p>Get the Spark session</p></a></li>
<li><a href='#pathling_spark_info'><p>Get versions of Spark and other dependencies</p></a></li>
<li><a href='#pathling_version'><p>Get version of Pathling</p></a></li>
<li><a href='#PropertyType'><p>Coding property data types</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#SNOMED_URI'><p>SNOMED CT system URI</p></a></li>
<li><a href='#StorageType'><p>Terminology cache storage type</p></a></li>
<li><a href='#to_array'><p>Convert a vector to a SQL array literal</p></a></li>
<li><a href='#tx_designation'><p>Get designations for codings</p></a></li>
<li><a href='#tx_display'><p>Get the display text for codings</p></a></li>
<li><a href='#tx_member_of'><p>Test membership within a value set</p></a></li>
<li><a href='#tx_property_of'><p>Get properties for codings</p></a></li>
<li><a href='#tx_subsumed_by'><p>Test subsumption between codings</p></a></li>
<li><a href='#tx_subsumes'><p>Test subsumption between codings</p></a></li>
<li><a href='#tx_to_coding'><p>Convert codes to Coding structures</p></a></li>
<li><a href='#tx_to_ecl_value_set'><p>Convert a SNOMED CT ECL expression to a ValueSet URI</p></a></li>
<li><a href='#tx_to_loinc_coding'><p>Convert LOINC codes to Coding structures</p></a></li>
<li><a href='#tx_to_snomed_coding'><p>Convert SNOMED CT codes to Coding structures</p></a></li>
<li><a href='#tx_translate'><p>Translate between value sets</p></a></li>
<li><a href='#Version'><p>FHIR versions</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>A Library for using 'Pathling'</td>
</tr>
<tr>
<td>Version:</td>
<td>6.4.2</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>"Australian e-Health Research Centre, CSIRO" &lt;ontoserver-support@csiro.au&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>R API for 'Pathling', a tool for querying and transforming electronic health record data that is represented using the 'Fast Healthcare Interoperability Resources' (FHIR) standard - see <a href="https://pathling.csiro.au/docs">https://pathling.csiro.au/docs</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License 2.0</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://pathling.csiro.au/">https://pathling.csiro.au/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/aehrc/pathling/issues">https://github.com/aehrc/pathling/issues</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>rlang(&ge; 1.0.0), sparklyr(&ge; 1.8.4)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat(&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>Spark: 3.4.x</td>
</tr>
<tr>
<td>Config/pathling/Version:</td>
<td>6.4.2</td>
</tr>
<tr>
<td>Config/pathling/SparkVersion:</td>
<td>3.4.0</td>
</tr>
<tr>
<td>Config/pathling/ScalaVersion:</td>
<td>2.12</td>
</tr>
<tr>
<td>Config/pathling/HadoopMajorVersion:</td>
<td>3</td>
</tr>
<tr>
<td>Config/pathling/HadoopVersion:</td>
<td>3.3.4</td>
</tr>
<tr>
<td>Config/pathling/DeltaVersion:</td>
<td>2.4.0</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-12-21 01:35:57 UTC; runner</td>
</tr>
<tr>
<td>Author:</td>
<td>Australian e-Health Research Centre, CSIRO [cph, cre],
  Piotr Szul [aut],
  John Grimes [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-12-21 04:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='conditions'>Synthetic conditions data</h2><span id='topic+conditions'></span>

<h3>Description</h3>

<p>A synthetic data set of simplified and flattened FHIR Condition resources generated by Synthea.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>conditions
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 19 rows and 6 columns.
</p>


<h3>Details</h3>

<p>A data frame with 19 rows and 6 columns:
</p>

<ul>
<li> <p><code>START</code> - The onset date
</p>
</li>
<li> <p><code>STOP</code> - The abatement date
</p>
</li>
<li> <p><code>PATIENT</code> - The ID of the patient
</p>
</li>
<li> <p><code>ENCOUNTER</code> - The ID of the encounter
</p>
</li>
<li> <p><code>CODE</code> - The SNOMED CT code of the condition
</p>
</li>
<li> <p><code>DESCRIPTION</code> - The display name of the condition
</p>
</li></ul>


<hr>
<h2 id='ds_aggregate'>Execute an aggregate query</h2><span id='topic+ds_aggregate'></span>

<h3>Description</h3>

<p>Executes an aggregate query over FHIR data. The query calculates summary values based on 
aggregations and groupings of FHIR resources.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ds_aggregate(
  ds,
  subject_resource,
  aggregations,
  groupings = NULL,
  filters = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ds_aggregate_+3A_ds">ds</code></td>
<td>
<p>The DataSource object containing the data to be queried.</p>
</td></tr>
<tr><td><code id="ds_aggregate_+3A_subject_resource">subject_resource</code></td>
<td>
<p>A string representing the type of FHIR resource to aggregate data from.</p>
</td></tr>
<tr><td><code id="ds_aggregate_+3A_aggregations">aggregations</code></td>
<td>
<p>A named list of FHIRPath expressions that calculate a summary value from each
grouping. The expressions must be singular.</p>
</td></tr>
<tr><td><code id="ds_aggregate_+3A_groupings">groupings</code></td>
<td>
<p>An optional named list of FHIRPath expressions that determine which groupings
the resources should be counted within.</p>
</td></tr>
<tr><td><code id="ds_aggregate_+3A_filters">filters</code></td>
<td>
<p>An optional sequence of FHIRPath expressions that can be evaluated against each resource
in the data set to determine whether it is included within the result. The expression must evaluate to a
Boolean value. Multiple filters are combined using logical AND operation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Spark DataFrame containing the aggregated data.
</p>


<h3>See Also</h3>

<p><a href="https://pathling.csiro.au/docs/libraries/fhirpath-query#aggregate">Pathling documentation - Aggregate</a>
</p>
<p>Other FHIRPath queries: 
<code><a href="#topic+ds_extract">ds_extract</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pc &lt;- pathling_connect()
data_source &lt;- pc %&gt;% pathling_read_ndjson(pathling_examples('ndjson'))
data_source %&gt;% ds_aggregate('Patient',
     aggregations = c(patientCount='count()', 'id.count()'),
     groupings = c('gender', givenName='name.given'),
     filters = c('birthDate &gt; @1950-01-01')
)
pathling_disconnect(pc)

</code></pre>

<hr>
<h2 id='ds_extract'>Execute an extract query</h2><span id='topic+ds_extract'></span>

<h3>Description</h3>

<p>Executes an extract query over FHIR data. This type of query extracts specified columns from 
FHIR resources in a tabular format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ds_extract(ds, subject_resource, columns, filters = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ds_extract_+3A_ds">ds</code></td>
<td>
<p>The DataSource object containing the data to be queried.</p>
</td></tr>
<tr><td><code id="ds_extract_+3A_subject_resource">subject_resource</code></td>
<td>
<p>A string representing the type of FHIR resource to extract data from.</p>
</td></tr>
<tr><td><code id="ds_extract_+3A_columns">columns</code></td>
<td>
<p>A named list of FHIRPath expressions that define the columns to include in the extract.</p>
</td></tr>
<tr><td><code id="ds_extract_+3A_filters">filters</code></td>
<td>
<p>An optional sequence of FHIRPath expressions that can be evaluated against each resource
in the data set to determine whether it is included within the result. The expression must evaluate to a
Boolean value. Multiple filters are combined using AND logic.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Spark DataFrame containing the extracted data.
</p>


<h3>See Also</h3>

<p><a href="https://pathling.csiro.au/docs/libraries/fhirpath-query#extract">Pathling documentation - Extract</a>
</p>
<p>Other FHIRPath queries: 
<code><a href="#topic+ds_aggregate">ds_aggregate</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pc &lt;- pathling_connect()
data_source &lt;- pc %&gt;% pathling_read_ndjson(pathling_examples('ndjson'))
data_source %&gt;% ds_extract('Patient',
     columns = c('gender', givenName='name.given'),
     filters = c('birthDate &gt; @1950-01-01')
)
pathling_disconnect(pc)

</code></pre>

<hr>
<h2 id='ds_read'>Get data for a resource type from a data source</h2><span id='topic+ds_read'></span>

<h3>Description</h3>

<p>Get data for a resource type from a data source
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ds_read(ds, resource_code)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ds_read_+3A_ds">ds</code></td>
<td>
<p>The DataSource object.</p>
</td></tr>
<tr><td><code id="ds_read_+3A_resource_code">resource_code</code></td>
<td>
<p>A string representing the type of FHIR resource to read data from.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Spark DataFrame containing the data for the given resource type.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pc &lt;- pathling_connect()
data_source &lt;- pc %&gt;% pathling_read_ndjson(pathling_examples('ndjson'))
data_source %&gt;% ds_read('Patient') %&gt;% sparklyr::sdf_nrow()
data_source %&gt;% ds_read('Condition') %&gt;% sparklyr::sdf_nrow()
pathling_disconnect(pc)

</code></pre>

<hr>
<h2 id='ds_write_delta'>Write FHIR data to Delta files</h2><span id='topic+ds_write_delta'></span>

<h3>Description</h3>

<p>Writes the data from a data source to a directory of Delta files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ds_write_delta(ds, path, import_mode = ImportMode$OVERWRITE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ds_write_delta_+3A_ds">ds</code></td>
<td>
<p>The DataSource object.</p>
</td></tr>
<tr><td><code id="ds_write_delta_+3A_path">path</code></td>
<td>
<p>The URI of the directory to write the files to.</p>
</td></tr>
<tr><td><code id="ds_write_delta_+3A_import_mode">import_mode</code></td>
<td>
<p>The import mode to use when writing the data - &quot;overwrite&quot; will overwrite any 
existing data, &quot;merge&quot; will merge the new data with the existing data based on resource ID.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects only.
</p>


<h3>See Also</h3>

<p><a href="https://pathling.csiro.au/docs/libraries/fhirpath-query#delta-lake-1">Pathling documentation - Writing Delta</a>
</p>
<p><code><a href="#topic+ImportMode">ImportMode</a></code>
</p>
<p>Other data sink functions: 
<code><a href="#topic+ds_write_ndjson">ds_write_ndjson</a>()</code>,
<code><a href="#topic+ds_write_parquet">ds_write_parquet</a>()</code>,
<code><a href="#topic+ds_write_tables">ds_write_tables</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pc &lt;- pathling_connect()
data_source &lt;- pc %&gt;% pathling_read_ndjson(pathling_examples('ndjson'))

# Write the data to a directory of Delta files.
data_source %&gt;% ds_write_delta(file.path(tempdir(), 'delta'), import_mode = ImportMode$OVERWRITE)

pathling_disconnect(pc)

</code></pre>

<hr>
<h2 id='ds_write_ndjson'>Write FHIR data to NDJSON files</h2><span id='topic+ds_write_ndjson'></span>

<h3>Description</h3>

<p>Writes the data from a data source to a directory of NDJSON files. The files will be named using 
the resource type and the &quot;.ndjson&quot; extension.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ds_write_ndjson(ds, path, file_name_mapper = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ds_write_ndjson_+3A_ds">ds</code></td>
<td>
<p>The DataSource object.</p>
</td></tr>
<tr><td><code id="ds_write_ndjson_+3A_path">path</code></td>
<td>
<p>The URI of the directory to write the files to.</p>
</td></tr>
<tr><td><code id="ds_write_ndjson_+3A_file_name_mapper">file_name_mapper</code></td>
<td>
<p>An optional function that can be used to customise the mapping 
of the resource type to the file name. Currently not implemented.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects only.
</p>


<h3>See Also</h3>

<p><a href="https://pathling.csiro.au/docs/libraries/fhirpath-query#ndjson-1">Pathling documentation - Writing NDJSON</a>
</p>
<p>Other data sink functions: 
<code><a href="#topic+ds_write_delta">ds_write_delta</a>()</code>,
<code><a href="#topic+ds_write_parquet">ds_write_parquet</a>()</code>,
<code><a href="#topic+ds_write_tables">ds_write_tables</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pc &lt;- pathling_connect()
data_source &lt;- pc %&gt;% pathling_read_ndjson(pathling_examples('ndjson'))

# Write the data to a directory of NDJSON files.
data_source %&gt;% ds_write_ndjson(file.path(tempdir(), 'ndjson'))

pathling_disconnect(pc)

</code></pre>

<hr>
<h2 id='ds_write_parquet'>Write FHIR data to Parquet files</h2><span id='topic+ds_write_parquet'></span>

<h3>Description</h3>

<p>Writes the data from a data source to a directory of Parquet files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ds_write_parquet(ds, path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ds_write_parquet_+3A_ds">ds</code></td>
<td>
<p>The DataSource object.</p>
</td></tr>
<tr><td><code id="ds_write_parquet_+3A_path">path</code></td>
<td>
<p>The URI of the directory to write the files to.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects only.
</p>


<h3>See Also</h3>

<p><a href="https://pathling.csiro.au/docs/libraries/fhirpath-query#parquet-1">Pathling documentation - Writing Parquet</a>
</p>
<p>Other data sink functions: 
<code><a href="#topic+ds_write_delta">ds_write_delta</a>()</code>,
<code><a href="#topic+ds_write_ndjson">ds_write_ndjson</a>()</code>,
<code><a href="#topic+ds_write_tables">ds_write_tables</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pc &lt;- pathling_connect()
data_source &lt;- pc %&gt;% pathling_read_ndjson(pathling_examples('ndjson'))

# Write the data to a directory of Parquet files.
data_source %&gt;% ds_write_parquet(file.path(tempdir(), 'parquet'))

pathling_disconnect(pc)

</code></pre>

<hr>
<h2 id='ds_write_tables'>Write FHIR data to managed tables</h2><span id='topic+ds_write_tables'></span>

<h3>Description</h3>

<p>Writes the data from a data source to a set of tables in the Spark catalog.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ds_write_tables(ds, schema = NULL, import_mode = ImportMode$OVERWRITE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ds_write_tables_+3A_ds">ds</code></td>
<td>
<p>The DataSource object.</p>
</td></tr>
<tr><td><code id="ds_write_tables_+3A_schema">schema</code></td>
<td>
<p>The name of the schema to write the tables to.</p>
</td></tr>
<tr><td><code id="ds_write_tables_+3A_import_mode">import_mode</code></td>
<td>
<p>The import mode to use when writing the data - &quot;overwrite&quot; will overwrite any 
existing data, &quot;merge&quot; will merge the new data with the existing data based on resource ID.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects only.
</p>


<h3>See Also</h3>

<p><a href="https://pathling.csiro.au/docs/libraries/fhirpath-query#managed-tables-1">Pathling documentation - Writing managed tables</a>
</p>
<p><code><a href="#topic+ImportMode">ImportMode</a></code>
</p>
<p>Other data sink functions: 
<code><a href="#topic+ds_write_delta">ds_write_delta</a>()</code>,
<code><a href="#topic+ds_write_ndjson">ds_write_ndjson</a>()</code>,
<code><a href="#topic+ds_write_parquet">ds_write_parquet</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Create a temporary warehouse location, which will be used when we call ds_write_tables().
temp_dir_path &lt;- tempfile()
dir.create(temp_dir_path)
sc &lt;- sparklyr::spark_connect(master = "local[*]", config = list(
  "sparklyr.shell.conf" = c(
    paste0("spark.sql.warehouse.dir=", temp_dir_path),
    "spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension",
    "spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog"
  )
), version = pathling_spark_info()$spark_version)

pc &lt;- pathling_connect(sc)
data_source &lt;- pc %&gt;% pathling_read_ndjson(pathling_examples('ndjson'))

# Write the data to a set of Spark tables in the 'default' database.
data_source %&gt;% ds_write_tables("default", import_mode = ImportMode$MERGE)

pathling_disconnect(pc)
unlink(temp_dir_path, recursive = TRUE)

</code></pre>

<hr>
<h2 id='Equivalence'>Concept map equivalence types</h2><span id='topic+Equivalence'></span>

<h3>Description</h3>

<p>The following values are supported:
</p>

<ul>
<li> <p><code>RELATEDTO</code> - The concepts are related to each other, and have at least some overlap in meaning, but the exact relationship is not known.
</p>
</li>
<li> <p><code>EQUIVALENT</code> - The definitions of the concepts mean the same thing (including when structural implications of meaning are considered) (i.e. extensionally identical).
</p>
</li>
<li> <p><code>EQUAL</code> - The definitions of the concepts are exactly the same (i.e. only grammatical differences) and structural implications of meaning are identical or irrelevant (i.e. intentionally identical).
</p>
</li>
<li> <p><code>WIDER</code> - The target mapping is wider in meaning than the source concept.
</p>
</li>
<li> <p><code>SUBSUMES</code> - The target mapping subsumes the meaning of the source concept (e.g. the source is-a target).
</p>
</li>
<li> <p><code>NARROWER</code> - The target mapping is narrower in meaning than the source concept. The sense in which the mapping is narrower SHALL be described in the comments in this case, and applications should be careful when attempting to use these mappings operationally.
</p>
</li>
<li> <p><code>SPECIALIZES</code> - The target mapping specializes the meaning of the source concept (e.g. the target is-a source).
</p>
</li>
<li> <p><code>INEXACT</code> - There is some similarity between the concepts, but the exact relationship is not known.
</p>
</li>
<li> <p><code>UNMATCHED</code> - This is an explicit assertion that there is no mapping between the source and target concept.
</p>
</li>
<li> <p><code>DISJOINT</code> - This is an explicit assertion that the target concept is not in any way related to the source concept.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>Equivalence
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 10.
</p>


<h3>See Also</h3>

<p><a href="https://hl7.org/fhir/R4/valueset-concept-map-equivalence.html">FHIR R4 - ConceptMapEquivalence</a>
</p>

<hr>
<h2 id='ImportMode'>ImportMode</h2><span id='topic+ImportMode'></span>

<h3>Description</h3>

<p>The following import modes are supported:
</p>

<ul>
<li><p><code>OVERWRITE</code>: Overwrite any existing data.
</p>
</li>
<li><p><code>MERGE</code>: Merge the new data with the existing data based on resource ID.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>ImportMode
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 2.
</p>

<hr>
<h2 id='LOINC_URI'>LOINC system URI</h2><span id='topic+LOINC_URI'></span>

<h3>Description</h3>

<p>The URI of the LOINC code system: <code>http://loinc.org</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LOINC_URI
</code></pre>


<h3>Format</h3>

<p>An object of class <code>character</code> of length 1.
</p>


<h3>See Also</h3>

<p><a href="https://terminology.hl7.org/LOINC.html">Using LOINC with HL7 Standards</a>
</p>

<hr>
<h2 id='MimeType'>FHIR MIME types</h2><span id='topic+MimeType'></span>

<h3>Description</h3>

<p>The following MIME types are supported:
</p>

<ul>
<li><p><code>FHIR_JSON</code>: FHIR resources encoded as JSON
</p>
</li>
<li><p><code>FHIR_XML</code>: FHIR resources encoded as XML
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>MimeType
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 2.
</p>


<h3>See Also</h3>

<p><a href="https://hl7.org/fhir/R4/formats.html">FHIR R4 - Resource Formats</a>
</p>

<hr>
<h2 id='pathling_connect'>Create or retrieve the Pathling context</h2><span id='topic+pathling_connect'></span>

<h3>Description</h3>

<p>Creates a Pathling context with the given configuration options.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pathling_connect(
  spark = NULL,
  max_nesting_level = 3,
  enable_extensions = FALSE,
  enabled_open_types = c("boolean", "code", "date", "dateTime", "decimal", "integer",
    "string", "Coding", "CodeableConcept", "Address", "Identifier", "Reference"),
  enable_terminology = TRUE,
  terminology_server_url = "https://tx.ontoserver.csiro.au/fhir",
  terminology_verbose_request_logging = FALSE,
  terminology_socket_timeout = 60000,
  max_connections_total = 32,
  max_connections_per_route = 16,
  terminology_retry_enabled = TRUE,
  terminology_retry_count = 2,
  enable_cache = TRUE,
  cache_max_entries = 2e+05,
  cache_storage_type = StorageType$MEMORY,
  cache_storage_path = NULL,
  cache_default_expiry = 600,
  cache_override_expiry = NULL,
  token_endpoint = NULL,
  enable_auth = FALSE,
  client_id = NULL,
  client_secret = NULL,
  scope = NULL,
  token_expiry_tolerance = 120,
  accept_language = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pathling_connect_+3A_spark">spark</code></td>
<td>
<p>A pre-configured SparkSession instance, use this if you need to control the way
that the session is set up</p>
</td></tr>
<tr><td><code id="pathling_connect_+3A_max_nesting_level">max_nesting_level</code></td>
<td>
<p>Controls the maximum depth of nested element data that is encoded
upon import. This affects certain elements within FHIR resources that contain recursive
references, e.g., QuestionnaireResponse.item.</p>
</td></tr>
<tr><td><code id="pathling_connect_+3A_enable_extensions">enable_extensions</code></td>
<td>
<p>Enables support for FHIR extensions</p>
</td></tr>
<tr><td><code id="pathling_connect_+3A_enabled_open_types">enabled_open_types</code></td>
<td>
<p>The list of types that are encoded within open types, such as
extensions.</p>
</td></tr>
<tr><td><code id="pathling_connect_+3A_enable_terminology">enable_terminology</code></td>
<td>
<p>Enables the use of terminology functions</p>
</td></tr>
<tr><td><code id="pathling_connect_+3A_terminology_server_url">terminology_server_url</code></td>
<td>
<p>The endpoint of a FHIR terminology service (R4) that the server
can use to resolve terminology queries.</p>
</td></tr>
<tr><td><code id="pathling_connect_+3A_terminology_verbose_request_logging">terminology_verbose_request_logging</code></td>
<td>
<p>Setting this option to TRUE will enable additional
logging of the details of requests to the terminology service.</p>
</td></tr>
<tr><td><code id="pathling_connect_+3A_terminology_socket_timeout">terminology_socket_timeout</code></td>
<td>
<p>The maximum period (in milliseconds) that the server should
wait for incoming data from the HTTP service</p>
</td></tr>
<tr><td><code id="pathling_connect_+3A_max_connections_total">max_connections_total</code></td>
<td>
<p>The maximum total number of connections for the client</p>
</td></tr>
<tr><td><code id="pathling_connect_+3A_max_connections_per_route">max_connections_per_route</code></td>
<td>
<p>The maximum number of connections per route for the client</p>
</td></tr>
<tr><td><code id="pathling_connect_+3A_terminology_retry_enabled">terminology_retry_enabled</code></td>
<td>
<p>Controls whether terminology requests that fail for possibly
transient reasons should be retried</p>
</td></tr>
<tr><td><code id="pathling_connect_+3A_terminology_retry_count">terminology_retry_count</code></td>
<td>
<p>The number of times to retry failed terminology requests</p>
</td></tr>
<tr><td><code id="pathling_connect_+3A_enable_cache">enable_cache</code></td>
<td>
<p>Set this to FALSE to disable caching of terminology requests</p>
</td></tr>
<tr><td><code id="pathling_connect_+3A_cache_max_entries">cache_max_entries</code></td>
<td>
<p>Sets the maximum number of entries that will be held in memory</p>
</td></tr>
<tr><td><code id="pathling_connect_+3A_cache_storage_type">cache_storage_type</code></td>
<td>
<p>The type of storage to use for the terminology cache</p>
</td></tr>
<tr><td><code id="pathling_connect_+3A_cache_storage_path">cache_storage_path</code></td>
<td>
<p>The path on disk to use for the cache</p>
</td></tr>
<tr><td><code id="pathling_connect_+3A_cache_default_expiry">cache_default_expiry</code></td>
<td>
<p>The default expiry time for cache entries (in seconds)</p>
</td></tr>
<tr><td><code id="pathling_connect_+3A_cache_override_expiry">cache_override_expiry</code></td>
<td>
<p>If provided, this value overrides the expiry time provided by the
terminology server</p>
</td></tr>
<tr><td><code id="pathling_connect_+3A_token_endpoint">token_endpoint</code></td>
<td>
<p>An OAuth2 token endpoint for use with the client credentials grant</p>
</td></tr>
<tr><td><code id="pathling_connect_+3A_enable_auth">enable_auth</code></td>
<td>
<p>Enables authentication of requests to the terminology server</p>
</td></tr>
<tr><td><code id="pathling_connect_+3A_client_id">client_id</code></td>
<td>
<p>A client ID for use with the client credentials grant</p>
</td></tr>
<tr><td><code id="pathling_connect_+3A_client_secret">client_secret</code></td>
<td>
<p>A client secret for use with the client credentials grant</p>
</td></tr>
<tr><td><code id="pathling_connect_+3A_scope">scope</code></td>
<td>
<p>A scope value for use with the client credentials grant</p>
</td></tr>
<tr><td><code id="pathling_connect_+3A_token_expiry_tolerance">token_expiry_tolerance</code></td>
<td>
<p>The minimum number of seconds that a token should have before
expiry when deciding whether to send it with a terminology request</p>
</td></tr>
<tr><td><code id="pathling_connect_+3A_accept_language">accept_language</code></td>
<td>
<p>The default value of the Accept-Language HTTP header passed to the
terminology server</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If no Spark session is provided and there is not one already present in this process, a new
one will be created.
</p>
<p>If a SparkSession is not provided, and one is already running within the current process, it
will be reused.
</p>
<p>It is assumed that the Pathling library API JAR is already on the classpath. If you are running 
your own cluster, make sure it is on the list of packages.
</p>


<h3>Value</h3>

<p>A Pathling context instance initialized with the specified configuration
</p>


<h3>See Also</h3>

<p>Other context lifecycle functions: 
<code><a href="#topic+pathling_disconnect_all">pathling_disconnect_all</a>()</code>,
<code><a href="#topic+pathling_disconnect">pathling_disconnect</a>()</code>,
<code><a href="#topic+pathling_spark">pathling_spark</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Create PathlingContext for an existing Spark connecton.
sc &lt;- sparklyr::spark_connect(master = "local")
pc &lt;- pathling_connect(spark = sc)
pathling_disconnect(pc)

# Create PathlingContext with a new Spark connection.
pc &lt;- pathling_connect()
spark &lt;- pathling_spark(pc)
pathling_disconnect_all()

</code></pre>

<hr>
<h2 id='pathling_disconnect'>Disconnect from the Spark session</h2><span id='topic+pathling_disconnect'></span>

<h3>Description</h3>

<p>Disconnects the Spark connection associated with a Pathling context.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pathling_disconnect(pc)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pathling_disconnect_+3A_pc">pc</code></td>
<td>
<p>The PathlingContext object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects only.
</p>


<h3>See Also</h3>

<p>Other context lifecycle functions: 
<code><a href="#topic+pathling_connect">pathling_connect</a>()</code>,
<code><a href="#topic+pathling_disconnect_all">pathling_disconnect_all</a>()</code>,
<code><a href="#topic+pathling_spark">pathling_spark</a>()</code>
</p>

<hr>
<h2 id='pathling_disconnect_all'>Disconnect all Spark connections</h2><span id='topic+pathling_disconnect_all'></span>

<h3>Description</h3>

<p>Disconnect all Spark connections
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pathling_disconnect_all()
</code></pre>


<h3>Value</h3>

<p>No return value, called for side effects only.
</p>


<h3>See Also</h3>

<p>Other context lifecycle functions: 
<code><a href="#topic+pathling_connect">pathling_connect</a>()</code>,
<code><a href="#topic+pathling_disconnect">pathling_disconnect</a>()</code>,
<code><a href="#topic+pathling_spark">pathling_spark</a>()</code>
</p>

<hr>
<h2 id='pathling_encode'>Encode FHIR JSON or XML to a dataframe</h2><span id='topic+pathling_encode'></span>

<h3>Description</h3>

<p>Takes a Spark DataFrame with string representations of FHIR resources in the given column and
encodes the resources of the given types as Spark DataFrame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pathling_encode(pc, df, resource_name, input_type = NULL, column = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pathling_encode_+3A_pc">pc</code></td>
<td>
<p>The Pathling context object.</p>
</td></tr>
<tr><td><code id="pathling_encode_+3A_df">df</code></td>
<td>
<p>A Spark DataFrame containing the resources to encode.</p>
</td></tr>
<tr><td><code id="pathling_encode_+3A_resource_name">resource_name</code></td>
<td>
<p>The name of the FHIR resource to extract (e.g., &quot;Condition&quot;, &quot;Observation&quot;).</p>
</td></tr>
<tr><td><code id="pathling_encode_+3A_input_type">input_type</code></td>
<td>
<p>The MIME type of input string encoding. Defaults to &quot;application/fhir+json&quot;.</p>
</td></tr>
<tr><td><code id="pathling_encode_+3A_column">column</code></td>
<td>
<p>The column in which the resources to encode are stored. If set to NULL, the input
DataFrame is assumed to have one column of type string.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Spark DataFrame containing the given type of resources encoded into Spark columns.
</p>


<h3>See Also</h3>

<p>Other encoding functions: 
<code><a href="#topic+pathling_encode_bundle">pathling_encode_bundle</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pc &lt;- pathling_connect()
json_resources_df &lt;- pathling_spark(pc) %&gt;% 
     sparklyr::spark_read_text(path=system.file('extdata','ndjson', 'Condition.ndjson', 
             package='pathling'))
pc %&gt;% pathling_encode(json_resources_df, 'Condition')
pathling_disconnect(pc)

</code></pre>

<hr>
<h2 id='pathling_encode_bundle'>Encode FHIR Bundles to a dataframe</h2><span id='topic+pathling_encode_bundle'></span>

<h3>Description</h3>

<p>Takes a dataframe with string representations of FHIR bundles in the given column and outputs
a dataframe of encoded resources.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pathling_encode_bundle(pc, df, resource_name, input_type = NULL, column = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pathling_encode_bundle_+3A_pc">pc</code></td>
<td>
<p>A Pathling context object.</p>
</td></tr>
<tr><td><code id="pathling_encode_bundle_+3A_df">df</code></td>
<td>
<p>A Spark DataFrame containing the bundles with the resources to encode.</p>
</td></tr>
<tr><td><code id="pathling_encode_bundle_+3A_resource_name">resource_name</code></td>
<td>
<p>The name of the FHIR resource to extract (Condition, Observation, etc.).</p>
</td></tr>
<tr><td><code id="pathling_encode_bundle_+3A_input_type">input_type</code></td>
<td>
<p>The MIME type of the input string encoding. Defaults to 'application/fhir+json'.</p>
</td></tr>
<tr><td><code id="pathling_encode_bundle_+3A_column">column</code></td>
<td>
<p>The column in which the resources to encode are stored. If 'NULL', then the
input DataFrame is assumed to have one column of type string.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Spark DataFrame containing the given type of resources encoded into Spark columns.
</p>


<h3>See Also</h3>

<p>Other encoding functions: 
<code><a href="#topic+pathling_encode">pathling_encode</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pc &lt;- pathling_connect()
json_resources_df &lt;- pathling_spark(pc) %&gt;% 
     sparklyr::spark_read_text(path=system.file('extdata','bundle-xml', package='pathling'), 
         whole = TRUE)
pc %&gt;% pathling_encode_bundle(json_resources_df, 'Condition',
     input_type = MimeType$FHIR_XML, column = 'contents')
pathling_disconnect(pc)

</code></pre>

<hr>
<h2 id='pathling_example_resource'>Read resource from Pathling example data</h2><span id='topic+pathling_example_resource'></span>

<h3>Description</h3>

<p>Reads a FHIR resource dataframe from the package example data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pathling_example_resource(pc, resource_name)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pathling_example_resource_+3A_pc">pc</code></td>
<td>
<p>The PathlingContext object.</p>
</td></tr>
<tr><td><code id="pathling_example_resource_+3A_resource_name">resource_name</code></td>
<td>
<p>The name of the resource to read.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The resources are read from the package example data in the <code>extdata/parquet</code> directory. 
Currently the following resources are available: 'Patient' and 'Condition'.
</p>


<h3>Value</h3>

<p>A Spark DataFrame containing the resource data.
</p>


<h3>See Also</h3>

<p>Other example functions: 
<code><a href="#topic+pathling_examples">pathling_examples</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pc &lt;- pathling_connect()
pathling_example_resource(pc, 'Condition')
pathling_disconnect(pc)

</code></pre>

<hr>
<h2 id='pathling_examples'>Get path to Pathling example data</h2><span id='topic+pathling_examples'></span>

<h3>Description</h3>

<p>Construct the path to the package example data in a platform-independent way.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pathling_examples(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pathling_examples_+3A_...">...</code></td>
<td>
<p>character vector of the path components.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The path to the examples data.
</p>


<h3>See Also</h3>

<p>Other example functions: 
<code><a href="#topic+pathling_example_resource">pathling_example_resource</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pathling_examples('ndjson', 'Condition.ndjson')
</code></pre>

<hr>
<h2 id='pathling_install_spark'>Install Spark</h2><span id='topic+pathling_install_spark'></span>

<h3>Description</h3>

<p>Installs the version of Spark/Hadoop defined in the package metadata using the 
<code>sparklyr::spark_install</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pathling_install_spark()
</code></pre>


<h3>Value</h3>

<p>List with information about the installed version.
</p>


<h3>See Also</h3>

<p>Other installation functions: 
<code><a href="#topic+pathling_is_spark_installed">pathling_is_spark_installed</a>()</code>,
<code><a href="#topic+pathling_spark_info">pathling_spark_info</a>()</code>,
<code><a href="#topic+pathling_version">pathling_version</a>()</code>
</p>

<hr>
<h2 id='pathling_is_spark_installed'>Check if Spark is installed</h2><span id='topic+pathling_is_spark_installed'></span>

<h3>Description</h3>

<p>Checks if the version of Spark/Hadoop required by Pathling is installed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pathling_is_spark_installed()
</code></pre>


<h3>Value</h3>

<p><code>TRUE</code> if the required version of Spark/Hadoop is installed, <code>FALSE</code> otherwise.
</p>


<h3>See Also</h3>

<p>Other installation functions: 
<code><a href="#topic+pathling_install_spark">pathling_install_spark</a>()</code>,
<code><a href="#topic+pathling_spark_info">pathling_spark_info</a>()</code>,
<code><a href="#topic+pathling_version">pathling_version</a>()</code>
</p>

<hr>
<h2 id='pathling_read_bundles'>Create a data source from FHIR bundles</h2><span id='topic+pathling_read_bundles'></span>

<h3>Description</h3>

<p>Creates a data source from a directory containing FHIR bundles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pathling_read_bundles(pc, path, resource_types, mime_type = MimeType$FHIR_JSON)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pathling_read_bundles_+3A_pc">pc</code></td>
<td>
<p>The PathlingContext object.</p>
</td></tr>
<tr><td><code id="pathling_read_bundles_+3A_path">path</code></td>
<td>
<p>The URI of the directory containing the bundles.</p>
</td></tr>
<tr><td><code id="pathling_read_bundles_+3A_resource_types">resource_types</code></td>
<td>
<p>A sequence of resource type codes that should be extracted from the bundles.</p>
</td></tr>
<tr><td><code id="pathling_read_bundles_+3A_mime_type">mime_type</code></td>
<td>
<p>The MIME type of the bundles. Defaults to &quot;application/fhir+json&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A DataSource object that can be used to run queries against the data.
</p>


<h3>See Also</h3>

<p><a href="https://pathling.csiro.au/docs/libraries/fhirpath-query#fhir-bundles">Pathling documentation - Reading Bundles</a>
</p>
<p>Other data source functions: 
<code><a href="#topic+pathling_read_datasets">pathling_read_datasets</a>()</code>,
<code><a href="#topic+pathling_read_delta">pathling_read_delta</a>()</code>,
<code><a href="#topic+pathling_read_ndjson">pathling_read_ndjson</a>()</code>,
<code><a href="#topic+pathling_read_parquet">pathling_read_parquet</a>()</code>,
<code><a href="#topic+pathling_read_tables">pathling_read_tables</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pc &lt;- pathling_connect()
data_source &lt;- pc %&gt;% pathling_read_bundles(pathling_examples('bundle-xml'),
     c("Patient", "Observation"), MimeType$FHIR_XML)
data_source %&gt;% ds_read('Observation') %&gt;% sparklyr::sdf_nrow()
pathling_disconnect(pc)

</code></pre>

<hr>
<h2 id='pathling_read_datasets'>Create a data source from datasets</h2><span id='topic+pathling_read_datasets'></span>

<h3>Description</h3>

<p>Creates an immutable, ad-hoc data source from a named list of Spark datasets indexed with
resource type codes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pathling_read_datasets(pc, resources)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pathling_read_datasets_+3A_pc">pc</code></td>
<td>
<p>The PathlingContext object.</p>
</td></tr>
<tr><td><code id="pathling_read_datasets_+3A_resources">resources</code></td>
<td>
<p>A name list of Spark datasets, where the keys are resource type codes
and the values are the data frames containing the resource data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A DataSource object that can be used to run queries against the data.
</p>


<h3>See Also</h3>

<p><a href="https://pathling.csiro.au/docs/libraries/fhirpath-query#datasets">Pathling documentation - Reading datasets</a>
</p>
<p>Other data source functions: 
<code><a href="#topic+pathling_read_bundles">pathling_read_bundles</a>()</code>,
<code><a href="#topic+pathling_read_delta">pathling_read_delta</a>()</code>,
<code><a href="#topic+pathling_read_ndjson">pathling_read_ndjson</a>()</code>,
<code><a href="#topic+pathling_read_parquet">pathling_read_parquet</a>()</code>,
<code><a href="#topic+pathling_read_tables">pathling_read_tables</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pc &lt;- pathling_connect()
patient_df &lt;- pc %&gt;% pathling_example_resource('Patient')
condition_df &lt;- pc %&gt;% pathling_example_resource('Condition')
data_source &lt;- pc %&gt;% pathling_read_datasets(list(Patient = patient_df, Condition = condition_df))
data_source %&gt;% ds_read('Patient') %&gt;% sparklyr::sdf_nrow()
pathling_disconnect(pc)

</code></pre>

<hr>
<h2 id='pathling_read_delta'>Create a data source from Delta tables</h2><span id='topic+pathling_read_delta'></span>

<h3>Description</h3>

<p><code>pathling_read_delta()</code> creates a data source from a directory containing Delta tables.
Each table must be named according to the name of the resource type that it stores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pathling_read_delta(pc, path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pathling_read_delta_+3A_pc">pc</code></td>
<td>
<p>The PathlingContext object.</p>
</td></tr>
<tr><td><code id="pathling_read_delta_+3A_path">path</code></td>
<td>
<p>The URI of the directory containing the Delta tables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A DataSource object that can be used to run queries against the data.
</p>


<h3>See Also</h3>

<p><a href="https://pathling.csiro.au/docs/libraries/fhirpath-query#delta-lake">Pathling documentation - Reading Delta</a>
</p>
<p>Other data source functions: 
<code><a href="#topic+pathling_read_bundles">pathling_read_bundles</a>()</code>,
<code><a href="#topic+pathling_read_datasets">pathling_read_datasets</a>()</code>,
<code><a href="#topic+pathling_read_ndjson">pathling_read_ndjson</a>()</code>,
<code><a href="#topic+pathling_read_parquet">pathling_read_parquet</a>()</code>,
<code><a href="#topic+pathling_read_tables">pathling_read_tables</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pc &lt;- pathling_connect()
data_source &lt;- pc %&gt;% pathling_read_delta(pathling_examples('delta'))
data_source %&gt;% ds_read('Patient') %&gt;% sparklyr::sdf_nrow()
pathling_disconnect(pc)

</code></pre>

<hr>
<h2 id='pathling_read_ndjson'>Create a data source from NDJSON</h2><span id='topic+pathling_read_ndjson'></span>

<h3>Description</h3>

<p>Creates a data source from a directory containing NDJSON files. The files must be named with the 
resource type code and must have the &quot;.ndjson&quot; extension, e.g. &quot;Patient.ndjson&quot; or 
&quot;Observation.ndjson&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pathling_read_ndjson(pc, path, extension = "ndjson", file_name_mapper = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pathling_read_ndjson_+3A_pc">pc</code></td>
<td>
<p>The PathlingContext object.</p>
</td></tr>
<tr><td><code id="pathling_read_ndjson_+3A_path">path</code></td>
<td>
<p>The URI of the directory containing the NDJSON files.</p>
</td></tr>
<tr><td><code id="pathling_read_ndjson_+3A_extension">extension</code></td>
<td>
<p>The file extension to use when searching for files. Defaults to &quot;ndjson&quot;.</p>
</td></tr>
<tr><td><code id="pathling_read_ndjson_+3A_file_name_mapper">file_name_mapper</code></td>
<td>
<p>An optional function that maps a filename to the set of resource types
that it contains. Currently not implemented.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A DataSource object that can be used to run queries against the data.
</p>


<h3>See Also</h3>

<p><a href="https://pathling.csiro.au/docs/libraries/fhirpath-query#ndjson">Pathling documentation - Reading NDJSON</a>
</p>
<p>Other data source functions: 
<code><a href="#topic+pathling_read_bundles">pathling_read_bundles</a>()</code>,
<code><a href="#topic+pathling_read_datasets">pathling_read_datasets</a>()</code>,
<code><a href="#topic+pathling_read_delta">pathling_read_delta</a>()</code>,
<code><a href="#topic+pathling_read_parquet">pathling_read_parquet</a>()</code>,
<code><a href="#topic+pathling_read_tables">pathling_read_tables</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pc &lt;- pathling_connect()
data_source &lt;- pc %&gt;% pathling_read_ndjson(pathling_examples('ndjson'))
data_source %&gt;% ds_read('Patient') %&gt;% sparklyr::sdf_nrow()
pathling_disconnect(pc)

</code></pre>

<hr>
<h2 id='pathling_read_parquet'>Create a data source from Parquet tables</h2><span id='topic+pathling_read_parquet'></span>

<h3>Description</h3>

<p><code>pathling_read_parquet()</code> creates a data source from a directory containing Parquet tables. 
Each table must be named according to the name of the resource type that it stores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pathling_read_parquet(pc, path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pathling_read_parquet_+3A_pc">pc</code></td>
<td>
<p>The PathlingContext object.</p>
</td></tr>
<tr><td><code id="pathling_read_parquet_+3A_path">path</code></td>
<td>
<p>The URI of the directory containing the Parquet tables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A DataSource object that can be used to run queries against the data.
</p>


<h3>See Also</h3>

<p><a href="https://pathling.csiro.au/docs/libraries/fhirpath-query#parquet">Pathling documentation - Reading Parquet</a>
</p>
<p>Other data source functions: 
<code><a href="#topic+pathling_read_bundles">pathling_read_bundles</a>()</code>,
<code><a href="#topic+pathling_read_datasets">pathling_read_datasets</a>()</code>,
<code><a href="#topic+pathling_read_delta">pathling_read_delta</a>()</code>,
<code><a href="#topic+pathling_read_ndjson">pathling_read_ndjson</a>()</code>,
<code><a href="#topic+pathling_read_tables">pathling_read_tables</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pc &lt;- pathling_connect()
data_source &lt;- pc %&gt;% pathling_read_parquet(pathling_examples('parquet'))
data_source %&gt;% ds_read('Patient') %&gt;% sparklyr::sdf_nrow()
pathling_disconnect(pc)

</code></pre>

<hr>
<h2 id='pathling_read_tables'>Create a data source from managed tables</h2><span id='topic+pathling_read_tables'></span>

<h3>Description</h3>

<p><code>pathling_read_tables()</code> creates a data source from a set of Spark tables, 
where the table names are the resource type codes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pathling_read_tables(pc, schema = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pathling_read_tables_+3A_pc">pc</code></td>
<td>
<p>The PathlingContext object.</p>
</td></tr>
<tr><td><code id="pathling_read_tables_+3A_schema">schema</code></td>
<td>
<p>An optional schema name that should be used to qualify the table names.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A DataSource object that can be used to run queries against the data.
</p>


<h3>See Also</h3>

<p><a href="https://pathling.csiro.au/docs/libraries/fhirpath-query#managed-tables">Pathling documentation - Reading managed tables</a>
</p>
<p>Other data source functions: 
<code><a href="#topic+pathling_read_bundles">pathling_read_bundles</a>()</code>,
<code><a href="#topic+pathling_read_datasets">pathling_read_datasets</a>()</code>,
<code><a href="#topic+pathling_read_delta">pathling_read_delta</a>()</code>,
<code><a href="#topic+pathling_read_ndjson">pathling_read_ndjson</a>()</code>,
<code><a href="#topic+pathling_read_parquet">pathling_read_parquet</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pc &lt;- pathling_connect()
spark &lt;- pathling_spark(pc)
data_source &lt;- pc %&gt;% pathling_read_tables()
data_source %&gt;% ds_read('Patient') %&gt;% sparklyr::sdf_nrow()
pathling_disconnect(pc)

</code></pre>

<hr>
<h2 id='pathling_spark'>Get the Spark session</h2><span id='topic+pathling_spark'></span>

<h3>Description</h3>

<p>Returns the Spark connection associated with a Pathling context.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pathling_spark(pc)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pathling_spark_+3A_pc">pc</code></td>
<td>
<p>The PathlingContext object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The Spark connection associated with this Pathling context.
</p>


<h3>See Also</h3>

<p>Other context lifecycle functions: 
<code><a href="#topic+pathling_connect">pathling_connect</a>()</code>,
<code><a href="#topic+pathling_disconnect_all">pathling_disconnect_all</a>()</code>,
<code><a href="#topic+pathling_disconnect">pathling_disconnect</a>()</code>
</p>

<hr>
<h2 id='pathling_spark_info'>Get versions of Spark and other dependencies</h2><span id='topic+pathling_spark_info'></span>

<h3>Description</h3>

<p>Returns the versions of Spark and Spark packages used by the Pathling R library.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pathling_spark_info()
</code></pre>


<h3>Value</h3>

<p>A list containing the following keys:
</p>

<ul>
<li><p><code>spark_version</code>: The version of Spark used by Pathling.
</p>
</li>
<li><p><code>scala_version</code>: The version of Scala used by Pathling.
</p>
</li>
<li><p><code>hadoop_version</code>: The version of Hadoop used by Pathling.
</p>
</li>
<li><p><code>hadoop_major_version</code>: The major version of Hadoop used by Pathling.
</p>
</li>
<li><p><code>delta_version</code>: The version of Delta used by Pathling.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other installation functions: 
<code><a href="#topic+pathling_install_spark">pathling_install_spark</a>()</code>,
<code><a href="#topic+pathling_is_spark_installed">pathling_is_spark_installed</a>()</code>,
<code><a href="#topic+pathling_version">pathling_version</a>()</code>
</p>

<hr>
<h2 id='pathling_version'>Get version of Pathling</h2><span id='topic+pathling_version'></span>

<h3>Description</h3>

<p>Get version of Pathling
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pathling_version()
</code></pre>


<h3>Value</h3>

<p>The version of the Pathling R library.
</p>


<h3>See Also</h3>

<p>Other installation functions: 
<code><a href="#topic+pathling_install_spark">pathling_install_spark</a>()</code>,
<code><a href="#topic+pathling_is_spark_installed">pathling_is_spark_installed</a>()</code>,
<code><a href="#topic+pathling_spark_info">pathling_spark_info</a>()</code>
</p>

<hr>
<h2 id='PropertyType'>Coding property data types</h2><span id='topic+PropertyType'></span>

<h3>Description</h3>

<p>The following data types are supported:
</p>

<ul>
<li> <p><code>STRING</code> - A string value.
</p>
</li>
<li> <p><code>INTEGER</code> - An integer value.
</p>
</li>
<li> <p><code>BOOLEAN</code> - A boolean value.
</p>
</li>
<li> <p><code>DECIMAL</code> - A decimal value.
</p>
</li>
<li> <p><code>DATETIME</code> - A date/time value.
</p>
</li>
<li> <p><code>CODE</code> - A code value.
</p>
</li>
<li> <p><code>CODING</code> - A Coding value.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>PropertyType
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 7.
</p>


<h3>See Also</h3>

<p><a href="https://hl7.org/fhir/R4/datatypes.html">FHIR R4 - Data Types</a>
</p>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>sparklyr</dt><dd><p><code><a href="sparklyr.html#topic+pipe">%&gt;%</a></code></p>
</dd>
</dl>

<hr>
<h2 id='SNOMED_URI'>SNOMED CT system URI</h2><span id='topic+SNOMED_URI'></span>

<h3>Description</h3>

<p>The URI of the SNOMED CT code system: <code>http://snomed.info/sct</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SNOMED_URI
</code></pre>


<h3>Format</h3>

<p>An object of class <code>character</code> of length 1.
</p>


<h3>See Also</h3>

<p><a href="https://terminology.hl7.org/SNOMEDCT.html">Using SNOMED CT with HL7 Standards</a>
</p>

<hr>
<h2 id='StorageType'>Terminology cache storage type</h2><span id='topic+StorageType'></span>

<h3>Description</h3>

<p>The type of storage to use for the terminology cache.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StorageType
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 2.
</p>


<h3>Details</h3>

<p>The following values are supported:
</p>

<ul>
<li> <p><code>MEMORY</code> - Use an in-memory cache
</p>
</li>
<li> <p><code>DISK</code> - Use a disk-based cache
</p>
</li></ul>


<hr>
<h2 id='to_array'>Convert a vector to a SQL array literal</h2><span id='topic+to_array'></span>

<h3>Description</h3>

<p>Converts a vector to an expression with the corresponding SQL array literal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>to_array(value)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="to_array_+3A_value">value</code></td>
<td>
<p>A character or numeric vector to be converted</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>quosure</code> with the SQL array literal that can be used in <code>dplyr::mutate</code>.
</p>

<hr>
<h2 id='tx_designation'>Get designations for codings</h2><span id='topic+tx_designation'></span>

<h3>Description</h3>

<p>Takes a Coding column as its input. Returns a Column that contains the values of designations 
(strings) for this coding that match the specified use and language. If the language is
not provided, then all designations with the specified type are returned regardless of
their language.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tx_designation(coding, use = NULL, language = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tx_designation_+3A_coding">coding</code></td>
<td>
<p>A Column containing a struct representation of a Coding.</p>
</td></tr>
<tr><td><code id="tx_designation_+3A_use">use</code></td>
<td>
<p>The code with the use of the designations.</p>
</td></tr>
<tr><td><code id="tx_designation_+3A_language">language</code></td>
<td>
<p>The language of the designations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The Column containing the result of the operation (array of strings with designation values).
</p>


<h3>See Also</h3>

<p><a href="https://pathling.csiro.au/docs/libraries/terminology#retrieving-designations">Pathling documentation - Retrieving designations</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pc &lt;- pathling_connect()

# Get the (first) SNOMED CT "Fully specified name" ('900000000000003001')  
# for the first coding of the Condition resource, in the 'en' language.
pc %&gt;% pathling_example_resource('Condition') %&gt;% 
     sparklyr::mutate(
            id, 
            designation = (!!tx_designation(code[['coding']][[0]], 
                     !!tx_to_snomed_coding('900000000000003001'), language = 'en'))[[0]], 
            .keep='none')
pathling_disconnect(pc)

</code></pre>

<hr>
<h2 id='tx_display'>Get the display text for codings</h2><span id='topic+tx_display'></span>

<h3>Description</h3>

<p>Takes a Coding column as its input. Returns a Column that contains the canonical display
name associated with the given code.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tx_display(coding, accept_language = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tx_display_+3A_coding">coding</code></td>
<td>
<p>A Column containing a struct representation of a Coding.</p>
</td></tr>
<tr><td><code id="tx_display_+3A_accept_language">accept_language</code></td>
<td>
<p>The optional language preferences for the returned display name.
Overrides the parameter 'accept_language' in <code><a href="#topic+pathling_connect">pathling_connect</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Column containing the result of the operation (String).
</p>


<h3>See Also</h3>

<p><a href="https://pathling.csiro.au/docs/libraries/terminology#multi-language-support">Pathling documentation - Multi-language support</a>
</p>
<p>Other terminology functions: 
<code><a href="#topic+tx_member_of">tx_member_of</a>()</code>,
<code><a href="#topic+tx_property_of">tx_property_of</a>()</code>,
<code><a href="#topic+tx_subsumed_by">tx_subsumed_by</a>()</code>,
<code><a href="#topic+tx_subsumes">tx_subsumes</a>()</code>,
<code><a href="#topic+tx_translate">tx_translate</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pc &lt;- pathling_connect()

# Get the display name of the first coding of the Condition resource, with the default language.
pc %&gt;% pathling_example_resource('Condition') %&gt;%
     sparklyr::mutate(
         id, 
         display = !!tx_display(code[['coding']][[0]]), 
         .keep='none')

pathling_disconnect(pc)

</code></pre>

<hr>
<h2 id='tx_member_of'>Test membership within a value set</h2><span id='topic+tx_member_of'></span>

<h3>Description</h3>

<p>Takes a Coding or array of Codings column as its input. Returns the column which contains a
Boolean value, indicating whether any of the input Codings is a member of the specified FHIR
ValueSet.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tx_member_of(codings, value_set_uri)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tx_member_of_+3A_codings">codings</code></td>
<td>
<p>A Column containing a struct representation of a Coding or an array of such 
structs.</p>
</td></tr>
<tr><td><code id="tx_member_of_+3A_value_set_uri">value_set_uri</code></td>
<td>
<p>An identifier for a FHIR ValueSet.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Column containing the result of the operation.
</p>


<h3>See Also</h3>

<p><a href="https://pathling.csiro.au/docs/libraries/terminology#value-set-membership">Pathling documentation - Value set membership</a>
</p>
<p>Other terminology functions: 
<code><a href="#topic+tx_display">tx_display</a>()</code>,
<code><a href="#topic+tx_property_of">tx_property_of</a>()</code>,
<code><a href="#topic+tx_subsumed_by">tx_subsumed_by</a>()</code>,
<code><a href="#topic+tx_subsumes">tx_subsumes</a>()</code>,
<code><a href="#topic+tx_translate">tx_translate</a>()</code>
</p>

<hr>
<h2 id='tx_property_of'>Get properties for codings</h2><span id='topic+tx_property_of'></span>

<h3>Description</h3>

<p>Takes a Coding column as its input. Returns a Column that contains the values of properties
for this coding with specified names and types. The type of the result column depends on the
types of the properties. Primitive FHIR types are mapped to their corresponding SQL primitives.
Complex types are mapped to their corresponding structs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tx_property_of(
  coding,
  property_code,
  property_type = "string",
  accept_language = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tx_property_of_+3A_coding">coding</code></td>
<td>
<p>A Column containing a struct representation of a Coding.</p>
</td></tr>
<tr><td><code id="tx_property_of_+3A_property_code">property_code</code></td>
<td>
<p>The code of the property to retrieve.</p>
</td></tr>
<tr><td><code id="tx_property_of_+3A_property_type">property_type</code></td>
<td>
<p>The type of the property to retrieve.</p>
</td></tr>
<tr><td><code id="tx_property_of_+3A_accept_language">accept_language</code></td>
<td>
<p>The optional language preferences for the returned property values.
Overrides the parameter 'accept_language' in 'PathlingContext.create'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The Column containing the result of the operation (array of property values).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PropertyType">PropertyType</a></code>
</p>
<p><a href="https://pathling.csiro.au/docs/libraries/terminology#retrieving-properties">Pathling documentation - Retrieving properties</a>
</p>
<p>Other terminology functions: 
<code><a href="#topic+tx_display">tx_display</a>()</code>,
<code><a href="#topic+tx_member_of">tx_member_of</a>()</code>,
<code><a href="#topic+tx_subsumed_by">tx_subsumed_by</a>()</code>,
<code><a href="#topic+tx_subsumes">tx_subsumes</a>()</code>,
<code><a href="#topic+tx_translate">tx_translate</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pc &lt;- pathling_connect()

# Get the (first) value of the `inactive` property of the first coding of the Condition resource.
pc %&gt;% pathling_example_resource('Condition') %&gt;%
     sparklyr::mutate(id, 
         is_inavtive = (!!tx_property_of(code[['coding']][[0]], 
                                 "inactive",PropertyType$BOOLEAN))[[0]], 
         .keep='none'
     )

pathling_disconnect(pc)

</code></pre>

<hr>
<h2 id='tx_subsumed_by'>Test subsumption between codings</h2><span id='topic+tx_subsumed_by'></span>

<h3>Description</h3>

<p>Takes two Coding columns as input. Returns a Column that contains a Boolean value,
indicating whether the left Coding is subsumed by the right Coding.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tx_subsumed_by(left_codings, right_codings)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tx_subsumed_by_+3A_left_codings">left_codings</code></td>
<td>
<p>A Column containing a struct representation of a Coding or an array of Codings.</p>
</td></tr>
<tr><td><code id="tx_subsumed_by_+3A_right_codings">right_codings</code></td>
<td>
<p>A Column containing a struct representation of a Coding or an array of Codings.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Column containing the result of the operation (boolean).
</p>


<h3>See Also</h3>

<p><a href="https://pathling.csiro.au/docs/libraries/terminology#subsumption-testing">Pathling documentation - Subsumption testing</a>
</p>
<p>Other terminology functions: 
<code><a href="#topic+tx_display">tx_display</a>()</code>,
<code><a href="#topic+tx_member_of">tx_member_of</a>()</code>,
<code><a href="#topic+tx_property_of">tx_property_of</a>()</code>,
<code><a href="#topic+tx_subsumes">tx_subsumes</a>()</code>,
<code><a href="#topic+tx_translate">tx_translate</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pc &lt;- pathling_connect()

# Test the codings of the Condition `code` for subsumption by a SNOMED CT code.
pc %&gt;% pathling_example_resource('Condition') %&gt;%
    sparklyr::mutate(
         id,
         is_subsumed_by = !!tx_subsumed_by(code[['coding']],
             !!tx_to_snomed_coding('444814009')),
         .keep='none')
 
pathling_disconnect(pc)

</code></pre>

<hr>
<h2 id='tx_subsumes'>Test subsumption between codings</h2><span id='topic+tx_subsumes'></span>

<h3>Description</h3>

<p>Takes two Coding columns as input. Returns a Column that contains a Boolean value,
indicating whether the left Coding subsumes the right Coding.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tx_subsumes(left_codings, right_codings)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tx_subsumes_+3A_left_codings">left_codings</code></td>
<td>
<p>A Column containing a struct representation of a Coding or an array of Codings.</p>
</td></tr>
<tr><td><code id="tx_subsumes_+3A_right_codings">right_codings</code></td>
<td>
<p>A Column containing a struct representation of a Coding or an array of Codings.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Column containing the result of the operation (boolean).
</p>


<h3>See Also</h3>

<p><a href="https://pathling.csiro.au/docs/libraries/terminology#subsumption-testing">Pathling documentation - Subsumption testing</a>
</p>
<p>Other terminology functions: 
<code><a href="#topic+tx_display">tx_display</a>()</code>,
<code><a href="#topic+tx_member_of">tx_member_of</a>()</code>,
<code><a href="#topic+tx_property_of">tx_property_of</a>()</code>,
<code><a href="#topic+tx_subsumed_by">tx_subsumed_by</a>()</code>,
<code><a href="#topic+tx_translate">tx_translate</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pc &lt;- pathling_connect()

# Test the codings of the Condition `code` for subsumption of a SNOMED CT code.
pc %&gt;% pathling_example_resource('Condition') %&gt;%
    sparklyr::mutate(
         id,
         subsumes = !!tx_subsumes(code[['coding']],
             !!tx_to_snomed_coding('444814009')),
         .keep='none')
 
pathling_disconnect(pc)

</code></pre>

<hr>
<h2 id='tx_to_coding'>Convert codes to Coding structures</h2><span id='topic+tx_to_coding'></span>

<h3>Description</h3>

<p>Converts a Column containing codes into a Column that contains a Coding struct.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tx_to_coding(coding_column, system, version = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tx_to_coding_+3A_coding_column">coding_column</code></td>
<td>
<p>The Column containing the codes.</p>
</td></tr>
<tr><td><code id="tx_to_coding_+3A_system">system</code></td>
<td>
<p>The URI of the system the codes belong to.</p>
</td></tr>
<tr><td><code id="tx_to_coding_+3A_version">version</code></td>
<td>
<p>The version of the code system.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Coding struct Column can be used as an input to terminology functions such as 
<code><a href="#topic+tx_member_of">tx_member_of</a></code> and <code><a href="#topic+tx_translate">tx_translate</a></code>. Please note that inside 
<code>sparklyr</code> verbs such as <code>mutate</code> the functions calls need to be preceded with 
<code>!!</code>, e.g: <code>!!tx_to_coding(CODE, SNOMED_URI)</code>.
</p>


<h3>Value</h3>

<p>A Column containing a Coding struct.
</p>


<h3>See Also</h3>

<p><a href="https://hl7.org/fhir/R4/datatypes.html#Coding">FHIR R4 - Coding</a>
</p>
<p>Other terminology helpers: 
<code><a href="#topic+tx_to_ecl_value_set">tx_to_ecl_value_set</a>()</code>,
<code><a href="#topic+tx_to_loinc_coding">tx_to_loinc_coding</a>()</code>,
<code><a href="#topic+tx_to_snomed_coding">tx_to_snomed_coding</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pc &lt;- pathling_connect()
condition_df &lt;- pathling_spark(pc) %&gt;% sparklyr::copy_to(conditions)

# Convert codes to ICD-10 codings.
condition_df %&gt;% sparklyr::mutate(
    icdCoding = !!tx_to_coding(CODE, "http://hl7.org/fhir/sid/icd-10"), .keep = 'none'
)

pathling_disconnect(pc)

</code></pre>

<hr>
<h2 id='tx_to_ecl_value_set'>Convert a SNOMED CT ECL expression to a ValueSet URI</h2><span id='topic+tx_to_ecl_value_set'></span>

<h3>Description</h3>

<p>Converts a SNOMED CT ECL expression into a FHIR ValueSet URI. It can be used with the 
'<code><a href="#topic+tx_member_of">tx_member_of</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tx_to_ecl_value_set(ecl)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tx_to_ecl_value_set_+3A_ecl">ecl</code></td>
<td>
<p>The ECL expression.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The ValueSet URI.
</p>


<h3>See Also</h3>

<p><a href="https://terminology.hl7.org/SNOMEDCT.html#snomed-ct-implicit-value-sets">Using SNOMED CT with HL7 Standards - Implicit Value Sets</a>
</p>
<p>Other terminology helpers: 
<code><a href="#topic+tx_to_coding">tx_to_coding</a>()</code>,
<code><a href="#topic+tx_to_loinc_coding">tx_to_loinc_coding</a>()</code>,
<code><a href="#topic+tx_to_snomed_coding">tx_to_snomed_coding</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Example usage of tx_to_ecl_value_set function
tx_to_ecl_value_set('&lt;&lt;373265006 |Analgesic (substance)|')

</code></pre>

<hr>
<h2 id='tx_to_loinc_coding'>Convert LOINC codes to Coding structures</h2><span id='topic+tx_to_loinc_coding'></span>

<h3>Description</h3>

<p>Converts a Column containing codes into a Column that contains a LOINC Coding struct.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tx_to_loinc_coding(coding_column, version = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tx_to_loinc_coding_+3A_coding_column">coding_column</code></td>
<td>
<p>The Column containing the codes.</p>
</td></tr>
<tr><td><code id="tx_to_loinc_coding_+3A_version">version</code></td>
<td>
<p>The version of the code system.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Coding struct Column can be used as an input to terminology functions such as 
<code><a href="#topic+tx_member_of">tx_member_of</a></code> and <code><a href="#topic+tx_translate">tx_translate</a></code>. Please note that inside 
<code>sparklyr</code> verbs such as <code>mutate</code> the functions calls need to be preceded with 
<code>!!</code>, e.g: <code>!!tx_to_coding(CODE, SNOMED_URI)</code>.
</p>


<h3>Value</h3>

<p>A Column containing a Coding struct.
</p>


<h3>See Also</h3>

<p>Other terminology helpers: 
<code><a href="#topic+tx_to_coding">tx_to_coding</a>()</code>,
<code><a href="#topic+tx_to_ecl_value_set">tx_to_ecl_value_set</a>()</code>,
<code><a href="#topic+tx_to_snomed_coding">tx_to_snomed_coding</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pc &lt;- pathling_connect()
condition_df &lt;- pathling_spark(pc) %&gt;% sparklyr::copy_to(conditions)

# Convert codes to LOINC codings.
# Equivalent to: tx_to_coding(CODE, "http://loinc.org")
condition_df %&gt;% sparklyr::mutate(loincCoding = !!tx_to_loinc_coding(CODE), .keep = 'none')

pathling_disconnect(pc)

</code></pre>

<hr>
<h2 id='tx_to_snomed_coding'>Convert SNOMED CT codes to Coding structures</h2><span id='topic+tx_to_snomed_coding'></span>

<h3>Description</h3>

<p>Converts a Column containing codes into a Column that contains a SNOMED Coding struct.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tx_to_snomed_coding(coding_column, version = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tx_to_snomed_coding_+3A_coding_column">coding_column</code></td>
<td>
<p>The Column containing the codes.</p>
</td></tr>
<tr><td><code id="tx_to_snomed_coding_+3A_version">version</code></td>
<td>
<p>The version of the code system.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Coding struct Column can be used as an input to terminology functions such as 
<code><a href="#topic+tx_member_of">tx_member_of</a></code> and <code><a href="#topic+tx_translate">tx_translate</a></code>. Please note that inside 
<code>sparklyr</code> verbs such as <code>mutate</code> the functions calls need to be preceded with 
<code>!!</code>, e.g: <code>!!tx_to_coding(CODE, SNOMED_URI)</code>.
</p>


<h3>Value</h3>

<p>A Column containing a Coding struct.
</p>


<h3>See Also</h3>

<p>Other terminology helpers: 
<code><a href="#topic+tx_to_coding">tx_to_coding</a>()</code>,
<code><a href="#topic+tx_to_ecl_value_set">tx_to_ecl_value_set</a>()</code>,
<code><a href="#topic+tx_to_loinc_coding">tx_to_loinc_coding</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pc &lt;- pathling_connect()
condition_df &lt;- pathling_spark(pc) %&gt;% sparklyr::copy_to(conditions)

# Convert codes to SNOMED CT codings.
# Equivalent to: tx_to_coding(CODE, "http://snomed.info/sct")
condition_df %&gt;% sparklyr::mutate(snomedCoding = !!tx_to_snomed_coding(CODE), .keep = 'none')

pathling_disconnect(pc)

</code></pre>

<hr>
<h2 id='tx_translate'>Translate between value sets</h2><span id='topic+tx_translate'></span>

<h3>Description</h3>

<p>Takes a Coding column as input. Returns the Column which contains an array of
Coding value with translation targets from the specified FHIR ConceptMap. There
may be more than one target concept for each input concept. Only the translation with
the specified equivalences are returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tx_translate(
  codings,
  concept_map_uri,
  reverse = FALSE,
  equivalences = NULL,
  target = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tx_translate_+3A_codings">codings</code></td>
<td>
<p>A Column containing a struct representation of a Coding.</p>
</td></tr>
<tr><td><code id="tx_translate_+3A_concept_map_uri">concept_map_uri</code></td>
<td>
<p>An identifier for a FHIR ConceptMap.</p>
</td></tr>
<tr><td><code id="tx_translate_+3A_reverse">reverse</code></td>
<td>
<p>The direction to traverse the map. FALSE results in &quot;source to target&quot;
mappings, while TRUE results in &quot;target to source&quot;.</p>
</td></tr>
<tr><td><code id="tx_translate_+3A_equivalences">equivalences</code></td>
<td>
<p>A value of a collection of values from the ConceptMapEquivalence ValueSet.</p>
</td></tr>
<tr><td><code id="tx_translate_+3A_target">target</code></td>
<td>
<p>Identifies the value set in which a translation is sought. If there's no
target specified, the server should return all known translations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Column containing the result of the operation (an array of Coding structs).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Equivalence">Equivalence</a></code>
</p>
<p><a href="https://pathling.csiro.au/docs/libraries/terminology#concept-translation">Pathling documentation - Concept translation</a>
</p>
<p>Other terminology functions: 
<code><a href="#topic+tx_display">tx_display</a>()</code>,
<code><a href="#topic+tx_member_of">tx_member_of</a>()</code>,
<code><a href="#topic+tx_property_of">tx_property_of</a>()</code>,
<code><a href="#topic+tx_subsumed_by">tx_subsumed_by</a>()</code>,
<code><a href="#topic+tx_subsumes">tx_subsumes</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pc &lt;- pathling_connect()

# Translates the codings of the Condition `code` using a SNOMED implicit concept map.
pc %&gt;% pathling_example_resource('Condition') %&gt;%
    sparklyr::mutate(
         id,
         translation = !!tx_translate(code[['coding']],
                 'http://snomed.info/sct?fhir_cm=900000000000527005'),
         .keep='none')
 
pathling_disconnect(pc)

</code></pre>

<hr>
<h2 id='Version'>FHIR versions</h2><span id='topic+Version'></span>

<h3>Description</h3>

<p>The following FHIR versions are supported:
</p>

<ul>
<li><p><code>R4</code>: FHIR R4
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>Version
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 1.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
