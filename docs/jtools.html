<!DOCTYPE html><html><head><title>Help for package jtools</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {jtools}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#%nin%'><p>Not <code>%in%</code></p></a></li>
<li><a href='#%not%'><p>Subsetting operators</p></a></li>
<li><a href='#add_gridlines'><p>Add and remove gridlines</p></a></li>
<li><a href='#center'><p>Mean-center vectors, data frames, and survey designs</p></a></li>
<li><a href='#center_mod'><p>Center variables in fitted regression models</p></a></li>
<li><a href='#effect_plot'><p>Plot simple effects in regression models</p></a></li>
<li><a href='#export_summs'><p>Export regression summaries to tables</p></a></li>
<li><a href='#get_colors'><p>Get colors for plotting functions</p></a></li>
<li><a href='#get_formula'><p>Retrieve formulas from model objects</p></a></li>
<li><a href='#get_offset_name'><p>Utility functions for generating model predictions</p></a></li>
<li><a href='#get_robust_se'><p>Calculate robust standard errors and produce coefficient tables</p></a></li>
<li><a href='#gscale'><p>Scale and/or center data, including survey designs</p></a></li>
<li><a href='#interact_plot'><p>Deprecated interaction functions</p></a></li>
<li><a href='#jtools_colors'><p>Color palettes in <code>jtools</code> functions</p></a></li>
<li><a href='#knit_print.summ.lm'><p>knitr methods for summ</p></a></li>
<li><a href='#make_new_data'><p>Make new data for generating predicted data from regression models.</p></a></li>
<li><a href='#make_predictions'><p>Generate predicted data for plotting results of regression models</p></a></li>
<li><a href='#md_table'><p>Print attractive data frames in the console</p></a></li>
<li><a href='#movies'><p>Data about movies</p></a></li>
<li><a href='#num_print'><p>Numbering printing with signed zeroes and trailing zeroes</p></a></li>
<li><a href='#partialize'><p>Adjust observed data for partial residuals plots</p></a></li>
<li><a href='#pf_sv_test'><p>Test whether sampling weights are needed</p></a></li>
<li><a href='#plot_summs'><p>Plot Regression Summaries</p></a></li>
<li><a href='#predict_merMod'><p>Alternative interface for <code>merMod</code> predictions</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#scale_mod'><p>Scale variables in fitted regression models</p></a></li>
<li><a href='#set_summ_defaults'><p>Set defaults for <code>summ()</code> functions</p></a></li>
<li><a href='#standardize'><p>Standardize vectors, data frames, and survey designs</p></a></li>
<li><a href='#summ'><p>Regression summaries with options</p></a></li>
<li><a href='#summ.glm'><p>Generalized linear regression summaries with options</p></a></li>
<li><a href='#summ.lm'><p>Linear regression summaries with options</p></a></li>
<li><a href='#summ.merMod'><p>Mixed effects regression summaries with options</p></a></li>
<li><a href='#summ.rq'><p>Quantile regression summaries with options</p></a></li>
<li><a href='#summ.svyglm'><p>Complex survey regression summaries with options</p></a></li>
<li><a href='#svycor'><p>Calculate Pearson correlations with complex survey data</p></a></li>
<li><a href='#svysd'><p>Calculate standard deviations with complex survey data</p></a></li>
<li><a href='#theme_apa'><p>Format ggplot2 figures in APA style</p></a></li>
<li><a href='#theme_nice'><p>A nice, flexible <code>ggplot2</code> theme</p></a></li>
<li><a href='#tidy.summ'><p>Broom extensions for summ objects</p></a></li>
<li><a href='#weights_tests'><p>Test whether sampling weights are needed</p></a></li>
<li><a href='#wgttest'><p>Test whether sampling weights are needed</p></a></li>
<li><a href='#wrap_str'><p><code>cat</code>, <code>message</code>, <code>warning</code>, and <code>stop</code> wrapped to fit the console's</p>
width.</a></li>
<li><a href='#wtd.sd'><p>Weighted standard deviation calculation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Analysis and Presentation of Social Scientific Data</td>
</tr>
<tr>
<td>Version:</td>
<td>2.2.2</td>
</tr>
<tr>
<td>Description:</td>
<td>This is a collection of tools for more efficiently understanding 
  and sharing the results of (primarily) regression analyses. There are also a
  number of miscellaneous functions for statistical and programming purposes. 
  Support for models produced by the survey and lme4 packages are points of 
  emphasis.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://jtools.jacob-long.com">https://jtools.jacob-long.com</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/jacob-long/jtools/issues">https://github.com/jacob-long/jtools/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>crayon, generics, ggplot2 (&ge; 3.4.0), magrittr, pander,
pkgconfig, rlang (&ge; 0.3.0), tibble</td>
</tr>
<tr>
<td>Suggests:</td>
<td>boot, broom, broom.mixed, huxtable (&ge; 3.0.0), kableExtra,
lme4, lmerTest, MASS, methods, pbkrtest, RColorBrewer,
sandwich, scales, survey, weights, knitr, rmarkdown, testthat,
vdiffr</td>
</tr>
<tr>
<td>Enhances:</td>
<td>brms, quantreg, rstanarm</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-07-10 15:02:36 UTC; jacoblong</td>
</tr>
<tr>
<td>Author:</td>
<td>Jacob A. Long <a href="https://orcid.org/0000-0002-1582-6214"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jacob A. Long &lt;jacob.long@sc.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-07-11 08:40:29 UTC</td>
</tr>
</table>
<hr>
<h2 id='+25nin+25'>Not <code>%in%</code></h2><span id='topic++25nin+25'></span>

<h3>Description</h3>

<p>This function does the very opposite of <code>%in%</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>x %nin% table
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25nin+2B25_+3A_x">x</code></td>
<td>
<p>An object</p>
</td></tr>
<tr><td><code id="+2B25nin+2B25_+3A_table">table</code></td>
<td>
<p>The object you want see if <code>x</code> is not in</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A logical vector
</p>


<h3>See Also</h3>

<p>Other subsetters: 
<code><a href="#topic++25not+25">%not%</a>()</code>
</p>

<hr>
<h2 id='+25not+25'>Subsetting operators</h2><span id='topic++25not+25'></span><span id='topic++25not+25+3C-'></span><span id='topic++25just+25'></span><span id='topic++25just+25+3C-'></span><span id='topic++25not+25.default'></span><span id='topic++25not+25+3C-.default'></span><span id='topic++25not+25.data.frame'></span><span id='topic++25not+25+3C-.data.frame'></span><span id='topic++25not+25.matrix'></span><span id='topic++25not+25+3C-.matrix'></span><span id='topic++25not+25.list'></span><span id='topic++25not+25+3C-.list'></span><span id='topic++25just+25.default'></span><span id='topic++25just+25+3C-.default'></span><span id='topic++25just+25.data.frame'></span><span id='topic++25just+25+3C-.data.frame'></span><span id='topic++25just+25.matrix'></span><span id='topic++25just+25+3C-.matrix'></span><span id='topic++25just+25.list'></span><span id='topic++25just+25+3C-.list'></span>

<h3>Description</h3>

<p><code style="white-space: pre;">&#8288;%just%&#8288;</code> and <code style="white-space: pre;">&#8288;%not%&#8288;</code> are subsetting convenience functions
for situations when you would do <code>x[x %in% y]</code> or <code>x[x %nin% y]</code>. See
details for behavior when <code>x</code> is a data frame or matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>x %not% y

x %not% y &lt;- value

x %just% y

x %just% y &lt;- value

## Default S3 method:
x %not% y

## Default S3 method:
x %not% y &lt;- value

## S3 method for class 'data.frame'
x %not% y

## S3 method for class 'data.frame'
x %not% y &lt;- value

## S3 method for class 'matrix'
x %not% y

## S3 method for class 'matrix'
x %not% y &lt;- value

## S3 method for class 'list'
x %not% y

## S3 method for class 'list'
x %not% y &lt;- value

## Default S3 method:
x %just% y

## Default S3 method:
x %just% y &lt;- value

## S3 method for class 'data.frame'
x %just% y

## S3 method for class 'data.frame'
x %just% y &lt;- value

## S3 method for class 'matrix'
x %just% y

## S3 method for class 'matrix'
x %just% y &lt;- value

## S3 method for class 'list'
x %just% y

## S3 method for class 'list'
x %just% y &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25not+2B25_+3A_x">x</code></td>
<td>
<p>Object to subset</p>
</td></tr>
<tr><td><code id="+2B25not+2B25_+3A_y">y</code></td>
<td>
<p>List of items to include if they are/aren't in <code>x</code></p>
</td></tr>
<tr><td><code id="+2B25not+2B25_+3A_value">value</code></td>
<td>
<p>The object(s) to assign to the subsetted <code>x</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The behavior of <code style="white-space: pre;">&#8288;%not%&#8288;</code> and <code style="white-space: pre;">&#8288;%just%&#8288;</code> are different when you're subsetting
data frames or matrices. The subset <code>y</code> in this case is interpreted as
<strong>column</strong> names or indices.
</p>
<p>You can also make assignments to the subset in the same way you could if
subsetting with brackets.
</p>


<h3>Value</h3>

<p>All of <code>x</code> that are in <code>y</code> (<code style="white-space: pre;">&#8288;%just%&#8288;</code>) or all of <code>x</code> that are not in
<code>y</code> (<code style="white-space: pre;">&#8288;%not%&#8288;</code>).
</p>


<h3>See Also</h3>

<p>Other subsetters: 
<code><a href="#topic++25nin+25">%nin%</a>()</code>
</p>
<p>Other subsetters: 
<code><a href="#topic++25nin+25">%nin%</a>()</code>
</p>
<p>Other subsetters: 
<code><a href="#topic++25nin+25">%nin%</a>()</code>
</p>
<p>Other subsetters: 
<code><a href="#topic++25nin+25">%nin%</a>()</code>
</p>
<p>Other subsetters: 
<code><a href="#topic++25nin+25">%nin%</a>()</code>
</p>
<p>Other subsetters: 
<code><a href="#topic++25nin+25">%nin%</a>()</code>
</p>
<p>Other subsetters: 
<code><a href="#topic++25nin+25">%nin%</a>()</code>
</p>
<p>Other subsetters: 
<code><a href="#topic++25nin+25">%nin%</a>()</code>
</p>
<p>Other subsetters: 
<code><a href="#topic++25nin+25">%nin%</a>()</code>
</p>
<p>Other subsetters: 
<code><a href="#topic++25nin+25">%nin%</a>()</code>
</p>
<p>Other subsetters: 
<code><a href="#topic++25nin+25">%nin%</a>()</code>
</p>
<p>Other subsetters: 
<code><a href="#topic++25nin+25">%nin%</a>()</code>
</p>
<p>Other subsetters: 
<code><a href="#topic++25nin+25">%nin%</a>()</code>
</p>
<p>Other subsetters: 
<code><a href="#topic++25nin+25">%nin%</a>()</code>
</p>
<p>Other subsetters: 
<code><a href="#topic++25nin+25">%nin%</a>()</code>
</p>
<p>Other subsetters: 
<code><a href="#topic++25nin+25">%nin%</a>()</code>
</p>
<p>Other subsetters: 
<code><a href="#topic++25nin+25">%nin%</a>()</code>
</p>
<p>Other subsetters: 
<code><a href="#topic++25nin+25">%nin%</a>()</code>
</p>
<p>Other subsetters: 
<code><a href="#topic++25nin+25">%nin%</a>()</code>
</p>
<p>Other subsetters: 
<code><a href="#topic++25nin+25">%nin%</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 x &lt;- 1:5
 y &lt;- 3:8
 
 x %just% y # 3 4 5
 x %not% y # 1 2

 # Assignment works too
 x %just% y &lt;- NA # 1 2 NA NA NA
 x %not% y &lt;- NA # NA NA 3 4 5
 
 mtcars %just% c("mpg", "qsec", "cyl") # keeps only columns with those names
 mtcars %not% 1:5 # drops columns 1 through 5

 # Assignment works for data frames as well
 mtcars %just% c("mpg", "qsec") &lt;- gscale(mtcars, c("mpg", "qsec"))
 mtcars %not% c("mpg", "qsec") &lt;- gscale(mtcars %not% c("mpg", "qsec"))
 
 
</code></pre>

<hr>
<h2 id='add_gridlines'>Add and remove gridlines</h2><span id='topic+add_gridlines'></span><span id='topic+add_x_gridlines'></span><span id='topic+add_y_gridlines'></span><span id='topic+drop_gridlines'></span><span id='topic+drop_x_gridlines'></span><span id='topic+drop_y_gridlines'></span>

<h3>Description</h3>

<p>These are convenience wrappers for editing <code><a href="ggplot2.html#topic+theme">ggplot2::theme()</a></code>'s
<code>panel.grid.major</code> and <code>panel.grid.minor</code> parameters with sensible
defaults.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_gridlines(x = TRUE, y = TRUE, minor = TRUE)

add_x_gridlines(minor = TRUE)

add_y_gridlines(minor = TRUE)

drop_gridlines(x = TRUE, y = TRUE, minor.only = FALSE)

drop_x_gridlines(minor.only = FALSE)

drop_y_gridlines(minor.only = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_gridlines_+3A_x">x</code></td>
<td>
<p>Apply changes to the x axis?</p>
</td></tr>
<tr><td><code id="add_gridlines_+3A_y">y</code></td>
<td>
<p>Apply changes to the y axis?</p>
</td></tr>
<tr><td><code id="add_gridlines_+3A_minor">minor</code></td>
<td>
<p>Add minor gridlines in addition to major?</p>
</td></tr>
<tr><td><code id="add_gridlines_+3A_minor.only">minor.only</code></td>
<td>
<p>Remove only the minor gridlines?</p>
</td></tr>
</table>

<hr>
<h2 id='center'>Mean-center vectors, data frames, and survey designs</h2><span id='topic+center'></span>

<h3>Description</h3>

<p>This function is a wrapper around <code><a href="#topic+gscale">gscale()</a></code> that is configured
to mean-center variables without affecting the scaling of those variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>center(
  data = NULL,
  vars = NULL,
  binary.inputs = "center",
  binary.factors = FALSE,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="center_+3A_data">data</code></td>
<td>
<p>A data frame or survey design. Only needed if you would like to
rescale multiple variables at once. If <code>x = NULL</code>, all columns will
be rescaled. Otherwise, <code>x</code> should be a vector of variable names. If
<code>x</code> is a numeric vector, this argument is ignored.</p>
</td></tr>
<tr><td><code id="center_+3A_vars">vars</code></td>
<td>
<p>If <code>data</code> is a data.frame or similar, you can scale only
select columns by providing a vector column names to this argument.</p>
</td></tr>
<tr><td><code id="center_+3A_binary.inputs">binary.inputs</code></td>
<td>
<p>Options for binary variables. Default is <code>center</code>;
<code>0/1</code> keeps original scale; <code>-0.5/0.5</code> rescales 0 as -0.5 and 1
as 0.5; <code>center</code> subtracts the mean; and <code>full</code> subtracts the
mean and divides by 2 sd.</p>
</td></tr>
<tr><td><code id="center_+3A_binary.factors">binary.factors</code></td>
<td>
<p>Coerce two-level factors to numeric and apply scaling
functions to them? Default is FALSE.</p>
</td></tr>
<tr><td><code id="center_+3A_weights">weights</code></td>
<td>
<p>A vector of weights equal in length to <code>x</code>. If iterating
over a data frame, the weights will need to be equal in length to all the
columns to avoid errors. You may need to remove missing values before using
the weights.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Some more information can be found in the documentation for
<code><a href="#topic+gscale">gscale()</a></code>
</p>


<h3>Value</h3>

<p>A transformed version of the <code>data</code> argument.
</p>


<h3>See Also</h3>

<p>Other standardization: 
<code><a href="#topic+center_mod">center_mod</a>()</code>,
<code><a href="#topic+gscale">gscale</a>()</code>,
<code><a href="#topic+scale_mod">scale_mod</a>()</code>,
<code><a href="#topic+standardize">standardize</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Standardize just the "qsec" variable in mtcars
standardize(mtcars, vars = "qsec")

</code></pre>

<hr>
<h2 id='center_mod'>Center variables in fitted regression models</h2><span id='topic+center_mod'></span><span id='topic+center_lm'></span>

<h3>Description</h3>

<p><code>center_mod</code> (previously known as <code>center_lm</code>) takes fitted regression models
and mean-centers the
continuous variables in the model to aid interpretation, especially in
the case of models with interactions. It is a wrapper to
<code><a href="#topic+scale_mod">scale_mod</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>center_mod(
  model,
  binary.inputs = "0/1",
  center.response = FALSE,
  data = NULL,
  apply.weighted.contrasts = getOption("jtools-weighted.contrasts", FALSE),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="center_mod_+3A_model">model</code></td>
<td>
<p>A regression model of type <code>lm</code>, <code>glm</code>, or
<code><a href="survey.html#topic+svyglm">svyglm</a></code>; others may work as well but have not been
tested.</p>
</td></tr>
<tr><td><code id="center_mod_+3A_binary.inputs">binary.inputs</code></td>
<td>
<p>Options for binary variables. Default is <code>0/1</code>;
<code>0/1</code> keeps original scale; <code>-0.5,0.5</code> rescales 0 as -0.5 and 1
as 0.5; <code>center</code> subtracts the mean; and <code>full</code> treats them
like other continuous variables.</p>
</td></tr>
<tr><td><code id="center_mod_+3A_center.response">center.response</code></td>
<td>
<p>Should the response variable also be centered?
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="center_mod_+3A_data">data</code></td>
<td>
<p>If you provide the data used to fit the model here, that data
frame is used to re-fit the model instead of the <code><a href="stats.html#topic+model.frame">stats::model.frame()</a></code>
of the model. This is particularly useful if you have variable
transformations or polynomial terms specified in the formula.</p>
</td></tr>
<tr><td><code id="center_mod_+3A_apply.weighted.contrasts">apply.weighted.contrasts</code></td>
<td>
<p>Factor variables cannot be scaled, but you
can set the contrasts such that the intercept in a regression model will
reflect the true mean (assuming all other variables are centered). If set
to TRUE, the argument will apply weighted effects coding to all factors.
This is similar to the R default effects coding, but weights according to
how many observations are at each level. An adapted version of
<code>contr.wec()</code> from the <code>wec</code> package is used to do this. See
that package's documentation and/or Grotenhuis et al. (2016) for more
info.</p>
</td></tr>
<tr><td><code id="center_mod_+3A_...">...</code></td>
<td>
<p>Arguments passed on to <code><a href="#topic+gscale">gscale()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will mean-center all continuous variables in a
regression model for ease of interpretation, especially for those models
that have
interaction terms. The mean for <code>svyglm</code> objects is calculated using
<code>svymean</code>, so reflects the survey-weighted mean. The weight variables
in <code>svyglm</code> are not centered, nor are they in other <code>lm</code> family
models.
</p>
<p>This function re-estimates the model, so for large models one should
expect
a runtime equal to the first run.
</p>


<h3>Value</h3>

<p>The functions returns a <code>lm</code> or <code>glm</code> object, inheriting
from whichever class was supplied.
</p>


<h3>Author(s)</h3>

<p>Jacob Long <a href="mailto:jacob.long@sc.edu">jacob.long@sc.edu</a>
</p>


<h3>References</h3>

<p>Bauer, D. J., &amp; Curran, P. J. (2005). Probing interactions in fixed and
multilevel regression: Inferential and graphical techniques.
<em>Multivariate Behavioral Research</em>, <em>40</em>(3), 373-400.
</p>
<p>Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). <em>Applied
multiple regression/correlation analyses for the behavioral sciences</em> (3rd
ed.). Mahwah, NJ: Lawrence Erlbaum Associates, Inc.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sim_slopes">sim_slopes</a></code> performs a simple slopes analysis.
</p>
<p><code><a href="#topic+interact_plot">interact_plot</a></code> creates attractive, user-configurable plots of
interaction models.
</p>
<p>Other standardization: 
<code><a href="#topic+center">center</a>()</code>,
<code><a href="#topic+gscale">gscale</a>()</code>,
<code><a href="#topic+scale_mod">scale_mod</a>()</code>,
<code><a href="#topic+standardize">standardize</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
fit &lt;- lm(formula = Murder ~ Income * Illiteracy,
          data = as.data.frame(state.x77))
fit_center &lt;- center_mod(fit)

# With weights
fitw &lt;- lm(formula = Murder ~ Income * Illiteracy,
           data = as.data.frame(state.x77),
           weights = Population)
fitw_center &lt;- center_mod(fitw)

# With svyglm
if (requireNamespace("survey")) {
library(survey)
data(api)
dstrat &lt;- svydesign(id = ~1, strata = ~stype, weights = ~pw,
                    data = apistrat, fpc =~ fpc)
regmodel &lt;- svyglm(api00 ~ ell * meals, design = dstrat)
regmodel_center &lt;- center_mod(regmodel)
}

</code></pre>

<hr>
<h2 id='effect_plot'>Plot simple effects in regression models</h2><span id='topic+effect_plot'></span>

<h3>Description</h3>

<p><code>effect_plot()</code> plots regression paths. The plotting is done with
<code>ggplot2</code> rather than base graphics, which some similar functions use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>effect_plot(
  model,
  pred,
  pred.values = NULL,
  centered = "all",
  plot.points = FALSE,
  interval = FALSE,
  data = NULL,
  at = NULL,
  int.type = c("confidence", "prediction"),
  int.width = 0.95,
  outcome.scale = "response",
  robust = FALSE,
  cluster = NULL,
  vcov = NULL,
  set.offset = 1,
  x.label = NULL,
  y.label = NULL,
  pred.labels = NULL,
  main.title = NULL,
  colors = "black",
  line.colors = colors,
  line.thickness = 1.1,
  point.size = 1.5,
  point.alpha = 0.6,
  jitter = 0,
  rug = FALSE,
  rug.sides = "lb",
  force.cat = FALSE,
  cat.geom = c("point", "line", "bar"),
  cat.interval.geom = c("errorbar", "linerange"),
  cat.pred.point.size = 3.5,
  partial.residuals = FALSE,
  color.class = colors,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="effect_plot_+3A_model">model</code></td>
<td>
<p>A regression model. The function is tested with <code>lm</code>,
<code>glm</code>, <code><a href="survey.html#topic+svyglm">svyglm</a></code>,
<code><a href="lme4.html#topic+merMod-class">merMod</a></code>,
<code><a href="quantreg.html#topic+rq">rq</a></code>, <code>brmsfit</code>,
<code>stanreg</code> models.
Models from other classes may work as well but are not officially
supported. The model should include the interaction of interest.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_pred">pred</code></td>
<td>
<p>The name of the predictor variable involved
in the interaction. This can be a bare name or string. Note that it
is evaluated using <code>rlang</code>, so programmers can use the <code style="white-space: pre;">&#8288;!!&#8288;</code> syntax
to pass variables instead of the verbatim names.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_pred.values">pred.values</code></td>
<td>
<p>Values of <code>pred</code> to use instead of the equi-spaced
series by default (for continuous variables) or all unique values (for
non-continuous variables).</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_centered">centered</code></td>
<td>
<p>A vector of quoted variable names that are to be
mean-centered. If <code>"all"</code>, all non-focal predictors are centered. You
may instead pass a character vector of variables to center. User can
also use &quot;none&quot; to base all predictions on variables set at 0.
The response variable, <code>pred</code>, weights, and offset variables are never
centered.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_plot.points">plot.points</code></td>
<td>
<p>Logical. If <code>TRUE</code>, plots the actual data points as
a scatterplot on top of the interaction lines. The color of the dots will
be based on their moderator value.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_interval">interval</code></td>
<td>
<p>Logical. If <code>TRUE</code>, plots confidence/prediction
intervals around the line using <code><a href="ggplot2.html#topic+geom_ribbon">geom_ribbon</a></code>.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_data">data</code></td>
<td>
<p>Optional, default is NULL. You may provide the data used to
fit the model. This can be a better way to get mean values for centering
and can be crucial for models with variable transformations in the formula
(e.g., <code>log(x)</code>) or polynomial terms (e.g., <code>poly(x, 2)</code>). You will
see a warning if the function detects problems that would likely be
solved by providing the data with this argument and the function will
attempt to retrieve the original data from the global environment.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_at">at</code></td>
<td>
<p>If you want to manually set the values of other variables in the
model, do so by providing a named list where the names are the variables
and the list values are vectors of the values. This can be useful
especially when you are exploring interactions or other conditional
predictions.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_int.type">int.type</code></td>
<td>
<p>Type of interval to plot. Options are &quot;confidence&quot; or
&quot;prediction&quot;. Default is confidence interval.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_int.width">int.width</code></td>
<td>
<p>How large should the interval be, relative to the standard
error? The default, .95, corresponds to roughly 1.96 standard errors and
a .05 alpha level for values outside the range. In other words, for a
confidence interval, .95 is analogous to a 95% confidence interval.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_outcome.scale">outcome.scale</code></td>
<td>
<p>For nonlinear models (i.e., GLMs), should the outcome
variable be plotted on the link scale (e.g., log odds for logit models) or
the original scale (e.g., predicted probabilities for logit models)? The
default is <code>"response"</code>, which is the original scale. For the link
scale, which will show straight lines rather than curves, use
<code>"link"</code>.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_robust">robust</code></td>
<td>
<p>Should robust standard errors be used to find confidence
intervals for supported models? Default is FALSE, but you should specify
the type of sandwich standard errors if you'd like to use them (i.e.,
<code>"HC0"</code>, <code>"HC1"</code>, and so on). If <code>TRUE</code>, defaults to <code>"HC3"</code> standard
errors.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_cluster">cluster</code></td>
<td>
<p>For clustered standard errors, provide the column name of
the cluster variable in the input data frame (as a string). Alternately,
provide a vector of clusters.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_vcov">vcov</code></td>
<td>
<p>Optional. You may supply the variance-covariance matrix of the
coefficients yourself. This is useful if you are using some method for
robust standard error calculation not supported by the <span class="pkg">sandwich</span>
package.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_set.offset">set.offset</code></td>
<td>
<p>For models with an offset (e.g., Poisson models), sets an
offset for the predicted values. All predicted values will have the same
offset. By default, this is set to 1, which makes the predicted values a
proportion. See details for more about offset support.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_x.label">x.label</code></td>
<td>
<p>A character object specifying the desired x-axis label. If
<code>NULL</code>, the variable name is used.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_y.label">y.label</code></td>
<td>
<p>A character object specifying the desired x-axis label. If
<code>NULL</code>, the variable name is used.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_pred.labels">pred.labels</code></td>
<td>
<p>A character vector of labels for categorical predictors.
If <code>NULL</code>, the default, the factor labels are used.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_main.title">main.title</code></td>
<td>
<p>A character object that will be used as an overall title
for the plot. If <code>NULL</code>, no main title is used.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_colors">colors</code></td>
<td>
<p>See <a href="#topic+jtools_colors">jtools_colors</a> for details on the types of arguments
accepted. Default is &quot;black&quot;. This affects the coloration of the line
as well as confidence intervals and points unless you give a different
argument to <code>line.color</code>.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_line.colors">line.colors</code></td>
<td>
<p>See <a href="#topic+jtools_colors">jtools_colors</a> for details on the types of arguments
accepted. Default is <code>colors</code>. This affects the coloration of the line
as well as confidence intervals, but not the points.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_line.thickness">line.thickness</code></td>
<td>
<p>How thick should the plotted lines be? Default is 1.1;
ggplot's default is 1.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_point.size">point.size</code></td>
<td>
<p>What size should be used for observed data when
<code>plot.points</code> is TRUE? Default is 1.5.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_point.alpha">point.alpha</code></td>
<td>
<p>What should the <code>alpha</code> aesthetic for plotted points of
observed data be? Default is 0.6, and it can range from 0 (transparent) to
1 (opaque).</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_jitter">jitter</code></td>
<td>
<p>How much should <code>plot.points</code> observed values be &quot;jittered&quot;
via <code><a href="ggplot2.html#topic+position_jitter">ggplot2::position_jitter()</a></code>? When there are many points near each
other, jittering moves them a small amount to keep them from
totally overlapping. In some cases, though, it can add confusion since
it may make points appear to be outside the boundaries of observed
values or cause other visual issues. Default is 0, but try various
small values (e.g., 0.1) and increase as needed if your points are
overlapping too much. If the argument is a vector with two values,
then the first is assumed to be the jitter for width and the second
for the height.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_rug">rug</code></td>
<td>
<p>Show a rug plot in the margins? This uses <code><a href="ggplot2.html#topic+geom_rug">ggplot2::geom_rug()</a></code>
to show the distribution of the predictor (top/bottom) and/or
response variable (left/right) in the original data. Default is
FALSE.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_rug.sides">rug.sides</code></td>
<td>
<p>On which sides should rug plots appear? Default is &quot;lb&quot;,
meaning both left and bottom. &quot;t&quot; and/or &quot;b&quot; show the distribution of
the predictor
while &quot;l&quot; and/or &quot;r&quot; show the distribution of the response.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_force.cat">force.cat</code></td>
<td>
<p>Force the continuous <code>pred</code> to be treated as categorical?
default is FALSE, but this can be useful for things like dummy 0/1
variables.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_cat.geom">cat.geom</code></td>
<td>
<p>If <code>pred</code> is categorical (or <code>force.cat</code> is TRUE),
what type of plot should this be? There are several options
here since the best way to visualize categorical interactions varies by
context. Here are the options:
</p>

<ul>
<li> <p><code>"point"</code>: The default. Simply plot the point estimates. You may want to
use <code>point.shape = TRUE</code> with this and you should also consider
<code>interval = TRUE</code> to visualize uncertainty.
</p>
</li>
<li> <p><code>"line"</code>: This connects observations across levels of the <code>pred</code>
variable with a line. This is a good option when the <code>pred</code> variable
is ordinal (ordered). You may still consider <code>point.shape = TRUE</code> and
<code>interval = TRUE</code> is still a good idea.
</p>
</li>
<li> <p><code>"bar"</code>: A bar chart. Some call this a &quot;dynamite plot.&quot;
Many applied researchers advise against this type of plot because it
does not represent the distribution of the observed data or the
uncertainty of the predictions very well. It is best to at least use the
<code>interval = TRUE</code> argument with this geom.
</p>
</li></ul>
</td></tr>
<tr><td><code id="effect_plot_+3A_cat.interval.geom">cat.interval.geom</code></td>
<td>
<p>For categorical by categorical interactions.
One of &quot;errorbar&quot; or &quot;linerange&quot;. If the former,
<code><a href="ggplot2.html#topic+geom_linerange">ggplot2::geom_errorbar()</a></code> is used. If the latter,
<code><a href="ggplot2.html#topic+geom_linerange">ggplot2::geom_linerange()</a></code> is used.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_cat.pred.point.size">cat.pred.point.size</code></td>
<td>
<p>(for categorical <code>pred</code>)
If TRUE and <code>geom</code> is <code>"point"</code> or <code>"line"</code>,
sets the size of the predicted points. Default is 3.5.
Note the distinction from <code>point.size</code>, which refers to the
observed data points.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_partial.residuals">partial.residuals</code></td>
<td>
<p>Instead of plotting the observed data, you may plot
the partial residuals (controlling for the effects of variables besides
<code>pred</code>).</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_color.class">color.class</code></td>
<td>
<p>Deprecated. Now known as <code>colors</code>.</p>
</td></tr>
<tr><td><code id="effect_plot_+3A_...">...</code></td>
<td>
<p>extra arguments passed to <code>make_predictions()</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function provides a means for plotting effects for the
purpose of exploring regression estimates. You must have the
package <code>ggplot2</code> installed to benefit from these plotting functions.
</p>
<p>By default, all numeric predictors other than the one specified in the
<code>pred</code> argument are mean-centered, which usually produces more
intuitive plots. This only affects the y-axis in linear models, but
may be especially important/influential in non-linear/generalized linear
models.
</p>
<p>This function supports nonlinear and generalized linear models and by
default will plot them on
their original scale (<code>outcome.scale = "response"</code>).
</p>
<p>While mixed effects models from <code>lme4</code> are supported, only the fixed
effects are plotted. <code>lme4</code> does not provide confidence intervals,
so they are not supported with this function either.
</p>
<p>Note: to use transformed predictors, e.g., <code>log(x)</code>, or polynomials,
e.g., <code>poly(x, 2)</code>, provide the raw variable name (<code>x</code>) to the <code style="white-space: pre;">&#8288;pred =&#8288;</code>
argument. You will need to input the data frame used to fit the model with
the <code style="white-space: pre;">&#8288;data =&#8288;</code> argument.
</p>


<h3>Value</h3>

<p>The functions returns a <code>ggplot</code> object, which can be treated
like
a user-created plot and expanded upon as such.
</p>


<h3>Author(s)</h3>

<p>Jacob Long <a href="mailto:jacob.long@sc.edu">jacob.long@sc.edu</a>
</p>


<h3>See Also</h3>

<p><code>interact_plot</code> from the <code>interactions</code> package plots interaction
effects,
producing plots like this function but with separate lines for different
levels of a moderator. <code>cat_plot</code> from <code>interactions</code> does the same
for categorical by categorical interactions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Using a fitted lm model
states &lt;- as.data.frame(state.x77)
states$HSGrad &lt;- states$`HS Grad`
fit &lt;- lm(Income ~ HSGrad + Murder,
  data = states)
effect_plot(model = fit, pred = Murder)

# Using polynomial predictor, plus intervals
fit &lt;- lm(accel ~ poly(mag,3) + dist, data = attenu)
effect_plot(fit, pred = mag, interval = TRUE,
  int.type = "confidence", int.width = .8, data = attenu) # note data arg.

# With svyglm
if (requireNamespace("survey")) {
library(survey)
data(api)
dstrat &lt;- svydesign(id = ~1, strata = ~stype, weights = ~pw,
                    data = apistrat, fpc = ~fpc)
regmodel &lt;- svyglm(api00 ~ ell + meals, design = dstrat)
effect_plot(regmodel, pred = ell, interval = TRUE)
}

# With lme4
## Not run: 
library(lme4)
data(VerbAgg)
mv &lt;- glmer(r2 ~ Anger + mode + (1 | item), data = VerbAgg,
            family = binomial,
            control = glmerControl("bobyqa"))
effect_plot(mv, pred = Anger)

## End(Not run)

</code></pre>

<hr>
<h2 id='export_summs'>Export regression summaries to tables</h2><span id='topic+export_summs'></span>

<h3>Description</h3>

<p>This function allows users to use the features of
<code><a href="#topic+summ">summ()</a></code> (e.g., standardization, robust standard errors)
in the context of shareable HTML, LaTeX, and
Microsoft Word tables. It relies heavily on <code><a href="huxtable.html#topic+huxreg">huxtable::huxreg()</a></code>
to do the table formatting. This is particularly useful for putting
the results of multiple models into a single table.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>export_summs(
  ...,
  error_format = "({std.error})",
  error_pos = c("below", "right", "same"),
  ci_level = 0.95,
  statistics = NULL,
  model.names = NULL,
  coefs = NULL,
  to.file = NULL,
  file.name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="export_summs_+3A_...">...</code></td>
<td>
<p>At minimum, a regression object(s). See details for more
arguments.</p>
</td></tr>
<tr><td><code id="export_summs_+3A_error_format">error_format</code></td>
<td>
<p>Which of standard error, confidence intervals, test
statistics, or p values should be used to express uncertainty of estimates
for regression coefficients? See details for more info.
Default: &quot;(std.error)&quot;</p>
</td></tr>
<tr><td><code id="export_summs_+3A_error_pos">error_pos</code></td>
<td>
<p>Where should the error statistic defined in
<code>error_style</code> be placed relative to the coefficient estimate?
Default: &quot;below&quot;</p>
</td></tr>
<tr><td><code id="export_summs_+3A_ci_level">ci_level</code></td>
<td>
<p>If reporting confidence intervals, what should the
confidence level be? By default, it is .95 if
confidence intervals are requested in <code>error_format</code>.</p>
</td></tr>
<tr><td><code id="export_summs_+3A_statistics">statistics</code></td>
<td>
<p>Which model summary statistics should be included?
See <code><a href="huxtable.html#topic+huxreg">huxreg</a></code> for more on usage. The default
for this function depends on the model type. See details for more on
the defaults by model type.</p>
</td></tr>
<tr><td><code id="export_summs_+3A_model.names">model.names</code></td>
<td>
<p>If you want to give your model(s) names at the top
of each column, provide them here as a character vector.
Otherwise, they will just be labeled by number. Default: NULL</p>
</td></tr>
<tr><td><code id="export_summs_+3A_coefs">coefs</code></td>
<td>
<p>If you want to include only a subset of the coefficients in
the table, specify them here in a character vector. If you want the
table to show different names for the coefficients, give a named vector
where the names are the preferred coefficient names. See details for more.</p>
</td></tr>
<tr><td><code id="export_summs_+3A_to.file">to.file</code></td>
<td>
<p>Export the table to a Microsoft Word, PDF, or HTML document?
This functionality relies on <code>huxtable</code>'s <code>quick_</code> functions
(<code><a href="huxtable.html#topic+quick-output">huxtable::quick_docx()</a></code>, <code><a href="huxtable.html#topic+quick-output">huxtable::quick_pdf()</a></code>,
<code><a href="huxtable.html#topic+quick-output">huxtable::quick_html()</a></code>, <code><a href="huxtable.html#topic+quick-output">huxtable::quick_xlsx()</a></code>). Acceptable arguments
are &quot;Word&quot; or &quot;docx&quot; (equivalent), &quot;pdf&quot;, &quot;html&quot;, or &quot;xlsx&quot;. All are
case insensitive. Default is NULL, meaning the table is not saved.</p>
</td></tr>
<tr><td><code id="export_summs_+3A_file.name">file.name</code></td>
<td>
<p>File name with (optionally) file path to save the
file. Ignored if <code>to.file</code> is FALSE. Default: NULL</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are many optional parameters not documented above. Any
argument that you would want to pass to <code><a href="#topic+summ">summ()</a></code>, for instance,
will be used. Of particular interest may be the robust and scale
arguments. Note that some <code>summ</code> arguments may not have any bearing
on the table output.
</p>
<p>The default model summary statistics reporting follows this logic:
</p>

<ul>
<li><p> summ.lm = <code>c(N = "nobs", R2 = "r.squared")</code>,
</p>
</li>
<li><p> summ.glm = <code>c(N = "nobs", AIC = "AIC", BIC = "BIC",
                       `Pseudo R2` = "pseudo.r.squared")</code>,
</p>
</li>
<li><p> summ.svyglm = <code>c(N = "nobs", R2 = "r.squared")</code>,
</p>
</li>
<li><p> summ.merMod = <code>c(N = "nobs", AIC = "AIC", BIC = "BIC",
                          `R2 (fixed)` = "r.squared.fixed",
                          `R2 (total)` = "r.squared")</code>
</p>
</li>
<li><p> summ.rq = <code>c(N = "nobs", tau = "tau", R1 = "r.1", AIC = "AIC", BIC = "BIC")</code>
</p>
</li></ul>

<p>Be sure to look at the <code><a href="#topic+summ">summ()</a></code> documentation for more on the calculation
of these and other statistics, especially for mixed models.
</p>
<p>If you set <code>statistics = "all"</code>, then the statistics argument
passed to <code>huxreg</code> will be <code>NULL</code>, which reports whichever
model statistics are available via <code>glance</code>. If you want no
model summary statistics, set the argument to <code>character(0)</code>.
</p>
<p>You have a few options for the <code>error_format</code> argument.
You can include anything returned by <code><a href="broom.html#topic+reexports">broom::tidy()</a></code>
(see also <code><a href="#topic+tidy.summ">tidy.summ()</a></code>). For the most part, you will
be interested in <code>std.error</code> (standard error), <code>statistic</code>
(test statistic, e.g. t-value or z-value), <code>p.value</code>, or
<code>conf.high</code> and <code>conf.low</code>, which correspond to the
upper and lower bounds of the confidence interval for the estimate.
Note that the default <code>ci_level</code> argument is .95, but you
can alter that as desired.
</p>
<p>To format the error statistics, simply put the statistics desired in
curly braces wherever you want them in a character string. For example,
if you want the standard error in parentheses, the argument would be
<code>"({std.error})"</code>, which is the default. Some other ideas:
</p>

<ul>
<li> <p><code>"({statistic})"</code>, which gives you the test statistic in
parentheses.
</p>
</li>
<li> <p><code>"({statistic}, p = {p.value})"</code>, which gives the test
statistic followed by a &quot;p =&quot; p value all in parentheses. Note that
you'll have to pay special attention to rounding if you do this to keep
cells sufficiently narrow.
</p>
</li>
<li> <p><code>"[{conf.low}, {conf.high}]"</code>, which gives the confidence
interval in the standard bracket notation. You could also explicitly
write the confidence level, e.g.,
<code>"CI [{conf.low}, {conf.high}]"</code>.
</p>
</li></ul>

<p>For <code>coefs</code>, the argument is slightly different than what is default
in <code>huxreg</code>. If you provide a named vector of coefficients, then
the table will refer to the selected coefficients by the names of the
vector rather than the coefficient names. For instance, if I want to
include only the coefficients for the <code>hp</code> and <code>mpg</code> but have
the table refer to them as &quot;Horsepower&quot; and &quot;Miles/gallon&quot;, I'd provide
the argument like this:
<code>c("Horsepower" = "hp", "Miles/gallon" = "mpg")</code>
</p>
<p>You can also pass any argument accepted by the
<code><a href="huxtable.html#topic+huxreg">huxtable::huxreg()</a></code> function. A few that are likely to be
oft-used are documented above, but visit <code>huxreg</code>'s documentation
for more info.
</p>
<p>For info on converting the <code><a href="huxtable.html#topic+huxtable">huxtable::huxtable()</a></code> object to
HTML or LaTeX, see <code>huxtable</code>'s documentation.
</p>


<h3>Value</h3>

<p>A <code>huxtable</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summ">summ</a></code>
</p>
<p><code><a href="huxtable.html#topic+huxreg">huxreg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>states &lt;- as.data.frame(state.x77)
fit1 &lt;- lm(Income ~ Frost, data = states)
fit2 &lt;- lm(Income ~ Frost + Illiteracy, data = states)
fit3 &lt;- lm(Income ~ Frost + Illiteracy + Murder, data = states)

if (requireNamespace("huxtable")) {
  # Export all 3 regressions with "Model #" labels,
  # standardized coefficients, and robust standard errors
  export_summs(fit1, fit2, fit3,
               model.names = c("Model 1","Model 2","Model 3"),
               coefs = c("Frost Days" = "Frost",
                         "% Illiterate" = "Illiteracy",
                         "Murder Rate" = "Murder"),
               scale = TRUE, robust = TRUE)
}

</code></pre>

<hr>
<h2 id='get_colors'>Get colors for plotting functions</h2><span id='topic+get_colors'></span>

<h3>Description</h3>

<p>This is a helper function that provides hex color codes for
<code>jtools</code>, <code>interactions</code>, and perhaps other packages.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_colors(colors, num.colors = 1, reverse = FALSE, gradient = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_colors_+3A_colors">colors</code></td>
<td>
<p>The name of the desired color class or a vector of colors.
See details of <a href="#topic+jtools_colors">jtools_colors</a>.</p>
</td></tr>
<tr><td><code id="get_colors_+3A_num.colors">num.colors</code></td>
<td>
<p>How many colors should be returned? Default is 1.</p>
</td></tr>
<tr><td><code id="get_colors_+3A_reverse">reverse</code></td>
<td>
<p>Should the colors be returned in reverse order, compared to
normal? Default is FALSE.</p>
</td></tr>
<tr><td><code id="get_colors_+3A_gradient">gradient</code></td>
<td>
<p>Return endpoints for a gradient? Default is FALSE. If TRUE,
<code>num.colors</code> is ignored.</p>
</td></tr>
</table>

<hr>
<h2 id='get_formula'>Retrieve formulas from model objects</h2><span id='topic+get_formula'></span><span id='topic+get_formula.default'></span><span id='topic+get_formula.brmsfit'></span><span id='topic+get_formula.panelmodel'></span>

<h3>Description</h3>

<p>This function is primarily an internal helper function in <code>jtools</code> and
related packages to standardize the different types of formula objects used
by different types of models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_formula(model, ...)

## Default S3 method:
get_formula(model, ...)

## S3 method for class 'brmsfit'
get_formula(model, resp = NULL, dpar = NULL, ...)

## S3 method for class 'panelmodel'
get_formula(model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_formula_+3A_model">model</code></td>
<td>
<p>The fitted model object.</p>
</td></tr>
<tr><td><code id="get_formula_+3A_...">...</code></td>
<td>
<p>Ignored.</p>
</td></tr>
<tr><td><code id="get_formula_+3A_resp">resp</code></td>
<td>
<p>For <code>brmsfit</code> objects, the response variable for which
the formula is desired. <code>brmsfit</code> objects may have multiple formulas, so
this selects a particular one. If <code>NULL</code>, the first formula is chosen
(unless <code>dpar</code> is specified).</p>
</td></tr>
<tr><td><code id="get_formula_+3A_dpar">dpar</code></td>
<td>
<p>For <code>brmsfit</code> objects, the distributional variable for which
the formula is desired. If <code>NULL</code>, no distributional parameter is used.
If there are multiple responses with distributional parameters, then
<code>resp</code> should be specified or else the first formula will be used by
default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>formula</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(mtcars)
fit &lt;- lm(mpg ~ cyl, data = mtcars)
get_formula(fit)

</code></pre>

<hr>
<h2 id='get_offset_name'>Utility functions for generating model predictions</h2><span id='topic+get_offset_name'></span><span id='topic+get_weights'></span><span id='topic+get_data'></span><span id='topic+get_response_name'></span>

<h3>Description</h3>

<p>These functions get information and data from regression models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_offset_name(model)

get_weights(model, data)

get_data(model, formula = NULL, warn = TRUE, ...)

get_response_name(model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_offset_name_+3A_model">model</code></td>
<td>
<p>The model (e.g., <code>lm</code>, <code>glm</code>, <code>merMod</code>, <code>svyglm</code>)</p>
</td></tr>
<tr><td><code id="get_offset_name_+3A_data">data</code></td>
<td>
<p>For <code>get_weights()</code>, the data used to fit the model.</p>
</td></tr>
<tr><td><code id="get_offset_name_+3A_formula">formula</code></td>
<td>
<p>The formula for <code>model</code>, if desired. Otherwise <code>get_formula()</code>
is called.</p>
</td></tr>
<tr><td><code id="get_offset_name_+3A_warn">warn</code></td>
<td>
<p>For <code>get_data()</code>, should there be a warning when <code>model.frame()</code>
won't work because of variable transformations? Default is TRUE but this
may not be desired when <code>get_data()</code> is used inside of another function or
used multiple times.</p>
</td></tr>
<tr><td><code id="get_offset_name_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code>get_formula()</code></p>
</td></tr>
</table>


<h3>Value</h3>


<ul>
<li> <p><code>get_data()</code>: The data used to fit the model.
</p>
</li>
<li> <p><code>get_response_name()</code>: The name of the response variable.
</p>
</li>
<li> <p><code>get_offset_name()</code>: The name of the offset variable.
</p>
</li>
<li> <p><code>get_weights()</code>: A list with <code>weights_name</code>, the name of the weighting
variable, and <code>weights</code>, the weights themselves (or all 1 when there are
no weights).
</p>
</li></ul>


<hr>
<h2 id='get_robust_se'>Calculate robust standard errors and produce coefficient tables</h2><span id='topic+get_robust_se'></span>

<h3>Description</h3>

<p>This function wraps around several <span class="pkg">sandwich</span>
and <span class="pkg">lmtest</span> functions to calculate robust standard errors and returns
them in a useful format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_robust_se(
  model,
  type = "HC3",
  cluster = NULL,
  data = model.frame(model),
  vcov = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_robust_se_+3A_model">model</code></td>
<td>
<p>A regression model, preferably of class <code>lm</code> or <code>glm</code></p>
</td></tr>
<tr><td><code id="get_robust_se_+3A_type">type</code></td>
<td>
<p>One of <code>"HC3"</code>, <code>"const"</code>, <code>"HC"</code>, <code>"HC0"</code>, <code>"HC1"</code>,
<code>"HC2"</code>, <code>"HC4"</code>, <code>"HC4m"</code>, <code>"HC5"</code>. See <code><a href="sandwich.html#topic+vcovHC">sandwich::vcovHC()</a></code> for some
more details on these choices. Note that some of these do not work for
clustered standard errors (see sandwich::vcovCL()]).</p>
</td></tr>
<tr><td><code id="get_robust_se_+3A_cluster">cluster</code></td>
<td>
<p>If you want clustered standard errors, either a string naming
the column in <code>data</code> that represents the clusters or a vector of clusters
that is the same length as the number of rows in <code>data</code>.</p>
</td></tr>
<tr><td><code id="get_robust_se_+3A_data">data</code></td>
<td>
<p>The data used to fit the model. Default is to just get the
<code>model.frame</code> from <code>model</code>.</p>
</td></tr>
<tr><td><code id="get_robust_se_+3A_vcov">vcov</code></td>
<td>
<p>You may provide the variance-covariance matrix yourself and this
function will just calculate standard errors, etc. based on that. Default
is NULL.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following:
</p>

<ul>
<li> <p><code>coefs</code>: a coefficient table with the estimates, standard errors,
t-statistics, and p-values from <code>lmtest</code>.
</p>
</li>
<li> <p><code>ses</code>: The standard errors from <code>coefs</code>.
</p>
</li>
<li> <p><code>ts</code>: The t-statistics from <code>coefs</code>.
</p>
</li>
<li> <p><code>ps</code>: The p-values from <code>coefs</code>.
</p>
</li>
<li> <p><code>type</code>: The argument to <code>robust</code>.
</p>
</li>
<li> <p><code>use_cluster</code>: <code>TRUE</code> or <code>FALSE</code> indicator of whether clusters were used.
</p>
</li>
<li> <p><code>cluster</code>: The clusters or name of cluster variable used, if any.
</p>
</li>
<li> <p><code>vcov</code>: The robust variance-covariance matrix.
</p>
</li></ul>


<hr>
<h2 id='gscale'>Scale and/or center data, including survey designs</h2><span id='topic+gscale'></span>

<h3>Description</h3>

<p><code>gscale</code> standardizes variables by dividing them by 2 standard
deviations and mean-centering them by default. It contains options for
handling binary variables separately. <code>gscale()</code> is a fork of
<code>rescale</code> from the <code>arm</code> package&mdash;the key feature
difference is that <code>gscale()</code> will perform the same functions for
variables in <code><a href="survey.html#topic+svydesign">svydesign</a></code> objects. <code>gscale()</code> is
also more user-friendly in that it is more flexible in how it accepts input.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gscale(
  data = NULL,
  vars = NULL,
  binary.inputs = "center",
  binary.factors = FALSE,
  n.sd = 2,
  center.only = FALSE,
  scale.only = FALSE,
  weights = NULL,
  apply.weighted.contrasts = getOption("jtools-weighted.contrasts", FALSE),
  x = NULL,
  messages = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gscale_+3A_data">data</code></td>
<td>
<p>A data frame or survey design. Only needed if you would like to
rescale multiple variables at once. If <code>x = NULL</code>, all columns will
be rescaled. Otherwise, <code>x</code> should be a vector of variable names. If
<code>x</code> is a numeric vector, this argument is ignored.</p>
</td></tr>
<tr><td><code id="gscale_+3A_vars">vars</code></td>
<td>
<p>If <code>data</code> is a data.frame or similar, you can scale only
select columns by providing a vector column names to this argument.</p>
</td></tr>
<tr><td><code id="gscale_+3A_binary.inputs">binary.inputs</code></td>
<td>
<p>Options for binary variables. Default is <code>center</code>;
<code>0/1</code> keeps original scale; <code>-0.5/0.5</code> rescales 0 as -0.5 and 1
as 0.5; <code>center</code> subtracts the mean; and <code>full</code> subtracts the
mean and divides by 2 sd.</p>
</td></tr>
<tr><td><code id="gscale_+3A_binary.factors">binary.factors</code></td>
<td>
<p>Coerce two-level factors to numeric and apply scaling
functions to them? Default is FALSE.</p>
</td></tr>
<tr><td><code id="gscale_+3A_n.sd">n.sd</code></td>
<td>
<p>By how many standard deviations should the variables be divided
by? Default for <code>gscale</code> is 2, like <code>arm</code>'s <code>rescale</code>.
1 is the more typical standardization scheme.</p>
</td></tr>
<tr><td><code id="gscale_+3A_center.only">center.only</code></td>
<td>
<p>A logical value indicating whether you would like to mean
-center the values, but not scale them.</p>
</td></tr>
<tr><td><code id="gscale_+3A_scale.only">scale.only</code></td>
<td>
<p>A logical value indicating whether you would like to scale
the values, but not mean-center them.</p>
</td></tr>
<tr><td><code id="gscale_+3A_weights">weights</code></td>
<td>
<p>A vector of weights equal in length to <code>x</code>. If iterating
over a data frame, the weights will need to be equal in length to all the
columns to avoid errors. You may need to remove missing values before using
the weights.</p>
</td></tr>
<tr><td><code id="gscale_+3A_apply.weighted.contrasts">apply.weighted.contrasts</code></td>
<td>
<p>Factor variables cannot be scaled, but you
can set the contrasts such that the intercept in a regression model will
reflect the true mean (assuming all other variables are centered). If set
to TRUE, the argument will apply weighted effects coding to all factors.
This is similar to the R default effects coding, but weights according to
how many observations are at each level. An adapted version of
<code>contr.wec()</code> from the <code>wec</code> package is used to do this. See
that package's documentation and/or Grotenhuis et al. (2016) for more
info.</p>
</td></tr>
<tr><td><code id="gscale_+3A_x">x</code></td>
<td>
<p>Deprecated. Pass numeric vectors to <code>data</code>. Pass vectors of column
names to <code>vars</code>.</p>
</td></tr>
<tr><td><code id="gscale_+3A_messages">messages</code></td>
<td>
<p>Print messages when variables are not processed due to
being non-numeric or all missing? Default is FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is adapted from the <code>rescale</code> function of
the <code>arm</code> package. It is named <code>gscale()</code> after the
popularizer of this scaling method, Andrew <strong>G</strong>elman. By default, it
works just like <code>rescale</code>. But it contains many additional options and
can also accept multiple types of input without breaking a sweat.
</p>
<p>Only numeric variables are altered when in a data.frame or survey design.
Character variables, factors, etc. are skipped.
</p>
<p>For those dealing with survey data, if you provide a <code>survey.design</code>
object you can rest assured that the mean-centering and scaling is performed
with help from the <code><a href="survey.html#topic+surveysummary">svymean()</a></code> and
<code><a href="survey.html#topic+surveysummary">svyvar()</a></code> functions, respectively. It was among the
primary motivations for creating this function. <code>gscale()</code> will not
center or scale the weights variables defined in the survey design unless
the user specifically requests them in the <code>x =</code> argument.
</p>


<h3>Author(s)</h3>

<p>Jacob Long <a href="mailto:jacob.long@sc.edu">jacob.long@sc.edu</a>
</p>


<h3>References</h3>

<p>Gelman, A. (2008). Scaling regression inputs by dividing by two standard
deviations. <em>Statistics in Medicine</em>, <em>27</em>, 28652873.
<a href="http://www.stat.columbia.edu/~gelman/research/published/standardizing7.pdf">http://www.stat.columbia.edu/~gelman/research/published/standardizing7.pdf</a>
</p>
<p>Grotenhuis, M. te, Pelzer, B., Eisinga, R., Nieuwenhuis, R.,
Schmidt-Catran, A., &amp; Konig, R. (2017). When size matters: Advantages of
weighted effect coding in observational studies. <em>International Journal of
Public Health</em>, <em>62</em>, 163167. https://doi.org/10.1007/s00038-016-0901-1 (
open access)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+j_summ">j_summ</a></code> is a replacement for the <code>summary</code> function for
regression models. On request, it will center and/or standardize variables
before printing its output.
</p>
<p>Other standardization: 
<code><a href="#topic+center_mod">center_mod</a>()</code>,
<code><a href="#topic+center">center</a>()</code>,
<code><a href="#topic+scale_mod">scale_mod</a>()</code>,
<code><a href="#topic+standardize">standardize</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- rnorm(10, 2, 1)
x2 &lt;- rbinom(10, 1, .5)

# Basic use
gscale(x)
# Normal standardization
gscale(x, n.sd = 1)
# Scale only
gscale(x, scale.only = TRUE)
# Center only
gscale(x, center.only = TRUE)
# Binary inputs
gscale(x2, binary.inputs = "0/1")
gscale(x2, binary.inputs = "full") # treats it like a continous var
gscale(x2, binary.inputs = "-0.5/0.5") # keep scale, center at zero
gscale(x2, binary.inputs = "center") # mean center it

# Data frame as input
# loops through each numeric column
gscale(data = mtcars, binary.inputs = "-0.5/0.5")

# Specified vars in data frame
gscale(mtcars, vars = c("hp", "wt", "vs"), binary.inputs = "center")

# Weighted inputs

wts &lt;- runif(10, 0, 1)
gscale(x, weights = wts)
# If using a weights column of data frame, give its name
mtcars$weights &lt;- runif(32, 0, 1)
gscale(mtcars, weights = weights) # will skip over mtcars$weights
# If using a weights column of data frame, can still select variables
gscale(mtcars, vars = c("hp", "wt", "vs"), weights = weights)

# Survey designs
if (requireNamespace("survey")) {
  library(survey)
  data(api)
  ## Create survey design object
  dstrat &lt;- svydesign(id = ~1, strata = ~stype, weights = ~pw,
                       data = apistrat, fpc=~fpc)
  # Creating test binary variable
  dstrat$variables$binary &lt;- rbinom(200, 1, 0.5)

  gscale(data = dstrat, binary.inputs = "-0.5/0.5")
  gscale(data = dstrat, vars = c("api00","meals","binary"),
         binary.inputs = "-0.5/0.5")
}



</code></pre>

<hr>
<h2 id='interact_plot'>Deprecated interaction functions</h2><span id='topic+interact_plot'></span><span id='topic+cat_plot'></span><span id='topic+sim_slopes'></span><span id='topic+johnson_neyman'></span><span id='topic+probe_interaction'></span>

<h3>Description</h3>

<p>These functions are now part of the <code>interactions</code>
package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interact_plot(...)

cat_plot(...)

sim_slopes(...)

johnson_neyman(...)

probe_interaction(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="interact_plot_+3A_...">...</code></td>
<td>
<p>arguments are ignored</p>
</td></tr>
</table>

<hr>
<h2 id='jtools_colors'>Color palettes in <code>jtools</code> functions</h2><span id='topic+jtools_colors'></span>

<h3>Description</h3>

<p><code>jtools</code> combines several options into the <code>colors</code>
argument in plotting functions.
</p>


<h3>Details</h3>

<p>The argument to <code>colors</code> in functions like <code>effect_plot</code>,
<code>plot_coefs</code>, and others is very flexible but may also
cause confusion.
</p>
<p>If you provide an argument of length 1, it is assumed that you are naming
a palette. <code>jtools</code> provides 6 color palettes design for qualitative data.
4 of the 6 are based on Paul Tol's suggestions (see references) and are
meant to both optimize your ability to quickly differentiate the colors
and to be distinguishable to colorblind people.
These are called
<code>"Qual1"</code>, <code>"Qual2"</code>, <code>"Qual3"</code>, <code>"CUD"</code>, <code>"CUD Bright"</code>, and <code>"Rainbow"</code>.
Each of the &quot;Qual&quot; schemes comes from Paul Tol.
&quot;Rainbow&quot; is Paul Tol's compromise rainbow color scheme that is fairly
differentiable for colorblind people and when rendered in grayscale.
<code>"CUD Bright"</code> is a brightened and reordered version of Okabe and Ito's
suggestions for 'Color Universal Design' while <code>"CUD"</code> is their exact
scheme (see references). <code>"CUD Bright"</code> is the default for qualitative
scales in <code>jtools</code> functions.
</p>
<p>You may also provide any color palette supported by <code>RColorBrewer</code>.
See all of those options at <code><a href="RColorBrewer.html#topic+ColorBrewer">RColorBrewer::brewer.pal()</a></code>'s documentation.
If you provide one of <code>RColorBrewer</code>'s sequential palettes, like &quot;Blues&quot;,
<code>jtools</code> automatically requests one more color than needed from
<code>brewer.pal</code> and then drops the lightest color. My experience is that
those scales tend to give one color that is too light to easily
differentiate against a white background.
</p>
<p>For <strong>gradients</strong>, you can use any of the <code>RColorBrewer</code> sequential palette
names and get comparable results on a continuous scale. There are also some
<code>jtools</code>-specific gradient schemes: <code>"blue"</code>, <code>"blue2"</code>, <code>"green"</code>,
<code>"red"</code>, <code>"purple"</code>, <code>"seagreen"</code>.
If you want something a little non-standard, I'd suggest taking a look
at <code>"blue2"</code> or <code>"seagreen"</code>.
</p>
<p>Lastly, you may provide colors by name. This must be a vector of the
same length as whatever it is the colors will correspond to. The format
must be one understood by <code>ggplot2</code>'s manual scale functions. This
basically means it needs to be in hex format (e.g., &quot;#000000&quot;) or
one of the many names R understands (e.g., &quot;red&quot;; use <code>colors()</code> to
see all of those options).
</p>


<h3>References</h3>

<p>Paul Tol's site is what is used to derive 4 of the 6 <code>jtools</code>-specific
qualitative palettes: <a href="https://personal.sron.nl/~pault/">https://personal.sron.nl/~pault/</a>
</p>
<p>Okabe and Ito's palette inspired &quot;CUD Bright&quot;, though &quot;CUD Bright&quot; is not
exactly the same. &quot;CUD&quot; is the same.
See <a href="https://web.archive.org/web/20190216090108/jfly.iam.u-tokyo.ac.jp/color/">https://web.archive.org/web/20190216090108/jfly.iam.u-tokyo.ac.jp/color/</a>
for more.
</p>

<hr>
<h2 id='knit_print.summ.lm'>knitr methods for summ</h2><span id='topic+knit_print.summ.lm'></span><span id='topic+knit_print.summ.glm'></span><span id='topic+knit_print.summ.svyglm'></span><span id='topic+knit_print.summ.merMod'></span><span id='topic+knit_print.summ.rq'></span>

<h3>Description</h3>

<p>There's no reason for end users to utilize these functions,
but CRAN requires it to be documented.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>knit_print.summ.lm(x, options = NULL, ...)

knit_print.summ.glm(x, options = NULL, ...)

knit_print.summ.svyglm(x, options = NULL, ...)

knit_print.summ.merMod(x, options = NULL, ...)

knit_print.summ.rq(x, options = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="knit_print.summ.lm_+3A_x">x</code></td>
<td>
<p>The <code>summ</code> object</p>
</td></tr>
<tr><td><code id="knit_print.summ.lm_+3A_options">options</code></td>
<td>
<p>Chunk options.</p>
</td></tr>
<tr><td><code id="knit_print.summ.lm_+3A_...">...</code></td>
<td>
<p>Ignored.</p>
</td></tr>
</table>

<hr>
<h2 id='make_new_data'>Make new data for generating predicted data from regression models.</h2><span id='topic+make_new_data'></span>

<h3>Description</h3>

<p>This is a convenience function that helps automate the process
of generating predicted data from regression model from a predictor(s). It
is designed to give you the data frame for the <code>predict</code> method's <code>newdata</code>
argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_new_data(
  model,
  pred,
  pred.values = NULL,
  at = NULL,
  data = NULL,
  center = TRUE,
  set.offset = NULL,
  num.preds = 100,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_new_data_+3A_model">model</code></td>
<td>
<p>The model (e.g., <code>lm</code>, <code>glm</code>, <code>merMod</code>, <code>svyglm</code>)</p>
</td></tr>
<tr><td><code id="make_new_data_+3A_pred">pred</code></td>
<td>
<p>The name of the focal predictor as a string. This is the variable
for which, if you are plotting, you'd likely have along the x-axis (with
the dependent variable as the y-axis).</p>
</td></tr>
<tr><td><code id="make_new_data_+3A_pred.values">pred.values</code></td>
<td>
<p>The values of <code>pred</code> you want to include. Default is NULL,
which means a sequence of equi-spaced values over the range of a numeric
predictor or each level of a non-numeric predictor.</p>
</td></tr>
<tr><td><code id="make_new_data_+3A_at">at</code></td>
<td>
<p>If you want to manually set the values of other variables in the
model, do so by providing a named list where the names are the variables
and the list values are vectors of the values. This can be useful
especially when you are exploring interactions or other conditional
predictions.</p>
</td></tr>
<tr><td><code id="make_new_data_+3A_data">data</code></td>
<td>
<p>The data frame used in fitting the model. Default is NULL, in
which case the data will be retrieved via <code>model.frame</code> or, if there are
variable transformations in the formula, by looking in the environment
for the data.</p>
</td></tr>
<tr><td><code id="make_new_data_+3A_center">center</code></td>
<td>
<p>Set numeric covariates to their mean? Default is TRUE. You
may also just provide a vector of names (as strings) of covariates to
center. Note that for <code>svyglm</code> models, the survey-weighted means are used.
For models with weights, these are weighted means.</p>
</td></tr>
<tr><td><code id="make_new_data_+3A_set.offset">set.offset</code></td>
<td>
<p>If the model has an offset, the value to use for the offset
variable. Default is NULL, in which case the median of the offset variable
is used.</p>
</td></tr>
<tr><td><code id="make_new_data_+3A_num.preds">num.preds</code></td>
<td>
<p>The number of predictions to generate. Default is 100.
Ignored if <code>pred.values</code> is not <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="make_new_data_+3A_...">...</code></td>
<td>
<p>Extra arguments passed to <code>get_formula()</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Please bear in mind that this does not generate the predictions. You will
need to do that with a <code>predict</code> function for your model or another
interface, such as the <code>prediction</code> package's titular function.
</p>


<h3>Value</h3>

<p>A data frame.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
fit &lt;- lm(Income ~ Frost + Illiteracy + Murder, data = as.data.frame(state.x77))
# Basic use
new_data &lt;- make_new_data(fit, pred = "Frost")
# Set covariate to specific value
new_data &lt;- make_new_data(fit, pred = "Frost", at = list(Murder = 5))
# Set covariate to several specific values
new_data &lt;- make_new_data(fit, pred = "Frost", at = list(Murder = c(5, 10, 15)))


</code></pre>

<hr>
<h2 id='make_predictions'>Generate predicted data for plotting results of regression models</h2><span id='topic+make_predictions'></span><span id='topic+make_predictions.default'></span>

<h3>Description</h3>

<p>This is an alternate interface to the underlying tools that
make up <code><a href="#topic+effect_plot">effect_plot()</a></code> as well as <code>interactions::interact_plot()</code> and
<code>interactions::cat_plot()</code> from the <code>interactions</code> package.
<code>make_predictions()</code> creates the data to be plotted and adds information
to the original data to make it more amenable for plotting with the
predicted data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_predictions(model, ...)

## Default S3 method:
make_predictions(
  model,
  pred,
  pred.values = NULL,
  at = NULL,
  data = NULL,
  center = TRUE,
  interval = TRUE,
  int.type = c("confidence", "prediction"),
  int.width = 0.95,
  outcome.scale = "response",
  robust = FALSE,
  cluster = NULL,
  vcov = NULL,
  set.offset = NULL,
  new_data = NULL,
  return.orig.data = FALSE,
  partial.residuals = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_predictions_+3A_model">model</code></td>
<td>
<p>The model (e.g., <code>lm</code>, <code>glm</code>, <code>merMod</code>, <code>svyglm</code>)</p>
</td></tr>
<tr><td><code id="make_predictions_+3A_...">...</code></td>
<td>
<p>Ignored.</p>
</td></tr>
<tr><td><code id="make_predictions_+3A_pred">pred</code></td>
<td>
<p>The name of the focal predictor as a string. This is the variable
for which, if you are plotting, you'd likely have along the x-axis (with
the dependent variable as the y-axis).</p>
</td></tr>
<tr><td><code id="make_predictions_+3A_pred.values">pred.values</code></td>
<td>
<p>The values of <code>pred</code> you want to include. Default is NULL,
which means a sequence of equi-spaced values over the range of a numeric
predictor or each level of a non-numeric predictor.</p>
</td></tr>
<tr><td><code id="make_predictions_+3A_at">at</code></td>
<td>
<p>If you want to manually set the values of other variables in the
model, do so by providing a named list where the names are the variables
and the list values are vectors of the values. This can be useful
especially when you are exploring interactions or other conditional
predictions.</p>
</td></tr>
<tr><td><code id="make_predictions_+3A_data">data</code></td>
<td>
<p>Optional, default is NULL. You may provide the data used to
fit the model. This can be a better way to get mean values for centering
and can be crucial for models with variable transformations in the formula
(e.g., <code>log(x)</code>) or polynomial terms (e.g., <code>poly(x, 2)</code>). You will
see a warning if the function detects problems that would likely be
solved by providing the data with this argument and the function will
attempt to retrieve the original data from the global environment.</p>
</td></tr>
<tr><td><code id="make_predictions_+3A_center">center</code></td>
<td>
<p>Set numeric covariates to their mean? Default is TRUE. You
may also just provide a vector of names (as strings) of covariates to
center. Note that for <code>svyglm</code> models, the survey-weighted means are used.
For models with weights, these are weighted means.</p>
</td></tr>
<tr><td><code id="make_predictions_+3A_interval">interval</code></td>
<td>
<p>Logical. If <code>TRUE</code>, plots confidence/prediction
intervals around the line using <code><a href="ggplot2.html#topic+geom_ribbon">geom_ribbon</a></code>.</p>
</td></tr>
<tr><td><code id="make_predictions_+3A_int.type">int.type</code></td>
<td>
<p>Type of interval to plot. Options are &quot;confidence&quot; or
&quot;prediction&quot;. Default is confidence interval.</p>
</td></tr>
<tr><td><code id="make_predictions_+3A_int.width">int.width</code></td>
<td>
<p>How large should the interval be, relative to the standard
error? The default, .95, corresponds to roughly 1.96 standard errors and
a .05 alpha level for values outside the range. In other words, for a
confidence interval, .95 is analogous to a 95% confidence interval.</p>
</td></tr>
<tr><td><code id="make_predictions_+3A_outcome.scale">outcome.scale</code></td>
<td>
<p>For nonlinear models (i.e., GLMs), should the outcome
variable be plotted on the link scale (e.g., log odds for logit models) or
the original scale (e.g., predicted probabilities for logit models)? The
default is <code>"response"</code>, which is the original scale. For the link
scale, which will show straight lines rather than curves, use
<code>"link"</code>.</p>
</td></tr>
<tr><td><code id="make_predictions_+3A_robust">robust</code></td>
<td>
<p>Should robust standard errors be used to find confidence
intervals for supported models? Default is FALSE, but you should specify
the type of sandwich standard errors if you'd like to use them (i.e.,
<code>"HC0"</code>, <code>"HC1"</code>, and so on). If <code>TRUE</code>, defaults to <code>"HC3"</code> standard
errors.</p>
</td></tr>
<tr><td><code id="make_predictions_+3A_cluster">cluster</code></td>
<td>
<p>For clustered standard errors, provide the column name of
the cluster variable in the input data frame (as a string). Alternately,
provide a vector of clusters.</p>
</td></tr>
<tr><td><code id="make_predictions_+3A_vcov">vcov</code></td>
<td>
<p>Optional. You may supply the variance-covariance matrix of the
coefficients yourself. This is useful if you are using some method for
robust standard error calculation not supported by the <span class="pkg">sandwich</span>
package.</p>
</td></tr>
<tr><td><code id="make_predictions_+3A_set.offset">set.offset</code></td>
<td>
<p>For models with an offset (e.g., Poisson models), sets an
offset for the predicted values. All predicted values will have the same
offset. By default, this is set to 1, which makes the predicted values a
proportion. See details for more about offset support.</p>
</td></tr>
<tr><td><code id="make_predictions_+3A_new_data">new_data</code></td>
<td>
<p>If you would prefer to generate your own hypothetical
(or not hypothetical) data rather than have the function make a call to
<code><a href="#topic+make_new_data">make_new_data()</a></code>, you can provide it.</p>
</td></tr>
<tr><td><code id="make_predictions_+3A_return.orig.data">return.orig.data</code></td>
<td>
<p>Instead of returning a just the predicted data frame,
should the original data be returned as well? If so, then a list will be
return with both the predicted data (as the first element) and the original
data (as the second element). Default is FALSE.</p>
</td></tr>
<tr><td><code id="make_predictions_+3A_partial.residuals">partial.residuals</code></td>
<td>
<p>If <code>return.orig.data</code> is TRUE, should the observed
dependent variable be replaced with the partial residual? This makes a
call to <code><a href="#topic+partialize">partialize()</a></code>, where you can find more details.</p>
</td></tr>
</table>

<hr>
<h2 id='md_table'>Print attractive data frames in the console</h2><span id='topic+md_table'></span>

<h3>Description</h3>

<p>This function takes data frame input and prints to the console
as an ASCII/markdown table for better readability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>md_table(
  x,
  format = getOption("md_table_format", "grid"),
  digits = getOption("jtools-digits", 2),
  sig.digits = TRUE,
  row.names = rownames(x),
  col.names = colnames(x),
  align = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="md_table_+3A_x">x</code></td>
<td>
<p>A data frame or matrix.</p>
</td></tr>
<tr><td><code id="md_table_+3A_format">format</code></td>
<td>
<p>The style, which can be one of the following: &quot;multiline&quot;,
&quot;grid&quot;, &quot;simple&quot; (also &quot;pandoc&quot;), &quot;rmarkdown&quot; (also &quot;markdown&quot;).
Default: &quot;markdown&quot;</p>
</td></tr>
<tr><td><code id="md_table_+3A_digits">digits</code></td>
<td>
<p>How many digits to print for numbers.
Default: 2</p>
</td></tr>
<tr><td><code id="md_table_+3A_sig.digits">sig.digits</code></td>
<td>
<p>Should each number be printed with <code>digits</code> number of
digits or only when there are at least that many significant digits? Default
is TRUE, meaning only print <code>digits</code> number of <em>significant</em> digits.</p>
</td></tr>
<tr><td><code id="md_table_+3A_row.names">row.names</code></td>
<td>
<p>if FALSE, row names are suppressed. A character vector of
row names can also be specified here. By default, row names are included if
rownames(t) is neither NULL nor identical to 1:nrow(x).</p>
</td></tr>
<tr><td><code id="md_table_+3A_col.names">col.names</code></td>
<td>
<p>a character vector of column names to be used in the table</p>
</td></tr>
<tr><td><code id="md_table_+3A_align">align</code></td>
<td>
<p>Column alignment: a character vector consisting of 'l'
(left), 'c' (center) and/or 'r' (right). By default or if
align = NULL, numeric columns are right-aligned, and other
columns are left-aligned.</p>
</td></tr>
</table>

<hr>
<h2 id='movies'>Data about movies</h2><span id='topic+movies'></span>

<h3>Description</h3>

<p>A dataset containing information about films, how popular they were, and
the extent to which they feature women.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>movies
</code></pre>


<h3>Format</h3>

<p>A data frame with 841 rows and 24 variables:
</p>

<dl>
<dt>title</dt><dd><p>The movie's title</p>
</dd>
<dt>year</dt><dd><p>The year of the movie's US theatrical release</p>
</dd>
<dt>release_date</dt><dd><p>The exact date of the movie's US theatrical release</p>
</dd>
<dt>runtime</dt><dd><p>The length of the movie in hours</p>
</dd>
<dt>genre5</dt><dd><p>The movie's primary genre per IMDB, fit into one of 5
broad categories</p>
</dd>
<dt>genre_detailed</dt><dd><p>The verbatim genre description per IMDB</p>
</dd>
<dt>rated</dt><dd><p>The movie's MPA rating (G, PG, PG-13, R, or NC-17) as an
ordered factor</p>
</dd>
<dt>director</dt><dd><p>The name of the movie's director(s)</p>
</dd>
<dt>writer</dt><dd><p>The name of the movie's screenwriter(s)</p>
</dd>
<dt>actors</dt><dd><p>A comma-separated string of leading actors in the film</p>
</dd>
<dt>language</dt><dd><p>The movie's language(s), per IMDB</p>
</dd>
<dt>country</dt><dd><p>The country(ies) in which the movie was produced</p>
</dd>
<dt>metascore</dt><dd><p>The movie's score on MetaCritic, ranging from 0 to 100</p>
</dd>
<dt>imdb_rating</dt><dd><p>The movie's rating on IMDB, ranging from 0 to 10</p>
</dd>
<dt>imdb_votes</dt><dd><p>The number of users who submitted a rating on IMDB</p>
</dd>
<dt>imdb_id</dt><dd><p>The unique identifier for the movie at IMDB</p>
</dd>
<dt>studio</dt><dd><p>The studio(s) who produced the movie</p>
</dd>
<dt>bechdel_binary</dt><dd><p>A logical indicating whether the movie passed the
Bechdel test</p>
</dd>
<dt>bechdel_ordinal</dt><dd><p>A more granular measure of the bechdel test,
indicating not just whether the movie passed or failed but how close it
got to passing if it did fail</p>
</dd>
<dt>us_gross</dt><dd><p>The movie's US gross in 2013 US dollars</p>
</dd>
<dt>int_gross</dt><dd><p>The movie's international gross in 2013 US dollars</p>
</dd>
<dt>budget</dt><dd><p>The movie's budget in 2013 US dollars</p>
</dd>
<dt>men_lines</dt><dd><p>The proportion of spoken lines that were spoken by male
characters</p>
</dd>
<dt>lines_data</dt><dd><p>The raw data used to calculate <code>men_lines</code>; see Source
for more information</p>
</dd>
</dl>



<h3>Source</h3>

<p>These data are aggregated from several sources. Metadata is gathered from
IMDB. Other information, particularly about the lines, is collected from
<a href="https://github.com/matthewfdaniels/scripts/">The Pudding</a>. The data
regarding the Bechdel Test, as well as about finances, comes from
FiveThirtyEight and its associated R package (<code>fivethirtyeight</code> and its
dataset, <code>bechdel</code>).
</p>

<hr>
<h2 id='num_print'>Numbering printing with signed zeroes and trailing zeroes</h2><span id='topic+num_print'></span>

<h3>Description</h3>

<p>This function will print exactly the amount of digits requested
as well as signed zeroes when appropriate (e.g, <code>-0.00</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>num_print(x, digits = getOption("jtools-digits", 2), format = "f")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="num_print_+3A_x">x</code></td>
<td>
<p>The number(s) to print</p>
</td></tr>
<tr><td><code id="num_print_+3A_digits">digits</code></td>
<td>
<p>Number of digits past the decimal to print</p>
</td></tr>
<tr><td><code id="num_print_+3A_format">format</code></td>
<td>
<p>equal to <code>"d"</code> (for integers),
<code>"f"</code>, <code>"e"</code>, <code>"E"</code>, <code>"g"</code>, <code>"G"</code>, <code>"fg"</code> (for reals). Default is <code>"f"</code></p>
</td></tr>
</table>

<hr>
<h2 id='partialize'>Adjust observed data for partial residuals plots</h2><span id='topic+partialize'></span><span id='topic+partialize.default'></span>

<h3>Description</h3>

<p>This function is designed to facilitate the creation of partial
residual plots, in which you can plot observed data alongside model
predictions. The difference is instead of the <em>actual</em> observed data, the
outcome variable is adjusted for the effects of the covariates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>partialize(model, ...)

## Default S3 method:
partialize(
  model,
  vars = NULL,
  data = NULL,
  at = NULL,
  center = TRUE,
  scale = c("response", "link"),
  set.offset = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="partialize_+3A_model">model</code></td>
<td>
<p>A regression model.</p>
</td></tr>
<tr><td><code id="partialize_+3A_...">...</code></td>
<td>
<p>Ignored.</p>
</td></tr>
<tr><td><code id="partialize_+3A_vars">vars</code></td>
<td>
<p>The variable(s) to <em>not</em> adjust for, as a string (or vector of
strings). If I want to show the effect of <code>x</code> adjusting for the effect of
<code>z</code>, then I would make <code>"x"</code> the <code>vars</code> argument.</p>
</td></tr>
<tr><td><code id="partialize_+3A_data">data</code></td>
<td>
<p>Optionally, provide the data used to fit the model (or some
other data frame with the same variables). Otherwise, it will be retrieved
from the model or the global environment.</p>
</td></tr>
<tr><td><code id="partialize_+3A_at">at</code></td>
<td>
<p>If you want to manually set the values of other variables in the
model, do so by providing a named list where the names are the variables
and the list values are vectors of the values. This can be useful
especially when you are exploring interactions or other conditional
predictions.</p>
</td></tr>
<tr><td><code id="partialize_+3A_center">center</code></td>
<td>
<p>Set numeric covariates to their mean? Default is TRUE. You
may also just provide a vector of names (as strings) of covariates to
center. Note that for <code>svyglm</code> models, the survey-weighted means are used.
For models with weights, these are weighted means.</p>
</td></tr>
<tr><td><code id="partialize_+3A_scale">scale</code></td>
<td>
<p>For GLMs, should the outcome variable be returned on the link
scale or response scale? Default is <code>"response"</code>.</p>
</td></tr>
<tr><td><code id="partialize_+3A_set.offset">set.offset</code></td>
<td>
<p>For models with an offset (e.g., Poisson models), sets an
offset for the predicted values. All predicted values will have the same
offset. By default, this is set to 1, which makes the predicted values a
proportion. See details for more about offset support.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The main use for working with partial residuals rather than the observed
values is to explore patterns in the model fit with respect to one or more
variables while &quot;controlling out&quot; the effects of others. Plotting a
predicted line along with observed data may make a very well-fitting model
look as if it is a poor fit if a lot of variation is accounted for by
variables other than the one on the x-axis.
</p>
<p>I advise consulting Fox and Weisberg (available free) for more details
on what partial residuals are. This function is designed to produce
data in a similar format to <code>effects::Effect()</code> when that function has
<code>residuals</code> set to <code>TRUE</code> and is plotted. I wanted a more modular function
to produce the data separately. To be clear, the developers of the <code>effects</code>
package have nothing to do with this function; 'partialize&ldquo; is merely
designed to replicate some of that functionality.
</p>


<h3>Value</h3>

<p><code>data</code> plus the residualized outcome variable.
</p>


<h3>References</h3>

<p>Fox, J., &amp; Weisberg, S. (2018). Visualizing fit and lack of fit in complex
regression models with predictor effect plots and partial residuals.
<em>Journal of Statistical Software</em>, <em>87</em>(9), 127.
https://doi.org/10.18637/jss.v087.i09
</p>

<hr>
<h2 id='pf_sv_test'>Test whether sampling weights are needed</h2><span id='topic+pf_sv_test'></span>

<h3>Description</h3>

<p>Use the test proposed in Pfeffermann and Sverchkov (1999) to check whether
a regression model is specified correctly without weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pf_sv_test(
  model,
  data = NULL,
  weights,
  sims = 1000,
  digits = getOption("jtools-digits", default = 3)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pf_sv_test_+3A_model">model</code></td>
<td>
<p>The fitted model, without weights</p>
</td></tr>
<tr><td><code id="pf_sv_test_+3A_data">data</code></td>
<td>
<p>The data frame with the data fed to the fitted model and the
weights</p>
</td></tr>
<tr><td><code id="pf_sv_test_+3A_weights">weights</code></td>
<td>
<p>The name of the weights column in <code>model</code>'s data frame
or a vector of weights equal in length to the number of observations
included in <code>model</code>.</p>
</td></tr>
<tr><td><code id="pf_sv_test_+3A_sims">sims</code></td>
<td>
<p>The number of bootstrap simulations to use in estimating the
variance of the residual correlation. Default is 1000, but for publications
or when computing power/time is sufficient, a higher number is better.</p>
</td></tr>
<tr><td><code id="pf_sv_test_+3A_digits">digits</code></td>
<td>
<p>An integer specifying the number of digits past the decimal to
report in the output. Default is 3. You can change the default number of
digits for all jtools functions with
<code>options("jtools-digits" = digits)</code> where digits is the desired number.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a test described by Pfeffermann and Sverchkov (1999) that is
designed to help analysts decide whether they need to use sample weights
in their regressions to avoid biased parameter estimation.
</p>
<p>It first checks the correlation of the residuals of the model with the
weights. It then uses bootstrapping to estimate the variance of the
correlation, ending with a t-test of whether the correlation differs from
zero. This is done for the squared residuals and cubed residuals as well.
If anyone of them are statistically significant (at whatever level you
feel appropriate), it is best to do a weighted regression. Note that in
large samples, a very small correlation may have a low p-value without a
large bias in the unweighted regression.
</p>


<h3>References</h3>

<p>Pfeffermann, D., &amp; Sverchkov, M. (1999). Parametric and semi-parametric
estimation of regression models fitted to survey data.
<em>Sankhya: The Indian Journal of Statistics</em>, <em>61</em>. 166-186.
</p>


<h3>See Also</h3>

<p>Other survey tools: 
<code><a href="#topic+svycor">svycor</a>()</code>,
<code><a href="#topic+svysd">svysd</a>()</code>,
<code><a href="#topic+weights_tests">weights_tests</a>()</code>,
<code><a href="#topic+wgttest">wgttest</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Note: This is a contrived example to show how the function works,
# not a case with actual sammpling weights from a survey vendor
if (requireNamespace("boot")) {
  states &lt;- as.data.frame(state.x77)
  set.seed(100)
  states$wts &lt;- runif(50, 0, 3)
  fit &lt;- lm(Murder ~ Illiteracy + Frost, data = states)
  pf_sv_test(model = fit, data = states, weights = wts, sims = 100)
}

</code></pre>

<hr>
<h2 id='plot_summs'>Plot Regression Summaries</h2><span id='topic+plot_summs'></span><span id='topic+plot_coefs'></span>

<h3>Description</h3>

<p><code>plot_summs</code> and <code>plot_coefs</code> create regression coefficient
plots with ggplot2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_summs(
  ...,
  ci_level = 0.95,
  model.names = NULL,
  coefs = NULL,
  omit.coefs = "(Intercept)",
  inner_ci_level = NULL,
  colors = "CUD Bright",
  plot.distributions = FALSE,
  rescale.distributions = FALSE,
  exp = FALSE,
  point.shape = TRUE,
  point.size = 5,
  line.size = c(0.8, 2),
  legend.title = "Model",
  groups = NULL,
  facet.rows = NULL,
  facet.cols = NULL,
  facet.label.pos = "top",
  color.class = colors,
  resp = NULL,
  dpar = NULL
)

plot_coefs(
  ...,
  ci_level = 0.95,
  inner_ci_level = NULL,
  model.names = NULL,
  coefs = NULL,
  omit.coefs = c("(Intercept)", "Intercept"),
  colors = "CUD Bright",
  plot.distributions = FALSE,
  rescale.distributions = FALSE,
  exp = FALSE,
  point.shape = TRUE,
  point.size = 5,
  line.size = c(0.8, 2),
  legend.title = "Model",
  groups = NULL,
  facet.rows = NULL,
  facet.cols = NULL,
  facet.label.pos = "top",
  color.class = colors,
  resp = NULL,
  dpar = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_summs_+3A_...">...</code></td>
<td>
<p>regression model(s). You may also include arguments to be passed
to <code>tidy()</code>.</p>
</td></tr>
<tr><td><code id="plot_summs_+3A_ci_level">ci_level</code></td>
<td>
<p>The desired width of confidence intervals for the
coefficients. Default: 0.95</p>
</td></tr>
<tr><td><code id="plot_summs_+3A_model.names">model.names</code></td>
<td>
<p>If plotting multiple models simultaneously, you can
provide a vector of names here. If NULL, they will be named sequentially
as &quot;Model 1&quot;, &quot;Model 2&quot;, and so on. Default: NULL</p>
</td></tr>
<tr><td><code id="plot_summs_+3A_coefs">coefs</code></td>
<td>
<p>If you'd like to include only certain coefficients, provide
them as a vector. If it is a named vector, then the names will be used
in place of the variable names. See details for examples. Default: NULL</p>
</td></tr>
<tr><td><code id="plot_summs_+3A_omit.coefs">omit.coefs</code></td>
<td>
<p>If you'd like to specify some coefficients to not include
in the plot, provide them as a vector. This argument is overridden by
<code>coefs</code> if both are provided. By default, the intercept term is omitted.
To include the intercept term, just set omit.coefs to NULL.</p>
</td></tr>
<tr><td><code id="plot_summs_+3A_inner_ci_level">inner_ci_level</code></td>
<td>
<p>Plot a thicker line representing some narrower span
than <code>ci_level</code>. Default is NULL, but good options are .9, .8, or .5.</p>
</td></tr>
<tr><td><code id="plot_summs_+3A_colors">colors</code></td>
<td>
<p>See <a href="#topic+jtools_colors">jtools_colors</a> for more on your color options.
Default: 'CUD Bright'</p>
</td></tr>
<tr><td><code id="plot_summs_+3A_plot.distributions">plot.distributions</code></td>
<td>
<p>Instead of just plotting the ranges, you may
plot normal distributions representing the width of each estimate. Note
that these are completely theoretical and not based on a bootstrapping
or MCMC procedure, even if the source model was fit that way. Default is
FALSE.</p>
</td></tr>
<tr><td><code id="plot_summs_+3A_rescale.distributions">rescale.distributions</code></td>
<td>
<p>If <code>plot.distributions</code> is TRUE, the default
behavior is to plot each normal density curve on the same scale. If some
of the uncertainty intervals are much wider/narrower than others, that
means the wide ones will have such a low height that you won't be able
to see the curve. If you set this parameter to TRUE, each curve will
have the same maximum height regardless of their width.</p>
</td></tr>
<tr><td><code id="plot_summs_+3A_exp">exp</code></td>
<td>
<p>If TRUE, all coefficients are exponentiated (e.g., transforms
logit coefficents from log odds scale to odds). The reference line is
also moved to 1 instead of 0.</p>
</td></tr>
<tr><td><code id="plot_summs_+3A_point.shape">point.shape</code></td>
<td>
<p>When using multiple models, should each model's point
estimates use a different point shape to visually differentiate each
model from the others? Default is TRUE. You may also pass a vector of
shapes to specify shapes yourself.</p>
</td></tr>
<tr><td><code id="plot_summs_+3A_point.size">point.size</code></td>
<td>
<p>Change the size of the points. Default is 3.</p>
</td></tr>
<tr><td><code id="plot_summs_+3A_line.size">line.size</code></td>
<td>
<p>Change the thickness of the error bar lines.
Default is <code>c(0.8, 2)</code>. The first number is the size for the full
width of the interval, the second number is used for the thicker
inner interval when <code>inner.ci</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot_summs_+3A_legend.title">legend.title</code></td>
<td>
<p>What should the title for the legend be? Default is
&quot;Model&quot;, but you can specify it here since it is rather difficult to
change later via <code>ggplot2</code>'s typical methods.</p>
</td></tr>
<tr><td><code id="plot_summs_+3A_groups">groups</code></td>
<td>
<p>If you would like to have facets (i.e., separate panes) for
different groups of coefficients, you can specify those groups with a
list here. See details for more on how to do this.</p>
</td></tr>
<tr><td><code id="plot_summs_+3A_facet.rows">facet.rows</code></td>
<td>
<p>The number of rows in the facet grid (the <code>nrow</code> argument
to <code><a href="ggplot2.html#topic+facet_wrap">ggplot2::facet_wrap()</a></code>).</p>
</td></tr>
<tr><td><code id="plot_summs_+3A_facet.cols">facet.cols</code></td>
<td>
<p>The number of columns in the facet grid (the <code>nrow</code>
argument to <code><a href="ggplot2.html#topic+facet_wrap">ggplot2::facet_wrap()</a></code>).</p>
</td></tr>
<tr><td><code id="plot_summs_+3A_facet.label.pos">facet.label.pos</code></td>
<td>
<p>Where to put the facet labels. One of &quot;top&quot; (the
default), &quot;bottom&quot;, &quot;left&quot;, or &quot;right&quot;.</p>
</td></tr>
<tr><td><code id="plot_summs_+3A_color.class">color.class</code></td>
<td>
<p>Deprecated. Now known as <code>colors</code>.</p>
</td></tr>
<tr><td><code id="plot_summs_+3A_resp">resp</code></td>
<td>
<p>For any models that are <code>brmsfit</code> and have multiple response
variables, specify them with a vector here. If the model list includes
other types of models, you do not need to enter <code>resp</code> for those models.
For instance, if I want to plot a <code>lm</code> object and two <code>brmsfit</code> objects,
you only need to provide a vector of length 2 for <code>resp</code>.</p>
</td></tr>
<tr><td><code id="plot_summs_+3A_dpar">dpar</code></td>
<td>
<p>For any models that are <code>brmsfit</code> and have a distributional
dependent variable, that can be specified here. If NULL, it is assumed you
want coefficients for the location/mean parameter, not the distributional
parameter(s).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A note on the distinction between <code>plot_summs</code> and <code>plot_coefs</code>:
<code>plot_summs</code> only accepts models supported by <code><a href="#topic+summ">summ()</a></code> and allows users
to take advantage of the standardization and robust standard error features
(among others as may be relevant). <code>plot_coefs</code> supports any models that
have a <code><a href="broom.html#topic+reexports">broom::tidy()</a></code> method defined in the broom package, but of course
lacks any additional features like robust standard errors. To get a mix
of the two, you can pass <code>summ</code> objects to <code>plot_coefs</code> too.
</p>
<p>For <code>coefs</code>, if you provide a named vector of coefficients, then
the plot will refer to the selected coefficients by the names of the
vector rather than the coefficient names. For instance, if I want to
include only the coefficients for the <code>hp</code> and <code>mpg</code> but have
the plot refer to them as &quot;Horsepower&quot; and &quot;Miles/gallon&quot;, I'd provide
the argument like this:
<code>c("Horsepower" = "hp", "Miles/gallon" = "mpg")</code>
</p>
<p>To use the <code>groups</code> argument, provide a (preferably named) list of
character vectors. If I want separate panes with &quot;Frost&quot; and &quot;Illiteracy&quot;
in one and &quot;Population&quot; and &quot;Area&quot; in the other, I'd make a list like
this:
</p>
<p><code>list(pane_1 = c("Frost", "Illiteracy"), pane_2 = c("Population", "Area"))</code>
</p>


<h3>Value</h3>

<p>A ggplot object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>states &lt;- as.data.frame(state.x77)
fit1 &lt;- lm(Income ~ Frost + Illiteracy + Murder +
           Population + Area + `Life Exp` + `HS Grad`,
           data = states, weights = runif(50, 0.1, 3))
fit2 &lt;- lm(Income ~ Frost + Illiteracy + Murder +
           Population + Area + `Life Exp` + `HS Grad`,
           data = states, weights = runif(50, 0.1, 3))
fit3 &lt;- lm(Income ~ Frost + Illiteracy + Murder +
           Population + Area + `Life Exp` + `HS Grad`,
           data = states, weights = runif(50, 0.1, 3))

# Plot all 3 regressions with custom predictor labels,
# standardized coefficients, and robust standard errors
plot_summs(fit1, fit2, fit3,
           coefs = c("Frost Days" = "Frost", "% Illiterate" = "Illiteracy",
                     "Murder Rate" = "Murder"),
           scale = TRUE, robust = TRUE)

</code></pre>

<hr>
<h2 id='predict_merMod'>Alternative interface for <code>merMod</code> predictions</h2><span id='topic+predict_merMod'></span>

<h3>Description</h3>

<p>This function generates predictions for <code>merMod</code> models, but
with the ability to get standard errors as well.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_merMod(
  object,
  newdata = NULL,
  se.fit = FALSE,
  use.re.var = FALSE,
  allow.new.levels = FALSE,
  type = c("link", "response", "terms"),
  na.action = na.pass,
  re.form = NULL,
  boot = FALSE,
  sims = 100,
  prog.arg = "none",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_merMod_+3A_object">object</code></td>
<td>
<p>a fitted model object</p>
</td></tr>
<tr><td><code id="predict_merMod_+3A_newdata">newdata</code></td>
<td>
<p>data frame for which to evaluate
predictions.</p>
</td></tr>
<tr><td><code id="predict_merMod_+3A_se.fit">se.fit</code></td>
<td>
<p>Include standard errors with the predictions? Note that
these standard errors by default include only fixed effects variance.
See details for more info. Default is FALSE.</p>
</td></tr>
<tr><td><code id="predict_merMod_+3A_use.re.var">use.re.var</code></td>
<td>
<p>If <code>se.fit</code> is TRUE, include random effects variance in
standard errors? Default is FALSE.</p>
</td></tr>
<tr><td><code id="predict_merMod_+3A_allow.new.levels">allow.new.levels</code></td>
<td>
<p>logical if new levels (or NA values) in
<code>newdata</code> are allowed. If FALSE (default), such new values in
<code>newdata</code> will trigger an error; if TRUE, then the prediction
will use the unconditional (population-level) values for data with
previously unobserved levels (or NAs).</p>
</td></tr>
<tr><td><code id="predict_merMod_+3A_type">type</code></td>
<td>
<p>character string - either <code>"link"</code>, the default, or
<code>"response"</code> indicating the type of prediction object returned.</p>
</td></tr>
<tr><td><code id="predict_merMod_+3A_na.action">na.action</code></td>
<td>
<p><code><a href="base.html#topic+function">function</a></code> determining what should be done
with missing values for fixed effects in <code>newdata</code>.
The default is to predict <code>NA</code>: see <code><a href="stats.html#topic+na.pass">na.pass</a></code>.</p>
</td></tr>
<tr><td><code id="predict_merMod_+3A_re.form">re.form</code></td>
<td>
<p>(formula, <code>NULL</code>, or <code>NA</code>) specify which random effects to condition on when predicting.  If <code>NULL</code>,
include all random effects; if <code>NA</code> or <code>~0</code>,
include no random effects.</p>
</td></tr>
<tr><td><code id="predict_merMod_+3A_boot">boot</code></td>
<td>
<p>Use bootstrapping (via <code><a href="lme4.html#topic+bootMer">lme4::bootMer()</a></code>) to estimate
variance for <code>se.fit</code>? Default is FALSE</p>
</td></tr>
<tr><td><code id="predict_merMod_+3A_sims">sims</code></td>
<td>
<p>If <code>boot</code> is TRUE, how many simulations should be run? Default
is 100.</p>
</td></tr>
<tr><td><code id="predict_merMod_+3A_prog.arg">prog.arg</code></td>
<td>
<p>If <code>boot</code> and <code>se.fit</code> are TRUE, a character string -
type of progress bar to display. Default is &quot;none&quot;; the function will look
for a relevant *ProgressBar function, so &quot;txt&quot; will work in general;
&quot;tk&quot; is available if the tcltk package is loaded; or &quot;win&quot; on Windows
systems. Progress bars are disabled (with a message) for parallel operation.</p>
</td></tr>
<tr><td><code id="predict_merMod_+3A_...">...</code></td>
<td>
<p>When <code>boot</code> and <code>se.fit</code> are TRUE, any additional arguments are
passed to <code>lme4::bootMer()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The developers of <span class="pkg">lme4</span> omit an <code>se.fit</code> argument for a
reason, which is that it's not perfectly clear how best to estimate
the variance for these models. This solution is a logical one, but perhaps
not perfect. Bayesian models are one way to do better.
</p>
<p>The method used here is based on the one described here:
<a href="http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#predictions-andor-confidence-or-prediction-intervals-on-predictions">http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#predictions-andor-confidence-or-prediction-intervals-on-predictions</a>
</p>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+tidy'></span><span id='topic+glance'></span><span id='topic+as_tibble'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>generics</dt><dd><p><code><a href="generics.html#topic+glance">glance</a></code>, <code><a href="generics.html#topic+tidy">tidy</a></code></p>
</dd>
<dt>tibble</dt><dd><p><code><a href="tibble.html#topic+as_tibble">as_tibble</a></code></p>
</dd>
</dl>

<hr>
<h2 id='scale_mod'>Scale variables in fitted regression models</h2><span id='topic+scale_mod'></span><span id='topic+scale_mod.default'></span><span id='topic+scale_lm'></span>

<h3>Description</h3>

<p><code>scale_mod</code> (previously known as <code>scale_lm</code>) takes fitted regression models
and scales all
predictors by dividing each by 1 or 2 standard deviations (as chosen by the
user).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scale_mod(model, ...)

## Default S3 method:
scale_mod(
  model,
  binary.inputs = "0/1",
  n.sd = 1,
  center = TRUE,
  scale.response = FALSE,
  center.only = FALSE,
  scale.only = FALSE,
  data = NULL,
  vars = NULL,
  apply.weighted.contrasts = getOption("jtools-weighted.contrasts", FALSE),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scale_mod_+3A_model">model</code></td>
<td>
<p>A regression model of type <code>lm</code>, <code>glm</code>,
<code><a href="survey.html#topic+svyglm">svyglm</a></code>, or <a href="lme4.html#topic+merMod-class">lme4::merMod</a>. Other model types
may work as well but are not tested.</p>
</td></tr>
<tr><td><code id="scale_mod_+3A_...">...</code></td>
<td>
<p>Arguments passed on to <code><a href="#topic+gscale">gscale()</a></code>.</p>
</td></tr>
<tr><td><code id="scale_mod_+3A_binary.inputs">binary.inputs</code></td>
<td>
<p>Options for binary variables. Default is <code>"0/1"</code>;
<code>"0/1"</code> keeps original scale; <code>"-0.5,0.5"</code> rescales 0 as -0.5
and
1 as 0.5; <code>center</code> subtracts the mean; and <code>full</code> treats them
like other continuous variables.</p>
</td></tr>
<tr><td><code id="scale_mod_+3A_n.sd">n.sd</code></td>
<td>
<p>How many standard deviations should you divide by for
standardization? Default is 1, though some prefer 2.</p>
</td></tr>
<tr><td><code id="scale_mod_+3A_center">center</code></td>
<td>
<p>Default is <code>TRUE</code>. If <code>TRUE</code>, the predictors are
also
mean-centered. For binary predictors, the <code>binary.inputs</code> argument
supersedes this one.</p>
</td></tr>
<tr><td><code id="scale_mod_+3A_scale.response">scale.response</code></td>
<td>
<p>Should the response variable also be rescaled? Default
is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="scale_mod_+3A_center.only">center.only</code></td>
<td>
<p>Rather than actually scale predictors, just mean-center
them.</p>
</td></tr>
<tr><td><code id="scale_mod_+3A_scale.only">scale.only</code></td>
<td>
<p>A logical value indicating whether you would like to scale
the values, but not mean-center them.</p>
</td></tr>
<tr><td><code id="scale_mod_+3A_data">data</code></td>
<td>
<p>If you provide the data used to fit the model here, that data
frame is used to re-fit the model instead of the <code><a href="stats.html#topic+model.frame">stats::model.frame()</a></code>
of the model. This is particularly useful if you have variable
transformations or polynomial terms specified in the formula.</p>
</td></tr>
<tr><td><code id="scale_mod_+3A_vars">vars</code></td>
<td>
<p>A character vector of variable names that you want to be
scaled. If NULL, the default, it is all predictors.</p>
</td></tr>
<tr><td><code id="scale_mod_+3A_apply.weighted.contrasts">apply.weighted.contrasts</code></td>
<td>
<p>Factor variables cannot be scaled, but you
can set the contrasts such that the intercept in a regression model will
reflect the true mean (assuming all other variables are centered). If set
to TRUE, the argument will apply weighted effects coding to all factors.
This is similar to the R default effects coding, but weights according to
how many observations are at each level. An adapted version of
<code>contr.wec()</code> from the <code>wec</code> package is used to do this. See
that package's documentation and/or Grotenhuis et al. (2016) for more
info.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will scale all continuous variables in a regression
model for ease of interpretation, especially for those models that have
interaction terms. It can also mean-center all of them as well, if
requested.
</p>
<p>The scaling happens on the input data, not the terms themselves. That
means interaction terms are still properly calculated because they are
the product of standardized predictors, not a standardized product of
predictors.
</p>
<p>This function re-estimates the model, so for large models one should
expect a runtime equal to the first run.
</p>


<h3>Value</h3>

<p>The functions returns a re-fitted model object, inheriting
from whichever class was supplied.
</p>


<h3>Author(s)</h3>

<p>Jacob Long <a href="mailto:jacob.long@sc.edu">jacob.long@sc.edu</a>
</p>


<h3>References</h3>

<p>Bauer, D. J., &amp; Curran, P. J. (2005). Probing interactions in fixed and
multilevel regression: Inferential and graphical techniques.
<em>Multivariate Behavioral Research</em>, <em>40</em>(3), 373-400.
</p>
<p>Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). <em>Applied
multiple regression/correlation analyses for the behavioral sciences</em> (3rd
ed.). Mahwah, NJ: Lawrence Erlbaum Associates, Inc.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sim_slopes">sim_slopes</a></code> performs a simple slopes analysis.
</p>
<p><code><a href="#topic+interact_plot">interact_plot</a></code> creates attractive, user-configurable plots of
interaction models.
</p>
<p>Other standardization: 
<code><a href="#topic+center_mod">center_mod</a>()</code>,
<code><a href="#topic+center">center</a>()</code>,
<code><a href="#topic+gscale">gscale</a>()</code>,
<code><a href="#topic+standardize">standardize</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
fit &lt;- lm(formula = Murder ~ Income * Illiteracy,
          data = as.data.frame(state.x77))
fit_scale &lt;- scale_mod(fit)
fit_scale &lt;- scale_mod(fit, center = TRUE)

# With weights
fitw &lt;- lm(formula = Murder ~ Income * Illiteracy,
           data = as.data.frame(state.x77),
           weights = Population)
fitw_scale &lt;- scale_mod(fitw)
fitw_scale &lt;- scale_mod(fitw, center = TRUE, binary.input = "0/1")

# With svyglm
if (requireNamespace("survey")) {
library(survey)
data(api)
dstrat&lt;-svydesign(id=~1,strata=~stype, weights=~pw, data=apistrat, fpc=~fpc)
regmodel &lt;- svyglm(api00~ell*meals,design=dstrat)
regmodel_scale &lt;- scale_mod(regmodel)
regmodel_scale &lt;- scale_mod(regmodel, binary.input = "0/1")
}

</code></pre>

<hr>
<h2 id='set_summ_defaults'>Set defaults for <code>summ()</code> functions</h2><span id='topic+set_summ_defaults'></span>

<h3>Description</h3>

<p>This function is convenience wrapper for manually setting
options using <code><a href="base.html#topic+options">options()</a></code>. This gives a handy way to, for instance,
set the arguments to be used in every call to <code><a href="#topic+summ">summ()</a></code> in your
script/session.
</p>
<p>To make the settings persist across sessions, you can run this in your
<code>.Rprofile</code> file.
</p>
<p>Note that arguments that do not apply (e.g., <code>robust</code> for <code>merMod</code> models)
are silently ignored when those types of models are used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_summ_defaults(
  digits = NULL,
  model.info = NULL,
  model.fit = NULL,
  model.coefs = NULL,
  pvals = NULL,
  robust = NULL,
  confint = NULL,
  ci.width = NULL,
  vifs = NULL,
  conf.method = NULL,
  table.format = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set_summ_defaults_+3A_digits">digits</code></td>
<td>
<p>An integer specifying the number of digits past the decimal to
report in the output. Default is 2. You can change the default number of
digits for all jtools functions with
<code>options("jtools-digits" = digits)</code> where digits is the desired
number.</p>
</td></tr>
<tr><td><code id="set_summ_defaults_+3A_model.info">model.info</code></td>
<td>
<p>Toggles printing of basic information on sample size,
name of DV, and number of predictors.</p>
</td></tr>
<tr><td><code id="set_summ_defaults_+3A_model.fit">model.fit</code></td>
<td>
<p>Toggles printing of model fit statistics.</p>
</td></tr>
<tr><td><code id="set_summ_defaults_+3A_model.coefs">model.coefs</code></td>
<td>
<p>Toggles printing of model coefficents.</p>
</td></tr>
<tr><td><code id="set_summ_defaults_+3A_pvals">pvals</code></td>
<td>
<p>Show p values? If <code>FALSE</code>, these
are not printed. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="set_summ_defaults_+3A_robust">robust</code></td>
<td>
<p>If not <code>FALSE</code>, reports heteroskedasticity-robust standard
errors instead of conventional SEs. These are also known as Huber-White
standard errors. There are several options provided by
<code><a href="sandwich.html#topic+vcovHC">sandwich::vcovHC()</a></code>: <code>"HC0"</code>, <code>"HC1"</code>, <code>"HC2"</code>, <code>"HC3"</code>, <code>"HC4"</code>,
<code>"HC4m"</code>, <code>"HC5"</code>.
</p>
<p>Default is <code>FALSE</code>.
</p>
<p>This requires the <code>sandwich</code> package to compute the
standard errors.</p>
</td></tr>
<tr><td><code id="set_summ_defaults_+3A_confint">confint</code></td>
<td>
<p>Show confidence intervals instead of standard errors? Default
is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="set_summ_defaults_+3A_ci.width">ci.width</code></td>
<td>
<p>A number between 0 and 1 that signifies the width of the
desired confidence interval. Default is <code>.95</code>, which corresponds
to a 95% confidence interval. Ignored if <code>confint = FALSE</code>.</p>
</td></tr>
<tr><td><code id="set_summ_defaults_+3A_vifs">vifs</code></td>
<td>
<p>If <code>TRUE</code>, adds a column to output with variance inflation
factors (VIF). Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="set_summ_defaults_+3A_conf.method">conf.method</code></td>
<td>
<p>Argument passed to <code><a href="lme4.html#topic+confint.merMod">lme4::confint.merMod()</a></code>. Default
is <code>"Wald"</code>, but <code>"profile"</code> or <code>"boot"</code> are better when accuracy is a
priority. Be aware that both of the alternate methods are sometimes very
time-consuming.</p>
</td></tr>
<tr><td><code id="set_summ_defaults_+3A_table.format">table.format</code></td>
<td>
<p>A format understood by <code><a href="#topic+md_table">md_table()</a></code></p>
</td></tr>
</table>

<hr>
<h2 id='standardize'>Standardize vectors, data frames, and survey designs</h2><span id='topic+standardize'></span>

<h3>Description</h3>

<p>This function is a wrapper around <code><a href="#topic+gscale">gscale()</a></code> that is configured
to do a conventional standardization of continuous variables,
mean-centering and dividing by one standard deviation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standardize(
  data = NULL,
  vars = NULL,
  binary.inputs = "center",
  binary.factors = FALSE,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="standardize_+3A_data">data</code></td>
<td>
<p>A data frame or survey design. Only needed if you would like to
rescale multiple variables at once. If <code>x = NULL</code>, all columns will
be rescaled. Otherwise, <code>x</code> should be a vector of variable names. If
<code>x</code> is a numeric vector, this argument is ignored.</p>
</td></tr>
<tr><td><code id="standardize_+3A_vars">vars</code></td>
<td>
<p>If <code>data</code> is a data.frame or similar, you can scale only
select columns by providing a vector column names to this argument.</p>
</td></tr>
<tr><td><code id="standardize_+3A_binary.inputs">binary.inputs</code></td>
<td>
<p>Options for binary variables. Default is <code>center</code>;
<code>0/1</code> keeps original scale; <code>-0.5/0.5</code> rescales 0 as -0.5 and 1
as 0.5; <code>center</code> subtracts the mean; and <code>full</code> subtracts the
mean and divides by 2 sd.</p>
</td></tr>
<tr><td><code id="standardize_+3A_binary.factors">binary.factors</code></td>
<td>
<p>Coerce two-level factors to numeric and apply scaling
functions to them? Default is FALSE.</p>
</td></tr>
<tr><td><code id="standardize_+3A_weights">weights</code></td>
<td>
<p>A vector of weights equal in length to <code>x</code>. If iterating
over a data frame, the weights will need to be equal in length to all the
columns to avoid errors. You may need to remove missing values before using
the weights.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Some more information can be found in the documentation for
<code><a href="#topic+gscale">gscale()</a></code>
</p>


<h3>Value</h3>

<p>A transformed version of the <code>data</code> argument.
</p>


<h3>See Also</h3>

<p>Other standardization: 
<code><a href="#topic+center_mod">center_mod</a>()</code>,
<code><a href="#topic+center">center</a>()</code>,
<code><a href="#topic+gscale">gscale</a>()</code>,
<code><a href="#topic+scale_mod">scale_mod</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Standardize just the "qsec" variable in mtcars
standardize(mtcars, vars = "qsec")

</code></pre>

<hr>
<h2 id='summ'>Regression summaries with options</h2><span id='topic+summ'></span><span id='topic+j_summ'></span>

<h3>Description</h3>

<p>To get specific documentation, choose the appropriate link to the
type of model that you want to summarize from the details section.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summ(model, ...)

j_summ(model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summ_+3A_model">model</code></td>
<td>
<p>A <code>lm</code>, <code>glm</code>, <code><a href="survey.html#topic+svyglm">svyglm</a></code>,
<code><a href="lme4.html#topic+merMod-class">merMod</a></code>, <code><a href="quantreg.html#topic+rq">rq</a></code> object.</p>
</td></tr>
<tr><td><code id="summ_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to the model-specific function.</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li> <p><code><a href="#topic+summ.lm">summ.lm</a></code>
</p>
</li>
<li> <p><code><a href="#topic+summ.glm">summ.glm</a></code>
</p>
</li>
<li> <p><code><a href="#topic+summ.svyglm">summ.svyglm</a></code>
</p>
</li>
<li> <p><code><a href="#topic+summ.merMod">summ.merMod</a></code>
</p>
</li>
<li> <p><code><a href="#topic+summ.rq">summ.rq</a></code>
</p>
</li></ul>


<hr>
<h2 id='summ.glm'>Generalized linear regression summaries with options</h2><span id='topic+summ.glm'></span><span id='topic+j_summ.glm'></span>

<h3>Description</h3>

<p><code>summ()</code> prints output for a regression model in a fashion similar to
<code>summary()</code>, but formatted differently with more options.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glm'
summ(
  model,
  scale = FALSE,
  confint = getOption("summ-confint", FALSE),
  ci.width = getOption("summ-ci.width", 0.95),
  robust = getOption("summ-robust", FALSE),
  cluster = NULL,
  vifs = getOption("summ-vifs", FALSE),
  digits = getOption("jtools-digits", default = 2),
  exp = FALSE,
  pvals = getOption("summ-pvals", TRUE),
  n.sd = 1,
  center = FALSE,
  transform.response = FALSE,
  scale.only = FALSE,
  data = NULL,
  model.info = getOption("summ-model.info", TRUE),
  model.fit = getOption("summ-model.fit", TRUE),
  model.coefs = getOption("summ-model.coefs", TRUE),
  which.cols = NULL,
  vcov = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summ.glm_+3A_model">model</code></td>
<td>
<p>A <code>glm</code> object.</p>
</td></tr>
<tr><td><code id="summ.glm_+3A_scale">scale</code></td>
<td>
<p>If <code>TRUE</code>, reports standardized regression
coefficients by scaling and mean-centering input data (the latter can be
changed via the <code>scale.only</code> argument). Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.glm_+3A_confint">confint</code></td>
<td>
<p>Show confidence intervals instead of standard errors? Default
is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.glm_+3A_ci.width">ci.width</code></td>
<td>
<p>A number between 0 and 1 that signifies the width of the
desired confidence interval. Default is <code>.95</code>, which corresponds
to a 95% confidence interval. Ignored if <code>confint = FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.glm_+3A_robust">robust</code></td>
<td>
<p>If not <code>FALSE</code>, reports heteroskedasticity-robust standard
errors instead of conventional SEs. These are also known as Huber-White
standard errors. There are several options provided by
<code><a href="sandwich.html#topic+vcovHC">sandwich::vcovHC()</a></code>: <code>"HC0"</code>, <code>"HC1"</code>, <code>"HC2"</code>, <code>"HC3"</code>, <code>"HC4"</code>,
<code>"HC4m"</code>, <code>"HC5"</code>.
</p>
<p>Default is <code>FALSE</code>.
</p>
<p>This requires the <code>sandwich</code> package to compute the
standard errors.</p>
</td></tr>
<tr><td><code id="summ.glm_+3A_cluster">cluster</code></td>
<td>
<p>For clustered standard errors, provide the column name of
the cluster variable in the input data frame (as a string). Alternately,
provide a vector of clusters. Note that you must set <code>robust</code> to either
&quot;HC1&quot;, &quot;HC2&quot;, or &quot;HC3&quot; in order to have clustered standard errors (&quot;HC4&quot;
and &quot;HC5&quot; are not supported.</p>
</td></tr>
<tr><td><code id="summ.glm_+3A_vifs">vifs</code></td>
<td>
<p>If <code>TRUE</code>, adds a column to output with variance inflation
factors (VIF). Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.glm_+3A_digits">digits</code></td>
<td>
<p>An integer specifying the number of digits past the decimal to
report in the output. Default is 2. You can change the default number of
digits for all jtools functions with
<code>options("jtools-digits" = digits)</code> where digits is the desired
number.</p>
</td></tr>
<tr><td><code id="summ.glm_+3A_exp">exp</code></td>
<td>
<p>If <code>TRUE</code>, reports exponentiated coefficients with
confidence intervals for exponential models like logit and Poisson models.
This quantity is known as an odds ratio for binary outcomes and incidence
rate ratio for count models.</p>
</td></tr>
<tr><td><code id="summ.glm_+3A_pvals">pvals</code></td>
<td>
<p>Show p values? If <code>FALSE</code>, these
are not printed. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="summ.glm_+3A_n.sd">n.sd</code></td>
<td>
<p>If <code>scale = TRUE</code>, how many standard deviations should
predictors be divided by? Default is 1, though some suggest 2.</p>
</td></tr>
<tr><td><code id="summ.glm_+3A_center">center</code></td>
<td>
<p>If you want coefficients for mean-centered variables but don't
want to standardize, set this to <code>TRUE</code>. Note that setting this to
false does not affect whether <code>scale</code> mean-centers variables. Use
<code>scale.only</code> for that.</p>
</td></tr>
<tr><td><code id="summ.glm_+3A_transform.response">transform.response</code></td>
<td>
<p>Should scaling/centering apply to response
variable? Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.glm_+3A_scale.only">scale.only</code></td>
<td>
<p>If you want to scale but not center, set this to <code>TRUE</code>.
Note that for legacy reasons, setting <code>scale = TRUE</code> and <code>center = FALSE</code>
will not achieve the same effect. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.glm_+3A_data">data</code></td>
<td>
<p>If you provide the data used to fit the model here, that data
frame is used to re-fit the model (if <code>scale</code> is <code>TRUE</code>)
instead of the <code><a href="stats.html#topic+model.frame">stats::model.frame()</a></code>
of the model. This is particularly useful if you have variable
transformations or polynomial terms specified in the formula.</p>
</td></tr>
<tr><td><code id="summ.glm_+3A_model.info">model.info</code></td>
<td>
<p>Toggles printing of basic information on sample size,
name of DV, and number of predictors.</p>
</td></tr>
<tr><td><code id="summ.glm_+3A_model.fit">model.fit</code></td>
<td>
<p>Toggles printing of model fit statistics.</p>
</td></tr>
<tr><td><code id="summ.glm_+3A_model.coefs">model.coefs</code></td>
<td>
<p>Toggles printing of model coefficents.</p>
</td></tr>
<tr><td><code id="summ.glm_+3A_which.cols">which.cols</code></td>
<td>
<p>Developmental feature. By providing columns by name,
you can add/remove/reorder requested columns in the output. Not fully
supported, for now.</p>
</td></tr>
<tr><td><code id="summ.glm_+3A_vcov">vcov</code></td>
<td>
<p>You may provide your own variance-covariance matrix for the
regression coefficients if you want to calculate standard errors in
some way not accommodated by the <code>robust</code> and <code>cluster</code> options.</p>
</td></tr>
<tr><td><code id="summ.glm_+3A_...">...</code></td>
<td>
<p>Among other things, arguments are passed to <code><a href="#topic+scale_mod">scale_mod()</a></code> or
<code><a href="#topic+center_mod">center_mod()</a></code> when <code>center</code> or <code>scale</code> is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, this function will print the following items to the
console:
</p>

<ul>
<li><p> The sample size
</p>
</li>
<li><p> The name of the outcome variable
</p>
</li>
<li><p> The chi-squared test, (Pseudo-)R-squared value and AIC/BIC.
</p>
</li>
<li><p> A table with regression coefficients, standard errors, z values, and
p values.
</p>
</li></ul>

<p>There are several options available for <code>robust</code>. The heavy
lifting is done by <code><a href="sandwich.html#topic+vcovHC">sandwich::vcovHC()</a></code>, where those are better
described.
Put simply, you may choose from <code>"HC0"</code> to <code>"HC5"</code>. Based on the
recommendation of the developers of <span class="pkg">sandwich</span>, the default is set to
<code>"HC3"</code>. Stata's default is <code>"HC1"</code>, so that choice may be better
if the goal is to replicate Stata's output. Any option that is understood by
<code>vcovHC()</code> will be accepted. Cluster-robust standard errors are
computed
if <code>cluster</code> is set to the name of the input data's cluster variable
or is a vector of clusters.
</p>
<p>The <code>scale</code> and <code>center</code> options are performed via
refitting
the model with <code><a href="#topic+scale_mod">scale_mod()</a></code> and <code><a href="#topic+center_mod">center_mod()</a></code>,
respectively. Each of those in turn uses <code><a href="#topic+gscale">gscale()</a></code> for the
mean-centering and scaling.
</p>


<h3>Value</h3>

<p>If saved, users can access most of the items that are returned in
the output (and without rounding).
</p>
<table>
<tr><td><code>coeftable</code></td>
<td>
<p>The outputted table of variables and coefficients</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>The model for which statistics are displayed. This would be
most useful in cases in which <code>scale = TRUE</code>.</p>
</td></tr>
</table>
<p>Much other information can be accessed as attributes.
</p>


<h3>Author(s)</h3>

<p>Jacob Long <a href="mailto:jacob.long@sc.edu">jacob.long@sc.edu</a>
</p>


<h3>References</h3>

<p>King, G., &amp; Roberts, M. E. (2015). How robust standard errors expose
methodological problems they do not fix, and what to do about it.
<em>Political Analysis</em>, <em>23</em>(2), 159179.
<a href="https://doi.org/10.1093/pan/mpu015">doi:10.1093/pan/mpu015</a>
</p>
<p>Lumley, T., Diehr, P., Emerson, S., &amp; Chen, L. (2002). The Importance of the
Normality Assumption in Large Public Health Data Sets. <em>Annual Review
of
Public Health</em>, <em>23</em>, 151169.
<a href="https://doi.org/10.1146/annurev.publhealth.23.100901.140546">doi:10.1146/annurev.publhealth.23.100901.140546</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+scale_mod">scale_mod()</a></code> can simply perform the standardization if
preferred.
</p>
<p><code><a href="#topic+gscale">gscale()</a></code> does the heavy lifting for mean-centering and scaling
behind the scenes.
</p>
<p>Other summ: 
<code><a href="#topic+summ.lm">summ.lm</a>()</code>,
<code><a href="#topic+summ.merMod">summ.merMod</a>()</code>,
<code><a href="#topic+summ.rq">summ.rq</a>()</code>,
<code><a href="#topic+summ.svyglm">summ.svyglm</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Dobson (1990) Page 93: Randomized Controlled Trial :
 counts &lt;- c(18,17,15,20,10,20,25,13,12)
 outcome &lt;- gl(3,1,9)
 treatment &lt;- gl(3,3)
 print(d.AD &lt;- data.frame(treatment, outcome, counts))
 glm.D93 &lt;- glm(counts ~ outcome + treatment, family = poisson)

 # Summarize with standardized coefficients
 summ(glm.D93, scale = TRUE)

</code></pre>

<hr>
<h2 id='summ.lm'>Linear regression summaries with options</h2><span id='topic+summ.lm'></span><span id='topic+j_summ.lm'></span>

<h3>Description</h3>

<p><code>summ()</code> prints output for a regression model in a fashion similar to
<code>summary()</code>, but formatted differently with more options.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lm'
summ(
  model,
  scale = FALSE,
  confint = getOption("summ-confint", FALSE),
  ci.width = getOption("summ-ci.width", 0.95),
  robust = getOption("summ-robust", FALSE),
  cluster = NULL,
  vifs = getOption("summ-vifs", FALSE),
  digits = getOption("jtools-digits", 2),
  pvals = getOption("summ-pvals", TRUE),
  n.sd = 1,
  center = FALSE,
  transform.response = FALSE,
  scale.only = FALSE,
  data = NULL,
  part.corr = FALSE,
  model.info = getOption("summ-model.info", TRUE),
  model.fit = getOption("summ-model.fit", TRUE),
  model.coefs = getOption("summ-model.coefs", TRUE),
  which.cols = NULL,
  vcov = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summ.lm_+3A_model">model</code></td>
<td>
<p>A <code>lm</code> object.</p>
</td></tr>
<tr><td><code id="summ.lm_+3A_scale">scale</code></td>
<td>
<p>If <code>TRUE</code>, reports standardized regression
coefficients by scaling and mean-centering input data (the latter can be
changed via the <code>scale.only</code> argument). Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.lm_+3A_confint">confint</code></td>
<td>
<p>Show confidence intervals instead of standard errors? Default
is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.lm_+3A_ci.width">ci.width</code></td>
<td>
<p>A number between 0 and 1 that signifies the width of the
desired confidence interval. Default is <code>.95</code>, which corresponds
to a 95% confidence interval. Ignored if <code>confint = FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.lm_+3A_robust">robust</code></td>
<td>
<p>If not <code>FALSE</code>, reports heteroskedasticity-robust standard
errors instead of conventional SEs. These are also known as Huber-White
standard errors. There are several options provided by
<code><a href="sandwich.html#topic+vcovHC">sandwich::vcovHC()</a></code>: <code>"HC0"</code>, <code>"HC1"</code>, <code>"HC2"</code>, <code>"HC3"</code>, <code>"HC4"</code>,
<code>"HC4m"</code>, <code>"HC5"</code>.
</p>
<p>Default is <code>FALSE</code>.
</p>
<p>This requires the <code>sandwich</code> package to compute the
standard errors.</p>
</td></tr>
<tr><td><code id="summ.lm_+3A_cluster">cluster</code></td>
<td>
<p>For clustered standard errors, provide the column name of
the cluster variable in the input data frame (as a string). Alternately,
provide a vector of clusters. Note that you must set <code>robust</code> to either
&quot;HC1&quot;, &quot;HC2&quot;, or &quot;HC3&quot; in order to have clustered standard errors (&quot;HC4&quot;
and &quot;HC5&quot; are not supported.</p>
</td></tr>
<tr><td><code id="summ.lm_+3A_vifs">vifs</code></td>
<td>
<p>If <code>TRUE</code>, adds a column to output with variance inflation
factors (VIF). Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.lm_+3A_digits">digits</code></td>
<td>
<p>An integer specifying the number of digits past the decimal to
report in the output. Default is 2. You can change the default number of
digits for all jtools functions with
<code>options("jtools-digits" = digits)</code> where digits is the desired
number.</p>
</td></tr>
<tr><td><code id="summ.lm_+3A_pvals">pvals</code></td>
<td>
<p>Show p values? If <code>FALSE</code>, these
are not printed. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="summ.lm_+3A_n.sd">n.sd</code></td>
<td>
<p>If <code>scale = TRUE</code>, how many standard deviations should
predictors be divided by? Default is 1, though some suggest 2.</p>
</td></tr>
<tr><td><code id="summ.lm_+3A_center">center</code></td>
<td>
<p>If you want coefficients for mean-centered variables but don't
want to standardize, set this to <code>TRUE</code>. Note that setting this to
false does not affect whether <code>scale</code> mean-centers variables. Use
<code>scale.only</code> for that.</p>
</td></tr>
<tr><td><code id="summ.lm_+3A_transform.response">transform.response</code></td>
<td>
<p>Should scaling/centering apply to response
variable? Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.lm_+3A_scale.only">scale.only</code></td>
<td>
<p>If you want to scale but not center, set this to <code>TRUE</code>.
Note that for legacy reasons, setting <code>scale = TRUE</code> and <code>center = FALSE</code>
will not achieve the same effect. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.lm_+3A_data">data</code></td>
<td>
<p>If you provide the data used to fit the model here, that data
frame is used to re-fit the model (if <code>scale</code> is <code>TRUE</code>)
instead of the <code><a href="stats.html#topic+model.frame">stats::model.frame()</a></code>
of the model. This is particularly useful if you have variable
transformations or polynomial terms specified in the formula.</p>
</td></tr>
<tr><td><code id="summ.lm_+3A_part.corr">part.corr</code></td>
<td>
<p>Print partial (labeled &quot;partial.r&quot;) and
semipartial (labeled &quot;part.r&quot;) correlations with the table?
Default is <code>FALSE</code>. See details about these quantities when robust
standard errors are used.</p>
</td></tr>
<tr><td><code id="summ.lm_+3A_model.info">model.info</code></td>
<td>
<p>Toggles printing of basic information on sample size,
name of DV, and number of predictors.</p>
</td></tr>
<tr><td><code id="summ.lm_+3A_model.fit">model.fit</code></td>
<td>
<p>Toggles printing of model fit statistics.</p>
</td></tr>
<tr><td><code id="summ.lm_+3A_model.coefs">model.coefs</code></td>
<td>
<p>Toggles printing of model coefficents.</p>
</td></tr>
<tr><td><code id="summ.lm_+3A_which.cols">which.cols</code></td>
<td>
<p>Developmental feature. By providing columns by name,
you can add/remove/reorder requested columns in the output. Not fully
supported, for now.</p>
</td></tr>
<tr><td><code id="summ.lm_+3A_vcov">vcov</code></td>
<td>
<p>You may provide your own variance-covariance matrix for the
regression coefficients if you want to calculate standard errors in
some way not accommodated by the <code>robust</code> and <code>cluster</code> options.</p>
</td></tr>
<tr><td><code id="summ.lm_+3A_...">...</code></td>
<td>
<p>Among other things, arguments are passed to <code><a href="#topic+scale_mod">scale_mod()</a></code> or
<code><a href="#topic+center_mod">center_mod()</a></code> when <code>center</code> or <code>scale</code> is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, this function will print the following items to the
console:
</p>

<ul>
<li><p> The sample size
</p>
</li>
<li><p> The name of the outcome variable
</p>
</li>
<li><p> The R-squared value plus adjusted R-squared
</p>
</li>
<li><p> A table with regression coefficients, standard errors, t-values, and
p values.
</p>
</li></ul>

<p>There are several options available for <code>robust</code>. The heavy
lifting is done by <code><a href="sandwich.html#topic+vcovHC">sandwich::vcovHC()</a></code>, where those are better
described.
Put simply, you may choose from <code>"HC0"</code> to <code>"HC5"</code>. Based on the
recommendation of the developers of <span class="pkg">sandwich</span>, the default is set to
<code>"HC3"</code>. Stata's default is <code>"HC1"</code>, so that choice may be better
if the goal is to replicate Stata's output. Any option that is understood
by <code>vcovHC()</code> will be accepted. Cluster-robust standard errors are
computed if <code>cluster</code> is set to the name of the input data's cluster
variable or is a vector of clusters.
</p>
<p>The <code>scale</code> and <code>center</code> options are performed via
refitting
the model with <code><a href="#topic+scale_mod">scale_mod()</a></code> and <code><a href="#topic+center_mod">center_mod()</a></code>,
respectively. Each of those in turn uses <code><a href="#topic+gscale">gscale()</a></code> for the
mean-centering and scaling.
</p>
<p>If using <code>part.corr = TRUE</code>, then you will get these two common
effect size metrics on the far right two columns of the output table.
However, it should be noted that these do not go hand in hand with
robust standard error estimators. The standard error of the coefficient
doesn't change the point estimate, just the uncertainty. However,
this function uses <em>t</em>-statistics in its calculation of the
partial and semipartial correlation. This provides what amounts to a
heteroskedasticity-adjusted set of estimates, but I am unaware of any
statistical publication that validates this type of use. Please
use these as a heuristic when used alongside robust standard errors; do
not report the &quot;robust&quot; partial and semipartial correlations in
publications.
</p>


<h3>Value</h3>

<p>If saved, users can access most of the items that are returned in
the output (and without rounding).
</p>
<table>
<tr><td><code>coeftable</code></td>
<td>
<p>The outputted table of variables and coefficients</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>The model for which statistics are displayed. This would be
most useful in cases in which <code>scale = TRUE</code>.</p>
</td></tr>
</table>
<p>Much other information can be accessed as attributes.
</p>


<h3>Author(s)</h3>

<p>Jacob Long <a href="mailto:jacob.long@sc.edu">jacob.long@sc.edu</a>
</p>


<h3>References</h3>

<p>King, G., &amp; Roberts, M. E. (2015). How robust standard errors expose
methodological
problems they do not fix, and what to do about it. <em>Political
Analysis</em>,
<em>23</em>(2), 159179. <a href="https://doi.org/10.1093/pan/mpu015">doi:10.1093/pan/mpu015</a>
</p>
<p>Lumley, T., Diehr, P., Emerson, S., &amp; Chen, L. (2002). The Importance of the
Normality Assumption in Large Public Health Data Sets.
<em>Annual Review of
Public Health</em>, <em>23</em>, 151169.
<a href="https://doi.org/10.1146/annurev.publhealth.23.100901.140546">doi:10.1146/annurev.publhealth.23.100901.140546</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+scale_mod">scale_mod()</a></code> can simply perform the standardization if
preferred.
</p>
<p><code><a href="#topic+gscale">gscale()</a></code> does the heavy lifting for mean-centering and scaling
behind the scenes.
</p>
<p>Other summ: 
<code><a href="#topic+summ.glm">summ.glm</a>()</code>,
<code><a href="#topic+summ.merMod">summ.merMod</a>()</code>,
<code><a href="#topic+summ.rq">summ.rq</a>()</code>,
<code><a href="#topic+summ.svyglm">summ.svyglm</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create lm object
fit &lt;- lm(Income ~ Frost + Illiteracy + Murder,
          data = as.data.frame(state.x77))

# Print the output with standardized coefficients and 3 digits
summ(fit, scale = TRUE, digits = 3)

</code></pre>

<hr>
<h2 id='summ.merMod'>Mixed effects regression summaries with options</h2><span id='topic+summ.merMod'></span><span id='topic+j_summ.merMod'></span>

<h3>Description</h3>

<p><code>summ()</code> prints output for a regression model in a fashion similar to
<code>summary()</code>, but formatted differently with more options.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'merMod'
summ(
  model,
  scale = FALSE,
  confint = getOption("summ-confint", FALSE),
  ci.width = getOption("summ-ci.width", 0.95),
  conf.method = getOption("summ-conf.method", c("Wald", "profile", "boot")),
  digits = getOption("jtools-digits", default = 2),
  r.squared = TRUE,
  pvals = getOption("summ-pvals", NULL),
  n.sd = 1,
  center = FALSE,
  transform.response = FALSE,
  scale.only = FALSE,
  data = NULL,
  exp = FALSE,
  t.df = NULL,
  model.info = getOption("summ-model.info", TRUE),
  model.fit = getOption("summ-model.fit", TRUE),
  model.coefs = getOption("summ-model.coefs", TRUE),
  re.variance = getOption("summ-re.variance", c("sd", "var")),
  which.cols = NULL,
  re.table = getOption("summ-re.table", TRUE),
  groups.table = getOption("summ-groups.table", TRUE),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summ.merMod_+3A_model">model</code></td>
<td>
<p>A <code><a href="lme4.html#topic+merMod-class">merMod</a></code> object.</p>
</td></tr>
<tr><td><code id="summ.merMod_+3A_scale">scale</code></td>
<td>
<p>If <code>TRUE</code>, reports standardized regression
coefficients by scaling and mean-centering input data (the latter can be
changed via the <code>scale.only</code> argument). Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.merMod_+3A_confint">confint</code></td>
<td>
<p>Show confidence intervals instead of standard errors? Default
is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.merMod_+3A_ci.width">ci.width</code></td>
<td>
<p>A number between 0 and 1 that signifies the width of the
desired confidence interval. Default is <code>.95</code>, which corresponds
to a 95% confidence interval. Ignored if <code>confint = FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.merMod_+3A_conf.method">conf.method</code></td>
<td>
<p>Argument passed to <code><a href="lme4.html#topic+confint.merMod">lme4::confint.merMod()</a></code>. Default
is <code>"Wald"</code>, but <code>"profile"</code> or <code>"boot"</code> are better when accuracy is a
priority. Be aware that both of the alternate methods are sometimes very
time-consuming.</p>
</td></tr>
<tr><td><code id="summ.merMod_+3A_digits">digits</code></td>
<td>
<p>An integer specifying the number of digits past the decimal to
report in the output. Default is 2. You can change the default number of
digits for all jtools functions with
<code>options("jtools-digits" = digits)</code> where digits is the desired
number.</p>
</td></tr>
<tr><td><code id="summ.merMod_+3A_r.squared">r.squared</code></td>
<td>
<p>Calculate an r-squared model fit statistic? Default is
<code>TRUE</code>, but if it has errors or takes a long time to calculate you
may want to consider setting to FALSE.</p>
</td></tr>
<tr><td><code id="summ.merMod_+3A_pvals">pvals</code></td>
<td>
<p>Show p values? If <code>FALSE</code>, these
are not printed. Default is <code>TRUE</code>, except for merMod objects (see
details).</p>
</td></tr>
<tr><td><code id="summ.merMod_+3A_n.sd">n.sd</code></td>
<td>
<p>If <code>scale = TRUE</code>, how many standard deviations should
predictors be divided by? Default is 1, though some suggest 2.</p>
</td></tr>
<tr><td><code id="summ.merMod_+3A_center">center</code></td>
<td>
<p>If you want coefficients for mean-centered variables but don't
want to standardize, set this to <code>TRUE</code>. Note that setting this to
false does not affect whether <code>scale</code> mean-centers variables. Use
<code>scale.only</code> for that.</p>
</td></tr>
<tr><td><code id="summ.merMod_+3A_transform.response">transform.response</code></td>
<td>
<p>Should scaling/centering apply to response
variable? Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.merMod_+3A_scale.only">scale.only</code></td>
<td>
<p>If you want to scale but not center, set this to <code>TRUE</code>.
Note that for legacy reasons, setting <code>scale = TRUE</code> and <code>center = FALSE</code>
will not achieve the same effect. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.merMod_+3A_data">data</code></td>
<td>
<p>If you provide the data used to fit the model here, that data
frame is used to re-fit the model (if <code>scale</code> is <code>TRUE</code>)
instead of the <code><a href="stats.html#topic+model.frame">stats::model.frame()</a></code>
of the model. This is particularly useful if you have variable
transformations or polynomial terms specified in the formula.</p>
</td></tr>
<tr><td><code id="summ.merMod_+3A_exp">exp</code></td>
<td>
<p>If <code>TRUE</code>, reports exponentiated coefficients with
confidence intervals for exponential models like logit and Poisson models.
This quantity is known as an odds ratio for binary outcomes and incidence
rate ratio for count models.</p>
</td></tr>
<tr><td><code id="summ.merMod_+3A_t.df">t.df</code></td>
<td>
<p>For <code>lmerMod</code> models only. User may set the degrees of
freedom used in conducting t-tests. See details for options.</p>
</td></tr>
<tr><td><code id="summ.merMod_+3A_model.info">model.info</code></td>
<td>
<p>Toggles printing of basic information on sample size,
name of DV, and number of predictors.</p>
</td></tr>
<tr><td><code id="summ.merMod_+3A_model.fit">model.fit</code></td>
<td>
<p>Toggles printing of model fit statistics.</p>
</td></tr>
<tr><td><code id="summ.merMod_+3A_model.coefs">model.coefs</code></td>
<td>
<p>Toggles printing of model coefficents.</p>
</td></tr>
<tr><td><code id="summ.merMod_+3A_re.variance">re.variance</code></td>
<td>
<p>Should random effects variances be expressed in
standard deviations or variances? Default, to be consistent with previous
versions of <code>jtools</code>, is <code>"sd"</code>. Use <code>"var"</code> to get the variance instead.</p>
</td></tr>
<tr><td><code id="summ.merMod_+3A_which.cols">which.cols</code></td>
<td>
<p>Developmental feature. By providing columns by name,
you can add/remove/reorder requested columns in the output. Not fully
supported, for now.</p>
</td></tr>
<tr><td><code id="summ.merMod_+3A_re.table">re.table</code></td>
<td>
<p>Show table summarizing variance of random effects? Default
is TRUE.</p>
</td></tr>
<tr><td><code id="summ.merMod_+3A_groups.table">groups.table</code></td>
<td>
<p>Show table summarizing the grouping variables? Default
is TRUE.</p>
</td></tr>
<tr><td><code id="summ.merMod_+3A_...">...</code></td>
<td>
<p>Among other things, arguments are passed to <code><a href="#topic+scale_mod">scale_mod()</a></code> or
<code><a href="#topic+center_mod">center_mod()</a></code> when <code>center</code> or <code>scale</code> is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, this function will print the following items to the
console:
</p>

<ul>
<li><p> The sample size
</p>
</li>
<li><p> The name of the outcome variable
</p>
</li>
<li><p> The (Pseudo-)R-squared value and AIC/BIC.
</p>
</li>
<li><p> A table with regression coefficients, standard errors, and t-values.
</p>
</li></ul>

<p>The <code>scale</code> and <code>center</code> options are performed via refitting
the model with <code><a href="#topic+scale_mod">scale_mod()</a></code> and <code><a href="#topic+center_mod">center_mod()</a></code>,
respectively. Each of those in turn uses <code><a href="#topic+gscale">gscale()</a></code> for the
mean-centering and scaling.
</p>
<p><code>merMod</code> models are a bit different than the others. The <code>lme4</code>
package developers have, for instance, made a decision not to report or
compute p values for <code>lmer()</code> models. There are good reasons for this,
most notably that the t-values produced are not &quot;accurate&quot; in the sense of
the Type I error rate. For certain large, balanced samples with many
groups, this is no big deal. What's
a &quot;big&quot; or &quot;small&quot; sample? How much balance is necessary? What type of
random effects structure is okay? Good luck getting a statistician to
give you any clear guidelines on this.
Some simulation studies have been done on fewer than 100 observations, so
for sure if your sample is around 100 or fewer you should not interpret
the t-values. A large number of groups is also crucial for avoiding bias
using t-values. If groups are nested or crossed in a linear model,
it is best to just get the <span class="pkg">pbkrtest</span> package.
</p>
<p>By default, this function follows <code>lme4</code>'s lead and does not report
the p values for <code>lmer()</code> models. If the user has <span class="pkg">pbkrtest</span>
installed, however, p values are reported using the Kenward-Roger
d.f. approximation unless <code>pvals = FALSE</code> or <code>t.df</code> is
set to something other than <code>NULL</code>. In publications,
you should cite the
Kenward &amp; Roger (1997) piece as well as either this package or
<span class="pkg">pbkrtest</span> package to explain how the p values were calculated.
</p>
<p>See <code><a href="lme4.html#topic+pvalues">pvalues</a></code> from the <span class="pkg">lme4</span> for more details.
If you're looking for a simple test with no extra packages installed,
it is better to use the confidence
intervals and check to see if they exclude zero than use the t-test.
For users of <code>glmer()</code>, see some of the advice there as well. While
<code>lme4</code> and by association <code>summ()</code> does as well, they are
still imperfect.
</p>
<p>You have some options to customize the output in this regard with the
<code>t.df</code> argument. If <code>NULL</code>, the default, the
degrees of freedom used depends on whether the user has
<span class="pkg">lmerTest</span> or <span class="pkg">pbkrtest</span> installed. If <code>lmerTest</code> is installed,
the degrees of freedom for each coefficient are calculated using the
Satterthwaite method and the p values calculated accordingly.
If only <code>pbkrtest</code> is installed or <code>t.df</code> is <code>"k-r"</code>, the Kenward-Roger
approximation of the standard errors and degrees of freedom for each
coefficient is used. Note that Kenward-Roger standard errors can take
longer to calculate and may cause R to crash with models fit to large
(roughly greater than 5000 rows) datasets.
</p>
<p>If neither is installed and the user sets
<code>pvals = TRUE</code>, then the residual degrees of freedom
is used. If <code>t.df = "residual"</code>, then the residual d.f. is used
without a message. If the user prefers to use some other method to
determine the d.f., then any number provided as the argument will be
used.
</p>
<p><strong>About pseudo-R^2</strong>
</p>
<p>There is no one way to calculate R^2 for mixed models or nonlinear
models. Many caution against interpreting or even using such
approximations outside of OLS regression. With that said, this package
reports one version for your benefit, though you should of course
understand that it is not an unambiguous measure of model fit.
</p>
<p>This package calculates R^2 for mixed models using an adapted version
of <code>rsquared()</code> from the <code>piecewiseSEM</code>
package. This is an implementation of the Nakagawa &amp; Schielzeth (2013)
procedure with refinements by Johnson (2014). If you choose to report
the pseudo-R^2 in a publication, you should cite Nakagawa &amp; Schielzeth
to explain how the calculation was done.
</p>


<h3>Value</h3>

<p>If saved, users can access most of the items that are returned in
the output (and without rounding).
</p>
<table>
<tr><td><code>coeftable</code></td>
<td>
<p>The outputted table of variables and coefficients</p>
</td></tr>
<tr><td><code>rcoeftable</code></td>
<td>
<p>The secondary table with the grouping variables and
random coefficients.</p>
</td></tr>
<tr><td><code>gvars</code></td>
<td>
<p>The tertiary table with the grouping variables, numbers of
groups, and ICCs.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>The model for which statistics are displayed. This would be
most useful in cases in which <code>scale = TRUE</code>.</p>
</td></tr>
</table>
<p>Much other information can be accessed as attributes.
</p>


<h3>Author(s)</h3>

<p>Jacob Long <a href="mailto:jacob.long@sc.edu">jacob.long@sc.edu</a>
</p>


<h3>References</h3>

<p>Johnson, P. C. D. (2014). Extension of Nakagawa &amp; Schielzeth's
$R^2_GLMM$ to random slopes models. <em>Methods in Ecology and
Evolution</em>, <em>5</em>, 944946. <a href="https://doi.org/10.1111/2041-210X.12225">doi:10.1111/2041-210X.12225</a>
</p>
<p>Kenward, M. G., &amp; Roger, J. H. (1997). Small sample inference for fixed
effects from restricted maximum likelihood. <em>Biometrics</em>,
<em>53</em>, 983.
<a href="https://doi.org/10.2307/2533558">doi:10.2307/2533558</a>
</p>
<p>Kuznetsova, A., Brockhoff, P. B., &amp; Christensen, R. H. B. (2017). lmerTest
package: Tests in linear mixed effects models.
<em>Journal of Statistical Software</em>, <em>82</em>.
<a href="https://doi.org/10.18637/jss.v082.i13">doi:10.18637/jss.v082.i13</a>
</p>
<p>Luke, S. G. (2017). Evaluating significance in linear mixed-effects models
in R. <em>Behavior Research Methods</em>, <em>49</em>, 14941502.
<a href="https://doi.org/10.3758/s13428-016-0809-y">doi:10.3758/s13428-016-0809-y</a>
</p>
<p>Nakagawa, S., &amp; Schielzeth, H. (2013). A general and simple method for
obtaining $R^2$ from generalized linear mixed-effects models.
<em>Methods in Ecology and Evolution</em>, <em>4</em>, 133142.
<a href="https://doi.org/10.1111/j.2041-210x.2012.00261.x">doi:10.1111/j.2041-210x.2012.00261.x</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+scale_mod">scale_mod()</a></code> can simply perform the standardization if
preferred.
</p>
<p><code><a href="#topic+gscale">gscale()</a></code> does the heavy lifting for mean-centering and scaling
behind the scenes.
</p>
<p><code><a href="pbkrtest.html#topic+get_ddf_Lb">pbkrtest::get_ddf_Lb()</a></code> gets the Kenward-Roger degrees of
freedom if you have <span class="pkg">pbkrtest</span> installed.
</p>
<p>A tweaked version of <code>piecewiseSEM::rsquared()</code> is used to
generate the pseudo-R-squared estimates for linear models.
</p>
<p>Other summ: 
<code><a href="#topic+summ.glm">summ.glm</a>()</code>,
<code><a href="#topic+summ.lm">summ.lm</a>()</code>,
<code><a href="#topic+summ.rq">summ.rq</a>()</code>,
<code><a href="#topic+summ.svyglm">summ.svyglm</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("lme4")) {
  library(lme4, quietly = TRUE)
  data(sleepstudy)
  mv &lt;- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)

  summ(mv) # Note lack of p values if you don't have lmerTest/pbkrtest

  # Without lmerTest/pbkrtest, you'll get message about Type 1 errors
  summ(mv, pvals = TRUE)

  # To suppress message, manually specify t.df argument
  summ(mv, t.df = "residual")

  # Confidence intervals may be better alternative to p values
  summ(mv, confint = TRUE)
  # Use conf.method to get profile intervals (may be slow to run)
  # summ(mv, confint = TRUE, conf.method = "profile")

}

</code></pre>

<hr>
<h2 id='summ.rq'>Quantile regression summaries with options</h2><span id='topic+summ.rq'></span>

<h3>Description</h3>

<p><code>summ()</code> prints output for a regression model in a fashion
similar to <code>summary()</code>, but formatted differently with more options.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rq'
summ(
  model,
  scale = FALSE,
  confint = getOption("summ-confint", FALSE),
  ci.width = getOption("summ-ci.width", 0.95),
  se = c("nid", "rank", "iid", "ker", "boot"),
  boot.sims = 1000,
  boot.method = "xy",
  vifs = getOption("summ-vifs", FALSE),
  digits = getOption("jtools-digits", 2),
  pvals = getOption("summ-pvals", TRUE),
  n.sd = 1,
  center = FALSE,
  transform.response = FALSE,
  data = NULL,
  model.info = getOption("summ-model.info", TRUE),
  model.fit = getOption("summ-model.fit", TRUE),
  model.coefs = getOption("summ-model.coefs", TRUE),
  which.cols = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summ.rq_+3A_model">model</code></td>
<td>
<p>A <code>rq</code> model. At this time, <code>rqs</code> models (multiple <code>tau</code>
parameters) are not supported.</p>
</td></tr>
<tr><td><code id="summ.rq_+3A_scale">scale</code></td>
<td>
<p>If <code>TRUE</code>, reports standardized regression
coefficients by scaling and mean-centering input data (the latter can be
changed via the <code>scale.only</code> argument). Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.rq_+3A_confint">confint</code></td>
<td>
<p>Show confidence intervals instead of standard errors? Default
is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.rq_+3A_ci.width">ci.width</code></td>
<td>
<p>A number between 0 and 1 that signifies the width of the
desired confidence interval. Default is <code>.95</code>, which corresponds
to a 95% confidence interval. Ignored if <code>confint = FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.rq_+3A_se">se</code></td>
<td>
<p>One of &quot;nid&quot;, &quot;rank&quot;, &quot;iid&quot;, &quot;ker&quot;, or &quot;boot&quot;. &quot;nid&quot; is default.
See <code><a href="quantreg.html#topic+summary.rq">quantreg::summary.rq()</a></code> documentation for more about these options.</p>
</td></tr>
<tr><td><code id="summ.rq_+3A_boot.sims">boot.sims</code></td>
<td>
<p>If <code>se = "boot"</code>, the number of bootstrap replications to
perform. This is passed as the <code>R</code> argument to <code>boot.rq</code></p>
</td></tr>
<tr><td><code id="summ.rq_+3A_boot.method">boot.method</code></td>
<td>
<p>If <code>se = "boot"</code>, the type of bootstrapping method to
use. Default is &quot;xy&quot;, but see <code><a href="quantreg.html#topic+boot.rq">quantreg::boot.rq()</a></code> for more options.</p>
</td></tr>
<tr><td><code id="summ.rq_+3A_vifs">vifs</code></td>
<td>
<p>If <code>TRUE</code>, adds a column to output with variance inflation
factors (VIF). Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.rq_+3A_digits">digits</code></td>
<td>
<p>An integer specifying the number of digits past the decimal to
report in the output. Default is 2. You can change the default number of
digits for all jtools functions with
<code>options("jtools-digits" = digits)</code> where digits is the desired
number.</p>
</td></tr>
<tr><td><code id="summ.rq_+3A_pvals">pvals</code></td>
<td>
<p>Show p values? If <code>FALSE</code>, these
are not printed. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="summ.rq_+3A_n.sd">n.sd</code></td>
<td>
<p>If <code>scale = TRUE</code>, how many standard deviations should
predictors be divided by? Default is 1, though some suggest 2.</p>
</td></tr>
<tr><td><code id="summ.rq_+3A_center">center</code></td>
<td>
<p>If you want coefficients for mean-centered variables but don't
want to standardize, set this to <code>TRUE</code>. Note that setting this to
false does not affect whether <code>scale</code> mean-centers variables. Use
<code>scale.only</code> for that.</p>
</td></tr>
<tr><td><code id="summ.rq_+3A_transform.response">transform.response</code></td>
<td>
<p>Should scaling/centering apply to response
variable? Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.rq_+3A_data">data</code></td>
<td>
<p>If you provide the data used to fit the model here, that data
frame is used to re-fit the model (if <code>scale</code> is <code>TRUE</code>)
instead of the <code><a href="stats.html#topic+model.frame">stats::model.frame()</a></code>
of the model. This is particularly useful if you have variable
transformations or polynomial terms specified in the formula.</p>
</td></tr>
<tr><td><code id="summ.rq_+3A_model.info">model.info</code></td>
<td>
<p>Toggles printing of basic information on sample size,
name of DV, and number of predictors.</p>
</td></tr>
<tr><td><code id="summ.rq_+3A_model.fit">model.fit</code></td>
<td>
<p>Toggles printing of model fit statistics.</p>
</td></tr>
<tr><td><code id="summ.rq_+3A_model.coefs">model.coefs</code></td>
<td>
<p>Toggles printing of model coefficents.</p>
</td></tr>
<tr><td><code id="summ.rq_+3A_which.cols">which.cols</code></td>
<td>
<p>Developmental feature. By providing columns by name,
you can add/remove/reorder requested columns in the output. Not fully
supported, for now.</p>
</td></tr>
<tr><td><code id="summ.rq_+3A_...">...</code></td>
<td>
<p>Among other things, arguments are passed to <code><a href="#topic+scale_mod">scale_mod()</a></code> or
<code><a href="#topic+center_mod">center_mod()</a></code> when <code>center</code> or <code>scale</code> is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method implements most of the things I think most users would
asking <code>summary.rq</code> for. <code>hs</code>, <code>U</code>, and <code>gamma</code> are ignored.
</p>
<p>Note that when using <code>se = "rank"</code>, there are no standard errors,
test statistics, or p values calculated.
</p>
<p>About the R1 fit statistic: Described in Koenker &amp; Machado (1999), this
offers an interpretation similar to R-squared in OLS regression. While you
could calculate R-squared for these models, it goes against the underlying
theoretical rationale for them. Koenker himself is not a big fan of R1
either, but it's something. See Koenker &amp; Machado (1999) for more info.
</p>


<h3>References</h3>

<p>Koenker, R., &amp; Machado, J. A. F. (1999). Goodness of fit and related
inference processes for quantile regression.
<em>Journal of the American Statistical Association</em>, <em>94</em>, 12961310.
https://doi.org/10.1080/01621459.1999.10473882
</p>


<h3>See Also</h3>

<p>Other summ: 
<code><a href="#topic+summ.glm">summ.glm</a>()</code>,
<code><a href="#topic+summ.lm">summ.lm</a>()</code>,
<code><a href="#topic+summ.merMod">summ.merMod</a>()</code>,
<code><a href="#topic+summ.svyglm">summ.svyglm</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if (requireNamespace("quantreg")) {
 library(quantreg)
 data(engel)
 fitrq &lt;- rq(income ~ foodexp, data = engel, tau = 0.5)
 summ(fitrq)
}


</code></pre>

<hr>
<h2 id='summ.svyglm'>Complex survey regression summaries with options</h2><span id='topic+summ.svyglm'></span><span id='topic+j_summ.svyglm'></span>

<h3>Description</h3>

<p><code>summ()</code> prints output for a regression model in a fashion similar to
<code>summary()</code>, but formatted differently with more options.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'svyglm'
summ(
  model,
  scale = FALSE,
  confint = getOption("summ-confint", FALSE),
  ci.width = getOption("summ-ci.width", 0.95),
  digits = getOption("jtools-digits", default = 2),
  pvals = getOption("summ-pvals", TRUE),
  n.sd = 1,
  center = FALSE,
  transform.response = FALSE,
  scale.only = FALSE,
  exp = FALSE,
  vifs = getOption("summ-vifs", FALSE),
  model.info = getOption("summ-model.info", TRUE),
  model.fit = getOption("summ-model.fit", TRUE),
  model.coefs = getOption("summ-model.coefs", TRUE),
  which.cols = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summ.svyglm_+3A_model">model</code></td>
<td>
<p>A <code>svyglm</code> object.</p>
</td></tr>
<tr><td><code id="summ.svyglm_+3A_scale">scale</code></td>
<td>
<p>If <code>TRUE</code>, reports standardized regression
coefficients by scaling and mean-centering input data (the latter can be
changed via the <code>scale.only</code> argument). Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.svyglm_+3A_confint">confint</code></td>
<td>
<p>Show confidence intervals instead of standard errors? Default
is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.svyglm_+3A_ci.width">ci.width</code></td>
<td>
<p>A number between 0 and 1 that signifies the width of the
desired confidence interval. Default is <code>.95</code>, which corresponds
to a 95% confidence interval. Ignored if <code>confint = FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.svyglm_+3A_digits">digits</code></td>
<td>
<p>An integer specifying the number of digits past the decimal to
report in the output. Default is 2. You can change the default number of
digits for all jtools functions with
<code>options("jtools-digits" = digits)</code> where digits is the desired
number.</p>
</td></tr>
<tr><td><code id="summ.svyglm_+3A_pvals">pvals</code></td>
<td>
<p>Show p values? If <code>FALSE</code>, these
are not printed. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="summ.svyglm_+3A_n.sd">n.sd</code></td>
<td>
<p>If <code>scale = TRUE</code>, how many standard deviations should
predictors be divided by? Default is 1, though some suggest 2.</p>
</td></tr>
<tr><td><code id="summ.svyglm_+3A_center">center</code></td>
<td>
<p>If you want coefficients for mean-centered variables but don't
want to standardize, set this to <code>TRUE</code>. Note that setting this to
false does not affect whether <code>scale</code> mean-centers variables. Use
<code>scale.only</code> for that.</p>
</td></tr>
<tr><td><code id="summ.svyglm_+3A_transform.response">transform.response</code></td>
<td>
<p>Should scaling/centering apply to response
variable? Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.svyglm_+3A_scale.only">scale.only</code></td>
<td>
<p>If you want to scale but not center, set this to <code>TRUE</code>.
Note that for legacy reasons, setting <code>scale = TRUE</code> and <code>center = FALSE</code>
will not achieve the same effect. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.svyglm_+3A_exp">exp</code></td>
<td>
<p>If <code>TRUE</code>, reports exponentiated coefficients with
confidence intervals for exponential models like logit and Poisson models.
This quantity is known as an odds ratio for binary outcomes and incidence
rate ratio for count models.</p>
</td></tr>
<tr><td><code id="summ.svyglm_+3A_vifs">vifs</code></td>
<td>
<p>If <code>TRUE</code>, adds a column to output with variance inflation
factors (VIF). Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summ.svyglm_+3A_model.info">model.info</code></td>
<td>
<p>Toggles printing of basic information on sample size,
name of DV, and number of predictors.</p>
</td></tr>
<tr><td><code id="summ.svyglm_+3A_model.fit">model.fit</code></td>
<td>
<p>Toggles printing of model fit statistics.</p>
</td></tr>
<tr><td><code id="summ.svyglm_+3A_model.coefs">model.coefs</code></td>
<td>
<p>Toggles printing of model coefficents.</p>
</td></tr>
<tr><td><code id="summ.svyglm_+3A_which.cols">which.cols</code></td>
<td>
<p>Developmental feature. By providing columns by name,
you can add/remove/reorder requested columns in the output. Not fully
supported, for now.</p>
</td></tr>
<tr><td><code id="summ.svyglm_+3A_...">...</code></td>
<td>
<p>Among other things, arguments are passed to <code><a href="#topic+scale_mod">scale_mod()</a></code> or
<code><a href="#topic+center_mod">center_mod()</a></code> when <code>center</code> or <code>scale</code> is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, this function will print the following items to the
console:
</p>

<ul>
<li><p> The sample size
</p>
</li>
<li><p> The name of the outcome variable
</p>
</li>
<li><p> The (Pseudo-)R-squared value and AIC.
</p>
</li>
<li><p> A table with regression coefficients, standard errors, t values, and
p values.
</p>
</li></ul>

<p>The <code>scale</code> and <code>center</code> options are performed via refitting
the model with <code><a href="#topic+scale_mod">scale_mod()</a></code> and <code><a href="#topic+center_mod">center_mod()</a></code>,
respectively. Each of those in turn uses <code><a href="#topic+gscale">gscale()</a></code> for the
mean-centering and scaling. These functions can handle <code>svyglm</code> objects
correctly by calling <code>svymean()</code> and <code>svyvar()</code> to compute means
and
standard deviations. Weights are not altered. The fact that the model is
refit means the runtime will be similar to the original time it took to fit
the model.
</p>


<h3>Value</h3>

<p>If saved, users can access most of the items that are returned in the
output (and without rounding).
</p>
<table>
<tr><td><code>coeftable</code></td>
<td>
<p>The outputted table of variables and coefficients</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>The model for which statistics are displayed. This would be
most useful in cases in which <code>scale = TRUE</code>.</p>
</td></tr>
</table>
<p>Much other information can be accessed as attributes.
</p>


<h3>Author(s)</h3>

<p>Jacob Long <a href="mailto:jacob.long@sc.edu">jacob.long@sc.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+scale_mod">scale_mod()</a></code> can simply perform the standardization if
preferred.
</p>
<p><code><a href="#topic+gscale">gscale()</a></code> does the heavy lifting for mean-centering and scaling
behind the scenes.
</p>
<p>Other summ: 
<code><a href="#topic+summ.glm">summ.glm</a>()</code>,
<code><a href="#topic+summ.lm">summ.lm</a>()</code>,
<code><a href="#topic+summ.merMod">summ.merMod</a>()</code>,
<code><a href="#topic+summ.rq">summ.rq</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("survey")) {
  library(survey)
  data(api)
  dstrat &lt;- svydesign(id = ~1, strata =~ stype, weights =~ pw,
                      data = apistrat, fpc =~ fpc)
  regmodel &lt;- svyglm(api00 ~ ell * meals, design = dstrat)

  summ(regmodel)
}
</code></pre>

<hr>
<h2 id='svycor'>Calculate Pearson correlations with complex survey data</h2><span id='topic+svycor'></span>

<h3>Description</h3>

<p><code>svycor</code> extends the <code>survey</code> package by calculating correlations
with syntax similar to the original package, which for reasons unknown lacks
such a function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>svycor(
  formula,
  design,
  na.rm = FALSE,
  digits = getOption("jtools-digits", default = 2),
  sig.stats = FALSE,
  bootn = 1000,
  mean1 = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="svycor_+3A_formula">formula</code></td>
<td>
<p>A formula (e.g., ~var1+var2) specifying the terms to correlate.</p>
</td></tr>
<tr><td><code id="svycor_+3A_design">design</code></td>
<td>
<p>The <code>survey.design</code> or <code>svyrep.design</code> object.</p>
</td></tr>
<tr><td><code id="svycor_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical. Should cases with missing values be dropped?</p>
</td></tr>
<tr><td><code id="svycor_+3A_digits">digits</code></td>
<td>
<p>An integer specifying the number of digits past the decimal to
report in the output. Default is 2. You can change the default number of
digits for all jtools functions with
<code>options("jtools-digits" = digits)</code> where digits is the desired number.</p>
</td></tr>
<tr><td><code id="svycor_+3A_sig.stats">sig.stats</code></td>
<td>
<p>Logical. Perform non-parametric bootstrapping
(using <code><a href="weights.html#topic+wtd.cor">wtd.cor</a></code>) to generate standard errors and
associated t- and p-values. See details for some considerations when doing
null hypothesis testing with complex survey correlations.</p>
</td></tr>
<tr><td><code id="svycor_+3A_bootn">bootn</code></td>
<td>
<p>If <code>sig.stats</code> is TRUE, this defines the number of
bootstraps to be run to generate the standard errors and p-values. For
large values and large datasets, this can contribute considerably to
processing time.</p>
</td></tr>
<tr><td><code id="svycor_+3A_mean1">mean1</code></td>
<td>
<p>If <code>sig.stats</code> is TRUE, it is important to know whether the
sampling weights should have a mean of 1. That is, should the standard
errors be calculated as if the number of rows in your dataset is the total
number of observations (TRUE) or as if the sum of the weights in your
dataset is the total number of observations (FALSE)?</p>
</td></tr>
<tr><td><code id="svycor_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="survey.html#topic+svyglm">svyvar()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function extends the <code>survey</code> package by calculating the
correlations for user-specified variables in survey design and returning a
correlation matrix.
</p>
<p>Using the <code><a href="weights.html#topic+wtd.cor">wtd.cor</a></code> function, this function also
returns standard errors and p-values for the correlation terms using a
sample-weighted bootstrapping procedure. While correlations do not require
distributional assumptions, hypothesis testing (i.e., <code class="reqn">r &gt; 0</code>) does.
The appropriate way to calculate standard errors and use them to define a
probability is not straightforward in this scenario since the weighting
causes heteroskedasticity, thereby violating
an assumption inherent in the commonly used methods for converting Pearson's
correlations into t-values. The method provided here is defensible, but if
reporting in scientific publications the method should be spelled out.
</p>


<h3>Value</h3>

<p>If significance tests are not requested, there is one returned value:
</p>
<table>
<tr><td><code>cors</code></td>
<td>
<p>The correlation matrix (without rounding)</p>
</td></tr>
</table>
<p>If significance tests are requested, the following are also returned:
</p>
<table>
<tr><td><code>p.values</code></td>
<td>
<p>A matrix of p values</p>
</td></tr>
<tr><td><code>t.values</code></td>
<td>
<p>A matrix of t values</p>
</td></tr>
<tr><td><code>std.err</code></td>
<td>
<p>A matrix of standard errors</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function was designed in part on the procedure recommended by
Thomas Lumley, the author of the survey package, on
<a href="https://stackoverflow.com/questions/34418822/pearson-correlation-coefficient-in-rs-survey-package#41031088">Stack Overflow</a>. However, he has
not reviewed or endorsed this implementation.
All defects are attributed to the author.
</p>


<h3>Author(s)</h3>

<p>Jacob Long <a href="mailto:jacob.long@sc.edu">jacob.long@sc.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="weights.html#topic+wtd.cor">wtd.cor</a></code>, <code><a href="survey.html#topic+surveysummary">svymean()</a></code>
</p>
<p>Other survey package extensions: 
<code><a href="#topic+svysd">svysd</a>()</code>
</p>
<p>Other survey tools: 
<code><a href="#topic+pf_sv_test">pf_sv_test</a>()</code>,
<code><a href="#topic+svysd">svysd</a>()</code>,
<code><a href="#topic+weights_tests">weights_tests</a>()</code>,
<code><a href="#topic+wgttest">wgttest</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("survey")) {
 library(survey)
 data(api)
 # Create survey design object
 dstrat &lt;- svydesign(id = ~1, strata = ~stype, weights = ~pw,
                     data = apistrat, fpc = ~fpc)

 # Print correlation matrix
 svycor(~api00 + api99 + dnum, design = dstrat)

 # Save the results, extract correlation matrix
 out &lt;- svycor(~api00 + api99 + dnum, design = dstrat)
 out$cors

}

</code></pre>

<hr>
<h2 id='svysd'>Calculate standard deviations with complex survey data</h2><span id='topic+svysd'></span>

<h3>Description</h3>

<p><code>svysd</code> extends the <code>survey</code> package by calculating standard
deviations with syntax similar to the original package, which provides
only a <code><a href="survey.html#topic+surveysummary">svyvar()</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>svysd(
  formula,
  design,
  na.rm = FALSE,
  digits = getOption("jtools-digits", default = 3),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="svysd_+3A_formula">formula</code></td>
<td>
<p>A formula (e.g., ~var1+var2) specifying the term(s) of interest.</p>
</td></tr>
<tr><td><code id="svysd_+3A_design">design</code></td>
<td>
<p>The <code>survey.design</code> or <code>svyrep.design</code> object.</p>
</td></tr>
<tr><td><code id="svysd_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical. Should cases with missing values be dropped?</p>
</td></tr>
<tr><td><code id="svysd_+3A_digits">digits</code></td>
<td>
<p>An integer specifying the number of digits past the decimal to
report in the output. Default is 3. You can change the default number of
digits for all jtools functions with
<code>options("jtools-digits" = digits)</code> where digits is the desired number.</p>
</td></tr>
<tr><td><code id="svysd_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="survey.html#topic+surveysummary">svyvar()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An alternative is to simply do <code>sqrt(svyvar(~term, design = design))</code>.
However, if printing and sharing the output, this may be misleading since
the output will say &quot;variance.&quot;
</p>


<h3>Note</h3>

<p>This function was designed independent of the <span class="pkg">survey</span> package and
is neither endorsed nor known to its authors.
</p>


<h3>See Also</h3>

<p><code><a href="survey.html#topic+surveysummary">svyvar()</a></code>
</p>
<p>Other survey package extensions: 
<code><a href="#topic+svycor">svycor</a>()</code>
</p>
<p>Other survey tools: 
<code><a href="#topic+pf_sv_test">pf_sv_test</a>()</code>,
<code><a href="#topic+svycor">svycor</a>()</code>,
<code><a href="#topic+weights_tests">weights_tests</a>()</code>,
<code><a href="#topic+wgttest">wgttest</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("survey")) {
 library(survey)
 data(api)
 # Create survey design object
 dstrat &lt;- svydesign(id = ~1,strata = ~stype, weights = ~pw, data = apistrat,
                     fpc=~fpc)

 # Print the standard deviation of some variables
 svysd(~api00+ell+meals, design = dstrat)
}

</code></pre>

<hr>
<h2 id='theme_apa'>Format ggplot2 figures in APA style</h2><span id='topic+theme_apa'></span>

<h3>Description</h3>

<p><code>theme_apa()</code> is designed to work like any other complete theme from
<code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>. To the extent possible, it aligns with
the (vague) APA figure guidelines.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>theme_apa(
  legend.pos = "right",
  legend.use.title = FALSE,
  legend.font.size = 12,
  x.font.size = 12,
  y.font.size = 12,
  facet.title.size = 12,
  remove.y.gridlines = TRUE,
  remove.x.gridlines = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="theme_apa_+3A_legend.pos">legend.pos</code></td>
<td>
<p>One of <code>"right"</code>, <code>"left"</code>, <code>"top"</code>, <code>"bottom"</code>,
<code>"topleft"</code>, <code>"topright"</code>, <code>"topmiddle"</code>, <code>"bottomleft"</code>,
<code>"bottomright"</code>, or <code>"bottommiddle"</code>.
Positions the legend, which will layer on top of any geoms, on the plane.</p>
</td></tr>
<tr><td><code id="theme_apa_+3A_legend.use.title">legend.use.title</code></td>
<td>
<p>Logical. Specify whether to include a legend title.
Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="theme_apa_+3A_legend.font.size">legend.font.size</code></td>
<td>
<p>Integer indicating the font size of the labels in the
legend. Default and APA-recommended is 12, but if there are many labels it
may be necessary to choose a smaller size.</p>
</td></tr>
<tr><td><code id="theme_apa_+3A_x.font.size">x.font.size</code></td>
<td>
<p>Font size of x-axis label.</p>
</td></tr>
<tr><td><code id="theme_apa_+3A_y.font.size">y.font.size</code></td>
<td>
<p>Font size of x-axis label.</p>
</td></tr>
<tr><td><code id="theme_apa_+3A_facet.title.size">facet.title.size</code></td>
<td>
<p>Font size of facet labels.</p>
</td></tr>
<tr><td><code id="theme_apa_+3A_remove.y.gridlines">remove.y.gridlines</code></td>
<td>
<p>Should the coordinate grid on the y-axis
(horizontal lines) be removed? Default is TRUE.</p>
</td></tr>
<tr><td><code id="theme_apa_+3A_remove.x.gridlines">remove.x.gridlines</code></td>
<td>
<p>Should the coordinate grid on the x-axis (vertical
lines) be removed? Default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function applies a theme to <code>ggplot2</code> figures with a
style that is roughly in line with APA guidelines. Users may need to
perform further operations for their specific use cases.
</p>
<p>There are some things to keep in mind about APA style figures:
</p>

<ul>
<li><p> Main titles should be written in the word processor or typesetter
rather than on the plot image itself.
</p>
</li>
<li><p> In some cases, users can forgo a legend in favor of describing the
figure in a caption (also written in the word processor/typesetter).
</p>
</li>
<li><p> Legends are typically embedded on the coordinate plane of the figure
rather than next to it, as is default in <code>ggplot2</code>.
</p>
</li>
<li><p> Use of color is generally discouraged since most of the applications
for which APA figures are needed involve eventual publication in non-color
print media.
</p>
</li>
<li><p> There are no hard and fast rules on font size, though APA recommends
choosing between 8 and 14-point. Fonts in figures should be sans serif.
</p>
</li></ul>

<p>Because APA style calls for positioning legends on the plane itself, this
function includes options for choosing a position&ndash;top left, top right, bottom
left, bottom right&ndash;to place the legend. <code>ggplot2</code> provides no obvious
way to automatically choose a position that overlaps least with the geoms (the
plotted data), so users will need to choose one.
</p>
<p>Facetting is supported, but APA guidelines are considerably less clear for
such situations.
</p>
<p>This theme was created with inspiration from Rudolf Cardinal's
<a href="http://egret.psychol.cam.ac.uk/statistics/R/graphs2.html">code</a>, which
required updating for newer versions of <code>ggplot2</code> and adaptations for
APA style.
</p>


<h3>Author(s)</h3>

<p>Jacob Long <a href="mailto:jacob.long@sc.edu">jacob.long@sc.edu</a>
</p>


<h3>References</h3>

<p>American Psychological Association. (2010). <em>Publication manual of the American
Psychological Association, Sixth Edition</em>. Washington, DC: American Psychological
Association.
</p>
<p>Nicol, A.A.M. &amp; Pexman, P.M. (2010). <em>Displaying your findings: A practical
guide for creating figures, posters, and presentations, Sixth Edition</em>. Washington,
D.C.: American Psychological Association.
</p>


<h3>See Also</h3>

<p><code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>, <code><a href="ggplot2.html#topic+theme">theme</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create plot with ggplot2
library(ggplot2)
plot &lt;- ggplot(mpg, aes(cty, hwy)) +
  geom_jitter()

# Add APA theme with defaults
plot + theme_apa()


</code></pre>

<hr>
<h2 id='theme_nice'>A nice, flexible <code>ggplot2</code> theme</h2><span id='topic+theme_nice'></span>

<h3>Description</h3>

<p><code>theme_nice</code> is designed to work like any other complete theme from
<code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>. It has a nice appearance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>theme_nice(
  legend.pos = "right",
  style = c("white", "light", "dark_blue", "dark_gray"),
  base_size = 11,
  base_family = "",
  base_line_size = base_size/22,
  base_rect_size = base_size/22
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="theme_nice_+3A_legend.pos">legend.pos</code></td>
<td>
<p>One of <code>"right"</code>, <code>"left"</code>, <code>"top"</code>, <code>"bottom"</code> (outside
the plotting area), <code>"topleft"</code>, <code>"topright"</code>, <code>"topmiddle"</code>,
<code>"bottomleft"</code>, <code>"bottomright"</code>, or <code>"bottommiddle"</code> (inside the plotting
area).</p>
</td></tr>
<tr><td><code id="theme_nice_+3A_style">style</code></td>
<td>
<p>One of <code>"white"</code>, <code>"light"</code>, <code>"dark_blue"</code>, or <code>"dark_gray"</code>.
<code>"white"</code> sets the background to white, <code>"light"</code> to light gray,
<code>"dark_gray"</code> to dark gray, <code>"dark_blue"</code> to dark blue.</p>
</td></tr>
<tr><td><code id="theme_nice_+3A_base_size">base_size</code></td>
<td>
<p>base font size, given in pts.</p>
</td></tr>
<tr><td><code id="theme_nice_+3A_base_family">base_family</code></td>
<td>
<p>base font family</p>
</td></tr>
<tr><td><code id="theme_nice_+3A_base_line_size">base_line_size</code></td>
<td>
<p>base size for line elements</p>
</td></tr>
<tr><td><code id="theme_nice_+3A_base_rect_size">base_rect_size</code></td>
<td>
<p>base size for rect elements</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jacob Long <a href="mailto:jacob.long@sc.edu">jacob.long@sc.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create plot with ggplot2
library(ggplot2)
plot &lt;- ggplot(mpg, aes(cty, hwy)) +
  geom_jitter() + theme_nice()


</code></pre>

<hr>
<h2 id='tidy.summ'>Broom extensions for summ objects</h2><span id='topic+tidy.summ'></span><span id='topic+tidy.summ.merMod'></span><span id='topic+glance.summ.lm'></span><span id='topic+glance.summ.glm'></span><span id='topic+glance.summ.svyglm'></span><span id='topic+glance.summ.merMod'></span><span id='topic+glance.summ.rq'></span>

<h3>Description</h3>

<p>These are functions used for compatibility with broom's tidying
functions to facilitate use with huxreg, thereby making
<code><a href="#topic+export_summs">export_summs</a></code> works.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summ'
tidy(x, conf.int = FALSE, conf.level = 0.95, ...)

## S3 method for class 'summ.merMod'
tidy(x, conf.int = FALSE, conf.level = 0.95, ...)

## S3 method for class 'summ.lm'
glance(x, ...)

## S3 method for class 'summ.glm'
glance(x, ...)

## S3 method for class 'summ.svyglm'
glance(x, ...)

## S3 method for class 'summ.merMod'
glance(x, ...)

## S3 method for class 'summ.rq'
glance(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tidy.summ_+3A_x">x</code></td>
<td>
<p>The <code>summ</code> object.</p>
</td></tr>
<tr><td><code id="tidy.summ_+3A_conf.int">conf.int</code></td>
<td>
<p>Include confidence intervals? Default is FALSE.</p>
</td></tr>
<tr><td><code id="tidy.summ_+3A_conf.level">conf.level</code></td>
<td>
<p>How wide confidence intervals should be, if requested.
Default is .95.</p>
</td></tr>
<tr><td><code id="tidy.summ_+3A_...">...</code></td>
<td>
<p>Other arguments (usually ignored)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame with columns matching those appropriate for the model
type per <code>glance</code> documentation.
</p>


<h3>See Also</h3>

<p><code><a href="generics.html#topic+glance">glance</a></code>
</p>

<hr>
<h2 id='weights_tests'>Test whether sampling weights are needed</h2><span id='topic+weights_tests'></span>

<h3>Description</h3>

<p>Use the tests proposed in Pfeffermann and Sverchkov (1999)
and DuMouchel and Duncan (1983) to check whether
a regression model is specified correctly without weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weights_tests(
  model,
  weights,
  data,
  model_output = TRUE,
  test = NULL,
  sims = 1000,
  digits = getOption("jtools-digits", default = 2)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weights_tests_+3A_model">model</code></td>
<td>
<p>The fitted model, without weights</p>
</td></tr>
<tr><td><code id="weights_tests_+3A_weights">weights</code></td>
<td>
<p>The name of the weights column in <code>model</code>'s data frame
or a vector of weights equal in length to the number of observations
included in <code>model</code>.</p>
</td></tr>
<tr><td><code id="weights_tests_+3A_data">data</code></td>
<td>
<p>The data frame with the data fed to the fitted model and the
weights</p>
</td></tr>
<tr><td><code id="weights_tests_+3A_model_output">model_output</code></td>
<td>
<p>Should a summary of the model with weights as predictor
be printed? Default is TRUE, but you may not want it if you are trying to
declutter a document.</p>
</td></tr>
<tr><td><code id="weights_tests_+3A_test">test</code></td>
<td>
<p>Which type of test should be used in the ANOVA? The default,
<code>NULL</code>, chooses based on the model type (&quot;F&quot; for linear models).
This argument is passed to <code>anova</code>.</p>
</td></tr>
<tr><td><code id="weights_tests_+3A_sims">sims</code></td>
<td>
<p>The number of bootstrap simulations to use in estimating the
variance of the residual correlation. Default is 1000, but for publications
or when computing power/time is sufficient, a higher number is better.</p>
</td></tr>
<tr><td><code id="weights_tests_+3A_digits">digits</code></td>
<td>
<p>An integer specifying the number of digits past the decimal to
report in the output. Default is 3. You can change the default number of
digits for all jtools functions with
<code>options("jtools-digits" = digits)</code> where digits is the desired number.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a wrapper for the two tests implemented in this package that
test whether your regression model is correctly specified. The first is
<code><a href="#topic+wgttest">wgttest</a></code>, an R adaptation of the Stata macro of the same name.
This test can otherwise be referred to as the DuMouchel-Duncan test. The
other test is the Pfeffermann-Sverchkov test, which can be accessed directly
with <code><a href="#topic+pf_sv_test">pf_sv_test</a></code>.
</p>
<p>For more details on each, visit the documentation on the respective functions.
This function just runs each of them for you.
</p>


<h3>References</h3>

<p>DuMouchel, W. H. &amp; Duncan, D.J. (1983). Using sample survey weights in
multiple regression analyses of stratified samples. <em>Journal of the
American Statistical Association</em>, <em>78</em>. 535-543.
</p>
<p>Nordberg, L. (1989). Generalized linear modeling of sample survey data.
<em>Journal of Official Statistics; Stockholm</em>, <em>5</em>, 223-239.
</p>
<p>Pfeffermann, D., &amp; Sverchkov, M. (1999). Parametric and semi-parametric
estimation of regression models fitted to survey data.
<em>Sankhya: The Indian Journal of Statistics</em>, <em>61</em>. 166-186.
</p>


<h3>See Also</h3>

<p>Other survey tools: 
<code><a href="#topic+pf_sv_test">pf_sv_test</a>()</code>,
<code><a href="#topic+svycor">svycor</a>()</code>,
<code><a href="#topic+svysd">svysd</a>()</code>,
<code><a href="#topic+wgttest">wgttest</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Note: This is a contrived example to show how the function works,
# not a case with actual sammpling weights from a survey vendor
if (requireNamespace("boot")) {
  states &lt;- as.data.frame(state.x77)
  set.seed(100)
  states$wts &lt;- runif(50, 0, 3)
  fit &lt;- lm(Murder ~ Illiteracy + Frost, data = states)
  weights_tests(model = fit, data = states, weights = wts, sims = 100)
}

</code></pre>

<hr>
<h2 id='wgttest'>Test whether sampling weights are needed</h2><span id='topic+wgttest'></span>

<h3>Description</h3>

<p>Use the DuMouchel-Duncan (1983) test to assess the need for sampling weights
in your linear regression analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wgttest(
  model,
  weights,
  data = NULL,
  model_output = FALSE,
  test = NULL,
  digits = getOption("jtools-digits", default = 3)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wgttest_+3A_model">model</code></td>
<td>
<p>The unweighted linear model (must be <code>lm</code>,
<code>glm</code>, see details for other types) you want to check.</p>
</td></tr>
<tr><td><code id="wgttest_+3A_weights">weights</code></td>
<td>
<p>The name of the weights column in <code>model</code>'s data frame
or a vector of weights equal in length to the number of observations
included in <code>model</code>.</p>
</td></tr>
<tr><td><code id="wgttest_+3A_data">data</code></td>
<td>
<p>The data frame with the data fed to the fitted model and the
weights</p>
</td></tr>
<tr><td><code id="wgttest_+3A_model_output">model_output</code></td>
<td>
<p>Should a summary of the model with weights as predictor
be printed? Default is FALSE since the output can be very long for
complex models.</p>
</td></tr>
<tr><td><code id="wgttest_+3A_test">test</code></td>
<td>
<p>Which type of test should be used in the ANOVA? The default,
<code>NULL</code>, chooses based on the model type (&quot;F&quot; for linear models).
This argument is passed to <code>anova</code>.</p>
</td></tr>
<tr><td><code id="wgttest_+3A_digits">digits</code></td>
<td>
<p>An integer specifying the number of digits past the decimal to
report in the output. Default is 3. You can change the default number of
digits for all jtools functions with
<code>options("jtools-digits" = digits)</code> where digits is the desired number.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is designed to be similar to the <code>wgttest</code> macro for Stata
(<a href="http://fmwww.bc.edu/repec/bocode/w/wgttest.html">http://fmwww.bc.edu/repec/bocode/w/wgttest.html</a>). This method,
advocated for by DuMouchel and Duncan (1983), is fairly straightforward. To
decide whether weights are needed, the weights are added to the linear model
as a predictor and interaction with each other predictor. Then, an omnibus
test of significance is performed to compare the weights-added model to the
original; if insignificant, weights are not significantly related to the
result and you can use the more efficient estimation from unweighted OLS.
</p>
<p>It can be helpful to look at the created model using
<code>model_output = TRUE</code>
to see which variables might be the ones affected by inclusion of weights.
</p>
<p>This test can support most GLMs in addition to LMs, a use validated by
Nordberg (1989). This, to my knowledge, is different from the Stata macro.
It does not work for mixed models (e.g., <code>lmer</code> or <code>lme</code>) though
it could plausibly be
implemented. However, there is no scholarly consensus how to properly
incorporate weights into mixed models. There are other types of models that
may work, but have not been tested. The function is designed to be
compatible with as many model types as possible, but the user should be
careful to make sure s/he understands whether this type of test is
appropriate for the model being considered. DuMouchel and Duncan (1983) were
only thinking about linear regression when the test was conceived.
Nordberg (1989) validated its use with generalized linear models, but to
this author's knowledge it has not been tested with other model types.
</p>


<h3>References</h3>

<p>DuMouchel, W. H. &amp; Duncan, D.J. (1983). Using sample survey weights in
multiple regression analyses of stratified samples. <em>Journal of the
American Statistical Association</em>, <em>78</em>. 535-543.
</p>
<p>Nordberg, L. (1989). Generalized linear modeling of sample survey data.
<em>Journal of Official Statistics; Stockholm</em>, <em>5</em>, 223239.
</p>
<p>Winship, C. &amp; Radbill, L. (1994). Sampling weights and regression
analysis. <em>Sociological Methods and Research</em>, <em>23</em>, 230-257.
</p>


<h3>See Also</h3>

<p>Other survey tools: 
<code><a href="#topic+pf_sv_test">pf_sv_test</a>()</code>,
<code><a href="#topic+svycor">svycor</a>()</code>,
<code><a href="#topic+svysd">svysd</a>()</code>,
<code><a href="#topic+weights_tests">weights_tests</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># First, let's create some fake sampling weights
wts &lt;- runif(50, 0, 5)
# Create model
fit &lt;- lm(Income ~ Frost + Illiteracy + Murder,
          data = as.data.frame(state.x77))
# See if the weights change the model
wgttest(fit, weights = wts)

# With a GLM
wts &lt;- runif(100, 0, 2)
x &lt;- rnorm(100)
y &lt;- rbinom(100, 1, .5)
fit &lt;- glm(y ~ x, family = binomial)
wgttest(fit, wts)
## Can specify test manually
wgttest(fit, weights = wts, test = "Rao")

# Quasi family is treated differently than likelihood-based
## Dobson (1990) Page 93: Randomized Controlled Trial (plus some extra values):
counts &lt;- c(18,17,15,20,10,20,25,13,12,18,17,15,20,10,20,25,13,12)
outcome &lt;- gl(3,1,18)
treatment &lt;- gl(3,6)
glm.D93 &lt;- glm(counts ~ outcome + treatment, family = quasipoisson)
wts &lt;- runif(18, 0, 3)
wgttest(glm.D93, weights = wts)

</code></pre>

<hr>
<h2 id='wrap_str'><code>cat</code>, <code>message</code>, <code>warning</code>, and <code>stop</code> wrapped to fit the console's
width.</h2><span id='topic+wrap_str'></span><span id='topic+cat_wrap'></span><span id='topic+warn_wrap'></span><span id='topic+stop_wrap'></span><span id='topic+msg_wrap'></span>

<h3>Description</h3>

<p>These are convenience functions that format printed output to
fit the width of the user's console.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wrap_str(..., sep = "")

cat_wrap(..., brk = "")

warn_wrap(..., brk = "\n", class = NULL, call. = FALSE)

stop_wrap(
  ...,
  brk = "\n",
  trace = rlang::trace_back(bottom = rlang::caller_env()),
  class = NULL,
  call = rlang::caller_env(),
  call. = FALSE
)

msg_wrap(..., class = NULL, brk = "\n")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wrap_str_+3A_...">...</code></td>
<td>
<p>Objects to print. For <code>stop_wrap()</code>, <code>warn_wrap()</code>, and
<code>msg_wrap()</code>, any named objects are instead diverted to the <code>...</code> argument
of <code><a href="rlang.html#topic+abort">rlang::abort()</a></code>, <code><a href="rlang.html#topic+abort">rlang::warn()</a></code>, and <code><a href="rlang.html#topic+abort">rlang::inform()</a></code>,
respectively.</p>
</td></tr>
<tr><td><code id="wrap_str_+3A_sep">sep</code></td>
<td>
<p>Separator between <code>...</code>, Default: &rdquo;</p>
</td></tr>
<tr><td><code id="wrap_str_+3A_brk">brk</code></td>
<td>
<p>What should the last character of the message/warning/error be?
Default is <code>"\n"</code>, meaning the console output ends with a new line.</p>
</td></tr>
<tr><td><code id="wrap_str_+3A_class">class</code></td>
<td>
<p>Subclass of the condition.</p>
</td></tr>
<tr><td><code id="wrap_str_+3A_call.">call.</code></td>
<td>
<p>Here for legacy reasons. It is ignored.</p>
</td></tr>
<tr><td><code id="wrap_str_+3A_trace">trace</code></td>
<td>
<p>A <code>trace</code> object created by <code><a href="rlang.html#topic+trace_back">trace_back()</a></code>.</p>
</td></tr>
<tr><td><code id="wrap_str_+3A_call">call</code></td>
<td>
<p>The actual calling environment to report in the error message.
By default, <code>rlang::caller_env()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The point of these functions is to allow you to print
output/messages/warnings/errors to the console without having to figure out
where to place newline characters. These functions get the width of the
console from the <code>"width"</code> option, which in most editors adjusts dynamically
as you resize.
</p>
<p>So instead of writing a warning like this:
</p>
<div class="sourceCode"><pre>warning("I have to give you this very important message that may be too\n",
        "wide for your screen")
</pre></div>
<p>You can do it like this:
</p>
<div class="sourceCode"><pre>warn_wrap("I have to give you this very important message that may be
          too wide for your screen")
</pre></div>
<p>And the function will automatically insert line breaks to fit the console.
As a note, it will also ignore any newlines you insert. This means you can
make your own fit your editor's screen and indent in the middle of a string
without that formatting being carried over into the output.
</p>

<hr>
<h2 id='wtd.sd'>Weighted standard deviation calculation</h2><span id='topic+wtd.sd'></span>

<h3>Description</h3>

<p>This function calculates standard deviations with weights and
is a counterpart to the built-in <code>weighted.mean</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wtd.sd(x, weights)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wtd.sd_+3A_x">x</code></td>
<td>
<p>A vector of values for which you want the standard deviation</p>
</td></tr>
<tr><td><code id="wtd.sd_+3A_weights">weights</code></td>
<td>
<p>A vector of weights equal in length to <code>x</code></p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
