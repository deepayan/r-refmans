<!DOCTYPE html><html><head><title>Help for package Ravages</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Ravages}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#adjustedCADD.annotation'>
<p>SNVs and Indels annotation with adjusted CADD scores</p></a></li>
<li><a href='#adjustedCADD.annotation.indels'>
<p>Indels annotation with adjusted CADD scores</p></a></li>
<li><a href='#adjustedCADD.annotation.SNVs'>
<p>SNVs annotation with adjusted CADD scores</p></a></li>
<li><a href='#bed.matrix.split.genomic.region'><p> Bed matrix for variants associated to multiple genomic regions</p></a></li>
<li><a href='#burden'>
<p>Linear, logistic or multinomial regression on a genetic score</p></a></li>
<li><a href='#burden.continuous'>
<p>Linear regression on a genetic score</p></a></li>
<li><a href='#burden.continuous.subscores'>
<p>Linear regression on a multiple genetic scores within a genomic region</p></a></li>
<li><a href='#burden.mlogit'>
<p>Logistic or multinomial regression on a genetic score</p></a></li>
<li><a href='#burden.mlogit.subscores'>
<p>Logistic or multinomial regression on a multiple genetic scores within a genomic region</p></a></li>
<li><a href='#burden.subscores'>
<p>Linear, logistic or multinomial regression on a multiple genetic scores within a genomic region</p></a></li>
<li><a href='#burden.weighted.matrix'><p> Score matrix for burden tests</p></a></li>
<li><a href='#CAST'><p> Cohort Allelic Sum Test</p></a></li>
<li><a href='#filter.adjustedCADD'>
<p>Variant filtering based on frequency and median adjusted CADD by CADD regions</p></a></li>
<li><a href='#filter.rare.variants'>
<p>Rare variants filtering</p></a></li>
<li><a href='#genes.positions'><p>Genes positions</p></a></li>
<li><a href='#genotypic.freq'>
<p>Genotypic frequencies calculation for data simulations</p></a></li>
<li><a href='#GnomADgenes'><p>GnomADgenes dataset</p></a></li>
<li><a href='#GRR.matrix'>
<p>GRR matrix for genetic data simulation</p></a></li>
<li><a href='#Jaccard'>
<p>Jaccard index</p></a></li>
<li><a href='#Kryukov'><p>Kryukov data set</p></a></li>
<li><a href='#LCT.haplotypes'><p>LCT haplotypes data set</p></a></li>
<li><a href='#LCT.matrix'><p>LCT genotypes matrix</p></a></li>
<li><a href='#multinomial.asso.freq'>
<p>Single variant association test with categorical phenotype</p></a></li>
<li><a href='#NullObject.parameters'><p> Null Model for SKAT and burden tests</p></a></li>
<li><a href='#RAVA.FIRST'>
<p>RAVA-FIRST: RAre Variant Association using Functionally-InfoRmed STeps</p></a></li>
<li><a href='#rbm.GRR'>
<p>Simulation of genetic data using GRR values</p></a></li>
<li><a href='#rbm.GRR.power'>
<p>Power of RVAT based on simulations and theoretical calculations (CAST) with GRR</p></a></li>
<li><a href='#rbm.haplos.freqs'>
<p>Simulation of genetic data based on haplotypic frequencies</p></a></li>
<li><a href='#rbm.haplos.power'>
<p>Power of RVAT based on simulations with haplotypes</p></a></li>
<li><a href='#rbm.haplos.thresholds'>
<p>Simulation of genetic data based on haplotypes and a libaility model</p></a></li>
<li><a href='#set.CADDregions'><p> Variants annotation based on 'CADD regions' and genomic categories</p></a></li>
<li><a href='#set.genomic.region'><p> Variants annotation based on gene positions</p></a></li>
<li><a href='#set.genomic.region.subregion'><p> Variants annotation based on regions and subregions positions</p></a></li>
<li><a href='#SKAT'><p> SKAT test</p></a></li>
<li><a href='#SKAT.bootstrap'><p> Multi group SKAT test using bootstrap sampling</p></a></li>
<li><a href='#SKAT.continuous'><p> Multi group SKAT test using Liu et al. approximation</p></a></li>
<li><a href='#SKAT.permutations'><p> Multi group SKAT test using bootstrap sampling</p></a></li>
<li><a href='#SKAT.theoretical'><p> Multi group SKAT test using Liu et al. approximation</p></a></li>
<li><a href='#subregions.LCT'><p>Exemple of functional categories</p></a></li>
<li><a href='#WSS'><p> WSS genetic score</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Rare Variant Analysis and Genetic Simulations</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-03-28</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Author:</td>
<td>Ozvan Bocher and Herv√© Perdry</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ozvan Bocher &lt;bocherozvan@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Rare variant association tests: burden tests (Bocher et al. 2019 &lt;<a href="https://doi.org/10.1002%2Fgepi.22210">doi:10.1002/gepi.22210</a>&gt;) and the Sequence Kernel Association Test (Bocher et al. 2021 &lt;<a href="https://doi.org/10.1038%2Fs41431-020-00792-8">doi:10.1038/s41431-020-00792-8</a>&gt;) in the whole genome; and genetic simulations.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppParallel, RcppEigen, gaston, BH</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), Rcpp, RcppParallel, methods, gaston, mlogit (&ge;
1.1-0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Formula, dfidx, parallel, bedr, curl, data.table</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyDataCompression:</td>
<td>xz</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-03-28 11:56:06 UTC; obocher</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-03-28 13:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='adjustedCADD.annotation'>
SNVs and Indels annotation with adjusted CADD scores
</h2><span id='topic+adjustedCADD.annotation'></span>

<h3>Description</h3>

<p>Annotate SNVs and Indels with the adjusted CADD scores (CADD PHRED scores for coding, regulatory and intergenic regions)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjustedCADD.annotation(x, SNVs.scores = NULL, indels.scores = NULL,
			cores = 10, verbose = T, path.data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adjustedCADD.annotation_+3A_x">x</code></td>
<td>
<p> A bed.matrix annotated with CADD regions using <code>set.CADDregions</code> </p>
</td></tr>
<tr><td><code id="adjustedCADD.annotation_+3A_snvs.scores">SNVs.scores</code></td>
<td>
<p> A dataframe containing the ADJUSTED CADD scores of the SNVs (Optional, useful to gain in computation time if the adjusted CADD scores of variants in the study are available)</p>
</td></tr>
<tr><td><code id="adjustedCADD.annotation_+3A_indels.scores">indels.scores</code></td>
<td>
<p> A dataframe containing the CADD PHREDv1.4 scores of the indels - Compulsory if indels are present in <code>x</code></p>
</td></tr>
<tr><td><code id="adjustedCADD.annotation_+3A_cores">cores</code></td>
<td>
<p> How many cores to use, set at 10 by default</p>
</td></tr>
<tr><td><code id="adjustedCADD.annotation_+3A_verbose">verbose</code></td>
<td>
<p> Whether to display information about the function actions </p>
</td></tr>
<tr><td><code id="adjustedCADD.annotation_+3A_path.data">path.data</code></td>
<td>
<p> The repository where data for RAVA-FIRST are or will be downloaded from https://lysine.univ-brest.fr/RAVA-FIRST/</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calls <code>adjustedCADD.annotation.SNVs</code> and <code>adjustedCADD.annotation.indels</code>. See the help of those two functions for more details.  
</p>


<h3>Value</h3>

<p>The bed matrix x with adjusted CADD scores in <code>adjCADD</code>.
</p>


<h3>Source</h3>

<p>https://lysine.univ-brest.fr/RAVA-FIRST/</p>


<h3>See Also</h3>

<p><code><a href="#topic+adjustedCADD.annotation.SNVs">adjustedCADD.annotation.SNVs</a>, <a href="#topic+adjustedCADD.annotation.indels">adjustedCADD.annotation.indels</a>, <a href="#topic+RAVA.FIRST">RAVA.FIRST</a></code>, <code><a href="#topic+filter.adjustedCADD">filter.adjustedCADD</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Import 1000Genome data from region around LCT gene
#x &lt;- as.bed.matrix(LCT.gen, LCT.fam, LCT.bim)

#Annotate variants with adjusted CADD score
#x &lt;- adjustedCADD.annotation(x)
</code></pre>

<hr>
<h2 id='adjustedCADD.annotation.indels'>
Indels annotation with adjusted CADD scores
</h2><span id='topic+adjustedCADD.annotation.indels'></span>

<h3>Description</h3>

<p>Annotate Indels with the adjusted CADD scores (CADD PHRED scores for coding, regulatory and intergenic regions)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjustedCADD.annotation.indels(x, variant.scores = NULL, 
			       cores = 10, verbose = T, path.data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adjustedCADD.annotation.indels_+3A_x">x</code></td>
<td>
<p> A bed.matrix annotated with CADD regions using <code>set.CADDregions</code> </p>
</td></tr>
<tr><td><code id="adjustedCADD.annotation.indels_+3A_variant.scores">variant.scores</code></td>
<td>
<p> A dataframe containing the CADD PHREDv1.4 scores of the indels</p>
</td></tr>
<tr><td><code id="adjustedCADD.annotation.indels_+3A_cores">cores</code></td>
<td>
<p> How many cores to use, set at 10 by default</p>
</td></tr>
<tr><td><code id="adjustedCADD.annotation.indels_+3A_verbose">verbose</code></td>
<td>
<p> Whether to display information about the function actions </p>
</td></tr>
<tr><td><code id="adjustedCADD.annotation.indels_+3A_path.data">path.data</code></td>
<td>
<p> The repository where data for RAVA-FIRST are or will be downloaded from https://lysine.univ-brest.fr/RAVA-FIRST/</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Indels are directly annotated with the adjusted CADD scores in the function using the file &quot;AdjustedCADD_v1.4_202204_indels.tsv.gz&quot; downloaded from https://lysine.univ-brest.fr/RAVA-FIRST/ in the repository of the package Ravages.  
</p>
<p>The adjusted CADD scores in &quot;AdjustedCADD_v1.4_202204_indels.tsv.gz&quot; have been computed using a set of 48M indels already annotated in the CADD website. If indels not present in this set are to be annotated, they will be given the same adjusted score as the indel with the nearest PHRED score v1.4 provided in <code>variant.scores</code> which should contain the chromosome ('chr'), position ('pos'), reference allele ('A1'), alternative allele ('A2') and PHRED CADD scores v1.4 ('PHRED_1.4').  
</p>
<p>Those adjusted scores are used in the <code>RAVA.FIRST()</code> pipeline to filter rare variants.  
</p>
<p>As this function can take time when a large number of SNVs are present, it is recommended to use this function chromosome by chromosome for large datasets or to fitler the bed matrix before the annotation.
</p>


<h3>Value</h3>

<p>The bed matrix x with adjusted CADD scores in <code>adjCADD</code>.
</p>


<h3>Source</h3>

<p>https://lysine.univ-brest.fr/RAVA-FIRST/</p>


<h3>See Also</h3>

<p><code><a href="#topic+adjustedCADD.annotation">adjustedCADD.annotation</a>, <a href="#topic+adjustedCADD.annotation.SNVs">adjustedCADD.annotation.SNVs</a>, <a href="#topic+RAVA.FIRST">RAVA.FIRST</a></code>, <code><a href="#topic+filter.adjustedCADD">filter.adjustedCADD</a></code> 
</p>

<hr>
<h2 id='adjustedCADD.annotation.SNVs'>
SNVs annotation with adjusted CADD scores
</h2><span id='topic+adjustedCADD.annotation.SNVs'></span>

<h3>Description</h3>

<p>Annotate SNVs with the adjusted CADD scores (CADD PHRED scores for coding, regulatory and intergenic regions)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjustedCADD.annotation.SNVs(x, variant.scores = NULL, 
			     cores = 10, verbose = T, path.data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adjustedCADD.annotation.SNVs_+3A_x">x</code></td>
<td>
<p> A bed.matrix annotated with CADD regions using <code>set.CADDregions</code> </p>
</td></tr>
<tr><td><code id="adjustedCADD.annotation.SNVs_+3A_variant.scores">variant.scores</code></td>
<td>
<p> A dataframe containing the ADJUSTED CADD scores of the SNVs (Optional, useful to gain in computation time if the adjusted CADD scores of variants in the study are available)</p>
</td></tr>
<tr><td><code id="adjustedCADD.annotation.SNVs_+3A_cores">cores</code></td>
<td>
<p> How many cores to use, set at 10 by default</p>
</td></tr>
<tr><td><code id="adjustedCADD.annotation.SNVs_+3A_verbose">verbose</code></td>
<td>
<p> Whether to display information about the function actions </p>
</td></tr>
<tr><td><code id="adjustedCADD.annotation.SNVs_+3A_path.data">path.data</code></td>
<td>
<p> The repository where data for RAVA-FIRST are or will be downloaded from https://lysine.univ-brest.fr/RAVA-FIRST/</p>
</td></tr>
</table>


<h3>Details</h3>

<p>SNVs are directly annotated with the adjusted CADD scores in the function using the file &quot;AdjustedCADD_v1.4_202108.tsv.gz&quot; downloaded from https://lysine.univ-brest.fr/RAVA-FIRST/ in the repository of the package Ravages or the scores of variants can be provided to <code>variant.scores</code> to gain in computation time (this file should contain 5 columns: the chromosome ('chr'), position ('pos'), reference allele ('A1'), alternative allele ('A2') and adjusted CADD scores ('adjCADD').  
</p>
<p>Those adjusted scores are used in the <code>RAVA.FIRST()</code> pipeline to filter rare variants.  
</p>
<p>As this function can take time when a large number of SNVs are present, it is recommended to use this function chromosome by chromosome for large datasets or to fitler the bed matrix before the annotation.
</p>


<h3>Value</h3>

<p>The bed matrix x with adjusted CADD scores in <code>adjCADD</code>.
</p>


<h3>Source</h3>

<p>https://lysine.univ-brest.fr/RAVA-FIRST/</p>


<h3>See Also</h3>

<p><code><a href="#topic+adjustedCADD.annotation">adjustedCADD.annotation</a>, <a href="#topic+adjustedCADD.annotation.indels">adjustedCADD.annotation.indels</a>, <a href="#topic+RAVA.FIRST">RAVA.FIRST</a></code>, <code><a href="#topic+filter.adjustedCADD">filter.adjustedCADD</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Import 1000Genome data from region around LCT gene
#x &lt;- as.bed.matrix(LCT.gen, LCT.fam, LCT.bim)

#Annotate variants with adjusted CADD score
#x &lt;- adjustedCADD.annotation.SNVs(x)
</code></pre>

<hr>
<h2 id='bed.matrix.split.genomic.region'> Bed matrix for variants associated to multiple genomic regions</h2><span id='topic+bed.matrix.split.genomic.region'></span>

<h3>Description</h3>

<p>Creates a new bed matrix with variants associated to multiple genomic regions being duplicated
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bed.matrix.split.genomic.region(x, changeID=TRUE, genomic.region=NULL, 
                                split.pattern=",")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bed.matrix.split.genomic.region_+3A_x">x</code></td>
<td>
<p> A bed.matrix </p>
</td></tr>
<tr><td><code id="bed.matrix.split.genomic.region_+3A_changeid">changeID</code></td>
<td>
<p> TRUE/FALSE: whether to change the variants ID by including the gene name</p>
</td></tr>
<tr><td><code id="bed.matrix.split.genomic.region_+3A_genomic.region">genomic.region</code></td>
<td>
<p> A vector containing the genomic region of each variant </p>
</td></tr>
<tr><td><code id="bed.matrix.split.genomic.region_+3A_split.pattern">split.pattern</code></td>
<td>
<p> The character separating the genomic regions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>changeID=TRUE</code>, variants will have new IDs being CHR:POS:A1:A2:genomic.region.  
</p>
<p>The genomic region(s) associated to each varaint should be in <code>x@snps$genomic.region</code> or given as a vector to <code>genomic.region</code>. If both are present, <code>genomic.region</code> is used.
</p>


<h3>Value</h3>

<p>A bed matrix with variants assigned to multiple genomic regions being duplicated and the corresponding genomic regions separated and transformed into factors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Example bed matrix with 4 variants
  x.ex &lt;- as.bed.matrix(x=matrix(0, ncol=4, nrow=10), 
                       bim=data.frame(chr=1:4, id=paste("rs", 1:4, sep=""), dist = rep(0,4), 
                                      pos=c(150,150,200,250), A1=rep("A", 4), A2=rep("T", 4)))

#Example genes dataframe
  genes.ex &lt;- data.frame(Chr=c(1,1,3,4), Start=c(10,110,190,220), End=c(170,180,250,260), 
                         Gene_Name=factor(letters[1:4]))

#Attribute genomic regions
  x.ex &lt;- set.genomic.region(x.ex, regions = genes.ex)

#Split genomic regions
  x.ex.split &lt;- bed.matrix.split.genomic.region(x.ex, split.pattern = ",")
</code></pre>

<hr>
<h2 id='burden'>
Linear, logistic or multinomial regression on a genetic score
</h2><span id='topic+burden'></span>

<h3>Description</h3>

<p>Performs burden tests on categorical or continuous phenotypes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>burden(x, NullObject, genomic.region = x@snps$genomic.region, burden,
       maf.threshold = 0.5, get.effect.size = FALSE, alpha = 0.05, cores = 10,
       verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="burden_+3A_x">x</code></td>
<td>
<p> A bed matrix, only needed if <code>burden="CAST"</code> or <code>burden="WSS"</code></p>
</td></tr>
<tr><td><code id="burden_+3A_nullobject">NullObject</code></td>
<td>
<p> A list returned from <code>NullObject.parameters</code> </p>
</td></tr>
<tr><td><code id="burden_+3A_genomic.region">genomic.region</code></td>
<td>
<p> A factor containing the genomic region of each SNP, <code>x@snps$genomic.region</code> by default, only needed if <code>burden</code>=&quot;CAST&quot; or <code>burden</code>=&quot;WSS&quot;</p>
</td></tr>
<tr><td><code id="burden_+3A_burden">burden</code></td>
<td>
<p>&quot;CAST&quot; or &quot;WSS&quot; to directly compute the CAST or the WSS genetic score, or a matrix with one row per individual and one column per <code>genomic.region</code> if another genetic score is wanted.</p>
</td></tr>
<tr><td><code id="burden_+3A_maf.threshold">maf.threshold</code></td>
<td>
<p> The MAF threshold to use for the definition of a rare variant in the CAST score. Set at 0.5 by default</p>
</td></tr>
<tr><td><code id="burden_+3A_get.effect.size">get.effect.size</code></td>
<td>
<p> TRUE/FALSE: whether to return effect sizes of the tested <code>genomic.region</code> (OR for categorical phenotypes, betas for continuous phenotypes) </p>
</td></tr>
<tr><td><code id="burden_+3A_alpha">alpha</code></td>
<td>
<p> The alpha threshold to use for the OR confidence interval</p>
</td></tr>
<tr><td><code id="burden_+3A_cores">cores</code></td>
<td>
<p> How many cores to use, set at 10 by default.</p>
</td></tr>
<tr><td><code id="burden_+3A_verbose">verbose</code></td>
<td>
<p> Whether to display information about the function actions </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will return results from the regression of the phenotype on the genetic score for each genomic region.
</p>
<p>If only two groups of individuals are present, a classical logistic regression is performed.
If more than two groups of individuals are present, a non-ordinal multinomial regression is performed,
comparing each group of individuals to the reference group indicated by the argument <code>ref.level</code> in <code>NullObject.parameters</code>.
The choice of the reference group won't affect the p-values, but only the Odds Ratios.
In both types of regression, the p-value is estimated using the Likelihood Ratio test and the function <code>burden.mlogit</code>.  
</p>
<p>If the phenotype is continuous, a linear regression is performed using the function <code>burden.continuous</code>.  
</p>
<p>The type of phenotype is determined from <code>NullObject$pheno.type</code>.  
</p>
<p>If another genetic score than CAST or WSS is wanted, a matrix with one row per individual and one column per <code>genomic.region</code>
containing this score should be given to <code>burden</code>. In this situation, no bed matrix <code>x</code> is needed.
</p>


<h3>Value</h3>

<p>A dataframe with one row per genomic region and at least two columns:
</p>
<table>
<tr><td><code>p.value</code></td>
<td>
<p> The p.value of the regression</p>
</td></tr>
<tr><td><code>is.err</code></td>
<td>
<p> 0/1: whether there was a convergence problem with the regression</p>
</td></tr>
</table>
<p>If <code>NullObject$pheno.type = "categorical"</code> and <code>get.OR.value=TRUE</code>, additional columns are present:
</p>
<table>
<tr><td><code>OR/beta</code></td>
<td>
<p> The OR/beta value(s) associated to the regression. For categorical phenotypes, if there are more than two groups, there will be one OR value per group compared to the reference group</p>
</td></tr>
<tr><td><code>l.lower</code></td>
<td>
<p> The lower bound of the confidence interval of each OR/beta</p>
</td></tr>
<tr><td><code>l.upper</code></td>
<td>
<p> The upper bound of the confidence interval of each OR/beta</p>
</td></tr>
</table>


<h3>References</h3>

<p> Bocher O, et al. DOI: 10.1002/gepi.22210. <em>Rare variant association testing for multicategory phenotype.</em> Genet.Epidemiol. 2019;43:646‚Äì656.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+NullObject.parameters">NullObject.parameters</a></code>, <code><a href="#topic+burden.continuous">burden.continuous</a></code>, <code><a href="#topic+burden.mlogit">burden.mlogit</a></code>,  <code><a href="#topic+CAST">CAST</a></code>, <code><a href="#topic+WSS">WSS</a></code>, <code><a href="#topic+burden.weighted.matrix">burden.weighted.matrix</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Import data in a bed matrix
x &lt;- as.bed.matrix(x=LCT.matrix.bed, fam=LCT.matrix.fam, bim=LCT.snps)

#Add population
x@ped[,c("pop", "superpop")] &lt;- LCT.matrix.pop1000G[,c("population", "super.population")]

#Select EUR superpopulation
x &lt;- select.inds(x, superpop=="EUR")
x@ped$pop &lt;- droplevels(x@ped$pop)

#Group variants within known genes
x &lt;- set.genomic.region(x)

#Filter of rare variants: only non-monomorphic variants with
#a MAF lower than 2.5%
#keeping only genomic regions with at least 10 SNPs
x1 &lt;- filter.rare.variants(x, filter = "whole", maf.threshold = 0.025, min.nb.snps = 10)

#run null model, using the 1000Genome population as "outcome"
x1.H0 &lt;- NullObject.parameters(pheno = x1@ped$pop, ref.level = "CEU",
                               RVAT = "burden", pheno.type = "categorical")

#run burden test WSS
burden(x1, NullObject = x1.H0, burden = "WSS", get.effect.size=TRUE, cores = 1)


</code></pre>

<hr>
<h2 id='burden.continuous'>
Linear regression on a genetic score
</h2><span id='topic+burden.continuous'></span>

<h3>Description</h3>

<p>Performs a linear regression on a genetic score
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  burden.continuous(x, NullObject, genomic.region = x@snps$genomic.region, 
                    burden, maf.threshold = 0.5, get.effect.size = F, 
                    alpha = 0.05, cores = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="burden.continuous_+3A_x">x</code></td>
<td>
<p> A bed matrix, only needed if <code>burden="CAST"</code> or <code>burden="WSS"</code></p>
</td></tr>
<tr><td><code id="burden.continuous_+3A_nullobject">NullObject</code></td>
<td>
<p> A list returned from <code>NullObject.parameters</code> </p>
</td></tr>
<tr><td><code id="burden.continuous_+3A_genomic.region">genomic.region</code></td>
<td>
<p> A factor containing the genomic region of each SNP, <code>x@snps$genomic.region</code> by default, only needed if <code>burden</code>=&quot;CAST&quot; or <code>burden</code>=&quot;WSS&quot;</p>
</td></tr>
<tr><td><code id="burden.continuous_+3A_burden">burden</code></td>
<td>
<p>&quot;CAST&quot; or &quot;WSS&quot; to directly compute the CAST or the WSS genetic score, or a matrix with one row per individual and one column per <code>genomic.region</code> if another genetic score is wanted.</p>
</td></tr>
<tr><td><code id="burden.continuous_+3A_maf.threshold">maf.threshold</code></td>
<td>
<p> The MAF threshold to use for the definition of a rare variant in the CAST score. Set at 0.5 by default</p>
</td></tr>
<tr><td><code id="burden.continuous_+3A_get.effect.size">get.effect.size</code></td>
<td>
<p> TRUE/FALSE: whether to return the beta value</p>
</td></tr>
<tr><td><code id="burden.continuous_+3A_alpha">alpha</code></td>
<td>
<p> The alpha threshold to use for the OR confidence interval</p>
</td></tr>
<tr><td><code id="burden.continuous_+3A_cores">cores</code></td>
<td>
<p> How many cores to use for moments computation, set at 10 by default </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will return results from the regression of the continuous phenotype on the genetic score for each genomic region.
</p>
<p>If another genetic score than CAST or WSS is wanted, a matrix with one row per individual and one column per <code>genomic.region</code>
containing this score should be given to <code>burden</code>. In this situation, no bed matrix <code>x</code> is needed.
</p>


<h3>Value</h3>

<p>A dataframe with one row per genomic region and at least two columns:
</p>
<table>
<tr><td><code>p.value</code></td>
<td>
<p> The p.value of the regression</p>
</td></tr>
<tr><td><code>is.err</code></td>
<td>
<p> 0/1: whether there was a convergence problem with the regression</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p> The beta coefficient associated to the tested genomic region</p>
</td></tr>
<tr><td><code>l.lower</code></td>
<td>
<p> The lower bound of the confidence interval of beta</p>
</td></tr>
<tr><td><code>l.upper</code></td>
<td>
<p> The upper bound of the confidence interval of beta</p>
</td></tr>
</table>


<h3>See Also</h3>

 <p><code><a href="#topic+CAST">CAST</a></code>, <code><a href="#topic+WSS">WSS</a></code>, <code><a href="#topic+burden.weighted.matrix">burden.weighted.matrix</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Import data in a bed matrix
x &lt;- as.bed.matrix(x=LCT.matrix.bed, fam=LCT.matrix.fam, bim=LCT.snps)

#Add population
x@ped[,c("pop", "superpop")] &lt;- LCT.matrix.pop1000G[,c("population", "super.population")]

#Select EUR superpopulation
x &lt;- select.inds(x, superpop=="EUR")
x@ped$pop &lt;- droplevels(x@ped$pop)

#Group variants within known genes
x &lt;- set.genomic.region(x)

#Filter of rare variants: only non-monomorphic variants with
#a MAF lower than 2.5%
#keeping only genomic regions with at least 10 SNPs
x1 &lt;- filter.rare.variants(x, filter = "whole", maf.threshold = 0.025, min.nb.snps = 10)

#run burden test WSS, using a random continuous variable as phenotype
x1@ped$pheno &lt;- rnorm(nrow(x1))
#Null model
x1.H0 &lt;- NullObject.parameters(pheno = x1@ped$pheno, 
                               RVAT = "burden", pheno.type = "continuous")
#Get the beta value
burden.continuous(x1, NullObject = x1.H0, burden = "WSS", 
                  get.effect.size = TRUE, cores = 1)

</code></pre>

<hr>
<h2 id='burden.continuous.subscores'>
Linear regression on a multiple genetic scores within a genomic region
</h2><span id='topic+burden.continuous.subscores'></span>

<h3>Description</h3>

<p>Performs burden tests with subscores in the regression on continuous phenotypes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>burden.continuous.subscores(x, NullObject, genomic.region = x@snps$genomic.region, 
                            SubRegion = x@snps$SubRegion, burden.function = WSS, 
                            maf.threshold = 0.5, get.effect.size = FALSE, 
                            alpha = 0.05, cores = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="burden.continuous.subscores_+3A_x">x</code></td>
<td>
<p> A bed matrix, only needed if <code>burden="CAST"</code> or <code>burden="WSS"</code></p>
</td></tr>
<tr><td><code id="burden.continuous.subscores_+3A_nullobject">NullObject</code></td>
<td>
<p> A list returned from <code>NullObject.parameters</code> </p>
</td></tr>
<tr><td><code id="burden.continuous.subscores_+3A_genomic.region">genomic.region</code></td>
<td>
<p> A factor containing the genomic region of each SNP, <code>x@snps$genomic.region</code> by default, for example the CADD regions</p>
</td></tr>
<tr><td><code id="burden.continuous.subscores_+3A_subregion">SubRegion</code></td>
<td>
<p> A vector containing subregions within each <code>genomic.region</code>, <code>x@snps$SubRegion</code> by default, for example genomic categories</p>
</td></tr>
<tr><td><code id="burden.continuous.subscores_+3A_burden.function">burden.function</code></td>
<td>
<p>A function to compute the genetic score, <code>WSS</code> by default.</p>
</td></tr>
<tr><td><code id="burden.continuous.subscores_+3A_maf.threshold">maf.threshold</code></td>
<td>
<p> The MAF threshold to use for the definition of a rare variant in the CAST score. Set at 0.5 by default</p>
</td></tr>
<tr><td><code id="burden.continuous.subscores_+3A_get.effect.size">get.effect.size</code></td>
<td>
<p> TRUE/FALSE: whether to return effect sizes of the tested <code>genomic.region</code> (OR for categorical phenotypes, betas for continuous phenotypes) </p>
</td></tr>
<tr><td><code id="burden.continuous.subscores_+3A_alpha">alpha</code></td>
<td>
<p> The alpha threshold to use for the OR confidence interval</p>
</td></tr>
<tr><td><code id="burden.continuous.subscores_+3A_cores">cores</code></td>
<td>
<p> How many cores to use, set at 10 by default. Only needed if <code>NullObject$pheno.type = "categorical"</code> </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will return results from the regression of the phenotype on the genetic score(s) for each genomic region. Within each genomic region, a subscore will be computed for each SubRegion and one test will be performed for each genomic.region.
</p>


<h3>Value</h3>

<p>A dataframe with one row per genomic region and two columns:
</p>
<table>
<tr><td><code>p.value</code></td>
<td>
<p> The p.value of the regression</p>
</td></tr>
<tr><td><code>is.err</code></td>
<td>
<p> 0/1: whether there was a convergence problem with the regression</p>
</td></tr>
</table>
<p>If <code>get.effect.size=TRUE</code>, a list is returned with the previous dataframe in <code>$Asso</code> and with <code>effect</code>, a list containing matrices with three columns:
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p> The beta value(s) associated to the subscores in the regression</p>
</td></tr>
<tr><td><code>l.lower</code></td>
<td>
<p> The lower bound of the confidence interval of each beta</p>
</td></tr>
<tr><td><code>l.upper</code></td>
<td>
<p> The upper bound of the confidence interval of each beta</p>
</td></tr>
</table>


<h3>See Also</h3>

 <p><code><a href="#topic+NullObject.parameters">NullObject.parameters</a></code>, <code><a href="#topic+burden.subscores">burden.subscores</a></code>,  <code><a href="#topic+CAST">CAST</a></code>, <code><a href="#topic+WSS">WSS</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#Import data in a bed matrix
#x &lt;- as.bed.matrix(x=LCT.matrix.bed, fam=LCT.matrix.fam, bim=LCT.snps)

#Add population
#x@ped[,c("pop", "superpop")] &lt;- LCT.matrix.pop1000G[,c("population", "super.population")]

#Select EUR superpopulation
#x &lt;- select.inds(x, superpop=="EUR")
#x@ped$pop &lt;- droplevels(x@ped$pop)

#Group variants within CADD regions and genomic categories
#x &lt;- set.CADDregions(x)

#Filter of rare variants: only non-monomorphic variants with
#a MAF lower than 2.5%
#and with a adjusted CADD score greater than the median
#x1 &lt;- filter.adjustedCADD(x, filter = "whole", maf.threshold = 0.025)

#Simulation of a covariate + Sex as a covariate
#sex &lt;- x1@ped$sex
#set.seed(1) ; u &lt;- runif(nrow(x1))
#covar &lt;- cbind(sex, u)

#Null model with the covariate sex and a continuous phenotype
#x1.H0.covar &lt;- NullObject.parameters(pheno = x1@ped$pheno &lt;- rnorm(nrow(x1)),
#                                     RVAT = "burden", pheno.type = "continuous",
#                                     data = covar, formula = ~ sex)

#WSS test
#res.subscores &lt;-burden.continuous.subscores(x1, NullObject = x1.H0.covar, 
#                                            burden = WSS, get.effect.size=TRUE, cores = 1)
#res.subscores$Asso # p-values
#res.subscores$effect #beta values

</code></pre>

<hr>
<h2 id='burden.mlogit'>
Logistic or multinomial regression on a genetic score
</h2><span id='topic+burden.mlogit'></span>

<h3>Description</h3>

<p>Performs a logistical or a non-ordinal multinomial regression on a genetic score
</p>


<h3>Usage</h3>

<pre><code class='language-R'>burden.mlogit(x, NullObject, genomic.region = x@snps$genomic.region, burden,
              maf.threshold = 0.5, get.effect.size = FALSE, alpha = 0.05, cores = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="burden.mlogit_+3A_x">x</code></td>
<td>
<p> A bed matrix, only needed if <code>burden="CAST"</code> or <code>burden="WSS"</code></p>
</td></tr>
<tr><td><code id="burden.mlogit_+3A_nullobject">NullObject</code></td>
<td>
<p> A list returned from <code>NullObject.parameters</code> </p>
</td></tr>
<tr><td><code id="burden.mlogit_+3A_genomic.region">genomic.region</code></td>
<td>
<p> A factor containing the genomic region of each SNP, <code>x@snps$genomic.region</code> by default, only needed if <code>burden</code>=&quot;CAST&quot; or <code>burden</code>=&quot;WSS&quot;</p>
</td></tr>
<tr><td><code id="burden.mlogit_+3A_burden">burden</code></td>
<td>
<p>&quot;CAST&quot; or &quot;WSS&quot; to directly compute the CAST or the WSS genetic score; or a matrix with one row per individual and one column per <code>genomic.region</code> if another genetic score is wanted.</p>
</td></tr>
<tr><td><code id="burden.mlogit_+3A_maf.threshold">maf.threshold</code></td>
<td>
<p> The MAF threshold to use for the definition of a rare variant in the CAST score. Set at 0.5 by default</p>
</td></tr>
<tr><td><code id="burden.mlogit_+3A_get.effect.size">get.effect.size</code></td>
<td>
<p> TRUE/FALSE: whether to return OR values</p>
</td></tr>
<tr><td><code id="burden.mlogit_+3A_alpha">alpha</code></td>
<td>
<p> The alpha threshold to use for the OR confidence interval</p>
</td></tr>
<tr><td><code id="burden.mlogit_+3A_cores">cores</code></td>
<td>
<p> How many cores to use for moments computation, set at 10 by default </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will return results from the regression of the phenotype on the genetic score for each genomic region.
</p>
<p>If only two groups of individuals are present, a classical logistic regression is performed. 
If more than two groups of individuals are present, a non-ordinal multinomial regression is performed, 
comparing each group of individuals to the reference group indicated by the argument <code>ref.level</code> in <code>NullObject.parameters</code>. 
The choice of the reference group won't affect the p-values, but only the Odds Ratios.
In both types of regression, the p-value is estimated using the Likelihood Ratio test.
</p>
<p>If another genetic score than CAST or WSS is wanted, a matrix with one row per individual and one column per <code>genomic.region</code> 
containing this score should be given to <code>burden</code>. In this situation, no bed matrix <code>x</code> is needed.
</p>


<h3>Value</h3>

<p>A dataframe with one row per genomic region and at least two columns:
</p>
<table>
<tr><td><code>p.value</code></td>
<td>
<p> The p.value of the regression</p>
</td></tr>
<tr><td><code>is.err</code></td>
<td>
<p> 0/1: whether there was a convergence problem with the regression</p>
</td></tr>
</table>
<p>If <code>get.effect.size=TRUE</code>, additional columns are present:
</p>
<table>
<tr><td><code>OR</code></td>
<td>
<p> The OR value(s) associated to the regression. If there are more than two groups, there will be one OR value per group compared to the reference group</p>
</td></tr>
<tr><td><code>l.lower</code></td>
<td>
<p> The lower bound of the confidence interval of each OR</p>
</td></tr>
<tr><td><code>l.upper</code></td>
<td>
<p> The upper bound of the confidence interval of each OR</p>
</td></tr>
</table>


<h3>References</h3>

<p> Bocher O, et al. DOI: 10.1002/gepi.22210. <em>Rare variant associationtesting for multicategory phenotype.</em> Genet.Epidemiol. 2019;43:646‚Äì656.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+NullObject.parameters">NullObject.parameters</a></code>, <code><a href="#topic+CAST">CAST</a></code>, <code><a href="#topic+WSS">WSS</a></code>, <code><a href="#topic+burden.weighted.matrix">burden.weighted.matrix</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Import data in a bed matrix
x &lt;- as.bed.matrix(x=LCT.matrix.bed, fam=LCT.matrix.fam, bim=LCT.snps)

#Add population
x@ped[,c("pop", "superpop")] &lt;- LCT.matrix.pop1000G[,c("population", "super.population")]

#Select EUR superpopulation
x &lt;- select.inds(x, superpop=="EUR")
x@ped$pop &lt;- droplevels(x@ped$pop)

#Group variants within known genes
x &lt;- set.genomic.region(x)

#Filter of rare variants: only non-monomorphic variants with
#a MAF lower than 2.5%
#keeping only genomic regions with at least 200 SNP
x1 &lt;- filter.rare.variants(x, filter = "whole", maf.threshold = 0.025, min.nb.snps = 200)

#Simulation of a covariate + Sex as a covariate
sex &lt;- x1@ped$sex
set.seed(1) ; u &lt;- runif(nrow(x1))
covar &lt;- cbind(sex, u)
              
#run null model, using the 1000Genome population as "outcome"
#Null model with the covariate sex
x1.H0.covar &lt;- NullObject.parameters(pheno = x1@ped$pop, ref.level = "CEU", 
                                     RVAT = "burden", pheno.type = "categorical",
                                     data = covar, formula = ~ sex)
#WSS test
burden.mlogit(x1, NullObject = x1.H0.covar, burden = "WSS", get.effect.size=TRUE, cores = 1)

</code></pre>

<hr>
<h2 id='burden.mlogit.subscores'>
Logistic or multinomial regression on a multiple genetic scores within a genomic region
</h2><span id='topic+burden.mlogit.subscores'></span>

<h3>Description</h3>

<p>Performs burden tests with subscores in the regression on categorical phenotypes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>burden.mlogit.subscores(x, NullObject, genomic.region = x@snps$genomic.region, 
                        SubRegion = x@snps$SubRegion, burden.function = WSS, 
                        maf.threshold = 0.5, get.effect.size = FALSE, 
                        alpha = 0.05, cores = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="burden.mlogit.subscores_+3A_x">x</code></td>
<td>
<p> A bed matrix, only needed if <code>burden="CAST"</code> or <code>burden="WSS"</code></p>
</td></tr>
<tr><td><code id="burden.mlogit.subscores_+3A_nullobject">NullObject</code></td>
<td>
<p> A list returned from <code>NullObject.parameters</code> </p>
</td></tr>
<tr><td><code id="burden.mlogit.subscores_+3A_genomic.region">genomic.region</code></td>
<td>
<p> A factor containing the genomic region of each SNP, <code>x@snps$genomic.region</code> by default, for example the CADD regions</p>
</td></tr>
<tr><td><code id="burden.mlogit.subscores_+3A_subregion">SubRegion</code></td>
<td>
<p> A vector containing subregions within each <code>genomic.region</code>, <code>x@snps$SubRegion</code> by default, for example genomic categories</p>
</td></tr>
<tr><td><code id="burden.mlogit.subscores_+3A_burden.function">burden.function</code></td>
<td>
<p>A function to compute the genetic score, <code>WSS</code> by default.</p>
</td></tr>
<tr><td><code id="burden.mlogit.subscores_+3A_maf.threshold">maf.threshold</code></td>
<td>
<p> The MAF threshold to use for the definition of a rare variant in the CAST score. Set at 0.5 by default</p>
</td></tr>
<tr><td><code id="burden.mlogit.subscores_+3A_get.effect.size">get.effect.size</code></td>
<td>
<p> TRUE/FALSE: whether to return effect sizes of the tested <code>genomic.region</code> (OR for categorical phenotypes, betas for continuous phenotypes) </p>
</td></tr>
<tr><td><code id="burden.mlogit.subscores_+3A_alpha">alpha</code></td>
<td>
<p> The alpha threshold to use for the OR confidence interval</p>
</td></tr>
<tr><td><code id="burden.mlogit.subscores_+3A_cores">cores</code></td>
<td>
<p> How many cores to use, set at 10 by default. Only needed if <code>NullObject$pheno.type = "categorical"</code> </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will return results from the regression of the phenotype on the genetic score(s) for each genomic region. Within each genomic region, a subscore will be computed for each SubRegion and one test will be performed for each genomic.region.
</p>
<p>If only two groups of individuals are present, a classical logistic regression is performed.
If more than two groups of individuals are present, a non-ordinal multinomial regression is performed,
comparing each group of individuals to the reference group indicated by the argument <code>ref.level</code> in <code>NullObject.parameters</code>.
The choice of the reference group won't affect the p-values, but only the Odds Ratios.
In both types of regression, the p-value is estimated using the Likelihood Ratio test and the function <code>burden.mlogit</code>.  
</p>


<h3>Value</h3>

<p>A dataframe with one row per genomic region and two columns:
</p>
<table>
<tr><td><code>p.value</code></td>
<td>
<p> The p.value of the regression</p>
</td></tr>
<tr><td><code>is.err</code></td>
<td>
<p> 0/1: whether there was a convergence problem with the regression</p>
</td></tr>
</table>
<p>If <code>get.effect.size=TRUE</code>, a list is returned with the previous dataframe in <code>$Asso</code> and with <code>effect</code>, a list containing matrices with three columns:
</p>
<table>
<tr><td><code>OR</code></td>
<td>
<p> The OR value(s) associated to the subscores in the regression. If there are more than two groups, there will be one OR value per group compared to the reference group</p>
</td></tr>
<tr><td><code>l.lower</code></td>
<td>
<p> The lower bound of the confidence interval of each OR</p>
</td></tr>
<tr><td><code>l.upper</code></td>
<td>
<p> The upper bound of the confidence interval of each OR</p>
</td></tr>
</table>


<h3>See Also</h3>

 <p><code><a href="#topic+NullObject.parameters">NullObject.parameters</a></code>, <code><a href="#topic+burden.subscores">burden.subscores</a></code>,  <code><a href="#topic+CAST">CAST</a></code>, <code><a href="#topic+WSS">WSS</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#Import data in a bed matrix
#x &lt;- as.bed.matrix(x=LCT.matrix.bed, fam=LCT.matrix.fam, bim=LCT.snps)

#Add population
#x@ped[,c("pop", "superpop")] &lt;- LCT.matrix.pop1000G[,c("population", "super.population")]

#Select EUR superpopulation
#x &lt;- select.inds(x, superpop=="EUR")
#x@ped$pop &lt;- droplevels(x@ped$pop)

#Group variants within CADD regions and genomic categories
#x &lt;- set.CADDregions(x)

#Filter of rare variants: only non-monomorphic variants with
#a MAF lower than 2.5%
#and with a adjusted CADD score greater than the median
#x1 &lt;- filter.adjustedCADD(x, filter = "whole", maf.threshold = 0.025)

#run null model, using the 1000Genome population as "outcome"
#x1.H0 &lt;- NullObject.parameters(pheno = x1@ped$pop, ref.level = "CEU",
#                               RVAT = "burden", pheno.type = "categorical")

#run burden test WSS
#res.subscores &lt;- burden.subscores(x1, NullObject = x1.H0, burden = WSS, 
#                                  get.effect.size=TRUE, cores = 1)
#res.subscores$Asso # p-values
#res.subscores$effect #OR values

</code></pre>

<hr>
<h2 id='burden.subscores'>
Linear, logistic or multinomial regression on a multiple genetic scores within a genomic region
</h2><span id='topic+burden.subscores'></span>

<h3>Description</h3>

<p>Performs burden tests with subscores in the regression on categorical or continuous phenotypes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>burden.subscores(x, NullObject, genomic.region = x@snps$genomic.region, 
                 SubRegion = x@snps$SubRegion, burden.function = WSS, 
                 maf.threshold = 0.5, get.effect.size = FALSE, 
                 alpha = 0.05, cores = 10, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="burden.subscores_+3A_x">x</code></td>
<td>
<p> A bed matrix</p>
</td></tr>
<tr><td><code id="burden.subscores_+3A_nullobject">NullObject</code></td>
<td>
<p> A list returned from <code>NullObject.parameters</code> </p>
</td></tr>
<tr><td><code id="burden.subscores_+3A_genomic.region">genomic.region</code></td>
<td>
<p> A factor containing the genomic region of each SNP, <code>x@snps$genomic.region</code> by default, for example the CADD regions</p>
</td></tr>
<tr><td><code id="burden.subscores_+3A_subregion">SubRegion</code></td>
<td>
<p> A vector containing subregions within each <code>genomic.region</code>, <code>x@snps$SubRegion</code> by default, for example genomic categories</p>
</td></tr>
<tr><td><code id="burden.subscores_+3A_burden.function">burden.function</code></td>
<td>
<p>A function to compute the genetic score, <code>WSS</code> by default.</p>
</td></tr>
<tr><td><code id="burden.subscores_+3A_maf.threshold">maf.threshold</code></td>
<td>
<p> The MAF threshold to use for the definition of a rare variant in the CAST score. Set at 0.5 by default</p>
</td></tr>
<tr><td><code id="burden.subscores_+3A_get.effect.size">get.effect.size</code></td>
<td>
<p> TRUE/FALSE: whether to return effect sizes of the tested <code>genomic.region</code> (OR for categorical phenotypes, betas for continuous phenotypes) </p>
</td></tr>
<tr><td><code id="burden.subscores_+3A_alpha">alpha</code></td>
<td>
<p> The alpha threshold to use for the OR confidence interval</p>
</td></tr>
<tr><td><code id="burden.subscores_+3A_cores">cores</code></td>
<td>
<p> How many cores to use, set at 10 by default. Only needed if <code>NullObject$pheno.type = "categorical"</code> </p>
</td></tr>
<tr><td><code id="burden.subscores_+3A_verbose">verbose</code></td>
<td>
<p> Whether to display information about the function actions </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will return results from the regression of the phenotype on the genetic score(s) for each genomic region. Within each genomic region, a subscore will be computed for each SubRegion and one test will be performed for each genomic.region.  
</p>
<p>When used after <code>set.CADDregions</code>, it will perform a test by CADD region with one subscore by genomic category (coding, regulatory, intergenic) as in the <code>RAVA.FIRST()</code> strategy.  
</p>
<p>If only two groups of individuals are present, a classical logistic regression is performed.
If more than two groups of individuals are present, a non-ordinal multinomial regression is performed,
comparing each group of individuals to the reference group indicated by the argument <code>ref.level</code> in <code>NullObject.parameters</code>.
The choice of the reference group won't affect the p-values, but only the Odds Ratios.
In both types of regression, the p-value is estimated using the Likelihood Ratio test and the function <code>burden.mlogit</code>.  
</p>
<p>If the phenotype is continuous, a linear regression is performed using the function <code>burden.continuous</code>.  
</p>
<p>The type of phenotype is determined from <code>NullObject$pheno.type</code>.  
</p>


<h3>Value</h3>

<p>A dataframe with one row per genomic region and two columns:
</p>
<table>
<tr><td><code>p.value</code></td>
<td>
<p> The p.value of the regression</p>
</td></tr>
<tr><td><code>is.err</code></td>
<td>
<p> 0/1: whether there was a convergence problem with the regression</p>
</td></tr>
</table>
<p>If <code>get.effect.size=TRUE</code>, a list is returned with the previous dataframe in <code>$Asso</code> and with <code>effect</code>, a list containing matrices with three columns:
</p>
<table>
<tr><td><code>OR/beta</code></td>
<td>
<p> The OR/beta value(s) associated to the subscores in the regression. For categorical phenotypes, if there are more than two groups, there will be one OR value per group compared to the reference group</p>
</td></tr>
<tr><td><code>l.lower</code></td>
<td>
<p> The lower bound of the confidence interval of each OR/beta</p>
</td></tr>
<tr><td><code>l.upper</code></td>
<td>
<p> The upper bound of the confidence interval of each OR/beta</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+RAVA.FIRST">RAVA.FIRST</a></code>, <code><a href="#topic+NullObject.parameters">NullObject.parameters</a></code>, <code><a href="#topic+burden.continuous.subscores">burden.continuous.subscores</a></code>, <code><a href="#topic+burden.mlogit.subscores">burden.mlogit.subscores</a></code>,  <code><a href="#topic+CAST">CAST</a></code>, <code><a href="#topic+WSS">WSS</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#Import 1000Genome data from region around LCT gene
x &lt;- as.bed.matrix(x=LCT.matrix.bed, fam=LCT.matrix.fam, bim=LCT.snps)

#Group variants within known genes and
#Within coding and regulatory regions
x &lt;- set.genomic.region.subregion(x, regions = genes.b37, 
                                  subregions = subregions.LCT)

#Add population
x@ped[,c("pop", "superpop")] &lt;- LCT.matrix.pop1000G[,c("population", "super.population")]

#Select EUR superpopulation
x &lt;- select.inds(x, superpop=="EUR")
x@ped$pop &lt;- droplevels(x@ped$pop)

#Keep only variants with a MAF lower than 1%
x1 &lt;- filter.rare.variants(x, filter = "whole", maf.threshold = 0.01)

#run null model, using the 1000Genome population as "outcome"
x1.H0 &lt;- NullObject.parameters(pheno = x1@ped$pop, ref.level = "CEU",
                               RVAT = "burden", pheno.type = "categorical")

#run functionally-informed burden test WSS in LCT
burden.subscores(select.snps(x1, genomic.region == "LCT"), 
                 NullObject = x1.H0, burden.function = WSS, 
                 get.effect.size=FALSE, cores = 1)


####Using the RAVA-FIRST approach with CDD regions
#Group variants within CADD regions and genomic categories
#x &lt;- set.CADDregions(x)

#Filter of rare variants: only non-monomorphic variants with
#a MAF lower than 2.5%
#and with a adjusted CADD score greater than the median
#x1 &lt;- filter.adjustedCADD(x, filter = "whole", maf.threshold = 0.025)

#run functionally-informed burden test WSS
#burden.subscores(x1, NullObject = x1.H0, burden.function = WSS, 
#                 get.effect.size=FALSE, cores = 1)

</code></pre>

<hr>
<h2 id='burden.weighted.matrix'> Score matrix for burden tests</h2><span id='topic+burden.weighted.matrix'></span>

<h3>Description</h3>

<p>Computes the score matrix for burden tests based on variants' weights
</p>


<h3>Usage</h3>

<pre><code class='language-R'>burden.weighted.matrix(x, weights, genomic.region = x@snps$genomic.region)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="burden.weighted.matrix_+3A_x">x</code></td>
<td>
<p> A bed.matrix </p>
</td></tr>
<tr><td><code id="burden.weighted.matrix_+3A_weights">weights</code></td>
<td>
<p> A vector containing the weight of each variant</p>
</td></tr>
<tr><td><code id="burden.weighted.matrix_+3A_genomic.region">genomic.region</code></td>
<td>
<p> A factorcontaining the genomic region of each variant </p>
</td></tr>
</table>


<h3>Details</h3>

<p>For variant <em>i</em> and individual <em>j</em>, the genetic score will be computed as weight of variant <em>i</em> * number of minor alleles for individual <em>j</em>. This function returns a weighted score of rare alleles in the genomic region: if the reference allele is rare, it will be counted in the score instead of the atlernative allele.
</p>


<h3>Value</h3>

<p>A matrix containing the computed genetic score with one row per individual and one column per <code>genomic.region</code>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+CAST">CAST</a></code>, <code><a href="#topic+WSS">WSS</a></code>, <code><a href="#topic+burden.mlogit">burden.mlogit</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Import data in a bed matrix
x &lt;- as.bed.matrix(x=LCT.matrix.bed, fam=LCT.matrix.fam, bim=LCT.snps)

# Group variants within known genes
x &lt;- set.genomic.region(x)

# Filter variants with maf (computed on whole sample) &lt; 0.025
# keeping only genomic region with at least 10 SNPs
x1 &lt;- filter.rare.variants(x, filter = "whole", maf.threshold = 0.025, min.nb.snps = 10)

#Compute burden score with weights = 1-maf
score.burden &lt;- burden.weighted.matrix(x1, weights=1-x1@snps$maf)
</code></pre>

<hr>
<h2 id='CAST'> Cohort Allelic Sum Test</h2><span id='topic+CAST'></span>

<h3>Description</h3>

<p> Calculates the CAST genetic score </p>


<h3>Usage</h3>

<pre><code class='language-R'>CAST(x, genomic.region = x@snps$genomic.region, maf.threshold = 0.5, 
     flip.rare.alleles = T)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CAST_+3A_x">x</code></td>
<td>
<p> A bed.matrix </p>
</td></tr>
<tr><td><code id="CAST_+3A_genomic.region">genomic.region</code></td>
<td>
<p> A factor defining the genomic region of each variant </p>
</td></tr>
<tr><td><code id="CAST_+3A_maf.threshold">maf.threshold</code></td>
<td>
<p> The MAF used for the definition of a rare variant, set at 0.5 by default, i.e. all variants are kept</p>
</td></tr>
<tr><td><code id="CAST_+3A_flip.rare.alleles">flip.rare.alleles</code></td>
<td>
<p> Whether to flip the A1/A2 alleles if the A1 allele is rare, set at T by default</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, CAST counts if an individual carries at least one rare allele in the genomic region. If <code>flip.rare.alleles = F</code> and the reference allele A1 is rare, the alles A1 and A2 won't be flipped and CAST will count the number of alternative alleles A2.
</p>


<h3>Value</h3>

<p>A matrix containing the CAST genetic score with one row per individual and one column per <code>genomic.region</code>
</p>


<h3>References</h3>

<p> Morgenthaler S and Thilly WG. <em>A strategy to discover genes that carry multi-allelic or mono-allelic risk for common diseases: a cohort allelic sums test (CAST).</em> Mutat Res. 2007</p>


<h3>See Also</h3>

 <p><code><a href="#topic+WSS">WSS</a></code>, <code><a href="#topic+burden.weighted.matrix">burden.weighted.matrix</a></code>, <code><a href="#topic+burden.mlogit">burden.mlogit</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Import data in a bed matrix
x &lt;- as.bed.matrix(x=LCT.matrix.bed, fam=LCT.matrix.fam, bim=LCT.snps)

# Group variants within known genes
x &lt;- set.genomic.region(x)

# Filter variants with maf (computed on whole sample) &lt; 0.025
# keeping only genomic region with at least 10 SNPs
x1 &lt;- filter.rare.variants(x, filter = "whole", maf.threshold = 0.025, min.nb.snps = 10)

# Compute burden score CAST
score.CAST &lt;- CAST(x1, maf.threshold=0.025)
</code></pre>

<hr>
<h2 id='filter.adjustedCADD'>
Variant filtering based on frequency and median adjusted CADD by CADD regions
</h2><span id='topic+filter.adjustedCADD'></span>

<h3>Description</h3>

<p>Filter rare variants based on a MAF threshold, a given number of SNP or a given cumulative MAF per genomic region and the median of adjusted CADD score for each CADD region
</p>


<h3>Usage</h3>

<pre><code class='language-R'>filter.adjustedCADD(x, SNVs.scores = NULL, indels.scores = NULL,
                    ref.level = NULL, 
                    filter=c("whole", "controls", "any"), 
                    maf.threshold=0.01, min.nb.snps = 2, 
                    min.cumulative.maf = NULL, 
                    group = NULL, cores = 10, path.data, verbose = T)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="filter.adjustedCADD_+3A_x">x</code></td>
<td>
<p> A bed.matrix annotated with CADD regions using <code>set.CADDregions</code> </p>
</td></tr>
<tr><td><code id="filter.adjustedCADD_+3A_snvs.scores">SNVs.scores</code></td>
<td>
<p> A dataframe containing the ADJUSTED CADD scores of the SNVs (Optional, useful to gain in computation time if the adjusted CADD scores of variants in the study are available)</p>
</td></tr>
<tr><td><code id="filter.adjustedCADD_+3A_indels.scores">indels.scores</code></td>
<td>
<p> A dataframe containing the CADD PHREDv1.4 scores of the indels - Compulsory if indels are present in <code>x</code></p>
</td></tr>
<tr><td><code id="filter.adjustedCADD_+3A_ref.level">ref.level</code></td>
<td>
<p> The level corresponding to the controls group, only needed if <code>filter=="controls"</code> </p>
</td></tr>
<tr><td><code id="filter.adjustedCADD_+3A_filter">filter</code></td>
<td>
<p> On which group the filter will be applied </p>
</td></tr>
<tr><td><code id="filter.adjustedCADD_+3A_maf.threshold">maf.threshold</code></td>
<td>
<p> The MAF threshold used to define a rare variant, set at 0.01 by default</p>
</td></tr>
<tr><td><code id="filter.adjustedCADD_+3A_min.nb.snps">min.nb.snps</code></td>
<td>
<p> The minimum number of variants needed to keep a CADD region, set at 2 by default</p>
</td></tr>
<tr><td><code id="filter.adjustedCADD_+3A_min.cumulative.maf">min.cumulative.maf</code></td>
<td>
<p> The minimum cumulative maf of variants needed to keep a CADD region</p>
</td></tr>
<tr><td><code id="filter.adjustedCADD_+3A_group">group</code></td>
<td>
<p> A factor indicating the group of each individual, only needed if <code>filter = "controls"</code> or <code>filter = "any"</code>. If missing, <code>x@ped$pheno</code> is taken</p>
</td></tr>
<tr><td><code id="filter.adjustedCADD_+3A_cores">cores</code></td>
<td>
<p> How many cores to use, set at 10 by default</p>
</td></tr>
<tr><td><code id="filter.adjustedCADD_+3A_path.data">path.data</code></td>
<td>
<p> The repository where data for RAVA-FIRST are or will be downloaded from https://lysine.univ-brest.fr/RAVA-FIRST/</p>
</td></tr>
<tr><td><code id="filter.adjustedCADD_+3A_verbose">verbose</code></td>
<td>
<p> Whether to display information about the function actions </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Variants are directly annotated with the adjusted CADD scores in the function using the file &quot;AdjustedCADD_v1.4_202108.tsv.gz&quot; downloaded from https://lysine.univ-brest.fr/RAVA-FIRST/ in the repository of the package Ravages or the scores of variants can be provided to <code>variant.scores</code> to gain in computation time (this file should contain 5 columns: the chromosome ('chr'), position ('pos'), reference allele ('A1'), alternative allele ('A2') and adjusted CADD scores ('adjCADD'). As CADD scores are only available for SNVs, only those ones will be kept in the analysis.  
</p>
<p>If a column 'adjCADD' is already present in <code>x@snps</code>, no annotation will be performed and filtering will be directly on this column.  
</p>
<p>To use this function, a factor 'genomic.region' corresponding to the CADD regions and a vector 'adjCADD.Median' should be present in the slot <code>x@snps</code>. To obtain those two, use the function <code>set.CADDregions</code>.  
</p>
<p>Only variants with an adjusted CADD score upper than the median value are kept in the analysis. It is the filtering strategy applied in the <code>RAVA.FIRST()</code> pipeline.     
</p>
<p>If <code>filter="whole"</code>, only the variants having a MAF lower than the threshold in the entire sample are kept.
</p>
<p>If <code>filter="controls"</code>, only the variants having a MAF lower than the threshold in the controls group are kept.
</p>
<p>If <code>filter="any"</code>, only the variants having a MAF lower than the threshold in any of the groups are kept.  
</p>
<p>It is recommended to use this function chromosome by chromosome for large datasets.
</p>


<h3>Value</h3>

<p>A bed.matrix with filtered variants
</p>


<h3>Source</h3>

<p>https://lysine.univ-brest.fr/RAVA-FIRST/</p>


<h3>See Also</h3>

<p><code><a href="#topic+RAVA.FIRST">RAVA.FIRST</a></code>, <code><a href="#topic+set.CADDregions">set.CADDregions</a></code>, <code><a href="#topic+burden.subscores">burden.subscores</a></code>, <code><a href="#topic+filter.rare.variants">filter.rare.variants</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Import 1000Genome data from region around LCT gene
#x &lt;- as.bed.matrix(LCT.gen, LCT.fam, LCT.bim)

#Group variants within CADD regions and genomic categories
#x &lt;- set.CADDregions(x)

#Annotate variants with adjusted CADD score
#and filter on frequency and median
#x.median &lt;- filter.adjustedCADD(x, maf.threshold = 0.025, 
#                                min.nb.snps = 2)
</code></pre>

<hr>
<h2 id='filter.rare.variants'>
Rare variants filtering
</h2><span id='topic+filter.rare.variants'></span>

<h3>Description</h3>

<p>Filter rare variants based on a MAF threshold and a given number of SNP or a given cumulative MAF per genomic region
</p>


<h3>Usage</h3>

<pre><code class='language-R'>filter.rare.variants(x, ref.level = NULL, filter=c("whole", "controls", "any"), 
                     maf.threshold=0.01, min.nb.snps = 2, min.cumulative.maf = NULL, 
                     group = NULL, genomic.region = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="filter.rare.variants_+3A_x">x</code></td>
<td>
<p> A bed.matrix </p>
</td></tr>
<tr><td><code id="filter.rare.variants_+3A_ref.level">ref.level</code></td>
<td>
<p> The level corresponding to the controls group, only needed if <code>filter=="controls"</code> </p>
</td></tr>
<tr><td><code id="filter.rare.variants_+3A_filter">filter</code></td>
<td>
<p> On which group the filter will be applied </p>
</td></tr>
<tr><td><code id="filter.rare.variants_+3A_maf.threshold">maf.threshold</code></td>
<td>
<p> The MAF threshold used to define a rare variant, set at 0.01 by default</p>
</td></tr>
<tr><td><code id="filter.rare.variants_+3A_min.nb.snps">min.nb.snps</code></td>
<td>
<p> The minimum number of variants needed to keep a genomic region, set at 2 by default</p>
</td></tr>
<tr><td><code id="filter.rare.variants_+3A_min.cumulative.maf">min.cumulative.maf</code></td>
<td>
<p> The minimum cumulative maf of variants needed to keep a genomic region</p>
</td></tr>
<tr><td><code id="filter.rare.variants_+3A_group">group</code></td>
<td>
<p> A factor indicating the group of each individual, only needed if <code>filter = "controls"</code> or <code>filter = "any"</code>. If missing, <code>x@ped$pheno</code> is taken</p>
</td></tr>
<tr><td><code id="filter.rare.variants_+3A_genomic.region">genomic.region</code></td>
<td>
<p> An optional factor containing the genomic region of each variant, only needed if <code>min.nb.snps</code> or <code>min.cumulative.maf</code> is specified and if <code>x@snps$genomic.region</code> doesn't exist</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To use this function, a factor 'genomic.region' should be present in the slot <code>x@snps</code>.  
</p>
<p>If <code>filter="whole"</code>, only the variants having a MAF lower than the threshold in the entire sample are kept.
</p>
<p>If <code>filter="controls"</code>, only the variants having a MAF lower than the threshold in the controls group are kept.
</p>
<p>If <code>filter="any"</code>, only the variants having a MAF lower than the threshold in any of the groups are kept.
</p>


<h3>Value</h3>

<p>A bed.matrix with filtered variants
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Import 1000Genome data from region around LCT gene
x &lt;- as.bed.matrix(LCT.gen, LCT.fam, LCT.bim)

#Group variants within known genes
x &lt;- set.genomic.region(x)
table(x@snps$genomic.region, useNA="ifany")
                             
#Filter of rare variants: only non-monomorphic variants with 
#a MAF lower than 2.5%
#keeping only genomic regions with at least 10 SNPs
x1 &lt;- filter.rare.variants(x, filter = "whole", maf.threshold = 0.025, min.nb.snps = 10)
table(x1@snps$genomic.region, useNA="ifany")

#Keep only variants with a MAF&lt;2%
#and regions with a cumulative MAF&gt;10%
filter.rare.variants(x, filter = "whole", maf.threshold = 0.02, min.nb.snps = 1, 
                     min.cumulative.maf=0.2)

</code></pre>

<hr>
<h2 id='genes.positions'>Genes positions</h2><span id='topic+genes.positions'></span><span id='topic+genes.b37'></span><span id='topic+genes.b38'></span>

<h3>Description</h3>

<p>Positions of human genes in bed format (Start is 0-based and End is 1-based). These data were downloaded from Biomart on the Ensembl website with the GRCh37 and GRCh38 versions. Only genes present in GnomAD were kept.
</p>
<p>Data contain the <code>Chr</code>, the <code>Start</code> position, the <code>End</code> position and the <code>Name</code> of all the genes in chromosomes 1 to 22 representing 19375 and 18278 genes in the two GRCh versions respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(genes.b37)
data(genes.b38) </code></pre>


<h3>Format</h3>

<p>The data contain one dataframe with four columns:
</p>

<dl>
<dt><code>Chr</code></dt><dd><p>The chromosome of the gene</p>
</dd>
<dt><code>Start</code></dt><dd><p>The start position of the gene (0-based)</p>
</dd>
<dt><code>End</code></dt><dd><p>The end position of the gene (1-based)</p>
</dd>
<dt><code>Name</code></dt><dd><p>The name of the gene</p>
</dd>
</dl>



<h3>Source</h3>

<p>The data were obtained from the Ensembl website.</p>


<h3>References</h3>

<p> RJ Kinsella et al, 2011, <em>Ensembl BioMarts: a hub for data retrieval across taxonomic space</em>, Database. doi:10.1093/database/bar030;   
</p>
<p>AD Yates et al, 2020, <em>Ensembl 2020</em>, Nucleic Acide Research. doi:10.1093/nar/gkz966</p>


<h3>See Also</h3>

 <p><code><a href="#topic+set.genomic.region">set.genomic.region</a></code> </p>

<hr>
<h2 id='genotypic.freq'>
Genotypic frequencies calculation for data simulations
</h2><span id='topic+genotypic.freq'></span>

<h3>Description</h3>

<p>Calculates the three genotypic frequencies in the controls group and each group of cases based on MAF in the general population and GRR values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genotypic.freq(genes.maf = Kryukov, GRR.het, GRR.homo.alt, prev, 
               genetic.model = c("general", "multiplicative", 
                                 "dominant", "recessive"), select.gene,
               selected.controls = T)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="genotypic.freq_+3A_genes.maf">genes.maf</code></td>
<td>
<p> A file containing the MAF in the general population (column maf) for variants with their associated gene (column gene), by default the file <code>Kryukov</code> is used</p>
</td></tr>
<tr><td><code id="genotypic.freq_+3A_grr.het">GRR.het</code></td>
<td>
<p> A matrix giving the GRR of the heterozygous genotype compared to the homozygous reference genotype with one row per cases group and one column per variant </p>
</td></tr>
<tr><td><code id="genotypic.freq_+3A_grr.homo.alt">GRR.homo.alt</code></td>
<td>
<p> A matrix giving the GRR of the homozygous alternative genotype compared to the homozygous reference genotype with one row per cases group and one column per variant, only need if <code>genetic.model="general"</code></p>
</td></tr>
<tr><td><code id="genotypic.freq_+3A_prev">prev</code></td>
<td>
<p> A vector containing the prevalence of each group of cases</p>
</td></tr>
<tr><td><code id="genotypic.freq_+3A_genetic.model">genetic.model</code></td>
<td>
<p> The genetic model of the disease </p>
</td></tr>
<tr><td><code id="genotypic.freq_+3A_select.gene">select.gene</code></td>
<td>
<p> Which gene to choose from <code>genes.maf$gene</code> if multiple genes are present. If missing, only the first level is kept.</p>
</td></tr>
<tr><td><code id="genotypic.freq_+3A_selected.controls">selected.controls</code></td>
<td>
<p> Whether controls are selected controls (by default) or controls from the general population</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is used to simulate genetic data.
</p>
<p>The genetic model of the disease needs to be specified to <code>genetic.model</code>:
</p>
<p>If <code>genetic.model="general"</code>, there is no link between the GRR associated 
to the heterozygous genotype and the GRR associated to the homozygous alternative 
genotype. Therefore, the user has to give two matrices of GRR, one for each of these genotypes.
</p>
<p>If <code>genetic.model="multiplicative"</code>, we assume that the GRR associated to the homozygous 
alternative genotype is the square of the GRR associated to the heterozygous genotype.
</p>
<p>If <code>genetic.model="dominant"</code>, we assume that the GRR associated to the heterozygous genotype 
and the GRR associated to the homozygous alternative genotype are equal.
</p>
<p>If <code>genetic.model="recessive"</code>, we assume that the GRR associated to the heterozygous genotype 
is equal to 1: the GRR given is the one associated to the homozygous alternative genotype.  
</p>
<p><code>prev</code> corresponds to the proportion of each sub-group of cases in the population. 
It is used only to calculate the MAF in the controls group.  
</p>
<p>If <code>selected.controls</code> = T, genotypic frequencies in the control group are computed from genotypic frequencies in the cases groups and the prevalence of the disease. 
If FALSE, genotypic frequencies in the control group are computed from allelic frequencies under Hardy-Weinberg equilibrium.  
</p>
<p>The dataframes <code>Kryukov</code> or <code>GnomADgenes</code> available with the package Ravages can be used for the argument <code>genes.maf</code>.
</p>


<h3>Value</h3>

<p>A matrix of MAF values with one column per variant and one row per group (the first one being the controls group)
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+GRR.matrix">GRR.matrix</a></code>, <code><a href="#topic+rbm.GRR">rbm.GRR</a></code>, <code><a href="#topic+GnomADgenes">GnomADgenes</a></code>, <code><a href="#topic+Kryukov">Kryukov</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Construction of the GRR matrix using the formula from SKAT
#to compute the GRR (higher weights to rarer variants)
#GRR in the second group are twice as high as in the first group
GRR.del &lt;- GRR.matrix(GRR = "SKAT", GRR.multiplicative.factor=2,
                      select.gene="R1")

#Calculation of frequency in the three groups of individuals 
#under a multilpicative model of the disease
geno.freq.groups &lt;- genotypic.freq(genes.maf = Kryukov, GRR.het = GRR.del, 
                                   prev = c(0.001, 0.001), select.gene="R1", 
                                   genetic.model = "multiplicative")
</code></pre>

<hr>
<h2 id='GnomADgenes'>GnomADgenes dataset</h2><span id='topic+GnomADgenes'></span>

<h3>Description</h3>

<p>This dataframe contains variants from the GnomAD database with MAF values in the Non-Finnish European (NFE)
and their consequences from VEP with each associated gene in build version 37.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(GnomADgenes)</code></pre>


<h3>Format</h3>

<p>GnomADgenes is a dataframe with five columns:
</p>

<dl>
<dt>chr</dt><dd><p> The chromosome of the variant</p>
</dd>
<dt>pos</dt><dd><p> The position of the variant</p>
</dd>
<dt>consequence</dt><dd><p> The functionnal consequence of the variant predicted by Variant Effect Predictor (VEP)</p>
</dd>
<dt>gene</dt><dd><p> The gene associated to each variant predicted by VEP</p>
</dd>
<dt>maf</dt><dd><p> The MAF of the variant in the NFE population</p>
</dd>
</dl>



<h3>Source</h3>

<p>The data were obtained from the GnomAD website (see http://gnomad.broadinstitute.org/) and the VEP website (see https://www.ensembl.org/info/docs/tools/vep/).</p>

<hr>
<h2 id='GRR.matrix'>
GRR matrix for genetic data simulation
</h2><span id='topic+GRR.matrix'></span>

<h3>Description</h3>

<p>Computes a GRR matrix based on a simulation model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GRR.matrix(genes.maf = Kryukov, n.case.groups = 2, 
           GRR = c("SKAT", "constant", "variable"), 
           GRR.value, GRR.function, GRR.multiplicative.factor, select.gene)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GRR.matrix_+3A_genes.maf">genes.maf</code></td>
<td>
<p> A dataframe containing at least the MAF in the general population (column <code>maf</code>) with their associated gene (column <code>gene</code>). By default, <code>maf</code> from the file Kryukov are used</p>
</td></tr>
<tr><td><code id="GRR.matrix_+3A_n.case.groups">n.case.groups</code></td>
<td>
<p> The number of cases groups (set at 2 by default), i.e. the number of groups where variants will have a GRR greater than 1</p>
</td></tr>
<tr><td><code id="GRR.matrix_+3A_grr">GRR</code></td>
<td>
<p> How to calculate the GRR </p>
</td></tr>
<tr><td><code id="GRR.matrix_+3A_grr.value">GRR.value</code></td>
<td>
<p> GRR value if <code>GRR="constant"</code></p>
</td></tr>
<tr><td><code id="GRR.matrix_+3A_grr.function">GRR.function</code></td>
<td>
<p> A function indicating how to calculate the GRR depending on MAF in the general population, only needed if <code>GRR="variable"</code></p>
</td></tr>
<tr><td><code id="GRR.matrix_+3A_grr.multiplicative.factor">GRR.multiplicative.factor</code></td>
<td>
<p> A vector of size (<code>n.case.groups</code>-1) containing the multiplicative factor for the GRR for each group of cases compared to the first group of cases</p>
</td></tr>
<tr><td><code id="GRR.matrix_+3A_select.gene">select.gene</code></td>
<td>
<p> The gene(s) to be selected from the file <code>genes.maf</code> if multiple genes are present. If missing, the first level of <code>genes.maf$gene</code> is kept.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The GRR can be computed in three ways using the argument <code>GRR</code>.
</p>
<p>If <code>GRR="constant"</code>, the same GRR is given to all the variants, its value being specified to <code>GRR.value</code>.  
If <code>GRR="SKAT"</code>, the GRR are calculating using the formula from the paper presenting the SKAT method and thus depend on MAF.  
If <code>GRR="variable"</code>, the GRR are calculating using a function given by the user to <code>GRR.function</code> depending only on the MAF in the general population.  
</p>
<p>The argument <code>multiplicative.factor</code> contains <code>n.case.groups</code>-1 values; if <code>multiplicative.factor=1</code>, GRR will be the same between the different groups of cases.  
</p>
<p>The two dataframes <code>Kryukov</code> (used by default) and <code>GnomADgenes</code> (containing MAF in the NFE population) can be used as <code>genes.maf</code>.
</p>
<p><code>GRR.matrix</code> returns a matrix that can be used in other simulation functions such as <code>rbm.GRR</code>.
</p>


<h3>Value</h3>

<p>A matrix containing the GRR values with one column per variant and one line per cases group
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+rbm.GRR">rbm.GRR</a></code>, <code><a href="#topic+GnomADgenes">GnomADgenes</a></code>, <code><a href="#topic+Kryukov">Kryukov</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#GRR calculated on the MAF from the first unit of the file Kryukov
#using the formula from the SKAT paper, with the second group of cases 
#having GRR values twice as high as the first one
GRR.del &lt;- GRR.matrix(GRR = "SKAT", genes.maf = Kryukov,
                      GRR.multiplicative.factor=2, select.gene = "R1")
</code></pre>

<hr>
<h2 id='Jaccard'>
Jaccard index
</h2><span id='topic+Jaccard'></span>

<h3>Description</h3>

<p>Calculates the Jaccard index for each pair of individuals using a bed.matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Jaccard(x, maf.threshold = 0.01)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Jaccard_+3A_x">x</code></td>
<td>
<p>A bed.matrix</p>
</td></tr>
<tr><td><code id="Jaccard_+3A_maf.threshold">maf.threshold</code></td>
<td>
<p>The MAF used for the definition of a rare variant, set at 0.01 by default</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The individuals carrying no rare variants will have a null Jaccard index with all the individuals including themselves.
</p>


<h3>Value</h3>

<p>A squared matrix giving the Jaccard index for each pair of individuals
</p>


<h3>References</h3>

<p> Jaccard, P. (1908) <em>Nouvelles researches sur la distribution florale</em>, Bulletin de la Soci√©t√© vaudoise des sciences naturelles, <b>44, 223-270</b> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Simulation of genetic data with GRR values according to the SKAT formula
GRR.del &lt;- GRR.matrix(GRR = "SKAT", genes.maf = Kryukov, 
                      n.case.groups = 2, select.gene = "R1",
                      GRR.multiplicative.factor=2)

#Simulation of one group of 1,000 controls and two groups of 500 cases, 
#50% of causal variants, 5 genomic regions are simulated.
x &lt;- rbm.GRR(genes.maf=Kryukov, size = c(1000, 500, 500),
             prev = c(0.001, 0.001), select.gene = "R1", 
             GRR.matrix.del = GRR.del, p.causal = 0.5,
             genetic.model = "multiplicative", replicates = 5)
                           
#Calculate the Jaccard matrix
J &lt;- Jaccard(x, maf.threshold = 0.01)

</code></pre>

<hr>
<h2 id='Kryukov'>Kryukov data set</h2><span id='topic+Kryukov'></span>

<h3>Description</h3>

<p>The data from <em>Kryukov et al, 2009</em>, contain simulated site frequency spectrum data using European demographic models with purifying selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Kryukov) </code></pre>


<h3>Format</h3>

<p><code>Kryukov</code> is a dataframe with four columns:
</p>

<dl>
<dt>gene</dt><dd><p>The unit of each variant</p>
</dd>
<dt>maf</dt><dd><p>The maf of each variant in the European population</p>
</dd>
<dt>selection.coefficient</dt><dd><p>The selction coefficient of each variant in the European population</p>
</dd>
<dt>position</dt><dd><p>The position of each variant</p>
</dd>
</dl>



<h3>Details</h3>

<p>200 units are present corresponding to 200 genes. For each unit, the data set contains the maf in the European population, the selection coefficient and the position of each variant.
</p>


<h3>Source</h3>

<p> The data were obtained from the SeqPower software (see also <a href="http://www.bioinformatics.org/spower/input#data_download">http://www.bioinformatics.org/spower/input#data_download</a>). </p>


<h3>References</h3>

<p>Kryukov et al, 2009, <em>Power of deep, all-exon resequencing for discovery of human trait genes</em>, Proceedings of the National Academy of Sciences, DOI:10.1073/pnas.0812824106</p>

<hr>
<h2 id='LCT.haplotypes'>LCT haplotypes data set</h2><span id='topic+LCT.haplotypes'></span><span id='topic+LCT.hap'></span><span id='topic+LCT.sample'></span><span id='topic+LCT.snps'></span>

<h3>Description</h3>

<p>These data contain the haplotype matrix <code>LCT.hap</code> (5008 haplotypes) of the 2004 individuals from the 1000 Genomes data for a ~300kb segment containing the Lactase gene.  
Information about individuals (sex, population and super population) is present in <code>LCT.sample</code>, and information about snps is available in <code>LCT.snps</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> data(LCT.haplotypes) </code></pre>


<h3>Format</h3>

<p>Three data objects are present in <code>LCT.haplotypes</code>:
</p>

<dl>
<dt><code>LCT.hap</code></dt><dd><p> A matrix of haplotypes </p>
</dd>
<dt><code>LCT.sample</code></dt><dd><p> A data frame with information on individuals (sex, population, super.population)</p>
</dd>
<dt><code>LCT.snps</code></dt><dd><p> A data frame with information on snps (chr, id, dist, pos, A1, A2) </p>
</dd>
</dl>



<h3>Source</h3>

<p> Data were obtained from the 1000 Genomes Project. </p>


<h3>References</h3>

<p> McVean et al, 2012, <em>An integrated map of genetic variation from 1,092 human genomes</em>, Nature <b>491, 56-65</b> doi:10.1038/nature11632 </p>


<h3>See Also</h3>

 <p><code><a href="#topic+LCT.matrix">LCT.matrix</a></code> </p>

<hr>
<h2 id='LCT.matrix'>LCT genotypes matrix</h2><span id='topic+LCT.matrix'></span><span id='topic+LCT.matrix.bed'></span><span id='topic+LCT.matrix.fam'></span><span id='topic+LCT.matrix.pop1000G'></span>

<h3>Description</h3>

<p>These data contain the genotype matrix corresponding to haplotypes present in <code>LCT.haplotypes</code> from the 1000 Genomes data for a ~300kb segment containing the Lactase gene.  
Information about individuals is present in <code>LCT.matrix.fam</code>, and information about population (population and super population) is present in <code>LCT.matrix.pop1000G</code>, in a format needed to generate a bedmatrix.  
<code>LCT.snps</code> from <code>LCT.haplotypes</code> can be used as the corresponding bim file of this genotypes matrix.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'> data(LCT.matrix) </code></pre>


<h3>Format</h3>

<p>Three data objects are present in <code>LCT.haplotypes</code>:
</p>

<dl>
<dt><code>LCT.matrix.bed</code></dt><dd><p> The matrix of genotypes</p>
</dd>
<dt><code>LCT.matrix.fam</code></dt><dd><p> The corresponding fam file</p>
</dd>
<dt><code>LCT.matrix.pop1000G</code></dt><dd><p> A data frame with population information for individuals (population, superpopulation)</p>
</dd>
</dl>



<h3>Source</h3>

<p> Data were obtained from the 1000 Genomes Project. </p>


<h3>References</h3>

<p> McVean et al, 2012, <em>An integrated map of genetic variation from 1,092 human genomes</em>, Nature <b>491, 56-65</b> doi:10.1038/nature11632 </p>


<h3>See Also</h3>

 <p><code><a href="#topic+LCT.haplotypes">LCT.haplotypes</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Import data in a bed matrix
x &lt;- as.bed.matrix(x=LCT.matrix.bed, fam=LCT.matrix.fam, bim=LCT.snps)
#Add population
x@ped[,c("pop", "superpop")] &lt;- LCT.matrix.pop1000G[,c("population", "super.population")]

</code></pre>

<hr>
<h2 id='multinomial.asso.freq'>
Single variant association test with categorical phenotype
</h2><span id='topic+multinomial.asso.freq'></span>

<h3>Description</h3>

<p>Performs an association test between categorical phenotypes and single variants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multinomial.asso.freq(x, pheno = x@ped$pheno, ref.level,
                      test = c("Genotypic", "Allelic"), get.effect.size = F,
                      min.maf.threshold = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multinomial.asso.freq_+3A_x">x</code></td>
<td>
<p> A bed matrix, only needed if <code>burden="CAST"</code> or <code>burden="WSS"</code></p>
</td></tr>
<tr><td><code id="multinomial.asso.freq_+3A_pheno">pheno</code></td>
<td>
<p> The phenotype of each individual: a factor if <code>pheno.type = "categorical"</code>, and a numeric vector if <code>pheno.type = "continuous"</code> </p>
</td></tr>
<tr><td><code id="multinomial.asso.freq_+3A_ref.level">ref.level</code></td>
<td>
<p> The reference group of individuals for the estimation of the effect size, only needed if <code>get.effect.size = T</code> </p>
</td></tr>
<tr><td><code id="multinomial.asso.freq_+3A_test">test</code></td>
<td>
<p> Whether to perform the test on the three genotypes (&quot;Genotypic&quot;) or on the two alleles (&quot;Allelic&quot;)</p>
</td></tr>
<tr><td><code id="multinomial.asso.freq_+3A_get.effect.size">get.effect.size</code></td>
<td>
<p> TRUE/FALSE: whether to return effect sizes of the variants (OR) </p>
</td></tr>
<tr><td><code id="multinomial.asso.freq_+3A_min.maf.threshold">min.maf.threshold</code></td>
<td>
<p> MAF threshold used to define a frequent variant to apply single-variant test</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This association test is based on a chi-square with the following number of df:  
If <code>test = "Genotypic"</code>, (number of groups of individuals - 1)* 2  
If <code>test = "Allelic"</code>, (number of groups of individuals - 1)  
</p>


<h3>Value</h3>

<p>A dataframe with one row per variant and three columns: the chromosome, position and p-value of each variant.  
If <code>get.effect.size = T</code>, a list with <code>Asso</code> containing the previous dataframe and <code>OR</code> containing the OR in each group for each variant.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Import data in a bed matrix
x &lt;- as.bed.matrix(x=LCT.matrix.bed, fam=LCT.matrix.fam, bim=LCT.snps)

#Add population
x@ped[,c("pop", "superpop")] &lt;- LCT.matrix.pop1000G[,c("population", "super.population")]

#Select EUR superpopulation
x &lt;- select.inds(x, superpop=="EUR")
x@ped$pop &lt;- droplevels(x@ped$pop)

#Perform association test
x.freq.asso &lt;- multinomial.asso.freq(x, test = "Genotypic",
                                     pheno = x@ped$pop)
</code></pre>

<hr>
<h2 id='NullObject.parameters'> Null Model for SKAT and burden tests </h2><span id='topic+NullObject.parameters'></span>

<h3>Description</h3>

<p> Get the parameters under the null model to peforms burden tests or SKAT</p>


<h3>Usage</h3>

<pre><code class='language-R'>  NullObject.parameters(pheno, RVAT, pheno.type = c("categorical", "continuous"), 
                        ref.level, data, formula)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NullObject.parameters_+3A_pheno">pheno</code></td>
<td>
<p> The phenotype of each individual: a factor if <code>pheno.type = "categorical"</code>, and a numeric vector if <code>pheno.type = "continuous"</code> </p>
</td></tr>
<tr><td><code id="NullObject.parameters_+3A_rvat">RVAT</code></td>
<td>
<p> The type of Rare Variant Association Test (RVAT) to perform: should be &quot;burden&quot; or &quot;SKAT&quot;</p>
</td></tr>
<tr><td><code id="NullObject.parameters_+3A_pheno.type">pheno.type</code></td>
<td>
<p> The type of phenotype: &quot;categorical&quot; for binary or multinomial traits, or &quot;continuous&quot;</p>
</td></tr>
<tr><td><code id="NullObject.parameters_+3A_ref.level">ref.level</code></td>
<td>
<p> The reference group of individuals for the regression, only needed if <code>RVAT = "burden"</code> and <code>pheno.type = "categorical"</code></p>
</td></tr>
<tr><td><code id="NullObject.parameters_+3A_data">data</code></td>
<td>
<p> Optional, a matrix containing the covariates with one column per covariate and one row per individual </p>
</td></tr>
<tr><td><code id="NullObject.parameters_+3A_formula">formula</code></td>
<td>
<p> Optional, an R formula corresponding to the regression model indicating which covariates from <code>data</code> to include in the model if only some of them are to be included</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Warning: individuals in <code>pheno</code> and <code>data</code> should be in the same order.  
</p>
<p>This function gets the parameters under the null model for SKAT or the burden tests.  
</p>
<p>For burden tests, it computes the Log-Likelihood under the null model used to perform the Likelihood Ratio Test.   
</p>
<p>For SKAT, it computes the probabilites for each individual of belonging to each group based on the group sizes and the potential covariates.  
</p>
<p>If <code>formula</code> is missing, all columns from <code>data</code> will be included as covariates.
</p>


<h3>Value</h3>

<p>A list containing different elements depending on the <code>RVAT</code> performed and the <code>pheno.type</code>.  
</p>
<p>- if <code>RVAT = "burden"</code> and <code>pheno.type = "categorical"</code>:
</p>
<table>
<tr><td><code>group</code></td>
<td>
<p>A factor containing the group of each individual as given</p>
</td></tr>
<tr><td><code>ref.level</code></td>
<td>
<p> The reference group of individuals for the regression as given</p>
</td></tr>
<tr><td><code>H0.LogLik</code></td>
<td>
<p> The Log-Likelihood of the null model</p>
</td></tr>
<tr><td><code>covar.toinclude</code></td>
<td>
<p> Which covariates to include in the regression, depends on the argument <code>formula</code> </p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p> The <code>data</code> argument containing covariates, NULL if it was missing</p>
</td></tr>   
</table>
<p>- if <code>RVAT = "burden"</code> and <code>pheno.type = "continuous"</code>:
</p>
<table>
<tr><td><code>pheno</code></td>
<td>
<p>A numeric vector containing the phenotype value for each individual as given</p>
</td></tr>
<tr><td><code>covar.toinclude</code></td>
<td>
<p> Which covariates to include in the regression, depends on the argument <code>formula</code> </p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p> The <code>data</code> argument containing covariates, NULL if it was missing</p>
</td></tr>   
</table>
<p>- if <code>RVAT = "SKAT"</code> and <code>pheno.type = "categorical"</code>:  
</p>
<table>
<tr><td><code>Pi.data</code></td>
<td>
<p> A matrix n.individuals x n.groups containing the probabilities that each individual belong to each group </p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p> A matrix containing 1 in the first column for the intercept, and covariates from <code>data</code> and <code>formula</code></p>
</td></tr>
<tr><td><code>group</code></td>
<td>
<p> A factor containing the group of each individual as given</p>
</td></tr>
<tr><td><code>get.moments</code></td>
<td>
<p> How to compute moments based on sample size for p-value calculations (only used if <code>get.moments = "size.based"</code> for a categorical phenotype in <code>SKAT</code>. </p>
</td></tr>
<tr><td><code>P1</code></td>
<td>
<p> The vairance-covariance matrix of (Y - Pi_hat)</p>
</td></tr>   
</table>
<p>- if <code>RVAT = "SKAT"</code> and <code>pheno.type = "continuous"</code>:
</p>
<table>
<tr><td><code>ymp</code></td>
<td>
<p> A matrix n.individuals x 1 containing the (y - pi_hat) values, i.e. the residuals from the regression of the phenotype on the potential covariates </p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p> A matrix containing 1 in the first column for the intercept, and covariates from <code>data</code> and <code>formula</code></p>
</td></tr>
<tr><td><code>pheno</code></td>
<td>
<p> The phenotype of each individual as given</p>
</td></tr>
<tr><td><code>P1</code></td>
<td>
<p> The variance matrix of <code>ymp</code> </p>
</td></tr>
</table>


<h3>See Also</h3>

 <p><code><a href="#topic+SKAT">SKAT</a></code>, <code><a href="#topic+burden">burden</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Random phenotype of 100 individuals 
random.multi.pheno &lt;- sample(1:3, 100, replace = TRUE)
#Random continuous phenotype
random.continuous.pheno &lt;- rnorm(100)
#Random sex covariate
random.covar &lt;- matrix( sample(1:2, prob = c(0.4, 0.6), size = 100, replace = TRUE),
                        ncol = 1 )

#Null Model for burden with a multinomi-category phenotype
#Controls as reference group, no covariates
H0.burden.multi &lt;- NullObject.parameters(pheno = as.factor(random.multi.pheno), 
                                         RVAT = "burden", pheno.type = "categorical", ref.level = 1)
#Null Model for SKAT with a continuous phenotype and a covariate
H0.SKAT.continuous &lt;- NullObject.parameters(pheno = random.continuous.pheno,
                                            RVAT = "SKAT", pheno.type = "continuous",
                                            data = random.covar)
</code></pre>

<hr>
<h2 id='RAVA.FIRST'>
RAVA-FIRST: RAre Variant Association using Functionally-InfoRmed STeps
</h2><span id='topic+RAVA.FIRST'></span>

<h3>Description</h3>

<p>Analyse rare variants using the RAVA-FIRST approach based on CADD scores to group and filter rare variants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RAVA.FIRST(x, SNVs.scores = NULL, indels.scores = NULL, ref.level, 
           filter=c("whole", "controls", "any"), 
           maf.threshold=0.01, min.nb.snps = 2, 
           min.cumulative.maf = NULL, group = NULL, 
           cores = 10, burden = TRUE, H0.burden, burden.parameters, 
           SKAT = TRUE, H0.SKAT, SKAT.parameters, verbose = TRUE, path.data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RAVA.FIRST_+3A_x">x</code></td>
<td>
<p> A bed.matrix </p>
</td></tr>
<tr><td><code id="RAVA.FIRST_+3A_snvs.scores">SNVs.scores</code></td>
<td>
<p> A dataframe containing the ADJUSTED CADD scores of the SNVs (Optional, useful to gain in computation time if the adjusted CADD scores of variants in the study are available)</p>
</td></tr>
<tr><td><code id="RAVA.FIRST_+3A_indels.scores">indels.scores</code></td>
<td>
<p> A dataframe containing the CADD PHREDv1.4 scores of the indels - Compulsory if indels are present in <code>x</code></p>
</td></tr>
<tr><td><code id="RAVA.FIRST_+3A_ref.level">ref.level</code></td>
<td>
<p> The level corresponding to the controls group, only needed if <code>filter=="controls"</code> </p>
</td></tr>
<tr><td><code id="RAVA.FIRST_+3A_filter">filter</code></td>
<td>
<p> On which group the MAF filter will be applied </p>
</td></tr>
<tr><td><code id="RAVA.FIRST_+3A_maf.threshold">maf.threshold</code></td>
<td>
<p> The MAF threshold used to define a rare variant, set at 0.01 by default</p>
</td></tr>
<tr><td><code id="RAVA.FIRST_+3A_min.nb.snps">min.nb.snps</code></td>
<td>
<p> The minimum number of variants needed to keep a CADD region, set at 2 by default</p>
</td></tr>
<tr><td><code id="RAVA.FIRST_+3A_min.cumulative.maf">min.cumulative.maf</code></td>
<td>
<p> The minimum cumulative maf of variants needed to keep a CADD region</p>
</td></tr>
<tr><td><code id="RAVA.FIRST_+3A_group">group</code></td>
<td>
<p> A factor indicating the group of each individual, only needed if <code>filter = "controls"</code> or <code>filter = "any"</code>. If missing, <code>x@ped$pheno</code> is taken</p>
</td></tr>
<tr><td><code id="RAVA.FIRST_+3A_cores">cores</code></td>
<td>
<p> How many cores to use, set at 10 by default</p>
</td></tr>
<tr><td><code id="RAVA.FIRST_+3A_burden">burden</code></td>
<td>
<p> Whether to compute the burden test</p>
</td></tr>
<tr><td><code id="RAVA.FIRST_+3A_h0.burden">H0.burden</code></td>
<td>
<p>A list returned from <code>NullObject.parameters</code> with <code>RVAT="burden"</code> </p>
</td></tr>
<tr><td><code id="RAVA.FIRST_+3A_burden.parameters">burden.parameters</code></td>
<td>
<p> A list containing the parameters to use by <code>burden.subscores</code> for the burden analysis ('burden.function' and 'get.effect.size')</p>
</td></tr>
<tr><td><code id="RAVA.FIRST_+3A_skat">SKAT</code></td>
<td>
<p> Whether to compute SKAT</p>
</td></tr>
<tr><td><code id="RAVA.FIRST_+3A_h0.skat">H0.SKAT</code></td>
<td>
<p>A list returned from <code>NullObject.parameters</code> with <code>RVAT="SKAT"</code> </p>
</td></tr>
<tr><td><code id="RAVA.FIRST_+3A_skat.parameters">SKAT.parameters</code></td>
<td>
<p> A list containing the parameters to use by <code>SKAT</code> ('get.moments', 'estimation.pvalue', 'params.sampling', 'debug')</p>
</td></tr>
<tr><td><code id="RAVA.FIRST_+3A_verbose">verbose</code></td>
<td>
<p> Whether to display information about the function actions </p>
</td></tr>
<tr><td><code id="RAVA.FIRST_+3A_path.data">path.data</code></td>
<td>
<p> The repository where data for RAVA-FIRST are or will be downloaded from https://lysine.univ-brest.fr/RAVA-FIRST/</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Rare variants are analysed using the 'RAVA-FIRST' strategy composed of three steps:  
- Rare variants are grouped in 'CADD regions' defined from the CADD scores of variants observed in GnomAD.  
- Rare variant are selected within each CADD region based on an adjusted CADD score using a region-specific threshold corresponding to the median of scores observed in GnomAD in each region.  
- Burden analysis is performed by integrating sub-scores for the coding, regulatory and intergenic categories within each CADD region. For SKAT analysis, a test for each CADD region is performed.  
</p>
<p>RAVA.FIRST() is based on the functions <code>set.CADDregions</code>, <code>filter.adjustedCADD</code>, <code>burden.subscores</code> and <code>SKAT</code>. Please refer to these functions for more information.
Especially, refer to the functions <code>burden.subscores</code> and <code>SKAT</code> to get more information about what is need in <code>burden.parameters</code> and <code>SKAT.parameters</code>.   
</p>
<p>It is recommended to use this function chromosome by chromosome for large datasets.
</p>


<h3>Value</h3>

<p>A list containing the results for the burden analysis ('burden') and the results for the SKAT analysis ('SKAT'), along with information about CADD regions (positions, type of genomic categories overlapped by each region and median of adjusted CADD scores).
</p>


<h3>Source</h3>

<p>https://lysine.univ-brest.fr/RAVA-FIRST/</p>


<h3>See Also</h3>

<p><code>set.CADDregions</code>, <code>filter.adjustedCADD</code>, <code>burden.subscores</code>, <code>SKAT</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Import 1000Genome data from region around LCT gene
#x &lt;- as.bed.matrix(x=LCT.matrix.bed, fam=LCT.matrix.fam, bim=LCT.snps)

#Add population
#x@ped[,c("pop", "superpop")] &lt;- LCT.matrix.pop1000G[,c("population", "super.population")]

#Select EUR superpopulation
#x &lt;- select.inds(x, superpop=="EUR")
#x@ped$pop &lt;- droplevels(x@ped$pop)

#Remove indels from the bed matrix
#x &lt;- select.snps(x, nchar(A1)==1 &amp; nchar(A2)==1)

#Perform RAVA-FIRST with burden analysis
#H0.burden &lt;- NullObject.parameters(pheno = x@ped$pop, ref.level = "CEU",
#                                   RVAT = "burden", pheno.type = "categorical")
#res.burden &lt;- RAVA.FIRST(x, maf.threshold = 0.05,
#                         H0.burden = H0.burden, SKAT = F)
</code></pre>

<hr>
<h2 id='rbm.GRR'>
Simulation of genetic data using GRR values
</h2><span id='topic+rbm.GRR'></span>

<h3>Description</h3>

<p>Generates a simulated bed.matrix with genotypes for cases and controls based on GRR values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rbm.GRR(genes.maf = Kryukov, size, prev, replicates, 
        GRR.matrix.del, GRR.matrix.pro = NULL, 
        p.causal = 0.5, p.protect = 0, same.variant = FALSE, 
        genetic.model=c("general", "multiplicative", "dominant", "recessive"), 
        select.gene, selected.controls = T, max.maf.causal = 0.01)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rbm.GRR_+3A_genes.maf">genes.maf</code></td>
<td>
<p> A dataframe containing at least the MAF in the general population (column maf) for variants with their associated gene (column gene), by default the file <code>Kryukov</code> is used</p>
</td></tr>
<tr><td><code id="rbm.GRR_+3A_size">size</code></td>
<td>
<p> A vector containing the size of each group (the first one being the control group)</p>
</td></tr>
<tr><td><code id="rbm.GRR_+3A_prev">prev</code></td>
<td>
<p> A vector containing the prevalence of each group of cases</p>
</td></tr>
<tr><td><code id="rbm.GRR_+3A_replicates">replicates</code></td>
<td>
<p> The number of simulations to perform </p>
</td></tr>
<tr><td><code id="rbm.GRR_+3A_grr.matrix.del">GRR.matrix.del</code></td>
<td>
<p> A list containing the GRR matrix associated to the heterozygous genotype compared to the homozygous reference genotype as if all variants are deleterious. An additional GRR matrix associated to the homozygous for the alternate allele is needed if <code>genetic.genetic.model="general"</code></p>
</td></tr>
<tr><td><code id="rbm.GRR_+3A_grr.matrix.pro">GRR.matrix.pro</code></td>
<td>
<p> The same argument as <code>GRR.matrix.del</code> but for protective variants</p>
</td></tr>
<tr><td><code id="rbm.GRR_+3A_p.causal">p.causal</code></td>
<td>
<p> The proportion of causal variants in cases</p>
</td></tr>
<tr><td><code id="rbm.GRR_+3A_p.protect">p.protect</code></td>
<td>
<p> The proportion of protective variants in cases among causal variants</p>
</td></tr>
<tr><td><code id="rbm.GRR_+3A_same.variant">same.variant</code></td>
<td>
<p> TRUE/FALSE: whether the causal variants are the same in the different groups of cases</p>
</td></tr>
<tr><td><code id="rbm.GRR_+3A_genetic.model">genetic.model</code></td>
<td>
<p> The genetic model of the disease </p>
</td></tr>
<tr><td><code id="rbm.GRR_+3A_select.gene">select.gene</code></td>
<td>
<p> Which gene to choose from <code>genes.maf$gene</code> if multiple genes are present. If missing, only the first level is kept.</p>
</td></tr>
<tr><td><code id="rbm.GRR_+3A_selected.controls">selected.controls</code></td>
<td>
<p> Whether controls are selected controls (by default) or controls from the general population</p>
</td></tr>
<tr><td><code id="rbm.GRR_+3A_max.maf.causal">max.maf.causal</code></td>
<td>
<p> Only variants with a MAF lower than this threshold can be sampled as causal variants. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The genetic model of the disease needs to be specified in this function.
</p>
<p>If <code>genetic.model="general"</code>, there is no link between the GRR for the heterozygous genotype and the GRR for the homozygous alternative genotype. 
Therefore, the user has to give two matrices of GRR, one for the heterozygous genotype, the other for the homozygous alternative genotype.
</p>
<p>If <code>genetic.model="multiplicative"</code>, we assume that the the GRR for the homozygous alternative genotype is the square of the GRR for the heterozygous genotype. 
</p>
<p>If <code>genetic.model="dominant"</code>, we assume that the GRR for the heterozygous genotype and the GRR for the homozygous alternative genotype are equal.
</p>
<p>If <code>genetic.model="recessive"</code>, we assume that the GRR for the heterozygous genotype is equal to 1: the GRR given is the one associated to the homozygous alternative genotype.
</p>
<p><code>GRR.matrix.del</code> contains GRR values as if all variants are deleterious. These values will be used only for the proportion <code>p.causal</code> of variants that will be sampled as causal.  
</p>
<p>If <code>selected.controls</code> = T, genotypic frequencies in the control group are computed from genotypic frequencies in the cases groups and the prevalence of the disease.
If FALSE, genotypic frequencies in the control group are computed from allelic frequencies under Hardy-Weinberg equilibrium.  
</p>
<p>The files <code>Kryukov</code> or <code>GnomADgenes</code> available with the package Ravages can be used as the argument <code>genes.maf</code>.
</p>
<p>If <code>GRR.matrix.del</code> (or <code>GRR.matrix.pro</code>) has been generated using the function <code>GRR.matrix</code>, the arguments <code>genes.maf</code> and <code>select.gene</code> should have
the same value as in <code>GRR.matrix</code>.
</p>
<p>Only non-monomorphic variants are kept for the simulations.  
</p>
<p>Causal variants that have been sampled in each group of individuals are indicated in <code>x@ped$Causal</code>.
</p>


<h3>Value</h3>

<p>A bed.matrix with as much columns (variants) as <code>replicates</code>*number of variants.
The field <code>x@snps$genomic.region</code> contains the replicate number and the field <code>x@ped$pheno</code> contrains the group of each individual, &quot;0&quot; being the controls group.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+GRR.matrix">GRR.matrix</a></code>, <code><a href="#topic+Kryukov">Kryukov</a></code>, <code><a href="#topic+GnomADgenes">GnomADgenes</a></code>, <code><a href="#topic+rbm.GRR.power">rbm.GRR.power</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#GRR values calculated with the SKAT formula
GRR.del &lt;- GRR.matrix(GRR = "SKAT", genes.maf = Kryukov, 
                      n.case.groups = 2, select.gene = "R1",
                      GRR.multiplicative.factor=2)
                              
#Simulation of one group of 1,000 controls and two groups of 500 cases, 
#each one with a prevalence of 0.001
#with 50% of causal variants, 5 genomic regions are simulated.
x &lt;- rbm.GRR(genes.maf = Kryukov, size = c(1000, 500, 500), 
             prev = c(0.001, 0.001), GRR.matrix.del = GRR.del, 
             p.causal = 0.5, p.protect = 0, select.gene="R1",
             same.variant = FALSE, 
             genetic.model = "multiplicative", replicates = 5)
</code></pre>

<hr>
<h2 id='rbm.GRR.power'>
Power of RVAT based on simulations and theoretical calculations (CAST) with GRR
</h2><span id='topic+rbm.GRR.power'></span>

<h3>Description</h3>

<p>Computes the power of the tests CAST, WSS and SKAT based on simulations with GRR and based on theoretical calculations for CAST
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rbm.GRR.power(genes.maf = Kryukov, size = c(500, 500), prev = 0.01, 
              GRR.matrix.del, GRR.matrix.pro = NULL, 
              p.causal = 0.5, p.protect = 0, same.variant = FALSE, 
              genetic.model=c("multiplicative", "general", "dominant", "recessive"), 
              select.gene, alpha = 2.5e-6, selected.controls = TRUE, 
              power.type = c("simulations", "theoretical"), verbose = TRUE, 
              RVAT = c("CAST", "WSS", "SKAT"), 
              SKAT.method = c("permutations", "theoretical"),
              max.maf.causal = 0.01, maf.filter = max.maf.causal, 
              replicates = 1000, cores = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rbm.GRR.power_+3A_genes.maf">genes.maf</code></td>
<td>
<p> A dataframe containing at least the MAF in the general population (column maf) for variants with their associated gene (column gene), by default the file <code>Kryukov</code> is used</p>
</td></tr>
<tr><td><code id="rbm.GRR.power_+3A_size">size</code></td>
<td>
<p> A vector containing the size of each group (the first one being the control group)</p>
</td></tr>
<tr><td><code id="rbm.GRR.power_+3A_prev">prev</code></td>
<td>
<p> A vector containing the prevalence of each group of cases</p>
</td></tr>
<tr><td><code id="rbm.GRR.power_+3A_grr.matrix.del">GRR.matrix.del</code></td>
<td>
<p> A list containing the GRR matrix associated to the heterozygous genotype compared to the homozygous reference genotype as if all variants are deleterious. An additional GRR matrix associated to the homozygous for the alternate allele is needed if <code>genetic.genetic.model="general"</code></p>
</td></tr>
<tr><td><code id="rbm.GRR.power_+3A_grr.matrix.pro">GRR.matrix.pro</code></td>
<td>
<p> The same argument as <code>GRR.matrix.del</code> but for protective variants</p>
</td></tr>
<tr><td><code id="rbm.GRR.power_+3A_p.causal">p.causal</code></td>
<td>
<p> The proportion of causal variants in cases</p>
</td></tr>
<tr><td><code id="rbm.GRR.power_+3A_p.protect">p.protect</code></td>
<td>
<p> The proportion of protective variants in cases among causal variants</p>
</td></tr>
<tr><td><code id="rbm.GRR.power_+3A_same.variant">same.variant</code></td>
<td>
<p> TRUE/FALSE: whether the causal variants are the same in the different groups of cases</p>
</td></tr>
<tr><td><code id="rbm.GRR.power_+3A_genetic.model">genetic.model</code></td>
<td>
<p> The genetic model of the disease </p>
</td></tr>
<tr><td><code id="rbm.GRR.power_+3A_select.gene">select.gene</code></td>
<td>
<p> Which gene to choose from <code>genes.maf$gene</code> if multiple genes are present. If missing, only the first level is kept.</p>
</td></tr>
<tr><td><code id="rbm.GRR.power_+3A_alpha">alpha</code></td>
<td>
<p> The significance level to compute the power</p>
</td></tr>
<tr><td><code id="rbm.GRR.power_+3A_selected.controls">selected.controls</code></td>
<td>
<p> Whether controls are selected controls (by default) or controls from the general population</p>
</td></tr>
<tr><td><code id="rbm.GRR.power_+3A_power.type">power.type</code></td>
<td>
<p> Whether to compute the power based on 'simulations' (by default) or 'theoretical' calculations (only for CAST)</p>
</td></tr>
<tr><td><code id="rbm.GRR.power_+3A_verbose">verbose</code></td>
<td>
<p> Whether to print details about the running function</p>
</td></tr>
<tr><td><code id="rbm.GRR.power_+3A_rvat">RVAT</code></td>
<td>
<p> On which RVAT among 'CAST', 'WSS' and 'SKAT' to compute power (only needed if <code>power.type="simulations"</code> </p>
</td></tr>
<tr><td><code id="rbm.GRR.power_+3A_skat.method">SKAT.method</code></td>
<td>
<p> Which method to use to compute SKAT ppower, i.e. permutations or theoretical moments (cf <code>SKAT</code> documentation)</p>
</td></tr>
<tr><td><code id="rbm.GRR.power_+3A_max.maf.causal">max.maf.causal</code></td>
<td>
<p> The maf threshold to consider a causal variant  (set at 0.01 by default)</p>
</td></tr>
<tr><td><code id="rbm.GRR.power_+3A_maf.filter">maf.filter</code></td>
<td>
<p> The MAF filter to apply after the simulations to select rare variants to keep for RVAT power analysis. By default corresponds to <code>max.maf.causal</code></p>
</td></tr>
<tr><td><code id="rbm.GRR.power_+3A_replicates">replicates</code></td>
<td>
<p> On how many replicates the power should be computed</p>
</td></tr>
<tr><td><code id="rbm.GRR.power_+3A_cores">cores</code></td>
<td>
<p> How many cores to use for moments computation, set at 10 by default </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Simulations are performed in the same was as in <code>rbm.GRR</code>. Please refer to the documentation of this function.  
</p>
<p>Theoretical power is only available for CAST for which a non-central Chi-squared is used.   
</p>
<p>Variants are filtered after the simulations to keep only the rare ones, defined by <code>maf.filter</code>. By defaut, it corresponds to <code>max.maf.causal</code> is used. To disable this filter, set <code>maf.filter</code> at 0.5.
</p>


<h3>Value</h3>

<p>A single value giving the power of CAST if <code>power.type="theoretical"</code> or the power of <code>RVAT</code> if <code>power.type="simulations"</code>. 
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+GRR.matrix">GRR.matrix</a></code>, <code><a href="#topic+Kryukov">Kryukov</a></code>, <code><a href="#topic+GnomADgenes">GnomADgenes</a></code>, <code><a href="#topic+rbm.GRR">rbm.GRR</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#GRR values calculated with the SKAT formula
GRR.del &lt;- GRR.matrix(GRR = "SKAT", genes.maf = Kryukov, 
                      n.case.groups = 2, select.gene = "R1",
                      GRR.multiplicative.factor=2)
                              
#Simulation of one group of 1,000 controls and two groups of 500 cases, 
#each one with a prevalence of 0.001
#with 50% of causal variants, 5 genomic regions are simulated.
rbm.GRR.power(genes.maf = Kryukov, size = c(1000, 500, 500), 
              prev = c(0.001, 0.001), GRR.matrix.del = GRR.del, 
              p.causal = 0.5, p.protect = 0, select.gene="R1",
              same.variant = FALSE, genetic.model = "multiplicative", 
              power.type="theoretical", cores = 1, alpha = c(0.001,2.5e-6))
</code></pre>

<hr>
<h2 id='rbm.haplos.freqs'>
Simulation of genetic data based on haplotypic frequencies
</h2><span id='topic+rbm.haplos.freqs'></span>

<h3>Description</h3>

<p>Simulates genetic data with respect to allele frequency spectrum and linkage disequilibrium pattern observed on given haplotypes and their frequencies
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  rbm.haplos.freqs(haplos, freqs, size, replicates)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rbm.haplos.freqs_+3A_haplos">haplos</code></td>
<td>
<p> A matrix of haplotypes with one row per haplotype and one column per variant</p>
</td></tr>
<tr><td><code id="rbm.haplos.freqs_+3A_freqs">freqs</code></td>
<td>
<p> A matrix of haplotypes frequencies in each group of individuals</p>
</td></tr>
<tr><td><code id="rbm.haplos.freqs_+3A_size">size</code></td>
<td>
<p> The sizes of each group of individuals</p>
</td></tr>
<tr><td><code id="rbm.haplos.freqs_+3A_replicates">replicates</code></td>
<td>
<p> The number of simulations to perform</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Simulations are performed to respect linkage disequilibrium pattern and allelic frequency spectrum in each group of individuals
The phenotypic values will be the colnames of <code>freqs</code> and stored in <code>@ped$pheno</code>. The simulation number will be in <code>@snps$genomic.region</code>.
</p>


<h3>Value</h3>

<table>
<tr><td><code>x</code></td>
<td>
<p> A bed matrix with simulated genotypes</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>  #Simulations of 5 groups of individuals with haplotypes frequencies
  #from the 5 EUR populations

  #Load LCT dataset for haplotype matrix
  data(LCT.haplotypes)
  #Haplotypes for the variants in the LCT gene in the EUR population
  LCT.gene.hap &lt;- LCT.hap[which(LCT.sample$super.population=="EUR"),
                         which(LCT.snps$pos&gt;=136545410 &amp; LCT.snps$pos&lt;=136594750)]

  #Individuals from EUR
  LCT.sample.EUR &lt;- subset(LCT.sample, super.population=="EUR")
  #Matrix of haplotypic frequencies
  LCT.freqs &lt;- sapply(unique(LCT.sample.EUR$population), function(z) 
                      ifelse(LCT.sample.EUR$population==z, 
                             1/table(LCT.sample.EUR$population)[z], 0))

  #Simulation of genetic data for five groups of 50 individuals
  x &lt;- rbm.haplos.freqs(haplos=LCT.gene.hap, freqs=LCT.freqs, size=rep(50,5), replicates=5)
</code></pre>

<hr>
<h2 id='rbm.haplos.power'>
Power of RVAT based on simulations with haplotypes
</h2><span id='topic+rbm.haplos.power'></span>

<h3>Description</h3>

<p>Computes the power of the tests CAST, WSS and SKAT based on simulations with haplotypes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  rbm.haplos.power(haplos, freqs, weights = "SKAT", 
                   max.maf.causal = 0.01, maf.filter = max.maf.causal, p.causal = 0.5, 
                   p.protect = 0, h2 = c(0.01, 0.01), prev = c(1, 0.01),
                   normal.approx = TRUE, size = c(500, 500), verbose = TRUE,
                   alpha = 2.5e-6, RVAT = c("CAST", "WSS", "SKAT"),
                   SKAT.method = c("permutations", "theoretical"),
                   simus.haplos = c("freqs", "liability"), 
                   replicates = 1000, rep.by.causal = 50, cores = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rbm.haplos.power_+3A_haplos">haplos</code></td>
<td>
<p> A matrix of haplotypes with one row per haplotype and one column per variant</p>
</td></tr>
<tr><td><code id="rbm.haplos.power_+3A_freqs">freqs</code></td>
<td>
<p> A matrix of haplotypes frequencies in each group of individuals, only needed if <code>simus.haplos = "freqs"</code> </p>
</td></tr>
<tr><td><code id="rbm.haplos.power_+3A_weights">weights</code></td>
<td>
<p> How to weight rare variants (if &quot;constant&quot;, all variants have the same weight, if &quot;SKAT&quot;, the rarest variants have the highest weights: weights = -0.4*log10(MAF) )</p>
</td></tr>
<tr><td><code id="rbm.haplos.power_+3A_max.maf.causal">max.maf.causal</code></td>
<td>
<p> The maf threshold to consider a rare variant  (set at 0.01 by default). Only variants with a MAF upper than this threshold will be kept to compute RVAT power. If <code>simus.haplos="liability"</code>, variants with a MAF upper this threshold will have a weight of 0</p>
</td></tr>
<tr><td><code id="rbm.haplos.power_+3A_maf.filter">maf.filter</code></td>
<td>
<p> The MAF filter to apply after the simulations to select rare variants to keep for RVAT power analysis. By default corresponds to <code>max.maf.causal</code></p>
</td></tr>
<tr><td><code id="rbm.haplos.power_+3A_p.causal">p.causal</code></td>
<td>
<p> The percentage of causal variants, only needed if <code>simus.haplos = "liability"</code></p>
</td></tr>
<tr><td><code id="rbm.haplos.power_+3A_p.protect">p.protect</code></td>
<td>
<p> The proportion of protective variants among causal variants, only needed if <code>simus.haplos = "liability"</code></p>
</td></tr>
<tr><td><code id="rbm.haplos.power_+3A_h2">h2</code></td>
<td>
<p> The variance explained by the gene, only needed if <code>simus.haplos = "liability"</code></p>
</td></tr>
<tr><td><code id="rbm.haplos.power_+3A_prev">prev</code></td>
<td>
<p> A vector with the prevalence in each group of individuals, only needed if <code>simus.haplos = "liability"</code></p>
</td></tr>
<tr><td><code id="rbm.haplos.power_+3A_normal.approx">normal.approx</code></td>
<td>
<p> TRUE/FALSE: whether to use the normal approximation to compute thresholds. Set at TRUE by default, only needed if <code>simus.haplos = "liability"</code></p>
</td></tr>
<tr><td><code id="rbm.haplos.power_+3A_size">size</code></td>
<td>
<p> The sizes of each group of individuals</p>
</td></tr>
<tr><td><code id="rbm.haplos.power_+3A_verbose">verbose</code></td>
<td>
<p> Whether to display information about the function actions </p>
</td></tr>
<tr><td><code id="rbm.haplos.power_+3A_alpha">alpha</code></td>
<td>
<p> The significance level to compute the power</p>
</td></tr>
<tr><td><code id="rbm.haplos.power_+3A_rvat">RVAT</code></td>
<td>
<p> On which RVAT among 'CAST', 'WSS' and 'SKAT' to compute power (only needed if <code>power.type="simulations"</code> </p>
</td></tr>
<tr><td><code id="rbm.haplos.power_+3A_skat.method">SKAT.method</code></td>
<td>
<p> Which method to use to compute SKAT ppower, i.e. permutations or theoretical moments (cf <code>SKAT</code> documentation)</p>
</td></tr>
<tr><td><code id="rbm.haplos.power_+3A_simus.haplos">simus.haplos</code></td>
<td>
<p> Which method to simulate the data, if <code>simus.haplos="freqs"</code>, rbm.haplos.freqs() is used, otherwise <code>rbm.haplos.thresholds()</code> is used.</p>
</td></tr>
<tr><td><code id="rbm.haplos.power_+3A_replicates">replicates</code></td>
<td>
<p> The number of simulations to perform to estimate the power</p>
</td></tr>
<tr><td><code id="rbm.haplos.power_+3A_rep.by.causal">rep.by.causal</code></td>
<td>
<p> The number of time causal variants will be sampled</p>
</td></tr>
<tr><td><code id="rbm.haplos.power_+3A_cores">cores</code></td>
<td>
<p> How many cores to use for moments computation, set at 10 by default </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Simulations are perfromed accordingly to <code>rbm.haplos.thresholds()</code> or <code>rbm.haplos.freqs()</code>. Please refer to the corresponding manuals for more details on the simulation procedures.  
Variants are filtered after the simulations to keep only the rare ones, defined by <code>maf.filter</code>. By defaut, it corresponds to <code>max.maf.causal</code> is used. To disable this filter, set <code>maf.filter</code> at 0.5.
</p>


<h3>Value</h3>

<p>Power values of <code>RVAT</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  #Simulations of 5 groups of individuals with haplotypes frequencies
  #from the 5 EUR populations

  #Load LCT dataset for haplotype matrix
  data(LCT.haplotypes)
  #Haplotypes for the variants in the LCT gene in the EUR population
  LCT.gene.hap &lt;- LCT.hap[which(LCT.sample$super.population=="EUR"),
                          which(LCT.snps$pos&gt;=136545410 &amp; LCT.snps$pos&lt;=136594750)]

  #Individuals from EUR
  LCT.sample.EUR &lt;- subset(LCT.sample, super.population=="EUR")
  #Matrix of haplotypic frequencies
  LCT.freqs &lt;- sapply(unique(LCT.sample.EUR$population), function(z)
                      ifelse(LCT.sample.EUR$population==z,
                             1/table(LCT.sample.EUR$population)[z], 0))

  #Simulation of genetic data for five groups of 50 individuals
  rbm.haplos.power(haplos=LCT.gene.hap, freqs=LCT.freqs, size=rep(50,5), 
                   replicates=5, rep.by.causal = 5,  RVAT = "CAST", 
                   alpha = c(0.001,2.5e-6), cores = 1)

</code></pre>

<hr>
<h2 id='rbm.haplos.thresholds'>
Simulation of genetic data based on haplotypes and a libaility model
</h2><span id='topic+rbm.haplos.thresholds'></span>

<h3>Description</h3>

<p>Simulates genetic data with respect to allele frequency spectrum and linkage disequilibrium pattern observed on given haplotype data under a libaility model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  rbm.haplos.thresholds(haplos, weights = c("SKAT", "constant"), 
                        max.maf.causal = 0.01, p.causal = 0.5, p.protect = 0, 
                        h2, prev, normal.approx = TRUE, size, 
                        replicates, rep.by.causal, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rbm.haplos.thresholds_+3A_haplos">haplos</code></td>
<td>
<p> A matrix of haplotypes with one row per haplotype and one column per variant</p>
</td></tr>
<tr><td><code id="rbm.haplos.thresholds_+3A_weights">weights</code></td>
<td>
<p> How to weight rare variants (if &quot;constant&quot;, all variants have the same weight, if &quot;SKAT&quot;, the rarest variants have the highest weights as in the SKAT paper: weights = -0.4*log10(MAF) )</p>
</td></tr>
<tr><td><code id="rbm.haplos.thresholds_+3A_max.maf.causal">max.maf.causal</code></td>
<td>
<p> The maf threshold to consider a rare variant  (set at 0.01 by default), variants with a MAF upper this threshold will have a weight of 0</p>
</td></tr>
<tr><td><code id="rbm.haplos.thresholds_+3A_p.causal">p.causal</code></td>
<td>
<p> The proportion of causal variants</p>
</td></tr>
<tr><td><code id="rbm.haplos.thresholds_+3A_p.protect">p.protect</code></td>
<td>
<p> The proportion of protective variants among causal variants</p>
</td></tr>
<tr><td><code id="rbm.haplos.thresholds_+3A_h2">h2</code></td>
<td>
<p> The variance explained by the gene</p>
</td></tr>
<tr><td><code id="rbm.haplos.thresholds_+3A_prev">prev</code></td>
<td>
<p> A vector with the prevalence in each group of individuals</p>
</td></tr>
<tr><td><code id="rbm.haplos.thresholds_+3A_normal.approx">normal.approx</code></td>
<td>
<p> TRUE/FALSE: whether to use the normal approximation to compute thresholds. Set at TRUE by default</p>
</td></tr>
<tr><td><code id="rbm.haplos.thresholds_+3A_size">size</code></td>
<td>
<p> The sizes of each group of individuals</p>
</td></tr>
<tr><td><code id="rbm.haplos.thresholds_+3A_replicates">replicates</code></td>
<td>
<p> The number of simulations to perform</p>
</td></tr>
<tr><td><code id="rbm.haplos.thresholds_+3A_rep.by.causal">rep.by.causal</code></td>
<td>
<p> The number of time causal variants will be sampled</p>
</td></tr>
<tr><td><code id="rbm.haplos.thresholds_+3A_verbose">verbose</code></td>
<td>
<p> Whether to display information about the function actions </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>nb.causal</code>, <code>p.protect</code>, <code>h2</code> and <code>prev</code> should be vectors of length corresponding to the number of groups to simulate. If they are of size 1, values will be duplicated. 
</p>
<p>All monomorphic variants and variants with a MAF higher than <code>max.maf.causal</code> will have a weight of 0. Causal variants are sampled among variants having weights greater than 0. Causal variants in each group of individuals are indicated in <code>x@ped$Causal</code>.  
</p>
<p>A liability model is built on haplotypes' burden computed on sampled causal variants using each variant's <code>weights</code>, and adjusted on the desired <code>h2</code>. Thresholds from this liability are then chosen to respect the given <code>prev</code> (from a standard normal distribution if <code>normal.approx=TRUE</code>, or using a distribution from 1e6 sampled burdens if <code>normal.approx=FALSE</code>). Please be carreful when using the normal approximation with high <code>h2</code> values or low <code>prev</code> values. 
Haplotypes' probabilities in each group of individuals are then computed and two haplotypes are then sampled for each individual based on these probabilities.  
</p>
<p>To simulate a group of controls, <code>prev</code> needs to be set at 1, regardless of the other arguments.  
</p>
<p>N <code>replicates</code> will be performed, and to gain in computation time, the same causal variants can be used for multiple replicates as different haplotypes will be sampled for each individual. <code>rep.by.causal</code> indicates the number of replicates to perform for each set of causal variants.
To ensure a variability in the simulations, we yet recommend to resample causal variants a few times when many replicates are to be performed. 
For example, if 1000 replicates are to be performed, we recommend to resample causal variants 20 times.  
</p>
<p>The phenotype will be stored in <code>@ped$pheno</code>, and the simulation number is <code>@snps$genomic.region</code>.
</p>


<h3>Value</h3>

<table>
<tr><td><code>x</code></td>
<td>
<p> A bed matrix with simulated genotypes</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
  #Load LCT dataset for haplotype matrix
  data(LCT.haplotypes)
  #LCT gene in the EUR population
  LCT.gene.hap &lt;- LCT.hap[which(LCT.sample$super.population=="EUR"), 
                          which(LCT.snps$pos&gt;=136545410 &amp; LCT.snps$pos&lt;=136594750)]

  #Simulation of 100 controls, and two groups of 50 cases with 30% causal variants
  #and with the second group having half h2 and twice the prevalence
  #compared to the first one
  #5 replicates are performed and causal variants are sampled once
  x &lt;- rbm.haplos.thresholds(haplos=LCT.gene.hap, max.maf.causal = 0.01, p.causal=0.3,
                             p.protect=0, h2=c(0.01, 0.01, 0.02), prev=c(1, 0.01, 0.005),
                             size=c(100, 50, 50), replicates = 5, rep.by.causal = 5)

</code></pre>

<hr>
<h2 id='set.CADDregions'> Variants annotation based on 'CADD regions' and genomic categories </h2><span id='topic+set.CADDregions'></span>

<h3>Description</h3>

<p>Attributes CADD regions and genomic categories to variants based on their positions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set.CADDregions(x, verbose = T, path.data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set.CADDregions_+3A_x">x</code></td>
<td>
<p> A bed.matrix </p>
</td></tr>
<tr><td><code id="set.CADDregions_+3A_verbose">verbose</code></td>
<td>
<p> Whether to display information about the function actions </p>
</td></tr>
<tr><td><code id="set.CADDregions_+3A_path.data">path.data</code></td>
<td>
<p> The repository where data for RAVA-FIRST are or will be downloaded from https://lysine.univ-brest.fr/RAVA-FIRST/</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To attribute variants to CADD regions and genomic categories, the files &quot;CADDRegions.2021.hg19.bed.gz&quot; and &quot;FunctionalAreas.hg19.bed.gz&quot; will be downloaded from https://lysine.univ-brest.fr/RAVA-FIRST/ in the repository of the package Ravages.  
CADD regions are non-overlapping regions that have been defined in the whole genome to perform rare variant association tests in the <code>RAVA.FIRST()</code> pipeline.  
It is recommended to use this function chromosome by chromosome for large datasets for time and memory managment.
</p>


<h3>Value</h3>

<p>The same bed matrix as x with three additional columns :
</p>
<table>
<tr><td><code>genomic.region</code></td>
<td>
<p> The CADD region of each variant</p>
</td></tr>
<tr><td><code>SubRegion</code></td>
<td>
<p> The genomic category of each variant among 'Coding', 'Regulatory' or 'Intergenic'</p>
</td></tr>
<tr><td><code>adjCADD.Median</code></td>
<td>
<p> The median of adjusted CADD of variants observed at least to times in GnomAD genomes r2.0.1</p>
</td></tr>
</table>


<h3>Source</h3>

<p>https://lysine.univ-brest.fr/RAVA-FIRST/</p>


<h3>See Also</h3>

<p><code><a href="#topic+RAVA.FIRST">RAVA.FIRST</a></code>, <code><a href="#topic+filter.adjustedCADD">filter.adjustedCADD</a></code>, <code><a href="#topic+burden.subscores">burden.subscores</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Import 1000Genome data from region around LCT gene
#x &lt;- as.bed.matrix(LCT.gen, LCT.fam, LCT.bim)

#Group variants within CADD regions and genomic categories
#x &lt;- set.CADDregions(x)
#table(x@snps$genomic.region) #CADD regions
#table(x@snps$SubRegion) #Genomic categories
</code></pre>

<hr>
<h2 id='set.genomic.region'> Variants annotation based on gene positions </h2><span id='topic+set.genomic.region'></span>

<h3>Description</h3>

<p>Attributes regions to variants based on given region positions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set.genomic.region(x, regions = genes.b37, flank.width = 0L, split = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set.genomic.region_+3A_x">x</code></td>
<td>
<p> A bed.matrix </p>
</td></tr>
<tr><td><code id="set.genomic.region_+3A_regions">regions</code></td>
<td>

<p>A dataframe in bed format (start is 0-based and end is 1-based) containing the fields : <code>Chr</code> (the chromosome of the gene),
<code>Start</code> (the start position of the gene, 0-based), <code>End</code> (the end position of the gene, 1-based), and
<code>Name</code> (the name of the gene - a factor),
</p>
</td></tr>
<tr><td><code id="set.genomic.region_+3A_flank.width">flank.width</code></td>
<td>
<p> An integer: width of the flanking regions in base pairs downstream and upstream the regions. </p>
</td></tr>
<tr><td><code id="set.genomic.region_+3A_split">split</code></td>
<td>
<p> Whether to split variants attributed to multiple regions by duplicating this variants, set at TRUE by default</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>Warnings: <code>regions$Name</code> should be a factor containing UNIQUE names of the regions, ORDERED in the genome order. 
</p>
<p>We provide two data sets of autosomal humain genes, <code>genes.b37</code> and <code>genes.b38</code>.  
</p>
<p>If <code>x@snps$chr</code> is not a vector of integers, it should be a factor with same levels as <code>regions$Chr</code>.
</p>
<p>If <code>flank.width</code> is null, only the variants having their position between the <code>regions$Start</code> and the <code>regions$End</code> of a gene will be attributed to the corresponding gene.  
When two regions overlap, variants in the overlapping zone will be assigned to those two regions, separated by a comma.
</p>
<p>If <code>flank.width</code> is a positive number, variants <code>flank.width</code> downstream or upstream a gene will be annotated annotated to this gene. You can use <code>flank.width = Inf</code>
to have each variant attributed to the nearest gene.  
</p>
<p>If a variant is attributed to multiple genomic regions, it will be duplicated in the bed matrix with one row per genomic region if <code>split = TRUE</code>. Variants will have new IDs being CHR:POS:A1:A2:genomic.region.  
</p>


<h3>Value</h3>

<p>The same bed matrix as x with an additional column <code>x@snps$genomic.region</code> containing the annotation of each variant.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+genes.b37">genes.b37</a></code>, <code><a href="#topic+genes.b38">genes.b38</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Import 1000Genome data from region around LCT gene
x &lt;- as.bed.matrix(LCT.gen, LCT.fam, LCT.bim)

#Group variants within known genes
x &lt;- set.genomic.region(x)

#Group variants within know genes +/- 500bp
x &lt;- set.genomic.region(x, flank.width=500)
</code></pre>

<hr>
<h2 id='set.genomic.region.subregion'> Variants annotation based on regions and subregions positions </h2><span id='topic+set.genomic.region.subregion'></span>

<h3>Description</h3>

<p>Attributes regions and subregions to variants based on given positions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set.genomic.region.subregion(x, regions, subregions, split = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set.genomic.region.subregion_+3A_x">x</code></td>
<td>
<p> A bed.matrix </p>
</td></tr>
<tr><td><code id="set.genomic.region.subregion_+3A_regions">regions</code></td>
<td>

<p>A dataframe in bed format (start is 0-based and end is 1-based) containing the regions with the fields : <code>Chr</code> (the chromosome of the gene),
<code>Start</code> (the start position of the gene, 0-based), <code>End</code> (the end position of the gene, 1-based), and
<code>Name</code> (the name of the gene - a factor),
</p>
</td></tr>
<tr><td><code id="set.genomic.region.subregion_+3A_subregions">subregions</code></td>
<td>
<p> A dataframe containing the subregions in the same format as <code>regions</code> </p>
</td></tr>
<tr><td><code id="set.genomic.region.subregion_+3A_split">split</code></td>
<td>
<p> Whether to split variants attributed to multiple regions by duplicating this variants, set at TRUE by default</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>Warnings: <code>regions$Name</code> and <code>subregions$Name</code> should be factors containing UNIQUE names of the regions, ORDERED in the genome order. 
</p>
<p>If <code>x@snps$chr</code> is not a vector of integers, it should be a factor with same levels as <code>regions$Chr</code>.
</p>
<p>If a variant is attributed to multiple genomic regions, it will be duplicated in the bed matrix with one row per genomic region if <code>split = TRUE</code>.  
</p>
<p>This function can be applied before using <code>burden.subscores</code> to perform a functionally-informed burden tests with sub-scores for each <code>SubRegion</code> within each <code>genomic.region</code>. 
</p>


<h3>Value</h3>

<p>The same bed matrix as x with two additional columns: <code>x@snps$genomic.region</code> containing the annotation of the <code>regions</code> and <code>x@snps$SubRegion</code> containing the annotation of the <code>subregions</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+set.genomic.region">set.genomic.region</a></code>, <code><a href="#topic+burden.subscores">burden.subscores</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Import 1000Genome data from region around LCT gene
x &lt;- as.bed.matrix(LCT.gen, LCT.fam, LCT.bim)

#Group variants within known genes and 
#Within coding and regulatory regions
x &lt;- set.genomic.region.subregion(x, 
 regions = genes.b37, subregions = subregions.LCT)
</code></pre>

<hr>
<h2 id='SKAT'> SKAT test </h2><span id='topic+SKAT'></span>

<h3>Description</h3>

<p> Peforms SKAT on categorical or binary phenotypes </p>


<h3>Usage</h3>

<pre><code class='language-R'>SKAT(x, NullObject, genomic.region = x@snps$genomic.region, 
     weights = (1 - x@snps$maf)**24, maf.threshold = 0.5, 
     get.moments = "size.based", estimation.pvalue = "kurtosis",
     params.sampling, cores = 10, debug = FALSE, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SKAT_+3A_x">x</code></td>
<td>
<p> A bed.matrix </p>
</td></tr>
<tr><td><code id="SKAT_+3A_nullobject">NullObject</code></td>
<td>
<p> A list returned from <code>NullObject.parameters</code> </p>
</td></tr>
<tr><td><code id="SKAT_+3A_genomic.region">genomic.region</code></td>
<td>
<p> A factor defining the genomic region of each variant </p>
</td></tr>
<tr><td><code id="SKAT_+3A_weights">weights</code></td>
<td>
<p> A vector with the weight of each variant. By default, the weight of each variant is inversely proportionnal to its MAF, as it was computed in the original SKAT method</p>
</td></tr>
<tr><td><code id="SKAT_+3A_maf.threshold">maf.threshold</code></td>
<td>
<p> The MAF above which variants are removed (default is to keep all variants)</p>
</td></tr>
<tr><td><code id="SKAT_+3A_get.moments">get.moments</code></td>
<td>
<p> How to estimate the moments to compute the p-values among &quot;size.based&quot;, &quot;bootstrap&quot;, &quot;permutations&quot;, or &quot;theoretical&quot; for categorical phenotypes (2 or more groups of individuals). By default &quot;size.based&quot; that will choose the method depending on sample size (see <code>details</code>) </p>
</td></tr>
<tr><td><code id="SKAT_+3A_estimation.pvalue">estimation.pvalue</code></td>
<td>
<p> Whether to use the skewness (&quot;skewness&quot;) or the kurtosis (&quot;kurtosis&quot;) for the chi-square approximation </p>
</td></tr>
<tr><td><code id="SKAT_+3A_params.sampling">params.sampling</code></td>
<td>
<p> A list containing the elements &quot;perm.target&quot;, &quot;perm.max&quot;, &quot;debug&quot;. Only needed if <code>get.moments = "boostrap"</code> or <code>get.moments = "permutations" </code> </p>
</td></tr>
<tr><td><code id="SKAT_+3A_cores">cores</code></td>
<td>
<p> How many cores to use for moments computation, set at 10 by default. Only needed if <code>get.moments = "theoretical"</code> </p>
</td></tr>
<tr><td><code id="SKAT_+3A_debug">debug</code></td>
<td>
<p> Whether to return the mean, standard deviation, skewness and kurtosis of the statistics</p>
</td></tr>
<tr><td><code id="SKAT_+3A_verbose">verbose</code></td>
<td>
<p> Whether to display information about the function actions </p>
</td></tr>
</table>


<h3>Details</h3>

<p>For categorical phenotypes, the p-value is calculated using a chi-square approximation based on the statistics' moments. The user has to choose how to compute these moments (argument <code>get.moments</code>), and which moments to use for the chi-square approximation (argument <code>estimation.pvalue</code>).  
</p>
<p>The moments can be computed either using a sampling procedure (<code>"permutations"</code> if there are no covariates, or <code>"bootstrap"</code> otherwise), or using theoretical moments computed as in Liu et al. 2008 (<code>"theoretical"</code>).  
</p>
<p>If <code>get.moments = "size.based"</code>, the sampling procedure will be used for sample sizes lower than 2000, and the theoretical calculations otherwise.  
</p>
<p>To estimate the p-values, etiher the first three moments are used (<code>estimation.pvalue = "skewness"</code>), or the moments 1, 2 and 4 are used (<code>estimation.pvalue = "kurtosis"</code>). 
</p>
<p>If <code>get.moments = "theoretical"</code> and <code>estimation.pvalue = "skewness"</code>, it corresponds to <code>method = "liu"</code> in the SKAT package.
If <code>get.moments = "theoretical"</code> and <code>estimation.pvalue = "kurtosis"</code>, it corresponds to <code>method = "liu.mod"</code> in the SKAT package.
</p>
<p>For small samples, p-values estimation is based on sampling and a sequential procedure: permutated statistics are computed and each one is compared to the observed statistics.
This method requires <code>perm.target</code> and <code>perm.max</code> that should be given as a list to <code>params.bootstrap</code>.
If <code>params.bootstrap</code> is not specified, perm.target will be set at 100, perm.max at 5e4.
The boostrap progam stops when either <code>perm.target</code> or <code>perm.max</code> is reached.  
P-values are then computed using a mixed procedure:   
</p>
<p>if <code>perm.target</code> is reached, the p-value is computed as : <code>perm.target</code> divided by the number of permutations used to reach <code>perm.target</code>;   
</p>
<p>if <code>perm.max</code> is reached, the SKAT small sample procedure is used, and p-values are approximated using a chi-square distributions based on statistics' moments 1, 2 and 4 computed from the permutated values.     
</p>
<p>If <code>NullObject$pheno.type = "continuous"</code>, the method from Liu et al. will be used to compute the p-value for the continuous phenotype, but <code>estimation.pvalue</code> can be set at &quot;skewness&quot; or &quot;kurtosis&quot;.  
</p>
<p>If <code>debug=TRUE</code>, more informations about the estimated statistics moments are given.  
</p>
<p>All missing genotypes are imputed by the mean genotype.
</p>


<h3>Value</h3>

<p>A data frame containing for each genomic region: 
</p>
<table>
<tr><td><code>stat</code></td>
<td>
<p> The observed statistics</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p> The p-value of the test</p>
</td></tr>
</table>
<p>If <code>get.moments = "bootstrap"</code> or <code>get.moments = "permutations"</code>, additional fields are present:
</p>
<table>
<tr><td><code>p.perm</code></td>
<td>
<p> The p-value computed by permutations: number of times permutated is greater than observed statistics divided by the total number of permutations performed</p>
</td></tr>
<tr><td><code>p.chi2</code></td>
<td>
<p> The p-value computed by the chi-square approximation using the SKAT small sample procedure</p>
</td></tr>
</table>
<p>If <code>debug = TRUE</code>, the mean, standard deviation, skewness and kurtosis are also returned, as well as for the sampling procedure:
</p>
<table>
<tr><td><code>nb.gep</code></td>
<td>
<p> The number of times a permutated statistics is equal or greater than the observed statistics <code>stat</code></p>
</td></tr>
<tr><td><code>nb.eq</code></td>
<td>
<p> The number of times a permutated statistics is equal to the observed statistics <code>stat</code></p>
</td></tr>
<tr><td><code>nb.perms</code></td>
<td>
<p> The total number of simulations performed </p>
</td></tr>
</table>


<h3>References</h3>

<p> Wu et al. 2011, <em>Rare-variant association testing for sequencing data with the sequence kernel association test</em>, American Journal of Human Genetics <b>82-93</b> doi:10.1016/j.ajhg.2011.05.029;  
</p>
<p>Lee et al. 2012, <em>Optimal Unified Approach for Rare-Variant Association Testing with Application to Small-Sample Case-Control Whole-Exome Sequencing Studies</em>, American Journal of Human Genetics, doi:10.1016/j.ajhg.2012.06.007;  
</p>
<p>Liu et al. 2008, <em>A new chi-square approximation to the distribution of non-negative definite quadratic forms in non-central normal variables</em>, Computational Statistics &amp; Data Analysis, doi:10.1016/j.csda.2008.11.025
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+NullObject.parameters">NullObject.parameters</a></code>, <code><a href="#topic+SKAT.theoretical">SKAT.theoretical</a></code>, <code><a href="#topic+SKAT.bootstrap">SKAT.bootstrap</a></code>, <code><a href="#topic+SKAT.permutations">SKAT.permutations</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Example on simulated data from Ravages with 
#One group of 50 controls and 
#two groups of 25 cases, each one with a prevalence of 0.01
#with 50% of causal variants, 5 genomic regions are simulated
GRR.del &lt;- GRR.matrix(GRR = "SKAT", genes.maf = Kryukov,
                      n.case.groups = 2, select.gene = "R1",
                      GRR.multiplicative.factor=2)

x.sim &lt;- rbm.GRR(genes.maf = Kryukov, size = c(50, 25, 25),
                 prev = c(0.001, 0.001), GRR.matrix.del = GRR.del,
                 p.causal = 0.5, p.protect = 0, select.gene="R1",
                 same.variant = FALSE, genetic.model = "multiplicative", replicates = 5)
#Null Model
x.sim.H0 &lt;- NullObject.parameters(x.sim@ped$pheno, RVAT = "SKAT", pheno.type = "categorical")

#Run SKAT (here permutations as n&lt;2000 and no covariates)
#Parameters for the sampling procedure: target = 5, max = 100
#Please increase the number of permutations for a more accurate estimation of the p-values
params.sampling = list(perm.target = 5, perm.max = 100)
SKAT(x.sim, x.sim.H0, params.sampling = params.sampling)

#Run SKAT with a random continuous phenotype
#Null Model
x.sim.H0.c &lt;- NullObject.parameters(rnorm(100), RVAT = "SKAT", pheno.type = "continuous")
SKAT(x.sim, x.sim.H0.c, cores = 1)



#Example on 1000Genome data
#Import data in a bed matrix
x &lt;- as.bed.matrix(x=LCT.matrix.bed, fam=LCT.matrix.fam, bim=LCT.snps)
#Add population
x@ped[,c("pop", "superpop")] &lt;- LCT.matrix.pop1000G[,c("population", "super.population")]

#Select EUR superpopulation
x &lt;- select.inds(x, superpop=="EUR")
x@ped$pop &lt;- droplevels(x@ped$pop)

#Group variants within known genes
x &lt;- set.genomic.region(x)

#Filter of rare variants: only non-monomorphic variants with
#a MAF lower than 2.5%
#keeping only genomic regions with at least 10 SNPs
x1 &lt;- filter.rare.variants(x, filter = "whole", maf.threshold = 0.025, min.nb.snps = 10)

#Simulation of a covariate + Sex as a covariate
sex &lt;- x1@ped$sex
set.seed(1) ; u &lt;- runif(nrow(x1))
covar &lt;- cbind(sex, u)

#run SKAT using the 1000 genome EUR populations as "outcome"
#with very few permutations
#Please increase the permutations for a more accurate estimation of the p-values
#Fit Null model with covariate sex
x1.H0.covar &lt;- NullObject.parameters(x1@ped$pop, RVAT = "SKAT", pheno.type = "categorical",
                                     data = covar, formula = ~ sex)

#Run SKAT with the covariates: use boostrap as n&lt;2000
SKAT(x1, x1.H0.covar, params.sampling = params.sampling, get.moments = "bootstrap")

#Run SKAT using theoretical moments (discourage here as n&lt;2000) and 1 core
#SKAT(x1, x1.H0.covar, get.moments = "theoretical", cores = 1)


</code></pre>

<hr>
<h2 id='SKAT.bootstrap'> Multi group SKAT test using bootstrap sampling </h2><span id='topic+SKAT.bootstrap'></span>

<h3>Description</h3>

<p> Peforms SKAT on two or more groups of individuals using bootstrap sampling</p>


<h3>Usage</h3>

<pre><code class='language-R'>  SKAT.bootstrap(x, NullObject, genomic.region = x@snps$genomic.region,
                 weights = (1-x@snps$maf)**24, maf.threshold = 0.5,
                 perm.target = 100, perm.max = 5e4, debug = FALSE,
                 estimation.pvalue = "kurtosis")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SKAT.bootstrap_+3A_x">x</code></td>
<td>
<p> A bed.matrix </p>
</td></tr>
<tr><td><code id="SKAT.bootstrap_+3A_nullobject">NullObject</code></td>
<td>
<p> A list returned from <code>NullObject.parameters</code> </p>
</td></tr>
<tr><td><code id="SKAT.bootstrap_+3A_genomic.region">genomic.region</code></td>
<td>
<p> A factor defining the genomic region of each variant </p>
</td></tr>
<tr><td><code id="SKAT.bootstrap_+3A_weights">weights</code></td>
<td>
<p> A vector with the weight of each variant. By default, the weight of each variant is inversely proportionnal to its MAF, as it was computed in the original SKAT method</p>
</td></tr>
<tr><td><code id="SKAT.bootstrap_+3A_maf.threshold">maf.threshold</code></td>
<td>
<p> The MAF above which variants are removed (default is to keep all variants)</p>
</td></tr>
<tr><td><code id="SKAT.bootstrap_+3A_perm.target">perm.target</code></td>
<td>
<p> The number of times to exceed the observed statistics. If not reached, <code>perm.max</code> permutations will be used </p>
</td></tr>
<tr><td><code id="SKAT.bootstrap_+3A_perm.max">perm.max</code></td>
<td>
<p> The maximum number of permutations to perform to estimate the p-value, will be used if <code>perm.target</code> is not reached</p>
</td></tr>
<tr><td><code id="SKAT.bootstrap_+3A_debug">debug</code></td>
<td>
<p> Whether to print details about the permutations (mean, standard deviation, skewness, kurtosis), FALSE by default</p>
</td></tr>
<tr><td><code id="SKAT.bootstrap_+3A_estimation.pvalue">estimation.pvalue</code></td>
<td>
<p> Whether to use the skewness (&quot;skewness&quot;) or the kurtosis (&quot;kurtosis&quot;) for the chi-square approximation </p>
</td></tr>
</table>


<h3>Details</h3>

<p>P-values estimation is based on bootstrap sampling and a sequential procedure: permutated statistics are computed and each one is compared to the observed statistics.
The boostrap progam stops when either <code>perm.target</code> or <code>perm.max</code> is reached.
P-values are then computed using a mixed procedure:
</p>
<p>if <code>perm.target</code> is reached, the p-value is computed as : <code>perm.target</code> divided by the number of permutations used to reach <code>perm.target</code>;
</p>
<p>if <code>perm.max</code> is reached, p-values are approximated using a chi-square distributions based on the first three moments if <code>estimation.pvalue = "skewness"</code>, or on statistics' moments 1, 2 and 4 if <code>estimation.pvalue = "kurtosis"</code>.  
</p>
<p>If <code>debug=TRUE</code>, more informations about the estimated statistics moments are given.  
</p>
<p>This function is used by <code>SKAT</code> when the sample size is smaller than 2000 and covariates are present.
</p>
<p>All missing genotypes are imputed by the mean genotype.
</p>


<h3>Value</h3>

<p>A data frame containing for each genomic:
</p>
<table>
<tr><td><code>stat</code></td>
<td>
<p> The observed statistics</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
 <p><code>p.perm</code> if <code>perm.target</code> is reached, <code>p.chi2</code> if <code>perm.max</code> is reached. </p>
</td></tr>
<tr><td><code>p.perm</code></td>
<td>
<p> The p-value computed by permutations: number of times permutated is greater than observed statistics divided by the total number of permutations performed</p>
</td></tr>
<tr><td><code>p.chi2</code></td>
<td>
<p> The p-value computed by the chi-square approximation using the SKAT small sample procedure</p>
</td></tr>
</table>
<p>If <code>debug=TRUE</code>, other informations are given about the moments estimation:
</p>
<table>
<tr><td><code>nb.gep</code></td>
<td>
<p> The number of times a permutated statistics is equal or greater than the observed statistics <code>stat</code></p>
</td></tr>
<tr><td><code>nb.eq</code></td>
<td>
<p> The number of times a permutated statistics is equal to the observed statistics <code>stat</code></p>
</td></tr>
<tr><td><code>nb.perms</code></td>
<td>
<p> The total number of simulations performed </p>
</td></tr>
<tr><td><code>mean</code></td>
<td>
<p> The mean of the permutated statistics</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p> The standard deviation of the permutated statistics</p>
</td></tr>
<tr><td><code>skewness</code></td>
<td>
<p> The skweness of the permutated statistics</p>
</td></tr>
<tr><td><code>kurtosis</code></td>
<td>
<p> The kurtosis of the permutated statistics</p>
</td></tr>
</table>


<h3>References</h3>

<p> Wu et al. 2011, <em>Rare-variant association testing for sequencing data with the sequence kernel association test</em>, American Journal of Human Genetics <b>82-93</b> doi:10.1016/j.ajhg.2011.05.029;  
</p>
<p>Lee et al. 2012, <em>Optimal Unified Approach for Rare-Variant Association Testing with Application to Small-Sample Case-Control Whole-Exome Sequencing Studies</em>, American Journal of Human Genetics, doi:10.1016/j.ajhg.2012.06.007;
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+NullObject.parameters">NullObject.parameters</a></code>, <code><a href="#topic+SKAT">SKAT</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Import data in a bed matrix
x &lt;- as.bed.matrix(x=LCT.matrix.bed, fam=LCT.matrix.fam, bim=LCT.snps)
#Add population
x@ped[,c("pop", "superpop")] &lt;- LCT.matrix.pop1000G[,c("population", "super.population")]

#Select EUR superpopulation
x &lt;- select.inds(x, superpop=="EUR")
x@ped$pop &lt;- droplevels(x@ped$pop)

#Group variants within known genes
x &lt;- set.genomic.region(x)

#Filter of rare variants: only non-monomorphic variants with
#a MAF lower than 1%
#keeping only genomic regions with at least 10 SNPs
x1 &lt;- filter.rare.variants(x, filter = "whole", maf.threshold = 0.01, min.nb.snps = 10)

#Simulation of a covariate + Sex as a covariate
sex &lt;- x1@ped$sex
set.seed(1) ; u &lt;- runif(nrow(x1))
covar &lt;- cbind(sex, u)

#run SKAT using the 1000 genome EUR populations as "outcome"
#The maximum number of permutations used is 100,
#and the target number is 10, please increase
#both values for a more accurate estimation of the p-values
#Fit Null model with covariates
x1.H0 &lt;- NullObject.parameters(x1@ped$pop, data = covar, RVAT = "SKAT", pheno.type = "categorical")

SKAT.bootstrap(x1, x1.H0, perm.target = 10, perm.max = 100)

</code></pre>

<hr>
<h2 id='SKAT.continuous'> Multi group SKAT test using Liu et al. approximation </h2><span id='topic+SKAT.continuous'></span>

<h3>Description</h3>

<p> Peforms SKAT on a continuous phenotype using Liu et al. approximation </p>


<h3>Usage</h3>

<pre><code class='language-R'>SKAT.continuous(x, NullObject, genomic.region = x@snps$genomic.region,
                weights = (1 - x@snps$maf)**24, maf.threshold = 0.5,
                estimation.pvalue = "kurtosis", cores = 10, debug = FALSE )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SKAT.continuous_+3A_x">x</code></td>
<td>
<p> A bed.matrix </p>
</td></tr>
<tr><td><code id="SKAT.continuous_+3A_nullobject">NullObject</code></td>
<td>
<p> A list returned from <code>NullObject.parameters</code> </p>
</td></tr>
<tr><td><code id="SKAT.continuous_+3A_genomic.region">genomic.region</code></td>
<td>
<p> A factor defining the genomic region of each variant </p>
</td></tr>
<tr><td><code id="SKAT.continuous_+3A_weights">weights</code></td>
<td>
<p> A vector with the weight of each variant. By default, the weight of each variant is inversely proportionnal to its MAF, as it was computed in the original SKAT method</p>
</td></tr>
<tr><td><code id="SKAT.continuous_+3A_maf.threshold">maf.threshold</code></td>
<td>
<p> The MAF above which variants are removed (default is to keep all variants)</p>
</td></tr>
<tr><td><code id="SKAT.continuous_+3A_estimation.pvalue">estimation.pvalue</code></td>
<td>
<p> Whether to use the skewness (&quot;skewness&quot;) or the kurtosis (&quot;kurtosis&quot;) for the chi-square approximation </p>
</td></tr>
<tr><td><code id="SKAT.continuous_+3A_cores">cores</code></td>
<td>
<p> How many cores to use for moments computation, set at 10 by default </p>
</td></tr>
<tr><td><code id="SKAT.continuous_+3A_debug">debug</code></td>
<td>
<p> Whether to return the mean, standard deviation, skewness and kurtosis of the statistics. Set at FALSE by default </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method from Liu et al. 2008 is used where p-values are estimated using a chi-square approximation from moment's
</p>
<p>If <code>estimation.pvalue = "kurtosis"</code>, the kurtosis is used instead of skewness in the chi-square approximation. This is equivalent to &quot;liu.mod&quot; in SKAT package.   
</p>


<h3>Value</h3>

<p>A data frame containing for each genomic region:
</p>
<table>
<tr><td><code>stat</code></td>
<td>
<p> The observed statistics</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p> The p-value of the test</p>
</td></tr>
</table>
<p>If <code>debug = TRUE</code>, the mean, standard deviation, skewness and kurtosis used to compute the p-value are returned
</p>


<h3>References</h3>

<p> Wu et al. 2011, <em>Rare-variant association testing for sequencing data with the sequence kernel association test</em>, American Journal of Human Genetics <b>82-93</b> doi:10.1016/j.ajhg.2011.05.029;  
</p>
<p>Liu et al. 2008, <em>A new chi-square approximation to the distribution of non-negative definite quadratic forms in non-central normal variables</em>, Computational Statistics &amp; Data Analysis, doi:10.1016/j.csda.2008.11.025
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+NullObject.parameters">NullObject.parameters</a></code>, <code><a href="#topic+SKAT">SKAT</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Import data in a bed matrix
x &lt;- as.bed.matrix(x=LCT.matrix.bed, fam=LCT.matrix.fam, bim=LCT.snps)
#Add population
x@ped[,c("pop", "superpop")] &lt;- LCT.matrix.pop1000G[,c("population", "super.population")]

#Select EUR superpopulation
x &lt;- select.inds(x, superpop=="EUR")
x@ped$pop &lt;- droplevels(x@ped$pop)

#Group variants within known genes
x &lt;- set.genomic.region(x)

#Filter of rare variants: only non-monomorphic variants with
#a MAF lower than 2.5%
#keeping only genomic regions with at least 10 SNPs
x1 &lt;- filter.rare.variants(x, filter = "whole", maf.threshold = 0.025, min.nb.snps = 10)

#run SKAT using a random continuous phenotype
#Fit Null model
x1.H0 &lt;- NullObject.parameters(rnorm(nrow(x1)), RVAT = "SKAT", pheno.type = "continuous")

SKAT.continuous(x1, x1.H0, cores = 1)

</code></pre>

<hr>
<h2 id='SKAT.permutations'> Multi group SKAT test using bootstrap sampling </h2><span id='topic+SKAT.permutations'></span>

<h3>Description</h3>

<p> Peforms SKAT on two or more groups of individuals using bootstrap sampling</p>


<h3>Usage</h3>

<pre><code class='language-R'>SKAT.permutations(x, NullObject, genomic.region = x@snps$genomic.region,
                  weights = (1-x@snps$maf)**24, maf.threshold = 0.5,
                  perm.target = 100, perm.max = 5e4, debug = FALSE,
                  estimation.pvalue = "kurtosis")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SKAT.permutations_+3A_x">x</code></td>
<td>
<p> A bed.matrix </p>
</td></tr>
<tr><td><code id="SKAT.permutations_+3A_nullobject">NullObject</code></td>
<td>
<p> A list returned from <code>NullObject.parameters</code> </p>
</td></tr>
<tr><td><code id="SKAT.permutations_+3A_genomic.region">genomic.region</code></td>
<td>
<p> A factor defining the genomic region of each variant </p>
</td></tr>
<tr><td><code id="SKAT.permutations_+3A_weights">weights</code></td>
<td>
<p> A vector with the weight of each variant. By default, the weight of each variant is inversely proportionnal to its MAF, as it was computed in the original SKAT method</p>
</td></tr>
<tr><td><code id="SKAT.permutations_+3A_maf.threshold">maf.threshold</code></td>
<td>
<p> The MAF above which variants are removed (default is to keep all variants)</p>
</td></tr>
<tr><td><code id="SKAT.permutations_+3A_perm.target">perm.target</code></td>
<td>
<p> The number of times to exceed the observed statistics. If not reached, <code>perm.max</code> permutations will be used </p>
</td></tr>
<tr><td><code id="SKAT.permutations_+3A_perm.max">perm.max</code></td>
<td>
<p> The maximum number of permutations to perform to estimate the p-value, will be used if <code>perm.target</code> is not reached</p>
</td></tr>
<tr><td><code id="SKAT.permutations_+3A_debug">debug</code></td>
<td>
<p> Whether to print details about the permutations (mean, standard deviation, skewness, kurtosis), FALSE by default</p>
</td></tr>
<tr><td><code id="SKAT.permutations_+3A_estimation.pvalue">estimation.pvalue</code></td>
<td>
<p> Whether to use the skewness (&quot;skewness&quot;) or the kurtosis (&quot;kurtosis&quot;) for the chi-square approximation </p>
</td></tr>
</table>


<h3>Details</h3>

<p>P-values estimation is based on permutations sampling and a sequential procedure: permutated statistics are computed and each one is compared to the observed statistics.
The boostrap progam stops when either <code>perm.target</code> or <code>perm.max</code> is reached.
P-values are then computed using a mixed procedure:
</p>
<p>if <code>perm.target</code> is reached, the p-value is computed as : <code>perm.target</code> divided by the number of permutations used to reach <code>perm.target</code>;
</p>
<p>if <code>perm.max</code> is reached, p-values are approximated using a chi-square distributions based on the first three moments if <code>estimation.pvalue = "skewness"</code>, or on statistics' moments 1, 2 and 4 if <code>estimation.pvalue = "kurtosis"</code>.  
</p>
<p>If <code>debug=TRUE</code>, more informations about the estimated statistics moments are given.  
</p>
<p>This function is used by <code>SKAT</code> when the sample size is smaller than 2000 and no covariates are present.  
</p>
<p>All missing genotypes are imputed by the mean genotype.
</p>


<h3>Value</h3>

<p>A data frame containing for each genomic:
</p>
<table>
<tr><td><code>stat</code></td>
<td>
<p> The observed statistics</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
 <p><code>p.perm</code> if <code>perm.target</code> is reached, <code>p.chi2</code> if <code>perm.max</code> is reached. </p>
</td></tr>
<tr><td><code>p.perm</code></td>
<td>
<p> The p-value computed by permutations: number of times permutated is greater than observed statistics divided by the total number of permutations performed</p>
</td></tr>
<tr><td><code>p.chi2</code></td>
<td>
<p> The p-value computed by the chi-square approximation using the SKAT small sample procedure</p>
</td></tr>
</table>
<p>If <code>debug=TRUE</code>, other informations are given about the moments estimation:
</p>
<table>
<tr><td><code>nb.gep</code></td>
<td>
<p> The number of times a permutated statistics is equal or greater than the observed statistics <code>stat</code></p>
</td></tr>
<tr><td><code>nb.eq</code></td>
<td>
<p> The number of times a permutated statistics is equal to the observed statistics <code>stat</code></p>
</td></tr>
<tr><td><code>nb.perms</code></td>
<td>
<p> The total number of simulations performed </p>
</td></tr>
<tr><td><code>mean</code></td>
<td>
<p> The mean of the permutated statistics</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p> The standard deviation of the permutated statistics</p>
</td></tr>
<tr><td><code>skewness</code></td>
<td>
<p> The skweness of the permutated statistics</p>
</td></tr>
<tr><td><code>kurtosis</code></td>
<td>
<p> The kurtosis of the permutated statistics</p>
</td></tr>
</table>


<h3>References</h3>

<p> Wu et al. 2011, <em>Rare-variant association testing for sequencing data with the sequence kernel association test</em>, American Journal of Human Genetics <b>82-93</b> doi:10.1016/j.ajhg.2011.05.029;  
</p>
<p>Lee et al. 2012, <em>Optimal Unified Approach for Rare-Variant Association Testing with Application to Small-Sample Case-Control Whole-Exome Sequencing Studies</em>, American Journal of Human Genetics, doi:10.1016/j.ajhg.2012.06.007;
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+NullObject.parameters">NullObject.parameters</a></code>, <code><a href="#topic+SKAT">SKAT</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Import data in a bed matrix
x &lt;- as.bed.matrix(x=LCT.matrix.bed, fam=LCT.matrix.fam, bim=LCT.snps)
#Add population
x@ped[,c("pop", "superpop")] &lt;- LCT.matrix.pop1000G[,c("population", "super.population")]

#Select EUR superpopulation
x &lt;- select.inds(x, superpop=="EUR")
x@ped$pop &lt;- droplevels(x@ped$pop)

#Group variants within known genes
x &lt;- set.genomic.region(x)

#Filter of rare variants: only non-monomorphic variants with
#a MAF lower than 1%
#keeping only genomic regions with at least 10 SNPs
x1 &lt;- filter.rare.variants(x, filter = "whole", maf.threshold = 0.01, min.nb.snps = 10)

#run SKAT using the 1000 genome EUR populations as "outcome"
#The maximum number of permutations used is 100,
#and the target number is 10, please increase
#both values for a more accurate estimation of the p-values
#Fit Null model
x1.H0 &lt;- NullObject.parameters(x1@ped$pop, RVAT = "SKAT", pheno.type = "categorical")
SKAT.permutations(x1, x1.H0, perm.target = 10, perm.max=100)

</code></pre>

<hr>
<h2 id='SKAT.theoretical'> Multi group SKAT test using Liu et al. approximation </h2><span id='topic+SKAT.theoretical'></span>

<h3>Description</h3>

<p> Peforms SKAT on two or more groups of individuals using Liu et al. approximation </p>


<h3>Usage</h3>

<pre><code class='language-R'>SKAT.theoretical(x, NullObject, genomic.region = x@snps$genomic.region,
                 weights = (1 - x@snps$maf)**24, maf.threshold = 0.5,
                 estimation.pvalue = "kurtosis", cores = 10, debug = FALSE )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SKAT.theoretical_+3A_x">x</code></td>
<td>
<p> A bed.matrix </p>
</td></tr>
<tr><td><code id="SKAT.theoretical_+3A_nullobject">NullObject</code></td>
<td>
<p> A list returned from <code>NullObject.parameters</code> </p>
</td></tr>
<tr><td><code id="SKAT.theoretical_+3A_genomic.region">genomic.region</code></td>
<td>
<p> A factor defining the genomic region of each variant </p>
</td></tr>
<tr><td><code id="SKAT.theoretical_+3A_weights">weights</code></td>
<td>
<p> A vector with the weight of each variant. By default, the weight of each variant is inversely proportionnal to its MAF, as it was computed in the original SKAT method</p>
</td></tr>
<tr><td><code id="SKAT.theoretical_+3A_maf.threshold">maf.threshold</code></td>
<td>
<p> The MAF above which variants are removed (default is to keep all variants)</p>
</td></tr>
<tr><td><code id="SKAT.theoretical_+3A_estimation.pvalue">estimation.pvalue</code></td>
<td>
<p> Whether to use the skewness (&quot;skewness&quot;) or the kurtosis (&quot;kurtosis&quot;) for the chi-square approximation </p>
</td></tr>
<tr><td><code id="SKAT.theoretical_+3A_cores">cores</code></td>
<td>
<p> How many cores to use for moments computation, set at 10 by default </p>
</td></tr>
<tr><td><code id="SKAT.theoretical_+3A_debug">debug</code></td>
<td>
<p> Whether to return the mean, standard deviation, skewness and kurtosis of the statistics. Set at FALSE by default </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method from Liu et al. 2008 is used where p-values are estimated using a chi-square approximation from moment's statistics
</p>
<p>If <code>estimation.pvalue = "kurtosis"</code>, the kurtosis is used instead of skewness in the chi-square approximation. This is equivalent to &quot;liu.mod&quot; in SKAT package.  
</p>
<p>This function is used by <code>SKAT</code> when the sample size is larger than 2000.  
</p>
<p>All missing genotypes are imputed by the mean genotype.
</p>


<h3>Value</h3>

<p>A data frame containing for each genomic region:
</p>
<table>
<tr><td><code>stat</code></td>
<td>
<p> The observed statistics</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p> The p-value of the test</p>
</td></tr>
</table>
<p>If <code>debug = TRUE</code>, the mean, standard deviation, skewness and kurtosis used to compute the p-value are returned
</p>


<h3>References</h3>

<p> Wu et al. 2011, <em>Rare-variant association testing for sequencing data with the sequence kernel association test</em>, American Journal of Human Genetics <b>82-93</b> doi:10.1016/j.ajhg.2011.05.029;  
</p>
<p>Liu et al. 2008, <em>A new chi-square approximation to the distribution of non-negative definite quadratic forms in non-central normal variables</em>, Computational Statistics &amp; Data Analysis, doi:10.1016/j.csda.2008.11.025
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+NullObject.parameters">NullObject.parameters</a></code>, <code>SKAT</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Import data in a bed matrix
x &lt;- as.bed.matrix(x=LCT.matrix.bed, fam=LCT.matrix.fam, bim=LCT.snps)
#Add population
x@ped[,c("pop", "superpop")] &lt;- LCT.matrix.pop1000G[,c("population", "super.population")]

#Select EUR superpopulation
x &lt;- select.inds(x, superpop=="EUR")
x@ped$pop &lt;- droplevels(x@ped$pop)

#Group variants within known genes
x &lt;- set.genomic.region(x)

#Filter of rare variants: only non-monomorphic variants with
#a MAF lower than 2.5%
#keeping only genomic regions with at least 10 SNPs
x1 &lt;- filter.rare.variants(x, filter = "whole", maf.threshold = 0.025, min.nb.snps = 10)

#run SKAT using the 1000 genome EUR populations as "outcome" using one core
#Fit Null model
x1.H0 &lt;- NullObject.parameters(x1@ped$pop, RVAT = "SKAT", pheno.type = "categorical")

SKAT.theoretical(x1, x1.H0, cores = 1)

</code></pre>

<hr>
<h2 id='subregions.LCT'>Exemple of functional categories</h2><span id='topic+subregions.LCT'></span>

<h3>Description</h3>

<p>Example of arbitrary functional categories (coding or regulatory) in the LCT locus (bed format, GRCH37).  
&quot;Coding&quot; corresponds to coding parts of the exons and &quot;Regulatory&quot; corresponds to everything that falls outside these coding regions.  
</p>
<p>Data contain the <code>Chr</code>, the <code>Start</code> position, the <code>End</code> position and the <code>Name</code> of all functional regions in the LCT locus.
</p>


<h3>Format</h3>

<p>The data contain one dataframe with four columns:
</p>

<dl>
<dt><code>Chr</code></dt><dd><p>The chromosome of the gene</p>
</dd>
<dt><code>Start</code></dt><dd><p>The start position of the functional region (0-based)</p>
</dd>
<dt><code>End</code></dt><dd><p>The end position of the functional region (1-based)</p>
</dd>
<dt><code>Name</code></dt><dd><p>The name of the gene</p>
</dd>
</dl>



<h3>See Also</h3>

 <p><code><a href="#topic+set.genomic.region.subregion">set.genomic.region.subregion</a></code>, <code><a href="#topic+burden.subscores">burden.subscores</a></code> </p>

<hr>
<h2 id='WSS'> WSS genetic score</h2><span id='topic+WSS'></span>

<h3>Description</h3>

<p>Caluclates the WSS genetic score
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WSS(x, genomic.region = x@snps$genomic.region)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WSS_+3A_x">x</code></td>
<td>
<p> A bed.matrix </p>
</td></tr>
<tr><td><code id="WSS_+3A_genomic.region">genomic.region</code></td>
<td>
<p> A factor containing the genomic region of each variant </p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix containing the WSS genetic score with one row per individual and one column per <code>genomic.region</code>
</p>


<h3>References</h3>

<p> Madsen E and Browning S. <em>A Groupwise Association Test for Rare Mutations Using a Weighted Sum Statistic.</em> PLoS Genet. 2009 </p>


<h3>See Also</h3>

 <p><code><a href="#topic+CAST">CAST</a></code>, <code><a href="#topic+burden.weighted.matrix">burden.weighted.matrix</a></code>, <code><a href="#topic+burden.mlogit">burden.mlogit</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Import data in a bed matrix
x &lt;- as.bed.matrix(x=LCT.matrix.bed, fam=LCT.matrix.fam, bim=LCT.snps)

# Group variants within known genes
x &lt;- set.genomic.region(x)

# Filter variants with maf (computed on whole sample) &lt; 0.025
# keeping only genomic region with at least 10 SNPs
x1 &lt;- filter.rare.variants(x, filter = "whole", maf.threshold = 0.025, min.nb.snps = 10)

# Compute burden score WSS
score.WSS &lt;- WSS(x1)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
