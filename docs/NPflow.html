<!DOCTYPE html><html><head><title>Help for package NPflow</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {NPflow}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#NPflow-package'><p>Bayesian Nonparametrics for Automatic Gating of Flow Cytometry data</p></a></li>
<li><a href='#burn.DPMMclust'><p>Burning MCMC iterations from a Dirichlet Process Mixture Model.</p></a></li>
<li><a href='#cluster_est_binder'><p>Point estimate of the partition for the Binder loss function</p></a></li>
<li><a href='#cluster_est_Fmeasure'><p>Point estimate of the partition using the F-measure as the cost function.</p></a></li>
<li><a href='#cluster_est_Mbinder_norm'><p>Point estimate of the partition using a modified Binder loss function</p></a></li>
<li><a href='#cluster_est_pear'><p>Gets a point estimate of the partition using posterior expected adjusted</p>
Rand index (PEAR)</a></li>
<li><a href='#cytoScatter'><p>Scatterplot of flow cytometry data</p></a></li>
<li><a href='#DPMGibbsN'><p>Slice Sampling of the Dirichlet Process Mixture Model with a prior on alpha</p></a></li>
<li><a href='#DPMGibbsN_parallel'><p>Slice Sampling of the Dirichlet Process Mixture Model</p>
with a prior on alpha</a></li>
<li><a href='#DPMGibbsN_SeqPrior'><p>Slice Sampling of Dirichlet Process Mixture of Gaussian distributions</p></a></li>
<li><a href='#DPMGibbsSkewN'><p>Slice Sampling of Dirichlet Process Mixture of skew normal distributions</p></a></li>
<li><a href='#DPMGibbsSkewN_parallel'><p>Parallel Implementation of Slice Sampling of Dirichlet Process Mixture of skew normal distributions</p></a></li>
<li><a href='#DPMGibbsSkewT'><p>Slice Sampling of Dirichlet Process Mixture of skew Student's t-distributions</p></a></li>
<li><a href='#DPMGibbsSkewT_parallel'><p>Slice Sampling of Dirichlet Process Mixture of skew Student's t-distributions</p></a></li>
<li><a href='#DPMGibbsSkewT_SeqPrior'><p>Slice Sampling of Dirichlet Process Mixture of skew Student's t-distributions</p></a></li>
<li><a href='#DPMGibbsSkewT_SeqPrior_parallel'><p>Slice Sampling of Dirichlet Process Mixture of skew Student's t-distributions</p></a></li>
<li><a href='#DPMpost'><p>Posterior estimation for Dirichlet process mixture of multivariate (potentially skew) distributions models</p></a></li>
<li><a href='#evalClustLoss'><p>ELoss of a partition point estimate compared to a gold standard</p></a></li>
<li><a href='#Flimited'><p>Compute a limited F-measure</p></a></li>
<li><a href='#Fmeasure_costC'><p>Multiple cost computations with the F-measure as the loss function</p></a></li>
<li><a href='#FmeasureC'><p>C++ implementation of the F-measure computation</p></a></li>
<li><a href='#FmeasureC_no0'><p>C++ implementation of the F-measure computation without the reference class 0</p></a></li>
<li><a href='#invwishrnd'><p>Sample from a inverse-Wishart distribution</p></a></li>
<li><a href='#lgamma_mv'><p>Multivariate log gamma function</p></a></li>
<li><a href='#MAP_sNiW_mmEM'><p>EM MAP for mixture of sNiW</p></a></li>
<li><a href='#MLE_gamma'><p>MLE for Gamma distribution</p></a></li>
<li><a href='#MLE_NiW_mmEM'><p>EM MLE for mixture of NiW</p></a></li>
<li><a href='#MLE_sNiW'><p>MLE for sNiW distributed observations</p></a></li>
<li><a href='#MLE_sNiW_mmEM'><p>EM MLE for mixture of sNiW</p></a></li>
<li><a href='#mmNiWpdf'><p>multivariate Normal inverse Wishart probability density function for multiple inputs</p></a></li>
<li><a href='#mmNiWpdfC'><p>C++ implementation of multivariate Normal inverse Wishart probability density function for multiple inputs</p></a></li>
<li><a href='#mmsNiWlogpdf'><p>Probability density function of multiple structured Normal inverse Wishart</p></a></li>
<li><a href='#mmsNiWpdfC'><p>C++ implementation of multivariate structured Normal inverse Wishart probability density function for multiple inputs</p></a></li>
<li><a href='#mmvnpdfC'><p>C++ implementation of multivariate Normal probability density function for multiple inputs</p></a></li>
<li><a href='#mmvsnpdfC'><p>C++ implementation of multivariate skew Normal probability density function for multiple inputs</p></a></li>
<li><a href='#mmvstpdfC'><p>C++ implementation of multivariate Normal probability density function for multiple inputs</p></a></li>
<li><a href='#mmvtpdfC'><p>C++ implementation of multivariate Normal probability density function for multiple inputs</p></a></li>
<li><a href='#mvnlikC'><p>C++ implementation of multivariate Normal probability density function for multiple inputs</p></a></li>
<li><a href='#mvnpdf'><p>multivariate-Normal probability density function</p></a></li>
<li><a href='#mvnpdfC'><p>C++ implementation of multivariate normal probability density function for</p>
multiple inputs</a></li>
<li><a href='#mvsnlikC'><p>C++ implementation of multivariate skew normal likelihood function for multiple inputs</p></a></li>
<li><a href='#mvsnpdf'><p>multivariate Skew-Normal probability density function</p></a></li>
<li><a href='#mvstlikC'><p>C++ implementation of multivariate skew t likelihood function for multiple inputs</p></a></li>
<li><a href='#mvstpdf'><p>multivariate skew-t  probability density function</p></a></li>
<li><a href='#mvtpdf'><p>multivariate Student's t-distribution probability density function</p></a></li>
<li><a href='#NuMatParC'><p>C++ implementation of similarity matrix computation using pre-computed distances</p></a></li>
<li><a href='#plot_ConvDPM'><p>Convergence diagnostic plots</p></a></li>
<li><a href='#plot_DPM'><p>Plot of a Dirichlet process mixture of gaussian distribution partition</p></a></li>
<li><a href='#plot_DPMsn'><p>Plot of a Dirichlet process mixture of skew normal distribution partition</p></a></li>
<li><a href='#plot_DPMst'><p>Plot of a Dirichlet process mixture of skew t-distribution partition</p></a></li>
<li><a href='#postProcess.DPMMclust'><p>Post-processing Dirichlet Process Mixture Models results to get</p>
a mixture distribution of the posterior locations</a></li>
<li><a href='#print.summaryDPMMclust'><p>Methods for a summary of a <code>DPMMclust</code> object</p></a></li>
<li><a href='#priormix'><p>Construction of an Empirical based prior</p></a></li>
<li><a href='#rCRP'><p>Generating cluster data from the Chinese Restaurant Process</p></a></li>
<li><a href='#rNiW'><p>Sample from a Normal inverse-Wishart distribution</p>
whose parameter are given by the structure hyper</a></li>
<li><a href='#rNNiW'><p>Sample from a normal inverse Wishart distribution</p>
whose parameter are given by the structure <code>SufStat</code></a></li>
<li><a href='#sample_alpha'><p>Sampler for the concentration parameter of a Dirichlet process</p></a></li>
<li><a href='#sampleClassC'><p>C++ implementation of the multinomial sampling from a matrix</p>
of column vectors, each containing the sampling probabilities
for their respective draw</a></li>
<li><a href='#similarityMat'><p>Computes the co-clustering (or similarity) matrix</p></a></li>
<li><a href='#similarityMat_nocostC'><p>C++ implementation</p></a></li>
<li><a href='#similarityMatC'><p>C++ implementation</p></a></li>
<li><a href='#summary.DPMMclust'><p>Summarizing Dirichlet Process Mixture Models</p></a></li>
<li><a href='#traceEpsC'><p>C++ implementation of residual trace computation step used when sampling the scale</p></a></li>
<li><a href='#update_SS'><p>Return updated sufficient statistics S with new data matrix z</p></a></li>
<li><a href='#update_SSsn'><p>Return updated sufficient statistics S with new data matrix z</p></a></li>
<li><a href='#update_SSst'><p>Return updated sufficient statistics S for skew t-distribution</p>
with data matrix z</a></li>
<li><a href='#vclust2mcoclustC'><p>C++ implementation</p></a></li>
<li><a href='#wishrnd'><p>Sample from a Wishart distribution</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Bayesian Nonparametrics for Automatic Gating of Flow-Cytometry
Data</td>
</tr>
<tr>
<td>Version:</td>
<td>0.13.5</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-01-13</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1), Rcpp (&ge; 0.12.11), truncnorm</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, stats, grDevices, ellipse, fastcluster, ggplot2,
pheatmap, reshape2, GGally</td>
</tr>
<tr>
<td>Suggests:</td>
<td>foreach, parallel, doParallel, itertools, microbenchmark</td>
</tr>
<tr>
<td>Description:</td>
<td>Dirichlet process mixture of multivariate normal, skew normal or skew t-distributions
             modeling oriented towards flow-cytometry data preprocessing applications. Method is 
             detailed in: Hejblum, Alkhassimn, Gottardo, Caron &amp; Thiebaut (2019) &lt;<a href="https://doi.org/10.1214%2F18-AOAS1209">doi:10.1214/18-AOAS1209</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/LGPL-3">LGPL-3</a> | file LICENSE</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/sistm/NPflow/issues">https://github.com/sistm/NPflow/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.0</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-13 08:40:49 UTC; boris</td>
</tr>
<tr>
<td>Author:</td>
<td>Boris P Hejblum [aut, cre],
  Chariff Alkhassim [aut],
  Francois Caron [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Boris P Hejblum &lt;boris.hejblum@u-bordeaux.fr&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-13 10:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='NPflow-package'>Bayesian Nonparametrics for Automatic Gating of Flow Cytometry data</h2><span id='topic+NPflow-package'></span><span id='topic+NPflow'></span>

<h3>Description</h3>

<p>Dirichlet process mixture of multivariate normal, skew normal or skew t-distributions
modeling oriented towards flow-cytometry data pre-processing applications.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> NPflow</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 0.13.5</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2024-01-13</td>
</tr>
<tr>
 <td style="text-align: left;">
License:</td><td style="text-align: left;"> <a href="http://www.gnu.org/licenses/lgpl.txt">LGPL-3</a></td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>The main function in this package is <code><a href="#topic+DPMpost">DPMpost</a></code>.
</p>


<h3>Author(s)</h3>

<p>Boris P. Hejblum, Chariff Alkhassim, Francois Caron
&mdash; Maintainer: Boris P. Hejblum
</p>


<h3>References</h3>

<p>Hejblum BP, Alkhassim C, Gottardo R, Caron F and Thiebaut R (2019) 
Sequential Dirichlet Process Mixtures of Multivariate Skew t-distributions for 
Model-based Clustering of Flow Cytometry Data. The Annals of Applied Statistics, 
13(1): 638-660. &lt;doi: 10.1214/18-AOAS1209&gt; &lt;arXiv: 1702.04407&gt; 
<a href="https://arxiv.org/abs/1702.04407">https://arxiv.org/abs/1702.04407</a> <a href="https://doi.org/10.1214/18-AOAS1209">doi:10.1214/18-AOAS1209</a>
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li><p> Report bugs at <a href="https://github.com/sistm/NPflow/issues">https://github.com/sistm/NPflow/issues</a>
</p>
</li></ul>


<hr>
<h2 id='burn.DPMMclust'>Burning MCMC iterations from a Dirichlet Process Mixture Model.</h2><span id='topic+burn.DPMMclust'></span>

<h3>Description</h3>

<p>Utility function for burning MCMC iteration from a <code>DPMMclust</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>burn.DPMMclust(x, burnin = 0, thin = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="burn.DPMMclust_+3A_x">x</code></td>
<td>
<p>a <code>DPMMclust</code> object.</p>
</td></tr>
<tr><td><code id="burn.DPMMclust_+3A_burnin">burnin</code></td>
<td>
<p>the number of MCMC iterations to burn (default is <code>0</code>).</p>
</td></tr>
<tr><td><code id="burn.DPMMclust_+3A_thin">thin</code></td>
<td>
<p>the spacing at which MCMC iterations are kept.
Default is <code>1</code>, i.e. no thining.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>DPMMclust</code> object minus the burnt iterations
</p>


<h3>Author(s)</h3>

<p>Boris Hejblum
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.DPMMclust">summary.DPMMclust</a></code>
</p>

<hr>
<h2 id='cluster_est_binder'>Point estimate of the partition for the Binder loss function</h2><span id='topic+cluster_est_binder'></span>

<h3>Description</h3>

<p>Get a point estimate of the partition using the Binder loss function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cluster_est_binder(c, logposterior)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cluster_est_binder_+3A_c">c</code></td>
<td>
<p>a list of vector of length <code>n</code>. <code>c[[j]][i]</code> is
the cluster allocation of observation <code>i=1...n</code> at iteration
<code>j=1...N</code>.</p>
</td></tr>
<tr><td><code id="cluster_est_binder_+3A_logposterior">logposterior</code></td>
<td>
<p>vector of logposterior corresponding to each
partition from <code>c</code> used to break ties when minimizing the cost function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>list</code>:
</p>

<dl>
<dt><code>c_est</code>:</dt><dd><p> a vector of length <code>n</code>. Point estimate of the partition</p>
</dd>
<dt><code>cost</code>:</dt><dd><p> a vector of length <code>N</code>. <code>cost[j]</code> is the cost
associated to partition <code>c[[j]]</code></p>
</dd>
<dt><code>similarity</code>:</dt><dd><p>  matrix of size <code>n x n</code>. Similarity matrix
(see <code><a href="#topic+similarityMat">similarityMat</a></code>)</p>
</dd>
<dt><code>opt_ind</code>:</dt><dd><p> the index of the optimal partition
among the MCMC iterations.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Francois Caron, Boris Hejblum
</p>


<h3>References</h3>

<p>F Caron, YW Teh, TB Murphy, Bayesian nonparametric Plackett-Luce
models for the analysis of preferences for college degree programmes,
<em>Annals of Applied Statistics</em>, 8(2):1145-1181, 2014.
</p>
<p>DB Dahl, Model-Based Clustering for Expression Data via a
Dirichlet Process Mixture Model, <em>Bayesian Inference for
Gene Expression and Proteomics</em>, K-A Do, P Muller, M Vannucci
(Eds.), Cambridge University Press, 2006.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+similarityMat">similarityMat</a></code> <code><a href="#topic+similarityMatC">similarityMatC</a></code>
</p>

<hr>
<h2 id='cluster_est_Fmeasure'>Point estimate of the partition using the F-measure as the cost function.</h2><span id='topic+cluster_est_Fmeasure'></span>

<h3>Description</h3>

<p>Get a point estimate of the partition using the F-measure as the cost function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cluster_est_Fmeasure(c, logposterior)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cluster_est_Fmeasure_+3A_c">c</code></td>
<td>
<p>a list of vector of length <code>n</code>. <code>c[[j]][i]</code> is
the cluster allocation of observation <code>i=1...n</code> at iteration
<code>j=1...N</code>.</p>
</td></tr>
<tr><td><code id="cluster_est_Fmeasure_+3A_logposterior">logposterior</code></td>
<td>
<p>a vector of logposterior corresponding to each
partition from <code>c</code> used to break ties when minimizing the cost function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>list</code>:
</p>
<table>
<tr><td><code>c_est:</code></td>
<td>
<p> a vector of length <code>n</code>. Point estimate of the partition</p>
</td></tr>
<tr><td><code>cost:</code></td>
<td>
<p> a vector of length <code>N</code>. <code>cost[j]</code> is the cost
associated to partition <code>c[[j]]</code></p>
</td></tr>
<tr><td><code>similarity:</code></td>
<td>
<p>  matrix of size <code>n x n</code>. Similarity matrix
(see <code><a href="#topic+similarityMat">similarityMat</a></code>)</p>
</td></tr>
<tr><td><code>opt_ind:</code></td>
<td>
<p> the index of the optimal partition
among the MCMC iterations.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Francois Caron, Boris Hejblum
</p>


<h3>See Also</h3>

<p><code><a href="#topic+similarityMat">similarityMat</a></code>
</p>

<hr>
<h2 id='cluster_est_Mbinder_norm'>Point estimate of the partition using a modified Binder loss function</h2><span id='topic+cluster_est_Mbinder_norm'></span>

<h3>Description</h3>

<p>Get a point estimate of the partition using a modified Binder loss function
for Gaussian components
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cluster_est_Mbinder_norm(c, Mu, Sigma, lambda = 0, a = 1, b = a, logposterior)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cluster_est_Mbinder_norm_+3A_c">c</code></td>
<td>
<p>a list of vector of length <code>n</code>. <code>c[[j]][i]</code> is
the cluster allocation of observation <code>i=1...n</code> at iteration
<code>j=1...N</code>.</p>
</td></tr>
<tr><td><code id="cluster_est_Mbinder_norm_+3A_mu">Mu</code></td>
<td>
<p>is a list of length <code>n</code> composed of <code>p x l</code> matrices.
Where <code>l</code> is the maximum number of components per partition.</p>
</td></tr>
<tr><td><code id="cluster_est_Mbinder_norm_+3A_sigma">Sigma</code></td>
<td>
<p>is list of length <code>n</code> composed of arrays containing a maximum of
<code>l</code> <code>p x p</code> covariance matrices.</p>
</td></tr>
<tr><td><code id="cluster_est_Mbinder_norm_+3A_lambda">lambda</code></td>
<td>
<p>is a nonnegative tunning parameter allowing further control over the distance
function. Default is 0.</p>
</td></tr>
<tr><td><code id="cluster_est_Mbinder_norm_+3A_a">a</code></td>
<td>
<p>nonnegative constant seen as the unit cost for pairwise misclassification. Default is 1.</p>
</td></tr>
<tr><td><code id="cluster_est_Mbinder_norm_+3A_b">b</code></td>
<td>
<p>nonnegative constant seen as the unit cost for the other kind of pairwise misclassification.
Default is 1.</p>
</td></tr>
<tr><td><code id="cluster_est_Mbinder_norm_+3A_logposterior">logposterior</code></td>
<td>
<p>vector of logposterior corresponding to each
partition from <code>c</code> used to break ties when minimizing the cost function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that he current implementation only allows Gaussian components.
</p>
<p>The modified Binder loss function takes into account the distance between
mixture components using #'the  Bhattacharyya distance.
</p>


<h3>Value</h3>

<p>a <code>list</code>:
</p>
<table>
<tr><td><code>c_est:</code></td>
<td>
<p> a vector of length <code>n</code>. Point estimate of the partition</p>
</td></tr>
<tr><td><code>cost:</code></td>
<td>
<p> a vector of length <code>N</code>. <code>cost[j]</code> is the cost
associated to partition <code>c[[j]]</code></p>
</td></tr>
<tr><td><code>similarity:</code></td>
<td>
<p>  matrix of size <code>n x n</code>. Similarity matrix
(see <code><a href="#topic+similarityMat">similarityMat</a></code>)</p>
</td></tr>
<tr><td><code>opt_ind:</code></td>
<td>
<p> the index of the optimal partition
among the MCMC iterations.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Chariff Alkhassim
</p>


<h3>References</h3>

<p>JW Lau, PJ Green, Bayesian Model-Based Clustering Procedures,
<em>Journal of Computational and Graphical Statistics</em>, 16(3):526-558, 2007.
</p>
<p>DA Binder, Bayesian cluster analysis, <em>Biometrika</em> 65(1):31-38, 1978.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+similarityMat">similarityMat</a></code> <code><a href="#topic+similarityMatC">similarityMatC</a></code>
<code><a href="#topic+similarityMat_nocostC">similarityMat_nocostC</a></code>
</p>

<hr>
<h2 id='cluster_est_pear'>Gets a point estimate of the partition using posterior expected adjusted
Rand index (PEAR)</h2><span id='topic+cluster_est_pear'></span>

<h3>Description</h3>

<p>Gets a point estimate of the partition using posterior expected adjusted
Rand index (PEAR)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cluster_est_pear(c)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cluster_est_pear_+3A_c">c</code></td>
<td>
<p>a list of vector of length <code>n</code>. <code>c[[j]][i]</code> is
the cluster allocation of observation <code>i=1...n</code> at iteration
<code>j=1...N</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>list</code>:
</p>
<table>
<tr><td><code>c_est:</code></td>
<td>
<p> a vector of length <code>n</code>. Point estimate of the partition</p>
</td></tr>
<tr><td><code>pear:</code></td>
<td>
<p> a vector of length <code>N</code>. <code>pear[j]</code> is the
posterior expected adjusted Rand index associated to partition <code>c[[j]]</code></p>
</td></tr>
<tr><td><code>similarity:</code></td>
<td>
<p>  matrix of size <code>n x n</code>. Similarity matrix
(see <code><a href="#topic+similarityMat">similarityMat</a></code>)</p>
</td></tr>
<tr><td><code>opt_ind:</code></td>
<td>
<p> the index of the optimal partition
among the MCMC iterations.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Chariff Alkhassim
</p>


<h3>References</h3>

<p>A. Fritsch, K. Ickstadt. Improved Criteria for Clustering Based
on the Posterior Similarity Matrix, in Bayesian Analysis, Vol.4 : p.367-392
(2009)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+similarityMat">similarityMat</a></code> <code><a href="#topic+similarityMatC">similarityMatC</a></code>
</p>

<hr>
<h2 id='cytoScatter'>Scatterplot of flow cytometry data</h2><span id='topic+cytoScatter'></span>

<h3>Description</h3>

<p>Scatterplot of flow cytometry data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cytoScatter(
  cytomatrix,
  dims2plot = c(1, 2),
  gating = NULL,
  scale_log = FALSE,
  xlim = NULL,
  ylim = NULL,
  gg.add = list(theme())
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cytoScatter_+3A_cytomatrix">cytomatrix</code></td>
<td>
<p>a <code>p x n</code> data matrix, of <code>n</code> cell observations measured over <code>p</code>
markers.</p>
</td></tr>
<tr><td><code id="cytoScatter_+3A_dims2plot">dims2plot</code></td>
<td>
<p>a vector of length at least 2, indicating of the dimensions to be plotted.
Default is <code>c(1, 2)</code>.</p>
</td></tr>
<tr><td><code id="cytoScatter_+3A_gating">gating</code></td>
<td>
<p>an optional vector of length <code>n</code> indicating a known gating of the cells to be 
displayed. Default is <code>NULL</code> in which case no gating is displayed.</p>
</td></tr>
<tr><td><code id="cytoScatter_+3A_scale_log">scale_log</code></td>
<td>
<p>a logical Flag indicating whether the data should be plotted on the log scale.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="cytoScatter_+3A_xlim">xlim</code></td>
<td>
<p>a vector of length 2 to specify the x-axis limits. Only used if <code>dims2plot</code> is
of length 2Default is the data range.</p>
</td></tr>
<tr><td><code id="cytoScatter_+3A_ylim">ylim</code></td>
<td>
<p>a vector of length 2 to specify the y-axis limits. Only used if <code>dims2plot</code> is
of length 2. Default is the data range.</p>
</td></tr>
<tr><td><code id="cytoScatter_+3A_gg.add">gg.add</code></td>
<td>
<p>A list of instructions to add to the <code>ggplot2</code> instruction (see <code><a href="ggplot2.html#topic+gg-add">gg-add</a></code>).
Default is <code>list(theme())</code>, which adds nothing.
to the plot.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
rm(list=ls())
#Number of data
n &lt;- 500
#n &lt;- 2000
set.seed(1234)
#set.seed(123)
#set.seed(4321)

# Sample data
m &lt;- matrix(nrow=2, ncol=4, c(-1, 1, 1.5, 2, 2, -2, -1.5, -2))
p &lt;- c(0.2, 0.1, 0.4, 0.3) # frequence des clusters

sdev &lt;- array(dim=c(2,2,4))
sdev[, ,1] &lt;- matrix(nrow=2, ncol=2, c(0.3, 0, 0, 0.3))
sdev[, ,2] &lt;- matrix(nrow=2, ncol=2, c(0.1, 0, 0, 0.3))
sdev[, ,3] &lt;- matrix(nrow=2, ncol=2, c(0.3, 0.15, 0.15, 0.3))
sdev[, ,4] &lt;- .3*diag(2)
c &lt;- rep(0,n)
z &lt;- matrix(0, nrow=2, ncol=n)
for(k in 1:n){
 c[k] = which(rmultinom(n=1, size=1, prob=p)!=0)
 z[,k] &lt;- m[, c[k]] + sdev[, , c[k]]%*%matrix(rnorm(2, mean = 0, sd = 1), nrow=2, ncol=1)
 #cat(k, "/", n, " observations simulated\n", sep="")
}

cytoScatter(z)

</code></pre>

<hr>
<h2 id='DPMGibbsN'>Slice Sampling of the Dirichlet Process Mixture Model with a prior on alpha</h2><span id='topic+DPMGibbsN'></span>

<h3>Description</h3>

<p>Slice Sampling of the Dirichlet Process Mixture Model with a prior on alpha
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DPMGibbsN(
  z,
  hyperG0,
  a = 1e-04,
  b = 1e-04,
  N,
  doPlot = TRUE,
  nbclust_init = 30,
  plotevery = N/10,
  diagVar = TRUE,
  use_variance_hyperprior = TRUE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DPMGibbsN_+3A_z">z</code></td>
<td>
<p>data matrix <code>d x n</code> with <code>d</code> dimensions in rows and <code>n</code> observations in
columns.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_+3A_hyperg0">hyperG0</code></td>
<td>
<p>prior mixing distribution.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_+3A_a">a</code></td>
<td>
<p>shape hyperparameter of the Gamma prior on the concentration parameter of the Dirichlet
Process. Default is <code>0.0001</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_+3A_b">b</code></td>
<td>
<p>scale hyperparameter of the Gamma prior on the concentration parameter of the Dirichlet
Process. Default is <code>0.0001</code>. If <code>0</code>, then the concentration is fixed set to <code>a</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_+3A_n">N</code></td>
<td>
<p>number of MCMC iterations.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_+3A_doplot">doPlot</code></td>
<td>
<p>logical flag indicating whether to plot MCMC iteration or not. Default to
<code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_+3A_nbclust_init">nbclust_init</code></td>
<td>
<p>number of clusters at initialization. Default to 30 (or less if there are less
than 30 observations).</p>
</td></tr>
<tr><td><code id="DPMGibbsN_+3A_plotevery">plotevery</code></td>
<td>
<p>an integer indicating the interval between plotted iterations when <code>doPlot</code>
is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_+3A_diagvar">diagVar</code></td>
<td>
<p>logical flag indicating whether the variance of each cluster is estimated as a
diagonal matrix, or as a full matrix. Default is <code>TRUE</code> (diagonal variance).</p>
</td></tr>
<tr><td><code id="DPMGibbsN_+3A_use_variance_hyperprior">use_variance_hyperprior</code></td>
<td>
<p>logical flag indicating whether a hyperprior is added 
for the variance parameter. Default is <code>TRUE</code> which decrease the impact of the variance prior
on the posterior. <code>FALSE</code> is useful for using an informative prior.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_+3A_verbose">verbose</code></td>
<td>
<p>logical flag indicating whether partition info is written in the console at each
MCMC iteration.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code><a href="#topic+plot_DPM">plot_DPM</a></code>. Only used if <code>doPlot</code>
is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a object of class <code>DPMclust</code> with the following attributes:
</p>
<table>
<tr><td><code>mcmc_partitions:</code></td>
<td>
<p> a list of length <code>N</code>. Each
element <code>mcmc_partitions[n]</code> is a vector of length
<code>n</code> giving the partition of the <code>n</code> observations.</p>
</td></tr>
<tr><td><code>alpha:</code></td>
<td>
<p> a vector of length <code>N</code>. <code>cost[j]</code> is the cost
associated to partition <code>c[[j]]</code></p>
</td></tr>
<tr><td><code>listU_mu:</code></td>
<td>
<p>a list of length <code>N</code> containing the matrices of
mean vectors for all the mixture components at each MCMC iteration</p>
</td></tr>
<tr><td><code>listU_Sigma:</code></td>
<td>
<p>a list of length <code>N</code> containing the arrays of
covariances matrices for all the mixture components at each MCMC iteration</p>
</td></tr>
<tr><td><code>U_SS_list:</code></td>
<td>
<p>a list of length <code>N</code> containing the lists of
sufficient statistics for all the mixture components at each MCMC iteration</p>
</td></tr>
<tr><td><code>weights_list:</code></td>
<td>
<p>a list of length <code>N</code> containing the logposterior values
at each MCMC iterations</p>
</td></tr>
<tr><td><code>logposterior_list:</code></td>
<td>
<p>a list of length <code>N</code> containing the logposterior values
at each MCMC iterations</p>
</td></tr>
<tr><td><code>data:</code></td>
<td>
<p> the data matrix <code>d x n</code> with <code>d</code> dimensions in rows
and <code>n</code> observations in columns.</p>
</td></tr>
<tr><td><code>nb_mcmcit:</code></td>
<td>
<p> the number of MCMC iterations</p>
</td></tr>
<tr><td><code>clust_distrib:</code></td>
<td>
<p>the parametric distribution of the mixture component - <code>"gaussian"</code></p>
</td></tr>
<tr><td><code>hyperG0:</code></td>
<td>
<p>the prior on the cluster location</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boris Hejblum
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rm(list=ls())
#Number of data
n &lt;- 500
d &lt;- 4
#n &lt;- 2000
set.seed(1234)
#set.seed(123)
#set.seed(4321)

# Sample data
m &lt;- matrix(nrow=d, ncol=4, c(-1, 1, 1.5, 2, 2, -2, -1.5, -2))
p &lt;- c(0.2, 0.1, 0.4, 0.3) # frequence des clusters

sdev &lt;- array(dim=c(d,d,4))
sdev[, ,1] &lt;- 0.3*diag(d)
sdev[, ,2] &lt;- c(0.1, 0.3)*diag(d)
sdev[, ,3] &lt;- matrix(nrow=d, ncol=d, 0.15)
diag(sdev[, ,3]) &lt;- 0.3
sdev[, ,4] &lt;- 0.3*diag(d)
c &lt;- rep(0,n)
z &lt;- matrix(0, nrow=d, ncol=n)
for(k in 1:n){
 c[k] = which(rmultinom(n=1, size=1, prob=p)!=0)
 z[,k] &lt;- m[, c[k]] + sdev[, , c[k]]%*%matrix(rnorm(d, mean = 0, sd = 1), nrow=d, ncol=1)
 #cat(k, "/", n, " observations simulated\n", sep="")
}

 # Set parameters of G0
 hyperG0 &lt;- list()
 hyperG0[["mu"]] &lt;- rep(0,d)
 hyperG0[["kappa"]] &lt;- 0.001
 hyperG0[["nu"]] &lt;- d+2
 hyperG0[["lambda"]] &lt;- diag(d)/10

 # hyperprior on the Scale parameter of DPM
 a &lt;- 0.0001
 b &lt;- 0.0001

 # Number of iterations
 N &lt;- 30

 # do some plots
 doPlot &lt;- TRUE
 nbclust_init &lt;- 30



 ## Data
 ########
 library(ggplot2)
 p &lt;- (ggplot(data.frame("X"=z[1,], "Y"=z[2,]), aes(x=X, y=Y))
       + geom_point()
       + ggtitle("Toy example Data"))
 p


 ## alpha priors plots
 #####################
 prioralpha &lt;- data.frame("alpha"=rgamma(n=5000, shape=a, scale=1/b),
                         "distribution" =factor(rep("prior",5000),
                         levels=c("prior", "posterior")))
 p &lt;- (ggplot(prioralpha, aes(x=alpha))
       + geom_histogram(aes(y=..density..),
                        colour="black", fill="white", bins=30)
       + geom_density(alpha=.6, fill="red", color=NA)
       + ggtitle(paste("Prior distribution on alpha: Gamma(", a,
                 ",", b, ")\n", sep=""))
       + theme_bw()
      )
 p


if(interactive()){
 # Gibbs sampler for Dirichlet Process Mixtures
 ##############################################

 MCMCsample &lt;- DPMGibbsN(z, hyperG0, a, b, N=500, doPlot, nbclust_init, plotevery=100,
                         gg.add=list(theme_bw(),
                                 guides(shape=guide_legend(override.aes = list(fill="grey45")))),
                         diagVar=FALSE)

 plot_ConvDPM(MCMCsample, from=2)

 s &lt;- summary(MCMCsample, burnin = 200, thin=2, posterior_approx=FALSE,
 lossFn = "MBinderN")

 F &lt;- FmeasureC(pred=s$point_estim$c_est, ref=c)

 postalpha &lt;- data.frame("alpha"=MCMCsample$alpha[50:500],
                         "distribution" = factor(rep("posterior",500-49),
                         levels=c("prior", "posterior")))
 p &lt;- (ggplot(postalpha, aes(x=alpha))
       + geom_histogram(aes(y=..density..), binwidth=.1,
                        colour="black", fill="white")
       + geom_density(alpha=.2, fill="blue")
       + ggtitle("Posterior distribution of alpha\n")
       # Ignore NA values for mean
       # Overlay with transparent density plot
       + geom_vline(aes(xintercept=mean(alpha, na.rm=TRUE)),
                    color="red", linetype="dashed", size=1)
     )
 p

 p &lt;- (ggplot(drop=FALSE, alpha=.6)
       + geom_density(aes(x=alpha, fill=distribution),
                      color=NA, alpha=.6,
                      data=prioralpha)
       #+ geom_density(aes(x=alpha, fill=distribution),
       #               color=NA, alpha=.6,
       #               data=postalpha)
       + ggtitle("Prior and posterior distributions of alpha\n")
       + scale_fill_discrete(drop=FALSE)
       + theme_bw()
       +xlim(0,10)
       +ylim(0, 1.3)
     )
 p

}

# k-means comparison
####################

 plot(x=z[1,], y=z[2,], col=kmeans(t(z), centers=4)$cluster,
      xlab = "d = 1", ylab= "d = 2", main="k-means with K=4 clusters")

 KM &lt;- kmeans(t(z), centers=4)
 dataKM &lt;- data.frame("X"=z[1,], "Y"=z[2,],
                    "Cluster"=as.character(KM$cluster))
 dataCenters &lt;- data.frame("X"=KM$centers[,1],
                           "Y"=KM$centers[,2],
                           "Cluster"=rownames(KM$centers))

 p &lt;- (ggplot(dataKM)
       + geom_point(aes(x=X, y=Y, col=Cluster))
       + geom_point(aes(x=X, y=Y, fill=Cluster, order=Cluster),
                    data=dataCenters, shape=22, size=5)
       + scale_colour_discrete(name="Cluster")
       + ggtitle("K-means with K=4 clusters\n"))
 p




</code></pre>

<hr>
<h2 id='DPMGibbsN_parallel'>Slice Sampling of the Dirichlet Process Mixture Model
with a prior on alpha</h2><span id='topic+DPMGibbsN_parallel'></span>

<h3>Description</h3>

<p>Slice Sampling of the Dirichlet Process Mixture Model
with a prior on alpha
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DPMGibbsN_parallel(
  Ncpus,
  type_connec,
  z,
  hyperG0,
  a = 1e-04,
  b = 1e-04,
  N,
  doPlot = TRUE,
  nbclust_init = 30,
  plotevery = N/10,
  diagVar = TRUE,
  use_variance_hyperprior = TRUE,
  verbose = TRUE,
  monitorfile = "",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DPMGibbsN_parallel_+3A_ncpus">Ncpus</code></td>
<td>
<p>the number of processors available</p>
</td></tr>
<tr><td><code id="DPMGibbsN_parallel_+3A_type_connec">type_connec</code></td>
<td>
<p>The type of connection between the processors. Supported
cluster types are <code>"SOCK"</code>, <code>"FORK"</code>, <code>"MPI"</code>, and
<code>"NWS"</code>. See also <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_parallel_+3A_z">z</code></td>
<td>
<p>data matrix <code>d x n</code> with <code>d</code> dimensions in rows
and <code>n</code> observations in columns.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_parallel_+3A_hyperg0">hyperG0</code></td>
<td>
<p>prior mixing distribution.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_parallel_+3A_a">a</code></td>
<td>
<p>shape hyperparameter of the Gamma prior
on the concentration parameter of the Dirichlet Process. Default is <code>0.0001</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_parallel_+3A_b">b</code></td>
<td>
<p>scale hyperparameter of the Gamma prior
on the concentration parameter of the Dirichlet Process. Default is <code>0.0001</code>. If <code>0</code>, 
then the concentration is fixed set to <code>a</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_parallel_+3A_n">N</code></td>
<td>
<p>number of MCMC iterations.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_parallel_+3A_doplot">doPlot</code></td>
<td>
<p>logical flag indicating whether to plot MCMC iteration or not.
Default to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_parallel_+3A_nbclust_init">nbclust_init</code></td>
<td>
<p>number of clusters at initialization.
Default to 30 (or less if there are less than 30 observations).</p>
</td></tr>
<tr><td><code id="DPMGibbsN_parallel_+3A_plotevery">plotevery</code></td>
<td>
<p>an integer indicating the interval between plotted iterations when <code>doPlot</code>
is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_parallel_+3A_diagvar">diagVar</code></td>
<td>
<p>logical flag indicating whether the variance of each cluster is
estimated as a diagonal matrix, or as a full matrix.
Default is <code>TRUE</code> (diagonal variance).</p>
</td></tr>
<tr><td><code id="DPMGibbsN_parallel_+3A_use_variance_hyperprior">use_variance_hyperprior</code></td>
<td>
<p>logical flag indicating whether a hyperprior is added 
for the variance parameter. Default is <code>TRUE</code> which decrease the impact of the variance prior
on the posterior. <code>FALSE</code> is useful for using an informative prior.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_parallel_+3A_verbose">verbose</code></td>
<td>
<p>logical flag indicating whether partition info is
written in the console at each MCMC iteration.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_parallel_+3A_monitorfile">monitorfile</code></td>
<td>
<p>a writable <a href="base.html#topic+connections">connections</a> or a character string naming a file to write into,
to monitor the progress of the analysis.
Default is <code>""</code> which is no monitoring.  See Details.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_parallel_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code><a href="#topic+plot_DPM">plot_DPM</a></code>.
Only used if <code>doPlot</code> is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a object of class <code>DPMclust</code> with the following attributes:
</p>
<table>
<tr><td><code>mcmc_partitions:</code></td>
<td>
<p> a list of length <code>N</code>. Each
element <code>mcmc_partitions[n]</code> is a vector of length
<code>n</code> giving the partition of the <code>n</code> observations.</p>
</td></tr>
<tr><td><code>alpha:</code></td>
<td>
<p>a vector of length <code>N</code>. <code>cost[j]</code> is the cost
associated to partition <code>c[[j]]</code></p>
</td></tr>
<tr><td><code>listU_mu:</code></td>
<td>
<p>a list of length <code>N</code> containing the matrices of
mean vectors for all the mixture components at each MCMC iteration</p>
</td></tr>
<tr><td><code>listU_Sigma:</code></td>
<td>
<p>a list of length <code>N</code> containing the arrays of
covariances matrices for all the mixture components at each MCMC iteration</p>
</td></tr>
<tr><td><code>U_SS_list:</code></td>
<td>
<p>a list of length <code>N</code> containing the lists of
sufficient statistics for all the mixture components at each MCMC iteration</p>
</td></tr>
<tr><td><code>weights_list:</code></td>
<td>
<p>a list of length <code>N</code> containing the logposterior values
at each MCMC iterations</p>
</td></tr>
<tr><td><code>logposterior_list:</code></td>
<td>
<p>a list of length <code>N</code> containing the logposterior values
at each MCMC iterations</p>
</td></tr>
<tr><td><code>data:</code></td>
<td>
<p>the data matrix <code>d x n</code> with <code>d</code> dimensions in rows
and <code>n</code> observations in columns</p>
</td></tr>
<tr><td><code>nb_mcmcit:</code></td>
<td>
<p> the number of MCMC iterations</p>
</td></tr>
<tr><td><code>clust_distrib:</code></td>
<td>
<p>the parametric distribution of the mixture component - <code>"gaussian"</code></p>
</td></tr>
<tr><td><code>hyperG0:</code></td>
<td>
<p>the prior on the cluster location</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boris Hejblum
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DPMGibbsN">DPMGibbsN</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Scaling up: ----
rm(list=ls())
#Number of data
n &lt;- 2000
set.seed(1234)

# Sample data
d &lt;- 3
nclust &lt;- 5
m &lt;- matrix(nrow=d, ncol=nclust, runif(d*nclust)*8)
# p: cluster probabilities
p &lt;- runif(nclust)
p &lt;- p/sum(p)

# Covariance matrix of the clusters
sdev &lt;- array(dim=c(d, d, nclust))
for (j in 1:nclust){
    sdev[, ,j] &lt;- matrix(NA, nrow=d, ncol=d)
    diag(sdev[, ,j]) &lt;- abs(rnorm(n=d, mean=0.3, sd=0.1))
    sdev[, ,j][lower.tri(sdev[, ,j], diag = FALSE)] &lt;- rnorm(n=d*(d-1)/2,
    mean=0, sd=0.05)
    sdev[, ,j][upper.tri(sdev[, ,j], diag = FALSE)] &lt;- (sdev[, ,j][
                                                        lower.tri(sdev[, ,j], diag = FALSE)])
}
c &lt;- rep(0,n)
z &lt;- matrix(0, nrow=d, ncol=n)
for(k in 1:n){
    c[k] = which(rmultinom(n=1, size=1, prob=p)!=0)
    z[,k] &lt;- m[, c[k]] + sdev[, , c[k]]%*%matrix(rnorm(d, mean = 0, sd = 1), nrow=d, ncol=1)
    #cat(k, "/", n, " observations simulated\n", sep="")
}

# hyperprior on the Scale parameter of DPM
a &lt;- 0.001
b &lt;- 0.001

# Number of iterations
N &lt;- 25

# do some plots
doPlot &lt;- TRUE

# Set parameters of G0
hyperG0 &lt;- list()
hyperG0[["mu"]] &lt;- rep(0, d)
hyperG0[["kappa"]] &lt;- 0.01
hyperG0[["nu"]] &lt;- d + 2
hyperG0[["lambda"]] &lt;- diag(d)/10


nbclust_init &lt;- 30

if(interactive()){
 library(doParallel)
 MCMCsample &lt;- DPMGibbsN_parallel(Ncpus=2, type_connec="FORK", z, hyperG0, a, b, 
                                  N=1000, doPlot=FALSE, nbclust_init=30, 
                                  plotevery=100, gg.add=list(ggplot2::theme_bw(),
                                  ggplot2::guides(shape = 
                                    ggplot2::guide_legend(override.aes = list(fill="grey45")))),
                                  diagVar=FALSE)
}


</code></pre>

<hr>
<h2 id='DPMGibbsN_SeqPrior'>Slice Sampling of Dirichlet Process Mixture of Gaussian distributions</h2><span id='topic+DPMGibbsN_SeqPrior'></span>

<h3>Description</h3>

<p>Slice Sampling of Dirichlet Process Mixture of Gaussian distributions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DPMGibbsN_SeqPrior(
  z,
  prior_inform,
  hyperG0,
  N,
  nbclust_init,
  add.vagueprior = TRUE,
  weightnoninfo = NULL,
  doPlot = TRUE,
  plotevery = N/10,
  diagVar = TRUE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DPMGibbsN_SeqPrior_+3A_z">z</code></td>
<td>
<p>data matrix <code>d x n</code> with <code>d</code> dimensions in rows
and <code>n</code> observations in columns.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_SeqPrior_+3A_prior_inform">prior_inform</code></td>
<td>
<p>an informative prior such as the approximation computed by <code>summary.DPMMclust</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_SeqPrior_+3A_hyperg0">hyperG0</code></td>
<td>
<p>a non informative prior component for the mixing distribution.
Only used if <code>add.vagueprior</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_SeqPrior_+3A_n">N</code></td>
<td>
<p>number of MCMC iterations.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_SeqPrior_+3A_nbclust_init">nbclust_init</code></td>
<td>
<p>number of clusters at initialization.
Default to 30 (or less if there are less than 30 observations).</p>
</td></tr>
<tr><td><code id="DPMGibbsN_SeqPrior_+3A_add.vagueprior">add.vagueprior</code></td>
<td>
<p>logical flag indicating whether a non informative component should
be added to the informative prior. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_SeqPrior_+3A_weightnoninfo">weightnoninfo</code></td>
<td>
<p>a real between 0 and 1 giving the weights of the non informative component
in the prior.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_SeqPrior_+3A_doplot">doPlot</code></td>
<td>
<p>logical flag indicating whether to plot MCMC iteration or not.
Default to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_SeqPrior_+3A_plotevery">plotevery</code></td>
<td>
<p>an integer indicating the interval between plotted iterations when <code>doPlot</code>
is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_SeqPrior_+3A_diagvar">diagVar</code></td>
<td>
<p>logical flag indicating whether the variance of each cluster is
estimated as a diagonal matrix, or as a full matrix.
Default is <code>TRUE</code> (diagonal variance).</p>
</td></tr>
<tr><td><code id="DPMGibbsN_SeqPrior_+3A_verbose">verbose</code></td>
<td>
<p>logical flag indicating whether partition info is
written in the console at each MCMC iteration.</p>
</td></tr>
<tr><td><code id="DPMGibbsN_SeqPrior_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code><a href="#topic+plot_DPM">plot_DPM</a></code>.
Only used if <code>doPlot</code> is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a object of class <code>DPMclust</code> with the following attributes:
</p>
<table>
<tr><td><code>mcmc_partitions:</code></td>
<td>
<p> a list of length <code>N</code>. Each
element <code>mcmc_partitions[n]</code> is a vector of length
<code>n</code> giving the partition of the <code>n</code> observations.</p>
</td></tr>
<tr><td><code>alpha:</code></td>
<td>
<p> a vector of length <code>N</code>. <code>cost[j]</code> is the cost
associated to partition <code>c[[j]]</code></p>
</td></tr>
<tr><td><code>listU_mu:</code></td>
<td>
<p> a list of length <code>N</code> containing the matrices of
mean vectors for all the mixture components at each MCMC iteration</p>
</td></tr>
<tr><td><code>listU_Sigma:</code></td>
<td>
<p> a list of length <code>N</code> containing the arrays of
covariances matrices for all the mixture components at each MCMC iteration</p>
</td></tr>
<tr><td><code>U_SS_list:</code></td>
<td>
<p> a list of length <code>N</code> containing the lists of
sufficient statistics for all the mixture components at each MCMC iteration</p>
</td></tr>
<tr><td><code>weights_list:</code></td>
<td>
</td></tr>
<tr><td><code>logposterior_list:</code></td>
<td>
<p> a list of length <code>N</code> containing the logposterior values
at each MCMC iterations</p>
</td></tr>
<tr><td><code>data:</code></td>
<td>
<p> the data matrix <code>d x n</code> with <code>d</code> dimensions in rows
and <code>n</code> observations in columns.</p>
</td></tr>
<tr><td><code>nb_mcmcit:</code></td>
<td>
<p> the number of MCMC iterations</p>
</td></tr>
<tr><td><code>clust_distrib:</code></td>
<td>
<p> the parametric distribution of the mixture component - <code>"gaussian"</code></p>
</td></tr>
<tr><td><code>hyperG0:</code></td>
<td>
<p> the prior on the cluster location</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boris Hejblum, Chariff Alkhassim
</p>


<h3>References</h3>

<p>Hejblum BP, Alkhassim C, Gottardo R, Caron F and Thiebaut R (2019) 
Sequential Dirichlet Process Mixtures of Multivariate Skew t-distributions for 
Model-based Clustering of Flow Cytometry Data. The Annals of Applied Statistics, 
13(1): 638-660. &lt;doi: 10.1214/18-AOAS1209&gt; &lt;arXiv: 1702.04407&gt; 
<a href="https://arxiv.org/abs/1702.04407">https://arxiv.org/abs/1702.04407</a> <a href="https://doi.org/10.1214/18-AOAS1209">doi:10.1214/18-AOAS1209</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+postProcess.DPMMclust">postProcess.DPMMclust</a></code> <code><a href="#topic+DPMGibbsN">DPMGibbsN</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
rm(list=ls())
library(NPflow)
#Number of data
n &lt;- 1500
# Sample data
#m &lt;- matrix(nrow=2, ncol=4, c(-1, 1, 1.5, 2, 2, -2, 0.5, -2))
m &lt;- matrix(nrow=2, ncol=4, c(-.8, .7, .5, .7, .5, -.7, -.5, -.7))
p &lt;- c(0.2, 0.1, 0.4, 0.3) # frequence des clusters

sdev &lt;- array(dim=c(2,2,4))
sdev[, ,1] &lt;- matrix(nrow=2, ncol=2, c(0.3, 0, 0, 0.3))
sdev[, ,2] &lt;- matrix(nrow=2, ncol=2, c(0.1, 0, 0, 0.3))
sdev[, ,3] &lt;- matrix(nrow=2, ncol=2, c(0.3, 0.15, 0.15, 0.3))
sdev[, ,4] &lt;- .3*diag(2)
c &lt;- rep(0,n)
z &lt;- matrix(0, nrow=2, ncol=n)
for(k in 1:n){
 c[k] = which(rmultinom(n=1, size=1, prob=p)!=0)
 z[,k] &lt;- m[, c[k]] + sdev[, , c[k]]%*%matrix(rnorm(2, mean = 0, sd = 1), nrow=2, ncol=1)
 #cat(k, "/", n, " observations simulated\n", sep="")
}

d&lt;-2
# Set parameters of G0
hyperG0 &lt;- list()
hyperG0[["mu"]] &lt;- rep(0,d)
hyperG0[["kappa"]] &lt;- 0.001
hyperG0[["nu"]] &lt;- d+2
hyperG0[["lambda"]] &lt;- diag(d)/10

# hyperprior on the Scale parameter of DPM
a &lt;- 0.0001
b &lt;- 0.0001

# Number of iterations
N &lt;- 30

# do some plots
doPlot &lt;- TRUE
nbclust_init &lt;- 20



## Data
########
library(ggplot2)
p &lt;- (ggplot(data.frame("X"=z[1,], "Y"=z[2,]), aes(x=X, y=Y))
      + geom_point()
      + ggtitle("Toy example Data"))
p


if(interactive()){
# Gibbs sampler for Dirichlet Process Mixtures
##############################################

MCMCsample &lt;- DPMGibbsN(z, hyperG0, a, b, N=1500, doPlot, nbclust_init, plotevery=200,
                        gg.add=list(theme_bw(),
                                 guides(shape=guide_legend(override.aes = list(fill="grey45")))),
                        diagVar=FALSE)

s &lt;- summary(MCMCsample, posterior_approx=TRUE, burnin = 1000, thin=5)
F1 &lt;- FmeasureC(pred=s$point_estim$c_est, ref=c)
F1


MCMCsample2 &lt;- DPMGibbsN_SeqPrior(z, prior_inform=s$param_posterior,
                                  hyperG0, N=1500,
                                  add.vagueprior = TRUE,
                                  doPlot=TRUE, plotevery=100,
                                  nbclust_init=nbclust_init,
                                  gg.add=list(theme_bw(),
                                 guides(shape=guide_legend(override.aes = list(fill="grey45")))),
                                  diagVar=FALSE)


s2 &lt;- summary(MCMCsample2, burnin = 500, thin=5)
F2 &lt;- FmeasureC(pred=s2$point_estim$c_est, ref=c)
F2
}
</code></pre>

<hr>
<h2 id='DPMGibbsSkewN'>Slice Sampling of Dirichlet Process Mixture of skew normal distributions</h2><span id='topic+DPMGibbsSkewN'></span>

<h3>Description</h3>

<p>Slice Sampling of Dirichlet Process Mixture of skew normal distributions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DPMGibbsSkewN(
  z,
  hyperG0,
  a = 1e-04,
  b = 1e-04,
  N,
  doPlot = TRUE,
  nbclust_init = 30,
  plotevery = N/10,
  diagVar = TRUE,
  use_variance_hyperprior = TRUE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DPMGibbsSkewN_+3A_z">z</code></td>
<td>
<p>data matrix <code>d x n</code> with <code>d</code> dimensions in rows
and <code>n</code> observations in columns.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_+3A_hyperg0">hyperG0</code></td>
<td>
<p>prior mixing distribution.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_+3A_a">a</code></td>
<td>
<p>shape hyperparameter of the Gamma prior
on the concentration parameter of the Dirichlet Process. Default is <code>0.0001</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_+3A_b">b</code></td>
<td>
<p>scale hyperparameter of the Gamma prior
on the concentration parameter of the Dirichlet Process. Default is <code>0.0001</code>. If <code>0</code>, 
then the concentration is fixed set to <code>a</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_+3A_n">N</code></td>
<td>
<p>number of MCMC iterations.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_+3A_doplot">doPlot</code></td>
<td>
<p>logical flag indicating whether to plot MCMC iteration or not.
Default to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_+3A_nbclust_init">nbclust_init</code></td>
<td>
<p>number of clusters at initialization.
Default to 30 (or less if there are less than 30 observations).</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_+3A_plotevery">plotevery</code></td>
<td>
<p>an integer indicating the interval between plotted iterations when <code>doPlot</code>
is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_+3A_diagvar">diagVar</code></td>
<td>
<p>logical flag indicating whether the variance of a cluster is a diagonal matrix.
Default is <code>FALSE</code> (full matrix).</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_+3A_use_variance_hyperprior">use_variance_hyperprior</code></td>
<td>
<p>logical flag indicating whether a hyperprior is added 
for the variance parameter. Default is <code>TRUE</code> which decrease the impact of the variance prior
on the posterior. <code>FALSE</code> is useful for using an informative prior.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_+3A_verbose">verbose</code></td>
<td>
<p>logical flag indicating whether partition info is
written in the console at each MCMC iteration.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code><a href="#topic+plot_DPMsn">plot_DPMsn</a></code>.
Only used if <code>doPlot</code> is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a object of class <code>DPMclust</code> with the following attributes:
</p>
<table>
<tr><td><code>mcmc_partitions:</code></td>
<td>
<p>a list of length <code>N</code>. Each
element <code>mcmc_partitions[n]</code> is a vector of length
<code>n</code> giving the partition of the <code>n</code> observations.</p>
</td></tr>
<tr><td><code>alpha:</code></td>
<td>
<p> a vector of length <code>N</code>. <code>cost[j]</code> is the cost
associated to partition <code>c[[j]]</code></p>
</td></tr>
<tr><td><code>U_SS_list:</code></td>
<td>
<p>a list of length <code>N</code> containing the lists of
sufficient statistics for all the mixture components at each MCMC iteration</p>
</td></tr>
<tr><td><code>weights_list:</code></td>
<td>
</td></tr>
<tr><td><code>logposterior_list:</code></td>
<td>
<p>a list of length <code>N</code> containing the logposterior values
at each MCMC iterations</p>
</td></tr>
<tr><td><code>data:</code></td>
<td>
<p>the data matrix <code>d x n</code> with <code>d</code> dimensions in rows
and <code>n</code> observations in columns</p>
</td></tr>
<tr><td><code>nb_mcmcit:</code></td>
<td>
<p>the number of MCMC iterations</p>
</td></tr>
<tr><td><code>clust_distrib:</code></td>
<td>
<p>the parametric distribution of the mixture component - <code>"skewnorm"</code></p>
</td></tr>
<tr><td><code>hyperG0:</code></td>
<td>
<p>the prior on the cluster location</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boris Hejblum
</p>


<h3>References</h3>

<p>Hejblum BP, Alkhassim C, Gottardo R, Caron F and Thiebaut R (2019) 
Sequential Dirichlet Process Mixtures of Multivariate Skew t-distributions for 
Model-based Clustering of Flow Cytometry Data. The Annals of Applied Statistics, 
13(1): 638-660. &lt;doi: 10.1214/18-AOAS1209&gt; &lt;arXiv: 1702.04407&gt; 
<a href="https://arxiv.org/abs/1702.04407">https://arxiv.org/abs/1702.04407</a> <a href="https://doi.org/10.1214/18-AOAS1209">doi:10.1214/18-AOAS1209</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rm(list=ls())

#Number of data
n &lt;- 1000
set.seed(123)

d &lt;- 2
ncl &lt;- 4

# Sample data

sdev &lt;- array(dim=c(d,d,ncl))

#xi &lt;- matrix(nrow=d, ncol=ncl, c(-1.5, 1, 1.5, 1, 1.5, -2, -2, -2))
xi &lt;- matrix(nrow=d, ncol=ncl, c(-0.5, 0, 0.5, 0, 0.5, -1, -1, 1))
##xi &lt;- matrix(nrow=d, ncol=ncl, c(-0.3, 0, 0.5, 0.5, 0.5, -1.2, -1, 1))
psi &lt;- matrix(nrow=d, ncol=4, c(0.4, -0.6, 0.8, 0, 0.3, -0.7, -0.3, -1.2))
p &lt;- c(0.2, 0.1, 0.4, 0.3) # frequence des clusters
sdev[, ,1] &lt;- matrix(nrow=d, ncol=d, c(0.3, 0, 0, 0.3))
sdev[, ,2] &lt;- matrix(nrow=d, ncol=d, c(0.1, 0, 0, 0.3))
sdev[, ,3] &lt;- matrix(nrow=d, ncol=d, c(0.3, 0.15, 0.15, 0.3))
sdev[, ,4] &lt;- .3*diag(2)


c &lt;- rep(0,n)
z &lt;- matrix(0, nrow=d, ncol=n)
for(k in 1:n){
 c[k] = which(rmultinom(n=1, size=1, prob=p)!=0)
 z[,k] &lt;- xi[, c[k]] + psi[, c[k]]*abs(rnorm(1)) + sdev[, , c[k]]%*%matrix(rnorm(d, mean = 0,
                                                                       sd = 1), nrow=d, ncol=1)
 #cat(k, "/", n, " observations simulated\n", sep="")
}

# Set parameters of G0
hyperG0 &lt;- list()
hyperG0[["b_xi"]] &lt;- rep(0,d)
hyperG0[["b_psi"]] &lt;- rep(0,d)
hyperG0[["kappa"]] &lt;- 0.0001
hyperG0[["D_xi"]] &lt;- 100
hyperG0[["D_psi"]] &lt;- 100
hyperG0[["nu"]] &lt;- d + 1
hyperG0[["lambda"]] &lt;- diag(d)

 # hyperprior on the Scale parameter of DPM
 a &lt;- 0.0001
 b &lt;- 0.0001

 # do some plots
 doPlot &lt;- TRUE
 nbclust_init &lt;- 30



 ## Data
 ########
 library(ggplot2)
 p &lt;- (ggplot(data.frame("X"=z[1,], "Y"=z[2,]), aes(x=X, y=Y))
       + geom_point()
       + ggtitle("Simple example in 2d data")
       +xlab("D1")
       +ylab("D2")
       +theme_bw())
 p

 c2plot &lt;- factor(c)
 levels(c2plot) &lt;- c("3", "2", "4", "1")
 pp &lt;- (ggplot(data.frame("X"=z[1,], "Y"=z[2,], "Cluster"=as.character(c2plot)))
       + geom_point(aes(x=X, y=Y, colour=Cluster, fill=Cluster))
       + ggtitle("Slightly overlapping skew-normal simulation\n")
       + xlab("D1")
       + ylab("D2")
       + theme_bw()
       + scale_colour_discrete(guide=guide_legend(override.aes = list(size = 6, shape=22))))
 pp


 ## alpha priors plots
 #####################
 prioralpha &lt;- data.frame("alpha"=rgamma(n=5000, shape=a, scale=1/b),
                         "distribution" =factor(rep("prior",5000),
                         levels=c("prior", "posterior")))
 p &lt;- (ggplot(prioralpha, aes(x=alpha))
       + geom_histogram(aes(y=..density..),
                        colour="black", fill="white")
       + geom_density(alpha=.2, fill="red")
       + ggtitle(paste("Prior distribution on alpha: Gamma(", a,
                 ",", b, ")\n", sep=""))
      )
 p


if(interactive()){
 # Gibbs sampler for Dirichlet Process Mixtures
 ##############################################

 MCMCsample_sn &lt;- DPMGibbsSkewN(z, hyperG0, a, b, N=2500,
                                doPlot, nbclust_init, plotevery=200,
                                gg.add=list(theme_bw(),
                                 guides(shape=guide_legend(override.aes = list(fill="grey45")))),
                               diagVar=FALSE)

 s &lt;- summary(MCMCsample_sn, burnin = 2000, thin=10)
 #cluster_est_binder(MCMCsample_sn$mcmc_partitions[1000:1500])
 print(s)
 plot(s)
 #plot_ConvDPM(MCMCsample_sn, from=2)






 # k-means

 plot(x=z[1,], y=z[2,], col=kmeans(t(z), centers=4)$cluster,
      xlab = "d = 1", ylab= "d = 2", main="k-means with K=4 clusters")

 KM &lt;- kmeans(t(z), centers=4)
 KMclust &lt;- factor(KM$cluster)
 levels(KMclust) &lt;- c("2", "4", "1", "3")
 dataKM &lt;- data.frame("X"=z[1,], "Y"=z[2,],
                    "Cluster"=as.character(KMclust))
 dataCenters &lt;- data.frame("X"=KM$centers[,1],
                           "Y"=KM$centers[,2],
                           "Cluster"=c("2", "4", "1", "3"))


 p &lt;- (ggplot(dataKM)
       + geom_point(aes(x=X, y=Y, col=Cluster))
       + geom_point(aes(x=X, y=Y, fill=Cluster, order=Cluster),
                    data=dataCenters, shape=22, size=5)
       + scale_colour_discrete(name="Cluster",
                               guide=guide_legend(override.aes=list(size=6, shape=22)))
       + ggtitle("K-means with K=4 clusters\n")
       + theme_bw()
 )
 p

 postalpha &lt;- data.frame("alpha"=MCMCsample_sn$alpha[501:1000],
                         "distribution" = factor(rep("posterior",1000-500),
                         levels=c("prior", "posterior")))

 postK &lt;- data.frame("K"=sapply(lapply(postalpha$alpha, "["),
                                function(x){sum(x/(x+0:(1000-1)))}))

 p &lt;- (ggplot(postalpha, aes(x=alpha))
       + geom_histogram(aes(y=..density..), binwidth=.1,
                        colour="black", fill="white")
       + geom_density(alpha=.2, fill="blue")
       + ggtitle("Posterior distribution of alpha\n")
       # Ignore NA values for mean
       # Overlay with transparent density plot
       + geom_vline(aes(xintercept=mean(alpha, na.rm=T)),
                    color="red", linetype="dashed", size=1)
     )
 p

 p &lt;- (ggplot(postK, aes(x=K))
       + geom_histogram(aes(y=..density..),
                        colour="black", fill="white")
       + geom_density(alpha=.2, fill="blue")
       + ggtitle("Posterior distribution of predicted K\n")
       # Ignore NA values for mean
       # Overlay with transparent density plot
       + geom_vline(aes(xintercept=mean(K, na.rm=T)),
                    color="red", linetype="dashed", size=1)
       #+ scale_x_continuous(breaks=c(0:6)*2, minor_breaks=c(0:6)*2+1)
       + scale_x_continuous(breaks=c(1:12))
     )
 p

 p &lt;- (ggplot(drop=FALSE, alpha=.6)
       + geom_density(aes(x=alpha, fill=distribution),
                      color=NA, alpha=.6,
                      data=postalpha)
       + geom_density(aes(x=alpha, fill=distribution),
                      color=NA, alpha=.6,
                      data=prioralpha)
       + ggtitle("Prior and posterior distributions of alpha\n")
       + scale_fill_discrete(drop=FALSE)
       + theme_bw()
       + xlim(0,100)
     )
 p

#Skew Normal
n=100000
xi &lt;- 0
d &lt;- 0.995
alpha &lt;- d/sqrt(1-d^2)
z &lt;- rtruncnorm(n,a=0, b=Inf)
e &lt;- rnorm(n, mean = 0, sd = 1)
x &lt;- d*z + sqrt(1-d^2)*e
o &lt;- 1
y &lt;- xi+o*x
nu=1.3
w &lt;- rgamma(n,scale=nu/2, shape=nu/2)
yy &lt;- xi+o*x/w
snd &lt;- data.frame("Y"=y,"YY"=yy)
p &lt;- (ggplot(snd)+geom_density(aes(x=Y), fill="blue", alpha=.2)
     + theme_bw()
     + ylab("Density")
     + ggtitle("Y~SN(0,1,10)\n")
     + xlim(-1,6)
     + ylim(0,0.8)
     )
p

p &lt;- (ggplot(snd)+geom_density(aes(x=YY), fill="blue", alpha=.2)
     + theme_bw()
     + ylab("Density")
     + ggtitle("Y~ST(0,1,10,1.3)\n")
     + xlim(-2,40)
     + ylim(0,0.8)
     )
p

p &lt;- (ggplot(snd)
     + geom_density(aes(x=Y, fill="blue"), alpha=.2)
     + geom_density(aes(x=YY, fill="red"), alpha=.2)
     + theme_bw()
     +theme(legend.text = element_text(size = 13), legend.position="bottom")
     + ylab("Density")
     + xlim(-2,40)
     + ylim(0,0.8)
     + scale_fill_manual(name="", labels=c("Y~SN(0,1,10)       ", "Y~ST(0,1,10,1.3)"),
     guide="legend", values=c("blue", "red"))
     )
p

#Variations
n=100000
xi &lt;- -1
d &lt;- 0.995
alpha &lt;- d/sqrt(1-d^2)
z &lt;- rtruncnorm(n,a=0, b=Inf)
e &lt;- rnorm(n, mean = 0, sd = 1)
x &lt;- d*z + sqrt(1-d^2)*e
snd &lt;- data.frame("X"=x)
p &lt;- (ggplot(snd)+geom_density(aes(x=X), fill="blue", alpha=.2)
     + theme_bw()
     + ylab("Density")
     + ggtitle("X~SN(10)\n")
     + xlim(-1.5,4)
     + ylim(0,1.6)
     )
p

o &lt;- 0.5
y &lt;- xi+o*x
snd &lt;- data.frame("Y"=y)
p &lt;- (ggplot(snd)+geom_density(aes(x=Y), fill="blue", alpha=.2)
     + theme_bw()
     + ylab("Density")
     + ggtitle("Y~SN(-1,1,10)\n")
     + xlim(-1.5,4)
     + ylim(0,1.6)
     )
p




#Simple toy example
###################

n &lt;- 500
set.seed(12345)


d &lt;- 2
ncl &lt;- 4

# Sample data

sdev &lt;- array(dim=c(d,d,ncl))

xi &lt;- matrix(nrow=d, ncol=ncl, c(-1.5, 1, 1.5, 1, 1.5, -2, -2, -2))
psi &lt;- matrix(nrow=d, ncol=4, c(0.4, -0.6, 0.8, 0, 0.3, -0.7, -0.3, -1.2))
p &lt;- c(0.2, 0.1, 0.4, 0.3) # frequence des clusters
sdev[, ,1] &lt;- matrix(nrow=d, ncol=d, c(0.3, 0, 0, 0.3))
sdev[, ,2] &lt;- matrix(nrow=d, ncol=d, c(0.1, 0, 0, 0.3))
sdev[, ,3] &lt;- matrix(nrow=d, ncol=d, c(0.3, 0.15, 0.15, 0.3))
sdev[, ,4] &lt;- .3*diag(2)

#' # Set parameters of G0
hyperG0 &lt;- list()
hyperG0[["b_xi"]] &lt;- rep(0,d)
hyperG0[["b_psi"]] &lt;- rep(0,d)
hyperG0[["kappa"]] &lt;- 0.0001
hyperG0[["D_xi"]] &lt;- 100
hyperG0[["D_psi"]] &lt;- 100
hyperG0[["nu"]] &lt;- d + 1
hyperG0[["lambda"]] &lt;- diag(d)


c &lt;- rep(0,n)
z &lt;- matrix(0, nrow=d, ncol=n)
for(k in 1:n){
 c[k] = which(rmultinom(n=1, size=1, prob=p)!=0)
 z[,k] &lt;- xi[, c[k]] + psi[, c[k]]*abs(rnorm(1)) + sdev[, , c[k]]%*%matrix(rnorm(d, mean = 0,
                                                                        sd = 1), nrow=d, ncol=1)
 cat(k, "/", n, " observations simulated\n", sep="")
}

 MCMCsample_sn_sep &lt;- DPMGibbsSkewN(z, hyperG0, a, b, N=600,
                                    doPlot, nbclust_init, plotevery=100,
                                    gg.add=list(theme_bw(),
                               guides(shape=guide_legend(override.aes = list(fill="grey45")))),
                                    diagVar=TRUE)

 s &lt;- summary(MCMCsample_sn, burnin = 400)

}

</code></pre>

<hr>
<h2 id='DPMGibbsSkewN_parallel'>Parallel Implementation of Slice Sampling of Dirichlet Process Mixture of skew normal distributions</h2><span id='topic+DPMGibbsSkewN_parallel'></span>

<h3>Description</h3>

<p>If the <code>monitorfile</code> argument is a character string naming a file to
write into, in the case of a new file that does not exist yet, such a new
file will be created. A line is written at each MCMC iteration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DPMGibbsSkewN_parallel(
  Ncpus,
  type_connec,
  z,
  hyperG0,
  a = 1e-04,
  b = 1e-04,
  N,
  doPlot = FALSE,
  nbclust_init = 30,
  plotevery = N/10,
  diagVar = TRUE,
  use_variance_hyperprior = TRUE,
  verbose = FALSE,
  monitorfile = "",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DPMGibbsSkewN_parallel_+3A_ncpus">Ncpus</code></td>
<td>
<p>the number of processors available</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_parallel_+3A_type_connec">type_connec</code></td>
<td>
<p>The type of connection between the processors. Supported
cluster types are <code>"SOCK"</code>, <code>"FORK"</code>, <code>"MPI"</code>, and
<code>"NWS"</code>. See also <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_parallel_+3A_z">z</code></td>
<td>
<p>data matrix <code>d x n</code> with <code>d</code> dimensions in rows
and <code>n</code> observations in columns.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_parallel_+3A_hyperg0">hyperG0</code></td>
<td>
<p>prior mixing distribution.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_parallel_+3A_a">a</code></td>
<td>
<p>shape hyperparameter of the Gamma prior
on the concentration parameter of the Dirichlet Process. Default is <code>0.0001</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_parallel_+3A_b">b</code></td>
<td>
<p>scale hyperparameter of the Gamma prior
on the concentration parameter of the Dirichlet Process. Default is <code>0.0001</code>. If <code>0</code>, 
then the concentration is fixed set to <code>a</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_parallel_+3A_n">N</code></td>
<td>
<p>number of MCMC iterations.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_parallel_+3A_doplot">doPlot</code></td>
<td>
<p>logical flag indicating whether to plot MCMC iteration or not.
Default to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_parallel_+3A_nbclust_init">nbclust_init</code></td>
<td>
<p>number of clusters at initialization.
Default to 30 (or less if there are less than 30 observations).</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_parallel_+3A_plotevery">plotevery</code></td>
<td>
<p>an integer indicating the interval between plotted iterations when <code>doPlot</code>
is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_parallel_+3A_diagvar">diagVar</code></td>
<td>
<p>logical flag indicating whether the variance of each cluster is
estimated as a diagonal matrix, or as a full matrix.
Default is <code>TRUE</code> (diagonal variance).</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_parallel_+3A_use_variance_hyperprior">use_variance_hyperprior</code></td>
<td>
<p>logical flag indicating whether a hyperprior is added 
for the variance parameter. Default is <code>TRUE</code> which decrease the impact of the variance prior
on the posterior. <code>FALSE</code> is useful for using an informative prior.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_parallel_+3A_verbose">verbose</code></td>
<td>
<p>logical flag indicating whether partition info is
written in the console at each MCMC iteration.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_parallel_+3A_monitorfile">monitorfile</code></td>
<td>
<p>a writable <a href="base.html#topic+connections">connections</a> or a character string naming a file to write into,
to monitor the progress of the analysis.
Default is <code>""</code> which is no monitoring.  See Details.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewN_parallel_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code><a href="#topic+plot_DPM">plot_DPM</a></code>.
Only used if <code>doPlot</code> is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a object of class <code>DPMclust</code> with the following attributes:
</p>
<table>
<tr><td><code>mcmc_partitions:</code></td>
<td>
<p>a list of length <code>N</code>. Each
element <code>mcmc_partitions[n]</code> is a vector of length
<code>n</code> giving the partition of the <code>n</code> observations.</p>
</td></tr>
<tr><td><code>alpha:</code></td>
<td>
<p>a vector of length <code>N</code>. <code>cost[j]</code> is the cost
associated to partition <code>c[[j]]</code></p>
</td></tr>
<tr><td><code>U_SS_list:</code></td>
<td>
<p>a list of length <code>N</code> containing the lists of
sufficient statistics for all the mixture components at each MCMC iteration</p>
</td></tr>
<tr><td><code>weights_list:</code></td>
<td>
</td></tr>
<tr><td><code>logposterior_list:</code></td>
<td>
<p>a list of length <code>N</code> containing the logposterior values
at each MCMC iterations</p>
</td></tr>
<tr><td><code>data:</code></td>
<td>
<p>the data matrix <code>d x n</code> with <code>d</code> dimensions in rows
and <code>n</code> observations in columns</p>
</td></tr>
<tr><td><code>nb_mcmcit:</code></td>
<td>
<p>the number of MCMC iterations</p>
</td></tr>
<tr><td><code>clust_distrib:</code></td>
<td>
<p>the parametric distribution of the mixture component - <code>"skewnorm"</code></p>
</td></tr>
<tr><td><code>hyperG0:</code></td>
<td>
<p>the prior on the cluster location</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boris Hejblum
</p>


<h3>References</h3>

<p>Hejblum BP, Alkhassim C, Gottardo R, Caron F and Thiebaut R (2019) 
Sequential Dirichlet Process Mixtures of Multivariate Skew t-distributions for 
Model-based Clustering of Flow Cytometry Data. The Annals of Applied Statistics, 
13(1): 638-660. &lt;doi: 10.1214/18-AOAS1209&gt; &lt;arXiv: 1702.04407&gt; 
<a href="https://arxiv.org/abs/1702.04407">https://arxiv.org/abs/1702.04407</a> <a href="https://doi.org/10.1214/18-AOAS1209">doi:10.1214/18-AOAS1209</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rm(list=ls())
#Number of data
n &lt;- 2000
set.seed(1234)

d &lt;- 4
ncl &lt;- 5

# Sample data

sdev &lt;- array(dim=c(d,d,ncl))

xi &lt;- matrix(nrow=d, ncol=ncl, c(runif(n=d*ncl,min=0,max=3)))
psi &lt;- matrix(nrow=d, ncol=ncl, c(runif(n=d*ncl,min=-1,max=1)))
p &lt;- runif(n=ncl)
p &lt;- p/sum(p)
sdev0 &lt;- diag(runif(n=d, min=0.05, max=0.6))
for (j in 1:ncl){
     sdev[, ,j] &lt;- invwishrnd(n = d+2, lambda = sdev0)
}


c &lt;- rep(0,n)
z &lt;- matrix(0, nrow=d, ncol=n)
for(k in 1:n){
 c[k] = which(rmultinom(n=1, size=1, prob=p)!=0)
 z[,k] &lt;- xi[, c[k]] + psi[, c[k]]*abs(rnorm(1)) + sdev[, , c[k]]%*%matrix(rnorm(d, mean = 0,
                                                                        sd = 1), nrow=d, ncol=1)
 #cat(k, "/", n, " observations simulated\n", sep="")
}

# Set parameters of G0
hyperG0 &lt;- list()
hyperG0[["b_xi"]] &lt;- rep(0,d)
hyperG0[["b_psi"]] &lt;- rep(0,d)
hyperG0[["kappa"]] &lt;- 0.001
hyperG0[["D_xi"]] &lt;- 100
hyperG0[["D_psi"]] &lt;- 100
hyperG0[["nu"]] &lt;- d + 1
hyperG0[["lambda"]] &lt;- diag(d)/10

 # hyperprior on the Scale parameter of DPM
 a &lt;- 0.0001
 b &lt;- 0.0001

 # do some plots
 doPlot &lt;- TRUE
 nbclust_init &lt;- 30


 z &lt;- z*200
 ## Data
 ########
library(ggplot2)
 p &lt;- (ggplot(data.frame("X"=z[1,], "Y"=z[2,]), aes(x=X, y=Y))
       + geom_point()
       + ggtitle("Simple example in 2d data")
       +xlab("D1")
       +ylab("D2")
       +theme_bw())
 p


 ## alpha priors plots
 #####################
 prioralpha &lt;- data.frame("alpha"=rgamma(n=5000, shape=a, scale=1/b),
                         "distribution" =factor(rep("prior",5000),
                         levels=c("prior", "posterior")))
 p &lt;- (ggplot(prioralpha, aes(x=alpha))
       + geom_histogram(aes(y=..density..),
                        colour="black", fill="white")
       + geom_density(alpha=.2, fill="red")
       + ggtitle(paste("Prior distribution on alpha: Gamma(", a,
                 ",", b, ")\n", sep=""))
      )
 p



 # Gibbs sampler for Dirichlet Process Mixtures
 ##############################################
 if(interactive()){
  MCMCsample_sn_par &lt;- DPMGibbsSkewN_parallel(Ncpus=parallel::detectCores()-1,
                                              type_connec="SOCK", z, hyperG0,
                                              a, b, N=5000, doPlot, nbclust_init,
                                              plotevery=25, gg.add=list(theme_bw(),
                                guides(shape=guide_legend(override.aes = list(fill="grey45")))))
  plot_ConvDPM(MCMCsample_sn_par, from=2)
 }




</code></pre>

<hr>
<h2 id='DPMGibbsSkewT'>Slice Sampling of Dirichlet Process Mixture of skew Student's t-distributions</h2><span id='topic+DPMGibbsSkewT'></span>

<h3>Description</h3>

<p>Slice Sampling of Dirichlet Process Mixture of skew Student's t-distributions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DPMGibbsSkewT(
  z,
  hyperG0,
  a = 1e-04,
  b = 1e-04,
  N,
  doPlot = TRUE,
  nbclust_init = 30,
  plotevery = N/10,
  diagVar = TRUE,
  use_variance_hyperprior = TRUE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DPMGibbsSkewT_+3A_z">z</code></td>
<td>
<p>data matrix <code>d x n</code> with <code>d</code> dimensions in rows
and <code>n</code> observations in columns.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_+3A_hyperg0">hyperG0</code></td>
<td>
<p>parameters of the prior mixing distribution in a <code>list</code> with the following named components:
</p>

<ul>
<li><p><code>"b_xi"</code>:  a vector of length <code>d</code> with the mean location prior parameter. 
Can be set as the empirical mean of the data in an Empirical Bayes fashion.
</p>
</li>
<li><p><code>"b_psi"</code>: a vector of length <code>d</code> with the skewness location prior 
parameter. Can be set as 0 a priori.
</p>
</li>
<li><p><code>"kappa"</code>: a strictly positive number part of the inverse-Wishart 
component of the prior on the variance matrix. Can be set as very small (e.g. 
0.001) a priori.
</p>
</li>
<li><p><code>"D_xi"</code>: hyperprior controlling the information in <code class="reqn">\xi</code> (the larger
the less information is carried). 100 is a reasonable value, based on 
Fruhwirth-Schnatter et al., Biostatistics, 2010.
</p>
</li>
<li><p><code>"D_psi"</code>: hyperprior controlling the information in <code class="reqn">\psi</code> (the larger
the less information is carried). 100 is a reasonable value, based on 
Fruhwirth-Schnatter et al., Biostatistics, 2010
</p>
</li>
<li><p><code>"nu"</code>: a prior number on the degrees of freedom of the <code class="reqn">t</code> component that must be
strictly greater than <code>d</code>. Can be set as <code>d + 1</code> for instance.
</p>
</li>
<li><p><code>"lambda"</code>: a <code>d x d</code> symmetric definitive positive matrix 
part of the inverse-Wishart component of the prior on the variance matrix. 
Can be set as the diagonal of empirical variance of the data in an Empircal 
Bayes fashion divided by a factor 3 according to Fruhwirth-Schnatter et al., 
Biostatistics, 2010.
</p>
</li></ul>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_+3A_a">a</code></td>
<td>
<p>shape hyperparameter of the Gamma prior
on the concentration parameter of the Dirichlet Process. Default is <code>0.0001</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_+3A_b">b</code></td>
<td>
<p>scale hyperparameter of the Gamma prior
on the concentration parameter of the Dirichlet Process. Default is <code>0.0001</code>. If <code>0</code>, 
then the concentration is fixed set to <code>a</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_+3A_n">N</code></td>
<td>
<p>number of MCMC iterations.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_+3A_doplot">doPlot</code></td>
<td>
<p>logical flag indicating whether to plot MCMC iteration or not.
Default to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_+3A_nbclust_init">nbclust_init</code></td>
<td>
<p>number of clusters at initialization.
Default to 30 (or less if there are less than 30 observations).</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_+3A_plotevery">plotevery</code></td>
<td>
<p>an integer indicating the interval between plotted iterations when <code>doPlot</code>
is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_+3A_diagvar">diagVar</code></td>
<td>
<p>logical flag indicating whether the variance of each cluster is
estimated as a diagonal matrix, or as a full matrix.
Default is <code>TRUE</code> (diagonal variance).</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_+3A_use_variance_hyperprior">use_variance_hyperprior</code></td>
<td>
<p>logical flag indicating whether a hyperprior is added 
for the variance parameter. Default is <code>TRUE</code> which decrease the impact of the variance prior
on the posterior. <code>FALSE</code> is useful for using an informative prior.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_+3A_verbose">verbose</code></td>
<td>
<p>logical flag indicating whether partition info is
written in the console at each MCMC iteration.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code><a href="#topic+plot_DPMst">plot_DPMst</a></code>.
Only used if <code>doPlot</code> is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a object of class <code>DPMclust</code> with the following attributes:
</p>
<table>
<tr><td><code>mcmc_partitions:</code></td>
<td>
<p> a list of length <code>N</code>. Each
element <code>mcmc_partitions[n]</code> is a vector of length
<code>n</code> giving the partition of the <code>n</code> observations.</p>
</td></tr>
<tr><td><code>alpha:</code></td>
<td>
<p>a vector of length <code>N</code>. <code>cost[j]</code> is the cost
associated to partition <code>c[[j]]</code></p>
</td></tr>
<tr><td><code>U_SS_list:</code></td>
<td>
<p>a list of length <code>N</code> containing the lists of
sufficient statistics for all the mixture components at each MCMC iteration</p>
</td></tr>
<tr><td><code>weights_list:</code></td>
<td>
<p>a list of length <code>N</code> containing the weights of each
mixture component for each MCMC iterations</p>
</td></tr>
<tr><td><code>logposterior_list:</code></td>
<td>
<p>a list of length <code>N</code> containing the logposterior values
at each MCMC iterations</p>
</td></tr>
<tr><td><code>data:</code></td>
<td>
<p>the data matrix <code>d x n</code> with <code>d</code> dimensions in rows
and <code>n</code> observations in columns</p>
</td></tr>
<tr><td><code>nb_mcmcit:</code></td>
<td>
<p>the number of MCMC iterations</p>
</td></tr>
<tr><td><code>clust_distrib:</code></td>
<td>
<p>the parametric distribution of the mixture component - <code>"skewt"</code></p>
</td></tr>
<tr><td><code>hyperG0:</code></td>
<td>
<p>the prior on the cluster location</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boris Hejblum
</p>


<h3>References</h3>

<p>Hejblum BP, Alkhassim C, Gottardo R, Caron F and Thiebaut R (2019) 
Sequential Dirichlet Process Mixtures of Multivariate Skew t-distributions for 
Model-based Clustering of Flow Cytometry Data. The Annals of Applied Statistics, 
13(1): 638-660. &lt;doi: 10.1214/18-AOAS1209&gt; &lt;arXiv: 1702.04407&gt; 
<a href="https://arxiv.org/abs/1702.04407">https://arxiv.org/abs/1702.04407</a> <a href="https://doi.org/10.1214/18-AOAS1209">doi:10.1214/18-AOAS1209</a>
</p>
<p>Fruhwirth-Schnatter S, Pyne S, Bayesian inference for finite mixtures 
of univariate and multivariate skew-normal and skew-t distributions, Biostatistics,
2010.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rm(list=ls())

#Number of data
n &lt;- 2000
set.seed(4321)


d &lt;- 2
ncl &lt;- 4

# Sample data
library(truncnorm)

sdev &lt;- array(dim=c(d,d,ncl))

#xi &lt;- matrix(nrow=d, ncol=ncl, c(-1.5, 1.5, 1.5, 1.5, 2, -2.5, -2.5, -3))
#xi &lt;- matrix(nrow=d, ncol=ncl, c(-0.5, 0, 0.5, 0, 0.5, -1, -1, 1))
xi &lt;- matrix(nrow=d, ncol=ncl, c(-0.2, 0.5, 2.4, 0.4, 0.6, -1.3, -0.9, -2.7))
psi &lt;- matrix(nrow=d, ncol=4, c(0.3, -0.7, -0.8, 0, 0.3, -0.7, 0.2, 0.9))
nu &lt;- c(100,25,8,5)
p &lt;- c(0.15, 0.05, 0.5, 0.3) # frequence des clusters
sdev[, ,1] &lt;- matrix(nrow=d, ncol=d, c(0.3, 0, 0, 0.3))
sdev[, ,2] &lt;- matrix(nrow=d, ncol=d, c(0.1, 0, 0, 0.3))
sdev[, ,3] &lt;- matrix(nrow=d, ncol=d, c(0.3, 0.15, 0.15, 0.3))
sdev[, ,4] &lt;- .3*diag(2)


c &lt;- rep(0,n)
w &lt;- rep(1,n)
z &lt;- matrix(0, nrow=d, ncol=n)
for(k in 1:n){
 c[k] = which(rmultinom(n=1, size=1, prob=p)!=0)
 w[k] &lt;- rgamma(1, shape=nu[c[k]]/2, rate=nu[c[k]]/2)
 z[,k] &lt;- xi[, c[k]] + psi[, c[k]]*rtruncnorm(n=1, a=0, b=Inf, mean=0, sd=1/sqrt(w[k])) +
                (sdev[, , c[k]]/sqrt(w[k]))%*%matrix(rnorm(d, mean = 0, sd = 1), nrow=d, ncol=1)
 #cat(k, "/", n, " observations simulated\n", sep="")
}

# Set parameters of G0
hyperG0 &lt;- list()
hyperG0[["b_xi"]] &lt;- rowMeans(z)
hyperG0[["b_psi"]] &lt;- rep(0,d)
hyperG0[["kappa"]] &lt;- 0.001
hyperG0[["D_xi"]] &lt;- 100
hyperG0[["D_psi"]] &lt;- 100
hyperG0[["nu"]] &lt;- d+1
hyperG0[["lambda"]] &lt;- diag(apply(z,MARGIN=1, FUN=var))/3

 # hyperprior on the Scale parameter of DPM
 a &lt;- 0.0001
 b &lt;- 0.0001



 ## Data
 ########
 library(ggplot2)
 p &lt;- (ggplot(data.frame("X"=z[1,], "Y"=z[2,]), aes(x=X, y=Y))
       + geom_point()
       #+ ggtitle("Simple example in 2d data")
       +xlab("D1")
       +ylab("D2")
       +theme_bw())
 p #pdf(height=8.5, width=8.5)

 c2plot &lt;- factor(c)
 levels(c2plot) &lt;- c("4", "1", "3", "2")
 pp &lt;- (ggplot(data.frame("X"=z[1,], "Y"=z[2,], "Cluster"=as.character(c2plot)))
       + geom_point(aes(x=X, y=Y, colour=Cluster, fill=Cluster))
       #+ ggtitle("Slightly overlapping skew-normal simulation\n")
       + xlab("D1")
       + ylab("D2")
       + theme_bw()
       + scale_colour_discrete(guide=guide_legend(override.aes = list(size = 6, shape=22))))
 pp #pdf(height=7, width=7.5)


 ## alpha priors plots
 #####################
 prioralpha &lt;- data.frame("alpha"=rgamma(n=5000, shape=a, scale=1/b),
                         "distribution" =factor(rep("prior",5000),
                         levels=c("prior", "posterior")))
 p &lt;- (ggplot(prioralpha, aes(x=alpha))
       + geom_histogram(aes(y=..density..),
                        colour="black", fill="white")
       + geom_density(alpha=.2, fill="red")
       + ggtitle(paste("Prior distribution on alpha: Gamma(", a,
                 ",", b, ")\n", sep=""))
      )
 p



if(interactive()){
 # Gibbs sampler for Dirichlet Process Mixtures
 ##############################################
 MCMCsample_st &lt;- DPMGibbsSkewT(z, hyperG0, a, b, N=1500,
                                doPlot=TRUE, nbclust_init=30, plotevery=100,
                               diagVar=FALSE)
 s &lt;- summary(MCMCsample_st, burnin = 1000, thin=10, lossFn = "Binder")
 print(s)
 plot(s, hm=TRUE) #pdf(height=8.5, width=10.5) #png(height=700, width=720)
 plot_ConvDPM(MCMCsample_st, from=2)
 #cluster_est_binder(MCMCsample_st$mcmc_partitions[900:1000])
}

</code></pre>

<hr>
<h2 id='DPMGibbsSkewT_parallel'>Slice Sampling of Dirichlet Process Mixture of skew Student's t-distributions</h2><span id='topic+DPMGibbsSkewT_parallel'></span>

<h3>Description</h3>

<p>Slice Sampling of Dirichlet Process Mixture of skew Student's t-distributions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DPMGibbsSkewT_parallel(
  Ncpus,
  type_connec,
  z,
  hyperG0,
  a = 1e-04,
  b = 1e-04,
  N,
  doPlot = FALSE,
  nbclust_init = 30,
  plotevery = N/10,
  diagVar = TRUE,
  use_variance_hyperprior = TRUE,
  verbose = FALSE,
  monitorfile = "",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DPMGibbsSkewT_parallel_+3A_ncpus">Ncpus</code></td>
<td>
<p>the number of processors available</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_parallel_+3A_type_connec">type_connec</code></td>
<td>
<p>The type of connection between the processors. Supported
cluster types are <code>"PSOCK"</code>, <code>"FORK"</code>, <code>"SOCK"</code>, <code>"MPI"</code>, and
<code>"NWS"</code>. See also <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_parallel_+3A_z">z</code></td>
<td>
<p>data matrix <code>d x n</code> with <code>d</code> dimensions in rows
and <code>n</code> observations in columns.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_parallel_+3A_hyperg0">hyperG0</code></td>
<td>
<p>prior mixing distribution.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_parallel_+3A_a">a</code></td>
<td>
<p>shape hyperparameter of the Gamma prior
on the concentration parameter of the Dirichlet Process. Default is <code>0.0001</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_parallel_+3A_b">b</code></td>
<td>
<p>scale hyperparameter of the Gamma prior
on the concentration parameter of the Dirichlet Process. Default is <code>0.0001</code>. If <code>0</code>, 
then the concentration is fixed set to <code>a</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_parallel_+3A_n">N</code></td>
<td>
<p>number of MCMC iterations.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_parallel_+3A_doplot">doPlot</code></td>
<td>
<p>logical flag indicating whether to plot MCMC iteration or not.
Default to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_parallel_+3A_nbclust_init">nbclust_init</code></td>
<td>
<p>number of clusters at initialization.
Default to 30 (or less if there are less than 30 observations).</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_parallel_+3A_plotevery">plotevery</code></td>
<td>
<p>an integer indicating the interval between plotted iterations when <code>doPlot</code>
is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_parallel_+3A_diagvar">diagVar</code></td>
<td>
<p>logical flag indicating whether the variance of each cluster is
estimated as a diagonal matrix, or as a full matrix.
Default is <code>TRUE</code> (diagonal variance).</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_parallel_+3A_use_variance_hyperprior">use_variance_hyperprior</code></td>
<td>
<p>logical flag indicating whether a hyperprior is added 
for the variance parameter. Default is <code>TRUE</code> which decrease the impact of the variance prior
on the posterior. <code>FALSE</code> is useful for using an informative prior.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_parallel_+3A_verbose">verbose</code></td>
<td>
<p>logical flag indicating whether partition info is
written in the console at each MCMC iteration.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_parallel_+3A_monitorfile">monitorfile</code></td>
<td>
<p>a writable <a href="base.html#topic+connections">connections</a> or a character string naming a file to write into,
to monitor the progress of the analysis.
Default is <code>""</code> which is no monitoring. See Details.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_parallel_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code><a href="#topic+plot_DPMst">plot_DPMst</a></code>.
Only used if <code>doPlot</code> is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a object of class <code>DPMclust</code> with the following attributes:
</p>
<table>
<tr><td><code>mcmc_partitions:</code></td>
<td>
<p>a list of length <code>N</code>. Each
element <code>mcmc_partitions[n]</code> is a vector of length
<code>n</code> giving the partition of the <code>n</code> observations.</p>
</td></tr>
<tr><td><code>alpha:</code></td>
<td>
<p>a vector of length <code>N</code>. <code>cost[j]</code> is the cost
associated to partition <code>c[[j]]</code></p>
</td></tr>
<tr><td><code>U_SS_list:</code></td>
<td>
<p>a list of length <code>N</code> containing the lists of
sufficient statistics for all the mixture components at each MCMC iteration</p>
</td></tr>
<tr><td><code>weights_list:</code></td>
<td>
<p>a list of length <code>N</code> containing the weights of each
mixture component for each MCMC iterations</p>
</td></tr>
<tr><td><code>logposterior_list:</code></td>
<td>
<p>a list of length <code>N</code> containing the logposterior values
at each MCMC iterations</p>
</td></tr>
<tr><td><code>data:</code></td>
<td>
<p>the data matrix <code>d x n</code> with <code>d</code> dimensions in rows
and <code>n</code> observations in columns</p>
</td></tr>
<tr><td><code>nb_mcmcit:</code></td>
<td>
<p>the number of MCMC iterations</p>
</td></tr>
<tr><td><code>clust_distrib:</code></td>
<td>
<p>the parametric distribution of the mixture component - <code>"skewt"</code></p>
</td></tr>
<tr><td><code>hyperG0:</code></td>
<td>
<p>the prior on the cluster location</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boris Hejblum
</p>


<h3>References</h3>

<p>Hejblum BP, Alkhassim C, Gottardo R, Caron F and Thiebaut R (2019) 
Sequential Dirichlet Process Mixtures of Multivariate Skew t-distributions for 
Model-based Clustering of Flow Cytometry Data. The Annals of Applied Statistics, 
13(1): 638-660. &lt;doi: 10.1214/18-AOAS1209&gt; &lt;arXiv: 1702.04407&gt; 
<a href="https://arxiv.org/abs/1702.04407">https://arxiv.org/abs/1702.04407</a> <a href="https://doi.org/10.1214/18-AOAS1209">doi:10.1214/18-AOAS1209</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rm(list=ls())

#Number of data
n &lt;- 2000
set.seed(123)
#set.seed(4321)


d &lt;- 2
ncl &lt;- 4

# Sample data

sdev &lt;- array(dim=c(d,d,ncl))

xi &lt;- matrix(nrow=d, ncol=ncl, c(-1.5, 1, 1.5, 1, 1.5, -2, -2, -2))
psi &lt;- matrix(nrow=d, ncol=4, c(0.4, -0.6, 0.8, 0, 0.3, -0.7, -0.3, -0.8))
p &lt;- c(0.2, 0.1, 0.4, 0.3) # frequence des clusters
sdev[, ,1] &lt;- matrix(nrow=d, ncol=d, c(0.3, 0, 0, 0.3))
sdev[, ,2] &lt;- matrix(nrow=d, ncol=d, c(0.1, 0, 0, 0.3))
sdev[, ,3] &lt;- matrix(nrow=d, ncol=d, c(0.3, 0.15, 0.15, 0.3))
sdev[, ,4] &lt;- .3*diag(2)


c &lt;- rep(0,n)
z &lt;- matrix(0, nrow=d, ncol=n)
for(k in 1:n){
 c[k] = which(rmultinom(n=1, size=1, prob=p)!=0)
 z[,k] &lt;- (xi[, c[k]]
          + psi[, c[k]]*abs(rnorm(1))
          + sdev[, , c[k]]%*%matrix(rnorm(d, mean = 0, sd = 1), nrow=d, ncol=1))
 #cat(k, "/", n, " observations simulated\n", sep="")
}

# Set parameters of G0
hyperG0 &lt;- list()
hyperG0[["b_xi"]] &lt;- rep(0,d)
hyperG0[["b_psi"]] &lt;- rep(0,d)
hyperG0[["kappa"]] &lt;- 0.001
hyperG0[["D_xi"]] &lt;- 100
hyperG0[["D_psi"]] &lt;- 100
hyperG0[["nu"]] &lt;- d + 1
hyperG0[["lambda"]] &lt;- diag(d)

 # hyperprior on the Scale parameter of DPM
 a &lt;- 0.0001
 b &lt;- 0.0001

 # do some plots
 doPlot &lt;- TRUE
 nbclust_init &lt;- 30



 ## Data
 ########
library(ggplot2)
 p &lt;- (ggplot(data.frame("X"=z[1,], "Y"=z[2,]), aes(x=X, y=Y))
       + geom_point()
       + ggtitle("Simple example in 2d data")
       +xlab("D1")
       +ylab("D2")
       +theme_bw())
 p

 c2plot &lt;- factor(c)
 levels(c2plot) &lt;- c("3", "2", "4", "1")
 pp &lt;- (ggplot(data.frame("X"=z[1,], "Y"=z[2,], "Cluster"=as.character(c2plot)))
       + geom_point(aes(x=X, y=Y, colour=Cluster, fill=Cluster))
       + ggtitle("Slightly overlapping skew-normal simulation\n")
       + xlab("D1")
       + ylab("D2")
       + theme_bw()
       + scale_colour_discrete(guide=guide_legend(override.aes = list(size = 6, shape=22))))
 pp


 ## alpha priors plots
 #####################
 prioralpha &lt;- data.frame("alpha"=rgamma(n=5000, shape=a, scale=1/b),
                         "distribution" =factor(rep("prior",5000),
                         levels=c("prior", "posterior")))
 p &lt;- (ggplot(prioralpha, aes(x=alpha))
       + geom_histogram(aes(y=..density..),
                        colour="black", fill="white")
       + geom_density(alpha=.2, fill="red")
       + ggtitle(paste("Prior distribution on alpha: Gamma(", a,
                 ",", b, ")\n", sep=""))
      )
 p


if(interactive()){
 # Gibbs sampler for Dirichlet Process Mixtures
 ##############################################
 MCMCsample_st &lt;- DPMGibbsSkewT(z, hyperG0, a, b, N=2000,
                                doPlot, nbclust_init, plotevery=100, gg.add=list(theme_bw(),
                                 guides(shape=guide_legend(override.aes = list(fill="grey45")))),
                                diagVar=FALSE)
 s &lt;- summary(MCMCsample_st, burnin = 350)
 print(s)
 plot(s)
 plot_ConvDPM(MCMCsample_st, from=2)
 cluster_est_binder(MCMCsample_st$mcmc_partitions[1500:2000])
}



</code></pre>

<hr>
<h2 id='DPMGibbsSkewT_SeqPrior'>Slice Sampling of Dirichlet Process Mixture of skew Student's t-distributions</h2><span id='topic+DPMGibbsSkewT_SeqPrior'></span>

<h3>Description</h3>

<p>Slice Sampling of Dirichlet Process Mixture of skew Student's t-distributions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DPMGibbsSkewT_SeqPrior(
  z,
  prior_inform,
  hyperG0,
  N,
  nbclust_init,
  add.vagueprior = TRUE,
  weightnoninfo = NULL,
  doPlot = TRUE,
  plotevery = N/10,
  diagVar = TRUE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_+3A_z">z</code></td>
<td>
<p>data matrix <code>d x n</code> with <code>d</code> dimensions in rows
and <code>n</code> observations in columns.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_+3A_prior_inform">prior_inform</code></td>
<td>
<p>an informative prior such as the approximation computed by <code>summary.DPMMclust</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_+3A_hyperg0">hyperG0</code></td>
<td>
<p>prior mixing distribution.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_+3A_n">N</code></td>
<td>
<p>number of MCMC iterations.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_+3A_nbclust_init">nbclust_init</code></td>
<td>
<p>number of clusters at initialization.
Default to 30 (or less if there are less than 30 observations).</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_+3A_add.vagueprior">add.vagueprior</code></td>
<td>
<p>logical flag indicating whether a non informative component should
be added to the informative prior. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_+3A_weightnoninfo">weightnoninfo</code></td>
<td>
<p>a real between 0 and 1 giving the weights of the non informative component
in the prior.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_+3A_doplot">doPlot</code></td>
<td>
<p>logical flag indicating whether to plot MCMC iteration or not.
Default to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_+3A_plotevery">plotevery</code></td>
<td>
<p>an integer indicating the interval between plotted iterations when <code>doPlot</code>
is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_+3A_diagvar">diagVar</code></td>
<td>
<p>logical flag indicating whether the variance of each cluster is
estimated as a diagonal matrix, or as a full matrix.
Default is <code>TRUE</code> (diagonal variance).</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_+3A_verbose">verbose</code></td>
<td>
<p>logical flag indicating whether partition info is
written in the console at each MCMC iteration.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code><a href="#topic+plot_DPM">plot_DPM</a></code>.
Only used if <code>doPlot</code> is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a object of class <code>DPMclust</code> with the following attributes:
</p>
<table>
<tr><td><code>mcmc_partitions:</code></td>
<td>
<p>a list of length <code>N</code>. Each
element <code>mcmc_partitions[n]</code> is a vector of length
<code>n</code> giving the partition of the <code>n</code> observations.</p>
</td></tr>
<tr><td><code>alpha:</code></td>
<td>
<p> a vector of length <code>N</code>. <code>cost[j]</code> is the cost
associated to partition <code>c[[j]]</code></p>
</td></tr>
<tr><td><code>U_SS_list:</code></td>
<td>
<p>a list of length <code>N</code> containing the lists of
sufficient statistics for all the mixture components at each MCMC iteration</p>
</td></tr>
<tr><td><code>weights_list:</code></td>
<td>
<p>a list of length <code>N</code> containing the weights of each
mixture component for each MCMC iterations</p>
</td></tr>
<tr><td><code>logposterior_list:</code></td>
<td>
<p>a list of length <code>N</code> containing the logposterior values
at each MCMC iterations</p>
</td></tr>
<tr><td><code>data:</code></td>
<td>
<p>the data matrix <code>d x n</code> with <code>d</code> dimensions in rows
and <code>n</code> observations in columns</p>
</td></tr>
<tr><td><code>nb_mcmcit:</code></td>
<td>
<p>the number of MCMC iterations</p>
</td></tr>
<tr><td><code>clust_distrib:</code></td>
<td>
<p>the parametric distribution of the mixture component - <code>"skewt"</code></p>
</td></tr>
<tr><td><code>hyperG0:</code></td>
<td>
<p>the prior on the cluster location</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boris Hejblum
</p>


<h3>References</h3>

<p>Hejblum BP, Alkhassim C, Gottardo R, Caron F and Thiebaut R (2019) 
Sequential Dirichlet Process Mixtures of Multivariate Skew t-distributions for 
Model-based Clustering of Flow Cytometry Data. The Annals of Applied Statistics, 
13(1): 638-660. &lt;doi: 10.1214/18-AOAS1209&gt; &lt;arXiv: 1702.04407&gt; 
<a href="https://arxiv.org/abs/1702.04407">https://arxiv.org/abs/1702.04407</a> <a href="https://doi.org/10.1214/18-AOAS1209">doi:10.1214/18-AOAS1209</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rm(list=ls())

#Number of data
n &lt;- 2000
set.seed(123)


d &lt;- 2
ncl &lt;- 4

# Sample data

sdev &lt;- array(dim=c(d,d,ncl))

xi &lt;- matrix(nrow=d, ncol=ncl, c(-1.5, 1, 1.5, 1, 1.5, -2, -2, -2))
psi &lt;- matrix(nrow=d, ncol=4, c(0.4, -0.6, 0.8, 0, 0.3, -0.7, -0.3, -0.8))
nu &lt;- c(100,15,8,5)
p &lt;- c(0.15, 0.05, 0.5, 0.3) # frequence des clusters
sdev[, ,1] &lt;- matrix(nrow=d, ncol=d, c(0.3, 0, 0, 0.3))
sdev[, ,2] &lt;- matrix(nrow=d, ncol=d, c(0.1, 0, 0, 0.3))
sdev[, ,3] &lt;- matrix(nrow=d, ncol=d, c(0.3, 0.15, 0.15, 0.3))
sdev[, ,4] &lt;- .3*diag(2)


c &lt;- rep(0,n)
w &lt;- rep(1,n)
z &lt;- matrix(0, nrow=d, ncol=n)
for(k in 1:n){
 c[k] = which(rmultinom(n=1, size=1, prob=p)!=0)
 w[k] &lt;- rgamma(1, shape=nu[c[k]]/2, rate=nu[c[k]]/2)
 z[,k] &lt;- xi[, c[k]] + psi[, c[k]]*rtruncnorm(n=1, a=0, b=Inf, mean=0, sd=1/sqrt(w[k])) +
                (sdev[, , c[k]]/sqrt(w[k]))%*%matrix(rnorm(d, mean = 0, sd = 1), nrow=d, ncol=1)
 #cat(k, "/", n, " observations simulated\n", sep="")
}

# Set parameters of G0
hyperG0 &lt;- list()
hyperG0[["b_xi"]] &lt;- rowMeans(z)
hyperG0[["b_psi"]] &lt;- rep(0,d)
hyperG0[["kappa"]] &lt;- 0.001
hyperG0[["D_xi"]] &lt;- 100
hyperG0[["D_psi"]] &lt;- 100
hyperG0[["nu"]] &lt;- d+1
hyperG0[["lambda"]] &lt;- diag(apply(z,MARGIN=1, FUN=var))/3

 # hyperprior on the Scale parameter of DPM
 a &lt;- 0.0001
 b &lt;- 0.0001

 # do some plots
 nbclust_init &lt;- 30

 ## Plot Data
 library(ggplot2)
 q &lt;- (ggplot(data.frame("X"=z[1,], "Y"=z[2,]), aes(x=X, y=Y))
       + geom_point()
       + ggtitle("Simple example in 2d data")
       +xlab("D1")
       +ylab("D2")
       +theme_bw())
 q

if(interactive()){
 MCMCsample_st &lt;- DPMGibbsSkewT(z, hyperG0, a, b, N=2000,
                                doPlot=TRUE, plotevery=250,
                                nbclust_init, diagVar=FALSE,
                                gg.add=list(theme_bw(),
                                 guides(shape=guide_legend(override.aes = list(fill="grey45")))))
 s &lt;- summary(MCMCsample_st, burnin = 1500, thin=2, posterior_approx=TRUE)
 F &lt;- FmeasureC(pred=s$point_estim$c_est, ref=c)

for(k in 1:n){
 c[k] = which(rmultinom(n=1, size=1, prob=p)!=0)
 w[k] &lt;- rgamma(1, shape=nu[c[k]]/2, rate=nu[c[k]]/2)
 z[,k] &lt;- xi[, c[k]] + psi[, c[k]]*rtruncnorm(n=1, a=0, b=Inf, mean=0, sd=1/sqrt(w[k])) +
                (sdev[, , c[k]]/sqrt(w[k]))%*%matrix(rnorm(d, mean = 0, sd = 1), nrow=d, ncol=1)
 cat(k, "/", n, " observations simulated\n", sep="")
}
 MCMCsample_st2 &lt;- DPMGibbsSkewT_SeqPrior(z, prior=s$param_posterior,
                                          hyperG0, N=2000,
                                          doPlot=TRUE, plotevery=100,
                                          nbclust_init, diagVar=FALSE,
                                          gg.add=list(theme_bw(),
                                 guides(shape=guide_legend(override.aes = list(fill="grey45")))))
s2 &lt;- summary(MCMCsample_st2, burnin = 1500, thin=5)
F2 &lt;- FmeasureC(pred=s2$point_estim$c_est, ref=c)

# MCMCsample_st2_par &lt;- DPMGibbsSkewT_SeqPrior_parallel(Ncpus= 2, type_connec="SOCK",
#                                                       z, prior_inform=s$param_posterior,
#                                                       hyperG0, N=2000,
#                                                       doPlot=TRUE, plotevery=50,
#                                                       nbclust_init, diagVar=FALSE,
#                                                       gg.add=list(theme_bw(),
#                                  guides(shape=guide_legend(override.aes = list(fill="grey45"))))
}


</code></pre>

<hr>
<h2 id='DPMGibbsSkewT_SeqPrior_parallel'>Slice Sampling of Dirichlet Process Mixture of skew Student's t-distributions</h2><span id='topic+DPMGibbsSkewT_SeqPrior_parallel'></span>

<h3>Description</h3>

<p>Slice Sampling of Dirichlet Process Mixture of skew Student's t-distributions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DPMGibbsSkewT_SeqPrior_parallel(
  Ncpus,
  type_connec,
  z,
  prior_inform,
  hyperG0,
  N,
  nbclust_init,
  add.vagueprior = TRUE,
  weightnoninfo = NULL,
  doPlot = FALSE,
  plotevery = N/10,
  diagVar = TRUE,
  verbose = TRUE,
  monitorfile = "",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_parallel_+3A_ncpus">Ncpus</code></td>
<td>
<p>the number of processors available</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_parallel_+3A_type_connec">type_connec</code></td>
<td>
<p>The type of connection between the processors. Supported
cluster types are <code>"SOCK"</code>, <code>"FORK"</code>, <code>"MPI"</code>, and
<code>"NWS"</code>. See also <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_parallel_+3A_z">z</code></td>
<td>
<p>data matrix <code>d x n</code> with <code>d</code> dimensions in rows
and <code>n</code> observations in columns.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_parallel_+3A_prior_inform">prior_inform</code></td>
<td>
<p>an informative prior such as the approximation computed by <code>summary.DPMMclust</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_parallel_+3A_hyperg0">hyperG0</code></td>
<td>
<p>prior mixing distribution.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_parallel_+3A_n">N</code></td>
<td>
<p>number of MCMC iterations.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_parallel_+3A_nbclust_init">nbclust_init</code></td>
<td>
<p>number of clusters at initialization.
Default to 30 (or less if there are less than 30 observations).</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_parallel_+3A_add.vagueprior">add.vagueprior</code></td>
<td>
<p>logical flag indicating whether a non informative component should
be added to the informative prior. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_parallel_+3A_weightnoninfo">weightnoninfo</code></td>
<td>
<p>a real between 0 and 1 giving the weights of the non informative component
in the prior.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_parallel_+3A_doplot">doPlot</code></td>
<td>
<p>logical flag indicating whether to plot MCMC iteration or not.
Default to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_parallel_+3A_plotevery">plotevery</code></td>
<td>
<p>an integer indicating the interval between plotted iterations when <code>doPlot</code>
is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_parallel_+3A_diagvar">diagVar</code></td>
<td>
<p>logical flag indicating whether the variance of each cluster is
estimated as a diagonal matrix, or as a full matrix.
Default is <code>TRUE</code> (diagonal variance).</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_parallel_+3A_verbose">verbose</code></td>
<td>
<p>logical flag indicating whether partition info is
written in the console at each MCMC iteration.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_parallel_+3A_monitorfile">monitorfile</code></td>
<td>
<p>a writable <a href="base.html#topic+connections">connections</a> or a character string naming a file to write into,
to monitor the progress of the analysis.
Default is <code>""</code> which is no monitoring. See Details.</p>
</td></tr>
<tr><td><code id="DPMGibbsSkewT_SeqPrior_parallel_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code><a href="#topic+plot_DPM">plot_DPM</a></code>.
Only used if <code>doPlot</code> is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a object of class <code>DPMclust</code> with the following attributes:
</p>
<table>
<tr><td><code>mcmc_partitions:</code></td>
<td>
<p>a list of length <code>N</code>. Each
element <code>mcmc_partitions[n]</code> is a vector of length
<code>n</code> giving the partition of the <code>n</code> observations.</p>
</td></tr>
<tr><td><code>alpha:</code></td>
<td>
<p> a vector of length <code>N</code>. <code>cost[j]</code> is the cost
associated to partition <code>c[[j]]</code></p>
</td></tr>
<tr><td><code>U_SS_list:</code></td>
<td>
<p>a list of length <code>N</code> containing the lists of
sufficient statistics for all the mixture components at each MCMC iteration</p>
</td></tr>
<tr><td><code>weights_list:</code></td>
<td>
<p>a list of length <code>N</code> containing the logposterior values
at each MCMC iterations</p>
</td></tr>
<tr><td><code>logposterior_list:</code></td>
<td>
<p>a list of length <code>N</code> containing the logposterior values
at each MCMC iterations</p>
</td></tr>
<tr><td><code>data:</code></td>
<td>
<p>the data matrix <code>d x n</code> with <code>d</code> dimensions in rows
and <code>n</code> observations in columns</p>
</td></tr>
<tr><td><code>nb_mcmcit:</code></td>
<td>
<p>the number of MCMC iterations</p>
</td></tr>
<tr><td><code>clust_distrib:</code></td>
<td>
<p>the parametric distribution of the mixture component - <code>"skewt"</code></p>
</td></tr>
<tr><td><code>hyperG0:</code></td>
<td>
<p>the prior on the cluster location</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boris Hejblum
</p>


<h3>References</h3>

<p>Hejblum BP, Alkhassim C, Gottardo R, Caron F and Thiebaut R (2019) 
Sequential Dirichlet Process Mixtures of Multivariate Skew t-distributions for 
Model-based Clustering of Flow Cytometry Data. The Annals of Applied Statistics, 
13(1): 638-660. &lt;doi: 10.1214/18-AOAS1209&gt; &lt;arXiv: 1702.04407&gt; 
<a href="https://arxiv.org/abs/1702.04407">https://arxiv.org/abs/1702.04407</a> <a href="https://doi.org/10.1214/18-AOAS1209">doi:10.1214/18-AOAS1209</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rm(list=ls())

#Number of data
n &lt;- 2000
set.seed(123)


d &lt;- 2
ncl &lt;- 4

# Sample data

sdev &lt;- array(dim=c(d,d,ncl))

#xi &lt;- matrix(nrow=d, ncol=ncl, c(-1.5, 1.5, 1.5, 1.5, 2, -2.5, -2.5, -3))
#psi &lt;- matrix(nrow=d, ncol=4, c(0.4, -0.6, 0.8, 0, 0.3, -0.7, -0.3, -0.8))
xi &lt;- matrix(nrow=d, ncol=ncl, c(-0.2, 0.5, 2.4, 0.4, 0.6, -1.3, -0.9, -2.7))
psi &lt;- matrix(nrow=d, ncol=4, c(0.3, -0.7, -0.8, 0, 0.3, -0.7, 0.2, 0.9))
nu &lt;- c(100,15,8,5)
p &lt;- c(0.15, 0.05, 0.5, 0.3) # frequence des clusters
sdev[, ,1] &lt;- matrix(nrow=d, ncol=d, c(0.3, 0, 0, 0.3))
sdev[, ,2] &lt;- matrix(nrow=d, ncol=d, c(0.1, 0, 0, 0.3))
sdev[, ,3] &lt;- matrix(nrow=d, ncol=d, c(0.3, 0.15, 0.15, 0.3))
sdev[, ,4] &lt;- .3*diag(2)


c &lt;- rep(0,n)
w &lt;- rep(1,n)
z &lt;- matrix(0, nrow=d, ncol=n)
for(k in 1:n){
 c[k] = which(rmultinom(n=1, size=1, prob=p)!=0)
 w[k] &lt;- rgamma(1, shape=nu[c[k]]/2, rate=nu[c[k]]/2)
 z[,k] &lt;- xi[, c[k]] + psi[, c[k]]*rtruncnorm(n=1, a=0, b=Inf, mean=0, sd=1/sqrt(w[k])) +
                (sdev[, , c[k]]/sqrt(w[k]))%*%matrix(rnorm(d, mean = 0, sd = 1), nrow=d, ncol=1)
 #cat(k, "/", n, " observations simulated\n", sep="")
}

# Set parameters of G0
hyperG0 &lt;- list()
hyperG0[["b_xi"]] &lt;- rowMeans(z)
hyperG0[["b_psi"]] &lt;- rep(0,d)
hyperG0[["kappa"]] &lt;- 0.001
hyperG0[["D_xi"]] &lt;- 100
hyperG0[["D_psi"]] &lt;- 100
hyperG0[["nu"]] &lt;- d+1
hyperG0[["lambda"]] &lt;- diag(apply(z,MARGIN=1, FUN=var))/3

 # hyperprior on the Scale parameter of DPM
 a &lt;- 0.0001
 b &lt;- 0.0001

 # do some plots
 nbclust_init &lt;- 30

 ## Plot Data
 library(ggplot2)
 q &lt;- (ggplot(data.frame("X"=z[1,], "Y"=z[2,]), aes(x=X, y=Y))
       + geom_point()
       + ggtitle("Simple example in 2d data")
       +xlab("D1")
       +ylab("D2")
       +theme_bw())
 q

if(interactive()){
 MCMCsample_st &lt;- DPMGibbsSkewT(z, hyperG0, a, b, N=2000,
                                doPlot=TRUE, plotevery=250,
                                nbclust_init,
                                gg.add=list(theme_bw(),
                                 guides(shape=guide_legend(override.aes = list(fill="grey45")))),
                                diagVar=FALSE)
 s &lt;- summary(MCMCsample_st, burnin = 1500, thin=5, posterior_approx=TRUE)
 F &lt;- FmeasureC(pred=s$point_estim$c_est, ref=c)

for(k in 1:n){
 c[k] = which(rmultinom(n=1, size=1, prob=p)!=0)
 w[k] &lt;- rgamma(1, shape=nu[c[k]]/2, rate=nu[c[k]]/2)
 z[,k] &lt;- xi[, c[k]] + psi[, c[k]]*rtruncnorm(n=1, a=0, b=Inf, mean=0, sd=1/sqrt(w[k])) +
                (sdev[, , c[k]]/sqrt(w[k]))%*%matrix(rnorm(d, mean = 0, sd = 1), nrow=d, ncol=1)
 #cat(k, "/", n, " observations simulated\n", sep="")
}
MCMCsample_st2 &lt;- DPMGibbsSkewT_SeqPrior_parallel(Ncpus=2, type_connec="SOCK",
                                                  z, prior_inform=s$param_posterior,
                                                  hyperG0, N=3000,
                                                  doPlot=TRUE, plotevery=100,
                                                  nbclust_init, diagVar=FALSE, verbose=FALSE,
                                                  gg.add=list(theme_bw(),
                                 guides(shape=guide_legend(override.aes = list(fill="grey45")))))
s2 &lt;- summary(MCMCsample_st2, burnin = 2000, thin=5)
F2 &lt;- FmeasureC(pred=s2$point_estim$c_est, ref=c)
}


</code></pre>

<hr>
<h2 id='DPMpost'>Posterior estimation for Dirichlet process mixture of multivariate (potentially skew) distributions models</h2><span id='topic+DPMpost'></span>

<h3>Description</h3>

<p>Partially collapse slice Gibbs sampling for Dirichlet process mixture of multivariate
normal, skew normal or skew t distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DPMpost(
  data,
  hyperG0,
  a = 1e-04,
  b = 1e-04,
  N,
  doPlot = TRUE,
  nbclust_init = 30,
  plotevery = floor(N/10),
  diagVar = TRUE,
  verbose = TRUE,
  distrib = c("gaussian", "skewnorm", "skewt"),
  ncores = 1,
  type_connec = "SOCK",
  informPrior = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DPMpost_+3A_data">data</code></td>
<td>
<p>data matrix <code>d x n</code> with <code>d</code> dimensions in rows
and <code>n</code> observations in columns.</p>
</td></tr>
<tr><td><code id="DPMpost_+3A_hyperg0">hyperG0</code></td>
<td>
<p>prior mixing distribution.</p>
</td></tr>
<tr><td><code id="DPMpost_+3A_a">a</code></td>
<td>
<p>shape hyperparameter of the Gamma prior
on the concentration parameter of the Dirichlet Process. Default is <code>0.0001</code>.</p>
</td></tr>
<tr><td><code id="DPMpost_+3A_b">b</code></td>
<td>
<p>scale hyperparameter of the Gamma prior
on the concentration parameter of the Dirichlet Process. Default is <code>0.0001</code>. If <code>0</code>, 
then the concentration is fixed set to <code>a</code>.</p>
</td></tr>
<tr><td><code id="DPMpost_+3A_n">N</code></td>
<td>
<p>number of MCMC iterations.</p>
</td></tr>
<tr><td><code id="DPMpost_+3A_doplot">doPlot</code></td>
<td>
<p>logical flag indicating whether to plot MCMC iteration or not.
Default to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="DPMpost_+3A_nbclust_init">nbclust_init</code></td>
<td>
<p>number of clusters at initialization.
Default to 30 (or less if there are less than 30 observations).</p>
</td></tr>
<tr><td><code id="DPMpost_+3A_plotevery">plotevery</code></td>
<td>
<p>an integer indicating the interval between plotted iterations when <code>doPlot</code>
is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="DPMpost_+3A_diagvar">diagVar</code></td>
<td>
<p>logical flag indicating whether the variance of each cluster is
estimated as a diagonal matrix, or as a full matrix.
Default is <code>TRUE</code> (diagonal variance).</p>
</td></tr>
<tr><td><code id="DPMpost_+3A_verbose">verbose</code></td>
<td>
<p>logical flag indicating whether partition info is
written in the console at each MCMC iteration.</p>
</td></tr>
<tr><td><code id="DPMpost_+3A_distrib">distrib</code></td>
<td>
<p>the distribution used for the clustering. Current possibilities are
<code>"gaussian"</code>, <code>"skewnorm"</code> and <code>"skewt"</code>.</p>
</td></tr>
<tr><td><code id="DPMpost_+3A_ncores">ncores</code></td>
<td>
<p>number of cores to use.</p>
</td></tr>
<tr><td><code id="DPMpost_+3A_type_connec">type_connec</code></td>
<td>
<p>The type of connection between the processors. Supported
cluster types are <code>"SOCK"</code>, <code>"FORK"</code>, <code>"MPI"</code>, and
<code>"NWS"</code>. See also <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>.</p>
</td></tr>
<tr><td><code id="DPMpost_+3A_informprior">informPrior</code></td>
<td>
<p>an optional informative prior such as the approximation computed
by <code>summary.DPMMclust</code>.</p>
</td></tr>
<tr><td><code id="DPMpost_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code><a href="#topic+plot_DPM">plot_DPM</a></code>.
Only used if <code>doPlot</code> is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a wrapper around the following functions: 
<code><a href="#topic+DPMGibbsN">DPMGibbsN</a></code>, <code><a href="#topic+DPMGibbsN_parallel">DPMGibbsN_parallel</a></code>,
<code><a href="#topic+DPMGibbsN_SeqPrior">DPMGibbsN_SeqPrior</a></code>, <code><a href="#topic+DPMGibbsSkewN">DPMGibbsSkewN</a></code>, <code><a href="#topic+DPMGibbsSkewN_parallel">DPMGibbsSkewN_parallel</a></code>,
<code><a href="#topic+DPMGibbsSkewT">DPMGibbsSkewT</a></code>, <code><a href="#topic+DPMGibbsSkewT_parallel">DPMGibbsSkewT_parallel</a></code>,
<code><a href="#topic+DPMGibbsSkewT_SeqPrior">DPMGibbsSkewT_SeqPrior</a></code>, <code><a href="#topic+DPMGibbsSkewT_SeqPrior_parallel">DPMGibbsSkewT_SeqPrior_parallel</a></code>.
</p>


<h3>Value</h3>

<p>a object of class <code>DPMclust</code> with the following attributes:
</p>
<table>
<tr><td><code>mcmc_partitions:</code></td>
<td>
<p> a list of length <code>N</code>. Each
element <code>mcmc_partitions[n]</code> is a vector of length
<code>n</code> giving the partition of the <code>n</code> observations.</p>
</td></tr>
<tr><td><code>alpha:</code></td>
<td>
<p> a vector of length <code>N</code>. <code>cost[j]</code> is the cost
associated to partition <code>c[[j]]</code></p>
</td></tr>
<tr><td><code>U_SS_list:</code></td>
<td>
<p> a list of length <code>N</code> containing the lists of
sufficient statistics for all the mixture components at each MCMC iteration</p>
</td></tr>
<tr><td><code>weights_list:</code></td>
<td>
<p> a list of length <code>N</code> containing the weights of each
mixture component for each MCMC iterations</p>
</td></tr>
<tr><td><code>logposterior_list:</code></td>
<td>
<p> a list of length <code>N</code> containing the logposterior values
at each MCMC iterations</p>
</td></tr>
<tr><td><code>data:</code></td>
<td>
<p> the data matrix <code>d x n</code> with <code>d</code> dimensions in rows
and <code>n</code> observations in columns</p>
</td></tr>
<tr><td><code>nb_mcmcit:</code></td>
<td>
<p> the number of MCMC iterations</p>
</td></tr>
<tr><td><code>clust_distrib:</code></td>
<td>
<p> the parametric distribution of the mixture component</p>
</td></tr>
<tr><td><code>hyperG0:</code></td>
<td>
<p> the prior on the cluster location</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boris Hejblum
</p>


<h3>References</h3>

<p>Hejblum BP, Alkhassim C, Gottardo R, Caron F and Thiebaut R (2019) 
Sequential Dirichlet Process Mixtures of Multivariate Skew t-distributions for 
Model-based Clustering of Flow Cytometry Data. The Annals of Applied Statistics, 
13(1): 638-660. &lt;doi: 10.1214/18-AOAS1209&gt; &lt;arXiv: 1702.04407&gt; 
<a href="https://arxiv.org/abs/1702.04407">https://arxiv.org/abs/1702.04407</a> <a href="https://doi.org/10.1214/18-AOAS1209">doi:10.1214/18-AOAS1209</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.DPMMclust">summary.DPMMclust</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#rm(list=ls())
set.seed(123)

# Exemple in 2 dimensions with skew-t distributions

# Generate data:
n &lt;- 2000 # number of data points
d &lt;- 2 # dimensions
ncl &lt;- 4 # number of true clusters
sdev &lt;- array(dim=c(d,d,ncl))
xi &lt;- matrix(nrow=d, ncol=ncl, c(-1.5, 1.5, 1.5, 1.5, 2, -2.5, -2.5, -3))
psi &lt;- matrix(nrow=d, ncol=4, c(0.3, -0.7, -0.8, 0, 0.3, -0.7, 0.2, 0.9))
nu &lt;- c(100,25,8,5)
proba &lt;- c(0.15, 0.05, 0.5, 0.3) # cluster frequencies
sdev[, ,1] &lt;- matrix(nrow=d, ncol=d, c(0.3, 0, 0, 0.3))
sdev[, ,2] &lt;- matrix(nrow=d, ncol=d, c(0.1, 0, 0, 0.3))
sdev[, ,3] &lt;- matrix(nrow=d, ncol=d, c(0.3, 0, 0, 0.2))
sdev[, ,4] &lt;- .3*diag(2)
c &lt;- rep(0,n)
w &lt;- rep(1,n)
z &lt;- matrix(0, nrow=d, ncol=n)
for(k in 1:n){
 c[k] = which(rmultinom(n=1, size=1, prob=proba)!=0)
 w[k] &lt;- rgamma(1, shape=nu[c[k]]/2, rate=nu[c[k]]/2)
 z[,k] &lt;- xi[, c[k]] + psi[, c[k]]*rtruncnorm(n=1, a=0, b=Inf, mean=0, sd=1/sqrt(w[k])) +
               (sdev[, , c[k]]/sqrt(w[k]))%*%matrix(rnorm(d, mean = 0, sd = 1), nrow=d, ncol=1)
}

# Define hyperprior
hyperG0 &lt;- list()
hyperG0[["b_xi"]] &lt;- rowMeans(z)
hyperG0[["b_psi"]] &lt;- rep(0,d)
hyperG0[["kappa"]] &lt;- 0.001
hyperG0[["D_xi"]] &lt;- 100
hyperG0[["D_psi"]] &lt;- 100
hyperG0[["nu"]] &lt;- d+1
hyperG0[["lambda"]] &lt;- diag(apply(z,MARGIN=1, FUN=var))/3


if(interactive()){
# Plot data
cytoScatter(z)

# Estimate posterior
MCMCsample_st &lt;- DPMpost(data=z, hyperG0=hyperG0, N=2000,
   distrib="skewt",
   gg.add=list(ggplot2::theme_bw(),
      ggplot2::guides(shape=ggplot2::guide_legend(override.aes = list(fill="grey45"))))
 )
 s &lt;- summary(MCMCsample_st, burnin = 1600, thin=5, lossFn = "Binder")
 s
 plot(s)
 #plot(s, hm=TRUE) # this can take a few sec...
 
 
 # more data plotting:
 library(ggplot2)
 p &lt;- (ggplot(data.frame("X"=z[1,], "Y"=z[2,]), aes(x=X, y=Y))
       + geom_point()
       + ggtitle("Unsupervised data")
       + xlab("D1")
       + ylab("D2")
       + theme_bw()
 )
 p

 c2plot &lt;- factor(c)
 levels(c2plot) &lt;- c("4", "1", "3", "2")
 pp &lt;- (ggplot(data.frame("X"=z[1,], "Y"=z[2,], "Cluster"=as.character(c2plot)))
       + geom_point(aes(x=X, y=Y, colour=Cluster, fill=Cluster))
       + ggtitle("True clusters")
       + xlab("D1")
       + ylab("D2")
       + theme_bw()
       + scale_colour_discrete(guide=guide_legend(override.aes = list(size = 6, shape=22)))
 )
 pp
}




# Exemple in 2 dimensions with Gaussian distributions

set.seed(1234)

# Generate data 
n &lt;- 2000 # number of data points
d &lt;- 2 # dimensions
ncl &lt;- 4 # number of true clusters
m &lt;- matrix(nrow=2, ncol=4, c(-1, 1, 1.5, 2, 2, -2, -1.5, -2)) # cluster means
sdev &lt;- array(dim=c(2, 2, 4)) # cluster standard-deviations
sdev[, ,1] &lt;- matrix(nrow=2, ncol=2, c(0.3, 0, 0, 0.3))
sdev[, ,2] &lt;- matrix(nrow=2, ncol=2, c(0.1, 0, 0, 0.3))
sdev[, ,3] &lt;- matrix(nrow=2, ncol=2, c(0.3, 0.15, 0.15, 0.3))
sdev[, ,4] &lt;- .3*diag(2)
proba &lt;- c(0.15, 0.05, 0.5, 0.3) # cluster frequencies
c &lt;- rep(0,n)
z &lt;- matrix(0, nrow=2, ncol=n)
for(k in 1:n){
 c[k] = which(rmultinom(n=1, size=1, prob=proba)!=0)
 z[,k] &lt;- m[, c[k]] + sdev[, , c[k]]%*%matrix(rnorm(2, mean = 0, sd = 1), nrow=2, ncol=1)
}

# Define hyperprior
hyperG0 &lt;- list()
hyperG0[["mu"]] &lt;- rep(0,d)
hyperG0[["kappa"]] &lt;- 0.001
hyperG0[["nu"]] &lt;- d+2
hyperG0[["lambda"]] &lt;- diag(d)


if(interactive()){
# Plot data
cytoScatter(z)

# Estimate posterior
MCMCsample_n &lt;- DPMpost(data=z, hyperG0=hyperG0, N=2000,
   distrib="gaussian", diagVar=FALSE,
   gg.add=list(ggplot2::theme_bw(),
      ggplot2::guides(shape=ggplot2::guide_legend(override.aes = list(fill="grey45"))))
 )
 s &lt;- summary(MCMCsample_n, burnin = 1500, thin=5, lossFn = "Binder")
 s
 plot(s)
 #plot(s, hm=TRUE) # this can take a few sec...
 
 
 # more data plotting:
 library(ggplot2)
 p &lt;- (ggplot(data.frame("X"=z[1,], "Y"=z[2,]), aes(x=X, y=Y))
       + geom_point()
       + ggtitle("Unsupervised data")
       + xlab("D1")
       + ylab("D2")
       + theme_bw()
 )
 p

 c2plot &lt;- factor(c)
 levels(c2plot) &lt;- c("4", "1", "3", "2")
 pp &lt;- (ggplot(data.frame("X"=z[1,], "Y"=z[2,], "Cluster"=as.character(c2plot)))
       + geom_point(aes(x=X, y=Y, colour=Cluster, fill=Cluster))
       #+ ggtitle("Slightly overlapping skew-normal simulation\n")
       + xlab("D1")
       + ylab("D2")
       + theme_bw()
       + scale_colour_discrete(guide=guide_legend(override.aes = list(size = 6, shape=22)))
       + ggtitle("True clusters")
 )
 pp
}


</code></pre>

<hr>
<h2 id='evalClustLoss'>ELoss of a partition point estimate compared to a gold standard</h2><span id='topic+evalClustLoss'></span>

<h3>Description</h3>

<p>Evaluate the loss of a point estimate of the partition compared to a gold standard according to a given loss function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evalClustLoss(c, gs, lossFn = "F-measure", a = 1, b = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evalClustLoss_+3A_c">c</code></td>
<td>
<p>vector of length <code>n</code> containing the estimated partition
of the  <code>n</code> observations.</p>
</td></tr>
<tr><td><code id="evalClustLoss_+3A_gs">gs</code></td>
<td>
<p>vector of length <code>n</code> containing the  gold standard
partition of the  <code>n</code> observations.</p>
</td></tr>
<tr><td><code id="evalClustLoss_+3A_lossfn">lossFn</code></td>
<td>
<p>character string specifying the loss function to be used.
Either &quot;F-measure&quot; or &quot;Binder&quot; (see Details). Default is &quot;F-measure&quot;.</p>
</td></tr>
<tr><td><code id="evalClustLoss_+3A_a">a</code></td>
<td>
<p>only relevant if <code>lossFn</code> is &quot;Binder&quot;. Penalty for wrong
co-clustering in <code>c</code> compared to <code>gs</code>. Defaults is 1.</p>
</td></tr>
<tr><td><code id="evalClustLoss_+3A_b">b</code></td>
<td>
<p>only relevant if <code>lossFn</code> is &quot;Binder&quot;. Penalty for missed
co-clustering in <code>c</code> compared to <code>gs</code>. Defaults is 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The cost of a point estimate partition is calculated using either a pairwise
coincidence loss function (Binder), or 1-Fmeasure (F-measure).
</p>


<h3>Value</h3>

<p>the cost of the point estimate <code>c</code> in regard of the
gold standard <code>gs</code> for a given loss function.
</p>


<h3>Author(s)</h3>

<p>Boris Hejblum
</p>


<h3>References</h3>

<p>J.W. Lau &amp; P.J. Green. Bayesian Model-Based Clustering
Procedures, Journal of Computational and Graphical Statistics,
16(3): 526-558, 2007.
</p>
<p>D. B. Dahl. Model-Based Clustering for Expression Data via a
Dirichlet Process Mixture Model, in Bayesian Inference for
Gene Expression and Proteomics, K.-A. Do, P. Muller, M. Vannucci
(Eds.), Cambridge University Press, 2006.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+similarityMat">similarityMat</a></code>, <code><a href="#topic+cluster_est_binder">cluster_est_binder</a></code>
</p>

<hr>
<h2 id='Flimited'>Compute a limited F-measure</h2><span id='topic+Flimited'></span>

<h3>Description</h3>

<p>A limited version of F-measure that only takes into account small clusters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Flimited(n_small_clst, pred, ref)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Flimited_+3A_n_small_clst">n_small_clst</code></td>
<td>
<p>an integer for limit size of the small cluster</p>
</td></tr>
<tr><td><code id="Flimited_+3A_pred">pred</code></td>
<td>
<p>vector of a predicted partition</p>
</td></tr>
<tr><td><code id="Flimited_+3A_ref">ref</code></td>
<td>
<p>vector of a reference partition</p>
</td></tr>
</table>


<h3>References</h3>

<p>Hejblum BP, Alkhassim C, Gottardo R, Caron F and Thiebaut R (2019) 
Sequential Dirichlet Process Mixtures of Multivariate Skew t-distributions for 
Model-based Clustering of Flow Cytometry Data. The Annals of Applied Statistics, 
13(1): 638-660. &lt;doi: 10.1214/18-AOAS1209&gt; &lt;arXiv: 1702.04407&gt; 
<a href="https://arxiv.org/abs/1702.04407">https://arxiv.org/abs/1702.04407</a> <a href="https://doi.org/10.1214/18-AOAS1209">doi:10.1214/18-AOAS1209</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pred &lt;- c(rep(1, 5),rep(2, 8),rep(3,10))
ref &lt;- c(rep(1, 5),rep(c(2,3), 4),rep(c(3,2),5))
FmeasureC(pred, ref)
Flimited(6, pred, ref)

</code></pre>

<hr>
<h2 id='Fmeasure_costC'>Multiple cost computations with the F-measure as the loss function</h2><span id='topic+Fmeasure_costC'></span>

<h3>Description</h3>

<p>C++ implementation of multiple cost computations with the F-measure as the loss
function using the Armadillo library
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Fmeasure_costC(c)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Fmeasure_costC_+3A_c">c</code></td>
<td>
<p>a matrix where each column is one MCMC partition</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with the following elements:
</p>
<table>
<tr><td><code>Fmeas:</code></td>
<td>
<p> TODO</p>
</td></tr>
<tr><td><code>cost:</code></td>
<td>
<p> TODO</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library(NPflow)
c &lt;- list(c(1,1,2,3,2,3), c(1,1,1,2,3,3),c(2,2,1,1,1,1))
#Fmeasure_costC(sapply(c, "["))

if(interactive()){
c2 &lt;- list()
for(i in 1:100){
    c2 &lt;- c(c2, list(rmultinom(n=1, size=2000, prob=rexp(n=2000))))
}
Fmeasure_costC(sapply(c2, "["))
}

</code></pre>

<hr>
<h2 id='FmeasureC'>C++ implementation of the F-measure computation</h2><span id='topic+FmeasureC'></span>

<h3>Description</h3>

<p>C++ implementation of the F-measure computation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FmeasureC(pred, ref)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FmeasureC_+3A_pred">pred</code></td>
<td>
<p>vector of a predicted partition</p>
</td></tr>
<tr><td><code id="FmeasureC_+3A_ref">ref</code></td>
<td>
<p>vector of a reference partition</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>pred &lt;- c(1,1,2,3,2,3)
ref &lt;- c(2,2,1,1,1,3)
FmeasureC(pred, ref)

</code></pre>

<hr>
<h2 id='FmeasureC_no0'>C++ implementation of the F-measure computation without the reference class 0</h2><span id='topic+FmeasureC_no0'></span>

<h3>Description</h3>

<p>Aghaeepour in FlowCAP 1 ignore the reference class labeled &quot;0&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FmeasureC_no0(pred, ref)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FmeasureC_no0_+3A_pred">pred</code></td>
<td>
<p>vector of a predicted partition</p>
</td></tr>
<tr><td><code id="FmeasureC_no0_+3A_ref">ref</code></td>
<td>
<p>vector of a reference partition</p>
</td></tr>
</table>


<h3>References</h3>

<p>N Aghaeepour, G Finak, H Hoos, TR Mosmann, RR Brinkman, R Gottardo,
RH Scheuermann, Critical assessment of automated flow cytometry data analysis
techniques, <em>Nature Methods</em>, 10(3):228-38, 2013.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(NPflow)
pred &lt;- c(1,1,2,3,2,3)
ref &lt;- c(2,2,0,0,0,3)
FmeasureC(pred, ref)
FmeasureC_no0(pred, ref)

</code></pre>

<hr>
<h2 id='invwishrnd'>Sample from a inverse-Wishart distribution</h2><span id='topic+invwishrnd'></span>

<h3>Description</h3>

<p>For internal use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>invwishrnd(n, lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="invwishrnd_+3A_n">n</code></td>
<td>
<p>degrees of freedom</p>
</td></tr>
<tr><td><code id="invwishrnd_+3A_lambda">lambda</code></td>
<td>
<p>scale parameter</p>
</td></tr>
</table>

<hr>
<h2 id='lgamma_mv'>Multivariate log gamma function</h2><span id='topic+lgamma_mv'></span>

<h3>Description</h3>

<p>Multivariate log gamma function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lgamma_mv(x, p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lgamma_mv_+3A_x">x</code></td>
<td>
<p>strictly positive real number</p>
</td></tr>
<tr><td><code id="lgamma_mv_+3A_p">p</code></td>
<td>
<p>integer</p>
</td></tr>
</table>

<hr>
<h2 id='MAP_sNiW_mmEM'>EM MAP for mixture of sNiW</h2><span id='topic+MAP_sNiW_mmEM'></span><span id='topic+MAP_sNiW_mmEM_weighted'></span><span id='topic+MAP_sNiW_mmEM_vague'></span>

<h3>Description</h3>

<p>Maximum A Posteriori (MAP) estimation of mixture of
Normal inverse Wishart distributed observations with an EM algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MAP_sNiW_mmEM(
  xi_list,
  psi_list,
  S_list,
  hyperG0,
  init = NULL,
  K,
  maxit = 100,
  tol = 0.1,
  doPlot = TRUE,
  verbose = TRUE
)

MAP_sNiW_mmEM_weighted(
  xi_list,
  psi_list,
  S_list,
  obsweight_list,
  hyperG0,
  K,
  maxit = 100,
  tol = 0.1,
  doPlot = TRUE,
  verbose = TRUE
)

MAP_sNiW_mmEM_vague(
  xi_list,
  psi_list,
  S_list,
  hyperG0,
  K = 10,
  maxit = 100,
  tol = 0.1,
  doPlot = TRUE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MAP_sNiW_mmEM_+3A_xi_list">xi_list</code></td>
<td>
<p>a list of length <code>n</code>, each element is a vector of size <code>d</code>
containing the argument <code>xi</code> of the corresponding allocated cluster.</p>
</td></tr>
<tr><td><code id="MAP_sNiW_mmEM_+3A_psi_list">psi_list</code></td>
<td>
<p>a list of length <code>n</code>, each element is a vector of size <code>d</code>
containing the argument <code>psi</code> of the corresponding allocated cluster.</p>
</td></tr>
<tr><td><code id="MAP_sNiW_mmEM_+3A_s_list">S_list</code></td>
<td>
<p>a list of length <code>n</code>, each element is a matrix of size <code>d x d</code>
containing the argument <code>S</code> of the corresponding allocated cluster.</p>
</td></tr>
<tr><td><code id="MAP_sNiW_mmEM_+3A_hyperg0">hyperG0</code></td>
<td>
<p>prior mixing distribution used if <code>init</code> is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="MAP_sNiW_mmEM_+3A_init">init</code></td>
<td>
<p>a list for initializing the algorithm with the following elements: <code>b_xi</code>,
<code>b_psi</code>, <code>lambda</code>, <code>B</code>, <code>nu</code>. Default is <code>NULL</code> in which case
the initialization of the algorithm is random.</p>
</td></tr>
<tr><td><code id="MAP_sNiW_mmEM_+3A_k">K</code></td>
<td>
<p>integer giving the number of mixture components.</p>
</td></tr>
<tr><td><code id="MAP_sNiW_mmEM_+3A_maxit">maxit</code></td>
<td>
<p>integer giving the maximum number of iteration for the EM algorithm.
Default is <code>100</code>.</p>
</td></tr>
<tr><td><code id="MAP_sNiW_mmEM_+3A_tol">tol</code></td>
<td>
<p>real number giving the tolerance for the stopping of the EM algorithm.
Default is <code>0.1</code>.</p>
</td></tr>
<tr><td><code id="MAP_sNiW_mmEM_+3A_doplot">doPlot</code></td>
<td>
<p>a logical flag indicating whether the algorithm progression should be plotted.
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="MAP_sNiW_mmEM_+3A_verbose">verbose</code></td>
<td>
<p>logical flag indicating whether plot should be drawn. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="MAP_sNiW_mmEM_+3A_obsweight_list">obsweight_list</code></td>
<td>
<p>a list of length <code>n</code> where each element is a vector of weights for
each sampled cluster at each MCMC iterations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>MAP_sNiW_mmEM</code> provides an estimation for the MAP of mixtures of
Normal inverse Wishart distributed observations. <code>MAP_sNiW_mmEM_vague</code> provides
an estimates incorporating a vague component in the mixture.
<code>MAP_sNiW_mmEM_weighted</code> provides a weighted version of the algorithm.
</p>


<h3>Author(s)</h3>

<p>Boris Hejblum, Chariff Alkhassim
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
hyperG0 &lt;- list()
hyperG0$b_xi &lt;- c(0.3, -1.5)
hyperG0$b_psi &lt;- c(0, 0)
hyperG0$kappa &lt;- 0.001
hyperG0$D_xi &lt;- 100
hyperG0$D_psi &lt;- 100
hyperG0$nu &lt;- 20
hyperG0$lambda &lt;- diag(c(0.25,0.35))

hyperG0 &lt;- list()
hyperG0$b_xi &lt;- c(1, -1.5)
hyperG0$b_psi &lt;- c(0, 0)
hyperG0$kappa &lt;- 0.1
hyperG0$D_xi &lt;- 1
hyperG0$D_psi &lt;- 1
hyperG0$nu &lt;- 2
hyperG0$lambda &lt;- diag(c(0.25,0.35))

xi_list &lt;- list()
psi_list &lt;- list()
S_list &lt;- list()
w_list &lt;- list()

for(k in 1:200){
 NNiW &lt;- rNNiW(hyperG0, diagVar=FALSE)
 xi_list[[k]] &lt;- NNiW[["xi"]]
 psi_list[[k]] &lt;- NNiW[["psi"]]
 S_list[[k]] &lt;- NNiW[["S"]]
 w_list [[k]] &lt;- 0.75
}


hyperG02 &lt;- list()
hyperG02$b_xi &lt;- c(-1, 2)
hyperG02$b_psi &lt;- c(-0.1, 0.5)
hyperG02$kappa &lt;- 0.1
hyperG02$D_xi &lt;- 1
hyperG02$D_psi &lt;- 1
hyperG02$nu &lt;- 4
hyperG02$lambda &lt;- 0.5*diag(2)

for(k in 201:400){
 NNiW &lt;- rNNiW(hyperG02, diagVar=FALSE)
 xi_list[[k]] &lt;- NNiW[["xi"]]
 psi_list[[k]] &lt;- NNiW[["psi"]]
 S_list[[k]] &lt;- NNiW[["S"]]
 w_list [[k]] &lt;- 0.25

}

map &lt;- MAP_sNiW_mmEM(xi_list, psi_list, S_list, hyperG0, K=2, tol=0.1)

</code></pre>

<hr>
<h2 id='MLE_gamma'>MLE for Gamma distribution</h2><span id='topic+MLE_gamma'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of Gamma distributed observations
distribution parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MLE_gamma(g)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLE_gamma_+3A_g">g</code></td>
<td>
<p>a list of Gamma distributed observation.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
g_list &lt;- list()
for(i in 1:1000){
 g_list &lt;- c(g_list, rgamma(1, shape=100, rate=5))
}

mle &lt;- MLE_gamma(g_list)
mle

</code></pre>

<hr>
<h2 id='MLE_NiW_mmEM'>EM MLE for mixture of NiW</h2><span id='topic+MLE_NiW_mmEM'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of mixture of
Normal inverse Wishart distributed observations with an EM algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MLE_NiW_mmEM(
  mu_list,
  S_list,
  hyperG0,
  K,
  maxit = 100,
  tol = 0.1,
  doPlot = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLE_NiW_mmEM_+3A_mu_list">mu_list</code></td>
<td>
<p>a list of length <code>N</code> whose elements are observed vectors of length <code>d</code>
of the mean parameters.</p>
</td></tr>
<tr><td><code id="MLE_NiW_mmEM_+3A_s_list">S_list</code></td>
<td>
<p>a list of length <code>N</code> whose elements are observed variance-covariance matrices
of dimension <code>d x d</code>.</p>
</td></tr>
<tr><td><code id="MLE_NiW_mmEM_+3A_hyperg0">hyperG0</code></td>
<td>
<p>prior mixing distribution used for randomly initializing the algorithm.</p>
</td></tr>
<tr><td><code id="MLE_NiW_mmEM_+3A_k">K</code></td>
<td>
<p>integer giving the number of mixture components.</p>
</td></tr>
<tr><td><code id="MLE_NiW_mmEM_+3A_maxit">maxit</code></td>
<td>
<p>integer giving the maximum number of iteration for the EM algorithm.
Default is <code>100</code>.</p>
</td></tr>
<tr><td><code id="MLE_NiW_mmEM_+3A_tol">tol</code></td>
<td>
<p>real number giving the tolerance for the stopping of the EM algorithm.
Default is <code>0.1</code>.</p>
</td></tr>
<tr><td><code id="MLE_NiW_mmEM_+3A_doplot">doPlot</code></td>
<td>
<p>a logical flag indicating whether the algorithm progression should be plotted. Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
U_mu &lt;- list()
U_Sigma &lt;- list()
U_nu&lt;-list()
U_kappa&lt;-list()

d &lt;- 2
hyperG0 &lt;- list()
hyperG0[["mu"]] &lt;- rep(1,d)
hyperG0[["kappa"]] &lt;- 0.01
hyperG0[["nu"]] &lt;- d+1
hyperG0[["lambda"]] &lt;- diag(d)

for(k in 1:200){

  NiW &lt;- rNiW(hyperG0, diagVar=FALSE)
  U_mu[[k]] &lt;-NiW[["mu"]]
  U_Sigma[[k]] &lt;-NiW[["S"]]
}


hyperG02 &lt;- list()
hyperG02[["mu"]] &lt;- rep(2,d)
hyperG02[["kappa"]] &lt;- 1
hyperG02[["nu"]] &lt;- d+10
hyperG02[["lambda"]] &lt;- diag(d)/10

for(k in 201:400){

  NiW &lt;- rNiW(hyperG02, diagVar=FALSE)
  U_mu[[k]] &lt;-NiW[["mu"]]
  U_Sigma[[k]] &lt;-NiW[["S"]]
}


mle &lt;- MLE_NiW_mmEM( U_mu, U_Sigma, hyperG0, K=2)

hyperG0[["mu"]]
hyperG02[["mu"]]
mle$U_mu

hyperG0[["lambda"]]
hyperG02[["lambda"]]
mle$U_lambda

hyperG0[["nu"]]
hyperG02[["nu"]]
mle$U_nu

hyperG0[["kappa"]]
hyperG02[["kappa"]]
mle$U_kappa
</code></pre>

<hr>
<h2 id='MLE_sNiW'>MLE for sNiW distributed observations</h2><span id='topic+MLE_sNiW'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of Normal inverse Wishart distributed observations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MLE_sNiW(xi_list, psi_list, S_list, doPlot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLE_sNiW_+3A_xi_list">xi_list</code></td>
<td>
<p>a list of length <code>N</code> whose elements are observed vectors of length <code>d</code>
of the mean parameters xi.</p>
</td></tr>
<tr><td><code id="MLE_sNiW_+3A_psi_list">psi_list</code></td>
<td>
<p>a list of length <code>N</code> whose elements are observed vectors of length <code>d</code>
of the skew parameters psi.</p>
</td></tr>
<tr><td><code id="MLE_sNiW_+3A_s_list">S_list</code></td>
<td>
<p>a list of length <code>N</code> whose elements are observed variance-covariance matrices
of dimension <code>d x d</code>.</p>
</td></tr>
<tr><td><code id="MLE_sNiW_+3A_doplot">doPlot</code></td>
<td>
<p>a logical flag indicating whether the algorithm progression should be plotted.
Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boris Hejblum, Chariff Alkhassim
</p>


<h3>Examples</h3>

<pre><code class='language-R'>hyperG0 &lt;- list()
hyperG0$b_xi &lt;- c(0.3, -1.5)
hyperG0$b_psi &lt;- c(0, 0)
hyperG0$kappa &lt;- 0.001
hyperG0$D_xi &lt;- 100
hyperG0$D_psi &lt;- 100
hyperG0$nu &lt;- 35
hyperG0$lambda &lt;- diag(c(0.25,0.35))

xi_list &lt;- list()
psi_list &lt;- list()
S_list &lt;- list()
for(k in 1:1000){
 NNiW &lt;- rNNiW(hyperG0, diagVar=FALSE)
 xi_list[[k]] &lt;- NNiW[["xi"]]
 psi_list[[k]] &lt;- NNiW[["psi"]]
 S_list[[k]] &lt;- NNiW[["S"]]
}

mle &lt;- MLE_sNiW(xi_list, psi_list, S_list)
mle
</code></pre>

<hr>
<h2 id='MLE_sNiW_mmEM'>EM MLE for mixture of sNiW</h2><span id='topic+MLE_sNiW_mmEM'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of mixture of
Normal inverse Wishart distributed observations with an EM algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MLE_sNiW_mmEM(
  xi_list,
  psi_list,
  S_list,
  hyperG0,
  K,
  init = NULL,
  maxit = 100,
  tol = 0.1,
  doPlot = TRUE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLE_sNiW_mmEM_+3A_xi_list">xi_list</code></td>
<td>
<p>a list of length <code>N</code> whose elements are observed vectors of length <code>d</code>
of the mean parameters xi.</p>
</td></tr>
<tr><td><code id="MLE_sNiW_mmEM_+3A_psi_list">psi_list</code></td>
<td>
<p>a list of length <code>N</code> whose elements are observed vectors of length <code>d</code>
of the skew parameters psi.</p>
</td></tr>
<tr><td><code id="MLE_sNiW_mmEM_+3A_s_list">S_list</code></td>
<td>
<p>a list of length <code>N</code> whose elements are observed variance-covariance matrices
of dimension <code>d x d</code>.</p>
</td></tr>
<tr><td><code id="MLE_sNiW_mmEM_+3A_hyperg0">hyperG0</code></td>
<td>
<p>prior mixing distribution used if <code>init</code> is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="MLE_sNiW_mmEM_+3A_k">K</code></td>
<td>
<p>integer giving the number of mixture components.</p>
</td></tr>
<tr><td><code id="MLE_sNiW_mmEM_+3A_init">init</code></td>
<td>
<p>a list for initializing the algorithm with the following elements: <code>b_xi</code>,
<code>b_psi</code>, <code>lambda</code>, <code>B</code>, <code>nu</code>. Default is <code>NULL</code> in which case
the initialization of the algorithm is random.</p>
</td></tr>
<tr><td><code id="MLE_sNiW_mmEM_+3A_maxit">maxit</code></td>
<td>
<p>integer giving the maximum number of iteration for the EM algorithm.
Default is <code>100</code>.</p>
</td></tr>
<tr><td><code id="MLE_sNiW_mmEM_+3A_tol">tol</code></td>
<td>
<p>real number giving the tolerance for the stopping of the EM algorithm.
Default is <code>0.1</code>.</p>
</td></tr>
<tr><td><code id="MLE_sNiW_mmEM_+3A_doplot">doPlot</code></td>
<td>
<p>a logical flag indicating whether the algorithm progression should be plotted. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="MLE_sNiW_mmEM_+3A_verbose">verbose</code></td>
<td>
<p>logical flag indicating whether plot should be drawn. Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boris Hejblum, Chariff Alkhassim
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
hyperG0 &lt;- list()
hyperG0$b_xi &lt;- c(0.3, -1.5)
hyperG0$b_psi &lt;- c(0, 0)
hyperG0$kappa &lt;- 0.001
hyperG0$D_xi &lt;- 100
hyperG0$D_psi &lt;- 100
hyperG0$nu &lt;- 3
hyperG0$lambda &lt;- diag(c(0.25,0.35))

xi_list &lt;- list()
psi_list &lt;- list()
S_list &lt;- list()
for(k in 1:200){
 NNiW &lt;- rNNiW(hyperG0, diagVar=FALSE)
 xi_list[[k]] &lt;- NNiW[["xi"]]
 psi_list[[k]] &lt;- NNiW[["psi"]]
 S_list[[k]] &lt;- NNiW[["S"]]
}

hyperG02 &lt;- list()
hyperG02$b_xi &lt;- c(-1, 2)
hyperG02$b_psi &lt;- c(-0.1, 0.5)
hyperG02$kappa &lt;- 0.001
hyperG02$D_xi &lt;- 10
hyperG02$D_psi &lt;- 10
hyperG02$nu &lt;- 3
hyperG02$lambda &lt;- 0.5*diag(2)

for(k in 201:400){
 NNiW &lt;- rNNiW(hyperG02, diagVar=FALSE)
 xi_list[[k]] &lt;- NNiW[["xi"]]
 psi_list[[k]] &lt;- NNiW[["psi"]]
 S_list[[k]] &lt;- NNiW[["S"]]
}

mle &lt;- MLE_sNiW_mmEM(xi_list, psi_list, S_list, hyperG0, K=2)

</code></pre>

<hr>
<h2 id='mmNiWpdf'>multivariate Normal inverse Wishart probability density function for multiple inputs</h2><span id='topic+mmNiWpdf'></span>

<h3>Description</h3>

<p>multivariate Normal inverse Wishart probability density function for multiple inputs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mmNiWpdf(mu, Sigma, U_mu0, U_kappa0, U_nu0, U_lambda0, Log = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmNiWpdf_+3A_mu">mu</code></td>
<td>
<p>data matrix of dimension <code>p x n</code>, <code>p</code> being the dimension of the
data and n the number of data points, where each column is an observed mean vector.</p>
</td></tr>
<tr><td><code id="mmNiWpdf_+3A_sigma">Sigma</code></td>
<td>
<p>list of length <code>n</code> of observed variance-covariance matrices,
each of dimensions <code>p x p</code>.</p>
</td></tr>
<tr><td><code id="mmNiWpdf_+3A_u_mu0">U_mu0</code></td>
<td>
<p>mean vectors matrix of dimension <code>p x K</code>, <code>K</code> being the number of
distributions for which the density probability has to be evaluated</p>
</td></tr>
<tr><td><code id="mmNiWpdf_+3A_u_kappa0">U_kappa0</code></td>
<td>
<p>vector of length <code>K</code> of scale parameters.</p>
</td></tr>
<tr><td><code id="mmNiWpdf_+3A_u_nu0">U_nu0</code></td>
<td>
<p>vector of length <code>K</code> of degree of freedom parameters.</p>
</td></tr>
<tr><td><code id="mmNiWpdf_+3A_u_lambda0">U_lambda0</code></td>
<td>
<p>list of length <code>K</code> of variance-covariance matrices,
each of dimensions <code>p x p</code>.</p>
</td></tr>
<tr><td><code id="mmNiWpdf_+3A_log">Log</code></td>
<td>
<p>logical flag for returning the log of the probability density
function. Defaults is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix of densities of dimension K x n
</p>

<hr>
<h2 id='mmNiWpdfC'>C++ implementation of multivariate Normal inverse Wishart probability density function for multiple inputs</h2><span id='topic+mmNiWpdfC'></span>

<h3>Description</h3>

<p>C++ implementation of multivariate Normal inverse Wishart probability density function for multiple inputs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mmNiWpdfC(Mu, Sigma, U_Mu0, U_Kappa0, U_Nu0, U_Sigma0, Log = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmNiWpdfC_+3A_mu">Mu</code></td>
<td>
<p>data matrix of dimension <code>p x n</code>, <code>p</code> being the dimension of the
data and n the number of data points, where each column is an observed mean vector.</p>
</td></tr>
<tr><td><code id="mmNiWpdfC_+3A_sigma">Sigma</code></td>
<td>
<p>list of length <code>n</code> of observed variance-covariance matrices,
each of dimensions <code>p x p</code>.</p>
</td></tr>
<tr><td><code id="mmNiWpdfC_+3A_u_mu0">U_Mu0</code></td>
<td>
<p>mean vectors matrix of dimension <code>p x K</code>, <code>K</code> being the number of
distributions for which the density probability has to be evaluated</p>
</td></tr>
<tr><td><code id="mmNiWpdfC_+3A_u_kappa0">U_Kappa0</code></td>
<td>
<p>vector of length <code>K</code> of scale parameters.</p>
</td></tr>
<tr><td><code id="mmNiWpdfC_+3A_u_nu0">U_Nu0</code></td>
<td>
<p>vector of length <code>K</code> of degree of freedom parameters.</p>
</td></tr>
<tr><td><code id="mmNiWpdfC_+3A_u_sigma0">U_Sigma0</code></td>
<td>
<p>list of length <code>K</code> of variance-covariance matrices,
each of dimensions <code>p x p</code>.</p>
</td></tr>
<tr><td><code id="mmNiWpdfC_+3A_log">Log</code></td>
<td>
<p>logical flag for returning the log of the probability density
function. Defaults is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix of densities of dimension K x n
</p>


<h3>References</h3>

<p>Hejblum BP, Alkhassim C, Gottardo R, Caron F and Thiebaut R (2019) 
Sequential Dirichlet Process Mixtures of Multivariate Skew t-distributions for 
Model-based Clustering of Flow Cytometry Data. The Annals of Applied Statistics, 
13(1): 638-660. &lt;doi: 10.1214/18-AOAS1209&gt;. &lt;arXiv: 1702.04407&gt;. 
<a href="https://arxiv.org/abs/1702.04407">https://arxiv.org/abs/1702.04407</a> <a href="https://doi.org/10.1214/18-AOAS1209">doi:10.1214/18-AOAS1209</a>
</p>

<hr>
<h2 id='mmsNiWlogpdf'>Probability density function of multiple structured Normal inverse Wishart</h2><span id='topic+mmsNiWlogpdf'></span>

<h3>Description</h3>

<p>Probability density function of structured Normal inverse Wishart (sNiW)
for multiple inputs, on the log scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mmsNiWlogpdf(U_xi, U_psi, U_Sigma, U_xi0, U_psi0, U_B0, U_Sigma0, U_df0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmsNiWlogpdf_+3A_u_xi">U_xi</code></td>
<td>
<p>a list of length n of observed mean vectors, each of dimension p</p>
</td></tr>
<tr><td><code id="mmsNiWlogpdf_+3A_u_psi">U_psi</code></td>
<td>
<p>a list of length n of observed skew vectors of dimension p</p>
</td></tr>
<tr><td><code id="mmsNiWlogpdf_+3A_u_sigma">U_Sigma</code></td>
<td>
<p>a list of length n of observed covariance matrices, each of dimension p x p</p>
</td></tr>
<tr><td><code id="mmsNiWlogpdf_+3A_u_xi0">U_xi0</code></td>
<td>
<p>a list of length K of mean vector parameters for sNiW, each of dimension p</p>
</td></tr>
<tr><td><code id="mmsNiWlogpdf_+3A_u_psi0">U_psi0</code></td>
<td>
<p>a list of length K of mean vector parameters for sNiW, each of dimension p</p>
</td></tr>
<tr><td><code id="mmsNiWlogpdf_+3A_u_b0">U_B0</code></td>
<td>
<p>a list of length K of structuring matrix parameters for sNiW, each of dimension 2 x 2</p>
</td></tr>
<tr><td><code id="mmsNiWlogpdf_+3A_u_sigma0">U_Sigma0</code></td>
<td>
<p>a list of length K of covariance matrix parameters for sNiW, each of dimension p x p</p>
</td></tr>
<tr><td><code id="mmsNiWlogpdf_+3A_u_df0">U_df0</code></td>
<td>
<p>a list of length K of degrees of freedom parameters for sNiW, each of dimension p x p</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>hyperG0 &lt;- list()
hyperG0$b_xi &lt;- c(-1.6983129, -0.4819131)
hyperG0$b_psi &lt;- c(-0.0641866, -0.7606068)
hyperG0$kappa &lt;- 0.001
hyperG0$D_xi &lt;- 16.951313
hyperG0$D_psi &lt;- 1.255192
hyperG0$nu &lt;- 27.67656
hyperG0$lambda &lt;- matrix(c(2.3397761, -0.3975259,-0.3975259, 1.9601773), ncol=2)

xi_list &lt;- list()
psi_list &lt;- list()
S_list &lt;- list()
for(k in 1:1000){
 NNiW &lt;- rNNiW(hyperG0, diagVar=FALSE)
 xi_list[[k]] &lt;- NNiW[["xi"]]
 psi_list[[k]] &lt;- NNiW[["psi"]]
 S_list[[k]] &lt;- NNiW[["S"]]
}
mmsNiWlogpdf(U_xi=xi_list, U_psi=psi_list, U_Sigma=S_list,
            U_xi0=list(hyperG0$b_xi), U_psi0=list(hyperG0$b_psi) ,
            U_B0=list(diag(c(hyperG0$D_xi, hyperG0$D_psi))) ,
            U_Sigma0=list(hyperG0$lambda), U_df0=list(hyperG0$nu))


hyperG0 &lt;- list()
hyperG0$b_xi &lt;- c(-1.6983129)
hyperG0$b_psi &lt;- c(-0.0641866)
hyperG0$kappa &lt;- 0.001
hyperG0$D_xi &lt;- 16.951313
hyperG0$D_psi &lt;- 1.255192
hyperG0$nu &lt;- 27.67656
hyperG0$lambda &lt;- matrix(c(2.3397761), ncol=1)
#'xi_list &lt;- list()
psi_list &lt;- list()
S_list &lt;- list()
for(k in 1:1000){
 NNiW &lt;- rNNiW(hyperG0, diagVar=FALSE)
 xi_list[[k]] &lt;- NNiW[["xi"]]
 psi_list[[k]] &lt;- NNiW[["psi"]]
 S_list[[k]] &lt;- NNiW[["S"]]
}

mmsNiWlogpdf(U_xi=xi_list, U_psi=psi_list, U_Sigma=S_list,
            U_xi0=list(hyperG0$b_xi), U_psi0=list(hyperG0$b_psi) ,
            U_B0=list(diag(c(hyperG0$D_xi, hyperG0$D_psi))) ,
            U_Sigma0=list(hyperG0$lambda), U_df0=list(hyperG0$nu))

</code></pre>

<hr>
<h2 id='mmsNiWpdfC'>C++ implementation of multivariate structured Normal inverse Wishart probability density function for multiple inputs</h2><span id='topic+mmsNiWpdfC'></span>

<h3>Description</h3>

<p>C++ implementation of multivariate structured Normal inverse Wishart probability density function for multiple inputs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mmsNiWpdfC(xi, psi, Sigma, U_xi0, U_psi0, U_B0, U_Sigma0, U_df0, Log = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmsNiWpdfC_+3A_xi">xi</code></td>
<td>
<p>data matrix of dimensions <code>p x n</code> where columns contain the observed
mean vectors.</p>
</td></tr>
<tr><td><code id="mmsNiWpdfC_+3A_psi">psi</code></td>
<td>
<p>data matrix of dimensions <code>p x n</code> where columns contain the observed
skew parameter vectors.</p>
</td></tr>
<tr><td><code id="mmsNiWpdfC_+3A_sigma">Sigma</code></td>
<td>
<p>list of length <code>n</code> of observed variance-covariance matrices,
each of dimensions <code>p x p</code>.</p>
</td></tr>
<tr><td><code id="mmsNiWpdfC_+3A_u_xi0">U_xi0</code></td>
<td>
<p>mean vectors matrix of dimension <code>p x K</code>, <code>K</code> being the number of
distributions for which the density probability has to be evaluated.</p>
</td></tr>
<tr><td><code id="mmsNiWpdfC_+3A_u_psi0">U_psi0</code></td>
<td>
<p>skew parameter vectors matrix of dimension <code>p x K</code>.</p>
</td></tr>
<tr><td><code id="mmsNiWpdfC_+3A_u_b0">U_B0</code></td>
<td>
<p>list of length <code>K</code> of structured scale matrices,
each of dimensions <code>p x p</code>.</p>
</td></tr>
<tr><td><code id="mmsNiWpdfC_+3A_u_sigma0">U_Sigma0</code></td>
<td>
<p>list of length <code>K</code> of variance-covariance matrices,
each of dimensions <code>p x p</code>.</p>
</td></tr>
<tr><td><code id="mmsNiWpdfC_+3A_u_df0">U_df0</code></td>
<td>
<p>vector of length <code>K</code> of degree of freedom parameters.</p>
</td></tr>
<tr><td><code id="mmsNiWpdfC_+3A_log">Log</code></td>
<td>
<p>logical flag for returning the log of the probability density
function. Defaults is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix of densities of dimension <code>K x n</code>
</p>


<h3>References</h3>

<p>Hejblum BP, Alkhassim C, Gottardo R, Caron F and Thiebaut R (2019) 
Sequential Dirichlet Process Mixtures of Multivariate Skew t-distributions for 
Model-based Clustering of Flow Cytometry Data. The Annals of Applied Statistics, 
13(1): 638-660. &lt;doi: 10.1214/18-AOAS1209&gt;. &lt;arXiv: 1702.04407&gt;. 
<a href="https://arxiv.org/abs/1702.04407">https://arxiv.org/abs/1702.04407</a> <a href="https://doi.org/10.1214/18-AOAS1209">doi:10.1214/18-AOAS1209</a>
</p>

<hr>
<h2 id='mmvnpdfC'>C++ implementation of multivariate Normal probability density function for multiple inputs</h2><span id='topic+mmvnpdfC'></span>

<h3>Description</h3>

<p>C++ implementation of multivariate Normal probability density function for multiple inputs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mmvnpdfC(x, mean, varcovM, Log = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmvnpdfC_+3A_x">x</code></td>
<td>
<p>data matrix of dimension <code>p x n</code>, <code>p</code> being the dimension of the
data and n the number of data points.</p>
</td></tr>
<tr><td><code id="mmvnpdfC_+3A_mean">mean</code></td>
<td>
<p>mean vectors matrix of dimension <code>p x K</code>, <code>K</code> being the number of
distributions for which the density probability has to be evaluated.</p>
</td></tr>
<tr><td><code id="mmvnpdfC_+3A_varcovm">varcovM</code></td>
<td>
<p>list of length <code>K</code> of variance-covariance matrices,
each of dimensions <code>p x p</code>.</p>
</td></tr>
<tr><td><code id="mmvnpdfC_+3A_log">Log</code></td>
<td>
<p>logical flag for returning the log of the probability density
function. Defaults is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix of densities of dimension <code>K x n</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(require(microbenchmark)){
library(microbenchmark)
microbenchmark(mvnpdf(x=matrix(1.96), mean=0, varcovM=diag(1), Log=FALSE),
               mvnpdfC(x=matrix(1.96), mean=0, varcovM=diag(1), Log=FALSE),
               mmvnpdfC(x=matrix(1.96), mean=matrix(0), varcovM=list(diag(1)), Log=FALSE),
               times=1000L)
microbenchmark(mvnpdf(x=matrix(rep(1.96,2), nrow=2, ncol=1), mean=c(-0.2, 0.3),
                      varcovM=matrix(c(2, 0.2, 0.2, 2), ncol=2), Log=FALSE),
               mvnpdfC(x=matrix(rep(1.96,2), nrow=2, ncol=1), mean=c(-0.2, 0.3),
                       varcovM=matrix(c(2, 0.2, 0.2, 2), ncol=2), Log=FALSE),
               mmvnpdfC(x=matrix(rep(1.96,2), nrow=2, ncol=1),
                        mean=matrix(c(-0.2, 0.3), nrow=2, ncol=1),
                        varcovM=list(matrix(c(2, 0.2, 0.2, 2), ncol=2)), Log=FALSE),
               times=1000L)
microbenchmark(mvnpdf(x=matrix(c(rep(1.96,2),rep(0,2)), nrow=2, ncol=2),
                      mean=list(c(0,0),c(-1,-1), c(1.5,1.5)),
                      varcovM=list(diag(2),10*diag(2), 20*diag(2)), Log=FALSE),
               mmvnpdfC(matrix(c(rep(1.96,2),rep(0,2)), nrow=2, ncol=2),
                        mean=matrix(c(0,0,-1,-1, 1.5,1.5), nrow=2, ncol=3),
                        varcovM=list(diag(2),10*diag(2), 20*diag(2)), Log=FALSE),
               times=1000L)
}else{
cat("package 'microbenchmark' not available\n")
}
</code></pre>

<hr>
<h2 id='mmvsnpdfC'>C++ implementation of multivariate skew Normal probability density function for multiple inputs</h2><span id='topic+mmvsnpdfC'></span>

<h3>Description</h3>

<p>C++ implementation of multivariate skew Normal probability density function for multiple inputs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mmvsnpdfC(x, xi, psi, sigma, Log = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmvsnpdfC_+3A_x">x</code></td>
<td>
<p>data matrix of dimension <code>p x n</code>, <code>p</code> being the dimension of the
data and n the number of data points.</p>
</td></tr>
<tr><td><code id="mmvsnpdfC_+3A_xi">xi</code></td>
<td>
<p>mean vectors matrix of dimension <code>p x K</code>, <code>K</code> being the number of
distributions for which the density probability has to be evaluated.</p>
</td></tr>
<tr><td><code id="mmvsnpdfC_+3A_psi">psi</code></td>
<td>
<p>skew parameter vectors matrix of dimension <code>p x K</code>.</p>
</td></tr>
<tr><td><code id="mmvsnpdfC_+3A_sigma">sigma</code></td>
<td>
<p>list of length K of variance-covariance matrices,
each of dimensions <code>p x p</code>.</p>
</td></tr>
<tr><td><code id="mmvsnpdfC_+3A_log">Log</code></td>
<td>
<p>logical flag for returning the log of the probability density
function. Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix of densities of dimension <code>K x n</code>.
</p>


<h3>Author(s)</h3>

<p>Boris Hejblum
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mmvsnpdfC(x=matrix(rep(1.96,2), nrow=2, ncol=1),
         xi=matrix(c(0, 0)), psi=matrix(c(1, 1),ncol=1), sigma=list(diag(2)), Log=FALSE
         )
mmvsnpdfC(x=matrix(rep(1.96,2), nrow=2, ncol=1),
         xi=matrix(c(0, 0)), psi=matrix(c(1, 1),ncol=1), sigma=list(diag(2))
         )

if(require(microbenchmark)){
library(microbenchmark)
microbenchmark(mvsnpdf(x=matrix(rep(1.96,2), nrow=2, ncol=1), xi=c(0, 0), psi=c(1, 1),
                       sigma=diag(2), Log=FALSE),
               mmvsnpdfC(x=matrix(rep(1.96,2), nrow=2, ncol=1), xi=matrix(c(0, 0)),
                         psi=matrix(c(1, 1),ncol=1), sigma=list(diag(2)), Log=FALSE),
               times=1000L
             )
microbenchmark(mvsnpdf(x=matrix(c(rep(1.96,2),rep(0,2)), nrow=2, ncol=2),
                      xi=list(c(0,0),c(-1,-1), c(1.5,1.5)),
                      psi=list(c(0.1,0.1),c(-0.1,-1), c(0.5,-1.5)),
                      sigma=list(diag(2),10*diag(2), 20*diag(2)), Log=FALSE),
               mmvsnpdfC(matrix(c(rep(1.96,2),rep(0,2)), nrow=2, ncol=2),
                         xi=matrix(c(0,0,-1,-1, 1.5,1.5), nrow=2, ncol=3),
                         psi=matrix(c(0.1,0.1,-0.1,-1, 0.5,-1.5), nrow=2, ncol=3),
                         sigma=list(diag(2),10*diag(2), 20*diag(2)), Log=FALSE),
              times=1000L)
}else{
cat("package 'microbenchmark' not available\n")
}
</code></pre>

<hr>
<h2 id='mmvstpdfC'>C++ implementation of multivariate Normal probability density function for multiple inputs</h2><span id='topic+mmvstpdfC'></span>

<h3>Description</h3>

<p>C++ implementation of multivariate Normal probability density function for multiple inputs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mmvstpdfC(x, xi, psi, sigma, df, Log = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmvstpdfC_+3A_x">x</code></td>
<td>
<p>data matrix of dimension <code>p x n</code>, <code>p</code> being the dimension of the
data and n the number of data points.</p>
</td></tr>
<tr><td><code id="mmvstpdfC_+3A_xi">xi</code></td>
<td>
<p>mean vectors matrix of dimension <code>p x K</code>, <code>K</code> being the number of
distributions for which the density probability has to be evaluated.</p>
</td></tr>
<tr><td><code id="mmvstpdfC_+3A_psi">psi</code></td>
<td>
<p>skew parameter vectors matrix of dimension <code>p x K</code>.</p>
</td></tr>
<tr><td><code id="mmvstpdfC_+3A_sigma">sigma</code></td>
<td>
<p>list of length <code>K</code> of variance-covariance matrices,
each of dimensions <code>p x p</code>.</p>
</td></tr>
<tr><td><code id="mmvstpdfC_+3A_df">df</code></td>
<td>
<p>vector of length K of degree of freedom parameters.</p>
</td></tr>
<tr><td><code id="mmvstpdfC_+3A_log">Log</code></td>
<td>
<p>logical flag for returning the log of the probability density
function. Defaults is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix of densities of dimension <code>K x n</code>.
</p>


<h3>Author(s)</h3>

<p>Boris Hejblum
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mmvstpdfC(x = matrix(c(3.399890,-5.936962), ncol=1), xi=matrix(c(0.2528859,-2.4234067)),
psi=matrix(c(11.20536,-12.51052), ncol=1),
sigma=list(matrix(c(0.2134011, -0.0382573, -0.0382573, 0.2660086), ncol=2)),
df=c(7.784106)
)
mvstpdf(x = matrix(c(3.399890,-5.936962), ncol=1), xi=c(0.2528859,-2.4234067),
psi=c(11.20536,-12.51052),
sigma=matrix(c(0.2134011, -0.0382573, -0.0382573, 0.2660086), ncol=2),
df=c(7.784106)
)

#skew-normal limit
mmvsnpdfC(x=matrix(rep(1.96,2), nrow=2, ncol=1),
         xi=matrix(c(0, 0)), psi=matrix(c(1, 1),ncol=1), sigma=list(diag(2))
         )
mvstpdf(x=matrix(rep(1.96,2), nrow=2, ncol=1),
       xi=c(0, 0), psi=c(1, 1), sigma=diag(2),
       df=100000000
       )
mmvstpdfC(x=matrix(rep(1.96,2), nrow=2, ncol=1),
         xi=matrix(c(0, 0)), psi=matrix(c(1, 1),ncol=1), sigma=list(diag(2)),
         df=100000000
         )

#non-skewed limit
mmvtpdfC(x=matrix(rep(1.96,2), nrow=2, ncol=1),
        mean=matrix(c(0, 0)), varcovM=list(diag(2)),
        df=10
        )
mmvstpdfC(x=matrix(rep(1.96,2), nrow=2, ncol=1),
         xi=matrix(c(0, 0)), psi=matrix(c(0, 0),ncol=1), sigma=list(diag(2)),
         df=10
         )

if(require(microbenchmark)){
library(microbenchmark)
microbenchmark(mvstpdf(x=matrix(rep(1.96,2), nrow=2, ncol=1),
                       xi=c(0, 0), psi=c(1, 1),
                       sigma=diag(2), df=10),
               mmvstpdfC(x=matrix(rep(1.96,2), nrow=2, ncol=1),
                         xi=matrix(c(0, 0)), psi=matrix(c(1, 1),ncol=1),
                         sigma=list(diag(2)), df=10),
               times=1000L)
}else{
cat("package 'microbenchmark' not available\n")
}
</code></pre>

<hr>
<h2 id='mmvtpdfC'>C++ implementation of multivariate Normal probability density function for multiple inputs</h2><span id='topic+mmvtpdfC'></span>

<h3>Description</h3>

<p>C++ implementation of multivariate Normal probability density function for multiple inputs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mmvtpdfC(x, mean, varcovM, df, Log = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmvtpdfC_+3A_x">x</code></td>
<td>
<p>data matrix of dimension <code>p x n</code>, <code>p</code> being the dimension of the
data and n the number of data points.</p>
</td></tr>
<tr><td><code id="mmvtpdfC_+3A_mean">mean</code></td>
<td>
<p>mean vectors matrix of dimension <code>p x K</code>, <code>K</code> being the number of
distributions for which the density probability has to be evaluated.</p>
</td></tr>
<tr><td><code id="mmvtpdfC_+3A_varcovm">varcovM</code></td>
<td>
<p>list of length <code>K</code> of variance-covariance matrices,
each of dimensions <code>p x p</code>.</p>
</td></tr>
<tr><td><code id="mmvtpdfC_+3A_df">df</code></td>
<td>
<p>vector of length <code>K</code> of degree of freedom parameters.</p>
</td></tr>
<tr><td><code id="mmvtpdfC_+3A_log">Log</code></td>
<td>
<p>logical flag for returning the log of the probability density
function. Defaults is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix of densities of dimension <code>K x n</code>.
</p>


<h3>Author(s)</h3>

<p>Boris Hejblum
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mvnpdf(x=matrix(1.96), mean=0, varcovM=diag(1), Log=FALSE)
mvtpdf(x=matrix(1.96), mean=0, varcovM=diag(1), df=10000000, Log=FALSE)
mmvtpdfC(x=matrix(1.96), mean=matrix(0), varcovM=list(diag(1)), df=10000000, Log=FALSE)

mvnpdf(x=matrix(1.96), mean=0, varcovM=diag(1))
mvtpdf(x=matrix(1.96), mean=0, varcovM=diag(1), df=10000000)
mmvtpdfC(x=matrix(1.96), mean=matrix(0), varcovM=list(diag(1)), df=10000000)

mvtpdf(x=matrix(1.96), mean=0, varcovM=diag(1), df=10)
mmvtpdfC(x=matrix(1.96), mean=matrix(0), varcovM=list(diag(1)), df=10)


if(require(microbenchmark)){
library(microbenchmark)
microbenchmark(mvtpdf(x=matrix(1.96), mean=0, varcovM=diag(1), df=1, Log=FALSE),
               mmvtpdfC(x=matrix(1.96), mean=matrix(0), varcovM=list(diag(1)),
                        df=c(1), Log=FALSE),
               times=10000L)
}else{
cat("package 'microbenchmark' not available\n")
}
</code></pre>

<hr>
<h2 id='mvnlikC'>C++ implementation of multivariate Normal probability density function for multiple inputs</h2><span id='topic+mvnlikC'></span>

<h3>Description</h3>

<p>C++ implementation of multivariate Normal probability density function for multiple inputs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvnlikC(x, c, clustval, mu, sigma, loglik = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvnlikC_+3A_x">x</code></td>
<td>
<p>data matrix of dimension p x n, p being the dimension of the
data and n the number of data points</p>
</td></tr>
<tr><td><code id="mvnlikC_+3A_c">c</code></td>
<td>
<p>integer vector of cluster allocations with values from 1 to K</p>
</td></tr>
<tr><td><code id="mvnlikC_+3A_clustval">clustval</code></td>
<td>
<p>vector of unique values from c in the order corresponding to
the storage of cluster parameters in <code>xi</code>, <code>psi</code>, and <code>varcovM</code></p>
</td></tr>
<tr><td><code id="mvnlikC_+3A_mu">mu</code></td>
<td>
<p>mean vectors matrix of dimension p x K, K being the number of
clusters</p>
</td></tr>
<tr><td><code id="mvnlikC_+3A_sigma">sigma</code></td>
<td>
<p>list of length <code>K</code> of variance-covariance matrices,
each of dimensions <code>p x p</code>.</p>
</td></tr>
<tr><td><code id="mvnlikC_+3A_loglik">loglik</code></td>
<td>
<p>logical flag or returning the log-likelihood instead of the likelihood.
Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list:
</p>
<table>
<tr><td><code>"indiv":</code></td>
<td>
<p> vector of likelihood of length n;</p>
</td></tr>
<tr><td><code>"clust":</code></td>
<td>
<p> vector of likelihood of length K;</p>
</td></tr>
<tr><td><code>"total":</code></td>
<td>
<p> total (log)-likelihood;</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boris Hejblum
</p>

<hr>
<h2 id='mvnpdf'>multivariate-Normal probability density function</h2><span id='topic+mvnpdf'></span>

<h3>Description</h3>

<p>multivariate-Normal probability density function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvnpdf(x, mean, varcovM, Log = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvnpdf_+3A_x">x</code></td>
<td>
<p>p x n data matrix with n the number of observations and
p the number of dimensions</p>
</td></tr>
<tr><td><code id="mvnpdf_+3A_mean">mean</code></td>
<td>
<p>mean vector or list of mean vectors (either a vector,
a matrix or a list)</p>
</td></tr>
<tr><td><code id="mvnpdf_+3A_varcovm">varcovM</code></td>
<td>
<p>variance-covariance matrix or list of variance-covariance
matrices (either a matrix or a list)</p>
</td></tr>
<tr><td><code id="mvnpdf_+3A_log">Log</code></td>
<td>
<p>logical flag for returning the log of the probability density
function. Defaults is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boris P. Hejblum
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvnpdf">mvnpdf</a></code>, <code><a href="#topic+mmvnpdfC">mmvnpdfC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
mvnpdf(x=matrix(1.96), mean=0, varcovM=diag(1), Log=FALSE)
dnorm(1.96)

mvnpdf(x=matrix(rep(1.96,2), nrow=2, ncol=1),
      mean=c(0, 0), varcovM=diag(2), Log=FALSE
)

</code></pre>

<hr>
<h2 id='mvnpdfC'>C++ implementation of multivariate normal probability density function for 
multiple inputs</h2><span id='topic+mvnpdfC'></span>

<h3>Description</h3>

<p>Based on the implementation from Nino Hardt and Dicko Ahmadou
<a href="https://gallery.rcpp.org/articles/dmvnorm_arma/">https://gallery.rcpp.org/articles/dmvnorm_arma/</a>
(accessed in August 2014)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvnpdfC(x, mean, varcovM, Log = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvnpdfC_+3A_x">x</code></td>
<td>
<p>data matrix</p>
</td></tr>
<tr><td><code id="mvnpdfC_+3A_mean">mean</code></td>
<td>
<p>mean vector</p>
</td></tr>
<tr><td><code id="mvnpdfC_+3A_varcovm">varcovM</code></td>
<td>
<p>variance covariance matrix</p>
</td></tr>
<tr><td><code id="mvnpdfC_+3A_log">Log</code></td>
<td>
<p>logical flag for returning the log of the probability density
function. Default is <code>TRUE</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of densities
</p>


<h3>Author(s)</h3>

<p>Boris P. Hejblum
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mvnpdf(x=matrix(1.96), mean=0, varcovM=diag(1), Log=FALSE)
mvnpdfC(x=matrix(1.96), mean=0, varcovM=diag(1), Log=FALSE)
mvnpdf(x=matrix(1.96), mean=0, varcovM=diag(1))
mvnpdfC(x=matrix(1.96), mean=0, varcovM=diag(1))

if(require(microbenchmark)){
library(microbenchmark)
microbenchmark(dnorm(1.96),
               mvnpdf(x=matrix(1.96), mean=0, varcovM=diag(1), Log=FALSE),
               mvnpdfC(x=matrix(1.96), mean=0, varcovM=diag(1), Log=FALSE),
               times=10000L)
}else{
cat("package 'microbenchmark' not available\n")
}

</code></pre>

<hr>
<h2 id='mvsnlikC'>C++ implementation of multivariate skew normal likelihood function for multiple inputs</h2><span id='topic+mvsnlikC'></span>

<h3>Description</h3>

<p>C++ implementation of multivariate skew normal likelihood function for multiple inputs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvsnlikC(x, c, clustval, xi, psi, sigma, loglik = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvsnlikC_+3A_x">x</code></td>
<td>
<p>data matrix of dimension p x n, p being the dimension of the
data and n the number of data points</p>
</td></tr>
<tr><td><code id="mvsnlikC_+3A_c">c</code></td>
<td>
<p>integer vector of cluster allocations with values from 1 to K</p>
</td></tr>
<tr><td><code id="mvsnlikC_+3A_clustval">clustval</code></td>
<td>
<p>vector of unique values from c in the order corresponding to
the storage of cluster parameters in <code>xi</code>, <code>psi</code>, and <code>sigma</code></p>
</td></tr>
<tr><td><code id="mvsnlikC_+3A_xi">xi</code></td>
<td>
<p>mean vectors matrix of dimension p x K, K being the number of
clusters</p>
</td></tr>
<tr><td><code id="mvsnlikC_+3A_psi">psi</code></td>
<td>
<p>skew parameter vectors matrix of dimension <code>p x K</code></p>
</td></tr>
<tr><td><code id="mvsnlikC_+3A_sigma">sigma</code></td>
<td>
<p>list of length <code>K</code> of variance-covariance matrices,
each of dimensions <code>p x p</code>.</p>
</td></tr>
<tr><td><code id="mvsnlikC_+3A_loglik">loglik</code></td>
<td>
<p>logical flag or returning the log-likelihood instead of the likelihood.
Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list:
</p>
<table>
<tr><td><code>"indiv":</code></td>
<td>
<p> vector of likelihood of length n;</p>
</td></tr>
<tr><td><code>"clust":</code></td>
<td>
<p> vector of likelihood of length K;</p>
</td></tr>
<tr><td><code>"total":</code></td>
<td>
<p> total (log)-likelihood;</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boris Hejblum
</p>

<hr>
<h2 id='mvsnpdf'>multivariate Skew-Normal probability density function</h2><span id='topic+mvsnpdf'></span>

<h3>Description</h3>

<p>multivariate Skew-Normal probability density function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvsnpdf(x, xi, sigma, psi, Log = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvsnpdf_+3A_x">x</code></td>
<td>
<p>p x n data matrix with n the number of observations and
p the number of dimensions</p>
</td></tr>
<tr><td><code id="mvsnpdf_+3A_xi">xi</code></td>
<td>
<p>mean vector or list of mean vectors (either a vector,
a matrix or a list)</p>
</td></tr>
<tr><td><code id="mvsnpdf_+3A_sigma">sigma</code></td>
<td>
<p>variance-covariance matrix or list of variance-covariance
matrices (either a matrix or a list)</p>
</td></tr>
<tr><td><code id="mvsnpdf_+3A_psi">psi</code></td>
<td>
<p>skew parameter vector or list of skew parameter vectors
(either a vector, a matrix or a list)</p>
</td></tr>
<tr><td><code id="mvsnpdf_+3A_log">Log</code></td>
<td>
<p>logical flag for returning the log of the probability density
function. Defaults is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+mvnpdf">mvnpdf</a></code>, <code><a href="#topic+mmvsnpdfC">mmvsnpdfC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
mvnpdf(x=matrix(1.96), mean=0, varcovM=diag(1), Log=FALSE)
dnorm(1.96)
mvsnpdf(x=matrix(rep(1.96,1), nrow=1, ncol=1),
      xi=c(0), psi=c(0), sigma=diag(1),
      Log=FALSE
)

mvsnpdf(x=matrix(rep(1.96,2), nrow=2, ncol=1),
      xi=c(0, 0), psi=c(1, 1), sigma=diag(2)
)

N=50000#00
Yn &lt;- rnorm(n=N, mean=0, sd=1)

Z &lt;- rtruncnorm(n=N, a=0, b=Inf, mean=0, sd=1)
eps &lt;- rnorm(n=N, mean=0, sd=1)
psi &lt;- 10
Ysn &lt;- psi*Z + eps

nu &lt;- 1.5
W &lt;- rgamma(n=N, shape=nu/2, rate=nu/2)
Yst=Ysn/sqrt(W)

library(reshape2)
library(ggplot2)
data2plot &lt;- melt(cbind.data.frame(Ysn, Yst))
#pdf(file="ExSNST.pdf", height=5, width=4)
p &lt;- (ggplot(data=data2plot)
     + geom_density(aes(x=value, fill=variable, alpha=variable), col="black")#, lwd=1.1)
     + theme_bw()
     + xlim(-15,100)
     + theme(legend.position="bottom")
     + scale_fill_manual(values=alpha(c("#F8766D", "#00B0F6"),c(0.2,0.45)),
                         name =" ",
                         labels=c("Y~SN(0,1,10)      ", "Y~ST(0,1,10,1.5)")
     )
     + scale_alpha_manual(guide=FALSE, values=c(0.25, 0.45))
     + xlab("Y")
     + ylim(0,0.08)
     + ylab("Density")
     + guides(fill = guide_legend(override.aes = list(colour = NULL)))
     + theme(legend.key = element_rect(colour = "black"))
)
p
#dev.off()


</code></pre>

<hr>
<h2 id='mvstlikC'>C++ implementation of multivariate skew t likelihood function for multiple inputs</h2><span id='topic+mvstlikC'></span>

<h3>Description</h3>

<p>C++ implementation of multivariate skew t likelihood function for multiple inputs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvstlikC(x, c, clustval, xi, psi, sigma, df, loglik = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvstlikC_+3A_x">x</code></td>
<td>
<p>data matrix of dimension p x n, p being the dimension of the
data and n the number of data points</p>
</td></tr>
<tr><td><code id="mvstlikC_+3A_c">c</code></td>
<td>
<p>integer vector of cluster allocations with values from 1 to K</p>
</td></tr>
<tr><td><code id="mvstlikC_+3A_clustval">clustval</code></td>
<td>
<p>vector of unique values from c in the order corresponding to
the storage of cluster parameters in <code>xi</code>, <code>psi</code>, and <code>sigma</code></p>
</td></tr>
<tr><td><code id="mvstlikC_+3A_xi">xi</code></td>
<td>
<p>mean vectors matrix of dimension p x K, K being the number of
clusters</p>
</td></tr>
<tr><td><code id="mvstlikC_+3A_psi">psi</code></td>
<td>
<p>skew parameter vectors matrix of dimension <code>p x K</code></p>
</td></tr>
<tr><td><code id="mvstlikC_+3A_sigma">sigma</code></td>
<td>
<p>list of length <code>K</code> of variance-covariance matrices,
each of dimensions <code>p x p</code>.</p>
</td></tr>
<tr><td><code id="mvstlikC_+3A_df">df</code></td>
<td>
<p>vector of length <code>K</code> of degree of freedom parameters.</p>
</td></tr>
<tr><td><code id="mvstlikC_+3A_loglik">loglik</code></td>
<td>
<p>logical flag or returning the log-likelihood instead of the likelihood.
Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list:
</p>
<table>
<tr><td><code>"indiv":</code></td>
<td>
<p> vector of likelihood of length n;</p>
</td></tr>
<tr><td><code>"clust":</code></td>
<td>
<p> vector of likelihood of length K;</p>
</td></tr>
<tr><td><code>"total":</code></td>
<td>
<p> total (log)-likelihood;</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boris Hejblum
</p>

<hr>
<h2 id='mvstpdf'>multivariate skew-t  probability density function</h2><span id='topic+mvstpdf'></span>

<h3>Description</h3>

<p>multivariate skew-t  probability density function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvstpdf(x, xi, sigma, psi, df, Log = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvstpdf_+3A_x">x</code></td>
<td>
<p><code>p x n</code> data matrix with <code>n</code> the number of observations and
<code>p</code> the number of dimensions</p>
</td></tr>
<tr><td><code id="mvstpdf_+3A_xi">xi</code></td>
<td>
<p>mean vector or list of mean vectors (either a vector,
a matrix or a list)</p>
</td></tr>
<tr><td><code id="mvstpdf_+3A_sigma">sigma</code></td>
<td>
<p>variance-covariance matrix or list of variance-covariance
matrices (either a matrix or a list)</p>
</td></tr>
<tr><td><code id="mvstpdf_+3A_psi">psi</code></td>
<td>
<p>skew parameter vector or list of skew parameter vectors
(either a vector, a matrix or a list)</p>
</td></tr>
<tr><td><code id="mvstpdf_+3A_df">df</code></td>
<td>
<p>a numeric vector or a list of the degrees of freedom
(either a vector or a list)</p>
</td></tr>
<tr><td><code id="mvstpdf_+3A_log">Log</code></td>
<td>
<p>logical flag for returning the log of the probability density
function. Defaults is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+mvtpdf">mvtpdf</a></code>, <code><a href="#topic+mvsnpdf">mvsnpdf</a></code>, <code><a href="#topic+mmvstpdfC">mmvstpdfC</a></code>, <code><a href="#topic+mvstlikC">mvstlikC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mvstpdf(x=matrix(rep(1.96,2), nrow=2, ncol=1),
      xi=c(0, 0), psi=c(1, 1), sigma=diag(2),
      df=100000000, Log=FALSE
)
mvsnpdf(x=matrix(rep(1.96,2), nrow=2, ncol=1),
      xi=c(0, 0), psi=c(1, 1), sigma=diag(2),
      Log=FALSE
)
mvstpdf(x=matrix(rep(1.96,2), nrow=2, ncol=1),
      xi=c(0, 0), psi=c(1, 1), sigma=diag(2),
      df=100000000
)
mvsnpdf(x=matrix(rep(1.96,2), nrow=2, ncol=1),
      xi=c(0, 0), psi=c(1, 1), sigma=diag(2)
)


</code></pre>

<hr>
<h2 id='mvtpdf'>multivariate Student's t-distribution probability density function</h2><span id='topic+mvtpdf'></span>

<h3>Description</h3>

<p>multivariate Student's t-distribution probability density function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvtpdf(x, mean, varcovM, df, Log = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvtpdf_+3A_x">x</code></td>
<td>
<p><code>p x n</code> data matrix with <code>n</code> the number of observations and
<code>p</code> the number of dimensions</p>
</td></tr>
<tr><td><code id="mvtpdf_+3A_mean">mean</code></td>
<td>
<p>mean vector or list of mean vectors (either a vector,
a matrix or a list)</p>
</td></tr>
<tr><td><code id="mvtpdf_+3A_varcovm">varcovM</code></td>
<td>
<p>variance-covariance matrix or list of variance-covariance
matrices (either a matrix or a list)</p>
</td></tr>
<tr><td><code id="mvtpdf_+3A_df">df</code></td>
<td>
<p>a numeric vector or a list of the degrees of freedom
(either a vector or a list)</p>
</td></tr>
<tr><td><code id="mvtpdf_+3A_log">Log</code></td>
<td>
<p>logical flag for returning the log of the probability density
function. Defaults is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>mvtpdf(x=matrix(1.96), mean=0, varcovM=diag(1), df=10000000)
mvnpdf(x=matrix(1.96), mean=0, varcovM=diag(1))

mvtpdf(x=matrix(1.96), mean=0, varcovM=diag(1), df=10)

mvtpdf(x=matrix(rep(1.96,2), nrow=2, ncol=1),
      mean=c(0, 0), varcovM=diag(2), df=10
)

</code></pre>

<hr>
<h2 id='NuMatParC'>C++ implementation of similarity matrix computation using pre-computed distances</h2><span id='topic+NuMatParC'></span>

<h3>Description</h3>

<p>C++ implementation of similarity matrix computation using pre-computed distances
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NuMatParC(c, d)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NuMatParC_+3A_c">c</code></td>
<td>
<p>an MCMC partitions of length <code>n</code>.</p>
</td></tr>
<tr><td><code id="NuMatParC_+3A_d">d</code></td>
<td>
<p>a symmetric <code>n x n</code> matrix containing distances
between each group distributions.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boris Hejblum, Chariff Alkhassim
</p>


<h3>Examples</h3>

<pre><code class='language-R'>c &lt;- c(1,1,2,3,2,3)
d &lt;- matrix(runif(length(c)^2),length(c))
NuMatParC(c,d)


</code></pre>

<hr>
<h2 id='plot_ConvDPM'>Convergence diagnostic plots</h2><span id='topic+plot_ConvDPM'></span>

<h3>Description</h3>

<p>Convergence diagnostic plots
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_ConvDPM(
  MCMCsample,
  from = 1,
  to = length(MCMCsample$logposterior_list),
  shift = 0,
  thin = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_ConvDPM_+3A_mcmcsample">MCMCsample</code></td>
<td>
<p>a <code>DPMMclust</code> or <code>summaryDPMMclust</code> object.</p>
</td></tr>
<tr><td><code id="plot_ConvDPM_+3A_from">from</code></td>
<td>
<p>the MCMC iteration from which the plot should start.
Default is <code>1</code>.</p>
</td></tr>
<tr><td><code id="plot_ConvDPM_+3A_to">to</code></td>
<td>
<p>the MCMC iteration up until which the plot should stop.
Default is <code>1</code>.</p>
</td></tr>
<tr><td><code id="plot_ConvDPM_+3A_shift">shift</code></td>
<td>
<p>a number of initial iterations not to be displayed. Default is <code>0</code>.</p>
</td></tr>
<tr><td><code id="plot_ConvDPM_+3A_thin">thin</code></td>
<td>
<p>integer giving the spacing at which MCMC iterations are kept.
Default is <code>1</code>, i.e. no thining.</p>
</td></tr>
<tr><td><code id="plot_ConvDPM_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods</p>
</td></tr>
</table>

<hr>
<h2 id='plot_DPM'>Plot of a Dirichlet process mixture of gaussian distribution partition</h2><span id='topic+plot_DPM'></span>

<h3>Description</h3>

<p>Plot of a Dirichlet process mixture of gaussian distribution partition
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_DPM(
  z,
  U_mu = NULL,
  U_Sigma = NULL,
  m,
  c,
  i,
  alpha = "?",
  U_SS = NULL,
  dims2plot = 1:nrow(z),
  ellipses = ifelse(length(dims2plot) &lt; 3, TRUE, FALSE),
  gg.add = list(theme())
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_DPM_+3A_z">z</code></td>
<td>
<p>data matrix <code>d x n</code> with <code>d</code> dimensions in rows
and <code>n</code> observations in columns.</p>
</td></tr>
<tr><td><code id="plot_DPM_+3A_u_mu">U_mu</code></td>
<td>
<p>either a list or a matrix containing the current estimates of mean vectors
of length <code>d</code> for each cluster. Default is <code>NULL</code> in which case
<code>U_SS</code> has to be provided.</p>
</td></tr>
<tr><td><code id="plot_DPM_+3A_u_sigma">U_Sigma</code></td>
<td>
<p>either a list or an array containing the <code>d x d</code> current estimates
for covariance matrix of each cluster. Default is <code>NULL</code> in which case
<code>U_SS</code> has to be provided.</p>
</td></tr>
<tr><td><code id="plot_DPM_+3A_m">m</code></td>
<td>
<p>vector of length <code>n</code> containing the number of observations currently assigned to
each clusters.</p>
</td></tr>
<tr><td><code id="plot_DPM_+3A_c">c</code></td>
<td>
<p>allocation vector of length <code>n</code> indicating which observation belongs to which
clusters.</p>
</td></tr>
<tr><td><code id="plot_DPM_+3A_i">i</code></td>
<td>
<p>current MCMC iteration number.</p>
</td></tr>
<tr><td><code id="plot_DPM_+3A_alpha">alpha</code></td>
<td>
<p>current value of the DP concentration parameter.</p>
</td></tr>
<tr><td><code id="plot_DPM_+3A_u_ss">U_SS</code></td>
<td>
<p>a list containing <code>"mu"</code> and <code>"S"</code>. Default is <code>NULL</code> in which case
<code>U_mu</code> and <code>U_Sigma</code> have to be provided.</p>
</td></tr>
<tr><td><code id="plot_DPM_+3A_dims2plot">dims2plot</code></td>
<td>
<p>index vector, subset of <code>1:d</code> indicating which dimensions should be drawn.
Default is all of them.</p>
</td></tr>
<tr><td><code id="plot_DPM_+3A_ellipses">ellipses</code></td>
<td>
<p>a logical flag indicating whether ellipses should be drawn around clusters. Default
is <code>TRUE</code> if only 2 dimensions are plotted, <code>FALSE</code> otherwise.</p>
</td></tr>
<tr><td><code id="plot_DPM_+3A_gg.add">gg.add</code></td>
<td>
<p>a list of instructions to add to the <code>ggplot2</code> instruction (see 
<code><a href="ggplot2.html#topic+gg-add">gg-add</a></code>). Default is <code>list(theme())</code>, which adds 
nothing to the plot.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boris Hejblum
</p>

<hr>
<h2 id='plot_DPMsn'>Plot of a Dirichlet process mixture of skew normal distribution partition</h2><span id='topic+plot_DPMsn'></span>

<h3>Description</h3>

<p>Plot of a Dirichlet process mixture of skew normal distribution partition
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_DPMsn(
  z,
  c,
  i = "",
  alpha = "?",
  U_SS,
  dims2plot = 1:nrow(z),
  ellipses = ifelse(length(dims2plot) &lt; 3, TRUE, FALSE),
  gg.add = list(theme()),
  nbsim_dens = 1000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_DPMsn_+3A_z">z</code></td>
<td>
<p>data matrix <code>d x n</code> with <code>d</code> dimensions in rows
and <code>n</code> observations in columns.</p>
</td></tr>
<tr><td><code id="plot_DPMsn_+3A_c">c</code></td>
<td>
<p>allocation vector of length <code>n</code> indicating which observation belongs to which
clusters.</p>
</td></tr>
<tr><td><code id="plot_DPMsn_+3A_i">i</code></td>
<td>
<p>current MCMC iteration number.</p>
</td></tr>
<tr><td><code id="plot_DPMsn_+3A_alpha">alpha</code></td>
<td>
<p>current value of the DP concentration parameter.</p>
</td></tr>
<tr><td><code id="plot_DPMsn_+3A_u_ss">U_SS</code></td>
<td>
<p>a list containing <code>"xi"</code>, <code>"psi"</code>, <code>"S"</code>, and <code>"df"</code>.</p>
</td></tr>
<tr><td><code id="plot_DPMsn_+3A_dims2plot">dims2plot</code></td>
<td>
<p>index vector, subset of <code>1:d</code> indicating which dimensions should be drawn.
Default is all of them.</p>
</td></tr>
<tr><td><code id="plot_DPMsn_+3A_ellipses">ellipses</code></td>
<td>
<p>a logical flag indicating whether ellipses should be drawn around clusters. Default
is <code>TRUE</code> if only 2 dimensions are plotted, <code>FALSE</code> otherwise.</p>
</td></tr>
<tr><td><code id="plot_DPMsn_+3A_gg.add">gg.add</code></td>
<td>
<p>A list of instructions to add to the <code>ggplot2</code> instruction (see <code><a href="ggplot2.html#topic+gg-add">gg-add</a></code>).
Default is <code>list(theme())</code>, which adds nothing to the plot.</p>
</td></tr>
<tr><td><code id="plot_DPMsn_+3A_nbsim_dens">nbsim_dens</code></td>
<td>
<p>number of simulated points used for computing clusters density contours in 2D
plots. Default is <code>1000</code> points.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boris Hejblum
</p>

<hr>
<h2 id='plot_DPMst'>Plot of a Dirichlet process mixture of skew t-distribution partition</h2><span id='topic+plot_DPMst'></span>

<h3>Description</h3>

<p>Plot of a Dirichlet process mixture of skew t-distribution partition
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_DPMst(
  z,
  c,
  i = "",
  alpha = "?",
  U_SS,
  dims2plot = 1:nrow(z),
  ellipses = ifelse(length(dims2plot) &lt; 3, TRUE, FALSE),
  gg.add = list(theme()),
  nbsim_dens = 1000,
  nice = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_DPMst_+3A_z">z</code></td>
<td>
<p>data matrix <code>d x n</code> with <code>d</code> dimensions in rows
and <code>n</code> observations in columns.</p>
</td></tr>
<tr><td><code id="plot_DPMst_+3A_c">c</code></td>
<td>
<p>allocation vector of length <code>n</code> indicating which observation belongs to which
clusters.</p>
</td></tr>
<tr><td><code id="plot_DPMst_+3A_i">i</code></td>
<td>
<p>current MCMC iteration number.</p>
</td></tr>
<tr><td><code id="plot_DPMst_+3A_alpha">alpha</code></td>
<td>
<p>current value of the DP concentration parameter.</p>
</td></tr>
<tr><td><code id="plot_DPMst_+3A_u_ss">U_SS</code></td>
<td>
<p>a list containing <code>"xi"</code>, <code>"psi"</code>, <code>"S"</code>, and <code>"df"</code>.</p>
</td></tr>
<tr><td><code id="plot_DPMst_+3A_dims2plot">dims2plot</code></td>
<td>
<p>index vector, subset of <code>1:d</code> indicating which dimensions should be drawn.
Default is all of them.</p>
</td></tr>
<tr><td><code id="plot_DPMst_+3A_ellipses">ellipses</code></td>
<td>
<p>a logical flag indicating whether ellipses should be drawn around clusters. Default
is <code>TRUE</code> if only 2 dimensions are plotted, <code>FALSE</code> otherwise.</p>
</td></tr>
<tr><td><code id="plot_DPMst_+3A_gg.add">gg.add</code></td>
<td>
<p>A list of instructions to add to the <code>ggplot2</code> instruction (see <code><a href="ggplot2.html#topic+gg-add">gg-add</a></code>).
Default is <code>list(theme())</code>, which adds nothing to the plot.</p>
</td></tr>
<tr><td><code id="plot_DPMst_+3A_nbsim_dens">nbsim_dens</code></td>
<td>
<p>number of simulated points used for computing clusters density contours in 2D
plots. Default is <code>1000</code> points.</p>
</td></tr>
<tr><td><code id="plot_DPMst_+3A_nice">nice</code></td>
<td>
<p>logical flag changing the plot looks. Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boris Hejblum
</p>

<hr>
<h2 id='postProcess.DPMMclust'>Post-processing Dirichlet Process Mixture Models results to get
a mixture distribution of the posterior locations</h2><span id='topic+postProcess.DPMMclust'></span>

<h3>Description</h3>

<p>Post-processing Dirichlet Process Mixture Models results to get
a mixture distribution of the posterior locations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>postProcess.DPMMclust(
  x,
  burnin = 0,
  thin = 1,
  gs = NULL,
  lossFn = "F-measure",
  K = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="postProcess.DPMMclust_+3A_x">x</code></td>
<td>
<p>a <code>DPMMclust</code> object.</p>
</td></tr>
<tr><td><code id="postProcess.DPMMclust_+3A_burnin">burnin</code></td>
<td>
<p>integer giving the number of MCMC iterations to burn (defaults is half)</p>
</td></tr>
<tr><td><code id="postProcess.DPMMclust_+3A_thin">thin</code></td>
<td>
<p>integer giving the spacing at which MCMC iterations are kept.
Default is <code>1</code>, i.e. no thining.</p>
</td></tr>
<tr><td><code id="postProcess.DPMMclust_+3A_gs">gs</code></td>
<td>
<p>optional vector of length <code>n</code> containing the gold standard
partition of the <code>n</code> observations to compare to the point estimate.</p>
</td></tr>
<tr><td><code id="postProcess.DPMMclust_+3A_lossfn">lossFn</code></td>
<td>
<p>character string specifying the loss function to be used.
Either &quot;F-measure&quot; or &quot;Binder&quot; (see Details). Default is &quot;F-measure&quot;.</p>
</td></tr>
<tr><td><code id="postProcess.DPMMclust_+3A_k">K</code></td>
<td>
<p>integer giving the number of mixture components. Default is <code>10</code>.</p>
</td></tr>
<tr><td><code id="postProcess.DPMMclust_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The cost of a point estimate partition is calculated using either a pairwise
coincidence loss function (Binder), or 1-Fmeasure (F-measure).
</p>


<h3>Value</h3>

<p>a <code>list</code>:
</p>
<table>
<tr><td><code>burnin:</code></td>
<td>
<p>an integer passing along the <code>burnin</code> argument</p>
</td></tr>
<tr><td><code>thin:</code></td>
<td>
<p>an integer passing along the <code>thin</code> argument</p>
</td></tr>
<tr><td><code>lossFn:</code></td>
<td>
<p>a character string passing along the <code>lossFn</code> argument</p>
</td></tr>
<tr><td><code>point_estim:</code></td>
<td>
</td></tr>
<tr><td><code>loss:</code></td>
<td>
</td></tr>
<tr><td><code>index_estim:</code></td>
<td>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boris Hejblum
</p>


<h3>See Also</h3>

<p><code><a href="#topic+similarityMat">similarityMat</a></code> <code><a href="#topic+summary.DPMMclust">summary.DPMMclust</a></code>
</p>

<hr>
<h2 id='print.summaryDPMMclust'>Methods for a summary of a <code>DPMMclust</code> object</h2><span id='topic+print.summaryDPMMclust'></span><span id='topic+summaryDPMMclust'></span><span id='topic+plot.summaryDPMMclust'></span>

<h3>Description</h3>

<p>Methods for a summary of a <code>DPMMclust</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summaryDPMMclust'
print(x, ...)

## S3 method for class 'summaryDPMMclust'
plot(
  x,
  hm = FALSE,
  nbsim_densities = 5000,
  hm_subsample = NULL,
  hm_order_by_clust = TRUE,
  gg.add = list(theme_bw()),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summaryDPMMclust_+3A_x">x</code></td>
<td>
<p>a <code>summaryDPMMclust</code> object.</p>
</td></tr>
<tr><td><code id="print.summaryDPMMclust_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods</p>
</td></tr>
<tr><td><code id="print.summaryDPMMclust_+3A_hm">hm</code></td>
<td>
<p>logical flag to plot the heatmap of the similarity matrix.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="print.summaryDPMMclust_+3A_nbsim_densities">nbsim_densities</code></td>
<td>
<p>the number of simulated observations to be used
to plot the density lines of the clusters in the point estimate partition plot</p>
</td></tr>
<tr><td><code id="print.summaryDPMMclust_+3A_hm_subsample">hm_subsample</code></td>
<td>
<p>a integer designating the number of observations to use when plotting the heatmap. 
Used only if <code>hm</code> is <code>TRUE</code>. #'Default is <code>NULL</code> in which no subsampling is done and 
all observations are plotted.</p>
</td></tr>
<tr><td><code id="print.summaryDPMMclust_+3A_hm_order_by_clust">hm_order_by_clust</code></td>
<td>
<p>logical flag indicating whether observations should be ordered according to
the point estimate first. Used only if <code>hm</code> is <code>TRUE</code>. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="print.summaryDPMMclust_+3A_gg.add">gg.add</code></td>
<td>
<p>a list of instructions to add to the <code>ggplot2</code> instruction (see 
<code><a href="ggplot2.html#topic+gg-add">gg-add</a></code>). Default is <code>list(theme())</code>, which adds nothing to the plot.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boris Hejblum
</p>

<hr>
<h2 id='priormix'>Construction of an Empirical based prior</h2><span id='topic+priormix'></span>

<h3>Description</h3>

<p>Construction of an Empirical based prior
</p>


<h3>Usage</h3>

<pre><code class='language-R'>priormix(sDPMclust, nu0add = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="priormix_+3A_sdpmclust">sDPMclust</code></td>
<td>
<p>an object of class <code>summary.DPMMclust</code></p>
</td></tr>
<tr><td><code id="priormix_+3A_nu0add">nu0add</code></td>
<td>
<p>an additional value integer added to hyperprior parameter nu
(increase to avoid non positive definite matrix sampling)</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code>summary.DPMMclust</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rm(list=ls())

#Number of data
n &lt;- 2000
set.seed(123)
#set.seed(4321)


d &lt;- 2
ncl &lt;- 4

# Sample data

sdev &lt;- array(dim=c(d,d,ncl))

xi &lt;- matrix(nrow=d, ncol=ncl, c(-1.5, 1.5, 1.5, 1.5, 2, -2.5, -2.5, -3))
#xi &lt;- matrix(nrow=d, ncol=ncl, c(-0.5, 0, 0.5, 0, 0.5, -1, -1, 1))
psi &lt;- matrix(nrow=d, ncol=4, c(0.4, -0.6, 0.8, 0, 0.3, -0.7, -0.3, -0.8))
nu &lt;- c(100,15,8,5)
p &lt;- c(0.15, 0.05, 0.5, 0.3) # frequence des clusters
sdev[, ,1] &lt;- matrix(nrow=d, ncol=d, c(0.3, 0, 0, 0.3))
sdev[, ,2] &lt;- matrix(nrow=d, ncol=d, c(0.1, 0, 0, 0.3))
sdev[, ,3] &lt;- matrix(nrow=d, ncol=d, c(0.3, 0.15, 0.15, 0.3))
sdev[, ,4] &lt;- .3*diag(2)


c &lt;- rep(0,n)
w &lt;- rep(1,n)
z &lt;- matrix(0, nrow=d, ncol=n)
for(k in 1:n){
 c[k] = which(rmultinom(n=1, size=1, prob=p)!=0)
 w[k] &lt;- rgamma(1, shape=nu[c[k]]/2, rate=nu[c[k]]/2)
 z[,k] &lt;- xi[, c[k]] + psi[, c[k]]*rtruncnorm(n=1, a=0, b=Inf, mean=0, sd=1/sqrt(w[k])) +
                (sdev[, , c[k]]/sqrt(w[k]))%*%matrix(rnorm(d, mean = 0, sd = 1), nrow=d, ncol=1)
 #cat(k, "/", n, " observations simulated\n", sep="")
}

# Set parameters of G0
hyperG0 &lt;- list()
hyperG0[["b_xi"]] &lt;- rowMeans(z)
hyperG0[["b_psi"]] &lt;- rep(0,d)
hyperG0[["kappa"]] &lt;- 0.001
hyperG0[["D_xi"]] &lt;- 100
hyperG0[["D_psi"]] &lt;- 100
hyperG0[["nu"]] &lt;- d+1
hyperG0[["lambda"]] &lt;- diag(apply(z,MARGIN=1, FUN=var))/3

 # hyperprior on the Scale parameter of DPM
 a &lt;- 0.0001
 b &lt;- 0.0001

 nbclust_init &lt;- 30

if(interactive()){
 MCMCsample_st &lt;- DPMGibbsSkewT(z, hyperG0, a, b, N=2000, doPlot=FALSE,
                                nbclust_init, diagVar=FALSE)
 s &lt;- summary(MCMCsample_st, burnin = 1500, thin=5, posterior_approx=TRUE)
 pmix &lt;- priormix(s)
}

</code></pre>

<hr>
<h2 id='rCRP'>Generating cluster data from the Chinese Restaurant Process</h2><span id='topic+rCRP'></span>

<h3>Description</h3>

<p>Generating cluster data from the Chinese Restaurant Process
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rCRP(n = 1000, alpha = 2, hyperG0, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rCRP_+3A_n">n</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code id="rCRP_+3A_alpha">alpha</code></td>
<td>
<p>concentration parameter</p>
</td></tr>
<tr><td><code id="rCRP_+3A_hyperg0">hyperG0</code></td>
<td>
<p>base distribution hyperparameter</p>
</td></tr>
<tr><td><code id="rCRP_+3A_verbose">verbose</code></td>
<td>
<p>logical flag indicating whether info is written in the console.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
rm(list=ls())

d=2
hyperG0 &lt;- list()
hyperG0[["NNiW"]] &lt;- list()
hyperG0[["NNiW"]][["b_xi"]] &lt;- rep(0,d)
hyperG0[["NNiW"]][["b_psi"]] &lt;- rep(0,d)
hyperG0[["NNiW"]][["D_xi"]] &lt;- 100
hyperG0[["NNiW"]][["D_psi"]] &lt;- 8
hyperG0[["NNiW"]][["nu"]] &lt;- d+1
hyperG0[["NNiW"]][["lambda"]] &lt;- diag(c(1,1))

hyperG0[["scale"]] &lt;- list()

set.seed(4321)
N &lt;- 200
alph &lt;- runif(n=1,0.2,2)
GvHD_sims &lt;- rCRP(n=2*N, alpha=alph, hyperG0=hyperG0)
library(ggplot2)
q &lt;- (ggplot(data=cbind.data.frame("D1"=GvHD_sims$data[1,],
                                  "D2"=GvHD_sims$data[2,],
                                  "Cluster"=GvHD_sims$cluster),
             aes(x=D1, y=D2))
      + geom_point(aes(colour=Cluster), alpha=0.6)
      + theme_bw()
      )
q
#q + stat_density2d(alpha=0.15, geom="polygon")

if(interactive()){
MCMCy1 &lt;- DPMGibbsSkewT(z=GvHD_sims$data[,1:N],
                        hyperG0$NNiW, a=0.0001, b=0.0001, N=5000,
                        doPlot=TRUE, nbclust_init=64, plotevery=500,
                        gg.add=list(theme_bw()), diagVar=FALSE)
 s1 &lt;- summary(MCMCy1, burnin=4000, thin=5,
               posterior_approx=TRUE)
 F1 &lt;- FmeasureC(ref=GvHD_sims$cluster[1:N], pred=s1$point_estim$c_est)

 # s &lt;- summary(MCMCy1, burnin=4000, thin=5,
 #               posterior_approx=TRUE, K=1)
 # s2 &lt;- summary(MCMCy1, burnin=4000, thin=5,
 #               posterior_approx=TRUE, K=2)
 # MCMCy2_seqPost&lt;- DPMGibbsSkewT(z=GvHD_sims$data[,(N+1):(2*N)],
 #                                  hyperG0=s1$param_post$parameters,
 #                                  a=s1$param_post$alpha_param$shape,
 #                                  b=s1$param_post$alpha_param$rate,
 #                                  N=5000, doPlot=TRUE, nbclust_init=64, plotevery=500,
 #                                  gg.add=list(theme_bw()), diagVar=FALSE)

 MCMCy2_seqPost &lt;- DPMGibbsSkewT_SeqPrior(z=GvHD_sims$data[,(N+1):(2*N)],
                                           prior=s1$param_post, hyperG0=hyperG0$NNiW, , N=1000,
                                           doPlot=TRUE, nbclust_init=10, plotevery=100,
                                           gg.add=list(theme_bw()), diagVar=FALSE)
 s2_seqPost &lt;- summary(MCMCy2_seqPost, burnin=600, thin=2)
 F2_seqPost &lt;- FmeasureC(ref=GvHD_sims$cluster[(N+1):(2*N)], pred=s2_seqPost$point_estim$c_est)

 MCMCy2 &lt;- DPMGibbsSkewT(z=GvHD_sims$data[,(N+1):(2*N)],
                         hyperG0$NNiW, a=0.0001, b=0.0001, N=5000,
                         doPlot=TRUE, nbclust_init=64, plotevery=500,
                         gg.add=list(theme_bw()), diagVar=FALSE)
 s2 &lt;- summary(MCMCy2, burnin=4000, thin=5)
 F2 &lt;- FmeasureC(ref=GvHD_sims$cluster[(N+1):(2*N)], pred=s2$point_estim$c_est)

 MCMCtot &lt;- DPMGibbsSkewT(z=GvHD_sims$data,
                          hyperG0$NNiW, a=0.0001, b=0.0001, N=5000,
                          doPlot=TRUE, nbclust_init=10, plotevery=500,
                          gg.add=list(theme_bw()), diagVar=FALSE)
 stot &lt;- summary(MCMCtot, burnin=4000, thin=5)
 F2tot &lt;- FmeasureC(ref=GvHD_sims$cluster[(N+1):(2*N)], pred=stot$point_estim$c_est[(N+1):(2*N)])

 c(F1, F2, F2_seqPost, F2tot)
}

</code></pre>

<hr>
<h2 id='rNiW'>Sample from a Normal inverse-Wishart distribution
whose parameter are given by the structure hyper</h2><span id='topic+rNiW'></span>

<h3>Description</h3>

<p>For internal use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rNiW(hyper, diagVar)
</code></pre>

<hr>
<h2 id='rNNiW'>Sample from a normal inverse Wishart distribution
whose parameter are given by the structure <code>SufStat</code></h2><span id='topic+rNNiW'></span>

<h3>Description</h3>

<p>For internal use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rNNiW(SufStat, diagVar)
</code></pre>

<hr>
<h2 id='sample_alpha'>Sampler for the concentration parameter of a Dirichlet process</h2><span id='topic+sample_alpha'></span>

<h3>Description</h3>

<p>Sampler updating the concentration parameter of a Dirichlet process given
the number of observations and a Gamma(<code>a</code>, <code>b</code>) prior, following the augmentation
strategy of West, and of Escobar and West.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_alpha(alpha_old, n, K, a = 1e-04, b = 1e-04)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_alpha_+3A_alpha_old">alpha_old</code></td>
<td>
<p>the current value of alpha</p>
</td></tr>
<tr><td><code id="sample_alpha_+3A_n">n</code></td>
<td>
<p>the number of data points</p>
</td></tr>
<tr><td><code id="sample_alpha_+3A_k">K</code></td>
<td>
<p>current number of cluster</p>
</td></tr>
<tr><td><code id="sample_alpha_+3A_a">a</code></td>
<td>
<p>shape hyperparameter of the Gamma prior
on the concentration parameter of the Dirichlet Process.
Default is <code>0.0001</code>.</p>
</td></tr>
<tr><td><code id="sample_alpha_+3A_b">b</code></td>
<td>
<p>scale hyperparameter of the Gamma prior
on the concentration parameter of the Dirichlet Process.
Default is <code>0.0001</code>. If <code>0</code> then the concentration is fixed and this function
returns <code>a</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A Gamma prior is used.
</p>


<h3>References</h3>

<p>M West, Hyperparameter estimation in Dirichlet process mixture models,
Technical Report, Duke University, 1992.
</p>
<p>MD Escobar, M West, Bayesian Density Estimation and Inference Using Mixtures
<em>Journal of the American Statistical Association</em>, 90(430):577-588, 1995.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Test with a fixed K
####################

alpha_init &lt;- 1000
N &lt;- 10000
#n=500
n=10000
K &lt;- 80
a &lt;- 0.0001
b &lt;- a
alphas &lt;- numeric(N)
alphas[1] &lt;- alpha_init
for (i in 2:N){
 alphas[i] &lt;- sample_alpha(alpha_old = alphas[i-1], n=n, K=K, a=a, b=b)
}

postalphas &lt;- alphas[floor(N/2):N]
alphaMMSE &lt;- mean(postalphas)
alphaMAP &lt;- density(postalphas)$x[which.max(density(postalphas)$y)]

expK &lt;- sum(alphaMMSE/(alphaMMSE+0:(n-1)))
round(expK)


 prioralpha &lt;- data.frame("alpha"=rgamma(n=5000, a,1/b),
                         "distribution" =factor(rep("prior",5000),
                         levels=c("prior", "posterior")))

 library(ggplot2)
 p &lt;- (ggplot(prioralpha, aes(x=alpha))
       + geom_histogram(aes(y=..density..),
                        colour="black", fill="white")
       + geom_density(alpha=.2, fill="red")
       + ggtitle(paste("Prior distribution on alpha: Gamma(", a,
                 ",", b, ")\n", sep=""))
      )
 p

postalpha.df &lt;- data.frame("alpha"=postalphas,
                         "distribution" = factor(rep("posterior",length(postalphas)),
                         levels=c("prior", "posterior")))
 p &lt;- (ggplot(postalpha.df, aes(x=alpha))
       + geom_histogram(aes(y=..density..), binwidth=.1,
                        colour="black", fill="white")
       + geom_density(alpha=.2, fill="blue")
       + ggtitle("Posterior distribution of alpha\n")
       # Ignore NA values for mean
       # Overlay with transparent density plot
       + geom_vline(aes(xintercept=mean(alpha, na.rm=TRUE)),
                    color="red", linetype="dashed", size=1)
     )
 p






</code></pre>

<hr>
<h2 id='sampleClassC'>C++ implementation of the multinomial sampling from a matrix
of column vectors, each containing the sampling probabilities
for their respective draw</h2><span id='topic+sampleClassC'></span>

<h3>Description</h3>

<p>C++ implementation of the multinomial sampling from a matrix
of column vectors, each containing the sampling probabilities
for their respective draw
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleClassC(probMat, Log = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleClassC_+3A_probmat">probMat</code></td>
<td>
<p>a numeric matrix of dim <code>k x n</code> of containing column vectors of sampling
probabilities for each class <code>k</code>.</p>
</td></tr>
<tr><td><code id="sampleClassC_+3A_log">Log</code></td>
<td>
<p>a logical flag indicating whether the provided <code>probMat</code> is on the log scale
or natural probability scale. Default is <code>FALSE</code> in which case it is considered on the natural
probability scale.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of integer of length <code>n</code> containing the multinomial draws for each
observation, i.e. the class allocation.
</p>

<hr>
<h2 id='similarityMat'>Computes the co-clustering (or similarity) matrix</h2><span id='topic+similarityMat'></span>

<h3>Description</h3>

<p>Computes the co-clustering (or similarity) matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>similarityMat(c, step = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="similarityMat_+3A_c">c</code></td>
<td>
<p>a list of vector of length <code>n</code>. <code>c[[j]][i]</code> is 
the cluster allocation of observation <code>i=1...n</code> at iteration 
<code>j=1...N</code>.</p>
</td></tr>
<tr><td><code id="similarityMat_+3A_step">step</code></td>
<td>
<p>provide co-clustering every <code>step</code> iterations.
Default is 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of size <code>n x n</code> whose term <code>[i,j]</code> 
is the proportion of MCMC iterations where observation <code>i</code> and 
observations <code>j</code> are allocated to the same cluster.
</p>


<h3>Author(s)</h3>

<p>Boris Hejblum
</p>

<hr>
<h2 id='similarityMat_nocostC'>C++ implementation</h2><span id='topic+similarityMat_nocostC'></span>

<h3>Description</h3>

<p>C++ implementation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>similarityMat_nocostC(cc)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="similarityMat_nocostC_+3A_cc">cc</code></td>
<td>
<p>a matrix whose columns each represents a ()MCMC) partition</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>c &lt;- list(c(1,1,2,3,2,3), c(1,1,1,2,3,3),c(2,2,1,1,1,1))
similarityMat_nocostC(sapply(c, "["))

c2 &lt;- list()
for(i in 1:10){
    c2 &lt;- c(c2, list(rmultinom(n=1, size=1000, prob=rexp(n=1000))))
}

c3 &lt;- sapply(c2, "[")

if(require(microbenchmark)){
library(microbenchmark)
microbenchmark(similarityMat(c3), similarityMat_nocostC(c3), times=2L)
}else{
cat("package 'microbenchmark' not available\n")
}
</code></pre>

<hr>
<h2 id='similarityMatC'>C++ implementation</h2><span id='topic+similarityMatC'></span>

<h3>Description</h3>

<p>C++ implementation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>similarityMatC(cc)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="similarityMatC_+3A_cc">cc</code></td>
<td>
<p>a matrix whose columns each represents a (MCMC) partition</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>c &lt;- list(c(1,1,2,3,2,3), c(1,1,1,2,3,3),c(2,2,1,1,1,1))
similarityMatC(sapply(c, "["))

c2 &lt;- list()
for(i in 1:10){
    c2 &lt;- c(c2, list(rmultinom(n=1, size=200, prob=rexp(n=200))))
}
similarityMatC(sapply(c2, "["))

</code></pre>

<hr>
<h2 id='summary.DPMMclust'>Summarizing Dirichlet Process Mixture Models</h2><span id='topic+summary.DPMMclust'></span>

<h3>Description</h3>

<p>Summary methods for <code>DPMMclust</code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'DPMMclust'
summary(
  object,
  burnin = 0,
  thin = 1,
  gs = NULL,
  lossFn = "Binder",
  posterior_approx = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.DPMMclust_+3A_object">object</code></td>
<td>
<p>a <code>DPMMclust</code> object.</p>
</td></tr>
<tr><td><code id="summary.DPMMclust_+3A_burnin">burnin</code></td>
<td>
<p>integer giving the number of MCMC iterations to burn (defaults is half)</p>
</td></tr>
<tr><td><code id="summary.DPMMclust_+3A_thin">thin</code></td>
<td>
<p>integer giving the spacing at which MCMC iterations are kept.
Default is <code>1</code>, i.e. no thining.</p>
</td></tr>
<tr><td><code id="summary.DPMMclust_+3A_gs">gs</code></td>
<td>
<p>optional vector of length <code>n</code> containing the gold standard
partition of the <code>n</code> observations to compare to the point estimate</p>
</td></tr>
<tr><td><code id="summary.DPMMclust_+3A_lossfn">lossFn</code></td>
<td>
<p>character string specifying the loss function to be used.
Either &quot;F-measure&quot; or &quot;Binder&quot; (see Details). Default is &quot;Binder&quot;.</p>
</td></tr>
<tr><td><code id="summary.DPMMclust_+3A_posterior_approx">posterior_approx</code></td>
<td>
<p>logical flag whether a parametric approximation of the posterior should be
computed. Default is <code>FALSE</code></p>
</td></tr>
<tr><td><code id="summary.DPMMclust_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The cost of a point estimate partition is calculated using either a pairwise
coincidence loss function (Binder), or 1-Fmeasure (F-measure).
</p>
<p>The number of retained sampled partitions is <code>m = (N - burnin)/thin</code>
</p>


<h3>Value</h3>

<p>a <code>list</code> containing the following elements:
</p>

<dl>
<dt><code>nb_mcmcit</code>:</dt><dd><p> an integer giving the value of <code>m</code>, the number of retained 
sampled partitions, i.e. <code>(N - burnin)/thin</code></p>
</dd>
<dt><code>burnin</code>:</dt><dd><p> an integer passing along the <code>burnin</code> argument</p>
</dd>
<dt><code>thin</code>:</dt><dd><p> an integer passing along the <code>thin</code> argument</p>
</dd>
<dt><code>lossFn</code>:</dt><dd><p> a character string passing along the <code>lossFn</code> argument</p>
</dd>
<dt><code>clust_distrib</code>:</dt><dd><p> a character string passing along the <code>clust_distrib</code> argument </p>
</dd>
<dt><code>point_estim</code>:</dt><dd><p> a <code>list</code> containing: </p>

<dl>
<dt><code>c_est</code>:</dt><dd><p> a vector of length <code>n</code>containing the point estimated clustering for each observations</p>
</dd>
<dt><code>cost</code>:</dt><dd><p> a vector of length <code>m</code> containing the cost of each sampled partition</p>
</dd>
<dt><code>Fmeas</code>:</dt><dd><p> if <code>lossFn</code> is <code>'F-measure'</code>, the <code>m x m</code> matrix of total F-measures for each pair of sampled partitions</p>
</dd>
<dt><code>opt_ind</code>:</dt><dd><p> the index of the point estimate partition among the <code>m</code> sampled</p>
</dd>
</dl>
</dd>
<dt><code>loss</code>:</dt><dd><p> the loss for the point estimate. <code>NA</code> if <code>lossFn</code> is not <code>'Binder'</code></p>
</dd>
<dt><code>param_posterior</code>:</dt><dd><p> a list containing the parametric approximation of the posterior,
suitable to be plugged in as prior for a new MCMC algorithm run</p>
</dd>
<dt><code>mcmc_partitions</code>:</dt><dd><p> a list containing the <code>m</code> sampled partitions</p>
</dd>
<dt><code>alpha</code>:</dt><dd><p> a vector of length <code>m</code> with the values of the <code>alpha</code> DP parameter</p>
</dd>
<dt><code>index_estim</code>:</dt><dd><p> the index of the point estimate partition among the <code>m</code> sampled</p>
</dd>
<dt><code>hyperG0</code>:</dt><dd><p> a list passing along the prior, i.e. the <code>hyperG0</code> argument</p>
</dd>
<dt><code>logposterior_list</code>:</dt><dd><p> a list of length <code>m</code> containing the logposterior and its decomposition, for each sampled partition</p>
</dd>
<dt><code>U_SS_list</code>:</dt><dd><p> a list of length <code>m</code> containing the containing the lists of sufficient statistics for all the mixture components,
for each sampled partition</p>
</dd>
<dt><code>data</code>:</dt><dd><p> a <code>d x n</code> matrix containing the clustered data</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Boris Hejblum
</p>


<h3>See Also</h3>

<p><code><a href="#topic+similarityMat">similarityMat</a></code> <code><a href="#topic+similarityMatC">similarityMatC</a></code>
</p>

<hr>
<h2 id='traceEpsC'>C++ implementation of residual trace computation step used when sampling the scale</h2><span id='topic+traceEpsC'></span>

<h3>Description</h3>

<p>C++ implementation of residual trace computation step used when sampling the scale
</p>


<h3>Usage</h3>

<pre><code class='language-R'>traceEpsC(eps, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="traceEpsC_+3A_eps">eps</code></td>
<td>
<p>a numeric matrix where each column contains the centered and unskewed observations</p>
</td></tr>
<tr><td><code id="traceEpsC_+3A_sigma">sigma</code></td>
<td>
<p>a numeric covariance matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the computed trace
</p>

<hr>
<h2 id='update_SS'>Return updated sufficient statistics S with new data matrix z</h2><span id='topic+update_SS'></span>

<h3>Description</h3>

<p>For internal use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_SS(z, S, hyperprior = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="update_SS_+3A_z">z</code></td>
<td>
<p>data matrix</p>
</td></tr>
<tr><td><code id="update_SS_+3A_s">S</code></td>
<td>
<p>previous sufficient statistics</p>
</td></tr>
<tr><td><code id="update_SS_+3A_hyperprior">hyperprior</code></td>
<td>
<p>Default is <code>NULL</code></p>
</td></tr>
</table>

<hr>
<h2 id='update_SSsn'>Return updated sufficient statistics S with new data matrix z</h2><span id='topic+update_SSsn'></span>

<h3>Description</h3>

<p>For internal use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_SSsn(z, S, ltn, hyperprior = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="update_SSsn_+3A_z">z</code></td>
<td>
<p>data matrix</p>
</td></tr>
<tr><td><code id="update_SSsn_+3A_s">S</code></td>
<td>
<p>previous sufficient statistics</p>
</td></tr>
<tr><td><code id="update_SSsn_+3A_ltn">ltn</code></td>
<td>
<p>random effects</p>
</td></tr>
<tr><td><code id="update_SSsn_+3A_hyperprior">hyperprior</code></td>
<td>
<p>Default is <code>NULL</code></p>
</td></tr>
</table>

<hr>
<h2 id='update_SSst'>Return updated sufficient statistics S for skew t-distribution
with data matrix z</h2><span id='topic+update_SSst'></span>

<h3>Description</h3>

<p>For internal use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_SSst(z, S, ltn, scale, df, hyperprior = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="update_SSst_+3A_z">z</code></td>
<td>
<p>data matrix</p>
</td></tr>
<tr><td><code id="update_SSst_+3A_s">S</code></td>
<td>
<p>previous sufficient statistics</p>
</td></tr>
<tr><td><code id="update_SSst_+3A_ltn">ltn</code></td>
<td>
<p>random effects</p>
</td></tr>
<tr><td><code id="update_SSst_+3A_scale">scale</code></td>
<td>
</td></tr>
<tr><td><code id="update_SSst_+3A_df">df</code></td>
<td>
<p>skew t degrees of freedom</p>
</td></tr>
<tr><td><code id="update_SSst_+3A_hyperprior">hyperprior</code></td>
<td>
<p>Default is <code>NULL</code></p>
</td></tr>
</table>

<hr>
<h2 id='vclust2mcoclustC'>C++ implementation</h2><span id='topic+vclust2mcoclustC'></span>

<h3>Description</h3>

<p>C++ implementation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vclust2mcoclustC(c)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vclust2mcoclustC_+3A_c">c</code></td>
<td>
<p>is an MCMC partition</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Chariff Alkhassim
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cc &lt;- c(1,1,2,3,2,3)
vclust2mcoclustC(cc)


</code></pre>

<hr>
<h2 id='wishrnd'>Sample from a Wishart distribution</h2><span id='topic+wishrnd'></span>

<h3>Description</h3>

<p>For internal use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wishrnd(n, Sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wishrnd_+3A_n">n</code></td>
<td>
<p>degrees of freedom</p>
</td></tr>
<tr><td><code id="wishrnd_+3A_sigma">Sigma</code></td>
<td>
<p>scale parameter (matrix)</p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
