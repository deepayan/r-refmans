<!DOCTYPE html><html lang="en"><head><title>Help for package PIE</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {PIE}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#PIE'><p>PIE: A Partially Interpretable Model with Black-box Refinement</p></a></li>
<li><a href='#data_process'><p>data_process: process tabular data into the format for the PIE model.</p></a></li>
<li><a href='#MAE'><p>MAE: Mean Absolute Error</p></a></li>
<li><a href='#PIE_fit'><p>PIE: Partially Interpretable Model</p></a></li>
<li><a href='#predict.PIE'><p>Make Predictions for PIE</p></a></li>
<li><a href='#RPE'><p>RPE: Relative Prediction Error</p></a></li>
<li><a href='#sparsity_count'><p>sparsity_count</p></a></li>
<li><a href='#winequality'><p>Wine Quality Data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>A Partially Interpretable Model with Black-Box Refinement</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-01-20</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements a novel predictive model, Partially Interpretable Estimators (PIE), which jointly trains an interpretable model and a black-box model to achieve high predictive performance as well as partial model. See the paper, Wang, Yang, Li, and Wang (2021) &lt;<a href="https://doi.org/10.48550%2FarXiv.2105.02410">doi:10.48550/arXiv.2105.02410</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), gglasso, xgboost</td>
</tr>
<tr>
<td>Imports:</td>
<td>splines, stats</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-23 07:25:10 UTC; MissTiny</td>
</tr>
<tr>
<td>Author:</td>
<td>Tong Wang [aut],
  Jingyi Yang [aut, cre],
  Yunyi Li [aut],
  Boxiang Wang [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jingyi Yang &lt;jy4057@stern.nyu.edu&gt;</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-27 18:30:09 UTC</td>
</tr>
</table>
<hr>
<h2 id='PIE'>PIE: A Partially Interpretable Model with Black-box Refinement</h2><span id='topic+PIE-package'></span><span id='topic+PIE'></span>

<h3>Description</h3>

<p>The PIE package implements a novel Partially Interpretable Model (PIE) framework
introduced by Wang et al. &lt;arxiv:2105.02410&gt;. This framework jointly train an interpretable model
and a black-box model to achieve high predictive performance as well as partial model transparency.
</p>


<h3>Functions</h3>

<p>- <code>predict.PIE()</code>: Main function for generating predictions with the PIE model on dataset.
- <code>PIE()</code>: Main function for training the PIE model with dataset.
- <code>data_process()</code>: Process data into the format that can be used by PIE model.
- <code>sparsity_count()</code>: Counts the number of features used in group lasso.
- <code>RPE()</code>: Evaluate the RPE of a PIE model.
- <code>MAE()</code>: Evaluate the MAE of a PIE model.
</p>
<p>For more details, see the documentation for individual functions.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Jingyi Yang <a href="mailto:jy4057@stern.nyu.edu">jy4057@stern.nyu.edu</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Tong Wang
</p>
</li>
<li><p> Yunyi Li
</p>
</li>
<li><p> Boxiang Wang
</p>
</li></ul>


<hr>
<h2 id='data_process'>data_process: process tabular data into the format for the PIE model.</h2><span id='topic+data_process'></span>

<h3>Description</h3>

<p>This function take tabular dataset and meta-data (such as numerical columns and categorical columns), then output k fold cross validation dataset with
splines on numerical features in order to capture the non-linear relationship among numerical features. Within this function, numerical features and target
variable are normalized and reorganize into order: (numerical features, categorical features, target).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_process(
  X,
  y,
  num_col,
  cat_col,
  y_col,
  k = 5,
  validation_rate = 0.2,
  spline_num = 5,
  random_seed = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="data_process_+3A_x">X</code></td>
<td>
<p>Feature columns in dataset</p>
</td></tr>
<tr><td><code id="data_process_+3A_y">y</code></td>
<td>
<p>Target column in dataset</p>
</td></tr>
<tr><td><code id="data_process_+3A_num_col">num_col</code></td>
<td>
<p>Index of the columns that are numerical features</p>
</td></tr>
<tr><td><code id="data_process_+3A_cat_col">cat_col</code></td>
<td>
<p>Index of the columns that are categorical features.</p>
</td></tr>
<tr><td><code id="data_process_+3A_y_col">y_col</code></td>
<td>
<p>Index of the column that is the response.</p>
</td></tr>
<tr><td><code id="data_process_+3A_k">k</code></td>
<td>
<p>Number of fold for cross validation dataset setup. By default 'k = 5'.</p>
</td></tr>
<tr><td><code id="data_process_+3A_validation_rate">validation_rate</code></td>
<td>
<p>Validation ratio within training dataset. By default 'validation_rate = 0.2'</p>
</td></tr>
<tr><td><code id="data_process_+3A_spline_num">spline_num</code></td>
<td>
<p>The degree of freedom for natural splines. By default 'spline_num = 5'</p>
</td></tr>
<tr><td><code id="data_process_+3A_random_seed">random_seed</code></td>
<td>
<p>Random seed for cross validation data split. By default 'random_seed = 1'</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function generates a suitable cross-validation dataset for PIE model. It contains training dataset,
validation dataset, testing dataset and also group indicator for group lasso. When 'k=5', the training
testing splits in 80/20. When 'validation_rate=0.2', 20
Setting 'validation_rate=0' will only generate training and testing data without validation data.
</p>


<h3>Value</h3>

<p>A list containing:
</p>
<table role = "presentation">
<tr><td><code>spl_train_X</code></td>
<td>
<p>A list of splined training dataset where all numerical features are splined
into 'spline_num' columns. The number of element in list equals 'k' the number of fold. </p>
</td></tr>
<tr><td><code>orig_train_X</code></td>
<td>
<p>A list of original training dataset where the numerical features remains the
original format. The number of element in list equals 'k' the number of fold.</p>
</td></tr>
<tr><td><code>train_y</code></td>
<td>
<p>A list of vectors representing target variable for training dataset. The number of
element in list equals 'k' the number of fold.</p>
</td></tr>
<tr><td><code>spl_validation_X</code></td>
<td>
<p>A list of splined validation dataset where all numerical features are splined
into 'spline_num' columns. The number of element in list equals 'k' the number of fold.
It could be None, when 'validation_rate == 0'</p>
</td></tr>
<tr><td><code>orig_validation_X</code></td>
<td>
<p>A list of original validation dataset where the numerical features remains the
original format. The number of element in list equals 'k' the number of fold.
It could be None, when 'validation_rate == 0'</p>
</td></tr>
<tr><td><code>validation_y</code></td>
<td>
<p>A list of vectors representing target variable for validation dataset. The number of
element in list equals 'k' the number of fold. It could be None, when 'validation_rate == 0'</p>
</td></tr>
<tr><td><code>spl_test_X</code></td>
<td>
<p>A list of splined testing dataset where all numerical features are splined
into 'spline_num' columns. The number of element in list equals 'k' the number of fold. </p>
</td></tr>
<tr><td><code>orig_test_X</code></td>
<td>
<p>A list of original testing dataset where the numerical features remains the
original format. The number of element in list equals 'k' the number of fold.</p>
</td></tr>
<tr><td><code>test_y</code></td>
<td>
<p>A list of vectors representing target variable for testing dataset. The number of
element in list equals 'k' the number of fold.</p>
</td></tr>
<tr><td><code>lasso_group</code></td>
<td>
<p>A vector of consecutive integers describing the grouping of the coefficients</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load the training data
data("winequality")

# Which columns are numerical?
num_col &lt;- 1:11
# Which columns are categorical?
cat_col &lt;- 12
# Which column is the response?
y_col &lt;- ncol(winequality)

# Data Processing (the first 200 rows are sampled for demonstration)
dat &lt;- data_process(X = as.matrix(winequality[1:200, -y_col]), 
  y = winequality[1:200, y_col], 
  num_col = num_col, cat_col = cat_col, y_col = y_col)

</code></pre>

<hr>
<h2 id='MAE'>MAE: Mean Absolute Error</h2><span id='topic+MAE'></span>

<h3>Description</h3>

<p>This function calculates the mean absolute error between the predicted values and the true values.
The formula for MAE is:
</p>
<p style="text-align: center;"><code class="reqn">MAE = \frac{1}{n} \sum_i |y_i - \hat{y}_i|</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>MAE(pred, true_label)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MAE_+3A_pred">pred</code></td>
<td>
<p>The predicted values of the dataset.</p>
</td></tr>
<tr><td><code id="MAE_+3A_true_label">true_label</code></td>
<td>
<p>The actual target values of the dataset.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value representing the mean absolute error (MAE).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load the training data
data("winequality")

# Which columns are numerical?
num_col &lt;- 1:11
# Which columns are categorical?
cat_col &lt;- 12
# Which column is the response?
y_col &lt;- ncol(winequality)

# Data Processing (the first 200 rows are sampled for demonstration)
dat &lt;- data_process(X = as.matrix(winequality[1:200, -y_col]), 
  y = winequality[1:200, y_col], 
  num_col = num_col, cat_col = cat_col, y_col = y_col)

# Fit a PIE model
fold &lt;- 1
fit &lt;- PIE_fit(
  X = dat$spl_train_X[[fold]],
  y = dat$train_y[[fold]],
  lasso_group = dat$lasso_group,
  X_orig = dat$orig_train_X[[fold]],
  lambda1 = 0.01, lambda2 = 0.01, iter = 5, eta = 0.05, nrounds = 200
)

# Prediction
pred &lt;- predict(fit, 
  X = dat$spl_validation_X[[fold]],
  X_orig = dat$orig_validation_X[[fold]]
)

# Validation
val_rrmae_test &lt;- MAE(pred$total, dat$validation_y[[fold]])

</code></pre>

<hr>
<h2 id='PIE_fit'>PIE: Partially Interpretable Model</h2><span id='topic+PIE_fit'></span>

<h3>Description</h3>

<p>Partially Interpretable Estimators (PIE), which jointly train an interpretable model and a black-box model to
achieve high predictive performance as well as partial model transparency. PIE is designed to attribute a prediction
to contribution from individual features via a linear additive model to achieve interpretability while complementing
the prediction by a black-box model to boost the predictive performance. Experimental results show that PIE achieves
comparable accuracy to the state-of-the-art black-box models on tabular data. In addition, the understandability of PIE
is close to linear models as validated via human evaluations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PIE_fit(X, y, lasso_group, X_orig, lambda1, lambda2, iter, eta, nrounds, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PIE_fit_+3A_x">X</code></td>
<td>
<p>A matrix for the dataset features with numerical splines.</p>
</td></tr>
<tr><td><code id="PIE_fit_+3A_y">y</code></td>
<td>
<p>A vector for the dataset target label.</p>
</td></tr>
<tr><td><code id="PIE_fit_+3A_lasso_group">lasso_group</code></td>
<td>
<p>A vector that indicates groups</p>
</td></tr>
<tr><td><code id="PIE_fit_+3A_x_orig">X_orig</code></td>
<td>
<p>A matrix for the dataset features without numerical splines.</p>
</td></tr>
<tr><td><code id="PIE_fit_+3A_lambda1">lambda1</code></td>
<td>
<p>A numeric number for group lasso penalty. The larger the value, the larger the penalty.</p>
</td></tr>
<tr><td><code id="PIE_fit_+3A_lambda2">lambda2</code></td>
<td>
<p>A numeric number for black-box model. The larger the value, the larger contribution of XGBoost model.</p>
</td></tr>
<tr><td><code id="PIE_fit_+3A_iter">iter</code></td>
<td>
<p>A numeric number for iterations.</p>
</td></tr>
<tr><td><code id="PIE_fit_+3A_eta">eta</code></td>
<td>
<p>A numeric number for learning rate of XGBoost model.</p>
</td></tr>
<tr><td><code id="PIE_fit_+3A_nrounds">nrounds</code></td>
<td>
<p>A numeric number for number of rounds of XGBoost model.</p>
</td></tr>
<tr><td><code id="PIE_fit_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the XGBoost function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The PIE_fit function use training dataset to train the PIE model through jointly train an interpretable model and a black-box model to
achieve high predictive performance as well as partial model transparency.
</p>


<h3>Value</h3>

<p>An object of class <code>PIE</code> containing the following components:
</p>
<table role = "presentation">
<tr><td><code>Betas</code></td>
<td>
<p>The coefficient of group lasso model</p>
</td></tr>
<tr><td><code>Trees</code></td>
<td>
<p>The coefficients of XGBoost trees</p>
</td></tr>
<tr><td><code>rrMSE_fit</code></td>
<td>
<p>A matrix containing the evaluation between group lasso and y, and evaluation between full model and y for each iteration.</p>
</td></tr>
<tr><td><code>GAM_pred</code></td>
<td>
<p>A matrix containing the contribution of group lasso in each iteration.</p>
</td></tr>
<tr><td><code>Tree_pred</code></td>
<td>
<p>A matrix containing the contribution of XGBoost model in each iteration.</p>
</td></tr>
<tr><td><code>best_iter</code></td>
<td>
<p>The number of the best iteration.</p>
</td></tr>
<tr><td><code>lambda1</code></td>
<td>
<p>The <code>lambda1</code> tuning parameter used in PIE.</p>
</td></tr>
<tr><td><code>lambda2</code></td>
<td>
<p>The <code>lambda2</code> tuning parameter used in PIE.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load the training data
data("winequality")

# Which columns are numerical?
num_col &lt;- 1:11
# Which columns are categorical?
cat_col &lt;- 12
# Which column is the response?
y_col &lt;- ncol(winequality)

# Data Processing (the first 200 rows are sampled for demonstration)
dat &lt;- data_process(X = as.matrix(winequality[1:200, -y_col]), 
  y = winequality[1:200, y_col], 
  num_col = num_col, cat_col = cat_col, y_col = y_col)

# Fit a PIE model
fold &lt;- 1
fit &lt;- PIE_fit(
  X = dat$spl_train_X[[fold]],
  y = dat$train_y[[fold]],
  lasso_group = dat$lasso_group,
  X_orig = dat$orig_train_X[[fold]],
  lambda1 = 0.01, lambda2 = 0.01, iter = 5, eta = 0.05, nrounds = 200
)

</code></pre>

<hr>
<h2 id='predict.PIE'>Make Predictions for PIE</h2><span id='topic+predict.PIE'></span>

<h3>Description</h3>

<p>predicts the response of a <code><a href="#topic+PIE">PIE</a></code> object using new data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'PIE'
predict(object, X, X_orig, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.PIE_+3A_object">object</code></td>
<td>
<p>A fitted <code><a href="#topic+PIE">PIE</a></code> object.</p>
</td></tr>
<tr><td><code id="predict.PIE_+3A_x">X</code></td>
<td>
<p>A matrix for the dataset with features expanded using numerical splines.</p>
</td></tr>
<tr><td><code id="predict.PIE_+3A_x_orig">X_orig</code></td>
<td>
<p>A matrix for the dataset with original features without numerical splines.</p>
</td></tr>
<tr><td><code id="predict.PIE_+3A_...">...</code></td>
<td>
<p>Not used. Other arguments to <code>predict</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Make Predictions for PIE
</p>
<p>This function predicts the response of a <code><a href="#topic+PIE">PIE</a></code> object.
</p>
<p>The PIE_predict function use generate predictions on dataset given the coefficients of group lasso and coefficients for XGBoost Trees
</p>


<h3>Value</h3>

<p>A list containing:
</p>
<table role = "presentation">
<tr><td><code>total</code></td>
<td>
<p>The predicted value of the whole model for given features</p>
</td></tr>
<tr><td><code>white_box</code></td>
<td>
<p>The contribution of group lasso for the given features</p>
</td></tr>
<tr><td><code>black_box</code></td>
<td>
<p>The contribution of XGBoost model for the given features</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load the training data
data("winequality")

# Which columns are numerical?
num_col &lt;- 1:11
# Which columns are categorical?
cat_col &lt;- 12
# Which column is the response?
y_col &lt;- ncol(winequality)

# Data Processing (the first 200 rows are sampled for demonstration)
dat &lt;- data_process(X = as.matrix(winequality[1:200, -y_col]), 
  y = winequality[1:200, y_col], 
  num_col = num_col, cat_col = cat_col, y_col = y_col)

# Fit a PIE model
fold &lt;- 1
fit &lt;- PIE_fit(
  X = dat$spl_train_X[[fold]],
  y = dat$train_y[[fold]],
  lasso_group = dat$lasso_group,
  X_orig = dat$orig_train_X[[fold]],
  lambda1 = 0.01, lambda2 = 0.01, iter = 5, eta = 0.05, nrounds = 200
)

# Prediction
pred &lt;- predict(fit, 
  X = dat$spl_validation_X[[fold]],
  X_orig = dat$orig_validation_X[[fold]]
)

</code></pre>

<hr>
<h2 id='RPE'>RPE: Relative Prediction Error</h2><span id='topic+RPE'></span>

<h3>Description</h3>

<p>This function takes predicted values and target values to evaluate the performance of a PIE model.
The formula for RPE is:
</p>
<p style="text-align: center;"><code class="reqn">RPE = \frac{\sum_i (y_i - \hat{y}_i)^2}{\sum_i (y_i - \bar{y})^2}</code>
</p>

<p>where <code class="reqn">\bar{y} = \frac{1}{n}\sum_i^n y_i</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RPE(pred, true_label)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RPE_+3A_pred">pred</code></td>
<td>
<p>The predicted values of the dataset.</p>
</td></tr>
<tr><td><code id="RPE_+3A_true_label">true_label</code></td>
<td>
<p>The actual target values of the dataset.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value representing the relative prediction error (RPE).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load the training data
data("winequality")

# Which columns are numerical?
num_col &lt;- 1:11
# Which columns are categorical?
cat_col &lt;- 12
# Which column is the response?
y_col &lt;- ncol(winequality)

# Data Processing (the first 200 rows are sampled for demonstration)
dat &lt;- data_process(X = as.matrix(winequality[1:200, -y_col]), 
  y = winequality[1:200, y_col], 
  num_col = num_col, cat_col = cat_col, y_col = y_col)

# Fit a PIE model
fold &lt;- 1
fit &lt;- PIE_fit(
  X = dat$spl_train_X[[fold]],
  y = dat$train_y[[fold]],
  lasso_group = dat$lasso_group,
  X_orig = dat$orig_train_X[[fold]],
  lambda1 = 0.01, lambda2 = 0.01, iter = 5, eta = 0.05, nrounds = 200
)

# Prediction
pred &lt;- predict(fit, 
  X = dat$spl_validation_X[[fold]],
  X_orig = dat$orig_validation_X[[fold]]
)

# Validation
val_rrmse_test &lt;- RPE(pred$total, dat$validation_y[[fold]])

</code></pre>

<hr>
<h2 id='sparsity_count'>sparsity_count</h2><span id='topic+sparsity_count'></span>

<h3>Description</h3>

<p>This function counts the number of features used in group lasso of PIE model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sparsity_count(Betas, lasso_group)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sparsity_count_+3A_betas">Betas</code></td>
<td>
<p>The coefficient of group lasso model.</p>
</td></tr>
<tr><td><code id="sparsity_count_+3A_lasso_group">lasso_group</code></td>
<td>
<p>The group indicator for group lasso model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An integer: The number of features used in group lasso
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load the training data
data("winequality")

# Which columns are numerical?
num_col &lt;- 1:11
# Which columns are categorical?
cat_col &lt;- 12
# Which column is the response?
y_col &lt;- ncol(winequality)

# Data Processing (the first 200 rows are sampled for demonstration)
dat &lt;- data_process(X = as.matrix(winequality[1:200, -y_col]), 
  y = winequality[1:200, y_col], 
  num_col = num_col, cat_col = cat_col, y_col = y_col)

# Fit a PIE model
fold &lt;- 1
fit &lt;- PIE_fit(
  X = dat$spl_train_X[[fold]],
  y = dat$train_y[[fold]],
  lasso_group = dat$lasso_group,
  X_orig = dat$orig_train_X[[fold]],
  lambda1 = 0.01, lambda2 = 0.01, iter = 5, eta = 0.05, nrounds = 200
)

# Sparsity count
sparsity_count(fit$Betas, dat$lasso_group)

</code></pre>

<hr>
<h2 id='winequality'>Wine Quality Data</h2><span id='topic+winequality'></span>

<h3>Description</h3>

<p>This dataset contains 5197 data points. It is related to Portuguese 'Vinho Verdo' wine. Input variables are based on physicochemical tests.
This dataset can also be found at [Wine Quality](https://archive.ics.uci.edu/dataset/186/wine+quality) in UC Irvine Machine Learning Repository.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(winequality)
</code></pre>


<h3>Details</h3>

<p>Wine Quality Data
</p>
<p>A benchmark data set.
</p>


<h3>Value</h3>

<p>A matrix with 5197 rows and 13 columns. The first 11 columns are numerical variables, the 12th column contains categorical variable, and the last column is the response.
</p>


<h3>Source</h3>

<p>The data were introduced in Cortez et al. (2009).
</p>


<h3>References</h3>

<p>Cortez, P., Cerdeira, A., Almeida, F., Matos, T., &amp; Reis, J. (2009). 
&ldquo;Modeling wine preferences by data mining from physicochemical properties,&rdquo;
<em>Decision Support Systems</em>, <b>47</b>(4), 547-553.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load the PIE library
library(PIE)

# Load the dataset
data(winequality)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
