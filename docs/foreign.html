<!DOCTYPE html><html><head><title>Help for package foreign</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {foreign}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#lookup.xport'><p>Lookup Information on a SAS XPORT Format Library</p></a></li>
<li><a href='#read.arff'><p>Read Data from ARFF Files</p></a></li>
<li><a href='#read.dbf'><p>Read a DBF File</p></a></li>
<li><a href='#read.dta'><p>Read Stata Binary Files</p></a></li>
<li><a href='#read.epiinfo'><p>Read Epi Info Data Files</p></a></li>
<li><a href='#read.mtp'><p>Read a Minitab Portable Worksheet</p></a></li>
<li><a href='#read.octave'><p>Read Octave Text Data Files</p></a></li>
<li><a href='#read.spss'><p>Read an SPSS Data File</p></a></li>
<li><a href='#read.ssd'><p>Obtain a Data Frame from a SAS Permanent Dataset, via read.xport</p></a></li>
<li><a href='#read.systat'><p>Obtain a Data Frame from a Systat File</p></a></li>
<li><a href='#read.xport'><p>Read a SAS XPORT Format Library</p></a></li>
<li><a href='#S3 read functions'><p>Read an S3 Binary or data.dump File</p></a></li>
<li><a href='#write.arff'><p>Write Data into ARFF Files</p></a></li>
<li><a href='#write.dbf'><p>Write a DBF File</p></a></li>
<li><a href='#write.dta'><p>Write Files in Stata Binary Format</p></a></li>
<li><a href='#write.foreign'><p>Write Text Files and Code to Read Them</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Priority:</td>
<td>recommended</td>
</tr>
<tr>
<td>Version:</td>
<td>0.8-86</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-11-26</td>
</tr>
<tr>
<td>Title:</td>
<td>Read Data Stored by 'Minitab', 'S', 'SAS', 'SPSS', 'Stata',
'Systat', 'Weka', 'dBase', ...</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, utils, stats</td>
</tr>
<tr>
<td>Contact:</td>
<td>see 'MailingList'</td>
</tr>
<tr>
<td>Copyright:</td>
<td>see file COPYRIGHTS</td>
</tr>
<tr>
<td>Description:</td>
<td>Reading and writing data stored by some versions of
	'Epi Info', 'Minitab', 'S', 'SAS', 'SPSS', 'Stata', 'Systat', 'Weka',
	and for reading and writing some 'dBase' files.</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>yes</td>
</tr>
<tr>
<td>Biarch:</td>
<td>yes</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://bugs.r-project.org">https://bugs.r-project.org</a></td>
</tr>
<tr>
<td>MailingList:</td>
<td>R-help@r-project.org</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://svn.r-project.org/R-packages/trunk/foreign/">https://svn.r-project.org/R-packages/trunk/foreign/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-26 16:54:35 UTC; ripley</td>
</tr>
<tr>
<td>Author:</td>
<td>R Core Team [aut, cph, cre],
  Roger Bivand [ctb, cph],
  Vincent J. Carey [ctb, cph],
  Saikat DebRoy [ctb, cph],
  Stephen Eglen [ctb, cph],
  Rajarshi Guha [ctb, cph],
  Swetlana Herbrandt [ctb],
  Nicholas Lewin-Koh [ctb, cph],
  Mark Myatt [ctb, cph],
  Michael Nelson [ctb],
  Ben Pfaff [ctb],
  Brian Quistorff [ctb],
  Frank Warmerdam [ctb, cph],
  Stephen Weigand [ctb, cph],
  Free Software Foundation, Inc. [cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>R Core Team &lt;R-core@R-project.org&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-28 06:42:13 UTC</td>
</tr>
<tr>
<td>Built:</td>
<td>R 4.4.0; x86_64-pc-linux-gnu; 2024-03-26 07:26:25 UTC; unix</td>
</tr>
</table>
<hr>
<h2 id='lookup.xport'>Lookup Information on a SAS XPORT Format Library</h2><span id='topic+lookup.xport'></span>

<h3>Description</h3>

<p>Scans a file as a SAS XPORT format library and returns a list
containing information about the SAS library.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lookup.xport(file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lookup.xport_+3A_file">file</code></td>
<td>
<p>character variable with the name of the file to read.  The
file must be in SAS XPORT format.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with one component for each dataset in the XPORT format library.
</p>


<h3>Author(s)</h3>

<p>Saikat DebRoy</p>


<h3>References</h3>

<p>SAS Technical Support document TS-140:
&ldquo;The Record Layout of a Data Set in SAS Transport (XPORT) Format&rdquo;
available as
<a href="https://support.sas.com/content/dam/SAS/support/en/technical-papers/record-layout-of-a-sas-version-5-or-6-data-set-in-sas-transport-xport-format.pdf">https://support.sas.com/content/dam/SAS/support/en/technical-papers/record-layout-of-a-sas-version-5-or-6-data-set-in-sas-transport-xport-format.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.xport">read.xport</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: ## no XPORT file is installed.
lookup.xport("test.xpt")

## End(Not run)
</code></pre>

<hr>
<h2 id='read.arff'>Read Data from ARFF Files</h2><span id='topic+read.arff'></span>

<h3>Description</h3>

<p>Reads data from Weka Attribute-Relation File Format (ARFF) files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.arff(file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.arff_+3A_file">file</code></td>
<td>
<p>a character string with the name of the ARFF file to read
from, or a <code><a href="base.html#topic+connection">connection</a></code> which will be opened if
necessary, and if so closed at the end of the function call.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing the data from the ARFF file.
</p>


<h3>References</h3>

<p>Attribute-Relation File Format
<a href="https://waikato.github.io/weka-wiki/formats_and_processing/arff/">https://waikato.github.io/weka-wiki/formats_and_processing/arff/</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write.arff">write.arff</a></code>;
functions <code>write.arff</code> and <code>read.arff</code> in package
<span class="pkg">RWeka</span> which provide some support for logicals via conversion to
or from factors.
</p>

<hr>
<h2 id='read.dbf'>Read a DBF File</h2><span id='topic+read.dbf'></span>

<h3>Description</h3>

<p>The function reads a DBF file into a data frame, converting character
fields to factors, and trying to respect NULL fields.
</p>
<p>The DBF format is documented but not much adhered to.  There is is no
guarantee this will read all DBF files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.dbf(file, as.is = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.dbf_+3A_file">file</code></td>
<td>
<p>name of input file</p>
</td></tr>
<tr><td><code id="read.dbf_+3A_as.is">as.is</code></td>
<td>
<p>should character vectors not be converted to factors?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>DBF is the extension used for files written for the &lsquo;XBASE&rsquo;
family of database languages, &lsquo;covering the dBase, Clipper,
FoxPro, and their Windows equivalents Visual dBase, Visual Objects,
and Visual FoxPro, plus some older products&rsquo;
(<a href="https://www.clicketyclick.dk/databases/xbase/format/">https://www.clicketyclick.dk/databases/xbase/format/</a>).
Most of these follow the file structure used by Ashton-Tate's dBase
II, III or 4 (later owned by Borland).
</p>
<p><code>read.dbf</code> is based on C code from
<a href="http://shapelib.maptools.org/">http://shapelib.maptools.org/</a> which implements the
&lsquo;XBASE&rsquo; specification.  It can convert fields of type
<code>"L"</code> (logical), <code>"N"</code> and <code>"F"</code> (numeric and float)
and <code>"D"</code> (dates): all other field types are read as-is as
character vectors.  A numeric field is read as an <span class="rlang"><b>R</b></span> integer vector if
it is encoded to have no decimals, otherwise as a numeric vector.  However,
if the numbers are too large to fit into an integer vector, it is
changed to numeric.  Note that is possible to read integers that cannot be
represented exactly even as doubles: this sometimes occurs if IDs are
incorrectly coded as numeric.
</p>


<h3>Value</h3>

<p>A data frame of data from the DBF file; note that the field names are
adjusted to use in R using <code><a href="base.html#topic+make.names">make.names</a>(unique=TRUE)</code>.
</p>
<p>There is an attribute <code>"data_type"</code> giving the single-character
dBase types for each field.
</p>


<h3>Note</h3>

<p>Not to be able to read a particular &lsquo;DBF&rsquo; file is not a bug:
this is a convenience function especially for shapefiles.
</p>


<h3>Author(s)</h3>

<p>Nicholas Lewin-Koh and Roger Bivand; shapelib by Frank Warmerdam
</p>


<h3>References</h3>

<p><a href="http://shapelib.maptools.org/">http://shapelib.maptools.org/</a>.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+write.dbf">write.dbf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- read.dbf(system.file("files/sids.dbf", package="foreign")[1])
str(x)
summary(x)
</code></pre>

<hr>
<h2 id='read.dta'>Read Stata Binary Files</h2><span id='topic+read.dta'></span>

<h3>Description</h3>

<p>Reads a file in Stata version 5&ndash;12 binary format into a data frame. 
</p>
<p>Frozen: will not support Stata formats after 12.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.dta(file, convert.dates = TRUE, convert.factors = TRUE,
         missing.type = FALSE,
         convert.underscore = FALSE, warn.missing.labels = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.dta_+3A_file">file</code></td>
<td>
<p>a filename or URL as a character string.</p>
</td></tr>
<tr><td><code id="read.dta_+3A_convert.dates">convert.dates</code></td>
<td>
<p>Convert Stata dates to <code>Date</code> class, and
date-times to <code>POSIXct</code> class?</p>
</td></tr>
<tr><td><code id="read.dta_+3A_convert.factors">convert.factors</code></td>
<td>
<p>Use Stata value labels to create factors?
(Version 6.0 or later).</p>
</td></tr>
<tr><td><code id="read.dta_+3A_missing.type">missing.type</code></td>
<td>
<p>For version 8 or later, store information about
different types of missing data?</p>
</td></tr>
<tr><td><code id="read.dta_+3A_convert.underscore">convert.underscore</code></td>
<td>
<p>Convert <code>"_"</code> in Stata variable names
to <code>"."</code> in R names?</p>
</td></tr>
<tr><td><code id="read.dta_+3A_warn.missing.labels">warn.missing.labels</code></td>
<td>
<p>Warn if a variable is specified with value
labels and those value labels are not present in the file.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the filename appears to be a URL (of schemes &lsquo;<span class="samp">&#8288;http:&#8288;</span>&rsquo;,
&lsquo;<span class="samp">&#8288;ftp:&#8288;</span>&rsquo; or &lsquo;<span class="samp">&#8288;https:&#8288;</span>&rsquo;) the URL is first downloaded to a
temporary file and then read.  (&lsquo;<span class="samp">&#8288;https:&#8288;</span>&rsquo; is only supported on
some platforms.)
</p>
<p>The variables in the Stata data set become the columns of the data
frame.  Missing values are correctly handled.  The data label,
variable labels, timestamp, and variable/dataset characteristics
are stored as attributes of the data frame.
</p>
<p>By default Stata dates (%d and %td formats) are converted to <span class="rlang"><b>R</b></span>'s
<code>Date</code> class, and variables with Stata value labels are
converted to factors.  Ordinarily, <code>read.dta</code> will not convert
a variable to a factor unless a label is present for every level.  Use
<code>convert.factors = NA</code> to override this.  In any case the value
label and format information is stored as attributes on the returned
data frame.  Stata's date formats are sketchily documented: if
necessary use <code>convert.dates = FALSE</code> and examine the attributes
to work out how to post-process the dates.
</p>
<p>Stata 8 introduced a system of 27 different missing data values.  If
<code>missing.type</code> is <code>TRUE</code> a separate list is created with the
same variable names as the loaded data.  For string variables the list
value is <code>NULL</code>.  For other variables the value is <code>NA</code>
where the observation is not missing and 0&ndash;26 when the observation is
missing.  This is attached as the <code>"missing"</code> attribute of the
returned value.
</p>
<p>The default file format for Stata 13, <code>format-115</code>, is
substantially different from those for Stata 5&ndash;12.
</p>


<h3>Value</h3>

<p>A data frame with attributes.  These will include <code>"datalabel"</code>,
<code>"time.stamp"</code>, <code>"formats"</code>, <code>"types"</code>,
<code>"val.labels"</code>, <code>"var.labels"</code> and <code>"version"</code> and may
include <code>"label.table"</code> and <code>"expansion.table"</code>.  
Possible versions are <code>5, 6, 7</code>,
<code>-7</code> (Stata 7SE, &lsquo;format-111&rsquo;), <code>8</code> (Stata 8 and 9,
&lsquo;format-113&rsquo;), <code>10</code> (Stata 10 and 11, &lsquo;format-114&rsquo;).
and <code>12</code> (Stata 12, &lsquo;format-115&rsquo;).
</p>
<p>The value labels in attribute <code>"val.labels"</code> name a table for
each variable, or are an empty string.  The tables are elements of the
named list attribute <code>"label.table"</code>: each is an integer vector with
names.
</p>


<h3>Author(s)</h3>

<p>Thomas Lumley and R-core members: support for value labels by
Brian Quistorff.
</p>


<h3>References</h3>

<p>Stata Users Manual (versions 5 &amp; 6), Programming manual (version 7),
or online help (version 8 and later) describe the format of the files.
Or directly at <a href="https://www.stata.com/help.cgi?dta_114">https://www.stata.com/help.cgi?dta_114</a> and
<a href="https://www.stata.com/help.cgi?dta_113">https://www.stata.com/help.cgi?dta_113</a>, but note that these have
been changed since first published.
</p>


<h3>See Also</h3>

<p>Different approaches are available in package <span class="pkg">memisc</span> (see its
help for <code>Stata.file</code>), function <code>read_dta</code> in package
<span class="pkg">haven</span> and package <span class="pkg">readstata13</span>.
</p>
<p><code><a href="#topic+write.dta">write.dta</a></code>,
<code><a href="base.html#topic+attributes">attributes</a></code>,
<code><a href="base.html#topic+Date">Date</a></code>,
<code><a href="base.html#topic+factor">factor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>write.dta(swiss,swissfile &lt;- tempfile())
read.dta(swissfile)
</code></pre>

<hr>
<h2 id='read.epiinfo'>Read Epi Info Data Files</h2><span id='topic+read.epiinfo'></span>

<h3>Description</h3>

<p>Reads data files in the <code>.REC</code> format used by Epi Info versions 6
and earlier and by EpiData.  Epi Info is a public domain database and
statistics package produced by the US Centers for Disease Control
and EpiData is a freely available data entry and validation system.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.epiinfo(file, read.deleted = FALSE, guess.broken.dates = FALSE,
             thisyear = NULL, lower.case.names = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.epiinfo_+3A_file">file</code></td>
<td>
<p>A filename, URL, or connection.</p>
</td></tr>
<tr><td><code id="read.epiinfo_+3A_read.deleted">read.deleted</code></td>
<td>
<p>Deleted records are read if <code>TRUE</code>, omitted
if <code>FALSE</code> or replaced with <code>NA</code> if <code>NA</code>.</p>
</td></tr>
<tr><td><code id="read.epiinfo_+3A_guess.broken.dates">guess.broken.dates</code></td>
<td>
<p>Attempt to convert dates with 0 or 2 digit
year information (see &lsquo;Details&rsquo;).</p>
</td></tr>
<tr><td><code id="read.epiinfo_+3A_thisyear">thisyear</code></td>
<td>
<p>A 4-digit year to use for dates with no year. Defaults
to the current year.</p>
</td></tr>
<tr><td><code id="read.epiinfo_+3A_lower.case.names">lower.case.names</code></td>
<td>
<p>Convert variable names to lowercase?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Epi Info allows dates to be specified with no year or with a 2 or 4
digits.  Dates with four-digit years are always converted to
<code>Date</code> class.  With the <code>guess.broken.dates</code> option the function
will attempt to convert two-digit years using the operating system's
default method (see <a href="base.html#topic+Date">Date</a>) and will use the current
year or the <code>thisyear</code> argument for dates with no year
information.
</p>
<p>If <code>read.deleted</code> is <code>TRUE</code> the <code>"deleted"</code> attribute
of the data frame indicates the deleted records.
</p>


<h3>Value</h3>

<p>A data frame.
</p>


<h3>Note</h3>

<p>Some later versions of Epi Info use the Microsoft Access file
format to store data. That may be readable with the <span class="pkg">RODBC</span> package.
</p>


<h3>References</h3>

<p><a href="https://www.cdc.gov/epiinfo/">https://www.cdc.gov/epiinfo/</a>,
<a href="http://www.epidata.dk">http://www.epidata.dk</a>
</p>


<h3>See Also</h3>

<p><a href="base.html#topic+DateTimeClasses">DateTimeClasses</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: ## That file is not available
read.epiinfo("oswego.rec", guess.broken.dates = TRUE, thisyear = "1972")

## End(Not run)
</code></pre>

<hr>
<h2 id='read.mtp'>Read a Minitab Portable Worksheet</h2><span id='topic+read.mtp'></span>

<h3>Description</h3>

<p>Return a list with the data stored in a file as a Minitab Portable
Worksheet.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.mtp(file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.mtp_+3A_file">file</code></td>
<td>
<p>character variable with the name of the file to read.  The
file must be in Minitab Portable Worksheet format.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with one component for each column, matrix, or constant stored
in the Minitab worksheet.
</p>


<h3>Note</h3>

<p>This function was written around 1990 for the format current
then. Later versions of Minitab appear to have added to the format.
</p>


<h3>Author(s)</h3>

<p>Douglas M. Bates</p>


<h3>References</h3>

<p><a href="https://www.minitab.com/">https://www.minitab.com/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
read.mtp("ex1-10.mtp")

## End(Not run)
</code></pre>

<hr>
<h2 id='read.octave'>Read Octave Text Data Files</h2><span id='topic+read.octave'></span>

<h3>Description</h3>

<p>Read a file in Octave text data format into a list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.octave(file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.octave_+3A_file">file</code></td>
<td>
<p>a character string with the name of the file to read.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is used to read in files in Octave text data format, as
created by <code>save -text</code> in Octave.  It knows about most of the
common types of variables, including the standard atomic (real and
complex scalars, matrices, and <code class="reqn">N</code>-d arrays, strings, ranges, and
boolean scalars and matrices) and recursive (structs, cells, and
lists) ones, but has no guarantee to read all types.  If a type is not
recognized, a warning indicating the unknown type is issued, it is
attempted to skip the unknown entry, and <code>NULL</code> is used as its
value.  Note that this will give incorrect results, and maybe even
errors, in the case of unknown recursive data types.
</p>
<p>As Octave can read MATLAB binary files, one can make the contents of
such files available to R by using Octave's load and save (as text)
facilities as an intermediary step.
</p>


<h3>Value</h3>

<p>A list with one named component for each variable in the file.
</p>


<h3>Author(s)</h3>

<p>Stephen Eglen <a href="mailto:stephen@gnu.org">stephen@gnu.org</a> and Kurt Hornik</p>


<h3>References</h3>

<p><a href="https://octave.org/">https://octave.org/</a></p>

<hr>
<h2 id='read.spss'>Read an SPSS Data File</h2><span id='topic+read.spss'></span>

<h3>Description</h3>

<p><code>read.spss</code> reads a file stored by the SPSS <code>save</code> or
<code>export</code> commands.
</p>
<p>This was orignally written in 2000 and has limited support for changes
in SPSS formats since (which have not been many).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.spss(file, use.value.labels = TRUE, to.data.frame = FALSE,
          max.value.labels = Inf, trim.factor.names = FALSE,
          trim_values = TRUE, reencode = NA, use.missings = to.data.frame, 
          sub = ".", add.undeclared.levels = c("sort", "append", "no"),
          duplicated.value.labels = c("append", "condense"),
          duplicated.value.labels.infix = "_duplicated_", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.spss_+3A_file">file</code></td>
<td>
<p>character string: the name of the file or URL to read.</p>
</td></tr>
<tr><td><code id="read.spss_+3A_use.value.labels">use.value.labels</code></td>
<td>
<p>logical: convert variables with value labels
into <span class="rlang"><b>R</b></span> factors with those levels?  This is only done if there are
at least as many labels as values of the variable (when values
without a matching label are returned as <code>NA</code>).</p>
</td></tr>
<tr><td><code id="read.spss_+3A_to.data.frame">to.data.frame</code></td>
<td>
<p>logical: return a data frame?</p>
</td></tr>
<tr><td><code id="read.spss_+3A_max.value.labels">max.value.labels</code></td>
<td>
<p>logical: only variables with value labels and
at most this many unique values will be converted to factors if
<code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="read.spss_+3A_trim.factor.names">trim.factor.names</code></td>
<td>
<p>logical: trim trailing spaces from factor levels?</p>
</td></tr>
<tr><td><code id="read.spss_+3A_trim_values">trim_values</code></td>
<td>
<p>logical: should values and value labels have
trailing spaces ignored when matching for <code>use.value.labels = TRUE</code>?</p>
</td></tr>
<tr><td><code id="read.spss_+3A_reencode">reencode</code></td>
<td>
<p>logical: should character strings be re-encoded to the
current locale.  The default, <code>NA</code>, means to do so in UTF-8 or latin-1
locales, only.  Alternatively a character string specifying an encoding to
assume for the file.</p>
</td></tr>
<tr><td><code id="read.spss_+3A_use.missings">use.missings</code></td>
<td>
<p>logical: should information on user-defined
missing values be used to set the corresponding values to <code>NA</code>?</p>
</td></tr>
<tr><td><code id="read.spss_+3A_sub">sub</code></td>
<td>
<p>character string: If not <code>NA</code> it is used by <code><a href="base.html#topic+iconv">iconv</a></code> 
to replace any non-convertible bytes in character/factor input. 
Default is <code>"."</code>. For back compatibility with <span class="pkg">foreign</span> 
versions &lt;= 0.8-68 use <code>sub=NA</code>.</p>
</td></tr>
<tr><td><code id="read.spss_+3A_add.undeclared.levels">add.undeclared.levels</code></td>
<td>
<p>character: 
specify how to handle variables with at least one value label and further 
non-missing values that have no value label (like a factor levels in R).
For <code>"sort"</code> (the default) it adds undeclared factor levels to the 
already declared levels (and labels) and sort them according to level,
for <code>"append"</code> it appends undeclared factor levels to declared levels 
(and labels) without sorting, and
for <code>"no"</code> this does not convert to factor in case of numeric SPSS levels 
(not labels), and still converts to factor if the SPSS levels are characters 
and <code>to.data.frame=TRUE</code>.
For back compatibility with <span class="pkg">foreign</span> versions &lt;= 0.8-68 use 
<code>add.undeclared.levels="no"</code> (not recommended as this may convert some 
values with missing corresponding value labels to <code>NA</code>).</p>
</td></tr>
<tr><td><code id="read.spss_+3A_duplicated.value.labels">duplicated.value.labels</code></td>
<td>
<p>character: what to do with duplicated value 
labels for different levels.
For <code>"append"</code> (the default), the first original value label is kept 
while further duplicated labels are renamed to 
<code>paste0(label, duplicated.value.labels.infix, level)</code>,
for <code>"condense"</code>, all levels with identical labels are condensed into 
exactly the first of these levels in R.
Back compatibility with <span class="pkg">foreign</span> versions &lt;= 0.8-68 is not given as 
R versions &gt;= 3.4.0 no longer support duplicated factor labels.
</p>
</td></tr>
<tr><td><code id="read.spss_+3A_duplicated.value.labels.infix">duplicated.value.labels.infix</code></td>
<td>
<p>character: the infix used for labels of 
factor levels with duplicated value labels in SPSS (default <code>"_duplicated_"</code>) 
if <code>duplicated.value.labels="append"</code>.</p>
</td></tr>
<tr><td><code id="read.spss_+3A_...">...</code></td>
<td>
<p>passed to <code><a href="base.html#topic+as.data.frame">as.data.frame</a></code> if <code>to.data.frame = TRUE</code>.</p>
</td></tr></table>


<h3>Details</h3>

<p>This uses modified code from the PSPP project
(<a href="http://www.gnu.org/software/pspp/">http://www.gnu.org/software/pspp/</a> for reading the SPSS formats.
</p>
<p>If the filename appears to be a URL (of schemes &lsquo;<span class="samp">&#8288;http:&#8288;</span>&rsquo;,
&lsquo;<span class="samp">&#8288;ftp:&#8288;</span>&rsquo; or &lsquo;<span class="samp">&#8288;https:&#8288;</span>&rsquo;) the URL is first downloaded to a
temporary file and then read.  (&lsquo;<span class="samp">&#8288;https:&#8288;</span>&rsquo; is supported where
supported by <code><a href="utils.html#topic+download.file">download.file</a></code> with its current default
<code>method</code>.)
</p>
<p>Occasionally in SPSS, value labels will be added to some values of a
continuous variable (e.g. to distinguish different types of missing
data), and you will not want these variables converted to factors.  By
setting <code>max.value.labels</code> you can specify that variables with a
large number of distinct values are not converted to factors even if
they have value labels.  
</p>
<p>If SPSS variable labels are present, they are returned as the
<code>"variable.labels"</code> attribute of the answer.
</p>
<p>Fixed length strings (including value labels) are padded on the right
with spaces by SPSS, and so are read that way by <span class="rlang"><b>R</b></span>.  The default
argument <code>trim_values=TRUE</code> causes trailing spaces to be ignored
when matching to value labels, as examples have been seen where the
strings and the value labels had different amounts of padding.  See
the examples for <code><a href="base.html#topic+sub">sub</a></code> for ways to remove trailing spaces
in character data.
</p>
<p>URL <a href="https://learn.microsoft.com/en-us/windows/win32/intl/code-page-identifiers">https://learn.microsoft.com/en-us/windows/win32/intl/code-page-identifiers</a>
provides a list of translations from Windows codepage numbers to
encoding names that <code><a href="base.html#topic+iconv">iconv</a></code> is likely to know about and so
suitable values for <code>reencode</code>.  Automatic re-encoding is
attempted for apparent codepages of 200 or more in a UTF-8 or latin-1 locale:
some other high-numbered codepages can be re-encoded on most systems,
but the encoding names are platform-dependent (see
<code><a href="base.html#topic+iconvlist">iconvlist</a></code>).
</p>


<h3>Value</h3>

<p>A list (or optionally a data frame) with one component for each
variable in the saved data set.
</p>
<p>If what looks like a Windows codepage was recorded in the SPSS file,
it is attached (as a number) as attribute <code>"codepage"</code> to the
result.
</p>
<p>There may be attributes <code>"label.table"</code> and
<code>"variable.labels"</code>.  Attribute <code>"label.table"</code> is a named
list of value labels with one element per variable, either <code>NULL</code>
or a named character vector.  Attribute <code>"variable.labels"</code> is a
named character vector with names the short variable names and
elements the long names.
</p>
<p>If there are user-defined missing values, there will be a attribute
<code>"Missings"</code>.  This is a named list with one list element per
variable.  Each element has an element <code>type</code>, a length-one
character vector giving the type of missingness, and may also have an
element <code>value</code> with the values corresponding to missingness.
This is a complex subject (where the <span class="rlang"><b>R</b></span> and C source code for
<code>read.spss</code> is the main documentation), but the simplest cases
are types <code>"one"</code>, <code>"two"</code> and <code>"three"</code> with a
corresponding number of (real or string) values whose labels can be
found from the <code>"label.table"</code> attribute.  Other possibilities are
a finite or semi-infinite range, possibly plus a single value.
See also <a href="http://www.gnu.org/software/pspp/manual/html_node/Missing-Observations.html#Missing-Observations">http://www.gnu.org/software/pspp/manual/html_node/Missing-Observations.html#Missing-Observations</a>.
</p>


<h3>Note</h3>

<p>If SPSS value labels are converted to factors the underlying numerical
codes will not in general be the same as the SPSS numerical
values, since the numerical codes in R are always <code class="reqn">1,2,3,\dots</code>.
</p>
<p>You may see warnings about the file encoding for SPSS <code>save</code>
files: it is possible such files contain non-ASCII character data
which need re-encoding.  The most common occurrence is Windows codepage
1252, a superset of Latin-1.  The encoding is recorded (as an integer)
in attribute <code>"codepage"</code> of the result if it looks like a
Windows codepage.  Automatic re-encoding is done only in UTF-8 and latin-1
locales: see argument <code>reencode</code>.
</p>


<h3>Author(s)</h3>

<p>Saikat DebRoy and the R-core team</p>


<h3>See Also</h3>

<p>A different interface also based on the PSPP codebase is available in
package <span class="pkg">memisc</span>: see its help for <code>spss.system.file</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(sav &lt;- system.file("files", "electric.sav", package = "foreign"))
dat &lt;- read.spss(file=sav) 
str(dat)   # list structure with attributes

dat &lt;- read.spss(file=sav, to.data.frame=TRUE) 
str(dat)   # now a data.frame


### Now we use an example file that is not very well structured and 
### hence may need some special treatment with appropriate argument settings.
### Expect lots of warnings as value labels (corresponding to R factor labels) are uncomplete, 
### and an unsupported long string variable is present in the data
(sav &lt;- system.file("files", "testdata.sav", package = "foreign"))

### Examples for add.undeclared.levels:
## add.undeclared.levels = "sort" (default):
x.sort &lt;- read.spss(file=sav, to.data.frame = TRUE)
## add.undeclared.levels = "append":
x.append &lt;- read.spss(file=sav, to.data.frame = TRUE, 
    add.undeclared.levels = "append")
## add.undeclared.levels = "no":
x.no &lt;- read.spss(file=sav, to.data.frame = TRUE, 
    add.undeclared.levels = "no")

levels(x.sort$factor_n_undeclared)
levels(x.append$factor_n_undeclared)
str(x.no$factor_n_undeclared)


### Examples for duplicated.value.labels:
## duplicated.value.labels = "append" (default)
x.append &lt;- read.spss(file=sav, to.data.frame=TRUE)
## duplicated.value.labels = "condense"
x.condense &lt;- read.spss(file=sav, to.data.frame=TRUE, 
    duplicated.value.labels = "condense")

levels(x.append$factor_n_duplicated)
levels(x.condense$factor_n_duplicated)

as.numeric(x.append$factor_n_duplicated)
as.numeric(x.condense$factor_n_duplicated)

    
## Long Strings (&gt;255 chars) are imported in consecutive separate variables 
## (see warning about subtype 14):
x &lt;- read.spss(file=sav, to.data.frame=TRUE, stringsAsFactors=FALSE)

cat.long.string &lt;- function(x, w=70) cat(paste(strwrap(x, width=w), "\n"))

## first part: x$string_500:
cat.long.string(x$string_500)
## second part: x$STRIN0:
cat.long.string(x$STRIN0)
## complete long string:
long.string &lt;- apply(x[,c("string_500", "STRIN0")], 1, paste, collapse="")
cat.long.string(long.string)
</code></pre>

<hr>
<h2 id='read.ssd'>Obtain a Data Frame from a SAS Permanent Dataset, via read.xport </h2><span id='topic+read.ssd'></span>

<h3>Description</h3>

<p>Generates a SAS program to convert the ssd contents to SAS transport format
and then uses <code>read.xport</code> to obtain a data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.ssd(libname, sectionnames, 
   tmpXport=tempfile(), tmpProgLoc=tempfile(), sascmd="sas")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.ssd_+3A_libname">libname</code></td>
<td>
<p>character string defining the SAS library (usually a
directory reference)</p>
</td></tr>
<tr><td><code id="read.ssd_+3A_sectionnames">sectionnames</code></td>
<td>
<p>character vector giving member names.  These are
files in the <code>libname</code> directory. They will usually have a
<code>.ssd0x</code> or <code>.sas7bdat</code> extension, which should be
omitted.  Use of ASCII names of at most 8 characters is strongly
recommended.</p>
</td></tr>
<tr><td><code id="read.ssd_+3A_tmpxport">tmpXport</code></td>
<td>
<p>character  string: location where temporary xport
format archive should reside &ndash; defaults to a randomly named file
in the session temporary directory, which will be removed.</p>
</td></tr>
<tr><td><code id="read.ssd_+3A_tmpprogloc">tmpProgLoc</code></td>
<td>
<p>character  string: location where temporary
conversion SAS program should reside &ndash; defaults to a randomly named
file in session temporary directory, which will be removed on
successful operation.</p>
</td></tr>
<tr><td><code id="read.ssd_+3A_sascmd">sascmd</code></td>
<td>
<p>character string giving full path to SAS executable.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Creates a SAS program and runs it.
</p>
<p>Error handling is primitive.
</p>


<h3>Value</h3>

<p>A data frame if all goes well, or <code>NULL</code> with warnings and some
enduring side effects (log file for auditing)
</p>


<h3>Note</h3>

<p><strong>This requires SAS to be available.</strong>  If you have a SAS dataset
without access to SAS you will need another product to convert it to a 
format such as <code>.csv</code>, for example &lsquo;Stat/Transfer&rsquo; or 
&lsquo;DBMS/Copy&rsquo; or the &lsquo;SAS System Viewer&rsquo; (Windows only).
</p>
<p>SAS requires section names to be no more than 8 characters.  This is
worked by the use of symbolic links: these are barely supported on Windows.
</p>


<h3>Author(s)</h3>

<p>For Unix: VJ Carey <a href="mailto:stvjc@channing.harvard.edu">stvjc@channing.harvard.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.xport">read.xport</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## if there were some files on the web we could get a real
## runnable example
## Not run: 
R&gt; list.files("trialdata")
 [1] "baseline.sas7bdat" "form11.sas7bdat"   "form12.sas7bdat"  
 [4] "form13.sas7bdat"   "form22.sas7bdat"   "form23.sas7bdat"  
 [7] "form3.sas7bdat"    "form4.sas7bdat"    "form48.sas7bdat"  
[10] "form50.sas7bdat"   "form51.sas7bdat"   "form71.sas7bdat"  
[13] "form72.sas7bdat"   "form8.sas7bdat"    "form9.sas7bdat"   
[16] "form90.sas7bdat"   "form91.sas7bdat"  
R&gt; baseline &lt;- read.ssd("trialdata", "baseline")
R&gt; form90 &lt;- read.ssd("trialdata", "form90")

## Or for a Windows example
sashome &lt;- "/Program Files/SAS/SAS 9.1"
read.ssd(file.path(sashome, "core", "sashelp"), "retail",
         sascmd = file.path(sashome, "sas.exe"))

## End(Not run)
</code></pre>

<hr>
<h2 id='read.systat'>Obtain a Data Frame from a Systat File</h2><span id='topic+read.systat'></span>

<h3>Description</h3>

<p><code>read.systat</code> reads a rectangular data file stored by the Systat
<code>SAVE</code> command as (legacy) <code>*.sys</code> or more recently
<code>*.syd</code> files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.systat(file, to.data.frame = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.systat_+3A_file">file</code></td>
<td>
<p>character variable with the name of the file to read</p>
</td></tr>
<tr><td><code id="read.systat_+3A_to.data.frame">to.data.frame</code></td>
<td>
<p>return a data frame (otherwise a list)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function only reads those Systat files that are rectangular data
files (<code>mtype = 1</code>), and warns when files have non-standard
variable name codings.  The files tested were produced on MS-DOS and
Windows: files for the Mac version of Systat have a completely
different format.
</p>
<p>The C code was originally written for an add-on module for Systat
described in Bivand (1992 paper).  Variable names retain the trailing
dollar in the list returned when <code>to.data.frame</code> is <code>FALSE</code>,
and in that case character variables are returned as is and filled up
to 12 characters with blanks on the right.  The original function was
limited to reading Systat files with up to 256 variables (a Systat
limitation); it will now read up to 8192 variables.
</p>
<p>If there is a user comment in the header this is returned as attribute
<code>"comment"</code>.  Such comments are always a multiple of 72
characters (with a maximum of 720 chars returned), normally padded with
trailing spaces.
</p>


<h3>Value</h3>

<p>A data frame (or list) with one component for each variable in the
saved data set.
</p>


<h3>Author(s)</h3>

<p>Roger Bivand</p>


<h3>References</h3>

<p>Systat Manual, 1987, 1989<br />
</p>
<p>Bivand, R. S. (1992)
SYSTAT-compatible software for modelling spatial dependence among
observations. <em>Computers and Geosciences</em> <b>18</b>, 951&ndash;963.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>summary(iris)
iris.s &lt;- read.systat(system.file("files/Iris.syd", package="foreign")[1])
str(iris.s)
summary(iris.s)
</code></pre>

<hr>
<h2 id='read.xport'>Read a SAS XPORT Format Library</h2><span id='topic+read.xport'></span>

<h3>Description</h3>

<p>Reads a file as a SAS XPORT format library and returns a list of
data.frames.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.xport(file, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.xport_+3A_file">file</code></td>
<td>
<p>character variable with the name of the file to read.  The
file must be in SAS XPORT format.</p>
</td></tr>
<tr><td><code id="read.xport_+3A_...">...</code></td>
<td>
<p>passed to <code><a href="base.html#topic+as.data.frame">as.data.frame</a></code> when creating the data
frames.</p>
</td></tr> 
</table>


<h3>Value</h3>

<p>If there is a more than one dataset in the XPORT format library, a named
list of data frames, otherwise a data frame.  The columns of the data
frames will be either numeric (corresponding to numeric in SAS) or
factor (corresponding to character in SAS).  All SAS numeric missing
values (including special missing values represented by <code>._</code>,
<code>.A</code> to <code>.Z</code> by SAS) are mapped to <span class="rlang"><b>R</b></span> <code>NA</code>.
</p>
<p>Trailing blanks are removed from character columns before conversion to
a factor.  Some sources claim that character missing values in SAS are
represented by <code>' '</code> or <code>''</code>: these are not treated as <span class="rlang"><b>R</b></span>
missing values.
</p>


<h3>Author(s)</h3>

<p>Saikat DebRoy <a href="mailto:saikat@stat.wisc.edu">saikat@stat.wisc.edu</a></p>


<h3>References</h3>

<p>SAS Technical Support document TS-140:
&ldquo;The Record Layout of a Data Set in SAS Transport (XPORT) Format&rdquo;
available at
<a href="https://support.sas.com/content/dam/SAS/support/en/technical-papers/record-layout-of-a-sas-version-5-or-6-data-set-in-sas-transport-xport-format.pdf">https://support.sas.com/content/dam/SAS/support/en/technical-papers/record-layout-of-a-sas-version-5-or-6-data-set-in-sas-transport-xport-format.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lookup.xport">lookup.xport</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: ## no XPORT file is installed
read.xport("test.xpt")

## End(Not run)
</code></pre>

<hr>
<h2 id='S3+20read+20functions'>Read an S3 Binary or data.dump File</h2><span id='topic+data.restore'></span><span id='topic+read.S'></span>

<h3>Description</h3>

<p>Reads binary data files or <code>data.dump</code> files that were produced
in S version 3.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  data.restore(file, print = FALSE, verbose = FALSE, env = .GlobalEnv)
  read.S(file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="S3+2B20read+2B20functions_+3A_file">file</code></td>
<td>
<p>the filename of the S-PLUS <code>data.dump</code> or binary
file.</p>
</td></tr>
<tr><td><code id="S3+2B20read+2B20functions_+3A_print">print</code></td>
<td>
<p>whether to print the name of each object as read from the
file.</p>
</td></tr>
<tr><td><code id="S3+2B20read+2B20functions_+3A_verbose">verbose</code></td>
<td>
<p>whether to print the name of every subitem within each
object.</p>
</td></tr>
<tr><td><code id="S3+2B20read+2B20functions_+3A_env">env</code></td>
<td>
<p>environment within which to create the restored object(s).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>read.S</code> can read the binary files produced in some older
versions of S-PLUS on either Windows (versions 3.x, 4.x, 2000) or Unix
(version 3.x with 4 byte integers).  It automatically detects whether
the file was produced on a big- or little-endian machine and adapts
itself accordingly.
</p>
<p><code>data.restore</code> can read a similar range of files produced by
<code>data.dump</code> and for newer versions of S-PLUS, those from
<code>data.dump(....., oldStyle=TRUE)</code>.
</p>
<p>Not all S3 objects can be handled in the current version.  The most
frequently encountered exceptions are functions and expressions; you
will also have trouble with objects that contain model formulas.  In
particular, comments will be lost from function bodies, and the
argument lists of functions will often be changed.
</p>


<h3>Value</h3>

<p>For <code>read.S</code>, an R version of the S3 object.
</p>
<p>For <code>data.restore</code>, the name of the file.
</p>


<h3>Author(s)</h3>

<p>Duncan Murdoch
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## if you have an S-PLUS _Data file containing 'myobj'
## Not run: read.S(file.path("_Data", "myobj"))
data.restore("dumpdata", print = TRUE)

## End(Not run)</code></pre>

<hr>
<h2 id='write.arff'>Write Data into ARFF Files</h2><span id='topic+write.arff'></span>

<h3>Description</h3>

<p>Writes data into Weka Attribute-Relation File Format (ARFF) files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.arff(x, file, eol = "\n", relation = deparse(substitute(x)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write.arff_+3A_x">x</code></td>
<td>
<p>the data to be written, preferably a matrix or data frame.
If not, coercion to a data frame is attempted.</p>
</td></tr>
<tr><td><code id="write.arff_+3A_file">file</code></td>
<td>
<p>either a character string naming a file, or a connection.
<code>""</code> indicates output to the standard output connection.</p>
</td></tr>
<tr><td><code id="write.arff_+3A_eol">eol</code></td>
<td>
<p>the character(s) to print at the end of each line (row).</p>
</td></tr>
<tr><td><code id="write.arff_+3A_relation">relation</code></td>
<td>
<p>The name of the relation to be written in the file.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>relation</code> will be passed through <code><a href="base.html#topic+make.names">make.names</a></code> before
writing to the file, in an attempt to it them acceptable to Weka, and
column names what do not start with an alphabetic character will have
<code>X</code> prepended.
</p>
<p>However, the references say that ARFF files are ASCII files, and that
encoding is not enforced.
</p>


<h3>References</h3>

<p>Attribute-Relation File Format
<a href="https://waikato.github.io/weka-wiki/formats_and_processing/arff/">https://waikato.github.io/weka-wiki/formats_and_processing/arff/</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.arff">read.arff</a></code>;
functions <code>write.arff</code> and <code>read.arff</code> in package
<span class="pkg">RWeka</span> which provide some support for logicals via conversion to
or from factors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>write.arff(iris, file = "")
</code></pre>

<hr>
<h2 id='write.dbf'>Write a DBF File</h2><span id='topic+write.dbf'></span>

<h3>Description</h3>

<p>The function tries to write a data frame to a DBF file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.dbf(dataframe, file, factor2char = TRUE, max_nchar = 254)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write.dbf_+3A_dataframe">dataframe</code></td>
<td>
<p>a data frame object.</p>
</td></tr>
<tr><td><code id="write.dbf_+3A_file">file</code></td>
<td>
<p>a file name to be written to.</p>
</td></tr>
<tr><td><code id="write.dbf_+3A_factor2char">factor2char</code></td>
<td>
<p>logical, default <code>TRUE</code>, convert factor columns to
character: otherwise they are written as the internal integer codes.</p>
</td></tr>
<tr><td><code id="write.dbf_+3A_max_nchar">max_nchar</code></td>
<td>
<p>The maximum number of characters allowed in a
character field.  Strings which exceed this will be truncated with a
warning.  See Details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Dots in column names are replaced by underlines in the DBF file, and
names are truncated to 11 characters.
</p>
<p>Only vector columns of classes <code>"logical"</code>, <code>"numeric"</code>,
<code>"integer"</code>, <code>"character"</code>, <code>"factor"</code> and
<code>"Date"</code> can be written.  Other columns should be converted to
one of these.
</p>
<p>Maximum precision (number of digits including minus sign and decimal
sign) for numeric is 19 - scale (digits after the decimal sign) which is
calculated internally based on the number of digits before the decimal
sign.
</p>
<p>The original DBASE format limited character fields to 254 bytes.
It is said that Clipper and FoxPro can read up to 32K, and it is
possible to write a reader that could accept up to 65535 bytes.
(The documentation suggests that only ASCII characters can be assumed
to be supported.)  Readers expecting the older standard (which
includes Excel 2003, Access 2003 and OpenOffice 2.0) will truncate the
field to the maximum width modulo 256, so increase <code>max_nchar</code>
only if you are sure the intended reader supports wider character fields.
</p>


<h3>Value</h3>

<p>Invisible <code>NULL</code>.
</p>


<h3>Note</h3>

<p>Other applications have varying abilities to read the data types used
here.  Microsoft Access reads <code>"numeric"</code>, <code>"integer"</code>,
<code>"character"</code> and <code>"Date"</code> fields, including recognizing
missing values, but not <code>"logical"</code> (read as <code>0,-1</code>).
Microsoft Excel understood all possible types but did not interpret missing
values in character fields correctly (showing them as character nuls).
</p>


<h3>Author(s)</h3>

<p>Nicholas J. Lewin-Koh, modified by Roger Bivand and Brian Ripley;
shapelib by Frank Warmerdam.
</p>


<h3>References</h3>

<p><a href="http://shapelib.maptools.org/">http://shapelib.maptools.org/</a>
</p>
<p><a href="https://www.clicketyclick.dk/databases/xbase/format/data_types.html">https://www.clicketyclick.dk/databases/xbase/format/data_types.html</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.dbf">read.dbf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>str(warpbreaks)
try1 &lt;- paste(tempfile(), ".dbf", sep = "")
write.dbf(warpbreaks, try1, factor2char = FALSE)
in1 &lt;- read.dbf(try1)
str(in1)
try2 &lt;- paste(tempfile(), ".dbf", sep = "")
write.dbf(warpbreaks, try2, factor2char = TRUE)
in2 &lt;- read.dbf(try2)
str(in2)
unlink(c(try1, try2))
</code></pre>

<hr>
<h2 id='write.dta'>Write Files in Stata Binary Format</h2><span id='topic+write.dta'></span>

<h3>Description</h3>

<p>Writes the data frame to file in the Stata binary
format.  Does not write array variables unless they can be
<code><a href="base.html#topic+drop">drop</a></code>-ed to a vector.
</p>
<p>Frozen: will not support Stata formats after 10 (also used by Stata 11).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.dta(dataframe, file, version = 7L,
          convert.dates = TRUE, tz = "GMT",
          convert.factors = c("labels", "string", "numeric", "codes"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write.dta_+3A_dataframe">dataframe</code></td>
<td>
<p>a data frame.</p>
</td></tr>
<tr><td><code id="write.dta_+3A_file">file</code></td>
<td>
<p>character string giving filename.</p>
</td></tr>
<tr><td><code id="write.dta_+3A_version">version</code></td>
<td>
<p>integer: Stata version: 6, 7, 8 and 10 are supported,
and 9 is mapped to 8, 11 to 10.</p>
</td></tr>
<tr><td><code id="write.dta_+3A_convert.dates">convert.dates</code></td>
<td>
<p>logical: convert <code>Date</code> and <code>POSIXct</code>
objects: see section &lsquo;Dates&rsquo;.</p>
</td></tr>
<tr><td><code id="write.dta_+3A_tz">tz</code></td>
<td>
<p>timezone for date conversion.</p>
</td></tr>
<tr><td><code id="write.dta_+3A_convert.factors">convert.factors</code></td>
<td>
<p>how to handle factors.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The major difference between supported file formats in Stata versions
is that version 7.0 and later allow 32-character variable names (5 and
6 were restricted to 8-character names).  The <code>abbreviate</code>
function is used to trim variable names to the permitted length.  A
warning is given if this is needed and it is an error for the
abbreviated names not to be unique.  Each version of Stata is claimed
to be able to read all earlier formats.
</p>
<p>The columns in the data frame become variables in the Stata data set.
Missing values are handled correctly.
</p>
<p>There are four options for handling factors.  The default is to use
Stata &lsquo;value labels&rsquo; for the factor levels.  With
<code>convert.factors = "string"</code>, the factor levels are written as
strings (the name of the value label is taken from the
<code>"val.labels"</code> attribute if it exists or the variable name
otherwise).  With <code>convert.factors = "numeric"</code> the numeric values
of the levels are written, or <code>NA</code> if they cannot be coerced to
numeric.  Finally, <code>convert.factors = "codes"</code> writes the
underlying integer codes of the factors.  This last used to be the
only available method and is provided largely for backwards
compatibility.
</p>
<p>If the <code>"label.table"</code> attribute contains value labels with
names not already attached to a variable (not the variable name or
name from <code>"val.labels"</code>) then these will be written out as well.
</p>
<p>If the <code>"datalabel"</code> attribute contains a string, it is written out
as the dataset label otherwise the dataset label is <code>"Written by R."</code>.
</p>
<p>If the <code>"expansion.table"</code> attribute exists expansion fields are
written.  This attribute should contain a <code><a href="base.html#topic+list">list</a></code> where each element is
<code><a href="base.html#topic+character">character</a></code> vector of length three.  The first vector element contains the
name of a variable or &quot;_dta&quot; (meaning the dataset). The second element
contains the characeristic name. The third contains the associated data.
</p>
<p>If the <code>"val.labels"</code> attribute contains a <code><a href="base.html#topic+character">character</a></code> vector with a
string label for each value then this is written as the value
labels.  Otherwise the variable names are used. 
</p>
<p>If the <code>"var.labels"</code> attribute contains a <code><a href="base.html#topic+character">character</a></code> vector with a
string label for each variable then this is written as the variable
labels.  Otherwise the variable names are repeated as variable labels.
</p>
<p>For Stata 8 or later use the default <code>version = 7</code> &ndash; the only
advantage of Stata 8 format over 7 is that it can represent multiple
different missing value types, and <span class="rlang"><b>R</b></span> doesn't have them.  Stata 10/11
allows longer format lists, but <span class="rlang"><b>R</b></span> does not make use of them.
</p>
<p>Note that the Stata formats are documented to use ASCII strings &ndash;
<span class="rlang"><b>R</b></span> does not enforce this, but use of non-ASCII character strings will
not be portable as the encoding is not recorded.  Up to 244 bytes are
allowed in character data, and longer strings will be truncated with a
warning.
</p>
<p>Stata uses some large numerical values to represent missing
values.  This function does not currently check, and hence integers
greater than <code>2147483620</code> and doubles greater than
<code>8.988e+307</code> may be misinterpreted by Stata.
</p>


<h3>Value</h3>

<p><code>NULL</code>
</p>


<h3>Dates</h3>

<p>Unless disabled by argument <code>convert.dates = FALSE</code>, <span class="rlang"><b>R</b></span> date and
date-time objects (<code>POSIXt</code> classes) are converted into the Stata
date format, the number of days since 1960-01-01.  (For date-time
objects this may lose information.)  Stata can be told that these are
dates by </p>
<pre>format xdate %td;</pre>
<p>It is possible to pass objects of class <code>POSIXct</code> to Stata to be
treated as one of its versions of date-times.  Stata uses the number
of milliseconds since 1960-01-01, either excluding (format
<code>%tc</code>) or counting (format <code>%tC</code>) leap seconds.  So
either an object of class <code>POSICct</code> can be passed to Stata with
<code>convert.dates = FALSE</code> and converted in Stata, or
<code>315619200</code> should be added and then multiplied by <code>1000</code>
before passing to <code>write.dta</code> and assigning format <code>%tc</code>.
Stata's comments on the first route are at
<a href="https://www.stata.com/manuals13/ddatetime.pdf">https://www.stata.com/manuals13/ddatetime.pdf</a>, but at the time of
writing were wrong: <span class="rlang"><b>R</b></span> uses POSIX conventions and hence does not count
leap seconds.
</p>


<h3>Author(s)</h3>

<p>Thomas Lumley and R-core members: support for value labels by
Brian Quistorff.
</p>


<h3>References</h3>

<p>Stata 6.0 Users Manual, Stata 7.0 Programming manual, Stata online
help (version 8 and later, also <a href="https://www.stata.com/help.cgi?dta_114">https://www.stata.com/help.cgi?dta_114</a>
and <a href="https://www.stata.com/help.cgi?dta_113">https://www.stata.com/help.cgi?dta_113</a>) describe the file formats.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.dta">read.dta</a></code>,
<code><a href="base.html#topic+attributes">attributes</a></code>,
<code><a href="base.html#topic+DateTimeClasses">DateTimeClasses</a></code>,
<code><a href="base.html#topic+abbreviate">abbreviate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>write.dta(swiss, swissfile &lt;- tempfile())
read.dta(swissfile)
</code></pre>

<hr>
<h2 id='write.foreign'>Write Text Files and Code to Read Them</h2><span id='topic+write.foreign'></span>

<h3>Description</h3>

<p>This function exports simple data frames to other statistical packages by
writing the data as free-format text and writing a separate file of
instructions for the other package to read the data. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.foreign(df, datafile, codefile,
              package = c("SPSS", "Stata", "SAS"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write.foreign_+3A_df">df</code></td>
<td>
<p>A data frame</p>
</td></tr>
<tr><td><code id="write.foreign_+3A_datafile">datafile</code></td>
<td>
<p>Name of file for data output</p>
</td></tr>
<tr><td><code id="write.foreign_+3A_codefile">codefile</code></td>
<td>
<p>Name of file for code output</p>
</td></tr>
<tr><td><code id="write.foreign_+3A_package">package</code></td>
<td>
<p>Name of package</p>
</td></tr>
<tr><td><code id="write.foreign_+3A_...">...</code></td>
<td>
<p>Other arguments for the individual <code>writeForeign</code>
functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The work for this function is done by
<code>foreign:::writeForeignStata</code>, <code>foreign:::writeForeignSAS</code> and
<code>foreign:::writeForeignSPSS</code>.  To add support for another package,
eg Systat, create a function <code>writeForeignSystat</code> with the same first
three arguments as <code>write.foreign</code>. This will be called from
<code>write.foreign</code> when <code>package="Systat"</code>.
</p>
<p>Numeric variables and factors are supported for all packages: dates and
times (<code>Date</code>, <code>dates</code>, <code>date</code>, and <code>POSIXt</code>
classes) and logical vectors are also supported for SAS and characters
are supported for SPSS.
</p>
<p>For <code>package="SAS"</code> there are optional arguments
<code>dataname = "rdata"</code> taking a string that will be the SAS data set
name, <code>validvarname</code> taking either <code>"V6"</code> or <code>"V7"</code>,
and <code>libpath = NULL</code> taking a string that will be the directory where
the target SAS datset will be written when the generated SAS code been
run.
</p>
<p>For <code>package="SPSS"</code> there is an optional argument <code>maxchars = 32L</code> 
taking an integer that causes the variable names (not variable labels) 
to be abbreviated to not more than <code>maxchars</code> chars.
For compatibility with SPSS version 12 and before, change this to <code>maxchars = 8L</code>.
In single byte locales with SPSS versions 13 or later, this can be set to <code>maxchars = 64L</code>.
</p>
<p>For <code>package="SPSS"</code>, as a side effect, the decimal indicator is always set by 
<code>SET DECIMAL=DOT.</code> which may override user settings of the indicator or its default 
derived from the current locale.
</p>


<h3>Value</h3>

<p>Invisible <code>NULL</code>.
</p>


<h3>Author(s)</h3>

<p>Thomas Lumley and Stephen Weigand
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
datafile &lt;- tempfile()
codefile &lt;- tempfile()
write.foreign(esoph, datafile, codefile, package="SPSS")
file.show(datafile)
file.show(codefile)
unlink(datafile)
unlink(codefile)

## End(Not run)</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
