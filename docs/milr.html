<!DOCTYPE html><html lang="en"><head><title>Help for package milr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {milr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#milr-package'><p>The milr package: multiple-instance logistic regression with lasso penalty</p></a></li>
<li><a href='#DGP'><p>DGP: data generation</p></a></li>
<li><a href='#fitted.milr'><p>Fitted Response of milr Fits</p></a></li>
<li><a href='#fitted.softmax'><p>Fitted Response of softmax Fits</p></a></li>
<li><a href='#logit'><p>logit link function</p></a></li>
<li><a href='#milr'><p>Maximum likelihood estimation of multiple-instance logistic regression with LASSO penalty</p></a></li>
<li><a href='#predict.milr'><p>Predict Method for milr Fits</p></a></li>
<li><a href='#predict.softmax'><p>Predict Method for softmax Fits</p></a></li>
<li><a href='#softmax'><p>Multiple-instance logistic regression via softmax function</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Multiple-Instance Logistic Regression with LASSO Penalty</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-10-28</td>
</tr>
<tr>
<td>Description:</td>
<td>The multiple instance data set consists of many independent
    subjects (called bags) and each subject is composed of several components
    (called instances). The outcomes of such data set are binary or categorical responses,
    and, we can only observe the subject-level outcomes. For example, in manufacturing
    processes, a subject is labeled as "defective" if at least one of its own
    components is defective, and otherwise, is labeled as "non-defective". The
    'milr' package focuses on the predictive model for the multiple instance
    data set with binary outcomes and performs the maximum likelihood estimation
    with the Expectation-Maximization algorithm under the framework of logistic
    regression. Moreover, the LASSO penalty is attached to the likelihood function
    for simultaneous parameter estimation and variable selection.</td>
</tr>
<tr>
<td>Author:</td>
<td>Ping-Yang Chen [aut, cre],
  ChingChuan Chen [aut],
  Chun-Hao Yang [aut],
  Sheng-Mao Chang [aut]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/PingYangChen/milr">https://github.com/PingYangChen/milr</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/PingYangChen/milr/issues">https://github.com/PingYangChen/milr/issues</a></td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ping-Yang Chen &lt;pychen.ping@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2.3)</td>
</tr>
<tr>
<td>Imports:</td>
<td>utils, pipeR (&ge; 0.5), numDeriv, glmnet, Rcpp (&ge; 0.12.0),
RcppParallel</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo, RcppParallel</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, knitr, Hmisc, rmarkdown, data.table, ggplot2, plyr</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>GNU make</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-10-28 09:52:41 UTC; rbchen</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-10-31 07:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='milr-package'>The milr package: multiple-instance logistic regression with lasso penalty</h2><span id='topic+milr-package'></span>

<h3>Description</h3>

<p>The multiple instance data set consists of many independent subjects (called bags) 
and each subject is composed of several components (called instances). The outcomes 
of such data set are binary or multinomial, and, we can only observe the subject-level 
outcomes. For example, in manufactory processes, a subject is labeled as &quot;defective&quot; 
if at least one of its own components is defective, and otherwise, is labeled as 
&quot;non-defective&quot;.  The milr package focuses on the predictive model for the multiple 
instance data set with binary outcomes and performs the maximum likelihood estimation 
with the Expectation-Maximization algorithm under the framework of logistic regression.  
Moreover, the LASSO penalty is attached to the likelihood function for simultaneous parameter 
estimation and variable selection.
</p>


<h3>References</h3>


<ol>
<li><p> Chen, R.-B., Cheng, K.-H., Chang, S.-M., Jeng, S.-L., Chen, P.-Y., Yang, C.-H., 
and Hsia, C.-C. (2016). Multiple-Instance Logistic Regression with LASSO Penalty. arXiv:1607.03615 [stat.ML].
</p>
</li></ol>


<hr>
<h2 id='DGP'>DGP: data generation</h2><span id='topic+DGP'></span>

<h3>Description</h3>

<p>Generating the multiple-instance data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DGP(n, m, beta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DGP_+3A_n">n</code></td>
<td>
<p>an integer. The number of bags.</p>
</td></tr>
<tr><td><code id="DGP_+3A_m">m</code></td>
<td>
<p>an integer or vector of length <code>n</code>. If <code>m</code> is an integer, each bag has the identical number of instances, <code>m</code>. 
If <code>m</code> is a vector, the <code>i</code>th bag has <code>m[i]</code> instances.</p>
</td></tr>
<tr><td><code id="DGP_+3A_beta">beta</code></td>
<td>
<p>a vector. The true regression coefficients.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list including (1) bag-level labels, <code>Z</code>, (2) the design matrix, <code>X</code>, and (3) bag ID of each instance, <code>ID</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data1 &lt;- DGP(50, 3, runif(10, -5, 5))
data2 &lt;- DGP(50, sample(3:5, 50, TRUE), runif(10, -5, 5))
</code></pre>

<hr>
<h2 id='fitted.milr'>Fitted Response of milr Fits</h2><span id='topic+fitted.milr'></span>

<h3>Description</h3>

<p>Fitted Response of milr Fits
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'milr'
fitted(object, type = "bag", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitted.milr_+3A_object">object</code></td>
<td>
<p>A fitted obejct of class inheriting from <code>"milr"</code>.</p>
</td></tr>
<tr><td><code id="fitted.milr_+3A_type">type</code></td>
<td>
<p>The type of fitted response required. Default is <code>"bag"</code>, the fitted labels of bags.
The <code>"instance"</code> option returns the fitted labels of instances.</p>
</td></tr>
<tr><td><code id="fitted.milr_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>

<hr>
<h2 id='fitted.softmax'>Fitted Response of softmax Fits</h2><span id='topic+fitted.softmax'></span>

<h3>Description</h3>

<p>Fitted Response of softmax Fits
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'softmax'
fitted(object, type = "bag", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitted.softmax_+3A_object">object</code></td>
<td>
<p>A fitted obejct of class inheriting from <code>"softmax"</code>.</p>
</td></tr>
<tr><td><code id="fitted.softmax_+3A_type">type</code></td>
<td>
<p>The type of fitted response required. Default is <code>"bag"</code>, the fitted labels of bags.
The <code>"instance"</code> option returns the fitted labels of instances.</p>
</td></tr>
<tr><td><code id="fitted.softmax_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>

<hr>
<h2 id='logit'>logit link function</h2><span id='topic+logit'></span>

<h3>Description</h3>

<p>calculate the values of logit link
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logit(X, beta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logit_+3A_x">X</code></td>
<td>
<p>A matrix, the design matrix.</p>
</td></tr>
<tr><td><code id="logit_+3A_beta">beta</code></td>
<td>
<p>A vector, the coefficients.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An vector of the values of logit link.
</p>

<hr>
<h2 id='milr'>Maximum likelihood estimation of multiple-instance logistic regression with LASSO penalty</h2><span id='topic+milr'></span>

<h3>Description</h3>

<p>Please refer to <a href="#topic+milr-package">milr-package</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>milr(
  y,
  x,
  bag,
  lambda = 0,
  numLambda = 20L,
  lambdaCriterion = "BIC",
  nfold = 10L,
  maxit = 500L
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="milr_+3A_y">y</code></td>
<td>
<p>a vector. Bag-level binary labels.</p>
</td></tr>
<tr><td><code id="milr_+3A_x">x</code></td>
<td>
<p>the design matrix. The number of rows of <code>x</code> must be equal to the length of <code>y</code>.</p>
</td></tr>
<tr><td><code id="milr_+3A_bag">bag</code></td>
<td>
<p>a vector, bag id.</p>
</td></tr>
<tr><td><code id="milr_+3A_lambda">lambda</code></td>
<td>
<p>the tuning parameter for LASSO-penalty.  If <code>lambda</code> is a real value number, then the <code>milr</code> 
fits the model based on this lambda value.  Second, if <code>lambda</code> is vector, then the optimal lambda value would be
be chosen based on the optimality criterion, <code>lambdaCriterion</code>.  
Finally, if <code>lambda = -1</code>, then the optimal lambda value would be chosen automatically.
The default is 0.</p>
</td></tr>
<tr><td><code id="milr_+3A_numlambda">numLambda</code></td>
<td>
<p>An integer, the maximum length of LASSO-penalty. in atuo-tunning mode 
(<code>lambda = -1</code>). The default is 20.</p>
</td></tr>
<tr><td><code id="milr_+3A_lambdacriterion">lambdaCriterion</code></td>
<td>
<p>a string, the used optimality criterion for tuning the <code>lambda</code> value.
It can be specified with <code>lambdaCriterion = "BIC"</code> or <code>lambdaCriterion = "deviance"</code>.</p>
</td></tr>
<tr><td><code id="milr_+3A_nfold">nfold</code></td>
<td>
<p>an integer, the number of fold for cross-validation to choose the optimal <code>lambda</code> when
<code>lambdaCriterion = "deviance"</code>.</p>
</td></tr>
<tr><td><code id="milr_+3A_maxit">maxit</code></td>
<td>
<p>an integer, the maximum iteration for the EM algorithm. The default is 500.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object with S3 class &quot;milr&quot;.
</p>

<ul>
<li><p>lambdaa vector of candidate lambda values.
</p>
</li>
<li><p>cva vector of predictive deviance via <code>nfold</code>-fold cross validation
when <code>lambdaCriterion = "deviance"</code>.
</p>
</li>
<li><p>deviancea vector of deviance of candidate model for each candidate lambda value.
</p>
</li>
<li><p>BICa vector of BIC of candidate model for each candidate lambda value.
</p>
</li>
<li><p>best_indexan integer, indicates the index of the best model among candidate lambda values.
</p>
</li>
<li><p>best_modela list of the information for the best model including deviance (not cv deviance), 
BIC, chosen lambda, coefficients, fitted values, log-likelihood and variances of coefficients.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>set.seed(100)
beta &lt;- runif(5, -5, 5)
trainData &lt;- DGP(40, 3, beta)
testData &lt;- DGP(5, 3, beta)
# default (not use LASSO)
milr_result &lt;- milr(trainData$Z, trainData$X, trainData$ID)
coef(milr_result)      # coefficients
fitted(milr_result)                    # fitted bag labels
fitted(milr_result, type = "instance") # fitted instance labels
summary(milr_result)   # summary milr
predict(milr_result, testData$X, testData$ID)                    # predicted bag labels
predict(milr_result, testData$X, testData$ID, type = "instance") # predicted instance labels

# use BIC to choose penalty (not run)
#milr_result &lt;- milr(trainData$Z, trainData$X, trainData$ID,
#                    exp(seq(log(0.01), log(50), length = 30)))
#coef(milr_result)      # coefficients
#fitted(milr_result)                    # fitted bag labels
#fitted(milr_result, type = "instance") # fitted instance labels
#summary(milr_result)   # summary milr
#predict(milr_result, testData$X, testData$ID)                    # predicted bag labels
#predict(milr_result, testData$X, testData$ID, type = "instance") # predicted instance labels

# use auto-tuning (not run)
#milr_result &lt;- milr(trainData$Z, trainData$X, trainData$ID, lambda = -1, numLambda = 20)
#coef(milr_result)      # coefficients
#fitted(milr_result)                    # fitted bag labels
#fitted(milr_result, type = "instance") # fitted instance labels
#summary(milr_result)   # summary milr
#predict(milr_result, testData$X, testData$ID)                    # predicted bag labels
#predict(milr_result, testData$X, testData$ID, type = "instance") # predicted instance labels

# use cv in auto-tuning (not run)
#milr_result &lt;- milr(trainData$Z, trainData$X, trainData$ID, 
#                    lambda = -1, numLambda = 20, lambdaCriterion = "deviance")
#coef(milr_result)      # coefficients
#fitted(milr_result)                    # fitted bag labels
#fitted(milr_result, type = "instance") # fitted instance labels
#summary(milr_result)   # summary milr
#predict(milr_result, testData$X, testData$ID)                    # predicted bag labels
#predict(milr_result, testData$X, testData$ID, type = "instance") # predicted instance labels
</code></pre>

<hr>
<h2 id='predict.milr'>Predict Method for milr Fits</h2><span id='topic+predict.milr'></span>

<h3>Description</h3>

<p>Predict Method for milr Fits
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'milr'
predict(object, newdata = NULL, bag_newdata = NULL, type = "bag", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.milr_+3A_object">object</code></td>
<td>
<p>A fitted obejct of class inheriting from <code>"milr"</code>.</p>
</td></tr>
<tr><td><code id="predict.milr_+3A_newdata">newdata</code></td>
<td>
<p>Default is <code>NULL</code>. A matrix with variables to predict.</p>
</td></tr>
<tr><td><code id="predict.milr_+3A_bag_newdata">bag_newdata</code></td>
<td>
<p>Default is <code>NULL</code>. A vector. The labels of instances to bags.
If <code>newdata</code> and <code>bag_newdata</code> both are <code>NULL</code>, return the fitted result.</p>
</td></tr>
<tr><td><code id="predict.milr_+3A_type">type</code></td>
<td>
<p>The type of prediction required. Default is <code>"bag"</code>, the predicted labels of bags.
The <code>"instance"</code> option returns the predicted labels of instances.</p>
</td></tr>
<tr><td><code id="predict.milr_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>

<hr>
<h2 id='predict.softmax'>Predict Method for softmax Fits</h2><span id='topic+predict.softmax'></span>

<h3>Description</h3>

<p>Predict Method for softmax Fits
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'softmax'
predict(object, newdata = NULL, bag_newdata = NULL, type = "bag", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.softmax_+3A_object">object</code></td>
<td>
<p>A fitted obejct of class inheriting from <code>"softmax"</code>.</p>
</td></tr>
<tr><td><code id="predict.softmax_+3A_newdata">newdata</code></td>
<td>
<p>Default is <code>NULL</code>. A matrix with variables to predict.</p>
</td></tr>
<tr><td><code id="predict.softmax_+3A_bag_newdata">bag_newdata</code></td>
<td>
<p>Default is <code>NULL</code>.  A vector. The labels of instances to bags.
If <code>newdata</code> and <code>bag_newdata</code> both are <code>NULL</code>, return the fitted result.</p>
</td></tr>
<tr><td><code id="predict.softmax_+3A_type">type</code></td>
<td>
<p>The type of prediction required. Default is <code>"bag"</code>, the predicted labels of bags.
The <code>"instance"</code> option returns the predicted labels of instances.</p>
</td></tr>
<tr><td><code id="predict.softmax_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>

<hr>
<h2 id='softmax'>Multiple-instance logistic regression via softmax function</h2><span id='topic+softmax'></span>

<h3>Description</h3>

<p>This function calculates the alternative maximum likelihood estimation for 
multiple-instance logistic regression
through a softmax function (Xu and Frank, 2004; Ray and Craven, 2005).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>softmax(y, x, bag, alpha = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="softmax_+3A_y">y</code></td>
<td>
<p>a vector. Bag-level binary labels.</p>
</td></tr>
<tr><td><code id="softmax_+3A_x">x</code></td>
<td>
<p>the design matrix. The number of rows of <code>x</code> must be equal to the length of <code>y</code>.</p>
</td></tr>
<tr><td><code id="softmax_+3A_bag">bag</code></td>
<td>
<p>a vector, bag id.</p>
</td></tr>
<tr><td><code id="softmax_+3A_alpha">alpha</code></td>
<td>
<p>A non-negative realnumber, the softmax parameter.</p>
</td></tr>
<tr><td><code id="softmax_+3A_...">...</code></td>
<td>
<p>arguments to be passed to the <code>optim</code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list including coefficients and fitted values.
</p>


<h3>References</h3>


<ol>
<li><p> S. Ray, and M. Craven. (2005) Supervised versus multiple instance learning: 
An empirical comparsion. in Proceedings of the 22nd International Conference on 
Machine Learnings, ACM, 697&ndash;704.
</p>
</li>
<li><p> X. Xu, and E. Frank. (2004) Logistic regression and boosting for labeled bags 
of instances. in Advances in Knowledge Discovery and Data Mining, Springer, 272&ndash;281.
</p>
</li></ol>



<h3>Examples</h3>

<pre><code class='language-R'>set.seed(100)
beta &lt;- runif(10, -5, 5)
trainData &lt;- DGP(40, 3, beta)
testData &lt;- DGP(5, 3, beta)
# Fit softmax-MILR model S(0)
softmax_result &lt;- softmax(trainData$Z, trainData$X, trainData$ID, alpha = 0)
coef(softmax_result)      # coefficients
fitted(softmax_result)                    # fitted bag labels
fitted(softmax_result, type = "instance") # fitted instance labels
predict(softmax_result, testData$X, testData$ID)                    # predicted bag labels
predict(softmax_result, testData$X, testData$ID, type = "instance") # predicted instance labels
# Fit softmax-MILR model S(3) (not run)
# softmax_result &lt;- softmax(trainData$Z, trainData$X, trainData$ID, alpha = 3)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
