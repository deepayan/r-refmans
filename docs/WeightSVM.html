<!DOCTYPE html><html lang="en"><head><title>Help for package WeightSVM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {WeightSVM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#plot.tune_wsvm'><p>Plot Tuning Object</p></a></li>
<li><a href='#plot.wsvm'><p>Plot WSVM Objects</p></a></li>
<li><a href='#predict.wsvm'><p>Predict Method for Subject Weighted Support Vector Machines</p></a></li>
<li><a href='#tune_wsvm'><p>Parameter Tuning of Functions Using Grid Search</p></a></li>
<li><a href='#tune.control'><p>Control Parameters for the tune/tune_wsvm Function</p></a></li>
<li><a href='#wsvm'><p>Subject Weighted Support Vector Machines</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>1.7-16</td>
</tr>
<tr>
<td>Title:</td>
<td>Subject Weighted Support Vector Machines</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, grDevices, stats, methods, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>SparseM, xtable, Matrix, MASS, e1071, knitr, slam, kernlab</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Tianchen Xu &lt;tx2155@columbia.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions for subject/instance weighted support vector machines (SVM). 
    It uses a modified version of 'libsvm' and is compatible with package 'e1071'. It also allows user defined kernel matrix.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/#weights_for_data_instances">https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/#weights_for_data_instances</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/zjph602xtc/wsvm/issues">https://github.com/zjph602xtc/wsvm/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-10-12 01:53:38 UTC; Peter Xu</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-10-12 03:30:02 UTC</td>
</tr>
<tr>
<td>Author:</td>
<td>Tianchen Xu <a href="https://orcid.org/0000-0002-0102-7630"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Chih-Chung Chang [ctb, cph] (libsvm C++-code),
  Chih-Chen Lin [ctb, cph] (libsvm C++-code),
  Ming-Wei Chang [ctb, cph] (libsvm C++-code),
  Hsuan-Tien Lin [ctb, cph] (libsvm C++-code),
  Ming-Hen Tsai [ctb, cph] (libsvm C++-code),
  Chia-Hua Ho [ctb, cph] (libsvm C++-code),
  Hsiang-Fu Yu [ctb, cph] (libsvm C++-code),
  David Meyer [ctb],
  Evgenia Dimitriadou [ctb],
  Kurt Hornik [ctb],
  Andreas Weingessel [ctb],
  Friedrich Leisch [ctb]</td>
</tr>
</table>
<hr>
<h2 id='plot.tune_wsvm'>Plot Tuning Object</h2><span id='topic+plot.tune_wsvm'></span>

<h3>Description</h3>

<p>Visualizes the results of parameter tuning.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tune_wsvm'
plot(x, type = c("contour", "perspective"), theta = 60,
          col = "lightblue", main = NULL, xlab = NULL, ylab = NULL,
          swapxy = FALSE, transform.x = NULL, transform.y = NULL,
          transform.z = NULL, color.palette = hsv_palette(),
          nlevels = 20, ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.tune_wsvm_+3A_x">x</code></td>
<td>
<p>an object of class <code>tune_wsvm</code></p>
</td></tr>
<tr><td><code id="plot.tune_wsvm_+3A_type">type</code></td>
<td>
<p>choose whether a contour plot or a perspective plot is
used if two parameters are to be visualized. Ignored if only one
parameter has been tuned.</p>
</td></tr>
<tr><td><code id="plot.tune_wsvm_+3A_theta">theta</code></td>
<td>
<p>angle of azimuthal direction.</p>
</td></tr>
<tr><td><code id="plot.tune_wsvm_+3A_col">col</code></td>
<td>
<p>the color(s) of the surface facets.  Transparent colors are
ignored.</p>
</td></tr>
<tr><td><code id="plot.tune_wsvm_+3A_main">main</code></td>
<td>
<p>main title.</p>
</td></tr>
<tr><td><code id="plot.tune_wsvm_+3A_xlab">xlab</code>, <code id="plot.tune_wsvm_+3A_ylab">ylab</code></td>
<td>
<p>titles for the axes.  N.B. These must be character
strings; expressions are not accepted.  Numbers will be
coerced to character strings.</p>
</td></tr>
<tr><td><code id="plot.tune_wsvm_+3A_swapxy">swapxy</code></td>
<td>
<p>if <code>TRUE</code>, the parameter axes are swaped (only used
in case of two parameters).</p>
</td></tr>
<tr><td><code id="plot.tune_wsvm_+3A_transform.x">transform.x</code>, <code id="plot.tune_wsvm_+3A_transform.y">transform.y</code>, <code id="plot.tune_wsvm_+3A_transform.z">transform.z</code></td>
<td>
<p>functions to transform
the parameters (<code>x</code> and <code>y</code>) and the error measures
(<code>z</code>). Ignored if <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plot.tune_wsvm_+3A_color.palette">color.palette</code></td>
<td>
<p>color palette used in contour plot.</p>
</td></tr>
<tr><td><code id="plot.tune_wsvm_+3A_nlevels">nlevels</code></td>
<td>
<p>number of levels used in contour plot.</p>
</td></tr>
<tr><td><code id="plot.tune_wsvm_+3A_...">...</code></td>
<td>
<p>Further graphics parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None</p>


<h3>Author(s)</h3>

<p>David Meyer (based on C/C++-code by Chih-Chung Chang and Chih-Jen Lin)<br />
Modified by Tianchen Xu <a href="mailto:tx2155@columbia.edu">tx2155@columbia.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+tune_wsvm">tune_wsvm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)

obj &lt;- tune_wsvm(Species~., weight = c(rep(0.8, 50),rep(1,100)),
            data = iris, ranges = list(gamma = 2^(-1:1), cost = 2^(2:4)),
            tunecontrol = tune.control(sampling = "fix"))

summary(obj)
plot(obj, transform.x = log2, transform.y = log2)
plot(obj, type = "perspective", theta = 120, phi = 45)
</code></pre>

<hr>
<h2 id='plot.wsvm'>Plot WSVM Objects</h2><span id='topic+plot.wsvm'></span>

<h3>Description</h3>

<p>Generates a scatter plot of the input data of a <code>wsvm</code> fit for
classification models by highlighting the classes and support
vectors. Optionally, draws a filled contour plot of the class regions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'wsvm'
plot(x, data, formula, fill = TRUE, grid = 50, slice = list(),
symbolPalette = palette(), svSymbol = "x", dataSymbol = "o", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.wsvm_+3A_x">x</code></td>
<td>
<p>An object of class <code>wsvm</code></p>
</td></tr>
<tr><td><code id="plot.wsvm_+3A_data">data</code></td>
<td>
<p>data to visualize. Should be the same used for fitting.</p>
</td></tr>
<tr><td><code id="plot.wsvm_+3A_formula">formula</code></td>
<td>
<p>formula selecting the visualized two dimensions. Only
needed if more than two input variables are used.</p>
</td></tr>
<tr><td><code id="plot.wsvm_+3A_fill">fill</code></td>
<td>
<p>switch indicating whether a contour plot for the class
regions should be added.</p>
</td></tr>
<tr><td><code id="plot.wsvm_+3A_grid">grid</code></td>
<td>
<p>granularity for the contour plot.</p>
</td></tr>
<tr><td><code id="plot.wsvm_+3A_slice">slice</code></td>
<td>
<p>a list of named values for the dimensions held
constant (only needed if more than two variables are
used). The defaults for unspecified dimensions are 0 (for numeric
variables) and the first level (for factors). Factor levels can
either be specified as factors or character vectors of length 1.</p>
</td></tr>
<tr><td><code id="plot.wsvm_+3A_symbolpalette">symbolPalette</code></td>
<td>
<p>Color palette used for the class the data points and support
vectors belong to.</p>
</td></tr>
<tr><td><code id="plot.wsvm_+3A_svsymbol">svSymbol</code></td>
<td>
<p>Symbol used for support vectors.</p>
</td></tr>
<tr><td><code id="plot.wsvm_+3A_datasymbol">dataSymbol</code></td>
<td>
<p>Symbol used for data points (other than support vectors).</p>
</td></tr>
<tr><td><code id="plot.wsvm_+3A_...">...</code></td>
<td>
<p>additional graphics parameters passed to
<code>filled.contour</code> and <code>plot</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None</p>


<h3>Author(s)</h3>

<p>David Meyer <br />
Modified by Tianchen Xu <a href="mailto:tx2155@columbia.edu">tx2155@columbia.edu</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+wsvm">wsvm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## a simple example
data(cats, package = "MASS")
m &lt;- wsvm(Sex~., data = cats, weight = rep(1,144))
plot(m, cats)

## more than two variables: fix 2 dimensions
data(iris)
m2 &lt;- wsvm(Species~., data = iris, weight = rep(1,150))
plot(m2, iris, Petal.Width ~ Petal.Length,
     slice = list(Sepal.Width = 3, Sepal.Length = 4))

## plot with custom symbols and colors
plot(m, cats, svSymbol = 1, dataSymbol = 2, symbolPalette = rainbow(4),
color.palette = terrain.colors)
</code></pre>

<hr>
<h2 id='predict.wsvm'>Predict Method for Subject Weighted Support Vector Machines</h2><span id='topic+predict.wsvm'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by <code>wsvm</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'wsvm'
predict(object, newdata, decision.values = FALSE,
probability = FALSE, ..., na.action = na.omit)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.wsvm_+3A_object">object</code></td>
<td>
<p>Object of class <code>"wsvm"</code>, created by <code>wsvm</code>.</p>
</td></tr>
<tr><td><code id="predict.wsvm_+3A_newdata">newdata</code></td>
<td>
<p>An object containing the new input data: either a
matrix or a sparse matrix (object of class
<code><a href="Matrix.html#topic+Matrix">Matrix</a></code> provided by the <span class="pkg">Matrix</span> package,
or of class <code><a href="SparseM.html#topic+matrix.csr">matrix.csr</a></code>
provided by the <span class="pkg">SparseM</span> package, or of class
<code><a href="slam.html#topic+simple_triplet_matrix">simple_triplet_matrix</a></code> provided by the <span class="pkg">slam</span>
package). A vector will
be transformed to a n x 1 matrix.</p>
</td></tr>
<tr><td><code id="predict.wsvm_+3A_decision.values">decision.values</code></td>
<td>
<p>Logical controlling whether the decision values
of all binary classifiers computed in multiclass classification
shall be computed and returned.</p>
</td></tr>
<tr><td><code id="predict.wsvm_+3A_probability">probability</code></td>
<td>
<p>Logical indicating whether class probabilities
should be computed and returned. Only possible if the model was
fitted with the <code>probability</code> option enabled.</p>
</td></tr>
<tr><td><code id="predict.wsvm_+3A_na.action">na.action</code></td>
<td>
<p>A function to specify the action to be taken if &lsquo;NA&rsquo;s are
found. The default action is <code>na.omit</code>, which leads to rejection of cases
with missing values on any required variable. An alternative
is <code>na.fail</code>, which causes an error if <code>NA</code> cases
are found. (NOTE: If given, this argument must be named.)</p>
</td></tr>
<tr><td><code id="predict.wsvm_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of predicted values (for classification: a vector of labels, for density
estimation: a logical vector). If <code>decision.value</code> is
<code>TRUE</code>, the vector gets a <code>"decision.values"</code> attribute
containing a n x c matrix (n number of predicted values, c number of
classifiers) of all c binary classifiers' decision values. There are k
* (k - 1) / 2 classifiers (k number of classes). The colnames of
the matrix indicate the labels of the two classes. If <code>probability</code> is
<code>TRUE</code>, the vector gets a <code>"probabilities"</code> attribute
containing a n x k matrix (n number of predicted values, k number of
classes) of the class probabilities.
</p>


<h3>Note</h3>

<p>If the training set was scaled by <code>wsvm</code> (done by default), the
new data is scaled accordingly using scale and center of
the training data.
</p>


<h3>Author(s)</h3>

<p>David Meyer (based on C/C++-code by Chih-Chung Chang and Chih-Jen Lin) <br />
Modified by Tianchen Xu <a href="mailto:tx2155@columbia.edu">tx2155@columbia.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+wsvm">wsvm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## load dataset
data(iris)
attach(iris)

## classification mode
# default with factor response:
model1 &lt;- wsvm(Species ~ ., weight = rep(1,150), data = iris) # same weights
model2 &lt;- wsvm(x = iris[,1:4], y = iris[,5],
              weight = c(rep(0.08, 50),rep(1,100))) # less weights to setosa
x &lt;- subset(iris, select = -Species)
y &lt;- iris$Species
model3 &lt;- wsvm(x, y, weight = rep(10,150)) # similar to model 1, but larger weights for all subjects

# test with train data
pred &lt;- predict(model1, iris[,1:4])
# (same as:)
pred &lt;- fitted(model1)

# Check accuracy:
table(pred, y) # model 1, equal weights

# compute decision values and probabilities:
pred &lt;- predict(model1, x, decision.values = TRUE)
attr(pred, "decision.values")[1:4,]


## try regression mode on two dimensions
# create data
x &lt;- seq(0.1, 5, by = 0.05)
y &lt;- log(x) + rnorm(x, sd = 0.2)

# estimate model and predict input values
model1 &lt;- wsvm(x, y, weight = rep(1,99))
model2 &lt;- wsvm(x, y,
        weight = seq(99,1,length.out = 99)) # decreasing weights

# visualize
plot(x, y)
points(x, log(x), col = 2)
points(x, fitted(model1), col = 4)
points(x, fitted(model2), col = 3) # better fit for the first few points
</code></pre>

<hr>
<h2 id='tune_wsvm'>Parameter Tuning of Functions Using Grid Search</h2><span id='topic+tune_wsvm'></span><span id='topic+best.tune_wsvm'></span><span id='topic+print.tune_wsvm'></span><span id='topic+summary.tune_wsvm'></span><span id='topic+print.summary.tune_wsvm'></span>

<h3>Description</h3>

<p>This generic function tunes hyperparameters of statistical methods
using a grid search over supplied parameter ranges.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tune_wsvm(train.x, train.y = NULL, weight, use_zero_weight = FALSE,
     pre.check = TRUE, data = list(), validation.x = NULL,
     validation.y = NULL, validation.weight = NULL,
     weigthed.error = TRUE, ranges = NULL, predict.func = predict,
     tunecontrol = tune.control(), ...)
best.tune_wsvm(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tune_wsvm_+3A_train.x">train.x</code></td>
<td>
<p>either a formula or a '<em>design</em> matrix' of predictors.</p>
</td></tr>
<tr><td><code id="tune_wsvm_+3A_train.y">train.y</code></td>
<td>
<p>the response variable if <code>train.x</code> is a predictor
matrix. Ignored if <code>train.x</code> is a formula.</p>
</td></tr>
<tr><td><code id="tune_wsvm_+3A_weight">weight</code></td>
<td>
<p>the weight of each subject. It should be in the same length of <code>train.y</code>.</p>
</td></tr>
<tr><td><code id="tune_wsvm_+3A_use_zero_weight">use_zero_weight</code></td>
<td>
<p>if <code>FALSE</code>, any subjects in the training data and the validation data (if exist) with zero (or negative) weights will be removed.</p>
</td></tr>
<tr><td><code id="tune_wsvm_+3A_pre.check">pre.check</code></td>
<td>
<p>if <code>TRUE</code>, we prefit the model with partitioned training data using the first set of parameters in <code>range</code>. If fails (i.e., too many zero weight subjects in the partitioned training data), we re-partition the data and re-try the model for up to 10 times. This is useful when <code>use_zero_weight=TRUE</code> and there many zero weights subjects in the data. </p>
</td></tr>
<tr><td><code id="tune_wsvm_+3A_data">data</code></td>
<td>
<p>data, if a formula interface is used. Ignored, if
predictor matrix and response are supplied directly.</p>
</td></tr>
<tr><td><code id="tune_wsvm_+3A_validation.x">validation.x</code></td>
<td>
<p>an optional validation set. Depending on whether a
formula interface is used or not, the response can be
included in <code>validation.x</code> or separately specified using
<code>validation.y</code>. Only used for bootstrap and fixed validation
set (see <code><a href="#topic+tune.control">tune.control</a></code>)</p>
</td></tr>
<tr><td><code id="tune_wsvm_+3A_validation.y">validation.y</code></td>
<td>
<p>if no formula interface is used, the response of
the (optional) validation set. Only used for bootstrap and fixed validation
set (see <code><a href="#topic+tune.control">tune.control</a></code>)</p>
</td></tr>
<tr><td><code id="tune_wsvm_+3A_validation.weight">validation.weight</code></td>
<td>
<p>the weight of each subject in the validation set. Will be set to 1, if the user does not provide.</p>
</td></tr>
<tr><td><code id="tune_wsvm_+3A_weigthed.error">weigthed.error</code></td>
<td>
<p>if <code>TRUE</code>, the preformance measure will be weighted.</p>
</td></tr>
<tr><td><code id="tune_wsvm_+3A_ranges">ranges</code></td>
<td>
<p>a named list of parameter vectors spanning the sampling
space. See <code><a href="#topic+wsvm">wsvm</a></code>. The vectors will usually be created by <code>seq</code>.</p>
</td></tr>
<tr><td><code id="tune_wsvm_+3A_predict.func">predict.func</code></td>
<td>
<p>optional predict function, if the standard <code>predict</code>
behavior is inadequate.</p>
</td></tr>
<tr><td><code id="tune_wsvm_+3A_tunecontrol">tunecontrol</code></td>
<td>
<p>object of class <code>"tune.control"</code>, as created by the
function <code>tune.control()</code>. In additon, <code>tune.control$error.fun</code> should be a
function that takes three arguments: (true y, predicted y, weight). If omitted, <code>tune.control()</code>
gives the defaults.</p>
</td></tr>
<tr><td><code id="tune_wsvm_+3A_...">...</code></td>
<td>
<p>Further parameters passed to the training functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As performance measure, the classification error is used
for classification, and the mean squared error for regression. It is
possible to specify only one parameter combination (i.e., vectors of
length 1) to obtain an error estimation of the specified type
(bootstrap, cross-classification, etc.) on the given data set.
</p>
<p>Cross-validation randomizes the data set before building the splits
which&mdash;once created&mdash;remain constant during the training
process. The splits can be recovered through the <code>train.ind</code>
component of the returned object.
</p>


<h3>Value</h3>

<p>For <code>tune_wsvm</code>, an object of class <code>tune_wsvm</code>, including the components:
</p>
<table role = "presentation">
<tr><td><code>best.parameters</code></td>
<td>
<p>a 1 x k data frame, k number of parameters.</p>
</td></tr>
<tr><td><code>best.performance</code></td>
<td>
<p>best achieved performance.</p>
</td></tr>
<tr><td><code>performances</code></td>
<td>
<p>if requested, a data frame of all parameter
combinations along with the corresponding performance results.</p>
</td></tr>
<tr><td><code>train.ind</code></td>
<td>
<p>list of index vectors used for splits into
training and validation sets.</p>
</td></tr>
<tr><td><code>best.model</code></td>
<td>
<p>if requested, the model trained on the complete training data
using the best parameter combination.</p>
</td></tr>
</table>
<p><code>best.tune_wsvm()</code> returns the best model detected by <code>tune_wsvm</code>.
</p>


<h3>Author(s)</h3>

<p>David Meyer <br />
Modified by Tianchen Xu <a href="mailto:tx2155@columbia.edu">tx2155@columbia.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+tune.control">tune.control</a></code>, <code><a href="#topic+plot.tune_wsvm">plot.tune_wsvm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)

obj &lt;- tune_wsvm(Species~., weight = c(rep(0.8, 50),rep(1,100)),
            data = iris, ranges = list(gamma = 2^(-1:1), cost = 2^(2:4)),
            tunecontrol = tune.control(sampling = "fix"))


set.seed(11)
obj &lt;- tune_wsvm(Species~., weight = c(rep(0, 52),rep(1,98)),
            data = iris, use_zero_weight = TRUE,
            ranges = list(gamma = 2^(-1:1), cost = 2^(2:4)),
            tunecontrol = tune.control(sampling = "bootstrap"))



summary(obj)
plot(obj, transform.x = log2, transform.y = log2)
plot(obj, type = "perspective", theta = 120, phi = 45)

best.tune_wsvm(Species~.,weight = c(rep(0.08, 50),rep(1,100)),
            data = iris, ranges = list(gamma = 2^(-1:1), cost = 2^(2:4)),
            tunecontrol = tune.control(sampling = "fix"))
</code></pre>

<hr>
<h2 id='tune.control'>Control Parameters for the tune/tune_wsvm Function</h2><span id='topic+tune.control'></span>

<h3>Description</h3>

<p>Creates an object of class <code>tune.control</code> to be used with
the <code>tune</code>/<code>tune_wsvm</code> function, containing various control parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tune.control(random = FALSE, nrepeat = 1, repeat.aggregate = mean,
sampling = c("cross", "fix", "bootstrap"), sampling.aggregate = mean,
sampling.dispersion = sd,
cross = 10, fix = 2/3, nboot = 10, boot.size = 9/10, best.model = TRUE,
performances = TRUE, error.fun = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tune.control_+3A_random">random</code></td>
<td>
<p>if an integer value is specified, <code>random</code>
parameter vectors are drawn from the parameter space.</p>
</td></tr>
<tr><td><code id="tune.control_+3A_nrepeat">nrepeat</code></td>
<td>
<p>specifies how often training shall be repeated.</p>
</td></tr>
<tr><td><code id="tune.control_+3A_repeat.aggregate">repeat.aggregate</code></td>
<td>
<p>function for aggregating the repeated training results.</p>
</td></tr>
<tr><td><code id="tune.control_+3A_sampling">sampling</code></td>
<td>
<p>sampling scheme. If <code>sampling = "cross"</code>, a
<code>cross</code>-times cross validation is performed. If <code>sampling
      = "boot"</code>, <code>nboot</code> training sets of size <code>boot.size</code> (part)
are sampled (with replacement) from the supplied data. If <code>sampling
      = "fix"</code>, a single split into training/validation set is
used, the training set containing a <code>fix</code> part of the supplied
data. Note that a separate validation set can be supplied via
<code>validation.x</code> and <code>validation.y</code>. It is only used for
<code>sampling = "boot"</code> and <code>sampling = "fix"</code>; in the latter
case, <code>fix</code> is set to 1.</p>
</td></tr>
<tr><td><code id="tune.control_+3A_sampling.aggregate">sampling.aggregate</code>, <code id="tune.control_+3A_sampling.dispersion">sampling.dispersion</code></td>
<td>
<p>functions for aggregating the training
results on the generated training samples (default: mean and
standard deviation).</p>
</td></tr>
<tr><td><code id="tune.control_+3A_cross">cross</code></td>
<td>
<p>number of partitions for cross-validation.</p>
</td></tr>
<tr><td><code id="tune.control_+3A_fix">fix</code></td>
<td>
<p>part of the data used for training in fixed sampling.</p>
</td></tr>
<tr><td><code id="tune.control_+3A_nboot">nboot</code></td>
<td>
<p>number of bootstrap replications.</p>
</td></tr>
<tr><td><code id="tune.control_+3A_boot.size">boot.size</code></td>
<td>
<p>size of the bootstrap samples.</p>
</td></tr>
<tr><td><code id="tune.control_+3A_best.model">best.model</code></td>
<td>
<p>if <code>TRUE</code>, the best model is trained and
returned (the best parameter set is used for
training on the complete training set).</p>
</td></tr>
<tr><td><code id="tune.control_+3A_performances">performances</code></td>
<td>
<p>if <code>TRUE</code>, the performance results for all
parameter combinations are returned.</p>
</td></tr>
<tr><td><code id="tune.control_+3A_error.fun">error.fun</code></td>
<td>
<p>function returning the error measure to be minimized.
It takes two arguments: a vector of true values and a vector of
predicted values. If <code>NULL</code>, the misclassification error is used
for categorical predictions and the mean squared error for numeric
predictions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"tune.control"</code> containing all the above
parameters (either the defaults or the user specified values).
</p>


<h3>Author(s)</h3>

<p>David Meyer
</p>


<h3>See Also</h3>

<p><code><a href="#topic+tune_wsvm">tune_wsvm</a></code>, <code><a href="e1071.html#topic+tune">tune</a></code> (in package <span class="pkg">e1071</span>)</p>

<hr>
<h2 id='wsvm'>Subject Weighted Support Vector Machines</h2><span id='topic+wsvm'></span><span id='topic+wsvm.default'></span><span id='topic+wsvm.formula'></span><span id='topic+summary.wsvm'></span><span id='topic+print.summary.wsvm'></span><span id='topic+coef.wsvm'></span><span id='topic+print.wsvm'></span>

<h3>Description</h3>

<p><code>wsvm</code> is used to train a subject weighted support vector machine. It can be used to carry out general regression and classification (of nu and epsilon-type), as
well as density-estimation. A formula interface is provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'formula'
wsvm(formula, weight, data = NULL, ..., subset, na.action =
na.omit, scale = TRUE)
## Default S3 method:
wsvm(x, y = NULL, weight, scale = TRUE, type = NULL, kernel =
"radial", degree = 3, gamma = if (is.vector(x)) 1 else 1 / ncol(x),
coef0 = 0, cost = 1, nu = 0.5,
class.weights = NULL, cachesize = 100, tolerance = 0.001, epsilon = 0.1,
shrinking = TRUE, cross = 0, probability = FALSE, fitted = TRUE,
..., subset, na.action = na.omit)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="wsvm_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit.</p>
</td></tr>
<tr><td><code id="wsvm_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model.
By default the variables are taken from the environment which
&lsquo;wsvm&rsquo; is called from.</p>
</td></tr>
<tr><td><code id="wsvm_+3A_x">x</code></td>
<td>
<p>a data matrix, a vector, or a sparse '<em>design</em> matrix' (object of class
<code><a href="Matrix.html#topic+Matrix">Matrix</a></code> provided by the <span class="pkg">Matrix</span> package,
or of class <code><a href="SparseM.html#topic+matrix.csr">matrix.csr</a></code>
provided by the <span class="pkg">SparseM</span> package, or of class
<code><a href="slam.html#topic+simple_triplet_matrix">simple_triplet_matrix</a></code> provided by the <span class="pkg">slam</span>
package). Or a kernel matrix of class <code><a href="kernlab.html#topic+kernelMatrix">kernelMatrix</a></code> by the <span class="pkg">kernlab</span> package.</p>
</td></tr>
<tr><td><code id="wsvm_+3A_y">y</code></td>
<td>
<p>a response vector with one label for each row/component of
<code>x</code>. Can be either a factor (for classification tasks)
or a numeric vector (for regression).</p>
</td></tr>
<tr><td><code id="wsvm_+3A_weight">weight</code></td>
<td>
<p>the weight of each subject. It should be in the same length of <code>y</code>.</p>
</td></tr>
<tr><td><code id="wsvm_+3A_scale">scale</code></td>
<td>
<p>A logical vector indicating the variables to be
scaled. If <code>scale</code> is of length 1, the value is recycled as
many times as needed.
By default, data are scaled internally (both <code>x</code> and <code>y</code>
variables) to zero mean and unit variance. The center and scale
values are returned and used for later predictions. <em>If x is a design matrix which contains dummy variables, please make these variable NOT scaled.</em></p>
</td></tr>
<tr><td><code id="wsvm_+3A_type">type</code></td>
<td>
<p><code>wsvm</code> can be used as a classification
machine, as a regression machine, or for novelty detection.
Depending of whether <code>y</code> is
a factor or not, the default setting for <code>type</code> is <code>C-classification</code> or <code>eps-regression</code>, respectively, but may be overwritten by setting an explicit value.<br />
Valid options are:
</p>

<ul>
<li> <p><code>C-classification</code>
</p>
</li>
<li> <p><code>nu-classification</code>
</p>
</li>
<li> <p><code>one-classification</code> (for novelty detection)
</p>
</li>
<li> <p><code>eps-regression</code>
</p>
</li>
<li> <p><code>nu-regression</code>
</p>
</li></ul>

</td></tr>
<tr><td><code id="wsvm_+3A_kernel">kernel</code></td>
<td>
<p>the kernel used in training and predicting. You
might consider changing some of the following parameters, depending
on the kernel type.<br />
</p>

<dl>
<dt>linear:</dt><dd><p><code class="reqn">u'v</code></p>
</dd>
<dt>polynomial:</dt><dd><p><code class="reqn">(\gamma u'v + coef0)^{degree}</code></p>
</dd>
<dt>radial basis:</dt><dd><p><code class="reqn">e^(-\gamma |u-v|^2)</code></p>
</dd>
<dt>sigmoid:</dt><dd><p><code class="reqn">tanh(\gamma u'v + coef0)</code></p>
</dd>
<dt>precomputed:</dt><dd><p>x is a precomputed kernel matrix that contains NO missing values. <code>scale</code> will not work. Cannot use <code>subset</code> and <code>na.action</code> with this kernel. </p>
</dd>
</dl>

</td></tr>
<tr><td><code id="wsvm_+3A_degree">degree</code></td>
<td>
<p>parameter needed for kernel of type <code>polynomial</code> (default: 3)</p>
</td></tr>
<tr><td><code id="wsvm_+3A_gamma">gamma</code></td>
<td>
<p>parameter needed for all kernels except <code>linear</code>
(default: 1/(data dimension))</p>
</td></tr>
<tr><td><code id="wsvm_+3A_coef0">coef0</code></td>
<td>
<p>parameter needed for kernels of type <code>polynomial</code>
and <code>sigmoid</code> (default: 0)</p>
</td></tr>
<tr><td><code id="wsvm_+3A_cost">cost</code></td>
<td>
<p>cost of constraints violation (default: 1)&mdash;it is the
&lsquo;C&rsquo;-constant of the regularization term in the Lagrange formulation.</p>
</td></tr>
<tr><td><code id="wsvm_+3A_nu">nu</code></td>
<td>
<p>parameter needed for <code>nu-classification</code>,
<code>nu-regression</code>, and <code>one-classification</code></p>
</td></tr>
<tr><td><code id="wsvm_+3A_class.weights">class.weights</code></td>
<td>
<p>a named vector of weights for the different
classes, used for asymmetric class sizes. Not all factor levels have
to be supplied (default weight: 1). All components have to be
named. Specifying <code>"inverse"</code> will choose the weights <em>inversely</em>
proportional to the class distribution.</p>
</td></tr>
<tr><td><code id="wsvm_+3A_cachesize">cachesize</code></td>
<td>
<p>cache memory in MB (default 100)</p>
</td></tr>
<tr><td><code id="wsvm_+3A_tolerance">tolerance</code></td>
<td>
<p>tolerance of termination criterion (default: 0.001)</p>
</td></tr>
<tr><td><code id="wsvm_+3A_epsilon">epsilon</code></td>
<td>
<p>epsilon in the insensitive-loss function (default: 0.1)</p>
</td></tr>
<tr><td><code id="wsvm_+3A_shrinking">shrinking</code></td>
<td>
<p>option whether to use the shrinking-heuristics
(default: <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="wsvm_+3A_cross">cross</code></td>
<td>
<p>if a integer value k&gt;0 is specified, a k-fold cross
validation on the training data is performed to assess the quality
of the model: the accuracy rate for classification and the Mean
Squared Error for regression. Note the result is not weighted. For weighted results,
use <code>tune_wsvm</code> fucntion.</p>
</td></tr>
<tr><td><code id="wsvm_+3A_fitted">fitted</code></td>
<td>
<p>logical indicating whether the fitted values should be computed
and included in the model or not (default: <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="wsvm_+3A_probability">probability</code></td>
<td>
<p>logical indicating whether the model should
allow for probability predictions.</p>
</td></tr>
<tr><td><code id="wsvm_+3A_...">...</code></td>
<td>
<p>additional parameters for the low level fitting function
<code>wsvm.default</code></p>
</td></tr>
<tr><td><code id="wsvm_+3A_subset">subset</code></td>
<td>
<p>An index vector specifying the cases to be used in the
training sample.  (NOTE: If given, this argument must be
named.)</p>
</td></tr>
<tr><td><code id="wsvm_+3A_na.action">na.action</code></td>
<td>
<p>A function to specify the action to be taken if <code>NA</code>s are
found. The default action is <code>na.omit</code>, which leads to rejection of cases
with missing values on any required variable. An alternative
is <code>na.fail</code>, which causes an error if <code>NA</code> cases
are found. (NOTE: If given, this argument must be named.)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The original <code>libsvm</code> does not support subject/instance weighted svm. From the 'LIBSVM Tools' <a href="https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/#weights_for_data_instances">https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/#weights_for_data_instances</a>, we are able to use a modified version of <code>libsvm</code> to support subject weights.
</p>
<p>For multiclass-classification with k levels, k&gt;2, <code>libsvm</code> uses the
&lsquo;one-against-one&rsquo;-approach, in which k(k-1)/2 binary classifiers are
trained; the appropriate class is found by a voting scheme.
</p>
<p><code>libsvm</code> internally uses a sparse data representation, which is
also high-level supported by the package <span class="pkg">SparseM</span>.
</p>
<p>If the predictor variables include factors, the formula interface must be used to get a
correct model matrix or make x a design matrix.
</p>
<p>When using the formula interface and <code>na.action</code> is <code>na.omit</code>, we delete any subjects with missing values on x, y (if exists) or weight in the training and predicting procedure (when <code>fitted = TRUE</code>). When using the x, y interface and <code>na.action</code> is <code>na.omit</code>, we delete any subjects with missing values on x, y (if exists) or weight in the training procedure, and retain the subjects with missing values only on weight in the predicting procedure (when <code>fitted = TRUE</code>).
</p>
<p><code>plot.wsvm</code> allows a simple graphical
visualization of classification models.
</p>
<p>The probability model for classification fits a logistic distribution
using maximum likelihood to the decision values of all binary
classifiers, and computes the a-posteriori class probabilities for the
multi-class problem using quadratic optimization. The probabilistic
regression model assumes (zero-mean) laplace-distributed errors for the
predictions, and estimates the scale parameter using maximum
likelihood.
</p>
<p>For linear kernel, the coefficients of the regression/decision hyperplane
can be extracted using the <code>coef</code> method (see examples).
</p>


<h3>Value</h3>

<p>An object of class <code>"wsvm"</code> containing the fitted model, including:
</p>
<table role = "presentation">
<tr><td><code>SV</code></td>
<td>
<p>The resulting support vectors (possibly scaled).</p>
</td></tr>
<tr><td><code>index</code></td>
<td>
<p>The index of the resulting support vectors in the data
matrix. Note that this index refers to the preprocessed data (after
the possible effect of <code>na.omit</code> and <code>subset</code>)</p>
</td></tr>
<tr><td><code>coefs</code></td>
<td>
<p>The corresponding coefficients times the training labels.</p>
</td></tr>
<tr><td><code>rho</code></td>
<td>
<p>The negative intercept.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>In case of a probabilistic regression model, the scale
parameter of the hypothesized (zero-mean) laplace distribution estimated by
maximum likelihood.</p>
</td></tr>
<tr><td><code>probA</code>, <code>probB</code></td>
<td>
<p>numeric vectors of length k(k-1)/2, k number of
classes, containing the parameters of the logistic distributions fitted to
the decision values of the binary classifiers (1 / (1 + exp(a x + b))).</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Data are scaled internally, usually yielding better results.
</p>
<p>Parameters of SVM-models usually <em>must</em> be tuned to yield sensible results!
</p>


<h3>Author(s)</h3>

<p>David Meyer (based on C/C++-code by Chih-Chung Chang and Chih-Jen Lin)<br />
Modified by Tianchen Xu <a href="mailto:tx2155@columbia.edu">tx2155@columbia.edu</a>
</p>


<h3>References</h3>


<ul>
<li>
<p>Chang, Chih-Chung and Lin, Chih-Jen:<br />
<em>LIBSVM: a library for Support Vector Machines</em><br />
<a href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/">https://www.csie.ntu.edu.tw/~cjlin/libsvm/</a>
</p>
</li>
<li><p> Ming-Wei Chang, Hsuan-Tien Lin, Ming-Hen Tsai, Chia-Hua Ho and Hsiang-Fu Yu<br />
<em>Weights for data instances</em><br />
<a href="https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/#weights_for_data_instances">https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/#weights_for_data_instances</a>
</p>
</li>
<li>
<p>Exact formulations of models, algorithms, etc. can be found in the
document:<br />
Chang, Chih-Chung and Lin, Chih-Jen:<br />
<em>LIBSVM: a library for Support Vector Machines</em><br />
<a href="https://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.ps.gz">https://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.ps.gz</a>
</p>
</li>
<li>
<p>More implementation details and speed benchmarks can be found on:
Rong-En Fan and Pai-Hsune Chen and Chih-Jen Lin:<br />
<em>Working Set Selection Using the Second Order Information for Training SVM</em><br />
<a href="https://www.csie.ntu.edu.tw/~cjlin/papers/quadworkset.pdf">https://www.csie.ntu.edu.tw/~cjlin/papers/quadworkset.pdf</a>
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+predict.wsvm">predict.wsvm</a></code>,
<code><a href="#topic+plot.wsvm">plot.wsvm</a></code>,
<code><a href="#topic+tune_wsvm">tune_wsvm</a></code>,
<code><a href="SparseM.html#topic+matrix.csr">matrix.csr</a></code> (in package <span class="pkg">SparseM</span>)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## check what is loaded
dllpath &lt;- getLoadedDLLs()
getDLLRegisteredRoutines(dllpath$WeightSVM[[2]])

## load dataset
data(iris)

## classification mode
# default with factor response:
model1 &lt;- wsvm(Species ~ ., weight = rep(1,150), data = iris) # same weights
model2 &lt;- wsvm(x = iris[,1:4], y = iris[,5],
              weight = c(rep(0.08, 50),rep(1,100))) # less weights to setosa
# alternatively the traditional interface:
x &lt;- subset(iris, select = -Species)
y &lt;- iris$Species
model3 &lt;- wsvm(x, y, weight = rep(10,150)) # similar to model 1,
                               # but larger weights for all subjects

# These models provide error/warning info
try(wsvm(x, y)) # no weight
try(wsvm(x, y, weight = rep(10,100))) # wrong length
try(wsvm(x, y, weight = c(Inf, rep(1,149)))) # contains inf weight

print(model1)
summary(model1)

# test with train data
pred &lt;- predict(model1, iris[,1:4])
# (same as:)
pred &lt;- fitted(model1)

# Check accuracy:
table(pred, y) # model 1, equal weights

# compute decision values and probabilities:
pred &lt;- predict(model1, x, decision.values = TRUE)
attr(pred, "decision.values")[1:4,]

# visualize (classes by color, SV by crosses):
plot(cmdscale(dist(iris[,-5])),
     col = as.integer(iris[,5]),
     pch = c("o","+")[1:150 %in% model1$index + 1]) # model 1
plot(cmdscale(dist(iris[,-5])),
     col = as.integer(iris[,5]),
     pch = c("o","+")[1:150 %in% model2$index + 1])
  # In model 2, less support vectors are based on setosa


## try regression mode on two dimensions
# create data
x &lt;- seq(0.1, 5, by = 0.05)
y &lt;- log(x) + rnorm(x, sd = 0.2)

# estimate model and predict input values
model1 &lt;- wsvm(x, y, weight = rep(1,99))
model2 &lt;- wsvm(x, y, weight = seq(99,1,length.out = 99)) # decreasing weights
# library(kernlab)
# model3 &lt;- wsvm(kernlab::kernelMatrix(kernlab::rbfdot(sigma = 1), x), y,
#      weight = rep(1,99), kernel = 'precomputed') # try user defined kernel

# visualize
plot(x, y)
lines(x, log(x), col = 2)
points(x, fitted(model1), col = 4)
points(x, fitted(model2), col = 3) # better fit for the first few points
# points(x, fitted(model3), col = 5) # similar to model 1 with user defined kernel

## density-estimation
# create 2-dim. normal with rho=0:
X &lt;- data.frame(a = rnorm(1000), b = rnorm(1000))
attach(X)

# formula interface:
model &lt;- wsvm(~ a + b, gamma = 0.1, weight = c(seq(5000,1,length.out = 500),1:500))

# test:
newdata &lt;- data.frame(a = c(0, 4), b = c(0, 4))

# visualize:
plot(X, col = 1:1000 %in% model$index + 1, xlim = c(-5,5), ylim=c(-5,5))
points(newdata, pch = "+", col = 2, cex = 5)

## class weights:
i2 &lt;- iris
levels(i2$Species)[3] &lt;- "versicolor"
summary(i2$Species)
wts &lt;- 100 / table(i2$Species)
wts
m &lt;- wsvm(Species ~ ., data = i2, class.weights = wts, weight=rep(1,150))

## extract coefficients for linear kernel

# a. regression
x &lt;- 1:100
y &lt;- x + rnorm(100)
m &lt;- wsvm(y ~ x, scale = FALSE, kernel = "linear", weight = rep(1,100))
coef(m)
plot(y ~ x)
abline(m, col = "red")

# b. classification
# transform iris data to binary problem, and scale data
setosa &lt;- as.factor(iris$Species == "setosa")
iris2 = scale(iris[,-5])

# fit binary C-classification model
model1 &lt;- wsvm(setosa ~ Petal.Width + Petal.Length,
          data = iris2, kernel = "linear", weight = rep(1,150))
model2 &lt;- wsvm(setosa ~ Petal.Width + Petal.Length,
               data = iris2, kernel = "linear",
               weight = c(rep(0.08, 50),rep(1,100))) # less weights to setosa

# plot data and separating hyperplane
plot(Petal.Length ~ Petal.Width, data = iris2, col = setosa)
(cf &lt;- coef(model1))
abline(-cf[1]/cf[3], -cf[2]/cf[3], col = "red")
(cf2 &lt;- coef(model2))
abline(-cf2[1]/cf2[3], -cf2[2]/cf2[3], col = "red", lty = 2)

# plot margin and mark support vectors
abline(-(cf[1] + 1)/cf[3], -cf[2]/cf[3], col = "blue")
abline(-(cf[1] - 1)/cf[3], -cf[2]/cf[3], col = "blue")
points(model1$SV, pch = 5, cex = 2)
abline(-(cf2[1] + 1)/cf2[3], -cf2[2]/cf2[3], col = "blue", lty = 2)
abline(-(cf2[1] - 1)/cf2[3], -cf2[2]/cf2[3], col = "blue", lty = 2)
points(model2$SV, pch = 6, cex = 2)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
