<!DOCTYPE html><html><head><title>Help for package ARUtools</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ARUtools}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ARUtools'><p>ARUtools: Management and Processing of Autonomous Recording Unit (ARU) Data</p></a></li>
<li><a href='#acoustic_indices'><p>Get acoustic complexity values</p></a></li>
<li><a href='#add_sites'><p>Add site-level data to the metadata</p></a></li>
<li><a href='#add_wildtrax'><p>Add file name formated for Wildtrax to metadata</p></a></li>
<li><a href='#calc_selection_weights'><p>Calculate Selection Weights</p></a></li>
<li><a href='#calc_sun'><p>Calculate time to sunrise/sunset</p></a></li>
<li><a href='#check_file'><p>Explore a file</p></a></li>
<li><a href='#check_meta'><p>Check output of <code>clean_metadata()</code></p></a></li>
<li><a href='#check_problems'><p>Check problems in output of <code>clean_metadata()</code></p></a></li>
<li><a href='#clean_gps'><p>Check and clean GPS data</p></a></li>
<li><a href='#clean_logs'><p>Extract log data from BAR-LT log files</p></a></li>
<li><a href='#clean_metadata'><p>Extract and clean ARU metadata from file names</p></a></li>
<li><a href='#clean_site_index'><p>Prepare and clean site index file</p></a></li>
<li><a href='#clip_wave'><p>Clip multiple wave files and format names</p></a></li>
<li><a href='#clip_wave_single'><p>Clip single wave file</p></a></li>
<li><a href='#common_docs'><p>Common arguments and documentation for various functions</p></a></li>
<li><a href='#count_files'><p>Count files in a project directory</p></a></li>
<li><a href='#create_dirs'><p>Create directory structure for recording folders</p></a></li>
<li><a href='#create_pattern'><p>Create a pattern to match date</p></a></li>
<li><a href='#example_clean'><p>Example cleaned recording meta data</p></a></li>
<li><a href='#example_files'><p>Example recording files</p></a></li>
<li><a href='#example_files_long'><p>Example long-term deployment recording files</p></a></li>
<li><a href='#example_sites'><p>Example site-level meta data</p></a></li>
<li><a href='#example_sites_clean'><p>Example cleaned site-level meta data</p></a></li>
<li><a href='#get_wav_length'><p>Get the length of a recording in seconds</p></a></li>
<li><a href='#sample_recordings'><p>Sample recordings</p></a></li>
<li><a href='#sim_selection_weights'><p>Create parameters and simulate selection weights</p></a></li>
<li><a href='#sox_spectro'><p>Create spectrogram image from wave file</p></a></li>
<li><a href='#task_template'><p>Example template of tasks for WildTrax</p></a></li>
<li><a href='#temp_wavs'><p>Helper function to create test wave files</p></a></li>
<li><a href='#template_observers'><p>Example template of tasks for WildTrax</p></a></li>
<li><a href='#wind_detection_pre_processing'><p>Pre-processing of files for Wind Detection program</p></a></li>
<li><a href='#wind_detection_summarize_json'><p>Summarize wind detection results</p></a></li>
<li><a href='#wt_assign_tasks'><p>Assign tasks for interpretation on Wildtrax</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Management and Processing of Autonomous Recording Unit (ARU)
Data</td>
</tr>
<tr>
<td>Version:</td>
<td>0.6.2</td>
</tr>
<tr>
<td>Description:</td>
<td>Parse Autonomous Recording Unit (ARU) data and for sub-sampling recordings. 
    Extract Metadata from your recordings, select a subset of recordings for 
    interpretation, and prepare files for processing on the 
    'WildTrax' <a href="https://wildtrax.ca/">https://wildtrax.ca/</a> platform. Read and process metadata 
    from recordings collected using the SongMeter and BAR-LT types of ARUs. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://arutools.github.io/ARUtools/">https://arutools.github.io/ARUtools/</a>,
<a href="https://github.com/ARUtools/ARUtools">https://github.com/ARUtools/ARUtools</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/ARUtools/ARUtools/issues">https://github.com/ARUtools/ARUtools/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, fs (&ge; 1.6.1), glue, here, hms (&ge; 1.1.2), lifecycle,
lubridate, lutz, parzer, purrr, readr, rlang (&ge; 0.4), seewave
(&ge; 2.2.3), sf, spsurvey (&ge; 5.0.1), stringr, suncalc, tidyr,
units, withr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>covr, ggplot2, job, jsonlite, knitr, parallel, patchwork,
readxl (&ge; 1.4.2), rmarkdown, rstudioapi, sessioninfo,
soundecology, testthat (&ge; 3.0.0), tuneR, vdiffr (&ge; 1.0.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-04-18 16:20:00 UTC; HopeD</td>
</tr>
<tr>
<td>Author:</td>
<td>David Hope <a href="https://orcid.org/0000-0002-2140-4261"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Steffi LaZerte <a href="https://orcid.org/0000-0002-7690-8360"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Government of Canada [cph, fnd]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>David Hope &lt;david.hope@ec.gc.ca&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-04-18 19:32:51 UTC</td>
</tr>
</table>
<hr>
<h2 id='ARUtools'>ARUtools: Management and Processing of Autonomous Recording Unit (ARU) Data</h2><span id='topic+ARUtools-package'></span><span id='topic+ARUtools'></span>

<h3>Description</h3>

<p>Parse Autonomous Recording Unit (ARU) data and for sub-sampling recordings.
Extract Metadata from your recordings, select a subset of recordings for
interpretation, and prepare files for processing on the
WildTrax <a href="https://wildtrax.ca/">https://wildtrax.ca/</a> platform. Read and process metadata
from recordings collected using the Song Meter and BAR-LT types of ARUs.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: David Hope <a href="mailto:david.hope@ec.gc.ca">david.hope@ec.gc.ca</a> (<a href="https://orcid.org/0000-0002-2140-4261">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Steffi LaZerte <a href="mailto:sel@steffilazerte.ca">sel@steffilazerte.ca</a> (<a href="https://orcid.org/0000-0002-7690-8360">ORCID</a>)
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Government of Canada [copyright holder, funder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://arutools.github.io/ARUtools/">https://arutools.github.io/ARUtools/</a>
</p>
</li>
<li> <p><a href="https://github.com/ARUtools/ARUtools">https://github.com/ARUtools/ARUtools</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/ARUtools/ARUtools/issues">https://github.com/ARUtools/ARUtools/issues</a>
</p>
</li></ul>


<hr>
<h2 id='acoustic_indices'>Get acoustic complexity values</h2><span id='topic+acoustic_indices'></span>

<h3>Description</h3>

<p>Wrapper for 'soundecology' package to calculate acoustic complexity, the
bioacoustic index, and acoustic diversity. See Value for details about
these indices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>acoustic_indices(
  path,
  min_freq = NA,
  max_freq = NA,
  units = "samples",
  quiet = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="acoustic_indices_+3A_path">path</code></td>
<td>
<p>Character. Path to wave file.</p>
</td></tr>
<tr><td><code id="acoustic_indices_+3A_min_freq">min_freq</code></td>
<td>
<p>Numeric. Minimum frequency for acoustic complexity (see
<code><a href="soundecology.html#topic+acoustic_complexity_index">soundecology::acoustic_complexity()</a></code>)</p>
</td></tr>
<tr><td><code id="acoustic_indices_+3A_max_freq">max_freq</code></td>
<td>
<p>Numeric. Maximum frequency for acoustic complexity (see
<code><a href="soundecology.html#topic+acoustic_complexity_index">soundecology::acoustic_complexity()</a></code>)</p>
</td></tr>
<tr><td><code id="acoustic_indices_+3A_units">units</code></td>
<td>
<p>Character. Wave file units for reading the file. Defaults to
&quot;samples&quot; (see <code><a href="tuneR.html#topic+readWave">tuneR::readWave()</a></code>).</p>
</td></tr>
<tr><td><code id="acoustic_indices_+3A_quiet">quiet</code></td>
<td>
<p>Logical. Whether to suppress progress messages and other
non-essential updates.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data frame with acoustic indices. Those prefaced with
</p>

<ul>
<li> <p><code>complx_</code> are from <code><a href="soundecology.html#topic+acoustic_complexity_index">soundecology::acoustic_complexity()</a></code>
</p>
</li>
<li> <p><code>bio_</code> are from <code><a href="soundecology.html#topic+bioacoust_index">soundecology::bioacoustic_index()</a></code>
</p>
</li>
<li> <p><code>div_</code> are from <code><a href="soundecology.html#topic+acoustic_diversity">soundecology::acoustic_diversity()</a></code>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>w &lt;- tuneR::sine(440, duration = 300000) # &gt; 5s
tuneR::writeWave(w, "test_wave.wav")
acoustic_indices("test_wave.wav")
acoustic_indices("test_wave.wav", quiet = TRUE)
unlink("test_wave.wav")
</code></pre>

<hr>
<h2 id='add_sites'>Add site-level data to the metadata</h2><span id='topic+add_sites'></span>

<h3>Description</h3>

<p>Uses dates to join site-level data (coordinates and site ids) to the meta
data. If the site data have only single dates, then a buffer before and after
is used to determine which recordings belong to that site observation. Can
join by site ids alone if set <code>by_date = NULL</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_sites(
  meta,
  sites,
  buffer_before = 0,
  buffer_after = NULL,
  by = c("site_id", "aru_id"),
  by_date = "date_time",
  quiet = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_sites_+3A_meta">meta</code></td>
<td>
<p>Data frame. Recording metadata. Output of <code>clean_metadata()</code>.</p>
</td></tr>
<tr><td><code id="add_sites_+3A_sites">sites</code></td>
<td>
<p>Data frame. Site-level data from <code>clean_site_index()</code>.</p>
</td></tr>
<tr><td><code id="add_sites_+3A_buffer_before">buffer_before</code></td>
<td>
<p>Numeric. Number of hours before a deployment in which to
include recordings. <code>NULL</code> means include the time up to the last
deployment. Coupled with <code>buffer_after</code>, this creates a window around a
date/time in which to join recordings to the site-level data. Ignored if
<code>sites</code> has both a start and end column for date/times. Default 0.</p>
</td></tr>
<tr><td><code id="add_sites_+3A_buffer_after">buffer_after</code></td>
<td>
<p>Numeric. Number of hours after the deployment in which to
include recordings. <code>NULL</code> means include the time up to the next
deployment. Coupled with <code>buffer_before</code>, creates a window around a
date/time in which to join recordings to the site-level data. Ignored if
<code>sites</code> has both a start and end column for date/times. Default <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="add_sites_+3A_by">by</code></td>
<td>
<p>Character. Columns which identify a deployment in <code>sites</code> as well
as <code>meta</code>, besides date/time, which are used to join the data. Default is
<code>site_id</code> and <code>aru_id</code>.</p>
</td></tr>
<tr><td><code id="add_sites_+3A_by_date">by_date</code></td>
<td>
<p>Character. Date/time type to join data by. <code>date</code> is faster
but <code>date_time</code> is more precise. Default <code>date_time</code>. <code>NULL</code> means ignore
dates and join only with <code>by</code> columns (<code>dplyr::left_join()</code>).</p>
</td></tr>
<tr><td><code id="add_sites_+3A_quiet">quiet</code></td>
<td>
<p>Logical. Whether to suppress progress messages and other
non-essential updates.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame of metadata with site-level data joined in.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- clean_metadata(project_files = example_files)
s &lt;- clean_site_index(example_sites_clean,
  name_date = c("date_time_start", "date_time_end")
)
m &lt;- add_sites(m, s)

# Without dates (by site only)
m &lt;- clean_metadata(project_files = example_files)
eg &lt;- dplyr::select(example_sites_clean, -date_time_start, -date_time_end)
s &lt;- clean_site_index(eg, name_date_time = NULL)
m &lt;- add_sites(m, s, by_date = NULL)

</code></pre>

<hr>
<h2 id='add_wildtrax'>Add file name formated for Wildtrax to metadata</h2><span id='topic+add_wildtrax'></span>

<h3>Description</h3>

<p>Create and append file name appropriate for uploading data to the Wildtrax
platform <a href="https://wildtrax.ca/">https://wildtrax.ca/</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_wildtrax(meta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_wildtrax_+3A_meta">meta</code></td>
<td>
<p>Data frame. Recording metadata. Output of <code>clean_metadata()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame of metadata with appended column of WildTrax appropriate
file names.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
m &lt;- clean_metadata(project_files = example_files)
m &lt;- add_wildtrax(m)
m
</code></pre>

<hr>
<h2 id='calc_selection_weights'>Calculate Selection Weights</h2><span id='topic+calc_selection_weights'></span>

<h3>Description</h3>

<p>Calculate selection weights for a series of recordings based on the selection
parameters defined by <code>sim_selection_weights()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_selection_weights(
  meta_sun,
  params,
  col_site_id = site_id,
  col_min = t2sr,
  col_day = date
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calc_selection_weights_+3A_meta_sun">meta_sun</code></td>
<td>
<p>(Spatial) Data frame. Recording meta data with time to
sunrise/sunset. Output of <code>calc_sun()</code>. Must have at least <code>col_min</code>,
<code>col_day</code>, and <code>col_site_id</code>.</p>
</td></tr>
<tr><td><code id="calc_selection_weights_+3A_params">params</code></td>
<td>
<p>Named list. Parameters created by <code>sim_selection_weights()</code>, containing
<code>min_range</code>, <code>min_mean</code>, <code>min_sd</code>, <code>day_range</code>, <code>day_mean</code>, <code>day_sd</code>,
<code>offset</code>, <code>return_log</code>, <code>selection_fun</code>.</p>
</td></tr>
<tr><td><code id="calc_selection_weights_+3A_col_site_id">col_site_id</code></td>
<td>
<p>Column. Unquoted column containing site strata IDs
(defaults to <code>site_id</code>).</p>
</td></tr>
<tr><td><code id="calc_selection_weights_+3A_col_min">col_min</code></td>
<td>
<p>Column. Unquoted column containing minutes to sunrise (<code>t2sr</code>)
or sunset (<code>t2ss</code>) output from <code>calc_sun()</code> (defaults to <code>t2sr</code>).</p>
</td></tr>
<tr><td><code id="calc_selection_weights_+3A_col_day">col_day</code></td>
<td>
<p>Column. Unquoted column containing dates or day-of-year (doy)
to use (defaults to <code>date</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns data with appended selection weights columns:
</p>

<ul>
<li> <p><code>psel_by</code> - The minutes column used
</p>
</li>
<li> <p><code>psel_min</code> - Probability of selection by time of day (min column)
</p>
</li>
<li> <p><code>psel_doy</code> - Probability of selection by day of year
</p>
</li>
<li> <p><code>psel</code> - Probability of selection overall
</p>
</li>
<li> <p><code>psel_scaled</code> - Probability of selection scaled overall
</p>
</li>
<li> <p><code>psel_std</code> - Probability of selection standardized within a site
</p>
</li>
<li> <p><code>psel_normalized</code> - Probability of selection normalized within a site
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>s &lt;- clean_site_index(example_sites_clean,
  name_date_time = c("date_time_start", "date_time_end")
)
m &lt;- clean_metadata(project_files = example_files) |&gt;
  add_sites(s) |&gt;
  calc_sun()

params &lt;- sim_selection_weights()
calc_selection_weights(m, params = params)
</code></pre>

<hr>
<h2 id='calc_sun'>Calculate time to sunrise/sunset</h2><span id='topic+calc_sun'></span>

<h3>Description</h3>

<p>Calculate the sunrise/sunset of each sound file for the day of, the day before
and the day after to get the nearest sunrise to the recording. Times are
calculated using the 'suncalc' package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_sun(meta_sites, aru_tz = "local")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calc_sun_+3A_meta_sites">meta_sites</code></td>
<td>
<p>(Spatial) Data frame. Recording metadata with added
coordinates. Output of <code>clean_metadata()</code> and then <code>add_sites()</code> (with
either <code>clean_gps()</code> or <code>clean_site_index()</code>).</p>
</td></tr>
<tr><td><code id="calc_sun_+3A_aru_tz">aru_tz</code></td>
<td>
<p>Character. Must be either &quot;local&quot; or a timezone listed in
<code>OlsonNames()</code>. See Details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Timezones. To ensure that the sunrise/sunset times are calculated
correctly relative to the time of the recording, we need to know the
timezone of the date/time of the recording. If ARUs were calibrated with a
specific timezone before going into the field, that can be specified by
using, for example, <code>aru_tz = "America/Toronto"</code>. If on the other hand each
ARU was calibrated to whichever timezone was local when it was deployed use
<code>aru_tz = "local"</code>. The specific timezone will be calculated individually
based on the longitude and latitude of each recording.
</p>


<h3>Value</h3>

<p>Data frame with metadata and added timezone of recording time (<code>tz</code>),
and time to sunrise/sunset (<code>t2sr</code>, <code>t2ss</code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s &lt;- clean_site_index(example_sites_clean,
  name_date = c("date_time_start", "date_time_end")
)
m &lt;- clean_metadata(project_files = example_files) |&gt;
  add_sites(s)
calc_sun(m)

</code></pre>

<hr>
<h2 id='check_file'>Explore a file</h2><span id='topic+check_file'></span>

<h3>Description</h3>

<p>Shows the first few lines in a text file. Useful for trying to understand
problems in GPS files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_file(file_name, n_max = 10, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_file_+3A_file_name">file_name</code></td>
<td>
<p>Character. File path to check.</p>
</td></tr>
<tr><td><code id="check_file_+3A_n_max">n_max</code></td>
<td>
<p>Numeric. Number of lines in the file to show. Default 10.</p>
</td></tr>
<tr><td><code id="check_file_+3A_...">...</code></td>
<td>
<p>Arguments passed on to <code>readr::read_lines()</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Wrapper around <code>readr::read_lines(n_max)</code>.
</p>


<h3>Value</h3>

<p>A character vector with one element for each line
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- system.file("extdata", "logfile_00015141_SD1.txt", package = "ARUtools")
check_file(f)

</code></pre>

<hr>
<h2 id='check_meta'>Check output of <code>clean_metadata()</code></h2><span id='topic+check_meta'></span>

<h3>Description</h3>

<p>Cleaning metadata can take a series of tries. This function helps summarize
and explore the metadata for possible patterns which may help find problems.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_meta(meta, date = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_meta_+3A_meta">meta</code></td>
<td>
<p>Data frame. Recording metadata. Output of <code>clean_metadata()</code>.</p>
</td></tr>
<tr><td><code id="check_meta_+3A_date">date</code></td>
<td>
<p>Logical. Whether to summarize output by date (as well as
<code>site_id</code> and <code>aru_id</code>. Default <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame summarizing the metadata by site_id, aru_type, aru_id,
and (optionally) by date. Presents the number of files, directories, and days
worth of recordings, as well as the minimum and maximum recording times.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- clean_metadata(project_files = example_files)

check_meta(m)
check_meta(m, date = TRUE)

</code></pre>

<hr>
<h2 id='check_problems'>Check problems in output of <code>clean_metadata()</code></h2><span id='topic+check_problems'></span>

<h3>Description</h3>

<p>Cleaning metadata can take a series of tries. This function helps summarize
and explore missing metadata (problems).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_problems(
  df,
  check = c("site_id", "aru_id", "date", "date_time", "longitude", "latitude"),
  path = FALSE,
  date = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_problems_+3A_df">df</code></td>
<td>
<p>Data frame. Either meta data (<code>clean_metadata()</code>) or GPS
coordinates (<code>clean_gps()</code>)</p>
</td></tr>
<tr><td><code id="check_problems_+3A_check">check</code></td>
<td>
<p>Character. Character vector of columns to check for missing
values. Default is <code>site_id</code>, <code>aru_id</code>, <code>date</code>, <code>date_time</code>, <code>longitude</code>
and <code>latitude</code>.</p>
</td></tr>
<tr><td><code id="check_problems_+3A_path">path</code></td>
<td>
<p>Logical. Whether to return just the file paths which have missing
attributes. Default <code>FALSE</code></p>
</td></tr>
<tr><td><code id="check_problems_+3A_date">date</code></td>
<td>
<p>Logical. Whether to summarize output by date (as well as
<code>site_id</code> and <code>aru_id</code>. Default <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame summarizing the metadata by site_id, aru_type, aru_id,
and (optionally) by date. Presents the number of files, directories, and days
worth of recordings, as well as the minimum and maximum recording times.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
m &lt;- clean_metadata(project_files = example_files, pattern_aru_id = "test")

check_problems(m)
check_problems(m, date = TRUE)
check_problems(m, path = TRUE)
</code></pre>

<hr>
<h2 id='clean_gps'>Check and clean GPS data</h2><span id='topic+clean_gps'></span>

<h3>Description</h3>

<p>Check and clean GPS data from ARU logs. GPS points are checked for obvious
problems (expected range, distance cutoffs and timing) then attached to the
meta data frame. Note that it is often safer and more reliable to create
your own Site Index file including site ids, and GPS coordinates. This file
can be cleaned and prepared with <code>clean_site_index()</code> instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clean_gps(
  meta = NULL,
  dist_cutoff = 100,
  dist_crs = 3161,
  dist_by = c("site_id", "aru_id"),
  quiet = FALSE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clean_gps_+3A_meta">meta</code></td>
<td>
<p>Data frame. Output of <code>clean_metadata()</code>.</p>
</td></tr>
<tr><td><code id="clean_gps_+3A_dist_cutoff">dist_cutoff</code></td>
<td>
<p>Numeric. Maximum distance (m) between GPS points within a
site. Default is 100m but can be set to <code>Inf</code> to skip.</p>
</td></tr>
<tr><td><code id="clean_gps_+3A_dist_crs">dist_crs</code></td>
<td>
<p>Numeric. Coordinate Reference System to use when calculating
distance (should be one with m).</p>
</td></tr>
<tr><td><code id="clean_gps_+3A_dist_by">dist_by</code></td>
<td>
<p>Character. Column which identifies sites within which to
compare distance among GPS points. Only valid if <code>dist_cutoff</code> is not
<code>Inf</code>.</p>
</td></tr>
<tr><td><code id="clean_gps_+3A_quiet">quiet</code></td>
<td>
<p>Logical. Whether to suppress progress messages and other
non-essential updates.</p>
</td></tr>
<tr><td><code id="clean_gps_+3A_verbose">verbose</code></td>
<td>
<p>Logical. Show extra loading information. Default <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If checking for a maximum distance (<code>dist_cutoff</code>) among GPS points within a
group (<code>dist_by</code>), the returned data frame will include a column <code>max_dist</code>,
which represents the largest distance among points within that group.
</p>


<h3>Value</h3>

<p>Data frame of site-level metadata.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
m &lt;- clean_metadata(project_dir = "my_project")
g &lt;- clean_gps(meta = m)

</code></pre>

<hr>
<h2 id='clean_logs'>Extract log data from BAR-LT log files</h2><span id='topic+clean_logs'></span>

<h3>Description</h3>

<p>Process BAR-LT log files into a data frame reflecting metadata, schedule
information, and events. Events are time-stamped logs of either GPS fixes
(<code>lat</code> and <code>lon</code>) or recordings (<code>rec_file</code>, <code>rec_size</code>, <code>rec_end</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clean_logs(
  log_files,
  return = "all",
  pattern_sr = "(SR)",
  pattern_ss = "(SS)",
  progress = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clean_logs_+3A_log_files">log_files</code></td>
<td>
<p>Character vector of log files to process.</p>
</td></tr>
<tr><td><code id="clean_logs_+3A_return">return</code></td>
<td>
<p>Character. What kind of data to return, GPS fixes (<code>"gps"</code>),
recording events (<code>"recordings"</code>) or <code>"all"</code> (default).</p>
</td></tr>
<tr><td><code id="clean_logs_+3A_pattern_sr">pattern_sr</code></td>
<td>
<p>Character. Pattern to match the sunrise schedule in the log
files.</p>
</td></tr>
<tr><td><code id="clean_logs_+3A_pattern_ss">pattern_ss</code></td>
<td>
<p>Character. Pattern to match the sunset schedule in the log
files.</p>
</td></tr>
<tr><td><code id="clean_logs_+3A_progress">progress</code></td>
<td>
<p>Logical. Whether to use <code>purrr::map()</code> progress bars (default
<code>TRUE</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that log files can have glitches. If there is no start time for a
recording (generally when there is a problem and no recording is made), the
<code>date_time</code> value for that recording will be the same as the <code>rec_end</code> time.
</p>
<p>Because the BAR-LT units adjust their time according to the GPS locations,
all times are in &quot;local&quot; to that area.
</p>


<h3>Value</h3>

<p>Data frame containing
</p>

<ul>
<li> <p><code>file_name</code>s and <code>path</code>s of the log files
</p>
</li>
<li> <p><code>event</code>s and their <code>date_time</code>s
</p>
</li>
<li> <p><code>lat</code> and <code>lon</code> for &quot;gps&quot; events
</p>
</li>
<li> <p><code>rec_file</code>, <code>rec_size</code> and <code>rec_end</code> for &quot;recording&quot; events
(recording start is the <code>date_time</code> of the event)
</p>
</li>
<li> <p><code>schedule</code> information such as <code>schedule_date</code>, <code>schedule_name</code>,
<code>schedule_lat</code>, <code>schedule_lon</code>, <code>schedule_sr</code> (sunrise),
and <code>schedule_ss</code> (sunset)
</p>
</li>
<li> <p><code>meta</code>data information such as <code>meta_serial</code> and <code>meta_firmware</code>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
# Replace "my_project_folder" with your directory containing your recordings and logfiles
log_files &lt;- fs::dir_ls("my_project_folder", recurse = TRUE, glob = "*logfile*")
log_files
logs &lt;- clean_logs(log_files)

log_files &lt;- "../ARUtools - Extra/aru_log_files/P028/1A_BARLT10962/logfile_00010962_SD1.txt"

clean_logs(log_files)
clean_logs(log_files, return = "gps")
clean_logs(log_files, return = "recordings")

log_files &lt;- fs::dir_ls("../ARUtools - Extra/aru_log_files/", recurse = TRUE, glob = "*logfile*")

l &lt;- clean_logs(log_files)

</code></pre>

<hr>
<h2 id='clean_metadata'>Extract and clean ARU metadata from file names</h2><span id='topic+clean_metadata'></span>

<h3>Description</h3>

<p>Using regular expressions, metadata is extracted from file names and
directory structure, checked and cleaned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clean_metadata(
  project_dir = NULL,
  project_files = NULL,
  file_type = "wav",
  subset = NULL,
  subset_type = "keep",
  pattern_site_id = create_pattern_site_id(),
  pattern_aru_id = create_pattern_aru_id(),
  pattern_date = create_pattern_date(),
  pattern_time = create_pattern_time(),
  pattern_dt_sep = create_pattern_dt_sep(),
  order_date = "ymd",
  quiet = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clean_metadata_+3A_project_dir">project_dir</code></td>
<td>
<p>Character. Directory where project files are stored. File
paths will be used to extract information and must actually exist.</p>
</td></tr>
<tr><td><code id="clean_metadata_+3A_project_files">project_files</code></td>
<td>
<p>Character. Vector of project file paths. These paths can
be absolute or relative to the working directory, and don't actually need
to point to existing files unless you plan to use <code>clean_gps()</code> or other
sampling steps down the line. Must be provided if <code>project_dir</code> is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="clean_metadata_+3A_file_type">file_type</code></td>
<td>
<p>Character. Type of file (extension) to summarize. Default
wav.</p>
</td></tr>
<tr><td><code id="clean_metadata_+3A_subset">subset</code></td>
<td>
<p>Character. Text pattern to mark a subset of files/directories
to either <code>"keep"</code> or <code>"omit"</code> (see <code>subset_type</code>)</p>
</td></tr>
<tr><td><code id="clean_metadata_+3A_subset_type">subset_type</code></td>
<td>
<p>Character. Either <code>keep</code> (default) or <code>omit</code>
files/directories which match the pattern in <code>subset</code>.</p>
</td></tr>
<tr><td><code id="clean_metadata_+3A_pattern_site_id">pattern_site_id</code></td>
<td>
<p>Character. Regular expression to extract site ids. See
<code>create_pattern_site_id()</code>. Can be a vector of multiple patterns to match.</p>
</td></tr>
<tr><td><code id="clean_metadata_+3A_pattern_aru_id">pattern_aru_id</code></td>
<td>
<p>Character. Regular expression to extract ARU ids. See
<code>create_pattern_aru_id()</code>. Can be a vector of multiple patterns to match.</p>
</td></tr>
<tr><td><code id="clean_metadata_+3A_pattern_date">pattern_date</code></td>
<td>
<p>Character. Regular expression to extract dates. See
<code>create_pattern_date()</code>. Can be a vector of multiple patterns to match.</p>
</td></tr>
<tr><td><code id="clean_metadata_+3A_pattern_time">pattern_time</code></td>
<td>
<p>Character. Regular expression to extract times. See
<code>create_pattern_time()</code>. Can be a vector of multiple patterns to match.</p>
</td></tr>
<tr><td><code id="clean_metadata_+3A_pattern_dt_sep">pattern_dt_sep</code></td>
<td>
<p>Character. Regular expression to mark separators
between dates and times. See <code>create_pattern_dt_sep()</code>.</p>
</td></tr>
<tr><td><code id="clean_metadata_+3A_order_date">order_date</code></td>
<td>
<p>Character. Order that the date appears in. &quot;ymd&quot;
(default), &quot;mdy&quot;, or &quot;dmy&quot;. Can be a vector of multiple patterns to match.</p>
</td></tr>
<tr><td><code id="clean_metadata_+3A_quiet">quiet</code></td>
<td>
<p>Logical. Whether to suppress progress messages and other
non-essential updates.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that times are extracted by first combining the date, date/time
separator and the time patterns. This means that if there is a problem with
this combination, dates might be extracted but date/times will not. This
mismatch can be used to determine which part of a pattern needs to be
tweaked.
</p>
<p>See <code>vignette("customizing", package = "ARUtools")</code> for details on
customizing <code>clean_metadata()</code> for your project.
</p>


<h3>Value</h3>

<p>Data frame with extracted metadata
</p>


<h3>Examples</h3>

<pre><code class='language-R'>clean_metadata(project_files = example_files)
clean_metadata(project_files = example_files, subset = "P02")

</code></pre>

<hr>
<h2 id='clean_site_index'>Prepare and clean site index file</h2><span id='topic+clean_site_index'></span>

<h3>Description</h3>

<p>A site index file contains information on when specific ARUs were deployed
where. This function cleans a file (csv, xlsx) or data frame in preparation
for adding these details to the output of <code>clean_metadata()</code>. It can be used
to specify missing information according to date, such as GPS lon/lats and
site ids.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clean_site_index(
  site_index,
  name_aru_id = "aru_id",
  name_site_id = "site_id",
  name_date_time = "date",
  name_coords = c("longitude", "latitude"),
  name_extra = NULL,
  resolve_overlaps = TRUE,
  quiet = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clean_site_index_+3A_site_index">site_index</code></td>
<td>
<p>(Spatial) Data frame or file path. Site index data
to clean. If file path, must be to a local csv or xlsx file.</p>
</td></tr>
<tr><td><code id="clean_site_index_+3A_name_aru_id">name_aru_id</code></td>
<td>
<p>Character. Name of the column that contains ARU ids.
Default <code>"aru_id"</code>.</p>
</td></tr>
<tr><td><code id="clean_site_index_+3A_name_site_id">name_site_id</code></td>
<td>
<p>Character. Name of the column that contains site ids.
Default <code>"site_id"</code>.</p>
</td></tr>
<tr><td><code id="clean_site_index_+3A_name_date_time">name_date_time</code></td>
<td>
<p>Character. Column name that contains dates or
date/times. Can be vector of two names if there are both 'start' and 'end'
columns. Can be <code>NULL</code> to ignore dates. Default <code>"date"</code>.</p>
</td></tr>
<tr><td><code id="clean_site_index_+3A_name_coords">name_coords</code></td>
<td>
<p>Character. Column names that contain longitude and
latitude (in that order). Ignored if <code>site_index</code> is spatial. Default
<code>c("longitude", "latitude")</code></p>
</td></tr>
<tr><td><code id="clean_site_index_+3A_name_extra">name_extra</code></td>
<td>
<p>Character. Column names for extra data to include. If a named
vector, will rename the columns (see examples). Default <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="clean_site_index_+3A_resolve_overlaps">resolve_overlaps</code></td>
<td>
<p>Logical. Whether or not to resolve date overlaps by
shifting the start/end dates to noon (default <code>TRUE</code>). This assumes that
ARUs are generally <em>not</em> deployed/removed at midnight (the official
start/end of a day) and so noon is used as an approximation for when an ARU
was deployed or removed. If possible, use specific deployment times to
avoid this issue.</p>
</td></tr>
<tr><td><code id="clean_site_index_+3A_quiet">quiet</code></td>
<td>
<p>Logical. Whether to suppress progress messages and other
non-essential updates.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that times are assumed to be in 'local' time and a timezone isn't used
(and is removed if present, replaced with UTC). This allows sites
from different timezones to be processed at the same time.
</p>


<h3>Value</h3>

<p>Standardized site index data frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
s &lt;- clean_site_index(example_sites,
  name_aru_id = "ARU",
  name_site_id = "Sites",
  name_date_time = c("Date_set_out", "Date_removed"),
  name_coords = c("lon", "lat")
)

s &lt;- clean_site_index(example_sites,
  name_aru_id = "ARU",
  name_site_id = "Sites",
  name_date_time = c("Date_set_out", "Date_removed"),
  name_coords = c("lon", "lat"),
  name_extra = c("plot" = "Plots")
)

# Without dates
eg &lt;- dplyr::select(example_sites, -Date_set_out, -Date_removed)
s &lt;- clean_site_index(eg,
  name_aru_id = "ARU",
  name_site_id = "Sites",
  name_date_time = NULL,
  name_coords = c("lon", "lat"),
  name_extra = c("plot" = "Plots")
)

</code></pre>

<hr>
<h2 id='clip_wave'>Clip multiple wave files and format names</h2><span id='topic+clip_wave'></span>

<h3>Description</h3>

<p>Process multiple wave files by copying them with a new filename and
clipping to a given length.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clip_wave(
  waves,
  dir_out,
  dir_in = NULL,
  col_path_in = path,
  col_subdir_out = subdir_out,
  col_filename_out = filename_out,
  col_clip_length = clip_length,
  col_start_time = start_time,
  overwrite = FALSE,
  create_dir = TRUE,
  diff_limit = 30,
  use_job = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clip_wave_+3A_waves">waves</code></td>
<td>
<p>Data frame. Details of file locations.</p>
</td></tr>
<tr><td><code id="clip_wave_+3A_dir_out">dir_out</code></td>
<td>
<p>Character. Output directory.</p>
</td></tr>
<tr><td><code id="clip_wave_+3A_dir_in">dir_in</code></td>
<td>
<p>Character. Directory wave files are read from. Default is
<code>NULL</code> meaning the current working directory.</p>
</td></tr>
<tr><td><code id="clip_wave_+3A_col_path_in">col_path_in</code></td>
<td>
<p>Column. Unquoted column containing the current file paths.
Default <code>path</code>.
<strong>Note: file paths must be either relative to <code>dir_in</code> or absolute</strong>.</p>
</td></tr>
<tr><td><code id="clip_wave_+3A_col_subdir_out">col_subdir_out</code></td>
<td>
<p>Column. Unquoted column containing the
subdirectories in which to put output files. Default <code>subdir_out</code>.</p>
</td></tr>
<tr><td><code id="clip_wave_+3A_col_filename_out">col_filename_out</code></td>
<td>
<p>Column. Unquoted column containing the output
filenames. Default <code>filename_out</code>.</p>
</td></tr>
<tr><td><code id="clip_wave_+3A_col_clip_length">col_clip_length</code></td>
<td>
<p>Column. Unquoted column containing the length of the
new clip. Default <code>length</code>.</p>
</td></tr>
<tr><td><code id="clip_wave_+3A_col_start_time">col_start_time</code></td>
<td>
<p>Column. Unquoted column containing the start time of
the new clip. Default <code>start_time</code>.</p>
</td></tr>
<tr><td><code id="clip_wave_+3A_overwrite">overwrite</code></td>
<td>
<p>Logical. Overwrite pre-existing files when clipping and
moving. Default <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="clip_wave_+3A_create_dir">create_dir</code></td>
<td>
<p>Logical. Whether to create directory structure for newly
formatted and clipped wave files.</p>
</td></tr>
<tr><td><code id="clip_wave_+3A_diff_limit">diff_limit</code></td>
<td>
<p>Numeric. How much longer in seconds clip lengths can be
compared to file lengths before triggering an error. Default <code>30</code>.</p>
</td></tr>
<tr><td><code id="clip_wave_+3A_use_job">use_job</code></td>
<td>
<p>Logical. Use the 'job' package to copy files Default <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE if successful and clipped wave files created
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
w &lt;- data.frame(
  path = temp_wavs(n = 4),
  subdir_out = c("test1/a", "test2/a", "test3/c", "test4/d"),
  subsub_dir_out = rep("zz", 4),
  filename_out = c("wave1_clean.wav", "wave2_clean.wav", "wave3_clean.wav", "wave4_clean.wav"),
  clip_length = c(1, 1, 1, 2),
  start_time = c(1.2, 0.5, 1, 0)
)

clip_wave(w, dir_out = "clean", col_subdir_out = c(subdir_out, subsub_dir_out))

unlink("clean", recursive = TRUE) # Remove this new 'clean' directory

</code></pre>

<hr>
<h2 id='clip_wave_single'>Clip single wave file</h2><span id='topic+clip_wave_single'></span>

<h3>Description</h3>

<p>Clip and copy a single wave files to a given length. See <code>clip_wave()</code> for
processing multiple files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clip_wave_single(
  path_in,
  path_out,
  clip_length,
  start_time = 0,
  wave_length = NULL,
  overwrite = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clip_wave_single_+3A_path_in">path_in</code></td>
<td>
<p>Character. Path to the wave file to clip.</p>
</td></tr>
<tr><td><code id="clip_wave_single_+3A_path_out">path_out</code></td>
<td>
<p>Character. Path to copy the new clipped wave file to.</p>
</td></tr>
<tr><td><code id="clip_wave_single_+3A_clip_length">clip_length</code></td>
<td>
<p>Numeric. Length of new clip in seconds.</p>
</td></tr>
<tr><td><code id="clip_wave_single_+3A_start_time">start_time</code></td>
<td>
<p>Numeric. Time in seconds where new clip should start.
Default 0.</p>
</td></tr>
<tr><td><code id="clip_wave_single_+3A_wave_length">wave_length</code></td>
<td>
<p>Numeric. Length of the clipped wave file in seconds (if
<code>NULL</code>, default, will be the length of time from <code>start_time</code> to the end of
the file).</p>
</td></tr>
<tr><td><code id="clip_wave_single_+3A_overwrite">overwrite</code></td>
<td>
<p>Logical. Whether to overwrite existing files when creating
new clipped wave files. Default (<code>FALSE</code>) will error if the file already
exists.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE if successful
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create test wave file
f &lt;- temp_wavs(1)

# Clip file and check it out
clip_wave_single(f, "new_file.wav", clip_length = 1)
tuneR::readWave("new_file.wav")
unlink("new_file.wav")
</code></pre>

<hr>
<h2 id='common_docs'>Common arguments and documentation for various functions</h2><span id='topic+common_docs'></span>

<h3>Description</h3>

<p>Common arguments and documentation for various functions
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="common_docs_+3A_project_dir">project_dir</code></td>
<td>
<p>Character. Directory where project files are stored. File
paths will be used to extract information and must actually exist.</p>
</td></tr>
<tr><td><code id="common_docs_+3A_project_files">project_files</code></td>
<td>
<p>Character. Vector of project file paths. These paths can
be absolute or relative to the working directory, and don't actually need
to point to existing files unless you plan to use <code>clean_gps()</code> or other
sampling steps down the line. Must be provided if <code>project_dir</code> is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="common_docs_+3A_subset">subset</code></td>
<td>
<p>Character. Text pattern to mark a subset of files/directories
to either <code>"keep"</code> or <code>"omit"</code> (see <code>subset_type</code>)</p>
</td></tr>
<tr><td><code id="common_docs_+3A_subset_type">subset_type</code></td>
<td>
<p>Character. Either <code>keep</code> (default) or <code>omit</code>
files/directories which match the pattern in <code>subset</code>.</p>
</td></tr>
<tr><td><code id="common_docs_+3A_meta">meta</code></td>
<td>
<p>Data frame. Recording metadata. Output of <code>clean_metadata()</code>.</p>
</td></tr>
<tr><td><code id="common_docs_+3A_meta_sites">meta_sites</code></td>
<td>
<p>(Spatial) Data frame. Recording metadata with added
coordinates. Output of <code>clean_metadata()</code> and then <code>add_sites()</code> (with
either <code>clean_gps()</code> or <code>clean_site_index()</code>).</p>
</td></tr>
<tr><td><code id="common_docs_+3A_col_site_id">col_site_id</code></td>
<td>
<p>Column. Unquoted column containing site strata IDs
(defaults to <code>site_id</code>).</p>
</td></tr>
<tr><td><code id="common_docs_+3A_date">date</code></td>
<td>
<p>Logical. Whether to summarize output by date (as well as
<code>site_id</code> and <code>aru_id</code>. Default <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="common_docs_+3A_path">path</code></td>
<td>
<p>Character. Path to wave file.</p>
</td></tr>
<tr><td><code id="common_docs_+3A_dir_out">dir_out</code></td>
<td>
<p>Character. Output directory.</p>
</td></tr>
<tr><td><code id="common_docs_+3A_quiet">quiet</code></td>
<td>
<p>Logical. Whether to suppress progress messages and other
non-essential updates.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Use <code style="white-space: pre;">&#8288;@inheritParams common_docs&#8288;</code> to include the above in any function
documentation with a matching argument (will only include matching args)
</p>

<hr>
<h2 id='count_files'>Count files in a project directory</h2><span id='topic+count_files'></span>

<h3>Description</h3>

<p>Helper function to explore the number of files in a directory, recursively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>count_files(project_dir, subset = NULL, subset_type = "keep")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="count_files_+3A_project_dir">project_dir</code></td>
<td>
<p>Character. Directory where project files are stored. File
paths will be used to extract information and must actually exist.</p>
</td></tr>
<tr><td><code id="count_files_+3A_subset">subset</code></td>
<td>
<p>Character. Text pattern to mark a subset of files/directories
to either <code>"keep"</code> or <code>"omit"</code> (see <code>subset_type</code>)</p>
</td></tr>
<tr><td><code id="count_files_+3A_subset_type">subset_type</code></td>
<td>
<p>Character. Either <code>keep</code> (default) or <code>omit</code>
files/directories which match the pattern in <code>subset</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with number of files in a directory
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
count_files("PROJECT_DIR")

</code></pre>

<hr>
<h2 id='create_dirs'>Create directory structure for recording folders</h2><span id='topic+create_dirs'></span>

<h3>Description</h3>

<p>Create a set of nested folders for storing ARU recordings by plots and sites.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_dirs(
  plots,
  site_ids,
  base_dir = NULL,
  dir_list = FALSE,
  dry_run = TRUE,
  expect_dirs = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_dirs_+3A_plots">plots</code></td>
<td>
<p>Character vector. Hexagon or cluster names for folder names.</p>
</td></tr>
<tr><td><code id="create_dirs_+3A_site_ids">site_ids</code></td>
<td>
<p>Character vector. Site IDs. Should include the plot/cluster
id in the name.</p>
</td></tr>
<tr><td><code id="create_dirs_+3A_base_dir">base_dir</code></td>
<td>
<p>Character. Base directory to build directory structure in.</p>
</td></tr>
<tr><td><code id="create_dirs_+3A_dir_list">dir_list</code></td>
<td>
<p>Logical. Whether to return a vector of directories (to be)
created (defaults to <code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="create_dirs_+3A_dry_run">dry_run</code></td>
<td>
<p>Logical. Whether to do a dry-run of the process (i.e. do not
actually create directories; defaults to <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="create_dirs_+3A_expect_dirs">expect_dirs</code></td>
<td>
<p>Logical. Expect that directories may already exist? Default
(<code>FALSE</code>) is to stop if directories to be created already exist.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>dir_list = TRUE</code>, returns a list of directories (to be) created.
If not a dry run, also creates the folder structure.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Default is to do a dry-run (don't actually create the directories)
create_dirs(
  plots = c("river1", "river2", "river3"),
  site_ids = c(
    "river1_sm01", "river1_sm02", "river2_sm03", "river2_sm04",
    "river3_sm05", "river3_sm06"
  ),
  base_dir = "Recordings"
)

# Get a list of directories which would be created
create_dirs(
  plots = c("river1", "river2", "river3"),
  site_ids = c(
    "river1_sm01", "river1_sm02", "river2_sm03", "river2_sm04",
    "river3_sm05", "river3_sm06"
  ),
  base_dir = "Recordings", dir_list = TRUE
)


# Create directories AND return a list of those created
d &lt;- create_dirs(
  plots = c("river1", "river2", "river3"),
  site_ids = c(
    "river1_sm01", "river1_sm02", "river2_sm03", "river2_sm04",
    "river3_sm05", "river3_sm06"
  ),
  base_dir = "Recordings", dir_list = TRUE, expect_dirs =TRUE,
  dry_run = FALSE
)
d

</code></pre>

<hr>
<h2 id='create_pattern'>Create a pattern to match date</h2><span id='topic+create_pattern'></span><span id='topic+create_pattern_date'></span><span id='topic+create_pattern_time'></span><span id='topic+create_pattern_dt_sep'></span><span id='topic+create_pattern_aru_id'></span><span id='topic+create_pattern_site_id'></span><span id='topic+test_pattern'></span>

<h3>Description</h3>

<p>Helper functions to create regular expression patterns to match different
metadata in file paths.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_pattern_date(order = "ymd", sep = c("_", "-", ""), yr_digits = 4)

create_pattern_time(sep = c("_", "-", ":", ""), seconds = "yes")

create_pattern_dt_sep(sep = "T", optional = FALSE)

create_pattern_aru_id(
  arus = c("BARLT", "S\\d(A|U)", "SM\\d", "SMM", "SMA"),
  n_digits = c(4, 8),
  sep = c("_", "-", ""),
  prefix = "",
  suffix = ""
)

create_pattern_site_id(
  prefix = c("P", "Q"),
  p_digits = 2,
  sep = c("_", "-"),
  suffix = "",
  s_digits = 1
)

test_pattern(test, pattern)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_pattern_+3A_order">order</code></td>
<td>
<p>Character vector. Expected orders of (y)ear, (m)onth and (d)ate.
Default is &quot;ymd&quot; for Year-Month-Date order. Can have more than one possible
order.</p>
</td></tr>
<tr><td><code id="create_pattern_+3A_sep">sep</code></td>
<td>
<p>Character vector. Expected separator(s) between the pattern parts.
Can be &quot;&quot; for no separator.</p>
</td></tr>
<tr><td><code id="create_pattern_+3A_yr_digits">yr_digits</code></td>
<td>
<p>Numeric vector. Number of digits in Year, either 2 or 4.</p>
</td></tr>
<tr><td><code id="create_pattern_+3A_seconds">seconds</code></td>
<td>
<p>Character. Whether seconds are included. Options are &quot;yes&quot;,
&quot;no&quot;, &quot;maybe&quot;.</p>
</td></tr>
<tr><td><code id="create_pattern_+3A_optional">optional</code></td>
<td>
<p>Logical. Whether the separator should be optional or not.
Allows matching on different date/time patterns.</p>
</td></tr>
<tr><td><code id="create_pattern_+3A_arus">arus</code></td>
<td>
<p>Character vector. Pattern(s) identifying the ARU prefix (usually
model specific).</p>
</td></tr>
<tr><td><code id="create_pattern_+3A_n_digits">n_digits</code></td>
<td>
<p>Numeric vector. Number of digits expected to follow the
<code>arus</code> pattern. Can be one or two (a range).</p>
</td></tr>
<tr><td><code id="create_pattern_+3A_prefix">prefix</code></td>
<td>
<p>Character vector. Prefix(es) for site ids.</p>
</td></tr>
<tr><td><code id="create_pattern_+3A_suffix">suffix</code></td>
<td>
<p>Character vector. Suffix(es) for site ids.</p>
</td></tr>
<tr><td><code id="create_pattern_+3A_p_digits">p_digits</code></td>
<td>
<p>Numeric vector. Number(s) of digits following the <code>prefix</code>.</p>
</td></tr>
<tr><td><code id="create_pattern_+3A_s_digits">s_digits</code></td>
<td>
<p>Numeric vector. Number(s) of digits following the <code>suffix</code>.</p>
</td></tr>
<tr><td><code id="create_pattern_+3A_test">test</code></td>
<td>
<p>Character vector. Examples of text to test.</p>
</td></tr>
<tr><td><code id="create_pattern_+3A_pattern">pattern</code></td>
<td>
<p>Character. Regular expression pattern to test.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default <code>create_pattern_aru_id()</code> matches many common ARU patterns like
<code>BARLT0000</code>, <code>S4A0000</code>, <code>SM40000</code>, <code>SMM0000</code>, <code>SMA0000</code>.
</p>
<p><code>test_pattern()</code> is a helper function to see what a regular expression
pattern will pick out of some example text. Can be used to see if your
pattern grabs what you want. This is just a simple wrapper around
<code>stringr::str_extract()</code>.
</p>


<h3>Value</h3>

<p>Either a pattern (<code>create_pattern_xxx()</code>) or the text extracted by a
pattern (<code>test_pattern()</code>)
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>create_pattern_date()</code>: Create a pattern to match a date
</p>
</li>
<li> <p><code>create_pattern_time()</code>: Create a pattern to match a time
</p>
</li>
<li> <p><code>create_pattern_dt_sep()</code>: Create a pattern to match a date/time separator
</p>
</li>
<li> <p><code>create_pattern_aru_id()</code>: Create a pattern to match an ARU id
</p>
</li>
<li> <p><code>create_pattern_site_id()</code>: Create a pattern to match a site id
</p>
</li>
<li> <p><code>test_pattern()</code>: Test patterns
</p>
</li></ul>


<h3>Examples</h3>

<pre><code class='language-R'>create_pattern_date() # Default matches 2020-01-01 or 2020_01_01 or 20200101
# ("-", "_" or "" as separators)
create_pattern_date(sep = "") # Matches only 20200101 (no separator allowed)

create_pattern_time() # Default matches 23_59_59 (_, -, :, as optional separators)
create_pattern_time(sep = "", seconds = "no") # Matches 2359 (no seconds no separators)

create_pattern_dt_sep() # Default matches 'T' as a required separator
create_pattern_dt_sep(optional = TRUE) # 'T' as an optional separator
create_pattern_dt_sep(c("T", "_", "-")) # 'T', '_', or '-' as separators

create_pattern_aru_id()
create_pattern_aru_id(prefix = "CWS")
create_pattern_aru_id(n_digits = 12)


create_pattern_site_id() # Default matches P00-0
create_pattern_site_id(
  prefix = "site", p_digits = 3, sep = "",
  suffix = c("a", "b", "c"), s_digits = 0
) # Matches site000a

pat &lt;- create_pattern_aru_id(prefix = "CWS")
test_pattern("CWS_BARLT1012", pat) # No luck
pat &lt;- create_pattern_aru_id(prefix = "CWS_")
test_pattern("CWS_BARLT1012", pat) # Ah ha!
pat &lt;- create_pattern_site_id()

pat &lt;- create_pattern_site_id()
test_pattern("P03", pat) # Nope
test_pattern("P03-1", pat) # Success!

pat &lt;- create_pattern_site_id(prefix = "site", p_digits = 3, sep = "", s_digits = 0)
test_pattern("site111", pat)
pat &lt;- create_pattern_site_id(
  prefix = "site", p_digits = 3, sep = "",
  suffix = c("a", "b", "c"), s_digits = 0
)
test_pattern(c("site9", "site100a"), pat)

</code></pre>

<hr>
<h2 id='example_clean'>Example cleaned recording meta data</h2><span id='topic+example_clean'></span>

<h3>Description</h3>

<p>A data frame with examples of correctly formatted metadata with added
site-level information
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example_clean
</code></pre>


<h3>Format</h3>



<h4><code>example_clean</code></h4>

<p>A data frame with 42 rows and 10 columns:
</p>

<dl>
<dt>file_name</dt><dd><p>Name of the file</p>
</dd>
<dt>type</dt><dd><p>File type</p>
</dd>
<dt>path</dt><dd><p>Relative file path including file name</p>
</dd>
<dt>aru_type</dt><dd><p>ARU model</p>
</dd>
<dt>aru_id</dt><dd><p>ARU ids</p>
</dd>
<dt>site_id</dt><dd><p>Site ids</p>
</dd>
<dt>date_time</dt><dd><p>Recording date/time</p>
</dd>
<dt>date</dt><dd><p>Recording date</p>
</dd>
<dt>longitude</dt><dd><p>Latitude in decimal degrees</p>
</dd>
<dt>latitude</dt><dd><p>Longitude in decimal degrees</p>
</dd>
</dl>




<h3>Source</h3>

<p>data-raw/data_test.R
</p>

<hr>
<h2 id='example_files'>Example recording files</h2><span id='topic+example_files'></span>

<h3>Description</h3>

<p>A vector of examples ARU recording files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example_files
</code></pre>


<h3>Format</h3>



<h4><code>example_files</code></h4>

<p>A vector with 42 file paths
</p>



<h3>Source</h3>

<p>data-raw/data_test.R
</p>

<hr>
<h2 id='example_files_long'>Example long-term deployment recording files</h2><span id='topic+example_files_long'></span>

<h3>Description</h3>

<p>A vector of examples ARU recording files. Uses the
<code>example_sites</code> data, but deploys them for a longer deployment
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example_files_long
</code></pre>


<h3>Format</h3>



<h4><code>example_files_long</code></h4>

<p>A vector with 614 file paths
</p>



<h3>Source</h3>

<p>data-raw/data_long_deployment.R
</p>

<hr>
<h2 id='example_sites'>Example site-level meta data</h2><span id='topic+example_sites'></span>

<h3>Description</h3>

<p>A data frame with examples of incorrectly formatted site-level data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example_sites
</code></pre>


<h3>Format</h3>



<h4><code>example_sites</code></h4>

<p>A data frame with 10 rows and 8 columns:
</p>

<dl>
<dt>Sites</dt><dd><p>Site ids</p>
</dd>
<dt>Date_set_out</dt><dd><p>Deployment start date</p>
</dd>
<dt>Date_removed</dt><dd><p>Deployment end date</p>
</dd>
<dt>ARU</dt><dd><p>ARU ids</p>
</dd>
<dt>lon</dt><dd><p>Longitude in decimal degrees</p>
</dd>
<dt>lat</dt><dd><p>Latitude in decimal degrees</p>
</dd>
<dt>Plots</dt><dd><p>Hypothetical extra plot column</p>
</dd>
<dt>Subplot</dt><dd><p>Hypothetical extra subplot column</p>
</dd>
</dl>




<h3>Source</h3>

<p>data-raw/data_test.R
</p>

<hr>
<h2 id='example_sites_clean'>Example cleaned site-level meta data</h2><span id='topic+example_sites_clean'></span>

<h3>Description</h3>

<p>A data frame with examples of correctly formatted site-level data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example_sites_clean
</code></pre>


<h3>Format</h3>



<h4><code>example_sites_clean</code></h4>

<p>A data frame with 10 rows and 8 columns:
</p>

<dl>
<dt>site_id</dt><dd><p>Site ids</p>
</dd>
<dt>aru_id</dt><dd><p>ARU ids</p>
</dd>
<dt>date_time_start</dt><dd><p>Deployment start date/time</p>
</dd>
<dt>date_time_end</dt><dd><p>Deployment end date/time</p>
</dd>
<dt>date_start</dt><dd><p>Deployment start date</p>
</dd>
<dt>date_end</dt><dd><p>Deployment end date</p>
</dd>
<dt>longitude</dt><dd><p>Latitude in decimal degrees</p>
</dd>
<dt>latitude</dt><dd><p>Longitude in decimal degrees</p>
</dd>
</dl>




<h3>Source</h3>

<p>data-raw/data_test.R
</p>

<hr>
<h2 id='get_wav_length'>Get the length of a recording in seconds</h2><span id='topic+get_wav_length'></span>

<h3>Description</h3>

<p>Get the length of a recording in seconds
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_wav_length(path, return_numeric = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_wav_length_+3A_path">path</code></td>
<td>
<p>Character. Path to wave file.</p>
</td></tr>
<tr><td><code id="get_wav_length_+3A_return_numeric">return_numeric</code></td>
<td>
<p>Logical. Return numeric or character?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Length of recording in seconds
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  f &lt;- tempfile()
  w &lt;- tuneR::sine(440, duration = 100000)
  tuneR::writeWave(w, f)
  get_wav_length(f)
</code></pre>

<hr>
<h2 id='sample_recordings'>Sample recordings</h2><span id='topic+sample_recordings'></span>

<h3>Description</h3>

<p>Sample recordings based on selection weights from <code>calc_selection_weights()</code>
using <code>spsurvey::grts()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_recordings(
  meta_weights,
  n,
  os = NULL,
  col_site_id = site_id,
  col_sel_weights = psel_std,
  seed = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_recordings_+3A_meta_weights">meta_weights</code></td>
<td>
<p>(Spatial) Data frame. Recording meta data selection
weights. Output of <code>calc_selection_weights()</code>. Must have at least the
columns identified by <code>col_site_id</code> and <code>col_sel_weights</code>, as well as the
probability of selection columns (those starting with <code>psel</code>) and <code>doy</code>.</p>
</td></tr>
<tr><td><code id="sample_recordings_+3A_n">n</code></td>
<td>
<p>Numeric, Data frame, Vector, or List. Number of base samples to
choose. For stratification by site, a named vector/list of samples per site, or
a data frame with columns <code>n</code> for samples, <code>n_os</code> for oversamples and the
column matching that identified by <code>col_site_id</code>.</p>
</td></tr>
<tr><td><code id="sample_recordings_+3A_os">os</code></td>
<td>
<p>Numeric, Vector, or List. Over sample size (proportional) or named
vector/list of number of samples per site Ignored if <code>n</code> is a data
frame.</p>
</td></tr>
<tr><td><code id="sample_recordings_+3A_col_site_id">col_site_id</code></td>
<td>
<p>Column. Unquoted column containing site strata IDs
(defaults to <code>site_id</code>).</p>
</td></tr>
<tr><td><code id="sample_recordings_+3A_col_sel_weights">col_sel_weights</code></td>
<td>
<p>Column. Unquoted name of column identifying selection
weights (defaults to <code>psel_std</code>)</p>
</td></tr>
<tr><td><code id="sample_recordings_+3A_seed">seed</code></td>
<td>
<p>Numeric. Random seed to use for random sampling. Seed only
applies to specific sampling events (does not change seed in the
environment). <code>NULL</code> does not set a seed.</p>
</td></tr>
<tr><td><code id="sample_recordings_+3A_...">...</code></td>
<td>
<p>Extra named arguments passed on to <code>spsurvey::grts()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A sampling run from grts. Note that the included dataset is spatial,
but is a dummy spatial dataset created by using dates and times to create
the spatial landscape.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s &lt;- clean_site_index(example_sites_clean,
  name_date_time = c("date_time_start", "date_time_end")
)
m &lt;- clean_metadata(project_files = example_files) |&gt;
  add_sites(s) |&gt;
  calc_sun()

params &lt;- sim_selection_weights()
w &lt;- calc_selection_weights(m, params = params)

# No stratification by site
samples &lt;- sample_recordings(w, n = 10, os = 0.1, col_site_id = NULL)

# Stratification by site defined by...

# lists
samples &lt;- sample_recordings(w, n = list(P01_1 = 2, P02_1 = 5, P03_1 = 2), os = 0.2)

# vectors
samples &lt;- sample_recordings(w, n = c(P01_1 = 2, P02_1 = 5, P03_1 = 2), os = 0.2)

# data frame
samples &lt;- sample_recordings(
  w,
  n = data.frame(
    site_id = c("P01_1", "P02_1", "P03_1"),
    n = c(2, 5, 2),
    n_os = c(0, 0, 1)
  )
)

</code></pre>

<hr>
<h2 id='sim_selection_weights'>Create parameters and simulate selection weights</h2><span id='topic+sim_selection_weights'></span>

<h3>Description</h3>

<p>This function creates and explores parameters for generating selections.
These parameters define the selection distribution of minutes (<code>min</code>) around
the sun event (sunrise/sunset), as well as of days (<code>day</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_selection_weights(
  min_range = c(-70, 240),
  min_mean = 30,
  min_sd = 60,
  day_range = c(120, 201),
  day_mean = 161,
  day_sd = 20,
  offset = 0,
  return_log = TRUE,
  selection_fun = "norm",
  selection_var = "psel_normalized",
  return_params = TRUE,
  plot = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim_selection_weights_+3A_min_range">min_range</code></td>
<td>
<p>Numeric vector. Range of the sampling distribution of
minutes around the sun event.</p>
</td></tr>
<tr><td><code id="sim_selection_weights_+3A_min_mean">min_mean</code></td>
<td>
<p>Numeric. Mean of the sampling distribution of minutes to the
sun event.</p>
</td></tr>
<tr><td><code id="sim_selection_weights_+3A_min_sd">min_sd</code></td>
<td>
<p>Numeric. SD in minutes of the sampling distribution of minutes
around the sun event.</p>
</td></tr>
<tr><td><code id="sim_selection_weights_+3A_day_range">day_range</code></td>
<td>
<p>Date/Datetime/Numeric vector. Range of sampling distribution
of days. Can be Dates, Date-times, or DOY (day-of-year, 1-366).</p>
</td></tr>
<tr><td><code id="sim_selection_weights_+3A_day_mean">day_mean</code></td>
<td>
<p>Date/Datetime/Numeric. Mean date of the sampling distribution
of days. Can be Date, Date-time, or DOY (day-of-year, 1-366).</p>
</td></tr>
<tr><td><code id="sim_selection_weights_+3A_day_sd">day_sd</code></td>
<td>
<p>Numeric. SD in days of the sampling distribution of days.</p>
</td></tr>
<tr><td><code id="sim_selection_weights_+3A_offset">offset</code></td>
<td>
<p>Numeric. Offset to shift for time of day in minutes.</p>
</td></tr>
<tr><td><code id="sim_selection_weights_+3A_return_log">return_log</code></td>
<td>
<p>Logical. Log the density in the selection function?</p>
</td></tr>
<tr><td><code id="sim_selection_weights_+3A_selection_fun">selection_fun</code></td>
<td>
<p>Character. Selection function to use. Options are
<code>lognorm</code>, <code>norm</code> (default), or <code>cauchy</code>.</p>
</td></tr>
<tr><td><code id="sim_selection_weights_+3A_selection_var">selection_var</code></td>
<td>
<p>Character. Selection variable to plot
(if <code>plot = TRUE</code>). Options are are <code>psel</code>, <code>psel_doy</code>, <code>psel_min</code>,
<code>psel_std</code>, <code>psel_scaled</code>, or <code>psel_normalized</code> (default).</p>
</td></tr>
<tr><td><code id="sim_selection_weights_+3A_return_params">return_params</code></td>
<td>
<p>Logical. Return parameter list for use in
calc_selection_weights()?</p>
</td></tr>
<tr><td><code id="sim_selection_weights_+3A_plot">plot</code></td>
<td>
<p>Logical. Create plot of simulated selection weights? If
<code>return_param = TRUE</code> and <code>plot = TRUE</code> plot is created as a side effect.
Other wise, plot is returned directly.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns either a list of selection parameters or a plot of simulated
selection weights
</p>


<h3>Examples</h3>

<pre><code class='language-R'>params &lt;- sim_selection_weights()
</code></pre>

<hr>
<h2 id='sox_spectro'>Create spectrogram image from wave file</h2><span id='topic+sox_spectro'></span>

<h3>Description</h3>

<p>Using the external program <code>SoX</code> (the Swiss Army knife of sound processing
programs), create a spectrogram image file. Note that you must have <code>SoX</code>
installed to use this function. Spectrograms will be silently overwritten.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sox_spectro(
  path,
  dir_out = "Spectrograms",
  prepend = "spectro_",
  width = NULL,
  height = NULL,
  start = NULL,
  end = NULL,
  rate = "20k",
  dry_run = FALSE,
  quiet = FALSE,
  sox_file_path = NULL,
  skip_check = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sox_spectro_+3A_path">path</code></td>
<td>
<p>Character. Path to wave file.</p>
</td></tr>
<tr><td><code id="sox_spectro_+3A_dir_out">dir_out</code></td>
<td>
<p>Character. Output directory.</p>
</td></tr>
<tr><td><code id="sox_spectro_+3A_prepend">prepend</code></td>
<td>
<p>Character. Text to add to the start of the output file.
Defaults to &quot;spectro_&quot;.</p>
</td></tr>
<tr><td><code id="sox_spectro_+3A_width">width</code></td>
<td>
<p>Numeric. Width of the spectrogram image in pixels.</p>
</td></tr>
<tr><td><code id="sox_spectro_+3A_height">height</code></td>
<td>
<p>Numeric. Height of the spectrogram image in pixels.</p>
</td></tr>
<tr><td><code id="sox_spectro_+3A_start">start</code></td>
<td>
<p>Numeric/Character. Start the spectrogram at this time (seconds
or HH:MM:SS format).</p>
</td></tr>
<tr><td><code id="sox_spectro_+3A_end">end</code></td>
<td>
<p>Numeric/Character. End time the spectrogram at this time (seconds
or HH:MM:SS format).</p>
</td></tr>
<tr><td><code id="sox_spectro_+3A_rate">rate</code></td>
<td>
<p>Numeric. Audio sampling rate to display (used by the <code>rate</code>
effect in <code>sox</code>). This effectively limits the upper frequency of the
spectrogram to rate/2. The default (<code>"20k"</code>), limits the spectrogram to
10kHz. Use <code>rate = NULL</code> for no limiting.</p>
</td></tr>
<tr><td><code id="sox_spectro_+3A_dry_run">dry_run</code></td>
<td>
<p>Logical. If <code>TRUE</code> show the sox command, but do not run (for
debugging and understanding precise details).</p>
</td></tr>
<tr><td><code id="sox_spectro_+3A_quiet">quiet</code></td>
<td>
<p>Logical. Whether to suppress progress messages and other
non-essential updates.</p>
</td></tr>
<tr><td><code id="sox_spectro_+3A_sox_file_path">sox_file_path</code></td>
<td>
<p>Path to sox file if not installed at the system level,
otherwise NULL.</p>
</td></tr>
<tr><td><code id="sox_spectro_+3A_skip_check">skip_check</code></td>
<td>
<p>Logical. Should the function skip check to ensure SoX is installed.
This may allow speed ups if running across large numbers of files.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Most arguments are passed through to the <code>seewave::sox()</code> command.
</p>

<ul>
<li><p> width and height correspond to the <code>-x</code> and <code>-y</code> options for the
<code>spectrogram</code> effect.
</p>
</li>
<li> <p><code>start</code> and <code>end</code> are used by the <code>trim</code> effect
</p>
</li>
<li> <p><code>rate</code> is passed on to the <code>rate</code> effect
</p>
</li></ul>

<p>Based on code from Sam Hache.
</p>


<h3>Value</h3>

<p>Does not return anything, but creates a spectrogram image in
<code>dir_out</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Prep sample file
w &lt;- tuneR::sine(440, duration = 300000)
td &lt;- tempdir()
temp_wave &lt;- glue::glue("{td}/test_wave.wav")
tuneR::writeWave(w, temp_wave)

# Create spectrograms

try({sox_spectro(temp_wave)
sox_spectro(temp_wave, rate = NULL)
sox_spectro(temp_wave, start = 2, end = 3)
sox_spectro(temp_wave, start = "0:01", end = "0:04")
sox_spectro(temp_wave, prepend = "")
})

# Clean up
unlink(temp_wave)
unlink("Spectrograms", recursive = TRUE)
</code></pre>

<hr>
<h2 id='task_template'>Example template of tasks for WildTrax</h2><span id='topic+task_template'></span>

<h3>Description</h3>

<p>A data frame with tasks generated from <code>example_clean</code> using
the wildRtrax::wt_make_aru_tasks() function. Allows updating of
tasks on WildTrax <a href="https://wildtrax.ca/">https://wildtrax.ca/</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>task_template
</code></pre>


<h3>Format</h3>



<h4><code>task_template</code></h4>

<p>A data frame with 14 rows and 13 columns:
</p>

<dl>
<dt>location</dt><dd><p>Site location name</p>
</dd>
<dt>recording_date_time</dt><dd><p>Date time of the recording</p>
</dd>
<dt>method</dt><dd><p>Method of interpretation (generally '1SPT')</p>
</dd>
<dt>taskLength</dt><dd><p>Length of recording in seconds</p>
</dd>
<dt>transcriber</dt><dd><p>Transcriber ID, to be filled in with function</p>
</dd>
<dt>rain</dt><dd><p>Empty character for filling in WildTrax</p>
</dd>
<dt>wind</dt><dd><p>Empty character for filling in WildTrax</p>
</dd>
<dt>industryNoise</dt><dd><p>Empty character for filling in WildTrax</p>
</dd>
<dt>audioQuality</dt><dd><p>Empty character for filling in WildTrax</p>
</dd>
<dt>taskComments</dt><dd><p>Empty character for filling in WildTrax</p>
</dd>
<dt>internal_task_id</dt><dd><p>Empty character for filling in WildTrax</p>
</dd>
</dl>




<h3>Source</h3>

<p>data-raw/data_wt_assign_tasks.R
</p>

<hr>
<h2 id='temp_wavs'>Helper function to create test wave files</h2><span id='topic+temp_wavs'></span>

<h3>Description</h3>

<p>Creates a directory structure and example wave files in temp folders.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>temp_wavs(n = 6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="temp_wavs_+3A_n">n</code></td>
<td>
<p>Numeric. How many test files to create (up to six). D</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of paths to temporary wave files
</p>


<h3>Examples</h3>

<pre><code class='language-R'>temp_wavs(n=3)

</code></pre>

<hr>
<h2 id='template_observers'>Example template of tasks for WildTrax</h2><span id='topic+template_observers'></span>

<h3>Description</h3>

<p>A data frame showing example observers and their effort
</p>


<h3>Usage</h3>

<pre><code class='language-R'>template_observers
</code></pre>


<h3>Format</h3>



<h4><code>template_observers</code></h4>

<p>A data frame with 4 rows and 2 columns:
</p>

<dl>
<dt>transcriber</dt><dd><p>Interpreter name in Wildtrax system</p>
</dd>
<dt>hrs</dt><dd><p>Number of hours to assign to interpreter</p>
</dd>
</dl>




<h3>Source</h3>

<p>data-raw/data_wt_assign_tasks.R
</p>

<hr>
<h2 id='wind_detection_pre_processing'>Pre-processing of files for Wind Detection program</h2><span id='topic+wind_detection_pre_processing'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a>
</p>
<p>This function takes a vector of wave file names and returns a list
of three vectors that can be provided to the wind detection software or
written to files that the software can read. Details of the usable fork of the
wind detection software can be found at
<a href="https://github.com/dhope/WindNoiseDetection">https://github.com/dhope/WindNoiseDetection</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wind_detection_pre_processing(
  wav_files,
  site_pattern,
  output_directory,
  write_to_file = FALSE,
  chunk_size = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wind_detection_pre_processing_+3A_wav_files">wav_files</code></td>
<td>
<p>Vector of path to wav files</p>
</td></tr>
<tr><td><code id="wind_detection_pre_processing_+3A_site_pattern">site_pattern</code></td>
<td>
<p>Pattern to extract sites from file names</p>
</td></tr>
<tr><td><code id="wind_detection_pre_processing_+3A_output_directory">output_directory</code></td>
<td>
<p>Directory path to export files to</p>
</td></tr>
<tr><td><code id="wind_detection_pre_processing_+3A_write_to_file">write_to_file</code></td>
<td>
<p>Logical Should the function write files to output_directory</p>
</td></tr>
<tr><td><code id="wind_detection_pre_processing_+3A_chunk_size">chunk_size</code></td>
<td>
<p>Numeric If not NULL, sets number of files to include in each chunk</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List including filePath, filenames, and sites suitable for wind software.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> wind_files &lt;-
 wind_detection_pre_processing(
 wav_files = example_clean$path,
   output_directory = td,
     site_pattern = create_pattern_site_id(
         p_digits = c(2, 3), sep = "_",
             s_digits = c(1, 2)
               ),
                 write_to_file = FALSE, chunk_size = NULL
                 )


</code></pre>

<hr>
<h2 id='wind_detection_summarize_json'>Summarize wind detection results</h2><span id='topic+wind_detection_summarize_json'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a>
</p>
<p>This function takes output from the command line program and summarizes it.
Details of the wind detection software can be found at
<a href="https://github.com/dhope/WindNoiseDetection">https://github.com/dhope/WindNoiseDetection</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wind_detection_summarize_json(f)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wind_detection_summarize_json_+3A_f">f</code></td>
<td>
<p>filepath for json
</p>
<p>#'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tibble of summarized data from json file
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example code

 example_json &lt;- system.file("extdata",
 "P71-1__20210606T232500-0400_SS.json",
 package = "ARUtools"
 )

 wind_summary &lt;- wind_detection_summarize_json(example_json)

</code></pre>

<hr>
<h2 id='wt_assign_tasks'>Assign tasks for interpretation on Wildtrax</h2><span id='topic+wt_assign_tasks'></span>

<h3>Description</h3>

<p>Assign tasks for interpretation on Wildtrax
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wt_assign_tasks(
  wt_task_template_in,
  interp_hours,
  wt_task_output_file,
  interp_hours_column,
  random_seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wt_assign_tasks_+3A_wt_task_template_in">wt_task_template_in</code></td>
<td>
<p>Path to csv template downloaded from Wildtrax
platform <a href="https://wildtrax.ca">https://wildtrax.ca</a> listing all tasks. Alternatively,
can be a data.frame that is correctly formatted using
<code>wildRtrax::wt_make_aru_tasks()</code>. See <code>vignette("Misc")</code> for details.</p>
</td></tr>
<tr><td><code id="wt_assign_tasks_+3A_interp_hours">interp_hours</code></td>
<td>
<p>Path to number of hours for each interpreter or a data.table. If a file, must be csv and must include
the columns &quot;transcriber&quot; and whatever the variable <code>interp_hours_column</code> is.</p>
</td></tr>
<tr><td><code id="wt_assign_tasks_+3A_wt_task_output_file">wt_task_output_file</code></td>
<td>
<p>Path to csv of output file for uploading to Wildtrax. If left as NULL will not write file</p>
</td></tr>
<tr><td><code id="wt_assign_tasks_+3A_interp_hours_column">interp_hours_column</code></td>
<td>
<p>LazyEval column name with hours for interpreters</p>
</td></tr>
<tr><td><code id="wt_assign_tasks_+3A_random_seed">random_seed</code></td>
<td>
<p>Integer. Random seed to select with. If left NULL will use timestamp</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with a tibble of assigned tasks and a summary tibble.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  task_output &lt;- wt_assign_tasks(
  wt_task_template_in = task_template,
  wt_task_output_file = NULL,
  interp_hours = template_observers,
  interp_hours_column = hrs,
  random_seed = 65122
  )

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
