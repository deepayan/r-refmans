<!DOCTYPE html><html lang="en-US"><head><title>Help for package goldilocks</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {goldilocks}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#goldilocks-package'><p>goldilocks: Goldilocks Adaptive Trial Designs for Time-to-Event Endpoints</p></a></li>
<li><a href='#enrollment'><p>Simulate enrollment times</p></a></li>
<li><a href='#goldilocks'><p>goldilocks</p></a></li>
<li><a href='#ppwe'><p>Cumulative distribution function of the PWE for a vectorized hazard</p>
rate parameter</a></li>
<li><a href='#prop_to_haz'><p>Estimate plausible piecewise constant hazard rates from summary</p>
summary event proportions</a></li>
<li><a href='#pwe_impute'><p>Impute piecewise exponential time-to-event outcomes</p></a></li>
<li><a href='#pwe_sim'><p>Simulate piecewise exponential time-to-event outcomes</p></a></li>
<li><a href='#randomization'><p>Randomization allocation</p></a></li>
<li><a href='#sim_comp_data'><p>Simulate a complete clinical trial with event data drawn from a</p>
piecewise exponential distribution</a></li>
<li><a href='#sim_trials'><p>Simulate one or more clinical trials subject to known design</p>
parameters and treatment effect</a></li>
<li><a href='#summarise_sims'><p>Summarize simulations to get operating characteristics</p></a></li>
<li><a href='#survival_adapt'><p>Simulate and execute a single adaptive clinical trial design with a</p>
time-to-event endpoint</a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Goldilocks Adaptive Trial Designs for Time-to-Event Endpoints</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements the Goldilocks adaptive trial design for a time to event
    outcome using a piecewise exponential model and conjugate Gamma prior
    distributions. The method closely follows the article by Broglio and
    colleagues &lt;<a href="https://doi.org/10.1080%2F10543406.2014.888569">doi:10.1080/10543406.2014.888569</a>&gt;, which allows users to explore
    the operating characteristics of different trial designs.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/graemeleehickey/goldilocks">https://github.com/graemeleehickey/goldilocks</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/graemeleehickey/goldilocks/issues">https://github.com/graemeleehickey/goldilocks/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0), survival</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, parallel, pbmcapply, PWEALL, Rcpp, rlang, stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>covr, testthat (&ge; 3.0.0), knitr, rmarkdown</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>BH, Rcpp</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-07 21:54:40 UTC; hickeg3</td>
</tr>
<tr>
<td>Author:</td>
<td>Graeme L. Hickey <a href="https://orcid.org/0000-0002-4989-0054"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Ying Wan [aut],
  Thevaa Chandereng <a href="https://orcid.org/0000-0003-4078-9176"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut] (bayesDP code as a template),
  Becton, Dickinson and Company [cph],
  Tim Kacprowski [ctb] (For code from fastlogrank R package.)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Graeme L. Hickey &lt;graemeleehickey@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-08 15:30:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='goldilocks-package'>goldilocks: Goldilocks Adaptive Trial Designs for Time-to-Event Endpoints</h2><span id='topic+goldilocks-package'></span>

<h3>Description</h3>

<p>Implements the Goldilocks adaptive trial design for a time to event outcome using a piecewise exponential model and conjugate Gamma prior distributions. The method closely follows the article by Broglio and colleagues <a href="https://doi.org/10.1080/10543406.2014.888569">doi:10.1080/10543406.2014.888569</a>, which allows users to explore the operating characteristics of different trial designs.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Graeme L. Hickey <a href="mailto:graemeleehickey@gmail.com">graemeleehickey@gmail.com</a> (<a href="https://orcid.org/0000-0002-4989-0054">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Ying Wan <a href="mailto:ying.wan@bd.com">ying.wan@bd.com</a>
</p>
</li>
<li><p> Thevaa Chandereng <a href="mailto:tc3123@cumc.columbia.edu">tc3123@cumc.columbia.edu</a> (<a href="https://orcid.org/0000-0003-4078-9176">ORCID</a>) (bayesDP code as a template)
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Becton, Dickinson and Company [copyright holder]
</p>
</li>
<li><p> Tim Kacprowski <a href="mailto:t.kacprowski@tu-braunschweig.de">t.kacprowski@tu-braunschweig.de</a> (For code from fastlogrank R package.) [contributor]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/graemeleehickey/goldilocks">https://github.com/graemeleehickey/goldilocks</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/graemeleehickey/goldilocks/issues">https://github.com/graemeleehickey/goldilocks/issues</a>
</p>
</li></ul>


<hr>
<h2 id='enrollment'>Simulate enrollment times</h2><span id='topic+enrollment'></span>

<h3>Description</h3>

<p>Simulate enrollment time using a piecewise Poisson distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>enrollment(lambda = 1, N_total, lambda_time = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="enrollment_+3A_lambda">lambda</code></td>
<td>
<p>vector. Rate parameter(s) for Poisson distribution.</p>
</td></tr>
<tr><td><code id="enrollment_+3A_n_total">N_total</code></td>
<td>
<p>integer. Value of total sample size.</p>
</td></tr>
<tr><td><code id="enrollment_+3A_lambda_time">lambda_time</code></td>
<td>
<p>vector. Knots (of <code>length(lambda)</code>) indicating
regions where a specific hazard rate (<code>lambda</code>) applies. The first
element is always <code>lambda_time = 0</code>, denoting the trial start time.
Note: final element of <code>lambda</code> is assumed to be constant as
<code>lambda_time</code> tends to infinity.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Subject recruitment is assumed to follow a (piecewise stationary)
Poisson process. We assume trial recruitment to be an independent process,
thus the 'memoryless' property modelling of subject recruitment is used.
Since the subject recruitment rate can vary over time, we can account for
differential rates over time. Note that the first trial enrollment is
assumed to occur at time zero.
</p>
<p>To illustrate, suppose we use a piecewise function to specify the change in
enrollment rate over time:
</p>
<p style="text-align: center;"><code class="reqn">
    \lambda = \left\{
      \begin{array}{ll}
        0.3 &amp; \textrm{time} \in [0, 5) \\
        0.7 &amp; \textrm{time} \in [5, 10) \\
        0.9 &amp; \textrm{time} \in [10, 15) \\
        1.2 &amp; \textrm{time} \in [15, \infty) \\
      \end{array}
    \right.
</code>
</p>

<p>Then, to simulate individual patient enrollment dates with a sample size
(<code>N_total</code>) of 50, we use
</p>
<p><code>enrollment(lambda = c(0.3, 0.7, 0.9, 1.2), N_total = 50,
        lambda_time = c(0, 5, 10, 15))</code>
</p>


<h3>Value</h3>

<p>A vector of enrollment times (from time of first patient enrollment)
in unit time (e.g. days).
</p>


<h3>See Also</h3>

<p>This function is based on the <code>enrollment</code> function from the
<a href="https://cran.r-project.org/package=bayesCT"><code>bayesCT</code></a>
R package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>enrollment(lambda = c(0.003, 0.7), N_total = 100, lambda_time = c(0, 10))
enrollment(lambda = c(0.3, 0.5, 0.9, 1.2, 2.1), N_total = 200,
           lambda_time = c(0, 20, 30, 40, 60))
</code></pre>

<hr>
<h2 id='goldilocks'>goldilocks</h2><span id='topic+goldilocks'></span>

<h3>Description</h3>

<p>The goal of <code>goldilocks</code> is to implement the Goldilocks Bayesian
adaptive design proposed by Broglio et al. (2014) for time-to-event
endpoint trials, both one- and two-arm, with an underlying piecewise
exponential hazard model. The method can be used for a confirmatory trial
to select a trial's sample size based on accumulating data. During accrual,
frequent sample size selection analyses are made and predictive
probabilities are used to determine whether the current sample size is
sufficient or whether continuing accrual would be futile. The algorithm
explicitly accounts for complete follow-up of all patients before the
primary analysis is conducted. Broglio et al. (2014) refer to this as a
Goldilocks trial design, as it is constantly asking the question, <strong>“Is the
sample size too big, too small, or just right?”</strong>
</p>


<h3>References</h3>

<p>Broglio KR, Connor JT, Berry SM. Not too big, not too small: a Goldilocks
approach to sample size selection. <em>Journal of Biopharmaceutical Statistics</em>,
2014; <strong>24(3)</strong>: 685–705.
</p>

<hr>
<h2 id='ppwe'>Cumulative distribution function of the PWE for a vectorized hazard
rate parameter</h2><span id='topic+ppwe'></span>

<h3>Description</h3>

<p>Extends the <code><a href="PWEALL.html#topic+pwe">pwe</a></code> function to allow for
vectorization over the hazard rates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ppwe(hazard, end_of_study, cutpoints)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ppwe_+3A_hazard">hazard</code></td>
<td>
<p>matrix. A matrix of hazard rate parameters with number of
columns equal to the length of the <code>cutpoints</code> vector. The number of
rows can be anything, and is typically dictated by the number of MCMC
draws.</p>
</td></tr>
<tr><td><code id="ppwe_+3A_end_of_study">end_of_study</code></td>
<td>
<p>scalar. Length of the study; i.e. time at which endpoint
will be evaluated.</p>
</td></tr>
<tr><td><code id="ppwe_+3A_cutpoints">cutpoints</code></td>
<td>
<p>vector. The change-point vector indicating time when the
hazard rates change. Note the first element of <code>cutpoints</code> should
always be 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of (0, 1) probabilities from evaluation of the PWE
cumulative distribution function. Length of the vector matches the number
of rows of the <code>hazard</code> matrix parameter.
</p>

<hr>
<h2 id='prop_to_haz'>Estimate plausible piecewise constant hazard rates from summary
summary event proportions</h2><span id='topic+prop_to_haz'></span>

<h3>Description</h3>

<p>Given estimates of the event probability at one or more fixed
times, the corresponding piecewise hazard rates can be determined through
closed-form formulae. This utility function can be useful when simulating
trial datasets with plausible event rates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prop_to_haz(probs, cutpoints = 0, endtime)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prop_to_haz_+3A_probs">probs</code></td>
<td>
<p>vector. Probabilities of the event (i.e. cumulative incidence
probabilities) at one or more time point. If only a single value is given,
then it is assumed that this is the probability at the <code>endtime</code>.</p>
</td></tr>
<tr><td><code id="prop_to_haz_+3A_cutpoints">cutpoints</code></td>
<td>
<p>vector. Times at which the baseline hazard changes. Default
is <code>cutpoints = 0</code>, which corresponds to a simple (non-piecewise)
exponential model.</p>
</td></tr>
<tr><td><code id="prop_to_haz_+3A_endtime">endtime</code></td>
<td>
<p>scalar. Time at which final element in <code>probs</code>
corresponds to. Typically this would be the study endpoint time.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given <code class="reqn">J-1</code> internal cut-points, then there are J intervals
defined as: <code class="reqn">[s_0, s_1)</code>, <code class="reqn">[s_1, s_2)</code>, <code class="reqn">\dots</code>, <code class="reqn">[s_{J-1},
  s_{J})</code>, with conditions that <code class="reqn">s_0 = 0</code> and <code class="reqn">s_J = \infty</code>. Each
interval corresponds to constant hazard <code class="reqn">\lambda_j</code>.
</p>


<h3>Value</h3>

<p>Vector of constant hazard rates for each time piece defined by
<code>cutpoints</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lambda &lt;- prop_to_haz(0.15, endtime = 36) # 15% probability at 36-months
all.equal(pexp(36, lambda), 0.15)

# 15% probability at 12-months, and 30% at 24-months
prop_to_haz(c(0.15, 0.30), c(0, 12), 24)
PWEALL::pwe(12, prop_to_haz(c(0.15, 0.30), c(0, 12), 24), c(0, 12))$dist
PWEALL::pwe(24, prop_to_haz(c(0.15, 0.30), c(0, 12), 24), c(0, 12))$dist
</code></pre>

<hr>
<h2 id='pwe_impute'>Impute piecewise exponential time-to-event outcomes</h2><span id='topic+pwe_impute'></span>

<h3>Description</h3>

<p>Imputation of time-to-event outcomes using the piecewise
constant hazard exponential function conditional on observed exposure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwe_impute(time, hazard, cutpoints = 0, maxtime = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pwe_impute_+3A_time">time</code></td>
<td>
<p>vector. The observed time for patient that have had no event or
passed <code>maxtime</code>.</p>
</td></tr>
<tr><td><code id="pwe_impute_+3A_hazard">hazard</code></td>
<td>
<p>vector. The constant hazard rates for exponential failures.</p>
</td></tr>
<tr><td><code id="pwe_impute_+3A_cutpoints">cutpoints</code></td>
<td>
<p>vector. The change-point vector indicating time when the
hazard rates change. Note the first element of <code>cutpoints</code> should
always be 0.</p>
</td></tr>
<tr><td><code id="pwe_impute_+3A_maxtime">maxtime</code></td>
<td>
<p>scalar. Maximum time before end of study.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If a subject is event-free at time <code class="reqn">s &lt; t</code>, then the conditional
probability <code class="reqn">F_{T \| s}|(t \| s) = P[T \le \| T &gt; s] = (F(t) - F(s)) /
  (1 - F(s))</code>, where <code class="reqn">F(\cdot)</code> is the cumulative distribution function
of the piecewise exponential (PWE) distribution. Equivalently, <code class="reqn">F(t) =
  1 - S(t)</code>, where <code>S(t)</code> is the survival function. If <code class="reqn">U \sim
  Unif(0, 1)</code>, then we can generate an event time (conditional on being event
free up until <code class="reqn">s</code>) as <code class="reqn">F^{-1}(U(1-F(s)) + F(s))</code>. Note: if <code class="reqn">s =
  0</code>, then this is the equivalent of a direct (unconditional) sample from the
PWE distribution.
</p>


<h3>Value</h3>

<p>A data frame with simulated follow-up times (<code>time</code>) and
respective event indicator (<code>event</code>, 1 = event occurred, 0 =
censoring).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pwe_impute(time = c(3, 4, 5), hazard = c(0.002, 0.01), cutpoints = c(0, 12))
pwe_impute(time = c(3, 4, 5), hazard = c(0.002, 0.01), cutpoints = c(0, 12),
           maxtime = 36)
pwe_impute(time = 19.621870008, hazard = c(2.585924e-02, 3.685254e-09),
           cutpoints = c(0, 12), maxtime = 36)
</code></pre>

<hr>
<h2 id='pwe_sim'>Simulate piecewise exponential time-to-event outcomes</h2><span id='topic+pwe_sim'></span>

<h3>Description</h3>

<p>Simulate time-to-event outcomes using the piecewise constant
hazard exponential function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwe_sim(n = 1, hazard = 1, cutpoints = 0, maxtime = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pwe_sim_+3A_n">n</code></td>
<td>
<p>integer. The number of random samples to generate. Default is
<code>n=1</code>.</p>
</td></tr>
<tr><td><code id="pwe_sim_+3A_hazard">hazard</code></td>
<td>
<p>vector. The constant hazard rates for exponential failures.</p>
</td></tr>
<tr><td><code id="pwe_sim_+3A_cutpoints">cutpoints</code></td>
<td>
<p>vector. The change-point vector indicating time when the
hazard rates change. Note the first element of <code>cutpoints</code> should
always be 0.</p>
</td></tr>
<tr><td><code id="pwe_sim_+3A_maxtime">maxtime</code></td>
<td>
<p>scalar. Maximum time before end of study.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+pwe_impute">pwe_impute</a></code> for details.
</p>


<h3>Value</h3>

<p>A data frame with simulated follow-up times (<code>time</code>) and
respective event indicator (<code>event</code>, 1 = event occurred, 0 =
censoring).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pwe_sim(10, hazard = c(0.005, 0.001), cutpoints = c(0, 3), maxtime = 36)
y &lt;- pwe_sim(n = 1, hazard = c(2.585924e-02, 3.685254e-09),
             cutpoints = c(0, 12))
</code></pre>

<hr>
<h2 id='randomization'>Randomization allocation</h2><span id='topic+randomization'></span>

<h3>Description</h3>

<p>Implements a randomization allocation for control and treatment
arms with different randomization ratios and block sizes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>randomization(N_total, block = 2, allocation = c(1, 1))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="randomization_+3A_n_total">N_total</code></td>
<td>
<p>integer. Total sample size for randomization allocation.</p>
</td></tr>
<tr><td><code id="randomization_+3A_block">block</code></td>
<td>
<p>vector. Block size for randomization. Note that it needs to be a
multiple of the sum of <code>allocation</code>.</p>
</td></tr>
<tr><td><code id="randomization_+3A_allocation">allocation</code></td>
<td>
<p>vector. The randomization allocation in the order
<code>c(control, treatment)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Complete randomization may not always be ideal due to the chance of
drawing a large block of a single treatment arm, potentially impacting the
time to enrollment completion. Therefore, a block randomization allocation
may be preferable. The block randomization allocation specification allows
for different randomization ratios, but they must be given in integer form.
Additionally, the block size should be an integer that is divisible by the
sum of the randomization allocation; see the examples.
</p>


<h3>Value</h3>

<p>The randomization allocation with 0, 1 for control and treatment,
respectively.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Implementing treatment allocation for control to treatment with 1:1.5
# randomization ratio
randomization(N_total = 100, block = 5, allocation = c(2, 3))

# Treatment allocation with 2:1 for control to treatment
randomization(N_total = 70, block = 9, allocation = c(2, 1))

# Treatment allocation for control to treatment with 1:2 for control
# to treatment with multiple block sizes c(3, 9, 6)
randomization(N_total = 100, block = c(3, 9, 6), allocation = c(1, 2))

# For complete randomization set the N_total to block size
randomization(N_total = 100, block = 100, allocation = c(1, 1))
</code></pre>

<hr>
<h2 id='sim_comp_data'>Simulate a complete clinical trial with event data drawn from a
piecewise exponential distribution</h2><span id='topic+sim_comp_data'></span>

<h3>Description</h3>

<p>Simulate a complete clinical trial with event data drawn from a
piecewise exponential distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_comp_data(
  hazard_treatment,
  hazard_control = NULL,
  cutpoints = 0,
  N_total,
  lambda = 0.3,
  lambda_time = 0,
  end_of_study,
  block = 2,
  rand_ratio = c(1, 1),
  prop_loss = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sim_comp_data_+3A_hazard_treatment">hazard_treatment</code></td>
<td>
<p>vector. Constant hazard rates under the treatment
arm.</p>
</td></tr>
<tr><td><code id="sim_comp_data_+3A_hazard_control">hazard_control</code></td>
<td>
<p>vector. Constant hazard rates under the control arm.</p>
</td></tr>
<tr><td><code id="sim_comp_data_+3A_cutpoints">cutpoints</code></td>
<td>
<p>vector. Times at which the baseline hazard changes. Default
is <code>cutpoints = 0</code>, which corresponds to a simple (non-piecewise)
exponential model.</p>
</td></tr>
<tr><td><code id="sim_comp_data_+3A_n_total">N_total</code></td>
<td>
<p>integer. Maximum sample size allowable</p>
</td></tr>
<tr><td><code id="sim_comp_data_+3A_lambda">lambda</code></td>
<td>
<p>vector. Enrollment rates across simulated enrollment times. See
<code><a href="#topic+enrollment">enrollment</a></code> for more details.</p>
</td></tr>
<tr><td><code id="sim_comp_data_+3A_lambda_time">lambda_time</code></td>
<td>
<p>vector. Enrollment time(s) at which the enrollment rates
change. Must be same length as lambda. See <code><a href="#topic+enrollment">enrollment</a></code> for
more details.</p>
</td></tr>
<tr><td><code id="sim_comp_data_+3A_end_of_study">end_of_study</code></td>
<td>
<p>scalar. Length of the study; i.e. time at which endpoint
will be evaluated.</p>
</td></tr>
<tr><td><code id="sim_comp_data_+3A_block">block</code></td>
<td>
<p>scalar. Block size for generating the randomization schedule.</p>
</td></tr>
<tr><td><code id="sim_comp_data_+3A_rand_ratio">rand_ratio</code></td>
<td>
<p>vector. Randomization allocation for the ratio of control
to treatment. Integer values mapping the size of the block. See
<code><a href="#topic+randomization">randomization</a></code> for more details.</p>
</td></tr>
<tr><td><code id="sim_comp_data_+3A_prop_loss">prop_loss</code></td>
<td>
<p>scalar. Overall proportion of subjects lost to follow-up.
Defaults to zero.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with 1 row per subject and columns:
</p>

<dl>
<dt><code>time:</code></dt><dd>
<p>numeric. Time of event or censoring time.
</p>
</dd>
<dt><code>treatment:</code></dt><dd>
<p>integer. Treatment arm with values <code>1L</code> for experimental arm, and
<code>0L</code> for control arm (only if <code>hazard_control</code> is given).
</p>
</dd>
<dt><code>event:</code></dt><dd>
<p>integer. Indicator of whether event occurred (<code>=1L</code> if occurred
and <code>=0L</code> if right-censored).
</p>
</dd>
<dt><code>enrollment:</code></dt><dd>
<p>numeric. Time of patient enrollment relative to time trial enrolled
first patient.
</p>
</dd>
<dt><code>id:</code></dt><dd>
<p>integer. Identification number for each patient.
</p>
</dd>
<dt><code>loss_to_fu:</code></dt><dd>
<p>logical. Indicator of whether the patient was lost to follow-up during
the course of observation.
</p>
</dd>
</dl>


<hr>
<h2 id='sim_trials'>Simulate one or more clinical trials subject to known design
parameters and treatment effect</h2><span id='topic+sim_trials'></span>

<h3>Description</h3>

<p>Simulate multiple clinical trials with fixed input parameters,
and tidily extract the relevant data to generate operating characteristics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_trials(
  hazard_treatment,
  hazard_control = NULL,
  cutpoints = 0,
  N_total,
  lambda = 0.3,
  lambda_time = 0,
  interim_look = NULL,
  end_of_study,
  prior = c(0.1, 0.1),
  block = 2,
  rand_ratio = c(1, 1),
  prop_loss = 0,
  alternative = "two.sided",
  h0 = 0,
  Fn = 0.1,
  Sn = 0.9,
  prob_ha = 0.95,
  N_impute = 10,
  N_mcmc = 10,
  N_trials = 10,
  method = "logrank",
  imputed_final = FALSE,
  ncores = 1L
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sim_trials_+3A_hazard_treatment">hazard_treatment</code></td>
<td>
<p>vector. Constant hazard rates under the treatment
arm.</p>
</td></tr>
<tr><td><code id="sim_trials_+3A_hazard_control">hazard_control</code></td>
<td>
<p>vector. Constant hazard rates under the control arm.</p>
</td></tr>
<tr><td><code id="sim_trials_+3A_cutpoints">cutpoints</code></td>
<td>
<p>vector. Times at which the baseline hazard changes. Default
is <code>cutpoints = 0</code>, which corresponds to a simple (non-piecewise)
exponential model.</p>
</td></tr>
<tr><td><code id="sim_trials_+3A_n_total">N_total</code></td>
<td>
<p>integer. Maximum sample size allowable</p>
</td></tr>
<tr><td><code id="sim_trials_+3A_lambda">lambda</code></td>
<td>
<p>vector. Enrollment rates across simulated enrollment times. See
<code><a href="#topic+enrollment">enrollment</a></code> for more details.</p>
</td></tr>
<tr><td><code id="sim_trials_+3A_lambda_time">lambda_time</code></td>
<td>
<p>vector. Enrollment time(s) at which the enrollment rates
change. Must be same length as lambda. See <code><a href="#topic+enrollment">enrollment</a></code> for
more details.</p>
</td></tr>
<tr><td><code id="sim_trials_+3A_interim_look">interim_look</code></td>
<td>
<p>vector. Sample size for each interim look. Note: the
maximum sample size should not be included.</p>
</td></tr>
<tr><td><code id="sim_trials_+3A_end_of_study">end_of_study</code></td>
<td>
<p>scalar. Length of the study; i.e. time at which endpoint
will be evaluated.</p>
</td></tr>
<tr><td><code id="sim_trials_+3A_prior">prior</code></td>
<td>
<p>vector. The prior distributions for the piecewise hazard rate
parameters are each <code class="reqn">Gamma(a_0, b_0)</code>, with specified (known)
hyper-parameters <code class="reqn">a_0</code> and <code class="reqn">b_0</code>. The default non-informative prior
distribution used is Gamma(0.1, 0.1), which is specified by setting
<code>prior = c(0.1, 0.1)</code>.</p>
</td></tr>
<tr><td><code id="sim_trials_+3A_block">block</code></td>
<td>
<p>scalar. Block size for generating the randomization schedule.</p>
</td></tr>
<tr><td><code id="sim_trials_+3A_rand_ratio">rand_ratio</code></td>
<td>
<p>vector. Randomization allocation for the ratio of control
to treatment. Integer values mapping the size of the block. See
<code><a href="#topic+randomization">randomization</a></code> for more details.</p>
</td></tr>
<tr><td><code id="sim_trials_+3A_prop_loss">prop_loss</code></td>
<td>
<p>scalar. Overall proportion of subjects lost to follow-up.
Defaults to zero.</p>
</td></tr>
<tr><td><code id="sim_trials_+3A_alternative">alternative</code></td>
<td>
<p>character. The string specifying the alternative
hypothesis, must be one of <code>"greater"</code> (default), <code>"less"</code> or
<code>"two.sided"</code>.</p>
</td></tr>
<tr><td><code id="sim_trials_+3A_h0">h0</code></td>
<td>
<p>scalar. Null hypothesis value of <code class="reqn">p_\textrm{treatment} -
  p_\textrm{control}</code> when <code>method = "bayes"</code>. Default is <code>h0 = 0</code>.
The argument is ignored when <code>method = "logrank"</code> or <code>= "cox"</code>;
in those cases the usual test of non-equal hazards is assumed.</p>
</td></tr>
<tr><td><code id="sim_trials_+3A_fn">Fn</code></td>
<td>
<p>vector of <code>[0, 1]</code> values. Each element is the probability
threshold to stop at the <code class="reqn">i</code>-th look early for futility. If there are
no interim looks (i.e. <code>interim_look = NULL</code>), then <code>Fn</code> is not
used in the simulations or analysis. The length of <code>Fn</code> should be the
same as <code>interim_look</code>, else the values are recycled.</p>
</td></tr>
<tr><td><code id="sim_trials_+3A_sn">Sn</code></td>
<td>
<p>vector of <code>[0, 1]</code> values. Each element is the probability
threshold to stop at the <code class="reqn">i</code>-th look early for expected success. If
there are no interim looks (i.e. <code>interim_look = NULL</code>), then
<code>Sn</code> is not used in the simulations or analysis. The length of
<code>Sn</code> should be the same as <code>interim_look</code>, else the values are
recycled.</p>
</td></tr>
<tr><td><code id="sim_trials_+3A_prob_ha">prob_ha</code></td>
<td>
<p>scalar <code>[0, 1]</code>. Probability threshold of alternative
hypothesis.</p>
</td></tr>
<tr><td><code id="sim_trials_+3A_n_impute">N_impute</code></td>
<td>
<p>integer. Number of imputations for Monte Carlo simulation of
missing data.</p>
</td></tr>
<tr><td><code id="sim_trials_+3A_n_mcmc">N_mcmc</code></td>
<td>
<p>integer. Number of samples to draw from the posterior
distribution when using a Bayesian test (<code>method = "bayes"</code>).</p>
</td></tr>
<tr><td><code id="sim_trials_+3A_n_trials">N_trials</code></td>
<td>
<p>integer. Number of trials to simulate.</p>
</td></tr>
<tr><td><code id="sim_trials_+3A_method">method</code></td>
<td>
<p>character. For an imputed data set (or the final data set after
follow-up is complete), whether the analysis should be a log-rank
(<code>method = "logrank"</code>) test, Cox proportional hazards regression model
Wald test (<code>method = "cox"</code>), a fully-Bayesian analysis (<code>method
  = "bayes"</code>), or a chi-square test (<code>method = "chisq"</code>). See Details
section.</p>
</td></tr>
<tr><td><code id="sim_trials_+3A_imputed_final">imputed_final</code></td>
<td>
<p>logical. Should the final analysis (after all subjects
have been followed-up to the study end) be based on imputed outcomes for
subjects who were LTFU (i.e. right-censored with time
<code>&lt;end_of_study</code>)? Default is <code>TRUE</code>. Setting to <code>FALSE</code>
means that the final analysis would incorporate right-censoring.</p>
</td></tr>
<tr><td><code id="sim_trials_+3A_ncores">ncores</code></td>
<td>
<p>integer. Number of cores to use for parallel processing.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is basically a wrapper function for
<code><a href="#topic+survival_adapt">survival_adapt</a></code>, whereby we repeatedly run the function for a
independent number of trials (all with the same input design parameters and
treatment effect).
</p>
<p>To use will multiple cores (where available), the argument <code>ncores</code>
can be increased from the default of 1. Note: on Windows machines, it is
not possible to use the <code><a href="parallel.html#topic+mclapply">mclapply</a></code> function with
<code>ncores</code> <code class="reqn">&gt;1</code>.
</p>


<h3>Value</h3>

<p>Data frame with 1 row per simulated trial and columns for key summary
statistics. See <code><a href="#topic+survival_adapt">survival_adapt</a></code> for details of what is
returned in each row.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>hc &lt;- prop_to_haz(c(0.20, 0.30), c(0, 12), 36)
ht &lt;- prop_to_haz(c(0.05, 0.15), c(0, 12), 36)

out &lt;- sim_trials(
  hazard_treatment = ht,
  hazard_control = hc,
  cutpoints = c(0, 12),
  N_total = 600,
  lambda = 20,
  lambda_time = 0,
  interim_look = c(400, 500),
  end_of_study = 36,
  prior = c(0.1, 0.1),
  block = 2,
  rand_ratio = c(1, 1),
  prop_loss = 0.30,
  alternative = "two.sided",
  h0 = 0,
  Fn = 0.05,
  Sn = 0.9,
  prob_ha = 0.975,
  N_impute = 5,
  N_mcmc = 5,
  method = "logrank",
  N_trials = 2,
  ncores = 1)
</code></pre>

<hr>
<h2 id='summarise_sims'>Summarize simulations to get operating characteristics</h2><span id='topic+summarise_sims'></span>

<h3>Description</h3>

<p>Summarize simulations to get operating characteristics
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarise_sims(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summarise_sims_+3A_data">data</code></td>
<td>
<p>list (of data frames) or a single data frame. If summarizing a
single run of simulations, <code>data</code> will be a <code>data.frame</code> object
returned from <code><a href="#topic+survival_adapt">survival_adapt</a></code>. If summarizing multiple
simulation scenarios, <code>data</code> will be a <code>list</code> object, with each
element being a <code>data.frame</code> object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame reporting the operating characteristics, including the
power (which will be equal to the type I error in the null case); the
proportion of trials that stopped for early expected success, futility, or
went to the maximum sample size. The average stopping sample size (and
standard deviation) are also recorded. The proportion of trials that
stopped early for expected success, yet went to ultimately fail are also
reported.
</p>

<hr>
<h2 id='survival_adapt'>Simulate and execute a single adaptive clinical trial design with a
time-to-event endpoint</h2><span id='topic+survival_adapt'></span>

<h3>Description</h3>

<p>Simulate and execute a single adaptive clinical trial design with a
time-to-event endpoint
</p>


<h3>Usage</h3>

<pre><code class='language-R'>survival_adapt(
  hazard_treatment,
  hazard_control = NULL,
  cutpoints = 0,
  N_total,
  lambda = 0.3,
  lambda_time = 0,
  interim_look = NULL,
  end_of_study,
  prior = c(0.1, 0.1),
  block = 2,
  rand_ratio = c(1, 1),
  prop_loss = 0,
  alternative = "greater",
  h0 = 0,
  Fn = 0.05,
  Sn = 0.9,
  prob_ha = 0.95,
  N_impute = 10,
  N_mcmc = 10,
  method = "logrank",
  imputed_final = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="survival_adapt_+3A_hazard_treatment">hazard_treatment</code></td>
<td>
<p>vector. Constant hazard rates under the treatment
arm.</p>
</td></tr>
<tr><td><code id="survival_adapt_+3A_hazard_control">hazard_control</code></td>
<td>
<p>vector. Constant hazard rates under the control arm.</p>
</td></tr>
<tr><td><code id="survival_adapt_+3A_cutpoints">cutpoints</code></td>
<td>
<p>vector. Times at which the baseline hazard changes. Default
is <code>cutpoints = 0</code>, which corresponds to a simple (non-piecewise)
exponential model.</p>
</td></tr>
<tr><td><code id="survival_adapt_+3A_n_total">N_total</code></td>
<td>
<p>integer. Maximum sample size allowable</p>
</td></tr>
<tr><td><code id="survival_adapt_+3A_lambda">lambda</code></td>
<td>
<p>vector. Enrollment rates across simulated enrollment times. See
<code><a href="#topic+enrollment">enrollment</a></code> for more details.</p>
</td></tr>
<tr><td><code id="survival_adapt_+3A_lambda_time">lambda_time</code></td>
<td>
<p>vector. Enrollment time(s) at which the enrollment rates
change. Must be same length as lambda. See <code><a href="#topic+enrollment">enrollment</a></code> for
more details.</p>
</td></tr>
<tr><td><code id="survival_adapt_+3A_interim_look">interim_look</code></td>
<td>
<p>vector. Sample size for each interim look. Note: the
maximum sample size should not be included.</p>
</td></tr>
<tr><td><code id="survival_adapt_+3A_end_of_study">end_of_study</code></td>
<td>
<p>scalar. Length of the study; i.e. time at which endpoint
will be evaluated.</p>
</td></tr>
<tr><td><code id="survival_adapt_+3A_prior">prior</code></td>
<td>
<p>vector. The prior distributions for the piecewise hazard rate
parameters are each <code class="reqn">Gamma(a_0, b_0)</code>, with specified (known)
hyper-parameters <code class="reqn">a_0</code> and <code class="reqn">b_0</code>. The default non-informative prior
distribution used is Gamma(0.1, 0.1), which is specified by setting
<code>prior = c(0.1, 0.1)</code>.</p>
</td></tr>
<tr><td><code id="survival_adapt_+3A_block">block</code></td>
<td>
<p>scalar. Block size for generating the randomization schedule.</p>
</td></tr>
<tr><td><code id="survival_adapt_+3A_rand_ratio">rand_ratio</code></td>
<td>
<p>vector. Randomization allocation for the ratio of control
to treatment. Integer values mapping the size of the block. See
<code><a href="#topic+randomization">randomization</a></code> for more details.</p>
</td></tr>
<tr><td><code id="survival_adapt_+3A_prop_loss">prop_loss</code></td>
<td>
<p>scalar. Overall proportion of subjects lost to follow-up.
Defaults to zero.</p>
</td></tr>
<tr><td><code id="survival_adapt_+3A_alternative">alternative</code></td>
<td>
<p>character. The string specifying the alternative
hypothesis, must be one of <code>"greater"</code> (default), <code>"less"</code> or
<code>"two.sided"</code>.</p>
</td></tr>
<tr><td><code id="survival_adapt_+3A_h0">h0</code></td>
<td>
<p>scalar. Null hypothesis value of <code class="reqn">p_\textrm{treatment} -
  p_\textrm{control}</code> when <code>method = "bayes"</code>. Default is <code>h0 = 0</code>.
The argument is ignored when <code>method = "logrank"</code> or <code>= "cox"</code>;
in those cases the usual test of non-equal hazards is assumed.</p>
</td></tr>
<tr><td><code id="survival_adapt_+3A_fn">Fn</code></td>
<td>
<p>vector of <code>[0, 1]</code> values. Each element is the probability
threshold to stop at the <code class="reqn">i</code>-th look early for futility. If there are
no interim looks (i.e. <code>interim_look = NULL</code>), then <code>Fn</code> is not
used in the simulations or analysis. The length of <code>Fn</code> should be the
same as <code>interim_look</code>, else the values are recycled.</p>
</td></tr>
<tr><td><code id="survival_adapt_+3A_sn">Sn</code></td>
<td>
<p>vector of <code>[0, 1]</code> values. Each element is the probability
threshold to stop at the <code class="reqn">i</code>-th look early for expected success. If
there are no interim looks (i.e. <code>interim_look = NULL</code>), then
<code>Sn</code> is not used in the simulations or analysis. The length of
<code>Sn</code> should be the same as <code>interim_look</code>, else the values are
recycled.</p>
</td></tr>
<tr><td><code id="survival_adapt_+3A_prob_ha">prob_ha</code></td>
<td>
<p>scalar <code>[0, 1]</code>. Probability threshold of alternative
hypothesis.</p>
</td></tr>
<tr><td><code id="survival_adapt_+3A_n_impute">N_impute</code></td>
<td>
<p>integer. Number of imputations for Monte Carlo simulation of
missing data.</p>
</td></tr>
<tr><td><code id="survival_adapt_+3A_n_mcmc">N_mcmc</code></td>
<td>
<p>integer. Number of samples to draw from the posterior
distribution when using a Bayesian test (<code>method = "bayes"</code>).</p>
</td></tr>
<tr><td><code id="survival_adapt_+3A_method">method</code></td>
<td>
<p>character. For an imputed data set (or the final data set after
follow-up is complete), whether the analysis should be a log-rank
(<code>method = "logrank"</code>) test, Cox proportional hazards regression model
Wald test (<code>method = "cox"</code>), a fully-Bayesian analysis (<code>method
  = "bayes"</code>), or a chi-square test (<code>method = "chisq"</code>). See Details
section.</p>
</td></tr>
<tr><td><code id="survival_adapt_+3A_imputed_final">imputed_final</code></td>
<td>
<p>logical. Should the final analysis (after all subjects
have been followed-up to the study end) be based on imputed outcomes for
subjects who were LTFU (i.e. right-censored with time
<code>&lt;end_of_study</code>)? Default is <code>TRUE</code>. Setting to <code>FALSE</code>
means that the final analysis would incorporate right-censoring.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Implements the Goldilocks design method described in Broglio et al.
(2014). At each interim analysis, two probabilities are computed:
</p>

<ol>
<li> <p><strong>The posterior predictive probability of eventual success.</strong> This is
calculated as the proportion of imputed datasets at the <em>current</em> sample
size that would go on to be success at the specified threshold. At each
interim analysis it is compared to the corresponding element of
<code>Sn</code>, and if it exceeds the threshold,
accrual/enrollment is suspended and the outstanding follow-up allowed to
complete before conducting the pre-specified final analysis.
</p>
</li>
<li> <p><strong>The posterior predictive probability of final success</strong>. This is
calculated as the proportion of imputed datasets at the <em>maximum</em>
threshold that would go on to be successful. Similar to above, it is
compared to the corresponding element of <code>Fn</code>, and if it
is less than the threshold, accrual/enrollment is suspended and the
trial terminated. Typically this would be a binding decision. If it is
not a binding decision, then one should also explore the simulations
with <code>Fn = 0</code>.
</p>
</li></ol>

<p>Hence, at each interim analysis look, 3 decisions are allowed:
</p>

<ol>
<li> <p><strong>Stop for expected success</strong>
</p>
</li>
<li> <p><strong>Stop for futility</strong>
</p>
</li>
<li> <p><strong>Continue to enroll</strong> new subjects, or if at maximum sample size,
proceed to final analysis.
</p>
</li></ol>

<p>At each interim (and final) analysis methods as:
</p>

<ul>
<li><p> Log-rank test (<code>method = "logrank"</code>).
Each (imputed) dataset with both treatment and control arms can be
compared using a standard log-rank test. The output is a <em>P</em>-value,
and there is no treatment effect reported. The function returns <code class="reqn">1 -
     P</code>, which is reported in <code>post_prob_ha</code>. Whilst not a posterior
probability, it can be contrasted in the same manner. For example, if
the success threshold is <code class="reqn">P &lt; 0.05</code>, then one requires
<code>post_prob_ha</code> <code class="reqn">&gt; 0.95</code>. The reason for this is to enable
simple switching between Bayesian and frequentist paradigms for
analysis.
</p>
</li>
<li><p> Cox proportional hazards regression Wald test (<code>method = "cox"</code>).
Similar to the log-rank test, a <em>P</em>-value is calculated based on a
two-sided test. However, for consistency, <code class="reqn">1 - P</code>, which is
reported in <code>post_prob_ha</code>. Whilst not a posterior probability, it
can be contrasted in the same manner. For example, if the success
threshold is <code class="reqn">P &lt; 0.05</code>, then one requires <code>post_prob_ha</code>
<code class="reqn">&gt; 0.95</code>.
</p>
</li>
<li><p> Bayesian absolute difference (<code>method = "bayes"</code>).
Each imputed dataset is used to update the conjugate Gamma prior
(defined by <code>prior</code>), yielding a posterior distribution for the
piecewise exponential rate parameters. In turn, the posterior
distribution of the cumulative incidence function (<code class="reqn">1 - S(t)</code>, where
<code class="reqn">S(t)</code> is the survival function) evaluated at time
<code>end_of_study</code> is calculated. If a single arm study, then this
summarizes the treatment effect, else, if a two-armed study, the
independent posteriors are used to estimate the posterior distribution
of the difference. A posterior probability is calculated according to
the specification of the test type (<code>alternative</code>) and the value of
the null hypothesis (<code>h0</code>).
</p>
</li>
<li><p> Chi-square test (<code>method = "chisq"</code>).
Each (imputed) dataset with both treatment and control arms can be
compared using a standard chi-square test on the final event status,
which discards the event time information. The output is a
<em>P</em>-value, and there is no treatment effect reported. The function
returns <code class="reqn">1 - P</code>, which is reported in <code>post_prob_ha</code>. Whilst
not a posterior probability, it can be contrasted in the same manner.
For example, if the success threshold is <code class="reqn">P &lt; 0.05</code>, then one
requires <code>post_prob_ha</code> <code class="reqn">&gt; 0.95</code>. The reason for this is to
enable simple switching between Bayesian and frequentist paradigms for
analysis.
</p>
</li>
<li><p> Imputed final analysis (<code>imputed_final</code>).
The overall final analysis conducted after accrual is suspended and
follow-up is complete can be analyzed on imputed datasets (default) or
on the non-imputed dataset. Since the imputations/predictions used
during the interim analyses assume all subjects are imputed (since loss
to follow-up is not yet known), it would seem most appropriate to
conduct the trial in the same manner, especially if loss to follow-up
rates are appreciable. Note, this only applies to subjects who are
right-censored due to loss to follow-up, which we assume is a
non-informative process. This can be used with any <code>method</code>.
</p>
</li></ul>



<h3>Value</h3>

<p>A data frame containing some input parameters (arguments) as well as
statistics from the analysis, including:
</p>

<dl>
<dt><code>N_treatment:</code></dt><dd>
<p>integer. The number of patients enrolled in the treatment arm for
each simulation.</p>
</dd>
<dt><code>N_control:</code></dt><dd>
<p>integer. The number of patients enrolled in the control arm for
each simulation.</p>
</dd>
<dt><code>est_interim:</code></dt><dd>
<p>scalar. The treatment effect that was estimated at the time of the
interim analysis. Note this is not actually used in the final
analysis.</p>
</dd>
<dt><code>est_final:</code></dt><dd>
<p>scalar. The treatment effect that was estimated at the final analysis.
Final analysis occurs when either the maximum sample size is reached
and follow-up complete, or the interim analysis triggered an early
stopping of enrollment/accrual and follow-up for those subjects is
complete.</p>
</dd>
<dt><code>post_prob_ha:</code></dt><dd>
<p>scalar. The corresponding posterior probability from the final
analysis. If <code>imputed_final</code> is true, this is calculated as the
posterior probability of efficacy (or equivalent, depending on how
<code>alternative:</code> and <code>h0</code> were specified) for each imputed
final analysis dataset, and then averaged over the <code>N_impute</code>
imputations. If <code>method = "logrank"</code>, <code>post_prob_ha</code> is
calculated in the same fashion, but value represents <code class="reqn">1 - P</code>,
where <code class="reqn">P</code> denotes the frequentist <code class="reqn">P</code>-value.</p>
</dd>
<dt><code>stop_futility:</code></dt><dd>
<p>integer. A logical indicator of whether the trial was stopped early for
futility.</p>
</dd>
<dt><code>stop_expected_success:</code></dt><dd>
<p>integer. A logical indicator of whether the trial was stopped early for
expected success.</p>
</dd>
</dl>



<h3>References</h3>

<p>Broglio KR, Connor JT, Berry SM. Not too big, not too small: a Goldilocks
approach to sample size selection. <em>Journal of Biopharmaceutical
Statistics</em>, 2014; 24(3): 685–705.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># RCT with exponential hazard (no piecewise breaks)
# Note: the number of imputations is small to enable this example to run
#       quickly on CRAN tests. In practice, much larger values are needed.
survival_adapt(
 hazard_treatment = -log(0.85) / 36,
 hazard_control = -log(0.7) / 36,
 cutpoints = 0,
 N_total = 600,
 lambda = 20,
 lambda_time = 0,
 interim_look = 400,
 end_of_study = 36,
 prior = c(0.1, 0.1),
 block = 2,
 rand_ratio = c(1, 1),
 prop_loss = 0.30,
 alternative = "less",
 h0 = 0,
 Fn = 0.05,
 Sn = 0.9,
 prob_ha = 0.975,
 N_impute = 10,
 N_mcmc = 10,
 method = "bayes")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
