<!DOCTYPE html><html><head><title>Help for package mallet</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mallet}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mallet-package'><p>An R Wrapper for the Java Mallet Topic Modeling Toolkit</p></a></li>
<li><a href='#load.mallet.state'><p>Load a Mallet state into Mallet</p></a></li>
<li><a href='#mallet_jar'><p>Return the mallet jar filename(s)</p></a></li>
<li><a href='#mallet_stoplist_file_path'><p>Return the file path to the mallet stoplists</p></a></li>
<li><a href='#mallet_supported_stoplists'><p>Mallet supported stoplists</p></a></li>
<li><a href='#mallet.doc.topics'><p>Retrieve a matrix of topic weights for every document</p></a></li>
<li><a href='#mallet.import'><p>Import text documents into Mallet format</p></a></li>
<li><a href='#mallet.read.dir'><p>Import documents from a directory into Mallet format</p></a></li>
<li><a href='#mallet.subset.topic.words'><p>Estimate topic-word distributions from a sub-corpus</p></a></li>
<li><a href='#mallet.top.words'><p>Get the most probable words and their probabilities for one topic</p></a></li>
<li><a href='#mallet.topic.hclust'><p>Return a hierarchical clustering of topics</p></a></li>
<li><a href='#mallet.topic.labels'><p>Get strings containing the most probable words for each topic</p></a></li>
<li><a href='#mallet.topic.model.read'><p>Load (read) and save (write) a topic from a file</p></a></li>
<li><a href='#mallet.topic.words'><p>Retrieve a matrix of words weights for topics</p></a></li>
<li><a href='#mallet.word.freqs'><p>Descriptive statistics of word frequencies</p></a></li>
<li><a href='#MalletLDA'><p>Create a Mallet topic model trainer</p></a></li>
<li><a href='#save.mallet.instances'><p>Load and save mallet instances from/to file</p></a></li>
<li><a href='#save.mallet.state'><p>Save a Mallet state to file</p></a></li>
<li><a href='#sotu'><p>State of the Union Adresses.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>An R Wrapper for the Java Mallet Topic Modeling Toolkit</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-07-19</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Måns Magnusson &lt;mons.magnusson@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>
  An R interface for the Java Machine Learning for Language Toolkit (mallet)
  <a href="http://mallet.cs.umass.edu/">http://mallet.cs.umass.edu/</a> to estimate probabilistic topic models, such
  as Latent Dirichlet Allocation. We can use the R package to read textual 
  data into mallet from R objects, run the Java implementation of mallet 
  directly in R, and extract results as R objects. The Mallet toolkit 
  has many functions, this wrapper focuses on the topic modeling sub-package 
  written by David Mimno. The package uses the rJava package to connect to a 
  JVM.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/mimno/RMallet">https://github.com/mimno/RMallet</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/mimno/RMallet/issues">https://github.com/mimno/RMallet/issues</a></td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>java</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.3)</td>
</tr>
<tr>
<td>Imports:</td>
<td>rJava, checkmate</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, dplyr, testthat</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>rmarkdown, knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.0</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-07-19 14:10:22 UTC; mansmagnusson</td>
</tr>
<tr>
<td>Author:</td>
<td>Måns Magnusson <a href="https://orcid.org/0000-0002-0296-2719"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [cre, aut],
  David Mimno <a href="https://orcid.org/0000-0001-7510-9404"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cph]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-07-20 15:50:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='mallet-package'>An R Wrapper for the Java Mallet Topic Modeling Toolkit</h2><span id='topic+mallet-package'></span>

<h3>Description</h3>

<p>An R interface for the Java Machine Learning for Language Toolkit (mallet)
&lt;http://mallet.cs.umass.edu/&gt; to estimate probabilistic topic models, such
as Latent Dirichlet Allocation. We can use the R package to read textual data into mallet from R objects,
run the Java implementation of mallet directly in R, and extract results
as R objects. The Mallet toolkit  has many functions, this wrapper focuses
on the topic modeling sub-package written by David Mimno. The package uses
the rJava package to connect to a JVM.
</p>


<h3>References</h3>

<p>The model, Latent Dirichlet allocation (LDA):
<cite>David M Blei, Andrew Ng, Michael Jordan. Latent Dirichlet Allocation. J. of Machine Learning Research, 2003.</cite>
</p>
<p>The Java toolkit:
<cite>Andrew Kachites McCallum. The Mallet Toolkit. 2002.</cite>
</p>
<p>Details of the fast sparse Gibbs sampling algorithm:
<cite>Limin Yao, David Mimno, Andrew McCallum. Streaming Inference for Latent Dirichlet Allocation. KDD, 2009.</cite>
</p>
<p>Hyperparameter optimization:
<cite>Hanna Wallach, David Mimno, Andrew McCallum. Rethinking LDA: Why Priors Matter. NIPS, 2010.</cite>
</p>

<hr>
<h2 id='load.mallet.state'>Load a Mallet state into Mallet</h2><span id='topic+load.mallet.state'></span>

<h3>Description</h3>

<p>This reads writes a current sampling state of mallet to file. The state contain
hyperparameters <code class="reqn">\alpha</code> and <code class="reqn">\beta</code> together with topic indicators.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>load.mallet.state(topic.model, state.file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="load.mallet.state_+3A_topic.model">topic.model</code></td>
<td>
<p>A <code>cc.mallet.topics.RTopicModel</code> object created by <code><a href="#topic+MalletLDA">MalletLDA</a></code>.</p>
</td></tr>
<tr><td><code id="load.mallet.state_+3A_state.file">state.file</code></td>
<td>
<p>File path to store the mallet state file to.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a java <code>cc.mallet.topics.RTopicModel</code> object
</p>

<hr>
<h2 id='mallet_jar'>Return the mallet jar filename(s)</h2><span id='topic+mallet_jar'></span><span id='topic+mallet.jar'></span>

<h3>Description</h3>

<p>Return the mallet jar filename(s)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mallet_jar(full.names = FALSE)

mallet.jar(full.names = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mallet_jar_+3A_full.names">full.names</code></td>
<td>
<p>a logical value.
If TRUE, the directory path is prepended to the file names to give
a relative file path. If FALSE, the file name(s) (rather than paths)
are returned.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Mallet is implemented as a jar-file in the mallet R package.
This function returns the file name and file path for that file(s)
</p>

<hr>
<h2 id='mallet_stoplist_file_path'>Return the file path to the mallet stoplists</h2><span id='topic+mallet_stoplist_file_path'></span><span id='topic+mallet.stoplist.file.path'></span>

<h3>Description</h3>

<p>Return the file path to the mallet stoplists
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mallet_stoplist_file_path(language = "en")

mallet.stoplist.file.path(language = "en")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mallet_stoplist_file_path_+3A_language">language</code></td>
<td>
<p>language to return stoplist for. Defaults to engligs ([en]).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns the path to the mallet stop word list.
See [mallet_supported_stoplists()] for which stoplists that are included.
</p>

<hr>
<h2 id='mallet_supported_stoplists'>Mallet supported stoplists</h2><span id='topic+mallet_supported_stoplists'></span><span id='topic+mallet.supported.stoplists'></span>

<h3>Description</h3>

<p>Mallet supported stoplists
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mallet_supported_stoplists()

mallet.supported.stoplists()
</code></pre>


<h3>Details</h3>

<p>return vector with included stoplists
</p>

<hr>
<h2 id='mallet.doc.topics'>Retrieve a matrix of topic weights for every document</h2><span id='topic+mallet.doc.topics'></span>

<h3>Description</h3>

<p>This function returns a matrix with one row for every document and one
column for every topic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mallet.doc.topics(topic.model, normalized = FALSE, smoothed = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mallet.doc.topics_+3A_topic.model">topic.model</code></td>
<td>
<p>A <code>cc.mallet.topics.RTopicModel</code> object created by <code><a href="#topic+MalletLDA">MalletLDA</a></code>.</p>
</td></tr>
<tr><td><code id="mallet.doc.topics_+3A_normalized">normalized</code></td>
<td>
<p>If <code>TRUE</code>, normalize the rows so that each document sums to one. If <code>FALSE</code>,
values will be integers (possibly plus the smoothing constant) representing the
actual number of words of each topic in the documents.</p>
</td></tr>
<tr><td><code id="mallet.doc.topics_+3A_smoothed">smoothed</code></td>
<td>
<p>If <code>TRUE</code>, add the smoothing parameter for the model (initial value specified as
<code>alpha.sum</code> in <code>MalletLDA</code>). If <code>FALSE</code>, many values will be zero.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a number of documents by number of topics matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Read in sotu example data
data(sotu)
sotu.instances &lt;-
   mallet.import(id.array = row.names(sotu),
                 text.array = sotu[["text"]],
                 stoplist = mallet_stoplist_file_path("en"),
                 token.regexp = "\\p{L}[\\p{L}\\p{P}]+\\p{L}")

# Create topic model
topic.model &lt;- MalletLDA(num.topics=10, alpha.sum = 1, beta = 0.1)
topic.model$loadDocuments(sotu.instances)

# Train topic model
topic.model$train(200)

# Extract results
doc_topics &lt;- mallet.doc.topics(topic.model, smoothed=TRUE, normalized=TRUE)
topic_words &lt;- mallet.topic.words(topic.model, smoothed=TRUE, normalized=TRUE)
top_words &lt;- mallet.top.words(topic.model, word.weights = topic_words[2,], num.top.words = 5)

## End(Not run)


</code></pre>

<hr>
<h2 id='mallet.import'>Import text documents into Mallet format</h2><span id='topic+mallet.import'></span>

<h3>Description</h3>

<p>This function takes an array of document IDs and text files (as character strings)
and converts them into a Mallet instance list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mallet.import(
  id.array = NULL,
  text.array,
  stoplist = "",
  preserve.case = FALSE,
  token.regexp = "[\\p{L}]+"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mallet.import_+3A_id.array">id.array</code></td>
<td>
<p>An array of document IDs. Default is <code>text.array</code> index.</p>
</td></tr>
<tr><td><code id="mallet.import_+3A_text.array">text.array</code></td>
<td>
<p>A character vector with each element containing a document.</p>
</td></tr>
<tr><td><code id="mallet.import_+3A_stoplist">stoplist</code></td>
<td>
<p>The name of a file containing stopwords (words to ignore), one per line, or a character vector containing stop words.
If the file is not in the current working directory, you may need to include a full path.
Default is no stoplist.</p>
</td></tr>
<tr><td><code id="mallet.import_+3A_preserve.case">preserve.case</code></td>
<td>
<p>By default, the input text is converted to all lowercase.</p>
</td></tr>
<tr><td><code id="mallet.import_+3A_token.regexp">token.regexp</code></td>
<td>
<p>A quoted string representing a regular expression that defines a token. The default
is one or more unicode letter: &quot;[\\p{L}]+&quot;. Note that special characters must
have double backslashes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>cc/mallet/types/InstanceList</code> object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mallet.word.freqs">mallet.word.freqs</a></code> returns term and document frequencies, which may be useful in selecting stopwords.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Read in sotu example data
data(sotu)
sotu.instances &lt;-
   mallet.import(id.array = row.names(sotu),
                 text.array = sotu[["text"]],
                 stoplist = mallet_stoplist_file_path("en"),
                 token.regexp = "\\p{L}[\\p{L}\\p{P}]+\\p{L}")


## End(Not run)

</code></pre>

<hr>
<h2 id='mallet.read.dir'>Import documents from a directory into Mallet format</h2><span id='topic+mallet.read.dir'></span>

<h3>Description</h3>

<p>This function takes a directory path as its only argument and returns a
<code>data.frame</code> with two columns: &lt;id&gt; &amp; &lt;text&gt;,
which can be passed to the <code>mallet.import</code> function.
This <code>data.frame</code> has as many rows as there are files in the <code>Dir</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mallet.read.dir(Dir)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mallet.read.dir_+3A_dir">Dir</code></td>
<td>
<p>The path to a directory containing one document per file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>data.frame</code> with file <code>id</code> and <code>text</code> content.
</p>


<h3>Note</h3>

<p>This function was contributed to RMallet by Dan Bowen.
</p>


<h3>Author(s)</h3>

<p>Dan Bowen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mallet.import">mallet.import</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
directory &lt;- system.file("stoplists", package = "mallet")
stoplists &lt;- mallet.read.dir(directory)

## End(Not run)

</code></pre>

<hr>
<h2 id='mallet.subset.topic.words'>Estimate topic-word distributions from a sub-corpus</h2><span id='topic+mallet.subset.topic.words'></span>

<h3>Description</h3>

<p>This function returns a matrix of word probabilities for each topic similar to
<code><a href="#topic+mallet.topic.words">mallet.topic.words</a></code>, but estimated from a subset of the documents
in the corpus. The model assumes that topics are the same no matter where they
are used, but we know this is often not the case. This function lets us test
whether some words are used more or less than we expect in a particular set
of documents.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mallet.subset.topic.words(
  topic.model,
  subset.docs,
  normalized = FALSE,
  smoothed = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mallet.subset.topic.words_+3A_topic.model">topic.model</code></td>
<td>
<p>A <code>cc.mallet.topics.RTopicModel</code> object created by <code><a href="#topic+MalletLDA">MalletLDA</a></code>.</p>
</td></tr>
<tr><td><code id="mallet.subset.topic.words_+3A_subset.docs">subset.docs</code></td>
<td>
<p>A logical vector of <code>TRUE</code>/<code>FALSE</code> values specifying which documents should
be used/included and which should be ignored.</p>
</td></tr>
<tr><td><code id="mallet.subset.topic.words_+3A_normalized">normalized</code></td>
<td>
<p>If <code>TRUE</code>, normalize the rows so that each topic sums to one. If <code>FALSE</code>,
values will be integers (possibly plus the smoothing constant) representing
the actual number of words of each type in the topics.</p>
</td></tr>
<tr><td><code id="mallet.subset.topic.words_+3A_smoothed">smoothed</code></td>
<td>
<p>If <code>TRUE</code>, add the smoothing parameter for the model (initial value specified
as <code>beta</code> in <code>MalletLDA</code>). If <code>FALSE</code>, many values will be zero.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a number of topics by vocabulary size matrix for the the included documents.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mallet.topic.words">mallet.topic.words</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Read in sotu example data
data(sotu)
sotu.instances &lt;-
   mallet.import(id.array = row.names(sotu),
                 text.array = sotu[["text"]],
                 stoplist = mallet_stoplist_file_path("en"),
                 token.regexp = "\\p{L}[\\p{L}\\p{P}]+\\p{L}")

# Create topic model
topic.model &lt;- MalletLDA(num.topics=10, alpha.sum = 1, beta = 0.1)
topic.model$loadDocuments(sotu.instances)

# Train topic model
topic.model$train(200)

# Extract subcorpus topic word matrix
post1975_topic_words &lt;- mallet.subset.topic.words(topic.model, sotu[["year"]] &gt; 1975)
mallet.top.words(topic.model, word.weights = post1975_topic_words[2,], num.top.words = 5)

## End(Not run)

</code></pre>

<hr>
<h2 id='mallet.top.words'>Get the most probable words and their probabilities for one topic</h2><span id='topic+mallet.top.words'></span>

<h3>Description</h3>

<p>This function returns a data frame with two columns, one containing the most
probable words as character values, the second containing the weight assigned
to that word in the word weights vector you supplied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mallet.top.words(topic.model, word.weights, num.top.words = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mallet.top.words_+3A_topic.model">topic.model</code></td>
<td>
<p>A <code>cc.mallet.topics.RTopicModel</code> object created by <code><a href="#topic+MalletLDA">MalletLDA</a></code>.</p>
</td></tr>
<tr><td><code id="mallet.top.words_+3A_word.weights">word.weights</code></td>
<td>
<p>A vector of word weights for one topic, usually a row from the <code>topic.words</code>
matrix from <code>mallet.topic.words</code>.</p>
</td></tr>
<tr><td><code id="mallet.top.words_+3A_num.top.words">num.top.words</code></td>
<td>
<p>The number of most probable words to return. If not specified, defaults to 10.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>data.frame</code> with the top terms (<code>term</code>) and their weights/probability (<code>weight</code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Read in sotu example data
data(sotu)
sotu.instances &lt;-
   mallet.import(id.array = row.names(sotu),
                 text.array = sotu[["text"]],
                 stoplist = mallet_stoplist_file_path("en"),
                 token.regexp = "\\p{L}[\\p{L}\\p{P}]+\\p{L}")

# Create topic model
topic.model &lt;- MalletLDA(num.topics=10, alpha.sum = 1, beta = 0.1)
topic.model$loadDocuments(sotu.instances)

# Train topic model
topic.model$train(200)

# Extract top words
top_words &lt;- mallet.top.words(topic.model, word.weights = topic_words[2,], num.top.words = 5)

## End(Not run)

</code></pre>

<hr>
<h2 id='mallet.topic.hclust'>Return a hierarchical clustering of topics</h2><span id='topic+mallet.topic.hclust'></span>

<h3>Description</h3>

<p>Returns a hierarchical clustering of topics that can be plotted as a dendrogram.
There are two ways of measuring topic similarity: topics may contain the some of
the same words, or the may appear in some of the same documents. The <code>balance</code> parameter allows you to interpolate between the similarities determined by these two methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mallet.topic.hclust(
  doc.topics,
  topic.words,
  balance = 0.3,
  method = "euclidean",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mallet.topic.hclust_+3A_doc.topics">doc.topics</code></td>
<td>
<p>A documents by topics matrix of topic probabilities (see <code><a href="#topic+mallet.doc.topics">mallet.doc.topics</a></code>).</p>
</td></tr>
<tr><td><code id="mallet.topic.hclust_+3A_topic.words">topic.words</code></td>
<td>
<p>A topics by words matrix of word probabilities (see <code><a href="#topic+mallet.topic.words">mallet.topic.words</a></code>) .</p>
</td></tr>
<tr><td><code id="mallet.topic.hclust_+3A_balance">balance</code></td>
<td>
<p>A value between 0.0 (use only document-level similarity)
and 1.0 (use only word-level similarity).</p>
</td></tr>
<tr><td><code id="mallet.topic.hclust_+3A_method">method</code></td>
<td>
<p>method to use in <code><a href="stats.html#topic+dist">dist</a></code> to compute distance between topics.
Defaults to <code>euclidian</code>.</p>
</td></tr>
<tr><td><code id="mallet.topic.hclust_+3A_...">...</code></td>
<td>
<p>Further arguments for <code><a href="stats.html#topic+hclust">hclust</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code><a href="stats.html#topic+hclust">hclust</a></code> which describes the tree produced by the clustering process.
</p>


<h3>See Also</h3>

<p>This function uses data matrices from <code><a href="#topic+mallet.doc.topics">mallet.doc.topics</a></code>
and <code><a href="#topic+mallet.topic.words">mallet.topic.words</a></code> using the <code><a href="stats.html#topic+hclust">hclust</a></code> function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Read in sotu example data
data(sotu)
sotu.instances &lt;-
   mallet.import(id.array = row.names(sotu),
                 text.array = sotu[["text"]],
                 stoplist = mallet_stoplist_file_path("en"),
                 token.regexp = "\\p{L}[\\p{L}\\p{P}]+\\p{L}")

# Create topic model
topic.model &lt;- MalletLDA(num.topics=10, alpha.sum = 1, beta = 0.1)
topic.model$loadDocuments(sotu.instances)

# Train topic model
topic.model$train(200)

# Create hiearchical clusters of topics
doc_topics &lt;- mallet.doc.topics(topic.model, smoothed=TRUE, normalized=TRUE)
topic_words &lt;- mallet.topic.words(topic.model, smoothed=TRUE, normalized=TRUE)
topic_labels &lt;- mallet.topic.labels(topic.model)
plot(mallet.topic.hclust(doc_topics, topic_words, balance = 0.3), labels=topic_labels)

## End(Not run)

</code></pre>

<hr>
<h2 id='mallet.topic.labels'>Get strings containing the most probable words for each topic</h2><span id='topic+mallet.topic.labels'></span>

<h3>Description</h3>

<p>This function returns a vector of strings, one for each topic, with the
most probable words in that topic separated by spaces.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mallet.topic.labels(topic.model, topic.words = NULL, num.top.words = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mallet.topic.labels_+3A_topic.model">topic.model</code></td>
<td>
<p>A <code>cc.mallet.topics.RTopicModel</code> object created by <code><a href="#topic+MalletLDA">MalletLDA</a></code>.</p>
</td></tr>
<tr><td><code id="mallet.topic.labels_+3A_topic.words">topic.words</code></td>
<td>
<p>The matrix of topic-word weights returned by <code><a href="#topic+mallet.topic.words">mallet.topic.words</a></code>
Default (NULL) is to use the <code>topic.model</code> to extract the <code>topic.words</code>.</p>
</td></tr>
<tr><td><code id="mallet.topic.labels_+3A_num.top.words">num.top.words</code></td>
<td>
<p>The number of words to include for each topic. Defaults to 3.</p>
</td></tr>
<tr><td><code id="mallet.topic.labels_+3A_...">...</code></td>
<td>
<p>Further arguments supplied to <code><a href="#topic+mallet.topic.words">mallet.topic.words</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a character vector with one element per topic
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mallet.topic.words">mallet.topic.words</a></code> produces topic-word weights.
<code><a href="#topic+mallet.top.words">mallet.top.words</a></code> produces a data frame for a single topic.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Read in sotu example data
data(sotu)
sotu.instances &lt;-
   mallet.import(id.array = row.names(sotu),
                 text.array = sotu[["text"]],
                 stoplist = mallet_stoplist_file_path("en"),
                 token.regexp = "\\p{L}[\\p{L}\\p{P}]+\\p{L}")

# Create topic model
topic.model &lt;- MalletLDA(num.topics=10, alpha.sum = 1, beta = 0.1)
topic.model$loadDocuments(sotu.instances)

# Train topic model
topic.model$train(200)

# Create hiearchical clusters of topics
doc_topics &lt;- mallet.doc.topics(topic.model, smoothed=TRUE, normalized=TRUE)
topic_words &lt;- mallet.topic.words(topic.model, smoothed=TRUE, normalized=TRUE)
topic_labels &lt;- mallet.topic.labels(topic.model)
plot(mallet.topic.hclust(doc_topics, topic_words, balance = 0.3), labels=topic_labels)

## End(Not run)

</code></pre>

<hr>
<h2 id='mallet.topic.model.read'>Load (read) and save (write) a topic from a file</h2><span id='topic+mallet.topic.model.read'></span><span id='topic+mallet.topic.model.load'></span><span id='topic+mallet.topic.model.write'></span><span id='topic+mallet.topic.model.save'></span>

<h3>Description</h3>

<p>This function returns the topic model loaded from a file or stores a topic model to file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mallet.topic.model.read(filename)

mallet.topic.model.load(filename)

mallet.topic.model.write(topic.model, filename)

mallet.topic.model.save(topic.model, filename)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mallet.topic.model.read_+3A_filename">filename</code></td>
<td>
<p>The mallet topic model file</p>
</td></tr>
<tr><td><code id="mallet.topic.model.read_+3A_topic.model">topic.model</code></td>
<td>
<p>A <code>cc.mallet.topics.RTopicModel</code> object created by <code><a href="#topic+MalletLDA">MalletLDA</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='mallet.topic.words'>Retrieve a matrix of words weights for topics</h2><span id='topic+mallet.topic.words'></span>

<h3>Description</h3>

<p>This function returns a matrix with one row for every topic
and one column for every word in the vocabulary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mallet.topic.words(topic.model, normalized = FALSE, smoothed = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mallet.topic.words_+3A_topic.model">topic.model</code></td>
<td>
<p>A <code>cc.mallet.topics.RTopicModel</code> object created by <code><a href="#topic+MalletLDA">MalletLDA</a></code>.</p>
</td></tr>
<tr><td><code id="mallet.topic.words_+3A_normalized">normalized</code></td>
<td>
<p>If <code>TRUE</code>, normalize the rows so that each topic sums to one. If <code>FALSE</code>,
values will be integers (possibly plus the smoothing constant) representing the
actual number of words of each type in the topics.</p>
</td></tr>
<tr><td><code id="mallet.topic.words_+3A_smoothed">smoothed</code></td>
<td>
<p>If <code>TRUE</code>, add the smoothing parameter for the model (initial value specified as
<code>beta</code> in <code>MalletLDA</code>). If <code>FALSE</code>, many values will be zero.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a number of topics by vocabulary size matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Read in sotu example data
data(sotu)
sotu.instances &lt;-
   mallet.import(id.array = row.names(sotu),
                 text.array = sotu[["text"]],
                 stoplist = mallet_stoplist_file_path("en"),
                 token.regexp = "\\p{L}[\\p{L}\\p{P}]+\\p{L}")

# Create topic model
topic.model &lt;- MalletLDA(num.topics=10, alpha.sum = 1, beta = 0.1)
topic.model$loadDocuments(sotu.instances)

# Train topic model
topic.model$train(200)

# Extract results
doc_topics &lt;- mallet.doc.topics(topic.model, smoothed=TRUE, normalized=TRUE)
topic_words &lt;- mallet.topic.words(topic.model, smoothed=TRUE, normalized=TRUE)
top_words &lt;- mallet.top.words(topic.model, word.weights = topic_words[2,], num.top.words = 5)

## End(Not run)

</code></pre>

<hr>
<h2 id='mallet.word.freqs'>Descriptive statistics of word frequencies</h2><span id='topic+mallet.word.freqs'></span>

<h3>Description</h3>

<p>This method returns a data frame with one row for each unique vocabulary word,
and three columns: the word as a <code>character</code> value, the total number of
tokens of that word type, and the total number of documents that contain that
word at least once. This information can be useful in identifying candidate
stopwords.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mallet.word.freqs(topic.model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mallet.word.freqs_+3A_topic.model">topic.model</code></td>
<td>
<p>A <code>cc.mallet.topics.RTopicModel</code> object created by <code><a href="#topic+MalletLDA">MalletLDA</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>data.frame</code> with the word type (<code>word</code>), the word frequency (<code>word.freq</code>), and the document frequency (<code>doc.freq</code>)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MalletLDA">MalletLDA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Read in sotu example data
data(sotu)
sotu.instances &lt;-
   mallet.import(id.array = row.names(sotu),
                 text.array = sotu[["text"]],
                 stoplist = mallet_stoplist_file_path("en"),
                 token.regexp = "\\p{L}[\\p{L}\\p{P}]+\\p{L}")

# Create topic model
topic.model &lt;- MalletLDA(num.topics=10, alpha.sum = 1, beta = 0.1)
topic.model$loadDocuments(sotu.instances)

# Get word frequencies
word_freqs &lt;- mallet.word.freqs(topic.model)


## End(Not run)

</code></pre>

<hr>
<h2 id='MalletLDA'>Create a Mallet topic model trainer</h2><span id='topic+MalletLDA'></span>

<h3>Description</h3>

<p>This function creates a java cc.mallet.topics.RTopicModel object that wraps a
Mallet topic model trainer java object, cc.mallet.topics.ParallelTopicModel.
Note that you can call any of the methods of this java object as properties.
In the example below, I make a call directly to the
<code>topic.model$setAlphaOptimization(20, 50)</code> java method,
which passes this update to the model itself.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MalletLDA(num.topics = 10, alpha.sum = 5, beta = 0.01)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MalletLDA_+3A_num.topics">num.topics</code></td>
<td>
<p>The number of topics to use. If not specified, this defaults to 10.</p>
</td></tr>
<tr><td><code id="MalletLDA_+3A_alpha.sum">alpha.sum</code></td>
<td>
<p>This is the magnitude of the Dirichlet prior over the topic distribution of a document.
The default value is 5.0. With 10 topics, this setting leads to a Dirichlet with
parameter <code class="reqn">\alpha_k = 0.5</code>. You can intuitively think of this parameter as a
number of &quot;pseudo-words&quot;, divided evenly between all topics, that are present in
every document no matter how the other words are allocated to topics. This is an
initial value, which may be changed during training if hyperparameter
optimization is active.</p>
</td></tr>
<tr><td><code id="MalletLDA_+3A_beta">beta</code></td>
<td>
<p>This is the per-word weight of the Dirichlet prior over topic-word distributions.
The magnitude of the distribution (the sum over all words of this parameter) is
determined by the number of words in the vocabulary. Again, this value may change
due to hyperparameter optimization.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>cc.mallet.topics.RTopicModel</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Read in sotu example data
data(sotu)
sotu.instances &lt;-
   mallet.import(id.array = row.names(sotu),
                 text.array = sotu[["text"]],
                 stoplist = mallet_stoplist_file_path("en"),
                 token.regexp = "\\p{L}[\\p{L}\\p{P}]+\\p{L}")

# Create topic model
topic.model &lt;- MalletLDA(num.topics=10, alpha.sum = 1, beta = 0.1)
topic.model$loadDocuments(sotu.instances)

# Train topic model
topic.model$train(200)

# Extract results
doc_topics &lt;- mallet.doc.topics(topic.model, smoothed=TRUE, normalized=TRUE)
topic_words &lt;- mallet.topic.words(topic.model, smoothed=TRUE, normalized=TRUE)
top_words &lt;- mallet.top.words(topic.model, word.weights = topic_words[2,], num.top.words = 5)

## End(Not run)

</code></pre>

<hr>
<h2 id='save.mallet.instances'>Load and save mallet instances from/to file</h2><span id='topic+save.mallet.instances'></span><span id='topic+load.mallet.instances'></span>

<h3>Description</h3>

<p>This function returns the topic model loaded from a file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>save.mallet.instances(instances, filename)

load.mallet.instances(filename)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="save.mallet.instances_+3A_instances">instances</code></td>
<td>
<p>An <code>cc/mallet/types/InstanceList</code> <code>instanceList</code> object to save/write to file.</p>
</td></tr>
<tr><td><code id="save.mallet.instances_+3A_filename">filename</code></td>
<td>
<p>The filename to save to or load from.</p>
</td></tr>
</table>

<hr>
<h2 id='save.mallet.state'>Save a Mallet state to file</h2><span id='topic+save.mallet.state'></span>

<h3>Description</h3>

<p>This function writes a current sampling state of mallet to file.
The state contain hyperparameters <code class="reqn">\alpha</code> and <code class="reqn">\beta</code> together with topic indicators.
</p>
<p>The state file can be read into R using the function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>save.mallet.state(topic.model, state.file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="save.mallet.state_+3A_topic.model">topic.model</code></td>
<td>
<p>A <code>cc.mallet.topics.RTopicModel</code> object created by <code><a href="#topic+MalletLDA">MalletLDA</a></code>.</p>
</td></tr>
<tr><td><code id="save.mallet.state_+3A_state.file">state.file</code></td>
<td>
<p>File path (.gz format) to store the mallet state file to.</p>
</td></tr>
</table>

<hr>
<h2 id='sotu'>State of the Union Adresses.</h2><span id='topic+sotu'></span>

<h3>Description</h3>

<p>A dataset containing State of the Union Adresses by paragraph from 1946 to 2000.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sotu
</code></pre>


<h3>Format</h3>

<p>A <code><a href="tibble.html#topic+tibble">tibble</a></code> <code>data.frame</code> with 6816 rows and 3 variables:
</p>

<dl>
<dt>year</dt><dd><p>Year of the adress.</p>
</dd>
<dt>paragraph</dt><dd><p>The paragraph of the address.</p>
</dd>
<dt>text</dt><dd><p>The address content.</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://en.wikipedia.org/wiki/State_of_the_Union">https://en.wikipedia.org/wiki/State_of_the_Union</a>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
