<!DOCTYPE html><html lang="en"><head><title>Help for package SVMMaj</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SVMMaj}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#auc'><p>Returns the area under the curve value</p></a></li>
<li><a href='#AusCredit'><p>Australian Credit Approval Dataset</p></a></li>
<li><a href='#classification'><p>Show the classification performance</p></a></li>
<li><a href='#diabetes'><p>Pima Indians Diabetes Data Set</p></a></li>
<li><a href='#getHinge'><p>Hinge error function of SVM-Maj</p></a></li>
<li><a href='#isb'><p>I-spline basis of each column of a given matrix</p></a></li>
<li><a href='#isplinebasis'><p>Transform a given data into I-splines</p></a></li>
<li><a href='#normalize'><p>Normalize/standardize the columns of a matrix</p></a></li>
<li><a href='#plot.hinge'><p>Plot the hinge function</p></a></li>
<li><a href='#plot.svmmajcrossval'><p>Plot the cross validation output</p></a></li>
<li><a href='#plotWeights'><p>Plot the weights of all attributes from the trained SVM model</p></a></li>
<li><a href='#predict.svmmaj'><p>Out-of-Sample Prediction from Unseen Data.</p></a></li>
<li><a href='#predict.transDat'><p>Perform the transformation based on predefined settings</p></a></li>
<li><a href='#print.q.svmmaj'><p>SVM-Maj Algorithm</p></a></li>
<li><a href='#print.svmmaj'><p>Print Svmmaj class</p></a></li>
<li><a href='#print.svmmajcrossval'><p>Print SVMMaj cross validation results</p></a></li>
<li><a href='#roccurve'><p>Plot the ROC curve of the predicted values</p></a></li>
<li><a href='#supermarket1996'><p>Supermarket data 1996</p></a></li>
<li><a href='#svmmajcrossval'><p>k-fold Cross-Validation of SVM-Maj</p></a></li>
<li><a href='#transformdata'><p>Transform the data with normalization and/or spline basis</p></a></li>
<li><a href='#voting'><p>Congressional Voting Records Data Set</p></a></li>
<li><a href='#X.svmmaj'><p>Returns transformed attributes</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Implementation of the SVM-Maj Algorithm</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.9.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-11-21</td>
</tr>
<tr>
<td>Description:</td>
<td>
  Implements the SVM-Maj algorithm to train data with support vector machine
  &lt;<a href="https://doi.org/10.1007%2Fs11634-008-0020-9">doi:10.1007/s11634-008-0020-9</a>&gt;.
  This algorithm uses two efficient updates, one for linear kernel and one 
  for the nonlinear kernel.</td>
</tr>
<tr>
<td>Imports:</td>
<td>reshape2, scales, gridExtra, dplyr, ggplot2, kernlab</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.13.0), stats, graphics, parallel</td>
</tr>
<tr>
<td>Suggests:</td>
<td>utils, testthat, magrittr, xtable</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>Yes</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>utils</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-11-21 23:25:00 UTC; hoksanyip</td>
</tr>
<tr>
<td>Author:</td>
<td>Hoksan Yip [aut, cre],
  Patrick J.F. Groenen [aut],
  Georgi Nalbantov [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Hoksan Yip &lt;hoksan@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-11-22 13:40:18 UTC</td>
</tr>
</table>
<hr>
<h2 id='auc'>Returns the area under the curve value</h2><span id='topic+auc'></span>

<h3>Description</h3>

<p>Returns the area under the curve value as a fraction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>auc(q, y = attr(q, "y"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="auc_+3A_q">q</code></td>
<td>
<p>the predicted values</p>
</td></tr>
<tr><td><code id="auc_+3A_y">y</code></td>
<td>
<p>a list of the actual classes of <code>q</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>the area under the curve value
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df &lt;- with(diabetes, cbind(y, X))
lm.y &lt;- glm(y ~ ., data = df, family = binomial())
print(with(lm.y, auc(fitted.values, y)))

</code></pre>

<hr>
<h2 id='AusCredit'>Australian Credit Approval Dataset</h2><span id='topic+AusCredit'></span><span id='topic+AusCredit.te'></span><span id='topic+AusCredit.tr'></span>

<h3>Description</h3>

<p>This file concerns credit card applications of 690 households.
</p>


<h3>Format</h3>

<p>This data set has been split into two components for the convenience
of the model training.
</p>
<p><code>data.frame</code>-object <code>X</code> consists of with 6 numerical and 8
categorical attributes. The labels have been changed for the convenience of
the statistical algorithms. For example, attribute 4 originally had 3 labels
p,g,gg and these have been changed to labels 1,2,3.
</p>
<p>Factor <code>y</code> indicates whether the application has been <code>Accepted</code>
or <code>Rejected</code>
</p>
<p>The training set <code>AusCredit.tr</code> contains a randomly selected set of 400
subjects, and <code>AusCredit.te</code> contains the remaining 290 subjects.
<code>AusCredit</code> contains all 690 objects.
</p>


<h3>Details</h3>

<p>All attribute names and values have been changed to meaningless symbols to
protect confidentiality of the data.
</p>
<p>This dataset is interesting because there is a good mix of attributes &ndash;
continuous, nominal with small numbers of values, and nominal with larger
numbers of values.  There are also a few missing values.
</p>


<h3>Source</h3>

<p>Chih-Chung Chang and Chih-Jen Lin, LIBSVM : a library for support
vector machines, 2001.  Software available at
<a href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/">https://www.csie.ntu.edu.tw/~cjlin/libsvm/</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
attach(AusCredit)
summary(X)
summary(y)
detach(AusCredit)

</code></pre>

<hr>
<h2 id='classification'>Show the classification performance</h2><span id='topic+classification'></span>

<h3>Description</h3>

<p>Given the predicted value <code>q</code> and the observed classes <code>y</code>,
it shows an overview of the prediction performances with hit rates,
misclassification rates, true positives (TP), false positives (FP)
and precision.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classification(q, y, classes = c("-1", "1"), weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="classification_+3A_q">q</code></td>
<td>
<p>the predicted values</p>
</td></tr>
<tr><td><code id="classification_+3A_y">y</code></td>
<td>
<p>a list of the actual classes of <code>q</code></p>
</td></tr>
<tr><td><code id="classification_+3A_classes">classes</code></td>
<td>
<p>a character vector with the labels of the two classes</p>
</td></tr>
<tr><td><code id="classification_+3A_weights">weights</code></td>
<td>
<p>an optional parameter to specify a weighted hit rate and
misclassification rate</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with three elements, <code>matrix</code> equals the confusion
matrix,<code>overall</code> equals the overall prediction performance and
in <code>measures</code> the measures per class is stored.
</p>

<hr>
<h2 id='diabetes'>Pima Indians Diabetes Data Set</h2><span id='topic+diabetes'></span><span id='topic+diabetes.tr'></span><span id='topic+diabetes.te'></span>

<h3>Description</h3>

<p>From National Institute of Diabetes and Digestive and Kidney Diseases.
</p>


<h3>Format</h3>

<p><code>X</code> is a data frame of 768 female patients with 8 attributes.
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>no.pregnant</code> </td><td style="text-align: left;"> number of pregnancies. </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>glucose</code> </td><td style="text-align: left;"> plasma glucose concentration in an oral glucose
                     tolerance test </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>blood.press</code> </td><td style="text-align: left;"> diastolic blood pressure (mm Hg) </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>triceps.thick</code> </td><td style="text-align: left;"> triceps skin fold thickness (mm) </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>insulin</code> </td><td style="text-align: left;"> 2-Hour serum insulin (mu U/ml) </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>BMI</code> </td><td style="text-align: left;"> body mass index (weight in kg/(height in m)**2) </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>pedigree</code> </td><td style="text-align: left;"> diabetes pedigree function </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>age</code> </td><td style="text-align: left;"> age in years
</td>
</tr>

</table>

<p><code>y</code> contains the class labels: <code>Yes</code> or No, for diabetic according
to WHO criteria.
</p>
<p>The training set <code>diabetes.tr</code> contains a randomly selected set of 600
subjects, and <code>diabetes.te</code> contains the remaining 168 subjects.
<code>diabetes</code> contains all 768 objects.
</p>


<h3>Details</h3>

<p>Several constraints were placed on the selection of these instances from a
larger database.  In particular, all patients here are females at least 21
years old of Pima Indian heritage.
</p>


<h3>Source</h3>

<p>Chih-Chung Chang and Chih-Jen Lin, LIBSVM : a library for support
vector machines, 2001. Software available at
<a href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/">https://www.csie.ntu.edu.tw/~cjlin/libsvm/</a>.
</p>


<h3>References</h3>

<p>Smith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., &amp;
Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the
onset of diabetes mellitus. In Proceedings of the <em>Symposium on
Computer Applications and Medical Care</em> (pp. 261&ndash;265). IEEE Computer
Society Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
attach(diabetes)
summary(X)
summary(y)

</code></pre>

<hr>
<h2 id='getHinge'>Hinge error function of SVM-Maj</h2><span id='topic+getHinge'></span><span id='topic+print.hinge'></span>

<h3>Description</h3>

<p>This function creates a function to compute the hinge error,
given its predicted value <code>q</code> and its class <code>y</code>,
according to the loss term of the Support Vector machine loss function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getHinge(hinge = "quadratic", delta = 3, eps = 1e-08)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getHinge_+3A_hinge">hinge</code></td>
<td>
<p>Hinge error function to be used, possible values are
<code>'absolute'</code>, <code>'quadratic'</code> and <code>'huber'</code></p>
</td></tr>
<tr><td><code id="getHinge_+3A_delta">delta</code></td>
<td>
<p>The parameter of the huber hinge
(only if <code>hinge = 'huber'</code>).</p>
</td></tr>
<tr><td><code id="getHinge_+3A_eps">eps</code></td>
<td>
<p>Specifies the maximum steepness of the quadratic majorization
function <code>m(q) = a * q ^ 2 -2 * b * q + c</code>, where
<code>a &lt;= .25 * eps ^ -1</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The hinge error function with arguments <code>q</code> and <code>y</code> to
compute the hinge error. The function returns a list with the parameters
of the majorization function SVM-Maj (<code>a</code>, <code>b</code> and <code>c</code>)
and the loss error of each object (<code>loss</code>).
</p>


<h3>References</h3>

<p>P.J.F. Groenen, G. Nalbantov and J.C. Bioch (2008)
<em>SVM-Maj: a majorization approach to linear support
vector machines with different hinge errors.</em>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+svmmaj">svmmaj</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>hingefunction &lt;- getHinge()
## plot hinge function value and, if specified,
## the majorization function at z
## plot(hingefunction, z = 3)
## generate loss function value
loss &lt;- hingefunction(q = -10:10, y = 1)$loss
print(loss)
plot(hingefunction, z = 3)
</code></pre>

<hr>
<h2 id='isb'>I-spline basis of each column of a given matrix</h2><span id='topic+isb'></span>

<h3>Description</h3>

<p>Create a I-spline basis for an array. <code>isb</code> will equally distribute the
knots over the value range using quantiles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isb(x, spline.knots = 0, knots = NULL, spline.degree = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="isb_+3A_x">x</code></td>
<td>
<p>The predictor variable, which will be transformed into I-spline
basis.</p>
</td></tr>
<tr><td><code id="isb_+3A_spline.knots">spline.knots</code></td>
<td>
<p>Number of inner knots to use. <code>isb</code> will equally
distribute the knots over the value range using quantiles.
<code>spline.knots</code> will only be used if <code>knots</code> is not given.</p>
</td></tr>
<tr><td><code id="isb_+3A_knots">knots</code></td>
<td>
<p>An array consisting all knots (boundary knots as well as the
interior knots) to be used to create the spline basis.</p>
</td></tr>
<tr><td><code id="isb_+3A_spline.degree">spline.degree</code></td>
<td>
<p>The polynomial degree of the spline basis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The I-spline with the used spline settings as attribute. The
spline settings attribute can transform the same attribute of any other
objects using the same knots.
</p>


<h3>Author(s)</h3>

<p>Hok San Yip, Patrick J.F. Groenen, Georgi Nalbantov
</p>


<h3>References</h3>

<p>P.J.F. Groenen, G. Nalbantov and J.C. Bioch (2008)
<em>SVM-Maj: a majorization approach to linear support vector machines with
different hinge errors.</em>
</p>
<p>J.O. Ramsay (1988) <em>Monotone regression
splines in action.</em> Statistical Science, 3(4):425-461
</p>


<h3>See Also</h3>

<p><code><a href="#topic+svmmaj">svmmaj</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## plot the spline transformation given a monotone sequence
B0 &lt;- isb(0:100, spline.knots = 2, spline.degree = 3)
plot(NULL, xlim = c(0, 140), ylim = c(0, 1), xlab = "x", ylab = "I-spline")
for (i in 1:ncol(B0)) {
  lines(B0[, i], col = i, lwd = 3)
}
legend("bottomright",
  legend = 1:ncol(B0), col = 1:ncol(B0),
  lty = 1, lwd = 3, title = "Spline Columns"
)
## create I-spline basis for the first 50 observations
x &lt;- iris$Sepal.Length
B1 &lt;- isb(x[1:50], spline.knots = 4, spline.degree = 3)
## extracting the spline transformation settings
spline.param &lt;- attr(B1, "splineInterval")
## use the same settings to apply to the next 50 observations
B2 &lt;- isb(x[-(1:50)], spline.degree = 3, knots = spline.param)
</code></pre>

<hr>
<h2 id='isplinebasis'>Transform a given data into I-splines</h2><span id='topic+isplinebasis'></span>

<h3>Description</h3>

<p>Inner function call to create I-splines based on the
user defined <code>knots</code>  and polynomial degree <code>d</code> of the splines
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isplinebasis(x, knots, d)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="isplinebasis_+3A_x">x</code></td>
<td>
<p>a scalar or vector of values which will be transformed into splines</p>
</td></tr>
<tr><td><code id="isplinebasis_+3A_knots">knots</code></td>
<td>
<p>a vector of knot values of the splines</p>
</td></tr>
<tr><td><code id="isplinebasis_+3A_d">d</code></td>
<td>
<p>the polynomial degree of the splines</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix with for each value of x the corresponding spline values.
</p>

<hr>
<h2 id='normalize'>Normalize/standardize the columns of a matrix</h2><span id='topic+normalize'></span>

<h3>Description</h3>

<p>Standardize the columns of an attribute matrix <code>X</code> to zscores, to the
range <code>[0 1]</code> or a prespecified scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalize(x, standardize = "zscore")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="normalize_+3A_x">x</code></td>
<td>
<p>An attribute variable which will be scaled.</p>
</td></tr>
<tr><td><code id="normalize_+3A_standardize">standardize</code></td>
<td>
<p>Either a string value denoting a predefined scaling, or a
list with values <code>a</code> and <code>b</code> corresponding with the numeric
centering and scaling, that is, using the function <code>x * standardize$b -
standardize$a</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The standardized matrix. The numeric centering and scalings used are
returned as attribute <code>"standardize"</code>.
</p>


<h3>Author(s)</h3>

<p>Hok San Yip, Patrick J.F. Groenen, Georgi Nalbantov
</p>


<h3>References</h3>

<p>P.J.F. Groenen, G. Nalbantov and J.C. Bioch (2008)
<em>SVM-Maj: a majorization approach to linear support vector machines with
different hinge errors.</em>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+svmmaj">svmmaj</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## standardize the first 50 objects to zscores
x &lt;- iris$Sepal.Length
x1 &lt;- normalize(x[1:50], standardize = "zscore")
## use the same settings to apply to the next 100 observations
x2 &lt;- normalize(x[-(1:50)], standardize = attr(x1, "standardization"))
</code></pre>

<hr>
<h2 id='plot.hinge'>Plot the hinge function</h2><span id='topic+plot.hinge'></span>

<h3>Description</h3>

<p>This function plots the hinge object created by <code>getHinge</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hinge'
plot(x, y = 1, z = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.hinge_+3A_x">x</code></td>
<td>
<p>The hinge object returned from <code>getHinge</code>.</p>
</td></tr>
<tr><td><code id="plot.hinge_+3A_y">y</code></td>
<td>
<p>Specifies the class (<code>-1</code> or <code>1</code>)
to be plotted for the hinge error.</p>
</td></tr>
<tr><td><code id="plot.hinge_+3A_z">z</code></td>
<td>
<p>If specified, the majorization function with the supporting point
<code>z</code> will also be plotted.</p>
</td></tr>
<tr><td><code id="plot.hinge_+3A_...">...</code></td>
<td>
<p>Other arguments passed to plot method.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>hingefunction &lt;- getHinge()
## plot hinge function value
plot(hingefunction, z = 3)
</code></pre>

<hr>
<h2 id='plot.svmmajcrossval'>Plot the cross validation output</h2><span id='topic+plot.svmmajcrossval'></span>

<h3>Description</h3>

<p>Shows the results of the cross validation graphically.
Possible graphics are among others the distribution of
the predicted values <code>q</code> per class per lambda value
and the misclassification rate per lambda.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'svmmajcrossval'
plot(x, type = "grid", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.svmmajcrossval_+3A_x">x</code></td>
<td>
<p>the <code>svmmajcrossval</code> object</p>
</td></tr>
<tr><td><code id="plot.svmmajcrossval_+3A_type">type</code></td>
<td>
<p>the type of graph being shown, possible values are
<code>'grid'</code> for the missclassification rate per lambda value,
<code>'profile'</code> the distribution of predicted values
of the classes per lambda value</p>
</td></tr>
<tr><td><code id="plot.svmmajcrossval_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>

<hr>
<h2 id='plotWeights'>Plot the weights of all attributes from the trained SVM model</h2><span id='topic+plotWeights'></span>

<h3>Description</h3>

<p>Shows, one graph per attribute, the weights of all
attributes. The type of graph depends on the type of the attribute: the
spline line of the corresponding attribute in case a spline has been used, a
bar plot for categorical and logical values, and a linear line for all other
type of the attribute values. This function cannot be used in a model with a
non-linear kernel.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotWeights(object, plotdim = c(3, 3), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotWeights_+3A_object">object</code></td>
<td>
<p>The model returned from <code>svmmaj</code>.</p>
</td></tr>
<tr><td><code id="plotWeights_+3A_plotdim">plotdim</code></td>
<td>
<p>A vector of the form <code>c(nr, nc)</code>. Subsequent figures
will be drawn in an <code>nr</code>-by-<code>nc</code> array on the device.</p>
</td></tr>
<tr><td><code id="plotWeights_+3A_...">...</code></td>
<td>
<p>other parameters given to the <code>plot</code> function</p>
</td></tr>
</table>

<hr>
<h2 id='predict.svmmaj'>Out-of-Sample Prediction from Unseen Data.</h2><span id='topic+predict.svmmaj'></span>

<h3>Description</h3>

<p>This function predicts the predicted value (including intercept), given a
previous trained model which has been returned by
<code><a href="#topic+svmmaj">svmmaj</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'svmmaj'
predict(object, X.new, y = NULL, weights = NULL, show.plot = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.svmmaj_+3A_object">object</code></td>
<td>
<p>Model which has been trained beforehand using
<code><a href="#topic+svmmaj">svmmaj</a></code>.</p>
</td></tr>
<tr><td><code id="predict.svmmaj_+3A_x.new">X.new</code></td>
<td>
<p>Attribute matrix of the objects to be predicted, which has the
same number of attributes as the untransformed attribute matrix in
<code>model</code>.</p>
</td></tr>
<tr><td><code id="predict.svmmaj_+3A_y">y</code></td>
<td>
<p>The actual class labels (only if <code>show.plot==TRUE</code>).</p>
</td></tr>
<tr><td><code id="predict.svmmaj_+3A_weights">weights</code></td>
<td>
<p>The weight of observation as the relative importance of the
prediction error of the observation.</p>
</td></tr>
<tr><td><code id="predict.svmmaj_+3A_show.plot">show.plot</code></td>
<td>
<p>If <code>show.plot=TRUE</code>, it plots the density of the
predicted value for both class labels, if <code>y</code> is not specified, the
density of all objects will be plotted.</p>
</td></tr>
<tr><td><code id="predict.svmmaj_+3A_...">...</code></td>
<td>
<p>Arguments to be passed to methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The predicted value (including intercept) of class <code>q.svmmaj</code>,
with attributes: </p>
<table role = "presentation">
<tr><td><code>y</code></td>
<td>
<p>The observed class labels of each object.</p>
</td></tr>
<tr><td><code>yhat</code></td>
<td>
<p> he predicted class labels of each object.</p>
</td></tr> <tr><td><code>classes</code></td>
<td>
<p>The
class labels.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Hok San Yip, Patrick J.F. Groenen, Georgi Nalbantov
</p>


<h3>References</h3>

<p>P.J.F. Groenen, G. Nalbantov and J.C. Bioch (2008)
<em>SVM-Maj: a majorization approach to linear support vector machines with
different hinge errors.</em>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+svmmaj">svmmaj</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
attach(AusCredit)

## model training
model &lt;- svmmaj(X[1:400, ], y[1:400], hinge = "quadratic", lambda = 1)
## model prediction
q4 &lt;- predict(model, X[-(1:400), ], y[-(1:400)], show.plot = TRUE)
q4
</code></pre>

<hr>
<h2 id='predict.transDat'>Perform the transformation based on predefined settings</h2><span id='topic+predict.transDat'></span>

<h3>Description</h3>

<p>Given the input parameters, which are generated from
<code>transformdata</code>, it performs the same transformation
with the same settings to the given input
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'transDat'
predict(
  x,
  attrib = NULL,
  values = NULL,
  standardization = NULL,
  splineInterval = NULL,
  splineDegree = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.transDat_+3A_x">x</code></td>
<td>
<p>a (new) vector of numerics to be transformed</p>
</td></tr>
<tr><td><code id="predict.transDat_+3A_attrib">attrib</code></td>
<td>
<p>either a list of settings, or <code>NULL</code> in case
the attributes are given as separate input</p>
</td></tr>
<tr><td><code id="predict.transDat_+3A_values">values</code></td>
<td>
<p>a vector of levels in case <code>x</code> is a factor</p>
</td></tr>
<tr><td><code id="predict.transDat_+3A_standardization">standardization</code></td>
<td>
<p>the standardization rules from <code>normalize</code></p>
</td></tr>
<tr><td><code id="predict.transDat_+3A_splineinterval">splineInterval</code></td>
<td>
<p>the knots to be used for spline basis</p>
</td></tr>
<tr><td><code id="predict.transDat_+3A_splinedegree">splineDegree</code></td>
<td>
<p>the polynomial degree of the splines</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a transformed data based on the user defined settings
</p>

<hr>
<h2 id='print.q.svmmaj'>SVM-Maj Algorithm</h2><span id='topic+print.q.svmmaj'></span><span id='topic+svmmaj'></span><span id='topic+svmmaj.default'></span>

<h3>Description</h3>

<p>SVM-Maj is an algorithm to compute a support vector machine (SVM) solution.
In its most simple form, it aims at finding hyperplane that optimally
separates two given classes.  This objective is equivalent to finding a
linear combination of <code>k</code> predictor variables to predict the two
classes for <code>n</code> observations.  SVM-Maj minimizes the standard support
vector machine (SVM) loss function.  The algorithm uses three efficient
updates for three different situations: primal method which is efficient in
the case of <code>n &gt; k</code>, the decomposition method, used when the matrix of
predictor variables is not of full rank, and a dual method, that is
efficient when <code>n &lt; k</code>.  Apart from the standard absolute hinge error,
SVM-Maj can also handle the quadratic and the Huber hinge.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'q.svmmaj'
print(x, ...)

svmmaj(
  X,
  y,
  lambda = 1,
  weights.obs = 1,
  weights.var = 1,
  scale = c("interval", "zscore", "none"),
  spline.knots = 0,
  spline.degree = 1L,
  kernel = vanilladot,
  kernel.sigma = 1,
  kernel.scale = 1,
  kernel.degree = 1,
  kernel.offset = 1,
  hinge = c("absolute", "quadratic", "huber", "logitistic"),
  hinge.delta = 1e-08,
  options = setSVMoptions(),
  initial.point = NULL,
  verbose = FALSE,
  na.action = na.omit,
  ...
)

## Default S3 method:
svmmaj(
  X,
  y,
  lambda = 1,
  weights.obs = 1,
  weights.var = 1,
  scale = c("interval", "zscore", "none"),
  spline.knots = 0,
  spline.degree = 1L,
  kernel = vanilladot,
  kernel.sigma = 1,
  kernel.scale = 1,
  kernel.degree = 1,
  kernel.offset = 1,
  hinge = c("absolute", "quadratic", "huber", "logitistic"),
  hinge.delta = 1e-08,
  options = setSVMoptions(),
  initial.point = NULL,
  verbose = FALSE,
  na.action = na.omit,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.q.svmmaj_+3A_x">x</code></td>
<td>
<p>the <code>svmmaj</code> object as result of <code><a href="#topic+svmmaj">svmmaj</a></code></p>
</td></tr>
<tr><td><code id="print.q.svmmaj_+3A_...">...</code></td>
<td>
<p>Other arguments passed to methods.</p>
</td></tr>
<tr><td><code id="print.q.svmmaj_+3A_x">X</code></td>
<td>
<p>A data frame (or object coercible by
<code><a href="base.html#topic+as.data.frame">as.data.frame</a></code> to a data frame) consisting the attributes,
the class of each attribute can be either <code>numeric</code>, <code>logical</code> or
<code>factor</code>.</p>
</td></tr>
<tr><td><code id="print.q.svmmaj_+3A_y">y</code></td>
<td>
<p>A factor (or object coercible by <code><a href="base.html#topic+factor">factor</a></code> to a
factor) consisting the class labels.</p>
</td></tr>
<tr><td><code id="print.q.svmmaj_+3A_lambda">lambda</code></td>
<td>
<p>Regularization parameter of the penalty term.</p>
</td></tr>
<tr><td><code id="print.q.svmmaj_+3A_weights.obs">weights.obs</code></td>
<td>
<p>a vector of length <code>n</code> with the nonnegative weight
for the residual of each object (with length <code>n</code>).  If the length is
<code>2</code>, then it specifies the weight per class.</p>
</td></tr>
<tr><td><code id="print.q.svmmaj_+3A_weights.var">weights.var</code></td>
<td>
<p>a vector of length <code>k</code> with weights for each
attribute.</p>
</td></tr>
<tr><td><code id="print.q.svmmaj_+3A_scale">scale</code></td>
<td>
<p>Specifies whether the columns of attribute matrix <code>X</code>
needs to be standardized into zscores or to the interval <code>[0 1]</code>.
Possible values are: <code>none</code>, <code>zscore</code> and <code>interval</code>.
Moreover, the standardization parameters can be given instead.</p>
</td></tr>
<tr><td><code id="print.q.svmmaj_+3A_spline.knots">spline.knots</code></td>
<td>
<p>equals the number of internal knots of the spline basis.
When the number of knots exceeds the number of (categorical) values of
an explanatory variable, the duplicate knots will be removed using
<code><a href="base.html#topic+unique">unique</a></code>. For no splines, use <code>spline.knots = 0</code>.</p>
</td></tr>
<tr><td><code id="print.q.svmmaj_+3A_spline.degree">spline.degree</code></td>
<td>
<p>equals the polynomial degree of the splines,
for no splines:<code>spline.degree = 1</code>.</p>
</td></tr>
<tr><td><code id="print.q.svmmaj_+3A_kernel">kernel</code></td>
<td>
<p>Specifies which kernel function to be used (see
<code><a href="kernlab.html#topic+dots">dots</a></code> of package <span class="pkg">kernlab</span>).
Default kernel is the linear kernel.</p>
</td></tr>
<tr><td><code id="print.q.svmmaj_+3A_kernel.sigma">kernel.sigma</code></td>
<td>
<p>additional parameters used for the kernel function
(see <code><a href="kernlab.html#topic+dots">dots</a></code>)</p>
</td></tr>
<tr><td><code id="print.q.svmmaj_+3A_kernel.scale">kernel.scale</code></td>
<td>
<p>additional parameters used for the kernel function
(see <code><a href="kernlab.html#topic+dots">dots</a></code>)</p>
</td></tr>
<tr><td><code id="print.q.svmmaj_+3A_kernel.degree">kernel.degree</code></td>
<td>
<p>additional parameters used for the kernel function
(see <code><a href="kernlab.html#topic+dots">dots</a></code>)</p>
</td></tr>
<tr><td><code id="print.q.svmmaj_+3A_kernel.offset">kernel.offset</code></td>
<td>
<p>additional parameters used for the kernel function
(see <code><a href="kernlab.html#topic+dots">dots</a></code>)</p>
</td></tr>
<tr><td><code id="print.q.svmmaj_+3A_hinge">hinge</code></td>
<td>
<p>Specifies with hinge function from
<code><a href="#topic+getHinge">getHinge</a></code> should be used.</p>
</td></tr>
<tr><td><code id="print.q.svmmaj_+3A_hinge.delta">hinge.delta</code></td>
<td>
<p>The parameter of the huber hinge
(only if <code>hinge = 'huber'</code>).</p>
</td></tr>
<tr><td><code id="print.q.svmmaj_+3A_options">options</code></td>
<td>
<p>additional settings used in the <code>svmmaj</code> algorithm</p>
</td></tr>
<tr><td><code id="print.q.svmmaj_+3A_initial.point">initial.point</code></td>
<td>
<p>Initial solution.</p>
</td></tr>
<tr><td><code id="print.q.svmmaj_+3A_verbose">verbose</code></td>
<td>
<p><code>TRUE</code> shows the progress of the
iteration.</p>
</td></tr>
<tr><td><code id="print.q.svmmaj_+3A_na.action">na.action</code></td>
<td>
<p>Generic function for handling NA values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following settings can be added as element in the <code>options</code>
parameter:
<code>decomposition</code> Specifies whether the QR decomposition should be used
for efficient updates. Possible values are <code>'svd'</code> for Singular value
decomposition (Eigenvalue decomposition for non-linear kernel) or
<code>'chol'</code> for Cholesky (or QR decomposition in case of linear kernel)
</p>
<p><code>convergence</code> Specifies the convergence criterion of the algorithm.
Default is <code>1e-08</code>.
<code>increase.step</code> The iteration number from which relaxed update will be
used.
<code>eps</code> The relaxation of the majorization function for absolute hinge:
<code>.25 * eps^-1</code> is the maximum steepness of the majorization function.
</p>
<p><code>check.positive</code> Specifies whether a check has to be made for positive
input values.
<code>max.iter</code> maximum number of iterations to use
</p>


<h3>Value</h3>

<p>Returns a svmmaj-class object,
of which the methods <code>plot</code>,
<code>plotWeights</code>, <code>summary</code> and <code>predict</code> can be applied.
(see also <code><a href="#topic+predict.svmmaj">predict.svmmaj</a></code> and
<code><a href="#topic+print.svmmaj">print.svmmaj</a></code>)
</p>


<h3>Author(s)</h3>

<p>Hok San Yip, Patrick J.F. Groenen, Georgi Nalbantov
</p>


<h3>References</h3>

<p>P.J.F. Groenen, G. Nalbantov and J.C. Bioch (2008)
<em>SVM-Maj: a majorization approach to linear support vector machines
with different hinge errors.</em>
</p>


<h3>See Also</h3>

<p><code><a href="kernlab.html#topic+dots">dots</a></code> for the computations of the kernels.
<code><a href="#topic+predict.svmmaj">predict.svmmaj</a></code>
<code><a href="#topic+normalize">normalize</a></code>
<code><a href="#topic+isb">isb</a></code>
<code><a href="#topic+getHinge">getHinge</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## using default settings
model1 &lt;- svmmaj(
  diabetes$X, diabetes$y,
  hinge = "quadratic", lambda = 1
)
summary(model1)

weights.obs &lt;- list(positive = 2, negative = 1)
## using radial basis kernel
library(kernlab)
model2 &lt;- svmmaj(
  diabetes$X, diabetes$y,
  hinge = "quadratic", lambda = 1,
  weights.obs = weights.obs, scale = "interval",
  kernel = rbfdot,
  kernel.sigma = 1
)
summary(model2)
## I-spline basis
library(ggplot2)
model3 &lt;- svmmaj(
  diabetes$X, diabetes$y,
  weight.obs = weight.obs,
  spline.knots = 3, spline.degree = 2
)
plotWeights(model3, plotdim = c(2, 4))
</code></pre>

<hr>
<h2 id='print.svmmaj'>Print Svmmaj class</h2><span id='topic+print.svmmaj'></span><span id='topic+summary.svmmaj'></span><span id='topic+print.summary.svmmaj'></span><span id='topic+plot.svmmaj'></span>

<h3>Description</h3>

<p>Trained SVM model as output from <code><a href="#topic+svmmaj">svmmaj</a></code>.
The returning object consist of the following values:
</p>

<dl>
<dt>call</dt><dd><p> The function specifications which has been called.</p>
</dd>
<dt>lambda</dt><dd><p> The regularization parameter of the penalty
term which has been used.</p>
</dd>
<dt>loss</dt><dd><p> The corresponding loss function
value of the final solution.</p>
</dd>
<dt>iteration</dt><dd><p> Number of iterations needed
to evaluate the algorithm.</p>
</dd>
<dt>X</dt><dd><p> The attribute matrix of <code>dim(X) = c(n,k)</code>.</p>
</dd>
<dt>y</dt><dd><p> The vector of length <code>n</code> with the actual class labels.
These labels can be numeric <code>[0 1]</code> or two strings.</p>
</dd>
<dt>classes</dt><dd><p> A vector of length <code>n</code> with the predicted
class labels of each object, derived from q.tilde</p>
</dd>
<dt>Xtrans</dt><dd><p> The attribute matrix <code>X</code> after standardization and
(if specified) spline transformation.</p>
</dd>
<dt>norm.param</dt><dd><p> The applied normalization parameters
(see <code><a href="#topic+normalize">normalize</a></code>).</p>
</dd>
<dt>splineInterval</dt><dd><p> The spline knots which has been used
(see <code><a href="#topic+isb">isb</a></code>).</p>
</dd>
<dt>splineLength</dt><dd><p>Denotes the number of spline basis of
each explanatory variable in <code>X</code>.</p>
</dd>
<dt>method</dt><dd><p>The decomposition matrices used in estimating the model.</p>
</dd>
<dt>hinge</dt><dd><p> The hinge function which has been used
(see <code><a href="#topic+getHinge">getHinge</a></code>).</p>
</dd>
<dt>beta </dt><dd><p>If identified, the beta parameters for the linear combination
(only available for linear kernel).</p>
</dd>
<dt>q</dt><dd><p> A vector of length <code>n</code> with predicted values of
each object including the intercept.</p>
</dd>
<dt>nSV</dt><dd><p> Number of support vectors.</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'svmmaj'
print(x, ...)

## S3 method for class 'svmmaj'
summary(object, ...)

## S3 method for class 'summary.svmmaj'
print(x, ...)

## S3 method for class 'svmmaj'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.svmmaj_+3A_x">x</code></td>
<td>
<p>the <code>svmmaj</code> object as result of <code><a href="#topic+svmmaj">svmmaj</a></code></p>
</td></tr>
<tr><td><code id="print.svmmaj_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="print.svmmaj_+3A_object">object</code></td>
<td>
<p>the <code>svmmaj</code> object as result of <code><a href="#topic+svmmaj">svmmaj</a></code></p>
</td></tr>
</table>

<hr>
<h2 id='print.svmmajcrossval'>Print SVMMaj cross validation results</h2><span id='topic+print.svmmajcrossval'></span><span id='topic+summary.svmmajcrossval'></span>

<h3>Description</h3>

<p>Prints the result from the cross validation procedure in
<code><a href="#topic+svmmajcrossval">svmmajcrossval</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'svmmajcrossval'
print(x, ...)

## S3 method for class 'svmmajcrossval'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.svmmajcrossval_+3A_x">x</code></td>
<td>
<p>the cross-validation output from <code><a href="#topic+svmmajcrossval">svmmajcrossval</a></code></p>
</td></tr>
<tr><td><code id="print.svmmajcrossval_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
<tr><td><code id="print.svmmajcrossval_+3A_object">object</code></td>
<td>
<p>the output object from <code>svmmajcrossval</code></p>
</td></tr>
</table>

<hr>
<h2 id='roccurve'>Plot the ROC curve of the predicted values</h2><span id='topic+roccurve'></span>

<h3>Description</h3>

<p>Given the predicted values <code>q</code> and its corresponding
observed classes <code>y</code>, it shows its separation performances
by showing the roc-curve.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>roccurve(q, y = attr(q, "y"), class = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="roccurve_+3A_q">q</code></td>
<td>
<p>the predicted values</p>
</td></tr>
<tr><td><code id="roccurve_+3A_y">y</code></td>
<td>
<p>a list of the actual classes of <code>q</code></p>
</td></tr>
<tr><td><code id="roccurve_+3A_class">class</code></td>
<td>
<p>the base class to show the roc-curve</p>
</td></tr>
<tr><td><code id="roccurve_+3A_...">...</code></td>
<td>
<p>additional parameters given as input to the <code>plot</code> function</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- svmmaj(diabetes$X, diabetes$y)
roccurve(model$q)
</code></pre>

<hr>
<h2 id='supermarket1996'>Supermarket data 1996</h2><span id='topic+supermarket1996'></span>

<h3>Description</h3>

<p>This
</p>


<h3>Format</h3>

<p>This dataframe contains the following columns
</p>

<dl>
<dt>STORE</dt><dd><p>Identifier of the store</p>
</dd>
<dt>CITY</dt><dd><p>The city of the store</p>
</dd>
<dt>ZIP</dt><dd><p>The zip code of the store</p>
</dd>
<dt>GROCERY_sum</dt><dd></dd>
<dt>GROCCOUP_sum</dt><dd></dd>
<dt>AGE9</dt><dd></dd>
<dt>AGE60</dt><dd></dd>
<dt>ETHNIC</dt><dd></dd>
<dt>EDUC</dt><dd></dd>
<dt>NOCAR</dt><dd></dd>
<dt>INCOME</dt><dd></dd>
<dt>INCSIGMA</dt><dd></dd>
<dt>HSIZEAVG</dt><dd></dd>
<dt>HSIZE1</dt><dd></dd>
<dt>HSIZE2</dt><dd></dd>
<dt>HSIZE34</dt><dd></dd>
<dt>HSIZE567</dt><dd></dd>
<dt>HH3PLUS</dt><dd></dd>
<dt>HH4PLUS</dt><dd></dd>
<dt>HHSINGLE</dt><dd></dd>
<dt>HHLARGE</dt><dd></dd>
<dt>WORKWOM</dt><dd></dd>
<dt>SINHOUSE</dt><dd></dd>
<dt>DENSITY</dt><dd></dd>
<dt>HVAL150</dt><dd></dd>
<dt>HVAL200</dt><dd></dd>
<dt>HVALMEAN</dt><dd></dd>
<dt>SINGLE</dt><dd></dd>
<dt>RETIRED</dt><dd></dd>
<dt>UNEMP</dt><dd></dd>
<dt>WRKCH5</dt><dd></dd>
<dt>WRKCH17</dt><dd></dd>
<dt>NWRKCH5</dt><dd></dd>
<dt>NWRKCH17</dt><dd></dd>
<dt>WRKCH</dt><dd></dd>
<dt>NWRKCH</dt><dd></dd>
<dt>WRKWCH</dt><dd></dd>
<dt>WRKWNCH</dt><dd></dd>
<dt>TELEPHN</dt><dd></dd>
<dt>MORTGAGE</dt><dd></dd>
<dt>NWHITE</dt><dd></dd>
<dt>POVERTY</dt><dd></dd>
<dt>SHPCONS</dt><dd></dd>
<dt>SHPHURR</dt><dd></dd>
<dt>SHPAVID</dt><dd></dd>
<dt>SHPKSTR</dt><dd></dd>
<dt>SHPUNFT</dt><dd></dd>
<dt>SHPBIRD</dt><dd></dd>
<dt>SHOPINDX</dt><dd></dd>
<dt>SHPINDX</dt><dd></dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>head(supermarket1996, 3)
</code></pre>

<hr>
<h2 id='svmmajcrossval'>k-fold Cross-Validation of SVM-Maj</h2><span id='topic+svmmajcrossval'></span>

<h3>Description</h3>

<p>This function performs a gridsearch of k-fold cross-validations using SVM-Maj
and returns the combination of input values which has the best forecasting
performance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>svmmajcrossval(
  X,
  y,
  search.grid = list(lambda = 2^seq(5, -5, length.out = 19)),
  ...,
  convergence = 1e-04,
  weights.obs = 1,
  check.positive = TRUE,
  mc.cores = getOption("mc.cores"),
  options = NULL,
  verbose = FALSE,
  ngroup = 5,
  groups = NULL,
  return.model = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="svmmajcrossval_+3A_x">X</code></td>
<td>
<p>A data frame (or object coercible by
<code><a href="base.html#topic+as.data.frame">as.data.frame</a></code> to a data frame) consisting the attributes.</p>
</td></tr>
<tr><td><code id="svmmajcrossval_+3A_y">y</code></td>
<td>
<p>A factor (or object coercible by <code><a href="base.html#topic+factor">factor</a></code> to a
factor) consisting the class labels.</p>
</td></tr>
<tr><td><code id="svmmajcrossval_+3A_search.grid">search.grid</code></td>
<td>
<p>A list with for each factor the range of values to search
for.</p>
</td></tr>
<tr><td><code id="svmmajcrossval_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed through <code>svmmaj</code>.</p>
</td></tr>
<tr><td><code id="svmmajcrossval_+3A_convergence">convergence</code></td>
<td>
<p>Specifies the convergence criterion for <code>svmmaj</code>.
Default is <code>1e-08</code>.</p>
</td></tr>
<tr><td><code id="svmmajcrossval_+3A_weights.obs">weights.obs</code></td>
<td>
<p>Weights for the classes.</p>
</td></tr>
<tr><td><code id="svmmajcrossval_+3A_check.positive">check.positive</code></td>
<td>
<p>Specifies whether a check should be performed for
positive <code>lambda</code> and <code>weights.obs</code>.</p>
</td></tr>
<tr><td><code id="svmmajcrossval_+3A_mc.cores">mc.cores</code></td>
<td>
<p>the number of cores to be used (for parallel computing)</p>
</td></tr>
<tr><td><code id="svmmajcrossval_+3A_options">options</code></td>
<td>
<p>additional settings used in the <code>svmmaj</code> algorithm</p>
</td></tr>
<tr><td><code id="svmmajcrossval_+3A_verbose">verbose</code></td>
<td>
<p><code>=TRUE</code> shows the progress of the
cross-validation.</p>
</td></tr>
<tr><td><code id="svmmajcrossval_+3A_ngroup">ngroup</code></td>
<td>
<p>The number of groups to be divided into.</p>
</td></tr>
<tr><td><code id="svmmajcrossval_+3A_groups">groups</code></td>
<td>
<p>A predetermined group division for performing the cross
validation.</p>
</td></tr>
<tr><td><code id="svmmajcrossval_+3A_return.model">return.model</code></td>
<td>
<p><code>=TRUE</code> estimates the model with the optimal
parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>loss.opt</code></td>
<td>
<p> The minimum (weighted) missclassification rate
found in out-of-sample training along the search grid. </p>
</td></tr> <tr><td><code>param.opt</code></td>
<td>

<p>The level of the factors which gives the minimum loss term value.</p>
</td></tr>
<tr><td><code>loss.grp</code></td>
<td>
<p>A list of missclassification rates per hold-out sample</p>
</td></tr>
<tr><td><code>groups</code></td>
<td>
<p>A vector defining the cross-validation groups which has been
used.</p>
</td></tr>
<tr><td><code>qhat</code></td>
<td>
<p>The estimated out-of-sample predicted values in the
cross-validation.</p>
</td></tr>
<tr><td><code>qhat.in</code></td>
<td>
<p>The trained predicted values</p>
</td></tr>
<tr><td><code>param.grid</code></td>
<td>
<p> The matrix of all gridpoints which has been performed
during the cross-validation, with its corresponding weighted out-of-sample
missclassification rate.</p>
</td></tr> <tr><td><code>model</code></td>
<td>
<p> The <code>svmmaj</code>-object with the
estimated model using the optimal parameters found in the cross-validation.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Hok San Yip, Patrick J.F. Groenen, Georgi Nalbantov
</p>


<h3>References</h3>

<p>P.J.F. Groenen, G. Nalbantov and J.C. Bioch (2008)
<em>SVM-Maj: a majorization approach to linear support vector machines
with different hinge errors.</em>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+svmmaj">svmmaj</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
Xt &lt;- diabetes$X
yt &lt;- diabetes$y

## performing gridsearch with k-fold cross-validation
results &lt;- svmmajcrossval(
  Xt, yt,
  scale = "interval",
  mc.cores = 2,
  ngroup = 5,
  return.model = TRUE
)

summary(results$model)
results
plot(results)
plot(results, "profile")
</code></pre>

<hr>
<h2 id='transformdata'>Transform the data with normalization and/or spline basis</h2><span id='topic+transformdata'></span>

<h3>Description</h3>

<p>Performs subsequently a normalization of the input data and
creating spline basis based on the user defined input
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transformdata(
  x,
  standardize = c("interval", "zscore", "none"),
  spline.knots = 0,
  spline.degree = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="transformdata_+3A_x">x</code></td>
<td>
<p>a single column of values as input for the data
transformation</p>
</td></tr>
<tr><td><code id="transformdata_+3A_standardize">standardize</code></td>
<td>
<p>Either a string value denoting a predefined scaling, or a
list with values <code>a</code> and <code>b</code> corresponding with the numeric
centering and scaling, that is, using the function
<code>x * standardize$b - standardize$a</code>.</p>
</td></tr>
<tr><td><code id="transformdata_+3A_spline.knots">spline.knots</code></td>
<td>
<p>Number of inner knots to use. <code>isb</code> will equally
distribute the knots over the value range using quantiles.
<code>spline.knots</code> will only be used if <code>knots</code> is not given.</p>
</td></tr>
<tr><td><code id="transformdata_+3A_spline.degree">spline.degree</code></td>
<td>
<p>The polynomial degree of the spline basis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>transformed data in spline basis or (in case of no spline)
a normalized vector
</p>

<hr>
<h2 id='voting'>Congressional Voting Records Data Set</h2><span id='topic+voting'></span><span id='topic+voting.tr'></span><span id='topic+voting.te'></span>

<h3>Description</h3>

<p>1984 United Stated Congressional Voting Records; Classify as Republican or
Democrat.
</p>


<h3>Format</h3>

<p><code>X</code> is a data frame with 434 congress members and 16 attributes: 16 key
votes identified by the Congressional Quarterly Almanac (CQA). All
attributes are binary values, with <code>1=</code> yes and <code>0=</code> no.
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>X1</code> </td><td style="text-align: left;"> handicapped-infants </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>X2</code> </td><td style="text-align: left;"> water-project-cost-sharing </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>X3</code> </td><td style="text-align: left;"> adoption-of-the-budget-resolution </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>X4</code> </td><td style="text-align: left;"> physician-fee-freeze </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>X5</code> </td><td style="text-align: left;"> el-salvador-aid </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>X6</code> </td><td style="text-align: left;"> religious-groups-in-schools </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>X7</code> </td><td style="text-align: left;"> anti-satellite-test-ban </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>X8</code> </td><td style="text-align: left;"> aid-to-nicaraguan-contras </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>X9</code> </td><td style="text-align: left;"> mx-missile </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>X10</code> </td><td style="text-align: left;"> immigration </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>X11</code> </td><td style="text-align: left;"> synfuels-corporation-cutback </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>X12</code> </td><td style="text-align: left;"> education-spending </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>X13</code> </td><td style="text-align: left;"> superfund-right-to-sue </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>X14</code> </td><td style="text-align: left;"> crime </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>X15</code> </td><td style="text-align: left;"> duty-free-exports </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>X16</code> </td><td style="text-align: left;"> export-administration-act-south-africa </td>
</tr>
<tr>
 <td style="text-align: left;">
 </td>
</tr>

</table>

<p><code>y</code> consists factors which denotes whether the congress member is a
<code>Republican</code> or a <code>Democrat</code>.
</p>
<p>The training set <code>voting.tr</code> contains a randomly selected set of 300
subjects, and <code>voting.te</code> contains the remaining 134 subjects.
<code>voting</code> contains all 434 objects.
</p>


<h3>Details</h3>

<p>This data set includes votes for each of the U.S. House of Representatives
Congressmen on the 16 key votes identified by the CQA. The CQA lists nine
different types of votes: voted for, paired for, and announced for (these
three simplified to yea), voted against, paired against, and announced
against (these three simplified to nay), voted present, voted present to
avoid conflict of interest, and did not vote or otherwise make a position
known (these three simplified to an unknown disposition).
</p>


<h3>Source</h3>

<p>Chih-Chung Chang and Chih-Jen Lin, LIBSVM : a library for support
vector machines, 2001. Software available at
<a href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/">https://www.csie.ntu.edu.tw/~cjlin/libsvm/</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
attach(voting)
summary(X)
summary(y)

</code></pre>

<hr>
<h2 id='X.svmmaj'>Returns transformed attributes</h2><span id='topic+X.svmmaj'></span>

<h3>Description</h3>

<p>For efficiency use in svmmajcrossval
</p>


<h3>Usage</h3>

<pre><code class='language-R'>X.svmmaj(object, X.new, weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="X.svmmaj_+3A_object">object</code></td>
<td>
<p>Model which has been trained beforehand using
<code><a href="#topic+svmmaj">svmmaj</a></code>.</p>
</td></tr>
<tr><td><code id="X.svmmaj_+3A_x.new">X.new</code></td>
<td>
<p>Attribute matrix of the objects to be predicted, which has the
same number of attributes as the untransformed attribute matrix in
<code>model</code>.</p>
</td></tr>
<tr><td><code id="X.svmmaj_+3A_weights">weights</code></td>
<td>
<p>The weight of observation as the relative importance of the
prediction error of the observation.</p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
