<!DOCTYPE html><html><head><title>Help for package hqreg</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {hqreg}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cv.hqreg'><p>Cross-validation for hqreg</p></a></li>
<li><a href='#hqreg'><p>Fit a robust regression model with Huber or quantile loss penalized by lasso or elasti-net</p></a></li>
<li><a href='#hqreg_raw'><p>Fit a robust regression model on raw data with Huber or quantile loss penalized by lasso or elasti-net</p></a></li>
<li><a href='#hqreg-package'><p>Regularization Paths for Lasso or Elastic-net Penalized Huber Loss Regression and Quantile Regression</p></a></li>
<li><a href='#plot.cv.hqreg'><p>Plot the cross-validation curve for a &quot;cv.hqreg&quot; object</p></a></li>
<li><a href='#plot.hqreg'><p>Plot coefficients from a &quot;hqreg&quot; object</p></a></li>
<li><a href='#predict.cv.hqreg'><p>Model predictions based on &quot;cv.hqreg&quot; object.</p></a></li>
<li><a href='#predict.hqreg'><p>Model predictions based on &quot;hqreg&quot; object.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Regularization Paths for Lasso or Elastic-Net Penalized Huber
Loss Regression and Quantile Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>1.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2017-2-15</td>
</tr>
<tr>
<td>Author:</td>
<td>Congrui Yi</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Congrui Yi &lt;congrui-yi@uiowa.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Efficient algorithms for fitting regularization paths for lasso or elastic-net penalized regression models with Huber loss, quantile loss or squared loss.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://arxiv.org/abs/1509.02957">http://arxiv.org/abs/1509.02957</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>parallel</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-02-16 00:06:26 UTC; cyi</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-02-16 07:13:26</td>
</tr>
</table>
<hr>
<h2 id='cv.hqreg'>Cross-validation for hqreg</h2><span id='topic+cv.hqreg'></span>

<h3>Description</h3>

<p>Perform k-fold cross validation for elastic-net penalized Huber loss regression 
and quantile regression over a sequence of lambda values and find an optimal lambda.</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.hqreg(X, y, ..., FUN = c("hqreg", "hqreg_raw"), ncores = 1, nfolds = 10, fold.id, 
         type.measure = c("deviance", "mse", "mae"), seed)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.hqreg_+3A_x">X</code></td>
<td>
<p>The input matrix.</p>
</td></tr>
<tr><td><code id="cv.hqreg_+3A_y">y</code></td>
<td>
<p>The response vector.</p>
</td></tr>
<tr><td><code id="cv.hqreg_+3A_...">...</code></td>
<td>
<p>Additional arguments to <code>FUN</code>.</p>
</td></tr>
<tr><td><code id="cv.hqreg_+3A_fun">FUN</code></td>
<td>
<p>Model fitting function. The default is &quot;hqreg&quot; which preprocesses the data internally. 
The other option is &quot;hqreg_raw&quot; which uses the raw data as is.</p>
</td></tr>
<tr><td><code id="cv.hqreg_+3A_ncores">ncores</code></td>
<td>
<p><code>cv.hqreg</code> can be run in parallel across a
cluster using the <code>parallel</code> package. If <code>ncores &gt; 1</code>,a cluster is 
created to run <code>cv.hqreg</code> in parallel. The code is run sequentially if 
<code>ncores = 1</code> (the default). A message is printed if <code>ncores</code> is larger than the
total number of available cores, and all available cores will be used.</p>
</td></tr>
<tr><td><code id="cv.hqreg_+3A_nfolds">nfolds</code></td>
<td>
<p>The number of cross-validation folds. Default is 10.</p>
</td></tr>
<tr><td><code id="cv.hqreg_+3A_fold.id">fold.id</code></td>
<td>
<p>(Optional) a vector of values between 1 and nfold indicating 
which fold each observation belongs to. If supplied, nfolds can be missing. 
By default the observations are randomly assigned by <code>cv.hqreg</code>. </p>
</td></tr>
<tr><td><code id="cv.hqreg_+3A_type.measure">type.measure</code></td>
<td>
<p>The default is &quot;deviance&quot;, which uses the chosen loss function of the model. 
Other options include &quot;mse&quot; for mean squared error and &quot;mae&quot; for mean absolute error.</p>
</td></tr>
<tr><td><code id="cv.hqreg_+3A_seed">seed</code></td>
<td>
<p>(Optional) Seed for the random number generator in order to obtain reproducible results.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function randomly partitions the data in <code>nfolds</code>. It calls <code>hqreg</code> 
<code>nfolds</code>+1 times, the first to obtain the <code>lambda</code> sequence, and the remainder 
to fit with each of the folds left out once for validation. The cross-validation error is 
the average of validation errors for the <code>nfolds</code> fits.
</p>
<p>Note that <code>cv.hqreg</code> does not search for values of <code>alpha</code>, <code>gamma</code> or <code>tau</code>. 
Specific values should be supplied, otherwise the default ones for <code>hqreg</code> are used. 
If users would like to cross-validate <code>alpha</code>, <code>gamma</code> or <code>tau</code> as well, 
they should call <code>cv.hqreg</code> for each combination of these parameters and use the same 
&quot;seed&quot; in these calls so that the partitioning remains the same.
</p>


<h3>Value</h3>

<p>The function returns an object of S3 class <code>"cv.hqreg"</code>, which is a list containing:
</p>
<table>
<tr><td><code>cve</code></td>
<td>
<p>The error for each value of <code>lambda</code>, averaged across the cross-validation folds.</p>
</td></tr>
<tr><td><code>cvse</code></td>
<td>
<p>The estimated standard error associated with each value of <code>cve</code>.</p>
</td></tr>
<tr><td><code>type.measure</code></td>
<td>
<p>Same as above.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The values of <code>lambda</code> used in the cross-validation fits.</p>
</td></tr>
<tr><td><code>fit</code></td>
<td>
<p>The fitted <code>hqreg</code> object for the whole data.</p>
</td></tr>
<tr><td><code>lambda.1se</code></td>
<td>
<p>The largest <code>lambda</code> such that the error is within 1 standard 
error of the minimum.</p>
</td></tr>
<tr><td><code>lambda.min</code></td>
<td>
<p>The value of <code>lambda</code> with the minimum cross-validation error.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Congrui Yi &lt;congrui-yi@uiowa.edu&gt;</p>


<h3>References</h3>

<p>Yi, C. and Huang, J. (2016) 
<em>Semismooth Newton Coordinate Descent Algorithm for 
Elastic-Net Penalized Huber Loss Regression and Quantile Regression</em>,
<a href="https://arxiv.org/abs/1509.02957">https://arxiv.org/abs/1509.02957</a> <br />
<em>Journal of Computational and Graphical Statistics, accepted in Nov 2016</em> <br />
<a href="http://www.tandfonline.com/doi/full/10.1080/10618600.2016.1256816">http://www.tandfonline.com/doi/full/10.1080/10618600.2016.1256816</a></p>


<h3>See Also</h3>

<p><code>hqreg</code>, <code>plot.cv.hqreg</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>X = matrix(rnorm(1000*100), 1000, 100)
beta = rnorm(10)
eps = 4*rnorm(1000)
y = drop(X[,1:10] %*% beta + eps)
cv = cv.hqreg(X, y, seed = 123)
plot(cv)

cv_raw = cv.hqreg(X, y, FUN = "hqreg_raw", seed = 321)
predict(cv_raw, X[1:5,])

# parallel cross validation
## Not run: 
cv_parallel = cv.hqreg(X, y, ncores = 5)
plot(cv_parallel)

## End(Not run)
</code></pre>

<hr>
<h2 id='hqreg'>Fit a robust regression model with Huber or quantile loss penalized by lasso or elasti-net</h2><span id='topic+hqreg'></span>

<h3>Description</h3>

<p>Fit solution paths for Huber loss regression or quantile regression penalized 
by lasso or elastic-net over a grid of values for the regularization parameter lambda.</p>


<h3>Usage</h3>

<pre><code class='language-R'>hqreg(X, y, method = c("huber", "quantile", "ls"),
    gamma = IQR(y)/10, tau = 0.5, alpha = 1, nlambda = 100, lambda.min = 0.05, lambda, 
    preprocess = c("standardize", "rescale"), screen = c("ASR", "SR", "none"), 
    max.iter = 10000, eps = 1e-7, dfmax = ncol(X)+1, penalty.factor = rep(1, ncol(X)), 
    message = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hqreg_+3A_x">X</code></td>
<td>
<p>Input matrix.</p>
</td></tr>
<tr><td><code id="hqreg_+3A_y">y</code></td>
<td>
<p>Response vector.</p>
</td></tr>
<tr><td><code id="hqreg_+3A_method">method</code></td>
<td>
<p>The loss function to be used in the model. Either &quot;huber&quot; (default), 
&quot;quantile&quot;, or &quot;ls&quot; for least squares (see <code>Details</code>).</p>
</td></tr>
<tr><td><code id="hqreg_+3A_gamma">gamma</code></td>
<td>
<p>The tuning parameter of Huber loss, with no effect for the other loss 
functions. Huber loss is quadratic for absolute values less than gamma and linear for those 
greater than gamma. The default value is IQR(y)/10.</p>
</td></tr>
<tr><td><code id="hqreg_+3A_tau">tau</code></td>
<td>
<p>The tuning parameter of the quantile loss, with no effect for the other loss 
functions. It represents the conditional quantile of the response to be estimated, so 
must be a number between 0 and 1. It includes the absolute loss when tau = 0.5 (default).</p>
</td></tr>
<tr><td><code id="hqreg_+3A_alpha">alpha</code></td>
<td>
<p>The elastic-net mixing parameter that controls the relative contribution 
from the lasso and the ridge penalty. It must be a number between 0 and 1. <code>alpha=1</code> 
is the lasso penalty and <code>alpha=0</code> the ridge penalty.</p>
</td></tr>
<tr><td><code id="hqreg_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of lambda values.  Default is 100.</p>
</td></tr>
<tr><td><code id="hqreg_+3A_lambda.min">lambda.min</code></td>
<td>
<p>The smallest value for lambda, as a fraction of lambda.max, the data 
derived entry value. Default is 0.05.</p>
</td></tr>
<tr><td><code id="hqreg_+3A_lambda">lambda</code></td>
<td>
<p>A user-specified sequence of lambda values. Typical usage is to leave 
blank and have the program automatically compute a <code>lambda</code> sequence based on 
<code>nlambda</code> and <code>lambda.min</code>. Specifying <code>lambda</code> overrides this. This 
argument should be used with care and supplied with a decreasing sequence instead of 
a single value. To get coefficients for a single <code>lambda</code>, use <code>coef</code> or 
<code>predict</code> instead after fitting the solution path with <code>hqreg</code> or performing 
k-fold CV with <code>cv.hqreg</code>.</p>
</td></tr>
<tr><td><code id="hqreg_+3A_preprocess">preprocess</code></td>
<td>
<p>Preprocessing technique to be applied to the input. Either 
&quot;standardize&quot; (default) or &quot;rescale&quot;(see <code>Details</code>). The coefficients 
are always returned on the original scale.</p>
</td></tr>
<tr><td><code id="hqreg_+3A_screen">screen</code></td>
<td>
<p>Screening rule to be applied at each <code>lambda</code> that discards variables 
for speed. Either &quot;ASR&quot; (default), &quot;SR&quot; or &quot;none&quot;. &quot;SR&quot; stands for the strong rule, 
and &quot;ASR&quot; for the adaptive strong rule. Using &quot;ASR&quot; typically requires fewer iterations 
to converge than &quot;SR&quot;, but the computing time are generally close. Note that the option 
&quot;none&quot; is used mainly for debugging, which may lead to much longer computing time.</p>
</td></tr>
<tr><td><code id="hqreg_+3A_max.iter">max.iter</code></td>
<td>
<p>Maximum number of iterations. Default is 10000.</p>
</td></tr>
<tr><td><code id="hqreg_+3A_eps">eps</code></td>
<td>
<p>Convergence threshold. The algorithms continue until the maximum change in the
objective after any coefficient update is less than <code>eps</code> times the null deviance. 
Default is <code>1E-7</code>.</p>
</td></tr>
<tr><td><code id="hqreg_+3A_dfmax">dfmax</code></td>
<td>
<p>Upper bound for the number of nonzero coefficients. The algorithm exits and 
returns a partial path if <code>dfmax</code> is reached. Useful for very large dimensions.</p>
</td></tr>
<tr><td><code id="hqreg_+3A_penalty.factor">penalty.factor</code></td>
<td>
<p>A numeric vector of length equal to the number of variables. Each 
component multiplies <code>lambda</code> to allow differential penalization. Can be 0 for 
some variables, in which case the variable is always in the model without penalization. 
Default is 1 for all variables.</p>
</td></tr>
<tr><td><code id="hqreg_+3A_message">message</code></td>
<td>
<p>If set to TRUE,  hqreg will inform the user of its progress. This argument 
is kept for debugging. Default is FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sequence of models indexed by the regularization parameter <code>lambda</code> is fit 
using a semismooth Newton coordinate descent algorithm. The objective function is defined 
to be </p>
<p style="text-align: center;"><code class="reqn">\frac{1}{n} \sum loss_i + \lambda\textrm{penalty}.</code>
</p>

<p>For <code>method = "huber"</code>, 
</p>
<p style="text-align: center;"><code class="reqn">loss(t) = \frac{t^2}{2\gamma} I(|t|\le \gamma) + (|t| - \frac{\gamma}{2};) I(|t|&gt;
  \gamma)</code>
</p>

<p>for <code>method = "quantile"</code>, </p>
<p style="text-align: center;"><code class="reqn">loss(t) = t (\tau - I(t&lt;0));</code>
</p>

<p>for <code>method = "ls"</code>, </p>
<p style="text-align: center;"><code class="reqn">loss(t) = \frac{t^2}{2}</code>
</p>

<p>In the model, &quot;t&quot; is replaced by residuals.
</p>
<p>The program supports different types of preprocessing techniques. They are applied to 
each column of the input matrix <code>X</code>. Let x be a column of <code>X</code>. For 
<code>preprocess = "standardize"</code>, the formula is 
</p>
<p style="text-align: center;"><code class="reqn">x' = \frac{x-mean(x)}{sd(x)};</code>
</p>

<p>for <code>preprocess = "rescale"</code>, 
</p>
<p style="text-align: center;"><code class="reqn">x' = \frac{x-min(x)}{max(x)-min(x)}.</code>
</p>

<p>The models are fit with preprocessed input, then the coefficients are transformed back
to the original scale via some algebra. To fit a model for raw data with no preprocessing, use <code>hqreg_raw</code>.
</p>


<h3>Value</h3>

<p>The function returns an object of S3 class <code>"hqreg"</code>, which is a list containing:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>The call that produced this object.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>The fitted matrix of coefficients.  The number of rows is equal to the number 
of coefficients, and the number of columns is equal to <code>nlambda</code>. An intercept is included.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>A vector of length <code>nlambda</code> containing the number of iterations until 
convergence at each value of <code>lambda</code>.</p>
</td></tr>
<tr><td><code>saturated</code></td>
<td>
<p>A logical flag for whether the number of nonzero coefficients has reached <code>dfmax</code>.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The sequence of regularization parameter values in the path.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>Same as above.</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>
<p>Same as above. <code>NULL</code> except when <code>method = "huber"</code>.</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>
<p>Same as above. <code>NULL</code> except when <code>method = "quantile"</code>.</p>
</td></tr>
<tr><td><code>penalty.factor</code></td>
<td>
<p>Same as above.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Same as above.</p>
</td></tr>
<tr><td><code>nv</code></td>
<td>
<p>The variable screening rules are accompanied with checks of optimality 
conditions. When violations occur, the program adds in violating variables and re-runs 
the inner loop until convergence. <code>nv</code> is the number of violations.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Congrui Yi &lt;congrui-yi@uiowa.edu&gt;</p>


<h3>References</h3>

<p>Yi, C. and Huang, J. (2016) 
<em>Semismooth Newton Coordinate Descent Algorithm for 
Elastic-Net Penalized Huber Loss Regression and Quantile Regression</em>,
<a href="https://arxiv.org/abs/1509.02957">https://arxiv.org/abs/1509.02957</a> <br />
<em>Journal of Computational and Graphical Statistics, accepted in Nov 2016</em> <br />
<a href="http://www.tandfonline.com/doi/full/10.1080/10618600.2016.1256816">http://www.tandfonline.com/doi/full/10.1080/10618600.2016.1256816</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.hqreg">plot.hqreg</a></code>, <code><a href="#topic+cv.hqreg">cv.hqreg</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>X = matrix(rnorm(1000*100), 1000, 100)
beta = rnorm(10)
eps = 4*rnorm(1000)
y = drop(X[,1:10] %*% beta + eps)

# Huber loss
fit1 = hqreg(X, y)
coef(fit1, 0.01)
predict(fit1, X[1:5,], lambda = c(0.02, 0.01))

# Quantile loss
fit2 = hqreg(X, y, method = "quantile", tau = 0.2)
plot(fit2)

# Squared loss
fit3 = hqreg(X, y, method = "ls", preprocess = "rescale")
plot(fit3, xvar = "norm")
</code></pre>

<hr>
<h2 id='hqreg_raw'>Fit a robust regression model on raw data with Huber or quantile loss penalized by lasso or elasti-net</h2><span id='topic+hqreg_raw'></span>

<h3>Description</h3>

<p>On raw data without internal data preprocessing, fit solution paths for Huber loss regression or 
quantile regression penalized by lasso or elastic-net over a grid of values for the regularization parameter lambda.</p>


<h3>Usage</h3>

<pre><code class='language-R'>hqreg_raw(X, y, method = c("huber", "quantile", "ls"),
    gamma = IQR(y)/10, tau = 0.5, alpha = 1, nlambda = 100, lambda.min = 0.05, lambda, 
    intercept = TRUE, screen = c("ASR", "SR", "none"), 
    max.iter = 10000, eps = 1e-7, dfmax = ncol(X)+1, penalty.factor = rep(1, ncol(X)), 
    message = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hqreg_raw_+3A_x">X</code></td>
<td>
<p>Input matrix.</p>
</td></tr>
<tr><td><code id="hqreg_raw_+3A_y">y</code></td>
<td>
<p>Response vector.</p>
</td></tr>
<tr><td><code id="hqreg_raw_+3A_method">method</code></td>
<td>
<p>The loss function to be used in the model. Either &quot;huber&quot; (default), 
&quot;quantile&quot;, or &quot;ls&quot; for least squares (see <code>Details</code>).</p>
</td></tr>
<tr><td><code id="hqreg_raw_+3A_gamma">gamma</code></td>
<td>
<p>The tuning parameter of Huber loss, with no effect for the other loss 
functions. Huber loss is quadratic for absolute values less than gamma and linear for those 
greater than gamma. The default value is IQR(y)/10.</p>
</td></tr>
<tr><td><code id="hqreg_raw_+3A_tau">tau</code></td>
<td>
<p>The tuning parameter of the quantile loss, with no effect for the other loss 
functions. It represents the conditional quantile of the response to be estimated, so 
must be a number between 0 and 1. It includes the absolute loss when tau = 0.5 (default).</p>
</td></tr>
<tr><td><code id="hqreg_raw_+3A_alpha">alpha</code></td>
<td>
<p>The elastic-net mixing parameter that controls the relative contribution 
from the lasso and the ridge penalty. It must be a number between 0 and 1. <code>alpha=1</code> 
is the lasso penalty and <code>alpha=0</code> the ridge penalty.</p>
</td></tr>
<tr><td><code id="hqreg_raw_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of lambda values.  Default is 100.</p>
</td></tr>
<tr><td><code id="hqreg_raw_+3A_lambda.min">lambda.min</code></td>
<td>
<p>The smallest value for lambda, as a fraction of lambda.max, the data 
derived entry value. Default is 0.05.</p>
</td></tr>
<tr><td><code id="hqreg_raw_+3A_lambda">lambda</code></td>
<td>
<p>A user-specified sequence of lambda values. Typical usage is to leave 
blank and have the program automatically compute a <code>lambda</code> sequence based on 
<code>nlambda</code> and <code>lambda.min</code>. Specifying <code>lambda</code> overrides this. This 
argument should be used with care and supplied with a decreasing sequence instead of 
a single value. To get coefficients for a single <code>lambda</code>, use <code>coef</code> or 
<code>predict</code> instead after fitting the solution path with <code>hqreg</code> or performing 
k-fold CV with <code>cv.hqreg</code>.</p>
</td></tr>
<tr><td><code id="hqreg_raw_+3A_intercept">intercept</code></td>
<td>
<p>Should an intercept be included? Default is TRUE.</p>
</td></tr>
<tr><td><code id="hqreg_raw_+3A_screen">screen</code></td>
<td>
<p>Screening rule to be applied at each <code>lambda</code> that discards variables 
for speed. Either &quot;ASR&quot; (default), &quot;SR&quot; or &quot;none&quot;. &quot;SR&quot; stands for the strong rule, 
and &quot;ASR&quot; for the adaptive strong rule. Using &quot;ASR&quot; typically requires fewer iterations 
to converge than &quot;SR&quot;, but the computing time are generally close. Note that the option 
&quot;none&quot; is used mainly for debugging, which may lead to much longer computing time.</p>
</td></tr>
<tr><td><code id="hqreg_raw_+3A_max.iter">max.iter</code></td>
<td>
<p>Maximum number of iterations. Default is 10000.</p>
</td></tr>
<tr><td><code id="hqreg_raw_+3A_eps">eps</code></td>
<td>
<p>Convergence threshold. The algorithms continue until the maximum change in the
objective after any coefficient update is less than <code>eps</code> times the null deviance. 
Default is <code>1E-7</code>.</p>
</td></tr>
<tr><td><code id="hqreg_raw_+3A_dfmax">dfmax</code></td>
<td>
<p>Upper bound for the number of nonzero coefficients. The algorithm exits and 
returns a partial path if <code>dfmax</code> is reached. Useful for very large dimensions.</p>
</td></tr>
<tr><td><code id="hqreg_raw_+3A_penalty.factor">penalty.factor</code></td>
<td>
<p>A numeric vector of length equal to the number of variables. Each 
component multiplies <code>lambda</code> to allow differential penalization. Can be 0 for 
some variables, in which case the variable is always in the model without penalization. 
Default is 1 for all variables.</p>
</td></tr>
<tr><td><code id="hqreg_raw_+3A_message">message</code></td>
<td>
<p>If set to TRUE,  hqreg will inform the user of its progress. This argument 
is kept for debugging. Default is FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sequence of models indexed by the regularization parameter <code>lambda</code> is fit 
using a semismooth Newton coordinate descent algorithm. The objective function is defined 
to be </p>
<p style="text-align: center;"><code class="reqn">\frac{1}{n} \sum loss_i + \lambda\textrm{penalty}.</code>
</p>

<p>For <code>method = "huber"</code>, 
</p>
<p style="text-align: center;"><code class="reqn">loss(t) = \frac{t^2}{2\gamma} I(|t|\le \gamma) + (|t| - \frac{\gamma}{2};) I(|t|&gt;
  \gamma)</code>
</p>

<p>for <code>method = "quantile"</code>, </p>
<p style="text-align: center;"><code class="reqn">loss(t) = t (\tau - I(t&lt;0));</code>
</p>

<p>for <code>method = "ls"</code>, </p>
<p style="text-align: center;"><code class="reqn">loss(t) = \frac{t^2}{2}</code>
</p>

<p>In the model, &quot;t&quot; is replaced by residuals.
</p>


<h3>Value</h3>

<p>The function returns an object of S3 class <code>"hqreg"</code>, which is a list containing:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>The call that produced this object.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>The fitted matrix of coefficients.  The number of rows is equal to the number 
of coefficients, and the number of columns is equal to <code>nlambda</code>. An intercept is included.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>A vector of length <code>nlambda</code> containing the number of iterations until 
convergence at each value of <code>lambda</code>.</p>
</td></tr>
<tr><td><code>saturated</code></td>
<td>
<p>A logical flag for whether the number of nonzero coefficients has reached <code>dfmax</code>.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The sequence of regularization parameter values in the path.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>Same as above.</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>
<p>Same as above. <code>NULL</code> except when <code>method = "huber"</code>.</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>
<p>Same as above. <code>NULL</code> except when <code>method = "quantile"</code>.</p>
</td></tr>
<tr><td><code>penalty.factor</code></td>
<td>
<p>Same as above.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Same as above.</p>
</td></tr>
<tr><td><code>nv</code></td>
<td>
<p>The variable screening rules are accompanied with checks of optimality 
conditions. When violations occur, the program adds in violating variables and re-runs 
the inner loop until convergence. <code>nv</code> is the number of violations.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Congrui Yi &lt;congrui-yi@uiowa.edu&gt;</p>


<h3>References</h3>

<p>Yi, C. and Huang, J. (2016) 
<em>Semismooth Newton Coordinate Descent Algorithm for 
Elastic-Net Penalized Huber Loss Regression and Quantile Regression</em>,
<a href="https://arxiv.org/abs/1509.02957">https://arxiv.org/abs/1509.02957</a> <br />
<em>Journal of Computational and Graphical Statistics, accepted in Nov 2016</em> <br />
<a href="http://www.tandfonline.com/doi/full/10.1080/10618600.2016.1256816">http://www.tandfonline.com/doi/full/10.1080/10618600.2016.1256816</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.hqreg">plot.hqreg</a></code>, <code><a href="#topic+cv.hqreg">cv.hqreg</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>X = matrix(rnorm(1000*100), 1000, 100)
beta = rnorm(10)
eps = 4*rnorm(1000)
y = drop(X[,1:10] %*% beta) + eps

# Huber loss
# include an intercept by default
fit1 = hqreg_raw(X, y)
coef(fit1, 0.01)
predict(fit1, X[1:5,], lambda = c(0.02, 0.01))

# no intercept
fit2 = hqreg_raw(X, y, intercept = FALSE)
plot(fit2)
</code></pre>

<hr>
<h2 id='hqreg-package'>Regularization Paths for Lasso or Elastic-net Penalized Huber Loss Regression and Quantile Regression</h2><span id='topic+hqreg-package'></span>

<h3>Description</h3>

<p>Efficient algorithms for fitting regularization paths for lasso or elastic-net penalized regression models with 
Huber loss, quantile loss or squared loss.</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> hqreg</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.4</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2017-2-15</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-3</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Very simple to use. Accepts <code>X,y</code> data for regression models, and
produces the regularization path over a grid of values for the tuning
parameter <code>lambda</code>. Also provides functions for plotting, prediction and parallelized cross-validation.
</p>


<h3>Author(s)</h3>

<p>Congrui Yi &lt;congrui-yi@uiowa.edu&gt;</p>


<h3>References</h3>

<p>Yi, C. and Huang, J. (2016) 
<em>Semismooth Newton Coordinate Descent Algorithm for 
Elastic-Net Penalized Huber Loss Regression and Quantile Regression</em>,
<a href="https://arxiv.org/abs/1509.02957">https://arxiv.org/abs/1509.02957</a> <br />
<em>Journal of Computational and Graphical Statistics, accepted in Nov 2016</em> <br />
<a href="http://www.tandfonline.com/doi/full/10.1080/10618600.2016.1256816">http://www.tandfonline.com/doi/full/10.1080/10618600.2016.1256816</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>X = matrix(rnorm(1000*100), 1000, 100)
beta = rnorm(10)
eps = 4*rnorm(1000)
y = drop(X[,1:10] %*% beta + eps) 

# Huber loss
fit1 = hqreg(X, y)
coef(fit1, 0.01)
predict(fit1, X[1:5,], lambda = c(0.02, 0.01))
cv.fit1 = cv.hqreg(X, y)
plot(cv.fit1)

# Quantile loss
fit2 = hqreg(X, y, method = "quantile", tau = 0.2)
plot(fit2)

# Squared loss
fit3 = hqreg(X, y, method = "ls", preprocess = "rescale")
plot(fit3, xvar = "norm")
</code></pre>

<hr>
<h2 id='plot.cv.hqreg'>Plot the cross-validation curve for a &quot;cv.hqreg&quot; object</h2><span id='topic+plot.cv.hqreg'></span>

<h3>Description</h3>

<p>Plot the cross-validation curve for a &quot;cv.hqreg&quot; object against the 
<code>lambda</code> values used, along with standard error bars.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.hqreg'
plot(x, log.l = TRUE, nvars = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cv.hqreg_+3A_x">x</code></td>
<td>
<p>A <code>"cv.hqreg"</code> object.</p>
</td></tr>
<tr><td><code id="plot.cv.hqreg_+3A_log.l">log.l</code></td>
<td>
<p>Should <code>log(lambda)</code> be used instead of <code>lambda</code> for X-axis? Default is TRUE.</p>
</td></tr>
<tr><td><code id="plot.cv.hqreg_+3A_nvars">nvars</code></td>
<td>
<p>If <code>TRUE</code> (the default), places an axis on top of the plot denoting 
the number of variables with nonzero coefficients at each <code>lambda</code>.</p>
</td></tr>
<tr><td><code id="plot.cv.hqreg_+3A_...">...</code></td>
<td>
<p>Other graphical parameters to <code>plot</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Produces a plot of mean cv errors at each <code>lambda</code> along with upper and lower standard error bars.</p>


<h3>Author(s)</h3>

<p>Congrui Yi &lt;congrui-yi@uiowa.edu&gt;</p>


<h3>References</h3>

<p>Yi, C. and Huang, J. (2016) 
<em>Semismooth Newton Coordinate Descent Algorithm for 
Elastic-Net Penalized Huber Loss Regression and Quantile Regression</em>,
<a href="https://arxiv.org/abs/1509.02957">https://arxiv.org/abs/1509.02957</a> <br />
<em>Journal of Computational and Graphical Statistics, accepted in Nov 2016</em> <br />
<a href="http://www.tandfonline.com/doi/full/10.1080/10618600.2016.1256816">http://www.tandfonline.com/doi/full/10.1080/10618600.2016.1256816</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+hqreg">hqreg</a></code>, <code><a href="#topic+cv.hqreg">cv.hqreg</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>X = matrix(rnorm(1000*100), 1000, 100)
beta = rnorm(10)
eps = 4*rnorm(1000)
y = drop(X[,1:10] %*% beta + eps)
cv = cv.hqreg(X, y, seed = 123)
plot(cv)
</code></pre>

<hr>
<h2 id='plot.hqreg'>Plot coefficients from a &quot;hqreg&quot; object</h2><span id='topic+plot.hqreg'></span>

<h3>Description</h3>

<p>Produce a plot of the coefficient paths for a fitted
<code>"hqreg"</code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hqreg'
plot(x, xvar = c("lambda", "norm"), log.l= TRUE, nvars = TRUE, 
    alpha = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.hqreg_+3A_x">x</code></td>
<td>
<p>A <code>hqreg</code> object.</p>
</td></tr>
<tr><td><code id="plot.hqreg_+3A_xvar">xvar</code></td>
<td>
<p>What is on the X-axis. <code>"lambda"</code> plots against the lambda sequence, 
<code>"norm"</code> against the L1-norm of the coefficients. Default is <code>"lambda"</code>.</p>
</td></tr>
<tr><td><code id="plot.hqreg_+3A_log.l">log.l</code></td>
<td>
<p>Should <code>log(lambda)</code> be used instead of <code>lambda</code> when <code>xvar = "lambda"</code>? 
Default is TRUE. It has no effect for <code>"norm"</code>.</p>
</td></tr>
<tr><td><code id="plot.hqreg_+3A_nvars">nvars</code></td>
<td>
<p>If <code>TRUE</code> (the default), places an axis on top of the plot denoting the 
number of variables with nonzero coefficients at each <code>lambda</code>.</p>
</td></tr>
<tr><td><code id="plot.hqreg_+3A_alpha">alpha</code></td>
<td>
<p>A value between 0 and 1 for alpha transparency channel(0 means transparent 
and 1 means opaque), helpful when the number of variables is large.</p>
</td></tr>
<tr><td><code id="plot.hqreg_+3A_...">...</code></td>
<td>
<p>Other graphical parameters to <code>plot</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Congrui Yi &lt;congrui-yi@uiowa.edu&gt;</p>


<h3>References</h3>

<p>Yi, C. and Huang, J. (2016) 
<em>Semismooth Newton Coordinate Descent Algorithm for 
Elastic-Net Penalized Huber Loss Regression and Quantile Regression</em>,
<a href="https://arxiv.org/abs/1509.02957">https://arxiv.org/abs/1509.02957</a> <br />
<em>Journal of Computational and Graphical Statistics, accepted in Nov 2016</em> <br />
<a href="http://www.tandfonline.com/doi/full/10.1080/10618600.2016.1256816">http://www.tandfonline.com/doi/full/10.1080/10618600.2016.1256816</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+hqreg">hqreg</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>X = matrix(rnorm(1000*100), 1000, 100)
beta = rnorm(10)
eps = 4*rnorm(1000)
y = drop(X[,1:10] %*% beta + eps) 
fit = hqreg(X, y)
par(mfrow = c(2,2))
plot(fit)
plot(fit, nvars = FALSE, alpha = 0.5)
plot(fit, xvar = "norm")
</code></pre>

<hr>
<h2 id='predict.cv.hqreg'>Model predictions based on &quot;cv.hqreg&quot; object.</h2><span id='topic+predict.cv.hqreg'></span><span id='topic+coef.cv.hqreg'></span>

<h3>Description</h3>

<p>This function makes predictions from a cross-validated hqreg model, using the stored fit 
and the optimal value chosen for <code>lambda</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.hqreg'
predict(object, X, lambda = c("lambda.1se","lambda.min"), 
    type = c("response","coefficients","nvars"), ...)
## S3 method for class 'cv.hqreg'
coef(object, lambda = c("lambda.1se","lambda.min"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.cv.hqreg_+3A_object">object</code></td>
<td>
<p>Fitted <code>"hqreg"</code> model object.</p>
</td></tr>
<tr><td><code id="predict.cv.hqreg_+3A_x">X</code></td>
<td>
<p>Matrix of values at which predictions are to be made. Used only for <code>type = "response"</code>.</p>
</td></tr>
<tr><td><code id="predict.cv.hqreg_+3A_lambda">lambda</code></td>
<td>
<p>Values of the regularization parameter <code>lambda</code> at which predictions 
are requested. Default is the value <code>"lambda.1se"</code> stored on the CV <code>object</code>. 
Alternatively <code>"lambda.min"</code> can be used. If <code>lambda</code> is numeric, it is taken 
as the value(s) of <code>lambda</code> to be used.</p>
</td></tr>
<tr><td><code id="predict.cv.hqreg_+3A_type">type</code></td>
<td>
<p>Type of prediction. <code>"response"</code> returns the fitted values; <code>"coefficients"</code> 
returns the coefficients; <code>"nvars"</code> returns the number of nonzero coefficients at 
each value of <code>lambda</code>.</p>
</td></tr>
<tr><td><code id="predict.cv.hqreg_+3A_...">...</code></td>
<td>
<p>Not used. Other arguments to predict.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The object returned depends on type.</p>


<h3>Author(s)</h3>

<p>Congrui Yi &lt;congrui-yi@uiowa.edu&gt;</p>


<h3>References</h3>

<p>Yi, C. and Huang, J. (2016) 
<em>Semismooth Newton Coordinate Descent Algorithm for 
Elastic-Net Penalized Huber Loss Regression and Quantile Regression</em>,
<a href="https://arxiv.org/abs/1509.02957">https://arxiv.org/abs/1509.02957</a> <br />
<em>Journal of Computational and Graphical Statistics, accepted in Nov 2016</em> <br />
<a href="http://www.tandfonline.com/doi/full/10.1080/10618600.2016.1256816">http://www.tandfonline.com/doi/full/10.1080/10618600.2016.1256816</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+hqreg">hqreg</a></code> <code><a href="#topic+cv.hqreg">cv.hqreg</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>X = matrix(rnorm(1000*100), 1000, 100)
beta = rnorm(10)
eps = 4*rnorm(1000)
y = drop(X[,1:10] %*% beta + eps) 
cv = cv.hqreg(X, y, seed = 1011)
predict(cv, X[1:5,])
predict(cv, X[1:5,], lambda = "lambda.min")
predict(cv, X[1:5,], lambda = 0.05)
</code></pre>

<hr>
<h2 id='predict.hqreg'>Model predictions based on &quot;hqreg&quot; object.</h2><span id='topic+predict.hqreg'></span><span id='topic+coef.hqreg'></span>

<h3>Description</h3>

<p>This function returns fitted values, coefficients and more from a fitted <code>"hqreg"</code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hqreg'
predict(object, X, lambda, type = c("response","coefficients","nvars"), 
    exact = FALSE, ...)
## S3 method for class 'hqreg'
coef(object, lambda, exact = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.hqreg_+3A_object">object</code></td>
<td>
<p>Fitted <code>"hqreg"</code> model object.</p>
</td></tr>
<tr><td><code id="predict.hqreg_+3A_x">X</code></td>
<td>
<p>Matrix of values at which predictions are to be made. Used only for <code>type = "response"</code>.</p>
</td></tr>
<tr><td><code id="predict.hqreg_+3A_lambda">lambda</code></td>
<td>
<p>Values of the regularization parameter <code>lambda</code> at which predictions 
are requested. Default is the entire sequence used to create the model.</p>
</td></tr>
<tr><td><code id="predict.hqreg_+3A_type">type</code></td>
<td>
<p>Type of prediction. <code>"response"</code> returns the fitted values; 
<code>"coefficients"</code> returns the coefficients; <code>"nvars"</code> returns the number of 
nonzero coefficients at each value of <code>lambda</code>.</p>
</td></tr>
<tr><td><code id="predict.hqreg_+3A_exact">exact</code></td>
<td>
<p>If <code>exact=FALSE</code> (default), then the function uses linear interpolation 
to make predictions for values of <code>lambda</code> that do not coincide with those used to 
fit the model. If <code>exact=TRUE</code>, and predictions are requested at values of <code>lambda</code> 
not included in the original fit, the model is refit on a lambda sequence consisting 
<code>object$lambda</code> and the new ones before predictions are made. </p>
</td></tr>
<tr><td><code id="predict.hqreg_+3A_...">...</code></td>
<td>
<p>Not used. Other arguments to predict.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The object returned depends on type.</p>


<h3>Author(s)</h3>

<p>Congrui Yi &lt;congrui-yi@uiowa.edu&gt;</p>


<h3>References</h3>

<p>Yi, C. and Huang, J. (2016) 
<em>Semismooth Newton Coordinate Descent Algorithm for 
Elastic-Net Penalized Huber Loss Regression and Quantile Regression</em>,
<a href="https://arxiv.org/abs/1509.02957">https://arxiv.org/abs/1509.02957</a> <br />
<em>Journal of Computational and Graphical Statistics, accepted in Nov 2016</em> <br />
<a href="http://www.tandfonline.com/doi/full/10.1080/10618600.2016.1256816">http://www.tandfonline.com/doi/full/10.1080/10618600.2016.1256816</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+hqreg">hqreg</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>X = matrix(rnorm(1000*100), 1000, 100)
beta = rnorm(10)
eps = 4*rnorm(1000)
y = drop(X[,1:10] %*% beta + eps) 
fit = hqreg(X, y, method = "quantile", tau = 0.7)
predict(fit, X[1:5,], lambda = c(0.05, 0.01))
predict(fit, X[1:5,], lambda = 0.05, exact = TRUE)
predict(fit, X[1:5,], lambda = 0.05, type = "nvars")
coef(fit, lambda = 0.05)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
