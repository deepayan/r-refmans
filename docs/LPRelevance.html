<!DOCTYPE html><html><head><title>Help for package LPRelevance</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {LPRelevance}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#data.dti'>
<p>DTI data.</p></a></li>
<li><a href='#funnel'>
<p>A stylized simulated example.</p></a></li>
<li><a href='#g2l.proc'>
<p>Procedures for global and local inference.</p></a></li>
<li><a href='#kidney'>
<p>Kidney data.</p></a></li>
<li><a href='#LASER'>
<p>Generates Artificial RELevance Samples.</p></a></li>
<li><a href='#LPRelevance-package'>
<p>Relevance-Integrated Statistical Inference Engine</p></a></li>
<li><a href='#rEB.Finite.Bayes'>
<p>Relevance-Integrated Finite Bayes.</p></a></li>
<li><a href='#rEB.proc'>
<p>Relevance-Integrated Empirical Bayes Inference</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Relevance-Integrated Statistical Inference Engine</td>
</tr>
<tr>
<td>Version:</td>
<td>3.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-05-17</td>
</tr>
<tr>
<td>Author:</td>
<td>Subhadeep Mukhopadhyay, Kaijun Wang</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kaijun Wang &lt;kaijunwang.19@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Provide methods to perform customized inference at individual level by taking 
	contextual covariates into account. Three main functions are provided 
	in this package: (i) LASER(): it generates specially-designed artificial relevant 
	samples for a given case; (ii) g2l.proc(): computes customized fdr(z|x); and (iii) 
	rEB.proc(): performs empirical Bayes inference based on LASERs. The details can be 
	found in Mukhopadhyay, S., and Wang, K (2021, &lt;<a href="https://arxiv.org/abs/2004.09588">arXiv:2004.09588</a>&gt;). </td>
</tr>
<tr>
<td>Imports:</td>
<td>leaps,locfdr,Bolstad2,reshape2,ggplot2,polynom,glmnet,caret</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.3), stats, BayesGOF, MASS</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-05-18 00:10:40 UTC; palan</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-05-18 06:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='data.dti'>
DTI data.
</h2><span id='topic+data.dti'></span>

<h3>Description</h3>

<p>A diffusion tensor imaging study comparing brain activity of six dyslexic children versus six normal controls. Two-sample tests produced z-values at <code class="reqn">N = 15443</code> voxels (3-dimensional brain locations), with each <code class="reqn">z_i \sim N(0,1)</code> under the null hypothesis of no difference between the dyslexic and normal children.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data.dti)</code></pre>


<h3>Format</h3>

<p>A data frame with 15443 observations on the following 4 variables.
</p>

<dl>
<dt><code>coordx</code></dt><dd><p>A list of x coordinates</p>
</dd>
<dt><code>coordy</code></dt><dd><p>A list of y coordinates</p>
</dd>
<dt><code>coordz</code></dt><dd><p>A list of z coordinates</p>
</dd>
<dt><code>z</code></dt><dd><p>The <code class="reqn">z</code>-values.</p>
</dd>
</dl>



<h3>Source</h3>

<p>http://statweb.stanford.edu/~ckirby/brad/LSI/datasets-and-programs/datasets.html
</p>


<h3>References</h3>

<p>Efron, B. (2012). &quot;Large-scale inference: empirical Bayes methods for estimation, testing, and prediction&quot;. Cambridge University Press.
</p>

<hr>
<h2 id='funnel'>
A stylized simulated example.
</h2><span id='topic+funnel'></span>

<h3>Description</h3>

<p>A large-scale heterogeneous dataset used in our paper.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("funnel")</code></pre>


<h3>Format</h3>

<p>A data frame with 3565 observations on the following 3 variables.
</p>

<dl>
<dt><code>x</code></dt><dd><p>A list of covariate values.</p>
</dd>
<dt><code>z</code></dt><dd><p>A list of z-values.</p>
</dd>
<dt><code>tags</code></dt><dd><p>Binary vector of labels, 1 indicates a data point is a signal.</p>
</dd>
</dl>



<h3>References</h3>

<p>Mukhopadhyay, S., and Wang, K (2021) &quot;On The Problem of Relevance in Statistical Inference&quot;. &lt;arXiv:2004.09588&gt;
</p>

<hr>
<h2 id='g2l.proc'>
Procedures for global and local inference.
</h2><span id='topic+g2l.proc'></span><span id='topic+g2l.infer'></span><span id='topic+g2l.infer.boot'></span><span id='topic+fdr.thresh'></span><span id='topic+get_bh_threshold'></span><span id='topic+getNullProb'></span>

<h3>Description</h3>

<p>This function performs customized fdr analyses tailored to each individual cases.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>g2l.proc(X, z, X.target = NULL, z.target = NULL, m = c(4, 6), alpha = 0.1,
	nbag = NULL, nsample = length(z), lp.reg.method = "lm",
	null.scale = "QQ", approx.method = "direct", ngrid = 2000,
	centering = TRUE, coef.smooth = "BIC", fdr.method = "locfdr",
	plot = TRUE, rel.null = "custom", locfdr.df = 10,
	fdr.th.fixed = NULL, parallel = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="g2l.proc_+3A_x">X</code></td>
<td>
<p>A <code class="reqn">n</code>-by-<code class="reqn">d</code> matrix of covariate values</p>
</td></tr>
<tr><td><code id="g2l.proc_+3A_z">z</code></td>
<td>
<p>A length <code class="reqn">n</code> vector containing observations of z values.</p>
</td></tr>
<tr><td><code id="g2l.proc_+3A_x.target">X.target</code></td>
<td>
<p>A <code class="reqn">k</code>-by-<code class="reqn">d</code> matrix providing <code class="reqn">k</code> sets of covariates for target cases to investigate. Set to NULL to investigate all cases and provide global inference results.</p>
</td></tr>
<tr><td><code id="g2l.proc_+3A_z.target">z.target</code></td>
<td>
<p>A vector of length <code class="reqn">k</code>, providing the target <code class="reqn">z</code> values to investigate</p>
</td></tr>
<tr><td><code id="g2l.proc_+3A_m">m</code></td>
<td>
<p>An ordered pair. First number indicates how many LP-nonparametric basis to construct for each <code class="reqn">X</code>, second number indicates how many to construct for <code class="reqn">z</code>. Default: <code>m=c(4,6)</code>.</p>
</td></tr>
<tr><td><code id="g2l.proc_+3A_alpha">alpha</code></td>
<td>
<p>Confidence level for determining signals.</p>
</td></tr>
<tr><td><code id="g2l.proc_+3A_nbag">nbag</code></td>
<td>
<p>Number of bags of parametric bootstrapped samples to use for each target case, each time a new set of relevance samples will be generated for analysis, and the resulting fdr curves are aggregated together by taking the mean values. Set to <code>NULL</code> to disable.</p>
</td></tr>
<tr><td><code id="g2l.proc_+3A_nsample">nsample</code></td>
<td>
<p>Number of relevance samples generated for each case. The default is the size of the input z-statistic.</p>
</td></tr>
<tr><td><code id="g2l.proc_+3A_lp.reg.method">lp.reg.method</code></td>
<td>
<p>Method for estimating the relevance function and its conditional LP-Fourier coefficients. We currently support three options: lm (inbuilt with subset selection), glmnet, and knn.</p>
</td></tr>
<tr><td><code id="g2l.proc_+3A_null.scale">null.scale</code></td>
<td>
<p>Method of estimating null standard deviation from the laser samples. Available options: &quot;IQR&quot;, &quot;QQ&quot; and &quot;locfdr&quot;</p>
</td></tr>
<tr><td><code id="g2l.proc_+3A_approx.method">approx.method</code></td>
<td>
<p>Method used to approximate customized fdr curve, default is &quot;direct&quot;.When set to &quot;indirect&quot;, the customized fdr is computed by modifying pooled fdr using relevant density function.</p>
</td></tr>
<tr><td><code id="g2l.proc_+3A_ngrid">ngrid</code></td>
<td>
<p>Number of gridpoints to use for computing customized fdr curve.</p>
</td></tr>
<tr><td><code id="g2l.proc_+3A_centering">centering</code></td>
<td>
<p>Whether to perform regression-adjustment to center the data, default is TRUE.</p>
</td></tr>
<tr><td><code id="g2l.proc_+3A_coef.smooth">coef.smooth</code></td>
<td>
<p>Specifies the method to use for LP coefficient smoothing (AIC or BIC). Uses BIC by default.</p>
</td></tr>
<tr><td><code id="g2l.proc_+3A_fdr.method">fdr.method</code></td>
<td>
<p>Method for controlling false discoveries (either &quot;locfdr&quot; or &quot;BH&quot;), default choice is &quot;locfdr&quot;.</p>
</td></tr>
<tr><td><code id="g2l.proc_+3A_plot">plot</code></td>
<td>
<p>Whether to include plots in the results, default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="g2l.proc_+3A_rel.null">rel.null</code></td>
<td>
<p>How the relevant null changes with x: &quot;custom&quot; denotes we allow it to vary with x, and &quot;th&quot; denotes fixed.</p>
</td></tr>
<tr><td><code id="g2l.proc_+3A_locfdr.df">locfdr.df</code></td>
<td>
<p>Degrees of freedom to use for <code>locfdr()</code></p>
</td></tr>
<tr><td><code id="g2l.proc_+3A_fdr.th.fixed">fdr.th.fixed</code></td>
<td>
<p>Use fixed fdr threshold for finding signals. Default set to <code>NULL</code>, which finds different thresholds for different cases. </p>
</td></tr>
<tr><td><code id="g2l.proc_+3A_parallel">parallel</code></td>
<td>
<p>Use parallel computing for obtaining the relevance samples, mainly used for very huge <code>nsample</code>, default is FALSE.</p>
</td></tr>
<tr><td><code id="g2l.proc_+3A_...">...</code></td>
<td>
<p>Extra parameters to pass to other functions. Currently only supports the arguments for <code>knn()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following items:
</p>
<table>
<tr><td><code>macro</code></td>
<td>
<p>Available when <code>X.target</code> set to <code>NULL</code>, contains the following items:</p>
</td></tr>
<tr><td><code>$result</code></td>
<td>
<p>A list of global inference results:</p>
</td></tr>
<tr><td><code>$X</code></td>
<td>
<p>Matrix of covariates, same as input <code>X</code>.</p>
</td></tr>
<tr><td><code>$z</code></td>
<td>
<p>Vector of observations, same as input <code>z</code>.</p>
</td></tr>
<tr><td><code>$probnull</code></td>
<td>
<p>A vector of length <code class="reqn">n</code>, indicating how likely the observed z belongs to local null.</p>
</td></tr>
<tr><td><code>$signal</code></td>
<td>
<p>A binary vector of length <code class="reqn">n</code>, discoveries are indicated by <code class="reqn">1</code>.</p>
</td></tr>
<tr><td><code>plots</code></td>
<td>
<p>A list of plots for global inference:</p>
</td></tr>
<tr><td><code>$signal_x</code></td>
<td>
<p>A plot of signals discovered, marked in red</p>
</td></tr>
<tr><td><code>$dps_xz</code></td>
<td>
<p>A scatterplot of z on x, colored based on the discovery propensity scores, only available when <code>fdr.method = "locfdr"</code>.</p>
</td></tr>
<tr><td><code>$dps_x</code></td>
<td>
<p>A scatterplot of discovery propensity scores on x, only available when <code>fdr.method = "locfdr"</code>.</p>
</td></tr>
<tr><td><code>micro</code></td>
<td>
<p>Available when <code>X.target</code> are provided with values, contains the following items:</p>
</td></tr>
<tr><td><code>$result</code></td>
<td>
<p>Customized estimates for null probabilities for target <code class="reqn">X</code> and <code class="reqn">z</code></p>
</td></tr>
<tr><td><code>$result$signal</code></td>
<td>
<p>A binary vector of length <code class="reqn">k</code>, discoveries in the target cases are indicated by <code class="reqn">1</code></p>
</td></tr>
<tr><td><code>$global</code></td>
<td>
<p>Pooled global estimates for null probabilities for target <code class="reqn">X</code> and <code class="reqn">z</code></p>
</td></tr>
<tr><td><code>$plots</code></td>
<td>
<p>Customized fdr plots for the target cases.</p>
</td></tr>
<tr><td><code>m.lp</code></td>
<td>
<p>Same as input <code>m</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Subhadeep Mukhopadhyay, Kaijun Wang
</p>
<p>Maintainer: Kaijun Wang &lt;kaijunwang.19@gmail.com&gt;
</p>


<h3>References</h3>

<p>Mukhopadhyay, S., and Wang, K (2021) &quot;On The Problem of Relevance in Statistical Inference&quot;. &lt;arXiv:2004.09588&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(funnel)
X&lt;-funnel$x
z&lt;-funnel$z
##macro-inference using locfdr and LASER:
g2l_macro&lt;-g2l.proc(X,z)
g2l_macro$macro$plots

#Microinference for the DTI data: case A with x=(18,55) and z=3.95
data(data.dti)
X&lt;- cbind(data.dti$coordx,data.dti$coordy)
z&lt;-data.dti$z
g2l_x&lt;-g2l.proc(X,z,X.target=c(18,55),z.target=3.95,nsample =3000)
g2l_x$micro$plots$fdr.1+ggplot2::coord_cartesian(xlim=c(0,4))
g2l_x$micro$result[4]

</code></pre>

<hr>
<h2 id='kidney'>
Kidney data.
</h2><span id='topic+kidney'></span>

<h3>Description</h3>

<p>This data set records age and kidney function of <code class="reqn">N = 157</code> volunteers. Higher scores indicates better function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(kidney)</code></pre>


<h3>Format</h3>

<p>A data frame with 157 observations on the following 2 variables.
</p>

<dl>
<dt><code>x</code></dt><dd><p>A list of patients' age.</p>
</dd>
<dt><code>z</code></dt><dd><p>A list of kidney scores.</p>
</dd>
</dl>



<h3>Source</h3>

<p>http://statweb.stanford.edu/~ckirby/brad/LSI/datasets-and-programs/datasets.html
</p>


<h3>References</h3>

<p>Efron, B. (2012). &quot;Large-scale inference: empirical Bayes methods for estimation, testing, and prediction&quot;. Cambridge University Press.
</p>
<p>Lemley, K. V., Lafayette, R. A., Derby, G., Blouch, K. L., Anderson, L., Efron, B., &amp; Myers, B. D. (2007). &quot;Prediction of early progression in recently diagnosed IgA nephropathy.&quot; Nephrology Dialysis Transplantation, 23(1), 213-222.
</p>

<hr>
<h2 id='LASER'>
Generates Artificial RELevance Samples.
</h2><span id='topic+LASER'></span><span id='topic+g2l.sampler'></span><span id='topic+z.lp.center'></span>

<h3>Description</h3>

<p>This function generates the artificial relevance samples (LASER).These are &quot;sharpened&quot; z-samples manufactured by the relevance-function <code class="reqn">d_x(z)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LASER( X,z, X.target, m=c(4,6), nsample=length(z), lp.reg.method='lm',
       coef.smooth='BIC', centering=TRUE,parallel=FALSE,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LASER_+3A_x">X</code></td>
<td>
<p>A <code class="reqn">n</code>-by-<code class="reqn">d</code> matrix of covariate values</p>
</td></tr>
<tr><td><code id="LASER_+3A_z">z</code></td>
<td>
<p>A length <code class="reqn">n</code> vector containing observations of z values.</p>
</td></tr>
<tr><td><code id="LASER_+3A_x.target">X.target</code></td>
<td>
<p>A <code class="reqn">k</code>-by-<code class="reqn">d</code> matrix providing k sets of target points for which the LASERs are required.</p>
</td></tr>
<tr><td><code id="LASER_+3A_m">m</code></td>
<td>
<p>An ordered pair. First number indicates how many LP-nonparametric basis to construct for each <code class="reqn">X</code>, second number indicates how many to construct for <code class="reqn">z</code>. Default: <code>m=c(4,6)</code></p>
</td></tr>
<tr><td><code id="LASER_+3A_nsample">nsample</code></td>
<td>
<p>Number of relevance samples to generate for each case.</p>
</td></tr>
<tr><td><code id="LASER_+3A_lp.reg.method">lp.reg.method</code></td>
<td>
<p>Method for estimating the relevance function and its conditional LP-Fourier coefficients. We currently support thee options: lm (inbuilt with subset selection), glmnet, and knn.</p>
</td></tr>
<tr><td><code id="LASER_+3A_centering">centering</code></td>
<td>
<p>Whether to perform regression-adjustment to center the data, default is TRUE.</p>
</td></tr>
<tr><td><code id="LASER_+3A_coef.smooth">coef.smooth</code></td>
<td>
<p>Specifies the method to use for LP coefficient smoothing (AIC or BIC). Uses BIC by default.</p>
</td></tr>
<tr><td><code id="LASER_+3A_parallel">parallel</code></td>
<td>
<p>Use parallel computing for obtaining the relevance samples, mainly used for very huge <code>nsample</code>, default is FALSE.</p>
</td></tr>
<tr><td><code id="LASER_+3A_...">...</code></td>
<td>
<p>Extra parameters to pass to other functions. Currently only supports the arguments for <code>knn()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following items:
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>The relevant samples at <code>X.target</code>.</p>
</td></tr>
<tr><td><code>LPcoef</code></td>
<td>
<p>Parameters of the relevance function <code class="reqn">d_x(x)</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Subhadeep Mukhopadhyay, Kaijun Wang
</p>
<p>Maintainer: Kaijun Wang &lt;kaijunwang.19@gmail.com&gt;
</p>


<h3>References</h3>

<p>Mukhopadhyay, S., and Wang, K (2021) &quot;On The Problem of Relevance in Statistical Inference&quot;. &lt;arXiv:2004.09588&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(funnel)
X&lt;-funnel$x
z&lt;-funnel$z
z.laser.x30&lt;-LASER(X,z,X.target=30,m=c(4,8))$data
hist(z.laser.x30,50)

</code></pre>

<hr>
<h2 id='LPRelevance-package'>
Relevance-Integrated Statistical Inference Engine
</h2><span id='topic+LPRelevance-package'></span><span id='topic+LPRelevance'></span><span id='topic+LPcden'></span><span id='topic+eLP.poly'></span><span id='topic+eLP.univar'></span><span id='topic+LPregression'></span><span id='topic+Predict.LP.poly'></span><span id='topic+eLP.poly.predict'></span><span id='topic+LP.smooth'></span>

<h3>Description</h3>

<p>How to individualize a global inference method? The goal of this package is to provide a systematic
recipe for converting classical global inference algorithms into customized ones. It provides
methods that perform individual level inferences by taking contextual covariates into
account. At the heart of our solution is the concept of &quot;artificially-designed relevant samples&quot;,
called LASERs&ndash;which pave the way to construct an inference mechanism that is simultaneously
efficiently estimable and contextually relevant, thus works at both macroscopic (overall
simultaneous) and microscopic (individual-level) scale.
</p>


<h3>Author(s)</h3>

<p>Subhadeep Mukhopadhyay, Kaijun Wang
</p>
<p>Maintainer: Kaijun Wang &lt;kaijunwang.19@gmail.com&gt;
</p>


<h3>References</h3>

<p>Mukhopadhyay, S., and Wang, K (2021) &quot;On The Problem of Relevance in Statistical Inference&quot;. &lt;arXiv:2004.09588&gt;
</p>

<hr>
<h2 id='rEB.Finite.Bayes'>
Relevance-Integrated Finite Bayes.
</h2><span id='topic+rEB.Finite.Bayes'></span>

<h3>Description</h3>

<p>Performs custom-tailored Finite Bayes inference via LASERs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rEB.Finite.Bayes(X,z,X.target,z.target,m=c(4,6),m.EB=8, B=10, centering=TRUE,
            nsample=min(1000,length(z)), g.method='DL',LP.type='L2',  sd0=NULL,
            theta.set.prior=seq(-2.5*sd(z),2.5*sd(z),length.out=500),
            theta.set.post=seq(z.target-2.5*sd(z),z.target+2.5*sd(z),length.out=500),
            post.alpha=0.8,  plot=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rEB.Finite.Bayes_+3A_x">X</code></td>
<td>
<p>A <code class="reqn">n</code>-by-<code class="reqn">d</code> matrix of covariate values</p>
</td></tr>
<tr><td><code id="rEB.Finite.Bayes_+3A_z">z</code></td>
<td>
<p>A length <code class="reqn">n</code> vector containing observations of target random variable.</p>
</td></tr>
<tr><td><code id="rEB.Finite.Bayes_+3A_x.target">X.target</code></td>
<td>
<p>A length <code class="reqn">d</code> vector providing the set of covariates for the target case. </p>
</td></tr>
<tr><td><code id="rEB.Finite.Bayes_+3A_z.target">z.target</code></td>
<td>
<p>the target <code class="reqn">z</code> to investigate</p>
</td></tr>
<tr><td><code id="rEB.Finite.Bayes_+3A_m">m</code></td>
<td>
<p>An ordered pair. First number indicates how many LP-nonparametric basis to construct for each <code class="reqn">X</code>, second number indicates how many to construct for <code class="reqn">z</code>.</p>
</td></tr>
<tr><td><code id="rEB.Finite.Bayes_+3A_m.eb">m.EB</code></td>
<td>
<p>The truncation point reflecting the concentration of true nonparametric prior density <code class="reqn">\pi</code> around known prior distribution <code class="reqn">g</code></p>
</td></tr>
<tr><td><code id="rEB.Finite.Bayes_+3A_b">B</code></td>
<td>
<p>Number of bags of bootstrap samples for Finite Bayes.</p>
</td></tr>
<tr><td><code id="rEB.Finite.Bayes_+3A_centering">centering</code></td>
<td>
<p>Whether to perform regression-adjustment to center the data, default is TRUE.</p>
</td></tr>
<tr><td><code id="rEB.Finite.Bayes_+3A_nsample">nsample</code></td>
<td>
<p>Number of relevance samples generated for the target case.</p>
</td></tr>
<tr><td><code id="rEB.Finite.Bayes_+3A_g.method">g.method</code></td>
<td>
<p>Suggested method for finding parameter estimates <code class="reqn">\hat{\mu}</code> and <code class="reqn">\hat{\tau}^2</code> for normal prior: &quot;DL&quot; uses Dersimonian and Lard technique; &quot;SJ&quot; uses Sidik-Jonkman; 'REML' uses restricted maximum likelihood; and &quot;MoM&quot; uses a method of moments technique. </p>
</td></tr>
<tr><td><code id="rEB.Finite.Bayes_+3A_lp.type">LP.type</code></td>
<td>
<p>User selects either &quot;L2&quot; for LP-orthogonal series representation of relevance density function <code class="reqn">d</code> or &quot;MaxEnt&quot; for the maximum entropy representation. Default is L2.</p>
</td></tr>
<tr><td><code id="rEB.Finite.Bayes_+3A_sd0">sd0</code></td>
<td>
<p>Fixed standard deviation for <code class="reqn">z|\theta</code>. Default is NULL, the standard error will be calculated from data.</p>
</td></tr>
<tr><td><code id="rEB.Finite.Bayes_+3A_theta.set.prior">theta.set.prior</code></td>
<td>
<p>This indicates the set of grid points to compute prior density.</p>
</td></tr>
<tr><td><code id="rEB.Finite.Bayes_+3A_theta.set.post">theta.set.post</code></td>
<td>
<p>This indicates the set of grid points to compute posterior density.</p>
</td></tr>
<tr><td><code id="rEB.Finite.Bayes_+3A_post.alpha">post.alpha</code></td>
<td>
<p>The alpha level for posterior HPD interval.</p>
</td></tr>
<tr><td><code id="rEB.Finite.Bayes_+3A_plot">plot</code></td>
<td>
<p>Whether to display plots for prior and posterior of Relevance Finite Bayes.</p>
</td></tr>
<tr><td><code id="rEB.Finite.Bayes_+3A_...">...</code></td>
<td>
<p>Extra parameters to pass to LASER function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following items:
</p>
<table>
<tr><td><code>prior</code></td>
<td>
<p>Relevant Finite Bayes prior results.</p>
</td></tr>
<tr><td><code>$prior.fit</code></td>
<td>
<p>Prior density curve estimation.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>Relevant empirical Bayes posterior results. </p>
</td></tr>
<tr><td><code>$post.fit</code></td>
<td>
<p>Posterior density curve estimation.</p>
</td></tr>
<tr><td><code>$post.mode</code></td>
<td>
<p>Posterior mode for <code class="reqn">\pi(\theta|z,\boldsymbol{x})</code>.</p>
</td></tr>
<tr><td><code>$post.mean</code></td>
<td>
<p>Posterior mean for <code class="reqn">\pi(\theta|z,\boldsymbol{x})</code>.</p>
</td></tr>
<tr><td><code>$post.mean.sd</code></td>
<td>
<p>Standard error for the posterior mean.</p>
</td></tr>
<tr><td><code>$HPD.interval</code></td>
<td>
<p>The HPD interval for posterior <code class="reqn">\pi(\theta|z,\boldsymbol{x})</code>.</p>
</td></tr>
<tr><td><code>g.par</code></td>
<td>
<p>Parameters for <code class="reqn">g=N(\mu,\tau^2)</code>.</p>
</td></tr>
<tr><td><code>LP.coef</code></td>
<td>
<p>Reports the LP-coefficients of the relevance function <code class="reqn">d_x(x)</code>.</p>
</td></tr>
<tr><td><code>sd0</code></td>
<td>
<p>Initial estimate for null standard errors.</p>
</td></tr>
<tr><td><code>plots</code></td>
<td>
<p>The plots for prior and posterior density.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Subhadeep Mukhopadhyay, Kaijun Wang
</p>
<p>Maintainer: Kaijun Wang &lt;kaijunwang.19@gmail.com&gt;
</p>


<h3>References</h3>

<p>Mukhopadhyay, S., and Wang, K (2021) &quot;On The Problem of Relevance in Statistical Inference&quot;. &lt;arXiv:2004.09588&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(funnel)
X&lt;-funnel$x
z&lt;-funnel$z
X.target=30
z.target=4.49
rFB.out=rEB.Finite.Bayes(X,z,X.target,z.target,B=5,nsample=1000,m=c(4,8),m.EB=8,
                      theta.set.prior=seq(-4,4,length.out=500),
                      theta.set.post=seq(0,5,length.out=500),cred.interval=0.8,parallel=FALSE)
rFB.out$plots$prior
rFB.out$plots$post

</code></pre>

<hr>
<h2 id='rEB.proc'>
Relevance-Integrated Empirical Bayes Inference
</h2><span id='topic+rEB.proc'></span><span id='topic+LASER.rEB'></span><span id='topic+LP.post.conv'></span>

<h3>Description</h3>

<p>Performs custom-tailored empirical Bayes inference via LASERs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rEB.proc(X, z, X.target, z.target, m = c(4, 6), nbag = NULL, centering = TRUE,
	lp.reg.method = "lm", coef.smooth = "BIC", nsample = min(length(z),2000),
	theta.set.prior = NULL, theta.set.post = NULL, LP.type = "L2",
	g.method = "DL", sd0 = NULL, m.EB = 8, parallel = FALSE,
	avg.method = "mean", post.curve = "HPD", post.alpha = 0.8,
	color = "red", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rEB.proc_+3A_x">X</code></td>
<td>
<p>A <code class="reqn">n</code>-by-<code class="reqn">d</code> matrix of covariate values</p>
</td></tr>
<tr><td><code id="rEB.proc_+3A_z">z</code></td>
<td>
<p>A length <code class="reqn">n</code> vector containing observations of target random variable.</p>
</td></tr>
<tr><td><code id="rEB.proc_+3A_x.target">X.target</code></td>
<td>
<p>A length <code class="reqn">d</code> vector providing the set of covariates for the target case. </p>
</td></tr>
<tr><td><code id="rEB.proc_+3A_z.target">z.target</code></td>
<td>
<p>the target <code class="reqn">z</code> to investigate</p>
</td></tr>
<tr><td><code id="rEB.proc_+3A_m">m</code></td>
<td>
<p>An ordered pair. First number indicates how many LP-nonparametric basis to construct for each <code class="reqn">X</code>, second number indicates how many to construct for <code class="reqn">z</code>.</p>
</td></tr>
<tr><td><code id="rEB.proc_+3A_nbag">nbag</code></td>
<td>
<p>Number of bags of parametric bootstrapped samples to use, set to <code>NULL</code> to disable.</p>
</td></tr>
<tr><td><code id="rEB.proc_+3A_centering">centering</code></td>
<td>
<p>Whether to perform regression-adjustment to center the data, default is TRUE.</p>
</td></tr>
<tr><td><code id="rEB.proc_+3A_lp.reg.method">lp.reg.method</code></td>
<td>
<p>Method for estimating the relevance function and its conditional LP-Fourier coefficients. We currently support thee options: lm (inbuilt with subset selection), glmnet, and knn.</p>
</td></tr>
<tr><td><code id="rEB.proc_+3A_coef.smooth">coef.smooth</code></td>
<td>
<p>Specifies the method to use for LP coefficient smoothing (AIC or BIC). Uses BIC by default.</p>
</td></tr>
<tr><td><code id="rEB.proc_+3A_nsample">nsample</code></td>
<td>
<p>Number of relevance samples generated for the target case.</p>
</td></tr>
<tr><td><code id="rEB.proc_+3A_theta.set.prior">theta.set.prior</code></td>
<td>
<p>This indicates the set of grid points to compute prior density.</p>
</td></tr>
<tr><td><code id="rEB.proc_+3A_theta.set.post">theta.set.post</code></td>
<td>
<p>This indicates the set of grid points to compute posterior density.</p>
</td></tr>
<tr><td><code id="rEB.proc_+3A_lp.type">LP.type</code></td>
<td>
<p>User selects either &quot;L2&quot; for LP-orthogonal series representation of relevance density function <code class="reqn">d</code> or &quot;MaxEnt&quot; for the maximum entropy representation. Default is L2.</p>
</td></tr>
<tr><td><code id="rEB.proc_+3A_g.method">g.method</code></td>
<td>
<p>Suggested method for finding parameter estimates <code class="reqn">\hat{\mu}</code> and <code class="reqn">\hat{\tau}^2</code> for normal prior: &quot;DL&quot; uses Dersimonian and Lard technique; &quot;SJ&quot; uses Sidik-Jonkman; 'REML' uses restricted maximum likelihood; and &quot;MoM&quot; uses a method of moments technique. </p>
</td></tr>
<tr><td><code id="rEB.proc_+3A_sd0">sd0</code></td>
<td>
<p>Fixed standard deviation for <code class="reqn">z|\theta</code>. Default is NULL, the standard error will be calculated from data.</p>
</td></tr>
<tr><td><code id="rEB.proc_+3A_m.eb">m.EB</code></td>
<td>
<p>The truncation point reflecting the concentration of true nonparametric prior density <code class="reqn">\pi</code> around known prior distribution <code class="reqn">g</code></p>
</td></tr>
<tr><td><code id="rEB.proc_+3A_parallel">parallel</code></td>
<td>
<p>Use parallel computing for obtaining the relevance samples, mainly used for very huge <code>nsample</code>, default if FALSE.</p>
</td></tr>
<tr><td><code id="rEB.proc_+3A_avg.method">avg.method</code></td>
<td>
<p>For parametric bootstrapping, this specifies how the results from different bags are aggregated. (&quot;<code>mean</code>&quot; or &quot;<code>median</code>&quot;.)</p>
</td></tr>
<tr><td><code id="rEB.proc_+3A_post.curve">post.curve</code></td>
<td>
<p>For plotting, this specifies what to show on posterior curve. &quot;<code>HPD</code>&quot; provides HPD interval, &quot;<code>band</code>&quot; gives confidence band.</p>
</td></tr>
<tr><td><code id="rEB.proc_+3A_post.alpha">post.alpha</code></td>
<td>
<p>Confidence level to use when plotting posterior confidence band, or the alpha level for HPD interval.</p>
</td></tr>
<tr><td><code id="rEB.proc_+3A_color">color</code></td>
<td>
<p>The color of the plots.</p>
</td></tr>
<tr><td><code id="rEB.proc_+3A_...">...</code></td>
<td>
<p>Extra parameters to pass to other functions. Currently only supports the arguments for <code>knn()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following items:
</p>
<table>
<tr><td><code>result</code></td>
<td>
<p>Contains relevant empirical Bayes prior and posterior results.</p>
</td></tr>
<tr><td><code>sd0</code></td>
<td>
<p>Initial estimate for null standard errors.</p>
</td></tr>
<tr><td><code>prior</code></td>
<td>
<p>Relevant empirical Bayes prior results.</p>
</td></tr>
<tr><td><code>$g.par</code></td>
<td>
<p>Parameters for <code class="reqn">g=N(\mu,\tau^2)</code>.</p>
</td></tr>
<tr><td><code>$g.method</code></td>
<td>
<p>Method used for finding the parameter estimates <code class="reqn">\hat{\mu}</code> and <code class="reqn">\hat{\tau}^2</code> for <code class="reqn">g</code>.</p>
</td></tr>
<tr><td><code>$LP.coef</code></td>
<td>
<p>Reports the LP-coefficients of the relevance function <code class="reqn">d_x(x)</code>.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>Relevant empirical Bayes posterior results. </p>
</td></tr>
<tr><td><code>$post.mode</code></td>
<td>
<p>Posterior mode for <code class="reqn">\pi(\theta|z,\boldsymbol{x})</code>.</p>
</td></tr>
<tr><td><code>$post.mean</code></td>
<td>
<p>Posterior mean for <code class="reqn">\pi(\theta|z,\boldsymbol{x})</code>.</p>
</td></tr>
<tr><td><code>$post.mean.sd</code></td>
<td>
<p>Standard error for the posterior mean, when using parametric bootstrap.</p>
</td></tr>
<tr><td><code>$HPD.interval</code></td>
<td>
<p>The HPD interval for posterior <code class="reqn">\pi(\theta|z,\boldsymbol{x})</code>.</p>
</td></tr>
<tr><td><code>$post.alpha</code></td>
<td>
<p>same as input <code>post.alpha</code>.</p>
</td></tr>
<tr><td><code>plots</code></td>
<td>
<p>The plots for prior and posterior density.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Subhadeep Mukhopadhyay, Kaijun Wang
</p>
<p>Maintainer: Kaijun Wang &lt;kaijunwang.19@gmail.com&gt;
</p>


<h3>References</h3>

<p>Mukhopadhyay, S., and Wang, K (2021) &quot;On The Problem of Relevance in Statistical Inference&quot;. &lt;arXiv:2004.09588&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(funnel)
X&lt;-funnel$x
z&lt;-funnel$z
X.target=60
z.target=4.49
rEB.out&lt;-rEB.proc(X,z,X.target,z.target,m=c(4,8),
	theta.set.prior=seq(-2,2,length.out=200),
	theta.set.post=seq(-2,5,length.out=200),
	centering=TRUE,m.EB=6,nsample=1000)
rEB.out$plots$rEB.post
rEB.out$plots$rEB.prior

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
