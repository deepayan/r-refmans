<!DOCTYPE html><html><head><title>Help for package MacBehaviour</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {MacBehaviour}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#experimentDesign'><p>Step3: Generate the experimental design matrix.</p></a></li>
<li><a href='#loadData'><p>Step2: Load and format data</p></a></li>
<li><a href='#magicTokenizer'><p>magicTokenizer</p></a></li>
<li><a href='#preCheck'><p>Step4: Pre-check for token usage in experiment design.</p></a></li>
<li><a href='#runExperiment'><p>Run an Experiment Based on the Configuration</p></a></li>
<li><a href='#setKey'><p>Step1: Set model's API key and url.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Behavioural Studies of Large Language Models</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.3</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Shixuan Li &lt;shixuanli@cuhk.edu.hk&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>We provide an efficient way to design and conduct psycholinguistic experiments for testing the performance of large language models. It simplifies the process of setting up experiments, and data collection via large language models' API, streamlining workflow for researchers in the field of machine behavior. For methodology details, see Duan, X., Li, S., &amp; Cai, Z. G. (2023) &lt;<a href="https://doi.org/10.31234%2Fosf.io%2Fywtfd">doi:10.31234/osf.io/ywtfd</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/LGPL-3">LGPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), openxlsx, httr, dplyr, rjson</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, roxygen2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-19 03:30:46 UTC; LIN</td>
</tr>
<tr>
<td>Author:</td>
<td>Xufeng Duan [aut, cph],
  Shixuan Li [aut, cre],
  Zhenguang Cai [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-20 20:20:12 UTC</td>
</tr>
</table>
<hr>
<h2 id='experimentDesign'>Step3: Generate the experimental design matrix.</h2><span id='topic+experimentDesign'></span>

<h3>Description</h3>

<p>Defines the experiment setup based on the stimuli loaded.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>experimentDesign(data, Step = 1, random = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="experimentDesign_+3A_data">data</code></td>
<td>
<p>A data frame that has been processed through the 'loadData' function, containing the experimental items and their attributes.</p>
</td></tr>
<tr><td><code id="experimentDesign_+3A_step">Step</code></td>
<td>
<p>An integer indicating how many sessions (the whole set of trials) should be run. Default is 1, meaning no repetition.</p>
</td></tr>
<tr><td><code id="experimentDesign_+3A_random">random</code></td>
<td>
<p>A logical indicating whether the trials should be randomized. Default is FALSE, meaning trials will occur in the order provided.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame with the designed structure for the experiment, including any repetitions and randomizations as specified. Each row corresponds to a single trial or instance in the experiment.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
df &lt;- data.frame(
Run = c(1,2),
Item = c(1,2),
Condition = c(1,2),
TargetPrompt = c("1","2")
)

ExperimentItem=loadData(df$Run,df$Item,df$Condition,promptList = df$TargetPrompt)

Design=experimentDesign(ExperimentItem,Step=1,random = TRUE)

</code></pre>

<hr>
<h2 id='loadData'>Step2: Load and format data</h2><span id='topic+loadData'></span>

<h3>Description</h3>

<p>Prepares the stimuli data for the experiment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadData(runList, itemIDList, conditionList, promptList, header = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loadData_+3A_runlist">runList</code></td>
<td>
<p>A numeric vector of data representing the 'Run' column in the experiment.</p>
</td></tr>
<tr><td><code id="loadData_+3A_itemidlist">itemIDList</code></td>
<td>
<p>A numeric vector of data representing the 'itemID' column in the experiment.</p>
</td></tr>
<tr><td><code id="loadData_+3A_conditionlist">conditionList</code></td>
<td>
<p>A numeric/character vector of data representing the 'Condition' column in the experiment.</p>
</td></tr>
<tr><td><code id="loadData_+3A_promptlist">promptList</code></td>
<td>
<p>A character vector of the main prompt (usually experiment items).</p>
</td></tr>
<tr><td><code id="loadData_+3A_header">header</code></td>
<td>
<p>A logical value indicating if the output data.frame should include column headers (default is TRUE).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with the processed columns 'Run', 'Trial', 'Item', 'Condition', and 'Prompt', ready for use in experiments.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
df &lt;- data.frame(
Run = c(1,2),
Item = c(1,2),
Condition = c(1,2),
TargetPrompt = c("1","2")
)
ExperimentItem=loadData(df$Run,df$Item,df$Condition,promptList = df$TargetPrompt)

</code></pre>

<hr>
<h2 id='magicTokenizer'>magicTokenizer</h2><span id='topic+magicTokenizer'></span>

<h3>Description</h3>

<p>This function provides the number of tokens in a specified text, acting as a wrapper for an internal tokenizer function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>magicTokenizer(text)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="magicTokenizer_+3A_text">text</code></td>
<td>
<p>A character string: the text for which the number of tokens is required.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the number of tokens in the provided text.
</p>

<hr>
<h2 id='preCheck'>Step4: Pre-check for token usage in experiment design.</h2><span id='topic+preCheck'></span>

<h3>Description</h3>

<p>Configures experimental parameters before execution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>preCheck(
  data,
  checkToken = FALSE,
  systemPrompt = "",
  max_tokens = 500,
  temperature = 1,
  top_p = 1,
  n = 1,
  modality = "base",
  imgDetail = "auto"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="preCheck_+3A_data">data</code></td>
<td>
<p>A data.frame that has been structured by the 'experimentDesign' function, containing the experimental setup.</p>
</td></tr>
<tr><td><code id="preCheck_+3A_checktoken">checkToken</code></td>
<td>
<p>Whether to perform token count check, select TRUE to submit your experiment to our server's tokenizer for token count check, the default selection is FALSE (i.e., no token check will be performed, but you need to manually check if the number of tokens exceeds the model limit to avoid errors in the experiment).</p>
</td></tr>
<tr><td><code id="preCheck_+3A_systemprompt">systemPrompt</code></td>
<td>
<p>The system prompt text used in the chatGPT model interaction. If left empty, a space character is assumed.</p>
</td></tr>
<tr><td><code id="preCheck_+3A_max_tokens">max_tokens</code></td>
<td>
<p>The maximum number of tokens allowed for the model's response, default is 500.</p>
</td></tr>
<tr><td><code id="preCheck_+3A_temperature">temperature</code></td>
<td>
<p>The temperature setting for the chatGPT model, controlling randomness. Default is 0.7.</p>
</td></tr>
<tr><td><code id="preCheck_+3A_top_p">top_p</code></td>
<td>
<p>The top_p setting for the chatGPT model, controlling the diversity of responses. Default is 0.9.</p>
</td></tr>
<tr><td><code id="preCheck_+3A_n">n</code></td>
<td>
<p>The number of model responses per prompt, default is 1. Relevant only if 'oneTrialMode' is TRUE.</p>
</td></tr>
<tr><td><code id="preCheck_+3A_modality">modality</code></td>
<td>
<p>The default mode of GPT is &quot;base,&quot; with &quot;img&quot; as an optional choice.</p>
</td></tr>
<tr><td><code id="preCheck_+3A_imgdetail">imgDetail</code></td>
<td>
<p>The image quality of the img modality is set to auto by default, with low/high as selectable options.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the original data and the parameters for the chatGPT model interaction, confirming that the setup has passed the token checks or indicating issues if found.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
df &lt;- data.frame(
Run = c(1,2),
Item = c(1,2),
Condition = c(1,2),
TargetPrompt = c("1","2")
)

ExperimentItem=loadData(df$Run,df$Item,df$Condition,promptList = df$TargetPrompt)

Design=experimentDesign(ExperimentItem,Step=1,random = TRUE)

gptConfig=preCheck(Design, systemPrompt="You are a participant in a psycholinguistic experiment",
                    max_tokens=10,temperature=0.7,top_p=1,n=1,modality='base',imgDetail="low")

</code></pre>

<hr>
<h2 id='runExperiment'>Run an Experiment Based on the Configuration</h2><span id='topic+runExperiment'></span>

<h3>Description</h3>

<p>Executes the experiment and saves the results to an Excel file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runExperiment(gptConfig, savePath = "./output.xlsx")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="runExperiment_+3A_gptconfig">gptConfig</code></td>
<td>
<p>A list containing the configuration for the language model, including the system prompt,
model specifications, and token settings.</p>
</td></tr>
<tr><td><code id="runExperiment_+3A_savepath">savePath</code></td>
<td>
<p>The file path where the experiment results will be saved in Excel format.
Defaults to './output.xlsx' in the current working directory.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function does not return a value but saves the experiment results to the specified Excel file.
Upon completion, &quot;Done.&quot; will be printed to the console.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

runExperiment(Experiment_config,"./output.xlsx")

#The first argument Experiment_config is generated by preCheck() function.

Experiment_config &lt;- preCheck(data)

## End(Not run)
</code></pre>

<hr>
<h2 id='setKey'>Step1: Set model's API key and url.</h2><span id='topic+setKey'></span>

<h3>Description</h3>

<p>This function allows users to set and verify an API key for data collection. You can change the default api_url for open-source models' API.
</p>
<p>todo
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setKey(api_key, api_url = "https://api.openai.com/v1/chat/completions", model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setKey_+3A_api_key">api_key</code></td>
<td>
<p>A character string: the user's OpenAI/huggingface/other API key.Please fill 'NA' for self-deployed models.</p>
</td></tr>
<tr><td><code id="setKey_+3A_api_url">api_url</code></td>
<td>
<p>A character string: the user's OpenAI/huggingface/other url .default is OpenAI.</p>
</td></tr>
<tr><td><code id="setKey_+3A_model">model</code></td>
<td>
<p>A character string: specify the model version.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Prints a message to the console indicating whether the API key setup was successful.
If the setup fails, the function stops with an error message.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set_key(api_key="YOUR_API_KEY", api_url="api.openai.com/v1/chat/completions",model="gpt-3.5-turbo")

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
