<!DOCTYPE html><html><head><title>Help for package iBART</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {iBART}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#catalysis'><p>Single-Atom Catalysis Data</p></a></li>
<li><a href='#generate_unit'><p>A helper function to generate unit for iBART input</p></a></li>
<li><a href='#iBART'><p>iBART descriptor selection</p></a></li>
<li><a href='#iBART_real_data'><p>iBART Real Data Result</p></a></li>
<li><a href='#iBART_sim'><p>iBART Simulation Result</p></a></li>
<li><a href='#k_var_model'><p>Best subset selection for linear regression</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Iterative Bayesian Additive Regression Trees Descriptor
Selection Method</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Shengbin Ye &lt;sy53@rice.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>A statistical method based on Bayesian Additive Regression Trees with Global 
    Standard Error Permutation Test (BART-G.SE) for descriptor selection 
    and symbolic regression. It finds the symbolic formula of the regression function 
    y=f(x) as described in Ye, Senftle, and Li (2023) &lt;<a href="https://arxiv.org/abs/2110.10195">arXiv:2110.10195</a>&gt;.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/mattsheng/iBART">https://github.com/mattsheng/iBART</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/mattsheng/iBART/issues">https://github.com/mattsheng/iBART/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>bartMachine (&ge; 1.2.6), glmnet (&ge; 4.1-1), foreach, stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, ggplot2, ggpubr</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>Java (&gt;= 8.0)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-14 03:18:59 UTC; matts</td>
</tr>
<tr>
<td>Author:</td>
<td>Shengbin Ye <a href="https://orcid.org/0000-0001-8767-2595"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre, cph],
  Meng Li [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-14 17:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='catalysis'>Single-Atom Catalysis Data</h2><span id='topic+catalysis'></span>

<h3>Description</h3>

<p>Single-Atom Catalysis Data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>catalysis
</code></pre>


<h3>Format</h3>

<p>A list with 4 objects:
</p>

<dl>
<dt>X</dt><dd><p>Primary feature matrix: physical properties of transition metals and oxide supports</p>
</dd>
<dt>y</dt><dd><p>Reponse variable: binding energy of metal/oxide pairs</p>
</dd>
<dt>head</dt><dd><p>Column names of X</p>
</dd>
<dt>unit</dt><dd><p>Unit of columns of X</p>
</dd>
</dl>


<hr>
<h2 id='generate_unit'>A helper function to generate unit for iBART input</h2><span id='topic+generate_unit'></span>

<h3>Description</h3>

<p>A helper function to generate unit for iBART input
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate_unit(unit, dimension)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generate_unit_+3A_unit">unit</code></td>
<td>
<p>A vector of unit of the primary features. For example, unit &lt;- c(&quot;cm&quot;, &quot;s&quot;). Then the unit of <code class="reqn">x1</code> is centimeter and the unit of <code class="reqn">x2</code> is second.</p>
</td></tr>
<tr><td><code id="generate_unit_+3A_dimension">dimension</code></td>
<td>
<p>A vector of dimension of the units. For example, unit &lt;- c(&quot;cm&quot;, &quot;s&quot;) and dimension &lt;- c(2, 1) mean that the unit of <code class="reqn">x1</code> is square centimeter and the unit of <code class="reqn">x2</code> is second.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list that contains unit and dimension information.
</p>

<hr>
<h2 id='iBART'>iBART descriptor selection</h2><span id='topic+iBART'></span>

<h3>Description</h3>

<p>Finds a symbolic formula for the regression function <code class="reqn">y=f(X)</code> using <code class="reqn">(y,X)</code> as inputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iBART(
  X = NULL,
  y = NULL,
  head = NULL,
  unit = NULL,
  BART_var_sel_method = "global_se",
  num_trees = 20,
  num_burn_in = 10000,
  num_iterations_after_burn_in = 5000,
  num_reps_for_avg = 10,
  num_permute_samples = 50,
  type.measure = "deviance",
  nfolds = 10,
  nlambda = 100,
  relax = FALSE,
  gamma = c(0, 0.25, 0.5, 0.75, 1),
  opt = c("binary", "unary", "binary"),
  sin_cos = FALSE,
  apply_pos_opt_on_neg_x = TRUE,
  hold = 0,
  pre_screen = TRUE,
  corr_screen = TRUE,
  out_sample = FALSE,
  train_idx = NULL,
  train_ratio = 1,
  Lzero = TRUE,
  parallel = FALSE,
  K = ifelse(Lzero, 5, 0),
  aic = FALSE,
  standardize = TRUE,
  writeLog = FALSE,
  verbose = TRUE,
  count = NULL,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="iBART_+3A_x">X</code></td>
<td>
<p>Input matrix of primary features <code class="reqn">X</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_y">y</code></td>
<td>
<p>Response variable <code class="reqn">y</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_head">head</code></td>
<td>
<p>Optional: name of primary features.</p>
</td></tr>
<tr><td><code id="iBART_+3A_unit">unit</code></td>
<td>
<p>Optional: units and their respective dimensions of primary features. This is used to perform dimension analysis for generated descriptors to avoid generating unphyiscal descriptors, such as <code class="reqn">size + size^2</code>. See <code>generate_dimension()</code> for details.</p>
</td></tr>
<tr><td><code id="iBART_+3A_bart_var_sel_method">BART_var_sel_method</code></td>
<td>
<p>Variable selection criterion used in BART. Three options are available: (1) &quot;global_se&quot;, (2) &quot;global_max&quot;, (3) &quot;local&quot;. The default is &quot;global_se&quot;. See <code>var_selection_by_permute</code> in <code>R</code> package <code>bartMachine</code> for more detail.</p>
</td></tr>
<tr><td><code id="iBART_+3A_num_trees">num_trees</code></td>
<td>
<p>BART parameter: number of trees to be grown in the sum-of-trees model. If you want different values for each iteration of BART, input a vector of length equal to number of iterations. Default is <code>num_trees = 20</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_num_burn_in">num_burn_in</code></td>
<td>
<p>BART parameter: number of MCMC samples to be discarded as &ldquo;burn-in&quot;. If you want different values for each iteration of BART, input a vector of length equal to number of iterations. Default is <code>num_burn_in = 10000</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_num_iterations_after_burn_in">num_iterations_after_burn_in</code></td>
<td>
<p>BART parameter: number of MCMC samples to draw from the posterior distribution of <code class="reqn">hat{f}(x)</code>. If you want different values for each iteration of BART, input a vector of length equal to number of iterations. Default is <code>num_iterations_after_burn_in = 5000</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_num_reps_for_avg">num_reps_for_avg</code></td>
<td>
<p>BART parameter: number of replicates to over over to for the BART model's variable inclusion proportions. If you want different values for each iteration of BART, input a vector of length equal to number of iterations. Default is <code>num_reps_for_avg = 10</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_num_permute_samples">num_permute_samples</code></td>
<td>
<p>BART parameter: number of permutations of the response to be made to generate the “null” permutation distribution. If you want different values for each iteration of BART, input a vector of length equal to number of iterations. Default is <code>num_permute_samples = 50</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_type.measure">type.measure</code></td>
<td>
<p><code>glmnet</code> parameter: loss to use for cross-validation. The default is <code>type.measure="deviance"</code>, which uses squared-error for Gaussian models (a.k.a <code>type.measure="mse" there</code>). <code>type.measure="mae"</code> (mean absolute error) can be used also.</p>
</td></tr>
<tr><td><code id="iBART_+3A_nfolds">nfolds</code></td>
<td>
<p><code>glmnet</code> parameter: number of folds - default is 10. Smallest value allowable is <code>nfolds=3</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_nlambda">nlambda</code></td>
<td>
<p><code>glmnet</code> parameter: the number of <code>lambda</code> values - default is 100.</p>
</td></tr>
<tr><td><code id="iBART_+3A_relax">relax</code></td>
<td>
<p><code>glmnet</code> parameter: If <code>TRUE</code>, then CV is done with respect to the mixing parameter <code>gamma</code> as well as <code>lambda</code>. Default is <code>relax=FALSE</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_gamma">gamma</code></td>
<td>
<p><code>glmnet</code> parameter: the values of the parameter for mixing the relaxed fit with the regularized fit, between 0 and 1; default is <code>gamma = c(0, 0.25, 0.5, 0.75, 1)</code></p>
</td></tr>
<tr><td><code id="iBART_+3A_opt">opt</code></td>
<td>
<p>A vector of operation order. For example, <code>opt = c("unary", "binary", "unary")</code> will apply unary operators, then binary operators, then unary operators. Available operator sets are <code>"unary"</code>, <code>"binary"</code>, and <code>"all"</code>, where <code>"all"</code> is the union of <code>"unary"</code> and <code>"binary"</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_sin_cos">sin_cos</code></td>
<td>
<p>Logical flag for using <code class="reqn">sin(\pi*x)</code> and <code class="reqn">cos(\pi*x)</code> to generate descriptors. This is useful if you think there is periodic relationship between predictors and response. Default is <code>sin_cos = FALSE</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_apply_pos_opt_on_neg_x">apply_pos_opt_on_neg_x</code></td>
<td>
<p>Logical flag for applying non-negative-valued operators, such as <code class="reqn">\sqrt x</code> and <code class="reqn">log(x)</code>, when some values of <code class="reqn">x</code> is negative. If <code>apply_pos_opt_on_neg_x == TRUE</code>, apply absolute value operator first then non-negative-valued operator, i.e. generate <code class="reqn">\sqrt |x|</code> and <code class="reqn">log(|x|)</code> instead. Default is <code>apply_pos_opt_on_neg_x = TRUE</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_hold">hold</code></td>
<td>
<p>Number of iterations to hold. This allows iBART to run consecutive operator transformations before screening. Note <code>hold = 0</code> is equivalent to no skipping of variable selection in each iBART iterations. It should be less than <code>iter</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_pre_screen">pre_screen</code></td>
<td>
<p>Logical flag for pre-screening the primary features X using BART. Only selected primary features will be used to generate descriptors. Note that <code>pre_screen = FALSE</code> is equivalent to <code>hold = 1</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_corr_screen">corr_screen</code></td>
<td>
<p>Logical flag for screening out primary features that are independet of the response variable <code class="reqn">y</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_out_sample">out_sample</code></td>
<td>
<p>Logical flag for out of sample assessment. Default is <code>out_sample = FALSE</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_train_idx">train_idx</code></td>
<td>
<p>Numerical vector storing the row indices for training data. Please set <code>out_sample = TRUE</code> if you supplied <code>train_idx</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_train_ratio">train_ratio</code></td>
<td>
<p>Proportion of data used to train model. Value must be between (0,1]. This is only needed when <code>out_sample = TRUE</code> and <code>train_idx == NULL</code>. Default is <code>train_ratio = 1</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_lzero">Lzero</code></td>
<td>
<p>Logical flag for L-zero variable selection. Default is <code>Lzero = TRUE</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_parallel">parallel</code></td>
<td>
<p>Logical flag for parallel L-zero variable selection. Default is <code>parallel = FALSE</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_k">K</code></td>
<td>
<p>If <code>Lzero == TRUE</code>, <code>K</code> sets the maximum number of descriptors to be selected.</p>
</td></tr>
<tr><td><code id="iBART_+3A_aic">aic</code></td>
<td>
<p>If <code>Lzero == TRUE</code>, logical flag for selecting best number of descriptors using AIC. Possible number of descriptors are <code class="reqn">1 \le k \le K</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_standardize">standardize</code></td>
<td>
<p>Logical flag for data standardization prior to model fitting in BART and LASSO. Default is <code>standardize = TRUE</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_writelog">writeLog</code></td>
<td>
<p>Logical flag for writing log file to working directory. The log file will contain information such as the descriptors selected by iBART, RMSE of the linear model build on the selected descriptors, etc. Default is <code>writeLog = FALSE</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_verbose">verbose</code></td>
<td>
<p>Logical flag for printing progress to console. Default is <code>verbose = TRUE</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_count">count</code></td>
<td>
<p>Internal parameter. Default is <code>count = NULL</code>.</p>
</td></tr>
<tr><td><code id="iBART_+3A_seed">seed</code></td>
<td>
<p>Optional: sets the seed in both R and Java. Default is <code>seed = NULL</code> which does not set the seed in R nor Java.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of iBART output.
</p>
<table>
<tr><td><code>iBART_model</code></td>
<td>
<p>The LASSO output of the last iteration of iBART. The predictors with non-zero coefficient are called the iBART selected descriptors.</p>
</td></tr>
<tr><td><code>X_selected</code></td>
<td>
<p>The numerical values of the iBART selected descriptors.</p>
</td></tr>
<tr><td><code>descriptor_names</code></td>
<td>
<p>The names of the iBART selected descriptors.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>Coefficients of the iBART model. The first element is an intercept.</p>
</td></tr>
<tr><td><code>X_train</code></td>
<td>
<p>The training matrix used in the last iteration.</p>
</td></tr>
<tr><td><code>X_test</code></td>
<td>
<p>The testing matrix used in the last iteration.</p>
</td></tr>
<tr><td><code>iBART_gen_size</code></td>
<td>
<p>The number of descriptors generated by iBART in each iteration.</p>
</td></tr>
<tr><td><code>iBART_sel_size</code></td>
<td>
<p>The number of descriptors selected by iBART in each iteration.</p>
</td></tr>
<tr><td><code>iBART_in_sample_RMSE</code></td>
<td>
<p>In sample RMSE of the LASSO model.</p>
</td></tr>
<tr><td><code>iBART_out_sample_RMSE</code></td>
<td>
<p>Out of sample RMSE of the LASSO model if <code>out_sample == TRUE</code>.</p>
</td></tr>
<tr><td><code>Lzero_models</code></td>
<td>
<p>The <code class="reqn">l_0</code>-penalized regression models fitted on the iBART selected descriptors for <code class="reqn">1 \le k \le K</code>.</p>
</td></tr>
<tr><td><code>Lzero_names</code></td>
<td>
<p>The name of the best <code class="reqn">k</code>D descriptors selected by the <code class="reqn">l_0</code>-penalized regression model for <code class="reqn">1 \le k \le K</code>.</p>
</td></tr>
<tr><td><code>Lzero_in_sample_RMSE</code></td>
<td>
<p>In sample RMSE of the <code class="reqn">l_0</code>-penalized regression model for <code class="reqn">1 \le k \le K</code>.</p>
</td></tr>
<tr><td><code>Lzero_out_sample_RMSE</code></td>
<td>
<p>Out of sample RMSE of the <code class="reqn">l_0</code>-penalized regression model for <code class="reqn">1 \le k \le K</code> if <code>out_sample == TRUE</code>.</p>
</td></tr>
<tr><td><code>Lzero_AIC_model</code></td>
<td>
<p>The best <code class="reqn">l_0</code>-penalized regression model selected by AIC.</p>
</td></tr>
<tr><td><code>Lzero_AIC_names</code></td>
<td>
<p>The best <code class="reqn">k</code>D descriptors where <code class="reqn">1 \le k \le K</code> is chosen via AIC.</p>
</td></tr>
<tr><td><code>Lzero_AIC_in_sample_RMSE</code></td>
<td>
<p>In sample RMSE of the best <code class="reqn">l_0</code>-penalized regression models chosen by AIC.</p>
</td></tr>
<tr><td><code>Lzero_AIC_out_sample_RMSE</code></td>
<td>
<p>Out of sample RMSE of the best <code class="reqn">l_0</code>-penalized regression models chosen by AIC if <code>out_sample == TRUE</code>.</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>
<p>Runtime in second.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Shengbin Ye
</p>


<h3>References</h3>

<p>Ye, S., Senftle, T.P., and Li, M. (2023) <em>Operator-induced structural variable selection for identifying materials genes</em>, <a href="https://arxiv.org/abs/2110.10195">https://arxiv.org/abs/2110.10195</a>.
</p>

<hr>
<h2 id='iBART_real_data'>iBART Real Data Result</h2><span id='topic+iBART_real_data'></span>

<h3>Description</h3>

<p>iBART result in the real data vignette
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iBART_real_data
</code></pre>


<h3>Format</h3>

<p>A list of iBART outputs
</p>

<dl>
<dt>iBART_model</dt><dd><p>A cv.glmnet object storing the iBART selected model</p>
</dd>
</dl>
<p>...

</p>

<hr>
<h2 id='iBART_sim'>iBART Simulation Result</h2><span id='topic+iBART_sim'></span>

<h3>Description</h3>

<p>iBART result in the simulation vignette
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iBART_sim
</code></pre>


<h3>Format</h3>

<p>A list of iBART outputs
</p>

<dl>
<dt>iBART_model</dt><dd><p>A cv.glmnet object storing the iBART selected model</p>
</dd>
</dl>
<p>...

</p>

<hr>
<h2 id='k_var_model'>Best subset selection for linear regression</h2><span id='topic+k_var_model'></span>

<h3>Description</h3>

<p>Best subset selection for linear regression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_var_model(
  X_train,
  y_train,
  X_test = NULL,
  y_test = NULL,
  k = 1,
  parallel = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_var_model_+3A_x_train">X_train</code></td>
<td>
<p>The design matrix used during training.</p>
</td></tr>
<tr><td><code id="k_var_model_+3A_y_train">y_train</code></td>
<td>
<p>The response variable used during training.</p>
</td></tr>
<tr><td><code id="k_var_model_+3A_x_test">X_test</code></td>
<td>
<p>The design matrix used during testing. Default is <code>X_test = NULL</code> and full data will be used to train the best subset linear regression model.</p>
</td></tr>
<tr><td><code id="k_var_model_+3A_y_test">y_test</code></td>
<td>
<p>The response variable used during testing. Default is <code>y_test = NULL</code> and full data will be used to train the best subset linear regression model.</p>
</td></tr>
<tr><td><code id="k_var_model_+3A_k">k</code></td>
<td>
<p>The maximum number of predictors allowed in the model. For example, <code>k = 5</code> will produce the best model 5 predictors.</p>
</td></tr>
<tr><td><code id="k_var_model_+3A_parallel">parallel</code></td>
<td>
<p>Logical flag for parallelization. Default is <code>parallel = FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of outputs.
</p>
<table>
<tr><td><code>models</code></td>
<td>
<p>An <code>lm</code> object storing the best k-predictor linear model.</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>The variable name of the best k predictors.</p>
</td></tr>
<tr><td><code>rmse_in</code></td>
<td>
<p>In-sample RMSE of the model.</p>
</td></tr>
<tr><td><code>rmse_out</code></td>
<td>
<p>Out-of-sample RMSE of the model.</p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
