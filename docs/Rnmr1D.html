<!DOCTYPE html><html><head><title>Help for package Rnmr1D</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Rnmr1D}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#checkMacroCmdFile'><p>checkMacroCmdFile</p></a></li>
<li><a href='#detectCores'><p>detectCores</p></a></li>
<li><a href='#doProcCmd'><p>doProcCmd</p></a></li>
<li><a href='#doProcessing'><p>doProcessing</p></a></li>
<li><a href='#generateMetadata'><p>generateMetadata</p></a></li>
<li><a href='#getBucketsDataset'><p>getBucketsDataset</p></a></li>
<li><a href='#getBucketsTable'><p>getBucketsTable</p></a></li>
<li><a href='#getClusters'><p>getClusters</p></a></li>
<li><a href='#getMergedDataset'><p>getMergedDataset</p></a></li>
<li><a href='#getSnrDataset'><p>getSnrDataset</p></a></li>
<li><a href='#getSpectraData'><p>getSnrDataset</p></a></li>
<li><a href='#ggplotClusters'><p>ggplotClusters</p></a></li>
<li><a href='#ggplotCriterion'><p>ggplotCriterion</p></a></li>
<li><a href='#ggplotLoadings'><p>plotLoadings</p></a></li>
<li><a href='#ggplotPlotly'><p>ggplotPlotly</p></a></li>
<li><a href='#ggplotScores'><p>ggplotScores</p></a></li>
<li><a href='#plotClusters'><p>plotClusters</p></a></li>
<li><a href='#plotCriterion'><p>plotCriterion</p></a></li>
<li><a href='#plotLoadings'><p>plotLoadings</p></a></li>
<li><a href='#plotScores'><p>plotScores</p></a></li>
<li><a href='#plotSpecMat'><p>plotSpecMat Overlaid/Stacked Plot</p></a></li>
<li><a href='#RWrapperCMD1D'><p>RWrapperCMD1D</p></a></li>
<li><a href='#setLogFile'><p>setLogFile</p></a></li>
<li><a href='#setPPMbounds'><p>setPPMbounds</p></a></li>
<li><a href='#Spec1rDoProc'><p>Spec1rDoProc</p></a></li>
<li><a href='#Spec1rProcpar'><p>Spec1rProcpar</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Perform the Complete Processing of a Set of Proton Nuclear
Magnetic Resonance Spectra</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-04-13</td>
</tr>
<tr>
<td>Copyright:</td>
<td>Institut national de recherche pour l’agriculture,
l’alimentation et l’environnement (INRAE)</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/INRA/Rnmr1D">https://github.com/INRA/Rnmr1D</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Daniel Jacob &lt;daniel.jacob@inrae.fr&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Perform the complete processing of a set of proton nuclear magnetic resonance spectra from the free induction decay (raw data) and based on a processing sequence (macro-command file). An additional file specifies all the spectra to be considered by associating their sample code as well as the levels of experimental factors to which they belong. More detail can be found in Jacob et al. (2017) &lt;<a href="https://doi.org/10.1007%2Fs11306-017-1178-y">doi:10.1007/s11306-017-1178-y</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.12.7), base64enc (&ge; 0.1), MASS(&ge; 7.3), Matrix,
methods, scales, doParallel (&ge; 1.0.11), foreach (&ge; 1.4.4),
igraph (&ge; 1.2.1), impute (&ge; 1.54.0), MassSpecWavelet (&ge;
1.46.0), ptw (&ge; 1.9), signal (&ge; 0.7), XML (&ge; 3.98), ggplot2
(&ge; 3.0.0), plotly (&ge; 4.8.0), plyr (&ge; 1.8.4), minqa(&ge; 1.2.4)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-04-13 06:32:57 UTC; djacob</td>
</tr>
<tr>
<td>Author:</td>
<td>Daniel Jacob <a href="https://orcid.org/0000-0002-6687-7169"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [cre, aut],
  Catherine Deborde [ctb],
  Marie Lefebvre [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-04-13 07:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='checkMacroCmdFile'>checkMacroCmdFile</h2><span id='topic+checkMacroCmdFile'></span>

<h3>Description</h3>

<p><code>checkMacroCmdFile</code> Check if the macro-commands included in the input file (commandfile) 
are compliant with the allowed commands.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkMacroCmdFile(commandfile)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checkMacroCmdFile_+3A_commandfile">commandfile</code></td>
<td>
<p>The macro-commands file - the allowed commands are : 'align', 'warp', 
'clupa', 'gbaseline', 'baseline', 'qnmrbline', 'airpls', 'binning', 'calibration', 
'normalisation', 'denoising', 'bucket', 'zero'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>return 1 if the macro-commands included in the input file are compliant, 0 if not.
</p>


<h3>See Also</h3>

<p>the NMRProcFlow online documentation <a href="https://nmrprocflow.org/">https://nmrprocflow.org/</a> and especially 
the Macro-command Reference Guide (<a href="https://nmrprocflow.org/themes/pdf/Macrocommand.pdf">https://nmrprocflow.org/themes/pdf/Macrocommand.pdf</a>)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data_dir &lt;- system.file("extra", package = "Rnmr1D")
CMDFILE &lt;- file.path(data_dir, "NP_macro_cmd.txt")
ret &lt;- checkMacroCmdFile(CMDFILE)

</code></pre>

<hr>
<h2 id='detectCores'>detectCores</h2><span id='topic+detectCores'></span>

<h3>Description</h3>

<p><code>detectCores</code> is simply a shortcut for parallel::detectCores().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detectCores(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="detectCores_+3A_...">...</code></td>
<td>
<p>See <code>parallel::detectCores</code></p>
</td></tr>
</table>

<hr>
<h2 id='doProcCmd'>doProcCmd</h2><span id='topic+doProcCmd'></span>

<h3>Description</h3>

<p><code>doProcCmd</code> it process the Macro-commands string array specified at input.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>doProcCmd(specObj, cmdstr, ncpu = 1, debug = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="doProcCmd_+3A_specobj">specObj</code></td>
<td>
<p>a complex list return by <code>doProcessing</code> function. See the manual 
page of the <code><a href="#topic+doProcessing">doProcessing</a></code> function for more details on its structure.</p>
</td></tr>
<tr><td><code id="doProcCmd_+3A_cmdstr">cmdstr</code></td>
<td>
<p>the Macro-commands string array; See the Macro-command Reference Guide 
(<a href="https://nmrprocflow.org/themes/pdf/Macrocommand.pdf">https://nmrprocflow.org/themes/pdf/Macrocommand.pdf</a>) to have more details about 
macro-commands.</p>
</td></tr>
<tr><td><code id="doProcCmd_+3A_ncpu">ncpu</code></td>
<td>
<p>The number of cores [default: 1]</p>
</td></tr>
<tr><td><code id="doProcCmd_+3A_debug">debug</code></td>
<td>
<p>a boolean to specify if we want the function to be more verbose.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>specMat</code> : a 'specMat' object - See the manual page of the <code><a href="#topic+doProcessing">doProcessing</a></code> 
function for more details on its structure
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
    data_dir &lt;- system.file("extra", package = "Rnmr1D")
    CMDFILE &lt;- file.path(data_dir, "NP_macro_cmd.txt")
    SAMPLEFILE &lt;- file.path(data_dir, "Samples.txt")
    out &lt;- Rnmr1D::doProcessing(data_dir, cmdfile=CMDFILE, 
                                samplefile=SAMPLEFILE, ncpu=2)
# Apply an intelligent bucketing (AIBIN)
    specMat.new &lt;- Rnmr1D::doProcCmd(out, 
             c("bucket aibin 10.2 10.5 0.3 3 0", 
                 "9.5 4.9", 
                 "4.8 0.5", 
                 "EOL"
              ),ncpu=2, debug=TRUE)
    out$specMat &lt;- specMat.new

</code></pre>

<hr>
<h2 id='doProcessing'>doProcessing</h2><span id='topic+doProcessing'></span>

<h3>Description</h3>

<p><code>doProcessing</code> is the main function of this package. Indeed, this function performs 
the complete processing of a set of 1D NMR spectra from the FID (raw data) and based on a 
processing sequence (macro-command file). An additional file specifies all the spectra to 
be considered by associating their sample code as well as the levels of experimental 
factors to which they belong. In this way it is possible to select only a subset of spectra 
instead of the whole set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>doProcessing(
  path,
  cmdfile,
  samplefile = NULL,
  bucketfile = NULL,
  phcfile = NULL,
  ncpu = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="doProcessing_+3A_path">path</code></td>
<td>
<p>The full path of either the raw spectra directory on the disk</p>
</td></tr>
<tr><td><code id="doProcessing_+3A_cmdfile">cmdfile</code></td>
<td>
<p>The full path name of the Macro-commands file for processing (text format)</p>
</td></tr>
<tr><td><code id="doProcessing_+3A_samplefile">samplefile</code></td>
<td>
<p>The full path name of the Sample file (tabular format)</p>
</td></tr>
<tr><td><code id="doProcessing_+3A_bucketfile">bucketfile</code></td>
<td>
<p>The full path name of the file of bucket's zones (tabular format)</p>
</td></tr>
<tr><td><code id="doProcessing_+3A_phcfile">phcfile</code></td>
<td>
<p>The full path name of the phasing file for samples if required (tabular format)</p>
</td></tr>
<tr><td><code id="doProcessing_+3A_ncpu">ncpu</code></td>
<td>
<p>The number of cores [default: 1]</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>doProcessing</code> returns a list containing the following components:
</p>

<ul>
<li> <p><code>samples</code> : the samples matrix with the correspondence of the raw spectra, 
as well as the levels of the experimental factors if specified in the input.
</p>
</li>
<li> <p><code>factors</code> : the factors matrix with the corresponding factor names. 
At minimum, the list contains the Samplecode label corresponding to the samples without their 
group level.
</p>
</li>
<li> <p><code>rawids</code> : list of the full directories of the raw spectra (i.e. where the FID files 
are accessible)
</p>
</li>
<li> <p><code>infos</code> : list of the acquisition and processing parameters for each (raw) spectra.
</p>
</li>
<li> <p><code>specMat</code> : objects list  regarding the spectra data.
</p>

<ul>
<li> <p><code>int</code> : the matrix of the spectra data (<code>nspec</code> rows X <code>size</code> 
columns)
</p>
</li>
<li> <p><code>nspec</code> : the number of spectra
</p>
</li>
<li> <p><code>size</code> : the size (i.e number of points) of each spectra
</p>
</li>
<li> <p><code>ppm_min</code>, <code>ppm_max</code> : the minimum and the maximum ppm values of 
spectra
</p>
</li>
<li> <p><code>ppm</code> : the vector of the ppm values (<code>size</code> values)
</p>
</li>
<li> <p><code>dppm</code> : the ppm increment between each point
</p>
</li>
<li> <p><code>buckets_zones</code> : the matrix of the buckets zones including two columns 
(min and max) 
</p>
</li>
<li> <p><code>namesASintMax</code> : boolean - If TRUE, generate all output matrix with 
bucket names based on ppm values of the maximum of the average intensity of all spectra within
the ppm range of each bucket. If FALSE (default), then bucket names will be based on the ppm 
range center of each bucket.
</p>
</li></ul>

</li></ul>



<h3>See Also</h3>

<p>the NMRProcFlow online documentation <a href="https://nmrprocflow.org/">https://nmrprocflow.org/</a> and especially 
the Macro-command Reference Guide (<a href="https://nmrprocflow.org/themes/pdf/Macrocommand.pdf">https://nmrprocflow.org/themes/pdf/Macrocommand.pdf</a>)
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
    data_dir &lt;- system.file("extra", package = "Rnmr1D")
    cmdfile &lt;- file.path(data_dir, "NP_macro_cmd.txt")
    samplefile &lt;- file.path(data_dir, "Samples.txt")
    out &lt;- Rnmr1D::doProcessing(data_dir, cmdfile=cmdfile, 
                                samplefile=samplefile, ncpu=2)

</code></pre>

<hr>
<h2 id='generateMetadata'>generateMetadata</h2><span id='topic+generateMetadata'></span>

<h3>Description</h3>

<p><code>generateMetadata</code> Generate the metadata from the list of raw spectra namely the samples, the experimental factors and the list of selected raw spectra. Depending on whether the sample matrix is supplied as input or not,
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateMetadata(RAWDIR, procParams, samples = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generateMetadata_+3A_rawdir">RAWDIR</code></td>
<td>
<p>The full path of either the raw spectra directory on the disk</p>
</td></tr>
<tr><td><code id="generateMetadata_+3A_procparams">procParams</code></td>
<td>
<p>the list of processing parameters. First initialize this list with the <code>Spec1r.Procpar.default</code> list, then modify parameters depending of your spectra set.</p>
</td></tr>
<tr><td><code id="generateMetadata_+3A_samples">samples</code></td>
<td>
<p>the samples matrix with the correspondence of the raw spectra</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>generateMetadata</code> returns a list containing the following components:
</p>

<ul>
<li> <p><code>samples</code> : the samples matrix with the correspondence of the raw spectra, as well as the levels of the experimental factors if specified in the input.
</p>
</li>
<li> <p><code>factors</code> : the factors matrix with the corresponding factor names. At minimum, the list contains the Samplecode label corresponding to the samples without their group level.
</p>
</li>
<li> <p><code>rawids</code> : list of the full directories of the raw spectra (i.e. where the FID files are accessible)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data_dir &lt;- system.file("extra", package = "Rnmr1D")
samplefile &lt;- file.path(data_dir, "Samples.txt")
samples &lt;- read.table(samplefile, sep="\t", header=TRUE,stringsAsFactors=FALSE)
metadata &lt;- generateMetadata(data_dir, procParams=Spec1rProcpar, samples)

</code></pre>

<hr>
<h2 id='getBucketsDataset'>getBucketsDataset</h2><span id='topic+getBucketsDataset'></span>

<h3>Description</h3>

<p>Generates the matrix including the integrations of the areas defined by the buckets (columns) 
on each spectrum (rows)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getBucketsDataset(specObj, norm_meth = "none", zoneref = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getBucketsDataset_+3A_specobj">specObj</code></td>
<td>
<p>a complex list return by <code>doProcessing</code> function. See the manual page of the <code><a href="#topic+doProcessing">doProcessing</a></code> function for more details on its structure.</p>
</td></tr>
<tr><td><code id="getBucketsDataset_+3A_norm_meth">norm_meth</code></td>
<td>
<p>Normalization method. The possible values are : 'none', 'CSN' or 'PDN'. See below.</p>
</td></tr>
<tr><td><code id="getBucketsDataset_+3A_zoneref">zoneref</code></td>
<td>
<p>Specify the ppm zone of the internal reference (i.e. ERETIC) if applicable. default is NA.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Before bucket data export in order to make all spectra comparable with each other, the variations of the overall concentrations of samples have to be taken into account. We propose two normalization methods. In NMR metabolomics, the total intensity normalization (called the Constant Sum Normalization) is often used so that all spectra correspond to the same overall concentration. It simply consists in normalizing the total intensity of each individual spectrum to a same value. An other method called Probabilistic Quotient Normalization (Dieterle et al. 2006) assumes that biologically interesting concentration changes influence only parts of the NMR spectrum, while dilution effects will affect all metabolites signals. Probabilistic Quotient Normalization (PQN) starts by the calculation of a reference spectrum based on the median spectrum. Next, for each variable of interest the quotient of a given test spectrum and reference spectrum is calculated and the median of all quotients is estimated. Finally, all variables of the test spectrum are divided by the median quotient.
An internal reference can be used to normalize the data. For example, an electronic reference (ERETIC, see Akoka et al. 1999, or ERETIC2 generated with TopSpin software) can be used for this purpose. The integral value of each bucket will be divided by the integral value of the ppm range given as reference.
</p>


<h3>Value</h3>

<p>the data matrix
</p>


<h3>References</h3>


<p>Akoka S1, Barantin L, Trierweiler M. (1999) Concentration Measurement by Proton NMR 
Using the ERETIC Method, Anal. Chem 71(13):2554-7. doi: 10.1021/ac981422i.
</p>
<p>Dieterle F., Ross A., Schlotterbeck G. and Senn H. (2006). Probabilistic Quotient 
Normalization as Robust Method to Account for Dilution of Complex Biological Mixtures. 
Application in 1H NMR Metabonomics. Analytical Chemistry, 78:4281-4290.doi: 10.1021/ac051632c

</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
  data_dir &lt;- system.file("extra", package = "Rnmr1D")
  cmdfile &lt;- file.path(data_dir, "NP_macro_cmd.txt")
  samplefile &lt;- file.path(data_dir, "Samples.txt")
  out &lt;- Rnmr1D::doProcessing(data_dir, cmdfile=cmdfile, 
                                samplefile=samplefile, ncpu=2)
  outMat &lt;- getBucketsDataset(out, norm_meth='CSN')
 
</code></pre>

<hr>
<h2 id='getBucketsTable'>getBucketsTable</h2><span id='topic+getBucketsTable'></span>

<h3>Description</h3>

<p>Generates the buckets table
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getBucketsTable(specObj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getBucketsTable_+3A_specobj">specObj</code></td>
<td>
<p>a complex list return by <code>doProcessing</code> function. See the manual page of the <code><a href="#topic+doProcessing">doProcessing</a></code> function for more details on its structure.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the buckets table
</p>

<hr>
<h2 id='getClusters'>getClusters</h2><span id='topic+getClusters'></span>

<h3>Description</h3>

<p>From the data matrix generated from the integration of all bucket zones (columns) for each 
spectrum (rows), we can take advantage of the concentration variability of each compound in 
a series of samples by performing a clustering based on significant correlations that link 
these buckets together into clusters. Bucket Clustering based on either a lower threshold  
applied on correlations or a cutting value applied on a hierarchical tree of the variables 
(buckets) generated by an Hierarchical Clustering Analysis (HCA).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getClusters(data, method = "hca", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getClusters_+3A_data">data</code></td>
<td>
<p>the matrix including the integrations of the areas defined by the buckets (columns) 
on each spectrum (rows)</p>
</td></tr>
<tr><td><code id="getClusters_+3A_method">method</code></td>
<td>
<p>Clustering method of the buckets. Either 'corr' for 'correlation' or 'hca' for 
'hierarchical clustering analysis'.</p>
</td></tr>
<tr><td><code id="getClusters_+3A_...">...</code></td>
<td>
<p>Depending on the chosen method:
</p>

<ul>
<li> <p><code>corr</code> : cval, dC, ncpu
</p>
</li>
<li> <p><code>hca</code> :  vcutusr
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>At the bucketing step (see above),  we have chosen the intelligent bucketing, it means 
that each bucket exact matches with one resonance peak. Thanks to this, the buckets now 
have a strong chemical meaning, since the resonance peaks are the fingerprints of 
chemical compounds. However, to assign a chemical compound, several resonance peaks 
are generally required in 1D 1 H-NMR metabolic profiling. To generate relevant 
clusters (i.e. clusters possibly matching to chemical compounds), two approaches 
have been implemented:
</p>

<ul>
<li><p> Bucket Clustering based on a lower threshold  applied on correlations
</p>

<ul>
<li><p> In this approach an appropriate correlation threshold is applied on the correlation 
matrix before its cluster decomposition. Moreover, an improvement can be done by searching for 
a trade-off on a tolerance interval of the correlation threshold : from a fixed threshold of the 
correlation (cval), the clustering is calculated for the three values (cval-dC, cval, cval+dC), 
where dC is the tolerance interval of the correlation threshold. From these three sets of 
clusters, we establish a merger according to the following rules: 1) if a large cluster is 
broken, we keep the two resulting clusters. 2) If a small cluster disappears, the initial 
cluster is conserved. Generally, an interval of the correlation threshold included between 
0.002 and 0.01 gives good trade-off.
</p>
</li></ul>

</li>
<li><p> Bucket Clustering based on a hierarchical tree of the variables (buckets) generated 
by an Hierarchical Clustering Analysis (HCA)
</p>

<ul>
<li><p> In this approach a Hierachical Classification Analysis (HCA, <code><a href="stats.html#topic+hclust">hclust</a></code>) 
is applied on the data after calculating a matrix distance (&quot;euclidian&quot; by default). Then, a cut 
is applied on the tree (<code><a href="stats.html#topic+cutree">cutree</a></code>) resulting from <code><a href="stats.html#topic+hclust">hclust</a></code>, 
into several groups by specifying the cut height(s). For finding best cut value,  the cut height 
is chosen i) by testing several values equally spaced in a given range of the cut height, then, 
2) by keeping the one that gives the more cluster and by including most bucket variables. 
Otherwise, a cut value has to be specified by the user (vcutusr)
</p>
</li></ul>

</li></ul>



<h3>Value</h3>

<p><code>getClusters</code> returns a list containing the following components:
</p>

<ul>
<li> <p><code>vstats</code> Statistics that served to find the best value of the criterion (matrix)
</p>
</li>
<li> <p><code>clusters</code> List of  the ppm value corresponding to each cluster. the length of the list equal to number of clusters
</p>
</li>
<li> <p><code>clustertab</code> the associations matrix that gives for each cluster (column 2) the corresponding buckets (column 1)
</p>
</li>
<li> <p><code>params</code> List of parameters related to the chosen method for which the clustering was performed.
</p>
</li>
<li> <p><code>vcrit</code> Value of the (best/user) criterion, i.e correlation threshold for 'corr' method or the cut value for the 'hca' method.
</p>
</li>
<li> <p><code>indxopt</code> Index value within the vstats matrix corresponding to the criterion value (vcrit)
</p>
</li></ul>



<h3>References</h3>


<p>Jacob D., Deborde C. and Moing A. (2013) An efficient spectra processing method for metabolite identification from 1H-NMR metabolomics data.
Analytical and Bioanalytical Chemistry 405(15) 5049-5061 doi: 10.1007/s00216-013-6852-y

</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
  data_dir &lt;- system.file("extra", package = "Rnmr1D")
  cmdfile &lt;- file.path(data_dir, "NP_macro_cmd.txt")
  samplefile &lt;- file.path(data_dir, "Samples.txt")
  out &lt;- Rnmr1D::doProcessing(data_dir, cmdfile=cmdfile, 
                                samplefile=samplefile, ncpu=2)
  outMat &lt;- getBucketsDataset(out, norm_meth='CSN')
  clustcorr &lt;- getClusters(outMat, method='corr', cval=0, dC=0.003, ncpu=2)
  clusthca &lt;- getClusters(outMat, method='hca', vcutusr=0)
 
</code></pre>

<hr>
<h2 id='getMergedDataset'>getMergedDataset</h2><span id='topic+getMergedDataset'></span>

<h3>Description</h3>

<p>merged variables for each cluster (based on their average)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getMergedDataset(data, clustObj, onlycluster = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getMergedDataset_+3A_data">data</code></td>
<td>
<p>the matrix including the integrations of the areas defined by the buckets (columns)
on each spectrum (rows)</p>
</td></tr>
<tr><td><code id="getMergedDataset_+3A_clustobj">clustObj</code></td>
<td>
<p>a list generated by the <code>getClusters</code> function</p>
</td></tr>
<tr><td><code id="getMergedDataset_+3A_onlycluster">onlycluster</code></td>
<td>
<p>boolean - specifies if the merged data matrix at output must only contain 
the merged clusters (TRUE) or if it must also contain the buckets that are not include within a 
cluster (FALSE)</p>
</td></tr>
</table>

<hr>
<h2 id='getSnrDataset'>getSnrDataset</h2><span id='topic+getSnrDataset'></span>

<h3>Description</h3>

<p>Generates the Signal-Noise-Ratio dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getSnrDataset(specObj, zone_noise = c(10.2, 10.5), ratio = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getSnrDataset_+3A_specobj">specObj</code></td>
<td>
<p>a complex list return by <code>doProcessing</code> function. 
See the manual page of the <code><a href="#topic+doProcessing">doProcessing</a></code> function for more details on its structure.</p>
</td></tr>
<tr><td><code id="getSnrDataset_+3A_zone_noise">zone_noise</code></td>
<td>
<p>Specify a ppm range of noisy zone default is c(10.2,10.5)</p>
</td></tr>
<tr><td><code id="getSnrDataset_+3A_ratio">ratio</code></td>
<td>
<p>boolean; TRUE for output Signal-Noise Ratio, or FALSE to output maximum value of 
each bucket and in addition, the estimate noise as a separate column</p>
</td></tr>
</table>


<h3>Details</h3>

<p>whatever the bucketing approach used, the Signal-to-Noise ratio is a good quality indicator. 
Thus, it is possible to check buckets based on their Signal-to-Noise ratio.
</p>


<h3>Value</h3>

<p>the Signal-Noise-Ratio matrix
</p>

<hr>
<h2 id='getSpectraData'>getSnrDataset</h2><span id='topic+getSpectraData'></span>

<h3>Description</h3>

<p>Generates the spectral data matrix. The first column indicates the value of ppm, then the following columns correspond to spectral data, one column per spectrum.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getSpectraData(specObj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getSpectraData_+3A_specobj">specObj</code></td>
<td>
<p>a complex list return by <code>doProcessing</code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the spectral data matrix
</p>

<hr>
<h2 id='ggplotClusters'>ggplotClusters</h2><span id='topic+ggplotClusters'></span>

<h3>Description</h3>

<p>Plots the boxplot of all clusters allowing to have an insight on the clusters distribution.
Plot based on ggplot2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ggplotClusters(data, clustObj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ggplotClusters_+3A_data">data</code></td>
<td>
<p>the matrix including the integrations of the areas defined by the buckets (columns)
on each spectrum (rows)</p>
</td></tr>
<tr><td><code id="ggplotClusters_+3A_clustobj">clustObj</code></td>
<td>
<p>a list generated by the <code>getClusters</code> function</p>
</td></tr>
</table>

<hr>
<h2 id='ggplotCriterion'>ggplotCriterion</h2><span id='topic+ggplotCriterion'></span>

<h3>Description</h3>

<p>Plots the curves that show the number of clusters, the number of clustered buckets and the 
size of biggest cluster  versus the criterion, namely the correlation threshold for the 'corr' 
method, the cutting value for the 'hca' method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ggplotCriterion(clustObj, reverse = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ggplotCriterion_+3A_clustobj">clustObj</code></td>
<td>
<p>a list generated by the <code>getClusters</code> function</p>
</td></tr>
<tr><td><code id="ggplotCriterion_+3A_reverse">reverse</code></td>
<td>
<p>indicates if the x axis need to be reversed</p>
</td></tr>
</table>

<hr>
<h2 id='ggplotLoadings'>plotLoadings</h2><span id='topic+ggplotLoadings'></span>

<h3>Description</h3>

<p>Plots the two components defined by pc1, pc2 of the matrix of variable loadings coming from a 
multivariable analysis, typically a Principal Component Analysis (PCA).
It can also plot the ellipses corresponding to each cluster defined by the associations matrix 
if not null. (in fact it is the main interest of this function).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ggplotLoadings(
  data,
  pc1 = 1,
  pc2 = 2,
  EV = NULL,
  associations = NULL,
  main = "Loadings",
  onlylabels = FALSE,
  highlabels = FALSE,
  gcontour = "ellipse"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ggplotLoadings_+3A_data">data</code></td>
<td>
<p>the matrix of variable loadings coming from a multivariable analysis, typically a Principal Component Analysis (PCA)</p>
</td></tr>
<tr><td><code id="ggplotLoadings_+3A_pc1">pc1</code></td>
<td>
<p>the fist component of the matrix of variable loadings to be plotted.</p>
</td></tr>
<tr><td><code id="ggplotLoadings_+3A_pc2">pc2</code></td>
<td>
<p>the second component of the matrix of variable loadings to be plotted.</p>
</td></tr>
<tr><td><code id="ggplotLoadings_+3A_ev">EV</code></td>
<td>
<p>Eigenvalues vector</p>
</td></tr>
<tr><td><code id="ggplotLoadings_+3A_associations">associations</code></td>
<td>
<p>the associations matrix that gives for each cluster (column 2) the corresponding buckets (column 1). See <code>getClusters</code></p>
</td></tr>
<tr><td><code id="ggplotLoadings_+3A_main">main</code></td>
<td>
<p>Change the default plot title on the rigth corner</p>
</td></tr>
<tr><td><code id="ggplotLoadings_+3A_onlylabels">onlylabels</code></td>
<td>
<p>if TRUE, put only the association names without drawing the cluster contours. Implies that association matrix is provided.</p>
</td></tr>
<tr><td><code id="ggplotLoadings_+3A_highlabels">highlabels</code></td>
<td>
<p>if TRUE, put the the association names in blue, and others in grey. Implies that association matrix is provided and fONLYLABELS equal to TRUE.</p>
</td></tr>
<tr><td><code id="ggplotLoadings_+3A_gcontour">gcontour</code></td>
<td>
<p>type of contour; possible values are : 'ellipse', 'polygon', 'ellipse2', 'none'</p>
</td></tr>
</table>

<hr>
<h2 id='ggplotPlotly'>ggplotPlotly</h2><span id='topic+ggplotPlotly'></span>

<h3>Description</h3>

<p>Translate 'ggplot2' graphs to an interactive plotly version
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ggplotPlotly(g, width = NULL, height = NULL, textposition = "right")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ggplotPlotly_+3A_g">g</code></td>
<td>
<p>The ggplot2 graph object to be translated into an interactive plotly version</p>
</td></tr>
<tr><td><code id="ggplotPlotly_+3A_width">width</code></td>
<td>
<p>Width of the plot in pixels (optional, defaults to automatic sizing).</p>
</td></tr>
<tr><td><code id="ggplotPlotly_+3A_height">height</code></td>
<td>
<p>Height of the plot in pixels (optional, defaults to automatic sizing)</p>
</td></tr>
<tr><td><code id="ggplotPlotly_+3A_textposition">textposition</code></td>
<td>
<p>Position of the labels on the graphs relative to the points. Possible values are : 'right', 'left', 'top' or 'buttom'</p>
</td></tr>
</table>

<hr>
<h2 id='ggplotScores'>ggplotScores</h2><span id='topic+ggplotScores'></span>

<h3>Description</h3>

<p>Plots the two components defined by pc1, pc2 of the matrix of scores coming from a 
multivariable analysis, typically a Principal Component Analysis (PCA).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ggplotScores(
  data,
  pc1 = 1,
  pc2 = 2,
  groups = NULL,
  EV = NULL,
  main = "Scores",
  glabels = FALSE,
  psize = 3,
  gcontour = "ellipse",
  params = list(cellipse = 0.95)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ggplotScores_+3A_data">data</code></td>
<td>
<p>the matrix of scores coming from a multivariable analysis, typically a Principal Component Analysis (PCA)</p>
</td></tr>
<tr><td><code id="ggplotScores_+3A_pc1">pc1</code></td>
<td>
<p>the fist component of the matrix of variable loadings to be plotted.</p>
</td></tr>
<tr><td><code id="ggplotScores_+3A_pc2">pc2</code></td>
<td>
<p>the second component of the matrix of variable loadings to be plotted.</p>
</td></tr>
<tr><td><code id="ggplotScores_+3A_groups">groups</code></td>
<td>
<p>the vector defining the factorial groups (same dimension as data rows)</p>
</td></tr>
<tr><td><code id="ggplotScores_+3A_ev">EV</code></td>
<td>
<p>Eigenvalues vector</p>
</td></tr>
<tr><td><code id="ggplotScores_+3A_main">main</code></td>
<td>
<p>the plot main title</p>
</td></tr>
<tr><td><code id="ggplotScores_+3A_glabels">glabels</code></td>
<td>
<p>boolean indicating if labels have to be plotted</p>
</td></tr>
<tr><td><code id="ggplotScores_+3A_psize">psize</code></td>
<td>
<p>point size</p>
</td></tr>
<tr><td><code id="ggplotScores_+3A_gcontour">gcontour</code></td>
<td>
<p>type of contour; possible values are : 'ellipse', 'polygon', 'ellipse2', 'none'</p>
</td></tr>
<tr><td><code id="ggplotScores_+3A_params">params</code></td>
<td>
<p>parameters depending on the contour type</p>
</td></tr>
</table>

<hr>
<h2 id='plotClusters'>plotClusters</h2><span id='topic+plotClusters'></span>

<h3>Description</h3>

<p>Plots the boxplot of all clusters allowing to have an insight on the clusters distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotClusters(
  data,
  clustObj,
  horiz = TRUE,
  main = "Boxplot by clusters (log10 transformed)"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotClusters_+3A_data">data</code></td>
<td>
<p>the matrix including the integrations of the areas defined by the buckets (columns)
on each spectrum (rows)</p>
</td></tr>
<tr><td><code id="plotClusters_+3A_clustobj">clustObj</code></td>
<td>
<p>a list generated by the <code>getClusters</code> function</p>
</td></tr>
<tr><td><code id="plotClusters_+3A_horiz">horiz</code></td>
<td>
<p>Boolean - Indicates if the plot is horizontal (TRUE) or vertical (FALSE)</p>
</td></tr>
<tr><td><code id="plotClusters_+3A_main">main</code></td>
<td>
<p>Main title of the plot</p>
</td></tr>
</table>

<hr>
<h2 id='plotCriterion'>plotCriterion</h2><span id='topic+plotCriterion'></span>

<h3>Description</h3>

<p>Plots the curves that show the number of clusters, the number of clustered buckets and the 
size of biggest cluster  versus the criterion, namely the correlation threshold for the 'corr' 
method, the cutting value for the 'hca' method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotCriterion(clustObj, reverse = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotCriterion_+3A_clustobj">clustObj</code></td>
<td>
<p>a list generated by the <code>getClusters</code> function</p>
</td></tr>
<tr><td><code id="plotCriterion_+3A_reverse">reverse</code></td>
<td>
<p>Boolean - indicates if x-axis must be reversed (TRUE) or nor (FALSE)</p>
</td></tr>
</table>

<hr>
<h2 id='plotLoadings'>plotLoadings</h2><span id='topic+plotLoadings'></span>

<h3>Description</h3>

<p>Plots the two components defined by pc1, pc2 of the matrix of variable loadings coming from a 
multivariable analysis, typically a Principal Component Analysis (PCA).
It can also plot the ellipses corresponding to each cluster defined by the associations matrix 
if not null. (in fact it is the main interest of this function).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotLoadings(
  data,
  pc1,
  pc2,
  associations = NULL,
  main = "Loadings",
  xlimu = c(min(data[, pc1]), max(data[, pc1])),
  ylimu = c(min(data[, pc2]), max(data[, pc2])),
  cexlabel = 1,
  pch = 20,
  ellipse = TRUE,
  level = 0.8
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotLoadings_+3A_data">data</code></td>
<td>
<p>the matrix of variable loadings coming from a multivariable analysis, typically a Principal Component Analysis (PCA)</p>
</td></tr>
<tr><td><code id="plotLoadings_+3A_pc1">pc1</code></td>
<td>
<p>the fist component of the matrix of variable loadings to be plotted.</p>
</td></tr>
<tr><td><code id="plotLoadings_+3A_pc2">pc2</code></td>
<td>
<p>the second component of the matrix of variable loadings to be plotted.</p>
</td></tr>
<tr><td><code id="plotLoadings_+3A_associations">associations</code></td>
<td>
<p>the associations matrix that gives for each cluster (column 2) the corresponding buckets (column 1)</p>
</td></tr>
<tr><td><code id="plotLoadings_+3A_main">main</code></td>
<td>
<p>Change the default plot title on the rigth corner</p>
</td></tr>
<tr><td><code id="plotLoadings_+3A_xlimu">xlimu</code></td>
<td>
<p>gives the limit to be plotted of the first component</p>
</td></tr>
<tr><td><code id="plotLoadings_+3A_ylimu">ylimu</code></td>
<td>
<p>gives the limit to be plotted of the second component</p>
</td></tr>
<tr><td><code id="plotLoadings_+3A_cexlabel">cexlabel</code></td>
<td>
<p>number indicating the amount by which plotting text and symbols should be scaled relative to the default.</p>
</td></tr>
<tr><td><code id="plotLoadings_+3A_pch">pch</code></td>
<td>
<p>Plotting Symbols</p>
</td></tr>
<tr><td><code id="plotLoadings_+3A_ellipse">ellipse</code></td>
<td>
<p>boolean - specifies if ellipses are plot or not for each cluster</p>
</td></tr>
<tr><td><code id="plotLoadings_+3A_level">level</code></td>
<td>
<p>confidence level for plotting the ellipses</p>
</td></tr>
</table>

<hr>
<h2 id='plotScores'>plotScores</h2><span id='topic+plotScores'></span>

<h3>Description</h3>

<p>Plots the two components defined by pc1, pc2 of the matrix of scores coming from a 
multivariable analysis, typically a Principal Component Analysis (PCA).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotScores(
  data,
  pc1,
  pc2,
  samples,
  factor = NULL,
  cexlabel = 1.2,
  level = 0.95,
  xlim = NULL,
  ylim = NULL,
  col = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotScores_+3A_data">data</code></td>
<td>
<p>the matrix of scores coming from a multivariable analysis, typically a Principal Component Analysis (PCA)</p>
</td></tr>
<tr><td><code id="plotScores_+3A_pc1">pc1</code></td>
<td>
<p>the fist component of the matrix of variable loadings to be plotted.</p>
</td></tr>
<tr><td><code id="plotScores_+3A_pc2">pc2</code></td>
<td>
<p>the second component of the matrix of variable loadings to be plotted.
as well as the levels of the experimental factors if specified in the input. 
See <code>doProcessing</code> or <code>generateMetadata</code></p>
</td></tr>
<tr><td><code id="plotScores_+3A_samples">samples</code></td>
<td>
<p>the samples matrix with the correspondence of the raw spectra,</p>
</td></tr>
<tr><td><code id="plotScores_+3A_factor">factor</code></td>
<td>
<p>if not null, the name of one of the columns defining the factorial groups in the samples matrix at input</p>
</td></tr>
<tr><td><code id="plotScores_+3A_cexlabel">cexlabel</code></td>
<td>
<p>number indicating the amount by which plotting text and symbols should be scaled relative to the default.</p>
</td></tr>
<tr><td><code id="plotScores_+3A_level">level</code></td>
<td>
<p>confidence level for plotting the corresponding ellipse</p>
</td></tr>
<tr><td><code id="plotScores_+3A_xlim">xlim</code></td>
<td>
<p>gives the limit to be plotted of the first component</p>
</td></tr>
<tr><td><code id="plotScores_+3A_ylim">ylim</code></td>
<td>
<p>gives the limit to be plotted of the second component</p>
</td></tr>
<tr><td><code id="plotScores_+3A_col">col</code></td>
<td>
<p>colors vector for ellipses - automatically defined by default</p>
</td></tr>
</table>

<hr>
<h2 id='plotSpecMat'>plotSpecMat Overlaid/Stacked Plot</h2><span id='topic+plotSpecMat'></span>

<h3>Description</h3>

<p><code>plotSpecMat</code> Plot spectra set, overlaid or stacked; if stacked, plot with or 
without a perspective effect.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotSpecMat(
  specMat,
  ppm_lim = c(min(specMat$ppm), max(specMat$ppm)),
  K = 0.67,
  pY = 1,
  dppm_max = 0.2 * (max(ppm_lim) - min(ppm_lim)),
  asym = 1,
  beta = 0,
  cols = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotSpecMat_+3A_specmat">specMat</code></td>
<td>
<p>a 'specMat' object - Spectra matrix in specMat$int (rows = samples, 
columns = buckets)</p>
</td></tr>
<tr><td><code id="plotSpecMat_+3A_ppm_lim">ppm_lim</code></td>
<td>
<p>ppm range of the plot</p>
</td></tr>
<tr><td><code id="plotSpecMat_+3A_k">K</code></td>
<td>
<p>Graphical height of the stack (0 .. 1),(default=0.67)</p>
</td></tr>
<tr><td><code id="plotSpecMat_+3A_py">pY</code></td>
<td>
<p>Intensity limit factor (default 1)</p>
</td></tr>
<tr><td><code id="plotSpecMat_+3A_dppm_max">dppm_max</code></td>
<td>
<p>Max ppm shift to have a perspective effect</p>
</td></tr>
<tr><td><code id="plotSpecMat_+3A_asym">asym</code></td>
<td>
<p>Correction of vertical parallax effect  (-1 .. 1)
-1 : parallelogram
0 : trapeze with maximum asymmetric
1 : symmetric trapeze</p>
</td></tr>
<tr><td><code id="plotSpecMat_+3A_beta">beta</code></td>
<td>
<p>Correction of horizontal parallax effect   (0 .. 0.2) (defaut 0)</p>
</td></tr>
<tr><td><code id="plotSpecMat_+3A_cols">cols</code></td>
<td>
<p>Vector of colors (same size that the number of spectra, i.e dim(specmat)[1])</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'> 
  data_dir &lt;- system.file("extra", package = "Rnmr1D")
  cmdfile &lt;- file.path(data_dir, "NP_macro_cmd.txt")
  samplefile &lt;- file.path(data_dir, "Samples.txt")
  out &lt;- Rnmr1D::doProcessing(data_dir, cmdfile=cmdfile, 
                                samplefile=samplefile, ncpu=2)
  # Overlaid plot
  plotSpecMat(out$specMat, ppm_lim=c(0.5,9), K=0, pY=0.1)
  # Stacked plot with perspective effect
  plotSpecMat(out$specMat, ppm_lim=c(-0.1,9),K=0.33)
  # Stacked plot with perspective effect with maximum asymmetric
  plotSpecMat(out$specMat, ppm_lim=c(0.5,5), K=0.33, asym=0)
  cols &lt;- c(rep("red",3), rep("blue",3))
  # Stacked plot with colors accordings to group levels
  plotSpecMat(out$specMat, ppm_lim=c(0.5,5), K=0.67, dppm_max=0, cols=cols)

</code></pre>

<hr>
<h2 id='RWrapperCMD1D'>RWrapperCMD1D</h2><span id='topic+RWrapperCMD1D'></span>

<h3>Description</h3>

<p><code>RWrapperCMD1D</code> belongs to the low-level functions group - it serves as a wrapper to 
call internale functions for processing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RWrapperCMD1D(cmdName, specMat, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RWrapperCMD1D_+3A_cmdname">cmdName</code></td>
<td>
<p>the name of internal function</p>
</td></tr>
<tr><td><code id="RWrapperCMD1D_+3A_specmat">specMat</code></td>
<td>
<p>a 'specMat' object</p>
</td></tr>
<tr><td><code id="RWrapperCMD1D_+3A_...">...</code></td>
<td>
<p>specific parameters of the requested function</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>specMat</code> : a 'specMat' object
</p>

<hr>
<h2 id='setLogFile'>setLogFile</h2><span id='topic+setLogFile'></span>

<h3>Description</h3>

<p><code>setLogFile</code> allows to redirect all log messages to a file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setLogFile(con = stdout())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setLogFile_+3A_con">con</code></td>
<td>
<p>a connection object which inherits from class &quot;connection&quot;</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'> 
  # Redirect all log messages to a temporary file
   outtmp &lt;- tempfile()
   con &lt;- file(outtmp, "wt", encoding = "UTF-8")
   setLogFile(con)
   data_dir &lt;- system.file("extra", package = "Rnmr1D")
   RAWDIR &lt;- file.path(data_dir, "CD_BBI_16P02")
   CMDFILE &lt;- file.path(data_dir, "NP_macro_cmd.txt")
   SAMPLEFILE &lt;- file.path(data_dir, "Samples.txt")
   out &lt;- Rnmr1D::doProcessing(RAWDIR, cmdfile=CMDFILE, samplefile=SAMPLEFILE, ncpu=2)
   close(con)
   readLines(outtmp)
 
</code></pre>

<hr>
<h2 id='setPPMbounds'>setPPMbounds</h2><span id='topic+setPPMbounds'></span>

<h3>Description</h3>

<p>Set the PPM bounds for proton (1H) and carbon (13C) to consider in the processing step and then to store in the specMat object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setPPMbounds(proton = c(-0.5, 11), carbon = c(0, 200))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setPPMbounds_+3A_proton">proton</code></td>
<td>
<p>Minimal and Maximal ppm value for 1H NMR</p>
</td></tr>
<tr><td><code id="setPPMbounds_+3A_carbon">carbon</code></td>
<td>
<p>Minimal and Maximal ppm value for 13C NMR</p>
</td></tr>
</table>

<hr>
<h2 id='Spec1rDoProc'>Spec1rDoProc</h2><span id='topic+Spec1rDoProc'></span>

<h3>Description</h3>

<p><code>Spec1rDoProc</code> belongs to the low-level functions group - it processes only one raw spectrum at time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Spec1rDoProc(Input, param = Spec1rProcpar)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Spec1rDoProc_+3A_input">Input</code></td>
<td>
<p>Full directory path of the raw spectrum</p>
</td></tr>
<tr><td><code id="Spec1rDoProc_+3A_param">param</code></td>
<td>
<p>a Spec1rProcpar list</p>
</td></tr>
</table>


<h3>Value</h3>

<p>spec object
</p>

<hr>
<h2 id='Spec1rProcpar'>Spec1rProcpar</h2><span id='topic+Spec1rProcpar'></span>

<h3>Description</h3>

<p>Initialize Parameter Lists by the default ones
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Spec1rProcpar
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 33.
</p>


<h3>Value</h3>


<ul>
<li> <p><code>DEBUG</code> : Debug - defaut value = TRUE
</p>
</li>
<li> <p><code>LOGFILE</code> : Messages output file - default value = &quot;&quot;
</p>
</li>
<li> <p><code>VENDOR</code> : Instrumental origin of the raw data (bruker, varian, jeol, rs2d) - default value = 'bruker'
</p>
</li>
<li> <p><code>READ_RAW_ONLY</code> : Read raw file only; do not carry out processing; raw file is depending on INPUT_SIGNAL - default value = FALSE
</p>
</li>
<li> <p><code>INPUT_SIGNAL</code> : What type of input signal: 'fid' or '1r' - default value = 'fid'
</p>
</li>
<li> <p><code>PDATA_DIR</code> : subdirectory containing the 1r file (bruker's format only) - default value = 'pdata/1'
</p>
</li>
<li> <p><code>LB</code> : Exponantial Line Broadening parameter - default value = 0.3
</p>
</li>
<li> <p><code>GB</code> : Gaussian Line Broadening parameter - default value = 0
</p>
</li>
<li> <p><code>REMLFREQ</code> : Remove low frequencies by applying a polynomial subtraction method. - default order of the model = 0
</p>
</li>
<li> <p><code>REVPPM</code> : Reverse ppm scale - default value = FALSE
</p>
</li>
<li> <p><code>BLPHC</code> : Number of points for baseline smoothing during phasing - default value = 50
</p>
</li>
<li> <p><code>KSIG</code> : Number of times the noise signal to be considered during phasing - default value = 6
</p>
</li>
<li> <p><code>CPMG</code> : Indicate if CPMG sequence  - default value = FALSE
</p>
</li>
<li> <p><code>ZEROFILLING</code> : Zero Filling - - default value = FALSE
</p>
</li>
<li> <p><code>ZFFAC</code> : Max factor for Zero Filling - default value = 4
</p>
</li>
<li> <p><code>LINEBROADENING</code> : Line Broading - default value = TRUE
</p>
</li>
<li> <p><code>TSP</code> : PPM referencing - default value = FALSE
</p>
</li>
<li> <p><code>RABOT</code> : Zeroing of Negative Values - default value = FALSE
</p>
</li>
<li> <p><code>OPTPHC0</code> : Zero order phase optimization - default value = TRUE
</p>
</li>
<li> <p><code>OPTPHC1</code> : First order phase optimization - default value = FALSE
</p>
</li>
<li> <p><code>OPTCRIT1</code> : Criterium for phasing optimization (1 for SSpos, 2 for SSneg, 3 for Entropy - default value = 2
</p>
</li>
<li> <p><code>JGD_INNER</code> : JEOL : internal (or external) estimation for Group Delay - default value = TRUE
</p>
</li></ul>


</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
