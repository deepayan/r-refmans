<!DOCTYPE html><html><head><title>Help for package scraEP</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {scraEP}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#scraEP-package'>
<p>Scrape the Web with Extra Power.</p></a></li>
<li><a href='#strcomp'>
<p>Compare the contents of two vectors of character strings.</p></a></li>
<li><a href='#unaccent'>
<p>Remove all accents from character strings.</p></a></li>
<li><a href='#wiki'><p>Wikipedia page for R.</p></a></li>
<li><a href='#xscrape'>
<p>Extract information from webpages to a data.frame, using XPath or CSS queries.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Scrape the Web with Extra Power</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-06-21</td>
</tr>
<tr>
<td>Author:</td>
<td>Julien Boelaert &lt;jubo.stats@gmail.com&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Julien Boelaert &lt;jubo.stats@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Tools for scraping information from webpages and other XML contents, using XPath or CSS selectors.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>XML, xml2, rvest, data.table, parallel</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-06-22 17:24:53 UTC; bart</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-06-23 07:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='scraEP-package'>
Scrape the Web with Extra Power.
</h2><span id='topic+scraEP-package'></span>

<h3>Description</h3>

<p>A set of tools for scraping information from webpages and other XML contents.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> scraEP</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.2</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2021-06-21</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;=3)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Function <code>xscrape</code> is a general tool to extract information from html pages into data frames using XPath or CSS queries.
</p>
<p>Function <code>unaccent</code> removes accents from character strings.
</p>
<p>Function <code>strcomp</code> compares the elements of two character vectors.
</p>


<h3>Author(s)</h3>

<p>Julien Boelaert <a href="mailto:jubo.stats@gmail.com">jubo.stats@gmail.com</a>
</p>

<hr>
<h2 id='strcomp'>
Compare the contents of two vectors of character strings.
</h2><span id='topic+strcomp'></span>

<h3>Description</h3>

<p>This function compares the contents of two vectors of character strings: how many elements are present in both vectors, how many are only present in each one, etc., and lists the elements that are only present in one of the vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strcomp(text1, text2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="strcomp_+3A_text1">text1</code>, <code id="strcomp_+3A_text2">text2</code></td>
<td>
<p>two character vectors to be compared</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements: 
</p>
<p><code>matchTable</code>: a cross table of all the unique elements of the concatenation of text1 and text2, indicating whether they belong to text1 and/or to text2.
</p>
<p><code>matchOneInTwo</code>: a table of the elements of text1 according to how many times they are present in text2.
</p>
<p><code>matchTwoInOne</code>: a table of the elements of text2 according to how many times they are present in text1.
</p>
<p><code>tabOneInTwo</code>: a table of the elements of text1 according to whether they are present in text2.
</p>
<p><code>tabTwoInOne</code>: a table of the elements of text2 according to whether they are present in text1.
</p>
<p><code>oneNotInTwo</code>: a vector containing the elements of text1 not present in text2.
</p>
<p><code>twoNotInOne</code>: a vector containing the elements of text2 not present in text1.
</p>


<h3>Author(s)</h3>

<p>Julien Boelaert <a href="mailto:jubo.stats@gmail.com">jubo.stats@gmail.com</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>str1 &lt;- c("Alice", "Alice", "Bob", "Carol")
str2 &lt;- c("Bob", "Denise", "Emerson", "Foteini")
strcomp(str1, str2)
</code></pre>

<hr>
<h2 id='unaccent'>
Remove all accents from character strings.
</h2><span id='topic+unaccent'></span>

<h3>Description</h3>

<p>This function removes all diacritic accents from character strings (eg. transforms &quot;àüî&quot; into &quot;aui&quot;).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unaccent(text)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="unaccent_+3A_text">text</code></td>
<td>
<p>a character vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character vector, containing the unaccentuated version of the given text.
</p>


<h3>Author(s)</h3>

<p>Julien Boelaert <a href="mailto:jubo.stats@gmail.com">jubo.stats@gmail.com</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>unaccent("âàéèïì")
</code></pre>

<hr>
<h2 id='wiki'>Wikipedia page for R.</h2><span id='topic+wiki'></span>

<h3>Description</h3>

<p>Toy example to extract data using <code>xscrape</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(wiki)
</code></pre>


<h3>Format</h3>

<p>Object <code>wiki</code> is a character vector.
</p>


<h3>Details</h3>

<p>Object <code>wiki</code> is a raw webpage, containing the source of the 
'R (programming language)' article on English wikipedia 
(&lt;https://en.wikipedia.org/wiki/R_(programming_language)&gt;, retrieved on 15/11/2017).
</p>


<h3>Author(s)</h3>

<p>Julien Boelaert <a href="mailto:jubo.stats@gmail.com">jubo.stats@gmail.com</a>
</p>

<hr>
<h2 id='xscrape'>
Extract information from webpages to a data.frame, using XPath or CSS queries.
</h2><span id='topic+xscrape'></span>

<h3>Description</h3>

<p>This function transforms an html/xml page (or list of pages) into a data.frame, extracting nodes specified by their XPath.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xscrape(pages, 
        col.xpath = ".", row.xpath = "/html", 
        col.css = NULL, row.css = NULL, 
        collapse = " | ", encoding = NULL, 
        page.name = TRUE, nice.text = TRUE, 
        parallel = 0, 
        engine = c("auto", "XML", "xml2"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xscrape_+3A_pages">pages</code></td>
<td>
<p>an object of class <code>XMLInternalDocument</code> or <code>xml_document</code> (as returned by functions <code>XML::htmlParse</code> or <code>xml2::read_html</code> or <code>rvest::read_html</code>), or list of such objects. Alternatively, a character vector containing the URLs or local paths of webpages to be parsed. These are the webpages that information is to be extracted from. If the provided list or vector is named, its names will be used to indicate data provenance when <code>page.name</code> is TRUE.</p>
</td></tr>
<tr><td><code id="xscrape_+3A_col.xpath">col.xpath</code></td>
<td>
<p>a character vector of XPath queries used for creating the result columns. If the vector is named, these names are given to the columns. The default &quot;.&quot; takes the text from the whole of each page or intermediary node (specified by <code>row.xpath</code> or <code>row.css</code>).</p>
</td></tr>
<tr><td><code id="xscrape_+3A_row.xpath">row.xpath</code></td>
<td>
<p>a character string, containing an XPath query for creating the result rows. The result of this query (on each page) becomes a row in the resulting data.frame. If not specified (default), the intermediary nodes are whole html pages, so that each page becomes a row in the result.</p>
</td></tr>
<tr><td><code id="xscrape_+3A_col.css">col.css</code></td>
<td>
<p>same as <code>col.xpath</code>, but with CSS selectors instead of XPath queries. If <code>col.xpath</code> was also given, the XPath columns will be placed before the CSS columns in the result.</p>
</td></tr>
<tr><td><code id="xscrape_+3A_row.css">row.css</code></td>
<td>
<p>same as <code>row.xpath</code>, but with a CSS selector instead of an XPath query. If given, this will be used instead of <code>row.xpath</code>.</p>
</td></tr>
<tr><td><code id="xscrape_+3A_collapse">collapse</code></td>
<td>
<p>a character string, containing the separator that will be used in case a <code>col.xpath</code> query yields multiple results within a given intermediary node. The default is &quot; | &quot;.</p>
</td></tr>
<tr><td><code id="xscrape_+3A_encoding">encoding</code></td>
<td>
<p> a character string (eg. &quot;UTF-8&quot; or &quot;ISO-8859-1&quot;), containing the encoding parameter that will be used by <code>htmlParse</code> or <code>read_html</code> if <code>pages</code> is a vector of URLs or local file names.</p>
</td></tr>
<tr><td><code id="xscrape_+3A_page.name">page.name</code></td>
<td>
<p>a logical. If TRUE, the result will contain a column indicating the name of the page each row was extracted from. If <code>pages</code> has no names, they will be numbered from 1 to <code>length(pages)</code></p>
</td></tr>
<tr><td><code id="xscrape_+3A_nice.text">nice.text</code></td>
<td>
<p>a logical. If TRUE (only possible with engine xml2), the rvest::html_text2 function is used to extract text into the result, often making the text much cleaner. If FALSE, the function runs faster, but the text might be less clean.</p>
</td></tr>
<tr><td><code id="xscrape_+3A_parallel">parallel</code></td>
<td>
<p>a numeric, indicating the number of cores to use for parallel computation. The default 0 takes all available cores. The parallelization is done on the pages if their number is greater than the number of provided cores, otherwise it is done on the intermediary nodes. Note that parallelization relies on parallel::mclapply, and is thus not supported on Windows systems.</p>
</td></tr>
<tr><td><code id="xscrape_+3A_engine">engine</code></td>
<td>
<p>a character string, indicating the engine to use for data extraction: either &quot;XML&quot;, &quot;xml2&quot;, or &quot;auto&quot; (default). The default will adapt the engine to the type of <code>pages</code>, or will use &quot;xml2&quot; if <code>pages</code> are URLs or file names. Note: CSS selectors and <code>nice.text</code> are only available for &quot;xml2&quot;, but XPath queries and &quot;XML&quot; engine tend to be much faster.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If a <code>col.xpath</code> or <code>col.css</code> query designs a full node, only its text is extracted. If it designs an attribute (eg. ends with '/@href' for weblinks), only the attribute's value is extracted.
</p>
<p>If a <code>col.xpath</code> or <code>col.css</code> query matches no elements in a page, returned value is <code>NA</code>. If it matches multiple elements, they are concatenated into a single character string, separated by <code>collapse</code>.
</p>


<h3>Value</h3>

<p>A data.frame, where each row corresponds to an intermediary node (either a full page or an XML node within a page, specified by <code>row.xpath</code> or <code>row.css</code>), and each column corresponds to the text of a <code>col.xpath</code> or <code>col.css</code> query.
</p>


<h3>Author(s)</h3>

<p>Julien Boelaert <a href="mailto:jubo.stats@gmail.com">jubo.stats@gmail.com</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Extract all external links and their titles from a wikipedia page
data(wiki)
wiki.parse &lt;- XML::htmlParse(wiki)
links &lt;- xscrape(wiki.parse, 
                 row.xpath= "//a[starts-with(./@href, 'http')]", 
                 col.xpath= c(title= ".", link= "./@href"), 
                 parallel = 1)

## Not run: 
## Convert results from a search for 'R' on duckduckgo.com
## First download the search page
duck &lt;- XML::htmlParse("http://duckduckgo.com/html/?q=R")
## Then run xscrape on the dowloaded and parsed page
results &lt;- xscrape(duck, 
                   row.xpath= "//div[contains(@class, 'result__body')]",
                   col.xpath= c(title= "./h2", 
                                snippet= ".//*[@class='result__snippet']", 
                                url= ".//a[@class='result__url']/@href"))

## End(Not run)

## Not run: 
## Convert results from a search for 'R' and 'Julia' on duckduckgo.com
## Directly provide the URLs to xscrape
results &lt;- xscrape(c("http://duckduckgo.com/html/?q=R", 
                     "http://duckduckgo.com/html/?q=julia"), 
                   row.xpath= "//div[contains(@class, 'result__body')]",
                   col.xpath= c(title= "./h2", 
                                snippet= ".//*[@class='result__snippet']", 
                                url= ".//a[@class='result__url']/@href"))

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
