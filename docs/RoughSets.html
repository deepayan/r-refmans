<!DOCTYPE html><html><head><title>Help for package RoughSets</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {RoughSets}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#RoughSets-package'><p>Getting started with the RoughSets package</p></a></li>
<li><a href='#[.RuleSetRST'><p>The <code>[.</code> method for <code>"RuleSetRST"</code> objects</p></a></li>
<li><a href='#as.character.RuleSetRST'><p>The <code>as.character</code> method for RST rule sets</p></a></li>
<li><a href='#as.list.RuleSetRST'><p>The <code>as.list</code> method for RST rule sets</p></a></li>
<li><a href='#BC.boundary.reg.RST'><p>Computation of a boundary region</p></a></li>
<li><a href='#BC.discernibility.mat.FRST'><p>The decision-relative discernibility matrix based on fuzzy rough set theory</p></a></li>
<li><a href='#BC.discernibility.mat.RST'><p>Computation of a decision-relative discernibility matrix based on the rough set theory</p></a></li>
<li><a href='#BC.IND.relation.FRST'><p>The indiscernibility relation based on fuzzy rough set theory</p></a></li>
<li><a href='#BC.IND.relation.RST'><p>Computation of indiscernibility classes based on the rough set theory</p></a></li>
<li><a href='#BC.LU.approximation.FRST'><p>The fuzzy lower and upper approximations based on fuzzy rough set theory</p></a></li>
<li><a href='#BC.LU.approximation.RST'><p>Computation of lower and upper approximations of decision classes</p></a></li>
<li><a href='#BC.negative.reg.RST'><p>Computation of a negative region</p></a></li>
<li><a href='#BC.positive.reg.FRST'><p>Positive region based on fuzzy rough set</p></a></li>
<li><a href='#BC.positive.reg.RST'><p>Computation of a positive region</p></a></li>
<li><a href='#C.FRNN.FRST'><p>The fuzzy-rough nearest neighbor algorithm</p></a></li>
<li><a href='#C.FRNN.O.FRST'><p>The fuzzy-rough ownership nearest neighbor algorithm</p></a></li>
<li><a href='#C.POSNN.FRST'><p>The positive region based fuzzy-rough nearest neighbor algorithm</p></a></li>
<li><a href='#D.discretization.RST'><p>The wrapper function for discretization methods</p></a></li>
<li><a href='#D.discretize.equal.intervals.RST'><p>Unsupervised discretization into intervals of equal length.</p></a></li>
<li><a href='#D.discretize.quantiles.RST'><p>The quantile-based discretization</p></a></li>
<li><a href='#D.global.discernibility.heuristic.RST'><p>Supervised discretization based on the maximum discernibility heuristic</p></a></li>
<li><a href='#D.local.discernibility.heuristic.RST'><p>Supervised discretization based on the local discernibility heuristic</p></a></li>
<li><a href='#FS.all.reducts.computation'><p>A function for computing all decision reducts of a decision system</p></a></li>
<li><a href='#FS.DAAR.heuristic.RST'><p>The DAAR heuristic for computation of decision reducts</p></a></li>
<li><a href='#FS.feature.subset.computation'><p>The superreduct computation based on RST and FRST</p></a></li>
<li><a href='#FS.greedy.heuristic.reduct.RST'><p>The greedy heuristic algorithm for computing decision reducts and approximate decision reducts</p></a></li>
<li><a href='#FS.greedy.heuristic.superreduct.RST'><p>The greedy heuristic method for determining superreduct based on RST</p></a></li>
<li><a href='#FS.nearOpt.fvprs.FRST'><p>The near-optimal reduction algorithm based on fuzzy rough set theory</p></a></li>
<li><a href='#FS.one.reduct.computation'><p>Computing one reduct from a discernibility matrix</p></a></li>
<li><a href='#FS.permutation.heuristic.reduct.RST'><p>The permutation heuristic algorithm for computation of a decision reduct</p></a></li>
<li><a href='#FS.quickreduct.FRST'><p>The fuzzy QuickReduct algorithm based on FRST</p></a></li>
<li><a href='#FS.quickreduct.RST'><p>QuickReduct algorithm based on RST</p></a></li>
<li><a href='#FS.reduct.computation'><p>The reduct computation methods based on RST and FRST</p></a></li>
<li><a href='#IS.FRIS.FRST'><p>The fuzzy rough instance selection algorithm</p></a></li>
<li><a href='#IS.FRPS.FRST'><p>The fuzzy rough prototype selection method</p></a></li>
<li><a href='#MV.conceptClosestFit'><p>Concept Closest Fit</p></a></li>
<li><a href='#MV.deletionCases'><p>Missing value completion by deleting instances</p></a></li>
<li><a href='#MV.globalClosestFit'><p>Global Closest Fit</p></a></li>
<li><a href='#MV.missingValueCompletion'><p>Wrapper function of missing value completion</p></a></li>
<li><a href='#MV.mostCommonVal'><p>Replacing missing attribute values by the attribute mean or common values</p></a></li>
<li><a href='#MV.mostCommonValResConcept'><p>The most common value or mean of an attribute restricted to a concept</p></a></li>
<li><a href='#predict.RuleSetFRST'><p>The predicting function for rule induction methods based on FRST</p></a></li>
<li><a href='#predict.RuleSetRST'><p>Prediction of decision classes using rule-based classifiers.</p></a></li>
<li><a href='#print.FeatureSubset'><p>The print method of FeatureSubset objects</p></a></li>
<li><a href='#print.RuleSetRST'><p>The print function for RST rule sets</p></a></li>
<li><a href='#RI.AQRules.RST'><p>Rule induction using the AQ algorithm</p></a></li>
<li><a href='#RI.CN2Rules.RST'><p>Rule induction using a version of CN2 algorithm</p></a></li>
<li><a href='#RI.GFRS.FRST'><p>Generalized fuzzy rough set rule induction based on FRST</p></a></li>
<li><a href='#RI.hybridFS.FRST'><p>Hybrid fuzzy-rough rule and induction and feature selection</p></a></li>
<li><a href='#RI.indiscernibilityBasedRules.RST'><p>Rule induction from indiscernibility classes.</p></a></li>
<li><a href='#RI.laplace'><p>Quality indicators of RST decision rules</p></a></li>
<li><a href='#RI.LEM2Rules.RST'><p>Rule induction using the LEM2 algorithm</p></a></li>
<li><a href='#RoughSetData'><p>Data set of the package</p></a></li>
<li><a href='#SF.applyDecTable'><p>Apply for obtaining a new decision table</p></a></li>
<li><a href='#SF.asDecisionTable'><p>Converting a data.frame into a <code>DecisionTable</code> object</p></a></li>
<li><a href='#SF.asFeatureSubset'><p>Converting custom attribute name sets into a FeatureSubset object</p></a></li>
<li><a href='#SF.read.DecisionTable'><p>Reading tabular data from files.</p></a></li>
<li><a href='#summary.IndiscernibilityRelation'><p>The summary function for an indiscernibility relation</p></a></li>
<li><a href='#summary.LowerUpperApproximation'><p>The summary function of lower and upper approximations based on RST and FRST</p></a></li>
<li><a href='#summary.PositiveRegion'><p>The summary function of positive region based on RST and FRST</p></a></li>
<li><a href='#summary.RuleSetFRST'><p>The summary function of rules based on FRST</p></a></li>
<li><a href='#summary.RuleSetRST'><p>The summary function of rules based on RST</p></a></li>
<li><a href='#X.entropy'><p>The entropy measure</p></a></li>
<li><a href='#X.gini'><p>The gini-index measure</p></a></li>
<li><a href='#X.laplace'><p>Rule voting by the Laplace estimate</p></a></li>
<li><a href='#X.nOfConflicts'><p>The discernibility measure</p></a></li>
<li><a href='#X.rulesCounting'><p>Rule voting by counting matching rules</p></a></li>
<li><a href='#X.ruleStrength'><p>Rule voting by strength of the rule</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Maintainer:</td>
<td>Christoph Bergmeir &lt;c.bergmeir@decsai.ugr.es&gt;</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Title:</td>
<td>Data Analysis Using Rough Set and Fuzzy Rough Set Theories</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementations of algorithms for data analysis based on the
    rough set theory (RST) and the fuzzy rough set theory (FRST). We not only
    provide implementations for the basic concepts of RST and FRST but also
    popular algorithms that derive from those theories. The methods included in the
    package can be divided into several categories based on their functionality:
    discretization, feature selection, instance selection, rule induction and
    classification based on nearest neighbors. RST was introduced by Zdzis≈Çaw
    Pawlak in 1982 as a sophisticated mathematical tool to model and process
    imprecise or incomplete information. By using the indiscernibility relation for
    objects/instances, RST does not require additional parameters to analyze the
    data. FRST is an extension of RST. The FRST combines concepts of vagueness and
    indiscernibility that are expressed with fuzzy sets (as proposed by Zadeh, in
    1965) and RST.</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/janusza/RoughSets">https://github.com/janusza/RoughSets</a></td>
</tr>
<tr>
<td>Date:</td>
<td>2024-01-23</td>
</tr>
<tr>
<td>Suggests:</td>
<td>class</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>Depends:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-23 07:49:16 UTC; bergmeir</td>
</tr>
<tr>
<td>Author:</td>
<td>Andrzej Janusz [aut],
  Lala Septem Riza [aut],
  Dominik ≈ölƒôzak [ctb],
  Chris Cornelis [ctb],
  Francisco Herrera [ctb],
  Jose Manuel Benitez [ctb],
  Christoph Bergmeir [ctb, cre],
  Sebastian Stawicki [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-23 10:12:47 UTC</td>
</tr>
</table>
<hr>
<h2 id='RoughSets-package'>Getting started with the RoughSets package</h2><span id='topic+RoughSets-package'></span><span id='topic+RoughSets'></span><span id='topic+Introduction-RoughSets'></span><span id='topic+Introduction-FuzzyRoughSets'></span>

<h3>Description</h3>

<p>This part contains global explanations about the implementation and use of the <code>RoughSets</code> package.
The package <code>RoughSets</code> attempts to provide a complete tool to model and analyze
information systems based on rough set theory (RST) and fuzzy rough set theory (FRST).
From fundamental point of view, this package allows to construct rough sets by defining lower and upper approximations.
Furthermore, recent methods for tackling common tasks in data mining, such as data preprocessing (e.g., discretization, feature selection, missing value completion,
and instance selection), rule induction, and prediction classes or decision values of new datasets
are available as well.
</p>


<h3>Details</h3>

<p>There are two main parts considered in this package which are RST and FRST.
RST was introduced by (Pawlak, 1982; Pawlak, 1991) which provides sophisticated mathematical tools to model
and analyze information systems that involve uncertainty and imprecision. By employing indiscernibility relation among objects, RST does not require
additional parameters to extract information.
The detailed explanation about fundamental concepts of RST can be read in Section <code><a href="#topic+Introduction-RoughSets">Introduction-RoughSets</a></code>. Secondly, FRST, an extension of
RST, was introduced by (Dubois and Prade, 1990) as a combination between
fuzzy sets proposed by (Zadeh, 1965) and RST. This concept allows to analyze continuous attributes without
performing discretization on data first. Basic concepts of FRST
can be seen in <code><a href="#topic+Introduction-FuzzyRoughSets">Introduction-FuzzyRoughSets</a></code>.
</p>
<p>Based on the above concepts, many methods have been proposed and applied for dealing with several different domains.
In order to solve the problems, methods employ the indiscernibility relation and lower and upper approximation concepts.
All methods that have been implemented in this package will be explained by grouping based on their domains. The following is
a list of domains considered in this package:
</p>

<ul>
<li><p> Basic concepts: This part, we can divide into four different tasks which are
indiscernibility relation, lower and upper approximations, positive region and discernibility matrix.
All of those tasks have been explained briefly in Section <code><a href="#topic+Introduction-RoughSets">Introduction-RoughSets</a></code> and
</p>
<p><code><a href="#topic+Introduction-FuzzyRoughSets">Introduction-FuzzyRoughSets</a></code>.
</p>
</li>
<li><p> Discretization: It is used to convert real-valued attributes into nominal/symbolic ones in an information system.
In RST point of view, this task attempts to maintain the discernibility between objects.
</p>
</li>
<li><p> Feature selection: It is a process for finding a subset of features which have the same quality as the complete feature set.
In other words, its purpose is to select the significant features and eliminate the dispensible ones.
It is a useful and necessary process when we are facing datasets containing large numbers of features. From RST and FRST perspective,
feature selection refers to searching superreducts and reducts. The detailed information about reducts can be read in
<code><a href="#topic+Introduction-RoughSets">Introduction-RoughSets</a></code> and <code><a href="#topic+Introduction-FuzzyRoughSets">Introduction-FuzzyRoughSets</a></code>.
</p>
</li>
<li><p> Instance selection: This process is aimed to remove noisy, superfluous, or inconsistent instances from training datasets but retain consistent ones.
In other words, good accuracy of classification is achieved by removing instances which do not give positive contributions.
</p>
</li>
<li><p> Prediction/classification: This task is used to predict decision values of a new dataset (test data).
We consider implementing some methods to perform this task, such as fuzzy-rough nearest neighbor approaches, etc.
</p>
</li>
<li><p> Rule induction: This task refers to generate IF - THEN rules. The rule represents knowledge which is contained in a dataset.
One advantage of building rules is that naturally the model is easy to interpret. Then, predicted values over new datasets can be determined by
considering the rules.
</p>
</li></ul>

<p>As we mentioned before, we have embedded many well-known algorithms or techniques for handling the above domains. The algorithms were considered
since experimentally it has been proven that they were able to tackle complex tasks. They are implemented as functions that were organized
to work with the same data structures. So, users can perform various approaches for a particular task easily and then compare their results.
In order to be recognized quickly, generally we have chosen the names of the functions with some conventions. The names contain three parts
which are <code>prefix</code>, <code>suffix</code>, and <code>middle</code> that are separated by a point. The following is a description of each
part.
</p>

<ul>
<li> <p><code>prefix</code>: There are some different prefixes for names of functions expressing a kind of task to be performed.
The function names with prefix <code>BC</code> refer to <em>basic concepts</em> which means that the functions are created for
implementing the basic concepts of RST and FRST.
While prefix <code>D</code> refers to <em>discretization</em>, <code>FS</code>, <code>IS</code>, <code>RI</code>, <code>MV</code>, and <code>C</code> refer to <em>feature selection</em>,
<em>instance selection</em>, <em>rule induction</em>, <em>missing value completion</em>, and <em>classifier based on nearest neighbor</em> domains. Furthermore, <code>SF</code> and <code>X</code> mean that
functions are used as <em>supporting functions</em> which are not related directly with RST and FRST and <em>auxiliary</em> functions which are called as a parameter.
</p>
</li>
<li> <p><code>suffix</code>: It is located at the end of names. There are two types available: <code>RST</code> and <code>FRST</code>. <code>RST</code> represents <em>rough set theory</em>
while <code>FRST</code> shows that the function is applied to <em>fuzzy rough set theory</em>. Additionally, some functions that do not have
<code>RST</code> or <code>FRST</code> suffix are used for both theories.
</p>
</li>
<li> <p><code>middle</code>: All other words in the middle of the names are used to express the actual name of a particular method/algorithm or functionality.
In this case, it could consist of more than one word separated by points.
</p>
</li></ul>

<p>For instance, the function <code><a href="#topic+BC.IND.relation.RST">BC.IND.relation.RST</a></code> is used to calculate the indiscernibility relation which is one of the basic concepts of RST.
Other functions that have names not based on the above rules are S3 functions e.g., <code>summary</code> and <code>predict</code> which are
used to summarize objects and predict new data, respectively.
</p>
<p>The following description explains domains and their algorithms implemented in the package:
</p>

<ol>
<li> <p><b>The implementations of RST</b>: This part outlines some considered algorihtms/methods based on RST.
The approaches can be classified based on their tasks as follows:
</p>

<ol>
<li><p> The basic concepts: The following is a list showing tasks and their implementations as functions.
</p>

<ul>
<li><p> Indiscernibility relation: It is a relation determining whether two objects are indiscernible by some attributes.
It is implemented in <code><a href="#topic+BC.IND.relation.RST">BC.IND.relation.RST</a></code>.
</p>
</li>
<li><p> Lower and upper approximations: These approximations show whether objects can be classified with certainty or not.
It is implemented in <code><a href="#topic+BC.LU.approximation.RST">BC.LU.approximation.RST</a></code>.
</p>
</li>
<li><p> Positive region: It is used to determine objects that are included in positive region and the degree of dependency.
It is implemented in <code><a href="#topic+BC.positive.reg.RST">BC.positive.reg.RST</a></code>.
</p>
</li>
<li><p> Discernibility matrix: It is used to create a discernibility matrix showing attributes that discern each pair of objects.
It is implemented in <code><a href="#topic+BC.discernibility.mat.RST">BC.discernibility.mat.RST</a></code>.
</p>
</li></ul>

</li>
<li><p> Discretization: There are a few methods included in the package:
</p>

<ul>
<li> <p><code><a href="#topic+D.global.discernibility.heuristic.RST">D.global.discernibility.heuristic.RST</a></code>: It implements the global discernibility algorithm
which is computing globally semi-optimal cuts using the maximum discernibility heuristic.
</p>
</li>
<li> <p><code><a href="#topic+D.discretize.quantiles.RST">D.discretize.quantiles.RST</a></code>: It is a function used for computing cuts of the &quot;quantile-based&quot; discretization into <code class="reqn">n</code> intervals.
</p>
</li>
<li> <p><code><a href="#topic+D.discretize.equal.intervals.RST">D.discretize.equal.intervals.RST</a></code>: It is a function used for computing cuts of the &quot;equal interval size&quot; discretization into <code class="reqn">n</code> intervals.
</p>
</li></ul>

<p>The output of these functions is a list of cut values which are the values for converting real to nominal values.
So, in order to generate a new decision table according to the cut values, we need to call <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code>.
Additionally, we have implemented <code><a href="#topic+D.discretization.RST">D.discretization.RST</a></code> as a wrapper function collecting all methods considered to perform discretization tasks.
</p>
</li>
<li><p> Feature selection: According to its output, it can be classified into the following groups:
</p>

<ul>
<li><p> Feature subset: It refers to a superreduct which is not necessarily minimal. In other words, the methods in this group
might generate just a subset of attributes.
</p>

<ul>
<li><p> QuickReduct algorithm: It has been implemented in <code><a href="#topic+FS.quickreduct.RST">FS.quickreduct.RST</a></code>.
</p>
</li>
<li><p> Superreduct generation: It is based on some criteria:
entropy, gini index, discernibility measure, size of positive region.
</p>
<p>It is implemented in <code><a href="#topic+FS.greedy.heuristic.superreduct.RST">FS.greedy.heuristic.superreduct.RST</a></code>.
</p>
</li></ul>

<p>Furthermore, we provide a wrapper function <code><a href="#topic+FS.feature.subset.computation">FS.feature.subset.computation</a></code> in order to give a user interface for many methods of RST and FRST that are included in this group.
</p>
</li>
<li><p> Reduct: The following are methods that produce a single decision reduct:
</p>

<ul>
<li><p> Reduct generation based on criteria: It is based on different criteria which are
entropy, gini index, discernibility measure, size of positive region.
It has been implemented in <code><a href="#topic+FS.greedy.heuristic.reduct.RST">FS.greedy.heuristic.reduct.RST</a></code>.
</p>
</li>
<li><p> Permutation reduct: It is based on a permutation schema over all attributes.
It has been implemented in <code><a href="#topic+FS.permutation.heuristic.reduct.RST">FS.permutation.heuristic.reduct.RST</a></code>.
</p>
</li></ul>

<p>Furthermore, we provide a wrapper function <code><a href="#topic+FS.reduct.computation">FS.reduct.computation</a></code> in order to give a user interface toward many methods of RST and FRST that are included in this group.
</p>
</li>
<li><p> All reducts: In order to generate all reducts, we execute <code><a href="#topic+FS.all.reducts.computation">FS.all.reducts.computation</a></code>. However,
before doing that, we need to call <code><a href="#topic+BC.discernibility.mat.RST">BC.discernibility.mat.RST</a></code> for
constructing a decision-relative discernibility matrix
</p>
</li></ul>

<p>It should be noted that the outputs of the functions are decision reducts. So, for generating a new decision table according to the decision reduct,
we need to call <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code>.
</p>
</li>
<li><p> Rule induction: We provide several functions used to generate rules, as follows:
</p>

<ul>
<li><p> The function <code><a href="#topic+RI.indiscernibilityBasedRules.RST">RI.indiscernibilityBasedRules.RST</a></code>: This function requires the output of the feature selection functions.
</p>
</li>
<li><p> The function <code><a href="#topic+RI.CN2Rules.RST">RI.CN2Rules.RST</a></code>: It is a rule induction method based on the CN2 algorithm.
</p>
</li>
<li><p> The function <code><a href="#topic+RI.LEM2Rules.RST">RI.LEM2Rules.RST</a></code>: It implements a rule induction method based on the LEM2 algorithm.
</p>
</li>
<li><p> The function <code><a href="#topic+RI.AQRules.RST">RI.AQRules.RST</a></code>: It is a rule induction based on the AQ-style algorithm.
</p>
</li></ul>

<p>After obtaining the rules, we execute <code><a href="#topic+predict.RuleSetRST">predict.RuleSetRST</a></code> considering our rules and given newdata/testing data to obtain predicted values/classes.
</p>
</li></ol>

</li>
<li> <p><b>The implementations of FRST</b>: As in the <code>RST</code> part, this part contains several algorithms that can be classified into several groups based on their purpose.
The following is a description of all methods that have been implemented in functions:
</p>

<ol>
<li><p> Basic concepts: The following is a list showing tasks and their implementations:
</p>

<ul>
<li><p> Indiscernibility relations: they are fuzzy relations determining to which degree two objects are similar.
This package provides several types of relations which are implemented in a single function
called <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code>. We consider several types of relations e.g.,
fuzzy equivalence, tolerance, and <code class="reqn">T</code>-similarity relations. These relations can be chosen by
assigning <code>type.relation</code>. Additionally, in this function, we provide several options to
calculate aggregation e.g., triangular norm operators (e.g., <code>"lukasiewicz"</code>, <code>"min"</code>, etc)
and user-defined operators.
</p>
</li>
<li><p> Lower and upper approximations: These approximations show to what extent objects can be classified with certainty or not.
This task has been implemented in
</p>
<p><code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>. There are many approaches available in this package that can be selected by assigning the parameter <code>type.LU</code>.
The considered methods are
implication/t-norm, <code class="reqn">\beta</code>-precision fuzzy rough sets (<code class="reqn">\beta</code>-PFRS), vaguely quantified rough sets (VQRS), fuzzy variable precision rough sets (FVPRS), ordered weighted average (OWA),
soft fuzzy rough sets (SFRS), and robust fuzzy rough sets (RFRS). Furthermore, we provide a facility, which is <code>"custom"</code>, where users can create their own approximations by
defining functions to calculate lower and upper approximations. Many options to calculate implicator and triangular norm are also available.
</p>
</li>
<li><p> Positive region: It is used to determine the membership degree of each object to the positive region and the degree of dependency.
It is implemented in <code><a href="#topic+BC.positive.reg.FRST">BC.positive.reg.FRST</a></code>.
</p>
</li>
<li><p> Discernibility matrix: It is used to construct the decision-relative discernibility matrix. There are some approaches to construct the matrix,
e.g., based on standard approach, Gaussian reduction, alpha reduction, and minimal element in discernibility matrix. They have been implemented
in <code><a href="#topic+BC.discernibility.mat.FRST">BC.discernibility.mat.FRST</a></code>.
</p>
</li></ul>

</li>
<li><p> Feature selection: According to the output of functions,
we may divide them into three groups: those that produce a superreduct, a set of reducts, or a single reduct. The following is a description of functions based on their types:
</p>

<ul>
<li><p> Feature subset: It refers to methods which produce a superreduct which is not necessarily a reduct. In other words methods in this group
might generate just a subset of attributes.
The following is a complete list of methods considered in this package:
</p>

<ul>
<li><p> positive region based algorithms: It refers to
positive regions, as a way to evaluate attributes to be selected. They are implemented in <code><a href="#topic+FS.quickreduct.FRST">FS.quickreduct.FRST</a></code>.
Furthermore, we provide several different measures based on the positive region in this function.
All methods included in this part employ the QuickReduct algorithm to obtain selected features.
In order to choose a particular algorithm, we need to assign parameter <code>type.method</code> in <code><a href="#topic+FS.quickreduct.FRST">FS.quickreduct.FRST</a></code>.
</p>
</li>
<li><p> boundary region based algorithm: This algorithm is based on the membership degree to the fuzzy boundary region.
This algorithm has been implemented in <code><a href="#topic+FS.quickreduct.FRST">FS.quickreduct.FRST</a></code>.
</p>
</li></ul>

<p>Furthermore, we provide a wrapper function <code><a href="#topic+FS.feature.subset.computation">FS.feature.subset.computation</a></code> in order to give a user interface for many methods of RST and FRST.
</p>
</li>
<li><p> Reduct: It refers to a method that produces a single decision reduct. We provide one algorithm which is the near-optimal reduction proposed by Zhao et al.
It is implemented in <code><a href="#topic+FS.nearOpt.fvprs.FRST">FS.nearOpt.fvprs.FRST</a></code>.
Furthermore, we provide a wrapper function <code><a href="#topic+FS.reduct.computation">FS.reduct.computation</a></code> in order to provide a user interface toward many methods of RST and FRST.
</p>
</li>
<li><p> All reducts:  In order to get all decision reducts, we execute <code><a href="#topic+FS.all.reducts.computation">FS.all.reducts.computation</a></code>. However, before doing that, we firstly execute the <code><a href="#topic+BC.discernibility.mat.FRST">BC.discernibility.mat.FRST</a></code> function for
constructing a decision-relative discernibility matrix.
</p>
</li></ul>

<p>The output of the above methods is a class containing a decision reduct/feature subset and other descriptions.
For generating a new decision table according to the decision reduct, we provide the function <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code>.
</p>
</li>
<li><p> Rule induction: It is a task used to generate
rules representing knowledge of a decision table. Commonly, this process is called learning phase in machine learning.
The following methods are considered to generate rules:
</p>

<ul>
<li> <p><code><a href="#topic+RI.hybridFS.FRST">RI.hybridFS.FRST</a></code>: It combines fuzzy-rough rule induction
and feature selection.
</p>
</li>
<li> <p><code><a href="#topic+RI.GFRS.FRST">RI.GFRS.FRST</a></code>: It refers to rule induction based on generalized fuzzy rough sets (GFRS).
</p>
</li></ul>

<p>After generating rules, we can use them to predict decision values/classes of new data
by executing the S3 function <code><a href="#topic+predict.RuleSetFRST">predict.RuleSetFRST</a></code>.
</p>
</li>
<li><p> Instance selection: The following functions select instances to improve accuracy by
removing noisy, superfluous or inconsistent ones from training datasets.
</p>

<ul>
<li> <p><code><a href="#topic+IS.FRIS.FRST">IS.FRIS.FRST</a></code>: It refers to the fuzzy rough instance selection (FRIS). It evaluates the degree of membership to the positive region of each instance.
If an instance's membership degree is less than the threshold, then the instance can be removed.
</p>
</li>
<li> <p><code><a href="#topic+IS.FRPS.FRST">IS.FRPS.FRST</a></code>: It refers to the fuzzy-rough prototype selection (FRPS). It employs prototype selection (PS) to improve the accuracy of the $k$-nearest neighbor (kNN) method.
</p>
</li></ul>

<p>We provide the function <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code> that is used to generate a new decision table according to the output of instance selection functions.
</p>
</li>
<li><p> Fuzzy-rough nearest neighbors: This part provides methods based on nearest neighbors for
predicting decision values/classes of new datasets. In other words, by supplying a decision table as training data
we can predict decision values of new data at the same time.
We have considered the following methods:
</p>

<ul>
<li> <p><code><a href="#topic+C.FRNN.FRST">C.FRNN.FRST</a></code>: It refers to the fuzzy-rough nearest neighbors based on Jensen and Cornelis' technique.
</p>
</li>
<li> <p><code><a href="#topic+C.FRNN.O.FRST">C.FRNN.O.FRST</a></code>: It refers to the fuzzy-rough ownership nearest neighbor algorithm based on Sarkar's method.
</p>
</li>
<li> <p><code><a href="#topic+C.POSNN.FRST">C.POSNN.FRST</a></code>: The positive region based fuzzy-rough nearest neighbor algorithm based on Verbiest et al's technique.
</p>
</li></ul>

</li></ol>

</li></ol>

<p>Furthermore, we provide an additional feature which is missing value completion. Even though algorithms, included in this feature, are not based on RST and FRST, they will be usefull to do data analysis.
The following is a list of functions implemented for handling missing values in the data preprocessing step:
</p>

<ul>
<li> <p><code><a href="#topic+MV.deletionCases">MV.deletionCases</a></code>: it refers to the approach deleting instances.
</p>
</li>
<li> <p><code><a href="#topic+MV.mostCommonValResConcept">MV.mostCommonValResConcept</a></code>: it refers to the approach based on the most common value or mean of an attribute restricted to a concept.
</p>
</li>
<li> <p><code><a href="#topic+MV.mostCommonVal">MV.mostCommonVal</a></code>: it refers to the approach replacing missing attribute values by the attribute mean or common values.
</p>
</li>
<li> <p><code><a href="#topic+MV.globalClosestFit">MV.globalClosestFit</a></code>: it refers to the approach based on the global closest fit approach.
</p>
</li>
<li> <p><code><a href="#topic+MV.conceptClosestFit">MV.conceptClosestFit</a></code>: it refers to the approach based on the concept closest fit approach.
</p>
</li></ul>

<p>Additionally, we provide a wrapper function which is <code><a href="#topic+MV.missingValueCompletion">MV.missingValueCompletion</a></code>
in order to give a user interface for the methods.
</p>
<p>To get started with the package, the user can have a look at the examples included in
the documentation on each function. Additionally, to show general usage of the package briefly,
we also provide some examples showing general usage in this section.
</p>
<p>If you have problems using the package, find a bug, or have suggestions,
please contact the package maintainer by email, instead of writing to the general R lists
or to other internet forums and mailing lists.
</p>
<p>There are many demos that ship with the package. To get a list of them, type:
</p>
<p><code>demo()</code>
</p>
<p>Then, to start a demo, type <code>demo(&lt;demo_name_here&gt;)</code>. All the demos are presented as
R scripts in the package sources in the &quot;demo&quot; subdirectory.
</p>
<p>Currently, there are the following demos available:
</p>

<ul>
<li><p> Basic concepts of RST and FRST:
</p>
<p><code>demo(BasicConcept.RST)</code>,
<code>demo(BasicConcept.FRST)</code>,
</p>
<p><code>demo(DiscernibilityMatrix.RST)</code>,
<code>demo(DiscernibilityMatrix.FRST)</code>.
</p>
</li>
<li><p> Discretization based on RST:
</p>
<p><code>demo(D.local.discernibility.matrix.RST)</code>,
<code>demo(D.max.discernibility.matrix.RST)</code>,
</p>
<p><code>demo(D.global.discernibility.heuristic.RST)</code>,
<code>demo(D.discretize.quantiles.RST)</code>,
</p>
<p><code>demo(D.discretize.equal.intervals.RST)</code>.
</p>
</li>
<li><p> Feature selection based on RST:
</p>
<p><code>demo(FS.permutation.heuristic.reduct.RST)</code>,
<code>demo(FS.quickreduct.RST)</code>,
</p>
<p><code>demo(FS.greedy.heuristic.reduct.RST)</code>,
<code>demo(FS.greedy.heuristic.reduct.RST)</code>.
</p>
</li>
<li><p> Feature selection based on FRST:
</p>
<p><code>demo(FS.QuickReduct.FRST.Ex1)</code>,
<code>demo(FS.QuickReduct.FRST.Ex2)</code>,
</p>
<p><code>demo(FS.QuickReduct.FRST.Ex3)</code>,
<code>demo(FS.QuickReduct.FRST.Ex4)</code>,
</p>
<p><code>demo(FS.QuickReduct.FRST.Ex5)</code>,
<code>demo(FS.nearOpt.fvprs.FRST)</code>.
</p>
</li>
<li><p> Instance selection based on FRST:
</p>
<p><code>demo(IS.FRIS.FRST)</code>,
<code>demo(IS.FRPS.FRST)</code>
</p>
</li>
<li><p> Classification using the Iris dataset:
</p>
<p><code>demo(FRNN.O.iris)</code>,
<code>demo(POSNN.iris)</code>,
<code>demo(FRNN.iris)</code>.
</p>
</li>
<li><p> Rule induction based on RST:
</p>
<p><code>demo(RI.indiscernibilityBasedRules.RST)</code>.
</p>
</li>
<li><p> Rule induction based on FRST:
</p>
<p><code>demo(RI.classification.FRST)</code>,
<code>demo(RI.regression.FRST)</code>.
</p>
</li>
<li><p> Missing value completion:
<code>demo(MV.simpleData)</code>.
</p>
</li></ul>

<p>Some decision tables have been embedded in this package which can be seen in
<code><a href="#topic+RoughSetData">RoughSetData</a></code>.
</p>


<h3>Introduction to Rough Set Theory</h3>

<p>This part attempts to introduce rough set theory (RST) and its application to data analysis. 
While the classical RST proposed by Pawlak in 1982 is explained in detail in this section, 
some recent advancements will be treated in the documentation of the related functions.  
</p>
<p>In RST, a data set is represented as a table called an information system <code class="reqn">\mathcal{A} = (U, A)</code>, where
<code class="reqn">U</code> is a non-empty set of finite objects known as the universe of discourse (note: it refers to all instances/rows 
in datasets) and <code class="reqn">A</code> is a non-empty finite set of attributes, such that <code class="reqn">a : U \to V_{a}</code> for every <code class="reqn">a \in A</code>. 
The set <code class="reqn">V_{a}</code> is the set of values that attribute <code class="reqn">a</code> may take. Information systems that involve a decision attribute, 
containing classes for each object, are called decision systems or decision tables. More formally, it is a pair <code class="reqn">\mathcal{A} = (U, A \cup \{d\})</code>,
where <code class="reqn">d \notin A</code> is the decision attribute. The elements of <code class="reqn">A</code> are called conditional attributes. The information system
representing all data in a particular system may contain redundant parts. It could happen because there are the same 
or indiscernible objects or some superfluous attributes. The indiscernibility relation is a binary relation showing the relation between two objects.
This relation is an equivalence relation.  
Let <code class="reqn">\mathcal{A} = (U, A)</code> be an information system, then for any <code class="reqn">B \subseteq A</code> there is an equivalence 
relation <code class="reqn">R_B(x,y)</code>:
</p>
<p><code class="reqn">R_B(x,y)= \{(x,y) \in U^2 | \forall a \in B, a(x) = a(y)\}</code>
</p>
<p>If <code class="reqn">(x,y) \in R_B(x,y)</code>, then <code class="reqn">x</code> and <code class="reqn">y</code> are indiscernible by attributes from <code class="reqn">B</code>. The equivalence
classes of the <code class="reqn">B</code>-indiscernibility relation are denoted <code class="reqn">[x]_{B}</code>. The indiscernibility relation will be further used to define basic concepts of rough
set theory which are lower and upper approximations.
</p>
<p>Let <code class="reqn">B \subseteq A</code> and <code class="reqn">X \subseteq U</code>,
<code class="reqn">X</code> can be approximated using the information contained within <code class="reqn">B</code> by constructing 
the <code class="reqn">B</code>-lower and <code class="reqn">B</code>-upper approximations of <code class="reqn">X</code>:
</p>
<p><code class="reqn">R_B \downarrow X = \{ x \in U | [x]_{B} \subseteq X \}</code>
</p>
<p><code class="reqn">R_B \uparrow X = \{ x \in U | [x]_{B} \cap X \not= \emptyset \}</code>
</p>
<p>The tuple <code class="reqn">\langle R_B \downarrow X, R_B \uparrow X \rangle</code> is called a rough set.
The objects in <code class="reqn">R_B \downarrow X</code> mean that they can be with certainty classified as members of <code class="reqn">X</code> on the basis of knowledge in <code class="reqn">B</code>, while
the objects in <code class="reqn">R_B \uparrow X</code> can be only classified as possible members of <code class="reqn">X</code> on the basis of knowledge in <code class="reqn">B</code>. 
</p>
<p>In a decision system, for <code class="reqn">X</code> we use decision concepts (equivalence classes of decision attribute) <code class="reqn">[x]_d</code>. 
We can define <code class="reqn">B</code>-lower and <code class="reqn">B</code>-upper approximations as follows.
</p>
<p><code class="reqn">R_B \downarrow [x]_d = \{ x \in U | [x]_{B} \subseteq [x]_d \}</code>
</p>
<p><code class="reqn">R_B \uparrow [x]_d = \{ x \in U | [x]_{B} \cap [x]_d \not= \emptyset \}</code>
</p>
<p>The positive, negative and boundary of <code class="reqn">B</code> regions can be defined as:
</p>
<p><code class="reqn">POS_{B} = \bigcup_{x \in U } R_B \downarrow [x]_d</code>
</p>
<p>The boundary region, <code class="reqn">BND_{B}</code>, is the set of objects that can possibly, but not certainly, be classified.
</p>
<p><code class="reqn">BND_{B} = \bigcup_{x \in U} R_B \uparrow [x]_d - \bigcup_{x \in U} R_B \downarrow [x]_d</code>
</p>
<p>Furthermore, we can calculate the degree of dependency of the decision on a set of attributes. The decision attribute <code class="reqn">d</code>
depends totally on a set of attributes <code class="reqn">B</code>, denoted <code class="reqn">B \Rightarrow d</code>,
if all  attribute values from <code class="reqn">d</code> are uniquely determined by values of attributes from <code class="reqn">B</code>. It can be defined as follows.
For <code class="reqn">B \subseteq A</code>, it is said that <code class="reqn">d</code> depends on <code class="reqn">B</code> in a degree of dependency <code class="reqn">\gamma_{B} = \frac{|POS_{B}|}{|U|}</code>. 
</p>
<p>A decision reduct is a set <code class="reqn">B \subseteq A</code> such that <code class="reqn">\gamma_{B} = \gamma_{A}</code> and <code class="reqn">\gamma_{B'} &lt; \gamma_{B}</code> for every <code class="reqn">B' \subset B</code>.
One algorithm to determine all reducts is by constructing the decision-relative discernibility matrix. 
The discernibility matrix <code class="reqn">M(\mathcal{A})</code> is an <code class="reqn">n \times n</code> matrix <code class="reqn">(c_{ij})</code> where
</p>
<p><code class="reqn">c_{ij} = \{a \in A: a(x_i) \neq a(x_j) \}</code> if <code class="reqn">d(x_i) \neq d(x_j)</code> and
</p>
<p><code class="reqn">c_{ij} = \oslash</code> otherwise
</p>
<p>The discernibility function <code class="reqn">f_{\mathcal{A}}</code> for a decision system <code class="reqn">\mathcal{A}</code> is a boolean function of <code class="reqn">m</code> boolean variables <code class="reqn">\bar{a}_1, \ldots, \bar{a}_m</code>
corresponding to the attributes <code class="reqn">a_1, \ldots, a_m</code> respectively, and defined by
</p>
<p><code class="reqn">f_{\mathcal{A}}(\bar{a_1}, \ldots, \bar{a_m}) = \wedge \{\vee \bar{c}_{ij}: 1 \le j &lt; i \le n, c_{ij} \neq \oslash \}</code>
</p>
<p>where <code class="reqn">\bar{c}_{ij}= \{ \bar{a}: a \in c_{ij}\}</code>. The decision reducts of <code class="reqn">A</code> are then the prime implicants of the function <code class="reqn">f_{\mathcal{A}}</code>. 
The complete explanation of the algorithm can be seen in (Skowron and Rauszer, 1992).
</p>
<p>The implementations of the RST concepts can be seen in <code><a href="#topic+BC.IND.relation.RST">BC.IND.relation.RST</a></code>, 
</p>
<p><code><a href="#topic+BC.LU.approximation.RST">BC.LU.approximation.RST</a></code>, <code><a href="#topic+BC.positive.reg.RST">BC.positive.reg.RST</a></code>, and 
</p>
<p><code><a href="#topic+BC.discernibility.mat.RST">BC.discernibility.mat.RST</a></code>.
</p>


<h3>Introduction to Fuzzy Rough Set Theory</h3>

<p>This part introduces briefly fuzzy rough set theory (FRST) and its application to data analysis. 
Since recently there are a lot of FRST variants that have been
proposed by researchers, in this introduction, we only provide some basic concepts of FRST based on (Radzikowska and Kerre, 2002). 
</p>
<p>Just like in RST (see <code><a href="#topic+Introduction-RoughSets">Introduction-RoughSets</a></code>),
a data set is represented as a table called an information system <code class="reqn">\mathcal{A} = (U, A)</code>, where
<code class="reqn">U</code> is a non-empty set of finite objects as the universe of discourse (note: it refers to all instances/experiments/rows 
in datasets) and <code class="reqn">A</code> is a non-empty finite set of attributes, such that <code class="reqn">a : U \to V_{a}</code> for every <code class="reqn">a \in A</code>. 
The set <code class="reqn">V_{a}</code> is the set of values that attribute <code class="reqn">a</code> may take. Information systems that involve a decision attribute, 
containing classes or decision values of each objects, are called decision systems (or said as decision tables). More formally, it is a pair <code class="reqn">\mathcal{A} = (U, A \cup \{d\})</code>,
where <code class="reqn">d \notin A</code> is the decision attribute. The elements of <code class="reqn">A</code> are called conditional attributes. However, different from RST, FRST has several ways
to express indiscernibility. 
</p>
<p>Fuzzy indiscernibility relation (FIR) is used for any fuzzy relation that determines the degree to which two objects are indiscernible. 
We consider some special cases of FIR.
</p>

<ul>
<li><p> fuzzy tolerance relation: this relation has properties which are reflexive and symmetric where
</p>
<p>reflexive: <code class="reqn">R(x,x) = 1</code>
</p>
<p>symmetric: <code class="reqn">R(x,y) = R(y,x)</code>
</p>
</li>
<li><p> similarity relation (also called fuzzy equivalence relation): this relation has properties not only reflexive and symmetric but also
transitive defined as
</p>
<p><code class="reqn">min(R(x,y), R(y,z)) \le R(x,z)</code>
</p>
</li>
<li> <p><code class="reqn">\mathcal{T}</code>-similarity relation (also called fuzzy <code class="reqn">\mathcal{T}</code>-equivalence relation): this relation is a fuzzy tolerance relation that is also <code class="reqn">\mathcal{T}</code>-transitive.
</p>
<p><code class="reqn">\mathcal{T}(R(x,y), R(y,z)) \le R(x,z)</code>, for a given triangular norm <code class="reqn">\mathcal{T}</code>. 
</p>
</li></ul>

<p>The following equations are the tolerance relations on a quantitative attribute <code class="reqn">a</code>, <code class="reqn">R_a</code>, proposed by (Jensen and Shen, 2009).
</p>

<ul>
<li> <p><code>eq.1</code>: <code class="reqn">R_a(x,y) = 1 - \frac{|a(x) - a(y)|}{|a_{max} - a_{min}|}</code>
</p>
</li>
<li> <p><code>eq.2</code>: <code class="reqn">R_a(x,y) = exp(-\frac{(a(x) - a(y))^2}{2 \sigma_a^2})</code>
</p>
</li>
<li> <p><code>eq.3</code>: <code class="reqn">R_a(x,y) = max(min(\frac{a(y) - a(x) + \sigma_a}{\sigma_a}, \frac{a(x) - a(y) + \sigma_a}{\sigma_a}), 0)</code>
</p>
</li></ul>

<p>where <code class="reqn">\sigma_{a}^2</code> is the variance of feature <code class="reqn">a</code> and <code class="reqn">a_{min}</code> and <code class="reqn">a_{max}</code> are the minimal and maximal values of data supplied by user. 
Additionally, other relations have been implemented in <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code>
</p>
<p>For a qualitative (i.e., nominal) attribute <code class="reqn">a</code>, the classical manner of discerning objects is used, i.e., <code class="reqn">R_a(x,y) = 1</code>
if <code class="reqn">a(x) = a(y)</code> and <code class="reqn">R_a(x,y) = 0</code>, otherwise. We can then define, for any subset <code class="reqn">B</code> of <code class="reqn">A</code>, the fuzzy <code class="reqn">B</code>-indiscernibility relation by
</p>
<p><code class="reqn">R_B(x,y) = \mathcal{T}(R_a(x,y))</code>,
</p>
<p>where <code class="reqn">\mathcal{T}</code> is a t-norm operator, for instance minimum, product and Lukasiewicz t-norm. 
In general, <code class="reqn">\mathcal{T}</code> can be replaced by any aggregation operator, like e.g., the average.
</p>
<p>In the context of FRST, according to (Radzikowska and Kerre, 2002) lower and upper approximation 
are generalized by means of an implicator <code class="reqn">\mathcal{I}</code> and a t-norm <code class="reqn">\mathcal{T}</code>. 
The following are the fuzzy <code class="reqn">B</code>-lower and <code class="reqn">B</code>-upper approximations of a fuzzy set <code class="reqn">A</code> in <code class="reqn">U</code>
</p>
<p><code class="reqn">(R_B \downarrow A)(y) = inf_{x \in U} \mathcal{I}(R_B(x,y), A(x))</code>
</p>
<p><code class="reqn">(R_B \uparrow A)(y) = sup_{x \in U} \mathcal{T}(R_B(x,y), A(x))</code>
</p>
<p>The underlying meaning is that <code class="reqn">R_B \downarrow A</code> is the set of elements <em>necessarily</em> satisfying
the concept (strong membership), while <code class="reqn">R_B \uparrow A</code> is the set of elements <em>possibly</em> belonging
to the concept (weak membership). Many other ways to define the approximations can be found in <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.
Mainly, these were designed to deal with noise in the data and to make the approximations more robust.
</p>
<p>Based on fuzzy <code class="reqn">B</code>-indiscernibility relations, we define the fuzzy <code class="reqn">B</code>-positive region by, for <code class="reqn">y \in X</code>,
</p>
<p><code class="reqn">POS_B(y) = (\cup_{x \in U} R_B \downarrow R_dx)(y)</code>
</p>
<p>We can define the degree of dependency of <code class="reqn">d</code> on <code class="reqn">B</code>, <code class="reqn">\gamma_{B}</code> by
</p>
<p><code class="reqn">\gamma_{B} = \frac{|POS_{B}|}{|U|} = \frac{\sum_{x \in U} POS_{B}(x)}{|U|}</code>
</p>
<p>A decision reduct is a set <code class="reqn">B \subseteq A</code> such that <code class="reqn">\gamma_{B} = \gamma_{A}</code> and <code class="reqn">\gamma_{B'} = \gamma_{B}</code> for every <code class="reqn">B' \subset B</code>. 
</p>
<p>As we know from rough set concepts (See <code><a href="#topic+Introduction-RoughSets">Introduction-RoughSets</a></code>), we are able to calculate the 
decision reducts by constructing the decision-relative discernibility matrix. Based on (Tsang et al, 2008), the discernibility matrix
can be defined as follows. 
The discernibility matrix is an <code class="reqn">n \times n</code> matrix <code class="reqn">(c_{ij})</code> where 
for <code class="reqn">i,j = 1, \ldots, n</code>
</p>
<p>1) <code class="reqn">c_{ij}= \{a \in A : 1 - R_{a}(x_i, x_j) \ge	\lambda_i\}</code> if <code class="reqn">\lambda_j &lt; \lambda_i</code>.
</p>
<p>2) <code class="reqn">c_{ij}={\oslash}</code>, otherwise. 
</p>
<p>with <code class="reqn">\lambda_i = (R_A \downarrow R_{d}x_{i})(x_i)</code> and <code class="reqn">\lambda_j = (R_A \downarrow R_{d}x_{j})(x_{j})</code>
</p>
<p>Other approaches of discernibility matrix can be read at <code><a href="#topic+BC.discernibility.mat.FRST">BC.discernibility.mat.FRST</a></code>.
</p>
<p>The other implementations of the FRST concepts can be seen at <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code>, 
</p>
<p><code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>, and <code><a href="#topic+BC.positive.reg.FRST">BC.positive.reg.FRST</a></code>.
</p>


<h3>Author(s)</h3>

<p>Lala Septem Riza <a href="mailto:lala.s.riza@decsai.ugr.es">lala.s.riza@decsai.ugr.es</a>,
</p>
<p>Andrzej Janusz <a href="mailto:andrzejanusz@gmail.com">andrzejanusz@gmail.com</a>,
</p>
<p>Chris Cornelis <a href="mailto:chriscornelis@decsai.ugr.es">chriscornelis@decsai.ugr.es</a>,
</p>
<p>Francisco Herrera <a href="mailto:herrera@decsai.ugr.es">herrera@decsai.ugr.es</a>,
</p>
<p>Dominik Slezak <a href="mailto:slezak@mimuw.edu.pl">slezak@mimuw.edu.pl</a>,
</p>
<p>and Jose Manuel Benitez <a href="mailto:j.m.benitez@decsai.ugr.es">j.m.benitez@decsai.ugr.es</a>
</p>
<p>DiCITS Lab, SCI2S group, CITIC-UGR, DECSAI, University of Granada,
</p>
<p><a href="https://sci2s.ugr.es">https://sci2s.ugr.es</a>
</p>
<p>Institute of Mathematics, University of Warsaw.
</p>


<h3>References</h3>

<p>D. Dubois and H. Prade, &quot;Rough Fuzzy Sets and Fuzzy Rough Sets&quot;,
International Journal of General Systems, vol. 17, p. 91 - 209 (1990).
</p>
<p><em>General references</em>
</p>
<p>L.A. Zadeh, &quot;Fuzzy Sets&quot;,
Information and Control, vol. 8, p. 338 - 353 (1965).
</p>
<p>Z. Pawlak, &quot;Rough Sets&quot;,
International Journal of Computer and Information System,
vol. 11, no. 5, p. 341 - 356 (1982).
</p>
<p>Z. Pawlak, &quot;Rough Sets: Theoretical Aspects of Reasoning About Data, System Theory, Knowledge Engineering and Problem Solving&quot;,
vol. 9, Kluwer Academic Publishers, Dordrecht, Netherlands (1991).
</p>
<p><em>Introduction to Rough Set Theory  references</em>
</p>
<p>A. Skowron and C. Rauszer,  
&quot;The Discernibility Matrices and Functions in Information Systems&quot;, 
in: R. Slowinski (Ed.), Intelligent Decision Support: Handbook of Applications and
Advances of Rough Sets Theory, Kluwer Academic Publishers, Dordrecht, Netherland,  
p. 331 - 362 (1992).
</p>
<p>Z. Pawlak, &quot;Rough Sets&quot;, 
International Journal of Computer and Information System, 
vol. 11, no.5, p. 341 - 356 (1982).
</p>
<p>Z. Pawlak, &quot;Rough Sets: Theoretical Aspects of Reasoning about Data, System Theory, Knowledge Engineering and Problem Solving&quot;,
vol. 9, Kluwer Academic Publishers, Dordrecht, Netherlands (1991). 
</p>
<p><em>Introduction to Fuzzy Rough Set Theory references</em>
</p>
<p>A. M. Radzikowska and E. E. Kerre, &quot;A Comparative Study of Fuzzy Rough Sets&quot;, 
Fuzzy Sets and Systems, vol. 126, p. 137 - 156 (2002). 
</p>
<p>D. Dubois and H. Prade, &quot;Rough Fuzzy Sets and Fuzzy Rough Sets&quot;,
International Journal of General Systems, vol. 17, p. 91 - 209 (1990).
</p>
<p>E. C. C. Tsang, D. G. Chen, D. S. Yeung, X. Z. Wang, and J. W. T. Lee, 
&quot;Attributes Reduction Using Fuzzy Rough Sets&quot;, IEEE Trans. Fuzzy Syst., 
vol. 16, no. 5, p. 1130 - 1141 (2008).
</p>
<p>L. A. Zadeh, &quot;Fuzzy Sets&quot;,
Information and Control, vol. 8, p. 338 - 353 (1965).
</p>
<p>R. Jensen and Q. Shen,  
&quot;New Approaches to Fuzzy-Rough Feature Selection&quot;, 
IEEE Trans. on Fuzzy Systems, vol. 19, no. 4,
p. 824 - 838 (2009).
</p>
<p>Z. Pawlak, &quot;Rough Sets&quot;, International Journal of Computer and Information Sciences, 
vol. 11, no. 5, p. 341 - 356 (1982).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##############################################################
## A.1 Example: Basic concepts of rough set theory
##############################################################
## Using hiring data set, see RoughSetData
data(RoughSetData)
decision.table &lt;- RoughSetData$hiring.dt

## define considered attributes which are first, second, and
## third attributes
attr.P &lt;- c(1,2,3)

## compute indiscernibility relation
IND &lt;- BC.IND.relation.RST(decision.table, feature.set = attr.P)

## compute lower and upper approximations
roughset &lt;- BC.LU.approximation.RST(decision.table, IND)

## Determine regions
region.RST &lt;- BC.positive.reg.RST(decision.table, roughset)

## The decision-relative discernibility matrix and reduct
disc.mat &lt;- BC.discernibility.mat.RST(decision.table, range.object = NULL)

##############################################################
## A.2 Example: Basic concepts of fuzzy rough set theory
##############################################################
## Using pima7 data set, see RoughSetData
data(RoughSetData)
decision.table &lt;- RoughSetData$pima7.dt

## In this case, let us consider the first and second attributes
conditional.attr &lt;- c(1, 2)

## We are using the "lukasiewicz" t-norm and the "tolerance" relation
## with "eq.1" as fuzzy similarity equation
control.ind &lt;- list(type.aggregation = c("t.tnorm", "lukasiewicz"),
                    type.relation = c("tolerance", "eq.1"))

## Compute fuzzy indiscernibility relation
IND.condAttr &lt;- BC.IND.relation.FRST(decision.table, attributes = conditional.attr,
                            control = control.ind)

## Compute fuzzy lower and upper approximation using type.LU : "implicator.tnorm"
## Define index of decision attribute
decision.attr = c(9)

## Compute fuzzy indiscernibility relation of decision attribute
## We are using "crisp" for type of aggregation and type of relation
control.dec &lt;- list(type.aggregation = c("crisp"), type.relation = "crisp")

IND.decAttr &lt;- BC.IND.relation.FRST(decision.table, attributes = decision.attr,
                            control = control.dec)

## Define control parameter containing type of implicator and t-norm
control &lt;- list(t.implicator = "lukasiewicz", t.tnorm = "lukasiewicz")

## Compute fuzzy lower and upper approximation
FRST.LU &lt;- BC.LU.approximation.FRST(decision.table, IND.condAttr, IND.decAttr,
              type.LU = "implicator.tnorm", control = control)

## Determine fuzzy positive region and its degree of dependency
fuzzy.region &lt;- BC.positive.reg.FRST(decision.table, FRST.LU)

###############################################################
## B Example : Data analysis based on RST and FRST
## In this example, we are using wine dataset for both RST and FRST
###############################################################
## Load the data
## Not run: data(RoughSetData)
dataset &lt;- RoughSetData$wine.dt

## Shuffle the data with set.seed
set.seed(5)
dt.Shuffled &lt;- dataset[sample(nrow(dataset)),]

## Split the data into training and testing
idx &lt;- round(0.8 * nrow(dt.Shuffled))
  wine.tra &lt;-SF.asDecisionTable(dt.Shuffled[1:idx,],
decision.attr = 14, indx.nominal = 14)
  wine.tst &lt;- SF.asDecisionTable(dt.Shuffled[
 (idx+1):nrow(dt.Shuffled), -ncol(dt.Shuffled)])

## DISCRETIZATION
cut.values &lt;- D.discretization.RST(wine.tra,
type.method = "global.discernibility")
d.tra &lt;- SF.applyDecTable(wine.tra, cut.values)
d.tst &lt;- SF.applyDecTable(wine.tst, cut.values)

## FEATURE SELECTION
red.rst &lt;- FS.feature.subset.computation(d.tra,
  method="quickreduct.rst")
fs.tra &lt;- SF.applyDecTable(d.tra, red.rst)

## RULE INDUCTION
rules &lt;- RI.indiscernibilityBasedRules.RST(d.tra,
  red.rst)

## predicting newdata
pred.vals &lt;- predict(rules, d.tst)

#################################################
## Examples: Data analysis using the wine dataset
## 2. Learning and prediction using FRST
#################################################

## FEATURE SELECTION
reduct &lt;- FS.feature.subset.computation(wine.tra,
 method = "quickreduct.frst")

## generate new decision tables
wine.tra.fs &lt;- SF.applyDecTable(wine.tra, reduct)
wine.tst.fs &lt;- SF.applyDecTable(wine.tst, reduct)

## INSTANCE SELECTION
indx &lt;- IS.FRIS.FRST(wine.tra.fs,
 control = list(threshold.tau = 0.2, alpha = 1))

## generate a new decision table
wine.tra.is &lt;- SF.applyDecTable(wine.tra.fs, indx)

## RULE INDUCTION (Rule-based classifiers)
control.ri &lt;- list(
 type.aggregation = c("t.tnorm", "lukasiewicz"),
 type.relation = c("tolerance", "eq.3"),
 t.implicator = "kleene_dienes")

decRules.hybrid &lt;- RI.hybridFS.FRST(wine.tra.is,
  control.ri)

## predicting newdata
predValues.hybrid &lt;- predict(decRules.hybrid,
  wine.tst.fs)

#################################################
## Examples: Data analysis using the wine dataset
## 3. Prediction using fuzzy nearest neighbor classifiers
#################################################

## using FRNN.O
control.frnn.o &lt;- list(m = 2,
  type.membership = "gradual")

predValues.frnn.o &lt;- C.FRNN.O.FRST(wine.tra.is,
  newdata = wine.tst.fs, control = control.frnn.o)

## Using FRNN
control.frnn &lt;- list(type.LU = "implicator.tnorm",k=20,
  type.aggregation = c("t.tnorm", "lukasiewicz"),
  type.relation = c("tolerance", "eq.1"),
  t.implicator = "lukasiewicz")

predValues.frnn &lt;- C.FRNN.FRST(wine.tra.is,
  newdata = wine.tst.fs, control = control.frnn)

## calculating error
real.val &lt;- dt.Shuffled[(idx+1):nrow(dt.Shuffled),
  ncol(dt.Shuffled), drop = FALSE]

err.1 &lt;- 100*sum(pred.vals!=real.val)/nrow(pred.vals)
err.2 &lt;- 100*sum(predValues.hybrid!=real.val)/
  nrow(predValues.hybrid)
err.3 &lt;- 100*sum(predValues.frnn.o!=real.val)/
  nrow(predValues.frnn.o)
err.4 &lt;- 100*sum(predValues.frnn!=real.val)/
  nrow(predValues.frnn)

cat("The percentage error = ", err.1, "\n")
cat("The percentage error = ", err.2, "\n")
cat("The percentage error = ", err.3, "\n")
cat("The percentage error = ", err.4, "\n")
## End(Not run)
</code></pre>

<hr>
<h2 id='+5B.RuleSetRST'>The <code>[.</code> method for <code>"RuleSetRST"</code> objects</h2><span id='topic++5B.RuleSetRST'></span><span id='topic+Extract.RuleSetRST'></span>

<h3>Description</h3>

<p>Subsetting a set of decision rules.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'RuleSetRST'
x[i, ...]
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B5B.RuleSetRST_+3A_x">x</code></td>
<td>
<p>a <code>"RuleSetRST"</code> object from which to extract rules(s) or in which to replace rules(s).
See <code><a href="#topic+RI.LEM2Rules.RST">RI.LEM2Rules.RST</a></code>.</p>
</td></tr>
<tr><td><code id="+2B5B.RuleSetRST_+3A_i">i</code></td>
<td>
<p>integer indices specifying elements to be extracted or replaced.</p>
</td></tr>
<tr><td><code id="+2B5B.RuleSetRST_+3A_...">...</code></td>
<td>
<p>the other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A subset of rules.
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###########################################################
## Example : Subsetting a set of decision rules
###########################################################
data(RoughSetData)
hiring.data &lt;- RoughSetData$hiring.dt

rules &lt;- RI.LEM2Rules.RST(hiring.data)

rules

# taking a subset of rules
rules[1:3]
rules[c(TRUE,FALSE,TRUE,FALSE)]

# replacing a subset of rules
rules2 &lt;- rules
rules2[c(2,4)] &lt;- rules[c(1,3)]
rules2
</code></pre>

<hr>
<h2 id='as.character.RuleSetRST'>The <code>as.character</code> method for RST rule sets</h2><span id='topic+as.character.RuleSetRST'></span>

<h3>Description</h3>

<p>A function for converting a set of rules into their character representation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'RuleSetRST'
as.character(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.character.RuleSetRST_+3A_x">x</code></td>
<td>
<p>a <code>"RuleSetRST"</code> object. See <code><a href="#topic+RI.LEM2Rules.RST">RI.LEM2Rules.RST</a></code>.</p>
</td></tr>
<tr><td><code id="as.character.RuleSetRST_+3A_...">...</code></td>
<td>
<p>the other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Converts rules from a set into their character representation.
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###########################################################
## Example : Converting a set of decision rules
###########################################################
data(RoughSetData)
hiring.data &lt;- RoughSetData$hiring.dt

rules &lt;- RI.LEM2Rules.RST(hiring.data)

as.character(rules)
</code></pre>

<hr>
<h2 id='as.list.RuleSetRST'>The <code>as.list</code> method for RST rule sets</h2><span id='topic+as.list.RuleSetRST'></span>

<h3>Description</h3>

<p>A function for converting a set of rules into a list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'RuleSetRST'
as.list(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.list.RuleSetRST_+3A_x">x</code></td>
<td>
<p>a <code>"RuleSetRST"</code> object. See <code><a href="#topic+RI.LEM2Rules.RST">RI.LEM2Rules.RST</a></code>.</p>
</td></tr>
<tr><td><code id="as.list.RuleSetRST_+3A_...">...</code></td>
<td>
<p>the other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Converts rules from a set into a list.
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###########################################################
## Example : Converting a set of decision rules
###########################################################
data(RoughSetData)
hiring.data &lt;- RoughSetData$hiring.dt

rules &lt;- RI.LEM2Rules.RST(hiring.data)

as.list(rules)
</code></pre>

<hr>
<h2 id='BC.boundary.reg.RST'>Computation of a boundary region</h2><span id='topic+BC.boundary.reg.RST'></span>

<h3>Description</h3>

<p>This function implements a fundamental part of RST: computation of a boundary region and the
degree of dependency. This function can be used as a basic building block for development 
of other RST-based methods. A more detailed explanation of this notion can be found 
in <code><a href="#topic+Introduction-RoughSets">Introduction-RoughSets</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BC.boundary.reg.RST(decision.table, roughset)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BC.boundary.reg.RST_+3A_decision.table">decision.table</code></td>
<td>
<p>an object inheriting from the <code>"DecisionTable"</code> class, which represents a decision system. 
See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="BC.boundary.reg.RST_+3A_roughset">roughset</code></td>
<td>
<p>an object inheriting from the <code>"LowerUpperApproximation"</code> class, which represents
lower and upper approximations of decision classes in the data. Such objects are typically produced by calling 
the <code><a href="#topic+BC.LU.approximation.RST">BC.LU.approximation.RST</a></code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of a class <code>"BoundaryRegion"</code> which is a list with the following components:
</p>

<ul>
<li> <p><code>boundary.reg</code>: an integer vector containing indices of data instances belonging 
to the boundary region,
</p>
</li>
<li> <p><code>degree.dependency</code>: a numeric value giving the degree of dependency,
</p>
</li>
<li> <p><code>type.model</code>: a varacter vector identifying the utilized model. In this case, 
it is <code>"RST"</code> which means the rough set theory.       
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Dariusz Jankowski, Andrzej Janusz
</p>


<h3>References</h3>

<p>Z. Pawlak, &quot;Rough Sets&quot;, International Journal of Computer and Information Sciences, 
vol. 11, no. 5, p. 341 - 356 (1982).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BC.IND.relation.RST">BC.IND.relation.RST</a></code>, <code><a href="#topic+BC.LU.approximation.RST">BC.LU.approximation.RST</a></code>, <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>########################################################
data(RoughSetData)
hiring.data &lt;- RoughSetData$hiring.dt

## We select a single attribute for computation of indiscernibility classes:
A &lt;- c(2)

## compute the indiscernibility classes:
IND.A &lt;- BC.IND.relation.RST(hiring.data, feature.set = A)

## compute the lower and upper approximation:
roughset &lt;- BC.LU.approximation.RST(hiring.data, IND.A)

## get the boundary region:
pos.boundary = BC.boundary.reg.RST(hiring.data, roughset)
pos.boundary

</code></pre>

<hr>
<h2 id='BC.discernibility.mat.FRST'>The decision-relative discernibility matrix based on fuzzy rough set theory</h2><span id='topic+BC.discernibility.mat.FRST'></span>

<h3>Description</h3>

<p>This is a function that is used to build the decision-relative discernibility matrix based on FRST.
It is a matrix whose elements contain discernible attributes among pairs of objects. 
By means of this matrix, we are able to produce all decision reducts of the given decision system.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BC.discernibility.mat.FRST(
  decision.table,
  type.discernibility = "standard.red",
  control = list()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BC.discernibility.mat.FRST_+3A_decision.table">decision.table</code></td>
<td>
<p>a <code>"DecisionTable"</code> class representing the decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>. 
It should be noted that this case only supports the nominal/symbolic decision attribute.</p>
</td></tr>
<tr><td><code id="BC.discernibility.mat.FRST_+3A_type.discernibility">type.discernibility</code></td>
<td>
<p>a string representing a type of discernibility. See in Section <code>Details</code>.</p>
</td></tr>
<tr><td><code id="BC.discernibility.mat.FRST_+3A_control">control</code></td>
<td>
<p>a list of other parameters.
</p>

<ul>
<li> <p><code>type.relation</code>: a type of fuzzy indiscernibility relation. The default value is <code>type.relation = c("tolerance", "eq.1")</code>.
</p>
<p>See <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code>.
</p>
</li>
<li> <p><code>type.aggregation</code>: a type of aggregation operator. The default value is <code>type.aggregation = c("t.tnorm", "lukasiewicz")</code>.
</p>
<p>See <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code>.
</p>
</li>
<li> <p><code>t.implicator</code>: a type of implicator operator. The default value is <code>"lukasiewicz"</code>.
</p>
<p>See <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.
</p>
</li>
<li> <p><code>type.LU</code>: a type of method of lower and upper approximations. The default value is <code>"implicator.tnorm"</code>.
</p>
<p>See <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.
</p>
</li>
<li> <p><code>alpha.precision</code>: a numeric value representing a precision variable. It is used when using <code>"alpha.red"</code> as <code>type.discernibility</code>.
The default value is 0.05.
</p>
<p>See <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.  
</p>
</li>
<li> <p><code>show.discernibilityMatrix</code>: a boolean value determining whether the discernibility matrix will be shown or not (NULL). The default value is <code>FALSE</code>.
</p>
</li>
<li> <p><code>epsilon</code>: a numeric between 0 and 1 representing the <code class="reqn">\epsilon</code> value on 
</p>
<p><code>type.discernibility = "gaussian.red"</code>. It should be noted that when having nominal values on all attributes then <code class="reqn">\epsilon</code> should be 0. 
The default value is 0.
</p>
</li>
<li> <p><code>delta</code>: a numeric representing the <code class="reqn">\delta</code> value on <code>"gaussian"</code> equations 
</p>
<p>(see <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code>). The default value is 2.
</p>
</li>
<li> <p><code>range.object</code>: a vector representing considered objects to construct the <code>k</code>-relative discernibility matrix. 
The default value is <code>NULL</code> which means that we are using all objects in the decision table.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>In this function, we provide several approaches in order to generate the decision-relative discernibility matrix. 
Theoretically, all reducts are found by constructing 
the matrix that contains elements showing discernible attributes among objects. 
The discernible attributes are determined by a specific condition which depends on the selected algorithm. A particular approach can be executed by selecting
a value of the parameter <code>type.discernibility</code>. The following shows the different 
values of the parameter <code>type.discernibility</code> corresponding approaches considered in this function.
</p>

<ul>
<li> <p><code>"standard.red"</code>: It is adopted from (Tsang et al, 2008)'s approach. 
The concept has been explained briefly in <code><a href="#topic+Introduction-FuzzyRoughSets">Introduction-FuzzyRoughSets</a></code>. 
In order to use this algorithm, we assign the <code>control</code> parameter
with the following components:
</p>
<p><code>control = list(type.aggregation, type.relation, type.LU, t.implicator)</code>
</p>
<p>The detailed description of the components can be seen in <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code> and 
</p>
<p><code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>. Furthermore, in this case the authors suggest to use the &quot;min&quot; t-norm  
(i.e., <code>type.aggregation = c("t.tnorm", "min")</code>) and the implicator operator &quot;kleene_dienes&quot; (i.e., <code>t.implicator = "kleene_dienes"</code>).
</p>
</li>
<li> <p><code>"alpha.red"</code>: It is based on (Zhao et al, 2009)'s approach where all reductions will 
be found by building an <code class="reqn">\alpha</code>-discernibility matrix. This matrix contains elements which are defined by
</p>
<p>1) if <code class="reqn">x_i</code> and <code class="reqn">x_j</code> belong to different decision concept,
</p>
<p><code class="reqn">c_{ij} = \{R : \mathcal{T}(R(x_i, x_j), \lambda) \le \alpha \}</code>,
</p>
<p>where <code class="reqn">\lambda = (R_{\alpha} \downarrow A)(u)</code> which is lower approximation 
of FVPRS (See <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>). 
</p>
<p>2) <code class="reqn">c_{ij}={\oslash}</code>, otherwise.
</p>
<p>To generate the discernibility matrix based on this approach, we use the <code>control</code> parameter
with the following components:
</p>
<p><code>control = list(type.aggregation, type.relation, t.implicator, alpha.precision)</code> 
</p>
<p>where the lower approximation <code class="reqn">\lambda</code> is fixed to <code>type.LU = "fvprs"</code>. The detailed
description of the components can be seen in <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code> and <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.
Furthermore, in this case the authors suggest to use <code class="reqn">\mathcal{T}</code>-similarity relation 
</p>
<p>e.g., <code>type.relation = c("transitive.closure", "eq.3")</code>,
</p>
<p>the &quot;lukasiewicz&quot; t-norm  (i.e., <code>type.aggregation = c("t.tnorm", "lukasiewicz")</code>), and <code>alpha.precision</code> from 0 to 0.5.
</p>
</li>
<li> <p><code>"gaussian.red"</code>: It is based on (Chen et al, 2011)'s approach. The discernibility matrix contains elements which are defined by: 
</p>
<p>1) if <code class="reqn">x_i</code> and <code class="reqn">x_j</code> belong to different decision concept, 
</p>
<p><code class="reqn">c_{ij}= \{R : R(x_i, x_j) \le \sqrt{1 - \lambda^2(x_i)}\}</code>,
</p>
<p>where <code class="reqn">\lambda = inf_{u \in U}\mathcal{I}_{cos}(R(x_i, u), A(u)) - \epsilon</code>. To generate fuzzy relation <code class="reqn">R</code> , we use the fixed parameters as follows:
</p>
<p><code>t.tnorm = "t.cos"</code> and <code>type.relation = c("transitive.kernel", "gaussian")</code>. 
</p>
<p>2) <code class="reqn">c_{ij}={\oslash}</code>, otherwise.
</p>
<p>In this case, we need to define <code>control</code> parameter as follows.
</p>
<p><code>control &lt;- list(epsilon)</code>
</p>
<p>It should be noted that when having nominal values on all attributes then <code>epsilon</code> (<code class="reqn">\epsilon</code>) should be 0. 
</p>
</li>
<li> <p><code>"min.element"</code>: It is based on (Chen et al, 2012)'s approach where we only consider finding 
the minimal element of the discernibility matrix by introducing the binary relation <code class="reqn">DIS(R)</code> the relative discernibility relation 
of conditional attribute <code class="reqn">R</code> with respect to decision attribute <code class="reqn">d</code>, which is computed as
</p>
<p><code class="reqn">DIS(R) = \{(x_i, x_j) \in U \times U: 1 - R(x_i, x_j) &gt; \lambda_i, x_j \notin [x_i]_d\}</code>,
</p>
<p>where <code class="reqn">\lambda_i = (Sim(R) \downarrow [x_i]_d)(x_i)</code> with <code class="reqn">Sim(R)</code> a fuzzy equivalence relation. 
In other words, this algorithm does not need to build the discernibility matrix. 
To generate the fuzzy relation <code class="reqn">R</code> and lower approximation <code class="reqn">\lambda</code>, we use the <code>control</code> parameter
with the following components:
</p>
<p><code>control = list(type.aggregation, type.relation, type.LU, t.implicator)</code>. 
</p>
<p>The detailed description of the components can be seen in <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code> and 
</p>
<p><code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.
</p>
</li></ul>



<h3>Value</h3>

<p>A class <code>"DiscernibilityMatrix"</code> containing the following components: 
</p>

<ul>
<li> <p><code>disc.mat</code>: a matrix showing the decision-relative discernibility matrix <code class="reqn">M(\mathcal{A})</code> 
which contains <code class="reqn">n \times n</code> where <code class="reqn">n</code> is the number of objects. It will be printed when choosing 
</p>
<p><code>show.discernibilityMatrix = TRUE</code>.
</p>
</li>
<li> <p><code>disc.list</code>: the decision-relative discernibility represented in a list.
</p>
</li>
<li> <p><code>discernibility.type</code>: a string showing the chosen type of discernibility methods.
</p>
</li>
<li> <p><code>type.model</code>: in this case, it is <code>"FRST"</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>References</h3>

<p>D. Chen, L. Zhang, S. Zhao, Q. Hu, and P. Zhu, &quot;A Novel Algorithm for Finding Reducts 
with Fuzzy Rough Sets&quot;, IEEE Trans. on Fuzzy Systems, vol. 20, no. 2, p. 385 - 389 (2012). 
</p>
<p>D. G. Chen, Q. H. Hu, and Y. P. Yang, &quot;Parameterized Attribute Reduction with
Gaussian Kernel Based Fuzzy Rough Sets&quot;, Information Sciences, vol. 181, no. 23, 
p. 5169 - 5179 (2011).
</p>
<p>E. C. C. Tsang, D. G. Chen, D. S. Yeung, X. Z. Wang, and J. W. T. Lee, 
&quot;Attributes Reduction Using Fuzzy Rough Sets&quot;, IEEE Trans. Fuzzy Syst., 
vol. 16, no. 5, p. 1130 - 1141 (2008).
</p>
<p>S. Zhao, E. C. C. Tsang, and D. Chen, &quot;The Model of Fuzzy Variable Precision Rough Sets&quot;,
IEEE Trans. on Fuzzy Systems, vol. 17, no. 2, p. 451 - 467 (2009).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BC.discernibility.mat.RST">BC.discernibility.mat.RST</a></code>, <code><a href="#topic+BC.LU.approximation.RST">BC.LU.approximation.RST</a></code>, and <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#######################################################################
## Example 1: Constructing the decision-relative discernibility matrix
## In this case, we are using The simple Pima dataset containing 7 rows. 
#######################################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$pima7.dt 

## using "standard.red"
control.1 &lt;- list(type.relation = c("tolerance", "eq.1"), 
                type.aggregation = c("t.tnorm", "min"), 
                t.implicator = "kleene_dienes", type.LU = "implicator.tnorm")
res.1 &lt;- BC.discernibility.mat.FRST(decision.table, type.discernibility = "standard.red", 
                                    control = control.1)

## using "gaussian.red"
control.2 &lt;- list(epsilon = 0)
res.2 &lt;- BC.discernibility.mat.FRST(decision.table, type.discernibility = "gaussian.red",
                                    control = control.2)

## using "alpha.red"
control.3 &lt;- list(type.relation = c("tolerance", "eq.1"), 
                type.aggregation = c("t.tnorm", "min"),
                t.implicator = "lukasiewicz", alpha.precision = 0.05)
res.3 &lt;- BC.discernibility.mat.FRST(decision.table, type.discernibility = "alpha.red", 
                                    control = control.3)

## using "min.element"
control.4 &lt;- list(type.relation = c("tolerance", "eq.1"), 
                type.aggregation = c("t.tnorm", "lukasiewicz"),
                t.implicator = "lukasiewicz", type.LU = "implicator.tnorm")
res.4 &lt;- BC.discernibility.mat.FRST(decision.table, type.discernibility = "min.element", 
                                    control = control.4)

#######################################################################
## Example 2: Constructing the decision-relative discernibility matrix
## In this case, we are using the Hiring dataset containing nominal values
#######################################################################
## Not run: data(RoughSetData)
decision.table &lt;- RoughSetData$hiring.dt 

control.1 &lt;- list(type.relation = c("crisp"), 
                type.aggregation = c("crisp"),
                t.implicator = "lukasiewicz", type.LU = "implicator.tnorm")
res.1 &lt;- BC.discernibility.mat.FRST(decision.table, type.discernibility = "standard.red", 
                                    control = control.1)

control.2 &lt;- list(epsilon = 0)
res.2 &lt;- BC.discernibility.mat.FRST(decision.table, type.discernibility = "gaussian.red",
                                    control = control.2)
## End(Not run)
</code></pre>

<hr>
<h2 id='BC.discernibility.mat.RST'>Computation of a decision-relative discernibility matrix based on the rough set theory</h2><span id='topic+BC.discernibility.mat.RST'></span>

<h3>Description</h3>

<p>This function implements a fundamental part of RST: a decision-relative discernibility matrix. This notion
was proposed by (Skowron and Rauszer, 1992) as a middle-step in many RST algorithms for computaion of reducts, 
discretization and rule induction. A more detailed explanation of this notion can be found 
in <code><a href="#topic+Introduction-RoughSets">Introduction-RoughSets</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BC.discernibility.mat.RST(
  decision.table,
  range.object = NULL,
  return.matrix = FALSE,
  attach.data = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BC.discernibility.mat.RST_+3A_decision.table">decision.table</code></td>
<td>
<p>an object inheriting from the <code>DecisionTable</code> class, which represents a decision system. 
See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="BC.discernibility.mat.RST_+3A_range.object">range.object</code></td>
<td>
<p>an integer vector indicating objects for construction of the <code class="reqn">k</code>-relative discernibility matrix. 
The default value is <code>NULL</code> which means that all objects in the decision table are used.</p>
</td></tr>
<tr><td><code id="BC.discernibility.mat.RST_+3A_return.matrix">return.matrix</code></td>
<td>
<p>a logical value determining whether the discernibility matrix should be retunred in the output. 
If it is set to FALSE (the default) only a list containing unique clauses from the CNF representation 
of the discernibility function is returned.</p>
</td></tr>
<tr><td><code id="BC.discernibility.mat.RST_+3A_attach.data">attach.data</code></td>
<td>
<p>a logical indicating whether the original decision table should be attached as 
an additional element of the resulting list named as <code>dec.table</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of a class <code>DiscernibilityMatrix</code> which has the following components: 
</p>

<ul>
<li> <p><code>disc.mat</code>: the decision-relative discernibility matrix which for pairs of objects from different 
decision classes stores names of attributes which can be used to discern between them. Only pairs of 
objects from different decision classes are considered. For other pairs the <code>disc.mat</code> contains
<code>NA</code> values. Moreover, since the classical discernibility matrix is symmetric only the pairs 
from the lower triangular part are considered.
</p>
</li>
<li> <p><code>disc.list</code>: a list containing unique clauses from the CNF representation of the discernibility 
function,
</p>
</li>
<li> <p><code>dec.table</code>: an object of a class <code>DecisionTable</code>, which was used to compute the
discernibility matrix,
</p>
</li>
<li> <p><code>discernibility.type</code>: a type of discernibility relation used in the computations,
</p>
</li>
<li> <p><code>type.model</code>: a character vector identifying the type of model which was used. 
In this case, it is <code>"RST"</code> which means the rough set theory.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Lala Septem Riza and Andrzej Janusz
</p>


<h3>References</h3>

<p>A. Skowron and C. Rauszer,  
&quot;The Discernibility Matrices and Functions in Information Systems&quot;, 
in: R. S≈Çowinski (Ed.), Intelligent Decision Support: Handbook of Applications and
Advances of Rough Sets Theory, Kluwer Academic Publishers, Dordrecht, Netherland,  
p. 331 - 362 (1992).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BC.IND.relation.RST">BC.IND.relation.RST</a></code>, <code><a href="#topic+BC.LU.approximation.RST">BC.LU.approximation.RST</a></code>, <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>
and <code><a href="#topic+BC.discernibility.mat.FRST">BC.discernibility.mat.FRST</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#######################################################################
## Example 1: Constructing the decision-relative discernibility matrix
#######################################################################
data(RoughSetData)
hiring.data &lt;- RoughSetData$hiring.dt

## building the decision-relation discernibility matrix
disc.matrix &lt;- BC.discernibility.mat.RST(hiring.data, return.matrix = TRUE)
disc.matrix

</code></pre>

<hr>
<h2 id='BC.IND.relation.FRST'>The indiscernibility relation based on fuzzy rough set theory</h2><span id='topic+BC.IND.relation.FRST'></span>

<h3>Description</h3>

<p>This is a function used to implement a fundamental concept of FRST which is fuzzy indiscernibility relations. 
It is used for any fuzzy relations that determine the degree to which two objects are indiscernibility. 
The detailed description about basic concepts of FRST 
can be found in <code><a href="#topic+Introduction-FuzzyRoughSets">Introduction-FuzzyRoughSets</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BC.IND.relation.FRST(decision.table, attributes = NULL, control = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BC.IND.relation.FRST_+3A_decision.table">decision.table</code></td>
<td>
<p>a <code>"DecisionTable"</code> class representing a decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="BC.IND.relation.FRST_+3A_attributes">attributes</code></td>
<td>
<p>a numerical vector expressing indexes of subset of attributes to be considered. 
The default value is <code>NULL</code> which means that 
all conditional attributes will be considered.</p>
</td></tr>
<tr><td><code id="BC.IND.relation.FRST_+3A_control">control</code></td>
<td>
<p>a list of other parameters consisting of the following parameters:
</p>
 
<ul>
<li> <p><code>type.relation</code>: a list containing string values that express the 
type of the fuzzy relation and its equation. The default value is <code>type.relation = c("tolerance", "eq.1")</code>. See in the Section <code>Details</code>.
</p>
</li>
<li> <p><code>type.aggregation</code>: a list expressing type of aggregation. The default value is <code>type.aggregation = c("t.tnorm", "lukasiewicz")</code>. 
See in the Section <code>Details</code>.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>Briefly, the indiscernibility relation is a relation that shows a degree of similarity among the objects.
For example, <code class="reqn">R(x_i, x_j) = 0</code> means the object <code class="reqn">x_i</code> is completely different from <code class="reqn">x_j</code>, 
and otherwise if <code class="reqn">R(x_i, x_j) = 1</code>, while between those values we consider a degree of similarity. 
To calculate this relation, several methods have been implemented
in this function which are approaches based on fuzzy tolerance, equivalence and <code class="reqn">T</code>-equivalence relations. 
The fuzzy tolerance relations proposed by (Jensen and Shen, 2009) include three equations while
(Hu, 2004) proposed five <code class="reqn">T_{cos}</code>-transitive kernel functions as fuzzy <code class="reqn">T</code>-equivalence relations. The simple
algorithm of fuzzy equivalence relation is implemented as well. Furthermore, we facilitate users to define their own equation for similarity relation.
</p>
<p>To calculate a particular relation, we should pay attention to several components in 
the parameter <code>control</code>. The main component in the <code>control</code> parameter is <code>type.relation</code> that defines 
what kind of approach we are going to use. The detailed explanation about the parameters and their equations 
is as follows:
</p>

<ul>
<li> <p><code>"tolerance"</code>: It refers to fuzzy tolerance relations proposed by (Jensen and Shen, 2009). 
In order to represent the <code>"tolerance"</code> relation, we must set <code>type.relation</code> as follows:
</p>
<p><code>type.relation = c("tolerance", &lt;chosen equation&gt;)</code> 
</p>
<p>where the chosen equation called as <code>t.similarity</code> is one of the
<code>"eq.1"</code>, <code>"eq.2"</code>, and <code>"eq.3"</code> equations which have been explained in <code><a href="#topic+Introduction-FuzzyRoughSets">Introduction-FuzzyRoughSets</a></code>.
</p>
</li>
<li> <p><code>"transitive.kernel"</code>: It refers to the relations employing kernel functions (Genton, 2001).
In order to represent the relation, we must set the <code>type.relation</code> parameter as follows.
</p>
<p><code>type.relation = c("transitive.kernel", &lt;chosen equation&gt;, &lt;delta&gt;)</code>      
</p>
<p>where the chosen equation is one of five following equations (called <code>t.similarity</code>):
</p>

<ul>
<li> <p><code>"gaussian"</code>: It means Gaussian kernel which is <code class="reqn">R_G(x,y) = \exp (-\frac{|x - y|^2}{\delta})</code>
</p>
</li>
<li> <p><code>"exponential"</code>: It means exponential kernel which is <code class="reqn">R_E(x,y) = \exp(-\frac{|x - y|}{\delta})</code>
</p>
</li>
<li> <p><code>"rational"</code>: It means rational quadratic kernel which is <code class="reqn">R_R(x,y) = 1 - \frac{|x - y|^2}{|x - y|^2 + \delta}</code>
</p>
</li>
<li> <p><code>"circular"</code>: It means circular kernel which is if <code class="reqn">|x - y| &lt; \delta</code>, 
<code class="reqn">R_C(x,y) = \frac{2}{\pi}\arccos(\frac{|x - y|}{\delta}) - \frac{2}{\pi}\frac{|x - y|}{\delta}\sqrt{1 - (\frac{|x - y|}{\delta})^2}</code>
</p>
</li>
<li> <p><code>"spherical"</code>: It means spherical kernel which is if <code class="reqn">|x - y| &lt; \delta</code>,
<code class="reqn">R_S(x,y) = 1 - \frac{3}{2}\frac{|x - y|}{\delta} + \frac{1}{2}(\frac{|x - y|}{\delta})^3</code>
</p>
</li></ul>

<p>and <code>delta</code> is a specified value. 
For example: let us assume we are going to use <code>"transitive.kernel"</code> as the fuzzy relation,
<code>"gaussian"</code> as its equation and the delta is 0.2. So, we assign the <code>type.relation</code> parameter as follows:
</p>
<p><code>type.relation = c("transitive.kernel", "gaussian", 0.2)</code>
</p>
<p>If we omit the <code>delta</code> parameter then we are using <code>"gaussian"</code> defined as <code class="reqn">R_E(x,y) = \exp(-\frac{|x - y|}{2\sigma^2})</code>, where <code class="reqn">\sigma</code> is the variance.
Furthermore, when using this relation, usually we set 
</p>
<p><code>type.aggregation = c("t.tnorm", "t.cos")</code>.  
</p>
</li>
<li> <p><code>"kernel.frst"</code>: It refers to <code class="reqn">T</code>-equivalence relation proposed by (Hu, 2004).
In order to represent the relation, we must set <code>type.relation</code> parameter as follows.
</p>
<p><code>type.relation = c("kernel.frst", &lt;chosen equation&gt;, &lt;delta&gt;)</code>      
</p>
<p>where the chosen equation is one of the kernel functions, but they have different names corresponding to previous ones: 
<code>"gaussian.kernel"</code>, <code>"exponential.kernel"</code>, <code>"rational.kernel"</code>, <code>"circular.kernel"</code>, and <code>"spherical.kernel"</code>. And
<code>delta</code> is a specified value. 
For example: let us assume we are going to use <code>"gaussian.kernel"</code> as its equation and the delta is 0.2. 
So, we assign the <code>type.relation</code> parameter as follows:
</p>
<p><code>type.relation = c("kernel.frst", "gaussian.kernel", 0.2)</code>
</p>
<p>In this case, we do not need to define type of aggregation. Furthemore, regarding the distance used in the equations if objects <code class="reqn">x</code> and <code class="reqn">y</code> contains mixed values (nominal and continuous)
then we use the Gower distance and we use the euclidean distance for continuous only. 
</p>
</li>
<li> <p><code>"transitive.closure"</code>: It refers to similarity relation (also called fuzzy equivalence relation). 
We consider a simple algorithm to calculate this relation as follows:
</p>
<p>Input: a fuzzy relation R
</p>
<p>Output: a min-transitive fuzzy relation <code class="reqn">R^m</code>
</p>
<p>Algorithm:
</p>
<p>1. For every x, y: compute
</p>
<p><code class="reqn">R'(x,y) = max(R(x,y), max_{z \in U}min(R(x,z), R(z,y)))</code>
</p>
<p>2. If <code class="reqn">R' \not= R</code>, then <code class="reqn">R \gets R'</code> and go to 1, else <code class="reqn">R^m \gets R'</code>
</p>
<p>For interested readers, other algorithms can be seen in (Naessens et al, 2002). Let <code>"eq.1"</code> be the <code class="reqn">R</code> fuzzy relations, to define it as parameter is
</p>
<p><code>type.relation = c("transitive.closure", "eq.1")</code>. We can also use other equations that have been explained in <code>"tolerance"</code> and <code>"transitive.kernel"</code>.
</p>
</li>
<li> <p><code>"crisp"</code>: It uses crisp equality for all attributes and 
we set the parameter <code>type.relation = "crisp"</code>. In this case, we only have <code class="reqn">R(x_i, x_j) = 0</code> 
which means the object <code class="reqn">x_i</code> is completely different from <code class="reqn">x_j</code>, 
and otherwise if <code class="reqn">R(x_i, x_j) = 1</code>. 
</p>
</li>
<li> <p><code>"custom"</code>: this value means that we define our own equation for the indiscernibility relation.
The equation should be defined in parameter <code>FUN.relation</code>. 
</p>
<p><code>type.relation = c("custom", &lt;FUN.relation&gt;)</code>
</p>
<p>The function <code>FUN.relation</code> should consist of three arguments which are <code>decision.table</code>, 
<code>x</code>, and <code>y</code>, where <code>x</code> and <code>y</code> represent two objects which we want to compare. 
It should be noted that the user must ensure that the values of this equation are always between 0 and 1. 
An example can be seen in Section <code>Examples</code>.
</p>
</li></ul>

<p>Beside the above <code>type.relation</code>, we provide several options of values for the <code>type.aggregation</code> parameter. 
The following is a description about it.
</p>

<ul>
<li> <p><code>type.aggregation = c("crisp")</code>: It uses crisp equality for all attributes.
</p>
</li>
<li> <p><code>type.aggregation = c("t.tnorm", &lt;t.tnorm operator&gt;)</code>: It means we are using <code>"t.tnorm"</code> aggregation 
which is a triangular norm operator with 
a specified operator <code>t.tnorm</code> as follows: 
</p>

<ul>
<li> <p><code>"min"</code>: standard t-norm i.e., <code class="reqn">min(x_1, x_2)</code>.
</p>
</li>
<li> <p><code>"hamacher"</code>: hamacher product i.e., <code class="reqn">(x_1 * x_2)/(x_1 + x_2 - x_1 * x_2)</code>.
</p>
</li>
<li> <p><code>"yager"</code>: yager class i.e., <code class="reqn">1 - min(1, ((1 - x_1) + (1 - x_2)))</code>.
</p>
</li>
<li> <p><code>"product"</code>: product t-norm i.e., <code class="reqn">(x_1 * x_2)</code>.
</p>
</li>
<li> <p><code>"lukasiewicz"</code>: lukasiewicz's t-norm (default) i.e., <code class="reqn">max(x_2 + x_1 - 1, 0)</code>. 
</p>
</li>
<li> <p><code>"t.cos"</code>: <code class="reqn">T_{cos}</code>t-norm i.e., <code class="reqn">max(x_1 * x_2 - \sqrt{1 - x_1^2}\sqrt{1 - x_2^2, 0})</code>.
</p>
</li>
<li> <p><code>FUN.tnorm</code>: It is a user-defined function for <code>"t.tnorm"</code>. It has to have two arguments, for example:
</p>
<p><code>FUN.tnorm &lt;- function(left.side, right.side)</code>
</p>
<p><code>if ((left.side + right.side) &gt; 1)</code>
</p>
<p><code>return(min(left.side, right.side))</code>
</p>
<p><code>else return(0)</code>
</p>
</li></ul>

<p>The default value is <code>type.aggregation = c("t.tnorm", "lukasiewicz")</code>.
</p>
</li>
<li> <p><code>type.aggregation = c("custom", &lt;FUN.agg&gt;)</code>: It is used to define our own function for a type of aggregations. <code>&lt;FUN.agg&gt;</code> is 
a function having one argument representing data that is produced by fuzzy similarity equation calculation.
The data is a list of one or many matrices which depend on the number of considered attributes and has dimension: 
the number of object <code class="reqn">\times</code> the number of object. For example:
</p>
<p><code>FUN.agg &lt;- function(data) return(Reduce("+", data)/length(data))</code>
</p>
<p>which is a function to calculate average along all attributes. Then,
we can set <code>type.aggregation</code> as follows:
</p>
<p><code>type.aggregation = c("general.custom", &lt;FUN.agg&gt;)</code>. An example can be seen in Section <code>Examples</code>.        
</p>
</li></ul>

<p>Furthermore, the use of this function has been illustrated in Section <code>Examples</code>. 
Finally, this function is important since it is a basic function needed by other functions, such as <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code> and 
<code><a href="#topic+BC.positive.reg.FRST">BC.positive.reg.FRST</a></code> for calculating lower and upper approximation and determining positive regions.
</p>


<h3>Value</h3>

<p>A class <code>"IndiscernibilityRelation"</code> which contains
</p>

<ul>
<li> <p><code>IND.relation</code>: a matrix representing the indiscernibility relation over all objects. 
</p>
</li>
<li> <p><code>type.relation</code>: a vector representing the type of relation. 
</p>
</li>
<li> <p><code>type.aggregation</code>: a vector representing the type of aggregation operator.
</p>
</li>
<li> <p><code>type.model</code>: a string showing the type of model which is used. In this case it is <code>"FRST"</code> which means fuzzy rough set theory.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>References</h3>

<p>M. Genton, &quot;Classes of Kernels for Machine Learning: a Statistics Perspective&quot;, 
J. Machine Learning Research, vol. 2, p. 299 - 312 (2001). 
</p>
<p>H. Naessens, H. De Meyer, and B. De Baets, 
&quot;Algorithms for the Computation of T-Transitive Closures&quot;,
IEEE Trans. on Fuzzy Systems, vol. 10, No. 4, p. 541 - 551 (2002).
</p>
<p>R. Jensen and Q. Shen,  
&quot;New Approaches to Fuzzy-Rough Feature Selection&quot;, 
IEEE Trans. on Fuzzy Systems, vol. 19, no. 4,
p. 824 - 838 (2009).
</p>
<p>Q. Hu, D. Yu, W. Pedrycz, and D. Chen, &quot;Kernelized Fuzzy Rough Sets and Their Applications&quot;,
IEEE Trans. Knowledge Data Eng., vol. 23, no. 11, p. 1649 - 1471 (2011).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>, <code><a href="#topic+BC.IND.relation.RST">BC.IND.relation.RST</a></code>, <code><a href="#topic+BC.LU.approximation.RST">BC.LU.approximation.RST</a></code>, 
</p>
<p>and <code><a href="#topic+BC.positive.reg.FRST">BC.positive.reg.FRST</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###########################################################
## Example 1: Dataset containing nominal values for 
## all attributes.
###########################################################
## Decision table is represented as data frame
dt.ex1 &lt;- data.frame(c(1,0,2,1,1,2,2,0), c(0, 1,0, 1,0,2,1,1), 
                        c(2,1,0,0,2,0,1,1), c(2,1,1,2,0,1,1,0), c(0,2,1,2,1,1,2,1))
colnames(dt.ex1) &lt;- c("aa", "bb", "cc", "dd", "ee")
decision.table &lt;- SF.asDecisionTable(dataset = dt.ex1, decision.attr = 5, 
      indx.nominal = c(1:5))

## In this case, we only consider the second and third attributes.
attributes &lt;- c(2, 3)

## calculate fuzzy indiscernibility relation ##
## in this case, we are using "crisp" as a type of relation and type of aggregation
control.ind &lt;- list(type.relation = c("crisp"), type.aggregation = c("crisp"))
IND &lt;- BC.IND.relation.FRST(decision.table, attributes = attributes, control = control.ind)

###########################################################
## Example 2: Dataset containing real-valued attributes
###########################################################
dt.ex2 &lt;- data.frame(c(-0.4, -0.4, -0.3, 0.3, 0.2, 0.2), 
                     c(-0.3, 0.2, -0.4, -0.3, -0.3, 0),
			        c(-0.5, -0.1, -0.3, 0, 0, 0),
			        c("no", "yes", "no", "yes", "yes", "no"))
colnames(dt.ex2) &lt;- c("a", "b", "c", "d")
decision.table &lt;- SF.asDecisionTable(dataset = dt.ex2, decision.attr = 4)

## in this case, we only consider the first and second attributes
attributes &lt;- c(1, 2)

## Calculate fuzzy indiscernibility relation 
## in this case, we choose "tolerance" relation and "eq.1" as similarity equation
## and "lukasiewicz" as t-norm of type of aggregation
control.1 &lt;- list(type.aggregation = c("t.tnorm", "lukasiewicz"), 
                    type.relation = c("tolerance", "eq.1"))
IND.1 &lt;- BC.IND.relation.FRST(decision.table, attributes = attributes, 
                              control = control.1) 

## Calculate fuzzy indiscernibility relation: transitive.kernel
control.2 &lt;- list(type.aggregation = c("t.tnorm", "t.cos"), 
                    type.relation = c("transitive.kernel", "gaussian", 0.2))
IND.2 &lt;- BC.IND.relation.FRST(decision.table, attributes = attributes, 
                              control = control.2) 

## Calculate fuzzy indiscernibility relation: kernel.frst 
control.3 &lt;- list(type.relation = c("kernel.frst", "gaussian.kernel", 0.2))
IND.3 &lt;- BC.IND.relation.FRST(decision.table, attributes = attributes, 
                              control = control.3) 

## calculate fuzzy transitive closure
control.4 &lt;- list(type.aggregation = c("t.tnorm", "lukasiewicz"), 
                    type.relation = c("transitive.closure", "eq.1"))
IND.4 &lt;- BC.IND.relation.FRST(decision.table, attributes = attributes, 
                              control = control.4) 

## Calculate fuzzy indiscernibility relation: using user-defined relation
## The customized function should have three arguments which are : decision.table 
## and object x, and y.
## This following example shows that we have an equation for similarity equation: 
## 1 - abs(x - y) where x and y are two objects that will be compared.
## In this case, we do not consider decision.table in calculation.
FUN.relation &lt;- function(decision.table, x, y) {
           return(1 - (abs(x - y)))
       }
control.5 &lt;- list(type.aggregation = c("t.tnorm", "lukasiewicz"), 
                     type.relation = c("custom", FUN.relation))
IND.5 &lt;- BC.IND.relation.FRST(decision.table, attributes = attributes, 
                              control = control.5) 

## In this case, we calculate aggregation as average of all objects 
## by executing the Reduce function
FUN.average &lt;- function(data){
  	 return(Reduce("+", data)/length(data))
}
control.6 &lt;- list(type.aggregation = c("custom", FUN.average), 
                     type.relation = c("tolerance", "eq.1"))
IND.6 &lt;- BC.IND.relation.FRST(decision.table, attributes = attributes, 
                              control = control.6)

## using user-defined tnorms 
FUN.tnorm &lt;- function(left.side, right.side) {
               if ((left.side + right.side) &gt; 1)
                   return(min(left.side, right.side))
               else return(0)}
control.7 &lt;- list(type.aggregation = c("t.tnorm", FUN.tnorm), 
                    type.relation = c("tolerance", "eq.1"))
IND.7 &lt;- BC.IND.relation.FRST(decision.table, attributes = attributes, 
                              control = control.7) 

## Calculate fuzzy indiscernibility relation: kernel fuzzy rough set 
control.8 &lt;- list(type.relation = c("kernel.frst", "gaussian.kernel", 0.2))
IND.8 &lt;- BC.IND.relation.FRST(decision.table, attributes = attributes, 
                              control = control.8) 						   
##################################################################
## Example 3: Dataset containing continuous and nominal attributes
## Note. we only consider type.relation = c("tolerance", "eq.1")
## but other approaches have the same way.
##################################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$housing7.dt 

## in this case, we only consider the attribute: 1, 2, 3, 4 
attributes &lt;- c(1,2,3,4)

## Calculate fuzzy indiscernibility relation
control.9 &lt;- list(type.aggregation = c("t.tnorm", "lukasiewicz"),
                    type.relation = c("tolerance", "eq.1"))
IND.9 &lt;- BC.IND.relation.FRST(decision.table, attributes = attributes, control = control.9) 

</code></pre>

<hr>
<h2 id='BC.IND.relation.RST'>Computation of indiscernibility classes based on the rough set theory</h2><span id='topic+BC.IND.relation.RST'></span>

<h3>Description</h3>

<p>This function implements a fundamental part of RST: the indiscernibility relation.
This binary relation indicates whether it is possible to discriminate any given pair of objects from an information system. 
</p>
<p>This function can be used as a basic building block for development of other RST-based methods.
A more detailed explanation of the notion of indiscernibility relation can be found in <code><a href="#topic+Introduction-RoughSets">Introduction-RoughSets</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BC.IND.relation.RST(decision.table, feature.set = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BC.IND.relation.RST_+3A_decision.table">decision.table</code></td>
<td>
<p>an object inheriting from the <code>"DecisionTable"</code> class, which represents a decision system. 
See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="BC.IND.relation.RST_+3A_feature.set">feature.set</code></td>
<td>
<p>an integer vector indicating indexes of attributes which should be used or an object inheriting from
the <code>FeatureSubset</code> class.
The computed indiscernibility classes will be relative to this attribute set. 
The default value is <code>NULL</code> which means that 
all conditional attributes should be considered. It is usually reasonable 
to discretize numeric attributes before the computation of indiscernibility classes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of a class <code>"IndiscernibilityRelation"</code> which is a list with the following components:
</p>

<ul>
<li> <p><code>IND.relation</code>: a list of indiscernibility classes in the data. Each class is represented by indices 
of data instances which belong to that class
</p>
</li>
<li> <p><code>type.relation</code>: a character vector representing a type of relation used in computations. Currently, 
only <code>"equivalence"</code> is provided. 
</p>
</li>
<li> <p><code>type.model</code>: a character vector identifying the type of model which is used. 
In this case, it is <code>"RST"</code> which means the rough set theory.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>References</h3>

<p>Z. Pawlak, &quot;Rough Sets&quot;, International Journal of Computer and Information Sciences, 
vol. 11, no. 5, p. 341 - 356 (1982).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BC.LU.approximation.RST">BC.LU.approximation.RST</a></code>, <code><a href="#topic+FS.reduct.computation">FS.reduct.computation</a></code>, <code><a href="#topic+FS.feature.subset.computation">FS.feature.subset.computation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################
data(RoughSetData)
hiring.data &lt;- RoughSetData$hiring.dt

## In this case, we only consider the second and third attribute:
A &lt;- c(2,3)
## We can also compute a decision reduct:
B &lt;- FS.reduct.computation(hiring.data)

## Compute the indiscernibility classes:
IND.A &lt;- BC.IND.relation.RST(hiring.data, feature.set = A)
IND.A

IND.B &lt;- BC.IND.relation.RST(hiring.data, feature.set = B)
IND.B

</code></pre>

<hr>
<h2 id='BC.LU.approximation.FRST'>The fuzzy lower and upper approximations based on fuzzy rough set theory</h2><span id='topic+BC.LU.approximation.FRST'></span>

<h3>Description</h3>

<p>This is a function implementing a fundamental concept of FRST: fuzzy lower and upper approximations. 
Many options have been considered for determining lower and upper approximations, 
such as techniques based on implicator and t-norm functions proposed by 
(Radzikowska and Kerre, 2002).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BC.LU.approximation.FRST(
  decision.table,
  IND.condAttr,
  IND.decAttr,
  type.LU = "implicator.tnorm",
  control = list()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BC.LU.approximation.FRST_+3A_decision.table">decision.table</code></td>
<td>
<p>a <code>"DecisionTable"</code> class representing the decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="BC.LU.approximation.FRST_+3A_ind.condattr">IND.condAttr</code></td>
<td>
<p>a <code>"IndiscernibilityRelation"</code> class of the conditional attributes which is produced by <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code>.</p>
</td></tr>
<tr><td><code id="BC.LU.approximation.FRST_+3A_ind.decattr">IND.decAttr</code></td>
<td>
<p>a <code>"IndiscernibilityRelation"</code> class of the decision attribute which is produced by <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code>.</p>
</td></tr>
<tr><td><code id="BC.LU.approximation.FRST_+3A_type.lu">type.LU</code></td>
<td>
<p>a string representing a chosen method to calculate lower and upper approximations. See the explanation in Section <code>Details</code>.</p>
</td></tr>
<tr><td><code id="BC.LU.approximation.FRST_+3A_control">control</code></td>
<td>
<p>a list of other parameters. In order to understand how to express the <code>control</code> parameter, 
see the explanation in Section <code>Details</code>. 
The descriptions of those components and their values is as follows. 
</p>
 
<ul>
<li> <p><code>t.tnorm</code>: a type of triangular functions which have been explained 
</p>
<p>in <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code>.
</p>
</li>
<li> <p><code>t.implicator</code>: a type of implicator functions.  
The following are values of this parameter:               
</p>

<ul>
<li> <p><code>"kleene_dienes"</code> means <code class="reqn">max(1 - x_1, x_2)</code>.
</p>
</li>
<li> <p><code>"lukasiewicz"</code> means <code class="reqn">min(1 - x_1 + x_2, 1)</code>. It is the default value. 
</p>
</li>
<li> <p><code>"zadeh"</code> means <code class="reqn">max(1 - x_1, min(x_1, x_2))</code>.
</p>
</li>
<li> <p><code>"gaines"</code> means <code class="reqn">(x_1 &lt;= x_2 ? 1 : x_2 / x_1)</code>.
</p>
</li>
<li> <p><code>"godel"</code> means <code class="reqn">(x_1 &lt;= x_2 ? 1 : x_2)</code>.
</p>
</li>
<li> <p><code>"kleene_dienes_lukasiewicz"</code> means <code class="reqn">1 - x_1 + x_1 * x_2</code>.
</p>
</li>
<li> <p><code>"mizumoto"</code> means <code class="reqn">(1 - x_1 + x_1 * x_2)</code>.
</p>
</li>
<li> <p><code>"dubois_prade"</code> means <code class="reqn">(x_2 == 0 ? 1 - x_1 : (x_1 == 1 ? x_2 : 1))</code>.
</p>
</li></ul>

<p>Where we consider the following rule: <code class="reqn">x_1 -&gt; x_2</code>. 
</p>
</li>
<li> <p><code>q.some</code>: a vector of alpha and beta parameters of vaguely quantified rough set  
for quantifier <code>some</code>. The default value is <code>q.some = c(0.1, 0.6)</code>.
</p>
</li>
<li> <p><code>q.most</code>: a vector of alpha and beta parameters of vaguely quantified rough set 
for quantifier <code>most</code>. The default value is <code>q.most = c(0.2, 1)</code>.
</p>
</li>
<li> <p><code>alpha</code>: a numeric between 0 and 1 representing the threshold parameter of the fuzzy variable precision rough sets 
(FVPRS) (see Section <code>Details</code>). The default value is 0.05.
</p>
</li>
<li> <p><code>m.owa</code>: an integer number (<code class="reqn">m</code>) which is used in the OWA fuzzy rough sets (see Section <code>Details</code>). 
</p>
<p>The default value is <code>m.owa = round(0.5 * ncol(decision.table))</code>.
</p>
</li>
<li> <p><code>w.owa</code>: a vector representing the weight vector in the OWA fuzzy rough sets (see Section <code>Details</code>).
The default value is <code>NULL</code>, which means we use the <code>m.owa</code> type.
</p>
</li>
<li> <p><code>type.rfrs</code>: a type of robust fuzzy rough sets which is one of the following methods:
<code>"k.trimmed.min"</code>, <code>"k.mean.min"</code>, <code>"k.median.min"</code>, <code>"k.trimmed.max"</code>,
<code>"k.mean.max"</code>, and <code>"k.median.max"</code> (see Section <code>Details</code>). The default value is <code>"k.trimmed.min"</code>.
</p>
</li>
<li> <p><code>k.rfrs</code>: a number between 0 and the number of data which is used to define considered data on 
robust fuzzy rough sets (RFRS) (see Section <code>Details</code>). The default value is 
<code>k.rfrs = round(0.5*nrow(decision.table))</code>.
</p>
</li>
<li> <p><code>beta.quasi</code>: a number between 0 and 1 representing <code class="reqn">\beta</code>-precision t-norms and t-conorms in <code class="reqn">\beta</code>-PFRS.
The default value is 0.05.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>Fuzzy lower and upper approximations as explained in <code><a href="#topic+Introduction-FuzzyRoughSets">Introduction-FuzzyRoughSets</a></code> are used
to define to what extent the set of elements can be classified into a certain class strongly or weakly. We can perform various methods by choosing the parameter <code>type.LU</code>. 
The following is a list of all <code>type.LU</code> values: 
</p>

<ul>
<li> <p><code>"implicator.tnorm"</code>: It means implicator/t-norm based model proposed by (Radzikowska and Kerre, 2002). 
The explanation has been given in <code><a href="#topic+Introduction-FuzzyRoughSets">Introduction-FuzzyRoughSets</a></code>.
Other parameters in <code>control</code> related with this approach are <code>t.tnorm</code> and <code>t.implicator</code>.
In other words, when we are using <code>"implicator.tnorm"</code> as <code>type.LU</code>, 
we should consider parameters <code>t.tnorm</code> and <code>t.implicator</code>.
The possible values of these parameters can be seen in the description of parameters. 
</p>
</li>
<li> <p><code>"vqrs"</code>: It means vaguely quantified rough sets proposed by 
(Cornelis et al, 2007). Basically, this concept proposed to replace fuzzy lower and upper approximations 
based on Radzikowska and Kerre's technique (see <code><a href="#topic+Introduction-FuzzyRoughSets">Introduction-FuzzyRoughSets</a></code>)
with the following equations, respectively. 
</p>
<p><code class="reqn">(R_{Q_u} \downarrow A)(y) = Q_u(\frac{|R_y \cap A|}{|R_y|})</code> 
</p>
<p><code class="reqn">(R_{Q_l} \uparrow A)(y) = Q_l(\frac{|R_y \cap A|}{|R_y|})</code>
</p>
<p>where the quantifier <code class="reqn">Q_u</code> and <code class="reqn">Q_l</code> represent the terms <code>most</code> and <code>some</code>. 
</p>
</li>
<li> <p><code>"owa"</code>: It refers to ordered weighted average based fuzzy rough sets. 
This method was introduced by (Cornelis et al, 2010) and computes the approximations
by an aggregation process proposed by (Yager, 1988). The OWA-based lower and upper approximations of 
<code class="reqn">A</code> under <code class="reqn">R</code> with weight vectors <code class="reqn">W_l</code> and <code class="reqn">W_u</code> are defined as
</p>
<p><code class="reqn">(R \downarrow W_l A)(y) = OW A_{W_l}\langle I(R(x, y), A(y))\rangle</code>
</p>
<p><code class="reqn">(R \uparrow W_u A)(y) = OW A_{W_u}\langle T(R(x, y), A(y))\rangle</code>
</p>
<p>We provide two ways to define the weight vectors as follows:
</p>

<ul>
<li> <p><code>m.owa</code>: Let <code class="reqn">m.owa</code> be <code class="reqn">m</code> and <code class="reqn">m \le n</code>, this model is defined by
</p>
<p><code class="reqn">W_l = &lt;w_i^l&gt; = w_{n+1-i}^l = \frac{2^{m-i}}{2^{m}-1}</code> for <code class="reqn">i = 1,\ldots, m</code> and <code class="reqn">0</code> for <code class="reqn">i = m + 1, \ldots, n</code>
</p>
<p><code class="reqn">W_u = &lt;w_i^u&gt; = w_i^u = \frac{2^{m - i}}{2^{m} - 1}</code> for <code class="reqn">i = 1, \ldots, m</code> and <code class="reqn">0</code> for <code class="reqn">i = m + 1, \ldots, n</code>
</p>
<p>where <code class="reqn">n</code> is the number of data.
</p>
</li>
<li> <p><code>custom</code>: In this case, users define the own weight vector.
It should be noted that the weight vectors <code class="reqn">&lt;w_i&gt;</code> should satisfy <code class="reqn">w_i \in [0, 1]</code> and 
their summation is 1.
</p>
</li></ul>

</li>
<li> <p><code>"fvprs"</code>: It refers to fuzzy variable precision rough sets (FVPRS) introduced by 
(Zhao et al, 2009). It is a combination between variable precision rough sets (VPRS)
and FRST. This function implements the construction of lower and upper approximations as follows.
</p>
<p><code class="reqn">(R_{\alpha} \downarrow A)(y) = inf_{A(y) \le \alpha} \mathcal{I}(R(x,y), \alpha) \wedge inf_{A(y) &gt; \alpha} \mathcal{I}(R(x,y), A(y))</code>
</p>
<p><code class="reqn">(R_{\alpha} \uparrow A)(y) = sup_{A(y) \ge N(\alpha)} \mathcal{T}(R(x,y), N(\alpha)) \vee sup_{A(y) &lt; N(\alpha)} \mathcal{T}(R(x,y), A(y))</code>
</p>
<p>where <code class="reqn">\alpha</code>, <code class="reqn">\mathcal{I}</code> and <code class="reqn">\mathcal{T}</code> are the variable precision parameter, implicator and t-norm operators, respectively.
</p>
</li>
<li> <p><code>"rfrs"</code>: It refers to robust fuzzy rough sets (RFRS) proposed by (Hu et al, 2012). 
This package provides six types of RFRS which are k-trimmed minimum, k-mean minimum, k-median minimum, 
k-trimmed maximum, k-mean maximum, and k-median maximum. 
Basically, these methods are a special case of ordered weighted average (OWA) where they consider 
the weight vectors as follows.
</p>

<ul>
<li> <p><code>"k.trimmed.min"</code>: <code class="reqn">w_i^l = 1</code> for <code class="reqn">i = n - k</code> and <code class="reqn">w_i^l = 0</code> otherwise.
</p>
</li>
<li> <p><code>"k.mean.min"</code>: <code class="reqn">w_i^l = 1/k</code> for <code class="reqn">i &gt; n - k</code> and <code class="reqn">w_i^l = 0</code> otherwise.
</p>
</li>
<li> <p><code>"k.median.min"</code>: <code class="reqn">w_i^l = 1</code> if k odd, <code class="reqn">i = n - (k-1)/2</code> and <code class="reqn">w_i^l = 1/2</code> if k even, <code class="reqn">i = n - k/2</code> 
and <code class="reqn">w_i^l = 0</code> otherwise.
</p>
</li>
<li> <p><code>"k.trimmed.max"</code>: <code class="reqn">w_i^u = 1</code> for <code class="reqn">i = k + 1</code> and <code class="reqn">w_i^u = 0</code> otherwise. 
</p>
</li>
<li> <p><code>"k.mean.max"</code>: <code class="reqn">w_i^u = 1/k</code> for <code class="reqn">i &lt; k + 1</code> and <code class="reqn">w_i^u = 0</code> otherwise.   
</p>
</li>
<li> <p><code>"k.median.max"</code>: <code class="reqn">w_i^u = 1</code> if k odd, <code class="reqn">i = (k + 1)/2</code> and <code class="reqn">w_i^u = 1/2</code> if k even, <code class="reqn">i = k/2 + 1</code> 
or <code class="reqn">w_i^u = 0</code> otherwise.
</p>
</li></ul>

</li>
<li> <p><code>"beta.pfrs"</code>: It refers to <code class="reqn">\beta</code>-precision fuzzy rough sets (<code class="reqn">\beta</code>-PFRS) proposed by 
(Salido and Murakami, 2003). This algorithm uses <code class="reqn">\beta</code>-precision quasi-<code class="reqn">\mathcal{T}</code>-norm and 
<code class="reqn">\beta</code>-precision quasi-<code class="reqn">\mathcal{T}</code>-conorm. The following are the <code class="reqn">\beta</code>-precision versions of fuzzy lower and upper approximations of a fuzzy set <code class="reqn">A</code> in <code class="reqn">U</code>
</p>
<p><code class="reqn">(R_B \downarrow A)(y) = T_{\beta_{x \in U}} \mathcal{I}(R_B(x,y), A(x))</code>
</p>
<p><code class="reqn">(R_B \uparrow A)(y) = S_{\beta_{x \in U}} \mathcal{T}(R_B(x,y), A(x))</code> 
</p>
<p>where <code class="reqn">T_{\beta}</code> and <code class="reqn">S_{\beta}</code> are <code class="reqn">\beta</code>-precision quasi-<code class="reqn">\mathcal{T}</code>-norm and <code class="reqn">\beta</code>-precision quasi-<code class="reqn">\mathcal{T}</code>-conorm.
Given a t-norm <code class="reqn">\mathcal{T}</code>, a t-conorm <code class="reqn">S</code>, <code class="reqn">\beta \in [0,1]</code> and <code class="reqn">n \in N \setminus \{0, 1\}</code>, the corresponding 
<code class="reqn">\beta</code>-precision quasi-t-norm <code class="reqn">T_{\beta}</code> and <code class="reqn">\beta</code>-precision-<code class="reqn">\mathcal{T}</code>-conorm <code class="reqn">S_{\beta}</code> of order <code class="reqn">n</code> are
<code class="reqn">[0,1]^n \to [0,1]</code> mappings such that for all <code class="reqn">x = (x_1,...,x_n)</code> in <code class="reqn">[0,1]^n</code>,
</p>
<p><code class="reqn">T_{\beta}(x) = \mathcal{T}(y_1,...,y_{n-m})</code>,
</p>
<p><code class="reqn">S_{\beta}(x) = \mathcal{T}(z_1,...,z_{n-p})</code>,
</p>
<p>where <code class="reqn">y_i</code> is the <code class="reqn">i^{th}</code> greatest element of <code class="reqn">x</code> and <code class="reqn">z_i</code> is the <code class="reqn">i^{th}</code> smallest element of <code class="reqn">x</code>, and
</p>
<p><code class="reqn">m = max(i \in \{0,...,n\}|i \le (1-\beta)\sum_{j=1}^{n}x_j)</code>,
</p>
<p><code class="reqn">p = max(i \in \{0,...,n\}|i \le (1-\beta)\sum_{j=1}^{n}(a - x_j))</code>.
</p>
<p>In this package we use <code>min</code> and <code>max</code> for <code class="reqn">\mathcal{T}</code>-norm and <code class="reqn">\mathcal{T}</code>-conorm, respectively. 
</p>
</li>
<li> <p><code>"custom"</code>: It refers to user-defined lower and upper approximations. An example can be seen in Section <code>Examples</code>.
</p>
</li></ul>

<p>The parameter <code>type.LU</code>, which is explained above, is related with parameter <code>control</code>. 
In other words, when choosing a specific value of <code>type.LU</code>, we should take into account to set values of related components in <code>control</code>.
The components that are considered depend on what kind of lower and upper approximations are used. 
So, we do not need to assign all components for a particular approach but only components related with <code>type.LU</code>.
The following is a list showing the components of each approaches.
</p>

<ul>
<li> <p><code>type.LU = "implicator.tnorm"</code>: 
</p>
<p><code>control &lt;- list(t.implicator, t.tnorm)</code>
</p>
</li>
<li> <p><code>type.LU = "vqrs"</code>:
</p>
<p><code>control &lt;- list(q.some, q.most, type.aggregation, t.tnorm)</code>
</p>
</li>
<li> <p><code>type.LU = "owa"</code>:
</p>
<p><code>control &lt;- list(t.implicator, t.tnorm, m.owa)</code> 
</p>
<p>or
</p>
<p><code>control &lt;- list(t.implicator, t.tnorm, w.owa)</code> 
</p>
</li>
<li> <p><code>type.LU = "fvprs"</code>:
</p>
<p><code>control &lt;- list(t.implicator, t.tnorm, alpha)</code>
</p>
</li>
<li> <p><code>type.LU = "beta.pfrs"</code>: 
</p>
<p><code>control &lt;- list(t.implicator, t.tnorm, beta.quasi)</code>
</p>
</li>
<li> <p><code>type.LU = "rfrs"</code>:
</p>
<p><code>control &lt;- list(t.implicator, t.tnorm, type.rfrs, k.rfrs)</code>
</p>
</li>
<li> <p><code>type.LU = "custom"</code>:
</p>
<p><code>control &lt;- list(t.implicator, t.tnorm, FUN.lower, FUN.upper)</code>
</p>
</li></ul>

<p>The description of the components can be seen in the <code>control</code> parameter.
In Section <code>Examples</code>, we provide two examples showing different cases which are
when we have to handle a nominal decision attribute and a continuous one. 
</p>
<p>It should be noted that this function depends on <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code>
which is a function used to calculate the fuzzy indiscernibility relation as input data. 
So, it is obvious that before performing this function, users must execute <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code> first.
</p>


<h3>Value</h3>

<p>A class <code>"LowerUpperApproximation"</code> representing fuzzy rough set (fuzzy lower and upper approximations). It contains the following components:
</p>

<ul>
<li> <p><code>fuzzy.lower</code>: a list showing the lower approximation classified 
based on decision concepts for each index of objects. The value refers to
the degree of objects included in the lower approximation.  
In case the decision attribute is continuous, the result is in a data frame 
with dimension (number of objects x number of objects) and the value on position <code class="reqn">(i,j)</code> 
shows the membership of object <code class="reqn">i</code> to the lower approximation of the similarity class of object <code class="reqn">j</code>.
</p>
</li>
<li> <p><code>fuzzy.upper</code>: a list showing the upper approximation classified 
based on decision concepts for each index of objects. The value refers to
the degree of objects included in the upper approximation. 
In case the decision attribute is continuous values, the result is in data frame 
with dimension (number of objects x number of objects) and the value on position <code class="reqn">(i,j)</code> 
shows the membership of object <code class="reqn">i</code> to the upper approximation of the similarity class of object <code class="reqn">j</code>.
</p>
</li>
<li> <p><code>type.LU</code>: a string representing the type of lower and upper approximation approaches.
</p>
</li>
<li> <p><code>type.model</code>: a string showing the type of model which is used. In this case, it is <code>"FRST"</code> which means fuzzy rough set theory.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>References</h3>

<p>A. M. Radzikowska and E. E. Kerre, &quot;A Comparative Study of Fuzzy Rough Sets&quot;, 
Fuzzy Sets and Systems, vol. 126, p. 137 - 156 (2002). 
</p>
<p>C. Cornelis, M. De Cock, and A. Radzikowska, &quot;Vaguely Quantified Rough Sets&quot;,
Proceedings of 11th International Conference on Rough Sets, Fuzzy Sets,
Data Mining and Granular Computing (RSFDGrC2007), Lecture Notes in
Artificial Intelligence 4482, p. 87 - 94 (2007).
</p>
<p>C. Cornelis, N. Verbiest, and R. Jensen, &quot;Ordered Weighted Average Based Fuzzy
Rough Sets&quot;, Proceedings of the 5th International Conference on Rough Sets
and Knowledge Technology (RSKT 2010), p. 78 - 85 (2010).
</p>
<p>J. M. F. Salido and S. Murakami, &quot;Rough Set Analysis of a General Type of Fuzzy Data
Using Transitive Aggregations of Fuzzy Similarity Relations&quot;, 
Fuzzy Sets Syst., vol. 139, p. 635 - 660 (2003).
</p>
<p>Q. Hu, L. Zhang, S. An, D. Zhang, and D. Yu, &quot;On Robust Fuzzy Rough Set Models&quot;,
IEEE Trans. on Fuzzy Systems, vol. 20, no. 4, p. 636 - 651 (2012).
</p>
<p>R. Jensen and Q. Shen,  
&quot;New Approaches to Fuzzy-Rough Feature Selection&quot;, 
IEEE Trans. on Fuzzy Systems, vol. 19, no. 4,
p. 824 - 838 (2009).
</p>
<p>R. R. Yager, &quot;On Ordered Weighted Averaging Aggregation Operators in Multicriteria
Decision Making&quot;, IEEE Transactions on Systems, Man, and Cybernetics, vol. 18, p. 183 - 190 (1988).
</p>
<p>S. Y. Zhao, E. C. C. Tsang, and D. G. Chen, 
&quot;The Model of Fuzzy Variable Precision Rough Sets&quot;,
IEEE Trans. Fuzzy Systems, vol. 17, no. 2,
p. 451 - 467 (2009).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BC.IND.relation.RST">BC.IND.relation.RST</a></code>, <code><a href="#topic+BC.LU.approximation.RST">BC.LU.approximation.RST</a></code>, 
and <code><a href="#topic+BC.positive.reg.FRST">BC.positive.reg.FRST</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###########################################################
## 1. Example: Decision table contains nominal decision attribute
## we are using the same dataset and indiscernibility 
## relation along this example.
###########################################################
dt.ex1 &lt;- data.frame(c(-0.4, -0.4, -0.3, 0.3, 0.2, 0.2), 
                     c(-0.3, 0.2, -0.4, -0.3, -0.3, 0),
			        c(-0.5, -0.1, -0.3, 0, 0, 0),
			        c("no", "yes", "no", "yes", "yes", "no"))
colnames(dt.ex1) &lt;- c("a", "b", "c", "d")
decision.table &lt;- SF.asDecisionTable(dataset = dt.ex1, decision.attr = 4)

## let us consider the first and second attributes 
## only as conditional attributes
condAttr &lt;- c(1, 2)

## let us consider the fourth attribute as decision attribute
decAttr &lt;- c(4)

#### calculate fuzzy indiscernibility relation ####
control.ind &lt;- list(type.aggregation = c("t.tnorm", "lukasiewicz"), 
                    type.relation = c("tolerance", "eq.1"))
control.dec &lt;- list(type.aggregation = c("crisp"), type.relation = "crisp")

## fuzzy indiscernibility relation of conditional attribute
IND.condAttr &lt;- BC.IND.relation.FRST(decision.table, attributes = condAttr, 
                                     control = control.ind)

## fuzzy indiscernibility relation of decision attribute 
IND.decAttr &lt;- BC.IND.relation.FRST(decision.table, attributes = decAttr, 
                                     control = control.dec)

#### Calculate fuzzy lower and upper approximation using type.LU : "implicator.tnorm" ####	 
control &lt;- list(t.implicator = "lukasiewicz", t.tnorm = "lukasiewicz")
FRST.LU &lt;- BC.LU.approximation.FRST(decision.table, IND.condAttr, IND.decAttr, 
              type.LU = "implicator.tnorm", control = control)

#### Calculate fuzzy lower and upper approximation using type.LU : "vqrs" ####	 
control &lt;- list(q.some = c(0.1, 0.6), q.most = c(0.2, 1), t.tnorm = "lukasiewicz")
FRST.VQRS &lt;- BC.LU.approximation.FRST(decision.table, IND.condAttr, IND.decAttr, 
              type.LU = "vqrs", control = control)

#### Calculate fuzzy lower and upper approximation using type.LU : "owa" ####	 
control &lt;- list(t.implicator = "lukasiewicz", t.tnorm = "lukasiewicz", m.owa = 3) 
FRST.OWA.1 &lt;- BC.LU.approximation.FRST(decision.table, IND.condAttr, IND.decAttr, 
              type.LU = "owa", control = control)

#### Calculate fuzzy lower and upper approximation using type.LU : 
#### "owa" with customized function 
#### In this case, we are using the same weight vector as
#### previous one with m.owa = 3
control &lt;- list(t.implicator = "lukasiewicz", t.tnorm = "lukasiewicz", 
               w.owa =  c(0, 0, 0, 0.14, 0.29, 0.57)) 
FRST.OWA.2 &lt;- BC.LU.approximation.FRST(decision.table, IND.condAttr, IND.decAttr, 
              type.LU = "owa", control = control)

#### Calculate fuzzy lower and upper approximation using type.LU : "fvprs" ####	 
control &lt;- list(t.implicator = "lukasiewicz", t.tnorm = "lukasiewicz", alpha = 0.05)
FRST.fvprs &lt;- BC.LU.approximation.FRST(decision.table, IND.condAttr, IND.decAttr, 
              type.LU = "fvprs", control = control)


#### Calculate fuzzy lower and upper approximation using type.LU : "rfrs" ####	 
control &lt;- list(t.implicator = "lukasiewicz", t.tnorm = "lukasiewicz", 
                type.rfrs = "k.trimmed.min", k.rfrs = 0)
FRST.rfrs &lt;- BC.LU.approximation.FRST(decision.table, IND.condAttr, IND.decAttr, 
              type.LU = "rfrs", control = control)

#### Calculate fuzzy lower and upper approximation using type.LU : "beta.pfrs" ####	 
control &lt;- list(t.implicator = "lukasiewicz", t.tnorm = "lukasiewicz", beta.quasi = 0.05)
FRST.beta.pfrs &lt;- BC.LU.approximation.FRST(decision.table, IND.condAttr, IND.decAttr, 
              type.LU = "beta.pfrs", control = control)

#### Calculate fuzzy lower and upper approximation using type.LU : "custom" ####	
## In this case, we calculate approximations randomly. 
f.lower &lt;- function(x){
        return(min(runif(1, min = 0, max = 1) * x))	
}
f.upper &lt;- function(x){
        return(max(runif(1, min = 0, max = 1) * x))
}
control &lt;- list(t.implicator = "lukasiewicz", t.tnorm = "lukasiewicz", FUN.lower = f.lower, 
                FUN.upper = f.upper)
FRST.custom &lt;- BC.LU.approximation.FRST(decision.table, IND.condAttr, IND.decAttr, 
              type.LU = "custom", control = control)

#### In this case, we use custom function for triangular norm and implicator operator
## For example, let us define our implicator and t-norm operator as follows.
imp.lower &lt;- function(antecedent, consequent){
                 return(max(1 - antecedent, consequent))
              }
tnorm.upper &lt;- function(x, y){
                return (x * y)
             } 
control.custom &lt;- list(t.implicator = imp.lower, t.tnorm = tnorm.upper)
FRST.LU.custom &lt;- BC.LU.approximation.FRST(decision.table, IND.condAttr, IND.decAttr, 
              type.LU = "implicator.tnorm", control = control.custom)

###########################################################
## 2. Example: Decision table contains a continuous decision attribute.
## It should be noted that in this example, we are using
## the same dataset and indiscernibility relation.
## We only show one method but for other approaches 
## the procedure is analogous to the previous example
###########################################################
## In this case, we are using housing dataset containing 7 objects
data(RoughSetData)
decision.table &lt;- RoughSetData$housing7.dt

## let us consider the first and second conditional attributes only,
## and the decision attribute at 14.
cond.attributes &lt;- c(1, 2)
dec.attributes &lt;- c(14)
control.ind &lt;- list(type.aggregation = c("t.tnorm", "lukasiewicz"), 
               type.relation = c("tolerance", "eq.1"))
IND.condAttr &lt;- BC.IND.relation.FRST(decision.table, attributes = cond.attributes, 
                                     control = control.ind) 
IND.decAttr &lt;- BC.IND.relation.FRST(decision.table, attributes = dec.attributes, 
                                    control = control.ind) 

#### Calculate fuzzy lower and upper approximation using type.LU : "implicator.tnorm" ####	 
control &lt;- list(t.implicator = "lukasiewicz", t.tnorm = "lukasiewicz")
FRST.LU &lt;- BC.LU.approximation.FRST(decision.table, IND.condAttr, IND.decAttr, 
              type.LU = "implicator.tnorm", control = control)

</code></pre>

<hr>
<h2 id='BC.LU.approximation.RST'>Computation of lower and upper approximations of decision classes</h2><span id='topic+BC.LU.approximation.RST'></span>

<h3>Description</h3>

<p>This function implements a fundamental part of RST: computation of lower and upper approximations. 
The lower and upper approximations determine whether the objects can be certainty or possibly classified 
to a particular decision class on the basis of available knowledge.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BC.LU.approximation.RST(decision.table, IND)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BC.LU.approximation.RST_+3A_decision.table">decision.table</code></td>
<td>
<p>an object inheriting from the <code>"DecisionTable"</code> class, which represents a decision system. 
See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="BC.LU.approximation.RST_+3A_ind">IND</code></td>
<td>
<p>an object inheriting from the <code>"IndiscernibilityRelation"</code> class, which represents indiscernibility clasees in the data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function can be used as a basic building block for development of other RST-based methods.
A more detailed explanation of this notion can be found in <code><a href="#topic+Introduction-RoughSets">Introduction-RoughSets</a></code>.
</p>


<h3>Value</h3>

<p>An object of a class <code>"LowerUpperApproximation"</code> which is a list with the following components:
</p>

<ul>
<li> <p><code>lower.approximation</code>: a list with indices of data instances included in lower approximations of decision classes.
</p>
</li>
<li> <p><code>upper.approximation</code>: a list with indices of data instances included in upper approximations of decision classes.
</p>
</li>
<li> <p><code>type.model</code>: a character vector identifying the type of model which was used. 
In this case, it is <code>"RST"</code> which means the rough set theory.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>References</h3>

<p>Z. Pawlak, &quot;Rough Sets&quot;, International Journal of Computer and Information Sciences, 
vol. 11, no. 5, p. 341 - 356 (1982).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BC.IND.relation.RST">BC.IND.relation.RST</a></code>, <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#######################################
data(RoughSetData)
hiring.data &lt;- RoughSetData$hiring.dt

## We select a single attribute for computation of indiscernibility classes:
A &lt;- c(2)

## Compute the indiscernibility classes:
IND.A &lt;- BC.IND.relation.RST(hiring.data, feature.set = A)

## Compute the lower and upper approximations:
roughset &lt;- BC.LU.approximation.RST(hiring.data, IND.A)
roughset

</code></pre>

<hr>
<h2 id='BC.negative.reg.RST'>Computation of a negative region</h2><span id='topic+BC.negative.reg.RST'></span>

<h3>Description</h3>

<p>This function implements a fundamental part of RST: computation of a negative region and the
degree of dependency. This function can be used as a basic building block for development 
of other RST-based methods. A more detailed explanation of this notion can be found 
in <code><a href="#topic+Introduction-RoughSets">Introduction-RoughSets</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BC.negative.reg.RST(decision.table, roughset)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BC.negative.reg.RST_+3A_decision.table">decision.table</code></td>
<td>
<p>an object inheriting from the <code>"DecisionTable"</code> class, which represents a decision system. 
See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="BC.negative.reg.RST_+3A_roughset">roughset</code></td>
<td>
<p>an object inheriting from the <code>"LowerUpperApproximation"</code> class, which represents
lower and upper approximations of decision classes in the data. Such objects are typically produced by calling 
the <code><a href="#topic+BC.LU.approximation.RST">BC.LU.approximation.RST</a></code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of a class <code>"NegativeRegion"</code> which is a list with the following components:
</p>

<ul>
<li> <p><code>negative.reg</code>: an integer vector containing indices of data instances belonging 
to the boundary region,
</p>
</li>
<li> <p><code>degree.dependency</code>: a numeric value giving the degree of dependency,
</p>
</li>
<li> <p><code>type.model</code>: a varacter vector identifying the utilized model. In this case, 
it is <code>"RST"</code> which means the rough set theory.       
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Dariusz Jankowski, Andrzej Janusz
</p>


<h3>References</h3>

<p>Z. Pawlak, &quot;Rough Sets&quot;, International Journal of Computer and Information Sciences, 
vol. 11, no. 5, p. 341 - 356 (1982).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BC.IND.relation.RST">BC.IND.relation.RST</a></code>, <code><a href="#topic+BC.LU.approximation.RST">BC.LU.approximation.RST</a></code>, <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>########################################################
data(RoughSetData)
hiring.data &lt;- RoughSetData$hiring.dt

## We select a single attribute for computation of indiscernibility classes:
A &lt;- c(2)

## compute the indiscernibility classes:
IND.A &lt;- BC.IND.relation.RST(hiring.data, feature.set = A)

## compute the lower and upper approximation:
roughset &lt;- BC.LU.approximation.RST(hiring.data, IND.A)

## get the boundary region:
pos.negative = BC.negative.reg.RST(hiring.data, roughset)
pos.negative

</code></pre>

<hr>
<h2 id='BC.positive.reg.FRST'>Positive region based on fuzzy rough set</h2><span id='topic+BC.positive.reg.FRST'></span>

<h3>Description</h3>

<p>This is a function that implements a fundamental concept of fuzzy rough set theory which is
the positive region and the corresponding degree of dependency. The explanation about this concept can be seen 
in <code><a href="#topic+Introduction-FuzzyRoughSets">Introduction-FuzzyRoughSets</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BC.positive.reg.FRST(decision.table, fuzzyroughset)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BC.positive.reg.FRST_+3A_decision.table">decision.table</code></td>
<td>
<p>a <code>"DecisionTable"</code> class representing the decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="BC.positive.reg.FRST_+3A_fuzzyroughset">fuzzyroughset</code></td>
<td>
<p>a <code>"LowerUpperApproximation"</code> class representing a fuzzy rough set that is produced by <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In order to compute the function, we need to calculate the indiscernibility relation by executing <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code> 
and the lower and upper approximations by calling <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.
</p>


<h3>Value</h3>

<p>A class <code>"PositiveRegion"</code> containing the following components:
</p>

<ul>
<li> <p><code>positive.freg</code>: a vector representing membership degrees to the fuzzy positive region for each index of objects.
</p>
</li>
<li> <p><code>degree.dependency</code>: a value expressing the degree of dependency. 
</p>
</li>
<li> <p><code>type.model</code>: a string representing type of models. In this case, it is <code>"FRST"</code> which means fuzzy rough set theory.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>References</h3>

<p>R. Jensen and Q. Shen,  
&quot;New Approaches to Fuzzy-Rough Feature Selection&quot;, 
IEEE Trans. on Fuzzy Systems, vol. 19, no. 4,
p. 824 - 838 (2009).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>, <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code>, <code><a href="#topic+BC.IND.relation.RST">BC.IND.relation.RST</a></code>, 
</p>
<p><code><a href="#topic+BC.LU.approximation.RST">BC.LU.approximation.RST</a></code>, and <code><a href="#topic+BC.positive.reg.FRST">BC.positive.reg.FRST</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###########################################################
##### 1. Example: Using a simple decision table containing 
#####             nominal values for the decision attribute
###########################################################
dt.ex1 &lt;- data.frame(c(-0.4, -0.4, -0.3, 0.3, 0.2, 0.2), 
                     c(-0.3, 0.2, -0.4, -0.3, -0.3, 0),
			        c(-0.5, -0.1, -0.3, 0, 0, 0),
			        c("no", "yes", "no", "yes", "yes", "no"))
colnames(dt.ex1) &lt;- c("a", "b", "c", "d")
decision.table &lt;- SF.asDecisionTable(dataset = dt.ex1, decision.attr = 4)

## let us consider the first and second attributes only as conditional attribute
condAttr &lt;- c(1, 2)

## let us consider the fourth attribute as decision attribute
decAttr &lt;- c(4)

#### Calculate fuzzy indiscernibility relation ####
control.ind &lt;- list(type.aggregation = c("t.tnorm", "lukasiewicz"), 
                    type.relation = c("tolerance", "eq.1"))
control.dec &lt;- list(type.aggregation = c("crisp"), type.relation = "crisp")

IND.condAttr &lt;- BC.IND.relation.FRST(decision.table, attributes = condAttr, 
                                     control = control.ind) 
IND.decAttr &lt;- BC.IND.relation.FRST(decision.table, attributes = decAttr, 
                                     control = control.dec) 

#### Calculate fuzzy lower and upper approximation using type.LU : 
#### "implicator.tnorm" 
control &lt;- list(t.implicator = "lukasiewicz")
FRST.LU &lt;- BC.LU.approximation.FRST(decision.table, IND.condAttr, IND.decAttr, 
              type.LU = "implicator.tnorm", control = control)

#### Determine positive regions ####
res.1 &lt;- BC.positive.reg.FRST(decision.table, FRST.LU)

###########################################################
##### 2. Example: Using the housing decision table containing 
#####             continuous values for the decision attribute
###########################################################

## In this case, we are using the housing dataset containing 7 objects
data(RoughSetData)
decision.table &lt;- RoughSetData$housing7.dt

conditional.attr &lt;- c(1, 2)
decision.attr = c(14)
control.ind &lt;- list(type.aggregation = c("t.tnorm", "lukasiewicz"), 
                     type.relation = c("tolerance", "eq.1"))

#### Calculate fuzzy indiscernibility relation ####
IND.condAttr &lt;- BC.IND.relation.FRST(decision.table, attributes = conditional.attr, 
                                     control = control.ind) 
IND.decAttr &lt;- BC.IND.relation.FRST(decision.table, attributes = decision.attr, 
                                     control = control.ind) 

#### Calculate fuzzy lower and upper approximation using type.LU : 
#### "implicator.tnorm" 
control &lt;- list(t.implicator = "lukasiewicz", t.tnorm = "lukasiewicz")

FRST.LU &lt;- BC.LU.approximation.FRST(decision.table, IND.condAttr, IND.decAttr, 
              type.LU = "implicator.tnorm", control = control)

#### Determine fuzzy regions ####
res.2 &lt;- BC.positive.reg.FRST(decision.table, FRST.LU)

</code></pre>

<hr>
<h2 id='BC.positive.reg.RST'>Computation of a positive region</h2><span id='topic+BC.positive.reg.RST'></span>

<h3>Description</h3>

<p>This function implements a fundamental part of RST: computation of a positive region and the
degree of dependency. This function can be used as a basic building block for development 
of other RST-based methods. A more detailed explanation of this notion can be found 
in <code><a href="#topic+Introduction-RoughSets">Introduction-RoughSets</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BC.positive.reg.RST(decision.table, roughset)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BC.positive.reg.RST_+3A_decision.table">decision.table</code></td>
<td>
<p>an object inheriting from the <code>"DecisionTable"</code> class, which represents a decision system. 
See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="BC.positive.reg.RST_+3A_roughset">roughset</code></td>
<td>
<p>an object inheriting from the <code>"LowerUpperApproximation"</code> class, which represents
lower and upper approximations of decision classes in the data. Such objects are typically produced by calling 
the <code><a href="#topic+BC.LU.approximation.RST">BC.LU.approximation.RST</a></code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of a class <code>"PositiveRegion"</code> which is a list with the following components:
</p>

<ul>
<li> <p><code>positive.reg</code>: an integer vector containing indices of data instances belonging 
to the positive region,
</p>
</li>
<li> <p><code>degree.dependency</code>: a numeric value giving the degree of dependency,
</p>
</li>
<li> <p><code>type.model</code>: a varacter vector identifying the utilized model. In this case, 
it is <code>"RST"</code> which means the rough set theory.       
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>References</h3>

<p>Z. Pawlak, &quot;Rough Sets&quot;, International Journal of Computer and Information Sciences, 
vol. 11, no. 5, p. 341 - 356 (1982).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BC.IND.relation.RST">BC.IND.relation.RST</a></code>, <code><a href="#topic+BC.LU.approximation.RST">BC.LU.approximation.RST</a></code>, <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>########################################################
data(RoughSetData)
hiring.data &lt;- RoughSetData$hiring.dt

## We select a single attribute for computation of indiscernibility classes:
A &lt;- c(2)

## compute the indiscernibility classes:
IND.A &lt;- BC.IND.relation.RST(hiring.data, feature.set = A)

## compute the lower and upper approximation:
roughset &lt;- BC.LU.approximation.RST(hiring.data, IND.A)

## get the positive region:
pos.region = BC.positive.reg.RST(hiring.data, roughset)
pos.region

</code></pre>

<hr>
<h2 id='C.FRNN.FRST'>The fuzzy-rough nearest neighbor algorithm</h2><span id='topic+C.FRNN.FRST'></span>

<h3>Description</h3>

<p>It is used to predict new datasets/patterns based on the fuzzy-rough nearest neighbor algorithm (FRNN)
proposed by (Jensen and Cornelis, 2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>C.FRNN.FRST(decision.table, newdata, control = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="C.FRNN.FRST_+3A_decision.table">decision.table</code></td>
<td>
<p>a <code>"DecisionTable"</code> class representing the decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>. 
It should be noted that the data must be numeric values instead of string/char.</p>
</td></tr>
<tr><td><code id="C.FRNN.FRST_+3A_newdata">newdata</code></td>
<td>
<p>a <code>"DecisionTable"</code> class representing data for the test process. 
</p>
<p>See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="C.FRNN.FRST_+3A_control">control</code></td>
<td>
<p>a list of other parameters as follows.
</p>

<ul>
<li> <p><code>type.LU</code>: a type of lower and upper approximations. See Section <code>Details</code>. The default value is <code>type.LU = "implicator.tnorm"</code>.
</p>
</li>
<li> <p><code>k</code>: the number of neighbors. It should be taken into account that 
this value could affect the accuracy. The default value is 5.
</p>
</li>
<li> <p><code>type.aggregation</code>: the type of the aggregation operator. See <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code>.
The default value is <code>type.aggregation = c("t.tnorm", "lukasiewicz")</code>.
</p>
</li>
<li> <p><code>type.relation</code>: the type of relation. See <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.
</p>
<p>The default value is <code>c("tolerance", "eq.1")</code>.
</p>
</li>
<li> <p><code>type.implicator</code>: the type of implicator operator. 
</p>
<p>See <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>. The default value is <code>"lukasiewicz"</code>.
</p>
</li>
<li> <p><code>q.some</code>: a vector of values of alpha and beta parameters of VQRS. 
</p>
<p>See <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>. The default value is <code>c(0.1, 0.6)</code>.
</p>
</li>
<li> <p><code>q.most</code>: a vector of values of alpha and beta parameter of VQRS. 
</p>
<p>See <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>. The default value is <code>c(0.2, 1)</code>.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>This method uses the fuzzy lower and upper approximations to improve the fuzzy nearest neighbor (FNN) algorithm.
This algorithm assigns a class to a target instance <code class="reqn">t</code> as follows.
</p>

<ul>
<li><p> Determine <code class="reqn">k</code> nearest neighbors considering their similarity to new patterns.
</p>
</li>
<li><p> Assign new patterns to the class based on maximal value of fuzzy lower and upper approximations. 
If a value of fuzzy lower approximation is high, it shows that neighbors of newdata belong to a particular class, e.g. <code>C</code>. On the other hand, 
a high value of fuzzy upper approximation means that at least one neighbor belongs to that class. 
</p>
</li></ul>
  
<p>In this function, we provide two approaches based on types of fuzzy lower and upper approximations. The following is 
a list of the considered approximations:
</p>

<ul>
<li> <p><code>"implicator.tnorm"</code>: It refers to lower and upper approximations based on implicator/t-norm approach. 
For more detail, it can be seen in <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>. When using this approach, 
we need to assign the <code>control</code> parameter as follows:
</p>
<p><code>control &lt;- list(type.LU = "implicator.tnorm", k,</code>
</p>
<p><code>type.aggregation, type.relation, t.implicator)</code>
</p>
<p>The detailed description of the components in the <code>control</code> parameter can be seen in 
</p>
<p><code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.
</p>
</li>
<li> <p><code>"vqrs"</code>: It refers to lower and upper approximations based on vaguely quantified rough sets. 
For more detail, it can be seen in <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>. When using this approach, 
we need to assign the <code>control</code> parameter as follows:
</p>
<p><code>control &lt;- list(type.LU = "vqrs", k, q.some, q.most,</code>
</p>
<p><code>type.relation, type.aggregation)</code>
</p>
<p>The detailed description of the components in the <code>control</code> parameter can be seen in 
</p>
<p><code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.
</p>
</li></ul>



<h3>Value</h3>

<p>A matrix of predicted classes of newdata.
</p>


<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>References</h3>

<p>R. Jensen and C. Cornelis, &quot;Fuzzy-rough Nearest Neighbour Classification and Prediction&quot;,
Theoretical Computer Science, vol. 412, p. 5871 - 5884 (2011).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+C.FRNN.O.FRST">C.FRNN.O.FRST</a></code>, 
<code><a href="#topic+C.POSNN.FRST">C.POSNN.FRST</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################
## In this example, we are using Iris dataset.
## It should be noted that since the values of the decision attribute are strings,
## they should be transformed into numeric values using unclass()
#############################################################
data(iris)
## shuffle the data
set.seed(2)
irisShuffled &lt;- iris[sample(nrow(iris)),]

## transform values of the decision attribute into numerics
irisShuffled[,5] &lt;- unclass(irisShuffled[,5])

## split the data into training and testing data
iris.training &lt;- irisShuffled[1:105,]
iris.testing &lt;- irisShuffled[106:nrow(irisShuffled),1:4]

colnames(iris.training) &lt;- c("Sepal.Length", "Sepal.Width", "Petal.Length", 
                       "Petal.Width", "Species")

## convert into a standard decision table
decision.table &lt;- SF.asDecisionTable(dataset = iris.training, decision.attr = 5, 
                                     indx.nominal = c(5))
tst.iris &lt;- SF.asDecisionTable(dataset = iris.testing)

###### FRNN algorithm using lower/upper approximation: 
###### Implicator/tnorm based approach
control &lt;- list(type.LU = "implicator.tnorm", k = 20, 
                type.aggregation = c("t.tnorm", "lukasiewicz"), 
                type.relation = c("tolerance", "eq.1"), t.implicator = "lukasiewicz") 									   
## Not run: res.1 &lt;- C.FRNN.FRST(decision.table = decision.table, newdata = tst.iris,
                             control = control)
## End(Not run)

###### FRNN algorithm using VQRS
control &lt;- list(type.LU = "vqrs", k = 20, q.some = c(0.1, 0.6), q.most = c(0.2, 1), 
                 type.relation = c("tolerance", "eq.1"), 
                 type.aggregation = c("t.tnorm","lukasiewicz"))
## Not run: res.2 &lt;- C.FRNN.FRST(decision.table = decision.table, newdata = tst.iris,
                             control = control)
## End(Not run)

</code></pre>

<hr>
<h2 id='C.FRNN.O.FRST'>The fuzzy-rough ownership nearest neighbor algorithm</h2><span id='topic+C.FRNN.O.FRST'></span>

<h3>Description</h3>

<p>It is used to predict classes of new datasets/patterns based on the fuzzy-rough ownership nearest neighbor algorithm (FRNN.O) 
proposed by (Sarkar, 2007).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>C.FRNN.O.FRST(decision.table, newdata, control = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="C.FRNN.O.FRST_+3A_decision.table">decision.table</code></td>
<td>
<p>a <code>"DecisionTable"</code> class representing the decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.
It should be noted that the data must be numeric values instead of strings/characters.</p>
</td></tr>
<tr><td><code id="C.FRNN.O.FRST_+3A_newdata">newdata</code></td>
<td>
<p>a <code>"DecisionTable"</code> class representing data for the test process. 
</p>
<p>See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="C.FRNN.O.FRST_+3A_control">control</code></td>
<td>
<p>a list of other parameters.
</p>

<ul>
<li> <p><code>m</code>: the weight of distance. The default value is 2.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>This method improves fuzzy <code class="reqn">k</code>-nearest neighbors (FNN) by introducing rough sets into it. 
To avoid determining <code class="reqn">k</code> by trial and error procedure, this method uses all training data. Uncertainties in data are accommodated by 
introducing the rough ownership function. It is the following equation <code class="reqn">o_c</code> of each class expressing a squared weighted distance between a test pattern and all training data <code class="reqn">d</code>
and constrained fuzzy membership <code class="reqn">\mu_{C_c}</code>. 
</p>
<p><code class="reqn">o_c(y) = \frac{1}{|X|}\mu_{C_c}(x)\exp{(-d^{1/(q-1)})}</code>
</p>
<p>where <code class="reqn">d = \sum_{j=1}^{N}K_j(y_j-x_{ij})^2</code>
</p>
<p>The predicted value of <code class="reqn">y</code> is obtained by selecting class <code class="reqn">c</code> where <code class="reqn">o_c(y)</code> is maximum.
</p>


<h3>Value</h3>

<p>A matrix of predicted classes of newdata.
</p>


<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>References</h3>

<p>M. Sarkar, &quot;Fuzzy-Rough Nearest-Neighbor Algorithm in Classification&quot; 
Fuzzy Sets and Systems, vol. 158, no. 19, p. 2123 - 2152 (2007).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+C.FRNN.FRST">C.FRNN.FRST</a></code>,  
<code><a href="#topic+C.POSNN.FRST">C.POSNN.FRST</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################
## In this example, we are using Iris dataset.
## It should be noted that since the values of the decision attribute are strings,
## they should be transformed into numeric values using unclass()
#############################################################
data(iris)
## shuffle the data
set.seed(2)
irisShuffled &lt;- iris[sample(nrow(iris)),]

## transform values of the decision attribute into numerics
irisShuffled[,5] &lt;- unclass(irisShuffled[,5])

## split the data into training and testing data
iris.training &lt;- irisShuffled[1:105,]
iris.testing &lt;- irisShuffled[106:nrow(irisShuffled),1:4]

## convert into the standard decision table
colnames(iris.training) &lt;- c("Sepal.Length", "Sepal.Width", "Petal.Length", 
                             "Petal.Width", "Species")
decision.table &lt;- SF.asDecisionTable(dataset = iris.training, decision.attr = 5, 
                                    indx.nominal = c(5))
tst.iris &lt;- SF.asDecisionTable(dataset = iris.testing)

## in this case, we are using "gradual" for type of membership					   
control &lt;- list(m = 2)

## Not run: res.test.FRNN.O &lt;- C.FRNN.O.FRST(decision.table = decision.table, newdata = tst.iris, 
                                 control = control)
## End(Not run)

</code></pre>

<hr>
<h2 id='C.POSNN.FRST'>The positive region based fuzzy-rough nearest neighbor algorithm</h2><span id='topic+C.POSNN.FRST'></span>

<h3>Description</h3>

<p>It is a function used to implement the positive region based fuzzy-rough nearest neighbor algorithm (POSNN)
which was proposed by (Verbiest et al, 2012) for predicting classes of new data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>C.POSNN.FRST(decision.table, newdata, control = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="C.POSNN.FRST_+3A_decision.table">decision.table</code></td>
<td>
<p>a <code>"DecisionTable"</code> class representing the decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>. 
It should be noted that the data must be numeric values instead of string/char.</p>
</td></tr>
<tr><td><code id="C.POSNN.FRST_+3A_newdata">newdata</code></td>
<td>
<p>a <code>"DecisionTable"</code> class representing data for the test process. 
</p>
<p>See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="C.POSNN.FRST_+3A_control">control</code></td>
<td>
<p>a list of other parameters which is the same as <code><a href="#topic+C.FRNN.FRST">C.FRNN.FRST</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method is aimed to improve the fuzzy-rough nearest neighbor algorithm (<code><a href="#topic+C.FRNN.FRST">C.FRNN.FRST</a></code>) algorithm by considering the fuzzy positive region. 
Basically the following steps are used to classify an instance <code class="reqn">t</code>:
</p>

<ul>
<li><p> determine the set of <code class="reqn">k</code>-nearest neighbor of <code class="reqn">t</code>, <code class="reqn">NN</code>.
</p>
</li>
<li><p> assign <code class="reqn">t</code> to the class <code class="reqn">C</code> for which
</p>
<p><code class="reqn">\frac{\displaystyle\sum\limits_{x \in NN} R(x,t)C(x)POS(x)}{\displaystyle\sum\limits_{x \in NN} R(x,t)}</code>
</p>
<p>is maximal.
</p>
</li></ul>



<h3>Value</h3>

<p>A matrix of predicted classes of newdata.
</p>


<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>References</h3>

<p>N. Verbiest, C. Cornelis and R. Jensen, &quot;Fuzzy-rough Positive Region Based Nearest Neighbour Classification&quot;,
In Proceedings of the 20th International Conference on Fuzzy Systems (FUZZ-IEEE 2012), p. 1961 - 1967 (2012).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+C.FRNN.FRST">C.FRNN.FRST</a></code>, <code><a href="#topic+C.FRNN.O.FRST">C.FRNN.O.FRST</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################
## In this example, we are using Iris dataset.
## It should be noted that since the values of the decision attribute are strings,
## they should be transformed into numeric values using unclass()
#############################################################
data(iris)
## shuffle the data
set.seed(2) 
irisShuffled &lt;- iris[sample(nrow(iris)),]

## transform values of the decision attribute into numerics
irisShuffled[,5] &lt;- unclass(irisShuffled[,5])

## split the data into training and testing data
iris.training &lt;- irisShuffled[1:105,]
iris.testing &lt;- irisShuffled[106:nrow(irisShuffled),1:4]

colnames(iris.training) &lt;- c("Sepal.Length", "Sepal.Width", "Petal.Length", 
                       "Petal.Width", "Species")

## convert into the standard decision table
decision.table &lt;- SF.asDecisionTable(dataset = iris.training, decision.attr = 5, 
                                     indx.nominal = c(5))
tst.iris &lt;- SF.asDecisionTable(dataset = iris.testing)
   
## FRNN algorithm using lower/upper approximation: Implicator/tnorm based approach
control &lt;- list(type.LU = "implicator.tnorm", k = 20, t.tnorm = "lukasiewicz", 
                type.relation = c("tolerance", "eq.1"), t.implicator = "lukasiewicz")

## Not run: res.test.POSNN &lt;- C.POSNN.FRST(decision.table = decision.table, 
                              newdata = tst.iris, control = control)
## End(Not run)

</code></pre>

<hr>
<h2 id='D.discretization.RST'>The wrapper function for discretization methods</h2><span id='topic+D.discretization.RST'></span>

<h3>Description</h3>

<p>It is a wrapper function for all discretization methods based on RST.
It provides an interface that allows users to use the discretization methods easily.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>D.discretization.RST(
  decision.table,
  type.method = "unsupervised.quantiles",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="D.discretization.RST_+3A_decision.table">decision.table</code></td>
<td>
<p>an object inheriting from the <code>"DecisionTable"</code> class, which represents a decision system.
See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="D.discretization.RST_+3A_type.method">type.method</code></td>
<td>
<p>a character representing a discretization method to be used in the computations.
Currently it can be one of the following methods:
</p>

<ul>
<li> <p><code>"global.discernibility"</code>: See <code><a href="#topic+D.global.discernibility.heuristic.RST">D.global.discernibility.heuristic.RST</a></code>.
</p>
</li>
<li> <p><code>"local.discernibility"</code>: See <code><a href="#topic+D.local.discernibility.heuristic.RST">D.local.discernibility.heuristic.RST</a></code>.
</p>
</li>
<li> <p><code>"unsupervised.intervals"</code>: See <code><a href="#topic+D.discretize.equal.intervals.RST">D.discretize.equal.intervals.RST</a></code>.
</p>
</li>
<li> <p><code>"unsupervised.quantiles"</code>: See <code><a href="#topic+D.discretize.quantiles.RST">D.discretize.quantiles.RST</a></code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="D.discretization.RST_+3A_...">...</code></td>
<td>
<p>parameters that are passed to the discretization methods. See the manual of particular functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The discretization is used to convert numeric attributes into nominal ones
in an information system. It is usually a preliminary step for the most of methods based on the rough set theory, which
need nominal attributes, for exemple, to compute the indiscernibility relation.
</p>
<p>Output of this function is an object of a class <code>Discretization</code> which
contains cut values. The function <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code> can be used
to generate a new (discretized) decision table from the computed cuts. Type of
all attributes in the resulting table will be changed into nominal (i.e. ordered factors).
</p>
<p>All implemented supervised discretization methods need a nominal decision attribute.
Furthermore, especially for the method type <code>"global.discernibility"</code>, all conditional attributes
must be numeric. A different method needs to be chosen in a case when
a data set contains attributes of mixed types (numeric and nominal).
</p>


<h3>Value</h3>

<p>An object of a class <code>"Discretization"</code> which stores cuts for each conditional attribute. It contains the following components:
</p>

<ul>
<li> <p><code>cut.values</code>: a list representing cut values for each of numeric attributes. NULL value means that
no cut was selected for a given attribute.
</p>
</li>
<li> <p><code>type.method</code>: the type of method which is used to define cut values.
</p>
</li>
<li> <p><code>type.task</code>: the type of task which is <code>"discretization"</code>.
</p>
</li>
<li> <p><code>model</code>: the type of model which is <code>"RST"</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BC.LU.approximation.RST">BC.LU.approximation.RST</a></code>, <code><a href="#topic+FS.reduct.computation">FS.reduct.computation</a></code>, <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#################################################################
## Example: Determine cut values and generate new decision table
#################################################################
data(RoughSetData)
wine.data &lt;- RoughSetData$wine.dt
cut.values1 &lt;- D.discretization.RST(wine.data,
                                   type.method = "unsupervised.quantiles",
                                   nOfIntervals = 3)

## generate a new decision table
wine.discretized1 &lt;- SF.applyDecTable(wine.data, cut.values1)
dim(wine.discretized1)
lapply(wine.discretized1, unique)

cut.values2 &lt;- D.discretization.RST(wine.data,
                                    type.method = "global.discernibility")

wine.discretized2 &lt;- SF.applyDecTable(wine.data, cut.values2)
dim(wine.discretized2)
lapply(wine.discretized2, unique)

</code></pre>

<hr>
<h2 id='D.discretize.equal.intervals.RST'>Unsupervised discretization into intervals of equal length.</h2><span id='topic+D.discretize.equal.intervals.RST'></span>

<h3>Description</h3>

<p>This function implements unsupervised discretization into intervals of equal size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>D.discretize.equal.intervals.RST(decision.table, nOfIntervals = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="D.discretize.equal.intervals.RST_+3A_decision.table">decision.table</code></td>
<td>
<p>an object inheriting from the <code>"DecisionTable"</code> class, which represents a decision system.
See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="D.discretize.equal.intervals.RST_+3A_nofintervals">nOfIntervals</code></td>
<td>
<p>a positive integer giving the number of intervals.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This approach belongs to a class of unsupervised discretization methods
since it does not consider the class labels. Each numeric attribute is divided in <code>k</code> intervals of equal length.
Detailed information regarding this method can be found in (Dougherty et al, 1995).
</p>
<p>It should be noted that the output of this function is an object of a class <code>"Discretization"</code>
which contains the cut values.
The function <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code> has to be used in order to generate the new (discretized) decision table.
</p>


<h3>Value</h3>

<p>An object of a class <code>"Discretization"</code> which stores cuts for each conditional attribute.
See <code><a href="#topic+D.discretization.RST">D.discretization.RST</a></code>.
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>References</h3>

<p>J. Dougherty, R. Kohavi, and M. Sahami, &quot;Supervised and Unsupervised Discretization of Continuous Features&quot;,
In A. Prieditis &amp; S. J. Russell, eds. Work. Morgan Kaufmann, p. 194-202 (1995).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+D.discretize.quantiles.RST">D.discretize.quantiles.RST</a></code>, <code><a href="#topic+D.global.discernibility.heuristic.RST">D.global.discernibility.heuristic.RST</a></code>,
<code><a href="#topic+D.local.discernibility.heuristic.RST">D.local.discernibility.heuristic.RST</a></code>, <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code>.
A wrapper function for all available discretization methods: <code><a href="#topic+D.discretization.RST">D.discretization.RST</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#################################################################
## Example: Determine cut values and generate new decision table
#################################################################
data(RoughSetData)
wine.data &lt;- RoughSetData$wine.dt
cut.values &lt;- D.discretize.equal.intervals.RST(wine.data, nOfIntervals = 3)

## generate a new decision table
wine.discretized &lt;- SF.applyDecTable(wine.data, cut.values)
dim(wine.discretized)
lapply(wine.discretized, unique)

</code></pre>

<hr>
<h2 id='D.discretize.quantiles.RST'>The quantile-based discretization</h2><span id='topic+D.discretize.quantiles.RST'></span>

<h3>Description</h3>

<p>This function implements unsupervised discretization into intervals containing similar number of instances (&quot;quantile-based&quot;).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>D.discretize.quantiles.RST(decision.table, nOfIntervals = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="D.discretize.quantiles.RST_+3A_decision.table">decision.table</code></td>
<td>
<p>an object inheriting from the <code>"DecisionTable"</code> class, which represents a decision system.
See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="D.discretize.quantiles.RST_+3A_nofintervals">nOfIntervals</code></td>
<td>
<p>a positive integer giving the number of intervals.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This approach belongs to a class of unsupervised discretization methods
since it does not consider the class labels. Each numeric attribute is divided in <code>k</code> intervals which contain approximately
the same number of data instances (objects).
Detailed information regarding this method can be found in (Dougherty et al, 1995).
</p>
<p>It should be noted that the output of this function is an object of a class <code>"Discretization"</code>
which contains the cut values.
The function <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code> has to be used in order to generate the new (discretized) decision table.
</p>


<h3>Value</h3>

<p>An object of a class <code>"Discretization"</code> which stores cuts for each conditional attribute.
See <code><a href="#topic+D.discretization.RST">D.discretization.RST</a></code>.
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>References</h3>

<p>J. Dougherty, R. Kohavi, and M. Sahami, &quot;Supervised and Unsupervised Discretization of Continuous Features&quot;,
In A. Prieditis &amp; S. J. Russell, eds. Work. Morgan Kaufmann, p. 194-202 (1995).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+D.discretize.equal.intervals.RST">D.discretize.equal.intervals.RST</a></code>, <code><a href="#topic+D.global.discernibility.heuristic.RST">D.global.discernibility.heuristic.RST</a></code>,
<code><a href="#topic+D.local.discernibility.heuristic.RST">D.local.discernibility.heuristic.RST</a></code>, <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code>.
A wrapper function for all available discretization methods: <code><a href="#topic+D.discretization.RST">D.discretization.RST</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#################################################################
## Example: Determine cut values and generate new decision table
#################################################################
data(RoughSetData)
wine.data &lt;- RoughSetData$wine.dt
cut.values &lt;- D.discretize.quantiles.RST(wine.data, nOfIntervals = 5)

## generate a new decision table
wine.discretized &lt;- SF.applyDecTable(wine.data, cut.values)
dim(wine.discretized)
lapply(wine.discretized, unique)

</code></pre>

<hr>
<h2 id='D.global.discernibility.heuristic.RST'>Supervised discretization based on the maximum discernibility heuristic</h2><span id='topic+D.global.discernibility.heuristic.RST'></span>

<h3>Description</h3>

<p>It is a function used for computing globally semi-optimal cuts using the maximum discernibility heuristic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>D.global.discernibility.heuristic.RST(
  decision.table,
  maxNOfCuts = 2 * ncol(decision.table),
  attrSampleSize = ncol(decision.table) - 1,
  cutCandidatesList = NULL,
  discFunction = global.discernibility,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="D.global.discernibility.heuristic.RST_+3A_decision.table">decision.table</code></td>
<td>
<p>an object inheriting from the <code>"DecisionTable"</code> class, which represents a decision system.
See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.
It should be noted that for this particular method all conditional attributes
must be numeric.</p>
</td></tr>
<tr><td><code id="D.global.discernibility.heuristic.RST_+3A_maxnofcuts">maxNOfCuts</code></td>
<td>
<p>a positive integer indicating the maximum number of allowed cuts.</p>
</td></tr>
<tr><td><code id="D.global.discernibility.heuristic.RST_+3A_attrsamplesize">attrSampleSize</code></td>
<td>
<p>an integer between 1 and the number of conditional attributes (the default). It indicates
the attribute sample size for the Monte Carlo selection of candidating cuts.</p>
</td></tr>
<tr><td><code id="D.global.discernibility.heuristic.RST_+3A_cutcandidateslist">cutCandidatesList</code></td>
<td>
<p>an optional list containing candidates for optimal cut values.
By default the candidating cuts are determined automatically.</p>
</td></tr>
<tr><td><code id="D.global.discernibility.heuristic.RST_+3A_discfunction">discFunction</code></td>
<td>
<p>a function used for computation of cuts. Currently only one implementation of maximu discernibility heuristic
is available (the default). However, this parameter can be used to integrate custom implementations of
discretization functions with the <code>RoughSets</code> package.</p>
</td></tr>
<tr><td><code id="D.global.discernibility.heuristic.RST_+3A_...">...</code></td>
<td>
<p>additional parameters to the <code>discFunction</code> (currently unsupported).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A complete description of the implemented algorithm can be found in (Nguyen, 2001).
</p>
<p>It should be noted that the output of this function is an object of a class <code>"Discretization"</code>
which contains the cut values.
The function <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code> has to be used in order to generate the new (discretized) decision table.
</p>


<h3>Value</h3>

<p>An object of a class <code>"Discretization"</code> which stores cuts for each conditional attribute.
See <code><a href="#topic+D.discretization.RST">D.discretization.RST</a></code>.
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>References</h3>

<p>S. H. Nguyen, &quot;On Efficient Handling of Continuous Attributes in Large Data Bases&quot;,
Fundamenta Informaticae, vol. 48, p. 61 - 81 (2001).
</p>
<p>Jan G. Bazan, Hung Son Nguyen, Sinh Hoa Nguyen, Piotr Synak, and Jakub Wroblewski,
&quot;Rough Set Algorithms in Classification Problem&quot;, Chapter 2
In: L. Polkowski, S. Tsumoto and T.Y. Lin (eds.): Rough Set Methods and Applications
Physica-Verlag, Heidelberg, New York, p. 49 - 88 ( 2000).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+D.discretize.quantiles.RST">D.discretize.quantiles.RST</a></code>, <code><a href="#topic+D.discretize.equal.intervals.RST">D.discretize.equal.intervals.RST</a></code>,
<code><a href="#topic+D.local.discernibility.heuristic.RST">D.local.discernibility.heuristic.RST</a></code> and <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code>.
A wrapper function for all available discretization methods: <code><a href="#topic+D.discretization.RST">D.discretization.RST</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#################################################################
## Example: Determine cut values and generate new decision table
#################################################################
data(RoughSetData)
wine.data &lt;- RoughSetData$wine.dt
cut.values &lt;- D.global.discernibility.heuristic.RST(wine.data)

## generate a new decision table:
wine.discretized &lt;- SF.applyDecTable(wine.data, cut.values)
dim(wine.discretized)
lapply(wine.discretized, unique)

## remove attributes with only one possible value:
to.rm.idx &lt;- which(sapply(lapply(wine.discretized, unique), function(x) length(x) == 1))
to.rm.idx
wine.discretized.reduced &lt;- wine.discretized[-to.rm.idx]
dim(wine.discretized.reduced)

## check whether the attributes in the reduced data are a super-reduct of the original data:
colnames(wine.discretized.reduced)
class.idx &lt;- which(colnames(wine.discretized.reduced) == "class")
sum(duplicated(wine.discretized.reduced)) == sum(duplicated(wine.discretized.reduced[-class.idx]))
## yes it is

</code></pre>

<hr>
<h2 id='D.local.discernibility.heuristic.RST'>Supervised discretization based on the local discernibility heuristic</h2><span id='topic+D.local.discernibility.heuristic.RST'></span>

<h3>Description</h3>

<p>It is a function used for computing locally semi-optimal cuts using the local discernibility heuristic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>D.local.discernibility.heuristic.RST(
  decision.table,
  maxNOfCuts = 2,
  cutCandidatesList = NULL,
  discFunction = local.discernibility
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="D.local.discernibility.heuristic.RST_+3A_decision.table">decision.table</code></td>
<td>
<p>an object inheriting from the <code>"DecisionTable"</code> class, which represents a decision system.
See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.
It should be noted that for this particular method all conditional attributes
must be numeric.</p>
</td></tr>
<tr><td><code id="D.local.discernibility.heuristic.RST_+3A_maxnofcuts">maxNOfCuts</code></td>
<td>
<p>a positive integer indicating the maximum number of allowed cuts on a single attribute.</p>
</td></tr>
<tr><td><code id="D.local.discernibility.heuristic.RST_+3A_cutcandidateslist">cutCandidatesList</code></td>
<td>
<p>an optional list containing candidates for optimal cut values.
By default the candidating cuts are determined automatically.</p>
</td></tr>
<tr><td><code id="D.local.discernibility.heuristic.RST_+3A_discfunction">discFunction</code></td>
<td>
<p>a function used for computation of cuts. Currently only one implementation of the local discernibility heuristic
is available (the default). However, this parameter can be used to integrate custom implementations of
discretization functions with the <code>RoughSets</code> package.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A local (univariate) version of the algorithm described in (Nguyen, 2001) and (Bazan et al., 2000).
</p>
<p>The output of this function is an object of a class <code>"Discretization"</code>
which contains cut values.
The function <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code> has to be used in order to generate the new (discretized) decision table.
</p>


<h3>Value</h3>

<p>An object of a class <code>"Discretization"</code> which stores cuts for each conditional attribute.
See <code><a href="#topic+D.discretization.RST">D.discretization.RST</a></code>.
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>References</h3>

<p>S. H. Nguyen, &quot;On Efficient Handling of Continuous Attributes in Large Data Bases&quot;,
Fundamenta Informaticae, vol. 48, p. 61 - 81 (2001).
</p>
<p>Jan G. Bazan, Hung Son Nguyen, Sinh Hoa Nguyen, Piotr Synak, and Jakub Wroblewski,
&quot;Rough Set Algorithms in Classification Problem&quot;, Chapter 2
In: L. Polkowski, S. Tsumoto and T.Y. Lin (eds.): Rough Set Methods and Applications
Physica-Verlag, Heidelberg, New York, p. 49 - 88 ( 2000).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+D.discretize.quantiles.RST">D.discretize.quantiles.RST</a></code>, <code><a href="#topic+D.discretize.equal.intervals.RST">D.discretize.equal.intervals.RST</a></code>,
<code><a href="#topic+D.global.discernibility.heuristic.RST">D.global.discernibility.heuristic.RST</a></code> and <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code>.
A wrapper function for all available discretization methods: <code><a href="#topic+D.discretization.RST">D.discretization.RST</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#################################################################
## Example: Determine cut values and generate new decision table
#################################################################
data(RoughSetData)
wine.data &lt;- RoughSetData$wine.dt
cut.values &lt;- D.local.discernibility.heuristic.RST(wine.data)

## generate a new decision table:
wine.discretized &lt;- SF.applyDecTable(wine.data, cut.values)
dim(wine.discretized)
lapply(wine.discretized, unique)

</code></pre>

<hr>
<h2 id='FS.all.reducts.computation'>A function for computing all decision reducts of a decision system</h2><span id='topic+FS.all.reducts.computation'></span>

<h3>Description</h3>

<p>A wrapper function used for generating all decision reducts of a decision system. The reducts
are obtained from a discernibility matrix which can be computed using methods based on RST
and FRST. Therefore, it should be noted that before calling the function, we need to
compute a discernibility matrix using <code><a href="#topic+BC.discernibility.mat.RST">BC.discernibility.mat.RST</a></code> or
<code><a href="#topic+BC.discernibility.mat.FRST">BC.discernibility.mat.FRST</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FS.all.reducts.computation(discernibilityMatrix)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FS.all.reducts.computation_+3A_discernibilitymatrix">discernibilityMatrix</code></td>
<td>
<p>an <code>"DiscernibilityMatrix"</code> object representing
a discernibility matrix of a decision system.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of a class <code>"ReductSet"</code>.
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BC.discernibility.mat.RST">BC.discernibility.mat.RST</a></code>, <code><a href="#topic+BC.discernibility.mat.FRST">BC.discernibility.mat.FRST</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>########################################################
## Example 1: Generate all reducts and
##            a new decision table using RST
########################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$hiring.dt

## build the decision-relation discernibility matrix
res.2 &lt;- BC.discernibility.mat.RST(decision.table, range.object = NULL)

## generate all reducts
reduct &lt;- FS.all.reducts.computation(res.2)

## generate new decision table
new.decTable &lt;- SF.applyDecTable(decision.table, reduct, control = list(indx.reduct = 1))

##############################################################
## Example 2: Generate all reducts and
##            a new decision table using FRST
##############################################################
## Not run: data(RoughSetData)
decision.table &lt;- RoughSetData$hiring.dt

## build the decision-relation discernibility matrix
control.1 &lt;- list(type.relation = c("crisp"),
                type.aggregation = c("crisp"),
                t.implicator = "lukasiewicz", type.LU = "implicator.tnorm")
res.1 &lt;- BC.discernibility.mat.FRST(decision.table, type.discernibility = "standard.red",
                                    control = control.1)

## generate single reduct
reduct &lt;- FS.all.reducts.computation(res.1)

## generate new decision table
new.decTable &lt;- SF.applyDecTable(decision.table, reduct, control = list(indx.reduct = 1))
## End(Not run)
</code></pre>

<hr>
<h2 id='FS.DAAR.heuristic.RST'>The DAAR heuristic for computation of decision reducts</h2><span id='topic+FS.DAAR.heuristic.RST'></span>

<h3>Description</h3>

<p>This function implements the Dynamically Adjusted Approximate Reducts heuristic (DAAR)
for feature selection based on RST. The algorithm modifies the greedy approach to selecting
attributes by introducing an additional stop condition. The algorithm stops when a random
probe (permutation) test fails to reject a hypothesis that the selected attribute introduces
illusionary dependency in data (in a context of previously selected attributes).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FS.DAAR.heuristic.RST(
  decision.table,
  attrDescriptions = attr(decision.table, "desc.attrs"),
  decisionIdx = attr(decision.table, "decision.attr"),
  qualityF = X.gini,
  nAttrs = NULL,
  allowedRandomness = 1/ncol(decision.table),
  nOfProbes = max(ncol(decision.table), 100),
  permsWithinINDclasses = FALSE,
  semigreedy = FALSE,
  inconsistentDecisionTable = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FS.DAAR.heuristic.RST_+3A_decision.table">decision.table</code></td>
<td>
<p>an object of a <code>"DecisionTable"</code> class representing a decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="FS.DAAR.heuristic.RST_+3A_attrdescriptions">attrDescriptions</code></td>
<td>
<p>a list containing possible values of attributes (columns) in <code>decision.table</code>. 
It usually corresponds to <code>attr(decision.table, "desc.attrs")</code>.</p>
</td></tr>
<tr><td><code id="FS.DAAR.heuristic.RST_+3A_decisionidx">decisionIdx</code></td>
<td>
<p>an integer value representing an index of the decision attribute.</p>
</td></tr>
<tr><td><code id="FS.DAAR.heuristic.RST_+3A_qualityf">qualityF</code></td>
<td>
<p>a function used for computation of the quality of attribute subsets.
Currently, the following functions are included:
</p>

<ul>
<li> <p><code>X.entropy</code>: See <code><a href="#topic+X.entropy">X.entropy</a></code>.
</p>
</li>
<li> <p><code>X.gini</code>: See <code><a href="#topic+X.gini">X.gini</a></code>.
</p>
</li>
<li> <p><code>X.nOfConflicts</code>: See <code><a href="#topic+X.nOfConflicts">X.nOfConflicts</a></code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="FS.DAAR.heuristic.RST_+3A_nattrs">nAttrs</code></td>
<td>
<p>an integer between 1 and the number of conditional attributes. It indicates
the attribute sample size for the Monte Carlo selection of candidating attributes.
If set to <code>NULL</code> (default) all attributes are used and the algorithm changes
to a standard greedy method for computation of decision reducts.</p>
</td></tr>
<tr><td><code id="FS.DAAR.heuristic.RST_+3A_allowedrandomness">allowedRandomness</code></td>
<td>
<p>a threshold for attribute relevance. Computations will be terminated
when the relevance of a selected attribute fall below this threshold.</p>
</td></tr>
<tr><td><code id="FS.DAAR.heuristic.RST_+3A_nofprobes">nOfProbes</code></td>
<td>
<p>a number of random probes used for estimating the attribute relevance
(see the references).</p>
</td></tr>
<tr><td><code id="FS.DAAR.heuristic.RST_+3A_permswithinindclasses">permsWithinINDclasses</code></td>
<td>
<p>a logical value indicating whether the permutation test
should be conducted within indescernibility classes.</p>
</td></tr>
<tr><td><code id="FS.DAAR.heuristic.RST_+3A_semigreedy">semigreedy</code></td>
<td>
<p>a logical indicating whether the semigreedy heuristic should be used for
selecting the best attribute in each iteration of the algorithm</p>
</td></tr>
<tr><td><code id="FS.DAAR.heuristic.RST_+3A_inconsistentdecisiontable">inconsistentDecisionTable</code></td>
<td>
<p>a logical indicating whether the decision table is suspected
to be inconsistent or <code>NULL</code> (the default) which indicated that a test should
be made to determine the data consistency.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As in the case of <code><a href="#topic+FS.greedy.heuristic.reduct.RST">FS.greedy.heuristic.reduct.RST</a></code> the implementation can use
different attribute subset quality functions (parameter <code>qualityF</code>) and Monte Carlo
generation of candidating attributes (parameter <code>nAttrs</code>).
</p>


<h3>Value</h3>

<p>A class <code>"FeatureSubset"</code> that contains the following components:
</p>

<ul>
<li> <p><code>reduct</code>: a list representing a single reduct. In this case, it could be a superreduct or just a subset of features.
</p>
</li>
<li> <p><code>type.method</code>: a string representing the type of method which is <code>"greedy.heuristic"</code>.
</p>
</li>
<li> <p><code>type.task</code>: a string showing the type of task which is <code>"feature selection"</code>.
</p>
</li>
<li> <p><code>model</code>: a string representing the type of model. In this case, it is <code>"RST"</code> which means rough set theory.
</p>
</li>
<li> <p><code>relevanceProbabilities</code>: an intiger vector with estimated relevances of selected attributes.
</p>
</li>
<li> <p><code>epsilon</code>: a value between 0 and 1 representing the estimated approximation threshold.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>References</h3>

<p>A. Janusz and D. ≈ölƒôzak, &quot;Random Probes in Computation and Assessment of Approximate Reducts&quot;,
Proceedings of RSEISP 2014, Springer, LNCS vol. 8537: p. 53 - 64 (2014).
</p>
<p>Andrzej Janusz and Dominik Slezak. &quot;Computation of approximate reducts with dynamically
adjusted approximation threshold&quot;. In Proceedings of ISMIS 2015, LNCS
volume 9384, pages 19‚Äì28. Springer, 2015.
</p>
<p>A. Janusz and S. Stawicki, &quot;Applications of Approximate Reducts to the Feature Selection Problem&quot;,
Proceedings of International Conference on Rough Sets and Knowledge Technology (RSKT), vol. 6954, p. 45 - 50 (2011).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+FS.greedy.heuristic.reduct.RST">FS.greedy.heuristic.reduct.RST</a></code> and <code><a href="#topic+FS.reduct.computation">FS.reduct.computation</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###################################################
## Example 1: Evaluate reduct and generate
##            new decision table
###################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$hiring.dt

## evaluate a single reduct
res.1 &lt;- FS.DAAR.heuristic.RST(decision.table)

## generate a new decision table corresponding to the reduct
new.decTable &lt;- SF.applyDecTable(decision.table, res.1)
</code></pre>

<hr>
<h2 id='FS.feature.subset.computation'>The superreduct computation based on RST and FRST</h2><span id='topic+FS.feature.subset.computation'></span>

<h3>Description</h3>

<p>This function is a wrapper for computing different types of decision superreducts
(i.e. attribute subsets which do not lose any information regarding the decisions
but are not require to be irreducable).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FS.feature.subset.computation(
  decision.table,
  method = "greedy.heuristic.superreduct",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FS.feature.subset.computation_+3A_decision.table">decision.table</code></td>
<td>
<p>an object of a <code>"DecisionTable"</code> class representing a decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="FS.feature.subset.computation_+3A_method">method</code></td>
<td>
<p>a character representing the type of a method to use for computations. See in Section <code>Details</code>.</p>
</td></tr>
<tr><td><code id="FS.feature.subset.computation_+3A_...">...</code></td>
<td>
<p>other parameters corresponding to the chosen <code>method</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Currently, there are implemented three methods that can be used with this function:
</p>

<ul>
<li> <p><code>"greedy.heuristic.superreduct"</code>: it is a greedy heuristic method which employs several quality measures from RST.
See <code><a href="#topic+FS.greedy.heuristic.superreduct.RST">FS.greedy.heuristic.superreduct.RST</a></code>.
</p>
</li>
<li> <p><code>"quickreduct.frst"</code>: it is a feature selection function based on the fuzzy QuickReduct algorithm on FRST.
See <code><a href="#topic+FS.quickreduct.FRST">FS.quickreduct.FRST</a></code>.
</p>
</li>
<li> <p><code>"quickreduct.rst"</code>: it is a feature selection function based on the RST QuickReduct algorithm.
See <code><a href="#topic+FS.quickreduct.RST">FS.quickreduct.RST</a></code>.
</p>
</li></ul>

<p>These methods can be selected by assigning an appropriate value of the parameter <code>method</code>.
Additionally, <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code> is provided to generate the new decision table.
</p>


<h3>Value</h3>

<p>A class <code>"FeatureSubset"</code>.
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>See Also</h3>

<p><code><a href="#topic+FS.greedy.heuristic.superreduct.RST">FS.greedy.heuristic.superreduct.RST</a></code>, <code><a href="#topic+FS.quickreduct.RST">FS.quickreduct.RST</a></code>, <code><a href="#topic+FS.quickreduct.FRST">FS.quickreduct.FRST</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###############################################################
## Example 1: generate reduct and new decision table using RST
###############################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$hiring.dt

## generate single superreduct
res.1 &lt;- FS.feature.subset.computation(decision.table,
                                       method = "quickreduct.rst")

## generate new decision table according to the reduct
new.decTable &lt;- SF.applyDecTable(decision.table, res.1)

###############################################################
## Example 2: generate reduct and new decision table using FRST
###############################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$housing7.dt

## generate single superreduct
res.2 &lt;- FS.feature.subset.computation(decision.table,
                                       method = "quickreduct.frst")

## generate new decision table according to the reduct
new.decTable &lt;- SF.applyDecTable(decision.table, res.2)
</code></pre>

<hr>
<h2 id='FS.greedy.heuristic.reduct.RST'>The greedy heuristic algorithm for computing decision reducts and approximate decision reducts</h2><span id='topic+FS.greedy.heuristic.reduct.RST'></span>

<h3>Description</h3>

<p>This function implements a greedy heuristic algorithm for computing decision reducts
(or approximate decision reducts) based on RST.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FS.greedy.heuristic.reduct.RST(
  decision.table,
  attrDescriptions = attr(decision.table, "desc.attrs"),
  decisionIdx = attr(decision.table, "decision.attr"),
  qualityF = X.gini,
  nAttrs = NULL,
  epsilon = 0,
  inconsistentDecisionTable = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FS.greedy.heuristic.reduct.RST_+3A_decision.table">decision.table</code></td>
<td>
<p>an object of a <code>"DecisionTable"</code> class representing a decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="FS.greedy.heuristic.reduct.RST_+3A_attrdescriptions">attrDescriptions</code></td>
<td>
<p>a list containing possible values of attributes (columns) in <code>decision.table</code>. 
It usually corresponds to <code>attr(decision.table, "desc.attrs")</code>.</p>
</td></tr>
<tr><td><code id="FS.greedy.heuristic.reduct.RST_+3A_decisionidx">decisionIdx</code></td>
<td>
<p>an integer value representing an index of the decision attribute.</p>
</td></tr>
<tr><td><code id="FS.greedy.heuristic.reduct.RST_+3A_qualityf">qualityF</code></td>
<td>
<p>a function used for computation of the quality of attribute subsets.
Currently, the following functions are included:
</p>

<ul>
<li> <p><code>X.entropy</code>: See <code><a href="#topic+X.entropy">X.entropy</a></code>.
</p>
</li>
<li> <p><code>X.gini</code>: See <code><a href="#topic+X.gini">X.gini</a></code>.
</p>
</li>
<li> <p><code>X.nOfConflicts</code>: See <code><a href="#topic+X.nOfConflicts">X.nOfConflicts</a></code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="FS.greedy.heuristic.reduct.RST_+3A_nattrs">nAttrs</code></td>
<td>
<p>an integer between 1 and the number of conditional attributes. It indicates
the attribute sample size for the Monte Carlo selection of candidating attributes.
If set to <code>NULL</code> (default) all attributes are used and the algorithm changes
to a standard greedy method for computation of decision reducts.</p>
</td></tr>
<tr><td><code id="FS.greedy.heuristic.reduct.RST_+3A_epsilon">epsilon</code></td>
<td>
<p>a numeric value between [0, 1) representing an approximate threshold. It
indicates whether to compute approximate reducts or not. If it equals 0 (the default)
a standard decision reduct is computed.</p>
</td></tr>
<tr><td><code id="FS.greedy.heuristic.reduct.RST_+3A_inconsistentdecisiontable">inconsistentDecisionTable</code></td>
<td>
<p>logical indicating whether the decision table is suspected
to be inconsistent or <code>NULL</code> (the default) which indicated that a test should
be made to determine the data consistency.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In this implementation, we provided some attribute subset quality measures which can be
passed to the algorithm by the parameter <code>qualityF</code>. Those measures
guide the computations in the search for a decision/approximated reduct. They are used to
assess amount of information gained after addition of an attribute. For example,
<code>X.entropy</code> corresponds to the information gain measure.
</p>
<p>Additionally, this function can use the value of <code>epsilon</code> parameter in order to compute
<code class="reqn">\epsilon</code>-approximate reducts. The <code class="reqn">\epsilon</code>-approximate can be defined as an
irreducable subset of attributes <code>B</code>, such that:
</p>
<p><code class="reqn">Quality_{\mathcal{A}}(B) \ge (1 - \epsilon)Quality_{\mathcal{A}}(A)</code>,
</p>
<p>where <code class="reqn">Quality_{\mathcal{A}}(B)</code> is the value of a quality measure (see possible values
of the parameter <code>qualityF</code>) for an attribute subset <code class="reqn">B</code> in decision table <code class="reqn">\mathcal{A}</code>
and <code class="reqn">\epsilon</code> is a numeric value between 0 and 1 expressing the approximation threshold.
A lot of monographs provide comprehensive explanations about this topics, for example
(Janusz and Stawicki, 2011; Slezak, 2002; Wroblewski, 2001) which are used as the references of this function.
</p>
<p>Finally, this implementation allows to restrain the computational complexity of greedy
searching for decision reducts by setting the value of the parameter <code>nAttrs</code>. If this
parameter is set to a positive integer, the Monte Carlo method of selecting candidating
attributes will be used in each iteration of the algorithm.
</p>


<h3>Value</h3>

<p>A class <code>"FeatureSubset"</code> that contains the following components:
</p>

<ul>
<li> <p><code>reduct</code>: a list representing a single reduct. In this case, it could be a superreduct or just a subset of features.
</p>
</li>
<li> <p><code>type.method</code>: a string representing the type of method which is <code>"greedy.heuristic"</code>.
</p>
</li>
<li> <p><code>type.task</code>: a string showing the type of task which is <code>"feature selection"</code>.
</p>
</li>
<li> <p><code>model</code>: a string representing the type of model. In this case, it is <code>"RST"</code> which means rough set theory.
</p>
</li>
<li> <p><code>epsilon</code>: the approximation threshold.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>References</h3>

<p>Andrzej Janusz and Dominik Slezak. &quot;Rough Set Methods for Attribute
Clustering and Selection&quot;. Applied Artificial Intelligence, 28(3):220‚Äì242, 2014.
</p>
<p>A. Janusz and S. Stawicki, &quot;Applications of Approximate Reducts to the Feature Selection Problem&quot;,
Proceedings of International Conference on Rough Sets and Knowledge Technology (RSKT), vol. 6954, p. 45 - 50 (2011).
</p>
<p>D. ≈ölƒôzak, &quot;Approximate Entropy Reducts&quot;, Fundamenta Informaticae, vol. 53, no. 3 - 4, p. 365 - 390 (2002).
</p>
<p>J. Wr√≥blewski, &quot;Ensembles of Classifiers Based on Approximate Reducts&quot;, Fundamenta Informaticae, vol. 47, no. 3 - 4, p. 351 - 360 (2001).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+FS.DAAR.heuristic.RST">FS.DAAR.heuristic.RST</a></code> and <code><a href="#topic+FS.reduct.computation">FS.reduct.computation</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###################################################
## Example 1: Evaluate reduct and generate
##            new decision table
###################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$hiring.dt

## evaluate a single reduct
res.1 &lt;- FS.greedy.heuristic.reduct.RST(decision.table, qualityF = X.entropy,
                                        epsilon = 0.0)

## generate a new decision table corresponding to the reduct
new.decTable &lt;- SF.applyDecTable(decision.table, res.1)
</code></pre>

<hr>
<h2 id='FS.greedy.heuristic.superreduct.RST'>The greedy heuristic method for determining superreduct based on RST</h2><span id='topic+FS.greedy.heuristic.superreduct.RST'></span>

<h3>Description</h3>

<p>It is used to get a feature subset (superreduct) based on the greedy heuristic algorithm
employing some quality measurements. Regarding the quality measurements, the detailed description can be seen in <code><a href="#topic+FS.greedy.heuristic.reduct.RST">FS.greedy.heuristic.reduct.RST</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FS.greedy.heuristic.superreduct.RST(
  decision.table,
  attrDescriptions = attr(decision.table, "desc.attrs"),
  decisionIdx = attr(decision.table, "decision.attr"),
  qualityF = X.gini,
  nAttrs = NULL,
  inconsistentDecisionTable = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FS.greedy.heuristic.superreduct.RST_+3A_decision.table">decision.table</code></td>
<td>
<p>an object of a <code>"DecisionTable"</code> class representing a decision table.
See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="FS.greedy.heuristic.superreduct.RST_+3A_attrdescriptions">attrDescriptions</code></td>
<td>
<p>a list containing possible values of attributes (columns)
in <code>decision.table</code>. It usually corresponds to <code>attr(decision.table, "desc.attrs")</code>.</p>
</td></tr>
<tr><td><code id="FS.greedy.heuristic.superreduct.RST_+3A_decisionidx">decisionIdx</code></td>
<td>
<p>a integer value representing an index of decision attribute.</p>
</td></tr>
<tr><td><code id="FS.greedy.heuristic.superreduct.RST_+3A_qualityf">qualityF</code></td>
<td>
<p>a function for calculating a quality of an attribute subset.
See <code><a href="#topic+FS.greedy.heuristic.reduct.RST">FS.greedy.heuristic.reduct.RST</a></code>.</p>
</td></tr>
<tr><td><code id="FS.greedy.heuristic.superreduct.RST_+3A_nattrs">nAttrs</code></td>
<td>
<p>an integer between 1 and the number of conditional attributes. It indicates
the attribute sample size for the Monte Carlo selection of candidating attributes.
If set to <code>NULL</code> (default) all attributes are used and the algorithm changes
to a standard greedy method for computation of decision reducts.</p>
</td></tr>
<tr><td><code id="FS.greedy.heuristic.superreduct.RST_+3A_inconsistentdecisiontable">inconsistentDecisionTable</code></td>
<td>
<p>logical indicating whether the decision table is suspected
to be inconsistent or <code>NULL</code> (the default) which indicated that a test should
be made to determine the data consistency.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A class <code>"FeatureSubset"</code> that contains the following components:
</p>

<ul>
<li> <p><code>reduct</code>: a list representing a single reduct. In this case, it could be a superreduct or just a subset of features.
</p>
</li>
<li> <p><code>type.method</code>: a string representing the type of method which is <code>"greedy.heuristic.superreduct"</code>.
</p>
</li>
<li> <p><code>type.task</code>: a string showing the type of task which is <code>"feature selection"</code>.
</p>
</li>
<li> <p><code>model</code>: a string representing the type of model. In this case, it is <code>"RST"</code> which means rough set theory.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>References</h3>

<p>Andrzej Janusz and Dominik Slezak. &quot;Rough Set Methods for Attribute
Clustering and Selection&quot;. Applied Artificial Intelligence, 28(3):220‚Äì242, 2014.
</p>
<p>A. Janusz and S. Stawicki, &quot;Applications of Approximate Reducts to the Feature Selection Problem&quot;,
Proceedings of International Conference on Rough Sets and Knowledge Technology (RSKT), vol. 6954, p. 45 - 50 (2011).
</p>
<p>D. ≈ölƒôzak, &quot;Approximate Entropy Reducts&quot;, Fundamenta Informaticae, vol. 53, no. 3 - 4, p. 365 - 390 (2002).
</p>
<p>J. Wroblewski, &quot;Ensembles of Classifiers Based on Approximate Reducts&quot;, Fundamenta Informaticae, vol. 47, no. 3 - 4, p. 351 - 360 (2001).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+FS.quickreduct.RST">FS.quickreduct.RST</a></code> and <code><a href="#topic+FS.feature.subset.computation">FS.feature.subset.computation</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###################################################
## Example 1: Evaluate reduct and generate
##            new decision table
###################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$hiring.dt

## evaluate single reduct
res.1 &lt;- FS.greedy.heuristic.superreduct.RST(decision.table, qualityF = X.nOfConflicts)
print(res.1)

## generate new decision table according to the reduct
new.decTable &lt;- SF.applyDecTable(decision.table, res.1)
</code></pre>

<hr>
<h2 id='FS.nearOpt.fvprs.FRST'>The near-optimal reduction algorithm based on fuzzy rough set theory</h2><span id='topic+FS.nearOpt.fvprs.FRST'></span>

<h3>Description</h3>

<p>This is a function implementing the near-optimal reduction algorithm by employing
fuzzy variable precision rough sets (FVPRS) for feature selection
based on FRST proposed by (Zhao et al, 2009).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FS.nearOpt.fvprs.FRST(decision.table, alpha.precision = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FS.nearOpt.fvprs.FRST_+3A_decision.table">decision.table</code></td>
<td>
<p>an object of a <code>"DecisionTable"</code> class representing a decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.
In this case, the decision attribute must be nominal.</p>
</td></tr>
<tr><td><code id="FS.nearOpt.fvprs.FRST_+3A_alpha.precision">alpha.precision</code></td>
<td>
<p>a numeric value representing variable precision of FVPRS.
</p>
<p>See <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The near-optimal algorithm is an algorithm to find one reduct only rather than all reducts. It modifies the <code class="reqn">\alpha</code>-reduction based on
discernibility matrix by using a heuristic algorithm. To get basic knowledge about discernibility matrix,
users can refers to the <code>"alpha.red"</code> discernibility type in <code><a href="#topic+BC.discernibility.mat.FRST">BC.discernibility.mat.FRST</a></code> .
</p>
<p>It should be noted that this function does not give the new decision table directly.
The other additional function called <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code> is used to produce the new decision table based on
information about the reduct from this function.
</p>


<h3>Value</h3>

<p>A class <code>"FeatureSubset"</code> that contains the following components:
</p>

<ul>
<li> <p><code>reduct</code>: a list representing a single reduct. In this case, it could be a superreduct or just a subset of features.
</p>
</li>
<li> <p><code>type.method</code>: a string representing the type of method which is <code>"near.optimal.fvprs"</code>.
</p>
</li>
<li> <p><code>type.task</code>: a string showing the type of task which is <code>"feature selection"</code>.
</p>
</li>
<li> <p><code>model</code>: a string representing the type of model. In this case, it is <code>"FRST"</code> which means fuzzy rough set theory.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>References</h3>

<p>S. Zhao, E. C. C. Tsang, and D. Chen, &quot;The Model of Fuzzy Variable Precision Rough Sets&quot;,
IEEE Trans. on Fuzzy Systems, vol. 17, no. 2, p. 451 - 467 (2009).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BC.discernibility.mat.FRST">BC.discernibility.mat.FRST</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#########################################################
## Example 1: Hiring dataset containing 8 objects with 5 attributes
#########################################################
## Not run: data(RoughSetData)
decision.table &lt;- RoughSetData$hiring.dt

## get reduct as FeatureSubset class
reduct.1 &lt;- FS.nearOpt.fvprs.FRST(decision.table)

## get new decision table according to the reduct
new.decTable &lt;- SF.applyDecTable(decision.table, reduct.1)
## End(Not run)

#########################################################
## Example 2: Pima dataset containing 7 objects with 9 attributes
#########################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$pima7.dt

## get reduct
reduct.2 &lt;- FS.nearOpt.fvprs.FRST(decision.table)

## get new decision table according to the reduct
new.decTable &lt;- SF.applyDecTable(decision.table, reduct.2)
</code></pre>

<hr>
<h2 id='FS.one.reduct.computation'>Computing one reduct from a discernibility matrix</h2><span id='topic+FS.one.reduct.computation'></span>

<h3>Description</h3>

<p>It is a function for computing one reduct from a discernibility matrix - it can use
the greedy heuristic or a randomized (Monte Carlo) search.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FS.one.reduct.computation(discernibilityMatrix, greedy = TRUE, power = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FS.one.reduct.computation_+3A_discernibilitymatrix">discernibilityMatrix</code></td>
<td>
<p>a <code>"DiscernibilityMatrix"</code> class representing the discernibility matrix of RST and FRST.</p>
</td></tr>
<tr><td><code id="FS.one.reduct.computation_+3A_greedy">greedy</code></td>
<td>
<p>a boolean value indicating whether the greedy heuristic or a randomized search should be used in computations.</p>
</td></tr>
<tr><td><code id="FS.one.reduct.computation_+3A_power">power</code></td>
<td>
<p>a numeric representing a parameter of the randomized search heuristic.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of a class <code>"ReductSet"</code>.
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>References</h3>

<p>Jan G. Bazan, Hung Son Nguyen, Sinh Hoa Nguyen, Piotr Synak, and Jakub Wroblewski,
&quot;Rough Set Algorithms in Classification Problem&quot;, Chapter 2
In: L. Polkowski, S. Tsumoto and T.Y. Lin (eds.): Rough Set Methods and Applications
Physica-Verlag, Heidelberg, New York, p. 49 - 88 ( 2000).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BC.discernibility.mat.RST">BC.discernibility.mat.RST</a></code> and <code><a href="#topic+BC.discernibility.mat.FRST">BC.discernibility.mat.FRST</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>########################################################
## Example 1: Generate one reduct and
##            a new decision table using RST
########################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$hiring.dt

## build the decision-relation discernibility matrix
res.1 &lt;- BC.discernibility.mat.RST(decision.table)

## generate all reducts
reduct &lt;- FS.one.reduct.computation(res.1)

## generate new decision table
new.decTable &lt;- SF.applyDecTable(decision.table, reduct, control = list(indx.reduct = 1))

##############################################################
## Example 2: Generate one reduct and
##            a new decision table using FRST
##############################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$hiring.dt

## build the decision-relative discernibility matrix
control &lt;- list(type.relation = c("crisp"),
                type.aggregation = c("crisp"),
                t.implicator = "lukasiewicz", type.LU = "implicator.tnorm")
res.2 &lt;- BC.discernibility.mat.FRST(decision.table, type.discernibility = "standard.red",
                                    control = control)

## generate a single reduct
reduct &lt;- FS.one.reduct.computation(res.2)

## generate new decision table
new.decTable &lt;- SF.applyDecTable(decision.table, reduct, control = list(indx.reduct = 1))
</code></pre>

<hr>
<h2 id='FS.permutation.heuristic.reduct.RST'>The permutation heuristic algorithm for computation of a decision reduct</h2><span id='topic+FS.permutation.heuristic.reduct.RST'></span>

<h3>Description</h3>

<p>It is a function implementing the permutation heuristic approach based on RST.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FS.permutation.heuristic.reduct.RST(
  decision.table,
  permutation = NULL,
  decisionIdx = ncol(decision.table)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FS.permutation.heuristic.reduct.RST_+3A_decision.table">decision.table</code></td>
<td>
<p>an object of a <code>"DecisionTable"</code> class representing a decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="FS.permutation.heuristic.reduct.RST_+3A_permutation">permutation</code></td>
<td>
<p>a logical value, an integer vector or<code>NULL</code> (the default). If an integer vector with a length
equal the cardinality of the conditional attribute set of the decision table is given (it must contain a permutation of
integers from 1:(ncol(decision.table) - 1) ), then it will define the elimination order. Otherwise, if <code>permutation</code>
is <code>NULL</code> or <code>TRUE</code> a random permutation will be generated. In the case when <code>permutation</code> is FALSE, the
elimination will be performed in the order of attributes in the decision system.</p>
</td></tr>
<tr><td><code id="FS.permutation.heuristic.reduct.RST_+3A_decisionidx">decisionIdx</code></td>
<td>
<p>an index of the decision attribute. The default value is the last column of a decision table.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Basically there are two steps in this algorithm which are
</p>

<ul>
<li><p> generating feature subset as a superreduct: In this step, we choose a subset of attributes that
discern all object from different decision classes. It is done by adding consecutive attributes
in an order defined by a permutation of attribute indices. The permutation can be random
or it can be explicitly given (by the parameter <code>permutation</code>).
</p>
</li>
<li><p> iterative elimination of attributes from the set obtained in the previous step.
It is done in the reverse order to that, defined by the permutation.
</p>
</li></ul>

<p>More details regarding this algorithm can be found in (Janusz and Slezak, 2012).
</p>
<p>Additionally, <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code> has been provided to generate new decision table.
</p>


<h3>Value</h3>

<p>A class <code>"FeatureSubset"</code> that contains the following components:
</p>

<ul>
<li> <p><code>reduct</code>: a list representing a single reduct. In this case, it could be a superreduct or just a subset of features.
</p>
</li>
<li> <p><code>type.method</code>: a string representing the type of method which is <code>"permutation.heuristic"</code>.
</p>
</li>
<li> <p><code>type.task</code>: a string showing the type of task which is <code>"feature selection"</code>.
</p>
</li>
<li> <p><code>model</code>: a string representing the type of model. In this case, it is <code>"RST"</code> which means rough set theory.
</p>
</li>
<li> <p><code>epsilon</code>: the approximation threshold.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>References</h3>

<p>A. Janusz and D. ≈ölƒôzak, &quot;Utilization of Attribute Clustering Methods for Scalable Computation of Reducts from High-Dimensional Data&quot;.
Proceedings of Federated Conference on Computer Science and Information Systems - FedCSIS, p. 295 - 302 (2012).
</p>
<p>Andrzej Janusz and Dominik Slezak. &quot;Rough Set Methods for Attribute
Clustering and Selection&quot;. Applied Artificial Intelligence, 28(3):220‚Äì242, 2014.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+FS.quickreduct.RST">FS.quickreduct.RST</a></code> and <code><a href="#topic+FS.reduct.computation">FS.reduct.computation</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###################################################
## Example 1: Generate reduct and new decision table
###################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$hiring.dt

## generate single reduct
res.1 &lt;- FS.permutation.heuristic.reduct.RST(decision.table,
                                             permutation = NULL,
                                             decisionIdx = 5)
print(res.1)

res.2 &lt;- FS.permutation.heuristic.reduct.RST(decision.table,
                                             permutation = 4:1,
                                             decisionIdx = 5)
print(res.2)

## generate new decision table according to the reduct
new.decTable &lt;- SF.applyDecTable(decision.table, res.1)
</code></pre>

<hr>
<h2 id='FS.quickreduct.FRST'>The fuzzy QuickReduct algorithm based on FRST</h2><span id='topic+FS.quickreduct.FRST'></span>

<h3>Description</h3>

<p>It is a function implementing the fuzzy QuickReduct algorithm
for feature selection based on FRST.
The fuzzy QuickReduct is a modification of QuickReduct based on RST (see <code><a href="#topic+FS.quickreduct.RST">FS.quickreduct.RST</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FS.quickreduct.FRST(
  decision.table,
  type.method = "fuzzy.dependency",
  type.QR = "fuzzy.QR",
  control = list()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FS.quickreduct.FRST_+3A_decision.table">decision.table</code></td>
<td>
<p>an object of a <code>"DecisionTable"</code> class representing a decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="FS.quickreduct.FRST_+3A_type.method">type.method</code></td>
<td>
<p>a string representing the type of methods.
The complete description can be found in Section <code>Details</code>.</p>
</td></tr>
<tr><td><code id="FS.quickreduct.FRST_+3A_type.qr">type.QR</code></td>
<td>
<p>a string expressing the type of QuickReduct algorithm which is one of the two following algorithms:
</p>

<ul>
<li> <p><code>"fuzzy.QR"</code>: it is the original fuzzy rough QuickReduct algorithm based on (Jensen and Shen, 2002).
</p>
</li>
<li> <p><code>"modified.QR"</code>: it is the modified QuickReduct algorithm based on (Bhatt and Gopal, 2005).
</p>
</li></ul>
</td></tr>
<tr><td><code id="FS.quickreduct.FRST_+3A_control">control</code></td>
<td>
<p>a list of other parameters as follows.
</p>

<ul>
<li> <p><code>type.aggregation</code>: a type of aggregation operator. See <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code>.
</p>
</li>
<li> <p><code>t.implicator</code>: a type of implicator function. See <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.
The default value is <code>"lukasiewicz"</code>.
</p>
</li>
<li> <p><code>type.relation</code>: a type of indiscernibility relation. See <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code>.
The default value is <code>type.relation = c("tolerance", "eq.3")</code>.
</p>
</li>
<li> <p><code>alpha</code>: a real number between 0 and 1 expressing a threshold value or stopping criterion.
The following methods use the parameter: <code>"vqrs"</code>,
</p>
<p><code>"min.positive.reg"</code>, and <code>"fuzzy.discernibility"</code>.
The default value is 0.95.
</p>
</li>
<li> <p><code>alpha.precision</code>: a real number between 0 and 1 expressing variable precision (<code class="reqn">\alpha</code>) for <code>"fvprs"</code>.
See <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>. The default value is 0.05.
</p>
</li>
<li> <p><code>q.some</code>: a pair of numeric values for the alpha and beta parameter of VQRS for the quantifier <code>some</code>.
The default value is <code>q.some = c(0.1, 0.6)</code>.
</p>
<p>See <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.
</p>
</li>
<li> <p><code>q.most</code>: a pair of numeric values for the alpha and beta parameter of VQRS for the quantifier <code>most</code>.
The default value is <code>q.most = c(0.2, 1)</code>.
</p>
<p>See <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.
</p>
</li>
<li> <p><code>m.owa</code>: a numeric value to define the parameter in OWA. The default value is the mean number of objects.
</p>
</li>
<li> <p><code>type.rfrs</code>: a type of robust fuzzy rough sets.
</p>
<p>The default is <code>type.rfrs = "k.trimmed.min")</code>.
</p>
<p>See <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.
</p>
</li>
<li> <p><code>k.rfrs</code>: a value between 0 and length of data representing index of considered data.
The default is <code>k.rfrs = round(0.5*nrow(decision.table))</code>.
See <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.
</p>
</li>
<li> <p><code>beta.quasi</code>: a number between 0 and 1 representing <code class="reqn">\beta</code>-precision t-norms and t-conorms.
The default value is 0.05.
</p>
</li>
<li> <p><code>randomize</code>: a boolean value to define whether selecting attributes randomly or not. For more detail,
see in Section <code>Details</code>. The default value is <code>FALSE</code>.
</p>
</li></ul>

<p>It should be noted that instead of supplying all the above parameters, we only set
those parameters needed by the considered method. See in Section <code>Details</code>.
Also, we provide some examples to illustrate how the parameters are used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In this function, we provide an algorithm proposed by
(Jensen and Shen, 2002) which is fuzzy QuickReduct. Then, the algorithm has been modified by (Bhatt and Gopal, 2005) to improve stopping criteria.
This function is aimed to implement both algorithms. These algorithms can be executed by assigning the parameter <code>type.QR</code>
with <code>"fuzzy.QR"</code> and <code>"modified.QR"</code> for fuzzy quickreduct and modified fuzzy quickreduct
algorithms, respectively. Additionally, in the <code>control</code> parameter, we provide one component which is
<code>randomize</code> having boolean values: <code>TRUE</code> or <code>FALSE</code>. <code>randomize = TRUE</code> means that
we evaluate some (or not all) attributes randomly along iteration. It will be useful if we have a large number of attributes
in a decision table.
</p>
<p>In this function, we have considered many approaches of the lower and upper approximations.
The following list shows considered methods and their descriptions. Additionally, those approaches can be executed by
assigning the following value to the parameter <code>type.method</code>.
</p>

<ul>
<li> <p><code>"fuzzy.dependency"</code>: It is based on the degree of dependency using the implication/t-norm model approximation (Jensen and Shen, 2009).
The detailed concepts about this approximation have been explained in <code><a href="#topic+Introduction-FuzzyRoughSets">Introduction-FuzzyRoughSets</a></code>
and
</p>
<p><code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.
</p>
</li>
<li> <p><code>"fuzzy.boundary.reg"</code>: It is based on the fuzzy boundary region proposed by (Jensen and Shen, 2009).
This algorithm introduced the usage of the total uncertainty degree <code class="reqn">\lambda_B(Q)</code>
for all concepts of feature subset <code class="reqn">B</code> and decision attribute <code class="reqn">Q</code>.
The total uncertainty degree is used as a parameter to select appropriate features.
</p>
</li>
<li> <p><code>"vqrs"</code>: It is based on vaquely quantified rough set (VQRS)
proposed by (Cornelis and Jensen, 2008). See also <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.
</p>
</li>
<li> <p><code>"owa"</code>: Based on ordered weighted average (OWA) based fuzzy rough set, (Cornelis et al, 2010) proposed
the degree of dependency as a parameter employed in the algorithm to select appropriate features. The explanation
about lower and upper approximations based on OWA can be found in <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.
</p>
</li>
<li> <p><code>"rfrs"</code>: It is based on degree of dependency that is obtained by performing
the robust fuzzy rough sets proposed by (Hu et al, 2012).
The detailed concepts about this approximation have been explained in <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.
</p>
</li>
<li> <p><code>"min.positive.reg"</code>: Based on measure introduced in (Cornelis et al, 2010) which considers the most problematic element in
the positive region, defined using the implicator/t-norm model.
</p>
</li>
<li> <p><code>"fvprs"</code>: It is based on degree of dependency proposed by (Zhao et al, 2009).
The degree is obtained by using fuzzy lower approximation based on
fuzzy variable precision rough set model.
</p>
</li>
<li> <p><code>"fuzzy.discernibility"</code>: This approach attempts to combine the the decision-relative discernibility matrix
and the fuzzy QuickReduct algorithm. (Jensen and Shen, 2009) introduced a measurement which is the degree of satisfaction to select the attributes.
</p>
</li>
<li> <p><code>"beta.pfrs"</code>: Based on <code class="reqn">\beta</code>-precision fuzzy rough sets (<code class="reqn">\beta</code>-PFRS) proposed by (Salido and Murakami, 2003),
the degree of dependency as a parameter employed in the algorithm to select appropriate features. The explanation
about lower and upper approximations based on <code class="reqn">\beta</code>-PFRS can be found in <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.
</p>
</li></ul>

<p>It should be noted that the parameter <code>type.method</code> is related to parameter <code>control</code>.
In other words, we only set the components in the <code>control</code> parameter that related to the chosen type of method.
The following is a list showing the components of <code>control</code> needed by each type of methods.
</p>

<ul>
<li> <p><code>type.method = "fuzzy.dependency"</code>:
</p>
<p><code>control &lt;- list(t.implicator, type.relation, type.aggregation)</code>
</p>
</li>
<li> <p><code>type.method = "fuzzy.boundary.reg"</code>:
</p>
<p><code>control &lt;- list(t.implicator, type.relation, type.aggregation)</code>
</p>
</li>
<li> <p><code>type.method = "vqrs"</code>:
</p>
<p><code>control &lt;- list(alpha, q.some, q.most, type.aggregation)</code>
</p>
</li>
<li> <p><code>type.method = "owa"</code>:
</p>
<p><code>control &lt;- list(t.implicator, type.relation, m.owa, type.aggregation)</code>
</p>
</li>
<li> <p><code>type.method = "rfrs"</code>:
</p>
<p><code>control &lt;- list(t.implicator, type.relation, type.rfrs,</code>
</p>
<p><code>k.rfrs, type.aggregation)</code>
</p>
</li>
<li> <p><code>type.method = "min.positive.reg"</code>:
</p>
<p><code>control &lt;- list(alpha, t.implicator, type.relation, type.aggregation)</code>
</p>
</li>
<li> <p><code>type.method = "fuzzy.discernibility"</code>:
</p>
<p><code>control &lt;- list(alpha, t.implicator, type.relation, type.aggregation)</code>
</p>
</li>
<li> <p><code>type.method = "fvprs"</code>:
</p>
<p><code>control &lt;- list(alpha.precision, t.implicator, type.relation, type.aggregation)</code>
</p>
</li>
<li> <p><code>type.method = "beta.pfrs"</code>:
</p>
<p><code>control &lt;- list(t.implicator, type.relation, beta.quasi, type.aggregation)</code>
</p>
</li></ul>

<p>The descriptions of each component can be seen in the documentation of the <code>control</code> parameter.
</p>
<p>It should be noted that this function does not give the new decision table directly.
An additional function called <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code> is used to produce new decision table based on
information about the reduct from this function. See Section <code>Examples</code>.
</p>


<h3>Value</h3>

<p>A class <code>"FeatureSubset"</code> that contains the following components:
</p>

<ul>
<li> <p><code>reduct</code>: a list representing a single reduct. In this case, it could be a superreduct or just a subset of feature.
</p>
</li>
<li> <p><code>type.method</code>: a string representing the type of method.
</p>
</li>
<li> <p><code>type.task</code>: a string showing the type of task which is <code>"feature selection"</code>.
</p>
</li>
<li> <p><code>model</code>: a string representing the type of model. In this case, it is <code>"FRST"</code> which means fuzzy rough set theory.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>References</h3>

<p>C. Cornelis, G. Hurtado Martin, R. Jensen, and D. Slezak,
&quot;Feature Selection with Fuzzy Decision Reducts&quot;, Information Sciences, vol. 180, no. 2, p. 209 - 224 (2010).
</p>
<p>C. Cornelis and R. Jensen, &quot;A Noise-tolerant Approach to Fuzzy-rough Feature Selection&quot;,
Proceedings of the 2008 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE 2008),
p. 1598 - 1605 (2008).
</p>
<p>Q. Hu, L. Zhang, S. An, D. Zhang, and D. Yu, &quot;On Robust Fuzzy Rough Set Models&quot;,
IEEE Trans. on Fuzzy Systems, vol. 20, no. 4, p. 636 - 651 (2012).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+FS.quickreduct.RST">FS.quickreduct.RST</a></code> and <code><a href="#topic+FS.feature.subset.computation">FS.feature.subset.computation</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##########################################################
## Example 1: Dataset containing nominal values on all attributes
##########################################################

data(RoughSetData)
decision.table &lt;- RoughSetData$housing7.dt

########## using fuzzy lower approximation ##############
control &lt;- list(t.implicator = "lukasiewicz", type.relation = c("tolerance", "eq.1"),
               type.aggregation = c("t.tnorm", "lukasiewicz"))
reduct.1 &lt;- FS.quickreduct.FRST(decision.table, type.method = "fuzzy.dependency",
                            type.QR = "fuzzy.QR", control = control)

########## using fuzzy boundary region ##############
## Not run: control &lt;- list(t.implicator = "lukasiewicz", type.relation = c("tolerance", "eq.1"),
                type.aggregation = c("t.tnorm", "lukasiewicz"))
reduct.2 &lt;- FS.quickreduct.FRST(decision.table, type.method = "fuzzy.boundary.reg",
                            type.QR = "fuzzy.QR", control = control)

########## using vaguely quantified rough sets (VQRS) #########
control &lt;- list(alpha = 0.9, q.some = c(0.1, 0.6), q.most = c(0.2, 1),
                type.aggregation = c("t.tnorm", "lukasiewicz"))
reduct.3 &lt;- FS.quickreduct.FRST(decision.table, type.method = "vqrs",
                            type.QR = "fuzzy.QR", control = control)

########## ordered weighted average (OWA) #########
control &lt;- list(t.implicator = "lukasiewicz", type.relation = c("tolerance", "eq.1"),
                m.owa = 3, type.aggregation = c("t.tnorm","lukasiewicz"))
reduct.4 &lt;- FS.quickreduct.FRST(decision.table, type.method = "owa",
                            type.QR = "fuzzy.QR", control = control)

########## robust fuzzy rough sets (RFRS) #########
control &lt;- list(t.implicator = "lukasiewicz", type.relation = c("tolerance", "eq.1"),
               type.rfrs = "k.trimmed.min", type.aggregation = c("t.tnorm", "lukasiewicz"),
               k.rfrs = 0)
reduct.5 &lt;- FS.quickreduct.FRST(decision.table, type.method = "rfrs",
                            type.QR = "fuzzy.QR", control = control)

########## using min positive region (delta) ###########
control &lt;- list(alpha = 1, t.implicator = "lukasiewicz",
                type.relation = c("tolerance", "eq.1"), type.aggregation =
                                c("t.tnorm", "lukasiewicz"))
reduct.6 &lt;- FS.quickreduct.FRST(decision.table, type.method = "min.positive.reg",
                            type.QR = "fuzzy.QR", control = control)

########## using FVPRS approximation ##############
control &lt;- list(alpha.precision = 0.05, t.implicator = "lukasiewicz",
               type.aggregation = c("t.tnorm", "lukasiewicz"),
               type.relation = c("tolerance", "eq.1"))
reduct.7 &lt;- FS.quickreduct.FRST(decision.table, type.method = "fvprs",
                            type.QR = "fuzzy.QR", control = control)

########## using beta.PFRS approximation ##############
control &lt;- list(t.implicator = "lukasiewicz", type.relation = c("tolerance", "eq.1"),
                beta.quasi = 0.05, type.aggregation = c("t.tnorm", "lukasiewicz"))
reduct.8 &lt;- FS.quickreduct.FRST(decision.table, type.method = "beta.pfrs",
                            type.QR = "fuzzy.QR", control = control)

########## using fuzzy discernibility matrix ##############
control &lt;- list(alpha = 1, type.relation = c("tolerance", "eq.1"),
               type.aggregation = c("t.tnorm", "lukasiewicz"),
                t.implicator = "lukasiewicz")
reduct.9 &lt;- FS.quickreduct.FRST(decision.table, type.method = "fuzzy.discernibility",
                            type.QR = "fuzzy.QR", control = control)
## End(Not run)

##########################################################
## Example 2: Dataset containing nominal and continuous values
## In this case, we only provide one method but others work in
## the same way.
## In this example, we will show how to get the
## new decision table as well
##########################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$hiring.dt

########## using fuzzy lower approximation ##############
control &lt;- list(type.aggregation = c("t.tnorm", "lukasiewicz"),
               t.implicator = "lukasiewicz", type.relation = c("tolerance", "eq.1"))
reduct.1 &lt;- FS.quickreduct.FRST(decision.table, type.method = "fuzzy.dependency",
                            type.QR = "fuzzy.QR", control = control)

## get new decision table based on reduct
new.decTable &lt;- SF.applyDecTable(decision.table, reduct.1)

</code></pre>

<hr>
<h2 id='FS.quickreduct.RST'>QuickReduct algorithm based on RST</h2><span id='topic+FS.quickreduct.RST'></span>

<h3>Description</h3>

<p>This is a function for implementing the QuickReduct algorithm for feature selection based
on RST proposed by (Shen and Chouchoulas, 2000). The algorithm produces only one feature subset that could be a superreduct.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FS.quickreduct.RST(decision.table, control = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FS.quickreduct.RST_+3A_decision.table">decision.table</code></td>
<td>
<p>an object of a <code>"DecisionTable"</code> class representing a decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="FS.quickreduct.RST_+3A_control">control</code></td>
<td>
<p>other parameters. It contains the following component:
</p>

<ul>
<li> <p><code>randomize</code>: it has a boolean value. For the detailed description, see in Section <code>Details</code>.
The default value is <code>FALSE</code>.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>This algorithm considers the dependency degree (see <code><a href="#topic+Introduction-RoughSets">Introduction-RoughSets</a></code>)
of the addition of each attribute to the current reduct candidate. Then the best candidate will be chosen.
This process continues until the dependency of the subset equals to the dependency of the full dataset.
</p>
<p>Additionally, in <code>control</code> parameter, we provide one component which is
<code>randomize</code>. It has a boolean value: <code>TRUE</code> or <code>FALSE</code> that means we want to perform
quickreduct by evaluating attributes randomly or all attributes in decision table.
</p>
<p>It should be noted that this function does not give the new decision table directly.
The other additional function called <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code> is used to produce new decision table based on
information about the reduct from this function.
</p>


<h3>Value</h3>

<p>A class <code>"FeatureSubset"</code> that contains the following components:
</p>

<ul>
<li> <p><code>reduct</code>: a list representing single reduct. In this case, it could be super reduct or just subset of feature.
</p>
</li>
<li> <p><code>type.method</code>: a string representing a type of method which is <code>"quickreduct"</code>.
</p>
</li>
<li> <p><code>type.task</code>: a string showing type of task which is <code>"feature selection"</code>.
</p>
</li>
<li> <p><code>model</code>: a string representing a type of model. In this case, it is <code>"RST"</code> which means rough set theory.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>References</h3>

<p>Q. Shen and A. Chouchoulas, &quot;A Modular Approach to Generating Fuzzy Rules with Reduced Attributes for the Monitoring of Complex Systems&quot;,
Engineering Applications of Artificial Intelligence, vol. 13, p. 263 - 278 (2000).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+FS.quickreduct.FRST">FS.quickreduct.FRST</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###################################################
## Example 1: Evaluate reduct and generate
##            new decision table
###################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$hiring.dt

## evaluate single reduct
res.1 &lt;- FS.quickreduct.RST(decision.table)

## generate new decision table according to the reduct
new.decTable &lt;- SF.applyDecTable(decision.table, res.1)

</code></pre>

<hr>
<h2 id='FS.reduct.computation'>The reduct computation methods based on RST and FRST</h2><span id='topic+FS.reduct.computation'></span>

<h3>Description</h3>

<p>This function is a wrapper for computing different types of decision reducts
and approximate decision reducts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FS.reduct.computation(decision.table, method = "greedy.heuristic", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FS.reduct.computation_+3A_decision.table">decision.table</code></td>
<td>
<p>an object of a <code>"DecisionTable"</code> class representing a decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="FS.reduct.computation_+3A_method">method</code></td>
<td>
<p>a character representing the type of computation method to use. See in Section <code>Details</code>.</p>
</td></tr>
<tr><td><code id="FS.reduct.computation_+3A_...">...</code></td>
<td>
<p>other parameters. See the parameters of <code><a href="#topic+FS.greedy.heuristic.reduct.RST">FS.greedy.heuristic.reduct.RST</a></code>, <code><a href="#topic+FS.DAAR.heuristic.RST">FS.DAAR.heuristic.RST</a></code>,
<code><a href="#topic+FS.nearOpt.fvprs.FRST">FS.nearOpt.fvprs.FRST</a></code> and <code><a href="#topic+FS.permutation.heuristic.reduct.RST">FS.permutation.heuristic.reduct.RST</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The implemented methods include the following approaches:
</p>

<ul>
<li> <p><code>"greedy.heuristic"</code>: a greedy heuristic method for computation of decision reducts (or approximate decision reducts) based on RST.
See <code><a href="#topic+FS.greedy.heuristic.reduct.RST">FS.greedy.heuristic.reduct.RST</a></code>.
</p>
</li>
<li> <p><code>"DAAR.heuristic"</code>: Dynamically Adapted Approximate Reduct heuristic, which is a modification of the greedy heuristic with a random probe test to avoid inclusion of irrelevant attributes to the reduct.
See <code><a href="#topic+FS.DAAR.heuristic.RST">FS.DAAR.heuristic.RST</a></code>.
</p>
</li>
<li> <p><code>"nearOpt.fvprs"</code>: the near-optimal reduction algorithm based on FRST.
See <code><a href="#topic+FS.nearOpt.fvprs.FRST">FS.nearOpt.fvprs.FRST</a></code>.
</p>
</li>
<li> <p><code>"permutation.heuristic"</code>: a permutation-based elimination heuristic for computation of decision reducts based on RST.
See <code><a href="#topic+FS.permutation.heuristic.reduct.RST">FS.permutation.heuristic.reduct.RST</a></code>.
</p>
</li></ul>

<p>Those methods can be selected by setting the parameter <code>method</code>.
Additionally, <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code> has been provided to generate a new decision table.
</p>


<h3>Value</h3>

<p>An object of a class <code>"FeatureSubset"</code>. See <code><a href="#topic+FS.greedy.heuristic.reduct.RST">FS.greedy.heuristic.reduct.RST</a></code>,
<code><a href="#topic+FS.DAAR.heuristic.RST">FS.DAAR.heuristic.RST</a></code>, <code><a href="#topic+FS.permutation.heuristic.reduct.RST">FS.permutation.heuristic.reduct.RST</a></code> or
<code><a href="#topic+FS.nearOpt.fvprs.FRST">FS.nearOpt.fvprs.FRST</a></code> for more details.
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>See Also</h3>

<p><code><a href="#topic+D.discretization.RST">D.discretization.RST</a></code>, <code><a href="#topic+BC.LU.approximation.RST">BC.LU.approximation.RST</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##############################################################
## Example 1: generate reduct and new decision table
## using RST and FRST
##############################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$hiring.dt

## generate a single reduct using RST
reduct.1 &lt;- FS.reduct.computation(decision.table, method = "greedy.heuristic")

## generate a single reduct using FRST
reduct.2 &lt;- FS.reduct.computation(decision.table, method = "nearOpt.fvprs")

## generate a new decision table using reduct.1
new.decTable.1 &lt;- SF.applyDecTable(decision.table, reduct.1)

## generate new decision table using reduct.2
new.decTable.2 &lt;- SF.applyDecTable(decision.table, reduct.2)

</code></pre>

<hr>
<h2 id='IS.FRIS.FRST'>The fuzzy rough instance selection algorithm</h2><span id='topic+IS.FRIS.FRST'></span>

<h3>Description</h3>

<p>This is a function that implements the fuzzy-rough instance selection (FRIS) proposed by  
(Jensen and Cornelis, 2010) which is used to perform instance selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IS.FRIS.FRST(decision.table, control = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IS.FRIS.FRST_+3A_decision.table">decision.table</code></td>
<td>
<p>a <code>"DecisionTable"</code> class representing the decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="IS.FRIS.FRST_+3A_control">control</code></td>
<td>
<p>a list of other parameters which are 
</p>

<ul>
<li> <p><code>threshold.tau</code>: a value determining whether an object can be removed or not. 
The object can be removed if it is less than the threshold. The default value is 0.95.
</p>
</li>
<li> <p><code>alpha</code>: a parameter determining the granularity of the fuzzy similarity measure, which has positive values (&gt;= 0). The default value is 1.
</p>
</li>
<li> <p><code>type.aggregation</code>: a list representing the type of aggregation and its value. 
The default value is <code>type.aggregation = c("t.tnorm", "lukasiewicz")</code>. See <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code>.
</p>
</li>
<li> <p><code>t.implicator</code>: a string representing the value of implicator function. The default value is <code>"lukasiewicz"</code>. See <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>FRIS is used to remove training instances that cause conflicts with other instances as 
determined by the fuzzy positive region. 
</p>
<p>This algorithm evaluates the degree of membership of each instance to the fuzzy positive region.
If there is a instance less than the threshold, then the instance can be removed. 
Additionally, it uses a fuzzy indiscernibility relation <code class="reqn">R_a</code> to express the approximate equality between 
objects <code class="reqn">x</code> and <code class="reqn">y</code> on attribute <code class="reqn">a</code> in the training set:
</p>
<p><code class="reqn">R_{a}^{\alpha}(x,y)=max(0, 1 - \alpha \frac{|a(x) - a(y)|}{l(a)})</code>
</p>
<p>where parameter <code class="reqn">\alpha</code> (<code class="reqn">\alpha \ge 0</code>) determines the granularity of <code class="reqn">R_{a}^{\alpha}</code>.
Then, the fuzzy <code class="reqn">B</code>-indiscernibility relation, fuzzy lower approximation, positive region and degree of dependency are calculated based on 
the concept in <code><a href="#topic+Introduction-FuzzyRoughSets">Introduction-FuzzyRoughSets</a></code>. 
</p>
<p>It should be noted that this function does not give the new decision table directly. 
The other additional function called <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code> is used to produce the new decision table based on 
the output of this function.
</p>


<h3>Value</h3>

<p>A class <code>"InstanceSelection"</code> that contains the following components:
</p>

<ul>
<li> <p><code>indx.objects</code>: it contains all indexes of objects that are selected. 
</p>
</li>
<li> <p><code>type.method</code>: a string representing the type of method. In this case, it is <code>"IS.FRIS"</code>.
</p>
</li>
<li> <p><code>type.task</code>: a string showing the type of task which is <code>"instance selection"</code>.
</p>
</li>
<li> <p><code>type.model</code>: a string representing the type of model which is <code>"FRST"</code>. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>References</h3>

<p>R. Jensen and C. Cornelis, &quot;Fuzzy-rough Instance Selection&quot;,
Proceedings of the 19th International Conference on Fuzzy Systems (FUZZ-IEEE 2010), 
p. 1776 - 1782 (2010).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+IS.FRPS.FRST">IS.FRPS.FRST</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################
## Example: Evaluate instances/objects and
##          generate new decision table
#############################################
dt.ex1 &lt;- data.frame(c(0.1, 0.5, 0.2, 0.3, 0.2, 0.2, 0.8), 
                  c(0.1, 0.1, 0.4, 0.2, 0.4, 0.4, 0.5), c(0, 0, 0, 0, 1, 1, 1))
colnames(dt.ex1) &lt;- c("a1", "a2", "d")
decision.table &lt;- SF.asDecisionTable(dataset = dt.ex1, decision.attr = 3, indx.nominal = c(3))

## evaluate index of objects
res.1 &lt;- IS.FRIS.FRST(decision.table = decision.table, control = 
                        list(threshold.tau = 0.5, alpha = 0.8, 
                        type.aggregation = c("t.tnorm", "lukasiewicz"), 
                        t.implicator = "lukasiewicz"))

## generate new decision table
new.decTable &lt;- SF.applyDecTable(decision.table, res.1)

</code></pre>

<hr>
<h2 id='IS.FRPS.FRST'>The fuzzy rough prototype selection method</h2><span id='topic+IS.FRPS.FRST'></span>

<h3>Description</h3>

<p>This is a function for implementing instance selection using prototype selection method (FRPS) proposed by (Verbiest et al, 2013).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IS.FRPS.FRST(decision.table, type.alpha = "FRPS.1")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IS.FRPS.FRST_+3A_decision.table">decision.table</code></td>
<td>
<p>a <code>"DecisionTable"</code> class representing the decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="IS.FRPS.FRST_+3A_type.alpha">type.alpha</code></td>
<td>
<p>type of FRPS expressing the equations of <code class="reqn">\alpha</code>. The default value is <code>"FRPS.1"</code>.
See Section <code>Details</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This algorithm uses prototype selection (PS) to improve the accuracy of the k-nearest neighbour (kNN) method. 
It selects a subset of instances <code class="reqn">S \subseteq X</code> and then classifies a new instance <code class="reqn">t</code> using the kNN rule acting over
<code class="reqn">S</code> instead of over <code class="reqn">X</code>. Based on fuzzy rough set theory, <code class="reqn">S</code> is built. Basically, two steps are performed in the algorithm.
First, the instances are ordered according to a measure called <code class="reqn">\alpha</code> which is based on fuzzy rough set theory that evaluates the lack of 
predictive ability of the instances, and the instances for which the values exceeds a certain threshold are removed from training set.
To determine this threshold, we consider several equations which are applied on all instances. 
These equations are constructed by considering fuzzy positive region membership degree on several implication and t-norm operators.
The following is the equations of <code class="reqn">\alpha</code>:
</p>

<ul>
<li> <p><code>"FRPS.1"</code>: <code class="reqn">max_{y \notin [x]_{d}} \frac{1}{max_{i=1}^{m} \delta_{a_i}(x,y)}</code>
</p>
</li>
<li> <p><code>"FRPS.2"</code>: <code class="reqn">OW A_w \left(\frac{1}{OW A_w \delta_{a_i}(x,y)}\right)</code>
</p>
</li>
<li> <p><code>"FRPS.3"</code>: <code class="reqn">max_{y \notin [x]_{d}} \frac{1}{\displaystyle\sum\limits_{i=1}^m {\delta_{a_i}(x,y)}}</code>
</p>
</li>
<li> <p><code>"FRPS.4"</code>: <code class="reqn">OW A_w \left(\frac{1}{\displaystyle\sum\limits_{i=1}^m {\delta_{a_i}(x,y)}}\right)</code>
</p>
</li></ul>

<p>where <code class="reqn">[x]_d</code> and <code class="reqn">OW A_w</code> are equivalence class on the decision attribute and ordered weighted average operator, respectively.
And <code class="reqn">\delta_{a_i}(x,y)</code> is a distance measure of the attribute <code class="reqn">a_i</code> between <code class="reqn">x</code> and <code class="reqn">y</code>.
After that, <code>1knn</code> will be performed in order to select and get prototype <code class="reqn">S</code> which produces the highest training accuracy.
</p>
<p>It should be noted that this function does not give the new decision table directly. 
The other additional function called <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code> is used to produce new decision table based on 
the output of this function.
</p>


<h3>Value</h3>

<p>A class <code>"InstanceSelection"</code> that contains the following components:
</p>

<ul>
<li> <p><code>indx.objects</code>: it contains all indexes of objects that are selected. 
</p>
</li>
<li> <p><code>type.method</code>: a string representing a type of method. In this case, it is <code>"IS.FRPS"</code>.
</p>
</li>
<li> <p><code>type.task</code>: a string showing the type of task which is <code>"instance selection"</code>.
</p>
</li>
<li> <p><code>type.model</code>: a string representing the type of model which is <code>"FRST"</code>. It means fuzzy rough set theory.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>References</h3>

<p>N. Verbiest, C. Cornelis, and F. Herrera, &quot;A Fuzzy Rough Prototype Selection Method&quot;, 
Pattern Recognition, Vol. 46, no. 10, p. 2770 - 2782 (2013).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+IS.FRIS.FRST">IS.FRIS.FRST</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################
## Example: Evaluate instances/objects and
## generate new decision table
#############################################
dt.ex1 &lt;- data.frame(c(0.5, 0.2, 0.3, 0.7, 0.2, 0.2), c(0.1, 0.4, 0.2, 0.8, 0.4, 0.4), 
                      c(0, 0, 0, 1, 1, 1))
colnames(dt.ex1) &lt;- c("a1", "a2", "d")
decision.table &lt;- SF.asDecisionTable(dataset = dt.ex1, decision.attr = 3, indx.nominal = c(3))

## evaluate instances
res.1 &lt;- IS.FRPS.FRST(decision.table, type.alpha = "FRPS.3")

## generate new decision table
new.decTable &lt;- SF.applyDecTable(decision.table, res.1)
</code></pre>

<hr>
<h2 id='MV.conceptClosestFit'>Concept Closest Fit</h2><span id='topic+MV.conceptClosestFit'></span>

<h3>Description</h3>

<p>It is used for handling missing values based on the concept closest fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MV.conceptClosestFit(decision.table)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MV.conceptClosestFit_+3A_decision.table">decision.table</code></td>
<td>
<p>a <code>"DecisionTable"</code> class representing a decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>. 
Note: missing values are recognized as NA.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method is similar to the global closest fit method. The difference is
that the original data set, containing missing attribute values, is first split into
smaller data sets, each smaller data set corresponds to a concept from the original
data set. More precisely, every smaller data set is constructed from one of
the original concepts, by restricting cases to the concept.
</p>


<h3>Value</h3>

<p>A class <code>"MissingValue"</code>. See <code><a href="#topic+MV.missingValueCompletion">MV.missingValueCompletion</a></code>.
</p>


<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>References</h3>

<p>J. Grzymala-Busse and W. Grzymala-Busse, &quot;Handling Missing Attribute Values,&quot; in Data Mining and Knowledge Discovery Handbook, 
O. Maimon and L. Rokach, Eds. New York : Springer, 2010, pp. 33-51
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MV.missingValueCompletion">MV.missingValueCompletion</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################
## Example: Concept Closest Fit
#############################################
dt.ex1 &lt;- data.frame(
     c(100.2, 102.6, NA, 99.6, 99.8, 96.4, 96.6, NA), 
     c(NA, "yes", "no", "yes", NA, "yes", "no", "yes"), 
     c("no", "yes", "no", "yes", "yes", "no", "yes", NA),
     c("yes", "yes", "no", "yes", "no", "no", "no", "yes"))
colnames(dt.ex1) &lt;- c("Temp", "Headache", "Nausea", "Flu")
decision.table &lt;- SF.asDecisionTable(dataset = dt.ex1, decision.attr = 4, 
                                    indx.nominal = c(2:4))
indx = MV.conceptClosestFit(decision.table)
</code></pre>

<hr>
<h2 id='MV.deletionCases'>Missing value completion by deleting instances</h2><span id='topic+MV.deletionCases'></span>

<h3>Description</h3>

<p>It is used for handling missing values by deleting instances. It should be noted that the output of the function is <code>val.NA</code> 
which contains indices of missing values and their values (i.e., NA). Therefore, in order to generate a new decision table (dataset) 
the user need to execute <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MV.deletionCases(decision.table)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MV.deletionCases_+3A_decision.table">decision.table</code></td>
<td>
<p>a <code>"DecisionTable"</code> class representing a decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>. 
Note: missing values are recognized as NA.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A class <code>"MissingValue"</code>. See <code><a href="#topic+MV.missingValueCompletion">MV.missingValueCompletion</a></code>.
</p>


<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>References</h3>

<p>J. Grzymala-Busse and W. Grzymala-Busse, &quot;Handling Missing Attribute Values,&quot; in Data Mining and Knowledge Discovery Handbook, 
O. Maimon and L. Rokach, Eds. New York : Springer, 2010, pp. 33-51
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MV.missingValueCompletion">MV.missingValueCompletion</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################
## Example : Deletion Cases
#############################################
dt.ex1 &lt;- data.frame(
     c("high", "very_high", NA, "high", "high", "normal", "normal", NA), 
     c(NA, "yes", "no", "yes", NA, "yes", "no", "yes"), 
     c("no", "yes", "no", "yes", "yes", "no", "yes", NA),
     c("yes", "yes", "no", "yes", "no", "no", "no", "yes"))
colnames(dt.ex1) &lt;- c("Temp", "Headache", "Nausea", "Flu")
decision.table &lt;- SF.asDecisionTable(dataset = dt.ex1, decision.attr = 4, 
                                    indx.nominal = c(1:4))
indx = MV.deletionCases(decision.table)
</code></pre>

<hr>
<h2 id='MV.globalClosestFit'>Global Closest Fit</h2><span id='topic+MV.globalClosestFit'></span>

<h3>Description</h3>

<p>It is used for handling missing values based on the global closest fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MV.globalClosestFit(decision.table)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MV.globalClosestFit_+3A_decision.table">decision.table</code></td>
<td>
<p>a <code>"DecisionTable"</code> class representing a decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>. 
Note: missing values are recognized as NA.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The global closes fit method is based on replacing
a missing attribute value by the known value in another case that resembles
as much as possible the case with the missing attribute value. In searching
for the closest fit case we compare two vectors of attribute values, one vector
corresponds to the case with a missing attribute value, the other vector is a candidate
for the closest fit. The search is conducted for all cases, hence the name
global closest fit. For each case a distance is computed, the case for which the
distance is the smallest is the closest fitting case that is used to determine the
missing attribute value.
</p>


<h3>Value</h3>

<p>A class <code>"MissingValue"</code>. See <code><a href="#topic+MV.missingValueCompletion">MV.missingValueCompletion</a></code>.
</p>


<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>References</h3>

<p>J. Grzymala-Busse and W. Grzymala-Busse, &quot;Handling Missing Attribute Values,&quot; in Data Mining and Knowledge Discovery Handbook, 
O. Maimon and L. Rokach, Eds. New York : Springer, 2010, pp. 33-51
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MV.missingValueCompletion">MV.missingValueCompletion</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################
## Example: Global Closest Fit
#############################################
dt.ex1 &lt;- data.frame(
     c(100.2, 102.6, NA, 99.6, 99.8, 96.4, 96.6, NA), 
     c(NA, "yes", "no", "yes", NA, "yes", "no", "yes"), 
     c("no", "yes", "no", "yes", "yes", "no", "yes", NA),
     c("yes", "yes", "no", "yes", "no", "no", "no", "yes"))
colnames(dt.ex1) &lt;- c("Temp", "Headache", "Nausea", "Flu")
decision.table &lt;- SF.asDecisionTable(dataset = dt.ex1, decision.attr = 4, 
                                    indx.nominal = c(2:4))
indx = MV.globalClosestFit(decision.table)
</code></pre>

<hr>
<h2 id='MV.missingValueCompletion'>Wrapper function of missing value completion</h2><span id='topic+MV.missingValueCompletion'></span>

<h3>Description</h3>

<p>It is a wrapper function for missing value completion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MV.missingValueCompletion(decision.table, type.method = "deletionCases")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MV.missingValueCompletion_+3A_decision.table">decision.table</code></td>
<td>
<p>a <code>"DecisionTable"</code> class representing a decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>. 
Note: missing values are recognized as NA.</p>
</td></tr>
<tr><td><code id="MV.missingValueCompletion_+3A_type.method">type.method</code></td>
<td>
<p>one of the following methods:
</p>

<ul>
<li> <p><code>"deletionCases"</code>: See <code><a href="#topic+MV.deletionCases">MV.deletionCases</a></code>.
</p>
</li>
<li> <p><code>"mostCommonValResConcept"</code>: See <code><a href="#topic+MV.mostCommonValResConcept">MV.mostCommonValResConcept</a></code>.
</p>
</li>
<li> <p><code>"mostCommonVal"</code>: See <code><a href="#topic+MV.mostCommonVal">MV.mostCommonVal</a></code>.
</p>
</li>
<li> <p><code>"globalClosestFit"</code>: See <code><a href="#topic+MV.globalClosestFit">MV.globalClosestFit</a></code>.
</p>
</li>
<li> <p><code>"conceptClosestFit"</code>: See <code><a href="#topic+MV.conceptClosestFit">MV.conceptClosestFit</a></code>.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>A class <code>"MissingValue"</code> which contains
</p>

<ul>
<li> <p><code>val.NA</code>: a matrix containing indices of missing value (i.e., unknown values) positions and their values.
</p>
</li>
<li> <p><code>type.method</code>: a string showing the type of used method. In this case, it is <code>"deleteCases"</code>. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>References</h3>

<p>J. Grzymala-Busse and W. Grzymala-Busse, &quot;Handling Missing Attribute Values,&quot; in Data Mining and Knowledge Discovery Handbook, 
O. Maimon and L. Rokach, Eds. New York : Springer, 2010, pp. 33-51
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MV.deletionCases">MV.deletionCases</a></code>, <code><a href="#topic+MV.mostCommonValResConcept">MV.mostCommonValResConcept</a></code>, <code><a href="#topic+MV.mostCommonVal">MV.mostCommonVal</a></code>,
<code><a href="#topic+MV.globalClosestFit">MV.globalClosestFit</a></code>, and <code><a href="#topic+MV.conceptClosestFit">MV.conceptClosestFit</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################
## Example : 
#############################################
dt.ex1 &lt;- data.frame(
     c(100.2, 102.6, NA, 99.6, 99.8, 96.4, 96.6, NA), 
     c(NA, "yes", "no", "yes", NA, "yes", "no", "yes"), 
     c("no", "yes", "no", "yes", "yes", "no", "yes", NA),
     c("yes", "yes", "no", "yes", "no", "no", "no", "yes"))
colnames(dt.ex1) &lt;- c("Temp", "Headache", "Nausea", "Flu")
decision.table &lt;- SF.asDecisionTable(dataset = dt.ex1, decision.attr = 4, 
                                    indx.nominal = c(2:4))
indx = MV.missingValueCompletion(decision.table, type.method = "deletionCases")

## generate new decision table
new.decTable &lt;- SF.applyDecTable(decision.table, indx)
</code></pre>

<hr>
<h2 id='MV.mostCommonVal'>Replacing missing attribute values by the attribute mean or common values</h2><span id='topic+MV.mostCommonVal'></span>

<h3>Description</h3>

<p>It is used for handling missing values by replacing the attribute mean or common values. If an attributes containing missing values is continuous/real, the method uses mean of the attribute instead of the most common value.
In order to generate a new decision table, we need to execute <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MV.mostCommonVal(decision.table)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MV.mostCommonVal_+3A_decision.table">decision.table</code></td>
<td>
<p>a <code>"DecisionTable"</code> class representing a decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>. 
Note: missing values are recognized as NA.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A class <code>"MissingValue"</code>. See <code><a href="#topic+MV.missingValueCompletion">MV.missingValueCompletion</a></code>.
</p>


<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>References</h3>

<p>J. Grzymala-Busse and W. Grzymala-Busse, &quot;Handling Missing Attribute Values,&quot; in Data Mining and Knowledge Discovery Handbook, 
O. Maimon and L. Rokach, Eds. New York : Springer, 2010, pp. 33-51
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MV.missingValueCompletion">MV.missingValueCompletion</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################
## Example: Replacing missing attribute values
##          by the attribute mean/common values
#############################################
dt.ex1 &lt;- data.frame(
     c(100.2, 102.6, NA, 99.6, 99.8, 96.4, 96.6, NA), 
     c(NA, "yes", "no", "yes", NA, "yes", "no", "yes"), 
     c("no", "yes", "no", "yes", "yes", "no", "yes", NA),
     c("yes", "yes", "no", "yes", "no", "no", "no", "yes"))
colnames(dt.ex1) &lt;- c("Temp", "Headache", "Nausea", "Flu")
decision.table &lt;- SF.asDecisionTable(dataset = dt.ex1, decision.attr = 4, 
                                    indx.nominal = c(2:4))
indx = MV.mostCommonVal(decision.table)
</code></pre>

<hr>
<h2 id='MV.mostCommonValResConcept'>The most common value or mean of an attribute restricted to a concept</h2><span id='topic+MV.mostCommonValResConcept'></span>

<h3>Description</h3>

<p>It is used for handling missing values by assigning the most common value of an attribute restricted to a concept. 
If an attributes containing missing values is continuous/real, the method uses mean of the attribute instead of the most common value.
In order to generate a new decision table, we need to execute <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MV.mostCommonValResConcept(decision.table)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MV.mostCommonValResConcept_+3A_decision.table">decision.table</code></td>
<td>
<p>a <code>"DecisionTable"</code> class representing a decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>. 
Note: missing values are recognized as NA.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A class <code>"MissingValue"</code>. See <code><a href="#topic+MV.missingValueCompletion">MV.missingValueCompletion</a></code>.
</p>


<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>References</h3>

<p>J. Grzymala-Busse and W. Grzymala-Busse, &quot;Handling Missing Attribute Values,&quot; in Data Mining and Knowledge Discovery Handbook, 
O. Maimon and L. Rokach, Eds. New York : Springer, 2010, pp. 33-51
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MV.missingValueCompletion">MV.missingValueCompletion</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################
## Example: The most common value
#############################################
dt.ex1 &lt;- data.frame(
     c(100.2, 102.6, NA, 99.6, 99.8, 96.4, 96.6, NA), 
     c(NA, "yes", "no", "yes", NA, "yes", "no", "yes"), 
     c("no", "yes", "no", "yes", "yes", "no", "yes", NA),
     c("yes", "yes", "no", "yes", "no", "no", "no", "yes"))
colnames(dt.ex1) &lt;- c("Temp", "Headache", "Nausea", "Flu")
decision.table &lt;- SF.asDecisionTable(dataset = dt.ex1, decision.attr = 4, 
                                    indx.nominal = c(2:4))
indx = MV.mostCommonValResConcept(decision.table)
</code></pre>

<hr>
<h2 id='predict.RuleSetFRST'>The predicting function for rule induction methods based on FRST</h2><span id='topic+predict.RuleSetFRST'></span><span id='topic+predict.FRST'></span>

<h3>Description</h3>

<p>It is a function used to obtain predicted values after obtaining rules by using rule induction methods.
We have provided the functions <code><a href="#topic+RI.GFRS.FRST">RI.GFRS.FRST</a></code> and <code><a href="#topic+RI.hybridFS.FRST">RI.hybridFS.FRST</a></code> to generate rules based on FRST.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'RuleSetFRST'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.RuleSetFRST_+3A_object">object</code></td>
<td>
<p>a <code>"RuleSetFRST"</code> class resulted by <code><a href="#topic+RI.GFRS.FRST">RI.GFRS.FRST</a></code> and <code><a href="#topic+RI.hybridFS.FRST">RI.hybridFS.FRST</a></code>.</p>
</td></tr>
<tr><td><code id="predict.RuleSetFRST_+3A_newdata">newdata</code></td>
<td>
<p>a <code>"DecisionTable"</code> class containing a data frame or matrix (m x n) of data for the prediction process, where m is the number of instances and
n is the number of input attributes. It should be noted that this data must have <code>colnames</code> on each attributes.</p>
</td></tr>
<tr><td><code id="predict.RuleSetFRST_+3A_...">...</code></td>
<td>
<p>the other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The predicted values.
</p>


<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RI.indiscernibilityBasedRules.RST">RI.indiscernibilityBasedRules.RST</a></code>, <code><a href="#topic+RI.GFRS.FRST">RI.GFRS.FRST</a></code> and <code><a href="#topic+RI.hybridFS.FRST">RI.hybridFS.FRST</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##############################################
## Example: Classification Task
##############################################
data(RoughSetData)
decision.table &lt;- RoughSetData$pima7.dt

## using RI.hybrid.FRST for generating rules
control &lt;- list(type.aggregation = c("t.tnorm", "lukasiewicz"),
           type.relation = c("tolerance", "eq.1"), t.implicator = "lukasiewicz")
rules.hybrid &lt;- RI.hybridFS.FRST(decision.table, control)

## in this case, we are using the same data set as the training data
res.1 &lt;- predict(rules.hybrid, decision.table[, -ncol(decision.table)])

## using RI.GFRS.FRST for generating rules
control &lt;- list(alpha.precision = 0.01, type.aggregation = c("t.tnorm", "lukasiewicz"),
                type.relation = c("tolerance", "eq.3"), t.implicator = "lukasiewicz")
rules.gfrs &lt;- RI.GFRS.FRST(decision.table, control)

## in this case, we are using the same data set as the training data
res.2 &lt;- predict(rules.gfrs, decision.table[, -ncol(decision.table)])

##############################################
## Example: Regression Task
##############################################
data(RoughSetData)
decision.table &lt;- RoughSetData$housing7.dt

## using RI.hybrid.FRST for generating rules
control &lt;- list(type.aggregation = c("t.tnorm", "lukasiewicz"),
           type.relation = c("tolerance", "eq.1"), t.implicator = "lukasiewicz")
rules &lt;- RI.hybridFS.FRST(decision.table, control)

## in this case, we are using the same data set as the training data
res.1 &lt;- predict(rules, decision.table[, -ncol(decision.table)])

</code></pre>

<hr>
<h2 id='predict.RuleSetRST'>Prediction of decision classes using rule-based classifiers.</h2><span id='topic+predict.RuleSetRST'></span><span id='topic+predict.RST'></span>

<h3>Description</h3>

<p>The prediction method for objects inheriting from the <code>RuleSetRST</code> class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'RuleSetRST'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.RuleSetRST_+3A_object">object</code></td>
<td>
<p>an object inheriting from the <code>"RuleSetRST"</code> class. Such objects are typically produced
by implementations of rule induction methods, which derives from the rough set theory (RST), such as
<code><a href="#topic+RI.indiscernibilityBasedRules.RST">RI.indiscernibilityBasedRules.RST</a></code>, <code><a href="#topic+RI.CN2Rules.RST">RI.CN2Rules.RST</a></code>,
<code><a href="#topic+RI.LEM2Rules.RST">RI.LEM2Rules.RST</a></code> or <code><a href="#topic+RI.AQRules.RST">RI.AQRules.RST</a></code>.</p>
</td></tr>
<tr><td><code id="predict.RuleSetRST_+3A_newdata">newdata</code></td>
<td>
<p>an object inheriting from the <code>"DecisionTable"</code> class, which represents the data
for which predictions are to be made. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>. Columns in <code>newdata</code>
should correspond to columns of a data set used for the rule induction.</p>
</td></tr>
<tr><td><code id="predict.RuleSetRST_+3A_...">...</code></td>
<td>
<p>additional parameters for a rule voting strategy. It can be applied only to the methods which classify
new objects by voting. Currently, those methods include <code><a href="#topic+RI.LEM2Rules.RST">RI.LEM2Rules.RST</a></code> and
<code><a href="#topic+RI.AQRules.RST">RI.AQRules.RST</a></code> which accept a named parameter <code>votingMethod</code>. This parameter can be used
to pass a custom function for computing a weight of a voting rule. There are three such functions already
available in the package:
</p>

<ul>
<li> <p><code>X.ruleStrength</code> is the default voting method. It is defined as a product of a cardinality
of a support of a rule and the length of this rule. See <code><a href="#topic+X.ruleStrength">X.ruleStrength</a></code>.
</p>
</li>
<li> <p><code>X.laplace</code> corresponds to a voting weighted by the Laplace estimates of rules' confidence.
See <code><a href="#topic+X.laplace">X.laplace</a></code>.
</p>
</li>
<li> <p><code>X.rulesCounting</code> corresponds to voting by counting the matching rules for different decision
classes. See <code><a href="#topic+X.rulesCounting">X.rulesCounting</a></code>.
</p>
</li></ul>

<p>A custom function passed using the <code>votingMethod</code> can get additional parameters using the <code>...</code>
interface.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame with a single column containing predictions for objects from <code>newdata</code>.
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>See Also</h3>

<p>Rule induction methods implemented within RST include: <code><a href="#topic+RI.indiscernibilityBasedRules.RST">RI.indiscernibilityBasedRules.RST</a></code>,
<code><a href="#topic+RI.CN2Rules.RST">RI.CN2Rules.RST</a></code>, <code><a href="#topic+RI.LEM2Rules.RST">RI.LEM2Rules.RST</a></code> and <code><a href="#topic+RI.AQRules.RST">RI.AQRules.RST</a></code>.
For details on rule induction methods based on FRST see <code><a href="#topic+RI.GFRS.FRST">RI.GFRS.FRST</a></code> and <code><a href="#topic+RI.hybridFS.FRST">RI.hybridFS.FRST</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##############################################
## Example: Classification Task
##############################################
data(RoughSetData)
wine.data &lt;- RoughSetData$wine.dt
set.seed(13)
wine.data &lt;- wine.data[sample(nrow(wine.data)),]

## Split the data into a training set and a test set,
## 60% for training and 40% for testing:
idx &lt;- round(0.6 * nrow(wine.data))
wine.tra &lt;-SF.asDecisionTable(wine.data[1:idx,],
                              decision.attr = 14,
                              indx.nominal = 14)
wine.tst &lt;- SF.asDecisionTable(wine.data[(idx+1):nrow(wine.data), -ncol(wine.data)])

true.classes &lt;- wine.data[(idx+1):nrow(wine.data), ncol(wine.data)]

## discretization:
cut.values &lt;- D.discretization.RST(wine.tra,
                                   type.method = "unsupervised.quantiles",
                                   nOfIntervals = 3)
data.tra &lt;- SF.applyDecTable(wine.tra, cut.values)
data.tst &lt;- SF.applyDecTable(wine.tst, cut.values)

## rule induction from the training set:
rules &lt;- RI.LEM2Rules.RST(data.tra)

## predicitons for the test set:
pred.vals1 &lt;- predict(rules, data.tst)
pred.vals2 &lt;- predict(rules, data.tst,
                      votingMethod = X.laplace)
pred.vals3 &lt;- predict(rules, data.tst,
                      votingMethod = X.rulesCounting)

## checking the accuracy of predictions:
mean(pred.vals1 == true.classes)
mean(pred.vals2 == true.classes)
mean(pred.vals3 == true.classes)

</code></pre>

<hr>
<h2 id='print.FeatureSubset'>The print method of FeatureSubset objects</h2><span id='topic+print.FeatureSubset'></span>

<h3>Description</h3>

<p>This is a print method for FeatureSubset objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'FeatureSubset'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.FeatureSubset_+3A_x">x</code></td>
<td>
<p>an object inheriting from <code>"FeatureSubset"</code> class. See <code><a href="#topic+FS.reduct.computation">FS.reduct.computation</a></code>.</p>
</td></tr>
<tr><td><code id="print.FeatureSubset_+3A_...">...</code></td>
<td>
<p>parameters passes to other functions (currently omitted).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Prints its argument and returns it invisibly.
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###########################################################
## Example : Computation of a decision reduct
###########################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$hiring.dt

res.1 &lt;- FS.reduct.computation(decision.table)
print(res.1)
</code></pre>

<hr>
<h2 id='print.RuleSetRST'>The print function for RST rule sets</h2><span id='topic+print.RuleSetRST'></span>

<h3>Description</h3>

<p>A print method for RuleSetRST objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'RuleSetRST'
print(x, howMany = min(10, length(x)), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.RuleSetRST_+3A_x">x</code></td>
<td>
<p>a <code>"RuleSetRST"</code> object. See <code><a href="#topic+RI.LEM2Rules.RST">RI.LEM2Rules.RST</a></code>.</p>
</td></tr>
<tr><td><code id="print.RuleSetRST_+3A_howmany">howMany</code></td>
<td>
<p>an integer giving the number of rules to be printed.
The default is minimum from 10 and the total number of rules in the set.</p>
</td></tr>
<tr><td><code id="print.RuleSetRST_+3A_...">...</code></td>
<td>
<p>the other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>prints its argument and returns it invisibly
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###########################################################
## Example : Printing of a decision rule set problem
###########################################################
data(RoughSetData)
hiring.data &lt;- RoughSetData$hiring.dt

rules &lt;- RI.LEM2Rules.RST(hiring.data)

rules             # all rules are printed
print(rules, 2)   # only the first two rules are printed

# printing a subset of rules
rules[2:3]
</code></pre>

<hr>
<h2 id='RI.AQRules.RST'>Rule induction using the AQ algorithm</h2><span id='topic+RI.AQRules.RST'></span>

<h3>Description</h3>

<p>A version of the AQ algorithm which was originally proposed by R.S. Michalski.
This implamentation is based on a concept of a local (object-relative) decision reduct from RST.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RI.AQRules.RST(decision.table, confidence = 1, timesCovered = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RI.AQRules.RST_+3A_decision.table">decision.table</code></td>
<td>
<p>an object inheriting from the <code>"DecisionTable"</code> class, which represents a decision system.
See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="RI.AQRules.RST_+3A_confidence">confidence</code></td>
<td>
<p>a numeric value giving the minimal confidence of computed rules.</p>
</td></tr>
<tr><td><code id="RI.AQRules.RST_+3A_timescovered">timesCovered</code></td>
<td>
<p>a positive integer. The algorithm will try to find a coverage of training examples with rules,
such that each example is covered by at least <code>timesCovered</code> rules and no rule can be removed from
the coverage without breaking this property. This is not always possible - there is a chance that some rules
are duplicated if the value of <code>timesCovered</code> is larger than 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of a class <code>"RuleSetRST"</code>. For details see <code><a href="#topic+RI.indiscernibilityBasedRules.RST">RI.indiscernibilityBasedRules.RST</a></code>.
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>References</h3>

<p>R.S. Michalski, K. Kaufman, J. Wnek: &quot;The AQ Family of Learning Programs: A Review of Recent Developments
and an Exemplary Application&quot;, Reports of Machine Learning and Inference Laboratory, George Mason University (1991)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.RuleSetFRST">predict.RuleSetFRST</a></code>, <code><a href="#topic+RI.indiscernibilityBasedRules.RST">RI.indiscernibilityBasedRules.RST</a></code>, <code><a href="#topic+RI.CN2Rules.RST">RI.CN2Rules.RST</a></code>,
<code><a href="#topic+RI.LEM2Rules.RST">RI.LEM2Rules.RST</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###########################################################
## Example
##############################################################
data(RoughSetData)
wine.data &lt;- RoughSetData$wine.dt
set.seed(13)
wine.data &lt;- wine.data[sample(nrow(wine.data)),]

## Split the data into a training set and a test set,
## 60% for training and 40% for testing:
idx &lt;- round(0.6 * nrow(wine.data))
wine.tra &lt;-SF.asDecisionTable(wine.data[1:idx,],
                              decision.attr = 14,
                              indx.nominal = 14)
wine.tst &lt;- SF.asDecisionTable(wine.data[(idx+1):nrow(wine.data), -ncol(wine.data)])

true.classes &lt;- wine.data[(idx+1):nrow(wine.data), ncol(wine.data)]

## discretization:
cut.values &lt;- D.discretization.RST(wine.tra,
                                   type.method = "unsupervised.quantiles",
                                   nOfIntervals = 3)
data.tra &lt;- SF.applyDecTable(wine.tra, cut.values)
data.tst &lt;- SF.applyDecTable(wine.tst, cut.values)

## rule induction from the training set:
rules &lt;- RI.AQRules.RST(data.tra, confidence = 0.9, timesCovered = 3)
rules

## predicitons for the test set:
pred.vals &lt;- predict(rules, data.tst)

## checking the accuracy of predictions:
mean(pred.vals == true.classes)

</code></pre>

<hr>
<h2 id='RI.CN2Rules.RST'>Rule induction using a version of CN2 algorithm</h2><span id='topic+RI.CN2Rules.RST'></span>

<h3>Description</h3>

<p>An implementation of verions of the famous CN2 algorithm for induction of decision rules, proposed by P.E. Clark and T. Niblett.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RI.CN2Rules.RST(decision.table, K = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RI.CN2Rules.RST_+3A_decision.table">decision.table</code></td>
<td>
<p>an object inheriting from the <code>"DecisionTable"</code> class, which represents a decision system.
See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="RI.CN2Rules.RST_+3A_k">K</code></td>
<td>
<p>a positive integer that controls a complexity of the algorithm. In each iteration <code>K</code> best rule predicates are
extended by all possible descriptors.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of a class <code>"RuleSetRST"</code>. For details see <code><a href="#topic+RI.indiscernibilityBasedRules.RST">RI.indiscernibilityBasedRules.RST</a></code>.
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>References</h3>

<p>P.E. Clark and T. Niblett, &quot;The CN2 Induction algorithm&quot;,
Machine Learning, 3, p. 261 - 284 (1986).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.RuleSetFRST">predict.RuleSetFRST</a></code>, <code><a href="#topic+RI.indiscernibilityBasedRules.RST">RI.indiscernibilityBasedRules.RST</a></code>, <code><a href="#topic+RI.LEM2Rules.RST">RI.LEM2Rules.RST</a></code>,
<code><a href="#topic+RI.AQRules.RST">RI.AQRules.RST</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###########################################################
## Example
##############################################################
data(RoughSetData)
wine.data &lt;- RoughSetData$wine.dt
set.seed(13)
wine.data &lt;- wine.data[sample(nrow(wine.data)),]

## Split the data into a training set and a test set,
## 60% for training and 40% for testing:
idx &lt;- round(0.6 * nrow(wine.data))
wine.tra &lt;-SF.asDecisionTable(wine.data[1:idx,],
                              decision.attr = 14,
                              indx.nominal = 14)
wine.tst &lt;- SF.asDecisionTable(wine.data[(idx+1):nrow(wine.data), -ncol(wine.data)])

true.classes &lt;- wine.data[(idx+1):nrow(wine.data), ncol(wine.data)]

## discretization:
cut.values &lt;- D.discretization.RST(wine.tra,
                                   type.method = "unsupervised.quantiles",
                                   nOfIntervals = 3)
data.tra &lt;- SF.applyDecTable(wine.tra, cut.values)
data.tst &lt;- SF.applyDecTable(wine.tst, cut.values)

## rule induction from the training set:
rules &lt;- RI.CN2Rules.RST(data.tra, K = 5)
rules

## predicitons for the test set:
pred.vals &lt;- predict(rules, data.tst)

## checking the accuracy of predictions:
mean(pred.vals == true.classes)

</code></pre>

<hr>
<h2 id='RI.GFRS.FRST'>Generalized fuzzy rough set rule induction based on FRST</h2><span id='topic+RI.GFRS.FRST'></span>

<h3>Description</h3>

<p>It is a function generating rules in classification tasks using the fuzzy variable precision rough sets (FVPRS) approach (see <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RI.GFRS.FRST(decision.table, control = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RI.GFRS.FRST_+3A_decision.table">decision.table</code></td>
<td>
<p>a <code>"DecisionTable"</code> class representing the decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="RI.GFRS.FRST_+3A_control">control</code></td>
<td>
<p>a list of other parameters which consist of
</p>

<ul>
<li> <p><code>alpha.precision</code>: a numeric value representing variable precision of FVPRS.
The default value is 0.05. See <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.
</p>
</li>
<li> <p><code>type.aggregation</code>: a list of a type of aggregations. The default value is <code>type.aggregation = c("t.tnorm", "lukasiewicz")</code>.
</p>
<p>See <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code>.
</p>
</li>
<li> <p><code>type.relation</code>: a type of indiscernibility relation. The default value is <code>type.relation = c("tolerance", "eq.1")</code>.
See <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code>.
</p>
</li>
<li> <p><code>t.implicator</code>: a type of implication function. The default value is <code>"lukasiewicz"</code>.
See <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>The method proposed by (Zhao, 2010) consists of three steps as follows.
First, it builds a general lower approximation that is able to deal with misclassification and perturbation.
In this case, the fuzzy variable precision rough sets (FVPRS)
is used to calculate the lower approximation (see <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code>).
Secondly, a discernibility matrix considering a consistence degree is constructed for obtaining rules.
The details about the matrix can be seen in <code><a href="#topic+BC.discernibility.mat.FRST">BC.discernibility.mat.FRST</a></code>.
Then, we calculate attribute value reduction of every object and perform near-minimal rule set.
The final step is to construct rules considering the consistence degree of associated objects.
</p>
<p>It should be noted that this function only allows classification problems. After obtaining the rules,
predicting can be done by calling <code>predict</code> or <code><a href="#topic+predict.RuleSetFRST">predict.RuleSetFRST</a></code>.
Additionally, to get better representation we can execute <code><a href="base.html#topic+summary">summary</a></code>.
</p>


<h3>Value</h3>

<p>A class <code>"RuleSetFRST"</code> which has following components:
</p>

<ul>
<li> <p><code>rules</code>: It is a list containing two elements which are <code>rules</code> and <code>threshold</code>.
The <code>rules</code> represent knowledge in data set that can be expressed as an IF-THEN form.
For example, we got the rule as follows: <code>90 8 2</code> and its colnames: <code>pres</code>, <code>preg</code>, and <code>class</code>.
It refers to the following rule: <code>IF pres is about 90 and preg is about 8 THEN class is 2</code>.
In other words, while the last column represents the consequent part,
the rest expresses the antecedent part.
The second part of this object is <code>threshold</code> representing a value used to predict new data.
In order to change IF-THEN form, we can use <code><a href="base.html#topic+summary">summary</a></code>.
</p>
</li>
<li> <p><code>type.model</code>: It is the type of the theory whether <code>"FRST"</code> or <code>"RST"</code>. In this case, it is <code>FRST</code>.
</p>
</li>
<li> <p><code>type.method</code>: It is the considered method. In this case, it is <code>RI.GFRS.FRST</code>.
</p>
</li>
<li> <p><code>type.task</code>: It is the type of task. In this case, it is <code>"classification"</code>.
</p>
</li>
<li> <p><code>t.similariy</code>: It is the type of similarity equation. See <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code>.
</p>
</li>
<li> <p><code>t.tnorm</code>: It is the type of triangular operator. See <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code>.
</p>
</li>
<li> <p><code>variance.data</code>: It represents the variance of the data set. It has <code>NA</code> values when the associated attributes are nominal values.
</p>
</li>
<li> <p><code>range.data</code>: It represents the range of the data set. It has <code>NA</code> values when the associated attributes are nominal values.
</p>
</li>
<li> <p><code>antecedent.attr</code>: It is a list of attribute names involved in the antecedent part.
</p>
</li>
<li> <p><code>consequent.attr</code>: It is the attribute in the consequent part.
</p>
</li>
<li> <p><code>nominal.att</code>: It is a list of boolean that represent whether a attribute is nominal or not.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>References</h3>

<p>S. Y. Zhao, E. C. C. Tsang, D. G. Chen, and X. Z. Wang, &quot;Building a Rule-based
Classifier &ndash; A Fuzzy-rough Set Approach&quot;,
IEEE Trans. on Knowledge and Data Engineering, vol. 22, no. 5, p. 624 - 638 (2010).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RI.indiscernibilityBasedRules.RST">RI.indiscernibilityBasedRules.RST</a></code>, <code><a href="#topic+predict.RuleSetFRST">predict.RuleSetFRST</a></code>, and <code><a href="#topic+RI.hybridFS.FRST">RI.hybridFS.FRST</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###########################################################
## Example
##############################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$pima7.dt

control &lt;- list(alpha.precision = 0.01, type.aggregation = c("t.tnorm", "lukasiewicz"),
                type.relation = c("tolerance", "eq.3"), t.implicator = "lukasiewicz")
rules &lt;- RI.GFRS.FRST(decision.table, control)

</code></pre>

<hr>
<h2 id='RI.hybridFS.FRST'>Hybrid fuzzy-rough rule and induction and feature selection</h2><span id='topic+RI.hybridFS.FRST'></span>

<h3>Description</h3>

<p>It is a function for generating rules based on hybrid fuzzy-rough rule induction and feature selection.
It allows for classification and regression tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RI.hybridFS.FRST(decision.table, control = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RI.hybridFS.FRST_+3A_decision.table">decision.table</code></td>
<td>
<p>a <code>"DecisionTable"</code> class representing the decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="RI.hybridFS.FRST_+3A_control">control</code></td>
<td>
<p>a list of other parameters which consist of
</p>

<ul>
<li> <p><code>type.aggregation</code> a list representing the type of aggregation. The default value is <code>type.aggregation = c("t.tnorm", "lukasiewicz")</code>.
</p>
<p>See <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code>.
</p>
</li>
<li> <p><code>type.relation</code> the type of indiscernibility relation. The default value is <code>type.relation = c("tolerance", "eq.3")</code>.
See <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code>.
</p>
</li>
<li> <p><code>t.implicator</code> the type of implication function. The default value is <code>"lukasiewicz"</code>.
See BC.LU.approximation.FRST.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>It was proposed by (Jensen et al, 2009) attempting to combine rule induction and feature selection
at the same time. Basically this algorithm inserts some steps to generate rules
into the fuzzy QuickReduct algorithm (see <code><a href="#topic+FS.quickreduct.FRST">FS.quickreduct.FRST</a></code>.
Furthermore, by introducing the degree of coverage, this algorithm selects proper rules.
</p>
<p>This function allows not only for classification but also for regression problems. After obtaining the rules,
predicting can be done by calling <code>predict</code> or <code><a href="#topic+predict.RuleSetFRST">predict.RuleSetFRST</a></code>.
Additionally, to get better representation we can execute <code><a href="base.html#topic+summary">summary</a></code>.
</p>


<h3>Value</h3>

<p>A class <code>"RuleSetFRST"</code> which has similar components as <code><a href="#topic+RI.GFRS.FRST">RI.GFRS.FRST</a></code>
but in this case the <code>threshold</code> component is not included.
</p>


<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>References</h3>

<p>R. Jensen, C. Cornelis, and Q. Shen, &quot;Hybrid Fuzzy-rough Rule Induction and Feature Selection&quot;,
in: IEEE International Conference on Fuzzy Systems (FUZZ-IEEE), p. 1151 - 1156 (2009).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RI.indiscernibilityBasedRules.RST">RI.indiscernibilityBasedRules.RST</a></code>, <code><a href="#topic+predict.RuleSetFRST">predict.RuleSetFRST</a></code>, and <code><a href="#topic+RI.GFRS.FRST">RI.GFRS.FRST</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###########################################################
## Example 1: Regression problem
###########################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$housing7.dt

control &lt;- list(type.aggregation = c("t.tnorm", "lukasiewicz"), type.relation =
                c("tolerance", "eq.3"), t.implicator = "lukasiewicz")
res.1 &lt;- RI.hybridFS.FRST(decision.table, control)

###########################################################
## Example 2: Classification problem
##############################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$pima7.dt

control &lt;- list(type.aggregation = c("t.tnorm", "lukasiewicz"), type.relation =
                c("tolerance", "eq.3"), t.implicator = "lukasiewicz")
res.2 &lt;- RI.hybridFS.FRST(decision.table, control)

</code></pre>

<hr>
<h2 id='RI.indiscernibilityBasedRules.RST'>Rule induction from indiscernibility classes.</h2><span id='topic+RI.indiscernibilityBasedRules.RST'></span>

<h3>Description</h3>

<p>Rule induction from indiscernibility classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RI.indiscernibilityBasedRules.RST(decision.table, feature.set)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RI.indiscernibilityBasedRules.RST_+3A_decision.table">decision.table</code></td>
<td>
<p>an object inheriting from the <code>"DecisionTable"</code> class, which represents a decision system.
See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="RI.indiscernibilityBasedRules.RST_+3A_feature.set">feature.set</code></td>
<td>
<p>an object inheriting from the <code>"FeatureSubset"</code> class which is a typical output of feature
selection methods based on RST  e.g. <code><a href="#topic+FS.greedy.heuristic.reduct.RST">FS.greedy.heuristic.reduct.RST</a></code>.
See also <code><a href="#topic+FS.reduct.computation">FS.reduct.computation</a></code>, <code><a href="#topic+FS.feature.subset.computation">FS.feature.subset.computation</a></code> and
<code><a href="#topic+FS.all.reducts.computation">FS.all.reducts.computation</a></code> based on RST.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function generates &quot;if-then&quot; decision rules from indiscernibility classes defined by a given
subset of conditional attributes.
</p>
<p>After obtaining the rules, decision classes of new objects can be predicted using the <code>predict</code> method or
by a direct call to <code><a href="#topic+predict.RuleSetRST">predict.RuleSetRST</a></code>.
</p>


<h3>Value</h3>

<p>An object of a class <code>"RuleSetRST"</code>, which is a list with additional attributes:
</p>

<ul>
<li> <p><code>uniqueCls</code>: a vector of possible decision classes,
</p>
</li>
<li> <p><code>supportDenominator</code>: an integer giving the number of objects in the data,
</p>
</li>
<li> <p><code>clsProbs</code>: a vector giving the a priori probability of the decision classes,
</p>
</li>
<li> <p><code>majorityCls</code>: a class label representing the majority class in the data,
</p>
</li>
<li> <p><code>method</code>: the type a rule induction method used for computations,
</p>
</li>
<li> <p><code>dec.attr</code>: a name of the decision attribute in the data,
</p>
</li>
<li> <p><code>colnames</code>: a vector of conditional attribute names.
</p>
</li></ul>

<p>Each rule is a list with the following elements:
</p>

<ul>
<li> <p><code>idx</code>: a vector of indexes of attribute that are used in antecedent of a rule,
</p>
</li>
<li> <p><code>values</code>: a vector of values of attributes indicated by <code>idx</code>,
</p>
</li>
<li> <p><code>consequent</code>: a value of the consequent of a rule,
</p>
</li>
<li> <p><code>support</code>: a vactor of integers indicating objects from the data, which support a given rule,
</p>
</li>
<li> <p><code>laplace</code>: ia numeric value representing the Laplace estimate of the rule's confidence.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.RuleSetRST">predict.RuleSetRST</a></code>, <code><a href="#topic+RI.CN2Rules.RST">RI.CN2Rules.RST</a></code>, <code><a href="#topic+RI.LEM2Rules.RST">RI.LEM2Rules.RST</a></code>,
<code><a href="#topic+RI.AQRules.RST">RI.AQRules.RST</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###########################################################
## Example
##############################################################
data(RoughSetData)
hiring.data &lt;- RoughSetData$hiring.dt

## determine feature subset/reduct
reduct &lt;- FS.reduct.computation(hiring.data,
                                method = "permutation.heuristic",
                                permutation = FALSE)

rules &lt;- RI.indiscernibilityBasedRules.RST(hiring.data, reduct)
rules

</code></pre>

<hr>
<h2 id='RI.laplace'>Quality indicators of RST decision rules</h2><span id='topic+RI.laplace'></span><span id='topic+RI.support'></span><span id='topic+RI.confidence'></span><span id='topic+RI.lift'></span>

<h3>Description</h3>

<p>Functions for extracting quality indices of rules.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RI.laplace(rules, ...)
RI.support(rules, ...)
RI.confidence(rules, ...)
RI.lift(rules, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RI.laplace_+3A_rules">rules</code></td>
<td>
<p>a <code>"RuleSetRST"</code> object containing a set of decision rules. See <code><a href="#topic+RI.LEM2Rules.RST">RI.LEM2Rules.RST</a></code>.</p>
</td></tr>
<tr><td><code id="RI.laplace_+3A_...">...</code></td>
<td>
<p>the other parameters (currently omitted).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector with values of the corresponding quality measure.
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###########################################################
## Example : Filtering a set of decision rules
###########################################################
data(RoughSetData)
hiring.data &lt;- RoughSetData$hiring.dt

rules &lt;- RI.LEM2Rules.RST(hiring.data)

rules

# a vector of rules' Laplace estimate of the confidence:
RI.laplace(rules)
# a vector of rules' confidence values:
RI.confidence(rules)

# subsetting a set of rules:
rules[RI.support(rules) &gt; 0.2]
rules[RI.lift(rules) &lt; 1.5]

</code></pre>

<hr>
<h2 id='RI.LEM2Rules.RST'>Rule induction using the LEM2 algorithm</h2><span id='topic+RI.LEM2Rules.RST'></span>

<h3>Description</h3>

<p>An implementation of LEM2 (Learning from Examples Module, version 2) for induction of decision rules,
originally proposed by J.W. Grzymala-Busse.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RI.LEM2Rules.RST(decision.table)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RI.LEM2Rules.RST_+3A_decision.table">decision.table</code></td>
<td>
<p>an object inheriting from the <code>"DecisionTable"</code> class, which represents a decision system.
See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of a class <code>"RuleSetRST"</code>. For details see <code><a href="#topic+RI.indiscernibilityBasedRules.RST">RI.indiscernibilityBasedRules.RST</a></code>.
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>References</h3>

<p>J.W. Grzymala-Busse, &quot;A New Version of the Rule Induction System LERS&quot;,
Fundamenta Informaticae, 31, p. 27 - 39 (1997).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.RuleSetFRST">predict.RuleSetFRST</a></code>, <code><a href="#topic+RI.indiscernibilityBasedRules.RST">RI.indiscernibilityBasedRules.RST</a></code>, <code><a href="#topic+RI.CN2Rules.RST">RI.CN2Rules.RST</a></code>,
<code><a href="#topic+RI.AQRules.RST">RI.AQRules.RST</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###########################################################
## Example
##############################################################
data(RoughSetData)
wine.data &lt;- RoughSetData$wine.dt
set.seed(13)
wine.data &lt;- wine.data[sample(nrow(wine.data)),]

## Split the data into a training set and a test set,
## 60% for training and 40% for testing:
idx &lt;- round(0.6 * nrow(wine.data))
wine.tra &lt;-SF.asDecisionTable(wine.data[1:idx,],
                              decision.attr = 14,
                              indx.nominal = 14)
wine.tst &lt;- SF.asDecisionTable(wine.data[(idx+1):nrow(wine.data), -ncol(wine.data)])

true.classes &lt;- wine.data[(idx+1):nrow(wine.data), ncol(wine.data)]

## discretization:
cut.values &lt;- D.discretization.RST(wine.tra,
                                   type.method = "local.discernibility",
                                   maxNOfCuts = 1)
data.tra &lt;- SF.applyDecTable(wine.tra, cut.values)
data.tst &lt;- SF.applyDecTable(wine.tst, cut.values)

## rule induction from the training set:
rules &lt;- RI.LEM2Rules.RST(data.tra)
rules

## predicitons for the test set:
pred.vals &lt;- predict(rules, data.tst)

## checking the accuracy of predictions:
mean(pred.vals == true.classes)

</code></pre>

<hr>
<h2 id='RoughSetData'>Data set of the package</h2><span id='topic+RoughSetData'></span>

<h3>Description</h3>

<p>Several datasets have been embedded in this package to be used as decision table of examples.
They can be accessed by typing <code>data(RoughSetData)</code>. The following is a description of each 
datasets.
</p>


<h3>Details</h3>

<p><b>The hiring dataset</b>
</p>
<p>It is simple data taken from (Komorowski et al, 1999) where all the attributes have nominal values. 
It consists of eight objects with four conditional attributes and one decision attribute. 
The detailed description of each attribute is as follows:
</p>

<ul>
<li><p> Diploma: it has the following values: {&quot;MBA&quot;, &quot;MSc&quot;, &quot;MCE&quot;}.
</p>
</li>
<li><p> Exprience: it has the following values: {&quot;High&quot;, &quot;Low&quot;, &quot;Medium&quot;}.
</p>
</li>
<li><p> French: it has the following values: {&quot;Yes&quot;, &quot;No&quot;}.
</p>
</li>
<li><p> Reference: it has the following values: {&quot;Excellent&quot;, &quot;Good&quot;, &quot;Neutral&quot;}.
</p>
</li>
<li><p> Decision: it is a decision attribute that contains the following values: {&quot;Accept&quot;, &quot;Reject&quot;}.
</p>
</li></ul>

<p><b>The housing dataset</b>
</p>
<p>This data was taken from the Boston housing dataset located at the UCI Machine Learning repository, 
available at http://www.ics.uci.edu. It was first created by 
(Harrison and Rubinfeld, 1978). It contains 506 objects with 13 conditional attributes and one decision attribute.
Furthermore, it should be noted that the housing dataset is a regression dataset which means that 
the decision attribute has continuous values. The conditional attributes contain both continuous and nominal attributes.
The following is a description of each attribute:
</p>

<ul>
<li><p> CRIM: it is a continuous attribute that expresses per capita crime rate by town. 
It has values in: [0.0062, 88.9762].
</p>
</li>
<li><p> ZN: it is a continuous attribute that represents the proportion of residential land 
zoned for lots over 25,000 sq.ft. It has values in: [0, 100].
</p>
</li>
<li><p> INDUS: it is a continuous attribute that shows the proportion of non-retail business acres per town.
It has values in: [0.46, 27.74].
</p>
</li>
<li><p> CHAS: it is a nominal attribute that represents Charles River dummy variable. 
It has two values which are 1 if tract bounds river and 0 otherwise.
</p>
</li>
<li><p> NOX: it is a continuous attribute that shows the nitric oxides concentration (parts per 10 million).
It has values in: [0.385, 0.871].
</p>
</li>
<li><p> RM: it is a continuous attribute that explains the average number of rooms per dwelling.
It has values in: [3.561, 8.78].
</p>
</li>
<li><p> AGE: it is a continuous attribute that expresses proportion of owner-occupied 
units built prior to 1940. It has values in: [2.9, 100].
</p>
</li>
<li><p> DIS: it is a continuous attribute that shows weighted distances to five Boston employment centres.
It has values in: [1.1296, 12.1265].
</p>
</li>
<li><p> RAD: it is a nominal attribute that shows the index of accessibility to radial highways.
it has the integer value from 1 to 24.
</p>
</li>
<li><p> TAX: it is a continuous attribute that shows the full-value property-tax rate per $10,000.
It has values in: [187, 711].
</p>
</li>
<li><p> PTRATIO: it is a continuous attribute that shows the pupil-teacher ratio by town.
It has values in: [12.6, 22].
</p>
</li>
<li><p> B: it is a continuous attribute that can be expressed by 1000(Bk - 0.63)^2 
where Bk is the proportion of blacks by town. It has values in: [0.32, 396.9].
</p>
</li>
<li><p> LSTAT: it is a continuous attribute that illustrates the percentage of lower status of the population.
It has values in: [1.73, 37.97].
</p>
</li>
<li><p> MEDV: it is a continuous attribute that shows the median value of owner-occupied homes in $1000's.
It has values in: [5, 50].
</p>
</li></ul>

<p><b>The wine dataset</b>
</p>
<p>This dataset is a classification dataset introduced first by (Forina, et al) 
which is commonly used as benchmark for simulation in the machine learning area. 
Additionally, it is available at the KEEL dataset repository (Alcala-Fdez, 2009), available at http://www.keel.es/. 
It consists of 178 instances with 13 conditional attributes and one decision attribute 
where all conditional attributes have continuous values. The description of 
each attribute is as follows:
</p>

<ul>
<li><p> alcohol: it has a range in: [11, 14.9].
</p>
</li>
<li><p> malid_acid: it has a range in: [0.7, 5.8].
</p>
</li>
<li><p> ash: it has a range in: [1.3, 3.3].
</p>
</li>
<li><p> alcalinity_of_ash: it has a range in: [10.6, 30.0].
</p>
</li>
<li><p> magnesium: it has a range in: [70, 162].
</p>
</li>
<li><p> total_phenols: it has a range in: [0.9, 3.9].
</p>
</li>
<li><p> flavanoids: it has a range in: [0.3 5.1].
</p>
</li>
<li><p> nonflavanoid_phenols: it has a range in: [0.4 3.6].
</p>
</li>
<li><p> proanthocyanins: it has a range in: [0.4 3.6].
</p>
</li>
<li><p> color_intensity: it has a range in: [1.2 13.0].
</p>
</li>
<li><p> hue: it has a range in: [0.4 1.8].
</p>
</li>
<li><p> od: it has a range in: [1.2 4.0].
</p>
</li>
<li><p> proline: it has a range in: [278 1680].
</p>
</li>
<li><p> class: it is nominal decision attribute that has values: {1, 2, 3}.
</p>
</li></ul>

<p><b>The pima dataset</b>
</p>
<p>It was taken from the pima Indians diabetes dataset which is available at the KEEL dataset repository 
(Alcala-Fdez, 2009), available at http://www.keel.es/. It was first created by 
National Institute of Diabetes and Digestive and Kidney Diseases. It contains 768 objects with 8 continuous conditional
attributes. The description of each attribute is as follows:
</p>

<ul>
<li><p> preg: it represents number of times pregnant and has values in: [1, 17].
</p>
</li>
<li><p> plas: it represents plasma glucose concentration 
a 2 hours in an oral glucose tolerance test and has values in: [0.0, 199.0].
</p>
</li>
<li><p> pres: it represents diastolic blood pressure (mm Hg) and has values in: [0.0, 122.0].
</p>
</li>
<li><p> skin: it represents triceps skin fold thickness (mm) and has values in: [0.0, 99.0].
</p>
</li>
<li><p> insu: it represents 2-hour serum insulin (mu U/ml) and has values in: [0.0, 846.0].
</p>
</li>
<li><p> mass: it represents body mass index (weight in kg/(height in m)^2) and has values in: [0.0, 67.1].
</p>
</li>
<li><p> pedi: it represents diabetes pedigree function and has values in: [0.078, 2.42].
</p>
</li>
<li><p> age: it represents age (years) and has values in: [21.0, 81.0].
</p>
</li>
<li><p> class: it is a decision attribute and has values in: [1, 2].
</p>
</li></ul>



<h3>References</h3>

<p>M. Forina, E. Leardi, C. Armanino, and S. Lanteri, &quot;PARVUS -
An Extendible Package for Data Exploration, Classification and Correlation&quot;,
Journal of Chemonetrics, vol. 4, no. 2, p. 191 - 193 (1988). 
</p>
<p>D. Harrison, and D. L. Rubinfeld, &quot;Hedonic Prices and the 
Demand for Clean Air&quot;, J. Environ. Economics &amp; Management,
vol.5, 81-102 (1978).
</p>
<p>J. Alcala-Fdez, L. Sanchez, S. Garcia, M. J. del Jesus, S. Ventura, 
J. M. Garrell, J. Otero, C. Romero, J. Bacardit, V. M. Rivas, 
J. C. Fernandez, and F. Herrera,  
&quot;KEEL: A Software Tool to Assess Evolutionary Algorithms to Data Mining Problems&quot;, 
Soft Computing vol. 13, no. 3, p. 307 - 318 (2009).
</p>
<p>J. Komorowski, Z. Pawlak, L. Polwski, and A. Skowron,
&quot;Rough Sets: A Tutorial&quot;, In S. K. Pal and A. Skowron, editors,
Rough Fuzzy Hybridization, A New Trend in Decision Making,
pp. 3 - 98, Singopore, Springer (1999).
</p>

<hr>
<h2 id='SF.applyDecTable'>Apply for obtaining a new decision table</h2><span id='topic+SF.applyDecTable'></span>

<h3>Description</h3>

<p>It is used to apply a particular object/model for obtaining a new decision table. In other words, in order to use the function,
the models, which are objects of missing value completion, feature selection, instance selection, or
discretization, have been calculated previously .
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SF.applyDecTable(decision.table, object, control = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SF.applyDecTable_+3A_decision.table">decision.table</code></td>
<td>
<p>a <code>"DecisionTable"</code> class representing a decision table. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="SF.applyDecTable_+3A_object">object</code></td>
<td>
<p>a class resulting from feature selection (e.g., <code><a href="#topic+FS.reduct.computation">FS.reduct.computation</a></code>), discretization (e.g., <code><a href="#topic+D.discretization.RST">D.discretization.RST</a></code>),
instance selection functions
(e.g., <code><a href="#topic+IS.FRIS.FRST">IS.FRIS.FRST</a></code>), and missing value completion (e.g., <code><a href="#topic+MV.missingValueCompletion">MV.missingValueCompletion</a></code>).</p>
</td></tr>
<tr><td><code id="SF.applyDecTable_+3A_control">control</code></td>
<td>
<p>a list of other parameters which are <code>indx.reduct</code> representing an index of the chosen decision reduct. It is only considered when
we calculate all reducts using <code><a href="#topic+FS.all.reducts.computation">FS.all.reducts.computation</a></code>. The default value is that the first reduct will be chosen.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A new decision table. Especially for the new decision table resulting from discretization, we
obtain a different representation. Values are expressed in intervals instead of labels. For example,
<code class="reqn">a_1 = [-Inf, 1.35]</code> refers to the value <code class="reqn">a_1</code> has a value in that range.
</p>


<h3>Author(s)</h3>

<p>Lala Septem Riza and Andrzej Janusz
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################
## Example 1: The feature selection in RST
## using quickreduct
#############################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$hiring.dt

## generate reducts
red.1 &lt;- FS.quickreduct.RST(decision.table)

new.decTable &lt;- SF.applyDecTable(decision.table, red.1)

#############################################################
## Example 2: The feature selection in FRST
## using fuzzy.QR (fuzzy quickreduct)
#############################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$hiring.dt

## fuzzy quickreduct using fuzzy lower approximation
control &lt;- list(decision.attr = c(5), t.implicator = "lukasiewicz",
                type.relation = c("tolerance", "eq.1"), type.aggregation =
                c("t.tnorm", "lukasiewicz"))
red.2 &lt;- FS.quickreduct.FRST(decision.table, type.method = "fuzzy.dependency",
                            type.QR = "fuzzy.QR", control = control)

## generate new decision table
new.decTable &lt;- SF.applyDecTable(decision.table, red.2)

###################################################
## Example 3: The Instance selection by IS.FRPS and
## generate new decision table
###################################################
dt.ex1 &lt;- data.frame(c(0.5, 0.2, 0.3, 0.7, 0.2, 0.2),
                  c(0.1, 0.4, 0.2, 0.8, 0.4, 0.4), c(0, 0, 0, 1, 1, 1))
colnames(dt.ex1) &lt;- c("a1", "a2", "d")
decision.table &lt;- SF.asDecisionTable(dataset = dt.ex1, decision.attr = 3)

## evaluate and select instances
res.1 &lt;- IS.FRPS.FRST(decision.table, type.alpha = "FRPS.3")

## generate new decision table
new.decTable &lt;- SF.applyDecTable(decision.table, res.1)

#################################################################
## Example 4: Discretization by determining cut values and
## then generate new decision table
#################################################################
dt.ex2 &lt;- data.frame(c(1, 1.2, 1.3, 1.4, 1.4, 1.6, 1.3), c(2, 0.5, 3, 1, 2, 3, 1),
                             c(1, 0, 0, 1, 0, 1, 1))
colnames(dt.ex2) &lt;- c("a", "b", "d")
decision.table &lt;- SF.asDecisionTable(dataset = dt.ex2, decision.attr = 3,
                  indx.nominal = 3)

## get cut values using the local strategy algorithm
cut.values &lt;- D.discretization.RST(decision.table, type.method = "global.discernibility")

## generate new decision table
new.decTable &lt;- SF.applyDecTable(decision.table, cut.values)

#################################################################
## Example 5: Missing value completion
#################################################################
dt.ex1 &lt;- data.frame(
     c(100.2, 102.6, NA, 99.6, 99.8, 96.4, 96.6, NA),
     c(NA, "yes", "no", "yes", NA, "yes", "no", "yes"),
     c("no", "yes", "no", "yes", "yes", "no", "yes", NA),
     c("yes", "yes", "no", "yes", "no", "no", "no", "yes"))
colnames(dt.ex1) &lt;- c("Temp", "Headache", "Nausea", "Flu")
decision.table &lt;- SF.asDecisionTable(dataset = dt.ex1, decision.attr = 4,
                                    indx.nominal = c(2:4))

## missing value completion
val.NA = MV.missingValueCompletion(decision.table, type.method = "globalClosestFit")

## generate new decision table
new.decTable &lt;- SF.applyDecTable(decision.table, val.NA)
new.decTable
</code></pre>

<hr>
<h2 id='SF.asDecisionTable'>Converting a data.frame into a <code>DecisionTable</code> object</h2><span id='topic+SF.asDecisionTable'></span>

<h3>Description</h3>

<p>This function converts <code>data.frames</code> into <code>DecisionTable</code> objects. This is a standard data representation
in the <code>RoughSets</code> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SF.asDecisionTable(dataset, decision.attr = NULL, indx.nominal = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SF.asDecisionTable_+3A_dataset">dataset</code></td>
<td>
<p>data.frame that contains objects/instances and attributes/features in its rows and columns, respectively.
See in Section <code>Details</code>.</p>
</td></tr>
<tr><td><code id="SF.asDecisionTable_+3A_decision.attr">decision.attr</code></td>
<td>
<p>an integer value representing the index position of the decision attribute. If this parameter is ignored, then
the function will treat the data as an information system or newdata/test data. In other words,
it is necessary to define the index of the decision attribute in order to construct a decision table (e.g. a training data set).</p>
</td></tr>
<tr><td><code id="SF.asDecisionTable_+3A_indx.nominal">indx.nominal</code></td>
<td>
<p>a logical vector indicating nominal attributes in the data.
If this parameter is not given, then the function will use a heuristic to guess which of the attributes are nominal.
The following rules will be applied used:
</p>

<ul>
<li><p> an attribute contains character values or factors: it will be recognized as a nominal attribute.
</p>
</li>
<li><p> an attribute contains integer or numeric values: it will be recognized as a numeric attribute.
</p>
</li>
<li><p> indx.nominal: the indicated attributes will be considered as nominal.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>An object of the <code>"DecisionTable"</code> class adds a few attributes to a standard data.frame:
</p>

<ul>
<li> <p><code>desc.attrs</code>: a list containing the names of attributes and their range/possible symbolic values.
There are two kinds of representation in this parameters which depend on whether the attributes are
nominal or numeric, for example:
</p>

<ul>
<li><p> nominal attribute: <code>a = c(1,2,3)</code> means that the attribute <code>a</code> has values 1, 2, and 3.
</p>
</li>
<li><p> numeric attribute: <code>a = c(10, 20)</code> means that the attribute <code>a</code> has values between 10 and 20.
</p>
</li></ul>

</li>
<li> <p><code>nominal.attrs</code>: a logical vector whose length equals the number of columns in the data. In this vector <code>TRUE</code> values
indicate that the corresponding attribute is a nominal. For example:
<code>nominal.attrs = c(FALSE, TRUE, FALSE)</code> means that the first and third attributes
are numeric and the second one is nominal.
</p>
</li>
<li> <p><code>decision.attr</code>: a numeric value representing the index of the decision attribute. It is necessary to define
the index of the decision attribute in order to construct a proper decision system. If the value
of <code>decision.attr</code> is NULL, the constructed object will correspond to an information system.
It is strongly recommended to place the decision attribute as the last data column.
</p>
</li></ul>

<p><code>"DecisionTable"</code> objects allow to use all methods of standard data.frame objects.
The function <code><a href="#topic+SF.read.DecisionTable">SF.read.DecisionTable</a></code> can be used to import data from a file and then construct <code>DecisionTable</code> object.
</p>


<h3>Value</h3>

<p>An object of the <code>"DecisionTable"</code> class.
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SF.read.DecisionTable">SF.read.DecisionTable</a></code>, <code><a href="#topic+SF.applyDecTable">SF.applyDecTable</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>################################################################
## Example : converting from datasets in data.frame
##            into decision table
################################################################
## Let use iris which is available in R be dataset
decision.table &lt;- SF.asDecisionTable(dataset = iris, decision.attr = 5,
                  indx.nominal = 5)
</code></pre>

<hr>
<h2 id='SF.asFeatureSubset'>Converting custom attribute name sets into a FeatureSubset object</h2><span id='topic+SF.asFeatureSubset'></span>

<h3>Description</h3>

<p>The function can be used to change a custom set of attribute names from
a decision table into an object of the FeatureSubset class. It can be useful
for converting results of discernibility matrix-based attribute selection
methods (i.e. functions FS.all.reducts.computation and FS.one.reduct.computation).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SF.asFeatureSubset(
  colNames,
  decisionTable = NULL,
  attributeNames = NULL,
  type.method = "custom subset",
  model = "custom"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SF.asFeatureSubset_+3A_colnames">colNames</code></td>
<td>
<p>a character vector containing names of attributes from a decision table</p>
</td></tr>
<tr><td><code id="SF.asFeatureSubset_+3A_decisiontable">decisionTable</code></td>
<td>
<p>a decision table which contains attributes from colNames, 
can be <code>NULL</code> and in that case a non-NULL value of <code>attributeNames</code>
must be given</p>
</td></tr>
<tr><td><code id="SF.asFeatureSubset_+3A_attributenames">attributeNames</code></td>
<td>
<p>a character vector of names of decision table's attributes,
can be <code>NULL</code> and in that case a non-NULL value of <code>decisionTable</code>
must be given</p>
</td></tr>
<tr><td><code id="SF.asFeatureSubset_+3A_type.method">type.method</code></td>
<td>
<p>an indicator of the method used for selecting the attributes</p>
</td></tr>
<tr><td><code id="SF.asFeatureSubset_+3A_model">model</code></td>
<td>
<p>an indicator of the model used for selecting the attributes</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of a class FeatureSubset
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################
## Example 1:
#############################################################
data(RoughSetData)
wine.data &lt;- RoughSetData$wine.dt
dim(wine.data)

## selection of an arbitrary attribute subset
attrNames = colnames(wine.data)[1:3]
attrNames
class(attrNames)

## convertion into a FeatureSubset object
reduct &lt;- SF.asFeatureSubset(attrNames, wine.data,
                             type.method = "greedy reduct from a discernibility matrix")

class(reduct)
reduct

</code></pre>

<hr>
<h2 id='SF.read.DecisionTable'>Reading tabular data from files.</h2><span id='topic+SF.read.DecisionTable'></span>

<h3>Description</h3>

<p>This function can be used to import data sets from files and then construct a <code>DecisionTable</code> object. It uses
<code><a href="utils.html#topic+read.table">read.table</a></code> function from <code>base</code> R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SF.read.DecisionTable(filename, decision.attr = NULL, indx.nominal = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SF.read.DecisionTable_+3A_filename">filename</code></td>
<td>
<p>a path with a file name.</p>
</td></tr>
<tr><td><code id="SF.read.DecisionTable_+3A_decision.attr">decision.attr</code></td>
<td>
<p>an integer indicating an index of the decision attribute. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="SF.read.DecisionTable_+3A_indx.nominal">indx.nominal</code></td>
<td>
<p>an integer vector with indices of attributes which should be considered as nominal.
See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.</p>
</td></tr>
<tr><td><code id="SF.read.DecisionTable_+3A_...">...</code></td>
<td>
<p>additional parameters which are passed to the <code>read.table</code> function. See <code><a href="utils.html#topic+read.table">read.table</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data should be in a tabular format containing rows and columns, where every row represents
an object/instance, while columns represent attributes of the objects.
</p>


<h3>Value</h3>

<p>An object of the <code>"DecisionTable"</code> class. See <code><a href="#topic+SF.asDecisionTable">SF.asDecisionTable</a></code>.
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################
## Example 1: data set saved in a file
#############################################################
## Let us assume we have the following data which has been already saved to the file "tes.dat"
data &lt;- data.frame(c(0.12, 0.23, 0.24), c(1,3,2), c(10, 12, 18), c("a", "a", "b"), c(1, 1, 2))
## Not run: write.table(data, file = "tes.dat", row.names = FALSE, col.names = FALSE,
                    fileEncoding ="")
## End(Not run)

## Then we would generate decision table from tes.dat file.
## in this case, we want to define that second and third attributes are nominal and continuous,
## respectively.
## Not run: decision.table &lt;- SF.read.DecisionTable(filename = "tes.dat", decision.attr = 5,
                  indx.nominal = c(2, 5), sep= " ", col.names = c("v1", "v2", "v3", "v4", "o1"))
## End(Not run)

</code></pre>

<hr>
<h2 id='summary.IndiscernibilityRelation'>The summary function for an indiscernibility relation</h2><span id='topic+summary.IndiscernibilityRelation'></span>

<h3>Description</h3>

<p>This function enables the output of a summary of the indiscernibility relation functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'IndiscernibilityRelation'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.IndiscernibilityRelation_+3A_object">object</code></td>
<td>
<p>a <code>"IndiscernibilityRelation"</code> object. See <code><a href="#topic+BC.IND.relation.FRST">BC.IND.relation.FRST</a></code>
</p>
<p>and <code><a href="#topic+BC.IND.relation.RST">BC.IND.relation.RST</a></code>.</p>
</td></tr>
<tr><td><code id="summary.IndiscernibilityRelation_+3A_...">...</code></td>
<td>
<p>the other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a description that contains the following information. For FRST model:
</p>


<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###########################################################
## Example 1: Dataset containing nominal values for
## all attributes.
###########################################################
## Decision table is represented as data frame
dt.ex1 &lt;- data.frame(c(1,0,2,1,1,2,2,0), c(0, 1,0, 1,0,2,1,1),
                        c(2,1,0,0,2,0,1,1), c(2,1,1,2,0,1,1,0), c(0,2,1,2,1,1,2,1))
colnames(dt.ex1) &lt;- c("aa", "bb", "cc", "dd", "ee")
decision.table &lt;- SF.asDecisionTable(dataset = dt.ex1, decision.attr = 5)

## In this case, we only consider the second and third attributes.
attributes &lt;- c(2, 3)

#### calculate fuzzy indiscernibility relation ####
## in this case, we are using "crisp" as a type of relation and type of aggregation
control.ind &lt;- list(type.relation = c("crisp"), type.aggregation = c("crisp"))
IND &lt;- BC.IND.relation.FRST(decision.table, attributes = attributes, control = control.ind)

summary(IND)
</code></pre>

<hr>
<h2 id='summary.LowerUpperApproximation'>The summary function of lower and upper approximations based on RST and FRST</h2><span id='topic+summary.LowerUpperApproximation'></span>

<h3>Description</h3>

<p>This function enables the output of a summary of the lower and upper approximations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LowerUpperApproximation'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.LowerUpperApproximation_+3A_object">object</code></td>
<td>
<p>a <code>"LowerUpperApproximation"</code> object. See <code><a href="#topic+BC.LU.approximation.FRST">BC.LU.approximation.FRST</a></code> and <code><a href="#topic+BC.LU.approximation.RST">BC.LU.approximation.RST</a></code>.</p>
</td></tr>
<tr><td><code id="summary.LowerUpperApproximation_+3A_...">...</code></td>
<td>
<p>the other parameters.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#######################################
## Example: Using simple data set
#######################################
dt.ex1 &lt;- data.frame(c(1,0,2,1,1,2,2,0), c(0, 1,0, 1,0,2,1,1),
                        c(2,1,0,0,2,0,1,1), c(2,1,1,2,0,1,1,0), c(0,2,1,2,1,1,2,1))
colnames(dt.ex1) &lt;- c("aa", "bb", "cc", "dd", "ee")
decision.table &lt;- SF.asDecisionTable(dataset = dt.ex1, decision.attr = 5,
                                     indx.nominal = c(1:5))

P &lt;- c(2,3)

####### Compute indiscernibility relation #######
IND &lt;- BC.IND.relation.RST(decision.table, feature.set = P)

####### Compute lower and upper approximation #####
roughset &lt;- BC.LU.approximation.RST(decision.table, IND)

summary(roughset)
</code></pre>

<hr>
<h2 id='summary.PositiveRegion'>The summary function of positive region based on RST and FRST</h2><span id='topic+summary.PositiveRegion'></span>

<h3>Description</h3>

<p>This function enables the output of a summary of the positive region and degree of dependency.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'PositiveRegion'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.PositiveRegion_+3A_object">object</code></td>
<td>
<p>a <code>"PositiveRegion"</code> object. See <code><a href="#topic+BC.positive.reg.FRST">BC.positive.reg.FRST</a></code> and <code><a href="#topic+BC.positive.reg.RST">BC.positive.reg.RST</a></code>.</p>
</td></tr>
<tr><td><code id="summary.PositiveRegion_+3A_...">...</code></td>
<td>
<p>the other parameters.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dt.ex1 &lt;- data.frame(c(1,0,2,1,1,2,2,0), c(0, 1,0, 1,0,2,1,1),
                        c(2,1,0,0,2,0,1,1), c(2,1,1,2,0,1,1,0), c(0,2,1,2,1,1,2,1))
colnames(dt.ex1) &lt;- c("aa", "bb", "cc", "dd", "ee")
decision.table &lt;- SF.asDecisionTable(dataset = dt.ex1, decision.attr = 5,
                                    indx.nominal = c(1:5))

## in this case, we consider second and third attributes only
P &lt;- c(2,3)

####### Perform indiscernibility relation #######
IND &lt;- BC.IND.relation.RST(decision.table, feature.set = P)

####### Perform lower and upper approximations #####
roughset &lt;- BC.LU.approximation.RST(decision.table, IND)

####### Determine the positive region ######
region &lt;- BC.positive.reg.RST(decision.table, roughset)

summary(region)
</code></pre>

<hr>
<h2 id='summary.RuleSetFRST'>The summary function of rules based on FRST</h2><span id='topic+summary.RuleSetFRST'></span>

<h3>Description</h3>

<p>This function enables the output of a summary of the rule induction methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'RuleSetFRST'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.RuleSetFRST_+3A_object">object</code></td>
<td>
<p>a <code>"RuleSetFRST"</code> object. See <code><a href="#topic+RI.hybridFS.FRST">RI.hybridFS.FRST</a></code> and <code><a href="#topic+RI.GFRS.FRST">RI.GFRS.FRST</a></code>.</p>
</td></tr>
<tr><td><code id="summary.RuleSetFRST_+3A_...">...</code></td>
<td>
<p>the other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a description that contains the following information:
</p>

<ul>
<li><p> The type of the considered model.
</p>
</li>
<li><p> The type of the considered method.
</p>
</li>
<li><p> The type of the considered task.
</p>
</li>
<li><p> The type of similarity.
</p>
</li>
<li><p> The type of triangular norm.
</p>
</li>
<li><p> The names of attributes and their type (whether nominal or not).
</p>
</li>
<li><p> The interval of the data.
</p>
</li>
<li><p> the variance values of the data.
</p>
</li>
<li><p> The rules. Every rule constitutes two parts which are IF and THEN parts.
For example, <code>"IF pres is around 90 and preg is around 8 THEN class is 2"</code>.
See <code><a href="#topic+RI.GFRS.FRST">RI.GFRS.FRST</a></code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Lala Septem Riza
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###########################################################
## Example 1: Regression problem
###########################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$housing7.dt

control &lt;- list(type.aggregation = c("t.tnorm", "lukasiewicz"), type.relation =
                c("tolerance", "eq.3"), t.implicator = "lukasiewicz")
res.1 &lt;- RI.hybridFS.FRST(decision.table, control)

summary(res.1)
###########################################################
## Example 2: Classification problem
##############################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$pima7.dt

control &lt;- list(type.aggregation = c("t.tnorm", "lukasiewicz"), type.relation =
                c("tolerance", "eq.3"), t.implicator = "lukasiewicz")
res.2 &lt;- RI.hybridFS.FRST(decision.table, control)

summary(res.2)
</code></pre>

<hr>
<h2 id='summary.RuleSetRST'>The summary function of rules based on RST</h2><span id='topic+summary.RuleSetRST'></span>

<h3>Description</h3>

<p>This function enables the output of a summary of the rule induction methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'RuleSetRST'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.RuleSetRST_+3A_object">object</code></td>
<td>
<p>a <code>"RuleSetRST"</code> object. See <code><a href="#topic+RI.indiscernibilityBasedRules.RST">RI.indiscernibilityBasedRules.RST</a></code>.</p>
</td></tr>
<tr><td><code id="summary.RuleSetRST_+3A_...">...</code></td>
<td>
<p>the other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a description that contains the following information:
</p>

<ul>
<li><p> The type of the considered model.
</p>
</li>
<li><p> The type of the considered method.
</p>
</li>
<li><p> The type of the considered task.
</p>
</li>
<li><p> The rules. Every rule constitutes two parts which are IF and THEN parts.
For example, <code>"IF pres is around 90 and preg is around 8 THEN class is 2; (support=4;laplace=0.67)"</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Lala Septem Riza and Andrzej Janusz
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###########################################################
## Example : Classification problem
###########################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$hiring.dt

## determine feature subset/reduct
reduct &lt;- FS.permutation.heuristic.reduct.RST(decision.table,  permutation = NULL)

rules &lt;- RI.indiscernibilityBasedRules.RST(decision.table, reduct)

summary(rules)
</code></pre>

<hr>
<h2 id='X.entropy'>The entropy measure</h2><span id='topic+X.entropy'></span>

<h3>Description</h3>

<p>An auxiliary function for the <code>qualityF</code> parameter in the <code><a href="#topic+FS.greedy.heuristic.reduct.RST">FS.greedy.heuristic.reduct.RST</a></code>, <code><a href="#topic+FS.DAAR.heuristic.RST">FS.DAAR.heuristic.RST</a></code> and <code><a href="#topic+FS.greedy.heuristic.superreduct.RST">FS.greedy.heuristic.superreduct.RST</a></code> functions.
It is based on <em>entropy</em> as a measure of information(Shannon, 1948).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>X.entropy(decisionDistrib)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="X.entropy_+3A_decisiondistrib">decisionDistrib</code></td>
<td>
<p>an integer vector corresponding to a distribution of attribute values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric value indicating entropy of an attribute.
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>References</h3>

<p>C. E. Shannon, &quot;A Mathematical Theory of Communication&quot;, Bell System Technical Journal, vol. 27, p. 379 - 423, 623 - 656 (1948).
</p>

<hr>
<h2 id='X.gini'>The gini-index measure</h2><span id='topic+X.gini'></span>

<h3>Description</h3>

<p>An auxiliary function for the <code>qualityF</code> parameter in the <code><a href="#topic+FS.greedy.heuristic.reduct.RST">FS.greedy.heuristic.reduct.RST</a></code>, <code><a href="#topic+FS.DAAR.heuristic.RST">FS.DAAR.heuristic.RST</a></code> and <code><a href="#topic+FS.greedy.heuristic.superreduct.RST">FS.greedy.heuristic.superreduct.RST</a></code> functions.
It is based on the <em>gini</em> index as a measure of information (Stoffel and Raileanu, 2000).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>X.gini(decisionDistrib)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="X.gini_+3A_decisiondistrib">decisionDistrib</code></td>
<td>
<p>an integer vector corresponding to a distribution of attribute values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric value indicating the gini index of an attribute.
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>References</h3>

<p>K. Stoffel and L. E. Raileanu, &quot;Selecting Optimal Split-Functions with Linear Threshold Unit Trees and Madaline-Style Networks&quot;,
in: Research and Development in Intelligent Systems XVII, BCS Conference Series (2000).
</p>

<hr>
<h2 id='X.laplace'>Rule voting by the Laplace estimate</h2><span id='topic+X.laplace'></span>

<h3>Description</h3>

<p>A function returning a weight of rule's vote understood as the Laplace estimate of its confidence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>X.laplace(rule)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="X.laplace_+3A_rule">rule</code></td>
<td>
<p>a decision rule, i.e. element of an &quot;RuleSetRST&quot; object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numerical weight of the vote
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>See Also</h3>

<p>Other currently available voting methods are: <code><a href="#topic+X.ruleStrength">X.ruleStrength</a></code>, <code><a href="#topic+X.rulesCounting">X.rulesCounting</a></code>.
</p>

<hr>
<h2 id='X.nOfConflicts'>The discernibility measure</h2><span id='topic+X.nOfConflicts'></span>

<h3>Description</h3>

<p>It is an auxiliary function for the <code>qualityF</code> parameter in the <code><a href="#topic+FS.greedy.heuristic.reduct.RST">FS.greedy.heuristic.reduct.RST</a></code> and <code><a href="#topic+FS.greedy.heuristic.superreduct.RST">FS.greedy.heuristic.superreduct.RST</a></code> functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>X.nOfConflicts(decisionDistrib)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="X.nOfConflicts_+3A_decisiondistrib">decisionDistrib</code></td>
<td>
<p>an integer vector corresponding to a distribution of decision attribute values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric value indicating a number of conflicts in a decision attribute
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>

<hr>
<h2 id='X.rulesCounting'>Rule voting by counting matching rules</h2><span id='topic+X.rulesCounting'></span>

<h3>Description</h3>

<p>A function returning an equal vote's weight for every rule. It corresponds to voting by counting the
matching rules.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>X.rulesCounting(rule)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="X.rulesCounting_+3A_rule">rule</code></td>
<td>
<p>a decision rule, i.e. element of an &quot;RuleSetRST&quot; object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numerical weight of the vote
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>See Also</h3>

<p>Other currently available voting methods are: <code><a href="#topic+X.ruleStrength">X.ruleStrength</a></code>, <code><a href="#topic+X.laplace">X.laplace</a></code>.
</p>

<hr>
<h2 id='X.ruleStrength'>Rule voting by strength of the rule</h2><span id='topic+X.ruleStrength'></span>

<h3>Description</h3>

<p>A function returning a weight of rule's vote understood as strength of the rule.
It is defined as a product of a cardinality of a support of a rule and the length of this rule.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>X.ruleStrength(rule)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="X.ruleStrength_+3A_rule">rule</code></td>
<td>
<p>a decision rule, i.e. element of a &quot;RuleSetRST&quot; object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numerical weight of the vote
</p>


<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>See Also</h3>

<p>Other currently available voting methods are: <code><a href="#topic+X.laplace">X.laplace</a></code>, <code><a href="#topic+X.rulesCounting">X.rulesCounting</a></code>.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
