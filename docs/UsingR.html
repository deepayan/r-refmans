<!DOCTYPE html><html><head><title>Help for package UsingR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {UsingR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#age.universe'><p> Best estimate of the age of the universe</p></a></li>
<li><a href='#aid'><p> monthly payment for federal program</p></a></li>
<li><a href='#alaska.pipeline'><p>Comparison of in-field and laboratory measurement of defects</p></a></li>
<li><a href='#alltime.movies'><p>Top movies of all time</p></a></li>
<li><a href='#answers'>
<p>Answers to selected problems</p></a></li>
<li><a href='#aosat'><p>Artic Oscillation data based on SAT data</p></a></li>
<li><a href='#arctic.oscillations'><p>Measurement of sea-level pressure at the arctic</p></a></li>
<li><a href='#babies'><p>Mothers and their babies data</p></a></li>
<li><a href='#babyboom'><p>Babyboom: data for 44 babies born in one 24-hour period.</p></a></li>
<li><a href='#batting'><p> Batting statistics for 2002 baseball season</p></a></li>
<li><a href='#baycheck'><p> Population estimate of type of Bay Checkerspot butterfly</p></a></li>
<li><a href='#best.times'><p> Best track and field times by age and distance</p></a></li>
<li><a href='#blood'><p> blood pressure readings</p></a></li>
<li><a href='#breakdown'><p> Time of insulating fluid to breakdown</p></a></li>
<li><a href='#bright.stars'><p> List of bright stars with Hipparcos catalog number</p></a></li>
<li><a href='#brightness'><p>Brightness of 966 stars</p></a></li>
<li><a href='#bumpers'><p> Bumper repair costs for various automobiles</p></a></li>
<li><a href='#BushApproval'><p>U.S. President George Bush approval ratings</p></a></li>
<li><a href='#bycatch'><p>Number of Albatrosses accidentaly caught during a fishing haul</p></a></li>
<li><a href='#cabinet'><p>Estimated tax savings for US President Bush's cabinet</p></a></li>
<li><a href='#camp'><p>Mount Campito Yearly Treering Data, -3435-1969.</p></a></li>
<li><a href='#cancer'><p> cancer survival times</p></a></li>
<li><a href='#carbon'><p>Carbon Monoxide levels at different sites</p></a></li>
<li><a href='#carsafety'><p>Fatality information in U.S. for several popular cars</p></a></li>
<li><a href='#central.park'><p>Weather in Central Park NY in May 2003</p></a></li>
<li><a href='#central.park.cloud'><p> Type of day in Central Park, NY May 2003</p></a></li>
<li><a href='#ceo2013'>
<p>CEO compensation in 2013</p></a></li>
<li><a href='#cfb'><p> Bootstrap sample from the Survey of Consumer Finances</p></a></li>
<li><a href='#chicken'><p>weight gain of chickens fed 3 different rations</p></a></li>
<li><a href='#chips'><p>Measurements of chip wafers</p></a></li>
<li><a href='#co2emiss'><p>Carbon Dioxide Emissions from the U.S.A. from fossil fuel</p></a></li>
<li><a href='#coins'><p>The coins in my change bin</p></a></li>
<li><a href='#coldvermont'><p>Daily minimum temperature in Woodstock Vermont</p></a></li>
<li><a href='#confint.htest'>
<p>Produce confidence interval for objects of class <code>htest</code></p></a></li>
<li><a href='#corn'><p>Comparison of corn for new and standard variety</p></a></li>
<li><a href='#crime'><p> violent crime rates in 50 states of US</p></a></li>
<li><a href='#deflection'><p> Deflection under load</p></a></li>
<li><a href='#demos'>
<p>Provide menu for possible shiny demonstrations</p></a></li>
<li><a href='#DensityPlot'><p> Plots densities of data</p></a></li>
<li><a href='#diamond'><p>Price by size for diamond rings</p></a></li>
<li><a href='#divorce'><p>Time until divorce for divorced women (by age)</p></a></li>
<li><a href='#DOTplot'><p> Make big DOT plot likestripchart</p></a></li>
<li><a href='#dottodot'><p>Dot-to-dot puzzle</p></a></li>
<li><a href='#dowdata'><p>The Dow Jones average from Jan 1999 to October 2000</p></a></li>
<li><a href='#dvdsales'><p>Monthly DVD player sales since introduction to May 2004</p></a></li>
<li><a href='#emissions'><p> CO2 emissions data and gross domestic product for 26 countries</p></a></li>
<li><a href='#errata'><p>Show errata</p></a></li>
<li><a href='#ewr'><p> Taxi in and taxi out times at EWR (Newark) airport for 1999-2001</p></a></li>
<li><a href='#exec.pay'><p> Direct compensation for 199 United States CEOs in the year 2000</p></a></li>
<li><a href='#fat'><p>Body measurements to predict percentage of body fat in males</p></a></li>
<li><a href='#father.son'><p>Pearson's data set on heights of  fathers and their sons</p></a></li>
<li><a href='#female.inc'><p> Income distribution for females in 2001</p></a></li>
<li><a href='#firstchi'><p>Age of mother at birth of first child</p></a></li>
<li><a href='#five.yr.temperature'><p> Five years of weather in New York City</p></a></li>
<li><a href='#florida'><p> County-by-county results of year 2000 US presidential election</p>
in Florida</a></li>
<li><a href='#galileo'><p> Galileo data on falling bodies</p></a></li>
<li><a href='#galton'><p> Galton's height data for parents and children</p></a></li>
<li><a href='#gap'><p> Sales data for the Gap</p></a></li>
<li><a href='#gasprices'><p> Monthly average gasoline prices in the United States</p></a></li>
<li><a href='#getAnswer'><p>function to get answer to problem</p></a></li>
<li><a href='#goalspergame'><p> Goals per game in NHL</p></a></li>
<li><a href='#google'><p> Google stock values during 2005-02-07 to 2005-07-07</p></a></li>
<li><a href='#grades'><p> Current and previous grades</p></a></li>
<li><a href='#grip'><p>Effects of cross-country ski-pole grip</p></a></li>
<li><a href='#hall.fame'><p>Data frame containing baseball statistics including Hall of Fame</p>
membership</a></li>
<li><a href='#headtail'>
<p>Show head and tail</p></a></li>
<li><a href='#healthy'><p>Healthy or not?</p></a></li>
<li><a href='#heartrate'><p>Simulated data of age vs. max heart rate</p></a></li>
<li><a href='#home'><p>Maplewood NJ homedata</p></a></li>
<li><a href='#homedata'><p> Maplewood NJ assessed values for years 1970 and 2000</p></a></li>
<li><a href='#homeprice'><p> Sale price of homes in New Jersey in the year 2001</p></a></li>
<li><a href='#homework'><p>Homework averages for Private and Public schools</p></a></li>
<li><a href='#HUMMER'><p>Deliveries of new HUMMER vehicles</p></a></li>
<li><a href='#income_percentiles'>
<p>Top percentiles of U.S. income</p></a></li>
<li><a href='#iq'><p> IQ scores</p></a></li>
<li><a href='#kid.weights'><p>Weight and height measurement for a sample of U.S. children</p></a></li>
<li><a href='#KSI'><p>Data set on automobile deaths and injuries in Great Britain</p></a></li>
<li><a href='#last.tie'><p> Last tie in 100 coin tosses</p></a></li>
<li><a href='#lawsuits'><p> Law suit settlements</p></a></li>
<li><a href='#lorem'><p>Placeholder text</p></a></li>
<li><a href='#malpract'><p> malpractice settlements</p></a></li>
<li><a href='#mandms'><p>Proportions of colors in various M and M's varieties</p></a></li>
<li><a href='#math'><p> Standardized math scores</p></a></li>
<li><a href='#maydow'><p> Dow Jones industrial average and May maximum temperature</p></a></li>
<li><a href='#Medicare'>
<p>Sample from &quot;Medicare Provider Charge Data&quot;</p></a></li>
<li><a href='#midsize'><p> Price of new and used of three mid-sized cars</p></a></li>
<li><a href='#MLBattend'><p>Major league baseball attendance data</p></a></li>
<li><a href='#movie_data_2011'><p>Movie data for 2011 by weekend</p></a></li>
<li><a href='#movies'><p>Data frome on top 25 movies for some week, many weeks ago</p></a></li>
<li><a href='#mw.ages'><p> Age distribution in year 2000 in Maplewood New Jersey</p></a></li>
<li><a href='#nba.draft'><p> NBA draft lottery odds for 2002</p></a></li>
<li><a href='#nisdc'>
<p>NISCD</p></a></li>
<li><a href='#normtemp'><p> Body temperature and heart rate of 130 health individuals</p></a></li>
<li><a href='#npdb'><p> National Practioner Data Bank</p></a></li>
<li><a href='#nym.2002'><p>Random sample of 2002 New York City Marathon finishers</p></a></li>
<li><a href='#ObamaApproval'>
<p>Approval ratings for President Obama</p></a></li>
<li><a href='#OBP'><p> On base percentage for 2002 major league baseball season</p></a></li>
<li><a href='#oral.lesion'><p>Oral lesion location by town</p></a></li>
<li><a href='#ozonemonthly'><p>Monthly mean ozone values at Halley Bay Antartica</p></a></li>
<li><a href='#paradise'><p> Annual snowfall at Paradise Ranger Station, Mount Ranier</p></a></li>
<li><a href='#pi2000'><p>first 2000 digits of pi</p></a></li>
<li><a href='#primes'><p> Primes numbers less than 2003</p></a></li>
<li><a href='#puerto'><p>Incomes for Puerto Rican immigrants to Miami</p></a></li>
<li><a href='#QQplot'><p> Creates a qqplot with shaded density estimate</p></a></li>
<li><a href='#rat'><p>Survival times of 20 rats exposed to radiation</p></a></li>
<li><a href='#reaction.time'><p>Reaction time with cell phone usage</p></a></li>
<li><a href='#reddrum'><p>Growth of red drum</p></a></li>
<li><a href='#salmon.rate'><p>Simulated Data on Rate of Recruitment for Salmon</p></a></li>
<li><a href='#salmonharvest'><p> Salmon harvest in Alaska from 1980 to 1998</p></a></li>
<li><a href='#samhda'><p> Substance Abuse and Mental Health Data for teens</p></a></li>
<li><a href='#SAT'>
<p>SAT data with expenditures</p></a></li>
<li><a href='#scatter.with.hist'><p> Scatterplot with histograms</p></a></li>
<li><a href='#scrabble'><p> Distribution of Scrabble pieces</p></a></li>
<li><a href='#simple.chutes'><p>simulate a chutes and ladder game</p></a></li>
<li><a href='#simple.densityplot'><p> Plots densities of data</p></a></li>
<li><a href='#simple.eda'><p> Simple function to plot histogram, boxplot and normal plot</p></a></li>
<li><a href='#simple.eda.ts'><p>Makes 3 useful graphs for eda of times series</p></a></li>
<li><a href='#simple.fancy.stripchart'><p> Makes a fancier strip chart: plots means and a line</p></a></li>
<li><a href='#simple.freqpoly'><p> Simply plot histogram and frequency polygon</p></a></li>
<li><a href='#simple.hist.and.boxplot'><p>A function to plot both a histogram and a boxplot</p></a></li>
<li><a href='#simple.lag'><p> applies function to moving subsets of a data vector</p></a></li>
<li><a href='#simple.lm'><p> Simplify usage of lm</p></a></li>
<li><a href='#simple.median.test'><p> Do simple sign test for median &ndash; no ranks</p></a></li>
<li><a href='#simple.scatterplot'><p> Simple scatter plot of x versus y with histograms of each</p></a></li>
<li><a href='#simple.sim'><p>Simplify the process of simulation</p></a></li>
<li><a href='#simple.violinplot'><p> Plots violinplots instead of boxplots</p></a></li>
<li><a href='#simple.z.test'><p> Implement basic z-test for illustrative purposes</p></a></li>
<li><a href='#skateranks'><p> Judges scores for disputed ice skating competition</p></a></li>
<li><a href='#slc'><p> Sodium-Lithium countertransport</p></a></li>
<li><a href='#smokyph'><p>Water pH levels at 75 water samples in the Great Smoky Mountains</p></a></li>
<li><a href='#snacks'>
<p>Snack data from the USDA</p></a></li>
<li><a href='#south'><p> Murder rates for 30 Southern US cities</p></a></li>
<li><a href='#southernosc'><p> Southern Oscillations</p></a></li>
<li><a href='#sp500.excess'><p> Excess returns of S\&amp;P 500</p></a></li>
<li><a href='#Split.zoo'><p> Add split method for zoo objects</p></a></li>
<li><a href='#squareplot'><p> Create a squareplot alternative to a segmented barplot</p></a></li>
<li><a href='#stud.recs'><p> Student records</p></a></li>
<li><a href='#student.expenses'><p>Some simulated data on student expenses</p></a></li>
<li><a href='#superbarplot'><p> super segmented barplot</p></a></li>
<li><a href='#tastesgreat'><p>Does new goo taste great?</p></a></li>
<li><a href='#tcm1y'><p> One-year treasury security values</p></a></li>
<li><a href='#tempsalinity'><p>Temperature/Salinity measurements along a moving Eddy</p></a></li>
<li><a href='#too.young'><p> What age is too young for a male to data a female?</p></a></li>
<li><a href='#twins'><p>Burt's IQ data for twins</p></a></li>
<li><a href='#u2'><p>Song and lengths for U2 albums</p></a></li>
<li><a href='#urchin.growth'><p> Data on growth of sea urchins</p></a></li>
<li><a href='#vacation'><p>vacation days</p></a></li>
<li><a href='#violinplot'><p> Plots violinplots instead of boxplots</p></a></li>
<li><a href='#watertemp'><p>Temperature measurement of water at 85m depth</p></a></li>
<li><a href='#wchomes'>
<p>A random sample of Wake County, North Carolina residential real estate plots</p></a></li>
<li><a href='#wellbeing'>
<p>What makes us happy?</p></a></li>
<li><a href='#yahoo.get.hist.quote'><p> Download stock data from Yahoo!</p></a></li>
<li><a href='#yellowfin'><p>Yellow fin tuna catch rate in Tropical Indian Ocean</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>2.0-7</td>
</tr>
<tr>
<td>Title:</td>
<td>Data Sets, Etc. for the Text "Using R for Introductory
Statistics", Second Edition</td>
</tr>
<tr>
<td>Author:</td>
<td>John Verzani &lt;verzani@math.csi.cuny.edu&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>John Verzani &lt;verzani@math.csi.cuny.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>A collection of data sets to accompany the
    textbook "Using R for Introductory Statistics," second
    edition.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.15.0), MASS, HistData, Hmisc</td>
</tr>
<tr>
<td>Suggests:</td>
<td>zoo, ggplot2, vcd, lubridate, aplpack</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-01-10 19:16:26 UTC; jverzani</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-01-11 09:52:45 UTC</td>
</tr>
</table>
<hr>
<h2 id='age.universe'> Best estimate of the age of the universe</h2><span id='topic+age.universe'></span>

<h3>Description</h3>

<p>For years people have tried to estimate the age of the universe. This
data set collects a few estimates starting with lower bounds using
estimates for the earth's age.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(age.universe)</code></pre>


<h3>Format</h3>

<p>A data frame with 16 observations on the following 4 variables.
</p>

<dl>
<dt>lower</dt><dd><p>a numeric vector</p>
</dd>
<dt>upper</dt><dd><p>a numeric vector</p>
</dd>
<dt>year</dt><dd><p>a numeric vector</p>
</dd>
<dt>source</dt><dd><p>Short description of source</p>
</dd>
</dl>



<h3>Details</h3>

<p>In the last two decades estimates for the age of the universe have
been greatly improved. As of 2013, the best guess is 13.7 billion
years with a margin of error of 1 percent. This last estimate is found
by WMAP using microwave background radiation. Previous estimates were
also based on estimates of Hubble's constant, and dating of old stars.
</p>


<h3>Source</h3>

<p>This data was collected from the following web sites:
<a href="https://arxiv.org/abs/1212.5225">https://arxiv.org/abs/1212.5225</a>,
https://case.edu/pubaff/univcomm/2003/1-03/kraussuniverse.html (now off-line),
<a href="https://www.astro.ucla.edu/~wright/age.html">https://www.astro.ucla.edu/~wright/age.html</a>,
http://www.lhup.edu/~dsimanek/cutting/ageuniv.htm (now off-line), and
<a href="https://map.gsfc.nasa.gov/m_uni/uni_101age.html">https://map.gsfc.nasa.gov/m_uni/uni_101age.html</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(age.universe)
n &lt;- nrow(age.universe)
x &lt;- 1:n
names(x) = age.universe$year
plot(x,age.universe$upper,ylim=c(0,20))
points(x,age.universe$lower)
with(age.universe,sapply(x,function(i) lines(c(i,i),c(lower[i],upper[i]))))
</code></pre>

<hr>
<h2 id='aid'> monthly payment for federal program </h2><span id='topic+aid'></span>

<h3>Description</h3>

<p> monthly payment for federal program </p>


<h3>Usage</h3>

<pre><code class='language-R'>data(aid)</code></pre>


<h3>Format</h3>

<p>The format is:
Named num [1:51]  57.2 253.5 114.2  68.2 199.6 ...
- attr(*, &quot;names&quot;)= chr [1:51] &quot;Alabama&quot; &quot;Alaska&quot; &quot;Arizona&quot; &quot;Arkansas&quot; ...
</p>


<h3>Source</h3>

<p>From Kitchen's Exploring Statistics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(aid)
hist(aid)
</code></pre>

<hr>
<h2 id='alaska.pipeline'>Comparison of in-field and laboratory measurement of defects </h2><span id='topic+alaska.pipeline'></span>

<h3>Description</h3>

<p>The Alaska pipeline data consists of in-field ultrasonic measurements
of the depths of defects in the Alaska pipeline. The depth of the
defects were then re-measured in the laboratory. These measurements
were performed in six different batches.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(alaska.pipeline)</code></pre>


<h3>Format</h3>

<p>A data frame with 107 observations on the following 3 variables.
</p>

<dl>
<dt>field.defect</dt><dd><p>Depth of defect as measured in field</p>
</dd>
<dt>lab.defect</dt><dd><p>Depth of defect as measured in lab</p>
</dd>
<dt>batch</dt><dd><p>One of 6 batches</p>
</dd>
</dl>



<h3>Source</h3>

<p>From an example in <em>Engineering Statistics Handbook</em> from http://www.itl.nist.gov/div898/handbook/
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(alaska.pipeline)
res = lm(lab.defect ~ field.defect, alaska.pipeline)
plot(lab.defect ~ field.defect, alaska.pipeline)
abline(res)
plot(fitted(res),resid(res))
</code></pre>

<hr>
<h2 id='alltime.movies'>Top movies of all time</h2><span id='topic+alltime.movies'></span>

<h3>Description</h3>

<p>The top 79 all-time movies as of 2003 by domestic (US) gross receipts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(alltime.movies)</code></pre>


<h3>Format</h3>

<p>A data frame with 79 observations on the following 2 variables.
</p>

<dl>
<dt>Gross</dt><dd><p>a numeric vector</p>
</dd>
<dt>Release.Year</dt><dd><p>a numeric vector</p>
</dd>
</dl>

<p>The row names are the titles of the movies.
</p>


<h3>Source</h3>

<p>This data was found on http://movieweb.com/movie/alltime.html on
June 17, 2003. The source of the data is attributed to (partially)
Exhibitor Relations Co. .
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(alltime.movies)
hist(alltime.movies$Gross)
</code></pre>

<hr>
<h2 id='answers'>
Answers to selected problems
</h2><span id='topic+answers'></span>

<h3>Description</h3>

<p>Opens pdf file containing answers to selected problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>answers()
</code></pre>


<h3>Value</h3>

<p>Called for its side-effect of opening a pdf
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## answers()
</code></pre>

<hr>
<h2 id='aosat'>Artic Oscillation data based on SAT data</h2><span id='topic+aosat'></span>

<h3>Description</h3>

<p>A time series of January, February, and March measurements of the
annular modes from January 1851 to March 1997.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(aosat)</code></pre>


<h3>Format</h3>

<p>The format is: first column is date in years with fraction to indicate
month. The second column is the measurement.
</p>


<h3>Details</h3>

<p>This site http://jisao.washington.edu/ao/ had more details on the
importance of this time series.
</p>


<h3>Source</h3>

<p>This data came from the file AO\_SATindex\_JFM\_Jan1851March1997.ascii at
http://www.atmos.colostate.edu/ao/Data/ao\_index.html
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(aosat)
## Not run: 
library(zoo)
z = zoo(aosat[,2], order.by=aosat[,1])
plot(z)
## yearly
plot(aggregate(z, floor(index(z)), mean))
## decade-long means
plot(aggregate(z, 10*floor(index(z)/10), mean))

## End(Not run)
</code></pre>

<hr>
<h2 id='arctic.oscillations'>Measurement of sea-level pressure at the arctic</h2><span id='topic+arctic.oscillations'></span>

<h3>Description</h3>

<p>A monthly time series from January 1899 to June 2002 of sea-level
pressure measurements relative to some baseline. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(arctic.oscillations)</code></pre>


<h3>Format</h3>

<p>The format is:
chr &quot;arctic.oscillations&quot;
</p>


<h3>Details</h3>

<p>See <a href="https://toptotop.org/">https://toptotop.org/</a> for more details on the
importance of climate studies.
</p>


<h3>Source</h3>

<p>The data came from the file AO\_TREN\_NCEP\_Jan1899Current.ascii found many years ago at
http://www.atmos.colostate.edu/ao/Data/ao\_index.html.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(arctic.oscillations)
x = ts(arctic.oscillations, start=c(1899,1), frequency=12)
plot(x)
</code></pre>

<hr>
<h2 id='babies'>Mothers and their babies data</h2><span id='topic+babies'></span>

<h3>Description</h3>

<p>A collection of variables taken for each new mother in a Child and
Health Development Study.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(babies)</code></pre>


<h3>Format</h3>

<p>A data frame with 1,236 observations on the following 23 variables.
</p>

<p>Variables in data file
</p>
<dl>
<dt>id</dt><dd><p>identification number</p>
</dd>
<dt>pluralty</dt><dd><p> 5= single fetus</p>
</dd>
<dt>outcome</dt><dd><p>1= live birth that survived at least 28 days</p>
</dd>
<dt>date</dt><dd><p>birth date where 1096=January1,1961 </p>
</dd>
<dt>gestation</dt><dd><p>length of gestation in days</p>
</dd>
<dt>sex</dt><dd><p>infant's sex 1=male 2=female 9=unknown</p>
</dd>
<dt>wt</dt><dd><p> birth weight in ounces (999 unknown)</p>
</dd>
<dt>parity</dt><dd><p>total number of previous pregnancies including
fetal deaths and still births, 99=unknown</p>
</dd>
<dt>race</dt><dd><p>mother's race 0-5=white 6=mex 7=black 8=asian 9=mixed 99=unknown </p>
</dd>
<dt>age</dt><dd><p>mother's age in years at termination of pregnancy, 99=unknown</p>
</dd>
<dt>ed</dt><dd><p>mother's education 0= less than 8th grade,
1 = 8th -12th grade - did not graduate,
2= HS graduate&ndash;no other schooling , 3= HS+trade,
4=HS+some college 5= College graduate, 6\&amp;7 Trade school HS
unclear, 9=unknown
</p>
</dd>
<dt>ht</dt><dd><p>mother's height in inches to the last completed inch
99=unknown</p>
</dd>
<dt>wt1</dt><dd><p>mother prepregnancy wt in pounds, 999=unknown </p>
</dd>
<dt>drace</dt><dd><p>father's race, coding same as mother's race.</p>
</dd>
<dt>dage</dt><dd><p>father's age, coding same as mother's age.</p>
</dd>
<dt>ded </dt><dd><p>father's education, coding same as mother's education.</p>
</dd>
<dt>dht</dt><dd><p>father's height, coding same as for mother's height</p>
</dd>
<dt>dwt </dt><dd><p>father's weight coding same as for mother's weight</p>
</dd>
<dt>marital</dt><dd><p> 1=married, 2= legally separated, 3= divorced,
4=widowed, 5=never married</p>
</dd>
<dt>inc</dt><dd><p>family yearly income in \$2500 increments 0 = under 2500,
1=2500-4999, ..., 8= 12,500-14,999, 9=15000+,
98=unknown, 99=not asked</p>
</dd>
<dt>smoke</dt><dd><p>does mother smoke? 0=never, 1= smokes now,
2=until current pregnancy, 3=once did, not now, 9=unknown</p>
</dd>
<dt>time</dt><dd><p>If mother quit, how long ago? 0=never smoked, 1=still smokes,
2=during current preg, 3=within 1 yr, 4= 1 to 2 years ago,
5= 2 to 3 yr ago, 6= 3 to 4 yrs ago, 7=5 to 9yrs ago,
8=10+yrs ago, 9=quit and don't know, 98=unknown, 99=not asked </p>
</dd>
<dt>number </dt><dd><p>number of cigs smoked per day for past and current
smokers 0=never, 1=1-4,2=5-9, 3=10-14, 4=15-19, 5=20-29, 6=30-39,
7=40-60, 8=60+, 9=smoke but don't know,98=unknown, 99=not asked</p>
</dd>
</dl>



<h3>Source</h3>

<p>This dataset is found from
<a href="https://www.stat.berkeley.edu/users/statlabs/labs.html">https://www.stat.berkeley.edu/users/statlabs/labs.html</a>. It
accompanies the excellent text <em>Stat Labs: Mathematical
Statistics through Applications</em> Springer-Verlag (2001) by Deborah
Nolan and Terry Speed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(babies)
plot(wt ~ factor(smoke), data=babies)
plot(wt1 ~ dwt, data=babies, subset=wt1 &lt; 800 &amp; dwt &lt; 800)
</code></pre>

<hr>
<h2 id='babyboom'>Babyboom: data for 44 babies born in one 24-hour period.</h2><span id='topic+babyboom'></span>

<h3>Description</h3>

<p>The <code>babyboom</code> dataset contains the time of birth, sex, and birth
weight for 44 babies born in one 24-hour period at a hospital in
Brisbane, Australia.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(babyboom)</code></pre>


<h3>Format</h3>

<p>A data frame with 44 observations on the following 4 variables.
</p>

<dl>
<dt>clock.time</dt><dd><p>Time on clock</p>
</dd>
<dt>gender</dt><dd><p>a factor with levels <code>girl</code> <code>boy</code></p>
</dd>
<dt>wt</dt><dd><p>weight in grams of child</p>
</dd>
<dt>running.time</dt><dd><p>minutes after midnight of birth</p>
</dd>
</dl>



<h3>Source</h3>

<p>This data set was submitted to the <em>Journal of Statistical
Education</em>,
https://www.amstat.org/publications/jse/secure/v7n3/datasets.dunn.cfm (now off-line),
by Peter K. Dunn.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(babyboom)
hist(babyboom$wt)
hist(diff(babyboom$running.time))
</code></pre>

<hr>
<h2 id='batting'> Batting statistics for 2002 baseball season</h2><span id='topic+batting'></span>

<h3>Description</h3>

<p>This dataset contains batting statistics for the 2002 baseball
season. The data allows you to compute batting averages, on base
percentages, and other statistics of interest to baseball fans. The
data only contains players with more than 100 atbats for a team in the
year. The data is excerpted with permission from the Lahman baseball
database at <a href="http://www.seanlahman.com/">http://www.seanlahman.com/</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(batting)</code></pre>


<h3>Format</h3>

<p>A data frame with 438 observations on the following 22 variables.
</p>

<dl>
<dt>playerID</dt><dd><p>This is coded, but those familiar with the players
should be able to find their favorites.</p>
</dd>
<dt>yearID</dt><dd><p>a numeric vector. Always 2002 in this dataset.</p>
</dd>
<dt>stintID</dt><dd><p>a numeric vector. Player's stint (order of appearances within a season)</p>
</dd>
<dt>teamID</dt><dd><p>a factor with Team</p>
</dd>
<dt>lgID</dt><dd><p>a factor with levels <code>AL</code> <code>NL</code></p>
</dd>
<dt>G</dt><dd><p>number of games played</p>
</dd>
<dt>AB</dt><dd><p>number of at bats</p>
</dd>
<dt>R</dt><dd><p>number of runs</p>
</dd>
<dt>H</dt><dd><p>number of hits</p>
</dd>
<dt>DOUBLE</dt><dd><p>number of doubles. &quot;2B&quot; in original dat
a base.</p>
</dd>
<dt>TRIPLE</dt><dd><p>number of triples. &quot;3B&quot; in original data base</p>
</dd>
<dt>HR</dt><dd><p>number of home runs</p>
</dd>
<dt>RBI</dt><dd><p>number of runs batted in</p>
</dd>
<dt>SB</dt><dd><p>number of stolen bases</p>
</dd>
<dt>CS</dt><dd><p>number of times caught stealing</p>
</dd>
<dt>BB</dt><dd><p>number of base on balls (walks)</p>
</dd>
<dt>SO</dt><dd><p>number of strikeouts</p>
</dd>
<dt>IBB</dt><dd><p>number of intentional walks</p>
</dd>
<dt>HBP</dt><dd><p>number of hit by pitches</p>
</dd>
<dt>SH</dt><dd><p>number of sacrifice hits</p>
</dd>
<dt>SF</dt><dd><p>number of sacrifice flies</p>
</dd>
<dt>GIDP</dt><dd><p>number of grounded into double plays</p>
</dd>
</dl>



<h3>Details</h3>

<p>Baseball fans are &ldquo;statistics&rdquo; crazy. They love to talk about things
like RBIs, BAs and OBPs. In order to do so, they need the
numbers. This data comes from the Lahman baseball
database at <a href="http://www.seanlahman.com/">http://www.seanlahman.com/</a>. The complete dataset
includes data for all of baseball not just the year 2002 presented here.
</p>


<h3>Source</h3>

<p>Lahman baseball database, <a href="http://www.seanlahman.com/)">http://www.seanlahman.com/)</a>
</p>


<h3>References</h3>

<p>In addition to the data set above, the book
<em>Curve Ball</em>, by Albert, J. and Bennett, J., Copernicus Books,
gives an extensive statistical analysis of baseball.
</p>
<p>See <a href="https://www.baseball-almanac.com/stats.shtml">https://www.baseball-almanac.com/stats.shtml</a> for definitions
of common baseball statistics.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(batting)
attach(batting)
BA = H/AB			# batting average
OBP = (H + BB + HBP) / (AB + BB + HBP + SF) # On base "percentage"
</code></pre>

<hr>
<h2 id='baycheck'> Population estimate of type of Bay Checkerspot butterfly</h2><span id='topic+baycheck'></span>

<h3>Description</h3>

<p>Estimates of the population of a type of Bay Checkerspot butterfly
near San Francisco.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(baycheck)</code></pre>


<h3>Format</h3>

<p>A data frame with 27 observations on the following 2 variables.
</p>

<dl>
<dt>year</dt><dd><p>a numeric vector</p>
</dd>
<dt>Nt</dt><dd><p>estimated number</p>
</dd>
</dl>



<h3>Source</h3>

<p>From chapter 4 of Morris and Doak, <em>Quantitative Conservation
Biology: Theory and Practice of Population Viability Analysis</em>,
Sinauer Associates, 2003.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(baycheck)
plot(Nt ~ year,baycheck)
## fit Ricker model N_{t+1} = N_t e^{-rt}W_t
n = length(baycheck$year)
yt = with(baycheck,log(Nt[-1]/Nt[-n]))
nt = with(baycheck,Nt[-n])
lm(yt ~ nt,baycheck)
</code></pre>

<hr>
<h2 id='best.times'> Best track and field times by age and distance</h2><span id='topic+best.times'></span>

<h3>Description</h3>

<p>A dataset giving world records in track and field running events for various
distances and different age groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(best.times)</code></pre>


<h3>Format</h3>

<p>A data frame with 113 observations on the following 6 variables.
</p>

<dl>
<dt>Dist</dt><dd><p>Distance in meters (42195 is a marathon)</p>
</dd>
<dt>Name</dt><dd><p>Name of record holder</p>
</dd>
<dt>Date</dt><dd><p>Date of record</p>
</dd>
<dt>Time</dt><dd><p>Time in seconds</p>
</dd>
<dt>Time.1</dt><dd><p>Time as character</p>
</dd>
<dt>age</dt><dd><p>Age at time of record</p>
</dd>
</dl>



<h3>Details</h3>

<p>Age-graded race results allow competitors of different ages to compare
their race performances. This data set allows one to see what the
relationship is based on peak performances.  
</p>


<h3>Source</h3>

<p>The data came from
http://www.personal.rdg.ac.uk/~snsgrubb/athletics/agegroups.html
which included a calculator to compare results.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(best.times)
attach(best.times)
by.dist = split(best.times,as.factor(Dist))
lm(scale(Time) ~ age, by.dist[['400']])
dists = names(by.dist)
lapply(dists, function(n) print(lm(scale(Time) ~ age, by.dist[[n]])))
</code></pre>

<hr>
<h2 id='blood'> blood pressure readings </h2><span id='topic+blood'></span>

<h3>Description</h3>

<p>blood pressure of 15 males taken by machine and expert
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(blood)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>Machine</dt><dd><p>a numeric vector</p>
</dd>
<dt>Expert</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>Taken from Kitchen's Exploring Statistics.
</p>


<h3>References</h3>

<p>~~ possibly secondary sources and usages ~~
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(blood)
attach(blood)
t.test(Machine,Expert)
detach(blood)
</code></pre>

<hr>
<h2 id='breakdown'> Time of insulating fluid to breakdown</h2><span id='topic+breakdown'></span>

<h3>Description</h3>

<p>The time in minutes for an insulating fluid to break down under
varying voltage loads
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(breakdown)</code></pre>


<h3>Format</h3>

<p>A data frame with 75 observations on the following 2 variables.
</p>

<dl>
<dt>voltage</dt><dd><p>Number of kV</p>
</dd>
<dt>time</dt><dd><p>time in minutes</p>
</dd>
</dl>



<h3>Details</h3>

<p>An example from industry where a linear model is used with replication
and transformation of variables.
</p>


<h3>Source</h3>

<p>Data is from Display 8.3 of Ramsay and Shafer, <em>The Statistical
Sleuth</em> Duxbury Press, 1997.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(breakdown)
plot(log(time) ~ voltage, data = breakdown)
</code></pre>

<hr>
<h2 id='bright.stars'> List of bright stars with Hipparcos catalog number</h2><span id='topic+bright.stars'></span>

<h3>Description</h3>

<p>List of bright stars with Hipparcos catalog number.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(bright.stars)</code></pre>


<h3>Format</h3>

<p>A data frame with 96 observations on the following 2 variables.
</p>

<dl>
<dt>name</dt><dd><p>Common name of star</p>
</dd>
<dt>hip</dt><dd><p>HIP number for identification</p>
</dd>
</dl>



<h3>Details</h3>

<p>The source of star names goes back to the Greeks and Arabs. Few are
modern. This is a list of 96 common stars.
</p>


<h3>Source</h3>

<p>Form the Hipparcos website http://astro.estec.esa.nl/Hipparcos/ident6.html.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bright.stars)
all.names  = paste(bright.stars$name, sep="", collapse="")
x = unlist(strsplit(tolower(all.names), ""))
letter.dist = sapply(letters, function(i) sum(x == i))
data(scrabble)			#  for frequency info
p = scrabble$frequency[1:26];p=p/sum(p)
chisq.test(letter.dist, p=p)	# compare with English
</code></pre>

<hr>
<h2 id='brightness'>Brightness of 966 stars</h2><span id='topic+brightness'></span>

<h3>Description</h3>

<p>The Hipparcos Catalogue has information on over 100,000 stars. Listed
in this dataset are brightness measurements for 966 stars from a given
sector of the sky.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(brightness)</code></pre>


<h3>Format</h3>

<p>A univariate dataset of 966 numbers.
</p>


<h3>Details</h3>

<p>This is field H5 in the catalog measuring the magnitude, V , in the
Johnson UBV photometric system. The smaller numbers are for brighter stars.
</p>


<h3>Source</h3>

<p>http://astro.estec.esa.nl/hipparcos
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(brightness)
hist(brightness)
</code></pre>

<hr>
<h2 id='bumpers'> Bumper repair costs for various automobiles</h2><span id='topic+bumpers'></span>

<h3>Description</h3>

<p> bumper repair costs </p>


<h3>Usage</h3>

<pre><code class='language-R'>data(bumpers)</code></pre>


<h3>Format</h3>

<p>Price in dollars to repair a bumper.
</p>


<h3>Source</h3>

<p>From <em>Exploring Statistics</em>, Duxbury Press, 1998, L. Kitchens.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bumpers)
stem(bumpers)
</code></pre>

<hr>
<h2 id='BushApproval'>U.S. President George Bush approval ratings</h2><span id='topic+BushApproval'></span>

<h3>Description</h3>

<p>Approval ratings as reported by six different polls.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(BushApproval)</code></pre>


<h3>Format</h3>

<p>A data frame with 323 observations on the following 3 variables.
</p>

<dl>
<dt>date</dt><dd><p>The date poll was begun (some take a few days)</p>
</dd>
<dt>approval</dt><dd><p>a numeric number between 0 and 100</p>
</dd>
<dt>who</dt><dd><p>a factor with levels <code>fox</code> <code>gallup</code> <code>newsweek</code> <code>time.cnn</code> <code>upenn</code> <code>zogby</code></p>
</dd>
</dl>



<h3>Details</h3>

<p>A data set of approval ratings of George Bush over the time of his
presidency, as reported by several agencies. Most polls were of size
approximately 1,000 so the margin of error is about 3 percentage points.
</p>


<h3>Source</h3>

<p>This data was found at
http://www.pollingreport.com/BushJob.htm. The idea came from an
article in <em>Salon</em>
http://salon.com/opinion/feature/2004/02/09/bush_approval/index.html  by James K. Galbraith.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(BushApproval)
attach(BushApproval)

## Plot data with confidence intervals. Each poll gets different line type
## no points at first
plot(strptime(date,"%m/%d/%y"),approval,type="n",
     ylab = "Approval Rating",xlab="Date",
     ylim=c(30,100)
     )

## plot line for CI. Margin or error about 3
## matlines has trouble with dates from strptime()
colors = rainbow(6)

for(i in 1:nrow(BushApproval)) {
  lines(rep(strptime(date[i],"%m/%d/%y"),2),
        c(approval[i]-3,approval[i]+3),
        lty=as.numeric(who[i]),
        col=colors[as.numeric(who[i])]
        )
  
}

## plot points
points(strptime(date,"%m/%d/%y"),approval,pch=as.numeric(who))

## add legend
legend((2003-1970)*365*24*60*60,90,legend=as.character(levels(who)),lty=1:6,col=1:6)
detach(BushApproval)
</code></pre>

<hr>
<h2 id='bycatch'>Number of Albatrosses accidentaly caught during a fishing haul</h2><span id='topic+bycatch'></span>

<h3>Description</h3>

<p>This data set from Hillborn and Mangel contains data on the number of
Albatrosses accidentally caught while fishing by commercial
fisheries. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(bycatch)</code></pre>


<h3>Format</h3>

<p>A data frame with 18 observations on the following 2 variables.
</p>

<dl>
<dt>no.albatross</dt><dd><p>The number of albatross caught</p>
</dd>
<dt>no.hauls</dt><dd><p>Number of hauls with this many albatross caught</p>
</dd>
</dl>



<h3>Details</h3>

<p>During fishing operations non-target species are often captured. These
are called &ldquo;incidental catch&rdquo;. In some cases, large-scale observer
programs are used to monitor this incidental catch.
</p>
<p>When fishing for squid, albatrosses are caught while feeding on the
squid at the time of fising. This feeding is encouraged while the net
is being hauled in, as the squid are clustered making it  an opportunistic
time for the albatross to eat.
</p>


<h3>Source</h3>

<p>This is from Hilborn and Mangel, <em>The Ecological Detective</em>,
Princeton University Press, 1997. Original source of data is Bartle.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bycatch)
hauls = with(bycatch,rep(no.albatross,no.hauls))
</code></pre>

<hr>
<h2 id='cabinet'>Estimated tax savings for US President Bush's cabinet</h2><span id='topic+cabinet'></span>

<h3>Description</h3>

<p>Estimated savings from a repeal of the tax on capital gains and
dividends for Bush's cabinet members.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cabinet)</code></pre>


<h3>Format</h3>

<p>A data frame with 19 observations on the following 4 variables.
</p>

<dl>
<dt>name</dt><dd><p>Name of individual</p>
</dd>
<dt>position</dt><dd><p>Position of individual</p>
</dd>
<dt>est.dividend.cg</dt><dd><p>Estimated amount of dividend and capital gain
income</p>
</dd>
<dt>est.tax.savings</dt><dd><p>Estimated tax savings</p>
</dd>
</dl>



<h3>Details</h3>

<p>Quoting from the data source
http://www.house.gov/reform/min/pdfs_108/pdf_inves/pdf_admin_tax_law_cabinet_june_3_rep.pdf (From Henry Waxman, congressional watchdog.)
</p>
<p>&ldquo;On May 22, 2003, the House of Representatives and the Senate passed
tax legislation that included \$320 billion in tax cuts. The final tax
cut bill was signed into law by President Bush on May 28, 2003. The
largest component of the new tax law is the reduction of tax rates on
both capital gains and dividend income. The law also includes the
acceleration of future tax cuts, as well as new tax reductions for
businesses.
</p>
<p>This capital gains and dividend tax cut will have virtually no impact
on the average American. The vast majority of Americans (88
no capital gains on their tax returns. These taxpayers will receive
no tax savings at all from the reduction in taxes on capital
gains. Similarly, most Americans (75
from the reduction of taxes on dividends.
</p>
<p>While the average American will derive little, if any, benefit from the
cuts in dividend and capital gains taxes, the law offers significant
benefits to the wealthy. For example, the top 1
receive an average tax cut of almost \$21,000 each. In particular, some
of the major beneficiaries of this plan will be Vice President Cheney,
President Bush, and other members of the cabinet. Based on 2001 and 2002
dividends and capital gains income, Vice President Cheney, President
Bush, and the cabinet are estimated to receive an average tax cut of at
least \$42,000 per year. Their average tax savings equals the median
household income in the United States.&rdquo;
</p>


<h3>Source</h3>

<p>From http://www.house.gov/reform/min/pdfs_108/pdf_inves/pdf_admin_tax_law_cabinet_june_3_rep.pdfx
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cabinet)
attach(cabinet)
median(est.dividend.cg)
mean(est.dividend.cg)
detach(cabinet)
</code></pre>

<hr>
<h2 id='camp'>Mount Campito Yearly Treering Data, -3435-1969.</h2><span id='topic+camp'></span>

<h3>Description</h3>

<p>Contains annual tree-ring measurements from Mount Campito from
3426 BC through 1969 AD.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(camp)</code></pre>


<h3>Format</h3>

<p>A univariate time series with 5405 observations. The object is of
class '&quot;ts&quot;'.
</p>


<h3>Details</h3>

<p>This series is a standard example for the concept of long memory
time series.
</p>
<p>The data was produced and assembled at the Tree Ring Laboratory at
the University of Arizona, Tuscon.
</p>


<h3>Source</h3>

<p>Time Series Data
Library:<a href="https://robjhyndman.com/TSDL/">https://robjhyndman.com/TSDL/</a> 
</p>


<h3>References</h3>

<p>This data set is in the tseries package. It is repackaged here for
convenience only.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(camp)
acf(camp)
</code></pre>

<hr>
<h2 id='cancer'> cancer survival times  </h2><span id='topic+cancer'></span>

<h3>Description</h3>

<p> cancer survival times </p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cancer)</code></pre>


<h3>Format</h3>

<p>The format is:
The format is:
List of 5 numeric components stomach, bronchus, colon, ovary and breast
</p>


<h3>Source</h3>

<p>Taken  from L. Kitchens, <em>Exploring Statistics</em>, Duxbury Press, 1997.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cancer)
boxplot(cancer)
</code></pre>

<hr>
<h2 id='carbon'>Carbon Monoxide levels at different sites </h2><span id='topic+carbon'></span>

<h3>Description</h3>

<p>Carbon Monoxide levels at different sites 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(carbon)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>Monoxide</dt><dd><p>a numeric vector</p>
</dd>
<dt>Site</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>Borrowed from Kitchen's Exploring Statistics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(carbon)
boxplot(Monoxide ~ Site,data=carbon)
</code></pre>

<hr>
<h2 id='carsafety'>Fatality information in U.S. for several popular cars</h2><span id='topic+carsafety'></span>

<h3>Description</h3>

<p>Safety statistics appearing in a January 12th, 2004 issue of the <em>New
Yorker</em>  showing fatality rates per million vehicles both for
drivers of a car, and drivers of other cars that are hit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(carsafety)</code></pre>


<h3>Format</h3>

<p>A data frame with 33 observations on the following 4 variables.
</p>

<dl>
<dt>Make.model</dt><dd><p>The make and model of the car</p>
</dd>
<dt>type</dt><dd><p>Type of car</p>
</dd>
<dt>Driver.deaths</dt><dd><p>Number of drivers deaths per year if 1,000,000 cars
were on the road</p>
</dd>
<dt>Other.deaths</dt><dd><p>Number of deaths in other vehicle caused by
accidents involving
these cars per year if 1,000,000 cars were on the road</p>
</dd>
</dl>



<h3>Details</h3>

<p>The article this data came from wishes to make the case that SUVs are
not safer despite a perception among the U.S. public that they are.
</p>


<h3>Source</h3>

<p>From &quot;Big and Bad&quot; by Malcolm Gladwell. <em>New Yorker</em>, Jan. 12 2004
pp28-33. Data attributed to Tom Wenzel and Marc Ross who have written
<a href="https://www2.lbl.gov/Science-Articles/Archive/assets/images/2002/Aug-26-2002/SUV-report.pdf">https://www2.lbl.gov/Science-Articles/Archive/assets/images/2002/Aug-26-2002/SUV-report.pdf</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(carsafety)
plot(Driver.deaths + Other.deaths ~ type, data = carsafety)
plot(Driver.deaths + Other.deaths ~ type, data = carsafety)
</code></pre>

<hr>
<h2 id='central.park'>Weather in Central Park NY in May 2003</h2><span id='topic+central.park'></span>

<h3>Description</h3>

<p>A listing of various weather measurements made at Central Park in New
York City during the month of May 2003.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(central.park)</code></pre>


<h3>Format</h3>

<p>A data frame with 31 observations on the following 19 variables.
</p>

<dl>
<dt>DY</dt><dd><p>the day</p>
</dd>
<dt>MAX</dt><dd><p>maximum temperature (temperatures in Farenheit)</p>
</dd>
<dt>MIN</dt><dd><p>minimum temperature</p>
</dd>
<dt>AVG</dt><dd><p>average temperature</p>
</dd>
<dt>DEP</dt><dd><p>departure from normal</p>
</dd>
<dt>HDD</dt><dd><p>heating degree days</p>
</dd>
<dt>CDD</dt><dd><p>cooling degree days</p>
</dd>
<dt>WTR</dt><dd><p>Water fall. A factor as &quot;T&quot; is a trace.</p>
</dd>
<dt>SNW</dt><dd><p>Amount of snowfall</p>
</dd>
<dt>DPTH</dt><dd><p>Depth of snow</p>
</dd>
<dt>SPD</dt><dd><p>Average wind speed</p>
</dd>
<dt>SPD1</dt><dd><p>Max wind speed</p>
</dd>
<dt>DIR</dt><dd><p>2 minimum direction</p>
</dd>
<dt>MIN2</dt><dd><p>Sunshine measurement a factor with two levels <code>0</code> <code>M</code></p>
</dd>
<dt>PSBL</dt><dd><p>Sunshine measurement a factor with levels <code>0</code> <code>M</code></p>
</dd>
<dt>S.S</dt><dd><p>Sunshine measurement. 0-3 = Clear, 4-7 partly cloudy,
8-10 is cloudy</p>
</dd>
<dt>WX</dt><dd><p>(This is not as documented in the data source. Ignore this
variable. It should be:
1 = FOG,
2 = FOG REDUCING VISIBILITY  
TO 1/4 MILE OR LESS,      
3 = THUNDER,                  
4 = ICE PELLETS,              
5 = HAIL,                     
6 = GLAZE OR RIME,
7 = BLOWING DUST OR SAND:    
VSBY 1/2 MILE OR LESS,    
8 = SMOKE OR HAZE,            
9 = BLOWING SNOW,             
X = TORNADO)
</p>
</dd>
<dt>SPD3</dt><dd><p>peak wind speed</p>
</dd>
<dt>DR</dt><dd><p>direction of peak wind</p>
</dd>
</dl>



<h3>Details</h3>

<p>This datasets summarizes the weather in New York City during the merry
month of May 2003.  This data set comes from the daily climate report
issued by the National Weather Service Office.  
</p>


<h3>Source</h3>

<p>This data was published
on http://www.noah.gov
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(central.park)
attach(central.park)
barplot(rbind(MIN,MAX-MIN),ylim=c(0,80))
</code></pre>

<hr>
<h2 id='central.park.cloud'> Type of day in Central Park, NY May 2003</h2><span id='topic+central.park.cloud'></span>

<h3>Description</h3>

<p>The type of day in May 2003 in Central Park, NY
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(central.park.cloud)</code></pre>


<h3>Format</h3>

<p>A factor with levels <code>clear</code>,<code>partly.cloudy</code> and <code>cloudy</code>.
</p>


<h3>Source</h3>

<p>This type of data, and much more, is available from
<a href="https://www.noaa.gov">https://www.noaa.gov</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(central.park.cloud)
table(central.park.cloud)
</code></pre>

<hr>
<h2 id='ceo2013'>
CEO compensation in 2013
</h2><span id='topic+ceo2013'></span>

<h3>Description</h3>

<p>Data on top 200 CEO compensations in the year 2013
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ceo2013)</code></pre>


<h3>Format</h3>

<p>a data frame.
</p>


<h3>Source</h3>

<p>Scraped from <a href="https://archive.nytimes.com/www.nytimes.com/interactive/2013/06/30/business/executive-compensation-tables.html?ref=business">https://archive.nytimes.com/www.nytimes.com/interactive/2013/06/30/business/executive-compensation-tables.html?ref=business</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ceo2013)
</code></pre>

<hr>
<h2 id='cfb'> Bootstrap sample from the Survey of Consumer Finances</h2><span id='topic+cfb'></span>

<h3>Description</h3>

<p>A bootstrap sample from the &ldquo;Survey of Consumer Finances&rdquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cfb)</code></pre>


<h3>Format</h3>

<p>A data frame with 1000 observations on the following 14
variables.
</p>

<dl>
<dt>WGT</dt><dd><p>Weights to comensate for undersampling. Not applicable</p>
</dd>
<dt>AGE</dt><dd><p>Age of participants</p>
</dd>
<dt>EDUC</dt><dd><p>Education level (number of years) of participant</p>
</dd>
<dt>INCOME</dt><dd><p>Income in year 2001 of participant</p>
</dd>
<dt>CHECKING</dt><dd><p>Amount in checking account for participant</p>
</dd>
<dt>SAVING</dt><dd><p>Amount in savings accounts</p>
</dd>
<dt>NMMF</dt><dd><p>Total directly-held mutual funds</p>
</dd>
<dt>STOCKS</dt><dd><p>Amount held in stocks</p>
</dd>
<dt>FIN</dt><dd><p>Total financial assets</p>
</dd>
<dt>VEHIC</dt><dd><p>Value of all vehicles (includes autos, motor homes, RVs, airplanes,
boats)</p>
</dd>
<dt>HOMEEQ</dt><dd><p>Total home equity</p>
</dd>
<dt>OTHNFIN</dt><dd><p>Other financial assets</p>
</dd>
<dt>DEBT</dt><dd><p>Total debt</p>
</dd>
<dt>NETWORTH</dt><dd><p>Total net worth</p>
</dd>
</dl>



<h3>Details</h3>

<p>The SCF dataset is a comprehensive survey of consumer finances
sponsored by the United States Federal Reserve,
<a href="https://www.federalreserve.gov/pubs/oss/oss2/2001/scf2001home.html">https://www.federalreserve.gov/pubs/oss/oss2/2001/scf2001home.html</a>.
</p>
<p>The data is oversampled to compensate for low response in the upper
brackets. To compensate, weights are assigned. By bootstrapping the
data with the weights, we get a &ldquo;better&rdquo; version of a random sample
from the population.
</p>


<h3>Source</h3>

<p><a href="https://www.federalreserve.gov/pubs/oss/oss2/2001/scf2001home.html">https://www.federalreserve.gov/pubs/oss/oss2/2001/scf2001home.html</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cfb)
attach(cfb)
mean(INCOME)
</code></pre>

<hr>
<h2 id='chicken'>weight gain of chickens fed 3 different rations </h2><span id='topic+chicken'></span>

<h3>Description</h3>

<p>weight gain of chickens fed 3 different rations 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(chicken)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>Ration1</dt><dd><p>a numeric vector</p>
</dd>
<dt>Ration2</dt><dd><p>a numeric vector</p>
</dd>
<dt>Ration3</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>From Kitchens' Exploring Statistics.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(chicken)
boxplot(chicken)
</code></pre>

<hr>
<h2 id='chips'>Measurements of chip wafers </h2><span id='topic+chips'></span>

<h3>Description</h3>

<p>The <code>chips</code> data frame has 30 rows and 8 columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(chips)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>wafer11</dt><dd><p>a numeric vector</p>
</dd>
<dt>wafer12</dt><dd><p>a numeric vector</p>
</dd>
<dt>wafer13</dt><dd><p>a numeric vector</p>
</dd>
<dt>wafer14</dt><dd><p>a numeric vector</p>
</dd>
<dt>wafer21</dt><dd><p>a numeric vector</p>
</dd>
<dt>wafer22</dt><dd><p>a numeric vector</p>
</dd>
<dt>wafer23</dt><dd><p>a numeric vector</p>
</dd>
<dt>wafer24</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>From Kitchens' Exploring Statistics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(chips)
boxplot(chips)
</code></pre>

<hr>
<h2 id='co2emiss'>Carbon Dioxide Emissions from the U.S.A. from fossil fuel </h2><span id='topic+co2emiss'></span>

<h3>Description</h3>

<p>Carbon Dioxide Emissions from the U.S.A. from fossil fuel
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(co2emiss)</code></pre>


<h3>Format</h3>

<p>The format is:
Time-Series [1:276] from 1981 to 2004: -30.5 -30.4 -30.3 -29.8 -29.6 ...
</p>


<h3>Details</h3>

<p>Monthly estimates of 13C/12C in fossil-fuel CO2 emissions. Originally
at
http://cdiac.esd.ornl.gov/trends/emis_mon/emis_mon_co2.html; now off-line.
</p>
<p>At one time:
&quot;An annual cycle, peaking during the winter months and reflecting
natural gas consumption, and a semi-annual cycle of lesser amplitude,
peaking in summer and winter and reflecting coal consumption, comprise
the dominant features of the annual pattern. The relatively constant
emissions until 1987, followed by an increase from 1987-1989, a
decrease in 1990-1991 and record highs during the late 1990s, are also
evident in the annual data of Marland et al. However, emissions have
declined somewhat since 2000.&quot;
</p>


<h3>Source</h3>

<p>http://cdiac.esd.ornl.gov/ftp/trends/emis_mon/emis_mon_c13.dat (off-line)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(co2emiss)
monthplot(co2emiss)
stl(co2emiss, s.window="periodic")
</code></pre>

<hr>
<h2 id='coins'>The coins in my change bin</h2><span id='topic+coins'></span>

<h3>Description</h3>

<p>The coins in author's change bin with year and value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(coins)</code></pre>


<h3>Format</h3>

<p>A data frame with 371 observations on the following 2 variables.
</p>

<dl>
<dt>year</dt><dd><p>Year of coin</p>
</dd>
<dt>value</dt><dd><p>Value of coin: quarter, dime, nickel, or penny</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(coins)
years = cut(coins$year,seq(1920,2010,by=10),include.lowest=TRUE,
  labels = paste(192:200,"*",sep=""))
table(years)
</code></pre>

<hr>
<h2 id='coldvermont'>Daily minimum temperature in Woodstock Vermont</h2><span id='topic+coldvermont'></span>

<h3>Description</h3>

<p>Recordings of daily minimum temperature in Woodstock Vermont from January 1 1980 through 1985.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(coldvermont)</code></pre>


<h3>Format</h3>

<p>A ts object with daily frequency
</p>


<h3>Source</h3>

<p>Extracted from http://www.ce.washington.edu/pub/HYDRO/edm/met_thru_97/vttmin.dly.gz. Errors were possibly introduced.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(coldvermont)
plot(coldvermont)
</code></pre>

<hr>
<h2 id='confint.htest'>
Produce confidence interval for objects of class <code>htest</code>
</h2><span id='topic+confint.htest'></span>

<h3>Description</h3>

<p>Simple means to output a confidence interval for an <code>htest</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'htest'
confint(object, parm, level, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confint.htest_+3A_object">object</code></td>
<td>

<p>A object of class <code>htest</code>, such as output from <code>t.test</code>.
</p>
</td></tr>
<tr><td><code id="confint.htest_+3A_parm">parm</code></td>
<td>

<p>ignored	
</p>
</td></tr>
<tr><td><code id="confint.htest_+3A_level">level</code></td>
<td>

<p>ignored
</p>
</td></tr>
<tr><td><code id="confint.htest_+3A_...">...</code></td>
<td>

<p>can pass in function to transform via <code>transform</code> argument.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, outputs interval through <code>cat</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>confint(t.test(rnorm(10)))	
</code></pre>

<hr>
<h2 id='corn'>Comparison of corn for new and standard variety</h2><span id='topic+corn'></span>

<h3>Description</h3>

<p>Comparison of corn for new and standard variety</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(corn)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>New</dt><dd><p>a numeric vector</p>
</dd>
<dt>Standard</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>From Kitchens' Exploring Statitistcs
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(corn)
t.test(corn)
</code></pre>

<hr>
<h2 id='crime'> violent crime rates in 50 states of US </h2><span id='topic+crime'></span>

<h3>Description</h3>

<p>crime rates for 50 states in 1983 and 1993
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(crime)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>y1983</dt><dd><p>a numeric vector</p>
</dd>
<dt>y1993</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>from Kitchens' Exploring Statistics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(crime)
boxplot(crime)
t.test(crime[,1],crime[,2],paired=TRUE)
</code></pre>

<hr>
<h2 id='deflection'> Deflection under load</h2><span id='topic+deflection'></span>

<h3>Description</h3>

<p>The data collected in a calibration experiment consisting of a known
load, applied to the load cell, and the corresponding deflection of
the cell from its nominal position.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(deflection)</code></pre>


<h3>Format</h3>

<p>A data frame with 40 observations on the following 2 variables.
</p>

<dl>
<dt>Deflection</dt><dd><p>a numeric vector</p>
</dd>
<dt>Load</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>From an example in <em>Engineering Statistics Handbook</em> from http://www.itl.nist.gov/div898/handbook/
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(deflection)
res = lm(Deflection ~ Load, data = deflection)
plot(Deflection ~ Load, data = deflection)
abline(res)			# looks good?
plot(res)
</code></pre>

<hr>
<h2 id='demos'>
Provide menu for possible shiny demonstrations
</h2><span id='topic+demos'></span>

<h3>Description</h3>

<p>Provides a menu to open one of the provided demonstrations which use <span class="pkg">shiny</span> for animation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>demos()
</code></pre>


<h3>Details</h3>

<p>User must have installed <span class="pkg">shiny</span> prior to usage. As <span class="pkg">shiny</span> has some dependencies that don't always work, this package is not a dependency of <span class="pkg">UsingR</span>.
</p>


<h3>Value</h3>

<p>No return value, when called a web page opens. Use Ctrl-C (or equivalent) in terminal to return to an interactive session.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## demos()
</code></pre>

<hr>
<h2 id='DensityPlot'> Plots densities of data </h2><span id='topic+DensityPlot'></span><span id='topic+DensityPlot.default'></span><span id='topic+DensityPlot.formula'></span>

<h3>Description</h3>

<p>Allows one to compare empirical densities of different distributions
in a simple manner. The density is used as graphs with multiple
histograms are too crowded. The usage is similar to side-by-side boxplots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DensityPlot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DensityPlot_+3A_x">x</code></td>
<td>
<p>x may be a sequence of data vectors (eg. x,y,z), a data frame 
with numeric column vectors or a model formula</p>
</td></tr>
<tr><td><code id="DensityPlot_+3A_...">...</code></td>
<td>
<p>You can pass in a bandwidth argument such as bw=&quot;SJ&quot;. See 
density for details. A legend will be placed for you automatically. To 
overide the positioning set do.legend=&quot;manual&quot;. To skip the legend,
set do.legend=FALSE. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Makes a plot
</p>


<h3>Author(s)</h3>

<p> John Verzani</p>


<h3>References</h3>

<p> Basically a modified boxplot function. As well it should be 
as it serves the same utility: comparing distributions.</p>


<h3>See Also</h3>

 <p><code><a href="graphics.html#topic+boxplot">boxplot</a></code>,<code><a href="#topic+violinplot">violinplot</a></code>,<code><a href="stats.html#topic+density">density</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## taken from boxplot
## using a formula
data(InsectSprays)
DensityPlot(count ~ spray, data = InsectSprays)
## on a matrix (data frame)
mat &lt;- cbind(Uni05 = (1:100)/21, Norm = rnorm(100),
             T5 = rt(100, df = 5), Gam2 = rgamma(100, shape = 2))
DensityPlot(data.frame(mat))


</code></pre>

<hr>
<h2 id='diamond'>Price by size for diamond rings</h2><span id='topic+diamond'></span>

<h3>Description</h3>

<p>A data set on 48 diamond rings containing price in Singapore dollars
and size of diamond in carats.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(diamond)</code></pre>


<h3>Format</h3>

<p>A data frame with 48 observations on the following 2 variables.
</p>

<dl>
<dt>carat</dt><dd><p>A measurement of a diamond's size</p>
</dd>
<dt>price</dt><dd><p>Price in Singapore dollars</p>
</dd>
</dl>



<h3>Details</h3>

<p>This data comes from a collection of the <em>Journal of Statistics
Education</em>. The accompanying documentation says:
</p>
<p>&ldquo;Data presented in a newspaper advertisement suggest the use of simple
linear regression to relate the prices of diamond rings to the weights
of their diamond stones.  The intercept of the resulting regression line
is negative and significantly different from zero.  This finding raises
questions about an assumed pricing mechanism and motivates consideration
of remedial actions.&rdquo;
</p>


<h3>Source</h3>

<p>This comes from
<a href="http://jse.amstat.org/datasets/diamond.txt">http://jse.amstat.org/datasets/diamond.txt</a>. Data
set is contributed by Singfat Chu.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(diamond)
plot(price ~ carat, diamond, pch=5)
</code></pre>

<hr>
<h2 id='divorce'>Time until divorce for divorced women (by age)</h2><span id='topic+divorce'></span>

<h3>Description</h3>

<p>The <code>divorce</code> data frame has 25 rows and 6 columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(divorce)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>time of divorce</dt><dd><p>a factor</p>
</dd>
<dt>all ages</dt><dd><p>a numeric vector</p>
</dd>
<dt>0-17</dt><dd><p>a numeric vector</p>
</dd>
<dt>18-19</dt><dd><p>a numeric vector</p>
</dd>
<dt>20-24</dt><dd><p>a numeric vector</p>
</dd>
<dt>25-100</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>Forgot source
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(divorce)
apply(divorce[,2:6],2,sum)	# percent divorced by age of marriage
</code></pre>

<hr>
<h2 id='DOTplot'> Make big DOT plot likestripchart </h2><span id='topic+DOTplot'></span><span id='topic+DOTplot.default'></span><span id='topic+DOTplot.formula'></span><span id='topic+DOTplt'></span><span id='topic+DOTplot.formula'></span>

<h3>Description</h3>

<p>A variant of the <code>stripchart</code> using big dots as the default.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DOTplot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DOTplot_+3A_x">x</code></td>
<td>
<p>May be a vector, data frame, matrix (each column a variable),
list or model formula. Treats each variable or group as a univariate
dataset and 
makes corresponding DOTplot.</p>
</td></tr>
<tr><td><code id="DOTplot_+3A_...">...</code></td>
<td>
<p>arguments passed onto
<code>points</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the graphic only.
</p>


<h3>Author(s)</h3>

<p> John Verzani</p>


<h3>See Also</h3>

<p> See also as <code><a href="graphics.html#topic+stripchart">stripchart</a></code>, <code><a href="lattice.html#topic+dotplot">dotplot</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>x = c(1,1,2,3,5,8)
DOTplot(x,main="Fibonacci",cex=2)
</code></pre>

<hr>
<h2 id='dottodot'>Dot-to-dot puzzle</h2><span id='topic+dottodot'></span>

<h3>Description</h3>

<p>A set of points to make a dot-to-dot puzzle
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(dottodot)</code></pre>


<h3>Format</h3>

<p>A data frame with 49 observations on the following 4 variables.
</p>

<dl>
<dt>x</dt><dd><p>x position</p>
</dd>
<dt>y</dt><dd><p>y position</p>
</dd>
<dt>pos</dt><dd><p>where to put label</p>
</dd>
<dt>ind</dt><dd><p>number for label</p>
</dd>
</dl>



<h3>Details</h3>

<p>Points to make a dot to dot puzzle to illustrate,
<code><a href="graphics.html#topic+text">text</a></code>, <code><a href="graphics.html#topic+points">points</a></code>, and the argument <code>pos</code>.
</p>


<h3>Source</h3>

<p>Illustration by Noah Verzani.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dottodot)
# make a blank graph
plot(y~x,data=dottodot,type="n",bty="n",xaxt="n",xlab="",yaxt="n",ylab="")
# add the points
points(y~x,data=dottodot)
# add the labels using pos argument
with(dottodot, text(x,y,labels=ind,pos=pos))
# solve the puzzle
lines(y~x, data=dottodot)
</code></pre>

<hr>
<h2 id='dowdata'>The Dow Jones average from Jan 1999 to October 2000</h2><span id='topic+dowdata'></span>

<h3>Description</h3>

<p>The <code>dowdata</code> data frame has 443 rows and 5 columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(dowdata)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:	
</p>

<dl>
<dt>Open</dt><dd><p>a numeric vector</p>
</dd>
<dt>High</dt><dd><p>a numeric vector</p>
</dd>
<dt>Date</dt><dd><p>a numeric vector</p>
</dd>
<dt>Low</dt><dd><p>a numeric vector</p>
</dd>
<dt>Close</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>this data comes from the site <a href="http://www.forecasts.org/">http://www.forecasts.org/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dowdata)
the.close &lt;- dowdata$Close
n &lt;- length(the.close)
plot(log(the.close[2:n]/the.close[1:(n-1)]))
</code></pre>

<hr>
<h2 id='dvdsales'>Monthly DVD player sales since introduction to May 2004</h2><span id='topic+dvdsales'></span>

<h3>Description</h3>

<p>Monthly DVD player sales since introduction of DVD format to May 2004
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(dvdsales)</code></pre>


<h3>Format</h3>

<p>Matrix with rows recording the year, and columns the month.
</p>


<h3>Source</h3>

<p>Original data retrieved from http://www.thedigitalbits.com/articles/cemadvdsales.html
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dvdsales)
barplot(t(dvdsales[7:1,]),beside=TRUE)
</code></pre>

<hr>
<h2 id='emissions'> CO2 emissions data and gross domestic product for 26 countries</h2><span id='topic+emissions'></span>

<h3>Description</h3>

<p>The <code>emissions</code> data frame has 26 rows and 3 columns.
</p>
<p>A data set listing GDP, GDP per capita, and CO2 emissions for 1999.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>data(emissions)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>GDP</dt><dd><p>a numeric vector</p>
</dd>
<dt>perCapita</dt><dd><p>a numeric vector</p>
</dd>
<dt>CO2</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>http://www.grida.no for CO2 data and
http://www.mrdowling.com for GDP data.
</p>
<p>Prompted by a plot appearing in a June 2001 issue of the <em>New
York Times</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(emissions)
plot(emissions)
</code></pre>

<hr>
<h2 id='errata'>Show errata</h2><span id='topic+errata'></span>

<h3>Description</h3>

<p>Show errata
</p>


<h3>Usage</h3>

<pre><code class='language-R'>errata()
</code></pre>


<h3>Value</h3>

<p>opens browse to errata page
</p>

<hr>
<h2 id='ewr'> Taxi in and taxi out times at EWR (Newark) airport for 1999-2001 </h2><span id='topic+ewr'></span>

<h3>Description</h3>

<p>The <code>ewr</code> data frame has 46 rows and 11 columns.
</p>
<p>Gives taxi in and taxi out times for 8 different airlines and several
months at EWR airport.
</p>
<p>Airline codes are
<code>AA</code> (American Airlines),
<code>AQ</code> (Aloha Airlines),
<code>AS</code> (Alaska Airlines),
<code>CO</code> (Continental Airlines),
<code>DL</code> (Delta Airlines),
<code>HP</code> (America West Airlines),
<code>NW</code> (Northwest Airlines),
<code>TW</code> (Trans World Airlines),
<code>UA</code> (United Airlines),
<code>US</code> (US Airways), and
<code>WN</code> (Southwest Airlines)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ewr)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>Year</dt><dd><p>a numeric vector</p>
</dd>
<dt>Month</dt><dd><p>a factor for months</p>
</dd>
<dt>AA</dt><dd><p>a numeric vector</p>
</dd>
<dt>CO</dt><dd><p>a numeric vector</p>
</dd>
<dt>DL</dt><dd><p>a numeric vector</p>
</dd>
<dt>HP</dt><dd><p>a numeric vector</p>
</dd>
<dt>NW</dt><dd><p>a numeric vector</p>
</dd>
<dt>TW</dt><dd><p>a numeric vector</p>
</dd>
<dt>UA</dt><dd><p>a numeric vector</p>
</dd>
<dt>US</dt><dd><p>a numeric vector</p>
</dd>
<dt>inorout</dt><dd><p>a factor with levels <code>in</code> or <code>out</code> </p>
</dd>
</dl>



<h3>Source</h3>

<p>Retrieved from http://www.bts.gov/oai/taxitime/html/ewrtaxi.html
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ewr)
boxplot(ewr[3:10])
</code></pre>

<hr>
<h2 id='exec.pay'> Direct compensation for 199 United States CEOs in the year 2000  </h2><span id='topic+exec.pay'></span>

<h3>Description</h3>

<p> Direct compensation for 199 United States CEOs in the year 2000
in units of \$10,000.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>data(exec.pay)</code></pre>


<h3>Format</h3>

<p>A numeric vector with 199 entries each measuring compensation in 10,000s
of dollars.
</p>


<h3>Source</h3>

<p><em>New York Times</em> Business section 04/01/2001. See also <a href="https://aflcio.org">https://aflcio.org</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(exec.pay)
hist(exec.pay)
</code></pre>

<hr>
<h2 id='fat'>Body measurements to predict percentage of body fat in males</h2><span id='topic+fat'></span>

<h3>Description</h3>

<p>A data set containing many physical measurements of 252 males. Most of
the variables can be measured with a scale or tape measure. Can they
be used to predict the percentage of body fat? If so, this offers an
easy alternative to an underwater weighing technique.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(fat)</code></pre>


<h3>Format</h3>

<p>A data frame with 252 observations on the following 19 variables.
</p>

<dl>
<dt>case</dt><dd><p>Case Number</p>
</dd>
<dt>body.fat</dt><dd><p>Percent body fat using Brozek's equation,
457/Density - 414.2</p>
</dd>
<dt>body.fat.siri</dt><dd><p>Percent body fat using Siri's equation,
495/Density - 450</p>
</dd>
<dt>density</dt><dd><p>Density (gm/cm<code class="reqn">\mbox{\textasciicircum}</code>2)</p>
</dd>
<dt>age</dt><dd><p>Age (yrs)</p>
</dd>
<dt>weight</dt><dd><p>Weight (lbs)</p>
</dd>
<dt>height</dt><dd><p>Height (inches)</p>
</dd>
<dt>BMI</dt><dd><p>Adiposity index = Weight/Height<code class="reqn">\mbox{\textasciicircum}</code>2 (kg/m<code class="reqn">\mbox{\textasciicircum}</code>2)</p>
</dd>
<dt>ffweight</dt><dd><p>Fat Free Weight
= (1 - fraction of body fat) * Weight,            using Brozek's formula (lbs)</p>
</dd>
<dt>neck</dt><dd><p>Neck circumference (cm)</p>
</dd>
<dt>chest</dt><dd><p>Chest circumference (cm)</p>
</dd>
<dt>abdomen</dt><dd><p>Abdomen circumference (cm) &quot;at the umbilicus
and level with the iliac crest&quot;</p>
</dd>
<dt>hip</dt><dd><p>Hip circumference (cm)</p>
</dd>
<dt>thigh</dt><dd><p>Thigh circumference (cm)</p>
</dd>
<dt>knee</dt><dd><p>Knee circumference (cm)</p>
</dd>
<dt>ankle</dt><dd><p>Ankle circumference (cm)</p>
</dd>
<dt>bicep</dt><dd><p>Extended biceps circumference (cm)</p>
</dd>
<dt>forearm</dt><dd><p>Forearm circumference (cm)</p>
</dd>
<dt>wrist</dt><dd><p>Wrist circumference (cm) &quot;distal to the
styloid processes&quot;</p>
</dd>
</dl>



<h3>Details</h3>

<p>From the source:
</p>
<p>&ldquo;The data are as received from Dr. Fisher.  Note, however, that there
are a few errors.  The body densities for cases 48, 76, and 96, for
instance, each seem to have one digit in error as can be seen from the
two body fat percentage values.  Also note the presence of a man (case
42) over 200 pounds in weight who is less than 3 feet tall (the height
should presumably be 69.5 inches, not 29.5 inches)!  The percent body
fat estimates are truncated to zero when negative (case 182).&rdquo;
</p>


<h3>Source</h3>

<p>This data set comes from the collection of the <em>Journal of
Statistics Education</em> at
<a href="http://jse.amstat.org/datasets/fat.txt">http://jse.amstat.org/datasets/fat.txt</a>. The
data set was contributed by Roger W. Johnson.
</p>


<h3>References</h3>

<p>The source of the data is attributed to Dr. A. Garth Fisher, Human
Performance Research Center, Brigham Young University, Provo, Utah
84602,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(fat)
f = body.fat ~ age + weight + height + BMI + neck + chest + abdomen +
hip + thigh + knee + ankle + bicep + forearm + wrist
res = lm(f, data=fat)
summary(res)
</code></pre>

<hr>
<h2 id='father.son'>Pearson's data set on heights of  fathers and their sons</h2><span id='topic+father.son'></span>

<h3>Description</h3>

<p>1078 measurements of a father's height and his son's height.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(father.son)</code></pre>


<h3>Format</h3>

<p>A data frame with 1078 observations on the following 2 variables.
</p>

<dl>
<dt>fheight</dt><dd><p>Father's height in inches</p>
</dd>
<dt>sheight</dt><dd><p>Son's height in inches</p>
</dd>
</dl>



<h3>Details</h3>

<p>Data set used by Pearson to investigate regression. See data set
<code>galton</code> for data set used by Galton.
</p>


<h3>Source</h3>

<p>Read into R by the command
</p>
<p><code>read.table("http://stat-www.berkeley.edu/users/juliab/141C/pearson.dat",sep=" ")[,-1]</code>,
</p>
<p>as mentioned by Chuck Cleland on the r-help mailing list.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(father.son)
## like cover of Freedman, Pisani, and Purves
plot(sheight ~ fheight, data=father.son,bty="l",pch=20)
abline(a=0,b=1,lty=2,lwd=2)
abline(lm(sheight ~ fheight, data=father.son),lty=1,lwd=2)
</code></pre>

<hr>
<h2 id='female.inc'> Income distribution for females in 2001</h2><span id='topic+female.inc'></span>

<h3>Description</h3>

<p>A data set containing incomes for 1,000 females along with race
information. The data is sampled from data provided by the United
States Census Bureau.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(female.inc)</code></pre>


<h3>Format</h3>

<p>A data frame with 1,000 observations on the following 2 variables.
</p>

<dl>
<dt>income</dt><dd><p>Income for 2001 in dollars</p>
</dd>
<dt>race</dt><dd><p>a factor with levels <code>black</code>, <code>hispanic</code> or <code>white</code></p>
</dd>
</dl>



<h3>Details</h3>

<p>The United States Census Bureau provides alot of data on income
distributions. This data comes from the Current Population Survey
(CPS) for the year 2001. The raw data appears in  table format. This
data is sampled from the data in that table.
</p>


<h3>Source</h3>

<p>The original table was found at
http://ferret.bls.census.gov/macro/032002/perinc/new11_002.htm
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(female.inc)
boxplot(income ~ race, female.inc)
boxplot(log(income,10) ~ race, female.inc)
sapply(with(female.inc,split(income,race)),median)
</code></pre>

<hr>
<h2 id='firstchi'>Age of mother at birth of first child </h2><span id='topic+firstchi'></span>

<h3>Description</h3>

<p>Age of mother at birth of first child </p>


<h3>Usage</h3>

<pre><code class='language-R'>data(firstchi)</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:87] 30 18 35 22 23 22 36 24 23 28 ...
</p>


<h3>Source</h3>

<p>From <em>Exploring Statistics</em>,  L. Kitchens, Duxbury Press, 1998.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(firstchi)
hist(firstchi)
</code></pre>

<hr>
<h2 id='five.yr.temperature'> Five years of weather in New York City</h2><span id='topic+five.yr.temperature'></span>

<h3>Description</h3>

<p>Five years of maximum temperatures in New York City
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(five.yr.temperature)</code></pre>


<h3>Format</h3>

<p>A data frame with 2,439 observations on the following 3 variables.
</p>

<dl>
<dt>days</dt><dd><p>Which day of the year</p>
</dd>
<dt>years</dt><dd><p>The year</p>
</dd>
<dt>temps</dt><dd><p>Maximum temperature</p>
</dd>
</dl>



<h3>Source</h3>

<p>Dataset found on the internet, but original source is lost.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(five.yr.temperature)
attach(five.yr.temperature)
scatter.smooth(temps ~ days,col=gray(.75))
lines(smooth.spline(temps ~ days), lty=2)
lines(supsmu(days, temps), lty=3)
</code></pre>

<hr>
<h2 id='florida'> County-by-county results of year 2000 US presidential election
in Florida </h2><span id='topic+florida'></span>

<h3>Description</h3>

<p>The <code>florida</code> data frame has 67 rows and 13 columns.
</p>
<p>Gives a county by county accounting of the US elections in the state of
Florida.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>data(florida)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>County</dt><dd><p>Name of county</p>
</dd>
<dt>GORE</dt><dd><p>Votes for Gore</p>
</dd>
<dt>BUSH</dt><dd><p>Votes for Bush</p>
</dd>
<dt>BUCHANAN</dt><dd><p>Votes for Buchanan</p>
</dd>
<dt>NADER</dt><dd><p>Votes for Nader</p>
</dd>
<dt>BROWN</dt><dd><p>a numeric vector</p>
</dd>
<dt>HAGELIN</dt><dd><p>a numeric vector</p>
</dd>
<dt>HARRIS</dt><dd><p>a numeric vector</p>
</dd>
<dt>MCREYNOLDS</dt><dd><p>a numeric vector</p>
</dd>
<dt>MOOREHEAD</dt><dd><p>a numeric vector</p>
</dd>
<dt>PHILLIPS</dt><dd><p>a numeric vector</p>
</dd>
<dt>Total</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>Found in the excellent notes <em>Using R for Data Analysis and
Graphics</em> by John Maindonald. (As of 2003 a book published by
Cambridge University Press.)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(florida)
attach(florida)
result.lm &lt;- lm(BUCHANAN ~ BUSH)
plot(BUSH,BUCHANAN)
abline(result.lm) ## can you find Palm Beach and Miami Dade counties?
</code></pre>

<hr>
<h2 id='galileo'> Galileo data on falling bodies</h2><span id='topic+galileo'></span>

<h3>Description</h3>

<p>Data recorded by Galileo in 1609 during his investigations of the
trajectory of a falling body.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(galileo)</code></pre>


<h3>Format</h3>

<p>A data frame with 7 observations on the following 2 variables.
</p>

<dl>
<dt>init.h</dt><dd><p>Initial height of ball</p>
</dd>
<dt>h.d</dt><dd><p>Horizontal distance traveled</p>
</dd>
</dl>



<h3>Details</h3>

<p>A simple ramp 500 punti above the ground was constructed. A ball was
placed on the ramp at an indicated height from the ground and
released. The horizontal distance traveled is recorded (in
punti). (One punto is 169/180 millimeter, not a car by FIAT.)
</p>


<h3>Source</h3>

<p>This data and example come from the <em>Statistical Sleuth</em> by
Ramsay and Schafer, Duxbury (2001), section 10.1.1. They attribute an
article in <em>Scientific American</em> by
Drake and MacLachlan.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(galileo)
polynomial = function(x,coefs) {
  sum = 0
  for(i in 0:(length(coefs)-1)) {
    sum = sum + coefs[i+1]*x^i
  }
  sum
}
res.lm = lm(h.d ~ init.h, data = galileo)
res.lm2 = update(res.lm, . ~ . + I(init.h^2), data=galileo)
res.lm3 = update(res.lm2, . ~ . + I(init.h^3), data=galileo)
plot(h.d ~ init.h, data = galileo)
curve(polynomial(x,coef(res.lm)),add=TRUE)
curve(polynomial(x,coef(res.lm2)),add=TRUE)
curve(polynomial(x,coef(res.lm3)),add=TRUE)

</code></pre>

<hr>
<h2 id='galton'> Galton's height data for parents and children</h2><span id='topic+galton'></span>

<h3>Description</h3>

<p>Data set from tabulated data set used by Galton in 1885 to study the
relationship between a parent's height and their childrens.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(galton)</code></pre>


<h3>Format</h3>

<p>A data frame with 928 observations on the following 2 variables.
</p>

<dl>
<dt>child</dt><dd><p>The child's height</p>
</dd>
<dt>parent</dt><dd><p>The &ldquo;midparent&rdquo; height</p>
</dd>
</dl>



<h3>Details</h3>

<p>The midparent's height is an average of the fathers height and 1.08 times
the mother's. In the data there are 205 different parents and 928 children.
The data here is truncated at the ends for both parents and
children so that it can be treated as numeric data. The data were
tabulated and consequently made discrete. The <code>father.son</code> data set is
similar data used by Galton and is continuous.
</p>


<h3>Source</h3>

<p>This data was found at
http://www.bun.kyoto-u.ac.jp/~suchii/galton86.html.
</p>
<p>See also the data.set <a href="#topic+father.son">father.son</a> which was found from
http://stat-www.berkeley.edu/users/juliab/141C/pearson.dat. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(galton)
plot(galton)
## or with some jitter.
plot(jitter(child,5) ~ jitter(parent,5),galton)
## sunflowerplot shows flowers for multiple plots (Thanks MM)
sunflowerplot(galton)
</code></pre>

<hr>
<h2 id='gap'> Sales data for the Gap</h2><span id='topic+gap'></span>

<h3>Description</h3>

<p>Sales data for the Gap from Jan
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(gap)</code></pre>


<h3>Format</h3>

<p>The format is a ts object storing data from June 2002 through June 2005.
</p>


<h3>Source</h3>

<p>http://home.businesswire.com
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gap)
monthplot(gap)
</code></pre>

<hr>
<h2 id='gasprices'> Monthly average gasoline prices in the United States</h2><span id='topic+gasprices'></span>

<h3>Description</h3>

<p>Average retail gasoline prices per month in the United States from January
2000 through February 2006. The hurricane Katrina caused a
percentage loss of refinery capability leading to rapidly increasing prices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(gasprices)</code></pre>


<h3>Format</h3>

<p>The format is:
Time-Series [1:74] from 2000 to 2006: 129 138 152 146 148 ...
</p>


<h3>Source</h3>

<p>Oringally from the Department of Energy web site:
https://www.eia.gov/petroleum/gasdiesel/
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gasprices)
plot(gasprices)
</code></pre>

<hr>
<h2 id='getAnswer'>function to get answer to problem</h2><span id='topic+getAnswer'></span>

<h3>Description</h3>

<p>Returns answers for the first edition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getAnswer(chapter = NULL, problem = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getAnswer_+3A_chapter">chapter</code></td>
<td>
<p>which chapter</p>
</td></tr>
<tr><td><code id="getAnswer_+3A_problem">problem</code></td>
<td>
<p>which problem</p>
</td></tr>
</table>


<h3>Value</h3>

<p>opens web page to answer
</p>

<hr>
<h2 id='goalspergame'> Goals per game in NHL</h2><span id='topic+goalspergame'></span>

<h3>Description</h3>

<p>Goals per game in NHL
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(goalspergame)</code></pre>


<h3>Format</h3>

<p>The format is:
mts [1:53, 1:4] 6 6 6 6 6 6 6 6 6 6 ...
- attr(*, &quot;dimnames&quot;)=List of 2
..$ : NULL
..$ : chr [1:4] &quot;n.teams&quot; &quot;n.games&quot; &quot;n.goals&quot; &quot;gpg&quot;
- attr(*, &quot;tsp&quot;)= num [1:3] 1946 1998    1
- attr(*, &quot;class&quot;)= chr [1:2] &quot;mts&quot; &quot;ts&quot;
</p>


<h3>Source</h3>

<p>Off internet site. Forgot which.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(goalspergame)
</code></pre>

<hr>
<h2 id='google'> Google stock values during 2005-02-07 to 2005-07-07</h2><span id='topic+google'></span>

<h3>Description</h3>

<p>Closing stock price of a share of Google stock during 2005-02-07 to 2005-07-07</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(google)</code></pre>


<h3>Format</h3>

<p>A data vector of numeric values with names attribute giving the dates.
</p>


<h3>Source</h3>

<p>finance.yahoo.com
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(google)
plot(google,type="l")
</code></pre>

<hr>
<h2 id='grades'> Current and previous grades</h2><span id='topic+grades'></span>

<h3>Description</h3>

<p>A dataframe of a students grade and their grade in their previous
class. Graded on American A-F scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(grades)</code></pre>


<h3>Format</h3>

<p> A dataframe of 122 rows with 2 columns
</p>

<dl>
<dt>prev</dt><dd><p>The grade in the previous class in the subject matter</p>
</dd>
<dt>grade</dt><dd><p>The grade in the current class</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(grades)
table(grades)
</code></pre>

<hr>
<h2 id='grip'>Effects of cross-country ski-pole grip</h2><span id='topic+grip'></span>

<h3>Description</h3>

<p>Simulated data set investigating effects of cross-country ski-pole grip.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(grip)</code></pre>


<h3>Format</h3>

<p>A data frame with 36 observations on the following 4 variables.
</p>

<dl>
<dt>UBP</dt><dd><p>Measurement of upper-body power</p>
</dd>
<dt>person</dt><dd><p>One of four skiers</p>
</dd>
<dt>grip.type</dt><dd><p>Either classic, modern, or integrated.</p>
</dd>
<dt>replicate</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>Based on a study originally described at
http://www.montana.edu/wwwhhd/movementscilab/ and
mentioned on http://www.xcskiworld.com/. The study investigated
the effect of grip type on upper body power. As this influences
performance in races, presumably a skier would prefer the grip that
provides the best power output.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(grip)
ftable(xtabs(UBP ~ person + replicate + grip.type,grip))
</code></pre>

<hr>
<h2 id='hall.fame'>Data frame containing baseball statistics including Hall of Fame
membership</h2><span id='topic+hall.fame'></span>

<h3>Description</h3>

<p>A data frame containing baseball statistics for several players.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(hall.fame)</code></pre>


<h3>Format</h3>

<p>A data frame with 1340 observations on the following 28 variables.
</p>

<dl>
<dt>first</dt><dd><p>first name</p>
</dd>
<dt>last</dt><dd><p>last name</p>
</dd>
<dt>seasons</dt><dd><p>Seasons played</p>
</dd>
<dt>games</dt><dd><p>Games played</p>
</dd>
<dt>AB</dt><dd><p>Official At Bats</p>
</dd>
<dt>runs</dt><dd><p>Runs scored</p>
</dd>
<dt>hits</dt><dd><p>hits</p>
</dd>
<dt>doubles</dt><dd><p>doubles</p>
</dd>
<dt>triples</dt><dd><p>triples numeric vector</p>
</dd>
<dt>HR</dt><dd><p>Home runs</p>
</dd>
<dt>RBI</dt><dd><p>Runs batted in</p>
</dd>
<dt>BB</dt><dd><p>Base on balls</p>
</dd>
<dt>SO</dt><dd><p>Strike outs</p>
</dd>
<dt>BA</dt><dd><p>Batting Average</p>
</dd>
<dt>OBP</dt><dd><p>On Base percentage</p>
</dd>
<dt>SP</dt><dd><p>Slugging Percentage</p>
</dd>
<dt>AP</dt><dd><p>Adjusted productions</p>
</dd>
<dt>BR</dt><dd><p>batting runs</p>
</dd>
<dt>ABRuns</dt><dd><p>adjusted batting runs</p>
</dd>
<dt>Runs.Created</dt><dd><p>Runs created</p>
</dd>
<dt>SB</dt><dd><p>Stolen Bases</p>
</dd>
<dt>CS</dt><dd><p>Caught stealing</p>
</dd>
<dt>Stolen.Base.Runs</dt><dd><p>Runs scored by stealing</p>
</dd>
<dt>Fielding.Average</dt><dd><p>Fielding average</p>
</dd>
<dt>Fielding.Runs</dt><dd><p>Fielding runs</p>
</dd>
<dt>Primary.Position.Played</dt><dd><p>    C = Catcher,
1 = First Base,
2 = Second Base,
3 = Third Base,
S = Shortstop,
O = Outfield, and
D = Designated hitter</p>
</dd>
<dt>Total.Player.Rating</dt><dd><p>a numeric vector</p>
</dd>
<dt>Hall.Fame.Membership</dt><dd><p>    Not a member,
Elected by the BBWAA, or
Chosen by the Old Timers Committee or Veterans Committee</p>
</dd>
</dl>



<h3>Details</h3>

<p>The sport of baseball lends itself to the collection of data. This
data set contains many variables used to assess a players
career. The Hall of Fame is reserved for outstanding players as judged
initially by the Baseball Writers Association and subsequently by the
Veterans Committee.
</p>


<h3>Source</h3>

<p>This data set was submitted to the <em>Journal of Statistical
Education</em>,
https://www.amstat.org/publications/jse/secure/v8n2/datasets.cochran.new.cfm (now off-line),
by James J. Cochran.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hall.fame)
hist(hall.fame$OBP)
with(hall.fame,last[Hall.Fame.Membership != "not a member"])
</code></pre>

<hr>
<h2 id='headtail'>
Show head and tail
</h2><span id='topic+headtail'></span>

<h3>Description</h3>

<p>helper function to shorten display of a data frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>headtail(x, k = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="headtail_+3A_x">x</code></td>
<td>

<p>a data frame
</p>
</td></tr>
<tr><td><code id="headtail_+3A_k">k</code></td>
<td>

<p>number of rows at top and bottom to show.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value. Uses <code>cat</code> to show data
</p>


<h3>Examples</h3>

<pre><code class='language-R'>headtail(mtcars)
</code></pre>

<hr>
<h2 id='healthy'>Healthy or not?</h2><span id='topic+healthy'></span>

<h3>Description</h3>

<p>Data on whether a patient is healthy with two covariates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(healthy)</code></pre>


<h3>Format</h3>

<p>A data frame with 32 observations on the following 3 variables.
</p>

<dl>
<dt>p</dt><dd><p>One covariate</p>
</dd>
<dt>g</dt><dd><p>Another covariate</p>
</dd>
<dt>healthy</dt><dd><p>0 is healthy, 1 is not</p>
</dd>
</dl>



<h3>Details</h3>

<p>Data on health with information from two unspecified covariates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(healthy)
library(MASS)
stepAIC(glm(healthy ~ p + g, healthy, family=binomial))
</code></pre>

<hr>
<h2 id='heartrate'>Simulated data of age vs. max heart rate </h2><span id='topic+heartrate'></span>

<h3>Description</h3>

<p>Simulated data of age vs. max heart rate
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(heartrate)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>age</dt><dd><p>a numeric vector</p>
</dd>
<dt>maxrate</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>Does this fit the workout room value of 220 - age?
</p>


<h3>Source</h3>

<p>Simulated based on &ldquo;Age-predicted maximal heart
rate revisited&rdquo; Hirofumi Tanaka, Kevin D. Monahan, Douglas R.
Seals <em>Journal of the American College of Cardiology</em>,
37:1:153-156.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(heartrate)
plot(heartrate)
abline(lm(maxrate ~ age,data=heartrate))
</code></pre>

<hr>
<h2 id='home'>Maplewood NJ homedata</h2><span id='topic+home'></span>

<h3>Description</h3>

<p>The <code>home</code> data frame has 15 rows and 2 columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(home)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>old</dt><dd><p>a numeric vector</p>
</dd>
<dt>new</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>See full dataset homedata
</p>


<h3>Source</h3>

<p>See full dataset homedata
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(home)
## compare on the same scale
boxplot(data.frame(scale(home))) 
</code></pre>

<hr>
<h2 id='homedata'> Maplewood NJ assessed values for years 1970 and 2000 </h2><span id='topic+homedata'></span>

<h3>Description</h3>

<p>The <code>homedata</code> data frame has 6841 rows and 2 columns.
</p>
<p>Data set containing assessed values of homes in Maplewood NJ for the
years 1970 and 2000. The properties were not officially assessed
during that time and it is interesting to see the change in percentage 
appreciation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(homedata)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>y1970</dt><dd><p>a numeric vector</p>
</dd>
<dt>y2000</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>Maplewood Reval
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(homedata)
plot(homedata)
</code></pre>

<hr>
<h2 id='homeprice'> Sale price of homes in New Jersey in the year 2001 </h2><span id='topic+homeprice'></span>

<h3>Description</h3>

<p>The <code>homeprice</code> data frame has 29 rows and 7 columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(homeprice)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>list</dt><dd><p>list price of home (in thousands)</p>
</dd>
<dt>sale</dt><dd><p>actual sale price</p>
</dd>
<dt>full</dt><dd><p>Number of full bathrooms</p>
</dd>
<dt>half</dt><dd><p>number of half bathrooms</p>
</dd>
<dt>bedrooms</dt><dd><p>number of bedrooms</p>
</dd>
<dt>rooms</dt><dd><p>total number of rooms</p>
</dd>
<dt>neighborhood</dt><dd><p>Subjective assessment of neighborhood on scale
of 1-5</p>
</dd>
</dl>



<h3>Details</h3>

<p>This dataset is a random sampling of the homes sold in Maplewood, NJ
during the year 2001. Of course the prices will either seem incredibly
high or fantastically cheap depending on where you live, and if you
have recently purchased a home.
</p>


<h3>Source</h3>

<p>Source Burgdorff Realty.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(homeprice)
plot(homeprice$sale,homeprice$list)
abline(lm(homeprice$list~homeprice$sale))
</code></pre>

<hr>
<h2 id='homework'>Homework averages for Private and Public schools </h2><span id='topic+homework'></span>

<h3>Description</h3>

<p>Homework averages for Private and Public schools 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(homework)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>Private</dt><dd><p>a numeric vector</p>
</dd>
<dt>Public</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>This is from Kitchens Exploring Statistics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(homework)
boxplot(homework)
</code></pre>

<hr>
<h2 id='HUMMER'>Deliveries of new HUMMER vehicles</h2><span id='topic+HUMMER'></span>

<h3>Description</h3>

<p>Gives monthly delivery numbers for new HUMMER vehicles from June 2003 through
February 2006. During July, August, and September 2005 there was an
Employee Pricing Incentive.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(HUMMER)</code></pre>


<h3>Format</h3>

<p>The format is:
Time-Series [1:33] from 2003 to 2006: 2493 2654 2987 2837 3157 2837 3157 1927 2141 2334 ...
</p>


<h3>Source</h3>

<p>Compiled from delivery data avalailble at
http://www.gm.com/company/investor_information/sales_prod/hist_sales.html
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(HUMMER)
plot(HUMMER)
</code></pre>

<hr>
<h2 id='income_percentiles'>
Top percentiles of U.S. income
</h2><span id='topic+income_percentiles'></span>

<h3>Description</h3>

<p>Top percentiles of U.S. income
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(income_percentiles)</code></pre>


<h3>Format</h3>

<p>A data frame with <code>Year</code> and various percentile (90th, 95th, ...)
</p>


<h3>Source</h3>

<p>Not available</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(income_percentiles)
</code></pre>

<hr>
<h2 id='iq'> IQ scores </h2><span id='topic+iq'></span>

<h3>Description</h3>

<p> simulated IQ scores </p>


<h3>Usage</h3>

<pre><code class='language-R'>data(iq)</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:100] 72 75 77 77 81 82 83 84 84 86 ...
</p>


<h3>Source</h3>

<p>From Kitchens Exploring Statistics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iq)
qqnorm(iq)
</code></pre>

<hr>
<h2 id='kid.weights'>Weight and height measurement for a sample of U.S. children</h2><span id='topic+kid.weights'></span>

<h3>Description</h3>

<p>A sample from the data presented in the NHANES III survey
(<a href="https://www.cdc.gov/nchs/nhanes.htm">https://www.cdc.gov/nchs/nhanes.htm</a>). This survey is used to
form the CDC Growth Charts (<a href="https://www.cdc.gov/growthcharts/">https://www.cdc.gov/growthcharts/</a>) for
children.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(kid.weights)</code></pre>


<h3>Format</h3>

<p>A data frame with 250 observations on the following 4 variables.
</p>

<dl>
<dt>age</dt><dd><p>Age in months</p>
</dd>
<dt>weight</dt><dd><p>weight in pounds</p>
</dd>
<dt>height</dt><dd><p>height in inches</p>
</dd>
<dt>gender</dt><dd><p>Male of Female</p>
</dd>
</dl>



<h3>Source</h3>

<p>This data is extracted from  the NHANES III survey:
<a href="https://www.cdc.gov/nchs/nhanes.htm">https://www.cdc.gov/nchs/nhanes.htm</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(kid.weights)
attach(kid.weights)
plot(weight,height,pch=as.character(gender))
## find the BMI -- body mass index
m.ht = height*2.54/100        # 2.54 cm per inch
m.wt = weight / 2.2046        # 2.2046 lbs. per kg
bmi = m.wt/m.ht^2
hist(bmi)
</code></pre>

<hr>
<h2 id='KSI'>Data set on automobile deaths and injuries in Great Britain</h2><span id='topic+KSI'></span>

<h3>Description</h3>

<p>Data on car drivers killed, car drivers killed or seriously injured
(KSI), and light goods drivers killed during the years 1969 to 1984 in
Great Britain. In February 1982 a compulsory seat belt law was introduced.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(KSI)</code></pre>


<h3>Format</h3>

<p>The data is stored as a multi-variate <code>zoo</code> object.
</p>


<h3>Source</h3>

<p>Data copied from Appendix 2 &quot;Forecasting, structural time series, models and the
Kalman Filter&quot; by Andrew Harvey. The <code>lg.k</code> data is also found in
the <code>vandrivers</code> dataset contained in the <code>sspir</code> package.
</p>


<h3>References</h3>

<p>Source: HMSO: Road Accidents in Great Britain 1984.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(KSI)
plot(KSI)
seatbelt = time(KSI) &lt; 1983 + (2-1)/12

</code></pre>

<hr>
<h2 id='last.tie'> Last tie in 100 coin tosses</h2><span id='topic+last.tie'></span>

<h3>Description</h3>

<p>Toss a coin 100 times and keep a running count of the number of heads
and the number of tails. Record the times when the number is tied and
report the last one. The distribution will have an approximate
&ldquo;arc-sine&rdquo; law or well-shaped distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(last.tie)</code></pre>


<h3>Format</h3>

<p>200 numbers between 0 and 100 indicating when the last tie was.
</p>


<h3>Details</h3>

<p>This data comes from simulating the commands:
<code>x = cumsum(sample(c(-1,1),100,replace=T))</code>
</p>
<p>and then finding the
last tie with
</p>
<p><code>last.tie[i]&lt;-max(0,max(which(!sign(x) ==
    sign(x[length(x)]))))</code>. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(last.tie)
hist(last.tie)
</code></pre>

<hr>
<h2 id='lawsuits'> Law suit settlements</h2><span id='topic+lawsuits'></span>

<h3>Description</h3>

<p>A simulated dataset on the settlement amount of 250 lawsuits based on
values reported by Class Action Reports.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(lawsuits)</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:250] 16763 10489 17693 14268   442 ...
</p>


<h3>Details</h3>

<p>Class Action Reports  completed an extensive survey of attorney fee
awards from 1,120 common fund class actions (Volume 24, No. 2,
March/April 2003). The full data set is available for a fee. This data
is simulated from the values published in an excerpt.
</p>


<h3>Source</h3>

<p>Original data from http://www.classactionreports.com/classactionreports/attorneyfee.htm
</p>


<h3>References</h3>

<p>See also &quot;Study Disputes View of Costly Surge in Class-Action Suits&quot;
by Jonathan D. Glater in the January 14, 2004 New York Times which
cites a Jan. 2004 paper in the <em>Journal of Empirical Legal Studies</em> by
Eisenberg and Miller.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(lawsuits)
mean(lawsuits)
median(lawsuits)
</code></pre>

<hr>
<h2 id='lorem'>Placeholder text</h2><span id='topic+lorem'></span>

<h3>Description</h3>

<p>Lorem Ipsum is simply dummy text of the printing and typesetting industry.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lorem</code></pre>


<h3>Format</h3>

<p>a character string
</p>


<h3>Source</h3>

<p><a href="https://www.lipsum.com/">https://www.lipsum.com/</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>table(unlist(strsplit(lorem, "")))
</code></pre>

<hr>
<h2 id='malpract'> malpractice settlements  </h2><span id='topic+malpract'></span>

<h3>Description</h3>

<p> malpractice settlements  </p>


<h3>Usage</h3>

<pre><code class='language-R'>data(malpract)</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:17] 760 380 125 250 2800 450 100 150 2000 180 ...
</p>


<h3>Source</h3>

<p>From Kitchens Exploring Statistics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(malpract)
boxplot(malpract)
</code></pre>

<hr>
<h2 id='mandms'>Proportions of colors in various M and M's varieties</h2><span id='topic+mandms'></span>

<h3>Description</h3>

<p>A bag of the candy M and M's has many different colors. Each large
production batch is blended to the ratios given in this data set. The
batches are thoroughly mixed and then the individual packages are
filled by weight using high-speed equipment, not by count.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(mandms)</code></pre>


<h3>Format</h3>

<p>A data frame with 5 observations on the following 6 variables.
</p>

<dl>
<dt>blue</dt><dd><p>percentage of blue</p>
</dd>
<dt>brown</dt><dd><p>percentage of brown</p>
</dd>
<dt>green</dt><dd><p>percentage of green</p>
</dd>
<dt>orange</dt><dd><p>percentage of orange</p>
</dd>
<dt>red</dt><dd><p>percentage of red</p>
</dd>
<dt>yellow</dt><dd><p>percentage of yellow</p>
</dd>
</dl>



<h3>Source</h3>

<p>This data is attributed to an email sent by Masterfoods USA, A Mars,
Incoporated Company. This email was archived at the Math Forum,
http://www.mathforum.org (now off-line).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(mandms)
bagfull = c(15,34,7,19,29,24)
names(bagfull) = c("blue","brown","green","orange","red","yellow")
prop = function(x) x/sum(x)
chisq.test(bagfull,p = prop(mandms["milk chocolate",]))
chisq.test(bagfull,p = prop(mandms["Peanut",]))
</code></pre>

<hr>
<h2 id='math'> Standardized math scores </h2><span id='topic+math'></span>

<h3>Description</h3>

<p>Standardized math scores
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(math)</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:30] 44 49 62 45 51 59 57 55 70 64 ...
</p>


<h3>Source</h3>

<p>From Larry Kitchens, <em>Exploring Statistics</em>, Duxbury Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(math)
hist(math)
</code></pre>

<hr>
<h2 id='maydow'> Dow Jones industrial average and May maximum temperature</h2><span id='topic+maydow'></span>

<h3>Description</h3>

<p>A data set of both the Dow Jones industrial average and the maximum
daily temperature in New York City for May 2003.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(maydow)</code></pre>


<h3>Format</h3>

<p>A data frame with 21 observations on the following 3 variables.
</p>

<dl>
<dt>Day</dt><dd><p>Day of the month</p>
</dd>
<dt>DJA</dt><dd><p>The daily close of the DJIQ</p>
</dd>
<dt>max.temp</dt><dd><p>Daily maximum temperature in Central Park</p>
</dd>
</dl>



<h3>Details</h3>

<p>Are stock traders influenced by the weather? This dataset looks
briefly at this question by comparing the daily close of the Dow Jones
industrial average with the maximum daily temperature for the month of
May 2003. This month was rainy and unseasonably cool weather wise, yet
the DJIA did well.
</p>


<h3>Source</h3>

<p>The DJIA data was taken from https://finance.yahoo.com the temperature data from
<a href="https://www.noaa.gov">https://www.noaa.gov</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(maydow)
attach(maydow)
plot(max.temp,DJA)
plot(max.temp[-1],diff(DJA))
</code></pre>

<hr>
<h2 id='Medicare'>
Sample from &quot;Medicare Provider Charge Data&quot;
</h2><span id='topic+Medicare'></span>

<h3>Description</h3>

<p>Sample from &quot;Medicare Provider Charge Data&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Medicare)</code></pre>


<h3>Format</h3>

<p>A data frame with 10000 observations and data for on billings for procedures at many different hospitals.
</p>


<h3>Source</h3>

<p>http://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/Medicare-Provider-Charge-Data/index.html
</p>


<h3>References</h3>

<p>This data came from
http://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/Medicare-Provider-Charge-Data/index
and was referenced in the article
<a href="https://www.nytimes.com/2013/05/08/business/hospital-billing-varies-wildly-us-data-shows.html">https://www.nytimes.com/2013/05/08/business/hospital-billing-varies-wildly-us-data-shows.html</a>,
as retrieved on 5/8/2013.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Medicare)
</code></pre>

<hr>
<h2 id='midsize'> Price of new and used of three mid-sized cars</h2><span id='topic+midsize'></span>

<h3>Description</h3>

<p>New and used prices of three popular mid-sized cars.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(midsize)</code></pre>


<h3>Format</h3>

<p>A data frame with 15 observations on the following 4 variables.
</p>

<dl>
<dt>Year</dt><dd><p>2004 is new car price, others are for used car</p>
</dd>
<dt>Accord</dt><dd><p>Honda Accord</p>
</dd>
<dt>Camry</dt><dd><p>Toyota Camry</p>
</dd>
<dt>Taurus</dt><dd><p>Ford Taurus</p>
</dd>
</dl>



<h3>Details</h3>

<p>The value of a car depreciates over time. This data gives the price of a
new car and values of similar models for previous years as reported by
https://www.edmunds.com.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(midsize)
plot(Accord ~ I(2004-Year), data = midsize)
</code></pre>

<hr>
<h2 id='MLBattend'>Major league baseball attendance data</h2><span id='topic+MLBattend'></span>

<h3>Description</h3>

<p>Data on home-game attendance in Major League Baseball for the years
1969-2000.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(MLBattend)</code></pre>


<h3>Format</h3>

<p>A data frame with 838 observations on the following 10 variables.
</p>

<dl>
<dt>franchise</dt><dd><p>Which team</p>
</dd>
<dt>league</dt><dd><p>American or National league</p>
</dd>
<dt>division</dt><dd><p>Which division</p>
</dd>
<dt>year</dt><dd><p>The year (the year 2000 is recorded as 0)</p>
</dd>
<dt>attendance</dt><dd><p>Actual attendance</p>
</dd>
<dt>runs.scored</dt><dd><p>Runs scored by the team during year</p>
</dd>
<dt>runs.allowed</dt><dd><p>Runs allows by the team during year</p>
</dd>
<dt>wins</dt><dd><p>Number of wins for season</p>
</dd>
<dt>losses</dt><dd><p>Number of losses for season</p>
</dd>
<dt>games.behind</dt><dd><p>A measure of how far from division winner the
team was. Higher numbers are worse.</p>
</dd>
</dl>



<h3>Source</h3>

<p>This data was submitted to <em>The Journal of Statistical Education</em>
by James J. Cochran, <a href="http://jse.amstat.org/v10n2/datasets.cochran.html">http://jse.amstat.org/v10n2/datasets.cochran.html</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(MLBattend)
boxplot(attendance ~ franchise, MLBattend)
with(MLBattend, cor(attendance,wins))
</code></pre>

<hr>
<h2 id='movie_data_2011'>Movie data for 2011 by weekend</h2><span id='topic+movie_data_2011'></span>

<h3>Description</h3>

<p>Movie data for 2011 by weekend</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(movie_data_2011)</code></pre>


<h3>Format</h3>

<p>A data frame with variables <code>Previous</code> (previous weekend rank), <code>Movie</code> (title), <code>Distributor</code>, <code>Genre</code>, <code>Gross</code> (per current weekend), <code>Change</code> (change from previous week), <code>Theaters</code> (number of theaters), <code>TotalGross</code> (total gross to date), <code>Days</code> (days out), <code>weekend</code> (weekend of report)
</p>


<h3>Source</h3>

<p>Scraped from pages such as <a href="https://www.the-numbers.com/box-office-chart/weekend/2011/04/29">https://www.the-numbers.com/box-office-chart/weekend/2011/04/29</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(movie_data_2011)
</code></pre>

<hr>
<h2 id='movies'>Data frome on top 25 movies for some week, many weeks ago</h2><span id='topic+movies'></span>

<h3>Description</h3>

<p>Data on 25 top movies
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(movies)</code></pre>


<h3>Format</h3>

<p>A data frame with 26 observations on the following 5 variables.
</p>

<dl>
<dt><code>title</code></dt><dd><p>Titles</p>
</dd>
<dt><code>current</code></dt><dd><p>Current week</p>
</dd>
<dt><code>previous</code></dt><dd><p>Previous weel</p>
</dd>
<dt><code>gross</code></dt><dd><p>Total</p>
</dd>
</dl>



<h3>Source</h3>

<p>Some movie website, sorry lost the url.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(movies)
boxplot(movies$previous)
</code></pre>

<hr>
<h2 id='mw.ages'> Age distribution in year 2000 in Maplewood New Jersey </h2><span id='topic+mw.ages'></span>

<h3>Description</h3>

<p>Age distribution in Maplewood New Jersey, a suburb of New York
City. Data is broken down by Male and Female.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(mw.ages)</code></pre>


<h3>Format</h3>

<p>A data frame with 103 observations on the following 2 variables.
</p>

<dl>
<dt>Male</dt><dd><p>Counts per age group. Most groups are 1 year, except for
100-104, 105-110, 110+</p>
</dd>
<dt>Female</dt><dd><p>Same</p>
</dd>
</dl>



<h3>Source</h3>

<p>US Census 2000 data from <a href="http://factfinder.census.gov/">http://factfinder.census.gov/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(mw.ages)
barplot(mw.ages$Male + mw.ages$Female)
</code></pre>

<hr>
<h2 id='nba.draft'> NBA draft lottery odds for 2002</h2><span id='topic+nba.draft'></span>

<h3>Description</h3>

<p>The NBA draft in 2002 has a lottery
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(nba.draft)</code></pre>


<h3>Format</h3>

<p>A data frame with 13 observations on the following 2 variables.
</p>

<dl>
<dt>Team</dt><dd><p>Team name</p>
</dd>
<dt>Record</dt><dd><p>The team won-loss record</p>
</dd>
<dt>Balls</dt><dd><p>The number of balls (of 1000) that this team has in the
lottery selection</p>
</dd>
</dl>



<h3>Details</h3>

<p>The NBA draft has a lottery to determing the top 13 placings. The odds
in the lottery are determined by the won-loss record of the team, with
poorer records having better odds of winning.
</p>


<h3>Source</h3>

<p>Data is taken from <a href="https://www.nba.com/news/draft_ties_020424.html">https://www.nba.com/news/draft_ties_020424.html</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(nba.draft)
top.pick = sample(row.names(nba.draft),1,prob = nba.draft$Balls)
</code></pre>

<hr>
<h2 id='nisdc'>
NISCD
</h2><span id='topic+nisdc'></span>

<h3>Description</h3>

<p>A data frame measuring daily sea-ice extent from 1978 until 2013.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(nisdc)</code></pre>


<h3>Format</h3>

<p>A data frame measuring daily sea-ice extent from 1978 until 2013
</p>


<h3>Source</h3>

<p>ftp://sidads.colorado.edu/DATASETS/NOAA/G02135/north/daily/data/NH_seaice_extent_final.csv
and
ftp://sidads.colorado.edu/DATASETS/NOAA/G02135/north/daily/data/NH_seaice_extent_nrt.csv (now offline).
</p>


<h3>References</h3>

<p>See the blog post <a href="https://www.r-bloggers.com/2012/08/arctic-sea-ice-at-lowest-levels-since-observations-began/">https://www.r-bloggers.com/2012/08/arctic-sea-ice-at-lowest-levels-since-observations-began/</a> for a description and nice script to play with.
</p>

<hr>
<h2 id='normtemp'> Body temperature and heart rate of 130 health individuals</h2><span id='topic+normtemp'></span>

<h3>Description</h3>

<p>A data set used to investigate the claim that &ldquo;normal&rdquo; temperature is
98.6 degrees.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(normtemp)</code></pre>


<h3>Format</h3>

<p>A data frame with 130 observations on the following 3 variables.
</p>

<dl>
<dt>temperature</dt><dd><p>normal body temperature</p>
</dd>
<dt>gender</dt><dd><p>Gender 1 = male, 2 = female</p>
</dd>
<dt>hr</dt><dd><p>Resting heart rate</p>
</dd>
</dl>



<h3>Details</h3>

<p>Is normal body temperature 98.6 degrees Fahrenheit? This dataset was
constructed to match data presented in an are article intending to
establish the true value of &ldquo;normal&rdquo; body temperature.
</p>


<h3>Source</h3>

<p>This data set was contributed by Allen L. Shoemaker to the
<em>Journal of Statistics Education</em>,
<a href="http://jse.amstat.org/datasets/normtemp.txt">http://jse.amstat.org/datasets/normtemp.txt</a>.
</p>


<h3>References</h3>

<p>Data set is simulated from values contained in
Mackowiak, P. A., Wasserman, S. S., and Levine, M. M.  (1992), &quot;A
Critical Appraisal of 98.6 Degrees F, the Upper Limit of the Normal Body
Temperature, and Other Legacies of Carl Reinhold August Wunderlich,&quot;
<em>Journal of the American Medical Association</em>, 268, 1578-1580.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(normtemp)
hist(normtemp$temperature)
t.test(normtemp$temperature,mu=98.2)
summary(lm(temperature ~ factor(gender), normtemp))
</code></pre>

<hr>
<h2 id='npdb'> National Practioner Data Bank </h2><span id='topic+npdb'></span>

<h3>Description</h3>

<p>Selected variables from the publicly available data from the National
Practioner Data Bank (NPDB).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(npdb)</code></pre>


<h3>Format</h3>

<p>A data frame with 6797 observations on the following 6 variables.
</p>

<dl>
<dt>state</dt><dd><p>2 digit abbreviation of state</p>
</dd>
<dt>field</dt><dd><p>Field of practice</p>
</dd>
<dt>age</dt><dd><p>Age of practictioner (rounded down to 10s digit)</p>
</dd>
<dt>year</dt><dd><p>Year of claim</p>
</dd>
<dt>amount</dt><dd><p>Dollar amount of reward</p>
</dd>
<dt>ID</dt><dd><p>a practioner ID, masked for anonymity</p>
</dd>
</dl>

<p>The variable names do not match the original. The codings for
<code>field</code> come from a document on http://63.240.212.200/publicdata.html.
</p>


<h3>Details</h3>

<p>This dataset excerpts some interesting variables from the NPDB for the
years 2000-2003. The question of capping medical malpractice awards to
lower insurance costs is currently being debated nationwide
(U.S.). This data is a primary source for determining this debate.
</p>
<p>A quotation from  <a href="https://npdb-hipdb.com/">https://npdb-hipdb.com/</a>:
</p>
<p>&ldquo;The legislation that led to the creation of the NPDB was
enacted the U.S. Congress believed that the increasing occurrence of
medical malpractice litigation and the need to improve the quality of medical
care had become nationwide problems that warranted greater efforts than
any individual State could undertake. The intent is to improve the
quality of health care by encouraging State licensing boards, hospitals
and other health care entities, and professional societies to identify
and discipline those who engage in unprofessional behavior; and to
restrict the ability of incompetent physicians, dentists, and other
health care practitioners to move from State to State without disclosure
or discovery of previous medical malpractice payment and adverse action
history. Adverse actions can involve licensure, clinical privileges,
professional society membership, and exclusions from Medicare and
Medicaid.&rdquo;
</p>


<h3>Source</h3>

<p>This data came from <a href="https://npdb-hipdb.com/">https://npdb-hipdb.com/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(npdb)
table(table(npdb$ID))		# big offenders
hist(log(npdb$amount))		# log normal?
</code></pre>

<hr>
<h2 id='nym.2002'>Random sample of 2002 New York City Marathon finishers</h2><span id='topic+nym.2002'></span>

<h3>Description</h3>

<p>A random sample of finishers from the New York City Marathon.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(nym.2002)</code></pre>


<h3>Format</h3>

<p>A data frame with 1000 observations on the following 5 variables.
</p>

<dl>
<dt>place</dt><dd><p>Place in the race</p>
</dd>
<dt>gender</dt><dd><p>What gender</p>
</dd>
<dt>age</dt><dd><p>Age on day of race</p>
</dd>
<dt>home</dt><dd><p>Indicator of hometown or nation</p>
</dd>
<dt>time</dt><dd><p>Time in minutes to finish</p>
</dd>
</dl>



<h3>Details</h3>

<p>Each year thousands of particpants line up to run the New York City
Marathon. This list is a random sample from the finishers.
</p>


<h3>Source</h3>

<p>From the New York City Road Runners web site <a href="http://www.nyrc.org">http://www.nyrc.org</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(nym.2002)
with(nym.2002, cor(time,age))
</code></pre>

<hr>
<h2 id='ObamaApproval'>
Approval ratings for President Obama
</h2><span id='topic+ObamaApproval'></span>

<h3>Description</h3>

<p>A collection of approval ratings for President Obama spanning a duration from early 2010 to the summer of 2013.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ObamaApproval)</code></pre>


<h3>Format</h3>

<p>A data frame 7 variables.
</p>


<h3>Source</h3>

<p>Scraped on 7-5-13 from https://www.realclearpolitics.com/epolls/other/president_obama_job_approval-1044.html.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ObamaApproval)
</code></pre>

<hr>
<h2 id='OBP'> On base percentage for 2002 major league baseball season</h2><span id='topic+OBP'></span>

<h3>Description</h3>

<p>The on base percentage, <code>OBP</code>, is a measure of how often a players gets
on base. It differs from the more familiar batting average, as it
include bases on balls (<code>BB</code>) and hit by pitches (<code>HBP</code>). The exact
formula is <code>OBP = (H + BB + HBP) / (AB + BB + HBP + SF)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(OBP)</code></pre>


<h3>Format</h3>

<p>438 numbers between 0 and 1 corresponding the on base &ldquo;percentage&rdquo; for
the 438 players who had 100 or more at bats in the 2002 baseball
season. The &quot;outlier&quot; is Barry Bonds.
</p>


<h3>Source</h3>

<p>This data came from the  interesting Lahman baseball data base
<a href="http://www.seanlahman.com/">http://www.seanlahman.com/</a>. The names attribute uses the <code>playerID</code>
from this database. Unfortunately there were some errors in the
extraction from the original data set. Consult the original for
accurate numbers.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(OBP)
hist(OBP)
OBP[OBP&gt;.5]			# who is better than 50%? (only Barry Bonds)
</code></pre>

<hr>
<h2 id='oral.lesion'>Oral lesion location by town</h2><span id='topic+oral.lesion'></span>

<h3>Description</h3>

<p>A data set on oral lesion location for three Indian towns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(oral.lesion)</code></pre>


<h3>Format</h3>

<p>A data frame with 9 observations on the following 3 variables.
</p>

<dl>
<dt>Kerala</dt><dd><p>a numeric vector</p>
</dd>
<dt>Gujarat</dt><dd><p>a numeric vector</p>
</dd>
<dt>Andhra</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>&quot;Exact Inference for Categorical Data&quot;, by
Cyrus R. Mehta and Nitin R. Patel. Found at
http://www.cytel.com/papers/sxpaper.pdf. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(oral.lesion)
chisq.test(oral.lesion)$p.value
chisq.test(oral.lesion,simulate.p.value=TRUE)$p.value ## exact is.0269
</code></pre>

<hr>
<h2 id='ozonemonthly'>Monthly mean ozone values at Halley Bay Antartica</h2><span id='topic+ozonemonthly'></span>

<h3>Description</h3>

<p>A time series showing ozone values at Halley Bay Antartica
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ozonemonthly)</code></pre>


<h3>Format</h3>

<p>The format is:
Time-Series [1:590] from 1957 to 2006: 313 311 370 359 334 296 288 274 NA NA ...
- attr(*, &quot;names&quot;)= chr [1:590] &quot;V5&quot; &quot;V6&quot; &quot;V7&quot; &quot;V8&quot; ...
</p>


<h3>Details</h3>

<p>Provisional monthly mean ozone values for Halley Bay Antartica between
1956 and 2005. Data comes from <a href="https://legacy.bas.ac.uk/met/jds/ozone/">https://legacy.bas.ac.uk/met/jds/ozone/</a>.
</p>


<h3>Source</h3>

<p>Found at https://legacy.bas.ac.uk/met/jds/ozone/data/ZNOZ.DAT, now off-line.
</p>


<h3>References</h3>

<p>See <a href="https://www.meteohistory.org/2004proceedings1.1/pdfs/11christie.pdf">https://www.meteohistory.org/2004proceedings1.1/pdfs/11christie.pdf</a>
for a discussion of data collection and the Ozone hole.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ozonemonthly)
## notice decay in the 80s
plot(ozonemonthly)
## October plot shows dramatic swing
monthplot(ozonemonthly)
</code></pre>

<hr>
<h2 id='paradise'> Annual snowfall at Paradise Ranger Station, Mount Ranier</h2><span id='topic+paradise'></span>

<h3>Description</h3>

<p>Annual snowfall (from July 1 to June 30th) measured at
Paradise ranger station at Mount Ranier Washington. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(paradise)</code></pre>


<h3>Format</h3>

<p>The data is stored as a zoo class object. The time index
refers to the year the snowfall begins.
</p>


<h3>Details</h3>

<p>Due to its rapid elevation gain, and proximity to the warm
moist air of the Pacific Northwest record amounts of snow can
fall on Mount Ranier. This data set shows the
fluctuations. 
</p>


<h3>Source</h3>

<p>Original data from http://www.nps.gov/mora/current/weather.htm
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(zoo)
data(paradise)
range(paradise, na.rm=TRUE)
plot(paradise)
</code></pre>

<hr>
<h2 id='pi2000'>first 2000 digits of pi </h2><span id='topic+pi2000'></span>

<h3>Description</h3>

<p>first 2000 digits of pi </p>


<h3>Usage</h3>

<pre><code class='language-R'>data(pi2000)</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:2000] 3 1 4 1 5 9 2 6 5 3 ...
</p>


<h3>Source</h3>

<p>Generated by <em>Mathematica</em>, <a href="http://www.wolfram.com">http://www.wolfram.com</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(pi2000)
chisq.test(table(pi2000))
</code></pre>

<hr>
<h2 id='primes'> Primes numbers less than 2003</h2><span id='topic+primes'></span>

<h3>Description</h3>

<p>Prime numbers between 1 and 2003.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(primes)</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:304] 2 3 5 7 11 13 17 19 23 29 ...
</p>


<h3>Source</h3>

<p>Generated using <a href="http://www.rsok.com/~jrm/printprimes.html">http://www.rsok.com/~jrm/printprimes.html</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(primes)
diff(primes)
</code></pre>

<hr>
<h2 id='puerto'>Incomes for Puerto Rican immigrants to Miami </h2><span id='topic+puerto'></span>

<h3>Description</h3>

<p>Incomes for Puerto Rican immigrants to Miami </p>


<h3>Usage</h3>

<pre><code class='language-R'>data(puerto)</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:50] 150 280 175 190 305 380 290 300 170 315 ...
</p>


<h3>Source</h3>

<p>From Kitchens Exploring Statistics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(puerto)
hist(puerto)
</code></pre>

<hr>
<h2 id='QQplot'> Creates a qqplot with shaded density estimate </h2><span id='topic+QQplot'></span>

<h3>Description</h3>

<p>Creates a qqplot of two variables along with graphs of their
densities, shaded so that the corresponding percentiles are clearly
matched up.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>QQplot(x, y, n = 20, xsf = 4, ysf = 4, main = "qqplot", xlab = deparse(substitute(x)),
        ylab = deparse(substitute(y)), pch = 16, pcol = "black", shade = "gray", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="QQplot_+3A_x">x</code></td>
<td>
<p> The x variable</p>
</td></tr>
<tr><td><code id="QQplot_+3A_y">y</code></td>
<td>
<p> The y variable </p>
</td></tr>
<tr><td><code id="QQplot_+3A_n">n</code></td>
<td>
<p> number of points to plot in qqplot. </p>
</td></tr>
<tr><td><code id="QQplot_+3A_xsf">xsf</code></td>
<td>
<p> scale factor to adjust size of x density graph </p>
</td></tr>
<tr><td><code id="QQplot_+3A_ysf">ysf</code></td>
<td>
<p> scale factor to adjust size of y density graph </p>
</td></tr>
<tr><td><code id="QQplot_+3A_main">main</code></td>
<td>
<p> title </p>
</td></tr>
<tr><td><code id="QQplot_+3A_xlab">xlab</code></td>
<td>
<p> label for x axis </p>
</td></tr>
<tr><td><code id="QQplot_+3A_ylab">ylab</code></td>
<td>
<p> label for y axis </p>
</td></tr>
<tr><td><code id="QQplot_+3A_pch">pch</code></td>
<td>
<p> plot character for points in qqplot </p>
</td></tr>
<tr><td><code id="QQplot_+3A_pcol">pcol</code></td>
<td>
<p> color of plot character </p>
</td></tr>
<tr><td><code id="QQplot_+3A_shade">shade</code></td>
<td>
<p> shading color </p>
</td></tr>
<tr><td><code id="QQplot_+3A_...">...</code></td>
<td>
<p> extra arguments passed to <code>plot.window</code> </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Shows density estimates for the two samples in a qqplot. Meant to make
this useful plot more transparent to first-time users of
quantile-quantile plots.
</p>
<p>This function has some limitations: the scale factor may need to be
adjusted; the code to shade only shaded trapezoids, and does not
completely follow the density.
</p>


<h3>Value</h3>

<p>Produces a graphic
</p>


<h3>Author(s)</h3>

<p> John Verzani </p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+qqplot">qqplot</a></code>, <code><a href="stats.html#topic+qqnorm">qqnorm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
x = rnorm(100)
y = rt(100, df=3)
QQplot(x,y)

</code></pre>

<hr>
<h2 id='rat'>Survival times of 20 rats exposed to radiation</h2><span id='topic+rat'></span>

<h3>Description</h3>

<p>Survival times of 20 rats exposed to radiation</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(rat)</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:20] 152 152 115 109 137 88 94 77 160 165 ...
</p>


<h3>Source</h3>

<p>From Kitchents Exploring Statistics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(rat)
hist(rat)
</code></pre>

<hr>
<h2 id='reaction.time'>Reaction time with cell phone usage</h2><span id='topic+reaction.time'></span>

<h3>Description</h3>

<p>A simulated dataset on reaction time to an external event for subject
using cell phones.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(reaction.time)</code></pre>


<h3>Format</h3>

<p>A data frame with 60 observations on the following 4 variables.
</p>

<dl>
<dt>age</dt><dd><p>Age of participant coded as 16-24 or 25+</p>
</dd>
<dt>gender</dt><dd><p>Male of Female</p>
</dd>
<dt>control</dt><dd><p>Code to indicate if subject is using a cell phone &quot;T&quot;
or is in the control group &quot;C&quot;</p>
</dd>
<dt>time</dt><dd><p>Time in seconds to react to external event</p>
</dd>
</dl>



<h3>Details</h3>

<p>Several studies indicate that cell phone usage while driving can
effect reaction times to external events. This dataset uses simulated data
based on values from the  NHTSA study &quot;The Influence of the Use of
Mobile Phones on Driver Situation Awareness&quot;.
</p>


<h3>Source</h3>

<p>The NHTSA study was  found at http://www-nrd.nhtsa.dot.gov/departments/nrd-13/driver-distraction/PDF/2.PDF
</p>


<h3>References</h3>

<p>This study and others were linked from the web page http://www.accidentreconstruction.com/research/cellphones/ (now off-line).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(reaction.time)
boxplot(time ~ control, data = reaction.time)
</code></pre>

<hr>
<h2 id='reddrum'>Growth of red drum</h2><span id='topic+reddrum'></span>

<h3>Description</h3>

<p>Simulated length-at-age data for the red drum.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(reddrum)</code></pre>


<h3>Format</h3>

<p>A data frame with 100 observations on the following 2 variables.
</p>

<dl>
<dt>age</dt><dd><p>age</p>
</dd>
<dt>length</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>This data is simulated from values reported in a paper by Porch,
Wilson and Nieland titled &quot;A new growth model for red drum (Sciaenops
ocellaus) that accommodates seasonal and ontogenic changes in growth
rates&quot; which appeard in <em>Fishery Bulletin</em> 100(1)
(was at http://fishbull.noaa.gov/1001/por.pdf, now off-line). They attribute the data
to Beckman et. al and say it comes from measurements in the Northern
Gulf of Mexico, between September 1985 and October 1998.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(reddrum)
plot(length ~ age, reddrum)
</code></pre>

<hr>
<h2 id='salmon.rate'>Simulated Data on Rate of Recruitment for Salmon</h2><span id='topic+salmon.rate'></span>

<h3>Description</h3>

<p>The Ricker model is used to model the relationship of recruitment of a
salmon species versus the number of spawners. The model has two
parameters, a rate of growth at small numbers and a decay rate at large
numbers. This data set is simulated data for 83 different recordings
using parameters found in a paper by Chen and Holtby.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(salmon.rate)</code></pre>


<h3>Format</h3>

<p>The format is:
83 numbers on decay rates.
</p>


<h3>Details</h3>

<p>The Ricker model for recruitment modeled by spawner count </p>
<p style="text-align: center;"><code class="reqn">R_t =
  S_t e^{a - bS_t}</code>
</p>
<p> The paramter <code class="reqn">b</code> is a decay rate
for large values of <code class="reqn">S</code>. In the paper by Chen and Holtby, they
studied 83 datasets and found that <code class="reqn">b</code> is log-normally distributed. The
data is simulated from their values to illustrate a log normal
distribution.
</p>


<h3>Source</h3>

<p>These values are from D.G. Chen and L. Blair Holtby, &ldquo;A regional
meta-model for stock recruitment analysis using an empirical
Bayesian approach&rdquo;, found at <a href="https://iphc.int/">https://iphc.int/</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(salmon.rate)
hist(log(salmon.rate))
</code></pre>

<hr>
<h2 id='salmonharvest'> Salmon harvest in Alaska from 1980 to 1998</h2><span id='topic+salmonharvest'></span>

<h3>Description</h3>

<p>A data set of unofficial tallies of salmon harvested in Alaska between
the years 1980 and 1998. The units are in thousands of fish.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(salmonharvest)</code></pre>


<h3>Format</h3>

<p>A multiple time series object with yearly sampling for the five species
Chinook, Sockeye, Coho, Pink, and Chum.
</p>


<h3>Source</h3>

<p>This data was found at http://seamarkets.alaska.edu/ak_harv_fish.htm
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(salmonharvest)
acf(salmonharvest)
</code></pre>

<hr>
<h2 id='samhda'> Substance Abuse and Mental Health Data for teens </h2><span id='topic+samhda'></span>

<h3>Description</h3>

<p>A data frame containing data on health behaviour for school-aged children.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(samhda)</code></pre>


<h3>Format</h3>

<p>A data frame with 600 observations on the following 9 variables.
</p>

<dl>
<dt>wt</dt><dd><p>A numeric weight used in sampling</p>
</dd>
<dt>gender</dt><dd><p>1=Male, 2=Female, 7=not recorded</p>
</dd>
<dt>grade</dt><dd><p>1 = 6th, 2 = 8th, 3 = 10th</p>
</dd>
<dt>live.with.father</dt><dd><p>1 = Y, 2 = N</p>
</dd>
<dt>amt.smoke</dt><dd><p>Amount of days you smoked cigarettes in last 30. 1 = all 30, 2=
20-29, 3 = 10-19, 4 = 6-9, 5= 3-5, 6 = 1-2, 7=0</p>
</dd>
<dt>alcohol</dt><dd><p>Have you ever drank alcohol, 1 = Y, 2 = N</p>
</dd>
<dt>amt.alcohol</dt><dd><p>Number of days in last 30 in which you drank
alcohol </p>
</dd>
<dt>marijuana</dt><dd><p>Ever smoke marijuana. 1 = Y, 2= N</p>
</dd>
<dt>amt.marijuana</dt><dd><p>Number of days in lst 30 that marijuana was
used. 1 = Never used, 2 = all 30, 3 =
20-29, 4 = 10-19, 5 = 6-9, 6 = 3-5, 7 = 1-2, 8 =Used, but not in
last 30 days</p>
</dd>
</dl>



<h3>Details</h3>

<p>A data frame containing data on health behaviour for school-aged children.
</p>


<h3>Source</h3>

<p>This data is sampled from the data set  &quot;Health Behavior in School-Aged
Children, 1996: [United States]&quot; collected by the World Health
Organization, https://www.icpsr.umich.edu/. It is available at
the Substance Abuse and Mental Health Data Archive (SAMHDA). Only
complete cases are given.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(samhda)
attach(samhda)
table(amt.smoke)
</code></pre>

<hr>
<h2 id='SAT'>
SAT data with expenditures
</h2><span id='topic+SAT'></span>

<h3>Description</h3>

<p>This dataset contains variables that address the
relationship between public school expenditures and academic
performance, as measured by the SAT.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(SAT)</code></pre>


<h3>Format</h3>

<p>A data frame with variables <code>state</code>, <code>expend</code>
(expenditure per pupil), <code>ratio</code> (pupil/teacher ratio);
<code>salary</code> (average teacher salary; <code>percentage of SAT
takers</code>; <code>verbal</code> (verbal score); <code>math</code> (math score);
<code>total</code> (average total).
</p>


<h3>Source</h3>

<p>The data came from http://www.amstat.org/publications/jse/datasets/sat.txt
</p>


<h3>References</h3>

<p>This data comes from
http://www.amstat.org/publications/jse/secure/v7n2/datasets.guber.cfm. It
is also included in the <span class="pkg">mosaic</span> package and commented on at
http://sas-and-r.blogspot.com/2012/02/example-920-visualizing-simpsons.html. The
variables are described at
http://www.amstat.org/publications/jse/datasets/sat.txt.
</p>
<p>The author references the original source: The variables in this
dataset, all aggregated to the state level, were extracted from the
1997 <em>Digest of Education Statistics</em>, an annual publication
of the U.S. Department of Education.  Data from a number of
different tables were downloaded from the National Center for
Education Statistics (NCES) website (Available at:
http://nces01.ed.gov/pubs/digest97/index.html) and merged
into a single data file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SAT)
</code></pre>

<hr>
<h2 id='scatter.with.hist'> Scatterplot with histograms </h2><span id='topic+scatter.with.hist'></span>

<h3>Description</h3>

<p>Draws a scatterplot of the data, and histogram in the margins. A
trend line can be added, if desired.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scatter.with.hist(x, y,
  hist.col = gray(0.95),
  trend.line = "lm",
   ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scatter.with.hist_+3A_x">x</code></td>
<td>
<p> numeric predictor </p>
</td></tr>
<tr><td><code id="scatter.with.hist_+3A_y">y</code></td>
<td>
<p> numeric response variables </p>
</td></tr>
<tr><td><code id="scatter.with.hist_+3A_hist.col">hist.col</code></td>
<td>
<p> color for histogram </p>
</td></tr>
<tr><td><code id="scatter.with.hist_+3A_trend.line">trend.line</code></td>
<td>
<p> Draw a trend line using <code><a href="stats.html#topic+lm">lm</a></code>,
<code><a href="stats.html#topic+supsmu">supsmu</a></code> or <code><a href="stats.html#topic+lowess">lowess</a></code>. Use <code>NULL</code> for
none.</p>
</td></tr>
<tr><td><code id="scatter.with.hist_+3A_...">...</code></td>
<td>
<p> Passed to <code><a href="graphics.html#topic+plot">plot</a></code> command for scatterplot</p>
</td></tr> </table>


<h3>Value</h3>

<p>Draws the graphic. No return value.
</p>


<h3>Author(s)</h3>

<p> John Verzani </p>


<h3>References</h3>

<p> This example comes from the help page for <code><a href="graphics.html#topic+layout">layout</a></code>. </p>


<h3>See Also</h3>

 <p><code><a href="graphics.html#topic+layout">layout</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(emissions)
attach(emissions)
scatter.with.hist(perCapita,CO2)
</code></pre>

<hr>
<h2 id='scrabble'> Distribution of Scrabble pieces</h2><span id='topic+scrabble'></span>

<h3>Description</h3>

<p>Distribution and point values of letters in Scrabble.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(scrabble)</code></pre>


<h3>Format</h3>

<p>A data frame with 27 observations on the following 3 variables.
</p>

<dl>
<dt>piece</dt><dd><p>Which piece</p>
</dd>
<dt>points</dt><dd><p>point value</p>
</dd>
<dt>frequency</dt><dd><p>Number of pieces</p>
</dd>
</dl>



<h3>Details</h3>

<p>Scrabble is a popular board game based on forming words from the
players' pieces. These consist of letters drawn from a pile at
random. The game has a certain frequency of letters given by this
data. These match fairly well with the letter distribution of the
English language.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(scrabble)
## perform chi-squared analysis on long string. Is it in English?
quote = " R is a language and environment for statistical computing  \
and graphics. It is a GNU project which is similar to the S language \
and environment which was developed at Bell Laboratories (formerly   \
AT&amp;T, now Lucent Technologies) by John Chambers and colleagues. R    \
can be considered as a different implementation of S. There are      \
some important differences, but much code written for S runs         \
unaltered under R."
quote.lc = tolower(quote)
quote = unlist(strsplit(quote.lc,""))
ltr.dist = sapply(c(letters," "),function(x) sum(quote == x))
chisq.test(ltr.dist,,scrabble$freq)

</code></pre>

<hr>
<h2 id='simple.chutes'>simulate a chutes and ladder game</h2><span id='topic+simple.chutes'></span>

<h3>Description</h3>

<p>This function will simulate a chutes and ladder game. It 
returns a trajectory for a single player. Optionally it can return the 
transition matrix which can be used to speed up the simulation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simple.chutes(sim=FALSE, return.cl=FALSE, cl=make.cl())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simple.chutes_+3A_sim">sim</code></td>
<td>
<p>Set to TRUE to return a trajectory.</p>
</td></tr>
<tr><td><code id="simple.chutes_+3A_return.cl">return.cl</code></td>
<td>
<p>Set to TRUE to return a transistion matrix </p>
</td></tr>
<tr><td><code id="simple.chutes_+3A_cl">cl</code></td>
<td>
<p>set to the chutes and ladders transition matrix </p>
</td></tr>
</table>


<h3>Details</h3>

<p>To make a chutes and ladders trajectory
</p>
<p>simple.chutes(sim=TRUE)
</p>
<p>To return the game board
</p>
<p>simple.chutes(return.cl=TRUE)
</p>
<p>when doing a lot of simulations, it may be best to pass in the game
board
</p>
<p>cl &lt;- simple.chutes(return.cl=TRUE)
simple.chutes(sim=TRUE,cl)
</p>


<h3>Value</h3>

<p>returns a trajectory as a vector, or a matrix if asked to return the
transition matrix
</p>


<h3>Author(s)</h3>

<p>John Verzani</p>


<h3>References</h3>

<p> board was from http://www.ahs.uwaterloo.ca/~musuem/vexhibit/Whitehill/snakes/snakes.gif  </p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(simple.chutes(sim=TRUE))
</code></pre>

<hr>
<h2 id='simple.densityplot'> Plots densities of data </h2><span id='topic+simple.densityplot'></span><span id='topic+simple.densityplot.default'></span><span id='topic+simple.densityplot.formula'></span><span id='topic+dnstyplt'></span>

<h3>Description</h3>

<p>Allows one to compare empirical densities of different distributions
in a simple manner. The density is used as graphs with multiple
histograms are too crowded. The usage is similar to side-by-side boxplots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simple.densityplot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simple.densityplot_+3A_x">x</code></td>
<td>
<p>x may be a sequence of data vectors (eg. x,y,z), a data frame 
with numeric column vectors or a model formula</p>
</td></tr>
<tr><td><code id="simple.densityplot_+3A_...">...</code></td>
<td>
<p>You can pass in a bandwidth argument such as bw=&quot;SJ&quot;. See 
density for details. A legend will be placed for you automatically. To 
overide the positioning set do.legend=&quot;manual&quot;. To skip the legend,
set do.legend=FALSE. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Makes a plot
</p>


<h3>Author(s)</h3>

<p> John Verzani</p>


<h3>References</h3>

<p> Basically a modified boxplot function. As well it should be 
as it serves the same utility: comparing distributions.</p>


<h3>See Also</h3>

 <p><code><a href="graphics.html#topic+boxplot">boxplot</a></code>,<code><a href="#topic+simple.violinplot">simple.violinplot</a></code>,<code><a href="stats.html#topic+density">density</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## taken from boxplot
## using a formula
data(InsectSprays)
simple.densityplot(count ~ spray, data = InsectSprays)
## on a matrix (data frame)
mat &lt;- cbind(Uni05 = (1:100)/21, Norm = rnorm(100),
             T5 = rt(100, df = 5), Gam2 = rgamma(100, shape = 2))
simple.densityplot(data.frame(mat))


</code></pre>

<hr>
<h2 id='simple.eda'> Simple function to plot histogram, boxplot and normal plot </h2><span id='topic+simple.eda'></span>

<h3>Description</h3>

<p>Simply plots histogram, boxplot and normal plot for experimental data
analysis. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simple.eda(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simple.eda_+3A_x">x</code></td>
<td>
<p> a vector of data </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Just does the plots. No return value
</p>


<h3>Author(s)</h3>

<p> John Verzani </p>


<h3>References</h3>

<p> Inspired by S-Plus documentation </p>


<h3>See Also</h3>

<p>hist,boxplot,qnorm </p>


<h3>Examples</h3>

<pre><code class='language-R'>  x&lt;- rnorm(100,5,10)
  simple.eda(x)
</code></pre>

<hr>
<h2 id='simple.eda.ts'>Makes 3 useful graphs for eda of times series </h2><span id='topic+simple.eda.ts'></span>

<h3>Description</h3>

<p>This makes 3 graphs to check for serial correlation in data. The
graphs are a sequential plot (i vs <code class="reqn">X_i</code>), a lag plot
(plotting <code class="reqn">X_i</code> vs <code class="reqn">X_i</code> where k=1 by default)
and an autocorrelation plot from the times series (&quot;ts&quot;) package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simple.eda.ts(x, lag=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simple.eda.ts_+3A_x">x</code></td>
<td>
<p> a univariate vector of data </p>
</td></tr>
<tr><td><code id="simple.eda.ts_+3A_lag">lag</code></td>
<td>
<p> a lag to give to the lag plot </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Makes the graph with 1 row, 3 columns
</p>


<h3>Author(s)</h3>

<p> John Verzani </p>


<h3>References</h3>

<p> Downloaded from
http://www.itl.nist.gov/div898/handbook/eda/section3/eda34.htm.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The function is currently defined as

## look for no correlation
x &lt;- rnorm(100);simple.eda.ts(x)
## you will find correlation here
simple.eda.ts(cumsum(x))
</code></pre>

<hr>
<h2 id='simple.fancy.stripchart'> Makes a fancier strip chart: plots means and a line </h2><span id='topic+simple.fancy.stripchart'></span>

<h3>Description</h3>

<p>Not much, just hides some ugly code
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simple.fancy.stripchart(l)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simple.fancy.stripchart_+3A_l">l</code></td>
<td>
<p> A list with each element to be plotted with a stripchart </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Creates the plot
</p>


<h3>Author(s)</h3>

<p> John Verzani </p>


<h3>See Also</h3>

<p> stripchart </p>


<h3>Examples</h3>

<pre><code class='language-R'>x = rnorm(10);y=rnorm(10,1)
simple.fancy.stripchart(list(x=x,y=y))
</code></pre>

<hr>
<h2 id='simple.freqpoly'> Simply plot histogram and frequency polygon </h2><span id='topic+simple.freqpoly'></span>

<h3>Description</h3>

<p>Simply plot histogram and frequency polygon. Students do  not need to
know how to add lines to a histogram, and how to extract values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simple.freqpoly(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simple.freqpoly_+3A_x">x</code></td>
<td>
<p> a vector of data </p>
</td></tr>
<tr><td><code id="simple.freqpoly_+3A_...">...</code></td>
<td>
<p> arguments passed onto histogram </p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns just the plot
</p>


<h3>Author(s)</h3>

<p> John Verzani</p>


<h3>See Also</h3>

<p>hist,density </p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rt(100,4)
simple.freqpoly(x)
</code></pre>

<hr>
<h2 id='simple.hist.and.boxplot'>A function to plot both a histogram and a boxplot</h2><span id='topic+simple.hist.and.boxplot'></span><span id='topic+simple.plot.hist.and.box'></span>

<h3>Description</h3>

<p>Simple function to plot both histogram and boxplot to compare
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simple.hist.and.boxplot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simple.hist.and.boxplot_+3A_x">x</code></td>
<td>
<p> vector of univariate data </p>
</td></tr>
<tr><td><code id="simple.hist.and.boxplot_+3A_...">...</code></td>
<td>
<p> Arguments passed to the hist function </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Just prints the two graphs
</p>


<h3>Author(s)</h3>

<p>John Verzani</p>


<h3>See Also</h3>

<p>hist,boxplot,layout </p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-rnorm(100)
simple.hist.and.boxplot(x)
</code></pre>

<hr>
<h2 id='simple.lag'> applies function to moving subsets of a data vector </h2><span id='topic+simple.lag'></span>

<h3>Description</h3>

<p>Used to apply a function to subsets of a data vector. In particular,
it is used to find moving averages over a certain &quot;lag&quot; period.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simple.lag(x, lag, FUN = mean)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simple.lag_+3A_x">x</code></td>
<td>
<p> a data vector </p>
</td></tr>
<tr><td><code id="simple.lag_+3A_lag">lag</code></td>
<td>
<p> the lag amount to use. </p>
</td></tr>
<tr><td><code id="simple.lag_+3A_fun">FUN</code></td>
<td>
<p> a function to apply to the lagged data. Defaults to mean </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function FUN is applied to the data x[(i-lag):i] and assigned to
the (i-lag)th component of the return vector. Useful for finding
moving averages.
</p>


<h3>Value</h3>

<p>returns a vector.
</p>


<h3>Author(s)</h3>

<p> Provided to R help list by Martyn Plummer </p>


<h3>See Also</h3>

<p> filter </p>


<h3>Examples</h3>

<pre><code class='language-R'>## find a moving average of the dow daily High
data(dowdata)
lag = 50; n = length(dowdata$High)
plot(simple.lag(dowdata$High,lag),type="l")
lines(dowdata$High[lag:n])
</code></pre>

<hr>
<h2 id='simple.lm'> Simplify usage of lm </h2><span id='topic+simple.lm'></span>

<h3>Description</h3>

<p>Simplify usage of lm by avoiding model notation, drawing plot, drawing 
regression line, drawing confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simple.lm(x, y, show.residuals=FALSE, show.ci=FALSE, conf.level=0.95,pred=)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simple.lm_+3A_x">x</code></td>
<td>
<p> The predictor variable </p>
</td></tr>
<tr><td><code id="simple.lm_+3A_y">y</code></td>
<td>
<p> The response variable </p>
</td></tr>
<tr><td><code id="simple.lm_+3A_show.residuals">show.residuals</code></td>
<td>
<p> set to TRUE to plot residuals </p>
</td></tr>
<tr><td><code id="simple.lm_+3A_show.ci">show.ci</code></td>
<td>
<p> set to TRUE to plot confidence intervals </p>
</td></tr>
<tr><td><code id="simple.lm_+3A_conf.level">conf.level</code></td>
<td>
<p> if show.ci=TRUE will plot these CI's at this level
</p>
</td></tr>
<tr><td><code id="simple.lm_+3A_pred">pred</code></td>
<td>
<p> values of the x-variable for prediction</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns plots and an instance of lm, as though it were called
<code>lm(y ~ x)</code>
</p>


<h3>Author(s)</h3>

<p> John Verzani </p>


<h3>See Also</h3>

<p>lm </p>


<h3>Examples</h3>

<pre><code class='language-R'>## on simulated data
x&lt;-1:10
y&lt;-5*x + rnorm(10,0,1)
tmp&lt;-simple.lm(x,y)
summary(tmp)

## predict values
simple.lm(x,y,pred=c(5,6,7))
</code></pre>

<hr>
<h2 id='simple.median.test'> Do simple sign test for median &ndash; no ranks </h2><span id='topic+simple.median.test'></span>

<h3>Description</h3>

<p>Do simple sign test like wilcox.test without ranking. Just computes
two-sided p-value, no confidence interval is given.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simple.median.test(x, median=NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simple.median.test_+3A_x">x</code></td>
<td>
<p> A data vector </p>
</td></tr>
<tr><td><code id="simple.median.test_+3A_median">median</code></td>
<td>
<p>The value of median under the null hyptohesis </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Unlike wilcox.test, this tests the null hypothesis that the median is
specified agains the two-sided alternative. For illustration purposes
only. 
</p>


<h3>Value</h3>

<p>Returns the p value.
</p>


<h3>Author(s)</h3>

<p> John Verzani  </p>


<h3>See Also</h3>

<p> wilcox.test </p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-c(12,2,17,25,52,8,1,12)
simple.median.test(x,20)
</code></pre>

<hr>
<h2 id='simple.scatterplot'> Simple scatter plot of x versus y with histograms of each </h2><span id='topic+simple.scatterplot'></span>

<h3>Description</h3>

<p>Shows scatterplot of x vs y with histograms of each on sides of
graph. As in the example from layout.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simple.scatterplot(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simple.scatterplot_+3A_x">x</code></td>
<td>
<p> data vector </p>
</td></tr>
<tr><td><code id="simple.scatterplot_+3A_y">y</code></td>
<td>
<p> data vector </p>
</td></tr>
<tr><td><code id="simple.scatterplot_+3A_...">...</code></td>
<td>
<p> passed to plot command </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the plot
</p>


<h3>Author(s)</h3>

<p> John Verzani </p>


<h3>See Also</h3>

<p>layout </p>


<h3>Examples</h3>

<pre><code class='language-R'>  x&lt;-sort(rnorm(100))
  y&lt;-sort(rt(100,3))
  simple.scatterplot(x,y)

</code></pre>

<hr>
<h2 id='simple.sim'>Simplify the process of simulation</h2><span id='topic+simple.sim'></span>

<h3>Description</h3>

<p>'simple.sim' is intended to make it a little easier to do simulations
with R. Instead of writing a for loop, or dealing with column or row
sums, a student can use this &quot;simpler&quot; interface.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simple.sim(no.samples, f, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simple.sim_+3A_no.samples">no.samples</code></td>
<td>
<p>How many samples do you wish to generate </p>
</td></tr>
<tr><td><code id="simple.sim_+3A_f">f</code></td>
<td>
<p>A function which generates a single random number from some
distributions. simple.sim generates the rest.</p>
</td></tr>
<tr><td><code id="simple.sim_+3A_...">...</code></td>
<td>
<p>parameters passed to f. It does not like named parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is simply a wrapper for a for loop that uses the function f to
create random numbers from some distribution.
</p>


<h3>Value</h3>

<p>returns a vector of size no.samples
</p>


<h3>Note</h3>

<p>There must be a 1000 better ways to do this. See <code><a href="base.html#topic+replicate">replicate</a></code> or <code><a href="base.html#topic+sapply">sapply</a></code> for example.</p>


<h3>Author(s)</h3>

<p>John Verzani</p>


<h3>Examples</h3>

<pre><code class='language-R'>## First shows trivial (and very unnecessary usage)
## define a function f and then simulate
f&lt;-function() rnorm(1)     # create a single random real number
sim &lt;- simple.sim(100,f)   # create 100 random normal numbers
hist(sim)

## what does range look like?
f&lt;- function (n,mu=0,sigma=1) {
  tmp &lt;- rnorm(n,mu,sigma)
  max(tmp) - min(tmp)
}
sim &lt;- simple.sim(100,f,5)
hist(sim)
</code></pre>

<hr>
<h2 id='simple.violinplot'> Plots violinplots instead of boxplots </h2><span id='topic+simple.violinplot'></span><span id='topic+simple.violinplot.formula'></span><span id='topic+simple.violinplot.default'></span><span id='topic+vlnplt'></span>

<h3>Description</h3>

<p>This function serves the same utility as side-by-side boxplots, only
it provides more detail about the different distribution. It
plots violinplots instead of boxplots. That is, instead of a box, it
uses the density function to plot the density. For skewed
distributions, the results look like &quot;violins&quot;. Hence the name.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simple.violinplot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simple.violinplot_+3A_x">x</code></td>
<td>
<p>Either a sequence of variable names, or a data frame, or a
model formula</p>
</td></tr>
<tr><td><code id="simple.violinplot_+3A_...">...</code></td>
<td>
<p>You can pass arguments to polygon with this. Notably, you 
can set the color to red with col='red', and a border color with border='blue'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a plot.
</p>


<h3>Author(s)</h3>

<p> John Verzani </p>


<h3>References</h3>

<p> This is really the boxplot function from R/base with some
minor adjustments </p>


<h3>See Also</h3>

<p> boxplot, simple.densityplot </p>


<h3>Examples</h3>

<pre><code class='language-R'>## make a "violin"
x &lt;- rnorm(100) ;x[101:150] &lt;- rnorm(50,5)
simple.violinplot(x,col="brown")
f&lt;-factor(rep(1:5,30))
## make a quintet. Note also choice of bandwidth
simple.violinplot(x~f,col="brown",bw="SJ")



</code></pre>

<hr>
<h2 id='simple.z.test'> Implement basic z-test for illustrative purposes </h2><span id='topic+simple.z.test'></span>

<h3>Description</h3>

<p>Imlements a z-test similar to the t.test function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simple.z.test(x, sigma, conf.level=0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simple.z.test_+3A_x">x</code></td>
<td>
<p>A data vector </p>
</td></tr>
<tr><td><code id="simple.z.test_+3A_sigma">sigma</code></td>
<td>
<p> the known variance </p>
</td></tr>
<tr><td><code id="simple.z.test_+3A_conf.level">conf.level</code></td>
<td>
<p> Confidence level for confidence interval </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a confidence interval for the mean
</p>


<h3>Author(s)</h3>

<p> Joh Verzani </p>


<h3>See Also</h3>

<p> t.test, prop.test </p>


<h3>Examples</h3>

<pre><code class='language-R'>  x&lt;-rnorm(10,0,5)
  simple.z.test(x,5)
</code></pre>

<hr>
<h2 id='skateranks'> Judges scores for disputed ice skating competition</h2><span id='topic+skateranks'></span>

<h3>Description</h3>

<p>Judges scores from the disputed ice skating competition at the 2002
Winter olympics
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(skateranks)</code></pre>


<h3>Format</h3>

<p>A data frame with 20 observations on the following 11 variables.
</p>

<dl>
<dt>Name</dt><dd><p>a factor with levels <code>Berankova/Diabola</code> <code>Berezhnaya/Sikharulidze</code> <code>Bestnadigova/Bestandif</code> <code>Chuvaeva/Palamarchuk</code> <code>Cobisi/DePra</code> <code>Ina/Zimmerman</code> <code>Kautz/Jeschke</code> <code>Krasitseva/Znachkov</code> <code>Langlois/Archetto</code> <code>Lariviere/Faustino</code> <code>Pang/Tong</code> <code>Petrova/Tikhonov</code> <code>Ponomareva/SWviridov</code> <code>Savchenko/Morozov</code> <code>Scott/Dulebohn</code> <code>Sele/Pelletier</code> <code>Shen/Zhao</code> <code>Totmianina/Marinin</code> <code>Zagorska/Siudek</code> <code>Zhang/Zhang</code></p>
</dd>
<dt>Country</dt><dd><p>a factor with levels <code>Armenia</code> <code>Canada</code> <code>China</code> <code>Czech</code> <code>Germany</code> <code>Italy</code> <code>Poland</code> <code>Russia</code> <code>Slovakia</code> <code>US</code> <code>Ukraine</code> <code>Uzbekistan</code></p>
</dd>
<dt>Russia</dt><dd><p>a numeric vector</p>
</dd>
<dt>China</dt><dd><p>a numeric vector</p>
</dd>
<dt>US</dt><dd><p>a numeric vector</p>
</dd>
<dt>France</dt><dd><p>a numeric vector</p>
</dd>
<dt>Poland</dt><dd><p>a numeric vector</p>
</dd>
<dt>Canada</dt><dd><p>a numeric vector</p>
</dd>
<dt>Ukraine</dt><dd><p>a numeric vector</p>
</dd>
<dt>Germany</dt><dd><p>a numeric vector</p>
</dd>
<dt>Japan</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(skateranks)
</code></pre>

<hr>
<h2 id='slc'> Sodium-Lithium countertransport </h2><span id='topic+slc'></span>

<h3>Description</h3>

<p> Sodium-Lithium countertransport </p>


<h3>Usage</h3>

<pre><code class='language-R'>data(slc)</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:190] 0.467 0.430 0.192 0.192 0.293 ...
</p>


<h3>Source</h3>

<p>From Kitchens' Exploring Statistics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(slc)
hist(slc)
</code></pre>

<hr>
<h2 id='smokyph'>Water pH levels at 75 water samples in the Great Smoky Mountains </h2><span id='topic+smokyph'></span>

<h3>Description</h3>

<p>Water pH levels at 75 water samples in the Great Smoky Mountains 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(smokyph)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>waterph</dt><dd><p>a numeric vector</p>
</dd>
<dt>elev</dt><dd><p>a numeric vector</p>
</dd>
<dt>code</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>From Kitchens' Exploring Statistics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(smokyph)
plot(smokyph$elev,smokyph$waterph)
</code></pre>

<hr>
<h2 id='snacks'>
Snack data from the USDA
</h2><span id='topic+snacks'></span>

<h3>Description</h3>

<p> subset of SR26 data on nutrients compiled by the USDA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(snacks)</code></pre>


<h3>Format</h3>

<p>A data frame with some nutrition variables
</p>


<h3>Source</h3>

<p>This data came from the SR26 data set found at <a href="http://www.ars.usda.gov/Services/docs.htm?docid=8964">http://www.ars.usda.gov/Services/docs.htm?docid=8964</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(snacks)
</code></pre>

<hr>
<h2 id='south'> Murder rates for 30 Southern US cities</h2><span id='topic+south'></span>

<h3>Description</h3>

<p> Murder rates for 30 Southern US cities</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(south)</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:30] 12 10 10 13 12 12 14 7 16 18 ...
</p>


<h3>Source</h3>

<p>From Kitchens' Exploring Statistics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(south)
hist(south)
</code></pre>

<hr>
<h2 id='southernosc'> Southern Oscillations</h2><span id='topic+southernosc'></span>

<h3>Description</h3>

<p>The southern oscillation is defined as the barametric pressure
difference between Tahiti and the Darwin Islands at sea level. The
southern oscillation is a predictor of el nino which in turn is
thought to be a driver of world-wide weather. Specifically, repeated
southern oscillation values less than -1 typically defines an el nino.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(southernosc)</code></pre>


<h3>Format</h3>

<p>The format is:
Time-Series [1:456] from 1952 to 1990: -0.7 1.3 0.1 -0.9 0.8 1.6 1.7 1.4 1.4 1.5 ...
</p>


<h3>Source</h3>

<p>Originally downloaded from http://www.itl.nist.gov/div898/handbook/pmc/section4/pmc4412.htm
</p>


<h3>References</h3>

<p>A description was available at
http://www.itl.nist.gov/div898/handbook/pmc/section4/pmc4461.htm
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(southernosc)
plot(southernosc)
</code></pre>

<hr>
<h2 id='sp500.excess'> Excess returns of S\&amp;P 500 </h2><span id='topic+sp500.excess'></span>

<h3>Description</h3>

<p>Excess returns of S\&amp;P 500. These are defined as the
difference between the series and some riskless asset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(sp500.excess)</code></pre>


<h3>Format</h3>

<p>The format is:
Time-Series [1:792] from 1929 to 1995: 0.0225 -0.044 -0.0591 0.0227 0.0077 0.0432 0.0455 0.0171 0.0229 -0.0313 ...
</p>


<h3>Source</h3>

<p>This data set is used in Tsay, Analysis of Financial Time
Series.  At the time, it was downloaded from
www.gsb.uchicago.edu/fac/ruey.tsay/teaching/fts (now off-line). The
fSeries package may also contain this data set.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sp500.excess)
plot(sp500.excess)
</code></pre>

<hr>
<h2 id='Split.zoo'> Add split method for zoo objects</h2><span id='topic+Split.zoo'></span>

<h3>Description</h3>

<p>Splits zoo objects by a grouping variable ala split(). Each univariate
series is turned into a multivariate zoo object. If the original
series is multivariate, the output is a list of multivariate zoo objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Split.zoo(x, f)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Split.zoo_+3A_x">x</code></td>
<td>
<p>an univariate or multivariate zoo object </p>
</td></tr>
<tr><td><code id="Split.zoo_+3A_f">f</code></td>
<td>
<p>A grouping variable of the same length of x. A warning is
given is length(f) is not the same as index size of x</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a multivariate zoo object, or list of such.
</p>


<h3>Author(s)</h3>

<p> John Verzani</p>


<h3>See Also</h3>

 <p><code><a href="base.html#topic+split">split</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>if(require(zoo)) {
split.zoo = Split.zoo ## make generic
x = zoo(1:30,1:30)
f = sample(letters[1:5],30, replace=TRUE)
split(x,f)
}
</code></pre>

<hr>
<h2 id='squareplot'> Create a squareplot alternative to a segmented barplot </h2><span id='topic+squareplot'></span>

<h3>Description</h3>

<p>Create a squareplot as an alternative to a segmented barplot. Useful
when the viewer is interested in exact counts in the categories. A
squareplot is often used  by the <em>New York Times</em>. A grid of squares
is presented with each color representing a different category. The
colors appear contiguously reading top to bottom, left to right. The
colors segment the graph as a segmented bargraph, but the squares
allow an interested reader to easily tally the counts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>squareplot(x, col = gray(seq(0.5, 1, length = length(x))),
border =NULL, nrows = ceiling(sqrt(sum(x))), ncols =
ceiling(sum(x)/nrows),
...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="squareplot_+3A_x">x</code></td>
<td>
<p> a vector of counts</p>
</td></tr>
<tr><td><code id="squareplot_+3A_col">col</code></td>
<td>
<p> a vector of colors </p>
</td></tr>
<tr><td><code id="squareplot_+3A_border">border</code></td>
<td>
<p>border color passed to <code><a href="graphics.html#topic+polygon">polygon</a></code></p>
</td></tr>
<tr><td><code id="squareplot_+3A_nrows">nrows</code></td>
<td>
<p>number of rows</p>
</td></tr>
<tr><td><code id="squareplot_+3A_ncols">ncols</code></td>
<td>
<p>number of columns </p>
</td></tr>
<tr><td><code id="squareplot_+3A_...">...</code></td>
<td>
<p> passed to <code>title</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Creates the graph, but has no return  value.
</p>


<h3>Author(s)</h3>

<p> John Verzani </p>


<h3>References</h3>

<p> The <em>New York Times</em>, <a href="https://www.nytimes.com">https://www.nytimes.com</a>. In particular,
Sports page 6, June 15, 2003. </p>


<h3>Examples</h3>

<pre><code class='language-R'>## A Roger Clemens Cy Young year -- roids?
squareplot(c(21,7,6),col=c("blue","green","white"))
</code></pre>

<hr>
<h2 id='stud.recs'> Student records</h2><span id='topic+stud.recs'></span>

<h3>Description</h3>

<p>A simulation of student records used for placement purposes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(stud.recs)</code></pre>


<h3>Format</h3>

<p>A data frame with 160 observations on the following 6 variables.
</p>

<dl>
<dt>seq.1</dt><dd><p>Score on sequential 1 test</p>
</dd>
<dt>seq.2</dt><dd><p>Score on sequential 2 test</p>
</dd>
<dt>seq.3</dt><dd><p>Score on sequential 3 test</p>
</dd>
<dt>sat.v</dt><dd><p>SAT verbal score</p>
</dd>
<dt>sat.m</dt><dd><p>SAT math score</p>
</dd>
<dt>num.grade</dt><dd><p>grade on first math class</p>
</dd>
<dt>letter.grade</dt><dd><p>grade on first math class</p>
</dd>
</dl>



<h3>Details</h3>

<p>Some simulated student records for placement purpores
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(stud.recs)
hist(stud.recs$sat.v)
with(stud.recs,cor(sat.v,sat.m))
</code></pre>

<hr>
<h2 id='student.expenses'>Some simulated data on student expenses</h2><span id='topic+student.expenses'></span>

<h3>Description</h3>

<p>Some data for possible student expenses
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(student.expenses)</code></pre>


<h3>Format</h3>

<p>A data frame of 5 variables for 10 students. All answers are coded &quot;<code>Y</code>&quot;
for yes, &quot;<code>N</code>&quot; for no.
</p>

<dl>
<dt>cell.phone</dt><dd><p>Does student have cell phone.</p>
</dd>
<dt>cable.tv</dt><dd><p>Does student have cable TV.</p>
</dd>
<dt>dial.up</dt><dd><p>Does student pay for dial-up internet access.</p>
</dd>
<dt>cable.modem</dt><dd><p>Does student pay for high-speed or cable modem access to internet.</p>
</dd>
<dt>car</dt><dd><p>Does student own a car.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Sample dataset of students expenses.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(student.expenses)
attach(student.expenses)
table(dial.up,cable.modem)
</code></pre>

<hr>
<h2 id='superbarplot'> super segmented barplot </h2><span id='topic+superbarplot'></span>

<h3>Description</h3>

<p>Plot a barplot, with bars nested and ranging from a max to a minimum
value. A similar graphic is used on the weather page of the <em>New
York Times</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>superbarplot(x, names = 1:dim(x)[2], names_height = NULL,
  col = gray(seq(0.8, 0.5, length = dim(x)[1]/2)), ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="superbarplot_+3A_x">x</code></td>
<td>
<p>A matrix with each pair of rows representing a min and max
for the bar.</p>
</td></tr>
<tr><td><code id="superbarplot_+3A_names">names</code></td>
<td>
<p> Place a name in each bar. </p>
</td></tr>
<tr><td><code id="superbarplot_+3A_names_height">names_height</code></td>
<td>
<p> Where the names should go </p>
</td></tr>
<tr><td><code id="superbarplot_+3A_col">col</code></td>
<td>
<p> What colors to use for the bars. There should be half as
many specified as rows of <code>x</code> </p>
</td></tr>
<tr><td><code id="superbarplot_+3A_...">...</code></td>
<td>
<p>passed to <code><a href="graphics.html#topic+plot.window">plot.window</a></code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>A similar graphic on the weather page of the <em>New York Times</em>
shows bars for record highs and lows, normal highs and lows and actual
(or predicted) highs or lows for 10 days of weather. This graphic
succintly and elegantly displays a wealth of information. Intended as
an illustration of the <code><a href="graphics.html#topic+polygon">polygon</a></code> function.
</p>


<h3>Value</h3>

<p>Returns a plot, but no other values.
</p>


<h3>Author(s)</h3>

<p> John Verzani </p>


<h3>References</h3>

<p> The  weather page of the <em>New York Times</em> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+squareplot">squareplot</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>record.high=c(95,95,93,96,98,96,97,96,95,97)
record.low= c(49,47,48,51,49,48,52,51,49,52)
normal.high=c(78,78,78,79,79,79,79,80,80,80)
normal.low= c(62,62,62,63,63,63,64,64,64,64)
actual.high=c(80,78,80,68,83,83,73,75,77,81)
actual.low =c(62,65,66,58,69,63,59,58,59,60)
x=rbind(record.low,record.high,normal.low,normal.high,actual.low,actual.high)
the.names=c("S","M","T","W","T","F","S")[c(3:7,1:5)]
superbarplot(x,names=the.names)

</code></pre>

<hr>
<h2 id='tastesgreat'>Does new goo taste great?</h2><span id='topic+tastesgreat'></span>

<h3>Description</h3>

<p>Fictitious data on taste test for new <em>goo</em>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(tastesgreat)</code></pre>


<h3>Format</h3>

<p>A data frame with 40 observations on the following 3 variables.
</p>

<dl>
<dt>gender</dt><dd><p>a factor with levels <code>Female</code> <code>Male</code></p>
</dd>
<dt>age</dt><dd><p>a numeric vector</p>
</dd>
<dt>enjoyed</dt><dd><p>1 if enjoyed, 0 otherwise</p>
</dd>
</dl>



<h3>Details</h3>

<p>Fictitious data on a taste test with gender and age as covariates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tastesgreat)
summary(glm(enjoyed ~ gender + age, data=tastesgreat, family=binomial))
</code></pre>

<hr>
<h2 id='tcm1y'> One-year treasury security values</h2><span id='topic+tcm1y'></span>

<h3>Description</h3>

<p>The yields at constant fixed maturity have been constructed by the
Treasury Department, based on the most actively traded marketable
treasury securities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(tcm1y)</code></pre>


<h3>Format</h3>

<p>The format is:
Time-Series [1:558] from 1953 to 2000: 2.36 2.48 2.45 2.38 2.28 2.2 1.79 1.67 1.66 1.41 ...
</p>


<h3>Source</h3>

<p>From the tcm data set in the tseries package. Given here for
convenience only. They reference
<a href="https://www.federalreserve.gov/Releases/H15/data.htm">https://www.federalreserve.gov/Releases/H15/data.htm</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tcm1y)
ar(diff(log(tcm1y)))
</code></pre>

<hr>
<h2 id='tempsalinity'>Temperature/Salinity measurements along a moving Eddy</h2><span id='topic+tempsalinity'></span>

<h3>Description</h3>

<p>Simulated measurements of temperature and salinity in the center of
'Eddy Juggernaut', a huge anti-cyclone (clockwise rotating) Loop
Current Ring in the Gulf of Mexico. The start date is October 18, 1999.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(tempsalinity)</code></pre>


<h3>Format</h3>

<p>The data is stored as multivariate zooreg object with variables
longitude, latitude, temperature (Celsius), and salinity (psu -
practical salinity units, originally from <a href="https://toptotop.org/2014/10/21/climate_solutio/">https://toptotop.org/2014/10/21/climate_solutio/</a>).
</p>


<h3>Details</h3>

<p>The temperature salinity profile of body of water can be
characteristic. This data shows a change in the profile in time as the
eddy accumulates new water.
</p>


<h3>Source</h3>

<p>Data from simulation by Andrew Poje.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tempsalinity)
if(require(zoo)) {
  plot(tempsalinity[,3:4])
  ## overide plot.zoo method
  plot.default(tempsalinity[,3:4])
  abline(lm(salinity ~ temperature, tempsalinity, subset = 1:67))
  abline(lm(salinity ~ temperature, tempsalinity, subset = -(1:67)))
  }
</code></pre>

<hr>
<h2 id='too.young'> What age is too young for a male to data a female?</h2><span id='topic+too.young'></span>

<h3>Description</h3>

<p>In U.S. culture, an older man dating a younger woman is not uncommon,
but when the age difference becomes too great is may seem to some to
be unacceptable. This data set is a survey of 10 people with their
minimum age for an acceptable partner for a range of ages for the
male. A surprising rule of thumb (in the sense that someone took the
time to figure this out) for the minimum is half the age plus
seven. Does this rule hold for this data set?
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(too.young)</code></pre>


<h3>Format</h3>

<p>A data frame with 80 observations on the following 2 variables.
</p>

<dl>
<dt>Male</dt><dd><p>a numeric vector</p>
</dd>
<dt>Female</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(too.young)
lm(Female ~ Male, data=too.young)
</code></pre>

<hr>
<h2 id='twins'>Burt's IQ data for twins</h2><span id='topic+twins'></span>

<h3>Description</h3>

<p>IQ data of Burt on identical twins that were separated near birth.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(twins)</code></pre>


<h3>Format</h3>

<p>A data frame with 27 observations on the following 3 variables.
</p>

<dl>
<dt>Foster</dt><dd><p>IQ for twin raised with foster parents</p>
</dd>
<dt>Biological</dt><dd><p>IQ for twin raised with biological parents</p>
</dd>
<dt>Social</dt><dd><p>Social status of biological parents</p>
</dd>
</dl>



<h3>Source</h3>

<p>This data comes from the R package that accompanies Julian Faraway's
notes <em>Practical Regression and Anova in R</em> (now a book).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(twins)
plot(Foster ~ Biological, twins)
</code></pre>

<hr>
<h2 id='u2'>Song and lengths for U2 albums</h2><span id='topic+u2'></span>

<h3>Description</h3>

<p>Song titles and lengths of U2 albums from 1980 to 1997.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(u2)</code></pre>


<h3>Format</h3>

<p>The data is stored as  a list with names. Each list entry correspond
to an album stored as a vector. The values of the vector are the song
lengths in seconds and the names are the track titles.
</p>


<h3>Source</h3>

<p>Original data retrieved from http://www.u2station.com/u2ography.html
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(u2)
sapply(u2,mean)			# average track length
max(sapply(u2,max))		# longest track length
sort(unlist(u2))		# lengths in sorted order
</code></pre>

<hr>
<h2 id='urchin.growth'> Data on growth of sea urchins</h2><span id='topic+urchin.growth'></span>

<h3>Description</h3>

<p>Data on growth of sea urchins.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(urchin.growth)</code></pre>


<h3>Format</h3>

<p>A data frame with 250 observations on the following 2 variables.
</p>

<dl>
<dt>age</dt><dd><p>Estimated age of sea urchin</p>
</dd>
<dt>size</dt><dd><p>Measurement of size</p>
</dd>
</dl>



<h3>Details</h3>

<p>Data is sampled from a data set that accompanies the thesis of P. Grosjean.
</p>


<h3>Source</h3>

<p>Thesis was found at http://www.sciviews.org/_pgrosjean
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(urchin.growth)
plot(jitter(size) ~ jitter(age), data=urchin.growth)
</code></pre>

<hr>
<h2 id='vacation'>vacation days</h2><span id='topic+vacation'></span>

<h3>Description</h3>

<p>vacation days</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(vacation)</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:35] 23 12 10 34 25 16 27 18 28 13 ...
</p>


<h3>Source</h3>

<p>From Kitchens' Exploring Statistics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(vacation)
hist(vacation)
</code></pre>

<hr>
<h2 id='violinplot'> Plots violinplots instead of boxplots </h2><span id='topic+violinplot'></span><span id='topic+violinplot.default'></span><span id='topic+violinplot.formula'></span>

<h3>Description</h3>

<p>This function serves the same utility as side-by-side boxplots, only
it provides more detail about the different distribution. It
plots violinplots instead of boxplots. That is, instead of a box, it
uses the density function to plot the density. For skewed
distributions, the results look like &quot;violins&quot;. Hence the name.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>violinplot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="violinplot_+3A_x">x</code></td>
<td>
<p>Either a sequence of variable names, or a data frame, or a
model formula</p>
</td></tr>
<tr><td><code id="violinplot_+3A_...">...</code></td>
<td>
<p>You can pass arguments to polygon with this. Notably, you 
can set the color to red with col='red', and a border color with border='blue'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a plot.
</p>


<h3>Author(s)</h3>

<p> John Verzani </p>


<h3>References</h3>

<p> This is really the boxplot function from R/base with some
minor adjustments </p>


<h3>See Also</h3>

<p> boxplot, densityplot </p>


<h3>Examples</h3>

<pre><code class='language-R'>## make a "violin"
x &lt;- rnorm(100) ;x[101:150] &lt;- rnorm(50,5)
violinplot(x,col="brown")
f&lt;-factor(rep(1:5,30))
## make a quintet. Note also choice of bandwidth
violinplot(x~f,col="brown",bw="SJ")



</code></pre>

<hr>
<h2 id='watertemp'>Temperature measurement of water at 85m depth</h2><span id='topic+watertemp'></span>

<h3>Description</h3>

<p>Water temperature measurements at 10 minute intervals at a site off the East coast of the United States in the summer of 1974.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(watertemp)</code></pre>


<h3>Format</h3>

<p>A zoo class object with index stored as POSIXct elements. The measurements are in Celsius.
</p>


<h3>Source</h3>

<p>NODC Coastal Ocean Time Series Database Search Page which was at http://www.nodc.noaa.gov/dsdt/tsdb/search.html
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(require(zoo)) {
data(watertemp)	 
plot(watertemp)
acf(watertemp)
acf(diff(watertemp))
}
</code></pre>

<hr>
<h2 id='wchomes'>
A random sample of Wake County, North Carolina residential real estate plots
</h2><span id='topic+wchomes'></span>

<h3>Description</h3>

<p>This data set comes from a JSE article
<a href="http://jse.amstat.org/v20n3/woodard.pdf">http://jse.amstat.org/v20n3/woodard.pdf</a> by
Roger Woodard. The data is described by: The information for this
data set was taken from a Wake County, North Carolina real estate
database. Wake County is home to the capital of North Carolina,
Raleigh, and to Cary. These cities are the fifteenth and eighth
fastest growing cities in the USA respectively, helping Wake County
become the ninth fastest growing county in the country. Wake County
boasts a 31.18
of approximately 823,345 residents. This data includes 100 randomly
selected residential properties in the Wake County registry denoted
by their real estate ID number. For each selected property, 11
variables are recorded. These variables include year built, square
feet, adjusted land value, address, et al.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(wchomes)</code></pre>


<h3>Format</h3>

<p>a data frame</p>


<h3>Source</h3>

<p>https://www.amstat.org/publications/jse/v16n3/woodard.xls (now off-line)
</p>


<h3>References</h3>

 <p><a href="http://jse.amstat.org/v20n3/woodard.pdf">http://jse.amstat.org/v20n3/woodard.pdf</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(wchomes)
</code></pre>

<hr>
<h2 id='wellbeing'>
What makes us happy?
</h2><span id='topic+wellbeing'></span>

<h3>Description</h3>

<p>Correlated data on what makes us happy
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(wellbeing)</code></pre>


<h3>Format</h3>

<p>A data frame with data about what makes people happy (well being) along with several other covariates
</p>


<h3>Source</h3>

<p>Found from <a href="https://www.prcweb.co.uk/lab/what-makes-us-happy/">https://www.prcweb.co.uk/lab/what-makes-us-happy/</a>.
</p>


<h3>References</h3>

<p><a href="https://www.prcweb.co.uk/lab/what-makes-us-happy/">https://www.prcweb.co.uk/lab/what-makes-us-happy/</a> and https://www.nationalaccountsofwellbeing.org/
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(wellbeing)
</code></pre>

<hr>
<h2 id='yahoo.get.hist.quote'> Download stock data from Yahoo!</h2><span id='topic+yahoo.get.hist.quote'></span>

<h3>Description</h3>

<p>Downloads stock data from Yahoo!
</p>


<h3>Usage</h3>

<pre><code class='language-R'>yahoo.get.hist.quote(instrument = "^gspc", 
destfile = paste(instrument, ".csv", sep = ""), 
start, end, quote = c("Open", "High", "Low", "Close"), 
adjusted = TRUE, download = TRUE, 
origin = "1970-01-01", compression = "d")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="yahoo.get.hist.quote_+3A_instrument">instrument</code></td>
<td>
<p>Ticker symbol as character string. </p>
</td></tr>
<tr><td><code id="yahoo.get.hist.quote_+3A_destfile">destfile</code></td>
<td>
<p>Temporary file for storage </p>
</td></tr>
<tr><td><code id="yahoo.get.hist.quote_+3A_start">start</code></td>
<td>
<p>Date to start. Specified as &quot;2005-12-31&quot;</p>
</td></tr>
<tr><td><code id="yahoo.get.hist.quote_+3A_end">end</code></td>
<td>
<p> Date to end </p>
</td></tr>
<tr><td><code id="yahoo.get.hist.quote_+3A_quote">quote</code></td>
<td>
<p>Any/All of &quot;Open&quot;, &quot;High&quot;, &quot;Low&quot;, &quot;Close&quot;</p>
</td></tr>
<tr><td><code id="yahoo.get.hist.quote_+3A_adjusted">adjusted</code></td>
<td>
<p> Adjust for stock splits, dividends. Defaults to TRUE </p>
</td></tr>
<tr><td><code id="yahoo.get.hist.quote_+3A_download">download</code></td>
<td>
<p> Download the data </p>
</td></tr>
<tr><td><code id="yahoo.get.hist.quote_+3A_origin">origin</code></td>
<td>
<p>Dates are recorded in the number of days since the
origin. A value of &quot;1970-01-01&quot; is the default. This was changed from &quot;1899-12-30&quot;.</p>
</td></tr>
<tr><td><code id="yahoo.get.hist.quote_+3A_compression">compression</code></td>
<td>
<p>Passed to yahoo</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Goes to chart.yahoo.com and downloads the stock data. By default
returns a multiple time series of class mts with missing days padded
by NAs.
</p>


<h3>Value</h3>

<p>A multiple time series with time measureing the number of days since
the value specified to origin.
</p>


<h3>Author(s)</h3>

<p>Daniel Herlemont &lt;dherlemont@yats.com&gt; </p>


<h3>References</h3>

<p>This function was found on the mailling list for R-SIG finance</p>


<h3>See Also</h3>

<p>yahoo.get.hist.quote in the tseries package</p>

<hr>
<h2 id='yellowfin'>Yellow fin tuna catch rate in Tropical Indian Ocean</h2><span id='topic+yellowfin'></span>

<h3>Description</h3>

<p>Mean catch rate of yellow fin tuna in Tropical Indian Ocean for the
given years.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(yellowfin)</code></pre>


<h3>Format</h3>

<p>A data frame with 49 observations on the following 2 variables.
</p>

<dl>
<dt>year</dt><dd><p>The year</p>
</dd>
<dt>count</dt><dd><p>Mean number of fish per 100 hooks cast</p>
</dd>
</dl>



<h3>Details</h3>

<p>Estimates for the mean number of fish caught per 100 hooks are given
for a number of years. This can be used to give an estimate for the
size, or biomass, of the species during these years assuming the more
abundant the fish, the larger the mean. In practice this assumption is
viewed with a wide range of attitudes.
</p>


<h3>Source</h3>

<p>This data is read from a graph that accompanies Myers RA, Worm B
(2003) &ldquo;Rapid worldwide depletion of predatory fish
communities&rdquo;. <em>Nature</em> 423:280-283.
</p>


<h3>References</h3>

<p>See also
http://www.soest.hawaii.edu/PFRP/large_pelagic_predators.html
for rebuttals to the Myers and Worm article.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(yellowfin)
plot(yellowfin)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
