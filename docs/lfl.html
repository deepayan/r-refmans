<!DOCTYPE html><html lang="en-US"><head><title>Help for package lfl</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {lfl}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#lfl-package'><p>lfl - Linguistic Fuzzy Logic</p></a></li>
<li><a href='#aggregateConsequents'><p>Aggregation of fired consequents into a resulting fuzzy set</p></a></li>
<li><a href='#algebra'><p>Algebra for Fuzzy Sets</p></a></li>
<li><a href='#antecedents'><p>Extract antecedent-part (left-hand side) of rules in a list</p></a></li>
<li><a href='#as.data.frame.farules'><p>Convert the instance of the <code>farules()</code> S3 class into a data frame.</p>
Empty <code>farules()</code> object is converted into an empty <code>data.frame()</code>.</a></li>
<li><a href='#as.data.frame.fsets'><p>Convert an object of <code>fsets</code> class into a matrix or data frame</p>
This function converts an instance of S3 class fsets into a
matrix or a data frame. The <code>vars()</code> and <code>specs()</code> attributes
of the original object are deleted.</a></li>
<li><a href='#c.farules'><p>Take a sequence of instances of S3 class <code>farules()</code> and combine them into a single</p>
object. An error is thrown if some argument does not inherit from the <code>farules()</code>
class.</a></li>
<li><a href='#cbind.fsets'><p>Combine several 'fsets' objects into a single one</p></a></li>
<li><a href='#compose'><p>Composition of Fuzzy Relations</p></a></li>
<li><a href='#consequents'><p>Extract consequent-part (right-hand side) of rules in a list</p></a></li>
<li><a href='#ctx'><p>Context for linguistic expressions</p></a></li>
<li><a href='#defaultHedgeParams'><p>A list of the parameters that define the shape of the hedges.</p></a></li>
<li><a href='#defuzz'><p>Convert fuzzy set into a crisp numeric value</p></a></li>
<li><a href='#equidist'><p>Return equidistant breaks</p></a></li>
<li><a href='#equifreq'><p>Return equifrequent breaks</p></a></li>
<li><a href='#evalfrbe'><p>Evaluate the performance of the FRBE forecast</p></a></li>
<li><a href='#farules'><p>Create an instance of S3 class <code>farules</code> which represents a set of fuzzy</p>
association rules and their statistical characteristics.</a></li>
<li><a href='#fcut'><p>Transform data into a <code>fsets</code> S3 class using shapes derived from</p>
triangles or raised cosines</a></li>
<li><a href='#fire'><p>Evaluate rules and obtain truth-degrees</p></a></li>
<li><a href='#frbe'><p>Fuzzy Rule-Based Ensemble (FRBE) of time-series forecasts</p></a></li>
<li><a href='#fsets'><p>S3 class representing a set of fuzzy sets on the fixed universe</p></a></li>
<li><a href='#ft'><p>Fuzzy transform</p></a></li>
<li><a href='#ftinv'><p>Inverse of the fuzzy transform</p></a></li>
<li><a href='#hedge'><p>Linguistic hedges</p></a></li>
<li><a href='#horizon'><p>Create a function that computes linguistic horizons</p></a></li>
<li><a href='#is.farules'><p>Test whether <code>x</code> inherits from the S3 <code>farules</code> class.</p></a></li>
<li><a href='#is.frbe'><p>Test whether <code>x</code> is a valid object of the S3 <code>frbe</code> class</p></a></li>
<li><a href='#is.fsets'><p>Test whether <code>x</code> is a valid object of the S3 <code>fsets</code> class</p></a></li>
<li><a href='#is.ft'><p>Test whether <code>x</code> is a valid object of the S3 <code>ft</code> class</p></a></li>
<li><a href='#is.specific'><p>Determine whether the first set <code>x</code> of predicates is more specific (or equal)</p>
than <code>y</code> with respect to <code>vars</code> and <code>specs</code>.</a></li>
<li><a href='#lcut'><p>Transform data into a <code>fsets</code> S3 class of linguistic fuzzy attributes</p></a></li>
<li><a href='#lingexpr'><p>Creator of functions representing linguistic expressions</p></a></li>
<li><a href='#mase'><p>Compute Mean Absolute Scaled Error (MASE)</p></a></li>
<li><a href='#minmax'><p>Creating linguistic context directly from values</p></a></li>
<li><a href='#mult'><p>Callback-based Multiplication of Matrices</p></a></li>
<li><a href='#pbld'><p>Perform a Perception-based Logical Deduction (PbLD) with given rule-base on</p>
given dataset</a></li>
<li><a href='#perceive'><p>From a set of rules, remove each rule for which another rule exists that is</p>
more specific.</a></li>
<li><a href='#plot.fsets'><p>Plot membership degrees stored in the instance of the S3 class</p>
<code>fsets()</code> as a line diagram.</a></li>
<li><a href='#print.algebra'><p>Print an instance of the <code>algebra()</code> S3 class in a human readable form.</p></a></li>
<li><a href='#print.ctx3'><p>Print the linguistic context</p></a></li>
<li><a href='#print.farules'><p>Print an instance of the <code>farules()</code> S3 class in a human readable form.</p></a></li>
<li><a href='#print.frbe'><p>Print an instance of the <code>frbe()</code> class</p></a></li>
<li><a href='#print.fsets'><p>Print an instance of the <code>fsets()</code> class</p></a></li>
<li><a href='#quantifier'><p>A quantifier is a function that computes a fuzzy truth value of a claim about</p>
the quantity. This function creates the &lt;1&gt;-type quantifier. (See the examples
below on how to use it as a quantifier of the &lt;1,1&gt; type.)</a></li>
<li><a href='#rbcoverage'><p>Compute rule base coverage of data</p></a></li>
<li><a href='#reduce'><p>Reduce the size of rule base</p></a></li>
<li><a href='#rmse'><p>Compute Root Mean Squared Error (RMSE)</p></a></li>
<li><a href='#searchrules'><p>Searching for fuzzy association rules</p></a></li>
<li><a href='#slices'><p>Return vector of values from given interval</p></a></li>
<li><a href='#smape'><p>Compute Symmetric Mean Absolute Percentage Error (SMAPE)</p></a></li>
<li><a href='#sobocinski'><p>Modify algebra's way of computing with <code>NA</code> values.</p></a></li>
<li><a href='#sugeno'><p>A factory function for creation of sugeno-integrals.</p></a></li>
<li><a href='#triangle'><p>Deprecated functions to compute membership degrees of numeric fuzzy sets</p></a></li>
<li><a href='#triangular'><p>Factories for functions that convert numeric data into membership degrees of fuzzy sets</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Linguistic Fuzzy Logic</td>
</tr>
<tr>
<td>Version:</td>
<td>2.2.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-10-22</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Michal Burda &lt;michal.burda@osu.cz&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Various algorithms related to linguistic fuzzy logic: mining for linguistic fuzzy association
    rules, composition of fuzzy relations, performing perception-based logical deduction (PbLD), 
    and forecasting time-series using fuzzy rule-based ensemble (FRBE). The package also contains basic
    fuzzy-related algebraic functions capable of handling missing values in different styles (Bochvar,
    Sobocinski, Kleene etc.), computation of Sugeno integrals and fuzzy transform.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, doMC, knitr, rmarkdown, R.rsp</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.12.12), foreach, forecast (&ge; 5.5), plyr, tseries,
e1071, zoo, tibble</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>R.rsp</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-10-22 13:51:00 UTC; michal</td>
</tr>
<tr>
<td>Author:</td>
<td>Michal Burda <a href="https://orcid.org/0000-0002-4182-4407"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-10-22 14:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='lfl-package'>lfl - Linguistic Fuzzy Logic</h2><span id='topic+lfl'></span><span id='topic+lfl-package'></span>

<h3>Description</h3>

<p>Various algorithms related (not only) to linguistic fuzzy logic: mining for linguistic fuzzy association
rules, composition of fuzzy relations, performing perception-based logical deduction (PbLD),
and forecasting time-series using fuzzy rule-based ensemble (FRBE).
</p>


<h3>Details</h3>

<p>Other methods include fuzzy transform and computation of Sugeno integrals. Also basic algebraic
functions related to fuzzy logic are contained, which allow to handle missing values using different
styles such as Kleene, Bochvar, Sobocinski and other.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Michal Burda <a href="mailto:michal.burda@osu.cz">michal.burda@osu.cz</a> (<a href="https://orcid.org/0000-0002-4182-4407">ORCID</a>)
</p>

<hr>
<h2 id='aggregateConsequents'>Aggregation of fired consequents into a resulting fuzzy set</h2><span id='topic+aggregateConsequents'></span>

<h3>Description</h3>

<p>Take a character vector of consequent names, a numeric vector representing
the degree of consequents' firing and a matrix that models fuzzy sets
corresponding to the consequent names, and perform an aggregation of the
consequents into a resulting fuzzy set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aggregateConsequents(
  conseq,
  degrees,
  partition,
  firing = lukas.residuum,
  aggreg = pgoedel.tnorm
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="aggregateConsequents_+3A_conseq">conseq</code></td>
<td>
<p>A character vector of consequents. Each value in the vector
must correspond to a name of some column of the <code>partition</code> matrix.
The length of this vector must be the same as of the <code>degrees</code>
argument.</p>
</td></tr>
<tr><td><code id="aggregateConsequents_+3A_degrees">degrees</code></td>
<td>
<p>A numeric vector of membership degrees at which the
corresponding consequents (see the <code>conseq</code> argument) are fired.</p>
</td></tr>
<tr><td><code id="aggregateConsequents_+3A_partition">partition</code></td>
<td>
<p>A matrix of membership degrees that describes the meaning of
the consequents in vector <code>conseq</code>: each column of the matrix
corresponds to a fuzzy set that models a single consequent (of a name given
by column names of the matrix), each row corresponds to a single crisp
value (which is not important for this function), hence each cell
corresponds to a membership degree in which the crisp value is a member of
a fuzzy set modeling the consequent.  Each consequent in <code>conseq</code>
must correspond to some column of this matrix. Such matrix may be created
e.g. by using <code><a href="#topic+fcut">fcut()</a></code> or <code><a href="#topic+lcut">lcut()</a></code> functions.</p>
</td></tr>
<tr><td><code id="aggregateConsequents_+3A_firing">firing</code></td>
<td>
<p>A two-argument function used to compute the resulting truth value of the consequent.
Function is evaluated for each consequent in <code>conseq</code>, with corresponding <code>degrees</code> value
as the first argument and corresponding truth-value of the consequent (from <code>partition</code>)
as the second argument. In default, the Lukasiewicz residuum (<code><a href="#topic+lukas.residuum">lukas.residuum()</a></code>) is
evaluated that way.</p>
</td></tr>
<tr><td><code id="aggregateConsequents_+3A_aggreg">aggreg</code></td>
<td>
<p>An aggregation function to be used to combine fuzzy sets resulting from firing
the consequents with the <code>firing</code> function. The function should accept multiple
numeric vectors of membership degrees as its arguments.
In default, the Goedel t-norm (<code><a href="#topic+pgoedel.tnorm">pgoedel.tnorm()</a></code>) is evaluated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is typically used within an inference mechanism, after a set of
firing rules is determined and membership degrees of their antecedents are
computed, to combine the consequents of the firing rules into a resulting
fuzzy set. The result of this function is then typically defuzzified
(see <code><a href="#topic+defuzz">defuzz()</a></code>) to  obtain a crisp result of the inference.
</p>
<p>Function assumes a set of rules with antecedents firing at degrees given in
<code>degrees</code> and with consequents in <code>conseq</code>. The meaning of the consequents is
modeled with fuzzy sets whose membership degree values are captured in the
<code>partition</code> matrix.
</p>
<p>With default values of <code>firing</code> and <code>aggreg</code> parameters, the function
computes a fuzzy set that results from a conjunction (Goedel minimum t-norm)
of all provided implicative (Lukasiewicz residuum) rules.
</p>
<p>In detail, the function first computes the fuzzy set of each fired consequent
by calling <code style="white-space: pre;">&#8288;part\[i\] &lt;- firing(degrees\[i\], partition\[, conseq\[i\]\])&#8288;</code> for each
<code>i</code>-th consequent and the results are aggregated using the <code>aggreg</code>
parameter: <code style="white-space: pre;">&#8288;aggreg(part\[1\], part\[2\], ...)&#8288;</code>. In order to aggregate consequents
in a Mamdani-Assilian's fashion, set <code>firing</code> to <code><a href="#topic+pgoedel.tnorm">pgoedel.tnorm()</a></code> and <code>aggreg</code>
to <code><a href="#topic+pgoedel.tconorm">pgoedel.tconorm()</a></code>.
</p>


<h3>Value</h3>

<p>A vector of membership degrees of fuzzy set elements that correspond
to rows in the <code>partition</code> matrix. If empty vector of consequents is
provided, vector of 1's is returned. The length of the resulting vector
equals to the number of rows of the <code>partition</code> matrix.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fire">fire()</a></code>, <code><a href="#topic+perceive">perceive()</a></code>, <code><a href="#topic+defuzz">defuzz()</a></code>, <code><a href="#topic+fcut">fcut()</a></code>, <code><a href="#topic+lcut">lcut()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    # create a partition matrix
    partition &lt;- matrix(c(0:10/10, 10:0/10, rep(0, 5),
                          rep(0, 5), 0:10/10, 10:0/10,
                          0:12/12, 1, 12:0/12),
                        byrow=FALSE,
                        ncol=3)
    colnames(partition) &lt;- c('a', 'b', 'c')

    # the result of aggregation is equal to:
    # pmin(1, partition[, 1] + (1 - 0.5), partition[, 2] + (1 - 0.8))
    aggregateConsequents(c('a', 'b'), c(0.5, 0.8), partition)

</code></pre>

<hr>
<h2 id='algebra'>Algebra for Fuzzy Sets</h2><span id='topic+algebra'></span><span id='topic+is.algebra'></span><span id='topic+goedel.tnorm'></span><span id='topic+lukas.tnorm'></span><span id='topic+goguen.tnorm'></span><span id='topic+pgoedel.tnorm'></span><span id='topic+plukas.tnorm'></span><span id='topic+pgoguen.tnorm'></span><span id='topic+goedel.tconorm'></span><span id='topic+lukas.tconorm'></span><span id='topic+goguen.tconorm'></span><span id='topic+pgoedel.tconorm'></span><span id='topic+plukas.tconorm'></span><span id='topic+pgoguen.tconorm'></span><span id='topic+goedel.residuum'></span><span id='topic+lukas.residuum'></span><span id='topic+goguen.residuum'></span><span id='topic+goedel.biresiduum'></span><span id='topic+lukas.biresiduum'></span><span id='topic+goguen.biresiduum'></span><span id='topic+invol.neg'></span><span id='topic+strict.neg'></span>

<h3>Description</h3>

<p>Compute triangular norms (t-norms), triangular conorms (t-conorms), residua,
bi-residua, and negations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>algebra(name, stdneg = FALSE, ...)

is.algebra(a)

goedel.tnorm(...)

lukas.tnorm(...)

goguen.tnorm(...)

pgoedel.tnorm(...)

plukas.tnorm(...)

pgoguen.tnorm(...)

goedel.tconorm(...)

lukas.tconorm(...)

goguen.tconorm(...)

pgoedel.tconorm(...)

plukas.tconorm(...)

pgoguen.tconorm(...)

goedel.residuum(x, y)

lukas.residuum(x, y)

goguen.residuum(x, y)

goedel.biresiduum(x, y)

lukas.biresiduum(x, y)

goguen.biresiduum(x, y)

invol.neg(x)

strict.neg(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="algebra_+3A_name">name</code></td>
<td>
<p>The name of the algebra to be created. Must be one of: &quot;goedel&quot;,
&quot;lukasiewicz&quot;, &quot;goguen&quot; (or an unambiguous abbreviation).</p>
</td></tr>
<tr><td><code id="algebra_+3A_stdneg">stdneg</code></td>
<td>
<p>(Deprecated.) <code>TRUE</code> if to force the use of a &quot;standard&quot; negation (i.e.
involutive negation).  Otherwise, the appropriate negation is used in the
algebra (e.g. strict negation in Goedel and Goguen algebra and involutive
negation in Lukasiewicz algebra).</p>
</td></tr>
<tr><td><code id="algebra_+3A_...">...</code></td>
<td>
<p>For t-norms and t-conorms, these arguments are numeric vectors
of values to compute t-norms or t-conorms from.  Values outside the
<code class="reqn">[0,1]</code> interval cause an error. NA values are also permitted.
</p>
<p>For the <code>algebra()</code> function, these arguments are passed to the factory
functions that create the algebra. (Currently unused.)</p>
</td></tr>
<tr><td><code id="algebra_+3A_a">a</code></td>
<td>
<p>An object to be checked if it is a valid algebra (i.e. a list
returned by the <code>algebra</code> function).</p>
</td></tr>
<tr><td><code id="algebra_+3A_x">x</code></td>
<td>
<p>Numeric vector of values to compute a residuum or bi-residuum from.
Values outside the <code class="reqn">[0,1]</code> interval cause an error. NA values are also
permitted.</p>
</td></tr>
<tr><td><code id="algebra_+3A_y">y</code></td>
<td>
<p>Numeric vector of values to compute a residuum or bi-residuum from.
Values outside the <code class="reqn">[0,1]</code> interval cause an error. NA values are also
permitted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>goedel.tnorm</code>, <code>lukas.tnorm</code>, and <code>goguen.tnorm</code> compute the
Goedel, Lukasiewicz, and Goguen triangular norm (t-norm) from all values in
the arguments. If the arguments are vectors they are combined together
firstly so that a numeric vector of length 1 is returned.
</p>
<p><code>pgoedel.tnorm</code>, <code>plukas.tnorm</code>, and <code>pgoguen.tnorm</code> compute
the same t-norms, but in an element-wise manner. I.e. the values
with indices 1 of all arguments are used to compute the t-norm, then the
second values (while recycling the vectors if they do not have the same
size) so that the result is a vector of values.
</p>
<p><code>goedel.tconorm</code>, <code>lukas.tconorm</code>, <code>goguen.tconorm</code>, are
similar to the previously mentioned functions, except that they compute
triangular conorms (t-conorms).  <code>pgoedel.tconorm</code>,
<code>plukas.tconorm</code>, and <code>pgoguen.tconorm</code> are their element-wise alternatives.
</p>
<p><code>goedel.residuum</code>, <code>lukas.residuum</code>, and <code>goguen.residuum</code>
compute residua (i.e. implications) and <code>goedel.biresiduum</code>,
<code>lukas.biresiduum</code>, and <code>goguen.biresiduum</code> compute bi-residua. Residua and
bi-residua are computed in an element-wise manner, for each corresponding
pair of values in <code>x</code> and <code>y</code> arguments.
</p>
<p><code>invol.neg</code> and <code>strict.neg</code> compute the involutive and strict
negation, respectively.
</p>
<p>Let <code class="reqn">a</code>, <code class="reqn">b</code> be values from the interval <code class="reqn">[0, 1]</code>. The realized functions
can be defined as follows:
</p>

<ul>
<li><p> Goedel t-norm: <code class="reqn">min{a, b}</code>;
</p>
</li>
<li><p> Goguen t-norm: <code class="reqn">ab</code>;
</p>
</li>
<li><p> Lukasiewicz t-norm: <code class="reqn">max{0, a+b-1}</code>;
</p>
</li>
<li><p> Goedel t-conorm: <code class="reqn">max{a, b}</code>;
</p>
</li>
<li><p> Goguen t-conorm: <code class="reqn">a+b-ab</code>;
</p>
</li>
<li><p> Lukasiewicz t-conorm: <code class="reqn">min{1, a+b}</code>;
</p>
</li>
<li><p> Goedel residuum (standard Goedel implication): <code class="reqn">1</code> if <code class="reqn">a \le b</code> and
<code class="reqn">b</code> otherwise;
</p>
</li>
<li><p> Goguen residuum (implication): <code class="reqn">1</code> if <code class="reqn">a \le b</code> and <code class="reqn">b/a</code>
otherwise;
</p>
</li>
<li><p> Lukasiewicz residuum (standard Lukasiewicz implication): <code class="reqn">1</code> if
<code class="reqn">a \le b</code> and <code class="reqn">1-a+b</code> otherwise;
</p>
</li>
<li><p> Involutive negation: <code class="reqn">1-x</code>;
</p>
</li>
<li><p> Strict negation: <code class="reqn">1</code> if <code class="reqn">x=0</code> and <code class="reqn">0</code> otherwise.
</p>
</li></ul>

<p>Bi-residuum <code class="reqn">B</code> is derived from residuum <code class="reqn">R</code>
as follows: </p>
<p style="text-align: center;"><code class="reqn">B(a, b) = inf(R(a, b), R(b, a)),</code>
</p>

<p>where <code class="reqn">inf</code> is the operation of infimum, which for all three algebras
corresponds to the <code class="reqn">min</code> operation.
</p>
<p>The arguments have to be numbers from the interval <code class="reqn">[0, 1]</code>. Values
outside that range cause an error. NaN values are treated as NAs.
</p>
<p>If some argument is NA or NaN, the result is NA. For other handling of missing values,
see <a href="#topic+algebraNA">algebraNA</a>.
</p>
<p>Selection of a t-norm may serve as a basis for definition of other operations.
From the t-norm, the operation of a residual implication may be defined, which
in turn allows the definition of a residual negation. If the residual negation
is not involutive, the involutive negation is often added as a new operation
and together with the t-norm can be used to define the t-conorm. Therefore,
the <code>algebra</code> function returns a named list of operations derived from the selected
Goedel, Goguen, or Lukasiewicz t-norm. Concretely:
</p>

<ul>
<li> <p><code>algebra("goedel")</code>: returns the strict negation as the residual negation,
the involutive negation, and also the Goedel t-norm, t-conorm, residuum, and bi-residuum;
</p>
</li>
<li> <p><code>algebra("goguen")</code>: returns the strict negation as the residual negation,
the involutive negation, and also the Goguen t-norm, t-conorm, residuum, and bi-residuum;
</p>
</li>
<li> <p><code>algebra("lukasiewicz")</code>: returns involutive negation as both residual and involutive
negation, and also the Lukasiewicz t-norm, t-conorm, residuum, and bi-residuum.
</p>
</li></ul>

<p>Moreover, <code>algebra</code> returns the supremum and infimum functions computed as maximum and minimum,
respectively.
</p>
<p><code>is.algebra</code> tests whether the given <code>a</code> argument is a valid
algebra, i.e. a list returned by the <code>algebra</code> function.
</p>


<h3>Value</h3>

<p>Functions for t-norms and t-conorms (such as <code>goedel.tnorm</code>)
return a numeric vector of size 1 that is the result of the appropriate
t-norm or t-conorm applied on all values of all arguments.
</p>
<p>Element-wise versions of t-norms and t-conorms (such as <code>pgoedel.tnorm</code>)
return a vector of results after applying the appropriate t-norm or t-conorm
on argument in an element-wise (i.e. by indices) way. The
resulting vector is of length of the longest argument (shorter arguments are
recycled).
</p>
<p>Residua and bi-residua functions return a numeric vector of length of the
longest argument (shorter argument is recycled).
</p>
<p><code>strict.neg</code> and <code>invol.neg</code> compute negations and return a
numeric vector of the same size as the argument <code>x</code>.
</p>
<p><code>algebra</code> returns a list of functions of the requested algebra:
<code>"n"</code> (residual negation), <code>"ni"</code> (involutive negation), <code>"t"</code> (t-norm),
<code>"pt"</code> (element-wise t-norm),
<code>"c"</code> (t-conorm), <code>"pc"</code> (element-wise t-conorm), <code>"r"</code> (residuum),
<code>"b"</code> (bi-residuum), <code>"s"</code> (supremum),
<code>"ps"</code> (element-wise supremum), <code>"i"</code> (infimum), and
<code>"pi"</code> (element-wise infimum).
</p>
<p>For Lukasiewicz algebra, the elements <code>"n"</code> and <code>"ni"</code> are the same, i.e.
the <code>invol.neg</code> function. For Goedel and Goguen algebra, <code>"n"</code> (the residual
negation) equals <code>strict.neg</code> and <code>"ni"</code> (the involutive negation) equals
<code>invol.neg</code>.
</p>
<p><code>"s"</code>, <code>"ps"</code>, <code>"i"</code>, <code>"pi"</code> are the same for each type of algebra:
<code>goedel.conorm</code>, <code>pgoedel.conorm</code>, <code>goedel.tnorm</code>, and <code>pgoedel.tnorm</code>.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    # direct and element-wise version of functions
    goedel.tnorm(c(0.3, 0.2, 0.5), c(0.8, 0.1, 0.5))  # 0.1
    pgoedel.tnorm(c(0.3, 0.2, 0.5), c(0.8, 0.1, 0.5)) # c(0.3, 0.1, 0.5)

    # algebras
    x &lt;- runif(10)
    y &lt;- runif(10)
    a &lt;- algebra('goedel')
    a$n(x)     # residual negation
    a$ni(x)    # involutive negation
    a$t(x, y)  # t-norm
    a$pt(x, y) # element-wise t-norm
    a$c(x, y)  # t-conorm
    a$pc(x, y) # element-wise t-conorm
    a$r(x, y)  # residuum
    a$b(x, y)  # bi-residuum
    a$s(x, y)  # supremum
    a$ps(x, y) # element-wise supremum
    a$i(x, y)  # infimum
    a$pi(x, y) # element-wise infimum

    is.algebra(a) # TRUE
</code></pre>

<hr>
<h2 id='antecedents'>Extract antecedent-part (left-hand side) of rules in a list</h2><span id='topic+antecedents'></span>

<h3>Description</h3>

<p>Given a list of rules or an instance of the S3 <code><a href="#topic+farules">farules()</a></code> class,
the function returns a list of their antecedents (i.e.
left-hand side of rules).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>antecedents(rules)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="antecedents_+3A_rules">rules</code></td>
<td>
<p>Either a list of character vectors or an object of class <code><a href="#topic+farules">farules()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function assumes <code>rules</code> to be a valid <code><a href="#topic+farules">farules()</a></code> object or
a list of character vectors where
the first element of each vector is a consequent part and the
rest is an antecedent part of rules. Function returns a list of
antecedents.
</p>


<h3>Value</h3>

<p>A list of character vectors.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+consequents">consequents()</a></code>, <code><a href="#topic+farules">farules()</a></code>, <code><a href="#topic+searchrules">searchrules()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    rules &lt;- list(c('a', 'b', 'c'), c('d'), c('a', 'e'))
    antecedents(rules)
</code></pre>

<hr>
<h2 id='as.data.frame.farules'>Convert the instance of the <code><a href="#topic+farules">farules()</a></code> S3 class into a data frame.
Empty <code><a href="#topic+farules">farules()</a></code> object is converted into an empty <code><a href="base.html#topic+data.frame">data.frame()</a></code>.</h2><span id='topic+as.data.frame.farules'></span>

<h3>Description</h3>

<p>Convert the instance of the <code><a href="#topic+farules">farules()</a></code> S3 class into a data frame.
Empty <code><a href="#topic+farules">farules()</a></code> object is converted into an empty <code><a href="base.html#topic+data.frame">data.frame()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'farules'
as.data.frame(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as.data.frame.farules_+3A_x">x</code></td>
<td>
<p>An instance of class <code><a href="#topic+farules">farules()</a></code> to be transformed.</p>
</td></tr>
<tr><td><code id="as.data.frame.farules_+3A_...">...</code></td>
<td>
<p>Unused.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame of statistics of the rules that are stored in the given
<code><a href="#topic+farules">farules()</a></code> object. Row names of the resulting data frame are in
the form: <code style="white-space: pre;">&#8288;A1 &amp; A2 &amp; ... &amp; An =&gt; C&#8288;</code>, where <code>Ai</code> are antecedent
predicates and <code>C</code> is a consequent. An empty <code><a href="#topic+farules">farules()</a></code> object
is converted into an empty <code><a href="base.html#topic+data.frame">data.frame()</a></code> object.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+farules">farules()</a></code>, <code><a href="#topic+searchrules">searchrules()</a></code>
</p>

<hr>
<h2 id='as.data.frame.fsets'>Convert an object of <code>fsets</code> class into a matrix or data frame
This function converts an instance of S3 class <a href="#topic+fsets">fsets</a> into a
matrix or a data frame. The <code><a href="#topic+vars">vars()</a></code> and <code><a href="#topic+specs">specs()</a></code> attributes
of the original object are deleted.</h2><span id='topic+as.data.frame.fsets'></span><span id='topic+as.matrix.fsets'></span>

<h3>Description</h3>

<p>Convert an object of <code>fsets</code> class into a matrix or data frame
This function converts an instance of S3 class <a href="#topic+fsets">fsets</a> into a
matrix or a data frame. The <code><a href="#topic+vars">vars()</a></code> and <code><a href="#topic+specs">specs()</a></code> attributes
of the original object are deleted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fsets'
as.data.frame(x, ...)

## S3 method for class 'fsets'
as.matrix(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as.data.frame.fsets_+3A_x">x</code></td>
<td>
<p>An instance of class <a href="#topic+fsets">fsets</a> to be converted</p>
</td></tr>
<tr><td><code id="as.data.frame.fsets_+3A_...">...</code></td>
<td>
<p>arguments further passed to <code>as.data.frame</code> after converting
to matrix in <code>as.data.frame.fsets</code>. Unused in <code>as.matrix.fsets</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric matrix or data frame of membership degrees.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fsets">fsets()</a></code>, <code><a href="#topic+fcut">fcut()</a></code>, <code><a href="#topic+lcut">lcut()</a></code>
</p>

<hr>
<h2 id='c.farules'>Take a sequence of instances of S3 class <code><a href="#topic+farules">farules()</a></code> and combine them into a single
object. An error is thrown if some argument does not inherit from the <code><a href="#topic+farules">farules()</a></code>
class.</h2><span id='topic+c.farules'></span>

<h3>Description</h3>

<p>Take a sequence of instances of S3 class <code><a href="#topic+farules">farules()</a></code> and combine them into a single
object. An error is thrown if some argument does not inherit from the <code><a href="#topic+farules">farules()</a></code>
class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'farules'
c(..., recursive = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="c.farules_+3A_...">...</code></td>
<td>
<p>A sequence of objects of class <code><a href="#topic+farules">farules()</a></code> to be concatenated.</p>
</td></tr>
<tr><td><code id="c.farules_+3A_recursive">recursive</code></td>
<td>
<p>This argument has currently no function and is added here
only for compatibility with generic <code><a href="base.html#topic+c">c</a></code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+farules">farules()</a></code> that is created by merging the
arguments together, i.e.  by concatenating the rules and row-binding the
statistics of given objects.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+farules">farules()</a></code>, <code><a href="#topic+searchrules">searchrules()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    ori1 &lt;- farules(rules=list(letters[1:3],
                               letters[2:5]),
                    statistics=matrix(runif(16), nrow=2))
    ori2 &lt;- farules(rules=list(letters[4],
                               letters[3:8]),
                    statistics=matrix(runif(16), nrow=2))
    res &lt;- c(ori1, ori2)
    print(res)
</code></pre>

<hr>
<h2 id='cbind.fsets'>Combine several 'fsets' objects into a single one</h2><span id='topic+cbind.fsets'></span>

<h3>Description</h3>

<p>Take a sequence of objects of class 'fsets' and combine them by columns.
This version of cbind takes care of the <code><a href="#topic+vars">vars()</a></code> and <code><a href="#topic+specs">specs()</a></code>
attributes of the arguments and merges them to the result. If some argument
does not inherit from the 'fsets' class, an error is thrown.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fsets'
cbind(..., deparse.level = 1, warn = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cbind.fsets_+3A_...">...</code></td>
<td>
<p>A sequence of objects of class 'fsets' to be merged by columns.</p>
</td></tr>
<tr><td><code id="cbind.fsets_+3A_deparse.level">deparse.level</code></td>
<td>
<p>This argument has currently no function and is added
here only for compatibility with generic <code><a href="base.html#topic+cbind">cbind()</a></code> function.</p>
</td></tr>
<tr><td><code id="cbind.fsets_+3A_warn">warn</code></td>
<td>
<p>Whether to issue warning when combining two fsets having the same vars
about the fact that specs may not be accurate</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code><a href="#topic+vars">vars()</a></code> attribute is merged by concatenating the <code><a href="#topic+vars">vars()</a></code> attributes
of each argument. Also the <code><a href="#topic+specs">specs()</a></code> attributes of the arguments are merged together.
</p>


<h3>Value</h3>

<p>An object of class 'fsets' that is created by merging the arguments
by columns.  Also the arguments' attributes <code><a href="#topic+vars">vars()</a></code> and <code><a href="#topic+specs">specs()</a></code> are merged together.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vars">vars()</a></code>, <code><a href="#topic+specs">specs()</a></code>, <code><a href="#topic+fcut">fcut()</a></code>, <code><a href="#topic+lcut">lcut()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    d1 &lt;- fcut(CO2[, 1:2])
    d2 &lt;- fcut(CO2[, 3:4], breaks=list(conc=1:4*1000/4))
    r &lt;- cbind(d1, d2)

    print(colnames(d1))
    print(colnames(d2))
    print(colnames(r))

    print(vars(d1))
    print(vars(d2))
    print(vars(r))

    print(specs(d1))
    print(specs(d2))
    print(specs(r))

</code></pre>

<hr>
<h2 id='compose'>Composition of Fuzzy Relations</h2><span id='topic+compose'></span>

<h3>Description</h3>

<p>Composition of Fuzzy Relations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compose(
  x,
  y,
  e = NULL,
  alg = c("goedel", "goguen", "lukasiewicz"),
  type = c("basic", "sub", "super", "square"),
  quantifier = NULL,
  sorting = sort
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compose_+3A_x">x</code></td>
<td>
<p>A first fuzzy relation to be composed. It must be a numeric matrix
with values within the <code class="reqn">[0,1]</code> interval. The number of columns must
match with the number of rows of the <code>y</code> matrix.</p>
</td></tr>
<tr><td><code id="compose_+3A_y">y</code></td>
<td>
<p>A second fuzzy relation to be composed. It must be a numeric matrix
with values within the <code class="reqn">[0,1]</code> interval. The number of columns must
match with the number of rows of the <code>x</code> matrix.</p>
</td></tr>
<tr><td><code id="compose_+3A_e">e</code></td>
<td>
<p>Deprecated. An excluding fuzzy relation. If not NULL,
it must be a numeric matrix with dimensions equal to the <code>y</code> matrix.</p>
</td></tr>
<tr><td><code id="compose_+3A_alg">alg</code></td>
<td>
<p>An algebra to be used for composition. It must be one of
<code>'goedel'</code> (default), <code>'goguen'</code>, or <code>'lukasiewicz'</code>, or an instance of class <code>algebra</code>
(see <code><a href="#topic+algebra">algebra()</a></code>).</p>
</td></tr>
<tr><td><code id="compose_+3A_type">type</code></td>
<td>
<p>A type of a composition to be performed. It must be one of
<code>'basic'</code> (default), <code>'sub'</code>, <code>'super'</code>, or <code>'square'</code>.</p>
</td></tr>
<tr><td><code id="compose_+3A_quantifier">quantifier</code></td>
<td>
<p>Deprecated. If not NULL, it must be a function taking a single
argument, a vector of relative cardinalities, that would be translated into
membership degrees. A result of the <code><a href="#topic+lingexpr">lingexpr()</a></code> function is a
good candidate for that. Note that the vector of relative cardinalities contains also
two attributes, <code>x</code> and <code>y</code>, which carry the original <code>R</code>'s data row (in <code>x</code>) and <code>S</code>'s
feature column (in <code>y</code>). These attributes are accessible using the standard <code><a href="base.html#topic+attr">base::attr()</a></code>
function. Find examples below that define some quantifiers.</p>
</td></tr>
<tr><td><code id="compose_+3A_sorting">sorting</code></td>
<td>
<p>Deprecated. Sorting function used within quantifier application. The given function
must sort the membership degrees and allow the <code>decreasing</code> argument as in <code><a href="base.html#topic+sort">base::sort()</a></code>.
This function have to be explicitly specified typically if performing compositions that
handle <code>NA</code> values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function composes a fuzzy relation <code>x</code> (i.e. a numeric matrix of size
<code class="reqn">(u,v)</code>) with a fuzzy relation <code>y</code> (i.e. a numeric matrix of size
<code class="reqn">(v,w)</code>) and possibly with the deprecated use of an exclusion fuzzy relation
<code>e</code> (i.e. a numeric matrix of size <code class="reqn">(v,w)</code>).
</p>
<p>The style of composition is determined by the algebra <code>alg</code>, the
composition type <code>type</code>, and possibly also by a deprecated <code>quantifier</code>.
</p>
<p>This function performs four main composition types, the basic composition (
also known as direct product), the Bandler-Kohout subproduct (also subdirect
product), the Bandler-Kohout superproduct (also supdirect product), and finally,
the Bandler-Kohout square product. More complicated composition operations
may be performed by using the <code><a href="#topic+mult">mult()</a></code> function and/or by combining multiple
composition results with the <code><a href="#topic+algebra">algebra()</a></code> operations.
</p>


<h3>Value</h3>

<p>A matrix with <code class="reqn">v</code> rows and <code class="reqn">w</code> columns, where <code class="reqn">v</code> is the
number of rows of <code>x</code> and <code class="reqn">w</code> is the number of columns of <code>y</code>.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p>[algebra(), <code><a href="#topic+mult">mult()</a></code>, <code><a href="#topic+lingexpr">lingexpr()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    R &lt;- matrix(c(0.1, 0.6, 1, 0, 0, 0,
                  0, 0.3, 0.7, 0.9, 1, 1,
                  0, 0, 0.6, 0.8, 1, 0,
                  0, 1, 0.5, 0, 0, 0,
                  0, 0, 1, 1, 0, 0), byrow=TRUE, nrow=5)

    S &lt;- matrix(c(0.9, 1, 0.9, 1,
                  1, 1, 1, 1,
                  0.1, 0.2, 0, 0.2,
                  0, 0, 0, 0,
                  0.7, 0.6, 0.5, 0.4,
                  1, 0.9, 0.7, 0.6), byrow=TRUE, nrow=6)

    RS &lt;- matrix(c(0.6, 0.6, 0.6, 0.6,
                   1, 0.9, 0.7, 0.6,
                   0.7, 0.6, 0.5, 0.4,
                   1, 1, 1, 1,
                   0.1, 0.2, 0, 0.2), byrow=TRUE, nrow=5)

    compose(R, S, alg='goedel', type='basic') # should be equal to RS
</code></pre>

<hr>
<h2 id='consequents'>Extract consequent-part (right-hand side) of rules in a list</h2><span id='topic+consequents'></span>

<h3>Description</h3>

<p>Given a list of rules or an instance of the S3 <code><a href="#topic+farules">farules()</a></code> class,
the function returns a list of their consequents (i.e.
right-hand side of rules).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>consequents(rules)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="consequents_+3A_rules">rules</code></td>
<td>
<p>Either a list of character vectors or an object of class <code><a href="#topic+farules">farules()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function assumes <code>rules</code> to be a valid <code><a href="#topic+farules">farules()</a></code> object or
a list of character vectors where
the first element of each vector is a consequent part and the
rest is an antecedent part of rules. Function returns a list of
consequents.
</p>


<h3>Value</h3>

<p>A list of character vectors.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+antecedents">antecedents()</a></code>, <code><a href="#topic+farules">farules()</a></code>, <code><a href="#topic+searchrules">searchrules()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    rules &lt;- list(c('a', 'b', 'c'), c('d'), c('a', 'e'))
    consequents(rules)
    unlist(consequents(rules))   # as vector
</code></pre>

<hr>
<h2 id='ctx'>Context for linguistic expressions</h2><span id='topic+ctx'></span><span id='topic+ctx3'></span><span id='topic+ctx3bilat'></span><span id='topic+ctx5'></span><span id='topic+ctx5bilat'></span><span id='topic+as.ctx3'></span><span id='topic+as.ctx3.ctx3'></span><span id='topic+as.ctx3.ctx3bilat'></span><span id='topic+as.ctx3.ctx5'></span><span id='topic+as.ctx3.ctx5bilat'></span><span id='topic+as.ctx3.default'></span><span id='topic+as.ctx3bilat'></span><span id='topic+as.ctx3bilat.ctx3bilat'></span><span id='topic+as.ctx3bilat.ctx3'></span><span id='topic+as.ctx3bilat.ctx5'></span><span id='topic+as.ctx3bilat.ctx5bilat'></span><span id='topic+as.ctx3bilat.default'></span><span id='topic+as.ctx5'></span><span id='topic+as.ctx5.ctx5'></span><span id='topic+as.ctx5.ctx3'></span><span id='topic+as.ctx5.ctx3bilat'></span><span id='topic+as.ctx5.ctx5bilat'></span><span id='topic+as.ctx5.default'></span><span id='topic+as.ctx5bilat'></span><span id='topic+as.ctx5bilat.ctx5bilat'></span><span id='topic+as.ctx5bilat.ctx3'></span><span id='topic+as.ctx5bilat.ctx3bilat'></span><span id='topic+as.ctx5bilat.ctx5'></span><span id='topic+as.ctx5bilat.default'></span><span id='topic+is.ctx3'></span><span id='topic+is.ctx3bilat'></span><span id='topic+is.ctx5'></span><span id='topic+is.ctx5bilat'></span>

<h3>Description</h3>

<p>A context describes a range of allowed values for a data column.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ctx3(
  low = 0,
  center = low + (high - low) * relCenter,
  high = 1,
  relCenter = 0.5
)

ctx3bilat(
  negMax = -1,
  negCenter = origin + (negMax - origin) * relCenter,
  origin = 0,
  center = origin + (max - origin) * relCenter,
  max = 1,
  relCenter = 0.5
)

ctx5(
  low = 0,
  lowerCenter = mean(c(low, center)),
  center = low + (high - low) * relCenter,
  upperCenter = mean(c(center, high)),
  high = 1,
  relCenter = 0.5
)

ctx5bilat(
  negMax = -1,
  negUpperCenter = mean(c(negCenter, negMax)),
  negCenter = origin + (negMax - origin) * relCenter,
  negLowerCenter = mean(c(origin, negCenter)),
  origin = 0,
  lowerCenter = mean(c(origin, center)),
  center = origin + (max - origin) * relCenter,
  upperCenter = mean(c(center, max)),
  max = 1,
  relCenter = 0.5
)

as.ctx3(x)

## S3 method for class 'ctx3'
as.ctx3(x)

## S3 method for class 'ctx3bilat'
as.ctx3(x)

## S3 method for class 'ctx5'
as.ctx3(x)

## S3 method for class 'ctx5bilat'
as.ctx3(x)

## Default S3 method:
as.ctx3(x)

as.ctx3bilat(x)

## S3 method for class 'ctx3bilat'
as.ctx3bilat(x)

## S3 method for class 'ctx3'
as.ctx3bilat(x)

## S3 method for class 'ctx5'
as.ctx3bilat(x)

## S3 method for class 'ctx5bilat'
as.ctx3bilat(x)

## Default S3 method:
as.ctx3bilat(x)

as.ctx5(x)

## S3 method for class 'ctx5'
as.ctx5(x)

## S3 method for class 'ctx3'
as.ctx5(x)

## S3 method for class 'ctx3bilat'
as.ctx5(x)

## S3 method for class 'ctx5bilat'
as.ctx5(x)

## Default S3 method:
as.ctx5(x)

as.ctx5bilat(x)

## S3 method for class 'ctx5bilat'
as.ctx5bilat(x)

## S3 method for class 'ctx3'
as.ctx5bilat(x)

## S3 method for class 'ctx3bilat'
as.ctx5bilat(x)

## S3 method for class 'ctx5'
as.ctx5bilat(x)

## Default S3 method:
as.ctx5bilat(x)

is.ctx3(x)

is.ctx3bilat(x)

is.ctx5(x)

is.ctx5bilat(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ctx_+3A_low">low</code></td>
<td>
<p>Lowest value of an unilateral context.</p>
</td></tr>
<tr><td><code id="ctx_+3A_center">center</code></td>
<td>
<p>A positive middle value of a bilateral context, or simply a
middle value of an unilateral context.</p>
</td></tr>
<tr><td><code id="ctx_+3A_high">high</code></td>
<td>
<p>Highest value of an unilateral context.</p>
</td></tr>
<tr><td><code id="ctx_+3A_relcenter">relCenter</code></td>
<td>
<p>A relative quantity used to compute the <code>negCenter</code>
and/or <code>center</code>, if they are not specified explicitly. The sensible
value is 0.5 for context symmetric around center, or 0.42 as proposed by
Novak.</p>
</td></tr>
<tr><td><code id="ctx_+3A_negmax">negMax</code></td>
<td>
<p>Lowest negative value of a bilateral context.</p>
</td></tr>
<tr><td><code id="ctx_+3A_negcenter">negCenter</code></td>
<td>
<p>A negative middle value.</p>
</td></tr>
<tr><td><code id="ctx_+3A_origin">origin</code></td>
<td>
<p>Origin, i.e. the initial point of the bilateral context. It is
typically a value of zero.</p>
</td></tr>
<tr><td><code id="ctx_+3A_max">max</code></td>
<td>
<p>Highest value of a bilateral context.</p>
</td></tr>
<tr><td><code id="ctx_+3A_lowercenter">lowerCenter</code></td>
<td>
<p>A typical positive value between origin and center.</p>
</td></tr>
<tr><td><code id="ctx_+3A_uppercenter">upperCenter</code></td>
<td>
<p>A typical positive value between center and maximum.</p>
</td></tr>
<tr><td><code id="ctx_+3A_neguppercenter">negUpperCenter</code></td>
<td>
<p>A typical negative value between <code>negMax</code> and
<code>negCenter</code>.</p>
</td></tr>
<tr><td><code id="ctx_+3A_neglowercenter">negLowerCenter</code></td>
<td>
<p>A typical negative value between <code>negCenter</code> and
<code>negOrigin</code>.</p>
</td></tr>
<tr><td><code id="ctx_+3A_x">x</code></td>
<td>
<p>A value to be examined or converted. For <code style="white-space: pre;">&#8288;as.ctx*&#8288;</code>, it can be
an instance of any <code style="white-space: pre;">&#8288;ctx*&#8288;</code> class or a numeric vector of size equal to
the number of points required for the given context type.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A context describes a range of allowed values for a data column. For that,
only the borders of the interval, i.e. minimum and maximum, are usually
needed, but we use contexts to hold more additional information that is
crucial for the construction of linguistic expressions.
</p>
<p>Currently, four different contexts are supported that determine the types of
possible linguistic expressions, as constructed with <code><a href="#topic+lingexpr">lingexpr()</a></code>.
Unilateral or bilateral context is allowed in the variants of trichotomy or
pentachotomy. Trichotomy distinguishes three points in the interval: the
lowest value, highest value, and center. Pentachotomy adds lower center and
upper center to them. As opposite to unilateral, the bilateral context
handles explicitly the negative values. That is, bilateral context expects
some middle point, the origin (usually 0), around which the positive and
negative values are placed.
</p>
<p>Concretely, the type of the context determines the allowed atomic
expressions as follows:
</p>

<ul>
<li> <p><code>ctx3</code>: trichotomy (low, center, high) enables atomic expressions:
small, medium, big;
</p>
</li>
<li> <p><code>ctx5</code>: pentachotomy (low, lowerCenter, center, upperCenter, high) enables
atomic expressions: small, lower medium, medium, upper medium, big;
</p>
</li>
<li> <p><code>ctx3bilat</code>: bilateral trichotomy (negMax, negCenter, origin, center, max)
enables atomic expressions: negative big, negative medium, negative small,
zero, small, medium, big;
</p>
</li>
<li> <p><code>ctx5bilat</code>: bilateral pentachotomy (negMax, negCenter, origin, center,
max) enables atomic expressions: negative big, negative medium, negative
small, zero, small, medium, big.
</p>
</li></ul>

<p>The <code style="white-space: pre;">&#8288;as.ctx*&#8288;</code> functions return instance of the appropriate class. The
functions perform the conversion so that missing points of the new context
are computed from the old context that is being transformed. In the
subsequent table, rows represent compatible values of different context
types:
</p>

<table>
<tr>
 <td style="text-align: left;">
ctx3   </td><td style="text-align: left;"> ctx5        </td><td style="text-align: left;"> ctx3bilat </td><td style="text-align: left;"> ctx5bilat      </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;">             </td><td style="text-align: left;"> negMax    </td><td style="text-align: left;"> negMax         </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;">             </td><td style="text-align: left;">           </td><td style="text-align: left;"> negUpperCenter </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;">             </td><td style="text-align: left;"> negCenter </td><td style="text-align: left;"> negCenter      </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;">             </td><td style="text-align: left;">           </td><td style="text-align: left;"> negLowerCenter </td>
</tr>
<tr>
 <td style="text-align: left;">
low    </td><td style="text-align: left;"> low         </td><td style="text-align: left;"> origin    </td><td style="text-align: left;"> origin         </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> lowerCenter </td><td style="text-align: left;">           </td><td style="text-align: left;"> lowerCenter    </td>
</tr>
<tr>
 <td style="text-align: left;">
center </td><td style="text-align: left;"> center      </td><td style="text-align: left;"> center    </td><td style="text-align: left;"> center </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> upperCenter </td><td style="text-align: left;">           </td><td style="text-align: left;"> upperCenter </td>
</tr>
<tr>
 <td style="text-align: left;">
high   </td><td style="text-align: left;"> high        </td><td style="text-align: left;"> max       </td><td style="text-align: left;"> max
</td>
</tr>

</table>

<p>The <code style="white-space: pre;">&#8288;as.ctx*&#8288;</code> conversion is performed by replacing values by rows, as
indicated in the table above.  When converting from a context with less
points to a context with more points (e.g. from unilateral to bilateral, or
from trichotomy to pentachotomy), missing points are computed as follows:
</p>

<ul>
<li> <p><code>center</code> is computed as a mean of <code>origin</code> (or <code>low</code>) and <code>max</code> (or <code>high</code>).
</p>
</li>
<li> <p><code>lowerCenter</code> is computed as a mean of <code>origin</code> (or <code>low</code>) and <code>center</code>.
</p>
</li>
<li> <p><code>upperCenter</code> is computed as a mean of <code>mas</code> (or <code>high</code>) and <code>center</code>.
</p>
</li>
<li><p> negative points (such as <code>negMax</code>, <code>negCenter</code> etc.) are computed
symmetrically around <code>origin</code> to the corresponding positive points.
</p>
</li></ul>

<p>The code <code style="white-space: pre;">&#8288;as.ctx*&#8288;</code> functions allow the parameter to be also a numeric
vector of size equal to the number of points required for the given context
type, i.e. 3 (<code>ctx3</code>), 5 (<code>ctx3bilat</code>, <code>ctx5</code>), or 9 (<code>ctx5bilat</code>).
</p>


<h3>Value</h3>

<p><code style="white-space: pre;">&#8288;ctx*&#8288;</code> and <code style="white-space: pre;">&#8288;as.ctx*&#8288;</code> return an instance of the appropriate
class. <code style="white-space: pre;">&#8288;is.ctx*&#8288;</code> returns <code>TRUE</code> or <code>FALSE</code>.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+minmax">minmax()</a></code>, <code><a href="#topic+lingexpr">lingexpr()</a></code>, <code><a href="#topic+horizon">horizon()</a></code>, <code><a href="#topic+hedge">hedge()</a></code>, <code><a href="#topic+fcut">fcut()</a></code>, <code><a href="#topic+lcut">lcut()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    ctx3(low=0, high=10)
    as.ctx3bilat(ctx3(low=0, high=10))
</code></pre>

<hr>
<h2 id='defaultHedgeParams'>A list of the parameters that define the shape of the hedges.</h2><span id='topic+defaultHedgeParams'></span>

<h3>Description</h3>

<p>A list of the parameters that define the shape of the hedges.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>defaultHedgeParams
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 9.
</p>

<hr>
<h2 id='defuzz'>Convert fuzzy set into a crisp numeric value</h2><span id='topic+defuzz'></span>

<h3>Description</h3>

<p>Take a discretized fuzzy set (i.e. a vector of membership degrees and a vector
of numeric values that correspond to that degrees) and perform a selected
type of defuzzification, i.e. conversion of the fuzzy set into a single
crisp value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>defuzz(
  degrees,
  values,
  type = c("mom", "fom", "lom", "dee", "cog", "expun", "expw1", "expw2")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="defuzz_+3A_degrees">degrees</code></td>
<td>
<p>A fuzzy set in the form of a numeric vector of membership
degrees of values provided as the <code>values</code> argument.</p>
</td></tr>
<tr><td><code id="defuzz_+3A_values">values</code></td>
<td>
<p>A universe for the fuzzy set.</p>
</td></tr>
<tr><td><code id="defuzz_+3A_type">type</code></td>
<td>
<p>Type of the requested defuzzification method. The possibilities are:
</p>

<ul>
<li> <p><code>'mom'</code>: Mean of Maxima - maximum membership degrees are
found and a mean of values that correspond to that degrees is returned;
</p>
</li>
<li> <p><code>'fom'</code>: First of Maxima - first value with maximum membership
degree is returned;
</p>
</li>
<li> <p><code>'lom'</code>: Last of Maxima - last value with maximum membership degree
is returned;
</p>
</li>
<li> <p><code>'dee'</code>: Defuzzification of Evaluative Expressions - method used
by the <code><a href="#topic+pbld">pbld()</a></code> inference mechanism that combines the former three
approaches accordingly to the shape of the <code>degrees</code> vector:
If <code>degrees</code> is non-increasing then <code>'lom'</code> type is used,
if it is non-decreasing then <code>'fom'</code> is applied, else <code>'mom'</code> is selected;
</p>
</li>
<li> <p><code>'cog'</code>: Center of Gravity - the result is a mean of <code>values</code> weighted by <code>degrees</code>;
</p>
</li>
<li> <p><code>'exp1'</code>: Experimental 1.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>Function converts input fuzzy set into a crisp value. The definition of
input fuzzy set is provided by the arguments <code>degrees</code> and
<code>values</code>. These arguments should be numeric vectors of the same length,
the former containing membership degrees in the interval <code class="reqn">[0, 1]</code> and
the latter containing the corresponding crisp values: i.e., <code>values[i]</code>
has a membership degree <code>degrees[i]</code>.
</p>


<h3>Value</h3>

<p>A defuzzified value.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fire">fire()</a></code>, <code><a href="#topic+aggregateConsequents">aggregateConsequents()</a></code>, <code><a href="#topic+perceive">perceive()</a></code>, <code><a href="#topic+pbld">pbld()</a></code>, <code><a href="#topic+fcut">fcut()</a></code>, <code><a href="#topic+lcut">lcut()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# returns mean of maxima, i.e., mean of 6, 7, 8
defuzz(c(0, 0, 0, 0.1, 0.3, 0.9, 0.9, 0.9, 0.2, 0),
       1:10,
       type='mom')

</code></pre>

<hr>
<h2 id='equidist'>Return equidistant breaks</h2><span id='topic+equidist'></span>

<h3>Description</h3>

<p>If both <code>left</code> and <code>right</code> equal to <code>"none"</code>, the function returns a vector of <code>n</code> values from <code>x</code>
that divide the range of values in <code>x</code> into <code>n - 1</code> equidistant intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>equidist(
  x,
  n,
  left = c("infinity", "same", "none"),
  right = c("infinity", "same", "none")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="equidist_+3A_x">x</code></td>
<td>
<p>A numeric vector of input values</p>
</td></tr>
<tr><td><code id="equidist_+3A_n">n</code></td>
<td>
<p>The number of breaks of <code>x</code> to find (<code>n</code> must be at least 2)</p>
</td></tr>
<tr><td><code id="equidist_+3A_left">left</code></td>
<td>
<p>The left border of the returned vector of breaks: <code>"infinity"</code>, <code>"same"</code> or <code>"none"</code>
(see the description below)</p>
</td></tr>
<tr><td><code id="equidist_+3A_right">right</code></td>
<td>
<p>The right border of the returned vector of breaks: <code>"infinity"</code>, <code>"same"</code> or <code>"none"</code>
(see the description below)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the <code>left</code> (resp. <code>right</code>) argument equals to <code>"infinity"</code>, <code>-Inf</code> (resp. <code>Inf</code>) is prepended
(resp. appended) to the result. If it equals to <code>"same"</code>, the first (resp. last) value is doubled.
Such functionality is beneficial if using the result of this function with e.g. the <code><a href="#topic+fcut">fcut()</a></code> function:
<code>Inf</code> values at the beginning (resp. at the end) of the vector of breaks means that the fuzzy set
partition starts with a fuzzy set with kernel going to negative (resp. positive) infinity; the doubled
value at the beginning (resp. end) results in half-cut (trimmed) fuzzy set.
</p>


<h3>Value</h3>

<p>A vector of equidistant breaks, which can be used e.g. in <code><a href="#topic+fcut">fcut()</a></code>
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+equifreq">equifreq()</a></code>, <code><a href="#topic+fcut">fcut()</a></code>
</p>

<hr>
<h2 id='equifreq'>Return equifrequent breaks</h2><span id='topic+equifreq'></span>

<h3>Description</h3>

<p>If both <code>left</code> and <code>right</code> equal to <code>"none"</code>, the function returns a vector of <code>n</code> values from <code>x</code>
that divide the range of values in <code>x</code> into <code>n - 1</code> equidistant intervals. If the <code>left</code> (resp. <code>right</code>)
argument equals to <code>"infinity"</code>, <code>-Inf</code> (resp. <code>Inf</code>) is prepended (resp. appended) to the result. If
it equals to <code>"same"</code>, the first (resp. last) value is doubled. See <code><a href="#topic+fcut">fcut()</a></code> for what such vectors
mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>equifreq(
  x,
  n,
  left = c("infinity", "same", "none"),
  right = c("infinity", "same", "none")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="equifreq_+3A_x">x</code></td>
<td>
<p>A numeric vector of input values</p>
</td></tr>
<tr><td><code id="equifreq_+3A_n">n</code></td>
<td>
<p>The number of breaks of <code>x</code> to find (<code>n</code> must be at least 2)</p>
</td></tr>
<tr><td><code id="equifreq_+3A_left">left</code></td>
<td>
<p>The left border of the returned vector of breaks: <code>"infinity"</code>, <code>"same"</code> or <code>"none"</code>
(see the description below)</p>
</td></tr>
<tr><td><code id="equifreq_+3A_right">right</code></td>
<td>
<p>The right border of the returned vector of breaks: <code>"infinity"</code>, <code>"same"</code> or <code>"none"</code>
(see the description below)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the <code>left</code> (resp. <code>right</code>) argument equals to <code>"infinity"</code>, <code>-Inf</code> (resp. <code>Inf</code>) is prepended
(resp. appended) to the result. If it equals to <code>"same"</code>, the first (resp. last) value is doubled.
Such functionality is beneficial if using the result of this function with e.g. the <code><a href="#topic+fcut">fcut()</a></code> function:
<code>Inf</code> values at the beginning (resp. at the end) of the vector of breaks means that the fuzzy set
partition starts with a fuzzy set with kernel going to negative (resp. positive) infinity; the doubled
value at the beginning (resp. end) results in half-cut (trimmed) fuzzy set.
</p>


<h3>Value</h3>

<p>A vector of equifrequent breaks
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+equidist">equidist()</a></code>, <code><a href="#topic+fcut">fcut()</a></code>
</p>

<hr>
<h2 id='evalfrbe'>Evaluate the performance of the FRBE forecast</h2><span id='topic+evalfrbe'></span>

<h3>Description</h3>

<p>Take a FRBE forecast and compare it with real values using arbitrary error
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evalfrbe(fit, real, error = c("smape", "mase", "rmse"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="evalfrbe_+3A_fit">fit</code></td>
<td>
<p>A FRBE model of class <code>frbe</code> as returned by the <code><a href="#topic+frbe">frbe()</a></code> function.</p>
</td></tr>
<tr><td><code id="evalfrbe_+3A_real">real</code></td>
<td>
<p>A numeric vector of real (known) values. The vector must
correspond to the values being forecasted, i.e. the length must be the same
as the horizon forecasted by <code><a href="#topic+frbe">frbe()</a></code>.</p>
</td></tr>
<tr><td><code id="evalfrbe_+3A_error">error</code></td>
<td>
<p>Error measure to be computed. It can be either Symmetric Mean
Absolute Percentage Error (<code>smape</code>), Mean Absolute Scaled Error (<code>mase</code>), or
Root Mean Squared Error (<code>rmse</code>). See also <code><a href="#topic+smape">smape()</a></code>, <code><a href="#topic+mase">mase()</a></code>, and <code><a href="#topic+rmse">rmse()</a></code>
for more details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Take a FRBE forecast and compare it with real values by evaluating a given
error measure.  FRBE forecast should be made for a horizon of the same value
as length of the vector of real values.
</p>


<h3>Value</h3>

<p>Function returns a data.frame with single row and columns
corresponding to the error of the individual forecasting methods that the
FRBE is computed from. Additionally to this, a column &quot;avg&quot; is added with
error of simple average of the individual forecasting methods and a column
&quot;frbe&quot; with error of the FRBE forecasts.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>References</h3>

<p>Štěpnička, M., Burda, M., Štěpničková, L. Fuzzy Rule Base
Ensemble Generated from Data by Linguistic Associations Mining. FUZZY SET
SYST. 2015.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+frbe">frbe()</a></code>, <code><a href="#topic+smape">smape()</a></code>, <code><a href="#topic+mase">mase()</a></code>, <code><a href="#topic+rmse">rmse()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  # prepare data (from the forecast package)
  library(forecast)
  horizon &lt;- 10
  train &lt;- wineind[-1 * (length(wineind)-horizon+1):length(wineind)]
  test &lt;- wineind[(length(wineind)-horizon+1):length(wineind)]
  f &lt;- frbe(ts(train, frequency=frequency(wineind)), h=horizon)
  evalfrbe(f, test)

</code></pre>

<hr>
<h2 id='farules'>Create an instance of S3 class <code>farules</code> which represents a set of fuzzy
association rules and their statistical characteristics.</h2><span id='topic+farules'></span>

<h3>Description</h3>

<p>This function is a constructor that returns an instance of the <code>farules</code> S3 class.
To search for fuzzy association rules, refer to the <code><a href="#topic+searchrules">searchrules()</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>farules(rules, statistics)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="farules_+3A_rules">rules</code></td>
<td>
<p>A list of character vectors, where each vector represents a
rule and each value of the vector represents a predicate. The first value of
the vector is assumed to be a rule's consequent, the rest is a rule's antecedent.</p>
</td></tr>
<tr><td><code id="farules_+3A_statistics">statistics</code></td>
<td>
<p>A numeric matrix of various statistical characteristics of
the rules. Each column of that matrix corresponds to some statistic (such as
support, confidence, etc.) and each row corresponds to a rule in the list of
<code>rules</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>farules</code>.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+searchrules">searchrules()</a></code>
</p>

<hr>
<h2 id='fcut'>Transform data into a <code>fsets</code> S3 class using shapes derived from
triangles or raised cosines</h2><span id='topic+fcut'></span><span id='topic+fcut.default'></span><span id='topic+fcut.numeric'></span><span id='topic+fcut.matrix'></span><span id='topic+fcut.data.frame'></span><span id='topic+fcut.factor'></span><span id='topic+fcut.logical'></span>

<h3>Description</h3>

<p>This function creates a set of fuzzy attributes from crisp data. Factors,
numeric vectors, matrix or data frame columns are transformed into a set of
fuzzy attributes, i.e. columns with membership degrees. Unlike
<code><a href="#topic+lcut">lcut()</a></code>, for transformation is not used the linguistic linguistic
approach, but partitioning using regular shapes of the fuzzy sets (such as
triangle, raised cosine).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fcut(x, ...)

## Default S3 method:
fcut(x, ...)

## S3 method for class 'factor'
fcut(x, name = deparse(substitute(x)), ...)

## S3 method for class 'logical'
fcut(x, name = deparse(substitute(x)), ...)

## S3 method for class 'numeric'
fcut(
  x,
  breaks,
  name = deparse(substitute(x)),
  type = c("triangle", "raisedcos"),
  merge = 1,
  parallel = FALSE,
  ...
)

## S3 method for class 'data.frame'
fcut(
  x,
  breaks = NULL,
  name = NULL,
  type = c("triangle", "raisedcos"),
  merge = 1,
  parallel = FALSE,
  ...
)

## S3 method for class 'matrix'
fcut(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fcut_+3A_x">x</code></td>
<td>
<p>Data to be transformed: a vector, matrix, or data frame.
Non-numeric data are allowed.</p>
</td></tr>
<tr><td><code id="fcut_+3A_...">...</code></td>
<td>
<p>Other parameters to some methods.</p>
</td></tr>
<tr><td><code id="fcut_+3A_name">name</code></td>
<td>
<p>A name to be added as a suffix to the created fuzzy attribute
names. This parameter can be used only if <code>x</code> is a vector. If <code>x</code>
is a matrix or data frame, <code>name</code> should be NULL because the fuzzy
attribute names are taken from column names of the argument <code>x</code>.</p>
</td></tr>
<tr><td><code id="fcut_+3A_breaks">breaks</code></td>
<td>
<p>This argument determines the break-points of the positions of
the fuzzy sets (see also <code><a href="#topic+equidist">equidist()</a></code>. It should be an ordered vector of
numbers such that the <code class="reqn">i</code>-th index specifies the beginning,
<code class="reqn">(i+1)</code>-th the center, and <code class="reqn">(i+2)</code>-th the ending of the <code class="reqn">i</code>-th
fuzzy set.
</p>
<p>I.e. the minimum number of breaks-points is 3; <code class="reqn">n-2</code> elementary fuzzy
sets would be created for <code class="reqn">n</code> break-points.
</p>
<p>If considering an i-th fuzzy set (of <code>type='triangle'</code>), <code>x</code>
values lower than <code class="reqn">i</code>-th break (and greater than <code class="reqn">(i+2)</code>-th break)
would result in zero membership degree, values equal to <code class="reqn">(i+1)</code>-th break
would have membership degree equal 1 and values between them the appropriate
membership degree between 0 and 1.
</p>
<p>The resulting fuzzy sets would be named after the original data by adding
dot (&quot;.&quot;) and a number <code class="reqn">i</code> of fuzzy set.
</p>
<p>Unlike <code><a href="base.html#topic+cut">base::cut()</a></code>, <code>x</code> values, that are lower or greater than
the given break-points, will have all membership degrees equal to zero.
</p>
<p>For non-numeric data, this argument is ignored. For <code>x</code> being a numeric
vector, it must be a vector of numeric values. For <code>x</code> being a numeric
matrix or data frame, it must be a named list containing a numeric vector
for each column - if not, the values are repeated for each column.</p>
</td></tr>
<tr><td><code id="fcut_+3A_type">type</code></td>
<td>
<p>The type of fuzzy sets to create. Currently, <code>'triangle'</code> or
<code>'raisedcos'</code> may be used. The <code>type</code> argument may be also a
function with 3 or 4 arguments:
</p>

<ul>
<li><p> if <code>type</code> is a 4-argument function, it is assumed that that it computes
membership degrees from values of the first argument while considering
the boundaries given by the next 3 arguments;
</p>
</li>
<li><p> if <code>type</code> is a 3-argument function, it is assumed that it is a factory
function similar to <code><a href="#topic+triangular">triangular()</a></code> or <code><a href="#topic+raisedcosine">raisedcosine()</a></code>, which, from given
three boundaries, creates a function that computes membership degrees.
</p>
</li></ul>
</td></tr>
<tr><td><code id="fcut_+3A_merge">merge</code></td>
<td>
<p>This argument determines whether to derive additional fuzzy
sets by merging the elementary fuzzy sets (whose position is determined with
the <code>breaks</code> argument) into super-sets.  The argument is ignored for
non-numeric data in <code>x</code>.
</p>
<p><code>merge</code> may contain any integer number from <code>1</code> to
<code>length(breaks) - 2</code>.  Value <code>1</code> means that the elementary fuzzy
sets should be present in the output.  Value <code>2</code> means that the two
consecutive elementary fuzzy sets should be combined by using the Lukasiewic
t-conorm, value <code>3</code> causes combining three consecutive elementary fuzzy
sets etc.
</p>
<p>The names of the derived (merged) fuzzy sets is derived from the names of
the original elementary fuzzy sets by concatenating them with the &quot;|&quot; (pipe)
separator.</p>
</td></tr>
<tr><td><code id="fcut_+3A_parallel">parallel</code></td>
<td>
<p>Whether the processing should be run in parallel or not.
Parallelization is implemented using the <code><a href="foreach.html#topic+foreach">foreach::foreach()</a></code> function.
The parallel environment must be set properly in advance, e.g. with
the <code><a href="doMC.html#topic+registerDoMC">doMC::registerDoMC()</a></code> function.  Currently this argument is
applied only if <code>x</code> is a matrix or data frame.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The aim of this function is to transform numeric data into a set of fuzzy
attributes.  The result is in the form of the object of class &quot;fsets&quot;, i.e.
a numeric matrix whose columns represent fuzzy sets (fuzzy attributes) with
values being the membership degrees.
</p>
<p>The function behaves differently to the type of input <code>x</code>.
</p>
<p>If <code>x</code> is a factor or a logical vector (or other non-numeric data) then
for each distinct value of an input, a fuzzy set is created, and data would
be transformed into crisp membership degrees 0 or 1 only.
</p>
<p>If <code>x</code> is a numeric vector then fuzzy sets are created accordingly to
break-points specified in the <code>breaks</code> argument with 1st, 2nd and 3rd
break-point specifying the first fuzzy set, 2nd, 3rd and 4th break-point
specifying th second fuzzy set etc. The shape of the fuzzy set is determined
by the <code>type</code> argument that may be equal either to a string
<code>'triangle'</code> or <code>'raisedcos'</code> or it could be a function that
computes the membership degrees for itself (see <code><a href="#topic+triangular">triangular()</a></code> or
<code><a href="#topic+raisedcosine">raisedcosine()</a></code> functions for details). Additionally, super-sets of
these elementary sets may be created by specifying the <code>merge</code>
argument. Values of this argument specify how many consecutive fuzzy sets
should be combined (by using the Lukasiewic's t-conorm) to produce
super-sets - see the description of <code>merge</code> above.
</p>
<p>If a matrix (resp. data frame) is provided to this function instead of
single vector, all columns are processed separately as described above and
the result is combined with the <code><a href="#topic+cbind.fsets">cbind.fsets()</a></code> function.
</p>
<p>The function sets up properly the <code><a href="#topic+vars">vars()</a></code> and <code><a href="#topic+specs">specs()</a></code>
properties of the result.
</p>


<h3>Value</h3>

<p>An object of class &quot;fsets&quot; is returned, which is a numeric matrix
with columns representing the fuzzy attributes. Each source column of the
<code>x</code> argument corresponds to multiple columns in the resulting matrix.
Columns have names that indicate the name of the source as well as a index
<code class="reqn">i</code> of fuzzy set(s) &ndash; see the description of arguments <code>breaks</code>
and <code>merge</code> above.
</p>
<p>The resulting object would also have set the <code><a href="#topic+vars">vars()</a></code> and
<code><a href="#topic+specs">specs()</a></code> properties with the former being created from original
column names (if <code>x</code> is a matrix or data frame) or the <code>name</code>
argument (if <code>x</code> is a numeric vector). The <code><a href="#topic+specs">specs()</a></code>
incidency matrix would be created to reflect the superset-hood of the merged
fuzzy sets.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lcut">lcut()</a></code>, <code><a href="#topic+equidist">equidist()</a></code>, <code><a href="#topic+farules">farules()</a></code>, <code><a href="#topic+pbld">pbld()</a></code>, <code><a href="#topic+vars">vars()</a></code>, <code><a href="#topic+specs">specs()</a></code>,
<code><a href="#topic+cbind.fsets">cbind.fsets()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# fcut on non-numeric data
ff &lt;- factor(substring("statistics", 1:10, 1:10), levels = letters)
fcut(ff)

# transform a single vector into a single fuzzy set
x &lt;- runif(10)
fcut(x, breaks=c(0, 0.5, 1), name='age')

# transform single vector into a partition of the interval 0-1
# (the boundary triangles are right-angled)
fcut(x, breaks=c(0, 0, 0.5, 1, 1), name='age')

# also create supersets
fcut(x, breaks=c(0, 0, 0.5, 1, 1), name='age', merge=c(1, 2))

# transform all columns of a data frame
# with different breakpoints
data &lt;- CO2[, c('conc', 'uptake')]
fcut(data, breaks=list(conc=c(95, 95, 350, 1000, 1000),
                       uptake=c(7, 7, 28.3, 46, 46)))

# using a custom 3-argument function (a function factory):
f &lt;- function(a, b, c) {
  return(function(x) ifelse(a &lt;= x &amp; x &lt;= b, 1, 0))
}
fcut(x, breaks=c(0, 0.5, 1), name='age', type=f)

# using a custom 4-argument function:
f &lt;- function(x, a, b, c) {
  return(ifelse(a &lt;= x &amp; x &lt;= b, 1, 0))
}
fcut(x, breaks=c(0, 0.5, 1), name='age', type=f)

</code></pre>

<hr>
<h2 id='fire'>Evaluate rules and obtain truth-degrees</h2><span id='topic+fire'></span>

<h3>Description</h3>

<p>Given truth degrees of predicates, compute the truth value of given list of rules.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fire(
  x,
  rules,
  tnorm = c("goedel", "goguen", "lukasiewicz"),
  onlyAnte = TRUE,
  parallel = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fire_+3A_x">x</code></td>
<td>
<p>Truth degrees of predicates. <code>x</code> could be either a numeric
matrix or a numeric vector. If vector is given then each named element represents
a truth value of a predicate. If matrix is given then each row of the matrix
is evaluated sequentially as a vector. The values must be in the interval
<code class="reqn">[0, 1]</code>.</p>
</td></tr>
<tr><td><code id="fire_+3A_rules">rules</code></td>
<td>
<p>Either an object of S3 class <code><a href="#topic+farules">farules()</a></code> or a list of character
vectors where each vector is a rule in a conjunctive form. Elements of these
character vectors (i.e., predicate names) must correspond to
the <code>x</code>'s names (of elements resp. columns if <code>x</code> is a vector resp. matrix).</p>
</td></tr>
<tr><td><code id="fire_+3A_tnorm">tnorm</code></td>
<td>
<p>A character string representing a triangular norm to be used
(either <code>"goedel"</code>, <code>"goguen"</code>, or <code>"lukasiewicz"</code>) or an arbitrary function
that performs element-wise computation on arbitrary number of vector parameters
similarly as e.g. <code><a href="#topic+pgoedel.tnorm">pgoedel.tnorm()</a></code>, <code><a href="#topic+pgoguen.tnorm">pgoguen.tnorm()</a></code> or <code><a href="#topic+plukas.tnorm">plukas.tnorm()</a></code>.</p>
</td></tr>
<tr><td><code id="fire_+3A_onlyante">onlyAnte</code></td>
<td>
<p><code>TRUE</code> is useful if rules store both the antecedent and consequent
and if only the antecedent-part of a rule should be included into the evaluated
conjunction. Antecedent-part of a rule are all predicates in the vector starting from
the 2nd position. <code>TRUE</code> value in this parameter causes the first element of each
rule to be ignored.
</p>
<p>If <code>FALSE</code>, all predicates in a rule will be included in the conjunction.</p>
</td></tr>
<tr><td><code id="fire_+3A_parallel">parallel</code></td>
<td>
<p>Deprecated parameter. Computation is done sequentially.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The aim of this function is to compute the truth value of each rule in a
<code>rules</code> list by assigning truth values to rule's predicates given by data <code>x</code>.
</p>
<p><code>x</code> is a numeric vector or numeric matrix of truth values of predicates. If
<code>x</code> is vector then <code>names(x)</code> must correspond to the predicate names
in <code>rules</code>. If <code>x</code> is a matrix then each column should represent a predicate
and thus <code>colnames(x)</code> must correspond to predicate names in <code>rules</code>.
Values of <code>x</code> are interpreted as truth values, i.e., they must be from the
interval <code class="reqn">[0, 1]</code>. If matrix is given, the resulting truth values are
computed row-wisely.
</p>
<p><code>rules</code> may be a list of character vectors or an instance of the S3 class
<code><a href="#topic+farules">farules()</a></code>. The character vectors in the <code>rules</code> list represent formulae
in conjunctive form. If <code>onlyAnte=FALSE</code>, <code>fire()</code> treats the rule as
a conjunction of all predicates, i.e., a conjunction of all predicates is
computed. If <code>onlyAnte=TRUE</code>, the first element of each rule is removed
prior evaluation, i.e., a conjunction of all predicates except the first
are computed: this is useful if <code>rules</code> is a <code><a href="#topic+farules">farules()</a></code> object, since
<code><a href="#topic+farules">farules()</a></code> objects save a rule's consequent as the first element (see also
<code><a href="#topic+antecedents">antecedents()</a></code> and <code><a href="#topic+consequents">consequents()</a></code> functions).
</p>
<p>The type of  conjunction to be computed can be specified with the <code>tnorm</code> parameter.
</p>


<h3>Value</h3>

<p>If <code>x</code> is a matrix then the result of this function is a list
of numeric vectors with truth values of each rule, i.e., each element of the
resulting list corresponds to a rule and each value of the vector in the resulting
list corresponds to a row of the original data matrix <code>x</code>.
</p>
<p><code>x</code> as a vector is treated as a single-row matrix.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aggregateConsequents">aggregateConsequents()</a></code>, <code><a href="#topic+defuzz">defuzz()</a></code>, <code><a href="#topic+perceive">perceive()</a></code>, <code><a href="#topic+pbld">pbld()</a></code>, <code><a href="#topic+fcut">fcut()</a></code>, <code><a href="#topic+lcut">lcut()</a></code>, <code><a href="#topic+farules">farules()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# fire whole rules on a vector
x &lt;- 1:10 / 10
names(x) &lt;- letters[1:10]
rules &lt;- list(c('a', 'c', 'e'),
              c('b'),
              c('d', 'a'),
              c('c', 'a', 'b'))
fire(x, rules, tnorm='goguen', onlyAnte=FALSE)

# fire antecedents of the rules on a matrix
x &lt;- matrix(1:20 / 20, nrow=2)
colnames(x) &lt;- letters[1:10]
rules &lt;- list(c('a', 'c', 'e'),
              c('b'),
              c('d', 'a'),
              c('c', 'a', 'b'))
fire(x, rules, tnorm='goedel', onlyAnte=TRUE)

# the former command should be equal to
fire(x, antecedents(rules), tnorm='goedel', onlyAnte=FALSE)

</code></pre>

<hr>
<h2 id='frbe'>Fuzzy Rule-Based Ensemble (FRBE) of time-series forecasts</h2><span id='topic+frbe'></span>

<h3>Description</h3>

<p>This function computes the fuzzy rule-based ensemble of time-series
forecasts.  Several forecasting methods are used to predict future values of
given time-series and a weighted sum is computed from them with weights
being determined from a fuzzy rule base.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>frbe(d, h = 10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="frbe_+3A_d">d</code></td>
<td>
<p>A source time-series in the ts time-series format.  Note that the
frequency of the time-series must to be set properly.</p>
</td></tr>
<tr><td><code id="frbe_+3A_h">h</code></td>
<td>
<p>A forecasting horizon, i.e. the number of values to forecast.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the fuzzy rule-based ensemble of time-series
forecasts.  The evaluation comprises of the following steps:
</p>

<ol>
<li><p> Several features are extracted from the given time-series <code>d</code>:
</p>

<ul>
<li><p> length of the time-series;
</p>
</li>
<li><p> strength of trend;
</p>
</li>
<li><p> strength of seasonality;
</p>
</li>
<li><p> skewness;
</p>
</li>
<li><p> kurtosis;
</p>
</li>
<li><p> variation coefficient;
</p>
</li>
<li><p> stationarity;
</p>
</li>
<li><p> frequency.
These features are used later to infer weights of the forecasting methods.
</p>
</li></ul>

</li>
<li><p> Several forecasting methods are applied on the given time-series <code>d</code> to
obtain forecasts. Actually, the following methods are used:
</p>

<ul>
<li><p> ARIMA - by calling <code><a href="forecast.html#topic+auto.arima">forecast::auto.arima()</a></code>;
</p>
</li>
<li><p> Exponential Smoothing - by calling <code><a href="forecast.html#topic+ets">forecast::ets()</a></code>;
</p>
</li>
<li><p> Random Walk with Drift - by calling <code><a href="forecast.html#topic+naive">forecast::rwf()</a></code>;
</p>
</li>
<li><p> Theta - by calling [forecast::thetaf().
</p>
</li></ul>

</li>
<li><p> Computed features are input to the fuzzy rule-based inference mechanism
which yields into weights of the forecasting methods. The fuzzy rule base is
hardwired in this package and it was obtained by performing data mining with
the use of the <code><a href="#topic+farules">farules()</a></code> function.
</p>
</li>
<li><p> A weighted sum of forecasts is computed and returned as a result.
</p>
</li></ol>



<h3>Value</h3>

<p>Result is a list of class <code>frbe</code> with the following elements:
</p>

<ul>
<li> <p><code>features</code> - a data frame with computed features of the given time-series;
</p>
</li>
<li> <p><code>forecasts</code> - a data frame with forecasts to be ensembled;
</p>
</li>
<li> <p><code>weights</code> - weights of the forecasting methods as inferred from the features
and the hard-wired fuzzy rule base;
</p>
</li>
<li> <p><code>mean</code> - the resulting ensembled forecast (computed as a weighted sum
of forecasts).
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>References</h3>

<p>Štěpnička, M., Burda, M., Štěpničková, L. Fuzzy Rule Base
Ensemble Generated from Data by Linguistic Associations Mining. FUZZY SET
SYST. 2015.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evalfrbe">evalfrbe()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # prepare data (from the forecast package)
  library(forecast)
  horizon &lt;- 10
  train &lt;- wineind[-1 * (length(wineind)-horizon+1):length(wineind)]
  test &lt;- wineind[(length(wineind)-horizon+1):length(wineind)]

  # perform FRBE
  f &lt;- frbe(ts(train, frequency=frequency(wineind)), h=horizon)

  # evaluate FRBE forecasts
  evalfrbe(f, test)

  # display forecast results
  f$mean

</code></pre>

<hr>
<h2 id='fsets'>S3 class representing a set of fuzzy sets on the fixed universe</h2><span id='topic+fsets'></span><span id='topic+vars'></span><span id='topic+vars+3C-'></span><span id='topic+specs'></span><span id='topic+specs+3C-'></span>

<h3>Description</h3>

<p>The aim of the <code>fsets</code> S3 class is to store several fuzzy sets in the
form of numeric matrix where columns represent fuzzy sets, rows are
elements from the universe, and therefore a value of <code>i</code>-th row and <code>j</code>-th
column is a membership degree of <code>i</code>-th element of the universe to <code>j</code>-th fuzzy
set. The <code>fsets</code> object also stores the information about
the origin of the fuzzy sets as well as a relation of specificity among
them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fsets(
  x,
  vars = rep(deparse(substitute(x)), ncol(x)),
  specs = matrix(0, nrow = ncol(x), ncol = ncol(x))
)

vars(f)

vars(f) &lt;- value

specs(f)

specs(f) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fsets_+3A_x">x</code></td>
<td>
<p>A matrix of membership degrees. Columns of the matrix represent
fuzzy sets, colnames are names of the fuzzy sets (and must not be NULL). Rows
of the matrix represent elements of the universe.</p>
</td></tr>
<tr><td><code id="fsets_+3A_vars">vars</code></td>
<td>
<p>A character vector that must correspond to the
columns of <code>x</code>. It is a vector of names of original variables that the
fuzzy sets were created from. In other words, the <code>vars</code> vector should
contain the same value for each <code>x</code>'s column that corresponds to the same
variable. Names of the <code>vars</code> vector are ignored.
For instance, an <code><a href="#topic+fcut">fcut()</a></code> function can transform a single numeric
vector into several different fuzzy sets. To indicate that all of them in
fact describe the same original variable, the same name is stored on
appropriate positions of the <code>vars</code> vector.</p>
</td></tr>
<tr><td><code id="fsets_+3A_specs">specs</code></td>
<td>
<p>A square numeric matrix containing values from <code style="white-space: pre;">&#8288;{0, 1}&#8288;</code>.
It is a specificity matrix, for which both rows and columns correspond to
<code>x</code>'s columns and where <code>specs[i][j] == 1</code> if and only if <code>i</code>-th fuzzy
set (i.e. <code>x[, i]</code>) is more specific (is a subset or equal to) than <code>j</code>-th fuzzy
set (i.e. <code>x[, j]</code>).</p>
</td></tr>
<tr><td><code id="fsets_+3A_f">f</code></td>
<td>
<p>An instance of S3 class <code>fsets</code>.</p>
</td></tr>
<tr><td><code id="fsets_+3A_value">value</code></td>
<td>
<p>Attribute values to be set to the object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>fsets()</code> function is a constructor of an object of type <code>fsets</code>.
Each object stores two attributes: <code>vars</code> and <code>specs</code>. The functions <code><a href="#topic+vars">vars()</a></code>
and <code><a href="#topic+specs">specs()</a></code>). can be used to access these attributes.
</p>
<p>It is assumed that the fuzzy sets
are derived from some raw variables, e.g. numeric vectors or factors. <code>vars</code>
attribute is a character vector of names of raw variables with size equal
to the number of fuzzy sets in <code>fsets</code> object. It is then assumed that
two fuzzy sets with the same name in <code><a href="#topic+vars">vars()</a></code> attribute are derived from
the same variable.
</p>
<p><code>specs</code> attribute gives a square numeric matrix of size equal to the number
of fuzzy sets in <code>fsets</code>. <code>specs[i][j] == 1</code> if and only if the <code>i</code>-th fuzzy
set is more specific than <code>j</code>-th fuzzy set. Specificity of fuzzy sets means
the nestedness of fuzzy set: for instance, <code style="white-space: pre;">&#8288;very small&#8288;</code> is more specific than
<code>small</code>; similarly, <code style="white-space: pre;">&#8288;extremely big&#8288;</code> is more specific than <code style="white-space: pre;">&#8288;very big&#8288;</code>; on the
other hand, <code style="white-space: pre;">&#8288;very big&#8288;</code> and <code style="white-space: pre;">&#8288;extremely small&#8288;</code> are incomparable. A necessary
condition for specificity is subsethood.
</p>


<h3>Value</h3>

<p><code><a href="#topic+fsets">fsets()</a></code> returns an object of S3 class <code>fsets</code>. <code><a href="#topic+vars">vars()</a></code> returns
a vector of original variable names of the <code>fsets</code> object. <code>specs</code>
returns the specificity matrix.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fcut">fcut()</a></code>, <code><a href="#topic+lcut">lcut()</a></code>, <code><a href="#topic+is.specific">is.specific()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    # create a matrix of random membership degrees
    m &lt;- matrix(runif(30), ncol=5)
    colnames(m) &lt;- c('a1', 'a2', 'a12', 'b1', 'b2')

    # create vars - first three (a1, a2, a3) and next two (b1, b2)
    # fuzzy sets originate from the same variable
    v &lt;- c('a', 'a', 'a', 'b', 'b')
    names(v) &lt;- colnames(m)

    # create specificity matrix - a1 and a2 are more specific than a12,
    # the rest is incomparable
    s &lt;- matrix(c(0, 0, 1, 0, 0,
                  0, 0, 1, 0, 0,
                  0, 0, 0, 0, 0,
                  0, 0, 0, 0, 0,
                  0, 0, 0, 0, 0), byrow=TRUE, ncol=5)
    colnames(s) &lt;- colnames(m)
    rownames(s) &lt;- colnames(m)

    # create a valid instance of the fsets class
    o &lt;- fsets(m, v, s)

</code></pre>

<hr>
<h2 id='ft'>Fuzzy transform</h2><span id='topic+ft'></span>

<h3>Description</h3>

<p>Compute a fuzzy tranform of the given input matrix <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ft(x, xmemb, y, order = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ft_+3A_x">x</code></td>
<td>
<p>the numeric matrix of input values</p>
</td></tr>
<tr><td><code id="ft_+3A_xmemb">xmemb</code></td>
<td>
<p>the partitioning of input values, i.e., a <code>fsets</code> object with membership degrees
(see <code><a href="#topic+fcut">fcut()</a></code>)</p>
</td></tr>
<tr><td><code id="ft_+3A_y">y</code></td>
<td>
<p>the numeric vector of target values</p>
</td></tr>
<tr><td><code id="ft_+3A_order">order</code></td>
<td>
<p>the order of the fuzzy transform (0, 1, 2, ...)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the instance of the S3 class <code>ft</code>
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>References</h3>

<p>Perfilieva I. Fuzzy transforms: Theory and applications. FUZZY SET SYST,
volume 157, issue 8, p. 993-1023. 2006.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ftinv">ftinv()</a></code>, <code><a href="#topic+is.ft">is.ft()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# create the fuzzy transform object
y &lt;- (1:30)^2
x &lt;- as.matrix(data.frame(a = 1:30, b = 30:1))
xmemb &lt;- fcut(x,
              breaks = list(a = equidist(x[, 'a'], 3),
                            b = equidist(x[, 'b'], 3)))
fit &lt;- ft(x, xmemb, y, order = 1)

# obtain function values
x2 &lt;- as.matrix(data.frame(a = 10:20, b = 20:10))
xmemb2 &lt;- fcut(x2,
               breaks = list(a = equidist(x[, 'a'], 3),
                             b = equidist(x[, 'b'], 3)))
y2 &lt;- ftinv(fit, x2, xmemb2)
print(y2)

# compare original values with those obtained by the fuzzy transform
y[10:20] - y2

</code></pre>

<hr>
<h2 id='ftinv'>Inverse of the fuzzy transform</h2><span id='topic+ftinv'></span>

<h3>Description</h3>

<p>Compute an inverse of fuzzy transform <code>fit</code> for values <code>x</code> with corresponding
membership degrees <code>xmemb</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ftinv(fit, x, xmemb)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ftinv_+3A_fit">fit</code></td>
<td>
<p>The fuzzy transform object as the instance of the <code>ft</code> S3 class</p>
</td></tr>
<tr><td><code id="ftinv_+3A_x">x</code></td>
<td>
<p>The numeric matrix of input values, for which the inverse fuzzy transform
has to be computed</p>
</td></tr>
<tr><td><code id="ftinv_+3A_xmemb">xmemb</code></td>
<td>
<p>the partitioning of input values, i.e., a <code>fsets</code> object with membership degrees
(see <code><a href="#topic+fcut">fcut()</a></code>). Such partitioning must correspond to the <code>xmemb</code> partitioning used to
create <code>fit</code> using the <code><a href="#topic+ft">ft()</a></code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The inverse of the fuzzy transform <code>fit</code>, i.e., the approximated values
of the original function that was the subject of the fuzzy transform
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>References</h3>

<p>Perfilieva I. Fuzzy transforms: Theory and applications. FUZZY SET SYST,
volume 157, issue 8, p. 993-1023. 2006.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ft">ft()</a></code>, <code><a href="#topic+is.ft">is.ft()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# create the fuzzy transform object
y &lt;- (1:30)^2
x &lt;- as.matrix(data.frame(a = 1:30, b = 30:1))
xmemb &lt;- fcut(x,
              breaks = list(a = equidist(x[, 'a'], 3),
                            b = equidist(x[, 'b'], 3)))
fit &lt;- ft(x, xmemb, y, order = 1)

# obtain function values
x2 &lt;- as.matrix(data.frame(a = 10:20, b = 20:10))
xmemb2 &lt;- fcut(x2,
               breaks = list(a = equidist(x[, 'a'], 3),
                             b = equidist(x[, 'b'], 3)))
y2 &lt;- ftinv(fit, x2, xmemb2)
print(y2)

# compare original values with those obtained by the fuzzy transform
y - y2

</code></pre>

<hr>
<h2 id='hedge'>Linguistic hedges</h2><span id='topic+hedge'></span>

<h3>Description</h3>

<p>Returns a function that realizes linguistic hedging - i.e. transformation of linguistic
horizon (see <code><a href="#topic+horizon">horizon()</a></code>) into a linguistic expression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hedge(
  type = c("ex", "si", "ve", "ty", "-", "ml", "ro", "qr", "vr"),
  hedgeParams = defaultHedgeParams
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hedge_+3A_type">type</code></td>
<td>
<p>The type of the required linguistic hedge</p>
</td></tr>
<tr><td><code id="hedge_+3A_hedgeparams">hedgeParams</code></td>
<td>
<p>Parameters that determine the shape of the hedges</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>hedge()</code> returns a function that realizes the selected linguistic hedge on its parameter:
</p>

<ul>
<li> <p><code>ex</code>: extremely,
</p>
</li>
<li> <p><code>si</code>: significantly,
</p>
</li>
<li> <p><code>ve</code>: very,
</p>
</li>
<li> <p><code>ty</code>: typically,
</p>
</li>
<li> <p><code>-</code>: empty hedge (no hedging),
</p>
</li>
<li> <p><code>ml</code>: more or less,
</p>
</li>
<li> <p><code>ro</code>: roughly,
</p>
</li>
<li> <p><code>qr</code>: quite roughly,
</p>
</li>
<li> <p><code>vr</code>: very roughly.
</p>
</li></ul>

<p>This function is quite low-level. Perhaps a more convenient way to create linguistic expressions
is to use the <code><a href="#topic+lingexpr">lingexpr()</a></code> function.
</p>


<h3>Value</h3>

<p>Returns a function with a single argument, which has to be a numeric
vector.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+horizon">horizon()</a></code>, <code><a href="#topic+lingexpr">lingexpr()</a></code>, <code><a href="#topic+fcut">fcut()</a></code>, <code><a href="#topic+lcut">lcut()</a></code>, <code><a href="#topic+ctx">ctx()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    a &lt;- horizon(ctx3(), 'sm')
    plot(a)
    h &lt;- hedge('ve')
    plot(h)
    verySmall &lt;- function(x) h(a(x))
    plot(verySmall)

    # the last plot should be equal to:
    plot(lingexpr(ctx3(), atomic='sm', hedge='ve'))

</code></pre>

<hr>
<h2 id='horizon'>Create a function that computes linguistic horizons</h2><span id='topic+horizon'></span>

<h3>Description</h3>

<p>Based on given <code>context</code> and <code>atomic</code> expression, this function returns a function that computes a linguistic
horizon, i.e. a triangular function representing basic limits of what humans treat as &quot;small&quot;, &quot;medium&quot;, &quot;big&quot; etc.
within given <code>context</code>. Linguistic horizon stands as a base for creation of linguistic expressions. A linguistic
expression is created by applying a <code><a href="#topic+hedge">hedge()</a></code> on horizon. (Atomic linguistic expression is created from horizon by
applying an empty (<code>-</code>) hedge).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>horizon(
  context,
  atomic = c("sm", "me", "bi", "lm", "um", "ze", "neg.sm", "neg.me", "neg.bi", "neg.lm",
    "neg.um")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="horizon_+3A_context">context</code></td>
<td>
<p>A context of linguistic expressions (see <code><a href="#topic+ctx3">ctx3()</a></code>, <code><a href="#topic+ctx5">ctx5()</a></code>, <code><a href="#topic+ctx3bilat">ctx3bilat()</a></code> or <code><a href="#topic+ctx5bilat">ctx5bilat()</a></code>)</p>
</td></tr>
<tr><td><code id="horizon_+3A_atomic">atomic</code></td>
<td>
<p>An atomic expression whose horizon we would like to obtain</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The values of the <code>atomic</code> parameter have the following meaning (in ascending order):
</p>

<ul>
<li> <p><code>neg.bi</code>: big negative (far from zero)
</p>
</li>
<li> <p><code>neg.um</code>: upper medium negative (between medium negative and big negative)
</p>
</li>
<li> <p><code>neg.me</code>: medium negative
</p>
</li>
<li> <p><code>neg.lm</code>: lower medium negative (between medium negative and small negative)
</p>
</li>
<li> <p><code>neg.sm</code>: small negative (close to zero)
</p>
</li>
<li> <p><code>ze</code>: zero
</p>
</li>
<li> <p><code>sm</code>: small
</p>
</li>
<li> <p><code>lm</code>: lower medium
</p>
</li>
<li> <p><code>me</code>: medium
</p>
</li>
<li> <p><code>um</code>: upper medium
</p>
</li>
<li> <p><code>bi</code>: big
</p>
</li></ul>

<p>Based on the context type, the following atomic expressions are allowed:
</p>

<ul>
<li> <p><code><a href="#topic+ctx3">ctx3()</a></code> (trichotomy): small, medium, big;
</p>
</li>
<li> <p><code><a href="#topic+ctx5">ctx5()</a></code> (pentachotomy): small, lower medium, medium, upper medium, big;
</p>
</li>
<li> <p><code><a href="#topic+ctx3bilat">ctx3bilat()</a></code> (bilateral trichotomy): negative big, negative medium, negative small,
zero, small, medium, big;
</p>
</li>
<li> <p><code><a href="#topic+ctx5bilat">ctx5bilat()</a></code> (bilateral pentachotomy): negative big, negative medium, negative
small, zero, small, medium, big.
</p>
</li></ul>

<p>This function is quite low-level. Perhaps a more convenient way to create linguistic expressions
is to use the <code><a href="#topic+lingexpr">lingexpr()</a></code> function.
</p>


<h3>Value</h3>

<p>A function of single argument that must be a numeric vector
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ctx3">ctx3()</a></code>, <code><a href="#topic+ctx5">ctx5()</a></code>, <code><a href="#topic+ctx3bilat">ctx3bilat()</a></code>, <code><a href="#topic+ctx5bilat">ctx5bilat()</a></code>, <code><a href="#topic+hedge">hedge()</a></code>, <code><a href="#topic+fcut">fcut()</a></code>, <code><a href="#topic+lcut">lcut()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    plot(horizon(ctx3(), 'sm'), from=-1, to=2)
    plot(horizon(ctx3(), 'me'), from=-1, to=2)
    plot(horizon(ctx3(), 'bi'), from=-1, to=2)

    a &lt;- horizon(ctx3(), 'sm')
    plot(a)
    h &lt;- hedge('ve')
    plot(h)
    verySmall &lt;- function(x) h(a(x))
    plot(verySmall)
</code></pre>

<hr>
<h2 id='is.farules'>Test whether <code>x</code> inherits from the S3 <code>farules</code> class.</h2><span id='topic+is.farules'></span>

<h3>Description</h3>

<p>Test whether <code>x</code> inherits from the S3 <code>farules</code> class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.farules(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="is.farules_+3A_x">x</code></td>
<td>
<p>An object being tested.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>TRUE</code> if <code>x</code> is a valid <code><a href="#topic+farules">farules()</a></code> object and <code>FALSE</code> otherwise.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+farules">farules</a></code>
</p>

<hr>
<h2 id='is.frbe'>Test whether <code>x</code> is a valid object of the S3 <code>frbe</code> class</h2><span id='topic+is.frbe'></span>

<h3>Description</h3>

<p>Test whether <code>x</code> has a valid format for the objects of the S3 <code>frbe</code> class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.frbe(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="is.frbe_+3A_x">x</code></td>
<td>
<p>An object being tested.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function tests whether <code>x</code> inherits from <code>frbe</code> i.e. whether
it is a list with the following elements: <code>forecasts</code> data frame,
<code>features</code> data frame, <code>weights</code> vector, and <code>mean</code> vector.
Instances of the S3 class <code>frbe</code> are usually created by the <code><a href="#topic+frbe">frbe()</a></code> function.
</p>


<h3>Value</h3>

<p><code>TRUE</code> if <code>x</code> is a valid <code>frbe</code> object and <code>FALSE</code> otherwise.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>References</h3>

<p>Štěpnička, M., Burda, M., Štěpničková, L. Fuzzy Rule Base
Ensemble Generated from Data by Linguistic Associations Mining. FUZZY SET
SYST. 2015.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+frbe">frbe()</a></code>
</p>

<hr>
<h2 id='is.fsets'>Test whether <code>x</code> is a valid object of the S3 <code>fsets</code> class</h2><span id='topic+is.fsets'></span>

<h3>Description</h3>

<p>This function tests whether <code>x</code> inherits from S3 <code>fsets</code> class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.fsets(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="is.fsets_+3A_x">x</code></td>
<td>
<p>An object being tested.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE if <code>x</code> is a valid <code>fsets</code> object and FALSE otherwise.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fsets">fsets()</a></code>
</p>

<hr>
<h2 id='is.ft'>Test whether <code>x</code> is a valid object of the S3 <code>ft</code> class</h2><span id='topic+is.ft'></span>

<h3>Description</h3>

<p>Test whether <code>x</code> has a valid format for objects of the S3 <code>ft</code> class that represents
the Fuzzy Transform.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.ft(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="is.ft_+3A_x">x</code></td>
<td>
<p>An object to be tested</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function tests whether <code>x</code> is an instance of the <code>ft</code> class and whether it is a list
with the following elements: <code>inputs</code> character vector, <code>partitions</code> list, <code>order</code> number,
<code>antecedents</code> matrix and <code>consequents</code> matrix.
</p>


<h3>Value</h3>

<p><code>TRUE</code> if <code>x</code> is a valid <code>ft</code> object and <code>FALSE</code> otherwise.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ft">ft()</a></code>, <code><a href="#topic+ftinv">ftinv()</a></code>
</p>

<hr>
<h2 id='is.specific'>Determine whether the first set <code>x</code> of predicates is more specific (or equal)
than <code>y</code> with respect to <code>vars</code> and <code>specs</code>.</h2><span id='topic+is.specific'></span>

<h3>Description</h3>

<p>The function takes two character vectors of predicates and determines whether
<code>x</code> is more specific (or equal w.r.t. the specificity) than <code>y</code>. The
specificity relation is fully determined with the values of the <code><a href="#topic+vars">vars()</a></code> vector
and the <code><a href="#topic+specs">specs()</a></code> incidence matrix that is encapsulated in the given <code>fsets</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.specific(x, y, fsets, vars = NULL, specs = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="is.specific_+3A_x">x</code></td>
<td>
<p>The first character vector of predicates.</p>
</td></tr>
<tr><td><code id="is.specific_+3A_y">y</code></td>
<td>
<p>The second character vector of predicates.</p>
</td></tr>
<tr><td><code id="is.specific_+3A_fsets">fsets</code></td>
<td>
<p>A valid instance of the <code><a href="#topic+fsets">fsets()</a></code> class such that all values in <code>x</code> and <code>y</code>
can be found in <code>colnames(fsets)</code></p>
</td></tr>
<tr><td><code id="is.specific_+3A_vars">vars</code></td>
<td>
<p>Deprecated parameter must be <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="is.specific_+3A_specs">specs</code></td>
<td>
<p>Deprecated parameter must be <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">x_i</code> and <code class="reqn">y_j</code> represent some predicates of vectors <code>x</code> and <code>y</code>,
respectively. Function assumes that each vector <code>x</code> and <code>y</code> does not
contain two or more predicates with the same value of <code><a href="#topic+vars">vars()</a></code>.
</p>
<p>This function returns TRUE iff all of the following conditions hold:
</p>

<ul>
<li><p> for any <code class="reqn">y_j</code> there exists <code class="reqn">x_i</code> such that <code class="reqn">vars[y_j] = vars[x_i]</code>;
</p>
</li>
<li><p> for any <code class="reqn">x_i</code> there either does not exist <code class="reqn">y_j</code> such that
<code class="reqn">vars[x_i] = vars[y_j]</code>, or <code class="reqn">x_i = y_j</code>, or <code class="reqn">specs[x_i, y_j] = 1</code>.
</p>
</li></ul>



<h3>Value</h3>

<p>TRUE or FALSE (see description).
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+perceive">perceive()</a></code>, <code><a href="#topic+pbld">pbld()</a></code>, <code><a href="#topic+fsets">fsets()</a></code>, <code><a href="#topic+vars">vars()</a></code>, <code><a href="#topic+specs">specs()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    # prepare fsets object
    v &lt;- c(rep('a', 3), rep('b', 3), rep('c', 3), rep('d', 3))
    s &lt;- matrix(c(0,1,0, 0,0,0, 0,0,0, 0,0,0,
                  0,0,0, 0,0,0, 0,0,0, 0,0,0,
                  0,0,0, 0,0,0, 0,0,0, 0,0,0,

                  0,0,0, 0,1,0, 0,0,0, 0,0,0,
                  0,0,0, 0,0,0, 0,0,0, 0,0,0,
                  0,0,0, 0,0,0, 0,0,0, 0,0,0,

                  0,0,0, 0,0,0, 0,1,0, 0,0,0,
                  0,0,0, 0,0,0, 0,0,0, 0,0,0,
                  0,0,0, 0,0,0, 0,0,0, 0,0,0,

                  0,0,0, 0,0,0, 0,0,0, 0,1,0,
                  0,0,0, 0,0,0, 0,0,0, 0,0,0,
                  0,0,0, 0,0,0, 0,0,0, 0,0,0),
                byrow=TRUE,
                ncol=12)
    m &lt;- matrix(0, nrow=1, ncol=12)
    colnames(m) &lt;- paste(rep(c('VeSm', 'Sm', 'Bi'), times=4),
                         rep(c('a', 'b', 'c', 'd'), each=3),
                         sep='.')
    f &lt;- fsets(m, v, s)


    # returns TRUE
    is.specific(c('VeSm.a', 'Bi.c'),
                c('VeSm.a', 'Bi.c'),
                f)

    # returns TRUE (x and y swapped return FALSE)
    is.specific(c('VeSm.a', 'Bi.c', 'Sm.d'),
                c('Sm.a', 'Bi.c', 'Sm.d'),
                f)

    # returns TRUE (x and y swapped return FALSE)
    is.specific(c('VeSm.a', 'Bi.c', 'Sm.d'),
                c('VeSm.a', 'Bi.c'),
                f)

    # returns TRUE (x and y swapped return FALSE)
    is.specific(c('VeSm.a', 'Bi.c', 'Sm.d'),
                character(),
                f)

    # returns FALSE
    is.specific(c('Sm.a'), c('Bi.c'), f)

    # returns FALSE
    is.specific(c('VeSm.a', 'Sm.c'),
                c('Sm.a', 'Bi.c'),
                f)
</code></pre>

<hr>
<h2 id='lcut'>Transform data into a <code>fsets</code> S3 class of linguistic fuzzy attributes</h2><span id='topic+lcut'></span><span id='topic+lcut.default'></span><span id='topic+lcut.factor'></span><span id='topic+lcut.logical'></span><span id='topic+lcut.numeric'></span><span id='topic+lcut.data.frame'></span><span id='topic+lcut.matrix'></span>

<h3>Description</h3>

<p>This function creates a set of linguistic fuzzy attributes from crisp data.
Numeric vectors, matrix or data frame columns are transformed into a set of
fuzzy attributes, i.e. columns with membership degrees. Factors and other
data types are transformed to fuzzy attributes by calling the <code><a href="#topic+fcut">fcut()</a></code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lcut(x, ...)

## Default S3 method:
lcut(x, ...)

## S3 method for class 'factor'
lcut(x, name = deparse(substitute(x)), ...)

## S3 method for class 'logical'
lcut(x, name = deparse(substitute(x)), ...)

## S3 method for class 'numeric'
lcut(
  x,
  context = minmax,
  atomic = c("sm", "me", "bi", "lm", "um", "ze", "neg.sm", "neg.me", "neg.bi", "neg.lm",
    "neg.um"),
  hedges = c("ex", "si", "ve", "ty", "-", "ml", "ro", "qr", "vr"),
  name = deparse(substitute(x)),
  hedgeParams = defaultHedgeParams,
  ...
)

## S3 method for class 'data.frame'
lcut(
  x,
  context = minmax,
  atomic = c("sm", "me", "bi", "lm", "um", "ze", "neg.sm", "neg.me", "neg.bi", "neg.lm",
    "neg.um"),
  hedges = c("ex", "si", "ve", "ty", "-", "ml", "ro", "qr", "vr"),
  ...
)

## S3 method for class 'matrix'
lcut(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lcut_+3A_x">x</code></td>
<td>
<p>Data to be transformed: if it is a numeric vector, matrix, or data
frame, then the creation of linguistic fuzzy attributes takes place. For
other data types the <code><a href="#topic+fcut">fcut()</a></code> function is called implicitly.</p>
</td></tr>
<tr><td><code id="lcut_+3A_...">...</code></td>
<td>
<p>Other parameters to some methods.</p>
</td></tr>
<tr><td><code id="lcut_+3A_name">name</code></td>
<td>
<p>A name to be added as a suffix to the created fuzzy attribute
names. This parameter can be used only if <code>x</code> is a numeric or logical
vector or a factor. If <code>x</code> is a matrix or data frame, <code>name</code> should be NULL
because the fuzzy attribute names are taken from column names of parameter
<code>x</code>. The <code>name</code> is also used as a value for the <code>vars</code> attribute of the
resulting <code><a href="#topic+fsets">fsets()</a></code> instance.</p>
</td></tr>
<tr><td><code id="lcut_+3A_context">context</code></td>
<td>
<p>A definition of context of a numeric attribute. It must be an
instance of an S3 class <code><a href="#topic+ctx3">ctx3()</a></code>, <code><a href="#topic+ctx5">ctx5()</a></code>, <code><a href="#topic+ctx3bilat">ctx3bilat()</a></code> or <code><a href="#topic+ctx5bilat">ctx5bilat()</a></code>.
</p>
<p>If <code>x</code> is a matrix or data frame then <code>context</code> should be a named list of
contexts for each <code>x</code>'s column.</p>
</td></tr>
<tr><td><code id="lcut_+3A_atomic">atomic</code></td>
<td>
<p>A vector of atomic linguistic expressions to be used for
creation of fuzzy attributes.</p>
</td></tr>
<tr><td><code id="lcut_+3A_hedges">hedges</code></td>
<td>
<p>A vector of linguistic hedges to be used for creation of fuzzy
attributes.</p>
</td></tr>
<tr><td><code id="lcut_+3A_hedgeparams">hedgeParams</code></td>
<td>
<p>Parameters that determine the shape of the hedges</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The aim of this function is to transform numeric data into a set of fuzzy
attributes.  The resulting fuzzy attributes have direct linguistic
interpretation. This is a unique variant of fuzzification that is suitable
for the inference mechanism based on Perception-based Linguistic Description
(PbLD) &ndash; see <code><a href="#topic+pbld">pbld()</a></code>.
</p>
<p>A numeric vector is transformed into a set of fuzzy attributes accordingly to
the following scheme:
</p>
<p><code class="reqn">&lt;hedge&gt; &lt;atomic expression&gt;</code>
</p>
<p>where <code class="reqn">&lt;atomic expression&gt;</code> is an atomic linguistic expression, a value
from the following possibilities (note that the allowance of atomic
expressions is influenced with <code>context</code> being used - see <a href="#topic+ctx">ctx</a> for details):
</p>

<ul>
<li> <p><code>neg.bi</code>: big negative (far from zero)
</p>
</li>
<li> <p><code>neg.um</code>: upper medium negative (between medium negative and big negative)
</p>
</li>
<li> <p><code>neg.me</code>: medium negative
</p>
</li>
<li> <p><code>neg.lm</code>: lower medium negative (between medium negative and small
negative)
</p>
</li>
<li> <p><code>neg.sm</code>: small negative (close to zero)
</p>
</li>
<li> <p><code>ze</code>: zero
</p>
</li>
<li> <p><code>sm</code>: small
</p>
</li>
<li> <p><code>lm</code>: lower medium
</p>
</li>
<li> <p><code>me</code>: medium
</p>
</li>
<li> <p><code>um</code>: upper medium
</p>
</li>
<li> <p><code>bi</code>: big
</p>
</li></ul>

<p>A <code class="reqn">&lt;hedge&gt;</code> is a modifier that further concretizes the atomic expression
(note that not each combination of hedge and atomic expression is allowed -
see <a href="#topic+allowed.lingexpr">allowed.lingexpr</a> for more details):
</p>

<ul>
<li> <p><code>ex</code>: extremely,
</p>
</li>
<li> <p><code>si</code>: significantly,
</p>
</li>
<li> <p><code>ve</code>: very,
</p>
</li>
<li> <p><code>ty</code>: typically,
</p>
</li>
<li> <p><code>-</code>: empty hedge (no hedging),
</p>
</li>
<li> <p><code>ml</code>: more or less,
</p>
</li>
<li> <p><code>ro</code>: roughly,
</p>
</li>
<li> <p><code>qr</code>: quite roughly,
</p>
</li>
<li> <p><code>vr</code>: very roughly.
</p>
</li></ul>

<p>Accordingly to the theory developed by Novak (2008), not every hedge is
suitable with each atomic #' expression (see the description of the <code>hedges</code>
argument).  The hedges to be used can be selected with the <code>hedges</code> argument.
Function takes care of not to use hedge together with an unapplicable atomic
expression by itself.
</p>
<p>Obviously, distinct data have different meaning of what is &quot;small&quot;, &quot;medium&quot;,
or &quot;big&quot; etc.  Therefore, a <code>context</code> has to be set that specifies sensible
values for these linguistic expressions.
</p>
<p>If a matrix (resp. data frame) is provided to this function instead of a
single vector, all columns are processed the same way.
</p>
<p>The function also sets up properly the <code><a href="#topic+vars">vars()</a></code> and <code><a href="#topic+specs">specs()</a></code> properties of
the result.
</p>


<h3>Value</h3>

<p>An object of S3 class <code>fsets</code> is returned, which is a numeric matrix
with columns representing the fuzzy attributes. Each source column of the
<code>x</code> argument corresponds to multiple columns in the resulting matrix.
Columns will have names derived from used <code class="reqn">hedges</code>, atomic expression,
and <code class="reqn">name</code> specified as the optional parameter.
</p>
<p>The resulting object would also have set the <code><a href="#topic+vars">vars()</a></code> and <code><a href="#topic+specs">specs()</a></code>
properties with the former being created from original column names (if <code>x</code>
is a matrix or data frame) or the <code>name</code> argument (if <code>x</code> is a numeric
vector). The <code><a href="#topic+specs">specs()</a></code> incidency matrix would be created to reflect the
following order of the hedges: <code class="reqn">"ex" &lt; "si" &lt; "ve" &lt; "-" &lt; "ml" &lt; "ro"
  &lt; "qr" &lt; "vr"</code> and <code class="reqn">"ty" &lt; "" &lt; "ml" &lt; "ro" &lt; "qr" &lt; "vr"</code>.  Fuzzy
attributes created from the same source numeric vector (or column) would be
ordered that way, with other fuzzy attributes (from the other source) being
incomparable.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>References</h3>

<p>V. Novak, A comprehensive theory of trichotomous evaluative
linguistic expressions, Fuzzy Sets and Systems 159 (22) (2008) 2939&ndash;2969.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fcut">fcut()</a></code>, <code><a href="#topic+fsets">fsets()</a></code>, <code><a href="#topic+vars">vars()</a></code>, <code><a href="#topic+specs">specs()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# transform a single vector
x &lt;- runif(10)
lcut(x, name='age')

# transform single vector with a custom context
lcut(x, context=ctx5(0, 0.2, 0.5, 0.7, 1), name='age')

# transform all columns of a data frame
# and do not use any hedges
data &lt;- CO2[, c('conc', 'uptake')]
lcut(data)


# definition of custom contexts for different columns
# of a data frame while selecting only "ve" and "ro" hedges.
lcut(data,
     context=list(conc=minmax,
                  uptake=ctx3(0, 25, 50)),
     hedges=c('ve', 'ro'))


# lcut on non-numeric data is the same as fcut()
ff &lt;- factor(substring("statistics", 1:10, 1:10), levels = letters)
lcut(ff)

</code></pre>

<hr>
<h2 id='lingexpr'>Creator of functions representing linguistic expressions</h2><span id='topic+lingexpr'></span><span id='topic+allowed.lingexpr'></span>

<h3>Description</h3>

<p>A linguistic expression represents vague human terms such as &quot;very small&quot;, &quot;extremely big&quot; etc. Such notions are
always reasoned within a given context. <code>lingexpr</code> returns a function that models a selected linguistic expression.
Accordingly to the given <code>context</code>, <code>atomic</code> expression (such as &quot;small&quot;, &quot;big&quot;) and a linguistic <code>hedge</code> (such as
<code>very</code>, <code>extremely</code>), the returned function transforms numeric values into degrees (from <code style="white-space: pre;">&#8288;[0, 1]&#8288;</code> interval),
at which the values correspond to the expression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lingexpr(
  context,
  atomic = c("sm", "me", "bi", "lm", "um", "ze", "neg.sm", "neg.me", "neg.bi", "neg.lm",
    "neg.um"),
  hedge = c("ex", "si", "ve", "ty", "-", "ml", "ro", "qr", "vr"),
  negated = FALSE,
  hedgeParams = defaultHedgeParams
)

allowed.lingexpr
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lingexpr_+3A_context">context</code></td>
<td>
<p>A context of linguistic expressions (see <code><a href="#topic+ctx3">ctx3()</a></code>, <code><a href="#topic+ctx5">ctx5()</a></code>, <code><a href="#topic+ctx3bilat">ctx3bilat()</a></code> or <code><a href="#topic+ctx5bilat">ctx5bilat()</a></code>)</p>
</td></tr>
<tr><td><code id="lingexpr_+3A_atomic">atomic</code></td>
<td>
<p>An atomic expression whose horizon we would like to obtain</p>
</td></tr>
<tr><td><code id="lingexpr_+3A_hedge">hedge</code></td>
<td>
<p>The type of the required linguistic hedge ('-' for no hedging)</p>
</td></tr>
<tr><td><code id="lingexpr_+3A_negated">negated</code></td>
<td>
<p>Negate the expression? (For instance, &quot;not very small&quot;.) Negation
is done using the <code><a href="#topic+invol.neg">invol.neg()</a></code> function.</p>
</td></tr>
<tr><td><code id="lingexpr_+3A_hedgeparams">hedgeParams</code></td>
<td>
<p>Parameters that determine the shape of the hedges</p>
</td></tr>
</table>


<h3>Format</h3>

<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 9 rows and 11 columns.
</p>


<h3>Details</h3>

<p>Based on the context type, the following atomic expressions are allowed:
</p>

<ul>
<li> <p><code><a href="#topic+ctx3">ctx3()</a></code> (trichotomy): small, medium, big;
</p>
</li>
<li> <p><code><a href="#topic+ctx5">ctx5()</a></code> (pentachotomy): small, lower medium, medium, upper medium, big;
</p>
</li>
<li> <p><code><a href="#topic+ctx3bilat">ctx3bilat()</a></code> (bilateral trichotomy): negative big, negative medium, negative small,
zero, small, medium, big;
</p>
</li>
<li> <p><code><a href="#topic+ctx5bilat">ctx5bilat()</a></code> (bilateral pentachotomy): negative big, negative medium, negative
small, zero, small, medium, big.
</p>
</li></ul>

<p>The values of the <code>atomic</code> parameter have the following meaning (in ascending order):
</p>

<ul>
<li> <p><code>neg.bi</code>: big negative (far from zero)
</p>
</li>
<li> <p><code>neg.um</code>: upper medium negative (between medium negative and big negative)
</p>
</li>
<li> <p><code>neg.me</code>: medium negative
</p>
</li>
<li> <p><code>neg.lm</code>: lower medium negative (between medium negative and small negative)
</p>
</li>
<li> <p><code>neg.sm</code>: small negative (close to zero)
</p>
</li>
<li> <p><code>ze</code>: zero
</p>
</li>
<li> <p><code>sm</code>: small
</p>
</li>
<li> <p><code>lm</code>: lower medium
</p>
</li>
<li> <p><code>me</code>: medium
</p>
</li>
<li> <p><code>um</code>: upper medium
</p>
</li>
<li> <p><code>bi</code>: big
</p>
</li></ul>

<p><code>hedge</code> parameter has the following meaning:
</p>

<ul>
<li> <p><code>ex</code>: extremely,
</p>
</li>
<li> <p><code>si</code>: significantly,
</p>
</li>
<li> <p><code>ve</code>: very,
</p>
</li>
<li> <p><code>ty</code>: typically,
</p>
</li>
<li> <p><code>-</code>: empty hedge,
</p>
</li>
<li> <p><code>ml</code>: more or less,
</p>
</li>
<li> <p><code>ro</code>: roughly,
</p>
</li>
<li> <p><code>qr</code>: quite roughly,
</p>
</li>
<li> <p><code>vr</code>: very roughly.
</p>
</li></ul>

<p>Accordingly to the theory of linguistic expressions by Novak, not every hedge is applicable to each atomic
expression. The combinations of allowed pairs can be found in <a href="#topic+allowed.lingexpr">allowed.lingexpr</a>. Trying to create forbidden
combination results in error.
</p>


<h3>Value</h3>

<p>Returns a function with a single argument, which has to be a numeric vector.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+horizon">horizon()</a></code>, <code><a href="#topic+hedge">hedge()</a></code>, <code><a href="#topic+fcut">fcut()</a></code>, <code><a href="#topic+lcut">lcut()</a></code>, <code><a href="#topic+ctx">ctx()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    small &lt;- lingexpr(ctx3(0, 0.5, 1), atomic='sm', hedge='-')
    small(0)   # 1
    small(0.8) # 0
    plot(small)

    verySmall &lt;- lingexpr(ctx3(0, 0.5, 1), atomic='sm', hedge='ve')
    plot(verySmall)
</code></pre>

<hr>
<h2 id='mase'>Compute Mean Absolute Scaled Error (MASE)</h2><span id='topic+mase'></span>

<h3>Description</h3>

<p>MASE is computed as <code class="reqn">sum(abs(validation - forecast)) / sum(abs(validation[-1] - validation[-n])) / (n/(n-1))</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mase(forecast, validation)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mase_+3A_forecast">forecast</code></td>
<td>
<p>A numeric vector of forecasted values</p>
</td></tr>
<tr><td><code id="mase_+3A_validation">validation</code></td>
<td>
<p>A numeric vector of actual (real) values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Mean Absolute Scaled Error (MASE)
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rmse">rmse()</a></code>, <code><a href="#topic+smape">smape()</a></code>, <code><a href="#topic+frbe">frbe()</a></code>
</p>

<hr>
<h2 id='minmax'>Creating linguistic context directly from values</h2><span id='topic+minmax'></span>

<h3>Description</h3>

<p>This function creates a context (i.e. an instance of S3 class
<code><a href="#topic+ctx3">ctx3()</a></code>, <code><a href="#topic+ctx3bilat">ctx3bilat()</a></code>, <code><a href="#topic+ctx5">ctx5()</a></code>, or <code><a href="#topic+ctx5bilat">ctx5bilat()</a></code>) based on values
of the numeric vector <code>x</code>. In default, the context is based on minimum
and maximum value of <code>x</code> in the following way:
</p>

<ul>
<li> <p><code>ctx3</code>, <code>ctx5</code>: low = minimum, high = maximum value of <code>x</code>;
</p>
</li>
<li> <p><code>ctx3bilat</code>, <code>ctx5bilat</code>: negMax = minimum, max = maximum value of <code>x</code>,
origin = mean of minimum and maximum.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>minmax(x, type = c("ctx3", "ctx5", "ctx3bilat", "ctx5bilat"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="minmax_+3A_x">x</code></td>
<td>
<p>A numeric vector to compute the context from</p>
</td></tr>
<tr><td><code id="minmax_+3A_type">type</code></td>
<td>
<p>A type of the context to be returned. Must be one of:
<code>ctx3</code>, <code>ctx5</code>, <code>ctx3bilat</code> or <code>ctx5bilat</code></p>
</td></tr>
<tr><td><code id="minmax_+3A_...">...</code></td>
<td>
<p>other parameters to be passed to the appropriate constructor
(<code><a href="#topic+ctx3">ctx3()</a></code>, <code><a href="#topic+ctx3bilat">ctx3bilat()</a></code>, <code><a href="#topic+ctx5">ctx5()</a></code>, and <code><a href="#topic+ctx5bilat">ctx5bilat()</a></code>) that is called internally.
These values overwrite the defaults computed by <code>minmax</code> &ndash; see the examples.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Other values are computed accordingly to defaults as defined in the constructors
<code><a href="#topic+ctx3">ctx3()</a></code>, <code><a href="#topic+ctx3bilat">ctx3bilat()</a></code>, <code><a href="#topic+ctx5">ctx5()</a></code>, and <code><a href="#topic+ctx5bilat">ctx5bilat()</a></code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  minmax(0:100)                # returns ctx3: 0, 50, 100
  minmax(0:100, high=80)       # returns ctx3: 0, 40, 80
  minmax(0:100, relCenter=0.4) # returns ctx3: 0, 40, 100
  minmax(0:100, type='ctx5')   # returns ctx5: 0, 25, 50, 75, 100
</code></pre>

<hr>
<h2 id='mult'>Callback-based Multiplication of Matrices</h2><span id='topic+mult'></span>

<h3>Description</h3>

<p>Perform a custom multiplication of the matrices <code>x</code> and <code>y</code> by
using the callback function <code>f</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mult(x, y, f, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mult_+3A_x">x</code></td>
<td>
<p>A first matrix. The number of columns must match with the number of
rows of the <code>y</code> matrix.</p>
</td></tr>
<tr><td><code id="mult_+3A_y">y</code></td>
<td>
<p>A second matrix. The number of rows must match with the number of
columns of the <code>x</code> matrix.</p>
</td></tr>
<tr><td><code id="mult_+3A_f">f</code></td>
<td>
<p>A function to be applied to the matrices in order to compute the
multiplication.  It must accept at least two arguments.</p>
</td></tr>
<tr><td><code id="mult_+3A_...">...</code></td>
<td>
<p>Additional arguments that are passed to the function <code>f</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a matrix <code>x</code> of size <code class="reqn">(u,v)</code> and a matrix <code>y</code> of size
<code class="reqn">(v,w)</code>, <code>mult</code> calls the function <code>f</code> <code class="reqn">uw</code>-times to
create a resulting matrix of size <code class="reqn">(u,w)</code>.  Each <code class="reqn">(i,j)</code>-th element
of the resulting matrix is obtained from a call of the function <code>f</code>
with <code>x</code>'s <code class="reqn">i</code>-th row and <code>y</code>'s <code class="reqn">j</code>-th column passed as its arguments.
</p>


<h3>Value</h3>

<p>A matrix with <code class="reqn">v</code> rows and <code class="reqn">w</code> columns, where <code class="reqn">v</code> is the
number of rows of <code>x</code> and <code class="reqn">w</code> is the number of columns of <code>y</code>.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compose">compose()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    x &lt;- matrix(runif(24, -100, 100), ncol=6)
    y &lt;- matrix(runif(18, -100, 100), nrow=6)

    mult(x, y, function(xx, yy) sum(xx * yy)) # the same as "x %*% y"

</code></pre>

<hr>
<h2 id='pbld'>Perform a Perception-based Logical Deduction (PbLD) with given rule-base on
given dataset</h2><span id='topic+pbld'></span>

<h3>Description</h3>

<p>Take a set of rules (a rule-base) and perform a Perception-based Logical
Deduction (PbLD) on each row of a given <code><a href="#topic+fsets">fsets()</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pbld(
  x,
  rules,
  partition,
  values,
  type = c("global", "local"),
  parallel = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pbld_+3A_x">x</code></td>
<td>
<p>Input to the inference. It should be an object of class
<code><a href="#topic+fsets">fsets()</a></code> (e.g. created by using the <code><a href="#topic+fcut">fcut()</a></code> or <code><a href="#topic+lcut">lcut()</a></code> functions).
It is basically a matrix with columns representing fuzzy sets.
</p>
<p>Each row represents a single case of inference. Columns should be named
after predicates in rules' antecedents.</p>
</td></tr>
<tr><td><code id="pbld_+3A_rules">rules</code></td>
<td>
<p>A rule-base (a.k.a. linguistic description) either in the form
of the <code><a href="#topic+farules">farules()</a></code> object or as a list of character vectors where
each element is a fuzzy set name (a predicate) and thus each such vector
forms a rule.</p>
</td></tr>
<tr><td><code id="pbld_+3A_partition">partition</code></td>
<td>
<p>A <code><a href="#topic+fsets">fsets()</a></code> object with columns that are
consequents in <code>rules</code>. These membership degrees must correspond to
<code>values</code>.</p>
</td></tr>
<tr><td><code id="pbld_+3A_values">values</code></td>
<td>
<p>Crisp values that correspond to rows of membership degrees in
the <code>partition</code> matrix.  Function assumes that the values are sorted in
the ascending order.</p>
</td></tr>
<tr><td><code id="pbld_+3A_type">type</code></td>
<td>
<p>The type of inference to use. It can be either <code>"local"</code> or
<code>"global"</code> (default).</p>
</td></tr>
<tr><td><code id="pbld_+3A_parallel">parallel</code></td>
<td>
<p>Whether the processing should be run in parallel or not.
Parallelization is implemented using the <code><a href="foreach.html#topic+foreach">foreach::foreach()</a></code>
package. The parallel environment must be set properly in advance, e.g. with
the <code><a href="doMC.html#topic+registerDoMC">doMC::registerDoMC()</a></code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Perform a Perception-based Logical Deduction (PbLD) with given rule-base
<code>rules</code> on each row of input <code>x</code>. Columns of <code>x</code> are truth
values of predicates that appear in the antecedent part of <code>rules</code>,
<code>partition</code> together with <code>values</code> determine the shape of
predicates in consequents: each element in <code>values</code> corresponds to a
row of membership degrees in <code>partition</code>.
</p>


<h3>Value</h3>

<p>A vector of inferred defuzzified values. The number of resulting
values corresponds to the number of rows of the <code>x</code> argument.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>References</h3>

<p>A. Dvořák, M. Štěpnička, On perception-based logical deduction
and its variants, in: Proc. 16th World Congress of the International Fuzzy
Systems Association and 9th Conference of the European Society for Fuzzy
Logic and Technology (IFSA-EUSFLAT 2015), Advances in Intelligent Systems
Research, Atlantic Press, Gijon, 2015.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lcut">lcut()</a></code>, <code><a href="#topic+searchrules">searchrules()</a></code>, <code><a href="#topic+fire">fire()</a></code>, <code><a href="#topic+aggregateConsequents">aggregateConsequents()</a></code>, <code><a href="#topic+defuzz">defuzz()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# --- TRAINING PART ---
# custom context of the RHS variable
uptakeContext &lt;- ctx3(7, 28.3, 46)

# convert data into fuzzy sets
d &lt;- lcut(CO2, context=list(uptake=uptakeContext))

# split data into the training and testing set
testingIndices &lt;- 1:5
trainingIndices &lt;- setdiff(seq_len(nrow(CO2)), testingIndices)
training &lt;- d[trainingIndices, ]
testing &lt;- d[testingIndices, ]

# search for rules
r &lt;- searchrules(training, lhs=1:38, rhs=39:58, minConfidence=0.5)

# --- TESTING PART ---
# prepare values and partition
v &lt;- seq(uptakeContext[1], uptakeContext[3], length.out=1000)
p &lt;- lcut(v, name='uptake', context=uptakeContext)

# do the inference
pbld(testing, r, p, v)

</code></pre>

<hr>
<h2 id='perceive'>From a set of rules, remove each rule for which another rule exists that is
more specific.</h2><span id='topic+perceive'></span>

<h3>Description</h3>

<p>Examine rules in a list and remove all of them for whose other more specific
rules are present in the list. The specificity is determined by calling the
<code><a href="#topic+is.specific">is.specific()</a></code> function.  This operation is a part of the
<code><a href="#topic+pbld">pbld()</a></code> inference mechanism.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>perceive(
  rules,
  fsets,
  type = c("global", "local"),
  fired = NULL,
  vars = NULL,
  specs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="perceive_+3A_rules">rules</code></td>
<td>
<p>A list of character vectors where each element is a fuzzy set
name (a predicate) and thus each such vector forms a rule.</p>
</td></tr>
<tr><td><code id="perceive_+3A_fsets">fsets</code></td>
<td>
<p>A valid instance of the <code><a href="#topic+fsets">fsets()</a></code> class such that all predicates
in <code>rules</code> (i.e., all values of all character vectors in <code>rules$rules</code>)
can be found in <code>colnames(fsets)</code></p>
</td></tr>
<tr><td><code id="perceive_+3A_type">type</code></td>
<td>
<p>The type of perception to use. It can be either <code>"local"</code>
or <code>"global"</code> (default).</p>
</td></tr>
<tr><td><code id="perceive_+3A_fired">fired</code></td>
<td>
<p>If <code>type=="global"</code> then this argument can be NULL. If
<code>type</code> is <code>"local"</code> then <code>fired</code> must be a numeric vector of
values in the interval <code class="reqn">[0,1]</code> indicating the truth values of all rules,
i.e. the length of the vector must be equal to the number of rules in the
<code>rules</code> argument.</p>
</td></tr>
<tr><td><code id="perceive_+3A_vars">vars</code></td>
<td>
<p>A deprecated parameter that must be <code>NULL</code>. Formerly, it was
a named (typically character) vector that determined which
predicates originate from the same variable, i.e. which of them semantically
deal with the same property.  For that purpose, each value from any vector
stored in the <code>rules</code> list must be present in <code>names(vars)</code>.  See
also <code><a href="#topic+vars">vars()</a></code> function of the <code><a href="#topic+fsets">fsets()</a></code> class.</p>
</td></tr>
<tr><td><code id="perceive_+3A_specs">specs</code></td>
<td>
<p>A deprecated parameter that must be <code>NULL</code>. Formerly, it was
a square numeric matrix containing values from <code class="reqn">\{0, 1\}</code>.
It is a specificity matrix for which each row and column corresponds to an
<code>rules</code>'es predicate <code>specs[i][j] = 1</code> if and only if the
<code class="reqn">i</code>-th predicate is more specific (i.e. the corresponding fuzzy set is a
subset of) than the <code class="reqn">j</code>-th predicate (i.e. <code>x[, j]</code>).  See also
<code><a href="#topic+specs">specs()</a></code> function of the <code><a href="#topic+fsets">fsets()</a></code> class.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In other words, for each rule <code>x</code> in the <code>rules</code> list, it searches for another
rule <code>y</code> such that <code>is.specific(y, x)</code> returns TRUE. If yes then
<code>x</code> is removed from the list.
</p>


<h3>Value</h3>

<p>A modified list of rules for which no other more specific rule
exists. (Each rule is a vector.)
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.specific">is.specific()</a></code>, <code><a href="#topic+fsets">fsets()</a></code>, <code><a href="#topic+fcut">fcut()</a></code>, <code><a href="#topic+lcut">lcut()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># prepare fsets
f &lt;- lcut(data.frame(a=0:1, b=0:1, c=0:1, d=0:1))

# run perceive function: (sm.a, bi.c) has
# more specific rule (ve.sm.a, bi.c)
perceive(list(c('sm.a', 'bi.c'),
              c('ve.sm.a', 'bi.c'),
              c('sm.b', 'sm.d')),
         f)

</code></pre>

<hr>
<h2 id='plot.fsets'>Plot membership degrees stored in the instance of the S3 class
<code><a href="#topic+fsets">fsets()</a></code> as a line diagram.</h2><span id='topic+plot.fsets'></span>

<h3>Description</h3>

<p>This function plots the membership degrees stored in the instance of the
<code><a href="#topic+fsets">fsets()</a></code> class. Internally, the membership degrees are
transformed into a time-series object and viewed in a plot using the
<code><a href="stats.html#topic+ts.plot">ts.plot()</a></code> function. This function is useful mainly to see the
shape of fuzzy sets on regularly sampled inputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fsets'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.fsets_+3A_x">x</code></td>
<td>
<p>An instance of class <code><a href="#topic+fsets">fsets()</a></code></p>
</td></tr>
<tr><td><code id="plot.fsets_+3A_...">...</code></td>
<td>
<p>Other arguments that are passed to the underlying <code><a href="stats.html#topic+ts.plot">ts.plot()</a></code>
function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Result of the <code><a href="stats.html#topic+ts.plot">ts.plot()</a></code> method.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fsets">fsets()</a></code>, <code><a href="#topic+fcut">fcut()</a></code>, <code><a href="#topic+lcut">lcut()</a></code>, <code><a href="stats.html#topic+ts.plot">ts.plot()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d &lt;- lcut(0:1000/1000, name='x')
plot(d)

# Additional arguments are passed to the ts.plot method
# Here thick lines represent atomic linguistic expressions,
# i.e. ``small'', ``medium'', and ``big''.
plot(d,
     ylab='membership degree',
     xlab='values',
     gpars=list(lwd=c(rep(1, 3), 5, rep(1, 5), 5, rep(1, 7), 5, rep(1,4))))
</code></pre>

<hr>
<h2 id='print.algebra'>Print an instance of the <code><a href="#topic+algebra">algebra()</a></code> S3 class in a human readable form.</h2><span id='topic+print.algebra'></span>

<h3>Description</h3>

<p>Print an instance of the <code><a href="#topic+algebra">algebra()</a></code> S3 class in a human readable form.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'algebra'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.algebra_+3A_x">x</code></td>
<td>
<p>An instance of the <code><a href="#topic+algebra">algebra()</a></code> S3 class</p>
</td></tr>
<tr><td><code id="print.algebra_+3A_...">...</code></td>
<td>
<p>Unused.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+algebra">algebra()</a></code>
</p>

<hr>
<h2 id='print.ctx3'>Print the linguistic context</h2><span id='topic+print.ctx3'></span><span id='topic+print.ctx5'></span><span id='topic+print.ctx3bilat'></span><span id='topic+print.ctx5bilat'></span>

<h3>Description</h3>

<p>Format an object of the <code><a href="#topic+ctx3">ctx3()</a></code>, <code><a href="#topic+ctx5">ctx5()</a></code>, <code><a href="#topic+ctx3bilat">ctx3bilat()</a></code> and the <code><a href="#topic+ctx5bilat">ctx5bilat()</a></code>
class into human readable form and print it to the output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ctx3'
print(x, ...)

## S3 method for class 'ctx5'
print(x, ...)

## S3 method for class 'ctx3bilat'
print(x, ...)

## S3 method for class 'ctx5bilat'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.ctx3_+3A_x">x</code></td>
<td>
<p>A linguistic context to be printed</p>
</td></tr>
<tr><td><code id="print.ctx3_+3A_...">...</code></td>
<td>
<p>Unused.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nothing.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ctx3">ctx3()</a></code>, <code><a href="#topic+ctx5">ctx5()</a></code>, <code><a href="#topic+ctx3bilat">ctx3bilat()</a></code>, <code><a href="#topic+ctx5bilat">ctx5bilat()</a></code>, <code><a href="#topic+minmax">minmax()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  context &lt;- ctx3()
  print(context)

</code></pre>

<hr>
<h2 id='print.farules'>Print an instance of the <code><a href="#topic+farules">farules()</a></code> S3 class in a human readable form.</h2><span id='topic+print.farules'></span>

<h3>Description</h3>

<p>Print an instance of the <code><a href="#topic+farules">farules()</a></code> S3 class in a human readable form.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'farules'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.farules_+3A_x">x</code></td>
<td>
<p>An instance of the <code><a href="#topic+farules">farules()</a></code> S3 class</p>
</td></tr>
<tr><td><code id="print.farules_+3A_...">...</code></td>
<td>
<p>Unused.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+farules">farules()</a></code>, <code><a href="#topic+searchrules">searchrules()</a></code>
</p>

<hr>
<h2 id='print.frbe'>Print an instance of the <code><a href="#topic+frbe">frbe()</a></code> class</h2><span id='topic+print.frbe'></span>

<h3>Description</h3>

<p>Format an object of the <code><a href="#topic+frbe">frbe()</a></code> class into human readable form
and print it to the output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'frbe'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.frbe_+3A_x">x</code></td>
<td>
<p>An instance of <code><a href="#topic+frbe">frbe()</a></code> class</p>
</td></tr>
<tr><td><code id="print.frbe_+3A_...">...</code></td>
<td>
<p>Unused.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Format an object of the <code><a href="#topic+frbe">frbe()</a></code> class into human readable form
and print it to the output.
</p>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>References</h3>

<p>Štěpnička, M., Burda, M., Štěpničková, L. Fuzzy Rule Base
Ensemble Generated from Data by Linguistic Associations Mining. FUZZY SET
SYST. 2015.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+frbe">frbe()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  # prepare data (from the forecast package)
  library(forecast)
  horizon &lt;- 10
  train &lt;- wineind[-1 * (length(wineind)-horizon+1):length(wineind)]
  test &lt;- wineind[(length(wineind)-horizon+1):length(wineind)]
  f &lt;- frbe(ts(train, frequency=frequency(wineind)), h=horizon)
  print(f)
  print(test)

</code></pre>

<hr>
<h2 id='print.fsets'>Print an instance of the <code><a href="#topic+fsets">fsets()</a></code> class</h2><span id='topic+print.fsets'></span>

<h3>Description</h3>

<p>Format an object of the <code><a href="#topic+fsets">fsets()</a></code> class into human readable form
and print it to the output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fsets'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.fsets_+3A_x">x</code></td>
<td>
<p>An instance of the <code><a href="#topic+fsets">fsets()</a></code> class</p>
</td></tr>
<tr><td><code id="print.fsets_+3A_...">...</code></td>
<td>
<p>Unused.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nothing
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fsets">fsets()</a></code>, <code><a href="#topic+fcut">fcut()</a></code>, <code><a href="#topic+lcut">lcut()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    d &lt;- fcut(CO2[, 1:2])
    print(d)

</code></pre>

<hr>
<h2 id='quantifier'>A quantifier is a function that computes a fuzzy truth value of a claim about
the quantity. This function creates the &lt;1&gt;-type quantifier. (See the examples
below on how to use it as a quantifier of the &lt;1,1&gt; type.)</h2><span id='topic+quantifier'></span>

<h3>Description</h3>

<p>A quantifier is a function that computes a fuzzy truth value of a claim about
the quantity. This function creates the &lt;1&gt;-type quantifier. (See the examples
below on how to use it as a quantifier of the &lt;1,1&gt; type.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quantifier(
  quantity = c("all", "almost.all", "most", "many", "few", "several", "some", "at.least"),
  n = NULL,
  alg = c("lukasiewicz", "goedel", "goguen")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="quantifier_+3A_quantity">quantity</code></td>
<td>
<p>the quantity to be evaluated. 'all' computes the degree of
truth to which all elements of the universe have the given property,
'almost.all', #'   'most', and 'many' evaluate whether the property is
present in extremely big, very big, or not small number of elements from
the universe, where these linguistic expressions are internally modeled
using the <code><a href="#topic+lingexpr">lingexpr()</a></code> function. 'at.least' quantity requires the 'n'
argument to be specified, as it computes the truth value that at least
<code class="reqn">n</code> elements from the universe have the given property.</p>
</td></tr>
<tr><td><code id="quantifier_+3A_n">n</code></td>
<td>
<p>the number of elements in the 'at.least n' quantifier</p>
</td></tr>
<tr><td><code id="quantifier_+3A_alg">alg</code></td>
<td>
<p>the underlying algebra in which to compute the quantifier.
Note that the algebra must have properly defined the <code>order</code> function,
as in the case of 'goedel', 'goguen', or 'lukasiewicz' algebra, (see the
<code><a href="#topic+algebra">algebra()</a></code> function) or as in the <code><a href="#topic+dragonfly">dragonfly()</a></code> or <code><a href="#topic+lowerEst">lowerEst()</a></code> algebra.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A two-argument function, which expects two numeric vectors of equal length
(the vector elements are recycled to ensure equal lengths). The first argument, <code>x</code>,
is a vector of membership degrees to be measured, the second argument, <code>w</code>, is
the vector of weights to which the element belongs to the universe.
</p>
<p>Let <code class="reqn">U</code> be the set of input vector indices (1 to <code>length(x)</code>). Then the quantifier
computes the truth values accordingly to the following formula:
<code class="reqn">\vee_{z \subseteq U} \wedge_{u \in z} (x[u]) \wedge measure(m_z)</code>,
where
<code class="reqn">m_z = sum(w)</code> for <code>"some"</code> and <code style="white-space: pre;">&#8288;"at.least&#8288;</code> and <code class="reqn">m_z = sum(w[z]) / sum(w)</code> otherwise.
See <code><a href="#topic+sugeno">sugeno()</a></code> for more details on how the quantifier is evaluated.
</p>
<p>Setting <code>w</code> to 1 yields to operation of the &lt;1&gt; quantifier as developed by Dvořák et al.
To compute the &lt;1,1&gt; quantifier as developed by Dvořák et al., e.g. &quot;almost all A are B&quot;, <code>w</code> must
be set again to 1 and <code>x</code> to the result of the implication <code class="reqn">A \Rightarrow B</code>.
To compute the &lt;1,1&gt; quantifier as proposed by Murinová et al., e.g. &quot;almost all A are B&quot;,
<code>x</code> must be set to the result of the implication <code class="reqn">A \Rightarrow B</code> and <code>w</code> to the membership
degrees of <code class="reqn">A</code>. See the examples below.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>References</h3>

<p>Dvořák, A., Holčapek, M. L-fuzzy quantifiers of type &lt;1&gt; determined by fuzzy measures.
Fuzzy Sets and Systems vol.160, issue 23, 3425-3452, 2009.
</p>
<p>Dvořák, A., Holčapek, M. Type &lt;1,1&gt; fuzzy quantifiers determined by fuzzy measures.
IEEE International Conference on Fuzzy Systems (FuzzIEEE), 2010.
</p>
<p>Murinová, P., Novák, V. The theory of intermediate quantifiers in fuzzy natural logic
revisited and the model of &quot;Many&quot;. Fuzzy Sets and Systems, vol 388, 2020.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sugeno">sugeno()</a></code>, <code><a href="#topic+lingexpr">lingexpr()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # Dvorak &lt;1&gt; "almost all" quantifier
  q &lt;- quantifier('almost.all')
  a &lt;- c(0.9, 1, 1, 0.2, 1)
  q(x=a, w=1)

  # Dvorak &lt;1,1&gt; "almost all" quantifier (w set to 1)
  a &lt;- c(0.9, 1, 1, 0.2, 1)
  b &lt;- c(0.2, 1, 0, 0.5, 0.8)
  q &lt;- quantifier('almost.all')
  q(x=lukas.residuum(a, b), w=1)

  # Murinová &lt;1,1&gt; "almost all" quantifier (note w set to a)
  a &lt;- c(0.9, 1, 1, 0.2, 1)
  b &lt;- c(0.2, 1, 0, 0.5, 0.8)
  q &lt;- quantifier('almost.all')
  q(x=lukas.residuum(a, b), w=a)

  # Murinová &lt;1,1&gt; "some" quantifier
  a &lt;- c(0.9, 1, 1, 0.2, 1)
  b &lt;- c(0.2, 1, 0, 0.5, 0.8)
  q &lt;- quantifier('some')
  q(x=plukas.tnorm(a, b), w=a)
</code></pre>

<hr>
<h2 id='rbcoverage'>Compute rule base coverage of data</h2><span id='topic+rbcoverage'></span>

<h3>Description</h3>

<p>This function computes rule base coverage, i.e. a an average of maximum
membership degree at which each row of data fires the rules in rule base.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rbcoverage(
  x,
  rules,
  tnorm = c("goedel", "goguen", "lukasiewicz"),
  onlyAnte = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rbcoverage_+3A_x">x</code></td>
<td>
<p>Data for the rules to be evaluated on. Could be either a numeric
matrix or numeric vector.  If matrix is given then the rules are evaluated
on rows. Each value of the vector or column of the matrix represents a
predicate - it's numeric value represents the truth values (values in the
interval <code class="reqn">[0, 1]</code>).</p>
</td></tr>
<tr><td><code id="rbcoverage_+3A_rules">rules</code></td>
<td>
<p>Either an object of class &quot;farules&quot; or list of character
vectors where each vector is a rule with consequent being the first element
of the vector. Elements of the vectors (predicate names) must correspond to
the <code>x</code>'s names (of columns if <code>x</code> is a matrix).</p>
</td></tr>
<tr><td><code id="rbcoverage_+3A_tnorm">tnorm</code></td>
<td>
<p>A character string representing a triangular norm to be used
(either <code>"goedel"</code>, <code>"goguen"</code>, or <code>"lukasiewicz"</code>) or an
arbitrary function that takes a vector of truth values and returns a t-norm
computed of them.</p>
</td></tr>
<tr><td><code id="rbcoverage_+3A_onlyante">onlyAnte</code></td>
<td>
<p>TRUE if only antecedent-part of a rule should be evaluated.
Antecedent-part of a rule are all predicates in rule vector starting from
the 2nd position. (First element of a rule is the consequent - see above.)
</p>
<p>If FALSE, then the whole rule will be evaluated (antecedent part together
with consequent).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">f_{ij}</code> be a truth value of <code class="reqn">i</code>-th rule on <code class="reqn">j</code>-th row of
data <code>x</code>.  Then <code class="reqn">m_j = max(f_{.j})</code> is a maximum truth value that
is reached for the <code class="reqn">j</code>-th data row with the rule base. Then the rule
base coverage is a mean of that truth values, i.e.  <code class="reqn">rbcoverage =
mean(m_.)</code>.
</p>


<h3>Value</h3>

<p>A numeric value of the rule base coverage of given data.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>References</h3>

<p>M. Burda, M. Štěpnička, Reduction of Fuzzy Rule Bases Driven by
the Coverage of Training Data, in: Proc. 16th World Congress of the
International Fuzzy Systems Association and 9th Conference of the European
Society for Fuzzy Logic and Technology (IFSA-EUSFLAT 2015), Advances in
Intelligent Systems Research, Atlantic Press, Gijon, 2015.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fire">fire()</a></code>, <code><a href="#topic+reduce">reduce()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
    x &lt;- matrix(1:20 / 20, nrow=2)
    colnames(x) &lt;- letters[1:10]

    rules &lt;- list(c('a', 'c', 'e'),
                  c('b'),
                  c('d', 'a'),
                  c('c', 'a', 'b'))
    rbcoverage(x, rules, "goguen", TRUE)  # returns 1


    rules &lt;- list(c('d', 'a'),
                  c('c', 'a', 'b'))
    rbcoverage(x, rules, "goguen", TRUE)  # returns 0.075)

</code></pre>

<hr>
<h2 id='reduce'>Reduce the size of rule base</h2><span id='topic+reduce'></span>

<h3>Description</h3>

<p>From given rule base, select such set of rules that influence mostly the
rule base coverage of the input data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reduce(
  x,
  rules,
  ratio,
  tnorm = c("goedel", "goguen", "lukasiewicz"),
  tconorm = c("goedel", "goguen", "lukasiewicz"),
  numThreads = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="reduce_+3A_x">x</code></td>
<td>
<p>Data for the rules to be evaluated on. Could be either a numeric
matrix or numeric vector.  If matrix is given then the rules are evaluated
on rows. Each value of the vector or column of the matrix represents a
predicate - it's numeric value represents the truth values (values in the
interval <code class="reqn">[0, 1]</code>).</p>
</td></tr>
<tr><td><code id="reduce_+3A_rules">rules</code></td>
<td>
<p>Either an object of class &quot;farules&quot; or list of character
vectors where each vector is a rule with consequent being the first element
of the vector. Elements of the vectors (predicate names) must correspond to
the <code>x</code>'s names (of columns if <code>x</code> is a matrix).</p>
</td></tr>
<tr><td><code id="reduce_+3A_ratio">ratio</code></td>
<td>
<p>A percentage of rule base coverage that must be preserved. It
must be a value within the <code class="reqn">[0, 1]</code> interval. Value of 1 means that the
rule base coverage of the result must be the same as coverage of input
<code>rules</code>. A sensible value is e.g. 0.9.</p>
</td></tr>
<tr><td><code id="reduce_+3A_tnorm">tnorm</code></td>
<td>
<p>Which t-norm to use as a conjunction of antecedents. The
default is <code>"goedel"</code>.</p>
</td></tr>
<tr><td><code id="reduce_+3A_tconorm">tconorm</code></td>
<td>
<p>Which t-norm to use as a disjunction, i.e. to combine
multiple antecedents to get coverage of the rule base. The default is
<code>"goedel"</code>.</p>
</td></tr>
<tr><td><code id="reduce_+3A_numthreads">numThreads</code></td>
<td>
<p>How many threads to use for computation. Value higher than
1 causes that the algorithm runs in several parallel threads (using the
OpenMP library).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>From a given rulebase, a rule with greatest coverage is selected. After
that, additional rules are selected that increase the rule base coverage the
most. Addition stops after the coverage exceeds <code class="reqn">original coverage *
ratio</code>.
</p>
<p>Note that the size of the resulting rule base is not necessarily minimal
because the algorithm does not search all possible combination of rules. It
only finds a local minimum of rule base size.
</p>


<h3>Value</h3>

<p>Function returns an instance of class <code><a href="#topic+farules">farules()</a></code> or a
list depending on the type of the <code>rules</code> argument.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>References</h3>

<p>M. Burda, M. Štěpnička, Reduction of Fuzzy Rule Bases Driven by
the Coverage of Training Data, in: Proc. 16th World Congress of the
International Fuzzy Systems Association and 9th Conference of the European
Society for Fuzzy Logic and Technology (IFSA-EUSFLAT 2015), Advances in
Intelligent Systems Research, Atlantic Press, Gijon, 2015.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rbcoverage">rbcoverage()</a></code>, <code><a href="#topic+farules">farules()</a></code>
</p>

<hr>
<h2 id='rmse'>Compute Root Mean Squared Error (RMSE)</h2><span id='topic+rmse'></span>

<h3>Description</h3>

<p>RMSE is computed as <code class="reqn">sqrt(mean((forecast - validation)^2))</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmse(forecast, validation)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rmse_+3A_forecast">forecast</code></td>
<td>
<p>A numeric vector of forecasted values</p>
</td></tr>
<tr><td><code id="rmse_+3A_validation">validation</code></td>
<td>
<p>A numeric vector of actual (real) values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Root Mean Squared Error (RMSE)
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+smape">smape()</a></code>, <code><a href="#topic+mase">mase()</a></code>, <code><a href="#topic+frbe">frbe()</a></code>
</p>

<hr>
<h2 id='searchrules'>Searching for fuzzy association rules</h2><span id='topic+searchrules'></span>

<h3>Description</h3>

<p>This function searches the given <code><a href="#topic+fsets">fsets()</a></code> object <code>d</code> for all
fuzzy association rules that satisfy defined constraints. It returns a list
of fuzzy association rules together with some statistics characterizing them
(such as support, confidence etc.).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>searchrules(
  d,
  lhs = 2:ncol(d),
  rhs = 1,
  tnorm = c("goedel", "goguen", "lukasiewicz"),
  n = 100,
  best = c("confidence"),
  minSupport = 0.02,
  minConfidence = 0.75,
  maxConfidence = 1,
  maxLength = 4,
  numThreads = 1,
  trie = (maxConfidence &lt; 1)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="searchrules_+3A_d">d</code></td>
<td>
<p>An object of class <code><a href="#topic+fsets">fsets()</a></code> - it is basically a matrix
where columns represent the fuzzy sets and values are the membership
degrees. For creation of such object, use <code><a href="#topic+fcut">fcut()</a></code> or <code><a href="#topic+lcut">lcut()</a></code> function.</p>
</td></tr>
<tr><td><code id="searchrules_+3A_lhs">lhs</code></td>
<td>
<p>Indices of fuzzy attributes that may appear on the left-hand-side
(LHS) of association rules, i.e. in the antecedent.</p>
</td></tr>
<tr><td><code id="searchrules_+3A_rhs">rhs</code></td>
<td>
<p>Indices of fuzzy attributes that may appear on the
right-hand-side (RHS) of association rules, i.e. in the consequent.</p>
</td></tr>
<tr><td><code id="searchrules_+3A_tnorm">tnorm</code></td>
<td>
<p>A t-norm to be used for computation of conjunction of fuzzy
attributes. (Allowed are even only starting letters of &quot;lukasiewicz&quot;,
&quot;goedel&quot; and &quot;goguen&quot;).</p>
</td></tr>
<tr><td><code id="searchrules_+3A_n">n</code></td>
<td>
<p>The non-negative number of rules to be found. If zero, the function
returns all rules satisfying the given conditions. If positive, only
<code>n</code> best rules are returned. The criterium of what is &ldquo;best&rdquo; is
specified with the <code>best</code> argument.</p>
</td></tr>
<tr><td><code id="searchrules_+3A_best">best</code></td>
<td>
<p>Specifies measure accordingly to which the rules are ordered
from best to worst. This argument is used mainly in combination with the
<code>n</code> argument. Currently, only single value (&quot;confidence&quot;) can be used.</p>
</td></tr>
<tr><td><code id="searchrules_+3A_minsupport">minSupport</code></td>
<td>
<p>The minimum support degree of a rule. Rules with support
below that number are filtered out. It must be a numeric value from interval
<code class="reqn">[0, 1]</code>. See below for details on how the support degree is computed.</p>
</td></tr>
<tr><td><code id="searchrules_+3A_minconfidence">minConfidence</code></td>
<td>
<p>The minimum confidence degree of a rule. Rules with
confidence below that number are filtered out.  It must be a numeric value
from interval <code class="reqn">[0, 1]</code>. See below for details on how the confidence degree is
computed.</p>
</td></tr>
<tr><td><code id="searchrules_+3A_maxconfidence">maxConfidence</code></td>
<td>
<p>Maximum confidence threshold. After finding a rule that
has confidence degree above the <code>maxConfidence</code> threshold, no other
rule is resulted based on adding some additional attribute to its antecedent
part. I.e. if &quot;Sm.age &amp; Me.age =&gt; Sm.height&quot; has confidence above
<code>maxConfidence</code> threshold, no another rule containing &quot;Sm.age &amp; Me.age&quot;
will be produced regardless of its interest measures.
</p>
<p>If you want to disable this feature, set <code>maxConfidence</code> to 1.</p>
</td></tr>
<tr><td><code id="searchrules_+3A_maxlength">maxLength</code></td>
<td>
<p>Maximum allowed length of the rule, i.e. maximum
number of predicates that are allowed on the left-hand + right-hand side of the rule. If
negative, the maximum length of rules is unlimited.</p>
</td></tr>
<tr><td><code id="searchrules_+3A_numthreads">numThreads</code></td>
<td>
<p>Number of threads used to perform the algorithm in
parallel. If greater than 1, the OpenMP library (not to be confused with
Open MPI) is used for parallelization.  Please note that there are known
problems of using OpenMP together with another means of parallelization that
may be used within R. Therefore, if you plan to use the <code>searchrules</code>
function with some of the external parallelization mechanisms such as
library <code>doMC</code>, make sure that <code>numThreads</code> equals 1.  This
feature is available only on systems that have installed the OpenMP library.</p>
</td></tr>
<tr><td><code id="searchrules_+3A_trie">trie</code></td>
<td>
<p>Whether or not to use internal mechanism of Tries. If FALSE,
then in the output may appear such rule that is a descendant of a rule that
has confidence above <code>maxConfidence</code> threshold.
</p>
<p>Tries consume very much memory, so if you encounter problems with
insufficient memory, set this argument to FALSE. On the other hand, the size
of result (if <code>n</code> is set to 0) can be very high if trie is set to
FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function searches data frame <code>d</code> for fuzzy association rules that
satisfy conditions specified by the parameters.
</p>


<h3>Value</h3>

<p>A list of the following elements: <code>rules</code> and <code>statistics</code>.
</p>
<p><code>rules</code> is a list of mined fuzzy association rules. Each element of
that list is a character vector with consequent attribute being on the first
position.
</p>
<p><code>statistics</code> is a data frame of statistical characteristics about mined
rules. Each row corresponds to a rule in the <code>rules</code> list. Let us
consider a rule &quot;a &amp; b =&gt; c&quot;, let <code class="reqn">\otimes</code> be a t-norm specified with
the <code>tnorm</code> parameter and <code class="reqn">i</code> goes over all rows of a data table
<code>d</code>. Then columns of the <code>statistics</code> data frame are as follows:
</p>

<ul>
<li><p> support: a rule's support degree: <code class="reqn">1/nrow(d) * \sum_{\forall i} a(i) \otimes b(i) \otimes c(i)</code>
</p>
</li>
<li><p> lhsSupport: a support of rule's antecedent (LHS): <code class="reqn">1/nrow(d) * \sum_{\forall i} a(i) \otimes b(i)</code>
</p>
</li>
<li><p> rhsSupport: a support of rule's consequent (RHS): <code class="reqn">1/nrow(d) * \sum_{\forall i} c(i)</code>
</p>
</li>
<li><p> confidence: a rule's confidence degree: <code class="reqn">support / lhsSupport</code>
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fcut">fcut()</a></code>, <code><a href="#topic+lcut">lcut()</a></code>, <code><a href="#topic+farules">farules()</a></code>, <code><a href="#topic+fsets">fsets()</a></code>, <code><a href="#topic+pbld">pbld()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  d &lt;- lcut(CO2)
  searchrules(d, lhs=1:ncol(d), rhs=1:ncol(d))

</code></pre>

<hr>
<h2 id='slices'>Return vector of values from given interval</h2><span id='topic+slices'></span>

<h3>Description</h3>

<p>Returns an ordered vector of values from given interval, of given size,
generated by equal steps.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>slices(from, to, n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="slices_+3A_from">from</code></td>
<td>
<p>The lower bound of the interval.</p>
</td></tr>
<tr><td><code id="slices_+3A_to">to</code></td>
<td>
<p>The upper bound of the interval.</p>
</td></tr>
<tr><td><code id="slices_+3A_n">n</code></td>
<td>
<p>The length of the vector to be produced.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns a vector of values from <code>from</code> to <code>to</code> (inclusive), with
equal difference between two consecutive values, with total length <code>n</code>.
Function is useful e.g. together with the <code><a href="#topic+pbld">pbld</a></code> or
<code><a href="#topic+defuzz">defuzz</a></code> functions (for the <code>values</code> argument; see also
<code><a href="#topic+lcut">lcut</a></code> or <code><a href="#topic+fcut">fcut</a></code>) or <code><a href="#topic+defuzz">defuzz</a></code>).
</p>


<h3>Value</h3>

<p>A vector of numbers in the given interval and size.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pbld">pbld</a></code>, <code><a href="#topic+defuzz">defuzz</a></code>, <code><a href="#topic+fcut">fcut</a></code>,
<code><a href="#topic+lcut">lcut</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
    slices(1, 5, 10) # 1, 1.5, 2, 2.5, 3, 3.5 4, 4.5, 5

## End(Not run)
# is the same as
seq(1, 5, length.out=10)


</code></pre>

<hr>
<h2 id='smape'>Compute Symmetric Mean Absolute Percentage Error (SMAPE)</h2><span id='topic+smape'></span>

<h3>Description</h3>

<p>SMAPE is computed as <code class="reqn">mean(abs(forecast - validation) / ((abs(forecast) + abs(validation)) / 2))</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smape(forecast, validation)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="smape_+3A_forecast">forecast</code></td>
<td>
<p>A numeric vector of forecasted values</p>
</td></tr>
<tr><td><code id="smape_+3A_validation">validation</code></td>
<td>
<p>A numeric vector of actual (real) values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Symmetric Mean Absolute Percentage Error (SMAPE)
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rmse">rmse()</a></code>, <code><a href="#topic+mase">mase()</a></code>, <code><a href="#topic+frbe">frbe()</a></code>
</p>

<hr>
<h2 id='sobocinski'>Modify algebra's way of computing with <code>NA</code> values.</h2><span id='topic+sobocinski'></span><span id='topic+algebraNA'></span><span id='topic+kleene'></span><span id='topic+dragonfly'></span><span id='topic+nelson'></span><span id='topic+lowerEst'></span>

<h3>Description</h3>

<p>By default, the objects created with the <code><a href="#topic+algebra">algebra()</a></code> function represent a mathematical
algebra capable to work on the <code class="reqn">[0,1]</code> interval. If <code>NA</code> appears as a value instead,
it is propagated to the result. That is, any operation with <code>NA</code> results in <code>NA</code>, by default.
This scheme of handling missing values is also known as Bochvar's. To change this default
behavior, the following functions may be applied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sobocinski(algebra)

kleene(algebra)

dragonfly(algebra)

nelson(algebra)

lowerEst(algebra)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sobocinski_+3A_algebra">algebra</code></td>
<td>
<p>the underlying algebra object to be modified &ndash; see the <code><a href="#topic+algebra">algebra()</a></code> function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>sobocinski()</code>, <code>kleene()</code>, <code>nelson()</code>, <code>lowerEst()</code> and <code>dragonfly()</code> functions modify the algebra to
handle the <code>NA</code> in a different way than is the default. Sobocinski's algebra simply ignores <code>NA</code> values
whereas Kleene's algebra treats <code>NA</code> as &quot;unknown value&quot;. Dragonfly approach is a combination
of Sobocinski's and Bochvar's approach, which preserves the ordering <code style="white-space: pre;">&#8288;0 &lt;= NA &lt;= 1&#8288;</code>
to obtain from compositions (see <code><a href="#topic+compose">compose()</a></code>)
the lower-estimate in the presence of missing values.
</p>
<p>In detail, the behavior of the algebra modifiers is defined as follows:
</p>
<p>Sobocinski's negation for <code>n</code> being the underlying algebra:
</p>

<table>
<tr>
 <td style="text-align: left;">
a  </td><td style="text-align: left;"> n(a)</td>
</tr>
<tr>
 <td style="text-align: left;">
NA </td><td style="text-align: left;"> 0
</td>
</tr>

</table>

<p>Sobocinski's operation for <code>op</code> being one of <code>t</code>, <code>pt</code>, <code>c</code>, <code>pc</code>, <code>i</code>, <code>pi</code>, <code>s</code>, <code>ps</code>
from the underlying algebra:
</p>

<table>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> b        </td><td style="text-align: left;"> NA</td>
</tr>
<tr>
 <td style="text-align: left;">
a  </td><td style="text-align: left;"> op(a, b) </td><td style="text-align: left;"> a </td>
</tr>
<tr>
 <td style="text-align: left;">
NA </td><td style="text-align: left;"> b        </td><td style="text-align: left;"> NA
</td>
</tr>

</table>

<p>Sobocinski's operation for <code>r</code> from the underlying algebra:
</p>

<table>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> b       </td><td style="text-align: left;"> NA  </td>
</tr>
<tr>
 <td style="text-align: left;">
a  </td><td style="text-align: left;"> r(a, b) </td><td style="text-align: left;"> n(a)</td>
</tr>
<tr>
 <td style="text-align: left;">
NA </td><td style="text-align: left;"> b       </td><td style="text-align: left;"> NA
</td>
</tr>

</table>

<p>Kleene's negation is identical to <code>n</code> from the underlying algebra.
</p>
<p>Kleene's operation for <code>op</code> being one of <code>t</code>, <code>pt</code>, <code>i</code>, <code>pi</code> from the underlying algebra:
</p>

<table>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> b        </td><td style="text-align: left;"> NA </td><td style="text-align: left;"> 0</td>
</tr>
<tr>
 <td style="text-align: left;">
a  </td><td style="text-align: left;"> op(a, b) </td><td style="text-align: left;"> NA </td><td style="text-align: left;"> 0</td>
</tr>
<tr>
 <td style="text-align: left;">
NA </td><td style="text-align: left;"> NA       </td><td style="text-align: left;"> NA </td><td style="text-align: left;"> 0</td>
</tr>
<tr>
 <td style="text-align: left;">
0  </td><td style="text-align: left;"> 0        </td><td style="text-align: left;"> 0  </td><td style="text-align: left;"> 0
</td>
</tr>

</table>

<p>Kleene's operation for <code>op</code> being one of <code>c</code>, <code>pc</code>, <code>s</code>, <code>ps</code> from the underlying algebra:
</p>

<table>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> b        </td><td style="text-align: left;"> NA </td><td style="text-align: left;"> 1</td>
</tr>
<tr>
 <td style="text-align: left;">
a  </td><td style="text-align: left;"> op(a, b) </td><td style="text-align: left;"> NA </td><td style="text-align: left;"> 1</td>
</tr>
<tr>
 <td style="text-align: left;">
NA </td><td style="text-align: left;"> NA       </td><td style="text-align: left;"> NA </td><td style="text-align: left;"> 1</td>
</tr>
<tr>
 <td style="text-align: left;">
1  </td><td style="text-align: left;"> 1        </td><td style="text-align: left;"> 1  </td><td style="text-align: left;"> 1
</td>
</tr>

</table>

<p>Kleene's operation for <code>r</code> from the underlying algebra:
</p>

<table>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> b        </td><td style="text-align: left;"> NA </td><td style="text-align: left;"> 1</td>
</tr>
<tr>
 <td style="text-align: left;">
a  </td><td style="text-align: left;"> r(a, b)  </td><td style="text-align: left;"> NA </td><td style="text-align: left;"> 1</td>
</tr>
<tr>
 <td style="text-align: left;">
NA </td><td style="text-align: left;"> NA       </td><td style="text-align: left;"> NA </td><td style="text-align: left;"> 1</td>
</tr>
<tr>
 <td style="text-align: left;">
0  </td><td style="text-align: left;"> 1        </td><td style="text-align: left;"> 1  </td><td style="text-align: left;"> 1
</td>
</tr>

</table>

<p>Dragonfly negation is identical to <code>n</code> from the underlying algebra.
</p>
<p>Dragonfly operation for <code>op</code> being one of <code>t</code>, <code>pt</code>, <code>i</code>, <code>pi</code> from the underlying algebra:
</p>

<table>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> b        </td><td style="text-align: left;"> NA </td><td style="text-align: left;"> 0 </td><td style="text-align: left;"> 1</td>
</tr>
<tr>
 <td style="text-align: left;">
a  </td><td style="text-align: left;"> op(a, b) </td><td style="text-align: left;"> NA </td><td style="text-align: left;"> 0 </td><td style="text-align: left;"> a</td>
</tr>
<tr>
 <td style="text-align: left;">
NA </td><td style="text-align: left;"> NA       </td><td style="text-align: left;"> NA </td><td style="text-align: left;"> 0 </td><td style="text-align: left;"> NA</td>
</tr>
<tr>
 <td style="text-align: left;">
0  </td><td style="text-align: left;"> 0        </td><td style="text-align: left;"> 0  </td><td style="text-align: left;"> 0 </td><td style="text-align: left;"> 0</td>
</tr>
<tr>
 <td style="text-align: left;">
1  </td><td style="text-align: left;"> b        </td><td style="text-align: left;"> NA </td><td style="text-align: left;"> 0 </td><td style="text-align: left;"> 1
</td>
</tr>

</table>

<p>Dragonfly operation for <code>op</code> being one of <code>c</code>, <code>pc</code>, <code>s</code>, <code>ps</code> from the underlying algebra:
</p>

<table>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> b        </td><td style="text-align: left;"> NA </td><td style="text-align: left;"> 0  </td><td style="text-align: left;"> 1</td>
</tr>
<tr>
 <td style="text-align: left;">
a  </td><td style="text-align: left;"> op(a, b) </td><td style="text-align: left;"> a  </td><td style="text-align: left;"> a  </td><td style="text-align: left;"> 1</td>
</tr>
<tr>
 <td style="text-align: left;">
NA </td><td style="text-align: left;"> b        </td><td style="text-align: left;"> NA </td><td style="text-align: left;"> NA </td><td style="text-align: left;"> 1</td>
</tr>
<tr>
 <td style="text-align: left;">
0  </td><td style="text-align: left;"> b        </td><td style="text-align: left;"> NA </td><td style="text-align: left;"> 0  </td><td style="text-align: left;"> 1</td>
</tr>
<tr>
 <td style="text-align: left;">
1  </td><td style="text-align: left;"> 1        </td><td style="text-align: left;"> 1  </td><td style="text-align: left;"> 1  </td><td style="text-align: left;"> 1
</td>
</tr>

</table>

<p>Dragonfly operation for <code>r</code> from the underlying algebra:
</p>

<table>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> b       </td><td style="text-align: left;"> NA </td><td style="text-align: left;"> 0    </td><td style="text-align: left;"> 1</td>
</tr>
<tr>
 <td style="text-align: left;">
a  </td><td style="text-align: left;"> r(a, b) </td><td style="text-align: left;"> NA </td><td style="text-align: left;"> n(a) </td><td style="text-align: left;"> 1</td>
</tr>
<tr>
 <td style="text-align: left;">
NA </td><td style="text-align: left;"> b       </td><td style="text-align: left;"> 1  </td><td style="text-align: left;"> NA   </td><td style="text-align: left;"> 1</td>
</tr>
<tr>
 <td style="text-align: left;">
0  </td><td style="text-align: left;"> 1       </td><td style="text-align: left;"> 1  </td><td style="text-align: left;"> 1    </td><td style="text-align: left;"> 1</td>
</tr>
<tr>
 <td style="text-align: left;">
1  </td><td style="text-align: left;"> b       </td><td style="text-align: left;"> NA </td><td style="text-align: left;"> 0    </td><td style="text-align: left;"> 1
</td>
</tr>

</table>



<h3>Value</h3>

<p>A list of function of the same structure as is the list returned from the <code><a href="#topic+algebra">algebra()</a></code> function
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- algebra('lukas')
b &lt;- sobocinski(a)

a$t(0.3, NA)  # NA
b$t(0.3, NA)  # 0.3

</code></pre>

<hr>
<h2 id='sugeno'>A factory function for creation of sugeno-integrals.</h2><span id='topic+sugeno'></span>

<h3>Description</h3>

<p>A factory function for creation of sugeno-integrals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sugeno(
  measure,
  relative = TRUE,
  strong = FALSE,
  alg = c("lukasiewicz", "goedel", "goguen")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sugeno_+3A_measure">measure</code></td>
<td>
<p>A non-decreasing function that assigns a truth value from the
<code class="reqn">[0, 1]</code> interval to the either relative or absolute quantity</p>
</td></tr>
<tr><td><code id="sugeno_+3A_relative">relative</code></td>
<td>
<p>Whether the measure assumes relative or absolute quantity.
Relative quantity is always a number from the <code class="reqn">[0,1]</code> interval</p>
</td></tr>
<tr><td><code id="sugeno_+3A_strong">strong</code></td>
<td>
<p>Whether to use the strong conjunction (<code>TRUE</code>) or the weak
conjunction (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="sugeno_+3A_alg">alg</code></td>
<td>
<p>The underlying algebra must be either a string (one from 'lukasiewicz',
'goedel' or 'goguen') or an instance of the S3 class <code><a href="#topic+algebra">algebra()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A two-argument function, which expects two numeric vectors of equal length
(the vector elements are recycled to ensure equal lengths). The first argument, <code>x</code>,
is a vector of membership degrees to be measured, the second argument, <code>w</code>, is
the vector of weights.
</p>
<p>Let <code class="reqn">U</code> be the set of input vector indices (1 to <code>length(x)</code>). Then the sugeno integral
computes the truth values accordingly to the following formula:
<code class="reqn">\vee_{z \subseteq U} \wedge_{u \in z} (x[u]) CONJ measure(m_z)</code>,
where
<code class="reqn">m_z = sum(w[z]) / sum(w)</code> if <code>relative==TRUE</code> or <code class="reqn">m_z = sum(w)</code> if <code>relative==FALSE</code>
and where CONJ is a strong conjunction (i.e. <code>alg$pt</code>) or a weak conjunction
(i.e. <code>alg$pi</code>) accordingly to the <code>strong</code> parameter.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+quantifier">quantifier()</a></code>, <code><a href="#topic+lingexpr">lingexpr()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # Dvorak &lt;1&gt; "almost all" quantifier
  q &lt;- sugeno(lingexpr(ctx3(), atomic='bi', hedge='ex'))
  a &lt;- c(0.9, 1, 1, 0.2, 1)
  q(x=a, w=1)

  # Dvorak &lt;1,1&gt; "almost all" quantifier
  a &lt;- c(0.9, 1, 1, 0.2, 1)
  b &lt;- c(0.2, 1, 0, 0.5, 0.8)
  q &lt;- sugeno(lingexpr(ctx3(), atomic='bi', hedge='ex'))
  q(x=lukas.residuum(a, b), w=1)

  # Murinová &lt;1,1&gt; "almost all" quantifier
  a &lt;- c(0.9, 1, 1, 0.2, 1)
  b &lt;- c(0.2, 1, 0, 0.5, 0.8)
  q &lt;- sugeno(lingexpr(ctx3(), atomic='bi', hedge='ex'))
  q(x=lukas.residuum(a, b), w=a)
</code></pre>

<hr>
<h2 id='triangle'>Deprecated functions to compute membership degrees of numeric fuzzy sets</h2><span id='topic+triangle'></span><span id='topic+raisedcos'></span>

<h3>Description</h3>

<p>These functions compute membership degrees of numeric fuzzy sets with
triangular or raised-cosine shape. These functions are <em>deprecated</em>.
Please use <code><a href="#topic+triangular">triangular()</a></code> or <code><a href="#topic+raisedcosine">raisedcosine()</a></code> functions instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>triangle(x, lo, center, hi)

raisedcos(x, lo, center, hi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="triangle_+3A_x">x</code></td>
<td>
<p>A numeric vector to be transformed.</p>
</td></tr>
<tr><td><code id="triangle_+3A_lo">lo</code></td>
<td>
<p>A lower bound (can be -Inf).</p>
</td></tr>
<tr><td><code id="triangle_+3A_center">center</code></td>
<td>
<p>A peak value.</p>
</td></tr>
<tr><td><code id="triangle_+3A_hi">hi</code></td>
<td>
<p>An upper bound (can be Inf).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of membership degrees of <code>x</code> to a fuzzy set with the shape
determined with <code>lo</code>, <code>center</code>, <code>hi</code>.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+triangular">triangular()</a></code>, <code><a href="#topic+raisedcosine">raisedcosine()</a></code>
</p>

<hr>
<h2 id='triangular'>Factories for functions that convert numeric data into membership degrees of fuzzy sets</h2><span id='topic+triangular'></span><span id='topic+raisedcosine'></span>

<h3>Description</h3>

<p>These functions create functions with a single argument <code>x</code> that compute membership degrees of <code>x</code> to a fuzzy set
of either triangular or raised-cosine shape that is defined by <code>lo</code>, <code>center</code>, and <code>hi</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>triangular(lo, center, hi)

raisedcosine(lo, center, hi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="triangular_+3A_lo">lo</code></td>
<td>
<p>A lower bound (can be -Inf).</p>
</td></tr>
<tr><td><code id="triangular_+3A_center">center</code></td>
<td>
<p>A peak value.</p>
</td></tr>
<tr><td><code id="triangular_+3A_hi">hi</code></td>
<td>
<p>An upper bound (can be Inf).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The arguments must satisfy <code style="white-space: pre;">&#8288;lo &lt;= center &lt;= hi&#8288;</code>. Functions compute membership degrees of triangular or
raised-cosine fuzzy sets. <code>x</code> values equal to <code style="white-space: pre;">&#8288;center obtain membership degree equal to 1, &#8288;</code>x<code style="white-space: pre;">&#8288;values lower than&#8288;</code>lo<code style="white-space: pre;">&#8288;or greater than&#8288;</code>hi<code style="white-space: pre;">&#8288;obtain membership degree equal to 0. A transition of the triangular (resp. raised cosine) shape (with peak at&#8288;</code>center<code style="white-space: pre;">&#8288;is computed for&#8288;</code>x<code style="white-space: pre;">&#8288;values between&#8288;</code>lo<code>and</code>hi'.
</p>
<p>If <code>lo == -Inf</code> then any value that is lower or equal to center gets membership degree 1.  Similarly, if <code>hi == Inf</code>
then any value that is greater or equal to center gets membership degree 1. <code>NA</code> and <code>NaN</code> values remain unchanged.
</p>
<p><code>triangular()</code> produces fuzzy sets of a triangular shape (with peak at <code>center</code>), <code>raisedcosine()</code> produces
fuzzy sets defined as a raised cosine hill.
</p>


<h3>Value</h3>

<p>A function with single argument <code>x</code> that should be a numeric vector to be converted.
</p>


<h3>Author(s)</h3>

<p>Michal Burda
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fcut">fcut()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
tr &lt;- triangular(1, 2, 3)
tr(1:30 / 3)

rc &lt;- raisedcosine(1, 2, 3)
rc(1:30 / 3)

plot(triangular(-1, 0, 1), from=-2, to=3)
plot(triangular(-1, 0, 2), from=-2, to=3)
plot(triangular(-Inf, 0, 1), from=-2, to=3)
plot(triangular(-1, 0, Inf), from=-2, to=3)

plot(raisedcosine(-1, 0, 1), from=-2, to=3)
plot(raisedcosine(-1, 0, 2), from=-2, to=3)
plot(raisedcosine(-Inf, 0, 1), from=-2, to=3)
plot(raisedcosine(-1, 0, Inf), from=-2, to=3)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
