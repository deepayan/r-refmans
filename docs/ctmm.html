<!DOCTYPE html><html lang="en"><head><title>Help for package ctmm</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ctmm}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ctmm-package'><p>Continuous-time movement modeling</p></a></li>
<li><a href='#akde'><p>Calculate an autocorrelated kernel density estimate</p></a></li>
<li><a href='#as.telemetry'><p>Import, coerce, summarize, and combine MoveBank data</p></a></li>
<li><a href='#bandwidth'><p>Calculate the optimal bandwidth matrix of movement data</p></a></li>
<li><a href='#buffalo'><p>African buffalo GPS dataset from Kruger National Park, South Africa.</p></a></li>
<li><a href='#cluster'><p>Clustering of movement-model parameters</p></a></li>
<li><a href='#coati'><p>Coatis on Barro Colorado Island, Panama.</p></a></li>
<li><a href='#color'><p>Color telemetry objects by time</p></a></li>
<li><a href='#ctmm'><p>Specify, fit, and select continuous-time movement models</p></a></li>
<li><a href='#ctmm-FAQ'><p>ctmm FAQ</p></a></li>
<li><a href='#ctmm.boot'><p>Parametric bootstrap continuous-time movement models</p></a></li>
<li><a href='#difference'><p>Estimate the proximity of two individuals</p></a></li>
<li><a href='#distance'><p>Calculate the square distance between two distributions or location estimates</p></a></li>
<li><a href='#dt.plot'><p>Functions for diagnosing sampling schedules</p></a></li>
<li><a href='#emulate'><p>Draw a random model-fit from the sampling distribution</p></a></li>
<li><a href='#encounter'><p>Encounter statistics</p></a></li>
<li><a href='#export'><p>Export ctmm data formats</p></a></li>
<li><a href='#extent'><p>Extent</p></a></li>
<li><a href='#format'><p>Scientific formatting of numbers</p></a></li>
<li><a href='#gazelle'><p>Mongolian gazelle GPS dataset from the Mongolia's Eastern Steppe.</p></a></li>
<li><a href='#homerange'><p>Calculate a range distribution estimate</p></a></li>
<li><a href='#intensity'><p>Compare empirical and theoretical intensity (resource-selection) functions [IN DEVELOPMENT]</p></a></li>
<li><a href='#jaguar'><p>Jaguar data from the Jaguar movement database.</p></a></li>
<li><a href='#Log'><p>Log transformation of parameter estimates and their uncertainties</p></a></li>
<li><a href='#mean.ctmm'><p>Average movement models and autocorrelated kernel density estimates</p></a></li>
<li><a href='#mean.variogram'><p>Compute a number-weighted average of variogram objects</p></a></li>
<li><a href='#meta'><p>Meta-analysis of movement-model parameters</p></a></li>
<li><a href='#npr'><p>Calculate a non-parametric regression surface</p></a></li>
<li><a href='#occurrence'><p>Calculate a Kriged occurrence distribution estimate</p></a></li>
<li><a href='#optimizer'><p>Minimize a function</p></a></li>
<li><a href='#outlie'><p>Methods to facilitate outlier detection.</p></a></li>
<li><a href='#overlap'><p>Calculate the overlap between two stationary distributions</p></a></li>
<li><a href='#pelican'><p>Brown Pelican GPS and ARGOS data.</p></a></li>
<li><a href='#periodogram'><p>Calculate the Lomb-Scargle periodogram of animal-tracking data</p></a></li>
<li><a href='#plot.telemetry'><p>Plotting methods for telemetry objects</p></a></li>
<li><a href='#plot.variogram'><p>Plotting methods for variogram objects.</p></a></li>
<li><a href='#projection'><p>Projection</p></a></li>
<li><a href='#residuals.ctmm'><p>Calculate model fit residuals and assess their autocorrelation</p></a></li>
<li><a href='#revisitation'><p>Calculate an revisitation distribution estimate</p></a></li>
<li><a href='#rsf.fit'><p>Fit integrated resource selection functions (iRSFs) with autocorrelation-adjusted weighted likelihood</p></a></li>
<li><a href='#sdm.fit'><p>Fit species distribution models (SDMs) [IN DEVELOPMENT]</p></a></li>
<li><a href='#select'><p>Spatial selection methods for telemetry objects.</p></a></li>
<li><a href='#simulate.ctmm'><p>Predict or simulate from a continuous-time movement model</p></a></li>
<li><a href='#speed'><p>Estimate the average speed of a tracked animal</p></a></li>
<li><a href='#summary.ctmm'><p>Summarize a continuous-time movement model</p></a></li>
<li><a href='#summary.UD'><p>Summarize a range distribution</p></a></li>
<li><a href='#turtle'><p>Wood turtle GPS and calibration dataset from Working Land and Seascapes.</p></a></li>
<li><a href='#uere'><p>Estimate RMS UERE from calibration data</p></a></li>
<li><a href='#Unit+20conversion'><p>Convert dimensionful quantities to and from SI units</p></a></li>
<li><a href='#variogram'><p>Calculate an empirical variogram from movement data</p></a></li>
<li><a href='#variogram.fit'><p>Visually fit a movement model to a variogram</p></a></li>
<li><a href='#video'><p>Video record animated telemetry objects.</p></a></li>
<li><a href='#wolf'><p>Maned wolf GPS dataset from The Maned Wolf Conservation Program.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-09-22</td>
</tr>
<tr>
<td>Title:</td>
<td>Continuous-Time Movement Modeling</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/ctmm-initiative/ctmm">https://github.com/ctmm-initiative/ctmm</a>,
<a href="https://groups.google.com/g/ctmm-user">https://groups.google.com/g/ctmm-user</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Bessel, data.table, digest, expm, fasttime, Gmedian, graphics,
grDevices, gsl, manipulate, MASS, methods, numDeriv, parsedate,
pbivnorm, pracma, raster, shape, sf, sp, statmod, stats, terra,
utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>animation, bit64, dplyr, fftw, knitr, move, parallel,
quadprog, rmarkdown, suncalc</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions for identifying, fitting, and applying continuous-space, continuous-time stochastic-process movement models to animal tracking data.
  The package is described in Calabrese et al (2016) &lt;<a href="https://doi.org/10.1111%2F2041-210X.12559">doi:10.1111/2041-210X.12559</a>&gt;, with models and methods based on those introduced and detailed in
  Fleming &amp; Calabrese et al (2014) &lt;<a href="https://doi.org/10.1086%2F675504">doi:10.1086/675504</a>&gt;,
  Fleming et al (2014) &lt;<a href="https://doi.org/10.1111%2F2041-210X.12176">doi:10.1111/2041-210X.12176</a>&gt;,
  Fleming et al (2015) &lt;<a href="https://doi.org/10.1103%2FPhysRevE.91.032107">doi:10.1103/PhysRevE.91.032107</a>&gt;,
  Fleming et al (2015) &lt;<a href="https://doi.org/10.1890%2F14-2010.1">doi:10.1890/14-2010.1</a>&gt;,
  Fleming et al (2016) &lt;<a href="https://doi.org/10.1890%2F15-1607">doi:10.1890/15-1607</a>&gt;,
  Péron &amp; Fleming et al (2016) &lt;<a href="https://doi.org/10.1186%2Fs40462-016-0084-7">doi:10.1186/s40462-016-0084-7</a>&gt;,
  Fleming &amp; Calabrese (2017) &lt;<a href="https://doi.org/10.1111%2F2041-210X.12673">doi:10.1111/2041-210X.12673</a>&gt;,
  Péron et al (2017) &lt;<a href="https://doi.org/10.1002%2Fecm.1260">doi:10.1002/ecm.1260</a>&gt;,
  Fleming et al (2017) &lt;<a href="https://doi.org/10.1016%2Fj.ecoinf.2017.04.008">doi:10.1016/j.ecoinf.2017.04.008</a>&gt;,
  Fleming et al (2018) &lt;<a href="https://doi.org/10.1002%2Feap.1704">doi:10.1002/eap.1704</a>&gt;,
  Winner &amp; Noonan et al (2018) &lt;<a href="https://doi.org/10.1111%2F2041-210X.13027">doi:10.1111/2041-210X.13027</a>&gt;,
  Fleming et al (2019) &lt;<a href="https://doi.org/10.1111%2F2041-210X.13270">doi:10.1111/2041-210X.13270</a>&gt;,
  Noonan &amp; Fleming et al (2019) &lt;<a href="https://doi.org/10.1186%2Fs40462-019-0177-1">doi:10.1186/s40462-019-0177-1</a>&gt;,
  Fleming et al (2020) &lt;<a href="https://doi.org/10.1101%2F2020.06.12.130195">doi:10.1101/2020.06.12.130195</a>&gt;,
  Noonan et al (2021) &lt;<a href="https://doi.org/10.1111%2F2041-210X.13597">doi:10.1111/2041-210X.13597</a>&gt;,
  Fleming et al (2022) &lt;<a href="https://doi.org/10.1111%2F2041-210X.13815">doi:10.1111/2041-210X.13815</a>&gt;,
  Silva et al (2022) &lt;<a href="https://doi.org/10.1111%2F2041-210X.13786">doi:10.1111/2041-210X.13786</a>&gt;,
  Alston &amp; Fleming et al (2023) &lt;<a href="https://doi.org/10.1111%2F2041-210X.14025">doi:10.1111/2041-210X.14025</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-09-23 01:56:04 UTC; root</td>
</tr>
<tr>
<td>Author:</td>
<td>Christen H. Fleming [aut, cre],
  Justin M. Calabrese [aut],
  Xianghui Dong [ctb],
  Kevin Winner [ctb],
  Björn Reineking [ctb],
  Guillaume Péron [ctb],
  Michael J. Noonan [ctb],
  Bart Kranstauber [ctb],
  Chad J. Wilhite [ctb],
  Eliezer Gurarie [ctb],
  Kamran Safi [ctb],
  Paul C. Cross [dtc],
  Thomas Mueller [dtc],
  Rogério C. de Paula [dtc],
  Thomas Akre [dtc],
  Jonathan Drescher-Lehman [dtc],
  Autumn-Lynn Harrison [dtc],
  Ronaldo G. Morato [dtc]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Christen H. Fleming &lt;flemingc@si.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-09-23 23:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ctmm-package'>Continuous-time movement modeling</h2><span id='topic+ctmm-package'></span>

<h3>Description</h3>

<p>Functions for identifying, fitting, and applying continuous-space, continuous-time stochastic-process movement models to animal tracking data.
The package is described in Calabrese &amp; Fleming (2016) &lt;doi:10.1111/2041-210X.12559&gt; and its models and methods are based on those introduced and detailed in
Fleming &amp; Calabrese et al (2014) &lt;doi:10.1086/675504&gt;,
Fleming et al (2014) &lt;doi:10.1111/2041-210X.12176&gt;,
Fleming et al (2015) &lt;doi:10.1103/PhysRevE.91.032107&gt;,
Fleming et al (2015) &lt;doi:10.1890/14-2010.1&gt;,
Fleming et al (2016) &lt;doi:10.1890/15-1607&gt;,
Péron &amp; Fleming et al (2016) &lt;doi:10.1186/s40462-016-0084-7&gt;,
Fleming &amp; Calabrese (2017) &lt;doi:10.1111/2041-210X.12673&gt;,
Péron et al (2017) &lt;doi:10.1002/ecm.1260&gt;,
Fleming et al (2017) &lt;doi:10.1016/j.ecoinf.2017.04.008&gt;,
Fleming et al (2018) &lt;doi:10.1002/eap.1704&gt;,
Winner &amp; Noonan et al (2018) &lt;doi:10.1111/2041-210X.13027&gt;,
Fleming et al (2019) &lt;doi:10.1111/2041-210X.13270&gt;,
Noonan &amp; Fleming et al (2019) &lt;doi:10.1186/s40462-019-0177-1&gt;,
Fleming et al (2020) &lt;doi:10.1101/2020.06.12.130195&gt;,
Noonan et al (2021) &lt;doi:10.1111/2041-210X.13597&gt;,
Fleming et al (2022) &lt;doi:10.1111/2041-210X.13815&gt;,
Silva et al (2022) &lt;doi:10.1111/2041-210X.13786&gt;,
and
Alston &amp; Fleming et al (2023) &lt;doi:10.1111/2041-210X.14025&gt;.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> ctmm</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.2.0 </td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2023-09-22</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-3 </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<ul>
<li> <p><a href="https://biology.umd.edu/movement">CTMM Initiative</a> 
</p>
</li>
<li> <p><a href="https://movementoflife.si.edu/analytical-tools/">Movement of Life</a> 
</p>
</li>
<li> <p><a href="https://CRAN.R-project.org/package=ctmm">CRAN package</a> 
</p>
</li>
<li> <p><a href="https://github.com/ctmm-initiative/ctmm">Github project</a> 
</p>
</li>
<li> <p><a href="http://www2.physics.umd.edu/~hfleming/">Source packages</a> 
</p>
</li>
<li> <p><a href="https://ctmm-initiative.github.io/ctmm/">Github reference</a> 
</p>
</li>
<li> <p><a href="https://groups.google.com/g/ctmm-user">Google group</a> 
</p>
</li>
<li> <p><a href="#topic+ctmm-FAQ">ctmm-FAQ</a> 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Christen H. Fleming and Justin M. Calabrese
</p>
<p>Maintainer: Christen H. Fleming &lt;flemingc@si.edu&gt;
</p>


<h3>References</h3>

<p>C. H. Fleming, J. M. Calabrese, T. Mueller, K. A. Olson, P. Leimgruber, W. F. Fagan,
&ldquo;From fine-scale foraging to home ranges: A semi-variance approach to identifying movement modes across spatiotemporal scales&rdquo;,
The American Naturalist 183:5 E154-E167 (2014) <a href="https://doi.org/10.1086/675504">doi:10.1086/675504</a>.
</p>
<p>C. H. Fleming, J. M. Calabrese, T. Mueller, K. A. Olson, P. Leimgruber, W. F. Fagan,
&ldquo;Non-Markovian maximum likelihood estimation of autocorrelated movement processes&rdquo;,
Methods in Ecology and Evolution 5:5 462-472 (2014) <a href="https://doi.org/10.1111/2041-210X.12176">doi:10.1111/2041-210X.12176</a>.
</p>
<p>C. H. Fleming, Y. Subaşı, J. M. Calabrese,
&ldquo;A maximum-entropy description of animal movement&rdquo;,
Physical Review E 91 032107 (2015) <a href="https://doi.org/10.1103/PhysRevE.91.032107">doi:10.1103/PhysRevE.91.032107</a>.
</p>
<p>C. H. Fleming, W. F. Fagan, T. Mueller, K. A. Olson, P. Leimgruber, J. M. Calabrese,
&ldquo;Rigorous home-range estimation with movement data: A new autocorrelated kernel-density estimator&rdquo;,
Ecology 96:5 1182-1188 (2015) <a href="https://doi.org/10.1890/14-2010.1">doi:10.1890/14-2010.1</a>.
</p>
<p>J. M. Calabrese, C. H. Fleming, E. Gurarie,
&ldquo;ctmm: an R package for analyzing animal relocation data as a continuous-time stochastic process&rdquo;,
Methods in Ecology and Evolution 7:9 1124-1132 (2016) <a href="https://doi.org/10.1111/2041-210X.12559">doi:10.1111/2041-210X.12559</a>.
</p>
<p>C. H. Fleming, W. F. Fagan, T. Mueller, K. A. Olson, P. Leimgruber, J. M. Calabrese,
&ldquo;Estimating where and how animals travel: An optimal framework for path reconstruction from autocorrelated tracking data&rdquo;,
Ecology 97:3 576-582 (2016) <a href="https://doi.org/10.1890/15-1607.1">doi:10.1890/15-1607.1</a>.
</p>
<p>G. Péron, C. H. Fleming,  R. C. de Paula, J. M. Calabrese,
&ldquo;Uncovering periodic patterns of space use in animal tracking data with periodograms, including a new algorithm for the Lomb-Scargle periodogram and improved randomization tests&rdquo;,
Movement Ecology 4:19 (2016) <a href="https://doi.org/10.1186/s40462-016-0084-7">doi:10.1186/s40462-016-0084-7</a>.
</p>
<p>C. H. Fleming, J. M. Calabrese,
&ldquo;A new kernel-density estimator for accurate home-range and species-range area estimation&rdquo;,
Methods in Ecology and Evolution 8:5 571-579 (2017) <a href="https://doi.org/10.1111/2041-210X.12673">doi:10.1111/2041-210X.12673</a>.
</p>
<p>G. Péron, C. H. Fleming, R. C. de Paula, N. Mitchell, M. Strohbach, P. Leimgruber, J. M. Calabrese,
&ldquo;Periodic continuous-time movement models uncover behavioral changes of wild canids along anthropization gradients&rdquo;,
Ecological Monographs 87:3 442-456 (2017) <a href="https://doi.org/10.1002/ecm.1260">doi:10.1002/ecm.1260</a>
</p>
<p>C. H. Fleming, D. Sheldon, E. Gurarie, W. F. Fagan, S. LaPoint, J. M. Calabrese,
&ldquo;Kálmán filters for continuous-time movement models&rdquo;,
Ecological Informatics 40 8-21 (2017) <a href="https://doi.org/10.1016/j.ecoinf.2017.04.008">doi:10.1016/j.ecoinf.2017.04.008</a>.
</p>
<p>C. H. Fleming, D. Sheldon, W. F. Fagan, P. Leimgruber, T. Mueller, D. Nandintsetseg, M. J. Noonan, K. A. Olson, E. Setyawan, A. Sianipar, J. M. Calabrese,
&ldquo;Correcting for missing and irregular data in home-range estimation&rdquo;,
Ecological Applications 28:4 1003-1010 (2018) <a href="https://doi.org/10.1002/eap.1704">doi:10.1002/eap.1704</a>.
</p>
<p>K. Winner, M. J. Noonan, C. H. Fleming, K. Olson, T. Mueller, D. Sheldon, J. M. Calabrese.
&ldquo;Statistical inference for home range overlap&rdquo;,
Methods in Ecology and Evolution 9:7 1679-1691 (2018) <a href="https://doi.org/10.1111/2041-210X.13027">doi:10.1111/2041-210X.13027</a>.
</p>
<p>C. H. Fleming, M. J. Noonan, E. P. Medici, J. M. Calabrese,
&ldquo;Overcoming the challenge of small effective sample sizes in home-range estimation&rdquo;,
Methods in Ecology and Evolution 10:10 1679-1689 (2019) <a href="https://doi.org/10.1111/2041-210X.13270">doi:10.1111/2041-210X.13270</a>.
</p>
<p>M. J. Noonan, C. H. Fleming, T. S. Akre, J. Drescher-Lehman, E. Gurarie, A.-L. Harrison, R. Kays, Justin Calabrese,
&ldquo;Scale-insensitive estimation of speed and distance traveled from animal tracking data&rdquo;,
Movement Ecology 7:35 (2019) <a href="https://doi.org/10.1186/s40462-019-0177-1">doi:10.1186/s40462-019-0177-1</a>.
</p>
<p>C. H. Fleming et al, &ldquo;A comprehensive framework for handling location error in animal tracking data&rdquo;, bioRxiv (2020) <a href="https://doi.org/10.1101/2020.06.12.130195">doi:10.1101/2020.06.12.130195</a>.
</p>
<p>M. J. Noonan R. Martinez-Garcia, G. H. Davis, M. C. Crofoot, R. Kays, B. T. Hirsch, D. Caillaud, E. Payne, A. Sihm, D. L. Sinn, O. Spiegel, W. F. Fagan, C. H. Fleming, J. M. Calabrese, &ldquo;Estimating encounter location distributions from animal tracking data&rdquo;, Methods in Ecology and Evolution 12:7 1158-1173 (2021) <a href="https://doi.org/10.1111/2041-210X.13597">doi:10.1111/2041-210X.13597</a>.
</p>
<p>C. H. Fleming, I. Deznabi, S. Alavi, M. C. Crofoot, B. T. Hirsch, E. P. Medici, M. J. Noonan, R. Kays, W. F. Fagan, D. Sheldon, J. M. Calabrese,
&ldquo;Population-level inference for home-range areas&rdquo;,
Methods in Ecology and Evolution 13:5 1027-1041 (2022) <a href="https://doi.org/10.1111/2041-210X.13815">doi:10.1111/2041-210X.13815</a>.
</p>
<p>I. Silva, C. H. Fleming, M. J. Noonan, J. Alston, C. Folta, W. F. Fagan, J. M. Calabrese. &ldquo;Autocorrelation-informed home range estimation: A review and practical guide&rdquo;, Methods in Ecology and Evolution 13:3 534-544 (2022) <a href="https://doi.org/10.1111/2041-210X.13786">doi:10.1111/2041-210X.13786</a>.
</p>

<hr>
<h2 id='akde'>Calculate an autocorrelated kernel density estimate</h2><span id='topic+akde'></span><span id='topic+akde.telemetry'></span><span id='topic+akde.list'></span><span id='topic+pkde'></span>

<h3>Description</h3>

<p>These functions calculate individual and population-level autocorrelated kernel density home-range estimates from <code>telemetry</code> data and a corresponding continuous-time movement models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>akde(data,CTMM,VMM=NULL,R=list(),SP=NULL,SP.in=TRUE,variable="utilization",debias=TRUE,
     weights=FALSE,smooth=TRUE,error=0.001,res=10,grid=NULL,...)

pkde(data,UD,kernel="individual",weights=FALSE,ref="Gaussian",...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="akde_+3A_data">data</code></td>
<td>
<p> 2D timeseries telemetry data represented as a <code>telemetry</code> object or list of objects. </p>
</td></tr>
<tr><td><code id="akde_+3A_ctmm">CTMM</code></td>
<td>
<p>A <code>ctmm</code> movement model from the output of <code>ctmm.fit</code> or list of objects.</p>
</td></tr>
<tr><td><code id="akde_+3A_vmm">VMM</code></td>
<td>
<p>An optional vertical <code>ctmm</code> object for 3D home-range calculation.</p>
</td></tr>
<tr><td><code id="akde_+3A_r">R</code></td>
<td>
<p>A named list of raster covariates if <code>CTMM</code> contains an RSF model.</p>
</td></tr>
<tr><td><code id="akde_+3A_sp">SP</code></td>
<td>
<p>SpatialPolygonsDataFrame object for enforcing hard boundaries.</p>
</td></tr>
<tr><td><code id="akde_+3A_sp.in">SP.in</code></td>
<td>
<p>Locations are assumed to be inside the <code>SP</code> polygons if <code>SP.in=TRUE</code> and outside of <code>SP</code> if <code>SP.in=FALSE</code>.</p>
</td></tr>
<tr><td><code id="akde_+3A_variable">variable</code></td>
<td>
<p>Not yet supported.</p>
</td></tr>
<tr><td><code id="akde_+3A_debias">debias</code></td>
<td>
<p>Debias the distribution for area estimation (AKDEc).</p>
</td></tr>
<tr><td><code id="akde_+3A_smooth">smooth</code></td>
<td>
<p>&quot;Smooth&quot; out errors from the data.</p>
</td></tr>
<tr><td><code id="akde_+3A_weights">weights</code></td>
<td>
<p>Optimally weight the data to account for sampling bias (See <code><a href="#topic+bandwidth">bandwidth</a></code> for <code>akde</code> details).</p>
</td></tr>
<tr><td><code id="akde_+3A_error">error</code></td>
<td>
<p>Target probability error.</p>
</td></tr>
<tr><td><code id="akde_+3A_res">res</code></td>
<td>
<p>Number of grid points along each axis, relative to the bandwidth.</p>
</td></tr>
<tr><td><code id="akde_+3A_grid">grid</code></td>
<td>
<p>Optional grid specification via <code>raster</code>, <code>UD</code>, or list of arguments (See &lsquo;Details&rsquo; below).</p>
</td></tr>
<tr><td><code id="akde_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code>akde</code>, <code><a href="#topic+bandwidth">bandwidth</a></code>, and <code><a href="#topic+mean.ctmm">mean.ctmm</a></code>.</p>
</td></tr>
<tr><td><code id="akde_+3A_ud">UD</code></td>
<td>
<p>A list of individual <code>UD</code> objects corresponding to <code>data</code>.</p>
</td></tr>
<tr><td><code id="akde_+3A_kernel">kernel</code></td>
<td>
<p>Bandwidths are proportional to the individual covariances if <code>kernel="individual"</code> or to the population covariance if <code>kernel="population"</code>.</p>
</td></tr>
<tr><td><code id="akde_+3A_ref">ref</code></td>
<td>
<p>Include non-Gaussian overlap corrections if <code>ref="AKDE"</code> and <code>weights=TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For weighted AKDE, please note additional <code>...</code> arguments passed to <code><a href="#topic+bandwidth">bandwidth</a></code>, which can have a large impact on computation time in certain cases.
</p>
<p>When feeding in lists of <code>telemetry</code> and <code>ctmm</code> objects, all UDs will be calculated on the same grid. These UDs can be averaged with the <code><a href="#topic+mean.UD">mean.UD</a></code> command.
</p>
<p>If a <code>UD</code> or <code>raster</code> object is supplied in the <code>grid</code> argument, then the estimate will be calculated on the same grid. Alternatively, a list of grid arguments can be supplied, with any of the following components:
</p>

<dl>
<dt><code>r</code></dt><dd><p>A list with vectors <code>x</code> and <code>y</code> that define the grid-cell midpoints.</p>
</dd>
<dt><code>dr</code></dt><dd><p>A vector setting the <code>x</code> and <code>y</code> cell widths in meters. Equivalent to <code>res</code> for <code>raster</code> objects.</p>
</dd>
<dt><code>extent</code></dt><dd><p>The <code class="reqn">x</code>-<code class="reqn">y</code> extent of the grid cells, formatted as from the output of <code><a href="#topic+extent">extent</a></code>.</p>
</dd>
<dt><code>align.to.origin</code></dt><dd><p>Logical value indicating that cell midpoint locations are aligned to be an integer number of <code>dr</code> steps from the projection origin.</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns a <code>UD</code> object: a list with the sampled grid line locations <code>r$x</code> and <code>r$y</code>, the extent of each grid cell <code>dr</code>, the probability density and cumulative distribution functions evaluated on the sampled grid locations <code>PDF</code> &amp; <code>CDF</code>, the optimal bandwidth matrix <code>H</code>, and the effective sample size of the data in <code>DOF.H</code>.
</p>


<h3>Note</h3>

<p> In the case of coarse grids, the value of <code>PDF</code> in a grid cell corresponds to the average probability density over the entire rectangular cell.
</p>
<p>The <code>PDF</code> estimate is not re-normalized to 1, and may fall short of this by the target numerical <code>error</code>. If inspecting quantiles that are very far from the data, the quantiles may hit the grid boundary or become erratic, making it necessary to reduce the numerical <code>error</code> target. However, default arguments should be able to render any quantiles of reasonable accuracy.
</p>
<p>Prior to <code>ctmm</code> v0.3.2, the default AKDE method was the autocorrelated Gaussian reference function bandwidth.
Starting in v0.3.2, the default AKDE method is the autocorrelated Gaussian reference function bandwidth with debiased area.
</p>
<p>Prior to <code>ctmm</code> v0.3.1, AKDEs included only errors due to autocorrelation uncertainty, which are insignificant in cases such as IID data.
Starting in v0.3.1, <code>akde</code> calculated an effective sample size <code>DOF.H</code> and used this to estimate area uncertainty under a Gaussian reference function approxmation.
In v0.3.2, this method was further improved to use <code>DOF.area</code> from the Gaussian reference function approximation.
</p>


<h3>Author(s)</h3>

<p> C. H. Fleming and K. Winner. </p>


<h3>References</h3>

<p>C. H. Fleming, W. F. Fagan, T. Mueller, K. A. Olson, P. Leimgruber, J. M. Calabrese,
&ldquo;Rigorous home-range estimation with movement data: A new autocorrelated kernel-density estimator&rdquo;,
Ecology, 96:5, 1182-1188 (2015) <a href="https://doi.org/10.1890/14-2010.1">doi:10.1890/14-2010.1</a>.
</p>
<p>C. H. Fleming, J. M. Calabrese,
&ldquo;A new kernel-density estimator for accurate home-range and species-range area estimation&rdquo;,
Methods in Ecology and Evolution, 8:5, 571-579 (2017) <a href="https://doi.org/10.1111/2041-210X.12673">doi:10.1111/2041-210X.12673</a>.
</p>
<p>C. H. Fleming, D. Sheldon, W. F. Fagan, P. Leimgruber, T. Mueller, D. Nandintsetseg, M. J. Noonan, K. A. Olson, E. Setyawan, A. Sianipar, J. M. Calabrese,
&ldquo;Correcting for missing and irregular data in home-range estimation&rdquo;,
Ecological Applications, 28:4, 1003-1010 (2018) <a href="https://doi.org/10.1002/eap.1704">doi:10.1002/eap.1704</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+bandwidth">bandwidth</a></code>, <code><a href="#topic+mean.UD">mean.UD</a></code>, <code><a href="#topic+raster+2CUD-method">raster,UD-method</a></code>, <code><a href="#topic+revisitation">revisitation</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load package and data
library(ctmm)
data(buffalo)
DATA &lt;- buffalo$Cilla

# calculate fit guess object
GUESS &lt;- ctmm.guess(DATA,interactive=FALSE)
# in general, you should be running ctmm.select here instead of ctmm.fit
FIT &lt;- ctmm.fit(DATA,GUESS)

# Compute akde object
UD &lt;- akde(DATA,FIT)

# Plot data with AKDE
plot(DATA,UD=UD)
</code></pre>

<hr>
<h2 id='as.telemetry'>Import, coerce, summarize, and combine MoveBank data</h2><span id='topic+as.telemetry'></span><span id='topic+as.telemetry.character'></span><span id='topic+as.telemetry.data.frame'></span><span id='topic+as.telemetry.Move'></span><span id='topic+summary.telemetry'></span><span id='topic+head'></span><span id='topic+head.telemetry'></span><span id='topic+tail'></span><span id='topic+tail.telemetry'></span><span id='topic+tbind'></span>

<h3>Description</h3>

<p>Functions to import MoveBank csv files, <code>data.frame</code>, and <code>Move</code> objects, coerce them into <code>telemetry</code> objects, summarize them, and combine data from multiple tracking devices.</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.telemetry(object,timeformat="auto",timezone="UTC",projection=NULL,datum="WGS84",
             dt.hot=NA,timeout=Inf,na.rm="row",mark.rm=FALSE,keep=FALSE,drop=TRUE,...)

## S3 method for class 'character'
as.telemetry(object,timeformat="auto",timezone="UTC",projection=NULL,datum="WGS84",
             dt.hot=NA,timeout=Inf,na.rm="row",mark.rm=FALSE,keep=FALSE,drop=TRUE,...)

## S3 method for class 'data.frame'
as.telemetry(object,timeformat="auto",timezone="UTC",projection=NULL,datum="WGS84",
             dt.hot=NA,timeout=Inf,na.rm="row",mark.rm=FALSE,keep=FALSE,drop=TRUE,...)

## S3 method for class 'Move'
as.telemetry(object,timeformat="auto",timezone="UTC",projection=NULL,datum="WGS84",
             dt.hot=NA,timeout=Inf,na.rm="row",mark.rm=FALSE,keep=FALSE,drop=TRUE,...)

## S3 method for class 'telemetry'
summary(object,...)

head(x,...)

## S3 method for class 'telemetry'
head(x,n=6L,...)

tail(x,...)

## S3 method for class 'telemetry'
tail(x,n=6L,...)

tbind(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as.telemetry_+3A_object">object</code></td>
<td>
<p>A MoveBank CSV filename, MoveBank <code>data.frame</code> object, or <code>Move</code> object to coerce, or a <code>telemetry</code> object to summarize.</p>
</td></tr>
<tr><td><code id="as.telemetry_+3A_timeformat">timeformat</code></td>
<td>
<p>Format argument for <code><a href="base.html#topic+strptime">strptime</a></code>, corresponding to the input data. Alternatively <code>timeformat="auto"</code> will attempt to infer the timestamp format with <code><a href="parsedate.html#topic+parse_date">parse_date</a></code>.</p>
</td></tr>
<tr><td><code id="as.telemetry_+3A_timezone">timezone</code></td>
<td>
<p>Timezone argument for <code><a href="base.html#topic+strptime">strptime</a></code>, corresponding to the input data.</p>
</td></tr>
<tr><td><code id="as.telemetry_+3A_projection">projection</code></td>
<td>
<p>Optional PROJ projection argument for the <b>output</b> telemetry object.</p>
</td></tr>
<tr><td><code id="as.telemetry_+3A_datum">datum</code></td>
<td>
<p>Optional argument to specify the <b>input</b> longitude-latitude or UTM datum. The default is WGS84.</p>
</td></tr>
<tr><td><code id="as.telemetry_+3A_dt.hot">dt.hot</code></td>
<td>
<p>Time-interval threshold at which GPS location fixes can be considered as &ldquo;hot&rdquo; and location estimate precisions may be smaller (regardless of DOP value) for assigning <code>"hot"</code> and <code>"cold"</code> location classes.</p>
</td></tr>
<tr><td><code id="as.telemetry_+3A_timeout">timeout</code></td>
<td>
<p>GPS location fix timeout value (seconds) for assigning a <code>"timed-out"</code> location class.</p>
</td></tr>

<tr><td><code id="as.telemetry_+3A_na.rm">na.rm</code></td>
<td>
<p>If some values are <code>NA</code> in the data frame, are the rows (times) deleted or are the columns (data types) deleted.</p>
</td></tr>
<tr><td><code id="as.telemetry_+3A_mark.rm">mark.rm</code></td>
<td>
<p>Delete Movebank manually marked outliers. Also see <code><a href="#topic+outlie">outlie</a></code>.</p>
</td></tr>
<tr><td><code id="as.telemetry_+3A_keep">keep</code></td>
<td>
<p>Retain additonal columns after coercion. <code>keep=TRUE</code> retains all columns, while individual columns to retain can be specified by name.</p>
</td></tr>
<tr><td><code id="as.telemetry_+3A_drop">drop</code></td>
<td>
<p>Only return a <code>telemetry</code> object for one individual if <code>TRUE</code>. Always return a <code>list</code> of telemetry objects if <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="as.telemetry_+3A_...">...</code></td>
<td>
<p><code>telemetry</code> objects or a list of such objects, for <code>tbind()</code>. Optional arguments to be fed to <code>fread</code> or <code><a href="utils.html#topic+read.csv">read.csv</a></code>, in the case of compressed files, for <code>as.telemetry()</code>.</p>
</td></tr>
<tr><td><code id="as.telemetry_+3A_x">x</code></td>
<td>
<p><code>telemetry</code> object.</p>
</td></tr>
<tr><td><code id="as.telemetry_+3A_n">n</code></td>
<td>
<p>Number of rows to return, if positive, or number of rows to omit, if negative.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For data that have not been corralled throuh Movebank, timestamps either need to be provided in a POSIX format (see the output of <code>Sys.time()</code>) or supplied with a <code>timeformat</code> argument for interpretation (see <code><a href="base.html#topic+strptime">strptime</a></code>). Alternatively, you can try your luck with <code>timeformat="auto"</code>, and <code><a href="parsedate.html#topic+parse_date">parse_date</a></code> will attempt to infer the format.
</p>
<p>If no projection argument is specified, a two-point equidistant projection is calculated that should be good for most range resident and migratory species.
Global migrations that are not along one geodesic (locally straight line) will probably suffer distortion.
</p>
<p><code>as.telemetry()</code> assumes <a href="https://www.movebank.org/node/2381">Movebank naming conventions</a>.
Sufficient MoveBank columns include <code>individual.local.identifier</code> (or <code>tag.local.identifier</code>), <code>timestamp</code>, <code>location.long</code> and <code>location.lat</code>, while the optional Movebank columns include (e-obs) <code>eobs.horizontal.accuracy.estimate</code>, (Telonics) <code>GPS.Horizontal.Error</code>, <code>GPS.HDOP</code>, (Argos) <code>Argos.orientation</code>, <code>Argos.semi.minor</code> and <code>Argos.semi.major</code> or <code>Argos.location.class</code>, etc..
To have all columns detected and not overwrite eachother's information, <b>it is best to have only one tracking device model per file imported</b>.
Multiple deployments on a single individual can be merged afterwards, using <code>tbind()</code>.
</p>


<h3>Value</h3>

<p><code>as.telemetry</code> returns a single <code>telemetry</code> object or list of <code>telemetry</code> objects if multiple animals are identified.
</p>
<p><code>as.telemetry</code> will always report the smallest sampling interval, as a message, and the number repeating timestamps, as a warning. Tiny sampling intervals (and repeating timestamps) can sometimes result from misformated timestamps or an incorrect <code>timeformat</code> argument. However, even if geniune, they can necessitate data cleaning (<a href="#topic+outlie">outlie</a>) or location-error modeling (<code>vignette('error')</code>).
</p>


<h3>Note</h3>

<p>Prior to v1.1.1, <code>datum</code> was required to be a full PROJ string, but starting with v1.1.1 <code>datum</code> is just taken to be the PROJ datum argument.
</p>


<h3>Author(s)</h3>

<p>C. H. Fleming, X. Dong, B. Kranstauber, G. Péron, and K. Safi.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+plot.telemetry">plot.telemetry</a></code>, <code><a href="#topic+SpatialPoints.telemetry">SpatialPoints.telemetry</a></code>, <code><a href="#topic+uere">uere</a></code>.  </p>

<hr>
<h2 id='bandwidth'>Calculate the optimal bandwidth matrix of movement data</h2><span id='topic+bandwidth'></span>

<h3>Description</h3>

<p>This function calculates the optimal bandwidth matrix (kernel covariance) for a two-dimensional animal tracking dataset, given an autocorrelated movement model (Fleming et al, 2015). This optimal bandwidth can fully take into account all autocorrelation in the data, assuming it is captured by the movement model.</p>


<h3>Usage</h3>

<pre><code class='language-R'>bandwidth(data,CTMM,VMM=NULL,weights=FALSE,fast=NULL,dt=NULL,PC="Markov",error=0.01,
          precision=1/2,verbose=FALSE,trace=FALSE,dt.plot=TRUE,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bandwidth_+3A_data">data</code></td>
<td>
<p> 2D timeseries telemetry data represented as a <code>telemetry</code> object. </p>
</td></tr>
<tr><td><code id="bandwidth_+3A_ctmm">CTMM</code></td>
<td>
<p>A <code>ctmm</code> movement model as from the output of <code>ctmm.fit</code>.</p>
</td></tr>
<tr><td><code id="bandwidth_+3A_vmm">VMM</code></td>
<td>
<p>An optional vertical <code>ctmm</code> object for 3D bandwidth calculation.</p>
</td></tr>
<tr><td><code id="bandwidth_+3A_weights">weights</code></td>
<td>
<p>By default, the weights are taken to be uniform, whereas <code>weights=TRUE</code> will optimize the weights.</p>
</td></tr>
<tr><td><code id="bandwidth_+3A_fast">fast</code></td>
<td>
<p>Use FFT algorithms for weight optimization. <code>fast=NULL</code> will attempt to intelligently decide between the fast and exact algorithms based on computational complexity.</p>
</td></tr>
<tr><td><code id="bandwidth_+3A_dt">dt</code></td>
<td>
<p>Optional lag bin width for the FFT algorithm.</p>
</td></tr>
<tr><td><code id="bandwidth_+3A_pc">PC</code></td>
<td>
<p>Preconditioner to use: can be &quot;Markov&quot;, &quot;circulant&quot;, &quot;IID&quot;, or &quot;direct&quot;.</p>
</td></tr>
<tr><td><code id="bandwidth_+3A_error">error</code></td>
<td>
<p>Maximum grid error for FFT algorithm, if <code>dt</code> is not specified.</p>
</td></tr>
<tr><td><code id="bandwidth_+3A_precision">precision</code></td>
<td>
<p>Fraction of maximum possible digits of precision to target in weight optimization. <code>precision=1/2</code> results in about 7 decimal digits of precision if the preconditioner is stable.</p>
</td></tr>
<tr><td><code id="bandwidth_+3A_verbose">verbose</code></td>
<td>
<p> Optionally return the optimal <code>weights</code>, effective sample size <code>DOF.H</code>, and other information along with the bandwidth matrix <code>H</code>.</p>
</td></tr>
<tr><td><code id="bandwidth_+3A_trace">trace</code></td>
<td>
<p>Produce tracing information on the progress of weight optimization.</p>
</td></tr>
<tr><td><code id="bandwidth_+3A_dt.plot">dt.plot</code></td>
<td>
<p>Execute a diagnostic <code><a href="#topic+dt.plot">dt.plot</a></code> with a red line at <code>dt</code>, if <code>weights=TRUE</code>.</p>
</td></tr>
<tr><td><code id="bandwidth_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code><a href="#topic+mean.ctmm">mean.ctmm</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>weights=TRUE</code> argument can be used to correct temporal sampling bias caused by autocorrelation.
<code>weights=TRUE</code> will optimize <code>n=length(data$t)</code> weights via constrained &amp; preconditioned conjugate gradient algorithms.
These algorithms have a few options that should be considered if the data are very irregular.
</p>
<p><code>fast=TRUE</code> is an approximation that discretizes the data with timestep <code>dt</code> and applies FFT algorithms, for a computational cost as low as <code class="reqn">O(n \log n)</code> with only <code class="reqn">O(n)</code> function evaluations.
If no <code>dt</code> is specified, then a choice of <code>dt</code> will be automated with a message.
<strong>If the data contain some very tiny time intervals</strong>, say 1 second among hourly sampled data, then the default <code>dt</code> setting can create an excessively high-resolution discretization of time, which will cause slowdown. In this case <code>CTMM</code> should contain a location-error model and <code>dt</code> should be increased to a larger fraction of the most-frequent sampling intervals.
<strong>If the data are irregular (permitting gaps), then <code>dt</code> may need to be several times smaller</strong> than the median to avoid slow down.
In this case, try setting <code>trace=TRUE</code> and decreasing <code>dt</code> below the median until the interations speed up and the number of feasibility assessments becomes less than <code class="reqn">O(n)</code>.
</p>
<p><code>fast=FALSE</code> uses exact time spacing and has a computational cost as low as <code class="reqn">O(n^2)</code>, including <code class="reqn">O(n^2)</code> function evaluations. With <code>PC="direct"</code> this method will produce a result that is exact to within machine precision, but with a computational cost of <code class="reqn">O(n^3)</code>. <strong><code>fast=FALSE,PC='direct'</code> is often the fastest method with small datasets</strong>, where <code class="reqn">n \le O</code>(1,000), but scales terribly with larger datasets.
</p>


<h3>Value</h3>

<p>Returns a bandwidth <code>matrix</code> object, which is to be the optimal covariance matrix of the individual kernels of the kernel density estimate.</p>


<h3>Note</h3>

<p> To obtain a bandwidth scalar representing the variance of each kernel, a <code>ctmm</code> object with <code>isotropic=TRUE</code> is required.  In this case, <code>bandwidth</code> will return bandwidth matrix with identical variances along its diagonal. Note that forcing <code>isotropic=TRUE</code> will provide an inaccurate estimate for very eccentric distributions.
</p>
<p>In v1.0.1 the default <code>fast</code>, <code>dt</code>, <code>PC</code> arguments depend on the sample size, with <code>fast=FALSE</code>, <code>PC="Direct"</code> for small sample sizes, <code>fast=FALSE</code>, <code>PC="Markov"</code> for moderate sample sizes, and <code>fast=TRUE</code>, <code>PC="Markov"</code> for large sample sizes, where <code>dt</code> is taken to be the integer fraction of the median sampling interval closest to the minimum sampling interval.
</p>
<p>In v0.6.2 the default <code>dt</code> was increased form the minimum time difference to a small quantile no less than <code>error</code> times the median.
</p>


<h3>Author(s)</h3>

<p> C. H. Fleming. </p>


<h3>References</h3>

<p>T. F. Chan,
&ldquo;An Optimal Circulant Preconditioner for Toeplitz Systems&rdquo;,
SIAM Journal on Scientific and Statistical Computing, 9:4, 766-771 (1988) <a href="https://doi.org/10.1137/0909051">doi:10.1137/0909051</a>.
</p>
<p>D. Marcotte, &ldquo;Fast variogram computation with FFT&rdquo;, Computers and Geosciences 22:10, 1175-1186 (1996) <a href="https://doi.org/10.1016/S0098-3004%2896%2900026-X">doi:10.1016/S0098-3004(96)00026-X</a>.
</p>
<p>C. H. Fleming, W. F. Fagan, T. Mueller, K. A. Olson, P. Leimgruber, J. M. Calabrese,
&ldquo;Rigorous home-range estimation with movement data: A new autocorrelated kernel-density estimator&rdquo;,
Ecology, 96:5, 1182-1188 (2015) <a href="https://doi.org/10.1890/14-2010.1">doi:10.1890/14-2010.1</a>.
</p>
<p>C. H. Fleming, D. Sheldon, W. F. Fagan, P. Leimgruber, T. Mueller, D. Nandintsetseg, M. J. Noonan, K. A. Olson, E. Setyawan, A. Sianipar, J. M. Calabrese,
&ldquo;Correcting for missing and irregular data in home-range estimation&rdquo;,
Ecological Applications, 28:4, 1003-1010 (2018) <a href="https://doi.org/10.1002/eap.1704">doi:10.1002/eap.1704</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+akde">akde</a></code>, <code><a href="#topic+ctmm.fit">ctmm.fit</a></code> </p>

<hr>
<h2 id='buffalo'>African buffalo GPS dataset from Kruger National Park, South Africa.</h2><span id='topic+buffalo'></span>

<h3>Description</h3>

<p>GPS data on six African buffalo. When using this dataset, please cite the original article by Getz et al (2007) and the Movebank data package (Cross et al, 2016).</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("buffalo")</code></pre>


<h3>Format</h3>

<p> A list of 6 <code>telemetry</code> objects.</p>


<h3>Note</h3>

<p>In <code>ctmm</code> v0.3.2 the erroneous location fix <code>606</code> was removed from <code>buffalo[[4]]</code> &quot;Pepper&quot;.</p>


<h3>References</h3>

<p>W. M. Getz, S. Fortmann-Roe, P. C. Cross, A. J. Lyons, S. J. Ryan, C. C. Wilmers.
LoCoH: Nonparameteric kernel methods for constructing home ranges and utilization distributions.
PLoS ONE 2:2, e207 (2007).
</p>
<p>P. C. Cross, J. A. Bowers, C. T. Hay, J. Wolhuter, P. Buss, M. Hofmeyr, J. T. du Toit, W. M. Getz.
Data from: Nonparameteric kernel methods for constructing home ranges and utilization distributions.
Movebank Data Repository. DOI:10.5441/001/1.j900f88t (2016).
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+as.telemetry">as.telemetry</a></code>, <code><a href="#topic+plot.telemetry">plot.telemetry</a></code>, <code><a href="#topic+coati">coati</a></code>, <code><a href="#topic+gazelle">gazelle</a></code>, <code><a href="#topic+jaguar">jaguar</a></code>, <code><a href="#topic+pelican">pelican</a></code>, <code><a href="#topic+turtle">turtle</a></code>, <code><a href="#topic+wolf">wolf</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'># Load package and data
library(ctmm)
data("buffalo")

# Extract movement data for a single animal
Cilla &lt;- buffalo$Cilla

# Plot all sampled locations
plot(Cilla)
</code></pre>

<hr>
<h2 id='cluster'>Clustering of movement-model parameters</h2><span id='topic+cluster'></span>

<h3>Description</h3>

<p>These functions cluster and classify individual movement models and related estimates, including AKDE home-range areas, while taking into account estimation uncertainty.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cluster(x,level=0.95,level.UD=0.95,debias=TRUE,IC="BIC",units=TRUE,plot=TRUE,sort=FALSE,
        ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cluster_+3A_x">x</code></td>
<td>
<p>A list of <code>ctmm</code> movement-model objects, <code>UD</code> objects, or <code>UD</code> <code>summary</code> output, constituting a sampled population, or a list of such lists, each constituting a sampled sub-population.</p>
</td></tr>
<tr><td><code id="cluster_+3A_level">level</code></td>
<td>
<p>Confidence level for parameter estimates.</p>
</td></tr>
<tr><td><code id="cluster_+3A_level.ud">level.UD</code></td>
<td>
<p>Coverage level for home-range estimates. E.g., 50% core home range.</p>
</td></tr>
<tr><td><code id="cluster_+3A_debias">debias</code></td>
<td>
<p>Apply Bessel's inverse-Gaussian correction and various other bias corrections.</p>
</td></tr>
<tr><td><code id="cluster_+3A_ic">IC</code></td>
<td>
<p>Information criterion to determine whether or not population variation can be estimated. Can be <code>"AICc"</code>, <code>AIC</code>, or <code>"BIC"</code>.</p>
</td></tr>
<tr><td><code id="cluster_+3A_units">units</code></td>
<td>
<p>Convert result to natural units.</p>
</td></tr>
<tr><td><code id="cluster_+3A_plot">plot</code></td>
<td>
<p>Generate a meta-analysis forest plot with two means.</p>
</td></tr>
<tr><td><code id="cluster_+3A_sort">sort</code></td>
<td>
<p>Sort individuals by their point estimates in forest plot.</p>
</td></tr>
<tr><td><code id="cluster_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <code>plot</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>So-far only the clustering of home-range areas is implemented. More details will be provided in an upcomming manuscript.
</p>


<h3>Value</h3>

<p>A <code>list</code> with elements <code>P</code> and <code>CI</code>,
where <code>P</code> is an array of individual membership probabilities for sub-population 1,
and <code>CI</code> is a table with rows corresponding to the sub-population means, coefficients of variation, and membership probabilities, and the ratio of sub-population means.
</p>


<h3>Note</h3>

<p>The AICc formula is approximated via the Gaussian relation.</p>


<h3>Author(s)</h3>

<p> C. H. Fleming. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+akde">akde</a></code>, <code><a href="#topic+ctmm.fit">ctmm.fit</a></code>, <code><a href="#topic+meta">meta</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>
# load package and data
library(ctmm)
data(buffalo)

# fit movement models
FITS &lt;- AKDES &lt;- list()
for(i in 1:length(buffalo))
{
  GUESS &lt;- ctmm.guess(buffalo[[i]],interactive=FALSE)
  # use ctmm.select unless you are certain that the selected model is OUF
  FITS[[i]] &lt;- ctmm.fit(buffalo[[i]],GUESS)
}

# calculate AKDES on a consistent grid
AKDES &lt;- akde(buffalo,FITS)

# color to be spatially distinct
COL &lt;- color(AKDES,by='individual')

# plot AKDEs
plot(AKDES,col.DF=COL,col.level=COL,col.grid=NA,level=NA)

# cluster-analysis of buffalo
cluster(AKDES,sort=TRUE)
</code></pre>

<hr>
<h2 id='coati'>Coatis on Barro Colorado Island, Panama.</h2><span id='topic+coati'></span>

<h3>Description</h3>

<p>GPS data on 2 coati. When using this dataset, please cite the original article by Powell et al (in preparation) and the Movebank data package (Kays and Hirsch, 2015).</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("coati")</code></pre>


<h3>Format</h3>

<p> A list of 2 <code>telemetry</code> objects.</p>


<h3>References</h3>

<p>R. A. Powell, S. Ellwood, R. Kays. Stink or swim: techniques to meet the challenges for the study and conservation of small critters that hide, swim or climb and may otherwise make themselves unpleasant. In L. Harrington and D. W. Macdonald; Biology and Conservation of Mustelids and Procyonids (in preparation).
</p>
<p>R. Kays, B. T. Hirsch Data from: Stink or swim: techniques to meet the challenges for the study and conservation of small critters that hide, swim or climb and may otherwise make themselves unpleasant. Movebank Data Repository. DOI:10.5441/001/1.41076dq1 (2015).
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+as.telemetry">as.telemetry</a></code>, <code><a href="#topic+plot.telemetry">plot.telemetry</a></code>, <code><a href="#topic+buffalo">buffalo</a></code>, <code><a href="#topic+gazelle">gazelle</a></code>, <code><a href="#topic+jaguar">jaguar</a></code>, <code><a href="#topic+pelican">pelican</a></code>, <code><a href="#topic+turtle">turtle</a></code>, <code><a href="#topic+wolf">wolf</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'># Load package and data
library(ctmm)
data("coati")

# Plot all sampled locations
plot(coati,col=rainbow(2))
</code></pre>

<hr>
<h2 id='color'>Color telemetry objects by time</h2><span id='topic+annotate'></span><span id='topic+color'></span>

<h3>Description</h3>

<p>These functions facilitate the coloring of tracks by annotating tracking data with time/location specific information and computing color arguments for <code>plot</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>annotate(object,by="all",cores=1,...)

color(object,by="time",col.fn=NULL,alpha=1,dt=NULL,cores=1,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="color_+3A_object">object</code></td>
<td>
<p>A <code>telemetry</code> object or list of objects. <code>color</code> can also take <code>ctmm</code> and <code>UD</code> objects.</p>
</td></tr>
<tr><td><code id="color_+3A_by">by</code></td>
<td>
<p>What to <code>annotate</code> or <code>color</code> times by. Options include <code>"individual"</code>, <code>"time"</code>, <code>"sun"</code>, <code>"moon"</code>, <code>"season"</code>, and <code>"tropic"</code> (see Details below). <code>ctmm</code> and <code>UD</code> objects can only be colored by <code>"individual"</code>.</p>
</td></tr>
<tr><td><code id="color_+3A_col.fn">col.fn</code></td>
<td>
<p>Optional coloring function that can take a [0,1] interval and alpha channel argument.</p>
</td></tr>
<tr><td><code id="color_+3A_alpha">alpha</code></td>
<td>
<p>Base alpha channel value.</p>
</td></tr>
<tr><td><code id="color_+3A_dt">dt</code></td>
<td>
<p>Sampling interval specification for making oversampled times more transparent. If <code>NULL</code>, the median will be used. Disabled if zero.</p>
</td></tr>
<tr><td><code id="color_+3A_cores">cores</code></td>
<td>
<p>Number of annotations or overlap calculations to peform in parallel. <code>cores=0</code> will use all cores, while <code>cores&lt;0</code> will reserve <code>abs(cores)</code>.</p>
</td></tr>
<tr><td><code id="color_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Annotated <code>telemetry</code> objects are required for <code>color</code> <code>by</code> arguments <code>"sun"</code>, <code>"moon"</code>, <code>"season"</code>, or <code>"tropic"</code>.
</p>
<p><code>by="time"</code> colors tracking data with a gradient that increases in time.
<code>by="sun"</code> colors according to the sine of the sun's altitude, which is proportional to solar flux during daylight hours.
<code>by="moon"</code> colors according to the illuminated fraction of the moon.
<code>by="season"</code> colors according to the length of the day, and therefore corresponds to the local season.
<code>by="tropic"</code> currently colors according to the calender day, but will eventually be upgraded to tropical-year cycle. The default <code>col.fn</code> argument runs from blue to red with increasing time, sunlight, moonlight, or day length.
</p>
<p><code>by="individual"</code> assigns colors to minimize the maximum combined spatial and color overlap.
Finding the best color assignment is an <code class="reqn">NP</code>-hard problem that is here approximated in <code class="reqn">O(N^3)</code> time with a custom greedy algorithm.
</p>
<p>Other named columns in the <code>telemetry</code> object can also be used with <code>color</code>, by specifying the column name with <code>by</code>.
</p>


<h3>Value</h3>

<p><code>annotate</code> returns an annotated telemetry object with extra columns to facilitate coloring.
<code>color</code> returns a valid <code>col</code> argument for <code>{plot.telemetry}</code>.
</p>


<h3>Author(s)</h3>

<p> C. H. Fleming. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+plot.telemetry">plot.telemetry</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load package and data
library(ctmm)
data(buffalo)

# assign distinct colors to buffalo
COL &lt;- color(buffalo,by='individual')
# Notice the separation into RGB and CMY for maximum contrast
plot(buffalo,col=COL)

# annotate buffalo with sunlight data and compute colors
buffalo &lt;- annotate(buffalo,cores=2) # CRAN policy limits to 2 cores
COL &lt;- color(buffalo,by='sun')

# use North-preserving projection and plot
projection(buffalo) &lt;- median(buffalo)
plot(buffalo,col=COL)
</code></pre>

<hr>
<h2 id='ctmm'>Specify, fit, and select continuous-time movement models</h2><span id='topic+ctmm'></span><span id='topic+ctmm.loglike'></span><span id='topic+ctmm.fit'></span><span id='topic+ctmm.select'></span>

<h3>Description</h3>

<p>These functions allow one to propose hypothetical movement models (with initial estimates), fit those models to the data, and select among those models via an information criterion.
The fitting functions wrap around <code>optim</code> and <code>ctmm.loglike</code> to fit continuous-time movement models to 2D animal tracking data as described in Fleming et al (2014) and Fleming et al (2015), and Fleming et al (2017).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ctmm(tau=NULL,omega=FALSE,isotropic=FALSE,range=TRUE,circle=FALSE,error=FALSE,
     axes=c("x","y"),...)

ctmm.loglike(data,CTMM,REML=FALSE,profile=TRUE,zero=0,verbose=FALSE,compute=TRUE,...)

ctmm.fit(data,CTMM=ctmm(),method="pHREML",COV=TRUE,control=list(),trace=FALSE)

ctmm.select(data,CTMM,verbose=FALSE,level=1,IC="AICc",MSPE="position",trace=FALSE,cores=1,
            ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ctmm_+3A_tau">tau</code></td>
<td>
<p>Array of autocorrelation timescales (explained below).</p>
</td></tr>
<tr><td><code id="ctmm_+3A_omega">omega</code></td>
<td>
<p>Frequency (<code class="reqn">2\pi/period</code>) of oscillatory range crossings.</p>
</td></tr>
<tr><td><code id="ctmm_+3A_isotropic">isotropic</code></td>
<td>
<p>A Boolean denoting whether or not the animal's covariance is circular or elliptical.</p>
</td></tr>
<tr><td><code id="ctmm_+3A_range">range</code></td>
<td>
<p>A Boolean denoting whether or not the movement model has a finite range.</p>
</td></tr>
<tr><td><code id="ctmm_+3A_circle">circle</code></td>
<td>
<p>(<code class="reqn">2\pi</code> divided by) the period it takes the animal to stochastically circle its mean location.</p>
</td></tr>
<tr><td><code id="ctmm_+3A_error">error</code></td>
<td>
<p>A Boolean denoting whether or not to use annotated telemetry error estimates or an estimate of the error's standard deviation if the data are not annotated with error estimates or when <code class="reqn">HDOP=1</code>.</p>
</td></tr>
<tr><td><code id="ctmm_+3A_axes">axes</code></td>
<td>
<p>Spatial dimensions of the movement model.</p>
</td></tr>
<tr><td><code id="ctmm_+3A_data">data</code></td>
<td>
<p> Timeseries data represented as a <code>telemetry</code> object. </p>
</td></tr>
<tr><td><code id="ctmm_+3A_ctmm">CTMM</code></td>
<td>
<p> A <code>ctmm</code> movement-model object containing the initial parameter guesses conforming to the basic structure of the model hypothesis. <code>ctmm.select</code> can accept a list of such objects.</p>
</td></tr>
<tr><td><code id="ctmm_+3A_reml">REML</code></td>
<td>
<p>Use residual maximum likelihood if <code>TRUE</code>. Not recommended.</p>
</td></tr>
<tr><td><code id="ctmm_+3A_profile">profile</code></td>
<td>
<p>Analytically solve for as many covariance parameters as possible.</p>
</td></tr>
<tr><td><code id="ctmm_+3A_zero">zero</code></td>
<td>
<p>Calculates <code class="reqn">log(likelihood) - zero</code>, instead of just <code class="reqn">log(likelihood)</code>, in a way that maintains numerical precision if the constant <code>zero</code> is close to the log likelihood. Used internally by <code>ctmm.fit</code>.</p>
</td></tr>
<tr><td><code id="ctmm_+3A_verbose">verbose</code></td>
<td>
<p>Return additional information. See &quot;Value&quot; below.</p>
</td></tr>
<tr><td><code id="ctmm_+3A_compute">compute</code></td>
<td>
<p>Only return computational information if <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ctmm_+3A_method">method</code></td>
<td>
<p>Fitting method to use: <code>"ML"</code>, <code>"HREML"</code>, <code>"pREML"</code>, <code>"pHREML"</code>, or <code>"REML"</code>. See &quot;Description&quot; below.</p>
</td></tr>
<tr><td><code id="ctmm_+3A_cov">COV</code></td>
<td>
<p>Estimate the autocorrelation parameter covariance matrix.</p>
</td></tr>
<tr><td><code id="ctmm_+3A_control">control</code></td>
<td>
<p>An optional argument list for <code><a href="#topic+optimizer">optimizer</a></code>.</p>
</td></tr>
<tr><td><code id="ctmm_+3A_trace">trace</code></td>
<td>
<p>Report progress updates. Can be among <code>0:3</code> with increasing detail.</p>
</td></tr>
<tr><td><code id="ctmm_+3A_level">level</code></td>
<td>
<p>Attempt to simplify a model if a feature's non-existence falls within this level of confidence interval.</p>
</td></tr>
<tr><td><code id="ctmm_+3A_ic">IC</code></td>
<td>
<p>Information criterion used for selection. Can be <code>"AICc"</code>, <code>"AIC"</code>, <code>"BIC"</code>, <code>"LOOCV"</code>, <code>"HSCV"</code>, or none (<code>NA</code>). AICc is approximate.</p>
</td></tr>
<tr><td><code id="ctmm_+3A_mspe">MSPE</code></td>
<td>
<p>Reject non-stationary features that increase the mean square predictive error of <code>"position"</code>, <code>"velocity"</code>, or not (<code>NA</code>).</p>
</td></tr>
<tr><td><code id="ctmm_+3A_cores">cores</code></td>
<td>
<p>Maximum number of models to fit in parallel. cores=0 will use all cores, while cores&lt;0 will reserve abs(cores).</p>
</td></tr>
<tr><td><code id="ctmm_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <code>ctmm.fit</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Model fitting and selection first requires a prototype model with guesstimated parameters (i.e., Brownian motion with a particular diffusion rate).
The initial <code>ctmm</code> parameter guess can be generated by the output of <code>ctmm.guess</code>, <code>variogram.fit</code> or manually specified with the function <code>ctmm(...)</code>, where the argument <code>tau</code> is explained below and additional model options described in <code>vignette("ctmm")</code>.
</p>
<p>By default, <code>tau</code> (<code class="reqn">\tau</code>) is an ordered array of autocorrelation timescales.
If <code>length(tau)==0</code>, then an IID bi-variate Gaussian model is fit to the data.
If <code>length(tau)==1</code>, then an Ornstein-Uhlenbeck (OU) model (Brownian motion restricted to a finite home range) is fit the data, where <code>tau</code> is the position autocorrelation timescale. <code>tau=Inf</code> then yields Brownian motion (BM).
If <code>length(tau)==2</code>, then the OUF model (continuous-velocity motion restricted to a finite home range) is fit to the data, where <code>tau[1]</code> is again the position autocorrelation timescale and <code>tau[2]</code> is the velocity autocorrelation timescale. <code>tau[1]=Inf</code> then yields integrated Ornstein-Uhlenbeck (IOU) motion, which is a spatially unrestricted continuous-velocity process.
</p>
<p>Two new models were introduced in ctmm version 0.5.2 for the case of <code>tau[1]==tau[2]</code>, which can happen with short tracks of data. When <code>tau[1]==tau[2]</code> and <code>omega==0</code>, the model is categorized as OUf&mdash;a special case of OUF&mdash;and the two <code>tau</code> parameters are treated as identical. On the other hand, when <code>tau[1]==tau[2]</code> and <code>omega&gt;0</code>, an oscillatory model is implemented, which we refer to as OU<code class="reqn">\Omega</code>.
</p>
<p>The potential fitting methods&mdash;maximum likelihood (<code>ML</code>), residual maximum likelihood (<code>REML</code>), perturbative REML (<code>pREML</code>), hybrid REML (<code>HREML</code>), and perturbative hybrid REML (<code>pHREML</code>)&mdash;are described in Fleming et al (2019). In general, <code>pHREML</code> is the best method, though when parameter estimates lie near boundaries it can fail, in which case <code>ctmm.fit</code> will fall back to <code>HREML</code>, as reported by the <code>method</code> slot of the resulting fit object.
</p>
<p>The <code>control</code> list can take the following arguments, with defaults shown:
</p>

<dl>
<dt><code>method="pNewton"</code></dt><dd><p>The partial-Newton method of <code><a href="#topic+optimizer">optimizer</a></code> is default. See <code><a href="stats.html#topic+optim">optim</a></code> for alternative methods in multiple dimensions.</p>
</dd>
<dt><code>precision=1/2</code></dt><dd><p>Fraction of machine numerical precision to target in the maximized likelihood value. MLEs will necessarily have half this precision. On most computers, <code>precision=1</code> is approximately 16 decimal digits of precision for the likelihood and 8 for the MLEs.</p>
</dd>
<dt><code>maxit=.Machine$integer.max</code></dt><dd><p>Maximum number of iterations allowed for optimization.</p>
</dd>
</dl>

<p>Model selection in <code>ctmm.select</code> proceeds in two phases. If there are a large number of parameters that must be fit numerically (such as when error is modeled), then the target model (argument <code>CTMM</code>) is worked toward by first fitting simpler, compatible models. The second phase proceeds by attempting to simplify the autocorrelation model and complexify the deterministic (trend) model until the information criterion fails to improve. The intent of working in these directions is to improve numerical convergence and avoid fitting trends to autocorrelation.
Note that simpler models in a nested hierarchy will only be attempted if they appear credible, which can be adjusted with the <code>level</code> argument. <code>level=1</code> will, therefore, always attempt a simpler model.
</p>
<p>The leave-one-out cross validation IC, <code>IC="LOOCV"</code>, is (-2 times) the sum of log-likelihoods of the validation data, after fitting to and conditioning on the training data. This information criterion is intended for small amounts of data where AIC/BIC are not valid, and where the questions of interest are targeted at the finest scales of the data, such as speed or occurrence. Unlike other model-selection criteria, the computational complexity of LOOCV is <code class="reqn">O(n^2)</code>, which is very slow for sample sizes on the order of 10-100 thousand locations. Furthermore, as autocorrelation in the validation data is ignored, this information criterion is not valid for making inferences at scales coarser than the sampling interval, such as home range.
</p>
<p>The half-sample cross validation IC, <code>IC="HSCV"</code>, is (-2 times) the sum of log-likelihoods of the validation data, after fitting to and conditioning on the training data consisting of the first (and second) halves of the data when split temporally. This information criterion is intended for when few range crossings are observed and AIC/BIC may not be valid.
</p>


<h3>Value</h3>

<p>The function <code>ctmm</code> returns a prototype <code>ctmm</code> movement-model object.
By default, <code>ctmm.loglike</code> returns the log-likelihood of the model <code>CTMM</code>.
<code>ctmm.fit</code> (and <code>ctmm.loglike</code> with <code>verbose=TRUE</code>) returns the estimated <code>ctmm</code> movement-model object with all of the components of <code>CTMM</code> plus the components listed below.
<code>ctmm.select</code> returns the best model by default, or the sorted list of attempted models if <code>verbose=TRUE</code>, with the best model being first in the list.
</p>

<dl>
<dt><code>AICc</code></dt><dd><p>The approximate corrected Akaike information criterion for multivariate distributions with variable numbers of unknown mean and (structured) covariance parameters (Burnham &amp; Anderson, Eq. 7.91). This formula is only exact for IID data.</p>
</dd>
<dt><code>loglike</code></dt><dd><p>The log-likelihood.</p>
</dd>
<dt><code>sigma</code></dt><dd><p>The maximum likelihood variance/covariance estimate (possibly debiased). For the endlessly diffusing BM and IOU processes, this is instead the diffusion rate estimate.</p>
</dd>
<dt><code>mu</code></dt><dd><p>The maximum likelihood stationary mean vector estimate.</p>
</dd>
<dt><code>COV.mu</code></dt><dd><p>The covariance matrix of the <code>mu</code> estimate, assuming that the covariance estimate is correct.</p>
</dd>
<dt><code>DOF.mu</code></dt><dd><p>The effective number of degrees of freedom in the estimate of <code>mu</code>, assuming that the autocorrelation model is correct. This can be much smaller than <code>length(data$t)</code> if the data are autocorrelated.</p>
</dd>
<dt><code>COV</code></dt><dd><p>Covariance of the autocovariance parameter estimate vector <code>c(sigma,tau,circle)</code>, as derived (asymptotically) from the <code>hessian</code> of the log-likelihood function, and where <code>sigma</code> is parameterized in terms of its largest variance <code>major</code>, the ratio of the smallest to largest variance <code>minor</code>, and <code>angle</code> of orientation. Typically, <code>sigma</code>'s <code>major</code> parameter is extremely correlated to <code>tau[1]</code>, and sequential components of <code>tau</code> are slightly correlated.</p>
</dd>
</dl>



<h3>Warnings</h3>

<p>The warning &quot;MLE is near a boundary or optim() failed&quot; indicates that you should be using <code>ctmm.select</code> rather than <code>ctmm.fit</code>, because some features are not well supported by the data.
</p>
<p>The warning &quot;pREML failure: indefinite ML Hessian&quot; is normal if some autocorrelation parameters cannot be well resolved.
</p>


<h3>Note</h3>

<p>The default optimization method in <code>ctmm</code> v0.5.7 and above is <code><a href="#topic+optimizer">optimizer</a></code>'s <code>"pNewton"</code>. Annecdotally, on these problems, <code><a href="#topic+optimizer">optimizer</a></code>'s <code>pNewton</code> method generally outperforms <code><a href="stats.html#topic+optim">optim</a></code>'s <code>"Nelder-Mead"</code>, which generally outperforms <code><a href="stats.html#topic+optim">optim</a></code>'s <code>"BFGS"</code> and <code>"L-BFGS-B"</code> methods. With default arguments, <code>"pNewton"</code> is about half as fast as <code>"Nelder-Mead"</code>, but is resolving about twice as much numerical precision by default.
</p>
<p>The AICs/BICs of endlessly diffusing models like BM and IOU cannot be easily compared to the AICs/BICs of range resident models like bivariate Gaussian, OU, and OUF, as their joint likelihood functions are infinitely different. Endlessly diffusing models have to be conditioned off of an initial state, which we derive in <code>ctmm</code> by taking the large range limit of a range-restricted process. I.e., BM is the limit OU(<code>Inf</code>) and IOU(<code>tau</code>) is the limit OUF(<code>Inf</code>,<code>tau</code>). Using comparable likelihood functions gives up statistical efficiency and the objective prior. Moreover, comparing conditional likelihoods&mdash;with the objective prior taken from the joint likelihood&mdash;does not appear to select the true model with a likelihood ratio test. Different criteria must be used to select between range resident and endlessly diffusing movement models.
</p>
<p>Prior to v0.3.6, the univariate AICc formula was (mis)used, with the full parameter count treated as degrees of freedom in the mean. As of v.0.3.6, the mean and autocovariance parameters are treated separately in the approximate multivariate AICc formula (Burnham &amp; Anderson, Eq. 7.91). Still, this improved formula is only exact for IID data.
</p>
<p>Prior to v0.3.2, <code>ctmm.select</code> would consider every possible model.
This is no longer feasible with current versions of <code>ctmm</code>, as the number of possible models has grown too large.
</p>


<h3>Author(s)</h3>

<p> C. H. Fleming and G. Péron. </p>


<h3>References</h3>

<p>K. P. Burnham, D. R. Anderson,
&ldquo;Model Selection and Multimodel Inference: A Practical Information-Theoretic Approach&rdquo;,
Springer, 2nd edition (2003).
</p>
<p>C. H. Fleming, J. M. Calabrese, T. Mueller, K.A. Olson, P. Leimgruber, W. F. Fagan,
&ldquo;From fine-scale foraging to home ranges: A semi-variance approach to identifying movement modes across spatiotemporal scales&rdquo;,
The American Naturalist, 183:5, E154-E167 (2014) <a href="https://doi.org/10.1086/675504">doi:10.1086/675504</a>.
</p>
<p>C. H. Fleming, Y. Subaşı, J. M. Calabrese,
&ldquo;A maximum-entropy description of animal movement&rdquo;,
Physical Review E, 91, 032107 (2015) <a href="https://doi.org/10.1103/PhysRevE.91.032107">doi:10.1103/PhysRevE.91.032107</a>.
</p>
<p>C. H. Fleming, D. Sheldon, E. Gurarie, W. F. Fagan, S. LaPoint, J. M. Calabrese,
&ldquo;Kálmán filters for continuous-time movement models&rdquo;,
Ecological Informatics, 40, 8-21 (2017) <a href="https://doi.org/10.1016/j.ecoinf.2017.04.008">doi:10.1016/j.ecoinf.2017.04.008</a>.
</p>
<p>C. H. Fleming, M. J. Noonan, E. P. Medici, J. M. Calabrese,
&ldquo;Overcoming the challenge of small effective sample sizes in home-range estimation&rdquo;,
Methods in Ecology and Evolution 10:10, 1679-1689 (2019) <a href="https://doi.org/10.1111/2041-210X.13270">doi:10.1111/2041-210X.13270</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+ctmm.boot">ctmm.boot</a></code>, <code><a href="#topic+ctmm.guess">ctmm.guess</a></code>, <code><a href="#topic+optimizer">optimizer</a></code>, <code><a href="#topic+summary.ctmm">summary.ctmm</a></code>, <code><a href="#topic+variogram.fit">variogram.fit</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load package and data
library(ctmm)
data(buffalo)
DATA &lt;- buffalo$Cilla

GUESS &lt;- ctmm.guess(DATA,interactive=FALSE)
# in general, you want to run ctmm.select instead
FIT &lt;- ctmm.fit(DATA,GUESS)

# some human-readable information
summary(FIT)
</code></pre>

<hr>
<h2 id='ctmm-FAQ'>ctmm FAQ</h2><span id='topic+ctmm-FAQ'></span><span id='topic+ctmm-faq'></span>

<h3>Description</h3>

<p>Frequently asked questions for the <code>ctmm</code> package.</p>


<h3>Details</h3>

<p><b>General recommendations</b>
</p>

<ol>
<li><p>Work through the vignettes <code>vignette("variogram")</code> and <code>vignette("akde")</code>. Also, see the <code>help</code> file for the method of interest, and its <code>example</code>.
</p>
</li>
<li><p>Do not save workspaces between sessions. They will become corrupted over time. In RStudio, go to <code>Tools: Global Options: Workspace</code>, uncheck <code>Restore</code> and set <code>Save</code> to <code>Never</code>.
</p>
</li>
<li><p>If RStudio is crashing frequently in Windows (or your display driver is crashing), try setting the rendering engine to <code>Software</code> under <code>Tools : Global Options : General : Advanced : Rendering Engine</code>.
</p>
</li>
<li><p>Never edit or save your CSV in Microsoft Excel. The dates will be reformatted incorrectly and inconsistently.
</p>
</li>
<li><p>If using Windows, make sure to have the suggested version of &ldquo;Rtools&rdquo; installed. If using MacOS, make sure to have &ldquo;Xcode&rdquo; installed. If using Ubuntu, make sure to have &ldquo;build-essential&rdquo; installed. Otherwise, you can sometimes run into problems when trying to update packages.
</p>
</li>
<li><p>Upgrade <code>R</code> to the latest version and update all of your packages.
</p>
</li>
<li><p>The development build can be installed via <code>remotes::install_github("ctmm-initiative/ctmm")</code>.
</p>
</li>
<li><p>Sometimes installing from Github can silently fail to overwrite old files, requiring the package to be manually uninstalled, and then re-installed after restarting.
</p>
</li>
<li><p>Stable beta releases between the CRAN release are published <a href="http://www2.physics.umd.edu/~hfleming/">here</a> on request.
</p>
</li>
<li><p>The <a href="https://groups.google.com/g/ctmm-user"><code>ctmm</code> user's group</a> is a good place to find and ask for help.
</p>
</li>
<li><p>Bug reports and feature requests can be raised at the <a href="https://github.com/ctmm-initiative/ctmm">Github project page</a>.
</p>
</li></ol>

<p><b>Help installing packages on Linux</b>
</p>
<p>These are the packages I needed in Ubuntu:
</p>
<p><code>sudo apt install ffmpeg fftw3 libfftw3-dev libgdal-dev libgeos-dev libgit2-dev libgmp-dev libgsl-dev libmpfr-dev libproj-dev libnode-dev libudunits2-dev r-base-core</code>
</p>
<p><b><code>as.telemetry</code> reports abnormal sampling intervals and speeds</b>
</p>
<p>Make sure that you have the correct <code>timezone</code> and <code>timeformat</code> arguments specified. Also, see <code><a href="#topic+outlie">outlie</a></code>.
</p>
<p><b>rdb database corruption, &quot;could not find function&quot;, &quot;cannot coerce class&quot;, and other weird errors</b>
</p>
<p><code>R</code> might not have installed or loaded the package correctly&mdash;e.g., some files may have failed to overwrite previous versions&mdash;or the workspace/session might be corrupted. Uninstall <code>ctmm</code>, restart <code>R</code> without saving the workspace/session, and install <code>ctmm</code> again.
</p>
<p><b>Infinite recursion and stack overflow errors</b>
</p>
<p><code>ctmm</code> has no recursive functions, so I am not exactly sure what causes this error, but it only occurs with certain versions of <code>R</code> on certain computer architectures. There are several solutions that have worked for people, including restarting <code>R</code> in a fresh session and updating their software. Alternatively:
</p>

<ol>
<li><p>Reboot your computer.
</p>
</li>
<li><p>Increase the allowed number of nested expressions within <code>R</code> via <code>options(expressions=10000)</code> or some other large number.
</p>
</li>
<li><p>Try a different computer.
</p>
</li></ol>

<p><b><code>plot</code> complains about the datatype or has weird errors</b>
</p>
<p>Namespace collision sometimes occurs between <code>raster</code>, <code>sp</code>, <code>move</code>, and <code>ctmm</code>. Either restart <code>R</code> and only load the <code>ctmm</code> package, or run <code>ctmm::plot</code> instead of <code>plot</code>.
</p>
<p><b>North is no longer up after importing data</b>
</p>
<p>The default projection in <code>ctmm</code> does not preserve the direction of North, but better preserves distances for elongated distributions. See the <code>projection</code> argument in <code><a href="#topic+as.telemetry">as.telemetry</a></code> and the example in <code><a href="#topic+projection">projection</a></code>. The <code><a href="#topic+compass">compass</a></code> function is also useful for pointing north.
</p>
<p><b><code>projection</code> complains about the datatype and fails</b>
</p>
<p>Namespace collision can occur between <code>raster</code> and <code>ctmm</code>. Either restart <code>R</code> and only load the <code>ctmm</code> package, or run <code>ctmm::projection</code> instead of <code>projection</code>.
</p>
<p><b><code><a href="#topic+ctmm.guess">ctmm.guess</a></code> has no save button</b>
</p>
<p>Maximize the plot window and/or increase your screen resolution.
</p>
<p><b><code>manipulate</code> panel does not popup in <code><a href="#topic+ctmm.guess">ctmm.guess</a></code> or <code>zoom</code></b>
</p>
<p>Click the gear icon in the upper-left corner of the plot window.
</p>
<p><b>Gear icon missing in <code><a href="#topic+ctmm.guess">ctmm.guess</a></code> or <code>zoom</code></b>
</p>
<p>Recent versions of <code>manipulate</code> and/or RStudio seem to have some issues. Sometimes the gear icon does not render unless you re-run the function 2-5 times.
</p>
<p><b><code>manipulate::isAvailable</code> is not found</b>
</p>
<p>You probably have an outdated copy of the <code>manipulate</code> package installed. Update <code>R</code> to the latest version and then update all of your packages. This seems to happen frequently with the MacOS release of <code>R</code>.
</p>


<h3>Author(s)</h3>

<p>C. H. Fleming</p>

<hr>
<h2 id='ctmm.boot'>Parametric bootstrap continuous-time movement models</h2><span id='topic+ctmm.boot'></span>

<h3>Description</h3>

<p>This function allows the point estimates and confidence intervals of an initial estimated movement model to be improved by parametric boostrap, as described in Fleming et al (2019).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ctmm.boot(data,CTMM,method=CTMM$method,AICc=FALSE,iterate=FALSE,robust=FALSE,error=0.01,
          cores=1,trace=TRUE,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ctmm.boot_+3A_data">data</code></td>
<td>
<p> Timeseries data represented as a <code>telemetry</code> object. </p>
</td></tr>
<tr><td><code id="ctmm.boot_+3A_ctmm">CTMM</code></td>
<td>
<p> A <code>ctmm</code> movement-model object from the output of <code>ctmm.fit</code> containing the initial parameter estimates.</p>
</td></tr>
<tr><td><code id="ctmm.boot_+3A_method">method</code></td>
<td>
<p>Fitting method to use: <code>"ML"</code>, <code>"HREML"</code>, <code>"pREML"</code>, <code>"pHREML"</code>, or <code>"REML"</code>. See <code><a href="#topic+ctmm.fit">ctmm.fit</a></code> for descriptions.</p>
</td></tr>
<tr><td><code id="ctmm.boot_+3A_aicc">AICc</code></td>
<td>
<p>Run dual set of simulations to approximate AICc values via Kullback–Leibler divergence. Otherwise, only the AIC is updated.</p>
</td></tr>
<tr><td><code id="ctmm.boot_+3A_iterate">iterate</code></td>
<td>
<p>Iteratively solve for the parameters such that the average estimate (of <code>method</code>) is that of the data, whereas with <code>iterate=FALSE</code> only the first-order correction is calculated from the initial estimate.</p>
</td></tr>
<tr><td><code id="ctmm.boot_+3A_robust">robust</code></td>
<td>
<p>Uses robust estimates of the average and covariation for debiasing. Useful when parameters are near boundaries.</p>
</td></tr>
<tr><td><code id="ctmm.boot_+3A_error">error</code></td>
<td>
<p>Relative standard error target for bootstrap ensemble estimates and nonlinear iterations.</p>
</td></tr>
<tr><td><code id="ctmm.boot_+3A_cores">cores</code></td>
<td>
<p>Number of simulations to run in parallel. <code>cores=NULL</code> will use all cores, while <code>cores&lt;0</code> will reserve <code>abs(cores)</code>.</p>
</td></tr>
<tr><td><code id="ctmm.boot_+3A_trace">trace</code></td>
<td>
<p>Report progress updates. Can be among <code>0:2</code> with increasing detail.</p>
</td></tr>
<tr><td><code id="ctmm.boot_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <code><a href="#topic+ctmm.fit">ctmm.fit</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A model fit object with relatively unbiased estimates of location covariance, and autocorrelation timescales (and more accurate CIs than <code>ctmm.fit</code>). If <code>AICc=TRUE</code>, then, in addition to an updated <code>AICc</code> slot, the model fit object will also contain a <code>VAR.AICc</code> slot quantifying the numerical variance in the <code>AICc</code> estimate. This variance can be decreased by decreasing argument <code>error</code>.</p>


<h3>Author(s)</h3>

<p> C. H. Fleming. </p>


<h3>References</h3>

<p>C. H. Fleming, M. J. Noonan, E. P. Medici, J. M. Calabrese,
&ldquo;Overcoming the challenge of small effective sample sizes in home-range estimation&rdquo;,
Methods in Ecology and Evolution 10:10, 1679-1689 (2019) <a href="https://doi.org/10.1111/2041-210X.13270">doi:10.1111/2041-210X.13270</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+ctmm.fit">ctmm.fit</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load package and data
library(ctmm)
data(gazelle)
DATA &lt;- gazelle[[3]]

GUESS &lt;- ctmm.guess(DATA,interactive=FALSE)
FIT &lt;- ctmm.select(DATA,GUESS)

# some human-readable information
summary(FIT)

# in general, you will want to set iterate=TRUE,trace=TRUE
BOOT &lt;- ctmm.boot(DATA,FIT,iterate=FALSE,trace=FALSE)

# compare to the previous estimate
summary(BOOT)
</code></pre>

<hr>
<h2 id='difference'>Estimate the proximity of two individuals</h2><span id='topic+difference'></span><span id='topic+midpoint'></span><span id='topic+proximity'></span><span id='topic+distances'></span>

<h3>Description</h3>

<p>Given a pair of <code>telemetry</code> objects and <code>ctmm</code> movement models, predict their location differences or midpoints at shared times and estimate their distances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>difference(data,CTMM,t=NULL,...)

midpoint(data,CTMM,t=NULL,complete=FALSE,...)

distances(data,CTMM,t=NULL,level=0.95,...)

proximity(data,CTMM,t=NULL,GUESS=ctmm(error=TRUE),debias=TRUE,level=0.95,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="difference_+3A_data">data</code></td>
<td>
<p>A <code>list</code> of two <code>telemetry</code> objects.</p>
</td></tr>
<tr><td><code id="difference_+3A_ctmm">CTMM</code></td>
<td>
<p>A <code>list</code> of two <code>ctmm</code> movement-model objects.</p>
</td></tr>
<tr><td><code id="difference_+3A_t">t</code></td>
<td>
<p>An optional vector of times or range of times over which to predict the location differences.</p>
</td></tr>
<tr><td><code id="difference_+3A_complete">complete</code></td>
<td>
<p>Additionally calculate timestamps and geographic coordinates.</p>
</td></tr>
<tr><td><code id="difference_+3A_level">level</code></td>
<td>
<p>Confidence level for the distance/proximity estimate.</p>
</td></tr>
<tr><td><code id="difference_+3A_guess">GUESS</code></td>
<td>
<p>An optional <code>ctmm</code> object to specify the candidate model parameters of the location differences.</p>
</td></tr>
<tr><td><code id="difference_+3A_debias">debias</code></td>
<td>
<p>Include inverse-<code class="reqn">\chi^2</code> bias corrections.</p>
</td></tr>
<tr><td><code id="difference_+3A_...">...</code></td>
<td>
<p>Options passed to <code><a href="#topic+ctmm.select">ctmm.select</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>difference</code> function predicts the location difference vectors, <code class="reqn">(x_A-x_B,y_A-y_B)</code>, for a pair of individuals, <code class="reqn">\{A,B\}</code>, at overlapping times. The <code>midpoint</code> function predicts the location midpoints, <code class="reqn">(x_A+x_B,y_A+y_B)/2</code>, for a pair of individuals. The <code>distances</code> function further estimates the instantaneous distances between individuals. The <code>proximity</code> function fits an autocorrelation model to the output of <code>difference</code>, and then compares the mean-square distance between the individuals to what you would expect if the two individuals were moving independently.
</p>


<h3>Value</h3>

<p><code>difference</code> and <code>midpoint</code> output <code>telemetry</code> objects of the location differences and midpoints with prediction covariances. <code>distances</code> outputs a <code>data.frame</code> of distance estimates with confidence intervals. <code>proximity</code> outputs a ratio estimate with confidence intervals, where values <code>&lt;1</code> indiciate that the two individuals are closer on average than expected for independent movement, <code>1</code> is consistent with independent movement, and values <code>&gt;1</code> indicate that the individuals are farther from each other on average than expected for independent movement. Therefore, if the CIs contain 1, then the distance is insignificant with a p-value threshold of <code>1-level</code> (two-sided) or half that for a one-sided test.</p>


<h3>Author(s)</h3>

<p> C. H. Fleming. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+ctmm.select">ctmm.select</a></code>, <code><a href="#topic+predict.ctmm">predict.ctmm</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Load package
library(ctmm)

# load buffalo data
data(buffalo)

# select two buffalo that overlap in space and time
DATA &lt;- buffalo[c(1,3)]
# plot the two buffalo
plot(DATA,col=c('red','blue'))

FITS &lt;- list()
for(i in 1:2)
{
  GUESS &lt;- ctmm.guess(DATA[[i]],interactive=FALSE)
  # in general, you want to use ctmm.select
  FITS[[i]] &lt;- ctmm.fit(DATA[[i]],GUESS)
}

# calculate difference vectors
DIFF &lt;- difference(DATA,FITS)
# plot the difference vectors with prediction-error ellipses
plot(DIFF)

# calculate the proximity statistic
# disabling location error for speed
proximity(DATA,FITS,GUESS=ctmm(error=FALSE))
</code></pre>

<hr>
<h2 id='distance'>Calculate the square distance between two distributions or location estimates</h2><span id='topic+distance'></span>

<h3>Description</h3>

<p>This function calculates various square distances measures between distributions,
including the, Bhattacharyya distance, Mahalanobis distance, and Euclidean distance.</p>


<h3>Usage</h3>

<pre><code class='language-R'> distance(object,method="Mahalanobis",sqrt=FALSE,level=0.95,debias=TRUE,...) </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="distance_+3A_object">object</code></td>
<td>
<p>A <code>list</code> of <code>ctmm</code> fit objects or single-location <code>telemetry</code> objects to compare.</p>
</td></tr>
<tr><td><code id="distance_+3A_method">method</code></td>
<td>
<p>Square distance measure to return: <code>"Bhattacharyya"</code>, <code>"Mahalanobis"</code>, or <code>"Euclidean"</code>.</p>
</td></tr>
<tr><td><code id="distance_+3A_sqrt">sqrt</code></td>
<td>
<p>Return the linear distance.</p>
</td></tr>
<tr><td><code id="distance_+3A_level">level</code></td>
<td>
<p>The confidence level desired for the output.</p>
</td></tr>
<tr><td><code id="distance_+3A_debias">debias</code></td>
<td>
<p>Approximate debiasing of the square distance.</p>
</td></tr>
<tr><td><code id="distance_+3A_...">...</code></td>
<td>
<p>Not currently used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with tables <code>DOF</code>, containing the effective samples sizes of the estimates, and <code>CI</code>, containing the confidence intervals of the distance estimates. A value of <code>0</code> implies that the two distributions have the same mean location, while larger values imply that the two distributions are farther apart. The (square) Euclidean distance has units of square meters, if <code>sqrt=FALSE</code>. The square Mahalanobis and Bhattacharyya distances are unitless. For the Euclidean distance, only the centroids are compared.
</p>


<h3>Note</h3>

<p>The Bhattacharyya distance (BD) is naturally of a squared form and is not further squared.</p>


<h3>Author(s)</h3>

<p>C. H. Fleming</p>


<h3>See Also</h3>

 <p><code><a href="#topic+ctmm.fit">ctmm.fit</a></code>, <code><a href="#topic+overlap">overlap</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load package and data
library(ctmm)
data(buffalo)

# fit models for first two buffalo
GUESS &lt;- lapply(buffalo[1:2], function(b) ctmm.guess(b,interactive=FALSE) )
# using ctmm.fit here for speed, but you should almost always use ctmm.select
FITS &lt;- lapply(1:2, function(i) ctmm.fit(buffalo[[i]],GUESS[[i]]) )
names(FITS) &lt;- names(buffalo[1:2])

# Mahalanobis distance between these two buffalo
distance(FITS)
</code></pre>

<hr>
<h2 id='dt.plot'>Functions for diagnosing sampling schedules</h2><span id='topic+dt.plot'></span>

<h3>Description</h3>

<p>Produces a log-scale plot of the sorted sampling intervals for inspection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dt.plot(data,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dt.plot_+3A_data">data</code></td>
<td>
<p>A <code>telemetry</code> object.</p>
</td></tr>
<tr><td><code id="dt.plot_+3A_...">...</code></td>
<td>
<p>Additional options passed to <code>plot</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Horizontal lines are included at common sampling intervals (e.g., 1-hour) and dimmed horizontal lines are included at common subdivisions (e.g., 30-minutes).</p>


<h3>Author(s)</h3>

<p>C. H. Fleming.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+as.telemetry">as.telemetry</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'># Load package and data
library(ctmm)
data(gazelle)

# Plot the sampling intervals
dt.plot(gazelle)
</code></pre>

<hr>
<h2 id='emulate'>Draw a random model-fit from the sampling distribution</h2><span id='topic+emulate'></span><span id='topic+emulate.ctmm'></span><span id='topic+emulate.telemetry'></span>

<h3>Description</h3>

<p>This function generates random model-fit statistics from the sampling distribution of a given <code>ctmm</code> movement model and sampling schedule.
If <code>fast=FALSE</code>, the results are exact, though slow to evaluate.
Else if <code>fast=TRUE</code>, the central-limit theorem is invoked.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emulate(object,...)

## S3 method for class 'ctmm'
emulate(object,data=NULL,fast=FALSE,...)

## S3 method for class 'telemetry'
emulate(object,CTMM,fast=FALSE,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="emulate_+3A_object">object</code></td>
<td>
<p><code>telemetry</code> data or <code>ctmm</code> model object.</p>
</td></tr>
<tr><td><code id="emulate_+3A_ctmm">CTMM</code></td>
<td>
<p>A <code>ctmm</code> movement-model object.</p>
</td></tr>
<tr><td><code id="emulate_+3A_data">data</code></td>
<td>
<p>Optional <code>telemetry</code> object for exact results.</p>
</td></tr>
<tr><td><code id="emulate_+3A_fast">fast</code></td>
<td>
<p>Whether or not to invoke the central-limit theorem.</p>
</td></tr>
<tr><td><code id="emulate_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code><a href="#topic+ctmm.fit">ctmm.fit</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given <code>fast=FALSE</code>, which requires the <code>data</code> argument specified, new data are simulated from the <code>CTMM</code> movement model with the same sampling schedule and error structure as <code>data</code>. A new model, of the same structure as <code>CTMM</code>, is then fit to the simulated data and returned.
</p>
<p>Given <code>fast=TRUE</code>, a model-fit object is sampled from the central-limit distribution, using the covariance estimates within <code>CTMM</code>.
Strictly positive parametes, such as area, are log-transformed prior to the normal approximation.
Note that this faster method does not adjust for bias.
</p>


<h3>Value</h3>

<p> A <code>ctmm</code> movement model with the same structure as <code>CTMM</code>.</p>


<h3>Author(s)</h3>

<p> C. H. Fleming. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+ctmm.fit">ctmm.fit</a></code>, <code><a href="#topic+simulate.ctmm">simulate.ctmm</a></code> </p>

<hr>
<h2 id='encounter'>Encounter statistics</h2><span id='topic+encounter'></span><span id='topic+cde'></span>

<h3>Description</h3>

<p>Functions to calculate encounter probabilities and the conditional location distribution of where encounters take place (conditional on said encounters taking place), as described in Noonan et al (2021).</p>


<h3>Usage</h3>

<pre><code class='language-R'>encounter(object,debias=FALSE,level=0.95,normalize=FALSE,self=TRUE,...)

cde(object,include=NULL,exclude=NULL,debias=FALSE,...) </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="encounter_+3A_object">object</code></td>
<td>
<p>A <code>list</code> of aligned <code>UD</code> objects.</p>
</td></tr>
<tr><td><code id="encounter_+3A_debias">debias</code></td>
<td>
<p>Approximate bias corrections [IN DEVELOPMENT].</p>
</td></tr>
<tr><td><code id="encounter_+3A_level">level</code></td>
<td>
<p>Confidence level for relative encounter rates.</p>
</td></tr>
<tr><td><code id="encounter_+3A_normalize">normalize</code></td>
<td>
<p>Normalize relative encounter rates by the average uncorrelated self-encounter rate.</p>
</td></tr>
<tr><td><code id="encounter_+3A_self">self</code></td>
<td>
<p>Fix the self-interaction rate appropriately.</p>
</td></tr>
<tr><td><code id="encounter_+3A_include">include</code></td>
<td>
<p>A matrix of interactions to include in the calculation (see Details below).</p>
</td></tr>
<tr><td><code id="encounter_+3A_exclude">exclude</code></td>
<td>
<p>A matrix of interactions to exclude in the calculation (see Details below).</p>
</td></tr>
<tr><td><code id="encounter_+3A_...">...</code></td>
<td>
<p>Additional arguments for future use.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Encounter probabilities are standardized to 1 meter, and must be multiplied by the square encounter radius (in meters), to obtain other values. If <code>normalize=FALSE</code>, the relative encounter rates have units of <code class="reqn">1/m^2</code> and tend to be very small numbers for very large home-range areas. If <code>normalize=TRUE</code>, the relative encounter rates are normalized by the average uncorrelated self-encounter rate, which is an arbitrary value that provides a convenient scaling.
</p>
<p>The <code>include</code> argument is a matrix that indicates which interactions are considered in the calculation.
By default, <code>include = 1 - diag(length(object))</code>, which implies that all interactions are considered aside from self-interactions. Alternatively, <code>exclude = 1 - include</code> can be specified, and is by-default <code>exclude = diag(length(object))</code>, which implies that only self-encounters are excluded.
</p>


<h3>Value</h3>

<p><code>encounter</code> produces an array of standardized encounter probabilities with CIs, while <code>cde</code> produces a single <code>UD</code> object.</p>


<h3>Note</h3>

<p>Prior to v1.2.0, <code>encounter()</code> calculated the CDE and <code>rates()</code> calculated relative encounter probabilities.</p>


<h3>Author(s)</h3>

<p>C. H. Fleming</p>


<h3>References</h3>

<p>M. J. Noonan, R. Martinez-Garcia, G. H. Davis, M. C. Crofoot, R. Kays, B. T. Hirsch, D. Caillaud, E. Payne, A. Sih, D. L. Sinn, O. Spiegel, W. F. Fagan, C. H. Fleming, J. M. Calabrese, &ldquo;Estimating encounter location distributions from animal tracking data&rdquo;, Methods in Ecology and Evolution (2021) <a href="https://doi.org/10.1111/2041-210X.13597">doi:10.1111/2041-210X.13597</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+akde">akde</a></code>, <code><a href="#topic+overlap">overlap</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load package and data
library(ctmm)
data(buffalo)

# fit models for first two buffalo
GUESS &lt;- lapply(buffalo[1:2], function(b) ctmm.guess(b,interactive=FALSE) )
# in general, you should use ctmm.select here
FITS &lt;- lapply(1:2, function(i) ctmm.fit(buffalo[[i]],GUESS[[i]]) )
names(FITS) &lt;- names(buffalo[1:2])

# create aligned UDs
UDS &lt;- akde(buffalo[1:2],FITS)

# calculate 100-meter encounter probabilities
P &lt;- encounter(UDS)
P$CI * 100^2

# calculate CDE
CDE &lt;- cde(UDS)

# plot data and encounter distribution
plot(buffalo[1:2],col=c('red','blue'),UD=CDE,col.DF='purple',col.level='purple',col.grid=NA)
</code></pre>

<hr>
<h2 id='export'>Export ctmm data formats</h2><span id='topic+export'></span><span id='topic+as.sf'></span><span id='topic+raster+2CUD-method'></span><span id='topic+SpatialPoints.telemetry'></span><span id='topic+SpatialPointsDataFrame.telemetry'></span><span id='topic+SpatialPolygonsDataFrame.telemetry'></span><span id='topic+SpatialPolygonsDataFrame.UD'></span><span id='topic+writeRaster+2CUD+2Ccharacter-method'></span><span id='topic+writeVector'></span><span id='topic+writeVector+2Clist+2Ccharacter-method'></span><span id='topic+writeVector+2Clist+2Cmissing-method'></span><span id='topic+writeVector+2Ctelemetry+2Ccharacter-method'></span><span id='topic+writeVector+2Ctelemetry+2Cmissing-method'></span><span id='topic+writeVector+2CUD+2Ccharacter-method'></span><span id='topic+writeVector+2CUD+2Cmissing-method'></span>

<h3>Description</h3>

<p>Functions to export <code>ctmm</code> data formats into common <code>sp</code>, <code>sf</code>, <code>raster</code>, and ESRI formats.</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.sf(x,error=FALSE,...)

## S4 method for signature 'UD'
raster(x,DF="CDF",...)

## method for class 'telemetry'
SpatialPoints.telemetry(object,...)

## method for class 'telemetry'
SpatialPointsDataFrame.telemetry(object,...)

## method for class 'telemetry'
SpatialPolygonsDataFrame.telemetry(object,level.UD=0.95,...)

## method for class 'UD'
SpatialPolygonsDataFrame.UD(object,convex=FALSE,level.UD=0.95,level=0.95,...)

## S4 method for signature 'UD,character'
writeRaster(x,filename,format,DF="CDF",...)

## S4 method for signature 'list,character'
writeVector(x,filename,...)

## S4 method for signature 'list,missing'
writeVector(x,filename,...)

## S4 method for signature 'telemetry,character'
writeVector(x,filename,filetype="ESRI Shapefile",error=TRUE,level.UD=0.95,...)

## S4 method for signature 'telemetry,missing'
writeVector(x,filename,filetype="ESRI Shapefile",error=TRUE,level.UD=0.95,...)

## S4 method for signature 'UD,character'
writeVector(x,filename,filetype="ESRI Shapefile",convex=FALSE,level.UD=0.95,level=0.95,
            ...)

## S4 method for signature 'UD,missing'
writeVector(x,filename,filetype="ESRI Shapefile",convex=FALSE,level.UD=0.95,level=0.95,
            ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="export_+3A_x">x</code></td>
<td>
 <p><code>telemetry</code> or <code>UD</code> object. </p>
</td></tr>
<tr><td><code id="export_+3A_error">error</code></td>
<td>
<p>Export <code>telemetry</code> location error circles/ellipses as polygons if <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="export_+3A_object">object</code></td>
<td>
 <p><code>telemetry</code> or <code>UD</code> object. </p>
</td></tr>
<tr><td><code id="export_+3A_convex">convex</code></td>
<td>
<p>Export convex coverage areas if <code>TRUE</code>. By default, the highest density regions (HDRs) are exported.</p>
</td></tr>
<tr><td><code id="export_+3A_level.ud">level.UD</code></td>
<td>
<p> Coverage level of the UD area. I.e., the 50% core home range would be given by <code>level.UD=0.50</code>.</p>
</td></tr>
<tr><td><code id="export_+3A_level">level</code></td>
<td>
<p> Confidence level for the magnitude of the above area. I.e., the 95% CI of the core home range area. </p>
</td></tr>
<tr><td><code id="export_+3A_df">DF</code></td>
<td>
<p>Rasterize the probability density function <code>"PDF"</code>, probability mass function <code>"PMF"</code>, or cumulative distribution function <code>"CDF"</code>.</p>
</td></tr>
<tr><td><code id="export_+3A_filename">filename</code></td>
<td>
<p>Character name of file for raster or vector file.</p>
</td></tr>
<tr><td><code id="export_+3A_format">format</code></td>
<td>
<p>Output file type (see <code><a href="raster.html#topic+writeFormats">writeFormats</a></code>). If this argument is not provided, it is inferred it from the filename extension. If that fails, the default <code>'raster'</code> format is used, which can be changed using <code><a href="raster.html#topic+rasterOptions">rasterOptions</a></code>.</p>
</td></tr>
<tr><td><code id="export_+3A_filetype">filetype</code></td>
<td>
<p>A file format associated with a GDAL &quot;driver&quot;. See <code>gdal(drivers=TRUE)</code> or the <a href="https://gdal.org/drivers/vector/index.html">GDAL docs</a>. If <code>filetype=NULL</code>, the filetype is inferred from the filename extension.</p>
</td></tr>
<tr><td><code id="export_+3A_...">...</code></td>
<td>
<p> Optional arguments passed to <code><a href="raster.html#topic+writeRaster">writeRaster</a></code>, <code><a href="terra.html#topic+writeVector">writeVector</a></code>, etc..</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>as.sf</code> exports <code>ctmm</code> objects to the <code>sf</code> format. Arguments to <code>ctmm</code> <code>Spatial</code>* export functions can also be used, such as <code>level.UD</code> and <code>level</code>.
</p>
<p><code>raster</code> exports <code>UD</code> object point-estimates distribution functions (<code>DF</code>) to <code>raster</code> objects.
<code>DF="PDF"</code> gives the average probability density per cell,
<code>DF="PMF"</code> gives the total probability per cell,
and <code>DF="CDF"</code> gives the cumulative probability.
</p>
<p><code>Spatial</code>* functions export <code>ctmm</code> objects to <code>sp</code> formats.
</p>
<p><code>writeRaster</code> writes a raster file to disk, with pixel values corresponding to the distribution function <code>DF</code>.
</p>
<p><code>writeVector</code> writes a shapefile to disk, with UD polygons corresponding to the low-CI, point-estimate, and high-CI home-range area estimates.
</p>


<h3>Value</h3>

<p><code>as.sf</code> returns an <code>sf</code> object for the input points or polygons, with individual identity and other information retained.
</p>
<p><code>raster</code> returns a <code>raster</code> of the point-estimate distribution function <code>DF</code>, given a <code>UD</code> object.
</p>
<p><code>SpatialPoints.telemetry</code> returns a single <code>spatialPoints</code> object for the <code>x</code>-<code>y</code> locations, without individual identity and other information retained.
</p>
<p><code>SpatialPointsDataFrame.telemetry</code> returns a <code>SpatialPointsDataFrame</code> with the individual identities and other data recorded in the data frame retained.
</p>
<p><code>SpatialPolygonsDataFrame.telemetry</code> returns a <code>SpatialPolygonsDataFrame</code> that encodes the location estimate's error circles/ellipses.
</p>
<p><code>SpatialPolygonsDataFrame.UD</code> returns a <code>SpatialPolygonsDataFrame</code> of the low-CI, point-estimate, and high-CI home-range area estimates, in the appropriate order for plotting.
</p>


<h3>Author(s)</h3>

<p>C. H. Fleming and K. Safi.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+akde">akde</a></code>, <code><a href="#topic+as.telemetry">as.telemetry</a></code>, <code><a href="#topic+occurrence">occurrence</a></code>. </p>

<hr>
<h2 id='extent'>Extent</h2><span id='topic+extent'></span><span id='topic+extent+2Ctelemetry-method'></span><span id='topic+extent+2Cctmm-method'></span><span id='topic+extent+2CUD-method'></span><span id='topic+extent+2Cvariogram-method'></span><span id='topic+extent+2Clist-method'></span><span id='topic+extent+2Cdata.frame-method'></span><span id='topic+extent+2Cmatrix-method'></span>

<h3>Description</h3>

<p>Functions to calculate the <code class="reqn">(x,y)</code> plotting extent (or bounding box) of various ctmm objects or list of such objects, for use when plotting multiple ctmm objects.</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S4 method for signature 'telemetry'
extent(x,level=1,...)

## S4 method for signature 'ctmm'
extent(x,level=0.95,level.UD=0.95,...)

## S4 method for signature 'UD'
extent(x,level=0.95,level.UD=0.95,complete=FALSE,...)

## S4 method for signature 'variogram'
extent(x,level=0.95,threshold=2,...)

## S4 method for signature 'list'
extent(x,...)

## S4 method for signature 'data.frame'
extent(x,level=1,...)

## S4 method for signature 'matrix'
extent(x,level=1,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extent_+3A_x">x</code></td>
<td>
<p>A <code>telemetry</code>, <code>ctmm</code>, or <code>UD</code> object. </p>
</td></tr>
<tr><td><code id="extent_+3A_level">level</code></td>
<td>
<p> For <code>telemetry</code> objects, this is the fraction of locations bounded, according to two-sided quantiles. For <code>ctmm</code> and <code>UD</code> objects, this is confidence level for the magnitude of the utilization area circumscribed by <code>level.UD</code>. </p>
</td></tr>
<tr><td><code id="extent_+3A_level.ud">level.UD</code></td>
<td>
<p> Coverage level of the UD area. I.e., the 50% core home range would be given by <code>level.UD=0.50</code>. </p>
</td></tr>
<tr><td><code id="extent_+3A_complete">complete</code></td>
<td>
<p> Also calculate longitude-latitude extent of <code>UD</code> objects. </p>
</td></tr>
<tr><td><code id="extent_+3A_threshold">threshold</code></td>
<td>
<p>Limit <code>ylim</code> to <code>threshold</code> times the maximum semi-variance, even if the <code>level</code> confidence intervals exceed this amount.</p>
</td></tr>
<tr><td><code id="extent_+3A_...">...</code></td>
<td>
<p> Optional arguments for future extensions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns a <code>data.frame</code> with columns <code>x</code> and <code>y</code> with rows <code>min</code> and <code>max</code>.
See <code>vignette('akde')</code> for an example of <code>extent</code> used to plot multiple UDs on the same scale.
</p>


<h3>Author(s)</h3>

<p>C. H. Fleming</p>


<h3>See Also</h3>

 <p><code><a href="#topic+plot.telemetry">plot.telemetry</a></code>, <code><a href="#topic+plot.variogram">plot.variogram</a></code>. </p>

<hr>
<h2 id='format'>Scientific formatting of numbers</h2><span id='topic+sigfig'></span><span id='topic+dimfig'></span>

<h3>Description</h3>

<p>Functions for concisely representing dimensionful quantities and uncertain quantities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dimfig(data,dimension,thresh=1,...)

sigfig(est,VAR=NULL,SD=NULL,level=0.95,digits=2,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="format_+3A_data">data</code></td>
<td>
<p>A numerical vector of dimensionful quantities represented in SI units.</p>
</td></tr>
<tr><td><code id="format_+3A_dimension">dimension</code></td>
<td>
<p>One of <code>"length"</code>, <code>"area"</code>, <code>"time"</code>, <code>"frequency"</code>, <code>"speed"</code>, <code>"diffusion"</code>, or <code>"mass"</code>.</p>
</td></tr>
<tr><td><code id="format_+3A_thresh">thresh</code></td>
<td>
<p>Threshold quantity for switching between units. E.g., 100 cm is represented as 1 m only if <code>thresh&gt;=1</code>.</p>
</td></tr>
<tr><td><code id="format_+3A_est">est</code></td>
<td>
<p>Can be either confidence-interval estimates with rows (lower-limit,point-estimate,upper-limit) or point estimates (with <code>VAR</code> or <code>SD</code> also specified).</p>
</td></tr>
<tr><td><code id="format_+3A_var">VAR</code></td>
<td>
<p>Variance in the sampling distribution of <code>x</code>.</p>
</td></tr>
<tr><td><code id="format_+3A_sd">SD</code></td>
<td>
<p>Standard deviation in the sampling distribution of <code>x</code>.</p>
</td></tr>
<tr><td><code id="format_+3A_level">level</code></td>
<td>
<p>Confidence level for designating the numerical precision of the significant digits.</p>
</td></tr>
<tr><td><code id="format_+3A_digits">digits</code></td>
<td>
<p>Number of significant digits to retain.</p>
</td></tr>
<tr><td><code id="format_+3A_...">...</code></td>
<td>
<p>Not currently used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>dimfig</code> chooses the set of units that provides the most concise representation for <code>data</code>, and <code>sigfig</code> concisely represents statistical estimates with a fixed number of significant digits.</p>


<h3>Value</h3>

<p><code>dimfig</code> returns a <code>list</code> with slots for the converted <code>data</code> and the name of the most concise units. <code>sigfig</code> returns a character string that is formated with the specified number of significant digits.</p>


<h3>Author(s)</h3>

<p> C. H. Fleming. </p>


<h3>See Also</h3>

 <p><code><a href="#topic++25+23+25">%#%</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load package and data
library(ctmm)
data(buffalo)
DATA &lt;- buffalo$Cilla

GUESS &lt;- ctmm.guess(DATA,interactive=FALSE)
# in general, you want to run ctmm.select instead
FIT &lt;- ctmm.fit(DATA,GUESS)

# raw summary (SI units)
summary(FIT,units=FALSE)

# default summary (concise units)
summary(FIT,units=TRUE)

# text-formatted summary
sigfig( summary(FIT)$CI )
</code></pre>

<hr>
<h2 id='gazelle'>Mongolian gazelle GPS dataset from the Mongolia's Eastern Steppe.</h2><span id='topic+gazelle'></span>

<h3>Description</h3>

<p><code>x-y</code> projected GPS data on 36 Mongolian gazelle.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("gazelle")</code></pre>


<h3>Format</h3>

<p> A list of 36 <code>telemetry</code> objects.</p>


<h3>References</h3>

<p>C. H. Fleming, J. M. Calabrese, T. Mueller, K.A. Olson, P. Leimgruber, and W. F. Fagan. Data from: From fine-scale foraging to home ranges: A semi-variance approach to identifying movement modes across spatiotemporal scales. Dryad Digital Repository (2014) <a href="https://doi.org/10.5061/dryad.45157">doi:10.5061/dryad.45157</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+as.telemetry">as.telemetry</a></code>, <code><a href="#topic+plot.telemetry">plot.telemetry</a></code>, <code><a href="#topic+buffalo">buffalo</a></code>, <code><a href="#topic+coati">coati</a></code>, <code><a href="#topic+jaguar">jaguar</a></code>, <code><a href="#topic+pelican">pelican</a></code>, <code><a href="#topic+turtle">turtle</a></code>, <code><a href="#topic+wolf">wolf</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'># Load package and data
library(ctmm)
data("gazelle")

# Plot a gazelle's locations
plot(gazelle[[18]])
</code></pre>

<hr>
<h2 id='homerange'>Calculate a range distribution estimate</h2><span id='topic+homerange'></span><span id='topic+agde'></span><span id='topic+suitability'></span>

<h3>Description</h3>

<p>Estimates the range distributions and suitability from <code>telemetry</code> data and a continuous-time movement model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>homerange(data,CTMM,method="AKDE",...)

agde(data=NULL,CTMM=NULL,R=list(),variable="utilization",error=0.001,res=100,grid=NULL,
     ...)

suitability(data=NULL,CTMM=NULL,R=list(),level=0.95,grid=NULL,log=FALSE,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="homerange_+3A_data">data</code></td>
<td>
<p> 2D timeseries telemetry data represented as a <code>telemetry</code> object. </p>
</td></tr>
<tr><td><code id="homerange_+3A_ctmm">CTMM</code></td>
<td>
<p>A <code>ctmm</code> movement model from the output of <code>ctmm.fit</code>.</p>
</td></tr>
<tr><td><code id="homerange_+3A_method">method</code></td>
<td>
<p>Which range distribution method to use. Can be &quot;AKDE&quot; or &quot;AGDE&quot;.</p>
</td></tr>
<tr><td><code id="homerange_+3A_...">...</code></td>
<td>
<p>Arguments passed to the method call or <code><a href="#topic+bandwidth">bandwidth</a></code>.</p>
</td></tr>
<tr><td><code id="homerange_+3A_r">R</code></td>
<td>
<p>A named list of raster covariates if <code>CTMM</code> contains an RSF model</p>
</td></tr>
<tr><td><code id="homerange_+3A_variable">variable</code></td>
<td>
<p>Not yet supported.</p>
</td></tr>
<tr><td><code id="homerange_+3A_error">error</code></td>
<td>
<p>Target probability error.</p>
</td></tr>
<tr><td><code id="homerange_+3A_res">res</code></td>
<td>
<p>Number of grid points along each axis, relative to the location covariance.</p>
</td></tr>
<tr><td><code id="homerange_+3A_grid">grid</code></td>
<td>
<p>Grid specification via <code>raster</code>, <code>UD</code>, or list of arguments (See <code><a href="#topic+akde">akde</a></code> for details).</p>
</td></tr>
<tr><td><code id="homerange_+3A_level">level</code></td>
<td>
<p>Confidence level for output confidence intervals.</p>
</td></tr>
<tr><td><code id="homerange_+3A_log">log</code></td>
<td>
<p>Calculate the log(suitability).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>homerange</code> is a wrapper function that calls either <code><a href="#topic+akde">akde</a></code> or <code>agde</code>. Please consult <code><a href="#topic+akde">akde</a></code> for further details on <code>method="AKDE"</code>.
</p>
<p><code>suitability</code> calculates a suitability raster from an <code><a href="#topic+rsf.fit">rsf.fit</a></code> object. Population RSF fit objects calculated from <code><a href="base.html#topic+mean">mean</a></code> will produce a suitability estimate of the population.
</p>
<p><code>agde</code> calculates autocorrelated Gaussian and RSF home-range areas.</p>


<h3>Value</h3>

<p><code>homerange</code> and <code>agde</code> return a <code>UD</code> object. <code>suitability</code> returns a <code><a href="raster.html#topic+brick">brick</a></code> object.</p>


<h3>Author(s)</h3>

<p> C. H. Fleming. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+akde">akde</a></code>, <code><a href="#topic+raster+2CUD-method">raster,UD-method</a></code> </p>

<hr>
<h2 id='intensity'>Compare empirical and theoretical intensity (resource-selection) functions [IN DEVELOPMENT]</h2><span id='topic+intensity'></span>

<h3>Description</h3>

<p>This function plots the empirical and theoretical intensity functions with respect to a covariate of interest.</p>


<h3>Usage</h3>

<pre><code class='language-R'>intensity(data,UD,RSF,R=list(),variable=NULL,empirical=FALSE,level=0.95,ticks=TRUE,
          smooth=TRUE,interpolate=TRUE,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="intensity_+3A_data">data</code></td>
<td>
<p>A <code>telemetry</code> object.</p>
</td></tr>
<tr><td><code id="intensity_+3A_ud">UD</code></td>
<td>
<p>A <code>UD</code> object generated by <code><a href="#topic+akde">akde</a></code> from the same telemetry object as <code>data</code>. If weights were optimized in <code><a href="#topic+akde">akde</a></code>, then they will be adopted by <code>intensity</code>.</p>
</td></tr>
<tr><td><code id="intensity_+3A_rsf">RSF</code></td>
<td>
<p>An iRSF model-fit object from <code>rsf.fit</code> or <code>rsf.select</code>.</p>
</td></tr>
<tr><td><code id="intensity_+3A_r">R</code></td>
<td>
<p>A named list of rasters or time-varying raster stacks [NOT TESTED] to fit Poisson regression coefficients to (under a log link).</p>
</td></tr>
<tr><td><code id="intensity_+3A_variable">variable</code></td>
<td>
<p>Variable of interest from <code>names(R)</code>.</p>
</td></tr>
<tr><td><code id="intensity_+3A_empirical">empirical</code></td>
<td>
<p>Plot an empirical estimate of <code class="reqn">\log\lambda</code> [IN DEVELOPMENT].</p>
</td></tr>
<tr><td><code id="intensity_+3A_level">level</code></td>
<td>
<p>Confidence level for intensity function estimates.</p>
</td></tr>
<tr><td><code id="intensity_+3A_ticks">ticks</code></td>
<td>
<p>Demark used resource values atop the plot.</p>
</td></tr>
<tr><td><code id="intensity_+3A_smooth">smooth</code></td>
<td>
<p>Apply location-error smoothing to the tracking data before regression.</p>
</td></tr>
<tr><td><code id="intensity_+3A_interpolate">interpolate</code></td>
<td>
<p>Whether or not to interpolate raster values during extraction.</p>
</td></tr>
<tr><td><code id="intensity_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code><a href="#topic+plot">plot</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>With resepct to the Poisson point process likelihood <code class="reqn">L(\lambda)=\frac{\lambda(x,y)}{\iint \lambda(x',y') \, dx' dy'}</code>, the <code>formula</code> object of a ctmm iRSF model corresponds to the covariate dependence of <code class="reqn">\log(\lambda)</code>, which is typically of the form <code class="reqn">\boldsymbol{\beta} \cdot \mathbf{R}</code>. <code>intensity</code> plots both empirical (black) and theoretical (red) estimates of the log-intensity (or log-selection) function <code class="reqn">\log(\lambda)</code> as a function of the covariate <code>variable</code>, which provides a visualization of what the true <code>formula</code> looks like and how the fitted model compares. The empirical estimate is semi-parametric, in that it assumes that <code>RSF</code> is correct for all variables other than <code>variable</code>.
</p>


<h3>Note</h3>

<p>Only relative differences in <code class="reqn">\log(\lambda)</code> are meaningful.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+rsf.fit">rsf.fit</a></code>. </p>

<hr>
<h2 id='jaguar'>Jaguar data from the Jaguar movement database.</h2><span id='topic+jaguar'></span>

<h3>Description</h3>

<p><code>x-y</code> projected GPS data on 4 jaguar.
Please cite Morato et al (2018) when publishing with these data.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("jaguar")</code></pre>


<h3>Format</h3>

<p> A list of 4 <code>telemetry</code> objects.</p>


<h3>References</h3>

<p>R. G. Morato et al,
&ldquo;Jaguar movement database: a GPS-based movement dataset of an apex predator in the Neotropic&rdquo;,
Ecology, 99:7, 1691-1691 (2018) <a href="https://doi.org/10.1002/ecy.2379">doi:10.1002/ecy.2379</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+as.telemetry">as.telemetry</a></code>, <code><a href="#topic+plot.telemetry">plot.telemetry</a></code>, <code><a href="#topic+buffalo">buffalo</a></code>, <code><a href="#topic+coati">coati</a></code>, <code><a href="#topic+gazelle">gazelle</a></code>, <code><a href="#topic+pelican">pelican</a></code>, <code><a href="#topic+turtle">turtle</a></code>, <code><a href="#topic+wolf">wolf</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'># Load package and data
library(ctmm)
data("jaguar")

# Plot all jaguar locations
plot(jaguar,col=rainbow(length(jaguar)))
</code></pre>

<hr>
<h2 id='Log'>Log transformation of parameter estimates and their uncertainties</h2><span id='topic+Log'></span><span id='topic+Exp'></span>

<h3>Description</h3>

<p>Methods for log transforming individual parameter estimates and their uncertainty estimates for use in meta-analytic regression, and then back-transforming mean-log parameter estimates back to mean parameter estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Log(x,variable="area",debias=TRUE,...)

Exp(est,VAR.est=0,VAR=0,VAR.VAR=0,variable="area",debias=TRUE,level=0.95,units=TRUE,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Log_+3A_x">x</code></td>
<td>
<p>A list of <code>UD</code> objects, <code>UD</code> <code>summary</code> objects, or <code>speed</code> objects.</p>
</td></tr>
<tr><td><code id="Log_+3A_variable">variable</code></td>
<td>
<p>Can be <code>"area"</code>, <code>"diffusion"</code>, <code>"speed"</code>, <code>"tau position"</code>, or <code>"tau velocity"</code>.</p>
</td></tr>
<tr><td><code id="Log_+3A_debias">debias</code></td>
<td>
<p>Apply <code class="reqn">\log\chi^2</code> and <code class="reqn">\log\chi</code> bias corrections if <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="Log_+3A_...">...</code></td>
<td>
<p>Further arguments passed.</p>
</td></tr>
<tr><td><code id="Log_+3A_est">est</code></td>
<td>
<p>Point estimate of the mean log-parameter.</p>
</td></tr>
<tr><td><code id="Log_+3A_var.est">VAR.est</code></td>
<td>
<p>Uncertainty in the mean log-parameter estimate (square standard error).</p>
</td></tr>
<tr><td><code id="Log_+3A_var">VAR</code></td>
<td>
<p>Variance in the log-parameters.</p>
</td></tr>
<tr><td><code id="Log_+3A_var.var">VAR.VAR</code></td>
<td>
<p>Uncertainty in the log-paramter variance estimate (square standard error).</p>
</td></tr>
<tr><td><code id="Log_+3A_level">level</code></td>
<td>
<p>Confidence level for parameter estimates.</p>
</td></tr>
<tr><td><code id="Log_+3A_units">units</code></td>
<td>
<p>Convert result to natural units.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>Log</code> returns a list with two slots, <code>log</code> and <code>VAR.log</code>, corresponding to the point estimates and variance estimates of the logged variables.
</p>
<p><code>Exp</code> returns a confidence intervals for the back-transformed mean parameter estimate.</p>


<h3>Author(s)</h3>

<p> C. H. Fleming. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+meta">meta</a></code>, <code><a href="base.html#topic+mean">mean</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>
# load package and data
library(ctmm)
data(buffalo)

# fit movement models
FITS &lt;- AKDES &lt;- list()
for(i in 1:length(buffalo))
{
  GUESS &lt;- ctmm.guess(buffalo[[i]],interactive=FALSE)
  # use ctmm.select unless you are certain that the selected model is OUF
  FITS[[i]] &lt;- ctmm.fit(buffalo[[i]],GUESS)
}

# calculate AKDES on a consistent grid
AKDES &lt;- akde(buffalo,FITS)

# extract 95% areas
AREAS &lt;- lapply(AKDES,summary)

# log transform for further meta-analysis
LOG &lt;- Log(AREAS)

LOG
</code></pre>

<hr>
<h2 id='mean.ctmm'>Average movement models and autocorrelated kernel density estimates</h2><span id='topic+mean.ctmm'></span><span id='topic+mean.UD'></span>

<h3>Description</h3>

<p>These functions calculate population averages of continuous-time movement models and utilization distributions.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ctmm'
mean(x,weights=NULL,sample=TRUE,debias=TRUE,IC="AIC",trace=TRUE,...)

## S3 method for class 'UD'
mean(x,weights=NULL,sample=TRUE,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mean.ctmm_+3A_x">x</code></td>
<td>
<p>A list of <code>ctmm</code> objects calculated in the same projection or <code>UD</code> objects calculated on the compatible grids.</p>
</td></tr>
<tr><td><code id="mean.ctmm_+3A_weights">weights</code></td>
<td>
<p>A vector of numeric weights with the same length as <code>x</code>, specifying the relative frequency of each distribution in <code>x</code>.</p>
</td></tr>
<tr><td><code id="mean.ctmm_+3A_sample">sample</code></td>
<td>
<p><code>x</code> represents a sample of a larger population if <code>TRUE</code>, or the entire statistical population if <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="mean.ctmm_+3A_debias">debias</code></td>
<td>
<p>Include <code class="reqn">\log-\chi^2</code> and REML bias corrections.</p>
</td></tr>
<tr><td><code id="mean.ctmm_+3A_ic">IC</code></td>
<td>
<p>Model selection criterion for the anisotropy of the distribution of mean locations and covariance matrices.</p>
</td></tr>
<tr><td><code id="mean.ctmm_+3A_trace">trace</code></td>
<td>
<p>Report location and autocovariance model selection results.</p>
</td></tr>
<tr><td><code id="mean.ctmm_+3A_...">...</code></td>
<td>
<p>Additional arguments for future use.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When applied to a list of <code>ctmm</code> objects, <code>mean</code> calculates an average movement model with populaton variability estimates.
The population model is taken to be multivariate normal and log-normal.
The population mean location represents an arithmetic mean, while the population mean home-range areas, RMS speeds, and diffusion rates represent geometric means.
Location-error estimates are not correctly averaged yet.
</p>
<p>When applied to a list of <code>UD</code> objects, <code>mean</code> calculates a weighted average of autocorrelated kernel density home-range estimates from <code>akde</code>. The point estimates are correct, but the confidence-interval calculation is not yet complete.
</p>
<p>By default, uniform weights are used (<code>weights=rep(1,length(x))</code>). This can be sensible for averaging over individuals. For averaging over periods of time, users should consider weighting by the proportion of time spent in each distribution. For example, if an animal spends 4 months in its winter range, <code>x[[1]]</code>, and 7 months in its summer range, <code>x[[2]]</code>, then the annual range (sans migration corridor) would be calculated with <code>weights=c(4,7)</code>.
</p>
<p>All UDs need to be calculated on the same grid (see <code><a href="#topic+overlap">overlap</a></code> for an example).
</p>


<h3>Value</h3>

<p>When applied to a list of <code>ctmm</code> objects, <code>mean</code> returns a <code>ctmm</code> object with additional population variability parameter estimates.
</p>
<p>When applied to a list of <code>UD</code> objects, <code>mean</code> returns a <code>UD</code> object: a list with the sampled grid line locations <code>r$x</code> and <code>r$y</code>, the extent of each grid cell <code>dr</code>, the probability density and cumulative distribution functions evaluated on the sampled grid locations <code>PDF</code> &amp; <code>CDF</code>, the optimal bandwidth matrix <code>H</code>, and the effective sample size of the data in <code>DOF.H</code>.
</p>


<h3>Author(s)</h3>

<p> C. H. Fleming</p>


<h3>See Also</h3>

 <p><code><a href="#topic+akde">akde</a></code>, <code><a href="#topic+ctmm.select">ctmm.select</a></code> </p>

<hr>
<h2 id='mean.variogram'>Compute a number-weighted average of variogram objects</h2><span id='topic+mean.variogram'></span>

<h3>Description</h3>

<p>This function takes a list of variogram objects and calculates its number-weighted average variogram.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'variogram'
mean(x,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mean.variogram_+3A_x">x</code></td>
<td>
<p>A <code>variogram</code> object or list of such objects to be averaged.</p>
</td></tr>
<tr><td><code id="mean.variogram_+3A_...">...</code></td>
<td>
<p>Additional variograms if specified individually.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a <code>variogram</code> object which is a dataframe containing the lag, the semi-variance estimate at that lag, and the approximate degrees of freedom associated with the semi-variance estimate.
</p>


<h3>Note</h3>

<p>Variogram averaging should only be used when there is a degree of similarity across individual variograms.</p>


<h3>Author(s)</h3>

<p>J. M. Calabrese and C. H. Fleming
</p>


<h3>References</h3>

<p>C. H. Fleming, J. M. Calabrese, T. Mueller, K.A. Olson, P. Leimgruber, W. F. Fagan,
&ldquo;From fine-scale foraging to home ranges: A semi-variance approach to identifying movement modes across spatiotemporal scales&rdquo;, The American Naturalist, 183:5, E154-E167 (2014) <a href="https://doi.org/10.1086/675504">doi:10.1086/675504</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+plot.variogram">plot.variogram</a></code>, <code><a href="#topic+variogram">variogram</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load package and data
library(ctmm)
data(buffalo)

# Calculate a list of variograms for all similar individuals in the dataset
# the 4th buffalo has a different sampling rate
SVFS &lt;- lapply( buffalo[-4] , variogram )
# alternatively, we could variogram all at coarsest scale with variogram option dt

# Calculate the average variogram
SVF &lt;- mean(SVFS)

# Plot the mean variogram
plot(SVF)
</code></pre>

<hr>
<h2 id='meta'>Meta-analysis of movement-model parameters</h2><span id='topic+meta'></span><span id='topic+funnel'></span>

<h3>Description</h3>

<p>These functions estimate population-level mean parameters from individual movement models and related estimates, including AKDE home-range areas, while taking into account estimation uncertainty.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meta(x,variable="area",level=0.95,level.UD=0.95,method="MLE",IC="AICc",boot=FALSE,
     error=0.01,debias=TRUE,verbose=FALSE,units=TRUE,plot=TRUE,sort=FALSE,mean=TRUE,
     col="black",...)

funnel(x,y,variable="area",precision="t",level=0.95,level.UD=0.95,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meta_+3A_x">x</code></td>
<td>
<p>A named list of <code>ctmm</code> movement-model objects, <code>UD</code> objects, <code>UD</code> <code>summary</code> output, <code><a href="#topic+speed">speed</a></code> output, or 2<code class="reqn">\times</code>2 <code><a href="#topic+overlap">overlap</a></code> objects constituting a sampled population, or a named list of such lists, with each constituting a sampled population.</p>
</td></tr>
<tr><td><code id="meta_+3A_y">y</code></td>
<td>
<p>An optional named list of <code>telemetry</code> objects for the funnel-plot <code>precision</code> variable.</p>
</td></tr>
<tr><td><code id="meta_+3A_variable">variable</code></td>
<td>
<p>Biological &ldquo;effect&rdquo; variable of interest for <code>ctmm</code> object arguments. Can be <code>"area"</code>, <code>"diffusion"</code>, <code>"speed"</code>, <code>"tau position"</code>, or <code>"tau velocity"</code>.</p>
</td></tr>
<tr><td><code id="meta_+3A_precision">precision</code></td>
<td>
<p>Precision variable of interest. Can be <code>"t"</code> for sampling time period or time interval, <code>"n"</code> for nominal sample size, <code>"N"</code> or <code>"DOF"</code> for effective sample size.</p>
</td></tr>
<tr><td><code id="meta_+3A_level">level</code></td>
<td>
<p>Confidence level for parameter estimates.</p>
</td></tr>
<tr><td><code id="meta_+3A_level.ud">level.UD</code></td>
<td>
<p>Coverage level for home-range estimates. E.g., 50% core home range.</p>
</td></tr>
<tr><td><code id="meta_+3A_method">method</code></td>
<td>
<p>Statistical estimator used&mdash;either maximum likelihood estimation based (<code>"MLE"</code>) or approximate &lsquo;best linear unbiased estimator&rsquo; (<code>"BLUE"</code>)&mdash;for comparison purposes.</p>
</td></tr>
<tr><td><code id="meta_+3A_ic">IC</code></td>
<td>
<p>Information criterion to determine whether or not population variation can be estimated. Can be <code>"AICc"</code>, <code>AIC</code>, or <code>"BIC"</code>.</p>
</td></tr>
<tr><td><code id="meta_+3A_boot">boot</code></td>
<td>
<p>Perform a parametric bootstrap for confidence intervals and first-order bias correction if <code>debias=TRUE</code>.</p>
</td></tr>
<tr><td><code id="meta_+3A_error">error</code></td>
<td>
<p>Relative error tolerance for parametric bootstrap.</p>
</td></tr>
<tr><td><code id="meta_+3A_debias">debias</code></td>
<td>
<p>Apply Bessel's inverse-Gaussian correction and various other bias corrections if <code>method="MLE"</code>, REML if <code>method="BLUE"</code>, and an additional first-order correction if <code>boot=TRUE</code>.</p>
</td></tr>
<tr><td><code id="meta_+3A_verbose">verbose</code></td>
<td>
<p>Return a list of both population and meta-population analyses if <code>TRUE</code> and <code>x</code> is a list of population lists.</p>
</td></tr>
<tr><td><code id="meta_+3A_units">units</code></td>
<td>
<p>Convert result to natural units.</p>
</td></tr>
<tr><td><code id="meta_+3A_plot">plot</code></td>
<td>
<p>Generate a meta-analysis forest plot.</p>
</td></tr>
<tr><td><code id="meta_+3A_sort">sort</code></td>
<td>
<p>Sort individuals by their point estimates in forest plot.</p>
</td></tr>
<tr><td><code id="meta_+3A_mean">mean</code></td>
<td>
<p>Include population mean estimate in forest plot.</p>
</td></tr>
<tr><td><code id="meta_+3A_col">col</code></td>
<td>
<p>Color(s) for individual labels and error bars.</p>
</td></tr>
<tr><td><code id="meta_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <code>plot</code> or <code>meta</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>meta</code> employs a custom <code class="reqn">\chi^2</code>-IG hierarchical model to calculate debiased population mean estimates of positive scale parameters,
including home-range areas, diffusion rates, mean speeds, and autocorrelation timescales.
Model selection is performed between the <code class="reqn">\chi^2</code>-IG population model (with population mean and variance) and the Dirac-<code class="reqn">\delta</code> population model (population mean only).
Population &ldquo;coefficient of variation&rdquo; (CoV) estimates are also provided.
Further details are given in Fleming et al (2022).
</p>


<h3>Value</h3>

<p>If <code>x</code> constitutes a sampled population, then <code>meta</code> returns a table with rows corresponding to the population mean and coefficient of variation.
</p>
<p>If <code>x</code> constitutes a list of sampled populations, then <code>meta</code> returns confidence intervals on the population mean <code>variable</code> ratios.</p>


<h3>Note</h3>

<p>The AICc formula is approximated via the Gaussian relation.
</p>
<p>Confidence intervals depicted in the forest plot are <code class="reqn">\chi^2</code> and may differ from the output of <code>summary()</code> in the case of mean speed and timescale parameters with small effective sample sizes.
</p>
<p>As mean ratio estimates are debiased, reciprocal estimates can differ slightly.
</p>


<h3>Author(s)</h3>

<p> C. H. Fleming. </p>


<h3>References</h3>

<p>C. H. Fleming, I. Deznabi, S. Alavi, M. C. Crofoot, B. T. Hirsch, E. P. Medici, M. J. Noonan, R. Kays, W. F. Fagan, D. Sheldon, J. M. Calabrese,
&ldquo;Population-level inference for home-range areas&rdquo;,
Methods in Ecology and Evolution 13:5 1027&ndash;1041 (2022) <a href="https://doi.org/10.1111/2041-210X.13815">doi:10.1111/2041-210X.13815</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+akde">akde</a></code>, <code><a href="#topic+cluster">cluster</a></code>, <code><a href="#topic+ctmm.fit">ctmm.fit</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>
# load package and data
library(ctmm)
data(buffalo)

# fit movement models
FITS &lt;- AKDES &lt;- list()
for(i in 1:length(buffalo))
{
  GUESS &lt;- ctmm.guess(buffalo[[i]],interactive=FALSE)
  # use ctmm.select unless you are certain that the selected model is OUF
  FITS[[i]] &lt;- ctmm.fit(buffalo[[i]],GUESS)
}

# calculate AKDES on a consistent grid
AKDES &lt;- akde(buffalo,FITS)

# color to be spatially distinct
COL &lt;- color(AKDES,by='individual')

# plot AKDEs
plot(AKDES,col.DF=COL,col.level=COL,col.grid=NA,level=NA)

# meta-analysis of buffalo home-range areas
meta(AKDES,col=c(COL,'black'),sort=TRUE)

# funnel plot to check for sampling bias
funnel(AKDES,buffalo)
</code></pre>

<hr>
<h2 id='npr'>Calculate a non-parametric regression surface</h2><span id='topic+npr'></span>

<h3>Description</h3>

<p>This function estimates the mean value of an annotated covariate as a function of location, using non-parametric regression.</p>


<h3>Usage</h3>

<pre><code class='language-R'>npr(data,UD,variable="speed",normalize=FALSE,debias=TRUE,error=0.001,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="npr_+3A_data">data</code></td>
<td>
<p> 2D timeseries telemetry data represented as a <code>telemetry</code> object or list of objects. </p>
</td></tr>
<tr><td><code id="npr_+3A_ud">UD</code></td>
<td>
<p>A <code>UD</code> object from the output of <code><a href="#topic+akde">akde</a></code>.</p>
</td></tr>
<tr><td><code id="npr_+3A_variable">variable</code></td>
<td>
<p>Variable for mean estimation. Can be a column of <code>data</code>.</p>
</td></tr>
<tr><td><code id="npr_+3A_normalize">normalize</code></td>
<td>
<p>Consider <code>variable</code> as providing a weighted probability distribution.</p>
</td></tr>
<tr><td><code id="npr_+3A_debias">debias</code></td>
<td>
<p>Correct for oversmoothing if <code>normalize=TRUE</code>.</p>
</td></tr>
<tr><td><code id="npr_+3A_error">error</code></td>
<td>
<p>Target probability error.</p>
</td></tr>
<tr><td><code id="npr_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code><a href="#topic+akde">akde</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a <code>UD</code> object.</p>


<h3>Author(s)</h3>

<p> C. H. Fleming. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+akde">akde</a></code>, <code><a href="#topic+occurrence">occurrence</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load package and data
library(ctmm)
data(buffalo)
DATA &lt;- buffalo$Cilla

# calculate fit guess object
GUESS &lt;- ctmm.guess(DATA,interactive=FALSE)
# in general, you should be running ctmm.select here instead of ctmm.fit
FIT &lt;- ctmm.fit(DATA,GUESS)

# Compute akde object
UD &lt;- akde(DATA,FIT)

# compute revisitation distribution
RD &lt;- revisitation(DATA,UD)

# Plot data with revisitation distribution
plot(DATA,RD)
</code></pre>

<hr>
<h2 id='occurrence'>Calculate a Kriged occurrence distribution estimate</h2><span id='topic+occurrence'></span>

<h3>Description</h3>

<p>This function calculates an occurrence distribution from <code>telemetry</code> data and a continuous-time movement model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>occurrence(data,CTMM,R=list(),SP=NULL,SP.in=TRUE,H=0,variable="utilization",res.time=10,
           res.space=10,grid=NULL,cor.min=0.05,dt.max=NULL,buffer=TRUE,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="occurrence_+3A_data">data</code></td>
<td>
<p> A <code>telemetry</code> object or list of <code>telemetry</code> objects. </p>
</td></tr>
<tr><td><code id="occurrence_+3A_ctmm">CTMM</code></td>
<td>
<p>A <code>ctmm</code> movement model, as from the output of <code>ctmm.select</code>, or a list of <code>ctmm</code> objects.</p>
</td></tr>
<tr><td><code id="occurrence_+3A_r">R</code></td>
<td>
<p>A named list of raster covariates if <code>CTMM</code> contains an RSF model.</p>
</td></tr>
<tr><td><code id="occurrence_+3A_sp">SP</code></td>
<td>
<p>SpatialPolygonsDataFrame object for enforcing hard boundaries.</p>
</td></tr>
<tr><td><code id="occurrence_+3A_sp.in">SP.in</code></td>
<td>
<p>Locations are assumed to be inside the <code>SP</code> polygons if <code>SP.in=TRUE</code> and outside of <code>SP</code> if <code>SP.in=FALSE</code>.</p>
</td></tr>
<tr><td><code id="occurrence_+3A_h">H</code></td>
<td>
<p>Optional additional bandwidth matrix for future use.</p>
</td></tr>
<tr><td><code id="occurrence_+3A_variable">variable</code></td>
<td>
<p>Either <code>"utilization"</code> or <code>"revisitation"</code>. Only utilization is accurately estimated.</p>
</td></tr>
<tr><td><code id="occurrence_+3A_res.time">res.time</code></td>
<td>
<p>Number of temporal grid points per median timestep.</p>
</td></tr>
<tr><td><code id="occurrence_+3A_res.space">res.space</code></td>
<td>
<p>Number of grid points along each axis, relative to the average diffusion (per median timestep) from a stationary point.</p>
</td></tr>
<tr><td><code id="occurrence_+3A_grid">grid</code></td>
<td>
<p>Optional grid specification via <code>raster</code>, <code>UD</code>, or list of arguments (See <code><a href="#topic+akde">akde</a></code> for details).</p>
</td></tr>
<tr><td><code id="occurrence_+3A_cor.min">cor.min</code></td>
<td>
<p>Velocity correlation threshold for skipping gaps.</p>
</td></tr>
<tr><td><code id="occurrence_+3A_dt.max">dt.max</code></td>
<td>
<p>Maximum absolute gap size (in seconds) for Kriging interpolation. If left <code>NULL</code>, the median of <code>diff(data$t)</code> will be used.</p>
</td></tr>
<tr><td><code id="occurrence_+3A_buffer">buffer</code></td>
<td>
<p>Buffer the observation period, according to the minimum gap specified by <code>cor.min</code> and <code>dt.max</code>, to include more probable locations if possible.</p>
</td></tr>
<tr><td><code id="occurrence_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The arguments <code>cor.min</code> or <code>dt.max</code> are used to prevent the interpolation of large gaps, which would bias the estimate to more resemble the movement model than the data. Because <code>cor.min</code> can produce an empty range with fractal movement models, the larger of the two rules is employed for interpolation.
</p>
<p>If <code>buffer=TRUE</code>, then the data are also extrapolated according to the minimum of the two rules (<code>cor.min</code> and <code>dt.max</code>) which is limited to cases where persistence of motion is modeled.
</p>


<h3>Value</h3>

<p>Returns a <code>UD</code> object containing the sampled grid line locations <code>x</code> and <code>y</code>, the probability density and cumulative distribution functions evaluated on the sampled grid locations <code>PDF</code> &amp; <code>CDF</code>, the optional bandwidth matrix <code>H</code>, and the area of each grid cell <code>dA</code>.
</p>


<h3>Note</h3>

<p>Large gaps have a tendency to slow down computation and blow up the estimate. This can be avoided with the <code>cor.min</code> or <code>dt.max</code> arguments.
</p>
<p>In the case of coarse grids, the value of <code>PDF</code> in a grid cell actually corresponds to the average probability density over the entire rectangular cell.
</p>
<p>Prior to <code>ctmm</code> v0.5.6, <code>cor.min</code> referred to the location correlation, with a default of 50%.
In <code>ctmm</code> v0.5.6 and above, <code>cor.min</code> refers to the velocity correlation, with a default of 5%.</p>


<h3>Author(s)</h3>

<p> C. H. Fleming. </p>


<h3>References</h3>

<p>C. H. Fleming, W. F. Fagan, T. Mueller, K. A. Olson, P. Leimgruber, J. M. Calabrese,
&ldquo;Estimating where and how animals travel: An optimal framework for path reconstruction from autocorrelated tracking data&rdquo;,
Ecology, 97:3, 576-582 (2016) <a href="https://doi.org/10.1890/15-1607.1">doi:10.1890/15-1607.1</a>.
</p>
<p>C. H. Fleming, D. Sheldon, E. Gurarie, W. F. Fagan, S. LaPoint, J. M. Calabrese,
&ldquo;Kálmán filters for continuous-time movement models&rdquo;,
Ecological Informatics, 40, 8-21 (2017) <a href="https://doi.org/10.1016/j.ecoinf.2017.04.008">doi:10.1016/j.ecoinf.2017.04.008</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+akde">akde</a></code>, <code><a href="#topic+raster+2CUD-method">raster,UD-method</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load package and data
library(ctmm)
data(buffalo)
Cilla &lt;- buffalo$Cilla

GUESS &lt;- ctmm.guess(Cilla,interactive=FALSE)
FIT &lt;- ctmm.fit(Cilla,GUESS)

# Compute occurence distribution
UD &lt;- occurrence(Cilla,FIT)

# Plot occurrence UD
plot(UD,col.level=NA)
</code></pre>

<hr>
<h2 id='optimizer'>Minimize a function</h2><span id='topic+optimizer'></span>

<h3>Description</h3>

<p>This function serves as a wrapper around <code><a href="stats.html#topic+optimize">optimize</a></code>, <code><a href="stats.html#topic+optim">optim</a></code>, and <code>ctmm</code>'s partial-Newton optimization routine, with standardized arguments and return values. It finds the optimal parameters that minimize a function, whether it be a cost, loss, risk, or negative log-likelihood function.</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimizer(par,fn,...,method="pNewton",lower=-Inf,upper=Inf,period=FALSE,reset=identity,
          control=list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="optimizer_+3A_par">par</code></td>
<td>
<p>Initial parameter guess.</p>
</td></tr>
<tr><td><code id="optimizer_+3A_fn">fn</code></td>
<td>
<p>Function to be minimized with first argument <code>par</code> and optional argument <code>zero</code> (see 'Details' below).</p>
</td></tr>
<tr><td><code id="optimizer_+3A_...">...</code></td>
<td>
<p>Optional arguments fed to <code>fn</code>.</p>
</td></tr>
<tr><td><code id="optimizer_+3A_method">method</code></td>
<td>
<p>Optimization algorithm (see 'Details' below).</p>
</td></tr>
<tr><td><code id="optimizer_+3A_lower">lower</code></td>
<td>
<p>Lower bound for parameters.</p>
</td></tr>
<tr><td><code id="optimizer_+3A_upper">upper</code></td>
<td>
<p>Upper bound for parameters.</p>
</td></tr>
<tr><td><code id="optimizer_+3A_period">period</code></td>
<td>
<p>Period of circular parameters if not <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="optimizer_+3A_reset">reset</code></td>
<td>
<p>Optional function to re-center parameters, if symmetry permits, to prevent numerical underflow.</p>
</td></tr>
<tr><td><code id="optimizer_+3A_control">control</code></td>
<td>
<p>Argument list for the optimization routine (see 'Details' below).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Only <code>method='pNewton'</code> will work in both one dimension and multiple dimensions. Any other <code>method</code> argument will be ignored in one dimension, in favor of <code><a href="stats.html#topic+optimize">optimize</a></code> with a backup evaluation of <code><a href="stats.html#topic+nlm">nlm</a></code> (under a log-link) for cases where <code><a href="stats.html#topic+optimize">optimize</a></code> is known to fail. In multiple dimensions, methods other than <code>pNewton</code> include those detailed in <code><a href="stats.html#topic+optim">optim</a></code>.
</p>
<p><code>method='pNewton'</code> is <code>ctmm</code>'s partial-Newton optimizer, which is a quasi-Newton method that is more accurate than BFGS-based methods when the gradient of <code>fn</code> must be calculated numerically. In short, while BFGS-based methods provide a single rank-1 update to the Hessian matrix per iteration, the partial-Newton algorithm provides <code>length(par)+1</code> rank-1 updates to the Hessian matrix per iteration, at the same computational cost. Furthermore, <code>length(par)</code> of those updates have better numerical precision than the BFGS update, meaning that they can be used at smaller step sizes to obtain better numerical precision. The <code>pNewton</code> optimizer also supports several features not found in other <code>R</code> optimizers: the <code>zero</code> argument, the <code>period</code> argument, and parallelization.
</p>
<p>The <code>zero</code> argument is an optional argument in <code>fn</code> supported by <code>method='pNewton'</code>. Briefly, if you rewrite a negative log-likelihood of the form <code class="reqn">fn = \sum_{i=1}^n fn_i</code> as <code class="reqn">fn = \sum_{i=1}^n ( fn_i - zero/n ) + zero</code>, where <code>zero</code> is the current estimate of the minimum value of <code>fn</code>, then the sum becomes approximately &quot;zeroed&quot; and so the variance in numerical errors caused by the difference in magnitude between <code>fn</code> and <code>fn_i</code> is mitigated. In practice, without the <code>zero</code> argument, log-likelihood functions grow in magnitude with increasing data and then require increasing numerical precision to resolve the same differences in log-likelihood. But absolute differences in log-likelihoods (on the order of 1) are always important, even though most optimization routines more naturally consider relative differences as being important.
</p>
<p>The <code>period</code> argument informs <code>method='pNewton'</code> if parameters is circular, such as with angles, and what their periods are.
</p>
<p>The <code>control</code> list can take the folowing arguments, with defaults shown:
</p>

<dl>
<dt><code>precision=1/2</code></dt><dd><p>Fraction of machine numerical precision to target in the maximized likelihood value. The optimal <code>par</code> will have half this precision. On most computers, <code>precision=1</code> is approximately 16 decimal digits of precision for the objective function and 8 for the optimal <code>par</code>.</p>
</dd>
<dt><code>maxit=.Machine$integer.max</code></dt><dd><p>Maximum number of iterations allowed for optimization.</p>
</dd>
<dt><code>parscale=pmin(abs(par),abs(par-lower),abs(upper-par))</code></dt><dd><p>The natural scale of the parameters such that variations in <code>par</code> on the order of <code>parscale</code> produce variations in <code>fn</code> on the order of one.</p>
</dd>
<dt><code>trace=FALSE</code></dt><dd><p>Return step-by-step progress on optimization.</p>
</dd>
<dt><code>cores=1</code></dt><dd><p>Perform <code>cores</code> evaluations of <code>fn</code> in parallel, if running in UNIX. <code>cores&lt;=0</code> will use all available cores, save <code>abs(cores)</code>. This feature is only supported by <code>method='pNewton'</code> and is only useful if <code>fn</code> is slow to evaluate, <code>length(par)&gt;1</code>, and the total number of parallel evaluations required does not trigger fork-bomb detection by the OS.</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns a list with components <code>par</code> for the optimal parameters, <code>value</code> for the minimum value of <code>fn</code>, and possibly other components depending on the optimization routine employed.</p>


<h3>Note</h3>

<p><code>method='pNewton'</code> is very stringent about achieving its <code>precision</code> target and assumes that <code>fn</code> has small enough numerical errors (permitting the use of argument <code>zero</code>) to achieve that <code>precision</code> target. If the numerical errors in <code>fn</code> are too large, then the optimizer can fail to converge. <code><a href="#topic+ctmm.fit">ctmm.fit</a></code> standardizes its input data before optimization, and back-transforms afterwards, as one method to minimize numerical errors in <code>fn</code>.</p>


<h3>Author(s)</h3>

<p> C. H. Fleming. </p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+optim">optim</a></code>, <code><a href="stats.html#topic+optimize">optimize</a></code>, <code><a href="stats.html#topic+nlm">nlm</a></code> </p>

<hr>
<h2 id='outlie'>Methods to facilitate outlier detection.</h2><span id='topic+outlie'></span><span id='topic+outlier'></span><span id='topic+plot.outlie'></span>

<h3>Description</h3>

<p>Produces a <code>data.frame</code> of speed and distance estimates to analyze, as well as a plot highlighting potential speed and distance outliers in <code>telemetry</code> data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>outlie(data,plot=TRUE,by='d',...)

## S3 method for class 'outlie'
plot(x,level=0.95,units=TRUE,axes=c('d','v'),xlim=NULL,ylim=NULL,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="outlie_+3A_data">data</code></td>
<td>
<p><code>telemetry</code> object.</p>
</td></tr>
<tr><td><code id="outlie_+3A_plot">plot</code></td>
<td>
<p>Output a plot highlighting high speeds (blue) and distant locations (red).</p>
</td></tr>
<tr><td><code id="outlie_+3A_by">by</code></td>
<td>
<p>Color and size side-effect plot points by <code>'d'</code>, <code>'v'</code>, <code>'dz'</code>, <code>'vz'</code>, for distance from center, minimum speed, vertical distance from center, and minimum vertical speed.</p>
</td></tr>
<tr><td><code id="outlie_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code>plot</code>.</p>
</td></tr>
<tr><td><code id="outlie_+3A_x">x</code></td>
<td>
<p><code>outlie</code> object to plot.</p>
</td></tr>
<tr><td><code id="outlie_+3A_level">level</code></td>
<td>
<p>Confidence level for error bars.</p>
</td></tr>
<tr><td><code id="outlie_+3A_units">units</code></td>
<td>
<p>Convert axes to natural units.</p>
</td></tr>
<tr><td><code id="outlie_+3A_axes">axes</code></td>
<td>
<p><code class="reqn">x</code>-<code class="reqn">y</code> axes to plot. Can be any of <code>'d'</code>, <code>'v'</code>, <code>'dz'</code>, <code>'vz'</code>, for time, distance from center, minimum speed, vertical distance from center, and minimum vertical speed.</p>
</td></tr>
<tr><td><code id="outlie_+3A_xlim">xlim</code></td>
<td>
<p><code class="reqn">x</code>-axis plotting range in SI units.</p>
</td></tr>
<tr><td><code id="outlie_+3A_ylim">ylim</code></td>
<td>
<p><code class="reqn">y</code>-axis plotting range in SI units.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>plot=TRUE</code> in <code>outlie()</code>, intervals of high speed are highlighted with blue segments, while distant locations are highlighted with red points.
</p>
<p>When plotting the <code>outlie</code> object itself, &lsquo;median deviation&rsquo; denotes distances from the geometric median, while &lsquo;minimum speed&rsquo; denotes the minimum speed required to explain the location estimate's displacement as straight-line motion. Both estimates account for telemetry error and condition on as few data points as possible. The speed estimates furthermore account for timestamp truncation and assign each timestep's speed to the most likely offending time, based on its other adjacent speed estimate.
</p>
<p>The output <code>outlie</code> object contains the above noted speed and distance estimates in a <code>data.frame</code>, with rows corresponding to those of the input <code>telemetry</code> object.
</p>


<h3>Value</h3>

<p>Returns an <code>outlie</code> object, which is a data.frame of distance and speed information. Can also produce a plot as a side effect.</p>


<h3>Note</h3>

<p>The speed estimates here are tailored for outlier detection and have poor statistical efficiency. The <code><a href="#topic+predict">predict</a></code> and <code><a href="#topic+speed">speed</a></code> methods are appropriate for estimating speed (after outliers have been removed and a movement model has been selected).
</p>
<p>In <code>ctmm</code> v0.6.1 the <code>UERE</code> argument was deprecated. For uncalibrated data, the initial esitmates used by <code>outlie</code> are now generated on import and stated by <code>summary(uere(data))</code>. These values not be reasonable for arbitrary datasets.</p>


<h3>Author(s)</h3>

<p>C. H. Fleming.</p>


<h3>References</h3>

<p>C. H. Fleming et al, &ldquo;A comprehensive framework for handling location error in animal tracking data&rdquo;, bioRxiv 2020.06.12.130195 (2020) <a href="https://doi.org/10.1101/2020.06.12.130195">doi:10.1101/2020.06.12.130195</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+as.telemetry">as.telemetry</a></code>.  </p>


<h3>Examples</h3>

<pre><code class='language-R'># Load package and data
library(ctmm)
data(turtle)

# look for outliers in a turtle
OUT &lt;- outlie(turtle[[3]])

# look at the distribution of estimates
plot(OUT)
</code></pre>

<hr>
<h2 id='overlap'>Calculate the overlap between two stationary distributions</h2><span id='topic+overlap'></span>

<h3>Description</h3>

<p>This function calculates a useful measure of similarity between distributions known as the <em>Bhattacharyya coefficient</em> in statistics and simply the <em>fidelity</em> or <em>overlap</em> in quantum and statistical mechanics. It is roughly speaking the ratio of the intersection area to the average individual area, but it is a direct comparison between the density functions and does not require an arbitrary quantile to be specified. When applied to <code>ctmm</code> objects, this function returns the overlap of the two Gaussian distributions. When applied to aligned <code>UD</code> objects with corresponding movement models, this function returns the overlap of their (autocorrelated) kernel density estimates.</p>


<h3>Usage</h3>

<pre><code class='language-R'> overlap(object,method="Bhattacharyya",level=0.95,debias=TRUE,...) </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="overlap_+3A_object">object</code></td>
<td>
<p>A <code>list</code> of <code>ctmm</code> fit or aligned <code>UD</code> objects to compare.</p>
</td></tr>
<tr><td><code id="overlap_+3A_method">method</code></td>
<td>
<p>Can be <code>"Bhattacharyya"</code> or <code>"Encounter"</code> (see Details below).</p>
</td></tr>
<tr><td><code id="overlap_+3A_level">level</code></td>
<td>
<p>The confidence level desired for the output.</p>
</td></tr>
<tr><td><code id="overlap_+3A_debias">debias</code></td>
<td>
<p>Approximate debiasing of the overlap.</p>
</td></tr>
<tr><td><code id="overlap_+3A_...">...</code></td>
<td>
<p>Not currently used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default <code>method="Bhattacharyya"</code> estimates the standard overlap measure <code class="reqn">\int\int \sqrt{p(x,y) \, q(x,y)} \, dx \, dy</code> between the distributions <code class="reqn">p(x,y)</code> and <code class="reqn">q(x,y)</code>,
while <code>method="encounter"</code> estimates the non-standard measure <code class="reqn">\frac{\int\int p(x,y) \, q(x,y) \, dx \, dy}{\sqrt{\int\int p(x',y')^2 \, dx' dy' \int\int q(x'',y'')^2 \, dx'' dy''}}</code>,
which has a numerator proportional to the uncorrelated encounter probability.
Both measures lie between 0 and 1, where 0 indicates no shared support and 1 indicates identical distributions.
</p>


<h3>Value</h3>

<p>An object with slots <code>DOF</code>, containing the effective sample sizes, and <code>CI</code> containing a table of confidence intervals on the overlap estimates. A value of <code>1</code> implies that the two distributions are identical, while a value of <code>0</code> implies that the two distributions share no area in common.</p>


<h3>Note</h3>

<p>In <code>ctmm</code> v0.5.2, direct support for <code>telemetry</code> objects was dropped and the <code>CTMM</code> argument was depreciated for <code>UD</code> objects, simplifying usage.
</p>
<p>Uncertainties in the model fits are propagated into the overlap estimate under the approximation that the Bhattacharyya distance is a chi-square random variable. Debiasing makes further approximations noted in Winner &amp; Noonan et al (2018).</p>


<h3>Author(s)</h3>

<p>C. H. Fleming and K. Winner</p>


<h3>References</h3>

<p>K. Winner, M. J. Noonan, C. H. Fleming, K. Olson, T. Mueller, D. Sheldon, J. M. Calabrese.
&ldquo;Statistical inference for home range overlap&rdquo;,
Methods in Ecology and Evolution, 9:7, 1679-1691 (2018) <a href="https://doi.org/10.1111/2041-210X.13027">doi:10.1111/2041-210X.13027</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+akde">akde</a></code>, <code><a href="#topic+ctmm.fit">ctmm.fit</a></code>, <code><a href="#topic+distance">distance</a></code>, <code><a href="#topic+encounter">encounter</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load package and data
library(ctmm)
data(buffalo)

# fit models for first two buffalo
GUESS &lt;- lapply(buffalo[1:2], function(b) ctmm.guess(b,interactive=FALSE) )
# using ctmm.fit here for speed, but you should almost always use ctmm.select
FITS &lt;- lapply(1:2, function(i) ctmm.fit(buffalo[[i]],GUESS[[i]]) )
names(FITS) &lt;- names(buffalo[1:2])

# Gaussian overlap between these two buffalo
overlap(FITS)

# AKDE overlap between these two buffalo
# create aligned UDs
UDS &lt;- akde(buffalo[1:2],FITS)
# evaluate overlap
overlap(UDS)
</code></pre>

<hr>
<h2 id='pelican'>Brown Pelican GPS and ARGOS data.</h2><span id='topic+pelican'></span>

<h3>Description</h3>

<p>GPS and ARGOS data on a single brown pelican (<em>Pelecanus occidentalis</em>).
Please contact Autumn-Lynn Harrison (HarrisonAL@si.edu) if you want to publish with these data.
</p>
<p>Funding for Brown Pelican tracking was provided by the Friends of the National Zoo Conservation Research Grant and ConocoPhillips Global Signature Program. Field support provided by D. Brinker.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("pelican")</code></pre>


<h3>Format</h3>

<p> A list of 2 <code>telemetry</code> objects.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+as.telemetry">as.telemetry</a></code>, <code><a href="#topic+plot.telemetry">plot.telemetry</a></code>, <code><a href="#topic+buffalo">buffalo</a></code>, <code><a href="#topic+coati">coati</a></code>, <code><a href="#topic+gazelle">gazelle</a></code>, <code><a href="#topic+jaguar">jaguar</a></code>, <code><a href="#topic+turtle">turtle</a></code>, <code><a href="#topic+wolf">wolf</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'># Load package and data
library(ctmm)
data("pelican")
names(pelican)

# Plot all sampled locations
plot(pelican,col=c('blue','red'))
</code></pre>

<hr>
<h2 id='periodogram'>Calculate the Lomb-Scargle periodogram of animal-tracking data</h2><span id='topic+periodogram'></span><span id='topic+plot.periodogram'></span>

<h3>Description</h3>

<p>This function calculates isotropic Lomb-Scargle periodogram (LSP, Scargle, 1982) from a telemetry object. One of two algorithms is used. The slow <code class="reqn">O(n^2)</code> algorithm vectorizes the exact relations of Scargle (1982), while the fast <code class="reqn">O(n \log n)</code> algorithm uses the FFT method described in Péron &amp; Fleming et al (2016). The latter method is exact if the data are evenly scheduled, permitting gaps, and otherwise it can be made arbitrarily precise via the <code>res.time</code> option.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>periodogram(data,CTMM=NULL,dt=NULL,res.freq=1,res.time=1,fast=NULL,axes=c("x","y"))

## S3 method for class 'periodogram'
plot(x,max=FALSE,diagnostic=FALSE,col="black",transparency=0.25,grid=TRUE,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="periodogram_+3A_data">data</code></td>
<td>
 <p><code>telemetry</code> data object or list of such objects. </p>
</td></tr>
<tr><td><code id="periodogram_+3A_ctmm">CTMM</code></td>
<td>
<p> An optional <code>ctmm</code> model object for specifying the mean. </p>
</td></tr>
<tr><td><code id="periodogram_+3A_dt">dt</code></td>
<td>
<p>Sampling interval for frequency cutoff.</p>
</td></tr>
<tr><td><code id="periodogram_+3A_res.freq">res.freq</code></td>
<td>
<p>Multiplier to inflate the frequency resolution.</p>
</td></tr>
<tr><td><code id="periodogram_+3A_res.time">res.time</code></td>
<td>
<p>Integer multiplier to inflate the temporal resolution. Useful when <code>fast</code>&gt;0 and the sampling rate is variable.</p>
</td></tr>
<tr><td><code id="periodogram_+3A_fast">fast</code></td>
<td>
<p>Use the exact algorithm if FALSE, the FFT algorithm if TRUE, and further inflate the frequency resolution to a power of two sample size if <code>fast=2</code>.</p>
</td></tr>
<tr><td><code id="periodogram_+3A_axes">axes</code></td>
<td>
<p>Array of axes to calculate an average (isotropic) variogram for.</p>
</td></tr>
<tr><td><code id="periodogram_+3A_x">x</code></td>
<td>
<p>Output object of <code>periodogram</code>.</p>
</td></tr>
<tr><td><code id="periodogram_+3A_max">max</code></td>
<td>
<p>Plot only the local maxima of the periodogram. Use only with <code>res&gt;1</code>.</p>
</td></tr>
<tr><td><code id="periodogram_+3A_diagnostic">diagnostic</code></td>
<td>
<p>Plot the sampling schedule's periodogram to check for spurious periodicities.</p>
</td></tr>
<tr><td><code id="periodogram_+3A_col">col</code></td>
<td>
<p>Color of periodogram.</p>
</td></tr>
<tr><td><code id="periodogram_+3A_transparency">transparency</code></td>
<td>
<p>Adds transparency to clustered data if greater than zero. Should be less than one.</p>
</td></tr>
<tr><td><code id="periodogram_+3A_grid">grid</code></td>
<td>
<p>Whether or not to plot gridlines at common periodicities.</p>
</td></tr>
<tr><td><code id="periodogram_+3A_...">...</code></td>
<td>
<p>Optional arguments fed to <code><a href="#topic+plot">plot</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If no <code>dt</code> is specified, the median sampling interval is used. This is typically a good assumption for most data, even when there are gaps and this choice corresponds to the discrete Fourier transform (DFT) periodogram for evenly-sampled data.
</p>
<p>At default resolution the frequency grid interval is given by <code>1/(2*(range(data$t)+dt))</code> and the frequency cutoff is given by <code>1/(2*dt)</code>, both in accordance with the DFT periodogram. Increasing <code>res.freq</code> beyond <code>res.freq=1</code> will make for a smooth periodogram, but sequential frequencies will be highly correlated. The <code>max=TRUE</code> option to <code>plot.periodogram</code> may be useful for <code>res.freq&gt;1</code>. Increasing <code>res.time</code> beyond <code>res.time=1</code> is helpful if there is variability in the sampling rate and <code>fast&gt;0</code>.
</p>
<p>If a <code>CTMM</code> argument is provided, the ML mean will be detrended from the data prior to calculating the periodogram. Otherwise, the sample mean will be detrended.
</p>
<p>If a list of <code>telemetry</code> objects are fed into <code>periodogram</code>, then a mean <code>periodogram</code> object will be returned with the default <code>dt</code> and base frequency resolution selected on a worst case basis according to the method described by Péron &amp; Fleming et al (2016).
</p>


<h3>Value</h3>

<p>Returns a periodogram object (class <code>periodogram</code>) which is a dataframe containing the frequency, <code>f</code> and the Lomb-Scargle periodogram at that frequency, <code>LSP</code>.
</p>


<h3>Note</h3>

<p> The LSP is totally inappropriate if you in any way alter the sampling rate within the dataset. Stick with variograms in that case. There is a <code>diagnostic</code> option in <code>plot.periodogram</code> that can check for spurious periodicities that result from an autocorrelated sampling schedule. This plot will not contain any periodicities if the LSP is appropriate.
</p>
<p><code>res.time&gt;1</code> relies on Lagrange interpolation of the sinusoids (not the data), which can suffer from Runge's phenomena. <code>periodogram</code> tests for an invalid result and can fail with an error message. For whatever reason, this more frequently seems to happen when <code>res.time=3</code>. </p>


<h3>Author(s)</h3>

<p> C. H. Fleming and G. Péron </p>


<h3>References</h3>

<p>J. D. Scargle,
&ldquo;Studies in astronomical time-series analysis. II. Statistical aspects of spectral analysis of unevenly-sampled data&rdquo;,
The Astrophysical Journal, 263, 835-853 (1952) <a href="https://doi.org/10.1086/160554">doi:10.1086/160554</a>.
</p>
<p>G. Péron, C. H. Fleming,  R. C. de Paula, J. M. Calabrese,
&ldquo;Uncovering periodic patterns of space use in animal tracking data with periodograms, including a new algorithm for the Lomb-Scargle periodogram and improved randomization tests&rdquo;,
Movement Ecology, 4:19 (2016) <a href="https://doi.org/10.1186/s40462-016-0084-7">doi:10.1186/s40462-016-0084-7</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Load package and data
library(ctmm)
data(wolf)

#Extract movement data for a single animal
DATA &lt;- wolf$Tay

#Calculate periodogram (fast==2 for a speedy example)
#There is some variability in the sampling frequency, so we increase res.time
LSP &lt;- periodogram(DATA,fast=2,res.time=2)

#Plot the periodogram
plot(LSP,max=TRUE)
</code></pre>

<hr>
<h2 id='plot.telemetry'>Plotting methods for telemetry objects</h2><span id='topic+plot'></span><span id='topic+plot.telemetry'></span><span id='topic+zoom+2Clist-method'></span><span id='topic+zoom+2Ctelemetry-method'></span><span id='topic+zoom+2CUD-method'></span>

<h3>Description</h3>

<p>Produces simple plots of <code>telemetry</code> objects, possibly overlayed with a Gaussian <code>ctmm</code> movement model or a <code>UD</code> utilization distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot(x,y,...)

## S3 method for class 'telemetry'
plot(x,CTMM=NULL,UD=NULL,col.bg="white",cex=NULL,col="red",lwd=1,pch=1,type='p',
     error=TRUE,transparency.error=0.25,velocity=FALSE,DF="CDF",col.DF="blue",
     col.grid="white",labels=NULL,convex=FALSE,level=0.95,level.UD=0.95,col.level="black",
     lwd.level=1,SP=NULL,border.SP=TRUE,col.SP=NA,R=NULL,col.R="green",legend=FALSE,
     fraction=1,xlim=NULL,ylim=NULL,ext=NULL,units=TRUE,add=FALSE,...)

## S4 method for signature 'list'
zoom(x,...)

## S4 method for signature 'telemetry'
zoom(x,fraction=1,...)

## S4 method for signature 'UD'
zoom(x,fraction=1,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.telemetry_+3A_x">x</code></td>
<td>
<p><code>telemetry</code> or <code>UD</code> object.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_y">y</code></td>
<td>
<p>Unused option.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_ctmm">CTMM</code></td>
<td>
<p>Optional Gaussian <code>ctmm</code> movement model from the output of <code>ctmm.fit</code> or list of such objects.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_ud">UD</code></td>
<td>
<p>Optional <code>UD</code> object such as from the output of <code>akde</code> or list of such objects.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_col.bg">col.bg</code></td>
<td>
<p>Background color</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_cex">cex</code></td>
<td>
<p>Relative size of plotting symbols. Only used when <code>error=FALSE</code>, because <code>error=TRUE</code> uses the location-error radius instead of <code>cex</code>.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_col">col</code></td>
<td>
<p>Color option for telemetry data. Can be an array or list of arrays.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_lwd">lwd</code></td>
<td>
<p>Line widths of <code>telemetry</code> points.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_pch">pch</code></td>
<td>
<p>Plotting symbol. Can be an array or list of arrays.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_type">type</code></td>
<td>
<p>How plot points are connected. Can be an array.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_error">error</code></td>
<td>
<p>Plot error circles/ellipses if present in the data. <code>error=2</code> will fill in the circles and <code>error=3</code> will plot densities instead. <code>error=FALSE</code> will disable this feature.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_transparency.error">transparency.error</code></td>
<td>
<p>Transparency scaling for erroneous locations when <code>error=1:2</code>. <code>trans=0</code> disables transparancy. Should be no greater than <code>1</code>.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_velocity">velocity</code></td>
<td>
<p>Plot velocity vectors if present in the data.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_df">DF</code></td>
<td>
<p>Plot the maximum likelihood probability density function <code>"PDF"</code> or cumulative distribution function <code>"CDF"</code>.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_col.df">col.DF</code></td>
<td>
<p>Color option for the density function. Can be an array.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_col.grid">col.grid</code></td>
<td>
<p>Color option for the maximum likelihood <code>akde</code> bandwidth grid. <code>col.grid=NA</code> will disable the plotting of the bandwidth grid.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_labels">labels</code></td>
<td>
<p>Labels for UD contours. Can be an array or list of arrays.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_convex">convex</code></td>
<td>
<p>Plot convex coverage-area contours if <code>TRUE</code>. By default, the highest density region (HDR) contours are plotted.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_level">level</code></td>
<td>
<p> Confidence levels placed on the contour estimates themselves. I.e., the above 50% core home-range area can be estimated with 95% confidence via <code>level=0.95</code>. <code>level=NA</code> will disable the plotting of confidence intervals.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_level.ud">level.UD</code></td>
<td>
<p>Coverage level of Gaussian <code>ctmm</code> model or <code>UD</code> estimate contours to be displayed. I.e., <code>level.UD=0.50</code> can yield the 50% core home range within the rendered contours.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_col.level">col.level</code></td>
<td>
<p>Color option for home-range contours. Can be an array.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_lwd.level">lwd.level</code></td>
<td>
<p>Line widths of <code>UD</code> contours.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_sp">SP</code></td>
<td>
<p><code>SpatialPolygonsDataFrame</code> object for plotting a shapefile base layer.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_border.sp">border.SP</code></td>
<td>
<p>Color option for shapefile polygon boundaries.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_col.sp">col.SP</code></td>
<td>
<p>Color option for shapefile polygon regions.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_r">R</code></td>
<td>
<p>Background raster, such as habitat <code><a href="#topic+suitability">suitability</a></code>.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_col.r">col.R</code></td>
<td>
<p>Color option for background raster.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_legend">legend</code></td>
<td>
<p>Plot a color legend for background raster.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_fraction">fraction</code></td>
<td>
<p>Quantile fraction of the data, Gaussian <code>ctmm</code>, or <code>UD</code> range to plot, whichever is larger.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_xlim">xlim</code></td>
<td>
<p>The <code>x</code> limits <code>c(x1, x2)</code> of the plot (in SI units).</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_ylim">ylim</code></td>
<td>
<p>The <code>y</code> limits <code>c(y1, y2)</code> of the plot (in SI units).</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_ext">ext</code></td>
<td>
<p>Plot extent alternative to <code>xlim</code> and <code>ylim</code> (see <code><a href="#topic+extent">extent</a></code>).</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_units">units</code></td>
<td>
<p>Convert axes to natural units.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_add">add</code></td>
<td>
<p>Setting to <code>TRUE</code> will disable the unit conversions and base layer plot, so that <code>plot.telemetry</code> can be overlayed atop other outputs more easily.</p>
</td></tr>
<tr><td><code id="plot.telemetry_+3A_...">...</code></td>
<td>
<p> Additional options passed to <code>plot</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Confidence intervals placed on the <code>ctmm</code> Gaussian home-range contour estimates only represent uncertainty in the area's magnitude and not uncertainty in the mean location, eccentricity, or orientation angle. For <code>akde</code> <code>UD</code> estimates, the provided contours also only represent uncertainty in the magnitude of the area. With <code>akde</code> estimates, it is also important to note the scale of the bandwidth and, by default, grid cells are plotted with <code>akde</code> contours such that their length and width matches that of a bandwidth kernels' standard deviation in each direction. Therefore, this grid provides a visual approximation of the kernel-density estimate's &ldquo;resolution&rdquo;. Grid lines can be disabled with the argument <code>col.grid=NA</code>.</p>


<h3>Value</h3>

<p>Returns a plot of <code class="reqn">x</code> vs. <code class="reqn">y</code>, and, if specified, Gaussian <code>ctmm</code> distribution or <code>UD</code>.
<code>akde</code> <code>UD</code> plots also come with a standard resolution grid.
<code>zoom</code> includes a zoom slider to manipulate <code>fraction</code>.</p>


<h3>Note</h3>

<p>If <code>xlim</code> or <code>ylim</code> are provided, then the smaller or absent range will be expanded to ensure <code>asp=1</code>.</p>


<h3>Author(s)</h3>

<p>C. H. Fleming.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+akde">akde</a></code>, <code><a href="#topic+ctmm.fit">ctmm.fit</a></code>, <code><a href="#topic+plot">plot</a></code>, <code><a href="#topic+SpatialPoints.telemetry">SpatialPoints.telemetry</a></code>.  </p>


<h3>Examples</h3>

<pre><code class='language-R'># Load package and data
library(ctmm)
data(buffalo)

# Plot the data
plot(buffalo,col=rainbow(length(buffalo)))
</code></pre>

<hr>
<h2 id='plot.variogram'>Plotting methods for variogram objects.</h2><span id='topic+plot.variogram'></span><span id='topic+zoom+2Cvariogram-method'></span>

<h3>Description</h3>

<p>Produces simple plots of <code>varigram</code> objects (semi-variance vs. time lag) and model semi-variance functions, with approximate confidence intervals around the semi-variance estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'variogram'
plot(x,CTMM=NULL,level=0.95,units=TRUE,fraction=0.5,col="black",col.CTMM="red",xlim=NULL,
     ylim=NULL,ext=NULL,...)

## S4 method for signature 'variogram'
zoom(x,fraction=0.5,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.variogram_+3A_x">x</code></td>
<td>
<p>A <code>variogram</code> object calculated using <code><a href="#topic+variogram">variogram</a></code>.</p>
</td></tr>
<tr><td><code id="plot.variogram_+3A_ctmm">CTMM</code></td>
<td>
<p>A <code>ctmm</code> movement model object in the same format as the output of <code>ctmm.fit</code> or <code>variogram.fit</code>.</p>
</td></tr>
<tr><td><code id="plot.variogram_+3A_level">level</code></td>
<td>
<p>Confidence level of confidence bands (95% default CIs). Can be an array.</p>
</td></tr>
<tr><td><code id="plot.variogram_+3A_units">units</code></td>
<td>
<p>Convert axes to natural units.</p>
</td></tr>
<tr><td><code id="plot.variogram_+3A_fraction">fraction</code></td>
<td>
<p>The proportion of the variogram object, <code>variogram</code>, that will be plotted. By convention, half is shown. The tail end is generally garbage.</p>
</td></tr>

<tr><td><code id="plot.variogram_+3A_col">col</code></td>
<td>
<p>Color for the empirical variogram. Can be an array.</p>
</td></tr>
<tr><td><code id="plot.variogram_+3A_col.ctmm">col.CTMM</code></td>
<td>
<p>Color for the model. Can be an array.</p>
</td></tr>
<tr><td><code id="plot.variogram_+3A_xlim">xlim</code></td>
<td>
<p>Range of lags to plot (in SI units).</p>
</td></tr>
<tr><td><code id="plot.variogram_+3A_ylim">ylim</code></td>
<td>
<p>Range of semi-variance to plot (in SI units).</p>
</td></tr>
<tr><td><code id="plot.variogram_+3A_ext">ext</code></td>
<td>
<p>Plot extent alternative to <code>xlim</code> and <code>ylim</code> (see <code><a href="#topic+extent">extent</a></code>).</p>
</td></tr>
<tr><td><code id="plot.variogram_+3A_...">...</code></td>
<td>

<p>Additional <code>plot</code> function parameters.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a plot of semi-variance vs. time lag, with the empirical variogram in black and the <code>ctmm</code> semi-variance function in red if specified. <code>zoom</code> includes a log-scale zoom slider to manipulate <code>fraction</code>.</p>


<h3>Note</h3>

<p>The errors of the empirical variogram are correlated. Smooth trends are not necessarily significant.</p>


<h3>Author(s)</h3>

<p>J. M. Calabrese and C. H. Fleming</p>


<h3>References</h3>

<p>C. H. Fleming, J. M. Calabrese, T. Mueller, K.A. Olson, P. Leimgruber, W. F. Fagan.
From fine-scale foraging to home ranges: A semi-variance approach to identifying movement modes across spatiotemporal scales.
The American Naturalist, 183:5, E154-E167 (2014) <a href="https://doi.org/10.1086/675504">doi:10.1086/675504</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+correlogram">correlogram</a></code>, <code><a href="#topic+ctmm.fit">ctmm.fit</a></code>, <code><a href="#topic+plot">plot</a></code>, <code><a href="#topic+variogram">variogram</a></code>, <code><a href="#topic+variogram.fit">variogram.fit</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'># Load package and data
library(ctmm)
data(buffalo)

# Extract movement data for a single animal
Cilla &lt;- buffalo$Cilla

# Calculate variogram
SVF &lt;- variogram(Cilla)

# Plot the variogram
plot(SVF)
</code></pre>

<hr>
<h2 id='projection'>Projection</h2><span id='topic+projection'></span><span id='topic+projection+2Ctelemetry-method'></span><span id='topic+projection+3C-+2Ctelemetry-method'></span><span id='topic+projection+2Cctmm-method'></span><span id='topic+projection+2CUD-method'></span><span id='topic+projection+2Clist-method'></span><span id='topic+projection+3C-+2Clist-method'></span><span id='topic+projection+2CNULL-method'></span><span id='topic+median'></span><span id='topic+median.telemetry'></span><span id='topic+compass'></span>

<h3>Description</h3>

<p>Functions to manipulate the coordinate reference system (CRS) of ctmm objects</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'telemetry'
projection(x,asText=TRUE)

## S4 method for signature 'ctmm'
projection(x,asText=TRUE)

## S4 method for signature 'UD'
projection(x,asText=TRUE)

## S4 method for signature 'list'
projection(x,asText=TRUE)

## S4 method for signature 'NULL'
projection(x,asText=TRUE)

## S4 replacement method for signature 'telemetry'
projection(x) &lt;- value

## S4 replacement method for signature 'list'
projection(x) &lt;- value

## S3 method for class 'telemetry'
median(x,na.rm=FALSE,...)

compass(loc=NULL,cex=3,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="projection_+3A_x">x</code></td>
<td>
<p>A <code>telemetry</code>, <code>ctmm</code>, or <code>UD</code> object.</p>
</td></tr>
<tr><td><code id="projection_+3A_astext">asText</code></td>
<td>
<p> If <code>TRUE</code>, the projection is returned as text. Otherwise a <code>CRS</code> object is returned.</p>
</td></tr>
<tr><td><code id="projection_+3A_value">value</code></td>
<td>
<p>Projection to apply. Can also be a data.frame of longitude-latitude foci.</p>
</td></tr>
<tr><td><code id="projection_+3A_na.rm">na.rm</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr><td><code id="projection_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code><a href="Gmedian.html#topic+Gmedian">Gmedian</a></code> or <code><a href="graphics.html#topic+text">text</a></code>.</p>
</td></tr>
<tr><td><code id="projection_+3A_loc">loc</code></td>
<td>
<p>Optional two-dimensional coordinates (in meters) at which to draw a north-facing compass needle.</p>
</td></tr>
<tr><td><code id="projection_+3A_cex">cex</code></td>
<td>
<p>Relative size of compass.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>projection(x)</code> returns the projection information from ctmm object <code>x</code>, while <code>projection(x) &lt;- value</code> applies the projection <code>value</code> to object <code>x</code>.
<code>median(x)</code> returns the ellipsoidal geometric median of a telemetry object.
<code>compass(c(x,y))</code> plots a north-pointing compass needle at the coordinates <code class="reqn">(x,y)</code>.</p>


<h3>Note</h3>

<p>Plotting UTF-8 chracters in a PDF, like the compass needle, requires specifying a compatible font family. For example:
</p>
<p><code>library(ctmm)</code> <br />
<code>data(buffalo)</code> <br />
<code>cairo_pdf(file="buffalo.pdf",family="DejaVu Sans")</code> <br />
<code>plot(buffalo[[1]])</code> <br />
<code>compass()</code> <br />
<code>dev.off()</code>
</p>


<h3>Author(s)</h3>

<p>C. H. Fleming</p>


<h3>See Also</h3>

 <p><code><a href="#topic+as.telemetry">as.telemetry</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'># Load package and data
library(ctmm)
data(buffalo)

# Apply a 1-point projection that preserves North==up
projection(buffalo) &lt;- median(buffalo)
plot(buffalo)
compass()

# Apply a 2-point projection safer for elongated disributions
projection(buffalo) &lt;- median(buffalo,k=2)
# This is the default projection for ctmm
plot(buffalo)
compass()
</code></pre>

<hr>
<h2 id='residuals.ctmm'>Calculate model fit residuals and assess their autocorrelation</h2><span id='topic+residuals'></span><span id='topic+residuals.ctmm'></span><span id='topic+residuals.telemetry'></span><span id='topic+correlogram'></span><span id='topic+mag'></span><span id='topic+mag.telemetry'></span>

<h3>Description</h3>

<p>These functions calculate the residuals of a CTMM or UERE calibration model, which should be standardized and IID if the model correctly specified.
A correlogram method is also provided to assess autocorrelation.
This function is analogous to <code>acf</code>, but can handle missing data and multiple dimensions.
Finally, <code>mag</code> calculates residual magnitudes, which is useful for comparing against potential covariates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'ctmm'
residuals(object,data,...)

## S3 method for class 'telemetry'
residuals(object,CTMM=NULL,...)

correlogram(data,dt=NULL,fast=TRUE,res=1,axes=c("x","y"),trace=TRUE)

mag(x,...)

## S3 method for class 'telemetry'
mag(x,axes=c('x','y'),...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="residuals.ctmm_+3A_object">object</code></td>
<td>
<p><code>ctmm</code> model object or <code>telemetry</code> data object for calculating residuals.</p>
</td></tr>
<tr><td><code id="residuals.ctmm_+3A_data">data</code></td>
<td>
<p><code>telemetry</code> data object or <code>data.frame</code> with time column <code>t</code> and data columns <code>axes</code>.</p>
</td></tr>
<tr><td><code id="residuals.ctmm_+3A_ctmm">CTMM</code></td>
<td>
<p><code>ctmm</code> model object. If <code>NULL</code>, the data is treated as (calibrated) calibration data.</p>
</td></tr>
<tr><td><code id="residuals.ctmm_+3A_...">...</code></td>
<td>
<p>Unused arguments.</p>
</td></tr>
<tr><td><code id="residuals.ctmm_+3A_dt">dt</code></td>
<td>
<p> Lag bin width. An ordered array will yield a progressive coarsening of the lags. Defaults to the median sampling interval.</p>
</td></tr>
<tr><td><code id="residuals.ctmm_+3A_fast">fast</code></td>
<td>
<p> Use the lag-weighted algorithm if <code>FALSE</code> or the FFT algorithm if <code>TRUE</code>. The slow algorithm outputs a progress bar.</p>
</td></tr>
<tr><td><code id="residuals.ctmm_+3A_res">res</code></td>
<td>
<p>Increase the discretization resolution for irregularly sampled data with <code>res&gt;1</code>. Decreases bias at the cost of smoothness.</p>
</td></tr>
<tr><td><code id="residuals.ctmm_+3A_axes">axes</code></td>
<td>
<p>Array of axes for which to calculate residual correlogram or magnitudes.</p>
</td></tr>
<tr><td><code id="residuals.ctmm_+3A_trace">trace</code></td>
<td>
<p>Display a progress bar if <code>fast=FALSE</code>.</p>
</td></tr>
<tr><td><code id="residuals.ctmm_+3A_x">x</code></td>
<td>
<p><code>telemetry</code> object from the output of <code>residuals</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a <code>telemetry</code> dataset and <code>ctmm</code> model, <code>residuals</code> calculates the standardized residuals of the Kalman filter, which can be tested for independence. The residuals object can then be plotted with <code>plot</code> or fed into the <code>correlogram</code> method to test independence. Output of the correlogram can then be plotted as well, though <code>zoom</code> is much more useful.
</p>
<p>When calculating correlograms, minimizing bias is more important than producing a overall smooth estimate. If <code>fast=TRUE</code>, then <code>res</code> needs to be large enough to resolve variability in the sampling interval (missing data is permitted). E.g., if the sampling interval is set to 15 minutes, but can be off by a minute or two, then <code>res=15</code> is a good choice.
</p>


<h3>Value</h3>

<p><code>residuals</code> return a residual object (class <code>telemetry</code>, but flagged as residual) and <code>correlogram</code> returns a correlogram object (class <code>variogram</code>, but flagged as an ACF).
</p>


<h3>Note</h3>

<p>If the sampling schedule is irregular, permitting gaps, then the correlogram may not look good even if the model is correctly specified. In this case the correlogram of the residuals should be compared to the correlogram of simulated residuals, using &quot;data&quot; simulated from the fit model and with the same sampling schedule.</p>


<h3>Author(s)</h3>

<p> C. H. Fleming</p>


<h3>References</h3>

<p>C. H. Fleming, D. Sheldon, E. Gurarie, W. F. Fagan, S. LaPoint, J. M. Calabrese,
&ldquo;Kálmán filters for continuous-time movement models&rdquo;,
Ecological Informatics, 40, 8-21 (2017) <a href="https://doi.org/10.1016/j.ecoinf.2017.04.008">doi:10.1016/j.ecoinf.2017.04.008</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+plot.variogram">plot.variogram</a></code>, <code><a href="#topic+variogram">variogram</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load package and data
library(ctmm)
data(buffalo)
Cilla &lt;- buffalo$Cilla

# fit a model
GUESS &lt;- ctmm.guess(Cilla,interactive=FALSE)
FIT &lt;- ctmm.fit(Cilla,GUESS)

# calculate residuals
RES &lt;- residuals(Cilla,FIT)

# scatter plot of residuals with 50%, 95%, and 99.9% quantiles
plot(RES,col.DF=NA,level.UD=c(.50,.95,0.999))

# calculate correlogram of residuals
# increase the res argument to account for sampling variability
ACF &lt;- correlogram(RES,res=10)

# plot 4 day's worth of lags
plot(ACF[ACF$lag&lt;=4 %#% 'day',],fraction=1)
</code></pre>

<hr>
<h2 id='revisitation'>Calculate an revisitation distribution estimate</h2><span id='topic+revisitation'></span>

<h3>Description</h3>

<p>This function estimates the distribution of revisitations from <code>telemetry</code> data and a continuous-time movement model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>revisitation(data,UD,debias=TRUE,error=0.001,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="revisitation_+3A_data">data</code></td>
<td>
<p> 2D timeseries telemetry data represented as a <code>telemetry</code> object or list of objects. </p>
</td></tr>
<tr><td><code id="revisitation_+3A_ud">UD</code></td>
<td>
<p>A <code>UD</code> object from the output of <code><a href="#topic+akde">akde</a></code>.</p>
</td></tr>
<tr><td><code id="revisitation_+3A_debias">debias</code></td>
<td>
<p>Correct for oversmoothing.</p>
</td></tr>
<tr><td><code id="revisitation_+3A_error">error</code></td>
<td>
<p>Target probability error.</p>
</td></tr>
<tr><td><code id="revisitation_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code><a href="#topic+akde">akde</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a <code>UD</code> object.</p>


<h3>Author(s)</h3>

<p> C. H. Fleming. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+akde">akde</a></code>, <code><a href="#topic+occurrence">occurrence</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load package and data
library(ctmm)
data(buffalo)
DATA &lt;- buffalo$Cilla

# calculate fit guess object
GUESS &lt;- ctmm.guess(DATA,interactive=FALSE)
# in general, you should be running ctmm.select here instead of ctmm.fit
FIT &lt;- ctmm.fit(DATA,GUESS)

# Compute akde object
UD &lt;- akde(DATA,FIT)

# compute revisitation distribution
RD &lt;- revisitation(DATA,UD)

# Plot data with revisitation distribution
plot(DATA,RD)
</code></pre>

<hr>
<h2 id='rsf.fit'>Fit integrated resource selection functions (iRSFs) with autocorrelation-adjusted weighted likelihood</h2><span id='topic+rsf.fit'></span><span id='topic+rsf.select'></span>

<h3>Description</h3>

<p>This function fits integrated resource selection functions with autocorrelation-adjusted weights on the RSF likelihood function, importance sampling, and iterative numerical convergence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rsf.fit(data,UD,R=list(),formula=NULL,integrated=TRUE,level.UD=0.99,
        reference="auto",debias=TRUE,smooth=TRUE,standardize=TRUE,integrator="MonteCarlo",
        error=0.01,max.mem="1 Gb",interpolate=TRUE,trace=TRUE,...)

rsf.select(data,UD,R=list(),formula=NULL,verbose=FALSE,IC="AICc",trace=TRUE,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rsf.fit_+3A_data">data</code></td>
<td>
<p>A <code>telemetry</code> object.</p>
</td></tr>
<tr><td><code id="rsf.fit_+3A_ud">UD</code></td>
<td>
<p>A <code>UD</code> object generated by <code><a href="#topic+akde">akde</a></code> from the same telemetry object as <code>data</code>. If weights were optimized in <code><a href="#topic+akde">akde</a></code>, then they will be adopted by <code>rsf.fit</code>.</p>
</td></tr>
<tr><td><code id="rsf.fit_+3A_r">R</code></td>
<td>
<p>A named list of rasters or time-varying raster stacks [NOT TESTED] to fit Poisson regression coefficients to (under a log link).</p>
</td></tr>
<tr><td><code id="rsf.fit_+3A_formula">formula</code></td>
<td>
<p>Formula object for <code class="reqn">\log(\lambda)</code> referencing the elements of <code>R</code> and columns of <code>data</code> (see Details below). If not specified, a linear term will be included for every element of <code>R</code>.</p>
</td></tr>
<tr><td><code id="rsf.fit_+3A_integrated">integrated</code></td>
<td>
<p>Fit an integrated RSF model with simultaneously estimated spatial constraints. <code>integrated=FALSE</code> is for comparison purposes only.</p>
</td></tr>
<tr><td><code id="rsf.fit_+3A_level.ud">level.UD</code></td>
<td>
<p>Coverage probability of <code>UD</code> to sample uniformly from if <code>integrated=FALSE</code>. Can also be a pre-defined spatial polygon object.</p>
</td></tr>
<tr><td><code id="rsf.fit_+3A_reference">reference</code></td>
<td>
<p>When expanding categorical predictors into indicator variables, <code>reference="auto"</code> will choose the most common predictor to be the reference category. Otherwise, the reference category can be specified by this argument.</p>
</td></tr>
<tr><td><code id="rsf.fit_+3A_debias">debias</code></td>
<td>
<p>Apply a post-hoc bias correction to the spatial constraint parameters, and apply bias corrections to the numerical log-likelihood estimates.</p>
</td></tr>
<tr><td><code id="rsf.fit_+3A_smooth">smooth</code></td>
<td>
<p>Apply location-error smoothing to the tracking data before regression.</p>
</td></tr>
<tr><td><code id="rsf.fit_+3A_standardize">standardize</code></td>
<td>
<p>For numerical stability, predictors are <em>internally</em> standardized, if <code>standardize=TRUE</code> and no <code>formula</code> is specified. (The final outputs are not standardized.) <b>Otherwise, users are responsible for standardizing their predictors.</b></p>
</td></tr>
<tr><td><code id="rsf.fit_+3A_integrator">integrator</code></td>
<td>
<p>Numerical integrator used for likelihood evaluation. Can be <code>"MonteCarlo"</code> or <code>"Riemann"</code> (IN TESTING).</p>
</td></tr>
<tr><td><code id="rsf.fit_+3A_error">error</code></td>
<td>
<p>Relative numerical error threshold for the parameter estimates and log-likelihood.</p>
</td></tr>
<tr><td><code id="rsf.fit_+3A_max.mem">max.mem</code></td>
<td>
<p>Maximum amount of memory to allocate for availability sampling.</p>
</td></tr>
<tr><td><code id="rsf.fit_+3A_interpolate">interpolate</code></td>
<td>
<p>Whether or not to interpolate raster values during extraction.</p>
</td></tr>
<tr><td><code id="rsf.fit_+3A_trace">trace</code></td>
<td>
<p>Report progress on convergence (see Details).</p>
</td></tr>
<tr><td><code id="rsf.fit_+3A_verbose">verbose</code></td>
<td>
<p>Returns all candidate models if <code>TRUE</code>. Otherwise, only the <code>IC</code>-best model is returned.</p>
</td></tr>
<tr><td><code id="rsf.fit_+3A_ic">IC</code></td>
<td>
<p>Model selection criterion. Can be AIC, AICc, or BIC.</p>
</td></tr>
<tr><td><code id="rsf.fit_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code>rsf.fit</code> or <code><a href="#topic+optimizer">optimizer</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For autocorrelated tracking data, the relative weights of the log-likelihood used here are taken from the output of <code><a href="#topic+akde">akde</a></code>, which are optimzed for non-parametric denstity estimation (if <code>weights=TRUE</code>, and so are approximate here. The absolute weight of the data is taken to be the effective sample size of the integrated spatial parameters, when estimated seperately.
</p>
<p>Integrated resource selection functions simultaneously estimate the spatially constraining (availability) parameters with the resource selection parameters, rather than first estimating the availability parameters (usually via MCP) and then holding those parameters fixed&mdash;as known values&mdash;when estimating the resource selection parameters. The &ldquo;integrated&rdquo; analysis reduces estimation bias, exposes correlations in the resource and availability estimate uncertainties, and propagates the availability estimate uncertainties into the final outputs.
</p>
<p>Instead of specifying a number of &ldquo;available&rdquo; points to sample and having an unknown amount of numerical error to contend with, <code>rsf.fit</code> specifies an estimation target <code>error</code> and the number of &ldquo;available&rdquo; points is increased until this target is met. Moreover, the output log-likelihood is that of the continuous Poisson point process, which does not depend on the number of &ldquo;available&rdquo; points that were sampled, though the numerical variance estimate is recorded in the <code>VAR.loglike</code> slot of the fit object.
</p>
<p>When <code>trace=TRUE</code>, a number of convergence estimates are reported, including the standard deviation of the numerical error of the log-likelihood, SD[<code class="reqn">\log(\ell)</code>], the most recent log-likelihood update, d<code class="reqn">\log(\ell)</code>, and the most recent (relative) parameter estimate updates d<code class="reqn">\hat{\beta}/</code>SD[<code class="reqn">\hat{\beta}</code>].
</p>
<p>The <code>formula</code> object determines the covariate dependence of <code class="reqn">\log(\lambda)</code> in the Poisson point process likelihood <code class="reqn">L(\lambda)=\frac{\lambda(x,y)}{\iint \lambda(x',y') \, dx' dy'}</code>, and can reference static rasters in <code>R</code>, time-dependent raster stacks in <code>R</code> [NOT TESTED], and time-dependent effect modifiers in the columns of <code>data</code>, such as provided by <code><a href="#topic+annotate">annotate</a></code>.
Any <code>offset</code> terms are applied under a log transformation (or multiplicatively to <code class="reqn">\lambda</code>), and can be used to enforce hard boundaries,
where <code>offset(raster)=TRUE</code> denotes accesible points and <code>offset(raster)=FALSE</code> denotes inaccessible points [NOT TESTED].
Intercept terms are ignored, as they generally do not make sense for individual Poisson point process models.
This includes terms only involving the columns of <code>data</code>, as they lack spatial dependence.
</p>
<p>Categorical raster variables are expanded into indicator variables, according to the <code>reference</code> category argument.
Upon import via <code><a href="raster.html#topic+raster">raster</a></code>, categorical variables may need to be assigned with <code><a href="raster.html#topic+as.factor">as.factor</a></code>, or else they may be interpreted as numerical variables.
</p>


<h3>Note</h3>

<p>It is much faster to calculate all predictors ahead of time and specifying them in the <code>R</code> list than to reference then in the <code>formula</code> argument, which will calculate them as needed, saving memory.
</p>
<p>AIC and BIC values for <code>integrated=FALSE</code> models do not include any penalty for the estimated location and shape of the available area, and so their AIC and BIC values  are expected to be <em>worse</em> than reported.</p>


<h3>Author(s)</h3>

<p> C. H. Fleming and B. Reineking </p>


<h3>References</h3>

<p>J. M. Alston, C. H. Fleming, R. Kays, J. P. Streicher, C. T. Downs, T. Ramesh, B. Reineking, &amp; J. M. Calabrese, &ldquo;Mitigating pseudoreplication and bias in resource selection functions with autocorrelation-informed weighting&rdquo;, Methods in Ecology and Evolution 14:2  643&ndash;654 (2023) <a href="https://doi.org/10.1111/2041-210X.14025">doi:10.1111/2041-210X.14025</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+ctmm.fit">ctmm.fit</a></code>, <code><a href="#topic+intensity">intensity</a></code>, <code><a href="#topic+optimizer">optimizer</a></code>, <code><a href="#topic+summary.ctmm">summary.ctmm</a></code>. </p>

<hr>
<h2 id='sdm.fit'>Fit species distribution models (SDMs) [IN DEVELOPMENT]</h2><span id='topic+sdm.fit'></span><span id='topic+sdm.select'></span><span id='topic+sdm.integrate'></span>

<h3>Description</h3>

<p>This function fits species distribution models, sampling density models, and integrated SDMs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sdm.fit(data,R=list(),formula=NULL,area=NULL,reference="auto",standardize=TRUE,
        integrator="MonteCarlo",error=0.01,max.mem="1 Gb",interpolate=TRUE,trace=TRUE,...)

sdm.select(data,R=list(),formula=NULL,area=NULL,verbose=FALSE,IC="AICc",trace=TRUE,...)

sdm.integrate(biased=NULL,bias=NULL,unbiased=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sdm.fit_+3A_data">data</code></td>
<td>
<p>A <code>telemetry</code> object.</p>
</td></tr>
<tr><td><code id="sdm.fit_+3A_r">R</code></td>
<td>
<p>A named list of rasters or time-varying raster stacks [NOT TESTED] to fit Poisson regression coefficients to (under a log link).</p>
</td></tr>
<tr><td><code id="sdm.fit_+3A_formula">formula</code></td>
<td>
<p>Formula object for <code class="reqn">\log(\lambda)</code> referencing the elements of <code>R</code> and columns of <code>data</code> (see Details below). If not specified, a linear term will be included for every element of <code>R</code>.</p>
</td></tr>
<tr><td><code id="sdm.fit_+3A_area">area</code></td>
<td>
<p>A spatial polygon object defining the extent of the SDM. If left <code>NULL</code>, an integrated Gaussian model will be used to define the extent of the SDM, which can be a very bad model for geographic ranges.</p>
</td></tr>
<tr><td><code id="sdm.fit_+3A_reference">reference</code></td>
<td>
<p>When expanding categorical predictors into indicator variables, <code>reference="auto"</code> will choose the most common predictor to be the reference category. Otherwise, the reference category can be specified by this argument.</p>
</td></tr>
<tr><td><code id="sdm.fit_+3A_standardize">standardize</code></td>
<td>
<p>For numerical stability, predictors are <em>internally</em> standardized, if <code>rescale=TRUE</code> and no <code>formula</code> is specified. (The final outputs are not standardized.) <b>Otherwise, users are responsible for standardizing their predictors.</b></p>
</td></tr>
<tr><td><code id="sdm.fit_+3A_integrator">integrator</code></td>
<td>
<p>Numerical integrator used for likelihood evaluation. Can be <code>"MonteCarlo"</code> or <code>"Riemann"</code> (IN TESTING).</p>
</td></tr>
<tr><td><code id="sdm.fit_+3A_error">error</code></td>
<td>
<p>Relative numerical error threshold for the parameter estimates and log-likelihood.</p>
</td></tr>
<tr><td><code id="sdm.fit_+3A_max.mem">max.mem</code></td>
<td>
<p>Maximum amount of memory to allocate for availability sampling.</p>
</td></tr>
<tr><td><code id="sdm.fit_+3A_interpolate">interpolate</code></td>
<td>
<p>Whether or not to interpolate raster values during extraction.</p>
</td></tr>
<tr><td><code id="sdm.fit_+3A_trace">trace</code></td>
<td>
<p>Report progress on convergence (see Details).</p>
</td></tr>
<tr><td><code id="sdm.fit_+3A_verbose">verbose</code></td>
<td>
<p>Returns all candidate models if <code>TRUE</code>. Otherwise, only the <code>IC</code>-best model is returned.</p>
</td></tr>
<tr><td><code id="sdm.fit_+3A_ic">IC</code></td>
<td>
<p>Model selection criterion. Can be AIC, AICc, or BIC.</p>
</td></tr>
<tr><td><code id="sdm.fit_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code>rsf.fit</code> or <code><a href="#topic+optimizer">optimizer</a></code>.</p>
</td></tr>
<tr><td><code id="sdm.fit_+3A_biased">biased</code></td>
<td>
<p>A biased SDM calculated from occurrence records with non-uniform sampling density.</p>
</td></tr>
<tr><td><code id="sdm.fit_+3A_bias">bias</code></td>
<td>
<p>An &ldquo;SDM&rdquo; calculated from data representative of the above sampling density.</p>
</td></tr>
<tr><td><code id="sdm.fit_+3A_unbiased">unbiased</code></td>
<td>
<p>An unbiased SDM or list of RSFs.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Instead of specifying a number of &ldquo;available&rdquo; points to sample and having an unknown amount of numerical error to contend with, <code>rsf.fit</code> specifies an estimation target <code>error</code> and the number of &ldquo;available&rdquo; points is increased until this target is met. Moreover, the output log-likelihood is that of the continuous Poisson point process, which does not depend on the number of &ldquo;available&rdquo; points that were sampled, though the numerical variance estimate is recorded in the <code>VAR.loglike</code> slot of the fit object.
</p>
<p>When <code>trace=TRUE</code>, a number of convergence estimates are reported, including the standard deviation of the numerical error of the log-likelihood, SD[<code class="reqn">\log(\ell)</code>], the most recent log-likelihood update, d<code class="reqn">\log(\ell)</code>, and the most recent (relative) parameter estimate updates d<code class="reqn">\hat{\beta}/</code>SD[<code class="reqn">\hat{\beta}</code>].
</p>
<p>The <code>formula</code> object determines <code class="reqn">\log(\lambda)</code> and can reference static rasters in <code>R</code>, time-dependent raster stacks in <code>R</code> [NOT TESTED], and time-dependent effect modifiers in the columns of <code>data</code>, such as provided by <code><a href="#topic+annotate">annotate</a></code>.
Any <code>offset</code> terms are applied under a log transformation (or multiplicatively to <code class="reqn">\lambda</code>), and can be used to enforce hard boundaries,
where <code>offset(raster)=TRUE</code> denotes accesible points and <code>offset(raster)=FALSE</code> denotes inaccessible points [NOT TESTED].
Intercept terms are ignored, as they generally do not make sense for individual Poisson point process models.
This includes terms only involving the columns of <code>data</code>, as they lack spatial dependence.
</p>
<p>Categorical raster variables are expanded into indicator variables, according to the <code>reference</code> category argument.
Upon import via <code><a href="raster.html#topic+raster">raster</a></code>, categorical variables may need to be assigned with <code><a href="raster.html#topic+as.factor">as.factor</a></code>, or else they may be interpreted as numerical variables.
</p>


<h3>Note</h3>

<p>It is much faster to calculate all predictors ahead of time and specifying them in the <code>R</code> list than to reference then in the <code>formula</code> argument, which will calculate them as needed, saving memory.
</p>
<p>AIC and BIC values for <code>integrated=FALSE</code> models do not include any penalty for the estimated location and shape of the available area, and so their AIC and BIC values  are expected to be <em>worse</em> than reported.</p>


<h3>Author(s)</h3>

<p> C. H. Fleming </p>


<h3>References</h3>

<p>J. M. Alston, C. H. Fleming, R. Kays, J. P. Streicher, C. T. Downs, T. Ramesh, B. Reineking, &amp; J. M. Calabrese, &ldquo;Mitigating pseudoreplication and bias in resource selection functions with autocorrelation-informed weighting&rdquo;, Methods in Ecology and Evolution 14:2  643&ndash;654 (2023) <a href="https://doi.org/10.1111/2041-210X.14025">doi:10.1111/2041-210X.14025</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+rsf.fit">rsf.fit</a></code>, <code><a href="#topic+optimizer">optimizer</a></code>, <code><a href="#topic+summary.ctmm">summary.ctmm</a></code>. </p>

<hr>
<h2 id='select'>Spatial selection methods for telemetry objects.</h2><span id='topic+lasso'></span><span id='topic+marquee'></span><span id='topic+cleave'></span>

<h3>Description</h3>

<p>Methods to segment or subset telemety objects based on polygon lasso, rectangular marquee, and time slider selectors.</p>


<h3>Usage</h3>

<pre><code class='language-R'>lasso(object,...)

marquee(object,...)

cleave(object,fraction=0.5,name="CLEFT",...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="select_+3A_object">object</code></td>
<td>
<p><code>telemetry</code> object or list of such objects.</p>
</td></tr>
<tr><td><code id="select_+3A_fraction">fraction</code></td>
<td>
<p>Initial split, as fraction of total time period.</p>
</td></tr>
<tr><td><code id="select_+3A_name">name</code></td>
<td>
<p>Name of list to store cleft telemetry objects to.</p>
</td></tr>
<tr><td><code id="select_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>plot</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>lasso</code> and <code>marquee</code> allow the user to subset telemetry data into two groups (interior and exterior), based on a hand-drawn polygon lasso or rectangular marquee. <code>cleave</code> allows the user to split the data into two halves at a particular time selected via slider.</p>


<h3>Value</h3>

<p><code>lasso</code> and <code>marquee</code> return a named list telemetry objects, twice the length of the input <code>object</code>, where the first half are the interior subsets and the second half are the exterior subsets. <code>cleave</code> stores a similar list of telemetry objects to <code>name</code> on button press.</p>


<h3>Author(s)</h3>

<p>C. H. Fleming.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+plot.telemetry">plot.telemetry</a></code>  </p>


<h3>Examples</h3>

<pre><code class='language-R'># This example is interactive
if(interactive())
{
  # Load package and data
  library(ctmm)
  data(wolf)

  # Extract wolf Luna
  DATA &lt;- wolf$Luna

  # Select resident data
  SUB &lt;- lasso(DATA)

  # You can now work with the resident and dispersive data separately
  names(SUB)
}
</code></pre>

<hr>
<h2 id='simulate.ctmm'>Predict or simulate from a continuous-time movement model</h2><span id='topic+predict'></span><span id='topic+predict.ctmm'></span><span id='topic+predict.telemetry'></span><span id='topic+simulate'></span><span id='topic+simulate.ctmm'></span><span id='topic+simulate.telemetry'></span>

<h3>Description</h3>

<p>Given a <code>ctmm</code> movement model (and optional <code>telemetry</code> data to condition upon) these functions predict or simulate animal locations over a prescribed set of times.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict(object,...)

## S3 method for class 'ctmm'
predict(object,data=NULL,VMM=NULL,t=NULL,dt=NULL,res=1,complete=FALSE,...)

## S3 method for class 'telemetry'
predict(object,CTMM=NULL,VMM=NULL,t=NULL,dt=NULL,res=1,complete=FALSE,...)

simulate(object,nsim=1,seed=NULL,...)

## S3 method for class 'ctmm'
simulate(object,nsim=1,seed=NULL,data=NULL,VMM=NULL,t=NULL,dt=NULL,res=1,complete=FALSE,
         precompute=FALSE,...)

## S3 method for class 'telemetry'
simulate(object,nsim=1,seed=NULL,CTMM=NULL,VMM=NULL,t=NULL,dt=NULL,res=1,complete=FALSE,
         precompute=FALSE,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulate.ctmm_+3A_object">object</code></td>
<td>
<p>A <code>ctmm</code> movement-model or <code>telemetry</code> object, which requires an additional <code>CTMM</code> argument.</p>
</td></tr>
<tr><td><code id="simulate.ctmm_+3A_data">data</code></td>
<td>
<p>Optional <code>telemetry</code> object on which the prediction or simulation will be conditioned.</p>
</td></tr>
<tr><td><code id="simulate.ctmm_+3A_ctmm">CTMM</code></td>
<td>
<p>A <code>ctmm</code> movement model in the same format as the output of <code><a href="#topic+ctmm.fit">ctmm.fit</a></code> or <code><a href="#topic+variogram.fit">variogram.fit</a></code>.</p>
</td></tr>
<tr><td><code id="simulate.ctmm_+3A_vmm">VMM</code></td>
<td>
<p>An optional vertical <code>ctmm</code> movement model for 3D predictions and simulations.</p>
</td></tr>
<tr><td><code id="simulate.ctmm_+3A_t">t</code></td>
<td>
<p>Optional array of numeric time values over which the process will be predicted or simulated.</p>
</td></tr>
<tr><td><code id="simulate.ctmm_+3A_dt">dt</code></td>
<td>
<p>Timestep to space the prediction or simulation over if <code>data</code> is specified.</p>
</td></tr>
<tr><td><code id="simulate.ctmm_+3A_res">res</code></td>
<td>
<p>Average number of locations to predict or simulate per <code>data</code> time.</p>
</td></tr>
<tr><td><code id="simulate.ctmm_+3A_complete">complete</code></td>
<td>
<p>Additionally calculate timestamps and geographic coordinates.</p>
</td></tr>
<tr><td><code id="simulate.ctmm_+3A_nsim">nsim</code></td>
<td>
<p>Generates a list of <code>nsim</code> simulations.</p>
</td></tr>
<tr><td><code id="simulate.ctmm_+3A_seed">seed</code></td>
<td>
<p>Optional random seed to fix.</p>
</td></tr>
<tr><td><code id="simulate.ctmm_+3A_precompute">precompute</code></td>
<td>
<p>Precalculate matrices of the Kalman filter (see details).</p>
</td></tr>
<tr><td><code id="simulate.ctmm_+3A_...">...</code></td>
<td>
<p>Unused options.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The prediction or simulation necessarily requires a <code>ctmm</code> model object.
If a <code>telemetry</code> <code>data</code> object is supplied, the output will be conditional on the <code>data</code> (i.e., simulations that run through the data).
If no <code>data</code> is provided then the output will be purely Gaussian, and times <code>t</code> must be provided.
Details of the movement model parameters can be found in <code><a href="#topic+ctmm.fit">ctmm.fit</a></code>.
</p>
<p>The <code>t</code> argument fixes the output times to a specific array of times.
The <code>dt</code> and <code>res</code> arguments are relative to the sampling schedule present in the optional <code>telemetry</code> object.
The same span of time will be used, while <code>dt</code> will fix the sampling rate absolutely and <code>res</code> will fix the sampling rate relative to that of the data.
</p>
<p>The <code>precompute</code> option can speed up calculations of multiple simulations of the same model, data, and <em>irregular</em> sampling schedule.
First run <code>simulate</code> with <code>precompute=TRUE</code> to calculate and store all of the necessary matrices of the Kalman filter.
A simulated <code>telemetry</code> object will be produced, as usual, and the precomputed objects are stored in the environment.
Subsequent simulations with <code>precompute=-1</code> will then apply these precomputed matrices for a computational cost savings.
If the sampling schedule is irregular, then this can result in faster simulations.
</p>


<h3>Value</h3>

<p> A simulated animal-tracking <code>telemetry</code> object with components <code>t</code>, <code>x</code>, and <code>y</code>, or a predicted <code>telemetry</code> object that also includes <code>x</code>-<code>y</code> covariances for the location point estimates <code>x</code> and <code>y</code>. </p>


<h3>Note</h3>

<p> Predictions are autocorrelated and should not be treated as data. </p>


<h3>Author(s)</h3>

<p> C. H. Fleming. </p>


<h3>References</h3>

<p>C. H. Fleming, J. M. Calabrese, T. Mueller, K.A. Olson, P. Leimgruber, W. F. Fagan,
&ldquo;From fine-scale foraging to home ranges: A semi-variance approach to identifying movement modes across spatiotemporal scales&rdquo;,
The American Naturalist, 183:5, E154-E167 (2014) <a href="https://doi.org/10.1086/675504">doi:10.1086/675504</a>.
</p>
<p>C. H. Fleming, D. Sheldon, E. Gurarie, W. F. Fagan, S. LaPoint, J. M. Calabrese,
&ldquo;Kálmán filters for continuous-time movement models&rdquo;,
Ecological Informatics, 40, 8-21 (2017) <a href="https://doi.org/10.1016/j.ecoinf.2017.04.008">doi:10.1016/j.ecoinf.2017.04.008</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+ctmm.fit">ctmm.fit</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Load package
library(ctmm)

#prepare simulation parameters
t &lt;- 1:1000
MODEL &lt;- ctmm(tau=c(100,10),sigma=10,mu=c(0,0))

#simulate data
SIM &lt;- simulate(MODEL,t=t)

#plot data with Gaussian model
plot(SIM,CTMM=MODEL)
</code></pre>

<hr>
<h2 id='speed'>Estimate the average speed of a tracked animal</h2><span id='topic+speed'></span><span id='topic+speed.ctmm'></span><span id='topic+speed.telemetry'></span><span id='topic+speeds'></span><span id='topic+speeds.ctmm'></span><span id='topic+speeds.telemetry'></span>

<h3>Description</h3>

<p>Given a <code>ctmm</code> movement model and <code>telemetry</code> data, <code>speed</code> simulates multiple realizations of the individual's trajectory to estimate the time-averaged speed, which is proportional to distance traveled, while <code>speeds</code> estimates instantaneous speeds at a specified array of times <code>t</code>. Both tortuosity (non straight-line motion between the data) and telemetry error can be accounted for. Given only a <code>ctmm</code> movement model and no data, <code>speed</code> calculates the mean speed of the Gaussian movement process. All methods are described in Noonan &amp; Fleming et al (2019).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>speed(object,...)

## S3 method for class 'ctmm'
speed(object,data=NULL,t=NULL,level=0.95,robust=FALSE,units=TRUE,prior=TRUE,fast=TRUE,
      cor.min=0.5,dt.max=NULL,error=0.01,cores=1,trace=TRUE,...)

## S3 method for class 'telemetry'
speed(object,CTMM,t=NULL,level=0.95,robust=FALSE,units=TRUE,prior=TRUE,fast=TRUE,
      cor.min=0.5,dt.max=NULL,error=0.01,cores=1,trace=TRUE,...)

speeds(object,...)

## S3 method for class 'ctmm'
speeds(object,data=NULL,t=NULL,cycle=Inf,level=0.95,robust=FALSE,prior=FALSE,fast=TRUE,
       error=0.01,cores=1,trace=TRUE,...)

## S3 method for class 'telemetry'
speeds(object,CTMM,t=NULL,cycle=Inf,level=0.95,robust=FALSE,prior=FALSE,fast=TRUE,
       error=0.01,cores=1,trace=TRUE,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="speed_+3A_object">object</code></td>
<td>
<p>A <code>ctmm</code> movement-model or <code>telemetry</code> object, which requires an additional <code>CTMM</code> argument.</p>
</td></tr>
<tr><td><code id="speed_+3A_data">data</code></td>
<td>
<p>Optional <code>telemetry</code> object on which the simulations will be conditioned.</p>
</td></tr>
<tr><td><code id="speed_+3A_ctmm">CTMM</code></td>
<td>
<p>Movement model object.</p>
</td></tr>
<tr><td><code id="speed_+3A_t">t</code></td>
<td>
<p>Array of times to estimate instantaneous speeds at, or range of times to estimate mean speed over.</p>
</td></tr>
<tr><td><code id="speed_+3A_cycle">cycle</code></td>
<td>
<p>Average over time <code>t</code> indices modulo <code>cycle</code>. E.g., for <code>t</code> sequenced by hours, <code>cycle=24</code> gives daily the cycle of speeds. (Not yet supported.)</p>
</td></tr>
<tr><td><code id="speed_+3A_level">level</code></td>
<td>
<p>Confidence level to report on the estimated average speed.</p>
</td></tr>
<tr><td><code id="speed_+3A_robust">robust</code></td>
<td>
<p>Use robust statistics for the ensemble average and its confidence intervals (see Details).</p>
</td></tr>
<tr><td><code id="speed_+3A_units">units</code></td>
<td>
<p>Convert result to natural units.</p>
</td></tr>
<tr><td><code id="speed_+3A_prior">prior</code></td>
<td>
<p>Account for model parameter uncertainty.</p>
</td></tr>
<tr><td><code id="speed_+3A_fast">fast</code></td>
<td>
<p>Whether or not to invoke the central-limit theorem when propagating parameter uncertainty (see <code><a href="#topic+emulate">emulate</a></code>).</p>
</td></tr>
<tr><td><code id="speed_+3A_cor.min">cor.min</code></td>
<td>
<p>Velocity correlation threshold for skipping gaps.</p>
</td></tr>
<tr><td><code id="speed_+3A_dt.max">dt.max</code></td>
<td>
<p>Absolute gap sizes to skip (in seconds), alternative to <code>cor.min</code>.</p>
</td></tr>
<tr><td><code id="speed_+3A_error">error</code></td>
<td>
<p>Target (relative) standard error.</p>
</td></tr>
<tr><td><code id="speed_+3A_cores">cores</code></td>
<td>
<p>Number of simulations to run in parallel. <code>cores=0</code> will use all cores, while <code>cores&lt;0</code> will reserve <code>abs(cores)</code>.</p>
</td></tr>
<tr><td><code id="speed_+3A_trace">trace</code></td>
<td>
<p>Display a progress bar.</p>
</td></tr>
<tr><td><code id="speed_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code><a href="#topic+emulate">emulate</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>cor.min</code> or <code>dt.max</code> arguments are used to constrain the estimate to be derived from simulations near the data, and therefore ensure that the estimate is more reflective of the data than the model.
</p>
<p>If data quality is poor and velocity can barely be resolved, then the sampling distribution may occassionally include impersistent motion and its mean will be infinite. In these cases <code>robust=TRUE</code> can be used to report the sampling distribution's median rather than its mean. The time average of <code>speed</code>, in either case, is still the mean average of times and the resulting quantity is still proportional to distance traveled. Furthermore, note that medians should be compared to medians and means to means, so the <code>robust</code> option should be the same for all compared individuals.
</p>


<h3>Value</h3>

<p> Returns the estimated mean speed of the sampled trajectory with CIs by default. If <code>level=NULL</code>, then the ensemble of mean speeds is returned instead. </p>


<h3>Note</h3>

<p> The mean speed estimated by <code>speed</code> is applicable only during the sampling periods. If an individual is diurnal/nocturnal and only tracked during the day/night, then the output of <code>speed</code> will only be the mean speed during the day/night. For instance, if an individual is tracked the 12 hours per day during which it is active, and <code>speed</code> reports a mean speed of 10 kilometers per day during those periods, then the average distance traveled per day is only 5 kilometers (from 10 kilometers <code>/</code> day <code>*</code> 12 hours). An average of 10 kilometers would only result if the individual were similarly active for 24 hours a day.
</p>
<p>The average speeds estimated here are mean speeds. The speeds reported by <code><a href="#topic+summary.ctmm">summary.ctmm</a></code> are root-mean-square (RMS) speeds. These quantities are sometimes proportional, but not equivalent. </p>


<h3>Author(s)</h3>

<p> C. H. Fleming. </p>


<h3>References</h3>

<p>M. J. Noonan, C. H. Fleming, T. S. Akre, J. Drescher-Lehman, E. Gurarie, A.-L. Harrison, R. Kays, Justin Calabrese,
&ldquo;Scale-insensitive estimation of speed and distance traveled from animal tracking data&rdquo;,
<a href="https://movementecologyjournal.biomedcentral.com/articles/10.1186/s40462-019-0177-1">Movement Ecology, 7:35 (2019)</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+emulate">emulate</a></code>, <code><a href="#topic+simulate">simulate</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load package and data
library(ctmm)
data(buffalo)
DATA &lt;- buffalo$Gabs

GUESS &lt;- ctmm.guess(DATA,interactive=FALSE)
# in general, you should use ctmm.select instead
FIT &lt;- ctmm.fit(DATA,GUESS)

# stationary Gaussian estimate
speed(FIT)

# conditional estimate
# you will likely want trace=TRUE
speed(FIT,DATA,trace=FALSE)
</code></pre>

<hr>
<h2 id='summary.ctmm'>Summarize a continuous-time movement model</h2><span id='topic+summary.ctmm'></span>

<h3>Description</h3>

<p> This function returns a list of biologically interesting parameters in human readable format, as derived from a continuous-time movement model.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ctmm'
summary(object,level=0.95,level.UD=0.95,units=TRUE,IC=NULL,MSPE=NULL,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.ctmm_+3A_object">object</code></td>
<td>
<p> A <code>ctmm</code> movement-model object from the output of <code>ctmm.fit</code>. </p>
</td></tr>
<tr><td><code id="summary.ctmm_+3A_level">level</code></td>
<td>
<p> Confidence level for parameter estimates. </p>
</td></tr>
<tr><td><code id="summary.ctmm_+3A_level.ud">level.UD</code></td>
<td>
<p> Coverage level for the Gaussian home-range area. </p>
</td></tr>
<tr><td><code id="summary.ctmm_+3A_units">units</code></td>
<td>
<p>Convert result to natural units.</p>
</td></tr>
<tr><td><code id="summary.ctmm_+3A_ic">IC</code></td>
<td>
<p>Information criteria for sorting lists of <code>ctmm</code> objects. Can be <code>"AICc"</code>, <code>"AIC"</code>, <code>"BIC"</code>, <code>"LOOCV"</code>, <code>"HSCV"</code>, or none (<code>NA</code>). AICc is approximate.</p>
</td></tr>
<tr><td><code id="summary.ctmm_+3A_mspe">MSPE</code></td>
<td>
<p>Sort models with the same autocovariance structure by the mean square predictive error of <code>"position"</code>, <code>"velocity"</code>, or not (<code>NA</code>).</p>
</td></tr>
<tr><td><code id="summary.ctmm_+3A_...">...</code></td>
<td>
<p>Unused options.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If summary is called with a single <code>ctmm</code> object output from <code><a href="#topic+ctmm.fit">ctmm.fit</a></code>, then a list is returned with the effective sample sizes of various parameter estimates (<code>DOF</code>) and a parameter estimate table <code>CI</code>, with low, point, and high estimates for the following possible parameters:
</p>

<dl>
<dt><code>tau</code></dt><dd><p>The autocorrelation timescales. <code>tau position</code> is also the home-range crossing timescale.</p>
</dd>
<dt><code>area</code></dt><dd><p>The Gaussian home-range area, where the point estimate has a significance level of <code>level.UD</code>. I.e., the core home range is where the animal is located 50% of the time with <code>level.UD=0.50</code>.
This point estimate itself is subject to uncertainty, and is given confidence intervals derived from <code>level</code>.
</p>
<p>This Gaussian estimate differs from the kernel density estimate of <code><a href="#topic+summary.UD">summary.UD</a></code>. The Gaussian estimate has more statistical efficiency, but is less related to space use for non-Gaussian processes.</p>
</dd>
<dt><code>speed</code></dt><dd><p>The Gaussian root-mean-square (RMS) velocity, which is a convenient measure of average speed but not the conventional measure of average speed (see <code><a href="#topic+speed">speed</a></code>).</p>
</dd>
</dl>

<p>If summary is called on a list of <code>ctmm</code> objects output from <code><a href="#topic+ctmm.select">ctmm.select</a></code>, then a table is returned with the model names and IC differences for comparison across autocovariance structures. The mean square prediction error (MSPE) is also returned for comparison across trend structures (with autocovariance structure fixed). For the model names, &quot;IID&quot; denotes the uncorrelated bi-variate Gaussian model, &quot;OU&quot; denotes the continuous-position Ornstein-Uhlenbeck model, &quot;OUF&quot; denotes the continuous-velocity Ornstein-Uhlenbeck-F model, &quot;OUf&quot; denotes the OUF model where the two autocorrelation timescales cannot be statistically distinguished.
</p>


<h3>Note</h3>

<p> Confidence intervals on the autocorrelation timescales assume they are sufficiently greater than zero and less than infinity.
</p>
<p><code>IC="LOOCV"</code> can only be attempted if also specified during <code><a href="#topic+ctmm.select">ctmm.select</a></code>, as this argument requires additional calculations.
</p>
<p>Prior to <code>ctmm</code> v0.6.2, timescale confidence intervals were constructed from normal and inverse-normal sampling distributions, whereas v0.6.2 onward uses gamma and inverse-gamma sampling distributions.
</p>
<p>In <code>ctmm</code> v0.5.1 onward the MSPE is averaged over all possible times instead of over all sampled times.
</p>
<p>In <code>ctmm</code> v0.3.4 the speed estimate was fixed to be the RMS velocity and not <code class="reqn">1/\sqrt{2}</code> times the RMS velocity.
</p>


<h3>Author(s)</h3>

<p> C. H. Fleming. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+ctmm.fit">ctmm.fit</a></code>, <code><a href="#topic+ctmm.select">ctmm.select</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load package and data
library(ctmm)
data(buffalo)

# Extract movement data for a single animal
DATA &lt;- buffalo$Cilla

# fit model
GUESS &lt;- ctmm.guess(DATA,interactive=FALSE)
FIT &lt;- ctmm.fit(DATA,GUESS)

# Tell us something interpretable
summary(FIT)
</code></pre>

<hr>
<h2 id='summary.UD'>Summarize a range distribution</h2><span id='topic+summary.UD'></span>

<h3>Description</h3>

<p> This function returns a list of biologically interesting parameters in human readable format, as derived from an autocorrelated kernel density estimate.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'UD'
summary(object,convex=FALSE,level=0.95,level.UD=0.95,units=TRUE,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.UD_+3A_object">object</code></td>
<td>
<p> An <code>akde</code> autocorrelated kernel-density estimate from the output of <code>akde</code>.</p>
</td></tr>
<tr><td><code id="summary.UD_+3A_convex">convex</code></td>
<td>
<p>Report convex coverage areas if <code>TRUE</code>. By default, the highest density regions (HDRs) are reported.</p>
</td></tr>
<tr><td><code id="summary.UD_+3A_level">level</code></td>
<td>
<p> Confidence level for the above area estimate. E.g., the 95% confidence interval of the 50% core area.</p>
</td></tr>
<tr><td><code id="summary.UD_+3A_level.ud">level.UD</code></td>
<td>
<p> Coverage level for the home-range area. E.g., the 50% core area. </p>
</td></tr>
<tr><td><code id="summary.UD_+3A_units">units</code></td>
<td>
<p>Convert result to natural units.</p>
</td></tr>
<tr><td><code id="summary.UD_+3A_...">...</code></td>
<td>
<p>Unused options.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list is returned with the effective sample sizes of various parameter estimates (<code>DOF</code>) and a parameter estimate table <code>CI</code>, with low, point, and high estimates for the following possible parameters:
</p>

<dl>
<dt><code>area</code></dt><dd><p>The home-range area with fraction of inclusion <code>level.UD</code>. E.g., the 50% core home range is estimated with <code>level.UD=0.50</code>, and 95% confidence intervals are placed on that area estimate with <code>level=0.95</code>.
</p>
<p>This kernel density estimate differs from the Gaussian estimate of <code><a href="#topic+summary.ctmm">summary.ctmm</a></code>. The Gaussian estimate has more statistical efficiency, but is less related to space use for non-Gaussian processes.</p>
</dd>
</dl>



<h3>Note</h3>

<p> Prior to <code>ctmm</code> v0.3.1, AKDEs included only errors due to autocorrelation uncertainty, which are insignificant in cases such as IID data.
Starting in v0.3.1, <code>akde</code> calculated an effective sample size <code>DOF.H</code> and used this to estimate area uncertainty under a chi-square approxmation.
Starting in v0.3.2, this method was improved to use <code>DOF.area</code> in the Gaussian reference function approximation.
</p>


<h3>Author(s)</h3>

<p> C. H. Fleming. </p>


<h3>References</h3>

<p>C. H. Fleming, J. M. Calabrese.
A new kernel-density estimator for accurate home-range and species-range area estimation.
Methods in Ecology and Evolution, 8:5, 571-579 (2016) <a href="https://doi.org/10.1111/2041-210X.12673">doi:10.1111/2041-210X.12673</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+akde">akde</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load package and data
library(ctmm)
data(buffalo)

# Extract movement data for a single animal
DATA &lt;- buffalo$Cilla

# Fit a movement model
GUESS &lt;- ctmm.guess(DATA,interactive=FALSE)
FIT &lt;- ctmm.fit(DATA,GUESS)

# Estimate and summarize the AKDE
UD &lt;- akde(DATA,FIT)
summary(UD)
</code></pre>

<hr>
<h2 id='turtle'>Wood turtle GPS and calibration dataset from Working Land and Seascapes.</h2><span id='topic+turtle'></span>

<h3>Description</h3>

<p><code>x-y</code> projected GPS data from 2 calibration runs and 2 wood turtles.
Please contact Tom Akre (akret@si.edu) if you want to publish with these data.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("turtle")</code></pre>


<h3>Format</h3>

<p> A list of 4 <code>telemetry</code> objects.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+as.telemetry">as.telemetry</a></code>, <code><a href="#topic+plot.telemetry">plot.telemetry</a></code>, <code><a href="#topic+uere">uere</a></code>, <code><a href="#topic+buffalo">buffalo</a></code>, <code><a href="#topic+coati">coati</a></code>, <code><a href="#topic+gazelle">gazelle</a></code>, <code><a href="#topic+jaguar">jaguar</a></code>, <code><a href="#topic+pelican">pelican</a></code>, <code><a href="#topic+wolf">wolf</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'># Load package and data
library(ctmm)
data("turtle")

# Plot a turtle's locations
plot(turtle[[3]])
</code></pre>

<hr>
<h2 id='uere'>Estimate RMS UERE from calibration data</h2><span id='topic+uere'></span><span id='topic+uere.fit'></span><span id='topic+uere+3C-'></span><span id='topic+summary.UERE'></span>

<h3>Description</h3>

<p>Functions for estimating and assigning the root-mean-square User Equivalent Range Error (UERE) of a GPS device from calibration data.</p>


<h3>Usage</h3>

<pre><code class='language-R'>uere(data)

uere(data) &lt;- value

uere.fit(data,precision=1/2)

## S3 method for class 'UERE'
summary(object,level=0.95,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="uere_+3A_data">data</code></td>
<td>
<p><code>telemetry</code> object or list of telemetry objects, preferably with DOP columns.</p>
</td></tr>
<tr><td><code id="uere_+3A_value">value</code></td>
<td>
<p>RMS UERE value(s) to assign to telemetry data (see details).</p>
</td></tr>
<tr><td><code id="uere_+3A_precision">precision</code></td>
<td>
<p>Fraction of maximum possible digits of precision to target in categorical error fitting. <code>precision=1/2</code> results in about 7 decimal digits of precision.</p>
</td></tr>
<tr><td><code id="uere_+3A_object">object</code></td>
<td>
<p><code>UERE</code> object to summarize or list of <code>UERE</code> objects to compare.</p>
</td></tr>
<tr><td><code id="uere_+3A_level">level</code></td>
<td>
<p>Confidence level for UERE estimate confidence intervals.</p>
</td></tr>
<tr><td><code id="uere_+3A_...">...</code></td>
<td>
<p>Further arguments are ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Often times GPS animal tracking devices return HDOP values but do not specifiy the device's RMS UERE necessary to transform the HDOP values into absolute errors.
<code>uere.fit()</code> allows users to estimate the RMS UERE from calibration data, where the device was left fixed over a period of time.
The calibration RMS UERE can then be applied to tracking data with the <code>uere()&lt;-</code> assignment method.
Otherwise, when <code>error=TRUE</code> in <code><a href="#topic+ctmm">ctmm</a></code>, <code><a href="#topic+ctmm.fit">ctmm.fit</a></code> will estimate the RMS UERE simultaneously with the movement model, which is less reliable than using calibration data.
</p>
<p><code>summary()</code> applied to single <code>UERE</code> object will return RMS UERE parameter estimates and confidence intervals in meters, while <code>summary()</code> applied to a list of <code>UERE</code> objects will return a model-selection table, with AICc and reduced Z squared (goodness of fit) values.
</p>


<h3>Value</h3>

<p>The RMS UERE estimate.</p>


<h3>Note</h3>

<p>The GPS device should be fixed during calibraiton.</p>


<h3>Author(s)</h3>

<p>C. H. Fleming</p>


<h3>References</h3>

<p>C. H. Fleming et al, &ldquo;A comprehensive framework for handling location error in animal tracking data&rdquo;, bioRxiv 2020.06.12.130195 (2020) <a href="https://doi.org/10.1101/2020.06.12.130195">doi:10.1101/2020.06.12.130195</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+as.telemetry">as.telemetry</a></code>, <code><a href="#topic+residuals.telemetry">residuals.telemetry</a></code>.  </p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load package and data
library(ctmm)
data(turtle)

# the first two datasets are calibration data
names(turtle)

# estimate RMS UERE from calibration data
UERE &lt;- uere.fit(turtle[1:2])
# inspect UERE estimate
summary(UERE)

# assign RMS UERE to entire dataset
uere(turtle) &lt;- UERE

# calculate residuals of calibration data
RES &lt;- lapply(turtle[1:2],residuals)

# scatter plot of residuals with 50%, 95%, and 99.9% coverage areas
plot(RES,col.DF=NA,level.UD=c(0.50,0.95,0.999))

# check calibration data for autocorrelation using fast=FALSE because samples are small
ACFS &lt;- lapply(RES,function(R){correlogram(R,fast=FALSE,dt=10 %#% 'min',trace=FALSE)})

# pooling ACFs
ACF &lt;- mean(ACFS)

plot(ACF)
</code></pre>

<hr>
<h2 id='Unit+20conversion'>Convert dimensionful quantities to and from SI units</h2><span id='topic++25+23+25'></span>

<h3>Description</h3>

<p>This function takes a number in some specified units and converts that number to SI units,
or from SI units to the specified units.
Internally, all <code>ctmm</code> objects are specified in SI units, and so this is a utility function to facilitate working with <code>ctmm</code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>x %#% y
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Unit+2B20conversion_+3A_x">x</code></td>
<td>
<p>A numeric quantity specified in <code>y</code> character labeled units, or a character unit label to convert a numeric quantity <code>y</code> that is specified in SI units.</p>
</td></tr>
<tr><td><code id="Unit+2B20conversion_+3A_y">y</code></td>
<td>
<p>A unit character label for the quantity <code>x</code> to be converted to SI units, or a numeric quantity in SI units to be converted into unit label <code>x</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>x</code> is a number and <code>y</code> is a character unit label, then <code>x</code> is converted from units <code>y</code> to SI units. If <code>x</code> is a character unit label and <code>y</code> is a number, then <code>y</code> is converted from SI units to units <code>x</code>.
</p>
<p>The default non-SI units include the mean solar <code>'day'</code>, mean synodic <code>'month'</code> and mean tropical <code>'year'</code>. These defaults can be changed to conventional calendar units via <code>options(time.units='calendar')</code>.
</p>


<h3>Value</h3>

<p>Returns a numeric in SI units or units specified by character label <code>x</code>.</p>


<h3>Author(s)</h3>

<p> C. H. Fleming. </p>


<h3>See Also</h3>

 <p><code><a href="grid.html#topic+unit">unit</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># one yard -&gt; meters
1 %#% "yard"

# one meter -&gt; yards
"yard" %#% 1

# 1 month -&gt; days
"day" %#% 1 %#% "month"

# 6 miles per hour -&gt; meters per second
"hour" %#% 6 %#% "mile"

# the same conversion in one step
6 %#% "mph"
</code></pre>

<hr>
<h2 id='variogram'>Calculate an empirical variogram from movement data</h2><span id='topic+variogram'></span>

<h3>Description</h3>

<p>This function calculates the empirical variogram of multi-dimensional tracking data for visualizing stationary (time-averaged) autocorrelation structure.
One of two algorithms is used. The slow <code class="reqn">O(n^2)</code> algorithm is based upon Fleming &amp; Calabrese et al (2014), but with interval-weights instead of lag-weights and an iterative algorithm to adjust for calibrated errors.
Additional modifications have also been included to accommodate drift in the sampling rate.
The fast <code class="reqn">O(n \log n)</code> algorithm is based upon the FFT method of Marcotte (1996), with some tweaks to better handle irregularly sampled data.
Both methods reduce to the unbiased &ldquo;method of moments&rdquo; estimator in the case of evenly <em>scheduled</em> data, even with missing observations, but they produce slightly different outputs for irregularly sampled data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>variogram(data,dt=NULL,fast=TRUE,res=1,CI="Markov",error=FALSE,axes=c("x","y"),
          precision=1/8,trace=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="variogram_+3A_data">data</code></td>
<td>
 <p><code>telemetry</code> data object of the 2D timeseries data. </p>
</td></tr>
<tr><td><code id="variogram_+3A_dt">dt</code></td>
<td>
<p> Lag bin width. An ordered array will yield a progressive coarsening of the lags. Defaults to the median sampling interval.</p>
</td></tr>
<tr><td><code id="variogram_+3A_fast">fast</code></td>
<td>
<p> Use the interval-weighted algorithm if <code>FALSE</code> or the FFT algorithm if <code>TRUE</code>. The slow algorithm outputs a progress bar.</p>
</td></tr>
<tr><td><code id="variogram_+3A_res">res</code></td>
<td>
<p>Increase the discretization resolution for irregularly sampled data with <code>res&gt;1</code>. Decreases bias at the cost of smoothness.</p>
</td></tr>
<tr><td><code id="variogram_+3A_ci">CI</code></td>
<td>
<p>Argument for confidence-interval estimation. Can be <code>"IID"</code> to consider all unique lags as independent, <code>"Markov"</code> to consider only non-overlapping lags as independent, or <code>"Gauss"</code> for an exact calculation (see Details below).</p>
</td></tr>
<tr><td><code id="variogram_+3A_error">error</code></td>
<td>
<p>Adjust for the effect of calibrated errors.</p>
</td></tr>
<tr><td><code id="variogram_+3A_axes">axes</code></td>
<td>
<p>Array of axes to calculate an average (isotropic) variogram for.</p>
</td></tr>

<tr><td><code id="variogram_+3A_precision">precision</code></td>
<td>
<p>Fraction of machine precision to target when adjusting for telemetry error (<code>fast=FALSE</code> with calibrated errors). <code>precision=1/8</code> returns about 2 decimal digits of precision.</p>
</td></tr>
<tr><td><code id="variogram_+3A_trace">trace</code></td>
<td>
<p>Display a progress bar if <code>fast=FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If no <code>dt</code> is specified, the median sampling interval is used. This is typically a good assumption for most data, even when there are gaps. A <code>dt</code> coarser than the sampling interval may bias the variogram (particuarly if <code>fast=TRUE</code>) and so this should be reserved for poor data quality.
</p>
<p>For irregularly sampled data, it may be useful to provide an array of time-lag bin widths to progressively coarsen the variogram. I.e., if you made the very bad choice of changing your sampling interval on the fly from <code>dt1</code> to <code>dt2</code>, where <code>dt1</code> <code class="reqn">&lt;</code> <code>dt2</code>, the an appropriate choice would be <code>dt=c(dt1,dt2)</code>. On the other hand, if your sampling is itself a noisy process, then you might want to introduce larger and larger <code>dt</code> components as the visual appearance of the variogram breaks down with increasing lags.
Alternatively, you might try the <code>fast=FALSE</code> option or aggregating multiple individuals with <code><a href="#topic+mean.variogram">mean.variogram</a></code>.
</p>
<p>With irregularly sampled data, different size lags must be aggregated together, and with current fast methods there is a tradeoff between bias and smoothness. The default settings produce a relatively smooth estimate, while increasing <code>res</code> (or setting <code>fast=FALSE</code>) will produce a less biased estimate, which is very useful for <code><a href="#topic+correlogram">correlogram</a></code>.
</p>
<p>In conventional variogram regression treatments, all lags are considered as independent (<code>CI="IID"</code>) for the purposes of confidence-interval estimation, even if they overlap in time. However, in high resolution datasets this will produce vastly underestimated confidence intervals. Therefore, the default <code>CI="Markov"</code> behavior is to consider only the maximum number of non-overlapping lags in calculating confidence intervals, though this is a crude approximation and is overly conservative at large lags. <code>CI="Gauss"</code> implements exact confidence intervals under the assumption of a stationary Gaussian process, but this algorithm is <code class="reqn">O(n^2 \log n)</code> even when <code>fast=TRUE</code>.
</p>
<p>If <code>fast=FALSE</code> and the tracking data are calibrated (see <code><a href="#topic+uere">uere</a></code>), then with <code>error=TRUE</code> the variogram of the movement process (sans the telemetry-error process) is estimated using an iterative maximum-likelihood esitmator that downweights more erroneous location estimates (Fleming et al, 2020). The variogram is targeted to have <code>precision</code> fraction of machine precision. If the data are very irregular and location errors are very homoskedastic, then this algorithm can be slow to converge at time lags where there are few data pairs.
If <code>fast=TRUE</code> and <code>error=TRUE</code>, then the estimated contribution to the variogram from location error is subtracted on a per lag basis, which is less ideal for heteroskedastic errors.
</p>


<h3>Value</h3>

<p>Returns a variogram object (class variogram) which is a dataframe containing the time-lag, <code>lag</code>, the semi-variance estimate at that lag, <code>SVF</code>, and the approximate number of degrees of freedom associated with that semi-variance, <code>DOF</code>, with which its confidence intervals can be estimated.
</p>


<h3>Note</h3>

<p> Prior to <code>ctmm</code> v0.3.6, <code>fast=FALSE</code> used the lag-weighted esitmator of Fleming et al (2014). Lag weights have been abandoned in favor of interval weights, which are less sensitive to sampling irregularity. The same weighting formulas are used, but with <code>dt</code> instead of the current lag. </p>


<h3>Author(s)</h3>

<p> C. H. Fleming and J. M. Calabrese. </p>


<h3>References</h3>

<p>D. Marcotte, &ldquo;Fast variogram computation with FFT&rdquo;, Computers and Geosciences 22:10, 1175-1186 (1996) <a href="https://doi.org/10.1016/S0098-3004%2896%2900026-X">doi:10.1016/S0098-3004(96)00026-X</a>.
</p>
<p>C. H. Fleming, J. M. Calabrese, T. Mueller, K.A. Olson, P. Leimgruber, W. F. Fagan,
&ldquo;From fine-scale foraging to home ranges: A semi-variance approach to identifying movement modes across spatiotemporal scales&rdquo;,
The American Naturalist, 183:5, E154-E167 (2014) <a href="https://doi.org/10.1086/675504">doi:10.1086/675504</a>.
</p>
<p>C. H. Fleming et al, &ldquo;A comprehensive framework for handling location error in animal tracking data&rdquo;,
bioRxiv (2020) <a href="https://doi.org/10.1101/2020.06.12.130195">doi:10.1101/2020.06.12.130195</a>.
</p>


<h3>See Also</h3>

 <p><code>vignette("variogram")</code>, <code><a href="#topic+correlogram">correlogram</a></code>, <code><a href="#topic+mean.variogram">mean.variogram</a></code>, <code><a href="#topic+plot.variogram">plot.variogram</a></code>, <code><a href="#topic+variogram.fit">variogram.fit</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Load package and data
library(ctmm)
data(buffalo)

#Extract movement data for a single animal
DATA &lt;- buffalo$Cilla

#Calculate variogram
SVF &lt;- variogram(DATA)

#Plot the variogram with 50% and 95% CIs
plot(SVF,level=c(0.5,0.95))
</code></pre>

<hr>
<h2 id='variogram.fit'>Visually fit a movement model to a variogram</h2><span id='topic+ctmm.guess'></span><span id='topic+variogram.fit'></span>

<h3>Description</h3>

<p>This function plots a <code>variogram</code> object overlayed with a continuous-time movement model guesstimated from the variogram's shape. Sliders are given to adjust the parameter guesstimates and the result can be saved to a global variable. The intention of this function is to facilitate good starting guesses for <code>ctmm.fit</code>, starting with a prototype hypothesis argument <code>CTMM</code>, which can contain features such as <code>isotropic</code>, <code>range</code>, <code>circle</code>, etc..</p>


<h3>Usage</h3>

<pre><code class='language-R'>ctmm.guess(data,CTMM=ctmm(),variogram=NULL,name="GUESS",interactive=TRUE)

variogram.fit(variogram,CTMM=ctmm(),name="GUESS",fraction=0.5,interactive=TRUE,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="variogram.fit_+3A_data">data</code></td>
<td>
<p>A <code>telemetry</code> object.</p>
</td></tr>
<tr><td><code id="variogram.fit_+3A_ctmm">CTMM</code></td>
<td>
<p>Optional model prototype or initial guesstimate of the model parameters, in <code>ctmm</code> object format.</p>
</td></tr>
<tr><td><code id="variogram.fit_+3A_name">name</code></td>
<td>
<p>Name of the global variable to store the guesstimate in.</p>
</td></tr>
<tr><td><code id="variogram.fit_+3A_interactive">interactive</code></td>
<td>
<p>Boolean denoting whether to render the initial guess with interactive sliders or store the result silently.</p>
</td></tr>
<tr><td><code id="variogram.fit_+3A_variogram">variogram</code></td>
<td>
<p> A <code>variogram</code> object from the output of <code>variogram</code>. </p>
</td></tr>
<tr><td><code id="variogram.fit_+3A_fraction">fraction</code></td>
<td>
<p>Initial fraction of the variogram to render.</p>
</td></tr>
<tr><td><code id="variogram.fit_+3A_...">...</code></td>
<td>
<p>Optional parameters passed to <code>plot.variogram</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, <code>sigma</code> is the asymptote of the variogram and <code>tau</code> is an array of autocorrelation timescales. The position timescale is roughly the time lag it takes of the variogram to reach 63% of its asymptote. The velocity autocorrelation timescale visually corresponds to width of the concave bowl shape at the beginning of the variogram. If <code>CTMM=ctmm(range=FALSE)</code>, <code>sigma</code> is the asymptotic slope of the variogram and only the velocity timescale is finite.
</p>
<p>By default, parameter values are estimated from the shape of the variogram. If this fails, the <code>CTMM</code> option can provide alternative initial guesstimates.
</p>
<p><code>variogram.fit</code> is called by <code>ctmm.guess</code>, and there is usually no reason to call <code>variogram.fit</code> directly.
</p>


<h3>Note</h3>

<p> If the <code>manipulate</code> package is unavailable, then <code>interactive</code> is set to <code>FALSE</code>. </p>


<h3>Author(s)</h3>

<p> C. H. Fleming. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+ctmm.fit">ctmm.fit</a></code>, <code><a href="#topic+plot.variogram">plot.variogram</a></code>, <code><a href="#topic+variogram">variogram</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Load package and data
library(ctmm)
data(buffalo)

#Extract movement data for a single animal
DATA &lt;- buffalo$Cilla

# generate a visual fit of the variogram (requires RStudio or a guess object is returned)
ctmm.guess(DATA)
</code></pre>

<hr>
<h2 id='video'>Video record animated telemetry objects.</h2><span id='topic+video'></span>

<h3>Description</h3>

<p>Produces an MP4 video file by animating telemetry objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>video(x,ext=extent(x),fps=60,dt=NULL,ghost=0,timestamp=FALSE,file="ctmm.mp4",res=720,
      col="red",pch=1,cex=NULL,lwd=1,par.list=list(),...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="video_+3A_x">x</code></td>
<td>
<p><code>telemetry</code> object or list of <code>telemetry</code> objects.</p>
</td></tr>
<tr><td><code id="video_+3A_ext">ext</code></td>
<td>
<p>Plot extent for all frames.</p>
</td></tr>
<tr><td><code id="video_+3A_fps">fps</code></td>
<td>
<p>Frames per viewed second.</p>
</td></tr>
<tr><td><code id="video_+3A_dt">dt</code></td>
<td>
<p>Tracked time per frame (not per viewed second). By default, the median timestep will be used.</p>
</td></tr>
<tr><td><code id="video_+3A_ghost">ghost</code></td>
<td>
<p>Timescale over which image retention (ghosting) decays.</p>
</td></tr>
<tr><td><code id="video_+3A_timestamp">timestamp</code></td>
<td>
<p>Display timestamps on title.</p>
</td></tr>
<tr><td><code id="video_+3A_file">file</code></td>
<td>
<p>File name for MP4 file to save. The full path can also be specified. Otherwise the working directory will be used.</p>
</td></tr>
<tr><td><code id="video_+3A_res">res</code></td>
<td>
<p>Pixel resolution for square videos or pixel <code>c(width,height)</code> for rectangular videos.</p>
</td></tr>
<tr><td><code id="video_+3A_col">col</code></td>
<td>
<p>Color option for telemetry data. Can be an array or list of arrays.</p>
</td></tr>
<tr><td><code id="video_+3A_pch">pch</code></td>
<td>
<p>Plotting symbol. Can be an array or list of arrays.</p>
</td></tr>
<tr><td><code id="video_+3A_cex">cex</code></td>
<td>
<p>Relative size of plotting symbols. Only used when errors are missing.</p>
</td></tr>
<tr><td><code id="video_+3A_lwd">lwd</code></td>
<td>
<p>Line widths of <code>telemetry</code> points.</p>
</td></tr>
<tr><td><code id="video_+3A_par.list">par.list</code></td>
<td>
<p>List of additional arguments passed to <code><a href="graphics.html#topic+par">par</a></code> within <code>animate</code> that do not work outside of <code>animate</code>, like <code>mar</code>.</p>
</td></tr>
<tr><td><code id="video_+3A_...">...</code></td>
<td>
<p> Additional options passed to <code><a href="#topic+plot.telemetry">plot.telemetry</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function does not interpolate locations to make smooth animations. For that, please use <code><a href="#topic+predict">predict</a></code> or <code><a href="#topic+simulate">simulate</a></code> outputs instead of a raw tracking data.</p>


<h3>Value</h3>

<p>Saves an MP4 file named <code>file</code> to the working directory.</p>


<h3>Note</h3>

<p>Further <code>animation</code> and ffmpeg options can be set via <code><a href="animation.html#topic+ani.options">ani.options</a></code>.</p>


<h3>Author(s)</h3>

<p>C. H. Fleming.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+plot">plot</a></code>, <code><a href="#topic+plot.telemetry">plot.telemetry</a></code>, <code><a href="animation.html#topic+ani.options">ani.options</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load package and data
library(ctmm)
data(coati)

# temporary file to store videos for CRAN compliance
FILE &lt;- tempfile("ctmm",fileext=".mp4")
# you will likely want to save your video elsewhere
# the working directory is the default location

# create guess object
GUESS &lt;- ctmm.guess(coati[[2]],interactive=FALSE)
# in general, use ctmm.select instead of ctmm.fit
FIT &lt;- ctmm.fit(coati[[2]],GUESS)

# consider a few hours of consecutive sampling, at 1 minute per frame
t &lt;- seq(coati[[2]]$t[19],coati[[2]]$t[27],by=60)

# tau[velocity] is a natural scale to demonstrate persistance of motion
ghost &lt;- FIT$tau[2]

# predicted locations each minute
PRED &lt;- predict(coati[[2]],FIT,t=t)

# most likely path
video(PRED,error=FALSE,pch=16,ghost=ghost,file=FILE)

# prediction (distribution)
video(PRED,error=3,file=FILE)

# conditional simulations
SIMS &lt;- lapply(1:6,function(i){simulate(coati[[2]],FIT,t=t)})

# random paths
video(SIMS,pch=16,ghost=ghost,file=FILE)
</code></pre>

<hr>
<h2 id='wolf'>Maned wolf GPS dataset from The Maned Wolf Conservation Program.</h2><span id='topic+wolf'></span>

<h3>Description</h3>

<p><code>x-y</code> projected GPS data on 8 Maned wolves.
Please contact Rogerio Cunha de Paula (rogercunha@gmail.com) if you want to publish with these data.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("wolf")</code></pre>


<h3>Format</h3>

<p> A list of 8 <code>telemetry</code> objects.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+as.telemetry">as.telemetry</a></code>, <code><a href="#topic+plot.telemetry">plot.telemetry</a></code>, <code><a href="#topic+buffalo">buffalo</a></code>, <code><a href="#topic+coati">coati</a></code>, <code><a href="#topic+gazelle">gazelle</a></code>, <code><a href="#topic+pelican">pelican</a></code>, <code><a href="#topic+turtle">turtle</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'># Load package and data
library(ctmm)
data("wolf")

# Plot a wolf's locations
plot(wolf[[8]])
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
