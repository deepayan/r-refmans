<!DOCTYPE html><html lang="en"><head><title>Help for package overture</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {overture}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#AcceptProp'><p>Determine if a Metropolis–Hastings step should be accepted</p></a></li>
<li><a href='#Amwg'><p>Turn a non-adaptive Metropolis sampler into an adaptive Metropolis sampler</p></a></li>
<li><a href='#InitMcmc'><p>Initialize a Markov chain Monte Carlo run</p></a></li>
<li><a href='#LoadMcmc'><p>Load samples from a file-backed MCMC run</p></a></li>
<li><a href='#Peek'><p>Load samples from a partial MCMC run</p></a></li>
<li><a href='#Resume'><p>Resumes an interrupted file-backed MCMC</p></a></li>
<li><a href='#ToMemory'><p>Converts matrices in a file-backed MCMC to R matrix objects</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Tools for Writing MCMC</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4-0</td>
</tr>
<tr>
<td>Description:</td>
<td>Simplifies MCMC setup by automatically looping through sampling 
    functions and saving the results.  Reduces the memory footprint of running 
    MCMC and saves samples to disk as the chain runs.  Allows samples from the 
    chain to be analyzed while the MCMC is still running.  Provides functions 
    for commonly performed operations such as calculating Metropolis acceptance 
    ratios and creating adaptive Metropolis samplers.  References: Roberts and 
    Rosenthal (2009) &lt;<a href="https://doi.org/10.1198%2Fjcgs.2009.06134">doi:10.1198/jcgs.2009.06134</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/LGPL-3">LGPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/kurtis-s/overture">https://github.com/kurtis-s/overture</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/kurtis-s/overture/issues">https://github.com/kurtis-s/overture/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.0</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, mockery, covr</td>
</tr>
<tr>
<td>Imports:</td>
<td>bigmemory</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-08-10 04:39:48 UTC; kws</td>
</tr>
<tr>
<td>Author:</td>
<td>Kurtis Shuler [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kurtis Shuler &lt;kurtis.s.1122+CRAN@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-08-10 22:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='AcceptProp'>Determine if a Metropolis–Hastings step should be accepted</h2><span id='topic+AcceptProp'></span>

<h3>Description</h3>

<p><code>AcceptProp</code> is a utility function to determine if a proposal should
be accepted in a Metropolis or Metropolis-Hastings step.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AcceptProp(log.curr, log.prop, log.curr.to.prop = 0,
  log.prop.to.curr = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AcceptProp_+3A_log.curr">log.curr</code></td>
<td>
<p>log density of the target at the current value,
<code class="reqn">log(P(x))</code></p>
</td></tr>
<tr><td><code id="AcceptProp_+3A_log.prop">log.prop</code></td>
<td>
<p>log density of the target at the proposed value,
<code class="reqn">log(P(x'))</code></p>
</td></tr>
<tr><td><code id="AcceptProp_+3A_log.curr.to.prop">log.curr.to.prop</code></td>
<td>
<p>log of transition distribution from current value to
proposed value, <code class="reqn">log(g(x'|x))</code></p>
</td></tr>
<tr><td><code id="AcceptProp_+3A_log.prop.to.curr">log.prop.to.curr</code></td>
<td>
<p>log of transition distribution from proposed value to
current value, <code class="reqn">log(g(x|x'))</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function uses the Metropolis choice for a Metropolis/Metropolis-Hastings
sampler, which accepts a proposed value <code class="reqn">x'</code> with probability </p>
<p style="text-align: center;"><code class="reqn">
A(x', x) = min(1, P(x')/P(x) g(x|x')/g(x'|x)) </code>
</p>
<p> where <code class="reqn">P(x)</code> is the
target distribution and <code class="reqn">g(x'|x)</code> is the proposal distribution.
</p>


<h3>Value</h3>

<p><code>TRUE/FALSE</code> for whether the proposal should be accepted or
rejected, respectively
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Sample from triangular distribution P(x) = -2x + 2 ----------------------
# Target distribution
LogP &lt;- function(x) {
    log(-2*x + 2)
}

# Generate proposals using Beta(1/2, 1/2)
shape1 &lt;- 1/2
shape2 &lt;- 1/2

RProp &lt;- function() { # Draw proposal
    rbeta(1, shape1, shape2)
}

DLogProp &lt;- function(x) { # Log density of proposal distribution
    dbeta(x, shape1, shape2, log=TRUE)
}

SampleX &lt;- function(x) { # Draw once from the target distribution
    x.prop &lt;- RProp()
    if(AcceptProp(LogP(x), LogP(x.prop), DLogProp(x.prop), DLogProp(x))) {
        x &lt;- x.prop
    }

    return(x)
}

# Draw from the target distribution
n.samples &lt;- 10000
samples &lt;- vector(length=n.samples)
x &lt;- 0.5
Mcmc &lt;- InitMcmc(n.samples)
samples &lt;- Mcmc({
    x &lt;- SampleX(x)
})

# Plot the results
hist(samples$x, freq=FALSE, ylim=c(0, 2.5), xlim=c(0, 1), xlab="x")
grid &lt;- seq(0, 1, length.out=500)
lines(grid, exp(LogP(grid)), col="blue")
legend("topright", legend="True density", lty=1, col="blue", cex=0.75)
</code></pre>

<hr>
<h2 id='Amwg'>Turn a non-adaptive Metropolis sampler into an adaptive Metropolis sampler</h2><span id='topic+Amwg'></span>

<h3>Description</h3>

<p>Given a non-adaptive sampler of the form f(..., s), <code>Amwg</code> will return a
function g(...) that automatically adapts the Metropolis proposal standard
deviation s to try and achieve a target acceptance rate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Amwg(f, s, batch.size = 50, target = 0.44, DeltaN, stop.after = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Amwg_+3A_f">f</code></td>
<td>
<p>non-adaptive Metropolis sampler of the form f(..., s)</p>
</td></tr>
<tr><td><code id="Amwg_+3A_s">s</code></td>
<td>
<p>initial value for the Metropolis proposal SD</p>
</td></tr>
<tr><td><code id="Amwg_+3A_batch.size">batch.size</code></td>
<td>
<p>number of iterations before proposal SD is adapted</p>
</td></tr>
<tr><td><code id="Amwg_+3A_target">target</code></td>
<td>
<p>target acceptance rate</p>
</td></tr>
<tr><td><code id="Amwg_+3A_deltan">DeltaN</code></td>
<td>
<p>function of the form f(n) which returns the adaptation amount
based on the number of elapsed iterations, n.  Defaults to <code class="reqn">\delta(n) =
min(0.01, n^{-1/2})</code></p>
</td></tr>
<tr><td><code id="Amwg_+3A_stop.after">stop.after</code></td>
<td>
<p>stop adapting proposal SD after this many iterations</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>Amwg</code> uses the Adaptive Metropolis-Within-Gibbs algorithm from Roberts
&amp; Rosenthal (2009), which re-scales the proposal standard deviation after a
fixed number of MCMC iterations have elapsed.  The goal of the algorithm is
to achieve a target acceptance rate for the Metropolis step.  After the
n<em>th</em> batch of MCMC iterations the log of the proposal standard
deviation, <code class="reqn">log(s)</code>, is increased/decreased by <code class="reqn">\delta(n)</code>.
<code class="reqn">log(s)</code> is increased by <code class="reqn">\delta(n)</code> if the observed acceptance rate
is more than the target acceptance rate, or decreased by <code class="reqn">\delta(n)</code> if
the observed acceptance rate is less than the target acceptance rate.
<code>Amwg</code> keeps track of the the acceptance rate by comparing the
previously sampled value from <code>f</code> to the next value.  If the two values
are equal, the proposal is considered to be rejected, whereas if the two
values are different the proposal is considered accepted.  <code>Amwg</code> will
optionally stop adapting the proposal standard deviation after
<code>stop.after</code> iterations.  Setting <code>stop.after</code> can be used, for
example, to stop adapting the proposal standard deviation after some burn-in
period.  If <code>stop.after=NA</code> (the default), <code>Amwg</code> will continue to
modify the proposal standard deviation throughout the entire MCMC.
</p>
<p><code>DeltaN</code> is set to <code class="reqn">\delta(n) = min(0.01, n^{-1/2})</code> unless
re-specified in the function call. Some care should be taken if re-specifying
<code>DeltaN</code>, as the ergodicity of the chain may not be preserved if certain
conditions aren't met.  See Roberts &amp; Rosenthal (2009) in the references for
details.
</p>
<p>The proposal standard deviation <code>s</code> can be either a vector or a scalar.
If the initial value of <code>s</code> is a scalar, <code class="reqn">f</code> will be treated as a
sampler for a scalar, a random vector, or a joint parameter update.
Alternatively, if the dimension of <code class="reqn">s</code> is equal to the dimension of the
parameters returned by <code class="reqn">f</code>, the individual elements <code class="reqn">s</code> will be
treated as individual proposal standard deviations for the elements returned
by <code class="reqn">f</code>.  This functionality can be used, for example, if <code class="reqn">f</code> samples
each of its returned elements individually, updating each element using a
Metropolis step.  See the examples for an illustration of this use case.  In
such settings, <code class="reqn">f</code> should be constructed to receive <code class="reqn">s</code> as a vector
argument.
</p>


<h3>Value</h3>

<p>Adaptive Metropolis sampler function of the form g(...).
</p>


<h3>References</h3>

<p>Gareth O. Roberts &amp; Jeffrey S. Rosenthal (2009) Examples of
Adaptive MCMC, Journal of Computational and Graphical Statistics, 18:2,
349-367, doi: <a href="http://doi.org/10.1198/jcgs.2009.06134">10.1198/jcgs.2009.06134</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Sample from N(1, 2^2) ---------------------------------------------------
LogP &lt;- function(x) dnorm(x, 1, 2, log=TRUE) # Target distribution

f &lt;- function(x, s) { # Non-adaptive Metropolis sampler
    x.prop &lt;- x + rnorm(1, 0, s)
    if(AcceptProp(LogP(x), LogP(x.prop))) {
        x &lt;- x.prop
    }

    return(x)
}

s.start &lt;- 0.1
g &lt;- Amwg(f, s.start, batch.size=25)

n.save &lt;- 10000
Mcmc &lt;- InitMcmc(n.save)
y &lt;- 0
x &lt;- 0
samples &lt;- Mcmc({
    y &lt;- f(y, s.start) # Non-adaptive
    x &lt;- g(x) # Adaptive
})

plot(1:n.save, samples$x, ylim=c(-10, 10), main="Traceplots", xlab="Iteration",
     ylab="Value", type='l')
lines(1:n.save, samples$y, col="red")
legend("bottomleft", legend=c("Adaptive", "Non-adaptive"),
       col=c("black", "red"), lty=1, cex=0.8)

# Sample from Gamma(10, 5) ------------------------------------------------
LogP &lt;- function(x) dgamma(x, 10, 5, log=TRUE) # Target distribution

f &lt;- function(x, s) { # Non-adaptive Metropolis sampler
    x.prop &lt;- x + rnorm(1, 0, s)
    if(AcceptProp(LogP(x), LogP(x.prop))) {
        x &lt;- x.prop
    }

    return(x)
}

s.start &lt;- 10
stop.after &lt;- 5000 # Stop changing the proposal SD after 5000 iterations
g &lt;- Amwg(f, s.start, batch.size=25, stop.after=stop.after)

n.save &lt;- 10000
Mcmc &lt;- InitMcmc(n.save)
x &lt;- 1
samples &lt;- Mcmc({
    x &lt;- g(x)
})
hist(samples$x[stop.after:n.save,], xlab="x", main="Gamma(10, 5)", freq=FALSE)
curve(dgamma(x, 10, 5), from=0, to=max(samples$x), add=TRUE, col="blue")

# Overdispersed Poisson ---------------------------------------------------
## Likelihood:
## y_i|theta_i ~ Pois(theta_i), i=1,...,n
## Prior:
## theta_i ~ Log-Normal(mu, sigma^2)
## mu ~ Normal(m, v^2), m and v^2 fixed
## sigma^2 ~ InverseGamma(a, b), a and b fixed


SampleSigma2 &lt;- function(theta.vec, mu, a, b, n.obs) {
    1/rgamma(1, a + n.obs/2, b + (1/2)*sum((log(theta.vec) - mu)^2))
}

SampleMu &lt;- function(theta.vec, sigma.2, m, v.2, n.obs) {
    mu.var &lt;- (1/v.2 + n.obs/sigma.2)^(-1)
    mu.mean &lt;- (m/v.2 + sum(log(theta.vec))/sigma.2) * mu.var

    return(rnorm(1, mu.mean, sqrt(mu.var)))
}

LogDTheta &lt;- function(theta, mu, sigma.2, y) {
    dlnorm(theta, mu, sqrt(sigma.2), log=TRUE) + dpois(y, theta, log=TRUE)
}

# Non-adaptive Metropolis sampler
SampleTheta &lt;- function(theta.vec, mu, sigma.2, y.vec, n.obs, s) {
    theta.prop &lt;- exp(log(theta.vec) + rnorm(n.obs, 0, s))

    # Jacobians, because proposals are made on the log scale
    j.curr &lt;- log(theta.vec)
    j.prop &lt;- log(theta.prop)

    log.curr &lt;- LogDTheta(theta.vec, mu, sigma.2, y.vec) + j.curr
    log.prop &lt;- LogDTheta(theta.prop, mu, sigma.2, y.vec) + j.prop
    theta.vec &lt;- ifelse(AcceptProp(log.curr, log.prop), theta.prop, theta.vec)

    return(theta.vec)
}

## Data
y.vec &lt;- warpbreaks$breaks
n.obs &lt;- length(y.vec)

## Setup adaptive Metropolis sampler
s &lt;- rep(1, n.obs)
# s is a vector, so the acceptance rate of each component will be tracked
# individually in the adaptive Metropolis sampler
SampleThetaAdapative &lt;- Amwg(SampleTheta, s)

## Set prior
v.2 &lt;- 0.05
m &lt;- log(30) - v.2/2
a &lt;- 1
b &lt;- 2

## Initialize parameters
theta.vec &lt;- y.vec
mu &lt;- m

## MCMC
Mcmc &lt;- InitMcmc(10000)
samples &lt;- Mcmc({
    sigma.2 &lt;- SampleSigma2(theta.vec, mu, a, b, n.obs)
    mu &lt;- SampleMu(theta.vec, sigma.2, m, v.2, n.obs)
    theta.vec &lt;- SampleThetaAdapative(theta.vec, mu, sigma.2, y.vec, n.obs)
})

</code></pre>

<hr>
<h2 id='InitMcmc'>Initialize a Markov chain Monte Carlo run</h2><span id='topic+InitMcmc'></span>

<h3>Description</h3>

<p>Eliminates much of the &quot;boilerplate&quot; code needed for MCMC implementations by
looping through the samplers and saving the resulting draws automatically.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>InitMcmc(n.save, backing.path = NA, thin = 1, exclude = NULL,
  overwrite = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="InitMcmc_+3A_n.save">n.save</code></td>
<td>
<p>number of samples to take.  If <code>thin</code>=1, the number of
iterations to run the MCMC chain</p>
</td></tr>
<tr><td><code id="InitMcmc_+3A_backing.path">backing.path</code></td>
<td>
<p><code>NA</code> to save the samples in-memory, otherwise
directory path where MCMC samples will be saved</p>
</td></tr>
<tr><td><code id="InitMcmc_+3A_thin">thin</code></td>
<td>
<p>thinning interval</p>
</td></tr>
<tr><td><code id="InitMcmc_+3A_exclude">exclude</code></td>
<td>
<p>character vector specifying variables that should not be saved</p>
</td></tr>
<tr><td><code id="InitMcmc_+3A_overwrite">overwrite</code></td>
<td>
<p>TRUE/FALSE indicating whether previous MCMC results should
be overwritten</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>InitMcmc</code> returns a function that takes an R expression.  The returned
function automatically loops through the R expression and saves any numeric
assignments, typically MCMC samples, that are made within it. <code>exclude</code>
specifies assignments that should not be saved.  When <code>exclude</code> is
<code>NULL</code>, all the numeric assignments (scalar, vector, matrix, or array)
are saved.  The dimensions of matrix and array assignments are not preserved;
they are flattened into vectors before saving.  Non-numeric assignments are
not saved.
</p>
<p>The number of iterations for the MCMC chain is determined by <code>n.save</code>
and <code>thin</code>.  The desired number of samples to be saved from the target
distribution is set by <code>n.save</code>, and the chain is thinned according to
the interval set by <code>thin</code>.  The MCMC chain will run for <code>n.save</code>
<code class="reqn">x</code> <code>thin</code> iterations.
</p>
<p>The MCMC samples can be saved either in-memory or on-disk.  Unlike saving
in-memory, saving on-disk is not constrained by available RAM.  Saving
on-disk can be used in high-dimensional settings where running multiple MCMC
chains in parallel and saving the results in-memory would use up all
available RAM.  File-backed saving uses <code><a href="bigmemory.html#topic+big.matrix">big.matrix</a></code>, and the
behaviors of that implementation apply when saving on-disk.  In particular,
<code><a href="bigmemory.html#topic+big.matrix">big.matrix</a></code> has call-by-reference rather than call-by-value
behavior, so care must be taken not to introduce unintended side-effects when
modifying these objects.  In-memory saving is implemented via
<code><a href="base.html#topic+matrix">matrix</a></code> and has standard R behavior.
</p>
<p>When <code>backing.path</code> is <code>NA</code>, samples will be saved in-memory.  To
save samples on-disk, <code>backing.path</code> should specify the path to the
directory where the MCMC samples should be saved.  The
<code><a href="bigmemory.html#topic+big.matrix">big.matrix</a></code> <code>backingfile</code>s will be saved in that directory,
with filenames corresponding to the variable assignment names made in the R
expression.  Consequently, the assignment names in the R expression must be
chosen in such a way that they are compatible as filenames on the operating
system.  The <code><a href="bigmemory.html#topic+big.matrix">big.matrix</a></code> <code>descriptorfile</code>s are also named
according to the variable assignment names made in the R expression, but with
a &quot;.desc&quot; suffix.
</p>
<p>By default, <code>InitMcmc</code> will not overwrite the results from a previous
file-backed MCMC.  This behavior can be overridden by specifying
<code>overwrite=TRUE</code> in <code>InitMcmc</code>, or as the second argument to the
function returned by <code>InitMcmc</code>.  See the examples for an illustration.
<code>overwrite</code> is ignored for in-memory MCMC.
</p>


<h3>Value</h3>

<p>A function that returns a list of either <code><a href="base.html#topic+matrix">matrix</a></code> or
<code><a href="bigmemory.html#topic+big.matrix">big.matrix</a></code> with the MCMC samples.  Each row in the matrices
corresponds to one sample from the MCMC chain.
</p>


<h3>See Also</h3>

<p><code><a href="bigmemory.html#topic+bigmemory">bigmemory</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Beta-binomial -----------------------------------------------------------
## Likelihood:
## x|theta ~ Binomial(n, theta)
## Prior:
## theta ~ Unif(0, 1)

theta.truth &lt;- 0.75
n.obs &lt;- 100
x &lt;- rbinom(1, n.obs, prob=theta.truth)

# Sampling function
SampleTheta &lt;- function() {
    rbeta(1, 1 + x, 1 + n.obs - x)
}

# MCMC
Mcmc &lt;- InitMcmc(1000)
samples &lt;- Mcmc({
    theta &lt;- SampleTheta()
})

# Plot posterior distribution
hist(samples$theta, freq=FALSE, main="Posterior", xlab=expression(theta))
theta.grid &lt;- seq(min(samples$theta), max(samples$theta), length.out=500)
lines(theta.grid, dbeta(theta.grid, 1 + x, 1 + n.obs - x), col="blue")
abline(v=theta.truth, col="red")
legend("topleft", legend=c("Analytic posterior", "Simulation truth"),
       lty=1, col=c("blue", "red"), cex=0.75)

# Estimating mean with unknown variance -----------------------------------
## Likelihood:
## x|mu, sigma^2 ~ N(mu, sigma^2)
## Prior:
## p(mu) \propto 1
## p(sigma^2) \propto 1/sigma^2

# Simulated data
mu.truth &lt;- 10
sigma.2.truth &lt;- 2
n.obs &lt;- 100
x &lt;- rnorm(n.obs, mu.truth, sqrt(sigma.2.truth))
x.bar &lt;- mean(x)

# Sampling functions
SampleMu &lt;- function(sigma.2) {
    rnorm(1, x.bar, sqrt(sigma.2/n.obs))
}

SampleSigma2 &lt;- function(mu) {
    1/rgamma(1, n.obs/2, (1/2)*sum((x-mu)^2))
}

# MCMC
Mcmc &lt;- InitMcmc(1000, thin=10, exclude="sigma.2")
sigma.2 &lt;- 1 # Initialize parameter
samples &lt;- Mcmc({
    mu &lt;- SampleMu(sigma.2)
    sigma.2 &lt;- SampleSigma2(mu)
})

# Plot posterior distribution
hist(samples$mu, xlab=expression(mu), main="Posterior")
abline(v=mu.truth, col="red")
legend("topleft", legend="Simulation truth", lty=1, col="red", cex=0.75)

# sigma.2 is excluded from saved samples
is.null(samples$sigma.2)

# Linear regression -------------------------------------------------------
## Likelihood:
## y|beta, sigma^2, x ~ N(x %*% beta, sigma^2 * I)
## Prior:
## p(beta, sigma^2|x) \propto 1/sigma^2

# Simulated data
n.obs &lt;- 100
x &lt;- matrix(NA, nrow=n.obs, ncol=3)
x[,1] &lt;- 1
x[,2] &lt;- rnorm(n.obs)
x[,3] &lt;- x[,2] + rnorm(n.obs)
beta.truth &lt;- c(1, 2, 3)
sigma.2.truth &lt;- 5
y &lt;- rnorm(n.obs, x %*% beta.truth, sqrt(sigma.2.truth))

# Calculations for drawing beta
l.mod &lt;- lm(y ~ x - 1)
beta.hat &lt;- l.mod$coefficients
xtx.inv &lt;- summary(l.mod)$cov.unscaled
xtx.inv.chol &lt;- chol(xtx.inv)

# Calculations for drawing sigma.2
a.sigma.2 &lt;- (n.obs - length(beta.hat))/2
b.sigma.2 &lt;- (1/2) * t(y - x %*% beta.hat) %*% (y - x %*% beta.hat)

# Draw from multivariate normal
Rmvn &lt;- function(mu, sigma.chol) {
    d &lt;- length(mu)
    c(mu + t(sigma.chol) %*% rnorm(d))
}

SampleBeta &lt;- function(sigma.2) {
    Rmvn(beta.hat, xtx.inv.chol * sqrt(sigma.2))
}

SampleSigma2 &lt;- function() {
    1/rgamma(1, a.sigma.2, b.sigma.2)
}

# MCMC, samples saved on-disk
backing.path &lt;- tempfile()
dir.create(backing.path)
Mcmc &lt;- InitMcmc(1000, backing.path=backing.path)
samples &lt;- Mcmc({
    sigma.2 &lt;- SampleSigma2()
    beta &lt;- SampleBeta(sigma.2)
})

# Plot residuals using predictions made from the posterior mean of beta
y.hat &lt;- x %*% colMeans(samples$beta[,])
plot(y.hat, y-y.hat, xlab="Predicted", ylab="Residual")
abline(h=0, col="red")

# Overwrite previous results ----------------------------------------------
### Overwrite specified in InitMcmc
backing.path &lt;- tempfile()
dir.create(backing.path)
Mcmc &lt;- InitMcmc(5, backing.path=backing.path, overwrite=TRUE)
samples &lt;- Mcmc({
    x &lt;- 1
})
samples &lt;- Mcmc({
    x &lt;- 2
})
samples$x[,]

### Overwrite specified in the function returned by InitMcmc
backing.path &lt;- tempfile()
dir.create(backing.path)
Mcmc &lt;- InitMcmc(5, backing.path=backing.path, overwrite=FALSE)
samples &lt;- Mcmc({
    x &lt;- 3
})
samples &lt;- Mcmc({
    x &lt;- 4
}, overwrite=TRUE)
samples$x[,]
</code></pre>

<hr>
<h2 id='LoadMcmc'>Load samples from a file-backed MCMC run</h2><span id='topic+LoadMcmc'></span>

<h3>Description</h3>

<p><code>LoadMcmc</code> loads the samples from a file-backed MCMC run initiated by
<code>InitMcmc</code>.  The result is a list of <code><a href="bigmemory.html#topic+big.matrix">big.matrix</a></code> with all
of the parameters that were saved in the MCMC run.  Alternatively, the
samples for individual parameters can be loaded by using
<code><a href="bigmemory.html#topic+attach.big.matrix">attach.big.matrix</a></code> to load the corresponding <code>descriptor</code>
file, &quot;ParameterName.desc,&quot; in the MCMC's <code>backing.path</code> directory.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LoadMcmc(backing.path)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LoadMcmc_+3A_backing.path">backing.path</code></td>
<td>
<p>directory path where MCMC samples were saved</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of <code><a href="bigmemory.html#topic+big.matrix">big.matrix</a></code> with the MCMC samples
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ToMemory">ToMemory</a></code>, <code><a href="#topic+Peek">Peek</a></code>,
<code><a href="bigmemory.html#topic+attach.big.matrix">attach.big.matrix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Run a file-backed MCMC
backing.path &lt;- tempfile()
dir.create(backing.path)
Mcmc &lt;- InitMcmc(1000, backing.path=backing.path)
samples &lt;- Mcmc({
    x &lt;- rnorm(1)
})
rm(samples)

# Load the saved samples
loaded.samples &lt;- LoadMcmc(backing.path)
hist(loaded.samples$x[,], main="Samples", xlab="x")
</code></pre>

<hr>
<h2 id='Peek'>Load samples from a partial MCMC run</h2><span id='topic+Peek'></span>

<h3>Description</h3>

<p><code>Peek</code> allows the samples from a file-backed MCMC to be loaded in
another R session while the MCMC is still in progress.  By using <code>Peek</code>,
the chain's convergence can be monitored before the MCMC chain has finished
running.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Peek(backing.path)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Peek_+3A_backing.path">backing.path</code></td>
<td>
<p>directory path of an in-progress MCMC</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of <a href="bigmemory.html#topic+big.matrix">big.matrix</a> with samples from the partial MCMC run
</p>


<h3>See Also</h3>

<p><code><a href="#topic+InitMcmc">InitMcmc</a></code>, <code><a href="#topic+LoadMcmc">LoadMcmc</a></code>,
<code><a href="bigmemory.html#topic+big.matrix">big.matrix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
SampleSomething &lt;- function() {
    Sys.sleep(0.1)
    rnorm(1)
}

backing.path &lt;- tempfile()
dir.create(backing.path)
print(backing.path)

SlowMcmc &lt;- InitMcmc(1000, backing.path=backing.path)
SlowMcmc({
    x &lt;- SampleSomething()
})

### In another R process, while the MCMC is still running...
samples.so.far &lt;- Peek(backing.path)
samples.so.far$x[,]

</code></pre>

<hr>
<h2 id='Resume'>Resumes an interrupted file-backed MCMC</h2><span id='topic+Resume'></span>

<h3>Description</h3>

<p><code>Resume</code> will finish a file-backed MCMC that was interrupted.  To resume
an MCMC run, specify the MCMC's backing path and the sampling will continue
from the last completed sample in the chain.  Note, however, that the random
number generator state from when the MCMC was interrupted is <em>not</em>
restored, so the resulting chain my not be reproducible, even if a seed was
specified before the sampling was interrupted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Resume(backing.path)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Resume_+3A_backing.path">backing.path</code></td>
<td>
<p>directory path where the (partially completed) MCMC
samples were saved</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of either <code><a href="base.html#topic+matrix">matrix</a></code> or <code><a href="bigmemory.html#topic+big.matrix">big.matrix</a></code>
with the MCMC samples.  Each row in the matrices corresponds to one sample
from the MCMC chain.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+InitMcmc">InitMcmc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Setup the MCMC
n.iter &lt;- 5
SampleX &lt;- function(x) x + 1
backing.path &lt;- tempfile()
dir.create(backing.path)
x &lt;- 0
interrupt.mcmc &lt;- TRUE
Mcmc &lt;- InitMcmc(n.iter, backing.path=backing.path)

# Interrupt the MCMC during the third iteration
try({
    samps &lt;- Mcmc({
        x &lt;- SampleX(x)
        if(x==3 &amp;&amp; interrupt.mcmc) break
    })
}, silent=TRUE)

# The sampling is incomplete
samps &lt;- LoadMcmc(backing.path)
samps$x[,]
rm(samps)

# Resume the MCMC
interrupt.mcmc &lt;- FALSE
samps &lt;- Resume(backing.path)

# All samples are available
samps$x[,]
</code></pre>

<hr>
<h2 id='ToMemory'>Converts matrices in a file-backed MCMC to R matrix objects</h2><span id='topic+ToMemory'></span>

<h3>Description</h3>

<p><code>ToMemory</code> is a convenience method to load the samples from a
file-backed MCMC run into memory.  Given a list of <code><a href="bigmemory.html#topic+big.matrix">big.matrix</a></code>
objects, it will convert them to standard R matrix objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ToMemory(samples)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ToMemory_+3A_samples">samples</code></td>
<td>
<p>list of <code><a href="bigmemory.html#topic+big.matrix">big.matrix</a></code> objects, typically coming
from <code><a href="#topic+InitMcmc">InitMcmc</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of R <code><a href="base.html#topic+matrix">matrix</a></code> objects
</p>


<h3>See Also</h3>

<p><code><a href="#topic+InitMcmc">InitMcmc</a></code>, <code><a href="bigmemory.html#topic+big.matrix">big.matrix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Run a file-backed MCMC
backing.path &lt;- tempfile()
dir.create(backing.path)
Mcmc &lt;- InitMcmc(1000, backing.path=backing.path)
samples &lt;- Mcmc({
    x &lt;- rnorm(1)
    y &lt;- rnorm(2)
})

# Convert to standard in-memory R matrices
samples.in.memory &lt;- ToMemory(samples)

is.matrix(samples.in.memory$x)
is.matrix(samples.in.memory$y)
bigmemory::is.big.matrix(samples.in.memory$x)
bigmemory::is.big.matrix(samples.in.memory$y)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
