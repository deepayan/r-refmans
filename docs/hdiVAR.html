<!DOCTYPE html><html><head><title>Help for package hdiVAR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {hdiVAR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#CV_VARMLE'><p>cross-validation for transition matrix update in maximization step</p></a></li>
<li><a href='#Estep'><p>expectation step in sparse expectation-maximization algorithm</p></a></li>
<li><a href='#hdVARtest'><p>statistical inference for transition matrix in high-dimensional vector autoregression with measurement error</p></a></li>
<li><a href='#kalman'><p>kalman filtering and smoothing for vector autoregression with measurement error</p></a></li>
<li><a href='#Mstep'><p>maximization step of sparse expectation-maximization algorithm for updating error standard deviations</p></a></li>
<li><a href='#sEM'><p>sparse expectation-maximization algorithm for high-dimensional vector autoregression with measurement error</p></a></li>
<li><a href='#VARMLE'><p>generalized Dantzig selector for transition matrix update in maximization step</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Statistical Inference for Noisy Vector Autoregression</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.2</td>
</tr>
<tr>
<td>Description:</td>
<td>The model is high-dimensional vector autoregression with measurement error, also known as linear gaussian state-space model. Provable sparse expectation-maximization algorithm is provided for the estimation of transition matrix and noise variances. Global and simultaneous testings are implemented for transition matrix with false discovery rate control. For more information, see the accompanying paper: Lyu, X., Kang, J., &amp; Li, L. (2023). "Statistical inference for high-dimensional vector autoregression with measurement error", Statistica Sinica.</td>
</tr>
<tr>
<td>Imports:</td>
<td>lpSolve, abind</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Author:</td>
<td>Xiang Lyu [aut, cre],
  Jian Kang [aut],
  Lexin Li [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Xiang Lyu &lt;xianglyu.public@gmail.com&gt;</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-05-13 22:01:35 UTC; xianglyu</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-05-14 22:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='CV_VARMLE'>cross-validation for transition matrix update in maximization step</h2><span id='topic+CV_VARMLE'></span>

<h3>Description</h3>

<p>Tune the tolerance parameter of generalized Dantzig selector and hard thresholding
level via prediction error in test data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CV_VARMLE(tol_seq, ht_seq, S0_train, S1_train, Y_test, is_echo = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CV_VARMLE_+3A_tol_seq">tol_seq</code></td>
<td>
<p>vector; grid of tolerance parameter in Dantzig selector for cross-validation.</p>
</td></tr>
<tr><td><code id="CV_VARMLE_+3A_ht_seq">ht_seq</code></td>
<td>
<p>vector; grid of hard-thresholding levels for transition matrix estimate.
To avoid hard thresholding, set <code>ht_seq=0</code>.</p>
</td></tr>
<tr><td><code id="CV_VARMLE_+3A_s0_train">S0_train</code></td>
<td>
<p>a p by p matrix; average (over time points in training data) of conditional expectation of <code class="reqn">x_t x_t^\top</code> on <code class="reqn">y_1, \ldots, y_T</code> and parameter estimates, obtained from expectation step.</p>
</td></tr>
<tr><td><code id="CV_VARMLE_+3A_s1_train">S1_train</code></td>
<td>
<p>a p by p matrix; average (over time points in training data) of conditional expectation of <code class="reqn">x_t x_{t+1}^\top</code>on <code class="reqn">y_1, \ldots, y_T</code> and parameter estimates, obtained from expectation step.</p>
</td></tr>
<tr><td><code id="CV_VARMLE_+3A_y_test">Y_test</code></td>
<td>
<p>a p by T_test matrix; observations of time series in test set.</p>
</td></tr>
<tr><td><code id="CV_VARMLE_+3A_is_echo">is_echo</code></td>
<td>
<p>logical; if true, display the information of CV-optimal (tol, ht).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of CV-optimal parameters and test prediction error.
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>tol_min</code>  </td><td style="text-align: left;">  CV-optimal tolerance parameter in Dantzig selector. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>ht_min</code>  </td><td style="text-align: left;">  CV-optimal hard thresholding level for the output of Dantzig selector. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>test_loss</code>  </td><td style="text-align: left;">  a matrix of prediction error in test data; columns match <code>tol_seq</code>, and rows match <code>ht_seq</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Xiang Lyu, Jian Kang, Lexin Li
</p>

<hr>
<h2 id='Estep'>expectation step in sparse expectation-maximization algorithm</h2><span id='topic+Estep'></span>

<h3>Description</h3>

<p>Compute conditional expectation and covariance of <code class="reqn">x_t</code> given <code class="reqn">y_1,\ldots,y_T</code>
and current parameter estimates of <code class="reqn">A, \sigma_\eta,\sigma_\epsilon</code>
via kalman filter and smoothing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Estep(Y,A_init,sig_eta_init,sig_epsilon_init,X_init,P_init)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Estep_+3A_y">Y</code></td>
<td>
<p>observations of time series, a p by T matrix.</p>
</td></tr>
<tr><td><code id="Estep_+3A_a_init">A_init</code></td>
<td>
<p>current estimate of transition matrix <code class="reqn">A</code>.</p>
</td></tr>
<tr><td><code id="Estep_+3A_sig_eta_init">sig_eta_init</code></td>
<td>
<p>current estiamte of <code class="reqn">\sigma_\eta</code>.</p>
</td></tr>
<tr><td><code id="Estep_+3A_sig_epsilon_init">sig_epsilon_init</code></td>
<td>
<p>current estiamte <code class="reqn">\sigma_\epsilon</code>.</p>
</td></tr>
<tr><td><code id="Estep_+3A_x_init">X_init</code></td>
<td>
<p>current estimate of latent <code class="reqn">x_1</code> at the first iteration, a p-dimensional vector.</p>
</td></tr>
<tr><td><code id="Estep_+3A_p_init">P_init</code></td>
<td>
<p>current covariance estimate of latent <code class="reqn">x_1</code> at the first iteration, a p by p matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of conditional expectations and covariances for the sequential Maximization step.
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>EXtT</code>  </td><td style="text-align: left;">  a p by T matrix of column <code class="reqn">E[x_t | y_1,\ldots,y_T, \hat{A},\hat{\sigma}_\eta,\hat{\sigma}_\epsilon]</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>EXtt</code>  </td><td style="text-align: left;">  a p by p by T tensor of first-two-mode slice <code class="reqn">E[x_t x_t^\top | y_1,\ldots,y_T, \hat{A},\hat{\sigma}_\eta,\hat{\sigma}_\epsilon]</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>EXtt1</code>  </td><td style="text-align: left;">  a p by p by T-1 matrix of first-two-mode slice <code class="reqn">E[x_t x_{t+1}^\top | y_1,\ldots,y_T, \hat{A},\hat{\sigma}_\eta,\hat{\sigma}_\epsilon]</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Xiang Lyu, Jian Kang, Lexin Li
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p= 2; Ti=10  # dimension and time
A=diag(1,p) # transition matrix
sig_eta=sig_epsilon=0.2 # error std
Y=array(0,dim=c(p,Ti)) #observation t=1, ...., Ti
X=array(0,dim=c(p,Ti)) #latent t=1, ...., T
Ti_burnin=100 # time for burn-in to stationarity
for (t in 1:(Ti+Ti_burnin)) {
  if (t==1){
    x1=rnorm(p)
  } else if (t&lt;=Ti_burnin) { # burn in
    x1=A%*%x1+rnorm(p,mean=0,sd=sig_eta)
  } else if (t==(Ti_burnin+1)){ # time series used for learning
    X[,t-Ti_burnin]=x1
    Y[,t-Ti_burnin]=X[,t-Ti_burnin]+rnorm(p,mean=0,sd=sig_epsilon)
  } else {
    X[,t- Ti_burnin]=A%*%X[,t-1- Ti_burnin]+rnorm(p,mean=0,sd=sig_eta)
    Y[,t- Ti_burnin]=X[,t- Ti_burnin]+rnorm(p,mean=0,sd=sig_epsilon)
  }
}

Efit=Estep(Y,A,sig_eta,sig_epsilon,x1,diag(1,p))


</code></pre>

<hr>
<h2 id='hdVARtest'>statistical inference for transition matrix in high-dimensional vector autoregression with measurement error</h2><span id='topic+hdVARtest'></span>

<h3>Description</h3>

<p>Conduct global and simultaneous testing on the transition matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hdVARtest(
  Y,
  A_est,
  sig2_eta,
  sig2_epsilon,
  global_H0 = NULL,
  global_idx = NULL,
  simul_H0 = NULL,
  simul_idx = NULL,
  FDR_levels = 0.05,
  grid_num = 2000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hdVARtest_+3A_y">Y</code></td>
<td>
<p>observations of time series, a p by T matrix.</p>
</td></tr>
<tr><td><code id="hdVARtest_+3A_a_est">A_est</code></td>
<td>
<p>a p by p matrix of transition matrix <code class="reqn">A</code> estimate.</p>
</td></tr>
<tr><td><code id="hdVARtest_+3A_sig2_eta">sig2_eta</code></td>
<td>
<p>scalar; estimate of propagation error variance <code class="reqn">\sigma_\eta^2</code>.</p>
</td></tr>
<tr><td><code id="hdVARtest_+3A_sig2_epsilon">sig2_epsilon</code></td>
<td>
<p>scalar;  estimate of measurement error variance <code class="reqn">\sigma_\epsilon^2</code>.</p>
</td></tr>
<tr><td><code id="hdVARtest_+3A_global_h0">global_H0</code></td>
<td>
<p>a p by p matrix of global null hypothesis for transition matrix <code class="reqn">A</code>.
If <code>global_H0=NULL</code>, global testing will not be conducted, and <code>global_idx</code> will not be used.</p>
</td></tr>
<tr><td><code id="hdVARtest_+3A_global_idx">global_idx</code></td>
<td>
<p>a p by p boolean matrix. The TRUE/nonzero entry indicates the entry of interest
in global hypothesis testing. If <code>global_idx=NULL</code>, all p*p entries are included in global testing.</p>
</td></tr>
<tr><td><code id="hdVARtest_+3A_simul_h0">simul_H0</code></td>
<td>
<p>a p by p matrix of simultaneous null hypothesis for transition matrix <code class="reqn">A</code>.
If <code>simul_H0=NULL</code>, simultaneous testing will not be conducted, and (<code>simul_idx</code>, <code>FDR_levels</code>, <code>grid_num</code>) will not be used.</p>
</td></tr>
<tr><td><code id="hdVARtest_+3A_simul_idx">simul_idx</code></td>
<td>
<p>a p by p boolean matrix. The TRUE/nonzero entry indicates the entry of interest
in simultaneous hypothesis testing. If <code>simul_idx=NULL</code>, all p*p entries are included in simultaneous testing.</p>
</td></tr>
<tr><td><code id="hdVARtest_+3A_fdr_levels">FDR_levels</code></td>
<td>
<p>a vector of FDR control levels</p>
</td></tr>
<tr><td><code id="hdVARtest_+3A_grid_num">grid_num</code></td>
<td>
<p>scalar; the number of grids for cutoff search in FDR control.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of testing results and gaussian test statistic matrices.
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>pvalue</code>  </td><td style="text-align: left;">  scalar; p-value of global testing. Exist if <code>global_H0</code> is not NULL. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>global_test_stat</code> </td><td style="text-align: left;"> a p by p matrix of gaussian test statistic for global null hypothesis.
Exist if <code>global_H0</code> is not NULL. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>simul_test_stat</code>  </td><td style="text-align: left;">  a p by p matrix of gaussian test statistic for simultaneous null hypothesis.
Exist if <code>simul_H0</code> is not NULL. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>FDR_levels</code>  </td><td style="text-align: left;"> a vector of FDR control levels. The same as input argument <code>FDR_levels</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>crt</code> </td><td style="text-align: left;"> a vector of critical values for rejecting entries in simultaneous hypothesis
under corresponding FDR control levels.  </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>selected</code> </td><td style="text-align: left;"> a three-way tensor. The first two modes are p by p, and the third mode is for FDR control levels.
Nonzero elements indicate rejected entries (the first two modes) in simultanous hypothesis at correspoding FDR control levels (the third mode).
The entries outside of <code>simul_idx</code> is set at zero.

</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Xiang Lyu, Jian Kang, Lexin Li
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
p= 3; Ti=200  # dimension and time
A=diag(1,p) # transition matrix
sig_eta=sig_epsilon=0.2 # error std
Y=array(0,dim=c(p,Ti)) #observation t=1, ...., Ti
X=array(0,dim=c(p,Ti)) #latent t=1, ...., T
Ti_burnin=300 # time for burn-in to stationarity
for (t in 1:(Ti+Ti_burnin)) {
  if (t==1){
    x1=rnorm(p)
  } else if (t&lt;=Ti_burnin) { # burn in
    x1=A%*%x1+rnorm(p,mean=0,sd=sig_eta)
  } else if (t==(Ti_burnin+1)){ # time series used for learning
    X[,t-Ti_burnin]=x1
    Y[,t-Ti_burnin]=X[,t-Ti_burnin]+rnorm(p,mean=0,sd=sig_epsilon)
  } else {
    X[,t- Ti_burnin]=A%*%X[,t-1- Ti_burnin]+rnorm(p,mean=0,sd=sig_eta)
    Y[,t- Ti_burnin]=X[,t- Ti_burnin]+rnorm(p,mean=0,sd=sig_epsilon)
  }
}

# null hypotheses are true
hdVARtest(Y,A,sig_eta^2,sig_epsilon^2,global_H0=A,global_idx=NULL,
         simul_H0=A,simul_idx=NULL,FDR_levels=c(0.05,0.1))


# null hypotheses are false
hdVARtest(Y,A,sig_eta^2,sig_epsilon^2,global_H0=matrix(0,p,p),global_idx=NULL,
          simul_H0=matrix(0,p,p),simul_idx=NULL,FDR_levels=c(0.05,0.1))

</code></pre>

<hr>
<h2 id='kalman'>kalman filtering and smoothing for vector autoregression with measurement error</h2><span id='topic+kalman'></span>

<h3>Description</h3>

<p>kalman filtering and smoothing for vector autoregression with measurement error
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kalman(Y,A,sig_eta,sig_epsilon,X_init=NULL,P_init=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kalman_+3A_y">Y</code></td>
<td>
<p>observations of time series, a p by T matrix.</p>
</td></tr>
<tr><td><code id="kalman_+3A_a">A</code></td>
<td>
<p>current estimate of transition matrix.</p>
</td></tr>
<tr><td><code id="kalman_+3A_sig_eta">sig_eta</code></td>
<td>
<p>current estiamte of <code class="reqn">\sigma_\eta</code>.</p>
</td></tr>
<tr><td><code id="kalman_+3A_sig_epsilon">sig_epsilon</code></td>
<td>
<p>current estiamte <code class="reqn">\sigma_\epsilon</code>.</p>
</td></tr>
<tr><td><code id="kalman_+3A_x_init">X_init</code></td>
<td>
<p>inital estimate of latent <code class="reqn">x_1</code> at the first iteration, a p-dimensional vector.</p>
</td></tr>
<tr><td><code id="kalman_+3A_p_init">P_init</code></td>
<td>
<p>inital covariance estimate of latent <code class="reqn">x_1</code> at the first iteration, a p by p matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of conditional expectations and covariances of <code class="reqn">x_t</code>'s.
</p>


<h3>Author(s)</h3>

<p>Xiang Lyu, Jian Kang, Lexin Li
</p>

<hr>
<h2 id='Mstep'>maximization step of sparse expectation-maximization algorithm for updating error standard deviations</h2><span id='topic+Mstep'></span>

<h3>Description</h3>

<p>Update <code class="reqn">\sigma_\eta,\sigma_\epsilon</code> based on estimate of A and
conditional expecation and covariance from expectation step.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Mstep(Y,A,EXtT,EXtt,EXtt1,is_MLE=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Mstep_+3A_y">Y</code></td>
<td>
<p>observations of time series, a p by T matrix.</p>
</td></tr>
<tr><td><code id="Mstep_+3A_a">A</code></td>
<td>
<p>current estimate of transition matrix <code class="reqn">A</code>. If <code>is_MLE=TRUE</code>, use naive MLE of transition matrix, by conditional expecation and covariance from expecation step, to update error standard deviations.</p>
</td></tr>
<tr><td><code id="Mstep_+3A_extt">EXtT</code></td>
<td>
<p>a p by T matrix of column <code class="reqn">E[x_t | y_1,\ldots,y_T, \hat{A},\hat{\sigma}_\eta,\hat{\sigma}_\epsilon]</code> from expectation step.</p>
</td></tr>
<tr><td><code id="Mstep_+3A_extt">EXtt</code></td>
<td>
<p>a p by p by T tensor of first-two-mode slice <code class="reqn">E[x_t x_t^\top | y_1,\ldots,y_T, \hat{A},\hat{\sigma}_\eta,\hat{\sigma}_\epsilon]</code> from expectation step.</p>
</td></tr>
<tr><td><code id="Mstep_+3A_extt1">EXtt1</code></td>
<td>
<p>a p by p by T-1 matrix of first-two-mode slice <code class="reqn">E[x_t x_{t+1}^\top | y_1,\ldots,y_T, \hat{A},\hat{\sigma}_\eta,\hat{\sigma}_\epsilon]</code> from expectation step.</p>
</td></tr>
<tr><td><code id="Mstep_+3A_is_mle">is_MLE</code></td>
<td>
<p>logic; if true, use naive MLE of transition matrix, by conditional expecation and covariance from expecation step, to update error variances. Otherwise, use input argument <code>A</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of estimates of error standard deviations.
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>sig_eta</code>  </td><td style="text-align: left;">  estimate of <code class="reqn">\sigma_\eta</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>sig_epsilon</code>  </td><td style="text-align: left;">   estimate of <code class="reqn">\sigma_\epsilon</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>A</code>  </td><td style="text-align: left;">  naive MLE of transition matrix <code class="reqn">A</code> by conditional expecation and covariance from expecation step. Exist if <code>is_MLE=TRUE</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Xiang Lyu, Jian Kang, Lexin Li
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p= 2; Ti=10  # dimension and time
A=diag(1,p) # transition matrix
sig_eta=sig_epsilon=0.2 # error std
Y=array(0,dim=c(p,Ti)) #observation t=1, ...., Ti
X=array(0,dim=c(p,Ti)) #latent t=1, ...., T
Ti_burnin=100 # time for burn-in to stationarity
for (t in 1:(Ti+Ti_burnin)) {
  if (t==1){
    x1=rnorm(p)
  } else if (t&lt;=Ti_burnin) { # burn in
    x1=A%*%x1+rnorm(p,mean=0,sd=sig_eta)
  } else if (t==(Ti_burnin+1)){ # time series used for learning
    X[,t-Ti_burnin]=x1
    Y[,t-Ti_burnin]=X[,t-Ti_burnin]+rnorm(p,mean=0,sd=sig_epsilon)
  } else {
    X[,t- Ti_burnin]=A%*%X[,t-1- Ti_burnin]+rnorm(p,mean=0,sd=sig_eta)
    Y[,t- Ti_burnin]=X[,t- Ti_burnin]+rnorm(p,mean=0,sd=sig_epsilon)
  }
}

# expectation step
Efit=Estep(Y,A,sig_eta,sig_epsilon,x1,diag(1,p))
EXtT=Efit[["EXtT"]]
EXtt=Efit[["EXtt"]]
EXtt1=Efit[["EXtt1"]]
# maximization step for error standard deviations
Mfit=Mstep(Y,A,EXtT,EXtt,EXtt1)



</code></pre>

<hr>
<h2 id='sEM'>sparse expectation-maximization algorithm for high-dimensional vector autoregression with measurement error</h2><span id='topic+sEM'></span>

<h3>Description</h3>

<p>Alteranting between expectation step (by kalman filter and smoothing) and maximization step (by generalized Dantzig selector for transiton matrix)
to estimate transtion matrix and error variances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sEM(
  Y,
  A_init,
  sig2_eta_init,
  sig2_epsilon_init,
  Ti_train = NULL,
  Ti_gap = NULL,
  tol_seq = NULL,
  ht_seq = 0,
  is_cv = TRUE,
  thres = 0.001,
  count_vanish = 1,
  n_em = NULL,
  is_echo = FALSE,
  is_sparse = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sEM_+3A_y">Y</code></td>
<td>
<p>observations of time series, a p by T matrix.</p>
</td></tr>
<tr><td><code id="sEM_+3A_a_init">A_init</code></td>
<td>
<p>a p by p matrix as initial value of transition matrix <code class="reqn">A</code> estimate.</p>
</td></tr>
<tr><td><code id="sEM_+3A_sig2_eta_init">sig2_eta_init</code></td>
<td>
<p>scalar; initial value of propagation error variance <code class="reqn">\sigma_\eta^2</code> estimate in latent signal process.</p>
</td></tr>
<tr><td><code id="sEM_+3A_sig2_epsilon_init">sig2_epsilon_init</code></td>
<td>
<p>scalar; initial value of measurement error variance <code class="reqn">\sigma_\epsilon^2</code> estimate in observation process.</p>
</td></tr>
<tr><td><code id="sEM_+3A_ti_train">Ti_train</code></td>
<td>
<p>scalar; the number of time points in training data in cross-validation.</p>
</td></tr>
<tr><td><code id="sEM_+3A_ti_gap">Ti_gap</code></td>
<td>
<p>scalar; the number of time points between test data and train data in cross-validation.</p>
</td></tr>
<tr><td><code id="sEM_+3A_tol_seq">tol_seq</code></td>
<td>
<p>vector; grid of tolerance parameter in Dantzig selector for cross-validation. If <code>is_cv=FALSE</code>, use the first element.</p>
</td></tr>
<tr><td><code id="sEM_+3A_ht_seq">ht_seq</code></td>
<td>
<p>vector; grid of hard-thresholding levels for transition matrix estimate. If <code>is_cv=FALSE</code>, use the first element.
To avoid hard thresholding, set <code>ht_seq=0</code>.</p>
</td></tr>
<tr><td><code id="sEM_+3A_is_cv">is_cv</code></td>
<td>
<p>logical; if true, run cross-validation to tune Dantzig selector tolerance parameter each sparse EM iteration.</p>
</td></tr>
<tr><td><code id="sEM_+3A_thres">thres</code></td>
<td>
<p>scalar; if the difference between updates of two consecutive iterations is less that <code>thres</code>, record one hit.
The algorithm is terminated due to vanishing updates if hit times accumulate up to <code>count_vanish</code>. If <code>thres=NULL</code>, the algorithm will not be terminated
due to vanishing updates, but too many iterations instead.</p>
</td></tr>
<tr><td><code id="sEM_+3A_count_vanish">count_vanish</code></td>
<td>
<p>scalar; if the difference between updates of two consecutive
iterations is less that <code>thres</code> up to <code>count_vanish</code> times, the algorithm is terminated due to vanishing updates.</p>
</td></tr>
<tr><td><code id="sEM_+3A_n_em">n_em</code></td>
<td>
<p>scalar; the maximal allowed number of EM iterations, otherwise the algorithm is terminated due to too many iterations.
If <code>n_em=NULL</code>, the algorithm will not be terminated due to too many iterations, but vanishing updates instead.</p>
</td></tr>
<tr><td><code id="sEM_+3A_is_echo">is_echo</code></td>
<td>
<p>logical; if true, display the information of CV-optimal (tol, ht) each iteration, and of algorithm termination.</p>
</td></tr>
<tr><td><code id="sEM_+3A_is_sparse">is_sparse</code></td>
<td>
<p>logical; if false, use standard EM algorithm, and arguments for cross-validation are not needed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of parameter estimates.
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>A_est</code>  </td><td style="text-align: left;">  estimate of transition matrix <code class="reqn">A</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>sig2_eta_hat</code>  </td><td style="text-align: left;">  estimate of propagation error variance <code class="reqn">\sigma_\eta^2</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>sig2_epsilon_hat</code>  </td><td style="text-align: left;">   estimate of measurement error variance <code class="reqn">\sigma_\epsilon^2</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>iter_err</code> </td><td style="text-align: left;">   the difference between updates of two consecutive iterations. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>iter_err_ratio</code> </td><td style="text-align: left;">  the difference ratio (over the previous estimate) between updates of two consecutive iterations. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Xiang Lyu, Jian Kang, Lexin Li
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p= 3; Ti=20  # dimension and time
A=diag(1,p) # transition matrix
sig_eta=sig_epsilon=0.2 # error std
Y=array(0,dim=c(p,Ti)) #observation t=1, ...., Ti
X=array(0,dim=c(p,Ti)) #latent t=1, ...., T
Ti_burnin=30 # time for burn-in to stationarity
for (t in 1:(Ti+Ti_burnin)) {
  if (t==1){
    x1=rnorm(p)
  } else if (t&lt;=Ti_burnin) { # burn in
    x1=A%*%x1+rnorm(p,mean=0,sd=sig_eta)
  } else if (t==(Ti_burnin+1)){ # time series used for learning
    X[,t-Ti_burnin]=x1
    Y[,t-Ti_burnin]=X[,t-Ti_burnin]+rnorm(p,mean=0,sd=sig_epsilon)
  } else {
    X[,t- Ti_burnin]=A%*%X[,t-1- Ti_burnin]+rnorm(p,mean=0,sd=sig_eta)
    Y[,t- Ti_burnin]=X[,t- Ti_burnin]+rnorm(p,mean=0,sd=sig_epsilon)
  }
}

sEM_fit=sEM(Y,diag(0.5,p),0.1,0.1,Ti*0.5,Ti*0.2,c(0.01,0.1))


</code></pre>

<hr>
<h2 id='VARMLE'>generalized Dantzig selector for transition matrix update in maximization step</h2><span id='topic+VARMLE'></span>

<h3>Description</h3>

<p>Sparse estimation of transtion matrix in vector autoregression given conditional autocovariance matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VARMLE(S0, S1, tol)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VARMLE_+3A_s0">S0</code></td>
<td>
<p>a p by p matrix; average (over time points) of conditional expectation of <code class="reqn">x_t x_t^\top</code> on <code class="reqn">y_1, \ldots, y_T</code> and parameter estimates, obtained from expectation step.</p>
</td></tr>
<tr><td><code id="VARMLE_+3A_s1">S1</code></td>
<td>
<p>a p by p matrix; average (over time points) of conditional expectation of <code class="reqn">x_t x_{t+1}^\top</code>on <code class="reqn">y_1, \ldots, y_T</code> and parameter estimates, obtained from expectation step.</p>
</td></tr>
<tr><td><code id="VARMLE_+3A_tol">tol</code></td>
<td>
<p>tolerance parameter in Dantzig selector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Sparse estimate of transition matrix by Dantzig selector.
</p>


<h3>Author(s)</h3>

<p>Xiang Lyu, Jian Kang, Lexin Li
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
