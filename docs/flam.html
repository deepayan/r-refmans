<!DOCTYPE html><html lang="en"><head><title>Help for package flam</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {flam}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#flam-package'>
<p>Fit the Fused Lasso Additive Model</p></a></li>
<li><a href='#flam'>
<p>Fit the Fused Lasso Additive Model for a Sequence of Tuning Parameters</p></a></li>
<li><a href='#flamCV'>
<p>Fit the Fused Lasso Additive Model and Do Tuning Parameter Selection using K-Fold Cross-Validation</p></a></li>
<li><a href='#flamDOF'>
<p>Calculate Degrees of Freedom for Fused Lasso Additive Model</p></a></li>
<li><a href='#plot.flam'>
<p>Plots Function Estimates for Fit of Class &quot;flam&quot;</p></a></li>
<li><a href='#plot.flamCV'>
<p>Plots Cross-Validation Curve for Object of Class &quot;flamCV&quot;</p></a></li>
<li><a href='#predict.flam'>
<p>Predicts Observations for a New Covariate Matrix and Fit from <code>flam</code></p></a></li>
<li><a href='#sim.data'>
<p>Simulate Data from a Variety of Functional Scenarios</p></a></li>
<li><a href='#summary.flam'>
<p>Summarizes a Call to <code>flam</code></p></a></li>
<li><a href='#summary.flamCV'>
<p>Summarizes a Call to <code>flamCV</code></p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Fits Piecewise Constant Models with Data-Adaptive Knots</td>
</tr>
<tr>
<td>Version:</td>
<td>3.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2018-04-05</td>
</tr>
<tr>
<td>Author:</td>
<td>Ashley Petersen</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ashley Petersen &lt;ashleyjpete@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements the fused lasso additive model as proposed in Petersen, A., Witten, D., and Simon, N. (2016). Fused Lasso Additive Model. Journal of Computational and Graphical Statistics, 25(4): 1005-1025.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.11.6), MASS, graphics, grDevices, stats</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-04-05 23:43:16 UTC; ashleypetersen</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-04-06 03:26:45 UTC</td>
</tr>
</table>
<hr>
<h2 id='flam-package'>
Fit the Fused Lasso Additive Model
</h2><span id='topic+flam-package'></span>

<h3>Description</h3>

<p>This package is called flam for &quot;fused lasso additive model&quot;, which is proposed in Petersen, A., Witten, D., and Simon, N. (2014). Fused Lasso Additive Model. arXiv preprint arXiv:1409.5391. The fused lasso additive model provides an approach to fit an additive model in which each component is estimated to be piecewise constant with a small number of adaptively-chosen knots.
</p>
<p>The main functions are: (1) <code><a href="#topic+flam">flam</a></code> and (2) <code><a href="#topic+flamCV">flamCV</a></code>. The first function <code>flam</code> fits the fused lasso additive model for a range of tuning parameters and provides the fits for all of these tuning parameters. The second function <code>flamCV</code> considers a range of tuning parameters and provides the fits, but also returns the optimal tuning parameters, as chosen using K-fold cross-validation.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> flam</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 3.0</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2015-07-26</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;= 2)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>The package includes the following functions:
<code><a href="#topic+flam">flam</a></code>, <code><a href="#topic+flamCV">flamCV</a></code>, <code><a href="#topic+plot.flam">plot.flam</a></code>, <code><a href="#topic+plot.flamCV">plot.flamCV</a></code>, <code><a href="#topic+plot.flamSparsity">plot.flamSparsity</a></code>, <code><a href="#topic+predict.flam">predict.flam</a></code>, <code><a href="#topic+summary.flam">summary.flam</a></code>, <code><a href="#topic+summary.flamCV">summary.flamCV</a></code>, <code><a href="#topic+flamDOF">flamDOF</a></code>, and <code><a href="#topic+sim.data">sim.data</a></code>.
</p>


<h3>Author(s)</h3>

<p>Ashley Petersen
</p>
<p>Maintainer: Ashley Petersen &lt;ajpete@uw.edu&gt;
</p>


<h3>References</h3>

<p>Petersen, A., Witten, D., and Simon, N. (2014). Fused Lasso Additive Model. arXiv preprint arXiv:1409.5391.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#general example illustrating all functions
#see specific function help pages for details of using each function

#generate data
set.seed(1)
data &lt;- sim.data(n = 50, scenario = 1, zerof = 10, noise = 1)

#fit model for a range of tuning parameters, lambda and alpha
#lambda sequence is chosen automatically if not specified
flam.out &lt;- flam(x = data$x, y = data$y, alpha.seq = c(0.8, 0.9, 1))
#or fit model and select lambda using 2-fold cross-validation
#note: use larger 'n.fold' (e.g., 10) in practice
flamCV.out &lt;- flamCV(x = data$x, y = data$y, alpha = 1, n.fold = 2)

#summarize all of the fits (in particular, the percent sparsity achieved)
#note: percent sparsity is the percentage of features estimated
#to have no relationship with outcome
summary(flam.out)
#the percent sparsity over the range of tuning parameters can also 
#be displayed in a plot
plot(summary(flam.out))
#or just summarize a single fit 
#we'll examine the fit with an index of 25. that is, lambda and alpha of
flam.out$all.lambda[25]; flam.out$all.alpha[25]
summary(flam.out, index = 25)
#lastly, we can summarize the fit chosen using cross-validation
summary(flamCV.out$flam.out, index = flamCV.out$index.cv)
#the lambda chosen by cross-validation is also available using
flamCV.out$lambda.cv

#plot the estimated relationships between predictors and outcome
#do this for a specific fit
plot(flam.out, index = 25)
#or for the fit chosen using cross-validation
plot(flamCV.out$flam.out, index = flamCV.out$index.cv)
#by default, up to 10 non-sparse features with the largest L2 norms will 
#be plotted, see '?plot.flam' for other optional function arguments

#this data is simulated, so with a little more work, we can compare the 
#true generating functions to the estimated function fits
#we do this for the truly non-zero functions (i.e., the first four predictors)
#generate data from same model but larger n, just used to plot true functions
temp.data &lt;- sim.data(n = 500, scenario = 1, zerof = 10, noise = 1)
col.vec = c("dodgerblue1","orange","seagreen1","hotpink")
theta.hat = flamCV.out$flam.out$theta.hat.list[[flamCV.out$index.cv]]
par(mfrow=c(2,2))
for (i in 1:4) {
	rgb.num = col2rgb(col.vec[i])
	col=rgb(rgb.num[1], rgb.num[2], rgb.num[3], 100, max=256)
	plot(1,type="n",xlim=c(-2.5,2.5),ylim=c(-2,2),xlab=paste("x",i,sep=""),
		ylab=paste("f",i,"(x",i,")",sep=""),main="")
	points(sort(temp.data$x[,i]), temp.data$theta[order(temp.data$x[,i]),i],type="l",lwd=3)
	points(sort(data$x[,i]), theta.hat[order(data$x[,i]),i],col=col,type="l",lwd=3)
}

#we can make predictions for a covariate matrix with new observations
#choose the alpha and lambda of interest
alpha &lt;- flamCV.out$alpha; lambda &lt;- flamCV.out$lambda.cv
#new.x with 20 observations and the same number of features as flam.out$x
new.data &lt;- sim.data(n = 20, scenario = 1, zerof = 10, noise = 1)
new.x &lt;- new.data$x
#these will give the same predictions:
yhat1 &lt;- predict(flam.out, new.x = new.x, lambda = lambda, alpha = alpha)
yhat2 &lt;- predict(flamCV.out$flam.out, new.x = new.x, lambda = lambda, alpha = alpha)

#we can summarize the cross-validation function call
summary(flamCV.out)
#and also plot the cross-validation error
plot(flamCV.out)
#or calculate degrees of freedom for the model chosen using cross-validation
flamDOF(object = flamCV.out$flam.out, index = flamCV.out$index.cv)
#or for any fit of a 'flam' object
flamDOF(object = flam.out, index = 25)
</code></pre>

<hr>
<h2 id='flam'>
Fit the Fused Lasso Additive Model for a Sequence of Tuning Parameters
</h2><span id='topic+flam'></span>

<h3>Description</h3>

<p>Fit an additive model where each component is estimated to piecewise constant with a small number of adaptively-chosen knots. The model is fit for a sequence of tuning parameters. In particular, this function implements the &quot;fused lasso additive model&quot;, as proposed in Petersen, A., Witten, D., and Simon, N. (2014). Fused Lasso Additive Model. arXiv preprint arXiv:1409.5391.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flam(x, y, lambda.min.ratio = 0.01, n.lambda = 50, lambda.seq = NULL,
alpha.seq = 1, family = "gaussian", method = "BCD", tolerance = 10e-6)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="flam_+3A_x">x</code></td>
<td>

<p>n x p covariate matrix. May have p &gt; n.
</p>
</td></tr>
<tr><td><code id="flam_+3A_y">y</code></td>
<td>

<p>n-vector containing the outcomes for the n observations in <code>x</code>.
</p>
</td></tr>
<tr><td><code id="flam_+3A_lambda.min.ratio">lambda.min.ratio</code></td>
<td>

<p>smallest value for <code>lambda.seq</code>, as a fraction of the maximum lambda value, which is the data-derived smallest value for which all estimated functions are zero. The default is 0.01.
</p>
</td></tr>
<tr><td><code id="flam_+3A_n.lambda">n.lambda</code></td>
<td>

<p>the number of lambda values to consider - the default is 50.
</p>
</td></tr>
<tr><td><code id="flam_+3A_lambda.seq">lambda.seq</code></td>
<td>

<p>a user-supplied sequence of positive lambda values to consider. The typical usage is to calculate <code>lambda.seq</code> using <code>lambda.min.ratio</code> and <code>n.lambda</code>, but providing <code>lambda.seq</code> overrides this. If provided, <code>lambda.seq</code> should be a decreasing sequence of values, since <code>flam</code> relies on warm starts for speed. Thus fitting the model for a whole sequence of lambda values is often faster than fitting for a single lambda value. Note that the model is fit for all combinations of <code>alpha.seq</code> and <code>lambda.seq</code>, so all values of <code>lambda.seq</code> provided should be unique.
</p>
</td></tr>
<tr><td><code id="flam_+3A_alpha.seq">alpha.seq</code></td>
<td>

<p>the value(s) of alpha to consider - default is 1. Values must be in [0,1] with values near 0 prioritizing sparsity of functions and values near 1 prioritizing limiting the number of knots. Empirical evidence suggests using alpha of 1 when p &lt; n and alpha of 0.75 when p &gt; n. Note that the model is fit for all combinations of <code>alpha.seq</code> and <code>lambda.seq</code>, so all values of <code>alpha.seq</code> provided should be unique.
</p>
</td></tr>
<tr><td><code id="flam_+3A_family">family</code></td>
<td>

<p>specifies the loss function to use. Currently supports squared error loss (default; <code>family="gaussian"</code>) and logistic loss (<code>family="binomial"</code>).
</p>
</td></tr>
<tr><td><code id="flam_+3A_method">method</code></td>
<td>

<p>specifies the optimization algorithm to use. Options are block-coordinate descent (default; <code>method="BCD"</code>), generalized gradient descent (<code>method="GGD"</code>), or generalized gradient descent with backtracking (<code>method="GGD.backtrack"</code>). This argument is ignored if <code>family="binomial"</code>.
</p>
</td></tr>
<tr><td><code id="flam_+3A_tolerance">tolerance</code></td>
<td>

<p>specifies the convergence criterion for the objective (default is 10e-6).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object with S3 class &quot;flam&quot;.
</p>
<table role = "presentation">
<tr><td><code>all.alpha</code></td>
<td>
<p>vector of alpha values considered. This will be m times longer than the user-specified <code>alpha.seq</code> where m is the length of the user-specified <code>lambda.seq</code>.</p>
</td></tr>
<tr><td><code>all.lambda</code></td>
<td>
<p>vector of lambda values considered. This will be q times longer than the user-specified <code>lambda.seq</code> where q is the length of the user-specified <code>alpha.seq</code>.</p>
</td></tr>
<tr><td><code>theta.hat.list</code></td>
<td>
<p>list of estimated theta matrices of dimension n x p. Note that the predicted values <code>y.hat.mat[i,] = g(</code><code>beta0.hat.vec[i] + </code><code>rowSums(theta.hat.list[[i]]))</code> where <code>g</code> is the link function (identity if <code>family="gaussian"</code> and expit if <code>family="binomial"</code>).</p>
</td></tr>
<tr><td><code>f.hat.list</code></td>
<td>
<p>list of estimated function matrices of dimension n x p. Note that <code>f.hat.list[[i]]</code> is <code>theta.hat.list[[i]]</code> with the elements of each column ordered in terms of increasing <code>x[,i]</code>.</p>
</td></tr>
<tr><td><code>beta0.hat.vec</code></td>
<td>
<p>vector of estimated intercepts with <code>beta0.hat.vec[i]</code> being the intercept for the model with tuning parameters <code>all.alpha[i]</code> and <code>all.lambda[i]</code>.</p>
</td></tr>
<tr><td><code>y.hat.mat</code></td>
<td>
<p>matrix with <code>y.hat.mat[i,]</code> containing fitted y values for the tuning parameters <code>all.alpha[i]</code> and <code>all.lambda[i]</code>.</p>
</td></tr>
<tr><td><code>non.sparse.list</code></td>
<td>
<p>list with <code>non.sparse.list[[i]]</code> containing the indices for the predictors with non-sparse fits for the tuning parameters <code>all.alpha[i]</code> and <code>all.lambda[i]</code>.</p>
</td></tr>
<tr><td><code>num.non.sparse</code></td>
<td>
<p>vector with <code>num.non.sparse[i]</code> indicating the number of non-sparse predictor fits for the tuning parameters <code>all.alpha[i]</code> and <code>all.lambda[i]</code>.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>as specified by user.</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>as specified by user.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>as specified by user (or default).</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>as specified by user (or default).</p>
</td></tr>
<tr><td><code>tolerance</code></td>
<td>
<p>as specified by user (or default).</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ashley Petersen
</p>


<h3>References</h3>

<p>Petersen, A., Witten, D., and Simon, N. (2014). Fused Lasso Additive Model. arXiv preprint arXiv:1409.5391.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.flam">predict.flam</a></code>, <code><a href="#topic+plot.flam">plot.flam</a></code>, <code><a href="#topic+summary.flam">summary.flam</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See ?'flam-package' for a full example of how to use this package

#generate data
set.seed(1)
data &lt;- sim.data(n = 50, scenario = 1, zerof = 10, noise = 1)

#fit model for a range of lambda chosen by default and alpha's of 0.75 and 1
flam.out &lt;- flam(x = data$x, y = data$y, alpha.seq = c(0.75, 1))
#or specify desired lambda sequence (often equally spaced on log scale)
#should be a decreasing sequence of several values for computational speed
user.lambda.seq &lt;- exp(seq(log(50), log(1), len=40))
flam.out2 &lt;- flam(x = data$x, y = data$y, lambda.seq = user.lambda.seq)

## Not run: 
#alternatively, generate data for logistic FLAM model
data2 &lt;- sim.data(n = 50, scenario = 1, zerof = 10, family = "binomial")
#fit the FLAM model using logistic loss
flam.logistic.out &lt;- flam(x = data2$x, y = data2$y, family = "binomial")

## End(Not run)

#'flam' returns an object of the class 'flam'
#see ?'flam-package' for an example using S3 methods for 'flam' objects

</code></pre>

<hr>
<h2 id='flamCV'>
Fit the Fused Lasso Additive Model and Do Tuning Parameter Selection using K-Fold Cross-Validation
</h2><span id='topic+flamCV'></span>

<h3>Description</h3>

<p>Fit an additive model where each component is estimated to piecewise constant with a small number of adaptively-chosen knots. Tuning parameter selection is done using K-fold cross-validation. In particular, this function implements the &quot;fused lasso additive model&quot;, as proposed in Petersen, A., Witten, D., and Simon, N. (2014). Fused Lasso Additive Model. arXiv preprint arXiv:1409.5391.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flamCV(x, y, lambda.min.ratio = 0.01, n.lambda = 50, lambda.seq = NULL,
alpha = 1, family = "gaussian", method = "BCD", fold = NULL,
n.fold = NULL, seed = NULL, within1SE = T, tolerance = 10e-6)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="flamCV_+3A_x">x</code></td>
<td>

<p>n x p covariate matrix. May have p &gt; n.
</p>
</td></tr>
<tr><td><code id="flamCV_+3A_y">y</code></td>
<td>

<p>n-vector containing the outcomes for the n observations in <code>x</code>.
</p>
</td></tr>
<tr><td><code id="flamCV_+3A_lambda.min.ratio">lambda.min.ratio</code></td>
<td>

<p>smallest value for <code>lambda.seq</code>, as a fraction of the maximum lambda value, which is the data-derived smallest value for which all estimated functions are zero. The default is 0.01.
</p>
</td></tr>
<tr><td><code id="flamCV_+3A_n.lambda">n.lambda</code></td>
<td>

<p>the number of lambda values to consider - the default is 50.
</p>
</td></tr>
<tr><td><code id="flamCV_+3A_lambda.seq">lambda.seq</code></td>
<td>

<p>a user-supplied sequence of positive lambda values to consider. The typical usage is to calculate <code>lambda.seq</code> using <code>lambda.min.ratio</code> and <code>n.lambda</code>, but providing <code>lambda.seq</code> overrides this. If provided, <code>lambda.seq</code> should be a decreasing sequence of values, since <code>flamCV</code> relies on warm starts for speed. Thus fitting the model for a whole sequence of lambda values is often faster than fitting for a single lambda value.
</p>
</td></tr>
<tr><td><code id="flamCV_+3A_alpha">alpha</code></td>
<td>

<p>the value of the tuning parameter alpha to consider - default is 1. Value must be in [0,1] with values near 0 prioritizing sparsity of functions and values near 1 prioritizing limiting the number of knots. Empirical evidence suggests using alpha of 1 when p &lt; n and alpha of 0.75 when p &gt; n.
</p>
</td></tr>
<tr><td><code id="flamCV_+3A_family">family</code></td>
<td>

<p>specifies the loss function to use. Currently supports squared error loss (default; <code>family="gaussian"</code>) and logistic loss (<code>family="binomial"</code>).
</p>
</td></tr>
<tr><td><code id="flamCV_+3A_method">method</code></td>
<td>

<p>specifies the optimization algorithm to use. Options are block-coordinate descent (default; <code>method="BCD"</code>), generalized gradient descent (<code>method="GGD"</code>), or generalized gradient descent with backtracking (<code>method="GGD.backtrack"</code>).  This argument is ignored if <code>family="binomial"</code>.
</p>
</td></tr>
<tr><td><code id="flamCV_+3A_fold">fold</code></td>
<td>

<p>user-supplied fold numbers for cross-validation. If supplied, <code>fold</code> should be an n-vector with entries in 1,...,K when doing K-fold cross-validation. The default is to choose <code>fold</code> using <code>n.fold</code>.
</p>
</td></tr>
<tr><td><code id="flamCV_+3A_n.fold">n.fold</code></td>
<td>

<p>the number of folds, K, to use for the K-fold cross-validation selection of tuning parameters. The default is 10 - specification of <code>fold</code> overrides use of <code>n.fold</code>.
</p>
</td></tr>
<tr><td><code id="flamCV_+3A_seed">seed</code></td>
<td>

<p>an optional number used with <code>set.seed()</code> at the beginning of the function. This is only relevant if <code>fold</code> is not specified by the user.
</p>
</td></tr>
<tr><td><code id="flamCV_+3A_within1se">within1SE</code></td>
<td>

<p>logical (<code>TRUE</code> or <code>FALSE</code>) for how cross-validated tuning parameters should be chosen. If <code>within1SE=TRUE</code>, lambda is chosen to be the value corresponding to the most sparse model with cross-validation error within one standard error of the minimum cross-validation error. If <code>within1SE=FALSE</code>, lambda is chosen to be the value corresponding to the minimum cross-validation error.
</p>
</td></tr>
<tr><td><code id="flamCV_+3A_tolerance">tolerance</code></td>
<td>

<p>specifies the convergence criterion for the objective (default is 10e-6).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that <code>flamCV</code> does not cross-validate over <code>alpha</code> - just a single value should be provided. However, if the user would like to cross-validate over <code>alpha</code>, then <code>flamCV</code> should be called multiple times for different values of <code>alpha</code> and the same <code>seed</code>. This ensures that the cross-validation folds (<code>fold</code>) remain the same for the different values of <code>alpha</code>. See the example below for details.
</p>


<h3>Value</h3>

<p>An object with S3 class &quot;flamCV&quot;.
</p>
<table role = "presentation">
<tr><td><code>mean.cv.error</code></td>
<td>
<p>m-vector containing cross-validation error where m is the length of <code>lambda.seq</code>. Note that <code>mean.cv.error[i]</code> contains the cross-validation error for tuning parameters <code>alpha</code> and <code>flam.out$all.lambda[i]</code>.</p>
</td></tr>
<tr><td><code>se.cv.error</code></td>
<td>
<p>m-vector containing cross-validation standard error where m is the length of <code>lambda.seq</code>. Note that <code>se.cv.error[i]</code> contains the standard error of the cross-validation error for tuning parameters <code>alpha</code> and <code>flam.out$all.lambda[i]</code>.</p>
</td></tr>
<tr><td><code>lambda.cv</code></td>
<td>
<p>optimal lambda value chosen by cross-validation.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>as specified by user (or default).</p>
</td></tr>
<tr><td><code>index.cv</code></td>
<td>
<p>index of the model corresponding to 'lambda.cv'.</p>
</td></tr>
<tr><td><code>flam.out</code></td>
<td>
<p>object of class 'flam' returned by <code>flam</code>.</p>
</td></tr>
<tr><td><code>fold</code></td>
<td>
<p>as specified by user (or default).</p>
</td></tr>
<tr><td><code>n.folds</code></td>
<td>
<p>as specified by user (or default).</p>
</td></tr>
<tr><td><code>within1SE</code></td>
<td>
<p>as specified by user (or default).</p>
</td></tr>
<tr><td><code>tolerance</code></td>
<td>
<p>as specified by user (or default).</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>matched call.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ashley Petersen
</p>


<h3>References</h3>

<p>Petersen, A., Witten, D., and Simon, N. (2014). Fused Lasso Additive Model. arXiv preprint arXiv:1409.5391.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+flam">flam</a></code>, <code><a href="#topic+plot.flamCV">plot.flamCV</a></code>, <code><a href="#topic+summary.flamCV">summary.flamCV</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See ?'flam-package' for a full example of how to use this package

#generate data
set.seed(1)
data &lt;- sim.data(n = 50, scenario = 1, zerof = 10, noise = 1)

#fit model for a range of lambda chosen by default
#pick lambda using 2-fold cross-validation
#note: use larger 'n.fold' (e.g., 10) in practice
flamCV.out &lt;- flamCV(x = data$x, y = data$y, alpha = 0.75, n.fold = 2)

## Not run: 
#note that cross-validation is only done to choose lambda for specified alpha
#to cross-validate over alpha also, call 'flamCV' for several alpha and set seed
#note: use larger 'n.fold' (e.g., 10) in practice
flamCV.out1 &lt;- flamCV(x = data$x, y = data$y, alpha = 0.65, seed = 100, 
	within1SE = FALSE, n.fold = 2)
flamCV.out2 &lt;- flamCV(x = data$x, y = data$y, alpha = 0.75, seed = 100, 
	within1SE = FALSE, n.fold = 2)
flamCV.out3 &lt;- flamCV(x = data$x, y = data$y, alpha = 0.85, seed = 100, 
	within1SE = FALSE, n.fold = 2)
#this ensures that the folds used are the same
flamCV.out1$fold; flamCV.out2$fold; flamCV.out3$fold
#compare the CV error for the optimum lambda of each alpha to choose alpha
CVerrors &lt;- c(flamCV.out1$mean.cv.error[flamCV.out1$index.cv], 
	flamCV.out2$mean.cv.error[flamCV.out2$index.cv], 
	flamCV.out3$mean.cv.error[flamCV.out3$index.cv])
best.alpha &lt;- c(flamCV.out1$alpha, flamCV.out2$alpha, 
	flamCV.out3$alpha)[which(CVerrors==min(CVerrors))]

#also can generate data for logistic FLAM model
data2 &lt;- sim.data(n = 50, scenario = 1, zerof = 10, family = "binomial")
#fit the FLAM model with cross-validation using logistic loss
#note: use larger 'n.fold' (e.g., 10) in practice
flamCV.logistic.out &lt;- flamCV(x = data2$x, y = data2$y, family = "binomial",
	n.fold = 2)

## End(Not run)

#'flamCV' returns an object of the class 'flamCV' that includes an object
#of class 'flam' (flam.out); see ?'flam-package' for an example using S3
#methods for the classes of 'flam' and 'flamCV'
</code></pre>

<hr>
<h2 id='flamDOF'>
Calculate Degrees of Freedom for Fused Lasso Additive Model
</h2><span id='topic+flamDOF'></span>

<h3>Description</h3>

<p>This function calculates the degrees of freedom for a fused lasso additive model fit using <code><a href="#topic+flam">flam</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flamDOF(object, index)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="flamDOF_+3A_object">object</code></td>
<td>

<p>an object of the class &quot;flam&quot;.
</p>
</td></tr>
<tr><td><code id="flamDOF_+3A_index">index</code></td>
<td>

<p>the index for the model of interest. Note that <code>index</code> of i corresponds to the model with tuning parameters <code>object$all.alpha[i]</code> and <code>object$all.lambda[i]</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The degrees of freedom for FLAM were derived in Section 4.1 of Petersen, A., Witten, D., and Simon, N. (2014). Fused Lasso Additive Model. arXiv preprint arXiv:1409.5391.
</p>


<h3>Value</h3>

<p>The degrees of freedom for the specified model.
</p>


<h3>Author(s)</h3>

<p>Ashley Petersen
</p>


<h3>References</h3>

<p>Petersen, A., Witten, D., and Simon, N. (2014). Fused Lasso Additive Model. arXiv preprint arXiv:1409.5391.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See ?'flam-package' for a full example of how to use this package

#generate data
#note: use larger 'n' for more reasonable results
set.seed(1)
data &lt;- sim.data(n = 20, scenario = 1, zerof = 10, noise = 1)

#fit model for a range of tuning parameters
flam.out &lt;- flam(x = data$x, y = data$y)
#or fit model and select tuning parameters using 2-fold cross-validation
#note: use larger 'n.fold' (e.g., 10) in practice
flamCV.out &lt;- flamCV(x = data$x, y = data$y, n.fold = 2)

#calculate degrees of freedom for the model chosen using cross-validation
flamDOF(object = flamCV.out$flam.out, index = flamCV.out$index.cv)
#or for any fit from a 'flam' object
flamDOF(object = flam.out, index = 25)
flamDOF(object = flamCV.out$flam.out, index = 25)
#which corresponds to lambda and alpha of
flam.out$all.lambda[25]; flam.out$all.alpha[25]
</code></pre>

<hr>
<h2 id='plot.flam'>
Plots Function Estimates for Fit of Class &quot;flam&quot;
</h2><span id='topic+plot.flam'></span>

<h3>Description</h3>

<p>This function plots the estimated functions from a model estimated using <code><a href="#topic+flam">flam</a></code>. The user specifies the model of interest (i.e., the tuning parameters) and a plot is made for the estimated association between all non-sparse (or a chosen subset of) features and the outcome.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'flam'
plot(x, index, n.plot = 10, predictor.indicators = NULL,
predictor.labels = NULL, outcome.label = "outcome", ticks = F, 
col = "dodgerblue", n.panel.width = NULL, n.panel.height = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.flam_+3A_x">x</code></td>
<td>

<p>an object of class &quot;flam&quot;.
</p>
</td></tr>
<tr><td><code id="plot.flam_+3A_index">index</code></td>
<td>

<p>the index for the model of interest to be plotted. Note that <code>index</code> of i corresponds to the model with tuning parameters <code>x$all.alpha[i]</code> and <code>x$all.lambda[i]</code>.
</p>
</td></tr>
<tr><td><code id="plot.flam_+3A_n.plot">n.plot</code></td>
<td>

<p>the number of predictors to be plotted (default of 10). Note that only non-sparse predictors are plotted, however, this argument is ignored if <code>predictor.indicators</code> is specified.
</p>
</td></tr>
<tr><td><code id="plot.flam_+3A_predictor.indicators">predictor.indicators</code></td>
<td>

<p>a vector indicating which predictor function estimates to plot. The vector should contain the column numbers of <code>x$x</code> whose function estimates are to be plotted. By default, the <code>n.plot</code> predictors with the largest L2 norm are plotted.
</p>
</td></tr>
<tr><td><code id="plot.flam_+3A_predictor.labels">predictor.labels</code></td>
<td>

<p>a vector containing the predictor labels of the same length as <code>predictor.indicators</code> if specified, otherwise of length <code>ncol(x$x)</code>. By default, &quot;Predictor 1&quot;, &quot;Predictor 2&quot;, ... are used.
</p>
</td></tr>
<tr><td><code id="plot.flam_+3A_outcome.label">outcome.label</code></td>
<td>

<p>the name of the outcome used in the y-axis label. By default, the label is &quot;outcome&quot;.
</p>
</td></tr>
<tr><td><code id="plot.flam_+3A_ticks">ticks</code></td>
<td>

<p>a logical (<code>TRUE</code> or <code>FALSE</code>) for whether tick marks indicating the distribution of the predictor should be included at the bottom of each plot.
</p>
</td></tr>
<tr><td><code id="plot.flam_+3A_col">col</code></td>
<td>

<p>a vector of colors used to plot the function estimates. If <code>col</code> has length 1, then the same color is used for all predictors. Otherwise, <code>col</code> should indicate the color for each predictor and have the same length as <code>predictor.indicators</code> if specified, otherwise the number of columns of <code>x$x</code>.
</p>
</td></tr>
<tr><td><code id="plot.flam_+3A_n.panel.width">n.panel.width</code></td>
<td>

<p>the plots will be plotted with <code>par(mfrow=c(n.panel.height,n.panel.width))</code>. If specified, <code>n.panel.height</code> must also be specified. By default, an appropriate grid of plots is used.
</p>
</td></tr>
<tr><td><code id="plot.flam_+3A_n.panel.height">n.panel.height</code></td>
<td>

<p>the plots will be plotted with <code>par(mfrow=c(n.panel.height,n.panel.width))</code>. If specified, <code>n.panel.width</code> must also be specified. By default, an appropriate grid of plots is used.
</p>
</td></tr>
<tr><td><code id="plot.flam_+3A_...">...</code></td>
<td>

<p>additional arguments to be passed. These are ignored in this function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The estimated function fits are drawn by connecting the predictions for all of the observations in <code>x$x</code>. This may result in fits that appear not to be piecewise consant if only a single observation is observed for a range of x-values.
</p>


<h3>Author(s)</h3>

<p>Ashley Petersen
</p>


<h3>References</h3>

<p>Petersen, A., Witten, D., and Simon, N. (2014). Fused Lasso Additive Model. arXiv preprint arXiv:1409.5391.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+flam">flam</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See ?'flam-package' for a full example of how to use this package

#generate data
set.seed(1)
data &lt;- sim.data(n = 50, scenario = 1, zerof = 10, noise = 1)
#fit model for a range of tuning parameters
flam.out &lt;- flam(x = data$x, y = data$y, alpha.seq = c(0.8, 0.9, 1))

#we plot the predictor fits for a specific index, e.g. 25
#that is, lambda and alpha of
flam.out$all.lambda[25]; flam.out$all.alpha[25]
plot(flam.out, index = 25)
#the fit only has 5 non-sparse features

#by default, up to 10 non-sparse features with the largest L2 norms are 
#plotted, but we can plot a different number of features if desired
plot(flam.out, index = 40, n.plot = 12)
#or we can plot specific predictors of interest
plot(flam.out, index = 40, predictor.indicators = c(1:4, 6, 8, 11, 12))
</code></pre>

<hr>
<h2 id='plot.flamCV'>
Plots Cross-Validation Curve for Object of Class &quot;flamCV&quot;
</h2><span id='topic+plot.flamCV'></span>

<h3>Description</h3>

<p>This function plots the cross-validation curve for a series of models fit using <code><a href="#topic+flamCV">flamCV</a></code>. The cross-validation error with +/-1 standard error is plotted for each value of lambda considered in the call to <code>flamCV</code> with a dotted vertical line indicating the chosen lambda.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'flamCV'
plot(x, showSE = T, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.flamCV_+3A_x">x</code></td>
<td>

<p>an object of class &quot;flamCV&quot;.
</p>
</td></tr>
<tr><td><code id="plot.flamCV_+3A_showse">showSE</code></td>
<td>

<p>a logical (<code>TRUE</code> or <code>FALSE</code>) for whether the standard errors of the curve should be plotted.
</p>
</td></tr>
<tr><td><code id="plot.flamCV_+3A_...">...</code></td>
<td>

<p>additional arguments to be passed. These are ignored in this function.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ashley Petersen
</p>


<h3>References</h3>

<p>Petersen, A., Witten, D., and Simon, N. (2014). Fused Lasso Additive Model. arXiv preprint arXiv:1409.5391.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+flamCV">flamCV</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See ?'flam-package' for a full example of how to use this package

#generate data
set.seed(1)
data &lt;- sim.data(n = 50, scenario = 1, zerof = 0, noise = 1)

#fit model and select tuning parameters using 2-fold cross-validation
#note: use larger 'n.fold' (e.g., 10) in practice
flamCV.out &lt;- flamCV(x = data$x, y = data$y, within1SE = TRUE, n.fold = 2)

#lambdas chosen is
flamCV.out$lambda.cv

#we can now plot the cross-validation error curve with standard errors
#vertical dotted line at lambda chosen by cross-validation
plot(flamCV.out)
#or without standard errors
plot(flamCV.out, showSE = FALSE)

## Not run: 
#can choose lambda to be value with minimum CV error
#instead of lambda with CV error within 1 standard error of the minimum
flamCV.out2 &lt;- flamCV(x = data$x, y = data$y, within1SE = FALSE, n.fold = 2)

#contrast to chosen lambda for minimum cross-validation error
#it's a less-regularized model (i.e., lambda is smaller)
plot(flamCV.out2)

## End(Not run)
</code></pre>

<hr>
<h2 id='predict.flam'>
Predicts Observations for a New Covariate Matrix and Fit from <code><a href="#topic+flam">flam</a></code>
</h2><span id='topic+predict.flam'></span>

<h3>Description</h3>

<p>This function makes predictions from a specified covariate matrix for a fit of the class &quot;flam&quot; with user-specified tuning parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'flam'
predict(object, new.x, lambda, alpha, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.flam_+3A_object">object</code></td>
<td>

<p>an object of the class &quot;flam&quot;.
</p>
</td></tr>
<tr><td><code id="predict.flam_+3A_new.x">new.x</code></td>
<td>

<p>the covariate matrix for which to make predictions - the number of columns should match that of <code>object$x</code>.
</p>
</td></tr>
<tr><td><code id="predict.flam_+3A_lambda">lambda</code></td>
<td>

<p>the desired value for the tuning parameter lambda. This does not need to be a value in <code>object$all.lambda</code>.
</p>
</td></tr>
<tr><td><code id="predict.flam_+3A_alpha">alpha</code></td>
<td>

<p>the desired value for the tuning parameter alpha. This does not need to be a value in <code>object$all.alpha</code>.
</p>
</td></tr>
<tr><td><code id="predict.flam_+3A_...">...</code></td>
<td>

<p>additional arguments to be passed. These are ignored in this function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is likely that <code>new.x[,i]</code> contains values not contained in <code>object$x[,i]</code>. Predictions for that particular case are taken to be a linear interpolation of the nearest neighboring values in <code>object$x[,i]</code>, i.e., the closest smaller value and the closest larger value.
</p>


<h3>Value</h3>

<p>A vector containing the fitted y values for <code>new.x</code>.
</p>


<h3>Author(s)</h3>

<p>Ashley Petersen
</p>


<h3>References</h3>

<p>Petersen, A., Witten, D., and Simon, N. (2014). Fused Lasso Additive Model. arXiv preprint arXiv:1409.5391.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+flam">flam</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See ?'flam-package' for a full example of how to use this package

#generate data
set.seed(1)
data &lt;- sim.data(n = 100, scenario = 1, zerof = 0, noise = 1)

#fit model for a range of tuning parameters
flam.out &lt;- flam(x = data$x, y = data$y)

#we can make predictions for a covariate matrix with new observations
#choose desired alpha and lambda
alpha &lt;- flam.out$all.alpha[15]; lambda &lt;- flam.out$all.lambda[15]
#new.x with 20 observations and the same number of features as flam.out$x
new.data &lt;- sim.data(n = 20, scenario = 1, zerof = 0, noise = 1)
new.x &lt;- new.data$x
#make predictions
y.hat &lt;- predict(flam.out, new.x = new.x, lambda = lambda, alpha = alpha)
#which can be compared to the true y
plot(new.data$y, y.hat, xlab="y", ylab=expression(hat(y)))
abline(0,1,lty=2)

#can also make predictions for any alpha and lambda:
predict(flam.out, new.x = new.x, lambda = 2, alpha = 0.9)
</code></pre>

<hr>
<h2 id='sim.data'>
Simulate Data from a Variety of Functional Scenarios
</h2><span id='topic+sim.data'></span>

<h3>Description</h3>

<p>This function generates data according to the simulation scenarios considered in Section 5 and plotted in Figure 2 of Petersen, A., Witten, D., and Simon, N. (2014). Fused Lasso Additive Model. arXiv preprint arXiv:1409.5391. Each scenario has four covariates that have some non-linear association with the outcome. There is the option to also generate a user-specified number of covariates that have no association with the outcome.</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.data(n, scenario, zerof, noise = 1, family = "gaussian")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sim.data_+3A_n">n</code></td>
<td>

<p>number of observations.
</p>
</td></tr>
<tr><td><code id="sim.data_+3A_scenario">scenario</code></td>
<td>

<p>simulation scenario to use. Options are 1, 2, 3, or 4, which correspond to the simulation scenarios of Section 5 in Petersen, A., Witten, D., and Simon, N. (2014). Fused Lasso Additive Model. arXiv preprint arXiv:1409.5391. Each scenario has four covariates.
</p>
</td></tr>
<tr><td><code id="sim.data_+3A_zerof">zerof</code></td>
<td>

<p>number of noise covariates (those that have no relationship to the outcome) to include. This can be used to replicate the high-dimensional scenarios of Section 5 in Petersen, A., Witten, D., and Simon, N. (2014). Fused Lasso Additive Model. arXiv preprint arXiv:1409.5391. The total number of covariates will be <code>4 + zerof</code>.
</p>
</td></tr>
<tr><td><code id="sim.data_+3A_noise">noise</code></td>
<td>

<p>the variance of the errors. If <code>family = "gaussian"</code>, the errors of observations are generated using MVN(0, <code>noise</code>I) with default of 1, otherwise <code>noise</code> is not used if <code>family="binomial"</code>. 
</p>
</td></tr>
<tr><td><code id="sim.data_+3A_family">family</code></td>
<td>

<p>the error distribution of observations (must be <code>family="gaussian"</code> or <code>family="binomial"</code>). If <code>family = "gaussian"</code>, the errors of observations are generated using MVN(0, <code>noise</code>I), otherwise observations are Bernoulli if <code>family="binomial"</code>. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>x</code></td>
<td>
<p>n x p covariate matrix.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>n-vector containing the outcomes for the n observations in <code>x</code>.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>n x p mean matrix used to generate <code>y</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ashley Petersen
</p>


<h3>References</h3>

<p>Petersen, A., Witten, D., and Simon, N. (2014). Fused Lasso Additive Model. arXiv preprint arXiv:1409.5391.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See ?'flam-package' for a full example of how to use this package

#generate data to fit FLAM model with squared-error loss
set.seed(1)
data &lt;- sim.data(n = 50, scenario = 1, zerof = 10, noise = 1)
flam.out &lt;- flam(x = data$x, y = data$y, family = "gaussian")

#alternatively, generate data for logistic FLAM model 
#note: 'noise' argument no longer needed
data2 &lt;- sim.data(n = 50, scenario = 1, zerof = 0, family = "binomial")
flam.logistic.out &lt;- flam(x = data2$x, y = data2$y, family = "binomial")


#vary generating functions
#choose large n because we want to plot generating functions
data1 &lt;- sim.data(n = 500, scenario = 1, zerof = 0)
data2 &lt;- sim.data(n = 500, scenario = 2, zerof = 0)
data3 &lt;- sim.data(n = 500, scenario = 3, zerof = 0)
data4 &lt;- sim.data(n = 500, scenario = 4, zerof = 0)
#and plot to see functional forms
par(mfrow=c(2,2))
col.vec = c("dodgerblue1","orange","seagreen1","hotpink")
for (i in 1:4) {
	if (i==1) data = data1 else if (i==2) data = data2 
		else if (i==3) data = data3 else data = data4
	plot(1,type="n",xlim=c(-2.5,2.5),ylim=c(-3,3),xlab=expression(x[j]),
		ylab=expression(f[j](x[j])),main=paste("Scenario ",i,sep=""))
	sapply(1:4, function(j) points(sort(data$x[,j]), 
		data$theta[order(data$x[,j]),j],col=col.vec[j],type="l",lwd=3))
}

#include large number of predictors that have no relationship to outcome
data &lt;- sim.data(n = 50, scenario = 1, zerof = 100, noise = 1)
</code></pre>

<hr>
<h2 id='summary.flam'>
Summarizes a Call to <code>flam</code>
</h2><span id='topic+summary.flam'></span><span id='topic+plot.flamSparsity'></span>

<h3>Description</h3>

<p>This function summarizes a call to <code><a href="#topic+flam">flam</a></code>, as well as the sparsity pattern of the resulting feature estimates for a single or all fits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'flam'
summary(object, index = NULL, ...)
## S3 method for class 'flamSparsity'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.flam_+3A_object">object</code></td>
<td>

<p>an object of class &quot;flam&quot;.
</p>
</td></tr>
<tr><td><code id="summary.flam_+3A_index">index</code></td>
<td>

<p>the index for the fit of interest to be summarized. Note that <code>index</code> of i corresponds to the model with tuning parameters <code>object$all.alpha[i]</code> and <code>object$all.lambda[i]</code>. If <code>index</code> is not specified, information summarizing all fits is given.
</p>
</td></tr>
<tr><td><code id="summary.flam_+3A_x">x</code></td>
<td>

<p>an object of class 'flamSparsity', which is silently returned by <code>summary.flam</code>. 
</p>
</td></tr>
<tr><td><code id="summary.flam_+3A_...">...</code></td>
<td>

<p>additional arguments to be passed. These are ignored in this function.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>index</code> is not specified, <code>summary.flam</code> silently returns the sparsity matrix and tuning parameters in an object of class 'flamSparsity'. This is used when <code>plot(summary(object))</code> is called.
</p>


<h3>Author(s)</h3>

<p>Ashley Petersen
</p>


<h3>References</h3>

<p>Petersen, A., Witten, D., and Simon, N. (2014). Fused Lasso Additive Model. arXiv preprint arXiv:1409.5391.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+flam">flam</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See ?'flam-package' for a full example of how to use this package

#generate data
set.seed(1)
data &lt;- sim.data(n = 50, scenario = 1, zerof = 10, noise = 1)
#fit model for a range of tuning parameters
flam.out &lt;- flam(x = data$x, y = data$y, alpha.seq = c(0.8, 0.9, 1))

#summarize all of the fits (in particular, the percent sparsity achieved)
#note: percent sparsity is the percentage of features estimated to have 
#no relationship with outcome
summary(flam.out)
#the percent sparsity over the range of tuning parameters can also 
#be displayed in a plot
plot(summary(flam.out))

#we can also summarize the fit with a specific index, e.g. 25
#that is, lambda and alpha of
flam.out$all.lambda[25]; flam.out$all.alpha[25]
summary(flam.out, index = 25)
</code></pre>

<hr>
<h2 id='summary.flamCV'>
Summarizes a Call to <code>flamCV</code>
</h2><span id='topic+summary.flamCV'></span>

<h3>Description</h3>

<p>This function summarizes a call to code<a href="#topic+flamCV">flamCV</a> and identifies the tuning parameter chosen by cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'flamCV'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.flamCV_+3A_object">object</code></td>
<td>

<p>an object of class &quot;flamCV&quot;.
</p>
</td></tr>
<tr><td><code id="summary.flamCV_+3A_...">...</code></td>
<td>

<p>additional arguments to be passed. These are ignored in this function.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ashley Petersen
</p>


<h3>References</h3>

<p>Petersen, A., Witten, D., and Simon, N. (2014). Fused Lasso Additive Model. arXiv preprint arXiv:1409.5391.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+flamCV">flamCV</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See ?'flam-package' for a full example of how to use this package

#generate data
set.seed(1)
data &lt;- sim.data(n = 50, scenario = 1, zerof = 0, noise = 1)
#fit model and select tuning parameters using 2-fold cross-validation
#note: use larger 'n.fold' (e.g., 10) in practice
flamCV.out &lt;- flamCV(x = data$x, y = data$y, n.fold = 2)

#we can summarize the cross-validation function call
summary(flamCV.out)
#lambda chosen by cross-validation is also available from
flamCV.out$lambda.cv
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
