<!DOCTYPE html><html><head><title>Help for package robustmatrix</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {robustmatrix}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#clean_prob_mmcd'><p>Probability of obtaining at least one clean h-subset in the <code>mmcd</code> function.</p></a></li>
<li><a href='#cstep'><p>C-step of Matrix Minimum Covariance Determinant (MMCD) Estimator</p></a></li>
<li><a href='#darwin'><p>DARWIN (Diagnosis AlzheimeR WIth haNdwriting)</p></a></li>
<li><a href='#matrixShapley'><p>Outlier explanation based on Shapley values for matrix-variate data</p></a></li>
<li><a href='#mmcd'><p>The Matrix Minimum Covariance Determinant (MMCD) Estimator</p></a></li>
<li><a href='#mmd'><p>Matrix Mahalanobis distance</p></a></li>
<li><a href='#mmle'><p>Maximum Likelihood Estimation for Matrix Normal Distribtuion</p></a></li>
<li><a href='#n_subsets_mmcd'><p>Number of subsets that are required to obtain at least one clean h-subset in the <code>mmcd</code> function with probability <code>prob</code>.</p></a></li>
<li><a href='#rmatnorm'><p>Simulate from a Matrix Normal Distribution</p></a></li>
<li><a href='#weather'><p>Glacier weather data – Sonnblick observatory</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Robust Matrix-Variate Parameter Estimation</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.2</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Marcus Mayrhofer &lt;marcus.mayrhofer@tuwien.ac.at&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Robust covariance estimation for matrix-valued data and data with Kronecker-covariance structure using the Matrix Minimum Covariance Determinant (MMCD) estimators and outlier explanation using and Shapley values. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo,</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, stats, Rdpack</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, roxygen2, gridExtra, dplyr, forcats,
ggnewscale, ggplot2, ggrepel, tibble, tidyr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.0</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-29 08:42:25 UTC; Marcus Mayrhofer</td>
</tr>
<tr>
<td>Author:</td>
<td>Marcus Mayrhofer [aut, cre],
  Una Radojičić [aut],
  Peter Filzmoser [aut]</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-29 12:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='clean_prob_mmcd'>Probability of obtaining at least one clean h-subset in the <code><a href="#topic+mmcd">mmcd</a></code> function.</h2><span id='topic+clean_prob_mmcd'></span>

<h3>Description</h3>

<p>Probability of obtaining at least one clean h-subset in the <code><a href="#topic+mmcd">mmcd</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clean_prob_mmcd(p, q, n_subsets = 500, contamination = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clean_prob_mmcd_+3A_p">p</code></td>
<td>
<p>number of rows.</p>
</td></tr>
<tr><td><code id="clean_prob_mmcd_+3A_q">q</code></td>
<td>
<p>number of columns.</p>
</td></tr>
<tr><td><code id="clean_prob_mmcd_+3A_n_subsets">n_subsets</code></td>
<td>
<p>number of elemental h-substs (default is 500).</p>
</td></tr>
<tr><td><code id="clean_prob_mmcd_+3A_contamination">contamination</code></td>
<td>
<p>level of contamination (default is 0.5).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability of obtaining at least one clean h-subset in the <code><a href="#topic+mmcd">mmcd</a></code> function.
</p>

<hr>
<h2 id='cstep'>C-step of Matrix Minimum Covariance Determinant (MMCD) Estimator</h2><span id='topic+cstep'></span>

<h3>Description</h3>

<p>This function is part of the FastMMCD algorithm (double-blind 2024).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cstep(
  X,
  alpha = 0.5,
  h_init = -1L,
  init = TRUE,
  max_iter = 100L,
  max_iter_MLE = 100L,
  lambda = 0,
  adapt_alpha = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cstep_+3A_x">X</code></td>
<td>
<p>a 3d array of dimension <code class="reqn">(p,q,n)</code>, containing <code class="reqn">n</code> matrix-variate samples of <code class="reqn">p</code> rows and <code class="reqn">q</code> columns in each slice.</p>
</td></tr>
<tr><td><code id="cstep_+3A_alpha">alpha</code></td>
<td>
<p>numeric parameter between 0.5 (default) and 1. Controls the size <code class="reqn">h \approx alpha * n</code> of the h-subset over which the determinant is minimized.</p>
</td></tr>
<tr><td><code id="cstep_+3A_h_init">h_init</code></td>
<td>
<p>Integer. Size of initial h-subset. If smaller than 0 (default) size is chosen automatically.</p>
</td></tr>
<tr><td><code id="cstep_+3A_init">init</code></td>
<td>
<p>Logical. If TRUE (default) elemental subsets are used to initialize the procedure.</p>
</td></tr>
<tr><td><code id="cstep_+3A_max_iter">max_iter</code></td>
<td>
<p>upper limit of C-step iterations (default is 100)</p>
</td></tr>
<tr><td><code id="cstep_+3A_max_iter_mle">max_iter_MLE</code></td>
<td>
<p>upper limit of MLE iterations (default is 100)</p>
</td></tr>
<tr><td><code id="cstep_+3A_lambda">lambda</code></td>
<td>
<p>a smooting parameter for the rowwise and columnwise covariance matrices.</p>
</td></tr>
<tr><td><code id="cstep_+3A_adapt_alpha">adapt_alpha</code></td>
<td>
<p>Logical. If TRUE (default) alpha is adapted to take the dimension of the data into account.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following:
</p>
<table>
<tr><td><code>mu</code></td>
<td>
<p>Estimated <code class="reqn">p \times q</code> mean matrix.</p>
</td></tr>
<tr><td><code>cov_row</code></td>
<td>
<p>Estimated <code class="reqn">p</code> times <code class="reqn">p</code> rowwise covariance matrix.</p>
</td></tr>
<tr><td><code>cov_col</code></td>
<td>
<p>Estimated <code class="reqn">q</code> times <code class="reqn">q</code> columnwise covariance matrix.</p>
</td></tr>
<tr><td><code>cov_row_inv</code></td>
<td>
<p>Inverse of <code>cov_row</code>.</p>
</td></tr>
<tr><td><code>cov_col_inv</code></td>
<td>
<p>Inverse of <code>cov_col</code>.</p>
</td></tr>
<tr><td><code>md</code></td>
<td>
<p>Squared Mahalanobis distances.</p>
</td></tr>
<tr><td><code>md_raw</code></td>
<td>
<p>Squared Mahalanobis distances based on <em>raw</em> MMCD estimators.</p>
</td></tr>
<tr><td><code>det</code></td>
<td>
<p>Value of objective function (determinant of Kronecker product of rowwise and columnwise covariane).</p>
</td></tr>
<tr><td><code>dets</code></td>
<td>
<p>Objective values for the final h-subsets.</p>
</td></tr>
<tr><td><code>h_subset</code></td>
<td>
<p>Final h-subset of <em>raw</em> MMCD estimators.</p>
</td></tr>
<tr><td><code>iterations</code></td>
<td>
<p>Number of C-steps.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+mmcd">mmcd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 1000; p = 2; q = 3
mu = matrix(rep(0, p*q), nrow = p, ncol = q)
cov_row = matrix(c(1,0.5,0.5,1), nrow = p, ncol = p)
cov_col = matrix(c(3,2,1,2,3,2,1,2,3), nrow = q, ncol = q)
X &lt;- rmatnorm(n = 1000, mu, cov_row, cov_col)
ind &lt;- sample(1:n, 0.3*n)
X[,,ind] &lt;- rmatnorm(n = length(ind), matrix(rep(10, p*q), nrow = p, ncol = q), cov_row, cov_col)
par_mmle &lt;- mmle(X)
par_cstep &lt;- cstep(X)
distances_mmle &lt;- mmd(X, par_mmle$mu, par_mmle$cov_row, par_mmle$cov_col)
distances_cstep &lt;- mmd(X, par_cstep$mu, par_cstep$cov_row, par_cstep$cov_col)
plot(distances_mmle, distances_cstep)
abline(h = qchisq(0.99, p*q), lty = 2, col = "red")
abline(v = qchisq(0.99, p*q), lty = 2, col = "red")
</code></pre>

<hr>
<h2 id='darwin'>DARWIN (Diagnosis AlzheimeR WIth haNdwriting)</h2><span id='topic+darwin'></span>

<h3>Description</h3>

<p>The DARWIN (Diagnosis AlzheimeR WIth haNdwriting) dataset
comprises handwriting samples from 174 individuals.
Among them, 89 have been diagnosed with Alzheimer's disease (AD), while the remaining 85 are considered healthy subjects (H).
Each participant completed 25 handwriting tasks on paper, and their pen movements were recorded using a graphic tablet.
From the raw handwriting data, a set of 18 features was extracted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(darwin)
</code></pre>


<h3>Format</h3>

<p>An array of dimension <code class="reqn">(p,q,n)</code>, comprising <code class="reqn">n = 174</code> observations,
each represented by a <code class="reqn">p = 18</code> times <code class="reqn">q = 25</code> dimensional matrix.
The observed parameters are:
</p>

<ul>
<li><p>Total Time
</p>
</li>
<li><p>Air Time
</p>
</li>
<li><p>Paper Time
</p>
</li>
<li><p>Mean Speed on paper
</p>
</li>
<li><p>Mean Acceleration on paper
</p>
</li>
<li><p>Mean Acceleration in air
</p>
</li>
<li><p>Mean Jerk on paper
</p>
</li>
<li><p>Pressure Mean
</p>
</li>
<li><p>Pressure Variance
</p>
</li>
<li><p>Generalization of the Mean Relative Tremor (GMRT) on paper
</p>
</li>
<li><p>GMTR in air
</p>
</li>
<li><p>Mean GMRT
</p>
</li>
<li><p>Pendowns Number
</p>
</li>
<li><p>Max X Extension
</p>
</li>
<li><p>Max Y Extension
</p>
</li>
<li><p>Dispersion Index
</p>
</li></ul>



<h3>Source</h3>

<p>UC Irvine Machine Learning Repository - DARWIN - <a href="https://doi.org/10.24432/C55D0K">doi:10.24432/C55D0K</a>
</p>


<h3>References</h3>

<p>Cilia ND, De Stefano C, Fontanella F, Di Freca AS (2018).
&ldquo;An experimental protocol to support cognitive impairment diagnosis by using handwriting analysis.&rdquo;
<em>Procedia Computer Science</em>, <b>141</b>, 466&ndash;471. <br />
Cilia ND, De Gregorio G, De Stefano C, Fontanella F, Marcelli A, Parziale A (2022).
&ldquo;Diagnosing Alzheimer’s disease from on-line handwriting: a novel dataset and performance benchmarking.&rdquo;
<em>Engineering Applications of Artificial Intelligence</em>, <b>111</b>, 104822.
</p>

<hr>
<h2 id='matrixShapley'>Outlier explanation based on Shapley values for matrix-variate data</h2><span id='topic+matrixShapley'></span>

<h3>Description</h3>

<p><code>matrixShapley</code> decomposes the squared matrix Mahalanobis distance (<code><a href="#topic+mmd">mmd</a></code>) into additive outlyingness contributions of
the rows, columns, or cell of a matrix (Mayrhofer and Filzmoser 2023; double-blind 2024).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matrixShapley(X, mu = NULL, cov_row, cov_col, inverted = FALSE, type = "cell")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="matrixShapley_+3A_x">X</code></td>
<td>
<p>a 3d array of dimension <code class="reqn">(p,q,n)</code>, containing <code class="reqn">n</code> matrix-variate samples of <code class="reqn">p</code> rows and <code class="reqn">q</code> columns in each slice.</p>
</td></tr>
<tr><td><code id="matrixShapley_+3A_mu">mu</code></td>
<td>
<p>a <code class="reqn">p \times q</code> matrix containing the means.</p>
</td></tr>
<tr><td><code id="matrixShapley_+3A_cov_row">cov_row</code></td>
<td>
<p>a <code class="reqn">p \times p</code> positive-definite symmetric matrix specifying the rowwise covariance matrix</p>
</td></tr>
<tr><td><code id="matrixShapley_+3A_cov_col">cov_col</code></td>
<td>
<p>a <code class="reqn">q \times q</code> positive-definite symmetric matrix specifying the columnwise covariance matrix</p>
</td></tr>
<tr><td><code id="matrixShapley_+3A_inverted">inverted</code></td>
<td>
<p>Logical. FALSE by default.
If TRUE <code>cov_row</code> and <code>cov_col</code> are supposed to contain the inverted rowwise and columnwise covariance matrices, respectively.</p>
</td></tr>
<tr><td><code id="matrixShapley_+3A_type">type</code></td>
<td>
<p>Character. Either &quot;row&quot;, &quot;col&quot;, or &quot;cell&quot; (default) to compute rowwise, columnwise, or cellwise Shapley values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Rowwise, columnwise, or cellwise Shapley value(s).
</p>


<h3>References</h3>

<p>Mayrhofer M, Filzmoser P (2023).
&ldquo;Multivariate outlier explanations using Shapley values and Mahalanobis distances.&rdquo;
<em>Econometrics and Statistics</em>.<br /><br /> double-blind (2024).
&ldquo;Robust covariance estimation and explainable outlier detection for matrix-valued data.&rdquo;
<em>[Manuscript submitted for publication]</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mmd">mmd</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 1000; p = 2; q = 3
mu = matrix(rep(0, p*q), nrow = p, ncol = q)
cov_row = matrix(c(5,2,2,4), nrow = p, ncol = p)
cov_col = matrix(c(3,2,1,2,3,2,1,2,3), nrow = q, ncol = q)
X &lt;- rmatnorm(n = 1000, mu, cov_row, cov_col)
distances &lt;- mmd(X, mu, cov_row, cov_col)
</code></pre>

<hr>
<h2 id='mmcd'>The Matrix Minimum Covariance Determinant (MMCD) Estimator</h2><span id='topic+mmcd'></span>

<h3>Description</h3>

<p><code>mmcd</code> computes the robust MMCD estimators of location and covariance for matrix-variate data
using the FastMMCD algorithm (double-blind 2024).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mmcd(
  X,
  nsamp = 500L,
  alpha = 0.5,
  lambda = 0,
  max_iter_cstep = 100L,
  max_iter_MLE = 100L,
  max_iter_cstep_init = 2L,
  max_iter_MLE_init = 2L,
  adapt_alpha = TRUE,
  reweight = TRUE,
  scale_consistency = "quant",
  outlier_quant = 0.975,
  nthreads = 1L
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmcd_+3A_x">X</code></td>
<td>
<p>a 3d array of dimension <code class="reqn">(p,q,n)</code>, containing <code class="reqn">n</code> matrix-variate samples of <code class="reqn">p</code> rows and <code class="reqn">q</code> columns in each slice.</p>
</td></tr>
<tr><td><code id="mmcd_+3A_nsamp">nsamp</code></td>
<td>
<p>number of initial h-subsets (default is 500).</p>
</td></tr>
<tr><td><code id="mmcd_+3A_alpha">alpha</code></td>
<td>
<p>numeric parameter between 0.5 (default) and 1. Controls the size <code class="reqn">h \approx alpha * n</code> of the h-subset over which the determinant is minimized.</p>
</td></tr>
<tr><td><code id="mmcd_+3A_lambda">lambda</code></td>
<td>
<p>a smooting parameter for the rowwise and columnwise covariance matrices.</p>
</td></tr>
<tr><td><code id="mmcd_+3A_max_iter_cstep">max_iter_cstep</code></td>
<td>
<p>upper limit of C-step iterations (default is 100)</p>
</td></tr>
<tr><td><code id="mmcd_+3A_max_iter_mle">max_iter_MLE</code></td>
<td>
<p>upper limit of MLE iterations (default is 100)</p>
</td></tr>
<tr><td><code id="mmcd_+3A_max_iter_cstep_init">max_iter_cstep_init</code></td>
<td>
<p>upper limit of C-step iterations for initial h-subsets (default is 2)</p>
</td></tr>
<tr><td><code id="mmcd_+3A_max_iter_mle_init">max_iter_MLE_init</code></td>
<td>
<p>upper limit of MLE iterations for initial h-subsets (default is 2)</p>
</td></tr>
<tr><td><code id="mmcd_+3A_adapt_alpha">adapt_alpha</code></td>
<td>
<p>Logical. If TRUE (default) alpha is adapted to take the dimension of the data into account.</p>
</td></tr>
<tr><td><code id="mmcd_+3A_reweight">reweight</code></td>
<td>
<p>Logical. If TRUE (default) the reweighted MMCD estimators are computed.</p>
</td></tr>
<tr><td><code id="mmcd_+3A_scale_consistency">scale_consistency</code></td>
<td>
<p>Character. Either &quot;quant&quot; (default) or &quot;mmd_med&quot;. If &quot;quant&quot;, the consistency factor is chosen to achieve consistency under the matrix normal distribution.
If &quot;mmd_med&quot;, the consistency factor is chosen based on the Mahalanobis distances of the observations.</p>
</td></tr>
<tr><td><code id="mmcd_+3A_outlier_quant">outlier_quant</code></td>
<td>
<p>numeric parameter between 0 and 1. Chi-square quantile used in the reweighting step.</p>
</td></tr>
<tr><td><code id="mmcd_+3A_nthreads">nthreads</code></td>
<td>
<p>Integer. If 1 (default), all computations are carried out sequentially.
If larger then 1, C-steps are carried out in parallel using <code>nthreads</code> threads.
If &lt; 0, all possible threads are used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The MMCD estimators generalize the well-known Minimum Covariance Determinant (MCD)
(Rousseeuw 1985; Rousseeuw and Driessen 1999) to the matrix-variate setting.
It looks for the <code class="reqn">h</code> observations, <code class="reqn">h = \alpha * n</code>, whose covariance matrix has the smallest determinant.
The FastMMCD algorithm is used for computation and is described in detail in (double-blind 2024).
NOTE: The procedure depends on <em>random</em> initial subsets. Currently setting a seed is only possible if <code>nthreads = 1</code>.
</p>


<h3>Value</h3>

<p>A list containing the following:
</p>
<table>
<tr><td><code>mu</code></td>
<td>
<p>Estimated <code class="reqn">p \times q</code> mean matrix.</p>
</td></tr>
<tr><td><code>cov_row</code></td>
<td>
<p>Estimated <code class="reqn">p</code> times <code class="reqn">p</code> rowwise covariance matrix.</p>
</td></tr>
<tr><td><code>cov_col</code></td>
<td>
<p>Estimated <code class="reqn">q</code> times <code class="reqn">q</code> columnwise covariance matrix.</p>
</td></tr>
<tr><td><code>cov_row_inv</code></td>
<td>
<p>Inverse of <code>cov_row</code>.</p>
</td></tr>
<tr><td><code>cov_col_inv</code></td>
<td>
<p>Inverse of <code>cov_col</code>.</p>
</td></tr>
<tr><td><code>md</code></td>
<td>
<p>Squared Mahalanobis distances.</p>
</td></tr>
<tr><td><code>md_raw</code></td>
<td>
<p>Squared Mahalanobis distances based on <em>raw</em> MMCD estimators.</p>
</td></tr>
<tr><td><code>det</code></td>
<td>
<p>Value of objective function (determinant of Kronecker product of rowwise and columnwise covariane).</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The (adjusted) value of alpha used to determine the size of the h-subset.</p>
</td></tr>
<tr><td><code>consistency_factors</code></td>
<td>
<p>Consistency factors for raw and reweighted MMCD estimators.</p>
</td></tr>
<tr><td><code>dets</code></td>
<td>
<p>Objective values for the final h-subsets.</p>
</td></tr>
<tr><td><code>best_i</code></td>
<td>
<p>ID of subset with best objective.</p>
</td></tr>
<tr><td><code>h_subset</code></td>
<td>
<p>Final h-subset of <em>raw</em> MMCD estimators.</p>
</td></tr>
<tr><td><code>h_subset_reweighted</code></td>
<td>
<p>Final h-subset of <em>reweighted</em> MMCD estimators.</p>
</td></tr>
<tr><td><code>iterations</code></td>
<td>
<p>Number of C-steps.</p>
</td></tr>
<tr><td><code>dets_init_first</code></td>
<td>
<p>Objective values for the <code>nsamp</code> initial h-subsets after <code>max_iter_cstep_init</code> C-steps.</p>
</td></tr>
<tr><td><code>subsets_first</code></td>
<td>
<p>Subsets created in subsampling procedure for large <code>n</code>.</p>
</td></tr>
<tr><td><code>dets_init_second</code></td>
<td>
<p>Objective values of the 10 best initial subsets after executing C-steps until convergence.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Rousseeuw P (1985).
&ldquo;Multivariate Estimation With High Breakdown Point.&rdquo;
<em>Mathematical Statistics and Applications Vol. B</em>, 283-297.
<a href="https://doi.org/10.1007/978-94-009-5438-0_20">doi:10.1007/978-94-009-5438-0_20</a>.<br /><br /> Rousseeuw PJ, Driessen KV (1999).
&ldquo;A Fast Algorithm for the Minimum Covariance Determinant Estimator.&rdquo;
<em>Technometrics</em>, <b>41</b>(3), 212-223.
<a href="https://doi.org/10.1080/00401706.1999.10485670">doi:10.1080/00401706.1999.10485670</a>.<br /><br /> double-blind (2024).
&ldquo;Robust covariance estimation and explainable outlier detection for matrix-valued data.&rdquo;
<em>[Manuscript submitted for publication]</em>.
</p>


<h3>See Also</h3>

<p>The <code>mmcd</code> algorithm uses the <code><a href="#topic+cstep">cstep</a></code> and <code><a href="#topic+mmle">mmle</a></code> functions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 1000; p = 2; q = 3
mu = matrix(rep(0, p*q), nrow = p, ncol = q)
cov_row = matrix(c(1,0.5,0.5,1), nrow = p, ncol = p)
cov_col = matrix(c(3,2,1,2,3,2,1,2,3), nrow = q, ncol = q)
X &lt;- rmatnorm(n = n, mu, cov_row, cov_col)
ind &lt;- sample(1:n, 0.3*n)
X[,,ind] &lt;- rmatnorm(n = length(ind), matrix(rep(10, p*q), nrow = p, ncol = q), cov_row, cov_col)
par_mmle &lt;- mmle(X)
par_mmcd &lt;- mmcd(X)
distances_mmle &lt;- mmd(X, par_mmle$mu, par_mmle$cov_row, par_mmle$cov_col)
distances_mmcd &lt;- mmd(X, par_mmcd$mu, par_mmcd$cov_row, par_mmcd$cov_col)
plot(distances_mmle, distances_mmcd)
abline(h = qchisq(0.99, p*q), lty = 2, col = "red")
abline(v = qchisq(0.99, p*q), lty = 2, col = "red")
</code></pre>

<hr>
<h2 id='mmd'>Matrix Mahalanobis distance</h2><span id='topic+mmd'></span>

<h3>Description</h3>

<p>Matrix Mahalanobis distance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mmd(X, mu, cov_row, cov_col, inverted = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmd_+3A_x">X</code></td>
<td>
<p>a 3d array of dimension <code class="reqn">(p,q,n)</code>, containing <code class="reqn">n</code> matrix-variate samples of <code class="reqn">p</code> rows and <code class="reqn">q</code> columns in each slice.</p>
</td></tr>
<tr><td><code id="mmd_+3A_mu">mu</code></td>
<td>
<p>a <code class="reqn">p \times q</code> matrix containing the means.</p>
</td></tr>
<tr><td><code id="mmd_+3A_cov_row">cov_row</code></td>
<td>
<p>a <code class="reqn">p \times p</code> positive-definite symmetric matrix specifying the rowwise covariance matrix</p>
</td></tr>
<tr><td><code id="mmd_+3A_cov_col">cov_col</code></td>
<td>
<p>a <code class="reqn">q \times q</code> positive-definite symmetric matrix specifying the columnwise covariance matrix</p>
</td></tr>
<tr><td><code id="mmd_+3A_inverted">inverted</code></td>
<td>
<p>Logical. FALSE by default.
If TRUE <code>cov_row</code> and <code>cov_col</code> are supposed to contain the inverted rowwise and columnwise covariance matrices, respectively.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Squared Mahalanobis distance(s) of observation(s) in <code>X</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 1000; p = 2; q = 3
mu = matrix(rep(0, p*q), nrow = p, ncol = q)
cov_row = matrix(c(1,0.5,0.5,1), nrow = p, ncol = p)
cov_col = matrix(c(3,2,1,2,3,2,1,2,3), nrow = q, ncol = q)
X &lt;- rmatnorm(n = 1000, mu, cov_row, cov_col)
ind &lt;- sample(1:n, 0.3*n)
X[,,ind] &lt;- rmatnorm(n = length(ind), matrix(rep(10, p*q), nrow = p, ncol = q), cov_row, cov_col)
distances &lt;- mmd(X, mu, cov_row, cov_col)
plot(distances)
abline(h = qchisq(0.99, p*q), lty = 2, col = "red")
</code></pre>

<hr>
<h2 id='mmle'>Maximum Likelihood Estimation for Matrix Normal Distribtuion</h2><span id='topic+mmle'></span>

<h3>Description</h3>

<p><code>mmle</code> computes the Maximum Likelihood Estimators (MLEs) for the matrix normal distribution
using the iterative flip-flop algorithm (Dutilleul 1999).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mmle(X, max_iter = 100L, lambda = 0, silent = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmle_+3A_x">X</code></td>
<td>
<p>a 3d array of dimension <code class="reqn">(p,q,n)</code>, containing <code class="reqn">n</code> matrix-variate samples of <code class="reqn">p</code> rows and <code class="reqn">q</code> columns in each slice.</p>
</td></tr>
<tr><td><code id="mmle_+3A_max_iter">max_iter</code></td>
<td>
<p>upper limit of iterations.</p>
</td></tr>
<tr><td><code id="mmle_+3A_lambda">lambda</code></td>
<td>
<p>a smooting parameter for the rowwise and columnwise covariance matrices.</p>
</td></tr>
<tr><td><code id="mmle_+3A_silent">silent</code></td>
<td>
<p>Logical. If FALSE (default) warnings and errors are printed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following:
</p>
<table>
<tr><td><code>mu</code></td>
<td>
<p>Estimated <code class="reqn">p \times q</code> mean matrix.</p>
</td></tr>
<tr><td><code>cov_row</code></td>
<td>
<p>Estimated <code class="reqn">p</code> times <code class="reqn">p</code> rowwise covariance matrix.</p>
</td></tr>
<tr><td><code>cov_col</code></td>
<td>
<p>Estimated <code class="reqn">q</code> times <code class="reqn">q</code> columnwise covariance matrix.</p>
</td></tr>
<tr><td><code>cov_row_inv</code></td>
<td>
<p>Inverse of <code>cov_row</code>.</p>
</td></tr>
<tr><td><code>cov_col_inv</code></td>
<td>
<p>Inverse of <code>cov_col</code>.</p>
</td></tr>
<tr><td><code>norm</code></td>
<td>
<p>Forbenius norm of squared differences between covariance matrices in final iteration.</p>
</td></tr>
<tr><td><code>iterations</code></td>
<td>
<p>Number of iterations of the mmle procedure.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Dutilleul P (1999).
&ldquo;The mle algorithm for the matrix normal distribution.&rdquo;
<em>Journal of Statistical Computation and Simulation</em>, <b>64</b>(2), 105-123.
<a href="https://doi.org/10.1080/00949659908811970">doi:10.1080/00949659908811970</a>.
</p>


<h3>See Also</h3>

<p>For robust parameter estimation use <code><a href="#topic+mmcd">mmcd</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 1000; p = 2; q = 3
mu = matrix(rep(0, p*q), nrow = p, ncol = q)
cov_row = matrix(c(1,0.5,0.5,1), nrow = p, ncol = p)
cov_col = matrix(c(3,2,1,2,3,2,1,2,3), nrow = q, ncol = q)
X &lt;- rmatnorm(n = 1000, mu, cov_row, cov_col)
par_mmle &lt;- mmle(X)
</code></pre>

<hr>
<h2 id='n_subsets_mmcd'>Number of subsets that are required to obtain at least one clean h-subset in the <code><a href="#topic+mmcd">mmcd</a></code> function with probability <code>prob</code>.</h2><span id='topic+n_subsets_mmcd'></span>

<h3>Description</h3>

<p>Number of subsets that are required to obtain at least one clean h-subset in the <code><a href="#topic+mmcd">mmcd</a></code> function with probability <code>prob</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>n_subsets_mmcd(p, q, prob = 0.99, contamination = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="n_subsets_mmcd_+3A_p">p</code></td>
<td>
<p>number of rows.</p>
</td></tr>
<tr><td><code id="n_subsets_mmcd_+3A_q">q</code></td>
<td>
<p>number of columns.</p>
</td></tr>
<tr><td><code id="n_subsets_mmcd_+3A_prob">prob</code></td>
<td>
<p>probability (default is 0.99).</p>
</td></tr>
<tr><td><code id="n_subsets_mmcd_+3A_contamination">contamination</code></td>
<td>
<p>level of contamination (default is 0.5).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Number of subsets that are required to obtain at least one clean h-subset in the <code><a href="#topic+mmcd">mmcd</a></code> function with probability <code>prob</code>.
</p>

<hr>
<h2 id='rmatnorm'>Simulate from a Matrix Normal Distribution</h2><span id='topic+rmatnorm'></span>

<h3>Description</h3>

<p>Simulate from a Matrix Normal Distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmatnorm(n, mu = NULL, cov_row, cov_col)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmatnorm_+3A_n">n</code></td>
<td>
<p>the number of samples required.</p>
</td></tr>
<tr><td><code id="rmatnorm_+3A_mu">mu</code></td>
<td>
<p>a <code class="reqn">p \times q</code> matrix containing the means.</p>
</td></tr>
<tr><td><code id="rmatnorm_+3A_cov_row">cov_row</code></td>
<td>
<p>a <code class="reqn">p \times p</code> positive-definite symmetric matrix specifying the rowwise covariance matrix</p>
</td></tr>
<tr><td><code id="rmatnorm_+3A_cov_col">cov_col</code></td>
<td>
<p>a <code class="reqn">q \times q</code> positive-definite symmetric matrix specifying the columnwise covariance matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code class="reqn">n = 1</code> a matrix with <code class="reqn">p</code> rows and <code class="reqn">q</code> columns, o
otherwise a 3d array of dimensions <code class="reqn">(p,q,n)</code> with a sample in each slice.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 1000; p = 2; q = 3
mu = matrix(rep(0, p*q), nrow = p, ncol = q)
cov_row = matrix(c(5,2,2,4), nrow = p, ncol = p)
cov_col = matrix(c(3,2,1,2,3,2,1,2,3), nrow = q, ncol = q)
X &lt;- rmatnorm(n = 1000, mu, cov_row, cov_col)
X[,,9] #printing the 9th sample.
</code></pre>

<hr>
<h2 id='weather'>Glacier weather data – Sonnblick observatory</h2><span id='topic+weather'></span>

<h3>Description</h3>

<p>Weather data from Austria's highest weather station, situated in the Austrian Central Alps on the glaciated mountain
&quot;Hoher Sonnblick&quot;, standing 3106 meters above sea level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(weather)
</code></pre>


<h3>Format</h3>

<p>An array of dimension <code class="reqn">(p,q,n)</code>, comprising <code class="reqn">n = 136</code> observations,
each represented by a <code class="reqn">p = 5</code> times <code class="reqn">q = 12</code> dimensional matrix.
Observed parameters are monthly averages of
</p>

<ul>
<li><p>air pressure (AP)
</p>
</li>
<li><p>precipitation (P)
</p>
</li>
<li><p>sunshine hours (SH)
</p>
</li>
<li><p>temperature (T)
</p>
</li>
<li><p>proportion of solid precipitation (SP)
</p>
</li></ul>

<p>from 1891 to 2022.
</p>


<h3>Source</h3>

<p>Datasource: GeoSphere Austria - <a href="https://data.hub.geosphere.at">https://data.hub.geosphere.at</a>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
