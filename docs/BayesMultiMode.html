<!DOCTYPE html><html lang="en"><head><title>Help for package BayesMultiMode</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {BayesMultiMode}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bayes_fit'><p>Bayesian estimation of mixture distributions</p></a></li>
<li><a href='#bayes_mixture'><p>Creating a S3 object of class <code>bayes_mixture</code></p></a></li>
<li><a href='#bayes_mode'><p>Bayesian mode inference</p></a></li>
<li><a href='#bayes_trace'><p>Trace plots</p></a></li>
<li><a href='#ct47'><p>X chromosomal macrosatellite repeats ct47</p></a></li>
<li><a href='#cyclone'><p>Tropical cyclones lifetime maximum intensity</p></a></li>
<li><a href='#d4z4'><p>Autosomal macrosatellite repeats d4z4</p></a></li>
<li><a href='#galaxy'><p>Galaxy series</p></a></li>
<li><a href='#gibbs_SFM'><p>SFM MCMC algorithms to estimate mixtures.</p></a></li>
<li><a href='#mix_mode'><p>Mode estimation</p></a></li>
<li><a href='#mixture'><p>Creating a S3 object of class <code>mixture</code></p></a></li>
<li><a href='#plot.bayes_mixture'><p>Plot method for <code>bayes_mixture</code> objects</p></a></li>
<li><a href='#plot.bayes_mode'><p>Plot method for <code>bayes_mode</code> objects</p></a></li>
<li><a href='#plot.mix_mode'><p>Plot method for <code>mix_mode</code> objects</p></a></li>
<li><a href='#plot.mixture'><p>Plot method for <code>mixture</code> objects</p></a></li>
<li><a href='#print.bayes_mixture'><p>Print method for <code>bayes_mixture</code> objects</p></a></li>
<li><a href='#print.bayes_mode'><p>Print method for <code>bayes_mode</code> objects</p></a></li>
<li><a href='#print.mix_mode'><p>Print method for <code>mix_mode</code> objects</p></a></li>
<li><a href='#print.mixture'><p>Print method for <code>mixture</code> objects</p></a></li>
<li><a href='#summary.bayes_mixture'><p>Summary method for <code>bayes_mixture</code> objects</p>
The summary of MCMC draws is given by the function
<code>summarise_draws</code> from package <span class="pkg">posterior</span>.</a></li>
<li><a href='#summary.bayes_mode'><p>Summary method for <code>bayes_mode</code> objects</p></a></li>
<li><a href='#summary.mix_mode'><p>Summary method for <code>mix_mode</code> objects</p></a></li>
<li><a href='#summary.mixture'><p>Summary method for <code>mixture</code> objects</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Bayesian Mode Inference</td>
</tr>
<tr>
<td>Version:</td>
<td>0.7.3</td>
</tr>
<tr>
<td>Description:</td>
<td>A two-step Bayesian approach for mode inference following 
      Cross, Hoogerheide, Labonne and van Dijk (2024) &lt;<a href="https://doi.org/10.1016%2Fj.econlet.2024.111579">doi:10.1016/j.econlet.2024.111579</a>&gt;).
      First, a mixture distribution is fitted on the data using a sparse finite
      mixture (SFM) Markov chain Monte Carlo (MCMC) algorithm. The number of
      mixture components does not have to be known; the size of the mixture is
      estimated endogenously through the SFM approach. Second, the modes of the
      estimated mixture at each MCMC draw are retrieved using algorithms
      specifically tailored for mode detection. These estimates are then used to
      construct posterior probabilities for the number of modes, their locations
      and uncertainties, providing a powerful tool for mode inference.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>assertthat, bayesplot, dplyr, ggplot2 (&ge; 3.3.4), ggpubr,
gtools, magrittr, MCMCglmm, mvtnorm, posterior, sn, stringr,
tidyr, Rdpack</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/paullabonne/BayesMultiMode">https://github.com/paullabonne/BayesMultiMode</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/paullabonne/BayesMultiMode/issues">https://github.com/paullabonne/BayesMultiMode/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-10-31 11:50:05 UTC; paullabonne</td>
</tr>
<tr>
<td>Author:</td>
<td>Nalan Baştürk [aut],
  Jamie Cross [aut],
  Peter de Knijff [aut],
  Lennart Hoogerheide [aut],
  Paul Labonne [aut, cre],
  Herman van Dijk [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Paul Labonne &lt;labonnepaul@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-10-31 15:30:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='bayes_fit'>Bayesian estimation of mixture distributions</h2><span id='topic+bayes_fit'></span>

<h3>Description</h3>

<p>Estimation of a univariate mixture with unknown number of components using a sparse finite mixture Markov chain Monte Carlo (SFM MCMC) algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bayes_fit(
  data,
  K,
  dist,
  priors = list(),
  nb_iter = 2000,
  burnin = nb_iter/2,
  print = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bayes_fit_+3A_data">data</code></td>
<td>
<p>Vector of observations.</p>
</td></tr>
<tr><td><code id="bayes_fit_+3A_k">K</code></td>
<td>
<p>Maximum number of mixture components.</p>
</td></tr>
<tr><td><code id="bayes_fit_+3A_dist">dist</code></td>
<td>
<p>String indicating the distribution of the mixture components;
currently supports <code>"normal"</code>, <code>"skew_normal"</code>, <code>"poisson"</code> and <code>"shifted_poisson"</code>.</p>
</td></tr>
<tr><td><code id="bayes_fit_+3A_priors">priors</code></td>
<td>
<p>List of priors; default is an empty list which implies the following priors:<br />
<code>a0 = 1</code>,<br /> <code>A0 = 200</code>,<br /> <code>b0 = median(y)</code>,<br /> <code>B0 = (max(y) - min(y))^2</code> (normal),<br />
<code>D_xi = 1</code>,<br /> <code>D_psi =1</code>, (skew normal: <code>B0 = diag(D_xi,D_psi)</code>), <br /> <code>c0 = 2.5</code>,<br />
<code>l0 = 1.1</code> (poisson),<br /> <code>l0 = 5</code> (shifted poisson),<br /> <code>L0 = 1.1/median(y)</code>,<br /> <code>L0 = l0 - 1</code> (shifted poisson),<br />
<code>g0 = 0.5</code>,<br /> <code>G0 = 100*g0/c0/B0</code> (normal),<br />
<code>G0 = g0/(0.5*var(y))</code> (skew normal).</p>
</td></tr>
<tr><td><code id="bayes_fit_+3A_nb_iter">nb_iter</code></td>
<td>
<p>Number of MCMC iterations; default is <code>2000</code>.</p>
</td></tr>
<tr><td><code id="bayes_fit_+3A_burnin">burnin</code></td>
<td>
<p>Number of MCMC iterations used as burnin; default is <code>nb_iter/2</code>.</p>
</td></tr>
<tr><td><code id="bayes_fit_+3A_print">print</code></td>
<td>
<p>Showing MCMC progression ? Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">y_i</code>, <code class="reqn">i=1,\dots,n</code> denote observations.
A general mixture of <code class="reqn">K</code> distributions from the same
parametric family is given by:
</p>
<p style="text-align: center;"><code class="reqn">y_i \sim \sum_{k=1}^{K}\pi_k p(\cdot|\theta_k)</code>
</p>

<p>with <code class="reqn">\sum_{k=1}^{K}\pi_k=1</code> and <code class="reqn">\pi_k\geq 0</code>, <code class="reqn">k=1, ...,K</code>.
<br /><br />
The exact number of components does not have to be known <em>a priori</em>
when using an SFM MCMC approach. Rather, an upper bound is specified for the
number of components and the weights of superfluous components are shrunk
towards zero during estimation. Following Malsiner-Walli et al. (2016)
a symmetric Dirichlet prior is used for the mixture weights:
</p>
<p style="text-align: center;"><code class="reqn">\pi_k \sim \text{Dirichlet}(e_0,\dots,e_0),</code>
</p>

<p>where a Gamma hyperprior is used on the concentration parameter <code class="reqn">e_0</code>:<br /><br />
</p>
<p style="text-align: center;"><code class="reqn">e_0 \sim \text{Gamma}\left(a_0, A_0\right).</code>
</p>

<p><strong>Mixture of Normal distributions</strong>
</p>
<p>Normal components take the form:
</p>
<p style="text-align: center;"><code class="reqn">p(y_i|\mu_k,\sigma_k) = \frac{1}{\sqrt{2 \pi} \
  \sigma_k} \exp\left( - \, \frac{1}{2}            \left(  \frac{y_i -
      \mu_k}{\sigma_k} \right)^2     \right).</code>
</p>

<p>Independent conjugate priors are used for <code class="reqn">\mu_k</code> and <code class="reqn">\sigma^2_k</code>
(see for instance Malsiner-Walli et al. 2016):
</p>
<p style="text-align: center;"><code class="reqn">\mu_k \sim \text{Normal}( \text{b}_0, \text{B}_0),</code>
</p>

<p style="text-align: center;"><code class="reqn">\sigma^{-2}_k \sim \text{Gamma}( \text{c}_0, \text{C}_0),</code>
</p>

<p style="text-align: center;"><code class="reqn">C_0 \sim \text{Gamma}( \text{g}_0, \text{G}_0).</code>
</p>

<p><strong>Mixture of skew-Normal distributions</strong>
</p>
<p>We use the skew-Normal of Azzalini (1985) which takes the form:
</p>
<p style="text-align: center;"><code class="reqn">p(y_i| \xi_k,\omega_k,\alpha_k) = \frac{1}{\omega_k\sqrt{2\pi}} \ \exp\left( - \,
\frac{1}{2}            \left(  \frac{y_i - \xi_k}{\omega_k} \right)^2\right) \
\left(1 + \text{erf}\left( \alpha_k\left(\frac{y_i - \xi_k}{\omega_k\sqrt{2}}\right)\right)\right),</code>
</p>

<p>where <code class="reqn">\xi_k</code> is a location parameter, <code class="reqn">\omega_k</code> a scale parameter and <code class="reqn">\alpha_k</code>
the shape parameter introducing skewness. For Bayesian estimation, we adopt the approach of
Frühwirth-Schnatter and Pyne (2010) and use the following reparameterised random-effect model:
</p>
<p style="text-align: center;"><code class="reqn">z_i \sim TN_{[0,\infty)}(0, 1),</code>
</p>

<p style="text-align: center;"><code class="reqn">y_i|(S_i = k) = \xi_k + \psi_k z_i + \epsilon_i, \quad \epsilon_i \sim N(0, \sigma^2_k),</code>
</p>

<p>where the parameters of the skew-Normal are recovered with
</p>
<p style="text-align: center;"><code class="reqn">\omega_k = \frac{\psi_k}{\sigma_k}, \qquad \omega^2_k = \sigma^2_k + \psi^2_k.</code>
</p>

<p>By defining a regressor <code class="reqn">x_i = (1, z_i)'</code>, the skew-Normal mixture can be seen as
random effect model and sampled using standard techniques. Thus we use priors similar to
the Normal mixture model:
</p>
<p style="text-align: center;"><code class="reqn">(\xi_k, \psi_k)' \sim \text{Normal}(\text{b}_0, \text{B}_0),</code>
</p>

<p style="text-align: center;"><code class="reqn">\sigma^{-2}_k \sim \text{Gamma}(\text{c}_0, \text{C}_0),</code>
</p>

<p style="text-align: center;"><code class="reqn">\text{C}_0 \sim \text{Gamma}( \text{g}_0, \text{G}_0).</code>
</p>

<p>We set </p>
<p style="text-align: center;"><code class="reqn">\text{b}_0 = (\text{median}(y), 0)'</code>
</p>
<p> and </p>
<p style="text-align: center;"><code class="reqn">\text{B}_0 = \text{diag}(\text{D}\_\text{xi}, \text{D}\_\text{psi})</code>
</p>
<p> with D_xi = D_psi = 1.
</p>
<p><strong>Mixture of Poisson distributions</strong>
</p>
<p>Poisson components take the form:
</p>
<p style="text-align: center;"><code class="reqn">p(y_i|\lambda_k) = \frac{1}{y_i!} \, \lambda^{y_i}_k \,\exp(-\lambda_k).</code>
</p>

<p>The prior for <code class="reqn">\lambda_k</code> follows from Viallefont et al. (2002):
</p>
<p style="text-align: center;"><code class="reqn">\lambda_k \sim \text{Gamma}(\text{l}_0,\text{L}_0).</code>
</p>

<p><strong>Mixture of shifted-Poisson distributions</strong>
</p>
<p>Shifted-Poisson components take the form
</p>
<p style="text-align: center;"><code class="reqn">p(y_i |\lambda_k, \kappa_k) = \frac{1}{(y_i - \kappa_k)!} \,
\lambda^{(y_i - \kappa_k)!}_k \,\exp(-\lambda_k)</code>
</p>

<p>where <code class="reqn">\kappa_k</code> is a location or shift parameter with uniform prior, see Cross et al. (2024).
</p>


<h3>Value</h3>

<p>A list of class <code>bayes_mixture</code> containing:
</p>
<table role = "presentation">
<tr><td><code>data</code></td>
<td>
<p>Same as argument.</p>
</td></tr>
<tr><td><code>mcmc</code></td>
<td>
<p>Matrix of MCMC draws where the rows corresponding to burnin have been discarded;</p>
</td></tr>
<tr><td><code>mcmc_all</code></td>
<td>
<p>Matrix of MCMC draws.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>Log likelihood at each MCMC draw.</p>
</td></tr>
<tr><td><code>K</code></td>
<td>
<p>Number of components.</p>
</td></tr>
<tr><td><code>dist</code></td>
<td>
<p>Same as argument.</p>
</td></tr>
<tr><td><code>pdf_func</code></td>
<td>
<p>The pdf/pmf of the mixture components.</p>
</td></tr>
<tr><td><code>dist_type</code></td>
<td>
<p>Type of the distribution, i.e. continuous or discrete.</p>
</td></tr>
<tr><td><code>pars_names</code></td>
<td>
<p>Names of the mixture components' parameters.</p>
</td></tr>
<tr><td><code>loc</code></td>
<td>
<p>Name of the location parameter of the mixture components.</p>
</td></tr>
<tr><td><code>nb_var</code></td>
<td>
<p>Number of variables/parameters in the mixture distribution.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Azzalini A (1985).
&ldquo;A Class of Distributions Which Includes the Normal Ones.&rdquo;
<em>Scandinavian Journal of Statistics</em>, <b>12</b>(2), 171&ndash;178.
ISSN 0303-6898, Publisher: [Board of the Foundation of the Scandinavian Journal of Statistics, Wiley].<br /><br /> Cross JL, Hoogerheide L, Labonne P, van Dijk HK (2024).
&ldquo;Bayesian mode inference for discrete distributions in economics and finance.&rdquo;
<em>Economics Letters</em>, <b>235</b>, 111579.
ISSN 0165-1765, <a href="https://doi.org/10.1016/j.econlet.2024.111579">doi:10.1016/j.econlet.2024.111579</a>.<br /><br /> Frühwirth-Schnatter S, Pyne S (2010).
&ldquo;Bayesian inference for finite mixtures of univariate and multivariate skew-normal and skew-t distributions.&rdquo;
<em>Biostatistics</em>, <b>11</b>(2), 317&ndash;336.
ISSN 1465-4644, <a href="https://doi.org/10.1093/biostatistics/kxp062">doi:10.1093/biostatistics/kxp062</a>.<br /><br /> Malsiner-Walli G, Fruhwirth-Schnatter S, Grun B (2016).
&ldquo;Model-based clustering based on sparse finite Gaussian mixtures.&rdquo;
<em>Statistics and Computing</em>, <b>26</b>(1), 303&ndash;324.
ISSN 1573-1375, <a href="https://doi.org/10.1007/s11222-014-9500-2">doi:10.1007/s11222-014-9500-2</a>.<br /><br /> Viallefont V, Richardson S, Peter
J (2002).
&ldquo;Bayesian analysis of Poisson mixtures.&rdquo;
<em>Journal of Nonparametric Statistics</em>, <b>14</b>(1-2), 181&ndash;202.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example with galaxy data ================================================
set.seed(123)

# retrieve galaxy data
y &lt;- galaxy

# estimation
bayesmix &lt;- bayes_fit(
  data = y,
  K = 5, # not many to run the example rapidly
  dist = "normal",
  nb_iter = 500, # not many to run the example rapidly
  burnin = 100
)

# plot estimated mixture
# plot(bayesmix, max_size = 200)

# Changing priors ================================================
set.seed(123)

# retrieve galaxy data
y &lt;- galaxy

# estimation
K &lt;- 5
bayesmix &lt;- bayes_fit(
  data = y,
  K = K, # not many to run the example rapidly
  dist = "normal",
  priors = list(
    a0 = 10,
    A0 = 10 * K
  ),
  nb_iter = 500, # not many to run the example rapidly
  burnin = 100
)

# plot estimated mixture
# plot(bayesmix, max_size = 200)

# Example with DNA data =====================================================

set.seed(123)

# retrieve DNA data
y &lt;- d4z4

# estimation
bayesmix &lt;- bayes_fit(
  data = y,
  K = 5, # not many to run the example rapidly
  dist = "shifted_poisson",
  nb_iter = 500, # not many to run the example rapidly
  burnin = 100
)

# plot estimated mixture
# plot(bayesmix, max_size = 200)


</code></pre>

<hr>
<h2 id='bayes_mixture'>Creating a S3 object of class <code>bayes_mixture</code></h2><span id='topic+bayes_mixture'></span>

<h3>Description</h3>

<p>Creates an object of class <code>bayes_mixture</code> which can subsequently be used as argument in <code><a href="#topic+bayes_mode">bayes_mode()</a></code>.
This function is useful for users who want to use the mode inference capabilities of <code>BayesMultiMode</code> with mixture
estimated using external software.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bayes_mixture(
  mcmc,
  data,
  burnin = 0,
  dist = NA_character_,
  pdf_func = NULL,
  dist_type = NA_character_,
  loglik = NULL,
  vars_to_keep = NA_character_,
  vars_to_rename = NA_character_,
  loc = NA_character_
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bayes_mixture_+3A_mcmc">mcmc</code></td>
<td>
<p>A matrix of MCMC draws with one column per variable, e.g. eta1, eta2, ..., mu1, mu2, etc...</p>
</td></tr>
<tr><td><code id="bayes_mixture_+3A_data">data</code></td>
<td>
<p>Vector of observation used for estimating the model.</p>
</td></tr>
<tr><td><code id="bayes_mixture_+3A_burnin">burnin</code></td>
<td>
<p>Number of draws to discard as burnin; default is <code>0</code>.</p>
</td></tr>
<tr><td><code id="bayes_mixture_+3A_dist">dist</code></td>
<td>
<p>Distribution family of the mixture components supported by
the package (i.e. <code>"normal"</code>, <code>"student"</code>, <code>"skew_normal"</code> or <code>"shifted_poisson"</code>).
If left unspecified, <code>pdf_func</code> is required.</p>
</td></tr>
<tr><td><code id="bayes_mixture_+3A_pdf_func">pdf_func</code></td>
<td>
<p>(function) Pdf or pmf of the mixture components;
this input is used only if <code>dist</code> is left unspecified.
pdf_func should have two arguments : (i) the observation where the pdf is evaluated;
(ii) a named vector representing the function parameters. For instance a normal pdf would take the form:
<code>pdf_func &lt;- function(x, pars) dnorm(x, pars['mu'], pars['sigma'])</code>.
The names of <code>pars</code> should correspond to variables in <code>mcmc</code>, e.g. <code>"mu1"</code>, <code>"mu2"</code> etc...</p>
</td></tr>
<tr><td><code id="bayes_mixture_+3A_dist_type">dist_type</code></td>
<td>
<p>Either <code>"continuous"</code> or <code>"discrete"</code>.</p>
</td></tr>
<tr><td><code id="bayes_mixture_+3A_loglik">loglik</code></td>
<td>
<p>Vector showing the log likelihood at each MCMC draw.</p>
</td></tr>
<tr><td><code id="bayes_mixture_+3A_vars_to_keep">vars_to_keep</code></td>
<td>
<p>(optional) Character vector containing the names
of the variables to keep in <code>mcmc</code>, e.g. <code>c("eta", "mu", "sigma")</code>.</p>
</td></tr>
<tr><td><code id="bayes_mixture_+3A_vars_to_rename">vars_to_rename</code></td>
<td>
<p>(optional) Use for renaming variables/parameters in <code>mcmc</code>.
A named character vector where the names are the new variable names
and the elements the variables in <code>mcmc</code>, e.g. c(&quot;new_name&quot; = &quot;old_name&quot;).</p>
</td></tr>
<tr><td><code id="bayes_mixture_+3A_loc">loc</code></td>
<td>
<p>(for continuous mixtures other than Normal mixtures) String indicating the location parameter
of the distribution; the latter is used to initialise the MEM algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>bayes_mixture</code> containing:
</p>
<table role = "presentation">
<tr><td><code>data</code></td>
<td>
<p>Same as argument.</p>
</td></tr>
<tr><td><code>mcmc</code></td>
<td>
<p>Matrix of MCMC draws where the rows corresponding to burnin have been discarded;</p>
</td></tr>
<tr><td><code>mcmc_all</code></td>
<td>
<p>Matrix of MCMC draws.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>Log likelihood at each MCMC draw.</p>
</td></tr>
<tr><td><code>K</code></td>
<td>
<p>Number of components.</p>
</td></tr>
<tr><td><code>dist</code></td>
<td>
<p>Same as argument.</p>
</td></tr>
<tr><td><code>pdf_func</code></td>
<td>
<p>The pdf/pmf of the mixture components.</p>
</td></tr>
<tr><td><code>dist_type</code></td>
<td>
<p>Type of the distribution, i.e. continuous or discrete.</p>
</td></tr>
<tr><td><code>pars_names</code></td>
<td>
<p>Names of the mixture components' parameters.</p>
</td></tr>
<tr><td><code>loc</code></td>
<td>
<p>Name of the location parameter of the mixture components.</p>
</td></tr>
<tr><td><code>nb_var</code></td>
<td>
<p>Number of parameters in the mixture distribution.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
# Example with a Student t ================================================

# Constructing synthetic mcmc output
mu &lt;- c(0.5, 6)
mu_mat &lt;- matrix(rep(mu, 100) + rnorm(200, 0, 0.1),
  ncol = 2, byrow = TRUE
)

omega &lt;- c(1, 2)
sigma_mat &lt;- matrix(rep(omega, 100) + rnorm(200, 0, 0.1),
  ncol = 2, byrow = TRUE
)

nu &lt;- c(5, 5)
nu_mat &lt;- matrix(rep(nu, 100) + rnorm(200, 0, 0.1),
  ncol = 2, byrow = TRUE
)

eta &lt;- c(0.8, 0.2)
eta_mat &lt;- matrix(rep(eta[1], 100) + rnorm(100, 0, 0.05),
  ncol = 1
)
eta_mat &lt;- cbind(eta_mat, 1 - eta_mat)

xi_mat &lt;- matrix(0, 100, 2)

fit &lt;- cbind(eta_mat, mu_mat, sigma_mat, nu_mat, xi_mat)
colnames(fit) &lt;- c(
  "eta1", "eta2", "mu1", "mu2",
  "omega1", "omega2", "nu1", "nu2", "xi1", "xi2"
)

# sampling observations
data &lt;- c(
  sn::rst(eta[1] * 1000, mu[1], omega[1], nu = nu[1]),
  sn::rst(eta[2] * 1000, mu[2], omega[2], nu = nu[2])
)

pdf_func &lt;- function(x, pars) {
  sn::dst(x, pars["mu"], pars["sigma"], pars["xi"], pars["nu"])
}

dist_type &lt;- "continuous"

BM &lt;- bayes_mixture(fit, data,
  burnin = 50,
  pdf_func = pdf_func, dist_type = dist_type,
  vars_to_rename = c("sigma" = "omega"), loc = "xi"
)
# plot(BM)
</code></pre>

<hr>
<h2 id='bayes_mode'>Bayesian mode inference</h2><span id='topic+bayes_mode'></span>

<h3>Description</h3>

<p>Bayesian inference on the modes in a univariate mixture estimated with MCMC methods, see Cross et al. (2024).
Provides posterior probabilities of the number of modes and their locations.
Under the hood it calls the function <code><a href="#topic+mix_mode">mix_mode()</a></code> to find the modes in each MCMC draw.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bayes_mode(
  BayesMix,
  rd = 1,
  tol_mixp = 0,
  tol_x = sd(BayesMix$data)/10,
  tol_conv = 1e-08,
  inside_range = TRUE,
  range = c(min(BayesMix$data), max(BayesMix$data)),
  conditional_nb_modes = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bayes_mode_+3A_bayesmix">BayesMix</code></td>
<td>
<p>An object of class <code>bayes_mixture</code> generated with either <code><a href="#topic+bayes_fit">bayes_fit()</a></code> or <code><a href="#topic+bayes_mixture">bayes_mixture()</a></code>.</p>
</td></tr>
<tr><td><code id="bayes_mode_+3A_rd">rd</code></td>
<td>
<p>(for continuous mixtures) Integer indicating the number of decimal places when rounding the distribution's support.
It is necessary to compute posterior probabilities of mode locations.</p>
</td></tr>
<tr><td><code id="bayes_mode_+3A_tol_mixp">tol_mixp</code></td>
<td>
<p>Components with a mixture proportion below <code>tol_mixp</code> are discarded when estimating modes;
note that this does not apply to the biggest component so that it is not possible to discard all components;
should be between <code>0</code> and <code>1</code>; default is <code>0</code>.</p>
</td></tr>
<tr><td><code id="bayes_mode_+3A_tol_x">tol_x</code></td>
<td>
<p>(for continuous mixtures) Tolerance parameter for distance in-between modes; default is <code>sd(data)/10</code>
where data is the vector of observations from <code>BayesMix</code>.
If two modes are closer than <code>tol_x</code>, only the first estimated mode is kept.</p>
</td></tr>
<tr><td><code id="bayes_mode_+3A_tol_conv">tol_conv</code></td>
<td>
<p>(for continuous mixtures) Tolerance parameter for convergence of the algorithm; default is <code>1e-8</code>.</p>
</td></tr>
<tr><td><code id="bayes_mode_+3A_inside_range">inside_range</code></td>
<td>
<p>Should modes outside of <code>range</code> be discarded? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="bayes_mode_+3A_range">range</code></td>
<td>
<p>limits of the support where modes are saved (if <code>inside_range</code> is <code>TRUE</code>);</p>
</td></tr>
<tr><td><code id="bayes_mode_+3A_conditional_nb_modes">conditional_nb_modes</code></td>
<td>
<p>Mcmc draws are filtered to include those with only <code>conditional_nb_modes</code> number of modes;
default is <code>c(min(BayesMix$data), max(BayesMix$data))</code>.
This sometimes occurs with very small components when K is large.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Each draw from the MCMC output after burnin, <code class="reqn">\theta^{(d)}, \quad d = 1,...,D</code>, leads to a posterior predictive probability
density/mass function:
</p>
<p style="text-align: center;"><code class="reqn">p(y | \theta^{(d)}) =\sum_{k=1}^{K} \pi_k^{(d)} p(y | \theta_k^{(d)}).</code>
</p>

<p>Using this function, the mode in draw <code class="reqn">d</code> <code class="reqn">y_{m}^{(d)}</code>, <code class="reqn">m = 1,..., M^{(d)}</code>,
where <code class="reqn">M^{(d)}</code> is the number of modes, are estimated using the algorithm mentioned
in the description above.
</p>
<p>After running this procedure across all retained posterior draws,
we compute the posterior probability for the number of modes being <code class="reqn">M</code> as:
</p>
<p style="text-align: center;"><code class="reqn">P(\#\text{modes}=M)=\frac{1}{D}\sum_{d=1}^{D}1(M^{(d)} = M).</code>
</p>

<p>Similarly, posterior probabilities for locations of the modes are given by:
</p>
<p style="text-align: center;"><code class="reqn">P(y=\text{mode})=\frac{1}{D}\sum_{d=1}^{D} \sum_{m=1}^{M^{(d)}} 1(y = y_m^{(d)}),</code>
</p>

<p>for each location <code class="reqn">y</code> in the range <code class="reqn">[\min(y),\max(y)]</code>. Obviously,
continuous data are not defined on a discrete support;
it is therefore necessary to choose a rounding decimal to discretize their support (with the <code>rd</code> argument).
</p>


<h3>Value</h3>

<p>A list of class <code>bayes_mode</code> containing:
</p>
<table role = "presentation">
<tr><td><code>data</code></td>
<td>
<p>From <code>BayesMix</code>.</p>
</td></tr>
<tr><td><code>dist</code></td>
<td>
<p>From <code>BayesMix</code>.</p>
</td></tr>
<tr><td><code>dist_type</code></td>
<td>
<p>From <code>BayesMix</code>.</p>
</td></tr>
<tr><td><code>pars_names</code></td>
<td>
<p>From <code>BayesMix</code>.</p>
</td></tr>
<tr><td><code>modes</code></td>
<td>
<p>Matrix with a row for each draw and columns showing modes.</p>
</td></tr>
<tr><td><code>p1</code></td>
<td>
<p>Posterior probability of unimodality.</p>
</td></tr>
<tr><td><code>p_nb_modes</code></td>
<td>
<p>Matrix showing posterior probabilities for the number of modes.</p>
</td></tr>
<tr><td><code>p_mode_loc</code></td>
<td>
<p>Matrix showing posterior probabilities for mode locations.</p>
</td></tr>
<tr><td><code>mix_density</code></td>
<td>
<p>Mixture density at all mode locations in each draw.</p>
</td></tr>
<tr><td><code>algo</code></td>
<td>
<p>Algorithm used for mode estimation.</p>
</td></tr>
<tr><td><code>range</code></td>
<td>
<p>Range outside which modes are discarded if <code>inside_range</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code>conditional_nb_modes</code></td>
<td>
<p>From <code>BayesMix</code>.</p>
</td></tr>
<tr><td><code>BayesMix</code></td>
<td>
<p><code>BayesMix</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Cross JL, Hoogerheide L, Labonne P, van Dijk HK (2024).
&ldquo;Bayesian mode inference for discrete distributions in economics and finance.&rdquo;
<em>Economics Letters</em>, <b>235</b>, 111579.
ISSN 0165-1765, <a href="https://doi.org/10.1016/j.econlet.2024.111579">doi:10.1016/j.econlet.2024.111579</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example with galaxy data ================================================
set.seed(123)

# retrieve galaxy data
y &lt;- galaxy

# estimation
bayesmix &lt;- bayes_fit(
  data = y,
  K = 5, # not many to run the example rapidly
  dist = "normal",
  nb_iter = 500, # not many to run the example rapidly
  burnin = 100
)

# mode estimation
BayesMode &lt;- bayes_mode(bayesmix)

# plot
# plot(BayesMode, max_size = 200)

# summary
# summary(BayesMode)

# Example with DNA data ================================================
set.seed(123)

# retrieve DNA data
y &lt;- d4z4

# estimation
bayesmix &lt;- bayes_fit(
  data = y,
  K = 5, # not many to run the example rapidly
  dist = "shifted_poisson",
  nb_iter = 500, # not many to run the example rapidly
  burnin = 100
)

# mode estimation
BayesMode &lt;- bayes_mode(bayesmix)

# plot
# plot(BayesMode, max_size = 200)

# summary
# summary(BayesMode)

# Example with a Student t ================================================
mu &lt;- c(0.5, 6)
sigma &lt;- c(1, 2)
nu &lt;- c(5, 5)
p &lt;- c(0.8, 0.2) #'
data &lt;- c(
  sn::rst(p[1] * 1000, mu[1], sigma[1], nu = nu[1]),
  sn::rst(p[2] * 1000, mu[2], sigma[2], nu = nu[2])
)

fit &lt;- c(eta = p, mu = mu, sigma = sigma, nu = nu, xi = c(0, 0))
fit &lt;- rbind(fit, fit)

pdf_func &lt;- function(x, pars) {
  sn::dst(x, pars["mu"], pars["sigma"], pars["xi"], pars["nu"])
}

dist_type &lt;- "continuous"

bayesmix &lt;- bayes_mixture(fit, data,
  burnin = 1,
  pdf_func = pdf_func, dist_type = dist_type, loc = "mu"
)

BayesMode &lt;- bayes_mode(bayesmix)

# plot
# plot(BayesMode, max_size = 200)

# summary
# summary(BayesMode)

</code></pre>

<hr>
<h2 id='bayes_trace'>Trace plots</h2><span id='topic+bayes_trace'></span>

<h3>Description</h3>

<p>This is wrapper around the <code><a href="bayesplot.html#topic+MCMC-traces">bayesplot::mcmc_trace()</a></code> function from package <code>bayesplot</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bayes_trace(BayesMix, mcmc_vars = NULL, with_burnin = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bayes_trace_+3A_bayesmix">BayesMix</code></td>
<td>
<p>An object of class <code>bayes_mixture</code>.</p>
</td></tr>
<tr><td><code id="bayes_trace_+3A_mcmc_vars">mcmc_vars</code></td>
<td>
<p>Variables to plot; default is all the variable in the MCMC output.</p>
</td></tr>
<tr><td><code id="bayes_trace_+3A_with_burnin">with_burnin</code></td>
<td>
<p>Plot all draws ?</p>
</td></tr>
<tr><td><code id="bayes_trace_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to function <code><a href="bayesplot.html#topic+MCMC-traces">bayesplot::mcmc_trace()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A trace plot.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example with galaxy data ================================================
set.seed(123)

# retrieve galaxy data
y &lt;- galaxy

# estimation
bayesmix &lt;- bayes_fit(
  data = y,
  K = 5, # not many to run the example rapidly
  dist = "normal",
  nb_iter = 500, # not many to run the example rapidly
  burnin = 100
)

# trace plot
# bayes_trace(bayesmix)

</code></pre>

<hr>
<h2 id='ct47'>X chromosomal macrosatellite repeats ct47</h2><span id='topic+ct47'></span>

<h3>Description</h3>

<p>Repeat units that encode for a cancer testis antigen.<br />
Locus (hg18): Xq24 <br />
Unit (kb): 4.8 <br />
Restriction enzyme: EcoRI <br />
Encoded product : cancer testis antigen 47
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ct47
</code></pre>


<h3>Format</h3>

<p>A vector of counts with 410 elements.
</p>


<h3>References</h3>

<p>Schaap M, Lemmers RJ, Maassen R, van der Vliet PJ, Hoogerheide LF, van Dijk HK, Basturk N, de Knijff P, van der Maarel SM (2013).
&ldquo;Genome-wide analysis of macrosatellite repeat copy number variation in worldwide populations: evidence for differences and commonalities in size distributions and size restrictions.&rdquo;
<em>BMC Genomics</em>, <b>14</b>(1), 143.
ISSN 1471-2164, <a href="https://doi.org/10.1186/1471-2164-14-143">doi:10.1186/1471-2164-14-143</a>.
</p>

<hr>
<h2 id='cyclone'>Tropical cyclones lifetime maximum intensity</h2><span id='topic+cyclone'></span>

<h3>Description</h3>

<p>Dataset constructed using the International Best Track Archive for Climate Stewardship (IBTrACS).
The distribution of tropical cyclones lifetime maximum intensity across the globe is known
to be bimodal which has important implications for climate modelling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cyclone
</code></pre>


<h3>Format</h3>

<p>A dataset with three columns showing the identification of the cyclone, its year of occurrence and its lifetime maximum intensity (LMI).
LMI is calculated as the maximum wind speed for each cyclone with unit ks.
</p>


<h3>Source</h3>

<p>https://www.ncei.noaa.gov/products/international-best-track-archive
</p>


<h3>References</h3>

<p>Knapp KR, Kruk MC, Levinson DH, Diamond HJ, Neumann CJ (2010).
&ldquo;The International Best Track Archive for Climate Stewardship (IBTrACS): Unifying Tropical Cyclone Data.&rdquo;
<em>Bulletin of the American Meteorological Society</em>, <b>91</b>(3), 363&ndash;376.
ISSN 0003-0007, 1520-0477, <a href="https://doi.org/10.1175/2009BAMS2755.1">doi:10.1175/2009BAMS2755.1</a>, Publisher: American Meteorological Society Section: Bulletin of the American Meteorological Society.<br /><br />
Knapp KR, Diamond HJ, J.P. K, Kruk MC, Schreck CJ (2018).
&ldquo;International Best Track Archive for Climate Stewardship (IBTrACS) Project, Version 4.&rdquo;
<em>NOAA National Centers for Environmental Information</em>.
<a href="https://doi.org/10.1175/2009BAMS2755.1">doi:10.1175/2009BAMS2755.1</a>.
</p>

<hr>
<h2 id='d4z4'>Autosomal macrosatellite repeats d4z4</h2><span id='topic+d4z4'></span>

<h3>Description</h3>

<p>Macrosatellite repeats D4Z4 in the subtelomere of chromosome 4q.<br />
Locus (hg18): 4q35.2 <br />
Unit (kb): 3.3 <br />
Restriction enzyme: EcoRI + HindIII/EcoRI + BlnI/XapI <br />
Encoded product : DUX4
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d4z4
</code></pre>


<h3>Format</h3>

<p>A vector of counts with 410 elements.
</p>


<h3>References</h3>

<p>Schaap M, Lemmers RJ, Maassen R, van der Vliet PJ, Hoogerheide LF, van Dijk HK, Basturk N, de Knijff P, van der Maarel SM (2013).
&ldquo;Genome-wide analysis of macrosatellite repeat copy number variation in worldwide populations: evidence for differences and commonalities in size distributions and size restrictions.&rdquo;
<em>BMC Genomics</em>, <b>14</b>(1), 143.
ISSN 1471-2164, <a href="https://doi.org/10.1186/1471-2164-14-143">doi:10.1186/1471-2164-14-143</a>.
</p>

<hr>
<h2 id='galaxy'>Galaxy series</h2><span id='topic+galaxy'></span>

<h3>Description</h3>

<p>Velocity at which 82 galaxies in the Corona Borealis region are moving away from our galaxy, scaled by 1000.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>galaxy
</code></pre>


<h3>Format</h3>

<p>An object of class <code>numeric</code> of length 82.
</p>


<h3>Source</h3>

<p>https://people.maths.bris.ac.uk/~mapjg/mixdata
</p>


<h3>References</h3>

<p>Richardson S, Green PJ (1997).
&ldquo;On Bayesian Analysis of Mixtures with an Unknown Number of Components.&rdquo;
<em>Journal of the Royal Statistical Society. Series B (Methodological)</em>, <b>59</b>(4), pp. 731&ndash;792.
ISSN 00359246.
</p>

<hr>
<h2 id='gibbs_SFM'>SFM MCMC algorithms to estimate mixtures.</h2><span id='topic+gibbs_SFM'></span>

<h3>Description</h3>

<p>SFM MCMC algorithms to estimate mixtures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gibbs_SFM(y, K, nb_iter, priors = list(), print = TRUE, dist)
</code></pre>

<hr>
<h2 id='mix_mode'>Mode estimation</h2><span id='topic+mix_mode'></span>

<h3>Description</h3>

<p>Mode estimation in univariate mixture distributions.
The fixed-point algorithm of Carreira-Perpinan (2000) is used for Gaussian mixtures.
The Modal EM algorithm of Li et al. (2007) is used for other continuous mixtures.
A basic algorithm is used for discrete mixtures, see Cross et al. (2024).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mix_mode(
  mixture,
  tol_mixp = 0,
  tol_x = 1e-06,
  tol_conv = 1e-08,
  type = "all",
  inside_range = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mix_mode_+3A_mixture">mixture</code></td>
<td>
<p>An object of class <code>mixture</code> generated with <code><a href="#topic+mixture">mixture()</a></code>.</p>
</td></tr>
<tr><td><code id="mix_mode_+3A_tol_mixp">tol_mixp</code></td>
<td>
<p>Components with a mixture proportion below <code>tol_mixp</code> are discarded when estimating modes;
note that this does not apply to the biggest component so that it is not possible to discard all components;
should be between <code>0</code> and <code>1</code>; default is <code>0</code>.</p>
</td></tr>
<tr><td><code id="mix_mode_+3A_tol_x">tol_x</code></td>
<td>
<p>(for continuous mixtures) Tolerance parameter for distance in-between modes; default is <code>1e-6</code>; if two modes are closer than <code>tol_x</code> the first estimated mode is kept.</p>
</td></tr>
<tr><td><code id="mix_mode_+3A_tol_conv">tol_conv</code></td>
<td>
<p>(for continuous mixtures) Tolerance parameter for convergence of the algorithm; default is <code>1e-8</code>.</p>
</td></tr>
<tr><td><code id="mix_mode_+3A_type">type</code></td>
<td>
<p>(for discrete mixtures) Type of modes, either <code>"unique"</code> or <code>"all"</code> (the latter includes flat modes); default is <code>"all"</code>.</p>
</td></tr>
<tr><td><code id="mix_mode_+3A_inside_range">inside_range</code></td>
<td>
<p>Should modes outside of <code>mixture$range</code> be discarded? Default is <code>TRUE</code>.
This sometimes occurs with very small components when K is large.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function finds modes in a univariate mixture defined as:
</p>
<p style="text-align: center;"><code class="reqn">p(.) = \sum_{k=1}^{K}\pi_k p_k(.),</code>
</p>

<p>where <code class="reqn">p_k</code> is a density or probability mass/density function.
</p>
<p><strong>Fixed-point algorithm</strong>
Following Carreira-Perpinan (2000), a mode <code class="reqn">x</code> is found by iterating the two steps:
</p>
<p style="text-align: center;"><code class="reqn">(i) \quad p(k|x^{(n)}) = \frac{\pi_k p_k(x^{(n)})}{p(x^{(n)})},</code>
</p>

<p style="text-align: center;"><code class="reqn">(ii) \quad x^{(n+1)} = f(x^{(n)}),</code>
</p>

<p>with
</p>
<p style="text-align: center;"><code class="reqn">f(x) = (\sum_k p(k|x) \sigma_k)^{-1}\sum_k p(k|x) \sigma_k \mu_k,</code>
</p>

<p>until convergence, that is, until <code class="reqn">abs(x^{(n+1)}-x^{(n)})&lt; \text{tol}_\text{conv}</code>,
where <code class="reqn">\text{tol}_\text{conv}</code> is an argument with default value <code class="reqn">1e-8</code>.
Following Carreira-perpinan (2000), the algorithm is started at each component location.
Separately, it is necessary to identify identical modes which diverge only up to
a small value; this tolerance value can be controlled with the argument
<code>tol_x</code>.
</p>
<p><strong>MEM algorithm</strong>
Following Li et al. (2007), a mode <code class="reqn">x</code> is found by iterating the two steps:
</p>
<p style="text-align: center;"><code class="reqn">(i) \quad p(k|x^{(n)}) = \frac{\pi_k p_k(x^{(n)})}{p(x^{(n)})},</code>
</p>

<p style="text-align: center;"><code class="reqn">(ii) \quad x^{(n+1)} = \text{argmax}_x  \sum_k p(k|x) \text{log} p_k(x^{(n)}),</code>
</p>

<p>until convergence, that is, until <code class="reqn">abs(x^{(n+1)}-x^{(n)})&lt; \text{tol}_\text{conv}</code>,
where <code class="reqn">\text{tol}_\text{conv}</code> is an argument with default value <code class="reqn">1e-8</code>.
The algorithm is started at each component location.
Separately, it is necessary to identify identical modes which diverge only up to
a small value. Modes which are closer then <code>tol_x</code> are merged.
</p>
<p><strong>Discrete method</strong>
By definition, modes must satisfy either:
</p>
<p style="text-align: center;"><code class="reqn">p(y_{m}-1) &lt; p(y_{m}) &gt; p(y_{m}+1);</code>
</p>

<p style="text-align: center;"><code class="reqn">p(y_{m}-1) &lt; p(y_{m}) = p(y_{m}+1) = \ldots = p(y_{m}+l-1) &gt; p(y_{m}+l).</code>
</p>

<p>The algorithm evaluate each location point with these two conditions.
</p>


<h3>Value</h3>

<p>A list of class <code>mix_mode</code> containing:
</p>
<table role = "presentation">
<tr><td><code>mode_estimates</code></td>
<td>
<p>estimates of the mixture modes.</p>
</td></tr>
<tr><td><code>algo</code></td>
<td>
<p>algorithm used for mode estimation.</p>
</td></tr>
<tr><td><code>dist</code></td>
<td>
<p>from <code>mixture</code>.</p>
</td></tr>
<tr><td><code>dist_type</code></td>
<td>
<p>type of mixture distribution, i.e. continuous or discrete.</p>
</td></tr>
<tr><td><code>pars</code></td>
<td>
<p>from <code>mixture</code>.</p>
</td></tr>
<tr><td><code>pdf_func</code></td>
<td>
<p>from <code>mixture</code>.</p>
</td></tr>
<tr><td><code>K</code></td>
<td>
<p>from <code>mixture</code>.</p>
</td></tr>
<tr><td><code>nb_var</code></td>
<td>
<p>from <code>mixture</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Cross JL, Hoogerheide L, Labonne P, van Dijk HK (2024).
&ldquo;Bayesian mode inference for discrete distributions in economics and finance.&rdquo;
<em>Economics Letters</em>, <b>235</b>, 111579.
ISSN 0165-1765, <a href="https://doi.org/10.1016/j.econlet.2024.111579">doi:10.1016/j.econlet.2024.111579</a>.
</p>
<p>Carreira-Perpinan MA (2000).
&ldquo;Mode-finding for mixtures of Gaussian distributions.&rdquo;
<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, <b>22</b>(11), 1318&ndash;1323.
ISSN 1939-3539, <a href="https://doi.org/10.1109/34.888716">doi:10.1109/34.888716</a>, Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence.<br /><br /> Cross JL, Hoogerheide L, Labonne P, van Dijk HK (2024).
&ldquo;Bayesian mode inference for discrete distributions in economics and finance.&rdquo;
<em>Economics Letters</em>, <b>235</b>, 111579.
ISSN 0165-1765, <a href="https://doi.org/10.1016/j.econlet.2024.111579">doi:10.1016/j.econlet.2024.111579</a>.<br /><br /> Li J, Ray S, Lindsay BG (2007).
&ldquo;A Nonparametric Statistical Approach to Clustering via Mode Identification.&rdquo;
<em>Journal of Machine Learning Research</em>, <b>8</b>, 1687-1723.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Example with a normal distribution ====================================
mu &lt;- c(0, 5)
sigma &lt;- c(1, 2)
p &lt;- c(0.5, 0.5)

params &lt;- c(eta = p, mu = mu, sigma = sigma)
mix &lt;- mixture(params, dist = "normal", range = c(-5, 15))
modes &lt;- mix_mode(mix)

# summary(modes)
# plot(modes)

# Example with a skew normal =============================================
xi &lt;- c(0, 6)
omega &lt;- c(1, 2)
alpha &lt;- c(0, 0)
p &lt;- c(0.8, 0.2)
params &lt;- c(eta = p, xi = xi, omega = omega, alpha = alpha)
dist &lt;- "skew_normal"

mix &lt;- mixture(params, dist = dist, range = c(-5, 15))
modes &lt;- mix_mode(mix)
# summary(modes)
# plot(modes)

# Example with an arbitrary continuous distribution ======================
xi &lt;- c(0, 6)
omega &lt;- c(1, 2)
alpha &lt;- c(0, 0)
nu &lt;- c(3, 100)
p &lt;- c(0.8, 0.2)
params &lt;- c(eta = p, mu = xi, sigma = omega, xi = alpha, nu = nu)

pdf_func &lt;- function(x, pars) {
  sn::dst(x, pars["mu"], pars["sigma"], pars["xi"], pars["nu"])
}

mix &lt;- mixture(params,
  pdf_func = pdf_func,
  dist_type = "continuous", loc = "mu", range = c(-5, 15)
)
modes &lt;- mix_mode(mix)

# summary(modes)
# plot(modes, from = -4, to = 4)

# Example with a poisson distribution ====================================
lambda &lt;- c(0.1, 10)
p &lt;- c(0.5, 0.5)
params &lt;- c(eta = p, lambda = lambda)
dist &lt;- "poisson"


mix &lt;- mixture(params, range = c(0, 50), dist = dist)

modes &lt;- mix_mode(mix)

# summary(modes)
# plot(modes)

# Example with an arbitrary discrete distribution =======================
mu &lt;- c(20, 5)
size &lt;- c(20, 0.5)
p &lt;- c(0.5, 0.5)
params &lt;- c(eta = p, mu = mu, size = size)


pmf_func &lt;- function(x, pars) {
  dnbinom(x, mu = pars["mu"], size = pars["size"])
}

mix &lt;- mixture(params,
  range = c(0, 50),
  pdf_func = pmf_func, dist_type = "discrete"
)
modes &lt;- mix_mode(mix)

# summary(modes)
# plot(modes)

</code></pre>

<hr>
<h2 id='mixture'>Creating a S3 object of class <code>mixture</code></h2><span id='topic+mixture'></span>

<h3>Description</h3>

<p>Creates an object of class <code>mixture</code> which can subsequently be used as argument in <code><a href="#topic+mix_mode">mix_mode()</a></code> for mode estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixture(
  pars,
  dist = NA_character_,
  pdf_func = NULL,
  dist_type = NA_character_,
  range,
  loc = NA_character_
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mixture_+3A_pars">pars</code></td>
<td>
<p>Named vector of mixture parameters.</p>
</td></tr>
<tr><td><code id="mixture_+3A_dist">dist</code></td>
<td>
<p>Distribution family of the mixture components supported by
the package (i.e. <code>"normal"</code>, <code>"student"</code>, <code>"skew_normal"</code> or <code>"shifted_poisson"</code>).
If left unspecified, <code>pdf_func</code> is required.</p>
</td></tr>
<tr><td><code id="mixture_+3A_pdf_func">pdf_func</code></td>
<td>
<p>(function) Pdf or pmf of the mixture components;
this input is used only if <code>dist</code> is left unspecified.
pdf_func should have two arguments : (i) the observation where the pdf is evaluated;
(ii) a named vector representing the function parameters. For instance a normal pdf would take the form:
<code>pdf_func &lt;- function(x, par) dnorm(x, par['mu'], par['sigma'])</code>.
The names of <code>par</code> should correspond to variables in <code>pars</code>, e.g. <code>"mu1"</code>, <code>"mu2"</code> etc...</p>
</td></tr>
<tr><td><code id="mixture_+3A_dist_type">dist_type</code></td>
<td>
<p>Type of the distribution, either <code>"continuous"</code> or <code>"discrete"</code>.</p>
</td></tr>
<tr><td><code id="mixture_+3A_range">range</code></td>
<td>
<p>upper and lower limit of the range where the mixture should be evaluated.</p>
</td></tr>
<tr><td><code id="mixture_+3A_loc">loc</code></td>
<td>
<p>(for continuous mixtures other than Normal mixtures) String indicating the location parameter
of the distribution; the latter is used to initialise the MEM algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>mixture</code> containing:
</p>
<table role = "presentation">
<tr><td><code>pars</code></td>
<td>
<p>Same as argument.</p>
</td></tr>
<tr><td><code>pars_names</code></td>
<td>
<p>Names of the parameters of the components' distribution.</p>
</td></tr>
<tr><td><code>dist</code></td>
<td>
<p>Same as argument.</p>
</td></tr>
<tr><td><code>pdf_func</code></td>
<td>
<p>Pdf (or pmf) of the mixture components.</p>
</td></tr>
<tr><td><code>dist_type</code></td>
<td>
<p>Same as argument.</p>
</td></tr>
<tr><td><code>loc</code></td>
<td>
<p>Type of the distribution, either <code>"continuous"</code> or <code>"discrete"</code>.</p>
</td></tr>
<tr><td><code>nb_var</code></td>
<td>
<p>Number of parameters in the mixture distribution.</p>
</td></tr>
<tr><td><code>K</code></td>
<td>
<p>Number of mixture components.</p>
</td></tr>
<tr><td><code>range</code></td>
<td>
<p>Same as argument.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
# Example with the skew normal =============================================
xi &lt;- c(0, 6)
omega &lt;- c(1, 2)
alpha &lt;- c(0, 0)
p &lt;- c(0.8, 0.2)
params &lt;- c(eta = p, xi = xi, omega = omega, alpha = alpha)
dist &lt;- "skew_normal"

mix &lt;- mixture(params, dist = dist, range = c(-2, 10))

# summary(mix)
# plot(mix)

# Example with an arbitrary distribution ===================================
mu &lt;- c(0, 6)
omega &lt;- c(1, 2)
xi &lt;- c(0, 0)
nu &lt;- c(3, 100)
p &lt;- c(0.8, 0.2)
params &lt;- c(eta = p, mu = mu, sigma = omega, xi = xi, nu = nu)

pdf_func &lt;- function(x, pars) {
  sn::dst(x, pars["mu"], pars["sigma"], pars["xi"], pars["nu"])
}


mix &lt;- mixture(params,
  pdf_func = pdf_func,
  dist_type = "continuous", loc = "mu", range = c(-2, 10)
)

# summary(mix)
# plot(mix, from = -4, to = 4)

</code></pre>

<hr>
<h2 id='plot.bayes_mixture'>Plot method for <code>bayes_mixture</code> objects</h2><span id='topic+plot.bayes_mixture'></span>

<h3>Description</h3>

<p>Plot an estimated mixture for a given number of draws with a frequency distribution of the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bayes_mixture'
plot(x, draws = 250, draw = NULL, bins = 30, alpha = 0.1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.bayes_mixture_+3A_x">x</code></td>
<td>
<p>An object of class <code>bayes_mixture</code>.</p>
</td></tr>
<tr><td><code id="plot.bayes_mixture_+3A_draws">draws</code></td>
<td>
<p>The number of MCMC draws to plot.</p>
</td></tr>
<tr><td><code id="plot.bayes_mixture_+3A_draw">draw</code></td>
<td>
<p>Plot estimated mixture in draw <code>draw</code>; note that <code>draws</code> is discarded. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plot.bayes_mixture_+3A_bins">bins</code></td>
<td>
<p>(for continuous mixtures) Number of bins for the histogram of
the data. Passed to <code>geom_histogram()</code>.</p>
</td></tr>
<tr><td><code id="plot.bayes_mixture_+3A_alpha">alpha</code></td>
<td>
<p>transparency of the density lines. Default is 0.1. Should be greater than 0 and below or equal to 1.</p>
</td></tr>
<tr><td><code id="plot.bayes_mixture_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.bayes_mode'>Plot method for <code>bayes_mode</code> objects</h2><span id='topic+plot.bayes_mode'></span>

<h3>Description</h3>

<p>Plot method for <code>bayes_mode</code> objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bayes_mode'
plot(x, graphs = c("p1", "number", "loc"), draw = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.bayes_mode_+3A_x">x</code></td>
<td>
<p>An object of class <code>bayes_mode</code>.</p>
</td></tr>
<tr><td><code id="plot.bayes_mode_+3A_graphs">graphs</code></td>
<td>
<p>which plot to show ? Default is all three c(&quot;p1&quot;, &quot;number&quot;, &quot;loc&quot;).</p>
</td></tr>
<tr><td><code id="plot.bayes_mode_+3A_draw">draw</code></td>
<td>
<p>Plot modes in a given mcmc draw; note that <code>graphs</code> is discarded. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plot.bayes_mode_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.mix_mode'>Plot method for <code>mix_mode</code> objects</h2><span id='topic+plot.mix_mode'></span>

<h3>Description</h3>

<p>Plot method for <code>mix_mode</code> objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mix_mode'
plot(x, from = x$range[1], to = x$range[2], ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.mix_mode_+3A_x">x</code></td>
<td>
<p>An object of class <code>mix_mode</code>.</p>
</td></tr>
<tr><td><code id="plot.mix_mode_+3A_from">from</code></td>
<td>
<p>the lower limit of the range over which the function will be plotted.
Default is <code>x$range[1]</code>.</p>
</td></tr>
<tr><td><code id="plot.mix_mode_+3A_to">to</code></td>
<td>
<p>the upper limit of the range over which the function will be plotted.
Default is <code>x$range[2]</code>.</p>
</td></tr>
<tr><td><code id="plot.mix_mode_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.mixture'>Plot method for <code>mixture</code> objects</h2><span id='topic+plot.mixture'></span>

<h3>Description</h3>

<p>Plot method for <code>mixture</code> objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mixture'
plot(x, from = x$range[1], to = x$range[2], ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.mixture_+3A_x">x</code></td>
<td>
<p>An object of class <code>mixture</code>.</p>
</td></tr>
<tr><td><code id="plot.mixture_+3A_from">from</code></td>
<td>
<p>the lower limit of the range over which the function will be plotted.
Default is <code>x$range[1]</code>.</p>
</td></tr>
<tr><td><code id="plot.mixture_+3A_to">to</code></td>
<td>
<p>the upper limit of the range over which the function will be plotted.
Default is <code>x$range[2]</code>.</p>
</td></tr>
<tr><td><code id="plot.mixture_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>

<hr>
<h2 id='print.bayes_mixture'>Print method for <code>bayes_mixture</code> objects</h2><span id='topic+print.bayes_mixture'></span>

<h3>Description</h3>

<p>Print method for <code>bayes_mixture</code> objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bayes_mixture'
print(x, max_length = 6L, max_width = 6L, print_all = F, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.bayes_mixture_+3A_x">x</code></td>
<td>
<p>An object of class <code>bayes_mixture</code>.</p>
</td></tr>
<tr><td><code id="print.bayes_mixture_+3A_max_length">max_length</code></td>
<td>
<p>maximum number of elements (for vector) or rows (for matrices) to show. Default is <code>6L</code>.</p>
</td></tr>
<tr><td><code id="print.bayes_mixture_+3A_max_width">max_width</code></td>
<td>
<p>maximum number of columns to show (for matrices). Default is <code>6L</code>.</p>
</td></tr>
<tr><td><code id="print.bayes_mixture_+3A_print_all">print_all</code></td>
<td>
<p>override max_length and max_width to print everything? Default is FALSE.</p>
</td></tr>
<tr><td><code id="print.bayes_mixture_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>

<hr>
<h2 id='print.bayes_mode'>Print method for <code>bayes_mode</code> objects</h2><span id='topic+print.bayes_mode'></span>

<h3>Description</h3>

<p>Print method for <code>bayes_mode</code> objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bayes_mode'
print(x, max_length = 6L, max_width = 6L, print_all = F, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.bayes_mode_+3A_x">x</code></td>
<td>
<p>An object of class <code>bayes_mode</code>.</p>
</td></tr>
<tr><td><code id="print.bayes_mode_+3A_max_length">max_length</code></td>
<td>
<p>maximum number of elements (for vector) or rows (for matrices) to show. Default is <code>6L</code>.</p>
</td></tr>
<tr><td><code id="print.bayes_mode_+3A_max_width">max_width</code></td>
<td>
<p>maximum number of columns to show (for matrices). Default is <code>6L</code>.</p>
</td></tr>
<tr><td><code id="print.bayes_mode_+3A_print_all">print_all</code></td>
<td>
<p>override max_length and max_width to print everything? Default is FALSE.</p>
</td></tr>
<tr><td><code id="print.bayes_mode_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>

<hr>
<h2 id='print.mix_mode'>Print method for <code>mix_mode</code> objects</h2><span id='topic+print.mix_mode'></span>

<h3>Description</h3>

<p>Print method for <code>mix_mode</code> objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mix_mode'
print(x, max_length = 6L, max_width = 6L, print_all = F, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.mix_mode_+3A_x">x</code></td>
<td>
<p>An object of class <code>mix_mode</code>.</p>
</td></tr>
<tr><td><code id="print.mix_mode_+3A_max_length">max_length</code></td>
<td>
<p>maximum number of elements (for vector) or rows (for matrices) to show. Default is <code>6L</code>.</p>
</td></tr>
<tr><td><code id="print.mix_mode_+3A_max_width">max_width</code></td>
<td>
<p>maximum number of columns to show (for matrices). Default is <code>6L</code>.</p>
</td></tr>
<tr><td><code id="print.mix_mode_+3A_print_all">print_all</code></td>
<td>
<p>override max_length and max_width to print everything? Default is FALSE.</p>
</td></tr>
<tr><td><code id="print.mix_mode_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>

<hr>
<h2 id='print.mixture'>Print method for <code>mixture</code> objects</h2><span id='topic+print.mixture'></span>

<h3>Description</h3>

<p>Print method for <code>mixture</code> objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mixture'
print(x, max_length = 6L, max_width = 6L, print_all = F, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.mixture_+3A_x">x</code></td>
<td>
<p>An object of class <code>mixture</code>.</p>
</td></tr>
<tr><td><code id="print.mixture_+3A_max_length">max_length</code></td>
<td>
<p>maximum number of elements (for vector) or rows (for matrices) to show. Default is <code>6L</code>.</p>
</td></tr>
<tr><td><code id="print.mixture_+3A_max_width">max_width</code></td>
<td>
<p>maximum number of columns to show (for matrices). Default is <code>6L</code>.</p>
</td></tr>
<tr><td><code id="print.mixture_+3A_print_all">print_all</code></td>
<td>
<p>override max_length and max_width to print everything? Default is FALSE.</p>
</td></tr>
<tr><td><code id="print.mixture_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>

<hr>
<h2 id='summary.bayes_mixture'>Summary method for <code>bayes_mixture</code> objects
The summary of MCMC draws is given by the function
<code>summarise_draws</code> from package <span class="pkg">posterior</span>.</h2><span id='topic+summary.bayes_mixture'></span>

<h3>Description</h3>

<p>Summary method for <code>bayes_mixture</code> objects
The summary of MCMC draws is given by the function
<code>summarise_draws</code> from package <span class="pkg">posterior</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bayes_mixture'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.bayes_mixture_+3A_object">object</code></td>
<td>
<p>An object of class <code>bayes_mixture</code>.</p>
</td></tr>
<tr><td><code id="summary.bayes_mixture_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>

<hr>
<h2 id='summary.bayes_mode'>Summary method for <code>bayes_mode</code> objects</h2><span id='topic+summary.bayes_mode'></span>

<h3>Description</h3>

<p>Summary method for <code>bayes_mode</code> objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bayes_mode'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.bayes_mode_+3A_object">object</code></td>
<td>
<p>An object of class <code>bayes_mode</code>.</p>
</td></tr>
<tr><td><code id="summary.bayes_mode_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>

<hr>
<h2 id='summary.mix_mode'>Summary method for <code>mix_mode</code> objects</h2><span id='topic+summary.mix_mode'></span>

<h3>Description</h3>

<p>Summary method for <code>mix_mode</code> objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mix_mode'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.mix_mode_+3A_object">object</code></td>
<td>
<p>An object of class <code>mix_mode</code>.</p>
</td></tr>
<tr><td><code id="summary.mix_mode_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>

<hr>
<h2 id='summary.mixture'>Summary method for <code>mixture</code> objects</h2><span id='topic+summary.mixture'></span>

<h3>Description</h3>

<p>Summary method for <code>mixture</code> objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mixture'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.mixture_+3A_object">object</code></td>
<td>
<p>An object of class <code>mixture</code>.</p>
</td></tr>
<tr><td><code id="summary.mixture_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
