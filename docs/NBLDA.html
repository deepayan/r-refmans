<!DOCTYPE html><html><head><title>Help for package NBLDA</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {NBLDA}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#NBLDA-package'><p>Classifying count data using Poisson/Negative Binomial linear discriminant analysis</p></a></li>
<li><a href='#cervical'><p>Cervical cancer data</p></a></li>
<li><a href='#control'><p>Accessors for the 'control' slot.</p></a></li>
<li><a href='#FindBestTransform'><p>Find the Power Transformation Parameter.</p></a></li>
<li><a href='#generateCountData'><p>Generate Count Data</p></a></li>
<li><a href='#getShrinkedDispersions'><p>Estimate Shrinked Overdispersions</p></a></li>
<li><a href='#inputs'><p>Accessors for the 'input' slot.</p></a></li>
<li><a href='#nblda_input-class'><p><code>nblda_input</code> object</p></a></li>
<li><a href='#nblda_trained-class'><p><code>nblda_trained</code> object</p></a></li>
<li><a href='#nblda-class'><p><code>nblda</code> object</p></a></li>
<li><a href='#nbldaControl'><p>Control parameters for trained NBLDA model.</p></a></li>
<li><a href='#nbldaTrained'><p>Accessors for the 'crossValidated' slot.</p></a></li>
<li><a href='#normalization'><p>Accessors for the 'type' slot.</p></a></li>
<li><a href='#NullModel'><p>Calculate the Normalized Counts and Related Training Parameters.</p></a></li>
<li><a href='#plot'><p>Plot Method for the <code>nblda</code> and <code>nblda_trained</code> Classes</p></a></li>
<li><a href='#predict'><p>Extract predictions from NBLDA model</p></a></li>
<li><a href='#selectedFeatures'><p>Accessors for the 'selectedFeatures' slot.</p></a></li>
<li><a href='#show'><p>Show Method for the S4 classes in NBLDA Package</p></a></li>
<li><a href='#trainNBLDA'><p>Train Model over Different Tuning Parameters</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Negative Binomial Linear Discriminant Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-02-21</td>
</tr>
<tr>
<td>Description:</td>
<td>We proposed a package for the classification task which uses Negative Binomial distribution within Linear Discriminant Analysis (NBLDA). It is an extension of the 'PoiClaClu' package to Negative Binomial distribution. The classification algorithms are based on the papers Dong et al. (2016, ISSN: 1471-2105) and Witten, DM (2011, ISSN: 1932-6157) for NBLDA and PLDA, respectively. Although PLDA is a sparse algorithm and can be used for variable selection, the algorithm proposed by Dong et al. is not sparse. Therefore, it uses all variables in the classifier. Here, we extend Dong et al.'s algorithm to the sparse case by shrinking overdispersion towards 0 (Yu et al., 2013, ISSN: 1367-4803) and offset parameter towards 1 (as proposed by Witten DM, 2011). We support only the classification task with this version.</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, stats, graphics</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, PoiClaClu, sSeq</td>
</tr>
<tr>
<td>Depends:</td>
<td>ggplot2</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Collate:</td>
<td>'FindBestTransform.R' 'all_classes.R' 'all_generics.R'
'control.R' 'copiedFromOtherPackages.R' 'generateCountData.R'
'getShrinkedDispersions.R' 'helper_functions.R'
'normalize_counts.R' 'package_and_supplementary.R'
'plot.nblda.R' 'predict.nblda.R' 'trainNBLDA.R' 'zzz_methods.R'</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-02-21 18:57:52 UTC; root</td>
</tr>
<tr>
<td>Author:</td>
<td>Dincer Goksuluk [aut, cre],
  Gokmen Zararsiz [aut],
  Selcuk Korkmaz [aut],
  Ahmet Ergun Karaagaoglu [ths]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Dincer Goksuluk &lt;dincergoksuluk@erciyes.edu.tr&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-02-21 19:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='NBLDA-package'>Classifying count data using Poisson/Negative Binomial linear discriminant analysis</h2><span id='topic+NBLDA-package'></span>

<h3>Description</h3>

<p>This package applies linear discriminant analysis using Poisson (PLDA) and Negative Binomial (NBLDA) distributions for the classification of count data, such as gene expression data from RNA-sequencing. PLDA algorithms have been proposed by Witten (2011) through an R package <code>PoiClaClu</code>, which is available at CRAN. Dong et al. (2016) proposed an extension of PLDA to negative Binomial distribution. However, the algorithm is not provided through an R package. Hence, we develop an R package <code>NBLDA</code> to make the proposed algorithm available through CRAN. Detailed information about mathematical backgrounds is available in the references given below.
</p>


<h3>Author(s)</h3>

<p>Dincer Goksuluk, Gokmen Zararsiz, Selcuk Korkmaz, A. Ergun Karaagaoglu
</p>
<p>&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;
</p>
<p><strong>Maintainers:</strong>
</p>
<p>Dincer Goksuluk (Correspondence), <a href="mailto:dincer.goksuluk@hacettepe.edu.tr">dincer.goksuluk@hacettepe.edu.tr</a>
</p>
<p>Gokmen Zararsiz, <a href="mailto:gokmenzararsiz@erciyes.edu.tr">gokmenzararsiz@erciyes.edu.tr</a>
</p>
<p>Selcuk Korkmaz, <a href="mailto:selcukorkmaz@hotmail.com">selcukorkmaz@hotmail.com</a>
</p>


<h3>References</h3>

<p>Witten, DM (2011). Classification and clustering of sequencing data using a Poisson model.
Ann. Appl. Stat. 5(4), 2493&ndash;2518. doi:10.1214/11-AOAS493.
</p>
<p>Dong, K., Zhao, H., Tong, T., &amp; Wan, X. (2016). NBLDA: negative binomial linear discriminant analysis for RNA-Seq data.
BMC Bioinformatics, 17(1), 369. http://doi.org/10.1186/s12859-016-1208-1
</p>


<h3>See Also</h3>

<p><a href="https://CRAN.R-project.org/package=PoiClaClu">https://CRAN.R-project.org/package=PoiClaClu</a>
</p>

<table>
<tr>
 <td style="text-align: left;">
  Package: </td><td style="text-align: left;"> NBLDA</td>
</tr>
<tr>
 <td style="text-align: left;">
  Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
  License: </td><td style="text-align: left;"> GPL (&gt;= 2)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='cervical'>Cervical cancer data</h2><span id='topic+cervical'></span>

<h3>Description</h3>

<p>Cervical cancer data measures the gene expression levels of 714 miRNAs of human samples. There are 29 tumor and 29 non-tumor cervical samples, and these two groups correspond to two separate classes.
</p>


<h3>Format</h3>

<p>A data frame with 58 observations and 715 variables (including the class labels).
</p>


<h3>Source</h3>

<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2880020/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2880020/</a>
</p>


<h3>References</h3>

<p>Witten, D., et al. (2010) Ultra-high throughput sequencing-based small RNA discovery and discrete statistical biomarker analysis in a collection of cervical tumours and matched controls. BMC Biology, 8:58
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(cervical)

## End(Not run)
</code></pre>

<hr>
<h2 id='control'>Accessors for the 'control' slot.</h2><span id='topic+control'></span><span id='topic+control+2Cnblda-method'></span><span id='topic+control+2Cnblda_trained-method'></span>

<h3>Description</h3>

<p>This slot stores control parameters for training NBLDA model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'nblda'
control(object)

## S4 method for signature 'nblda_trained'
control(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="control_+3A_object">object</code></td>
<td>
<p>an <code>nblda</code> or <code>nblda_trained</code> object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+trainNBLDA">trainNBLDA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2128)
counts &lt;- generateCountData(n = 20, p = 10, K = 2, param = 1, sdsignal = 0.5, DE = 0.8,
                            allZero.rm = FALSE, tag.samples = TRUE)
x &lt;- t(counts$x + 1)
y &lt;- counts$y
xte &lt;- t(counts$xte + 1)
ctrl &lt;- nbldaControl(folds = 2, repeats = 2)

fit &lt;- trainNBLDA(x = x, y = y, type = "mle", tuneLength = 10,
                  metric = "accuracy", train.control = ctrl)

control(fit)

</code></pre>

<hr>
<h2 id='FindBestTransform'>Find the Power Transformation Parameter.</h2><span id='topic+FindBestTransform'></span>

<h3>Description</h3>

<p>Use this function to find a constant value of alpha to be used for transforming count data. The power transformation parameter <code>alpha</code>, which approximately fits transformed data to the Poisson log-linear model, is selected using a grid search within the interval [0, 1].
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FindBestTransform(x, grid.length = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FindBestTransform_+3A_x">x</code></td>
<td>
<p>an n-by-p data frame or matrix of count data. Samples should be in the rows.</p>
</td></tr>
<tr><td><code id="FindBestTransform_+3A_grid.length">grid.length</code></td>
<td>
<p>how many distinct points of alpha should be searched within the interval [0, 1]? Default is 50.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the value of alpha to be used within the power transformation.
</p>


<h3>Note</h3>

<p>This function is copied from <code>PoiClaClu</code> package and modified to control the total number of grid search.
</p>


<h3>Author(s)</h3>

<p>Dincer Goksuluk
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2128)
counts &lt;- generateCountData(n = 20, p = 10, K = 2, param = 1, sdsignal = 0.5, DE = 0.8,
                            allZero.rm = FALSE, tag.samples = TRUE)

x &lt;- counts$x
FindBestTransform(x)

</code></pre>

<hr>
<h2 id='generateCountData'>Generate Count Data</h2><span id='topic+generateCountData'></span>

<h3>Description</h3>

<p>This function can be used to generate counts, e.g., RNA-Sequencing data, for both the classification and clustering purposes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateCountData(n, p, K, param, sdsignal = 1, DE = 0.3, allZero.rm = TRUE,
  tag.samples = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generateCountData_+3A_n">n</code></td>
<td>
<p>number of samples.</p>
</td></tr>
<tr><td><code id="generateCountData_+3A_p">p</code></td>
<td>
<p>number of variables/features.</p>
</td></tr>
<tr><td><code id="generateCountData_+3A_k">K</code></td>
<td>
<p>number of classes.</p>
</td></tr>
<tr><td><code id="generateCountData_+3A_param">param</code></td>
<td>
<p>overdispersion parameter. This parameter is matched with the argument <code>size</code> in the <code><a href="stats.html#topic+rnbinom">rnbinom</a></code> function. Hence, the Negative Binomial distribution approximates to the Poisson distribution as <code>param</code> increases.</p>
</td></tr>
<tr><td><code id="generateCountData_+3A_sdsignal">sdsignal</code></td>
<td>
<p>a nonzero numeric value. As <code>sdsignal</code> increases, the observed counts greatly differs among K classes.</p>
</td></tr>
<tr><td><code id="generateCountData_+3A_de">DE</code></td>
<td>
<p>a numeric value within the interval [0, 1]. This is the proportion of total number of variables that is significantly different among K classes. The remaining part is assumed to be having no contribution to the discrimination function.</p>
</td></tr>
<tr><td><code id="generateCountData_+3A_allzero.rm">allZero.rm</code></td>
<td>
<p>a logical. If TRUE, the columns having all zero cells are dropped.</p>
</td></tr>
<tr><td><code id="generateCountData_+3A_tag.samples">tag.samples</code></td>
<td>
<p>a logical. If TRUE, the row names are automatically generated using a tag for each sample such as &quot;S1&quot;, &quot;S2&quot;, etc.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>x</code>, <code>xte</code></td>
<td>
<p>count data matrix for training and test set.</p>
</td></tr>
<tr><td><code>y</code>, <code>yte</code></td>
<td>
<p>class labels for training and test set.</p>
</td></tr>
<tr><td><code>truesf</code>, <code>truesfte</code></td>
<td>
<p>true size factors for training and test set. See Witten (2011) for more information on estimating size factors.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dincer Goksuluk
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2128)
counts &lt;- generateCountData(n = 20, p = 10, K = 2, param = 1, sdsignal = 0.5, DE = 0.8,
                            allZero.rm = FALSE, tag.samples = TRUE)
head(counts$x)

</code></pre>

<hr>
<h2 id='getShrinkedDispersions'>Estimate Shrinked Overdispersions</h2><span id='topic+getShrinkedDispersions'></span>

<h3>Description</h3>

<p>Use this function to shrink initial estimates of overdispersions towards a target value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getShrinkedDispersions(obs, shrinkTarget = NULL, delta = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getShrinkedDispersions_+3A_obs">obs</code></td>
<td>
<p>a numeric vector. Initial dispersion estimates for each feature.</p>
</td></tr>
<tr><td><code id="getShrinkedDispersions_+3A_shrinktarget">shrinkTarget</code></td>
<td>
<p>a numeric value. Initial dispersion estimates are shrunk towards this value. If NULL, target value is estimated from the initial dispersion estimates. See notes.</p>
</td></tr>
<tr><td><code id="getShrinkedDispersions_+3A_delta">delta</code></td>
<td>
<p>a numeric value. This is the weight that is used within the shrinkage algorithm. If 0, no shrinkage is performed on initial values. If equals 1, initial values are forced to be shrunken to the target value. If NULL, weights are automatically estimated from the initial dispersion estimates.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with the elements of initial and adjusted (shrunken) dispersion estimates, shrinkage target, and
weights that are used to shrink towards the target value. See the related paper for detailed information on shrinkage
algorithm (Yu et al., 2013).
</p>
<table>
<tr><td><code>initial</code></td>
<td>
<p>initial dispersion estimates using the method-of-moments.</p>
</td></tr>
<tr><td><code>adj</code></td>
<td>
<p>shrunken dispersion estimates.</p>
</td></tr>
<tr><td><code>cmp</code></td>
<td>
<p>the means and variances of initial estimates.</p>
</td></tr>
<tr><td><code>delta</code></td>
<td>
<p>a weight used for shrinkage estimates. See Yu et al. (2013) for details.</p>
</td></tr>
<tr><td><code>target</code></td>
<td>
<p>shrinkage target for initial dispersion estimates.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is modified from the source codes of <code><a href="sSeq.html#topic+getAdjustDisp">getAdjustDisp</a></code> function in the <b>sSeq</b> Bioconductor package.
</p>


<h3>Author(s)</h3>

<p>Dincer Goksuluk
</p>


<h3>References</h3>

<p>Yu, D., Huber, W., &amp; Vitek, O. (2013). Shrinkage estimation of dispersion in Negative Binomial models
for RNA-seq experiments with small sample size. Bioinformatics, 29(10), 1275-1282.
</p>


<h3>See Also</h3>

<p><code><a href="sSeq.html#topic+getT">getT</a></code>, <code><a href="sSeq.html#topic+getAdjustDisp">getAdjustDisp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2128)
initial &lt;- runif(10, 0, 4)

getShrinkedDispersions(initial, 0)  # shrink towards 0.
getShrinkedDispersions(initial, 0, delta = 1)  # force to shrink 0.

</code></pre>

<hr>
<h2 id='inputs'>Accessors for the 'input' slot.</h2><span id='topic+inputs'></span><span id='topic+inputs+2Cnblda-method'></span>

<h3>Description</h3>

<p>This slot stores the input data for trained model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'nblda'
inputs(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="inputs_+3A_object">object</code></td>
<td>
<p>an <code>nblda</code> object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+trainNBLDA">trainNBLDA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2128)
counts &lt;- generateCountData(n = 20, p = 10, K = 2, param = 1, sdsignal = 0.5, DE = 0.8,
                            allZero.rm = FALSE, tag.samples = TRUE)
x &lt;- t(counts$x + 1)
y &lt;- counts$y
xte &lt;- t(counts$xte + 1)
ctrl &lt;- nbldaControl(folds = 2, repeats = 2)

fit &lt;- trainNBLDA(x = x, y = y, type = "mle", tuneLength = 10,
                  metric = "accuracy", train.control = ctrl)

inputs(fit)

</code></pre>

<hr>
<h2 id='nblda_input-class'><code>nblda_input</code> object</h2><span id='topic+nblda_input-class'></span>

<h3>Description</h3>

<p>This object is the subclass for the NBLDA package. It stores input objects, i.e., count data and class labels.
</p>


<h3>Slots</h3>


<dl>
<dt><code>x</code>:</dt><dd><p>a data.frame or matrix containing the count data input for the NBLDA classifier.</p>
</dd>
<dt><code>y</code>:</dt><dd><p>a vector of length equal to the number of rows of x. This is the class label of each subject. Should be either a numeric vector or factor.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Dincer Goksuluk
</p>

<hr>
<h2 id='nblda_trained-class'><code>nblda_trained</code> object</h2><span id='topic+nblda_trained-class'></span>

<h3>Description</h3>

<p>This object is the subclass for the NBLDA package. It stores the cross-validated results and the final model.
</p>


<h3>Slots</h3>


<dl>
<dt><code>crossValidated</code>:</dt><dd><p>a list. Returns the results from cross-validation.</p>
</dd>
<dt><code>finalModel</code>:</dt><dd><p>a list with the elements from the final model that is fitted using optimum model parameters from the cross-validated model.</p>
</dd>
<dt><code>control</code>:</dt><dd><p>a list with controlling parameters for fitting NBLDA classifier.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Dincer Goksuluk
</p>

<hr>
<h2 id='nblda-class'><code>nblda</code> object</h2><span id='topic+nblda-class'></span>

<h3>Description</h3>

<p>This object is the main class for the NBLDA package. It stores inputs, results, and call info for the trained model.
</p>


<h3>Details</h3>

<p>Objects can be created by calls of the form <code>new("nblda", ...)</code>. This type of object is returned from <code>trainNBLDA</code> function of the <code>NBLDA</code> package. It is then used in <code>predict</code> function for predicting class labels of new samples.
</p>


<h3>Slots</h3>


<dl>
<dt><code>input</code>:</dt><dd><p>an <code>nblda_input</code> object including the count matrix (or data.frame) and class labels.</p>
</dd>
<dt><code>result</code>:</dt><dd><p>an <code>nblda_trained</code> object with elements from the cross-validated and final models.</p>
</dd>
<dt><code>call</code>:</dt><dd><p>a call expression.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Dincer Goksuluk
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nblda_trained-class">nblda_trained</a></code>, <code><a href="#topic+nblda_input-class">nblda_input</a></code>
</p>

<hr>
<h2 id='nbldaControl'>Control parameters for trained NBLDA model.</h2><span id='topic+nbldaControl'></span>

<h3>Description</h3>

<p>Define control parameters to be used within <code><a href="#topic+trainNBLDA">trainNBLDA</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nbldaControl(folds = 5, repeats = 2, foldIdx = NULL, rhos = NULL,
  beta = 1, prior = NULL, transform = FALSE, alpha = NULL, truephi = NULL,
  target = 0, phi.epsilon = 0.15, normalize.target = FALSE, delta = NULL,
  multicore = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nbldaControl_+3A_folds">folds</code></td>
<td>
<p>A positive integer. The number of folds for k-fold model validation.</p>
</td></tr>
<tr><td><code id="nbldaControl_+3A_repeats">repeats</code></td>
<td>
<p>A positive integer. This is the number of repeats for k-fold model validation. If NULL, 0 or negative, it is set to 1.</p>
</td></tr>
<tr><td><code id="nbldaControl_+3A_foldidx">foldIdx</code></td>
<td>
<p>a list with indices of hold-out samples for each fold. It should be a list where folds are nested within repeats. If NULL, <code>folds</code> and <code>repeats</code> are used to define hold-out samples.</p>
</td></tr>
<tr><td><code id="nbldaControl_+3A_rhos">rhos</code></td>
<td>
<p>A vector of tuning parameters that control the amount of soft thresholding performed. If NULL, it is automatically generated within <code><a href="#topic+trainNBLDA">trainNBLDA</a></code> using <code>tuneLength</code>, i.e., the length of grid search. See details.</p>
</td></tr>
<tr><td><code id="nbldaControl_+3A_beta">beta</code></td>
<td>
<p>A smoothing term. A Gamma(beta,beta) prior is used to fit the Poisson model. Recommendation is to just leave it at 1, the default value. See Witten (2011) and Dong et al. (2016) for details.</p>
</td></tr>
<tr><td><code id="nbldaControl_+3A_prior">prior</code></td>
<td>
<p>A vector with a length equal to the number of classes indicates the prior class probabilities. If NULL, all classes are assumed to be equally distributed.</p>
</td></tr>
<tr><td><code id="nbldaControl_+3A_transform">transform</code></td>
<td>
<p>a logical. If TRUE, count data is transformed using power transformation. If <code>alpha</code> is not specified the power transformation parameter is automatically calculated using a goodness-of-fit test. See Witten (2011) for details.</p>
</td></tr>
<tr><td><code id="nbldaControl_+3A_alpha">alpha</code></td>
<td>
<p>a numeric value within [0, 1] to be used for power transformation.</p>
</td></tr>
<tr><td><code id="nbldaControl_+3A_truephi">truephi</code></td>
<td>
<p>a vector with a length equal to the number of variables.  Its elements represent the true overdispersion parameters for each variable. If a single value is given, it is recycled for all variables. If a vector whose length is not equal to the number of variables given, the first element of this vector is used and recycled for all variables. If NULL, estimated overdispersions are used in the classifier. See details.</p>
</td></tr>
<tr><td><code id="nbldaControl_+3A_target">target</code></td>
<td>
<p>a value for the shrinkage target of dispersion estimates. If NULL, then then a value that is small and minimizes the average squared difference is automatically used as the target value. See <code><a href="sSeq.html#topic+getT">getT</a></code> for details.</p>
</td></tr>
<tr><td><code id="nbldaControl_+3A_phi.epsilon">phi.epsilon</code></td>
<td>
<p>a positive value for controlling the number of features whose dispersions are shrinked towards 0. See details.</p>
</td></tr>
<tr><td><code id="nbldaControl_+3A_normalize.target">normalize.target</code></td>
<td>
<p>a logical. If TRUE and <code>target</code> is NULL, the target value is estimated using the normalized dispersion estimates. See <code><a href="sSeq.html#topic+getT">getT</a></code> for details.</p>
</td></tr>
<tr><td><code id="nbldaControl_+3A_delta">delta</code></td>
<td>
<p>a weight within the interval [0, 1] that is used while shrinking dispersions towards 0. When &quot;delta = 0&quot;, initial dispersion estimates are forced to be shrunk to 1. Similarly, if &quot;delta = 0&quot;, no shrinkage is performed on the initial estimates.</p>
</td></tr>
<tr><td><code id="nbldaControl_+3A_multicore">multicore</code></td>
<td>
<p>a logical. If a parallel backend is loaded and available, the function runs in parallel setting for speeding up the computations.</p>
</td></tr>
<tr><td><code id="nbldaControl_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="#topic+trainNBLDA">trainNBLDA</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>rhos</code> is used to control the level of sparsity, i.e., the number of variables (or features) used in the classifier. If a variable has no contribution to the discrimination function, it should be removed from the model. By setting rhos within the interval [0, Inf], it is possible to control the number of variables that are removed from the model. As the upper bound of rhos decreases towards 0, fewer variables are removed. If <code>rhos = 0</code>, all variables are included in the classifier.
</p>
<p><code>truephi</code> controls how the Poisson model differs from the Negative Binomial model. If overdispersion is zero, the Negative Binomial model converges to the Poisson model. Hence, the results from <code><a href="#topic+trainNBLDA">trainNBLDA</a></code> are identical to PLDA results from <code><a href="PoiClaClu.html#topic+Classify">Classify</a></code> when truephi = 0.
</p>
<p><code>phi.epsilon</code> is a value used to shrink estimated overdispersions towards 0. The Poisson model assumes that there is no overdispersion in the observed counts. However, this is not a valid assumption in highly overdispersed count data. <code>NBLDA</code> performs a shrinkage on estimated overdispersions. Although the amount of shrinkage is dependent on several parameters such as <code>delta</code>, <code>target</code>, and <code>truephi</code>, some of the shrunken overdispersions might be very close to 0. By defining a threshold value for shrunken overdispersions, it is possible to shrink very small overdispersions towards 0. If estimated overdispersion is below <code>phi.epsilon</code>, it is shrunken to 0. If <code>phi.epsilon</code> = NULL, threshold value is set to 0. Hence, all the variables with very small overdispersion are included in the NBLDA model.
</p>


<h3>Value</h3>

<p>a list with all the control elements.
</p>


<h3>Author(s)</h3>

<p>Dincer Goksuluk
</p>


<h3>References</h3>

<p>Witten, DM (2011). Classification and clustering of sequencing data using a Poisson model.
Ann. Appl. Stat. 5(4), 2493&ndash;2518. doi:10.1214/11-AOAS493.
</p>
<p>Dong, K., Zhao, H., Tong, T., &amp; Wan, X. (2016). NBLDA: negative binomial linear discriminant analysis for RNA-Seq data.
BMC Bioinformatics, 17(1), 369. http://doi.org/10.1186/s12859-016-1208-1.
</p>
<p>Yu, D., Huber, W., &amp; Vitek, O. (2013). Shrinkage estimation of dispersion in Negative Binomial models
for RNA-seq experiments with small sample size. Bioinformatics, 29(10), 1275-1282.
</p>


<h3>See Also</h3>

<p><code><a href="sSeq.html#topic+getT">getT</a></code>, <code><a href="sSeq.html#topic+getAdjustDisp">getAdjustDisp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nbldaControl()  # return default control parameters.

</code></pre>

<hr>
<h2 id='nbldaTrained'>Accessors for the 'crossValidated' slot.</h2><span id='topic+nbldaTrained'></span><span id='topic+nbldaTrained+2Cnblda-method'></span><span id='topic+nbldaTrained+2Cnblda_trained-method'></span>

<h3>Description</h3>

<p>This slot stores the results for cross-validated model, e.g tuning results, optimum model parameters etc.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'nblda'
nbldaTrained(object)

## S4 method for signature 'nblda_trained'
nbldaTrained(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nbldaTrained_+3A_object">object</code></td>
<td>
<p>an <code>nblda</code> or <code>nblda_trained</code> object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+trainNBLDA">trainNBLDA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2128)
counts &lt;- generateCountData(n = 20, p = 10, K = 2, param = 1, sdsignal = 0.5, DE = 0.8,
                            allZero.rm = FALSE, tag.samples = TRUE)
x &lt;- t(counts$x + 1)
y &lt;- counts$y
xte &lt;- t(counts$xte + 1)
ctrl &lt;- nbldaControl(folds = 2, repeats = 2)

fit &lt;- trainNBLDA(x = x, y = y, type = "mle", tuneLength = 10,
                  metric = "accuracy", train.control = ctrl)

nbldaTrained(fit)

</code></pre>

<hr>
<h2 id='normalization'>Accessors for the 'type' slot.</h2><span id='topic+normalization'></span><span id='topic+normalization+2Cnblda-method'></span><span id='topic+normalization+2Cnblda_trained-method'></span>

<h3>Description</h3>

<p>This slot stores the name of normalization method. Normalization is defined using <code>type</code> argument in <code><a href="#topic+trainNBLDA">trainNBLDA</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'nblda'
normalization(object)

## S4 method for signature 'nblda_trained'
normalization(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalization_+3A_object">object</code></td>
<td>
<p>an <code>nblda</code> or <code>nblda_trained</code> object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+trainNBLDA">trainNBLDA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2128)
counts &lt;- generateCountData(n = 20, p = 10, K = 2, param = 1, sdsignal = 0.5, DE = 0.8,
                            allZero.rm = FALSE, tag.samples = TRUE)
x &lt;- t(counts$x + 1)
y &lt;- counts$y
xte &lt;- t(counts$xte + 1)
ctrl &lt;- nbldaControl(folds = 2, repeats = 2)

fit &lt;- trainNBLDA(x = x, y = y, type = "mle", tuneLength = 10,
                  metric = "accuracy", train.control = ctrl)

normalization(fit)

</code></pre>

<hr>
<h2 id='NullModel'>Calculate the Normalized Counts and Related Training Parameters.</h2><span id='topic+NullModel'></span><span id='topic+NullModelTest'></span>

<h3>Description</h3>

<p>Fit a training set to the NBLDA model and estimate normalized counts. The related model parameters, which are used while normalizing training sets, are also returned to normalize test sets using training set parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NullModel(x, type = c("mle", "deseq", "quantile", "none", "tmm"))

NullModelTest(null.out, xte = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NullModel_+3A_x">x</code></td>
<td>
<p>an n-by-p data frame or matrix of count data. Samples should be in the rows.</p>
</td></tr>
<tr><td><code id="NullModel_+3A_type">type</code></td>
<td>
<p>the normalization method. See <code><a href="#topic+control">control</a></code> for details.</p>
</td></tr>
<tr><td><code id="NullModel_+3A_null.out">null.out</code></td>
<td>
<p>an object returned from <code><a href="#topic+NullModel">NullModel</a></code>.</p>
</td></tr>
<tr><td><code id="NullModel_+3A_xte">xte</code></td>
<td>
<p>an n-by-p count matrix or data frame of test set. These counts are normalized using the training set parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with the normalized counts and the training set parameters that are used for normalizing the raw counts.
</p>


<h3>Note</h3>

<p>These functions are copied from the <code>PoiClaClu</code> package and modified here to make &quot;tmm&quot; and &quot;none&quot; methods available.
</p>


<h3>Author(s)</h3>

<p>Dincer Goksuluk
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2128)
counts &lt;- generateCountData(n = 20, p = 10, K = 2, param = 1, sdsignal = 0.5, DE = 0.8,
                            allZero.rm = FALSE, tag.samples = TRUE)
x &lt;- counts$x
xte &lt;- counts$xte

x.out &lt;- NullModel(x, "mle")
x.out$n ## Normalized counts using "mle" method

xte.out &lt;- NullModelTest(x.out, xte)
xte.out$n  # Normalized counts for test set using train set parameters.

</code></pre>

<hr>
<h2 id='plot'>Plot Method for the <code>nblda</code> and <code>nblda_trained</code> Classes</h2><span id='topic+plot'></span><span id='topic+plot.nblda'></span><span id='topic+plot.nblda_trained'></span><span id='topic+plot+2Cnblda-method'></span><span id='topic+plot+2Cnblda_trained-method'></span>

<h3>Description</h3>

<p>This function is used to generate model performance plots using <code><a href="ggplot2.html#topic+ggplot">ggplot2</a></code> functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'nblda'
plot(
  x,
  y,
  ...,
  theme = c("nblda", "default"),
  metric = c("accuracy", "error", "sparsity"),
  return = c("plot", "aes")
)

## S3 method for class 'nblda_trained'
plot(
  x,
  y,
  ...,
  theme = c("nblda", "default"),
  metric = c("accuracy", "error", "sparsity"),
  return = c("plot", "aes")
)

## S4 method for signature 'nblda'
plot(
  x,
  y,
  ...,
  theme = c("nblda", "default"),
  metric = c("accuracy", "error", "sparsity"),
  return = c("plot", "aes")
)

## S4 method for signature 'nblda_trained'
plot(
  x,
  y,
  ...,
  theme = c("nblda", "default"),
  metric = c("accuracy", "error", "sparsity"),
  return = c("plot", "aes")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_+3A_x">x</code></td>
<td>
<p>a <code>nblda</code> object returned from the <code><a href="#topic+trainNBLDA">trainNBLDA</a></code> or <code>nblda_trained</code> object returned from the <code><a href="#topic+nbldaTrained">nbldaTrained</a></code>.</p>
</td></tr>
<tr><td><code id="plot_+3A_y">y</code></td>
<td>
<p>same as <code>x</code> and not required to be defined. If <code>x</code> is missing or NULL, <code>nblda</code> or <code>nblda_trained</code> object is imported from <code>y</code>.</p>
</td></tr>
<tr><td><code id="plot_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to plotting function <code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>.</p>
</td></tr>
<tr><td><code id="plot_+3A_theme">theme</code></td>
<td>
<p>pre-defined plot themes. It can be defined outside <code>plot</code> function using the ggplot's library. See examples.</p>
</td></tr>
<tr><td><code id="plot_+3A_metric">metric</code></td>
<td>
<p>which metric should be used in the y-axis?</p>
</td></tr>
<tr><td><code id="plot_+3A_return">return</code></td>
<td>
<p>should a complete plot or a ggplot object from <code>ggplot</code> be returned? One may select &quot;aes&quot; in order to add plot layers to a returned ggplot aesthetics. See examples.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>ggplot</code>.
</p>


<h3>Author(s)</h3>

<p>Dincer Goksuluk
</p>


<h3>See Also</h3>

<p><code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2128)
counts &lt;- generateCountData(n = 20, p = 10, K = 2, param = 1, sdsignal = 0.5,
                            DE = 0.8, allZero.rm = FALSE, tag.samples = TRUE)
x &lt;- t(counts$x + 1)
y &lt;- counts$y
xte &lt;- t(counts$xte + 1)
ctrl &lt;- nbldaControl(folds = 2, repeats = 2)

fit &lt;- trainNBLDA(x = x, y = y, type = "mle", tuneLength = 10,
                  metric = "accuracy", train.control = ctrl)

plot(fit)

# Use pre-defined theme
plot(fit, theme = "nblda")

# Externally defining plot theme
plot(fit, theme = "default") + theme_dark(base_size = 14)

# Return empty ggplot object and add layers.
plot(fit, theme = "nblda", return = "aes") +
  geom_point() + geom_line(linetype = 2)

</code></pre>

<hr>
<h2 id='predict'>Extract predictions from NBLDA model</h2><span id='topic+predict'></span><span id='topic+predict.nblda'></span><span id='topic+predict+2Cnblda-method'></span>

<h3>Description</h3>

<p>This function predicts the class labels of a test data for a given model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'nblda'
predict(object, test.data, return = c("predictions", "everything"), ...)

## S4 method for signature 'nblda'
predict(object, test.data, return = c("predictions", "everything"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_+3A_object">object</code></td>
<td>
<p>a <code>nblda</code> object returned from the <code><a href="#topic+trainNBLDA">trainNBLDA</a></code>.</p>
</td></tr>
<tr><td><code id="predict_+3A_test.data">test.data</code></td>
<td>
<p>a data frame or matrix whose class labels to be predicted.</p>
</td></tr>
<tr><td><code id="predict_+3A_return">return</code></td>
<td>
<p>what should be returned? Predicted class labels or everything?</p>
</td></tr>
<tr><td><code id="predict_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>It is possible to return only predicted class labels or a list with elements which are used within prediction
process. These arguments are as follows:
</p>
<table>
<tr><td><code>xte</code></td>
<td>
<p>count data for test set.</p>
</td></tr>
<tr><td><code>nste</code></td>
<td>
<p>normalized count data for test set.</p>
</td></tr>
<tr><td><code>ds</code></td>
<td>
<p>estimates of offset parameter for each variable. See notes.</p>
</td></tr>
<tr><td><code>discriminant</code></td>
<td>
<p>discriminant scores of each subject.</p>
</td></tr>
<tr><td><code>prior</code></td>
<td>
<p>prior probabilities for each class.</p>
</td></tr>
<tr><td><code>ytehat</code></td>
<td>
<p>predicted class labels for test set.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>power transformation parameter. If no transformation is requested, it returns NULL.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>normalization method.</p>
</td></tr>
<tr><td><code>dispersions</code></td>
<td>
<p>dispersion estimates of each variable.</p>
</td></tr>
</table>


<h3>Note</h3>

<p><code>d_kj</code> is simply used to re-parameterize the Negative Binomial mean as s_i*g_j*d_kj where s_i is the size
factor for subject i, g_j is the total count of variable j and d_kj is the offset parameter for variable j at class k.
</p>


<h3>Author(s)</h3>

<p>Dincer Goksuluk
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2128)
counts &lt;- generateCountData(n = 20, p = 10, K = 2, param = 1, sdsignal = 0.5, DE = 0.8,
                            allZero.rm = FALSE, tag.samples = TRUE)
x &lt;- t(counts$x + 1)
y &lt;- counts$y
xte &lt;- t(counts$xte + 1)
ctrl &lt;- nbldaControl(folds = 2, repeats = 2)

fit &lt;- trainNBLDA(x = x, y = y, type = "mle", tuneLength = 10,
                  metric = "accuracy", train.control = ctrl)

predict(fit, xte)

</code></pre>

<hr>
<h2 id='selectedFeatures'>Accessors for the 'selectedFeatures' slot.</h2><span id='topic+selectedFeatures'></span><span id='topic+selectedFeatures+2Cnblda-method'></span><span id='topic+selectedFeatures+2Cnblda_trained-method'></span>

<h3>Description</h3>

<p>This slot, if not NULL, stores the selected features/variables for sparse model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'nblda'
selectedFeatures(object)

## S4 method for signature 'nblda_trained'
selectedFeatures(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="selectedFeatures_+3A_object">object</code></td>
<td>
<p>an <code>nblda</code> or <code>nblda_trained</code> object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of selected features info including the followings:
</p>
<table>
<tr><td><code>idx</code></td>
<td>
<p>column indices of selected features/variables</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>column names of selected features/variables if input data have pre-defined column names.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>If <code>return.selected.features</code> = FALSE within <code><a href="#topic+nbldaControl">nbldaControl</a></code> or all features/variables
are selected and used in discrimination function, <code>idx</code> and <code>names</code> are returned NULL.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+trainNBLDA">trainNBLDA</a></code>, <code><a href="#topic+nblda-class">nblda</a></code>, <code><a href="#topic+nblda_trained-class">nblda_trained</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2128)
counts &lt;- generateCountData(n = 20, p = 50, K = 2, param = 1, sdsignal = 0.5, DE = 0.6,
                            allZero.rm = FALSE, tag.samples = TRUE)
x &lt;- t(counts$x + 1)
y &lt;- counts$y
xte &lt;- t(counts$xte + 1)
ctrl &lt;- nbldaControl(folds = 2, repeats = 2, return.selected.features = TRUE,
                     transform = TRUE, phi.epsilon = 0.10)

fit &lt;- trainNBLDA(x = x, y = y, type = "mle", tuneLength = 10,
                  metric = "accuracy", train.control = ctrl)

selectedFeatures(fit)

</code></pre>

<hr>
<h2 id='show'>Show Method for the S4 classes in NBLDA Package</h2><span id='topic+show'></span><span id='topic+show.nblda'></span><span id='topic+show+2Cnblda-method'></span><span id='topic+show.nblda_trained'></span><span id='topic+show+2Cnblda_trained-method'></span><span id='topic+show.nblda_input'></span><span id='topic+show+2Cnblda_input-method'></span>

<h3>Description</h3>

<p>Pretty print the objects in S4 classes on R console.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'nblda'
show(object)

## S4 method for signature 'nblda'
show(object)

## S3 method for class 'nblda_trained'
show(object)

## S4 method for signature 'nblda_trained'
show(object)

## S3 method for class 'nblda_input'
show(object)

## S4 method for signature 'nblda_input'
show(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show_+3A_object">object</code></td>
<td>
<p>an object of class <code>nblda, nblda_trained</code> and <code>nblda_input</code> to be printed.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dincer Goksuluk
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2128)
counts &lt;- generateCountData(n = 20, p = 10, K = 2, param = 1, sdsignal = 0.5, DE = 0.8,
                            allZero.rm = FALSE, tag.samples = TRUE)
x &lt;- t(counts$x + 1)
y &lt;- counts$y
xte &lt;- t(counts$xte + 1)
ctrl &lt;- nbldaControl(folds = 2, repeats = 2)

fit &lt;- trainNBLDA(x = x, y = y, type = "mle", tuneLength = 10,
                  metric = "accuracy", train.control = ctrl)

show(fit)
show(inputs(fit))
show(nbldaTrained(fit))

</code></pre>

<hr>
<h2 id='trainNBLDA'>Train Model over Different Tuning Parameters</h2><span id='topic+trainNBLDA'></span>

<h3>Description</h3>

<p>This function fits the Negative Binomial classifier using various model parameters and finds the best model parameter using the resampling based performance measures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trainNBLDA(x, y, type = c("mle", "deseq", "quantile", "tmm"),
  tuneLength = 10, metric = c("accuracy", "error"), train.control = nbldaControl(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trainNBLDA_+3A_x">x</code></td>
<td>
<p>a n-by-p data frame or matrix. Samples should be in the rows and variables in the columns. Used to train the classifier.</p>
</td></tr>
<tr><td><code id="trainNBLDA_+3A_y">y</code></td>
<td>
<p>a vector of length n. Each element corresponds to a class label of a sample. Integer and/or factor types are allowed.</p>
</td></tr>
<tr><td><code id="trainNBLDA_+3A_type">type</code></td>
<td>
<p>a character string indicating the type of normalization method within the NBLDA model. See details.</p>
</td></tr>
<tr><td><code id="trainNBLDA_+3A_tunelength">tuneLength</code></td>
<td>
<p>a positive integer. This is the total number of levels to be used while tuning the model parameter(s) in grid search.</p>
</td></tr>
<tr><td><code id="trainNBLDA_+3A_metric">metric</code></td>
<td>
<p>which criteria should be used while determining the best model parameter? overall accuracy or average number of misclassified samples?</p>
</td></tr>
<tr><td><code id="trainNBLDA_+3A_train.control">train.control</code></td>
<td>
<p>a list with control parameters to be used in the NBLDA model. See <a href="#topic+nbldaControl">nbldaControl</a> for details.</p>
</td></tr>
<tr><td><code id="trainNBLDA_+3A_...">...</code></td>
<td>
<p>further arguments. Deprecated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>NBLDA is proposed to classify count data from any field, e.g., economics, social sciences, genomics, etc. In RNA-Seq studies, for example, normalization is used to adjust between-sample differences for downstream analysis. <code>type</code> is used to define normalization method. Available options are &quot;mle&quot;, &quot;deseq&quot;, &quot;quantile&quot;, and &quot;tmm&quot;. Since &quot;deseq&quot;, &quot;quantile&quot;, and &quot;tmm&quot; methods are originally proposed as robust methods to be used in RNA-Sequencing studies, one should carefully define normalization types. In greater detail, &quot;deseq&quot; estimates the size factors by dividing each sample by the geometric means of the transcript counts (Anders and Huber, 2010). &quot;tmm&quot; trims the lower and upper side of the data by log-fold changes to minimize the log-fold changes between the samples and by absolute intensity (Robinson and Oshlack, 2010). &quot;quantile&quot; is quantile normalization approach of Bullard et al. (2010). &quot;mle&quot; (less robust) divides total counts of each sample to the total counts (Witten, 2010). See related papers for mathematical backgrounds.
</p>


<h3>Value</h3>

<p>an <code>nblda</code> object with following slots:
</p>
<table>
<tr><td><code>input</code></td>
<td>
<p>an <code>nblda_input</code> object including the raw count data and response variable. See <code><a href="#topic+nblda_input-class">nblda_input</a></code> for details.</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>an <code>nblda_trained</code> object including the results from cross-validated and final models. See <code><a href="#topic+nblda_trained-class">nblda_trained</a></code> for details.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a call expression.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dincer Goksuluk
</p>


<h3>References</h3>

<p>Witten, DM (2011). Classification and clustering of sequencing data using a Poisson model. Ann. Appl. Stat. 5(4), 2493&ndash;2518. doi:10.1214/11-AOAS493.
</p>
<p>Dong, K., Zhao, H., Tong, T., &amp; Wan, X. (2016). NBLDA: negative binomial linear discriminant analysis for RNA-Seq data. BMC Bioinformatics, 17(1), 369. http://doi.org/10.1186/s12859-016-1208-1.
</p>
<p>Anders S. Huber W. (2010). Differential expression analysis for sequence count data. Genome Biology, 11:R106
</p>
<p>Witten D. et al. (2010) Ultra-high throughput sequencing-based small RNA discovery and discrete statistical biomarker analysis in a collection of cervical tumours and matched controls. BMC Biology, 8:58
</p>
<p>Robinson MD, Oshlack A (2010). A scaling normalization method for differential expression analysis of RNA-Seq data. Genome Biology, 11:R25, doi:10.1186/gb-2010-11-3-r25
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2128)
counts &lt;- generateCountData(n = 20, p = 10, K = 2, param = 1, sdsignal = 0.5, DE = 0.8,
                            allZero.rm = FALSE, tag.samples = TRUE)
x &lt;- t(counts$x + 1)
y &lt;- counts$y
xte &lt;- t(counts$xte + 1)
ctrl &lt;- nbldaControl(folds = 2, repeats = 2)

fit &lt;- trainNBLDA(x = x, y = y, type = "mle", tuneLength = 10,
                  metric = "accuracy", train.control = ctrl)

fit
nbldaTrained(fit)  # Cross-validated model summary.

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
