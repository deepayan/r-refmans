<!DOCTYPE html><html><head><title>Help for package mlr3resampling</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mlr3resampling}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#AZtrees'>
<p>Arizona Trees</p></a></li>
<li><a href='#ResamplingSameOtherCV'><p>Resampling for comparing training on same or other groups</p></a></li>
<li><a href='#ResamplingSameOtherSizesCV'><p>Resampling for comparing train subsets and sizes</p></a></li>
<li><a href='#ResamplingVariableSizeTrainCV'><p>Resampling for comparing training on same or other groups</p></a></li>
<li><a href='#score'>
<p>Score benchmark results</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Resampling Algorithms for 'mlr3' Framework</td>
</tr>
<tr>
<td>Version:</td>
<td>2024.7.7</td>
</tr>
<tr>
<td>Description:</td>
<td>A supervised learning algorithm inputs a train set,
 and outputs a prediction function, which can be used on a test set.
 If each data point belongs to a group
 (such as geographic region, year, etc), then
 how do we know if it is possible to train on one group, and predict
 accurately on another group? Cross-validation can be used to determine
 the extent to which this is possible, by first assigning fold IDs from
 1 to K to all data (possibly using stratification, usually by group
 and label). Then we loop over test sets (group/fold combinations),
 train sets (same group, other groups, all groups), and compute
 test/prediction accuracy for each combination.  Comparing
 test/prediction accuracy between same and other, we can determine the
 extent to which it is possible (perfect if same/other have similar
 test accuracy for each group; other is usually somewhat less accurate
 than same; other can be just as bad as featureless baseline when the
 groups have different patterns).
 For more information,
 <a href="https://tdhock.github.io/blog/2023/R-gen-new-subsets/">https://tdhock.github.io/blog/2023/R-gen-new-subsets/</a>
 describes the method in depth.
 How many train samples are required to get accurate predictions on a
 test set? Cross-validation can be used to answer this question, with
 variable size train sets.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/tdhock/mlr3resampling">https://github.com/tdhock/mlr3resampling</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/tdhock/mlr3resampling/issues">https://github.com/tdhock/mlr3resampling/issues</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>data.table, R6, checkmate, paradox, mlr3, mlr3misc</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ggplot2, animint2, mlr3tuning, lgr, future, testthat, knitr,
markdown, nc, rpart, directlabels</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-07-11 15:28:03 UTC; tdhock</td>
</tr>
<tr>
<td>Author:</td>
<td>Toby Hocking <a href="https://orcid.org/0000-0002-3146-0865"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Michel Lang <a href="https://orcid.org/0000-0001-9754-0393"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb]
    (Author of mlr3 when Resampling/ResamplingCV was copied/modified),
  Bernd Bischl <a href="https://orcid.org/0000-0001-6002-6980"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb] (Author of mlr3 when Resampling/ResamplingCV was
    copied/modified),
  Jakob Richter <a href="https://orcid.org/0000-0003-4481-5554"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb] (Author of mlr3 when Resampling/ResamplingCV was
    copied/modified),
  Patrick Schratz <a href="https://orcid.org/0000-0003-0748-6624"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb] (Author of mlr3 when Resampling/ResamplingCV was
    copied/modified),
  Giuseppe Casalicchio
    <a href="https://orcid.org/0000-0001-5324-5966"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb] (Author
    of mlr3 when Resampling/ResamplingCV was copied/modified),
  Stefan Coors <a href="https://orcid.org/0000-0002-7465-2146"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb] (Author of mlr3 when Resampling/ResamplingCV was
    copied/modified),
  Quay Au <a href="https://orcid.org/0000-0002-5252-8902"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb]
    (Author of mlr3 when Resampling/ResamplingCV was copied/modified),
  Martin Binder [ctb],
  Florian Pfisterer <a href="https://orcid.org/0000-0001-8867-762X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb] (Author of mlr3 when Resampling/ResamplingCV was
    copied/modified),
  Raphael Sonabend <a href="https://orcid.org/0000-0001-9225-4654"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb] (Author of mlr3 when Resampling/ResamplingCV was
    copied/modified),
  Lennart Schneider <a href="https://orcid.org/0000-0003-4152-5308"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb] (Author of mlr3 when Resampling/ResamplingCV was
    copied/modified),
  Marc Becker <a href="https://orcid.org/0000-0002-8115-0400"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb]
    (Author of mlr3 when Resampling/ResamplingCV was copied/modified),
  Sebastian Fischer <a href="https://orcid.org/0000-0002-9609-3197"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb] (Author of mlr3 when Resampling/ResamplingCV was
    copied/modified)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Toby Hocking &lt;toby.hocking@r-project.org&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-07-12 15:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='AZtrees'>
Arizona Trees
</h2><span id='topic+AZtrees'></span>

<h3>Description</h3>

<p>Classification data set with polygons (groups which should not be
split in CV) and subsets (region3 or region4).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("AZtrees")</code></pre>


<h3>Format</h3>

<p>A data frame with 5956 observations on the following 25 variables.
</p>

<dl>
<dt><code>region3</code></dt><dd><p>a character vector</p>
</dd>
<dt><code>region4</code></dt><dd><p>a character vector</p>
</dd>
<dt><code>polygon</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>y</code></dt><dd><p>a character vector</p>
</dd>
<dt><code>ycoord</code></dt><dd><p>latitude</p>
</dd>
<dt><code>xcoord</code></dt><dd><p>longitude</p>
</dd>
<dt><code>SAMPLE_1</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SAMPLE_2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SAMPLE_3</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SAMPLE_4</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SAMPLE_5</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SAMPLE_6</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SAMPLE_7</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SAMPLE_8</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SAMPLE_9</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SAMPLE_10</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SAMPLE_11</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SAMPLE_12</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SAMPLE_13</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SAMPLE_14</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SAMPLE_15</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SAMPLE_16</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SAMPLE_17</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SAMPLE_18</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SAMPLE_19</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SAMPLE_20</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SAMPLE_21</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>Paul Nelson Arellano, paul.arellano@nau.edu
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(AZtrees)
task.obj &lt;- mlr3::TaskClassif$new("AZtrees3", AZtrees, target="y")
task.obj$col_roles$feature &lt;- grep("SAMPLE", names(AZtrees), value=TRUE)
task.obj$col_roles$group &lt;- "polygon"
task.obj$col_roles$subset &lt;- "region3"
str(task.obj)
same_other_sizes_cv &lt;- mlr3resampling::ResamplingSameOtherSizesCV$new()
same_other_sizes_cv$instantiate(task.obj)
same_other_sizes_cv$instance$iteration.dt

</code></pre>

<hr>
<h2 id='ResamplingSameOtherCV'>Resampling for comparing training on same or other groups</h2><span id='topic+ResamplingSameOtherCV'></span>

<h3>Description</h3>

<p><code><a href="#topic+ResamplingSameOtherCV">ResamplingSameOtherCV</a></code>
defines how a task is partitioned for
resampling, for example in
<code><a href="mlr3.html#topic+resample">resample()</a></code> or
<code><a href="mlr3.html#topic+benchmark">benchmark()</a></code>.
</p>
<p>Resampling objects can be instantiated on a
<code><a href="mlr3.html#topic+Task">Task</a></code>,
which should define at least one group variable.
</p>
<p>After instantiation, sets can be accessed via
<code style="white-space: pre;">&#8288;$train_set(i)&#8288;</code> and
<code style="white-space: pre;">&#8288;$test_set(i)&#8288;</code>, respectively. 
</p>


<h3>Details</h3>

<p>A supervised learning algorithm inputs a train set, and outputs a
prediction function, which can be used on a test set. If each data
point belongs to a group (such as geographic region, year, etc), then
how do we know if it is possible to train on one group, and predict
accurately on another group? Cross-validation can be used to determine
the extent to which this is possible, by first assigning fold IDs from
1 to K to all data (possibly using stratification, usually by group
and label). Then we loop over test sets (group/fold combinations),
train sets (same group, other groups, all groups), and compute
test/prediction accuracy for each combination.  Comparing
test/prediction accuracy between same and other, we can determine the
extent to which it is possible (perfect if same/other have similar
test accuracy for each group; other is usually somewhat less accurate
than same; other can be just as bad as featureless baseline when the
groups have different patterns).
</p>


<h3>Stratification</h3>

<p><code><a href="#topic+ResamplingSameOtherCV">ResamplingSameOtherCV</a></code> supports stratified sampling.
The stratification variables are assumed to be discrete,
and must be stored in the <a href="mlr3.html#topic+Task">Task</a> with column role <code>"stratum"</code>.
In case of multiple stratification variables,
each combination of the values of the stratification variables forms a stratum.
</p>


<h3>Grouping</h3>

<p><code><a href="#topic+ResamplingSameOtherCV">ResamplingSameOtherCV</a></code> supports grouping of observations.
The grouping variable is assumed to be discrete,
and must be stored in the <a href="mlr3.html#topic+Task">Task</a> with column role <code>"group"</code>.
</p>
<p>The number of cross-validation folds K should be defined as the
<code>fold</code> parameter.
</p>
<p>In each group, there will be about an equal number of observations
assigned to each of the K folds.
The assignments are stored in
<code style="white-space: pre;">&#8288;$instance$id.dt&#8288;</code>.
The train/test splits are defined by all possible combinations of
test group, test fold, and train groups (same/other/all).
The splits are stored in
<code style="white-space: pre;">&#8288;$instance$iteration.dt&#8288;</code>.
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-Resampling-new"><code>Resampling$new()</code></a>
</p>
</li>
<li> <p><a href="#method-Resampling-train_set"><code>Resampling$train_set()</code></a>
</p>
</li>
<li> <p><a href="#method-Resampling-test_set"><code>Resampling$test_set()</code></a>
</p>
</li></ul>


<hr>
<a id="method-Resampling-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>Resampling$new(
  id,
  param_set = ps(),
  duplicated_ids = FALSE,
  label = NA_character_,
  man = NA_character_
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier for the new instance.</p>
</dd>
<dt><code>param_set</code></dt><dd><p>(<a href="paradox.html#topic+ParamSet">paradox::ParamSet</a>)<br />
Set of hyperparameters.</p>
</dd>
<dt><code>duplicated_ids</code></dt><dd><p>(<code>logical(1)</code>)<br />
Set to <code>TRUE</code> if this resampling strategy may have duplicated row ids in a single training set or test set.
</p>
</dd>
<dt><code>label</code></dt><dd><p>(<code>character(1)</code>)<br />
Label for the new instance.</p>
</dd>
<dt><code>man</code></dt><dd><p>(<code>character(1)</code>)<br />
String in the format <code style="white-space: pre;">&#8288;[pkg]::[topic]&#8288;</code> pointing to a manual page for this object.
The referenced help package can be opened via method <code style="white-space: pre;">&#8288;$help()&#8288;</code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-Resampling-train_set"></a>



<h4>Method <code>train_set()</code></h4>

<p>Returns the row ids of the i-th training set.
</p>


<h5>Usage</h5>

<div class="r"><pre>Resampling$train_set(i)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>i</code></dt><dd><p>(<code>integer(1)</code>)<br />
Iteration.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>(<code>integer()</code>) of row ids.
</p>


<hr>
<a id="method-Resampling-test_set"></a>



<h4>Method <code>test_set()</code></h4>

<p>Returns the row ids of the i-th test set.
</p>


<h5>Usage</h5>

<div class="r"><pre>Resampling$test_set(i)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>i</code></dt><dd><p>(<code>integer(1)</code>)<br />
Iteration.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>(<code>integer()</code>) of row ids.
</p>




<h3>See Also</h3>


<ul>
<li><p> Blog post
<a href="https://tdhock.github.io/blog/2023/R-gen-new-subsets/">https://tdhock.github.io/blog/2023/R-gen-new-subsets/</a>
</p>
</li>
<li><p> Package <a href="https://CRAN.R-project.org/package=mlr3"><span class="pkg">mlr3</span></a> for standard
<code><a href="mlr3.html#topic+Resampling">Resampling</a></code>, which does not support comparing
train on same or other groups.
</p>
</li>
<li> <p><code><a href="#topic+score">score</a></code> and Simulations vignette for more detailed examples.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>same_other &lt;- mlr3resampling::ResamplingSameOtherCV$new()
same_other$param_set$values$folds &lt;- 5
</code></pre>

<hr>
<h2 id='ResamplingSameOtherSizesCV'>Resampling for comparing train subsets and sizes</h2><span id='topic+ResamplingSameOtherSizesCV'></span>

<h3>Description</h3>

<p><code><a href="#topic+ResamplingSameOtherSizesCV">ResamplingSameOtherSizesCV</a></code>
defines how a task is partitioned for
resampling, for example in
<code><a href="mlr3.html#topic+resample">resample()</a></code> or
<code><a href="mlr3.html#topic+benchmark">benchmark()</a></code>.
</p>
<p>Resampling objects can be instantiated on a
<code><a href="mlr3.html#topic+Task">Task</a></code>,
which should define at least one group variable.
</p>
<p>After instantiation, sets can be accessed via
<code style="white-space: pre;">&#8288;$train_set(i)&#8288;</code> and
<code style="white-space: pre;">&#8288;$test_set(i)&#8288;</code>, respectively. 
</p>


<h3>Details</h3>

<p>A supervised learning algorithm inputs a train set, and outputs a
prediction function, which can be used on a test set. If each data
point belongs to a group (such as geographic region, year, etc), then
how do we know if it is possible to train on one group, and predict
accurately on another group? Cross-validation can be used to determine
the extent to which this is possible, by first assigning fold IDs from
1 to K to all data (possibly using stratification, usually by group
and label). Then we loop over test sets (group/fold combinations),
train sets (same group, other groups, all groups), and compute
test/prediction accuracy for each combination.  Comparing
test/prediction accuracy between same and other, we can determine the
extent to which it is possible (perfect if same/other have similar
test accuracy for each group; other is usually somewhat less accurate
than same; other can be just as bad as featureless baseline when the
groups have different patterns).
</p>
<p>This class has more parameters/potential applications than
<code><a href="#topic+ResamplingSameOtherCV">ResamplingSameOtherCV</a></code> and
<code><a href="#topic+ResamplingVariableSizeTrainCV">ResamplingVariableSizeTrainCV</a></code>,
which are older and should only be preferred
for visualization purposes.
</p>


<h3>Stratification</h3>

<p><code><a href="#topic+ResamplingSameOtherSizesCV">ResamplingSameOtherSizesCV</a></code> supports stratified sampling.
The stratification variables are assumed to be discrete,
and must be stored in the <a href="mlr3.html#topic+Task">Task</a> with column role <code>"stratum"</code>.
In case of multiple stratification variables,
each combination of the values of the stratification variables forms a stratum.
</p>


<h3>Grouping</h3>

<p><code><a href="#topic+ResamplingSameOtherSizesCV">ResamplingSameOtherSizesCV</a></code> supports grouping of observations.
The grouping variable is assumed to be discrete,
and must be stored in the <a href="mlr3.html#topic+Task">Task</a> with column role <code>"group"</code>.
</p>


<h3>Subsets</h3>

<p><code><a href="#topic+ResamplingSameOtherSizesCV">ResamplingSameOtherSizesCV</a></code> supports training on different
subsets of observations.
The subset variable is assumed to be discrete,
and must be stored in the <a href="mlr3.html#topic+Task">Task</a> with column role <code>"subset"</code>.
</p>


<h3>Parameters</h3>

<p>The number of cross-validation folds K should be defined as the
<code>fold</code> parameter, default 3.
</p>
<p>The number of random seeds for down-sampling should be defined as the
<code>seeds</code> parameter, default 1.
</p>
<p>The ratio for down-sampling should be defined as the <code>ratio</code>
parameter, default 0.5. The min size of same and other sets is
repeatedly multiplied by this ratio, to obtain smaller sample sizes.
</p>
<p>The number of down-sampling sizes/multiplications should be defined as
the <code>sizes</code> parameter, which can also take two special values:
default -1 means no down-sampling at all, and 0 means only down-sampling
to the sizes of the same/other sets.
</p>
<p>The <code>ignore_subset</code> parameter should be either <code>TRUE</code> or
<code>FALSE</code> (default), whether to ignore the <code>subset</code>
role. <code>TRUE</code> only creates splits for same subset (even if task
defines <code>subset</code> role), and is useful for subtrain/validation
splits (hyper-parameter learning). Note that this feature will work on a
task with <code>stratum</code> and <code>group</code> roles (unlike
<code>ResamplingCV</code>).
</p>
<p>In each subset, there will be about an equal number of observations
assigned to each of the K folds.
The train/test splits are defined by all possible combinations of
test subset, test fold, train subsets (same/other/all), down-sampling
sizes, and random seeds.
The splits are stored in
<code style="white-space: pre;">&#8288;$instance$iteration.dt&#8288;</code>.
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-Resampling-new"><code>Resampling$new()</code></a>
</p>
</li>
<li> <p><a href="#method-Resampling-train_set"><code>Resampling$train_set()</code></a>
</p>
</li>
<li> <p><a href="#method-Resampling-test_set"><code>Resampling$test_set()</code></a>
</p>
</li></ul>


<hr>
<a id="method-Resampling-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>Resampling$new(
  id,
  param_set = ps(),
  duplicated_ids = FALSE,
  label = NA_character_,
  man = NA_character_
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier for the new instance.</p>
</dd>
<dt><code>param_set</code></dt><dd><p>(<a href="paradox.html#topic+ParamSet">paradox::ParamSet</a>)<br />
Set of hyperparameters.</p>
</dd>
<dt><code>duplicated_ids</code></dt><dd><p>(<code>logical(1)</code>)<br />
Set to <code>TRUE</code> if this resampling strategy may have duplicated row ids in a single training set or test set.
</p>
</dd>
<dt><code>label</code></dt><dd><p>(<code>character(1)</code>)<br />
Label for the new instance.</p>
</dd>
<dt><code>man</code></dt><dd><p>(<code>character(1)</code>)<br />
String in the format <code style="white-space: pre;">&#8288;[pkg]::[topic]&#8288;</code> pointing to a manual page for this object.
The referenced help package can be opened via method <code style="white-space: pre;">&#8288;$help()&#8288;</code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-Resampling-train_set"></a>



<h4>Method <code>train_set()</code></h4>

<p>Returns the row ids of the i-th training set.
</p>


<h5>Usage</h5>

<div class="r"><pre>Resampling$train_set(i)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>i</code></dt><dd><p>(<code>integer(1)</code>)<br />
Iteration.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>(<code>integer()</code>) of row ids.
</p>


<hr>
<a id="method-Resampling-test_set"></a>



<h4>Method <code>test_set()</code></h4>

<p>Returns the row ids of the i-th test set.
</p>


<h5>Usage</h5>

<div class="r"><pre>Resampling$test_set(i)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>i</code></dt><dd><p>(<code>integer(1)</code>)<br />
Iteration.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>(<code>integer()</code>) of row ids.
</p>




<h3>See Also</h3>


<ul>
<li><p> Blog post
<a href="https://tdhock.github.io/blog/2023/R-gen-new-subsets/">https://tdhock.github.io/blog/2023/R-gen-new-subsets/</a>
</p>
</li>
<li><p> Package <a href="https://CRAN.R-project.org/package=mlr3"><span class="pkg">mlr3</span></a> for standard
<code><a href="mlr3.html#topic+Resampling">Resampling</a></code>, which does not support comparing
train on same or other groups.
</p>
</li>
<li> <p><code><a href="#topic+score">score</a></code> and Simulations vignette for more detailed examples.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>same_other_sizes &lt;- mlr3resampling::ResamplingSameOtherSizesCV$new()
same_other_sizes$param_set$values$folds &lt;- 5
</code></pre>

<hr>
<h2 id='ResamplingVariableSizeTrainCV'>Resampling for comparing training on same or other groups</h2><span id='topic+ResamplingVariableSizeTrainCV'></span>

<h3>Description</h3>

<p><code><a href="#topic+ResamplingVariableSizeTrainCV">ResamplingVariableSizeTrainCV</a></code>
defines how a task is partitioned for
resampling, for example in
<code><a href="mlr3.html#topic+resample">resample()</a></code> or
<code><a href="mlr3.html#topic+benchmark">benchmark()</a></code>.
</p>
<p>Resampling objects can be instantiated on a
<code><a href="mlr3.html#topic+Task">Task</a></code>.
</p>
<p>After instantiation, sets can be accessed via
<code style="white-space: pre;">&#8288;$train_set(i)&#8288;</code> and
<code style="white-space: pre;">&#8288;$test_set(i)&#8288;</code>, respectively. 
</p>


<h3>Details</h3>

<p>A supervised learning algorithm inputs a train set, and outputs a
prediction function, which can be used on a test set.
How many train samples are required to get accurate predictions on a
test set? Cross-validation can be used to answer this question, with
variable size train sets.
</p>


<h3>Stratification</h3>

<p><code><a href="#topic+ResamplingVariableSizeTrainCV">ResamplingVariableSizeTrainCV</a></code> supports stratified sampling.
The stratification variables are assumed to be discrete,
and must be stored in the <a href="mlr3.html#topic+Task">Task</a> with column role <code>"stratum"</code>.
In case of multiple stratification variables,
each combination of the values of the stratification variables forms a stratum.
</p>


<h3>Grouping</h3>

<p><code><a href="#topic+ResamplingVariableSizeTrainCV">ResamplingVariableSizeTrainCV</a></code>
does not support grouping of observations.
</p>


<h3>Hyper-parameters</h3>

<p>The number of cross-validation folds should be defined as the
<code>fold</code> parameter.
</p>
<p>For each fold ID, the corresponding observations are considered the
test set, and a variable number of other observations are considered
the train set.
</p>
<p>The <code>random_seeds</code> parameter controls the number of random
orderings of the train set that are considered.
</p>
<p>For each random order of the train set, the <code>min_train_data</code>
parameter controls the size of the smallest stratum in the smallest
train set considered.
</p>
<p>To determine the other train set sizes, we use an equally spaced grid
on the log scale, from <code>min_train_data</code> to the largest train set
size (all data not in test set). The
number of train set sizes in this grid is determined by the
<code>train_sizes</code> parameter.
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-Resampling-new"><code>Resampling$new()</code></a>
</p>
</li>
<li> <p><a href="#method-Resampling-train_set"><code>Resampling$train_set()</code></a>
</p>
</li>
<li> <p><a href="#method-Resampling-test_set"><code>Resampling$test_set()</code></a>
</p>
</li></ul>


<hr>
<a id="method-Resampling-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>Resampling$new(
  id,
  param_set = ps(),
  duplicated_ids = FALSE,
  label = NA_character_,
  man = NA_character_
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier for the new instance.</p>
</dd>
<dt><code>param_set</code></dt><dd><p>(<a href="paradox.html#topic+ParamSet">paradox::ParamSet</a>)<br />
Set of hyperparameters.</p>
</dd>
<dt><code>duplicated_ids</code></dt><dd><p>(<code>logical(1)</code>)<br />
Set to <code>TRUE</code> if this resampling strategy may have duplicated row ids in a single training set or test set.
</p>
</dd>
<dt><code>label</code></dt><dd><p>(<code>character(1)</code>)<br />
Label for the new instance.</p>
</dd>
<dt><code>man</code></dt><dd><p>(<code>character(1)</code>)<br />
String in the format <code style="white-space: pre;">&#8288;[pkg]::[topic]&#8288;</code> pointing to a manual page for this object.
The referenced help package can be opened via method <code style="white-space: pre;">&#8288;$help()&#8288;</code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-Resampling-train_set"></a>



<h4>Method <code>train_set()</code></h4>

<p>Returns the row ids of the i-th training set.
</p>


<h5>Usage</h5>

<div class="r"><pre>Resampling$train_set(i)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>i</code></dt><dd><p>(<code>integer(1)</code>)<br />
Iteration.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>(<code>integer()</code>) of row ids.
</p>


<hr>
<a id="method-Resampling-test_set"></a>



<h4>Method <code>test_set()</code></h4>

<p>Returns the row ids of the i-th test set.
</p>


<h5>Usage</h5>

<div class="r"><pre>Resampling$test_set(i)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>i</code></dt><dd><p>(<code>integer(1)</code>)<br />
Iteration.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>(<code>integer()</code>) of row ids.
</p>




<h3>Examples</h3>

<pre><code class='language-R'>(var_sizes &lt;- mlr3resampling::ResamplingVariableSizeTrainCV$new())
</code></pre>

<hr>
<h2 id='score'>
Score benchmark results
</h2><span id='topic+score'></span>

<h3>Description</h3>

<p>Computes a data table of scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>score(bench.result, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="score_+3A_bench.result">bench.result</code></td>
<td>

<p>Output of <code><a href="mlr3.html#topic+benchmark">benchmark()</a></code>.
</p>
</td></tr>
<tr><td><code id="score_+3A_...">...</code></td>
<td>

<p>Additional arguments to pass to <code>bench.result$score</code>, for
example <code>measures</code>. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data table with scores.
</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
N &lt;- 100
library(data.table)
set.seed(1)
reg.dt &lt;- data.table(
  x=runif(N, -2, 2),
  person=rep(1:2, each=0.5*N))
reg.pattern.list &lt;- list(
  easy=function(x, person)x^2,
  impossible=function(x, person)(x^2+person*3)*(-1)^person)
reg.task.list &lt;- list()
for(pattern in names(reg.pattern.list)){
  f &lt;- reg.pattern.list[[pattern]]
  yname &lt;- paste0("y_",pattern)
  reg.dt[, (yname) := f(x,person)+rnorm(N, sd=0.5)][]
  task.dt &lt;- reg.dt[, c("x","person",yname), with=FALSE]
  task.obj &lt;- mlr3::TaskRegr$new(
    pattern, task.dt, target=yname)
  task.obj$col_roles$stratum &lt;- "person"
  task.obj$col_roles$subset &lt;- "person"
  reg.task.list[[pattern]] &lt;- task.obj
}
same_other &lt;- mlr3resampling::ResamplingSameOtherSizesCV$new()
reg.learner.list &lt;- list(
  mlr3::LearnerRegrFeatureless$new())
if(requireNamespace("rpart")){
  reg.learner.list$rpart &lt;- mlr3::LearnerRegrRpart$new()
}
(bench.grid &lt;- mlr3::benchmark_grid(
  reg.task.list,
  reg.learner.list,
  same_other))
bench.result &lt;- mlr3::benchmark(bench.grid)
bench.score &lt;- mlr3resampling::score(bench.result)
if(require(animint2)){
  ggplot()+
    geom_point(aes(
      regr.mse, train.subsets, color=algorithm),
      shape=1,
      data=bench.score)+
    facet_grid(
      test.subset ~ task_id,
      labeller=label_both,
      scales="free")+
    scale_x_log10()
}

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
