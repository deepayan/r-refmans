<!DOCTYPE html><html><head><title>Help for package rsvd</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {rsvd}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#digits'><p>Digits</p></a></li>
<li><a href='#ggbiplot'><p>Biplot for <code>rpca</code> using <code>ggplot</code>.</p></a></li>
<li><a href='#ggcorplot'><p>Variables factor map for <code>rpca</code> using <code>ggplot</code>.</p></a></li>
<li><a href='#ggindplot'><p>Individual factor map for <code>rpca</code> using <code>ggplot</code>.</p></a></li>
<li><a href='#ggscreeplot'><p>Pretty Screeplot</p></a></li>
<li><a href='#plot.rpca'><p>Screeplot</p></a></li>
<li><a href='#rcur'><p>Randomized CUR matrix decomposition.</p></a></li>
<li><a href='#rid'><p>Randomized interpolative decomposition (ID).</p></a></li>
<li><a href='#rpca'><p>Randomized principal component analysis (rpca).</p></a></li>
<li><a href='#rqb'><p>Randomized QB Decomposition (rqb).</p></a></li>
<li><a href='#rrpca'><p>Randomized robust principal component analysis (rrpca).</p></a></li>
<li><a href='#rsvd'><p>Randomized Singular Value Decomposition (rsvd).</p></a></li>
<li><a href='#tiger'><p>Tiger</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Randomized Singular Value Decomposition</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.5</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-04-11</td>
</tr>
<tr>
<td>Author:</td>
<td>N. Benjamin Erichson [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>N. Benjamin Erichson &lt;erichson@berkeley.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Low-rank matrix decompositions are fundamental tools and widely used for data
  analysis, dimension reduction, and data compression. Classically, highly accurate 
  deterministic matrix algorithms are used for this task. However, the emergence of 
  large-scale data has severely challenged our computational ability to analyze big data. 
  The concept of randomness has been demonstrated as an effective strategy to quickly produce
  approximate answers to familiar problems such as the singular value decomposition (SVD). 
  The rsvd package provides several randomized matrix algorithms such as the randomized 
  singular value decomposition (rsvd), randomized principal component analysis (rpca), 
  randomized robust principal component analysis (rrpca), randomized interpolative 
  decomposition (rid), and the randomized CUR decomposition (rcur). In addition several plot 
  functions are provided.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Matrix</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>LazyDataCompression:</td>
<td>xz</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/erichson/rSVD">https://github.com/erichson/rSVD</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/erichson/rSVD/issues">https://github.com/erichson/rSVD/issues</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td>ggplot2, testthat</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-04-14 17:52:09 UTC; ben</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-04-16 05:40:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='digits'>Digits</h2><span id='topic+digits'></span>

<h3>Description</h3>

<p>Subsampled MNIST database of handwritten digits. This smaller dataset has 3000 samples for each
of the digits corresponding to the class labels 0,1,2,3. Each 28x28 image patch is stored as a flattened row vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data('digits')
</code></pre>


<h3>Format</h3>

<p>An object of class <code><a href="#topic+rsvd">rsvd</a></code>.
</p>


<h3>References</h3>

<p>Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. 
&quot;Gradient-based learning applied to document recognition.&quot; 
Proceedings of the IEEE, 86(11):2278-2324, November 1998.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library('rsvd')
data('digits')

#Display first digit
digit &lt;- matrix(digits[1,], nrow = 28, ncol = 28)
image(digit[,28:1], col = gray(255:0 / 255))

## End(Not run)   

</code></pre>

<hr>
<h2 id='ggbiplot'>Biplot for <code><a href="#topic+rpca">rpca</a></code> using <code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>.</h2><span id='topic+ggbiplot'></span>

<h3>Description</h3>

<p>Creates a pretty biplot which is showing the individual factor map overlayed by the
variables factor map, i.e, plotting both the principal component scores and directions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ggbiplot(
  rpcaObj,
  pcs = c(1, 2),
  loadings = TRUE,
  groups = NULL,
  alpha = 0.6,
  ellipse = TRUE,
  alpha.ellipse = 0.2,
  var_labels = TRUE,
  var_labels.names = NULL,
  ind_labels = TRUE,
  ind_labels.names = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ggbiplot_+3A_rpcaobj">rpcaObj</code></td>
<td>
<p>Object returned by the <code><a href="#topic+rpca">rpca</a></code> function.</p>
</td></tr>
<tr><td><code id="ggbiplot_+3A_pcs">pcs</code></td>
<td>
<p>Array_like. <br />
An array with two values indicating the two PCs which should be used for plotting. 
By default the first two PCs are used, e.g., <code class="reqn">c(1,2)</code>.</p>
</td></tr>
<tr><td><code id="ggbiplot_+3A_loadings">loadings</code></td>
<td>
<p>Bool (<code class="reqn">TRUE</code>, <code class="reqn">FALSE</code>), optional. <br />
If <code class="reqn">TRUE</code>, the eigenvectors
are unit scaled by the square root of the eigenvalues <code class="reqn">W = W * diag(sqrt(eigvals))</code>.</p>
</td></tr>
<tr><td><code id="ggbiplot_+3A_groups">groups</code></td>
<td>
<p>Factor, optional. <br />
Factor indicating groups.</p>
</td></tr>
<tr><td><code id="ggbiplot_+3A_alpha">alpha</code></td>
<td>
<p>Scalar, optional. <br />
Alpha transparency for scatter plot.</p>
</td></tr>
<tr><td><code id="ggbiplot_+3A_ellipse">ellipse</code></td>
<td>
<p>Bool (<code class="reqn">TRUE</code>, <code class="reqn">FALSE</code>), optional. <br />
Draw a 1sd data ellipse for each group, if <code class="reqn">TRUE</code>.</p>
</td></tr>
<tr><td><code id="ggbiplot_+3A_alpha.ellipse">alpha.ellipse</code></td>
<td>
<p>Scalar, optional. <br />
Alpha transparency for ellipse.</p>
</td></tr>
<tr><td><code id="ggbiplot_+3A_var_labels">var_labels</code></td>
<td>
<p>Bool (<code class="reqn">TRUE</code>, <code class="reqn">FALSE</code>), optional. <br />
Plot variable names, if <code class="reqn">TRUE</code>.</p>
</td></tr>
<tr><td><code id="ggbiplot_+3A_var_labels.names">var_labels.names</code></td>
<td>
<p>Array_like, optional. <br />
User specific labels for the individuals.</p>
</td></tr>
<tr><td><code id="ggbiplot_+3A_ind_labels">ind_labels</code></td>
<td>
<p>Bool (<code class="reqn">TRUE</code>, <code class="reqn">FALSE</code>), optional. <br />
Plot data point names, if <code class="reqn">TRUE</code>.</p>
</td></tr>
<tr><td><code id="ggbiplot_+3A_ind_labels.names">ind_labels.names</code></td>
<td>
<p>Array_like, optional. <br />
User specific labels for data points.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>N. Benjamin Erichson, <a href="mailto:erichson@berkeley.edu">erichson@berkeley.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rpca">rpca</a></code>, <code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See ?rpca
</code></pre>

<hr>
<h2 id='ggcorplot'>Variables factor map for <code><a href="#topic+rpca">rpca</a></code> using <code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>.</h2><span id='topic+ggcorplot'></span>

<h3>Description</h3>

<p>Creates a pretty plot which is showing the correlation of
the original variable with the principal component (PCs).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ggcorplot(
  rpcaObj,
  pcs = c(1, 2),
  loadings = TRUE,
  var_labels = FALSE,
  var_labels.names = NULL,
  alpha = 1,
  top.n = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ggcorplot_+3A_rpcaobj">rpcaObj</code></td>
<td>
<p>Object returned by the <code><a href="#topic+rpca">rpca</a></code> function.</p>
</td></tr>
<tr><td><code id="ggcorplot_+3A_pcs">pcs</code></td>
<td>
<p>Array_like. <br />
An array with two values indicating the two PCs which should be used for plotting. 
By default the first two PCs are used, e.g., <code class="reqn">c(1,2)</code>.</p>
</td></tr>
<tr><td><code id="ggcorplot_+3A_loadings">loadings</code></td>
<td>
<p>Bool (<code class="reqn">TRUE</code>, <code class="reqn">FALSE</code>), optional. <br />
If <code class="reqn">TRUE</code>, the eigenvectors
are unit scaled by the square root of the eigenvalues <code class="reqn">W = W * diag(sqrt(eigvals))</code>.</p>
</td></tr>
<tr><td><code id="ggcorplot_+3A_var_labels">var_labels</code></td>
<td>
<p>Bool (<code class="reqn">TRUE</code>, <code class="reqn">FALSE</code>), optional. <br />
Plot variable names, if <code class="reqn">TRUE</code>.</p>
</td></tr>
<tr><td><code id="ggcorplot_+3A_var_labels.names">var_labels.names</code></td>
<td>
<p>Array_like, optional. <br />
User specific labels for the variables</p>
</td></tr>
<tr><td><code id="ggcorplot_+3A_alpha">alpha</code></td>
<td>
<p>Scalar, optional. <br />
Alpha transparency of the arrows.</p>
</td></tr>
<tr><td><code id="ggcorplot_+3A_top.n">top.n</code></td>
<td>
<p>Scalar, optional. <br />
Number of (most influencial) variables to label with small circles.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>N. Benjamin Erichson, <a href="mailto:erichson@berkeley.edu">erichson@berkeley.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rpca">rpca</a></code>, <code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#

</code></pre>

<hr>
<h2 id='ggindplot'>Individual factor map for <code><a href="#topic+rpca">rpca</a></code> using <code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>.</h2><span id='topic+ggindplot'></span>

<h3>Description</h3>

<p>Creates a pretty plot which is showing the individual factor map, i.e,
plotting the principal component scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ggindplot(
  rpcaObj,
  pcs = c(1, 2),
  groups = NULL,
  alpha = 0.6,
  ellipse = TRUE,
  alpha.ellipse = 0.2,
  ind_labels = TRUE,
  ind_labels.names = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ggindplot_+3A_rpcaobj">rpcaObj</code></td>
<td>
<p>Object returned by the <code><a href="#topic+rpca">rpca</a></code> function.</p>
</td></tr>
<tr><td><code id="ggindplot_+3A_pcs">pcs</code></td>
<td>
<p>Array_like. <br />
An array with two values indicating the two PCs which should be used for plotting. 
By default the first two PCs are used, e.g., <code class="reqn">c(1,2)</code>.</p>
</td></tr>
<tr><td><code id="ggindplot_+3A_groups">groups</code></td>
<td>
<p>Factor, optional. <br />
Factor indicating groups.</p>
</td></tr>
<tr><td><code id="ggindplot_+3A_alpha">alpha</code></td>
<td>
<p>Scalar, optional. <br />
Alpha transparency for scatter plot.</p>
</td></tr>
<tr><td><code id="ggindplot_+3A_ellipse">ellipse</code></td>
<td>
<p>Bool (<code class="reqn">TRUE</code>, <code class="reqn">FALSE</code>), optional. <br />
Draw a 1sd data ellipse for each group, if <code class="reqn">TRUE</code>.</p>
</td></tr>
<tr><td><code id="ggindplot_+3A_alpha.ellipse">alpha.ellipse</code></td>
<td>
<p>Scalar, optional. <br />
Alpha transparency for ellipse.</p>
</td></tr>
<tr><td><code id="ggindplot_+3A_ind_labels">ind_labels</code></td>
<td>
<p>Bool (<code class="reqn">TRUE</code>, <code class="reqn">FALSE</code>), optional. <br />
Plot names for each individual point, if <code class="reqn">TRUE</code>.</p>
</td></tr>
<tr><td><code id="ggindplot_+3A_ind_labels.names">ind_labels.names</code></td>
<td>
<p>Array_like, optional. <br />
User specific labels for the individual points.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>N. Benjamin Erichson, <a href="mailto:erichson@berkeley.edu">erichson@berkeley.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rpca">rpca</a></code>, <code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See ?rpca
</code></pre>

<hr>
<h2 id='ggscreeplot'>Pretty Screeplot</h2><span id='topic+ggscreeplot'></span>

<h3>Description</h3>

<p>Creates a pretty screeplpot using <code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>. By default the explained variance is plotted
agaings the number of the principal component.
Alternatively the explained variance ratio, the cumulative
explained variance ratio, or the eigenvalues can be plotted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ggscreeplot(rpcaObj, type = c("var", "ratio", "cum", "eigenvals"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ggscreeplot_+3A_rpcaobj">rpcaObj</code></td>
<td>
<p>Object returned by the <code><a href="#topic+rpca">rpca</a></code> function.</p>
</td></tr>
<tr><td><code id="ggscreeplot_+3A_type">type</code></td>
<td>
<p>String c('var', 'ratio', 'cum', 'eigenvals'), optional. <br /></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>N. Benjamin Erichson, <a href="mailto:erichson@berkeley.edu">erichson@berkeley.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rpca">rpca</a></code>, <code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#

</code></pre>

<hr>
<h2 id='plot.rpca'>Screeplot</h2><span id='topic+plot.rpca'></span>

<h3>Description</h3>

<p>Creates a screeplot, variables and individual factor maps to
summarize the results of the <code><a href="#topic+rpca">rpca</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rpca'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.rpca_+3A_x">x</code></td>
<td>
<p>Object returned by the <code><a href="#topic+rpca">rpca</a></code> function.</p>
</td></tr>
<tr><td><code id="plot.rpca_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the individual plot functions (see below).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+ggscreeplot">ggscreeplot</a></code>, <code><a href="#topic+ggcorplot">ggcorplot</a></code> , <code><a href="#topic+ggindplot">ggindplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#

</code></pre>

<hr>
<h2 id='rcur'>Randomized CUR matrix decomposition.</h2><span id='topic+rcur'></span>

<h3>Description</h3>

<p>Randomized CUR matrix decomposition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rcur(A, k = NULL, p = 10, q = 0, idx_only = FALSE, rand = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rcur_+3A_a">A</code></td>
<td>
<p>array_like; <br />
numeric <code class="reqn">(m, n)</code> input matrix (or data frame). <br />
If the data contain <code class="reqn">NA</code>s na.omit is applied.</p>
</td></tr>
<tr><td><code id="rcur_+3A_k">k</code></td>
<td>
<p>integer; <br />
target rank of the low-rank approximation, i.e., the number of columns/rows
to be selected. It is required that <code class="reqn">k</code> is smaller or equal to <code class="reqn">min(m,n)</code>.</p>
</td></tr>
<tr><td><code id="rcur_+3A_p">p</code></td>
<td>
<p>integer, optional; <br />
oversampling parameter (default <code class="reqn">p=10</code>).</p>
</td></tr>
<tr><td><code id="rcur_+3A_q">q</code></td>
<td>
<p>integer, optional; <br />
number of additional power iterations (default <code class="reqn">q=0</code>).</p>
</td></tr>
<tr><td><code id="rcur_+3A_idx_only">idx_only</code></td>
<td>
<p>bool, optional; <br />
if (<code class="reqn">TRUE</code>), only the index set <code>C.idx</code> and <code>R.idx</code> is returned, but not 
the matrices <code>C</code> and <code>R</code>. 
This is more memory efficient, when dealing with large-scale data.</p>
</td></tr>
<tr><td><code id="rcur_+3A_rand">rand</code></td>
<td>
<p>bool, optional; <br />
if (<code class="reqn">TRUE</code>), a probabilistic strategy is used, otherwise a deterministic algorithm is used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Algorithm for computing the CUR matrix decomposition of a rectangular <code class="reqn">(m, n)</code> matrix <code class="reqn">A</code>, 
with target rank <code class="reqn">k &lt;&lt; min(m,n)</code>. The input matrix is factored as 
</p>
<p style="text-align: center;"><code class="reqn">A = C * U * R</code>
</p>
 
<p>using the <code><a href="#topic+rid">rid</a></code> decomposition. The factor matrix <code class="reqn">C</code> is formed using actual 
columns of <code class="reqn">A</code>, also called the partial column skeleton. The factor matrix <code class="reqn">R</code> is formed 
using actual rows of <code class="reqn">A</code>, also called the partial row skeleton.
</p>
<p>If <code class="reqn">rand=TRUE</code> a probabilistic strategy is used to compute the decomposition, otherwise a
deterministic algorithm is used.
</p>


<h3>Value</h3>

<p><code>rcur</code> returns a list with class <code class="reqn">id</code> containing the following components:
</p>

<dl>
<dt>C</dt><dd><p> array_like; <br />
column subset <code class="reqn">C = A[,C.idx]</code>; <code class="reqn">(m, k)</code> dimensional array.
</p>
</dd>
<dt>R</dt><dd><p> Array_like. <br />
row subset <code class="reqn">R = A[R.idx, ]</code>; <code class="reqn">(k, n)</code> dimensional array.
</p>
</dd>
<dt>U</dt><dd><p> array_like; <br />
connector matrix; <code class="reqn">(k,k)</code> dimensional array.
</p>
</dd>
<dt>C.idx</dt><dd><p> array_like; <br />
index set of the <code class="reqn">k</code> selected columns used to form <code class="reqn">C</code>. 
</p>
</dd>   
<dt>R.idx</dt><dd><p> array_like; <br />
index set of the <code class="reqn">k</code> selected rows used to form <code class="reqn">R</code>. 
</p>
</dd>   
<dt>C.scores</dt><dd><p> array_like; <br />
scores of the selected columns.
</p>
</dd> 
<dt>R.scores</dt><dd><p> array_like; <br />
scores  of the selected rows.
</p>
</dd>                   
</dl>



<h3>Author(s)</h3>

<p>N. Benjamin Erichson, <a href="mailto:erichson@berkeley.edu">erichson@berkeley.edu</a>
</p>


<h3>References</h3>


<ul>
<li><p> [1] N. B. Erichson, S. Voronin, S. L. Brunton and J. N. Kutz. 2019.
Randomized Matrix Decompositions Using R. 
Journal of Statistical Software, 89(11), 1-48.
doi: <a href="https://doi.org/10.18637/jss.v089.i11">10.18637/jss.v089.i11</a>.
</p>
</li>
<li><p>  [2] N. Halko, P. Martinsson, and J. Tropp.
&quot;Finding structure with randomness: probabilistic
algorithms for constructing approximate matrix
decompositions&quot; (2009).
(available at arXiv <a href="https://arxiv.org/abs/0909.4061">https://arxiv.org/abs/0909.4061</a>).
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+rid">rid</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Load test image
data('tiger')

# Compute (column) randomized interpolative decompsition
# Note that the image needs to be transposed for correct plotting
out &lt;- rcur(tiger, k = 150)

# Reconstruct image
tiger.re &lt;- out$C %*% out$U %*% out$R

# Compute relative error
print(norm(tiger-tiger.re, 'F') / norm(tiger, 'F')) 

# Plot approximated image
image(tiger.re, col = gray((0:255)/255))

## End(Not run)
</code></pre>

<hr>
<h2 id='rid'>Randomized interpolative decomposition (ID).</h2><span id='topic+rid'></span>

<h3>Description</h3>

<p>Randomized interpolative decomposition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rid(A, k = NULL, mode = "column", p = 10, q = 0, idx_only = FALSE, rand = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rid_+3A_a">A</code></td>
<td>
<p>array_like; <br />
numeric <code class="reqn">(m, n)</code> input matrix (or data frame). <br />
If the data contain <code class="reqn">NA</code>s na.omit is applied.</p>
</td></tr>
<tr><td><code id="rid_+3A_k">k</code></td>
<td>
<p>integer, optional; <br />
number of rows/columns to be selected. 
It is required that <code class="reqn">k</code> is smaller or equal to <code class="reqn">min(m,n)</code>.</p>
</td></tr>
<tr><td><code id="rid_+3A_mode">mode</code></td>
<td>
<p>string c('column', 'row'), optional; <br />
columns or rows ID.</p>
</td></tr>
<tr><td><code id="rid_+3A_p">p</code></td>
<td>
<p>integer, optional; <br />
oversampling parameter (default <code class="reqn">p=10</code>).</p>
</td></tr>
<tr><td><code id="rid_+3A_q">q</code></td>
<td>
<p>integer, optional. <br />
number of additional power iterations (default <code class="reqn">q=0</code>).</p>
</td></tr>
<tr><td><code id="rid_+3A_idx_only">idx_only</code></td>
<td>
<p>bool, optional; <br />
if (<code class="reqn">TRUE</code>), the index set <code>idx</code> is returned, but not the matrix <code>C</code> or <code>R</code>. 
This is more memory efficient, when dealing with large-scale data.</p>
</td></tr>
<tr><td><code id="rid_+3A_rand">rand</code></td>
<td>
<p>bool, optional; <br />
if (<code class="reqn">TRUE</code>), a probabilistic strategy is used, otherwise a deterministic algorithm is used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Algorithm for computing the ID of a rectangular <code class="reqn">(m, n)</code> matrix <code class="reqn">A</code>, with target rank 
<code class="reqn">k &lt;&lt; min(m,n)</code>. The input matrix is factored as 
</p>
<p style="text-align: center;"><code class="reqn">A = C * Z</code>
</p>
 
<p>using the column pivoted QR decomposition. The factor matrix <code class="reqn">C</code> is formed as a subset of 
columns of <code class="reqn">A</code>, also called the partial column skeleton. 
If <code>mode='row'</code>, then the input matrix is factored as 
</p>
<p style="text-align: center;"><code class="reqn">A = Z * R</code>
</p>
 
<p>using the row pivoted QR decomposition. The factor matrix <code class="reqn">R</code> is now formed as
a subset of rows of <code class="reqn">A</code>, also called the partial row skeleton. 
The factor matrix <code class="reqn">Z</code> contains a <code class="reqn">(k, k)</code> identity matrix as a submatrix, 
and is well-conditioned. 
</p>
<p>If <code class="reqn">rand='TRUE'</code> a probabilistic strategy is used to compute the decomposition, otherwise a
deterministic algorithm is used.
</p>


<h3>Value</h3>

<p><code>rid</code> returns a list containing the following components:
</p>

<dl>
<dt>C</dt><dd><p> array_like; <br />
column subset <code class="reqn">C = A[,idx]</code>, if <code>mode='column'</code>; array with dimensions <code class="reqn">(m, k)</code>.
</p>
</dd>
<dt>R</dt><dd><p> array_like; <br />
row subset <code class="reqn">R = A[idx, ]</code>, if <code>mode='row'</code>; array with dimensions <code class="reqn">(k, n)</code>.
</p>
</dd>
<dt>Z</dt><dd><p> array_like; <br />
well conditioned matrix; Depending on the selected mode, this is an 
array with dimensions <code class="reqn">(k,n)</code> or <code class="reqn">(m,k)</code>.
</p>
</dd>
<dt>idx</dt><dd><p> array_like; <br />
index set of the <code class="reqn">k</code> selected columns or rows used to form <code class="reqn">C</code> or <code class="reqn">R</code>. 
</p>
</dd>   
<dt>pivot</dt><dd><p> array_like; <br />
information on the pivoting strategy used during the decomposition. 
</p>
</dd>  
<dt>scores</dt><dd><p> array_like; <br />
scores of the columns or rows of the input matrix <code class="reqn">A</code>.
</p>
</dd> 
<dt>scores.idx</dt><dd><p> array_like; <br />
scores of the <code class="reqn">k</code> selected columns or rows in <code class="reqn">C</code> or <code class="reqn">R</code>.                    
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>N. Benjamin Erichson, <a href="mailto:erichson@uw.edu">erichson@uw.edu</a>
</p>


<h3>References</h3>


<ul>
<li><p>  [1] N. Halko, P. Martinsson, and J. Tropp.
&quot;Finding structure with randomness: probabilistic
algorithms for constructing approximate matrix
decompositions&quot; (2009).
(available at arXiv <a href="https://arxiv.org/abs/0909.4061">https://arxiv.org/abs/0909.4061</a>).
</p>
</li>
<li><p> [2] N. B. Erichson, S. Voronin, S. L. Brunton and J. N. Kutz. 2019.
Randomized Matrix Decompositions Using R. 
Journal of Statistical Software, 89(11), 1-48.
doi: <a href="https://doi.org/10.18637/jss.v089.i11">10.18637/jss.v089.i11</a>.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+rcur">rcur</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Load test image
data("tiger")

# Compute (column) randomized interpolative decompsition
# Note that the image needs to be transposed for correct plotting
out &lt;- rid(t(tiger), k = 150)

# Show selected columns 
tiger.partial &lt;- matrix(0, 1200, 1600)
tiger.partial[,out$idx] &lt;- t(tiger)[,out$idx]
image(t(tiger.partial), col = gray((0:255)/255), useRaster = TRUE)

# Reconstruct image
tiger.re &lt;- t(out$C %*% out$Z)

# Compute relative error
print(norm(tiger-tiger.re, 'F') / norm(tiger, 'F')) 

# Plot approximated image
image(tiger.re, col = gray((0:255)/255))

## End(Not run)
</code></pre>

<hr>
<h2 id='rpca'>Randomized principal component analysis (rpca).</h2><span id='topic+rpca'></span>

<h3>Description</h3>

<p>Fast computation of the principal components analysis using the randomized singular value decomposition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rpca(
  A,
  k = NULL,
  center = TRUE,
  scale = TRUE,
  retx = TRUE,
  p = 10,
  q = 2,
  rand = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rpca_+3A_a">A</code></td>
<td>
<p>array_like; <br />
a numeric <code class="reqn">(m, n)</code> input matrix (or data frame) to be analyzed. <br />
If the data contain <code class="reqn">NA</code>s na.omit is applied.</p>
</td></tr>
<tr><td><code id="rpca_+3A_k">k</code></td>
<td>
<p>integer; <br />
number of dominant principle components to be computed. It is required that <code class="reqn">k</code> is smaller or equal to
<code class="reqn">min(m,n)</code>, but it is recommended that <code class="reqn">k &lt;&lt; min(m,n)</code>.</p>
</td></tr>
<tr><td><code id="rpca_+3A_center">center</code></td>
<td>
<p>bool, optional; <br />
logical value which indicates whether the variables should be
shifted to be zero centered (<code class="reqn">TRUE</code> by default).</p>
</td></tr>
<tr><td><code id="rpca_+3A_scale">scale</code></td>
<td>
<p>bool, optional; <br />
logical value which indicates whether the variables should
be scaled to have unit variance (<code class="reqn">TRUE</code> by default).</p>
</td></tr>
<tr><td><code id="rpca_+3A_retx">retx</code></td>
<td>
<p>bool, optional; <br />
logical value indicating whether the rotated variables / scores
should be returned (<code class="reqn">TRUE</code> by default).</p>
</td></tr>
<tr><td><code id="rpca_+3A_p">p</code></td>
<td>
<p>integer, optional; <br />
oversampling parameter for <code class="reqn">rsvd</code> (default <code class="reqn">p=10</code>), see <code><a href="#topic+rsvd">rsvd</a></code>.</p>
</td></tr>
<tr><td><code id="rpca_+3A_q">q</code></td>
<td>
<p>integer, optional; <br />
number of additional power iterations for <code class="reqn">rsvd</code> (default <code class="reqn">q=1</code>), see <code><a href="#topic+rsvd">rsvd</a></code>.</p>
</td></tr>
<tr><td><code id="rpca_+3A_rand">rand</code></td>
<td>
<p>bool, optional; <br />
if (<code class="reqn">TRUE</code>), the <code class="reqn">rsvd</code> routine is used, otherwise <code class="reqn">svd</code> is used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Principal component analysis is an important linear dimension reduction technique.
</p>
<p>Randomized PCA is computed via the randomized SVD algorithm (<code><a href="#topic+rsvd">rsvd</a></code>).
The computational gain is substantial, if the desired number of principal components
is relatively small, i.e. <code class="reqn">k &lt;&lt; min(m,n)</code>.
</p>
<p>The print and summary method can be used to present the results in a nice format.
A scree plot can be produced with <code><a href="#topic+ggscreeplot">ggscreeplot</a></code>. 
The individuals factor map can be produced with <code><a href="#topic+ggindplot">ggindplot</a></code>,
and a correlation plot with <code><a href="#topic+ggcorplot">ggcorplot</a></code>.
</p>
<p>The predict function can be used to compute the scores of new observations. The data
will automatically be centered (and scaled if requested). This is not fully supported for
complex input matrices.
</p>


<h3>Value</h3>

<p><code>rpca</code> returns a list with class <code class="reqn">rpca</code> containing the following components:
</p>

<dl>
<dt>rotation</dt><dd><p>  array_like; <br />
the rotation (eigenvectors); <code class="reqn">(n, k)</code> dimensional array.
</p>
</dd>
<dt>eigvals</dt><dd><p>  array_like; <br />
eigenvalues; <code class="reqn">k</code> dimensional vector.
</p>
</dd>
<dt>sdev</dt><dd><p>     array_like; <br />
standard deviations of the principal components; <code class="reqn">k</code> dimensional vector.
</p>
</dd>
<dt>x</dt><dd><p>        array_like; <br />
the scores / rotated data; <code class="reqn">(m, k)</code> dimensional array.
</p>
</dd>
<dt>center, scale</dt><dd><p>  array_like; <br />
the centering and scaling used.
</p>
</dd>
</dl>



<h3>Note</h3>

<p>The principal components are not unique and only defined up to sign
(a constant of modulus one in the complex case) and so may differ between different
PCA implementations.
</p>
<p>Similar to <code><a href="stats.html#topic+prcomp">prcomp</a></code> the variances are computed with the usual divisor N - 1.
</p>


<h3>Author(s)</h3>

<p>N. Benjamin Erichson, <a href="mailto:erichson@berkeley.edu">erichson@berkeley.edu</a>
</p>


<h3>References</h3>


<ul>
<li><p> [1] N. B. Erichson, S. Voronin, S. L. Brunton and J. N. Kutz. 2019.
Randomized Matrix Decompositions Using R. 
Journal of Statistical Software, 89(11), 1-48.
doi: <a href="https://doi.org/10.18637/jss.v089.i11">10.18637/jss.v089.i11</a>.
</p>
</li>
<li><p>  [2] N. Halko, P. Martinsson, and J. Tropp.
&quot;Finding structure with randomness: probabilistic
algorithms for constructing approximate matrix
decompositions&quot; (2009).
(available at arXiv <a href="https://arxiv.org/abs/0909.4061">https://arxiv.org/abs/0909.4061</a>).
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+ggscreeplot">ggscreeplot</a></code>, <code><a href="#topic+ggindplot">ggindplot</a></code>,
<code><a href="#topic+ggcorplot">ggcorplot</a></code>, <code><a href="#topic+plot.rpca">plot.rpca</a></code>,
<code><a href="stats.html#topic+predict">predict</a></code>,   <code><a href="#topic+rsvd">rsvd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library('rsvd')
#
# Load Edgar Anderson's Iris Data
#
data('iris')

#
# log transform
#
log.iris &lt;- log( iris[ , 1:4] )
iris.species &lt;- iris[ , 5]

#
# Perform rPCA and compute only the first two PCs
#
iris.rpca &lt;- rpca(log.iris, k=2)
summary(iris.rpca) # Summary
print(iris.rpca) # Prints the rotations

#
# Use rPCA to compute all PCs, similar to \code{\link{prcomp}}
#
iris.rpca &lt;- rpca(log.iris)
summary(iris.rpca) # Summary
print(iris.rpca) # Prints the rotations
plot(iris.rpca) # Produce screeplot, variable and individuls factor maps.

</code></pre>

<hr>
<h2 id='rqb'>Randomized QB Decomposition (rqb).</h2><span id='topic+rqb'></span>

<h3>Description</h3>

<p>Compute the near-optimal QB decomposition of a rectangular matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rqb(A, k = NULL, p = 10, q = 2, sdist = "normal", rand = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rqb_+3A_a">A</code></td>
<td>
<p>array_like; <br />
real/complex <code class="reqn">(m, n)</code> input matrix (or data frame).</p>
</td></tr>
<tr><td><code id="rqb_+3A_k">k</code></td>
<td>
<p>integer, optional; <br />
target rank of the low-rank decomposition. It should satisfy <code class="reqn">k &lt;&lt; min(m,n)</code>.</p>
</td></tr>
<tr><td><code id="rqb_+3A_p">p</code></td>
<td>
<p>integer, optional; <br />
oversampling parameter (default <code class="reqn">p=10</code>).</p>
</td></tr>
<tr><td><code id="rqb_+3A_q">q</code></td>
<td>
<p>integer, optional; <br />
number of power iterations (default <code class="reqn">q=2</code>).</p>
</td></tr>
<tr><td><code id="rqb_+3A_sdist">sdist</code></td>
<td>
<p>string <code class="reqn">c( 'unif', 'normal', 'rademacher')</code>, optional; <br />
specifies the sampling distribution: <br />
<code class="reqn">'unif'</code> :  Uniform '[-1,1]'. <br />
<code class="reqn">'normal</code>' (default) : Normal '~N(0,1)'. <br />
<code class="reqn">'rademacher'</code> : Rademacher random variates. <br /></p>
</td></tr>
<tr><td><code id="rqb_+3A_rand">rand</code></td>
<td>
<p>bool, optional; <br />
If (<code class="reqn">TRUE</code>), a probabilistic strategy is used, otherwise a deterministic algorithm is used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The randomized QB decomposition factors a rectangular <code class="reqn">(m,n)</code> matrix <code class="reqn">A</code> as
<code class="reqn">A = Q * B</code>. <code class="reqn">Q</code> is an <code class="reqn">(m,k)</code> matrix with orthogonal columns, and <code class="reqn">B</code> a <code class="reqn">(k,n)</code> matrix.
The target rank is assumed to be <code class="reqn">k &lt;&lt; min(m,n)</code>.   
</p>
<p><code class="reqn">p</code> is an oversampling parameter to improve the approximation.
A value between 5 and 10 is recommended, and <code class="reqn">p=10</code> is set by default.
</p>
<p>The parameter <code class="reqn">q</code> specifies the number of power (subspace) iterations
to reduce the approximation error. This is recommended
if the the singular values decay slowly. In practice 1 or 2 iterations
achieve good results, however, computing power iterations increases the
computational time. The number of power iterations is set to <code class="reqn">q=2</code> by default.
</p>


<h3>Value</h3>

<p><code>rqb</code> returns a list containing the following components:
</p>

<dl>
<dt>Q</dt><dd><p>  array_like; <br />
matrix with orthogonal columns; <code class="reqn">(m, k)</code> dimensional array.
</p>
</dd>
<dt>B</dt><dd><p>  array_like; <br />
smaller matrix; <code class="reqn">(k, n)</code> dimensional array.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>N. Benjamin Erichson, <a href="mailto:erichson@berkeley.edu">erichson@berkeley.edu</a>
</p>


<h3>References</h3>


<ul>
<li><p> [1] N. B. Erichson, S. Voronin, S. L. Brunton and J. N. Kutz. 2019.
Randomized Matrix Decompositions Using R. 
Journal of Statistical Software, 89(11), 1-48.
doi: <a href="https://doi.org/10.18637/jss.v089.i11">10.18637/jss.v089.i11</a>.
</p>
</li>
<li><p>  [2] N. Halko, P. Martinsson, and J. Tropp.
&quot;Finding structure with randomness: probabilistic
algorithms for constructing approximate matrix
decompositions&quot; (2009).
(available at arXiv <a href="https://arxiv.org/abs/0909.4061">https://arxiv.org/abs/0909.4061</a>).
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="base.html#topic+svd">svd</a></code>
</p>

<hr>
<h2 id='rrpca'>Randomized robust principal component analysis (rrpca).</h2><span id='topic+rrpca'></span>

<h3>Description</h3>

<p>Robust principal components analysis separates a matrix into a low-rank plus sparse component.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrpca(
  A,
  lambda = NULL,
  maxiter = 50,
  tol = 1e-05,
  p = 10,
  q = 2,
  trace = FALSE,
  rand = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrpca_+3A_a">A</code></td>
<td>
<p>array_like; <br />
a real <code class="reqn">(m, n)</code> input matrix (or data frame) to be decomposed. <br />
na.omit is applied, if the data contain <code class="reqn">NA</code>s.</p>
</td></tr>
<tr><td><code id="rrpca_+3A_lambda">lambda</code></td>
<td>
<p>scalar, optional; <br />
tuning parameter (default <code class="reqn">lambda = max(m,n)^-0.5</code>).</p>
</td></tr>
<tr><td><code id="rrpca_+3A_maxiter">maxiter</code></td>
<td>
<p>integer, optional; <br />
maximum number of iterations (default <code class="reqn">maxiter = 50</code>).</p>
</td></tr>
<tr><td><code id="rrpca_+3A_tol">tol</code></td>
<td>
<p>scalar, optional; <br />
precision parameter (default <code class="reqn">tol = 1.0e-5</code>).</p>
</td></tr>
<tr><td><code id="rrpca_+3A_p">p</code></td>
<td>
<p>integer, optional; <br />
oversampling parameter for <code class="reqn">rsvd</code> (default <code class="reqn">p=10</code>), see <code><a href="#topic+rsvd">rsvd</a></code>.</p>
</td></tr>
<tr><td><code id="rrpca_+3A_q">q</code></td>
<td>
<p>integer, optional; <br />
number of additional power iterations for <code class="reqn">rsvd</code> (default <code class="reqn">q=2</code>), see <code><a href="#topic+rsvd">rsvd</a></code>.</p>
</td></tr>
<tr><td><code id="rrpca_+3A_trace">trace</code></td>
<td>
<p>bool, optional; <br />
print progress.</p>
</td></tr>
<tr><td><code id="rrpca_+3A_rand">rand</code></td>
<td>
<p>bool, optional; <br />
if (<code class="reqn">TRUE</code>), the <code class="reqn">rsvd</code> routine is used, otherwise <code class="reqn">svd</code> is used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Robust principal component analysis (RPCA) is a method for the robust seperation of a
a rectangular <code class="reqn">(m,n)</code> matrix <code class="reqn">A</code> into a low-rank component <code class="reqn">L</code> and a
sparse comonent <code class="reqn">S</code>: 
</p>
<p style="text-align: center;"><code class="reqn">A = L + S</code>
</p>

<p>To decompose the matrix, we use the inexact augmented Lagrange multiplier
method (IALM). The algorithm can be used in combination with either the randomized or deterministic SVD.
</p>


<h3>Value</h3>

<p><code>rrpca</code> returns a list containing the following components:
</p>

<dl>
<dt>L</dt><dd><p>  array_like; <br />
low-rank component; <code class="reqn">(m, n)</code> dimensional array.
</p>
</dd>
<dt>S</dt><dd><p>  array_like <br />
sparse component; <code class="reqn">(m, n)</code> dimensional array.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>N. Benjamin Erichson, <a href="mailto:erichson@berkeley.edu">erichson@berkeley.edu</a>
</p>


<h3>References</h3>


<ul>
<li><p> [1] N. B. Erichson, S. Voronin, S. L. Brunton and J. N. Kutz. 2019.
Randomized Matrix Decompositions Using R. 
Journal of Statistical Software, 89(11), 1-48.
doi: <a href="https://doi.org/10.18637/jss.v089.i11">10.18637/jss.v089.i11</a>.
</p>
</li>
<li><p>  [2] Lin, Zhouchen, Minming Chen, and Yi Ma.
&quot;The augmented lagrange multiplier method for exact
recovery of corrupted low-rank matrices.&quot; (2010).
(available at arXiv <a href="https://arxiv.org/abs/1009.5055">https://arxiv.org/abs/1009.5055</a>).
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>library('rsvd')

# Create toy video
# background frame
xy &lt;- seq(-50, 50, length.out=100)
mgrid &lt;- list( x=outer(xy*0,xy,FUN="+"), y=outer(xy,xy*0,FUN="+") )
bg &lt;- 0.1*exp(sin(-mgrid$x**2-mgrid$y**2))
toyVideo &lt;- matrix(rep(c(bg), 100), 100*100, 100)

# add moving object
for(i in 1:90) {
  mobject &lt;- matrix(0, 100, 100)
  mobject[i:(10+i), 45:55] &lt;- 0.2
  toyVideo[,i] =  toyVideo[,i] + c( mobject )
}

# Foreground/Background separation
out &lt;- rrpca(toyVideo, trace=TRUE)

# Display results of the seperation for the 10th frame
par(mfrow=c(1,4))
image(matrix(bg, ncol=100, nrow=100)) #true background
image(matrix(toyVideo[,10], ncol=100, nrow=100)) # frame
image(matrix(out$L[,10], ncol=100, nrow=100)) # seperated background
image(matrix(out$S[,10], ncol=100, nrow=100)) #seperated foreground
</code></pre>

<hr>
<h2 id='rsvd'>Randomized Singular Value Decomposition (rsvd).</h2><span id='topic+rsvd'></span>

<h3>Description</h3>

<p>The randomized SVD computes the near-optimal low-rank approximation of a rectangular matrix
using a fast probablistic algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rsvd(A, k = NULL, nu = NULL, nv = NULL, p = 10, q = 2, sdist = "normal")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rsvd_+3A_a">A</code></td>
<td>
<p>array_like; <br />
a real/complex <code class="reqn">(m, n)</code> input matrix (or data frame) to be decomposed.</p>
</td></tr>
<tr><td><code id="rsvd_+3A_k">k</code></td>
<td>
<p>integer; <br />
specifies the target rank of the low-rank decomposition. <code class="reqn">k</code> should satisfy <code class="reqn">k &lt;&lt; min(m,n)</code>.</p>
</td></tr>
<tr><td><code id="rsvd_+3A_nu">nu</code></td>
<td>
<p>integer, optional; <br />
number of left singular vectors to be returned. <code class="reqn">nu</code> must be between <code class="reqn">0</code> and <code class="reqn">k</code>.</p>
</td></tr>
<tr><td><code id="rsvd_+3A_nv">nv</code></td>
<td>
<p>integer, optional; <br />
number of right singular vectors to be returned. <code class="reqn">nv</code> must be between <code class="reqn">0</code> and <code class="reqn">k</code>.</p>
</td></tr>
<tr><td><code id="rsvd_+3A_p">p</code></td>
<td>
<p>integer, optional; <br />
oversampling parameter (by default <code class="reqn">p=10</code>).</p>
</td></tr>
<tr><td><code id="rsvd_+3A_q">q</code></td>
<td>
<p>integer, optional; <br />
number of additional power iterations (by default <code class="reqn">q=2</code>).</p>
</td></tr>
<tr><td><code id="rsvd_+3A_sdist">sdist</code></td>
<td>
<p>string <code class="reqn">c( 'unif', 'normal', 'rademacher')</code>, optional; <br />
specifies the sampling distribution of the random test matrix: <br />
<code class="reqn">'unif'</code> :  Uniform '[-1,1]'. <br />
<code class="reqn">'normal</code>' (default) : Normal '~N(0,1)'. <br />
<code class="reqn">'rademacher'</code> : Rademacher random variates. <br /></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The singular value decomposition (SVD) plays an important role in data analysis, and scientific computing.
Given a rectangular <code class="reqn">(m,n)</code> matrix <code class="reqn">A</code>, and a target rank <code class="reqn">k &lt;&lt; min(m,n)</code>, 
the SVD factors the input matrix <code class="reqn">A</code> as
</p>
<p style="text-align: center;"><code class="reqn"> A  =  U_{k} diag(d_{k}) V_{k}^\top </code>
</p>

<p>The <code class="reqn">k</code> left singular vectors are the columns of the
real or complex unitary matrix <code class="reqn">U</code>. The <code class="reqn">k</code> right singular vectors are the columns
of the real or complex unitary matrix <code class="reqn">V</code>. The <code class="reqn">k</code> dominant singular values are the 
entries of <code class="reqn">d</code>, and non-negative and real numbers.
</p>
<p><code class="reqn">p</code> is an oversampling parameter to improve the approximation.
A value of at least 10 is recommended, and <code class="reqn">p=10</code> is set by default.
</p>
<p>The parameter <code class="reqn">q</code> specifies the number of power (subspace) iterations
to reduce the approximation error. The power scheme is recommended,
if the singular values decay slowly. In practice, 2 or 3 iterations
achieve good results, however, computing power iterations increases the
computational costs. The power scheme is set to <code class="reqn">q=2</code> by default.
</p>
<p>If <code class="reqn">k &gt; (min(n,m)/4)</code>, a deterministic partial or truncated <code><a href="base.html#topic+svd">svd</a></code>
algorithm might be faster.
</p>


<h3>Value</h3>

<p><code>rsvd</code> returns a list containing the following three components:
</p>

<dl>
<dt>d</dt><dd><p>  array_like; <br />
singular values; vector of length <code class="reqn">(k)</code>.
</p>
</dd>
<dt>u</dt><dd><p>  array_like; <br />
left singular vectors; <code class="reqn">(m, k)</code> or <code class="reqn">(m, nu)</code> dimensional array.
</p>
</dd>
<dt>v</dt><dd><p>  array_like; <br />
right singular vectors; <code class="reqn">(n, k)</code> or <code class="reqn">(n, nv)</code> dimensional array. <br />
</p>
</dd>
</dl>



<h3>Note</h3>

<p>The singular vectors are not unique and only defined up to sign
(a constant of modulus one in the complex case). If a left singular vector
has its sign changed, changing the sign of the corresponding right vector
gives an equivalent decomposition.
</p>


<h3>Author(s)</h3>

<p>N. Benjamin Erichson, <a href="mailto:erichson@berkeley.edu">erichson@berkeley.edu</a>
</p>


<h3>References</h3>


<ul>
<li><p> [1] N. B. Erichson, S. Voronin, S. L. Brunton and J. N. Kutz. 2019.
Randomized Matrix Decompositions Using R. 
Journal of Statistical Software, 89(11), 1-48.
doi: <a href="https://doi.org/10.18637/jss.v089.i11">10.18637/jss.v089.i11</a>.
</p>
</li>
<li><p>  [2] N. Halko, P. Martinsson, and J. Tropp.
&quot;Finding structure with randomness: probabilistic
algorithms for constructing approximate matrix
decompositions&quot; (2009).
(available at arXiv <a href="https://arxiv.org/abs/0909.4061">https://arxiv.org/abs/0909.4061</a>).
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="base.html#topic+svd">svd</a></code>, <code><a href="#topic+rpca">rpca</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('rsvd')

# Create a n x n Hilbert matrix of order n,
# with entries H[i,j] = 1 / (i + j + 1).
hilbert &lt;- function(n) { i &lt;- 1:n; 1 / outer(i - 1, i, "+") }
H &lt;- hilbert(n=50)

# Low-rank (k=10) matrix approximation using rsvd
k=10
s &lt;- rsvd(H, k=k)
Hre &lt;- s$u %*% diag(s$d) %*% t(s$v) # matrix approximation
print(100 * norm( H - Hre, 'F') / norm( H,'F')) # percentage error
# Compare to truncated base svd
s &lt;- svd(H)
Hre &lt;- s$u[,1:k] %*% diag(s$d[1:k]) %*% t(s$v[,1:k]) # matrix approximation
print(100 * norm( H - Hre, 'F') / norm( H,'F')) # percentage error

</code></pre>

<hr>
<h2 id='tiger'>Tiger</h2><span id='topic+tiger'></span>

<h3>Description</h3>

<p>1600x1200 grayscaled (8 bit [0-255]/255) image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data('tiger')
</code></pre>


<h3>Format</h3>

<p>An object of class <code><a href="#topic+rsvd">rsvd</a></code>.
</p>


<h3>Source</h3>

<p><a href="https://en.wikipedia.org/wiki/File:Siberischer_tiger_de_edit02.jpg">Wikimedia</a>
</p>


<h3>References</h3>

<p>S. Taheri (2006). &quot;Panthera tigris altaica&quot;, (Online image)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library('rsvd')
data('tiger')

#Display image
image(tiger, col = gray((0:255)/255))

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
