<!DOCTYPE html><html lang="en"><head><title>Help for package covalchemy</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {covalchemy}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#augment_matrix_random_block'><p>Augment Matrix with Random 2x2 Block Adjustment</p></a></li>
<li><a href='#calculate_tv_distance_empirical'><p>Calculate Total Variation (TV) Distance Empirically</p></a></li>
<li><a href='#entropy_pair'><p>Calculate Entropy of a Pair</p></a></li>
<li><a href='#gaussian_copula_two_vars'><p>Generate Gaussian Copula Samples for Two Variables</p></a></li>
<li><a href='#gen_number_1'><p>Generate a New Number for Stepwise Modification</p></a></li>
<li><a href='#gen_number_max'><p>Generate a New Number for Maximizing Mutual Information</p></a></li>
<li><a href='#gen_number_min'><p>Generate a New Number for Minimizing Mutual Information</p></a></li>
<li><a href='#genCDFInv_akima'><p>Generate an Inverse CDF Function Using Akima Spline Interpolation</p></a></li>
<li><a href='#genCDFInv_linear'><p>Generate an Inverse CDF Function Using Linear Interpolation</p></a></li>
<li><a href='#genCDFInv_poly'><p>Generate an Inverse CDF Function Using Polynomial Regression</p></a></li>
<li><a href='#genCDFInv_quantile'><p>Generate an Inverse CDF Function Using Quantiles</p></a></li>
<li><a href='#generate_gaussian_copula_samples'><p>Generate Gaussian Copula Samples</p></a></li>
<li><a href='#generate_t_copula_samples'><p>Generate t-Copula Samples</p></a></li>
<li><a href='#get_mutual_information'><p>Calculate Mutual Information</p></a></li>
<li><a href='#get_optimal_grid'><p>Get Optimal Grid Assignment</p></a></li>
<li><a href='#get_simpsons_paradox_c'><p>Simpson's Paradox Transformation with Copula and Simulated Annealing</p></a></li>
<li><a href='#get_simpsons_paradox_d'><p>Introduce Simpson's Paradox in Discrete Data</p></a></li>
<li><a href='#get_target_corr'><p>Generate Samples with Target Kendall's Tau Correlation Using a Copula Approach</p></a></li>
<li><a href='#get_target_entropy'><p>Get Target Entropy</p></a></li>
<li><a href='#log_odds_dc'><p>Log-Odds Calculation for Concordant and Discordant Pairs</p></a></li>
<li><a href='#objective_function_SL'><p>Objective Function for Structural Learning (SL)</p></a></li>
<li><a href='#plot_log_odds'><p>Plot Log-Odds Before and After Transformation</p></a></li>
<li><a href='#simulated_annealing_MI'><p>Simulated Annealing Algorithm with Target Entropy Stopping Condition</p></a></li>
<li><a href='#simulated_annealing_SL'><p>Simulated Annealing Optimization with Categorical Variable and R^2 Differences</p></a></li>
<li><a href='#sinkhorn_algorithm'><p>Sinkhorn Algorithm for Matrix Scaling</p></a></li>
<li><a href='#softmax'><p>Softmax Function with Special Handling for Infinite Values</p></a></li>
<li><a href='#t_copula_two_vars'><p>Generate t-Copula Samples for Two Variables</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Constructing Joint Distributions with Control Over Statistical
Properties</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Synthesizing joint distributions from marginal densities, focusing on controlling key statistical properties such as correlation for continuous data, mutual information for categorical data, and inducing Simpson's Paradox. Generate datasets with specified correlation structures for continuous variables, adjust mutual information between categorical variables, and manipulate subgroup correlations to intentionally create Simpson's Paradox.
  Joe (1997) &lt;<a href="https://doi.org/10.1201%2Fb13150">doi:10.1201/b13150</a>&gt;
  Sklar (1959) <a href="https://en.wikipedia.org/wiki/Sklar%27s_theorem">https://en.wikipedia.org/wiki/Sklar%27s_theorem</a>.</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, ggplot2, mvtnorm, interp, clue, ggExtra, gridExtra,
DescTools, MASS</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/namanlab/covalchemy/issues">https://github.com/namanlab/covalchemy/issues</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/namanlab/covalchemy">https://github.com/namanlab/covalchemy</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-11-20 14:57:15 UTC; namanagrawal</td>
</tr>
<tr>
<td>Author:</td>
<td>Naman Agrawal [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Naman Agrawal &lt;naman.agr03@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-11-21 17:10:11 UTC</td>
</tr>
</table>
<hr>
<h2 id='augment_matrix_random_block'>Augment Matrix with Random 2x2 Block Adjustment</h2><span id='topic+augment_matrix_random_block'></span>

<h3>Description</h3>

<p>This function selects a random 2x2 block of values in the input matrix <code>table</code> and modifies them
based on the specified delta. It checks certain conditions before applying the modifications to
the selected block. The process repeats until a valid block is found or a maximum of 100 iterations
is reached.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>augment_matrix_random_block(table, delta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="augment_matrix_random_block_+3A_table">table</code></td>
<td>
<p>A matrix (numeric) to which the random block adjustment will be applied.</p>
</td></tr>
<tr><td><code id="augment_matrix_random_block_+3A_delta">delta</code></td>
<td>
<p>A numeric value that determines the magnitude of the adjustment.
If positive, values are subtracted from the block; if negative, values are added.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix (numeric) with the adjusted 2x2 block.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>table &lt;- matrix(1:9, 3, 3)
augment_matrix_random_block(table, 1)

</code></pre>

<hr>
<h2 id='calculate_tv_distance_empirical'>Calculate Total Variation (TV) Distance Empirically</h2><span id='topic+calculate_tv_distance_empirical'></span>

<h3>Description</h3>

<p>This function calculates the Total Variation (TV) distance between the empirical cumulative distribution
functions (ECDFs) of two datasets: original data and generated data. The TV distance is defined as half the sum of
the absolute differences between the two CDFs at each point in the domain.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculate_tv_distance_empirical(original_data, generated_data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calculate_tv_distance_empirical_+3A_original_data">original_data</code></td>
<td>
<p>A numeric vector of the original data.</p>
</td></tr>
<tr><td><code id="calculate_tv_distance_empirical_+3A_generated_data">generated_data</code></td>
<td>
<p>A numeric vector of the generated data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value representing the Total Variation distance between the empirical CDFs of the original and generated data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Test Case 1: Data from similar distributions
original_data &lt;- rnorm(1000, mean = 0, sd = 1)  # Normal distribution (mean = 0, sd = 1)
generated_data &lt;- rnorm(1000, mean = 0, sd = 1)  # Similar normal distribution
tv_distance &lt;- calculate_tv_distance_empirical(original_data, generated_data)
print(tv_distance)  # Expected to be close to 0, as both datasets are similar

# Test Case 2: Data from different distributions
original_data &lt;- rnorm(1000, mean = 0, sd = 1)  # Normal distribution (mean = 0, sd = 1)
generated_data &lt;- rnorm(1000, mean = 5, sd = 2)  # Different normal distribution
tv_distance &lt;- calculate_tv_distance_empirical(original_data, generated_data)
print(tv_distance)  # Expected to be larger, as the datasets are quite different

</code></pre>

<hr>
<h2 id='entropy_pair'>Calculate Entropy of a Pair</h2><span id='topic+entropy_pair'></span>

<h3>Description</h3>

<p>This function calculates the entropy of a pair of variables (or a pairwise contingency table)
based on the probability distribution of their joint occurrences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>entropy_pair(table)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="entropy_pair_+3A_table">table</code></td>
<td>
<p>A numeric vector or matrix. A contingency table or frequency table of a pair of variables.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The entropy is calculated using the formula:
[ H(X, Y) = - sum p(x, y) * log_2(p(x, y)) ]
where \( p(x, y) \) is the probability of observing the pair \( (x, y) \) from the table.
</p>


<h3>Value</h3>

<p>A numeric value representing the entropy of the pair.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example usage with a simple contingency table:
pair_table &lt;- table(c(1, 2, 2, 3), c(1, 1, 2, 2))
entropy_pair(pair_table)

</code></pre>

<hr>
<h2 id='gaussian_copula_two_vars'>Generate Gaussian Copula Samples for Two Variables</h2><span id='topic+gaussian_copula_two_vars'></span>

<h3>Description</h3>

<p>This function generates samples from a Gaussian copula with two variables,
given the specified correlation coefficient between the variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gaussian_copula_two_vars(n, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gaussian_copula_two_vars_+3A_n">n</code></td>
<td>
<p>Integer. The number of samples to generate.</p>
</td></tr>
<tr><td><code id="gaussian_copula_two_vars_+3A_p">p</code></td>
<td>
<p>Numeric. The correlation coefficient (<code class="reqn">\rho</code>) between the two variables.
Must be in the range <code>[-1, 1]</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function internally constructs a correlation matrix for two variables:
</p>
<p style="text-align: center;"><code class="reqn">\rho_matrix = \begin{bmatrix} 1 &amp; p \\ p &amp; 1 \end{bmatrix}</code>
</p>

<p>It then calls <code>generate_gaussian_copula_samples</code> to generate samples.
</p>


<h3>Value</h3>

<p>A matrix of size <code>n x 2</code>, where each row represents a sample,
and each column corresponds to one of the two variables. The values
are uniformly distributed in <code>[0, 1]</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+generate_gaussian_copula_samples">generate_gaussian_copula_samples</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example usage:
samples &lt;- gaussian_copula_two_vars(n = 1000, p = 0.7)
head(samples)

</code></pre>

<hr>
<h2 id='gen_number_1'>Generate a New Number for Stepwise Modification</h2><span id='topic+gen_number_1'></span>

<h3>Description</h3>

<p>This function modifies a given contingency table by swapping values between two cells
in a stepwise manner, where the change is fixed at a <code>delta</code> value of 1. The function
randomly selects two cells from the table and adjusts their values by subtracting and
adding the <code>delta</code> value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen_number_1(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gen_number_1_+3A_x">x</code></td>
<td>
<p>A contingency table (numeric matrix or table).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs the following steps:
</p>

<ol>
<li><p> Randomly selects two rows and two columns from the table.
</p>
</li>
<li><p> Ensures that the selected cells have non-zero values.
</p>
</li>
<li><p> Adjusts the values of the selected cells by subtracting 1 from two cells and
adding 1 to the other two.
</p>
</li>
<li><p> Returns the modified table with stepwise adjustments.
</p>
</li></ol>



<h3>Value</h3>

<p>A modified contingency table with stepwise adjustments.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example usage with a contingency table:
pair_table &lt;- table(c(1, 2, 2, 3), c(1, 1, 2, 2))
gen_number_1(pair_table)

</code></pre>

<hr>
<h2 id='gen_number_max'>Generate a New Number for Maximizing Mutual Information</h2><span id='topic+gen_number_max'></span>

<h3>Description</h3>

<p>This function modifies a given contingency table by swapping values between two cells
to maximize the mutual information. The function randomly selects two cells from the table
and adjusts their values in a way that increases mutual information. The function then
returns the modified table with the highest mutual information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen_number_max(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gen_number_max_+3A_x">x</code></td>
<td>
<p>A contingency table (numeric matrix or table).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs the following steps:
</p>

<ol>
<li><p> Randomly selects two rows and two columns from the table.
</p>
</li>
<li><p> Checks if the selected cells have non-zero values.
</p>
</li>
<li><p> Adjusts the values of the selected cells in two different modified tables, <code>table1</code> and <code>table2</code>.
</p>
</li>
<li><p> Calculates the mutual information for both modified tables.
</p>
</li>
<li><p> Returns the table with the higher mutual information.
</p>
</li></ol>



<h3>Value</h3>

<p>A modified contingency table with maximized mutual information.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example usage with a contingency table:
pair_table &lt;- table(c(1, 2, 2, 3), c(1, 1, 2, 2))
gen_number_max(pair_table)

</code></pre>

<hr>
<h2 id='gen_number_min'>Generate a New Number for Minimizing Mutual Information</h2><span id='topic+gen_number_min'></span>

<h3>Description</h3>

<p>This function modifies a given contingency table by swapping values between two cells
in a way that minimizes the mutual information. The function randomly selects two cells
from the table and adjusts their values to reduce mutual information, returning the modified table.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen_number_min(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gen_number_min_+3A_x">x</code></td>
<td>
<p>A contingency table (numeric matrix or table).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs the following steps:
</p>

<ol>
<li><p> Randomly selects two rows and two columns from the table.
</p>
</li>
<li><p> Ensures that the selected cells have non-zero values.
</p>
</li>
<li><p> Adjusts the values of the selected cells in the table to minimize mutual information.
</p>
</li>
<li><p> Returns the modified table with minimized mutual information.
</p>
</li></ol>



<h3>Value</h3>

<p>A modified contingency table with minimized mutual information.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example usage with a contingency table:
pair_table &lt;- table(c(1, 2, 2, 3), c(1, 1, 2, 2))
gen_number_min(pair_table)

</code></pre>

<hr>
<h2 id='genCDFInv_akima'>Generate an Inverse CDF Function Using Akima Spline Interpolation</h2><span id='topic+genCDFInv_akima'></span>

<h3>Description</h3>

<p>This function creates an inverse cumulative distribution function (CDF)
for a given dataset using Akima spline interpolation. The resulting function
maps probabilities (in the range <code>[0, 1]</code>) to values in the dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genCDFInv_akima(X)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="genCDFInv_akima_+3A_x">X</code></td>
<td>
<p>A numeric vector. The dataset for which the inverse CDF is to be created.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function works as follows:
</p>

<ol>
<li><p> Computes the empirical CDF (ECDF) of the dataset.
</p>
</li>
<li><p> Extracts the sorted ECDF values for the dataset.
</p>
</li>
<li><p> Sorts the original data values.
</p>
</li>
<li><p> Uses the <code><a href="akima.html#topic+aspline">aspline</a></code> function to create a spline interpolation
mapping probabilities to dataset values.
</p>
</li></ol>

<p>The resulting function leverages Akima splines, which are smooth and flexible for
interpolating data.
</p>


<h3>Value</h3>

<p>A function that takes a single argument, <code>p</code>, a numeric vector of
probabilities in <code>[0, 1]</code>, and returns the corresponding values interpolated
from the dataset using Akima splines.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ecdf">ecdf</a></code>, <code><a href="akima.html#topic+aspline">aspline</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example usage:
library(interp)
data &lt;- c(1, 2, 3, 4, 5)
inv_cdf &lt;- genCDFInv_akima(data)
inv_cdf(c(0.1, 0.5, 0.9))  # Compute interpolated values for given probabilities

</code></pre>

<hr>
<h2 id='genCDFInv_linear'>Generate an Inverse CDF Function Using Linear Interpolation</h2><span id='topic+genCDFInv_linear'></span>

<h3>Description</h3>

<p>This function creates an inverse cumulative distribution function (CDF) for
a given dataset using linear interpolation. The resulting function maps
probabilities (in the range <code>[0, 1]</code>) to values in the dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genCDFInv_linear(X)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="genCDFInv_linear_+3A_x">X</code></td>
<td>
<p>A numeric vector. The dataset for which the inverse CDF is to be created.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function works as follows:
</p>

<ol>
<li><p> Computes the empirical CDF (ECDF) of the dataset.
</p>
</li>
<li><p> Extracts the sorted ECDF values for the dataset.
</p>
</li>
<li><p> Sorts the original data values.
</p>
</li>
<li><p> Uses <code><a href="stats.html#topic+approxfun">approxfun</a></code> to create a linear interpolation function
mapping probabilities to dataset values.
</p>
</li></ol>

<p>The resulting function can handle probabilities outside <code>[0, 1]</code> using the
<code>rule = 2</code> parameter in <code><a href="stats.html#topic+approxfun">approxfun</a></code>, which extrapolates
based on the nearest data points.
</p>


<h3>Value</h3>

<p>A function that takes a single argument, <code>p</code>, a numeric vector of
probabilities in <code>[0, 1]</code>, and returns the corresponding values interpolated
from the dataset.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ecdf">ecdf</a></code>, <code><a href="stats.html#topic+approxfun">approxfun</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example usage:
data &lt;- c(1, 2, 3, 4, 5)
inv_cdf &lt;- genCDFInv_linear(data)
inv_cdf(c(0.1, 0.5, 0.9))  # Compute the interpolated values for given probabilities

</code></pre>

<hr>
<h2 id='genCDFInv_poly'>Generate an Inverse CDF Function Using Polynomial Regression</h2><span id='topic+genCDFInv_poly'></span>

<h3>Description</h3>

<p>This function creates an inverse cumulative distribution function (CDF) for a
given dataset using polynomial regression. The resulting function maps probabilities
(in the range <code>[0, 1]</code>) to values in the dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genCDFInv_poly(data, degree)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="genCDFInv_poly_+3A_data">data</code></td>
<td>
<p>A numeric vector. The dataset for which the inverse CDF is to be created.</p>
</td></tr>
<tr><td><code id="genCDFInv_poly_+3A_degree">degree</code></td>
<td>
<p>An integer. The degree of the polynomial to fit in the regression.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function works as follows:
</p>

<ol>
<li><p> Sorts the dataset and computes the empirical CDF (ECDF) of the data.
</p>
</li>
<li><p> Fits a polynomial regression to model the relationship between
ECDF values and the sorted dataset.
</p>
</li>
<li><p> Uses the fitted polynomial model to predict the inverse CDF for
given probabilities.
</p>
</li></ol>

<p>The degree of the polynomial can be specified to control the flexibility
of the regression model.
</p>


<h3>Value</h3>

<p>A function that takes a single argument, <code>y</code>, a numeric vector of
probabilities in <code>[0, 1]</code>, and returns the corresponding values predicted
by the polynomial regression.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="stats.html#topic+poly">poly</a></code>, <code><a href="stats.html#topic+ecdf">ecdf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example usage:
data &lt;- c(1, 2, 3, 4, 5)
inv_cdf &lt;- genCDFInv_poly(data, degree = 2)
inv_cdf(c(0.1, 0.5, 0.9))  # Compute predicted values for given probabilities

</code></pre>

<hr>
<h2 id='genCDFInv_quantile'>Generate an Inverse CDF Function Using Quantiles</h2><span id='topic+genCDFInv_quantile'></span>

<h3>Description</h3>

<p>This function creates an inverse cumulative distribution function (CDF)
for a given dataset using quantiles. The resulting function maps probabilities
(in the range <code>[0, 1]</code>) to quantiles of the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genCDFInv_quantile(data, type = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="genCDFInv_quantile_+3A_data">data</code></td>
<td>
<p>A numeric vector. The dataset for which the inverse CDF is to be created.</p>
</td></tr>
<tr><td><code id="genCDFInv_quantile_+3A_type">type</code></td>
<td>
<p>Integer. Specifies the algorithm used to compute quantiles.
See <code><a href="stats.html#topic+quantile">quantile</a></code> for details. Default is <code>1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function works by wrapping the <code><a href="stats.html#topic+quantile">quantile</a></code> function. The
<code>type</code> parameter controls the quantile computation method. For example:
</p>

<ul>
<li><p> Type 1 corresponds to inverse of the empirical distribution function (default).
</p>
</li>
<li><p> Other types correspond to different quantile algorithms as documented in
<code><a href="stats.html#topic+quantile">quantile</a></code>.
</p>
</li></ul>



<h3>Value</h3>

<p>A function that takes a single argument, <code>p</code>, a numeric vector of
probabilities in <code>[0, 1]</code>, and returns the corresponding quantiles from
the data.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+quantile">quantile</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example usage:
data &lt;- c(1, 2, 3, 4, 5)
inv_cdf &lt;- genCDFInv_quantile(data, type = 1)
inv_cdf(c(0.25, 0.5, 0.75))  # Compute the 25th, 50th, and 75th percentiles

</code></pre>

<hr>
<h2 id='generate_gaussian_copula_samples'>Generate Gaussian Copula Samples</h2><span id='topic+generate_gaussian_copula_samples'></span>

<h3>Description</h3>

<p>This function generates samples from a Gaussian copula given a specified
correlation matrix. The samples are uniformly distributed in <code>[0, 1]</code> across
dimensions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate_gaussian_copula_samples(n, d, rho_matrix)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generate_gaussian_copula_samples_+3A_n">n</code></td>
<td>
<p>Integer. The number of samples to generate.</p>
</td></tr>
<tr><td><code id="generate_gaussian_copula_samples_+3A_d">d</code></td>
<td>
<p>Integer. The dimensionality of the copula.</p>
</td></tr>
<tr><td><code id="generate_gaussian_copula_samples_+3A_rho_matrix">rho_matrix</code></td>
<td>
<p>A <code>d x d</code> positive-definite correlation matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function works as follows:
</p>

<ol>
<li><p> Generates multivariate normal samples with the given correlation matrix.
</p>
</li>
<li><p> Transforms the samples to the uniform distribution <code>[0, 1]</code> using the
cumulative distribution function (CDF) of the standard normal.
</p>
</li></ol>



<h3>Value</h3>

<p>A matrix of size <code>n x d</code>, where each row represents a sample
and each column corresponds to a dimension. The values are uniformly
distributed in <code>[0, 1]</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example usage:
library(MASS)  # Load package for `mvrnorm`
rho_matrix &lt;- matrix(c(1, 0.5, 0.5, 1), nrow = 2)  # 2x2 correlation matrix
samples &lt;- generate_gaussian_copula_samples(n = 1000, d = 2, rho_matrix = rho_matrix)
head(samples)

</code></pre>

<hr>
<h2 id='generate_t_copula_samples'>Generate t-Copula Samples</h2><span id='topic+generate_t_copula_samples'></span>

<h3>Description</h3>

<p>This function generates samples from a t-copula given a specified correlation
matrix and degrees of freedom. The samples are uniformly distributed in <code>[0, 1]</code>.
across dimensions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate_t_copula_samples(n, d, rho_matrix, df)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generate_t_copula_samples_+3A_n">n</code></td>
<td>
<p>Integer. The number of samples to generate.</p>
</td></tr>
<tr><td><code id="generate_t_copula_samples_+3A_d">d</code></td>
<td>
<p>Integer. The dimensionality of the copula.</p>
</td></tr>
<tr><td><code id="generate_t_copula_samples_+3A_rho_matrix">rho_matrix</code></td>
<td>
<p>A <code>d x d</code> positive-definite correlation matrix.</p>
</td></tr>
<tr><td><code id="generate_t_copula_samples_+3A_df">df</code></td>
<td>
<p>Numeric. The degrees of freedom of the t-distribution. Must be positive.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function works as follows:
</p>

<ol>
<li><p> Generates multivariate t-distributed samples using the specified
correlation matrix and degrees of freedom.
</p>
</li>
<li><p> Transforms the samples to the uniform distribution <code>[0, 1]</code> using the
cumulative distribution function (CDF) of the t-distribution.
</p>
</li></ol>



<h3>Value</h3>

<p>A matrix of size <code>n x d</code>, where each row represents a sample
and each column corresponds to a dimension. The values are uniformly
distributed in <code>[0, 1]</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example usage:
library(mvtnorm)  # Load package for `rmvt`
rho_matrix &lt;- diag(3)  # 3x3 identity matrix as correlation matrix
samples &lt;- generate_t_copula_samples(n = 1000, d = 3, rho_matrix = rho_matrix, df = 5)
head(samples)

</code></pre>

<hr>
<h2 id='get_mutual_information'>Calculate Mutual Information</h2><span id='topic+get_mutual_information'></span>

<h3>Description</h3>

<p>This function calculates the mutual information between two variables based on their joint distribution.
Mutual information measures the amount of information obtained about one variable through the other.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_mutual_information(table)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_mutual_information_+3A_table">table</code></td>
<td>
<p>A numeric matrix or table. A contingency table or frequency table of two variables.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mutual information is calculated using the formula:
[ I(X, Y) = H(X) + H(Y) - H(X, Y) ]
where:
</p>

<ul>
<li><p> \( H(X) \) is the entropy of variable X,
</p>
</li>
<li><p> \( H(Y) \) is the entropy of variable Y, and
</p>
</li>
<li><p> \( H(X, Y) \) is the joint entropy of X and Y.
</p>
</li></ul>



<h3>Value</h3>

<p>A numeric value representing the mutual information between the two variables.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example usage with a simple contingency table:
pair_table &lt;- table(c(1, 2, 2, 3), c(1, 1, 2, 2))
get_mutual_information(pair_table)

</code></pre>

<hr>
<h2 id='get_optimal_grid'>Get Optimal Grid Assignment</h2><span id='topic+get_optimal_grid'></span>

<h3>Description</h3>

<p>This function computes an optimal grid assignment between two variables <code>x</code> and <code>y</code> based on a third variable <code>z</code>.
It uses the quantiles of <code>x</code> and <code>y</code> to segment the data based on the distribution of <code>z</code>. Then, it computes the cost of
assigning points from <code>x</code> to <code>y</code> by calculating the counts of <code>y</code> values within quantile ranges of <code>x</code> and <code>y</code>, and then solves
the assignment problem using the Hungarian algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_optimal_grid(x, y, z)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_optimal_grid_+3A_x">x</code></td>
<td>
<p>A numeric vector of values representing the first variable.</p>
</td></tr>
<tr><td><code id="get_optimal_grid_+3A_y">y</code></td>
<td>
<p>A numeric vector of values representing the second variable.</p>
</td></tr>
<tr><td><code id="get_optimal_grid_+3A_z">z</code></td>
<td>
<p>A numeric vector representing the distribution of the third variable, used to define quantiles for <code>x</code> and <code>y</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of optimal indices that represents the optimal assignment of <code>x</code> values to <code>y</code> values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Test Case 1: Simple uniform data
x &lt;- rnorm(1000)
y &lt;- rnorm(1000)
z &lt;- sample(1:5, 1000, replace = TRUE)
optimal_assignment &lt;- get_optimal_grid(x, y, z)

# Test Case 2: Data with a skewed distribution
x &lt;- rexp(1000, rate = 1)
y &lt;- rpois(1000, lambda = 2)
z &lt;- sample(1:3, 1000, replace = TRUE)
optimal_assignment &lt;- get_optimal_grid(x, y, z)

</code></pre>

<hr>
<h2 id='get_simpsons_paradox_c'>Simpson's Paradox Transformation with Copula and Simulated Annealing</h2><span id='topic+get_simpsons_paradox_c'></span>

<h3>Description</h3>

<p>This function simulates the Simpson's Paradox phenomenon by transforming data using Gaussian copulas,
optimizing the transformation with simulated annealing, and comparing the results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_simpsons_paradox_c(
  x,
  y,
  z,
  corr_vector,
  inv_cdf_type = "quantile_7",
  sd_x = 0.05,
  sd_y = 0.05,
  lambda1 = 1,
  lambda2 = 1,
  lambda3 = 1,
  lambda4 = 1,
  max_iter = 1000,
  initial_temp = 1,
  cooling_rate = 0.99,
  order_vec = NA,
  degree = 5
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_simpsons_paradox_c_+3A_x">x</code></td>
<td>
<p>A numeric vector of data points for variable X.</p>
</td></tr>
<tr><td><code id="get_simpsons_paradox_c_+3A_y">y</code></td>
<td>
<p>A numeric vector of data points for variable Y.</p>
</td></tr>
<tr><td><code id="get_simpsons_paradox_c_+3A_z">z</code></td>
<td>
<p>A categorical variable representing groups (e.g., factor or character vector).</p>
</td></tr>
<tr><td><code id="get_simpsons_paradox_c_+3A_corr_vector">corr_vector</code></td>
<td>
<p>A vector of correlations for each category of z.</p>
</td></tr>
<tr><td><code id="get_simpsons_paradox_c_+3A_inv_cdf_type">inv_cdf_type</code></td>
<td>
<p>Type of inverse CDF transformation (&quot;quantile_1&quot;, &quot;quantile_4&quot;, &quot;quantile_7&quot;, &quot;quantile_8&quot;, &quot;linear&quot;, &quot;akima&quot;, &quot;poly&quot;). Default is &quot;quantile_7&quot;.</p>
</td></tr>
<tr><td><code id="get_simpsons_paradox_c_+3A_sd_x">sd_x</code></td>
<td>
<p>Standard deviation for perturbations on X (default is 0.05).</p>
</td></tr>
<tr><td><code id="get_simpsons_paradox_c_+3A_sd_y">sd_y</code></td>
<td>
<p>Standard deviation for perturbations on Y (default is 0.05).</p>
</td></tr>
<tr><td><code id="get_simpsons_paradox_c_+3A_lambda1">lambda1</code></td>
<td>
<p>Regularization parameter for simulated annealing (default is 1).</p>
</td></tr>
<tr><td><code id="get_simpsons_paradox_c_+3A_lambda2">lambda2</code></td>
<td>
<p>Regularization parameter for simulated annealing (default is 1).</p>
</td></tr>
<tr><td><code id="get_simpsons_paradox_c_+3A_lambda3">lambda3</code></td>
<td>
<p>Regularization parameter for simulated annealing (default is 1).</p>
</td></tr>
<tr><td><code id="get_simpsons_paradox_c_+3A_lambda4">lambda4</code></td>
<td>
<p>Regularization parameter for simulated annealing (default is 1).</p>
</td></tr>
<tr><td><code id="get_simpsons_paradox_c_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum iterations for simulated annealing (default is 1000).</p>
</td></tr>
<tr><td><code id="get_simpsons_paradox_c_+3A_initial_temp">initial_temp</code></td>
<td>
<p>Initial temperature for simulated annealing (default is 1.0).</p>
</td></tr>
<tr><td><code id="get_simpsons_paradox_c_+3A_cooling_rate">cooling_rate</code></td>
<td>
<p>Cooling rate for simulated annealing (default is 0.99).</p>
</td></tr>
<tr><td><code id="get_simpsons_paradox_c_+3A_order_vec">order_vec</code></td>
<td>
<p>Manual ordering of grids (default is NA, calculated automatically if not specified).</p>
</td></tr>
<tr><td><code id="get_simpsons_paradox_c_+3A_degree">degree</code></td>
<td>
<p>Degree of polynomial used for polynomial inverse CDF (default is 5).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing:
</p>
<table role = "presentation">
<tr><td><code>df_all</code></td>
<td>
<p>The final dataset with original, transformed, and annealed data.</p>
</td></tr>
<tr><td><code>df_res</code></td>
<td>
<p>A simplified version with only the optimized data.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
n &lt;- 300
z &lt;- sample(c("A", "B", "C"), prob = c(0.3, 0.4, 0.3), size = n, replace = TRUE)
x &lt;- rnorm(n, 10, sd = 5) + 5 * rbeta(n, 5, 3)
y &lt;- 2 * x + rnorm(n, 5, sd = 4)
t &lt;- c(-0.8, 0.8, -0.8)
res &lt;- get_simpsons_paradox_c(x, y, z, t, sd_x = 0.07, sd_y = 0.07, lambda4 = 5)

</code></pre>

<hr>
<h2 id='get_simpsons_paradox_d'>Introduce Simpson's Paradox in Discrete Data</h2><span id='topic+get_simpsons_paradox_d'></span>

<h3>Description</h3>

<p>This function modifies contingency tables associated with different levels of a categorical variable
to create or highlight Simpson's Paradox using simulated annealing. The paradox occurs when aggregated
data trends differ from subgroup trends.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_simpsons_paradox_d(
  x,
  y,
  z,
  manual_vec,
  target_overall,
  margin,
  margin_overall,
  max_n = 1000,
  temp = 10,
  log_odds_general = log_odds_dc
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_simpsons_paradox_d_+3A_x">x</code></td>
<td>
<p>A vector of categorical values for the first variable.</p>
</td></tr>
<tr><td><code id="get_simpsons_paradox_d_+3A_y">y</code></td>
<td>
<p>A vector of categorical values for the second variable.</p>
</td></tr>
<tr><td><code id="get_simpsons_paradox_d_+3A_z">z</code></td>
<td>
<p>A vector indicating levels of a third variable that segments the data.</p>
</td></tr>
<tr><td><code id="get_simpsons_paradox_d_+3A_manual_vec">manual_vec</code></td>
<td>
<p>A numeric vector specifying target log-odds trends for each level of <code>z</code>.</p>
</td></tr>
<tr><td><code id="get_simpsons_paradox_d_+3A_target_overall">target_overall</code></td>
<td>
<p>A numeric value representing the target log-odds for the aggregated data.</p>
</td></tr>
<tr><td><code id="get_simpsons_paradox_d_+3A_margin">margin</code></td>
<td>
<p>A numeric value for allowed deviation in log-odds within each subgroup.</p>
</td></tr>
<tr><td><code id="get_simpsons_paradox_d_+3A_margin_overall">margin_overall</code></td>
<td>
<p>A numeric value for allowed deviation in aggregated log-odds.</p>
</td></tr>
<tr><td><code id="get_simpsons_paradox_d_+3A_max_n">max_n</code></td>
<td>
<p>An integer specifying the maximum number of iterations for the annealing process.</p>
</td></tr>
<tr><td><code id="get_simpsons_paradox_d_+3A_temp">temp</code></td>
<td>
<p>A numeric value for the initial temperature in the annealing process.</p>
</td></tr>
<tr><td><code id="get_simpsons_paradox_d_+3A_log_odds_general">log_odds_general</code></td>
<td>
<p>A function to compute the log-odds for a given contingency table (default: <code>log_odds_dc</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function works by iteratively modifying individual matrices (contingency tables) corresponding
to levels of <code>z</code> while respecting log-odds constraints. The overall log-odds of the aggregated table
are also adjusted to achieve the specified <code>target_overall</code>. Simulated annealing ensures that the
modifications balance between achieving the targets and avoiding overfitting.
</p>


<h3>Value</h3>

<p>A list containing:
</p>

<ul>
<li> <p><code>final_df</code>: A data frame representing the modified dataset.
</p>
</li>
<li> <p><code>final_table</code>: A list of modified contingency tables.
</p>
</li>
<li> <p><code>history</code>: A data frame tracking the overall log-odds over iterations.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Example with predefined contingency tables
set.seed(42)
matrices &lt;- list(
  ta = matrix(c(512, 89, 313, 19), ncol = 2, byrow = TRUE),
  tb = matrix(c(353, 17, 207, 8), ncol = 2, byrow = TRUE),
  tc = matrix(c(120, 202, 205, 391), ncol = 2, byrow = TRUE)
)
df_list &lt;- lapply(seq_along(matrices), function(i) {
  mat &lt;- matrices[[i]]
  z_level &lt;- names(matrices)[i]
  df &lt;- as.data.frame(as.table(mat))
  colnames(df) &lt;- c("x", "y", "Freq")
  df$z &lt;- z_level
  return(df)
})
final_df &lt;- do.call(rbind, df_list)
expanded_df &lt;- final_df[rep(1:nrow(final_df), final_df$Freq), c("x", "y", "z")]
result &lt;- get_simpsons_paradox_d(
  expanded_df$x, expanded_df$y, expanded_df$z,
  manual_vec = c(-1, -1, -1),
  target_overall = +1,
  margin = 0.2, margin_overall = 0.2, max_n = 200
)
table(expanded_df$x) - table(result$final_df$x)

</code></pre>

<hr>
<h2 id='get_target_corr'>Generate Samples with Target Kendall's Tau Correlation Using a Copula Approach</h2><span id='topic+get_target_corr'></span>

<h3>Description</h3>

<p>This function generates two variables with a specified target Kendall's tau correlation
using copula-based methods. The user can specify the type of copula (Gaussian or t),
the type of inverse CDF method to apply to the variables, and the degree of the polynomial
interpolation if applicable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_target_corr(
  x1,
  x2,
  target_corr_kendall,
  copula_type = "gaussian",
  inv_cdf_type = "quantile_7",
  degree = 10
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_target_corr_+3A_x1">x1</code></td>
<td>
<p>A numeric vector. The first dataset used for generating inverse CDFs.</p>
</td></tr>
<tr><td><code id="get_target_corr_+3A_x2">x2</code></td>
<td>
<p>A numeric vector. The second dataset used for generating inverse CDFs.</p>
</td></tr>
<tr><td><code id="get_target_corr_+3A_target_corr_kendall">target_corr_kendall</code></td>
<td>
<p>A numeric value. The desired target Kendall's tau correlation
between the two generated variables.</p>
</td></tr>
<tr><td><code id="get_target_corr_+3A_copula_type">copula_type</code></td>
<td>
<p>A string. The type of copula to use, either &quot;gaussian&quot; or &quot;t&quot; (default is &quot;gaussian&quot;).</p>
</td></tr>
<tr><td><code id="get_target_corr_+3A_inv_cdf_type">inv_cdf_type</code></td>
<td>
<p>A string. The type of inverse CDF method to use. Options include:
&quot;quantile_1&quot;, &quot;quantile_4&quot;, &quot;quantile_7&quot;, &quot;quantile_8&quot;, &quot;linear&quot;,
&quot;akima&quot;, &quot;poly&quot; (default is &quot;quantile_7&quot;).</p>
</td></tr>
<tr><td><code id="get_target_corr_+3A_degree">degree</code></td>
<td>
<p>An integer. The degree of the polynomial interpolation (default is 10).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function works by:
</p>

<ol>
<li><p> Generating two variables using the specified copula type (Gaussian or t) with the target
Kendall's tau correlation.
</p>
</li>
<li><p> Applying the chosen inverse CDF transformation to the generated copula samples.
</p>
</li>
<li><p> Returning the modified variables that have the target correlation.
</p>
</li></ol>



<h3>Value</h3>

<p>A list containing two components: <code>x1</code> and <code>x2</code>, which are the modified
versions of the input datasets <code>x1</code> and <code>x2</code> with the desired target
Kendall's tau correlation.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gaussian_copula_two_vars">gaussian_copula_two_vars</a></code>, <code><a href="#topic+t_copula_two_vars">t_copula_two_vars</a></code>,
<code><a href="#topic+genCDFInv_quantile">genCDFInv_quantile</a></code>, <code><a href="#topic+genCDFInv_linear">genCDFInv_linear</a></code>,
<code><a href="#topic+genCDFInv_akima">genCDFInv_akima</a></code>, <code><a href="#topic+genCDFInv_poly">genCDFInv_poly</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example usage:
x1 &lt;- ChickWeight$weight
x2 &lt;- ChickWeight$Time
cor(x1, x2, method = "kendall")  # Calculate original Kendall's tau correlation
res &lt;- get_target_corr(x1, x2, target_corr_kendall = 0,
                       copula_type = "gaussian", inv_cdf_type = "poly")
cor(res$x1, res$x2, method = "kendall")  # Calculate modified Kendall's tau correlation

</code></pre>

<hr>
<h2 id='get_target_entropy'>Get Target Entropy</h2><span id='topic+get_target_entropy'></span>

<h3>Description</h3>

<p>This function adjusts the mutual information between two categorical variables (x and y)
by modifying their contingency table using simulated annealing to reach a target entropy.
The function first calculates the range of possible entropy values (min and max) and checks if the target entropy
lies within that range. If so, it adjusts the mutual information to reach the target entropy, either by increasing or
decreasing it, depending on the initial entropy value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_target_entropy(x, y, target_entropy, max_n = 10000, epsilon = 0.001)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_target_entropy_+3A_x">x</code></td>
<td>
<p>A vector of categorical values representing variable x.</p>
</td></tr>
<tr><td><code id="get_target_entropy_+3A_y">y</code></td>
<td>
<p>A vector of categorical values representing variable y.</p>
</td></tr>
<tr><td><code id="get_target_entropy_+3A_target_entropy">target_entropy</code></td>
<td>
<p>The target entropy value to be reached.</p>
</td></tr>
<tr><td><code id="get_target_entropy_+3A_max_n">max_n</code></td>
<td>
<p>Maximum number of iterations for the optimization process (default is 10,000).</p>
</td></tr>
<tr><td><code id="get_target_entropy_+3A_epsilon">epsilon</code></td>
<td>
<p>The tolerance value for determining if the target entropy has been reached (default is 0.001).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing:
</p>

<ul>
<li><p> final_df: A dataframe with the adjusted contingency table.
</p>
</li>
<li><p> final_table: The final contingency table after adjustments.
</p>
</li>
<li><p> history: The history of the optimization process.
</p>
</li>
<li><p> max_mut: The maximum mutual information found.
</p>
</li>
<li><p> min_mut: The minimum mutual information found.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>set.seed(33)
df &lt;- data.frame(
  x = sample(paste("Categ", 1:4), 10000, replace = TRUE),
  y = sample(paste("Categ", 10:4), 10000, replace = TRUE)
)
target_entropy &lt;- 1  # Set your target entropy here
res &lt;- get_target_entropy(df$x, df$y, target_entropy)


</code></pre>

<hr>
<h2 id='log_odds_dc'>Log-Odds Calculation for Concordant and Discordant Pairs</h2><span id='topic+log_odds_dc'></span>

<h3>Description</h3>

<p>This function calculates the log-odds ratio for concordant and discordant pairs
based on the contingency table provided. The log-odds ratio is defined as the
natural logarithm of the ratio of concordant to discordant pairs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>log_odds_dc(tab)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="log_odds_dc_+3A_tab">tab</code></td>
<td>
<p>A contingency table (matrix or data frame) containing counts of pairs
for each combination of outcomes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The log-odds ratio calculated as the natural logarithm of the ratio of
concordant pairs to discordant pairs. If discordant pairs are zero,
it returns <code>Inf</code> to avoid division by zero.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example contingency table
tab &lt;- matrix(c(10, 5, 7, 8), nrow = 2)
log_odds_dc(tab)

</code></pre>

<hr>
<h2 id='objective_function_SL'>Objective Function for Structural Learning (SL)</h2><span id='topic+objective_function_SL'></span>

<h3>Description</h3>

<p>This function calculates the objective function for a structural learning task. It computes multiple components
such as the total variation (TV) distance between original and generated datasets (<code>X</code> vs. <code>X_prime</code>, <code>Y</code> vs. <code>Y_prime</code>),
the changes in regression coefficients (<code>beta0</code> and <code>beta1</code>), the R² differences for each category in <code>Z</code>, and the
inter-cluster centroid distances. The loss function combines these components using penalty parameters (<code>lambda1</code>, <code>lambda2</code>,
<code>lambda3</code>, <code>lambda4</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>objective_function_SL(
  X_prime,
  Y_prime,
  X,
  Y,
  Z,
  p,
  beta0_orig,
  beta1_orig,
  lambda1,
  lambda2,
  lambda3,
  lambda4,
  R2_orig,
  printc = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="objective_function_SL_+3A_x_prime">X_prime</code></td>
<td>
<p>A numeric vector representing the generated values of <code>X</code>.</p>
</td></tr>
<tr><td><code id="objective_function_SL_+3A_y_prime">Y_prime</code></td>
<td>
<p>A numeric vector representing the generated values of <code>Y</code>.</p>
</td></tr>
<tr><td><code id="objective_function_SL_+3A_x">X</code></td>
<td>
<p>A numeric vector representing the original values of <code>X</code>.</p>
</td></tr>
<tr><td><code id="objective_function_SL_+3A_y">Y</code></td>
<td>
<p>A numeric vector representing the original values of <code>Y</code>.</p>
</td></tr>
<tr><td><code id="objective_function_SL_+3A_z">Z</code></td>
<td>
<p>A categorical vector representing the categories for each observation.</p>
</td></tr>
<tr><td><code id="objective_function_SL_+3A_p">p</code></td>
<td>
<p>A numeric vector representing the target correlation values for each category in <code>Z</code>.</p>
</td></tr>
<tr><td><code id="objective_function_SL_+3A_beta0_orig">beta0_orig</code></td>
<td>
<p>The original intercept value for the regression model.</p>
</td></tr>
<tr><td><code id="objective_function_SL_+3A_beta1_orig">beta1_orig</code></td>
<td>
<p>The original slope value for the regression model.</p>
</td></tr>
<tr><td><code id="objective_function_SL_+3A_lambda1">lambda1</code></td>
<td>
<p>Penalty parameters to control the importance of different loss components.</p>
</td></tr>
<tr><td><code id="objective_function_SL_+3A_lambda2">lambda2</code></td>
<td>
<p>Penalty parameters to control the importance of different loss components.</p>
</td></tr>
<tr><td><code id="objective_function_SL_+3A_lambda3">lambda3</code></td>
<td>
<p>Penalty parameters to control the importance of different loss components.</p>
</td></tr>
<tr><td><code id="objective_function_SL_+3A_lambda4">lambda4</code></td>
<td>
<p>Penalty parameters to control the importance of different loss components.</p>
</td></tr>
<tr><td><code id="objective_function_SL_+3A_r2_orig">R2_orig</code></td>
<td>
<p>The original R² value for the model (not used directly in the calculation but might be for reference).</p>
</td></tr>
<tr><td><code id="objective_function_SL_+3A_printc">printc</code></td>
<td>
<p>A boolean flag to control printing of intermediate values for debugging.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value representing the total loss calculated by the objective function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Test Case 1: Simple random data with normal distribution
set.seed(123)
X &lt;- rnorm(100)
Y &lt;- rnorm(100)
Z &lt;- sample(1:3, 100, replace = TRUE)
X_prime &lt;- rnorm(100)
Y_prime &lt;- rnorm(100)
p &lt;- c(0.5, 0.7, 0.9)
beta0_orig &lt;- 0
beta1_orig &lt;- 1
lambda1 &lt;- lambda2 &lt;- lambda3 &lt;- lambda4 &lt;- 1
R2_orig &lt;- 0.9
loss &lt;- objective_function_SL(X, Y, Z, X_prime, Y_prime, p, beta0_orig, beta1_orig,
                               lambda1, lambda2, lambda3, lambda4, R2_orig)
print(loss)

# Test Case 2: Skewed data with different categories and a larger lambda for penalty
X &lt;- rexp(100)
Y &lt;- rpois(100, lambda = 2)
Z &lt;- sample(1:4, 100, replace = TRUE)
X_prime &lt;- rnorm(100)
Y_prime &lt;- rnorm(100)
p &lt;- c(0.3, 0.5, 0.8, 0.6)
beta0_orig &lt;- 0.5
beta1_orig &lt;- 1.5
lambda1 &lt;- lambda2 &lt;- lambda3 &lt;- 0.5
lambda4 &lt;- 2
R2_orig &lt;- 0.85
loss &lt;- objective_function_SL(X, Y, Z, X_prime, Y_prime, p, beta0_orig, beta1_orig,
                               lambda1, lambda2, lambda3, lambda4, R2_orig)
print(loss)

</code></pre>

<hr>
<h2 id='plot_log_odds'>Plot Log-Odds Before and After Transformation</h2><span id='topic+plot_log_odds'></span>

<h3>Description</h3>

<p>This function calculates the log-odds ratio before and after applying a transformation
to multiple matrices, and generates a bar plot comparing the log-odds values.
The log-odds are calculated using a specified function (default is <code>log_odds_dc</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_log_odds(
  matrices,
  new_matrices,
  names_matrices,
  log_odds_general = log_odds_dc
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_log_odds_+3A_matrices">matrices</code></td>
<td>
<p>A list of matrices for which the log-odds are calculated before the transformation.</p>
</td></tr>
<tr><td><code id="plot_log_odds_+3A_new_matrices">new_matrices</code></td>
<td>
<p>A list of matrices for which the log-odds are calculated after the transformation.</p>
</td></tr>
<tr><td><code id="plot_log_odds_+3A_names_matrices">names_matrices</code></td>
<td>
<p>A vector of names corresponding to the matrices in <code>matrices</code> and <code>new_matrices</code>.</p>
</td></tr>
<tr><td><code id="plot_log_odds_+3A_log_odds_general">log_odds_general</code></td>
<td>
<p>A function used to calculate the log-odds (default is <code>log_odds_dc</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A bar plot showing the log-odds before and after the transformation for each matrix and overall.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example matrices and names
matrices &lt;- list(matrix(c(1, 2, 3, 4), nrow = 2), matrix(c(2, 3, 4, 5), nrow = 2))
new_matrices &lt;- list(matrix(c(5, 6, 7, 8), nrow = 2), matrix(c(4, 5, 6, 7), nrow = 2))
names_matrices &lt;- c("Matrix1", "Matrix2")
plot_log_odds(matrices, new_matrices, names_matrices)

</code></pre>

<hr>
<h2 id='simulated_annealing_MI'>Simulated Annealing Algorithm with Target Entropy Stopping Condition</h2><span id='topic+simulated_annealing_MI'></span>

<h3>Description</h3>

<p>This function performs simulated annealing to optimize a given objective (entropy, mutual information, etc.)
using a given table modification function. The optimization stops once the target entropy is reached or
after a maximum number of iterations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulated_annealing_MI(
  initial_table,
  obj,
  gen_fn,
  target,
  max_n = 5000,
  temp = 10,
  maxim = TRUE,
  readj = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulated_annealing_MI_+3A_initial_table">initial_table</code></td>
<td>
<p>A contingency table to start the optimization.</p>
</td></tr>
<tr><td><code id="simulated_annealing_MI_+3A_obj">obj</code></td>
<td>
<p>An objective function that calculates the value to be optimized (e.g., entropy, mutual information).</p>
</td></tr>
<tr><td><code id="simulated_annealing_MI_+3A_gen_fn">gen_fn</code></td>
<td>
<p>A function that generates a new table based on the current table.</p>
</td></tr>
<tr><td><code id="simulated_annealing_MI_+3A_target">target</code></td>
<td>
<p>The target value for the objective function (e.g., target entropy).</p>
</td></tr>
<tr><td><code id="simulated_annealing_MI_+3A_max_n">max_n</code></td>
<td>
<p>The maximum number of iterations to run the algorithm (default is 5000).</p>
</td></tr>
<tr><td><code id="simulated_annealing_MI_+3A_temp">temp</code></td>
<td>
<p>The initial temperature for the simulated annealing process (default is 10).</p>
</td></tr>
<tr><td><code id="simulated_annealing_MI_+3A_maxim">maxim</code></td>
<td>
<p>Logical: Should the algorithm maximize (TRUE) or minimize (FALSE) the objective function (default is TRUE).</p>
</td></tr>
<tr><td><code id="simulated_annealing_MI_+3A_readj">readj</code></td>
<td>
<p>Logical: If TRUE, the algorithm is in a readjusting state (default is FALSE).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing:
</p>

<ul>
<li> <p><code>best</code>: The best table found during the optimization process.
</p>
</li>
<li> <p><code>best_eval</code>: The best evaluation value (objective function value).
</p>
</li>
<li> <p><code>n</code>: The number of iterations completed.
</p>
</li>
<li> <p><code>mutual_info_history</code>: A data frame with the history of mutual information values (or objective function values)
during each iteration.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Example of using simulated annealing for entropy maximization:
initial_table &lt;- matrix(c(5, 3, 4, 2), nrow = 2, ncol = 2)
obj &lt;- entropy_pair  # Example entropy function
gen_fn &lt;- gen_number_max  # Example generation function
target &lt;- 0.5
result &lt;- simulated_annealing_MI(initial_table, obj, gen_fn, target)

</code></pre>

<hr>
<h2 id='simulated_annealing_SL'>Simulated Annealing Optimization with Categorical Variable and R^2 Differences</h2><span id='topic+simulated_annealing_SL'></span>

<h3>Description</h3>

<p>This function implements the Simulated Annealing algorithm to optimize a solution
based on the total variation distance, changes in regression coefficients,
R-squared differences, and inter-cluster distance, with respect to a set of
categorical and continuous variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulated_annealing_SL(
  X,
  Y,
  Z,
  X_st,
  Y_st,
  p,
  sd_x = 0.05,
  sd_y = 0.05,
  lambda1 = 1,
  lambda2 = 1,
  lambda3 = 1,
  lambda4 = 1,
  max_iter = 1000,
  initial_temp = 1,
  cooling_rate = 0.99
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulated_annealing_SL_+3A_x">X</code></td>
<td>
<p>A numeric vector or matrix of input data (independent variable).</p>
</td></tr>
<tr><td><code id="simulated_annealing_SL_+3A_y">Y</code></td>
<td>
<p>A numeric vector of the dependent variable (target).</p>
</td></tr>
<tr><td><code id="simulated_annealing_SL_+3A_z">Z</code></td>
<td>
<p>A categorical variable (vector), used for grouping data in the analysis.</p>
</td></tr>
<tr><td><code id="simulated_annealing_SL_+3A_x_st">X_st</code></td>
<td>
<p>A numeric vector of starting values for the composition method of X.</p>
</td></tr>
<tr><td><code id="simulated_annealing_SL_+3A_y_st">Y_st</code></td>
<td>
<p>A numeric vector of starting values for the composition method of Y.</p>
</td></tr>
<tr><td><code id="simulated_annealing_SL_+3A_p">p</code></td>
<td>
<p>A numeric vector representing the target R^2 values for each category in Z.</p>
</td></tr>
<tr><td><code id="simulated_annealing_SL_+3A_sd_x">sd_x</code></td>
<td>
<p>Standard deviation for the noise added to X during the perturbation (default is 0.05).</p>
</td></tr>
<tr><td><code id="simulated_annealing_SL_+3A_sd_y">sd_y</code></td>
<td>
<p>Standard deviation for the noise added to Y during the perturbation (default is 0.05).</p>
</td></tr>
<tr><td><code id="simulated_annealing_SL_+3A_lambda1">lambda1</code></td>
<td>
<p>Regularization parameter for the total variation distance term (default is 1).</p>
</td></tr>
<tr><td><code id="simulated_annealing_SL_+3A_lambda2">lambda2</code></td>
<td>
<p>Regularization parameter for the coefficient difference term (default is 1).</p>
</td></tr>
<tr><td><code id="simulated_annealing_SL_+3A_lambda3">lambda3</code></td>
<td>
<p>Regularization parameter for the R^2 difference term (default is 1).</p>
</td></tr>
<tr><td><code id="simulated_annealing_SL_+3A_lambda4">lambda4</code></td>
<td>
<p>Regularization parameter for the inter-cluster distance term (default is 1).</p>
</td></tr>
<tr><td><code id="simulated_annealing_SL_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum number of iterations for the annealing process (default is 1000).</p>
</td></tr>
<tr><td><code id="simulated_annealing_SL_+3A_initial_temp">initial_temp</code></td>
<td>
<p>Initial temperature for the annealing process (default is 1.0).</p>
</td></tr>
<tr><td><code id="simulated_annealing_SL_+3A_cooling_rate">cooling_rate</code></td>
<td>
<p>The rate at which the temperature cools down during annealing (default is 0.99).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the optimized values of X_prime and Y_prime.
</p>

<hr>
<h2 id='sinkhorn_algorithm'>Sinkhorn Algorithm for Matrix Scaling</h2><span id='topic+sinkhorn_algorithm'></span>

<h3>Description</h3>

<p>This function applies the Sinkhorn-Knopp algorithm to adjust the row and column sums of a matrix
to match the target sums. The algorithm iteratively scales the rows and columns by updating
scaling factors (alpha and beta) until convergence or the maximum number of iterations is reached.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sinkhorn_algorithm(initial_table, obj, max_iter = 500, tolerance = 1e-05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sinkhorn_algorithm_+3A_initial_table">initial_table</code></td>
<td>
<p>A matrix to be adjusted using the Sinkhorn algorithm.</p>
</td></tr>
<tr><td><code id="sinkhorn_algorithm_+3A_obj">obj</code></td>
<td>
<p>An objective function to evaluate the matrix (e.g., entropy, mutual information).</p>
</td></tr>
<tr><td><code id="sinkhorn_algorithm_+3A_max_iter">max_iter</code></td>
<td>
<p>The maximum number of iterations for the algorithm (default is 500).</p>
</td></tr>
<tr><td><code id="sinkhorn_algorithm_+3A_tolerance">tolerance</code></td>
<td>
<p>The convergence tolerance. If the change in the objective function is smaller than this,
the algorithm stops (default is 1e-5).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing:
</p>

<ul>
<li> <p><code>updated_table</code>: The matrix after Sinkhorn scaling.
</p>
</li>
<li> <p><code>new_mut</code>: The objective function value for the scaled matrix.
</p>
</li>
<li> <p><code>iter</code>: The number of iterations performed.
</p>
</li>
<li> <p><code>mutual_info_history</code>: A data frame with the history of objective function values during each iteration.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>initial_table &lt;- matrix(c(5, 3, 4, 2), nrow = 2, ncol = 2)
obj &lt;- entropy_pair  # Example entropy function
result &lt;- sinkhorn_algorithm(initial_table, obj)

</code></pre>

<hr>
<h2 id='softmax'>Softmax Function with Special Handling for Infinite Values</h2><span id='topic+softmax'></span>

<h3>Description</h3>

<p>This function computes the softmax of a vector <code>x</code>, with special handling for infinite values.
The softmax function transforms input values into a probability distribution by exponentiating
each value, then normalizing by the sum of all exponentiated values.
The function ensures numerical stability, particularly when dealing with very large or very small values,
and handles cases where the values are infinite (<code>Inf</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>softmax(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="softmax_+3A_x">x</code></td>
<td>
<p>A numeric vector for which the softmax function will be calculated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of the same length as <code>x</code>, where the values represent probabilities summing to 1.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>softmax(c(10, 5, 2))
softmax(c(Inf, -Inf, 0))
softmax(c(-Inf, -Inf, -Inf))

</code></pre>

<hr>
<h2 id='t_copula_two_vars'>Generate t-Copula Samples for Two Variables</h2><span id='topic+t_copula_two_vars'></span>

<h3>Description</h3>

<p>This function generates samples from a t-copula with two variables,
given the specified correlation coefficient between the variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>t_copula_two_vars(n, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="t_copula_two_vars_+3A_n">n</code></td>
<td>
<p>Integer. The number of samples to generate.</p>
</td></tr>
<tr><td><code id="t_copula_two_vars_+3A_p">p</code></td>
<td>
<p>Numeric. The correlation coefficient (<code class="reqn">\rho</code>) between the two variables.
Must be in the range <code>[-1, 1]</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function internally constructs a correlation matrix for two variables:
</p>
<p style="text-align: center;"><code class="reqn">\rho_matrix = \begin{bmatrix} 1 &amp; p \\ p &amp; 1 \end{bmatrix}</code>
</p>

<p>It then calls <code>generate_t_copula_samples</code> to generate samples using
a t-distribution with 5 degrees of freedom.
</p>


<h3>Value</h3>

<p>A matrix of size <code>n x 2</code>, where each row represents a sample,
and each column corresponds to one of the two variables. The values
are uniformly distributed in <code>[0, 1]</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+generate_t_copula_samples">generate_t_copula_samples</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example usage:
samples &lt;- t_copula_two_vars(n = 1000, p = 0.7)
head(samples)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
