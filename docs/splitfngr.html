<!DOCTYPE html><html lang="en"><head><title>Help for package splitfngr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {splitfngr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#fngr'><p>Access a list of values separately but calculate them together.</p>
This function generalizes grad_share for any number of functions.</a></li>
<li><a href='#grad_share'><p>Split function and gradient calculation</p></a></li>
<li><a href='#lbfgs_share'><p>Use splitfngr with lbfgs</p></a></li>
<li><a href='#make_share'><p>Convert a function from multiple function arguments to a</p>
single function</a></li>
<li><a href='#nlminb_share'><p>Use splitfngr with nlminb</p></a></li>
<li><a href='#optim_share'><p>Use splitfngr with optim</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Combined Evaluation and Split Access of Functions</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.2</td>
</tr>
<tr>
<td>Author:</td>
<td>Collin Erickson</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Collin Erickson &lt;collinberickson@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>
  Some R functions, such as optim(), require a function
  its gradient passed as separate arguments. When these are
  expensive to calculate it may be much faster to calculate
  the function (fn) and gradient (gr) together since they often share
  many calculations (chain rule). This package allows the user
  to pass in a single function that returns both the function
  and gradient, then splits (hence 'splitfngr') them
  so the results can be accessed
  separately. The functions provided allow this to be done with
  any number of functions/values, not just for functions and gradients.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>lbfgs</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-01-30 14:12:15 UTC; cbe117</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-01-30 15:20:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='fngr'>Access a list of values separately but calculate them together.
This function generalizes grad_share for any number of functions.</h2><span id='topic+fngr'></span>

<h3>Description</h3>

<p>Access a list of values separately but calculate them together.
This function generalizes grad_share for any number of functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fngr(func, evalForNewX = TRUE, recalculate_indices = c(),
  check_all = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fngr_+3A_func">func</code></td>
<td>
<p>Function that returns a list of values</p>
</td></tr>
<tr><td><code id="fngr_+3A_evalfornewx">evalForNewX</code></td>
<td>
<p>Should the function reevaluate for any new x?
Recommended.</p>
</td></tr>
<tr><td><code id="fngr_+3A_recalculate_indices">recalculate_indices</code></td>
<td>
<p>Indices for which the values should
be recalculated. Ignored if evalForNewX is true. Use this if
you don't want to pass x to dependent functions, or if you know
other indices won't need to be recalculated.</p>
</td></tr>
<tr><td><code id="fngr_+3A_check_all">check_all</code></td>
<td>
<p>Should it check that the accessed values were
calculated at the current input? Ignored if evalForNewX is true.
Will give a warning but still return the stored value.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An environment where the function values are calculated.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tfunc &lt;- function(x) {list(x+1, x+2, x+3, x+4, x+5)}
f &lt;- fngr(tfunc)
f(1)(0)
f(3)(0)
f(3)(1)
f(1)(23.4)
f(4)()

# Use same function but only recalculate when first value is called
g &lt;- fngr(tfunc, evalForNewX = FALSE, recalculate_indices = c(1))
g1 &lt;- g(1)
g3 &lt;- g(3)
g1(1)
g3(1)
g3(11) # This won't be give expected value
g1(11) # This updates all values
g3(11) # This is right
</code></pre>

<hr>
<h2 id='grad_share'>Split function and gradient calculation</h2><span id='topic+grad_share'></span>

<h3>Description</h3>

<p>Calculate function and gradient together but access separately.
Reduces computation since they share data in calculation.
Doesn't have to be function and gradient, can be any two
values calculated together but accessed separately.
Useful in optimization when function evaluation is expensive
since the chain rule means many parts of function and gradient
are the same.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grad_share(fn_gr)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="grad_share_+3A_fn_gr">fn_gr</code></td>
<td>
<p>A function that returns a list of two values.
Both are calculated when fn is called, but only the first
is returned. The second is returned when gr is called
but nothing is recalculated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An environment with two functions, fn and gr.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>quad_share &lt;- function(x){list(sum(x^4), 4*x^3)}
share &lt;- grad_share(quad_share)
share$fn(1)
share$gr(1)
share$gr(2)
share$fn(2)
share$gr(2)
</code></pre>

<hr>
<h2 id='lbfgs_share'>Use splitfngr with lbfgs</h2><span id='topic+lbfgs_share'></span>

<h3>Description</h3>

<p>Use lbfgs function from the lbfgs package but pass in a single function
that returns both the function and gradient
together in a list. Useful when the function and
gradient are expensive to calculate and can be
calculated faster together than separate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lbfgs_share(fngr, vars, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lbfgs_share_+3A_fngr">fngr</code></td>
<td>
<p>A function that returns a list of two elements:
the function value and the gradient value.</p>
</td></tr>
<tr><td><code id="lbfgs_share_+3A_vars">vars</code></td>
<td>
<p>Initial values for the parameters to be optimized over.
Will be passed to lbfgs as vars argument.</p>
</td></tr>
<tr><td><code id="lbfgs_share_+3A_...">...</code></td>
<td>
<p>Other arguments passed to lbfgs</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Result from running lbfgs on the given function
</p>


<h3>Examples</h3>

<pre><code class='language-R'>quad_share &lt;- function(x){list(sum(x^4), 4*x^3)}
lbfgs_share(vars=c(3, -5), fngr=quad_share)
</code></pre>

<hr>
<h2 id='make_share'>Convert a function from multiple function arguments to a
single function</h2><span id='topic+make_share'></span>

<h3>Description</h3>

<p>Convert a function from multiple function arguments to a
single function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_share(func, arg_fn, arg_gr)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="make_share_+3A_func">func</code></td>
<td>
<p>The function that takes in two function arguments</p>
</td></tr>
<tr><td><code id="make_share_+3A_arg_fn">arg_fn</code></td>
<td>
<p>The function (first) argument name of func</p>
</td></tr>
<tr><td><code id="make_share_+3A_arg_gr">arg_gr</code></td>
<td>
<p>The gradient (second) argument name of func</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A new function that evaluates the two arguments together
</p>


<h3>Examples</h3>

<pre><code class='language-R'>quad_share &lt;- function(x){list(sum(x^4), 4*x^3)}
lbfgs_share &lt;- make_share(lbfgs::lbfgs, 'call_eval', 'call_grad')
make_share(lbfgs::lbfgs, 'call_eval', 'call_grad')(quad_share, vars=c(5,-4))
</code></pre>

<hr>
<h2 id='nlminb_share'>Use splitfngr with nlminb</h2><span id='topic+nlminb_share'></span>

<h3>Description</h3>

<p>Use nlminb function but pass in a single function
that returns both the function and gradient
together in a list. Useful when the function and
gradient are expensive to calculate and can be
calculated faster together than separate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlminb_share(start, fngr, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nlminb_share_+3A_start">start</code></td>
<td>
<p>Initial values for the parameters to be optimized over.
Will be passed to nlminb as start argument.</p>
</td></tr>
<tr><td><code id="nlminb_share_+3A_fngr">fngr</code></td>
<td>
<p>A function that returns a list of two elements:
the function value and the gradient value.</p>
</td></tr>
<tr><td><code id="nlminb_share_+3A_...">...</code></td>
<td>
<p>Other arguments passed to nlminb</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Result from running nlminb on the given function
</p>


<h3>Examples</h3>

<pre><code class='language-R'>quad_share &lt;- function(x){list(sum(x^4), 4*x^3)}
nlminb_share(start=c(3, -5), fngr=quad_share)

## Not run: 
# Add a sleep amount to show when it can be faster

# Using share
quad_fngr &lt;- function(x){Sys.sleep(.01); list(sum(x^4), 4*x^3)}
system.time(nlminb_share(start=c(3, -5), fngr=quad_fngr))

# Without share
quad_fn &lt;- function(x) {Sys.sleep(.01); sum(x^4)}
quad_gr &lt;- function(x) {Sys.sleep(.01); 4*x^3}
system.time(nlminb(c(3,-5), quad_fn, quad_gr))

## End(Not run)
</code></pre>

<hr>
<h2 id='optim_share'>Use splitfngr with optim</h2><span id='topic+optim_share'></span>

<h3>Description</h3>

<p>Use R's optim function but pass in a single function
that returns both the function and gradient
together in a list. Useful when the function and
gradient are expensive to calculate and can be
calculated faster together than separate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optim_share(par, fngr, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="optim_share_+3A_par">par</code></td>
<td>
<p>Initial values for the parameters to be optimized over.
Will be passed to optim as par argument.</p>
</td></tr>
<tr><td><code id="optim_share_+3A_fngr">fngr</code></td>
<td>
<p>A function that returns a list of two elements:
the function value and the gradient value.</p>
</td></tr>
<tr><td><code id="optim_share_+3A_...">...</code></td>
<td>
<p>Arguments passed to optim, such as method,
lower, upper, control, and hessian.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Results from running optim
</p>


<h3>Examples</h3>

<pre><code class='language-R'>quad_share &lt;- function(x){list(sum(x^4), 4*x^3)}
optim_share(par=c(3, -5), quad_share, method="BFGS")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
