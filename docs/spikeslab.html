<!DOCTYPE html><html><head><title>Help for package spikeslab</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {spikeslab}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cv.spikeslab'><p>K-fold Cross-Validation for Spike and Slab Regression</p></a></li>
<li><a href='#diabetesI'><p>Diabetes Data with Interactions</p></a></li>
<li><a href='#housingI'><p>Boston Housing Interaction Data</p></a></li>
<li><a href='#leukemia'><p>Golub Leukemia Gene Expression Data</p></a></li>
<li><a href='#ozoneI'><p>Ozone Interaction Data</p></a></li>
<li><a href='#plot.spikeslab'><p>Plots for Spike and Slab Analysis</p></a></li>
<li><a href='#predict.spikeslab'><p>Spike and Slab Prediction</p></a></li>
<li><a href='#print.spikeslab'><p>Print Summary Output of Analysis</p></a></li>
<li><a href='#sparsePC.spikeslab'><p>Multiclass Prediction using Spike and Slab Regression</p></a></li>
<li><a href='#spikeslab'><p>Spike and Slab Regression</p></a></li>
<li><a href='#spikeslab.news'><p>Show the NEWS file</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.1.6</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-04-26</td>
</tr>
<tr>
<td>Title:</td>
<td>Prediction and Variable Selection Using Spike and Slab
Regression</td>
</tr>
<tr>
<td>Author:</td>
<td>Hemant Ishwaran &lt;hemant.ishwaran@gmail.com&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Udaya B. Kogalur &lt;ubk@kogalur.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0),</td>
</tr>
<tr>
<td>Imports:</td>
<td>lars, randomForest, parallel</td>
</tr>
<tr>
<td>Description:</td>
<td>Spike and slab for prediction and variable selection in linear regression models. Uses a generalized elastic net for variable selection.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://ishwaran.org/">https://ishwaran.org/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-04-26 15:22:17 UTC; kogalur</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-04-26 20:50:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='cv.spikeslab'>K-fold Cross-Validation for Spike and Slab Regression</h2><span id='topic+cv.spikeslab'></span>

<h3>Description</h3>

<p>Computes the K-fold cross-validated mean squared prediction error for
the generalized elastic net from spike and slab regression.  Returns a
stability index for each variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.spikeslab(x = NULL, y = NULL, K = 10,
    plot.it = TRUE, n.iter1 = 500, n.iter2 = 500, mse = TRUE,
    bigp.smalln = FALSE, bigp.smalln.factor = 1, screen = (bigp.smalln),
    r.effects = NULL, max.var = 500, center = TRUE, intercept = TRUE,
    fast = TRUE, beta.blocks = 5, verbose = TRUE, save.all = TRUE,
    ntree = 300, seed = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.spikeslab_+3A_x">x</code></td>
<td>
<p>x-predictor matrix.</p>
</td></tr>
<tr><td><code id="cv.spikeslab_+3A_y">y</code></td>
<td>
<p>y-response values.</p>
</td></tr>
<tr><td><code id="cv.spikeslab_+3A_k">K</code></td>
<td>
<p>Number of folds.</p>
</td></tr>
<tr><td><code id="cv.spikeslab_+3A_plot.it">plot.it</code></td>
<td>
<p>If TRUE, plots the mean prediction error and its standard error.</p>
</td></tr>
<tr><td><code id="cv.spikeslab_+3A_n.iter1">n.iter1</code></td>
<td>
<p>Number of burn-in Gibbs sampled values (i.e., discarded values).</p>
</td></tr>
<tr><td><code id="cv.spikeslab_+3A_n.iter2">n.iter2</code></td>
<td>
<p>Number of Gibbs sampled values, following burn-in.</p>
</td></tr>
<tr><td><code id="cv.spikeslab_+3A_mse">mse</code></td>
<td>
<p>If TRUE, an external estimate for the overall variance is calculated.</p>
</td></tr> 
<tr><td><code id="cv.spikeslab_+3A_bigp.smalln">bigp.smalln</code></td>
<td>
<p>Use if <code>p</code> &gt;&gt; <code>n</code>.</p>
</td></tr>
<tr><td><code id="cv.spikeslab_+3A_bigp.smalln.factor">bigp.smalln.factor</code></td>
<td>
<p>Top <code>n</code> times this value of variables
to be kept in the filtering step (used when <code>p</code> &gt;&gt; <code>n</code>).</p>
</td></tr>
<tr><td><code id="cv.spikeslab_+3A_screen">screen</code></td>
<td>
<p>If TRUE, variables are first pre-filtered.</p>
</td></tr>
<tr><td><code id="cv.spikeslab_+3A_r.effects">r.effects</code></td>
<td>
<p>List used for grouping variables (see details below).</p>
</td></tr>
<tr><td><code id="cv.spikeslab_+3A_max.var">max.var</code></td>
<td>
<p>Maximum number of variables allowed in the final model.</p>
</td></tr>
<tr><td><code id="cv.spikeslab_+3A_center">center</code></td>
<td>
<p>If TRUE, variables are centered by their
means. Default is TRUE and should only be adjusted in extreme examples.</p>
</td></tr>
<tr><td><code id="cv.spikeslab_+3A_intercept">intercept</code></td>
<td>
<p>If TRUE, an intercept is included in the model,
otherwise no intercept is included.  Default is TRUE.</p>
</td></tr>
<tr><td><code id="cv.spikeslab_+3A_fast">fast</code></td>
<td>
<p>If TRUE, use blocked Gibbs sampling to accelerate the algorithm.</p>
</td></tr>
<tr><td><code id="cv.spikeslab_+3A_beta.blocks">beta.blocks</code></td>
<td>
<p>Update beta using this number of blocks (<code>fast</code>
must be TRUE).</p>
</td></tr>
<tr><td><code id="cv.spikeslab_+3A_verbose">verbose</code></td>
<td>
<p>If TRUE, verbose output is sent to the terminal.</p>
</td></tr>
<tr><td><code id="cv.spikeslab_+3A_save.all">save.all</code></td>
<td>
<p>If TRUE, spikeslab object for each fold is saved and returned.</p>
</td></tr>
<tr><td><code id="cv.spikeslab_+3A_ntree">ntree</code></td>
<td>
<p>Number of trees used by random forests (applies only when <code>mse</code> is TRUE).</p>
</td></tr>
<tr><td><code id="cv.spikeslab_+3A_seed">seed</code></td>
<td>
<p>Seed for random number generator.  Must be a negative
integer.</p>
</td></tr>
<tr><td><code id="cv.spikeslab_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns a list with components:
</p>
<table>
<tr><td><code>spikeslab.obj</code></td>
<td>
<p>Spike and slab object from the full data.</p>
</td></tr>
<tr><td><code>cv.spikeslab.obj</code></td>
<td>
<p>List containing spike and slab objects from each fold.
Can be NULL.</p>
</td></tr>
<tr><td><code>cv.fold</code></td>
<td>
<p>List containing the cv splits.</p>
</td></tr>
<tr><td><code>cv</code></td>
<td>
<p>Mean-squared error for each fold for the gnet.</p>
</td></tr>
<tr><td><code>cv.path</code></td>
<td>
<p>A matrix of mean-squared errors for the gnet
solution path. Rows correspond to model sizes, columns are the folds.</p>
</td></tr>
<tr><td><code>stability</code></td>
<td>
<p>Matrix containing stability for each variable defined as the
percentage of times a variable is identified over the K-folds.
Also includes bma and gnet coefficient values and their cv-fold-averaged
values.</p>
</td></tr>
<tr><td><code>bma</code></td>
<td>
<p>bma coefficients from the full data in terms of the standardized x.</p>
</td></tr>
<tr><td><code>bma.scale</code></td>
<td>
<p>bma coefficients from the full data, scaled in terms of the original x.</p>
</td></tr>
<tr><td><code>gnet</code></td>
<td>
<p>cv-optimized gnet in terms of the standardized x.</p>
</td></tr>
<tr><td><code>gnet.scale</code></td>
<td>
<p>cv-optimized gnet in terms of the original x.</p>
</td></tr>
<tr><td><code>gnet.model</code></td>
<td>
<p>List of models selected by gnet over the K-folds.</p>
</td></tr>
<tr><td><code>gnet.path</code></td>
<td>
<p>gnet path from the full data, scaled in terms of the original x.</p>
</td></tr>
<tr><td><code>gnet.obj</code></td>
<td>
<p>gnet object from fitting the full data (a lars-type object).</p>
</td></tr>
<tr><td><code>gnet.obj.vars</code></td>
<td>
<p>Variables (in order) used to calculate the gnet object.</p>
</td></tr>
<tr><td><code>verbose</code></td>
<td>
<p>Verbose details (used for printing).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Hemant Ishwaran (<a href="mailto:hemant.ishwaran@gmail.com">hemant.ishwaran@gmail.com</a>)
</p>
<p>J. Sunil Rao (<a href="mailto:rao.jsunil@gmail.com">rao.jsunil@gmail.com</a>)
</p>
<p>Udaya B. Kogalur (<a href="mailto:ubk@kogalur.com">ubk@kogalur.com</a>)
</p>


<h3>References</h3>

<p>Ishwaran H. and Rao J.S. (2005a).  Spike and slab variable selection:
frequentist and Bayesian strategies.  <em>Ann. Statist.</em>,
33:730-773.
</p>
<p>Ishwaran H. and Rao J.S. (2010).  Generalized ridge regression:
geometry and computational solutions when p is larger than n.
</p>
<p>Ishwaran H. and Rao J.S. (2011).  Mixing generalized ridge
regressions.
</p>


<h3>See Also</h3>

<p><code>sparsePC.spikeslab</code>,
<code>plot.spikeslab</code>,
<code>predict.spikeslab</code>,
<code>print.spikeslab</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#------------------------------------------------------------
# Example 1: 10-fold validation using parallel processing
#------------------------------------------------------------

data(ozoneI, package = "spikeslab")
y &lt;- ozoneI[,  1]
x &lt;- ozoneI[, -1]
cv.obj &lt;- cv.spikeslab(x = x, y = y, parallel = 4)
plot(cv.obj, plot.type = "cv")
plot(cv.obj, plot.type = "path")

#------------------------------------------------------------
# Example 2: 10-fold validation using parallel processing
# (high dimensional diabetes data)
#------------------------------------------------------------

# add 2000 noise variables
data(diabetesI, package = "spikeslab")
diabetes.noise &lt;- cbind(diabetesI,
      noise = matrix(rnorm(nrow(diabetesI) * 2000), nrow(diabetesI)))
x &lt;- diabetes.noise[, -1]
y &lt;- diabetes.noise[, 1]

cv.obj &lt;- cv.spikeslab(x = x, y = y, bigp.smalln=TRUE, parallel = 4)
plot(cv.obj)

## End(Not run)
</code></pre>

<hr>
<h2 id='diabetesI'>Diabetes Data with Interactions</h2><span id='topic+diabetesI'></span>

<h3>Description</h3>

<p>The data consists of 442 patients in which the response of interest is a
quantitative measure of disease progression.  The data includes 10
baseline measurements for each patient, in addition to 45 interactions
and 9 quadratic terms, for a total of 64 variables for each patient.
The outcome is <code>Y</code>.
</p>


<h3>Source</h3>

<p>Efron B., Hastie T., Johnstone. I and Tibshirani R. (2004).
Least angle regression (with discussion).
<em>Ann. Statist.</em>, 32:407-499.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(diabetesI, package = "spikeslab")</code></pre>

<hr>
<h2 id='housingI'>Boston Housing Interaction Data</h2><span id='topic+housingI'></span>

<h3>Description</h3>

<p>Median house price for 506 census tracts of Boston from the 1970 census.
The original data comprises 506 observations and 13 variables but has
been modified here to include all pairwise interactions of main effects
and to include B-spline basis functions of up to 6 degrees of freedom
for all original predictors.  In addition, all real valued variables
were mapped to dummy variables representing a factor with three levels
and all pairwise interactions of these dummy variables were added to the
design matrix.  In total, the modified data contains 506 observations
and 658 variables.  The outcome is the median house price <code>medv</code>.
</p>


<h3>Source</h3>

<p>Harrison D. and Rubinfeld D.L. (1978).
Hedonic prices and the demand for clean air.
<em>J. Envir. Economics Management</em>, 5:81-102
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(housingI, package = "spikeslab")</code></pre>

<hr>
<h2 id='leukemia'>Golub Leukemia Gene Expression Data</h2><span id='topic+leukemia'></span>

<h3>Description</h3>

<p>Gene expression cancer data set (Golub et al.) of samples from human
acute myeloid (AML) and acute lymphoblastic leukemias (ALL).  3571
expression values on 72 individuals.
</p>


<h3>Source</h3>

<p>Golub T.R et al. (1999).
Molecular classification of cancer: class discovery and class prediction
by gene expression monitoring.
<em>Science</em>, 286(5439):531-537.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(leukemia, package = "spikeslab")</code></pre>

<hr>
<h2 id='ozoneI'>Ozone Interaction Data</h2><span id='topic+ozoneI'></span>

<h3>Description</h3>

<p>The data consists of 366 readings of maximum daily ozone measured in the
Los Angeles basin.  After removing missing values, the original data has
been expanded to include all pairwise interactions, as well as B-spline
basis functions (6 degrees of freedom), for each of the original 12
variables (9 meteorlogical variables and 3 variables recording date of
measurement: month, day of the month, and day of week).  In total, the
modified data has 203 observations and 134 variables.  The outcome is
<code>ozone</code>.
</p>


<h3>Source</h3>

<p>Breiman L. and Friedman J.H. (1985).
Estimating optimal transformations for multiple regression and correlation.
<em>J. Amer. Stat. Assoc.</em>, 80:580-598.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ozoneI, package = "spikeslab")</code></pre>

<hr>
<h2 id='plot.spikeslab'>Plots for Spike and Slab Analysis</h2><span id='topic+plot.spikeslab'></span>

<h3>Description</h3>

<p>Plots either the gnet solution path or the cross-validated
mean-squared-error (the latter only applies when cross-validation
is used).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'spikeslab'
plot(x, plot.type = c("path", "cv"), breaks = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.spikeslab_+3A_x">x</code></td>
<td>
<p>An object of class <code>spikeslab</code>.</p>
</td></tr>
<tr><td><code id="plot.spikeslab_+3A_plot.type">plot.type</code></td>
<td>
<p>Choosing &quot;path&quot; produces a plot of the gnet solution
path. The choice &quot;cv&quot; produces the mean-squared error plot.  The
latter applies only to objects from a <code>cv.spikeslab</code> call.</p>
</td></tr>
<tr><td><code id="plot.spikeslab_+3A_breaks">breaks</code></td>
<td>
<p>If TRUE, then vertical lines are drawn at each break
point in the gnet solution path.</p>
</td></tr>
<tr><td><code id="plot.spikeslab_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Hemant Ishwaran (<a href="mailto:hemant.ishwaran@gmail.com">hemant.ishwaran@gmail.com</a>)
</p>
<p>J. Sunil Rao (<a href="mailto:rao.jsunil@gmail.com">rao.jsunil@gmail.com</a>)
</p>
<p>Udaya B. Kogalur (<a href="mailto:ubk@kogalur.com">ubk@kogalur.com</a>)
</p>


<h3>References</h3>

<p>Efron B., Hastie T., Johnstone I., and Tibshirani R. (2004).
Least angle regression (with discussion). <em>Ann. Statist.</em>,
32:407-499.
</p>
<p>Ishwaran H. and Rao J.S. (2010).  Generalized ridge regression:
geometry and computational solutions when p is larger than n.
</p>


<h3>See Also</h3>

<p><code>spikeslab, cv.spikeslab</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#------------------------------------------------------------
# Example 1: diabetes data
#------------------------------------------------------------

data(diabetesI, package = "spikeslab")
obj &lt;- spikeslab(Y ~ . , diabetesI, verbose = TRUE)
plot(obj, plot.type = "path")

## End(Not run)
</code></pre>

<hr>
<h2 id='predict.spikeslab'>Spike and Slab Prediction</h2><span id='topic+predict.spikeslab'></span>

<h3>Description</h3>

<p>Prediction on test data using spike and slab regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'spikeslab'
predict(object, newdata = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.spikeslab_+3A_object">object</code></td>
<td>
<p>An object of class <code>spikeslab</code>.</p>
</td></tr>
<tr><td><code id="predict.spikeslab_+3A_newdata">newdata</code></td>
<td>
<p>Data frame or x-matrix containing test data (if
omitted, the training data is used).</p>
</td></tr>
<tr><td><code id="predict.spikeslab_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the predicted value using a test data set.
</p>


<h3>Value</h3>

<p>A vector of fitted values for the BMA and gnet and a matrix of fitted
values for the gnet path.  Also returns the grr mixing predictor if
the object has been parsed by the mixing wrapper.
</p>


<h3>Author(s)</h3>

<p>Hemant Ishwaran (<a href="mailto:hemant.ishwaran@gmail.com">hemant.ishwaran@gmail.com</a>)
</p>
<p>J. Sunil Rao (<a href="mailto:rao.jsunil@gmail.com">rao.jsunil@gmail.com</a>)
</p>
<p>Udaya B. Kogalur (<a href="mailto:ubk@kogalur.com">ubk@kogalur.com</a>)
</p>


<h3>References</h3>

<p>Ishwaran H. and Rao J.S. (2003).  Detecting differentially expressed
genes in microarrays using Bayesian model selection.
<em>J. Amer. Stat. Assoc.</em>, 98:438-455.
</p>
<p>Ishwaran H. and Rao J.S. (2005a).  Spike and slab variable selection: frequentist and Bayesian
strategies.  <em>Ann. Statist.</em>, 33:730-773.
</p>
<p>Ishwaran H. and Rao J.S. (2005b).  Spike and slab gene selection for
multigroup microarray data. <em>J. Amer. Stat. Assoc.</em>, 100:764-780.
</p>
<p>Ishwaran H. and Rao J.S. (2010).  Generalized ridge regression:
geometry and computational solutions when p is larger than n.
</p>
<p>Ishwaran H., Kogalur U.B. and Rao J.S. (2010). spikeslab: prediction
and variable selection using spike and slab regression. <em>R Journal</em>,
2(2), 68-73.
</p>
<p>Ishwaran H. and Rao J.S. (2011).  Mixing generalized ridge
regressions.
</p>


<h3>See Also</h3>

<p><code>spikeslab</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

#------------------------------------------------------------
# Example 1: get the predictor for the training data
#------------------------------------------------------------
data(diabetesI, package = "spikeslab")
x &lt;- diabetesI[, -1]
y &lt;- diabetesI[, 1]
obj &lt;- spikeslab(x = x, y = y)
#gnet predictor
yhat.gnet &lt;- predict(obj)$yhat.gnet
#an equivalent call is...
yhat.gnet &lt;- predict(obj, x = x)$yhat.gnet

#------------------------------------------------------------
# Example 2: ozone data with interactions
#------------------------------------------------------------

data(ozoneI, package = "spikeslab")
train.pt &lt;- sample(1:nrow(ozoneI), nrow(ozoneI) * 0.80)
obj &lt;- spikeslab(ozone ~ . , ozoneI[train.pt, ])
ytest &lt;- ozoneI$ozone[-train.pt]
ss.pred &lt;- predict(obj, ozoneI[-train.pt, ])
yhat.bma &lt;- ss.pred$yhat.bma
yhat.gnet &lt;- ss.pred$yhat.gnet
plot(ytest, yhat.bma, ylab = "yhat", pch = 16, col = 4)
points(ytest, yhat.gnet, pch = 16, col = 2)
abline(0, 1, lty = 2, col = 2)
legend("bottomright", legend = c("bma", "gnet"), col = c(4, 2), pch = 16)

## End(Not run)
</code></pre>

<hr>
<h2 id='print.spikeslab'>Print Summary Output of Analysis</h2><span id='topic+print.spikeslab'></span>

<h3>Description</h3>

<p>Print summary output from spike and slab analysis.
Note that this is the default print method for the package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'spikeslab'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.spikeslab_+3A_x">x</code></td>
<td>
<p>An object of class <code>spikeslab</code>.</p>
</td></tr>
<tr><td><code id="print.spikeslab_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Hemant Ishwaran (<a href="mailto:hemant.ishwaran@gmail.com">hemant.ishwaran@gmail.com</a>)
</p>
<p>J. Sunil Rao (<a href="mailto:rao.jsunil@gmail.com">rao.jsunil@gmail.com</a>)
</p>
<p>Udaya B. Kogalur (<a href="mailto:ubk@kogalur.com">ubk@kogalur.com</a>)
</p>


<h3>References</h3>

<p>Ishwaran H. and Rao J.S. (2003).  Detecting differentially expressed
genes in microarrays using Bayesian model selection.
<em>J. Amer. Stat. Assoc.</em>, 98:438-455.
</p>
<p>Ishwaran H. and Rao J.S. (2005a).  Spike and slab variable selection: frequentist and Bayesian
strategies.  <em>Ann. Statist.</em>, 33:730-773.
</p>
<p>Ishwaran H. and Rao J.S. (2005b).  Spike and slab gene selection for
multigroup microarray data. <em>J. Amer. Stat. Assoc.</em>, 100:764-780.
</p>
<p>Ishwaran H. and Rao J.S. (2009).  Generalized ridge regression:
geometry and computational solutions when p is larger than n.
</p>


<h3>See Also</h3>

<p><code>spikeslab</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#------------------------------------------------------------
# Example 1: diabetes data
#------------------------------------------------------------

data(diabetesI, package = "spikeslab")
obj &lt;- spikeslab(Y ~ . , diabetesI, verbose = TRUE)
print(obj)

## End(Not run)
</code></pre>

<hr>
<h2 id='sparsePC.spikeslab'>Multiclass Prediction using Spike and Slab Regression</h2><span id='topic+sparsePC.spikeslab'></span><span id='topic+sparsePC'></span>

<h3>Description</h3>

<p>Variable selection for the multiclass gene prediction problem.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sparsePC.spikeslab(x = NULL, y = NULL, n.rep = 10,
  n.iter1 = 150, n.iter2 = 100, n.prcmp = 5, max.genes = 100,
  ntree = 1000, nodesize = 1, verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sparsePC.spikeslab_+3A_x">x</code></td>
<td>
<p>x matrix of gene expressions.</p>
</td></tr>
<tr><td><code id="sparsePC.spikeslab_+3A_y">y</code></td>
<td>
<p>Class labels.</p>
</td></tr>
<tr><td><code id="sparsePC.spikeslab_+3A_n.rep">n.rep</code></td>
<td>
<p>Number of Monte Carlo replicates.</p>
</td></tr> 
<tr><td><code id="sparsePC.spikeslab_+3A_n.iter1">n.iter1</code></td>
<td>
<p>Number of burn-in Gibbs sampled values (i.e., discarded values).</p>
</td></tr>
<tr><td><code id="sparsePC.spikeslab_+3A_n.iter2">n.iter2</code></td>
<td>
<p>Number of Gibbs sampled values, following burn-in.</p>
</td></tr>
<tr><td><code id="sparsePC.spikeslab_+3A_n.prcmp">n.prcmp</code></td>
<td>
<p>Number of principal components.</p>
</td></tr>
<tr><td><code id="sparsePC.spikeslab_+3A_max.genes">max.genes</code></td>
<td>
<p>Maximum number of genes in final model.</p>
</td></tr>
<tr><td><code id="sparsePC.spikeslab_+3A_ntree">ntree</code></td>
<td>
<p>Number of trees used by random forests.</p>
</td></tr>
<tr><td><code id="sparsePC.spikeslab_+3A_nodesize">nodesize</code></td>
<td>
<p>Nodesize of trees.</p>
</td></tr>    
<tr><td><code id="sparsePC.spikeslab_+3A_verbose">verbose</code></td>
<td>
<p>If TRUE, verbose output is sent to the terminal.</p>
</td></tr>
<tr><td><code id="sparsePC.spikeslab_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Multiclass prediction using a hybrid combination of spike and slab
linear regression and random forest multiclass prediction (Ishwaran
and Rao, 2009).  A pseudo y-vector of response values is calculated
using each of the top <code>n.prcmp</code> principal components of the
x-gene expression matrix.  The generalized elastic net obtained from
using spike and slab regression is used to select genes; one
regression fit is used for each of the pseduo y-response vectors.  The
final combined set of genes are passed to random forests and used to
construct a multiclass forest predictor.  This procedure is repeated
<code>n.rep</code> times with each Monte Carlo replicate based on balanced
cross-validation with 2/3rds of the data used for training and 1/3rd
used for testing.
</p>
<p>&mdash;&gt; Miscellanea:
</p>
<p>Test set error is only computed when <code>n.rep</code> is larger than 1.
If <code>n.rep</code>=1 the full data is used without any cross-validation.
</p>


<h3>Value</h3>

<p>Invisibly, the final set of selected genes as well as the complete set
of genes selected over the <code>n.rep</code> Monte Carlo replications.  The
random forest classifier is also returned.
</p>
<p>The misclassification error rate, error rate for each class, and other
summary information are output to the terminal.
</p>


<h3>Author(s)</h3>

<p>Hemant Ishwaran (<a href="mailto:hemant.ishwaran@gmail.com">hemant.ishwaran@gmail.com</a>)
</p>
<p>J. Sunil Rao (<a href="mailto:rao.jsunil@gmail.com">rao.jsunil@gmail.com</a>)
</p>
<p>Udaya B. Kogalur (<a href="mailto:ubk@kogalur.com">ubk@kogalur.com</a>)
</p>


<h3>References</h3>

<p>Ishwaran H. and Rao J.S. (2009).  Generalized ridge regression:
geometry and computational solutions when p is larger than n.
</p>


<h3>See Also</h3>

<p><code>spikeslab</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#------------------------------------------------------------
# Example 1:  leukemia data
#------------------------------------------------------------

data(leukemia, package = "spikeslab")
sparsePC.out &lt;- sparsePC(x = leukemia[, -1], y = leukemia[, 1], n.rep = 3)
rf.obj &lt;- sparsePC.out$rf.obj
varImpPlot(rf.obj)

## End(Not run)
</code></pre>

<hr>
<h2 id='spikeslab'>Spike and Slab Regression</h2><span id='topic+spikeslab'></span>

<h3>Description</h3>

  
<p>Fits a rescaled spike and slab model using a continuous bimodal prior.
A generalized elastic net estimator is used for variable selection and
estimation.  Can be used for prediction and variable selection in low-
and high-dimensional linear regression models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spikeslab(formula, data = NULL, x = NULL, y = NULL,
    n.iter1 = 500, n.iter2 = 500, mse = TRUE,
    bigp.smalln = FALSE, bigp.smalln.factor = 1, screen = (bigp.smalln),
    r.effects = NULL, max.var = 500, center = TRUE, intercept = TRUE,
    fast = TRUE, beta.blocks = 5, verbose = FALSE, ntree = 300,
    seed = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spikeslab_+3A_formula">formula</code></td>
<td>
<p>A symbolic description of the model to be fit.</p>
</td></tr>
<tr><td><code id="spikeslab_+3A_data">data</code></td>
<td>
<p>Data frame containing the data used in the formula.</p>
</td></tr>
<tr><td><code id="spikeslab_+3A_x">x</code></td>
<td>
<p>x predictor matrix (can be used in place of formula and
data frame call).</p>
</td></tr>
<tr><td><code id="spikeslab_+3A_y">y</code></td>
<td>
<p>y response (can be used in place of formula and data frame call).</p>
</td></tr>
<tr><td><code id="spikeslab_+3A_n.iter1">n.iter1</code></td>
<td>
<p>Number of burn-in Gibbs sampled values (i.e., discarded values).</p>
</td></tr>
<tr><td><code id="spikeslab_+3A_n.iter2">n.iter2</code></td>
<td>
<p>Number of Gibbs sampled values, following burn-in.</p>
</td></tr>
<tr><td><code id="spikeslab_+3A_mse">mse</code></td>
<td>
<p>If TRUE, an external estimate for the
overall variance is calculated using ridge regression or random
forests (the latter is used when the degrees of freedom are low).
Otherwise, the variance is included in the prior and estimated
using Gibbs sampling.</p>
</td></tr>
<tr><td><code id="spikeslab_+3A_bigp.smalln">bigp.smalln</code></td>
<td>
<p>Use if <code>p</code> &gt;&gt; <code>n</code>.</p>
</td></tr>
<tr><td><code id="spikeslab_+3A_bigp.smalln.factor">bigp.smalln.factor</code></td>
<td>
<p>Removes all variables except the top
<code>n</code>times <code>bigp.smalln.factor</code> ones (used in filtering when 
<code>p</code> &gt;&gt; <code>n</code>).</p>
</td></tr>
<tr><td><code id="spikeslab_+3A_screen">screen</code></td>
<td>
<p>If TRUE, variables are pre-filtered.</p>
</td></tr>
<tr><td><code id="spikeslab_+3A_r.effects">r.effects</code></td>
<td>
<p>List used for grouping variables (see details below).</p>
</td></tr>
<tr><td><code id="spikeslab_+3A_max.var">max.var</code></td>
<td>
<p>Maximum number of variables allowed in the final model.</p>
</td></tr>
<tr><td><code id="spikeslab_+3A_center">center</code></td>
<td>
<p>If TRUE, variables are centered by their
means. Default is TRUE and should only be adjusted in extreme examples.</p>
</td></tr>
<tr><td><code id="spikeslab_+3A_intercept">intercept</code></td>
<td>
<p>If TRUE, an intercept is included in the model,
otherwise no intercept is included.  Default is TRUE.</p>
</td></tr>
<tr><td><code id="spikeslab_+3A_fast">fast</code></td>
<td>
<p>If TRUE, use blocked Gibbs sampling to accelerate the algorithm.</p>
</td></tr>
<tr><td><code id="spikeslab_+3A_beta.blocks">beta.blocks</code></td>
<td>
<p>Update beta using this number of blocks (<code>fast</code>
must be TRUE).</p>
</td></tr>
<tr><td><code id="spikeslab_+3A_verbose">verbose</code></td>
<td>
<p>If TRUE, verbose output is sent to the terminal.</p>
</td></tr>
<tr><td><code id="spikeslab_+3A_ntree">ntree</code></td>
<td>
<p>Number of trees used by random forests (applies only when <code>mse</code> is TRUE).</p>
</td></tr>
<tr><td><code id="spikeslab_+3A_seed">seed</code></td>
<td>
<p>Seed for random number generator.  Must be a negative
integer.</p>
</td></tr>
<tr><td><code id="spikeslab_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&mdash;&gt; General:
</p>
<p>The spike and slab method is described in detail in Ishwaran and Rao
(2003, 2005a, 2005b and 2009).  For high-dimensional problems in which
<code>p</code> &gt;&gt; <code>n</code>, where <code>p</code> is the number of variables and
<code>n</code> is the sample size, use the option <code>bigp.smalln</code>=TRUE.
Doing so implements a three-stage procedure:
</p>
<p>(1) Filtering step.  This removes all variables except the top
<code>n</code> times <code>bigp.smalln.factor</code> ones.  Uses spike and slab
regression with grouped regularization (complexity) parameters.
</p>
<p>(2) Model averaging step.  Refit the model using only those
predictors from step 1.  Returns the posterior mean values from
fitting a spike and slab model; referred to as the Bayesian model
averaged (bma) estimate.
</p>
<p>(3) Variable selection step.  Select variables using the generalized
elastic net (gnet).
</p>
<p>The filtering step is omitted when <code>bigp.smalln</code>=FALSE.
Filtering can however be requested by setting <code>screen</code>=TRUE
although users should be aware that this may degrade performance and
should only be used when <code>p</code> is on the same order of <code>n</code>.
</p>
<p>Variables can be grouped using <code>r.effects</code>.  Grouping has the
effect of forcing variables within a given group to share a common
complexity (regularization) parameter.  To do so, define a list with
each entry in the list made up of the variable names to be grouped.
There is no limit to the number of groups.  Any variable that does
not appear in the list will be assigned to a default group (the
default group also has its own group-specific regularization
parameter).  See Examples 1 and 3 below.
</p>
<p>&mdash;&gt; Miscellanea:
</p>
<p>By default, <code>fast</code>=TRUE when <code>bigp.smalln</code>=TRUE.  This
invokes an ultra-fast filtering step.  Setting <code>fast</code>=FALSE
invokes a more thorough filtering method that may slightly improve
inferential results, but computational times will become very slow.
The trade-off is unlikely to be justified.
</p>
<p>The formula and data-frame call should be avoided in high-dimensional
problems and instead the x-predictor matrix and y response vector
should be passed directly (see Example 3).  This avoids the huge
overhead in parsing formula in R.
</p>
<p>By default, predictors are normalized to have mean 0 and variance 1.
Pre-processing also involves centering y unless the user specifically
requests that the intercept be excluded from the model.  Users can
also over-ride centering predictors by setting <code>center</code>=FALSE.
Use with extreme care.
</p>
<p>The <code>verbose</code> option sends output to the terminal showing the
number of Gibbs iterations and the current complexity (regularization)
parameter(s).
</p>
<p>Depends on the <code>randomForest</code> package for estimating the variance
when <code>mse</code>=TRUE.  Note that <code>mse</code> is over-ridden and set to
FALSE when <code>bigp.smalln</code>=TRUE.
</p>
<p>Depends on the <code>lars</code> package for the variable slection step.
</p>


<h3>Value</h3>

<p>An object of class <code>spikeslab</code> with the following components:
</p>
<table>
<tr><td><code>summary</code></td>
<td>
<p>Summary object.</p>
</td></tr>
<tr><td><code>verbose</code></td>
<td>
<p>Verbose details (used for printing).</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>Terms.</p>
</td></tr>
<tr><td><code>sigma.hat</code></td>
<td>
<p>Estimated variance.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>Original y.</p>
</td></tr>
<tr><td><code>xnew</code></td>
<td>
<p>Centered, rescaled x-matrix.</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>Original x-matrix.</p>
</td></tr>
<tr><td><code>y.center</code></td>
<td>
<p>Centering for original y.</p>
</td></tr>
<tr><td><code>x.center</code></td>
<td>
<p>Centering for original x-matrix.</p>
</td></tr>
<tr><td><code>x.scale</code></td>
<td>
<p>Scaling for original x-matrix.</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>Variable names.</p>
</td></tr>
<tr><td><code>bma</code></td>
<td>
<p>bma coefficients in terms of xnew.</p>
</td></tr>
<tr><td><code>bma.scale</code></td>
<td>
<p>bma coefficients rescaled in terms of original x.</p>
</td></tr>
<tr><td><code>gnet</code></td>
<td>
<p>gnet coefficients in terms of xnew.</p>
</td></tr>
<tr><td><code>gnet.scale</code></td>
<td>
<p>gnet coefficients rescaled in terms of original x.</p>
</td></tr>
<tr><td><code>gnet.path</code></td>
<td>
<p>gnet path scaled in terms of the original x.</p>
</td></tr>
<tr><td><code>gnet.obj</code></td>
<td>
<p>gnet object (a lars-type object).</p>
</td></tr>
<tr><td><code>gnet.obj.vars</code></td>
<td>
<p>Variables (in order) used to calculate the gnet object.</p>
</td></tr>
<tr><td><code>gnet.parms</code></td>
<td>
<p>Generalized ridge regression parameters used to define the gnet.</p>
</td></tr>
<tr><td><code>phat</code></td>
<td>
<p>Estimated model dimension.</p>
</td></tr>
<tr><td><code>complexity</code></td>
<td>
<p>Complexity (regularization) parameter estimates.</p>
</td></tr>
<tr><td><code>ridge</code></td>
<td>
<p>List containing ridge values used to determine the bma.</p>
</td></tr>
<tr><td><code>models</code></td>
<td>
<p>List containing the models sampled.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Hemant Ishwaran (<a href="mailto:hemant.ishwaran@gmail.com">hemant.ishwaran@gmail.com</a>)
</p>
<p>J. Sunil Rao (<a href="mailto:rao.jsunil@gmail.com">rao.jsunil@gmail.com</a>)
</p>
<p>Udaya B. Kogalur (<a href="mailto:ubk@kogalur.com">ubk@kogalur.com</a>)
</p>


<h3>References</h3>

<p>Breiman L. (2001). Random forests, <em>Machine Learning</em>, 45:5-32.
</p>
<p>Efron B., Hastie T., Johnstone I. and Tibshirani R. (2004).
Least angle regression (with discussion). <em>Ann. Statist.</em>,
32:407-499.
</p>
<p>Ishwaran H. and Rao J.S. (2003).  Detecting differentially expressed
genes in microarrays using Bayesian model selection.
<em>J. Amer. Stat. Assoc.</em>, 98:438-455.
</p>
<p>Ishwaran H. and Rao J.S. (2005a).  Spike and slab variable selection:
frequentist and Bayesian strategies.  <em>Ann. Statist.</em>,
33:730-773.
</p>
<p>Ishwaran H. and Rao J.S. (2005b).  Spike and slab gene selection for
multigroup microarray data. <em>J. Amer. Stat. Assoc.</em>, 100:764-780.
</p>
<p>Ishwaran H. and Rao J.S. (2010).  Generalized ridge regression:
geometry and computational solutions when p is larger than n.
</p>
<p>Ishwaran H., Kogalur U.B. and Rao J.S. (2010). spikeslab: prediction
and variable selection using spike and slab regression. <em>R Journal</em>,
2(2), 68-73.
</p>
<p>Ishwaran H. and Rao J.S. (2011).  Mixing generalized ridge
regressions.
</p>
<p>Zou H. and Hastie T. (2005).  Regularization and variable selection
via the elastic net.  <em>J. Royal Statist. Society B</em>,
67(2):301-320.
</p>


<h3>See Also</h3>

<p><code>cv.spikeslab</code>,
<code>plot.spikeslab</code>,
<code>predict.spikeslab</code>,
<code>print.spikeslab</code>,
<code>sparsePC.spikeslab</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#------------------------------------------------------------
# Example 1:  diabetes data
#------------------------------------------------------------

# basic call
data(diabetesI, package = "spikeslab")
obj &lt;- spikeslab(Y ~ . , diabetesI, verbose=TRUE)
print(obj)
plot(obj)

# grouping effect
# separate main effects and interactions into two groups
# use a group-specific regularization parameter for each group
xnames &lt;- names(diabetesI[, -1])
r.eff &lt;- vector("list", 2)
r.eff[[1]] &lt;- xnames[c(1:10)]
r.eff[[2]] &lt;- xnames[-c(1:10)]
obj2 &lt;- spikeslab(Y ~ . , diabetesI, verbose=TRUE, r.effects=r.eff)
obj2
# extract the regularization parameters
print(apply(obj2$complexity, 2, summary))

## Not run: 
#------------------------------------------------------------
# Example 2: high-dimensional noise (diabetes data)
#------------------------------------------------------------

# add 2000 noise variables
data(diabetesI, package = "spikeslab")
diabetes.noise &lt;- cbind(diabetesI,
      noise = matrix(rnorm(nrow(diabetesI) * 2000), nrow(diabetesI)))

# example of a big p, small n call
# don't use formula call; make call with x and y arguments
x &lt;- diabetes.noise[, -1]
y &lt;- diabetes.noise[, 1]
obj &lt;- spikeslab(x=x, y=y, verbose=TRUE, bigp.smalln=TRUE, max.var=100)
obj

# same example ... but now group variables 
r.eff &lt;- vector("list", 2)
r.eff[[1]] &lt;- names(x)[c(1:100)]
r.eff[[2]] &lt;- names(x)[-c(1:100)]
obj2 &lt;- spikeslab(x=x, y=y, verbose=TRUE, bigp.smalln=TRUE,
                 r.effects=r.eff, max.var=100)
obj2

#------------------------------------------------------------
# Example 3: housing data with interactions
#------------------------------------------------------------

# another example of a big p, small n call
data(housingI, package = "spikeslab")
obj &lt;- spikeslab(medv ~ ., housingI, verbose = TRUE,
           bigp.smalln = TRUE, max.var = 200)
print(obj)



## End(Not run)
</code></pre>

<hr>
<h2 id='spikeslab.news'>Show the NEWS file</h2><span id='topic+spikeslab.news'></span>

<h3>Description</h3>

<p>Show the NEWS file of the <span class="pkg">spikeslab</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    spikeslab.news(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spikeslab.news_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p>Hemant Ishwaran <a href="mailto:hemant.ishwaran@gmail.com">hemant.ishwaran@gmail.com</a>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
