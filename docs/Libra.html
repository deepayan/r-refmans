<!DOCTYPE html><html lang="en"><head><title>Help for package Libra</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Libra}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cv.iss'><p>CV for ISS</p></a></li>
<li><a href='#cv.lb'><p>CV for lb</p></a></li>
<li><a href='#diabetes'><p>Blood and other measurements in diabetics</p></a></li>
<li><a href='#ggm'><p>Linearized Bregman solver for composite conditionally likelihood of Gaussian Graphical</p>
model with lasso penalty.</a></li>
<li><a href='#ising'><p>Linearized Bregman solver for composite conditionally likelihood of Ising model</p>
with lasso penalty.</a></li>
<li><a href='#isingdata'>
<p>Simulation data for Ising model</p></a></li>
<li><a href='#iss'><p>ISS solver for linear model with lasso penalty</p></a></li>
<li><a href='#lb'><p>Linearized Bregman solver for linear, binomial, multinomial models</p>
with lasso, group lasso or column lasso penalty.</a></li>
<li><a href='#plot.lb'><p>Plot method for lb objects</p></a></li>
<li><a href='#potts'><p>Linearized Bregman solver for composite conditionally likelihood of Potts model</p>
with lasso penalty and block-group penalty.</a></li>
<li><a href='#predict.lb'><p>Predict method for lb objects</p></a></li>
<li><a href='#west10'><p>Journey to the West, one of the Four Great Classical Novels of Chinese Literature by WU, Cheng'en.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Linearized Bregman Algorithms for Generalized Linear Models</td>
</tr>
<tr>
<td>Version:</td>
<td>1.7</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-4-9</td>
</tr>
<tr>
<td>Author:</td>
<td>Feng Ruan, Jiechao Xiong and Yuan Yao</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jiechao Xiong &lt;xiongjiechao@pku.edu.cn&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0), nnls</td>
</tr>
<tr>
<td>Suggests:</td>
<td>lars, MASS, igraph</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>GNU Scientific Library (GSL)</td>
</tr>
<tr>
<td>Description:</td>
<td>Efficient procedures for fitting the regularization path
    for linear, binomial, multinomial, Ising and Potts models with lasso,
    group lasso or column lasso(only for multinomial) penalty.
    The package uses Linearized Bregman Algorithm to solve the
    regularization path through iterations. Bregman Inverse Scale Space Differential
    Inclusion solver is also provided for linear model with lasso penalty.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://arxiv.org/abs/1406.7728">https://arxiv.org/abs/1406.7728</a></td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-04-09 08:43:10 UTC; jcxiong</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-04-11 09:22:30 UTC</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
</table>
<hr>
<h2 id='cv.iss'>CV for ISS</h2><span id='topic+cv.iss'></span>

<h3>Description</h3>

<p>Cross-validation method to tuning the parameter t for ISS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.iss(
  X,
  y,
  K = 5,
  t,
  intercept = TRUE,
  normalize = TRUE,
  plot.it = TRUE,
  se = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cv.iss_+3A_x">X</code></td>
<td>
<p>An n-by-p matrix of predictors</p>
</td></tr>
<tr><td><code id="cv.iss_+3A_y">y</code></td>
<td>
<p>Response Variable</p>
</td></tr>
<tr><td><code id="cv.iss_+3A_k">K</code></td>
<td>
<p>Folds number for CV. Default is 5.</p>
</td></tr>
<tr><td><code id="cv.iss_+3A_t">t</code></td>
<td>
<p>A vector of predecided tuning parameter.</p>
</td></tr>
<tr><td><code id="cv.iss_+3A_intercept">intercept</code></td>
<td>
<p>If TRUE, an intercept is included in the model (and not 
penalized), otherwise no intercept is included. Default is TRUE.</p>
</td></tr>
<tr><td><code id="cv.iss_+3A_normalize">normalize</code></td>
<td>
<p>if TRUE, each variable is scaled to have L2 norm 
square-root n. Default is TRUE.</p>
</td></tr>
<tr><td><code id="cv.iss_+3A_plot.it">plot.it</code></td>
<td>
<p>Plot it? Default is TRUE</p>
</td></tr>
<tr><td><code id="cv.iss_+3A_se">se</code></td>
<td>
<p>Include standard error bands? Default is TRUE</p>
</td></tr>
<tr><td><code id="cv.iss_+3A_...">...</code></td>
<td>
<p>Additonal arguments passing to lb</p>
</td></tr>
</table>


<h3>Details</h3>

<p>K-fold cross-validation method is used to tuning the parameter $t$ for ISS.
Mean square error is used as prediction error.
</p>


<h3>Value</h3>

<p>A list is returned. The list contains a vector of parameter t, 
crossvalidation error cv.error, and the estimated standard deviation for it cv.sd
</p>


<h3>Author(s)</h3>

<p>Feng Ruan, Jiechao Xiong and Yuan Yao
</p>


<h3>References</h3>

<p>Ohser, Ruan, Xiong, Yao and Yin, Sparse Recovery via Differential
Inclusions, <a href="https://arxiv.org/abs/1406.7728">https://arxiv.org/abs/1406.7728</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Examples in the reference paper
library(MASS)
n = 200;p = 100;k = 30;sigma = 1
Sigma = 1/(3*p)*matrix(rep(1,p^2),p,p)
diag(Sigma) = 1
A = mvrnorm(n, rep(0, p), Sigma)
u_ref = rep(0,p)
supp_ref = 1:k
u_ref[supp_ref] = rnorm(k)
u_ref[supp_ref] = u_ref[supp_ref]+sign(u_ref[supp_ref])
b = as.vector(A%*%u_ref + sigma*rnorm(n))
cv.iss(A,b,intercept = FALSE,normalize = FALSE)

</code></pre>

<hr>
<h2 id='cv.lb'>CV for lb</h2><span id='topic+cv.lb'></span>

<h3>Description</h3>

<p>Cross-validation method to tuning the parameter t for lb.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.lb(
  X,
  y,
  kappa,
  alpha,
  K = 5,
  tlist,
  nt = 100,
  trate = 100,
  family = c("gaussian", "binomial", "multinomial"),
  group = FALSE,
  intercept = TRUE,
  normalize = TRUE,
  plot.it = TRUE,
  se = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cv.lb_+3A_x">X</code></td>
<td>
<p>An n-by-p matrix of predictors</p>
</td></tr>
<tr><td><code id="cv.lb_+3A_y">y</code></td>
<td>
<p>Response Variable</p>
</td></tr>
<tr><td><code id="cv.lb_+3A_kappa">kappa</code></td>
<td>
<p>The damping factor of the Linearized Bregman Algorithm that is
defined in the reference paper. See details.</p>
</td></tr>
<tr><td><code id="cv.lb_+3A_alpha">alpha</code></td>
<td>
<p>Parameter in Linearized Bregman algorithm which controls the 
step-length of the discretized solver for the Bregman Inverse Scale Space. 
See details.</p>
</td></tr>
<tr><td><code id="cv.lb_+3A_k">K</code></td>
<td>
<p>Folds number for CV. Default is 5.</p>
</td></tr>
<tr><td><code id="cv.lb_+3A_tlist">tlist</code></td>
<td>
<p>Parameters t along the path.</p>
</td></tr>
<tr><td><code id="cv.lb_+3A_nt">nt</code></td>
<td>
<p>Number of t. Used only if tlist is missing. Default is 100.</p>
</td></tr>
<tr><td><code id="cv.lb_+3A_trate">trate</code></td>
<td>
<p>tmax/tmin. Used only if tlist is missing. Default is 100.</p>
</td></tr>
<tr><td><code id="cv.lb_+3A_family">family</code></td>
<td>
<p>Response type</p>
</td></tr>
<tr><td><code id="cv.lb_+3A_group">group</code></td>
<td>
<p>Whether to use a group penalty, Default is FALSE.</p>
</td></tr>
<tr><td><code id="cv.lb_+3A_intercept">intercept</code></td>
<td>
<p>If TRUE, an intercept is included in the model (and not 
penalized), otherwise no intercept is included. Default is TRUE.</p>
</td></tr>
<tr><td><code id="cv.lb_+3A_normalize">normalize</code></td>
<td>
<p>if TRUE, each variable is scaled to have L2 norm 
square-root n. Default is TRUE.</p>
</td></tr>
<tr><td><code id="cv.lb_+3A_plot.it">plot.it</code></td>
<td>
<p>Plot it? Default is TRUE</p>
</td></tr>
<tr><td><code id="cv.lb_+3A_se">se</code></td>
<td>
<p>Include standard error bands? Default is TRUE</p>
</td></tr>
<tr><td><code id="cv.lb_+3A_...">...</code></td>
<td>
<p>Additonal arguments passing to lb</p>
</td></tr>
</table>


<h3>Details</h3>

<p>K-fold cross-validation method is used to tuning the parameter t for ISS.
Mean square error is used for linear model. Miss-classification error
is used for binomial and multinomial model.
</p>


<h3>Value</h3>

<p>A list is returned. The list contains a vector of parameter t, 
crossvalidation error cv.error, and the estimated standard deviation for it cv.sd
</p>


<h3>Author(s)</h3>

<p>Feng Ruan, Jiechao Xiong and Yuan Yao
</p>


<h3>References</h3>

<p>Ohser, Ruan, Xiong, Yao and Yin, Sparse Recovery via Differential
Inclusions, <a href="https://arxiv.org/abs/1406.7728">https://arxiv.org/abs/1406.7728</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Examples in the reference paper
library(MASS)
n = 200;p = 100;k = 30;sigma = 1
Sigma = 1/(3*p)*matrix(rep(1,p^2),p,p)
diag(Sigma) = 1
A = mvrnorm(n, rep(0, p), Sigma)
u_ref = rep(0,p)
supp_ref = 1:k
u_ref[supp_ref] = rnorm(k)
u_ref[supp_ref] = u_ref[supp_ref]+sign(u_ref[supp_ref])
b = as.vector(A%*%u_ref + sigma*rnorm(n))
cv.lb(A,b,10,1/20,intercept = FALSE,normalize = FALSE)

#Simulated data, binomial case
X &lt;- matrix(rnorm(500*100), nrow=500, ncol=100)
alpha &lt;- c(rep(1,30), rep(0,70))
y &lt;- 2*as.numeric(runif(500)&lt;1/(1+exp(-X %*% alpha)))-1
cv.lb(X,y,kappa=5,alpha=1,family="binomial",
             intercept=FALSE,normalize = FALSE)

</code></pre>

<hr>
<h2 id='diabetes'>Blood and other measurements in diabetics</h2><span id='topic+diabetes'></span>

<h3>Description</h3>

<p>The <code>diabetes</code> data frame has 442 rows and 3 columns.
These are the data used in the Efron et al &quot;Least Angle Regression&quot; paper.
</p>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>x</dt><dd><p>a matrix with 10 columns</p>
</dd>
<dt>y</dt><dd><p>a numeric vector</p>
</dd>
<dt>x2</dt><dd><p>a matrix with 64 columns</p>
</dd>
</dl>



<h3>Details</h3>

<p>The x matrix has been standardized to have unit L2 norm in each column
and zero mean. The matrix x2 consists of x plus certain interactions.
</p>


<h3>References</h3>

<p>Efron, Hastie, Johnstone and Tibshirani (2003) &quot;Least Angle Regression&quot;
(with discussion) <em>Annals of Statistics</em>
</p>

<hr>
<h2 id='ggm'>Linearized Bregman solver for composite conditionally likelihood of Gaussian Graphical
model with lasso penalty.</h2><span id='topic+ggm'></span>

<h3>Description</h3>

<p>Solver for the entire solution path of coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ggm(
  X,
  kappa,
  alpha,
  S = NA,
  c = 2,
  tlist,
  nt = 100,
  trate = 100,
  print = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ggm_+3A_x">X</code></td>
<td>
<p>An n-by-p matrix of variables.</p>
</td></tr>
<tr><td><code id="ggm_+3A_kappa">kappa</code></td>
<td>
<p>The damping factor of the Linearized Bregman Algorithm that is
defined in the reference paper. See details.</p>
</td></tr>
<tr><td><code id="ggm_+3A_alpha">alpha</code></td>
<td>
<p>Parameter in Linearized Bregman algorithm which controls the 
step-length of the discretized solver for the Bregman Inverse Scale Space. 
See details.</p>
</td></tr>
<tr><td><code id="ggm_+3A_s">S</code></td>
<td>
<p>The covariance matrix can be provided directly if data matrix X is missing.</p>
</td></tr>
<tr><td><code id="ggm_+3A_c">c</code></td>
<td>
<p>Normalized step-length. If alpha is missing, alpha is automatically generated by 
<code>alpha=c*n/(kappa*||X^T*X||_2)</code>. Default is 2. It should be in (0,4).
If beyond this range the path may be oscillated at large t values.</p>
</td></tr>
<tr><td><code id="ggm_+3A_tlist">tlist</code></td>
<td>
<p>Parameters t along the path.</p>
</td></tr>
<tr><td><code id="ggm_+3A_nt">nt</code></td>
<td>
<p>Number of t. Used only if tlist is missing. Default is 100.</p>
</td></tr>
<tr><td><code id="ggm_+3A_trate">trate</code></td>
<td>
<p>tmax/tmin. Used only if tlist is missing. Default is 100.</p>
</td></tr>
<tr><td><code id="ggm_+3A_print">print</code></td>
<td>
<p>If TRUE, the percentage of finished computation is printed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data matrix X is assumed to follow the Gaussian Graohical model which is described as following:<br />
</p>
<p style="text-align: center;"><code class="reqn">X \sim N(\mu, \Theta^{-1})</code>
</p>
<p><br />
where <code class="reqn">\Theta</code> is sparse p-by-p symmetric matrix. Then conditional on <code class="reqn">x_{-j}</code><br />
</p>
<p style="text-align: center;"><code class="reqn">x_j \sim N(\mu_j - \sum_{k\neq j}\Theta_{jk}/\Theta_{jj}(x_k-\mu_k),1/\Theta_{jj}) </code>
</p>
<p><br />
then the composite conditional likelihood is like this:<br />
</p>
<p style="text-align: center;"><code class="reqn">- \sum_{j} condloglik(X_j | X_{-j})</code>
</p>
<p><br />
or in detail:<br />
</p>
<p style="text-align: center;"><code class="reqn">\sum_{j} \Theta_{j}^TS\Theta_{j}/2\Theta_{jj} - ln(\Theta_{jj})/2</code>
</p>
<p><br />
where <code class="reqn">S</code> is covariance matrix of data. It is easy to prove that this loss function
is convex.
</p>


<h3>Value</h3>

<p>A &quot;ggm&quot; class object is returned. The list contains the call, 
the path, value for alpha, kappa, t.
</p>


<h3>Author(s)</h3>

<p>Jiechao Xiong
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(MASS)
p = 20
Omega = diag(1,p,p)
Omega[0:(p-2)*(p+1)+2] = 1/3
Omega[1:(p-1)*(p+1)] = 1/3
S = solve(Omega)
X = mvrnorm(n=500,rep(0,p),S)
obj = ggm(X,10,trate=10)
obj$path[,,50]
</code></pre>

<hr>
<h2 id='ising'>Linearized Bregman solver for composite conditionally likelihood of Ising model 
with lasso penalty.</h2><span id='topic+ising'></span>

<h3>Description</h3>

<p>Solver for the entire solution path of coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ising(
  X,
  kappa,
  alpha,
  c = 2,
  tlist,
  responses = c(-1, 1),
  nt = 100,
  trate = 100,
  intercept = TRUE,
  print = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ising_+3A_x">X</code></td>
<td>
<p>An n-by-p matrix of variables.</p>
</td></tr>
<tr><td><code id="ising_+3A_kappa">kappa</code></td>
<td>
<p>The damping factor of the Linearized Bregman Algorithm that is
defined in the reference paper. See details.</p>
</td></tr>
<tr><td><code id="ising_+3A_alpha">alpha</code></td>
<td>
<p>Parameter in Linearized Bregman algorithm which controls the 
step-length of the discretized solver for the Bregman Inverse Scale Space. 
See details.</p>
</td></tr>
<tr><td><code id="ising_+3A_c">c</code></td>
<td>
<p>Normalized step-length. If alpha is missing, alpha is automatically generated by 
<code>alpha=c*n/(kappa*||X^T*X||_2)</code>. Default is 2. It should be in (0,4).
If beyond this range the path may be oscillated at large t values.</p>
</td></tr>
<tr><td><code id="ising_+3A_tlist">tlist</code></td>
<td>
<p>Parameters t along the path.</p>
</td></tr>
<tr><td><code id="ising_+3A_responses">responses</code></td>
<td>
<p>The type of data. c(0,1) or c(-1,1), Default is c(-1,1).</p>
</td></tr>
<tr><td><code id="ising_+3A_nt">nt</code></td>
<td>
<p>Number of t. Used only if tlist is missing. Default is 100.</p>
</td></tr>
<tr><td><code id="ising_+3A_trate">trate</code></td>
<td>
<p>tmax/tmin. Used only if tlist is missing. Default is 100.</p>
</td></tr>
<tr><td><code id="ising_+3A_intercept">intercept</code></td>
<td>
<p>if TRUE, an intercept is included in the model (and not 
penalized), otherwise no intercept is included. Default is TRUE.</p>
</td></tr>
<tr><td><code id="ising_+3A_print">print</code></td>
<td>
<p>If TRUE, the percentage of finished computation is printed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data matrix X is assumed in {1,-1}. The Ising model here used is described as following:<br />
</p>
<p style="text-align: center;"><code class="reqn">P(x) \sim \exp(\sum_i \frac{a_{0i}}{2}x_i + x^T \Theta x/4)</code>
</p>
<p><br />
where <code class="reqn">\Theta</code> is p-by-p symmetric and 0 on diagnal. Then conditional on <code class="reqn">x_{-j}</code><br />
</p>
<p style="text-align: center;"><code class="reqn">\frac{P(x_j=1)}{P(x_j=-1)} = exp(\sum_i a_{0i} + \sum_{i\neq j}\theta_{ji}x_i)</code>
</p>
<p><br />
then the composite conditional likelihood is like this:<br />
</p>
<p style="text-align: center;"><code class="reqn">- \sum_{j} condloglik(X_j | X_{-j})</code>
</p>



<h3>Value</h3>

<p>A &quot;ising&quot; class object is returned. The list contains the call, 
the path, the intercept term a0 and value for alpha, kappa, t.
</p>


<h3>Author(s)</h3>

<p>Jiechao Xiong
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library('Libra')
library('igraph')
data('west10')
X &lt;- as.matrix(2*west10-1);
obj = ising(X,10,0.1,nt=1000,trate=100)
g&lt;-graph.adjacency(obj$path[,,770],mode="undirected",weighted=TRUE)
E(g)[E(g)$weight&lt;0]$color&lt;-"red"
E(g)[E(g)$weight&gt;0]$color&lt;-"green"
V(g)$name&lt;-attributes(west10)$names
plot(g,vertex.shape="rectangle",vertex.size=35,vertex.label=V(g)$name,
edge.width=2*abs(E(g)$weight),main="Ising Model (LB): sparsity=0.51")
</code></pre>

<hr>
<h2 id='isingdata'>
Simulation data for Ising model
</h2><span id='topic+isingdata'></span>

<h3>Description</h3>

<p>The <code>isingdata</code> data list contains 2 variables. One is 5000 samples from the ising model on the 10-by-10 grid using Gibbs sampling. The other is the  groupdtruth parameter.
</p>


<h3>Format</h3>

<p>This data list contains the following two variables:
</p>

<dl>
<dt>J</dt><dd><p>a 100-by-100 matrix, the groudtruth of ising model.</p>
</dd>
<dt>X</dt><dd><p>a 5000-by-100 matrix, each entry is in -1,1.</p>
</dd>
</dl>


<hr>
<h2 id='iss'>ISS solver for linear model with lasso penalty</h2><span id='topic+iss'></span>

<h3>Description</h3>

<p>Solver for the entire solution path of coefficients for ISS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iss(X, y, intercept = TRUE, normalize = TRUE, nvar = min(dim(X)))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="iss_+3A_x">X</code></td>
<td>
<p>An n-by-p matrix of predictors</p>
</td></tr>
<tr><td><code id="iss_+3A_y">y</code></td>
<td>
<p>Response Variable</p>
</td></tr>
<tr><td><code id="iss_+3A_intercept">intercept</code></td>
<td>
<p>if TRUE, an intercept is included in the model (and 
not penalized), otherwise no intercept is included. Default is TRUE.</p>
</td></tr>
<tr><td><code id="iss_+3A_normalize">normalize</code></td>
<td>
<p>if normalize, each variable is scaled to have L2 norm
square-root n. Default is TRUE.</p>
</td></tr>
<tr><td><code id="iss_+3A_nvar">nvar</code></td>
<td>
<p>Maximal number of variables allowed in the model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ISS solver computes the whole regularization path for 
lasso-penalty for linear model. It gives the piecewise constant
solution path for Bregman Inverse Scale Space Differential 
Inclusion. It is the asymptotic limit of LB method with kaapa 
goes to infinity and alpha goes to zero.
</p>


<h3>Value</h3>

<p>An &quot;LB&quot; class object is returned. The list contains the call, 
the family, the path, the intercept term a0 and value for alpha, kappa,
iter, and meanvalue, scale factor of X, meanx and normx.
</p>


<h3>Author(s)</h3>

<p>Feng Ruan, Jiechao Xiong and Yuan Yao
</p>


<h3>References</h3>

<p>Ohser, Ruan, Xiong, Yao and Yin, Sparse Recovery via Differential
Inclusions, <a href="https://arxiv.org/abs/1406.7728">https://arxiv.org/abs/1406.7728</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Examples in the reference paper
library(MASS)
library(lars)
library(MASS)
library(lars)
n = 80;p = 100;k = 30;sigma = 1
Sigma = 1/(3*p)*matrix(rep(1,p^2),p,p)
diag(Sigma) = 1
A = mvrnorm(n, rep(0, p), Sigma)
u_ref = rep(0,p)
supp_ref = 1:k
u_ref[supp_ref] = rnorm(k)
u_ref[supp_ref] = u_ref[supp_ref]+sign(u_ref[supp_ref])
b = as.vector(A%*%u_ref + sigma*rnorm(n))
lasso = lars(A,b,normalize=FALSE,intercept=FALSE,max.steps=100)
par(mfrow=c(3,2))
matplot(n/lasso$lambda, lasso$beta[1:100,], xlab = bquote(n/lambda), 
        ylab = "Coefficients", xlim=c(0,3),ylim=c(range(lasso$beta)),type='l', main="Lasso")
object = iss(A,b,intercept=FALSE,normalize=FALSE)
plot(object,xlim=c(0,3),main=bquote("ISS"))
kappa_list = c(4,16,64,256)
alpha_list = 1/10/kappa_list
for (i in 1:4){
  object &lt;- lb(A,b,kappa_list[i],alpha_list[i],family="gaussian",group=FALSE,
               trate=20,intercept=FALSE,normalize=FALSE)
  plot(object,xlim=c(0,3),main=bquote(paste("LB ",kappa,"=",.(kappa_list[i]))))
}

</code></pre>

<hr>
<h2 id='lb'>Linearized Bregman solver for linear, binomial, multinomial models
with lasso, group lasso or column lasso penalty.</h2><span id='topic+lb'></span>

<h3>Description</h3>

<p>Solver for the entire solution path of coefficients for Linear Bregman iteration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lb(
  X,
  y,
  kappa,
  alpha,
  c = 1,
  tlist,
  nt = 100,
  trate = 100,
  family = c("gaussian", "binomial", "multinomial"),
  group = FALSE,
  index = NA,
  intercept = TRUE,
  normalize = TRUE,
  print = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lb_+3A_x">X</code></td>
<td>
<p>An n-by-p matrix of predictors</p>
</td></tr>
<tr><td><code id="lb_+3A_y">y</code></td>
<td>
<p>Response Variable</p>
</td></tr>
<tr><td><code id="lb_+3A_kappa">kappa</code></td>
<td>
<p>The damping factor of the Linearized Bregman Algorithm that is
defined in the reference paper. See details.</p>
</td></tr>
<tr><td><code id="lb_+3A_alpha">alpha</code></td>
<td>
<p>Parameter in Linearized Bregman algorithm which controls the 
step-length of the discretized solver for the Bregman Inverse Scale Space. 
See details.</p>
</td></tr>
<tr><td><code id="lb_+3A_c">c</code></td>
<td>
<p>Normalized step-length. If alpha is missing, alpha is automatically generated by 
<code>alpha=n*c/(kappa*||X^T*X||_2)</code>. It should be in (0,2) for 
family = &quot;gaussian&quot;(Default is 1), (0,8) for family = &quot;binomial&quot;(Default is 4),
(0,4) for family = &quot;multinomial&quot;(Default is 2).
If beyond these range the path may be oscillated at large t values.</p>
</td></tr>
<tr><td><code id="lb_+3A_tlist">tlist</code></td>
<td>
<p>Parameters t along the path.</p>
</td></tr>
<tr><td><code id="lb_+3A_nt">nt</code></td>
<td>
<p>Number of t. Used only if tlist is missing. Default is 100.</p>
</td></tr>
<tr><td><code id="lb_+3A_trate">trate</code></td>
<td>
<p>tmax/tmin. Used only if tlist is missing. Default is 100.</p>
</td></tr>
<tr><td><code id="lb_+3A_family">family</code></td>
<td>
<p>Response type</p>
</td></tr>
<tr><td><code id="lb_+3A_group">group</code></td>
<td>
<p>Whether to use a group penalty, Default is FALSE.</p>
</td></tr>
<tr><td><code id="lb_+3A_index">index</code></td>
<td>
<p>For group models, the index is a vector that determines the 
group of the parameters. Parameters of the same group should have equal 
value in index. Be careful that multinomial group model default assumes 
the variables in same column are in the same group, and a empty value of
index means each variable is a group.</p>
</td></tr>
<tr><td><code id="lb_+3A_intercept">intercept</code></td>
<td>
<p>if TRUE, an intercept is included in the model (and not 
penalized), otherwise no intercept is included. Default is TRUE.</p>
</td></tr>
<tr><td><code id="lb_+3A_normalize">normalize</code></td>
<td>
<p>if TRUE, each variable is scaled to have L2 norm 
square-root n. Default is TRUE.</p>
</td></tr>
<tr><td><code id="lb_+3A_print">print</code></td>
<td>
<p>If TRUE, the percentage of finished computation is printed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Linearized Bregman solver computes the whole regularization path
for different types of lasso-penalty for gaussian, binomial and 
multinomial models through iterations. It is the Euler forward 
discretized form of the continuous Bregman Inverse Scale Space 
Differential Inclusion. For binomial models, the response variable y
is assumed to be a vector of two classes which is transformed in to {1,-1}.
For the multinomial models, the response variable y can be a vector of k classes
or a n-by-k matrix that each entry is in {0,1} with 1 indicates 
the class. Under all circumstances, two parameters, kappa 
and alpha need to be specified beforehand. The definitions of kappa 
and alpha are the same as that defined in the reference paper. 
Parameter alpha is defined as stepsize and kappa is the damping factor
of the Linearized Bregman Algorithm that is defined in the reference paper.
</p>


<h3>Value</h3>

<p>A &quot;lb&quot; class object is returned. The list contains the call, 
the type, the path, the intercept term a0 and value for alpha, kappa, 
iter, and meanvalue, scale factor of X, meanx and normx. For gaussian and
bonomial, path is a p-by-nt matrix, and for multinomial, path is a k-by-p-by-nt 
array, each dimension represents class, predictor and parameter t.
</p>


<h3>Author(s)</h3>

<p>Feng Ruan, Jiechao Xiong and Yuan Yao
</p>


<h3>References</h3>

<p>Ohser, Ruan, Xiong, Yao and Yin, Sparse Recovery via Differential
Inclusions, <a href="https://arxiv.org/abs/1406.7728">https://arxiv.org/abs/1406.7728</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Examples in the reference paper
library(MASS)
n = 80;p = 100;k = 30;sigma = 1
Sigma = 1/(3*p)*matrix(rep(1,p^2),p,p)
diag(Sigma) = 1
A = mvrnorm(n, rep(0, p), Sigma)
u_ref = rep(0,p)
supp_ref = 1:k
u_ref[supp_ref] = rnorm(k)
u_ref[supp_ref] = u_ref[supp_ref]+sign(u_ref[supp_ref])
b = as.vector(A%*%u_ref + sigma*rnorm(n))
kappa = 16
alpha = 1/160
object &lt;- lb(A,b,kappa,alpha,family="gaussian",group=FALSE,
             trate=20,intercept=FALSE,normalize=FALSE)
plot(object,xlim=c(0,3),main=bquote(paste("LB ",kappa,"=",.(kappa))))


#Diabetes, linear case
library(Libra)
data(diabetes)
attach(diabetes)
object &lt;- lb(x,y,100,1e-3,family="gaussian",group=FALSE)
plot(object)
detach(diabetes)

#Simulated data, binomial case
data('west10')
y&lt;-2*west10[,1]-1;
X&lt;-as.matrix(2*west10[,2:10]-1);
path &lt;- lb(X,y,kappa = 1,family="binomial",trate=100,normalize = FALSE)
plot(path,xtype="norm",omit.zeros=FALSE)

#Simulated data, multinomial case
X &lt;- matrix(rnorm(500*100), nrow=500, ncol=100)
alpha &lt;- matrix(c(rnorm(30*3), rep(0,70*3)),nrow=3)
P &lt;- exp(alpha%*%t(X))
P &lt;- scale(P,FALSE,apply(P,2,sum))
y &lt;- rep(0,500)
rd &lt;- runif(500)
y[rd&lt;P[1,]] &lt;- 1
y[rd&gt;1-P[3,]] &lt;- -1
result &lt;- lb(X,y,kappa=5,alpha=0.1,family="multinomial",
 group=TRUE,intercept=FALSE,normalize = FALSE)
plot(result)

</code></pre>

<hr>
<h2 id='plot.lb'>Plot method for lb objects</h2><span id='topic+plot.lb'></span>

<h3>Description</h3>

<p>Produce a plot of an LB fit. The default is a complete coefficient path.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lb'
plot(x, xtype = c("t", "norm"), omit.zeros = TRUE, eps = 1e-10, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.lb_+3A_x">x</code></td>
<td>
<p>lb object</p>
</td></tr>
<tr><td><code id="plot.lb_+3A_xtype">xtype</code></td>
<td>
<p>The x-axis type. &quot;t&quot; or &quot;norm&quot;. Default is &quot;t&quot;.</p>
</td></tr>
<tr><td><code id="plot.lb_+3A_omit.zeros">omit.zeros</code></td>
<td>
<p>When the number of variables  is much greater than
the number of observations, many coefficients will never be nonzero;
this logical (default <code>TRUE</code>) avoids plotting these zero coefficents</p>
</td></tr>
<tr><td><code id="plot.lb_+3A_eps">eps</code></td>
<td>
<p>Definition of zero above, default is <code>1e-10</code></p>
</td></tr>
<tr><td><code id="plot.lb_+3A_...">...</code></td>
<td>
<p>Additonal arguments for generic plot. Can be used to set xlims, change colors, line widths, etc</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default plot uses the fraction of L1 norm as the x. 
For multinomial case, the sum of absolute values of different class's 
coefficients are caculated to represent each variable.
The intercept term is not ploted
</p>


<h3>Author(s)</h3>

<p>Feng Ruan, Jiechao Xiong and Yuan Yao
</p>

<hr>
<h2 id='potts'>Linearized Bregman solver for composite conditionally likelihood of Potts model 
with lasso penalty and block-group penalty.</h2><span id='topic+potts'></span>

<h3>Description</h3>

<p>Solver for the entire solution path of coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>potts(
  X,
  kappa,
  alpha,
  c = 1,
  tlist,
  nt = 100,
  trate = 100,
  group = FALSE,
  intercept = TRUE,
  print = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="potts_+3A_x">X</code></td>
<td>
<p>An n-by-p matrix of variables.</p>
</td></tr>
<tr><td><code id="potts_+3A_kappa">kappa</code></td>
<td>
<p>The damping factor of the Linearized Bregman Algorithm that is
defined in the reference paper. See details.</p>
</td></tr>
<tr><td><code id="potts_+3A_alpha">alpha</code></td>
<td>
<p>Parameter in Linearized Bregman algorithm which controls the 
step-length of the discretized solver for the Bregman Inverse Scale Space. 
See details.</p>
</td></tr>
<tr><td><code id="potts_+3A_c">c</code></td>
<td>
<p>Normalized step-length. If alpha is missing, alpha is automatically generated by 
<code>alpha=c*n/(kappa*||XX^T*XX||_2)</code>, where XX is 0-1 indicator matrix 
induced by the class of each Xi. Default is 1. It should be in (0,2).
If beyond this range the path may be oscillated at large t values.</p>
</td></tr>
<tr><td><code id="potts_+3A_tlist">tlist</code></td>
<td>
<p>Parameters t along the path.</p>
</td></tr>
<tr><td><code id="potts_+3A_nt">nt</code></td>
<td>
<p>Number of t. Used only if tlist is missing. Default is 100.</p>
</td></tr>
<tr><td><code id="potts_+3A_trate">trate</code></td>
<td>
<p>tmax/tmin. Used only if tlist is missing. Default is 100.</p>
</td></tr>
<tr><td><code id="potts_+3A_group">group</code></td>
<td>
<p>Whether to use a block-wise group penalty, Default is FALSE</p>
</td></tr>
<tr><td><code id="potts_+3A_intercept">intercept</code></td>
<td>
<p>if TRUE, an intercept is included in the model (and not 
penalized), otherwise no intercept is included. Default is TRUE.</p>
</td></tr>
<tr><td><code id="potts_+3A_print">print</code></td>
<td>
<p>If TRUE, the percentage of finished computation is printed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data matrix X is transformed into a 0-1 indicator matrix D with each column
<code class="reqn">D_{jk}</code> means <code class="reqn">1(X_j)==k</code>. The Potts model here used is described as following:
</p>
<p style="text-align: center;"><code class="reqn">P(x) \sim \exp(\sum_{jk} a_{0,jk}1(x_i=1) + d^T \Theta d/2)</code>
</p>

<p>where <code class="reqn">\Theta</code> is p-by-p symmetric and 0 on diagnal. Then conditional on <code class="reqn">x_{-j}</code><br />
</p>
<p style="text-align: center;"><code class="reqn">P(x_j=k) \sim exp(\sum_{k} a_{0,jk} + \sum_{i\neq j,r}\theta_{jk,ir}d_{ir})</code>
</p>
<p><br />
then the composite conditional likelihood is like this:<br />
</p>
<p style="text-align: center;"><code class="reqn">- \sum_{j} condloglik(X_j | X_{-j})</code>
</p>



<h3>Value</h3>

<p>A &quot;potts&quot; class object is returned. The list contains the call, 
the path, the intercept term a0 and value for alpha, kappa, t.
</p>


<h3>Author(s)</h3>

<p>Jiechao Xiong
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
X = matrix(floor(runif(200*10)*3),200,10)
obj = potts(X,10,nt=100,trate=10,group=TRUE)

</code></pre>

<hr>
<h2 id='predict.lb'>Predict method for lb objects</h2><span id='topic+predict.lb'></span>

<h3>Description</h3>

<p>Predict response variable for new data given a lb object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lb'
predict(object, newx, t, type = c("fit", "coefficients"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.lb_+3A_object">object</code></td>
<td>
<p>lb object</p>
</td></tr>
<tr><td><code id="predict.lb_+3A_newx">newx</code></td>
<td>
<p>New data matrix that each row is a data or a vector. If missing,
type switched to coefficients</p>
</td></tr>
<tr><td><code id="predict.lb_+3A_t">t</code></td>
<td>
<p>The parmeter for object to determin which coeffiecients used for prediction.
Linear interpolation is used if t is not in object\$t. 
If missing, all the coeffiecients along the path is used to predict.</p>
</td></tr>
<tr><td><code id="predict.lb_+3A_type">type</code></td>
<td>
<p>To predict response of newx or just fit coeffients on the path.</p>
</td></tr>
<tr><td><code id="predict.lb_+3A_...">...</code></td>
<td>
<p>Additonal arguments for generic predict.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default plot uses the fraction of L1 norm as the x. 
For multinomial case, the sum of absolute values of different class's 
coefficients are caculated to represent each variable.
The intercept term is not ploted
</p>


<h3>Value</h3>

<p>A list containing t and other variables. For type=&quot;fit&quot;, the rediction response
&quot;fit&quot; is returned. For &quot;binomial&quot;, a vector of the probabilities for newx 
falling into class +1 is redurned. For &quot;multinomial&quot;, a matrix with each column means
the probabilities for newx falling into the corresponding class. If type=&quot;coefficients&quot;
coefficients &quot;beta&quot; and intercepts &quot;a0&quot; are returned.
</p>


<h3>Author(s)</h3>

<p>Feng Ruan, Jiechao Xiong and Yuan Yao
</p>

<hr>
<h2 id='west10'>Journey to the West, one of the Four Great Classical Novels of Chinese Literature by WU, Cheng'en.</h2><span id='topic+west10'></span>

<h3>Description</h3>

<p>The <code>west10</code> data frame has 408 rows and 10 columns. It records the appearance of top 10 characters in 408 scenes, the characters who appeared (&quot;1&quot;) or not (&quot;0&quot;) in each of the scenes. The dataset was collected via crowdsourcing in the classes of Mathematical Introduction to Data Analysis and Statistical Learning, taught by Prof. Yuan YAO at Peking University. he original data contains all the 302 characters, which can be downloaded at the sourse website.
</p>


<h3>Format</h3>

<p>This file contains the following data frame:
</p>

<dl>
<dt>west10</dt><dd><p>a data frame of 408 rows and 10 columns</p>
</dd>
</dl>



<h3>Details</h3>

<p>It records the appearance of top 10 characters in 408 scenes, the characters who appeared (&quot;1&quot;) or not (&quot;0&quot;) in each of the scenes. All the character names are in Chinese Pinyin.
</p>


<h3>References</h3>

<p>Yuan YAO, A Mathematical Introduction to Data Analysis, Lecture Notes in <em>Peking University</em>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
