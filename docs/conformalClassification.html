<!DOCTYPE html><html><head><title>Help for package conformalClassification</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {conformalClassification}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#conformalClassification'><p>A Conformal Prediction  R Package for Classification</p></a></li>
<li><a href='#CPCalibrationPlot'><p>Plots the calibration plot</p></a></li>
<li><a href='#CPEfficiency'><p>Computes efficiency of a conformal predictor, which is defined as the</p>
ratio of predictions with more than one class over the size of the testset</a></li>
<li><a href='#CPErrorRate'><p>Computes error rate of a conformal predictor, which is defined as</p>
the ratio of predictions with missing true class lables over the size of the testset</a></li>
<li><a href='#CPObsFuzziness'><p>Computes observed fuzziness, which is defined as</p>
the sum of all p-values for the incorrect class labels.</a></li>
<li><a href='#CPValidity'><p>Computes the deviation from exact validity as the Euclidean norm of</p>
the difference of the observed error and the expected error</a></li>
<li><a href='#fitModel'><p>Fits the model and returns the fitted model</p></a></li>
<li><a href='#ICPClassification'><p>Class-conditional Inductive conformal classifier for multi-class problems</p></a></li>
<li><a href='#parTCPClassification'><p>Class-conditional transductive conformal classifier for multi-class problems, paralled computations</p></a></li>
<li><a href='#TCPClassification'><p>Class-conditional transductive conformal classifier for multi-class problems</p></a></li>
<li><a href='#tcpPValues'><p>Fits the model and computes p-values</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Transductive and Inductive Conformal Predictions for
Classification Problems</td>
</tr>
<tr>
<td>Date:</td>
<td>2017-12-19</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Niharika Gauraha and Ola Spjuth</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Niharika Gauraha &lt;niharika.gauraha@farmbio.uu.se&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementation of transductive conformal prediction (see Vovk, 2013, &lt;<a href="https://doi.org/10.1007%2F978-3-642-41142-7_36">doi:10.1007/978-3-642-41142-7_36</a>&gt;) and inductive conformal prediction (see Balasubramanian et al., 2014, ISBN:9780124017153) for classification problems.</td>
</tr>
<tr>
<td>Depends:</td>
<td>graphics, stats, randomForest, parallel, foreach, doParallel,
mlbench</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-12-21 17:32:37 UTC; niharika</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-12-22 18:29:54 UTC</td>
</tr>
</table>
<hr>
<h2 id='conformalClassification'>A Conformal Prediction  R Package for Classification</h2><span id='topic+conformalClassification'></span><span id='topic+conformalClassification-package'></span>

<h3>Description</h3>

<p>The conformalClassification package implements Transductive Conformal Prediction (TCP) and
Inductive Conformal Prediction (ICP) for classification problems.
</p>


<h3>Details</h3>

<p>Currently, the pakcage is built upon random forests method, where voting of random forests for each
class is considered as a conformity scores for each data point. Mainly the package generates
conformal prediction errors (p-values) for classification problems, it also provides various diagnostic
measures such as deviation from alidity, error rate, efficiency, observed fuzziness and calibration plots.
In future releases, we plan to extend package to use other
machine learning algorithms, (i.e. support vector machine) for model fitting.
</p>

<hr>
<h2 id='CPCalibrationPlot'>Plots the calibration plot</h2><span id='topic+CPCalibrationPlot'></span>

<h3>Description</h3>

<p>Plots the calibration plot
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CPCalibrationPlot(pValues, testSet, color = "blue")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CPCalibrationPlot_+3A_testset">testSet</code></td>
<td>
<p>The test set</p>
</td></tr>
<tr><td><code id="CPCalibrationPlot_+3A_color">color</code></td>
<td>
<p>colour of the calibration line</p>
</td></tr>
<tr><td><code id="CPCalibrationPlot_+3A_pvalues">pValues</code></td>
<td>
<p>Matrix of p-values</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+CPEfficiency">CPEfficiency</a></code>,
<code><a href="#topic+CPErrorRate">CPErrorRate</a></code>,
<code><a href="#topic+CPValidity">CPValidity</a></code>,
<code><a href="#topic+CPObsFuzziness">CPObsFuzziness</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## load the library
library(mlbench)
#library(caret)
library(conformalClassification)

## load the DNA dataset
data(DNA)
originalData &lt;- DNA

## make sure first column is always the label and class labels are always 1, 2, ...
nrAttr = ncol(originalData) #no of attributes
tempColumn = originalData[, 1]
originalData[, 1] = originalData[, nrAttr]
originalData[, nrAttr] = tempColumn
originalData[, 1] = as.factor(originalData[, 1])
originalData[, 1] = as.numeric(originalData[, 1])

## partition the data into training and test set
#result = createDataPartition(originalData[, 1], p = 0.8, list = FALSE)
size = nrow(originalData)
result = sample(1:size,  0.8*size)
trainingSet = originalData[result, ]
testSet = originalData[-result, ]

##ICP classification
pValues = ICPClassification(trainingSet, testSet)
CPCalibrationPlot(pValues, testSet, "blue")
</code></pre>

<hr>
<h2 id='CPEfficiency'>Computes efficiency of a conformal predictor, which is defined as the
ratio of predictions with more than one class over the size of the testset</h2><span id='topic+CPEfficiency'></span>

<h3>Description</h3>

<p>Computes efficiency of a conformal predictor, which is defined as the
ratio of predictions with more than one class over the size of the testset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CPEfficiency(matPValues, testLabels, sigfLevel = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CPEfficiency_+3A_matpvalues">matPValues</code></td>
<td>
<p>Matrix of p-values</p>
</td></tr>
<tr><td><code id="CPEfficiency_+3A_testlabels">testLabels</code></td>
<td>
<p>True labels for the test-set</p>
</td></tr>
<tr><td><code id="CPEfficiency_+3A_sigflevel">sigfLevel</code></td>
<td>
<p>Significance level</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The efficiency
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CPCalibrationPlot">CPCalibrationPlot</a></code>,
<code><a href="#topic+CPErrorRate">CPErrorRate</a></code>,
<code><a href="#topic+CPValidity">CPValidity</a></code>,
<code><a href="#topic+CPObsFuzziness">CPObsFuzziness</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## load the library
library(mlbench)
#library(caret)
library(conformalClassification)

## load the DNA dataset
data(DNA)
originalData &lt;- DNA

## make sure first column is always the label and class labels are always 1, 2, ...
nrAttr = ncol(originalData) #no of attributes
tempColumn = originalData[, 1]
originalData[, 1] = originalData[, nrAttr]
originalData[, nrAttr] = tempColumn
originalData[, 1] = as.factor(originalData[, 1])
originalData[, 1] = as.numeric(originalData[, 1])

## partition the data into training and test set
#result = createDataPartition(originalData[, 1], p = 0.8, list = FALSE)
size = nrow(originalData)
result = sample(1:size,  0.8*size)

trainingSet = originalData[result, ]
testSet = originalData[-result, ]

##ICP classification
pValues = ICPClassification(trainingSet, testSet)
testLabels = testSet[,1]
CPEfficiency(pValues, testLabels)
</code></pre>

<hr>
<h2 id='CPErrorRate'>Computes error rate of a conformal predictor, which is defined as
the ratio of predictions with missing true class lables over the size of the testset</h2><span id='topic+CPErrorRate'></span>

<h3>Description</h3>

<p>Computes error rate of a conformal predictor, which is defined as
the ratio of predictions with missing true class lables over the size of the testset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CPErrorRate(matPValues, testLabels, sigfLevel = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CPErrorRate_+3A_matpvalues">matPValues</code></td>
<td>
<p>Matrix of p-values</p>
</td></tr>
<tr><td><code id="CPErrorRate_+3A_testlabels">testLabels</code></td>
<td>
<p>True labels for the test-set</p>
</td></tr>
<tr><td><code id="CPErrorRate_+3A_sigflevel">sigfLevel</code></td>
<td>
<p>Significance level</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The error rate
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CPCalibrationPlot">CPCalibrationPlot</a></code>,
<code><a href="#topic+CPEfficiency">CPEfficiency</a></code>,
<code><a href="#topic+CPValidity">CPValidity</a></code>,
<code><a href="#topic+CPObsFuzziness">CPObsFuzziness</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## load the library
library(mlbench)
#library(caret)
library(conformalClassification)

## load the DNA dataset
data(DNA)
originalData &lt;- DNA

## make sure first column is always the label and class labels are always 1, 2, ...
nrAttr = ncol(originalData) #no of attributes
tempColumn = originalData[, 1]
originalData[, 1] = originalData[, nrAttr]
originalData[, nrAttr] = tempColumn
originalData[, 1] = as.factor(originalData[, 1])
originalData[, 1] = as.numeric(originalData[, 1])

## partition the data into training and test set
#result = createDataPartition(originalData[, 1], p = 0.8, list = FALSE)
size = nrow(originalData)
result = sample(1:size,  0.8*size)

trainingSet = originalData[result, ]
testSet = originalData[-result, ]

##ICP classification
pValues = ICPClassification(trainingSet, testSet)
testLabels = testSet[,1]
CPErrorRate(pValues, testLabels)
</code></pre>

<hr>
<h2 id='CPObsFuzziness'>Computes observed fuzziness, which is defined as
the sum of all p-values for the incorrect class labels.</h2><span id='topic+CPObsFuzziness'></span>

<h3>Description</h3>

<p>Computes observed fuzziness, which is defined as
the sum of all p-values for the incorrect class labels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CPObsFuzziness(matPValues, testLabels)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CPObsFuzziness_+3A_matpvalues">matPValues</code></td>
<td>
<p>Matrix of p-values</p>
</td></tr>
<tr><td><code id="CPObsFuzziness_+3A_testlabels">testLabels</code></td>
<td>
<p>True labels for the test-set</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The observed fuzziness
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CPCalibrationPlot">CPCalibrationPlot</a></code>,
<code><a href="#topic+CPEfficiency">CPEfficiency</a></code>,
<code><a href="#topic+CPErrorRate">CPErrorRate</a></code>,
<code><a href="#topic+CPValidity">CPValidity</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## load the library
library(mlbench)
#library(caret)
library(conformalClassification)

## load the DNA dataset
data(DNA)
originalData &lt;- DNA

## make sure first column is always the label and class labels are always 1, 2, ...
nrAttr = ncol(originalData) #no of attributes
tempColumn = originalData[, 1]
originalData[, 1] = originalData[, nrAttr]
originalData[, nrAttr] = tempColumn
originalData[, 1] = as.factor(originalData[, 1])
originalData[, 1] = as.numeric(originalData[, 1])

## partition the data into training and test set
#result = createDataPartition(originalData[, 1], p = 0.8, list = FALSE)
size = nrow(originalData)
result = sample(1:size,  0.8*size)

trainingSet = originalData[result, ]
testSet = originalData[-result, ]

##ICP classification
pValues = ICPClassification(trainingSet, testSet)
testLabels = testSet[,1]
CPObsFuzziness(pValues, testLabels)
</code></pre>

<hr>
<h2 id='CPValidity'>Computes the deviation from exact validity as the Euclidean norm of
the difference of the observed error and the expected error</h2><span id='topic+CPValidity'></span>

<h3>Description</h3>

<p>Computes the deviation from exact validity as the Euclidean norm of
the difference of the observed error and the expected error
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CPValidity(matPValues = NULL, testLabels = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CPValidity_+3A_matpvalues">matPValues</code></td>
<td>
<p>Matrix of p-values</p>
</td></tr>
<tr><td><code id="CPValidity_+3A_testlabels">testLabels</code></td>
<td>
<p>True labels for the test-set</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The deviation from exact validity
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CPCalibrationPlot">CPCalibrationPlot</a></code>,
<code><a href="#topic+CPEfficiency">CPEfficiency</a></code>,
<code><a href="#topic+CPErrorRate">CPErrorRate</a></code>,
<code><a href="#topic+CPObsFuzziness">CPObsFuzziness</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## load the library
library(mlbench)
#library(caret)
library(conformalClassification)

## load the DNA dataset
data(DNA)
originalData &lt;- DNA

## make sure first column is always the label and class labels are always 1, 2, ...
nrAttr = ncol(originalData) #no of attributes
tempColumn = originalData[, 1]
originalData[, 1] = originalData[, nrAttr]
originalData[, nrAttr] = tempColumn
originalData[, 1] = as.factor(originalData[, 1])
originalData[, 1] = as.numeric(originalData[, 1])

## partition the data into training and test set
#result = createDataPartition(originalData[, 1], p = 0.8, list = FALSE)
size = nrow(originalData)
result = sample(1:size,  0.8*size)

trainingSet = originalData[result, ]
testSet = originalData[-result, ]

##ICP classification
pValues = ICPClassification(trainingSet, testSet)
testLabels = testSet[,1]
CPValidity(pValues, testLabels)
</code></pre>

<hr>
<h2 id='fitModel'>Fits the model and returns the fitted model</h2><span id='topic+fitModel'></span>

<h3>Description</h3>

<p>Fits the model and returns the fitted model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitModel(trainingSet=NULL, method = "rf",  nrTrees = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitModel_+3A_trainingset">trainingSet</code></td>
<td>
<p>The training set</p>
</td></tr>
<tr><td><code id="fitModel_+3A_method">method</code></td>
<td>
<p>Method for modeling</p>
</td></tr>
<tr><td><code id="fitModel_+3A_nrtrees">nrTrees</code></td>
<td>
<p>Number of trees for RF</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The fitted model
</p>

<hr>
<h2 id='ICPClassification'>Class-conditional Inductive conformal classifier for multi-class problems</h2><span id='topic+ICPClassification'></span>

<h3>Description</h3>

<p>Class-conditional Inductive conformal classifier for multi-class problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ICPClassification(trainingSet, testSet, ratioTrain = 0.7, method = "rf",
  nrTrees = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ICPClassification_+3A_trainingset">trainingSet</code></td>
<td>
<p>Training set</p>
</td></tr>
<tr><td><code id="ICPClassification_+3A_testset">testSet</code></td>
<td>
<p>Test set</p>
</td></tr>
<tr><td><code id="ICPClassification_+3A_ratiotrain">ratioTrain</code></td>
<td>
<p>The ratio for proper training set</p>
</td></tr>
<tr><td><code id="ICPClassification_+3A_method">method</code></td>
<td>
<p>Method for modeling</p>
</td></tr>
<tr><td><code id="ICPClassification_+3A_nrtrees">nrTrees</code></td>
<td>
<p>Number of trees for RF</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The p-values
</p>


<h3>See Also</h3>

<p><code><a href="#topic+TCPClassification">TCPClassification</a></code>,
<code><a href="#topic+parTCPClassification">parTCPClassification</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## load the library
library(mlbench)
#library(caret)
library(conformalClassification)

## load the DNA dataset
data(DNA)
originalData &lt;- DNA

## make sure first column is always the label and class labels are always 1, 2, ...
nrAttr = ncol(originalData) #no of attributes
tempColumn = originalData[, 1]
originalData[, 1] = originalData[, nrAttr]
originalData[, nrAttr] = tempColumn
originalData[, 1] = as.factor(originalData[, 1])
originalData[, 1] = as.numeric(originalData[, 1])

## partition the data into training and test set
#result = createDataPartition(originalData[, 1], p = 0.8, list = FALSE)
size = nrow(originalData)
result = sample(1:size,  0.8*size)

trainingSet = originalData[result, ]
testSet = originalData[-result, ]

##ICP classification
pValues = ICPClassification(trainingSet, testSet)
#perfVlaues = pValues2PerfMetrics(pValues, testSet)
#print(perfVlaues)
#CPCalibrationPlot(pValues, testSet, "blue")
</code></pre>

<hr>
<h2 id='parTCPClassification'>Class-conditional transductive conformal classifier for multi-class problems, paralled computations</h2><span id='topic+parTCPClassification'></span>

<h3>Description</h3>

<p>Class-conditional transductive conformal classifier for multi-class problems, paralled computations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parTCPClassification(trainSet, testSet, method = "rf", nrTrees = 100, nrClusters = 12)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parTCPClassification_+3A_testset">testSet</code></td>
<td>
<p>Test set</p>
</td></tr>
<tr><td><code id="parTCPClassification_+3A_method">method</code></td>
<td>
<p>Method for modeling</p>
</td></tr>
<tr><td><code id="parTCPClassification_+3A_nrtrees">nrTrees</code></td>
<td>
<p>Number of trees for RF</p>
</td></tr>
<tr><td><code id="parTCPClassification_+3A_nrclusters">nrClusters</code></td>
<td>
<p>Number of clusters</p>
</td></tr>
<tr><td><code id="parTCPClassification_+3A_trainset">trainSet</code></td>
<td>
<p>Training set</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The p-values
</p>


<h3>See Also</h3>

<p><code><a href="#topic+TCPClassification">TCPClassification</a></code>.
<code><a href="#topic+ICPClassification">ICPClassification</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## load the library
#library(mlbench)
#library(caret)
#library(conformalClassification)

## load the DNA dataset
#data(DNA)
#originalData &lt;- DNA

## make sure first column is always the label and class labels are always 1, 2, ...
#nrAttr = ncol(originalData) #no of attributes
#tempColumn = originalData[, 1]
#originalData[, 1] = originalData[, nrAttr]
#originalData[, nrAttr] = tempColumn
#originalData[, 1] = as.factor(originalData[, 1])
#originalData[, 1] = as.numeric(originalData[, 1])

## partition the data into training and test set
#result = createDataPartition(originalData[, 1], p = 0.8, list = FALSE)
#trainingSet = originalData[result, ]
#testSet = originalData[-result, ]

##ICP classification
#pValues = parTCPClassification(trainingSet, testSet)
#perfVlaues = pValues2PerfMetrics(pValues, testSet)
#print(perfVlaues)
#CPCalibrationPlot(pValues, testSet, "blue")
#not run
</code></pre>

<hr>
<h2 id='TCPClassification'>Class-conditional transductive conformal classifier for multi-class problems</h2><span id='topic+TCPClassification'></span>

<h3>Description</h3>

<p>Class-conditional transductive conformal classifier for multi-class problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TCPClassification(trainSet, testSet, method = "rf", nrTrees = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TCPClassification_+3A_testset">testSet</code></td>
<td>
<p>Test set</p>
</td></tr>
<tr><td><code id="TCPClassification_+3A_method">method</code></td>
<td>
<p>Method for modeling</p>
</td></tr>
<tr><td><code id="TCPClassification_+3A_nrtrees">nrTrees</code></td>
<td>
<p>Number of trees for RF</p>
</td></tr>
<tr><td><code id="TCPClassification_+3A_trainset">trainSet</code></td>
<td>
<p>Training set</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The p-values
</p>


<h3>See Also</h3>

<p><code><a href="#topic+parTCPClassification">parTCPClassification</a></code>.
<code><a href="#topic+ICPClassification">ICPClassification</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## load the library
#library(mlbench)
#library(caret)
#library(conformalClassification)

## load the DNA dataset
#data(DNA)
#originalData &lt;- DNA

## make sure first column is always the label and class labels are always 1, 2, ...
#nrAttr = ncol(originalData) #no of attributes
#tempColumn = originalData[, 1]
#originalData[, 1] = originalData[, nrAttr]
#originalData[, nrAttr] = tempColumn
#originalData[, 1] = as.factor(originalData[, 1])
#originalData[, 1] = as.numeric(originalData[, 1])

## partition the data into training and test set
#result = createDataPartition(originalData[, 1], p = 0.8, list = FALSE)
#trainingSet = originalData[result, ]
#testSet = originalData[-result, ]

##reduce the size of the training set, because TCP is slow
#result = createDataPartition(trainingSet[, 1], p=0.8, list=FALSE)
#trainingSet = trainingSet[-result, ]

##TCP classification
#pValues = TCPClassification(trainingSet, testSet)
#perfVlaues = pValues2PerfMetrics(pValues, testSet)
#print(perfVlaues)
#CPCalibrationPlot(pValues, testSet, "blue")
#not run
</code></pre>

<hr>
<h2 id='tcpPValues'>Fits the model and computes p-values</h2><span id='topic+tcpPValues'></span>

<h3>Description</h3>

<p>Fits the model and computes p-values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tcpPValues(augTrainSet, method = "rf", nrTrees = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tcpPValues_+3A_augtrainset">augTrainSet</code></td>
<td>
<p>Augmented training set</p>
</td></tr>
<tr><td><code id="tcpPValues_+3A_method">method</code></td>
<td>
<p>Method for modeling</p>
</td></tr>
<tr><td><code id="tcpPValues_+3A_nrtrees">nrTrees</code></td>
<td>
<p>Number of trees for RF</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The p-values
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
