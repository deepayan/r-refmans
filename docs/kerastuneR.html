<!DOCTYPE html><html><head><title>Help for package kerastuneR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {kerastuneR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#BaseTuner'><p>Base Tuner</p></a></li>
<li><a href='#BayesianOptimization'><p>Bayesian Optimization</p></a></li>
<li><a href='#callback_tuner'><p>Tuner Callback</p></a></li>
<li><a href='#fit_tuner'><p>Search</p></a></li>
<li><a href='#get_best_models'><p>Get best models</p></a></li>
<li><a href='#Hyperband'><p>Hyperband</p></a></li>
<li><a href='#HyperModel_class'><p>HyperModel</p></a></li>
<li><a href='#HyperParameters'><p>HyperParameters</p></a></li>
<li><a href='#HyperResNet'><p>HyperResNet</p></a></li>
<li><a href='#HyperXception'><p>HyperXception</p></a></li>
<li><a href='#install_kerastuner'><p>Install Keras Tuner</p></a></li>
<li><a href='#keras_tuner_version'><p>Version of Keras Tuner</p></a></li>
<li><a href='#load_model'><p>Load model</p></a></li>
<li><a href='#Objective'><p>Objective</p></a></li>
<li><a href='#Oracle'><p>Oracle</p></a></li>
<li><a href='#plot_keras_model'><p>Plot Keras model</p></a></li>
<li><a href='#plot_tuner'><p>Plot the tuner results with 'plotly'</p></a></li>
<li><a href='#RandomSearch'><p>RandomSearch</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#results_summary'><p>Results summary</p></a></li>
<li><a href='#save_model'><p>Save model</p></a></li>
<li><a href='#search_summary'><p>Search summary</p></a></li>
<li><a href='#TensorBoard'><p>TensorBoard</p></a></li>
<li><a href='#Tuner_class'><p>Tuner</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Interface to 'Keras Tuner'</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0.7</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Turgut Abdullayev &lt;turqut.a.314@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>'Keras Tuner' <a href="https://keras-team.github.io/keras-tuner/">https://keras-team.github.io/keras-tuner/</a> is a hypertuning framework made for humans. 
             It aims at making the life of AI practitioners, hypertuner 
             algorithm creators and model designers as simple as possible by 
             providing them with a clean and easy to use API for hypertuning. 
             'Keras Tuner' makes moving from a base model to a hypertuned one quick and 
             easy by only requiring you to change a few lines of code.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License 2.0</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/EagerAI/kerastuneR/">https://github.com/EagerAI/kerastuneR/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/EagerAI/kerastuneR/issues/">https://github.com/EagerAI/kerastuneR/issues/</a></td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>TensorFlow &gt;= 2.0 (https://www.tensorflow.org/)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>reticulate, tensorflow, rstudioapi, plotly, data.table,
RJSONIO, rjson, tidyjson, dplyr, echarts4r, crayon, magick</td>
</tr>
<tr>
<td>Suggests:</td>
<td>keras3, knitr, tfdatasets, testthat, purrr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-04-13 13:02:42 UTC; turqu</td>
</tr>
<tr>
<td>Author:</td>
<td>Turgut Abdullayev [aut, cre],
  Google Inc. [cph]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-04-13 13:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='BaseTuner'>Base Tuner</h2><span id='topic+BaseTuner'></span>

<h3>Description</h3>

<p>Tuner base class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BaseTuner(
  oracle,
  hypermodel,
  directory = NULL,
  project_name = NULL,
  overwrite = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BaseTuner_+3A_oracle">oracle</code></td>
<td>
<p>Instance of Oracle class.</p>
</td></tr>
<tr><td><code id="BaseTuner_+3A_hypermodel">hypermodel</code></td>
<td>
<p>Instance of 'HyperModel' class (or callable that takes hyperparameters and returns a 'Model' instance). It is optional when 'Tuner.run_trial()' is overriden and does not use 'self.hypermodel'.</p>
</td></tr>
<tr><td><code id="BaseTuner_+3A_directory">directory</code></td>
<td>
<p>A string, the relative path to the working directory.</p>
</td></tr>
<tr><td><code id="BaseTuner_+3A_project_name">project_name</code></td>
<td>
<p>A string, the name to use as prefix for files saved by this Tuner.</p>
</td></tr>
<tr><td><code id="BaseTuner_+3A_overwrite">overwrite</code></td>
<td>
<p>Boolean, defaults to 'FALSE'. If 'FALSE', reloads an existing project of the same name if one is found. Otherwise, overwrites the project. **kwargs: Arguments for backward compatibility.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>'BaseTuner' is the super class of all 'Tuner' classes. It defines the APIs
for the 'Tuner' classes and serves as a wrapper class for the internal
logics. 'BaseTuner' supports parallel tuning. In parallel tuning, the communication
between 'BaseTuner' and 'Oracle' are all going through gRPC. There are
multiple running instances of 'BaseTuner' but only one 'Oracle'. This design
allows the user to run the same script on multiple machines to launch the
parallel tuning. The 'Oracle' instance should manage the life cycles of all the 'Trial's,
while a 'BaseTuner' is a worker for running the 'Trial's. 'BaseTuner's
requests 'Trial's from the 'Oracle', run them, and report the results back
to the 'Oracle'. A 'BaseTuner' also handles events happening during running
the 'Trial', like saving the model, logging, error handling. Other than
these responsibilities, a 'BaseTuner' should avoid managing a 'Trial' since
the relevant contexts for a 'Trial' are in the 'Oracle', which only
accessible from gRPC. The 'BaseTuner' should be a general tuner for all types of models and avoid
any logic directly related to Keras. The Keras related logics should be
handled by the 'Tuner' class, which is a subclass of 'BaseTuner'.
</p>


<h3>Value</h3>

<p>base tuner object
</p>


<h3>Attributes</h3>

<p>remaining_trials: Number of trials remaining, 'NULL' if 'max_trials' is not set. This is useful when resuming a previously stopped search.
</p>

<hr>
<h2 id='BayesianOptimization'>Bayesian Optimization</h2><span id='topic+BayesianOptimization'></span>

<h3>Description</h3>

<p>Bayesian optimization oracle.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BayesianOptimization(
  objective = NULL,
  max_trials = 10,
  num_initial_points = NULL,
  alpha = 1e-04,
  beta = 2.6,
  seed = NULL,
  hyperparameters = NULL,
  allow_new_entries = TRUE,
  tune_new_entries = TRUE,
  max_retries_per_trial = 0,
  max_consecutive_failed_trials = 3
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BayesianOptimization_+3A_objective">objective</code></td>
<td>
<p>A string, 'keras_tuner.Objective' instance, or a list of 'keras_tuner.Objective's and strings. If a string, the direction of the optimization (min or max) will be inferred. If a list of 'keras_tuner.Objective', we will minimize the sum of all the objectives to minimize subtracting the sum of all the objectives to maximize. The 'objective' argument is optional when 'Tuner.run_trial()' or 'HyperModel.fit()' returns a single float as the objective to minimize.</p>
</td></tr>
<tr><td><code id="BayesianOptimization_+3A_max_trials">max_trials</code></td>
<td>
<p>Integer, the total number of trials (model configurations) to test at most. Note that the oracle may interrupt the search before 'max_trial' models have been tested if the search space has been exhausted. Defaults to 10.</p>
</td></tr>
<tr><td><code id="BayesianOptimization_+3A_num_initial_points">num_initial_points</code></td>
<td>
<p>Optional number of randomly generated samples as initial training data for Bayesian optimization. If left unspecified, a value of 3 times the dimensionality of the hyperparameter space is used.</p>
</td></tr>
<tr><td><code id="BayesianOptimization_+3A_alpha">alpha</code></td>
<td>
<p>Float, the value added to the diagonal of the kernel matrix during fitting. It represents the expected amount of noise in the observed performances in Bayesian optimization. Defaults to 1e-4.</p>
</td></tr>
<tr><td><code id="BayesianOptimization_+3A_beta">beta</code></td>
<td>
<p>Float, the balancing factor of exploration and exploitation. The larger it is, the more explorative it is. Defaults to 2.6.</p>
</td></tr>
<tr><td><code id="BayesianOptimization_+3A_seed">seed</code></td>
<td>
<p>Optional integer, the random seed.</p>
</td></tr>
<tr><td><code id="BayesianOptimization_+3A_hyperparameters">hyperparameters</code></td>
<td>
<p>Optional 'HyperParameters' instance. Can be used to override (or register in advance) hyperparameters in the search space.</p>
</td></tr>
<tr><td><code id="BayesianOptimization_+3A_allow_new_entries">allow_new_entries</code></td>
<td>
<p>Boolean, whether the hypermodel is allowed to request hyperparameter entries not listed in 'hyperparameters'. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="BayesianOptimization_+3A_tune_new_entries">tune_new_entries</code></td>
<td>
<p>Boolean, whether hyperparameter entries that are requested by the hypermodel but that were not specified in 'hyperparameters' should be added to the search space, or not. If not, then the default value for these parameters will be used. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="BayesianOptimization_+3A_max_retries_per_trial">max_retries_per_trial</code></td>
<td>
<p>Integer. Defaults to 0. The maximum number of times to retry a 'Trial' if the trial crashed or the results are invalid.</p>
</td></tr>
<tr><td><code id="BayesianOptimization_+3A_max_consecutive_failed_trials">max_consecutive_failed_trials</code></td>
<td>
<p>Integer. Defaults to 3. The maximum number of consecutive failed 'Trial's. When this number is reached, the search will be stopped. A 'Trial' is marked as failed when none of the retries succeeded.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It uses Bayesian optimization with a underlying Gaussian process model.
The acquisition function used is upper confidence bound (UCB), which can
be found [here](
https://www.cse.wustl.edu/~garnett/cse515t/spring_2015/files/lecture_notes/12.pdf).
</p>


<h3>Value</h3>

<p>BayesianOptimization tuning with Gaussian process
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
# The usage of 'tf$keras'
library(tensorflow)
tf$keras$Input(shape=list(28L, 28L, 1L))

## End(Not run)
</code></pre>

<hr>
<h2 id='callback_tuner'>Tuner Callback</h2><span id='topic+callback_tuner'></span>

<h3>Description</h3>

<p>Abstract base class used to build new callbacks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>callback_tuner(tuner, trial)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="callback_tuner_+3A_tuner">tuner</code></td>
<td>
<p>tuner object</p>
</td></tr>
<tr><td><code id="callback_tuner_+3A_trial">trial</code></td>
<td>
<p>trial ID</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Attributes: params: dict. Training parameters (eg. verbosity, 
batch size, number of epochs...). model: instance of 'keras.models.Model'. 
Reference of the model being trained. validation_data: 
Deprecated. Do not use. The 'logs' dictionary that callback methods
take as argument will contain keys for quantities relevant to
the current batch or epoch. Currently, the '.fit()' method of the 'Model' class
will include the following quantities in the 'logs' that
it passes to its callbacks: on_epoch_end: logs include 'acc' and 'loss', 
and optionally include 'val_loss' (if validation is enabled in 'fit'), and 
'val_acc' (if validation and accuracy monitoring are enabled). on_batch_begin: 
logs include 'size', the number of samples in the current batch. on_batch_end: 
logs include 'loss', and optionally 'acc' (if accuracy monitoring is enabled).
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Attributes</h3>

<p>params: dict. Training parameters (eg. verbosity, batch size, 
number of epochs...). model: instance of 'keras.models.Model'. 
Reference of the model being trained. 
validation_data: Deprecated. Do not use.
</p>

<hr>
<h2 id='fit_tuner'>Search</h2><span id='topic+fit_tuner'></span>

<h3>Description</h3>

<p>Start the search for the best hyperparameter configuration. 
The call to search has the same signature as &ldquo;'model.fit()&ldquo;'.
Models are built iteratively by calling the model-building function, which populates the hyperparameter space 
(search space) tracked by the hp object. The tuner progressively explores the space, recording metrics for 
each configuration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_tuner(
  tuner,
  x = NULL,
  y = NULL,
  steps_per_epoch = NULL,
  batch_size = NULL,
  epochs = NULL,
  validation_data = NULL,
  validation_steps = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit_tuner_+3A_tuner">tuner</code></td>
<td>
<p>A tuner object</p>
</td></tr>
<tr><td><code id="fit_tuner_+3A_x">x</code></td>
<td>
<p>Vector, matrix, or array of training data (or list if the model has multiple inputs). 
If all inputs in the model are named, you can also pass a list mapping input names to data. x can be NULL
(default) if feeding from framework-native tensors (e.g. TensorFlow data tensors).</p>
</td></tr>
<tr><td><code id="fit_tuner_+3A_y">y</code></td>
<td>
<p>Vector, matrix, or array of target (label) data (or list if the model has multiple outputs). 
If all outputs in the model are named, you can also pass a list mapping output names to data. y can be 
NULL (default) if feeding from framework-native tensors (e.g. TensorFlow data tensors).</p>
</td></tr>
<tr><td><code id="fit_tuner_+3A_steps_per_epoch">steps_per_epoch</code></td>
<td>
<p>Integer. Total number of steps (batches of samples) to yield from generator before 
declaring one epoch finished and starting the next epoch. It should typically be equal to 
ceil(num_samples / batch_size). Optional for Sequence: if unspecified, will use the len(generator) 
as a number of steps.</p>
</td></tr>
<tr><td><code id="fit_tuner_+3A_batch_size">batch_size</code></td>
<td>
<p>Integer or 'NULL'. Number of samples per gradient update.
If unspecified, 'batch_size' will default to 32.</p>
</td></tr>
<tr><td><code id="fit_tuner_+3A_epochs">epochs</code></td>
<td>
<p>to train the model. Note that in conjunction with initial_epoch, 
epochs is to be understood as &quot;final epoch&quot;. The model is not trained for a number of iterations
given by epochs, but merely until the epoch of index epochs is reached.</p>
</td></tr>
<tr><td><code id="fit_tuner_+3A_validation_data">validation_data</code></td>
<td>
<p>Data on which to evaluate the loss and any model metrics at the end of each epoch. 
The model will not be trained on this data. validation_data will override validation_split. 
validation_data could be: - tuple (x_val, y_val) of Numpy arrays or 
tensors - tuple (x_val, y_val, val_sample_weights) of Numpy arrays - dataset or a dataset iterator</p>
</td></tr>
<tr><td><code id="fit_tuner_+3A_validation_steps">validation_steps</code></td>
<td>
<p>Only relevant if steps_per_epoch is specified. Total number of steps (batches of samples)
to validate before stopping.</p>
</td></tr>
<tr><td><code id="fit_tuner_+3A_...">...</code></td>
<td>
<p>Some additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>performs a search for best hyperparameter configuations
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

library(keras)
x_data &lt;- matrix(data = runif(500,0,1),nrow = 50,ncol = 5) 
y_data &lt;-  ifelse(runif(50,0,1) &gt; 0.6, 1L,0L) %&gt;% as.matrix()
x_data2 &lt;- matrix(data = runif(500,0,1),nrow = 50,ncol = 5)
y_data2 &lt;-  ifelse(runif(50,0,1) &gt; 0.6, 1L,0L) %&gt;% as.matrix()


HyperModel &lt;- PyClass(
  'HyperModel',
  inherit = HyperModel_class(),
  list(
    
    `__init__` = function(self, num_classes) {
      
      self$num_classes = num_classes
      NULL
    },
    build = function(self,hp) {
      model = keras_model_sequential() 
      model %&gt;% layer_dense(units = hp$Int('units',
                                           min_value = 32,
                                           max_value = 512,
                                           step = 32),
                            input_shape = ncol(x_data),
                            activation = 'relu') %&gt;% 
        layer_dense(as.integer(self$num_classes), activation = 'softmax') %&gt;% 
        compile(
          optimizer = tf$keras$optimizers$Adam(
            hp$Choice('learning_rate',
                      values = c(1e-2, 1e-3, 1e-4))),
          loss = 'sparse_categorical_crossentropy',
          metrics = 'accuracy')
    }
  )
)

hypermodel = HyperModel(num_classes=10L)


tuner = RandomSearch(hypermodel = hypermodel,
                     objective = 'val_accuracy',
                     max_trials = 2,
                    executions_per_trial = 1,
                     directory = 'my_dir5',
                     project_name = 'helloworld')
                     
tuner %&gt;% fit_tuner(x_data, y_data, epochs = 1, validation_data = list(x_data2,y_data2)) 

## End(Not run)
</code></pre>

<hr>
<h2 id='get_best_models'>Get best models</h2><span id='topic+get_best_models'></span>

<h3>Description</h3>

<p>The function for retrieving the top best models with hyperparameters
Returns the best model(s), as determined by the tuner's objective.
The models are loaded with the weights corresponding to their best checkpoint (at the end of the best epoch of best trial).
This method is only a convenience shortcut. For best performance, It is recommended to retrain your Model on the full 
dataset using the best hyperparameters found during search.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_best_models(tuner = NULL, num_models = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_best_models_+3A_tuner">tuner</code></td>
<td>
<p>A tuner object</p>
</td></tr>
<tr><td><code id="get_best_models_+3A_num_models">num_models</code></td>
<td>
<p>When search is over, one can retrieve the best model(s)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the list of best model(s)
</p>

<hr>
<h2 id='Hyperband'>Hyperband</h2><span id='topic+Hyperband'></span>

<h3>Description</h3>

<p>Variation of HyperBand algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Hyperband(
  hypermodel = NULL,
  objective = NULL,
  max_epochs = 100,
  factor = 3,
  hyperband_iterations = 1,
  seed = NULL,
  hyperparameters = NULL,
  tune_new_entries = TRUE,
  allow_new_entries = TRUE,
  max_retries_per_trial = 0,
  max_consecutive_failed_trials = 3,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Hyperband_+3A_hypermodel">hypermodel</code></td>
<td>
<p>Instance of 'HyperModel' class (or callable that takes hyperparameters and returns a 'Model' instance). It is optional when 'Tuner.run_trial()' is overriden and does not use 'self.hypermodel'.</p>
</td></tr>
<tr><td><code id="Hyperband_+3A_objective">objective</code></td>
<td>
<p>A string, 'keras_tuner.Objective' instance, or a list of 'keras_tuner.Objective's and strings. If a string, the direction of the optimization (min or max) will be inferred. If a list of 'keras_tuner.Objective', we will minimize the sum of all the objectives to minimize subtracting the sum of all the objectives to maximize. The 'objective' argument is optional when 'Tuner.run_trial()' or 'HyperModel.fit()' returns a single float as the objective to minimize.</p>
</td></tr>
<tr><td><code id="Hyperband_+3A_max_epochs">max_epochs</code></td>
<td>
<p>Integer, the maximum number of epochs to train one model. It is recommended to set this to a value slightly higher than the expected epochs to convergence for your largest Model, and to use early stopping during training (for example, via 'tf.keras.callbacks.EarlyStopping'). Defaults to 100.</p>
</td></tr>
<tr><td><code id="Hyperband_+3A_factor">factor</code></td>
<td>
<p>Integer, the reduction factor for the number of epochs and number of models for each bracket. Defaults to 3.</p>
</td></tr>
<tr><td><code id="Hyperband_+3A_hyperband_iterations">hyperband_iterations</code></td>
<td>
<p>Integer, at least 1, the number of times to iterate over the full Hyperband algorithm. One iteration will run approximately 'max_epochs * (math.log(max_epochs, factor) ** 2)' cumulative epochs across all trials. It is recommended to set this to as high a value as is within your resource budget. Defaults to 1.</p>
</td></tr>
<tr><td><code id="Hyperband_+3A_seed">seed</code></td>
<td>
<p>Optional integer, the random seed.</p>
</td></tr>
<tr><td><code id="Hyperband_+3A_hyperparameters">hyperparameters</code></td>
<td>
<p>Optional HyperParameters instance. Can be used to override (or register in advance) hyperparameters in the search space.</p>
</td></tr>
<tr><td><code id="Hyperband_+3A_tune_new_entries">tune_new_entries</code></td>
<td>
<p>Boolean, whether hyperparameter entries that are requested by the hypermodel but that were not specified in 'hyperparameters' should be added to the search space, or not. If not, then the default value for these parameters will be used. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="Hyperband_+3A_allow_new_entries">allow_new_entries</code></td>
<td>
<p>Boolean, whether the hypermodel is allowed to request hyperparameter entries not listed in 'hyperparameters'. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="Hyperband_+3A_max_retries_per_trial">max_retries_per_trial</code></td>
<td>
<p>Integer. Defaults to 0. The maximum number of times to retry a 'Trial' if the trial crashed or the results are invalid.</p>
</td></tr>
<tr><td><code id="Hyperband_+3A_max_consecutive_failed_trials">max_consecutive_failed_trials</code></td>
<td>
<p>Integer. Defaults to 3. The maximum number of consecutive failed 'Trial's. When this number is reached, the search will be stopped. A 'Trial' is marked as failed when none of the retries succeeded. **kwargs: Keyword arguments relevant to all 'Tuner' subclasses. Please see the docstring for 'Tuner'.</p>
</td></tr>
<tr><td><code id="Hyperband_+3A_...">...</code></td>
<td>
<p>Some additional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reference: Li, Lisha, and Kevin Jamieson. [&quot;Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization.&quot; Journal of Machine Learning Research 18 (2018): 1-52]( http://jmlr.org/papers/v18/16-558.html).
</p>


<h3>Value</h3>

<p>a hyperparameter tuner object Hyperband
</p>


<h3>Reference</h3>

<p>Li, Lisha, and Kevin Jamieson. [&quot;Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization.&quot; Journal of Machine Learning Research 18 (2018): 1-52]( http://jmlr.org/papers/v18/16-558.html).
</p>

<hr>
<h2 id='HyperModel_class'>HyperModel</h2><span id='topic+HyperModel_class'></span>

<h3>Description</h3>

<p>Defines a searchable space of Models and builds Models from this space.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HyperModel_class(name = NULL, tunable = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HyperModel_class_+3A_name">name</code></td>
<td>
<p>The name of this HyperModel.</p>
</td></tr>
<tr><td><code id="HyperModel_class_+3A_tunable">tunable</code></td>
<td>
<p>Whether the hyperparameters defined in this hypermodel should 
be added to search space. If 'FALSE', either the search space for these parameters 
must be defined in advance, or the default values will be used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HyperParameters'>HyperParameters</h2><span id='topic+HyperParameters'></span>

<h3>Description</h3>

<p>The HyperParameters class serves as a hyperparameter container. A HyperParameters instance contains information about both the search space and the current values of each hyperparameter.
Hyperparameters can be defined inline with the model-building code that uses them. This saves you from having to write boilerplate code and helps to make the code more maintainable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HyperParameters(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HyperParameters_+3A_...">...</code></td>
<td>
<p>Pass hyperparameter arguments to the tuner constructor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>container for both a hyperparameter space, and current values
</p>

<hr>
<h2 id='HyperResNet'>HyperResNet</h2><span id='topic+HyperResNet'></span>

<h3>Description</h3>

<p>A ResNet HyperModel.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HyperResNet(
  include_top = TRUE,
  input_shape = NULL,
  input_tensor = NULL,
  classes = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HyperResNet_+3A_include_top">include_top</code></td>
<td>
<p>whether to include the fully-connected layer at the top of the network.</p>
</td></tr>
<tr><td><code id="HyperResNet_+3A_input_shape">input_shape</code></td>
<td>
<p>Optional shape list, e.g. '(256, 256, 3)'. One of 'input_shape' or 
'input_tensor' must be specified.</p>
</td></tr>
<tr><td><code id="HyperResNet_+3A_input_tensor">input_tensor</code></td>
<td>
<p>Optional Keras tensor (i.e. output of 'layers.Input()') to use as image 
input for the model. One of 'input_shape' or 'input_tensor' must be specified.</p>
</td></tr>
<tr><td><code id="HyperResNet_+3A_classes">classes</code></td>
<td>
<p>optional number of classes to classify images into, only to be specified if 
'include_top' is TRUE, and if no 'weights' argument is specified. **kwargs: Additional keyword 
arguments that apply to all HyperModels. See 'kerastuner.HyperModel'.</p>
</td></tr>
<tr><td><code id="HyperResNet_+3A_...">...</code></td>
<td>
<p>Additional keyword arguments that apply to all HyperModels.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a pre-trained ResNet model
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 


cifar &lt;- dataset_cifar10()

hypermodel = HyperResNet(input_shape = list(32L, 32L, 3L), classes = 10L)
hypermodel2 = HyperXception(input_shape = list(32L, 32L, 3L), classes = 10L)


tuner = Hyperband(
  hypermodel = hypermodel,
  objective = 'accuracy',
  loss = 'sparse_categorical_crossentropy',
  max_epochs = 1,
  directory = 'my_dir',
  project_name='helloworld')


train_data = cifar$train$x[1:30,1:32,1:32,1:3]
test_data = cifar$train$y[1:30,1] %&gt;% as.matrix()


tuner %&gt;% fit_tuner(train_data,test_data, epochs = 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='HyperXception'>HyperXception</h2><span id='topic+HyperXception'></span>

<h3>Description</h3>

<p>An Xception HyperModel.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HyperXception(
  include_top = TRUE,
  input_shape = NULL,
  input_tensor = NULL,
  classes = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HyperXception_+3A_include_top">include_top</code></td>
<td>
<p>whether to include the fully-connected layer at the top of the network.</p>
</td></tr>
<tr><td><code id="HyperXception_+3A_input_shape">input_shape</code></td>
<td>
<p>Optional shape list, e.g. '(256, 256, 3)'. One of 'input_shape' or 
'input_tensor' must be specified.</p>
</td></tr>
<tr><td><code id="HyperXception_+3A_input_tensor">input_tensor</code></td>
<td>
<p>Optional Keras tensor (i.e. output of 'layers.Input()') to use as 
image input for the model. One of 'input_shape' or 'input_tensor' must be specified.</p>
</td></tr>
<tr><td><code id="HyperXception_+3A_classes">classes</code></td>
<td>
<p>optional number of classes to classify images into, only to be specified 
if 'include_top' is TRUE, and if no 'weights' argument is specified. **kwargs: Additional 
keyword arguments that apply to all HyperModels. See 'kerastuner.HyperModel'.</p>
</td></tr>
<tr><td><code id="HyperXception_+3A_...">...</code></td>
<td>
<p>Additional keyword arguments that apply to all HyperModels.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a pre-trained Xception model
</p>

<hr>
<h2 id='install_kerastuner'>Install Keras Tuner</h2><span id='topic+install_kerastuner'></span>

<h3>Description</h3>

<p>This function is used to install the Keras Tuner python module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>install_kerastuner(
  version = NULL,
  ...,
  bayesian = TRUE,
  restart_session = TRUE,
  from_git = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="install_kerastuner_+3A_version">version</code></td>
<td>
<p>for specific version of Keras Tuner, e.g. &quot;1.0.1&quot;</p>
</td></tr>
<tr><td><code id="install_kerastuner_+3A_...">...</code></td>
<td>
<p>other arguments passed to [reticulate::py_install()].</p>
</td></tr>
<tr><td><code id="install_kerastuner_+3A_bayesian">bayesian</code></td>
<td>
<p>install bayesian module</p>
</td></tr>
<tr><td><code id="install_kerastuner_+3A_restart_session">restart_session</code></td>
<td>
<p>Restart R session after installing (note this will only occur within RStudio).</p>
</td></tr>
<tr><td><code id="install_kerastuner_+3A_from_git">from_git</code></td>
<td>
<p>install the recent GitHub version of Keras Tuner</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a python module kerastuner
</p>

<hr>
<h2 id='keras_tuner_version'>Version of Keras Tuner</h2><span id='topic+keras_tuner_version'></span>

<h3>Description</h3>

<p>Get the current version of Keras Tuner
</p>


<h3>Usage</h3>

<pre><code class='language-R'>keras_tuner_version()
</code></pre>


<h3>Value</h3>

<p>prints the version.
</p>

<hr>
<h2 id='load_model'>Load model</h2><span id='topic+load_model'></span>

<h3>Description</h3>

<p>Loads a Model from a given trial
</p>


<h3>Usage</h3>

<pre><code class='language-R'>load_model(tuner, trial)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="load_model_+3A_tuner">tuner</code></td>
<td>
<p>A tuner object</p>
</td></tr>
<tr><td><code id="load_model_+3A_trial">trial</code></td>
<td>
<p>A 'Trial' instance. For models that report intermediate results 
to the 'Oracle', generally 'load_model' should load the best reported 'step' 
by relying of 'trial.best_step'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Objective'>Objective</h2><span id='topic+Objective'></span>

<h3>Description</h3>

<p>Objective(name, direction) includes strings, 
the direction of the optimization (min or max) will be inferred.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Objective(name, direction, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Objective_+3A_name">name</code></td>
<td>
<p>name</p>
</td></tr>
<tr><td><code id="Objective_+3A_direction">direction</code></td>
<td>
<p>direction</p>
</td></tr>
<tr><td><code id="Objective_+3A_...">...</code></td>
<td>
<p>Some additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Oracle'>Oracle</h2><span id='topic+Oracle'></span>

<h3>Description</h3>

<p>Implements a hyperparameter optimization algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Oracle(
  objective = NULL,
  max_trials = NULL,
  hyperparameters = NULL,
  allow_new_entries = TRUE,
  tune_new_entries = TRUE,
  seed = NULL,
  max_retries_per_trial = 0,
  max_consecutive_failed_trials = 3
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Oracle_+3A_objective">objective</code></td>
<td>
<p>A string, 'keras_tuner.Objective' instance, or a list of 'keras_tuner.Objective's and strings. If a string, the direction of the optimization (min or max) will be inferred. If a list of 'keras_tuner.Objective', we will minimize the sum of all the objectives to minimize subtracting the sum of all the objectives to maximize. The 'objective' argument is optional when 'Tuner.run_trial()' or 'HyperModel.fit()' returns a single float as the objective to minimize.</p>
</td></tr>
<tr><td><code id="Oracle_+3A_max_trials">max_trials</code></td>
<td>
<p>Integer, the total number of trials (model configurations) to test at most. Note that the oracle may interrupt the search before 'max_trial' models have been tested if the search space has been exhausted.</p>
</td></tr>
<tr><td><code id="Oracle_+3A_hyperparameters">hyperparameters</code></td>
<td>
<p>Optional 'HyperParameters' instance. Can be used to override (or register in advance) hyperparameters in the search space.</p>
</td></tr>
<tr><td><code id="Oracle_+3A_allow_new_entries">allow_new_entries</code></td>
<td>
<p>Boolean, whether the hypermodel is allowed to request hyperparameter entries not listed in 'hyperparameters'. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="Oracle_+3A_tune_new_entries">tune_new_entries</code></td>
<td>
<p>Boolean, whether hyperparameter entries that are requested by the hypermodel but that were not specified in 'hyperparameters' should be added to the search space, or not. If not, then the default value for these parameters will be used. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="Oracle_+3A_seed">seed</code></td>
<td>
<p>Int. Random seed.</p>
</td></tr>
<tr><td><code id="Oracle_+3A_max_retries_per_trial">max_retries_per_trial</code></td>
<td>
<p>Integer. Defaults to 0. The maximum number of times to retry a 'Trial' if the trial crashed or the results are invalid.</p>
</td></tr>
<tr><td><code id="Oracle_+3A_max_consecutive_failed_trials">max_consecutive_failed_trials</code></td>
<td>
<p>Integer. Defaults to 3. The maximum number of consecutive failed 'Trial's. When this number is reached, the search will be stopped. A 'Trial' is marked as failed when none of the retries succeeded.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In a parallel tuning setting, there is only one 'Oracle' instance. The
workers would communicate with the centralized 'Oracle' instance with gPRC
calls to the 'Oracle' methods. 'Trial' objects are often used as the communication packet through the gPRC
calls to pass information between the worker 'Tuner' instances and the
'Oracle'. For example, 'Oracle.create_trial()' returns a 'Trial' object, and
'Oracle.end_trial()' accepts a 'Trial' in its arguments. New copies of the same 'Trial' instance are reconstructed as it going
through the gRPC calls. The changes to the 'Trial' objects in the worker
'Tuner's are synced to the original copy in the 'Oracle' when they are
passed back to the 'Oracle' by calling 'Oracle.end_trial()'.
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='plot_keras_model'>Plot Keras model</h2><span id='topic+plot_keras_model'></span>

<h3>Description</h3>

<p>Converts a Keras model to dot format and save to a file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_keras_model(
  model,
  to_file = "model.png",
  show_shapes = FALSE,
  show_layer_names = TRUE,
  rankdir = "TB",
  expand_nested = FALSE,
  dpi = 96
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_keras_model_+3A_model">model</code></td>
<td>
<p>A Keras model instance</p>
</td></tr>
<tr><td><code id="plot_keras_model_+3A_to_file">to_file</code></td>
<td>
<p>File name of the plot image.</p>
</td></tr>
<tr><td><code id="plot_keras_model_+3A_show_shapes">show_shapes</code></td>
<td>
<p>whether to display shape information.</p>
</td></tr>
<tr><td><code id="plot_keras_model_+3A_show_layer_names">show_layer_names</code></td>
<td>
<p>whether to display layer names.</p>
</td></tr>
<tr><td><code id="plot_keras_model_+3A_rankdir">rankdir</code></td>
<td>
<p>'rankdir' argument passed to PyDot, a string specifying the format of the plot: 
'TB' creates a vertical plot; 'LR' creates a horizontal plot.</p>
</td></tr>
<tr><td><code id="plot_keras_model_+3A_expand_nested">expand_nested</code></td>
<td>
<p>Whether to expand nested models into clusters.</p>
</td></tr>
<tr><td><code id="plot_keras_model_+3A_dpi">dpi</code></td>
<td>
<p>Dots per inch.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>saves a png image on the system and builds a plot in R
</p>

<hr>
<h2 id='plot_tuner'>Plot the tuner results with 'plotly'</h2><span id='topic+plot_tuner'></span>

<h3>Description</h3>

<p>Plot the search space results
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_tuner(tuner, height = NULL, width = NULL, type = "plotly")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_tuner_+3A_tuner">tuner</code></td>
<td>
<p>A tuner object</p>
</td></tr>
<tr><td><code id="plot_tuner_+3A_height">height</code></td>
<td>
<p>height of the plot</p>
</td></tr>
<tr><td><code id="plot_tuner_+3A_width">width</code></td>
<td>
<p>width of the plot</p>
</td></tr>
<tr><td><code id="plot_tuner_+3A_type">type</code></td>
<td>
<p>Type parameter has 2 options: <br /> 
* By default it uses 'plotly' <br /> 
* Second option is 'echarts4r' <br /> 
**Note** that 'echarts4r' ignores width and height parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list which contains a dataframe of results and a plot
</p>

<hr>
<h2 id='RandomSearch'>RandomSearch</h2><span id='topic+RandomSearch'></span>

<h3>Description</h3>

<p>Random search tuner.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RandomSearch(
  hypermodel,
  objective,
  max_trials,
  seed = NULL,
  hyperparameters = NULL,
  tune_new_entries = TRUE,
  allow_new_entries = TRUE,
  max_retries_per_trial = 0,
  max_consecutive_failed_trials = 3,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RandomSearch_+3A_hypermodel">hypermodel</code></td>
<td>
<p>Define a model-building function. It takes an argument &quot;hp&quot; from which 
you can sample hyperparameters.</p>
</td></tr>
<tr><td><code id="RandomSearch_+3A_objective">objective</code></td>
<td>
<p>A loss metrics function for tracking the model performance e.g. &quot;val_precision&quot;. The name of 
the objective to optimize (whether to minimize or maximize is automatically inferred for built-in metrics)</p>
</td></tr>
<tr><td><code id="RandomSearch_+3A_max_trials">max_trials</code></td>
<td>
<p>the total number of trials (max_trials) to test</p>
</td></tr>
<tr><td><code id="RandomSearch_+3A_seed">seed</code></td>
<td>
<p>Int. Random seed</p>
</td></tr>
<tr><td><code id="RandomSearch_+3A_hyperparameters">hyperparameters</code></td>
<td>
<p>HyperParameters class instance. Can be used to override (or register in advance) hyperparamters 
in the search space</p>
</td></tr>
<tr><td><code id="RandomSearch_+3A_tune_new_entries">tune_new_entries</code></td>
<td>
<p>Whether hyperparameter entries that are requested by the hypermodel 
but that were not specified in hyperparameters should be added to the search space, or not. 
If not, then the default value for these parameters will be used.</p>
</td></tr>
<tr><td><code id="RandomSearch_+3A_allow_new_entries">allow_new_entries</code></td>
<td>
<p>Whether the hypermodel is allowed to request hyperparameter entries not listed in hyperparameters</p>
</td></tr>
<tr><td><code id="RandomSearch_+3A_max_retries_per_trial">max_retries_per_trial</code></td>
<td>
<p>Integer. Defaults to 0. The maximum number of times to retry a 'Trial' if the trial crashed or the results are invalid.</p>
</td></tr>
<tr><td><code id="RandomSearch_+3A_max_consecutive_failed_trials">max_consecutive_failed_trials</code></td>
<td>
<p>Integer. Defaults to 3. The maximum number of consecutive failed 'Trial's. When this number is reached, the search will be stopped. A 'Trial' is marked as failed when none of the retries succeeded. **kwargs: Keyword arguments relevant to all 'Tuner' subclasses. Please see the docstring for 'Tuner'.</p>
</td></tr>
<tr><td><code id="RandomSearch_+3A_...">...</code></td>
<td>
<p>Some additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a hyperparameter tuner object RandomSearch
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

x_data &lt;- matrix(data = runif(500,0,1),nrow = 50,ncol = 5) 
y_data &lt;-  ifelse(runif(50,0,1) &gt; 0.6, 1L,0L) %&gt;% as.matrix()
x_data2 &lt;- matrix(data = runif(500,0,1),nrow = 50,ncol = 5)
y_data2 &lt;-  ifelse(runif(50,0,1) &gt; 0.6, 1L,0L) %&gt;% as.matrix()

build_model = function(hp) {
 model = keras_model_sequential()
  model %&gt;% layer_dense(units=hp$Int('units',
                                    min_value=32L,
                                    max_value=512L,
                                    step=32L),
                                    input_shape = ncol(x_data),
                                    activation='relu') %&gt;%
   layer_dense(units=1L, activation='softmax') %&gt;%
   compile(
     optimizer= tf$keras$optimizers$Adam(
       hp$Choice('learning_rate',
                 values=c(1e-2, 1e-3, 1e-4))),
    loss='binary_crossentropy',
     metrics='accuracy')
     return(model)
 }
 tuner = RandomSearch(hypermodel = build_model,
                       objective = 'val_accuracy',
                       max_trials = 2,
                       executions_per_trial = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+use_python'></span><span id='topic+tf'></span><span id='topic+PyClass'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>reticulate</dt><dd><p><code><a href="reticulate.html#topic+PyClass">PyClass</a></code>, <code><a href="reticulate.html#topic+use_python">use_python</a></code></p>
</dd>
<dt>tensorflow</dt><dd><p><code><a href="tensorflow.html#topic+tf">tf</a></code></p>
</dd>
</dl>


<h3>Value</h3>

<p>a alias for reticulate::use_python
</p>
<p>a alias for tensorflow::tf
</p>
<p>a alias for reticulate::PyClass
</p>

<hr>
<h2 id='results_summary'>Results summary</h2><span id='topic+results_summary'></span>

<h3>Description</h3>

<p>Print a summary of the search results (best models)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>results_summary(tuner = NULL, num_trials = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="results_summary_+3A_tuner">tuner</code></td>
<td>
<p>Requires a tuner object</p>
</td></tr>
<tr><td><code id="results_summary_+3A_num_trials">num_trials</code></td>
<td>
<p>Shows the top best models</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the list of results summary of the tuner object
</p>

<hr>
<h2 id='save_model'>Save model</h2><span id='topic+save_model'></span>

<h3>Description</h3>

<p>Saves a Model for a given trial
</p>


<h3>Usage</h3>

<pre><code class='language-R'>save_model(tuner, trial_id, model, step = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="save_model_+3A_tuner">tuner</code></td>
<td>
<p>A tuner object</p>
</td></tr>
<tr><td><code id="save_model_+3A_trial_id">trial_id</code></td>
<td>
<p>The ID of the 'Trial' that corresponds to this Model.</p>
</td></tr>
<tr><td><code id="save_model_+3A_model">model</code></td>
<td>
<p>The trained model.</p>
</td></tr>
<tr><td><code id="save_model_+3A_step">step</code></td>
<td>
<p>For models that report intermediate results to the 'Oracle', the 
step that this saved file should correspond to. For example, for Keras models 
this is the number of epochs trained.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='search_summary'>Search summary</h2><span id='topic+search_summary'></span>

<h3>Description</h3>

<p>Print a summary of the search space
</p>


<h3>Usage</h3>

<pre><code class='language-R'>search_summary(tuner = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="search_summary_+3A_tuner">tuner</code></td>
<td>
<p>Requires a tuner object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the summary of search space of the tuner object
</p>

<hr>
<h2 id='TensorBoard'>TensorBoard</h2><span id='topic+TensorBoard'></span>

<h3>Description</h3>

<p>Enable visualizations for TensorBoard.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TensorBoard(
  log_dir = "logs",
  histogram_freq = 0,
  write_graph = TRUE,
  write_images = FALSE,
  update_freq = "epoch",
  profile_batch = 2,
  embeddings_freq = 0,
  embeddings_metadata = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TensorBoard_+3A_log_dir">log_dir</code></td>
<td>
<p>the path of the directory where to save the log files to be parsed by TensorBoard.</p>
</td></tr>
<tr><td><code id="TensorBoard_+3A_histogram_freq">histogram_freq</code></td>
<td>
<p>frequency (in epochs) at which to compute activation and weight histograms 
for the layers of the model. If set to 0, histograms won't be computed. Validation data (or split) 
must be specified for histogram visualizations.</p>
</td></tr>
<tr><td><code id="TensorBoard_+3A_write_graph">write_graph</code></td>
<td>
<p>whether to visualize the graph in TensorBoard. The log file can become quite 
large when write_graph is set to TRUE.</p>
</td></tr>
<tr><td><code id="TensorBoard_+3A_write_images">write_images</code></td>
<td>
<p>whether to write model weights to visualize as image in TensorBoard.</p>
</td></tr>
<tr><td><code id="TensorBoard_+3A_update_freq">update_freq</code></td>
<td>
<p>''batch'&lsquo; or '&rsquo;epoch'&lsquo; or integer. When using '&rsquo;batch'', writes the losses and 
metrics to TensorBoard after each batch. The same applies for ''epoch'&lsquo;. If using an integer, let&rsquo;s 
say '1000', the callback will write the metrics and losses to TensorBoard every 1000 samples. 
Note that writing too frequently to TensorBoard can slow down your training.</p>
</td></tr>
<tr><td><code id="TensorBoard_+3A_profile_batch">profile_batch</code></td>
<td>
<p>Profile the batch to sample compute characteristics. By default, it will 
profile the second batch. Set profile_batch=0 to disable profiling. Must run in 
TensorFlow eager mode.</p>
</td></tr>
<tr><td><code id="TensorBoard_+3A_embeddings_freq">embeddings_freq</code></td>
<td>
<p>frequency (in epochs) at which embedding layers will be visualized. 
If set to 0, embeddings won't be visualized.</p>
</td></tr>
<tr><td><code id="TensorBoard_+3A_embeddings_metadata">embeddings_metadata</code></td>
<td>
<p>a dictionary which maps layer name to a file name in which metadata 
for this embedding layer is saved. 
See the [details]( https://www.tensorflow.org/how_tos/embedding_viz/#metadata_optional) about 
metadata files format. In case if the same metadata file is used for all embedding layers, 
string can be passed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>TensorBoard is a visualization tool provided with TensorFlow. This callback logs events for TensorBoard, including:
* Metrics summary plots
* Training graph visualization
* Activation histograms
* Sampled profiling If you have installed TensorFlow with pip, you should be able
to launch TensorBoard from the command line: &ldquo;'sh
tensorboard &ndash;logdir=path_to_your_logs
&ldquo;' You can find more information about TensorBoard
[here](https://www.tensorflow.org/get_started/summaries_and_tensorboard).
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Raises</h3>

<p>ValueError: If histogram_freq is set and no validation data is provided.
</p>

<hr>
<h2 id='Tuner_class'>Tuner</h2><span id='topic+Tuner_class'></span>

<h3>Description</h3>

<p>Tuner class for Keras models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Tuner_class(
  oracle,
  hypermodel,
  max_model_size = NULL,
  optimizer = NULL,
  loss = NULL,
  metrics = NULL,
  distribution_strategy = NULL,
  directory = NULL,
  project_name = NULL,
  logger = NULL,
  tuner_id = NULL,
  overwrite = FALSE,
  executions_per_trial = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tuner_class_+3A_oracle">oracle</code></td>
<td>
<p>Instance of Oracle class.</p>
</td></tr>
<tr><td><code id="Tuner_class_+3A_hypermodel">hypermodel</code></td>
<td>
<p>Instance of HyperModel class (or 
callable that takes hyperparameters and returns a 
Model instance).</p>
</td></tr>
<tr><td><code id="Tuner_class_+3A_max_model_size">max_model_size</code></td>
<td>
<p>Int. Maximum size of weights 
(in floating point coefficients) for a valid models. 
Models larger than this are rejected.</p>
</td></tr>
<tr><td><code id="Tuner_class_+3A_optimizer">optimizer</code></td>
<td>
<p>Optional. Optimizer instance. May be 
used to override the 'optimizer' argument in the 'compile' 
step for the models. If the hypermodel does not compile 
the models it generates, then this argument must be specified.</p>
</td></tr>
<tr><td><code id="Tuner_class_+3A_loss">loss</code></td>
<td>
<p>Optional. May be used to override the 'loss' 
argument in the 'compile' step for the models. If the 
hypermodel does not compile the models it generates, 
then this argument must be specified.</p>
</td></tr>
<tr><td><code id="Tuner_class_+3A_metrics">metrics</code></td>
<td>
<p>Optional. May be used to override the 'metrics' 
argument in the 'compile' step for the models. If the hypermodel 
does not compile the models it generates, then this argument 
must be specified.</p>
</td></tr>
<tr><td><code id="Tuner_class_+3A_distribution_strategy">distribution_strategy</code></td>
<td>
<p>Optional. A TensorFlow 'tf$distribute' 
DistributionStrategy instance. If specified, each trial will run 
under this scope. For example, &lsquo;tf$distribute.MirroredStrategy([&rsquo;/gpu:0, /'gpu:1])' 
will run each trial on two GPUs. Currently only single-worker strategies are supported.</p>
</td></tr>
<tr><td><code id="Tuner_class_+3A_directory">directory</code></td>
<td>
<p>String. Path to the working directory (relative).</p>
</td></tr>
<tr><td><code id="Tuner_class_+3A_project_name">project_name</code></td>
<td>
<p>Name to use as prefix for files saved by this Tuner.</p>
</td></tr>
<tr><td><code id="Tuner_class_+3A_logger">logger</code></td>
<td>
<p>Optional. Instance of Logger class, used for 
streaming data to Cloud Service for monitoring.</p>
</td></tr>
<tr><td><code id="Tuner_class_+3A_tuner_id">tuner_id</code></td>
<td>
<p>tuner_id</p>
</td></tr>
<tr><td><code id="Tuner_class_+3A_overwrite">overwrite</code></td>
<td>
<p>Bool, default 'FALSE'. If 'FALSE', reloads an 
existing project of the same name if one is found. Otherwise, overwrites the project.</p>
</td></tr>
<tr><td><code id="Tuner_class_+3A_executions_per_trial">executions_per_trial</code></td>
<td>
<p>Integer, the number of executions 
(training a model from scratch, starting from a new initialization) to run per trial 
(model configuration). Model metrics may vary greatly depending on random initialization, 
hence it is often a good idea to run several executions per trial 
in order to evaluate the performance of a given set of hyperparameter values. 
**kwargs: Arguments for 'BaseTuner'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>May be subclassed to create new tuners.
</p>


<h3>Value</h3>

<p>a tuner object
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
