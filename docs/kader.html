<!DOCTYPE html><html lang="en"><head><title>Help for package kader</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {kader}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#kader'><p>Kernel Adjusted Density Estimation and Regression</p></a></li>
<li><a href='#adaptive_fnhat'><p>Specialized &ldquo;Workhorse&rdquo; Function for Kernel Adaptive Density Estimators</p></a></li>
<li><a href='#bias_AND_scaledvar'><p>Estimators of Bias and Scaled Variance</p></a></li>
<li><a href='#bias_ES2012'><p>Bias Estimator of Eichner &amp; Stute (2012)</p></a></li>
<li><a href='#compute_fnhat'><p>&ldquo;Unified&rdquo; Function for Kernel Adaptive Density Estimators</p></a></li>
<li><a href='#cuberoot'><p>Cube-root that retains its argument's sign</p></a></li>
<li><a href='#epanechnikov'><p>Epanechnikov kernel</p></a></li>
<li><a href='#fnhat_ES2013'><p>Robust Kernel Density Estimator of Eichner &amp; Stute (2013)</p></a></li>
<li><a href='#fnhat_SS2011'><p>(Non-robust) Kernel Density Estimator of Srihera &amp; Stute (2011)</p></a></li>
<li><a href='#J_admissible'><p>Admissible Rank Transformations of Eichner &amp; Stute (2013)</p></a></li>
<li><a href='#J1'><p>J1</p></a></li>
<li><a href='#J2'><p>J2</p></a></li>
<li><a href='#kade'><p>Kernel Adaptive Density Estimator</p></a></li>
<li><a href='#kare'><p>Kernel Adaptive Regression Estimator</p></a></li>
<li><a href='#kfn_vectorized'><p>Convolution of Kernel Function K with fn</p></a></li>
<li><a href='#minimize_MSEHat'><p>Minimization of Estimated MSE</p></a></li>
<li><a href='#mse_hat'><p>MSE Estimator</p></a></li>
<li><a href='#nadwat'><p>The Classical Nadaraya-Watson Regression Estimator</p></a></li>
<li><a href='#pc'><p>pc</p></a></li>
<li><a href='#qc'><p>qc</p></a></li>
<li><a href='#rectangular'><p>Rectangular kernel</p></a></li>
<li><a href='#var_ES2012'><p>Variance Estimator of Eichner &amp; Stute (2012)</p></a></li>
<li><a href='#weights_ES2012'><p>Weights <code class="reqn">W_{ni}</code> of Eichner &amp; Stute (2012)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Kernel Adaptive Density Estimation and Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>0.0.8</td>
</tr>
<tr>
<td>Date:</td>
<td>2017-10-04</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Gerrit Eichner &lt;gerrit.eichner@math.uni-giessen.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementation of various kernel adaptive methods in nonparametric curve
    estimation like density estimation as introduced in Stute and Srihera (2011)
    &lt;<a href="https://doi.org/10.1016%2Fj.spl.2011.01.013">doi:10.1016/j.spl.2011.01.013</a>&gt; and Eichner and Stute (2013)
    &lt;<a href="https://doi.org/10.1016%2Fj.jspi.2012.03.011">doi:10.1016/j.jspi.2012.03.011</a>&gt; for pointwise estimation, and like regression
    as described in Eichner and Stute (2012) &lt;<a href="https://doi.org/10.1080%2F10485252.2012.760737">doi:10.1080/10485252.2012.760737</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4.1)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://github.com/GerritEichner/kader">http://github.com/GerritEichner/kader</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="http://github.com/GerritEichner/kader/issues">http://github.com/GerritEichner/kader/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>Imports:</td>
<td>grDevices, graphics, stats</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-10-04 13:35:15 UTC; gcb7</td>
</tr>
<tr>
<td>Author:</td>
<td>Gerrit Eichner [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-10-04 17:18:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='kader'>Kernel Adjusted Density Estimation and Regression</h2><span id='topic+kader'></span><span id='topic+kader-package'></span>

<h3>Description</h3>

<p>Package of functions to compute kernel estimators for
</p>

<ul>
<li><p> nonparametric density estimation using a data-adjusted kernel or an
appropriate rank-transformation, and for
</p>
</li>
<li><p> nonparametric regression using a data-adjusted kernel.
</p>
</li></ul>



<h3>Details</h3>

<p>The functions are based on the theory laid out in the following papers:
</p>

<ul>
<li><p> Srihera, R., Stute, W. (2011): Kernel adjusted density
estimation. Statistics and Probability Letters 81, 571 - 579,
URL <a href="http://dx.doi.org/10.1016/j.spl.2011.01.013">http://dx.doi.org/10.1016/j.spl.2011.01.013</a>.
</p>
</li>
<li><p> Eichner, G., Stute, W. (2012): Kernel adjusted nonparametric
regression. Journal of Statistical Planning and Inference 142,
2537 - 2544, URL <a href="http://dx.doi.org/10.1016/j.jspi.2012.03.011">http://dx.doi.org/10.1016/j.jspi.2012.03.011</a>.
</p>
</li>
<li><p> Eichner, G., Stute, W. (2013): Rank Transformations in Kernel
Density Estimation. Journal of Nonparametric Statistics 25(2),
427 - 445, URL <a href="http://dx.doi.org/10.1080/10485252.2012.760737">http://dx.doi.org/10.1080/10485252.2012.760737</a>.
</p>
</li></ul>

<p>A very brief summary of the three papers above and sort of a vignette is
presented in Eichner, G. (2017): Kader - An R package for nonparametric
kernel adjusted density estimation and regression. In: Ferger, D., et al.
(eds.): From Statistics to Mathematical Finance, Festschrift in Honour of
Winfried Stute. Springer International Publishing. To appear in Jan. 2018.
DOI then(!) presumably: 10.1007/978-3-319-50986-0.
</p>

<hr>
<h2 id='adaptive_fnhat'>Specialized &ldquo;Workhorse&rdquo; Function for Kernel Adaptive Density Estimators</h2><span id='topic+adaptive_fnhat'></span>

<h3>Description</h3>

<p>Common specialized computational &ldquo;workhorse&rdquo; function to compute the kernel
adaptive density estimators both in eq. (1.6) of Srihera &amp; Stute (2011) and
in eq. (4) of Eichner &amp; Stute (2013) (together with several related
quantities) with a <code class="reqn">\sigma</code> that minimizes the estimated MSE using an
estimated <code class="reqn">\theta</code>. This function is &ldquo;specialized&rdquo; in that it expects
some pre-computed quantities (in addition to the point(s) at which the
density is to be estimated, the data, etc.). In particular, the estimator of
<code class="reqn">\theta</code> (which is typically the arithmetic mean of the data) is
expected to be already &ldquo;contained&rdquo; in those pre-computed quantities, which
increases the computational efficiency.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adaptive_fnhat(x, data, K, h, sigma, Ai, Bj, fnx, ticker = FALSE,
  plot = FALSE, parlist = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adaptive_fnhat_+3A_x">x</code></td>
<td>
<p>Numeric vector <code class="reqn">(x_1, \ldots, x_k)</code> of location(s) at which the
density estimate is to be computed.</p>
</td></tr>
<tr><td><code id="adaptive_fnhat_+3A_data">data</code></td>
<td>
<p>Numeric vector <code class="reqn">(X_1, \ldots, X_n)</code> of the data from which
the estimate is to be computed.</p>
</td></tr>
<tr><td><code id="adaptive_fnhat_+3A_k">K</code></td>
<td>
<p>Kernel function with vectorized in- &amp; output.</p>
</td></tr>
<tr><td><code id="adaptive_fnhat_+3A_h">h</code></td>
<td>
<p>Numeric scalar, where (usually) <code class="reqn">h = n^{-1/5}</code>.</p>
</td></tr>
<tr><td><code id="adaptive_fnhat_+3A_sigma">sigma</code></td>
<td>
<p>Numeric vector <code class="reqn">(\sigma_1, \ldots, \sigma_s)</code> with
<code class="reqn">s \ge 1</code>.</p>
</td></tr>
<tr><td><code id="adaptive_fnhat_+3A_ai">Ai</code></td>
<td>
<p>Numeric matrix expecting in its i-th row <code class="reqn">(x_i - X_1, \ldots,
x_i - X_n)/h</code>, where (usually) <code class="reqn">x_1, \ldots, x_k</code> with
<code class="reqn">k =</code> <code>length(x)</code> are the points at which the density is
to be estimated for the data <code class="reqn">X_1, \ldots, X_n</code> with
<code class="reqn">h = n^{-1/5}</code>.</p>
</td></tr>
<tr><td><code id="adaptive_fnhat_+3A_bj">Bj</code></td>
<td>
<p>Numeric vector expecting <code class="reqn">(-J(1/n), \ldots, -J(n/n))</code> in
case of the rank transformation method, but <code class="reqn">(\hat \theta -
X_1, \ldots, \hat \theta - X_n)</code> in case of the non-robust
Srihera-Stute-method.</p>
</td></tr>
<tr><td><code id="adaptive_fnhat_+3A_fnx">fnx</code></td>
<td>
<p>Numeric vector expecting <code class="reqn">(f_n(x_1), \ldots, f_n(x_k))</code> with
<code class="reqn">f_n(x_i)</code> the Parzen-Rosenblatt estimator at <code class="reqn">x_i</code>, i.e.,
<code class="reqn">f_n(x_i) =</code> <code>mean(K(Ai[i,]))/h</code> where here typically
<code>h</code> <code class="reqn">= n^{-1/5}</code>.</p>
</td></tr>
<tr><td><code id="adaptive_fnhat_+3A_ticker">ticker</code></td>
<td>
<p>Logical; determines if a 'ticker' documents the iteration
progress through <code>sigma</code>. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="adaptive_fnhat_+3A_plot">plot</code></td>
<td>
<p>Logical or character or numeric and indicates if graphical
output should be produced. Defaults to <code>FALSE</code> (i.e., no
graphical output is produced). If it is a character string or
a numeric value, graphical output will be written to numbered
pdf-files (one for each element of <code>x</code>, in the current
working directory) whose names start with the provided
&ldquo;value&rdquo; after converting it into a character string
followed by the index number of the pertaining
<code>x</code>-element. (Parts of the graphical output are
generated by <code><a href="#topic+minimize_MSEHat">minimize_MSEHat</a></code>.)</p>
</td></tr>
<tr><td><code id="adaptive_fnhat_+3A_parlist">parlist</code></td>
<td>
<p>A list of graphical parameters; affects only the pdf-files
(if any are created at all). Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="adaptive_fnhat_+3A_...">...</code></td>
<td>
<p>Possible further arguments passed to <code>minimize_MSEHat()</code>
(where they are currently ignored).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The computational procedure in this function can be highly iterative because
for each point in <code>x</code> (and hence for each row of matrix <code>Ai</code>) the
MSE estimator is computed as a function of <code class="reqn">\sigma</code> on a (usually fine)
<code class="reqn">\sigma</code>-grid provided through <code>sigma</code>. This happens by repeated
calls to <code><a href="#topic+bias_AND_scaledvar">bias_AND_scaledvar</a>()</code>. The minimization in <code class="reqn">\sigma</code>
is then performed by <code><a href="#topic+minimize_MSEHat">minimize_MSEHat</a>()</code> using both a discrete
grid-search and the numerical optimization routine implemented in base R's
<code>optimize()</code>. Finally, <code><a href="#topic+compute_fnhat">compute_fnhat</a>()</code> yields the actual
value of the density estimator for the adapted <code class="reqn">\sigma</code>, i.e., for the
MSE-estimator-minimizing <code class="reqn">\sigma</code>.
(If necessary the computation over the <code class="reqn">\sigma</code>-grid is repeated after
extending the range of the grid until the estimator functions for both bias
and variance are <em>not constant</em> across the <code class="reqn">\sigma</code>-grid.)
</p>


<h3>Value</h3>

<p>A list of as many lists as elements in <code>x</code>, each with components
<code>x</code>, <code>y</code>, <code>sigma.adap</code>, <code>msehat.min</code>,
<code>discr.min.smaller</code>, and <code>sig.range.adj</code> whose meanings are as
follows:
</p>

<table>
<tr>
 <td style="text-align: left;">
   <code>x</code> </td><td style="text-align: left;"> the n coordinates of the points where the density is
            estimated. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>y</code> </td><td style="text-align: left;"> the estimate of the density value <code class="reqn">f(x)</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>sigma.adap</code> </td><td style="text-align: left;"> Minimizer of MSE-estimator (from function
                     <code><a href="#topic+minimize_MSEHat">minimize_MSEHat</a></code>). </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>msehat.min</code> </td><td style="text-align: left;"> Minimum of MSE-estimator (from function
                     <code><a href="#topic+minimize_MSEHat">minimize_MSEHat</a></code>). </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>discr.min.smaller</code> </td><td style="text-align: left;"> TRUE iff the numerically found minimum was
                            smaller than the discrete one (from function
                            <code><a href="#topic+minimize_MSEHat">minimize_MSEHat</a></code>). </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>sig.range.adj</code> </td><td style="text-align: left;"> Number of adjustments of sigma-range. </td>
</tr>
<tr>
 <td style="text-align: left;">
   </td>
</tr>

</table>



<h3>References</h3>

<p>Srihera &amp; Stute (2011) and Eichner &amp; Stute (2013): see
<a href="#topic+kader">kader</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require(stats)

 # Kernel adaptive density estimators for simulated N(0,1)-data
 # computed on an x-grid using the rank transformation and the
 # non-robust method:
set.seed(2017);     n &lt;- 100;     Xdata &lt;- sort(rnorm(n))
x &lt;- seq(-4, 4, by = 0.5);     Sigma &lt;- seq(0.01, 10, length = 51)
h &lt;- n^(-1/5)

x.X_h &lt;- outer(x/h, Xdata/h, "-")
fnx &lt;- rowMeans(dnorm(x.X_h)) / h   # Parzen-Rosenblatt estim. at
                                    # x_j, j = 1, ..., length(x).
 # non-robust method:
theta.X &lt;- mean(Xdata) - Xdata
adaptive_fnhat(x = x, data = Xdata, K = dnorm, h = h, sigma = Sigma,
  Ai = x.X_h, Bj = theta.X, fnx = fnx, ticker = TRUE, plot = TRUE)

 # rank transformation-based method (requires sorted data):
negJ &lt;- -J_admissible(1:n / n)   # rank trafo
adaptive_fnhat(x = x, data = Xdata, K = dnorm, h = h, sigma = Sigma,
  Ai = x.X_h, Bj = negJ, fnx = fnx, ticker = TRUE, plot = TRUE)

## End(Not run)

</code></pre>

<hr>
<h2 id='bias_AND_scaledvar'>Estimators of Bias and Scaled Variance</h2><span id='topic+bias_AND_scaledvar'></span>

<h3>Description</h3>

<p>&ldquo;Workhorse&rdquo; function for vectorized (in <code class="reqn">\sigma</code>) computation of both
the bias estimator and the scaled variance estimator of eq. (2.3) in Srihera
&amp; Stute (2011), and for the analogous computation of the bias and scaled
variance estimator for the rank transformation method in the paragraph
after eq. (6) in Eichner &amp; Stute (2013).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bias_AND_scaledvar(sigma, Ai, Bj, h, K, fnx, ticker = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bias_AND_scaledvar_+3A_sigma">sigma</code></td>
<td>
<p>Numeric vector <code class="reqn">(\sigma_1, \ldots, \sigma_s)</code> with
<code class="reqn">s \ge 1</code>.</p>
</td></tr>
<tr><td><code id="bias_AND_scaledvar_+3A_ai">Ai</code></td>
<td>
<p>Numeric vector expecting <code class="reqn">(x_0 - X_1, \ldots, x_0 - X_n) / h</code>,
where (usually) <code class="reqn">x_0</code> is the point at which the density is to
be estimated for the data <code class="reqn">X_1, \ldots, X_n</code> with
<code class="reqn">h = n^{-1/5}</code>.</p>
</td></tr>
<tr><td><code id="bias_AND_scaledvar_+3A_bj">Bj</code></td>
<td>
<p>Numeric vector expecting <code class="reqn">(-J(1/n), \ldots, -J(n/n))</code> in case
of the rank transformation method, but <code class="reqn">(\hat{\theta} - X_1,
\ldots, \hat{\theta} - X_n)</code> in case of the non-robust
Srihera-Stute-method. (Note that this the same as argument
<code>Bj</code> of <code><a href="#topic+adaptive_fnhat">adaptive_fnhat</a></code>!)</p>
</td></tr>
<tr><td><code id="bias_AND_scaledvar_+3A_h">h</code></td>
<td>
<p>Numeric scalar, where (usually) <code class="reqn">h = n^{-1/5}</code>.</p>
</td></tr>
<tr><td><code id="bias_AND_scaledvar_+3A_k">K</code></td>
<td>
<p>Kernel function with vectorized in- &amp; output.</p>
</td></tr>
<tr><td><code id="bias_AND_scaledvar_+3A_fnx">fnx</code></td>
<td>
<p><code class="reqn">f_n(x_0) =</code> <code>mean(K(Ai))/h</code>, where here typically
<code class="reqn">h = n^{-1/5}</code>.</p>
</td></tr>
<tr><td><code id="bias_AND_scaledvar_+3A_ticker">ticker</code></td>
<td>
<p>Logical; determines if a 'ticker' documents the iteration
progress through <code>sigma</code>. Defaults to FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Pre-computed <code class="reqn">f_n(x_0)</code> is expected for efficiency reasons (and is
currently prepared in function <code>adaptive_fnhat</code>).
</p>


<h3>Value</h3>

<p>A list with components <code>BiasHat</code> and <code>VarHat.scaled</code>, both
numeric vectors of same length as <code>sigma</code>.
</p>


<h3>References</h3>

<p>Srihera &amp; Stute (2011) and Eichner &amp; Stute (2013): see
<a href="#topic+kader">kader</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(stats)

set.seed(2017);     n &lt;- 100;     Xdata &lt;- sort(rnorm(n))
x0 &lt;- 1;      Sigma &lt;- seq(0.01, 10, length = 21)

h &lt;- n^(-1/5)
Ai &lt;- (x0 - Xdata)/h
fnx0 &lt;- mean(dnorm(Ai)) / h   # Parzen-Rosenblatt estimator at x0.

 # non-robust method:
Bj &lt;- mean(Xdata) - Xdata
# # rank transformation-based method (requires sorted data):
# Bj &lt;- -J_admissible(1:n / n)   # rank trafo

kader:::bias_AND_scaledvar(sigma = Sigma, Ai = Ai, Bj = Bj, h = h,
  K = dnorm, fnx = fnx0, ticker = TRUE)

</code></pre>

<hr>
<h2 id='bias_ES2012'>Bias Estimator of Eichner &amp; Stute (2012)</h2><span id='topic+bias_ES2012'></span>

<h3>Description</h3>

<p>Bias estimator <code class="reqn">Bias_n(\sigma)</code>, vectorized in <code class="reqn">\sigma</code>, on p. 2540
of Eichner &amp; Stute (2012).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bias_ES2012(sigma, h, xXh, thetaXh, K, mmDiff)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bias_ES2012_+3A_sigma">sigma</code></td>
<td>
<p>Numeric vector <code class="reqn">(\sigma_1, \ldots, \sigma_s)</code> with
<code class="reqn">s \ge 1</code> with values of the scale parameter <code class="reqn">\sigma</code>.</p>
</td></tr>
<tr><td><code id="bias_ES2012_+3A_h">h</code></td>
<td>
<p>Numeric scalar for bandwidth <code class="reqn">h</code> (as &ldquo;contained&rdquo; in
<code>thetaXh</code> and <code>xXh</code>).</p>
</td></tr>
<tr><td><code id="bias_ES2012_+3A_xxh">xXh</code></td>
<td>
<p>Numeric vector expecting the pre-computed h-scaled differences
<code class="reqn">(x - X_1)/h</code>, ..., <code class="reqn">(x - X_n)/h</code> where <code class="reqn">x</code> is the
single (!) location for which the weights are to be computed,
the <code class="reqn">X_i</code>'s are the data values, and <code class="reqn">h</code> is the numeric
bandwidth scalar.</p>
</td></tr>
<tr><td><code id="bias_ES2012_+3A_thetaxh">thetaXh</code></td>
<td>
<p>Numeric vector expecting the pre-computed h-scaled differences
<code class="reqn">(\theta - X_1)/h</code>, ..., <code class="reqn">(\theta - X_n)/h</code> where
<code class="reqn">\theta</code> is the numeric scalar location parameter, and the
<code class="reqn">X_i</code>'s and <code class="reqn">h</code> are as in <code>xXh</code>.</p>
</td></tr>
<tr><td><code id="bias_ES2012_+3A_k">K</code></td>
<td>
<p>A kernel function (with vectorized in- &amp; output) to be used for the
estimator.</p>
</td></tr>
<tr><td><code id="bias_ES2012_+3A_mmdiff">mmDiff</code></td>
<td>
<p>Numeric vector expecting the pre-computed differences
<code class="reqn">m_n(X_1) - m_n(x), \ldots, m_n(X_n) - m_n(x)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The formula can also be found in eq. (15.21) of Eichner (2017).
Pre-computed <code class="reqn">(x - X_i)/h</code>, <code class="reqn">(\theta - X_i)/h</code>, and
<code class="reqn">m_n(X_i) - m_n(x)</code> are expected for efficiency reasons (and are
currently prepared in function <code><a href="#topic+kare">kare</a></code>).
</p>


<h3>Value</h3>

<p>A numeric vector of the length of <code>sigma</code>.
</p>


<h3>References</h3>

<p>Eichner &amp; Stute (2012) and Eichner (2017): see <code><a href="#topic+kader">kader</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kare">kare</a></code> which currently does the pre-computing.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(stats)

 # Regression function:
m &lt;- function(x, x1 = 0, x2 = 8, a = 0.01, b = 0) {
 a * (x - x1) * (x - x2)^3 + b
}
 # Note: For a few details on m() see examples in ?nadwat.

n &lt;- 100       # Sample size.
set.seed(42)   # To guarantee reproducibility.
X &lt;- runif(n, min = -3, max = 15)      # X_1, ..., X_n   # Design.
Y &lt;- m(X) + rnorm(length(X), sd = 5)   # Y_1, ..., Y_n   # Response.

h &lt;- n^(-1/5)
Sigma &lt;- seq(0.01, 10, length = 51)   # sigma-grid for minimization.
x0 &lt;- 5   # Location at which the estimator of m should be computed.

 # m_n(x_0) and m_n(X_i) for i = 1, ..., n:
mn &lt;- nadwat(x = c(x0, X), dataX = X, dataY = Y, K = dnorm, h = h)

 # Estimator of Bias_x0(sigma) on the sigma-grid:
(Bn &lt;- bias_ES2012(sigma = Sigma, h = h, xXh = (x0 - X) / h,
  thetaXh = (mean(X) - X) / h, K = dnorm, mmDiff = mn[-1] - mn[1]))

## Not run: 
 # Visualizing the estimator of Bias_n(sigma) at x on the sigma-grid:
plot(Sigma, Bn, type = "o", xlab = expression(sigma), ylab = "",
  main = bquote(widehat("Bias")[n](sigma)~~"at"~~x==.(x0)))

## End(Not run)

</code></pre>

<hr>
<h2 id='compute_fnhat'>&ldquo;Unified&rdquo; Function for Kernel Adaptive Density Estimators</h2><span id='topic+compute_fnhat'></span>

<h3>Description</h3>

<p>&ldquo;Unified&rdquo; function to compute the kernel density estimator both of Srihera
&amp; Stute (2011) and of Eichner &amp; Stute (2013).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_fnhat(x, data, K, h, Bj, sigma)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_fnhat_+3A_x">x</code></td>
<td>
<p>Numeric vector with the location(s) at which the density estimate
is to be computed.</p>
</td></tr>
<tr><td><code id="compute_fnhat_+3A_data">data</code></td>
<td>
<p>Numeric vector <code class="reqn">(X_1, \ldots, X_n)</code> of the data from which
the estimate is to be computed.</p>
</td></tr>
<tr><td><code id="compute_fnhat_+3A_k">K</code></td>
<td>
<p>A kernel function (with vectorized in- &amp; output) to be used for
the estimator.</p>
</td></tr>
<tr><td><code id="compute_fnhat_+3A_h">h</code></td>
<td>
<p>Numeric scalar for bandwidth <code class="reqn">h</code>.</p>
</td></tr>
<tr><td><code id="compute_fnhat_+3A_bj">Bj</code></td>
<td>
<p>Numeric vector expecting <code class="reqn">(-J(1/n), \ldots, -J(n/n))</code> as
produced in <code><a href="#topic+fnhat_SS2011">fnhat_SS2011</a></code> in case of the rank
transformation method (using an admissible rank transformation
as implemented by <code><a href="#topic+J_admissible">J_admissible</a></code>), but
<code class="reqn">(\hat \theta - X_1</code>, ..., <code class="reqn">\hat \theta - X_n)</code> as produced
in <code><a href="#topic+fnhat_ES2013">fnhat_ES2013</a></code> in case of the non-robust method.</p>
</td></tr>
<tr><td><code id="compute_fnhat_+3A_sigma">sigma</code></td>
<td>
<p>Numeric scalar for value of scale parameter <code class="reqn">\sigma</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Implementation of both eq. (1.6) in Srihera &amp; Stute (2011) for given and
fixed scalars <code class="reqn">\sigma</code> and <code class="reqn">\theta</code>, and eq. (4) in Eichner &amp; Stute
(2013) for a given and fixed scalar <code class="reqn">\sigma</code> and for a given and fixed
rank transformation (and, of course, for fixed and given location(s) in
<code class="reqn">x</code>, data <code class="reqn">(X_1, \ldots, X_n)</code>, a kernel function <code class="reqn">K</code> and a
bandwidth <code class="reqn">h</code>). The formulas that the computational version implemented
here is based upon are given in eq. (15.3) and eq. (15.9), respectively, of
Eichner (2017). This function rests on preparatory computations done in
<code><a href="#topic+fnhat_SS2011">fnhat_SS2011</a></code> or <code><a href="#topic+fnhat_ES2013">fnhat_ES2013</a></code>.
</p>


<h3>Value</h3>

<p>A numeric vector of the same length as <code>x</code> with the estimated
density values from eq. (1.6) of Srihera &amp; Stute (2011) or eq. (4)
of Eichner &amp; Stute (2013).
</p>


<h3>Note</h3>

<p>In case of the rank transformation method the data are expected to
be sorted in increasing order.
</p>


<h3>References</h3>

<p>Srihera &amp; Stute (2011), Eichner and Stute (2013), and Eichner
(2017): see <code><a href="#topic+kader">kader</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(stats)

 # The kernel density estimators for simulated N(0,1)-data and a single
 # sigma-value evaluated on a grid using the rank transformation and
 # the non-robust method:
set.seed(2017);     n &lt;- 100;     Xdata &lt;- rnorm(n)
xgrid &lt;- seq(-4, 4, by = 0.1)
negJ &lt;- -J_admissible(1:n / n)                 # The rank trafo requires
compute_fnhat(x = xgrid, data = sort(Xdata),   # sorted data!
  K = dnorm, h = n^(-1/5), Bj = negJ, sigma = 1)

theta.X &lt;- mean(Xdata) - Xdata    # non-robust method
compute_fnhat(x = xgrid, data = Xdata, K = dnorm, h = n^(-1/5),
  Bj = theta.X, sigma = 1)

</code></pre>

<hr>
<h2 id='cuberoot'>Cube-root that retains its argument's sign</h2><span id='topic+cuberoot'></span>

<h3>Description</h3>

<p>Computes <code class="reqn">(x_1^{1/3}, \ldots, x_n^{1/3})</code> with <code class="reqn">x_i^{1/3}</code> being
negative if <code class="reqn">x_i &lt; 0</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cuberoot(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cuberoot_+3A_x">x</code></td>
<td>
<p>Numeric vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of same length and mode as input.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>kader:::cuberoot(x = c(-27, -1, -0, 0, 1, 27))

curve(kader:::cuberoot(x), from = -27, to = 27)


</code></pre>

<hr>
<h2 id='epanechnikov'>Epanechnikov kernel</h2><span id='topic+epanechnikov'></span>

<h3>Description</h3>

<p>Vectorized evaluation of the Epanechnikov kernel.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>epanechnikov(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="epanechnikov_+3A_x">x</code></td>
<td>
<p>Numeric vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of the Epanechnikov kernel evaluated at the
values in <code>x</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>kader:::epanechnikov(x = c(-sqrt(6:5), -2:2, sqrt(5:6)))

curve(kader:::epanechnikov(x), from = -sqrt(6), to = sqrt(6))


</code></pre>

<hr>
<h2 id='fnhat_ES2013'>Robust Kernel Density Estimator of Eichner &amp; Stute (2013)</h2><span id='topic+fnhat_ES2013'></span>

<h3>Description</h3>

<p>Implementation of eq. (4) in Eichner &amp; Stute (2013) for a given and fixed
scalar <code class="reqn">\sigma</code>, for rank transformation function <code class="reqn">J</code> (and, of
course, for fixed and given location(s) in <code class="reqn">x</code>, data <code class="reqn">(X_1, \ldots,
X_n)</code>, a kernel function <code class="reqn">K</code>, and a bandwidth <code class="reqn">h</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fnhat_ES2013(x, data, K, h, ranktrafo, sigma)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fnhat_ES2013_+3A_x">x</code></td>
<td>
<p>Numeric vector with the location(s) at which the density
estimate is to be computed.</p>
</td></tr>
<tr><td><code id="fnhat_ES2013_+3A_data">data</code></td>
<td>
<p>Numeric vector <code class="reqn">(X_1, \ldots, X_n)</code> of the data from
which the estimate is to be computed. Missing values are not
allowed and entail an error.</p>
</td></tr>
<tr><td><code id="fnhat_ES2013_+3A_k">K</code></td>
<td>
<p>A kernel function to be used for the estimator.</p>
</td></tr>
<tr><td><code id="fnhat_ES2013_+3A_h">h</code></td>
<td>
<p>Numeric scalar for bandwidth <code class="reqn">h</code>.</p>
</td></tr>
<tr><td><code id="fnhat_ES2013_+3A_ranktrafo">ranktrafo</code></td>
<td>
<p>A function used for the rank transformation.</p>
</td></tr>
<tr><td><code id="fnhat_ES2013_+3A_sigma">sigma</code></td>
<td>
<p>Numeric scalar for value of scale parameter <code class="reqn">\sigma</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The formula upon which the computational version implemented here is based
is given in eq. (15.9) of Eichner (2017). This function does mainly only a
simple preparatory computation and then calls <code><a href="#topic+compute_fnhat">compute_fnhat</a></code>
which does the actual work.
</p>


<h3>Value</h3>

<p>An object with class &quot;density&quot; whose underlying structure is
a list containing the following components (as described in
<code><a href="stats.html#topic+density">density</a></code>), so that the <code>print</code> and
<code>plot</code> methods for <code>density</code>-objects are
immediately available):
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>x</code>  </td><td style="text-align: left;"> the n coordinates of the points where the density is
                estimated. </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>y</code>  </td><td style="text-align: left;"> the estimated density values from eq. (4) in Eichner &amp; Stute
                (2013). </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>bw</code> </td><td style="text-align: left;"> the bandwidth used. </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>  </td><td style="text-align: left;"> the sample size. (Recall: missing or infinite values are not
                allowed here.) </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>call</code>      </td><td style="text-align: left;"> the call which produced the result. </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>data.name</code> </td><td style="text-align: left;"> the deparsed name of the x argument. </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>has.na</code>    </td><td style="text-align: left;"> logical, for compatibility (always FALSE). </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
 Additionally: </td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>ranktrafo</code> </td><td style="text-align: left;"> as in Arguments. </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigma</code> </td><td style="text-align: left;"> as in Arguments. </td>
</tr>
<tr>
 <td style="text-align: left;">
 </td>
</tr>

</table>



<h3>References</h3>

<p>Eichner &amp; Stute (2013) and Eichner (2017): see <a href="#topic+kader">kader</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fnhat_SS2011">fnhat_SS2011</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(stats);   require(grDevices);   require(datasets)

 # Simulated N(0,1)-data and one sigma-value
set.seed(2016);     n &lt;- 100;     d &lt;- rnorm(n)
xgrid &lt;- seq(-4, 4, by = 0.1)
(fit &lt;- fnhat_ES2013(x = xgrid, data = d, K = dnorm, h = n^(-1/5),
  ranktrafo = J2, sigma = 1) )

plot(fit, ylim = range(0, dnorm(0), fit$y), col = "blue")
curve(dnorm, add = TRUE);   rug(d, col = "red")
legend("topleft", lty = 1, col = c("blue", "black", "red"),
  legend = expression(hat(f)[n], phi, "data"))


 # The same data, but several sigma-values
sigmas &lt;- seq(1, 4, length = 4)
(fit &lt;- lapply(sigmas, function(sig)
  fnhat_ES2013(x = xgrid, data = d, K = dnorm, h = n^(-1/5),
    ranktrafo = J2, sigma = sig)) )

ymat &lt;- sapply(fit, "[[", "y")
matplot(x = xgrid, y = ymat, type = "l", lty = 1, col = 2 + seq(sigmas),
  ylim = range(0, dnorm(0), ymat), main = "", xlab = "", ylab = "Density")
curve(dnorm, add = TRUE);   rug(d, col = "red")
legend("topleft", lty = 1, col = c("black", "red", NA), bty = "n",
  legend = expression(phi, "data", hat(f)[n]~"in other colors"))


 # Old-Faithful-eruptions-data and several sigma-values
d &lt;- faithful$eruptions;     n &lt;- length(d);     er &lt;- extendrange(d)
xgrid &lt;- seq(er[1], er[2], by = 0.1);    sigmas &lt;- seq(1, 4, length = 4)
(fit &lt;- lapply(sigmas, function(sig)
   fnhat_ES2013(x = xgrid, data = d, K = dnorm, h = n^(-1/5),
     ranktrafo = J2, sigma = sig)) )

ymat &lt;- sapply(fit, "[[", "y");     dfit &lt;- density(d, bw = "sj")
plot(dfit, ylim = range(0, dfit$y, ymat), main = "", xlab = "")
rug(d, col = "red")
matlines(x = xgrid, y = ymat, lty = 1, col = 2 + seq(sigmas))
legend("top", lty = 1, col = c("black", "red", NA), bty = "n",
  legend = expression("R's est.", "data", hat(f)[n]~"in other colors"))

</code></pre>

<hr>
<h2 id='fnhat_SS2011'>(Non-robust) Kernel Density Estimator of Srihera &amp; Stute (2011)</h2><span id='topic+fnhat_SS2011'></span>

<h3>Description</h3>

<p>Implementation of eq. (1.6) in Srihera &amp; Stute (2011) for given and fixed
scalars <code class="reqn">\sigma</code> and <code class="reqn">\theta</code> (and, of course, for fixed and given
location(s) in <code class="reqn">x</code>, data <code class="reqn">(X_1, \ldots, X_n)</code>, a kernel function
<code class="reqn">K</code> and a bandwidth <code class="reqn">h</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fnhat_SS2011(x, data, K, h, theta, sigma)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fnhat_SS2011_+3A_x">x</code></td>
<td>
<p>Numeric vector with the location(s) at which the density estimate
is to be computed.</p>
</td></tr>
<tr><td><code id="fnhat_SS2011_+3A_data">data</code></td>
<td>
<p>Numeric vector <code class="reqn">(X_1, \ldots, X_n)</code> of the data from which
the estimate is to be computed. Missing or infinite values are
not allowed and entail an error.</p>
</td></tr>
<tr><td><code id="fnhat_SS2011_+3A_k">K</code></td>
<td>
<p>A kernel function to be used for the estimator.</p>
</td></tr>
<tr><td><code id="fnhat_SS2011_+3A_h">h</code></td>
<td>
<p>Numeric scalar for bandwidth <code class="reqn">h</code>.</p>
</td></tr>
<tr><td><code id="fnhat_SS2011_+3A_theta">theta</code></td>
<td>
<p>Numeric scalar for value of location parameter <code class="reqn">\theta</code>.</p>
</td></tr>
<tr><td><code id="fnhat_SS2011_+3A_sigma">sigma</code></td>
<td>
<p>Numeric scalar for value of scale parameter <code class="reqn">\sigma</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The formula upon which the computational version implemented here is based
is given in eq. (15.3) of Eichner (2017). This function does mainly only a
simple preparatory computation and then calls <code><a href="#topic+compute_fnhat">compute_fnhat</a></code>
which does the actual work.
</p>


<h3>Value</h3>

<p>An object with class &quot;density&quot; whose underlying structure is
a list containing the following components (as described in
<code><a href="stats.html#topic+density">density</a></code>), so that the <code>print</code> and
<code>plot</code> methods for <code>density</code>-objects are
immediately available):
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>x</code>  </td><td style="text-align: left;"> the n coordinates of the points where the density is
                estimated. </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>y</code>  </td><td style="text-align: left;"> the estimated density values from eq. (1.6) in Srihera &amp;
                Stute (2011). </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>bw</code> </td><td style="text-align: left;"> the bandwidth used. </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>  </td><td style="text-align: left;"> the sample size. (Recall: missing or infinite values are
                not allowed here.) </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>call</code>      </td><td style="text-align: left;"> the call which produced the result. </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>data.name</code> </td><td style="text-align: left;"> the deparsed name of the x argument. </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>has.na</code>    </td><td style="text-align: left;"> logical, for compatibility (always FALSE). </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
 Additionally: </td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>theta</code> </td><td style="text-align: left;"> as in Arguments. </td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigma</code> </td><td style="text-align: left;"> as in Arguments. </td>
</tr>
<tr>
 <td style="text-align: left;">
 </td>
</tr>

</table>



<h3>References</h3>

<p>Srihera &amp; Stute (2011) and Eichner (2017): see <a href="#topic+kader">kader</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fnhat_ES2013">fnhat_ES2013</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(stats);   require(grDevices);    require(datasets)

 # Simulated N(0,1)-data and one sigma-value
set.seed(2017);     n &lt;- 100;     d &lt;- rnorm(n)
xgrid &lt;- seq(-4, 4, by = 0.1)
(fit &lt;- fnhat_SS2011(x = xgrid, data = d, K = dnorm, h = n^(-1/5),
  theta = mean(d), sigma = 1))

plot(fit, ylim = range(0, dnorm(0), fit$y), col = "blue")
curve(dnorm, add = TRUE);   rug(d, col = "red")
legend("topleft", lty = 1, col = c("blue", "black", "red"),
  legend = expression(tilde(f)[n], phi, "data")) 

 # The same data, but several sigma-values
sigmas &lt;- seq(1, 4, length = 4)
(fit &lt;- lapply(sigmas, function(sig)
  fnhat_SS2011(x = xgrid, data = d, K = dnorm, h = n^(-1/5),
    theta = mean(d), sigma = sig)))

ymat &lt;- sapply(fit, "[[", "y")
matplot(x = xgrid, y = ymat, type = "l", lty = 1, col = 3:6,
  ylim = range(0, dnorm(0), ymat), main = "", xlab = "", ylab = "Density")
curve(dnorm, add = TRUE);   rug(d, col = "red")
legend("topleft", lty = 1, col = c("black", "red", NA), bty = "n",
  legend = expression(phi, "data", tilde(f)[n]~"in other colors")) 

 # Old-Faithful-eruptions-data and several sigma-values
d &lt;- faithful$eruptions;     n &lt;- length(d);     er &lt;- extendrange(d)
xgrid &lt;- seq(er[1], er[2], by = 0.1);    sigmas &lt;- seq(1, 4, length = 4)
(fit &lt;- lapply(sigmas, function(sig)
   fnhat_SS2011(x = xgrid, data = d, K = dnorm, h = n^(-1/5),
     theta = mean(d), sigma = sig)))

ymat &lt;- sapply(fit, "[[", "y");     dfit &lt;- density(d, bw = "sj")
plot(dfit, ylim = range(0, dfit$y, ymat), main = "", xlab = "")
rug(d, col = "red")
matlines(x = xgrid, y = ymat, lty = 1, col = 3:6)
legend("top", lty = 1, col = c("black", "red", NA), bty = "n",
  legend = expression("R's est.", "data", tilde(f)[n]~"in other colors")) 
</code></pre>

<hr>
<h2 id='J_admissible'>Admissible Rank Transformations of Eichner &amp; Stute (2013)</h2><span id='topic+J_admissible'></span>

<h3>Description</h3>

<p>This is just a wrapper for the functions <code><a href="#topic+J1">J1</a></code>, <code><a href="#topic+J2">J2</a></code>,
and <code class="reqn">u -&gt; \sqrt 3 * (2u - 1)</code> which implement the admissible
transformations for the three cases for <code class="reqn">c</code>. For mathematical
details see eq. (15.16) and (15.17) in Eichner (2017) and/or Eichner &amp;
Stute (2013).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>J_admissible(u, cc = sqrt(5))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="J_admissible_+3A_u">u</code></td>
<td>
<p>Numeric vector.</p>
</td></tr>
<tr><td><code id="J_admissible_+3A_cc">cc</code></td>
<td>
<p>Numeric constant, defaults to <code class="reqn">\sqrt 5</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Basically, for <code>cc</code> in <code class="reqn">[\sqrt(5/3), \sqrt 5]</code>:
</p>
<p><code>J_admissible(u, cc)</code> = <code>J1(u, cc)</code> if <code>cc</code> <code class="reqn">&lt; \sqrt 3</code>,
</p>
<p><code>J_admissible(u, cc)</code> = <code>J2(u, cc)</code> if <code>cc</code> <code class="reqn">&gt; \sqrt 3</code>,
and
</p>
<p><code>J_admissible(u, cc)</code> = <code>sqrt(3) * (2*u - 1)</code> if <code>cc</code>
<code class="reqn">= \sqrt 3</code>.
</p>


<h3>Value</h3>

<p>Vector of same length and mode as <code>u</code>.
</p>


<h3>Note</h3>

<p>The admissible rank transformations require <code class="reqn">c</code> to
be in <code class="reqn">[\sqrt(5/3), \sqrt 5]</code>. If <code>cc</code> does
not satisfy this requirement a warning (only) is issued.
The default <code>cc = sqrt(5)</code>, i.e., <code class="reqn">c = \sqrt 5</code>,
yields the optimal rank transformation.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+J1">J1</a></code> and <code><a href="#topic+J2">J2</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
par(mfrow = c(1, 2), mar = c(3, 3, 0.5, 0.5), mgp = c(1.7, 0.7, 0))
example(J1)
example(J2)


</code></pre>

<hr>
<h2 id='J1'>J1</h2><span id='topic+J1'></span>

<h3>Description</h3>

<p>Eq. (15.16) in Eichner (2017) as a result of Cardano's formula.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>J1(u, cc = sqrt(5/3))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="J1_+3A_u">u</code></td>
<td>
<p>Numeric vector.</p>
</td></tr>
<tr><td><code id="J1_+3A_cc">cc</code></td>
<td>
<p>Numeric constant, defaults to <code class="reqn">\sqrt(5/3)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Using, for brevity's sake, <code class="reqn">J_{1a}(u, c) := -q_c(u)</code> and
<code class="reqn">J_{1b}(u, c) := J_{1a}(u, c)^2 + p_c^3</code>, the definition of
<code class="reqn">J_1</code> reads:
</p>
<p><code class="reqn">J_1(u, c) :=   [J_{1a}(u, c) + \sqrt(J_{1b}(u, c))]^{1/3}
                  + [J_{1a}(u, c) - \sqrt(J_{1b}(u, c))]^{1/3}</code>.
</p>
<p>For implementation details of <code class="reqn">q_c(u)</code> and <code class="reqn">p_c</code> see
<code><a href="#topic+qc">qc</a></code> and <code><a href="#topic+pc">pc</a></code>, respectively.
</p>
<p>For further mathematical details see Eichner (2017) and/or Eichner
&amp; Stute (2013).
</p>


<h3>Value</h3>

<p>Vector of same length and mode as <code>u</code>.
</p>


<h3>Note</h3>

<p>Eq. (15.16) in Eichner (2017), and hence <code class="reqn">J_1(u, c)</code>, requires
<code class="reqn">c</code> to be in <code class="reqn">[\sqrt(5/3), 3)</code>. If <code>cc</code> does
not satisfy this requirement a warning (only) is issued.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+J_admissible">J_admissible</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
u &lt;- seq(0, 1, by = 0.01)
c0 &lt;- expression(sqrt(5/3))
c1 &lt;- expression(sqrt(3) - 0.01)
cgrid &lt;- c(1.35, seq(1.4, 1.7, by = 0.1))
cvals &lt;- c(eval(c0), cgrid, eval(c1))

Y &lt;- sapply(cvals, function(cc, u) J1(u, cc = cc), u = u)
cols &lt;- rainbow(ncol(Y), end = 9/12)
matplot(u, Y, type = "l", lty = "solid", col = cols,
  ylab = expression(J[1](u, c)))
abline(h = 0)
legend("topleft", title = "c", legend = c(c0, cgrid, c1),
  lty = 1, col = cols, cex = 0.8)


</code></pre>

<hr>
<h2 id='J2'>J2</h2><span id='topic+J2'></span>

<h3>Description</h3>

<p>Eq. (20) in Eichner (2017) (based on &quot;Bronstein's formula for k = 3&quot;)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>J2(u, cc = sqrt(5))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="J2_+3A_u">u</code></td>
<td>
<p>Numeric vector.</p>
</td></tr>
<tr><td><code id="J2_+3A_cc">cc</code></td>
<td>
<p>Numeric constant, defaults to <code class="reqn">\sqrt 5</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code class="reqn">J_2(u, c) = 2\sqrt(-p_c) * sin(1/3 * arcsin(q_c(u) / (-p_c)^{3/2}))</code>
</p>
<p>For implementation details of <code class="reqn">q_c(u)</code> and <code class="reqn">p_c</code> see
<code><a href="#topic+qc">qc</a></code> and <code><a href="#topic+pc">pc</a></code>, respectively.
</p>
<p>For further mathematical details see Eichner (2017) and/or Eichner &amp;
Stute (2013).
</p>


<h3>Value</h3>

<p>Vector of same length and mode as <code>u</code>.
</p>


<h3>Note</h3>

<p>Eq. (20) in Eichner (2017), and hence <code class="reqn">J_2(u, c)</code>, requires
<code class="reqn">c</code> to be in <code class="reqn">(\sqrt 3, \sqrt 5]</code>. If <code>cc</code> does
not satisfy this requirement (only) a warning is issued.
</p>
<p>The default <code>cc = sqrt(5)</code> yields the optimal rank
transformation.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+J_admissible">J_admissible</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
u &lt;- seq(0, 1, by = 0.01)
c0 &lt;- expression(sqrt(3) + 0.01)
c1 &lt;- expression(sqrt(5))
cgrid &lt;- seq(1.85, 2.15, by = 0.1)
cvals &lt;- c(eval(c0), cgrid, eval(c1))

Y &lt;- sapply(cvals, function(cc, u) J2(u, cc = cc), u = u)
cols &lt;- rainbow(ncol(Y), end = 9/12)
matplot(u, Y, type = "l", lty = "solid", col = cols,
  ylab = expression(J[2](u, c)))
abline(h = 0)
legend("topleft", title = "c", legend = c(c0, cgrid, c1),
  lty = 1, col = cols, cex = 0.8)


</code></pre>

<hr>
<h2 id='kade'>Kernel Adaptive Density Estimator</h2><span id='topic+kade'></span>

<h3>Description</h3>

<p>Wrapper function which does some preparatory calculations and then calls
the actual &ldquo;workhorse&rdquo; functions which do the main computations for
kernel adaptive density estimation of Srihera &amp; Stute (2011) or Eichner
&amp; Stute (2013). Finally, it structures and returns the obtained results.
Summarizing information and technical details can be found in Eichner
(2017).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kade(x, data, kernel = c("gaussian", "epanechnikov", "rectangular"),
  method = c("both", "ranktrafo", "nonrobust"), Sigma = seq(0.01, 10, length
  = 51), h = NULL, theta = NULL, ranktrafo = J2, ticker = FALSE,
  plot = FALSE, parlist = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kade_+3A_x">x</code></td>
<td>
<p>Vector of location(s) at which the density estimate is
to be computed.</p>
</td></tr>
<tr><td><code id="kade_+3A_data">data</code></td>
<td>
<p>Vector <code class="reqn">(X_1, \ldots, X_n)</code> of the data from which the
estimate is to be computed. <code>NA</code>s or infinite values are
removed (and a warning is issued).</p>
</td></tr>
<tr><td><code id="kade_+3A_kernel">kernel</code></td>
<td>
<p>A character string naming the kernel to be used for the
adaptive estimator. This must partially match one of
&quot;gaussian&quot;, &quot;rectangular&quot; or &quot;epanechnikov&quot;, with default
&quot;gaussian&quot;, and may be abbreviated to a unique prefix.
(Currently, this kernel is also used for the initial,
non-adaptive Parzen-Rosenblatt estimator which enters
into the estimators of bias and variance as described in the
references.)</p>
</td></tr>
<tr><td><code id="kade_+3A_method">method</code></td>
<td>
<p>A character string naming the method to be used for the
adaptive estimator. This must partially match one of
&quot;both&quot;, &quot;ranktrafo&quot; or &quot;nonrobust&quot;, with default &quot;both&quot;,
and may be abbreviated to a unique prefix.</p>
</td></tr>
<tr><td><code id="kade_+3A_sigma">Sigma</code></td>
<td>
<p>Vector of value(s) of the scale parameter <code class="reqn">\sigma</code>.
If of length 1 no adaptation is performed. Otherwise
considered as the initial grid over which the optimization
of the adaptive method will be performed. Defaults to
<code>seq(0.01, 10, length = 51)</code>.</p>
</td></tr>
<tr><td><code id="kade_+3A_h">h</code></td>
<td>
<p>Numeric scalar for bandwidth <code class="reqn">h</code>. Defaults to NULL and is then
internally set to <code class="reqn">n^{-1/5}</code>.</p>
</td></tr>
<tr><td><code id="kade_+3A_theta">theta</code></td>
<td>
<p>Numeric scalar for value of location parameter <code class="reqn">\theta</code>.
Defaults to NULL and is then internally set to the arithmetic
mean of <code class="reqn">x_1, \ldots, x_n</code>.</p>
</td></tr>
<tr><td><code id="kade_+3A_ranktrafo">ranktrafo</code></td>
<td>
<p>Function used for the rank transformation. Defaults to
<code><a href="#topic+J2">J2</a></code> (with its default <code>cc = sqrt(5))</code>.</p>
</td></tr>
<tr><td><code id="kade_+3A_ticker">ticker</code></td>
<td>
<p>Logical; determines if a 'ticker' documents the iteration
progress through <code>Sigma</code>. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="kade_+3A_plot">plot</code></td>
<td>
<p>Logical or character or numeric and indicates if graphical
output should be produced. Defaults to FALSE (i.e., no
graphical output is produced) and is passed to
<code><a href="#topic+adaptive_fnhat">adaptive_fnhat</a>()</code> which does the actual work. For
details on how it is processed see there.</p>
</td></tr>
<tr><td><code id="kade_+3A_parlist">parlist</code></td>
<td>
<p>A list of graphical parameters that is passed to
<code><a href="#topic+adaptive_fnhat">adaptive_fnhat</a>()</code>; see there. Default:
<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="kade_+3A_...">...</code></td>
<td>
<p>Further arguments possibly passed down. Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>In the case of only one method a data frame whose components
have the following names and meanings:
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code>x</code> </td><td style="text-align: left;"> x_0. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>y</code> </td><td style="text-align: left;"> Estimate of f(x_0). </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>sigma.adap</code> </td><td style="text-align: left;"> The found minimizer of the MSE-estimator, i.e.,
                         the adaptive smoothing parameter value. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>msehat.min</code> </td><td style="text-align: left;"> The found minimum of the MSE-estimator. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>discr.min.smaller</code> </td><td style="text-align: left;"> TRUE iff the numerically found minimum
                                was smaller than the discrete one. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>sig.range.adj</code> </td><td style="text-align: left;"> Number of adjustments of sigma-range. </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>

<p>In the case of both methods a list of two data frames of the
just described structure.
</p>


<h3>References</h3>

<p>Srihera &amp; Stute (2011), Eichner &amp; Stute (2013), and Eichner
(2017): see <code><a href="#topic+kader">kader</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(stats)

 # Generating N(0,1)-data
set.seed(2017);     n &lt;- 80;     d &lt;- rnorm(n)

 # Estimating f(x0) for one sigma-value
x0 &lt;- 1
(fit &lt;- kade(x = x0, data = d, method = "nonrobust", Sigma = 1))

 # Estimating f(x0) for sigma-grid
x0 &lt;- 1
(fit &lt;- kade(x = x0, data = d, method = "nonrobust",
  Sigma = seq(0.01, 10, length = 10), ticker = TRUE))

## Not run: 
 # Estimating f(x0) for sigma-grid and Old-Faithful-eruptions-data
x0 &lt;- 2
(fit &lt;- kade(x = x0, data = faithful$eruptions, method = "nonrobust",
  Sigma = seq(0.01, 10, length = 51), ticker = TRUE, plot = TRUE))

## End(Not run)
</code></pre>

<hr>
<h2 id='kare'>Kernel Adaptive Regression Estimator</h2><span id='topic+kare'></span>

<h3>Description</h3>

<p>Wrapper function which does some preparatory calculations and then calls
the actual &ldquo;workhorse&rdquo; functions which do the main computations for
kernel adaptive regression estimation of Eichner &amp; Stute (2012). Finally,
it structures and returns the obtained results. Summarizing information
and technical details can be found in Eichner (2017).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kare(x.points, data, kernel = c("gaussian", "epanechnikov", "rectangular"),
  Sigma = seq(0.01, 10, length = 51), h = NULL, theta = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kare_+3A_x.points">x.points</code></td>
<td>
<p>Vector of location(s) at which the regression estimate is
to be computed.</p>
</td></tr>
<tr><td><code id="kare_+3A_data">data</code></td>
<td>
<p>Data frame or list with one component named <code>x</code> which
contains the vector of regressor values <code class="reqn">x_1, \ldots, x_n</code>
and one named <code>y</code> which holds the vector of pertaining
response values <code class="reqn">y_1, \ldots, y_n</code> (in the corresponding
order) of the data from which the estimate is to be computed
at the values given in <code>x.points</code>. Pairs <code class="reqn">(x_i, y_i)</code>
with <code>NA</code> or an infinite value in a least one of their
elements are removed (and a warning is issued).</p>
</td></tr>
<tr><td><code id="kare_+3A_kernel">kernel</code></td>
<td>
<p>A character string naming the kernel to be used for the
adaptive estimator. This must partially match one of
&quot;gaussian&quot;, &quot;rectangular&quot; or &quot;epanechnikov&quot;, with default
&quot;gaussian&quot;, and may be abbreviated to a unique prefix.
(Currently, this kernel is also used for the initial,
non-adaptive Nadaraya-Watson regression estimator which enters
into the estimators of bias and variance as described in the
references.)</p>
</td></tr>
<tr><td><code id="kare_+3A_sigma">Sigma</code></td>
<td>
<p>Vector of value(s) of the scale parameter <code class="reqn">\sigma</code>.
If of length 1 no adaptation is performed. Otherwise
considered as the grid over which the optimization of the
adaptive method will be performed. Defaults to
<code>seq(0.01, 10, length = 51)</code>.</p>
</td></tr>
<tr><td><code id="kare_+3A_h">h</code></td>
<td>
<p>Numeric scalar for bandwidth <code class="reqn">h</code>. Defaults to NULL and is then
internally set to <code class="reqn">n^{-1/5}</code>.</p>
</td></tr>
<tr><td><code id="kare_+3A_theta">theta</code></td>
<td>
<p>Numeric scalar for value of location parameter <code class="reqn">\theta</code>.
Defaults to NULL and is then internally set to the arithmetic
mean of <code class="reqn">x_1, \ldots, x_n</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>length(x.points)</code> = 1, a list of eight components with the
following names and meanings:
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code>x</code> </td><td style="text-align: left;"> Scalar <code class="reqn">x</code>-value in <code>x.points</code> at which the
                regression estimator was computed. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>y</code> </td><td style="text-align: left;"> Estimated scalar value of <code class="reqn">m(x)</code> at point in
                <code>x.points</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>sigma.adap</code> </td><td style="text-align: left;"> The found scalar minimizer of the MSE-estimator,
                         i.e., the adaptive smoothing parameter value. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>msehat.min</code> </td><td style="text-align: left;"> The found scalar minimum of the MSE-estimator. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>Sigma</code> </td><td style="text-align: left;"> Vector with the <code class="reqn">\sigma</code>-grid on which the
                    minimization process was performed. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>Bn</code> </td><td style="text-align: left;"> Vector with the estimator of bias on that
                 <code class="reqn">\sigma</code>-grid. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>Vn2</code> </td><td style="text-align: left;"> Ditto for the variance. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>MSE</code> </td><td style="text-align: left;"> Ditto for the MSE. </td>
</tr>
<tr>
 <td style="text-align: left;">
 </td>
</tr>

</table>

<p>If <code>length(x.points)</code> &gt; 1, a list with the same component names as
above, but then
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code>x</code> </td><td style="text-align: left;"> Vector <code>x.points</code> with x-values at which the regression
                estimator was computed. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>y</code> </td><td style="text-align: left;"> Vector of estimated values of <code class="reqn">m(x)</code> at the x-values in
                <code>x.points</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>sigma.adap</code> </td><td style="text-align: left;"> Vector of the found minimizers of the MSE-estimator,
                         i.e., the adaptive smoothing parameter values. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>msehat.min</code> </td><td style="text-align: left;"> Vector of the found minima of the MSE-estimator. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>Sigma</code> </td><td style="text-align: left;"> Vector with the <code class="reqn">\sigma</code>-grid on which the
                    minimization process was performed. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>Bn</code> </td><td style="text-align: left;"> (<code>length(Sigma)</code> by <code>length(x.points)</code>)-matrix
                 with the estimated values of the bias on the
                 <code class="reqn">\sigma</code>-grid in their columns (which correspond to the
                 x-values). </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>Vn2</code> </td><td style="text-align: left;"> Ditto for the variance. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>MSE</code> </td><td style="text-align: left;"> Ditto for the MSE. </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Eichner &amp; Stute (2012) and Eichner (2017): see <code><a href="#topic+kader">kader</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(stats)

 # Regression function:
m &lt;- function(x, x1 = 0, x2 = 8, a = 0.01, b = 0) {
 a * (x - x1) * (x - x2)^3 + b
}
 # Note: For a few details on m() see examples in ?nadwat.

x0 &lt;- 5   # The point x_0 at which the MSE-optimal kernel adjusted
 # nonparametric estimation of m should take place. (Recall: for m's
 # default values a minimum is at 2, a point of inflection at 4, and
 # a saddle point an 8; an "arbitrary" point would, e.g., be at 5.)

n &lt;- 100   # Sample size.
sdeps &lt;- 1   # Std. dev. of the \epsilon_i: \sqrt(Var(Y|X=x))
             # (here: constant in x).
design.ctr &lt;- x0 + 0.5   # "centre" and "scale" of the design, i.e.,
design.scl &lt;- 1  # in the normal scenario below, expected value and
                 # std. dev. of the distribution of the x_i's.

set.seed(42)   # To guarantee reproducibility.
x &lt;- rnorm(n, mean = design.ctr, sd = design.scl)   # x_1, ..., x_n
Y &lt;- m(x) + rnorm(length(x), sd = sdeps)            # Y_1, ..., Y_n
data &lt;- data.frame(x = x, y = Y)

 # Computing the kernel adaptive regression estimator values
 #**********************************************************
x.points &lt;- seq(-3.3 * design.scl, 3.3 * design.scl, length = 101) +
   design.ctr  # x-grid on which to draw and estimate the regr. fct. m.

Sigma &lt;- seq(0.01, 10, length = 51)   # \sigma-grid for minimization.
fit &lt;- kare(x.points = x0, data = data, Sigma = Sigma)

## Not run: 
 # Grafical display for the current data set
 #******************************************
 # Storing the curent settings of the graphics device
 # and changing its layout for the three plots to come:
op &lt;- par(mfrow = c(3, 1), mar = c(3, 3, 2, 0.1)+0.1,
   mgp = c(1.5, 0.5, 0), tcl = -0.3, cex.main = 2)

 # The scatter plot of the "raw data":
plot(y ~ x, data = data, xlim = range(data$x, x.points),
   ylim = range(data$y, fit$y, na.rm = TRUE),
   main = bquote(n == .(n)), xlab = "x", ylab = "y")

 # The "true" regression function m:
lines(x.points, m(x.points), lty = 2)

 # The MSE-optimal kernel adjusted nonparametric regression estimator
 # at x_0, i.e., the point (x_0, \hat m_n(x_0)):
points(fit$x, fit$y, col = "red", pch = 4, cex = 2)

 # The legend for the "true" regression function m and for the point
 # (x_0, \hat m_n(x_0)):
legend("topleft", lty = c(2, NA), pch = c(NA, 4),
 col = c("black", "red"), bty = "n", cex = 1.2,
 legend = c(as.expression(bquote(paste("m  with  ",
                                       sigma(paste(Y, "|", X == x))
                                 == .(sdeps)))),
            as.expression(bquote(paste(hat(m)[n](x[0]), "  at  ",
                                       x[0] == .(x0))))))

 # Visualizing the estimators of (Bias_n(sigma))^2 and
 # Var_n(sigma) at x0 on the sigma-grid:
with(fit,
  matplot(Sigma, cbind(Bn*Bn, Vn2), type = "l", lty = 1:2,
   col = c("black", "red"), xlab = expression(sigma), ylab = ""))

 # The legend for (Bias_n(sigma))^2 and Var_n(sigma):
legend("topleft", lty = 1:2, col = c("black", "red"), bty = "n",
  legend = c(expression(paste(widehat(plain(Bias))[n]^2, (sigma))),
             expression(widehat(plain(Var))[n](sigma))),
  cex = 1.2)

 # Visualizing the estimator of MSE_n(sigma) at x0 on the sigma-grid
 # together with the point indicating the detected minimum, and a legend:
plot(fit$Sigma, fit$MSE, type = "l",
 xlab = expression(sigma), ylab = "")
points(fit$sigma.adap, fit$msehat.min, pch = 4, col = "red", cex = 2)
legend("topleft", lty = c(1, NA), pch = c(NA, 4),
 col = c("black", "red"), bty = "n", cex = 1.2,
 legend = c(expression(widehat(plain(MSE))[n](sigma)),
            substitute(group("(", list(plain(Minimizer),
                                       plain(Minimum)), ")")
                         == group("(", list(x, y), ")"),
                       list(x = signif(fit$sigma.adap, 4),
                            y = signif(fit$msehat.min, 4)))))

par(op) # Restoring the previous settings of the graphics device.

## End(Not run)

</code></pre>

<hr>
<h2 id='kfn_vectorized'>Convolution of Kernel Function K with fn</h2><span id='topic+kfn_vectorized'></span>

<h3>Description</h3>

<p>Vectorized evaluation of the convolution of the kernel function K with fn.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kfn_vectorized(u, K, xixj, h, sig)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kfn_vectorized_+3A_u">u</code></td>
<td>
<p>Numeric vector.</p>
</td></tr>
<tr><td><code id="kfn_vectorized_+3A_k">K</code></td>
<td>
<p>Kernel function with vectorized in- &amp; output.</p>
</td></tr>
<tr><td><code id="kfn_vectorized_+3A_xixj">xixj</code></td>
<td>
<p>Numeric matrix.</p>
</td></tr>
<tr><td><code id="kfn_vectorized_+3A_h">h</code></td>
<td>
<p>Numeric scalar.</p>
</td></tr>
<tr><td><code id="kfn_vectorized_+3A_sig">sig</code></td>
<td>
<p>Numeric scalar.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Vectorized (in u) evaluation of - a more explicit representation of - the
integrand <code class="reqn">K(u) * f_n(\ldots - h^2/\sigma * u)</code> which is used in the
computation of the bias estimator before eq. (2.3) in Srihera &amp; Stute (2011).
Also used for the analogous computation of the respective bias estimator
in the paragraph after eq. (6) in Eichner &amp; Stute (2013).
</p>


<h3>Value</h3>

<p>A vector of <code class="reqn">(K * f_n)(u)</code> evaluated at the values in
<code>u</code>.
</p>


<h3>Note</h3>

<p>An alternative implementation could be
<code>K(u) * sapply(h/sig * u, function(v) mean(K(xixj - v))) / h</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(stats)

set.seed(2017);   n &lt;- 100;   Xdata &lt;- rnorm(n)
x0 &lt;- 1;          sig &lt;- 1;   h &lt;- n^(-1/5)

Ai &lt;- (x0 - Xdata)/h
Bj &lt;- mean(Xdata) - Xdata   # in case of non-robust method
AiBj &lt;- outer(Ai, Bj/sig, "+")

ugrid &lt;- seq(-10, 10, by = 1)
kader:::kfn_vectorized(u = ugrid, K = dnorm, xixj = AiBj, h = h, sig = sig)

</code></pre>

<hr>
<h2 id='minimize_MSEHat'>Minimization of Estimated MSE</h2><span id='topic+minimize_MSEHat'></span>

<h3>Description</h3>

<p>Minimization of the estimated MSE as function of <code class="reqn">\sigma</code> in four steps.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>minimize_MSEHat(VarHat.scaled, BiasHat.squared, sigma, Ai, Bj, h, K, fnx,
  ticker = FALSE, plot = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="minimize_MSEHat_+3A_varhat.scaled">VarHat.scaled</code></td>
<td>
<p>Vector of estimates of the scaled variance
(for values of <code class="reqn">\sigma</code> in <code>sigma</code>).</p>
</td></tr>
<tr><td><code id="minimize_MSEHat_+3A_biashat.squared">BiasHat.squared</code></td>
<td>
<p>Vector of estimates of the squared bias
(for values of <code class="reqn">\sigma</code> in <code>sigma</code>).</p>
</td></tr>
<tr><td><code id="minimize_MSEHat_+3A_sigma">sigma</code></td>
<td>
<p>Numeric vector <code class="reqn">(\sigma_1, \ldots, \sigma_s)</code> with
<code class="reqn">s \ge 1</code>.</p>
</td></tr>
<tr><td><code id="minimize_MSEHat_+3A_ai">Ai</code></td>
<td>
<p>Numeric vector expecting <code class="reqn">(x_0 - X_1, \ldots, x_0 - X_n) / h</code>,
where (usually) <code class="reqn">x_0</code> is the point at which the density is to
be estimated for the data <code class="reqn">X_1, \ldots, X_n</code> with
<code class="reqn">h = n^{-1/5}</code>.</p>
</td></tr>
<tr><td><code id="minimize_MSEHat_+3A_bj">Bj</code></td>
<td>
<p>Numeric vector expecting <code class="reqn">(-J(1/n), \ldots, -J(n/n))</code> in case
of the rank transformation method, but <code class="reqn">(\hat{\theta} - X_1,
\ldots, \hat{\theta} - X_n)</code> in case of the non-robust
Srihera-Stute-method. (Note that this the same as argument
<code>Bj</code> of <code><a href="#topic+adaptive_fnhat">adaptive_fnhat</a></code>!)</p>
</td></tr>
<tr><td><code id="minimize_MSEHat_+3A_h">h</code></td>
<td>
<p>Numeric scalar, where (usually) <code class="reqn">h = n^{-1/5}</code>.</p>
</td></tr>
<tr><td><code id="minimize_MSEHat_+3A_k">K</code></td>
<td>
<p>Kernel function with vectorized in- &amp; output.</p>
</td></tr>
<tr><td><code id="minimize_MSEHat_+3A_fnx">fnx</code></td>
<td>
<p><code class="reqn">f_n(x_0) =</code> <code>mean(K(Ai))/h</code>, where here typically
<code class="reqn">h = n^{-1/5}</code>.</p>
</td></tr>
<tr><td><code id="minimize_MSEHat_+3A_ticker">ticker</code></td>
<td>
<p>Logical; determines if a 'ticker' documents the iteration
progress through <code>sigma</code>. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="minimize_MSEHat_+3A_plot">plot</code></td>
<td>
<p>Should graphical output be produced? Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="minimize_MSEHat_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Step 1: determine first (= smallest) maximizer of <code>VarHat.scaled</code> (!)
on the grid in <code>sigma</code>. Step 2: determine first (= smallest) minimizer
of estimated MSE on the <code class="reqn">\sigma</code>-grid LEFT OF the first maximizer of
<code>VarHat.scaled</code>. Step 3: determine a range around the yet-found
(discrete) minimizer of estimated MSE within which a finer search for the
&ldquo;true&rdquo; minimum is continued using numerical minimization. Step 4: check if
the numerically determined minimum is indeed better, i.e., smaller than the
discrete one; if not keep the first.
</p>


<h3>Value</h3>

<p>A list with components <code>sigma.adap</code>, <code>msehat.min</code> and
<code>discr.min.smaller</code> whose meanings are as follows:
</p>

<table>
<tr>
 <td style="text-align: left;">
   <code>sigma.adap</code> </td><td style="text-align: left;"> Found minimizer of MSE estimator. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>msehat.min</code> </td><td style="text-align: left;"> Found minimum of MSE estimator. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>discr.min.smaller</code> </td><td style="text-align: left;"> TRUE iff the numerically found minimum was
                            smaller than the discrete one.
   </td>
</tr>

</table>



<h3>Examples</h3>

<pre><code class='language-R'>require(stats)

set.seed(2017);     n &lt;- 100;     Xdata &lt;- sort(rnorm(n))
x0 &lt;- 1;      Sigma &lt;- seq(0.01, 10, length = 11)

h &lt;- n^(-1/5)
Ai &lt;- (x0 - Xdata)/h
fnx0 &lt;- mean(dnorm(Ai)) / h   # Parzen-Rosenblatt estimator at x0.

 # For non-robust method:
Bj &lt;- mean(Xdata) - Xdata
#  # For rank transformation-based method (requires sorted data):
# Bj &lt;- -J_admissible(1:n / n)   # rank trafo

BV &lt;- kader:::bias_AND_scaledvar(sigma = Sigma, Ai = Ai, Bj = Bj,
  h = h, K = dnorm, fnx = fnx0, ticker = TRUE)

kader:::minimize_MSEHat(VarHat.scaled = BV$VarHat.scaled,
  BiasHat.squared = (BV$BiasHat)^2, sigma = Sigma, Ai = Ai, Bj = Bj,
  h = h, K = dnorm, fnx = fnx0, ticker = TRUE, plot = FALSE)

</code></pre>

<hr>
<h2 id='mse_hat'>MSE Estimator</h2><span id='topic+mse_hat'></span>

<h3>Description</h3>

<p>Vectorized (in <code class="reqn">\sigma</code>) function of the MSE estimator in eq. (2.3) of
Srihera &amp; Stute (2011), and of the analogous estimator in the paragraph after
eq. (6) in Eichner &amp; Stute (2013).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mse_hat(sigma, Ai, Bj, h, K, fnx, ticker = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mse_hat_+3A_sigma">sigma</code></td>
<td>
<p>Numeric vector <code class="reqn">(\sigma_1, \ldots, \sigma_s)</code> with
<code class="reqn">s \ge 1</code>.</p>
</td></tr>
<tr><td><code id="mse_hat_+3A_ai">Ai</code></td>
<td>
<p>Numeric vector expecting <code class="reqn">(x_0 - X_1, \ldots, x_0 - X_n) / h</code>,
where (usually) <code class="reqn">x_0</code> is the point at which the density is to
be estimated for the data <code class="reqn">X_1, \ldots, X_n</code> with
<code class="reqn">h = n^{-1/5}</code>.</p>
</td></tr>
<tr><td><code id="mse_hat_+3A_bj">Bj</code></td>
<td>
<p>Numeric vector expecting <code class="reqn">(-J(1/n), \ldots, -J(n/n))</code> in case
of the rank transformation method, but <code class="reqn">(\hat{\theta} - X_1,
\ldots, \hat{\theta} - X_n)</code> in case of the non-robust
Srihera-Stute-method. (Note that this the same as argument
<code>Bj</code> of <code><a href="#topic+adaptive_fnhat">adaptive_fnhat</a></code>!)</p>
</td></tr>
<tr><td><code id="mse_hat_+3A_h">h</code></td>
<td>
<p>Numeric scalar, where (usually) <code class="reqn">h = n^{-1/5}</code>.</p>
</td></tr>
<tr><td><code id="mse_hat_+3A_k">K</code></td>
<td>
<p>Kernel function with vectorized in- &amp; output.</p>
</td></tr>
<tr><td><code id="mse_hat_+3A_fnx">fnx</code></td>
<td>
<p><code class="reqn">f_n(x_0) =</code> <code>mean(K(Ai))/h</code>, where here typically
<code class="reqn">h = n^{-1/5}</code>.</p>
</td></tr>
<tr><td><code id="mse_hat_+3A_ticker">ticker</code></td>
<td>
<p>Logical; determines if a 'ticker' documents the iteration
progress through <code>sigma</code>. Defaults to FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with corresponding MSE values for the values in
<code>sigma</code>.
</p>


<h3>See Also</h3>

<p>For details see <code><a href="#topic+bias_AND_scaledvar">bias_AND_scaledvar</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(stats)

set.seed(2017);     n &lt;- 100;     Xdata &lt;- sort(rnorm(n))
x0 &lt;- 1;      Sigma &lt;- seq(0.01, 10, length = 11)

h &lt;- n^(-1/5)
Ai &lt;- (x0 - Xdata)/h
fnx0 &lt;- mean(dnorm(Ai)) / h   # Parzen-Rosenblatt estimator at x0.

 # non-robust method:
theta.X &lt;- mean(Xdata) - Xdata
kader:::mse_hat(sigma = Sigma, Ai = Ai, Bj = theta.X,
  h = h, K = dnorm, fnx = fnx0, ticker = TRUE)

 # rank transformation-based method (requires sorted data):
negJ &lt;- -J_admissible(1:n / n)   # rank trafo
kader:::mse_hat(sigma = Sigma, Ai = Ai, Bj = negJ,
  h = h, K = dnorm, fnx = fnx0, ticker = TRUE)

</code></pre>

<hr>
<h2 id='nadwat'>The Classical Nadaraya-Watson Regression Estimator</h2><span id='topic+nadwat'></span>

<h3>Description</h3>

<p>In its arguments <code>x</code> and <code>dataX</code> vectorized function to compute
the classical Nadaraya-Watson estimator (as it is <code class="reqn">m_n</code> in eq. (1.1)
in Eichner &amp; Stute (2012)).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nadwat(x, dataX, dataY, K, h)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nadwat_+3A_x">x</code></td>
<td>
<p>Numeric vector with the location(s) at which the Nadaraya-Watson
regression estimator is to be computed.</p>
</td></tr>
<tr><td><code id="nadwat_+3A_datax">dataX</code></td>
<td>
<p>Numeric vector <code class="reqn">(X_1, \ldots, X_n)</code> of the x-values from
which (together with the pertaining y-values) the estimate is
to be computed.</p>
</td></tr>
<tr><td><code id="nadwat_+3A_datay">dataY</code></td>
<td>
<p>Numeric vector <code class="reqn">(Y_1, \ldots, Y_n)</code> of the y-values from
which (together with the pertaining x-values) the estimate is
to be computed.</p>
</td></tr>
<tr><td><code id="nadwat_+3A_k">K</code></td>
<td>
<p>A kernel function (with vectorized in- &amp; output) to be used for the
estimator.</p>
</td></tr>
<tr><td><code id="nadwat_+3A_h">h</code></td>
<td>
<p>Numeric scalar for bandwidth <code class="reqn">h</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Implementation of the classical Nadaraya-Watson estimator as in eq. (1.1) in
Eichner &amp; Stute (2012) at given location(s) in <code>x</code> for data <code class="reqn">(X_1,
Y_1), \ldots, (X_n, Y_n)</code>, a kernel function <code class="reqn">K</code> and a bandwidth <code class="reqn">h</code>.
</p>


<h3>Value</h3>

<p>A numeric vector of the same length as <code>x</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(stats)

 # Regression function: a polynomial of degree 4 with one maximum (or
 # minimum), one point of inflection, and one saddle point.
 # Memo: for p(x) = a * (x - x1) * (x - x2)^3 + b the max. (or min.)
 # is at x = (3*x1 + x2)/4, the point of inflection is at x =
 # (x1 + x2)/2, and the saddle point at x = x2.
m &lt;- function(x, x1 = 0, x2 = 8, a = 0.01, b = 0) {
 a * (x - x1) * (x - x2)^3 + b
 }
 # Note: for m()'s default values a minimum is at x = 2, a point
 # of inflection at x = 4, and a saddle point at x = 8.

n &lt;- 100       # Sample size.
set.seed(42)   # To guarantee reproducibility.
X &lt;- runif(n, min = -3, max = 15)      # X_1, ..., X_n
Y &lt;- m(X) + rnorm(length(X), sd = 5)   # Y_1, ..., Y_n

x &lt;- seq(-3, 15, length = 51)   # Where the Nadaraya-Watson estimator
                                # mn of m shall be computed.
mn &lt;- nadwat(x = x, dataX = X, dataY = Y, K = dnorm, h = n^(-1/5))

plot(x = X, y = Y);   rug(X)
lines(x = x, y = mn, col = "blue")  # The estimator.
curve(m, add = TRUE, col = "red")   # The "truth".

</code></pre>

<hr>
<h2 id='pc'>pc</h2><span id='topic+pc'></span>

<h3>Description</h3>

<p>Coefficient <code class="reqn">p_c</code> of eq. (15.15) in Eichner (2017).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pc(cc)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pc_+3A_cc">cc</code></td>
<td>
<p>Numeric vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>p_c = 1/5 * (3c^2 - 5) / (3 - c^2) * c^2.
</p>
<p>For further details see p. 297 f. in Eichner (2017) and/or Eichner &amp; Stute
(2013).
</p>


<h3>Value</h3>

<p>Vector of same length and mode as <code>cc</code>.
</p>


<h3>Note</h3>

<p><code class="reqn">p_c</code> should be undefined for <code class="reqn">c = \sqrt 3</code>, but <code>pc</code>
is here implemented to return <code>Inf</code> in each element of its
return vector for which the corresponding element in <code>cc</code>
contains R's value of <code>sqrt(3)</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
c0 &lt;- expression(sqrt(5/3))
c1 &lt;- expression(sqrt(3) - 0.01)
cgrid &lt;- seq(1.325, 1.7, by = 0.025)
cvals &lt;- c(eval(c0), cgrid, eval(c1))

plot(cvals, pc(cvals), xaxt = "n", xlab = "c", ylab = expression(p[c]))
axis(1, at = cvals, labels = c(c0, cgrid, c1), las = 2)


</code></pre>

<hr>
<h2 id='qc'>qc</h2><span id='topic+qc'></span>

<h3>Description</h3>

<p>Coefficient <code class="reqn">q_c(u)</code> of eq. (15.15) in Eichner (2017).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qc(u, cc = sqrt(5/3))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qc_+3A_u">u</code></td>
<td>
<p>Numeric vector.</p>
</td></tr>
<tr><td><code id="qc_+3A_cc">cc</code></td>
<td>
<p>Numeric constant, defaults to <code class="reqn">\sqrt(5/3)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code class="reqn">q_c(u) = 2/5 * c^5 / (3 - c^2) * (1 - 2 * u)</code>
</p>
<p>For further details see p. 297 f. in Eichner (2017) and/or Eichner &amp; Stute
(2013).
</p>


<h3>Value</h3>

<p>Vector of same length and mode as <code>u</code>.
</p>


<h3>Note</h3>

<p><code class="reqn">q_c(u)</code> should be undefined for <code class="reqn">c = \sqrt 3</code>, but <code>qc</code>
is here implemented to return <code>Inf * (1 - 2*u)</code> if <code>cc</code>
contains R's value of <code>sqrt(3)</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
u &lt;- c(0, 1)   # seq(0, 1, by = 0.1)
c0 &lt;- expression(sqrt(5/3))
c1 &lt;- expression(sqrt(3) - 0.05)
cgrid &lt;- seq(1.4, 1.6, by = 0.1)
cvals &lt;- c(eval(c0), cgrid, eval(c1))

Y &lt;- sapply(cvals, function(cc, u) qc(u, cc = cc), u = u)
cols &lt;- rainbow(ncol(Y), end = 9/12)
matplot(u, Y, type = "l", lty = "solid", col = cols,
  ylab = expression(q[c](u)))
abline(h = 0, lty = "dashed")
legend("topright", title = "c", legend = c(c0, cgrid, c1),
  lty = 1, col = cols, cex = 0.8)


</code></pre>

<hr>
<h2 id='rectangular'>Rectangular kernel</h2><span id='topic+rectangular'></span>

<h3>Description</h3>

<p>Vectorized evaluation of the rectangular kernel.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rectangular(x, a = -0.5, b = 0.5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rectangular_+3A_x">x</code></td>
<td>
<p>Numeric vector.</p>
</td></tr>
<tr><td><code id="rectangular_+3A_a">a</code></td>
<td>
<p>Numeric scalar: lower bound of kernel support; defaults to -0.5.</p>
</td></tr>
<tr><td><code id="rectangular_+3A_b">b</code></td>
<td>
<p>Numeric scalar: upper bound of kernel support; defaults to 0.5.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of the rectangular kernel evaluated at the
values in <code>x</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>kader:::rectangular(x = seq(-1, 1, by = 0.1))

curve(kader:::rectangular(x), from = -1, to = 1)


</code></pre>

<hr>
<h2 id='var_ES2012'>Variance Estimator of Eichner &amp; Stute (2012)</h2><span id='topic+var_ES2012'></span>

<h3>Description</h3>

<p>Variance estimator <code class="reqn">Var_n(\sigma)</code>, vectorized in <code class="reqn">\sigma</code>, on p.
2540 of Eichner &amp; Stute (2012).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>var_ES2012(sigma, h, xXh, thetaXh, K, YmDiff2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="var_ES2012_+3A_sigma">sigma</code></td>
<td>
<p>Numeric vector <code class="reqn">(\sigma_1, \ldots, \sigma_s)</code> with
<code class="reqn">s \ge 1</code> with values of the scale parameter <code class="reqn">\sigma</code>.</p>
</td></tr>
<tr><td><code id="var_ES2012_+3A_h">h</code></td>
<td>
<p>Numeric scalar for bandwidth <code class="reqn">h</code> (as &ldquo;contained&rdquo; in
<code>thetaXh</code> and <code>xXh</code>).</p>
</td></tr>
<tr><td><code id="var_ES2012_+3A_xxh">xXh</code></td>
<td>
<p>Numeric vector expecting the pre-computed h-scaled differences
<code class="reqn">(x - X_1)/h</code>, ..., <code class="reqn">(x - X_n)/h</code> where <code class="reqn">x</code> is the
single (!) location for which the weights are to be computed,
the <code class="reqn">X_i</code>'s are the data values, and <code class="reqn">h</code> is the numeric
bandwidth scalar.</p>
</td></tr>
<tr><td><code id="var_ES2012_+3A_thetaxh">thetaXh</code></td>
<td>
<p>Numeric vector expecting the pre-computed h-scaled differences
<code class="reqn">(\theta - X_1)/h</code>, ..., <code class="reqn">(\theta - X_n)/h</code> where
<code class="reqn">\theta</code> is the numeric scalar location parameter, and the
<code class="reqn">X_i</code>'s and <code class="reqn">h</code> are as in <code>xXh</code>.</p>
</td></tr>
<tr><td><code id="var_ES2012_+3A_k">K</code></td>
<td>
<p>A kernel function (with vectorized in- &amp; output) to be used for the
estimator.</p>
</td></tr>
<tr><td><code id="var_ES2012_+3A_ymdiff2">YmDiff2</code></td>
<td>
<p>Numeric vector of the pre-computed squared differences
<code class="reqn">(Y_1 - m_n(x))^2</code>, ..., <code class="reqn">(Y_n - m_n(x))^2</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The formula can also be found in eq. (15.22) of Eichner (2017).
Pre-computed <code class="reqn">(x - X_i)/h</code>, <code class="reqn">(\theta - X_i)/h</code>, and
<code class="reqn">(Y_i - m_n(x))^2</code> are expected for efficiency reasons (and are
currently prepared in function <code><a href="#topic+kare">kare</a></code>).
</p>


<h3>Value</h3>

<p>A numeric vector of the length of <code>sigma</code>.
</p>


<h3>References</h3>

<p>Eichner &amp; Stute (2012) and Eichner (2017): see <code><a href="#topic+kader">kader</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kare">kare</a></code> which currently does the pre-computing.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(stats)

 # Regression function:
m &lt;- function(x, x1 = 0, x2 = 8, a = 0.01, b = 0) {
 a * (x - x1) * (x - x2)^3 + b
}
 # Note: For a few details on m() see examples in ?nadwat.

n &lt;- 100       # Sample size.
set.seed(42)   # To guarantee reproducibility.
X &lt;- runif(n, min = -3, max = 15)      # X_1, ..., X_n   # Design.
Y &lt;- m(X) + rnorm(length(X), sd = 5)   # Y_1, ..., Y_n   # Response.

h &lt;- n^(-1/5)
Sigma &lt;- seq(0.01, 10, length = 51)   # sigma-grid for minimization.
x0 &lt;- 5   # Location at which the estimator of m should be computed.

mnX  &lt;- nadwat(x = X, dataX = X, dataY = Y, K = dnorm, h = h) # m_n(X_i)
                                                     # for i = 1, ..., n.
 # Estimator of Var_x0(sigma) on the sigma-grid:
(Vn &lt;- var_ES2012(sigma = Sigma, h = h, xXh = (x0 - X) / h,
  thetaXh = (mean(X) - X) / h, K = dnorm, YmDiff2 = (Y - mnX)^2))

## Not run: 
 # Visualizing the estimator of Var_n(sigma) at x0 on the sigma-grid:
plot(Sigma, Vn, type = "o", xlab = expression(sigma), ylab = "",
  main = bquote(widehat("Var")[n](sigma)~~"at"~~x==.(x0)))

## End(Not run)

</code></pre>

<hr>
<h2 id='weights_ES2012'>Weights <code class="reqn">W_{ni}</code> of Eichner &amp; Stute (2012)</h2><span id='topic+weights_ES2012'></span>

<h3>Description</h3>

<p>Function, vectorized in its first argument <code>sigma</code>, to compute the
&ldquo;updated&rdquo; weights <code class="reqn">W_{ni}</code> in eq. (2.1) of Eichner &amp; Stute (2012) for
the kernel adjusted regression estimator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weights_ES2012(sigma, xXh, thetaXh, K, h)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="weights_ES2012_+3A_sigma">sigma</code></td>
<td>
<p>Numeric vector <code class="reqn">(\sigma_1, \ldots, \sigma_s)</code> with
<code class="reqn">s \ge 1</code> with values of the scale parameter <code class="reqn">\sigma</code>.</p>
</td></tr>
<tr><td><code id="weights_ES2012_+3A_xxh">xXh</code></td>
<td>
<p>Numeric vector expecting the pre-computed h-scaled differences
<code class="reqn">(x - X_1)/h</code>, ..., <code class="reqn">(x - X_n)/h</code> where <code class="reqn">x</code> is the
single (!) location for which the weights are to be computed,
the <code class="reqn">X_i</code>'s are the data values, and <code class="reqn">h</code> is the numeric
bandwidth scalar.</p>
</td></tr>
<tr><td><code id="weights_ES2012_+3A_thetaxh">thetaXh</code></td>
<td>
<p>Numeric vector expecting the pre-computed h-scaled differences
<code class="reqn">(\theta - X_1)/h</code>, ..., <code class="reqn">(\theta - X_n)/h</code> where
<code class="reqn">\theta</code> is the numeric scalar location parameter, and the
<code class="reqn">X_i</code>'s and <code class="reqn">h</code> are as in <code>xXh</code>.</p>
</td></tr>
<tr><td><code id="weights_ES2012_+3A_k">K</code></td>
<td>
<p>A kernel function (with vectorized in- &amp; output) to be used for the
estimator.</p>
</td></tr>
<tr><td><code id="weights_ES2012_+3A_h">h</code></td>
<td>
<p>Numeric scalar for bandwidth <code class="reqn">h</code> (as &ldquo;contained&rdquo; in
<code>thetaXh</code> and <code>xXh</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that it is not immediately obvious that <code class="reqn">W_{ni}</code> in eq. (2.1) of
Eichner &amp; Stute (2012) is a function of <code class="reqn">\sigma</code>. In fact, <code class="reqn">W_{ni}
= W_{ni}(x; h, \theta, \sigma)</code> as can be seen on p. 2542 ibid. The
computational version implemented here, however, is given in (15.19) of
Eichner (2017). Pre-computed <code class="reqn">(x - X_i)/h</code> and <code class="reqn">(\theta - X_i)/h</code>,
<code class="reqn">i = 1, \ldots, n</code> are expected for efficiency reasons (and are
currently prepared in function <code><a href="#topic+kare">kare</a></code>).
</p>


<h3>Value</h3>

<p>If <code>length(sigma)</code> &gt; 1 a numeric matrix of the dimension
<code>length(sigma)</code> by <code>length(xXh)</code> with elements
<code class="reqn">(W_{ni}(x; h, \theta, \sigma_r))</code> for <code class="reqn">r = 1, \ldots,</code>
<code>length(sigma)</code> and <code class="reqn">i = 1, \ldots,</code> <code>length(xXh)</code>;
otherwise a numeric vector of the same length as <code>xXh</code>.
</p>


<h3>References</h3>

<p>Eichner &amp; Stute (2012) and Eichner (2017): see <code><a href="#topic+kader">kader</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bias_ES2012">bias_ES2012</a></code> and <code><a href="#topic+var_ES2012">var_ES2012</a></code> which both
call this function, and <code><a href="#topic+kare">kare</a></code> which currently does
the pre-computing.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(stats)

 # Regression function:
m &lt;- function(x, x1 = 0, x2 = 8, a = 0.01, b = 0) {
 a * (x - x1) * (x - x2)^3 + b
}
 # Note: For a few details on m() see examples in ?nadwat.

n &lt;- 100       # Sample size.
set.seed(42)   # To guarantee reproducibility.
X &lt;- runif(n, min = -3, max = 15)      # X_1, ..., X_n   # Design.
Y &lt;- m(X) + rnorm(length(X), sd = 5)   # Y_1, ..., Y_n   # Response.

h &lt;- n^(-1/5)
Sigma &lt;- seq(0.01, 10, length = 51)   # sigma-grid for minimization.
x0 &lt;- 5   # Location at which the estimator of m should be computed.

 # Weights (W_{ni}(x; \sigma_r))_{1&lt;=r&lt;=length(Sigma), 1&lt;=i&lt;=n} for
 # Var_n(sigma) and Bias_n(sigma) each at x0 on the sigma-grid:
weights_ES2012(sigma = Sigma, xXh = (x0 - X) / h,
  thetaXh = (mean(X) - X) / h, K = dnorm, h = h)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
