<!DOCTYPE html><html><head><title>Help for package IMEC</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {IMEC}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#computeIMEC'><p>Computes the Ising model of explanatory coherence.</p></a></li>
<li><a href='#contradict'><p>contradict</p></a></li>
<li><a href='#explain'><p>explain</p></a></li>
<li><a href='#IMEC'><p>IMEC</p></a></li>
<li><a href='#initializeNetwork'><p>Initialize the explanatory network</p></a></li>
<li><a href='#plot.IMEC'><p>Plots the explanatory relations</p></a></li>
<li><a href='#summary.IMEC'><p>Summary of an IMEC object.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Ising Model of Explanatory Coherence</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.0</td>
</tr>
<tr>
<td>Description:</td>
<td>
    Theories are one of the most important tools of science. Although psychologists discussed problems of theory in their discipline for a long time, weak theories are still widespread in most subfields. 
    One possible reason for this is that psychologists lack the tools to systematically assess the quality of their theories. 
    Previously a computational model for formal theory evaluation based on the concept of explanatory coherence was developed (Thagard, 1989, &lt;<a href="https://doi.org/10.1017%2FS0140525X00057046">doi:10.1017/S0140525X00057046</a>&gt;). 
    However, there are possible improvements to this model and it is not available in software that psychologists typically use. 
    Therefore, a new implementation of explanatory coherence based on the Ising model is available in this R-package.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>IsingSampler, igraph, qgraph</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-11-25 16:13:47 UTC; Maximilian Maier</td>
</tr>
<tr>
<td>Author:</td>
<td>Maximilian Maier [aut, cre],
  Noah van Dongen [ths],
  Denny Borsboom [ths]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Maximilian Maier &lt;maximilianmaier0401@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-11-27 10:10:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='computeIMEC'>Computes the Ising model of explanatory coherence.</h2><span id='topic+computeIMEC'></span>

<h3>Description</h3>

<p>Computes IMEC based on previously specified explanatory relations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>computeIMEC(
  matrix,
  evidence,
  phenomena,
  theory1,
  theory2 = character(),
  analytic = TRUE,
  analogy = numeric()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="computeIMEC_+3A_matrix">matrix</code></td>
<td>
<p>matrix of explanatory relations.</p>
</td></tr>
<tr><td><code id="computeIMEC_+3A_evidence">evidence</code></td>
<td>
<p>vector of evidence for phenomena.</p>
</td></tr>
<tr><td><code id="computeIMEC_+3A_phenomena">phenomena</code></td>
<td>
<p>vector of phenomena should be the same length as evidence.</p>
</td></tr>
<tr><td><code id="computeIMEC_+3A_theory1">theory1</code></td>
<td>
<p>vector of propositions in theory1.</p>
</td></tr>
<tr><td><code id="computeIMEC_+3A_theory2">theory2</code></td>
<td>
<p>vector of propositions in theory2.</p>
</td></tr>
<tr><td><code id="computeIMEC_+3A_analytic">analytic</code></td>
<td>
<p>whether the result should be calculated analytically or (for large networks) estimated using
Metropolis-Hastings algorithm enhanced with Coupling from the past.</p>
</td></tr>
<tr><td><code id="computeIMEC_+3A_analogy">analogy</code></td>
<td>
<p>this argument is only for purposes of adding analogy in the future and should currently not be used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns an IMEC object which contains the explanatory coherence of the propositions, the explanatory relations,
the evidence, and the phenomena
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simple example comparing two hypotheses one of them with more explanatory breadth##
T1 &lt;- c("H1", "H2")
Phenomena &lt;- c("E1", "E2")
Thresholds &lt;- c(2,2)
explanations &lt;- initializeNetwork(Phenomena, T1)
explanations &lt;- explain("H1", "E1", explanations)
explanations &lt;- explain("H1", "E2", explanations)
explanations &lt;- explain("H2", "E2", explanations)
explanations &lt;- contradict("H1", "H2", explanations)
coherence &lt;- computeIMEC(explanations, Thresholds, Phenomena, T1)
summary(coherence)
plot(coherence)
</code></pre>

<hr>
<h2 id='contradict'>contradict</h2><span id='topic+contradict'></span>

<h3>Description</h3>

<p>Sets a contradictory relation between a set of propositions and a phenomenon.
If more than one proposition is used the edge weight will be reduced accordingly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>contradict(Explanation, Explanandum, matrix, weight = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="contradict_+3A_explanation">Explanation</code></td>
<td>
<p>Vector of explanations that explain the explanadum</p>
</td></tr>
<tr><td><code id="contradict_+3A_explanandum">Explanandum</code></td>
<td>
<p>A proposition or phenomenon that is explained</p>
</td></tr>
<tr><td><code id="contradict_+3A_matrix">matrix</code></td>
<td>
<p>Matrix of explanatory relations that is modified</p>
</td></tr>
<tr><td><code id="contradict_+3A_weight">weight</code></td>
<td>
<p>Strength of connection (i.e., strength of contradiction)
</p>
<p>#'@return returns the explanatory matrix with the edge weights modified according
to the specified contradiction</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># simple example comparing two hypotheses one of them with more explanatory breadth##
T1 &lt;- c("H1", "H2")
Phenomena &lt;- c("E1", "E2")
Thresholds &lt;- c(2,2)
explanations &lt;- initializeNetwork(Phenomena, T1)
explanations &lt;- explain("H1", "E1", explanations)
explanations &lt;- explain("H1", "E2", explanations)
explanations &lt;- explain("H2", "E2", explanations)
explanations &lt;- contradict("H1", "H2", explanations)
coherence &lt;- computeIMEC(explanations, Thresholds, Phenomena, T1)
summary(coherence)
plot(coherence)
</code></pre>

<hr>
<h2 id='explain'>explain</h2><span id='topic+explain'></span>

<h3>Description</h3>

<p>Sets an explanatory relation between a set of propositions and a phenomenon.
If more than one proposition is used the edge weight will be reduced accordingly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>explain(Explanation, Explanandum, matrix, weight = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="explain_+3A_explanation">Explanation</code></td>
<td>
<p>Vector of Explanations that explain the Explanadum</p>
</td></tr>
<tr><td><code id="explain_+3A_explanandum">Explanandum</code></td>
<td>
<p>A proposition or phenomenon that is explained</p>
</td></tr>
<tr><td><code id="explain_+3A_matrix">matrix</code></td>
<td>
<p>Matrix of Explanatory relations that is modified</p>
</td></tr>
<tr><td><code id="explain_+3A_weight">weight</code></td>
<td>
<p>Strength of connection (i.e., quality of explanation)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the explanatory matrix with the edge weights modified according
to the specified explanation
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simple example comparing two hypotheses one of them with more explanatory breadth##
T1 &lt;- c("H1", "H2")
Phenomena &lt;- c("E1", "E2")
Thresholds &lt;- c(2,2)
explanations &lt;- initializeNetwork(Phenomena, T1)
explanations &lt;- explain("H1", "E1", explanations)
explanations &lt;- explain("H1", "E2", explanations)
explanations &lt;- explain("H2", "E2", explanations)
explanations &lt;- contradict("H1", "H2", explanations)
coherence &lt;- computeIMEC(explanations, Thresholds, Phenomena, T1)
summary(coherence)
plot(coherence)
</code></pre>

<hr>
<h2 id='IMEC'>IMEC</h2><span id='topic+IMEC'></span>

<h3>Description</h3>

<p>This package computes the Ising Model of Explanatory Coherence for theory comparison and
theory appraisal.
</p>


<h3>Construct Explanary Network</h3>

<p><em>intializeNetwork</em> constructs an initial empty explanatoy network
<em>Explain</em> and <em>Contradict</em> specify explanatory relations.
</p>


<h3>Calculate IMEC</h3>

<p><em>computeIMEC</em> computes the Ising model of explanatory coherence and returns
an object of class IMEC. Use summary to summarize the result and plot to plot the
explanatory relations.
</p>

<hr>
<h2 id='initializeNetwork'>Initialize the explanatory network</h2><span id='topic+initializeNetwork'></span>

<h3>Description</h3>

<p>This function initializes the network in which explanatory relations can be stored later.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initializeNetwork(phenomena, theory1, theory2 = character())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="initializeNetwork_+3A_phenomena">phenomena</code></td>
<td>
<p>Vector of phenomena that are explained</p>
</td></tr>
<tr><td><code id="initializeNetwork_+3A_theory1">theory1</code></td>
<td>
<p>Vector of propositions included in theory 1</p>
</td></tr>
<tr><td><code id="initializeNetwork_+3A_theory2">theory2</code></td>
<td>
<p>Vector of propositions included in theory 2 (only set manually if theory comparison is intended)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An empty edge matrix (all edges 0)
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simple example comparing two hypotheses one of them with more explanatory breadth##
T1 &lt;- c("H1", "H2")
Phenomena &lt;- c("E1", "E2")
Thresholds &lt;- c(2,2)
explanations &lt;- initializeNetwork(Phenomena, T1)
explanations &lt;- explain("H1", "E1", explanations)
explanations &lt;- explain("H1", "E2", explanations)
explanations &lt;- explain("H2", "E2", explanations)
explanations &lt;- contradict("H1", "H2", explanations)
coherence &lt;- computeIMEC(explanations, Thresholds, Phenomena, T1)
summary(coherence)
plot(coherence)

</code></pre>

<hr>
<h2 id='plot.IMEC'>Plots the explanatory relations</h2><span id='topic+plot.IMEC'></span>

<h3>Description</h3>

<p>Plot the explanatory relations between data and phenomena. A window will open where you
can drag the nodes in the intended position. Then press enter to plot the network.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'IMEC'
plot(x, nodesize = 10, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.IMEC_+3A_x">x</code></td>
<td>
<p>Object of the class IMEC as returned by computeIMEC</p>
</td></tr>
<tr><td><code id="plot.IMEC_+3A_nodesize">nodesize</code></td>
<td>
<p>size of vertices in the plotted network</p>
</td></tr>
<tr><td><code id="plot.IMEC_+3A_...">...</code></td>
<td>
<p>other parameters passed on to S3 method.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># simple example comparing two hypotheses one of them with more explanatory breadth##
T1 &lt;- c("H1", "H2")
Phenomena &lt;- c("E1", "E2")
Thresholds &lt;- c(2,2)
explanations &lt;- initializeNetwork(Phenomena, T1)
explanations &lt;- explain("H1", "E1", explanations)
explanations &lt;- explain("H1", "E2", explanations)
explanations &lt;- explain("H2", "E2", explanations)
explanations &lt;- contradict("H1", "H2", explanations)
coherence &lt;- computeIMEC(explanations, Thresholds, Phenomena, T1)
summary(coherence)
plot(coherence)
</code></pre>

<hr>
<h2 id='summary.IMEC'>Summary of an IMEC object.</h2><span id='topic+summary.IMEC'></span>

<h3>Description</h3>

<p>Summary of an IMEC object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'IMEC'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.IMEC_+3A_object">object</code></td>
<td>
<p>IMEC object.</p>
</td></tr>
<tr><td><code id="summary.IMEC_+3A_...">...</code></td>
<td>
<p>other parameters passed on from S3 method.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># simple example comparing two hypotheses one of them with more explanatory breadth##
T1 &lt;- c("H1", "H2")
Phenomena &lt;- c("E1", "E2")
Thresholds &lt;- c(2,2)
explanations &lt;- initializeNetwork(Phenomena, T1)
explanations &lt;- explain("H1", "E1", explanations)
explanations &lt;- explain("H1", "E2", explanations)
explanations &lt;- explain("H2", "E2", explanations)
explanations &lt;- contradict("H1", "H2", explanations)
coherence &lt;- computeIMEC(explanations, Thresholds, Phenomena, T1)
summary(coherence)
plot(coherence)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
