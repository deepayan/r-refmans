<!DOCTYPE html><html lang="en"><head><title>Help for package pnd</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {pnd}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#checkCores'><p>Number of core checks and changes</p></a></li>
<li><a href='#checkDimensions'><p>Determine function dimensionality and vectorisation</p></a></li>
<li><a href='#dupRowInds'><p>Repeated indices of the first unique value</p></a></li>
<li><a href='#fdCoef'><p>Finite-difference coefficients for arbitrary grids</p></a></li>
<li><a href='#GenD'><p>Numerical derivative matrices with parallel capabilities</p></a></li>
<li><a href='#generateGrid'><p>Create a grid of points for a gradient / Jacobian</p></a></li>
<li><a href='#generateGrid2'><p>Generate grid points for Hessians</p></a></li>
<li><a href='#Grad'><p>Gradient computation with parallel capabilities</p></a></li>
<li><a href='#gradstep'><p>Automatic step selection for numerical derivatives</p></a></li>
<li><a href='#Hessian'><p>Numerical Hessians</p></a></li>
<li><a href='#Jacobian'><p>Jacobian matrix computation with parallel capabilities</p>
s
Computes the numerical Jacobian for vector-valued functions. Its columns are
partial derivatives of the function with respect to the input elements.
This function supports both two-sided (central, symmetric) and
one-sided (forward or backward) derivatives. It can utilise parallel processing
to accelerate computation of gradients for slow functions or
to attain higher accuracy faster. Currently, only Mac and Linux are supported
<code>parallel::mclapply()</code>. Windows support with <code>parallel::parLapply()</code>
is under development.</a></li>
<li><a href='#plotTE'><p>Estimated total error plot as in Mathur (2012)</p></a></li>
<li><a href='#runParallel'><p>Run a function in parallel over a list (internal use only)</p></a></li>
<li><a href='#solveVandermonde'><p>Numerically stable non-confluent Vandermonde system solver</p></a></li>
<li><a href='#step.CR'><p>Curtis&ndash;Reid automatic step selection</p></a></li>
<li><a href='#step.DV'><p>Dumontet&ndash;Vignes automatic step selection</p></a></li>
<li><a href='#step.M'><p>Mathur's AutoDX-like automatic step selection</p></a></li>
<li><a href='#step.plugin'><p>Plug-in step selection</p></a></li>
<li><a href='#step.SW'><p>Stepleman&ndash;Winarsky automatic step selection</p></a></li>
<li><a href='#stepx'><p>Default step size at given points</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Parallel Numerical Derivatives, Gradients, Jacobians, and
Hessians of Arbitrary Accuracy Order</td>
</tr>
<tr>
<td>Version:</td>
<td>0.0.9</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Andreï Victorovitch Kostyrka &lt;andrei.kostyrka@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Numerical derivatives through finite-difference approximations
    can be calculated using the 'pnd' package with parallel capabilities and
    optimal step-size selection to improve accuracy. These functions facilitate
    efficient computation of derivatives, gradients, Jacobians, and Hessians,
    allowing for more evaluations to reduce the mathematical and machine errors.
    Designed for compatibility with the 'numDeriv' package,
    which has not received updates in several years, it introduces advanced features
    such as computing derivatives of arbitrary order, improving
    the accuracy of Hessian approximations by avoiding repeated differencing,
    and parallelising slow functions on Windows, Mac, and Linux.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://joinup.ec.europa.eu/software/page/eupl">EUPL version 1.1</a> | <a href="https://joinup.ec.europa.eu/software/page/eupl">EUPL version 1.2</a> [expanded from: EUPL]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/Fifis/pnd">https://github.com/Fifis/pnd</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/Fifis/pnd/issues">https://github.com/Fifis/pnd/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>parallel, Rdpack</td>
</tr>
<tr>
<td>Suggests:</td>
<td>numDeriv, knitr, rmarkdown, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-11 12:47:43 UTC; avk</td>
</tr>
<tr>
<td>Author:</td>
<td>Andreï Victorovitch Kostyrka [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-11 23:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='checkCores'>Number of core checks and changes</h2><span id='topic+checkCores'></span>

<h3>Description</h3>

<p>Number of core checks and changes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkCores(cores = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="checkCores_+3A_cores">cores</code></td>
<td>
<p>Integer specifying the number of CPU cores used for parallel computation.
Recommended to be set to the number of physical cores on the machine minus one.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An integer with the number of cores.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>checkCores()
checkCores(2)
suppressWarnings(checkCores(1000))
</code></pre>

<hr>
<h2 id='checkDimensions'>Determine function dimensionality and vectorisation</h2><span id='topic+checkDimensions'></span>

<h3>Description</h3>

<p>Determine function dimensionality and vectorisation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkDimensions(
  FUN,
  x,
  f0 = NULL,
  func = NULL,
  elementwise = NA,
  vectorised = NA,
  multivalued = NA,
  deriv.order = 1,
  acc.order = 2,
  side = 0,
  h = NULL,
  report = 1L,
  zero.tol = sqrt(.Machine$double.eps),
  cores = 1,
  preschedule = TRUE,
  cl = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="checkDimensions_+3A_fun">FUN</code></td>
<td>
<p>A function returning a numeric scalar or a vector whose derivatives are to be
computed. If the function returns a vector, the output will be a Jacobian.</p>
</td></tr>
<tr><td><code id="checkDimensions_+3A_x">x</code></td>
<td>
<p>Numeric vector or scalar: the point(s) at which the derivative is estimated.
<code>FUN(x)</code> must be finite.</p>
</td></tr>
<tr><td><code id="checkDimensions_+3A_f0">f0</code></td>
<td>
<p>Optional numeric: if provided, used to determine the vectorisation type
to save time. If FUN(x) must be evaluated (e.g. second derivatives), saves one evaluation.</p>
</td></tr>
<tr><td><code id="checkDimensions_+3A_func">func</code></td>
<td>
<p>For compatibility with <code>numDeriv::grad()</code> only. If instead of
<code>FUN</code>, <code>func</code> is used, it will be reassigned to <code>FUN</code> with a warning.</p>
</td></tr>
<tr><td><code id="checkDimensions_+3A_elementwise">elementwise</code></td>
<td>
<p>Logical: is the domain effectively 1D, i.e. is this a mapping
<code class="reqn">\mathbb{R} \mapsto \mathbb{R}</code> or
<code class="reqn">\mathbb{R}^n \mapsto \mathbb{R}^n</code>. If <code>NA</code>,
compares the output length ot the input length.</p>
</td></tr>
<tr><td><code id="checkDimensions_+3A_vectorised">vectorised</code></td>
<td>
<p>Logical: if <code>TRUE</code>, the function
is assumed to be vectorised: it will accept a vector of parameters and return
a vector of values of the same length. Use <code>FALSE</code> or <code>"no"</code>  for
functions that take vector arguments and return outputs of arbitrary length (for
<code class="reqn">\mathbb{R}^n \mapsto \mathbb{R}^k</code> functions). If <code>NA</code>,
checks the output length and assumes vectorisation if it matches the input length;
this check is necessary and potentially slow.</p>
</td></tr>
<tr><td><code id="checkDimensions_+3A_multivalued">multivalued</code></td>
<td>
<p>Logical: if <code>TRUE</code>, the function is assumed to return vectors longer
than 1. Use <code>FALSE</code> for element-wise functions. If <code>NA</code>, attempts inferring it from
the function output.</p>
</td></tr>
<tr><td><code id="checkDimensions_+3A_deriv.order">deriv.order</code></td>
<td>
<p>Integer or vector of integers indicating the desired derivative order,
<code class="reqn">\mathrm{d}^m / \mathrm{d}x^m</code>, for each element of <code>x</code>.</p>
</td></tr>
<tr><td><code id="checkDimensions_+3A_acc.order">acc.order</code></td>
<td>
<p>Integer or vector of integers specifying the desired accuracy order
for each element of <code>x</code>.
The final error will be of the order <code class="reqn">O(h^{\mathrm{acc.order}})</code>.</p>
</td></tr>
<tr><td><code id="checkDimensions_+3A_side">side</code></td>
<td>
<p>Integer scalar or vector indicating the type of finite difference:
<code>0</code> for central, <code>1</code> for forward, and <code>-1</code> for backward differences.
Central differences are recommended unless computational cost is prohibitive.</p>
</td></tr>
<tr><td><code id="checkDimensions_+3A_h">h</code></td>
<td>
<p>Numeric or character specifying the step size(s) for the numerical
difference or a method of automatic step determination (<code>"CR"</code>, <code>"CRm"</code>,
<code>"DV"</code>, or <code>"SW"</code> to be used in <code><a href="#topic+gradstep">gradstep()</a></code>). The default value is
described in <code>?GenD</code>.</p>
</td></tr>
<tr><td><code id="checkDimensions_+3A_report">report</code></td>
<td>
<p>Integer for the level of detail in the output. If <code>0</code>,
returns a gradient without any attributes; if <code>1</code>,
attaches the step size and its selection method: <code>2</code> or higher attaches the full
diagnostic output as an attribute.</p>
</td></tr>
<tr><td><code id="checkDimensions_+3A_zero.tol">zero.tol</code></td>
<td>
<p>Small positive integer: if <code>abs(x) &gt;= zero.tol</code>, then, the automatically
guessed step size is relative (<code>x</code> multiplied by the step), unless an auto-selection
procedure is requested; otherwise, it is absolute.</p>
</td></tr>
<tr><td><code id="checkDimensions_+3A_cores">cores</code></td>
<td>
<p>Integer specifying the number of CPU cores used for parallel computation.
Recommended to be set to the number of physical cores on the machine minus one.</p>
</td></tr>
<tr><td><code id="checkDimensions_+3A_preschedule">preschedule</code></td>
<td>
<p>Logical: if <code>TRUE</code>, disables pre-scheduling for <code>mclapply()</code>
or enables load balancing with <code>parLapplyLB()</code>. Recommended for functions that
take less than 0.1 s per evaluation.</p>
</td></tr>
<tr><td><code id="checkDimensions_+3A_cl">cl</code></td>
<td>
<p>An optional user-supplied <code>cluster</code> object  (created by <code>makeCluster</code>
or similar functions). If not <code>NULL</code>, the code uses <code>parLapply()</code> (if <code>preschedule</code>
is <code>TRUE</code>) or <code>parLapplyLB()</code> on that cluster on Windows, and <code>mclapply</code>
(fork cluster) on everything else.</p>
</td></tr>
<tr><td><code id="checkDimensions_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>FUN</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following combinations of parameters are allowed, suggesting specific input and
output handling by other functions:</p>

<table>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> <code>elementwise</code> </td><td style="text-align: left;"> <code>!elementwise</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>!multivalued</code>, <code>vectorised</code> </td><td style="text-align: left;"> <code>FUN(xgrid)</code> </td><td style="text-align: left;"> <em>(undefined)</em> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>!multivalued</code>, <code>!vectorised</code> </td><td style="text-align: left;"> <code style="white-space: pre;">&#8288;[mc]lapply(xgrid, FUN)&#8288;</code> </td><td style="text-align: left;"> <code style="white-space: pre;">&#8288;[mc]lapply&#8288;</code> gradient </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>multivalued</code>, <code>vectorised</code> </td><td style="text-align: left;"> <em>(undefined)</em> </td><td style="text-align: left;"> <code>FUN(xgrid)</code> Jacobian </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>multivalued</code>, <code>!vectorised</code> </td><td style="text-align: left;"> <em>(undefined)</em> </td><td style="text-align: left;"> <code style="white-space: pre;">&#8288;[mc]lapply&#8288;</code> Jacobian </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Some combinations are impossible: multi-valued functions cannot be element-wise,
and single-valued vectorised functions must element-wise.
</p>
<p>In brief, testing the input and output length and vectorisation capabilities may result in five
cases, unlike 3 in <code>numDeriv::grad()</code> that does not provide checks for Jacobians.
</p>


<h3>Value</h3>

<p>A named logical vector indicating if a function is element-wise or not,
vectorised or not, and multivalued or not.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>checkDimensions(sin, x = 1:4, h = 1e-5, report = 2)  # Rn -&gt; Rn vectorised
checkDimensions(function(x) integrate(sin, 0, x)$value, x = 1:4, h = 1e-5, report = 2)  # non vec
checkDimensions(function(x) sum(sin(x)), x = 1:4, h = 1e-5, report = 2)  # Rn -&gt; R, gradient
checkDimensions(function(x) c(sin(x), cos(x)), x = 1, h = 1e-5, report = 2)  # R -&gt; Rn, Jacobian
checkDimensions(function(x) c(sin(x), cos(x)), x = 1:4, h = 1e-5, report = 2)  # vec Jac
checkDimensions(function(x) c(integrate(sin, 0, x)$value, integrate(sin, -x, 0)$value),
                 x = 1:4, h = 1e-5, report = 2)  # non-vectorised Jacobian
</code></pre>

<hr>
<h2 id='dupRowInds'>Repeated indices of the first unique value</h2><span id='topic+dupRowInds'></span>

<h3>Description</h3>

<p>Repeated indices of the first unique value
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dupRowInds(m)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dupRowInds_+3A_m">m</code></td>
<td>
<p>A matrix or a data frame.
</p>
<p>This function is an inverse function to such operations as
<code>m[c(1:3, 1, 1, 2), ]</code>: the matrix with potentially duplicated rows is
taken as input, and repeated indices of the first occurrence of each row
are returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of row indices corresponding to the first ocurrence of a given row.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dupRowInds(mtcars[rep(1:10, 10), rep(1:10, 10)])
dupRowInds(matrix(rnorm(1000), ncol = 10))
</code></pre>

<hr>
<h2 id='fdCoef'>Finite-difference coefficients for arbitrary grids</h2><span id='topic+fdCoef'></span>

<h3>Description</h3>

<p>This function computes the coefficients for a numerical approximation to derivatives
of any specified order. It provides the minimally sufficient stencil
for the chosen derivative order and desired accuracy order.
It can also use any user-supplied stencil (uniform or non-uniform).
For that stencil <code class="reqn">\{b_i\}_{i=1}^n</code>, it computes
the optimal weights <code class="reqn">\{w_i\}</code> that yield
the numerical approximation of the derivative:
</p>
<p style="text-align: center;"><code class="reqn">\frac{d^m f}{dx^m} \approx h^{-m} \sum_{i=1}^n w_i f(x + b_i\cdot h)</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>fdCoef(
  deriv.order = 1L,
  side = c(0L, 1L, -1L),
  acc.order = 2L,
  stencil = NULL,
  zero.action = c("drop", "round", "none"),
  zero.tol = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fdCoef_+3A_deriv.order">deriv.order</code></td>
<td>
<p>Order of the derivative (<code class="reqn">m</code> in <code class="reqn">\frac{d^m f}{dx^m}</code>)
for which a numerical approximation is needed.</p>
</td></tr>
<tr><td><code id="fdCoef_+3A_side">side</code></td>
<td>
<p>Integer that determines the type of finite-difference scheme:
<code>0</code> for central (AKA symmetrical or two-sided; the default),
<code>1</code> for forward, and <code>-1</code> for backward.
Using <code>2</code> (for 'two-sided') triggers a warning and is treated as <code>0</code>.
with a warning. Unless the function is computationally prohibitively,
central differences are strongly recommended for their accuracy.</p>
</td></tr>
<tr><td><code id="fdCoef_+3A_acc.order">acc.order</code></td>
<td>
<p>Order of accuracy: defines how the approximation error scales
with the step size <code class="reqn">h</code>, specifically <code class="reqn">O(h^{a+1})</code>, where
<code class="reqn">a</code> is the accuracy order and depends on the higher-order derivatives
of the function.</p>
</td></tr>
<tr><td><code id="fdCoef_+3A_stencil">stencil</code></td>
<td>
<p>Optional custom vector of points for function evaluation.
Must include at least <code>m+1</code> points for the <code>m</code>-th order derivative.</p>
</td></tr>
<tr><td><code id="fdCoef_+3A_zero.action">zero.action</code></td>
<td>
<p>Character string specifying how to handle near-zero weights:
<code>"drop"</code> to omit small (less in absolute value than <code>zero.tol</code> times
the median weight) weights and corresponding stencil points, <code>"round"</code>
to round small weights to zero, and <code>"none"</code> to leave
all weights as calculated.
E.g. the stencil for <code class="reqn">f'(x)</code> is <code>(-1, 0, 1)</code> with weights
<code>(-0.5, 0, 0.5)</code>; using <code>"drop"</code> eliminates the zero weight,
and the redundant <code>f(x)</code> is not computed.</p>
</td></tr>
<tr><td><code id="fdCoef_+3A_zero.tol">zero.tol</code></td>
<td>
<p>Non-negative scalar defining the threshold: weights below
<code>zero.tol</code> times the median weight are considered near-zero.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function relies on the approach of approximating numerical derivarives
by weghted sums of function values described in (Fornberg 1988).
It reproduces all tables from this paper exactly; see the example below to
create Table 1.
</p>
<p>The finite-difference coefficients for any given stencil are given as a solution of a linear
system. The capabilities of this function are similar to those of (Taylor 2016),
but instead of matrix inversion, the (Björck and Pereyra 1970) algorithm is used because
the left-hand-side matrix is a Vandermonde matrix, and its inverse may be
very inaccurate, especially for long one-sided stencils.
</p>
<p>The weights computed for the stencil via this algorithm are very reliable; numerical
simulations in (Higham 1987) show that the relative error is
low even for ill-conditioned systems. (Kostyrka 2025)
computes the exact relative error of the weights on the stencils returned by
this function; the zero tolerance is based on these calculations.
</p>


<h3>Value</h3>

<p>A list containing the <code>stencil</code> used and the corresponding
<code>weights</code> for each point.
</p>


<h3>References</h3>

<p>Björck Å, Pereyra V (1970).
&ldquo;Solution of Vandermonde systems of equations.&rdquo;
<em>Mathematics of computation</em>, <b>24</b>(112), 893&ndash;903.<br /><br /> Fornberg B (1988).
&ldquo;Generation of Finite Difference Formulas on Arbitrarily Spaced Grids.&rdquo;
<em>Mathematics of Computation</em>, <b>51</b>(184), 699&ndash;706.
<a href="https://doi.org/10.1090/S0025-5718-1988-0935077-0">doi:10.1090/S0025-5718-1988-0935077-0</a>.<br /><br /> Higham NJ (1987).
&ldquo;Error analysis of the Björck-Pereyra algorithms for solving Vandermonde systems.&rdquo;
<em>Numerische Mathematik</em>, <b>50</b>(5), 613&ndash;632.<br /><br /> Kostyrka AV (2025).
&ldquo;What are you doing, step size: fast computation of accurate numerical derivatives with finite precision.&rdquo;
Working paper.<br /><br /> Taylor CR (2016).
&ldquo;Finite Difference Coefficients Calculator.&rdquo;
<a href="https://web.media.mit.edu/~crtaylor/calculator.html">https://web.media.mit.edu/~crtaylor/calculator.html</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fdCoef()  # Simple two-sided derivative
fdCoef(2) # Simple two-sided second derivative
fdCoef(acc.order = 4)$weights * 12  # Should be (1, -8, 8, -1)

# Using an custom stencil for the first derivative: x-2h and x+h
fdCoef(stencil = c(-2, 1), acc.order = 1)

# Reproducing Table 1 from Fornberg (1988) (cited above)
pad9 &lt;- function(x) {l &lt;- length(x); c(a &lt;- rep(0, (9-l)/2), x, a)}
f &lt;- function(d, a) pad9(fdCoef(deriv.order = d, acc.order = a,
                                zero.action = "round")$weights)
t11 &lt;- t(sapply((1:4)*2, function(a) f(d = 1, a)))
t12 &lt;- t(sapply((1:4)*2, function(a) f(d = 2, a)))
t13 &lt;- t(sapply((1:3)*2, function(a) f(d = 3, a)))
t14 &lt;- t(sapply((1:3)*2, function(a) f(d = 4, a)))
t11 &lt;- cbind(t11[, 1:4], 0, t11[, 5:8])
t13 &lt;- cbind(t13[, 1:4], 0, t13[, 5:8])
t1 &lt;- data.frame(OrdDer = rep(1:4, times = c(4, 4, 3, 3)),
                 OrdAcc = c((1:4)*2, (1:4)*2, (1:3)*2, (1:3)*2),
                 rbind(t11, t12, t13, t14))
colnames(t1)[3:11] &lt;- as.character(-4:4)
print(t1, digits = 4)
</code></pre>

<hr>
<h2 id='GenD'>Numerical derivative matrices with parallel capabilities</h2><span id='topic+GenD'></span>

<h3>Description</h3>

<p>Computes numerical derivatives of a scalar or vector function using finite-difference methods.
This function serves as a backbone for <code><a href="#topic+Grad">Grad()</a></code> and <code><a href="#topic+Jacobian">Jacobian()</a></code>, allowing for detailed control
over the derivative computation process, including order of derivatives, accuracy, and step size.
<code>GenD</code> is fully vectorised over different coordinates of the function argument,
allowing arbitrary accuracies, sides, and derivative orders for different coordinates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GenD(
  FUN,
  x,
  elementwise = NA,
  vectorised = NA,
  multivalued = NA,
  deriv.order = 1L,
  side = 0,
  acc.order = 2L,
  h = NULL,
  zero.tol = sqrt(.Machine$double.eps),
  h0 = NULL,
  control = list(),
  f0 = NULL,
  cores = 1,
  preschedule = TRUE,
  cl = NULL,
  func = NULL,
  report = 1L,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GenD_+3A_fun">FUN</code></td>
<td>
<p>A function returning a numeric scalar or a vector whose derivatives are to be
computed. If the function returns a vector, the output will be a Jacobian.</p>
</td></tr>
<tr><td><code id="GenD_+3A_x">x</code></td>
<td>
<p>Numeric vector or scalar: the point(s) at which the derivative is estimated.
<code>FUN(x)</code> must be finite.</p>
</td></tr>
<tr><td><code id="GenD_+3A_elementwise">elementwise</code></td>
<td>
<p>Logical: is the domain effectively 1D, i.e. is this a mapping
<code class="reqn">\mathbb{R} \mapsto \mathbb{R}</code> or
<code class="reqn">\mathbb{R}^n \mapsto \mathbb{R}^n</code>. If <code>NA</code>,
compares the output length ot the input length.</p>
</td></tr>
<tr><td><code id="GenD_+3A_vectorised">vectorised</code></td>
<td>
<p>Logical: if <code>TRUE</code>, the function
is assumed to be vectorised: it will accept a vector of parameters and return
a vector of values of the same length. Use <code>FALSE</code> or <code>"no"</code>  for
functions that take vector arguments and return outputs of arbitrary length (for
<code class="reqn">\mathbb{R}^n \mapsto \mathbb{R}^k</code> functions). If <code>NA</code>,
checks the output length and assumes vectorisation if it matches the input length;
this check is necessary and potentially slow.</p>
</td></tr>
<tr><td><code id="GenD_+3A_multivalued">multivalued</code></td>
<td>
<p>Logical: if <code>TRUE</code>, the function is assumed to return vectors longer
than 1. Use <code>FALSE</code> for element-wise functions. If <code>NA</code>, attempts inferring it from
the function output.</p>
</td></tr>
<tr><td><code id="GenD_+3A_deriv.order">deriv.order</code></td>
<td>
<p>Integer or vector of integers indicating the desired derivative order,
<code class="reqn">\mathrm{d}^m / \mathrm{d}x^m</code>, for each element of <code>x</code>.</p>
</td></tr>
<tr><td><code id="GenD_+3A_side">side</code></td>
<td>
<p>Integer scalar or vector indicating the type of finite difference:
<code>0</code> for central, <code>1</code> for forward, and <code>-1</code> for backward differences.
Central differences are recommended unless computational cost is prohibitive.</p>
</td></tr>
<tr><td><code id="GenD_+3A_acc.order">acc.order</code></td>
<td>
<p>Integer or vector of integers specifying the desired accuracy order
for each element of <code>x</code>.
The final error will be of the order <code class="reqn">O(h^{\mathrm{acc.order}})</code>.</p>
</td></tr>
<tr><td><code id="GenD_+3A_h">h</code></td>
<td>
<p>Numeric or character specifying the step size(s) for the numerical
difference or a method of automatic step determination (<code>"CR"</code>, <code>"CRm"</code>,
<code>"DV"</code>, or <code>"SW"</code> to be used in <code><a href="#topic+gradstep">gradstep()</a></code>). The default value is
described in <code>?GenD</code>.</p>
</td></tr>
<tr><td><code id="GenD_+3A_zero.tol">zero.tol</code></td>
<td>
<p>Small positive integer: if <code>abs(x) &gt;= zero.tol</code>, then, the automatically
guessed step size is relative (<code>x</code> multiplied by the step), unless an auto-selection
procedure is requested; otherwise, it is absolute.</p>
</td></tr>
<tr><td><code id="GenD_+3A_h0">h0</code></td>
<td>
<p>Numeric scalar of vector: initial step size for automatic search with
<code>gradstep()</code>.</p>
</td></tr>
<tr><td><code id="GenD_+3A_control">control</code></td>
<td>
<p>A named list of tuning parameters passed to <code>gradstep()</code>.</p>
</td></tr>
<tr><td><code id="GenD_+3A_f0">f0</code></td>
<td>
<p>Optional numeric: if provided, used to determine the vectorisation type
to save time. If FUN(x) must be evaluated (e.g. second derivatives), saves one evaluation.</p>
</td></tr>
<tr><td><code id="GenD_+3A_cores">cores</code></td>
<td>
<p>Integer specifying the number of CPU cores used for parallel computation.
Recommended to be set to the number of physical cores on the machine minus one.</p>
</td></tr>
<tr><td><code id="GenD_+3A_preschedule">preschedule</code></td>
<td>
<p>Logical: if <code>TRUE</code>, disables pre-scheduling for <code>mclapply()</code>
or enables load balancing with <code>parLapplyLB()</code>. Recommended for functions that
take less than 0.1 s per evaluation.</p>
</td></tr>
<tr><td><code id="GenD_+3A_cl">cl</code></td>
<td>
<p>An optional user-supplied <code>cluster</code> object  (created by <code>makeCluster</code>
or similar functions). If not <code>NULL</code>, the code uses <code>parLapply()</code> (if <code>preschedule</code>
is <code>TRUE</code>) or <code>parLapplyLB()</code> on that cluster on Windows, and <code>mclapply</code>
(fork cluster) on everything else.</p>
</td></tr>
<tr><td><code id="GenD_+3A_func">func</code></td>
<td>
<p>For compatibility with <code>numDeriv::grad()</code> only. If instead of
<code>FUN</code>, <code>func</code> is used, it will be reassigned to <code>FUN</code> with a warning.</p>
</td></tr>
<tr><td><code id="GenD_+3A_report">report</code></td>
<td>
<p>Integer for the level of detail in the output. If <code>0</code>,
returns a gradient without any attributes; if <code>1</code>,
attaches the step size and its selection method: <code>2</code> or higher attaches the full
diagnostic output as an attribute.</p>
</td></tr>
<tr><td><code id="GenD_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>FUN</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For computing gradients and Jacobians, use convenience wrappers <code>Jacobian</code> and <code>Grad</code>.
</p>
<p>If the step size is too large, the slope of the secant poorly estimates the derivative;
if it is too small, it leads to numerical instability due to the function value rounding.
</p>
<p>The optimal step size for one-sided differences typically approaches Mach.eps^(1/2)
to balance the Taylor series truncation error with the rounding error due to storing
function values with limited precision. For two-sided differences, it is proportional
to Mach.eps^(1/3). However, selecting the best step size typically requires knowledge
of higher-order derivatives, which may not be readily available. Luckily,
using <code>step = "SW"</code> invokes a reliable automatic data-driven step-size selection.
Other options include <code>"DV"</code>, <code>"CR"</code>, and <code>"CRm"</code>.
The step size  defaults to <code>1.5e-8</code> (the square root of machine epsilon)
for <code>x</code> less than <code>1.5e-8</code>,
<code>(2.2e-16)^(1/(deriv.order + acc.order)) * x</code> for <code>x &gt; 1</code>, and interpolates
exponentially between these values for <code>1.5e-8 &lt; x &lt; 1</code>.
</p>
<p>The use of <code>f0</code> can reduce computation time similar to the use of <code>f.lower</code>
and <code>f.upper</code> in <code>uniroot()</code>.
</p>
<p>For convenience, <code>report = 2</code> overrides <code>diagnostics = FALSE</code> in the
<code>control</code>) list.
</p>
<p>Unlike <code>numDeriv::grad()</code> and <code>numDeriv::jacobian()</code>, this function
fully preserves the names of <code>x</code> and <code>FUN(x)</code>.
</p>


<h3>Value</h3>

<p>A vector or matrix containing the computed derivatives, structured according
to the dimensionality of <code>x</code> and <code>FUN</code>. If <code>FUN</code> is scalar-valued,
returns a gradient vector. If <code>FUN</code> is vector-valued, returns a Jacobian matrix.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gradstep">gradstep()</a></code> for automatic step-size selection.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Case 1: Vector argument, vector output
f1 &lt;- sin
g1 &lt;- GenD(FUN = f1, x = 1:100)
g1.true &lt;- cos(1:100)
plot(1:100, g1 - g1.true, main = "Approximation error of d/dx sin(x)")

# Case 2: Vector argument, scalar result
f2 &lt;- function(x) sum(sin(x))
g2    &lt;- GenD(FUN = f2, x = 1:4)
g2.h2 &lt;- Grad(FUN = f2, x = 1:4, h = 7e-6)
g2 - g2.h2  # Tiny differences due to different step sizes
g2.auto &lt;- Grad(FUN = f2, x = 1:4, h = "SW")
g2.full &lt;- Grad(FUN = f2, x = 1:4, h = "SW", report = 2)
print(attr(g2.full, "step.search")$exitcode)  # Success

# Case 3: vector input, vector argument of different length
f3 &lt;- function(x) c(sum(sin(x)), prod(cos(x)))
x3 &lt;- 1:3
j3 &lt;- GenD(f3, x3, multivalued = TRUE)
print(j3)

# Gradients for vectorised functions -- e.g. leaky ReLU
LReLU &lt;- function(x) ifelse(x &gt; 0, x, 0.01*x)
system.time(replicate(10, suppressMessages(GenD(LReLU, runif(30, -1, 1)))))
system.time(replicate(10, suppressMessages(GenD(LReLU, runif(30, -1, 1)))))

# Saving time for slow functions by using pre-computed values
x &lt;- 1:4
finner &lt;- function(x) sin(x*log(abs(x)+1))
fouter &lt;- function(x) integrate(finner, 0, x, rel.tol = 1e-12, abs.tol = 0)$value
# The outer function is non-vectorised
fslow &lt;- function(x) {Sys.sleep(0.01); fouter(x)}
f0 &lt;- sapply(x, fouter)
system.time(GenD(fslow, x, side = 1, acc.order = 2, f0 = f0))
# Now, with extra checks, it will be slower
system.time(GenD(fslow, x, side = 1, acc.order = 2))
</code></pre>

<hr>
<h2 id='generateGrid'>Create a grid of points for a gradient / Jacobian</h2><span id='topic+generateGrid'></span>

<h3>Description</h3>

<p>Create a grid of points for a gradient / Jacobian
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateGrid(x, h, stencils, elementwise, vectorised)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generateGrid_+3A_x">x</code></td>
<td>
<p>Numeric vector or scalar: the point(s) at which the derivative is estimated.
<code>FUN(x)</code> must be finite.</p>
</td></tr>
<tr><td><code id="generateGrid_+3A_h">h</code></td>
<td>
<p>Numeric or character specifying the step size(s) for the numerical
difference or a method of automatic step determination (<code>"CR"</code>, <code>"CRm"</code>,
<code>"DV"</code>, or <code>"SW"</code> to be used in <code><a href="#topic+gradstep">gradstep()</a></code>). The default value is
described in <code>?GenD</code>.</p>
</td></tr>
<tr><td><code id="generateGrid_+3A_stencils">stencils</code></td>
<td>
<p>A list of outputs from <code><a href="#topic+fdCoef">fdCoef()</a></code> for each coordinate of <code>x</code>.</p>
</td></tr>
<tr><td><code id="generateGrid_+3A_elementwise">elementwise</code></td>
<td>
<p>Logical: is the domain effectively 1D, i.e. is this a mapping
<code class="reqn">\mathbb{R} \mapsto \mathbb{R}</code> or
<code class="reqn">\mathbb{R}^n \mapsto \mathbb{R}^n</code>. If <code>NA</code>,
compares the output length ot the input length.</p>
</td></tr>
<tr><td><code id="generateGrid_+3A_vectorised">vectorised</code></td>
<td>
<p>Logical: if <code>TRUE</code>, the function
is assumed to be vectorised: it will accept a vector of parameters and return
a vector of values of the same length. Use <code>FALSE</code> or <code>"no"</code>  for
functions that take vector arguments and return outputs of arbitrary length (for
<code class="reqn">\mathbb{R}^n \mapsto \mathbb{R}^k</code> functions). If <code>NA</code>,
checks the output length and assumes vectorisation if it matches the input length;
this check is necessary and potentially slow.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with points for evaluation, summation weights for derivative computation, and
indices for combining values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>generateGrid(1:4, h = 1e-5, elementwise = TRUE, vectorised = TRUE,
             stencils = lapply(1:4, function(a) fdCoef(acc.order = a)))
</code></pre>

<hr>
<h2 id='generateGrid2'>Generate grid points for Hessians</h2><span id='topic+generateGrid2'></span>

<h3>Description</h3>

<p>Creates a list of unique evaluation points for second derivatives: both
diagonal (<code class="reqn">\partial^2 / \partial x_i^2</code>) and cross
(<code class="reqn">\partial^2 / \partial x_i \partial x_j</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateGrid2(x, side, acc.order, h)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generateGrid2_+3A_x">x</code></td>
<td>
<p>Numeric vector or scalar: the point(s) at which the derivative is estimated.
<code>FUN(x)</code> must be finite.</p>
</td></tr>
<tr><td><code id="generateGrid2_+3A_side">side</code></td>
<td>
<p>Integer scalar or vector indicating the type of finite difference:
<code>0</code> for central, <code>1</code> for forward, and <code>-1</code> for backward differences.
Central differences are recommended unless computational cost is prohibitive.</p>
</td></tr>
<tr><td><code id="generateGrid2_+3A_acc.order">acc.order</code></td>
<td>
<p>Integer or vector of integers specifying the desired accuracy order
for each element of <code>x</code>.
The final error will be of the order <code class="reqn">O(h^{\mathrm{acc.order}})</code>.</p>
</td></tr>
<tr><td><code id="generateGrid2_+3A_h">h</code></td>
<td>
<p>Numeric or character specifying the step size(s) for the numerical
difference or a method of automatic step determination (<code>"CR"</code>, <code>"CRm"</code>,
<code>"DV"</code>, or <code>"SW"</code> to be used in <code><a href="#topic+gradstep">gradstep()</a></code>). The default value is
described in <code>?GenD</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with elements:
</p>

<ul>
<li> <p><code>xlist</code>: a list of unique coordinate shifts,
</p>
</li>
<li> <p><code>w</code>: the finite-difference weights (one per point),
</p>
</li>
<li> <p><code>i1</code>, <code>i2</code>: integer vectors giving partial-derivative indices.
</p>
</li></ul>

<p>The length of each vector matches <code>xlist</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GenD">GenD()</a></code>, <code><a href="#topic+Hessian">Hessian()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>generateGrid2(1:4, side = rep(0, 4), acc.order = c(2, 6, 4, 2),
              h = c(1e-5, 1e-4, 2e-5, 1e-6))
</code></pre>

<hr>
<h2 id='Grad'>Gradient computation with parallel capabilities</h2><span id='topic+Grad'></span>

<h3>Description</h3>

<p>Computes numerical derivatives and gradients of scalar-valued functions using
finite differences. This function supports both two-sided (central, symmetric) and
one-sided (forward or backward) derivatives. It can utilise parallel processing
to accelerate computation of gradients for slow functions or
to attain higher accuracy faster. Currently, only Mac and Linux are supported
<code>parallel::mclapply()</code>. Windows support with <code>parallel::parLapply()</code>
is under development.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Grad(
  FUN,
  x,
  elementwise = NA,
  vectorised = NA,
  multivalued = NA,
  deriv.order = 1L,
  side = 0,
  acc.order = 2,
  h = NULL,
  zero.tol = sqrt(.Machine$double.eps),
  h0 = NULL,
  control = list(),
  f0 = NULL,
  cores = 1,
  preschedule = TRUE,
  cl = NULL,
  func = NULL,
  report = 1L,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Grad_+3A_fun">FUN</code></td>
<td>
<p>A function returning a numeric scalar or a vector whose derivatives are to be
computed. If the function returns a vector, the output will be a Jacobian.</p>
</td></tr>
<tr><td><code id="Grad_+3A_x">x</code></td>
<td>
<p>Numeric vector or scalar: the point(s) at which the derivative is estimated.
<code>FUN(x)</code> must be finite.</p>
</td></tr>
<tr><td><code id="Grad_+3A_elementwise">elementwise</code></td>
<td>
<p>Logical: is the domain effectively 1D, i.e. is this a mapping
<code class="reqn">\mathbb{R} \mapsto \mathbb{R}</code> or
<code class="reqn">\mathbb{R}^n \mapsto \mathbb{R}^n</code>. If <code>NA</code>,
compares the output length ot the input length.</p>
</td></tr>
<tr><td><code id="Grad_+3A_vectorised">vectorised</code></td>
<td>
<p>Logical: if <code>TRUE</code>, the function
is assumed to be vectorised: it will accept a vector of parameters and return
a vector of values of the same length. Use <code>FALSE</code> or <code>"no"</code>  for
functions that take vector arguments and return outputs of arbitrary length (for
<code class="reqn">\mathbb{R}^n \mapsto \mathbb{R}^k</code> functions). If <code>NA</code>,
checks the output length and assumes vectorisation if it matches the input length;
this check is necessary and potentially slow.</p>
</td></tr>
<tr><td><code id="Grad_+3A_multivalued">multivalued</code></td>
<td>
<p>Logical: if <code>TRUE</code>, the function is assumed to return vectors longer
than 1. Use <code>FALSE</code> for element-wise functions. If <code>NA</code>, attempts inferring it from
the function output.</p>
</td></tr>
<tr><td><code id="Grad_+3A_deriv.order">deriv.order</code></td>
<td>
<p>Integer or vector of integers indicating the desired derivative order,
<code class="reqn">\mathrm{d}^m / \mathrm{d}x^m</code>, for each element of <code>x</code>.</p>
</td></tr>
<tr><td><code id="Grad_+3A_side">side</code></td>
<td>
<p>Integer scalar or vector indicating the type of finite difference:
<code>0</code> for central, <code>1</code> for forward, and <code>-1</code> for backward differences.
Central differences are recommended unless computational cost is prohibitive.</p>
</td></tr>
<tr><td><code id="Grad_+3A_acc.order">acc.order</code></td>
<td>
<p>Integer or vector of integers specifying the desired accuracy order
for each element of <code>x</code>.
The final error will be of the order <code class="reqn">O(h^{\mathrm{acc.order}})</code>.</p>
</td></tr>
<tr><td><code id="Grad_+3A_h">h</code></td>
<td>
<p>Numeric or character specifying the step size(s) for the numerical
difference or a method of automatic step determination (<code>"CR"</code>, <code>"CRm"</code>,
<code>"DV"</code>, or <code>"SW"</code> to be used in <code><a href="#topic+gradstep">gradstep()</a></code>). The default value is
described in <code>?GenD</code>.</p>
</td></tr>
<tr><td><code id="Grad_+3A_zero.tol">zero.tol</code></td>
<td>
<p>Small positive integer: if <code>abs(x) &gt;= zero.tol</code>, then, the automatically
guessed step size is relative (<code>x</code> multiplied by the step), unless an auto-selection
procedure is requested; otherwise, it is absolute.</p>
</td></tr>
<tr><td><code id="Grad_+3A_h0">h0</code></td>
<td>
<p>Numeric scalar of vector: initial step size for automatic search with
<code>gradstep()</code>.</p>
</td></tr>
<tr><td><code id="Grad_+3A_control">control</code></td>
<td>
<p>A named list of tuning parameters passed to <code>gradstep()</code>.</p>
</td></tr>
<tr><td><code id="Grad_+3A_f0">f0</code></td>
<td>
<p>Optional numeric: if provided, used to determine the vectorisation type
to save time. If FUN(x) must be evaluated (e.g. second derivatives), saves one evaluation.</p>
</td></tr>
<tr><td><code id="Grad_+3A_cores">cores</code></td>
<td>
<p>Integer specifying the number of CPU cores used for parallel computation.
Recommended to be set to the number of physical cores on the machine minus one.</p>
</td></tr>
<tr><td><code id="Grad_+3A_preschedule">preschedule</code></td>
<td>
<p>Logical: if <code>TRUE</code>, disables pre-scheduling for <code>mclapply()</code>
or enables load balancing with <code>parLapplyLB()</code>. Recommended for functions that
take less than 0.1 s per evaluation.</p>
</td></tr>
<tr><td><code id="Grad_+3A_cl">cl</code></td>
<td>
<p>An optional user-supplied <code>cluster</code> object  (created by <code>makeCluster</code>
or similar functions). If not <code>NULL</code>, the code uses <code>parLapply()</code> (if <code>preschedule</code>
is <code>TRUE</code>) or <code>parLapplyLB()</code> on that cluster on Windows, and <code>mclapply</code>
(fork cluster) on everything else.</p>
</td></tr>
<tr><td><code id="Grad_+3A_func">func</code></td>
<td>
<p>For compatibility with <code>numDeriv::grad()</code> only. If instead of
<code>FUN</code>, <code>func</code> is used, it will be reassigned to <code>FUN</code> with a warning.</p>
</td></tr>
<tr><td><code id="Grad_+3A_report">report</code></td>
<td>
<p>Integer for the level of detail in the output. If <code>0</code>,
returns a gradient without any attributes; if <code>1</code>,
attaches the step size and its selection method: <code>2</code> or higher attaches the full
diagnostic output as an attribute.</p>
</td></tr>
<tr><td><code id="Grad_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>FUN</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function aims to be 100% compatible with the syntax of <code>numDeriv::Grad()</code>.
</p>
<p>There is one feature of the default step size in <code>numDeriv</code> that deserves
an explanation.
</p>

<ul>
<li><p> If <code>method = "simple"</code>, then, simple forward differences are used with
a fixed step size <code>eps</code>, which we denote by <code class="reqn">\varepsilon</code>.
</p>
</li>
<li><p> If <code>method = "Richardson"</code>, then, central differences are used with
a fixed step
<code class="reqn">h := |d\cdot x| + \varepsilon (|x| &lt; \mathrm{zero.tol})</code>,
where <code>d = 1e-4</code> is the relative step size and <code>eps</code> becomes an extra
addition to the step size for the argument that are closer to zero than <code>zero.tol</code>.
</p>
</li></ul>

<p>We believe that the latter may lead to mistakes when the user believes that they can set
the step size for near-zero arguments, whereas in reality, a combination of <code>d</code> and <code>eps</code>
is used.
</p>
<p>Here is the synopsis of the old arguments:
</p>

<dl>
<dt>side</dt><dd><p><code>numDeriv</code> uses <code>NA</code> for handling two-sided differences.
The <code>pnd</code> equivalent is <code>0</code>, and <code>NA</code> is replaced with <code>0</code>.</p>
</dd>
<dt>eps</dt><dd><p>If <code>numDeriv</code> <code>method = "simple"</code>, then, <code>eps = 1e-4</code> is
the absolute step size and forward differences are used.
If <code>method = "Richardson"</code>, then, <code>eps = 1e-4</code> is the absolute increment of the step
size for small arguments below the zero tolerance.</p>
</dd>
<dt>d</dt><dd><p>If <code>numDeriv</code> <code>method = "Richardson"</code>, then, <code>d*abs(x)</code> is the
step size for arguments above the zero tolerance and the baseline step size for
small arguments that gets incremented by <code>eps</code>.</p>
</dd>
<dt>r</dt><dd><p>The number of Richardson extrapolations that successively reduce the initial step size.
For two-sided differences, each extrapolation increases the accuracy order by 2.</p>
</dd>
<dt>v</dt><dd><p>The reduction factor in Richardson extrapolations.</p>
</dd>
</dl>

<p>Here are the differences in the new compatible implementation.
</p>

<dl>
<dt>eps</dt><dd><p>If <code>numDeriv</code> <code>method = "simple"</code>, then,
<code>ifelse(x!=0, abs(x), 1) * sqrt(.Machine$double.eps) * 2</code> is used because
one-sided differences require a smaller step size to reduce the truncation error.
If <code>method = "Richardson"</code>, then, <code>eps = 1e-5</code>.</p>
</dd>
<dt>d</dt><dd><p>If <code>numDeriv</code> <code>method = "Richardson"</code>, then, <code>d*abs(x)</code> is the
step size for arguments above the zero tolerance and the baseline step size for
small arguments that gets incremented by <code>eps</code>.</p>
</dd>
<dt>r</dt><dd><p>The number of Richardson extrapolations that successively reduce the initial step size.
For two-sided differences, each extrapolation increases the accuracy order by 2.</p>
</dd>
<dt>v</dt><dd><p>The reduction factor in Richardson extrapolations.</p>
</dd>
</dl>

<p><code>Grad</code> does an initial check (if <code>f0 = FUN(x)</code> is not provided)
and calls <code><a href="#topic+GenD">GenD()</a></code> with a set of appropriate parameters (<code>multivalued = FALSE</code>
if the check succeds). In case of parameter mismatch, throws and error.
</p>


<h3>Value</h3>

<p>Numeric vector of the gradient. If <code>FUN</code> returns a vector,
a warning is issued suggesting the use of <code><a href="#topic+Jacobian">Jacobian()</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GenD">GenD()</a></code>, <code><a href="#topic+Jacobian">Jacobian()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- function(x) sum(sin(x))
g1 &lt;- Grad(FUN = f, x = 1:4)
g2 &lt;- Grad(FUN = f, x = 1:4, h = 7e-6)
g2 - g1  # Tiny differences due to different step sizes
g.auto &lt;- Grad(FUN = f, x = 1:4, h = "SW")
g3.full &lt;- Grad(FUN = f, x = 1:4, h = "SW", report = 2)
print(g3.full)
attr(g3.full, "step.search")$exitcode  # Success

# Gradients for vectorised functions -- e.g. leaky ReLU
LReLU &lt;- function(x) ifelse(x &gt; 0, x, 0.01*x)
Grad(LReLU, seq(-1, 1, 0.1))
</code></pre>

<hr>
<h2 id='gradstep'>Automatic step selection for numerical derivatives</h2><span id='topic+gradstep'></span>

<h3>Description</h3>

<p>Automatic step selection for numerical derivatives
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gradstep(
  FUN,
  x,
  h0 = NULL,
  zero.tol = sqrt(.Machine$double.eps),
  method = c("plugin", "SW", "CR", "CRm", "DV", "M"),
  diagnostics = FALSE,
  control = NULL,
  cores = 1,
  preschedule = getOption("pnd.preschedule", TRUE),
  cl = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gradstep_+3A_fun">FUN</code></td>
<td>
<p>Function for which the optimal numerical derivative step size is needed.</p>
</td></tr>
<tr><td><code id="gradstep_+3A_x">x</code></td>
<td>
<p>Numeric vector or scalar: the point at which the derivative is computed
and the optimal step size is estimated.</p>
</td></tr>
<tr><td><code id="gradstep_+3A_h0">h0</code></td>
<td>
<p>Numeric vector or scalar: initial step size, defaulting to a relative step of
slightly greater than .Machine$double.eps^(1/3) (or absolute step if <code>x == 0</code>).</p>
</td></tr>
<tr><td><code id="gradstep_+3A_zero.tol">zero.tol</code></td>
<td>
<p>Small positive integer: if <code>abs(x) &gt;= zero.tol</code>, then, the automatically
guessed step size is relative (<code>x</code> multiplied by the step), unless an auto-selection
procedure is requested; otherwise, it is absolute.</p>
</td></tr>
<tr><td><code id="gradstep_+3A_method">method</code></td>
<td>
<p>Character indicating the method: <code>"CR"</code> for (Curtis and Reid 1974),
<code>"CR"</code> for modified Curtis&ndash;Reid, &quot;DV&quot; for (Dumontet and Vignes 1977),
<code>"SW"</code> (Stepleman and Winarsky 1979), and &quot;M&quot; for
(Mathur 2012).</p>
</td></tr>
<tr><td><code id="gradstep_+3A_diagnostics">diagnostics</code></td>
<td>
<p>Logical: if <code>TRUE</code>, returns the full iteration history
including all function evaluations. Passed to the appropriate <code>step.XX</code> function.</p>
</td></tr>
<tr><td><code id="gradstep_+3A_control">control</code></td>
<td>
<p>A named list of tuning parameters for the method. If <code>NULL</code>,
default values are used. See the documentation for the respective methods. Note that
if <code>control$diagnostics</code> is <code>TRUE</code>, full iteration history
including all function evaluations is returned; different methods have
slightly different diagnostic outputs.</p>
</td></tr>
<tr><td><code id="gradstep_+3A_cores">cores</code></td>
<td>
<p>Integer specifying the number of CPU cores used for parallel computation.
Recommended to be set to the number of physical cores on the machine minus one.</p>
</td></tr>
<tr><td><code id="gradstep_+3A_preschedule">preschedule</code></td>
<td>
<p>Logical: if <code>TRUE</code>, disables pre-scheduling for <code>mclapply()</code>
or enables load balancing with <code>parLapplyLB()</code>. Recommended for functions that
take less than 0.1 s per evaluation.</p>
</td></tr>
<tr><td><code id="gradstep_+3A_cl">cl</code></td>
<td>
<p>An optional user-supplied <code>cluster</code> object  (created by <code>makeCluster</code>
or similar functions). If not <code>NULL</code>, the code uses <code>parLapply()</code> (if <code>preschedule</code>
is <code>TRUE</code>) or <code>parLapplyLB()</code> on that cluster on Windows, and <code>mclapply</code>
(fork cluster) on everything else.</p>
</td></tr>
<tr><td><code id="gradstep_+3A_...">...</code></td>
<td>
<p>Passed to FUN.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We recommend using the Mathur algorithm because it does not suffer
from over-estimation of the truncation error in the Curtis&ndash;Reid approach
and from sensitivity to near-zero third derivatives in the Dumontet&ndash;Vignes
approach. It really tries muliple step sizes simultaneously and handles missing
values due to bad evaluations for inadequate step sizes really in a robust manner.
</p>


<h3>Value</h3>

<p>A list similar to the one returned by <code>optim()</code> and made of
concatenated individual elements coordinate-wise lists: <code>par</code> &ndash; the optimal
step sizes found, <code>value</code> &ndash; the estimated numerical gradient,
<code>counts</code> &ndash; the number of iterations for each coordinate,
<code>abs.error</code> &ndash; an estimate of the total approximation error
(sum of truncation and rounding errors),
<code>exitcode</code> &ndash; an integer code indicating the termination status:
<code>0</code> indicates optimal termination within tolerance,
<code>1</code> means that the truncation error (CR method) or the third derivative
(DV method) is zero and large step size is preferred,
<code>2</code> is returned if there is no change in step size within tolerance,
<code>3</code> indicates a solution at the boundary of the allowed value range,
<code>4</code> signals that the maximum number of iterations was reached.
<code>message</code> &ndash; summary messages of the exit status.
If <code>method.ards$diagnostics</code> is <code>TRUE</code>, <code>iterations</code> is a list of lists
including the full step size search path, argument grids, function values on
those grids, estimated error ratios, and estimated derivative values for
each coordinate.
</p>


<h3>References</h3>

<p>Curtis AR, Reid JK (1974).
&ldquo;The Choice of Step Lengths When Using Differences to Approximate Jacobian Matrices.&rdquo;
<em>IMA Journal of Applied Mathematics</em>, <b>13</b>(1), 121&ndash;126.
<a href="https://doi.org/10.1093/imamat/13.1.121">doi:10.1093/imamat/13.1.121</a>.<br /><br /> Dumontet J, Vignes J (1977).
&ldquo;Détermination du pas optimal dans le calcul des dérivées sur ordinateur.&rdquo;
<em>RAIRO. Analyse numérique</em>, <b>11</b>(1), 13&ndash;25.
<a href="https://doi.org/10.1051/m2an/1977110100131">doi:10.1051/m2an/1977110100131</a>.<br /><br /> Mathur R (2012).
<em>An Analytical Approach to Computing Step Sizes for Finite-Difference Derivatives</em>.
Ph.D. thesis, University of Texas at Austin.
<a href="http://hdl.handle.net/2152/ETD-UT-2012-05-5275">http://hdl.handle.net/2152/ETD-UT-2012-05-5275</a>.<br /><br /> Stepleman RS, Winarsky ND (1979).
&ldquo;Adaptive numerical differentiation.&rdquo;
<em>Mathematics of Computation</em>, <b>33</b>(148), 1257&ndash;1264.
<a href="https://doi.org/10.1090/s0025-5718-1979-0537969-8">doi:10.1090/s0025-5718-1979-0537969-8</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+step.CR">step.CR()</a></code> for Curtis&ndash;Reid (1974) and its modification,
<code><a href="#topic+step.DV">step.DV()</a></code> for Dumontet&ndash;Vignes (1977),
<code><a href="#topic+step.SW">step.SW()</a></code> for Stepleman&ndash;Winarsky (1979), and
<code><a href="#topic+step.M">step.M()</a></code> for Mathur (2012).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gradstep(x = 1, FUN = sin, method = "CR")
gradstep(x = 1, FUN = sin, method = "CRm")
gradstep(x = 1, FUN = sin, method = "DV")
gradstep(x = 1, FUN = sin, method = "SW")
gradstep(x = 1, FUN = sin, method = "M")
# Works for gradients
gradstep(x = 1:4, FUN = function(x) sum(sin(x)))
</code></pre>

<hr>
<h2 id='Hessian'>Numerical Hessians</h2><span id='topic+Hessian'></span>

<h3>Description</h3>

<p>Computes the second derivatives of a function with respect to all combinations
of its input coordinates. Arbitrary accuracies and sides for different coordinates
of the argument vector are supported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Hessian(
  FUN,
  x,
  side = 0,
  acc.order = 2,
  h = NULL,
  h0 = NULL,
  control = list(),
  f0 = NULL,
  cores = 1,
  preschedule = TRUE,
  cl = NULL,
  func = NULL,
  report = 1L,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Hessian_+3A_fun">FUN</code></td>
<td>
<p>A function returning a numeric scalar.
If the function returns a vector, the output will be is a Jacobian.
If instead of <code>FUN</code>, <code>func</code> is passed, as in <code>numDeriv::grad</code>,
it will be reassigned to <code>FUN</code> with a warning.</p>
</td></tr>
<tr><td><code id="Hessian_+3A_x">x</code></td>
<td>
<p>Numeric vector or scalar: point at which the derivative is estimated.
<code>FUN(x)</code> must return a finite value.</p>
</td></tr>
<tr><td><code id="Hessian_+3A_side">side</code></td>
<td>
<p>Integer scalar or vector indicating difference type:
<code>0</code> for central, <code>1</code> for forward, and <code>-1</code> for backward differences.
Central differences are recommended unless computational cost is prohibitive.</p>
</td></tr>
<tr><td><code id="Hessian_+3A_acc.order">acc.order</code></td>
<td>
<p>Integer specifying the desired accuracy order.
The error typically scales as <code class="reqn">O(h^{\mathrm{acc.order}})</code>.</p>
</td></tr>
<tr><td><code id="Hessian_+3A_h">h</code></td>
<td>
<p>Numeric scalar, vector, or character specifying the step size for the numerical
difference. If character (<code>"CR"</code>, <code>"CRm"</code>, <code>"DV"</code>, or <code>"SW"</code>),
calls <code>gradstep()</code> with the appropriate step-selection method.
Must be length 1 or match <code>length(x)</code>. Matrices of step sizes are not
supported. Suggestions how to handle all pairs of coordinates are welcome.</p>
</td></tr>
<tr><td><code id="Hessian_+3A_h0">h0</code></td>
<td>
<p>Numeric scalar of vector: initial step size for automatic search with
<code>gradstep()</code>.Hessian(f, 1:100)</p>
</td></tr>
<tr><td><code id="Hessian_+3A_control">control</code></td>
<td>
<p>A named list of tuning parameters passed to <code>gradstep()</code>.</p>
</td></tr>
<tr><td><code id="Hessian_+3A_f0">f0</code></td>
<td>
<p>Optional numeric scalar or vector: if provided and applicable, used
where the stencil contains zero (i.e. <code>FUN(x)</code> is part of the sum)
to save time.
TODO: Currently ignored.</p>
</td></tr>
<tr><td><code id="Hessian_+3A_cores">cores</code></td>
<td>
<p>Integer specifying the number of CPU cores used for parallel computation.
Recommended to be set to the number of physical cores on the machine minus one.</p>
</td></tr>
<tr><td><code id="Hessian_+3A_preschedule">preschedule</code></td>
<td>
<p>Logical: if <code>TRUE</code>, disables pre-scheduling for <code>mclapply()</code>
or enables load balancing with <code>parLapplyLB()</code>. Recommended for functions that
take less than 0.1 s per evaluation.</p>
</td></tr>
<tr><td><code id="Hessian_+3A_cl">cl</code></td>
<td>
<p>An optional user-supplied <code>cluster</code> object  (created by <code>makeCluster</code>
or similar functions). If not <code>NULL</code>, the code uses <code>parLapply()</code> (if <code>preschedule</code>
is <code>TRUE</code>) or <code>parLapplyLB()</code> on that cluster on Windows, and <code>mclapply</code>
(fork cluster) on everything else.</p>
</td></tr>
<tr><td><code id="Hessian_+3A_func">func</code></td>
<td>
<p>Deprecated; for <code>numDeriv::grad()</code> compatibility only.</p>
</td></tr>
<tr><td><code id="Hessian_+3A_report">report</code></td>
<td>
<p>Integer: if <code>0</code>, returns a gradient without any attributes; if <code>1</code>,
attaches the step size and its selection method: <code>2</code> or higher, attaches the full
diagnostic output (overrides <code>diagnostics = FALSE</code> in <code>control</code>).</p>
</td></tr>
<tr><td><code id="Hessian_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>FUN</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The optimal step size for 2nd-order-accurate central-differences-based Hessians
is of the order Mach.eps^(1/4)
to balance the Taylor series truncation error with the rounding error.
However, selecting the best step size typically requires knowledge
of higher-order cross derivatives and is highly technically involved. Future releases
will allow character arguments to invoke automatic data-driven step-size selection.
</p>
<p>The use of <code>f0</code> can reduce computation time similar to the use of <code>f.lower</code>
and <code>f.upper</code> in <code>uniroot()</code>.
</p>
<p>Some numerical packages use the option (or even the default behaviour) of computing
not only the <code>i &lt; j</code> cross-partials for the Hessian, but all pairs of <code>i</code>
and <code>j</code>. The upper and lower triangular matrices are filled, and the matrix is
averaged with its transpose to obtain a Hessian &ndash; this is the behaviour of <code>optimHess()</code>.
However, it can be shown that <code>H[i, j]</code> and <code>H[j, i]</code> use the same evaluation
grid, and with a single parallelisable evaluation of the function on that grid, no
symmetrisation is necessary because the result is mathematically and computationally identical.
In <code>pnd</code>, only the upper triangular matrix is computed, saving time and ensuring
unambiguous results owing to the interchangeability of summation terms (ignoring the numerical
error in summation as there is nothing that can be done apart from compensation summation, e.g.
via Kahan's algorithm).
</p>


<h3>Value</h3>

<p>A matrix with as many rows and columns as <code>length(x)</code>. Unlike the output of
<code>numDeriv::hessian()</code>, this output preserves the names of <code>x</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Grad">Grad()</a></code> for gradients, <code><a href="#topic+GenD">GenD()</a></code> for generalised numerical differences.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- function(x) prod(sin(x))
Hessian(f, 1:4)
# Large matrices

  system.time(Hessian(f, 1:100))

</code></pre>

<hr>
<h2 id='Jacobian'>Jacobian matrix computation with parallel capabilities
s
Computes the numerical Jacobian for vector-valued functions. Its columns are
partial derivatives of the function with respect to the input elements.
This function supports both two-sided (central, symmetric) and
one-sided (forward or backward) derivatives. It can utilise parallel processing
to accelerate computation of gradients for slow functions or
to attain higher accuracy faster. Currently, only Mac and Linux are supported
<code>parallel::mclapply()</code>. Windows support with <code>parallel::parLapply()</code>
is under development.</h2><span id='topic+Jacobian'></span>

<h3>Description</h3>

<p>Jacobian matrix computation with parallel capabilities
s
Computes the numerical Jacobian for vector-valued functions. Its columns are
partial derivatives of the function with respect to the input elements.
This function supports both two-sided (central, symmetric) and
one-sided (forward or backward) derivatives. It can utilise parallel processing
to accelerate computation of gradients for slow functions or
to attain higher accuracy faster. Currently, only Mac and Linux are supported
<code>parallel::mclapply()</code>. Windows support with <code>parallel::parLapply()</code>
is under development.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Jacobian(
  FUN,
  x,
  elementwise = NA,
  vectorised = NA,
  multivalued = NA,
  deriv.order = 1L,
  side = 0,
  acc.order = 2,
  h = NULL,
  zero.tol = sqrt(.Machine$double.eps),
  h0 = NULL,
  control = list(),
  f0 = NULL,
  cores = 1,
  preschedule = TRUE,
  cl = NULL,
  func = NULL,
  report = 1L,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Jacobian_+3A_fun">FUN</code></td>
<td>
<p>A function returning a numeric scalar or a vector whose derivatives are to be
computed. If the function returns a vector, the output will be a Jacobian.</p>
</td></tr>
<tr><td><code id="Jacobian_+3A_x">x</code></td>
<td>
<p>Numeric vector or scalar: the point(s) at which the derivative is estimated.
<code>FUN(x)</code> must be finite.</p>
</td></tr>
<tr><td><code id="Jacobian_+3A_elementwise">elementwise</code></td>
<td>
<p>Logical: is the domain effectively 1D, i.e. is this a mapping
<code class="reqn">\mathbb{R} \mapsto \mathbb{R}</code> or
<code class="reqn">\mathbb{R}^n \mapsto \mathbb{R}^n</code>. If <code>NA</code>,
compares the output length ot the input length.</p>
</td></tr>
<tr><td><code id="Jacobian_+3A_vectorised">vectorised</code></td>
<td>
<p>Logical: if <code>TRUE</code>, the function
is assumed to be vectorised: it will accept a vector of parameters and return
a vector of values of the same length. Use <code>FALSE</code> or <code>"no"</code>  for
functions that take vector arguments and return outputs of arbitrary length (for
<code class="reqn">\mathbb{R}^n \mapsto \mathbb{R}^k</code> functions). If <code>NA</code>,
checks the output length and assumes vectorisation if it matches the input length;
this check is necessary and potentially slow.</p>
</td></tr>
<tr><td><code id="Jacobian_+3A_multivalued">multivalued</code></td>
<td>
<p>Logical: if <code>TRUE</code>, the function is assumed to return vectors longer
than 1. Use <code>FALSE</code> for element-wise functions. If <code>NA</code>, attempts inferring it from
the function output.</p>
</td></tr>
<tr><td><code id="Jacobian_+3A_deriv.order">deriv.order</code></td>
<td>
<p>Integer or vector of integers indicating the desired derivative order,
<code class="reqn">\mathrm{d}^m / \mathrm{d}x^m</code>, for each element of <code>x</code>.</p>
</td></tr>
<tr><td><code id="Jacobian_+3A_side">side</code></td>
<td>
<p>Integer scalar or vector indicating the type of finite difference:
<code>0</code> for central, <code>1</code> for forward, and <code>-1</code> for backward differences.
Central differences are recommended unless computational cost is prohibitive.</p>
</td></tr>
<tr><td><code id="Jacobian_+3A_acc.order">acc.order</code></td>
<td>
<p>Integer or vector of integers specifying the desired accuracy order
for each element of <code>x</code>.
The final error will be of the order <code class="reqn">O(h^{\mathrm{acc.order}})</code>.</p>
</td></tr>
<tr><td><code id="Jacobian_+3A_h">h</code></td>
<td>
<p>Numeric or character specifying the step size(s) for the numerical
difference or a method of automatic step determination (<code>"CR"</code>, <code>"CRm"</code>,
<code>"DV"</code>, or <code>"SW"</code> to be used in <code><a href="#topic+gradstep">gradstep()</a></code>). The default value is
described in <code>?GenD</code>.</p>
</td></tr>
<tr><td><code id="Jacobian_+3A_zero.tol">zero.tol</code></td>
<td>
<p>Small positive integer: if <code>abs(x) &gt;= zero.tol</code>, then, the automatically
guessed step size is relative (<code>x</code> multiplied by the step), unless an auto-selection
procedure is requested; otherwise, it is absolute.</p>
</td></tr>
<tr><td><code id="Jacobian_+3A_h0">h0</code></td>
<td>
<p>Numeric scalar of vector: initial step size for automatic search with
<code>gradstep()</code>.</p>
</td></tr>
<tr><td><code id="Jacobian_+3A_control">control</code></td>
<td>
<p>A named list of tuning parameters passed to <code>gradstep()</code>.</p>
</td></tr>
<tr><td><code id="Jacobian_+3A_f0">f0</code></td>
<td>
<p>Optional numeric: if provided, used to determine the vectorisation type
to save time. If FUN(x) must be evaluated (e.g. second derivatives), saves one evaluation.</p>
</td></tr>
<tr><td><code id="Jacobian_+3A_cores">cores</code></td>
<td>
<p>Integer specifying the number of CPU cores used for parallel computation.
Recommended to be set to the number of physical cores on the machine minus one.</p>
</td></tr>
<tr><td><code id="Jacobian_+3A_preschedule">preschedule</code></td>
<td>
<p>Logical: if <code>TRUE</code>, disables pre-scheduling for <code>mclapply()</code>
or enables load balancing with <code>parLapplyLB()</code>. Recommended for functions that
take less than 0.1 s per evaluation.</p>
</td></tr>
<tr><td><code id="Jacobian_+3A_cl">cl</code></td>
<td>
<p>An optional user-supplied <code>cluster</code> object  (created by <code>makeCluster</code>
or similar functions). If not <code>NULL</code>, the code uses <code>parLapply()</code> (if <code>preschedule</code>
is <code>TRUE</code>) or <code>parLapplyLB()</code> on that cluster on Windows, and <code>mclapply</code>
(fork cluster) on everything else.</p>
</td></tr>
<tr><td><code id="Jacobian_+3A_func">func</code></td>
<td>
<p>For compatibility with <code>numDeriv::grad()</code> only. If instead of
<code>FUN</code>, <code>func</code> is used, it will be reassigned to <code>FUN</code> with a warning.</p>
</td></tr>
<tr><td><code id="Jacobian_+3A_report">report</code></td>
<td>
<p>Integer for the level of detail in the output. If <code>0</code>,
returns a gradient without any attributes; if <code>1</code>,
attaches the step size and its selection method: <code>2</code> or higher attaches the full
diagnostic output as an attribute.</p>
</td></tr>
<tr><td><code id="Jacobian_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>FUN</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix where each row corresponds to a function output and each column
to an input coordinate. For scalar-valued functions, a warning is issued and
the output is returned as a row matrix.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GenD">GenD()</a></code>, <code><a href="#topic+Grad">Grad()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>slowFun &lt;- function(x) {Sys.sleep(0.01); sum(sin(x))}
slowFunVec &lt;- function(x) {Sys.sleep(0.01);
                           c(sin = sum(sin(x)), exp = sum(exp(x)))}
true.g &lt;- cos(1:4)  # Analytical gradient
true.j &lt;- rbind(cos(1:4), exp(1:4)) # Analytical Jacobian
x0 &lt;- c(each = 1, par = 2, is = 3, named = 4)

# Compare computation times
system.time(g.slow &lt;- numDeriv::grad(slowFun, x = x0) - true.g)
system.time(j.slow &lt;- numDeriv::jacobian(slowFunVec, x = x0) - true.j)
system.time(g.fast &lt;- Grad(slowFun, x = x0, cores = 2) - true.g)
system.time(j.fast &lt;- Jacobian(slowFunVec, x = x0, cores = 2) - true.j)
system.time(j.fast4 &lt;- Jacobian(slowFunVec, x = x0, acc.order = 4, cores = 2) - true.j)

# Compare accuracy
rownames(j.slow) &lt;- paste0("numDeriv.jac.", c("sin", "exp"))
rownames(j.fast) &lt;- paste0("pnd.jac.order2.", rownames(j.fast))
rownames(j.fast4) &lt;- paste0("pnd.jac.order4.", rownames(j.fast4))
# Discrepancy
print(rbind(numDeriv.grad = g.slow, pnd.Grad = g.fast, j.slow, j.fast, j.fast4), 2)
# The order-4 derivative is more accurate for functions
# with non-zero third and higher derivatives -- look at pnd.jac.order.4


</code></pre>

<hr>
<h2 id='plotTE'>Estimated total error plot as in Mathur (2012)</h2><span id='topic+plotTE'></span>

<h3>Description</h3>

<p>Visualises the estimated truncation error, rounding error, and total error
used in automatic step-size selection for numerical differentiation.
The plot follows the approach used in Mathur (2012) and other step-selection methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotTE(
  hgrid,
  etrunc,
  eround,
  hopt = NULL,
  i.increasing = NULL,
  i.good = NULL,
  i.okay = NULL,
  eps = .Machine$double.eps/2,
  delta = .Machine$double.eps/2,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotTE_+3A_hgrid">hgrid</code></td>
<td>
<p>Numeric vector: a sequence of step sizes used as the horizontal positions
(usually exponentially spaced).</p>
</td></tr>
<tr><td><code id="plotTE_+3A_etrunc">etrunc</code></td>
<td>
<p>Numeric vector: estimated truncation error at each step size.
This is typically computed by subtracting a more accurate finite-difference approximation from
a less accurate one.</p>
</td></tr>
<tr><td><code id="plotTE_+3A_eround">eround</code></td>
<td>
<p>Numeric vector: estimated rounding error at each step size; usually the best guess
or the upper bound is used.</p>
</td></tr>
<tr><td><code id="plotTE_+3A_hopt">hopt</code></td>
<td>
<p>Numeric scalar (optional): selected optimal step size. If provided,
a vertical line is drawn at this value.</p>
</td></tr>
<tr><td><code id="plotTE_+3A_i.increasing">i.increasing</code></td>
<td>
<p>Integer vector (optional): indices of step sizes where the
truncation error is increasing, which indicates the search range.</p>
</td></tr>
<tr><td><code id="plotTE_+3A_i.good">i.good</code></td>
<td>
<p>Integer vector (optional): indices of step sizes where the truncation
error follows the expected reduction (slope ~ accuracy order; 2 for central differences).</p>
</td></tr>
<tr><td><code id="plotTE_+3A_i.okay">i.okay</code></td>
<td>
<p>Integer vector (optional): indices where the truncation error is
acceptable but slightly deviates from the expected behaviour.</p>
</td></tr>
<tr><td><code id="plotTE_+3A_eps">eps</code></td>
<td>
<p>Numeric scalar: condition error, i.e. the error bound for the accuracy of the evaluated
function; used for labelling rounding error assumptions.</p>
</td></tr>
<tr><td><code id="plotTE_+3A_delta">delta</code></td>
<td>
<p>Numeric scalar: subtraction cancellation error, used for labelling rounding error
assumptions.</p>
</td></tr>
<tr><td><code id="plotTE_+3A_...">...</code></td>
<td>
<p>Additional graphical parameters passed to <code>plot()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nothing (invisible null).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>hgrid &lt;- 10^seq(-8, 3, 0.25)
plotTE(hgrid, etrunc = 2e-12 * hgrid^2 + 1e-14 / hgrid,
       eround = 1e-14 / hgrid, hopt = 0.4, i.increasing = 30:45, i.good = 32:45)
</code></pre>

<hr>
<h2 id='runParallel'>Run a function in parallel over a list (internal use only)</h2><span id='topic+runParallel'></span>

<h3>Description</h3>

<p>Run a function in parallel over a list (internal use only)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runParallel(FUN, x, cores = 1L, cl = NULL, preschedule = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="runParallel_+3A_fun">FUN</code></td>
<td>
<p>A function of only one argument. If there are more arguments, use
the <code>FUN2 &lt;- do.call(FUN, c(list(x), ...))</code> annd call it.</p>
</td></tr>
<tr><td><code id="runParallel_+3A_x">x</code></td>
<td>
<p>A list to parallelise the evaluation of <code>FUN</code> over: either numbers
or expressions.</p>
</td></tr>
<tr><td><code id="runParallel_+3A_cores">cores</code></td>
<td>
<p>Integer specifying the number of CPU cores used for parallel computation.
Recommended to be set to the number of physical cores on the machine minus one.</p>
</td></tr>
<tr><td><code id="runParallel_+3A_cl">cl</code></td>
<td>
<p>An optional user-supplied <code>cluster</code> object  (created by <code>makeCluster</code>
or similar functions). If not <code>NULL</code>, the code uses <code>parLapply()</code> (if <code>preschedule</code>
is <code>TRUE</code>) or <code>parLapplyLB()</code> on that cluster on Windows, and <code>mclapply</code>
(fork cluster) on everything else.</p>
</td></tr>
<tr><td><code id="runParallel_+3A_preschedule">preschedule</code></td>
<td>
<p>Logical: if <code>TRUE</code>, disables pre-scheduling for <code>mclapply()</code>
or enables load balancing with <code>parLapplyLB()</code>. Recommended for functions that
take less than 0.1 s per evaluation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value that <code>lapply(x, FUN)</code> would have returned.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fslow &lt;- function(x) Sys.sleep(x)
x &lt;- rep(0.05, 6)
cl &lt;- parallel::makeCluster(2)
print(t1 &lt;- system.time(runParallel(fslow, x)))
print(t2 &lt;- system.time(runParallel(fslow, x, cl = cl)))
print(t3 &lt;- system.time(runParallel(fslow, x, cores = 2)))
parallel::stopCluster(cl)
cat("Parallel overhead at 2 cores: ", round(t2[3]*200/t1[3]-100), "%\n", sep = "")
# Ignore on Windows
cat("makeCluster() overhead at 2 cores: ", round(100*t2[3]/t3[3]-100), "%\n", sep = "")
</code></pre>

<hr>
<h2 id='solveVandermonde'>Numerically stable non-confluent Vandermonde system solver</h2><span id='topic+solveVandermonde'></span>

<h3>Description</h3>

<p>Numerically stable non-confluent Vandermonde system solver
</p>


<h3>Usage</h3>

<pre><code class='language-R'>solveVandermonde(s, b)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="solveVandermonde_+3A_s">s</code></td>
<td>
<p>Numeric vector of stencil points defining the Vandermonde matrix on
the left-hand side, where each element <code class="reqn">S_{i, j}</code> is calculated as
<code>s[j]^(i-1)</code>.</p>
</td></tr>
<tr><td><code id="solveVandermonde_+3A_b">b</code></td>
<td>
<p>Numeric vector of the right-hand side of the equation.
This vector must be the same length as <code>s</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function utilises the (Björck and Pereyra 1970) algorithm for
an accurate solution to non-confluent Vandermonde systems,
which are known for their numerical instability. Unlike Gaussian elimination,
which suffers from ill conditioning, this algorithm achieves numerical stability
through exploiting the ordering of the stencil.
An unsorted stencils will trigger a warning.
Additionally, the stencil must contain unique points, as repeated values make
the Vandermonde matrix confluent and therefore non-invertible.
</p>
<p>This implementation is a verbatim translation of Algorithm 4.6.2 from
(Golub and Van Loan 2013), which is robust against the issues
typically associated with Vandermonde systems.
</p>
<p>See (Higham 1987) for an in-depth error analysis of this algorithm.
</p>


<h3>Value</h3>

<p>A numeric vector of coefficients solving the Vandermonde system,
matching the length of <code>s</code>.
</p>


<h3>References</h3>

<p>Björck Å, Pereyra V (1970).
&ldquo;Solution of Vandermonde systems of equations.&rdquo;
<em>Mathematics of computation</em>, <b>24</b>(112), 893&ndash;903.<br /><br /> Golub GH, Van Loan CF (2013).
<em>Matrix computations</em>, 4 edition.
Johns Hopkins University Press.<br /><br /> Higham NJ (1987).
&ldquo;Error analysis of the Björck-Pereyra algorithms for solving Vandermonde systems.&rdquo;
<em>Numerische Mathematik</em>, <b>50</b>(5), 613&ndash;632.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Approximate the 4th derivatives on a non-negative stencil
solveVandermonde(s = 0:5, b = c(0, 0, 0, 0, 24, 0))

# Small numerical inaccuracies: note the 6.66e-15 in the 4th position --
# it should be rounded towards zero:
solveVandermonde(s = -3:3, b = c(0, 1, rep(0, 5))) * 60
</code></pre>

<hr>
<h2 id='step.CR'>Curtis&ndash;Reid automatic step selection</h2><span id='topic+step.CR'></span>

<h3>Description</h3>

<p>Curtis&ndash;Reid automatic step selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step.CR(
  FUN,
  x,
  h0 = 1e-05 * max(abs(x), sqrt(.Machine$double.eps)),
  version = c("original", "modified"),
  aim = if (version[1] == "original") 100 else 1,
  acc.order = c(2L, 4L),
  tol = if (version[1] == "original") 10 else 4,
  range = h0/c(1e+05, 1e-05),
  maxit = 20L,
  seq.tol = 1e-04,
  cores = 1,
  preschedule = getOption("pnd.preschedule", TRUE),
  cl = NULL,
  diagnostics = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="step.CR_+3A_fun">FUN</code></td>
<td>
<p>Function for which the optimal numerical derivative step size is needed.</p>
</td></tr>
<tr><td><code id="step.CR_+3A_x">x</code></td>
<td>
<p>Numeric scalar: the point at which the derivative is computed and the optimal step size is estimated.</p>
</td></tr>
<tr><td><code id="step.CR_+3A_h0">h0</code></td>
<td>
<p>Numeric scalar: initial step size, defaulting to a relative step of
slightly greater than .Machine$double.eps^(1/3) (or absolute step if <code>x == 0</code>).</p>
</td></tr>
<tr><td><code id="step.CR_+3A_version">version</code></td>
<td>
<p>Character scalar: <code>"original"</code> for the original 1974 version by
Curtis and Reid; <code>"modified"</code> for Kostyrka’s 2025 modification, which adds an
extra evaluation for a more accurate estimate of the truncation error.</p>
</td></tr>
<tr><td><code id="step.CR_+3A_aim">aim</code></td>
<td>
<p>Positive real scalar: desired ratio of truncation-to-rounding error. The <code>"original"</code>
version over-estimates the truncation error, hence a higher <code>aim</code> is recommended.
For the <code>"modified"</code> version, aim should be close to 1.</p>
</td></tr>
<tr><td><code id="step.CR_+3A_acc.order">acc.order</code></td>
<td>
<p>Numeric scalar: in the modified version, allows searching for a
step size that would be optimal for a 4th-order-accurate central difference
See the Details section below.</p>
</td></tr>
<tr><td><code id="step.CR_+3A_tol">tol</code></td>
<td>
<p>Numeric scalar greater than 1: tolerance multiplier for determining when to stop
the algorithm based on the current estimate being between <code>aim/tol</code> and <code>aim*tol</code>.</p>
</td></tr>
<tr><td><code id="step.CR_+3A_range">range</code></td>
<td>
<p>Numeric vector of length 2 defining the valid search range for the step size.</p>
</td></tr>
<tr><td><code id="step.CR_+3A_maxit">maxit</code></td>
<td>
<p>Integer: maximum number of algorithm iterations to prevent infinite
loops in degenerate cases.</p>
</td></tr>
<tr><td><code id="step.CR_+3A_seq.tol">seq.tol</code></td>
<td>
<p>Numeric scalar: maximum relative difference between old and new
step sizes for declaring convergence.</p>
</td></tr>
<tr><td><code id="step.CR_+3A_cores">cores</code></td>
<td>
<p>Integer specifying the number of CPU cores used for parallel computation.
Recommended to be set to the number of physical cores on the machine minus one.</p>
</td></tr>
<tr><td><code id="step.CR_+3A_preschedule">preschedule</code></td>
<td>
<p>Logical: if <code>TRUE</code>, disables pre-scheduling for <code>mclapply()</code>
or enables load balancing with <code>parLapplyLB()</code>. Recommended for functions that
take less than 0.1 s per evaluation.</p>
</td></tr>
<tr><td><code id="step.CR_+3A_cl">cl</code></td>
<td>
<p>An optional user-supplied <code>cluster</code> object  (created by <code>makeCluster</code>
or similar functions). If not <code>NULL</code>, the code uses <code>parLapply()</code> (if <code>preschedule</code>
is <code>TRUE</code>) or <code>parLapplyLB()</code> on that cluster on Windows, and <code>mclapply</code>
(fork cluster) on everything else.</p>
</td></tr>
<tr><td><code id="step.CR_+3A_diagnostics">diagnostics</code></td>
<td>
<p>Logical: if <code>TRUE</code>, returns the full iteration history
including all function evaluations.</p>
</td></tr>
<tr><td><code id="step.CR_+3A_...">...</code></td>
<td>
<p>Passed to <code>FUN</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the optimal step size for central differences using the
(Curtis and Reid 1974) algorithm.
If the estimated third derivative is exactly zero, then, the initial step size
is multiplied by 4 and returned.
</p>
<p>If 4th-order accuracy (4OA) is requested, then, two things happen. Firstly,
since 4OA differences requires a larger step size and the truncation error for
the 2OA differences grows if the step size is larger than the optimal one,
a higher ratio of truncation-to-rounding errors should be targeted. Secondly,
a 4OA numerical derivative is returned, but the truncation and rounding errors
are still estimated for the 2OA differences. Therefore, the estimating truncation
error is higher and the real truncation error of 4OA differences is lower.
</p>
<p>TODO: mention that f must be one-dimensional
</p>
<p>The arguments passed to <code>...</code> must not partially match those of <code><a href="#topic+step.CR">step.CR()</a></code>. For example, if
<code>cl</code> exists, then, attempting to avoid cluster export by using
<code>step.CR(f, x, h = 1e-4, cl = cl, a = a)</code> will result in an error: <code>a</code> matches <code>aim</code>
and <code>acc.order</code>. Redefine the function for this argument to have a name that is not equal
to the beginning of one of the arguments of <code><a href="#topic+step.CR">step.CR()</a></code>.
</p>


<h3>Value</h3>

<p>A list similar to the one returned by <code>optim()</code>: <code>par</code> &ndash; the optimal
step size found, <code>value</code> &ndash; the estimated numerical first derivative (central differences;
very useful for computationally expensive functions), <code>counts</code> &ndash; the number of
iterations (each iteration includes three function evaluations), <code>abs.error</code> &ndash;
an estimate of the total approximation error (sum of truncation and rounding errors),
<code>exitcode</code> &ndash; an integer code indicating the termination status:
<code>0</code> indicates optimal termination within tolerance,
<code>1</code> means that the third derivative is zero (large step size preferred),
<code>2</code> is returned if there is no change in step size within tolerance,
<code>3</code> indicates a solution at the boundary of the allowed value range,
<code>4</code> signals that the maximum number of iterations was reached.
<code>message</code> &ndash; a summary message of the exit status.
If <code>diagnostics</code> is <code>TRUE</code>, <code>iterations</code> is a list
including the full step size search path, argument grids, function values on
those grids, estimated error ratios, and estimated derivative values.
</p>


<h3>References</h3>

<p>Curtis AR, Reid JK (1974).
&ldquo;The Choice of Step Lengths When Using Differences to Approximate Jacobian Matrices.&rdquo;
<em>IMA Journal of Applied Mathematics</em>, <b>13</b>(1), 121&ndash;126.
<a href="https://doi.org/10.1093/imamat/13.1.121">doi:10.1093/imamat/13.1.121</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- function(x) x^4
step.CR(x = 2, f)
step.CR(x = 2, f, h0 = 1e-3, diagnostics = TRUE)
step.CR(x = 2, f, version = "modified")
step.CR(x = 2, f, version = "modified", acc.order = 4)

# A bad start: too far away
step.CR(x = 2, f, h0 = 1000)  # Bad exit code + a suggestion to extend the range
step.CR(x = 2, f, h0 = 1000, range = c(1e-10, 1e5))  # Problem solved

library(parallel)
cl &lt;- makePSOCKcluster(names = 2, outfile = "")
abc &lt;- 2
f &lt;- function(x, abc) {Sys.sleep(0.02); abc*sin(x)}
x &lt;- pi/4
system.time(step.CR(f, x, h = 1e-4, cores = 1, abc = abc))  # To remove speed-ups
system.time(step.CR(f, x, h = 1e-4, cores = 2, abc = abc))  # Faster
f2 &lt;- function(x) f(x, abc)
clusterExport(cl, c("f2", "f", "abc"))
system.time(step.CR(f2, x, h = 1e-4, cl = cl))  # Also fast
stopCluster(cl)
</code></pre>

<hr>
<h2 id='step.DV'>Dumontet&ndash;Vignes automatic step selection</h2><span id='topic+step.DV'></span>

<h3>Description</h3>

<p>Dumontet&ndash;Vignes automatic step selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step.DV(
  FUN,
  x,
  h0 = 1e-05 * max(abs(x), sqrt(.Machine$double.eps)),
  range = h0/c(1e+06, 1e-06),
  alpha = 4/3,
  ratio.limits = c(1/15, 1/2, 2, 15),
  maxit = 40L,
  cores = 1,
  preschedule = getOption("pnd.preschedule", TRUE),
  cl = NULL,
  diagnostics = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="step.DV_+3A_fun">FUN</code></td>
<td>
<p>Function for which the optimal numerical derivative step size is needed.</p>
</td></tr>
<tr><td><code id="step.DV_+3A_x">x</code></td>
<td>
<p>Numeric scalar: the point at which the derivative is computed and the optimal step size is estimated.</p>
</td></tr>
<tr><td><code id="step.DV_+3A_h0">h0</code></td>
<td>
<p>Numeric scalar: initial step size, defaulting to a relative step of
slightly greater than .Machine$double.eps^(1/3) (or absolute step if <code>x == 0</code>). This step
size for first derivarives is internallt translated into the initial step size for third
derivatives by multiplying it by the machine epsilon raised to the power -2/15.</p>
</td></tr>
<tr><td><code id="step.DV_+3A_range">range</code></td>
<td>
<p>Numeric vector of length 2 defining the valid search range for the step size.</p>
</td></tr>
<tr><td><code id="step.DV_+3A_alpha">alpha</code></td>
<td>
<p>Numeric scalar &gt;= 1 indicating the relative reduction in the
number of accurate bits due to the calculation of <code>FUN</code>. A value of <code>1</code>
implies that <code>FUN(x)</code> is assumed to have all bits accurate with maximum relative
error of <code>.Machine$double.eps/2</code>. A value of <code>2</code> indicates that the number of
accurate bits is half the mantissa length, <code>4</code> if it is quarter etc. The algorithm authors
recommend <code>4/3</code> even for highly accurate functions.</p>
</td></tr>
<tr><td><code id="step.DV_+3A_ratio.limits">ratio.limits</code></td>
<td>
<p>Numeric vector of length 4 defining the acceptable ranges
for step size: the algorithm stops if the relative perturbation of the third derivative by
amplified rounding errors falls either between the 1st and 2nd elements or between
the 3rd and 4th elements.</p>
</td></tr>
<tr><td><code id="step.DV_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of algorithm iterations to avoid infinite loops in cases
the desired relative perturbation factor cannot be achieved within the given <code>range</code>.
Consider extending the range if this limit is reached.</p>
</td></tr>
<tr><td><code id="step.DV_+3A_cores">cores</code></td>
<td>
<p>Integer specifying the number of CPU cores used for parallel computation.
Recommended to be set to the number of physical cores on the machine minus one.</p>
</td></tr>
<tr><td><code id="step.DV_+3A_preschedule">preschedule</code></td>
<td>
<p>Logical: if <code>TRUE</code>, disables pre-scheduling for <code>mclapply()</code>
or enables load balancing with <code>parLapplyLB()</code>. Recommended for functions that
take less than 0.1 s per evaluation.</p>
</td></tr>
<tr><td><code id="step.DV_+3A_cl">cl</code></td>
<td>
<p>An optional user-supplied <code>cluster</code> object  (created by <code>makeCluster</code>
or similar functions). If not <code>NULL</code>, the code uses <code>parLapply()</code> (if <code>preschedule</code>
is <code>TRUE</code>) or <code>parLapplyLB()</code> on that cluster on Windows, and <code>mclapply</code>
(fork cluster) on everything else.</p>
</td></tr>
<tr><td><code id="step.DV_+3A_diagnostics">diagnostics</code></td>
<td>
<p>Logical: if <code>TRUE</code>, returns the full iteration history
including all function evaluations.
Note: the history tracks the third derivative, not the first.</p>
</td></tr>
<tr><td><code id="step.DV_+3A_...">...</code></td>
<td>
<p>Passed to FUN.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the optimal step size for central differences using the
(Dumontet and Vignes 1977) algorithm.
If the estimated third derivative is exactly zero, the function assumes a third
derivative of 1 to prevent division-by-zero errors.
</p>


<h3>Value</h3>

<p>A list similar to the one returned by <code>optim()</code>: <code>par</code> &ndash; the optimal
step size found, <code>value</code> &ndash; the estimated numerical first derivative (central
differences), <code>counts</code> &ndash; the number of iterations (each iteration includes
four function evaluations), <code>abs.error</code> &ndash; an estimate of the total
approximation error (sum of truncation and rounding errors),
<code>exitcode</code> &ndash; an integer code indicating the termination status:
<code>0</code> indicates optimal termination within tolerance,
<code>1</code> means that the third derivative is zero (large step size preferred),
<code>3</code> indicates a solution at the boundary of the allowed value range,
<code>4</code> signals that the maximum number of iterations was reached and the
found optimal step size belongs to the allowed range,
<code>5</code> occurs when the maximum number of iterations was reached and the
found optimal step size did belong to the allowed range and had to be snapped
to one end.
<code>6</code> is used when <code>maxit = 1</code> and no search was performed.
<code>message</code> is a summary message of the exit status.
If <code>diagnostics</code> is <code>TRUE</code>, <code>iterations</code> is a list
including the full step size search path (NB: for the 3rd derivative),
argument grids, function values on those grids, and estimated 3rd derivative values.
</p>


<h3>References</h3>

<p>Dumontet J, Vignes J (1977).
&ldquo;Détermination du pas optimal dans le calcul des dérivées sur ordinateur.&rdquo;
<em>RAIRO. Analyse numérique</em>, <b>11</b>(1), 13&ndash;25.
<a href="https://doi.org/10.1051/m2an/1977110100131">doi:10.1051/m2an/1977110100131</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- function(x) x^4
step.DV(x = 2, f)
step.DV(x = 2, f, h0 = 1e-3, diagnostics = TRUE)

# Plug-in estimator with only one evaluation of f'''
step.DV(x = 2, f, maxit = 1)
</code></pre>

<hr>
<h2 id='step.M'>Mathur's AutoDX-like automatic step selection</h2><span id='topic+step.M'></span>

<h3>Description</h3>

<p>Mathur's AutoDX-like automatic step selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step.M(
  FUN,
  x,
  h0 = NULL,
  range = NULL,
  shrink.factor = 0.5,
  min.valid.slopes = 5L,
  seq.tol = 0.01,
  correction = TRUE,
  diagnostics = FALSE,
  plot = FALSE,
  cores = 1,
  preschedule = getOption("pnd.preschedule", TRUE),
  cl = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="step.M_+3A_fun">FUN</code></td>
<td>
<p>Function for which the optimal numerical derivative step size is needed.</p>
</td></tr>
<tr><td><code id="step.M_+3A_x">x</code></td>
<td>
<p>Numeric scalar: the point at which the derivative is computed and the optimal step size is estimated.</p>
</td></tr>
<tr><td><code id="step.M_+3A_h0">h0</code></td>
<td>
<p>Numeric scalar: initial step size, defaulting to a relative step of
slightly greater than .Machine$double.eps^(1/3) (or absolute step if <code>x == 0</code>).</p>
</td></tr>
<tr><td><code id="step.M_+3A_range">range</code></td>
<td>
<p>Numeric vector of length 2 defining the valid search range for the step size.</p>
</td></tr>
<tr><td><code id="step.M_+3A_shrink.factor">shrink.factor</code></td>
<td>
<p>A scalar less than 1 that is used to create a sequence of
step sizes. The recommended value is 0.5. Change to 0.25 for a faster search. This
number should be a negative power of 2 for the most accurate representation.</p>
</td></tr>
<tr><td><code id="step.M_+3A_min.valid.slopes">min.valid.slopes</code></td>
<td>
<p>Positive integer: how many points must form a sequence
with the correct slope with relative difference from 2 less than <code>seq.tol</code>.
If <code>shrink.factor</code> is small (&lt; 0.33), consider reducing this to 4.</p>
</td></tr>
<tr><td><code id="step.M_+3A_seq.tol">seq.tol</code></td>
<td>
<p>Numeric scalar: maximum relative difference between old and new
step sizes for declaring convergence.</p>
</td></tr>
<tr><td><code id="step.M_+3A_correction">correction</code></td>
<td>
<p>Logical: if <code>TRUE</code>, returns the corrected step size (last
point in the sequence times a less-than-1 number to account for the possible
continuation of the downwards slope of the total error); otherwise, returns
the grid point that is is lowest in the increasing sequence of valid error
estimates.</p>
</td></tr>
<tr><td><code id="step.M_+3A_diagnostics">diagnostics</code></td>
<td>
<p>Logical: if <code>TRUE</code>, returns the full iteration history
including all function evaluations.</p>
</td></tr>
<tr><td><code id="step.M_+3A_plot">plot</code></td>
<td>
<p>Logical: if <code>TRUE</code>, plots the estimated truncation and round-off
errors.</p>
</td></tr>
<tr><td><code id="step.M_+3A_cores">cores</code></td>
<td>
<p>Integer specifying the number of CPU cores used for parallel computation.
Recommended to be set to the number of physical cores on the machine minus one.</p>
</td></tr>
<tr><td><code id="step.M_+3A_preschedule">preschedule</code></td>
<td>
<p>Logical: if <code>TRUE</code>, disables pre-scheduling for <code>mclapply()</code>
or enables load balancing with <code>parLapplyLB()</code>. Recommended for functions that
take less than 0.1 s per evaluation.</p>
</td></tr>
<tr><td><code id="step.M_+3A_cl">cl</code></td>
<td>
<p>An optional user-supplied <code>cluster</code> object  (created by <code>makeCluster</code>
or similar functions). If not <code>NULL</code>, the code uses <code>parLapply()</code> (if <code>preschedule</code>
is <code>TRUE</code>) or <code>parLapplyLB()</code> on that cluster on Windows, and <code>mclapply</code>
(fork cluster) on everything else.</p>
</td></tr>
<tr><td><code id="step.M_+3A_...">...</code></td>
<td>
<p>Passed to FUN.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the optimal step size for central differences using the
(Mathur 2012) algorithm.
</p>


<h3>Value</h3>

<p>A list similar to the one returned by <code>optim()</code>: <code>par</code> &ndash; the optimal
step size found, <code>value</code> &ndash; the estimated numerical first derivative (central
differences), <code>counts</code> &ndash; the number of iterations (each iteration includes
two function evaluations), <code>abs.error</code> &ndash; an estimate of the total
approximation error (sum of truncation and rounding errors),
<code>exitcode</code> &ndash; an integer code indicating the termination status:
<code>0</code> indicates optimal termination due to a sequence of correct reductions,
<code>1</code> indicates that the reductions are slightly not within tolerance,
<code>2</code> indicates that the tolerances are so wrong, an approximate minimum is returned,
<code>3</code> signals that there are not enough finite function values and the rule of thumb is returned.
<code>message</code> is a summary message of the exit status.
If <code>diagnostics</code> is <code>TRUE</code>, <code>iterations</code> is a list
including the full step size search path,
argument grids, function values on those grids, estimated derivative values,
estimated error values, and monotonicity check results.
</p>


<h3>References</h3>

<p>Mathur R (2012).
<em>An Analytical Approach to Computing Step Sizes for Finite-Difference Derivatives</em>.
Ph.D. thesis, University of Texas at Austin.
<a href="http://hdl.handle.net/2152/ETD-UT-2012-05-5275">http://hdl.handle.net/2152/ETD-UT-2012-05-5275</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- function(x) x^4  # The derivative at 1 is 4
step.M(x = 1, f, plot = TRUE)
step.M(x = 1, f, h0 = 1e-9) # Starting low
step.M(x = 1, f, h0 = 1000) # Starting high

f &lt;- sin  # The derivative at pi/4 is sqrt(2)/2
step.M(x = pi/2, f, plot = TRUE)  # Bad case -- TODO a fix
step.M(x = pi/4, f, plot = TRUE)
step.M(x = pi/4, f, h0 = 1e-9) # Starting low
step.M(x = pi/4, f, h0 = 1000) # Starting high
# where the truncation error estimate is invalid
</code></pre>

<hr>
<h2 id='step.plugin'>Plug-in step selection</h2><span id='topic+step.plugin'></span>

<h3>Description</h3>

<p>Plug-in step selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step.plugin(
  FUN,
  x,
  h0 = 1e-05 * max(abs(x), sqrt(.Machine$double.eps)),
  range = h0/c(10000, 1e-04),
  cores = 1,
  preschedule = getOption("pnd.preschedule", TRUE),
  cl = NULL,
  diagnostics = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="step.plugin_+3A_fun">FUN</code></td>
<td>
<p>Function for which the optimal numerical derivative step size is needed.</p>
</td></tr>
<tr><td><code id="step.plugin_+3A_x">x</code></td>
<td>
<p>Numeric scalar: the point at which the derivative is computed and the optimal step size is estimated.</p>
</td></tr>
<tr><td><code id="step.plugin_+3A_h0">h0</code></td>
<td>
<p>Numeric scalar: initial step size, defaulting to a relative step of
slightly greater than .Machine$double.eps^(1/3) (or absolute step if <code>x == 0</code>). This step
size for first derivarives is internallt translated into the initial step size for third
derivatives by multiplying it by the machine epsilon raised to the power -2/15.</p>
</td></tr>
<tr><td><code id="step.plugin_+3A_range">range</code></td>
<td>
<p>Numeric vector of length 2 defining the valid search range for the step size.</p>
</td></tr>
<tr><td><code id="step.plugin_+3A_cores">cores</code></td>
<td>
<p>Integer specifying the number of CPU cores used for parallel computation.
Recommended to be set to the number of physical cores on the machine minus one.</p>
</td></tr>
<tr><td><code id="step.plugin_+3A_preschedule">preschedule</code></td>
<td>
<p>Logical: if <code>TRUE</code>, disables pre-scheduling for <code>mclapply()</code>
or enables load balancing with <code>parLapplyLB()</code>. Recommended for functions that
take less than 0.1 s per evaluation.</p>
</td></tr>
<tr><td><code id="step.plugin_+3A_cl">cl</code></td>
<td>
<p>An optional user-supplied <code>cluster</code> object  (created by <code>makeCluster</code>
or similar functions). If not <code>NULL</code>, the code uses <code>parLapply()</code> (if <code>preschedule</code>
is <code>TRUE</code>) or <code>parLapplyLB()</code> on that cluster on Windows, and <code>mclapply</code>
(fork cluster) on everything else.</p>
</td></tr>
<tr><td><code id="step.plugin_+3A_diagnostics">diagnostics</code></td>
<td>
<p>Logical: if <code>TRUE</code>, returns the full iteration history
including all function evaluations.
Note: the history tracks the third derivative, not the first.</p>
</td></tr>
<tr><td><code id="step.plugin_+3A_...">...</code></td>
<td>
<p>Passed to FUN.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the optimal step size for central differences using the
plug-in approach.
The optimal step size is determined as the minimiser of the total error, which for central
finite differences is (assuming minimal bounds for relative rounding errors)
</p>
<p style="text-align: center;"><code class="reqn">\sqrt[3]{1.5 \frac{f'(x)}{f'''(x) \epsilon_{\mathrm{mach}}}}</code>
</p>

<p>If the estimated third derivative is too small, the function assumes a third
derivative of 1 to prevent division-by-zero errors.
</p>


<h3>Value</h3>

<p>A list similar to the one returned by <code>optim()</code>: <code>par</code> &ndash; the optimal
step size found, <code>value</code> &ndash; the estimated numerical first derivative (central
differences), <code>counts</code> &ndash; the number of iterations (here, it is 2),
<code>abs.error</code> &ndash; an estimate of the total approximation error (sum of truncation and
rounding errors),
<code>exitcode</code> &ndash; an integer code indicating the termination status:
<code>0</code> indicates termination with checks passed tolerance,
<code>1</code> means that the third derivative is exactly zero (large step size preferred),
<code>2</code> signals that the third derivative is too close to zero (large step size preferred),
<code>3</code> indicates a solution at the boundary of the allowed value range.
<code>message</code> is a summary message of the exit status.
If <code>diagnostics</code> is <code>TRUE</code>, <code>iterations</code> is a list
including the two-step size search path, argument grids, function values on those grids,
and estimated 3rd derivative values.
</p>


<h3>References</h3>

<p>There are no references for Rd macro <code style="white-space: pre;">&#8288;\insertAllCites&#8288;</code> on this help page.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- function(x) x^4
step.plugin(x = 2, f)
step.plugin(x = 0, f, diagnostics = TRUE)  # f''' = 0, setting a large one
</code></pre>

<hr>
<h2 id='step.SW'>Stepleman&ndash;Winarsky automatic step selection</h2><span id='topic+step.SW'></span>

<h3>Description</h3>

<p>Stepleman&ndash;Winarsky automatic step selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step.SW(
  FUN,
  x,
  h0 = 1e-05 * (abs(x) + (x == 0)),
  shrink.factor = 0.5,
  range = h0/c(1e+12, 1e-08),
  seq.tol = 1e-04,
  max.rel.error = .Machine$double.eps/2,
  maxit = 40L,
  cores = 1,
  preschedule = getOption("pnd.preschedule", TRUE),
  cl = NULL,
  diagnostics = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="step.SW_+3A_fun">FUN</code></td>
<td>
<p>Function for which the optimal numerical derivative step size is needed.</p>
</td></tr>
<tr><td><code id="step.SW_+3A_x">x</code></td>
<td>
<p>Numeric scalar: the point at which the derivative is computed and the optimal step size is estimated.</p>
</td></tr>
<tr><td><code id="step.SW_+3A_h0">h0</code></td>
<td>
<p>Numeric scalar: initial step size, defaulting to a relative step of
slightly greater than .Machine$double.eps^(1/3) (or absolute step if <code>x == 0</code>).</p>
</td></tr>
<tr><td><code id="step.SW_+3A_shrink.factor">shrink.factor</code></td>
<td>
<p>A scalar less than 1 that is used to multiply the step size
during the search. The authors recommend 0.25, but this may be result in earlier
termination at slightly sub-optimal steps. Change to 0.5 for a more thorough search.</p>
</td></tr>
<tr><td><code id="step.SW_+3A_range">range</code></td>
<td>
<p>Numeric vector of length 2 defining the valid search range for the step size.</p>
</td></tr>
<tr><td><code id="step.SW_+3A_seq.tol">seq.tol</code></td>
<td>
<p>Numeric scalar: maximum relative difference between old and new
step sizes for declaring convergence.</p>
</td></tr>
<tr><td><code id="step.SW_+3A_max.rel.error">max.rel.error</code></td>
<td>
<p>Positive numeric scalar &gt; 0 indicating the maximum relative
error of function evaluation. For highly accurate functions with all accurate bits
is equal to half of machine epsilon. For noisy functions (derivatives, integrals,
output of optimisation routines etc.), it is higher.</p>
</td></tr>
<tr><td><code id="step.SW_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of algorithm iterations to avoid infinite loops.
Consider trying some smaller or larger initial step size <code>h0</code>
if this limit is reached.</p>
</td></tr>
<tr><td><code id="step.SW_+3A_cores">cores</code></td>
<td>
<p>Integer specifying the number of CPU cores used for parallel computation.
Recommended to be set to the number of physical cores on the machine minus one.</p>
</td></tr>
<tr><td><code id="step.SW_+3A_preschedule">preschedule</code></td>
<td>
<p>Logical: if <code>TRUE</code>, disables pre-scheduling for <code>mclapply()</code>
or enables load balancing with <code>parLapplyLB()</code>. Recommended for functions that
take less than 0.1 s per evaluation.</p>
</td></tr>
<tr><td><code id="step.SW_+3A_cl">cl</code></td>
<td>
<p>An optional user-supplied <code>cluster</code> object  (created by <code>makeCluster</code>
or similar functions). If not <code>NULL</code>, the code uses <code>parLapply()</code> (if <code>preschedule</code>
is <code>TRUE</code>) or <code>parLapplyLB()</code> on that cluster on Windows, and <code>mclapply</code>
(fork cluster) on everything else.</p>
</td></tr>
<tr><td><code id="step.SW_+3A_diagnostics">diagnostics</code></td>
<td>
<p>Logical: if <code>TRUE</code>, returns the full iteration history
including all function evaluations.</p>
</td></tr>
<tr><td><code id="step.SW_+3A_...">...</code></td>
<td>
<p>Passed to FUN.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the optimal step size for central differences using the
(Stepleman and Winarsky 1979) algorithm.
</p>


<h3>Value</h3>

<p>A list similar to the one returned by <code>optim()</code>: <code>par</code> &ndash; the optimal
step size found, <code>value</code> &ndash; the estimated numerical first derivative (central
differences), <code>counts</code> &ndash; the number of iterations (each iteration includes
four function evaluations), <code>abs.error</code> &ndash; an estimate of the total
approximation error (sum of truncation and rounding errors),
<code>exitcode</code> &ndash; an integer code indicating the termination status:
<code>0</code> indicates optimal termination within tolerance,
<code>2</code> is returned if there is no change in step size within tolerance,
<code>3</code> indicates a solution at the boundary of the allowed value range,
<code>4</code> signals that the maximum number of iterations was reached.
<code>message</code> is a summary message of the exit status.
If <code>diagnostics</code> is <code>TRUE</code>, <code>iterations</code> is a list
including the full step size search path,
argument grids, function values on those grids, estimated derivative values,
estimated error values, and monotonicity check results.
</p>


<h3>References</h3>

<p>Stepleman RS, Winarsky ND (1979).
&ldquo;Adaptive numerical differentiation.&rdquo;
<em>Mathematics of Computation</em>, <b>33</b>(148), 1257&ndash;1264.
<a href="https://doi.org/10.1090/s0025-5718-1979-0537969-8">doi:10.1090/s0025-5718-1979-0537969-8</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- function(x) x^4  # The derivative at 1 is 4
step.SW(x = 1, f)
step.SW(x = 1, f, h0 = 1e-9, diagnostics = TRUE) # Starting too low
# Starting somewhat high leads to too many preliminary iterations
step.SW(x = 1, f, h0 = 10, diagnostics = TRUE)
step.SW(x = 1, f, h0 = 1000, diagnostics = TRUE) # Starting absurdly high

f &lt;- sin  # The derivative at pi/4 is sqrt(2)/2
step.SW(x = pi/4, f)
step.SW(x = pi/4, f, h0 = 1e-9, diagnostics = TRUE) # Starting too low
step.SW(x = pi/4, f, h0 = 0.1, diagnostics = TRUE) # Starting slightly high
# The following two example fail because the truncation error estimate is invalid
step.SW(x = pi/4, f, h0 = 10, diagnostics = TRUE)   # Warning
step.SW(x = pi/4, f, h0 = 1000, diagnostics = TRUE) # Warning
</code></pre>

<hr>
<h2 id='stepx'>Default step size at given points</h2><span id='topic+stepx'></span>

<h3>Description</h3>

<p>Default step size at given points
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stepx(x, deriv.order = 1, acc.order = 2, zero.tol = sqrt(.Machine$double.eps))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stepx_+3A_x">x</code></td>
<td>
<p>Numeric vector or scalar: the point(s) at which the derivative is estimated.
<code>FUN(x)</code> must be finite.</p>
</td></tr>
<tr><td><code id="stepx_+3A_deriv.order">deriv.order</code></td>
<td>
<p>Integer or vector of integers indicating the desired derivative order,
<code class="reqn">\mathrm{d}^m / \mathrm{d}x^m</code>, for each element of <code>x</code>.</p>
</td></tr>
<tr><td><code id="stepx_+3A_acc.order">acc.order</code></td>
<td>
<p>Integer or vector of integers specifying the desired accuracy order
for each element of <code>x</code>.
The final error will be of the order <code class="reqn">O(h^{\mathrm{acc.order}})</code>.</p>
</td></tr>
<tr><td><code id="stepx_+3A_zero.tol">zero.tol</code></td>
<td>
<p>Small positive integer: if <code>abs(x) &gt;= zero.tol</code>, then, the automatically
guessed step size is relative (<code>x</code> multiplied by the step), unless an auto-selection
procedure is requested; otherwise, it is absolute.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of the same length as <code>x</code> with positve step sizes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>stepx(10^(-10:2))
stepx(10^(-10:2), deriv.order = 2, acc.order = 4)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
