<!DOCTYPE html><html><head><title>Help for package india</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {india}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cooks.distance'><p>Cook's distances</p></a></li>
<li><a href='#leverages'><p>Leverages</p></a></li>
<li><a href='#logLik.displacement'><p>Likelihood Displacement</p></a></li>
<li><a href='#portland'><p>Portland cement dataset</p></a></li>
<li><a href='#relative.condition'><p>Relative change in the condition number</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1</td>
</tr>
<tr>
<td>Title:</td>
<td>Influence Diagnostics in Statistical Models</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-11-01</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Felipe Osorio &lt;felipe.osorios@usm.cl&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Set of routines for influence diagnostics by using case-deletion in ordinary least 
    squares, ridge estimation [Walker and Birch (1988). &lt;<a href="https://doi.org/10.1080%2F00401706.1988.10488370">doi:10.1080/00401706.1988.10488370</a>&gt;] and 
    least absolute deviations (LAD) regression [Sun and Wei (2004). &lt;<a href="https://doi.org/10.1016%2Fj.spl.2003.08.018">doi:10.1016/j.spl.2003.08.018</a>&gt;].</td>
</tr>
<tr>
<td>Depends:</td>
<td>R(&ge; 3.5.0), fastmatrix, L1pack</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-01 23:17:02 UTC; root</td>
</tr>
<tr>
<td>Author:</td>
<td>Felipe Osorio <a href="https://orcid.org/0000-0002-4675-5201"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-02 07:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='cooks.distance'>Cook's distances</h2><span id='topic+cooks.distance.lad'></span><span id='topic+cooks.distance.ols'></span><span id='topic+cooks.distance.ridge'></span>

<h3>Description</h3>

<p>Cook's distance is a measure to assess the influence of the <em>i</em>th observation on the 
model parameter estimates. This function computes the Cook's distance based on leave-one-out 
cases deletion for ordinary least squares, lad and ridge regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'lad'
cooks.distance(model, ...)
  ## S3 method for class 'ols'
cooks.distance(model, ...)
  ## S3 method for class 'ridge'
cooks.distance(model, type = "cov", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cooks.distance_+3A_model">model</code></td>
<td>
<p> an <span class="rlang"><b>R</b></span> object, returned by <code>ols</code>, <code>lad</code> or <code><a href="survival.html#topic+ridge">ridge</a></code>.</p>
</td></tr>
<tr><td><code id="cooks.distance_+3A_type">type</code></td>
<td>
<p> only required for <code>'ridge'</code> objects, options available are <code>"1st"</code>, 
<code>"cov"</code> and <code>"both"</code> to obtain the Cook's distance based on Equation (2.5), (2.6) or 
both by Walker and Birch (1988), respectively.</p>
</td></tr>
<tr><td><code id="cooks.distance_+3A_...">...</code></td>
<td>
<p> further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector whose <em>i</em>th element contains the Cook's distance,
</p>
<p style="text-align: center;"><code class="reqn">D_i(\bold{M},c) = \frac{(\hat{\bold{\beta}}_{(i)} - \hat{\bold{\beta}})^T\bold{M}
  (\hat{\bold{\beta}}_{(i)} - \hat{\bold{\beta}})}{c},</code>
</p>

<p>for <code class="reqn">i = 1,\dots,n</code>, with <code class="reqn">\bold{M}</code> a positive definite matrix and <code class="reqn">c &gt; 0</code>. Specific 
choices of <code class="reqn">\bold{M}</code> and <code class="reqn">c</code> are done for objects of class <code>ols</code>, <code>lad</code> and 
<code>ridge</code>.
</p>


<h3>References</h3>

<p>Cook, R.D., Weisberg, S. (1980).
Characterizations of an empirical influence function for detecting influential cases in regression.
<em>Technometrics</em> <b>22</b>, 495-508.
<a href="https://doi.org/10.1080/00401706.1980.10486199">doi:10.1080/00401706.1980.10486199</a>
</p>
<p>Cook, R.D., Weisberg, S. (1982).
<em>Residuals and Influence in Regression</em>.
Chapman and Hall, London.
</p>
<p>Sun, R.B., Wei, B.C. (2004).
On influence assessment for LAD regression.
<em>Statistics &amp; Probability Letters</em> <b>67</b>, 97-110.
<a href="https://doi.org/10.1016/j.spl.2003.08.018">doi:10.1016/j.spl.2003.08.018</a>.
</p>
<p>Walker, E., Birch, J.B. (1988).
Influence measures in ridge regression.
<em>Technometrics</em> <b>30</b>, 221-227.
<a href="https://doi.org/10.1080/00401706.1988.10488370">doi:10.1080/00401706.1988.10488370</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Cook's distances for linear regression
fm &lt;- ols(stack.loss ~ ., data = stackloss)
CD &lt;- cooks.distance(fm)
plot(CD, ylab = "Cook's distances", ylim = c(0,0.8))
text(21, CD[21], label = as.character(21), pos = 3)

# Cook's distances for LAD regression
fm &lt;- lad(stack.loss ~ ., data = stackloss)
CD &lt;- cooks.distance(fm)
plot(CD, ylab = "Cook's distances", ylim = c(0,0.4))
text(17, CD[17], label = as.character(17), pos = 3)

# Cook's distances for ridge regression
data(portland)
fm &lt;- ridge(y ~ ., data = portland)
CD &lt;- cooks.distance(fm)
plot(CD, ylab = "Cook's distances", ylim = c(0,0.5))
text(8, CD[8], label = as.character(8), pos = 3)
</code></pre>

<hr>
<h2 id='leverages'>Leverages</h2><span id='topic+leverages'></span><span id='topic+hatvalues.ols'></span><span id='topic+hatvalues.ridge'></span><span id='topic+leverages.lm'></span><span id='topic+leverages.ols'></span><span id='topic+leverages.ridge'></span>

<h3>Description</h3>

<p>Computes leverage measures from a fitted model object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  leverages(model, ...)
  ## S3 method for class 'lm'
leverages(model, infl = lm.influence(model, do.coef = FALSE), ...)
  ## S3 method for class 'ols'
leverages(model, ...)
  ## S3 method for class 'ridge'
leverages(model, ...)

  ## S3 method for class 'ols'
hatvalues(model, ...)
  ## S3 method for class 'ridge'
hatvalues(model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="leverages_+3A_model">model</code></td>
<td>
<p> an <span class="rlang"><b>R</b></span> object, returned by <code><a href="stats.html#topic+lm">lm</a></code>, <code>ols</code> or <code><a href="survival.html#topic+ridge">ridge</a></code>.</p>
</td></tr>
<tr><td><code id="leverages_+3A_infl">infl</code></td>
<td>
<p> influence structure as returned by <code><a href="stats.html#topic+lm.influence">lm.influence</a></code>.</p>
</td></tr>
<tr><td><code id="leverages_+3A_...">...</code></td>
<td>
<p> further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector containing the diagonal of the prediction (or &lsquo;hat&rsquo;) matrix. 
</p>
<p>For linear regression (i.e., for <code>"lm"</code> or <code>"ols"</code> objects) the prediction matrix assumes 
the form 
</p>
<p style="text-align: center;"><code class="reqn">\bold{H} = \bold{X}(\bold{X}^T\bold{X})^{-1}\bold{X}^T,</code>
</p>

<p>in which case, <code class="reqn">h_{ii} = \bold{x}_i^T(\bold{X}^T\bold{X})^{-1}\bold{x}_i</code> for <code class="reqn">i=1,\dots,n</code>. Whereas
for ridge regression, the prediction matrix is given by 
</p>
<p style="text-align: center;"><code class="reqn">\bold{H}(\lambda) = \bold{X}(\bold{X}^T\bold{X} + \lambda\bold{I})^{-1}\bold{X}^T,</code>
</p>

<p>where <code class="reqn">\lambda</code> represents the ridge parameter. Thus, the diagonal elements of <code class="reqn">\bold{H}(\lambda)</code>,
are <code class="reqn">h_{ii}(\lambda) = \bold{x}_i^T(\bold{X}^T\bold{X} + \lambda\bm{I})^{-1}\bold{x}_i</code>, <code class="reqn">i=1,\dots,n</code>.
</p>


<h3>Note</h3>

<p>This function never creates the prediction matrix and only obtains its diagonal elements from 
the singular value decomposition of <code class="reqn">\bold{X}</code>.
</p>
<p>Function <code><a href="stats.html#topic+hatvalues">hatvalues</a></code> only is a wrapper for function <code>leverages</code>.
</p>


<h3>References</h3>

<p>Chatterjee, S., Hadi, A.S. (1988).
<em>Sensivity Analysis in Linear Regression</em>.
Wiley, New York.
</p>
<p>Cook, R.D., Weisberg, S. (1982).
<em>Residuals and Influence in Regression</em>.
Chapman and Hall, London.
</p>
<p>Walker, E., Birch, J.B. (1988).
Influence measures in ridge regression.
<em>Technometrics</em> <b>30</b>, 221-227.
<a href="https://doi.org/10.1080/00401706.1988.10488370">doi:10.1080/00401706.1988.10488370</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Leverages for linear regression
fm &lt;- ols(stack.loss ~ ., data = stackloss)
lev &lt;- leverages(fm)
cutoff &lt;- 2 * mean(lev)
plot(lev, ylab = "Leverages", ylim = c(0,0.45))
abline(h = cutoff, lty = 2, lwd = 2, col = "red")
text(17, lev[17], label = as.character(17), pos = 3)

# Leverages for ridge regression
data(portland)
fm &lt;- ridge(y ~ ., data = portland)
lev &lt;- leverages(fm)
cutoff &lt;- 2 * mean(lev)
plot(lev, ylab = "Leverages", ylim = c(0,0.7))
abline(h = cutoff, lty = 2, lwd = 2, col = "red")
text(10, lev[10], label = as.character(10), pos = 3)
</code></pre>

<hr>
<h2 id='logLik.displacement'>Likelihood Displacement</h2><span id='topic+logLik.displacement'></span><span id='topic+logLik.displacement.lm'></span><span id='topic+logLik.displacement.ols'></span><span id='topic+logLik.displacement.lad'></span><span id='topic+logLik.displacement.ridge'></span>

<h3>Description</h3>

<p>Compute the likelihood displacement influence measure based on leave-one-out cases deletion 
for linear models, lad and ridge regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  logLik.displacement(model, ...)
  ## S3 method for class 'lm'
logLik.displacement(model, pars = "full", ...)
  ## S3 method for class 'ols'
logLik.displacement(model, pars = "full", ...)
  ## S3 method for class 'lad'
logLik.displacement(model, method = "quasi", pars = "full", ...)
  ## S3 method for class 'ridge'
logLik.displacement(model, pars = "full", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik.displacement_+3A_model">model</code></td>
<td>
<p> an <span class="rlang"><b>R</b></span> object, returned by <code><a href="stats.html#topic+lm">lm</a></code>, <code>ols</code>, <code>lad</code> 
or <code><a href="survival.html#topic+ridge">ridge</a></code>.</p>
</td></tr>
<tr><td><code id="logLik.displacement_+3A_pars">pars</code></td>
<td>
<p> should be considered the whole vector of parameters (<code>pars = "full"</code>), 
or only the vector of coefficients (<code>pars = "coef"</code>).</p>
</td></tr>
<tr><td><code id="logLik.displacement_+3A_method">method</code></td>
<td>
<p> only required for <code>'lad'</code> objects, options available are <code>"quasi"</code> 
and <code>"BR"</code> to obtain the likelihood displacement based on Sun and Wei (2004) and Elian 
et al. (2000) approaches, respectively.</p>
</td></tr>
<tr><td><code id="logLik.displacement_+3A_...">...</code></td>
<td>
<p> further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector whose <em>i</em>th element contains the distance between the likelihood functions,
</p>
<p style="text-align: center;"><code class="reqn">LD_i(\bold{\beta},\sigma^2) = 2\{l(\hat{\bold{\beta}},\hat{\sigma}^2) - 
  l(\hat{\bold{\beta}}_{(i)},\hat{\sigma}^2_{(i)})\},</code>
</p>

<p>for <code>pars = "full"</code>, where <code class="reqn">\hat{\bold{\beta}}_{(i)}</code> and <code class="reqn">\hat{\sigma}^2_{(i)}</code> 
denote the estimates of <code class="reqn">\bold{\beta}</code> and <code class="reqn">\sigma^2</code> when the <em>i</em>th observation is 
removed from the dataset. If we are interested only in <code class="reqn">\bold{\beta}</code> (i.e. <code>pars = "coef"</code>)
the likelihood displacement becomes
</p>
<p style="text-align: center;"><code class="reqn">LD_i(\bold{\beta}|\sigma^2) = 2\{l(\hat{\bold{\beta}},\hat{\sigma}^2) - 
  \max_{\sigma^2} l(\hat{\bold{\beta}}_{(i)},\hat{\sigma}^2)\}.</code>
</p>



<h3>References</h3>

<p>Cook, R.D., Weisberg, S. (1982).
<em>Residuals and Influence in Regression</em>.
Chapman and Hall, London.
</p>
<p>Cook, R.D., Pena, D., Weisberg, S. (1988).
The likelihood displacement: A unifying principle for influence measures.
<em>Communications in Statistics - Theory and Methods</em> <b>17</b>, 623-640.
<a href="https://doi.org/10.1080/03610928808829645">doi:10.1080/03610928808829645</a>.
</p>
<p>Elian, S.N., Andre, C.D.S., Narula, S.C. (2000).
Influence measure for the L1 regression.
<em>Communications in Statistics - Theory and Methods</em> <b>29</b>, 837-849.
<a href="https://doi.org/10.1080/03610920008832518">doi:10.1080/03610920008832518</a>.
</p>
<p>Sun, R.B., Wei, B.C. (2004).
On influence assessment for LAD regression.
<em>Statistics &amp; Probability Letters</em> <b>67</b>, 97-110.
<a href="https://doi.org/10.1016/j.spl.2003.08.018">doi:10.1016/j.spl.2003.08.018</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Likelihood displacement for linear regression
fm &lt;- ols(stack.loss ~ ., data = stackloss)
LD &lt;- logLik.displacement(fm)
plot(LD, ylab = "Likelihood displacement", ylim = c(0,9))
text(21, LD[21], label = as.character(21), pos = 3)

# Likelihood displacement for LAD regression
fm &lt;- lad(stack.loss ~ ., data = stackloss)
LD &lt;- logLik.displacement(fm)
plot(LD, ylab = "Likelihood displacement", ylim = c(0,1.5))
text(17, LD[17], label = as.character(17), pos = 3)

# Likelihood displacement for ridge regression
data(portland)
fm &lt;- ridge(y ~ ., data = portland)
LD &lt;- logLik.displacement(fm)
plot(LD, ylab = "Likelihood displacement", ylim = c(0,4))
text(8, LD[8], label = as.character(8), pos = 3)
</code></pre>

<hr>
<h2 id='portland'>Portland cement dataset</h2><span id='topic+portland'></span>

<h3>Description</h3>

<p>This dataset comes from an experimental investigation of the heat evolved during the 
setting and hardening of Portland cements of varied composition and the dependence of 
this heat on the percentages of four compounds in the clinkers from which the cement 
was produced.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(portland)</code></pre>


<h3>Format</h3>

<p>A data frame with 13 observations on the following 5 variables.
</p>

<dl>
<dt>y</dt><dd><p> The heat evolved after 180 days of curing, measured in calories per gram of cement.</p>
</dd>
<dt>x1</dt><dd><p> Tricalcium aluminate.</p>
</dd>
<dt>x2</dt><dd><p> Tricalcium silicate.</p>
</dd>
<dt>x3</dt><dd><p> Tetracalcium aluminoferrite.</p>
</dd>
<dt>x4</dt><dd> <p><code class="reqn">\beta</code>-dicalcium silicate.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Kaciranlar, S., Sakallioglu, S., Akdeniz, F., Styan, G.P.H., Werner, H.J. (1999).
A new biased estimator in linear regression and a detailed analysis of the widely-analysed dataset on Portland cement.
<em>Sankhya, Series B</em> <b>61</b>, 443-459.
</p>

<hr>
<h2 id='relative.condition'>Relative change in the condition number</h2><span id='topic+relative.condition'></span>

<h3>Description</h3>

<p>Compute the relative condition index to identify collinearity-influential points in linear models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  relative.condition(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="relative.condition_+3A_x">x</code></td>
<td>
<p> the model matrix <code class="reqn">\bold{X}</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>To assess the influence of the <em>i</em>th row of <code class="reqn">\bold{X}</code> on the condition index of <code class="reqn">\bold{X}</code>,
Hadi (1988) proposed the relative change,
</p>
<p style="text-align: center;"><code class="reqn">\delta_i = \frac{\kappa_{(i)} - \kappa}{\kappa},</code>
</p>

<p>for <code class="reqn">i=1,\dots,n</code>, where <code class="reqn">\kappa = \kappa(\bold{X})</code> and <code class="reqn">\kappa_{(i)} = \kappa(\bold{X}_{(i)})</code> 
denote the (scaled) condition index for <code class="reqn">\bold{X}</code> and <code class="reqn">\bold{X}_{(i)}</code>, respectively.
</p>


<h3>References</h3>

<p>Chatterjee, S., Hadi, A.S. (1988).
<em>Sensivity Analysis in Linear Regression</em>.
Wiley, New York.
</p>
<p>Hadi, A.S. (1988).
Diagnosing collinerity-influential observations.
<em>Computational Statistics &amp; Data Analysis</em> <b>7</b>, 143-159. 
<a href="https://doi.org/10.1016/0167-9473%2888%2990089-8">doi:10.1016/0167-9473(88)90089-8</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(portland)
fm &lt;- ridge(y ~ ., data = portland, x = TRUE)
x &lt;- fm$x
rel &lt;- relative.condition(x)
plot(rel, ylab = "Relative condition number", ylim = c(-0.1,0.4))
abline(h = 0, lty = 2, lwd = 2, col = "red")
text(3, rel[3], label = as.character(3), pos = 3)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
