<!DOCTYPE html><html lang="en"><head><title>Help for package stockR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {stockR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#calcFst'><p>Calculate Fst statistics for frequency data</p></a></li>
<li><a href='#plot.stockBOOT.object'><p>Plots results of a stockR analysis (a barplot-like representation)</p></a></li>
<li><a href='#sim.stock.data'><p>Simulates SNP data according to stockSTRUCTURE model</p></a></li>
<li><a href='#stockBOOT'><p>Calculates bootstrap estimates of stockSTRUCTURE model</p></a></li>
<li><a href='#stockSTRUCTURE'><p>Finds stock structure for sampling groups of animals</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Identifying Stocks in Genetic Data</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.76</td>
</tr>
<tr>
<td>Author:</td>
<td>Scott D. Foster [aut, cre]</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides a mixture model for clustering individuals (or sampling groups) into stocks based on their genetic profile. Here, sampling groups are individuals that are sure to come from the same stock (e.g. breeding adults or larvae). The mixture (log-)likelihood is maximised using the EM-algorithm after finding good starting values via a K-means clustering of the genetic data. Details can be found in: Foster, S. D.; Feutry, P.; Grewe, P. M.; Berry, O.; Hui, F. K. C. &amp; Davies (2020) &lt;<a href="https://doi.org/10.1111%2F1755-0998.12920">doi:10.1111/1755-0998.12920</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, stats, gtools, parallel, RColorBrewer, methods</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-04-26 06:52:04 UTC; fos085</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Scott D. Foster &lt;scott.foster@data61.csiro.au&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-04-26 08:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='calcFst'>Calculate Fst statistics for frequency data</h2><span id='topic+calcFst'></span>

<h3>Description</h3>

<p>Calculates Weir and Cockerham's Fst for frequency data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcFst(data, grps)
</code></pre>


<h3>Arguments</h3>

<p>You can put normal text in <b>Arguments</b>, too, like this. Remember to indent all arguments, as below.
</p>
<table role = "presentation">
<tr><td><code id="calcFst_+3A_data">data</code></td>
<td>
<p>a nMarker by nAnimal matrix of allele frequencies. That is for animal i and codominant marker j data[j,i] is the number of copies of the SNP allele (0, 1, or 2).</p>
</td></tr>
<tr><td><code id="calcFst_+3A_grps">grps</code></td>
<td>
<p>a numeric vector giving the populations of the nAnimals</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is really just a wrapper for the <code>Fstat()</code> function, taken from the (now unsupported) Geneland package.
</p>


<h3>Value</h3>

<p>A numeric matrix containing the pairwise Fst values between all populations.
</p>


<h3>Authors</h3>

<p>Arnaud Estoup for original code in Turbo Pascal. Translation in Fortran and interface with R by Gilles Guillot (for Geneland package). Scott Foster for latest wrapper for stockR package.
</p>


<h3>Author(s)</h3>

<p>Scott D. Foster</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(717)
data &lt;- sim.stock.data( nAnimals=50, nSNPs=500, nSampleGrps=50, K=5, ninform=50)
calcFst( data, attributes( data)$grps)
</code></pre>

<hr>
<h2 id='plot.stockBOOT.object'>Plots results of a stockR analysis (a barplot-like representation)</h2><span id='topic+plot.stockBOOT.object'></span>

<h3>Description</h3>

<p>For a given fitted stockBOOT object, visualise the membership of each individual to each stock.</p>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.stockBOOT.object_+3A_x">x</code></td>
<td>
<p>A stockBOOT.object, typically obtained from a call to <code><a href="#topic+stockBOOT">stockBOOT</a></code>. Note that the accuracy of the results will depend on the number of bootstrap resamples used to create the stockBOOT.object.</p>
</td></tr>
<tr><td><code id="plot.stockBOOT.object_+3A_locations">locations</code></td>
<td>
<p>A data.frame with two columns and the number of rows defined by the number of individuals in the stockBOOT.object.  Important to note that the ordering of individuals must be the same in the locations data.frame as in the stockBOOT.oject (otherwise garbage will be given). The first column in the locations data.frame is the 'region' from which an individual was sampled.  The second column gives information about how to plot the 'regions' &ndash; in particular their plotting order.  Assign a low number to regions that you want plotted on the left side of the page and a high number for those on the right. Default argument value (for locations) is NULL, in which case all individuals are assumed to come from a single region (plot is for a single block).</p>
</td></tr>
<tr><td><code id="plot.stockBOOT.object_+3A_plottitle">plotTitle</code></td>
<td>
<p>The main title (text) to give the plot.</p>
</td></tr>
<tr><td><code id="plot.stockBOOT.object_+3A_ci.width">CI.width</code></td>
<td>
<p>The width of the confidence intervals to take transparency from. See details.</p>
</td></tr>
<tr><td><code id="plot.stockBOOT.object_+3A_region.lwd">region.lwd</code></td>
<td>
<p>The line width of the box around the regions (groups of individuals).</p>
</td></tr>
<tr><td><code id="plot.stockBOOT.object_+3A_...">...</code></td>
<td>
<p>Other parameters to be passed through to plotting functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These plots give the probability of an individual to be assigned to each group (stock) identified by the mixture model, through stockSTRUCTURE and stockBOOT. This is an assignment probability, not a admixture proportion that is obtained from the STRUCTURE program (for example). 
</p>
<p>The intensity of the colour is given by the amount of uncertainty in the estimate of the probabilities &ndash; more solid colours are less uncertain (or more certain if you like to avoid double negatives). Very faint colours have a 100*CI.wdith% confidence interval width that is essentially 1 (so nothing is known about the probabilities).
</p>


<h3>Value</h3>

<p>NULL
</p>


<h3>method</h3>

<p>plot.stockBOOT.object( x, locations=NULL, plotTitle=NULL, CI.width=0.95, region.lwd=3.5, ...)
</p>


<h3>Author(s)</h3>

<p>Scott D. Foster</p>


<h3>References</h3>

<p>Foster, S.D., Feutry, P., Grewe, P.M., Berry, O, Hui, F.K.C. and Davies, C.R. (in press) Reliably Discriminating Stock Structure with Genetic Markers: Mixture Models with Robust and Fast Computation. Molecular Ecology Resources
</p>


<h3>See Also</h3>

<p><code><a href="#topic+stockSTRUCTURE">stockSTRUCTURE</a></code>, <code><a href="#topic+stockBOOT">stockBOOT</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>    
      ##This example will take a little while to run.
      #This should be challenging as there are actually 2 stocks and we fit a model with 3.
      tmpDat1 &lt;- sim.stock.data( nAnimals=100, nSNP=5000, nSampleGrps=100, K=2, ninform=5000, 
                                 sds=c(alpha=1.6,beta.inform=0.75,beta.noise=0.0005))
      #EM estimation from Kmeans starting values
      tmp &lt;- stockSTRUCTURE( tmpDat1, sample.grps=attr(tmpDat1,"sampleGrps"), K=3, start.grps=NULL)
      #in general, you'll want to use as many cores as possible, or close to.
      #mc.cores=1 is used here to please the CRAN submission checks
      tmpBOOT &lt;- stockBOOT( tmp, B=100, mc.cores=1)
      print( round( apply( tmpBOOT$postProbs, FUN=quantile, MARGIN=1:2, probs=c(0.025,0.975))), 5)
      #Note that, in this case, the posterior probabilities are not very informative; they could
      #be anywhere between 0 and 1. There are likely to be a few individuals, of course, where 
      #they have a very low chance of belonging to a particular stock (and this is chance). There
      #may even some individuals that get assigned to a group with almost certainty.
      #Let's visualise it.
      plot( tmpBOOT, locations=NULL, plotTitle="Data contains 2 groups, model fits 3")
      #You can try it with 2 groups.
      
      #Let's now pretend that there are sampling regions
      plot( tmpBOOT, locations=data.frame( locations=rep(1:4, each=25), 
	  order=rep( c(4,3,1,2), each=25)), plotTitle="Plot with grouping")
    
  </code></pre>

<hr>
<h2 id='sim.stock.data'>Simulates SNP data according to stockSTRUCTURE model</h2><span id='topic+sim.stock.data'></span>

<h3>Description</h3>

<p>For given sample characteristics (number of sampling groups, number of animals, number of SNPs and number/size of stocks) simulates some SNP data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.stock.data(nAnimals, nSNPs, nSampleGrps, K, ninform = nSNPs, 
  means=c(alpha=-1.9,beta=0), sds=c(alpha=1.6,beta.inform=0.85,
  beta.noise=0.0005), minStockSize=1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sim.stock.data_+3A_nanimals">nAnimals</code></td>
<td>
<p>integer giving the number of animals to simulate. No default, must be specified.</p>
</td></tr>
<tr><td><code id="sim.stock.data_+3A_nsnps">nSNPs</code></td>
<td>
<p>integer giving the number of SNPs to generate. No default, must be specified.</p>
</td></tr>
<tr><td><code id="sim.stock.data_+3A_nsamplegrps">nSampleGrps</code></td>
<td>
<p>integer giving the number of sampling groups. Must be less than nAnimals. No default, must be specified.</p>
</td></tr>
<tr><td><code id="sim.stock.data_+3A_k">K</code></td>
<td>
<p>integer giving the number of stocks</p>
</td></tr>
<tr><td><code id="sim.stock.data_+3A_ninform">ninform</code></td>
<td>
<p>integer giving the number of informative SNPs. That is the first ninform SNPs will discriminate the stocks and the remainder will not.</p>
</td></tr>
<tr><td><code id="sim.stock.data_+3A_means">means</code></td>
<td>
<p>a named two-element numeric vector consisting of the mean of the intercepts (named &quot;alpha&quot;) and the mean of the deviations (named &quot;beta&quot;). The latter should always be zero (the betas will get standardised in any case).</p>
</td></tr>
<tr><td><code id="sim.stock.data_+3A_sds">sds</code></td>
<td>
<p>a names three-element numeric vector consisting of the standard deviations of the intercepts (named &quot;alpha&quot;), the sds of the betas that are differentiating between stocks (named &quot;beta.inform&quot;), and the sds of the SNP effects that are not differentiating between stocks (named &quot;beta.noise&quot;).</p>
</td></tr>
<tr><td><code id="sim.stock.data_+3A_minstocksize">minStockSize</code></td>
<td>
<p>the size of the smallest stock group allowed. That is the size within the sample, not the actual population size.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The proportions of each stock in the sample is taken as a single draw from a flat Dirichlet distribution (which is flat over the simplex). The expected frequencies, in each stock, are generated on the logit scale. The mean frequency, for each SNP, is drawn from a random normal with mean means[&quot;alpha&quot;] and sd sds[&quot;alpha&quot;]. Deviations from the mean, for the first ninform SNPs, are generated from a normal with mean means[&quot;beta&quot;] and sd=sds[&quot;beta.inform&quot;]. For other SNPs these deviations are drawn from a normal with mean means[&quot;alpha&quot;] and sd sds[&quot;beta.noise&quot;] (typically really small). These expectations are then inverse logit trasnsformed and SNP data generated using binomial sampling with 2 trials. There was a good reason for choosing these means and standard deviations for generating SNP expectations, but I can't remember what it was...
</p>


<h3>Value</h3>

<p>A numeric matrix containing SNP allele frequencies (in rows) for each animal (in columns). The matrix has attributes, &quot;grps&quot; for the stock groups and &quot;sampleGrps&quot; for the sampling groups.
</p>


<h3>Author(s)</h3>

<p>Scott D. Foster</p>


<h3>See Also</h3>

<p><code><a href="#topic+stockSTRUCTURE">stockSTRUCTURE</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#a data set with 100 individuals, from 100 different sampling groups (so no individual
#can be assumed a priori to belong to the same stock as any other individual), with 
#5000 SNP markers. There are 3 stocks and only 200 of the 500 SNP markers are 
#differentiated between stocks.
myData &lt;- sim.stock.data( nAnimal=100, nSNP=5000, nSampleGrps=100, K=3, ninform=200)
print( dim( myData))  #should be 5000 x 100
</code></pre>

<hr>
<h2 id='stockBOOT'>Calculates bootstrap estimates of stockSTRUCTURE model</h2><span id='topic+stockBOOT'></span>

<h3>Description</h3>

<p>For a given fitted stockSTRUCTURE model determine uncertainty in parameter values (and outputs) using Bayesian Bootstrap.</p>


<h3>Usage</h3>

<pre><code class='language-R'>  stockBOOT( fm, B=100, mc.cores=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stockBOOT_+3A_fm">fm</code></td>
<td>
<p>A stockSTRUCTURE.object, typically obtained from a call to <code><a href="#topic+stockSTRUCTURE">stockSTRUCTURE</a></code>. This object MUST NOT be run with the small object option. So, in the initial model fit make sure that small.object=FALSE in the control list (this is the default).</p>
</td></tr>
<tr><td><code id="stockBOOT_+3A_b">B</code></td>
<td>
<p>The number of (Bayesian) bootstrap resamples to perform. Default is 100 but for serious applications more will be needed.</p>
</td></tr>
<tr><td><code id="stockBOOT_+3A_mc.cores">mc.cores</code></td>
<td>
<p>The number of parallel processes to perform at once. Default is NULL, in which case the function will determine the number of cores available and use them all.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Bootstrapping is done here using the Bayesian Bootstrap of Rubin (1981) as described in Foster et al (2018). Briefly, the sampling distribution of the model's parameters is obtained by taking weighted re-samples of the original data and then re-estimating the model. The variability between the re-estimations is the same as the sampling variability.
</p>


<h3>Value</h3>

<p>An object of class stockBOOT.object. This is a list with the following components
</p>
<table role = "presentation">
<tr><td><code>condMeans</code></td>
<td>
<p>a three dimensional array with each slice corresponds to the mean frequencies for each allele in each stock for each bootstrap resample.</p>
</td></tr>
<tr><td><code>pis</code></td>
<td>
<p>a three dimensional array where each slice corresponds to the proportion, in the data, of each of the stocks for each bootstrap resample. Small numbers imply smaller stocks. Note that sum(pi)=1 within each resample.</p>
</td></tr>
<tr><td><code>postProbs</code></td>
<td>
<p>a three dimensional array where each slice is the soft-classification of sample.grps to stocks for each bootstrap resample. Be aware that the order will be according to levels( sample.grps) and not the <code>natural</code> ordering that you may have imagined. Blame this on R's internal representation of factors. Consider using mixedsort() from the gtools package.</p>
</td></tr>
<tr><td><code>margLogl</code></td>
<td>
<p>a vector giving the marginal log-likelihood obtained at the parameter estimates for each bootstrap sample.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Scott D. Foster</p>


<h3>References</h3>

<p>Foster, S.D., Feutry, P., Grewe, P.M., Berry, O, Hui, F.K.C. and Davies, C.R. (in press) Reliably Discriminating Stock Structure with Genetic Markers: Mixture Models with Robust and Fast Computation. Molecular Ecology Resources
</p>
<p>Rubin, D.B. (1981) The Bayesian Bootstrap. The Annals of Statistics <em>9</em>:130&ndash;134.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+stockSTRUCTURE">stockSTRUCTURE</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
  ##This example will take a little while to run.
  #This should be very challenging as stock differentiation is non-existant (K=1).
  tmpDat1 &lt;- sim.stock.data( nAnimals=100, nSNP=5000, nSampleGrps=100, K=1, ninform=5000, 
                                    sds=c(alpha=1.6,beta.inform=0.75,beta.noise=0.0005))
  #EM estimation from Kmeans starting values
  tmp &lt;- stockSTRUCTURE( tmpDat1, sample.grps=attr(tmpDat1,"sampleGrps"), K=3, start.grps=NULL)
  #in general, you'll want to use as many cores as possible, or close to.
  #mc.cores=1 is used here to please the CRAN submission checks
  tmpBOOT &lt;- stockBOOT( tmp, B=100, mc.cores=1) 
  print( round( apply( tmpBOOT$postProbs, FUN=quantile, MARGIN=1:2, probs=c(0.025,0.975))), 5)
  #Note that, in this case, the posterior probabilities are not very informative; they could
  #be anywhere between 0 and 1. There are likely to be a few individuals, of course, where 
  #they have a very low chance of belonging to a particular stock (and this is chance). There
  #may even some individuals that get assigned to a group with almost certainty.
  
</code></pre>

<hr>
<h2 id='stockSTRUCTURE'>Finds stock structure for sampling groups of animals</h2><span id='topic+stockSTRUCTURE'></span>

<h3>Description</h3>

<p>For a given set of markers, scored for each animal (in sampling groups), determine likely stock structure using mixture models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stockSTRUCTURE(SNPdata = NULL, sample.grps = as.factor(1:ncol(SNPdata)),  K = 3, 
        weights = rep(1, nlevels( sample.grps)), start.grps = NULL,  control = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stockSTRUCTURE_+3A_snpdata">SNPdata</code></td>
<td>
<p>a numeric matrix of dimension (number of SNPs X number of individuals). As the dimension suggests, each row corresponds to an SNP marker and each column an individual. The entries are the number of copies of a marker present in the animal. So, 0 for no copies (aa), 1 for one copy (Aa), and 2 for two copies (AA). Columns that are constant for all animals are removed.</p>
</td></tr>
<tr><td><code id="stockSTRUCTURE_+3A_sample.grps">sample.grps</code></td>
<td>
<p>a factor (or something that can be converted into a factor) of length ncol( SNPdata). This gives the sampling the allocation of animals (columns of SNPdata) to sampling groups. The animals must be ordered the same in sample.grps and in SNPdata. The default sample.grps is to have each animal in its own group (so that no knowledge of breeding groups is assumed). Note that if sample.grps is specified, then the function's output will have (internal) ordering which is based on the alphabetical listing of sample.grps.</p>
</td></tr>
<tr><td><code id="stockSTRUCTURE_+3A_k">K</code></td>
<td>
<p>an integer giving the number of stocks to partition the data into</p>
</td></tr>
<tr><td><code id="stockSTRUCTURE_+3A_weights">weights</code></td>
<td>
<p>a numeric vector of length ncol( SNPdata). Gives the weighting for each animal to the analysis. Default is to weight all animals equally. You should have a really good reason not to use equal weights.</p>
</td></tr>
<tr><td><code id="stockSTRUCTURE_+3A_start.grps">start.grps</code></td>
<td>
<p>a numeric vector of length ncol( SNPdata) or NULL. If NULL the (EM-)optimisation algorithm will be started from groups found using the K-means algorithm. If not NULL then these groups will be used to start the EM optimiser. For most purposes this argument should be set as NULL. If specified, then the model's likelihood is less likely to be maximised and the major signals in the data may not be found. This is not a prior, not in the sense of a Bayesian analysis in any case.  Please do not supply the groups you think are in the data as starting values &ndash; you are likely to just be confirming your own beliefs.</p>
</td></tr>
<tr><td><code id="stockSTRUCTURE_+3A_control">control</code></td>
<td>
<p>a list of control parameters for initialisation and optimisation. See below for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Control arguments, and especially their defaults, will vary depending on the type of optimisation used (only a handful are common). The arguments are
</p>
<p><b>Common to all methods</b>
</p>

<dl>
<dt>small.object</dt><dd><p>a boolean indicating whether the return object should be made small (ie no returning of data etc). Default is FALSE, so that the return object is normal size.</p>
</dd>
<dt>quiet</dt><dd><p>a boolean indicating whether reporting should be performed throughout the estimation process. Default is FALSE (not quiet) so that reporting is performed. Users could also use <code>suppressMessages</code> if they prefer.</p>
</dd>
<dt>method</dt><dd><p>a character string. One of &quot;Kmeans.EM&quot; (default), &quot;SA.EM&quot;, &quot;EM&quot;, or &quot;DA.EM&quot;. These specify how the optimisation is performed. &quot;SA.EM&quot; implements the initialisation-then-optimisation strategy in Foster et al (in prep). &quot;EM&quot; performs the EM algorithm from random starts (unless user specifies the start location), this is similar to Chen et al (2006). &quot;DA.EM&quot; implements the deterministic annealing algorithm proposed in Zhou and Lange (2010) from random starts, or user specified start.</p>
</dd>
</dl>

<p>*For &quot;Kmeans.EM&quot; (Default and recommended) method*
</p>

<dl>
<dt>nKmeanStart</dt><dd><p>the number of K-menas groupings to perform to obtain starting values. Default (NULL) corresponds to 25 starts.</p>
</dd>
<dt>nKPCA</dt><dd><p>the SNP data is rotated, prior to initial K-means clustering, using PCA. This argument defines the number of PCAs to use. The default is nKPCA=min( nFish, nSNP, 100). The argument is always checked and the value of min( nFish, nSNP, nKPCA) is used.</p>
</dd>
<dt>EM.eps</dt><dd><p>the absolute convergence tolerance for the EM-algorithm. Default is 1e-5, that is successive differences in parameters have to be very small before converged is reached.</p>
</dd>
<dt>EM.maxit</dt><dd><p>the maximum number of iterations for the EM-algorithm. Default is 100.</p>
</dd>
<dt>EM.minit</dt><dd><p>the minimum number of iteraction for the EM-algorithm. Default is 1. EM.minit is really only important for when EM.tau.step &lt; 1.</p>
</dd>
<dt>EM.tau.step</dt><dd><p>the step-size of the initial update for the posterior probabilities. Default is 1. If less than 1 (say 0.5), then the step size is less (half say) than the size that the EM-algorithm suggests. EM.tau.step increases linearly to 1 after EM.minit steps.</p>
</dd>
<dt>tau.init.max</dt><dd><p>After the initial hard-clustering, the groupings are made soft by specifying posterior probabilities that are less than 1 and greater than 0. The default is given in Foster et al (in prep), but makes sure that the hard clustering recieves twice the probability mass than other stocks.</p>
</dd>
</dl>

<p>*For &quot;SA.EM&quot; method*
</p>

<dl>
<dt>SANN.temp</dt><dd><p>the initial temperature for simulated annealing. Default is half the number of sampling groups. This means that half of the sampling groups can be swapped to new groups in the first iteration.</p>
</dd>
<dt>SANN.maxit</dt><dd><p>the maximum number of iterations for the simulated annealing. Default is 5000, which is probably overkill for many problems.</p>
</dd>
<dt>SANN.tmin</dt><dd><p>the minimum number of swaps per iteration (ie once the annealing has run for a while). The default is max( nSampGrps %/% 20, 1) where nSampGrps is the number of sampling groups.</p>
</dd>
<dt>SANN.nreport</dt><dd><p>the number of iterations to do before printing out report (if printing at all). Default is 100.</p>
</dd>
<dt>SANN.trace</dt><dd><p>a boolean indicating if any trace information should be given. See <code><a href="stats.html#topic+optim">optim</a></code>.</p>
</dd>
<dt>EM.eps</dt><dd><p>the absolute convergence tolerance for the EM-algorithm. Default is 1e-5, that is successive differences in parameters have to be very small before converged is reached.</p>
</dd>
<dt>EM.maxit</dt><dd><p>the maximum number of iterations for the EM-algorithm. Default is 100.</p>
</dd>
<dt>EM.minit</dt><dd><p>the minimum number of iteraction for the EM-algorithm. Default is 1. EM.minit is really only important for when EM.tau.step &lt; 1.</p>
</dd>
<dt>EM.tau.step</dt><dd><p>the step-size of the initial update for the posterior probabilities. Default is 1. If less than 1 (say 0.5), then the step size is less (half say) than the size that the EM-algorithm suggests. EM.tau.step increases linearly to 1 after EM.minit steps.</p>
</dd>
<dt>tau.init.max</dt><dd><p>After the initial hard-clustering, the groupings are made soft by specifying posterior probabilities that are less than 1 and greater than 0. The default is given in Foster et al (in prep), but makes sure that the hard clustering recieves twice the probability mass than other stocks.</p>
</dd>
</dl>

<p>*For &quot;EM&quot; method*
</p>
<p>As per last five entries for &quot;SA.EM&quot; (an having a random start rather than an initial clustering).
</p>
<p>*For &quot;DA.EM&quot; method*
</p>

<dl>
<dt>EM.eps</dt><dd><p>the absolute convergence tolerance for the EM-algorithm. Default is 1e-5, that is successive differences in parameters have to be very small before converged is reached.</p>
</dd>
<dt>EM.maxit</dt><dd><p>the maximum number of iterations for the EM-algorithm. Default is 100.</p>
</dd>
<dt>EM.minit</dt><dd><p>the minimum number of iteraction for the EM-algorithm. Default is 25. EM.minit is the number of steps required to reach the non-cooled log-likelihood surface.</p>
</dd>
<dt>EM.tau.step</dt><dd><p>the step-size of the initial update for the posterior probabilities. Default is 1. If less than 1 (say 0.5), then the step size is less (half say) than the size that the EM-algorithm suggests. EM.tau.step increases linearly to 1 after EM.minit steps.</p>
</dd>
<dt>tau.init.max</dt><dd><p>After the initial hard-clustering, the groupings are made soft by specifying posterior probabilities that are less than 1 and greater than 0. The default is to make the hard clusterings ever-so-slightly more likely than others.</p>
</dd>
<dt>DA.nu.init</dt><dd><p>the initial cooling parameter. Default is 1e-4. Algorithm seems particularly sensitive to this choice. The cooling parameter nu is increased gradually until it reaches 1 (max) at EM.tau.step iterations. See Zhou and Lange (2010) for details.</p>
</dd>
</dl>



<h3>Value</h3>

<p>An object of class stockSTRUCTURE.object. This is a list with the following components
</p>
<table role = "presentation">
<tr><td><code>condMeans</code></td>
<td>
<p>the mean frequencies for each allele in each stock</p>
</td></tr>
<tr><td><code>pis</code></td>
<td>
<p>the proportion, in the data, of each of the stocks. Small numbers imply smaller stocks. Note that sum(pi)=1.</p>
</td></tr>
<tr><td><code>margLogl</code></td>
<td>
<p>the marginal log-likelihood obtained at the parameter estimates.</p>
</td></tr>
<tr><td><code>postProbs</code></td>
<td>
<p>the soft-classification of sample.grps to stocks. Be aware that the order will be according to levels( sample.grps) and not the <code>natural</code> ordering that you may have imagined. Blame this on R's internal representation of factors. Consider using mixedsort() from the gtools package.</p>
</td></tr>
<tr><td><code>K</code></td>
<td>
<p>the number of stocks (specified by user).</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>a list containing all the bits and pieces of data used in the analysis.</p>
</td></tr>
<tr><td><code>init.grps</code></td>
<td>
<p>the initial stock structure for starting the final optimisation (via the EM algorithm).</p>
</td></tr>
<tr><td><code>constantSNPs</code></td>
<td>
<p>a boolean vector giving the locations of the SNP markers with no variation.</p>
</td></tr>
<tr><td><code>margLoglTrace</code></td>
<td>
<p>a trace of the marginal log-likelihood throughout the final optimisation (EM algorithm).</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>the control parameters used in estimation. See below for details.</p>
</td></tr>
</table>
<p>Note that only condMeans, pis, margLogl, postProbs, and K are returned if control$small.object=TRUE is specified. See below for details.
Note that if sample.grps is specified, then the value of the function's output is orientated for the alphabetical ordering of sample.grps. This is done to help keep track of the groupped results when the number of sample groups is less than the number of individuals.
</p>


<h3>Author(s)</h3>

<p>Scott D. Foster</p>


<h3>References</h3>

<p>Foster, S.D., Feutry, P., Grewe, P.M., Berry, O, Hui, F.K.C. and Davies, C.R. (in press) Reliably Discriminating Stock Structure with Genetic Markers: Mixture Models with Robust and Fast Computation. Molecular Ecology Resources
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sim.stock.data">sim.stock.data</a></code>, <code><a href="#topic+stockBOOT">stockBOOT</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(727)
tmpDat1 &lt;- sim.stock.data( nAnimals=100, nSNP=5000, nSampleGrps=100, K=3, ninform=5000, 
                                    sds=c(alpha=1.6,beta.inform=0.75,beta.noise=0.0005))
#This should not be too challenging as stock differentiation is quite large.
print( calcFst( tmpDat1, attributes( tmpDat1)$grps))
#EM estimation from Kmeans starting values
tmp &lt;- stockSTRUCTURE( tmpDat1, sample.grps=attr(tmpDat1,"sampleGrps"), K=3, start.grps=NULL)
#an easy gold-standard for simulations (only know starting values as this is simulated data)
tmp1 &lt;- stockSTRUCTURE( tmpDat1, sample.grps=attr(tmpDat1,"sampleGrps"), K=3, 
                      start.grps=attr( tmpDat1,"grps"), control=list( method="EM"))
#an easily misled estimation method
tmp2 &lt;- stockSTRUCTURE( tmpDat1, sample.grps=attr(tmpDat1,"sampleGrps"), K=3, 
                                              start.grps=NULL, control=list( method="EM"))
#combine into a single object to investigate results
grpings &lt;- cbind( attributes( tmpDat1)$grps, apply( tmp$postProbs, 1, which.max), 
              apply( tmp2$postProbs, 1, which.max), apply( tmp1$postProbs, 1, which.max))
colnames( grpings) &lt;- c("True","Kmeans.EM Estimated","EM Estimated","Estimated From TRUE Start")
print( "How did we go with the stock identification?")
print( grpings)
#up to label switching this looks good, except for the EM from random start method (a few 
#confused individuals for the second and thrid stocks)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
