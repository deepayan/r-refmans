<!DOCTYPE html><html><head><title>Help for package OTE</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {OTE}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Body'><p> Exploring Relationships in Body Dimensions</p></a></li>
<li><a href='#Galaxy'><p> Radial Velocity of Galaxy NGC7531</p></a></li>
<li><a href='#OTClass'>
<p>Train the ensemble of optimal trees for classification.</p></a></li>
<li><a href='#OTE-package'>
<p>Optimal Trees Ensembles for Regression, Classification and Class Membership Probability Estimation</p></a></li>
<li><a href='#OTProb'>
<p>Train the ensemble of optimal trees for class membership probability estimation.</p></a></li>
<li><a href='#OTReg'>
<p>Train the ensemble of optimal trees for regression.</p></a></li>
<li><a href='#Predict.OTClass'>
<p>Prediction function for the object returned by <code>OTClass</code></p></a></li>
<li><a href='#Predict.OTProb'><p>Prediction function for the object returned by <code>OTProb</code></p></a></li>
<li><a href='#Predict.OTReg'>
<p>Prediction function for the object returned by <code>OTReg</code></p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Optimal Trees Ensembles for Regression, Classification and Class
Membership Probability Estimation</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-04-18</td>
</tr>
<tr>
<td>Author:</td>
<td>Zardad Khan, Asma Gul, Aris Perperoglou, Osama Mahmoud, Werner Adler, Miftahuddin and Berthold Lausen</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Zardad Khan &lt;zardadkhan@awkum.edu.pk&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions for creating ensembles of optimal trees for regression, classification (Khan, Z., Gul, A., Perperoglou, A., Miftahuddin, M., Mahmoud, O., Adler, W., &amp; Lausen, B. (2019). (2019) &lt;<a href="https://doi.org/10.1007%2Fs11634-019-00364-9">doi:10.1007/s11634-019-00364-9</a>&gt;) and class membership probability estimation (Khan, Z, Gul, A, Mahmoud, O, Miftahuddin, M, Perperoglou, A, Adler, W &amp; Lausen, B (2016) &lt;<a href="https://doi.org/10.1007%2F978-3-319-25226-1_34">doi:10.1007/978-3-319-25226-1_34</a>&gt;) are given. A few trees are selected from an initial set of trees grown by random forest for the ensemble on the basis of their individual and collective performance. Three different methods of tree selection for the case of classification are given. The prediction functions return estimates of the test responses and their class membership probabilities. Unexplained variations, error rates, confusion matrix, Brier scores, etc. are also returned for the test data.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>randomForest,stats</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.0</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-04-20 09:32:39 UTC; ZKHAN</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-04-20 10:50:07 UTC</td>
</tr>
</table>
<hr>
<h2 id='Body'> Exploring Relationships in Body Dimensions</h2><span id='topic+Body'></span>

<h3>Description</h3>

<p> The Body data set consists of 507 observations on 24 predictor variables including age, weight, hight and 21 body dimensions. All the 507 observations are on individuals, 247 men and 260 women, in the age of twenties and thirties with a small number of old people. The class variable is gender having two categories male and female.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Body)</code></pre>


<h3>Format</h3>

<p>  A data frame with 507 observations recorded on the following 25 variables.
</p>

<dl>
<dt><code>  Biacrom </code></dt><dd><p> The diameter of Biacrom taken in centimeter.</p>
</dd>
<dt><code>  Biiliac </code></dt><dd><p> &quot;Pelvic breadth&quot; measured in centimeter.</p>
</dd>
<dt><code>  Bitro </code></dt><dd><p> Bitrochanteric whole diameter measured in centimeter.</p>
</dd>
<dt><code>  ChestDp </code></dt><dd><p> The depth of Chest of a person in centimeter between sternum and spine at nipple level.</p>
</dd>
<dt><code>  ChestD  </code></dt><dd><p> The diameter of Chest of a person in centimeter at nipple level.</p>
</dd>
<dt><code>  ElbowD  </code></dt><dd><p> The sum of diameters of two Elbows in centimeter.</p>
</dd>
<dt><code>  WristD  </code></dt><dd><p> Sum of two Wrists diameters in centimeter.</p>
</dd>
<dt><code>  KneeD </code></dt><dd><p> The sum of the diameters of two Knees in centimeter.</p>
</dd>
<dt><code>  AnkleD  </code></dt><dd><p> The sum of the diameters of two Ankles in centimeter.</p>
</dd>
<dt><code>  ShoulderG </code></dt><dd><p> The wideness of shoulder in centimeter.</p>
</dd>
<dt><code>  ChestG  </code></dt><dd><p> The circumference of chest centimeter taken at nipple line for males and just above breast tissue for females.</p>
</dd>
<dt><code>  WaistG  </code></dt><dd><p> The circumference of Waist in centimeter taken as the average of contracted and relaxed positions at the narrowest part.</p>
</dd>
<dt><code>  AbdG  </code></dt><dd><p> Girth of Abdomin in centimeter at umbilicus and iliac crest, where iliac crest is taken as a landmark.</p>
</dd>
<dt><code>  HipG  </code></dt><dd><p> Girth of Hip in centimeter at level of bitrochanteric diameter.</p>
</dd>
<dt><code>  ThighG  </code></dt><dd><p> Average of left and right Thigh girths in centimeter below gluteal fold.</p>
</dd>
<dt><code>  BicepG  </code></dt><dd><p> Average of left and right Bicep girths in centimeter.</p>
</dd>
<dt><code>  ForearmG  </code></dt><dd><p> Average of left and right Forearm girths, extended, palm up.</p>
</dd>
<dt><code>  KneeG </code></dt><dd><p> Average of left and right Knees girths over patella, slightly flexed position.</p>
</dd>
<dt><code>  CalfG </code></dt><dd><p> Average of right and left Calf maximum girths.</p>
</dd>
<dt><code>  AnkleG  </code></dt><dd><p>Average of right and left Ankle minimum girths.</p>
</dd>
<dt><code>  WristG  </code></dt><dd><p> Average of left and right minimum circumferences of Wrists.</p>
</dd>
<dt><code>  Age </code></dt><dd><p> Age in years</p>
</dd>
<dt><code>  Weight  </code></dt><dd><p> Weight in kilogram</p>
</dd>
<dt><code>  Height  </code></dt><dd><p> Height in centimeter</p>
</dd>
<dt><code>  Gender  </code></dt><dd><p> Binary response with two categories; 1 - male, 0 - female</p>
</dd>
</dl>



<h3>Source</h3>

<p>Heinz, G., Peterson, L.J., Johnson, R.W. and Kerk, C.J. (2003), &ldquo;Exploring Relationships in Body Dimensions&rdquo;, Journal of Statistics Education , 11.
</p>


<h3>References</h3>

<p>Hurley, C. (2012), &ldquo; gclus: Clustering Graphics&rdquo;, R package version 1.3.1, <a href="https://CRAN.R-project.org/package=gclus">https://CRAN.R-project.org/package=gclus</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Body)
str(Body)
</code></pre>

<hr>
<h2 id='Galaxy'> Radial Velocity of Galaxy NGC7531
</h2><span id='topic+Galaxy'></span>

<h3>Description</h3>

<p> This data set is a record of radial velocity of a spiral galaxy that is measured at 323 points in its covered area of the sky. The positions of the measurements, that are in the range of seven slot crossing at the origin, are denoted by 4 variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Galaxy)</code></pre>


<h3>Format</h3>

<p>  A data frame with 324 observations recorded on the following 5 variables.
</p>

<dl>
<dt><code> east.west </code></dt><dd><p> It is the east-west coordinate where east is taken as negative, west is taken as positive and origin, (0,0), is close to the center of galaxy.
</p>
</dd>
<dt><code>  north.south </code></dt><dd><p>  It is the north-south coordinate where south is taken as negative, north is taken as positive and origin, (0,0), is near the center of galaxy.
</p>
</dd>
<dt><code>  angle </code></dt><dd><p>  It is the degrees of anti rotation (clockwise) from the slot horizon where the observation lies.
</p>
</dd>
<dt><code>  radial.position </code></dt><dd><p>  It is the signed distance from the center, (0,0), which is signed as negative if the east-west coordinate is negative.
</p>
</dd>
<dt><code>  velocity  </code></dt><dd><p> This is the response variable denoting the radial velocity(km/sec) of the galaxy.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Buta, R. (1987), &ldquo;The Structure and Dynamics of Ringed Galaxies, III: Surface Photometry and Kinematics of the Ringed Nonbarred Spiral NGC7531&rdquo; The Astrophysical J. Supplement Ser. 64. 1&ndash;37.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Galaxy)
str(Galaxy)
</code></pre>

<hr>
<h2 id='OTClass'>
Train the ensemble of optimal trees for classification.
</h2><span id='topic+OTClass'></span>

<h3>Description</h3>

<p>This function selects optimal trees for classification from a total of <code>t.initial</code> trees grown by random forest. Number of trees in the initial set, <code>t.initial</code>, is specified by the user. If not specified then the default <code>t.initial = 1000</code> is used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OTClass(XTraining, YTraining, method=c("oob+independent","oob","sub-sampling"),
p = 0.1,t.initial = NULL,nf = NULL, ns = NULL, info = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OTClass_+3A_xtraining">XTraining</code></td>
<td>

<p>An <code>n x d</code> dimensional training data matrix/frame consiting of traing observation where <code>n</code> is the number of observations and <code>d</code> is the number of features.
</p>
</td></tr>
<tr><td><code id="OTClass_+3A_ytraining">YTraining</code></td>
<td>

<p>A vector of length <code>n</code> consisting of class labels for the training data. Should be binary (0,1).
</p>
</td></tr>
<tr><td><code id="OTClass_+3A_method">method</code></td>
<td>

<p>Method used in the selection of optimal trees. <code>method="oob+independent"</code> used out-of-bag observation from the bootstrap sample taken for growing the individual tree for indidual tree assessment while an independent training data for their collective assessement. <code>method="oob"</code> use the out-of-bag observations both for individual and collective assessment. <code>method="sub-sampling"</code> uses a sub-sample of the training data for individual tree assessment as well as its contribution towards the ensemble.
</p>
</td></tr>
<tr><td><code id="OTClass_+3A_p">p</code></td>
<td>

<p>Percent of the best <code>t.initial</code> trees to be selected on the basis of performance on out-of-bag observations.
</p>
</td></tr>
<tr><td><code id="OTClass_+3A_t.initial">t.initial</code></td>
<td>

<p>Size of the initial set of classification trees.
</p>
</td></tr>
<tr><td><code id="OTClass_+3A_nf">nf</code></td>
<td>

<p>Number of features to be sampled for spliting the nodes of the trees. If equal to <code>NULL</code> then the default <code>sqrt(number of features)</code> is executed.
</p>
</td></tr>
<tr><td><code id="OTClass_+3A_ns">ns</code></td>
<td>

<p>Node size: Minimal number of samples in the nodes. If equal to <code>NULL</code> then the default <code>1</code> is executed.
</p>
</td></tr>
<tr><td><code id="OTClass_+3A_info">info</code></td>
<td>

<p>If <code>TRUE</code>, displays processing information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Large values are recommended for <code>t.initial</code> for better performance as possible under the available computational resources.
</p>


<h3>Value</h3>

<p>A trained object consisting of the selected trees.
</p>


<h3>Note</h3>

<p>Prior action needs to be taken in the case of missing values as the fuction can not handle them at the current version.
</p>


<h3>Author(s)</h3>

<p>Zardad Khan &lt;zkhan@essex.ac.uk&gt;
</p>


<h3>References</h3>

<p>Khan, Z., Gul, A., Perperoglou, A., Miftahuddin, M., Mahmoud, O., Adler, W., &amp; Lausen, B. (2019). Ensemble of optimal trees, random forest and random projection ensemble classification. Advances in Data Analysis and Classification, 1-20.
</p>
<p>Liaw, A. and Wiener, M. (2002) &ldquo;Classification and regression by random forest&rdquo; R news. 2(3). 18&ndash;22.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Predict.OTClass">Predict.OTClass</a></code>, <code><a href="#topic+OTReg">OTReg</a></code>, <code><a href="#topic+OTProb">OTProb</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#load the data

  data(Body)
  data &lt;- Body

#Divide the data into training and test parts

  set.seed(9123)
  n &lt;- nrow(data)
  training &lt;- sample(1:n,round(2*n/3))
  testing &lt;- (1:n)[-training]
  X &lt;- data[,1:24]
  Y &lt;- data[,25]

#Train OTClass on the training data

  Opt.Trees &lt;- OTClass(XTraining=X[training,],YTraining = Y[training],
  t.initial=200,method="oob+independent")

#Predict on test data

  Prediction &lt;- Predict.OTClass(Opt.Trees, X[testing,],YTesting=Y[testing])

#Objects returned

  names(Prediction)
  Prediction$Confusion.Matrix
  Prediction$Predicted.Class.Labels

</code></pre>

<hr>
<h2 id='OTE-package'>
Optimal Trees Ensembles for Regression, Classification and Class Membership Probability Estimation
</h2><span id='topic+OTE-package'></span>

<h3>Description</h3>

<p>Functions for creating ensembles of optimal trees for regression, classification and class membership probability estimation are given. A few trees are selected from an initial set of trees grown by random forest for the ensemble on the basis of their individual and collective performance. The prediction functions return estimates of the test responses/class labels and their class membership probabilities. Unexplained variations, error rates, confusion matrix, Brier scores, etc. for the test data are also returned. Three different methods for tree selection are given for the case of classification.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> OTE</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.0.1</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2020-04-18</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-3</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Zardad Khan, Asma Gul, Aris Perperoglou, Osama Mahmoud, Werner Adler, Miftahuddin and Berthold Lausen
Maintainer: Zardad Khan &lt;zardadkhan@awkum.edu.pk&gt;
</p>


<h3>References</h3>

<p>Khan, Z., Gul, A., Perperoglou, A., Miftahuddin, M., Mahmoud, O., Adler, W., &amp; Lausen, B. (2019). Ensemble of optimal trees, random forest and random projection ensemble classification. Advances in Data Analysis and Classification, 1-20.
</p>

<hr>
<h2 id='OTProb'>
Train the ensemble of optimal trees for class membership probability estimation.
</h2><span id='topic+OTProb'></span>

<h3>Description</h3>

<p>This function selects optimal trees for class membership probability estimation from a total of <code>t.initial</code> trees grown by random forest. Number of trees in the initial set, <code>t.initial</code>, is specified by the user. If not specified then the default <code>t.initial = 1000</code> is used. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OTProb(XTraining, YTraining, p = 0.2, t.initial = NULL,
      nf = NULL, ns = NULL, info = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OTProb_+3A_xtraining">XTraining</code></td>
<td>

<p>An <code>n x d</code> dimensional training data matrix/frame consiting of traing observation where <code>n</code> is the number of observations and <code>d</code> is the number of features. 
</p>
</td></tr>
<tr><td><code id="OTProb_+3A_ytraining">YTraining</code></td>
<td>

<p>A vector of length <code>n</code> consisting of class labels for the training data. Should be binary (0,1).
</p>
</td></tr>
<tr><td><code id="OTProb_+3A_p">p</code></td>
<td>

<p>Percent of the best <code>t.initial</code> trees to be selected on the basis of performance on out-of-bag observations.
</p>
</td></tr>
<tr><td><code id="OTProb_+3A_t.initial">t.initial</code></td>
<td>

<p>Size of the initial set of probability estimation trees.
</p>
</td></tr>
<tr><td><code id="OTProb_+3A_nf">nf</code></td>
<td>

<p>Number of features to be sampled for spliting the nodes of the trees. If equal to <code>NULL</code> then the default <code>sqrt(number of features)</code> is executed.
</p>
</td></tr>
<tr><td><code id="OTProb_+3A_ns">ns</code></td>
<td>

<p>Node size: Minimal number of samples in the nodes. If equal to <code>NULL</code> then the default <code>5</code> is executed.
</p>
</td></tr>
<tr><td><code id="OTProb_+3A_info">info</code></td>
<td>

<p>If <code>TRUE</code>, displays processing information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Large values are recommended for <code>t.initial</code> for better performance as possible under the available computational resources. 
</p>


<h3>Value</h3>

<p>A trained object consisting of the selected trees.
</p>


<h3>Note</h3>

<p>Prior action needs to be taken in case of missing values as the fuction can not handle them at the current version. 
</p>


<h3>Author(s)</h3>

<p>Zardad Khan &lt;zkhan@essex.ac.uk&gt;
</p>


<h3>References</h3>

<p>Khan, Z., Gul, A., Perperoglou, A., Miftahuddin, M., Mahmoud, O., Adler, W., &amp; Lausen, B. (2019). Ensemble of optimal trees, random forest and random projection ensemble classification. Advances in Data Analysis and Classification, 1-20.
</p>
<p>Liaw, A. and Wiener, M. (2002) &ldquo;Classification and regression by random forest&rdquo; R news. 2(3). 18&ndash;22.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Predict.OTProb">Predict.OTProb</a></code>, <code><a href="#topic+OTReg">OTReg</a></code>, <code><a href="#topic+OTClass">OTClass</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#load the data

  data(Body)
  data &lt;- Body
  
#Divide the data into training and test parts

  set.seed(9123) 
  n &lt;- nrow(data)
  training &lt;- sample(1:n,round(2*n/3))
  testing &lt;- (1:n)[-training]
  X &lt;- data[,1:24]
  Y &lt;- data[,25]
  
#Train OTClass on the training data

  Opt.Trees &lt;- OTProb(XTraining=X[training,],YTraining = Y[training],t.initial=200)
  
#Predict on test data

  Prediction &lt;- Predict.OTProb(Opt.Trees, X[testing,],YTesting=Y[testing])
  
#Objects returned

  names(Prediction)
  Prediction$Brier.Score
  Prediction$Estimated.Probabilities

  </code></pre>

<hr>
<h2 id='OTReg'>
Train the ensemble of optimal trees for regression.
</h2><span id='topic+OTReg'></span>

<h3>Description</h3>

<p>This function selects optimal trees for regression from a total of <code>t.initial</code> trees grown by random forest. Number of trees in the initial set, <code>t.initial</code>, is specified by the user. If not specified then the default <code>t.initial = 1000</code> is used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OTReg(XTraining, YTraining, p = 0.2, t.initial = NULL,
      nf = NULL, ns = NULL, info = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OTReg_+3A_xtraining">XTraining</code></td>
<td>

<p>An <code>n x d</code> dimensional training data matrix/frame consiting of traing observation where <code>n</code> is the number of observations and <code>d</code> is the number of features. 
</p>
</td></tr>
<tr><td><code id="OTReg_+3A_ytraining">YTraining</code></td>
<td>

<p>A vector of length <code>n</code> consisting of the values of the continuous response variable for the training data.
</p>
</td></tr>
<tr><td><code id="OTReg_+3A_p">p</code></td>
<td>

<p>Percent of the best <code>t.initial</code> trees to be selected on the basis of performance on out-of-bag observations.
</p>
</td></tr>
<tr><td><code id="OTReg_+3A_t.initial">t.initial</code></td>
<td>

<p>Size of the initial set of regression trees.
</p>
</td></tr>
<tr><td><code id="OTReg_+3A_nf">nf</code></td>
<td>

<p>Number of features to be sampled for spliting the nodes of the trees. If equal to <code>NULL</code> then the default <code>sqrt(number of features)</code> is executed.
</p>
</td></tr>
<tr><td><code id="OTReg_+3A_ns">ns</code></td>
<td>

<p>Node size: Minimal number of samples in the nodes. If equal to <code>NULL</code> then the default <code>5</code> is executed.
</p>
</td></tr>
<tr><td><code id="OTReg_+3A_info">info</code></td>
<td>

<p>If <code>TRUE</code>, displays processing information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Large values are recommended for <code>t.initial</code> for better performance as possible under the available computational resources. 
</p>


<h3>Value</h3>

<p>A trained object consisting of the selected trees for regression.
</p>


<h3>Note</h3>

<p>Prior action needs to be taken in case of missing values as the fuction can not handle them at the current version. 
</p>


<h3>Author(s)</h3>

<p>Zardad Khan &lt;zkhan@essex.ac.uk&gt;
</p>


<h3>References</h3>

<p>Khan, Z., Gul, A., Perperoglou, A., Miftahuddin, M., Mahmoud, O., Adler, W., &amp; Lausen, B. (2019). Ensemble of optimal trees, random forest and random projection ensemble classification. Advances in Data Analysis and Classification, 1-20.
</p>
<p>Liaw, A. and Wiener, M. (2002) &ldquo;Classification and regression by random forest&rdquo; R news. 2(3). 18&ndash;22.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Predict.OTReg">Predict.OTReg</a></code>, <code><a href="#topic+OTProb">OTProb</a></code>, <code><a href="#topic+OTClass">OTClass</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load the data

  data(Galaxy)
  data &lt;- Galaxy
  
#Divide the data into training and test parts

  set.seed(9123) 
  n &lt;- nrow(data)
  training &lt;- sample(1:n,round(2*n/3))
  testing &lt;- (1:n)[-training]
  X &lt;- data[,1:4]
  Y &lt;- data[,5]
  
#Train OTReg on the training data

  Opt.Trees &lt;- OTReg(XTraining=X[training,],YTraining = Y[training],t.initial=200)
  
#Predict on test data

  Prediction &lt;- Predict.OTReg(Opt.Trees, X[testing,],YTesting=Y[testing])
  
#Objects returned

  names(Prediction)
  Prediction$Unexp.Variations
  Prediction$Pr.Values
  Prediction$Trees.Used
</code></pre>

<hr>
<h2 id='Predict.OTClass'>
Prediction function for the object returned by <code>OTClass</code>
</h2><span id='topic+Predict.OTClass'></span>

<h3>Description</h3>

<p>This function provides prediction for test data on the trained <code>OTClass</code> object for classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Predict.OTClass(Opt.Trees, XTesting, YTesting)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Predict.OTClass_+3A_opt.trees">Opt.Trees</code></td>
<td>

<p>An object of class <code>OptTreesEns</code>.
</p>
</td></tr>
<tr><td><code id="Predict.OTClass_+3A_xtesting">XTesting</code></td>
<td>

<p>An <code>m x d</code> dimensional training data matrix/frame consiting of test observations where <code>m</code> is the number of observations and <code>d</code> is the number of features.
</p>
</td></tr>
<tr><td><code id="Predict.OTClass_+3A_ytesting">YTesting</code></td>
<td>

<p>Optional. A vector of length <code>m</code> consisting of class labels for the test data. Should be binary (0,1).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with values
</p>
<table>
<tr><td><code>Error.Rate</code></td>
<td>
<p>Error rate of the clssifier for the observations in XTesting.</p>
</td></tr>
<tr><td><code>Confusion.Matrix</code></td>
<td>
<p>Confusion matrix based on the estimated class labels and the true class labels.</p>
</td></tr>
<tr><td><code>Estimated.Class</code></td>
<td>
<p>A vector of length <code>m</code> consisting of the estimated class labels for the observations in XTesting.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zardad Khan &lt;zkhan@essex.ac.uk&gt;
</p>


<h3>References</h3>

<p>Khan, Z., Gul, A., Perperoglou, A., Miftahuddin, M., Mahmoud, O., Adler, W., &amp; Lausen, B. (2019). Ensemble of optimal trees, random forest and random projection ensemble classification. Advances in Data Analysis and Classification, 1-20.
</p>
<p>Liaw, A. and Wiener, M. (2002) &ldquo;Classification and regression by random forest&rdquo; R news. 2(3). 18&ndash;22.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+OTClass">OTClass</a></code>, <code><a href="#topic+OTReg">OTReg</a></code>, <code><a href="#topic+OTProb">OTProb</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#load the data

  data(Body)
  data &lt;- Body

#Divide the data into training and test parts

  set.seed(9123)
  n &lt;- nrow(data)
  training &lt;- sample(1:n,round(2*n/3))
  testing &lt;- (1:n)[-training]
  X &lt;- data[,1:24]
  Y &lt;- data[,25]

#Train OTClass on the training data

  Opt.Trees &lt;- OTClass(XTraining=X[training,],YTraining = Y[training],
  t.initial=200, method="oob+independent")

#Predict on test data

  Prediction &lt;- Predict.OTClass(Opt.Trees, X[testing,],YTesting=Y[testing])

#Objects returned

  names(Prediction)
  Prediction$Confusion.Matrix
  Prediction$Predicted.Class.Labels

</code></pre>

<hr>
<h2 id='Predict.OTProb'>Prediction function for the object returned by <code>OTProb</code>
</h2><span id='topic+Predict.OTProb'></span>

<h3>Description</h3>

<p>This function provides prediction for test data on the trained <code>OTProb</code> object for class membership probability estimation. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Predict.OTProb(Opt.Trees, XTesting, YTesting)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Predict.OTProb_+3A_opt.trees">Opt.Trees</code></td>
<td>
 
<p>An object of class <code>OptTreesEns</code>.
</p>
</td></tr>
<tr><td><code id="Predict.OTProb_+3A_xtesting">XTesting</code></td>
<td>
  
<p>An <code>m x d</code> dimensional training data matrix/frame consiting of test observations where <code>m</code> is the number of observations and <code>d</code> is the number of features. 
</p>
</td></tr>
<tr><td><code id="Predict.OTProb_+3A_ytesting">YTesting</code></td>
<td>
  
<p>Optional. A vector of length <code>m</code> consisting of class labels for the test data. Should be binary (0,1).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with values
</p>
<table>
<tr><td><code>Brier.Score</code></td>
<td>
<p>Brier Score based on the estimated probabilities and true class label in YTesting.</p>
</td></tr>
<tr><td><code>Estimated.Probabilities</code></td>
<td>
<p>A vector of length <code>m</code> consisting of the estimated class membership probabilities for the observation in XTesting</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zardad Khan &lt;zkhan@essex.ac.uk&gt;
</p>


<h3>References</h3>

<p>Khan, Z., Gul, A., Perperoglou, A., Miftahuddin, M., Mahmoud, O., Adler, W., &amp; Lausen, B. (2019). Ensemble of optimal trees, random forest and random projection ensemble classification. Advances in Data Analysis and Classification, 1-20.
</p>
<p>Liaw, A. and Wiener, M. (2002) &ldquo;Classification and regression by random forest&rdquo; R news. 2(3). 18&ndash;22.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+OTProb">OTProb</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#load the data

  data(Body)
  data &lt;- Body
  
#Divide the data into training and test parts

  set.seed(9123) 
  n &lt;- nrow(data)
  training &lt;- sample(1:n,round(2*n/3))
  testing &lt;- (1:n)[-training]
  X &lt;- data[,1:24]
  Y &lt;- data[,25]
  
#Train OTClass on the training data

  Opt.Trees &lt;- OTProb(XTraining=X[training,],YTraining = Y[training],t.initial=200)
  
#Predict on test data

  Prediction &lt;- Predict.OTProb(Opt.Trees, X[testing,],YTesting=Y[testing])
  
#Objects returned

  names(Prediction)
  Prediction$Brier.Score
  Prediction$Estimated.Probabilities

  </code></pre>

<hr>
<h2 id='Predict.OTReg'>
Prediction function for the object returned by <code>OTReg</code>
</h2><span id='topic+Predict.OTReg'></span>

<h3>Description</h3>

<p>This function provides prediction for test data on the trained <code>OTReg</code> object for the continuous response variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Predict.OTReg(Opt.Trees, XTesting, YTesting)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Predict.OTReg_+3A_opt.trees">Opt.Trees</code></td>
<td>
 
<p>An object of class <code>OptTreesEns</code>.
</p>
</td></tr>
<tr><td><code id="Predict.OTReg_+3A_xtesting">XTesting</code></td>
<td>
  
<p>An <code>m x d</code> dimensional training data matrix/frame consiting of test observations where <code>m</code> is the number of observations and <em>d</em> is the number of features. 
</p>
</td></tr>
<tr><td><code id="Predict.OTReg_+3A_ytesting">YTesting</code></td>
<td>
  
<p>Optional. A vector of length <code>m</code> consisting of the values of the continuous response variable for the test data. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with values
</p>
<table>
<tr><td><code>Unexp.Variations</code></td>
<td>
<p>Unexplained variations based on estimated response and given response.</p>
</td></tr>
<tr><td><code>Pr.Values</code></td>
<td>
<p>A vector of length <code>m</code> consisting of the estimated values for the response observations in XTesting</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zardad Khan &lt;zkhan@essex.ac.uk&gt;
</p>


<h3>References</h3>

<p>Khan, Z., Gul, A., Perperoglou, A., Miftahuddin, M., Mahmoud, O., Adler, W., &amp; Lausen, B. (2019). Ensemble of optimal trees, random forest and random projection ensemble classification. Advances in Data Analysis and Classification, 1-20.
</p>
<p>Liaw, A. and Wiener, M. (2002) &ldquo;Classification and regression by random forest&rdquo; R news. 2(3). 18&ndash;22.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+OTProb">OTProb</a></code>, <code><a href="#topic+OTReg">OTReg</a></code>, <code><a href="#topic+OTClass">OTClass</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load the data

  data(Galaxy)
  data &lt;- Galaxy
  
#Divide the data into training and test parts

  set.seed(9123) 
  n &lt;- nrow(data)
  training &lt;- sample(1:n,round(2*n/3))
  testing &lt;- (1:n)[-training]
  X &lt;- data[,1:4]
  Y &lt;- data[,5]
  
#Train oTReg on the training data

  Opt.Trees &lt;- OTReg(XTraining=X[training,],YTraining = Y[training],t.initial=200)
  
#Predict on test data

  Prediction &lt;- Predict.OTReg(Opt.Trees, X[testing,],YTesting=Y[testing])
  
#Objects returned

  names(Prediction)
  Prediction$Unexp.Variations
  Prediction$Pr.Values
  Prediction$Trees.Used
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
