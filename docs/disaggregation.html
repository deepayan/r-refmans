<!DOCTYPE html><html><head><title>Help for package disaggregation</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {disaggregation}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#as.disag_data'><p>Function to fit the disaggregation model</p></a></li>
<li><a href='#build_mesh'><p>Build mesh for disaggregaton model</p></a></li>
<li><a href='#disaggregation-deprecated'><p>Deprecated functions in disaggregation</p></a></li>
<li><a href='#dummy'><p>Roxygen commands</p></a></li>
<li><a href='#fit_model'><p>Fit the disaggregation model</p></a></li>
<li><a href='#getCovariateRasters'><p>Get a SpatRaster of covariates from a folder containing .tif files</p></a></li>
<li><a href='#getPolygonData'><p>Extract polygon id and response data into a data.frame from a sf object</p></a></li>
<li><a href='#getStartendindex'><p>Function to match pixels to their corresponding polygon</p></a></li>
<li><a href='#make_model_object'><p>Create the TMB model object for the disaggregation model</p></a></li>
<li><a href='#plot.disag_data'><p>Plot input data for disaggregation</p></a></li>
<li><a href='#plot.disag_model'><p>Plot results of fitted model</p></a></li>
<li><a href='#plot.disag_prediction'><p>Plot mean and uncertainty predictions from the disaggregation model results</p></a></li>
<li><a href='#predict_model'><p>Function to predict mean from the model result</p></a></li>
<li><a href='#predict_uncertainty'><p>Function to predict uncertainty from the model result</p></a></li>
<li><a href='#predict.disag_model'><p>Predict mean and uncertainty from the disaggregation model result</p></a></li>
<li><a href='#prepare_data'><p>Prepare data for disaggregation modelling</p></a></li>
<li><a href='#print.disag_data'><p>Print function for disaggregation input data</p></a></li>
<li><a href='#print.disag_model'><p>Print function for disaggregation fit result.</p></a></li>
<li><a href='#print.disag_prediction'><p>Print function for disaggregation prediction</p></a></li>
<li><a href='#summary.disag_data'><p>Summary function for disaggregation input data</p></a></li>
<li><a href='#summary.disag_model'><p>Summary function for disaggregation fit result</p></a></li>
<li><a href='#summary.disag_prediction'><p>Summary function for disaggregation prediction</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Disaggregation Modelling</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Fits disaggregation regression models using 'TMB' ('Template Model
    Builder'). When the response data are aggregated to polygon level but
    the predictor variables are at a higher resolution, these models can be
    useful. Regression models with spatial random fields. The package is 
    described in detail in Nandi et al. (2023) &lt;<a href="https://doi.org/10.18637%2Fjss.v106.i11">doi:10.18637/jss.v106.i11</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Imports:</td>
<td>splancs, Matrix, stats, TMB, dplyr, ggplot2, cowplot,
sparseMVN, fmesher, tidyterra, terra, sf, utils</td>
</tr>
<tr>
<td>Additional_repositories:</td>
<td><a href="https://inla.r-inla-download.org/R/stable">https://inla.r-inla-download.org/R/stable</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, INLA, knitr, rmarkdown, SpatialEpi</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>TMB, RcppEigen</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>GNU make</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-08 09:12:28 UTC; simon</td>
</tr>
<tr>
<td>Author:</td>
<td>Anita Nandi <a href="https://orcid.org/0000-0002-5087-2494"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Tim Lucas <a href="https://orcid.org/0000-0003-4694-8107"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Rohan Arambepola [aut],
  Andre Python <a href="https://orcid.org/0000-0001-8094-7226"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Simon Smart [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Tim Lucas &lt;timcdlucas@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-08 14:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='as.disag_data'>Function to fit the disaggregation model</h2><span id='topic+as.disag_data'></span>

<h3>Description</h3>

<p>Function to fit the disaggregation model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.disag_data(
  polygon_shapefile,
  shapefile_names,
  covariate_rasters,
  polygon_data,
  covariate_data,
  aggregation_pixels,
  coordsForFit,
  coordsForPrediction,
  startendindex,
  mesh = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.disag_data_+3A_polygon_shapefile">polygon_shapefile</code></td>
<td>
<p>sf object containing the response data</p>
</td></tr>
<tr><td><code id="as.disag_data_+3A_shapefile_names">shapefile_names</code></td>
<td>
<p>List of 2: polygon id variable name and response variable name from x</p>
</td></tr>
<tr><td><code id="as.disag_data_+3A_covariate_rasters">covariate_rasters</code></td>
<td>
<p>SpatRaster of covariates</p>
</td></tr>
<tr><td><code id="as.disag_data_+3A_polygon_data">polygon_data</code></td>
<td>
<p>data.frame with two columns: polygon id and response</p>
</td></tr>
<tr><td><code id="as.disag_data_+3A_covariate_data">covariate_data</code></td>
<td>
<p>data.frame with cell id, polygon id and covariate columns</p>
</td></tr>
<tr><td><code id="as.disag_data_+3A_aggregation_pixels">aggregation_pixels</code></td>
<td>
<p>vector with value of aggregation raster at each pixel</p>
</td></tr>
<tr><td><code id="as.disag_data_+3A_coordsforfit">coordsForFit</code></td>
<td>
<p>coordinates of the covariate data points within the polygons in x</p>
</td></tr>
<tr><td><code id="as.disag_data_+3A_coordsforprediction">coordsForPrediction</code></td>
<td>
<p>coordinates of the covariate data points in the whole raster extent</p>
</td></tr>
<tr><td><code id="as.disag_data_+3A_startendindex">startendindex</code></td>
<td>
<p>matrix containing the start and end index for each polygon</p>
</td></tr>
<tr><td><code id="as.disag_data_+3A_mesh">mesh</code></td>
<td>
<p>inla.mesh object to use in the fit</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list is returned of class <code>disag_data</code>.
The functions <em>summary</em>, <em>print</em> and <em>plot</em> can be used on <code>disag_data</code>.
The list  of class <code>disag_data</code> contains:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The sf object used as an input.</p>
</td></tr>
<tr><td><code>covariate_rasters</code></td>
<td>
<p>The SpatRaster used as an input.</p>
</td></tr>
<tr><td><code>polygon_data</code></td>
<td>
<p>A data frame with columns of <em>area_id</em>, <em>response</em> and <em>N</em> (sample size: all NAs unless using binomial data). Each row represents a polygon.</p>
</td></tr>
<tr><td><code>covariate_data</code></td>
<td>
<p>A data frame with columns of <em>area_id</em>, <em>cell_id</em> and one for each covariate in <em>covariate_rasters</em>. Each row represents a pixel in a polygon.</p>
</td></tr>
<tr><td><code>aggregation_pixels</code></td>
<td>
<p>An array with the value of the aggregation raster for each pixel in the same order as the rows of <em>covariate_data</em>.</p>
</td></tr>
<tr><td><code>coordsForFit</code></td>
<td>
<p>A matrix with two columns of x, y coordinates of pixels within the polygons. Used to make the spatial field.</p>
</td></tr>
<tr><td><code>coordsForPrediction</code></td>
<td>
<p>A matrix with two columns of x, y coordinates of pixels in the whole Raster. Used to make predictions.</p>
</td></tr>
<tr><td><code>startendindex</code></td>
<td>
<p>A matrix with two columns containing the start and end index of the pixels within each polygon.</p>
</td></tr>
<tr><td><code>mesh</code></td>
<td>
<p>A INLA mesh to be used for the spatial field of the disaggregation model.</p>
</td></tr>
</table>

<hr>
<h2 id='build_mesh'>Build mesh for disaggregaton model</h2><span id='topic+build_mesh'></span>

<h3>Description</h3>

<p><em>build_mesh</em> function takes a sf object and mesh arguments to build an appropriate mesh for the spatial field.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>build_mesh(shapes, mesh.args = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="build_mesh_+3A_shapes">shapes</code></td>
<td>
<p>sf covering the region under investigation.</p>
</td></tr>
<tr><td><code id="build_mesh_+3A_mesh.args">mesh.args</code></td>
<td>
<p>list of parameters that control the mesh structure. <em>convex</em>, <em>concave</em> and <em>resolution</em>,
to control the boundary of the inner mesh, and <em>max.edge</em>, <em>cut</em> and <em>offset</em>, to control the  mesh itself,
with the parameters having the same meaning as in the INLA functions <em>inla.convex.hull</em> and <em>inla.mesh.2d</em>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mesh is created by finding a tight boundary around the polygon data, and creating a fine mesh within the boundary
and a coarser mesh outside. This speeds up computation time by only having a very fine mesh within the area of interest
and having a small region outside with a coarser mesh to avoid edge effects.
</p>
<p>Six mesh parameters can be specified as arguments: <em>convex</em>, <em>concave</em> and <em>resolution</em>,
to control the boundary of the inner mesh, and <em>max.edge</em>, <em>cut</em> and <em>offset</em>, to control the  mesh itself,
with the names meaning the same as used by INLA functions <em>inla.convex.hull</em> and <em>inla.mesh.2d</em>.
</p>
<p>Defaults are:
pars &lt;- list(convex = -0.01, concave = -0.5, resolution = 300, max.edge = c(3.0, 8),  cut = 0.4, offset = c(1, 15)).
</p>


<h3>Value</h3>

<p>An inla.mesh object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
polygons &lt;- list()
for(i in 1:14) {
  row &lt;- ceiling(i/10)
  col &lt;- ifelse(i %% 10 != 0, i %% 10, 10)
  xmin = 2*(col - 1); xmax = 2*col; ymin = 2*(row - 1); ymax = 2*row
polygons[[i]] &lt;- list(cbind(c(xmin, xmax, xmax, xmin, xmin),
                            c(ymax, ymax, ymin, ymin, ymax)))
}

polys &lt;- lapply(polygons, sf::st_polygon)
response_df &lt;- data.frame(area_id = 1:100,
                          response = runif(100, min = 0, max = 10))
spdf &lt;- sf::st_sf(polys, response_df)

my_mesh &lt;- build_mesh(spdf)

## End(Not run)

</code></pre>

<hr>
<h2 id='disaggregation-deprecated'>Deprecated functions in disaggregation</h2><span id='topic+disaggregation-deprecated'></span>

<h3>Description</h3>

<p>These functions still work but will be removed (defunct) in the next version.
</p>


<h3>Details</h3>


<ul>
<li> <p><code><a href="#topic+fit_model">fit_model</a></code>: This function is deprecated, and will
be removed in the next version of this package.
</p>
</li></ul>


<hr>
<h2 id='dummy'>Roxygen commands</h2><span id='topic+dummy'></span>

<h3>Description</h3>

<p>Roxygen commands
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dummy()
</code></pre>

<hr>
<h2 id='fit_model'>Fit the disaggregation model</h2><span id='topic+fit_model'></span><span id='topic+disag_model'></span>

<h3>Description</h3>

<p><em>fit_model</em> function takes a <em>disag_data</em> object created by
<code><a href="#topic+prepare_data">prepare_data</a></code> and performs a Bayesian disaggregation fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_model(
  data,
  priors = NULL,
  family = "gaussian",
  link = "identity",
  iterations = 100,
  field = TRUE,
  iid = TRUE,
  hess_control_parscale = NULL,
  hess_control_ndeps = 1e-04,
  silent = TRUE
)

disag_model(
  data,
  priors = NULL,
  family = "gaussian",
  link = "identity",
  iterations = 100,
  field = TRUE,
  iid = TRUE,
  hess_control_parscale = NULL,
  hess_control_ndeps = 1e-04,
  silent = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit_model_+3A_data">data</code></td>
<td>
<p>disag_data object returned by <code><a href="#topic+prepare_data">prepare_data</a></code> function that contains all the necessary objects for the model fitting</p>
</td></tr>
<tr><td><code id="fit_model_+3A_priors">priors</code></td>
<td>
<p>list of prior values</p>
</td></tr>
<tr><td><code id="fit_model_+3A_family">family</code></td>
<td>
<p>likelihood function: <em>gaussian</em>, <em>binomial</em> or <em>poisson</em></p>
</td></tr>
<tr><td><code id="fit_model_+3A_link">link</code></td>
<td>
<p>link function: <em>logit</em>, <em>log</em> or <em>identity</em></p>
</td></tr>
<tr><td><code id="fit_model_+3A_iterations">iterations</code></td>
<td>
<p>number of iterations to run the optimisation for</p>
</td></tr>
<tr><td><code id="fit_model_+3A_field">field</code></td>
<td>
<p>logical. Flag the spatial field on or off</p>
</td></tr>
<tr><td><code id="fit_model_+3A_iid">iid</code></td>
<td>
<p>logical. Flag the iid effect on or off</p>
</td></tr>
<tr><td><code id="fit_model_+3A_hess_control_parscale">hess_control_parscale</code></td>
<td>
<p>Argument to scale parameters during the calculation of the Hessian.
Must be the same length as the number of parameters. See <code><a href="stats.html#topic+optimHess">optimHess</a></code> for details.</p>
</td></tr>
<tr><td><code id="fit_model_+3A_hess_control_ndeps">hess_control_ndeps</code></td>
<td>
<p>Argument to control step sizes during the calculation of the Hessian.
Either length 1 (same step size applied to all parameters) or the same length as the number of parameters.
Default is 1e-3, try setting a smaller value if you get NaNs in the standard error of the parameters.
See <code><a href="stats.html#topic+optimHess">optimHess</a></code> for details.</p>
</td></tr>
<tr><td><code id="fit_model_+3A_silent">silent</code></td>
<td>
<p>logical. Suppress verbose output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>The model definition</strong>
</p>
<p>The disaggregation model makes predictions at the pixel level:
</p>
<p style="text-align: center;"><code class="reqn">link(pred_i) = \beta_0 + \beta X + GP(s_i) + u_i</code>
</p>

<p>And then aggregates these predictions to the polygon level using the weighted sum (via the aggregation raster, <code class="reqn">agg_i</code>):
</p>
<p style="text-align: center;"><code class="reqn">cases_j = \sum_{i \epsilon j} pred_i \times agg_i</code>
</p>

<p style="text-align: center;"><code class="reqn">rate_j = \frac{\sum_{i \epsilon j} pred_i \times agg_i}{\sum_{i \epsilon j} agg_i}</code>
</p>

<p>The different likelihood correspond to slightly different models (<code class="reqn">y_j</code> is the response count data):
</p>

<ul>
<li><p> Gaussian:
If <code class="reqn">\sigma</code> is the dispersion of the pixel data, <code class="reqn">\sigma_j</code> is the dispersion of the polygon data, where
<code class="reqn">\sigma_j = \sigma \sqrt{\sum agg_i^2} / \sum agg_i </code>
</p>
<p style="text-align: center;"><code class="reqn">dnorm(y_j/\sum agg_i, rate_j, \sigma_j)</code>
</p>
<p> - predicts incidence rate.
</p>
</li>
<li><p> Binomial:
For a survey in polygon j, <code class="reqn">y_j</code> is the number positive and <code class="reqn">N_j</code> is the number tested.
</p>
<p style="text-align: center;"><code class="reqn">dbinom(y_j, N_j, rate_j)</code>
</p>
<p> - predicts prevalence rate.
</p>
</li>
<li><p> Poisson:
</p>
<p style="text-align: center;"><code class="reqn">dpois(y_j, cases_j)</code>
</p>
<p> - predicts incidence count.
</p>
</li></ul>

<p>Specify priors for the regression parameters, field and iid effect as a single list. Hyperpriors for the field
are given as penalised complexity priors you specify <code class="reqn">\rho_{min}</code> and <code class="reqn">\rho_{prob}</code> for the range of the field
where <code class="reqn">P(\rho &lt; \rho_{min}) = \rho_{prob}</code>, and <code class="reqn">\sigma_{min}</code> and <code class="reqn">\sigma_{prob}</code> for the variation of the field
where <code class="reqn">P(\sigma &gt; \sigma_{min}) = \sigma_{prob}</code>. Also, specify pc priors for the iid effect
</p>
<p>The <em>family</em> and <em>link</em> arguments are used to specify the likelihood and link function respectively.
The likelihood function can be one of <em>gaussian</em>, <em>poisson</em> or <em>binomial</em>.
The link function can be one of <em>logit</em>, <em>log</em> or <em>identity</em>.
These are specified as strings.
</p>
<p>The field and iid effect can be turned on or off via the <em>field</em> and <em>iid</em> logical flags. Both are default TRUE.
</p>
<p>The <em>iterations</em> argument specifies the maximum number of iterations the model can run for to find an optimal point.
</p>
<p>The <em>silent</em> argument can be used to publish/suppress verbose output. Default TRUE.
</p>


<h3>Value</h3>

<p>A list is returned of class <code>disag_model</code>.
The functions <em>summary</em>, <em>print</em> and <em>plot</em> can be used on <code>disag_model</code>.
The list  of class <code>disag_model</code> contains:
</p>
<table>
<tr><td><code>obj</code></td>
<td>
<p>The TMB model object returned by <code><a href="TMB.html#topic+MakeADFun">MakeADFun</a></code>.</p>
</td></tr>
<tr><td><code>opt</code></td>
<td>
<p>The optimized model object returned by <code><a href="stats.html#topic+nlminb">nlminb</a></code>.</p>
</td></tr>
<tr><td><code>sd_out</code></td>
<td>
<p>The TMB object returned by <code><a href="TMB.html#topic+sdreport">sdreport</a></code>.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>The <em>disag_data</em> object used as an input to the model.</p>
</td></tr>
<tr><td><code>model_setup</code></td>
<td>
<p>A list of information on the model setup. Likelihood function (<em>family</em>), link function(<em>link</em>), logical: whether a field was used (<em>field</em>) and logical: whether an iid effect was used (<em>iid</em>).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Nanda et al. (2023) disaggregation: An R Package for Bayesian
Spatial Disaggregation Modeling. &lt;doi:10.18637/jss.v106.i11&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
polygons &lt;- list()
n_polygon_per_side &lt;- 10
n_polygons &lt;- n_polygon_per_side * n_polygon_per_side
n_pixels_per_side &lt;- n_polygon_per_side * 2

for(i in 1:n_polygons) {
  row &lt;- ceiling(i/n_polygon_per_side)
  col &lt;- ifelse(i %% n_polygon_per_side != 0, i %% n_polygon_per_side, n_polygon_per_side)
  xmin = 2*(col - 1); xmax = 2*col; ymin = 2*(row - 1); ymax = 2*row
  polygons[[i]] &lt;- list(cbind(c(xmin, xmax, xmax, xmin, xmin),
                              c(ymax, ymax, ymin, ymin, ymax)))
}

polys &lt;- lapply(polygons,sf::st_polygon)
N &lt;- floor(runif(n_polygons, min = 1, max = 100))
response_df &lt;- data.frame(area_id = 1:n_polygons, response = runif(n_polygons, min = 0, max = 1000))

spdf &lt;- sf::st_sf(response_df, geometry = polys)

# Create raster stack
r &lt;- terra::rast(ncol=n_pixels_per_side, nrow=n_pixels_per_side)
terra::ext(r) &lt;- terra::ext(spdf)
r[] &lt;- sapply(1:terra::ncell(r), function(x){
rnorm(1, ifelse(x %% n_pixels_per_side != 0, x %% n_pixels_per_side, n_pixels_per_side), 3))}
r2 &lt;- terra::rast(ncol=n_pixels_per_side, nrow=n_pixels_per_side)
terra::ext(r2) &lt;- terra::ext(spdf)
r2[] &lt;- sapply(1:terra::ncell(r), function(x) rnorm(1, ceiling(x/n_pixels_per_side), 3))
cov_stack &lt;- c(r, r2)
names(cov_stack) &lt;- c('layer1', 'layer2')

test_data &lt;- prepare_data(polygon_shapefile = spdf,
                          covariate_rasters = cov_stack)

 result &lt;- fit_model(test_data, iterations = 2)
 
## End(Not run)

</code></pre>

<hr>
<h2 id='getCovariateRasters'>Get a SpatRaster of covariates from a folder containing .tif files</h2><span id='topic+getCovariateRasters'></span>

<h3>Description</h3>

<p>Looks in a specified folder for raster files. Returns a multi-layered SpatRaster of the rasters cropped to the extent specified by the shape parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getCovariateRasters(directory, file_pattern = ".tif$", shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getCovariateRasters_+3A_directory">directory</code></td>
<td>
<p>Filepath to the directory containing the rasters.</p>
</td></tr>
<tr><td><code id="getCovariateRasters_+3A_file_pattern">file_pattern</code></td>
<td>
<p>Pattern the filenames must match. Default is all files ending in .tif .</p>
</td></tr>
<tr><td><code id="getCovariateRasters_+3A_shape">shape</code></td>
<td>
<p>An object with an extent that the rasters will be cropped to.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A multi-layered SpatRaster of the raster files in the directory
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  getCovariateRasters('/home/rasters', '.tif$', shape)
 
## End(Not run)

</code></pre>

<hr>
<h2 id='getPolygonData'>Extract polygon id and response data into a data.frame from a sf object</h2><span id='topic+getPolygonData'></span>

<h3>Description</h3>

<p>Returns a data.frame with a row for each polygon in the sf object and columns: area_id, response and N, containing the id of the
polygon, the values of the response for that polygon, and the sample size respectively. If the data is not survey data (the sample size does
not exist), this column will contain NAs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPolygonData(
  shape,
  id_var = "area_id",
  response_var = "response",
  sample_size_var = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getPolygonData_+3A_shape">shape</code></td>
<td>
<p>A sf object containing response data.</p>
</td></tr>
<tr><td><code id="getPolygonData_+3A_id_var">id_var</code></td>
<td>
<p>Name of column in shape object with the polygon id. Default 'area_id'.</p>
</td></tr>
<tr><td><code id="getPolygonData_+3A_response_var">response_var</code></td>
<td>
<p>Name of column in shape object with the response data. Default 'response'.</p>
</td></tr>
<tr><td><code id="getPolygonData_+3A_sample_size_var">sample_size_var</code></td>
<td>
<p>For survey data, name of column in sf object (if it exists) with the sample size data. Default NULL.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame with a row for each polygon in the sf object and columns: area_id, response and N, containing the id of the
polygon, the values of the response for that polygon, and the sample size respectively. If the data is not survey data (the sample size does
not exist), this column will contain NAs.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
polygons &lt;- list()
for(i in 1:100) {
  row &lt;- ceiling(i/10)
  col &lt;- ifelse(i %% 10 != 0, i %% 10, 10)
  xmin = 2*(col - 1); xmax = 2*col; ymin = 2*(row - 1); ymax = 2*row
  polygons[[i]] &lt;- list(cbind(c(xmin, xmax, xmax, xmin, xmin),
                              c(ymax, ymax, ymin, ymin, ymax)))
}

polys &lt;- lapply(polygons,sf::st_polygon)
response_df &lt;- data.frame(area_id = 1:100, response = runif(100, min = 0, max = 10))
spdf &lt;- sf::st_sf(response_df, geometry = polys)

 getPolygonData(spdf, id_var = 'area_id', response_var = 'response')
}


</code></pre>

<hr>
<h2 id='getStartendindex'>Function to match pixels to their corresponding polygon</h2><span id='topic+getStartendindex'></span>

<h3>Description</h3>

<p>From the covariate data and polygon data, the function matches the polygon id between the two to find
which pixels from the covariate data are contained in each of the polygons.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getStartendindex(covariates, polygon_data, id_var = "area_id")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getStartendindex_+3A_covariates">covariates</code></td>
<td>
<p>data.frame with each covariate as a column an and id column.</p>
</td></tr>
<tr><td><code id="getStartendindex_+3A_polygon_data">polygon_data</code></td>
<td>
<p>data.frame with polygon id and response data.</p>
</td></tr>
<tr><td><code id="getStartendindex_+3A_id_var">id_var</code></td>
<td>
<p>string with the name of the column in the covariate data.frame containing the polygon id.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Takes a data.frame containing the covariate data with a polygon id column and one column for each covariate,
and another data.frame containing polygon data with a polygon id, response and sample size column (as returned
by <code>getPolygonData</code> function).
</p>
<p>Returns a matrix with two columns and one row for each polygon. The first column is the index of the first row in
covariate data that corresponds to that polygon, the second column is the index of the last row in
covariate data that corresponds to that polygon.
</p>


<h3>Value</h3>

<p>A matrix with two columns and one row for each polygon. The first column is the index of the first row in
covariate data that corresponds to that polygon, the second column is the index of the last row in
covariate data that corresponds to that polygon.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
 covs &lt;- data.frame(area_id = c(1, 1, 1, 2, 2, 3, 3, 3, 3), response = c(3, 9, 5, 2, 3, 6, 7, 3, 5))
 response &lt;- data.frame(area_id = c(1, 2, 3), response = c(4, 7, 2), N = c(NA, NA, NA))
 getStartendindex(covs, response, 'area_id')
}


</code></pre>

<hr>
<h2 id='make_model_object'>Create the TMB model object for the disaggregation model</h2><span id='topic+make_model_object'></span>

<h3>Description</h3>

<p><em>make_model_object</em> function takes a <em>disag_data</em> object created by <code><a href="#topic+prepare_data">prepare_data</a></code>
and creates a TMB model object to be used in fitting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_model_object(
  data,
  priors = NULL,
  family = "gaussian",
  link = "identity",
  field = TRUE,
  iid = TRUE,
  silent = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_model_object_+3A_data">data</code></td>
<td>
<p>disag_data object returned by <code><a href="#topic+prepare_data">prepare_data</a></code> function that contains all the necessary objects for the model fitting</p>
</td></tr>
<tr><td><code id="make_model_object_+3A_priors">priors</code></td>
<td>
<p>list of prior values</p>
</td></tr>
<tr><td><code id="make_model_object_+3A_family">family</code></td>
<td>
<p>likelihood function: <em>gaussian</em>, <em>binomial</em> or <em>poisson</em></p>
</td></tr>
<tr><td><code id="make_model_object_+3A_link">link</code></td>
<td>
<p>link function: <em>logit</em>, <em>log</em> or <em>identity</em></p>
</td></tr>
<tr><td><code id="make_model_object_+3A_field">field</code></td>
<td>
<p>logical. Flag the spatial field on or off</p>
</td></tr>
<tr><td><code id="make_model_object_+3A_iid">iid</code></td>
<td>
<p>logical. Flag the iid effect on or off</p>
</td></tr>
<tr><td><code id="make_model_object_+3A_silent">silent</code></td>
<td>
<p>logical. Suppress verbose output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>The model definition</strong>
</p>
<p>The disaggregation model make predictions at the pixel level:
</p>
<p style="text-align: center;"><code class="reqn">link(pred_i) = \beta_0 + \beta X + GP(s_i) + u_i</code>
</p>

<p>And then aggregates these predictions to the polygon level using the weighted sum (via the aggregation raster, <code class="reqn">agg_i</code>):
</p>
<p style="text-align: center;"><code class="reqn">cases_j = \sum_{i \epsilon j} pred_i \times agg_i</code>
</p>

<p style="text-align: center;"><code class="reqn">rate_j = \frac{\sum_{i \epsilon j} pred_i \times agg_i}{\sum_{i \epsilon j} agg_i}</code>
</p>

<p>The different likelihood correspond to slightly different models (<code class="reqn">y_j</code> is the response count data):
</p>

<ul>
<li><p> Gaussian:
If <code class="reqn">\sigma</code> is the dispersion of the pixel data, <code class="reqn">\sigma_j</code> is the dispersion of the polygon data, where
<code class="reqn">\sigma_j = \sigma \sqrt{\sum agg_i^2} / \sum agg_i </code>
</p>
<p style="text-align: center;"><code class="reqn">dnorm(y_j/\sum agg_i, rate_j, \sigma_j)</code>
</p>
<p> - predicts incidence rate.
</p>
</li>
<li><p> Binomial:
For a survey in polygon j, <code class="reqn">y_j</code> is the number positive and <code class="reqn">N_j</code> is the number tested.
</p>
<p style="text-align: center;"><code class="reqn">dbinom(y_j, N_j, rate_j)</code>
</p>
<p> - predicts prevalence rate.
</p>
</li>
<li><p> Poisson:
</p>
<p style="text-align: center;"><code class="reqn">dpois(y_j, cases_j)</code>
</p>
<p> - predicts incidence count.
</p>
</li></ul>

<p>Specify priors for the regression parameters, field and iid effect as a single named list. Hyperpriors for the field
are given as penalised complexity priors you specify <code class="reqn">\rho_{min}</code> and <code class="reqn">\rho_{prob}</code> for the range of the field
where <code class="reqn">P(\rho &lt; \rho_{min}) = \rho_{prob}</code>, and <code class="reqn">\sigma_{min}</code> and <code class="reqn">\sigma_{prob}</code> for the variation of the field
where <code class="reqn">P(\sigma &gt; \sigma_{min}) = \sigma_{prob}</code>. Also, specify pc priors for the iid effect.
</p>
<p>The precise names and default values for these priors are:
</p>

<ul>
<li><p> priormean_intercept: 0
</p>
</li>
<li><p> priorsd_intercept: 10.0
</p>
</li>
<li><p> priormean_slope: 0.0
</p>
</li>
<li><p> priorsd_slope: 0.5
</p>
</li>
<li><p> prior_rho_min: A third the length of the diagonal of the bounding box.
</p>
</li>
<li><p> prior_rho_prob: 0.1
</p>
</li>
<li><p> prior_sigma_max: sd(response/mean(response))
</p>
</li>
<li><p> prior_sigma_prob: 0.1
</p>
</li>
<li><p> prior_iideffect_sd_max: 0.1
</p>
</li>
<li><p> prior_iideffect_sd_prob: 0.01
</p>
</li></ul>

<p>The <em>family</em> and <em>link</em> arguments are used to specify the likelihood and link function respectively.
The likelihood function can be one of <em>gaussian</em>, <em>poisson</em> or <em>binomial</em>.
The link function can be one of <em>logit</em>, <em>log</em> or <em>identity</em>.
These are specified as strings.
</p>
<p>The field and iid effect can be turned on or off via the <em>field</em> and <em>iid</em> logical flags. Both are default TRUE.
</p>
<p>The <em>iterations</em> argument specifies the maximum number of iterations the model can run for to find an optimal point.
</p>
<p>The <em>silent</em> argument can be used to publish/supress verbose output. Default TRUE.
</p>


<h3>Value</h3>

<p>The TMB model object returned by <code><a href="TMB.html#topic+MakeADFun">MakeADFun</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
polygons &lt;- list()
n_polygon_per_side &lt;- 10
n_polygons &lt;- n_polygon_per_side * n_polygon_per_side
n_pixels_per_side &lt;- n_polygon_per_side * 2

for(i in 1:n_polygons) {
  row &lt;- ceiling(i/n_polygon_per_side)
  col &lt;- ifelse(i %% n_polygon_per_side != 0, i %% n_polygon_per_side, n_polygon_per_side)
  xmin = 2*(col - 1); xmax = 2*col; ymin = 2*(row - 1); ymax = 2*row
  polygons[[i]] &lt;- list(cbind(c(xmin, xmax, xmax, xmin, xmin),
                              c(ymax, ymax, ymin, ymin, ymax)))
}

polys &lt;- lapply(polygons,sf::st_polygon)
N &lt;- floor(runif(n_polygons, min = 1, max = 100))
response_df &lt;- data.frame(area_id = 1:n_polygons, response = runif(n_polygons, min = 0, max = 1000))

spdf &lt;- sf::st_sf(response_df, geometry = polys)

# Create raster stack
r &lt;- terra::rast(ncol=n_pixels_per_side, nrow=n_pixels_per_side)
terra::ext(r) &lt;- terra::ext(spdf)
r[] &lt;- sapply(1:terra::ncell(r), function(x){
rnorm(1, ifelse(x %% n_pixels_per_side != 0, x %% n_pixels_per_side, n_pixels_per_side), 3))}
r2 &lt;- terra::rast(ncol=n_pixels_per_side, nrow=n_pixels_per_side)
terra::ext(r2) &lt;- terra::ext(spdf)
r2[] &lt;- sapply(1:terra::ncell(r), function(x) rnorm(1, ceiling(x/n_pixels_per_side), 3))
cov_stack &lt;- c(r, r2)
names(cov_stack) &lt;- c('layer1', 'layer2')

test_data &lt;- prepare_data(polygon_shapefile = spdf,
                          covariate_rasters = cov_stack)

 result &lt;- make_model_object(test_data)
 
## End(Not run)

</code></pre>

<hr>
<h2 id='plot.disag_data'>Plot input data for disaggregation</h2><span id='topic+plot.disag_data'></span>

<h3>Description</h3>

<p>Plotting function for class <em>disag_data</em> (the input data for disaggregation).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'disag_data'
plot(x, which = c(1, 2, 3), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.disag_data_+3A_x">x</code></td>
<td>
<p>Object of class <em>disag_data</em> to be plotted.</p>
</td></tr>
<tr><td><code id="plot.disag_data_+3A_which">which</code></td>
<td>
<p>If a subset of plots is required, specify a subset of the numbers 1:3</p>
</td></tr>
<tr><td><code id="plot.disag_data_+3A_...">...</code></td>
<td>
<p>Further arguments to <em>plot</em> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Produces three plots: polygon response data, covariate rasters and INLA mesh.
</p>


<h3>Value</h3>

<p>A list of three plots: the polygon plot (ggplot), covariate plot (spplot) and INLA mesh plot (ggplot)
</p>

<hr>
<h2 id='plot.disag_model'>Plot results of fitted model</h2><span id='topic+plot.disag_model'></span>

<h3>Description</h3>

<p>Plotting function for class <em>disag_model</em> (the result of the disaggregation fitting).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'disag_model'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.disag_model_+3A_x">x</code></td>
<td>
<p>Object of class <em>disag_model</em> to be plotted.</p>
</td></tr>
<tr><td><code id="plot.disag_model_+3A_...">...</code></td>
<td>
<p>Further arguments to <em>plot</em> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Produces two plots: results of the fixed effects and in-sample observed vs predicted plot.
</p>


<h3>Value</h3>

<p>A list of two ggplot plots: results of the fixed effects and an in-sample observed vs predicted plot
</p>

<hr>
<h2 id='plot.disag_prediction'>Plot mean and uncertainty predictions from the disaggregation model results</h2><span id='topic+plot.disag_prediction'></span>

<h3>Description</h3>

<p>Plotting function for class <em>disag_prediction</em> (the mean and uncertainty predictions of the disaggregation fitting).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'disag_prediction'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.disag_prediction_+3A_x">x</code></td>
<td>
<p>Object of class <em>disag_prediction</em> to be plotted.</p>
</td></tr>
<tr><td><code id="plot.disag_prediction_+3A_...">...</code></td>
<td>
<p>Further arguments to <em>plot</em> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Produces raster plots of the mean prediction, and the lower and upper confidence intervals.
</p>


<h3>Value</h3>

<p>A list of plots of rasters from the prediction: mean prediction, lower CI and upper CI.
</p>

<hr>
<h2 id='predict_model'>Function to predict mean from the model result</h2><span id='topic+predict_model'></span>

<h3>Description</h3>

<p><em>predict_model</em> function takes a <em>disag_model</em> object created by
<em>disaggregation::disag_model</em> and predicts mean maps.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_model(model_output, newdata = NULL, predict_iid = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_model_+3A_model_output">model_output</code></td>
<td>
<p>disag_model object returned by disag_model function</p>
</td></tr>
<tr><td><code id="predict_model_+3A_newdata">newdata</code></td>
<td>
<p>If NULL, predictions are made using the data in model_output.
If this is a raster stack or brick, predictions will be made over this data. Default NULL.</p>
</td></tr>
<tr><td><code id="predict_model_+3A_predict_iid">predict_iid</code></td>
<td>
<p>If TRUE, any polygon iid effect from the model will be used in the prediction. Default FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function returns rasters of the mean predictions as well as the  covariate and field contributions
to the linear predictor.
</p>
<p>To predict over a different spatial extent to that used in the model,
a SpatRaster covering the region to make predictions over is passed to the argument <em>newdata</em>.
If this is not given predictions are made over the data used in the fit.
</p>
<p>The <em>predict_iid</em> logical flag should be set to TRUE if the results of the iid effect from the model are to be used in the prediction.
</p>


<h3>Value</h3>

<p>The mean prediction, which is a list of:
</p>

<ul>
<li> <p><em>prediction</em> Raster of mean predictions based.
</p>
</li>
<li> <p><em>field</em> Raster of the field component of the linear predictor.
</p>
</li>
<li> <p><em>iid</em> Raster of the iid component of the linear predictor.
</p>
</li>
<li> <p><em>covariates</em> Raster of the covariate component of the linear predictor.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
predict_model(result)

## End(Not run)

</code></pre>

<hr>
<h2 id='predict_uncertainty'>Function to predict uncertainty from the model result</h2><span id='topic+predict_uncertainty'></span>

<h3>Description</h3>

<p><em>predict_uncertainty</em> function takes a <em>disag_model</em> object created by
<em>disaggregation::disag_model</em> and predicts upper and lower credible interval maps.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_uncertainty(
  model_output,
  newdata = NULL,
  predict_iid = FALSE,
  N = 100,
  CI = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_uncertainty_+3A_model_output">model_output</code></td>
<td>
<p>disag_model object returned by disag_model function.</p>
</td></tr>
<tr><td><code id="predict_uncertainty_+3A_newdata">newdata</code></td>
<td>
<p>If NULL, predictions are made using the data in model_output.
If this is a raster stack or brick, predictions will be made over this data. Default NULL.</p>
</td></tr>
<tr><td><code id="predict_uncertainty_+3A_predict_iid">predict_iid</code></td>
<td>
<p>If TRUE, any polygon iid effect from the model will be used in the prediction. Default FALSE.</p>
</td></tr>
<tr><td><code id="predict_uncertainty_+3A_n">N</code></td>
<td>
<p>number of realisations. Default: 100.</p>
</td></tr>
<tr><td><code id="predict_uncertainty_+3A_ci">CI</code></td>
<td>
<p>confidence interval. Default: 0.95.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function returns a SpatRaster of the realisations as well as the upper and lower credible interval rasters.
</p>
<p>To predict over a different spatial extent to that used in the model,
a SpatRaster covering the region to make predictions over is passed to the argument <em>newdata</em>.
If this is not given predictions are made over the data used in the fit.
</p>
<p>The <em>predict_iid</em> logical flag should be set to TRUE if the results of the iid effect from the model are to be used in the prediction.
</p>
<p>The number of the realisations and the size of the confidence interval to be calculated.
are given by the arguments <em>N</em> and <em>CI</em> respectively.
</p>


<h3>Value</h3>

<p>The uncertainty prediction, which is a list of:
</p>

<ul>
<li> <p><em>realisations</em> SpatRaster of realisations of predictions. Number of realisations defined by argument <em>N</em>.
</p>
</li>
<li> <p><em>predictions_ci</em> SpatRaster of the upper and lower credible intervals. Defined by argument <em>CI</em>.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
predict_uncertainty(result)

## End(Not run)

</code></pre>

<hr>
<h2 id='predict.disag_model'>Predict mean and uncertainty from the disaggregation model result</h2><span id='topic+predict.disag_model'></span>

<h3>Description</h3>

<p><em>predict.disag_model</em> function takes a <em>disag_model</em> object created by <em>disaggregation::disag_model</em> and
predicts mean and uncertainty maps.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'disag_model'
predict(object, newdata = NULL, predict_iid = FALSE, N = 100, CI = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.disag_model_+3A_object">object</code></td>
<td>
<p>disag_model object returned by disag_model function.</p>
</td></tr>
<tr><td><code id="predict.disag_model_+3A_newdata">newdata</code></td>
<td>
<p>If NULL, predictions are made using the data in model_output.
If this is a raster stack or brick, predictions will be made over this data.</p>
</td></tr>
<tr><td><code id="predict.disag_model_+3A_predict_iid">predict_iid</code></td>
<td>
<p>logical. If TRUE, any polygon iid effect from the model will be used in the prediction. Default FALSE.</p>
</td></tr>
<tr><td><code id="predict.disag_model_+3A_n">N</code></td>
<td>
<p>Number of realisations. Default: 100.</p>
</td></tr>
<tr><td><code id="predict.disag_model_+3A_ci">CI</code></td>
<td>
<p>Confidence interval to be calculated from the realisations. Default: 0.95.</p>
</td></tr>
<tr><td><code id="predict.disag_model_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To predict over a different spatial extent to that used in the model,
a SpatRaster covering the region to make predictions over is passed to the argument <em>newdata</em>.
If this is not given predictions are made over the data used in the fit.
</p>
<p>The <em>predict_iid</em> logical flag should be set to TRUE if the results of the iid effect from the model are to be used in the prediction.
</p>
<p>For the uncertainty calculations, the number of the realisations and the size of the confidence interval to be calculated
are given by the arguments <em>N</em> and <em>CI</em> respectively.
</p>


<h3>Value</h3>

<p>An object of class <em>disag_prediction</em> which consists of a list of two objects:
</p>
<table>
<tr><td><code>mean_prediction</code></td>
<td>
<p>List of:
</p>

<ul>
<li> <p><em>prediction</em> Raster of mean predictions based.
</p>
</li>
<li> <p><em>field</em> Raster of the field component of the linear predictor.
</p>
</li>
<li> <p><em>iid</em> Raster of the iid component of the linear predictor.
</p>
</li>
<li> <p><em>covariates</em> Raster of the covariate component of the linear predictor.
</p>
</li></ul>
</td></tr>
<tr><td><code>uncertainty_prediction:</code></td>
<td>
<p>List of:
</p>

<ul>
<li> <p><em>realisations</em> SpatRaster of realisations of predictions. Number of realisations defined by argument <em>N</em>.
</p>
</li>
<li> <p><em>predictions_ci</em> SpatRaster of the upper and lower credible intervals. Defined by argument <em>CI</em>.
</p>
</li></ul>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
predict(fit_result)

## End(Not run)

</code></pre>

<hr>
<h2 id='prepare_data'>Prepare data for disaggregation modelling</h2><span id='topic+prepare_data'></span>

<h3>Description</h3>

<p><em>prepare_data</em> function is used to extract all the data required for fitting a disaggregation model.
Designed to be used in the <em>disaggregation::fit_model</em> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prepare_data(
  polygon_shapefile,
  covariate_rasters,
  aggregation_raster = NULL,
  id_var = "area_id",
  response_var = "response",
  sample_size_var = NULL,
  mesh.args = NULL,
  na.action = FALSE,
  makeMesh = TRUE,
  ncores = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prepare_data_+3A_polygon_shapefile">polygon_shapefile</code></td>
<td>
<p>sf object containing at least three columns: one with the geometried, one with the id for the polygons (<em>id_var</em>) and one with the response count data (<em>response_var</em>); for binomial data, i.e survey data, it can also contain a sample size column (<em>sample_size_var</em>).</p>
</td></tr>
<tr><td><code id="prepare_data_+3A_covariate_rasters">covariate_rasters</code></td>
<td>
<p>SpatRaster of covariate rasters to be used in the model.</p>
</td></tr>
<tr><td><code id="prepare_data_+3A_aggregation_raster">aggregation_raster</code></td>
<td>
<p>SpatRaster to aggregate pixel level predictions to polygon level e.g. population to aggregate prevalence. If this is not supplied a uniform raster will be used.</p>
</td></tr>
<tr><td><code id="prepare_data_+3A_id_var">id_var</code></td>
<td>
<p>Name of column in sf object with the polygon id.</p>
</td></tr>
<tr><td><code id="prepare_data_+3A_response_var">response_var</code></td>
<td>
<p>Name of column in sf object with the response data.</p>
</td></tr>
<tr><td><code id="prepare_data_+3A_sample_size_var">sample_size_var</code></td>
<td>
<p>For survey data, name of column in sf object (if it exists) with the sample size data.</p>
</td></tr>
<tr><td><code id="prepare_data_+3A_mesh.args">mesh.args</code></td>
<td>
<p>list of parameters that control the mesh structure with the same names as used by INLA.</p>
</td></tr>
<tr><td><code id="prepare_data_+3A_na.action">na.action</code></td>
<td>
<p>logical. If TRUE, NAs in response will be removed, covariate NAs will be given the median value, aggregation NAs will be set to zero. Default FALSE (NAs in response or covariate data within the polygons will give errors).</p>
</td></tr>
<tr><td><code id="prepare_data_+3A_makemesh">makeMesh</code></td>
<td>
<p>logical. If TRUE, build INLA mesh, takes some time. Default TRUE.</p>
</td></tr>
<tr><td><code id="prepare_data_+3A_ncores">ncores</code></td>
<td>
<p>Deprecated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Takes a sf object with the response data and a SpatRaster of covariates.
</p>
<p>Extract the values of the covariates (as well as the aggregation raster, if given) at each pixel within the polygons
(<em>parallelExtract</em> function). This is done in parallel and <em>n.cores</em> argument is used to set the number of cores
to use for covariate extraction. This can be the number of covariates used in the model.
</p>
<p>The aggregation raster defines how the pixels within each polygon are aggregated.
The disaggregation model performs a weighted sum of the pixel prediction, weighted by the pixel values in the aggregation raster.
For disease incidence rate you use the population raster to aggregate pixel incidence rate by summing the number of cases
(rate weighted by population). If no aggregation raster is provided a uniform distribution is assumed, i.e. the pixel predictions
are aggregated to polygon level by summing the pixel values.
</p>
<p>Makes a matrix that contains the start and end pixel index for each polygon. Builds an INLA mesh to use for the spatial field
(<em>getStartendindex</em> function).
</p>
<p>The <em>mesh.args</em> argument allows you to supply a list of INLA mesh parameters to control the mesh used for the spatial field
(<em>build_mesh</em> function).
</p>
<p>The <em>na.action</em> flag is automatically off. If there are any NAs in the response or covariate data within the polygons the
<em>prepare_data</em> method will error. Ideally the NAs in the data would be dealt with beforehand, however, setting na.action = TRUE
will automatically deal with NAs. It removes any polygons that have NAs as a response, sets any aggregation pixels with NA to zero
and sets covariate NAs pixels to the median value for the that covariate.
</p>


<h3>Value</h3>

<p>A list is returned of class <code>disag_data</code>.
The functions <em>summary</em>, <em>print</em> and <em>plot</em> can be used on <code>disag_data</code>.
The list  of class <code>disag_data</code> contains:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The sf object used as an input.</p>
</td></tr>
<tr><td><code>covariate_rasters</code></td>
<td>
<p>The SpatRaster used as an input.</p>
</td></tr>
<tr><td><code>polygon_data</code></td>
<td>
<p>A data frame with columns of <em>area_id</em>, <em>response</em> and <em>N</em> (sample size: all NAs unless using binomial data). Each row represents a polygon.</p>
</td></tr>
<tr><td><code>covariate_data</code></td>
<td>
<p>A data frame with columns of <em>area_id</em>, <em>cell_id</em> and one for each covariate in <em>covariate_rasters</em>. Each row represents a pixel in a polygon.</p>
</td></tr>
<tr><td><code>aggregation_pixels</code></td>
<td>
<p>An array with the value of the aggregation raster for each pixel in the same order as the rows of <em>covariate_data</em>.</p>
</td></tr>
<tr><td><code>coordsForFit</code></td>
<td>
<p>A matrix with two columns of x, y coordinates of pixels within the polygons. Used to make the spatial field.</p>
</td></tr>
<tr><td><code>coordsForPrediction</code></td>
<td>
<p>A matrix with two columns of x, y coordinates of pixels in the whole Raster. Used to make predictions.</p>
</td></tr>
<tr><td><code>startendindex</code></td>
<td>
<p>A matrix with two columns containing the start and end index of the pixels within each polygon.</p>
</td></tr>
<tr><td><code>mesh</code></td>
<td>
<p>A INLA mesh to be used for the spatial field of the disaggregation model.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
polygons &lt;- list()
for(i in 1:100) {
  row &lt;- ceiling(i/10)
  col &lt;- ifelse(i %% 10 != 0, i %% 10, 10)
  xmin = 2*(col - 1); xmax = 2*col; ymin = 2*(row - 1); ymax = 2*row
  polygons[[i]] &lt;- list(cbind(c(xmin, xmax, xmax, xmin, xmin),
                              c(ymax, ymax, ymin, ymin, ymax)))
}

polys &lt;- lapply(polygons,sf::st_polygon)
response_df &lt;- data.frame(area_id = 1:100, response = runif(100, min = 0, max = 10))
spdf &lt;- sf::st_sf(response_df,geometry=polys)

r &lt;- terra::rast(nrow=20,ncol=20)
terra::ext(r) &lt;- terra::ext(spdf)
r[] &lt;- sapply(1:terra::ncell(r), function(x) rnorm(1, ifelse(x %% 20 != 0, x %% 20, 20), 3))

r2 &lt;- terra::rast(nrow=20,ncol=20)
terra::ext(r2) &lt;- terra::ext(spdf)
r2[] &lt;- sapply(1:terra::ncell(r), function(x) rnorm(1, ceiling(x/10), 3))
cov_rasters &lt;- c(r, r2)

test_data &lt;- prepare_data(polygon_shapefile = spdf,
                          covariate_rasters = cov_rasters)


</code></pre>

<hr>
<h2 id='print.disag_data'>Print function for disaggregation input data</h2><span id='topic+print.disag_data'></span>

<h3>Description</h3>

<p>Function that prints the input data from the disaggregation model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'disag_data'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.disag_data_+3A_x">x</code></td>
<td>
<p>Object returned from prepare_data.</p>
</td></tr>
<tr><td><code id="print.disag_data_+3A_...">...</code></td>
<td>
<p>Further arguments to <em>print</em> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prints the number of polyons and pixels, the number of pixels in the largest and smallest polygons and summaries of the covariates.
</p>

<hr>
<h2 id='print.disag_model'>Print function for disaggregation fit result.</h2><span id='topic+print.disag_model'></span>

<h3>Description</h3>

<p>Function that prints the result of the fit from the disaggregation model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'disag_model'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.disag_model_+3A_x">x</code></td>
<td>
<p>Object returned from disag_model.</p>
</td></tr>
<tr><td><code id="print.disag_model_+3A_...">...</code></td>
<td>
<p>Further arguments to <em>print</em> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prints the negative log likelihood, model parameters and calculates metrics from in-sample performance.
</p>

<hr>
<h2 id='print.disag_prediction'>Print function for disaggregation prediction</h2><span id='topic+print.disag_prediction'></span>

<h3>Description</h3>

<p>Function that prints the prediction from the disaggregation model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'disag_prediction'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.disag_prediction_+3A_x">x</code></td>
<td>
<p>Object returned from predict.disag_model.</p>
</td></tr>
<tr><td><code id="print.disag_prediction_+3A_...">...</code></td>
<td>
<p>Further arguments to <em>print</em> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prints the number of polyons and pixels, the number of pixels in the largest and smallest polygons and summaries of the covariates.
</p>

<hr>
<h2 id='summary.disag_data'>Summary function for disaggregation input data</h2><span id='topic+summary.disag_data'></span>

<h3>Description</h3>

<p>Function that summarizes the input data from the disaggregation model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'disag_data'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.disag_data_+3A_object">object</code></td>
<td>
<p>Object returned from prepare_data.</p>
</td></tr>
<tr><td><code id="summary.disag_data_+3A_...">...</code></td>
<td>
<p>Further arguments to <em>summary</em> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prints the number of polyons and pixels, the number of pixels in the largest and smallest polygons and summaries of the covariates.
</p>


<h3>Value</h3>

<p>A list of the number of polyons, the number of covariates and summaries of the covariates.
</p>

<hr>
<h2 id='summary.disag_model'>Summary function for disaggregation fit result</h2><span id='topic+summary.disag_model'></span>

<h3>Description</h3>

<p>Function that summarises the result of the fit from the disaggregation model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'disag_model'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.disag_model_+3A_object">object</code></td>
<td>
<p>Object returned from disag_model.</p>
</td></tr>
<tr><td><code id="summary.disag_model_+3A_...">...</code></td>
<td>
<p>Further arguments to <em>summary</em> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prints the negative log likelihood, model parameters and calculates metrics from in-sample performance.
</p>


<h3>Value</h3>

<p>A list of the model parameters, negative log likelihood and metrics from in-sample performance.
</p>

<hr>
<h2 id='summary.disag_prediction'>Summary function for disaggregation prediction</h2><span id='topic+summary.disag_prediction'></span>

<h3>Description</h3>

<p>Function that summarizes the prediction from the disaggregation model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'disag_prediction'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.disag_prediction_+3A_object">object</code></td>
<td>
<p>Object returned from predict.disag_model</p>
</td></tr>
<tr><td><code id="summary.disag_prediction_+3A_...">...</code></td>
<td>
<p>Further arguments to <em>summary</em> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prints the number of polyons and pixels, the number of pixels in the largest and smallest polygons and summaries of the covariates.
</p>


<h3>Value</h3>

<p>A list of the number of polyons, the number of covariates and summaries of the covariates.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
