<!DOCTYPE html><html><head><title>Help for package wordspace</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {wordspace}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#as.distmat'>
<p>Mark an arbitrary matrix as a pre-computed <code>dist.matrix</code> object (wordspace)</p></a></li>
<li><a href='#as.dsm'>
<p>Create DSM Object From Various R Data Structures (wordspace)</p></a></li>
<li><a href='#as.dsm.tm'>
<p>Create DSM Object From <code>tm</code> Package (wordspace)</p></a></li>
<li><a href='#as.matrix.dsm'>
<p>Extract Matrix from DSM Object (wordspace)</p></a></li>
<li><a href='#check.dsm'>
<p>Validate Internal Structure of DSM Object (wordspace)</p></a></li>
<li><a href='#context.vectors'>
<p>Compute Bag-of-Words Context Vectors (wordspace)</p></a></li>
<li><a href='#convert.lemma'>
<p>Transform CWB/Penn-Style Lemmas into Other Notation Formats (wordspace)</p>
</p></a></li>
<li><a href='#dim.dsm'>
<p>Dimensions of a DSM Object (wordspace)</p></a></li>
<li><a href='#dimnames.dsm'>
<p>Dimnames of a DSM Object (wordspace)</p></a></li>
<li><a href='#dist.matrix'>
<p>Distances/Similarities between Row or Column Vectors (wordspace)</p></a></li>
<li><a href='#dsm'>
<p>Create DSM Object Representing a Distributional Semantic Model (wordspace)</p></a></li>
<li><a href='#DSM_GoodsMatrix'>
<p>A Scored Co-occurrence Matrix of Nouns Denoting Goods (wordspace)</p></a></li>
<li><a href='#DSM_HieroglyphsMatrix'>
<p>A Small Co-occurrence Matrix (wordspace)</p></a></li>
<li><a href='#DSM_SingularValues'>
<p>Typical Singular Values of a Term-Context Matrix (wordspace)</p></a></li>
<li><a href='#DSM_TermContextMatrix'>
<p>Example of a Term-Context Co-occurrence Matrix (wordspace)</p></a></li>
<li><a href='#DSM_TermTermMatrix'>
<p>Example of a Term-Term Co-occurrence Matrix (wordspace)</p></a></li>
<li><a href='#DSM_Vectors'>
<p>Pre-Compiled DSM Vectors for Selected Words (wordspace)</p></a></li>
<li><a href='#DSM_VerbNounTriples_BNC'>
<p>Verb-Noun Co-occurrence Frequencies from British National Corpus (wordspace)</p></a></li>
<li><a href='#dsm.canonical.matrix'>
<p>Canonical Formats for a DSM Co-occurrence Matrix (wordspace)</p></a></li>
<li><a href='#dsm.projection'>
<p>Reduce Dimensionality of DSM by Subspace Projection (wordspace)</p></a></li>
<li><a href='#dsm.score'>
<p>Weighting, Scaling and Normalisation of Co-occurrence Matrix (wordspace)</p></a></li>
<li><a href='#ESSLLI08_Nouns'>
<p>Noun Clustering Task from ESSLLI 2008 (wordspace)</p></a></li>
<li><a href='#eval.clustering'>
<p>Evaluate DSM on Clustering Task (wordspace)</p>
</p></a></li>
<li><a href='#eval.multiple.choice'>
<p>Evaluate DSM on Multiple Choice Task (wordspace)</p>
</p></a></li>
<li><a href='#eval.similarity.correlation'>
<p>Evaluate DSM on Correlation with Similarity Ratings (wordspace)</p>
</p></a></li>
<li><a href='#head.dist.matrix'>
<p>Return the Top Left Corner of a Distance Matrix (wordspace)</p></a></li>
<li><a href='#head.dsm'>
<p>Return the Top Left Corner of a DSM Matrix (wordspace)</p></a></li>
<li><a href='#match.split'>
<p>Find Parallel Matches for Values in Groups (wordspace)</p></a></li>
<li><a href='#merge.dsm'>
<p>Merge Rows or Columns from Different DSM Objects (wordspace)</p></a></li>
<li><a href='#nearest.neighbours'>
<p>Find Nearest Neighbours in DSM Space (wordspace)</p></a></li>
<li><a href='#normalize.rows'>
<p>Normalize Rows or Columns of Matrix to Unit Length (wordspace)</p></a></li>
<li><a href='#pair.distances'>
<p>Semantic Distances Between Word Pairs (wordspace)</p>
</p></a></li>
<li><a href='#plot.dist.matrix'>
<p>Plotting Distance Matrices (wordspace)</p></a></li>
<li><a href='#plot.eval.similarity.correlation'>
<p>Printing and Plotting Similarity Correlation Evaluation Results (wordspace)</p></a></li>
<li><a href='#print.dsm'>
<p>Print Information About DSM Object (wordspace)</p></a></li>
<li><a href='#rbind.dsm'>
<p>Combine DSM Objects by Rows and Columns (wordspace)</p></a></li>
<li><a href='#read.dsm.matrix'>
<p>Load DSM Matrix from File (wordspace)</p></a></li>
<li><a href='#read.dsm.triplet'>
<p>Load DSM Data from Triplet Representation (wordspace)</p></a></li>
<li><a href='#read.dsm.ucs'>
<p>Load Raw DSM Data from Disk Files in UCS Export Format (wordspace)</p></a></li>
<li><a href='#RG65'>
<p>Similarity Ratings for 65 Noun Pairs (wordspace)</p></a></li>
<li><a href='#rowNorms'>
<p>Compute Norms of Row and Column Vectors of a Matrix (wordspace)</p></a></li>
<li><a href='#rsvd'>
<p>Randomized Singular Value Decomposition (wordspace)</p></a></li>
<li><a href='#scaleMargins'>
<p>Scale Rows and/or Columns of a Matrix (wordspace)</p></a></li>
<li><a href='#SemCorWSD'>
<p>SemCor Word Sense Disambiguation Task (wordspace)</p></a></li>
<li><a href='#signcount'>
<p>Efficiently Count Positive, Negative and Zero Values (wordspace)</p></a></li>
<li><a href='#subset.dsm'>
<p>Subsetting Distributional Semantic Models (wordspace)</p></a></li>
<li><a href='#t.dsm'>
<p>Swap the Rows and Columns of a DSM Object (wordspace)</p></a></li>
<li><a href='#WordSim353'>
<p>Similarity Ratings for 351 Noun Pairs (wordspace)</p></a></li>
<li><a href='#wordspace-package'>
<p>Distributional Semantic Models in R (wordspace)</p></a></li>
<li><a href='#wordspace.openmp'>
<p>Control multi-core processing in wordspace functions (wordspace)</p></a></li>
<li><a href='#write.dsm.matrix'>
<p>Export DSM Matrix to File (wordspace)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Distributional Semantic Models in R</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2-8</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-08-22</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3.0), Matrix (&ge; 1.3.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.11.0), sparsesvd, iotools, methods, stats, utils,
graphics, grDevices, cluster, MASS</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>Description:</td>
<td>An interactive laboratory for research on distributional semantic models ('DSM',
             see <a href="https://en.wikipedia.org/wiki/Distributional_semantics">https://en.wikipedia.org/wiki/Distributional_semantics</a> for more information).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://wordspace.r-forge.r-project.org/">http://wordspace.r-forge.r-project.org/</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyDataCompression:</td>
<td>xz</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, tm, testthat (&ge; 3.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-08-22 20:18:32 UTC; ex47emin</td>
</tr>
<tr>
<td>Author:</td>
<td>Stephanie Evert <a href="https://orcid.org/0000-0002-4192-2437"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [cre, aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Stephanie Evert &lt;stephanie.evert@fau.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-08-22 21:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='as.distmat'>
Mark an arbitrary matrix as a pre-computed <code>dist.matrix</code> object (wordspace)
</h2><span id='topic+as.distmat'></span><span id='topic+as.distmat.matrix'></span><span id='topic+as.distmat.sparseMatrix'></span><span id='topic+as.distmat.dsm'></span>

<h3>Description</h3>

<p>Mark an arbitrary dense or sparse matrix as a pre-computed <code><a href="#topic+dist.matrix">dist.matrix</a></code> object, so it can be used with <code><a href="#topic+nearest.neighbours">nearest.neighbours</a></code> and <code><a href="#topic+pair.distances">pair.distances</a></code>.  Default methods are provided for a regular dense <code><a href="base.html#topic+matrix">matrix</a></code>, any type of <code><a href="Matrix.html#topic+sparseMatrix">sparseMatrix</a></code> from the <b>Matrix</b> package, as well as a <code>dsm</code> object (from which the raw or scored co-occurrence matrix is extracted).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
as.distmat(x, ...)

## S3 method for class 'matrix'
as.distmat(x, similarity=FALSE, symmetric=FALSE, ...)
## S3 method for class 'sparseMatrix'
as.distmat(x, similarity=FALSE, symmetric=FALSE, force.dense=FALSE, ...)
## S3 method for class 'dsm'
as.distmat(x, similarity=FALSE, symmetric=FALSE, force.dense=FALSE, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.distmat_+3A_x">x</code></td>
<td>
<p>a matrix-like object of a suitable class (for which a method implementation is available) or a DSM object of class <code>dsm</code></p>
</td></tr>
<tr><td><code id="as.distmat_+3A_similarity">similarity</code></td>
<td>
<p>whether the matrix contains similarity or distance values. Note that sparse distance matrices (<code>similarity=FALSE</code>) are not supported.</p>
</td></tr>
<tr><td><code id="as.distmat_+3A_symmetric">symmetric</code></td>
<td>
<p>whether the distance or similarity is symmetric (i.e. it has the same rows and columns in the same order and <code class="reqn">d(x, y) = d(y, x)</code>). Methods trust the specified value and do not check whether this is actually true.</p>
</td></tr>
<tr><td><code id="as.distmat_+3A_force.dense">force.dense</code></td>
<td>
<p>whether to convert a sparse distance matrix into a dense <code>matrix</code> object. Keep in mind that the resulting matrix may be extremely large.</p>
</td></tr>
<tr><td><code id="as.distmat_+3A_...">...</code></td>
<td>
<p>additional arguments passed on to the method implementations (see respective manpages for details)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method is called <code>as.distmat</code> because the regular name <code>as.dist.matrix</code> would collide with the <code><a href="stats.html#topic+as.dist">as.dist</a></code> method for <code><a href="base.html#topic+matrix">matrix</a></code> objects.
</p>
<p>The method has two main purposes:
</p>

<ol>
<li><p> enable the use of pre-computed distance information from external sources in <b>wordspace</b>;
</p>
</li>
<li><p> disguise a (scored) co-occurrence matrix as a similarity matrix so that <code><a href="#topic+nearest.neighbours">nearest.neighbours</a></code> and <code><a href="#topic+pair.distances">pair.distances</a></code> can be used for lookup of first-order co-occurrence data.
</p>
</li></ol>



<h3>Value</h3>

<p>If <code>x</code> is a dense matrix or <code>force.dense=TRUE</code>, it is assigned to class <code><a href="#topic+dist.matrix">dist.matrix</a></code> so it can be used with <code><a href="#topic+nearest.neighbours">nearest.neighbours</a></code> and <code><a href="#topic+pair.distances">pair.distances</a></code> as well as the <code><a href="#topic+plot.dist.matrix">plot</a></code> and <code><a href="#topic+head.dist.matrix">head</a></code> methods.
</p>
<p>If <code>x</code> is a sparse matrix, it is marked with an attribute <code>dist.matrix</code> recognized by <code><a href="#topic+nearest.neighbours">nearest.neighbours</a></code> and <code><a href="#topic+pair.distances">pair.distances</a></code>; however, method implementations for <code>dist.matrix</code> objects will not apply.  <b>Important note:</b> In this case, <code>x</code> must be a non-negative similarity matrix and empty cells are treated as zeroes.
</p>
<p>In either case, attributes <code>similarity</code> and <code>symmetric</code> are set as specified.
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.dist.matrix">plot</a></code> and <code><a href="#topic+head.dist.matrix">head</a></code> methods for distances matrices; <code><a href="#topic+nearest.neighbours">nearest.neighbours</a></code> and <code><a href="#topic+pair.distances">pair.distances</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  # interpret co-occurrence frequency as similarity measure
  M &lt;- as.distmat(DSM_HieroglyphsMatrix, similarity=TRUE)
  nearest.neighbours(M, "cat")
  nearest.neighbours(M, "hear", byrow=FALSE)

</code></pre>

<hr>
<h2 id='as.dsm'>
Create DSM Object From Various R Data Structures (wordspace)
</h2><span id='topic+as.dsm'></span>

<h3>Description</h3>

<p>Convert co-occurrence data from various in-memory formats to DSM object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
as.dsm(obj, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.dsm_+3A_obj">obj</code></td>
<td>
<p>an object of a suitable class (for which a method implementation is available)</p>
</td></tr>
<tr><td><code id="as.dsm_+3A_...">...</code></td>
<td>
<p>additional arguments passed on to the method implementation
(see respective manpages for details)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+dsm">dsm</a></code>.
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p>Currently available implementations: <code><a href="#topic+as.dsm.TermDocumentMatrix">as.dsm.TermDocumentMatrix</a></code>, <code><a href="#topic+as.dsm.DocumentTermMatrix">as.dsm.DocumentTermMatrix</a></code>
</p>

<hr>
<h2 id='as.dsm.tm'>
Create DSM Object From <code>tm</code> Package (wordspace)
</h2><span id='topic+as.dsm.TermDocumentMatrix'></span><span id='topic+as.dsm.DocumentTermMatrix'></span>

<h3>Description</h3>

<p>Convert a <b>tm</b> term-document or document-term matrix into a <code>wordspace</code> DSM object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'TermDocumentMatrix'
as.dsm(obj, ..., verbose=FALSE)
## S3 method for class 'DocumentTermMatrix'
as.dsm(obj, ..., verbose=FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.dsm.tm_+3A_obj">obj</code></td>
<td>

<p>an term-document or document-term matrix from the <b>tm</b> package, i.e.
an object of a class <code><a href="tm.html#topic+TermDocumentMatrix">TermDocumentMatrix</a></code> or <code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>.
</p>
</td></tr>
<tr><td><code id="as.dsm.tm_+3A_...">...</code></td>
<td>

<p>additional arguments are ignored
</p>
</td></tr>
<tr><td><code id="as.dsm.tm_+3A_verbose">verbose</code></td>
<td>

<p>if <code>TRUE</code>, a few progress and information messages are shown
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+dsm">dsm</a></code>.
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p><code><a href="#topic+as.dsm">as.dsm</a></code> and the documentation of the <b>tm</b> package
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
library(tm) # tm package needs to be installed
data(crude) # news messages on crude oil from Reuters corpus

cat(as.character(crude[[1]]), "\n") # a text example

corpus &lt;- tm_map(crude, stripWhitespace) # some pre-processing
corpus &lt;- tm_map(corpus, content_transformer(tolower))
corpus &lt;- tm_map(corpus, removePunctuation)
corpus &lt;- tm_map(corpus, removeWords, stopwords("english"))

cat(as.character(corpus[[1]]), "\n") # pre-processed text

dtm &lt;- DocumentTermMatrix(corpus) # document-term matrix
inspect(dtm[1:5, 90:99])   # rows = documents

wordspace_dtm &lt;- as.dsm(dtm, verbose=TRUE) # convert to DSM
print(wordspace_dtm$S[1:5, 90:99]) # same part of dtm as above

wordspace_tdm &lt;- t(wordspace_dtm) # convert to term-document matrix
print(wordspace_tdm)

## End(Not run)

</code></pre>

<hr>
<h2 id='as.matrix.dsm'>
Extract Matrix from DSM Object (wordspace)
</h2><span id='topic+as.matrix.dsm'></span>

<h3>Description</h3>

<p>Extract the co-occurrence or score matrix from a DSM object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'dsm'
as.matrix(x, what = c("auto", "M", "S"), ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.matrix.dsm_+3A_x">x</code></td>
<td>

<p>an object of class <code>dsm</code>
</p>
</td></tr>
<tr><td><code id="as.matrix.dsm_+3A_what">what</code></td>
<td>

<p>whether to extract the raw co-occurrence matrix (<code>M</code>) or the score matrix (<code>S</code>). The default option <code>auto</code> prefers the score matrix if both are available.
</p>
</td></tr>
<tr><td><code id="as.matrix.dsm_+3A_...">...</code></td>
<td>

<p>any additional arguments are ignored
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function ensures that the row and column names of the matrix are consistent with the row/column information tables of the DSM.
For faster access to the matrix, simply use <code>x$M</code> or <code>x$S</code> directly.
</p>


<h3>Value</h3>

<p>Either the raw co-occurrence matrix or the score matrix of the DSM <code>x</code>.
</p>
<p>Note that unlike other <code>as.matrix</code> methods, a sparse matrix in canonical DSM format may be returned.
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p><code><a href="#topic+dsm">dsm</a></code>, <code><a href="#topic+dim.dsm">dim.dsm</a></code>, <code><a href="#topic+dimnames.dsm">dimnames.dsm</a></code>, <code><a href="#topic+dsm.is.canonical">dsm.is.canonical</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>as.matrix(DSM_TermTerm)
as.matrix(DSM_TermContext)
</code></pre>

<hr>
<h2 id='check.dsm'>
Validate Internal Structure of DSM Object (wordspace)
</h2><span id='topic+check.dsm'></span>

<h3>Description</h3>

<p>Validate the internal structure of a DSM object and return a list with information about the object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
check.dsm(model, validate = FALSE, nonneg.check = FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check.dsm_+3A_model">model</code></td>
<td>

<p>an object of class <code>dsm</code>
</p>
</td></tr>
<tr><td><code id="check.dsm_+3A_validate">validate</code></td>
<td>

<p>carry out extended validation of internal consistency? (may be expensive)
</p>
</td></tr>
<tr><td><code id="check.dsm_+3A_nonneg.check">nonneg.check</code></td>
<td>

<p>if <code>TRUE</code>, check the co-occurrence (<code class="reqn">M</code>) and/or score (<code class="reqn">S</code>) matrix for non-negativity (may be expensive)
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Aborts with error message if any inconsistency is detected.
Otherwise a list with the following items is returned:
</p>
<table>
<tr><td><code>nrow</code></td>
<td>

<p>number of rows (target terms) of the DSM
</p>
</td></tr>
<tr><td><code>ncol</code></td>
<td>

<p>number of columns (features) of the DSM
</p>
</td></tr>
<tr><td><code>N</code></td>
<td>

<p>sample size of the underlying data set (may be <code>NA</code>)
</p>
</td></tr>
<tr><td><code>M$ok</code></td>
<td>

<p>whether co-occurrence frequency matrix <code class="reqn">M</code> is available
</p>
</td></tr>
<tr><td><code>M$sparse</code></td>
<td>

<p>whether <code class="reqn">M</code> is sparse or dense (only present if <code>M$ok</code>)
</p>
</td></tr> 
<tr><td><code>M$canonical</code></td>
<td>

<p>whether <code class="reqn">M</code> is in canonical DSM format (only present if <code>M$ok</code>)
</p>
</td></tr>
<tr><td><code>M$nonneg</code></td>
<td>

<p>whether <code class="reqn">M</code> is non-negative (only present if <code>M$ok</code>, and may be <code>NA</code> unless <code>nonneg.check=TRUE was specified</code>)
</p>
</td></tr>
<tr><td><code>S$ok</code></td>
<td>

<p>whether score matrix <code class="reqn">S</code> is available
</p>
</td></tr>
<tr><td><code>S$sparse</code></td>
<td>

<p>whether <code class="reqn">S</code> is sparse or dense (only present if <code>S$ok</code>)
</p>
</td></tr> 
<tr><td><code>S$canonical</code></td>
<td>

<p>whether <code class="reqn">S</code> is in canonical DSM format (only present if <code>S$ok</code>)
</p>
</td></tr>
<tr><td><code>S$nonneg</code></td>
<td>

<p>whether <code class="reqn">S</code> is non-negative (only present if <code>S$ok</code>, and may be <code>NA</code> unless <code>nonneg.check=TRUE was specified</code>)
</p>
</td></tr>
<tr><td><code>locked</code></td>
<td>

<p><code>TRUE</code> if matrix combines data with inconsistent row or column marginals (in this case, association scores cannot be computed any more)
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p><code><a href="#topic+dsm">dsm</a></code>, <code><a href="#topic+print.dsm">print.dsm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
check.dsm(DSM_TermTerm)

</code></pre>

<hr>
<h2 id='context.vectors'>
Compute Bag-of-Words Context Vectors (wordspace)
</h2><span id='topic+context.vectors'></span>

<h3>Description</h3>

<p>Compute bag-of-words context vectors as proposed by Schütze (1998) for automatic word sense disambiguation and induction.  Each context vector is the centroid of the DSM vectors of all terms occurring in the context.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
context.vectors(M, contexts, split = "\\s+",
                drop.missing = TRUE, row.names=NULL)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="context.vectors_+3A_m">M</code></td>
<td>

<p>numeric matrix of row vectors for the terms specified by <code>rownames(M)</code>, or an object of class <code>dsm</code>
</p>
</td></tr>
<tr><td><code id="context.vectors_+3A_contexts">contexts</code></td>
<td>

<p>the contexts for which bag-of-words representations are to be computed.  Must be a character vector, a list of character vectors, or a list of labelled numeric vectors (see Details below).
</p>
</td></tr>
<tr><td><code id="context.vectors_+3A_split">split</code></td>
<td>

<p>Perl regular expression determining how contexts given as a character vector are split into terms.  The default behaviour is to split on whitespace.
</p>
</td></tr>
<tr><td><code id="context.vectors_+3A_drop.missing">drop.missing</code></td>
<td>

<p>if <code>TRUE</code> (default), contexts that do not contain any known terms are silently dropped; otherwise the corresponding context vectors will be all zeroes.
</p>
</td></tr>
<tr><td><code id="context.vectors_+3A_row.names">row.names</code></td>
<td>

<p>a character vector of the same length as <code>contexts</code>, specifying row names for the resulting matrix of centroid vectors
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>contexts</code> argument can be specified in several different ways:
</p>

<ul>
<li><p> A character vector: each element represents a context given as a string, which will be split on the Perl regular expression <code>split</code> and then looked up in <code>M</code>. Repetitions are allowed and will be weighted accordingly in the centroid.
</p>
</li>
<li><p> A list of character vectors: each item represents a pre-tokenized context given as a sequence of terms to be looked up in <code>M</code>. Repetitions are allowed and will be weighted accordingly in the centroid.
</p>
</li>
<li><p> A list of labelled numeric vectors: each item represents a bag-of-words representation of a context, where labels are terms to be looked up in <code>M</code> and the corresponding values their frequency counts or (possibly non-integer) weights.
</p>
</li>
<li> <p><em>(deprecated)</em> A logical vector corresponding to the rows of <code>M</code>, which will be used directly as an index into <code>M</code>.
</p>
</li>
<li> <p><em>(deprecated)</em> An unlabelled integer vector, which will be used as an index into the rows of <code>M</code>.
</p>
</li></ul>

<p>For each context, terms not found in the matrix <code>M</code> are silently computed.  Then a context vector is computed as the centroid of the remaining term vectors.  If the context contains multiple occurrences of the same term, its vector will be weighted accordingly.  If the context is specified as a bag-of-words representations, the terms are weighted according to the corresponding numerical values.
</p>
<p>Neither word order nor any other structural properties of the contexts are taken into account.
</p>


<h3>Value</h3>

<p>A numeric matrix with the same number of columns as <code>M</code> and one row for each context (excluding contexts without known terms if <code>drop.missing=TRUE</code>).  If the vector <code>contexts</code> has names or <code>row.names</code> is specified, the matrix rows will be labelled accordingly.  Otherwise the row labels correspond to the indices of the respective entries in <code>contexts</code>, so matrix rows can always be identified unambiguously if <code>drop.missing=TRUE</code>.
</p>
<p>If <code>drop.missing=FALSE</code>, a context without any known terms (including an empty context) is represented by an all-zero vector.
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>References</h3>

<p>Schütze, Hinrich (1998). Automatic word sense discrimination. <em>Computational Linguistics</em>, <b>24</b>(1), 97&ndash;123.  
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SemCorWSD">SemCorWSD</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># different ways of specifying contexts
M &lt;- DSM_TermTermMatrix
context.vectors(M, c("dog cat cat", "cause effect")) # contexts as strings
context.vectors(M, list(c("dog", "cat", "cat"), c("cause", "effect"))) # pre-tokenized
context.vectors(M, list(c(dog=1, cat=2), c(cause=1, effect=1))) # bag of words

# illustration of WSD algorithm: 6 sentences each for two senses of "vessel"
VesselWSD &lt;- subset(SemCorWSD, target == "vessel")
with(VesselWSD, cat(paste0(sense, ": ", sentence, "\n")))

# provide sense labels in case some contexts are dropped b/c of too many missing words
Centroids &lt;- with(VesselWSD, context.vectors(DSM_Vectors, lemma, row.names=sense))
Centroids[, 1:5]

(res &lt;- kmeans(Centroids, 2)$cluster) # flat clustering with k-means
table(rownames(Centroids), res)       # ... works perfectly

## Not run: 
plot(hclust(dist.matrix(Centroids, as.dist=TRUE)))

## End(Not run)
</code></pre>

<hr>
<h2 id='convert.lemma'>
Transform CWB/Penn-Style Lemmas into Other Notation Formats (wordspace)
</h2><span id='topic+convert.lemma'></span>

<h3>Description</h3>

<p>Transform POS-disambiguated lemma strings in CWB/Penn format (see Details)
into several other notation formats.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
convert.lemma(lemma, format=c("CWB", "BNC", "DM", "HW", "HWLC"), hw.tolower=FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="convert.lemma_+3A_lemma">lemma</code></td>
<td>
<p>a character vector specifying one or more POS-disambiguated lemmas in CWB/Penn notation</p>
</td></tr>
<tr><td><code id="convert.lemma_+3A_format">format</code></td>
<td>
<p>the notation format to be generated (see Details)</p>
</td></tr>
<tr><td><code id="convert.lemma_+3A_hw.tolower">hw.tolower</code></td>
<td>
<p>convert headword part to lowercase, regardless of output format</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Input strings must be POS-disambiguated lemmas in CWB/Penn notation, i.e. in the form
</p>
<pre>
    &lt;headword&gt;_&lt;P&gt; </pre>
<p>where <code>&lt;headword&gt;</code> is a dictionary headword (which may be case-sensitive) and <code>&lt;P&gt;</code> is
a one-letter code specifying the simple part of speech.  Standard POS codes are
</p>
<pre>
    N ... nouns
    Z ... proper nouns
    V ... lexical and auxiliary verbs
    J ... adjectives
    R ... adverbs
    I ... prepositions (including all uses of "to")
    D ... determiners
    . ... punctuation
  </pre>
<p>For other parts of speech, the first character of the corresponding Penn tag may be used.
Note that these codes are not standardised and are only useful for distinguishing between content
words and function words.
</p>
<p>The following output formats are supported:
</p>

<dl>
<dt><code>CWB</code></dt><dd>
<p>returns input strings without modifications, but validates that they are in CWB/Penn format
</p>
</dd>
<dt><code>BNC</code></dt><dd>
<p>BNC-style POS-disambiguated lemmas based on the simplified CLAWS tagset.
The headword part of the lemma is unconditionally converted to lowercase.
The standard POS codes listed above are translated into
<code>SUBST</code> (nouns and proper nouns), <code>VERB</code> (verbs), <code>ADJ</code> (adjectives), <code>ADV</code> (adverbs),
<code>ART</code> (determiners), <code>PREP</code> (prepositions), and <code>STOP</code> (punctuation).
Other POS codes have no direct CLAWS equivalents and are mapped to <code>UNC</code> (unclassified),
so the transformation should only be used for the categories listed above.
</p>
</dd>
<dt><code>DM</code></dt><dd>
<p>POS-disambiguated lemmas in the format used by Distributional Memory (Baroni &amp; Lenci 2010),
viz. <code>&lt;headword&gt;-&lt;p&gt;</code> with POS code in lowercase and headword in its original capitalisation.
For example, <code>light_N</code> will be mapped to <code>light-n</code>.
</p>
</dd>
<dt><code>HW</code></dt><dd>
<p>just the undisambiguated headword
</p>
</dd>
<dt><code>HWLC</code></dt><dd>
<p>undisambiguated headword mapped to lowercase (same as <code>HW</code> with <code>hw.tolower=TRUE</code>)
</p>
</dd>
</dl>



<h3>Value</h3>

<p>A character vector of the same length as <code>lemma</code>, containing the transformed lemmas.
See Details above for the different output formats.
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>References</h3>

<p>Baroni, Marco and Lenci, Alessandro (2010).
Distributional Memory: A general framework for corpus-based semantics.
<em>Computational Linguistics</em>, <b>36</b>(4), 673&ndash;712.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
convert.lemma(RG65$word1, "CWB") # original format
convert.lemma(RG65$word1, "BNC") # BNC-style (simple CLAWS tags)
convert.lemma(RG65$word1, "DM")  # as in Distributional Memory
convert.lemma(RG65$word1, "HW")  # just the headword

</code></pre>

<hr>
<h2 id='dim.dsm'>
Dimensions of a DSM Object (wordspace)
</h2><span id='topic+dim.dsm'></span>

<h3>Description</h3>

<p>Retrieve the dimensions of the co-occurrence and/or score matrix 
represented by a DSM object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'dsm'
dim(x)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dim.dsm_+3A_x">x</code></td>
<td>

<p>an object of class <code>dsm</code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that an assignment form (<code>dim&lt;-</code>) for modifying dimensions is not provided.
</p>


<h3>Value</h3>

<p>An integer vector of length 2, specifying the number of rows and the number of columns of the DSM matrix.
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p><code><a href="#topic+dsm">dsm</a></code>, <code><a href="#topic+check.dsm">check.dsm</a></code>, <code><a href="#topic+print.dsm">print.dsm</a></code>, <code><a href="#topic+dimnames.dsm">dimnames.dsm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dim(DSM_TermTerm)
</code></pre>

<hr>
<h2 id='dimnames.dsm'>
Dimnames of a DSM Object (wordspace)
</h2><span id='topic+dimnames.dsm'></span><span id='topic+dimnames+3C-.dsm'></span>

<h3>Description</h3>

<p>Retrieve or set the dimnames of the co-occurrence and/or score matrix
represented by a DSM object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'dsm'
dimnames(x)
## S3 replacement method for class 'dsm'
dimnames(x) &lt;- value

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dimnames.dsm_+3A_x">x</code></td>
<td>

<p>an object of class <code>dsm</code>
</p>
</td></tr>
<tr><td><code id="dimnames.dsm_+3A_value">value</code></td>
<td>

<p>a list of two character vectors with new row and column names for <code>x</code>. Both vectors must have appropriate length and may not be <code>NULL</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method automatically checks that the row and column names of the co-occurrence and/or score matrix are consistent with the target terms and features listed in the row/column information tables.
</p>


<h3>Value</h3>

<p>The <code>dimnames()</code> of a DSM object are always a list of length 2, consisting of two character vectors with row and column labels, respectively.
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p><code><a href="#topic+dsm">dsm</a></code>, <code><a href="#topic+check.dsm">check.dsm</a></code>, <code><a href="#topic+dim.dsm">dim.dsm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rownames(DSM_TermContext)
colnames(DSM_TermContext)

tmp &lt;- DSM_TermContext
rownames(tmp)[3] &lt;- "pet"
head(tmp, 4, 6)
</code></pre>

<hr>
<h2 id='dist.matrix'>
Distances/Similarities between Row or Column Vectors (wordspace)
</h2><span id='topic+dist.matrix'></span>

<h3>Description</h3>

<p>Compute a symmetric matrix of distances (or similarities) between the rows or columns of a matrix;
or compute cross-distances between the rows or columns of two different matrices.
This implementation is faster than <code><a href="stats.html#topic+dist">dist</a></code> and can operate on sparse matrices (in canonical DSM format).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
dist.matrix(M, M2 = NULL, method = "cosine", p = 2, 
            normalized = FALSE, byrow = TRUE, convert = TRUE, as.dist = FALSE, 
            terms = NULL, terms2 = terms, skip.missing = FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dist.matrix_+3A_m">M</code></td>
<td>
<p>a dense or sparse matrix representing a scored DSM, or an object of class <code>dsm</code></p>
</td></tr>
<tr><td><code id="dist.matrix_+3A_m2">M2</code></td>
<td>
<p>an optional dense or sparse matrix representing a second scored DSM, or an object of class <code>dsm</code>.
If present, cross-distances between the rows (or columns) of <code>M</code> and those of <code>M2</code> will be computed.
</p>
</td></tr>
<tr><td><code id="dist.matrix_+3A_method">method</code></td>
<td>
<p>distance or similarity measure to be used (see &ldquo;Distance Measures&rdquo; below for details)</p>
</td></tr>
<tr><td><code id="dist.matrix_+3A_p">p</code></td>
<td>
<p>exponent of the <code>minkowski</code> <code class="reqn">L_p</code>-metric, a numeric value in the range <code class="reqn">0 \le p &lt; \infty</code>.
The range <code class="reqn">0 \le p &lt; 1</code> represents a generalization of the standard Minkowski distance, which cannot be derived from a proper mathematical norm (see details below).
</p>
</td></tr>
<tr><td><code id="dist.matrix_+3A_normalized">normalized</code></td>
<td>
<p>if <code>TRUE</code>, assume that the row (or column) vectors of <code>M</code> and <code>M2</code> have been appropriately normalised (depending on the selected distance measure) in order to speed up calculations.
This option is often used with the <code>cosine</code> metric, for which vectors must be normalized wrt. the Euclidean norm.  It is currently ignored for other distance measures.
</p>
</td></tr>
<tr><td><code id="dist.matrix_+3A_byrow">byrow</code></td>
<td>
<p>whether to calculate distances between row vectors (default) or between column vectors (<code>byrow=FALSE</code>)</p>
</td></tr>
<tr><td><code id="dist.matrix_+3A_convert">convert</code></td>
<td>
<p>if <code>TRUE</code>, similarity measures are automatically converted to distances in an appropriate way (see &ldquo;Distance Measures&rdquo; below for details).
Note that this is the default setting and <code>convert=FALSE</code> has to be specified explicitly in order to obtain a similarity matrix.
</p>
</td></tr>
<tr><td><code id="dist.matrix_+3A_as.dist">as.dist</code></td>
<td>
<p>convert the full symmetric distance matrix to a compact object of class <code>dist</code>.
This option cannot be used if cross-distances are calculated (with argument <code>M2</code>) or if a similarity measure has been selected (with option <code>convert=FALSE</code>).
</p>
</td></tr>
<tr><td><code id="dist.matrix_+3A_terms">terms</code></td>
<td>
<p>a character vector specifying rows of <code>M</code> for which distance matrix is to be computed (or columns if <code>byrow=FALSE</code>)</p>
</td></tr>
<tr><td><code id="dist.matrix_+3A_terms2">terms2</code></td>
<td>
<p>a character vector specifying rows of <code>M2</code> for which the cross-distance matrix is to be computed (or columns if <code>byrow=FALSE</code>).
If only the argument <code>terms</code> is specified, the same set of rows (or columns) will be selected from both <code>M</code> and <code>M2</code>; you can explicitly specify <code>terms2=NULL</code> in order to compute cross-distances for all rows (or columns) of <code>M2</code>.
</p>
</td></tr>
<tr><td><code id="dist.matrix_+3A_skip.missing">skip.missing</code></td>
<td>
<p>if <code>TRUE</code>, silently ignores terms not found in <code>M</code> (or in <code>M2</code>). By default (<code>skip.missing=FALSE</code>) an error is raised in this case.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>By default, a numeric matrix of class <code>dist.matrix</code>, specifying distances or similarities between term vectors.
A similarity matrix is marked by an additional attribute <code>similarity</code> with value <code>TRUE</code>.
If the distance or similarity matrix is symmetric (i.e. neither a cross-distance matrix nor based on an asymmetric distance measure), it is marked by an attribute <code>symmetric</code> with value <code>TRUE</code>.
</p>
<p>If <code>as.dist=TRUE</code>, the matrix is compacted to an object of class <code>dist</code>.
</p>


<h3>Distance Measures</h3>

<p>Given two DSM vectors <code class="reqn">x</code> and <code class="reqn">y</code>, the following distance metrics can be computed:
</p>

<dl>
<dt><code>euclidean</code></dt><dd><p>The Euclidean distance given by </p>
<p style="text-align: center;"><code class="reqn">
        d_2(x, y) = \sqrt{ \sum_i (x_i - y_i)^2 }</code>
</p>

</dd>
<dt><code>manhattan</code></dt><dd><p>The Manhattan (or &ldquo;city block&rdquo;) distance given by </p>
<p style="text-align: center;"><code class="reqn">
        d_1(x, y) = \sum_i |x_i - y_i|</code>
</p>

</dd>
<dt><code>maximum</code></dt><dd><p>The maximum distance given by </p>
<p style="text-align: center;"><code class="reqn">
        d_{\infty}(x, y) = \max_i |x_i - y_i|</code>
</p>

</dd>
<dt><code>minkowski</code></dt><dd><p>The Minkowski distance is a family of metrics determined by a parameter <code class="reqn">0 \le p &lt; \infty</code>, which encompasses the Euclidean, Manhattan and maximum distance as special cases.  Also known as <code class="reqn">L_p</code>-metric, it is defined by </p>
<p style="text-align: center;"><code class="reqn">
        d_p(x, y) = \left( \sum_i |x_i - y_i|^p \right)^{1/p}</code>
</p>

<p>for <code class="reqn">p \ge 1</code> and by </p>
<p style="text-align: center;"><code class="reqn">
        d_p(x, y) = \sum_i | x_i - y_i |^p</code>
</p>

<p>for <code class="reqn">0 \le p &lt; 1</code>.  In the latter case, it is not homogeneous and cannot be derived from a corresponding mathematical norm (cf. <code><a href="#topic+rowNorms">rowNorms</a></code>).
</p>
<p>Special cases include the Euclidean metric <code class="reqn">d_2(x, y)</code> for <code class="reqn">p = 2</code> and the Manhattan metric <code class="reqn">d_1(x, y)</code> for <code class="reqn">p = 1</code>, but the dedicated methods above provide more efficient implementations.  For <code class="reqn">p \to \infty</code>, <code class="reqn">d_p(x, y)</code> converges to the maximum distance <code class="reqn">d_{\infty}(x, y)</code>, which is also selected by setting <code>p=Inf</code>.  For <code class="reqn">p = 0</code>, <code class="reqn">d_p(x, y)</code> corresponds to the Hamming distance, i.e. the number of differences </p>
<p style="text-align: center;"><code class="reqn">
      d_0(x, y) = \#\{ i | x_i \ne y_i \}</code>
</p>

</dd>
<dt><code>canberra</code></dt><dd><p>The Canberra metric has been implemented for compatibility with the <code><a href="stats.html#topic+dist">dist</a></code> function, even though it is probably not very useful for DSM vectors.  It is given by </p>
<p style="text-align: center;"><code class="reqn">
        \sum_i \frac{|x_i - y_i|}{|x_i| + |y_i|}</code>
</p>

<p>(see <a href="https://en.wikipedia.org/wiki/Canberra_distance">https://en.wikipedia.org/wiki/Canberra_distance</a>).  Terms with <code class="reqn">x_i = y_i = 0</code> are silently dropped from the summation.
</p>
<p>Note that <code><a href="stats.html#topic+dist">dist</a></code> uses a different formula </p>
<p style="text-align: center;"><code class="reqn">
        \sum_i \frac{|x_i - y_i|}{|x_i + y_i|}</code>
</p>

<p>which is highly problematic unless <code class="reqn">x</code> and <code class="reqn">y</code> are guaranteed to be non-negative.  Terms with <code class="reqn">x_i = y_i = 0</code> are imputed, i.e. set to the average value of all nonzero terms.
</p>
</dd>
</dl>

<p>In addition, the following similarity measures can be computed and optionally converted to a distance metric (or dissimilarity):
</p>

<dl>
<dt><code>cosine</code> (default)</dt><dd><p>The cosine similarity given by </p>
<p style="text-align: center;"><code class="reqn">
        \cos \phi = \frac{x^T y}{||x||_2 \cdot ||y||_2} 
      </code>
</p>

<p>If <code>normalized=TRUE</code>, the denominator is omitted. If <code>convert=TRUE</code> (the default), the cosine similarity is converted to angular distance <code class="reqn">\phi</code>, given in degrees ranging from 0 to 180.
</p>
</dd>
<dt><code>jaccard</code></dt><dd><p>The generalized Jaccard coefficient given by </p>
<p style="text-align: center;"><code class="reqn">
        J(x, y) = \frac{ \sum_i \min(x_i, y_i) }{ \sum_i \max(x_i, y_i) }
      </code>
</p>

<p>which is only defined for non-negative vectors <code class="reqn">x</code> and <code class="reqn">y</code>.  If <code>convert=TRUE</code> (the default), the Jaccard metric <code class="reqn">1 - J(x,y)</code> is returned (see Kosub 2016 for details).  Note that <code class="reqn">J(0, 0) = 1</code>.
</p>
</dd>
<dt><code>overlap</code></dt><dd><p>An asymmetric measure of overlap given by </p>
<p style="text-align: center;"><code class="reqn">
        o(x, y) = \frac{ \sum_i \min(x_i, y_i) }{ \sum_i x_i }
      </code>
</p>

<p>for non-negative vectors <code class="reqn">x</code> and <code class="reqn">y</code>. If <code>convert=TRUE</code> (the default), the result is converted into a dissimilarity measure <code class="reqn">1 - o(x,y)</code>, which is not a metric, of course.  Note that <code class="reqn">o(0, y) = 1</code> and in particular <code class="reqn">o(0, 0) = 1</code>.
</p>
<p>Overlap computes the proportion of the &ldquo;mass&rdquo; of <code class="reqn">x</code> that is shared with <code class="reqn">y</code>; as a consequence, <code class="reqn">o(x, y) = 1</code> whenever <code class="reqn">x \le y</code>.  If both vectors are normalized as probability distributions (<code class="reqn">||x||_1 = ||y||_1 = 1</code>) then overlap is symmetric (<code class="reqn">o(x, y) = o(y, x)</code>) and can be thought of as the shared probability mass of the two distributions.  In this case, <code>normalized=TRUE</code> can be passed in order to simplify the computation to <code class="reqn">o(x, y) = \sum_i \min(x_i, y_i)</code>.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.dist.matrix">plot</a></code> and <code><a href="#topic+head.dist.matrix">head</a></code> methods for distance matrices; <code><a href="#topic+nearest.neighbours">nearest.neighbours</a></code> and <code><a href="#topic+pair.distances">pair.distances</a></code> also accept a precomputed <code>dist.matrix</code> object instead of a DSM matrix <code>M</code>
</p>
<p><code><a href="#topic+rowNorms">rowNorms</a></code> for length normalization of DSM vectors, which is highly recommended for most distance metrics (and implicit in <code>cosine</code>)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
M &lt;- DSM_TermTermMatrix
dist.matrix(M, as.dist=TRUE)                     # angular distance
dist.matrix(M, method="euclidean", as.dist=TRUE) # Euclidean distance
dist.matrix(M, method="manhattan", as.dist=TRUE) # Manhattan distance
dist.matrix(M, method="minkowski", p=1, as.dist=TRUE)  # L_1 distance
dist.matrix(M, method="minkowski", p=99, as.dist=TRUE) # almost L_Inf
dist.matrix(M, method="maximum", as.dist=TRUE)         # L_Inf (maximum)
dist.matrix(M, method="minkowski", p=.5, as.dist=TRUE) # L_0.5 distance
dist.matrix(M, method="minkowski", p=0, as.dist=TRUE)  # Hamming distance

round(dist.matrix(M, method="cosine", convert=FALSE), 3) # cosine similarity

</code></pre>

<hr>
<h2 id='dsm'>
Create DSM Object Representing a Distributional Semantic Model (wordspace)
</h2><span id='topic+dsm'></span><span id='topic+dsm-object'></span>

<h3>Description</h3>

<p>This is the constructor function for <code>dsm</code> objects representing distributional semantic models,
i.e. a co-occurrence matrix together with additional information on target terms (rows) and features (columns).
A new DSM can be initialised with a dense or sparse co-occurrence matrix, or with a triplet representation of a sparse matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
dsm(M = NULL, target = NULL, feature = NULL, score = NULL,
    rowinfo = NULL, colinfo = NULL, N = NA,
    globals = list(), raw.freq = FALSE, sort = FALSE, verbose = FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dsm_+3A_m">M</code></td>
<td>

<p>a dense or sparse co-occurrence matrix. A sparse matrix must be a subclass of <code><a href="Matrix.html#topic+sparseMatrix-class">sparseMatrix</a></code> from the <code>Matrix</code> package. See &quot;Details&quot; below.
</p>
</td></tr>
<tr><td><code id="dsm_+3A_target">target</code></td>
<td>

<p>a character vector of target terms (see &quot;Details&quot; below)
</p>
</td></tr>
<tr><td><code id="dsm_+3A_feature">feature</code></td>
<td>

<p>a character vector of feature terms (see &quot;Details&quot; below)
</p>
</td></tr>
<tr><td><code id="dsm_+3A_score">score</code></td>
<td>

<p>a numeric vector of co-occurrence frequencies or weighted/transformed scores (see &quot;Details&quot; below)
</p>
</td></tr>
<tr><td><code id="dsm_+3A_rowinfo">rowinfo</code></td>
<td>

<p>a data frame containing information about the rows of the co-occurrence matrix, corresponding to target terms.  The data frame must include a column <code>term</code> with the target term labels.  If unspecified, a minimal <code>rowinfo</code> table is compiled automatically (see &quot;Details&quot; below).
</p>
</td></tr>
<tr><td><code id="dsm_+3A_colinfo">colinfo</code></td>
<td>

<p>a data frame containing information about the columns of the co-occurrence matrix, corresponding to feature terms.  The data frame must include a column <code>term</code> with the feature term labels.  If unspecified, a minimal <code>colinfo</code> table is compiled automatically (see &quot;Details&quot; below).
</p>
</td></tr>
<tr><td><code id="dsm_+3A_n">N</code></td>
<td>

<p>a single numeric value specifying the effective sample size of the co-occurrence matrix.  This value may be determined automatically if <code>raw.freq=TRUE</code>.
</p>
</td></tr>
<tr><td><code id="dsm_+3A_globals">globals</code></td>
<td>

<p>a list of global variables, which are included in the <code>globals</code> field of the DSM object.  May contain an entry for the sample size <code class="reqn">N</code>, which can be overridden by an explicitly specified value in the argument <code>N</code>.
</p>
</td></tr>
<tr><td><code id="dsm_+3A_raw.freq">raw.freq</code></td>
<td>

<p>if <code>TRUE</code>, entries of the co-occurrence matrix are interpreted as raw frequency counts. By default, it is assumed that some weighting/transformation has already been applied.
</p>
</td></tr>
<tr><td><code id="dsm_+3A_sort">sort</code></td>
<td>

<p>if <code>TRUE</code>, sort rows and columns of a co-occurrence matrix specified in triplet form alphabetically. If the matrix is given directly (in argument <code>M</code>), rows and columns are never reordered.
</p>
</td></tr>
<tr><td><code id="dsm_+3A_verbose">verbose</code></td>
<td>

<p>if <code>TRUE</code>, a few progress and information messages are shown
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The co-occurrence matrix forming the core of the distributional semantic model (DSM) can be specified in two different ways:
</p>

<ol>
<li>
<p>As a dense or sparse matrix in argument <code>M</code>.  A sparse matrix must be a subclass of <code><a href="Matrix.html#topic+dMatrix-class">dMatrix</a></code> (from the <code>Matrix</code> package) and is automatically converted to the canonical storage mode used by the <code>wordspace</code> package.  Row and column labels may be specified with arguments <code>target</code> and <code>feature</code>, which must be character vectors of suitable length; otherwise <code>dimnames(M)</code> are used.

</p>
</li>
<li>
<p>As a triplet representation in arguments <code>target</code> (row label), <code>feature</code> (column label) and <code>score</code> (co-occurrence frequency or pre-computed score).  The three arguments must be vectors of the same length; each set of corresponding elements specifies a non-zero cell of the co-occurrence matrix.  If multiple entries for the same cell are given, their frequency or score values are added up.

</p>
</li></ol>

<p>The optional arguments <code>rowinfo</code> and <code>colinfo</code> are data frames with additional information about target and feature terms.  If they are specified, they must contain a column <code>$term</code> matching the row or column labels of the co-occurrence matrix.  Marginal frequencies and nonzero or document counts can be given in columns <code>$f</code> and <code>$nnzero</code>; any further columns are interpreted as meta-information on the target or feature terms.  The rows of each data frame are automatically reordered to match the rows or columns of the co-occurrence matrix.  Target or feature terms that do not appear in the co-occurrence matrix are silently discarded.
</p>
<p>Counts of nonzero cells for each row and column are computed automatically, unless they are already present in the <code>rowinfo</code> and <code>colinfo</code> data frames.  If the co-occurrence matrix contains raw frequency values, marginal frequencies for the target and feature terms are also computed automatically unless given in <code>rowinfo</code> and <code>colinfo</code>; the same holds for the effective sample size <code>N</code>.
</p>
<p>If <code>raw.freq=TRUE</code>, all matrix entries must be non-negative; fractional frequency counts are allowed, however.
</p>


<h3>Value</h3>

<p>An object of class <code>dsm</code>, a list with the following components:
</p>
<table>
<tr><td><code>M</code></td>
<td>

<p>A co-occurrence matrix of raw frequency counts in canonical format (see <code><a href="#topic+dsm.canonical.matrix">dsm.canonical.matrix</a></code>).
</p>
</td></tr>
<tr><td><code>S</code></td>
<td>

<p>A weighted and transformed co-occurrence matrix (&quot;score&quot; matrix) in canonical format (see <code><a href="#topic+dsm.canonical.matrix">dsm.canonical.matrix</a></code>).
Either <code>M</code> or <code>S</code> or both may be present.  The object returned by <code>dsm()</code> will include <code>M</code> if <code>raw.freq=TRUE</code> and <code>S</code> otherwise.
</p>
</td></tr>
<tr><td><code>rows</code></td>
<td>

<p>A data frame with information about the target terms, corresponding to the rows of the co-occurrence matrix.  The data frame usually has at least three columns:
</p>

<dl>
<dt><code>rows$term</code></dt><dd><p>the target term = row label</p>
</dd>
<dt><code>rows$f</code></dt><dd><p>marginal frequency of the target term; must be present if the DSM object contains a raw co-occurrence matrix <code>M</code></p>
</dd>
<dt><code>rows$nnzero</code></dt><dd><p>number of nonzero entries in the corresponding row of the co-occurrence matrix</p>
</dd>
</dl>

<p>Further columns may provide additional information.
</p>
</td></tr>
<tr><td><code>cols</code></td>
<td>

<p>A data frame with information about the feature terms, corresponding to the columns of the co-occurrence matrix, in the same format as <code>rows</code>.
</p>
</td></tr>
<tr><td><code>globals</code></td>
<td>

<p>A list of global variables.  The following variables have a special meaning:
</p>

<dl>
<dt><code>globals$N</code></dt><dd><p>effective sample size of the underlying corpus; may be <code>NA</code> if raw co-occurrence counts are not available</p>
</dd>
<dt><code>globals$locked</code></dt><dd><p>if <code>TRUE</code>, the marginal frequencies are no longer valid due to a <code>merge</code>, <code>rbind</code> or <code>cbind</code> operation; in this case, association scores cannot be computed from the co-occurrence frequencies <code>M</code></p>
</dd>
</dl>

</td></tr>
</table>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+dsm.canonical.matrix">dsm.canonical.matrix</a></code> for a description of the canonical matrix formats.  DSM objects are usually loaded directly from a disk file in UCS (<code><a href="#topic+read.dsm.ucs">read.dsm.ucs</a></code>) or triplet (<code><a href="#topic+read.dsm.triplet">read.dsm.triplet</a></code>) format.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
MyDSM &lt;- dsm(
  target =  c("boat", "boat", "cat",  "dog", "dog"),
  feature = c("buy",  "use",  "feed", "buy", "feed"),
  score =   c(1,      3,      2,      1,     1),
  raw.freq = TRUE
)

print(MyDSM)   # 3 x 3 matrix with 5 out of 9 nonzero cells
print(MyDSM$M) # the actual co-occurrence matrix

print(MyDSM$rows) # row information
print(MyDSM$cols) # column information

</code></pre>

<hr>
<h2 id='DSM_GoodsMatrix'>
A Scored Co-occurrence Matrix of Nouns Denoting Goods (wordspace)
</h2><span id='topic+DSM_GoodsMatrix'></span>

<h3>Description</h3>

<p>A pre-scored verb-object co-occurrence matrix for 240 target nouns denoting goods
and the 3 feature verbs <em>own</em>, <em>buy</em> and <em>sell</em>.
This matrix is useful for illustrating the application and purpose of dimensionality reduction techniques.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
DSM_GoodsMatrix

</code></pre>


<h3>Format</h3>

<p>A numeric matrix with 240 rows corresponding to target nouns denoting goods and 4 columns, corresponding to
</p>

<dl>
<dt><code>own</code>, <code>buy</code>, <code>sell</code>:</dt><dd>
<p>association scores for co-occurrences of the nouns with the verbs <em>own</em>, <em>buy</em> and <em>sell</em>
</p>
</dd>
<dt><code>fringe</code>:</dt><dd>
<p>an indicator of how close each point is to the &ldquo;fringe&rdquo; of the data set (ranging from 0 to 1)
</p>
</dd>
</dl>



<h3>Details</h3>

<p>Co-occurrence data are based on verb-object dependency relations in the British National Corpus, obtained from <code><a href="#topic+DSM_VerbNounTriples_BNC">DSM_VerbNounTriples_BNC</a></code>.  Only nouns that co-occur with all three verbs are included in the data set.
</p>
<p>The co-occurrence matrix is weighted with <em>non-sparse</em> log-likelihood (<code>simple-ll</code>) and an additional logarithmic transformation (<code>log</code>).  Row vectors are <em>not</em> normalized.
</p>
<p>The <em>fringeness score</em> in column <code>fringe</code> indicates how close a data point is to the fringe of the data set.  Values are distance quantiles based on PCA-whitened Manhattan distance from the centroid.  For example, <code>fringe &gt;= .8</code> characterizes 20% of points that are closest to the fringe.  Fringeness is mainly used to select points to be labelled in plots or to take stratified samples from the data set.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
DSM_GoodsMatrix[c("time", "goods", "service"), ]

</code></pre>

<hr>
<h2 id='DSM_HieroglyphsMatrix'>
A Small Co-occurrence Matrix (wordspace)
</h2><span id='topic+DSM_HieroglyphsMatrix'></span>

<h3>Description</h3>

<p>A small co-occurrence matrix of verb-object combinations from the British National Corpus (BNC)
Verbs correspond to columns of the matrix and their object nouns to rows.
This matrix is shown as the &quot;hieroglyphs&quot; example in the DSM turorial.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
DSM_HieroglyphsMatrix

</code></pre>


<h3>Format</h3>

<p>A numeric matrix with 7 rows and 6 columns.
</p>
<p>Rows represent the target nouns <em>knife</em>, <em>cat</em>, <em>dog</em>, <em>boat</em>, <em>cup</em>, <em>pig</em> and <em>banana</em>.
Columns represent the feature verbs <em>get</em>, <em>see</em>, <em>use</em>, <em>hear</em>, <em>eat</em> and <em>kill</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
print(DSM_HieroglyphsMatrix)

## cosine similarities between rows of the matrix
round(dist.matrix(DSM_HieroglyphsMatrix, convert=FALSE), 3)

</code></pre>

<hr>
<h2 id='DSM_SingularValues'>
Typical Singular Values of a Term-Context Matrix (wordspace)
</h2><span id='topic+DSM_SingularValues'></span>

<h3>Description</h3>

<p>Typical singular values of a term-document matrix based on encyclopedia articles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  
DSM_SingularValues

</code></pre>


<h3>Format</h3>

<p>A numeric vector of length 2623.
</p>


<h3>Details</h3>

<p>The data were obtained by singular value decomposition of a term-document matrix representing 100,000 Wikipedia articles, with 2623 target terms from a Basic English vocabulary.  Articles were truncated to the first ca. 500 words.  Occurrence frequencies of the target terms were log-scaled and rows of the matrix were L2-normalized before applying the SVD.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
plot(DSM_SingularValues, type="h", xaxs="i", yaxs="i")

## End(Not run)

</code></pre>

<hr>
<h2 id='DSM_TermContextMatrix'>
Example of a Term-Context Co-occurrence Matrix (wordspace)
</h2><span id='topic+DSM_TermContextMatrix'></span><span id='topic+DSM_TermContext'></span>

<h3>Description</h3>

<p>This matrix is a typical example of a term-context DSM co-occurrence matrix,
derived from the English Wikipedia.  It is available as a plain matrix in sparse representation,
and as DSM object including marginal frequency data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
DSM_TermContextMatrix

DSM_TermContext

</code></pre>


<h3>Format</h3>

<p><code>DSM_TermContextMatrix</code> is a sparse numeric matrix of class <code><a href="Matrix.html#topic+dgCMatrix-class">dgCMatrix</a></code> with 7 rows and 7 columns.
</p>
<p>Rows represent the target nouns <em>cat</em>, <em>dog</em>, <em>animal</em>, <em>time</em>, <em>reason</em>, <em>cause</em>, <em>effect</em>.
</p>
<p>Columns specify the occurrence frequencies of these nouns in Wikipedia articles on <em>Felidae</em>, <em>Pet</em>, <em>Feral</em>, <em>Boat</em>, <em>Philosohpy</em>, <em>Kant</em> and <em>Back Pain</em>.
</p>
<p><code>DSM_TermContext</code> is an object of class <code><a href="#topic+dsm">dsm</a></code> based on the same co-occurrence matrix, but with additional information on marginal frequencies of the target terms and feature contexts.
</p>


<h3>See Also</h3>

<p>This matrix/DSM describes the same target nouns as the term-term matrix <code><a href="#topic+DSM_TermTermMatrix">DSM_TermTermMatrix</a></code> and corresponding DSM object <code><a href="#topic+DSM_TermTerm">DSM_TermTerm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
DSM_TermContextMatrix["time", ] # row vector for target noun "time"

all.equal(DSM_TermContextMatrix, head(DSM_TermContext, Inf))

# M M' = symmetric matrix of co-occurrence frequencies of nouns within articles
tcrossprod(DSM_TermContextMatrix) 

</code></pre>

<hr>
<h2 id='DSM_TermTermMatrix'>
Example of a Term-Term Co-occurrence Matrix (wordspace)
</h2><span id='topic+DSM_TermTermMatrix'></span><span id='topic+DSM_TermTerm'></span>

<h3>Description</h3>

<p>This matrix is a typical example of a term-term DSM co-occurrence matrix,
derived from the English Wikipedia.  It is available as a plain matrix in dense representation,
and as a DSM object including marginal frequency data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
DSM_TermTermMatrix

DSM_TermTerm

</code></pre>


<h3>Format</h3>

<p><code>DSM_TermTermMatrix</code> is a numeric matrix with 7 rows and 7 columns.
</p>
<p>Rows represent the target nouns <em>cat</em>, <em>dog</em>, <em>animal</em>, <em>time</em>, <em>reason</em>, <em>cause</em>, <em>effect</em>.
</p>
<p>Columns specify co-occurrence frequencies of these nouns with the words <em>breed</em>, <em>tail</em>, <em>feed</em>, <em>kill</em>, <em>important</em>, <em>explain</em> and <em>likely</em> in articles of the English Wikipedia.  Co-occurring words must appear within a distance of at most two word tokens of each other.
</p>
<p><code>DSM_TermTerm</code> is an object of class <code><a href="#topic+dsm">dsm</a></code> based on the same co-occurrence matrix, but with additional information on marginal frequencies of the target and feature terms.
</p>


<h3>See Also</h3>

<p>This matrix/DSM describes the same target terms as the term-context matrix <code><a href="#topic+DSM_TermContextMatrix">DSM_TermContextMatrix</a></code> and corresponding DSM object <code><a href="#topic+DSM_TermContext">DSM_TermContext</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
DSM_TermTermMatrix["time", ] # row vector for target noun "time"

all.equal(DSM_TermTermMatrix, head(DSM_TermTerm, Inf))

## Not run: 
plot(hclust(dist.matrix(DSM_TermTermMatrix, as.dist=TRUE)))

## End(Not run)

</code></pre>

<hr>
<h2 id='DSM_Vectors'>
Pre-Compiled DSM Vectors for Selected Words (wordspace)
</h2><span id='topic+DSM_Vectors'></span>

<h3>Description</h3>

<p>A matrix of 50-dimensional pre-compiled DSM vectors for selected English content words, covering most of the words needed for several basic evaluation tasks included in the package.
Targets are given as disambiguated lemmas in the form <code>&lt;headword&gt;_&lt;pos&gt;</code>, e.g. <code>walk_V</code> and <code>walk_N</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  
DSM_Vectors

</code></pre>


<h3>Format</h3>

<p>A numeric matrix with 1667 rows and 50 columns.
</p>
<p>Row labels are disambiguated lemmas of the form <code>&lt;headword&gt;_&lt;pos&gt;</code>, where the part-of-speech code is one of
<code>N</code> (noun), <code>V</code> (verb), <code>J</code> (adjective) or <code>R</code> (adverb).
</p>
<p>Attribute <code>"sigma"</code> contains singular values that can be used for post-hoc power scaling of the latent dimensions (see <code><a href="#topic+dsm.projection">dsm.projection</a></code>).
</p>


<h3>Details</h3>

<p>The vocabulary of this DSM covers several basic evaluation tasks, including <code><a href="#topic+RG65">RG65</a></code>, <code><a href="#topic+WordSim353">WordSim353</a></code> and <code><a href="#topic+ESSLLI08_Nouns">ESSLLI08_Nouns</a></code>, as well as the target nouns <em>bank</em> and <em>vessel</em> from <code><a href="#topic+SemCorWSD">SemCorWSD</a></code>.  In addition, 40 nearest neighbours each of the words <code>white_J</code>, <code>apple_N</code>, <code>kindness_N</code> and <code>walk_V</code> are included.
</p>
<p>Co-occurrence frequency data were extracted from a collection of Web corpora with a total size of ca. 9 billion words, using a L4/R4 surface window and 30,000 lexical words as feature terms.  They were scored with sparse simple log-likelihood with an additional log transformation, normalized to Euclidean unit length, and projected into 1000 latent dimensions using randomized SVD (see <code><a href="#topic+rsvd">rsvd</a></code>.  For size reasons, the vectors have been compressed into 50 latent dimensions and renormalized.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
nearest.neighbours(DSM_Vectors, "walk_V", 25)

eval.similarity.correlation(RG65, DSM_Vectors) # fairly good

# post-hoc power scaling: whitening (correspond to power=0 in dsm.projection)
sigma &lt;- attr(DSM_Vectors, "sigma")
M &lt;- scaleMargins(DSM_Vectors, cols=1 / sigma)
eval.similarity.correlation(RG65, M) # very good

</code></pre>

<hr>
<h2 id='DSM_VerbNounTriples_BNC'>
Verb-Noun Co-occurrence Frequencies from British National Corpus (wordspace)
</h2><span id='topic+DSM_VerbNounTriples_BNC'></span>

<h3>Description</h3>

<p>A table of co-occurrence frequency counts for verb-subject and verb-object pairs in the British National Corpus (BNC).
Subject and object are represented by the respective head noun.  Both verb and noun entries are lemmatized.
Separate frequency counts are provided for the written and the spoken part of the BNC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  
DSM_VerbNounTriples_BNC

</code></pre>


<h3>Format</h3>

<p>A data frame with 250117 rows and the following columns:
</p>

<dl>
<dt><code>noun</code>:</dt><dd><p>noun lemma</p>
</dd>
<dt><code>rel</code>:</dt><dd><p>syntactic relation (<code>subj</code> or <code>obj</code>)</p>
</dd>
<dt><code>verb</code>:</dt><dd><p>verb lemma</p>
</dd>
<dt><code>f</code>:</dt><dd><p>co-occurrence frequency of noun-rel-verb triple in subcorpus</p>
</dd>
<dt><code>mode</code>:</dt><dd><p>subcorpus (<code>written</code> for the writte part of the BNC, <code>spoken</code> for the spoken part of the BNC)</p>
</dd>
</dl>



<h3>Details</h3>

<p>In order to save disk space, triples that occur less than 5 times in the respective subcorpus have been omitted from the table.
The data set should therefore not be used for practical applications.
</p>


<h3>Source</h3>

<p>Syntactic dependencies were extracted from the British National Corpus (Aston &amp; Burnard 1998) using the C&amp;C robust syntactic parser (Curran <em>et al.</em> 2007).  Lemmatization and POS tagging are also based on the C&amp;C output.
</p>


<h3>References</h3>

<p>Aston, Guy and Burnard, Lou (1998). <em>The BNC Handbook</em>. Edinburgh University Press, Edinburgh. See also the BNC homepage at <a href="http://www.natcorp.ox.ac.uk/">http://www.natcorp.ox.ac.uk/</a>.
</p>
<p>Curran, James; Clark, Stephen; Bos, Johan (2007). Linguistically motivated large-scale NLP with C&amp;C and Boxer. In <em>Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, Posters and Demonstrations Sessions</em>, pages 33&ndash;36, Prague, Czech Republic.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# compile some typical DSMs for spoken part of BNC
bncS &lt;- subset(DSM_VerbNounTriples_BNC, mode == "spoken")
dim(bncS) # ca. 14k verb-rel-noun triples

# dependency-filtered DSM for nouns, using verbs as features
# (note that multiple entries for same relation are collapsed automatically)
bncS_depfilt &lt;- dsm(
  target=bncS$noun, feature=bncS$verb, score=bncS$f,
  raw.freq=TRUE, verbose=TRUE)

# dependency-structured DSM
bncS_depstruc &lt;- dsm(
  target=bncS$noun, feature=paste(bncS$rel, bncS$verb, sep=":"), score=bncS$f,
  raw.freq=TRUE, verbose=TRUE)

</code></pre>

<hr>
<h2 id='dsm.canonical.matrix'>
Canonical Formats for a DSM Co-occurrence Matrix (wordspace)
</h2><span id='topic+dsm.is.canonical'></span><span id='topic+dsm.canonical.matrix'></span>

<h3>Description</h3>

<p>Test whether a co-occurrence matrix is represented in a DSM canonical
format, or convert matrix to canonical format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
dsm.is.canonical(x, nonneg.check = FALSE)

dsm.canonical.matrix(x, triplet = FALSE, annotate = FALSE, nonneg.check = FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dsm.canonical.matrix_+3A_x">x</code></td>
<td>

<p>a dense or sparse DSM co-occurrence matrix
</p>
</td></tr>
<tr><td><code id="dsm.canonical.matrix_+3A_nonneg.check">nonneg.check</code></td>
<td>

<p>if <code>TRUE</code>, check whether all elements of the matrix are non-negative
</p>
</td></tr>
<tr><td><code id="dsm.canonical.matrix_+3A_triplet">triplet</code></td>
<td>

<p>if <code>TRUE</code> and if <code>x</code> is sparse, return a matrix in triplet format (class <code><a href="Matrix.html#topic+dgTMatrix-class">dgTMatrix</a></code>) rather than in column-compressed format (class <code><a href="Matrix.html#topic+dgCMatrix-class">dgCMatrix</a></code>).  Note that this is <em>not</em> a canonical DSM format.
</p>
</td></tr>
<tr><td><code id="dsm.canonical.matrix_+3A_annotate">annotate</code></td>
<td>

<p>if <code>TRUE</code>, annotate <code>x</code> with attributes <code>sparse</code> and <code>nonneg</code>, indicating whether the matrix is in sparse representation and non-negative, respectively.  Non-negativity is only checked if <code>nonneg.check=TRUE</code>; otherwise an existing attribute will be passed through without validation.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that conversion into canonical format may result in unnecessary copying of <code>x</code>, especially if <code>annotate=TRUE</code>.
For optimal performance, set <code>annotate=FALSE</code> whenever possible and do not call <code>dsm.canonical.matrix()</code> as a no-op.
</p>
<p>Instead of </p>
<pre>    M &lt;- dsm.canonical.matrix(M, annotate=TRUE, nonneg=TRUE)</pre>
<p>use </p>
<pre>    M.flags &lt;- dsm.is.canonical(M, nonneg=FALSE)
    if (!M.flags$canonical) M &lt;- dsm.canonical.matrix(M)
    M.flags &lt;- dsm.is.canonical(M, nonneg=TRUE)</pre>
<p>If <code>nonneg.check=FALSE</code> and <code>x</code> has an attribute <code>nonneg</code>, its value is accepted without validation.
</p>
<p>Checking non-negativity can be expensive and create substantial memory overhead.  It is guaranteed to be efficient for a matrix in canonical format.
</p>


<h3>Value</h3>

<p><code>dsm.is.canonical()</code> returns a data frame containing a single row with the following items:
</p>
<table>
<tr><td><code>sparse</code></td>
<td>
<p>whether <code>x</code> is a sparse (<code>TRUE</code>) or dense (<code>TRUE</code>) matrix</p>
</td></tr>
<tr><td><code>canonical</code></td>
<td>
<p>whether <code>x</code> is in canonical format</p>
</td></tr>
<tr><td><code>nonneg</code></td>
<td>
<p>whether all cells of <code>x</code> are non-negative; may be <code>NA</code> if <code>nonneg.check=FALSE</code></p>
</td></tr>
</table>
<p><code>dsm.canonical.matrix()</code> returns a matrix in canonical DSM format, i.e.
</p>

<ul>
<li><p>of class <code><a href="base.html#topic+matrix">matrix</a></code> for a dense matrix (even if <code>x</code> is a <code><a href="Matrix.html#topic+denseMatrix-class">denseMatrix</a></code> object);
</p>
</li>
<li><p>of class <code><a href="Matrix.html#topic+dgCMatrix-class">dgCMatrix</a></code> for a sparse matrix.
</p>
</li></ul>

<p>If <code>triplet=TRUE</code> and <code>x</code> is sparse, it returns a matrix of class <code><a href="Matrix.html#topic+dgTMatrix-class">dgTMatrix</a></code>, which is <em>not</em> a canonical format.
</p>
<p>If <code>annotate=TRUE</code>, the returned matrix has attributes <code>sparse</code> and <code>nonneg</code> (possibly <code>NA</code>).
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>

<hr>
<h2 id='dsm.projection'>
Reduce Dimensionality of DSM by Subspace Projection (wordspace)
</h2><span id='topic+dsm.projection'></span>

<h3>Description</h3>

<p>Reduce dimensionality of DSM by linear projection of row vectors
into a lower-dimensional subspace.  Various projections methods with
different properties are available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
dsm.projection(model, n,
               method = c("svd", "rsvd", "asvd", "ri", "ri+svd"),
               oversampling = NA, q = 2, rate = .01, power=1,
               with.basis = FALSE, verbose = FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dsm.projection_+3A_model">model</code></td>
<td>

<p>either an object of class <code>dsm</code>, or a dense or sparse numeric matrix
</p>
</td></tr>
<tr><td><code id="dsm.projection_+3A_method">method</code></td>
<td>

<p>projection method to use for dimensionality reduction (see &ldquo;DETAILS&rdquo; below)
</p>
</td></tr>
<tr><td><code id="dsm.projection_+3A_n">n</code></td>
<td>

<p>an integer specifying the number of target dimensions.  Use <code>n=NA</code> to generate as many latent dimensions as possible (i.e. the minimum of the number of rows and columns of the DSM matrix).
</p>
</td></tr>
<tr><td><code id="dsm.projection_+3A_oversampling">oversampling</code></td>
<td>

<p>oversampling factor for stochastic dimensionality reduction algorithms (<code>rsvd</code>, <code>asvd</code>, <code>ri+svd</code>).  If unspecified, the default value is 2 for <code>rsvd</code>, 10 for <code>asvd</code> and 10 for <code>ri+svd</code> (subject to change).
</p>
</td></tr>
<tr><td><code id="dsm.projection_+3A_q">q</code></td>
<td>

<p>number of power iterations in the randomized SVD algorithm (Halko <em>et al.</em> 2009 recommend <code>q=1</code> or <code>q=2</code>)
</p>
</td></tr>
<tr><td><code id="dsm.projection_+3A_rate">rate</code></td>
<td>

<p>fill rate of random projection vectors.  Each random dimension has on average <code>rate * ncol(model)</code> nonzero components in the original space
</p>
</td></tr>
<tr><td><code id="dsm.projection_+3A_power">power</code></td>
<td>
<p>apply power scaling after SVD-based projection, i.e. multiply each latent dimension with a suitable power of the corresponding singular value.
The default <code>power=1</code> corresponds to a regular orthogonal projection.  For power <code class="reqn">&gt; 1</code>, the first SVD dimensions &ndash; i.e. those capturing the main patterns of <code class="reqn">M</code> &ndash; are given more weight; for power <code class="reqn">&lt; 1</code>, they are given less weight.  The setting <code>power=0</code> results in a full equalization of the dimensions and is also known as &ldquo;whitening&rdquo; in the PCA case.
</p>
</td></tr>
<tr><td><code id="dsm.projection_+3A_with.basis">with.basis</code></td>
<td>

<p>if <code>TRUE</code>, also returns orthogonal basis of the subspace as attribute of the reduced matrix (not available for random indexing methods)
</p>
</td></tr>
<tr><td><code id="dsm.projection_+3A_verbose">verbose</code></td>
<td>

<p>if <code>TRUE</code>, some methods display progress messages during execution
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following dimensionality reduction algorithms can be selected with the <code>method</code> argument:
</p>

<dl>
<dt>svd</dt><dd><p>singular value decomposition (SVD), using the efficient SVDLIBC algorithm (Berry 1992) from package <b>sparsesvd</b> if the input is a sparse matrix.  If the DSM has been scored with <code>scale="center"</code>, this method is equivalent to principal component analysis (PCA).</p>
</dd>
<dt>rsvd</dt><dd><p>randomized SVD (Halko <em>et al.</em> 2009, p. 9) based on a factorization of rank <code>oversampling * n</code> with <code>q</code> power iterations.</p>
</dd>
<dt>asvd</dt><dd><p>approximate SVD, which determines latent dimensions from a random sample of matrix rows including  <code>oversampling * n</code> data points.  This heuristic algorithm is highly inaccurate and has been <b>deprecated</b>.</p>
</dd>
<dt>ri</dt><dd><p>random indexing (RI), i.e. a projection onto random basis vectors that are approximately orthogonal. Basis vectors are generated by setting a proportion of <code>rate</code> elements randomly to <code class="reqn">+1</code> or <code class="reqn">-1</code>. Note that this does not correspond to a proper orthogonal projection, so the resulting coordinates in the reduced space should be used with caution.</p>
</dd>
<dt>ri+svd</dt><dd><p>RI to <code>oversampling * n</code> dimensions, followed by SVD of the pre-reduced matrix to the final <code>n</code> dimensions. This is not a proper orthogonal projection because the RI basis vectors in the first step are only approximately orthogonal.</p>
</dd>
</dl>
  


<h3>Value</h3>

<p>A numeric matrix with <code>n</code> columns (latent dimensions) and the same number of rows as the original DSM.  Some SVD-based algorithms may discard poorly conditioned singular values, returning fewer than <code>n</code> columns.
</p>
<p>If <code>with.basis=TRUE</code> and an orthogonal projection is used, the corresponding orthogonal basis <code class="reqn">B</code> of the latent subspace is returned as an attribute <code>"basis"</code>.  <code class="reqn">B</code> is column-orthogonal, hence <code class="reqn">B^T</code> projects into latent coordinates and <code class="reqn">B B^T</code> is an orthogonal subspace projection in the original coordinate system.
</p>
<p>For orthogonal projections, the attribute <code>"R2"</code> contains a numeric vector specifying the proportion of the squared Frobenius norm of the original matrix captured by each of the latent dimensions.  If the original matrix has been centered (so that a SVD projection is equivalent to PCA), this corresponds to the proportion of variance &ldquo;explained&rdquo; by each dimension.
</p>
<p>For SVD-based projections, the attribute <code>"sigma"</code> contains the singular values corresponding to latent dimensions.  It can be used to adjust the power scaling exponent at a later time.
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>References</h3>

<p>Berry, Michael~W. (1992). Large scale sparse singular value computations.
<em>International Journal of Supercomputer Applications</em>, <b>6</b>, 13&ndash;49.  
</p>
<p>Halko, N., Martinsson, P. G., and Tropp, J. A. (2009).
Finding structure with randomness: Stochastic algorithms for constructing approximate matrix decompositions. Technical Report 2009-05, ACM, California Institute of Technology.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rsvd">rsvd</a></code> for the implementation of randomized SVD, and <code><a href="sparsesvd.html#topic+sparsesvd">sparsesvd</a></code> for the SVDLIBC wrapper
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# 240 English nouns in space with correlated dimensions "own", "buy" and "sell"
M &lt;- DSM_GoodsMatrix[, 1:3]

# SVD projection into 2 latent dimensions
S &lt;- dsm.projection(M, 2, with.basis=TRUE)
  
100 * attr(S, "R2") # dim 1 captures 86.4% of distances
round(attr(S, "basis"), 3) # dim 1 = commodity, dim 2 = owning vs. buying/selling
  
S[c("time", "goods", "house"), ] # some latent coordinates
  
## Not run: 
idx &lt;- DSM_GoodsMatrix[, 4] &gt; .85 # only show nouns on "fringe"
plot(S[idx, ], pch=20, col="red", xlab="commodity", ylab="own vs. buy/sell")
text(S[idx, ], rownames(S)[idx], pos=3)

## End(Not run)
</code></pre>

<hr>
<h2 id='dsm.score'>
Weighting, Scaling and Normalisation of Co-occurrence Matrix (wordspace)
</h2><span id='topic+dsm.score'></span>

<h3>Description</h3>

<p>Compute feature scores for a term-document or term-term co-occurrence matrix, using one of several standard association measures.  Scores can optionally be rescaled with an isotonic transformation function and centered or standardized.  In addition, row vectors can be normalized to unit length wrt. a given norm. 
</p>
<p>This function has been optimized for efficiency and low memory overhead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
dsm.score(model, score = "frequency",
          sparse = TRUE, negative.ok = NA,
          transform = c("none", "log", "root", "sigmoid"),
          scale = c("none", "standardize", "center", "scale"),
          normalize = FALSE, method = "euclidean", p = 2, tol = 1e-6,
          matrix.only = FALSE, update.nnzero = FALSE,
          batchsize = 1e6, gc.iter = Inf)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dsm.score_+3A_model">model</code></td>
<td>
<p>a DSM model, i.e. an object of class <code>dsm</code></p>
</td></tr>
<tr><td><code id="dsm.score_+3A_score">score</code></td>
<td>
<p>the association measure to be used for feature weighting; either a character string naming one of the built-in measures or a user-defined function (see &ldquo;Details&rdquo; below)</p>
</td></tr>
<tr><td><code id="dsm.score_+3A_sparse">sparse</code></td>
<td>
<p>if <code>TRUE</code> (the default), compute sparse non-negative association scores (see &ldquo;Details&rdquo; below).
Non-sparse association scores are only allowed if <code>negative.ok=TRUE</code>.
</p>
</td></tr>
<tr><td><code id="dsm.score_+3A_negative.ok">negative.ok</code></td>
<td>
<p>whether operations that introduce negative values into the score matrix (non-sparse association scores, standardization of columns, etc.) are allowed.
The default (<code>negative.ok=NA</code>) is <code>TRUE</code> if the co-occurrence matrix <code class="reqn">M</code> is dense, and <code>FALSE</code> if it is sparse.  See &ldquo;Details&rdquo; below for the special value <code>negative.ok="nonzero"</code>. 
</p>
</td></tr>
<tr><td><code id="dsm.score_+3A_transform">transform</code></td>
<td>
<p>scale transformation to be applied to association scores (see &ldquo;Details&rdquo; below)</p>
</td></tr>
<tr><td><code id="dsm.score_+3A_scale">scale</code></td>
<td>
<p>if not <code>"none"</code>, standardize columns of the scored matrix by z-transformation (<code>"standardize"</code>), center them without rescaling (<code>"center"</code>), or scale to unit RMS without centering (<code>"scale"</code>)</p>
</td></tr>
<tr><td><code id="dsm.score_+3A_normalize">normalize</code></td>
<td>
<p>if <code>TRUE</code> normalize row vectors of scored matrix to unit length, according to the norm indicated by <code>method</code> and <code>p</code></p>
</td></tr>
<tr><td><code id="dsm.score_+3A_method">method</code>, <code id="dsm.score_+3A_p">p</code></td>
<td>
<p>norm to be used with <code>normalize=TRUE</code>.
See <code><a href="#topic+rowNorms">rowNorms</a></code> for admissible values and details on the corresponding norms
</p>
</td></tr>
<tr><td><code id="dsm.score_+3A_tol">tol</code></td>
<td>
<p>if <code>normalize=TRUE</code>, row vectors with norm below <code>tol</code> are explicitly set to all zeroes instead of attempting to normalize them (see <code><a href="#topic+normalize.rows">normalize.rows</a></code> for more information)</p>
</td></tr>
<tr><td><code id="dsm.score_+3A_matrix.only">matrix.only</code></td>
<td>
<p>whether to return updated DSM model (default) or only the matrix of scores (<code>matrix.only=TRUE</code>)</p>
</td></tr>
<tr><td><code id="dsm.score_+3A_update.nnzero">update.nnzero</code></td>
<td>
<p>if <code>TRUE</code> and a full DSM model is returned, update the counts of nonzero entries in rows and columns according to the matrix of scores (there may be fewer nonzero entries with sparse association scores, or more from dense association scores and/or column scaling)</p>
</td></tr>
<tr><td><code id="dsm.score_+3A_batchsize">batchsize</code></td>
<td>
<p>if <code>score</code> is a user-defined function, the co-occurrence matrix is divided into blocks of approx. <code>batchsize</code> elements each in order to reduce memory overhead</p>
</td></tr>
<tr><td><code id="dsm.score_+3A_gc.iter">gc.iter</code></td>
<td>
<p>how often to run the garbage collector when computing user-defined association scores; <code>gc()</code> is called after every <code>gc.iter</code> batches in order to reclaim temporary data and keep memory overhead as low as possible. This option should only be specified if memory is very tight, since garbage collector runs can be expensive (e.g. when there are many distinct strings in the workspace). With the default value <code>gc.iter=Inf</code>, no calls to <code>gc()</code> will be made; <code>gc.iter=4</code> seems to give a good trade-off between memory overhead and degraded performance.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Association measures</h4>

<p>Association measures (AM) for feature scoring are defined in the notation of Evert (2008).  The most important symbols are <code class="reqn">O_{11} = O</code> for the observed co-occurrence frequency, <code class="reqn">E_{11} = E</code> for the co-occurrence frequency expected under a null hypothesis of independence, <code class="reqn">R_1</code> for the marginal frequency of the target term, <code class="reqn">C_1</code> for the marginal frequency of the feature term or context, and <code class="reqn">N</code> for the sample size of the underlying corpus.  Evert (2008) explains in detail how these values are computed for different types of co-occurrence; practical examples can be found in the distributional semantics tutorial at <a href="http://wordspace.collocations.de/">http://wordspace.collocations.de/</a>.
</p>
<p>Several commonly used AMs are implemented in optimized C++ code for efficiency and minimal memory overhead.  They are selected by name, which is passed as a character string in the <code>score</code> argument.  See below for a list of built-in measures and their full equations.
</p>
<p>Other AMs can be applied by passing a user-defined function in the <code>score</code> argument. See &ldquo;User-defined association measures&rdquo; at the end of this section for details.
</p>



<h4>Built-in association measures</h4>

<p>The names of the following measures can be abbreviated to a unique prefix. Equations are given in the notation of Evert (2008).
</p>

<dl>
<dt><code>frequency</code> (default)</dt><dd>
<p>Co-occurrence <b>frequency</b>: </p>
<p style="text-align: center;"><code class="reqn">
          O_{11}
        </code>
</p>

<p>Use this association measure to operate on raw, unweighted co-occurrence frequency data.
</p>
</dd>
<dt><code>MI</code></dt><dd>
<p><b>(Pointwise) Mutual Information</b>, a log-transformed version of the ratio between observed and expected co-occurrence frequency: </p>
<p style="text-align: center;"><code class="reqn">
          \log_2 \frac{O_{11}}{E_{11}}
        </code>
</p>

<p>Pointwise MI has a very strong bias towards pairs with low expected co-occurrence frequency (because of <code class="reqn">E_{11}</code> in the denominator). It should only be applied if low-frequency targets and features have been removed from the DSM.
</p>
<p>The sparse version of MI (with negative scores cut off at 0) is sometimes referred to as &quot;positive pointwise Mutual Information&quot; (<b>PPMI</b>) in the literature.
</p>
</dd>
<dt><code>log-likelihood</code></dt><dd>
<p>The <code class="reqn">G^2</code> statistic of a likelihood ratio test for independence of rows and columns in a contingency table, which is very popular in computational linguistics under the name <b>log-likelihood</b>: </p>
<p style="text-align: center;"><code class="reqn">
          \pm 2 \left( \sum_{ij} O_{ij}\cdot \log \frac{O_{ij}}{E_{ij}} \right)
        </code>
</p>

<p>This implementation computes <em>signed</em> association scores, which are negative iff <code class="reqn">O_{11} &lt; E_{11}</code>.
Log-likelihood has a strong bias towards high co-occurrence frequency and often produces a highly skewed distribution of scores. It may therefore be advisable to combine it with an additional <code>log</code> transformation.
</p>
</dd>
<dt><code>simple-ll</code></dt><dd>
<p>Simple <b>log-likelihood</b> (Evert 2008, p. 1225): </p>
<p style="text-align: center;"><code class="reqn">
          \pm 2 \left( O_{11}\cdot \log \frac{O_{11}}{E_{11}} - (O_{11} - E_{11}) \right)
        </code>
</p>

<p>This measure provides a good approximation to the full log-likelihood measure (Evert 2008, p. 1235), but can be computed much more efficiently. It is also very similar to the <b>local-MI</b> measure used by several popular DSMs.
</p>
<p>Like <code>log-likelihood</code>, this measure computes <em>signed</em> association scores and has a strong bias towards high co-occurrence frequency.
</p>
</dd>
<dt><code>t-score</code></dt><dd>
<p>The <b>t-score</b> association measure, which is popular for collocation identification in computational lexicography: </p>
<p style="text-align: center;"><code class="reqn">
          \frac{O_{11} - E_{11}}{\sqrt{O_{11}}}
        </code>
</p>

<p>T-score is known to filter out low-frequency data effectively.  If used as a non-sparse measure, a &ldquo;discounted&rdquo; version with <code class="reqn">\sqrt(O + 1)</code> in the denominator is computed.
</p>
</dd>
<dt><code>chi-squared</code></dt><dd>
<p>The <code class="reqn">X^2</code> statistic of Pearson's <b>chi-squared</b> test for independence of rows and columns in a contingency table, with Yates's correction applied: </p>
<p style="text-align: center;"><code class="reqn">
          \pm \frac{
            N \bigl( | O_{11}O_{22} - O_{12} O_{21} | - N/2 \bigr)^2
          }{
            R_1 R_2 C_1 C_2
          }
        </code>
</p>

<p>This implementation computes <em>signed</em> association scores, which are negative iff <code class="reqn">O_{11} &lt; E_{11}</code>.
</p>
<p>The formula above gives a more compact form of Yates's correction than the familiar sum over the four cells of the contingency table.
</p>
</dd>
<dt><code>z-score</code></dt><dd>
<p>The <b>z-score</b> association measure, based on a normal approximation to the binomial distribution of co-occurrence by chance: </p>
<p style="text-align: center;"><code class="reqn">
          \frac{O_{11} - E_{11}}{\sqrt{E_{11}}}
        </code>
</p>

<p>Z-score has a strong bias towards pairs with low expected co-occurrence frequency (because of <code class="reqn">E_{11}</code> in the denominator). It should only be applied if low-frequency targets and features have been removed from the DSM.
</p>
</dd>
<dt><code>Dice</code></dt><dd>
<p>The <b>Dice coefficient</b> of association, which corresponds to the harmonic mean of the conditional probabilities <code class="reqn">P(\mathrm{feature}|\mathrm{target})</code> and <code class="reqn">P(\mathrm{target}|\mathrm{feature})</code>: </p>
<p style="text-align: center;"><code class="reqn">
          \frac{2 O_{11}}{R_1 + C_1}
        </code>
</p>

<p>Note that Dice is inherently sparse: it preserves zeroes and does not produce negative scores.
</p>
</dd>
</dl>

<p>The following additional scoring functions can be selected:
</p>

<dl>
<dt><code>tf.idf</code></dt><dd>
<p>The <b>tf-idf</b> weighting scheme popular in Information Retrieval: </p>
<p style="text-align: center;"><code class="reqn">
          O_{11}\cdot \log \frac{1}{\mathit{df}}
        </code>
</p>

<p>where <code class="reqn">\mathit{df}</code> is the relative document frequency of the corresponding feature term and should be provided as a variable <code>df</code> in the model's column information.  Otherwise, it is approximated by the feature's nonzero count <code class="reqn">n_p</code> (variable <code>nnzero</code>) divided by the number <code class="reqn">K</code> of rows in the co-occurrence matrix: </p>
<p style="text-align: center;"><code class="reqn">
          \mathit{df} = \frac{n_p + 1}{K + 1}
        </code>
</p>

<p>The discounting avoids division-by-zero errors when <code class="reqn">n_p = 0</code>.
</p>
</dd> 
<dt><code>reweight</code></dt><dd>
<p>Apply scale transformation, column scaling and/or row normalization to previously computed feature scores (from <code>model$S</code>).  This is the only <code>score</code> that can be used with a DSM that does not contain raw co-occurrence frequency data.
</p>
</dd>
</dl>




<h4>Sparse association scores</h4>

<p>If <code>sparse=TRUE</code>, negative association scores are cut off at 0 in order to (i) ensure that the scored matrix is non-negative and (ii) preserve sparseness.  The implementation assumes that association scores are always <code class="reqn">\leq 0</code> for <code class="reqn">O_{11} = 0</code> in this case and only computes scores for nonzero entries in a sparse matrix.  All built-in association measures satisfy this criterion.
</p>
<p>Other researchers sometimes refer to such sparse scores as &quot;positive&quot; measures, most notably positive point-wise Mutual Information (PPMI). Since <code>sparse=TRUE</code> is the default setting, <code>score="MI"</code> actually computes the PPMI measure.
</p>
<p>Non-sparse association scores can only be computed if <code>negative.ok=TRUE</code> and will force a dense matrix representation. For this reason, the default is <code>FALSE</code> for a sparse co-occurrence matrix and <code>TRUE</code> for a dense one.  A special setting <code>negative.ok="nonzero"</code> is provided for those who wish to abuse <code>dsm.score</code> for collocation analysis.  In combination with <code>sparse=FALSE</code>, it will allow negative score values, but compute them only for the nonzero entries of a sparse co-occurrence matrix.  For a dense co-occurrence matrix, this setting is fully equivalent to <code>negative.ok=TRUE</code>.
</p>



<h4>Scale transformations</h4>

<p>Association scores can be re-scaled with an isotonic transformation function that preserves sign and ranking of the scores. This is often done in order to de-skew the distribution of scores or as an approximate binarization (presence vs. absence of features).  The following built-in transformations are available:
</p>

<dl>
<dt><code>none</code> (default)</dt><dd>
<p>A <b>linear</b> transformation leaves association scores unchanged. </p>
<p style="text-align: center;"><code class="reqn">
          f(x) = x
        </code>
</p>

</dd>
<dt><code>log</code></dt><dd>
<p>The <b>logarithmic</b> transformation has a strong de-skewing effect.  In order to preserve sparseness and sign of association scores, a signed and discounted version has been implemented. </p>
<p style="text-align: center;"><code class="reqn">
          f(x) = \mathop{\mathrm{sgn}}(x) \cdot \log (|x| + 1)
        </code>
</p>

</dd>
<dt><code>root</code></dt><dd>
<p>The <b>signed square root</b> transformation has a mild de-skewing effect. </p>
<p style="text-align: center;"><code class="reqn">
          f(x) = \mathop{\mathrm{sgn}}(x) \cdot \sqrt{|x|}
        </code>
</p>

</dd>
<dt><code>sigmoid</code></dt><dd>
<p>The <b>sigmoid</b> transformation produces a smooth binarization where negative values saturate at <code class="reqn">-1</code>, positive values saturate at <code class="reqn">+1</code> and zeroes remain unchanged. </p>
<p style="text-align: center;"><code class="reqn">
          f(x) = \tanh x
        </code>
</p>

</dd>
</dl>




<h4>User-defined association measures</h4>

<p>Instead of the name of a built-in AM, a function implementing a user-defined measure can be passed in the <code>score</code> argument. This function will be applied to the co-occurrence matrix in batches of approximately <code>batchsize</code> elements in order to limit the memory overhead incurred. A user-defined AM can be combined with any of the transformations above, and <code>sparse=TRUE</code> will cut off all negative scores.
</p>
<p>The user function can use any of following arguments to access the contingency tables of observed and expected frequencies, following the notation of Evert (2008):
</p>

<dl>
<dt><code>O</code>, <code>E</code></dt><dd><p>observed and expected co-occurrence frequency</p>
</dd>
<dt><code>R1</code>, <code>R2</code>, <code>C1</code>, <code>C2</code></dt><dd><p>the row and column marginals of the contingency table</p>
</dd>
<dt><code>N</code></dt><dd><p>sample size</p>
</dd>
<dt><code>f</code>, <code>f1</code>, <code>f2</code></dt><dd><p>the frequency signature of a target-feature pair, a different notation for <code class="reqn">f = O</code>, <code class="reqn">f_1 = R_1</code> and <code class="reqn">f_2 = C_1</code></p>
</dd>
<dt><code>O11</code>, <code>O12</code>, <code>O21</code>, <code>O22</code></dt><dd><p>the contingency table of observed frequencies</p>
</dd>
<dt><code>E11</code>, <code>E12</code>, <code>E21</code>, <code>E22</code></dt><dd><p>the contingency table of expected frequencies</p>
</dd>
<dt><code>rows</code></dt><dd><p>a data frame containing information about the target items (from the <code>rows</code> element of <code>model</code>)</p>
</dd>
<dt><code>cols</code></dt><dd><p>a data frame containing information about the feature items (from the <code>cols</code> element of <code>model</code>)</p>
</dd>
<dt><code>...</code></dt><dd><p>must be specified to ignore unused arguments</p>
</dd>
</dl>

<p>Except for <code>rows</code> and <code>cols</code>, all these arguments will be numeric vectors of the same lengths or scalar values (<code>N</code>), and the function must return a numeric vector of the same length.
</p>
<p>For example, the built-in Mutual Information measure could also be implemented with the user function
</p>
<pre>    my.MI &lt;- function (O, E, ...) log2(O / E) </pre>
<p>and tf.idf scoring could be implemented as follows, provided that the feature information table <code>model$cols</code> contains a column <code>df</code> with relative document frequencies:
</p>
<pre>    my.tfidf &lt;- function (O11, cols, ...) O11 * log(1 / cols$df)
    dsm.score(model, score=my.tfidf)</pre>
<p><b>Warning:</b> User-defined AMs are much less efficient than the built-in measures and should only be used on large data sets if there is a good reason to do so. Increasing <code>batchsize</code> may speed up the computation to some degree at the expense of bigger memory overhead.
</p>



<h3>Value</h3>

<p>Either an updated DSM model of class <code>dsm</code> (default) or the matrix of (scaled and normalised) association scores (<code>matrix.only=TRUE</code>).
</p>
<p>Note that updating DSM models may require a substantial amount of temporary memory (because of the way memory management is implemented in <span class="rlang"><b>R</b></span>).  This can be problematic when running a 32-bit build of <span class="rlang"><b>R</b></span> or when dealing with very large DSM models, so it may be better to return only the scored matrix in such cases.
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>References</h3>

<p>More information about assocation measures and the notation for contingency tables can be found at <a href="http://www.collocations.de/">http://www.collocations.de/</a> and in
</p>
<p>Evert, Stefan (2008). Corpora and collocations. In A. Lüdeling and M. Kytö (eds.), <em>Corpus Linguistics. An International Handbook</em>, chapter 58, pages 1212&ndash;1248. Mouton de Gruyter, Berlin, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dsm">dsm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- DSM_TermTerm
model$M # raw co-occurrence matrix
  
model &lt;- dsm.score(model, score="MI")
round(model$S, 3) # PPMI scores
  
model &lt;- dsm.score(model, score="reweight", transform="sigmoid")
round(model$S, 3) # additional sigmoid transformation

## user-defined scoring functions can implement additional measures,
## e.g. the conditional probability Pr(feature | target) as a percentage
my.CP &lt;- function (O11, R1, ...) 100 * O11 / R1  # "..." is mandatory
model &lt;- dsm.score(model, score=my.CP)
round(model$S, 3)

## shifted PPMI (with k = 2) creates all-zero rows and columns
model &lt;- dsm.score(model, score=function (O, E, ...) log2(O / E) - 2,
                   normalize=TRUE, update.nnzero=TRUE)
round(model$S, 3) # normalization preserves all-zero rows
## use subset to remove such rows and columns
m2 &lt;- subset(model, nnzero &gt; 0, nnzero &gt; 0) # must have updated nnzero counts
round(m2$S, 3)

## Not run: 
# visualization of the scale transformations implemented by dsm.score
x &lt;- seq(-2, 4, .025)
plot(x, x, type="l", lwd=2, xaxs="i", yaxs="i", xlab="x", ylab="f(x)")
abline(h=0, lwd=0.5); abline(v=0, lwd=0.5)
lines(x, sign(x) * log(abs(x) + 1), lwd=2, col=2)
lines(x, sign(x) * sqrt(abs(x)), lwd=2, col=3)
lines(x, tanh(x), lwd=2, col=4)
legend("topleft", inset=.05, bg="white", lwd=3, col=1:4,
       legend=c("none", "log", "root", "sigmoid"))

## End(Not run)
</code></pre>

<hr>
<h2 id='ESSLLI08_Nouns'>
Noun Clustering Task from ESSLLI 2008 (wordspace)
</h2><span id='topic+ESSLLI08_Nouns'></span>

<h3>Description</h3>

<p>A set of 44 nouns denoting basic-level concepts from 6 semantic classes,
used as a gold standard in the ESSLLI 2008 shared task on noun clustering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  
ESSLLI08_Nouns
  
</code></pre>


<h3>Format</h3>

<p>A data frame with 44 rows and the following 5 columns:  
</p>

<dl>
<dt><code>word</code></dt><dd><p>a character vector specifying the 44 nouns in CWB/Penn format (see <code><a href="#topic+convert.lemma">convert.lemma</a></code>)</p>
</dd>
<dt><code>class</code></dt><dd><p>a factor vector specifying the semantic class of each noun (bird, fruitTree, green, groundAnimal, tool, vehicle)</p>
</dd>
<dt><code>class2</code></dt><dd><p>a factor vector specifying a coarser 3-class categorization (animal, vegetable, artifact)</p>
</dd>
<dt><code>class3</code></dt><dd><p>a factor vector specifying a coarser 2-class categorization (natural, artifact)</p>
</dd>
<dt><code>freq.bnc</code></dt><dd><p>a numeric vector specifying the frequency of each noun in the British National Corpus</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="http://wordspace.collocations.de/doku.php/data:esslli2008:concrete_nouns_categorization">http://wordspace.collocations.de/doku.php/data:esslli2008:concrete_nouns_categorization</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
print(ESSLLI08_Nouns)

</code></pre>

<hr>
<h2 id='eval.clustering'>
Evaluate DSM on Clustering Task (wordspace)
</h2><span id='topic+eval.clustering'></span>

<h3>Description</h3>

<p>Performs evaluation on a word clustering task by comparing a flat clustering
solution based on semantic distances with a gold classification. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
eval.clustering(task, M, dist.fnc = pair.distances, ...,
                details = FALSE, format = NA, taskname = NA,
                scale.entropy = FALSE, n.clusters = NA,
                word.name = "word", class.name = "class")

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eval.clustering_+3A_task">task</code></td>
<td>
<p>a data frame listing words and their classes, usually in columns named <code>word</code> and <code>class</code></p>
</td></tr>
<tr><td><code id="eval.clustering_+3A_m">M</code></td>
<td>
<p>a scored DSM matrix, passed to <code>dist.fnc</code></p>
</td></tr>
<tr><td><code id="eval.clustering_+3A_dist.fnc">dist.fnc</code></td>
<td>
<p>a callback function used to compute distances between word pairs.
It will be invoked with character vectors containing the components of the word pairs as first and second argument,
the DSM matrix <code>M</code> as third argument, plus any additional arguments (<code>...</code>) passed to <code>eval.multiple.choice</code>.
The return value must be a numeric vector of appropriate length.  If one of the words in a pair is not represented in the DSM,
the corresponding distance value should be set to <code>Inf</code>.
</p>
</td></tr>
<tr><td><code id="eval.clustering_+3A_...">...</code></td>
<td>
<p>any further arguments are passed to <code>dist.fnc</code> and can be used e.g. to select a distance measure</p>
</td></tr>
<tr><td><code id="eval.clustering_+3A_details">details</code></td>
<td>
<p>if <code>TRUE</code>, a detailed report with information on each task item is returned (see &ldquo;Value&rdquo; below for details)</p>
</td></tr>
<tr><td><code id="eval.clustering_+3A_format">format</code></td>
<td>
<p>if the task definition specifies POS-disambiguated lemmas in CWB/Penn format, they can automatically be transformed into some other notation conventions; see <code><a href="#topic+convert.lemma">convert.lemma</a></code> for details</p>
</td></tr>
<tr><td><code id="eval.clustering_+3A_taskname">taskname</code></td>
<td>
<p>optional row label for the short report (<code>details=FALSE</code>)</p>
</td></tr>
<tr><td><code id="eval.clustering_+3A_scale.entropy">scale.entropy</code></td>
<td>
<p>whether to scale cluster entropy values to the range <code class="reqn">[0, 1]</code></p>
</td></tr>
<tr><td><code id="eval.clustering_+3A_n.clusters">n.clusters</code></td>
<td>
<p>number of clusters. The (very sensible) default is to generate as many clusters as their are classes in the gold standard.</p>
</td></tr>
<tr><td><code id="eval.clustering_+3A_word.name">word.name</code></td>
<td>
<p>the name of the column of <code>task</code> containing words</p>
</td></tr>
<tr><td><code id="eval.clustering_+3A_class.name">class.name</code></td>
<td>
<p>the name of the column of <code>task</code> containing gold standard classes</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test words are clustered using the &ldquo;partitioning around medoids&rdquo; (PAM) algorithm (Kaufman &amp; Rousseeuw 1990, Ch. 2) based on their semantic distances.
The PAM algorithm is used because it works with arbitrary distance measures (including neihbour rank), produces a stable solution (unlike most iterative algorithms)
and has shown to be on par with state-of-the-art spherical k-means clustering (CLUTO) in evaluation studies.
</p>
<p>Each cluster is automatically assigned a majority label, i.e. the gold standard class occurring most frequently in the cluster.
This represents the best possible classification that can be derived from the clustering.
</p>
<p>As evaluation metrics, clustering <b>purity</b> (accuracy of the majority classification) and <b>entropy</b> are computed.
The latter is defined as a weighted average over the entropy of the class distribution within each cluster, expressed in bits.
If <code>scale.entropy=TRUE</code>, the value is divided by the overall entropy of the class distribution in the gold standard, scaling it to the range <code class="reqn">[0, 1]</code>.
</p>
<p>NB: The semantic distance measure selected with the extra arguments (<code>...</code>) should be <em>symmetric</em>.
In particular, it is not very sensible to specify <code>rank="fwd"</code> or <code>rank="bwd"</code>.
</p>
<p>NB: Similarity measures are not supported by the current clustering algorithm.  Make sure not to call <code>dist.matrix</code>
(from <code>dist.fnc</code>) with <code>convert=FALSE</code>!
</p>


<h3>Value</h3>

<p>The default short report (<code>details=FALSE</code>) is a data frame with a single row and the columns
<code>purity</code> (clustering purity as a percentage), <code>entropy</code> (scaled or unscaled clustering entropy)
and <code>missing</code> (number of words not found in the DSM).
</p>
<p>The detailed report (<code>details=TRUE</code>) is a data frame with one row for each test word and the following columns:
</p>
<table>
<tr><td><code>word</code></td>
<td>
<p>the test word (character)</p>
</td></tr>
<tr><td><code>cluster</code></td>
<td>
<p>cluster to which the word has been assigned; all unknown words are collected in an additional cluster <code>"n/a"</code></p>
</td></tr>
<tr><td><code>label</code></td>
<td>
<p>majority label of this cluster (factor with same levels as <code>gold</code>)</p>
</td></tr>
<tr><td><code>gold</code></td>
<td>
<p>gold standard class of the test word (factor)</p>
</td></tr>
<tr><td><code>correct</code></td>
<td>
<p>whether majority class assignment is correct (logical)</p>
</td></tr>
<tr><td><code>missing</code></td>
<td>
<p>whether word was not found in the DSM (logical)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p>Suitable gold standard data sets in this package: <code><a href="#topic+ESSLLI08_Nouns">ESSLLI08_Nouns</a></code>
</p>
<p>Support functions: <code><a href="#topic+pair.distances">pair.distances</a></code>, <code><a href="#topic+convert.lemma">convert.lemma</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
eval.clustering(ESSLLI08_Nouns, DSM_Vectors, class.name="class2")

</code></pre>

<hr>
<h2 id='eval.multiple.choice'>
Evaluate DSM on Multiple Choice Task (wordspace)
</h2><span id='topic+eval.multiple.choice'></span>

<h3>Description</h3>

<p>Evaluates DSM on a multiple choice task by selecting the answer option closest to the target term in distributional space.
A typical example is the TOEFL Synonym Task (Landauer &amp; Dumais 1997).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
eval.multiple.choice(task, M, dist.fnc = pair.distances, ...,
                     details = FALSE, format = NA, taskname = NA,
                     target.name = "target", correct.name = "correct",
                     distractor.name = "^distract") 

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eval.multiple.choice_+3A_task">task</code></td>
<td>
<p>a data frame listing the target word, the correct answer, and one or more additional choices (distractors) for each test item</p>
</td></tr>
<tr><td><code id="eval.multiple.choice_+3A_m">M</code></td>
<td>
<p>a scored DSM matrix, passed to <code>dist.fnc</code></p>
</td></tr>
<tr><td><code id="eval.multiple.choice_+3A_dist.fnc">dist.fnc</code></td>
<td>
<p>a callback function used to compute distances between term pairs (or similarity scores, which must be marked with an attribute <code>similarity=TRUE</code>). See &ldquo;Details&rdquo; below for further information.</p>
</td></tr>
<tr><td><code id="eval.multiple.choice_+3A_...">...</code></td>
<td>
<p>any further arguments are passed to <code>dist.fnc</code> and can be used e.g. to select a distance measure</p>
</td></tr>
<tr><td><code id="eval.multiple.choice_+3A_details">details</code></td>
<td>
<p>if <code>TRUE</code>, a detailed report with information on each task item is returned (see &ldquo;Value&rdquo; below for details)</p>
</td></tr>
<tr><td><code id="eval.multiple.choice_+3A_format">format</code></td>
<td>
<p>if the task definition specifies POS-disambiguated lemmas in CWB/Penn format, they can automatically be transformed into some other notation conventions; see <code><a href="#topic+convert.lemma">convert.lemma</a></code> for details</p>
</td></tr>
<tr><td><code id="eval.multiple.choice_+3A_taskname">taskname</code></td>
<td>
<p>optional row label for the short report (<code>details=FALSE</code>)</p>
</td></tr>
<tr><td><code id="eval.multiple.choice_+3A_target.name">target.name</code></td>
<td>
<p>the name of the column of <code>task</code> containing the target word</p>
</td></tr>
<tr><td><code id="eval.multiple.choice_+3A_correct.name">correct.name</code></td>
<td>
<p>the name of the column of <code>task</code> containing the correct choice</p>
</td></tr>
<tr><td><code id="eval.multiple.choice_+3A_distractor.name">distractor.name</code></td>
<td>
<p>a regular expression matching columns of <code>task</code> containing the distractors. The regular expression is matched with <code>perl=TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The callback function <code>dist.fnc</code> will be invoked with character vectors containing the components of the term pairs as first and second argument,
the DSM matrix <code>M</code> as third argument, plus any additional arguments (<code>...</code>) passed to <code>eval.multiple.choice</code>.
The return value must be a numeric vector of appropriate length.  If one of the terms in a pair is not represented in the DSM,
the corresponding distance value should be set to <code>Inf</code> (or <code>-Inf</code> in the case of similarity scores).
In most cases, the default callback <code><a href="#topic+pair.distances">pair.distances</a></code> is sufficient if used with suitable parameter settings.
</p>
<p>For each task item, distances between the target word and the possible choices are computed.  Then all choices
are ranked according to their distances; in the case of a tie, the <em>higher</em> rank is assigned to both words.
A task item counts as a TP (<em>true positive</em>, i.e. a successful answer by the DSM) if the correct choice is
ranked in first place.  Note that if it is tied with another choice, both will be assigned rank 2, so the item does not count as a TP.
</p>
<p>If either the target word is missing from the DSM or none of the choices is found in the DSM, the result for this
item is set to <code>NA</code>, which counts as a FP (<em>false positive</em>) in the accuracy computation.
</p>
<p>With the default <code>dist.fnc</code> callback, additional arguments <code>method</code> and <code>p</code> can be used to select 
a distance measure (see <code><a href="#topic+dist.matrix">dist.matrix</a></code> for details).  It is pointless to specify <code>rank="fwd"</code>, as
the neighbour ranks produce exactly the same candidate ranking as the distance values.
</p>


<h3>Value</h3>

<p>The default short report (<code>details=FALSE</code>) is a data frame with a single row and the columns
<code>accuracy</code> (percentage correct), <code>TP</code> (number of correct answers), <code>FP</code> (number of wrong answers)
and <code>missing</code> (number of test items for which the distance between target and correct choice
was not found in the DSM).
</p>
<p>The detailed report (<code>details=TRUE</code>) is a data frame with one row for each task item and the following columns:
</p>
<table>
<tr><td><code>target</code></td>
<td>
<p>the target word (character)</p>
</td></tr>
<tr><td><code>correct</code></td>
<td>
<p>whether model's choice is correct (logical or <code>NA</code>)</p>
</td></tr>
<tr><td><code>best.choice</code></td>
<td>
<p>best choice according to the DSM (character)</p>
</td></tr>
<tr><td><code>best.dist</code></td>
<td>
<p>distance of best choice from target (numeric)</p>
</td></tr>
<tr><td><code>correct.choice</code></td>
<td>
<p>correct answer (numeric)</p>
</td></tr>
<tr><td><code>correct.rank</code></td>
<td>
<p>rank of correct answer among choices (integer)</p>
</td></tr>
<tr><td><code>correct.dist</code></td>
<td>
<p>distance of correct answer from target (numeric)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>References</h3>

<p>Landauer, Thomas K. and Dumais, Susan T. (1997).
A solution to Plato's problem: The latent semantic analysis theory of acquisition, induction and representation of knowledge.
<em>Psychological Review</em>, <b>104</b>(2), 211&ndash;240.
</p>


<h3>See Also</h3>

<p>Suitable gold standard data sets in this package: <b>TODO</b>
</p>
<p>Support functions: <code><a href="#topic+pair.distances">pair.distances</a></code>, <code><a href="#topic+convert.lemma">convert.lemma</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## TODO
</code></pre>

<hr>
<h2 id='eval.similarity.correlation'>
Evaluate DSM on Correlation with Similarity Ratings (wordspace)
</h2><span id='topic+eval.similarity.correlation'></span>

<h3>Description</h3>

<p>Performs evaluation by comparing the distances (or similarities) computed by a DSM with (typically human) word similarity ratings.
Well-know examples are the noun pair ratings collected by Rubenstein &amp; Goodenough (1965; <code><a href="#topic+RG65">RG65</a></code>) and Finkelstein et al. (2002;  <code><a href="#topic+WordSim353">WordSim353</a></code>).
</p>
<p>The quality of the DSM predictions is measured by Spearman rank correlation <code class="reqn">rho</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eval.similarity.correlation(task, M, dist.fnc=pair.distances,
                            details=FALSE, format=NA, taskname=NA,
                            word1.name="word1", word2.name="word2", score.name="score",
                            ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eval.similarity.correlation_+3A_task">task</code></td>
<td>
<p>a data frame containing word pairs (usually in columns <code>word1</code> and <code>word2</code>) with similarity ratings (usually in column <code>score</code>); any other columns will be ignored</p>
</td></tr>
<tr><td><code id="eval.similarity.correlation_+3A_m">M</code></td>
<td>
<p>a scored DSM matrix, passed to <code>dist.fnc</code></p>
</td></tr>
<tr><td><code id="eval.similarity.correlation_+3A_dist.fnc">dist.fnc</code></td>
<td>
<p>a callback function used to compute distances or similarities between word pairs.
It will be invoked with character vectors containing the components of the word pairs as first and second argument,
the DSM matrix <code>M</code> as third argument, plus any additional arguments (<code>...</code>) passed to <code>eval.similarity.correlation</code>.
The return value must be a numeric vector of appropriate length.  If one of the words in a pair is not represented in the DSM,
the corresponding distance value should be set to <code>Inf</code> (or <code>-Inf</code> in the case of similarities).
</p>
</td></tr>
<tr><td><code id="eval.similarity.correlation_+3A_details">details</code></td>
<td>
<p>if <code>TRUE</code>, a detailed report with information on each task item is returned (see Value below for details)</p>
</td></tr>
<tr><td><code id="eval.similarity.correlation_+3A_format">format</code></td>
<td>
<p>if the task definition specifies POS-disambiguated lemmas in CWB/Penn format, they can automatically be transformed into some other notation conventions; see <code><a href="#topic+convert.lemma">convert.lemma</a></code> for details</p>
</td></tr>
<tr><td><code id="eval.similarity.correlation_+3A_taskname">taskname</code></td>
<td>
<p>optional row label for the short report (<code>details=FALSE</code>)</p>
</td></tr>
<tr><td><code id="eval.similarity.correlation_+3A_...">...</code></td>
<td>
<p>any further arguments are passed to <code>dist.fnc</code> and can be used e.g. to select a distance measure</p>
</td></tr>
<tr><td><code id="eval.similarity.correlation_+3A_word1.name">word1.name</code></td>
<td>
<p>the name of the column of <code>task</code> containing the first word of each pair</p>
</td></tr>
<tr><td><code id="eval.similarity.correlation_+3A_word2.name">word2.name</code></td>
<td>
<p>the name of the column of <code>task</code> containing the second word of each pair</p>
</td></tr>
<tr><td><code id="eval.similarity.correlation_+3A_score.name">score.name</code></td>
<td>
<p>the name of the column of <code>task</code> containing the corresponding similarity ratings</p>
</td></tr>
</table>


<h3>Details</h3>

<p>DSM distances are computed for all word pairs and compared with similarity ratings from the gold standard.
As an evaluation criterion, Spearman rank correlation between the DSM and gold standard scores is computed.
The function also reports a confidence interval for Pearson correlation, which might require suitable transformation
to ensure a near-linear relationship in order to be meaningful.
</p>
<p><b>NB:</b> Since the correlation between similarity ratings and DSM distances will usually be negative, the evaluation
report omits minus signs on the correlation coefficients.
</p>
<p>With the default <code>dist.fnc</code>, the distance values can optionally be transformed through an arbitrary function specified in the <code>transform</code> argument (see <code><a href="#topic+pair.distances">pair.distances</a></code> for details).
Examples include <code>transform=log</code> (esp. for neighbour rank as a distance measure) 
and <code>transform=function (x) 1/(1+x)</code> (in order to transform distances into similarities).
Note that Spearman rank correlation is not affected by any monotonic transformation, so the main evaluation results
will remain unchanged.
</p>
<p>If one or both words of a pair are not found in the DSM, the distance is set to a fixed value 10% above the
maximum of all other DSM distances, or 10% below the minimum in the case of similarity values.
This is done in order to avoid numerical and visualization problems with <code>Inf</code> values;
the particular value used does not affect the rank correlation coefficient.
</p>
<p>With the default <code>dist.fnc</code> callback, additional arguments <code>method</code> and <code>p</code> can be used to select 
a distance measure (see <code><a href="#topic+dist.matrix">dist.matrix</a></code> for details); <code>rank=TRUE</code> can be specified in order to 
use neighbour rank as a measure of semantic distance.
</p>


<h3>Value</h3>

<p>The default short report (<code>details=FALSE</code>) is a data frame with a single row and the following columns:
</p>
<table>
<tr><td><code>rho</code></td>
<td>
<p>(absolute value of) Spearman rank correlation coefficient <code class="reqn">rho</code></p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>p-value indicating evidence for a significant correlation</p>
</td></tr>
<tr><td><code>missing</code></td>
<td>
<p>number of pairs not included in the DSM</p>
</td></tr>
<tr><td><code>r</code></td>
<td>
<p>(absolute value of) Pearson correlation coefficient <code class="reqn">r</code></p>
</td></tr>
<tr><td><code>r.lower</code></td>
<td>
<p>lower bound of confidence interval for Pearson correlation</p>
</td></tr>
<tr><td><code>r.upper</code></td>
<td>
<p>upper bound of confidence interval for Pearson correlation</p>
</td></tr>
</table>
<p>The detailed report (<code>details=TRUE</code>) is a copy of the original task data with two additional columns:
</p>
<table>
<tr><td><code>distance</code></td>
<td>
<p>distance calculated by the DSM for each word pair, possibly transformed (numeric)</p>
</td></tr>
<tr><td><code>missing</code></td>
<td>
<p>whether word pair is missing from the DSM (logical)</p>
</td></tr>
</table>
<p>In addition, the short report is appended to the data frame as an attribute <code>"eval.result"</code>, 
and the optional <code>taskname</code> value as attribute <code>"taskname"</code>.  The data frame is marked as an
object of class <code>eval.similarity.correlation</code>, for which suitable <code><a href="#topic+print.eval.similarity.correlation">print</a></code>
and <code><a href="#topic+plot.eval.similarity.correlation">plot</a></code> methods are defined.
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>References</h3>

<p>Finkelstein, Lev, Gabrilovich, Evgeniy, Matias, Yossi, Rivlin, Ehud, Solan, Zach, Wolfman, Gadi, and Ruppin, Eytan (2002).
Placing search in context: The concept revisited.
<em>ACM Transactions on Information Systems</em>, <b>20</b>(1), 116&ndash;131.
</p>
<p>Rubenstein, Herbert and Goodenough, John B. (1965).
Contextual correlates of synonymy.
<em>Communications of the ACM</em>, <b>8</b>(10), 627&ndash;633.
</p>


<h3>See Also</h3>

<p>Suitable gold standard data sets in this package: <code><a href="#topic+RG65">RG65</a></code>, <code><a href="#topic+WordSim353">WordSim353</a></code>
</p>
<p>Support functions: <code><a href="#topic+pair.distances">pair.distances</a></code>, <code><a href="#topic+convert.lemma">convert.lemma</a></code>
</p>
<p>Plotting and printing evaluation results: <code><a href="#topic+plot.eval.similarity.correlation">plot.eval.similarity.correlation</a></code>, <code><a href="#topic+print.eval.similarity.correlation">print.eval.similarity.correlation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
eval.similarity.correlation(RG65, DSM_Vectors)

## Not run: 
plot(eval.similarity.correlation(RG65, DSM_Vectors, details=TRUE))

## End(Not run)
</code></pre>

<hr>
<h2 id='head.dist.matrix'>
Return the Top Left Corner of a Distance Matrix (wordspace)
</h2><span id='topic+head.dist.matrix'></span>

<h3>Description</h3>

<p>Returns the first <code>n</code> rows and first <code>k</code> columns of a distance matrix returned by the <code><a href="#topic+dist.matrix">dist.matrix</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'dist.matrix'
head(x, n = 6L, k = n, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="head.dist.matrix_+3A_x">x</code></td>
<td>

<p>an distance matrix of class <code>dist.matrix</code>
</p>
</td></tr>
<tr><td><code id="head.dist.matrix_+3A_n">n</code></td>
<td>

<p>a single integer specifying the number of rows to extract
</p>
</td></tr>
<tr><td><code id="head.dist.matrix_+3A_k">k</code></td>
<td>

<p>a single integer specifying the number of columns to extract (default: same as number of rows)
</p>
</td></tr>
<tr><td><code id="head.dist.matrix_+3A_...">...</code></td>
<td>

<p>all other arguments are silently ignored
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that in contrast to other <code><a href="utils.html#topic+head">head</a></code> methods, negative values of <code>n</code> (and <code>k</code>) are not supported.  There is also currently no corresponding <code><a href="utils.html#topic+tail">tail</a></code> method.
</p>


<h3>Value</h3>

<p>A numeric matrix with <code>n</code> rows and <code>k</code> columns.
</p>
<p><b>Note:</b> this matrix is no longer marked as an object of class <code>dist.matrix</code> and thus prints nicely without attributes.
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p><code><a href="utils.html#topic+head">head</a></code> for the generic method.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dm &lt;- dist.matrix(DSM_Vectors[1:100, ])
print(head(dm, 8, 5), digits=3)

</code></pre>

<hr>
<h2 id='head.dsm'>
Return the Top Left Corner of a DSM Matrix (wordspace)
</h2><span id='topic+head.dsm'></span>

<h3>Description</h3>

<p>Returns the first <code>n</code> rows and first <code>k</code> columns of the co-occurrence matrix stored in a <code>dsm</code> object.
If a scored matrix is available, it is automatically used; otherwise the raw frequencies are shown.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'dsm'
head(x, n = 6L, k = n, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="head.dsm_+3A_x">x</code></td>
<td>

<p>an object of class <code>dsm</code>
</p>
</td></tr>
<tr><td><code id="head.dsm_+3A_n">n</code></td>
<td>

<p>a single integer specifying the number of rows to extract
</p>
</td></tr>
<tr><td><code id="head.dsm_+3A_k">k</code></td>
<td>

<p>a single integer specifying the number of columns to extract (default: same as number of rows)
</p>
</td></tr>
<tr><td><code id="head.dsm_+3A_...">...</code></td>
<td>

<p>all other arguments are silently ignored
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that in contrast to other <code><a href="utils.html#topic+head">head</a></code> methods, negative values of <code>n</code> (and <code>k</code>) are not supported.  There is also currently no corresponding <code><a href="utils.html#topic+tail">tail</a></code> method.
</p>


<h3>Value</h3>

<p>A dense or sparse co-occurrence matrix with <code>n</code> rows and <code>k</code> columns.
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p><code><a href="utils.html#topic+head">head</a></code> for the generic method.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
head(DSM_TermTerm, Inf, Inf) # show full co-occurrence matrix

head(DSM_TermTerm, 3, 4)

</code></pre>

<hr>
<h2 id='match.split'>
Find Parallel Matches for Values in Groups (wordspace)
</h2><span id='topic+match.split'></span>

<h3>Description</h3>

<p>Given a set of values and a grouped vector <code>x</code>, find parallel matches of each value in the different groups and return their positions in the original vector <code>x</code>.  If there are multiple matches of the same value in a group, only the position of the first match is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
match.split(x, f, values=NULL, groups=NULL, nomatch=NA_integer_)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="match.split_+3A_x">x</code></td>
<td>
<p>vector to be divided into groups and matched against</p>
</td></tr>
<tr><td><code id="match.split_+3A_f">f</code></td>
<td>
<p>a factor that defines the grouping (or a vector that can be converted to a factor)</p>
</td></tr>
<tr><td><code id="match.split_+3A_values">values</code></td>
<td>
<p>values to be matched in <code>x</code>.
Defaults to values that occur in all groups of <code>x</code> as determined by <code>f</code> and <code>groups</code>
</p>
</td></tr>
<tr><td><code id="match.split_+3A_groups">groups</code></td>
<td>

<p>a character vector listing the set of groups to be formed.  Defaults to the levels of <code>f</code> and should be a subset of these levels if given explicitly
</p>
</td></tr>
<tr><td><code id="match.split_+3A_nomatch">nomatch</code></td>
<td>

<p>the value to be returned in cases where no match is found (coerced to an integer)
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An integer matrix with one row for each value (in <code>values</code>) and one column for each group (in <code>groups</code>), specifying the index in <code>x</code> of the first match of a value within the respective group.  If not match is found for a given combination of value and group, <code>nomatch</code> is inserted (defaults to <code>NA</code>).
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>

<hr>
<h2 id='merge.dsm'>
Merge Rows or Columns from Different DSM Objects (wordspace)
</h2><span id='topic+merge.dsm'></span>

<h3>Description</h3>

<p><b>Warning: this function is deprecated and will be removed in a future release of <code>wordspace</code>. It may be re-introduced later with different semantics.</b>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
  ## S3 method for class 'dsm'
merge(x, y, ..., rows=TRUE, all=FALSE, term.suffix=NULL)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="merge.dsm_+3A_x">x</code>, <code id="merge.dsm_+3A_y">y</code>, <code id="merge.dsm_+3A_...">...</code></td>
<td>

<p>two or more objects of class <code>dsm</code> to be merged
</p>
</td></tr>
<tr><td><code id="merge.dsm_+3A_rows">rows</code></td>
<td>

<p>whether to merge rows (TRUE, default) or columns (FALSE) of the DSM matrices
</p>
</td></tr>
<tr><td><code id="merge.dsm_+3A_all">all</code></td>
<td>

<p>if FALSE (default), only features shared by all DSMs are included in the merged DSM (or target terms with <code>rows=FALSE</code>).  If TRUE, all features are included with missing frequency / score values replaced by zero (analogously for target terms with <code>rows=FALSE</code>).  <b>This option is not implemented yet.</b>
</p>
</td></tr>
<tr><td><code id="merge.dsm_+3A_term.suffix">term.suffix</code></td>
<td>

<p>optional character vector specifying one suffix string for each DSM, which will be appended to row (<code>rows=TRUE</code>) or column (<code>rows=FALSE</code>) labels in order to make them unique
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>if <code>term.suffix</code> is specified, row information of returned DSM object will be extended with variables <code>orig.term</code> specifying the original terms and <code>orig.part</code> specifying the original component model (identified by the corresponding entry from <code>term.suffix</code>) 
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>

<hr>
<h2 id='nearest.neighbours'>
Find Nearest Neighbours in DSM Space (wordspace)
</h2><span id='topic+nearest.neighbours'></span><span id='topic+nearest.neighbors'></span>

<h3>Description</h3>

<p>Find the nearest neighbours of a term vector in a DSM, given either as a scored cooccurrence matrix or a pre-computed distance matrix.  The target term can be selected by name (in which case the cooccurrence or distance matrix must be labelled appropriately) or specified as a vector (if the DSM is given as a matrix).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
nearest.neighbours(M, term, n = 10, M2 = NULL, byrow = TRUE,
                   drop = TRUE, skip.missing = FALSE, dist.matrix = FALSE,
                   ..., batchsize=50e6, verbose=FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nearest.neighbours_+3A_m">M</code></td>
<td>

<p>either a dense or sparse matrix representing a scored DSM (or an object of class <code>dsm</code>), or a pre-computed distance matrix returned by <code>dist.matrix</code> (as an object of class <code>dist.matrix</code>).  Note that the compact representation produced by the <code>dist</code> function (class <code>dist</code>) is not accepted.
</p>
</td></tr>
<tr><td><code id="nearest.neighbours_+3A_term">term</code></td>
<td>

<p>either a character vector specifying one or more target terms for which nearest neighbours will be found, or a matrix specifying the target vectors directly. A plain vector is interpreted as a single-row matrix.
</p>
</td></tr>
<tr><td><code id="nearest.neighbours_+3A_n">n</code></td>
<td>

<p>an integer giving the number of nearest neighbours to be returned for each target term
</p>
</td></tr>
<tr><td><code id="nearest.neighbours_+3A_m2">M2</code></td>
<td>

<p>an optional dense or sparse matrix (or object of class <code>dsm</code>). If specified, nearest neighbours are found among the rows (default) or columns (<code>byrow=FALSE</code>) of <code>M2</code>, allowing for NN search in a cross-distance setting.
</p>
</td></tr>
<tr><td><code id="nearest.neighbours_+3A_byrow">byrow</code></td>
<td>

<p>whether target terms are looked up in rows (default) or columns (<code>byrow=FALSE</code>) of <code>M</code>.  NB: Target vectors in the <code>term</code> argument are always given as row vectors, even if <code>byrow=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="nearest.neighbours_+3A_drop">drop</code></td>
<td>

<p>if <code>TRUE</code>, the return value is simplified to a vector (or distance matrix) if it contains nearest neighbours for exactly one target term (default).  Set <code>drop=FALSE</code> to ensure that <code>nearest.neighbours</code> always returns a list.
</p>
</td></tr>
<tr><td><code id="nearest.neighbours_+3A_skip.missing">skip.missing</code></td>
<td>

<p>if <code>TRUE</code>, silently ignores target terms not found in the DSM or distance matrix.  By default (<code>skip.missing=FALSE</code>) an error is raised in this case.
</p>
</td></tr>
<tr><td><code id="nearest.neighbours_+3A_dist.matrix">dist.matrix</code></td>
<td>

<p>if <code>TRUE</code>, return a full distance matrix between the target term and its nearest neighbours (instead of a vector of neighbours).  Note that a pre-computed distance matrix <code>M</code> must be symmetric in this case.
</p>
</td></tr>
<tr><td><code id="nearest.neighbours_+3A_...">...</code></td>
<td>

<p>additional arguments are passed to <code>dist.matrix</code> if <code>M</code> is a scored DSM matrix.  See the manpage of <code><a href="#topic+dist.matrix">dist.matrix</a></code> for details on available parameters and settings.
</p>
</td></tr>
<tr><td><code id="nearest.neighbours_+3A_batchsize">batchsize</code></td>
<td>
<p>if <code>term</code> is a long list of lookup terms, it will automatically be processed in batches.  The number of terms per batch is chosen in such a way that approximately <code>batchsize</code> intermediate similarity values have to be computed and stored at a time (not used if <code>M</code> is a pre-computed distance matrix).</p>
</td></tr>
<tr><td><code id="nearest.neighbours_+3A_verbose">verbose</code></td>
<td>
<p>if <code>TRUE</code>, display some progress messages indicating how data are split into batches</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In most cases, the target term itself is automatically excluded from the list of neighbours.  There are two exceptions:
</p>

<ol>
<li><p>The target term is given as a vector rather than by name.
</p>
</li>
<li><p>Nearest neighbours are determined in a cross-distance setting.  This is the case if (i) <code>M2</code> is specified or (ii) <code>M</code> is a pre-computed distance matrix and not marked to be symmetric.
</p>
</li></ol>

<p>With <code>dist.matrix=TRUE</code>, the returned distance matrix always includes the target term.
</p>
<p><code>M</code> can also be a pre-computed distance or similarity matrix from an external source, which must be marked with <code><a href="#topic+as.distmat">as.distmat</a></code>.  If <code>M</code> is a sparse similarity matrix, only non-zero cells will be considered when looking for the nearest neighbours.  Keep in mind that <code>dist.matrix=TRUE</code> is only valid if <code>M</code> is a symmetric matrix and marked as such.
</p>


<h3>Value</h3>

<p>A list with one entry for each target <code>term</code> found in <code>M</code>, giving
</p>

<ul>
<li><p><code>dist.matrix=FALSE</code> (default): the nearest neighbours as a numeric vector of distances or similarities labelled with the corresponding terms and ordered by distance
</p>
</li>
<li><p><code>dist.matrix=TRUE</code>: a full distance or similarity matrix for the target term and its nearest neighbours (as an object of class <code>dist.matrix</code>). An additional attribute <code>selected</code> contains a logical vector indicating the position of the target term in the matrix.
</p>
</li></ul>

<p>If <code>drop=TRUE</code>, a list containing only a single target term will be simplified to a plain vector or distance matrix.
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p><code><a href="#topic+dist.matrix">dist.matrix</a></code> for more information on available distance metrics and similarity measures
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
nearest.neighbours(DSM_Vectors, c("apple_N", "walk_V"), n=10)

nearest.neighbours(DSM_Vectors, "apple_N", n=10, method="maximum")

as.dist(nearest.neighbours(DSM_Vectors, "apple_N", n=10, dist.matrix=TRUE))

</code></pre>

<hr>
<h2 id='normalize.rows'>
Normalize Rows or Columns of Matrix to Unit Length (wordspace)
</h2><span id='topic+normalize.rows'></span><span id='topic+normalize.cols'></span>

<h3>Description</h3>

<p>Efficiently normalize the row or column vectors of a dense or sparse matrix to unit length.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
normalize.rows(M, method = "euclidean", p = 2, ..., 
               tol = 1e-6, inplace = FALSE)

normalize.cols(M, method = "euclidean", p = 2, ...,
               tol = 1e-6, inplace = FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalize.rows_+3A_m">M</code></td>
<td>
<p>a dense or sparse numeric matrix</p>
</td></tr>
<tr><td><code id="normalize.rows_+3A_method">method</code></td>
<td>
<p>norm to be computed, see <code><a href="#topic+rowNorms">rowNorms</a></code></p>
</td></tr>
<tr><td><code id="normalize.rows_+3A_p">p</code></td>
<td>
<p>exponent of Minkowski p-norm in the range <code class="reqn">0 &lt; p \le \infty</code>. Note that normalization is not possible for very small values of <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="normalize.rows_+3A_...">...</code></td>
<td>
<p>any further arguments are passed to <code><a href="#topic+rowNorms">rowNorms</a></code> (or <code><a href="#topic+colNorms">colNorms</a></code>)</p>
</td></tr>
<tr><td><code id="normalize.rows_+3A_tol">tol</code></td>
<td>
<p>row/column vectors with norm below <code>tol</code> are assumed to be all zeroes and cannot be normalized (see &ldquo;Details&rdquo; below)</p>
</td></tr>
<tr><td><code id="normalize.rows_+3A_inplace">inplace</code></td>
<td>
<p>if <code>TRUE</code>, modify the matrix <code>M</code> in place.  Don't ever set this argument to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions return a matrix with row (or column) vectors rescaled to a length of 1 according to the selected norm.
</p>
<p>All-zero vectors (with <code class="reqn">\|0\| = 0</code>) cannot be normalized.  In order to avoid scaling up rounding errors, rows (or columns) with <code class="reqn">\|x\| &lt; tol</code> are explicitly set to 0 (and thus not normalized). Since a suitable threshold for rounding errors depends on the scaling behaviour of the selected norm and the provenance of <code class="reqn">M</code>, it is advisable to set <code>tol</code> explicitly to an appropriate value. Pass <code>tol = 0</code> to normalize all nonzero vectors.
</p>
<p>The generalized Minkowski norm with <code class="reqn">p &lt; 1</code> is not homogeneous but can still be normalized.  This is numerically unstable for very small values of <code class="reqn">p</code>, which will be rejected with an error message.  The Hamming length (<code class="reqn">p = 0</code>) cannot be normalized at all.  See <code><a href="#topic+rowNorms">rowNorms</a></code> for more information.
</p>


<h3>Value</h3>

<p>A row-normalized (or column-normalized) matrix with the same dimensions as <code class="reqn">M</code>.
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+rowNorms">rowNorms</a></code> for details on available norms and their parameters.
</p>

<hr>
<h2 id='pair.distances'>
Semantic Distances Between Word Pairs (wordspace)
</h2><span id='topic+pair.distances'></span>

<h3>Description</h3>

<p>Compute semantic distances (or similarities) between pairs of target terms based on a scored DSM matrix <code>M</code>,
according to any of the distance measures supported by <code><a href="#topic+dist.matrix">dist.matrix</a></code>.
If one of the terms in a pair is not represented in the DSM, the distance is set to <code>Inf</code>
(or to <code>-Inf</code> in the case of a similarity measure).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
pair.distances(w1, w2, M, ..., transform = NULL, 
               rank = c("none", "fwd", "bwd", "avg"),
               avg.method = c("arithmetic", "geometric", "harmonic"),
               batchsize = 10e6, verbose = FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pair.distances_+3A_w1">w1</code></td>
<td>
<p>a character vector specifying the first term of each pair</p>
</td></tr>
<tr><td><code id="pair.distances_+3A_w2">w2</code></td>
<td>
<p>a character vector of the same length as <code>w1</code>, specifying the second term of each pair</p>
</td></tr>
<tr><td><code id="pair.distances_+3A_m">M</code></td>
<td>
<p>a sparse or dense DSM matrix, suitable for passing to <code><a href="#topic+dist.matrix">dist.matrix</a></code>, or an object of class <code>dsm</code>. Alternatively, <code>M</code> can be a pre-computed distance or similarity matrix returned by <code><a href="#topic+dist.matrix">dist.matrix</a></code> or marked as such with <code><a href="#topic+as.distmat">as.distmat</a></code>.</p>
</td></tr>
<tr><td><code id="pair.distances_+3A_...">...</code></td>
<td>
<p>further arguments are passed to <code>dist.matrix</code> and determine the distance or similarity measure to be used (see <code><a href="#topic+dist.matrix">dist.matrix</a></code> for details)</p>
</td></tr>
<tr><td><code id="pair.distances_+3A_rank">rank</code></td>
<td>
<p>whether to return the distance between the two terms (<code>"none"</code>) or the neighbour rank (see &ldquo;Details&rdquo; below)</p>
</td></tr>
<tr><td><code id="pair.distances_+3A_transform">transform</code></td>
<td>
<p>an optional transformation function applied to the distance, similarity or rank values (e.g. <code>transform=log10</code> for logarithmic ranks). This option is provided as a convenience for evaluation code that calls <code>pair.distances</code> with user-specified arguments.</p>
</td></tr>
<tr><td><code id="pair.distances_+3A_avg.method">avg.method</code></td>
<td>
<p>with <code>rank="avg"</code>, whether to compute the arithmetic, geometric or harmonic mean of forward and backward rank</p>
</td></tr>
<tr><td><code id="pair.distances_+3A_batchsize">batchsize</code></td>
<td>
<p>maximum number of similarity values to compute per batch. This parameter has an essential influence on efficiency and memory use of the algorithm and has to be tuned carefully for optimal performance.</p>
</td></tr>
<tr><td><code id="pair.distances_+3A_verbose">verbose</code></td>
<td>
<p>if <code>TRUE</code>, display some progress messages indicating how data are split into batches</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>rank</code> argument controls whether semantic distance is measured directly by geometric distance (<code>none</code>),
by forward neighbour rank (<code>fwd</code>), by backward neighbour rank (<code>bwd</code>), or by the average of forward and backward rank (<code>avg</code>).
Forward neighbour rank is the rank of <code>w2</code> among the nearest neighbours of <code>w1</code>.
Backward neighbour rank is the rank of <code>w1</code> among the nearest neighbours of <code>w2</code>.
The average can be computed as an arithmetic, geometric or harmonic mean, depending on <code>avg.method</code>.
</p>
<p>Note that a transformation function is applied <em>after</em> averaging.
In order to compute the arithmetic mean of log ranks, set <code>transform=log10</code>, <code>rank="avg"</code> and <code>avg.method="geometric"</code>.
</p>
<p>Neighbour ranks assume that each target term is its own nearest neighbour and adjust ranks to account for this (i.e. <code>w1 == w2</code> should return a rank of 0).
If <code>M</code> is a pre-computed distance matrix, the adjustment is only applied if it is also marked as symmetric (because otherwise <code>w1</code> might not appear in the list of neighbours at all).  This might lead to unexpected results once asymmetric measures are implemented in <code>dist.matrix</code>.
</p>
<p>For a sparse pre-computed similarity matrix <code>M</code>, only non-zero cells are considered as neighbours and all other ranks are set to <code>Inf</code>.  This is consistent with the behaviour of <code><a href="#topic+nearest.neighbours">nearest.neighbours</a></code>.
</p>
<p><code>pair.distances</code> is used as a default callback in several evaluation functions, which rely on the attribute <code>similarity</code> to distinguish between distance measures and similarity scores.  For this reason, transformation functions should always be <b>isotonic</b> (order-preserving) so as not to mislead the evaluation procedure.
</p>


<h3>Value</h3>

<p>If <code>rank="none"</code> (the default), a numeric vector of the same length as <code>w1</code> and <code>w2</code>
specifying the distances or similarities between the term pairs, according to the metric selected with the extra arguments (<code>...</code>).
</p>
<p>Otherwise, an integer or numeric vector of the same length as <code>w1</code> and <code>w2</code> specifying
forward, backward or average neighbour rank for the two terms.
</p>
<p>In either case, a distance or rank of <code>Inf</code> (or a similarity of <code>-Inf</code>) is returned for any term pair not represented in the DSM.
Attribute <code>similarity</code> is set to <code>TRUE</code> if the returned values are similarity scores rather than distances.
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p><code><a href="#topic+dist.matrix">dist.matrix</a></code>, <code><a href="#topic+eval.similarity.correlation">eval.similarity.correlation</a></code>, <code><a href="#topic+eval.multiple.choice">eval.multiple.choice</a></code>, <code><a href="#topic+nearest.neighbours">nearest.neighbours</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
transform(RG65, angle=pair.distances(word1, word2, DSM_Vectors))

</code></pre>

<hr>
<h2 id='plot.dist.matrix'>
Plotting Distance Matrices (wordspace)
</h2><span id='topic+plot.dist.matrix'></span>

<h3>Description</h3>

<p>Visualization of a DSM distance matrix as a neighbourhood graph based on multidimensional scaling (MDS).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'dist.matrix'
plot(x, y, labels=rownames(x), show.labels=TRUE, label.pos=3,
     selected=attr(x, "selected"), show.selected=TRUE,
     col="black", cex=1, pch=20, pt.cex=1.2, selected.cex=1.2, selected.col="red",
     show.edges=TRUE, edges.lwd=6, edges.col="#AABBFF", edges.threshold=quantile(x, 2/3),
     method=c("isomds", "sammon"), aspect=1, expand=.05, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.dist.matrix_+3A_x">x</code></td>
<td>
<p>a symmetric distance matrix of class <code>dist.matrix</code>.  NB: similarity values and asymmetric distance measures are not supported.</p>
</td></tr>
<tr><td><code id="plot.dist.matrix_+3A_y">y</code></td>
<td>
<p>unused, must not be specified</p>
</td></tr>
<tr><td><code id="plot.dist.matrix_+3A_labels">labels</code></td>
<td>
<p>a character vector of labels for the DSM vectors (defaults to rownames of <code>x</code>)</p>
</td></tr>
<tr><td><code id="plot.dist.matrix_+3A_show.labels">show.labels</code></td>
<td>
<p>if <code>TRUE</code> (default), labels are displayed if available</p>
</td></tr>
<tr><td><code id="plot.dist.matrix_+3A_label.pos">label.pos</code></td>
<td>
<p>position of labels (default: above points).  Possible values are <code>1</code> (below), <code>2</code> (left), <code>3</code> (above) and <code>4</code> (right).</p>
</td></tr>
<tr><td><code id="plot.dist.matrix_+3A_selected">selected</code></td>
<td>
<p>logical vector of selected points that will be highlighted (defaults to optional <code>selected</code> attribute of distance matrix)</p>
</td></tr>
<tr><td><code id="plot.dist.matrix_+3A_show.selected">show.selected</code></td>
<td>
<p>if <code>TRUE</code> (default), points marked by <code>selected</code> are highlighted in the plot</p>
</td></tr>
<tr><td><code id="plot.dist.matrix_+3A_col">col</code></td>
<td>
<p>colour of points and labels</p>
</td></tr>
<tr><td><code id="plot.dist.matrix_+3A_cex">cex</code></td>
<td>
<p>numeric character expansion factor for points and labels</p>
</td></tr>
<tr><td><code id="plot.dist.matrix_+3A_pch">pch</code></td>
<td>
<p>plot symbol for points</p>
</td></tr>
<tr><td><code id="plot.dist.matrix_+3A_pt.cex">pt.cex</code></td>
<td>
<p>character expansion factor for points relative to labels</p>
</td></tr>
<tr><td><code id="plot.dist.matrix_+3A_selected.cex">selected.cex</code></td>
<td>
<p>additional character expansion factor for selected points and labels</p>
</td></tr>
<tr><td><code id="plot.dist.matrix_+3A_selected.col">selected.col</code></td>
<td>
<p>colour of selected points and labels (if <code>show.selected=TRUE</code>)</p>
</td></tr>
<tr><td><code id="plot.dist.matrix_+3A_show.edges">show.edges</code></td>
<td>
<p>if <code>TRUE</code> (default), edges are drawn between points.  The line width of each edge is proportional to the distance between the corresponding points.</p>
</td></tr>
<tr><td><code id="plot.dist.matrix_+3A_edges.lwd">edges.lwd</code></td>
<td>
<p>maximal line width of edges (for <code class="reqn">d = 0</code>)</p>
</td></tr>
<tr><td><code id="plot.dist.matrix_+3A_edges.col">edges.col</code></td>
<td>
<p>colour of edges, usually a light or translucent shade</p>
</td></tr>
<tr><td><code id="plot.dist.matrix_+3A_edges.threshold">edges.threshold</code></td>
<td>
<p>maximal distance up to which edges are drawn.  The default is to display two thirds of all edges.</p>
</td></tr>
<tr><td><code id="plot.dist.matrix_+3A_method">method</code></td>
<td>
<p>whether to perform non-metric (<code>isomds</code>) or metric (<code>sammon</code>) multidimensional scaling</p>
</td></tr>
<tr><td><code id="plot.dist.matrix_+3A_aspect">aspect</code></td>
<td>
<p>aspect ratio of plot window (e.g. <code>aspect=16/10</code> for a window that is 8 inches wide and 5 inches high). Setting a correct aspect ratio ensures that the distances between points in the MDS map are correctly represented in the plot.</p>
</td></tr>
<tr><td><code id="plot.dist.matrix_+3A_expand">expand</code></td>
<td>
<p>fraction by which plotting region is extended on each side. Adjust this parameter so that points and labels are completely visible.</p>
</td></tr>
<tr><td><code id="plot.dist.matrix_+3A_...">...</code></td>
<td>
<p>all other arguments are passed to the initial plot function, which sets up the display but does not draw any graphical elements</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For multidimensional scaling (MDS), the functions <code><a href="MASS.html#topic+isoMDS">isoMDS</a></code> and <code><a href="MASS.html#topic+sammon">sammon</a></code> from the <b>MASS</b> package are used.
</p>


<h3>Value</h3>

<p>Invisibly returns a two-column matrix with MDS coordinates of all displayed points and <code>labels</code> as rownames (if available).
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p><code><a href="#topic+nearest.neighbours">nearest.neighbours</a></code>, which produces distance matrices suitable for plotting if the option <code>dist.matrix=TRUE</code> is specified
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
plot(nearest.neighbours(DSM_Vectors, "walk_V", n=20, dist.matrix=TRUE))

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.eval.similarity.correlation'>
Printing and Plotting Similarity Correlation Evaluation Results (wordspace)
</h2><span id='topic+plot.eval.similarity.correlation'></span><span id='topic+print.eval.similarity.correlation'></span>

<h3>Description</h3>

<p>Suitable printing and visualization of evaluation results from <code><a href="#topic+eval.similarity.correlation">eval.similarity.correlation</a></code>.
The <code>print</code> method displays an evaluation summary (stored in attribute <code>"eval.result"</code>) after the full data frame.
The <code>plot</code> method displays a scatterplot of gold standard ratings against DSM distances with optional
regression line (<code><a href="stats.html#topic+lowess">lowess</a></code>), a summary of evaluation results at the top, and various other formatting options.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'eval.similarity.correlation'
print(x, ...)
  
  ## S3 method for class 'eval.similarity.correlation'
plot(x, y, line = TRUE,
     categories = NULL, cat.col = NA, cat.legend = "bottomleft",
     pch = 20, cex = 1, xlim = NULL, ylim = NULL,
     xlab = "human rating", ylab = "distributional model",
     main = attr(x, "taskname"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.eval.similarity.correlation_+3A_x">x</code></td>
<td>
<p>detailed evaluation report from <code><a href="#topic+eval.similarity.correlation">eval.similarity.correlation</a></code> (with <code>details=TRUE</code>)</p>
</td></tr>
<tr><td><code id="plot.eval.similarity.correlation_+3A_y">y</code></td>
<td>
<p>unused, must not be specified</p>
</td></tr>
<tr><td><code id="plot.eval.similarity.correlation_+3A_line">line</code></td>
<td>
<p>if <code>TRUE</code>, a non-linear regression line is added to the plot in order to indicate the precise relationship between gold standard ratings and DSM distances (based on the <code><a href="stats.html#topic+lowess">lowess</a></code> smoother)</p>
</td></tr>
<tr><td><code id="plot.eval.similarity.correlation_+3A_categories">categories</code></td>
<td>
<p>a factor with one entry for each word pair in the evaluation task.
If specified, points in the scatterplot are colour-coded according to the categories of the corresponding word pairs.
Note that <code>categories</code> is evaluated within the data frame <code>x</code>, so any column of <code>x</code>
can directly be used as a variable.
</p>
</td></tr>
<tr><td><code id="plot.eval.similarity.correlation_+3A_cat.col">cat.col</code></td>
<td>
<p>a vector of colours to be used for the different categories (defaults to the standard palette built into <span class="rlang"><b>R</b></span>)</p>
</td></tr>
<tr><td><code id="plot.eval.similarity.correlation_+3A_cat.legend">cat.legend</code></td>
<td>
<p>corner of the plot in which to display the legend box for category colours</p>
</td></tr>
<tr><td><code id="plot.eval.similarity.correlation_+3A_pch">pch</code>, <code id="plot.eval.similarity.correlation_+3A_cex">cex</code></td>
<td>
<p>symbol used for plotting and its size</p>
</td></tr>
<tr><td><code id="plot.eval.similarity.correlation_+3A_xlim">xlim</code>, <code id="plot.eval.similarity.correlation_+3A_ylim">ylim</code></td>
<td>
<p>range of values shown on the x-axis and y-axis, respectively</p>
</td></tr>
<tr><td><code id="plot.eval.similarity.correlation_+3A_xlab">xlab</code>, <code id="plot.eval.similarity.correlation_+3A_ylab">ylab</code>, <code id="plot.eval.similarity.correlation_+3A_main">main</code></td>
<td>
<p>axis labels and main title of the plot</p>
</td></tr>
<tr><td><code id="plot.eval.similarity.correlation_+3A_...">...</code></td>
<td>
<p>all other arguments are passed to the scatterplot function (<code><a href="graphics.html#topic+plot.default">plot.default</a></code>) and can be used to set additional graphics parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Word pairs not found in the DSM are always shown as empty boxes in the scatterplot, regardless of the <code>pch</code> parameter.
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p><code><a href="#topic+eval.similarity.correlation">eval.similarity.correlation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
plot(eval.similarity.correlation(WordSim353, DSM_Vectors, details=TRUE))

## End(Not run)
</code></pre>

<hr>
<h2 id='print.dsm'>
Print Information About DSM Object (wordspace)
</h2><span id='topic+print.dsm'></span>

<h3>Description</h3>

<p>Prints a short summary describing a <code>dsm</code> object, including the number of rows and columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'dsm'
print(x, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.dsm_+3A_x">x</code></td>
<td>

<p>an object of class <code>dsm</code>
</p>
</td></tr>
<tr><td><code id="print.dsm_+3A_...">...</code></td>
<td>

<p>all other arguments are silently ignored
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The main purpose of this method is to keep users from accidentally trying to print out the internal data structures of a large DSM object.
</p>
<p>For compatibility with the generic method (and the documentation of <code><a href="base.html#topic+print">print</a></code>), the DSM object is returned invisibly.
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+print">print</a></code> for the generic method.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
print(dsm(DSM_HieroglyphsMatrix))

</code></pre>

<hr>
<h2 id='rbind.dsm'>
Combine DSM Objects by Rows and Columns (wordspace)
</h2><span id='topic+rbind.dsm'></span><span id='topic+cbind.dsm'></span>

<h3>Description</h3>

<p>Combine conformable DSM matrices by rows or columns.
Additional information in the DSM objects (such as marginal frequencies)
is checked for consistency and updated automatically.
</p>
<p><b>Warning: these functions are experimental and may be removed or modified in a future release of <code>wordspace</code></b>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'dsm'
rbind(..., term.suffix=NULL, deparse.level = 1)
  
  ## S3 method for class 'dsm'
cbind(..., term.suffix=NULL, deparse.level = 1)
  
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rbind.dsm_+3A_...">...</code></td>
<td>

<p>one or more objects of class <code>dsm</code>, which must have the same feature dimensions (<code>rbind</code>) or target terms (<code>cbind</code>)
</p>
</td></tr>
<tr><td><code id="rbind.dsm_+3A_term.suffix">term.suffix</code></td>
<td>

<p>optional character vector specifying one suffix string for each DSM, which will be appended to row (<code>rbind</code>) or column (<code>cbind</code>) labels in order to make them unique
</p>
</td></tr>
<tr><td><code id="rbind.dsm_+3A_deparse.level">deparse.level</code></td>
<td>

<p>ignored
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>if <code>term.suffix</code> is specified, row information of returned DSM object will be extended with variables <code>orig.term</code> specifying the original terms and <code>orig.part</code> specifying the original component model (identified by the corresponding entry from <code>term.suffix</code>) 
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>

<hr>
<h2 id='read.dsm.matrix'>
Load DSM Matrix from File (wordspace)
</h2><span id='topic+read.dsm.matrix'></span>

<h3>Description</h3>

<p>This function loads a DSM matrix from a disk file in the specified format (see section sQuote(Formats) for details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
read.dsm.matrix(file, format = c("word2vec"),
                encoding = "UTF-8", batchsize = 1e6, verbose=FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.dsm.matrix_+3A_file">file</code></td>
<td>

<p>either a character string naming a file or a <code><a href="base.html#topic+connection">connection</a></code> open for writing (in text mode)
</p>
</td></tr>
<tr><td><code id="read.dsm.matrix_+3A_format">format</code></td>
<td>

<p>input file format (see section sQuote(Formats)). The input file format cannot be guessed automatically.
</p>
</td></tr>
<tr><td><code id="read.dsm.matrix_+3A_encoding">encoding</code></td>
<td>

<p>character encoding of the input file (ignored if <code>file</code> is a connection)
</p>
</td></tr>
<tr><td><code id="read.dsm.matrix_+3A_batchsize">batchsize</code></td>
<td>

<p>for certain input formats, the matrix is read in batches of <code>batchsize</code> cells each in order to limit memory overhead
</p>
</td></tr>
<tr><td><code id="read.dsm.matrix_+3A_verbose">verbose</code></td>
<td>

<p>if <code>TRUE</code>, show progress bar when reading in batches
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In order to read text formats from a compressed file, pass a <code><a href="base.html#topic+gzfile">gzfile</a></code>, <code><a href="base.html#topic+bzfile">bzfile</a></code> or <code><a href="base.html#topic+xzfile">xzfile</a></code> connection with appropriate <code>encoding</code> in the argument <code>file</code>.  Make sure not to open the connection before passing it to <code>read.dsm.matrix</code>.
</p>


<h3>Formats</h3>

<p>Currently, the only supported file format is <code>word2vec</code>.
</p>

<dl>
<dt><code>word2vec</code></dt><dd>
<p>This widely used text format for word embeddings is only suitable for a dense matrix. Row labels must be unique and may not contain whitespace.
Values are usually rounded to a few decimal digits in order to keep file size manageable.
</p>
<p>The first line of the file lists the matrix dimensions (rows, columns) separated by a single blank.
It is followed by one text line for each matrix row, starting with the row label. The label and are cells are separated by single blanks, so row labels cannot contain whitespace.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p><code><a href="#topic+write.dsm.matrix">write.dsm.matrix</a></code>, <code><a href="#topic+read.dsm.triplet">read.dsm.triplet</a></code>, <code><a href="#topic+read.dsm.ucs">read.dsm.ucs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fn &lt;- system.file("extdata", "word2vec_hiero.txt", package="wordspace")
read.dsm.matrix(fn, format="word2vec")
</code></pre>

<hr>
<h2 id='read.dsm.triplet'>
Load DSM Data from Triplet Representation (wordspace)
</h2><span id='topic+read.dsm.triplet'></span>

<h3>Description</h3>

<p>This function loads a sparse distributional semantic model in triplet representation &ndash; (target label, feature label, score) &ndash; from a disk file or a pipe.  Such a triplet file usually represents a pre-scored DSM, but it can also be used to read raw co-occurrence frequencies.  In this case, marginals and sample size can either be derived from the co-occurrence matrix (for syntactic and term-context models) or provided in separate TAB-delimited tables (for surface and textual co-occurrence, or if frequency thresholds have been applied).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
read.dsm.triplet(filename, freq = FALSE, value.first = FALSE, tokens = FALSE,
                 rowinfo = NULL, rowinfo.header = NULL,
                 colinfo = NULL, colinfo.header = NULL,
                 N = NA, span.size = 1,
                 sep = "\t", quote = "", nmax = -1, sort = FALSE, 
                 encoding = getOption("encoding"), verbose = FALSE) 

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.dsm.triplet_+3A_filename">filename</code></td>
<td>

<p>the name of a file containing the triplet data (see &lsquo;File Format&rsquo; below for details), which may be compressed (&lsquo;<span class="file">.gz</span>&rsquo;, &lsquo;<span class="file">.bz2</span>&rsquo;, &lsquo;<span class="file">.xz</span>&rsquo;).  If <code>filename</code> ends in <code>|</code>, it is opened as a Unix pipe for reading.
</p>
</td></tr>
<tr><td><code id="read.dsm.triplet_+3A_freq">freq</code></td>
<td>

<p>whether values are raw co-occurrence frequencies (<code>TRUE</code>) or pre-computed scores (<code>FALSE</code>)
</p>
</td></tr>
<tr><td><code id="read.dsm.triplet_+3A_value.first">value.first</code></td>
<td>

<p>if <code>TRUE</code>, triplets are given as (score, row label, column label) instead of the default (row label, column label, score)
</p>
</td></tr>
<tr><td><code id="read.dsm.triplet_+3A_tokens">tokens</code></td>
<td>

<p>if <code>TRUE</code>, the input file contains pair <em>tokens</em>, i.e. row and column labels without score/frequency values.
Co-occurrence frequencies will automatically be calculated, but this input format should only be used for small samples up to a few millon tokens.
</p>
</td></tr>
<tr><td><code id="read.dsm.triplet_+3A_rowinfo">rowinfo</code></td>
<td>

<p>the name of an optional TAB-delimited table file with additional information about the target terms (see &lsquo;File Format&rsquo; below for details), which may be compressed (&lsquo;<span class="file">.gz</span>&rsquo;, &lsquo;<span class="file">.bz2</span>&rsquo;, &lsquo;<span class="file">.xz</span>&rsquo;).
</p>
</td></tr>
<tr><td><code id="read.dsm.triplet_+3A_rowinfo.header">rowinfo.header</code></td>
<td>

<p>if the <code>rowinfo</code> file does not start with a header row, specify its column names as a character vector here
</p>
</td></tr>
<tr><td><code id="read.dsm.triplet_+3A_colinfo">colinfo</code></td>
<td>

<p>the name of an optional TAB-delimited table file with additional information about the feature terms or contexts (see &lsquo;File Format&rsquo; below for details), which may be compressed (&lsquo;<span class="file">.gz</span>&rsquo;, &lsquo;<span class="file">.bz2</span>&rsquo;, &lsquo;<span class="file">.xz</span>&rsquo;).
</p>
</td></tr>
<tr><td><code id="read.dsm.triplet_+3A_colinfo.header">colinfo.header</code></td>
<td>

<p>if the <code>colinfo</code> file does not start with a header row, specify its column names as a character vector here
</p>
</td></tr>
<tr><td><code id="read.dsm.triplet_+3A_n">N</code></td>
<td>

<p>sample size to assume for the distributional model (see &lsquo;Details&rsquo; below)
</p>
</td></tr>
<tr><td><code id="read.dsm.triplet_+3A_span.size">span.size</code></td>
<td>

<p>if marginal frequencies are provided externally for surface co-occurrence, they need to be adjusted for span size.
If this hasn't been taken into account in data extraction, it can be approximated by specifying the total number of tokens in a span here (see &lsquo;Details&rsquo; below).
</p>
</td></tr>
<tr><td><code id="read.dsm.triplet_+3A_sep">sep</code>, <code id="read.dsm.triplet_+3A_quote">quote</code></td>
<td>

<p>specify field separator and the types of quotes used by the disk file (see the <code><a href="base.html#topic+scan">scan</a></code> documentation for details).  By default, a TAB-delimited file without quotes is assumed.
</p>
</td></tr>
<tr><td><code id="read.dsm.triplet_+3A_nmax">nmax</code></td>
<td>

<p>if the number of entries (= text lines) in the triplet file is known, it can be specified here in order to make loading faster and more memory-efficient.  Caution: If <code>nmax</code> is smaller than the number of lines in the disk file, the extra lines will silently be discarded.
</p>
</td></tr>
<tr><td><code id="read.dsm.triplet_+3A_sort">sort</code></td>
<td>

<p>if <code>TRUE</code>, the rows and columns of the co-occurrence matrix will be sorted alphabetically according to their labels (i.e. the target and feature terms); otherwise they are listed as encountered in the triplet representation
</p>
</td></tr>
<tr><td><code id="read.dsm.triplet_+3A_encoding">encoding</code></td>
<td>

<p>character encoding of the input files, which will automatically be converted to <span class="rlang"><b>R</b></span>'s internal representation if possible.  See &lsquo;Encoding&rsquo; in <code><a href="base.html#topic+file">file</a></code> for details.
</p>
</td></tr>
<tr><td><code id="read.dsm.triplet_+3A_verbose">verbose</code></td>
<td>

<p>if <code>TRUE</code>, a few progress and information messages are shown
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>read.dsm.triplet</code> can be used to read triplet representations of three different types of DSM.
</p>


<h4>1. A pre-scored DSM matrix</h4>

<p>If <code>freq=FALSE</code> and <code>tokens=FALSE</code>, the triplet file is assumed to contain pre-scored entries of the DSM matrix.
Marginal frequencies are not required for such a model, but additional information about targets and features can be provided in separate <code>rowinfo=</code> and <code>colinfo=</code> files.
</p>



<h4>2. Raw co-occurrence frequencies (syntactic or term-context)</h4>

<p>If the triplet file contains syntactic co-occurrence frequencies or term-document frequency counts, specify <code>freq=TRUE</code>. For small data sets, frequencies can also be aggregated directly in <span class="rlang"><b>R</b></span> from co-occurrence tokens; specify <code>tokens=TRUE</code>.
</p>
<p>Unless high frequency thresholds or other selective filters have been applied to the input data, the marginal frequencies of targets and features as well as the sample size can automatically be derived from the co-occurrence matrix.  <em>Do not specify <code>rowinfo=</code> or <code>colinfo=</code> in this case!</em>
</p>
<p>Evert (2008) explains the differences between syntactic, textual and surface co-occurrence.
</p>



<h4>3. Raw co-occurrence frequencies with explicit marginals</h4>

<p>For surface and textual co-occurrence data, the correct marginal frequencies cannot be derived automatically and have to be provided in auxiliary table files specified with <code>rowinfo=</code> and <code>colinfo</code>.  These files must contain a column <code>f</code> with the marginal frequency data.  In addition, the total sample size (which cannot be derived from the marginals) has to be passed in the argument <code>N=</code>.  Of course, it is still necessary to specify <code>freq=TRUE</code> (or <code>token=TRUE</code>) in order to indicate that the input data aren't pre-computed scores.
</p>
<p>The computation of consistent marginal frequencies is particulary tricky for surface co-occurrence (Evert 2008, p. 1233f) and specialized software should be used for this purpose.  As an approximation, simple corpus frequencies of target and feature terms can be corrected by a factor corresponding to the total size of the collocational span (e.g. <code>span.size=8</code> for a symmetric L4/R4 span, cf. Evert 2008, p. 1225).  The <code>read.dsm.triplet</code> function applies this correction to the row marginals.
</p>
<p>Explicit marginals should also be provided if syntactic co-occurrence data or text-context frequencies have been filtered, either individually with a frequency threshold or by selecting a subset of the targets and features.  See the examples below for an illustration.
</p>



<h3>Value</h3>

<p>An object of class <code><a href="#topic+dsm">dsm</a></code> containing a sparse DSM.
</p>
<p>For a model of type 1 (pre-scored) it will include the score matrix <code>$S</code> but no co-occurrence frequency data. Such a DSM object cannot be passed to <code><a href="#topic+dsm.score">dsm.score</a></code>, except with <code>score="reweight"</code>.  For models of type 2 and 3 it will include the matrix of raw co-occurrence frequencies <code>$M</code>, but no score matrix.
</p>


<h3>File Format</h3>



<h4>Triplet files</h4>

<p>The triplet file must be a plain-text table with two or three TAB-delimited columns and no header.  It may be compressed in <code>.gz</code>, <code>.bz2</code> or <code>.xz</code> format.
</p>
<p>For <code>tokens=TRUE</code>, each line represents a single pair token with columns
</p>

<ol>
<li><p> target term
</p>
</li>
<li><p> feature term / context
</p>
</li></ol>

<p>For <code>tokens=FALSE</code>, each line represents a pair type (i.e. a unique cell of the co-occurrence matrix) with columns:
</p>

<ol>
<li><p> target term
</p>
</li>
<li><p> feature term / context
</p>
</li>
<li><p> score (<code>freq=FALSE</code>) <em>or</em> co-occurrence frequency (<code>freq=TRUE</code>)
</p>
</li></ol>

<p>If <code>value.first=TRUE</code>, the score entry is expected in the first column:
</p>

<ol>
<li><p> score <em>or</em> co-occurrence frequency
</p>
</li>
<li><p> target term
</p>
</li>
<li><p> feature term / context
</p>
</li></ol>

<p>Note that the triplet file may contain multiple entries for the same cell, whose values will automatically be added up.
This might not be very sensible for pre-computed scores.
</p>



<h4>Row and column information</h4>

<p>Additional information about target terms (matrix rows) and feature terms / contexts (matrix columns) can be provided in additional TAB-delimited text tables, optionally compressed in <code>.gz</code>, <code>.bz2</code> or <code>.xz</code> format.
</p>
<p>Such tables can have an arbitrary number of columns whose data types are inferred from the first few rows of the table.
Tables should start with a header row specifying the column labels; otherwise they must be passed in the <code>rowinfo.header</code> and <code>colinfo.header</code> arguments.
</p>
<p>Every table must contain a column <code>term</code> listing the target terms or feature terms / contexts.  Their ordering need not be the same as in the main co-occurrence matrix, and redundant entries will silently be dropped.
</p>
<p>If <code>freq=TRUE</code> or <code>tokens=TRUE</code>, the tables must also contain marginal frequencies in a column <code>f</code>.  Nonzero counts for rows and columns of the matrix are automatically added unless a column <code>nnzero</code> is already present.
</p>



<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>References</h3>

<p>Evert, Stefan (2008). Corpora and collocations.
In A. Lüdeling and M. Kytö (eds.), <em>Corpus Linguistics. An International Handbook</em>, chapter 58, pages 1212&ndash;1248. Mouton de Gruyter, Berlin, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dsm">dsm</a></code>, <code><a href="#topic+read.dsm.ucs">read.dsm.ucs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## this helper function displays the cooccurrence matrix together with marginals
with.marginals &lt;- function (x) {
  y &lt;- x$M
  rownames(y) &lt;- with(x$rows, sprintf("%-8s | %6d", term, f))
  colnames(y) &lt;- with(x$cols, sprintf("  %s | %d", term, f))
  y
}

## we will read this term-context DSM from a triplet file included in the package
with.marginals(DSM_TermContext)

## the triplet file with term-document frequencies
triplet.file &lt;- system.file("extdata", "term_context_triplets.gz", package="wordspace")
cat(readLines(triplet.file), sep="\n") # file format

## marginals incorrect because matrix covers only subset of targets &amp; features
TC1 &lt;- read.dsm.triplet(triplet.file, freq=TRUE)
with.marginals(TC1) # marginal frequencies far too small

## TAB-delimited file with marginal frequencies and other information
marg.file &lt;- system.file("extdata", "term_context_marginals.txt.gz", package="wordspace")
cat(readLines(marg.file), sep="\n") # notice the header row with "term" and "f"

## single table with marginals for rows and columns, but has to be specified twice
TC2 &lt;- read.dsm.triplet(triplet.file, freq=TRUE, 
                        rowinfo=marg.file, colinfo=marg.file, N=108771103)
with.marginals(TC2) # correct marginal frequencies

## marginals table without header: specify column lables separately
no.hdr &lt;- system.file("extdata", "term_context_marginals_noheader.txt", 
                      package="wordspace")
hdr.names &lt;- c("term", "f", "df", "type")
TC3 &lt;- read.dsm.triplet(triplet.file, freq=TRUE, 
                        rowinfo=no.hdr, rowinfo.header=hdr.names,
                        colinfo=no.hdr, colinfo.header=hdr.names, N=108771103)
all.equal(TC2, TC3, check.attributes=FALSE) # same result
</code></pre>

<hr>
<h2 id='read.dsm.ucs'>
Load Raw DSM Data from Disk Files in UCS Export Format (wordspace)
</h2><span id='topic+read.dsm.ucs'></span>

<h3>Description</h3>

<p>This function loads raw DSM data &ndash; a cooccurrence frequency matrix and tables of marginal frequencies &ndash; in <b>UCS</b> export format. The data are read from a directory containing several text files with predefined names, which can optionally be compressed (see &lsquo;File Format&rsquo; below for details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
read.dsm.ucs(filename, encoding = getOption("encoding"), verbose = FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.dsm.ucs_+3A_filename">filename</code></td>
<td>

<p>the name of a directory containing files with the raw DSM data.
</p>
</td></tr>
<tr><td><code id="read.dsm.ucs_+3A_encoding">encoding</code></td>
<td>

<p>character encoding of the input files, which will automatically be converted to R's internal representation if possible.  See &lsquo;Encoding&rsquo; in <code><a href="base.html#topic+file">file</a></code> for details.
</p>
</td></tr>
<tr><td><code id="read.dsm.ucs_+3A_verbose">verbose</code></td>
<td>

<p>if <code>TRUE</code>, a few progress and information messages are shown
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+dsm">dsm</a></code> containing a dense or sparse DSM.
</p>
<p>Note that the information tables for target terms (field <code>rows</code>) and feature terms (field <code>cols</code>) include the correct marginal frequencies from the UCS export files.  Nonzero counts for rows are and columns are added automatically unless they are already present in the disk files.  Additional fields from the information tables as well as all global variables are preserved with their original names.
</p>


<h3>File Format</h3>

<p>The UCS export format is a directory containing the following files with the specified names:
</p>

<ul>
<li> <p>&lsquo;<span class="file">M</span>&rsquo; <strong>or</strong> &lsquo;<span class="file">M.mtx</span>&rsquo;
</p>
<p>cooccurrence matrix (dense, plain text) or sparse matrix (MatrixMarket format)
</p>
</li>
<li> <p>&lsquo;<span class="file">rows.tbl</span>&rsquo;
</p>
<p>row information (labels <code>term</code>, marginal frequencies <code>f</code>)
</p>
</li>
<li> <p>&lsquo;<span class="file">cols.tbl</span>&rsquo;
</p>
<p>column information (labels <code>term</code>, marginal frequencies <code>f</code>)
</p>
</li>
<li> <p>&lsquo;<span class="file">globals.tbl</span>&rsquo;
</p>
<p>table with single row containing global variables; must include variable <code>N</code> specifying sample size
</p>
</li></ul>

<p>Each individual file may be compressed with an additional filename extension <code>.gz</code>, <code>.bz2</code> or <code>.xz</code>; <code>read.dsm.ucs</code> automatically decompresses such files when loading them.
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>References</h3>

<p>The UCS toolkit is a software package for collecting and manipulating co-occurrence data available from <a href="http://www.collocations.de/software.html">http://www.collocations.de/software.html</a>.
</p>
<p>UCS relies on compressed text files as its main storage format.  They can be exported as a DSM with <code>ucs-tool export-dsm-matrix</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dsm">dsm</a></code>, <code><a href="#topic+read.dsm.triplet">read.dsm.triplet</a></code>
</p>

<hr>
<h2 id='RG65'>
Similarity Ratings for 65 Noun Pairs (wordspace)
</h2><span id='topic+RG65'></span>

<h3>Description</h3>

<p>A database of human similarity ratings for 65 English noun pairs,
collected by Rubenstein &amp; Goodenough (1965).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
RG65

</code></pre>


<h3>Format</h3>

<p>A data frame with 65 rows and the following 3 columns:
</p>

<dl>
<dt><code>word1</code></dt><dd><p>first noun (character)</p>
</dd>
<dt><code>word2</code></dt><dd><p>second noun (character)</p>
</dd>
<dt><code>score</code></dt><dd><p>average similarity rating by human judges on scale from 0 to 4 (numeric)</p>
</dd>
</dl>

<p>The nouns are given as disambiguated lemmas in the form <code>&lt;headword&gt;_N</code>.
</p>


<h3>Details</h3>

<p>The word pairs are sorted by increasing similarity score, as in the original paper.
</p>


<h3>Source</h3>

<p>Rubenstein, Herbert and Goodenough, John B. (1965).
Contextual correlates of synonymy.
<em>Communications of the ACM</em>, <b>8</b>(10), 627&ndash;633.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
head(RG65, 10) # least similar pairs
tail(RG65, 10) # most similar pairs

</code></pre>

<hr>
<h2 id='rowNorms'>
Compute Norms of Row and Column Vectors of a Matrix (wordspace)
</h2><span id='topic+rowNorms'></span><span id='topic+colNorms'></span>

<h3>Description</h3>

<p>Efficiently compute the norms of all row or column vectors of a dense or sparse matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
rowNorms(M, method = "euclidean", p = 2)

colNorms(M, method = "euclidean", p = 2)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rowNorms_+3A_m">M</code></td>
<td>
<p>a dense or sparse numeric matrix</p>
</td></tr>
<tr><td><code id="rowNorms_+3A_method">method</code></td>
<td>
<p>norm to be computed (see &ldquo;Norms&rdquo; below for details)</p>
</td></tr>
<tr><td><code id="rowNorms_+3A_p">p</code></td>
<td>
<p>exponent of the <code>minkowski</code> p-norm, a numeric value in the range <code class="reqn">1 \le p \le \infty</code>.
</p>
<p>Values <code class="reqn">0 \le p &lt; 1</code> are also permitted as an extension but do not correspond to a proper mathematical norm (see details below).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing one norm value for each row or column of <code>M</code>.
</p>


<h3>Norms</h3>

<p>Given a row or column vector <code class="reqn">x</code>, the following length measures can be computed:
</p>

<dl>
<dt><code>euclidean</code></dt><dd><p>The <b>Euclidean</b> norm given by </p>
<p style="text-align: center;"><code class="reqn">
        \|x\|_2 = \sqrt{ \sum_i x_i^2 }</code>
</p>

</dd>
<dt><code>maximum</code></dt><dd><p>The <b>maximum</b> norm given by </p>
<p style="text-align: center;"><code class="reqn">
        \|x\|_{\infty} = \max_i |x_i| </code>
</p>

</dd>
<dt><code>manhattan</code></dt><dd><p>The <b>Manhattan</b> norm given by </p>
<p style="text-align: center;"><code class="reqn">
        \|x\|_1 = \sum_i |x_i| </code>
</p>

</dd>
<dt><code>minkowski</code></dt><dd><p>The <b>Minkowski</b> (or <code class="reqn">L_p</code>) norm given by </p>
<p style="text-align: center;"><code class="reqn">
        \|x\|_p = \left( \sum_i |x_i|^p \right)^{1/p} </code>
</p>

<p>for <code class="reqn">p \ge 1</code>.  The Euclidean (<code class="reqn">p = 2</code>) and Manhattan (<code class="reqn">p = 1</code>) norms are special cases, and the maximum norm corresponds to the limit for <code class="reqn">p \to \infty</code>.
</p>
<p>As an extension, values in the range <code class="reqn">0 \le p &lt; 1</code> are also allowed and compute the length measure </p>
<p style="text-align: center;"><code class="reqn">
        \|x\|_p = \sum_i |x_i|^p </code>
</p>

<p>For <code class="reqn">0 &lt; p &lt; 1</code> this formula defines a <code class="reqn">p</code>-norm, which has the property <code class="reqn">\|r\cdot x\| = |r|^p \cdot \|x\|</code> for any scalar factor <code class="reqn">r</code> instead of being homogeneous. For <code class="reqn">p = 0</code>, it computes the Hamming length, i.e. the number of nonzero elements in the vector <code class="reqn">x</code>.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p><code><a href="#topic+dist.matrix">dist.matrix</a></code>, <code><a href="#topic+normalize.rows">normalize.rows</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
rowNorms(DSM_TermContextMatrix, "manhattan")

# fast and memory-friendly nonzero counts with "Hamming length"
rowNorms(DSM_TermContextMatrix, "minkowski", p=0)
colNorms(DSM_TermContextMatrix, "minkowski", p=0)
sum(colNorms(DSM_TermContextMatrix, "minkowski", p=0)) # = nnzero(DSM_TermContextMatrix)
</code></pre>

<hr>
<h2 id='rsvd'>
Randomized Singular Value Decomposition (wordspace)
</h2><span id='topic+rsvd'></span>

<h3>Description</h3>

<p>An implementation of the randomized truncated SVD algorithm of Halko, Martinsson &amp; Tropp (2009).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
rsvd(M, n, q = 2, oversampling = 2, transpose = FALSE, verbose = FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rsvd_+3A_m">M</code></td>
<td>

<p>a dense or sparse numeric matrix
</p>
</td></tr>
<tr><td><code id="rsvd_+3A_n">n</code></td>
<td>

<p>an integer specifying the desired number of singular components. This argument must be specified and must satisfy <code>n &lt;= min(nrow(M), ncol(M))</code>.
</p>
</td></tr>
<tr><td><code id="rsvd_+3A_q">q</code></td>
<td>

<p>number of power iterations (Halko <em>et al.</em> recommend <code>q=1</code> or <code>q=2</code>)
</p>
</td></tr>
<tr><td><code id="rsvd_+3A_oversampling">oversampling</code></td>
<td>

<p>oversampling factor. The rSVD algorithm computes an approximate SVD factorization of rank <code>n * oversampling</code>, which is then truncated to the first <code>n</code> components.
</p>
</td></tr>
<tr><td><code id="rsvd_+3A_transpose">transpose</code></td>
<td>

<p>if <code>TRUE</code>, apply the rSVD algorithm to the transpose <code>t(M)</code>, which may be more efficient depending on the dimensions of <code>M</code>
</p>
</td></tr>
<tr><td><code id="rsvd_+3A_verbose">verbose</code></td>
<td>

<p>whether to display progress messages during execution
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This implementation of randomized truncated SVD is based on the randomized PCA algorithm (Halko <em>et al.</em> 2009, p. 9).  The discussion in Sec. 4 and 5 of the paper shows that the same algorithm applies to the case where the columns of A are not centered (Algorithm 4.3 + Algorithm 5.1).
</p>


<h3>Value</h3>

<p>A list with components
</p>
<table>
<tr><td><code>u</code></td>
<td>
<p>a matrix whose columns contain the first <code>n</code> left singular vectors of <code>M</code></p>
</td></tr>
<tr><td><code>v</code></td>
<td>
<p>a matrix whose columns contain the first <code>n</code> right singular vectors of <code>M</code></p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>a vector containing the first <code>n</code> singular values of <code>M</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>References</h3>

<p>Halko, N., Martinsson, P. G., and Tropp, J. A. (2009).
Finding structure with randomness: Stochastic algorithms for constructing approximate matrix decompositions. Technical Report 2009-05, ACM, California Institute of Technology.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+svd">svd</a></code>, <code><a href="#topic+dsm.projection">dsm.projection</a></code>, <code><a href="sparsesvd.html#topic+sparsesvd">sparsesvd</a></code>
</p>

<hr>
<h2 id='scaleMargins'>
Scale Rows and/or Columns of a Matrix (wordspace)
</h2><span id='topic+scaleMargins'></span>

<h3>Description</h3>

<p>This function provides a fast and memory-efficient way to scale the rows and/or columns
of a dense or sparse matrix.  Each row is multiplied with the corresponding element of
the vector <code>rows</code>, each column with the corresponding element of the vector <code>cols</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
scaleMargins(M, rows=NULL, cols=NULL, duplicate=TRUE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scaleMargins_+3A_m">M</code></td>
<td>
<p>a dense or sparse matrix in canonical format</p>
</td></tr>
<tr><td><code id="scaleMargins_+3A_rows">rows</code></td>
<td>
<p>a numeric vector with length equal to the number of rows of M, or a single number.
If missing or <code>NULL</code>, the rows of M are not rescaled.
</p>
</td></tr>
<tr><td><code id="scaleMargins_+3A_cols">cols</code></td>
<td>
<p>a numeric vector with length equal to the number of columns of M, or a single number.
If missing or <code>NULL</code>, the columns of M are not rescaled.
</p>
</td></tr>
<tr><td><code id="scaleMargins_+3A_duplicate">duplicate</code></td>
<td>
<p>if <code>FALSE</code>, modify the matrix <code>M</code> in place.  Don't ever set this argument to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>M</code> is not in canonical format (dense numeric matrix or sparse matrix of class <code>dgCMatrix</code>),
it will automatically be converted.  In this case, the precise behaviour of <code>duplicate=FALSE</code> is undefined.
</p>
<p><code>duplicate=FALSE</code> is intended for internal use only.  
</p>


<h3>Value</h3>

<p>The rescaled dense or sparse matrix.
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p><code><a href="#topic+dsm.is.canonical">dsm.is.canonical</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
M &lt;- matrix(1, 5, 3)
scaleMargins(M, rows=1:5, cols=c(1, 10, 100))

</code></pre>

<hr>
<h2 id='SemCorWSD'>
SemCor Word Sense Disambiguation Task (wordspace)
</h2><span id='topic+SemCorWSD'></span>

<h3>Description</h3>

<p>A collection of sentences containing ambiguous words manually labelled with WordNet senses.
The data were obtained from the SemCor corpus version 3.0.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
SemCorWSD

</code></pre>


<h3>Format</h3>

<p>A data frame with 647 rows and the following 8 columns (all of type character):
</p>

<dl>
<dt><code>id</code></dt><dd><p>Unique item ID</p>
</dd>
<dt><code>target</code></dt><dd><p>The target word (lemmatized)</p>
</dd>
<dt><code>pos</code></dt><dd><p>Word class of the target word (<code>n</code>, <code>v</code> or <code>a</code>)</p>
</dd>
<dt><code>sense</code></dt><dd><p>Sense of the target word in this sentence (given as a WordNet lemma)</p>
</dd>
<dt><code>gloss</code></dt><dd><p>WordNet definition of this sense</p>
</dd>
<dt><code>sentence</code></dt><dd><p>The sentence containing the ambiguous word</p>
</dd>
<dt><code>hw</code></dt><dd><p>Lemmatized form of the sentence (&ldquo;headwords&rdquo;); punctuation marks are excluded and all remaining words are case-folded</p>
</dd>
<dt><code>lemma</code></dt><dd><p>Lemmatized and POS-disambiguated form in CWB/Penn format, e.g. <code>move_N</code> for the headword <em>move</em> used as a noun</p>
</dd>
</dl>



<h3>Details</h3>

<p>Target words and senses had to meet the following criteria in order to be included in the data set:
</p>

<ul>
<li><p>sense occurs <code class="reqn">f \ge 5</code> times in SemCor 3.0
</p>
</li>
<li><p>sense accounts for at least 10% of all occurrences of the target
</p>
</li>
<li><p>at least two senses of target remain after previous two filters
</p>
</li></ul>

<p><code>SemCorWSD</code> contains sentence contexts for the following target words:
</p>

<ul>
<li><p>ambiguous nouns from Schütze (1998): <em>interest</em>, <em>plant</em>, <em>space</em>, <em>vessel</em>
</p>
</li>
<li><p>misc. ambiguous nouns: <em>bank</em>
</p>
</li>
<li><p>misc. ambiguous verbs: <em>find</em>, <em>grasp</em>, <em>open</em>, <em>run</em>
</p>
</li></ul>



<h3>Source</h3>

<p><b>TODO</b> (SemCor reference, NLTK extraction)
</p>


<h3>References</h3>

<p>Schütze, Hinrich (1998). Automatic word sense discrimination. <em>Computational Linguistics</em>, <b>24</b>(1), 97&ndash;123.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+context.vectors">context.vectors</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
with(SemCorWSD, table(sense, target))

# all word senses with brief definitions ("glosses")
with(SemCorWSD, sort(unique(paste0(target, " ", sense, ": ", gloss))))

</code></pre>

<hr>
<h2 id='signcount'>
Efficiently Count Positive, Negative and Zero Values (wordspace)
</h2><span id='topic+signcount'></span>

<h3>Description</h3>

<p>This function counts the number of positive, negative and zero elements in a numeric vector or matrix,
including some types of dense and sparse representations in the <code><a href="Matrix.html#topic+Matrix">Matrix</a></code> package.
</p>
<p>It can be used to test for non-negativity and compute nonzero counts efficiently, without any memory overhead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
signcount(x, what = c("counts", "nonneg", "nnzero"))

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="signcount_+3A_x">x</code></td>
<td>

<p>a numeric vector or array, or a numeric <code>Matrix</code> (supported formats are <code><a href="Matrix.html#topic+dgeMatrix-class">dgeMatrix</a></code>,  <code><a href="Matrix.html#topic+dgCMatrix-class">dgCMatrix</a></code> and  <code><a href="Matrix.html#topic+dgRMatrix-class">dgRMatrix</a></code>)
</p>
</td></tr>
<tr><td><code id="signcount_+3A_what">what</code></td>
<td>

<p>whether to return the counts of positive, negative and zero elements (<code>counts</code>), the number of nonzero elements (<code>nnzero</code>), or to test for non-negativity (<code>nonneg</code>); see &lsquo;Value&rsquo; below
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>x</code> must not contain any undefined values; <code>signcount</code> does not check whether this is actually the case.
</p>


<h3>Value</h3>


<dl>
<dt><code>what="counts"</code></dt><dd>
<p>A labelled numeric vector of length 3 with the counts of positive (<code>pos</code>), zero (<code>zero</code>) and negative (<code>neg</code>) values.
</p>
</dd> 
<dt><code>what="nonneg"</code></dt><dd>
<p>A single logical value: <code>TRUE</code> if <code>x</code> is non-negative, <code>FALSE</code> otherwise.
</p>
</dd>
<dt><code>what="nonzero"</code></dt><dd>
<p>A single numeric value, the total number of nonzero elements in <code>x</code>.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>Examples</h3>

<pre><code class='language-R'>signcount(DSM_TermTermMatrix)     # dense matrix
signcount(DSM_TermContextMatrix)  # sparse dgCMatrix
signcount(DSM_TermContextMatrix, "nonneg") # confirm that it is non-negative
</code></pre>

<hr>
<h2 id='subset.dsm'>
Subsetting Distributional Semantic Models (wordspace)
</h2><span id='topic+subset.dsm'></span>

<h3>Description</h3>

<p>Filter the rows and/or columns of a DSM object according to user-specified conditions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'dsm'
subset(x, subset, select, recursive = FALSE, drop.zeroes = FALSE,
       matrix.only = FALSE, envir = parent.frame(), run.gc = FALSE, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subset.dsm_+3A_x">x</code></td>
<td>

<p>an object of class <code>dsm</code>
</p>
</td></tr>
<tr><td><code id="subset.dsm_+3A_subset">subset</code></td>
<td>

<p>Boolean expression or index vector selecting a subset of the rows; the expression can use variables <code>term</code> and <code>f</code> to access target terms and their marginal frequencies, <code>nnzero</code> for the number of nonzero elements in each row, further optional variables from the row information table, as well as global variables such as the sample size <code>N</code>
</p>
</td></tr>
<tr><td><code id="subset.dsm_+3A_select">select</code></td>
<td>

<p>Boolean expression or index vector selecting a subset of the columns; the expression can use variables <code>term</code> and <code>f</code> to access feature terms and their marginal frequencies, <code>nnzero</code> for the number of nonzero elements in each column, further optional variables from the column information table, as well as global variables such as the sample size <code>N</code>
</p>
</td></tr>
<tr><td><code id="subset.dsm_+3A_recursive">recursive</code></td>
<td>
<p>if <code>TRUE</code> and both <code>subset</code> and <code>select</code> conditions are specified, the <code>subset</code> is applied repeatedly until the DSM no longer changes.
This is typically needed if conditions on nonzero counts or row/column norms are specified, which may be affected by the subsetting procedure.
</p>
</td></tr>
<tr><td><code id="subset.dsm_+3A_drop.zeroes">drop.zeroes</code></td>
<td>

<p>if <code>TRUE</code>, all rows and columns without any nonzero entries after subsetting are removed from the model
(nonzero counts are based on the score matrix <code class="reqn">S</code> if available, raw cooccurrence frequencies <code class="reqn">M</code> otherwise)
</p>
</td></tr>
<tr><td><code id="subset.dsm_+3A_matrix.only">matrix.only</code></td>
<td>

<p>if <code>TRUE</code>, return only the selected subset of the score matrix <code class="reqn">S</code> (if available) or frequency matrix <code class="reqn">M</code>, not a full DSM object.  This may conserve a substantial amount of memory when processing very large DSMs.
</p>
</td></tr>
<tr><td><code id="subset.dsm_+3A_envir">envir</code></td>
<td>

<p>environment in which the <code>subset</code> and <code>select</code> conditions are evaluated.  Defaults to the context of the function call, so all variables visible there can be used in the expressions.
</p>
</td></tr>
<tr><td><code id="subset.dsm_+3A_run.gc">run.gc</code></td>
<td>
<p>whether to run the garbage collector after each iteration of a recursive subset (<code>recursive=TRUE</code>) in order to keep memory overhead as low as possible. This option should only be specified if memory is very tight, since garbage collector runs can be expensive (e.g. when there are many distinct strings in the workspace).</p>
</td></tr>
<tr><td><code id="subset.dsm_+3A_...">...</code></td>
<td>

<p>any further arguments are silently ignored
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>dsm</code> containing the specified subset of the model <code>x</code>.
</p>
<p>If necessary, counts of nonzero elements for each row and/or column are updated automatically.
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p><code><a href="#topic+dsm">dsm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
print(DSM_TermContext$M)
model &lt;- DSM_TermContext

subset(model, nchar(term) &lt;= 4)$M     # short target terms
subset(model, select=(nnzero &lt;= 3))$M # columns with &lt;= 3 nonzero cells

subset(model, nchar(term) &lt;= 4, nnzero &lt;= 3)$M # combine both conditions

subset(model, nchar(term) &lt;= 4, nnzero &gt;= 2)$M # still three columns with nnzero &lt; 2
subset(model, nchar(term) &lt;= 4, nnzero &gt;= 2, recursive=TRUE)$M

</code></pre>

<hr>
<h2 id='t.dsm'>
Swap the Rows and Columns of a DSM Object (wordspace)
</h2><span id='topic+t.dsm'></span>

<h3>Description</h3>

<p>Given a distributional model <code>x</code>, <code>t(x)</code> returns a new DSM object
representing the transposed co-occurrence and/or score matrix.  Marginal frequencies
and other row/column information are updated accordingly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'dsm'
t(x)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="t.dsm_+3A_x">x</code></td>
<td>
<p>an object of class <code>dsm</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>dsm</code> object with rows and columns swapped.
</p>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p><code><a href="#topic+dsm">dsm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
tdm &lt;- DSM_TermContext # term-document model
tdm$M

dtm &lt;- t(tdm) # document-term model
dtm$M

</code></pre>

<hr>
<h2 id='WordSim353'>
Similarity Ratings for 351 Noun Pairs (wordspace)
</h2><span id='topic+WordSim353'></span>

<h3>Description</h3>

<p>A database of human similarity ratings for 351 English noun pairs,
collected by Finkelstein et al. (2002) and annotated with semantic relations
(similarity vs. relatedness) by Agirre et al. (2009).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
WordSim353

</code></pre>


<h3>Format</h3>

<p>A data frame with 351 rows and the following 6 columns:
</p>

<dl>
<dt><code>word1</code></dt><dd><p>first noun (character)</p>
</dd>
<dt><code>word2</code></dt><dd><p>second noun (character)</p>
</dd>
<dt><code>score</code></dt><dd><p>average similarity rating by human judges on scale from 0 to 10 (numeric)</p>
</dd>
<dt><code>relation</code></dt><dd><p>semantic relation between first and second word (factor, see Details below)</p>
</dd>
<dt><code>similarity</code></dt><dd><p>whether word pair belongs to the <em>similarity</em> subset (logical)</p>
</dd>
<dt><code>relatedness</code></dt><dd><p>whether word pair belongs to the <em>relatedness</em> subset (logical)</p>
</dd>
</dl>

<p>The nouns are given as disambiguated lemmas in the form <code>&lt;headword&gt;_N</code>.
</p>


<h3>Details</h3>

<p>The data set is known as <code>WordSim353</code> because it originally consisted of 353 noun pairs.
One duplicate entry (<em>money</em>&ndash;<em>cash</em>) as well as the trivial combination 
<em>tiger</em>&ndash;<em>tiger</em> (which may have been included as a control item)
have been omitted in the present version, however.
</p>
<p>The following semantic relations are distinguished in the <code>relation</code> variable:
<code>synonym</code>, <code>antonym</code>, <code>hypernym</code>, <code>hyponym</code>, <code>co-hyponym</code>,
<code>holonym</code>, <code>meronym</code> and <code>other</code> (topically related or completely unrelated).
</p>
<p>Note that the <em>similarity</em> and <em>relatedness</em> subsets are not disjoint, because they
share 103 unrelated noun pairs (semantic relation <code>other</code> and score below 5.0).
</p>


<h3>Source</h3>

<p>Similarity ratings (Finkelstein <em>et al.</em> 2002): <a href="https://gabrilovich.com/resources/data/wordsim353/wordsim353.html">https://gabrilovich.com/resources/data/wordsim353/wordsim353.html</a>
</p>
<p>Semantic relations (Agirre <em>et al.</em> 2009): <a href="http://alfonseca.org/eng/research/wordsim353.html">http://alfonseca.org/eng/research/wordsim353.html</a>
</p>


<h3>References</h3>

<p>Agirre, Eneko, Alfonseca, Enrique, Hall, Keith, Kravalova, Jana, Pasca, Marius, and Soroa, Aitor (2009).
A study on similarity and relatedness using distributional and WordNet-based approaches.
In <em>Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT 2009)</em>, pages 19&ndash;27, Boulder, Colorado.
</p>
<p>Finkelstein, Lev, Gabrilovich, Evgeniy, Matias, Yossi, Rivlin, Ehud, Solan, Zach, Wolfman, Gadi, and Ruppin, Eytan (2002).
Placing search in context: The concept revisited.
<em>ACM Transactions on Information Systems</em>, <b>20</b>(1), 116&ndash;131.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
head(WordSim353, 20)

table(WordSim353$relation) # semantic relations

# split into "similarity" and "relatedness" subsets
xtabs(~ similarity + relatedness, data=WordSim353) 

</code></pre>

<hr>
<h2 id='wordspace-package'>
Distributional Semantic Models in R (wordspace)
</h2><span id='topic+wordspace-package'></span><span id='topic+wordspace'></span>

<h3>Description</h3>

<p>This package aims to provide a toy laboratory for research and experimentation in distributional semantics
as well as a user-friendly environment for building and applying distributional semantic models (DSM) in R 
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
    Package: </td><td style="text-align: left;"> wordspace</td>
</tr>
<tr>
 <td style="text-align: left;">
    Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
    Version: </td><td style="text-align: left;"> 0.2-7</td>
</tr>
<tr>
 <td style="text-align: left;">
    Date: </td><td style="text-align: left;"> 2022-02-22</td>
</tr>
<tr>
 <td style="text-align: left;">
    License: </td><td style="text-align: left;"> GPL-3</td>
</tr>
<tr>
 <td style="text-align: left;">
    LazyLoad: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)
</p>


<h3>References</h3>

<p>Please cite this package as
</p>
<p>Evert, Stefan (2014). Distributional semantics in R with the wordspace package. In <em>Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: System Demonstrations</em>, pages 110&ndash;114, Dublin, Ireland.
</p>
<p>and link to the package homepage at <a href="http://wordspace.r-forge.r-project.org/">http://wordspace.r-forge.r-project.org/</a>.
</p>
<p>Tutorial materials using the package for examples and exercises are available from <a href="http://wordspace.collocations.de/">http://wordspace.collocations.de/</a> under an open-source license.  You will also find some pre-compiled distributional semantic models (DSM) there.
</p>


<h3>See Also</h3>

<p>If you are new to the <b>wordspace</b> package, you should start by reading the package vignette and trying out the code examples show there.
</p>
<p>Good starting points into the package documentation are <code><a href="#topic+dsm">dsm</a></code>, <code><a href="#topic+read.dsm.triplet">read.dsm.triplet</a></code>, <code><a href="#topic+dist.matrix">dist.matrix</a></code> and <code><a href="#topic+nearest.neighbours">nearest.neighbours</a></code>.
</p>

<hr>
<h2 id='wordspace.openmp'>
Control multi-core processing in wordspace functions (wordspace)
</h2><span id='topic+wordspace.openmp'></span>

<h3>Description</h3>

<p>Control whether multi-core processing is used by wordspace functions (if available)
and how many threads are run in parallel.  See &quot;Details&quot; below for more information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
wordspace.openmp(threads = NULL)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wordspace.openmp_+3A_threads">threads</code></td>
<td>

<p>if specified, number of parallel threads to be used for multi-core processing
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>wordspace</code> package has experimental support for multi-core processing using OpenMP on some platforms.
So far, only the <code>dist.matrix</code> function uses multi-core processing (for all distance measures except <code>cosine</code>).
</p>
<p>Even where supported, OpenMP is not enabled by default and has to be activated explicitly with <code>wordspace.openmp(threads=N)</code>, where <code>N</code> is
the number of parallel threads to be used.
</p>
<p>Call <code>wordspace.openmp()</code> without arguments to find out whether OpenMP is supported on your platform
and obtain information about the maximum number of threads available as well as the current setting.
</p>
<p>Note that multi-threading of other R packages and functions (such as optimised matrix algebra in the BLAS library) is never affected by this function.
</p>


<h3>Value</h3>

<p>If <code>threads</code> is unspecified or <code>NULL</code>, a data frame with a single row and the following information is returned:
</p>
<table>
<tr><td><code>available</code></td>
<td>
<p><code>TRUE</code> if OpenMP multi-core support is available</p>
</td></tr>
<tr><td><code>max</code></td>
<td>
<p>maximum number of threads that can be used (0 if not available)</p>
</td></tr>
<tr><td><code>threads</code></td>
<td>
<p>currently selected number of threads (defaults to 1 if not available)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p><code><a href="#topic+dist.matrix">dist.matrix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>wordspace.openmp()
</code></pre>

<hr>
<h2 id='write.dsm.matrix'>
Export DSM Matrix to File (wordspace)
</h2><span id='topic+write.dsm.matrix'></span>

<h3>Description</h3>

<p>This function exports a DSM matrix to a disk file in the specified format (see section &lsquo;Formats&rsquo; for details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
write.dsm.matrix(x, file, format = c("word2vec"), round=FALSE,
                 encoding = "UTF-8", batchsize = 1e6, verbose=FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write.dsm.matrix_+3A_x">x</code></td>
<td>

<p>a dense or sparse matrix representing a DSM, or an object of class <code>dsm</code>
</p>
</td></tr>
<tr><td><code id="write.dsm.matrix_+3A_file">file</code></td>
<td>

<p>either a character string naming a file or a <code><a href="base.html#topic+connection">connection</a></code> open for writing (in text mode)
</p>
</td></tr>
<tr><td><code id="write.dsm.matrix_+3A_format">format</code></td>
<td>

<p>desired output file format. See section &lsquo;Formats&rsquo; for a list of available formats and their limitations.
</p>
</td></tr>
<tr><td><code id="write.dsm.matrix_+3A_round">round</code></td>
<td>

<p>for some output formats, numbers can be rounded to the specified number of decimal digits in order to reduce file size
</p>
</td></tr>
<tr><td><code id="write.dsm.matrix_+3A_encoding">encoding</code></td>
<td>

<p>character encoding of the output file (ignored if <code>file</code> is a connection)
</p>
</td></tr>
<tr><td><code id="write.dsm.matrix_+3A_batchsize">batchsize</code></td>
<td>

<p>for certain output formats, the matrix is written in batches of <code>batchsize</code> cells each in order to limit memory overhead
</p>
</td></tr>
<tr><td><code id="write.dsm.matrix_+3A_verbose">verbose</code></td>
<td>

<p>if <code>TRUE</code>, show progress bar when writing in batches
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In order to save text formats to a compressed file, pass a <code><a href="base.html#topic+gzfile">gzfile</a></code>, <code><a href="base.html#topic+bzfile">bzfile</a></code> or <code><a href="base.html#topic+xzfile">xzfile</a></code> connection with appropriate <code>encoding</code> in the argument <code>file</code>.  Make sure not to open the connection before passing it to <code>write.dsm.matrix</code>.  See section &lsquo;Examples&rsquo; below.
</p>


<h3>Formats</h3>

<p>Currently, the only supported file format is <code>word2vec</code>.
</p>

<dl>
<dt><code>word2vec</code></dt><dd>
<p>This widely used text format for word embeddings is only suitable for a dense matrix. Row labels must be unique and may not contain whitespace.
Values are usually rounded to a few decimal digits in order to keep file size manageable.
</p>
<p>The first line of the file lists the matrix dimensions (rows, columns) separated by a single blank.
It is followed by one text line for each matrix row, starting with the row label. The label and are cells are separated by single blanks, so row labels cannot contain whitespace.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.dsm.matrix">read.dsm.matrix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- dsm.score(DSM_TermTerm, score="MI", normalize=TRUE) # a typical DSM

# save in word2vec text format (rounded to 3 digits)
fn &lt;- tempfile(fileext=".txt")
write.dsm.matrix(model, fn, format="word2vec", round=3)
cat(readLines(fn), sep="\n")

# save as compressed file in word2vec format
fn &lt;- tempfile(fileext=".txt.gz")
fh &lt;- gzfile(fn, encoding="UTF-8") # need to set file encoding here
write.dsm.matrix(model, fh, format="word2vec", round=3)
# write.dsm.matrix() automatically opens and closes the connection
cat(readLines(gzfile(fn)), sep="\n")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
