<!DOCTYPE html><html lang="en"><head><title>Help for package kernelboot</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {kernelboot}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bw.silv'><p>Bandwidth selector for multivariate kernel density estimation</p></a></li>
<li><a href='#kernelboot'><p>Smoothed bootstrap</p></a></li>
<li><a href='#kernelboot-class'><p>'kernelboot' class object</p></a></li>
<li><a href='#rmvg'><p>Random generation from multivariate Gaussian kernel density</p></a></li>
<li><a href='#rmvk'><p>Random generation from product kernel density</p></a></li>
<li><a href='#ruvk'><p>Random generation from univariate kernel density</p></a></li>
<li><a href='#summary.kernelboot'><p>Summarize the result of kernelboot</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Smoothed Bootstrap and Random Generation from Kernel Densities</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.10</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-04-14</td>
</tr>
<tr>
<td>Author:</td>
<td>Tymoteusz Wolodzko</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Tymoteusz Wolodzko &lt;twolodzko+kernelboot@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Smoothed bootstrap and functions for random generation from
             univariate and multivariate kernel densities. It does not
             estimate kernel densities.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/twolodzko/kernelboot">https://github.com/twolodzko/kernelboot</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/twolodzko/kernelboot/issues">https://github.com/twolodzko/kernelboot/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, future, future.apply, parallelly</td>
</tr>
<tr>
<td>Suggests:</td>
<td>covr, testthat, ks, KernSmooth, cramer</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-04-14 10:06:57 UTC; tymek</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-04-14 10:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='bw.silv'>Bandwidth selector for multivariate kernel density estimation</h2><span id='topic+bw.silv'></span><span id='topic+bw.scott'></span>

<h3>Description</h3>

<p>Rule of thumb bandwidth selectors for Gaussian kernels as described by
Scott (1992) and Silverman (1986).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bw.silv(x, na.rm = FALSE)

bw.scott(x, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bw.silv_+3A_x">x</code></td>
<td>
<p>numeric matrix or data.frame.</p>
</td></tr>
<tr><td><code id="bw.silv_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical value indicating whether <code>NA</code> values should
be stripped before the computation proceeds.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Scott's (1992) rule is defined as
</p>
<p style="text-align: center;"><code class="reqn">
H = n^{-2/(m+4)} \hat\Sigma
</code>
</p>

<p>Silverman's (1986; see Chacon, Duong and Wand, 2011) rule is defined as
</p>
<p style="text-align: center;"><code class="reqn">
H = \left(\frac{4}{n(m+2)}\right)^{2/(m+4)} \hat\Sigma
</code>
</p>

<p>where <code class="reqn">m</code> is number of variables, <code class="reqn">n</code> is sample size, <code class="reqn">\hat\Sigma</code>
is the empirical covariance matrix. The bandwidth is returned as a <em>covariance matrix</em>,
so to use it for a product kernel, take square root of it's diagonal: <code>sqrt(diag(H))</code>.
</p>
<p><code>bw.silv</code> corresponds to <code>Hns</code> method with <code>deriv.order=0</code> from the
<span class="pkg">ks</span> package.
</p>


<h3>References</h3>

<p>Silverman, B.W. (1986). Density estimation for statistics and data analysis. Chapman and Hall/CRC.
</p>
<p>Wand, M.P. and Jones, M.C. (1995). Kernel smoothing. Chapman and Hall/CRC.
</p>
<p>Scott, D.W. (1992). Multivariate density estimation: theory, practice,
and visualization. John Wiley &amp; Sons.
</p>
<p>Chacon J.E., Duong, T. and Wand, M.P. (2011). Asymptotics for general multivariate kernel density
derivative estimators. Statistica Sinica, 21, 807-840.
</p>
<p>Epanechnikov, V.A. (1969). Non-parametric estimation of a multivariate probability density.
Theory of Probability &amp; Its Applications, 14(1): 153-158.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+bandwidth">bandwidth</a></code>
</p>

<hr>
<h2 id='kernelboot'>Smoothed bootstrap</h2><span id='topic+kernelboot'></span>

<h3>Description</h3>

<p>Smoothed bootstrap is an extension of standard bootstrap using kernel densities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kernelboot(
  data,
  statistic,
  R = 500L,
  bw = "default",
  kernel = c("multivariate", "gaussian", "epanechnikov", "rectangular", "triangular",
    "biweight", "cosine", "optcosine", "none"),
  weights = NULL,
  adjust = 1,
  shrinked = TRUE,
  ignore = NULL,
  parallel = FALSE,
  workers = 1L
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kernelboot_+3A_data">data</code></td>
<td>
<p>vector, matrix, or data.frame. For non-numeric values standard bootstrap
is applied (see below).</p>
</td></tr>
<tr><td><code id="kernelboot_+3A_statistic">statistic</code></td>
<td>
<p>a function that is applied to the <code>data</code>. The first argument of
the function will always be the original data.</p>
</td></tr>
<tr><td><code id="kernelboot_+3A_r">R</code></td>
<td>
<p>the number of bootstrap replicates.</p>
</td></tr>
<tr><td><code id="kernelboot_+3A_bw">bw</code></td>
<td>
<p>the smoothing bandwidth to be used (see <code><a href="stats.html#topic+density">density</a></code>).
The kernels are scaled such that this is the standard deviation,
or covariance matrix of the smoothing kernel. By default
<code><a href="stats.html#topic+bw.nrd0">bw.nrd0</a></code> is used for univariate data,
and <code><a href="#topic+bw.silv">bw.silv</a></code> is used for multivariate data. When using
<code>kernel = "multivariate"</code> this parameter should be a
<em>covariance matrix</em> of the smoothing kernel.</p>
</td></tr>
<tr><td><code id="kernelboot_+3A_kernel">kernel</code></td>
<td>
<p>a character string giving the smoothing kernel to be used.
This must partially match one of &quot;multivariate&quot;, &quot;gaussian&quot;,
&quot;rectangular&quot;, &quot;triangular&quot;, &quot;epanechnikov&quot;, &quot;biweight&quot;, &quot;cosine&quot;,
&quot;optcosine&quot;, or &quot;none&quot; with default &quot;multivariate&quot;, and may be abbreviated.
Using <code>kernel = "multivariate"</code> forces multivariate Gaussian kernel
(or univariate Gaussian for univariate data). Using <code>kernel = "none"</code>
forces using standard bootstrap (no kernel smoothing).</p>
</td></tr>
<tr><td><code id="kernelboot_+3A_weights">weights</code></td>
<td>
<p>vector of importance weights. It should have as many elements
as there are observations in <code>data</code>. It defaults to uniform
weights.</p>
</td></tr>
<tr><td><code id="kernelboot_+3A_adjust">adjust</code></td>
<td>
<p>scalar; the bandwidth used is actually <code>adjust*bw</code>. This makes
it easy to specify values like 'half the default' bandwidth.</p>
</td></tr>
<tr><td><code id="kernelboot_+3A_shrinked">shrinked</code></td>
<td>
<p>logical; if <code>TRUE</code> random generation algorithm preserves
means and variances of the variables. This parameter is ignored for
&quot;multivariate&quot; kernel.</p>
</td></tr>
<tr><td><code id="kernelboot_+3A_ignore">ignore</code></td>
<td>
<p>vector of names of columns to be ignored during the smoothing phase of
bootstrap procedure (their values are not altered using random noise).</p>
</td></tr>
<tr><td><code id="kernelboot_+3A_parallel">parallel</code></td>
<td>
<p>if <code>TRUE</code>, parallel computing is used (see <code><a href="future.apply.html#topic+future_lapply">future_lapply</a></code>).
<em>Warning:</em> using parallel computing does not necessary have to
lead to improved performance.</p>
</td></tr>
<tr><td><code id="kernelboot_+3A_workers">workers</code></td>
<td>
<p>the number of workers used for parallel computing.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Smoothed bootstrap</em> is an extension of standard bootstrap procedure, where instead
of drawing samples with replacement from the empirical distribution, they are drawn
from kernel density estimate of the distribution.
</p>
<p>For smoothed bootstrap, points (in univariate case), or rows (in multivariate case), are drawn with
replacement, to obtain samples of size <code class="reqn">n</code> from the initial dataset of size <code class="reqn">n</code>, as with
standard bootstrap. Next, random noise from kernel density <code class="reqn">K</code> is added to each of the drawn
values. The procedure is repeated <code class="reqn">R</code> times and <code>statistic</code> is evaluated on each of the
samples.
</p>
<p>The noise is added <em>only</em> to the numeric columns, while non-numeric columns (e.g.
<code>character</code>, <code>factor</code>, <code>logical</code>) are not altered. What follows, to the
non-numeric columns and columns listed in <code>ignore</code> parameter standard bootstrap procedure
is applied.
</p>
<p><strong>Univariate kernel densities</strong>
</p>
<p>Univariate kernel density estimator is defined as
</p>
<p style="text-align: center;"><code class="reqn">
\hat{f_h}(x) = \sum_{i=1}^n w_i \, K_h(x-y_i)
</code>
</p>

<p>where <code class="reqn">w</code> is a vector of weights such that all <code class="reqn">w_i \ge 0</code>
and <code class="reqn">\sum_i w_i = 1</code> (by default uniform <code class="reqn">1/n</code> weights are used),
<code class="reqn">K_h = K(x/h)/h</code> is kernel <code class="reqn">K</code> parametrized by bandwidth <code class="reqn">h</code>
and <code class="reqn">y</code> is a vector of data points used for estimating the kernel density.
</p>
<p>To draw samples from univariate kernel density, the following procedure can be applied (Silverman, 1986):
</p>
<p><em>Step 1</em> Sample <code class="reqn">i</code> uniformly with replacement from <code class="reqn">1,\dots,n</code>.
</p>
<p><em>Step 2</em> Generate <code class="reqn">\varepsilon</code> to have probability density <code class="reqn">K</code>.
</p>
<p><em>Step 3</em> Set <code class="reqn">x = y_i + h\varepsilon</code>.
</p>
<p>If samples are required to have the same variance as <code>data</code>
(i.e. <code>shrinked = TRUE</code>), then <em>Step 3</em> is modified
as following:
</p>
<p><em>Step 3'</em> <code class="reqn">
x = \bar y + (y_i - \bar y + h\varepsilon)/(1 + h^2 \sigma^2_K/\sigma^2_Y)^{1/2}
</code>
</p>
<p>where <code class="reqn">\sigma_K^2</code> is variance of the kernel (fixed to 1 for kernels used in this package).
</p>
<p>When shrinkage described in <em>Step 3'</em> is applied, the smoothed bootstrap density function changes
it's form to
</p>
<p style="text-align: center;"><code class="reqn">
\hat{f}_{h,b}(x) = (1 + r) \; \hat{f_h}(x + r(x - \bar{y}))
</code>
</p>

<p>where <code class="reqn">r = \left(1 + h^2 \sigma_K^2 / \sigma_y^2 \right)^{1/2}-1</code>.
</p>
<p>This package offers the following univariate kernels:
</p>

<table>
<tr>
 <td style="text-align: left;">
<em>Gaussian</em>     </td><td style="text-align: left;"> <code class="reqn">\frac{1}{\sqrt{2\pi}} e^{-{u^2}/2}</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
<em>Rectangular</em>  </td><td style="text-align: left;"> <code class="reqn">\frac{1}{2} \ \mathbf{1}_{(|u|\leq1)}</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
<em>Triangular</em>   </td><td style="text-align: left;"> <code class="reqn">(1-|u|) \ \mathbf{1}_{(|u|\leq1)}</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
<em>Epanchenikov</em> </td><td style="text-align: left;"> <code class="reqn">\frac{3}{4}(1-u^2) \ \mathbf{1}_{(|u|\leq1)}</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
<em>Biweight</em>     </td><td style="text-align: left;"> <code class="reqn">\frac{15}{16}(1-u^2)^2 \ \mathbf{1}_{(|u|\leq1)}</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
<em>Cosine</em>       </td><td style="text-align: left;"> <code class="reqn">\frac{1}{2} \left(1 + \cos(\pi u)\right) \ \mathbf{1}_{(|u|\leq1)}</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
<em>Optcosine</em>    </td><td style="text-align: left;"> <code class="reqn">\frac{\pi}{4}\cos\left(\frac{\pi}{2}u\right) \ \mathbf{1}_{(|u|\leq1)}</code>
</td>
</tr>

</table>

<p>All the kernels are re-scalled so that their standard deviations are equal to 1,
so that bandwidth parameter controls their standard deviations.
</p>
<p>Random generation from Epanchenikov kernel is done using algorithm
described by Devroye (1986). For optcosine kernel inverse transform
sampling is used. For biweight kernel random values are drawn from
<code class="reqn">\mathrm{Beta}(3, 3)</code> distribution and
<code class="reqn">\mathrm{Beta}(3.3575, 3.3575)</code>
distribution serves as a close approximation of cosine kernel.
Random generation for triangular kernel is done by taking difference
of two i.i.d. uniform random variates. To sample from rectangular
and Gaussian kernels standard random generation algorithms are used
(see <code><a href="stats.html#topic+runif">runif</a></code> and <code><a href="stats.html#topic+rnorm">rnorm</a></code>).
</p>
<p><strong>Product kernel densities</strong>
</p>
<p>Univariate kernels may easily be extended to multiple dimensions by
using product kernel
</p>
<p style="text-align: center;"><code class="reqn">
\hat{f_H}(\mathbf{x}) = \sum_{i=1}^n w_i \prod_{j=1}^m
K_{h_j}(x_i - y_{ij})
</code>
</p>

<p>where <code class="reqn">w</code> is a vector of weights such that all <code class="reqn">w_i \ge 0</code>
and <code class="reqn">\sum_i w_i = 1</code> (by default uniform <code class="reqn">1/n</code> weights are used),
and <code class="reqn">K_{h_j}</code> are univariate kernels <code class="reqn">K</code> parametrized by bandwidth
<code class="reqn">h_j</code>, where <code class="reqn">\boldsymbol{y}</code> is a matrix of data points used for
estimating the kernel density.
</p>
<p>Random generation from product kernel is done by drawing with replacement
rows of <code class="reqn">y</code>, and then adding to the sampled values random noise from
univariate kernels <code class="reqn">K</code>, parametrized by corresponding bandwidth parameters
<code class="reqn">h_j</code>.
</p>
<p><strong>Multivariate kernel densities</strong>
</p>
<p>Multivariate kernel density estimator may also be defined in terms of multivariate kernels
<code class="reqn">K_H</code> (e.g. multivariate normal distribution, as in this package)
</p>
<p style="text-align: center;"><code class="reqn">
\hat{f_H}(\mathbf{x}) = \sum_{i=1}^n w_i \, K_H( \mathbf{x}-\boldsymbol{y}_i)
</code>
</p>

<p>where <code class="reqn">w</code> is a vector of weights such that all <code class="reqn">w_i \ge 0</code>
and <code class="reqn">\sum_i w_i = 1</code> (by default uniform <code class="reqn">1/n</code> weights are used),
<code class="reqn">K_H</code> is kernel <code class="reqn">K</code> parametrized by bandwidth matrix <code class="reqn">H</code> and
<code class="reqn">\boldsymbol{y}</code> is a matrix of data points used for estimating the kernel density.
</p>
<p><em>Notice:</em> When using multivariate normal (Gaussian) distribution as a kernel <code class="reqn">K</code>, the
bandwidth parameter <code class="reqn">H</code> is a <em>covariance matrix</em> as compared to standard deviations
used in univariate and product kernels.
</p>
<p>Random generation from multivariate kernel is done by drawing with replacement
rows of <code class="reqn">y</code>, and then adding to the sampled values random noise from
multivariate normal distribution centered at the data points and parametrized
by corresponding bandwidth matrix <code class="reqn">H</code>. For further details see <code><a href="#topic+rmvg">rmvg</a></code>.
</p>


<h3>References</h3>

<p>Silverman, B. W. (1986). Density estimation for statistics and data analysis.
Chapman and Hall/CRC.
</p>
<p>Scott, D. W. (1992). Multivariate density estimation: theory, practice,
and visualization. John Wiley &amp; Sons.
</p>
<p>Efron, B. (1981). Nonparametric estimates of standard error: the jackknife,
the bootstrap and other methods. Biometrika, 589-599.
</p>
<p>Hall, P., DiCiccio, T.J. and Romano, J.P. (1989). On smoothing and the bootstrap.
The Annals of Statistics, 692-704.
</p>
<p>Silverman, B.W. and Young, G.A. (1987). The bootstrap: To smooth or not to smooth?
Biometrika, 469-479.
</p>
<p>Scott, D.W. (1992). Multivariate density estimation: theory, practice,
and visualization. John Wiley &amp; Sons.
</p>
<p>Wang, S. (1995). Optimizing the smoothed bootstrap. Annals of the Institute of
Statistical Mathematics, 47(1), 65-80.
</p>
<p>Young, G.A. (1990). Alternative smoothed bootstraps. Journal of the Royal
Statistical Society. Series B (Methodological), 477-484.
</p>
<p>De Angelis, D. and Young, G.A. (1992). Smoothing the bootstrap.
International Statistical Review/Revue Internationale de Statistique, 45-56.
</p>
<p>Polansky, A.M. and Schucany, W. (1997). Kernel smoothing to improve bootstrap
confidence intervals. Journal of the Royal Statistical Society: Series B
(Statistical Methodology), 59(4), 821-838.
</p>
<p>Devroye, L. (1986). Non-uniform random variate generation. New York: Springer-Verlag.
</p>
<p>Parzen, E. (1962). On estimation of a probability density function and mode.
The annals of mathematical statistics, 33(3), 1065-1076.
</p>
<p>Silverman, B.W. and Young, G.A. (1987). The bootstrap: To smooth or not to smooth?
Biometrika, 469-479.
</p>
<p>Jones, M.C. (1991). On correcting for variance inflation in kernel density estimation.
Computational Statistics &amp; Data Analysis, 11, 3-15.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bw.silv">bw.silv</a></code>, <code><a href="stats.html#topic+density">density</a></code>,
<code><a href="stats.html#topic+bandwidth">bandwidth</a></code>, <code><a href="#topic+kernelboot-class">kernelboot-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)

# smooth bootstrap of parameters of linear regression

b1 &lt;- kernelboot(mtcars, function(data) coef(lm(mpg ~ drat + wt, data = data)) , R = 250)
b1
summary(b1)

b2 &lt;- kernelboot(mtcars, function(data) coef(lm(mpg ~ drat + wt, data = data)) , R = 250,
                 kernel = "epanechnikov")
b2
summary(b2)

# smooth bootstrap of parameters of linear regression
# smoothing phase is not applied to "am" and "cyl" variables

b3 &lt;- kernelboot(mtcars, function(data) coef(lm(mpg ~ drat + wt + am + cyl, data = data)) , R = 250,
                 ignore = c("am", "cyl"))
b3
summary(b3)

# standard bootstrap (without kernel smoothing)

b4 &lt;- kernelboot(mtcars, function(data) coef(lm(mpg ~ drat + wt + am + cyl, data = data)) , R = 250,
                 ignore = colnames(mtcars))
b4
summary(b4)

# smooth bootstrap for median of univariate data

b5 &lt;- kernelboot(mtcars$mpg, function(data) median(data) , R = 250)
b5
summary(b5)


</code></pre>

<hr>
<h2 id='kernelboot-class'>'kernelboot' class object</h2><span id='topic+kernelboot-class'></span>

<h3>Description</h3>

<p>'kernelboot' class object
</p>


<h3>Details</h3>

<p>Object of class <code>"kernelboot"</code>, is a list with components including
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>orig.stat</code>          </td><td style="text-align: left;">  estimates from <code>statistic</code> on the original data, </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>boot.samples</code>       </td><td style="text-align: left;">  samples drawn, </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>call</code>               </td><td style="text-align: left;">  function call, </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>statistic</code>          </td><td style="text-align: left;">  actual <code>statistic</code> function that was used, </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>orig.data</code>          </td><td style="text-align: left;">  original data used for bootstrapping, </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>variables</code>          </td><td style="text-align: left;">  used variables: it is <code>NULL</code> for univariate data and
                                for multivariate data it contains two lists of <code>smoothed</code>
                                and <code>ignored</code> variables (names or column indexes) during
                                the smoothing phase. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>type</code>               </td><td style="text-align: left;">  type of kernel density that was used ("univariate", "product",
                                "multivariate"), </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>param</code>              </td><td style="text-align: left;">  list of parameters that were used.
</td>
</tr>

</table>

<p><code>param</code> section contains:
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>R</code>                  </td><td style="text-align: left;">  number of bootstrap iterations, </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>bw</code>                 </td><td style="text-align: left;">  the bandwidth that was used, </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>weights</code>            </td><td style="text-align: left;">  vector of the weights that were applied, </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>kernel</code>             </td><td style="text-align: left;">  name of the kernel that was used ("multivariate",
                                "gaussian", "epanechnikov", "rectangular",
                                "triangular", "biweight", "cosine", "optcosine",
                                "none"), </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>shrinked</code>           </td><td style="text-align: left;">  value of the <code>shrinked</code> parameter, </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>parallel</code>           </td><td style="text-align: left;">  indicates if parallel computation was used, </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>random.seed</code>        </td><td style="text-align: left;">  random seed used to initialize the random number
                                generator (see <code><a href="base.html#topic+.Random.seed">.Random.seed</a></code>).
</td>
</tr>

</table>



<h3>See Also</h3>

<p><code><a href="#topic+kernelboot">kernelboot</a></code>
</p>

<hr>
<h2 id='rmvg'>Random generation from multivariate Gaussian kernel density</h2><span id='topic+rmvg'></span>

<h3>Description</h3>

<p>Random generation from multivariate Gaussian kernel density
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmvg(n, y, bw = bw.silv(y), weights = NULL, adjust = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rmvg_+3A_n">n</code></td>
<td>
<p>number of observations. If <code>length(n) &gt; 1</code>,
the length is taken to be the number required.</p>
</td></tr>
<tr><td><code id="rmvg_+3A_y">y</code></td>
<td>
<p>numeric matrix or data.frame.</p>
</td></tr>
<tr><td><code id="rmvg_+3A_bw">bw</code></td>
<td>
<p>numeric matrix with number of rows and columns equal to
<code>ncol(y)</code>; the smoothing bandwidth to be used. This is the
<em>covariance matrix</em> of the smoothing kernel. If provided as
a single value, the same bandwidth is used for each variable.
If provided as a single value, or as a vector, variables are
considered as uncorrelated.</p>
</td></tr>
<tr><td><code id="rmvg_+3A_weights">weights</code></td>
<td>
<p>numeric vector of length equal to <code>nrow(y)</code>; must be non-negative.</p>
</td></tr>
<tr><td><code id="rmvg_+3A_adjust">adjust</code></td>
<td>
<p>scalar; the bandwidth used is actually <code>adjust*bw</code>.
This makes it easy to specify values like 'half the default'
bandwidth.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Multivariate kernel density estimator with multivariate Gaussian (normal) kernels
<code class="reqn">K_H</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">
\hat{f_H}(\mathbf{x}) = \sum_{i=1}^n w_i \, K_H \left( \mathbf{x}-\boldsymbol{y}_i \right)
</code>
</p>

<p>where <code class="reqn">w</code> is a vector of weights such that all <code class="reqn">w_i \ge 0</code>
and <code class="reqn">\sum_i w_i = 1</code> (by default uniform <code class="reqn">1/n</code> weights are used),
<code class="reqn">K_H</code> is kernel <code class="reqn">K</code> parametrized by bandwidth matrix <code class="reqn">H</code> and
<code class="reqn">\boldsymbol{y}</code> is a matrix of data points used for estimating the kernel density.
</p>
<p>Random generation from multivariate normal distribution is possible by taking
</p>
<p style="text-align: center;"><code class="reqn">
x = A' z + \mu
</code>
</p>

<p>where <code class="reqn">z</code> is a vector of <code class="reqn">m</code> i.i.d. standard normal deviates,
<code class="reqn">\mu</code> is a vector of means and <code class="reqn">A</code> is a <code class="reqn">m \times m</code>
matrix such that <code class="reqn">A'A=\Sigma</code> (<code class="reqn">A</code> is a Cholesky
factor of <code class="reqn">\Sigma</code>). In the case of multivariate Gaussian kernel
density, <code class="reqn">\mu</code>, is the <code class="reqn">i</code>-th row of <code class="reqn">\boldsymbol{y}</code>,
where <code class="reqn">i</code> is drawn randomly with replacement with probability
proportional to <code class="reqn">w_i</code>, and <code class="reqn">\Sigma</code> is the bandwidth
matrix <code class="reqn">H</code>.
</p>
<p>For functions estimating kernel densities please check <span class="pkg">KernSmooth</span>,
<span class="pkg">ks</span>, or other packages reviewed by Deng and Wickham (2011).
</p>


<h3>References</h3>

<p>Deng, H. and Wickham, H. (2011). Density estimation in R.
<a href="http://vita.had.co.nz/papers/density-estimation.pdf">http://vita.had.co.nz/papers/density-estimation.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kernelboot">kernelboot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)

dat &lt;- mtcars[, c(1,3)]
bw &lt;- bw.silv(dat)
X &lt;- rmvg(5000, dat, bw = bw)

if (requireNamespace("ks", quietly = TRUE)) {

   pal &lt;- colorRampPalette(c("chartreuse4", "yellow", "orange", "brown"))
   col &lt;- pal(10)[cut(ks::kde(dat, H = bw, eval.points = X)$estimate, breaks = 10)]

   plot(X, col = col, pch = 19, axes = FALSE,
        main = "Multivariate Gaussian Kernel")
   points(dat, pch = 2, col = "blue")
   axis(1); axis(2)

} else {

   plot(X, pch = 16, axes = FALSE, col = "#458B004D",
        main = "Multivariate Gaussian Kernel")
   points(dat, pch = 2, col = "red", lwd = 2)
   axis(1); axis(2)

}


</code></pre>

<hr>
<h2 id='rmvk'>Random generation from product kernel density</h2><span id='topic+rmvk'></span>

<h3>Description</h3>

<p>Random generation from product kernel density
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmvk(
  n,
  y,
  bw = sqrt(diag(bw.silv(y))),
  kernel = c("gaussian", "epanechnikov", "rectangular", "triangular", "biweight",
    "cosine", "optcosine"),
  weights = NULL,
  adjust = 1,
  shrinked = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rmvk_+3A_n">n</code></td>
<td>
<p>number of observations. If <code>length(n) &gt; 1</code>,
the length is taken to be the number required.</p>
</td></tr>
<tr><td><code id="rmvk_+3A_y">y</code></td>
<td>
<p>numeric matrix or data.frame.</p>
</td></tr>
<tr><td><code id="rmvk_+3A_bw">bw</code></td>
<td>
<p>numeric vector of length equal to <code>ncol(y)</code>;
the smoothing bandwidth to be used. The kernels are
scaled such that this is the standard deviation of the
smoothing kernel (see
<code><a href="stats.html#topic+density">density</a></code> for details). If provided as
a single value, the same bandwidth is used for each variable.</p>
</td></tr>
<tr><td><code id="rmvk_+3A_kernel">kernel</code></td>
<td>
<p>a character string giving the smoothing kernel to be used.
This must partially match one of &quot;gaussian&quot;, &quot;rectangular&quot;,
&quot;triangular&quot;, &quot;epanechnikov&quot;, &quot;biweight&quot;, &quot;cosine&quot;
or &quot;optcosine&quot;, with default &quot;gaussian&quot;, and may be abbreviated.</p>
</td></tr>
<tr><td><code id="rmvk_+3A_weights">weights</code></td>
<td>
<p>numeric vector of length equal to <code>nrow(y)</code>; must be non-negative.</p>
</td></tr>
<tr><td><code id="rmvk_+3A_adjust">adjust</code></td>
<td>
<p>scalar; the bandwidth used is actually <code>adjust*bw</code>.
This makes it easy to specify values like 'half the default'
bandwidth.</p>
</td></tr>
<tr><td><code id="rmvk_+3A_shrinked">shrinked</code></td>
<td>
<p>if <code>TRUE</code> random generation algorithm preserves mean and
variances of the individual variables (see <code><a href="#topic+ruvk">ruvk</a></code>).
Shrinking is applied to each of the variables individually.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Product kernel density is defined in terms of independent univariate kernels
</p>
<p style="text-align: center;"><code class="reqn">
\hat{f_H}(\mathbf{x}) = \sum_{i=1}^n w_i \prod_{j=1}^m
K_{h_j}( x_i - y_{ij})
</code>
</p>

<p>where <code class="reqn">w</code> is a vector of weights such that all <code class="reqn">w_i \ge 0</code>
and <code class="reqn">\sum_i w_i = 1</code> (by default uniform <code class="reqn">1/n</code> weights are used),
<code class="reqn">K_{h_j}</code> is univariate kernel <code class="reqn">K</code> parametrized by bandwidth <code class="reqn">h_j</code>,
where <code class="reqn">\boldsymbol{y}</code> is a matrix of data points used for estimating the
kernel density.
</p>
<p>For functions estimating kernel densities please check <span class="pkg">KernSmooth</span>,
<span class="pkg">ks</span>, or other packages reviewed by Deng and Wickham (2011).
</p>
<p>For random generation the algorithm described in <code><a href="#topic+kernelboot">kernelboot</a></code> is used.
When using <code>shrinked = TRUE</code>, random noise is drawn from independent, shrinked
univariate kernels.
</p>


<h3>References</h3>

<p>Deng, H. and Wickham, H. (2011). Density estimation in R.
<a href="http://vita.had.co.nz/papers/density-estimation.pdf">http://vita.had.co.nz/papers/density-estimation.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kernelboot">kernelboot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- mtcars[, c("mpg", "disp")]

partmp &lt;- par(mfrow = c(1, 2), mar = c(3, 3, 3, 3))

plot(rmvk(5000, dat, shrinked = FALSE), col = "#458B004D", pch = 16,
     xlim = c(0, 45), ylim = c(-200, 800),
     main = "Product kernel", axes = FALSE)
points(dat, pch = 2, lwd = 2, col = "red")
axis(1); axis(2)

plot(rmvk(5000, dat, shrinked = TRUE), col = "#458B004D", pch = 16,
     xlim = c(0, 45), ylim = c(-200, 800),
     main = "Product kernel (shrinked)", axes = FALSE)
points(dat, pch = 2, lwd = 2, col = "red")
axis(1); axis(2)

par(partmp)

cov(dat)
cov(rmvk(5000, dat, shrinked = FALSE))
cov(rmvk(5000, dat, shrinked = TRUE))

</code></pre>

<hr>
<h2 id='ruvk'>Random generation from univariate kernel density</h2><span id='topic+ruvk'></span>

<h3>Description</h3>

<p>Random generation from univariate kernel density
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ruvk(
  n,
  y,
  bw = bw.nrd0(y),
  kernel = c("gaussian", "epanechnikov", "rectangular", "triangular", "biweight",
    "cosine", "optcosine"),
  weights = NULL,
  adjust = 1,
  shrinked = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ruvk_+3A_n">n</code></td>
<td>
<p>number of observations. If <code>length(n) &gt; 1</code>,
the length is taken to be the number required.</p>
</td></tr>
<tr><td><code id="ruvk_+3A_y">y</code></td>
<td>
<p>numeric vector.</p>
</td></tr>
<tr><td><code id="ruvk_+3A_bw">bw</code></td>
<td>
<p>the smoothing bandwidth to be used. The kernels are scaled
such that this is the standard deviation of the smoothing
kernel (see <code><a href="stats.html#topic+density">density</a></code> for details).</p>
</td></tr>
<tr><td><code id="ruvk_+3A_kernel">kernel</code></td>
<td>
<p>a character string giving the smoothing kernel to be used.
This must partially match one of &quot;gaussian&quot;, &quot;rectangular&quot;,
&quot;triangular&quot;, &quot;epanechnikov&quot;, &quot;biweight&quot;, &quot;cosine&quot;
or &quot;optcosine&quot;, with default &quot;gaussian&quot;, and may be abbreviated.</p>
</td></tr>
<tr><td><code id="ruvk_+3A_weights">weights</code></td>
<td>
<p>numeric vector of length equal to <code>length(y)</code>; must be
non-negative.</p>
</td></tr>
<tr><td><code id="ruvk_+3A_adjust">adjust</code></td>
<td>
<p>scalar; the bandwidth used is actually <code>adjust*bw</code>.
This makes it easy to specify values like 'half the default'
bandwidth.</p>
</td></tr>
<tr><td><code id="ruvk_+3A_shrinked">shrinked</code></td>
<td>
<p>if <code>TRUE</code> random generation algorithm preserves
mean and variance of the original sample.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Univariate kernel density estimator is defined as
</p>
<p style="text-align: center;"><code class="reqn">
\hat{f_h}(x) = \sum_{i=1}^n w_i \, K_h(x-y_i)
</code>
</p>

<p>where <code class="reqn">w</code> is a vector of weights such that all <code class="reqn">w_i \ge 0</code>
and <code class="reqn">\sum_i w_i = 1</code> (by default uniform <code class="reqn">1/n</code> weights are used),
<code class="reqn">K_h = K(x/h)/h</code> is kernel <code class="reqn">K</code> parametrized by bandwidth
<code class="reqn">h</code> and <code class="reqn">y</code> is a vector of data points used for estimating the kernel density.
</p>
<p>For estimating kernel densities use the <code><a href="stats.html#topic+density">density</a></code> function.
</p>
<p>The random generation algorithm is described in the documentation of
<code><a href="#topic+kernelboot">kernelboot</a></code> function.
</p>


<h3>References</h3>

<p>Deng, H. and Wickham, H. (2011). Density estimation in R.
<a href="http://vita.had.co.nz/papers/density-estimation.pdf">http://vita.had.co.nz/papers/density-estimation.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kernelboot">kernelboot</a></code>, <code><a href="stats.html#topic+density">density</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# ruvk() produces samples from kernel densities as estimated using
# density() function from base R

hist(ruvk(1e5, mtcars$mpg), 100, freq = FALSE, xlim = c(5, 40))
lines(density(mtcars$mpg, bw = bw.nrd0(mtcars$mpg)), col = "red")

# when using 'shrinked = TRUE', the samples differ from density() estimates
# since they are shrinked to have the same variance as the underlying data

hist(ruvk(1e5, mtcars$mpg, shrinked = TRUE), 100, freq = FALSE, xlim = c(5, 40))
lines(density(mtcars$mpg, bw = bw.nrd0(mtcars$mpg)), col = "red")

# Comparison of different univariate kernels under standard parametrization

kernels &lt;- c("gaussian", "epanechnikov", "rectangular", "triangular",
             "biweight", "cosine", "optcosine")

partmp &lt;- par(mfrow = c(2, 4), mar = c(3, 3, 3, 3))
for (k in kernels) {
  hist(ruvk(1e5, 0, 1, kernel = k), 25, freq = FALSE, main = k)
  lines(density(0, 1, kernel = k), col = "red")
}
par(partmp)

</code></pre>

<hr>
<h2 id='summary.kernelboot'>Summarize the result of kernelboot</h2><span id='topic+summary.kernelboot'></span>

<h3>Description</h3>

<p>Summarize the result of kernelboot
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kernelboot'
summary(object, probs = c(0.025, 0.5, 0.975), ..., na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.kernelboot_+3A_object">object</code></td>
<td>
<p><code>kernelboot</code> class object.</p>
</td></tr>
<tr><td><code id="summary.kernelboot_+3A_probs">probs</code></td>
<td>
<p>quantiles returned by <code>summary</code> (see <code><a href="stats.html#topic+quantile">quantile</a></code>).</p>
</td></tr>
<tr><td><code id="summary.kernelboot_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="summary.kernelboot_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical value indicating whether <code>NA</code> values should be
stripped before the computation proceeds.</p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
