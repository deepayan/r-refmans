<!DOCTYPE html><html><head><title>Help for package stepPenal</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {stepPenal}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#findROC'><p>Compute the area under the ROC curve</p></a></li>
<li><a href='#lassomodel'><p>Fits a lasso model and a lasso followed by a stepAIC algorithm.</p></a></li>
<li><a href='#objFun'><p>Objective function</p></a></li>
<li><a href='#optimPenaLik'><p>Variable selection based on the combined penalty CL= (1-w)L0 + wL1</p></a></li>
<li><a href='#optimPenaLikL2'><p>Variable selection based on the combined penalty CL2= (1-w)L0 + wL2</p></a></li>
<li><a href='#penalBrier'><p>Evaluation of the performance of risk prediction models with binary status response variable.</p></a></li>
<li><a href='#SimData'><p>Simulate data with normally distributed predictors and binary response</p></a></li>
<li><a href='#stepaic'><p>Stepwise forward variable selection based on the AIC criterion</p></a></li>
<li><a href='#StepPenal'><p>Stepwise forward variable selection using penalized regression.</p></a></li>
<li><a href='#StepPenalL2'><p>Stepwise forward variable selection using penalized regression.</p></a></li>
<li><a href='#tuneParam'><p>Tune parameters w and lamda using the CL penalty</p></a></li>
<li><a href='#tuneParamCL2'><p>Tune parameters w and lamda using the CL2 penalty</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Stepwise Forward Variable Selection in Penalized Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2</td>
</tr>
<tr>
<td>Author:</td>
<td>Eleni Vradi</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Eleni Vradi &lt;vradi.eleni@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Model Selection Based on Combined Penalties. This package implements a stepwise forward variable selection algorithm based on a penalized likelihood criterion that combines the L0 with L2 or L1 norms.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>glmnet, mvtnorm, pROC, dfoptim, caret, stats, base</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.0</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-08-24 06:56:09 UTC; vradi</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-08-24 20:50:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='findROC'>Compute the area under the ROC curve</h2><span id='topic+findROC'></span>

<h3>Description</h3>

<p>This function computes the numeric value of area under the ROC curve (AUC) with the trapezoidal rule.
It is a wrapper function around the pRoc function in the roc package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findROC(Data, coeff)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findROC_+3A_data">Data</code></td>
<td>
<p>a data matrix; in the first column there should be the binary response variable y.
If you give the training dataset it will calculate the in-sample AUC.
If supplied with a new dataset then it will return the predictive AUC.</p>
</td></tr>
<tr><td><code id="findROC_+3A_coeff">coeff</code></td>
<td>
<p>vector of coefficients</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The area under the ROC curve, the sensitivity and specificity
</p>


<h3>See Also</h3>

<p><code><a href="pROC.html#topic+roc">roc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(14)
beta    &lt;- c(3, 2, -1.6, -4)
noise   &lt;- 5
simData &lt;- SimData(N=100,beta=beta, noise=noise, corr=FALSE)

stepPenal&lt;- StepPenal(Data=simData, lamda=1.2, w=0.7)

(coeffP &lt;- stepPenal$coeffP)

findROC(simData, coeff=coeffP)

## End(Not run)
</code></pre>

<hr>
<h2 id='lassomodel'>Fits a lasso model and a lasso followed by a stepAIC algorithm.</h2><span id='topic+lassomodel'></span>

<h3>Description</h3>

<p>Fits a lasso model and a lasso followed by a stepAIC algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lassomodel(Data, standardize = TRUE, measure = c("deviance"),
  nfold = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lassomodel_+3A_data">Data</code></td>
<td>
<p>a data frame, as a first column should have the response variable y</p>
</td></tr>
<tr><td><code id="lassomodel_+3A_standardize">standardize</code></td>
<td>
<p>Logical flag for variable standardization, prior to fitting the model.
Default is standardize=TRUE. If variables are in the same units already, you might not
wish to standardize.</p>
</td></tr>
<tr><td><code id="lassomodel_+3A_measure">measure</code></td>
<td>
<p>loss to use for cross-validation. measure=&quot;auc&quot; is for two-class logistic regression only,
and gives area under the ROC curve. measure=&quot;deviance&quot;, uses the deviance for logistic regression.</p>
</td></tr>
<tr><td><code id="lassomodel_+3A_nfold">nfold</code></td>
<td>
<p>number of folds - default is 5. Although nfolds can be as large as the sample size (leave-one-out CV),
it is not recommended for large datasets. Smallest value allowable is nfolds=3</p>
</td></tr>
</table>


<h3>Details</h3>

<p>the function lassomodel is a wrapper function over the glmnet::glmnet. The parameter lambda is tuned
by 10-fold cross-validation with the glmnet::cv.glmnet function.
The selected lambda is the one that gives either the minimum deviance (measure=&quot;deviance&quot;)
or the maximum auc (measure=&quot;auc&quot;) or minimum misclassification error (measure=&quot;class&quot;)
</p>


<h3>Value</h3>

<p>a list with the coefficients in the final model for the lasso fit and also for the lasso followed by stepAIC.
</p>


<h3>See Also</h3>

<p><code><a href="glmnet.html#topic+glmnet">glmnet</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(14)
beta    &lt;- c(3, 2, -1.6, -4)
noise   &lt;- 5
simData &lt;- SimData(N=100, beta=beta, noise=noise, corr=FALSE)

lassofit &lt;- lassomodel(Data=simData, measure="auc")
lassofit

lassofit2 &lt;- lassomodel(Data=simData, measure="deviance")
lassofit2

## End(Not run)

</code></pre>

<hr>
<h2 id='objFun'>Objective function</h2><span id='topic+objFun'></span>

<h3>Description</h3>

<p>Objective (non-convex) function to minimize (objFun=-logL+ lamda*CL, CL= (1-w)L0 + wL1)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>objFun(x, y, lamda, w, beta, epsilon)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="objFun_+3A_x">x</code></td>
<td>
<p>input matrix, of dimension nobs x nvars. Each row is an observation vector.</p>
</td></tr>
<tr><td><code id="objFun_+3A_y">y</code></td>
<td>
<p>binary response variable</p>
</td></tr>
<tr><td><code id="objFun_+3A_lamda">lamda</code></td>
<td>
<p>a tuning penalty parameter</p>
</td></tr>
<tr><td><code id="objFun_+3A_w">w</code></td>
<td>
<p>the weighting parameter for L1; then (1-w) is the weight for L0</p>
</td></tr>
<tr><td><code id="objFun_+3A_beta">beta</code></td>
<td>
<p>coefficients</p>
</td></tr>
<tr><td><code id="objFun_+3A_epsilon">epsilon</code></td>
<td>
<p>the continuity parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the value of the objective function evaluated at the given points.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(14)
beta    &lt;- c(3, 2, -1.6, -1)
noise   &lt;- 5
simData &lt;- SimData(N=100, beta=beta, noise=noise, corr=FALSE)

x  &lt;- as.matrix(simData[,-1][,1])
y  &lt;- as.matrix(simData$y)
betapoints &lt;- seq(-2,2,0.01)

lamda &lt;- 1
w     &lt;- 0.6
epsilon &lt;- 0.1

out &lt;- numeric(length(betapoints))
for(i in 1:length(betapoints)){
 out[i]&lt;- objFun(x, y, lamda=lamda, w=w, beta=betapoints[i], epsilon=epsilon)
}
plot(betapoints, out, type="l", ylab="objFun")

</code></pre>

<hr>
<h2 id='optimPenaLik'>Variable selection based on the combined penalty CL= (1-w)L0 + wL1</h2><span id='topic+optimPenaLik'></span>

<h3>Description</h3>

<p>Methods to use for optimization include Hooke-Jeeves derivative-free minimization algorithm (hjk),
or the BFGS method (modified Quasi-Newton). This method does variable selection by shrinking
the coefficients towards zero using the combined penalty (CL= (1-w)L0 + wL1).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimPenaLik(Data, lamda, w, standardize = TRUE, algorithms = c("QN",
  "hjk"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimPenaLik_+3A_data">Data</code></td>
<td>
<p>should have the following structure: the first column must be the response variable y</p>
</td></tr>
<tr><td><code id="optimPenaLik_+3A_lamda">lamda</code></td>
<td>
<p>tuning penalty parameter</p>
</td></tr>
<tr><td><code id="optimPenaLik_+3A_w">w</code></td>
<td>
<p>the weight parameter for the sum (1-w)L0+ wL1</p>
</td></tr>
<tr><td><code id="optimPenaLik_+3A_standardize">standardize</code></td>
<td>
<p>standardize Logical flag for x variable standardization, prior to fitting the model sequence.
The coefficients are always returned on the original scale. Default is standardize=TRUE</p>
</td></tr>
<tr><td><code id="optimPenaLik_+3A_algorithms">algorithms</code></td>
<td>
<p>select between BFGS ('QN') or Hooke-Jeeves (hjk) algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>it is recommended to use the tuneParam function to tune parameters lamda and w prior
using the optimPenaLik function.
</p>


<h3>Value</h3>

<p>a list with the shrinked coefficients and the names of the selected variables, i.e those variables with
estimated coefficient different from zero.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+optim">optim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># use the optimPenaLik function on a simulated dataset, with given lamda and w.
## Not run: 
set.seed(14)
beta    &lt;- c(3, 2, -1.6, -1)
noise   &lt;- 5
simData &lt;- SimData(N=100, beta=beta, noise=noise, corr=TRUE)

# use BFGS

before  &lt;- Sys.time()
PenalQN &lt;- optimPenaLik(Data=simData, lamda=1.5, w=0.7,
                     algorithms=c("QN"))
(tot &lt;- Sys.time()-before)
PenalQN


# use Hooke-Jeeves algorithm

before  &lt;- Sys.time()
Penalhjk &lt;- optimPenaLik(Data=simData, lamda=1.5, w=0.7,
                       algorithms=c("hjk"))
(totRun  &lt;- Sys.time() - before)
# total run of approx 0.25sec

Penalhjk

## End(Not run)

</code></pre>

<hr>
<h2 id='optimPenaLikL2'>Variable selection based on the combined penalty CL2= (1-w)L0 + wL2</h2><span id='topic+optimPenaLikL2'></span>

<h3>Description</h3>

<p>Methods to use for optimization include the
Hooke-Jeeves derivative-free minimization algorithm (hjk),
and the BFGS method (modified Quasi-Newton). This algorithm does variable selection
by shrinking the coefficients towards zero using the combined penalty (CL2= (1-w)L0 + wL2).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimPenaLikL2(Data, lamda, w, standardize = TRUE, algorithms = c("QN",
  "hjk"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimPenaLikL2_+3A_data">Data</code></td>
<td>
<p>should have the following structure: the first column must be the response variable y</p>
</td></tr>
<tr><td><code id="optimPenaLikL2_+3A_lamda">lamda</code></td>
<td>
<p>tuning penalty parameter</p>
</td></tr>
<tr><td><code id="optimPenaLikL2_+3A_w">w</code></td>
<td>
<p>the weight parameter for the sum (1-w)L0+ wL2</p>
</td></tr>
<tr><td><code id="optimPenaLikL2_+3A_standardize">standardize</code></td>
<td>
<p>standardize Logical flag for x variable standardization, prior to fitting the model sequence.
The coefficients are always returned on the original scale. Default is standardize=TRUE</p>
</td></tr>
<tr><td><code id="optimPenaLikL2_+3A_algorithms">algorithms</code></td>
<td>
<p>select between Simulated annealing or Differential evolution</p>
</td></tr>
</table>


<h3>Details</h3>

<p>it is recommended to use the tuneParam function to tune parameters lamda and w prior
using the optimPenaLik function.
</p>


<h3>Value</h3>

<p>a list with the shrinked coefficients and the names of the selected variables, i.e those variables with
estimated coefficient different from zero.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# use the optimPenaLik function on a simulated dataset, with given lamda and w.
set.seed(14)
beta    &lt;- c(3, 2, -1.6, -1)
noise   &lt;- 5
simData &lt;- SimData(N=100, beta=beta, noise=noise, corr=TRUE)

# example with Quasi-Newton:
before &lt;- Sys.time()
PenalQN &lt;- optimPenaLikL2(Data=simData, lamda=2, w=0.6,
                     algorithms=c("QN"))
after &lt;- Sys.time()
after-before
PenalQN

## End(Not run)

</code></pre>

<hr>
<h2 id='penalBrier'>Evaluation of the performance of risk prediction models with binary status response variable.</h2><span id='topic+penalBrier'></span>

<h3>Description</h3>

<p>Evaluation of the performance of risk prediction models with binary status response variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>penalBrier(Data, coeffP)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="penalBrier_+3A_data">Data</code></td>
<td>
<p>a data matrix; in the first column there should be the response variable y.
If you give the training dataset it will calculate the Brier score.</p>
</td></tr>
<tr><td><code id="penalBrier_+3A_coeffp">coeffP</code></td>
<td>
<p>a named vector of coefficients</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Brier score is a measure for classification performance of a binary classifier.
Its values range between [0,1] and the closest is to 0 the better the classifier is.
The area under the curve and the Brier score is used to summarize and compare the performance.
</p>


<h3>Value</h3>

<p>the Brier score (misclassification error)
</p>


<h3>References</h3>

<p>Brier, G. W. (1950). Verification of forecasts expressed in terms of probability.
Monthly Weather Review 78.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># use the penalBrier function on a simulated dataset, with given lamda and w.
## Not run: 
set.seed(14)
beta    &lt;- c(3, 2, -1.6, -4)
noise   &lt;- 5
simData &lt;- SimData(N=100,beta=beta, noise=noise, corr=FALSE)

before   &lt;- Sys.time()
stepPenal&lt;- StepPenal(Data=simData, lamda=1.2, w=0.4)
(totRun  &lt;- Sys.time() - before)

(coeff&lt;- stepPenal$coeffP)
 me &lt;- penalBrier(simData,coeff)

## End(Not run)
</code></pre>

<hr>
<h2 id='SimData'>Simulate data with normally distributed predictors and binary response</h2><span id='topic+SimData'></span>

<h3>Description</h3>

<p>Simulate data with normally distributed predictors and binary response
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SimData(N, beta, noise, corr = TRUE, corr.effect = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SimData_+3A_n">N</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="SimData_+3A_beta">beta</code></td>
<td>
<p>coefficients (effect of informative predictors)</p>
</td></tr>
<tr><td><code id="SimData_+3A_noise">noise</code></td>
<td>
<p>variables (effect of uninformative predictors)</p>
</td></tr>
<tr><td><code id="SimData_+3A_corr">corr</code></td>
<td>
<p>Logical, if FALSE the function generates uncorrelated predictors,
if TRUE  the correlation between predictors is 0.5 by default and the user can supply a different value in
the corr.effect argument.</p>
</td></tr>
<tr><td><code id="SimData_+3A_corr.effect">corr.effect</code></td>
<td>
<p>the correlation between informative predictors.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The response y follows a Binomial distribution with probability= exp(X*beta)/(1+exp(X*beta))
</p>


<h3>Value</h3>

<p>A data frame N x p, where p is the total number of informative and uninformative predictors.
The first column of the dataframe is the binary response variable y
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate data with N=100 (sample size) and 23 predictors; 4 informative and 20 noise

set.seed(14)
beta    &lt;- c(3, 2, -1.6, -4)
noise &lt;- 5
N     &lt;- 100
simData &lt;- SimData(N=N, beta=beta, noise=noise, corr=FALSE)

</code></pre>

<hr>
<h2 id='stepaic'>Stepwise forward variable selection based on the AIC criterion</h2><span id='topic+stepaic'></span>

<h3>Description</h3>

<p>It is a wrapper function over the step function in the buildin package stats
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stepaic(Data, standardize = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stepaic_+3A_data">Data</code></td>
<td>
<p>a data frame, as a first column should hava the response variable y</p>
</td></tr>
<tr><td><code id="stepaic_+3A_standardize">standardize</code></td>
<td>
<p>Logical flag for x variable standardization, prior to fitting the model sequence.
Default is standardize=TRUE</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with the coefficients of the final model.
It also returns the in-sample AUC and the Brier score
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+step">step</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(14)
beta    &lt;- c(3, 2, -1.6, -4)
noise   &lt;- 5
simData &lt;- SimData(N=100, beta=beta, noise=noise, corr=FALSE)

stepaicfit &lt;- stepaic(Data=simData)
stepaicfit

## End(Not run)
</code></pre>

<hr>
<h2 id='StepPenal'>Stepwise forward variable selection using penalized regression.</h2><span id='topic+StepPenal'></span>

<h3>Description</h3>

<p>Stepwise forward variable selection based on the combination of L1 and L0 penalties.
The optimization is done using the &quot;BFGS&quot; method in stats::optim
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StepPenal(Data, lamda, w, standardize = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StepPenal_+3A_data">Data</code></td>
<td>
<p>should have the following structure: the first column must be the binary response variable y.</p>
</td></tr>
<tr><td><code id="StepPenal_+3A_lamda">lamda</code></td>
<td>
<p>the tuning penalty parameter</p>
</td></tr>
<tr><td><code id="StepPenal_+3A_w">w</code></td>
<td>
<p>the weight parameter for the sum (1-w)L0+ wL1</p>
</td></tr>
<tr><td><code id="StepPenal_+3A_standardize">standardize</code></td>
<td>
<p>Logical flag for the predictors' standardization, prior to fitting the model.
Default is standardize=TRUE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>lamda and w  parameters need to be tuned by cross-Validation using stepPenal::tuneParam
</p>


<h3>Value</h3>

<p>a list with the shrinked coefficients and the names of the selected variables, i.e those variables with
an estimated coefficient different from zero. It also returns the value of the objective function, evaluated for the
values of the coefficients.
</p>


<h3>References</h3>

<p>Vradi E, Brannath W, Jaki T, Vonk R. Model selection based on combined penalties for biomarker
identification. Journal of biopharmaceutical statistics. 2018 Jul 4;28(4):735-49.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+optim">optim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># use the StepPenal function on a simulated dataset, with given lamda and w.

set.seed(14)
beta    &lt;- c(3, 2, -1.6, -1)
noise   &lt;- 5
simData &lt;- SimData(N=100, beta=beta, noise=noise, corr=FALSE)
## Not run: 
before &lt;- Sys.time()
stepPenal&lt;- StepPenal(Data=simData, lamda=1.5, w=0.3)
after &lt;- Sys.time()
after-before

(varstepPenal&lt;- stepPenal$coeffP)

## End(Not run)
</code></pre>

<hr>
<h2 id='StepPenalL2'>Stepwise forward variable selection using penalized regression.</h2><span id='topic+StepPenalL2'></span>

<h3>Description</h3>

<p>Stepwise forward variable selection based on the combination of L2 and L0 penalties.
The optimization is done using the &quot;BFGS&quot; method in stats::optim
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StepPenalL2(Data, lamda, w, standardize = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StepPenalL2_+3A_data">Data</code></td>
<td>
<p>should have the following structure: the first column must be the binary response variable y.</p>
</td></tr>
<tr><td><code id="StepPenalL2_+3A_lamda">lamda</code></td>
<td>
<p>the tuning penalty parameter</p>
</td></tr>
<tr><td><code id="StepPenalL2_+3A_w">w</code></td>
<td>
<p>the weight parameter for the sum (1-w)L0+ wL2</p>
</td></tr>
<tr><td><code id="StepPenalL2_+3A_standardize">standardize</code></td>
<td>
<p>Logical flag for the predictors' standardization, prior to fitting the model.
Default is standardize=TRUE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>lamda and w  parameters need to be tuned by cross-Validation using stepPenal::tuneParam
</p>


<h3>Value</h3>

<p>a list with the shrinked coefficients and the names of the selected variables, i.e those variables with
an estimated coefficient different from zero.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+optim">optim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># use the StepPenal function on a simulated dataset, with given lamda and w.

set.seed(14)
beta    &lt;- c(3, 2, -1.6, -1)
noise   &lt;- 5
simData &lt;- SimData(N=100, beta=beta, noise=noise, corr=TRUE)
## Not run: 
before &lt;- Sys.time()
stepPenalL2 &lt;- StepPenalL2(Data=simData, lamda=1.5, w=0.6)
after &lt;- Sys.time()
after-before

(varstepPenal&lt;- stepPenalL2$coeffP)

## End(Not run)
</code></pre>

<hr>
<h2 id='tuneParam'>Tune parameters w and lamda using the CL penalty</h2><span id='topic+tuneParam'></span>

<h3>Description</h3>

<p>Does k-fold cross-validation with the function optimPenalLik and returns
the values of lamda and w that maximize the area under the ROC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tuneParam(Data, nfolds = nfolds, grid, algorithm = c("hjk", "QN"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tuneParam_+3A_data">Data</code></td>
<td>
<p>a data frame, as a first column should have the response variable y and the other columns the predictors</p>
</td></tr>
<tr><td><code id="tuneParam_+3A_nfolds">nfolds</code></td>
<td>
<p>the number of folds used for cross-validation. OBS! nfolds&gt;=2</p>
</td></tr>
<tr><td><code id="tuneParam_+3A_grid">grid</code></td>
<td>
<p>a grid (data frame) with values of lamda and w that will be used for tuning
to tune the model. It is created by expand.grid see example below</p>
</td></tr>
<tr><td><code id="tuneParam_+3A_algorithm">algorithm</code></td>
<td>
<p>choose between BFGS (&quot;QN&quot;) and hjk (Hooke-Jeeves optimization free) to be used for optmization</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It supports the BFGS optimization method ('QN') from the optim stats function, the Hooke-Jeeves derivative-free
minimization algorithm ('hjk')
The value of lamda and w that yield the maximum AUC on the
cross-validating data set is selected.
</p>


<h3>Value</h3>

<p>A matrix with the following: the average (over folds) cross-validated AUC, the totalVariables selected on the training set,
and the standard deviation of the AUC over the nfolds.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(14)
beta    &lt;- c(3, 2, -1.6, -4)
noise   &lt;- 5
simData &lt;- SimData(N=100, beta=beta, noise=noise, corr=TRUE)

nfolds  &lt;- 3
grid &lt;- expand.grid(w = c( 0.3, 0.7),
                   lamda = c(1.5))

before &lt;- Sys.time()
paramCV &lt;- tuneParam(simData, nfolds, grid, algorithm=c("QN"))
(totalTime &lt;- Sys.time() - before)


maxAUC    &lt;- paramCV[which.max(paramCV$AUC),]$AUC
allmaxAUC &lt;- paramCV[which(paramCV$AUC==maxAUC),] # checks if the value of AUC
# is unique; if is not unique then it will take the combination of lamda and
# w where lamda has the largest value- thus achieving higher sparsity

runQN   &lt;- optimPenaLik(simData, lamda= allmaxAUC[nrow(allmaxAUC),]$lamda,
                         w= allmaxAUC[nrow(allmaxAUC),]$w,
                         algorithms=c("QN"))
(coefQN  &lt;- runQN$varQN)


# check the robustness of the choice of lamda

runQN2   &lt;- optimPenaLik(simData, lamda= allmaxAUC[1,]$lamda,
                         w= allmaxAUC[1,]$w,
                         algorithms=c("QN"))
(coefQN2  &lt;- runQN2$varQN)


## End(Not run)
</code></pre>

<hr>
<h2 id='tuneParamCL2'>Tune parameters w and lamda using the CL2 penalty</h2><span id='topic+tuneParamCL2'></span>

<h3>Description</h3>

<p>Does k-fold cross-validation with the function optimPenalLikL2 and returns
the values of lamda and w that maximize the area under the ROC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tuneParamCL2(Data, nfolds = nfolds, grid, algorithm = c("QN"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tuneParamCL2_+3A_data">Data</code></td>
<td>
<p>a data frame, as a first column should have the response variable y and the other columns the predictors</p>
</td></tr>
<tr><td><code id="tuneParamCL2_+3A_nfolds">nfolds</code></td>
<td>
<p>the number of folds used for cross-validation. OBS! nfolds&gt;=2</p>
</td></tr>
<tr><td><code id="tuneParamCL2_+3A_grid">grid</code></td>
<td>
<p>a grid (data frame) with values of lamda and w that will be used for tuning
to tune the model. It is created by expand.grid see example below</p>
</td></tr>
<tr><td><code id="tuneParamCL2_+3A_algorithm">algorithm</code></td>
<td>
<p>choose between BFGS (&quot;QN&quot;) and hjk (Hooke-Jeeves optimization free) to be used for optmization</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It supports the BFGS optimization method ('QN') from the optim stats function, the Hooke-Jeeves derivative-free
minimization algorithm ('hjk').
The value of lamda and w that yield the maximum AUC on the
cross-validating data set is selected. If more that one value of lamda nad w yield the same AUC,
then the biggest values of lamda and w are choosen.
</p>


<h3>Value</h3>

<p>A matrix with the following: the average (over folds) cross-validated AUC, the totalVariables selected on the training set,
and the standard deviation of the AUC over the nfolds
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
