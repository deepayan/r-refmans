<!DOCTYPE html><html lang="en"><head><title>Help for package msgps</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {msgps}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#msgps'>
<p>msgps (Degrees of Freedom of Elastic Net, Adaptive Lasso and Generalized Elastic Net)</p></a></li>
<li><a href='#plot.msgps'>
<p>plot the solution path from a &quot;msgps&quot; object.</p></a></li>
<li><a href='#predict.msgps'>
<p>make predictions from a &quot;msgps&quot; object.</p></a></li>
<li><a href='#summary.msgps'>
<p>A summary of  &quot;msgps&quot; object..</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Degrees of Freedom of Elastic Net, Adaptive Lasso and
Generalized Elastic Net</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3.5</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-10-20</td>
</tr>
<tr>
<td>Author:</td>
<td>Kei Hirose</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kei Hirose &lt;mail@keihirose.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Computes the degrees of freedom of the lasso,
        elastic net, generalized elastic net and adaptive lasso based
        on the generalized path seeking algorithm.  The optimal model
        can be selected by model selection criteria including Mallows'
        Cp, bias-corrected AIC (AICc), generalized cross validation
        (GCV) and BIC.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://keihirose.com/">https://keihirose.com/</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-10-20 08:52:44 UTC; hirosekei</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-10-20 17:12:43 UTC</td>
</tr>
</table>
<hr>
<h2 id='msgps'>
msgps (Degrees of Freedom of Elastic Net, Adaptive Lasso and Generalized Elastic Net)
</h2><span id='topic+msgps'></span><span id='topic+dfgps'></span><span id='topic+aicc.dfgps'></span><span id='topic+bic.dfgps'></span><span id='topic+cp.dfgps'></span><span id='topic+gcv.dfgps'></span><span id='topic+print.msgps'></span>

<h3>Description</h3>

<p>This package computes the degrees of freedom of the lasso, elastic net, generalized elastic net and adaptive lasso based on the generalized path seeking algorithm.  The optimal model can be selected by model selection criteria including Mallows' Cp, bias-corrected AIC (AICc), generalized cross validation (GCV) and BIC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>msgps(X,y,penalty="enet", alpha=0, gamma=1, lambda=0.001, tau2, STEP=20000, 
STEP.max=200000,  DFtype="MODIFIED",  p.max=300, intercept=TRUE, stand.coef=FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="msgps_+3A_x">X</code></td>
<td>

<p>predictor matrix
</p>
</td></tr>
<tr><td><code id="msgps_+3A_y">y</code></td>
<td>

<p>response vector
</p>
</td></tr>
<tr><td><code id="msgps_+3A_penalty">penalty</code></td>
<td>

<p>The penalty term.  The <code>"enet"</code> indicates the elastic net:
</p>
<p style="text-align: center;"><code class="reqn">\alpha/2||\beta||_2^2+(1-\alpha)||\beta||_1.</code>
</p>
 
<p>Note that <code>alpha=0</code> is the lasso penalty. The <code>"genet"</code> is the generalized elastic net: 
</p>
<p style="text-align: center;"><code class="reqn">log(\alpha+(1-\alpha)||\beta||_1).</code>
</p>
 
<p>The <code>"alasso"</code> is the adaptive lasso, which is a weighted version of the lasso given by
</p>
<p style="text-align: center;"><code class="reqn">w_i||\beta||_1,</code>
</p>

<p>where  <code class="reqn">w_i</code> is <code class="reqn">1/(\hat{\beta}_i)^{\gamma}</code>. Here <code class="reqn">\gamma&gt;0</code> is a tuning parameter, and <code class="reqn">\hat{\beta}_i</code> is the ridge estimate with regularization parameter being <code class="reqn">\lambda \ge 0</code>.  
</p>
</td></tr>
<tr><td><code id="msgps_+3A_alpha">alpha</code></td>
<td>

<p>The value of <code class="reqn">\alpha</code> on <code>"enet"</code> and <code>"genet"</code> penalty. 
</p>
</td></tr>
<tr><td><code id="msgps_+3A_gamma">gamma</code></td>
<td>

<p>The value of <code class="reqn">\gamma</code> on <code>"alasso"</code>. 
</p>
</td></tr>
<tr><td><code id="msgps_+3A_lambda">lambda</code></td>
<td>

<p>The value of  regularization parameter <code class="reqn">\lambda \ge 0</code> for ridge regression, which is used to calculate the weight vector of  <code>"alasso"</code> penalty.  Note that the ridge estimates can be ordinary least squared estimates when <code>lambda=0</code>.
</p>
</td></tr>
<tr><td><code id="msgps_+3A_tau2">tau2</code></td>
<td>

<p>Estimator of error variance for Mallows' Cp.  The default is the unbiased estimator of error vairance of the most complex model.  When the unbiased estimator of error vairance of the most complex model is not available (e.g., the number of variables exceeds the number of samples), <code>tau2</code> is the variance of response vector.
</p>
</td></tr>
<tr><td><code id="msgps_+3A_step">STEP</code></td>
<td>

<p>The approximate number of steps. 
</p>
</td></tr>
<tr><td><code id="msgps_+3A_step.max">STEP.max</code></td>
<td>

<p>The number of steps in this algorithm can often exceed <code>STEP</code>.  When the number of steps exceeds <code>STEP.max</code>, this algorithm stops.  
</p>
</td></tr>
<tr><td><code id="msgps_+3A_dftype">DFtype</code></td>
<td>

<p><code>"MODIFIED"</code> or <code>"NAIVE"</code>.  The <code>"MODIFIED"</code> update is much more efficient thatn <code>"NAIVE"</code> update.
</p>
</td></tr>
<tr><td><code id="msgps_+3A_p.max">p.max</code></td>
<td>

<p>If the number of selected variables exceeds <code>p.max</code>, the algorithm stops.
</p>
</td></tr>
<tr><td><code id="msgps_+3A_intercept">intercept</code></td>
<td>

<p>When intercept is <code>TRUE</code>, the result of intercept is included.
</p>
</td></tr>
<tr><td><code id="msgps_+3A_stand.coef">stand.coef</code></td>
<td>

<p>When stand.coef is <code>TRUE</code>, the standardized coefficient is displayed.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Kei Hirose<br />
<a href="mailto:mail@keihirose.com">mail@keihirose.com</a>
</p>


<h3>References</h3>

<p>Friedman, J. (2008).  Fast sparse regression and classification. <code class="reqn">Technical report</code>, Standford University.<br />
Hirose, K., Tateishi, S. and Konishi, S.. (2011).  Efficient algorithm to select tuning parameters in sparse regression modeling with regularization. arXiv:1109.2411 (arXiv).
</p>


<h3>See Also</h3>

<p><code>coef.msgps</code>, <code>plot.msgps</code>, <code>predict.msgps</code> and <code>summary.msgos</code> objects.</p>


<h3>Examples</h3>

<pre><code class='language-R'>#data
X &lt;- matrix(rnorm(100*8),100,8)
beta0 &lt;- c(3,1.5,0,0,2,0,0,0)
epsilon &lt;- rnorm(100,sd=3)
y &lt;- X %*% beta0 + epsilon
y &lt;- c(y)

#lasso
fit &lt;- msgps(X,y)
summary(fit) 
coef(fit) #extract coefficients at t selected by model selection criteria
coef(fit,c(0, 0.5, 2.5)) #extract coefficients at some values of t
predict(fit,X[1:10,]) #predict values at t selected by model selection criteria
predict(fit,X[1:10,],c(0, 0.5, 2.5)) #predict values at some values of t
plot(fit,criterion="cp") #plot the solution path with a model selected by Cp criterion

#elastic net
fit2 &lt;- msgps(X,y,penalty="enet",alpha=0.5)
summary(fit2) 

#generalized elastic net
fit3 &lt;- msgps(X,y,penalty="genet",alpha=0.5)
summary(fit3)

#adaptive lasso
fit4 &lt;- msgps(X,y,penalty="alasso",gamma=1,lambda=0)
summary(fit4)
</code></pre>

<hr>
<h2 id='plot.msgps'>
plot the solution path from a &quot;msgps&quot; object.
</h2><span id='topic+plot.msgps'></span><span id='topic+plot.df'></span>

<h3>Description</h3>

<p>This functions predicts fitted values from a &quot;msgps&quot; object.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'msgps'
plot(x, criterion="cp", xvar="norm", yvar="coef", yvar.dflasso=TRUE, 
stand.coef=TRUE, plot.step = 1000, col=TRUE,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.msgps_+3A_x">x</code></td>
<td>

<p>Fitted <code>"msgps"</code> model object.
</p>
</td></tr>
<tr><td><code id="plot.msgps_+3A_criterion">criterion</code></td>
<td>

<p>The code <code>criterion</code> plots the value of tuning parameter of each criterion (<code>"cp"</code>, <code>"aicc"</code>, <code>"gcv"</code>, <code>"bic"</code>).  The code <code>"none"</code> does not depict the tuning parameter.
</p>
</td></tr>
<tr><td><code id="plot.msgps_+3A_xvar">xvar</code></td>
<td>

<p>The type of x variable.   <code>"xvar=norm"</code> is max|beta|/|beta|, <code>"xvar=sum"</code> is max|beta|, <code>"xvar=step"</code> is the number of steps, and  <code>"xvar=t"</code> is tuning parameter.
</p>
</td></tr>
<tr><td><code id="plot.msgps_+3A_yvar">yvar</code></td>
<td>

<p>The type of y variable.   <code>"yvar=coef"</code> is the standardized coefficients, and  <code>"tvar=df"</code> is the degrees of freedom.  
</p>
</td></tr>
<tr><td><code id="plot.msgps_+3A_yvar.dflasso">yvar.dflasso</code></td>
<td>

<p>For lasso penalty, the degrees of freedom of the lasso (the number of non-zero parameters) is given when  <code>"yvar=df"</code> and <code>"yvar.dflasso=TRUE"</code>.
</p>
</td></tr>
<tr><td><code id="plot.msgps_+3A_stand.coef">stand.coef</code></td>
<td>

<p>The standardized coefficients and tuning parameters are dipicted if &quot;stand.coef=TRUE&quot;.
</p>
</td></tr>
<tr><td><code id="plot.msgps_+3A_plot.step">plot.step</code></td>
<td>

<p>The number of steps to plot the solution of df.  As <code>plot.step</code> increases, the picture will be well-looking whereas the file size of the picture will increase.
</p>
</td></tr>
<tr><td><code id="plot.msgps_+3A_col">col</code></td>
<td>

<p>The color option.</p>
</td></tr>
<tr><td><code id="plot.msgps_+3A_...">...</code></td>
<td>
<p>Other graphical parameters to plot</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The object returned depends on type.
</p>


<h3>Author(s)</h3>

<p>Kei Hirose<br />
<a href="mailto:mail@keihirose.com">mail@keihirose.com</a>
</p>


<h3>See Also</h3>

<p><code>coef.msgps</code>, <code>predict.msgps</code> and <code>summary.msgps</code> objects.</p>


<h3>Examples</h3>

<pre><code class='language-R'>#data
X &lt;- matrix(rnorm(100*8),100,8)
beta0 &lt;- c(3,1.5,0,0,2,0,0,0)
epsilon &lt;- rnorm(100,sd=3)
y &lt;- X %*% beta0 + epsilon
y &lt;- c(y)

#fit
fit &lt;- msgps(X,y)
plot(fit,criterion="cp") #plot the solution path with a model selected by Cp criterion
</code></pre>

<hr>
<h2 id='predict.msgps'>
make predictions from a &quot;msgps&quot; object.
</h2><span id='topic+predict.msgps'></span><span id='topic+coef.msgps'></span><span id='topic+coef.dfgps'></span><span id='topic+coef.step.dfgps'></span><span id='topic+coefmat.dfgps'></span>

<h3>Description</h3>

<p>This functions predicts fitted values via msgps function.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'msgps'
predict(object, X, tuning,...)
## S3 method for class 'msgps'
coef(object, tuning,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.msgps_+3A_object">object</code></td>
<td>

<p>Fitted <code>"msgps"</code> model object.
</p>
</td></tr>
<tr><td><code id="predict.msgps_+3A_x">X</code></td>
<td>

<p>Matrix of vector of new input <code>x</code>.
</p>
</td></tr>
<tr><td><code id="predict.msgps_+3A_tuning">tuning</code></td>
<td>

<p>Tuning  parameter vector <code>t</code> where predictions are required.  If <code>tuning</code> is missing, solutions selected by Cp, bias-corrected AIC (AICC), generalized cross validation (GCV) and BIC are displayed.</p>
</td></tr>
<tr><td><code id="predict.msgps_+3A_...">...</code></td>
<td>
<p>Other parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The object returned depends on type.
</p>


<h3>Author(s)</h3>

<p>Kei Hirose<br />
<a href="mailto:mail@keihirose.com">mail@keihirose.com</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#data
X &lt;- matrix(rnorm(100*8),100,8)
beta0 &lt;- c(3,1.5,0,0,2,0,0,0)
epsilon &lt;- rnorm(100,sd=3)
y &lt;- X %*% beta0 + epsilon
y &lt;- c(y)

#fit
fit &lt;- msgps(X,y)
coef(fit) #extract coefficients at t selected by model selection criteria
coef(fit,c(0, 0.5, 2.5)) #extract coefficients at some values of t
predict(fit,X[1:10,]) #predict values at t selected by model selection criteria
predict(fit,X[1:10,],c(0, 0.5, 2.5)) #predict values at some values of t
</code></pre>

<hr>
<h2 id='summary.msgps'>
A summary of  &quot;msgps&quot; object..
</h2><span id='topic+summary.msgps'></span>

<h3>Description</h3>

<p>This functions summarizes the &quot;msgps&quot; object.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'msgps'
summary(object, digits=max(3, getOption("digits") - 3), num.result = 20, 
coef.result=100,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.msgps_+3A_object">object</code></td>
<td>

<p>Fitted <code>"msgps"</code> model object.
</p>
</td></tr>
<tr><td><code id="summary.msgps_+3A_digits">digits</code></td>
<td>

<p>The digits of the output.
</p>
</td></tr>
<tr><td><code id="summary.msgps_+3A_num.result">num.result</code></td>
<td>

<p>The number of tuning parameter and the corresponding degrees of freedom displayed in this code. 
</p>
</td></tr>
<tr><td><code id="summary.msgps_+3A_coef.result">coef.result</code></td>
<td>

<p>If the coef.result exceeds the number of variables, the result of coefficient is not described in this code. 
</p>
</td></tr>
<tr><td><code id="summary.msgps_+3A_...">...</code></td>
<td>
<p>Other parameters on summary</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>df</code></td>
<td>
<p>The degrees of freedom for each tuning parameter.</p>
</td></tr>
<tr><td><code>tuning.max</code></td>
<td>
<p>Maximum value of tuning parameter.</p>
</td></tr>
<tr><td><code>ms.coef</code></td>
<td>
<p>The coefficient selected by each model selection criterion.</p>
</td></tr>
<tr><td><code>ms.tuning</code></td>
<td>
<p>The values of tuning parameter of models selected by each model selection criterion.</p>
</td></tr>
<tr><td><code>ms.df</code></td>
<td>
<p>The degerees of freedom selected of models each model selection criterion.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Kei Hirose<br />
<a href="mailto:mail@keihirose.com">mail@keihirose.com</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#data
X &lt;- matrix(rnorm(100*8),100,8)
beta0 &lt;- c(3,1.5,0,0,2,0,0,0)
epsilon &lt;- rnorm(100,sd=3)
y &lt;- X %*% beta0 + epsilon
y &lt;- c(y)

#fit
fit &lt;- msgps(X,y)
summary(fit) 
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
