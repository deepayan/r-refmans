<!DOCTYPE html><html><head><title>Help for package LaMa</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {LaMa}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#LaMa-package'><p>LaMa: Fast Numerical Maximum Likelihood Estimation for Latent Markov Models</p></a></li>
<li><a href='#calc_trackInd'><p>Calculate the index of the first observation of each track based on an ID variable</p></a></li>
<li><a href='#forward'><p><a href="https://www.taylorfrancis.com/books/mono/10.1201/b20790/hidden-markov-models-time-series-walter-zucchini-iain-macdonald-roland-langrock">Forward algorithm</a> with homogeneous transition probability matrix</p></a></li>
<li><a href='#forward_g'><p>General <a href="https://www.taylorfrancis.com/books/mono/10.1201/b20790/hidden-markov-models-time-series-walter-zucchini-iain-macdonald-roland-langrock">forward algorithm</a> with time-varying transition probability matrix</p></a></li>
<li><a href='#forward_p'><p><a href="https://www.taylorfrancis.com/books/mono/10.1201/b20790/hidden-markov-models-time-series-walter-zucchini-iain-macdonald-roland-langrock">Forward algorithm</a> with (only) periodically varying transition probability matrix</p></a></li>
<li><a href='#forward_s'><p><a href="https://www.taylorfrancis.com/books/mono/10.1201/b20790/hidden-markov-models-time-series-walter-zucchini-iain-macdonald-roland-langrock">Forward algorithm</a> for hidden semi-Markov models with homogeneous transition probability matrix</p></a></li>
<li><a href='#forward_sp'><p><a href="https://www.taylorfrancis.com/books/mono/10.1201/b20790/hidden-markov-models-time-series-walter-zucchini-iain-macdonald-roland-langrock">Forward algorithm</a> for hidden semi-Markov models with periodically varying transition probability matrices</p></a></li>
<li><a href='#stateprobs'><p>Calculate conditional local state probabilities for homogeneous HMMs</p></a></li>
<li><a href='#stateprobs_g'><p>Calculate conditional local state probabilities for inhomogeneous HMMs</p></a></li>
<li><a href='#stateprobs_p'><p>Calculate conditional local state probabilities for periodically inhomogeneous HMMs</p></a></li>
<li><a href='#stationary'><p>Compute the stationary distribution of a homogeneous Markov chain</p></a></li>
<li><a href='#stationary_p'><p>Compute the periodically stationary distribution of a periodically inhomogeneous Markov chain</p></a></li>
<li><a href='#tpm'><p>Build the transition probability matrix from unconstraint parameter vector</p></a></li>
<li><a href='#tpm_cont'><p>Calculation of continuous time transition probabilities</p></a></li>
<li><a href='#tpm_g'><p>Build all transition probability matrices of an inhomogeneous HMM</p></a></li>
<li><a href='#tpm_hsmm'><p>Build the transition probability matrix of an HSMM-approximating HMM</p></a></li>
<li><a href='#tpm_p'><p>Build all transition probability matrices of a periodically inhomogeneous HMM</p></a></li>
<li><a href='#tpm_phsmm'><p>Build all transition probability matrices of an periodic-HSMM-approximating HMM</p></a></li>
<li><a href='#tpm_thinned'><p>Compute the transition probability matrix of a thinned periodically inhomogeneous Markov chain.</p></a></li>
<li><a href='#trigBasisExp'><p>Trigonometric Basis Expansion</p></a></li>
<li><a href='#viterbi'><p>Viterbi algorithm for decoding states</p></a></li>
<li><a href='#viterbi_g'><p>Viterbi algorithm for decoding states of inhomogeneous HMMs</p></a></li>
<li><a href='#viterbi_p'><p>Viterbi algorithm for decoding states of periodically inhomogeneous HMMs</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Fast Numerical Maximum Likelihood Estimation for Latent Markov
Models</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Description:</td>
<td>
  The class of latent Markov models, including hidden Markov models, 
  hidden semi-Markov models, state space models, and point processes, is a very popular and powerful framework for inference of time series driven by latent processes. 
  Furthermore, all these models can be fitted using direct numerical maximum likelihood estimation using the so-called forward algorithm as discussed in 
  Zucchini et al. (2016) &lt;<a href="https://doi.org/10.1201%2Fb20790">doi:10.1201/b20790</a>&gt;.
  However, due to their great flexibility, researchers using these models in applied work often need to build highly customized models for which standard software implementation is lacking, 
  or the construction of such models in said software is as complicated as writing fully tailored 'R' code. 
  While providing greater flexibility and control, the latter suffers from slow estimation speeds that make custom solutions inconvenient. 
  We address the above issues in two ways. First, standard blocks of code, common to all these model classes, are implemented as simple-to-use functions that can be added like Lego blocks to an otherwise fully custom likelihood function, making writing custom code much easier. 
  Second, under the hood, these functions are written in 'C++', allowing for 10-20 times faster evaluation time, and thus drastically speeding up model estimation. 
  To aid in building fully custom likelihood functions, several vignettes are included that show how to simulate data from and estimate all the above model classes.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://janoleko.github.io/software/">https://janoleko.github.io/software/</a>,
<a href="https://github.com/janoleko/LaMa">https://github.com/janoleko/LaMa</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, mgcv</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat (&ge; 3.0.0), PHSMM</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-06-01 10:35:22 UTC; jan-ole</td>
</tr>
<tr>
<td>Author:</td>
<td>Jan-Ole Koslik <a href="https://orcid.org/0009-0004-1556-9053"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jan-Ole Koslik &lt;jan-ole.koslik@uni-bielefeld.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-06-04 09:47:46 UTC</td>
</tr>
</table>
<hr>
<h2 id='LaMa-package'>LaMa: Fast Numerical Maximum Likelihood Estimation for Latent Markov Models</h2><span id='topic+LaMa'></span><span id='topic+LaMa-package'></span>

<h3>Description</h3>

<p>The class of latent Markov models, including hidden Markov models, hidden semi-Markov models, state space models, and point processes, is a very popular and powerful framework for inference of time series driven by latent processes. Furthermore, all these models can be fitted using direct numerical maximum likelihood estimation using the so-called forward algorithm as discussed in Zucchini et al. (2016) <a href="https://doi.org/10.1201/b20790">doi:10.1201/b20790</a>. However, due to their great flexibility, researchers using these models in applied work often need to build highly customized models for which standard software implementation is lacking, or the construction of such models in said software is as complicated as writing fully tailored 'R' code. While providing greater flexibility and control, the latter suffers from slow estimation speeds that make custom solutions inconvenient. We address the above issues in two ways. First, standard blocks of code, common to all these model classes, are implemented as simple-to-use functions that can be added like Lego blocks to an otherwise fully custom likelihood function, making writing custom code much easier. Second, under the hood, these functions are written in 'C++', allowing for 10-20 times faster evaluation time, and thus drastically speeding up model estimation. To aid in building fully custom likelihood functions, several vignettes are included that show how to simulate data from and estimate all the above model classes.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Jan-Ole Koslik <a href="mailto:jan-ole.koslik@uni-bielefeld.de">jan-ole.koslik@uni-bielefeld.de</a> (<a href="https://orcid.org/0009-0004-1556-9053">ORCID</a>)
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://janoleko.github.io/software/">https://janoleko.github.io/software/</a>
</p>
</li>
<li> <p><a href="https://github.com/janoleko/LaMa">https://github.com/janoleko/LaMa</a>
</p>
</li></ul>


<hr>
<h2 id='calc_trackInd'>Calculate the index of the first observation of each track based on an ID variable</h2><span id='topic+calc_trackInd'></span>

<h3>Description</h3>

<p>Function to conveniently calculate the trackInd variable that is needed when fitting a model to longitudinal data with multiple tracks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_trackInd(ID)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calc_trackInd_+3A_id">ID</code></td>
<td>
<p>ID variable of track IDs that is of the same length as the data to be analyzed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Preferably, this function should not be used inside the likelihood function, as it may slow down the computation speed.
Instead, it can be called once and the result can then be passed as an argument to the likelihood function.
</p>


<h3>Value</h3>

<p>A vector of indices of the first observation of each track which can be passed to the forward and forward_g to sum likelihood contributions of each track
</p>


<h3>Examples</h3>

<pre><code class='language-R'>uniqueID = c("Animal1", "Animal2", "Animal3")
ID = rep(uniqueID, c(100, 200, 300))
trackInd = calc_trackInd(ID)
</code></pre>

<hr>
<h2 id='forward'><a href="https://www.taylorfrancis.com/books/mono/10.1201/b20790/hidden-markov-models-time-series-walter-zucchini-iain-macdonald-roland-langrock">Forward algorithm</a> with homogeneous transition probability matrix</h2><span id='topic+forward'></span>

<h3>Description</h3>

<p><a href="https://www.taylorfrancis.com/books/mono/10.1201/b20790/hidden-markov-models-time-series-walter-zucchini-iain-macdonald-roland-langrock">Forward algorithm</a> with homogeneous transition probability matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forward(delta, Gamma, allprobs, trackInd = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="forward_+3A_delta">delta</code></td>
<td>
<p>Initial or stationary distribution of length N, or matrix of dimension c(k,N) for k independent tracks, if trackInd is provided</p>
</td></tr>
<tr><td><code id="forward_+3A_gamma">Gamma</code></td>
<td>
<p>Transition probability matrix of dimension c(N,N), or array of k transition probability matrices of dimension c(N,N,k), if trackInd is provided.</p>
</td></tr>
<tr><td><code id="forward_+3A_allprobs">allprobs</code></td>
<td>
<p>Matrix of state-dependent probabilities/ density values of dimension c(n, N)</p>
</td></tr>
<tr><td><code id="forward_+3A_trackind">trackInd</code></td>
<td>
<p>Optional vector of length k containing the indices that correspond to the beginning of separate tracks. If provided, the total log-likelihood will be the sum of each track's likelihood contribution.
In this case, Gamma can be a matrix, leading to the same transition probabilities for each track, or an array of dimension c(N,N,k), with one (homogeneous) transition probability matrix for each track.
Furthermore, instead of a single vector delta corresponding to the initial distribution, a delta matrix of initial distributions, of dimension c(k,N), can be provided, such that each track starts with it's own initial distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Log-likelihood for given data and parameters
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generating data from homogeneous 2-state HMM
mu = c(0, 6)
sigma = c(2, 4)
Gamma = matrix(c(0.5, 0.05, 0.15, 0.85), nrow = 2, byrow = TRUE)
delta = c(0.5, 0.5)
# simulation
s = x = rep(NA, 500)
s[1] = sample(1:2, 1, prob = delta)
x[1] = rnorm(1, mu[s[1]], sigma[s[1]])
for(t in 2:500){
  s[t] = sample(1:2, 1, prob = Gamma[s[t-1],])
  x[t] = rnorm(1, mu[s[t]], sigma[s[t]])
}

## negative log likelihood function
mllk = function(theta.star, x){
  # parameter transformations for unconstraint optimization
  Gamma = tpm(theta.star[1:2])
  delta = stationary(Gamma) # stationary HMM
  mu = theta.star[3:4]
  sigma = exp(theta.star[5:6])
  # calculate all state-dependent probabilities
  allprobs = matrix(1, length(x), 2)
  for(j in 1:2){ allprobs[,j] = dnorm(x, mu[j], sigma[j]) }
  # return negative for minimization
  -forward(delta, Gamma, allprobs)
}

## fitting an HMM to the data
theta.star = c(-2,-2,0,5,log(2),log(3))
mod = stats::nlm(mllk, theta.star, x = x)

</code></pre>

<hr>
<h2 id='forward_g'>General <a href="https://www.taylorfrancis.com/books/mono/10.1201/b20790/hidden-markov-models-time-series-walter-zucchini-iain-macdonald-roland-langrock">forward algorithm</a> with time-varying transition probability matrix</h2><span id='topic+forward_g'></span>

<h3>Description</h3>

<p>General <a href="https://www.taylorfrancis.com/books/mono/10.1201/b20790/hidden-markov-models-time-series-walter-zucchini-iain-macdonald-roland-langrock">forward algorithm</a> with time-varying transition probability matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forward_g(delta, Gamma, allprobs, trackInd = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="forward_g_+3A_delta">delta</code></td>
<td>
<p>Initial distribution of length N, or matrix of dimension c(k,N) for k independent tracks, if trackInd is provided.</p>
</td></tr>
<tr><td><code id="forward_g_+3A_gamma">Gamma</code></td>
<td>
<p>Array of transition probability matrices of dimension c(N,N,n-1), as in a time series of length n, there are only n-1 transitions. 
If you provide an array of dimension c(N,N,n), the first slice will be ignored. <br />
</p>
<p>If the elements of <code class="reqn">\Gamma^{(t)}</code> depend on covariate values at t or covariates t+1 is your choice in the calculation of the array, prior to using this function.
When conducting the calculation by using tpm_g(), the choice comes down to including the covariate matrix Z[-1,] oder Z[-n,]. <br />
</p>
<p>If trackInd is provided, Gamma needs to be an array of dimension c(N,N,n), matching the number of rows of allprobs. For each track, the transition matrix at the beginning will be ignored.
If the parameters for Gamma are pooled across tracks or not, depends on your calculation of Gamma. If pooled, you can use tpm_g(Z, beta) to calculate the entire array of transition matrices when Z is of dimension c(n,p). <br />
</p>
<p>This function can also be used to fit continuous-time HMMs, where each array entry is the Markov semigroup <code class="reqn">\Gamma(\Delta t) = \exp(Q \Delta t)</code> and <code class="reqn">Q</code> is the generator of the continuous-time Markov chain.</p>
</td></tr>
<tr><td><code id="forward_g_+3A_allprobs">allprobs</code></td>
<td>
<p>Matrix of state-dependent probabilities/ density values of dimension c(n, N)</p>
</td></tr>
<tr><td><code id="forward_g_+3A_trackind">trackInd</code></td>
<td>
<p>Optional vector of length k containing the indices that correspond to the beginning of separate tracks. If provided, the total log-likelihood will be the sum of each track's likelihood contribution.
In this case, Gamma needs to be an array of dimension c(N,N,n), matching the number of rows of allprobs. For each track, the transition matrix at the beginning of the track will be ignored (as there is no transition between tracks).
Furthermore, instead of a single vector delta corresponding to the initial distribution, a delta matrix of initial distributions, of dimension c(k,N), can be provided, such that each track starts with it's own initial distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Log-likelihood for given data and parameters
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generating data from inhomogeneous 2-state HMM
mu = c(0, 6)
sigma = c(2, 4)
beta = matrix(c(-2,-2,0.5,-0.5),nrow=2)
delta = c(0.5, 0.5)
# simulation
n = 2000
s = x = rep(NA, n)
z = rnorm(n, 0, 2)
s[1] = sample(1:2, 1, prob = delta)
x[1] = rnorm(1, mu[s[1]], sigma[s[1]])
for(t in 2:n){
  Gamma = diag(2)
  Gamma[!Gamma] = exp(beta[,1]+beta[,2]*z[t])
  Gamma = Gamma / rowSums(Gamma)
  s[t] = sample(1:2, 1, prob = Gamma[s[t-1],])
  x[t] = rnorm(1, mu[s[t]], sigma[s[t]])
}

## negative log likelihood function
mllk = function(theta.star, x, z){
  # parameter transformations for unconstraint optimization
  beta = matrix(theta.star[1:4], 2, 2)
  Gamma = tpm_g(Z = z, beta = beta)
  delta = c(plogis(theta.star[5]), 1-plogis(theta.star[5]))
  mu = theta.star[6:7]
  sigma = exp(theta.star[8:9])
  # calculate all state-dependent probabilities
  allprobs = matrix(1, length(x), 2)
  for(j in 1:2){ allprobs[,j] = dnorm(x, mu[j], sigma[j]) }
  # return negative for minimization
  -forward_g(delta, Gamma, allprobs)
}

## fitting an HMM to the data
theta.star = c(-2,-2,1,-1,0,0,5,log(2),log(3))
mod = nlm(mllk, theta.star, x = x, z = z)

</code></pre>

<hr>
<h2 id='forward_p'><a href="https://www.taylorfrancis.com/books/mono/10.1201/b20790/hidden-markov-models-time-series-walter-zucchini-iain-macdonald-roland-langrock">Forward algorithm</a> with (only) periodically varying transition probability matrix</h2><span id='topic+forward_p'></span>

<h3>Description</h3>

<p>When the transition probability matrix only varies periodically (e.g. as a function of time of day), there are only <code class="reqn">L</code> unique matrices if <code class="reqn">L</code> is the period length (e.g. <code class="reqn">L=24</code> for hourly data and time-of-day variation).
Thus, it is much more efficient to only calculate these <code class="reqn">L</code> matrices and index them by a time variable (e.g. time of day or day of year) instead of calculating such a matrix for each index in the data set (which would be redundant).
This function allows for that, by only expecting a transition probability matrix for each time point in a period, and an integer valued (<code class="reqn">1, \dots, L</code>) time variable that maps the data index to the according time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forward_p(delta, Gamma, allprobs, tod)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="forward_p_+3A_delta">delta</code></td>
<td>
<p>Initial or periodically stationary distribution of length N</p>
</td></tr>
<tr><td><code id="forward_p_+3A_gamma">Gamma</code></td>
<td>
<p>Array of transition probability matrices of dimension c(N,N,L). <br /> <br />
Here we use the definition <code class="reqn">\Pr(S_t=j \mid S_{t-1}=i) = \gamma_{ij}^{(t)}</code>
such that the transition probabilities between time point <code class="reqn">t-1</code> and <code class="reqn">t</code> are an element of <code class="reqn">\Gamma^{(t)}</code>.</p>
</td></tr>
<tr><td><code id="forward_p_+3A_allprobs">allprobs</code></td>
<td>
<p>Matrix of state-dependent probabilities/ density values of dimension c(n, N)</p>
</td></tr>
<tr><td><code id="forward_p_+3A_tod">tod</code></td>
<td>
<p>(Integer valued) time variable in 1, ..., L, mapping the data index to a generalized time of day (length n).
For half-hourly data L = 48. It could, however, also be day of year for daily data and L = 365.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Log-likelihood for given data and parameters
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generating data from periodic 2-state HMM
mu = c(0, 6)
sigma = c(2, 4)
beta = matrix(c(-2,-2,1,-1, 1, -1),nrow=2)
delta = c(0.5, 0.5)
# simulation
n = 2000
s = x = rep(NA, n)
tod = rep(1:24, ceiling(2000/24))
s[1] = sample(1:2, 1, prob = delta)
x[1] = rnorm(1, mu[s[1]], sigma[s[1]])
# 24 unique t.p.m.s
Gamma = array(dim = c(2,2,24))
for(t in 1:24){
  G = diag(2)
  G[!G] = exp(beta[,1]+beta[,2]*sin(2*pi*t/24)+
    beta[,3]*cos(2*pi*t/24)) # trigonometric link
  Gamma[,,t] = G / rowSums(G)
}
for(t in 2:n){
  s[t] = sample(1:2, 1, prob = Gamma[s[t-1],,tod[t]])
  x[t] = rnorm(1, mu[s[t]], sigma[s[t]])
}
# we can also use function from LaMa to make building periodic tpms much easier
Gamma = tpm_p(1:24, 24, beta, degree = 1)

## negative log likelihood function
mllk = function(theta.star, x, tod){
  # parameter transformations for unconstraint optimization
  beta = matrix(theta.star[1:6], 2, 3)
  Gamma = tpm_p(tod=tod, L=24, beta=beta)
  delta = stationary_p(Gamma, t=tod[1])
  mu = theta.star[8:9]
  sigma = exp(theta.star[10:11])
  # calculate all state-dependent probabilities
  allprobs = matrix(1, length(x), 2)
  for(j in 1:2){ allprobs[,j] = dnorm(x, mu[j], sigma[j]) }
  # return negative for minimization
  -forward_p(delta, Gamma, allprobs, tod)
}

## fitting an HMM to the data
theta.star = c(-2,-2,1,-1,1,-1,0,0,5,log(2),log(3))
mod = nlm(mllk, theta.star, x = x, tod = tod)

</code></pre>

<hr>
<h2 id='forward_s'><a href="https://www.taylorfrancis.com/books/mono/10.1201/b20790/hidden-markov-models-time-series-walter-zucchini-iain-macdonald-roland-langrock">Forward algorithm</a> for hidden semi-Markov models with homogeneous transition probability matrix</h2><span id='topic+forward_s'></span>

<h3>Description</h3>

<p>Hidden semi-Markov models (HSMMs) are a flexible extension of HMMs. 
For direct numerical maximum likelhood estimation, HSMMs can be represented as HMMs on an enlarged state space (of size <code class="reqn">M</code>) and with structured transition probabilities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forward_s(delta, Gamma, allprobs, sizes)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="forward_s_+3A_delta">delta</code></td>
<td>
<p>Initial or stationary distribution of length M (where M is the number of approximating states)</p>
</td></tr>
<tr><td><code id="forward_s_+3A_gamma">Gamma</code></td>
<td>
<p>Transition probability matrix of dimension c(M,M)</p>
</td></tr>
<tr><td><code id="forward_s_+3A_allprobs">allprobs</code></td>
<td>
<p>Matrix of state-dependent probabilities/ density values of dimension c(n, N), where N is the number of semi-Markovian states.
This will automatically be converted to the appropriate dimension.</p>
</td></tr>
<tr><td><code id="forward_s_+3A_sizes">sizes</code></td>
<td>
<p>State aggregate sizes that are used for the approximation of the semi-Markov chain.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Log-likelihood for given data and parameters
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generating data from homogeneous 2-state HSMM
mu = c(0, 6)
lambda = c(6, 12)
omega = matrix(c(0,1,1,0), nrow = 2, byrow = TRUE)
# simulation
# for a 2-state HSMM the embedded chain always alternates between 1 and 2
s = rep(1:2, 100)
C = x = numeric(0)
for(t in 1:100){
  dt = rpois(1, lambda[s[t]])+1 # shifted Poisson
  C = c(C, rep(s[t], dt))
  x = c(x, rnorm(dt, mu[s[t]], 1.5)) # fixed sd 2 for both states
}

## negative log likelihood function
mllk = function(theta.star, x, sizes){
  # parameter transformations for unconstraint optimization
  omega = matrix(c(0,1,1,0), nrow = 2, byrow = TRUE) # omega fixed (2-states)
  lambda = exp(theta.star[1:2]) # dwell time means
  dm = list(dpois(1:sizes[1]-1, lambda[1]), dpois(1:sizes[2]-1, lambda[2]))
  Gamma = tpm_hsmm(omega, dm)
  delta = stationary(Gamma) # stationary
  mu = theta.star[3:4]
  sigma = exp(theta.star[5:6])
  # calculate all state-dependent probabilities
  allprobs = matrix(1, length(x), 2)
  for(j in 1:2){ allprobs[,j] = dnorm(x, mu[j], sigma[j]) }
  # return negative for minimization
  -forward_s(delta, Gamma, allprobs, sizes)
}

## fitting an HSMM to the data
theta.star = c(log(5), log(10), 1, 4, log(2), log(2))
mod = nlm(mllk, theta.star, x = x, sizes = c(20, 30), stepmax = 5)
</code></pre>

<hr>
<h2 id='forward_sp'><a href="https://www.taylorfrancis.com/books/mono/10.1201/b20790/hidden-markov-models-time-series-walter-zucchini-iain-macdonald-roland-langrock">Forward algorithm</a> for hidden semi-Markov models with periodically varying transition probability matrices</h2><span id='topic+forward_sp'></span>

<h3>Description</h3>

<p>Hidden semi-Markov models (HSMMs) are a flexible extension of HMMs. 
For direct numerical maximum likelhood estimation, HSMMs can be represented as HMMs on an enlarged state space (of size <code class="reqn">M</code>) and with structured transition probabilities such that approximate inference is possible.
Recently, this inference procedure has been generalized to allow either the dwell-time distributions or the conditional transition probabilities to depend on external covariates such as the time of day. This special case is implemented here.
This function allows for that, by expecting a transition probability matrix for each time point in a period, and an integer valued (<code class="reqn">1, \dots, L</code>) time variable that maps the data index to the according time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forward_sp(delta, Gamma, allprobs, sizes, tod)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="forward_sp_+3A_delta">delta</code></td>
<td>
<p>Initial or periodically stationary distribution of length M (where M is the number of approximating states)</p>
</td></tr>
<tr><td><code id="forward_sp_+3A_gamma">Gamma</code></td>
<td>
<p>Array of transition probability matrices of dimension c(M,M,L). <br /> <br />
Here we use the definition <code class="reqn">\Pr(S_t=j \mid S_{t-1}=i) = \gamma_{ij}^{(t)}</code>
such that the transition probabilities between time point <code class="reqn">t-1</code> and <code class="reqn">t</code> are an element of <code class="reqn">\Gamma^{(t)}</code>.</p>
</td></tr>
<tr><td><code id="forward_sp_+3A_allprobs">allprobs</code></td>
<td>
<p>Matrix of state-dependent probabilities/ density values of dimension c(n, N), where N is the number of semi-Markovian states.
This will automatically be converted to the appropriate dimension.</p>
</td></tr>
<tr><td><code id="forward_sp_+3A_sizes">sizes</code></td>
<td>
<p>State aggregate sizes that are used for the approximation of the semi-Markov chain.</p>
</td></tr>
<tr><td><code id="forward_sp_+3A_tod">tod</code></td>
<td>
<p>(Integer valued) time variable in 1, ..., L, mapping the data index to a generalized time of day (length n).
For half-hourly data L = 48. It could, however, also be day of year for daily data and L = 365.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Log-likelihood for given data and parameters
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generating data from homogeneous 2-state HSMM
mu = c(0, 6)
beta = matrix(c(log(4),log(6),-0.2,0.2,-0.1,0.4), nrow=2)
# time varying mean dwell time
Lambda = exp(cbind(1, trigBasisExp(1:24, 24, 1))%*%t(beta))
omega = matrix(c(0,1,1,0), nrow = 2, byrow = TRUE)
# simulation
# for a 2-state HSMM the embedded chain always alternates between 1 and 2
s = rep(1:2, 100)
C = x = numeric(0)
tod = rep(1:24, 50) # time of day variable
time = 1
for(t in 1:100){
  dt = rpois(1, Lambda[tod[time], s[t]])+1 # dwell time depending on time of day
  time = time + dt
  C = c(C, rep(s[t], dt))
  x = c(x, rnorm(dt, mu[s[t]], 1.5)) # fixed sd 2 for both states
}
tod = tod[1:length(x)]

## negative log likelihood function
mllk = function(theta.star, x, sizes, tod){
  # parameter transformations for unconstraint optimization
  omega = matrix(c(0,1,1,0), nrow = 2, byrow = TRUE) # omega fixed (2-states)
  mu = theta.star[1:2]
  sigma = exp(theta.star[3:4])
  beta = matrix(theta.star[5:10], nrow=2)
  # time varying mean dwell time
  Lambda = exp(cbind(1, trigBasisExp(1:24, 24, 1))%*%t(beta))
  dm = list()
  for(j in 1:2){
    dm[[j]] = sapply(1:sizes[j]-1, dpois, lambda = Lambda[,j])
  }
  Gamma = tpm_phsmm(omega, dm)
  delta = stationary_p(Gamma, tod[1])
  # calculate all state-dependent probabilities
  allprobs = matrix(1, length(x), 2)
  for(j in 1:2){ allprobs[,j] = dnorm(x, mu[j], sigma[j]) }
  # return negative for minimization
  -forward_sp(delta, Gamma, allprobs, sizes, tod)
}

## fitting an HSMM to the data
theta.star = c(1, 4, log(2), log(2), # state-dependent parameters
                 log(4), log(6), rep(0,4)) # state process parameters dm
mod = nlm(mllk, theta.star, x = x, sizes = c(10, 15), tod = tod, stepmax = 5)
</code></pre>

<hr>
<h2 id='stateprobs'>Calculate conditional local state probabilities for homogeneous HMMs</h2><span id='topic+stateprobs'></span>

<h3>Description</h3>

<p>Computes <br /> <br />
<code class="reqn">\Pr(S_t = j \mid X_1, ..., X_T)</code> <br /> <br />
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stateprobs(delta, Gamma, allprobs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stateprobs_+3A_delta">delta</code></td>
<td>
<p>Initial or stationary distribution of length N</p>
</td></tr>
<tr><td><code id="stateprobs_+3A_gamma">Gamma</code></td>
<td>
<p>Transition probability matrix of dimension c(N,N)</p>
</td></tr>
<tr><td><code id="stateprobs_+3A_allprobs">allprobs</code></td>
<td>
<p>Matrix of state-dependent probabilities/ density values of dimension c(n, N)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix of conditional state probabilities of dimension c(n,N)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Gamma = tpm(c(-1,-2))
delta = stationary(Gamma)
allprobs = matrix(runif(200), nrow = 100, ncol = 2)

probs = stateprobs(delta, Gamma, allprobs)
</code></pre>

<hr>
<h2 id='stateprobs_g'>Calculate conditional local state probabilities for inhomogeneous HMMs</h2><span id='topic+stateprobs_g'></span>

<h3>Description</h3>

<p>Computes <br /> <br />
<code class="reqn">\Pr(S_t = j \mid X_1, ..., X_T)</code> <br /> <br />
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stateprobs_g(delta, Gamma, allprobs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stateprobs_g_+3A_delta">delta</code></td>
<td>
<p>Initial distribution of length N</p>
</td></tr>
<tr><td><code id="stateprobs_g_+3A_gamma">Gamma</code></td>
<td>
<p>Array of transition probability matrices of dimension c(N,N,n-1), as in a time series of length n, there are only n-1 transitions.</p>
</td></tr>
<tr><td><code id="stateprobs_g_+3A_allprobs">allprobs</code></td>
<td>
<p>Matrix of state-dependent probabilities/ density values of dimension c(n, N)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix of conditional state probabilities of dimension c(n,N)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Gamma = tpm_g(runif(99), matrix(c(-1,-1,1,-2), nrow = 2, byrow = TRUE))
delta = c(0.5, 0.5)
allprobs = matrix(runif(200), nrow = 100, ncol = 2)

probs = stateprobs_g(delta, Gamma, allprobs)
</code></pre>

<hr>
<h2 id='stateprobs_p'>Calculate conditional local state probabilities for periodically inhomogeneous HMMs</h2><span id='topic+stateprobs_p'></span>

<h3>Description</h3>

<p>Computes <br /> <br />
<code class="reqn">\Pr(S_t = j \mid X_1, ..., X_T)</code> <br /> <br />
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stateprobs_p(delta, Gamma, allprobs, tod)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stateprobs_p_+3A_delta">delta</code></td>
<td>
<p>Initial or periodically stationary distribution of length N</p>
</td></tr>
<tr><td><code id="stateprobs_p_+3A_gamma">Gamma</code></td>
<td>
<p>Array of transition probability matrices of dimension c(N,N,L) where L is the cycle length. <br /> <br />
Here we use the definition <code class="reqn">\Pr(S_t=j \mid S_{t-1}=i) = \gamma_{ij}^{(t)}</code>
such that the transition probabilities between time point <code class="reqn">t-1</code> and <code class="reqn">t</code> are an element of <code class="reqn">\Gamma^{(t)}</code>.</p>
</td></tr>
<tr><td><code id="stateprobs_p_+3A_allprobs">allprobs</code></td>
<td>
<p>Matrix of state-dependent probabilities/ density values of dimension c(n, N)</p>
</td></tr>
<tr><td><code id="stateprobs_p_+3A_tod">tod</code></td>
<td>
<p>(Integer valued) time variable in 1, ..., L, mapping the data index to a generalized time of day (length n).
For half-hourly data L = 48. It could, however, also be day of year for daily data and L = 365.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix of conditional state probabilities of dimension c(n,N)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>L = 24
beta = matrix(c(-1, 2, -1, -2, 1, -1), nrow = 2, byrow = TRUE)
Gamma = tpm_p(1:L, L, beta, degree = 1)
delta = stationary_p(Gamma, 1)
allprobs = matrix(runif(200), nrow = 100, ncol = 2)
tod = rep(1:24, 5)[1:100]

probs = stateprobs_p(delta, Gamma, allprobs, tod)
</code></pre>

<hr>
<h2 id='stationary'>Compute the stationary distribution of a homogeneous Markov chain</h2><span id='topic+stationary'></span>

<h3>Description</h3>

<p>A homogeneous, finite state Markov chain that is irreducible and aperiodic converges to a unique stationary distribution, here called <code class="reqn">\delta</code>.
As it is stationary, this distribution satisfies <br /> <br />
<code class="reqn">\delta \Gamma = \delta</code>, subject to <code class="reqn">\sum_{j=1}^N \delta_j = 1</code>, <br /> <br />
where <code class="reqn">\Gamma</code> is the transition probability matrix. 
This function solves the linear system of equations above.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stationary(Gamma, tol = .Machine$double.eps)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stationary_+3A_gamma">Gamma</code></td>
<td>
<p>Transition probability matrix of dimension c(N,N)</p>
</td></tr>
<tr><td><code id="stationary_+3A_tol">tol</code></td>
<td>
<p>The tolerance for detecting linear dependencies in the columns of Gamma. The default is .Machine$double.eps.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Stationary distribution of the Markov chain with the given transition probability matrix
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Gamma = tpm(c(rep(-2,3), rep(-3,3)))
delta = stationary(Gamma)
</code></pre>

<hr>
<h2 id='stationary_p'>Compute the periodically stationary distribution of a periodically inhomogeneous Markov chain</h2><span id='topic+stationary_p'></span>

<h3>Description</h3>

<p>If the transition probability matrix of an inhomogeneous Markov chain varies only periodically (with period length <code class="reqn">L</code>), it converges to a so-called periodically stationary distribution. 
This happens, because the thinned Markov chain, which has a full cycle as each time step, has homogeneous transition probability matrix <br /><br />
<code class="reqn">\Gamma_t = \Gamma^{(t)} \Gamma^{(t+1)} \dots \Gamma^{(t+L-1)}</code> for all <code class="reqn">t = 1, \dots, L</code>. <br /> <br />
The stationary distribution for time <code class="reqn">t</code> satifies <code class="reqn">\delta^{(t)} \Gamma_t = \delta^{(t)}</code>. <br />
This function calculates the periodically stationary distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stationary_p(Gamma, t = NULL, tol = .Machine$double.eps)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stationary_p_+3A_gamma">Gamma</code></td>
<td>
<p>Array of transition probability matrices of dimension c(N,N,L).</p>
</td></tr>
<tr><td><code id="stationary_p_+3A_t">t</code></td>
<td>
<p>Integer index of the time point in the cycle, for which to calculate the stationary distribution
If t is not provided, the function calculates all stationary distributions for each time point in the cycle.</p>
</td></tr>
<tr><td><code id="stationary_p_+3A_tol">tol</code></td>
<td>
<p>The tolerance for detecting linear dependencies in the columns of the thinned transition matrix. The default is .Machine$double.eps.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Either the periodically stationary distribution at time t or all periodically stationary distributions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>L = 24
beta = matrix(c(-1, 2, -1, -2, 1, -1), nrow = 2, byrow = TRUE)
Gamma = tpm_p(1:L, L, beta, degree = 1)
# Periodically stationary distribution for specific time point
delta = stationary_p(Gamma, 4)

# All periodically stationary distributions
Delta = stationary_p(Gamma)
</code></pre>

<hr>
<h2 id='tpm'>Build the transition probability matrix from unconstraint parameter vector</h2><span id='topic+tpm'></span>

<h3>Description</h3>

<p>This function builds the transition probability matrix from an unconstraint parameter vector. 
For each row of the matrix, the inverse multinomial logistic link is applied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tpm(param, byrow = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tpm_+3A_param">param</code></td>
<td>
<p>Unconstraint parameter vector of length N*(N-1) where N is the number of states of the Markov chain</p>
</td></tr>
<tr><td><code id="tpm_+3A_byrow">byrow</code></td>
<td>
<p>Logical that indicates if the transition probability matrix should be filled by row. 
Defaults to FALSE, but should be set to TRUE if one wants to work with a matrix of beta parameters returned by popular HMM packages like moveHMM, momentuHMM, or hmmTMB.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Transition probability matrix of dimension c(N,N)
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 2 states: 2 free off-diagonal elements
param1 = rep(-1, 2)
Gamma1 = tpm(param1)

# 3 states: 6 free off-diagonal elements
param2 = rep(-2, 6)
Gamma2 = tpm(param2)
</code></pre>

<hr>
<h2 id='tpm_cont'>Calculation of continuous time transition probabilities</h2><span id='topic+tpm_cont'></span>

<h3>Description</h3>

<p>A continuous-time Markov chain is described by an infinitesimal generator matrix <code class="reqn">Q</code>. 
When observing data at time points <code class="reqn">t_1, \dots, t_n</code> the transition probabilites between <code class="reqn">t_i</code> and <code class="reqn">t_{i+1}</code> are caluclated as <br /> <br />
<code class="reqn">\Gamma(\Delta t_i) = \exp(Q \Delta t_i)</code>, <br /> <br />
where <code class="reqn">\exp()</code> is the matrix exponential. The mapping <code class="reqn">\Gamma(\Delta t)</code> is also called the Markov semigroup.
This function calculates all transition matrices based on a given generator and time differences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tpm_cont(Q, timediff)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tpm_cont_+3A_q">Q</code></td>
<td>
<p>Infinitesimal generator matrix of the continuous-time Markov chain of dimension c(N,N)</p>
</td></tr>
<tr><td><code id="tpm_cont_+3A_timediff">timediff</code></td>
<td>
<p>Time differences between observations of length n-1 when based on n observations</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An array of transition matrices of dimension c(N,N,n-1)
</p>


<h3>Examples</h3>

<pre><code class='language-R'># building a Q matrix for a 3-state cont.-time Markov chain
Q = diag(3)
Q[!Q] = rexp(6)
diag(Q) = 0
diag(Q) = - rowSums(Q)

# draw time differences
timediff = rexp(1000, 10)

Gamma = tpm_cont(Q, timediff)
</code></pre>

<hr>
<h2 id='tpm_g'>Build all transition probability matrices of an inhomogeneous HMM</h2><span id='topic+tpm_g'></span>

<h3>Description</h3>

<p>In an HMM, we can model the influence of covariates on the state process, by linking them to the transition probabiltiy matrix. 
Most commonly, this is done by specifying a linear predictor <br /> <br />
<code class="reqn"> \eta_{ij}^{(t)} = \beta^{(ij)}_0 + \beta^{(ij)}_1 z_{t1} + \dots + \beta^{(ij)}_p z_{tp} </code> <br /> <br />
for each off-diagonal element (<code class="reqn">i \neq j</code>) and then applying the inverse multinomial logistic link to each row.
This function efficiently calculates all transition probabilty matrices for a given design matrix <code class="reqn">Z</code> and parameter matrix beta.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tpm_g(Z, beta, byrow = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tpm_g_+3A_z">Z</code></td>
<td>
<p>Covariate design matrix (excluding intercept column) of dimension c(n, p), where p can also be one (i.e. Z can be a vector).</p>
</td></tr>
<tr><td><code id="tpm_g_+3A_beta">beta</code></td>
<td>
<p>Matrix of coefficients for the off-diagonal elements of the transition probability matrix.
Needs to be of dimension c(N*(N-1), p+1), where the first column contains the intercepts.</p>
</td></tr>
<tr><td><code id="tpm_g_+3A_byrow">byrow</code></td>
<td>
<p>Logical that indicates if each transition probability matrix should be filled by row. 
Defaults to FALSE, but should be set to TRUE if one wants to work with a matrix of beta parameters returned by popular HMM packages like moveHMM, momentuHMM, or hmmTMB.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Array of transition probability matrices of dimension c(N,N,n)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 1000
Z = matrix(runif(n*2), ncol = 2)
beta = matrix(c(-1, 1, 2, -2, 1, -2), nrow = 2, byrow = TRUE)
Gamma = tpm_g(Z, beta)
</code></pre>

<hr>
<h2 id='tpm_hsmm'>Build the transition probability matrix of an HSMM-approximating HMM</h2><span id='topic+tpm_hsmm'></span>

<h3>Description</h3>

<p>Hidden semi-Markov models (HSMMs) are a flexible extension of HMMs. 
For direct numerical maximum likelhood estimation, HSMMs can be represented as HMMs on an enlarged state space (of size <code class="reqn">M</code>) and with structured transition probabilities.
This function computes the transition matrix of an HSMM.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tpm_hsmm(omega, dm, eps = 1e-10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tpm_hsmm_+3A_omega">omega</code></td>
<td>
<p>Embedded transition probability matrix of dimension c(N,N)</p>
</td></tr>
<tr><td><code id="tpm_hsmm_+3A_dm">dm</code></td>
<td>
<p>State dwell-time distributions arranged in a list of length(N). Each list element needs to be a vector of length N_i, where N_i is the state aggregate size.</p>
</td></tr>
<tr><td><code id="tpm_hsmm_+3A_eps">eps</code></td>
<td>
<p>Rounding value: If an entry of the transition probabily matrix is smaller, than it is rounded to zero.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The extended-state-space transition probability matrix of the approximating HMM
</p>


<h3>Examples</h3>

<pre><code class='language-R'># building the t.p.m. of the embedded Markov chain
omega = matrix(c(0,1,1,0), nrow = 2, byrow = TRUE)
# defining state aggregate sizes
sizes = c(20, 30)
# defining state dwell-time distributions
lambda = c(5, 11)
dm = list(dpois(1:sizes[1]-1, lambda[1]), dpois(1:sizes[2]-1, lambda[2]))
# calculating extended-state-space t.p.m.
Gamma = tpm_hsmm(omega, dm)
</code></pre>

<hr>
<h2 id='tpm_p'>Build all transition probability matrices of a periodically inhomogeneous HMM</h2><span id='topic+tpm_p'></span>

<h3>Description</h3>

<p>Given a periodically varying variable such as time of day or day of year and the associated cycle length, 
this function calculates the transition probability matrices by applying the inverse multinomial logistic link to linear predictors of the form <br /> <br />
<code class="reqn"> 
 \eta^{(t)}_{ij} = \beta_0^{(ij)} + \sum_{k=1}^K \bigl( \beta_{1k}^{(ij)} \sin(\frac{2 \pi k t}{L}) + \beta_{2k}^{(ij)} \cos(\frac{2 \pi k t}{L}) \bigr) </code> <br /> <br />
for the off-diagonal elements (<code class="reqn">i \neq j</code>).
This is relevant for modeling e.g. diurnal variation and the flexibility can be increased by adding smaller frequencies (i.e. increasing <code class="reqn">K</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tpm_p(tod = 1:24, L = 24, beta, degree = 1, Z = NULL, byrow = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tpm_p_+3A_tod">tod</code></td>
<td>
<p>Equidistant (generalized) time of day sequence, denoting the time point in a cycle.
For time of day and e.g. half-hourly data, this could be 1, ..., L and L = 48, or 0.5, 1, 1.5, ..., 24 and L = 24.</p>
</td></tr>
<tr><td><code id="tpm_p_+3A_l">L</code></td>
<td>
<p>Length of one full cycle, on the scale of tod</p>
</td></tr>
<tr><td><code id="tpm_p_+3A_beta">beta</code></td>
<td>
<p>Matrix of coefficients for the off-diagonal elements of the transition probability matrix.
Needs to be of dimension c(N*(N-1), 2*degree+1), where the first column contains the intercepts.</p>
</td></tr>
<tr><td><code id="tpm_p_+3A_degree">degree</code></td>
<td>
<p>Degree of the trigonometric link function. For each additional degree, one sine and one cosine frequency are added.</p>
</td></tr>
<tr><td><code id="tpm_p_+3A_z">Z</code></td>
<td>
<p>Pre-calculated design matrix (excluding intercept column). Defaults to NULL if trigonometric link should be calculated. 
From an efficiency perspective, Z should be pre-calculated within the likelhood function, as the basis expansion should not be redundantly calculated. This can be done by using trigBasisExpansion(). <br /> <br />
Furthermore, Z can also be a pre-calculated design matrix from mgcv::cSplineDes() (with p columns), when one wants to use cyclic P-splines, or it can be any other basis expansion of the cyclic variable.
In that case, the dimension of beta needs to be c(N*(N-1), p+1) and a penalty term should be added at the end of the negative log-likelihood.</p>
</td></tr>
<tr><td><code id="tpm_p_+3A_byrow">byrow</code></td>
<td>
<p>Logical that indicates if each transition probability matrix should be filled by row. 
Defaults to FALSE, but should be set to TRUE if one wants to work with a matrix of beta parameters returned by popular HMM packages like moveHMM, momentuHMM, or hmmTMB.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Array of transition probability matrices of dimension c(N,N,length(tod))
</p>


<h3>Examples</h3>

<pre><code class='language-R'># hourly data 
tod = seq(1, 24, by = 1)
L = 24
beta = matrix(c(-1, 2, -1, -2, 1, -1), nrow = 2, byrow = TRUE)
Gamma = tpm_p(tod, L, beta, degree = 1)

# half-hourly data
## integer tod sequence
tod = seq(1, 48, by = 1)
L = 48
beta = matrix(c(-1, 2, -1, -2, 1, -1), nrow = 2, byrow = TRUE)
Gamma1 = tpm_p(tod, L, beta, degree = 1)

## equivalent specification
tod = seq(0.5, 24, by = 0.5)
L = 24
beta = matrix(c(-1, 2, -1, -2, 1, -1), nrow = 2, byrow = TRUE)
Gamma2 = tpm_p(tod, L, beta, degree = 1)

Gamma1-Gamma2 # same result

# cubic P-splines
set.seed(123)
nk = 8 # number of basis functions
tod = seq(0.5, 24, by = 0.5)
L = 24
k = L * 0:nk / nk # equidistant knots
Z = mgcv::cSplineDes(tod, k) ## cyclic spline design matrix
beta = matrix(c(-1, runif(8, -2, 2), # 9 parameters per off-diagonal element
                 -2, runif(8, -2, 2)), nrow = 2, byrow = TRUE)
Gamma = tpm_p(tod, L, beta, Z = Z)
</code></pre>

<hr>
<h2 id='tpm_phsmm'>Build all transition probability matrices of an periodic-HSMM-approximating HMM</h2><span id='topic+tpm_phsmm'></span>

<h3>Description</h3>

<p>Hidden semi-Markov models (HSMMs) are a flexible extension of HMMs. For direct numerical maximum likelhood estimation, HSMMs can be represented as HMMs on an enlarged state space (of size <code class="reqn">M</code>) and with structured transition probabilities.
This function computes the transition matrices of a periodically inhomogeneos HSMMs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tpm_phsmm(omega, dm, eps = 1e-10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tpm_phsmm_+3A_omega">omega</code></td>
<td>
<p>Embedded transition probability matrix.
Either a matrix of dimension c(N,N) for homogeneous conditional transition probabilities, or an array of dimension c(N,N,L) for inhomogeneous conditional transition probabilities.</p>
</td></tr>
<tr><td><code id="tpm_phsmm_+3A_dm">dm</code></td>
<td>
<p>State dwell-time distributions arranged in a list of length(N).
Each list element needs to be a matrix of dimension c(L, N_i), where each row t is the (approximate) probability mass function of state i at time t.</p>
</td></tr>
<tr><td><code id="tpm_phsmm_+3A_eps">eps</code></td>
<td>
<p>Rounding value: If an entry of the transition probabily matrix is smaller, than it is rounded to zero.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An array of dimension c(N,N,L), containing the extended-state-space transition probability matrices of the approximating HMM for each time point of the cycle.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>N = 3
L = 24
# time-varying mean dwell times
Lambda = exp(matrix(rnorm(L*N, 2, 0.5), nrow = L))
sizes = c(25, 25, 25) # approximating chain with 75 states
# state dwell-time distributions
dm = list()
for(i in 1:3){
  dmi = matrix(nrow = L, ncol = sizes[i])
  for(t in 1:L){
    dmi[t,] = dpois(1:sizes[i]-1, Lambda[t,i])
  }
  dm[[i]] = dmi
}

## homogeneous conditional transition probabilites
# diagonal elements are zero, rowsums are one
omega = matrix(c(0,0.5,0.5,0.2,0,0.8,0.7,0.3,0), nrow = N, byrow = TRUE)

# calculating extended-state-space t.p.m.s
Gamma = tpm_phsmm(omega, dm)

## inhomogeneous conditional transition probabilites
# omega can be an array
omega = array(rep(omega,L), dim = c(N,N,L))
omega[1,,4] = c(0, 0.2, 0.8) # small change for inhomogeneity

# calculating extended-state-space t.p.m.s
Gamma = tpm_phsmm(omega, dm)
</code></pre>

<hr>
<h2 id='tpm_thinned'>Compute the transition probability matrix of a thinned periodically inhomogeneous Markov chain.</h2><span id='topic+tpm_thinned'></span>

<h3>Description</h3>

<p>If the transition probability matrix of an inhomogeneous Markov chain varies only periodically (with period length <code class="reqn">L</code>), it converges to a so-called periodically stationary distribution. 
This happens, because the thinned Markov chain, which has a full cycle as each time step, has homogeneous transition probability matrix <br /><br />
<code class="reqn">\Gamma_t = \Gamma^{(t)} \Gamma^{(t+1)} \dots \Gamma^{(t+L-1)}</code> for all <code class="reqn">t = 1, \dots, L</code>. <br /> <br />
This function calculates the matrix above efficiently as a preliminery step to calculating the periodically stationary distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tpm_thinned(Gamma, t)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tpm_thinned_+3A_gamma">Gamma</code></td>
<td>
<p>Array of transition probability matrices of dimension c(N,N,L).</p>
</td></tr>
<tr><td><code id="tpm_thinned_+3A_t">t</code></td>
<td>
<p>Integer index of the time point in the cycle, for which to calculate the thinned transition probility matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Thinned transition probabilty matrix of dimension c(N,N)
</p>


<h3>Examples</h3>

<pre><code class='language-R'># setting parameters for trigonometric link
beta = matrix(c(-1, -2, 2, -1, 2, -4), nrow = 2, byrow = TRUE)
# building trigonometric design matrix
Z = cbind(1,trigBasisExp(1:24, 24, 1))
# calculating all 24 linear predictor vectors
Eta = Z%*%t(beta)
# building all 24 t.p.m.s
Gamma = array(dim = c(2,2,24))
for(t in 1:24){
  Gamma[,,t] = tpm(Eta[t,])
}
# calculating 
tpm_thinned(Gamma, 4)
</code></pre>

<hr>
<h2 id='trigBasisExp'>Trigonometric Basis Expansion</h2><span id='topic+trigBasisExp'></span>

<h3>Description</h3>

<p>Given a periodically varying variable such as time of day or day of year and the associated cycle length, this function performs a basis expansion to efficiently calculate a linear predictor of the form <br /> <br />
<code class="reqn"> 
 \eta^{(t)} = \beta_0 + \sum_{k=1}^K \bigl( \beta_{1k} \sin(\frac{2 \pi k t}{L}) + \beta_{2k} \cos(\frac{2 \pi k t}{L}) \bigr). 
 </code> <br /> <br />
This is relevant for modeling e.g. diurnal variation and the flexibility can be increased by adding smaller frequencies (i.e. increasing <code class="reqn">K</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trigBasisExp(tod, L = 24, degree = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trigBasisExp_+3A_tod">tod</code></td>
<td>
<p>Time variable, describing the time point in a cycle. Could for example be time of day (between 0 and 24) or day of year.</p>
</td></tr>
<tr><td><code id="trigBasisExp_+3A_l">L</code></td>
<td>
<p>Length of one cycle on the scale of the time variable. For time of day, this would be 24.</p>
</td></tr>
<tr><td><code id="trigBasisExp_+3A_degree">degree</code></td>
<td>
<p>Degree K of the trigonometric link above. Increasing K increases the flexibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A design matrix (without intercept column of ones), ordered as sin1, cos1, sin2, cos2, ...
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## hourly data
tod = rep(1:24, 10)
Z = trigBasisExp(tod, L = 24, degree = 2)

## half-hourly data
tod = rep(1:48/2, 10) # in [0,24] -&gt; L = 24
Z1 = trigBasisExp(tod, L = 24, degree = 3)

tod = rep(1:48, 10) # in [1,48] -&gt; L = 48
Z2 = trigBasisExp(tod, L = 48, degree = 3)

Z1 - Z2
# The latter two are equivalent specifications!
</code></pre>

<hr>
<h2 id='viterbi'>Viterbi algorithm for decoding states</h2><span id='topic+viterbi'></span>

<h3>Description</h3>

<p>Viterbi algorithm for decoding states
</p>


<h3>Usage</h3>

<pre><code class='language-R'>viterbi(delta, Gamma, allprobs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="viterbi_+3A_delta">delta</code></td>
<td>
<p>Initial or stationary distribution of length N</p>
</td></tr>
<tr><td><code id="viterbi_+3A_gamma">Gamma</code></td>
<td>
<p>Transition probability matrix of dimension c(N,N)</p>
</td></tr>
<tr><td><code id="viterbi_+3A_allprobs">allprobs</code></td>
<td>
<p>Matrix of state-dependent probabilities/ density values of dimension c(n, N)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of decoded states of length n
</p>


<h3>Examples</h3>

<pre><code class='language-R'>delta = c(0.5, 0.5)
Gamma = matrix(c(0.9, 0.1, 0.2, 0.8), nrow = 2, byrow = TRUE)
allprobs = matrix(runif(200), nrow = 100, ncol = 2)
states = viterbi(delta, Gamma, allprobs)
</code></pre>

<hr>
<h2 id='viterbi_g'>Viterbi algorithm for decoding states of inhomogeneous HMMs</h2><span id='topic+viterbi_g'></span>

<h3>Description</h3>

<p>Viterbi algorithm for decoding states of inhomogeneous HMMs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>viterbi_g(delta, Gamma, allprobs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="viterbi_g_+3A_delta">delta</code></td>
<td>
<p>Initial distribution of length N</p>
</td></tr>
<tr><td><code id="viterbi_g_+3A_gamma">Gamma</code></td>
<td>
<p>Array of transition probability matrices of dimension c(N,N,n-1), as in a time series of length n, there are only n-1 transitions. 
If you provide an array of dimension c(N,N,n), the first slice will be ignored. <br /></p>
</td></tr>
<tr><td><code id="viterbi_g_+3A_allprobs">allprobs</code></td>
<td>
<p>Matrix of state-dependent probabilities/ density values of dimension c(n, N)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of decoded states of length n
</p>


<h3>Examples</h3>

<pre><code class='language-R'>delta = c(0.5, 0.5)
Gamma = array(dim = c(2,2,99))
for(t in 1:99){
  gammas = rbeta(2, shape1 = 0.4, shape2 = 1)
  Gamma[,,t] = matrix(c(1-gammas[1], gammas[1], 
                      gammas[2], 1-gammas[2]), nrow = 2, byrow = TRUE)
}
allprobs = matrix(runif(200), nrow = 100, ncol = 2)
states = viterbi_g(delta, Gamma, allprobs)
</code></pre>

<hr>
<h2 id='viterbi_p'>Viterbi algorithm for decoding states of periodically inhomogeneous HMMs</h2><span id='topic+viterbi_p'></span>

<h3>Description</h3>

<p>Viterbi algorithm for decoding states of periodically inhomogeneous HMMs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>viterbi_p(delta, Gamma, allprobs, tod)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="viterbi_p_+3A_delta">delta</code></td>
<td>
<p>Initial or periodically statioanary distribution of length N</p>
</td></tr>
<tr><td><code id="viterbi_p_+3A_gamma">Gamma</code></td>
<td>
<p>Array of transition probability matrices of dimension c(N,N,L), where L is the cycle length.</p>
</td></tr>
<tr><td><code id="viterbi_p_+3A_allprobs">allprobs</code></td>
<td>
<p>Matrix of state-dependent probabilities/ density values of dimension c(n, N)</p>
</td></tr>
<tr><td><code id="viterbi_p_+3A_tod">tod</code></td>
<td>
<p>Integer valued cyclic variable to index the transition probability matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of decoded states of length n
</p>


<h3>Examples</h3>

<pre><code class='language-R'>delta = c(0.5, 0.5)
beta = matrix(c(-2, 1, -1,
                -2, -1, 1), nrow = 2, byrow = TRUE)
Gamma = tpm_p(1:24, 24, beta)

tod = rep(1:24, 10)
n = length(tod)

allprobs = matrix(runif(2*n), nrow = n, ncol = 2)
states = viterbi_p(delta, Gamma, allprobs, tod)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
