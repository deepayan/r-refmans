<!DOCTYPE html><html><head><title>Help for package PosteriorBootstrap</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {PosteriorBootstrap}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#draw_logit_samples'><p>Draw adaptive non-parametric learning samples for logistic regression</p></a></li>
<li><a href='#draw_stick_breaks'><p>Draw stick-breaks depending on a concentration parameter</p></a></li>
<li><a href='#get_file'><p>Get a file from extdata by name</p></a></li>
<li><a href='#get_german_credit_dataset'><p>Load and pre-process the dataset that ships with the package</p></a></li>
<li><a href='#get_german_credit_file'><p>Get the file with the German Statlog credit dataset</p></a></li>
<li><a href='#get_stan_file'><p>Get the Stan file with Bayesian Logistic Regression</p></a></li>
<li><a href='#PosteriorBootstrap'><p>A package with a parallel approach for adaptive non-parametric learning</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Non-Parametric Sampling with Parallel Monte Carlo</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.2</td>
</tr>
<tr>
<td>Description:</td>
<td>An implementation of a non-parametric statistical model using a
    parallelised Monte Carlo sampling scheme. The method implemented in this
    package allows non-parametric inference to be regularized for small sample
    sizes, while also being more accurate than approximations such as
    variational Bayes. The concentration parameter is an effective sample size
    parameter, determining the faith we have in the model versus the data. When
    the concentration is low, the samples are close to the exact Bayesian
    logistic regression method; when the concentration is high, the samples are
    close to the simplified variational Bayes logistic regression. The method is
    described in full in the paper Lyddon, Walker, and Holmes (2018),
    "Nonparametric learning from Bayesian models with randomized objective
    functions" &lt;<a href="https://arxiv.org/abs/1806.11544">arXiv:1806.11544</a>&gt;.</td>
</tr>
<tr>
<td>Language:</td>
<td>en-GB</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>e1071 (&ge; 1.7.1), MASS (&ge; 7.3.51.1), utils (&ge; 3.4.3)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>BH (&ge; 1.81.0), covr (&ge; 3.3.0), dplyr (&ge; 0.7.4), ggplot2
(&ge; 3.1.1), gridExtra (&ge; 2.3), knitr (&ge; 1.21), lintr (&ge;
1.0.3), RcppEigen (&ge; 0.3.3), RcppParallel (&ge; 5.1.7),
rmarkdown (&ge; 1.11), roxygen2 (&ge; 6.1.1), rstan (&ge; 2.18.2),
testthat (&ge; 2.0.1), tibble (&ge; 2.1.1)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/alan-turing-institute/PosteriorBootstrap/">https://github.com/alan-turing-institute/PosteriorBootstrap/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/alan-turing-institute/PosteriorBootstrap/issues">https://github.com/alan-turing-institute/PosteriorBootstrap/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-03-12 17:38:53 UTC; jrobinson</td>
</tr>
<tr>
<td>Author:</td>
<td>Simon Lyddon [aut],
  Miguel Morin [aut],
  James Robinson [aut, cre],
  The Alan Turing Institute [cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>James Robinson &lt;james.em.robinson@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-03-12 18:10:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='draw_logit_samples'>Draw adaptive non-parametric learning samples for logistic regression</h2><span id='topic+draw_logit_samples'></span>

<h3>Description</h3>

<p><code>draw_logit_samples</code> returns samples of the parameter of interest in a
logistic regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>draw_logit_samples(
  x,
  y,
  concentration,
  n_bootstrap = 100,
  posterior_sample = NULL,
  gamma_mean = NULL,
  gamma_vcov = NULL,
  threshold = 1e-08,
  num_cores = 1,
  show_progress = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="draw_logit_samples_+3A_x">x</code></td>
<td>
<p>The features of the data.</p>
</td></tr>
<tr><td><code id="draw_logit_samples_+3A_y">y</code></td>
<td>
<p>The outcomes of the data (either <code>0</code> or <code>1</code>).</p>
</td></tr>
<tr><td><code id="draw_logit_samples_+3A_concentration">concentration</code></td>
<td>
<p>The parameter <code>c</code> in the paper (page 3, formula 3),</p>
</td></tr>
<tr><td><code id="draw_logit_samples_+3A_n_bootstrap">n_bootstrap</code></td>
<td>
<p>The number of bootstrap samples required.</p>
</td></tr>
<tr><td><code id="draw_logit_samples_+3A_posterior_sample">posterior_sample</code></td>
<td>
<p>The function can take samples from the posterior to
generate non-parametric-learning samples, or it can take NULL and the
posterior is assumed normal N(<code>gamma_mean</code>, <code>gamma_vcov</code>). If
provided, the posterior sample must have a number of columns equal to the
number of covariates and a number of rows equal or larger than the
'n_bootstrap' (as the algorithm draws a new sample based on a single draw
of the posterior sample).</p>
</td></tr>
<tr><td><code id="draw_logit_samples_+3A_gamma_mean">gamma_mean</code></td>
<td>
<p>In case <code>posterior_sample</code> is NULL, the mean for the
centering model (equation 9, page 4).</p>
</td></tr>
<tr><td><code id="draw_logit_samples_+3A_gamma_vcov">gamma_vcov</code></td>
<td>
<p>In case <code>posterior_sample</code> is NULL, the
variance-covariance of the centering model for gamma (equation 9, page 4).</p>
</td></tr>
<tr><td><code id="draw_logit_samples_+3A_threshold">threshold</code></td>
<td>
<p>The threshold of stick remaining below which the function
stops looking for more stick-breaks. It correspondes to epsilon in the
paper, at the bottom of page 5 and in algorithm 2 in page 12.</p>
</td></tr>
<tr><td><code id="draw_logit_samples_+3A_num_cores">num_cores</code></td>
<td>
<p>Number of processor cores for the parallel run of the
algorithm. See <code>mc.cores</code> in <a href="parallel.html#topic+mclapply">mclapply</a> for details.</p>
</td></tr>
<tr><td><code id="draw_logit_samples_+3A_show_progress">show_progress</code></td>
<td>
<p>Boolean whether to show the progress of the algorithm in
a progress bar.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements the non-parametric-learning algorithm, which is
algorithm 2 in page 12 in the paper. It uses a mixture of Dirichlet processes
and stick-breaking to find the number of posterior samples and logistic
regression to find the randomized parameter of interest. For examples, see
the vignette.
</p>


<h3>Value</h3>

<p>A matrix of bootstrap samples for the parameter of interest.
</p>

<hr>
<h2 id='draw_stick_breaks'>Draw stick-breaks depending on a concentration parameter</h2><span id='topic+draw_stick_breaks'></span>

<h3>Description</h3>

<p><code>draw_stick_breaks</code> returns a vector with the breaks of a stick of
length 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>draw_stick_breaks(
  concentration = 1,
  min_stick_breaks = 100,
  threshold = 1e-08,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="draw_stick_breaks_+3A_concentration">concentration</code></td>
<td>
<p>The parameter <code>c</code> in the paper (page 3, formula 3),
which is an effective sample size.</p>
</td></tr>
<tr><td><code id="draw_stick_breaks_+3A_min_stick_breaks">min_stick_breaks</code></td>
<td>
<p>The minimal number of stick-breaks.</p>
</td></tr>
<tr><td><code id="draw_stick_breaks_+3A_threshold">threshold</code></td>
<td>
<p>The threshold of stick remaining below which the function
stops looking for more stick-breaks. It corresponds to epsilon in the
paper, at the bottom of page 5 and in algorithm 2 in page 12.</p>
</td></tr>
<tr><td><code id="draw_stick_breaks_+3A_seed">seed</code></td>
<td>
<p>A seed to start the sampling.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements the stick-breaking process for non-parametric
learning described in section 2 of the supplementary material. The name
&quot;stick-breaking&quot; comes from a stick of unit length that we need to break into
a number of items. This code implements algorithm 2 and the stick-breaking
function calculates the parameter T in algorithm 1, which is the only
difference between the two algorithms. The code uses the Beta distribution as
that distribution is part of the definition of the stick-breaking process.
The function draws from the beta distribution, e.g. <code>b_1</code>, <code>b_2</code>,
<code>b_3</code>, ..., and computes the stick breaks as <code>b_1</code>,
<code>(1-b_1)*b_2</code>, <code>(1-b_1)*(1-b_2)*b_3</code>, ... . The length remaining in
the stick at each step is <code>1-b_1</code>, <code>(1-b_1)* (1-b_2)</code>,
<code>(1-b_1)*(1-b_2)*(1-b_3)</code>, ... so the latter converges to zero.
</p>


<h3>Value</h3>

<p>A vector of stick-breaks summing to one.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>draw_stick_breaks(1)
draw_stick_breaks(1, min_stick_breaks = 10)
draw_stick_breaks(1, min_stick_breaks = 10, threshold = 1e-8)

</code></pre>

<hr>
<h2 id='get_file'>Get a file from extdata by name</h2><span id='topic+get_file'></span>

<h3>Description</h3>

<p>Get a file from extdata by name
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_file(name)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_file_+3A_name">name</code></td>
<td>
<p>The filename that is requested</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The requested file
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- get_file('bayes_logit.stan')
writeLines(readLines(f))

</code></pre>

<hr>
<h2 id='get_german_credit_dataset'>Load and pre-process the dataset that ships with the package</h2><span id='topic+get_german_credit_dataset'></span>

<h3>Description</h3>

<p>Load and pre-process the dataset that ships with the package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_german_credit_dataset(
  scale = TRUE,
  add_constant_term = TRUE,
  download_destination = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_german_credit_dataset_+3A_scale">scale</code></td>
<td>
<p>Whether to scale the features to have mean 0 and variance 1.</p>
</td></tr>
<tr><td><code id="get_german_credit_dataset_+3A_add_constant_term">add_constant_term</code></td>
<td>
<p>Whether to add a constant term as the first feature.</p>
</td></tr>
<tr><td><code id="get_german_credit_dataset_+3A_download_destination">download_destination</code></td>
<td>
<p>Provide a filepath if you want to download the
dataset from source. Note that although the original dataset has 20
features (some of them qualitative), the numeric dataset has 24 features.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with fields <code>x</code> for features and <code>y</code> for outcomes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
german &lt;- get_german_credit_dataset()
head(german$y)
head(german$x)


</code></pre>

<hr>
<h2 id='get_german_credit_file'>Get the file with the German Statlog credit dataset</h2><span id='topic+get_german_credit_file'></span>

<h3>Description</h3>

<p>The file contains a local copy of the German Statlog credit dataset with
1,000 observations and 24 features. The data page is at:
https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data) and the
original files at:
http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/ We
use the file 'german.data-numeric', which has 24 covariates instead of the 20
in the original data (as some are qualitative).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_german_credit_file()
</code></pre>


<h3>Value</h3>

<p>A file with the plain-text raw data for the German Statlog credit
that ships with this package (extension <code>.dat</code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- get_german_credit_file()
writeLines(readLines(f, n=5))

</code></pre>

<hr>
<h2 id='get_stan_file'>Get the Stan file with Bayesian Logistic Regression</h2><span id='topic+get_stan_file'></span>

<h3>Description</h3>

<p>Get the Stan file with Bayesian Logistic Regression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_stan_file()
</code></pre>


<h3>Value</h3>

<p>An RStan file with the model for variational Bayes that ships with
this package (extension <code>.stan</code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- get_stan_file()
writeLines(readLines(f))

</code></pre>

<hr>
<h2 id='PosteriorBootstrap'>A package with a parallel approach for adaptive non-parametric learning</h2><span id='topic+PosteriorBootstrap'></span>

<h3>Description</h3>

<p>The PosteriorBootstrap package provides two categories of functions.
The first category returns or loads the system files that ship with the
package: get_stan_file, get_german_credit_file, get_german_credit_dataset.
The second category performs statistical sampling: draw_stick_breaks and
draw_logit_samples (for adaptive non-parametric learning of the logistic
regression model).
</p>


<h3>Details</h3>

<p>Please see the vignette for sample usage and performance metrics.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
