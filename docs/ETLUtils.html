<!DOCTYPE html><html><head><title>Help for package ETLUtils</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ETLUtils}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ETLUtils-package'><p>Extra utility functions to execute standard ETL operations on large data</p></a></li>
<li><a href='#factorise'><p>Put character vectors, columns of a data.frame or list elements as factor</p></a></li>
<li><a href='#matchmerge'><p>Merge two data frames (fast) by common columns by performing a left (outer) join or an inner join.</p></a></li>
<li><a href='#naLOCFPlusone'><p>Performs NA replacement by last observation carried forward but adds 1 to the last observation carried forward.</p></a></li>
<li><a href='#read.dbi.ffdf'><p>Read data from a DBI connection into an ffdf.</p></a></li>
<li><a href='#read.jdbc.ffdf'><p>Read data from a JDBC connection into an ffdf.</p></a></li>
<li><a href='#read.odbc.ffdf'><p>Read data from a ODBC connection into an ffdf.</p></a></li>
<li><a href='#recoder'><p>Recodes the values of a character vector</p></a></li>
<li><a href='#renameColumns'><p>Renames variables in a data frame.</p></a></li>
<li><a href='#write.dbi.ffdf'><p>Write ffdf data to a database table by using a DBI connection.</p></a></li>
<li><a href='#write.jdbc.ffdf'><p>Write ffdf data to a database table by using a JDBC connection.</p></a></li>
<li><a href='#write.odbc.ffdf'><p>Write ffdf data to a database table by using a ODBC connection.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Maintainer:</td>
<td>Jan Wijffels &lt;jwijffels@bnosac.be&gt;</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Title:</td>
<td>Utility Functions to Execute Standard Extract/Transform/Load
Operations (using Package 'ff') on Large Data</td>
</tr>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>Author:</td>
<td>Jan Wijffels</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides functions to facilitate the use of the 'ff' package
    in interaction with big data in 'SQL' databases (e.g. in 'Oracle', 'MySQL',
    'PostgreSQL', 'Hive') by allowing easy importing directly into 'ffdf' objects
    using 'DBI', 'RODBC' and 'RJDBC'. Also contains some basic utility functions to
    do fast left outer join merging based on 'match', factorisation of data and a
    basic function for re-coding vectors.</td>
</tr>
<tr>
<td>Version:</td>
<td>1.5</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/jwijffels/ETLUtils">https://github.com/jwijffels/ETLUtils</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>ff (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>bit (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>RSQLite, zoo, DBI, RODBC, RJDBC</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.0</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-07-31 08:14:44 UTC; Jan</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-08-03 09:42:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='ETLUtils-package'>Extra utility functions to execute standard ETL operations on large data</h2><span id='topic+ETLUtils-package'></span><span id='topic+ETLUtils'></span>

<h3>Description</h3>

<p>Provides functions to load bigdata (e.g. from Oracle) directly into <code>ffdf</code> objects using DBI and some utility functions like recoding and matchmerge which does fast left outer join merging based on <code>match</code>.
</p>


<h3>Author(s)</h3>

<p>Jan Wijffels <a href="mailto:jwijffels@bnosac.be">jwijffels@bnosac.be</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See the specified functions in the package
</code></pre>

<hr>
<h2 id='factorise'>Put character vectors, columns of a data.frame or list elements as factor</h2><span id='topic+factorise'></span><span id='topic+factorise.default'></span><span id='topic+factorise.character'></span><span id='topic+factorise.data.frame'></span><span id='topic+factorise.list'></span>

<h3>Description</h3>

<p>Put character vectors, columns of a data.frame or list elements as factor if they are character strings
or optionally if they are logicals<br />
</p>


<h3>Usage</h3>

<pre><code class='language-R'>factorise(x, logicals = FALSE, ...)

## Default S3 method:
factorise(x, logicals = FALSE, ...)

## S3 method for class 'character'
factorise(x, logicals = FALSE, ...)

## S3 method for class 'data.frame'
factorise(x, logicals = FALSE, ...)

## S3 method for class 'list'
factorise(x, logicals = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="factorise_+3A_x">x</code></td>
<td>
<p>a character vector, a data.frame or a list</p>
</td></tr>
<tr><td><code id="factorise_+3A_logicals">logicals</code></td>
<td>
<p>logical indicating if logical vectors should also be converted to factors. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="factorise_+3A_...">...</code></td>
<td>
<p>optional arguments passed on to the methods</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The updated x vector/data.frame or list where the character vectors or optionally logical elements are 
converted to factors
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+as.factor">as.factor</a></code>, <code><a href="base.html#topic+factor">factor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- data.frame(x = 1:4, y = LETTERS[1:4], b = c(TRUE, FALSE, NA, TRUE), stringsAsFactors=FALSE)
str(factorise(x))
str(factorise(x, logicals = TRUE))
str(factorise(list(a = LETTERS, b = 1:10, c = pi, d = list(x = x))))
</code></pre>

<hr>
<h2 id='matchmerge'>Merge two data frames (fast) by common columns by performing a left (outer) join or an inner join.</h2><span id='topic+matchmerge'></span>

<h3>Description</h3>

<p>Merge two data frames (fast) by common columns by performing a left (outer) join or an inner join.<br />
The data frames are merged on the columns given by by.x and by.y. Columns can be specified only by name.
This differs from the merge function from the base package in that merging is done based on 1 column key only. 
If more than one column is supplied in by.x and by.y, these columns will be concatenated together 
to form 1 key which will be used to match. 
Alternatively, by.x and by.y can be 2 vectors of length NROW(x) which will be used as keys.<br />
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matchmerge(
  x,
  y,
  by.x,
  by.y,
  all.x = FALSE,
  by.iskey = FALSE,
  suffix = ".y",
  add.columns = colnames(y),
  check.duplicates = TRUE,
  trace = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="matchmerge_+3A_x">x</code></td>
<td>
<p>the left hand side data frame to merge</p>
</td></tr>
<tr><td><code id="matchmerge_+3A_y">y</code></td>
<td>
<p>the right hand side data frame to merge <br />
or a vector in which case you always need to supply by.y as a vector, make sure
by.iskey is set to TRUE and provide in add.columns the column name for which y will be relabelled to in the joined data frame (see the example).</p>
</td></tr>
<tr><td><code id="matchmerge_+3A_by.x">by.x</code></td>
<td>
<p>either the name of 1 column in x or a character vector of length NROW(x) 
which will be used as key to merge the 2 data frames</p>
</td></tr>
<tr><td><code id="matchmerge_+3A_by.y">by.y</code></td>
<td>
<p>either the name of 1 column in y or a character vector of length NROW(x) 
which will be used as key to merge the 2 data frames. 
Duplicate values in by.y are not allowed.</p>
</td></tr>
<tr><td><code id="matchmerge_+3A_all.x">all.x</code></td>
<td>
<p>logical, if TRUE, then extra rows will be added to the output, one for each row in x that has no matching row in y. 
These rows will have NAs in those columns that are usually filled with values from y. 
The default is FALSE, so that only rows with data from both x and y are included in the output. The
default value corresponds to an inner join. If TRUE is supplied, this corresponds to a left (outer) join.</p>
</td></tr>
<tr><td><code id="matchmerge_+3A_by.iskey">by.iskey</code></td>
<td>
<p>Logical, indicating that the by.x and the by.y inputs are vectors of length NROW(x) and NROW(y)
instead of column names in x and y. If this is FALSE, the input columns will be pasted together to create a key
to merge upon. Otherwise, the function will use the by.x and by.y vectors directly as matching key. 
Defaults to FALSE indicating the by.x and by.y are column names in x and y.</p>
</td></tr>
<tr><td><code id="matchmerge_+3A_suffix">suffix</code></td>
<td>
<p>a character string to be used for duplicate column names in x and y to make the y columns unique.</p>
</td></tr>
<tr><td><code id="matchmerge_+3A_add.columns">add.columns</code></td>
<td>
<p>character vector of column names in y to merge to the x data frame. Defaults to all columns in y.</p>
</td></tr>
<tr><td><code id="matchmerge_+3A_check.duplicates">check.duplicates</code></td>
<td>
<p>checks if by.y contains duplicates which is not allowed. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="matchmerge_+3A_trace">trace</code></td>
<td>
<p>logical, indicating to print some informative messages about the progress</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The rows in the right hand side data frame that match on the specific key are extracted, and joined together
with the left hand side data frame.<br />
</p>
<p>Merging is done based on the match function on the key value.
This makes the function a lot faster when compared to applying merge, especially for large data frames (see the example).
And also the memory consumption is a lot smaller.<br />
</p>
<p>In SQL database terminology, the default value of all.x = FALSE gives a natural join, 
a special case of an inner join. Specifying all.x = FALSE gives a left (outer) join. 
Right (outer) join or (full) outer join are not provided in this function.
</p>


<h3>Value</h3>

<p>data frame with x joined with y based on the supplied columns.
The output columns are the columns in x followed by the extra columns in y.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+cbind">cbind</a>, <a href="base.html#topic+match">match</a>, <a href="base.html#topic+merge">merge</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>left &lt;- data.frame(idlhs = c(1:4, 3:5), a = LETTERS[1:7], stringsAsFactors = FALSE)
right &lt;- data.frame(idrhs = c(1:4), b = LETTERS[8:11], stringsAsFactors = FALSE)
## Inner join
matchmerge(x=left, y=right, by.x = "idlhs", by.y = "idrhs")

## Left outer join in 2 ways
matchmerge(x=left, y=right, by.x = "idlhs", by.y = "idrhs", all.x=TRUE)
matchmerge(x=left, y=right, by.x = left$idlhs, by.y = right$idrhs, all.x=TRUE, by.iskey=TRUE)

## Show usage when y is just a vector instead of a data.frame
matchmerge(x=left, y=right$b, by.x = left$idlhs, by.y = right$idrhs, all.x=TRUE, 
by.iskey=TRUE, add.columns="b.renamed")

## Show speedup difference with merge
## Not run: 
size &lt;- 100000 
dimension &lt;- seq(Sys.Date(), Sys.Date()+10, by = "day")
left &lt;- data.frame(date = rep(dimension, size), sales = rnorm(size))
right &lt;- data.frame(date = dimension, feature = dimension-7, feature = dimension-14)
dim(left)
dim(right)
print(system.time(merge(left, right, by.x="date", by.y="date", all.x=TRUE, all.y=FALSE)))
print(system.time(matchmerge(left, right, by.x="date", by.y="date", all.x=TRUE, by.iskey=FALSE)))

## End(Not run)
## Show example usage 
products &lt;- expand.grid(product = c("Pepsi", "Coca Cola"), type = c("Can","Bottle"), 
size = c("6Ml","8Ml"), distributor = c("Distri X","Distri Y"), salesperson = c("Mr X","Mr Y"), 
stringsAsFactors=FALSE)
products &lt;- products[!duplicated(products[, c("product","type","size")]), ]
products$key &lt;- paste(products$product, products$type, products$size, sep=".")
sales &lt;- expand.grid(item = unique(products$key), sales = rnorm(10000, mean = 100))
str(products)
str(sales)
info &lt;- matchmerge(x=sales, y=products, 
  by.x=sales$item, by.y=products$key, all.x=TRUE, by.iskey=TRUE, 
  add.columns=c("size","distributor"), check.duplicates=FALSE)
str(info)
tapply(info$sales, info$distributor, FUN=sum)
</code></pre>

<hr>
<h2 id='naLOCFPlusone'>Performs NA replacement by last observation carried forward but adds 1 to the last observation carried forward.</h2><span id='topic+naLOCFPlusone'></span>

<h3>Description</h3>

<p>Performs NA replacement by last observation carried forward but adds 1 to the last observation carried forward. <br />
</p>


<h3>Usage</h3>

<pre><code class='language-R'>naLOCFPlusone(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="naLOCFPlusone_+3A_x">x</code></td>
<td>
<p>a numeric vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector where NA's are replaced with the LOCF + 1
</p>


<h3>See Also</h3>

<p><code><a href="zoo.html#topic+na.locf">na.locf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(zoo)
x &lt;- c(2,NA,NA,4,5,2,NA)
naLOCFPlusone(x)
</code></pre>

<hr>
<h2 id='read.dbi.ffdf'>Read data from a DBI connection into an ffdf.</h2><span id='topic+read.dbi.ffdf'></span>

<h3>Description</h3>

<p>Read data from a DBI connection into an <code><a href="ff.html#topic+ffdf">ffdf</a></code>. This can for example be used to import
large datasets from Oracle, SQLite, MySQL, PostgreSQL, Hive or other SQL databases into R. <br />
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.dbi.ffdf(
  query = NULL,
  dbConnect.args = list(drv = NULL, dbname = NULL, username = "", password = ""),
  dbSendQuery.args = list(),
  dbFetch.args = list(),
  x = NULL,
  nrows = -1,
  first.rows = NULL,
  next.rows = NULL,
  levels = NULL,
  appendLevels = TRUE,
  asffdf_args = list(),
  BATCHBYTES = getOption("ffbatchbytes"),
  VERBOSE = FALSE,
  colClasses = NULL,
  transFUN = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.dbi.ffdf_+3A_query">query</code></td>
<td>
<p>the SQL query to execute on the DBI connection</p>
</td></tr>
<tr><td><code id="read.dbi.ffdf_+3A_dbconnect.args">dbConnect.args</code></td>
<td>
<p>a list of arguments to pass to DBI's <code><a href="DBI.html#topic+dbConnect">dbConnect</a></code> (like drv, dbname, username, password). See the examples.</p>
</td></tr>
<tr><td><code id="read.dbi.ffdf_+3A_dbsendquery.args">dbSendQuery.args</code></td>
<td>
<p>a list containing database-specific parameters which will be passed to to pass to <code><a href="DBI.html#topic+dbSendQuery">dbSendQuery</a></code>.
Defaults to an empty list.</p>
</td></tr>
<tr><td><code id="read.dbi.ffdf_+3A_dbfetch.args">dbFetch.args</code></td>
<td>
<p>a list containing optional database-specific parameters which will be passed to to pass to <code><a href="DBI.html#topic+dbFetch">dbFetch</a></code>. 
Defaults to an empty list.</p>
</td></tr>
<tr><td><code id="read.dbi.ffdf_+3A_x">x</code></td>
<td>
<p>NULL or an optional ffdf object to which the read records are appended. 
See documentation in read.table.ffdf for more details and the example below.</p>
</td></tr>
<tr><td><code id="read.dbi.ffdf_+3A_nrows">nrows</code></td>
<td>
<p>Number of rows to read from the query resultset. Default value of -1 reads in all rows.</p>
</td></tr>
<tr><td><code id="read.dbi.ffdf_+3A_first.rows">first.rows</code></td>
<td>
<p>chunk size (rows) to read for first chunk from the query resultset</p>
</td></tr>
<tr><td><code id="read.dbi.ffdf_+3A_next.rows">next.rows</code></td>
<td>
<p>chunk size (rows) to read sequentially for subsequent chunks from the query resultset. Currently, this must be specified.</p>
</td></tr>
<tr><td><code id="read.dbi.ffdf_+3A_levels">levels</code></td>
<td>
<p>optional specification of factor levels. A list with as names the names the columns of the data.frame 
fetched in the first.rows, containing levels of the factors.</p>
</td></tr>
<tr><td><code id="read.dbi.ffdf_+3A_appendlevels">appendLevels</code></td>
<td>
<p>logical. A vector of permissions to expand levels for factor columns. See documentation in <code><a href="ff.html#topic+read.table.ffdf">read.table.ffdf</a></code> for more details.</p>
</td></tr>
<tr><td><code id="read.dbi.ffdf_+3A_asffdf_args">asffdf_args</code></td>
<td>
<p>further arguments passed to <code><a href="ff.html#topic+as.ffdf">as.ffdf</a></code> (ignored if 'x' gives an ffdf object )</p>
</td></tr>
<tr><td><code id="read.dbi.ffdf_+3A_batchbytes">BATCHBYTES</code></td>
<td>
<p>integer: bytes allowed for the size of the data.frame storing the result of reading one chunk. 
See documentation in <code><a href="ff.html#topic+read.table.ffdf">read.table.ffdf</a></code> for more details.</p>
</td></tr>
<tr><td><code id="read.dbi.ffdf_+3A_verbose">VERBOSE</code></td>
<td>
<p>logical: TRUE to verbose timings for each processed chunk (default FALSE).</p>
</td></tr>
<tr><td><code id="read.dbi.ffdf_+3A_colclasses">colClasses</code></td>
<td>
<p>See documentation in <code><a href="ff.html#topic+read.table.ffdf">read.table.ffdf</a></code></p>
</td></tr>
<tr><td><code id="read.dbi.ffdf_+3A_transfun">transFUN</code></td>
<td>
<p>function applied to the data frame after each chunk is retreived by <code><a href="DBI.html#topic+dbFetch">dbFetch</a></code></p>
</td></tr>
<tr><td><code id="read.dbi.ffdf_+3A_...">...</code></td>
<td>
<p>optional parameters passed on to transFUN</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Opens up the DBI connection using <code>DBI::dbConnect</code>, sends the query using <code>DBI::dbSendQuery</code> and <code>DBI::dbFetch</code>-es 
the results in batches of next.rows rows. Heavily borrowed from <code><a href="ff.html#topic+read.table.ffdf">read.table.ffdf</a></code>
</p>


<h3>Value</h3>

<p>An ffdf object unless the query returns zero records in which case the function will return the data.frame
returned by <code><a href="DBI.html#topic+dbFetch">dbFetch</a></code> and possibly transFUN.
</p>


<h3>See Also</h3>

<p><code><a href="ff.html#topic+read.table.ffdf">read.table.ffdf</a>, <a href="#topic+read.odbc.ffdf">read.odbc.ffdf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(ff)

##
## Example query using data in sqlite
##
require(RSQLite)
dbfile &lt;- system.file("smalldb.sqlite3", package="ETLUtils")
drv &lt;- dbDriver("SQLite")
query &lt;- "select * from testdata limit 10000"
x &lt;- read.dbi.ffdf(query = query, dbConnect.args = list(drv = drv, dbname = dbfile), 
first.rows = 100, next.rows = 1000, VERBOSE=TRUE)
class(x)
x[1:10, ]

## show it is the same as getting the data directly using RSQLite 
## apart from characters which are factors in ffdf objects
directly &lt;- dbGetQuery(dbConnect(drv = drv, dbname = dbfile), query)
directly &lt;- as.data.frame(as.list(directly), stringsAsFactors=TRUE)
all.equal(x[,], directly)

## show how to use the transFUN argument to transform the data before saving into the ffdf
## and shows the use of the levels argument
query &lt;- "select * from testdata limit 10"
x &lt;- read.dbi.ffdf(query = query, dbConnect.args = list(drv = drv, dbname = dbfile), 
first.rows = 100, next.rows = 1000, VERBOSE=TRUE, levels = list(a = rev(LETTERS)),
transFUN = function(x, subtractdays){
	x$b &lt;- as.Date(x$b)
	x$b.subtractdaysago &lt;- x$b - subtractdays
	x
}, subtractdays=7)
class(x)
x[1:10, ]
## remark that the levels of column a are reversed due to specifying the levels argument correctly
levels(x$a)

## show how to append data to an existing ffdf object 
transformexample &lt;- function(x, subtractdays){
	x$b &lt;- as.Date(x$b)
	x$b.subtractdaysago &lt;- x$b - subtractdays
	x
}
dim(x)
x[,]
combined &lt;- read.dbi.ffdf(query = query, 
 dbConnect.args = list(drv = drv, dbname = dbfile), 
 first.rows = 100, next.rows = 1000, x = x, VERBOSE=TRUE, 
 transFUN = transformexample, subtractdays=1000)
dim(combined)
combined[,]

##
## Example query using ROracle. Do try this at home with some larger data :)
##
## Not run: 
require(ROracle)
query &lt;- "select OWNER, TABLE_NAME, TABLESPACE_NAME, NUM_ROWS, LAST_ANALYZED from all_all_tables" 
x &lt;- read.dbi.ffdf(query=query,
dbConnect.args = list(drv = dbDriver("Oracle"), 
user = "YourUser", password = "YourPassword", dbname = "Mydatabase"),
first.rows = 100, next.rows = 50000, nrows = -1, VERBOSE=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='read.jdbc.ffdf'>Read data from a JDBC connection into an ffdf.</h2><span id='topic+read.jdbc.ffdf'></span>

<h3>Description</h3>

<p>Read data from a JDBC connection into an <code><a href="ff.html#topic+ffdf">ffdf</a></code>. This can for example be used to import
large datasets from Oracle, SQLite, MySQL, PostgreSQL, Hive or other SQL databases into R. <br />
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.jdbc.ffdf(
  query = NULL,
  dbConnect.args = list(drv = NULL, dbname = NULL, username = "", password = ""),
  dbSendQuery.args = list(),
  dbFetch.args = list(),
  x = NULL,
  nrows = -1,
  first.rows = NULL,
  next.rows = NULL,
  levels = NULL,
  appendLevels = TRUE,
  asffdf_args = list(),
  BATCHBYTES = getOption("ffbatchbytes"),
  VERBOSE = FALSE,
  colClasses = NULL,
  transFUN = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.jdbc.ffdf_+3A_query">query</code></td>
<td>
<p>the SQL query to execute on the JDBC connection</p>
</td></tr>
<tr><td><code id="read.jdbc.ffdf_+3A_dbconnect.args">dbConnect.args</code></td>
<td>
<p>a list of arguments to pass to JDBC's <code>RJDBC::dbConnect</code> (like drv, dbname, username, password). See the examples.</p>
</td></tr>
<tr><td><code id="read.jdbc.ffdf_+3A_dbsendquery.args">dbSendQuery.args</code></td>
<td>
<p>a list containing database-specific parameters which will be passed to to pass to <code>RJDBC::dbSendQuery</code>.
Defaults to an empty list.</p>
</td></tr>
<tr><td><code id="read.jdbc.ffdf_+3A_dbfetch.args">dbFetch.args</code></td>
<td>
<p>a list containing optional database-specific parameters which will be passed to to pass to <code>RJDBC::dbFetch</code>. 
Defaults to an empty list.</p>
</td></tr>
<tr><td><code id="read.jdbc.ffdf_+3A_x">x</code></td>
<td>
<p>NULL or an optional ffdf object to which the read records are appended. 
See documentation in read.table.ffdf for more details and the example below.</p>
</td></tr>
<tr><td><code id="read.jdbc.ffdf_+3A_nrows">nrows</code></td>
<td>
<p>Number of rows to read from the query resultset. Default value of -1 reads in all rows.</p>
</td></tr>
<tr><td><code id="read.jdbc.ffdf_+3A_first.rows">first.rows</code></td>
<td>
<p>chunk size (rows) to read for first chunk from the query resultset</p>
</td></tr>
<tr><td><code id="read.jdbc.ffdf_+3A_next.rows">next.rows</code></td>
<td>
<p>chunk size (rows) to read sequentially for subsequent chunks from the query resultset. Currently, this must be specified.</p>
</td></tr>
<tr><td><code id="read.jdbc.ffdf_+3A_levels">levels</code></td>
<td>
<p>optional specification of factor levels. A list with as names the names the columns of the data.frame 
fetched in the first.rows, containing levels of the factors.</p>
</td></tr>
<tr><td><code id="read.jdbc.ffdf_+3A_appendlevels">appendLevels</code></td>
<td>
<p>logical. A vector of permissions to expand levels for factor columns. See documentation in <code><a href="ff.html#topic+read.table.ffdf">read.table.ffdf</a></code> for more details.</p>
</td></tr>
<tr><td><code id="read.jdbc.ffdf_+3A_asffdf_args">asffdf_args</code></td>
<td>
<p>further arguments passed to <code><a href="ff.html#topic+as.ffdf">as.ffdf</a></code> (ignored if 'x' gives an ffdf object )</p>
</td></tr>
<tr><td><code id="read.jdbc.ffdf_+3A_batchbytes">BATCHBYTES</code></td>
<td>
<p>integer: bytes allowed for the size of the data.frame storing the result of reading one chunk. 
See documentation in <code><a href="ff.html#topic+read.table.ffdf">read.table.ffdf</a></code> for more details.</p>
</td></tr>
<tr><td><code id="read.jdbc.ffdf_+3A_verbose">VERBOSE</code></td>
<td>
<p>logical: TRUE to verbose timings for each processed chunk (default FALSE).</p>
</td></tr>
<tr><td><code id="read.jdbc.ffdf_+3A_colclasses">colClasses</code></td>
<td>
<p>See documentation in <code><a href="ff.html#topic+read.table.ffdf">read.table.ffdf</a></code></p>
</td></tr>
<tr><td><code id="read.jdbc.ffdf_+3A_transfun">transFUN</code></td>
<td>
<p>function applied to the data frame after each chunk is retreived by <code>RJDBC::dbFetch</code></p>
</td></tr>
<tr><td><code id="read.jdbc.ffdf_+3A_...">...</code></td>
<td>
<p>optional parameters passed on to transFUN</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Opens up the JDBC connection using <code>RJDBC::dbConnect</code>, sends the query using <code>RJDBC::dbSendQuery</code> and <code>RJDBC::dbFetch</code>-es 
the results in batches of next.rows rows. Heavily borrowed from <code><a href="ff.html#topic+read.table.ffdf">read.table.ffdf</a></code>
</p>


<h3>Value</h3>

<p>An ffdf object unless the query returns zero records in which case the function will return the data.frame
returned by <code>RJDBC::dbFetch</code> and possibly transFUN.
</p>


<h3>See Also</h3>

<p><code><a href="ff.html#topic+read.table.ffdf">read.table.ffdf</a>, <a href="#topic+read.jdbc.ffdf">read.jdbc.ffdf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require(ff)

##
## Example query using data in sqlite
##
require(RSQLite)
dbfile &lt;- system.file("smalldb.sqlite3", package="ETLUtils")
drv &lt;- JDBC(driverClass = "org.sqlite.JDBC", classPath = "/usr/local/lib/sqlite-jdbc-3.7.2.jar")
query &lt;- "select * from testdata limit 10000"
x &lt;- read.jdbc.ffdf(query = query, 
 dbConnect.args = list(drv = drv, url = sprintf("jdbc:sqlite:%s", dbfile)), 
 first.rows = 100, next.rows = 1000, VERBOSE=TRUE)
class(x)
x[1:10, ]

## End(Not run)
</code></pre>

<hr>
<h2 id='read.odbc.ffdf'>Read data from a ODBC connection into an ffdf.</h2><span id='topic+read.odbc.ffdf'></span>

<h3>Description</h3>

<p>Read data from a ODBC connection into an <code><a href="ff.html#topic+ffdf">ffdf</a></code>. This can for example be used to import
large datasets from Oracle, SQLite, MySQL, PostgreSQL, Hive or other SQL databases into R. <br />
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.odbc.ffdf(
  query = NULL,
  odbcConnect.args = list(dsn = NULL, uid = "", pwd = ""),
  odbcDriverConnect.args = list(connection = ""),
  odbcQuery.args = list(),
  sqlGetResults.args = list(),
  x = NULL,
  nrows = -1,
  first.rows = NULL,
  next.rows = NULL,
  levels = NULL,
  appendLevels = TRUE,
  asffdf_args = list(),
  BATCHBYTES = getOption("ffbatchbytes"),
  VERBOSE = FALSE,
  colClasses = NULL,
  transFUN = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.odbc.ffdf_+3A_query">query</code></td>
<td>
<p>the SQL query to execute on the ODBC connection</p>
</td></tr>
<tr><td><code id="read.odbc.ffdf_+3A_odbcconnect.args">odbcConnect.args</code></td>
<td>
<p>a list of arguments to pass to ODBC's <code><a href="RODBC.html#topic+odbcConnect">odbcConnect</a></code> (like dsn, uid, pwd). See the examples.</p>
</td></tr>
<tr><td><code id="read.odbc.ffdf_+3A_odbcdriverconnect.args">odbcDriverConnect.args</code></td>
<td>
<p>a list of arguments to pass to ODBC's <code><a href="RODBC.html#topic+odbcDriverConnect">odbcDriverConnect</a></code> (like connection). If you want to 
connect using odbcDriverConnect instead of odbcConnect.</p>
</td></tr>
<tr><td><code id="read.odbc.ffdf_+3A_odbcquery.args">odbcQuery.args</code></td>
<td>
<p>a list of arguments to pass to ODBC's <code><a href="RODBC.html#topic+odbcQuery">odbcQuery</a></code>, like rows_at_time. Defaults to an empty list.</p>
</td></tr>
<tr><td><code id="read.odbc.ffdf_+3A_sqlgetresults.args">sqlGetResults.args</code></td>
<td>
<p>a list containing optional parameters which will be passed to <code><a href="RODBC.html#topic+sqlGetResults">sqlGetResults</a></code>.
Defaults to an empty list. The max parameter will be overwritten with first.rows and next.rows when importing in batches.</p>
</td></tr>
<tr><td><code id="read.odbc.ffdf_+3A_x">x</code></td>
<td>
<p>NULL or an optional ffdf object to which the read records are appended. 
See documentation in <code><a href="ff.html#topic+read.table.ffdf">read.table.ffdf</a></code> for more details and the example below.</p>
</td></tr>
<tr><td><code id="read.odbc.ffdf_+3A_nrows">nrows</code></td>
<td>
<p>Number of rows to read from the query resultset. Default value of -1 reads in all rows.</p>
</td></tr>
<tr><td><code id="read.odbc.ffdf_+3A_first.rows">first.rows</code></td>
<td>
<p>chunk size (rows) to read for first chunk from the query resultset</p>
</td></tr>
<tr><td><code id="read.odbc.ffdf_+3A_next.rows">next.rows</code></td>
<td>
<p>chunk size (rows) to read sequentially for subsequent chunks from the query resultset. Currently, this must be specified.</p>
</td></tr>
<tr><td><code id="read.odbc.ffdf_+3A_levels">levels</code></td>
<td>
<p>optional specification of factor levels. A list with as names the names the columns of the data.frame 
fetched in the first.rows, containing levels of the factors.</p>
</td></tr>
<tr><td><code id="read.odbc.ffdf_+3A_appendlevels">appendLevels</code></td>
<td>
<p>logical. A vector of permissions to expand levels for factor columns. See documentation in <code><a href="ff.html#topic+read.table.ffdf">read.table.ffdf</a></code> for more details.</p>
</td></tr>
<tr><td><code id="read.odbc.ffdf_+3A_asffdf_args">asffdf_args</code></td>
<td>
<p>further arguments passed to <code><a href="ff.html#topic+as.ffdf">as.ffdf</a></code> (ignored if 'x' gives an ffdf object)</p>
</td></tr>
<tr><td><code id="read.odbc.ffdf_+3A_batchbytes">BATCHBYTES</code></td>
<td>
<p>integer: bytes allowed for the size of the data.frame storing the result of reading one chunk. 
See documentation in <code><a href="ff.html#topic+read.table.ffdf">read.table.ffdf</a></code> for more details.</p>
</td></tr>
<tr><td><code id="read.odbc.ffdf_+3A_verbose">VERBOSE</code></td>
<td>
<p>logical: TRUE to verbose timings for each processed chunk (default FALSE).</p>
</td></tr>
<tr><td><code id="read.odbc.ffdf_+3A_colclasses">colClasses</code></td>
<td>
<p>See documentation in <code><a href="ff.html#topic+read.table.ffdf">read.table.ffdf</a></code></p>
</td></tr>
<tr><td><code id="read.odbc.ffdf_+3A_transfun">transFUN</code></td>
<td>
<p>function applied to the data frame after each chunk is retreived by <code><a href="RODBC.html#topic+sqlGetResults">sqlGetResults</a></code></p>
</td></tr>
<tr><td><code id="read.odbc.ffdf_+3A_...">...</code></td>
<td>
<p>optional parameters passed on to transFUN</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Opens up the ODBC connection using <code>RODBC::odbcConnect</code> or <code>RODBC::odbcDriverConnect</code>, 
sends the query using <code>RODBC::odbcQuery</code> and retrieves
the results in batches of next.rows rows using <code>RODBC::sqlGetResults</code>. Heavily borrowed from <code><a href="ff.html#topic+read.table.ffdf">read.table.ffdf</a></code>
</p>


<h3>Value</h3>

<p>An ffdf object unless the query returns zero records in which case the function will return the data.frame
returned by <code><a href="RODBC.html#topic+sqlGetResults">sqlGetResults</a></code> and possibly transFUN.
</p>


<h3>See Also</h3>

<p><code><a href="ff.html#topic+read.table.ffdf">read.table.ffdf</a>, <a href="#topic+read.dbi.ffdf">read.dbi.ffdf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##
## Using the sqlite database (smalldb.sqlite3) in the /inst folder of the package
## set up the sqlite ODBC driver (www.stats.ox.ac.uk/pub/bdr/RODBC-manual.pd) 
## and call it 'smalltestsqlitedb' 
##
## Not run: 
require(RODBC)
x &lt;- read.odbc.ffdf(
query = "select * from testdata limit 10000",
odbcConnect.args = list(
 dsn="smalltestsqlitedb", uid = "", pwd = "", 
 believeNRows = FALSE, rows_at_time = 1), 
nrows = -1, 
first.rows = 100, next.rows = 1000, VERBOSE = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='recoder'>Recodes the values of a character vector</h2><span id='topic+recoder'></span>

<h3>Description</h3>

<p>Recodes the values of a character vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>recoder(x, from = c(), to = c())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="recoder_+3A_x">x</code></td>
<td>
<p>character vector</p>
</td></tr>
<tr><td><code id="recoder_+3A_from">from</code></td>
<td>
<p>character vector with old values</p>
</td></tr>
<tr><td><code id="recoder_+3A_to">to</code></td>
<td>
<p>character vector with new values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>x where from values are recoded to the supplied to values
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+match">match</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>recoder(x=append(LETTERS, NA, 5), from = c("A","B"), to = c("a.123","b.123")) 
</code></pre>

<hr>
<h2 id='renameColumns'>Renames variables in a data frame.</h2><span id='topic+renameColumns'></span>

<h3>Description</h3>

<p>Renames variables in a data frame. <br />
</p>


<h3>Usage</h3>

<pre><code class='language-R'>renameColumns(x, from = "", to = "")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="renameColumns_+3A_x">x</code></td>
<td>
<p>data frame to be modified.</p>
</td></tr>
<tr><td><code id="renameColumns_+3A_from">from</code></td>
<td>
<p>character vector containing the current names of each variable to be renamed.</p>
</td></tr>
<tr><td><code id="renameColumns_+3A_to">to</code></td>
<td>
<p>character vector containing the new names of each variable to be renamed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The updated data frame x where the variables listed in from are 
renamed to the corresponding to column names.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+colnames">colnames</a>, <a href="#topic+recoder">recoder</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- data.frame(x = 1:4, y = LETTERS[1:4])
renameColumns(x, from = c("x","y"), to = c("digits","letters"))
</code></pre>

<hr>
<h2 id='write.dbi.ffdf'>Write ffdf data to a database table by using a DBI connection.</h2><span id='topic+write.dbi.ffdf'></span>

<h3>Description</h3>

<p>Write <code><a href="ff.html#topic+ffdf">ffdf</a></code> data to a database table by using a DBI connection.
This can for example be used to store large ffdf datasets from R in
Oracle, SQLite, MySQL, PostgreSQL, Hive or other SQL databases. <br />
Mark that for very large datasets, these SQL databases might have tools to speed up by bulk loading.
You might also consider that as an alternative to using this procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.dbi.ffdf(
  x,
  name,
  dbConnect.args = list(drv = NULL, dbname = NULL, username = "", password = ""),
  RECORDBYTES = sum(.rambytes[vmode(x)]),
  BATCHBYTES = getOption("ffbatchbytes"),
  by = NULL,
  VERBOSE = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write.dbi.ffdf_+3A_x">x</code></td>
<td>
<p>the <code><a href="ff.html#topic+ffdf">ffdf</a></code> to write to the database</p>
</td></tr>
<tr><td><code id="write.dbi.ffdf_+3A_name">name</code></td>
<td>
<p>character string with the name of the table to store the data in. Passed on to <code><a href="DBI.html#topic+dbWriteTable">dbWriteTable</a></code>.</p>
</td></tr>
<tr><td><code id="write.dbi.ffdf_+3A_dbconnect.args">dbConnect.args</code></td>
<td>
<p>a list of arguments to pass to DBI's <code><a href="DBI.html#topic+dbConnect">dbConnect</a></code> (like drv, dbname, username, password). See the examples.</p>
</td></tr>
<tr><td><code id="write.dbi.ffdf_+3A_recordbytes">RECORDBYTES</code></td>
<td>
<p>optional integer scalar representing the bytes needed to process a single row of the ffdf</p>
</td></tr>
<tr><td><code id="write.dbi.ffdf_+3A_batchbytes">BATCHBYTES</code></td>
<td>
<p>integer: bytes allowed for the size of the data.frame storing the result of reading one chunk. 
See documentation in <code><a href="ff.html#topic+read.table.ffdf">read.table.ffdf</a></code> for more details.</p>
</td></tr>
<tr><td><code id="write.dbi.ffdf_+3A_by">by</code></td>
<td>
<p>integer passed on to <code><a href="bit.html#topic+chunk">chunk</a></code> indicating to write to the database in chunks of this size. Overwrites
the behaviour of BATCHBYTES and RECORDBYTES.</p>
</td></tr>
<tr><td><code id="write.dbi.ffdf_+3A_verbose">VERBOSE</code></td>
<td>
<p>logical: TRUE to verbose timings for each processed chunk (default FALSE).</p>
</td></tr>
<tr><td><code id="write.dbi.ffdf_+3A_...">...</code></td>
<td>
<p>optional parameters passed on to <code><a href="DBI.html#topic+dbWriteTable">dbWriteTable</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Opens up the DBI connection using <code>DBI::dbConnect</code>, writes data to the SQL table
using <code>DBI::dbWriteTable</code> by extracting the data in batches from the <code><a href="ff.html#topic+ffdf">ffdf</a></code>
and appending them to the table.
</p>


<h3>Value</h3>

<p>invisible()
</p>


<h3>See Also</h3>

<p><code><a href="DBI.html#topic+dbWriteTable">dbWriteTable</a></code>, <code><a href="bit.html#topic+chunk">chunk</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(ff)

##
## Example query using data in sqlite
##
require(RSQLite)
dbfile &lt;- system.file("smalldb.sqlite3", package="ETLUtils")
drv &lt;- dbDriver("SQLite")
query &lt;- "select * from testdata limit 10000"
x &lt;- read.dbi.ffdf(query = query, dbConnect.args = list(drv = drv, dbname = dbfile), 
first.rows = 100, next.rows = 1000, VERBOSE=TRUE)

## copy db in package folder to temp folder as CRAN does not allow writing in package dirs
dbfile &lt;- tempfile(fileext = ".sqlite3")
file.copy(from = system.file("smalldb.sqlite3", package="ETLUtils"), to = dbfile)
Sys.chmod(dbfile, mode = "777")
write.dbi.ffdf(x = x, name = "helloworld", row.names = FALSE, overwrite = TRUE,
  dbConnect.args = list(drv = drv, dbname = dbfile), 
  by = 1000, VERBOSE=TRUE)
test &lt;- read.dbi.ffdf(query = "select * from helloworld", 
  dbConnect.args = list(drv = drv, dbname = dbfile))

## clean up for CRAN
file.remove(dbfile)
## Not run: 
require(ROracle)
write.dbi.ffdf(x = x, name = "hellooracle", row.names = FALSE, overwrite = TRUE,
  dbConnect.args = list(drv = dbDriver("Oracle"), 
                        user = "YourUser", password = "YourPassword", dbname = "Mydatabase"), 
  VERBOSE=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='write.jdbc.ffdf'>Write ffdf data to a database table by using a JDBC connection.</h2><span id='topic+write.jdbc.ffdf'></span>

<h3>Description</h3>

<p>Write <code><a href="ff.html#topic+ffdf">ffdf</a></code> data to a database table by using a JDBC connection.
This can for example be used to store large ffdf datasets from R in
Oracle, SQLite, MySQL, PostgreSQL, Hive or other SQL databases. <br />
Mark that for very large datasets, these SQL databases might have tools to speed up by bulk loading.
You might also consider that as an alternative to using this procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.jdbc.ffdf(
  x,
  name,
  dbConnect.args = list(drv = NULL, dbname = NULL, username = "", password = ""),
  RECORDBYTES = sum(.rambytes[vmode(x)]),
  BATCHBYTES = getOption("ffbatchbytes"),
  by = NULL,
  VERBOSE = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write.jdbc.ffdf_+3A_x">x</code></td>
<td>
<p>the <code><a href="ff.html#topic+ffdf">ffdf</a></code> to write to the database</p>
</td></tr>
<tr><td><code id="write.jdbc.ffdf_+3A_name">name</code></td>
<td>
<p>character string with the name of the table to store the data in. Passed on to <code>dbWriteTable</code>.</p>
</td></tr>
<tr><td><code id="write.jdbc.ffdf_+3A_dbconnect.args">dbConnect.args</code></td>
<td>
<p>a list of arguments to pass to JDBC's <code>RJDBC::dbConnect</code> (like drv, dbname, username, password). See the examples.</p>
</td></tr>
<tr><td><code id="write.jdbc.ffdf_+3A_recordbytes">RECORDBYTES</code></td>
<td>
<p>optional integer scalar representing the bytes needed to process a single row of the ffdf</p>
</td></tr>
<tr><td><code id="write.jdbc.ffdf_+3A_batchbytes">BATCHBYTES</code></td>
<td>
<p>integer: bytes allowed for the size of the data.frame storing the result of reading one chunk. 
See documentation in <code><a href="ff.html#topic+read.table.ffdf">read.table.ffdf</a></code> for more details.</p>
</td></tr>
<tr><td><code id="write.jdbc.ffdf_+3A_by">by</code></td>
<td>
<p>integer passed on to <code><a href="bit.html#topic+chunk">chunk</a></code> indicating to write to the database in chunks of this size. Overwrites
the behaviour of BATCHBYTES and RECORDBYTES.</p>
</td></tr>
<tr><td><code id="write.jdbc.ffdf_+3A_verbose">VERBOSE</code></td>
<td>
<p>logical: TRUE to verbose timings for each processed chunk (default FALSE).</p>
</td></tr>
<tr><td><code id="write.jdbc.ffdf_+3A_...">...</code></td>
<td>
<p>optional parameters passed on to <code>dbWriteTable</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Opens up the JDBC connection using <code>RJDBC::dbConnect</code>, writes data to the SQL table
using <code>RJDBC::dbWriteTable</code> by extracting the data in batches from the <code><a href="ff.html#topic+ffdf">ffdf</a></code>
and appending them to the table.
</p>


<h3>Value</h3>

<p>invisible()
</p>


<h3>See Also</h3>

<p><code><a href="RJDBC.html#topic+JDBCConnection-methods">JDBCConnection-methods</a></code>, <code><a href="bit.html#topic+chunk">chunk</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require(ff)

##
## Example query using data in sqlite
##
require(RJDBC)
dbfile &lt;- system.file("smalldb.sqlite3", package="ETLUtils")
drv &lt;- JDBC(driverClass = "org.sqlite.JDBC", classPath = "/usr/local/lib/sqlite-jdbc-3.7.2.jar")
query &lt;- "select * from testdata limit 10000"
x &lt;- read.jdbc.ffdf(query = query, 
 dbConnect.args = list(drv = drv, url = sprintf("jdbc:sqlite:%s", dbfile)), 
 first.rows = 100, next.rows = 1000, VERBOSE=TRUE)
 
write.jdbc.ffdf(x = x, name = "helloworld", row.names = FALSE, overwrite = TRUE,
  dbConnect.args = list(drv = drv, url = sprintf("jdbc:sqlite:%s", dbfile)), 
  by = 1000, VERBOSE=TRUE)
test &lt;- read.jdbc.ffdf(query = "select * from helloworld", 
  dbConnect.args = list(drv = drv, url = sprintf("jdbc:sqlite:%s", dbfile)))

## End(Not run)
</code></pre>

<hr>
<h2 id='write.odbc.ffdf'>Write ffdf data to a database table by using a ODBC connection.</h2><span id='topic+write.odbc.ffdf'></span>

<h3>Description</h3>

<p>Write <code><a href="ff.html#topic+ffdf">ffdf</a></code> data to a database table by using a ODBC connection.
This can for example be used to store large ffdf datasets from R in
Oracle, SQLite, MySQL, PostgreSQL, Hive or other SQL databases. <br />
Mark that for very large datasets, these SQL databases might have tools to speed up by bulk loading.
You might also consider that as an alternative to using this procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.odbc.ffdf(
  x,
  tablename,
  odbcConnect.args = list(dsn = NULL, uid = "", pwd = ""),
  RECORDBYTES = sum(.rambytes[vmode(x)]),
  BATCHBYTES = getOption("ffbatchbytes"),
  by = NULL,
  VERBOSE = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write.odbc.ffdf_+3A_x">x</code></td>
<td>
<p>the <code><a href="ff.html#topic+ffdf">ffdf</a></code> to write to the database</p>
</td></tr>
<tr><td><code id="write.odbc.ffdf_+3A_tablename">tablename</code></td>
<td>
<p>character string with the name of the table to store the data in. Passed on to <code><a href="RODBC.html#topic+sqlSave">sqlSave</a></code>.</p>
</td></tr>
<tr><td><code id="write.odbc.ffdf_+3A_odbcconnect.args">odbcConnect.args</code></td>
<td>
<p>a list of arguments to pass to ODBC's <code><a href="RODBC.html#topic+odbcConnect">odbcConnect</a></code> (like dsn, uid, pwd). See the examples.</p>
</td></tr>
<tr><td><code id="write.odbc.ffdf_+3A_recordbytes">RECORDBYTES</code></td>
<td>
<p>optional integer scalar representing the bytes needed to process a single row of the ffdf</p>
</td></tr>
<tr><td><code id="write.odbc.ffdf_+3A_batchbytes">BATCHBYTES</code></td>
<td>
<p>integer: bytes allowed for the size of the data.frame storing the result of reading one chunk. 
See documentation in <code><a href="ff.html#topic+read.table.ffdf">read.table.ffdf</a></code> for more details.</p>
</td></tr>
<tr><td><code id="write.odbc.ffdf_+3A_by">by</code></td>
<td>
<p>integer passed on to <code><a href="bit.html#topic+chunk">chunk</a></code> indicating to write to the database in chunks of this size. Overwrites
the behaviour of BATCHBYTES and RECORDBYTES.</p>
</td></tr>
<tr><td><code id="write.odbc.ffdf_+3A_verbose">VERBOSE</code></td>
<td>
<p>logical: TRUE to verbose timings for each processed chunk (default FALSE).</p>
</td></tr>
<tr><td><code id="write.odbc.ffdf_+3A_...">...</code></td>
<td>
<p>optional parameters passed on to <code><a href="RODBC.html#topic+sqlSave">sqlSave</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Opens up the ODBC connection using <code>RODBC::odbcConnect</code>, writes data to the SQL table
using <code>RODBC::sqlSave</code> by extracting the data in batches from the <code><a href="ff.html#topic+ffdf">ffdf</a></code>
and appending them to the table.
</p>


<h3>Value</h3>

<p>invisible()
</p>


<h3>See Also</h3>

<p><code><a href="RODBC.html#topic+sqlSave">sqlSave</a></code>, <code><a href="bit.html#topic+chunk">chunk</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##
## Using the sqlite database (smalldb.sqlite3) in the /inst folder of the package
## set up the sqlite ODBC driver (www.stats.ox.ac.uk/pub/bdr/RODBC-manual.pd) 
## and call it 'smalltestsqlitedb' 
##
## Not run: 
require(RODBC)
x &lt;- read.odbc.ffdf(
  query = "select * from testdata limit 10000",
  odbcConnect.args = list(
   dsn="smalltestsqlitedb", uid = "", pwd = "", 
   believeNRows = FALSE, rows_at_time = 1), 
  nrows = -1, 
  first.rows = 100, next.rows = 1000, VERBOSE = TRUE)
  
write.odbc.ffdf(x = x, tablename = "testdata", rownames = FALSE, append = TRUE,
  odbcConnect.args = list(
   dsn="smalltestsqlitedb", uid = "", pwd = "", 
   believeNRows = FALSE, rows_at_time = 1),  
  by = 1000, VERBOSE=TRUE)

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
