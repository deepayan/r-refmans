<!DOCTYPE html><html lang="en"><head><title>Help for package multivariance</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {multivariance}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#multivariance-package'><p>multivariance: Measuring Multivariate Dependence Using Distance Multivariance</p></a></li>
<li><a href='#anscombe.extended'><p>Extended Anscombe's Quartett</p></a></li>
<li><a href='#cdm'><p>computes a doubly centered distance matrix</p></a></li>
<li><a href='#cdm.mu.bcd'><p>given the sample of a single variable the doubly centered distance matrix, mu (the limit moments) and bcd (the terms for the finite sample moments) are computed</p></a></li>
<li><a href='#cdms'><p>computes the doubly centered distance matrices</p></a></li>
<li><a href='#cdms.mu.bcd'><p>computes the doubly centered distance matrices, mus and bcds</p></a></li>
<li><a href='#circle.coordinates'><p>calculates the coordinates of n points on a circle of radius r</p>
if only 1 inner point, then it is placed in the center</a></li>
<li><a href='#clean.graph'><p>cleanup dependence structure graph</p></a></li>
<li><a href='#coins'><p>dependence example: k-independent coin sampling</p></a></li>
<li><a href='#copula.multicorrelation'><p>coupla versions of distance multicorrelation</p></a></li>
<li><a href='#copula.multicorrelation.test'><p>independence tests using the copula versions of distance multivariance</p></a></li>
<li><a href='#copula.multivariance'><p>copula version of distance multivariance</p></a></li>
<li><a href='#d2'><p>functions which are required for the calculation of the finite sample expectation and variance for m-multivariance and total multivariance</p></a></li>
<li><a href='#dep_struct_iterated_13_100'><p>example dataset for <code>dependence.structure</code></p></a></li>
<li><a href='#dep_struct_ring_15_100'><p>example dataset for <code>dependence.structure</code></p></a></li>
<li><a href='#dep_struct_several_26_100'><p>example dataset for <code>dependence.structure</code></p></a></li>
<li><a href='#dep_struct_star_9_100'><p>example dataset for <code>dependence.structure</code></p></a></li>
<li><a href='#dependence.structure'><p>determines the dependence structure</p></a></li>
<li><a href='#dependence.structure.full'><p>functions to detect the full (without clustering) dependence structure</p></a></li>
<li><a href='#dist.to.matrix'><p>transforms a distance matrix to a matrix</p></a></li>
<li><a href='#dm'><p>distance matrix</p></a></li>
<li><a href='#dms'><p>list of distance matrices</p></a></li>
<li><a href='#double.center'><p>double centering of a matrix</p></a></li>
<li><a href='#doubleCenterBiasCorrected'><p>bias corrected double centering</p>
# included for speed comparison</a></li>
<li><a href='#doubleCenterBiasCorrectedUpper'><p>bias corrected double centering with normalizing</p>
# included for speed comparison</a></li>
<li><a href='#doubleCenterBiasCorrectedUpperLower'><p>bias corrected double centering with normalizing constants for upper and lower bound</p></a></li>
<li><a href='#doubleCenterSymMat'><p>double center a symmetric matrix</p></a></li>
<li><a href='#emp.transf'><p>Monte Carlo empirical transform</p></a></li>
<li><a href='#emp.transf.dep'><p>A dependent Monte Carlo emprical transform</p></a></li>
<li><a href='#emp.transf.vec'><p>Transform a vector of samples into a vector of samples of the uniform distribution</p>
such that, if applied to multiple (dependent) sample vectors, the dependence is preserved.</a></li>
<li><a href='#fastdist'><p>fast Euclidean distance matrix</p></a></li>
<li><a href='#fastEuclideanCdm'><p>fast centered Euclidean distance matrix</p></a></li>
<li><a href='#find.cluster'><p>cluster detection</p></a></li>
<li><a href='#independence.test'><p>test for independence</p></a></li>
<li><a href='#is.doubly.centered'><p>checks if a matrix is doubly centered</p></a></li>
<li><a href='#layout_on_circles'><p>special igraph layout for the dependence structure visualization</p></a></li>
<li><a href='#lower.order'><p>check if lower order dependencies are present for the given tuple indices</p>
here 'm.values' is a list of boolean matrices. Matrix [[k]] corresponds to the k tuples. For each number of tuples, the first columns of the matrix always contain the indices of the tuples</a></li>
<li><a href='#m.multivariance'><p>m distance multivariance</p></a></li>
<li><a href='#match_rows'><p>for the fast detection of the full dependence structure</p></a></li>
<li><a href='#match.rows'><p>Returns the row indices of matrix A which match with B</p>
Use the fast cpp implementation 'match_rows' instead.
Function here just for reference.</a></li>
<li><a href='#moments.for.pearson'><p>computes the moments as required for Pearson's approximation</p></a></li>
<li><a href='#mu3.unbiased'><p>given the distance matrix the unbiased estimate for mu3 is computed</p></a></li>
<li><a href='#multicorrelation'><p>distance multicorrelation</p></a></li>
<li><a href='#multicorrelation.bias.corrected'><p>bias corrected total multicorrelations</p></a></li>
<li><a href='#multivariance'><p>distance multivariance</p></a></li>
<li><a href='#multivariance.pvalue'><p>transform multivariance to p-value</p></a></li>
<li><a href='#multivariance.test'><p>independence tests based on (total-/2-/3-) multivariance</p></a></li>
<li><a href='#multivariance.timing'><p>estimate of the computation time</p></a></li>
<li><a href='#multivariances.all'><p>simultaneous computation of multivariance and total/ 2-/ 3-multivariance</p></a></li>
<li><a href='#N.coefficients'><p>Computes the explicit coefficients for the finite sample variance for a sample of size N</p></a></li>
<li><a href='#p.value.to.star.label'><p>transforms a p-value into the corresponding label</p></a></li>
<li><a href='#pairwise.multicorrelation.bias.corrected'><p>pairwise multicorrelation</p></a></li>
<li><a href='#pearson.pvalue'><p>fast p-value approximation</p></a></li>
<li><a href='#pearson.pvalue.unif'><p>compute the p-value by Pearson's approximation assuming uniform marginals and euclidean distance</p></a></li>
<li><a href='#pearson.qf'><p>approximate distribution function of a Gaussian quadratic form</p></a></li>
<li><a href='#rejection.level'><p>rejection level for the test statistic</p></a></li>
<li><a href='#resample.multivariance'><p>resampling (total /m-) multivariance</p></a></li>
<li><a href='#resample.pvalue'><p>p-value via resampling</p></a></li>
<li><a href='#resample.rejection.level'><p>rejection level via resampling</p></a></li>
<li><a href='#sample.cdms'><p>resamples doubly centered distance matrices</p></a></li>
<li><a href='#sample.cols'><p>resample the columns of a matrix</p></a></li>
<li><a href='#signed.sqrt'><p>sign preserving square root</p></a></li>
<li><a href='#simple.int.hash'><p>Simple integer hash from text</p></a></li>
<li><a href='#sums.of.products'><p>This is the function GC which is required for the computation of the finite sample variance for m and total multivariance</p></a></li>
<li><a href='#tetrahedron'><p>dependence example: tetrahedron sampling</p></a></li>
<li><a href='#total.multicorrelation.bias.corrected.upper'><p># included for speed. it is faster than upper.lower</p></a></li>
<li><a href='#total.multivariance'><p>total distance multivariance</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Measuring Multivariate Dependence Using Distance Multivariance</td>
</tr>
<tr>
<td>Version:</td>
<td>2.4.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-10-06</td>
</tr>
<tr>
<td>Description:</td>
<td>Distance multivariance is a measure of dependence which can be used to detect 
    and quantify dependence of arbitrarily many random vectors. The necessary functions are
    implemented in this packages and examples are given. It includes: distance multivariance, 
    distance multicorrelation, dependence structure detection, tests of independence and
    copula versions of distance multivariance based on the Monte Carlo empirical transform.
    Detailed references are given in the package description, as starting point for the 
    theoretic background we refer to:
    B. Böttcher, Dependence and Dependence Structures: Estimation and Visualization Using 
    the Unifying Concept of Distance Multivariance. Open Statistics, Vol. 1, No. 1 (2020), 
    &lt;<a href="https://doi.org/10.1515%2Fstat-2020-0001">doi:10.1515/stat-2020-0001</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>igraph, graphics, stats, Rcpp, microbenchmark</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-10-06 15:06:41 UTC; BB</td>
</tr>
<tr>
<td>Author:</td>
<td>Björn Böttcher [aut, cre],
  Martin Keller-Ressel [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Björn Böttcher &lt;bjoern.boettcher@tu-dresden.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-10-06 15:50:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='multivariance-package'>multivariance: Measuring Multivariate Dependence Using Distance Multivariance</h2><span id='topic+multivariance-package'></span>

<h3>Description</h3>

<p>The multivariance package provides basic functions to calculate distance multivariance and related quantities. To test independence use <code><a href="#topic+multivariance.test">multivariance.test</a></code>, it provides an interface (via its arguments) to all the tests based on distance (m-/total-)multivariance. The package offers also several other functions related to distance multivariance, e.g. a detection and visualization of dependence structures <code><a href="#topic+dependence.structure">dependence.structure</a></code>. See below for details on the full content of the package.
</p>


<h3>Details</h3>

<p>Distance multivariance is a multivariate dependence measure, which can be used to detect dependencies between an arbitrary number of random vectors each of which can have a distinct dimension. The necessary functions are implemented in this package, and examples are given. For the theoretic background we refer to the papers [1,2,3,4,5,6]. Paper [3] includes a summary of the first two. It is the recommended starting point for users with an applied interest. Paper [4] is concerned with new (faster) p-value estimates for the independence tests, [5] introduces the copula versions of distance multivariance, [6] discusses the quantification of dependence using distance multicorrelations.
</p>
<p>The (current) code is speed improved in comparison to the former releases. Certainly there is still room for improvement and development. Questions, comments and remarks are welcome: <a href="mailto:bjoern.boettcher@tu-dresden.de">bjoern.boettcher@tu-dresden.de</a>
</p>
<p>For infos on the latest changes and/or updates to the package use <code>news(package="multivariance")</code>.
</p>
<p>To cite this package use the standard citation for R packages, i.e., the output of <code>citation("multivariance")</code>.
</p>


<h3>Multivariance</h3>

<p><code><a href="#topic+multivariance">multivariance</a></code> computes the distance multivariance
</p>
<p><code><a href="#topic+total.multivariance">total.multivariance</a></code> computes the total distance multivariance
</p>
<p><code><a href="#topic+m.multivariance">m.multivariance</a></code> computes the m-multivariance (introduced in [3])
</p>
<p>It might be convenient to compute these simultaneously using <code><a href="#topic+multivariances.all">multivariances.all</a></code>.
</p>
<p><code><a href="#topic+copula.multivariance">copula.multivariance</a></code> computes the copula versions of the above (introduced in [5])
</p>
<p><code><a href="#topic+multicorrelation">multicorrelation</a></code> computes the multicorrelations (discussed specifically in [6])
</p>


<h3>Functions to use and interpret multivariance</h3>

<p><code><a href="#topic+rejection.level">rejection.level</a></code> computes a (conservative) rejection level for a given significance level. This can be used for a conservative interpretation of distance multivariance. The counterpart is <code><a href="#topic+multivariance.pvalue">multivariance.pvalue</a></code>, which computes a conservative p-value for a given distance multivariance. Both methods are distribution-free.
</p>
<p><code><a href="#topic+resample.rejection.level">resample.rejection.level</a></code> and <code><a href="#topic+resample.pvalue">resample.pvalue</a></code> are the distribution dependent versions of the above. They are approximately sharp, but computational more expensive. Any resampling is done by <code><a href="#topic+resample.multivariance">resample.multivariance</a></code>.
</p>
<p>Using the methods developed in [4] approximate p-value estimates are provided by <code><a href="#topic+pearson.pvalue">pearson.pvalue</a></code>. This method is much faster than the resampling method.
</p>
<p><code><a href="#topic+multivariance.test">multivariance.test</a></code> provides the corresponding tests of independence. The former provides output as common for tests in R.
</p>
<p><code><a href="#topic+cdm">cdm</a></code> and <code><a href="#topic+cdms">cdms</a></code> compute the doubly centered distance matrix and matrices, respectively. These can be used to speed up repeated computations of distance multivariance.
</p>
<p>In [4] various methods to estimate the moments of the test statistic under H0 were developed, these are (implicitly) implemented in this package only for the moments used in <code><a href="#topic+pearson.pvalue">pearson.pvalue</a></code>. Further and explicit functions can be added upon request. Please feel free to contact the author.
</p>
<p><code><a href="#topic+emp.transf">emp.transf</a></code> computes the Monte Carlo empirical transform of the data. This data yields the copula version of distance multivariance. Hereto note, that values become randomized due to the &quot;Monte Carlo empirical transform&quot;, i.e., the copula versions yield in a finite sample setting not identical values for repeated runs.
</p>
<p>For planing of large projects or studies it might be convenient to estimate the computation time of multivariance via <code><a href="#topic+multivariance.timing">multivariance.timing</a></code>.
</p>


<h3>Dependence structures</h3>

<p><code><a href="#topic+dependence.structure">dependence.structure</a></code> performs the dependence structure detection algorithm as described in [3].
</p>
<p><code><a href="#topic+find.cluster">find.cluster</a></code> is the basic building block of <code><a href="#topic+dependence.structure">dependence.structure</a></code>. It is recommended to use <code><a href="#topic+dependence.structure">dependence.structure</a></code>.
</p>


<h3>Examples</h3>

<p><code><a href="#topic+coins">coins</a></code> and <code><a href="#topic+tetrahedron">tetrahedron</a></code> generate samples of pairwise independent random variables, with dependence of higher order.
</p>
<p><code><a href="#topic+dep_struct_iterated_13_100">dep_struct_iterated_13_100</a></code>, <code><a href="#topic+dep_struct_ring_15_100">dep_struct_ring_15_100</a></code>, <code><a href="#topic+dep_struct_several_26_100">dep_struct_several_26_100</a></code> and <code><a href="#topic+dep_struct_star_9_100">dep_struct_star_9_100</a></code> are example data sets for the dependence structure detection. These might also serve as benchmark examples.
</p>
<p><code><a href="#topic+anscombe.extended">anscombe.extended</a></code> provides an extension of Anscombe's Quartett. It illustrates that a large value of Pearson's correlation can occur for very different dependencies and that this is not a small-sample problem. These dependencies are at least partly differentiated by values of distance multicorrelation.
</p>


<h3>References</h3>

<p>[1] B. Böttcher, M. Keller-Ressel, R.L. Schilling, Detecting independence of random vectors: generalized distance covariance and Gaussian covariance. Modern Stochastics: Theory and Applications, Vol. 5, No. 3(2018) 353-383. <a href="https://www.vmsta.org/journal/VMSTA/article/127/info">https://www.vmsta.org/journal/VMSTA/article/127/info</a>
</p>
<p>[2] B. Böttcher, M. Keller-Ressel, R.L. Schilling, Distance multivariance: New dependence measures for random vectors. The Annals of Statistics, Vol. 47, No. 5 (2019) 2757-2789. doi: <a href="https://doi.org/10.1214/18-AOS1764">10.1214/18-AOS1764</a>
</p>
<p>[3] B. Böttcher, Dependence and Dependence Structures: Estimation and Visualization using the Unifying Concept of Distance Multivariance. Open Statistics, Vol. 1, No. 1 (2020) 1-46. doi: <a href="https://doi.org/10.1515/stat-2020-0001">10.1515/stat-2020-0001</a>
</p>
<p>[4] G. Berschneider, B. Böttcher, On complex Gaussian random fields, Gaussian quadratic forms and sample distance multivariance. Preprint. <a href="https://arxiv.org/abs/1808.07280">https://arxiv.org/abs/1808.07280</a>
</p>
<p>[5] B. Böttcher, Copula versions of distance multivariance and dHSIC via the distributional transform &ndash; a general approach to construct invariant dependence measures. Statistics, (2020) 1-18. doi: <a href="https://doi.org/10.1080/02331888.2020.1748029">10.1080/02331888.2020.1748029</a>
</p>
<p>[6] B. Böttcher, Notes on the interpretation of dependence measures &ndash; Pearson's correlation, distance correlation, distance multicorrelations and their copula versions. Preprint. <a href="https://arxiv.org/abs/2004.07649">https://arxiv.org/abs/2004.07649</a>
</p>

<hr>
<h2 id='anscombe.extended'>Extended Anscombe's Quartett</h2><span id='topic+anscombe.extended'></span>

<h3>Description</h3>

<p>The dataset extends 'anscombe' provided in the
standard R-package 'datasets'. All examples feature the same
correlation of 0.82, but different types of dependencies. The main aim was to extend the classical examples, which have
sample size 11, to larger sample sizes. This illustrates that the
implied problems of Pearson's correlation are not small sample
problems! Distance multicorrelation (which coincides in
this case with distance correlation) yields different values
for the datasets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>anscombe.extended
</code></pre>


<h3>Format</h3>

<p><code>list</code> with elements:
</p>

<ul>
<li><p><code>anscombe.extended$N11</code>
matrix with 11 samples for 5 examples the first 4 are the
classical Anscombe Quartett, the fifth is a monoton relation
which also features the same correlation.
</p>
</li>
<li> <p><code>anscombe.extended$N100</code> same as above but 100 samples
</p>
</li>
<li> <p><code>anscombe.extended$N1000</code> same as above but 1000 samples
</p>
</li></ul>



<h3>Details</h3>

<p>Note: Anscombe's quartett features further identical parameters
besides Pearson's correlation. The extended set is only
concerned with correlation.
</p>


<h3>References</h3>

<p>This example was introduced in the reference [6] given on the main help page of this package: <a href="#topic+multivariance-package">multivariance-package</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Code which generates plots of all included data:
op = par(mfrow = c(3,5),mar = c(0.5,0.5,3,0.5))
for (name in c("N11","N100","N1000")) {
 for (i in 1:5) {
   x = anscombe.extended[[name]][,2*i-1]
   y = anscombe.extended[[name]][,2*i]
   plot(x,y,main = paste0("cor = ",round(cor(x,y),2),
"\n Mcor = ",round(multicorrelation(cbind(x,y),type = "pairwise",squared = FALSE),2),
"\n CMcor = ",round(copula.multicorrelation(cbind(x,y),type = "pairwise",squared = FALSE),2)),
        axes = FALSE,xlab ="",ylab = "", cex.main=1)
   # for two variables 'pairwise' coincides with
   # both values of 'total.upper.lower'.
   box()
 }
}
par(op)

</code></pre>

<hr>
<h2 id='cdm'>computes a doubly centered distance matrix</h2><span id='topic+cdm'></span>

<h3>Description</h3>

<p>computes the doubly centered distance matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdm(
  x,
  normalize = TRUE,
  psi = NULL,
  p = NULL,
  isotropic = FALSE,
  external.dm.fun = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cdm_+3A_x">x</code></td>
<td>
<p>matrix, each row of the matrix is treated as one sample</p>
</td></tr>
<tr><td><code id="cdm_+3A_normalize">normalize</code></td>
<td>
<p>logical, indicates if the matrix should be normalized</p>
</td></tr>
<tr><td><code id="cdm_+3A_psi">psi</code></td>
<td>
<p>if it is <code>NULL</code>, the euclidean distance will be used. In the case of <code>isotropic = TRUE</code>: a real valued negative definite function of one variable (accepting vectors as arguments; returning a vector of the same length). In the case of <code>isotropic = FALSE</code>: a real valued function of two variables (or vectors) to compute the distance of two samples based on a continuous negative definite function.</p>
</td></tr>
<tr><td><code id="cdm_+3A_p">p</code></td>
<td>
<p>numeric, if it is a value between 1 and 2 then the Minkowski distance with parameter p is used.</p>
</td></tr>
<tr><td><code id="cdm_+3A_isotropic">isotropic</code></td>
<td>
<p>logical, indicates if psi of the Euclidean distance matrix should be computed, i.e., if an isotropic distance should be used.</p>
</td></tr>
<tr><td><code id="cdm_+3A_external.dm.fun">external.dm.fun</code></td>
<td>
<p>here one can supply an external function, which computes the distance matrix given <code>x</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The doubly centered distance matrices are required for the computation of (total / m-) multivariance.
</p>
<p>If <code>normalize = TRUE</code> then the value of multivariance is comparable and meaningful. It can be compared to the <code><a href="#topic+rejection.level">rejection.level</a></code> or its p-value <code><a href="#topic+multivariance.pvalue">multivariance.pvalue</a></code> can be computed.
</p>
<p>More details: If <code>normalize = TRUE</code> the matrix is scaled such that the multivariance based on it, times the sample size, has in the limit - in the case of independence - the distribution of an L^2 norm of a Gaussian process with known expectation.
</p>
<p>As default the Euclidean distance is used. The parameters <code>psi</code>, <code>p</code>, <code>isotropic</code> and <code>external.dm.fun</code> can be used to select a different distance. In particular, <code>external.dm.fun</code> can be used to provide any function which calculates a distance matrix for the rows of a given matrix.
</p>


<h3>References</h3>

<p>For the theoretic background see the references given on the main help page of this package: <a href="#topic+multivariance-package">multivariance-package</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = coins(100)
cdm(x) # fast euclidean distances
cdm(x,psi = function(x,y) sqrt(sum((x-y)^2))) # this is identical to the previous (but slower)

# the function cdm does the following three lines in a faster way
N = nrow(x)
C = diag(N) - matrix(1/N,nrow = N,ncol = N)
A = - C %*% as.matrix(stats::dist(x,method="euclidean")) %*% C #'
all(abs(A- cdm(x,normalize = FALSE)) &lt; 10^(-12))

</code></pre>

<hr>
<h2 id='cdm.mu.bcd'>given the sample of a single variable the doubly centered distance matrix, mu (the limit moments) and bcd (the terms for the finite sample moments) are computed</h2><span id='topic+cdm.mu.bcd'></span>

<h3>Description</h3>

<p>The normalization should be postponed to the moment calculation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdm.mu.bcd(
  x,
  normalize = FALSE,
  psi = NULL,
  p = NULL,
  isotropic = FALSE,
  unbiased.moments = TRUE,
  external.dm.fun = NULL
)
</code></pre>

<hr>
<h2 id='cdms'>computes the doubly centered distance matrices</h2><span id='topic+cdms'></span>

<h3>Description</h3>

<p>computes the doubly centered distance matrices
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdms(x, vec = 1:ncol(x), membership = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cdms_+3A_x">x</code></td>
<td>
<p>matrix, each row is a sample</p>
</td></tr>
<tr><td><code id="cdms_+3A_vec">vec</code></td>
<td>
<p>vector which indicates which columns are treated as one sample</p>
</td></tr>
<tr><td><code id="cdms_+3A_membership">membership</code></td>
<td>
<p>depreciated. Now use <code>vec</code>.</p>
</td></tr>
<tr><td><code id="cdms_+3A_...">...</code></td>
<td>
<p>these are passed to <code><a href="#topic+cdm">cdm</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>It returns a list of distance matrices.
</p>

<hr>
<h2 id='cdms.mu.bcd'>computes the doubly centered distance matrices, mus and bcds</h2><span id='topic+cdms.mu.bcd'></span>

<h3>Description</h3>

<p>computes the doubly centered distance matrices, mus and bcds
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdms.mu.bcd(x, vec = 1:ncol(x), membership = NULL, cdm.normalize = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cdms.mu.bcd_+3A_x">x</code></td>
<td>
<p>matrix, each row is a sample</p>
</td></tr>
<tr><td><code id="cdms.mu.bcd_+3A_vec">vec</code></td>
<td>
<p>vector which indicates which columns are treated as one sample</p>
</td></tr>
<tr><td><code id="cdms.mu.bcd_+3A_membership">membership</code></td>
<td>
<p>depreciated. Now use <code>vec</code>.</p>
</td></tr>
<tr><td><code id="cdms.mu.bcd_+3A_...">...</code></td>
<td>
<p>these are passed to <code><a href="#topic+cdm">cdm</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following components:
</p>

<dl>
<dt><code>list.cdm</code></dt><dd><p>list of the doubly centered distance matrices - these are always normalized if 'cdm.normalize = TRUE'!!!,</p>
</dd>
<dt><code>mu</code></dt><dd><p>matrix with the limit moments in a column for each variable,</p>
</dd>
<dt><code>bcd</code></dt><dd><p>matrix with b, c, d (which are required for the computation of the finite sample moments) in columns for each variable,</p>
</dd>
<dt><code>mean</code></dt><dd><p>vector with the mean of each distance matrix.</p>
</dd>
</dl>


<hr>
<h2 id='circle.coordinates'>calculates the coordinates of n points on a circle of radius r
if only 1 inner point, then it is placed in the center</h2><span id='topic+circle.coordinates'></span>

<h3>Description</h3>

<p>calculates the coordinates of n points on a circle of radius r
if only 1 inner point, then it is placed in the center
</p>


<h3>Usage</h3>

<pre><code class='language-R'>circle.coordinates(n, r = 0.5, add.angle = 0)
</code></pre>

<hr>
<h2 id='clean.graph'>cleanup dependence structure graph</h2><span id='topic+clean.graph'></span>

<h3>Description</h3>

<p>Given a dependence structure graph: vertices representing the multivariances of only two vertices can be turned into an edge labeled with the label of the vertex. Moreover, only subsets of the graph can be selected.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clean.graph(
  g,
  only.level = NULL,
  simplify.pairs = TRUE,
  drop.label.pairs = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clean.graph_+3A_g">g</code></td>
<td>
<p>graph, created by <code><a href="#topic+dependence.structure">dependence.structure</a></code></p>
</td></tr>
<tr><td><code id="clean.graph_+3A_only.level">only.level</code></td>
<td>
<p>integer vector, if provided all edges and dependency nodes corresponding to dependence orders not given in 'only.level' are removed</p>
</td></tr>
<tr><td><code id="clean.graph_+3A_simplify.pairs">simplify.pairs</code></td>
<td>
<p>boolean, if true dependency nodes which are only connected to two variables are turned into edges</p>
</td></tr>
<tr><td><code id="clean.graph_+3A_drop.label.pairs">drop.label.pairs</code></td>
<td>
<p>boolean, if true the labels for edges indicating pairwise dependence are removed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note: The option 'only.level' works only properly for a full dependence structure graph, in the case of a clustered dependence structure graph dependency nodes representing a cluster might be removed.
</p>


<h3>Value</h3>

<p>graph
</p>


<h3>Examples</h3>

<pre><code class='language-R'>N = 200
y = coins(N,2)
x = cbind(y,y,y)

ds = dependence.structure(x,structure.type = "clustered")
plot(clean.graph(ds$graph))
plot(clean.graph(ds$graph,only.level = 2))
plot(clean.graph(ds$graph,only.level = 3)) # of limited use for a clustered graph,
# i.e., here the three-dependence node without edges indicates that
# all edges were connected to clusters

ds = dependence.structure(x,structure.type = "full")
plot(clean.graph(ds$graph))
plot(clean.graph(ds$graph,drop.label.pairs = TRUE))
plot(clean.graph(ds$graph,only.level = 2))
plot(clean.graph(ds$graph,only.level = 2,drop.label.pairs = TRUE))
plot(clean.graph(ds$graph,only.level = 3))

</code></pre>

<hr>
<h2 id='coins'>dependence example: k-independent coin sampling</h2><span id='topic+coins'></span>

<h3>Description</h3>

<p>This function creates samples which are dependent but k-independent.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coins(N = 1000, k = 2, type = "even")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coins_+3A_n">N</code></td>
<td>
<p>number of samples</p>
</td></tr>
<tr><td><code id="coins_+3A_k">k</code></td>
<td>
<p>each k-tuple will be independent</p>
</td></tr>
<tr><td><code id="coins_+3A_type">type</code></td>
<td>
<p>one of <code>"even"</code> or <code>"odd"</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Throw <code>k</code> independent fair coins. Now consider
the k+1 events: The first shows head, the second shows head,... the <code>k</code>-th shows head,
there is an <code>even</code> (or <code>odd</code> as selected via <code>type</code>) number of heads. Each row
contains the state of these k+1 events.
</p>


<h3>Value</h3>

<p>It returns the samples as rows of an <code>N</code> by <code>k+1</code> matrix. The columns are dependent but k-independent.
</p>


<h3>References</h3>

<p>For the theoretic background see the reference [3] given on the main help page of this package: <a href="#topic+multivariance-package">multivariance-package</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>coins(200,4)

</code></pre>

<hr>
<h2 id='copula.multicorrelation'>coupla versions of distance multicorrelation</h2><span id='topic+copula.multicorrelation'></span><span id='topic+CMcor'></span>

<h3>Description</h3>

<p>Formally it is nothing but distance multicorrelation applied to the Monte Carlo emprical transform of the data. Hence its values vary for repeated runs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>copula.multicorrelation(x, vec = 1:ncol(x), ...)

CMcor(x, vec = 1:ncol(x), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="copula.multicorrelation_+3A_x">x</code></td>
<td>
<p>either a data matrix or a list of doubly centered distance matrices</p>
</td></tr>
<tr><td><code id="copula.multicorrelation_+3A_vec">vec</code></td>
<td>
<p>if x is a matrix, then this indicates which columns are treated together as one sample; if x is a list, these are the indexes for which the multivariance is calculated. The default is all columns and all indexes, respectively.</p>
</td></tr>
<tr><td><code id="copula.multicorrelation_+3A_...">...</code></td>
<td>
<p>are passed to <code><a href="#topic+multicorrelation">multicorrelation</a></code></p>
</td></tr>
</table>


<h3>References</h3>

<p>For the theoretic background see the reference [5] given on the main help page of this package: <a href="#topic+multivariance-package">multivariance-package</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multicorrelation">multicorrelation</a></code>
</p>

<hr>
<h2 id='copula.multicorrelation.test'>independence tests using the copula versions of distance multivariance</h2><span id='topic+copula.multicorrelation.test'></span>

<h3>Description</h3>

<p>Formally it is nothing but tests for distance multivariance applied to the Monte Carlo emprical transform of the data. Hence its values vary for repeated runs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>copula.multicorrelation.test(x, vec = 1:ncol(x), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="copula.multicorrelation.test_+3A_x">x</code></td>
<td>
<p>matrix, each row is a sample</p>
</td></tr>
<tr><td><code id="copula.multicorrelation.test_+3A_vec">vec</code></td>
<td>
<p>vector which indicates which columns are treated as one sample</p>
</td></tr>
<tr><td><code id="copula.multicorrelation.test_+3A_...">...</code></td>
<td>
<p>these are passed to <code><a href="#topic+cdm">cdm</a></code></p>
</td></tr>
</table>


<h3>References</h3>

<p>For the theoretic background see the reference [5] given on the main help page of this package: <a href="#topic+multivariance-package">multivariance-package</a>.
</p>

<hr>
<h2 id='copula.multivariance'>copula version of distance multivariance</h2><span id='topic+copula.multivariance'></span>

<h3>Description</h3>

<p>Formally it is nothing but distance multivariance applied to the Monte Carlo emprical transform of the data. Hence its values vary for repeated runs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>copula.multivariance(x, vec = 1:ncol(x), type = "total", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="copula.multivariance_+3A_x">x</code></td>
<td>
<p>either a data matrix or a list of doubly centered distance matrices</p>
</td></tr>
<tr><td><code id="copula.multivariance_+3A_vec">vec</code></td>
<td>
<p>if x is a matrix, then this indicates which columns are treated together as one sample; if x is a list, these are the indexes for which the multivariance is calculated. The default is all columns and all indexes, respectively.</p>
</td></tr>
<tr><td><code id="copula.multivariance_+3A_type">type</code></td>
<td>
<p>default: &quot;total.lower.upper&quot;, for details and other options see below</p>
</td></tr>
<tr><td><code id="copula.multivariance_+3A_...">...</code></td>
<td>
<p>these are passed to <code><a href="#topic+cdms">cdms</a></code> (which is only invoked if <code>x</code> is a matrix)</p>
</td></tr>
</table>


<h3>References</h3>

<p>For the theoretic background see the reference [5] given on the main help page of this package: <a href="#topic+multivariance-package">multivariance-package</a>.
</p>

<hr>
<h2 id='d2'>functions which are required for the calculation of the finite sample expectation and variance for m-multivariance and total multivariance</h2><span id='topic+d2'></span>

<h3>Description</h3>

<p>functions which are required for the calculation of the finite sample expectation and variance for m-multivariance and total multivariance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d2(a, b)
</code></pre>

<hr>
<h2 id='dep_struct_iterated_13_100'>example dataset for <code><a href="#topic+dependence.structure">dependence.structure</a></code></h2><span id='topic+dep_struct_iterated_13_100'></span>

<h3>Description</h3>

<p>It was generated by </p>
<pre>
set.seed(532333356)
N = 100
x = matrix(sample.int(2,10*N,replace = TRUE)-1,ncol = 10)
for (i in c(2,5,9)) x = cbind(x,(rowSums(as.matrix(x[,1:(i-1)])) 
dep_struct_iterated_13_100 = x
save(dep_struct_iterated_13_100,file ="dep_struct_iterated_13_100.rda")
</pre>


<h3>Usage</h3>

<pre><code class='language-R'>dep_struct_iterated_13_100
</code></pre>


<h3>Format</h3>

<p><code>matrix</code> 13 variables (columns), 100 independent samples (rows)
</p>


<h3>Details</h3>

<p>To avoid irritation, note that the seed is just a simple integer hash value of the variable name.
</p>

<hr>
<h2 id='dep_struct_ring_15_100'>example dataset for <code><a href="#topic+dependence.structure">dependence.structure</a></code></h2><span id='topic+dep_struct_ring_15_100'></span>

<h3>Description</h3>

<p>It was generated by </p>
<pre>
set.seed(436646700)
N = 100
n= 15
x=matrix(sample.int(2,N*n,replace = TRUE)-1,nrow =N)
x[,4] = rowSums(x[,1:3]) 
x[,7] = rowSums(x[,4:6]) 
x[,10] = rowSums(x[,7:9]) 
x[,13] = rowSums(x[,10:12]) 
x[,15] = rowSums(x[,c(13,14,1)]) 
dep_struct_ring_15_100 = x
save(dep_struct_ring_15_100,file ="dep_struct_ring_15_100.rda")
</pre>


<h3>Usage</h3>

<pre><code class='language-R'>dep_struct_ring_15_100
</code></pre>


<h3>Format</h3>

<p><code>matrix</code> 15 variables (columns), 100 independent samples (rows)
</p>


<h3>Details</h3>

<p>To avoid irritation, note that the seed is just a simple integer hash value of the variable name.
</p>

<hr>
<h2 id='dep_struct_several_26_100'>example dataset for <code><a href="#topic+dependence.structure">dependence.structure</a></code></h2><span id='topic+dep_struct_several_26_100'></span>

<h3>Description</h3>

<p>It was generated by </p>
<pre>
set.seed(1348879148)
N = 100
dep_struct_several_26_100 = cbind(coins(N,2),tetrahedron(N),coins(N,4),
    tetrahedron(N),tetrahedron(N),coins(N,3),coins(N,3),rnorm(N))
save(dep_struct_several_26_100,file ="dep_struct_several_26_100.rda")
</pre>


<h3>Usage</h3>

<pre><code class='language-R'>dep_struct_several_26_100
</code></pre>


<h3>Format</h3>

<p><code>matrix</code> 26 variables (columns), 100 independent samples (rows)
</p>


<h3>Details</h3>

<p>To avoid irritation, note that the seed is just a simple integer hash value of the variable name.
</p>

<hr>
<h2 id='dep_struct_star_9_100'>example dataset for <code><a href="#topic+dependence.structure">dependence.structure</a></code></h2><span id='topic+dep_struct_star_9_100'></span>

<h3>Description</h3>

<p>It was generated by </p>
<pre>
set.seed(222454572)
N = 100
y = coins(N,2)
dep_struct_star_9_100 = cbind(y,y,y)
save(dep_struct_star_9_100,file ="dep_struct_star_9_100.rda")
</pre>


<h3>Usage</h3>

<pre><code class='language-R'>dep_struct_star_9_100
</code></pre>


<h3>Format</h3>

<p><code>matrix</code> 9 variables (columns), 100 independent samples (rows)
</p>


<h3>Details</h3>

<p>To avoid irritation, note that the seed is just a simple integer hash value of the variable name.
</p>

<hr>
<h2 id='dependence.structure'>determines the dependence structure</h2><span id='topic+dependence.structure'></span>

<h3>Description</h3>

<p>Determines the dependence structure as described in [3].
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dependence.structure(
  x,
  vec = 1:ncol(x),
  verbose = TRUE,
  detection.aim = NULL,
  type = "conservative",
  structure.type = "clustered",
  c.factor = 2,
  list.cdm = NULL,
  alpha = 0.05,
  p.adjust.method = "holm",
  stop.too.many = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dependence.structure_+3A_x">x</code></td>
<td>
<p>matrix, each row of the matrix is treated as one sample</p>
</td></tr>
<tr><td><code id="dependence.structure_+3A_vec">vec</code></td>
<td>
<p>vector, it indicates which columns are initially treated together as one sample</p>
</td></tr>
<tr><td><code id="dependence.structure_+3A_verbose">verbose</code></td>
<td>
<p>boolean, if <code>TRUE</code> details are printed during the detection and whenever a cluster is newly detected the (so far) detected dependence structure is plotted.</p>
</td></tr>
<tr><td><code id="dependence.structure_+3A_detection.aim">detection.aim</code></td>
<td>
<p><code>=NULL</code> or a list of vectors which indicate the expected detection, see below for more details</p>
</td></tr>
<tr><td><code id="dependence.structure_+3A_type">type</code></td>
<td>
<p>the method used for the detection, one of '<code>conservative</code>','<code>resample</code>','<code>pearson_approx</code>' or '<code>consistent</code>'</p>
</td></tr>
<tr><td><code id="dependence.structure_+3A_structure.type">structure.type</code></td>
<td>
<p>either the '<code>clustered</code>' or the '<code>full</code>' structure is detected</p>
</td></tr>
<tr><td><code id="dependence.structure_+3A_c.factor">c.factor</code></td>
<td>
<p>numeric, larger than 0, a constant factor used in the case of '<code>type = "consistent"</code>'</p>
</td></tr>
<tr><td><code id="dependence.structure_+3A_list.cdm">list.cdm</code></td>
<td>
<p>not required, the list of doubly centered distance matrices corresponding to <code>x</code> speeds up the computation if given</p>
</td></tr>
<tr><td><code id="dependence.structure_+3A_alpha">alpha</code></td>
<td>
<p>numeric between 0 and 1, the significance level used for the tests</p>
</td></tr>
<tr><td><code id="dependence.structure_+3A_p.adjust.method">p.adjust.method</code></td>
<td>
<p>a string indicating the p-value adjustment for multiple testing, see <code><a href="stats.html#topic+p.adjust.methods">p.adjust.methods</a></code></p>
</td></tr>
<tr><td><code id="dependence.structure_+3A_stop.too.many">stop.too.many</code></td>
<td>
<p>numeric, upper limit for the number of tested tuples. A warning is issued if it is used. Use <code>stop.too.many = NULL</code> for no limit.</p>
</td></tr>
<tr><td><code id="dependence.structure_+3A_...">...</code></td>
<td>
<p>these are passed to <code><a href="#topic+find.cluster">find.cluster</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Performs the detection of the dependence structure as described in [3]. In the <code>clustered</code> structure variables are clustered and treated as one variable as soon as a dependence is detected, the <code>full</code> structure treats always each variable separately. The detection is either based on tests with significance level <code>alpha</code> or a <code>consistent</code> estimator is used. The latter yields (in the limit for increasing sample size) under very mild conditions always the correct dependence structure (but the convergence might be very slow).
</p>
<p>If <code>fixed.rejection.level</code> is not provided, the significance level <code>alpha</code> is used to determine which multivariances are significant using the distribution-free rejection level. As default the Holm method is used for p-value correction corresponding to multiple testing.
</p>
<p>The resulting graph can be simplified (pairwise dependence can be represented by edges instead of vertices) using <code><a href="#topic+clean.graph">clean.graph</a></code>.
</p>
<p>Advanced:
The argument <code>detection.aim</code> is currently only implemented for <code>structure.type = clustered</code>. It can be used to check, if an expected dependence structure was detected. This might be useful for simulation studies to determine the empirical power of the detection algorithm. Hereto  <code>detection.aim</code> is set to a list of vectors which indicate the expected detected dependence structures (one for each run of <code><a href="#topic+find.cluster">find.cluster</a></code>). The vector has as first element the <code>k</code> for which k-tuples are detected (for this aim the detection stops without success if no k-tuple is found), and the other elements, indicate to which clusters all present vertices belong after the detection, e.g. <code>c(3,2,2,1,2,1,1,2,1)</code> expects that 3-tuples are detected and in the graph are 8 vertices (including those representing the detected 3 dependencies), the order of the 2's and 1's indicate which vertices belong to which cluster. If <code>detection.aim</code> is provided, the vector representing the actual detection is printed, thus one can use the output with copy-paste to fix successively the expected detection aims.
</p>
<p>Note that a failed detection might invoke the warning:
</p>
<pre>
run$mem == detection.aim[[k]][-1] :
longer object length is not a multiple of shorter object length
</pre>


<h3>Value</h3>

<p>returns a list with elements:
</p>

<dl>
<dt><code>multivariances</code></dt><dd><p>calculated multivariances,</p>
</dd>
<dt><code>cdms</code></dt><dd><p>calculated doubly centered distance matrices,</p>
</dd>
<dt><code>graph</code></dt><dd><p>graph representing the dependence structure,</p>
</dd>
<dt><code>detected</code></dt><dd><p>boolean, this is only included if a <code>detection.aim</code> is given,</p>
</dd>
<dt><code>number.of.dep.tuples</code></dt><dd><p>vector, with the number of dependent tuples for each tested order. For the full dependence structure a value of -1 indicates that all tuples of this order are already lower order dependent, a value of -2 indicates that there were more than <code>stop.too.many</code> tuples,</p>
</dd>
<dt><code>structure.type</code></dt><dd><p>either <code>clustered</code> or <code>full</code>,</p>
</dd>
<dt><code>type</code></dt><dd><p>the type of p-value estimation or consistent estimation used,</p>
</dd>
<dt><code>total.number.of.tests</code></dt><dd><p>numeric vector, with the number of tests for each group of tests,</p>
</dd>
<dt><code>typeI.error.prob</code></dt><dd><p>estimated probability of a type I error,</p>
</dd>
<dt><code>alpha</code></dt><dd><p>significance level used if a p-value estimation procedure is used,</p>
</dd>
<dt><code>c.factor</code></dt><dd><p>factor used if a consistent estimation procedure is used,</p>
</dd>
<dt><code>parameter.range</code></dt><dd><p>significance levels (or 'c.factor' values) which yield the same detection result.</p>
</dd>
</dl>



<h3>References</h3>

<p>For the theoretic background see the reference [3] given on the main help page of this package: <a href="#topic+multivariance-package">multivariance-package</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# structures for the datasets included in the package
dependence.structure(dep_struct_several_26_100)
dependence.structure(dep_struct_star_9_100)
dependence.structure(dep_struct_iterated_13_100)
dependence.structure(dep_struct_ring_15_100)

# basic examples:

x = coins(100) # 3-dependent
dependence.structure(x)

colnames(x) = c("A","B","C")
dependence.structure(x) # names of variables are used as labels

dependence.structure(coins(100),vec = c(1,1,2))
# 3-dependent rv of which the first two rv are used together as one rv, thus 2-dependence.

dependence.structure(x,vec = c(1,1,2)) # names of variables are used as labels


dependence.structure(cbind(coins(200),coins(200,k=5)),verbose = TRUE)
#1,2,3 are 3-dependent, 4,..,9 are 6-dependent

# similar to the the previous example, but
# the pair 1,3 is treated as one sample,
# anagously the pair 2,4. In the resulting structure one does not
# see anymore that the dependence of 1,2,3,4 with the rest is due
# to 4.
dependence.structure(cbind(coins(200),coins(200,k=5)),
                           vec = c(1,2,1,2,3,4,5,6,7),verbose = TRUE)


### Advanced:

# How to check the empirical power of the detection algorithm?
# Use a dataset for which the structure is detected, e.g. dep_struct_several_26_100.
# run:
dependence.structure(dep_struct_several_26_100,
                     detection.aim = list(c(ncol(dep_struct_several_26_100))))
# The output provides the first detection aim. Now we run the same line with the added
# detection aim
dependence.structure(dep_struct_several_26_100,detection.aim = list(c(3,1, 1, 1, 2, 2, 2, 3, 4,
  5, 6, 7, 8, 8, 8, 9, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 1, 2, 8, 9),
  c(ncol(dep_struct_several_26_100))))
# and get the next detection aim ... thus we finally obtain all detection aims.
# now we can run the code with new sample data ....
N = 100
dependence.structure(cbind(coins(N,2),tetrahedron(N),coins(N,4),tetrahedron(N),
                           tetrahedron(N),coins(N,3),coins(N,3),rnorm(N)),
                     detection.aim = list(c(3,1, 1, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8, 8, 8,
  9, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 1, 2, 8, 9),
  c(4,1, 1, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8, 8, 8, 9, 9, 9, 10, 10, 10, 10, 11, 11, 11,
    11, 12, 1, 2, 8, 9, 10, 11),
  c(5, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7, 8, 1,
    2, 4, 5, 6, 7, 3),
  c(5, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7, 8, 1,
    2, 4, 5, 6, 7, 3)))$detected
# ... and one could start to store the results and compute the rate of successes.

# ... or one could try to check how many samples are necessary for the detection:
re = numeric(100)
for (i in 2:100) {
  re[i] =
    dependence.structure(dep_struct_several_26_100[1:i,],verbose = FALSE,
                         detection.aim = list(c(3,1, 1, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8,
      8, 8, 9, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 1, 2, 8, 9),
      c(4,1, 1, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8, 8, 8, 9, 9, 9, 10, 10, 10, 10, 11, 11,
        11, 11, 12, 1, 2, 8, 9, 10, 11),
      c(5, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7,
        8, 1, 2, 4, 5, 6, 7, 3),
      c(5, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7,
        8, 1, 2, 4, 5, 6, 7, 3)))$detected
  print(paste("First", i,"samples. Detected?", re[i]==1))
}
cat(paste("Given the 1 to k'th row the structure is not detected for k =",which(re == FALSE),"\n"))

</code></pre>

<hr>
<h2 id='dependence.structure.full'>functions to detect the full (without clustering) dependence structure</h2><span id='topic+dependence.structure.full'></span>

<h3>Description</h3>

<p>functions to detect the full (without clustering) dependence structure
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dependence.structure.full(
  x,
  vec = 1:ncol(x),
  verbose = TRUE,
  type = "conservative",
  alpha = 0.05,
  list.cdm = NULL,
  maxk = max(vec),
  stop.too.many = NULL,
  c.factor = 2,
  ...
)
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'># multivariance:::dependence.structure.full(dep_struct_ring_15_100)
# dependence.structure(dep_struct_ring_15_100,structure.type = "full")

</code></pre>

<hr>
<h2 id='dist.to.matrix'>transforms a distance matrix to a matrix</h2><span id='topic+dist.to.matrix'></span>

<h3>Description</h3>

<p>Does for a distance matrix generated via <code>dist</code> the same as <code>as.matrix</code> only slightly faster.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dist.to.matrix(ds)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dist.to.matrix_+3A_ds">ds</code></td>
<td>
<p>a distance matrix object, e.g. generated by <code><a href="stats.html#topic+dist">dist</a></code></p>
</td></tr>
</table>

<hr>
<h2 id='dm'>distance matrix</h2><span id='topic+dm'></span>

<h3>Description</h3>

<p># currently only used for the bias corrected multicorrelations
# it might be used globally to remove redundancies
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dm(x, psi = NULL, p = NULL, isotropic = FALSE, external.dm.fun = NULL)
</code></pre>

<hr>
<h2 id='dms'>list of distance matrices</h2><span id='topic+dms'></span>

<h3>Description</h3>

<p># currently only used for the bias corrected multicorrelations
# it might be used globally, to remove redundancies
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dms(x, vec = 1:ncol(x), ...)
</code></pre>

<hr>
<h2 id='double.center'>double centering of a matrix</h2><span id='topic+double.center'></span>

<h3>Description</h3>

<p># changed default after 2.0.0
</p>


<h3>Usage</h3>

<pre><code class='language-R'>double.center(dm, normalize = TRUE)
</code></pre>

<hr>
<h2 id='doubleCenterBiasCorrected'>bias corrected double centering
# included for speed comparison</h2><span id='topic+doubleCenterBiasCorrected'></span>

<h3>Description</h3>

<p>bias corrected double centering
# included for speed comparison
</p>


<h3>Usage</h3>

<pre><code class='language-R'>doubleCenterBiasCorrected(x)
</code></pre>

<hr>
<h2 id='doubleCenterBiasCorrectedUpper'>bias corrected double centering with normalizing
# included for speed comparison</h2><span id='topic+doubleCenterBiasCorrectedUpper'></span>

<h3>Description</h3>

<p>bias corrected double centering with normalizing
# included for speed comparison
</p>


<h3>Usage</h3>

<pre><code class='language-R'>doubleCenterBiasCorrectedUpper(x)
</code></pre>

<hr>
<h2 id='doubleCenterBiasCorrectedUpperLower'>bias corrected double centering with normalizing constants for upper and lower bound</h2><span id='topic+doubleCenterBiasCorrectedUpperLower'></span>

<h3>Description</h3>

<p>bias corrected double centering with normalizing constants for upper and lower bound
</p>


<h3>Usage</h3>

<pre><code class='language-R'>doubleCenterBiasCorrectedUpperLower(x, n)
</code></pre>

<hr>
<h2 id='doubleCenterSymMat'>double center a symmetric matrix</h2><span id='topic+doubleCenterSymMat'></span>

<h3>Description</h3>

<p>double center a symmetric matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>doubleCenterSymMat(x, normalize)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="doubleCenterSymMat_+3A_x">x</code></td>
<td>
<p>symmetric matrix</p>
</td></tr>
<tr><td><code id="doubleCenterSymMat_+3A_normalize">normalize</code></td>
<td>
<p>boolean. If <code>TRUE</code> the matrix will be normalized to mean 1.</p>
</td></tr>
</table>

<hr>
<h2 id='emp.transf'>Monte Carlo empirical transform</h2><span id='topic+emp.transf'></span>

<h3>Description</h3>

<p>Transforms a matrix (rows: samples, columns: variables) into a matrix of uniform samples with the same dependence structure via the Monte Carlo empirical transform.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emp.transf(x, continuous = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="emp.transf_+3A_x">x</code></td>
<td>
<p>data matrix (rows: samples, columns: variables)</p>
</td></tr>
<tr><td><code id="emp.transf_+3A_continuous">continuous</code></td>
<td>
<p>boolean, if TRUE it provides the classical (non-Monte-Carlo) transformation by the empirical distribution function, which is a reasonable choice for data of continuous distributions.</p>
</td></tr>
</table>


<h3>References</h3>

<p>For the theoretic background see the reference [5] given on the main help page of this package: <a href="#topic+multivariance-package">multivariance-package</a>.
</p>

<hr>
<h2 id='emp.transf.dep'>A dependent Monte Carlo emprical transform</h2><span id='topic+emp.transf.dep'></span>

<h3>Description</h3>

<p>It is dependendent, since each component uses the same uniformly distributed sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emp.transf.dep(x)
</code></pre>

<hr>
<h2 id='emp.transf.vec'>Transform a vector of samples into a vector of samples of the uniform distribution
such that, if applied to multiple (dependent) sample vectors, the dependence is preserved.</h2><span id='topic+emp.transf.vec'></span>

<h3>Description</h3>

<p>Transform a vector of samples into a vector of samples of the uniform distribution
such that, if applied to multiple (dependent) sample vectors, the dependence is preserved.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emp.transf.vec(x, unif.samples = stats::runif(length(x)))
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'># x = rnorm(100)
# plot(emp.transf.vec(x))

</code></pre>

<hr>
<h2 id='fastdist'>fast Euclidean distance matrix</h2><span id='topic+fastdist'></span>

<h3>Description</h3>

<p>fast Euclidean distance matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fastdist(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fastdist_+3A_x">x</code></td>
<td>
<p>matrix with sample rows for which the distance matrix is computed (to use with vectors, use <code>as.matrix(x)</code>)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>#require(microbenchmark)
#x = rnorm(100)
#microbenchmark(fastdist(as.matrix(x)),as.matrix(dist(x)))
</code></pre>

<hr>
<h2 id='fastEuclideanCdm'>fast centered Euclidean distance matrix</h2><span id='topic+fastEuclideanCdm'></span>

<h3>Description</h3>

<p>fast centered Euclidean distance matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fastEuclideanCdm(x, normalize)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fastEuclideanCdm_+3A_x">x</code></td>
<td>
<p>matrix with sample rows for which the distance matrix is computed (to use with vectors, use <code>as.matrix(x)</code>)</p>
</td></tr>
<tr><td><code id="fastEuclideanCdm_+3A_normalize">normalize</code></td>
<td>
<p>boolean. If <code>TRUE</code> the matrix will be normalized to mean 1.</p>
</td></tr>
</table>

<hr>
<h2 id='find.cluster'>cluster detection</h2><span id='topic+find.cluster'></span>

<h3>Description</h3>

<p>Performs the detection of dependence structures algorithm until a cluster is found. This function is the basic building block <code><a href="#topic+dependence.structure">dependence.structure</a></code>. Advanced users, might use it directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find.cluster(
  x,
  vec = 1:ncol(x),
  list.cdm = cdms(x, vec = vec),
  mem = as.numeric(1:max(vec)),
  cluster.to.vertex = 1:max(mem),
  vertex.to.cdm = 1:max(mem),
  previous.n.o.cdms = rep(0, max(mem)),
  all.multivariances = numeric(0),
  g = igraph::add.vertices(igraph::graph.empty(, directed = FALSE), max(mem), label =
    sapply(1:max(mem), function(r) paste(colnames(x, do.NULL = FALSE, prefix = "")[vec ==
    r], collapse = ",")), shape = "circle"),
  fixed.rejection.level = NA,
  alpha = 0.05,
  p.adjust.method = "holm",
  verbose = TRUE,
  kvec = 2:max(mem),
  parameter.range = NULL,
  type = "conservative",
  stop.too.many = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="find.cluster_+3A_x">x</code></td>
<td>
<p>matrix with the samples</p>
</td></tr>
<tr><td><code id="find.cluster_+3A_vec">vec</code></td>
<td>
<p>vector, it indicates which columns are initially treated together as one sample</p>
</td></tr>
<tr><td><code id="find.cluster_+3A_list.cdm">list.cdm</code></td>
<td>
<p>list of doubly centered distance matrices</p>
</td></tr>
<tr><td><code id="find.cluster_+3A_mem">mem</code></td>
<td>
<p>numeric vector, its length is the number of vertices, its content is the number of the corresponding cluster for the current iteration, i.e., vertex <code>i</code> belongs to cluster <code>mem[i]</code></p>
</td></tr>
<tr><td><code id="find.cluster_+3A_cluster.to.vertex">cluster.to.vertex</code></td>
<td>
<p>vector, contains the cluster to vertex relations, i.e., <code>cluster.to.vertex[i]</code> is the index of the vertex which represents cluster <code>i</code></p>
</td></tr>
<tr><td><code id="find.cluster_+3A_vertex.to.cdm">vertex.to.cdm</code></td>
<td>
<p>vector, contains the vertex to doubly centered distance matrix relations, i.e., <code>vertex.to.cdm[i]</code> is the index of the doubly centered distance matrix in <code>list.cdm</code> which corresponds to vertex <code>i</code></p>
</td></tr>
<tr><td><code id="find.cluster_+3A_previous.n.o.cdms">previous.n.o.cdms</code></td>
<td>
<p>vector, number of the doubly centered distance matrices in the previous iteration (it is used to ensure that previously check tuples are not checked again)</p>
</td></tr>
<tr><td><code id="find.cluster_+3A_all.multivariances">all.multivariances</code></td>
<td>
<p>vector, which contains all distance multivariances which have been calculated so far. Only used to finally return all distance multivariances which have been calculated.</p>
</td></tr>
<tr><td><code id="find.cluster_+3A_g">g</code></td>
<td>
<p>dependence structure graph</p>
</td></tr>
<tr><td><code id="find.cluster_+3A_fixed.rejection.level">fixed.rejection.level</code></td>
<td>
<p>vector, if not <code>NA</code> the <code>fixed.rejection.level[k]</code> is used for the k-tuples, instead of a level derived from the significance level <code>alpha</code></p>
</td></tr>
<tr><td><code id="find.cluster_+3A_alpha">alpha</code></td>
<td>
<p>numeric, significance level used for the (distribution-free) tests</p>
</td></tr>
<tr><td><code id="find.cluster_+3A_p.adjust.method">p.adjust.method</code></td>
<td>
<p>name of the method used to adjust the p-values for multiple testing, see <code><a href="stats.html#topic+p.adjust">p.adjust</a></code> for all possible options.</p>
</td></tr>
<tr><td><code id="find.cluster_+3A_verbose">verbose</code></td>
<td>
<p>boolean, if <code>TRUE</code> details during the detection are printed and whenever a cluster is newly detected the (so far) detected dependence structure is plotted.</p>
</td></tr>
<tr><td><code id="find.cluster_+3A_kvec">kvec</code></td>
<td>
<p>vector, k-tuples are only checked for each k in <code>kvec</code>, i.e., for <code>kvec = 2:4</code> only 2,3 and 4-tuples would be check and then the algorithm stops.</p>
</td></tr>
<tr><td><code id="find.cluster_+3A_parameter.range">parameter.range</code></td>
<td>
<p>numeric matrix, which hosts the range of significance levels or '<code>c.factor</code>' which yield the same detected structure</p>
</td></tr>
<tr><td><code id="find.cluster_+3A_type">type</code></td>
<td>
<p>the method for the detection, one of '<code>conservative</code>','<code>resample</code>','<code>pearson_approx</code>' or '<code>consistent</code>'.</p>
</td></tr>
<tr><td><code id="find.cluster_+3A_stop.too.many">stop.too.many</code></td>
<td>
<p>numeric, upper limit for the number of tested tuples. A warning is issued if it is used. Use <code>stop.too.many = NULL</code> for no limit.</p>
</td></tr>
<tr><td><code id="find.cluster_+3A_...">...</code></td>
<td>
<p>are passed to <code><a href="#topic+resample.multivariance">resample.multivariance</a></code> in the case of '<code>type = resample</code>'</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For further details see <code><a href="#topic+dependence.structure">dependence.structure</a></code>.
</p>

<hr>
<h2 id='independence.test'>test for independence</h2><span id='topic+independence.test'></span>

<h3>Description</h3>

<p>Depreciated. Use <code><a href="#topic+multivariance.test">multivariance.test</a></code> instead. It provides all options and returns test result in a standard R format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>independence.test(
  x,
  vec = 1:ncol(x),
  alpha = 0.05,
  type = "distribution_free",
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="independence.test_+3A_x">x</code></td>
<td>
<p>either a data matrix or a list of doubly centered distance matrices</p>
</td></tr>
<tr><td><code id="independence.test_+3A_vec">vec</code></td>
<td>
<p>if x is a matrix, then this indicates which columns are treated together as one sample; if x is a list, these are the indexes for which the multivariance is calculated. The default is all columns and all indexes, respectively.</p>
</td></tr>
<tr><td><code id="independence.test_+3A_alpha">alpha</code></td>
<td>
<p>significance level</p>
</td></tr>
<tr><td><code id="independence.test_+3A_type">type</code></td>
<td>
<p>one of <code>"pearson_approx","distribution_free","resample"</code></p>
</td></tr>
<tr><td><code id="independence.test_+3A_verbose">verbose</code></td>
<td>
<p>logical, if TRUE meaningful text output is generated.</p>
</td></tr>
<tr><td><code id="independence.test_+3A_...">...</code></td>
<td>
<p>these are passed to <code><a href="#topic+cdms">cdms</a></code> (which is only invoked if <code>x</code> is a matrix)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This computes a test of independence for the columns of a sample matrix (required for the resampling test) or for given doubly centered distance matrices (only possible for the distribution-free test).
</p>
<p>The <code>"pearson_approx"</code> and <code>"resample"</code> are approximately sharp. The latter is based on a resampling approach and thus much slower. The <code>"distribution_free"</code> test might be very conservative.
The doubly centered distance matrices can be prepared by <code><a href="#topic+cdms">cdms</a></code>. But note that for the test based on Pearson's approximation and for the resampling test, the data matrix has to be given.
</p>


<h3>Value</h3>

<p>Returns <code>TRUE</code> if the hypothesis of independence is NOT rejected, otherwise <code>FALSE</code>.
</p>


<h3>References</h3>

<p>For the theoretic background see the references given on the main help page of this package: <a href="#topic+multivariance-package">multivariance-package</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>independence.test(coins(100)) #dependent sample which is 2-independent
independence.test(coins(100),type = "resample") #dependent sample which is 2-independent

independence.test(coins(100)[,2:3]) # independent sample
independence.test(coins(100)[,2:3],type = "resample") # independent sample

independence.test(coins(10),type = "resample") #dependent sample which is 2-independent
independence.test(coins(10)[,2:3],type = "resample") #dependent sample which is 2-independent

</code></pre>

<hr>
<h2 id='is.doubly.centered'>checks if a matrix is doubly centered</h2><span id='topic+is.doubly.centered'></span>

<h3>Description</h3>

<p>!works only for the biased estimators
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.doubly.centered(mat)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="is.doubly.centered_+3A_mat">mat</code></td>
<td>
<p>matrix</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>multivariance:::is.doubly.centered(as.matrix(dist(rnorm(10))))
multivariance:::is.doubly.centered(multivariance:::double.center(as.matrix(dist(rnorm(10)))))

</code></pre>

<hr>
<h2 id='layout_on_circles'>special igraph layout for the dependence structure visualization</h2><span id='topic+layout_on_circles'></span>

<h3>Description</h3>

<p>It places the variable nodes on an outer circle and the dependency nodes on an inner circle
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layout_on_circles(g, n = sum(is.na(igraph::V(g)$level)))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="layout_on_circles_+3A_g">g</code></td>
<td>
<p>graph</p>
</td></tr>
<tr><td><code id="layout_on_circles_+3A_n">n</code></td>
<td>
<p>number of vertices on outer circle</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is the standard layout for the full dependence structure, since in this case there often too many nodes which make the other (usual) layout incomprehensible.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>N = 200
y = coins(N,2)
x = cbind(y,y,y)

g = dependence.structure(x,structure.type = "clustered",verbose = FALSE)$graph
plot(g)
plot(g,layout = layout_on_circles(g))
</code></pre>

<hr>
<h2 id='lower.order'>check if lower order dependencies are present for the given tuple indices
here 'm.values' is a list of boolean matrices. Matrix [[k]] corresponds to the k tuples. For each number of tuples, the first columns of the matrix always contain the indices of the tuples</h2><span id='topic+lower.order'></span>

<h3>Description</h3>

<p>check if lower order dependencies are present for the given tuple indices
here 'm.values' is a list of boolean matrices. Matrix [[k]] corresponds to the k tuples. For each number of tuples, the first columns of the matrix always contain the indices of the tuples
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lower.order(tuple, m.values)
</code></pre>

<hr>
<h2 id='m.multivariance'>m distance multivariance</h2><span id='topic+m.multivariance'></span>

<h3>Description</h3>

<p>Computes m distance multivariance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>m.multivariance(
  x,
  vec = NA,
  m = 2,
  Nscale = TRUE,
  Escale = TRUE,
  squared = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="m.multivariance_+3A_x">x</code></td>
<td>
<p>either a data matrix or a list of doubly centered distance matrices</p>
</td></tr>
<tr><td><code id="m.multivariance_+3A_vec">vec</code></td>
<td>
<p>if x is a matrix, then this indicates which columns are treated together as one sample; if x is a list, these are the indexes for which the multivariance is calculated. The default is all columns and all indexes, respectively.</p>
</td></tr>
<tr><td><code id="m.multivariance_+3A_m">m</code></td>
<td>
<p><code>=2</code> or <code>3</code> the m-multivariance will be computed.</p>
</td></tr>
<tr><td><code id="m.multivariance_+3A_nscale">Nscale</code></td>
<td>
<p>if <code>TRUE</code> the multivariance is scaled up by the sample size (and thus it is exactly as required for the test of independence)</p>
</td></tr>
<tr><td><code id="m.multivariance_+3A_escale">Escale</code></td>
<td>
<p>if <code>TRUE</code> then it is scaled by the number of multivariances which are theoretically summed up (in the case of independence this yields for normalized distance matrices an estimator with expectation 1)</p>
</td></tr>
<tr><td><code id="m.multivariance_+3A_squared">squared</code></td>
<td>
<p>if <code>FALSE</code> it returns the actual multivariance, otherwise the squared multivariance (less computation)</p>
</td></tr>
<tr><td><code id="m.multivariance_+3A_...">...</code></td>
<td>
<p>these are passed to <code><a href="#topic+cdms">cdms</a></code> (which is only invoked if <code>x</code> is a matrix)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>m-distance multivariance is per definition the scaled sum of certain distance multivariances, and it characterize m-dependence.
</p>
<p>As a rough guide to interpret the value of total distance multivariance note:
</p>

<ul>
<li><p> Large values indicate dependence.
</p>
</li>
<li><p> If the random variables are (m-1)-independent and <code>Nscale = TRUE</code>, values close to 1 and smaller indicate m-independence, larger values indicate dependence. In fact, in the case of independence the test statistic is a Gaussian quadratic form with expectation 1 and samples of it can be generated by <code><a href="#topic+resample.multivariance">resample.multivariance</a></code>.
</p>
</li>
<li><p> If the random variables are (m-1)-independent and <code>Nscale = FALSE</code>, small values (close to 0) indicate m-independence, larger values indicate dependence.
</p>
</li></ul>

<p>Since random variables are always 1-independent, the case <code>m=2</code> characterizes pairwise independence.
</p>
<p>Finally note, that due to numerical (in)precision the value of m-multivariance might become negative. In these cases it is set to 0. A warning is issued, if the value is negative and further than the usual (used by <code><a href="base.html#topic+all.equal">all.equal</a></code>) tolerance away from 0.
</p>


<h3>References</h3>

<p>For the theoretic background see the reference [3] given on the main help page of this package: <a href="#topic+multivariance-package">multivariance-package</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = matrix(rnorm(3*30),ncol = 3)

# the following values are identical
m.multivariance(x,m =2)
1/choose(3,2)*(multivariance(x[,c(1,2)]) +
               multivariance(x[,c(1,3)]) +
               multivariance(x[,c(2,3)]))

# the following values are identical
m.multivariance(x,m=3)
multivariance(x)

# the following values are identical
1/4*(3*(m.multivariance(x,m=2)) + m.multivariance(x,m=3))
total.multivariance(x, Nscale = TRUE)
1/4*(multivariance(x[,c(1,2)], Nscale = TRUE) +
     multivariance(x[,c(1,3)], Nscale = TRUE) +
     multivariance(x[,c(2,3)], Nscale = TRUE) + multivariance(x, Nscale = TRUE))

</code></pre>

<hr>
<h2 id='match_rows'>for the fast detection of the full dependence structure</h2><span id='topic+match_rows'></span>

<h3>Description</h3>

<p>Returns the row indicies of matrix A which match with B
</p>


<h3>Usage</h3>

<pre><code class='language-R'>match_rows(A, B)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="match_rows_+3A_a">A</code></td>
<td>
<p>matrix</p>
</td></tr>
<tr><td><code id="match_rows_+3A_b">B</code></td>
<td>
<p>matrix whose rows are subset of A</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># A = t(utils::combn(10,3))
# B = A[sort(sample.int(nrow(A),10)),]
# match_rows(A,B)

</code></pre>

<hr>
<h2 id='match.rows'>Returns the row indices of matrix A which match with B
Use the fast cpp implementation 'match_rows' instead.
Function here just for reference.</h2><span id='topic+match.rows'></span>

<h3>Description</h3>

<p>Returns the row indices of matrix A which match with B
Use the fast cpp implementation 'match_rows' instead.
Function here just for reference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>match.rows(A, B)
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'># A = t(utils::combn(10,3))
# B = A[sort(sample.int(nrow(A),10)),]
# match.rows(A,B)

</code></pre>

<hr>
<h2 id='moments.for.pearson'>computes the moments as required for Pearson's approximation</h2><span id='topic+moments.for.pearson'></span>

<h3>Description</h3>

<p>computes the moments as required for Pearson's approximation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>moments.for.pearson(N, bcd, mu, mmean, type = "multi")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="moments.for.pearson_+3A_n">N</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="moments.for.pearson_+3A_bcd">bcd</code></td>
<td>
<p>an array with b c d</p>
</td></tr>
<tr><td><code id="moments.for.pearson_+3A_mu">mu</code></td>
<td>
<p>the limit moments</p>
</td></tr>
<tr><td><code id="moments.for.pearson_+3A_mmean">mmean</code></td>
<td>
<p>the means of the distance matrices</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note: It is currently only implemented for the case of normalized multivariance, i.e., the OUTPUT values correspond to normalized multivariance!
</p>

<hr>
<h2 id='mu3.unbiased'>given the distance matrix the unbiased estimate for mu3 is computed</h2><span id='topic+mu3.unbiased'></span>

<h3>Description</h3>

<p>given the distance matrix the unbiased estimate for mu3 is computed
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mu3.unbiased(B, b2ob = sum(tcrossprod(B) * B))
</code></pre>

<hr>
<h2 id='multicorrelation'>distance multicorrelation</h2><span id='topic+multicorrelation'></span><span id='topic+Mcor'></span>

<h3>Description</h3>

<p>Computes various types of sample distance multicorrelation as defined and discussed in [3,4,6].
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multicorrelation(
  x,
  vec = 1:ncol(x),
  type = "total.upper.lower",
  multicorrelation.type = "normalized",
  estimator.type = "bias.corrected",
  squared = TRUE,
  ...
)

Mcor(
  x,
  vec = 1:ncol(x),
  type = "total.upper.lower",
  multicorrelation.type = "normalized",
  estimator.type = "bias.corrected",
  squared = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multicorrelation_+3A_x">x</code></td>
<td>
<p>either a data matrix or a list of doubly centered distance matrices</p>
</td></tr>
<tr><td><code id="multicorrelation_+3A_vec">vec</code></td>
<td>
<p>if x is a matrix, then this indicates which columns are treated together as one sample; if x is a list, these are the indexes for which the multivariance is calculated. The default is all columns and all indexes, respectively.</p>
</td></tr>
<tr><td><code id="multicorrelation_+3A_type">type</code></td>
<td>
<p>default: &quot;total.lower.upper&quot;, for details and other options see below</p>
</td></tr>
<tr><td><code id="multicorrelation_+3A_multicorrelation.type">multicorrelation.type</code></td>
<td>
<p>one of <code>"normalized","unnormalized"</code></p>
</td></tr>
<tr><td><code id="multicorrelation_+3A_estimator.type">estimator.type</code></td>
<td>
<p>one of <code>"biased","bias.corrected"</code></p>
</td></tr>
<tr><td><code id="multicorrelation_+3A_squared">squared</code></td>
<td>
<p>if <code>FALSE</code> it returns the actual multivariance, otherwise the squared multivariance (less computation)</p>
</td></tr>
<tr><td><code id="multicorrelation_+3A_...">...</code></td>
<td>
<p>these are passed to <code><a href="#topic+cdms">cdms</a></code> (which is only invoked if <code>x</code> is a matrix)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There exist many variants of distance multicorrelation as discussed in [6] &ndash; and only in specific cases a direct comparison of the values is meaningful.
</p>
<p>The implemented options are:
</p>

<ul>
<li> <p><code>total.upper.lower normalized bias.corrected</code>: default; bounded by 1; fast; population limit characterizes independence by 0
</p>
</li>
<li> <p><code>pairwise normalized bias.corrected</code>: bounded by 1; fast; population limit characterizes pairwise independence by 0
</p>
</li>
<li> <p><code>total.upper normalized biased</code>: biased versions of the above
</p>
</li>
<li> <p><code>total.lower normalized biased</code>
</p>
</li>
<li> <p><code>pairwise normalized biased</code>
</p>
</li>
<li> <p><code>multi normalized biased</code>: population limit characterizes only in case of lower independence the independence of all variables by 0
</p>
</li>
<li> <p><code>m.multi.3 normalized biased</code>: population limit characterizes only in case of pairwise independence the 3-independence of all variables by 0
</p>
</li>
<li> <p><code>pairwise unnormalized biased</code> population limit characterizes pairwise independence by 0 and relation by similarity transforms by 1
</p>
</li>
<li> <p><code>multi unnormalized biased</code>: population limit characterizes only in case of lower independence the independence of all variables by 0 and relation by similarity transforms by 1
</p>
</li>
<li> <p><code>m.multi.3 unnormalized biased</code>: population limit characterizes only in case of pairwise independence the 3-independence of all variables by 0 and relation by similarity transforms by 1
</p>
</li></ul>

<p>Further details:
</p>
<p>The <code>"bias.corrected"</code> versions require a data matrix, since they compute bias corrected centered distance matricies.
</p>
<p>For <code>"multi"</code> the unnormalized and normalized version coincide if an even number of variables is considered. They usually differ if an odd number of variables is considered. If all variables are related by similarity transforms the unnormalized <code>"unnormalized"</code> multicorrelations are 1.
</p>
<p>For <code>"pairwise"</code> an alias is <code>"m.multi.2"</code>.
</p>
<p>For total multicorrelation there is currently only a feasible empirical estimator for a lower or upper bound. These are upper and lower bounds for in the population setting. When using bias corrected estimators these are in general no proper bounds, but their range can be used as values for comparisons.
</p>


<h3>Value</h3>

<p>Value of the multicorrelation(s).
</p>


<h3>References</h3>

<p>For the theoretic background see the references [2,3,6] given on the main help page of this package: <a href="#topic+multivariance-package">multivariance-package</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y = rnorm(100)
x = cbind(y,y*2,(y-2)/3,y+1,y*5) # all variables are related by similarity transforms

# compute all types of correlations for x:
for (ty in c("total.lower","total.upper","pairwise","m.multi.3","multi"))
 for (mty in c("normalized"))
  print(paste(format(multicorrelation(
  x,type=ty,multicorrelation.type = mty,estimator.type = "biased")
  ,digits=3,nsmall = 3,width = 7),mty,ty,"correlation - biased estimate"))

for (ty in c("total.upper.lower","pairwise"))
 for (mty in c("normalized"))
  print(paste(format(multicorrelation(
  x,type=ty,multicorrelation.type = mty,estimator.type = "bias.corrected")
  ,digits=3,nsmall = 3,width = 7),mty,ty,"correlation - bias corrected estimate"))

for (ty in c("m.multi.2","m.multi.3","multi"))
 for (mty in c("unnormalized"))
  print(paste(format(multicorrelation(
  x,type=ty,multicorrelation.type = mty,estimator.type = "biased")
  ,digits=3,nsmall = 3,width = 7),mty,ty,"correlation - biased estimate"))

</code></pre>

<hr>
<h2 id='multicorrelation.bias.corrected'>bias corrected total multicorrelations</h2><span id='topic+multicorrelation.bias.corrected'></span>

<h3>Description</h3>

<p>bias corrected total multicorrelations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multicorrelation.bias.corrected(
  x,
  vec = 1:ncol(x),
  squared = FALSE,
  type = "all",
  ...
)
</code></pre>

<hr>
<h2 id='multivariance'>distance multivariance</h2><span id='topic+multivariance'></span>

<h3>Description</h3>

<p>Computes the distance multivariance, either for given data or a given list of doubly centered distance matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multivariance(
  x,
  vec = NA,
  Nscale = TRUE,
  correlation = FALSE,
  squared = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multivariance_+3A_x">x</code></td>
<td>
<p>either a data matrix or a list of doubly centered distance matrices</p>
</td></tr>
<tr><td><code id="multivariance_+3A_vec">vec</code></td>
<td>
<p>if x is a matrix, then this indicates which columns are treated together as one sample; if x is a list, these are the indexes for which the multivariance is calculated. The default is all columns and all indexes, respectively.</p>
</td></tr>
<tr><td><code id="multivariance_+3A_nscale">Nscale</code></td>
<td>
<p>if <code>TRUE</code> the multivariance is scaled up by the sample size (and thus it is exactly as required for the test of independence)</p>
</td></tr>
<tr><td><code id="multivariance_+3A_correlation">correlation</code></td>
<td>
<p>depreciated, please use the function <code><a href="#topic+multicorrelation">multicorrelation</a></code> instead.</p>
</td></tr>
<tr><td><code id="multivariance_+3A_squared">squared</code></td>
<td>
<p>if <code>FALSE</code> it returns the actual multivariance, otherwise the squared multivariance (less computation)</p>
</td></tr>
<tr><td><code id="multivariance_+3A_...">...</code></td>
<td>
<p>these are passed to <code><a href="#topic+cdms">cdms</a></code> (which is only invoked if <code>x</code> is a matrix)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>x</code> is a matrix and <code>vec</code> is not given, then each column is treated as a separate sample. Otherwise <code>vec</code> has to have as many elements as <code>x</code> has columns and values starting from 1 up to the number of 'variables', e.g. if <code>x</code> is an <code>N</code> by 5 matrix and <code>vec = c(1,2,1,3,1)</code> then the multivariance of the 1-dimensional variables represented by column 2 and 4 and the 3-dimensional variable represented by the columns 1,3,5 is computed.
</p>
<p>As default it computes the normalized Nscaled squared multivariance, for a multivariance without normalization the argument <code>normalize = FALSE</code> has to be passed to <code>cdms</code>.
</p>
<p><code>correlation = TRUE</code> yields values between 0 and 1. These can be interpreted similarly to classical correlations, see also <code><a href="#topic+multicorrelation">multicorrelation</a></code>.
</p>
<p>As a rough guide to interpret the value of distance multivariance note:
</p>

<ul>
<li><p> If the random variables are not (n-1)-independent, large values indicate dependence, but small values are meaningless. Thus in this case use <code><a href="#topic+total.multivariance">total.multivariance</a></code>.
</p>
</li>
<li><p> If the random variables are (n-1)-independent and <code>Nscale = TRUE</code>, values close to 1 and smaller indicate independence, larger values indicate dependence. In fact, in the case of independence the test statistic is a Gaussian quadratic form with expectation 1 and samples of it can be generated by <code><a href="#topic+resample.multivariance">resample.multivariance</a></code>.
</p>
</li>
<li><p> If the random variables are (n-1)-independent and <code>Nscale = FALSE</code>, small values (close to 0) indicate independence, larger values indicate dependence.
</p>
</li></ul>

<p>Finally note, that due to numerical (in)precision the value of multivariance might become negative. In these cases it is set to 0. A warning is issued, if the value is negative and further than the usual (used by <code><a href="base.html#topic+all.equal">all.equal</a></code>) tolerance away from 0.
</p>


<h3>References</h3>

<p>For the theoretic background see the references given on the main help page of this package: <a href="#topic+multivariance-package">multivariance-package</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>multivariance(matrix(rnorm(100*3),ncol = 3)) #independent sample
multivariance(coins(100)) #dependent sample which is 2-independent

x = matrix(rnorm(100*2),ncol = 2)
x = cbind(x,x[,2])
multivariance(x) #dependent sample which is not 2-independent (thus small values are meaningless!)
multivariance(x[,1:2]) #these are independent
multivariance(x[,2:3]) #these are dependent

multivariance(x[,2:3],correlation = TRUE)

</code></pre>

<hr>
<h2 id='multivariance.pvalue'>transform multivariance to p-value</h2><span id='topic+multivariance.pvalue'></span>

<h3>Description</h3>

<p>Computes a conservative p-value for the hypothesis of independence for a given multivariance / m-multivariance / total multivariance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multivariance.pvalue(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multivariance.pvalue_+3A_x">x</code></td>
<td>
<p>value of a normalized <code><a href="#topic+multivariance">multivariance</a></code> scaled by the sample size (i.e., computed with <code>Nscale = TRUE</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is based on a distribution-free approach. The p-value is conservative, i.e. it might be much smaller. This is the counterpart to <code><a href="#topic+rejection.level">rejection.level</a></code>. For a less conservative approach see <code><a href="#topic+resample.pvalue">resample.pvalue</a></code> or <code><a href="#topic+pearson.pvalue">pearson.pvalue</a></code>.
</p>
<p>p-values larger than 0.215 might be incorrect, since the distribution-free estimate on which the computation is based only holds up to 0.215.
</p>


<h3>References</h3>

<p>For the theoretic background see the references given on the main help page of this package: <a href="#topic+multivariance-package">multivariance-package</a>.
</p>

<hr>
<h2 id='multivariance.test'>independence tests based on (total-/2-/3-) multivariance</h2><span id='topic+multivariance.test'></span>

<h3>Description</h3>

<p>This performs the (specified by <code>type</code> and <code>p.value.type</code>) independence test for the columns of a sample matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multivariance.test(
  x,
  vec = 1:ncol(x),
  type = "total",
  p.value.type = "pearson_approx",
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multivariance.test_+3A_x">x</code></td>
<td>
<p>matrix, each row is a sample</p>
</td></tr>
<tr><td><code id="multivariance.test_+3A_vec">vec</code></td>
<td>
<p>vector which indicates which columns are treated as one sample</p>
</td></tr>
<tr><td><code id="multivariance.test_+3A_type">type</code></td>
<td>
<p>one of <code>"independence"</code>, <code>"pairwise independence"</code>, <code>"multi"</code>, <code>"total"</code>, <code>"m.multi.2"</code>, <code>"m.multi.3"</code></p>
</td></tr>
<tr><td><code id="multivariance.test_+3A_p.value.type">p.value.type</code></td>
<td>
<p>one of <code>"pearson_approx"</code>, <code>"distribution_free"</code>, <code>"resample"</code>, <code>"pearson_unif"</code></p>
</td></tr>
<tr><td><code id="multivariance.test_+3A_verbose">verbose</code></td>
<td>
<p>logical, if TRUE meaningful text output is generated.</p>
</td></tr>
<tr><td><code id="multivariance.test_+3A_...">...</code></td>
<td>
<p>these are passed to <code><a href="#topic+cdm">cdm</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the use of <code>vec</code> see the examples below and the more detailed explanation of this argument for <code><a href="#topic+multivariance">multivariance</a></code>.
</p>
<p>The types <code>"independence"</code> and <code>"total"</code> are identical: an independence test is performed.
</p>
<p>Also the types <code>"pairwise independence"</code> and <code>"m.multi.2"</code> are identical:  a test of pairwise independence is performed.
</p>
<p>The type <code>"m.multi.3"</code>, performs a test for 3-independence, assuming pairwise independence. The type  <code>"multi"</code> performs a test for n-independence, assuming (n-1)-independence.
</p>
<p>There are several ways (determined by <code>p.value.type</code>) to estimate the p-value: The <code>"pearson_approx"</code> and <code>"resample"</code> are approximately sharp. The latter is based on a resampling approach and thus much slower. The <code>"distribution_free"</code> test might be very conservative, its p-value estimates are only valid for p-values lower than 0.215 - values above should be interpreted as &quot;values larger than 0.215&quot;. Finally, <code>"pearson_unif"</code> uses fixed parameters in Pearson's estimate, it is only applicable for univariate uniformly distributed marginals
</p>
<p>All tests are performed using the standard euclidean distance. Other distances can be supplied via the <code>...</code>, see <code><a href="#topic+cdm">cdm</a></code> for the accepted arguments.
</p>


<h3>Value</h3>

<p>A list with class &quot;<code>htest</code>&quot; containing the following components:
</p>

<dl>
<dt><code>statistic</code></dt><dd><p>the value of the test statistic,</p>
</dd>
<dt><code>p.value</code></dt><dd><p>the p-value of the test statistic,</p>
</dd>
<dt><code>method</code></dt><dd><p>a character string indicating the type of test performed,</p>
</dd>
<dt><code>data.name</code></dt><dd><p>a character string giving the name(s) of the data.</p>
</dd>
</dl>



<h3>References</h3>

<p>For the theoretic background see the references given on the main help page of this package: <a href="#topic+multivariance-package">multivariance-package</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># an independence test
multivariance.test(dep_struct_several_26_100,p.value.type = "distribution_free") # conservative
multivariance.test(dep_struct_several_26_100,p.value.type = "resample") #sharp but slow
multivariance.test(dep_struct_several_26_100,p.value.type = "pearson_approx") #

# as an example, all tests for one data set:
coins100 = coins(100)
for (ty in c("total","m.multi.2","m.multi.3","multi"))
 for (pvt in c("distribution_free","resample","pearson_approx"))
  print(multivariance.test(coins100,type=ty,p.value.type = pvt))

# using the vec argument:
x = matrix(rnorm(50*6),ncol = 10) # a 50x6 data matrix
vec = c(1,2,3,4,5,6) # each column is treated as one variable
multivariance.test(x,vec,p.value.type = "distribution_free") # is the same as the default

vec = c(1,2,2,1,3,1)
# column 1,4,6 are treated as one variable
# column 2,3 are treated as one variable
# column 5 is treated as one variable
multivariance.test(x,vec,p.value.type = "distribution_free")

</code></pre>

<hr>
<h2 id='multivariance.timing'>estimate of the computation time</h2><span id='topic+multivariance.timing'></span>

<h3>Description</h3>

<p>Estimates the computation time. This is relative rough. First run with <code>determine.parameters = TRUE</code> (which takes a while). Then use the computed parameters to determine the computation time/or sample size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multivariance.timing(
  N = NULL,
  n,
  sectime = NULL,
  coef.cdm = 15.2,
  coef.prod = 2.1,
  coef.sum = 1.05,
  determine.parameters = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multivariance.timing_+3A_n">N</code></td>
<td>
<p>number of samples. If <code>NULL</code> and <code>sectime</code> is given, then <code>N</code> is computed.</p>
</td></tr>
<tr><td><code id="multivariance.timing_+3A_n">n</code></td>
<td>
<p>number of variables</p>
</td></tr>
<tr><td><code id="multivariance.timing_+3A_sectime">sectime</code></td>
<td>
<p>desired computation time in seconds. If <code>NULL</code> then the required computation time is computed.</p>
</td></tr>
<tr><td><code id="multivariance.timing_+3A_coef.cdm">coef.cdm</code></td>
<td>
<p>computation time parameter for the doubly centered distance matrices</p>
</td></tr>
<tr><td><code id="multivariance.timing_+3A_coef.prod">coef.prod</code></td>
<td>
<p>computation time parameter for matrix products</p>
</td></tr>
<tr><td><code id="multivariance.timing_+3A_coef.sum">coef.sum</code></td>
<td>
<p>computation time parameter for matrix sums</p>
</td></tr>
<tr><td><code id="multivariance.timing_+3A_determine.parameters">determine.parameters</code></td>
<td>
<p>if <code>TRUE</code> then the parameters for the current computer are determined. This might take a while (3 loops to N=1000).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When detecting the parameters, the median of the computation times is used.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Ns = (1:100)*10
ns = 1:100
fulltime = outer(Ns,ns,FUN = function(N,n) multivariance.timing(N,n))
contour(Ns,ns,fulltime,xlab = "N",ylab = "n",
 main = "computation time of multivariance in secs",
 sub = "using default parameters -
 use 'determine.parameters = TRUE' to compute machine specific values")

# Run to determine the parameters of your system:
# multivariance.timing(determine.parameters = TRUE)

</code></pre>

<hr>
<h2 id='multivariances.all'>simultaneous computation of multivariance and total/ 2-/ 3-multivariance</h2><span id='topic+multivariances.all'></span>

<h3>Description</h3>

<p>Computes simultaneously multivariance, total multivariance, 2-multivariance and 3-multivariance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multivariances.all(x, vec = NA, Nscale = TRUE, squared = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multivariances.all_+3A_x">x</code></td>
<td>
<p>either a data matrix or a list of doubly centered distance matrices</p>
</td></tr>
<tr><td><code id="multivariances.all_+3A_vec">vec</code></td>
<td>
<p>if x is a matrix, then this indicates which columns are treated together as one sample; if x is a list, these are the indexes for which the multivariance is calculated. The default is all columns and all indexes, respectively.</p>
</td></tr>
<tr><td><code id="multivariances.all_+3A_nscale">Nscale</code></td>
<td>
<p>if <code>TRUE</code> the multivariance is scaled up by the sample size (and thus it is exactly as required for the test of independence)</p>
</td></tr>
<tr><td><code id="multivariances.all_+3A_squared">squared</code></td>
<td>
<p>if <code>FALSE</code> it returns the actual multivariance, otherwise the squared multivariance (less computation)</p>
</td></tr>
<tr><td><code id="multivariances.all_+3A_...">...</code></td>
<td>
<p>these are passed to <code><a href="#topic+cdms">cdms</a></code> (which is only invoked if <code>x</code> is a matrix)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The computation is faster than the separate computations.
</p>


<h3>Value</h3>

<p>Returns a vector with multivariance, total.multivariance, 2-multivariance and 3-multivariance
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multivariance">multivariance</a></code>, <code><a href="#topic+total.multivariance">total.multivariance</a></code>, <code><a href="#topic+m.multivariance">m.multivariance</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = coins(100,k = 3)
multivariances.all(x)
# yields the same as:
multivariance(x)
total.multivariance(x)
m.multivariance(x,m=2)
m.multivariance(x,m=3)


</code></pre>

<hr>
<h2 id='N.coefficients'>Computes the explicit coefficients for the finite sample variance for a sample of size N</h2><span id='topic+N.coefficients'></span>

<h3>Description</h3>

<p>Computes the explicit coefficients for the finite sample variance for a sample of size N
</p>


<h3>Usage</h3>

<pre><code class='language-R'>N.coefficients(N)
</code></pre>

<hr>
<h2 id='p.value.to.star.label'>transforms a p-value into the corresponding label</h2><span id='topic+p.value.to.star.label'></span>

<h3>Description</h3>

<p>transforms a p-value into the corresponding label
</p>


<h3>Usage</h3>

<pre><code class='language-R'>p.value.to.star.label(pv)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="p.value.to.star.label_+3A_pv">pv</code></td>
<td>
<p>p-value</p>
</td></tr>
</table>

<hr>
<h2 id='pairwise.multicorrelation.bias.corrected'>pairwise multicorrelation</h2><span id='topic+pairwise.multicorrelation.bias.corrected'></span>

<h3>Description</h3>

<p>pairwise multicorrelation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pairwise.multicorrelation.bias.corrected(
  x,
  vec = 1:ncol(x),
  squared = FALSE,
  ...
)
</code></pre>

<hr>
<h2 id='pearson.pvalue'>fast p-value approximation</h2><span id='topic+pearson.pvalue'></span>

<h3>Description</h3>

<p>Computes the p-value of a sample using Pearson's approximation of Gaussian quadratic forms with the estimators developed by Berschneider and Böttcher in [4].
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pearson.pvalue(x, vec = NA, type = "multi", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pearson.pvalue_+3A_x">x</code></td>
<td>
<p>matrix, the rows should be iid samples</p>
</td></tr>
<tr><td><code id="pearson.pvalue_+3A_vec">vec</code></td>
<td>
<p>vector, which indicates which columns of <code>x</code> are treated together as one sample. The default case treats each column as a separate sample.</p>
</td></tr>
<tr><td><code id="pearson.pvalue_+3A_type">type</code></td>
<td>
<p>one of <code>"multi","total","m.multi.2","m.multi.3","all"</code></p>
</td></tr>
<tr><td><code id="pearson.pvalue_+3A_...">...</code></td>
<td>
<p>these are passed to <code><a href="#topic+cdms">cdms</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is the method recommended in [4], i.e., using Pearson's quadratic form estimate with the unbiased finite sample estimators for the mean and variance of normalized multivariance together with the unbiased estimator for the limit skewness.
</p>


<h3>References</h3>

<p>For the theoretic background see the reference [4] given on the main help page of this package: <a href="#topic+multivariance-package">multivariance-package</a>.
</p>

<hr>
<h2 id='pearson.pvalue.unif'>compute the p-value by Pearson's approximation assuming uniform marginals and euclidean distance</h2><span id='topic+pearson.pvalue.unif'></span>

<h3>Description</h3>

<p>compute the p-value by Pearson's approximation assuming uniform marginals and euclidean distance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pearson.pvalue.unif(
  x,
  vec = NA,
  type = "total",
  psi = NULL,
  isotropic = TRUE,
  ...
)
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'>multivariance:::pearson.pvalue.unif(matrix(runif(300),ncol = 3))

## Not run: 
library(microbenchmark)
x = matrix(runif(300*3),ncol = 3)
microbenchmark(
  multivariance.test(x,p.value.type = "pearson_approx")$p.value,
  multivariance:::pearson.pvalue.unif(emp.transf(x))
  )

## End(Not run)

</code></pre>

<hr>
<h2 id='pearson.qf'>approximate distribution function of a Gaussian quadratic form</h2><span id='topic+pearson.qf'></span>

<h3>Description</h3>

<p>Approximation of the of the value of the distribution function of a Gaussian quadratic form based on its first three moments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pearson.qf(x, moment, lower.tail = TRUE, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pearson.qf_+3A_x">x</code></td>
<td>
<p>value at which the distribution function is to be evaluated</p>
</td></tr>
<tr><td><code id="pearson.qf_+3A_moment">moment</code></td>
<td>
<p>vector with the mean, variance and skewness of the quadratic form</p>
</td></tr>
<tr><td><code id="pearson.qf_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, indicating of the lower or upper tail of the distribution function should be calculated</p>
</td></tr>
<tr><td><code id="pearson.qf_+3A_verbose">verbose</code></td>
<td>
<p>logical, if <code>TRUE</code> a warning is issued if negative moments are sanitized to 0.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is Pearson's approximation for Gaussian quadratic forms as stated in [4] (equation (4.65) in arXiv:1808.07280v2)
</p>


<h3>References</h3>

<p>For the theoretic background see the reference [4] given on the main help page of this package: <a href="#topic+multivariance-package">multivariance-package</a>.
</p>

<hr>
<h2 id='rejection.level'>rejection level for the test statistic</h2><span id='topic+rejection.level'></span>

<h3>Description</h3>

<p>Under independence the probability for the normalized and Nscaled (squared) multivariance to be above this level is less than <code>alpha</code>. The same holds for the normalized, Nscaled and Escaled (squared) total multivariance and m-multivariance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rejection.level(alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rejection.level_+3A_alpha">alpha</code></td>
<td>
<p>level of significance</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is based on a distribution-free approach. The value might be very conservative. This is the counterpart to <code><a href="#topic+multivariance.pvalue">multivariance.pvalue</a></code>. For a less conservative approach see <code><a href="#topic+resample.rejection.level">resample.rejection.level</a></code>.
</p>
<p>The estimate is only valid for <code>alpha</code> smaller than 0.215.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rejection.level(0.05) #the rejection level, for comparison with the following values
total.multivariance(matrix(rnorm(100*3),ncol = 3)) #independent sample
total.multivariance(coins(100)) #dependent sample which is 2-independent

# and the p values are (to compare with alpha)
multivariance.pvalue(total.multivariance(matrix(rnorm(100*3),ncol = 3))) #independent sample
multivariance.pvalue(total.multivariance(coins(100))) #dependent sample which is 2-independent

## Not run: 
# visualization of the rejection level
curve(rejection.level(x),xlim = c(0.001,0.215),xlab = "alpha")

## End(Not run)

</code></pre>

<hr>
<h2 id='resample.multivariance'>resampling (total /m-) multivariance</h2><span id='topic+resample.multivariance'></span>

<h3>Description</h3>

<p>The distribution of the test statistic under the hypothesis of independence is required for the independence tests. This function generates approximate samples of this distribution either by sampling without replacement (permutations) or by sampling with replacement (bootstrap).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resample.multivariance(
  x,
  vec = 1:ncol(x),
  times = 300,
  type = "multi",
  resample.type = "permutation",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="resample.multivariance_+3A_x">x</code></td>
<td>
<p>matrix, the rows should be iid samples</p>
</td></tr>
<tr><td><code id="resample.multivariance_+3A_vec">vec</code></td>
<td>
<p>vector, which indicates which columns of <code>x</code> are treated together as one sample</p>
</td></tr>
<tr><td><code id="resample.multivariance_+3A_times">times</code></td>
<td>
<p>integer, number of samples to generate</p>
</td></tr>
<tr><td><code id="resample.multivariance_+3A_type">type</code></td>
<td>
<p>one of <code>"multi","total","m.multi.2","m.multi.3","all"</code></p>
</td></tr>
<tr><td><code id="resample.multivariance_+3A_resample.type">resample.type</code></td>
<td>
<p>one of <code>"permutation", "bootstrap"</code>. The samples are generated without replacement (permutations) or with replacement (bootstrap).</p>
</td></tr>
<tr><td><code id="resample.multivariance_+3A_...">...</code></td>
<td>
<p>is passed to <code><a href="#topic+cdms">cdms</a>, <a href="#topic+multivariance">multivariance</a>, <a href="#topic+total.multivariance">total.multivariance</a>, <a href="#topic+m.multivariance">m.multivariance</a></code>, respectively.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The resampling is done by sampling from the original data either without replacement (<code>"permutation"</code>) or with replacement (<code>"bootstrap"</code>). Using resampling without replacement is (much) faster (due to special identities which only hold in this case).
</p>
<p>For convenience also the actual (total /m-) multivariance is computed and its p-value.
</p>


<h3>Value</h3>

<p>A list with elements
</p>

<dl>
<dt><code>resampled</code></dt><dd><p>the (total/m-)multivariances of the resampled data,</p>
</dd>
<dt><code>original</code></dt><dd><p>the (total/m-)multivariance of the original data,</p>
</dd>
<dt><code>p.value</code></dt><dd><p>the p-value of the original data, computed using the resampled data</p>
</dd>
</dl>



<h3>References</h3>

<p>For the theoretic background see the reference [3] given on the main help page of this package: <a href="#topic+multivariance-package">multivariance-package</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>re.m = resample.multivariance(matrix(rnorm(30*2),nrow = 30),
                        type= "multi",times = 300)$resampled
curve(ecdf(re.m)(x), xlim = c(0,4),main = "empirical distribution of the test statistic under H_0")
</code></pre>

<hr>
<h2 id='resample.pvalue'>p-value via resampling</h2><span id='topic+resample.pvalue'></span>

<h3>Description</h3>

<p>Use a resampling method to generate samples of the test statistic under the hypothesis of independence. Based on these the p.value of a given value of a test statistic is computed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resample.pvalue(value, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="resample.pvalue_+3A_value">value</code></td>
<td>
<p>numeric, the value of (total-/m-)multivariance for which the p-value shall be computed</p>
</td></tr>
<tr><td><code id="resample.pvalue_+3A_...">...</code></td>
<td>
<p>passed to <code><a href="#topic+resample.multivariance">resample.multivariance</a></code>. Required is the data matrix <code>x</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is useful if a p-value of a test statistic shall be computed based on the resampling values of the test statistic of a different sample. For the p-value based on the same sample <code><a href="#topic+resample.multivariance">resample.multivariance</a>(...)$p.value</code> is sufficient.
</p>


<h3>Value</h3>

<p>It returns 1 minus the value of the empirical distribution function of the resampling samples evaluated at the given value.
</p>


<h3>References</h3>

<p>For the theoretic background see the reference [3] given on the main help page of this package: <a href="#topic+multivariance-package">multivariance-package</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = coins(100)
resample.pvalue(multivariance(x),x=x,times = 300)
resample.pvalue(multivariances.all(x),x=x,times = 300,type = "all")

</code></pre>

<hr>
<h2 id='resample.rejection.level'>rejection level via resampling</h2><span id='topic+resample.rejection.level'></span>

<h3>Description</h3>

<p>Uses the resample method to sample from the test statistic under the hypothesis of independence. The alpha quantile of these samples is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resample.rejection.level(alpha = 0.05, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="resample.rejection.level_+3A_alpha">alpha</code></td>
<td>
<p>numeric, the significance value</p>
</td></tr>
<tr><td><code id="resample.rejection.level_+3A_...">...</code></td>
<td>
<p>passed to <code><a href="#topic+resample.multivariance">resample.multivariance</a></code>. Required is the data matrix <code>x</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>For the theoretic background see the reference [3] given on the main help page of this package: <a href="#topic+multivariance-package">multivariance-package</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>resample.rejection.level(0.05,matrix(rnorm(30*2),nrow = 30))
resample.rejection.level(0.05,matrix(rnorm(30*3),nrow = 30),vec = c(1,1,2))

</code></pre>

<hr>
<h2 id='sample.cdms'>resamples doubly centered distance matrices</h2><span id='topic+sample.cdms'></span>

<h3>Description</h3>

<p>resamples doubly centered distance matrices
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample.cdms(list.cdm, replace = FALSE, incl.first = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sample.cdms_+3A_list.cdm">list.cdm</code></td>
<td>
<p>a list of doubly centered distance matrices</p>
</td></tr>
<tr><td><code id="sample.cdms_+3A_replace">replace</code></td>
<td>
<p>boolean, sampling with or without replacement</p>
</td></tr>
<tr><td><code id="sample.cdms_+3A_incl.first">incl.first</code></td>
<td>
<p>boolean, if <code>TRUE</code> also the first component is resampled</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of doubly centered distance matrices, each matrix corresponds to the resampled columns of the corresponding sample, using resampling with replacement (bootstrap) or without replacement (permutations).
</p>

<hr>
<h2 id='sample.cols'>resample the columns of a matrix</h2><span id='topic+sample.cols'></span>

<h3>Description</h3>

<p>resample the columns of a matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample.cols(x, vec = 1:ncol(x), replace = TRUE, incl.first = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sample.cols_+3A_x">x</code></td>
<td>
<p>matrix</p>
</td></tr>
<tr><td><code id="sample.cols_+3A_vec">vec</code></td>
<td>
<p>vector, indicates which columns belong together</p>
</td></tr>
<tr><td><code id="sample.cols_+3A_replace">replace</code></td>
<td>
<p>boolean, sampling with or without replacement</p>
</td></tr>
<tr><td><code id="sample.cols_+3A_incl.first">incl.first</code></td>
<td>
<p>boolean, if <code>TRUE</code> also the first component is resampled</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a matrix with the same dimensions as <code>x</code>. The columns are resampled from the original columns. The resampling is done with replacement (<code>replace = TRUE</code>) or without (<code>replace = FALSE</code>). Columns which belong together (indicated by vec) are resampled identically, i.e., all values in rows of these are kept together.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sample.cols(matrix(1:15,nrow = 5),vec = c(1,1,2))

</code></pre>

<hr>
<h2 id='signed.sqrt'>sign preserving square root</h2><span id='topic+signed.sqrt'></span>

<h3>Description</h3>

<p>sign preserving square root
</p>


<h3>Usage</h3>

<pre><code class='language-R'>signed.sqrt(x)
</code></pre>

<hr>
<h2 id='simple.int.hash'>Simple integer hash from text</h2><span id='topic+simple.int.hash'></span>

<h3>Description</h3>

<p>Used to compute a random seed for <code>set.seed</code> based on the example name,
in order to aviod arbitrary seeds like '1234'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simple.int.hash(x)
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'>multivariance:::simple.int.hash("dep_struct_several_26_100")
</code></pre>

<hr>
<h2 id='sums.of.products'>This is the function GC which is required for the computation of the finite sample variance for m and total multivariance</h2><span id='topic+sums.of.products'></span>

<h3>Description</h3>

<p>This is the function GC which is required for the computation of the finite sample variance for m and total multivariance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sums.of.products(a, b, c, type = "multi")
</code></pre>

<hr>
<h2 id='tetrahedron'>dependence example: tetrahedron sampling</h2><span id='topic+tetrahedron'></span>

<h3>Description</h3>

<p>This function creates samples of a tetrahedron-dice colored r, g, b and rgb. Each sample indicates if for the thrown dice the colors r, g and b are contained on the bottom side of the dice.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tetrahedron(N = 1000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tetrahedron_+3A_n">N</code></td>
<td>
<p>number of samples</p>
</td></tr>
</table>


<h3>Value</h3>

<p>It returns the samples of the events r, g and b as rows of a <code>N</code> by 3 matrix (the first column corresponds to r, the second to g,...). TRUE indicates that this color is on the bottom side of the dice. The columns are dependent but 2-independent.
</p>


<h3>References</h3>

<p>For the theoretic background see the reference [3] given on the main help page of this package: <a href="#topic+multivariance-package">multivariance-package</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tetrahedron(10)

</code></pre>

<hr>
<h2 id='total.multicorrelation.bias.corrected.upper'># included for speed. it is faster than upper.lower</h2><span id='topic+total.multicorrelation.bias.corrected.upper'></span>

<h3>Description</h3>

<p># included for speed. it is faster than upper.lower
</p>


<h3>Usage</h3>

<pre><code class='language-R'>total.multicorrelation.bias.corrected.upper(
  x,
  vec = 1:ncol(x),
  squared = FALSE,
  ...
)
</code></pre>

<hr>
<h2 id='total.multivariance'>total distance multivariance</h2><span id='topic+total.multivariance'></span>

<h3>Description</h3>

<p>computes the total distance multivariance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>total.multivariance(
  x,
  vec = NA,
  lambda = 1,
  Nscale = TRUE,
  Escale = TRUE,
  squared = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="total.multivariance_+3A_x">x</code></td>
<td>
<p>either a data matrix or a list of doubly centered distance matrices</p>
</td></tr>
<tr><td><code id="total.multivariance_+3A_vec">vec</code></td>
<td>
<p>if x is a matrix, then this indicates which columns are treated together as one sample; if x is a list, these are the indexes for which the multivariance is calculated. The default is all columns and all indexes, respectively.</p>
</td></tr>
<tr><td><code id="total.multivariance_+3A_lambda">lambda</code></td>
<td>
<p>a scaling parameter &gt;0. Each k-tuple multivariance gets weight <code>lambda^(n-k)</code>.</p>
</td></tr>
<tr><td><code id="total.multivariance_+3A_nscale">Nscale</code></td>
<td>
<p>if <code>TRUE</code> the multivariance is scaled up by the sample size (and thus it is exactly as required for the test of independence)</p>
</td></tr>
<tr><td><code id="total.multivariance_+3A_escale">Escale</code></td>
<td>
<p>if <code>TRUE</code> then it is scaled by the number of multivariances which are theoretically summed up (in the case of independence this yields for normalized distance matrices an estimator with expectation 1)</p>
</td></tr>
<tr><td><code id="total.multivariance_+3A_squared">squared</code></td>
<td>
<p>if <code>FALSE</code> it returns the actual multivariance, otherwise the squared multivariance (less computation)</p>
</td></tr>
<tr><td><code id="total.multivariance_+3A_...">...</code></td>
<td>
<p>these are passed to <code><a href="#topic+cdms">cdms</a></code> (which is only invoked if <code>x</code> is a matrix)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Total distance multivariance is per definition the scaled sum of certain distance multivariances, and it characterize dependence.
</p>
<p>As a rough guide to interpret the value of total distance multivariance note:
</p>

<ul>
<li><p> Large values indicate dependence.
</p>
</li>
<li><p> For <code>Nscale = TRUE</code> values close to 1 and smaller indicate independence, larger values indicate dependence. In fact, in the case of independence the test statistic is a Gaussian quadratic form with expectation 1 and samples of it can be generated by <code><a href="#topic+resample.multivariance">resample.multivariance</a></code>.
</p>
</li>
<li><p> For <code>Nscale = FALSE</code> small values (close to 0) indicate independence, larger values indicate dependence.
</p>
</li></ul>

<p>Finally note, that due to numerical (in)precision the value of total multivariance might become negative. In these cases it is set to 0. A warning is issued, if the value is negative and further than the usual (used by <code><a href="base.html#topic+all.equal">all.equal</a></code>) tolerance away from 0.
</p>


<h3>References</h3>

<p>For the theoretic background see the references given on the main help page of this package: <a href="#topic+multivariance-package">multivariance-package</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = matrix(rnorm(100*3),ncol = 3)
total.multivariance(x) #for an independent sample
# the value coincides with
(multivariance(x[,c(1,2)],Nscale = TRUE) + multivariance(x[,c(1,3)],Nscale = TRUE)+
 multivariance(x[,c(2,3)],Nscale = TRUE) + multivariance(x,Nscale = TRUE))/4

total.multivariance(coins(100)) #value for a dependent sample which is 2-independent

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
