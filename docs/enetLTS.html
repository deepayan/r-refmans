<!DOCTYPE html><html><head><title>Help for package enetLTS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {enetLTS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#coef.enetLTS'>
<p>coefficients from the <code>enetLTS</code> object</p></a></li>
<li><a href='#cv.enetLTS'><p>Cross-validation for the <code>enetLTS</code> object</p></a></li>
<li><a href='#enetLTS'>
<p>Robust and Sparse Methods for High Dimensional Linear and Binary and Multinomial Regression</p></a></li>
<li><a href='#fitted.enetLTS'>
<p>the fitted values from the <code>"enetLTS"</code> object.</p></a></li>
<li><a href='#lambda00'><p>Upper limit of the penalty parameter for <code>family="binomial"</code></p></a></li>
<li><a href='#nonzeroCoef.enetLTS'>
<p>nonzero coefficients indices from the <code>"enetLTS"</code> object</p></a></li>
<li><a href='#plot.enetLTS'>
<p>plots from the <code>"enetLTS"</code> object</p></a></li>
<li><a href='#plotCoef.enetLTS'>
<p>coefficients plots from the <code>"enetLTS"</code> object</p></a></li>
<li><a href='#plotDiagnostic.enetLTS'>
<p>diagnostics plots from the <code>"enetLTS"</code> object</p></a></li>
<li><a href='#plotResid.enetLTS'>
<p>residuals plots from the <code>"enetLTS"</code> object</p></a></li>
<li><a href='#predict.enetLTS'>
<p>make predictions from the <code>"enetLTS"</code> object.</p></a></li>
<li><a href='#print.enetLTS'>
<p>print from the <code>"enetLTS"</code> object</p></a></li>
<li><a href='#residuals.enetLTS'>
<p>the residuals from the <code>"enetLTS"</code> object</p></a></li>
<li><a href='#weights.enetLTS'>
<p>binary weights from the <code>"enetLTS"</code> object</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Robust and Sparse Methods for High Dimensional Linear and Binary
and Multinomial Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Fatma Sevinc Kurnaz and Irene Hoffmann and Peter Filzmoser</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Fatma Sevinc Kurnaz &lt;fatmasevinckurnaz@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Fully robust versions of the elastic net estimator are introduced for linear and binary and multinomial regression, in particular high dimensional data. The algorithm searches for outlier free subsets on which the classical elastic net estimators can be applied. A reweighting step is added to improve the statistical efficiency of the proposed estimators. Selecting appropriate tuning parameters for elastic net penalties are done via cross-validation. </td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2, glmnet, grid, reshape, parallel, cvTools, stats,
robustbase, robustHD</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-05-21 12:24:36 UTC; root</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-05-21 23:00:14 UTC</td>
</tr>
</table>
<hr>
<h2 id='coef.enetLTS'>
coefficients from the <code>enetLTS</code> object
</h2><span id='topic+coef.enetLTS'></span>

<h3>Description</h3>

<p>Extracts model coefficients from object
returned by regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'enetLTS'
coef(object,vers,zeros,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.enetLTS_+3A_object">object</code></td>
<td>
<p>fitted <code>enetLTS</code> model object.</p>
</td></tr>
<tr><td><code id="coef.enetLTS_+3A_vers">vers</code></td>
<td>
<p>a character string specifying for which fit to make
predictions. Possible values are <code>reweighted</code> (the default) for
predicting values from the reweighted fit, <code>raw</code> for predicting
values from the raw fit.</p>
</td></tr>
<tr><td><code id="coef.enetLTS_+3A_zeros">zeros</code></td>
<td>
<p>a logical indicating whether to give nonzero coefficients indices.
(<code>TRUE</code>, the default) or to omit them (<code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="coef.enetLTS_+3A_...">...</code></td>
<td>
<p>additional arguments from the <code>enetLTS</code> object if needed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector (or a list object for family=&quot;multinomial&quot;) containing the requested coefficients.
</p>


<h3>Author(s)</h3>

<p>Fatma Sevinc KURNAZ, Irene HOFFMANN, Peter FILZMOSER
<br /> Maintainer: Fatma Sevinc KURNAZ &lt;fatmasevinckurnaz@gmail.com&gt;;&lt;fskurnaz@yildiz.edu.tr&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+enetLTS">enetLTS</a></code>,
<code><a href="#topic+predict.enetLTS">predict.enetLTS</a></code>,
<code><a href="#topic+nonzeroCoef.enetLTS">nonzeroCoef.enetLTS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## for gaussian

set.seed(86)
n &lt;- 100; p &lt;- 25                             # number of observations and variables
beta &lt;- rep(0,p); beta[1:6] &lt;- 1              # 10% nonzero coefficients
sigma &lt;- 0.5                                  # controls signal-to-noise ratio
x &lt;- matrix(rnorm(n*p, sigma),nrow=n)
e &lt;- rnorm(n,0,1)                             # error terms
eps &lt;- 0.1                                    # contamination level
m &lt;- ceiling(eps*n)                           # observations to be contaminated
eout &lt;- e; eout[1:m] &lt;- eout[1:m] + 10        # vertical outliers
yout &lt;- c(x %*% beta + sigma * eout)        # response
xout &lt;- x; xout[1:m,] &lt;- xout[1:m,] + 10      # bad leverage points


fit1 &lt;- enetLTS(xout,yout)
coef(fit1)
coef(fit1,vers="raw")
coef(fit1,vers="reweighted",zeros=FALSE)



## for binomial

eps &lt;-0.05                                     # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
y &lt;- sample(0:1,n,replace=TRUE)
xout &lt;- x
xout[y==0,][1:m,] &lt;- xout[1:m,] + 10;          # class 0
yout &lt;- y                                      # wrong classification for vertical outliers


fit2 &lt;- enetLTS(xout,yout,family="binomial")
coef(fit2)
coef(fit2,vers="reweighted")
coef(fit2,vers="raw",zeros=FALSE)



## for multinomial

n &lt;- 120; p &lt;- 15
NC &lt;- 3                # number of groups
X &lt;- matrix(rnorm(n * p), n, p)
betas &lt;- matrix(1:NC, ncol=NC, nrow=p, byrow=TRUE)
betas[(p-5):p,]=0; betas &lt;- rbind(rep(0,NC),betas)
lv &lt;- cbind(1,X)%*%betas
probs &lt;- exp(lv)/apply(exp(lv),1,sum)
y &lt;- apply(probs,1,function(prob){sample(1:NC, 1, TRUE, prob)})
xout &lt;- X
eps &lt;-0.05                          # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
xout[1:m,] &lt;- xout[1:m,] + 10       # bad leverage points
yout &lt;- y


fit3    &lt;- enetLTS(xout,yout,family="multinomial")
coef(fit3)
coef(fit3,vers="reweighted")
coef(fit3,vers="raw",zeros=FALSE)


</code></pre>

<hr>
<h2 id='cv.enetLTS'>Cross-validation for the <code>enetLTS</code> object</h2><span id='topic+cv.enetLTS'></span>

<h3>Description</h3>

<p>Does k-fold cross-validation for enetLTS, produces a plot,
and returns optimal values for <code>alpha</code> and <code>lambda</code>. Combine the cross-validation
functions internally used in the algorithm <code>enetLTS</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.enetLTS(index=NULL,family,xx,yy,alphas,lambdas,nfold,repl,ncores,plot=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.enetLTS_+3A_index">index</code></td>
<td>
<p>A user supplied index. The default is <code>NULL</code> in the algorithm <code>enetLTS.</code></p>
</td></tr>
<tr><td><code id="cv.enetLTS_+3A_family">family</code></td>
<td>
<p>a description of the error distribution and link function to be used
in the model. <code>"gaussian"</code> and <code>"binomial"</code> and <code>"multinomial"</code> options are available.</p>
</td></tr>
<tr><td><code id="cv.enetLTS_+3A_xx">xx</code></td>
<td>
<p>matrix <code>xx</code> as in <code>enetLTS</code>.</p>
</td></tr>
<tr><td><code id="cv.enetLTS_+3A_yy">yy</code></td>
<td>
<p>response <code>yy</code> as in <code>enetLTS</code>.</p>
</td></tr>
<tr><td><code id="cv.enetLTS_+3A_alphas">alphas</code></td>
<td>
<p>a user supplied alpha sequence for the elastic net penalty, which is
the mixing proportion of the ridge and lasso penalties and takes value in [0,1]. Here
<code class="reqn">\alpha=1</code> is the lasso penalty, and <code class="reqn">\alpha=0</code> the
ridge penalty.</p>
</td></tr>
<tr><td><code id="cv.enetLTS_+3A_lambdas">lambdas</code></td>
<td>
<p>a user supplied lambda sequence for the strength of the elastic net penalty.</p>
</td></tr>
<tr><td><code id="cv.enetLTS_+3A_nfold">nfold</code></td>
<td>
<p>a user supplied numeric value for fold number of k-fold cross-validation which
used in varied functions of the algorithm. The default is 5-fold cross-validation.</p>
</td></tr>
<tr><td><code id="cv.enetLTS_+3A_repl">repl</code></td>
<td>
<p>a user supplied posiitive number for more stable results, repeat the k-fold CV
<code>repl</code> times and take the average of the corresponding evaluation measure. The default is 5.</p>
</td></tr>
<tr><td><code id="cv.enetLTS_+3A_ncores">ncores</code></td>
<td>
<p>a positive integer giving the number of processor cores to be used for parallel
computing. The default is 4.</p>
</td></tr>
<tr><td><code id="cv.enetLTS_+3A_plot">plot</code></td>
<td>
<p>a logical indicating if produces a plot for k-fold cross-validation
based on alpha and lambda combinations. The default is TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>produces a plot,
and returns optimal values for <code>alpha</code> and <code>lambda</code>
</p>


<h3>Note</h3>

<p>This is an internal function. But, it is also available for direct usage to
obtain optimal values of alpha and lambda for user supplied index set.
</p>


<h3>Author(s)</h3>

<p>Fatma Sevinc KURNAZ, Irene HOFFMANN, Peter FILZMOSER
<br /> Maintainer: Fatma Sevinc KURNAZ &lt;fskurnaz@gmail.com&gt;;&lt;fskurnaz@yildiz.edu.tr&gt;
</p>

<hr>
<h2 id='enetLTS'>
Robust and Sparse Methods for High Dimensional Linear and Binary and Multinomial Regression
</h2><span id='topic+enetLTS'></span>

<h3>Description</h3>

<p>Compute fully robust versions of the elastic net estimator, which allows for sparse model estimates,
for linear regression and binary and multinomial logistic regression.</p>


<h3>Usage</h3>

<pre><code class='language-R'>enetLTS(
    xx,
    yy,
    family=c("gaussian","binomial","multinomial"),
    alphas=seq(0,1,length=41),
    lambdas=NULL,
    lambdaw=NULL,
    intercept=TRUE,
    scal=TRUE,
    hsize=0.75,
    nsamp=c(500,10),
    nCsteps=20,
    nfold=5,
    repl=1,
    ncores=1,
    tol=-1e6,
    seed=NULL,
    del=0.0125,
    crit.plot=FALSE,
    typegrouped=FALSE,
    type.response=c("link","response","class")
  )
  </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="enetLTS_+3A_xx">xx</code></td>
<td>
<p>a numeric matrix containing the predictor variables.</p>
</td></tr>
<tr><td><code id="enetLTS_+3A_yy">yy</code></td>
<td>
<p>response variable. Quantitative for <code>family="gaussian"</code>. For
<code>family="binomial"</code> should be a factor with two levels which is coded as <code>0</code> and 1.
For <code>family="multinomial"</code> should be a factor with the number of categories (NC) which is
coded as <code>1,2,...,NC</code>.</p>
</td></tr>
<tr><td><code id="enetLTS_+3A_family">family</code></td>
<td>
<p>a description of the error distribution and link function to be used
in the model. <code>"gaussian"</code>, <code>"binomial"</code> and <code>family="multinomial"</code> options are available.</p>
</td></tr>
<tr><td><code id="enetLTS_+3A_alphas">alphas</code></td>
<td>
<p>a user supplied alpha sequence for the elastic net penalty, which is
the mixing proportion of the ridge and lasso penalties and takes value in [0,1].
<code class="reqn">\alpha=1</code> is the lasso penalty, and <code class="reqn">\alpha=0</code> the
ridge penalty. If not provided a sequence, default is 41 equally spaced values.</p>
</td></tr>
<tr><td><code id="enetLTS_+3A_lambdas">lambdas</code></td>
<td>
<p>a user supplied lambda sequence for the strength of the elastic net penalty.
If not provided a sequence, default is chosen with steps of size -0.025 lambda0 with
<code class="reqn">0\le\lambda\le lambda0</code> for linear regression and
-0.025 lambda00 with <code class="reqn">0\le\lambda\le lambda00</code> for binary logistic regression. lambda0
is determined based on the Pearson correlation between y and the jth predictor variable x_j
on winsorized data for linear regression. In lambda00 for logistic regression, the Pearson
correlation is replaced by a robustified point-biserial correlation. Default is chosen with
steps of size -0.05 from 0.95 to 0.05 for multinomial logistic regression.</p>
</td></tr>
<tr><td><code id="enetLTS_+3A_lambdaw">lambdaw</code></td>
<td>
<p>a user supplied lambda sequence for reweighting step. If not provided,
default is computed by using k-fold cross-validation via <code>cv.glmnet</code> function.</p>
</td></tr>
<tr><td><code id="enetLTS_+3A_intercept">intercept</code></td>
<td>
<p>a logical indicating whether a constant term should be
included in the model (the default is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="enetLTS_+3A_scal">scal</code></td>
<td>
<p>a logical value indicating whether scale the predictors by their arithmetic means
and standard deviations. For <code>family="gaussian"</code>, it also indicates if
mean-center the response variable or not. The default is <code>TRUE</code>. Note that scaling
is performed on the subsamples rather than the full data set.</p>
</td></tr>
<tr><td><code id="enetLTS_+3A_hsize">hsize</code></td>
<td>
<p>a user supplied numeric value giving the percentage of the residuals for
which the elastic net penalized sum of squares for linear regression or for which the
elastic net penalized sum of deviances for binary and multinomial logistic regression
should be minimized. The default is 0.75.</p>
</td></tr>
<tr><td><code id="enetLTS_+3A_nsamp">nsamp</code></td>
<td>
<p>a numeric vector giving the number of subsamples to be used in
the beginning of the algorithm, which gives the number of
initial subsamples to be used. The default is to first perform C-steps on 500
initial subsamples, and then to keep the <code>s1</code> subsamples with the lowest value
(or highest value based on which model is used - <code>family="gaussian"</code> or <code>family="binomial"</code>
or <code>family="multinomial"</code>) of the objective function for additional C-steps until convergence.</p>
</td></tr>
<tr><td><code id="enetLTS_+3A_ncsteps">nCsteps</code></td>
<td>
<p>a positive integer giving the number of C-steps to perform on
determined s1 subsamples. The default is 20.</p>
</td></tr>
<tr><td><code id="enetLTS_+3A_nfold">nfold</code></td>
<td>
<p>a user supplied numeric value for fold number of k-fold cross-validation which
used in varied functions of the algorithm. The default is 5-fold cross-validation.</p>
</td></tr>
<tr><td><code id="enetLTS_+3A_repl">repl</code></td>
<td>
<p>a user supplied positive number for more stable results, repeat the k-fold CV
<code>repl</code> times and take the average of the corresponding evaluation measure. The default is 1.</p>
</td></tr>
<tr><td><code id="enetLTS_+3A_ncores">ncores</code></td>
<td>
<p>a positive integer giving the number of processor cores to be
used for parallel computing (the default is 1 for no parallelization). If
this is set to <code>NA</code>, all available processor cores are used. For
prediction error estimation, parallel computing is implemented on the <span class="rlang"><b>R</b></span>
level using package <span class="pkg">parallel</span>.</p>
</td></tr>
<tr><td><code id="enetLTS_+3A_tol">tol</code></td>
<td>
<p>a small numeric value for convergence. The default is -1e6.</p>
</td></tr>
<tr><td><code id="enetLTS_+3A_seed">seed</code></td>
<td>
<p>optional initial seed for the random number generator (see<code><a href="base.html#topic+.Random.seed">.Random.seed</a></code>)
when determine initial subsets at thebeginning of the algorithm. The default is NULL.</p>
</td></tr>
<tr><td><code id="enetLTS_+3A_del">del</code></td>
<td>
<p>The default is 0.0125.</p>
</td></tr>
<tr><td><code id="enetLTS_+3A_crit.plot">crit.plot</code></td>
<td>
<p>a logical value indicating if produces a plot for k-fold cross-validation based on
alpha and lambda combinations. The default is TRUE.</p>
</td></tr>
<tr><td><code id="enetLTS_+3A_typegrouped">typegrouped</code></td>
<td>
<p>This argument is available for only <code>family="multinomial"</code> in the last
fit based on the best subset. <code>TRUE</code> means &quot;grouped&quot; and <code>FALSE</code> means &quot;ungrouped&quot;.
If &quot;TRUE&quot; then a grouped lasso penalty is used on the multinomial coefficients for a variable.
The default is FALSE.</p>
</td></tr>
<tr><td><code id="enetLTS_+3A_type.response">type.response</code></td>
<td>
<p>type of prediction required. <code>type="link"</code> gives the linear predictors.
<code>type="response"</code> gives the
fitted probabilities for <code>family="multinomial"</code> and <code>family="binomial"</code> and
gives the fitted values for <code>family="gaussian"</code>.
<code>type="class"</code> is available only for <code>family="binomial"</code> and <code>family="multinomial"</code>,
and produces the class label corresponding to the maximum probability.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The idea of repeatedly applying the non-robust classical elastic net estimators to data subsets
only is used for linear and logistic regression. The algorithm starts with 500 elemental subsets
only for one combination of <code class="reqn">\alpha</code> and <code class="reqn">\lambda</code>, and takes the warm start strategy
for subsequent combinations. This idea saves the computation time.
To choose the elastic net penalties, k-fold cross-validation is used and the replication option is
provided for more stable results.
Robustness has been achieved by using trimming idea, therefore a reweighting step is introduced
in order to improve the efficiency. The outliers are identified according to current model.
For <code>family="gaussian"</code>, standardized residuals are used. For <code>family="binomial"</code>, the Pearson
residuals which are approximately standard normally distributed is used. Then the weights are defined by
the binary weight function using <code>del=0.0125</code>, which allows to be flagged as outliers of the
2.5% of the observations in the normal model. For <code>family="multinomial"</code>,
group-wise scaled robust distances are used. The the binary weights defined using the constant $c_2=5$.
Therefore, binary weight function produces a clear distinction between the &quot;good observations&quot; and &quot;outliers&quot;.</p>


<h3>Value</h3>

<table>
<tr><td><code>objective</code></td>
<td>
<p>a numeric vector giving the respective values of the
enetLTS objective function, i.e., the elastic net penalized sums of
the <code class="reqn">h</code> smallest squared residuals from the raw fits for <code>family="gaussian"</code>
and the elastic net penalized sums of the <code class="reqn">h</code> deviances from the raw fits for
<code>family="binomial"</code>.</p>
</td></tr>
<tr><td><code>raw.rmse</code></td>
<td>
<p>root mean squared error for raw fit, which is available for only
<code>family="gaussian"</code>.</p>
</td></tr>
<tr><td><code>rmse</code></td>
<td>
<p>root mean squared error for reweighted fit, which is available for only
<code>family  ="gaussian"</code>.</p>
</td></tr>
<tr><td><code>raw.mae</code></td>
<td>
<p>mean absolute error for raw fit.</p>
</td></tr>
<tr><td><code>mae</code></td>
<td>
<p>mean absolute error for reweighted fit.</p>
</td></tr>
<tr><td><code>best</code></td>
<td>
<p>an integer vector containing the respective best
subsets of <code class="reqn">h</code> observations found and used for computing the raw
estimates.</p>
</td></tr>
<tr><td><code>raw.wt</code></td>
<td>
<p>an integer vector containing binary weights
that indicate outliers from the respective raw fits, i.e., the weights used
for the reweighted fits.</p>
</td></tr>
<tr><td><code>wt</code></td>
<td>
<p>an integer vector containing binary weights that
indicate outliers from the respective reweighted fits, i.e., the weights are
<code class="reqn">1</code> for observations with reasonably small reweighted residuals and
<code class="reqn">0</code> for observations with large reweighted residuals.</p>
</td></tr>
<tr><td><code>raw.coefficients</code></td>
<td>
<p>a numeric vector containing the
respective coefficient estimates from the raw fit.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>a numeric vector containing the
respective coefficient estimates from the reweighted fit.</p>
</td></tr>
<tr><td><code>raw.fitted.values</code></td>
<td>
<p>a numeric vector containing the
respective fitted values of the response from the raw fits.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>a numeric vector containing the
respective fitted values of the response from the reweighted fits.</p>
</td></tr>
<tr><td><code>raw.residuals</code></td>
<td>
<p>a numeric vector containing the
respective residuals for <code>family="gaussian"</code> and respective deviances for
<code>family="binomial"</code> and <code>family="multinomial"</code> from the raw fits.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>a numeric vector containing the
respective residuals for <code>family="gaussian"</code> and respective deviances for
<code>family="binomial"</code> and <code>family="multinomial"</code> from the reweighted fits.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>an optimal elastic net mixing parameter value obtained with
k-fold cross-validation.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>an optimal value for the strength of the elastic net penalty
obtained with k-fold cross-validation.</p>
</td></tr>
<tr><td><code>lambdaw</code></td>
<td>
<p>an optimal value for the strength of the elastic net penalty
re-obtained with k-fold cross-validation for reweighted fit.</p>
</td></tr>
<tr><td><code>num.nonzerocoef</code></td>
<td>
<p>the number of the nonzero coefficients in the model.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>the number of observations.</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>the number of variables.</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>the number of observations used to compute the raw estimates.</p>
</td></tr>
<tr><td><code>classnames</code></td>
<td>
<p>class names for logistic model, which is available for only
<code>family="binomial"</code> and <code>family="multinomial"</code>.</p>
</td></tr>
<tr><td><code>classize</code></td>
<td>
<p>class sizes for logisitic model, which is available for only
<code>family="binomial"</code> and <code>family="multinomial"</code>.</p>
</td></tr>
<tr><td><code>inputs</code></td>
<td>
<p>all inputs used in the function <code>enetLTS.R</code>.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched function call.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Fatma Sevinc KURNAZ, Irene HOFFMANN, Peter FILZMOSER
</p>


<h3>References</h3>

<p>Kurnaz, F.S., Hoffmann, I. and Filzmoser, P. (2017) Robust and sparse estimation methods
for high dimensional linear and logistic regression. <em>Chemometrics and Intelligent Laboratory Systems.</em>
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+print">print</a></code>,
<code><a href="stats.html#topic+predict">predict</a></code>,
<code><a href="stats.html#topic+coef">coef</a></code>,
<code><a href="#topic+nonzeroCoef.enetLTS">nonzeroCoef.enetLTS</a></code>,
<code><a href="base.html#topic+plot">plot</a></code>,
<code><a href="#topic+plotCoef.enetLTS">plotCoef.enetLTS</a></code>,
<code><a href="#topic+plotResid.enetLTS">plotResid.enetLTS</a></code>,
<code><a href="#topic+plotDiagnostic.enetLTS">plotDiagnostic.enetLTS</a></code>,
<code><a href="stats.html#topic+residuals">residuals</a></code>,
<code><a href="stats.html#topic+fitted">fitted</a></code>,
<code><a href="stats.html#topic+weights">weights</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## for gaussian

set.seed(86)
n &lt;- 100; p &lt;- 25                             # number of observations and variables
beta &lt;- rep(0,p); beta[1:6] &lt;- 1              # 10% nonzero coefficients
sigma &lt;- 0.5                                  # controls signal-to-noise ratio
x &lt;- matrix(rnorm(n*p, sigma),nrow=n)
e &lt;- rnorm(n,0,1)                             # error terms
eps &lt;- 0.1                                    # contamination level
m &lt;- ceiling(eps*n)                           # observations to be contaminated
eout &lt;- e; eout[1:m] &lt;- eout[1:m] + 10        # vertical outliers
yout &lt;- c(x %*% beta + sigma * eout)        # response
xout &lt;- x; xout[1:m,] &lt;- xout[1:m,] + 10      # bad leverage points


# determine user supplied alpha and lambda sequences
# alphas=seq(0,1,length=11)
# l0 &lt;- robustHD::lambda0(xout,yout)          # use lambda0 function from robustHD package
# lambdas &lt;- seq(l0,0,by=-0.1*l0)
# fit &lt;- enetLTS(xout,yout,alphas=alphas,lambdas=lambdas)


## for binomial

eps &lt;-0.05                                     # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
y &lt;- sample(0:1,n,replace=TRUE)
xout &lt;- x
xout[y==0,][1:m,] &lt;- xout[1:m,] + 10;          # class 0
yout &lt;- y                                      # wrong classification for vertical outliers


# determine user supplied alpha and lambda sequences
# alphas=seq(0,1,length=11)
# l00 &lt;- lambda00(xout,yout,normalize=TRUE,intercept=TRUE)
# lambdas &lt;-  seq(l00,0,by=-0.01*l00)
# fit &lt;- enetLTS(xout,yout,family="binomial",alphas=alphas,lambdas=lambdas)


## for multinomial

n &lt;- 120; p &lt;- 15
NC &lt;- 3           # number of groups
X &lt;- matrix(rnorm(n * p), n, p)
betas &lt;- matrix(1:NC, ncol=NC, nrow=p, byrow=TRUE)
betas[(p-5):p,]=0; betas &lt;- rbind(rep(0,NC),betas)
lv &lt;- cbind(1,X) %*% betas
probs &lt;- exp(lv)/apply(exp(lv),1,sum)
y &lt;- apply(probs,1,function(prob){sample(1:NC, 1, TRUE, prob)})
xout &lt;- X
eps &lt;-0.05                          # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
xout[1:m,] &lt;- xout[1:m,] + 10       # bad leverage points
yout &lt;- y


# determine user supplied alpha and lambda sequences
alphas=seq(0,1,length=11)
lambdas &lt;- seq(from=0.95,to=0.05,by=-0.05)
fit &lt;- enetLTS(xout,yout,family="multinomial",alphas=alphas,lambdas=lambdas)

</code></pre>

<hr>
<h2 id='fitted.enetLTS'>
the fitted values from the <code>"enetLTS"</code> object.
</h2><span id='topic+fitted.enetLTS'></span>

<h3>Description</h3>

<p>A numeric vector which extract fitted values from the current model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'enetLTS'
fitted(object,vers=c("reweighted","raw","both"),type=c("response","class"),...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitted.enetLTS_+3A_object">object</code></td>
<td>
<p>the model fit from which to extract fitted values.</p>
</td></tr>
<tr><td><code id="fitted.enetLTS_+3A_vers">vers</code></td>
<td>
<p>a character string specifying for which fit to make
predictions. Possible values are <code>"reweighted"</code> (the default) for
predicting values from the reweighted fit, <code>"raw"</code> for predicting
values from the raw fit, or <code>"both"</code> for predicting values from both
fits.</p>
</td></tr>
<tr><td><code id="fitted.enetLTS_+3A_type">type</code></td>
<td>
<p>type of prediction required. <code>type="response"</code> gives the
fitted probabilities for <code>"multinomial"</code> and <code>"binomial"</code> and gives the fitted values
for <code>"gaussian"</code>. <code>type="class"</code> is available only for <code>"multinomial"</code> and
<code>"binomial"</code> model, and produces the class label corresponding to the maximum probability.</p>
</td></tr>
<tr><td><code id="fitted.enetLTS_+3A_...">...</code></td>
<td>
<p>additional arguments from the <code>enetLTS</code> object if needed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the requested fitted values.
</p>


<h3>Author(s)</h3>

<p>Fatma Sevinc KURNAZ, Irene HOFFMANN, Peter FILZMOSER
<br /> Maintainer: Fatma Sevinc KURNAZ &lt;fskurnaz@gmail.com&gt;;&lt;fskurnaz@yildiz.edu.tr&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+enetLTS">enetLTS</a></code>,
<code><a href="#topic+predict.enetLTS">predict.enetLTS</a></code>,
<code><a href="#topic+residuals.enetLTS">residuals.enetLTS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## for gaussian

set.seed(86)
n &lt;- 100; p &lt;- 25                             # number of observations and variables
beta &lt;- rep(0,p); beta[1:6] &lt;- 1              # 10% nonzero coefficients
sigma &lt;- 0.5                                  # controls signal-to-noise ratio
x &lt;- matrix(rnorm(n*p, sigma),nrow=n)
e &lt;- rnorm(n,0,1)                             # error terms
eps &lt;- 0.1                                    # contamination level
m &lt;- ceiling(eps*n)                           # observations to be contaminated
eout &lt;- e; eout[1:m] &lt;- eout[1:m] + 10        # vertical outliers
yout &lt;- c(x %*% beta + sigma * eout)        # response
xout &lt;- x; xout[1:m,] &lt;- xout[1:m,] + 10      # bad leverage points


fit1 &lt;- enetLTS(xout,yout,crit.plot=FALSE)
fitted(fit1)
fitted(fit1,vers="raw")
fitted(fit1,vers="both")
fitted(fit1,vers="reweighted",type="response")


## for binomial
eps &lt;-0.05                                     # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
y &lt;- sample(0:1,n,replace=TRUE)
xout &lt;- x
xout[y==0,][1:m,] &lt;- xout[1:m,] + 10;          # class 0
yout &lt;- y                                      # wrong classification for vertical outliers



fit2 &lt;- enetLTS(xout,yout,family="binomial")
fitted(fit2)
fitted(fit2,vers="raw")
fitted(fit2,vers="both",type="class")
fitted(fit2,vers="both")
fitted(fit2,vers="reweighted",type="class")




## for multinomial

n &lt;- 120; p &lt;- 15
NC &lt;- 3
X &lt;- matrix(rnorm(n * p), n, p)
betas &lt;- matrix(1:NC, ncol=NC, nrow=p, byrow=TRUE)
betas[(p-5):p,]=0; betas &lt;- rbind(rep(0,NC),betas)
lv &lt;- cbind(1,X) %*% betas
probs &lt;- exp(lv)/apply(exp(lv),1,sum)
y &lt;- apply(probs,1,function(prob){sample(1:NC, 1, TRUE, prob)})
xout &lt;- X
eps &lt;-0.05                          # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
xout[1:m,] &lt;- xout[1:m,] + 10       # bad leverage points
yout &lt;- y


fit3 &lt;- enetLTS(xout,yout,family="multinomial")
fitted(fit3)
fitted(fit3,vers="raw")
fitted(fit3,vers="both",type="class")
fitted(fit3,vers="both")
fitted(fit3,vers="reweighted",type="class")

</code></pre>

<hr>
<h2 id='lambda00'>Upper limit of the penalty parameter for <code>family="binomial"</code></h2><span id='topic+lambda00'></span>

<h3>Description</h3>

<p>Use bivariate winsorization to estimate the smallest value of the upper limit for the penalty
parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lambda00(x,y,normalize=TRUE,intercept=TRUE,const=2,prob=0.95,
      tol=.Machine$double.eps^0.5,eps=.Machine$double.eps,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lambda00_+3A_x">x</code></td>
<td>
<p>a numeric matrix containing the predictor variables.</p>
</td></tr>
<tr><td><code id="lambda00_+3A_y">y</code></td>
<td>
<p>a numeric vector containing the response variable.</p>
</td></tr>
<tr><td><code id="lambda00_+3A_normalize">normalize</code></td>
<td>
<p>a logical indicating whether the winsorized predictor
variables should be normalized or not (the
default is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="lambda00_+3A_intercept">intercept</code></td>
<td>
<p>a logical indicating whether a constant term should be
included in the model (the default is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="lambda00_+3A_const">const</code></td>
<td>
<p>numeric; tuning constant to be used in univariate
winsorization (the default is 2).</p>
</td></tr>
<tr><td><code id="lambda00_+3A_prob">prob</code></td>
<td>
<p>numeric; probability for the quantile of the
<code class="reqn">\chi^{2}</code> distribution to be used in bivariate
winsorization (the default is 0.95).</p>
</td></tr>
<tr><td><code id="lambda00_+3A_tol">tol</code></td>
<td>
<p>a small positive numeric value used to determine singularity
issues in the computation of correlation estimates for bivariate
winsorization.</p>
</td></tr>
<tr><td><code id="lambda00_+3A_eps">eps</code></td>
<td>
<p>a small positive numeric value used to determine whether the
robust scale estimate of a variable is too small (an effective zero).</p>
</td></tr>
<tr><td><code id="lambda00_+3A_...">...</code></td>
<td>
<p>additional arguments if needed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The estimation procedure is done with similar approach as in Alfons et al. (2013).
But the Pearson correlation between y and the jth predictor variable xj on winsorized data is
replaced to a robustified point-biserial correlation for logistic regression.
</p>


<h3>Value</h3>

<p>A robust estimate of the smallest value of the penalty parameter for
enetLTS regression (for <code>family="binomial"</code>).
</p>


<h3>Note</h3>

<p>For linear regression, we take exactly same procedure as in Alfons et al., which is based on
the Pearson correlation between y and the jth predictor variable xj on winsorized
data. See Alfons et al. (2013).
</p>


<h3>Author(s)</h3>

<p>Fatma Sevinc KURNAZ, Irene HOFFMANN, Peter FILZMOSER
<br /> Maintainer: Fatma Sevinc KURNAZ &lt;fatmasevinckurnaz@gmail.com&gt;;&lt;fskurnaz@yildiz.edu.tr&gt;</p>


<h3>References</h3>

<p>Kurnaz, F.S., Hoffmann, I. and Filzmoser, P. (2017) Robust and sparse estimation methods
for high dimensional linear and logistic regression.
<em>Chemometrics and Intelligent Laboratory Systems.</em>
</p>
<p>Alfons, A., Croux, C. and Gelper, S. (2013) Sparse least trimmed squares regression for
analyzing high-dimensional large data sets. <em>The Annals of Applied Statistics</em>, 7(1), 226&ndash;248.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+enetLTS">enetLTS</a></code>,
<code><a href="robustHD.html#topic+sparseLTS">sparseLTS</a></code>,
<code><a href="robustHD.html#topic+lambda0">lambda0</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(86)
n &lt;- 100; p &lt;- 25                             # number of observations and variables
beta &lt;- rep(0,p); beta[1:6] &lt;- 1              # 10% nonzero coefficients
sigma &lt;- 0.5                                  # controls signal-to-noise ratio
x &lt;- matrix(rnorm(n*p, sigma),nrow=n)
e &lt;- rnorm(n,0,1)                             # error terms
eps &lt;-0.05                                    # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
y &lt;- sample(0:1,n,replace=TRUE)
xout &lt;- x
xout[y==0,][1:m,] &lt;- xout[1:m,] + 10;         # class 0
yout &lt;- y                                     # wrong classification for vertical outliers

# compute smallest value of the upper limit for the penalty parameter
l00 &lt;- lambda00(xout,yout)
</code></pre>

<hr>
<h2 id='nonzeroCoef.enetLTS'>
nonzero coefficients indices from the <code>"enetLTS"</code> object
</h2><span id='topic+nonzeroCoef.enetLTS'></span>

<h3>Description</h3>

<p>A numeric vector which gives the indices of nonzero coefficients from the current model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nonzeroCoef.enetLTS(object,vers=c("reweighted","raw"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nonzeroCoef.enetLTS_+3A_object">object</code></td>
<td>
<p>the model fit from which to extract nonzero coefficients indices.</p>
</td></tr>
<tr><td><code id="nonzeroCoef.enetLTS_+3A_vers">vers</code></td>
<td>
<p>a character string denoting which model to use.
Possible values are <code>"reweighted"</code> (the default) for
plots from the reweighted fit, and <code>"raw"</code> for
plots from the raw fit.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector (or a list object for family=&quot;multinomial&quot;) containing the request.
</p>


<h3>Author(s)</h3>

<p>Fatma Sevinc KURNAZ, Irene HOFFMANN, Peter FILZMOSER
<br /> Maintainer: Fatma Sevinc KURNAZ &lt;fatmasevinckurnaz@gmail.com&gt;;&lt;fskurnaz@yildiz.edu.tr&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+enetLTS">enetLTS</a></code>,
<code><a href="#topic+predict.enetLTS">predict.enetLTS</a></code>,
<code><a href="#topic+coef.enetLTS">coef.enetLTS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## for gaussian

set.seed(86)
n &lt;- 100; p &lt;- 25                             # number of observations and variables
beta &lt;- rep(0,p); beta[1:6] &lt;- 1              # 10% nonzero coefficients
sigma &lt;- 0.5                                  # controls signal-to-noise ratio
x &lt;- matrix(rnorm(n*p, sigma),nrow=n)
e &lt;- rnorm(n,0,1)                             # error terms
eps &lt;- 0.1                                    # contamination level
m &lt;- ceiling(eps*n)                           # observations to be contaminated
eout &lt;- e; eout[1:m] &lt;- eout[1:m] + 10        # vertical outliers
yout &lt;- c(x %*% beta + sigma * eout)        # response
xout &lt;- x; xout[1:m,] &lt;- xout[1:m,] + 10      # bad leverage points


fit1 &lt;- enetLTS(xout,yout)
nonzeroCoef.enetLTS(fit1)
nonzeroCoef.enetLTS(fit1,vers="raw")


## for binomial

eps &lt;-0.05                                     # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
y &lt;- sample(0:1,n,replace=TRUE)
xout &lt;- x
xout[y==0,][1:m,] &lt;- xout[1:m,] + 10;          # class 0
yout &lt;- y                                      # wrong classification for vertical outliers


fit2 &lt;- enetLTS(xout,yout,family="binomial")
nonzeroCoef.enetLTS(fit2)
nonzeroCoef.enetLTS(fit2,vers="raw")



## for multinomial

n &lt;- 120; p &lt;- 15
NC &lt;- 3
X &lt;- matrix(rnorm(n * p), n, p)
betas &lt;- matrix(1:NC, ncol=NC, nrow=p, byrow=TRUE)
betas[(p-5):p,]=0; betas &lt;- rbind(rep(0,NC),betas)
lv &lt;- cbind(1,X) %*% betas
probs &lt;- exp(lv)/apply(exp(lv),1,sum)
y &lt;- apply(probs,1,function(prob){sample(1:NC, 1, TRUE, prob)})
xout &lt;- X
eps &lt;-0.05                          # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
xout[1:m,] &lt;- xout[1:m,] + 10       # bad leverage points
yout &lt;- y


fit3    &lt;- enetLTS(xout,yout,family="multinomial")
nonzeroCoef.enetLTS(fit3)
nonzeroCoef.enetLTS(fit3,vers="raw")


</code></pre>

<hr>
<h2 id='plot.enetLTS'>
plots from the <code>"enetLTS"</code> object
</h2><span id='topic+plot.enetLTS'></span>

<h3>Description</h3>

<p>Produce plots for the coefficients, residuals,
and diagnostics of the current model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'enetLTS'
plot(x,method=c("coefficients","resid","diagnostic"),
       vers=c("reweighted","raw"),...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.enetLTS_+3A_x">x</code></td>
<td>
<p>object of class enetLTS, the model fit to be plotted.</p>
</td></tr>
<tr><td><code id="plot.enetLTS_+3A_method">method</code></td>
<td>
<p>a character string specifying the type of plot. Possible values are
<code>"coefficients"</code> to plot the coefficients via <code>plotCoef.enetLTS</code>,
<code>"resid"</code> to plot the residuals via <code>plotResid.enetLTS</code>,
or <code>"diagnostic"</code> for diagnostic plot via <code>plotDiagnostic.enetLTS</code>.</p>
</td></tr>
<tr><td><code id="plot.enetLTS_+3A_vers">vers</code></td>
<td>
<p>a character string denoting which model to use for the plots.
Possible values are <code>"reweighted"</code> (the default) for
plots from the reweighted fit, and <code>"raw"</code> for plots from the raw fit.</p>
</td></tr>
<tr><td><code id="plot.enetLTS_+3A_...">...</code></td>
<td>
<p>additional arguments from the <code>enetLTS</code> object if needed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"ggplot"</code> (see <code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>).
</p>


<h3>Note</h3>

<p>For <code>method</code>, the choices are:
</p>
<p><code>method="coefficients"</code> - coefficients vs indices.
</p>
<p><code>method="resid"</code> - residuals vs indices. (for both <code>family="binomial"</code> and <code>family="gaussian"</code>).
</p>
<p>- additionally, residuals vs fitted values (for only <code>family="gaussian"</code>).
</p>
<p><code>method="diagnostics"</code> - fitted values vs indices.
</p>


<h3>Author(s)</h3>

<p>Fatma Sevinc KURNAZ, Irene HOFFMANN, Peter FILZMOSER
<br /> Maintainer: Fatma Sevinc KURNAZ &lt;fatmasevinckurnaz@gmail.com&gt;;&lt;fskurnaz@yildiz.edu.tr&gt;</p>


<h3>References</h3>

<p>Kurnaz, F.S., Hoffmann, I. and Filzmoser, P. (2017) Robust and sparse estimation methods
for high dimensional linear and logistic regression. <em>Chemometrics and Intelligent Laboratory Systems</em>.
</p>


<h3>See Also</h3>

<p><code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>,
<code><a href="#topic+enetLTS">enetLTS</a></code>,
<code><a href="#topic+coef.enetLTS">coef.enetLTS</a></code>,
<code><a href="#topic+predict.enetLTS">predict.enetLTS</a></code>,
<code><a href="#topic+residuals.enetLTS">residuals.enetLTS</a></code>,
<code><a href="#topic+fitted.enetLTS">fitted.enetLTS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## for gaussian

set.seed(86)
n &lt;- 100; p &lt;- 25                             # number of observations and variables
beta &lt;- rep(0,p); beta[1:6] &lt;- 1              # 10% nonzero coefficients
sigma &lt;- 0.5                                  # controls signal-to-noise ratio
x &lt;- matrix(rnorm(n*p, sigma),nrow=n)
e &lt;- rnorm(n,0,1)                             # error terms
eps &lt;- 0.1                                    # contamination level
m &lt;- ceiling(eps*n)                           # observations to be contaminated
eout &lt;- e; eout[1:m] &lt;- eout[1:m] + 10        # vertical outliers
yout &lt;- c(x %*% beta + sigma * eout)          # response
xout &lt;- x; xout[1:m,] &lt;- xout[1:m,] + 10      # bad leverage points


fit1 &lt;- enetLTS(xout,yout,crit.plot=FALSE)
plot(fit1)
plot(fit1,method="resid",vers="raw")
plot(fit1,method="coefficients",vers="reweighted")
plot(fit1,method="diagnostic")

## for binomial
eps &lt;-0.05                                     # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
y &lt;- sample(0:1,n,replace=TRUE)
xout &lt;- x
xout[y==0,][1:m,] &lt;- xout[1:m,] + 10;          # class 0
yout &lt;- y                                      # wrong classification for vertical outliers


fit2 &lt;- enetLTS(xout,yout,family="binomial",crit.plot=FALSE)
plot(fit2)
plot(fit2,method="resid",vers="raw")
plot(fit2,method="coefficients",vers="reweighted")
plot(fit2,method="diagnostic")


## for multinomial

n &lt;- 120; p &lt;- 15
NC &lt;- 3
X &lt;- matrix(rnorm(n * p), n, p)
betas &lt;- matrix(1:NC, ncol=NC, nrow=p, byrow=TRUE)
betas[(p-5):p,]=0; betas &lt;- rbind(rep(0,NC),betas)
lv &lt;- cbind(1,X) %*% betas
probs &lt;- exp(lv)/apply(exp(lv),1,sum)
y &lt;- apply(probs,1,function(prob){sample(1:NC, 1, TRUE, prob)})
xout &lt;- X
eps &lt;-0.05                          # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
xout[1:m,] &lt;- xout[1:m,] + 10       # bad leverage points
yout &lt;- y


fit3 &lt;- enetLTS(xout,yout,family="multinomial")
plotCoef.enetLTS(fit3)
plotCoef.enetLTS(fit3,vers="raw")

</code></pre>

<hr>
<h2 id='plotCoef.enetLTS'>
coefficients plots from the <code>"enetLTS"</code> object
</h2><span id='topic+plotCoef.enetLTS'></span>

<h3>Description</h3>

<p>Produce plots for the coefficients of the current model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotCoef.enetLTS(object,vers=c("reweighted","raw"),colors=NULL,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotCoef.enetLTS_+3A_object">object</code></td>
<td>
<p>the model fit to be plotted.</p>
</td></tr>
<tr><td><code id="plotCoef.enetLTS_+3A_vers">vers</code></td>
<td>
<p>a character string denoting which model to use for the plots.
Possible values are <code>"reweighted"</code> (the default) for
plots from the reweighted fit, and <code>"raw"</code> for
plots from the raw fit.</p>
</td></tr>
<tr><td><code id="plotCoef.enetLTS_+3A_colors">colors</code></td>
<td>
<p>optional parameter, list object with list names
<code>bars, errorbars, background, abline, scores, cutoffs, badouts, modouts</code>,
each containing a string referring to a color.</p>
</td></tr>
<tr><td><code id="plotCoef.enetLTS_+3A_...">...</code></td>
<td>
<p>additional arguments from the <code>enetLTS</code> object if needed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"ggplot"</code> (see <code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>).
</p>


<h3>Note</h3>

<p>gives the matplot of
</p>
<p>- coefficients vs indices.
</p>


<h3>Author(s)</h3>

<p>Fatma Sevinc KURNAZ, Irene HOFFMANN, Peter FILZMOSER
<br /> Maintainer: Fatma Sevinc KURNAZ &lt;fatmasevinckurnaz@gmail.com&gt;;&lt;fskurnaz@yildiz.edu.tr&gt;</p>


<h3>References</h3>

<p>Kurnaz, F.S., Hoffmann, I. and Filzmoser, P. (2017) Robust and sparse estimation methods
for high dimensional linear and logistic regression. <em>Chemometrics and Intelligent Laboratory Systems</em>.
</p>


<h3>See Also</h3>

<p><code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>,
<code><a href="#topic+enetLTS">enetLTS</a></code>,
<code><a href="#topic+coef.enetLTS">coef.enetLTS</a></code>,
<code><a href="#topic+predict.enetLTS">predict.enetLTS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## for gaussian

set.seed(86)
n &lt;- 100; p &lt;- 25                             # number of observations and variables
beta &lt;- rep(0,p); beta[1:6] &lt;- 1              # 10% nonzero coefficients
sigma &lt;- 0.5                                  # controls signal-to-noise ratio
x &lt;- matrix(rnorm(n*p, sigma),nrow=n)
e &lt;- rnorm(n,0,1)                             # error terms
eps &lt;- 0.1                                    # contamination level
m &lt;- ceiling(eps*n)                           # observations to be contaminated
eout &lt;- e; eout[1:m] &lt;- eout[1:m] + 10        # vertical outliers
yout &lt;- c(x %*% beta + sigma * eout)        # response
xout &lt;- x; xout[1:m,] &lt;- xout[1:m,] + 10      # bad leverage points


fit1 &lt;- enetLTS(xout,yout,crit.plot=FALSE)
plotCoef.enetLTS(fit1)
plotCoef.enetLTS(fit1,vers="raw")

## for binomial
eps &lt;-0.05                                     # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
y &lt;- sample(0:1,n,replace=TRUE)
xout &lt;- x
xout[y==0,][1:m,] &lt;- xout[1:m,] + 10;          # class 0
yout &lt;- y                                      # wrong classification for vertical outliers



fit2 &lt;- enetLTS(xout,yout,family="binomial")
plotCoef.enetLTS(fit2)
plotCoef.enetLTS(fit2,vers="raw")


## for multinomial

n &lt;- 120; p &lt;- 15
NC &lt;- 3
X &lt;- matrix(rnorm(n * p), n, p)
betas &lt;- matrix(1:NC, ncol=NC, nrow=p, byrow=TRUE)
betas[(p-5):p,]=0; betas &lt;- rbind(rep(0,NC),betas)
lv &lt;- cbind(1,X) %*% betas
probs &lt;- exp(lv)/apply(exp(lv),1,sum)
y &lt;- apply(probs,1,function(prob){sample(1:NC, 1, TRUE, prob)})
xout &lt;- X
eps &lt;-0.05                          # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
xout[1:m,] &lt;- xout[1:m,] + 10       # bad leverage points
yout &lt;- y


fit3 &lt;- enetLTS(xout,yout,family="multinomial")
plotCoef.enetLTS(fit3)
plotCoef.enetLTS(fit3,vers="raw")

</code></pre>

<hr>
<h2 id='plotDiagnostic.enetLTS'>
diagnostics plots from the <code>"enetLTS"</code> object
</h2><span id='topic+plotDiagnostic.enetLTS'></span>

<h3>Description</h3>

<p>Produce plots for the diagnostics of the current model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotDiagnostic.enetLTS(object,vers=c("reweighted","raw"),...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotDiagnostic.enetLTS_+3A_object">object</code></td>
<td>
<p>the model fit to be plotted.</p>
</td></tr>
<tr><td><code id="plotDiagnostic.enetLTS_+3A_vers">vers</code></td>
<td>
<p>a character string denoting which model to use for the plots.
Possible values are <code>"reweighted"</code> (the default) for
plots from the reweighted fit, and <code>"raw"</code> for
plots from the raw fit.</p>
</td></tr>
<tr><td><code id="plotDiagnostic.enetLTS_+3A_...">...</code></td>
<td>
<p>additional arguments from the <code>enetLTS</code> object if needed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"ggplot"</code> (see <code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>).
</p>


<h3>Note</h3>

<p>gives the plot of
</p>
<p>- First two components of estimated scores for multinomial logistic regression (for <code>family="multinomial"</code>)
</p>
<p>- y vs fitted values/link function. (for for both <code>family="binomial"</code> and <code>family="gaussian"</code>).
</p>


<h3>Author(s)</h3>

<p>Fatma Sevinc KURNAZ, Irene HOFFMANN, Peter FILZMOSER
<br /> Maintainer: Fatma Sevinc KURNAZ &lt;fatmasevinckurnaz@gmail.com&gt;; &lt;fskurnaz@yildiz.edu.tr&gt;</p>


<h3>References</h3>

<p>Kurnaz, F.S., Hoffmann, I. and Filzmoser, P. (2017) Robust and sparse estimation methods
for high dimensional linear and logistic regression. <em>Chemometrics and Intelligent Laboratory Systems</em>.
</p>


<h3>See Also</h3>

<p><code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>,
<code><a href="#topic+enetLTS">enetLTS</a></code>,
<code><a href="#topic+coef.enetLTS">coef.enetLTS</a></code>,
<code><a href="#topic+predict.enetLTS">predict.enetLTS</a></code>,
<code><a href="#topic+residuals.enetLTS">residuals.enetLTS</a></code>,
<code><a href="#topic+fitted.enetLTS">fitted.enetLTS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## for gaussian

set.seed(86)
n &lt;- 100; p &lt;- 25                             # number of observations and variables
beta &lt;- rep(0,p); beta[1:6] &lt;- 1              # 10% nonzero coefficients
sigma &lt;- 0.5                                  # controls signal-to-noise ratio
x &lt;- matrix(rnorm(n*p, sigma),nrow=n)
e &lt;- rnorm(n,0,1)                             # error terms
eps &lt;- 0.1                                    # contamination level
m &lt;- ceiling(eps*n)                           # observations to be contaminated
eout &lt;- e; eout[1:m] &lt;- eout[1:m] + 10        # vertical outliers
yout &lt;- c(x %*% beta + sigma * eout)        # response
xout &lt;- x; xout[1:m,] &lt;- xout[1:m,] + 10      # bad leverage points


fit1 &lt;- enetLTS(xout,yout,crit.plot=FALSE)
plotDiagnostic.enetLTS(fit1)
plotDiagnostic.enetLTS(fit1,vers="raw")

## for binomial

eps &lt;-0.05                                     # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
y &lt;- sample(0:1,n,replace=TRUE)
xout &lt;- x
xout[y==0,][1:m,] &lt;- xout[1:m,] + 10;          # class 0
yout &lt;- y                                      # wrong classification for vertical outliers


fit2 &lt;- enetLTS(xout,yout,family="binomial",crit.plot=FALSE)
plotDiagnostic.enetLTS(fit2)
plotDiagnostic.enetLTS(fit2,vers="raw")


## for multinomial

n &lt;- 120; p &lt;- 15
NC &lt;- 3
X &lt;- matrix(rnorm(n * p), n, p)
betas &lt;- matrix(1:NC, ncol=NC, nrow=p, byrow=TRUE)
betas[(p-5):p,]=0; betas &lt;- rbind(rep(0,NC),betas)
lv &lt;- cbind(1,X) %*% betas
probs &lt;- exp(lv)/apply(exp(lv),1,sum)
y &lt;- apply(probs,1,function(prob){sample(1:NC, 1, TRUE, prob)})
xout &lt;- X
eps &lt;-0.05                          # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
xout[1:m,] &lt;- xout[1:m,] + 10       # bad leverage points
yout &lt;- y


fit3 &lt;- enetLTS(xout,yout,family="multinomial",crit.plot=FALSE)
plotDiagnostic.enetLTS(fit3)
plotDiagnostic.enetLTS(fit3,vers="raw")

</code></pre>

<hr>
<h2 id='plotResid.enetLTS'>
residuals plots from the <code>"enetLTS"</code> object
</h2><span id='topic+plotResid.enetLTS'></span>

<h3>Description</h3>

<p>Produce plots for the residuals of the current model. Residuals corresponds to deviances for <code>family="multinomial"</code> and <code>family="binomial"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotResid.enetLTS(object,vers=c("reweighted","raw"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotResid.enetLTS_+3A_object">object</code></td>
<td>
<p>the model fit to be plotted.</p>
</td></tr>
<tr><td><code id="plotResid.enetLTS_+3A_vers">vers</code></td>
<td>
<p>a character string denoting which model to use for the plots.
Possible values are <code>"reweighted"</code> (the default) for
plots from the reweighted fit, and <code>"raw"</code> for
plots from the raw fit.</p>
</td></tr>
<tr><td><code id="plotResid.enetLTS_+3A_...">...</code></td>
<td>
<p>additional arguments from the <code>enetLTS</code> object if needed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"ggplot"</code> (see <code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>).
</p>


<h3>Note</h3>

<p>gives the plot of
- residuals vs indices. (for <code>family="gaussian"</code>).
</p>
<p>- deviances vs indices. (for both <code>family="multinomial"</code> and <code>family="binomial"</code>).
</p>
<p>- additionally, residuals vs fitted values/link function (for <code>family="binomial"</code> and <code>family="gaussian"</code>).
</p>


<h3>Author(s)</h3>

<p>Fatma Sevinc KURNAZ, Irene HOFFMANN, Peter FILZMOSER
<br /> Maintainer: Fatma Sevinc KURNAZ &lt;fatmasevincskurnaz@gmail.com&gt;;&lt;fskurnaz@yildiz.edu.tr&gt;</p>


<h3>References</h3>

<p>Kurnaz, F.S., Hoffmann, I. and Filzmoser, P. (2017) Robust and sparse
estimation methods for high dimensional linear and logistic regression.
<em>Chemometrics and Intelligent Laboratory Systems</em>.
</p>


<h3>See Also</h3>

<p><code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>,
<code><a href="#topic+enetLTS">enetLTS</a></code>,
<code><a href="#topic+predict.enetLTS">predict.enetLTS</a></code>,
<code><a href="#topic+residuals.enetLTS">residuals.enetLTS</a></code>,
<code><a href="#topic+fitted.enetLTS">fitted.enetLTS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## for gaussian

set.seed(86)
n &lt;- 100; p &lt;- 25                             # number of observations and variables
beta &lt;- rep(0,p); beta[1:6] &lt;- 1              # 10% nonzero coefficients
sigma &lt;- 0.5                                  # controls signal-to-noise ratio
x &lt;- matrix(rnorm(n*p, sigma),nrow=n)
e &lt;- rnorm(n,0,1)                             # error terms
eps &lt;- 0.1                                    # contamination level
m &lt;- ceiling(eps*n)                           # observations to be contaminated
eout &lt;- e; eout[1:m] &lt;- eout[1:m] + 10        # vertical outliers
yout &lt;- c(x %*% beta + sigma * eout)        # response
xout &lt;- x; xout[1:m,] &lt;- xout[1:m,] + 10      # bad leverage points


fit1 &lt;- enetLTS(xout,yout)
plotResid.enetLTS(fit1)
plotResid.enetLTS(fit1,vers="raw")

## for binomial

eps &lt;-0.05                                     # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
y &lt;- sample(0:1,n,replace=TRUE)
xout &lt;- x
xout[y==0,][1:m,] &lt;- xout[1:m,] + 10;          # class 0
yout &lt;- y                                      # wrong classification for vertical outliers


fit2 &lt;- enetLTS(xout,yout,family="binomial",crit.plot=FALSE)
plotResid.enetLTS(fit2)
plotResid.enetLTS(fit2,vers="raw")


## for multinomial

n &lt;- 120; p &lt;- 15
NC &lt;- 3
X &lt;- matrix(rnorm(n * p), n, p)
betas &lt;- matrix(1:NC, ncol=NC, nrow=p, byrow=TRUE)
betas[(p-5):p,]=0; betas &lt;- rbind(rep(0,NC),betas)
lv &lt;- cbind(1,X) %*% betas
probs &lt;- exp(lv)/apply(exp(lv),1,sum)
y &lt;- apply(probs,1,function(prob){sample(1:NC, 1, TRUE, prob)})
xout &lt;- X
eps &lt;-0.05                          # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
xout[1:m,] &lt;- xout[1:m,] + 10       # bad leverage points
yout &lt;- y


fit3 &lt;- enetLTS(xout,yout,family="multinomial")
plotResid.enetLTS(fit3)
plotResid.enetLTS(fit3,vers="raw")

</code></pre>

<hr>
<h2 id='predict.enetLTS'>
make predictions from the <code>"enetLTS"</code> object.
</h2><span id='topic+predict.enetLTS'></span>

<h3>Description</h3>

<p>Similar to other predict methods, this function predicts fitted values, logits,
coefficients and nonzero coefficients from a fitted <code>"enetLTS"</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'enetLTS'
predict(object,newX,vers=c("reweighted","raw"),
    type=c("link","response","coefficients","nonzero","class"),...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.enetLTS_+3A_object">object</code></td>
<td>
<p>the model fit from which to make predictions.</p>
</td></tr>
<tr><td><code id="predict.enetLTS_+3A_newx">newX</code></td>
<td>
<p>new values for the predictor matrix <code>X</code>.
Must be a matrix; can be sparse as in <code>Matrix</code> package.
This argument is not used for <code>type=c("coefficients","nonzero")</code>.</p>
</td></tr>
<tr><td><code id="predict.enetLTS_+3A_vers">vers</code></td>
<td>
<p>a character string denoting which fit to use for the predictions.
Possible values are <code>"reweighted"</code> (the default) for
predicting values from the reweighted fit, <code>"raw"</code> for predicting
values from the raw fit.</p>
</td></tr>
<tr><td><code id="predict.enetLTS_+3A_type">type</code></td>
<td>
<p>type of prediction required. <code>type="link"</code> gives the link function.
<code>type="response"</code> gives the
fitted probabilities for <code>"binomial"</code> and gives the fitted values for
<code>"gaussian"</code>. <code>type="coefficients"</code> computes the coefficients from the
fitted model. <code>type="nonzero"</code> returns a list of the indices of the nonzero
coefficients. <code>type="class"</code> is available only for <code>"binomial"</code> model,
and produces the class label corresponding to the maximum probability.</p>
</td></tr>
<tr><td><code id="predict.enetLTS_+3A_...">...</code></td>
<td>
<p>additional arguments from the <code>enetLTS</code> object if needed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>newdata</code> argument defaults to the matrix of predictors used to fit
the model such that the fitted values are computed.
</p>
<p><code>coef.enetLTS(...)</code> is equivalent to <code>predict.enetLTS(object,newX,type="coefficients",...)</code>, where newX argument is the matrix as in <code>enetLTS</code>.
</p>


<h3>Value</h3>

<p>The requested predicted values are returned.
</p>


<h3>Author(s)</h3>

<p>Fatma Sevinc KURNAZ, Irene HOFFMANN, Peter FILZMOSER
<br /> Maintainer: Fatma Sevinc KURNAZ &lt;fatmasevinckurnaz@gmail.com&gt;;&lt;fskurnaz@yildiz.edu.tr&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+enetLTS">enetLTS</a></code>,
<code><a href="#topic+coef.enetLTS">coef.enetLTS</a></code>,
<code><a href="#topic+nonzeroCoef.enetLTS">nonzeroCoef.enetLTS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## for gaussian

set.seed(86)
n &lt;- 100; p &lt;- 25                             # number of observations and variables
beta &lt;- rep(0,p); beta[1:6] &lt;- 1              # 10% nonzero coefficients
sigma &lt;- 0.5                                  # controls signal-to-noise ratio
x &lt;- matrix(rnorm(n*p, sigma),nrow=n)
e &lt;- rnorm(n,0,1)                             # error terms
eps &lt;- 0.1                                    # contamination level
m &lt;- ceiling(eps*n)                           # observations to be contaminated
eout &lt;- e; eout[1:m] &lt;- eout[1:m] + 10        # vertical outliers
yout &lt;- c(x %*% beta + sigma * eout)        # response
xout &lt;- x; xout[1:m,] &lt;- xout[1:m,] + 10      # bad leverage points


fit1 &lt;- enetLTS(xout,yout)
predict(fit1,newX=xout)
predict(fit1,newX=xout,type="coefficients")
predict(fit1,newX=xout,type="nonzero",vers="raw")
# provide new X matrix
newX &lt;- matrix(rnorm(n*p, sigma),nrow=n)
predict(fit1,newX=newX,type="response")
predict(fit1,newX=newX,type="coefficients")
predict(fit1,newX=newX,type="nonzero")

## for binomial

eps &lt;-0.05                                     # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
y &lt;- sample(0:1,n,replace=TRUE)
xout &lt;- x
xout[y==0,][1:m,] &lt;- xout[1:m,] + 10;          # class 0
yout &lt;- y                                      # wrong classification for vertical outliers


fit2 &lt;- enetLTS(xout,yout,family="binomial")
predict(fit2,newX=xout)
predict(fit2,newX=xout,type="coefficients")
predict(fit2,newX=xout,type="nonzero",vers="raw")
predict(fit2,newX=newX,type="response")
predict(fit2,newX=newX,type="class")
predict(fit2,newX=newX,type="coefficients",vers="raw")
predict(fit2,newX=newX,type="nonzero")



## for multinomial

n &lt;- 120; p &lt;- 15
NC &lt;- 3
X &lt;- matrix(rnorm(n * p), n, p)
betas &lt;- matrix(1:NC, ncol=NC, nrow=p, byrow=TRUE)
betas[(p-5):p,]=0; betas &lt;- rbind(rep(0,NC),betas)
lv &lt;- cbind(1,X) %*% betas
probs &lt;- exp(lv)/apply(exp(lv),1,sum)
y &lt;- apply(probs,1,function(prob){sample(1:NC, 1, TRUE, prob)})
xout &lt;- X
eps &lt;-0.05                          # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
xout[1:m,] &lt;- xout[1:m,] + 10       # bad leverage points
yout &lt;- y


fit3    &lt;- enetLTS(xout,yout,family="multinomial")
predict(fit3,newX=xout)
predict(fit3,newX=xout,type="coefficients")
predict(fit3,newX=xout,type="nonzero",vers="raw")
predict(fit3,newX=xout,type="response")
predict(fit3,newX=xout,type="class")
predict(fit3,newX=xout,type="coefficients",vers="raw")
predict(fit3,newX=xout,type="nonzero")

</code></pre>

<hr>
<h2 id='print.enetLTS'>
print from the <code>"enetLTS"</code> object
</h2><span id='topic+print.enetLTS'></span>

<h3>Description</h3>

<p>Print a summary of the <code>enetLTS</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'enetLTS'
print(x,vers=c("reweighted","raw"),...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.enetLTS_+3A_x">x</code></td>
<td>
<p>fitted <code>enetLTS</code> object</p>
</td></tr>
<tr><td><code id="print.enetLTS_+3A_vers">vers</code></td>
<td>
<p>a character string specifying for which fit to make
predictions.  Possible values are <code>"reweighted"</code> (the default) for
predicting values from the reweighted fit, <code>"raw"</code> for predicting
values from the raw fit.</p>
</td></tr>
<tr><td><code id="print.enetLTS_+3A_...">...</code></td>
<td>
<p>additional arguments from the <code>enetLTS</code> object if needed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The call that produced the <code>enetLTS</code> object is printed, followed by
the coefficients, the number of nonzero coefficients and penalty parameters.
</p>


<h3>Value</h3>

<p>The produced object, the coefficients, the number of nonzero coefficients and penalty parameters are returned.
</p>


<h3>Author(s)</h3>

<p>Fatma Sevinc KURNAZ, Irene HOFFMANN, Peter FILZMOSER
<br /> Maintainer: Fatma Sevinc KURNAZ &lt;fatmasevinckurnaz@gmail.com&gt;;&lt;fskurnaz@yildiz.edu.tr&gt;</p>


<h3>See Also</h3>

<p><code>enetLTS</code>,
<code>predict.enetLTS</code>,
<code>coef.enetLTS</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## for gaussian

set.seed(86)
n &lt;- 100; p &lt;- 25                             # number of observations and variables
beta &lt;- rep(0,p); beta[1:6] &lt;- 1              # 10% nonzero coefficients
sigma &lt;- 0.5                                  # controls signal-to-noise ratio
x &lt;- matrix(rnorm(n*p, sigma),nrow=n)
e &lt;- rnorm(n,0,1)                             # error terms
eps &lt;- 0.1                                    # contamination level
m &lt;- ceiling(eps*n)                           # observations to be contaminated
eout &lt;- e; eout[1:m] &lt;- eout[1:m] + 10        # vertical outliers
yout &lt;- c(x %*% beta + sigma * eout)        # response
xout &lt;- x; xout[1:m,] &lt;- xout[1:m,] + 10      # bad leverage points


fit1 &lt;- enetLTS(xout,yout)
print(fit1)
print(fit1,vers="raw")


## for binomial

eps &lt;-0.05                                     # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
y &lt;- sample(0:1,n,replace=TRUE)
xout &lt;- x
xout[y==0,][1:m,] &lt;- xout[1:m,] + 10;          # class 0
yout &lt;- y                                      # wrong classification for vertical outliers



fit2 &lt;- enetLTS(xout,yout,family="binomial")
print(fit2)
print(fit2,vers="raw")


## for multinomial

n &lt;- 120; p &lt;- 15
NC &lt;- 3
X &lt;- matrix(rnorm(n * p), n, p)
betas &lt;- matrix(1:NC, ncol=NC, nrow=p, byrow=TRUE)
betas[(p-5):p,]=0; betas &lt;- rbind(rep(0,NC),betas)
lv &lt;- cbind(1,X) %*% betas
probs &lt;- exp(lv)/apply(exp(lv),1,sum)
y &lt;- apply(probs,1,function(prob){sample(1:NC, 1, TRUE, prob)})
xout &lt;- X
eps &lt;-0.05                          # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
xout[1:m,] &lt;- xout[1:m,] + 10       # bad leverage points
yout &lt;- y


fit3    &lt;- enetLTS(xout,yout,family="multinomial")
print(fit3)
print(fit3,vers="raw")

</code></pre>

<hr>
<h2 id='residuals.enetLTS'>
the residuals from the <code>"enetLTS"</code> object
</h2><span id='topic+residuals.enetLTS'></span>

<h3>Description</h3>

<p>A numeric vector which returns residuals from the enetLTS object.  Residuals
correspond to deviances if <code>family="multinomial"</code> and <code>family="binomial"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'enetLTS'
residuals(object,vers=c("reweighted","raw","both"),...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residuals.enetLTS_+3A_object">object</code></td>
<td>
<p>the model fit from which to extract residuals.</p>
</td></tr>
<tr><td><code id="residuals.enetLTS_+3A_vers">vers</code></td>
<td>
<p>a character string specifying for which estimator to extract
outlier weights. Possible values are <code>"reweighted"</code> (the default) for
weights indicating outliers from the reweighted fit, <code>"raw"</code> for
weights indicating outliers from the raw fit, or <code>"both"</code> for the
outlier weights from both estimators.</p>
</td></tr>
<tr><td><code id="residuals.enetLTS_+3A_...">...</code></td>
<td>
<p>additional arguments from the enetLTS object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the requested residuals.
</p>


<h3>Author(s)</h3>

<p>Fatma Sevinc KURNAZ, Irene HOFFMANN, Peter FILZMOSER
<br /> Maintainer: Fatma Sevinc KURNAZ &lt;fatmasevinckurnaz@gmail.com&gt;;&lt;fskurnaz@yildiz.edu.tr&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+enetLTS">enetLTS</a></code>,
<code><a href="#topic+fitted.enetLTS">fitted.enetLTS</a></code>,
<code><a href="#topic+predict.enetLTS">predict.enetLTS</a></code>,
<code><a href="#topic+coef.enetLTS">coef.enetLTS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## for gaussian

set.seed(86)
n &lt;- 100; p &lt;- 25                             # number of observations and variables
beta &lt;- rep(0,p); beta[1:6] &lt;- 1              # 10% nonzero coefficients
sigma &lt;- 0.5                                  # controls signal-to-noise ratio
x &lt;- matrix(rnorm(n*p, sigma),nrow=n)
e &lt;- rnorm(n,0,1)                             # error terms
eps &lt;- 0.1                                    # contamination level
m &lt;- ceiling(eps*n)                           # observations to be contaminated
eout &lt;- e; eout[1:m] &lt;- eout[1:m] + 10        # vertical outliers
yout &lt;- c(x %*% beta + sigma * eout)        # response
xout &lt;- x; xout[1:m,] &lt;- xout[1:m,] + 10      # bad leverage points


fit1 &lt;- enetLTS(xout,yout)
residuals(fit1)
residuals(fit1,vers="raw")
residuals(fit1,vers="both")


## for binomial

eps &lt;-0.05                                    # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
y &lt;- sample(0:1,n,replace=TRUE)
xout &lt;- x
xout[y==0,][1:m,] &lt;- xout[1:m,] + 10;         # class 0
yout &lt;- y                                     # wrong classification for vertical outliers



fit2 &lt;- enetLTS(xout,yout,family="binomial")
residuals(fit2)
residuals(fit2,vers="raw")
residuals(fit2,vers="both")



## for multinomial

n &lt;- 120; p &lt;- 15
NC &lt;- 3
X &lt;- matrix(rnorm(n * p), n, p)
betas &lt;- matrix(1:NC, ncol=NC, nrow=p, byrow=TRUE)
betas[(p-5):p,]=0; betas &lt;- rbind(rep(0,NC),betas)
lv &lt;- cbind(1,X) %*% betas
probs &lt;- exp(lv)/apply(exp(lv),1,sum)
y &lt;- apply(probs,1,function(prob){sample(1:NC, 1, TRUE, prob)})
xout &lt;- X
eps &lt;-0.05                          # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
xout[1:m,] &lt;- xout[1:m,] + 10       # bad leverage points
yout &lt;- y


fit3    &lt;- enetLTS(xout,yout,family="multinomial")
residuals(fit3)
residuals(fit3,vers="raw")
residuals(fit3,vers="both")

</code></pre>

<hr>
<h2 id='weights.enetLTS'>
binary weights from the <code>"enetLTS"</code> object
</h2><span id='topic+weights.enetLTS'></span>

<h3>Description</h3>

<p>Extract binary weights that indicate outliers from the current model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'enetLTS'
weights(object,vers=c("reweighted","raw","both"),index=FALSE,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weights.enetLTS_+3A_object">object</code></td>
<td>
<p>the model fit from which to extract outlier weights.</p>
</td></tr>
<tr><td><code id="weights.enetLTS_+3A_vers">vers</code></td>
<td>
<p>a character string specifying for which estimator to extract
outlier weights. Possible values are <code>"reweighted"</code> (the default) for
weights indicating outliers from the reweighted fit, <code>"raw"</code> for
weights indicating outliers from the raw fit, or <code>"both"</code> for the
outlier weights from both estimators.</p>
</td></tr>
<tr><td><code id="weights.enetLTS_+3A_index">index</code></td>
<td>
<p>a logical indicating whether the indices of the weight vector should
be included or not (the default is <code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="weights.enetLTS_+3A_...">...</code></td>
<td>
<p>additional arguments from the <code>enetLTS</code> object if needed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the requested outlier weights.
</p>


<h3>Note</h3>

<p>The weights are <code class="reqn">1</code> for observations with reasonably small
residuals and <code class="reqn">0</code> for observations with large residuals.
Here, residuals represent standardized residuals
for <code>family="gaussian"</code>, Pearson residuals for
<code>family="binomial"</code> and group-wise scaled robust distances
<code>family="multinomial"</code>.
</p>
<p>Use weights with or without index is available.
</p>


<h3>Author(s)</h3>

<p>Fatma Sevinc KURNAZ, Irene HOFFMANN, Peter FILZMOSER
<br /> Maintainer: Fatma Sevinc KURNAZ &lt;fatmasevinckurnaz@gmail.com&gt;;&lt;fskurnaz@yildiz.edu.tr&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+enetLTS">enetLTS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## for gaussian

set.seed(86)
n &lt;- 100; p &lt;- 25                             # number of observations and variables
beta &lt;- rep(0,p); beta[1:6] &lt;- 1              # 10% nonzero coefficients
sigma &lt;- 0.5                                  # controls signal-to-noise ratio
x &lt;- matrix(rnorm(n*p, sigma),nrow=n)
e &lt;- rnorm(n,0,1)                             # error terms
eps &lt;- 0.1                                    # contamination level
m &lt;- ceiling(eps*n)                           # observations to be contaminated
eout &lt;- e; eout[1:m] &lt;- eout[1:m] + 10        # vertical outliers
yout &lt;- c(x %*% beta + sigma * eout)        # response
xout &lt;- x; xout[1:m,] &lt;- xout[1:m,] + 10      # bad leverage points


fit1 &lt;- enetLTS(xout,yout)
weights(fit1)
weights(fit1,vers="raw",index=TRUE)
weights(fit1,vers="both",index=TRUE)


## for binomial

eps &lt;-0.05                                     # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
y &lt;- sample(0:1,n,replace=TRUE)
xout &lt;- x
xout[y==0,][1:m,] &lt;- xout[1:m,] + 10;          # class 0
yout &lt;- y                                      # wrong classification for vertical outliers


fit2 &lt;- enetLTS(xout,yout,family="binomial")
weights(fit2)
weights(fit2,vers="raw",index=TRUE)
weights(fit2,vers="both",index=TRUE)


## for multinomial

n &lt;- 120; p &lt;- 15
NC &lt;- 3
X &lt;- matrix(rnorm(n * p), n, p)
betas &lt;- matrix(1:NC, ncol=NC, nrow=p, byrow=TRUE)
betas[(p-5):p,]=0; betas &lt;- rbind(rep(0,NC),betas)
lv &lt;- cbind(1,X) %*% betas
probs &lt;- exp(lv)/apply(exp(lv),1,sum)
y &lt;- apply(probs,1,function(prob){sample(1:NC, 1, TRUE, prob)})
xout &lt;- X
eps &lt;-0.05                          # %10 contamination to only class 0
m &lt;- ceiling(eps*n)
xout[1:m,] &lt;- xout[1:m,] + 10       # bad leverage points
yout &lt;- y


fit3    &lt;- enetLTS(xout,yout,family="multinomial")
weights(fit3)
weights(fit3,vers="raw",index=TRUE)
weights(fit3,vers="both",index=TRUE)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
