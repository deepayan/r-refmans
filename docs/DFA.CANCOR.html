<!DOCTYPE html><html><head><title>Help for package DFA.CANCOR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {DFA.CANCOR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#CANCOR'><p>Canonical correlation analysis</p></a></li>
<li><a href='#data_CANCOR'><p>data_CANCOR</p></a></li>
<li><a href='#data_DFA'><p>data_DFA</p></a></li>
<li><a href='#DFA'><p>Discriminant function analysis</p></a></li>
<li><a href='#DFA.CANCOR-package'><p>DFA.CANCOR</p></a></li>
<li><a href='#GROUP.DIFFS'><p>Group Mean Differences on a Continuous Outcome Variable</p></a></li>
<li><a href='#HOMOGENEITY'><p>Homogeneity of variances and covariances</p></a></li>
<li><a href='#LINEARITY'><p>Linearity</p></a></li>
<li><a href='#NORMALITY'><p>Univariate and multivariate normality</p></a></li>
<li><a href='#PLOT_LINEARITY'><p>Plot for linearity</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Linear Discriminant Function and Canonical Correlation Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.8</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-06-28</td>
</tr>
<tr>
<td>Author:</td>
<td>Brian P. O'Connor </td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Brian P. O'Connor  &lt;brian.oconnor@ubc.ca&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>
  Produces SPSS- and SAS-like output for linear discriminant 
  function analysis and canonical correlation analysis. The methods are described in
  Manly &amp; Alberto (2017, ISBN:9781498728966),
  Rencher (2002, ISBN:0-471-41889-7), and
  Tabachnik &amp; Fidell (2019, ISBN:9780134790541).</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, stats, BayesFactor, MVN, utils</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-06-28 09:59:16 UTC; brianoconnor</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-06-29 14:50:12 UTC</td>
</tr>
</table>
<hr>
<h2 id='CANCOR'>Canonical correlation analysis</h2><span id='topic+CANCOR'></span>

<h3>Description</h3>

<p>Produces SPSS- and SAS-like output for canonical 
correlation analysis. Portions of the code were adapted from James Steiger (www.statpower.net).</p>


<h3>Usage</h3>

<pre><code class='language-R'>CANCOR(data, set1, set2, plot, plotCV, plotcoefs, verbose)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CANCOR_+3A_data">data</code></td>
<td>

<p>A dataframe where the rows are cases &amp; the columns are the variables.</p>
</td></tr>
<tr><td><code id="CANCOR_+3A_set1">set1</code></td>
<td>

<p>The names of the continuous variables for the first set,
<br /> e.g., set1 = c('varA', 'varB', 'varC').</p>
</td></tr>
<tr><td><code id="CANCOR_+3A_set2">set2</code></td>
<td>

<p>The names of the continuous variables for the second set,
<br /> e.g., set2 = c('varD', 'varE', 'varF').</p>
</td></tr>
<tr><td><code id="CANCOR_+3A_plot">plot</code></td>
<td>

<p>Should a plot of the coefficients be produced? <br /> The options are: TRUE (default) or FALSE.</p>
</td></tr>
<tr><td><code id="CANCOR_+3A_plotcv">plotCV</code></td>
<td>

<p>The canonical variate number for the plot, e.g., plotCV = 1.</p>
</td></tr>
<tr><td><code id="CANCOR_+3A_plotcoefs">plotcoefs</code></td>
<td>

<p>The coefficient for the plots. <br /> The options are 'structure' (default) or 'standardized'.</p>
</td></tr>
<tr><td><code id="CANCOR_+3A_verbose">verbose</code></td>
<td>

<p>Should detailed results be displayed in the console? <br /> The options are: TRUE (default) or FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If verbose = TRUE, the displayed output includes Pearson correlations, multivariate significance
tests, canonical function correlations and bivariate significance tests, raw canonical 
coefficients, structure coefficients, standardized coefficients, and a bar plot  
of the structure or standardized coefficients.
</p>
<p>The returned output is a list with elements
</p>
<table>
<tr><td><code>cancorrels</code></td>
<td>
<p>canonical correlations and their significance tests</p>
</td></tr>
<tr><td><code>mv_Wilks</code></td>
<td>
<p>The Wilks' lambda multivariate test</p>
</td></tr>
<tr><td><code>mv_Pillai</code></td>
<td>
<p>The Pillai-Bartlett multivariate test</p>
</td></tr>
<tr><td><code>mv_Hotelling</code></td>
<td>
<p>The Lawley-Hotelling multivariate test</p>
</td></tr>
<tr><td><code>mv_Roy</code></td>
<td>
<p>Roy's greatest characteristic root multivariate test</p>
</td></tr>
<tr><td><code>mv_BartlettV</code></td>
<td>
<p>Bartlett's V multivariate significance test</p>
</td></tr>
<tr><td><code>mv_Rao</code></td>
<td>
<p>Rao's' multivariate significance test</p>
</td></tr> 
<tr><td><code>CoefRawSet1</code></td>
<td>
<p>raw canonical coefficients for Set 1</p>
</td></tr>
<tr><td><code>CoefRawSet2</code></td>
<td>
<p>raw canonical coefficients for Set 2</p>
</td></tr>
<tr><td><code>CoefStruct11</code></td>
<td>
<p>structure coefficients for Set 1 variables with the Set 1 variates</p>
</td></tr>
<tr><td><code>CoefStruct21</code></td>
<td>
<p>structure coefficients for Set 2 variables with the Set 1 variates</p>
</td></tr>
<tr><td><code>CoefStruct12</code></td>
<td>
<p>structure coefficients for Set 1 variables with the Set 2 variates</p>
</td></tr>
<tr><td><code>CoefStruct22</code></td>
<td>
<p>structure coefficients for Set 2 variables with the Set 2 variates</p>
</td></tr>
<tr><td><code>CoefStandSet1</code></td>
<td>
<p>standardized coefficients for Set 1 variables</p>
</td></tr>
<tr><td><code>CoefStandSet2</code></td>
<td>
<p>standardized coefficients for Set 2 variables</p>
</td></tr>
<tr><td><code>CorrelSet1</code></td>
<td>
<p>Pearson correlations for Set 1</p>
</td></tr>
<tr><td><code>CorrelSet2</code></td>
<td>
<p>Pearson correlations for Set 2</p>
</td></tr>
<tr><td><code>CorrelSet1n2</code></td>
<td>
<p>Pearson correlations between Set 1 &amp; Set 2</p>
</td></tr>
<tr><td><code>set1_scores</code></td>
<td>
<p>Canonical variate scores for Set 1</p>
</td></tr>
<tr><td><code>set2_scores</code></td>
<td>
<p>Canonical variate scores for Set 2</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Brian P. O'Connor </p>


<h3>References</h3>

<p>Manly, B. F. J., &amp; Alberto, J. A. (2017). <em>Multivariate statistical methods: 
A primer (4th Edition).</em> Chapman &amp; Hall/CRC, Boca Raton, FL.
<br /><br /> Rencher, A. C. (2002). <em>Methods of Multivariate Analysis</em> (2nd ed.). New York, NY: John Wiley &amp; Sons.
<br /><br /> Sherry, A., &amp; Henson, R. K. (2005). Conducting and interpreting canonical correlation analysis
in personality research: A user-friendly primer. <em>Journal of Personality Assessment, 84,</em> 37-48.
<br /><br /> Steiger, J. (2019). <em>Canonical correlation analysis.</em>
<br />www.statpower.net/Content/312/Lecture%20Slides/CanonicalCorrelation.pdf
<br /><br /> Tabachnik, B. G., &amp; Fidell, L. S. (2019). <em>Using multivariate statistics (7th ed.).</em> New York, NY: Pearson.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># data that simulate those from De Leo &amp; Wulfert (2013)
CANCOR(data = data_CANCOR$DeLeo_2013,
       set1 = c('Tobacco_Use','Alcohol_Use','Illicit_Drug_Use','Gambling_Behavior',
                'Unprotected_Sex','CIAS_Total'),
       set2 = c('Impulsivity','Social_Interaction_Anxiety','Depression',
                'Social_Support','Intolerance_of_Deviance','Family_Morals',
                'Family_Conflict','Grade_Point_Average'),
       plot = TRUE, plotCV = 1, plotcoefs='structure',
       verbose = TRUE)


	
# data from Ho (2014, Chapter 17)
CANCOR(data = data_CANCOR$Ho_2014,
       set1 = c("willing_use","likely_use","intend_use","certain_use"),
       set2 = c("perceived_risk","perceived_severity","self_efficacy",
                "response_efficacy","maladaptive_coping","fear"),
       plot = 'yes', plotCV = 1)

	
# data from Rencher (2002, pp. 366, 369, 372)
CANCOR(data = data_CANCOR$Rencher_2002,
       set1 = c("y1","y2","y3"),
       set2 = c("x1","x2","x3","x1x2","x1x3","x2x3","x1sq","x2sq","x3sq"),
       plot = 'yes', plotCV = 1)


# data from Tabachnik &amp; Fidell (2019, p. 451, 460)    small dataset
CANCOR(data = data_CANCOR$TabFid_2019_small,
       set1 = c('TS','TC'),
       set2 = c('BS','BC'),
       plot = TRUE, plotCV = 1, plotcoefs='structure',
       verbose = TRUE)


# data from Tabachnik &amp; Fidell (2019, p. 463)     complete dataset
CANCOR(data = data_CANCOR$TabFid_2019_complete,
       set1 = c("esteem","control","attmar","attrole"),
       set2 = c("timedrs","attdrug","phyheal","menheal","druguse"),
       plot = TRUE, plotCV = 1, plotcoefs='structure',
       verbose = TRUE)


# UCLA dataset   https://stats.oarc.ucla.edu/r/dae/canonical-correlation-analysis/
CANCOR(data = data_CANCOR$UCLA, 
       set1 = c("Locus_Control","Self_Concept","Motivation"),
       set2 = c("Read","Write","Math","Science","Sex"),
       plot = TRUE, plotCV = 1, plotcoefs='standardized',
       verbose = TRUE)


</code></pre>

<hr>
<h2 id='data_CANCOR'>data_CANCOR</h2><span id='topic+data_CANCOR'></span>

<h3>Description</h3>

<p>A list with example data that were used in various
presentations of canonical correlation analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_CANCOR)</code></pre>


<h3>Details</h3>

<p>A list with the example data that were used in the following presentations 
of canonical correlation analysis: De Leo and Wulfert (2013), Ho (2014), 
Rencher (2002), Tabachnick and Fidell (2019), and by the UCLA statistics tutorial 
at https://stats.oarc.ucla.edu/r/dae/canonical-correlation-analysis/.
</p>


<h3>References</h3>

<p>De Leo, J. A., &amp; Wulfert, E. (2013). Problematic internet use and other risky 
behaviors in college students: An application of problem-behavior theory. <em>Psychology 
of Addictive Behaviors, 27(1),</em> 133-141. 
<br /><br /> Ho, R. (2014). <em>Handbook of univariate and multivariate data analysis with 
IBM SPSS.</em> Boca Raton, FL: CRC Press.
<br /><br /> Rencher, A. (2002). <em>Methods of multivariate analysis</em> (2nd ed.). 
New York, NY: John Wiley &amp; Sons.
<br /><br /> Tabachnick, B. G., &amp; Fidell, L. S. (2019). Chapter 16: Multiway 
frequency analysis. <em>Using multivariate statistics.</em> New York, NY: Pearson.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>names(data_CANCOR)
 
head(data_CANCOR$DeLeo_2013)

head(data_CANCOR$Ho_2014)

head(data_CANCOR$Rencher_2002)

head(data_CANCOR$TabFid_2019_small)

head(data_CANCOR$TabFid_2019_complete)

</code></pre>

<hr>
<h2 id='data_DFA'>data_DFA</h2><span id='topic+data_DFA'></span>

<h3>Description</h3>

<p>A list with example data that were used in various
presentations of discrimination function analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_DFA)</code></pre>


<h3>Details</h3>

<p>A list with the example data that were used in the following presentations 
of discrimination function analysis: Field (2012), Green and Salkind (2008), 
Ho (2014), Huberty and Olejnik (2006), Noursis (2012), Rencher (2002), Sherry (2006), and
Tabachnick and Fidell (2019).
</p>


<h3>References</h3>

<p>Field, A., Miles, J., &amp; Field, Z. (2012). Chapter 18 Categorical data. 
<em>Discovering statistics using R.</em> Los Angeles, CA: Sage.
<br /><br /> Green, S. B., &amp; Salkind, N. J. (2008). Lesson 35: Discriminant analysis
(pp. 300-311). In, <em>Using SPSS for Windows and Macintosh: Analyzing and 
understanding data.</em> New York, NY: Pearson.
<br /><br /> Ho, R. (2014). <em>Handbook of univariate and multivariate data analysis with 
IBM SPSS.</em> Boca Raton, FL: CRC Press.
<br /><br /> Huberty, C. J., &amp; Olejnik, S. (2019). <em>Applied MANOVA and discriminant 
analysis</em> (2nd. ed.). New York, NY: John Wiley &amp; Sons.
<br /><br /> Noursis, M. J. (2012). <em>IBM SPSS Statistics 19 advanced statistical 
procedures companion.</em> Upper Saddle River, NJ: Prentice Hall.
<br /><br /> Rencher, A. (2002). <em>Methods of multivariate analysis</em> (2nd ed.). 
New York, NY: John Wiley &amp; Sons.
<br /><br /> Sherry, A. (2006). Discriminant analysis in counseling research.
<em>Counseling Psychologist, 34,</em> 661-683.
<br /><br /> Tabachnick, B. G., &amp; Fidell, L. S. (2019). Chapter 16: Multiway 
frequency analysis. <em>Using multivariate statistics.</em> New York, NY: Pearson.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>names(data_DFA)
 
head(data_DFA$Field_2012)

head(data_DFA$Green_2008)

head(data_DFA$Ho_2014)

head(data_DFA$Huberty_2019_p45)

head(data_DFA$Huberty_2019_p285)

head(data_DFA$Norusis_2012)

head(data_DFA$Rencher_2002_football)

head(data_DFA$Rencher_2002_root)

head(data_DFA$Sherry_2006)

head(data_DFA$TabFid_2019_complete)

head(data_DFA$TabFid_2019_small)

</code></pre>

<hr>
<h2 id='DFA'>Discriminant function analysis</h2><span id='topic+DFA'></span>

<h3>Description</h3>

<p>Produces SPSS- and SAS-like output for linear discriminant function analysis.</p>


<h3>Usage</h3>

<pre><code class='language-R'>DFA(data, groups, variables, plot, predictive, priorprob, covmat_type, CV, verbose)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DFA_+3A_data">data</code></td>
<td>

<p>A dataframe where the rows are cases &amp; the columns are the variables.</p>
</td></tr>
<tr><td><code id="DFA_+3A_groups">groups</code></td>
<td>

<p>The name of the groups variable in the dataframe, <br /> e.g., groups = 'Group'.</p>
</td></tr>
<tr><td><code id="DFA_+3A_variables">variables</code></td>
<td>
 
<p>The names of the continuous variables in the dataframe that will be used in the DFA, 
e.g., variables = c('varA', 'varB', 'varC').</p>
</td></tr>
<tr><td><code id="DFA_+3A_plot">plot</code></td>
<td>
 
<p>Should a plot of the mean standardized discriminant function scores  
<br /> for the groups be produced? The options are: TRUE (default) or FALSE.</p>
</td></tr>
<tr><td><code id="DFA_+3A_predictive">predictive</code></td>
<td>

<p>Should a predictive DFA be conducted? <br /> The options are: TRUE (default) or FALSE.</p>
</td></tr>
<tr><td><code id="DFA_+3A_priorprob">priorprob</code></td>
<td>

<p>If predictive = TRUE, how should the prior probabilities of the group sizes be computed? 
The options are:<br /> 
'EQUAL' for equal group sizes; or<br /> 
'SIZES' (default) for the group sizes to be based on the sizes of the groups in the dataframe.</p>
</td></tr>
<tr><td><code id="DFA_+3A_covmat_type">covmat_type</code></td>
<td>

<p>The kind of covariance to be used for a predictive DFA. The options are: 
<br /> 'within' (for the pooled within-groups covariance matrix, which is the default) or 
<br /> 'separate' (for separate-groups covariance matrices).</p>
</td></tr>
<tr><td><code id="DFA_+3A_cv">CV</code></td>
<td>

<p>If predictive = TRUE, should cross-validation (leave-one-out cross-validation) analyses also be conducted? 
The options are: TRUE (default) or FALSE.</p>
</td></tr>
<tr><td><code id="DFA_+3A_verbose">verbose</code></td>
<td>

<p>Should detailed results be displayed in console? <br /> The options are: TRUE (default) or FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The predictive DFA option using separate-groups covariance matrices (which is often called 'quadratic DFA') 
is conducted following the procedures described by Rencher (2002). The covariance matrices 
in this case are based on the scores on the continuous variables. In contrast, the 'separate-groups'
option in SPSS involves use of the group scores on the discriminant functions (not the original continuous variables), 
which can produce different classifications.
</p>
<p>When data has many cases (e.g., &gt; 1000), the leave-one-out cross-validation analyses can
be time-consuming to run. Set CV = FALSE to bypass the predictive DFA cross-validation analyses.
</p>
<p>See the documentation below for the GROUP.DIFFS function for information on the interpretation of the
Bayes factors and effect sizes that are produced for the group comparisons.
</p>


<h3>Value</h3>

<p>If verbose = TRUE, the displayed output includes descriptive statistics for the groups, 
tests of univariate and multivariate normality, 
the results of tests of the homogeneity of the group variance-covariance matrices, 
eigenvalues &amp; canonical correlations, Wilks' lambda &amp; peel-down statistics,
raw and standardized discriminant function coefficients, 
structure coefficients, functions at group centroids, 
one-way ANOVA tests of group differences in scores on each discriminant function,
one-way ANOVA tests of group differences in scores on each original DV,
significance tests for group differences on the original DVs according to Bird et al. (2014),
a plot of the group means on the standardized discriminant functions,
and extensive output from predictive discriminant function analyses (if requested).
</p>
<p>The returned output is a list with elements
</p>
<table>
<tr><td><code>evals</code></td>
<td>
<p>eigenvalues and canonical correlations</p>
</td></tr>
<tr><td><code>mv_Wilks</code></td>
<td>
<p>The Wilks' lambda multivariate test</p>
</td></tr>
<tr><td><code>mv_Pillai</code></td>
<td>
<p>The Pillai-Bartlett multivariate test</p>
</td></tr>
<tr><td><code>mv_Hotelling</code></td>
<td>
<p>The Lawley-Hotelling multivariate test</p>
</td></tr>
<tr><td><code>mv_Roy</code></td>
<td>
<p>Roy's greatest characteristic root multivariate test</p>
</td></tr>
<tr><td><code>coefs_raw</code></td>
<td>
<p>canonical discriminant function coefficients</p>
</td></tr>
<tr><td><code>coefs_structure</code></td>
<td>
<p>structure coefficients</p>
</td></tr>
<tr><td><code>coefs_standardized</code></td>
<td>
<p>standardized coefficients</p>
</td></tr>
<tr><td><code>coefs_standardizedSPSS</code></td>
<td>
<p>standardized coefficients from SPSS</p>
</td></tr>
<tr><td><code>centroids</code></td>
<td>
<p>unstandardized canonical discriminant functions evaluated at the group means</p>
</td></tr>
<tr><td><code>centroidSDs</code></td>
<td>
<p>group standard deviations on the unstandardized functions</p>
</td></tr>
<tr><td><code>centroidsZ</code></td>
<td>
<p>standardized canonical discriminant functions evaluated at the group means</p>
</td></tr>
<tr><td><code>centroidSDsZ</code></td>
<td>
<p>group standard deviations on the standardized functions</p>
</td></tr>
<tr><td><code>dfa_scores</code></td>
<td>
<p>scores on the discriminant functions</p>
</td></tr>
<tr><td><code>anovaDFoutput</code></td>
<td>
<p>One-way ANOVAs using the scores on a discriminant function as the DV</p>
</td></tr>
<tr><td><code>anovaDVoutput</code></td>
<td>
<p>One-way ANOVAs on the original DVs</p>
</td></tr>
<tr><td><code>MFWER1.sigtest</code></td>
<td>
<p>Significance tests when controlling the MFWER by (only) carrying out multiple t tests</p>
</td></tr>
<tr><td><code>MFWER2.sigtest</code></td>
<td>
<p>Significance tests for the two-stage approach to controling the MFWER</p>
</td></tr>  
<tr><td><code>classes_PRED</code></td>
<td>
<p>The predicted group classifications</p>
</td></tr>  
<tr><td><code>classes_CV</code></td>
<td>
<p>The classifications from leave-one-out cross-validations, if requested</p>
</td></tr>  
<tr><td><code>posteriors</code></td>
<td>
<p>The posterior probabilities for the predicted group classifications</p>
</td></tr>
<tr><td><code>grp_post_stats</code></td>
<td>
<p>Group mean posterior classification probabilities</p>
</td></tr>
<tr><td><code>classes_CV</code></td>
<td>
<p>Classifications from leave-one-out cross-validations</p>
</td></tr>
<tr><td><code>freqs_ORIG_PRED</code></td>
<td>
<p>Cross-tabulation of the original and predicted group memberships</p>
</td></tr>
<tr><td><code>chi_square_ORIG_PRED</code></td>
<td>
<p>Chi-square test of independence</p>
</td></tr>
<tr><td><code>PressQ_ORIG_PRED</code></td>
<td>
<p>Press's Q significance test of classifiation accuracy for original vs. predicted group memberships</p>
</td></tr>
<tr><td><code>kappas_ORIG_PRED</code></td>
<td>
<p>Agreement (kappas) between the predicted and original group memberships</p>
</td></tr>
<tr><td><code>PropOrigCorrect</code></td>
<td>
<p>Proportion of original grouped cases correctly classified</p>
</td></tr>  
<tr><td><code>freqs_ORIG_CV</code></td>
<td>
<p>Cross-Tabulation of the cross-validated and predicted group memberships</p>
</td></tr>
<tr><td><code>chi_square_ORIG_CV</code></td>
<td>
<p>Chi-square test of indepedence</p>
</td></tr>
<tr><td><code>PressQ_ORIG_CV</code></td>
<td>
<p>Press's Q significance test of classifiation accuracy for cross-validated vs. predicted group memberships</p>
</td></tr>
<tr><td><code>kappas_ORIG_CV</code></td>
<td>
<p>Agreement (kappas) between the cross-validated and original group memberships</p>
</td></tr>
<tr><td><code>PropCrossValCorrect</code></td>
<td>
<p>Proportion of cross-validated grouped cases correctly classified</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Brian P. O'Connor</p>


<h3>References</h3>

<p>Bird, K. D., &amp; Hadzi-Pavlovic, D. (2013). Controlling the maximum familywise Type I error 
rate in analyses of multivariate experiments. <em>Psychological Methods, 19(2),</em> p. 265-280.
<br /><br /> Manly, B. F. J., &amp; Alberto, J. A. (2017). <em>Multivariate statistical methods: 
A primer (4th Edition).</em> Chapman &amp; Hall/CRC, Boca Raton, FL.
<br /><br /> Rencher, A. C. (2002). <em>Methods of Multivariate Analysis</em> (2nd ed.). New York, NY: John Wiley &amp; Sons.
<br /><br /> Sherry, A. (2006). Discriminant analysis in counseling research. <em>Counseling Psychologist, 34,</em> 661-683.
<br /><br /> Tabachnik, B. G., &amp; Fidell, L. S. (2019). <em>Using multivariate statistics (7th ed.).</em> New York, NY: Pearson.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># data from Field et al. (2012, Chapter 16 MANOVA)
DFA_Field=DFA(data = data_DFA$Field_2012, 
    groups = 'Group', 
    variables = c('Actions','Thoughts'),
    predictive = TRUE, 
    priorprob = 'EQUAL',   
    covmat_type='within', # altho better to use 'separate' for these data
    verbose = TRUE)



# plots of posterior probabilities by group
# hoping to see correct separations between cases from different groups

# first, display the posterior probabilities
print(cbind(round(DFA_Field$posteriors[1:3],3), DFA_Field$posteriors[4]))

# group NT vs CBT
plot(DFA_Field$posteriors$posterior_NT, DFA_Field$posteriors$posterior_CBT, 
     pch = 16, col = c('red', 'blue', 'green')[DFA_Field$posteriors$Group],
     xlim=c(0,1), ylim=c(0,1),
     main = 'DFA Posterior Probabilities by Original Group Memberships',
     xlab='Posterior Probability of Being in Group NT',
     ylab='Posterior Probability of Being in Group CBT' )
legend(x=.8, y=.99, c('CBT','BT','NT'), cex=1.2, col=c('red', 'blue', 'green'), pch=16, bty='n')

# group NT vs BT
plot(DFA_Field$posteriors$posterior_NT, DFA_Field$posteriors$posterior_BT, 
     pch = 16, col = c('red', 'blue', 'green')[DFA_Field$posteriors$Group],
     xlim=c(0,1), ylim=c(0,1),
     main = 'DFA Posterior Probabilities by Group Membership',
     xlab='Posterior Probability of Being in Group NT',
     ylab='Posterior Probability of Being in Group BT' )
legend(x=.8, y=.99, c('CBT','BT','NT'), cex=1.2,col=c('red', 'blue', 'green'), pch=16, bty='n')

# group CBT vs BT
plot(DFA_Field$posteriors$posterior_CBT, DFA_Field$posteriors$posterior_BT, 
     pch = 16, col = c('red', 'blue', 'green')[DFA_Field$posteriors$Group],
     xlim=c(0,1), ylim=c(0,1),
     main = 'DFA Posterior Probabilities by Group Membership',
     xlab='Posterior Probability of Being in Group CBT',
     ylab='Posterior Probability of Being in Group BT' )
legend(x=.8, y=.99, c('CBT','BT','NT'), cex=1.2, col=c('red', 'blue', 'green'), pch=16, bty='n')


# data from Green &amp; Salkind (2008, Lesson 35)  
DFA(data = data_DFA$Green_2008,
    groups = 'job_cat', 
    variables = c('friendly','gpa','job_hist','job_test'),
    plot=TRUE,
    predictive = TRUE,
    priorprob = 'SIZES',  
    covmat_type='within', 
    CV=TRUE, 
    verbose=TRUE) 


# data from Ho (2014, Chapter 15) 
# with group_1 as numeric 
DFA(data = data_DFA$Ho_2014,
    groups = 'group_1_num',
    variables = c("fast_ris", "disresp", "sen_seek", "danger"),
    plot=TRUE,
    predictive = TRUE,
    priorprob = 'SIZES', 
    covmat_type='within', 
    CV=TRUE, 
    verbose=TRUE) 


# data from Ho (2014, Chapter 15)   
# with group_1 as a factor 
DFA(data = data_DFA$Ho_2014,
    groups = 'group_1_fac',
    variables = c("fast_ris", "disresp", "sen_seek", "danger"),
    plot=TRUE,
    predictive = TRUE,
    priorprob = 'SIZES', 
    covmat_type='within', 
    CV=TRUE, 
    verbose=TRUE) 


# data from Huberty (2006, p 45)
DFA_Huberty=DFA(data = data_DFA$Huberty_2019_p45, 
    groups = 'treatmnt_S', 
    variables = c('Y1','Y2'),
    predictive = TRUE, 
    priorprob = 'SIZES', 
    covmat_type='separate', # altho better to used 'separate' for these data
    verbose = TRUE)


# data from Huberty (2006, p 285)
DFA_Huberty=DFA(data = data_DFA$Huberty_2019_p285, 
    groups = 'Grade', 
    variables = c('counsum','gainsum','learnsum','qelib','qefac','qestacq',
                  'qeamt','qewrite','qesci'),
    predictive = TRUE, 
    priorprob = 'EQUAL', 
    covmat_type='within', 
    verbose = TRUE)


# data from Norusis (2012, Chaper 15)  
DFA_Norusis=DFA(data = data_DFA$Norusis_2012, 
    groups = 'internet', 
    variables = c('age','gender','income','kids','suburban','work','yearsed'),
    predictive = TRUE, 
    priorprob = 'EQUAL', 
    covmat_type='within', 
    verbose = TRUE)


# data from Rencher (2002, p 170)  - rootstock
DFA(data = data_DFA$Rencher_2002_root, 
    groups = 'rootstock', 
    variables = c('girth4','ext4','girth15','weight15'),
    predictive = TRUE, 
    priorprob = 'SIZES',
	covmat_type='within',     
	verbose = TRUE)


# data from Rencher (2002, p 280)  - football
DFA(data = data_DFA$Rencher_2002_football, 
    groups = 'grp', 
    variables = c('WDIM','CIRCUM','FBEYE','EYEHD','EARHD','JAW'),
    predictive = TRUE, 
    priorprob = 'SIZES',
	covmat_type='separate',     
	verbose = TRUE)


# Sherry (2006)   -  with Group as numeric 
DFA_Sherry &lt;- DFA(data = data_DFA$Sherry_2006, 
                  groups = 'Group_num',
                  variables = c('Neuroticism','Extroversion','Openness', 
                                'Agreeableness','Conscientiousness'),
                  predictive = TRUE, 
                  priorprob = 'SIZES', 
                  covmat_type='separate', 
                  verbose = TRUE)


# Sherry (2006)   -  with Group as a factor 
DFA_Sherry &lt;- DFA(data = data_DFA$Sherry_2006, 
                  groups = 'Group_fac',
                  variables = c('Neuroticism','Extroversion','Openness', 
                                'Agreeableness','Conscientiousness'),
                  predictive = TRUE, 
                  priorprob = 'SIZES', 
                  covmat_type='separate', 
                  verbose = TRUE)

# plots of posterior probabilities by group
# hoping to see correct separations between cases from different groups

# first, display the posterior probabilities
print(cbind(round(DFA_Sherry$posteriors[1:3],3), DFA_Sherry$posteriors[4]))

# group 1 vs 2
plot(DFA_Sherry$posteriors$posterior_1, DFA_Sherry$posteriors$posterior_2, 
     pch = 16, cex = 1, col = c('red', 'blue', 'green')[DFA_Sherry$posteriors$Group],
     xlim=c(0,1), ylim=c(0,1),
     main = 'DFA Posterior Probabilities by Original Group Memberships',
     xlab='Posterior Probability of Being in Group 1',
     ylab='Posterior Probability of Being in Group 2' )
legend(x=.8, y=.99, c('1','2','3'), cex=1.2, col=c('red', 'blue', 'green'), pch=16, bty='n')

# group 1 vs 3
plot(DFA_Sherry$posteriors$posterior_1, DFA_Sherry$posteriors$posterior_3, 
     pch = 16, col = c('red', 'blue', 'green')[DFA_Sherry$posteriors$Group],
     xlim=c(0,1), ylim=c(0,1),
     main = 'DFA Posterior Probabilities by Group Membership',
     xlab='Posterior Probability of Being in Group 1',
     ylab='Posterior Probability of Being in Group 3' )
legend(x=.8, y=.99, c('1','2','3'), cex=1.2,col=c('red', 'blue', 'green'), pch=16, bty='n')

# group 2 vs 3
plot(DFA_Sherry$posteriors$posterior_2, DFA_Sherry$posteriors$posterior_3, 
     pch = 16, col = c('red', 'blue', 'green')[DFA_Sherry$posteriors$Group],
     xlim=c(0,1), ylim=c(0,1),
     main = 'DFA Posterior Probabilities by Group Membership',
     xlab='Posterior Probability of Being in Group 2',
     ylab='Posterior Probability of Being in Group 3' )
legend(x=.8, y=.99, c('1','2','3'), cex=1.2, col=c('red', 'blue', 'green'), pch=16, bty='n')
    

# Tabachnik &amp; Fiddel (2019, p 307, 311)   - small - with group as numeric
DFA(data = data_DFA$TabFid_2019_small, 
    groups = 'group_num', 
    variables = c('perf','info','verbexp','age'),
    predictive = TRUE, 
    priorprob = 'SIZES', 
    covmat_type='within', 
    verbose = TRUE)  
    
    
# Tabachnik &amp; Fiddel (2019, p 307, 311)   - small - with group as a factor
DFA(data = data_DFA$TabFid_2019_small, 
    groups = 'group_fac', 
    variables = c('perf','info','verbexp','age'),
    predictive = TRUE, 
    priorprob = 'SIZES', 
    covmat_type='within', 
    verbose = TRUE)  


# Tabachnik &amp; Fiddel (2019, p 324)   - complete  - with WORKSTAT as numeric 
DFA(data = data_DFA$TabFid_2019_complete, 
    groups = 'WORKSTAT_num', 
    variables = c('CONTROL','ATTMAR','ATTROLE','ATTHOUSE'),
    plot=TRUE,
    predictive = TRUE,
    priorprob = 'SIZES',  
    covmat_type='within', 
    CV=TRUE, 
    verbose=TRUE) 

# Tabachnik &amp; Fiddel (2019, p 324)   - complete  -  with WORKSTAT as a factor  
DFA(data = data_DFA$TabFid_2019_complete, 
    groups = 'WORKSTAT_fac', 
    variables = c('CONTROL','ATTMAR','ATTROLE','ATTHOUSE'),
    plot=TRUE,
    predictive = TRUE,
    priorprob = 'SIZES',  
    covmat_type='within', 
    CV=TRUE, 
    verbose=TRUE) 

</code></pre>

<hr>
<h2 id='DFA.CANCOR-package'>DFA.CANCOR</h2><span id='topic+DFA.CANCOR-package'></span>

<h3>Description</h3>

<p>Provides SPSS- and SAS-like output for linear discriminant 
function analysis (via the DFA function) and for canonical correlation analysis
(via the CANCOR function), and for providing effect sizes and significance tests 
for pairwise group comparisons (via the GROUP.DIFFS function). There are also 
functions for assessing the assumptions of normality, linearity, and 
homogeneity of variances and covariances.</p>

<hr>
<h2 id='GROUP.DIFFS'>Group Mean Differences on a Continuous Outcome Variable</h2><span id='topic+GROUP.DIFFS'></span>

<h3>Description</h3>

<p>Produces a variety of statistics for all possible pairwise independent groups comparisons 
of means on a continuous outcome variable.</p>


<h3>Usage</h3>

<pre><code class='language-R'>GROUP.DIFFS(data, GROUPS=NULL, DV=NULL, var.equal=FALSE, p.adjust.method="holm", 
	            Ncomps=NULL, verbose=TRUE)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GROUP.DIFFS_+3A_data">data</code></td>
<td>

<p>A dataframe where the rows are cases &amp; the columns are the variables. If GROUPS and DV are not 
specified, then the GROUPS variable should be in the first column and the DV should be in the second
column of data.</p>
</td></tr>
<tr><td><code id="GROUP.DIFFS_+3A_groups">GROUPS</code></td>
<td>

<p>The name of the groups variable in the dataframe, e.g., groups = 'Group'.</p>
</td></tr>
<tr><td><code id="GROUP.DIFFS_+3A_dv">DV</code></td>
<td>

<p>The name of the dependent (outcome) variable in the dataframe, e.g., DV = 'esteem'.</p>
</td></tr>
<tr><td><code id="GROUP.DIFFS_+3A_var.equal">var.equal</code></td>
<td>
 
<p>(from stats::t.test) A logical variable indicating whether to treat the two variances as being equal.  
If TRUE then the pooled variance is used to estimate the variance otherwise the Welch (or Satterthwaite) 
approximation to the degrees of freedom is used.</p>
</td></tr>
<tr><td><code id="GROUP.DIFFS_+3A_p.adjust.method">p.adjust.method</code></td>
<td>

<p>The method to be used to adjust the p values for the number of comparisons. The options are &quot;holm&quot; 
(the default), &quot;hochberg&quot;, &quot;hommel&quot;, &quot;bonferroni&quot;, &quot;BH&quot;, &quot;BY&quot;, &quot;fdr&quot;, &quot;none&quot;.</p>
</td></tr>
<tr><td><code id="GROUP.DIFFS_+3A_ncomps">Ncomps</code></td>
<td>

<p>The number of pairwise comparisons for the adjusted p values. If unspecified, it will be the 
number of all possible comparisons (i.e., the family-wise number of number of comparisons). Ncomps
could alternatively be set to, e.g., the experiment-wise number of number of comparisons.</p>
</td></tr>
<tr><td><code id="GROUP.DIFFS_+3A_verbose">verbose</code></td>
<td>

<p>Should detailed results be displayed in console? <br /> The options are: TRUE (default) or FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function conducts all possible pairwise comparisons of the levels of the GROUPS variable on
the continuous outcome variable. It supplements independent groups t-test results with effect size statistics
and with the Bayes factor for each pairwise comparison.
</p>
<p>The d values are the Cohen d effect sizes, i.e., the mean difference expressed in standard deviation units.
</p>
<p>The g values are the Hedges g value corrections to the Cohen d effect sizes.
</p>
<p>The r values are the effect sizes for the group mean difference expressed in the metric of Pearson's r.
</p>
<p>The BESD values are the binomial effect size values for the group mean differences.
The BESD casts the effect size in terms of the success rate for the implementation of a hypothetical procedure
(e.g., the percentage of cases that were cured, or who died.) For example, an r = .32 is equivalent to increasing 
the success rate from 34% to 66% (or, possibly, reducing an illness or death rate from 66% to 34%).
</p>
<p>The Bayes factor values are obtained from the ttest.tstat function in the BayesFactor package.
</p>
<p>For example, a Bayes_Factor_alt_vs_null = 3 indicates that the data are 3 times <em>more</em> likely under the  
alternative hypothesis than under the null hypothesis. A Bayes_Factor_alt_vs_null = .2 indicates that 
the data are five times <em>less</em> likely under the alternative hypothesis than under the null hypothesis (1 / .2).
</p>
<p>Conversely, a Bayes_Factor_null_vs_alt = 3 indicates that the data are 3 times <em>more</em> likely under the  
null hypothesis than under the alternative hypothesis. A Bayes_Factor_null_vs_alt = .2 indicates that 
the data are five times <em>less</em> likely under the null hypothesis than under the alternative hypothesis (1 / .2).
</p>


<h3>Value</h3>

<p>If verbose = TRUE, the displayed output includes the means, standard deviations, and Ns for the groups, 
the t-test results for each pairwise comparison, the mean difference and its 95% confidence interval, four 
indices of effect size for each pairwise comparison (r, d, g, and BESD), and the Bayes factor. The returned 
output is a matrix with these values.
</p>


<h3>Author(s)</h3>

<p>Brian P. O'Connor</p>


<h3>References</h3>

<p>Funder, D. C., &amp; Ozer, D. J. (2019). Evaluating effect size in psychological research: Sense and nonsense. 
<em>Advances in Methods and Practices in Psychological Science, 2(2),</em> 156168.
<br /><br /> Jarosz, A. F., &amp; Wiley, J. (2014). What are the odds? A practical guide to computing and reporting 
Bayes factors. <em>Journal of Problem Solving, 7,</em> 29.
<br /><br /> Randolph, J. &amp; Edmondson, R.S. (2005). Using the binomial effect size display (BESD) to present the 
magnitude of effect sizes to the evaluation audience. <em>Practical Assessment Research &amp; Evaluation, 10,</em> 14.
<br /><br /> Rosenthal, R., Rosnow, R.L., &amp; Rubin, D.R. (2000). <em>Contrasts and effect sizes in behavioral research: 
A correlational approach.</em> Cambridge UK: Cambridge University Press.
<br /><br /> Rosenthal, R., &amp; Rubin, D. B. (1982). A simple general purpose display of magnitude and experimental effect. 
<em>Journal of Educational Psychology, 74,</em> 166-169.
<br /><br /> Rouder, J. N., Haaf, J. M., &amp; Vandekerckhove, J. (2018). Bayesian inference for psychology, part IV:
parameter estimation and Bayes factors. <em>Psychonomic Bulletin &amp; Review, 25(1),</em> 102113.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>GROUP.DIFFS(data_DFA$Field_2012, var.equal=FALSE, p.adjust.method="fdr")


GROUP.DIFFS(data = data_DFA$Sherry_2006, var.equal=FALSE, p.adjust.method="bonferroni")    

</code></pre>

<hr>
<h2 id='HOMOGENEITY'>Homogeneity of variances and covariances</h2><span id='topic+HOMOGENEITY'></span>

<h3>Description</h3>

<p>Produces tests of the homogeneity of variances and covariances.</p>


<h3>Usage</h3>

<pre><code class='language-R'>HOMOGENEITY(data, groups, variables, verbose)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HOMOGENEITY_+3A_data">data</code></td>
<td>

<p>A dataframe where the rows are cases &amp; the columns are the variables.</p>
</td></tr>
<tr><td><code id="HOMOGENEITY_+3A_groups">groups</code></td>
<td>

<p>(optional) The name of the groups variable in the dataframe (if there is one) <br /> e.g., groups = 'Group'.</p>
</td></tr>
<tr><td><code id="HOMOGENEITY_+3A_variables">variables</code></td>
<td>

<p>(optional) The names of the continuous variables in the dataframe for the analyses,
e.g., variables = c('varA', 'varB', 'varC').</p>
</td></tr>
<tr><td><code id="HOMOGENEITY_+3A_verbose">verbose</code></td>
<td>

<p>Should detailed results be displayed in the console? <br /> The options are: TRUE (default) or FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If &quot;variables&quot; is specified, the analyses will be run on the &quot;variables&quot; in &quot;data&quot;.
If verbose = TRUE, the displayed output includes descriptive statistics and
tests of univariate and multivariate homogeneity.
</p>
<p>Bartlett's test compares the variances of k samples. The data must be normally distributed.
</p>
<p>The non-parametric Fligner-Killeen test also compares the variances of k samples and
it is robust when there are departures from normality.
</p>
<p>Box's M test is a multivariate statistical test of the equality of multiple
variance-covariance matrices. The test is prone to errors when the sample sizes are small or when
the data do not meet model assumptions, especially the assumption of multivariate normality.
For large samples, Box's M test may be too strict, indicating heterogeneity when the covariance 
matrices are not very different.
</p>
<p>The returned output is a list with elements
</p>
<table>
<tr><td><code>covmatrix</code></td>
<td>
<p>The variance-covariance matrix for each group</p>
</td></tr>
<tr><td><code>Bartlett</code></td>
<td>
<p>Bartlett test of homogeneity of variances (parametric)</p>
</td></tr>
<tr><td><code>Figner_Killeen</code></td>
<td>
<p>Figner-Killeen test of homogeneity of variances (non parametric)</p>
</td></tr>
<tr><td><code>PooledWithinCovarSPSS</code></td>
<td>
<p>the pooled within groups covariance matrix from SPSS</p>
</td></tr>
<tr><td><code>PooledWithinCorrelSPSS</code></td>
<td>
<p>the pooled within groups correlation matrix from SPSS</p>
</td></tr>
<tr><td><code>sscpWithin</code></td>
<td>
<p>the within sums of squares and cross-products matrix</p>
</td></tr>
<tr><td><code>sscpBetween</code></td>
<td>
<p>the between sums of squares and cross-products matrix</p>
</td></tr>
<tr><td><code>BoxLogdets</code></td>
<td>
<p>the log determinants for Box's test</p>
</td></tr>
<tr><td><code>BoxMtest</code></td>
<td>
<p>Box's' test of the equality of covariance matrices</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Brian P. O'Connor </p>


<h3>References</h3>

<p>Box, G. E. P. (1949). A general distribution theory for a class of likelihood
criteria. <em>Biometrika, 36 (3-4),</em> 317-346.
</p>
<p>Bartlett, M. S. (1937). Properties of sufficiency and statistical tests. <em>Proceedings of the Royal Society
of London Series A 160,</em> 268-282.
</p>
<p>Conover, W. J., Johnson, M. E., &amp; Johnson, M. M. (1981). A comparative study of tests for homogeneity
of variances, with applications to the outer continental shelf bidding data. <em>Technometrics, 23,</em> 351-361.
</p>
<p>Warner, R. M. (2013). <em>Applied statistics: From bivariate through multivariate techniques.</em> Thousand Oaks, CA: SAGE.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># data from Field et al. (2012)
HOMOGENEITY(data = data_DFA$Field_2012,
            groups = 'Group', variables = c('Actions','Thoughts'))


# data from Sherry (2006)
HOMOGENEITY(data = data_DFA$Sherry_2006,
            groups = 'Group',
            variables = c('Neuroticism','Extroversion','Openness',
                          'Agreeableness','Conscientiousness'))


</code></pre>

<hr>
<h2 id='LINEARITY'>Linearity</h2><span id='topic+LINEARITY'></span>

<h3>Description</h3>

<p>Provides tests of the possible linear and quadratic
associations between two continuous variables.</p>


<h3>Usage</h3>

<pre><code class='language-R'>LINEARITY(data, variables, groups, idvs, dv, verbose)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LINEARITY_+3A_data">data</code></td>
<td>

<p>A dataframe where the rows are cases &amp; the columns are the variables.</p>
</td></tr>
<tr><td><code id="LINEARITY_+3A_variables">variables</code></td>
<td>
 
<p>(optional) The names of the continuous variables in the dataframe for the analyses, 
e.g., variables = c('varA', 'varB', 'varC').</p>
</td></tr>
<tr><td><code id="LINEARITY_+3A_groups">groups</code></td>
<td>

<p>(optional) The name of the groups variable in the dataframe (if there is one), 
<br /> e.g., groups = 'Group'.</p>
</td></tr>
<tr><td><code id="LINEARITY_+3A_idvs">idvs</code></td>
<td>

<p>(optional) The names of the predictor variables, 
e.g., variables = c('varA', 'varB', 'varC').</p>
</td></tr>
<tr><td><code id="LINEARITY_+3A_dv">dv</code></td>
<td>

<p>(optional) The name of the dependent variable, if output for just 
one dependent variable is desired.</p>
</td></tr>
<tr><td><code id="LINEARITY_+3A_verbose">verbose</code></td>
<td>

<p>(optional) Should detailed results be displayed in the console? 
<br /> The options are: TRUE (default) or FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If &quot;variables&quot; is specified, the analyses will be run on the &quot;variables&quot; in &quot;data&quot;.
If &quot;groups&quot; is specified, the analyses will be run for every value of &quot;groups&quot;.
If verbose = TRUE, the linear and quadratic regression
coefficients and their statistical tests are displayed.
</p>
<p>The returned output is a list with the regression 
coefficients and their statistical tests.</p>


<h3>Author(s)</h3>

<p>Brian P. O'Connor </p>


<h3>References</h3>

<p>Tabachnik, B. G., &amp; Fidell, L. S. (2019). <em>Using multivariate statistics (7th ed.).</em> New York, NY: Pearson.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># data from Sherry (2006), using all variables
LINEARITY(data=data_DFA$Sherry_2006, groups='Group',
          variables=c('Neuroticism','Extroversion','Openness',
                      'Agreeableness','Conscientiousness') )


# data from Sherry (2006), specifying independent variables and a dependent variable
LINEARITY(data=data_DFA$Sherry_2006, groups='Group',
          idvs=c('Neuroticism','Extroversion','Openness','Agreeableness'),
          dv=c('Conscientiousness'), 
          verbose=TRUE )

# data that simulate those from De Leo &amp; Wulfert (2013)
LINEARITY(data=data_CANCOR$DeLeo_2013,
          variables=c('Tobacco_Use','Alcohol_Use','Illicit_Drug_Use',
                      'Gambling_Behavior', 'Unprotected_Sex','CIAS_Total', 
                      'Impulsivity','Social_Interaction_Anxiety','Depression',
                      'Social_Support','Intolerance_of_Deviance','Family_Morals',
                      'Family_Conflict','Grade_Point_Average'), 
          verbose=TRUE )


</code></pre>

<hr>
<h2 id='NORMALITY'>Univariate and multivariate normality</h2><span id='topic+NORMALITY'></span>

<h3>Description</h3>

<p>Produces tests of univariate and multivariate normality using the MVN package.</p>


<h3>Usage</h3>

<pre><code class='language-R'>NORMALITY(data, groups, variables, verbose)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NORMALITY_+3A_data">data</code></td>
<td>

<p>A dataframe where the rows are cases &amp; the columns are the variables.</p>
</td></tr>
<tr><td><code id="NORMALITY_+3A_groups">groups</code></td>
<td>

<p>(optional) The name of the groups variable in the dataframe, <br /> e.g., groups = 'Group'.</p>
</td></tr>
<tr><td><code id="NORMALITY_+3A_variables">variables</code></td>
<td>
 
<p>(optional) The names of the continuous variables in the dataframe for the analyses, 
e.g., variables = c('varA', 'varB', 'varC').</p>
</td></tr>
<tr><td><code id="NORMALITY_+3A_verbose">verbose</code></td>
<td>

<p>Should detailed results be displayed in the console? <br /> The options are: TRUE (default) or FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If &quot;groups&quot; is not specified, the analyses will be run on all of the variables in &quot;data&quot;.
If &quot;groups&quot; is specified, the analyses will be run for every value of &quot;groups&quot;.
If &quot;variables&quot; is specified, the analyses will be run on the &quot;variables&quot; in &quot;data&quot;.
If verbose = TRUE, the displayed output includes descriptive statistics and
tests of univariate and multivariate normality.
</p>
<p>The returned output is a list with elements
</p>
<table>
<tr><td><code>descriptives</code></td>
<td>
<p>descriptive statistics, including skewness and kurtosis</p>
</td></tr>
<tr><td><code>Shapiro_Wilk</code></td>
<td>
<p>the Shapiro_Wilk test of univariate normality</p>
</td></tr>
<tr><td><code>Mardia</code></td>
<td>
<p>the Mardia test of multivariate normality</p>
</td></tr>
<tr><td><code>Henze_Zirkler</code></td>
<td>
<p>the Henze-Zirkler test of multivariate normality</p>
</td></tr>
<tr><td><code>Royston</code></td>
<td>
<p>the Royston test of multivariate normality</p>
</td></tr>
<tr><td><code>Doornik_Hansen</code></td>
<td>
<p>the Doornik_Hansen test of multivariate normality</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Brian P. O'Connor </p>


<h3>References</h3>

<p>Korkmaz, S., Goksuluk, D., Zararsiz, G. (2014). MVN: An R package for assessing 
multivariate normality. <em>The R Journal, 6(2),</em> 151-162.	
<br /><br /> Szekely,G. J., &amp; Rizzo, M. L. (2017). The energy of data. <em>Annual 
Review of Statistics and Its Application 4,</em> 447-79.	 
<br /><br /> Tabachnik, B. G., &amp; Fidell, L. S. (2019). <em>Using multivariate statistics (7th ed.).</em> New York, NY: Pearson.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># data that simulate those from De Leo &amp; Wulfert (2013)
NORMALITY(data = na.omit(data_CANCOR$DeLeo_2013[c(
          'Unprotected_Sex','Tobacco_Use','Alcohol_Use','Illicit_Drug_Use',
          'Gambling_Behavior','CIAS_Total','Impulsivity','Social_Interaction_Anxiety',
          'Depression','Social_Support','Intolerance_of_Deviance','Family_Morals',
          'Family_Conflict','Grade_Point_Average')]))
 

# data from Field et al. (2012)
NORMALITY(data = data_DFA$Field_2012, 
          groups = 'Group', 
          variables = c('Actions','Thoughts'))

# data from Tabachnik &amp; Fidell (2013, p. 589)
NORMALITY(data = na.omit(data_CANCOR$TabFid_2019_small[c('TS','TC','BS','BC')]))

# UCLA dataset
UCLA_CCA_data &lt;- read.csv("https://stats.idre.ucla.edu/stat/data/mmreg.csv")
colnames(UCLA_CCA_data) &lt;- c("LocusControl", "SelfConcept", "Motivation",
                             "read", "write", "math", "science", "female")
summary(UCLA_CCA_data)
NORMALITY(data = na.omit(UCLA_CCA_data[c("LocusControl","SelfConcept","Motivation",
                                         "read","write","math","science")]))


</code></pre>

<hr>
<h2 id='PLOT_LINEARITY'>Plot for linearity</h2><span id='topic+PLOT_LINEARITY'></span>

<h3>Description</h3>

<p>Plots the linear, quadratic, and loess regression lines for the
association between two continuous variables.</p>


<h3>Usage</h3>

<pre><code class='language-R'>PLOT_LINEARITY(data, idv, dv, groups=NULL, groupNAME=NULL, legposition=NULL, 
	                  leginset=NULL, verbose=TRUE)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PLOT_LINEARITY_+3A_data">data</code></td>
<td>

<p>A dataframe where the rows are cases &amp; the columns are the variables.</p>
</td></tr>
<tr><td><code id="PLOT_LINEARITY_+3A_idv">idv</code></td>
<td>

<p>The name of the predictor variable.</p>
</td></tr>
<tr><td><code id="PLOT_LINEARITY_+3A_dv">dv</code></td>
<td>

<p>The name of the dependent variable.</p>
</td></tr>
<tr><td><code id="PLOT_LINEARITY_+3A_groups">groups</code></td>
<td>

<p>(optional) The name of the groups variable in the dataframe, 
<br /> e.g., groups = 'Group'.</p>
</td></tr>
<tr><td><code id="PLOT_LINEARITY_+3A_groupname">groupNAME</code></td>
<td>

<p>(optional) The value (level, name, or number) from the groups 
variable that identifies the subset group whose data will be used 
for the analyses, <br /> e.g., groupNAME = 1.</p>
</td></tr>
<tr><td><code id="PLOT_LINEARITY_+3A_legposition">legposition</code></td>
<td>

<p>(optional) The position of the legend, as specified by one of the
<br /> following possible keywords: &quot;bottomright&quot;, &quot;bottom&quot;, &quot;bottomleft&quot;,  
<br /> &quot;left&quot;, &quot;topleft&quot;, &quot;top&quot;, &quot;topright&quot;, &quot;right&quot; or &quot;center&quot;.</p>
</td></tr>
<tr><td><code id="PLOT_LINEARITY_+3A_leginset">leginset</code></td>
<td>

<p>(optional) The inset distance(s) of the legend from the margins as a  
<br /> fraction of the plot region when legend is placed by keyword.</p>
</td></tr>
<tr><td><code id="PLOT_LINEARITY_+3A_verbose">verbose</code></td>
<td>

<p>Should detailed results be displayed in the console? 
<br /> The options are: TRUE (default) or FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If verbose = TRUE, the linear and quadratic regression
coefficients and their statistical tests are displayed.
</p>
<p>The returned output is a list with the regression 
coefficients and the plot data.</p>


<h3>Author(s)</h3>

<p>Brian P. O'Connor </p>


<h3>References</h3>

<p>Tabachnik, B. G., &amp; Fidell, L. S. (2019). <em>Using multivariate statistics (7th ed.).</em> New York, NY: Pearson.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># data that simulate those from De Leo &amp; Wulfert (2013)
PLOT_LINEARITY(data=data_CANCOR$DeLeo_2013, groups=NULL, 
               idv='Family_Conflict', dv='Grade_Point_Average', verbose=TRUE)


# data from Sherry (2006), ignoring the groups
PLOT_LINEARITY(data=data_DFA$Sherry_2006, groups=NULL, groupNAME=NULL,
               idv='Neuroticism', dv='Conscientiousness', verbose=TRUE)

# data from Sherry (2006), group 2 only
PLOT_LINEARITY(data=data_DFA$Sherry_2006, groups ='Group', groupNAME=2,
               idv='Neuroticism', dv='Conscientiousness', verbose=TRUE)
 

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
