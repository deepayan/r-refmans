<!DOCTYPE html><html><head><title>Help for package MPTinR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {MPTinR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bmpt.fia'>
<p>Compute FIA for MPTs</p></a></li>
<li><a href='#check.mpt'>
<p>Check construction of MPT models.</p></a></li>
<li><a href='#d.broeder'>
<p>Broeder &amp; Schuetz (2009) Experiment 3</p></a></li>
<li><a href='#fit.model'>
<p>Fit cognitive models for categorical data using model files</p></a></li>
<li><a href='#fit.mpt'>
<p>Function to fit MPT models</p></a></li>
<li><a href='#fit.mpt.old'>
<p>Function to fit MPT models (old)</p></a></li>
<li><a href='#fit.mptinr'>
<p>Fit cognitive models for categorical data using an objective function</p></a></li>
<li><a href='#gen.data'>
<p>Generate or bootstrap data and get predictions from a model specified in a model file (or connection).</p></a></li>
<li><a href='#get.mpt.fia'>
<p>Convenient function to get FIA for MPT</p></a></li>
<li><a href='#make.eqn'>
<p>Creates an EQN model file oir MDT data file</p></a></li>
<li><a href='#make.mpt.cf'>
<p>Functions to transform MPT models.</p></a></li>
<li><a href='#MPTinR-package'>
<p>Analyze Multinomial Processing Tree Models</p></a></li>
<li><a href='#prediction.plot'>
<p>Plot observed versus predicted values for categorical data.</p></a></li>
<li><a href='#prepare.mpt.fia'>
<p>Provides MATLAB command to get FIA</p></a></li>
<li><a href='#rb.fig1.data'>
<p>Data to be used for the examples of MPTinR.</p></a></li>
<li><a href='#ROCs'>
<p>Recognition memory ROCs used by Klauer &amp; Kellen (2015)</p></a></li>
<li><a href='#select.mpt'>
<p>Model Selection with MPTinR</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Analyze Multinomial Processing Tree Models</td>
</tr>
<tr>
<td>Version:</td>
<td>1.14.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides a user-friendly way for the analysis of multinomial processing tree (MPT) models (e.g.,  Riefer, D. M., and Batchelder, W. H. [1988]. Multinomial modeling and the measurement of cognitive processes. Psychological Review, 95, 318-339) for single and multiple datasets. The main functions perform model fitting and model selection. Model selection can be done using AIC, BIC, or the Fisher Information Approximation (FIA) a measure based on the Minimum Description Length (MDL) framework. The model and restrictions can be specified in external files or within an R script in an intuitive syntax or using the context-free language for MPTs. The 'classical' .EQN file format for model files is also supported. Besides MPTs, this package can fit a wide variety of other cognitive models such as SDT models (see fit.model). It also supports multicore fitting and FIA calculation (using the snowfall package), can generate or bootstrap data for simulations, and plot predicted versus observed data.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.15.1)</td>
</tr>
<tr>
<td>Imports:</td>
<td>numDeriv, Brobdingnag, Rcpp, stats, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>snowfall (&ge; 1.84), knitr</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppEigen</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>yes</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-12-07 16:31:14 UTC; hornik</td>
</tr>
<tr>
<td>Author:</td>
<td>Henrik Singmann [aut, cre],
  David Kellen [aut],
  Quentin Gronau [aut],
  Christian Mueller [ctb],
  Akhil S Bhel [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Henrik Singmann &lt;singmann@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-12-07 17:57:26</td>
</tr>
</table>
<hr>
<h2 id='bmpt.fia'>
Compute FIA for MPTs
</h2><span id='topic+bmpt.fia'></span>

<h3>Description</h3>

<p>R-port of the function to compute FIA for MPT models by Wu, Myung, and Batchelder (2010a, 2010b). This function is essentially a copy of the original Matlab code to R (with significant parts moved to C++ and allowing for multicore functionality). Also, the order of input arguments is more R-like.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bmpt.fia(s, parameters, category, N, ineq0 = NULL, Sample = 2e+05, 
        multicore = FALSE, split = NULL, mConst = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bmpt.fia_+3A_s">s</code></td>
<td>

<p>see Details
</p>
</td></tr>
<tr><td><code id="bmpt.fia_+3A_parameters">parameters</code></td>
<td>

<p>see Details
</p>
</td></tr>
<tr><td><code id="bmpt.fia_+3A_category">category</code></td>
<td>

<p>see Details
</p>
</td></tr>
<tr><td><code id="bmpt.fia_+3A_n">N</code></td>
<td>

<p>see Details
</p>
</td></tr>
<tr><td><code id="bmpt.fia_+3A_ineq0">ineq0</code></td>
<td>

<p>see Details
</p>
</td></tr>
<tr><td><code id="bmpt.fia_+3A_sample">Sample</code></td>
<td>

<p>see Details
</p>
</td></tr>
<tr><td><code id="bmpt.fia_+3A_multicore">multicore</code></td>
<td>

<p>logical. Should fitting be distributed across several cores? Requires <span class="pkg">snowfall</span> and initialized cluster. See also below.
</p>
</td></tr>
<tr><td><code id="bmpt.fia_+3A_split">split</code></td>
<td>

<p><code>NULL</code> (the default) or integer specifying in how many separate calls to the C++ workhorse the integrant should be calculated. See below.
</p>
</td></tr>
<tr><td><code id="bmpt.fia_+3A_mconst">mConst</code></td>
<td>

<p>A constant which is added in the Monte Carlo integration to avoid numerical underflows and is later subtracted (after appropriate transformation). Should be a power of 2 to avoid unnecessary numerical imprecision. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following is the original description by Wu, Myung, &amp; Batchelder (2010a) for their Matlab function. All changes to the original document are in squared brackets []:
</p>
<p>This function computes the FIA complexity measure, C_FIA, using a Monte Carlo numerical integration algorithm. When inequality is present, sampling from the restricted parameter space is performed by rejection algorithm.
</p>
<p>[...] [see References for References]
</p>
<p>The following symbols are used in the body of the function:<br />
S denotes number of parameters.<br />
C denotes the number of categories.<br />
M denotes the number of leaves in the tree.
</p>
<p>The first input argument <code>s</code> is related to the string representation of the BMPT model. It can be obtained by replacing all categories in the string by the capital letter C and all branching probabilities by the lower case letter p. 
</p>
<p>The second input argument <code>parameters</code> is a row vector that assigns parameters or constants to the p's in the  string <code>s</code>. Its length should be the same as the number of p's in <code>s</code>, and its elements correspond to the p's according to their order in <code>s</code>. Positive integer elements in <code>parameters</code> assign parameters to the corresponding p's, with the same integer denoting the same parameter. Constants are assigned to the p's using the negation of their values. 
</p>
<p>The [third] input argument <code>category</code> is a 1 by M vector assigning categories to the C's in the string &lsquo;s&rsquo; in the same way <code>parameters</code> assigns branching probabilities, except that only positive consecutive integers from 1 to <code>J</code>, the total number of categories, are allowed. 
</p>
<p>The [fourth] input argument <code>N</code> specifies the total sample size.
</p>
<p>The [fifth] input argument <code>ineq0</code> assigns inequality constraints imposed on the parameters. It is a matrix with two columns. Each element denotes a parameter coded in the same way as in <code>parameters</code>. For each row, the parameter on the left column is constrained to be smaller than that on the right column. The number of rows is determined by the total number of simple inequality constraints of the form <code>theta_1 &lt; theta_2</code> in the model. [Default is <code>NULL</code> corresponding to no inequality restrictions.]
</p>
<p>The last input argument &lsquo;Sample&rsquo; specifies the number of random samples to be drawn in the Monte Carlo algorithm. [Default is 200000.]
</p>
<p>[For returned values see Value]
</p>
<p>It should be noted that &lsquo;lnconst&rsquo; can be computed analytically free of Monte Carlo error on a case by case basis described below. For this reason, the users can calculate <code>C_FIA</code> [see Wu, Myung &amp; Batchelder, 2010a; Equation 7] by adding <code>(S/2)*ln*(N/(2*pi))</code>, <code>lnInt</code> and their hand-calculated <code>lnconst</code> to minimize the Monte Carlo errors. [In our experience this error is rather low and negligible.]
</p>
<p>A sequence of inequalities <code>theta_1 &lt; theta_2 &lt; ... &lt; theta_k</code> reduces the parameter space to its <code>1/k!</code>, so in this case <code>lnconst</code> should be <code>-ln * (k!)</code>. In general, any combination of inequality constraints specifies a union of subsets of the parameter space, each satisfying some sequence of inequalities. For example, the subspace defined by <code>theta_1 &lt; theta_2</code> and <code>theta_3 &lt; theta_2</code> is a union of two subspaces, one satisfying <code>theta_1 &lt; theta_3 &lt; theta_2</code> and the other <code>theta_3 &lt; theta_1 &lt; theta_2</code>, so the proportion is given by <code>2 * (1/3!) = 1/3</code>.
</p>
<p>A coding example:<br />
Suppose that for model 1HTM-5c of source monitoring [see Wu et al., 2010a] , the sample sizes of source A, source B and new items are 300, 300 and 400, respectively and the inequality constraint of <code>d_1 &lt; d_2</code> is imposed. In this case, the six input arguments should be specified as follows:<br />
s = 'ppppCpCCppCCCppCpCCppCCCppCCC';<br />
parameters = c(-.6,-.5,1,2,5,4,5,1,3,5,4,5,4,5); [adapted for R]<br />
ineq0 = matrix(c(2,3), 1,2); [adapted for R]<br />
category = c(1,1,2,1,2,3,5,4,5,4,5,6,7,8,9); [adapted for R]<br />
N = 1000;
</p>
<p>Another coding example:<br />
For the pair-clustering model in Batchelder and Riefer (1999, Figure 1), suppose in a pair-clustering experiment there are 300 pairs of words and 100 singletons, the six input arguments should be specified as follows:<br />
s = 'pppCCppCCpCCpCC';
parameters = c(-.75,1,2,3,3,3,3); [adapted for R]<br />
ineq0 = NULL;  [adapted for R]<br />
category = c(1,4,2,3,3,4,5,6); [adapted for R]<br />
N = 400;
</p>
<p>[For more examples, see Examples]
</p>
<p>Since MPTinR version 1.1.3 the Monte Carlo integration is performed in C++ using <span class="pkg">RcppEigen</span>. With the default arguments, one instance of the C++ workhorse is called. To call multiple instances of the C++ workhorse, you can use the <code>split</code> argument (which can be useful to replicate results obtained with <code>multicore = TRUE</code> as described below). Note, that each time before calling the C++ code, the seed is set (the set of random seeds are generated before calling the function for the first time).
</p>
<p>Multicore functionality is achieved via <span class="pkg">snowfall</span> which needs to be loaded and a cluster initialized via <code><a href="snowfall.html#topic+sfInit">sfInit</a></code> when setting <code>multicore = TRUE</code>. When <code>split = NULL</code> (the default), the <code>Samples</code> will be evenly distributed on the different cores (using <code><a href="snowfall.html#topic+sfClusterSplit">sfClusterSplit</a></code>), so that only one instance of the underlying C++ workhorse is called on each core. Setting <code>split</code> to non-<code>NULL</code> will produce as many instances (distributed across cores). Note that in order to obtain comparable results (as snowfall uses load balancing), the random seed is set (at each core) before calling each instance of the C++ workhorse. This allows to replicate results obtained via multicore in a non-multicore environment when seting <code>split</code> appropriately (and <code>set.seed</code> beforehands).
</p>


<h3>Value</h3>

<p>[A named vector:]
</p>
<p>The first output argument <code>CFIA</code> gives the FIA complexity value of the model.
</p>
<p>The second [and third] output argument <code>CI</code> gives the Monte Carlo confidence interval of <code>CFIA</code>. [<code>CI.l</code>, gives the lower, <code>CI.u</code>, the upper bound of the interval].
</p>
<p>The [fourth] output argument <code>lnInt</code> gives the log integral term in <code>C_FIA</code> [see Wu, Myung &amp; Batchelder, 2010a; Equation 7] for models without inequality constraints. When inequality constraints are present, <code>lnInt</code> does not take into account the change in the normalizing constant in the proposal distribution and must be adjusted with the output argument <code>lnconst</code>.
</p>
<p>The [fifth and sixth] output argument [<code>CI.lnint</code>] gives the Monte Carlo confidence interval of <code>lnInt</code>. [.l = lower &amp; .u = upper bound of the CI]
</p>
<p>When inequality constraints are present, the [seventh] output argument <code>lnconst</code> serves as an adjustment of &lsquo;lnInt&rsquo;. It estimates the logarithm of the proportion of parameter space [0,1]^S that satisfies those inequality constraints, and the log integral term is given by lnInt+lnconst.
</p>
<p>The next [two] output argument [<code>CI.lnconst</code>] give the Monte Carlo confidence interval of &lsquo;lnconst&rsquo;. [.l = lower &amp; .u = upper bound of the CI]
</p>


<h3>Note</h3>

<p>The R version of the code should now (after moving the code to RcppEigen) be considerably faster than the Matlab version of this code.
</p>


<h3>Author(s)</h3>

<p>The original Matlab code was written by Hao Wu, Jay I. Myung, and William H. Batchelder.<br /> This code was ported to R by Henrik Singmann and David Kellen. RcppEigen was added by Henrik Singmann and Christian Mueller. Multicore functionality was added by Henrik Singmann.
</p>


<h3>References</h3>

<p>Wu, H., Myung, J.I., &amp; Batchelder, W.H. (2010a). Minimum description length model selection of multinomial processing tree models. <em>Psychonomic Bulletin &amp; Review</em>, 17, 275-286.
</p>
<p>Wu, H., Myung, J.I., &amp; Batchelder, W.H. (2010b). On the minimum description length complexity of multinomial processing trees. <em>Journal of Mathematical Psychology</em>, 54, 291-303.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit.mpt">fit.mpt</a></code> for the main function of MPTinR.<br />
<code><a href="#topic+get.mpt.fia">get.mpt.fia</a></code> for a convenient wrapper of this function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# The following example is the code for the first example in Wu, Myung &amp; Batchelder (2010a, pp. 280)
# The result should be something like: CFIA = 12.61... or 12.62..., CI = 12.61... - 12.62....
# Executing this command can take a while.

bmpt.fia(s = "ppppCpCCppCCCppCpCCppCCCppCCC", 
	parameters = c(-0.5, -0.5, 3, 2, 5, 1, 5, 4, 2, 5, 1, 5, 1, 5), 
	category = c(1,1,2,1,2,3,5,4,5,4,5,6,7,8,9), 
  N = 1000, ineq0 = matrix(c(4,3),1,2))

bmpt.fia(s = "ppppCpCCppCCCppCpCCppCCCppCCC", 
	parameters = c(-0.5, -0.5, 3, 2, 5, 1, 5, 4, 2, 5, 1, 5, 1, 5), 
	category = c(1,1,2,1,2,3,5,4,5,4,5,6,7,8,9), 
  N = 1000, ineq0 = matrix(c(4,3),1,2), mConst = 2L^8)

## End(Not run)
  </code></pre>

<hr>
<h2 id='check.mpt'>
Check construction of MPT models.
</h2><span id='topic+check.mpt'></span>

<h3>Description</h3>

<p>A helper function which can aid in the process of constructing a MPT model file for MPTinR. It will check if the probabilities in each trees sum to 1 (if so, a tree is well constructed). If probabilities do not sum to 1, <code>check.mpt</code> will return for which trees. Furthermore, it will return the number of parameters and their names (helpful in spotting typos), the number of categories and the number of dfs the model provides. Finally, you can also pass restrictions as an argument and will receive the number and names of the parameters after restrictions are applied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.mpt(model.filename, restrictions.filename = NULL, model.type = c("easy", "eqn"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check.mpt_+3A_model.filename">model.filename</code></td>
<td>

<p>A character <code>vector</code> specifying the location and name of the model file. 
</p>
</td></tr>
<tr><td><code id="check.mpt_+3A_restrictions.filename">restrictions.filename</code></td>
<td>

<p><code>NULL</code> or a character <code>vector</code> specifying the location and name of the restrictions file. Default is <code>NULL</code> which corresponds to no restrictions.
</p>
</td></tr>
<tr><td><code id="check.mpt_+3A_model.type">model.type</code></td>
<td>

<p>Character vector specifying whether the model file is formatted in the <em>easy</em> format (<code>"easy"</code>; i.e., each line represents all branches corresponding to a response category) or the traditional EQN syntax (<code>"eqn"</code>; see e.g., Stahl &amp; Klauer, 2007). If the model filename ends with &quot;.eqn&quot; or &quot;.EQN&quot; the model is automatically treated as an EQN file.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As default, <code>check.mpt</code> expects a model file in the easy format, but if the filename ends with .eqn or .EQN <code>check.mpt</code> will expect the EQN format.<br />
</p>
<p>In case of inequality restrictions, the original parameters which are inequality restricted are replaced  with dummy parameters starting with <code>hankX</code>. When using <code><a href="#topic+fit.mpt">fit.mpt</a></code> you will not notice this, as the output only shows the original parameters. In contrast, <code>check.mpt</code> removes the original parameters and shows the dummy parameters called <code>hankX</code>. Note that this does not change the number of parameters in the model.
</p>
<p>For EQN model files, the output also contains two slots giving the ordering of trees (<code>eqn.order.trees</code>) as well as categories (<code>eqn.order.categories</code>).
</p>


<h3>Value</h3>

<p>A list with 
</p>
<table>
<tr><td><code>probabilites.eq.1</code></td>
<td>
<p>A logical value indicating whether or not the probabilities in each tree sum to 1. If <code>FALSE</code>, a warning is shown indicating in which trees the probabilities do not sum to 1.</p>
</td></tr>
<tr><td><code>n.trees</code></td>
<td>
<p>Number of trees in the model.</p>
</td></tr>
<tr><td><code>n.model.categories</code></td>
<td>
<p>Total number of categories expected in a dataset for that model.</p>
</td></tr>
<tr><td><code>n.independent.categories</code></td>
<td>
<p>Number of independent response categories (i.e., independent data points) the model provides (i.e., <code>n.model.categories - n.trees</code>). The number of parameters can not be higher than this value for a model to be identifiable.</p>
</td></tr>
<tr><td><code>n.params</code></td>
<td>
<p>Number of parameters in the model.</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>
<p>Names of parameters in the model.</p>
</td></tr>
<tr><td><code>eqn.order.trees</code></td>
<td>
<p>Order of trees in EQN model files (omitted if model is not an EQN file).</p>
</td></tr>
<tr><td><code>eqn.order.categories</code></td>
<td>
<p>Order of trees in EQN model files (omitted if model is not an EQN file).</p>
</td></tr>
</table>
<p>If restrictions are present, the <code>n.params</code> and <code>parameters</code> are displayed for the unrestricted model (<code>orig.model</code>) as well as for the restricted model (<code>restr.model</code>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit.mpt">fit.mpt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># model of example 1 from example(fit.mpt)
model1 &lt;- system.file("extdata", "rb.fig1.model", package = "MPTinR")
check.mpt(model1)

#model 1 in eqn format
model1.eqn &lt;- system.file("extdata", "rb.fig1.model.eqn", package = "MPTinR")
check.mpt(model1.eqn)



#models of example 2 from example(fit.mpt)
model2 &lt;- system.file("extdata", "rb.fig2.model", package = "MPTinR")
check.mpt(model2)

model2r.r.eq &lt;- system.file("extdata", "rb.fig2.r.equal", package = "MPTinR")
check.mpt(model2, model2r.r.eq)

model2r.c.eq &lt;- system.file("extdata", "rb.fig2.c.equal", package = "MPTinR")
check.mpt(model2, model2r.c.eq)

</code></pre>

<hr>
<h2 id='d.broeder'>
Broeder &amp; Schuetz (2009) Experiment 3
</h2><span id='topic+d.broeder'></span>

<h3>Description</h3>

<p>The data from Broeder &amp; Schuetz (2009) Experiment 3, used as an example in MPTinR
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(d.broeder)</code></pre>


<h3>References</h3>

<p>Broeder, A., &amp; Schuetz, J. (2009). Recognition ROCs are curvilinear-or are they? On premature arguments against the two-high-threshold model of recognition. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, 35(3), 587. doi:10.1037/a0015279
</p>

<hr>
<h2 id='fit.model'>
Fit cognitive models for categorical data using model files
</h2><span id='topic+fit.model'></span>

<h3>Description</h3>

<p><code>fit.model</code> fits MPT and other cognitive models for categorical data (e.g., SDT models) that can be specified in a model file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
fit.model(
	data,
	model.filename, 
	restrictions.filename = NULL, 
	n.optim = 5,
	fia = NULL,
	ci = 95, 
	starting.values = NULL,
	lower.bound = 0,
	upper.bound = 1,
	output = c("standard", "fia", "full"),
	reparam.ineq = TRUE,
	fit.aggregated = TRUE,
	sort.param = TRUE,
	show.messages = TRUE,
	model.type = c("easy", "eqn", "eqn2"),
	multicore = c("none", "individual", "n.optim", "fia"), sfInit = FALSE, nCPU = 2,
	control = list(),
	use.gradient = TRUE, use.hessian = FALSE, check.model = TRUE, 
    args.fia = list(), numDeriv = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit.model_+3A_data">data</code></td>
<td>

<p>Either a <em>numeric</em> <code>vector</code> for individual fit or a <em>numeric</em> <code>matrix</code> or <code>data.frame</code> for multi-individual fit. The data on each position (column for multi-individual fit) must correspond to the respective line in the model file. Fitting for multiple individuals can be parallelized via <code>multicore</code>.
</p>
</td></tr>
<tr><td><code id="fit.model_+3A_model.filename">model.filename</code></td>
<td>

<p>A character <code>vector</code> specifying the location and name of the model file. 
</p>
</td></tr>
<tr><td><code id="fit.model_+3A_restrictions.filename">restrictions.filename</code></td>
<td>

<p><code>NULL</code> or a character <code>vector</code> or a <code>list</code> of characters. The default is <code>NULL</code> which corresponds to no restrictions. A character <code>vector</code> specifies the location or name of the restrictions file. A <code>list</code> of characters contains the restrictions directly. See Details and Examples.
</p>
</td></tr>
<tr><td><code id="fit.model_+3A_n.optim">n.optim</code></td>
<td>

<p>Number of optimization runs. Can be parallelized via <code>multicore</code>. Default is 5. If the number is high, fitting can take long time for <em>large</em> models.
</p>
</td></tr>
<tr><td><code id="fit.model_+3A_fia">fia</code></td>
<td>

<p>Number of random samples to be drawn in the Monte Carlo algorithm to estimate the Fisher Information Approximation (FIA) for MPTs only. See Details at <code><a href="#topic+fit.mpt">fit.mpt</a></code>
</p>
</td></tr>
<tr><td><code id="fit.model_+3A_ci">ci</code></td>
<td>

<p>A scalar corresponding to the size of the confidence intervals for the parameter estimates. Default is 95 which corresponds to 95% confidence intervals.
</p>
</td></tr>
<tr><td><code id="fit.model_+3A_starting.values">starting.values</code></td>
<td>

<p>A <code>vector</code>, a <code>list</code>, or <code>NULL</code> (the default). If <code>NULL</code> starting values for parameters are randomly drawn from a uniform distribution with the interval <code>(0.1 - 0.9)</code>. See Details for the other options.
</p>
</td></tr>
<tr><td><code id="fit.model_+3A_output">output</code></td>
<td>

<p>If &quot;full&quot; <code>fit.mpt</code> will additionally return the return values of <code><a href="stats.html#topic+nlminb">nlminb</a></code> and the Hessian matrices. (If &quot;fia&quot;, <code>fit.mpt</code> will additionally return the results from <code><a href="#topic+get.mpt.fia">get.mpt.fia</a></code> (if <code>fia</code> not equal <code>NULL</code>).)
</p>
</td></tr>
<tr><td><code id="fit.model_+3A_reparam.ineq">reparam.ineq</code></td>
<td>

<p>Logical. Indicates whether or not inequality restrictions (when present in the model file) should be enforced while fitting the model. If <code>TRUE</code> (the default) inequality restricted parameters will be reparameterized, if <code>FALSE</code> not. Probably irrelevant for none MPTs.
</p>
</td></tr>
<tr><td><code id="fit.model_+3A_fit.aggregated">fit.aggregated</code></td>
<td>

<p>Logical. Only relevant for multiple datasets (i.e., <code>matrix</code> or <code>data.frame</code>). Should the aggregated dataset (i.e., data summed over rows) be fitted? Default (<code>TRUE</code>) fits the aggregated data. 
</p>
</td></tr>
<tr><td><code id="fit.model_+3A_sort.param">sort.param</code></td>
<td>

<p>Logical. If TRUE, parameters are alphabetically sorted in the parameter table. If FALSE, the first parameters in the parameter table are the non-restricted ones, followed by the restricted parameters. Default is TRUE.
</p>
</td></tr>
<tr><td><code id="fit.model_+3A_show.messages">show.messages</code></td>
<td>

<p>Logical. If TRUE the time the fitting algorithms takes is printed to the console.
</p>
</td></tr>
<tr><td><code id="fit.model_+3A_model.type">model.type</code></td>
<td>

<p>Character vector specifying whether the model file is formatted in the easy way (<code>"easy"</code>; i.e., each line represents all branches corresponding to a response category) or the traditional EQN syntax (<code>"eqn"</code> or <code>"eqn2"</code>; see Details and e.g., Stahl &amp; Klauer, 2007). If <code>model.filename</code> ends with .eqn or .EQN, <code>model.type</code> is automatically set to <code>"eqn"</code>. Default is <code>"easy"</code>.
</p>
</td></tr>
<tr><td><code id="fit.model_+3A_multicore">multicore</code></td>
<td>

<p>Character vector. If not <code>"none"</code>, uses <code>snowfall</code> for parallelization (which needs to be installed separately via <code>install.packages(snowfall)</code>). If <code>"individual"</code>, parallelizes the optimization for each individual (i.e., data needs to be a <code>matrix</code> or <code>data.frame</code>). If <code>"n.optim"</code>, parallelizes the <code>n.optim</code> optimization runs. If not <code>"none"</code> (e.g., <code>"fia"</code>) calculation of FIA is parallelized (if FIA is requested). Default is <code>"none"</code> which corresponds to no parallelization. Note that you need to initialize <code>snowfall</code> in default settings. See <code>sfInit</code> and Details.
</p>
</td></tr>
<tr><td><code id="fit.model_+3A_sfinit">sfInit</code></td>
<td>

<p>Logical. Relevant if <code>multicore</code> is not <code>"none"</code>. If <code>TRUE</code>, <code>fit.mpt</code> will initialize and close the multicore support. If <code>FALSE</code>, (the default) assumes that <code>sfInit()</code> was initialized before. See Details.
</p>
</td></tr>
<tr><td><code id="fit.model_+3A_ncpu">nCPU</code></td>
<td>

<p>Scalar. Only relevant if <code>multicore</code> is not <code>"none"</code> and <code>sfInit</code> is TRUE. Number of CPUs used by <code>snowfall</code>. Default is 2.
</p>
</td></tr>
<tr><td><code id="fit.model_+3A_lower.bound">lower.bound</code></td>
<td>

<p>numeric scalar or vector. Can be used in <code>fit.model</code> to set the lower bounds of the parameter space. See Details.
</p>
</td></tr>
<tr><td><code id="fit.model_+3A_upper.bound">upper.bound</code></td>
<td>

<p>numeric scalar or vector. Can be used in <code>fit.model</code> to set the upper bounds of the parameter space. See Details.
</p>
</td></tr>
<tr><td><code id="fit.model_+3A_control">control</code></td>
<td>

<p>list containing control arguments passed on to <code><a href="stats.html#topic+nlminb">nlminb</a></code>. See there.
</p>
</td></tr>
<tr><td><code id="fit.model_+3A_use.gradient">use.gradient</code></td>
<td>

<p>logical. Whether or not the symbolically derived function returning the gradient should be used for fitting. Default is <code>TRUE</code> meaning gradient function is used.
</p>
</td></tr>
<tr><td><code id="fit.model_+3A_use.hessian">use.hessian</code></td>
<td>

<p>logical. Whether or not the symbolically derived function returning the Hessian matrix should be used for fitting. Default is <code>FALSE</code> meaning hessian function is not used.
</p>
</td></tr>
<tr><td><code id="fit.model_+3A_check.model">check.model</code></td>
<td>

<p>logical. Should model be checked with random values whether or not the expected values sum to one per tree? Default is <code>TRUE</code>. (This also controls whether other model checks during optimization are performed. If <code>FALSE</code> the most permissive fitting is performed.)
</p>
</td></tr>
<tr><td><code id="fit.model_+3A_args.fia">args.fia</code></td>
<td>

<p>named list of further arguments passed to <code><a href="#topic+get.mpt.fia">get.mpt.fia</a></code>, such as <code>mConst</code> to avoid numerical problems in the FIA function.
</p>
</td></tr>
<tr><td><code id="fit.model_+3A_numderiv">numDeriv</code></td>
<td>

<p>logical. Should the Hessian matrix of the maximum likelihood estimates be estimated numerically using <code>numDeriv::hessian</code> in case it cannot be estimated analytically? This can be extremely time and memory consuming for larger models. Default is TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This functions should be used when fitting a model that is not an MPT model or when fitting using <code>fit.mpt</code> fails. For fitting MPT models and information on fitting MPT models see <code><a href="#topic+fit.mpt">fit.mpt</a></code>.
</p>
<p>The model file for non-MPT models should be of the <code>easy</code> format. That is the ordinal number or rank of each line should correspond to this column/position in the data object. Model files can contain any visible function (i.e., including self-defined functions). However, note that the derivation that is needed for the gradient and Hessian function can only be done for those functions that <code><a href="stats.html#topic+D">D</a></code> can handle. If derivation fails a warning will be given and fitting will be done without gradient and/or Hessian function.
</p>
<p>Equations that correspond to one item type/category must be not be separated by an empty line. Equations that do not correspond to the same item type/category must be separated by at least one empty line.
</p>
<p>Note that names of parameters in the model file should NOT start with <code>hank</code>. Variables with these names can lead to unforeseen problems as variables starting with these letters are internally used.
</p>
<p>The restrictions file may contain (sequential) equality (i.e., =) and inequality (i.e., &lt;) restrictions (see <code><a href="#topic+fit.mpt">fit.mpt</a></code> for more general info on the restrictions files). Note that inequality restrictions usually will lead to catastrophic results when used for non-MPT models. Our recommendation: Do never use inequality restrictions for non-MPT models. Equality restrictions or fixing parameters should be no problem though.
</p>
<p>For equality restrictions, the equality restricted parameters are simply exchanged with their restrictions (i.e., another parameter or a number) before the fitting.
</p>
<p>Restrictions or model files can contain comments (i.e., everything to the right of a # will be ignored; new behavior since version 0.9.2)
</p>
<p>Both models and restrictions can be specified as <code><a href="base.html#topic+textConnection">textConnection</a></code>s instead of as external files (see examples). Note that textConnections get &quot;consumed&quot; so you may need to specify them each time you fit a model using a connection (see <code>Examples</code> for how to avoid this).
</p>
<p>Confidence intervals (CI) are based on the Hessian matrix produced by the symbolically derived function for the Hessian (i.e., the second derivative of the likelihood function). If it is based on a numerically estimated Hessian, a warning will be given. <br />
</p>
<p>To set the starting values for the fitting process (e.g., to avoid local minima) one can set <code>starting.values</code> to a vector of length 2 and <code>n.optim &gt; 1</code>. Then, starting values are randomly drawn from a uniform distribution from <code>starting.values[1]</code> to <code>starting.values[2]</code>.
</p>
<p>Alternatively, one can supply a list with two elements to <code>starting.values</code>. Both elements need to be either of length 1 or of length equal to the number of parameters (if both are of length 1, it is the same as if you supply a vector of length 2). For each parameter n (in alphabetical order), a starting value is randomly drawn from a uniform distribution <code>starting.values[[1]][n]</code> to <code>starting.values[[2]][n]</code> (if length is 1, this is the border for all parameters).
</p>
<p>The least interesting option is to specify the starting values individually by supplying a vector with the same length as the number of parameters. Starting values must be ordered according to the alphabetical order of the parameter names. Use <code><a href="#topic+check.mpt">check.mpt</a></code> for a function that returns the alphabetical order of the parameters. If one specifies the starting values like that, <code>n.optim</code> will be set to 1 as all other values would not make any sense (the optimization routine will produce identical results with identical starting values).
</p>
<p>The <code>lower.bound</code> and <code>upper.bound</code> needs to be of length 1 or equal to the number of <code>free</code> parameters. If length &gt; 1, parameters are mapped to the bounds in alphabetic order of the parameters. Use <code><a href="#topic+check.mpt">check.mpt</a></code> to obtain the alphabetical order of parameters for your model.
</p>
<p>This function is basically a comfortable wrapper for <code><a href="#topic+fit.mptinr">fit.mptinr</a></code> producing the appropriate objective, gradient, hessian, and prediction function from the model equations (passed via <code>model.filename</code>) whilst allowing for custom lower or upper bounds on the parameters. You can specify whether or not gradient or hessian function should be used for fitting with <code>use.gradient</code> or <code>use.hessian</code>, respectively.
</p>
<p>Multicore fitting is achieved via the <code>snowfall</code> package and needs to be initialized via <code>sfInit</code>. As initialization needs some time, you can either initialize multicore facilities yourself using <code>sfInit()</code> and setting the <code>sfInit</code> argument to <code>FALSE</code> (the default) or let MPTinR initialize multicore facilities by setting the <code>sfInit</code> argument to <code>TRUE</code>. The former is recommended as initializing <code>snowfall</code> takes some time and only needs to be done once if you run <code>fit.mpt</code> multiple times. If there are any problems with multicore fitting, first try to initialize <code>snowfall</code> outside MPTinR (e.g., <code>sfInit( parallel=TRUE, cpus=2 )</code>). If this does not work, the problem is not related to MPTinR but to snowfall (for support and references visit: <a href="https://www.imbi.uni-freiburg.de/parallel/">https://www.imbi.uni-freiburg.de/parallel/</a>).<br />
Note that you should <em>close</em> snowfall via <code>sfStop()</code> after using MPTinR.
</p>


<h3>Value</h3>

<p>For individual fits (i.e., <code>data</code> is a <code>vector</code>) a <code>list</code> containing one or more of the following components from the best fitting model:
</p>
<table>
<tr><td><code>goodness.of.fit</code></td>
<td>
<p>A <code>data.frame</code> containing the goodness of fit values for the model. <code>Log.Likelihood</code> is the Log-Likelihood value. <code>G.Squared</code>, <code>df</code>, and <code>p.value</code> are the <code class="reqn">G^2</code> goodness of fit statistic.</p>
</td></tr>
<tr><td><code>information.criteria</code></td>
<td>
<p>A <code>data.frame</code> containing model information criteria based on the <code class="reqn">G^2</code> value. The FIA values(s) are presented if <code>fia</code> is not <code>NULL</code>.</p>
</td></tr>
<tr><td><code>model.info</code></td>
<td>
<p>A <code>data.frame</code> containing other information about the model. If the rank of the Fisher matrix (<code>rank.fisher</code>) <em>does not</em> correspond to the number of parameters in the model (<code>n.parameters</code>) this indicates a serious issue with the identifiability of the model. A common reason is that one of the parameter estimates lies on the bound of the parameter space (i.e., 0 or 1).</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>
<p>A data.frame containing the parameter estimates and corresponding confidence intervals. If a restriction file was present, the restricted parameters are marked.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>A <code>list</code> of two matrices; the first one (<code>observed</code>) contains the entered data, the second one (<code>predicted</code>) contains the predicted values.</p>
</td></tr>
</table>
<p>For multi-dataset fits (i.e., <code>data</code> is a <code>matrix</code> or <code>data.frame</code>) a <code>list</code> with similar elements, but the following differences:<br />
The first elements, <code>goodness.of.fit</code>, <code>information.criteria</code>, and <code>model.info</code>, contain the same information as for individual fits, but each are <code>lists</code> with three elements containing the respective values for: each individual in the list element <code>individual</code>, the sum of the individual values in the list element <code>sum</code>, and the values corresponding to the fit for the aggregated data in the list element <code>aggregated</code>.<br />
<code>parameters</code> is a list containing:
</p>
<table>
<tr><td><code>individual</code></td>
<td>
<p>A 3-dimensional array containing the parameter estimates ([,1,]), confidence intervals [,2:3,], and, if restrictions not <code>NULL</code>, column 4 [,4,] is 0 for non-restricted parameters, 1 for equality restricted parameters, and 2 for inequality restricted parameters. The first dimension refers to the parameters, the second to the information on each parameter, and the third to the individual/dataset.</p>
</td></tr>
<tr><td><code>mean</code></td>
<td>
<p>A <code>data.frame</code> with the mean parameter estimates from the individual estimates. No confidence intervals can be provided for these values.</p>
</td></tr>
<tr><td><code>aggregated</code></td>
<td>
<p>A data.frame containing the parameter estimates and corresponding confidence intervals for the aggregated data. If a restriction file was present, the restricted parameters are marked.</p>
</td></tr>
</table>
<p>The element <code>data</code> contains two matrices, one with the <code>observed</code>, and one with the <code>predicted</code> data (or is a list containing lists with <code>individual</code> and <code>aggregated</code> <code>observed</code> and <code>predicted</code> data).
</p>
<p>If <code>n.optim</code> &gt; 1, the <code><a href="base.html#topic+summary">summary</a></code> of the vector (matrix for multi-individual fit) containing the Log-Likelihood values returned by each run of <code>optim</code> is added to the output: <code>fitting.runs</code>
</p>
<p>When <code>output == "full"</code> the list contains the additional items:<br />
</p>
<table>
<tr><td><code>optim.runs</code></td>
<td>
<p>A list (or list of lists for multiple datasets) containing the outputs from all runs by <code>nlminb</code> (including those runs produced when fitting did not converge)</p>
</td></tr>
<tr><td><code>best.fits</code></td>
<td>
<p>A list (or list of lists for multiple datasets) containing the outputs from the runs by <code>nlminb</code> that had the lowest likelihood (i.e., the successful runs)</p>
</td></tr>
<tr><td><code>hessian</code></td>
<td>
<p>A list  containing the Hessian matrix or matrices of the final parameter estimates.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Warnings may relate to the optimization routine (e.g., <code>Optimization routine [...] did not converge successfully</code>).<br />
In these cases it is recommended to rerun the model fitting to check if the results are stable.
</p>
<p>The likelihood returned does not include the factorial constants of the multinomial probability-mass functions.
</p>
<p>All (model or restriction) files should end with an empty line, otherwise a warning will be shown.
</p>


<h3>Author(s)</h3>

<p>Henrik Singmann and David Kellen.
</p>


<h3>References</h3>

<p>Broeder, A., &amp; Schuetz, J. (2009). Recognition ROCs are curvilinear-or are they? On premature arguments against the two-high-threshold model of recognition. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, 35(3), 587. doi:10.1037/a0015279
</p>
<p>Wickens, T. D. (2002). <em>Elementary Signal Detection Theory</em>. Oxford; New York: Oxford University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+check.mpt">check.mpt</a></code> for a function that can help in constructing models.
</p>
<p><code><a href="#topic+fit.mptinr">fit.mptinr</a></code> for a function that can fit arbitrary objective functions.
</p>
<p><code><a href="#topic+fit.mpt">fit.mpt</a></code> for the function to fit MPTs (it should be slightly faster for MPTs).
</p>
<p><a href="#topic+roc6">roc6</a> for more examples fitting different SDT models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

#####################################
## Fit response-bias or payoff ROC ##
#####################################
  
# Example from Broder &amp; Schutz (2009)
# We fit the data from the 40 individuals from their Experiment 3
# We fit three different models:
# 1. Their SDT Model: br.sdt
# 2. Their 2HTM model: br.2htm
# 3. A restricted 2HTM model with Dn = Do: br.2htm.res
# 4. A 1HTM model (i.e., Dn = 0): br.1htm

data(d.broeder, package = "MPTinR")
m.2htm &lt;- system.file("extdata", "5points.2htm.model", package = "MPTinR")


# We specify the SDT model in the code using a textConnection.
# However, textConnection is only called in the function call on the string.

m.sdt &lt;- "
1-pnorm((cr1-mu)/ss)
pnorm((cr1-mu)/ss)

1-pnorm(cr1)
pnorm(cr1)

1-pnorm((cr2-mu)/ss)
pnorm((cr2-mu)/ss)

1-pnorm(cr2)
pnorm(cr2)

1-pnorm((cr3-mu)/ss)
pnorm((cr3-mu)/ss)

1-pnorm(cr3)
pnorm(cr3)

1-pnorm((cr4-mu)/ss)
pnorm((cr4-mu)/ss)

1-pnorm(cr4)
pnorm(cr4)

1-pnorm((cr5-mu)/ss)
pnorm((cr5-mu)/ss)

1-pnorm(cr5)
pnorm(cr5)
"

# How does the model look like?
check.mpt(textConnection(m.sdt))

# fit the SDT (unequal variance version)
br.uvsdt &lt;- fit.model(d.broeder, textConnection(m.sdt), 
  		lower.bound = c(rep(-Inf, 5), 0, 1), upper.bound = Inf)

# Is there any effect of studying the items?
br.uvsdt.2 &lt;- fit.model(d.broeder, textConnection(m.sdt), 
			restrictions.filename = list("mu = 0", "ss = 1"), 
			lower.bound = -Inf, upper.bound = Inf)

(diff.g2 &lt;- br.uvsdt.2[["goodness.of.fit"]][["sum"]][["G.Squared"]] -
			br.uvsdt[["goodness.of.fit"]][["sum"]][["G.Squared"]])
(diff.df &lt;- br.uvsdt.2[["goodness.of.fit"]][["sum"]][["df"]] - 
			br.uvsdt[["goodness.of.fit"]][["sum"]][["df"]])
1 - pchisq(diff.g2, diff.df)

# fit the equal variance SDT model:
br.evsdt &lt;- fit.model(d.broeder, textConnection(m.sdt), 
			lower.bound = c(rep(-Inf, 5), 0), upper.bound = Inf, 
			restrictions.filename = list("ss = 1"))

# fit the MPTs (see also ?fit.mpt).
# In contrast to ?fit.mpt we specify the restrictions using a textConnection or a list!
br.2htm &lt;- fit.mpt(d.broeder, m.2htm)
br.2htm.res &lt;- fit.mpt(d.broeder, m.2htm, textConnection("Do = Dn"))
br.1htm &lt;- fit.mpt(d.broeder, m.2htm, list("Dn = 0"))

select.mpt(list(uvsdt = br.uvsdt, evsdt = br.evsdt, two.htm = br.2htm, 
			two.htm.res = br.2htm.res, one.htm = br.1htm), output = "full")

# the restricted 2HTM "wins" for individual data (although evsdt does not perform too bad),
# but the 2htm and restricted 2htm restricted "win" for aggregated data.


###################################
## Fit confidence rating ROC SDT ##
###################################
#(see ?roc6 for more examples)

# We fit example data from Wickens (2002, Chapter 5)
# The example data is from Table 5.1, p. 84
# (data is entered in somewhat different order).

# Note that criteria are defined as increments to 
# the first (i.e., leftmost) criterion!
# This is the only way to do it in MPTinR.

# Data
dat &lt;- c(47, 65, 66, 92, 136, 294, 166, 161, 138, 128, 63, 43)

# UVSDT
m.uvsdt &lt;- "
pnorm(cr1, mu, sigma)
pnorm(cr1+cr2, mu, sigma) - pnorm(cr1, mu, sigma)
pnorm(cr3+cr2+cr1, mu, sigma) - pnorm(cr2+cr1, mu, sigma)
pnorm(cr4+cr3+cr2+cr1, mu, sigma) - pnorm(cr3+cr2+cr1, mu, sigma)
pnorm(cr5+cr4+cr3+cr2+cr1, mu, sigma) - pnorm(cr4+cr3+cr2+cr1, mu, sigma)
1 - pnorm(cr5+cr4+cr3+cr2+cr1, mu, sigma)
  
pnorm(cr1)
pnorm(cr2+cr1) - pnorm(cr1)
pnorm(cr3+cr2+cr1) - pnorm(cr2+cr1)
pnorm(cr4+cr3+cr2+cr1) - pnorm(cr3+cr2+cr1)
pnorm(cr5+cr4+cr3+cr2+cr1) - pnorm(cr4+cr3+cr2+cr1)
1 - pnorm(cr5+cr4+cr3+cr2+cr1)
"
check.mpt(textConnection(m.uvsdt))

# Model fitting
(cr_sdt &lt;- fit.model(dat, textConnection(m.uvsdt),
            lower.bound=c(-Inf, rep(0, 5), 0.1), upper.bound=Inf))

# To obtain the criteria (which match those in Wickens (2002, p. 90)
# obtain the cumulative sum:

cumsum(cr_sdt$parameters[paste0("cr",1:5), 1, drop = FALSE])


## End(Not run)

</code></pre>

<hr>
<h2 id='fit.mpt'>
Function to fit MPT models
</h2><span id='topic+fit.mpt'></span>

<h3>Description</h3>

<p><code>fit.mpt</code> fits <em>binary</em> multinomial processing tree models (MPT models; e.g., Riefer &amp; Batchelder, 1988) from an external model file and (optional) external restrictions using the general-purpose quasi-Newton box-constraint optimization routine provided by Byrd et al. (1995). Additionally, measures for model selection (AIC, BIC, FIA) can be computed. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit.mpt(
	data,
	model.filename, 
	restrictions.filename = NULL, 
	n.optim = 5,
	fia = NULL,
	ci = 95, 
	starting.values = NULL,
	output = c("standard", "fia", "full"),
	reparam.ineq = TRUE,
	fit.aggregated = TRUE,
	sort.param = TRUE,
	show.messages = TRUE,
	model.type = c("easy", "eqn", "eqn2"),
	multicore = c("none", "individual", "n.optim", "fia"), sfInit = FALSE, nCPU = 2,
	control = list(), args.fia = list(), numDeriv = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit.mpt_+3A_data">data</code></td>
<td>

<p>Either a <em>numeric</em> <code>vector</code> for individual fit or a <em>numeric</em> <code>matrix</code> or <code>data.frame</code> for multi-individual fit. The data on each position (column for multi-individual fit) must correspond to the respective line in the model file. For EQN model files, the required order is given by an alphabetic ordering of first model names than categories. This order in terms of the names in the EQN file can be obtained through <code><a href="#topic+check.mpt">check.mpt</a></code>. Fitting for multiple individuals can be parallelized via <code>multicore</code>.
</p>
</td></tr>
<tr><td><code id="fit.mpt_+3A_model.filename">model.filename</code></td>
<td>

<p>A character <code>vector</code> specifying the location and name of the model file. 
</p>
</td></tr>
<tr><td><code id="fit.mpt_+3A_restrictions.filename">restrictions.filename</code></td>
<td>

<p><code>NULL</code> or a character <code>vector</code> or a <code>list</code> of characters. The default is <code>NULL</code> which corresponds to no restrictions. A character <code>vector</code> specifies the location or name of the restrictions file. A <code>list</code> of characters contains the restrictions directly. See Details and Examples.
</p>
</td></tr>
<tr><td><code id="fit.mpt_+3A_n.optim">n.optim</code></td>
<td>

<p>Number of optimization runs. Can be parallelized via <code>multicore</code>. Default is 5. If the number is high, fitting can take long for <em>large</em> models.
</p>
</td></tr>
<tr><td><code id="fit.mpt_+3A_fia">fia</code></td>
<td>

<p>Number of random samples to be drawn in the Monte Carlo algorithm to estimate the Fisher Information Approximation (FIA), a minimum description length based measure of model complexity (see Wu, Myung &amp; Batchelder, 2010). The default is <code>NULL</code> which corresponds to no computation of the FIA. Reasonable values (e.g., &gt; 200000) can lead to long computation times (minutes to hours) depending on the size of the model. See Details.
</p>
</td></tr>
<tr><td><code id="fit.mpt_+3A_ci">ci</code></td>
<td>

<p>A scalar corresponding to the size of the confidence intervals for the parameter estimates. Default is 95 which corresponds to 95% confidence intervals.
</p>
</td></tr>
<tr><td><code id="fit.mpt_+3A_starting.values">starting.values</code></td>
<td>

<p>A <code>vector</code>, a <code>list</code>, or <code>NULL</code> (the default). If <code>NULL</code> starting values for parameters are randomly drawn from a uniform distribution with the interval <code>(0.1 - 0.9)</code>. See Details of <code><a href="#topic+fit.mptinr">fit.mptinr</a></code> for the other options.
</p>
</td></tr>
<tr><td><code id="fit.mpt_+3A_output">output</code></td>
<td>

<p>If &quot;fia&quot;, <code>fit.mpt</code> will additionally return the results from <code><a href="#topic+get.mpt.fia">get.mpt.fia</a></code> (if <code>fia</code> not equal <code>NULL</code>). If &quot;full&quot; <code>fit.mpt</code> will additionally return the results from <code><a href="#topic+get.mpt.fia">get.mpt.fia</a></code> and the output of <code><a href="stats.html#topic+nlminb">nlminb</a></code> and the Hessian matrix/matrices.
</p>
</td></tr>
<tr><td><code id="fit.mpt_+3A_reparam.ineq">reparam.ineq</code></td>
<td>

<p>Logical. Indicates whether or not inequality restrictions (when present in the model file) should be enforced while fitting the model. If <code>TRUE</code> (the default) inequality restricted parameters will be reparameterized, if <code>FALSE</code> not. See Details.
</p>
</td></tr>
<tr><td><code id="fit.mpt_+3A_fit.aggregated">fit.aggregated</code></td>
<td>

<p>Logical. Only relevant for multiple datasets (i.e., <code>matrix</code> or <code>data.frame</code>). Should the aggregated dataset (i.e., data summed over rows) be fitted? Default (<code>TRUE</code>) fits the aggregated data. 
</p>
</td></tr>
<tr><td><code id="fit.mpt_+3A_sort.param">sort.param</code></td>
<td>

<p>Logical. If TRUE, parameters are alphabetically sorted in the parameter table. If FALSE, the first parameters in the parameter table are the non-restricted ones, followed by the restricted parameters. Default is TRUE.
</p>
</td></tr>
<tr><td><code id="fit.mpt_+3A_show.messages">show.messages</code></td>
<td>

<p>Logical. If TRUE the time the fitting algorithms takes is printed to the console.
</p>
</td></tr>
<tr><td><code id="fit.mpt_+3A_model.type">model.type</code></td>
<td>

<p>Character vector specifying whether the model file is formatted in the easy way (<code>"easy"</code>; i.e., each line represents all branches corresponding to a response category) or the traditional EQN syntax (<code>"eqn"</code> or <code>"eqn2"</code>; see Details and e.g., Stahl &amp; Klauer, 2007). If <code>model.filename</code> ends with .eqn or .EQN, <code>model.type</code> is automatically set to <code>"eqn"</code>. Default is <code>"easy"</code>.
</p>
</td></tr>
<tr><td><code id="fit.mpt_+3A_multicore">multicore</code></td>
<td>

<p>Character vector. If not <code>"none"</code>, uses <code>snowfall</code> for parallelization (which needs to be installed separately via <code>install.packages(snowfall)</code>). If <code>"individual"</code>, parallelizes the optimization for each individual (i.e., data needs to be a <code>matrix</code> or <code>data.frame</code>). If <code>"n.optim"</code>, parallelizes the <code>n.optim</code> optimization runs. If not <code>"none"</code> (e.g., <code>"fia"</code>) calculation of FIA is parallelized (if FIA is requested). Default is <code>"none"</code> which corresponds to no parallelization. Note that you need to initialize <code>snowfall</code> in default settings. See <code>sfInit</code> and Details.
</p>
</td></tr>
<tr><td><code id="fit.mpt_+3A_sfinit">sfInit</code></td>
<td>

<p>Logical. Relevant if <code>multicore</code> is not <code>"none"</code>. If <code>TRUE</code>, <code>fit.mpt</code> will initialize and close the multicore support. If <code>FALSE</code>, (the default) assumes that <code>sfInit()</code> was initialized before. See Details.
</p>
</td></tr>
<tr><td><code id="fit.mpt_+3A_ncpu">nCPU</code></td>
<td>

<p>Scalar. Only relevant if <code>multicore</code> is not <code>"none"</code> and <code>sfInit</code> is TRUE. Number of CPUs used by <code>snowfall</code>. Default is 2.
</p>
</td></tr>
<tr><td><code id="fit.mpt_+3A_control">control</code></td>
<td>

<p>list containing control arguments passed on to <code><a href="stats.html#topic+nlminb">nlminb</a></code>. See there.
</p>
</td></tr>
<tr><td><code id="fit.mpt_+3A_args.fia">args.fia</code></td>
<td>

<p>named list of further arguments passed to <code><a href="#topic+get.mpt.fia">get.mpt.fia</a></code>, such as <code>mConst</code> to avoid numerical problems in the FIA function.
</p>
</td></tr>
<tr><td><code id="fit.mpt_+3A_numderiv">numDeriv</code></td>
<td>

<p>logical. Should the Hessian matrix of the maximum likelihood estimates be estimated numerically using <code>numDeriv::hessian</code> in case it cannot be estimated analytically? This can be extremely time and memory consuming for larger models. Default is TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model file is either of the easy format or the &quot;classical&quot; EQN format (see below).<br />
In the easy format (the default) the model file contains all trees of the model. Trees are separated by at least one empty line. Everything to the right of a hash (#) is ignored (this behavior is new since version 0.9.2). Lines starting with a # are treated as empty. Each line in each tree corresponds to all branches of this tree (concatenated by a +) that correspond to one of the possible response categories. The position of each line must correspond to the position of this response category in the data object (for multi-individual fit to the respective column).
</p>
<p>For EQN model files the order of the data does NOT correspond to the order in the model file, but to the order given by first sorting the tree names alphabetically/numerically and than the category names within the trees. As this is often difficult to see if the EQN files contains names and not numbers for trees and categories, <code><a href="#topic+check.mpt">check.mpt</a></code> returns the order of both trees and categories for EQN model files.
</p>
<p>The difference between both types of EQN format (<code>"eqn"</code> or<code>"eqn2"</code>) is the way the first line of the model file is treated. If <code>model.file</code> is set to <code>"eqn"</code>, <code>MPTinR</code> will ignore the first line of the model file and will read the rest of the file (as does multiTree; Moshagen, 2010). If <code>model.file</code> is set to <code>"eqn2"</code> MPTinR will only read as many lines as indicated in the first line of the EQN model file (as does e.g., HMMTree; Stahl &amp; Klauer, 2007). As default <code>fit.mpt</code> expects the easy format, but if the filename ends with .eqn or .EQN and <code>model.type</code> is <code>"easy"</code>, <code>model.type</code> is set to <code>"eqn"</code><br />
For the EQN format consult one of the corresponding papers (see e.g., Moshagen, 2010; Stahl &amp; Klauer, 2007). The positions in the data object (number of column for multi-individual fit) must correspond to the category number in the EQN file.<br />
</p>
<p>Note that names of parameters in the model file should not start with <code>hank.</code>. Variables with these names can lead to unforeseen problems as variables starting with these letters are internally used. Furthermore, any <code><a href="base.html#topic+reserved">reserved</a></code> names (e.g., <code>NA</code>) are not allowed in model files of any types (i.e., also not as category labels in .eqn files). All names in models need to be valid R variable names (see <code><a href="base.html#topic+make.names">make.names</a></code>).
</p>
<p>The restrictions file may contain (sequential) equality (i.e., =) and inequality (i.e., &lt;) restrictions and must adhere to the following rules:<br />
1. Inequalities first.<br />
2. If a variable appears in an inequality restriction, it can not be on the left hand side (LHS) of any further restriction.<br />
3. If a variable appears on the right hand side (RHS) of an equality restriction, it can not appear on LHS of an equality restriction.<br />
Note that only &quot;&lt;&quot; is supported as inequality operator but not &quot;&gt;&quot;!<br />
Examples of restrictions are (the following could all appear in one restrictions file):<br />
<code>D1 &lt; D2 &lt; D3</code><br />
<code>D4 = D3</code><br />
<code>B1 = B3 = 0.3333</code><br />
<code>X4 = X5 = D3</code><br />
Restrictions file may contain comments (i.e., everything to the right of a # will be ignored; new behavior since version 0.9.2)
</p>
<p>Restrictions can also be specified in line as a list. The same restrictions as the one above as a <code>list</code> would be <code>list("D1 &lt; D2 &lt; D3", "D4 = D3", "B1 = B3 = 0.3333", "X4 = X5 = D3")</code> (simply use this <code>list</code> as the <code>restrictions.filename</code> argument).
</p>
<p>For equality restrictions, the equality restricted parameters are simply exchanged with their restrictions before the fitting.<br />
For inequality restricted parameters, the model is reparameterized so that only the rightmost parameter of an inequality restriction remains the original parameter. Each instance of the other parameters in this restriction is replaced by the product of the rightmost parameter and dummy parameters (see Knapp &amp; Batchelder, 2004). This procedure (which is equivalent to method A described in Knapp &amp; Batchelder, 2004) leads to an equivalent model (although the binary MPT structure is not apparent in the resulting equations).<br />
To prohibit this reparameterization (i.e., if the inequality restrictions hold without reparameterization), you can set <code>reparam.ineq</code> to <code>FALSE</code>. This can be useful for obtaining the FIA (see examples in Wu, Myung, &amp; Batchelder, 2010).
</p>
<p>Both models and restrictions can be specified as <code><a href="base.html#topic+textConnection">textConnection</a></code>s instead of as external files.<br />
Furthermore, restrictions can be specified directly as a <code>list</code> containing the restrictions (quoted, i.e. as characters).<br />
<code><a href="#topic+fit.model">fit.model</a></code> contains additional examples showing model and restrictions specification within the code.
</p>
<p>Note that when setting some parameters equal and also restricting their order, the parameters set equal which are not the rightmost element in the order (i.e., inequality) restriction, are computed correctly, but are marked as inequality restricted instead of equality restricted in the output (this did not work at all before v1.0.1). An example: For the restrictions <code>list("G2 &lt; G3 &lt; G5", "G1 = G2", "G4 = G5")</code>, <code>G1</code> would be computed correctly, but marked as inequality restricted. In contrast, <code>G4</code> would be marked as equal to <code>G5</code> (and also computed correctly).
</p>
<p>To obtain a measure of the model's complexity beyond the number of parameters (and taking inequality restrictions into account), set <code>fia</code> to a (reasonably high) scalar integer (i.e., a number). Then, <code>fit.mpt</code> will obtain the Fisher Information Approximation (FIA), a Minimum Description Length (MDL) based measure of model complexity, using the algorithm provided by Wu, Myung, &amp; Batchelder (2010a, 2010b) ported from Matlab to R. When performing model-selection, this measure is superior to other methods such as the Akaike Information Criterion (AIC) or Bayesian Information Criterion (BIC) which basically only take the number of parameters into account.<br />
To get the FIA, <code>fit.mpt</code> performs the following steps:<br />
1. The representation of the model as equations is transformed into the string representation of the model in the context-free language of MPT models (L-BMPT; Purdy &amp; Batchelder, 2009). For this step to be successful it is <em>absolutely necessary</em> that the equations representing the model perfectly map the tree structure of the MPT. That is, the model file is only allowed to contain parameters, their inverse (e.g., <code>Dn</code> and <code>(1 - Dn)</code>) and the operators + and *, but nothing else. Simplifications of the equations will seriously distort this step. Similarly, unnecessary brackets will distort the results. Brackets must only be used to indicate the inverse of a parameter (i.e. (1 - parameter)). This step is achieved by <code><a href="#topic+make.mpt.cf">make.mpt.cf</a></code>.<br />
2. The context free representation of the model is then fed into the MCMC function computing the FIA (the port of BMPTFIA provided by Wu, Myung &amp; Batchelder (2010a), see <code><a href="#topic+bmpt.fia">bmpt.fia</a></code>).<br />
(Actually, both steps are achieved by a call to <code><a href="#topic+get.mpt.fia">get.mpt.fia</a></code>)
</p>
<p>Note that FIA can sometimes be non-consistent (i.e., larger FIA penalty values for restricted versions of a model than for the superordinate model; see Navarro, 2004). This may specifically happens for small ns and is for example the case for the Broder &amp; Schutz example below. In these cases FIA cannot be used! Therefore, always check for consistency of the FIA penalty terms.
</p>
<p>Once again: If one wants to compute the FIA, it is <em>absolutely necessary</em>, that the representation of the model via equations in the model file exactly maps on the structure of the binary MPT (see <code><a href="#topic+make.mpt.cf">make.mpt.cf</a></code> for more details).
</p>
<p>Confidence intervals (CI) are based on the observed Hessian matrix produced by the symbolically derived function for the Hessian (i.e., the second derivative of the likelihood function). If it is based on a numerically estimated Hessian, a warning will be given. <br />
For inequality restricted parameters, the CIs are computed using the parameter estimates' variance bounds (see Baldi &amp; Batchelder, 2003; especially Equation 19). Note that these bounds represent the &quot;worst case scenario&quot; variances, and can lead to CIs outside parameter boundaries if the set of inequalities is large and/or the variances for the reparameterized model are large (Note that CIs for non-restricted parameters can be outside the parameter boundaries as well due to large variances).
</p>
<p>To avoid local minima and instead find the maximum likelihood estimates it is useful to set <code>n.optim</code> &gt; 1 with random starting values (see below). If <code>n.optim</code> &gt; 1, the <code><a href="base.html#topic+summary">summary</a></code> of the vector containing the Log-Likelihood values returned by each run of <code>nlminb</code> is added to the output (to check whether local minima were present). If the model is rather big, <code>n.optim</code> &gt; 1 can be slow.
</p>
<p>Multicore fitting is achieved via the <code>snowfall</code> package and needs to be initialized via <code>sfInit</code>. As initialization needs some time, you can either initialize multicore facilities yourself using <code>sfInit()</code> and setting the <code>sfInit</code> argument to <code>FALSE</code> (the default) or let MPTinR initialize multicore facilities by setting the <code>sfInit</code> argument to <code>TRUE</code>. The former is recommended as initializing <code>snowfall</code> takes some time and only needs to be done once if you run <code>fit.mpt</code> multiple times. If there are any problems with multicore fitting, first try to initialize <code>snowfall</code> outside MPTinR (e.g., <code>sfInit( parallel=TRUE, cpus=2 )</code>). If this does not work, the problem is not related to MPTinR but to snowfall (for support and references visit: <a href="https://www.imbi.uni-freiburg.de/parallel/">https://www.imbi.uni-freiburg.de/parallel/</a>).<br />
Note that you should  <em>close</em> snowfall via <code>sfStop()</code> after using MPTinR.
</p>
<p>The fitting/optimization is achieved via <code><a href="stats.html#topic+nlminb">nlminb</a></code> (Fox, Hall, &amp; Schryer, 1978) a Newton based algorithm using the analytically derived gradient. In some cases (e.g., in case of empty cells) <code>nlminb</code> will not converge successfully in which <code>fit.mpt</code> will retry fitting using a numerically estimated gradient (with warning). 
</p>
<p><code>fit.mpt</code> is just a comfortable wrapper around the workhorse <code><a href="#topic+fit.mptinr">fit.mptinr</a></code>. <code>fit.mpt</code> produces the appropriate objective function, gradient function, hessian function, and prediction function that are handed over to <code>fit.mptinr</code> (functions are produced by symbolical derivation, see <code><a href="stats.html#topic+D">D</a></code>). A function similar to <code>fit.mpt</code> is <code><a href="#topic+fit.model">fit.model</a></code> which has the additional arguments <code>lower.bound</code> and <code>upper.bound</code> allowing to fit other models than just MPTs and the possibility to indicate whether or not to use the analytically derived gradient or hessian for fitting (here this is automatically handled). Note that for MPTs (where upper and lower bounds of parameters are set to 0 and 1, respectively) <code>fit.mpt</code> is probably faster as the objective function is slightly faster (i.e., more optimized). However, for datasets with many empty cells trying <code><a href="#topic+fit.model">fit.model</a></code> with or without gradient or hessian can be worth a try.
</p>
<p>Note that <code><a href="#topic+fit.mptinr">fit.mptinr</a></code> can fit models with arbitrary (i.e., custom) objective functions.
</p>
<p>The old version of this function using <code><a href="stats.html#topic+optim">optim</a></code>'s L-BFGS-B algorithm is <code><a href="#topic+fit.mpt.old">fit.mpt.old</a></code>.
</p>


<h3>Value</h3>

<p>For individual fits (i.e., <code>data</code> is a <code>vector</code>) a <code>list</code> containing one or more of the following components from the best fitting model:
</p>
<table>
<tr><td><code>goodness.of.fit</code></td>
<td>
<p>A <code>data.frame</code> containing the goodness of fit values for the model. <code>Log.Likelihood</code> is the Log-Likelihood value. <code>G.Squared</code>, <code>df</code>, and <code>p.value</code> are the <code class="reqn">G^2</code> goodness of fit statistic.</p>
</td></tr>
<tr><td><code>information.criteria</code></td>
<td>
<p>A <code>data.frame</code> containing model information criteria based on the <code class="reqn">G^2</code> value. The FIA values(s) are presented if <code>fia</code> is not <code>NULL</code>.</p>
</td></tr>
<tr><td><code>model.info</code></td>
<td>
<p>A <code>data.frame</code> containing other information about the model. If the rank of the Fisher matrix (<code>rank.fisher</code>) <em>does not</em> correspond to the number of parameters in the model (<code>n.parameters</code>) this indicates a serious issue with the identifiability of the model. A common reason is that one of the parameter estimates lies on the bound of the parameter space (i.e., 0 or 1).</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>
<p>A data.frame containing the parameter estimates and corresponding confidence intervals. If a restriction file was present, the restricted parameters are marked.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>A <code>list</code> of two matrices; the first one (<code>observed</code>) contains the entered data, the second one (<code>predicted</code>) contains the predicted values.</p>
</td></tr>
</table>
<p>For multi-dataset fits (i.e., <code>data</code> is a <code>matrix</code> or <code>data.frame</code>) a <code>list</code> with similar elements, but the following differences:<br />
The first elements, <code>goodness.of.fit</code>, <code>information.criteria</code>, and <code>model.info</code>, contain the same information as for individual fits, but each are <code>lists</code> with three elements containing the respective values for: each individual in the list element <code>individual</code>, the sum of the individual values in the list element <code>sum</code>, and the values corresponding to the fit for the aggregated data in the list element <code>aggregated</code>.<br />
<code>parameters</code> is a list containing:
</p>
<table>
<tr><td><code>individual</code></td>
<td>
<p>A 3-dimensional array containing the parameter estimates ([,1,]), confidence intervals [,2:3,], and, if restrictions not <code>NULL</code>, column 4 [,4,] is 0 for non-restricted parameters, 1 for equality restricted parameters, and 2 for inequality restricted parameters. The first dimension refers to the parameters, the second to the information on each parameter, and the third to the individual/dataset.</p>
</td></tr>
<tr><td><code>mean</code></td>
<td>
<p>A <code>data.frame</code> with the mean parameter estimates from the individual estimates. No confidence intervals can be provided for these values.</p>
</td></tr>
<tr><td><code>aggregated</code></td>
<td>
<p>A data.frame containing the parameter estimates and corresponding confidence intervals for the aggregated data. If a restriction file was present, the restricted parameters are marked.</p>
</td></tr>
</table>
<p>The element <code>data</code> contains two matrices, one with the <code>observed</code>, and one with the <code>predicted</code> data (or is a list containing lists with <code>individual</code> and <code>aggregated</code> <code>observed</code> and <code>predicted</code> data).
</p>
<p>If <code>n.optim</code> &gt; 1, the <code><a href="base.html#topic+summary">summary</a></code> of the vector (matrix for multi-individual fit) containing the Log-Likelihood values returned by each run of <code>optim</code> is added to the output: <code>fitting.runs</code>
</p>
<p>When <code>output == "full"</code> the list contains the additional items:<br />
</p>
<table>
<tr><td><code>optim.runs</code></td>
<td>
<p>A list (or list of lists for multiple datasets) containing the outputs from all runs by <code>nlminb</code> (including those runs produced when fitting did not converge)</p>
</td></tr>
<tr><td><code>best.fits</code></td>
<td>
<p>A list (or list of lists for multiple datasets) containing the outputs from the runs by <code>nlminb</code> that had the lowest likelihood (i.e., the successful runs)</p>
</td></tr>
<tr><td><code>hessian</code></td>
<td>
<p>A list  containing the Hessian matrix or matrices of the final parameter estimates.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Warnings may relate to the optimization routine (e.g., <code>Optimization routine [...] did not converge successfully</code>).<br />
In these cases it is recommended to rerun fit.mpt to check if the results are stable.
</p>


<h3>Note</h3>

<p>All (model or restriction) files should end with an empty line, otherwise a warning will be shown.
</p>
<p>The likelihood returned does not include the factorial constants of the multinomial probability-mass functions.
</p>


<h3>Author(s)</h3>

<p>Henrik Singmann and David Kellen with help from Karl Christoph Klauer.
</p>


<h3>References</h3>

<p>Baldi, P. &amp; Batchelder, W. H. (2003). Bounds on variances of estimators for multinomial processing tree models. <em>Journal of Mathematical Psychology</em>, 47, 467-470. 
</p>
<p>Broeder, A., &amp; Schuetz, J. (2009). Recognition ROCs are curvilinear-or are they? On premature arguments against the two-high-threshold model of recognition. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, 35(3), 587. doi:10.1037/a0015279
</p>
<p>Byrd, R. H., Lu, P., Nocedal, J., &amp; Zhu, C. (1995). A limited memory algorithm for bound constrained optimization. <em>SIAM J. Scientific Computing</em>, 16, 1190-1208.
</p>
<p>Fox, P. A., Hall, A. P., &amp; Schryer, N. L. (1978). The PORT Mathematical Subroutine Library. <em>CM Trans. Math. Softw.</em>, 4, 104-126. <a href="https://doi.org/10.1145/355780.355783">doi:10.1145/355780.355783</a>
</p>
<p>Knapp, B. R., &amp; Batchelder, W. H. (2004). Representing parametric order constraints in multi-trial applications of multinomial processing tree models. <em>Journal of Mathematical Psychology</em>, 48, 215-229.
</p>
<p>Moshagen, M. (2010). multiTree: A computer program for the analysis of multinomial processing tree models. <em>Behavior Research Methods</em>, 42, 42-54.
</p>
<p>Navarro, D. J. (2004). A Note on the Applied Use of MDL Approximations. <em>Neural Computation</em>, 16(9), 1763-1768.
</p>
<p>Purdy, B. P., &amp; Batchelder, W. H. (2009). A context-free language for binary multinomial processing tree models. <em>Journal of Mathematical Psychology</em>, 53, 547-561.
</p>
<p>Riefer, D. M., &amp; Batchelder, W. H. (1988). Multinomial modeling and the measurement of cognitive processes. <em>Psychological Review</em>, 95, 318-339.
</p>
<p>Stahl, C. &amp; Klauer, K. C. (2007). HMMTree: A computer program for latent-class hierarchical multinomial processing tree models. <em>Behavior Research Methods</em>, 39, 267- 273.
</p>
<p>Wu, H., Myung, J.I., &amp; Batchelder, W.H. (2010a). Minimum description length model selection of multinomial processing tree models. <em>Psychonomic Bulletin &amp; Review</em>, 17, 275-286.
</p>
<p>Wu, H., Myung, J.I., &amp; Batchelder, W.H. (2010b). On the minimum description length complexity of multinomial processing trees. <em>Journal of Mathematical Psychology</em>, 54, 291-303.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+check.mpt">check.mpt</a></code> for a function that can help in constructing models.
</p>
<p><code><a href="#topic+select.mpt">select.mpt</a></code> for the function that performs model selection on results from <code>fit.mpt</code>.
</p>
<p><code><a href="#topic+fit.model">fit.model</a></code> for a similar wrapper for which you can specify upper and lower bounds of parameters (and whether or not <code>nlminb</code> uses the symbolically derived gradient and hessian)
</p>
<p><code><a href="#topic+fit.mptinr">fit.mptinr</a></code> is the workhorse with which you can also fit your own objective functions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># The first example fits the MPT model presented in Riefer and Batchelder (1988, Figure 1)
# to the data presented in Riefer and Batchelder (1988, Table 1)
# Note that Riefer and Batchelder (1988, pp. 328) did some hypotheses tests not replicated here.
# Instead, we use each condition (i.e., row in Table 1) as a different dataset.

# load the data
data(rb.fig1.data, package = "MPTinR")

#get the character string with the position of the model:
model1 &lt;- system.file("extdata", "rb.fig1.model", package = "MPTinR")
model1.eqn &lt;- system.file("extdata", "rb.fig1.model.eqn", package = "MPTinR")

# just fit the first dataset:
fit.mpt(rb.fig1.data[1,], model1, n.optim = 1)
fit.model(rb.fig1.data[1,], model1, n.optim = 1)

#fit all datasets:
fit.mpt(rb.fig1.data, model1, n.optim = 1)
fit.model(rb.fig1.data, model1, n.optim = 1)

#fit all datasets using the .EQN model file:
fit.mpt(rb.fig1.data, model1.eqn, n.optim = 1)

#fit using a textConnection (i.e., you can specify the model in your script/code):
model1.txt &lt;- "p * q * r
p * q * (1-r)
p * (1-q) * r
p * (1-q) * (1-r) + (1-p)"
fit.mpt(rb.fig1.data, textConnection(model1.txt), n.optim = 1)



# The second example fits the MPT model presented in Riefer and Batchelder (1988, Figure 2)
# to the data presented in Riefer and Batchelder (1988, Table 3)
# First, the model without restrictions is fitted: ref.model
# Next, the model with all r set equal is fitted: r.equal
# Then, the model with all c set equal is fitted: c.equal
# Finally, the inferential tests reported by Riefer &amp; Batchelder, (1988, p. 332) are executed.

# get the data
data(rb.fig2.data, package = "MPTinR")

# positions of model and restriction files:
model2 &lt;- system.file("extdata", "rb.fig2.model", package = "MPTinR")
model2r.r.eq &lt;- system.file("extdata", "rb.fig2.r.equal", package = "MPTinR")
model2r.c.eq &lt;- system.file("extdata", "rb.fig2.c.equal", package = "MPTinR")

# The full (i.e., unconstrained) model
(ref.model &lt;- fit.mpt(rb.fig2.data, model2))

# All r equal
(r.equal &lt;- fit.mpt(rb.fig2.data, model2, model2r.r.eq))

# All c equal
(c.equal &lt;- fit.mpt(rb.fig2.data, model2, model2r.c.eq))

# is setting all r equal a good idea?
(g.sq.r.equal &lt;- r.equal[["goodness.of.fit"]][["G.Squared"]] - 
				ref.model[["goodness.of.fit"]][["G.Squared"]])
(df.r.equal &lt;- r.equal[["goodness.of.fit"]][["df"]] - 
				ref.model[["goodness.of.fit"]][["df"]])
(p.value.r.equal &lt;- pchisq(g.sq.r.equal, df.r.equal , lower.tail = FALSE))

# is setting all c equal a good idea?
(g.sq.c.equal &lt;- c.equal[["goodness.of.fit"]][["G.Squared"]] - 
				ref.model[["goodness.of.fit"]][["G.Squared"]])
(df.c.equal &lt;- c.equal[["goodness.of.fit"]][["df"]] - 
				ref.model[["goodness.of.fit"]][["df"]])
(p.value.c.equal &lt;- pchisq(g.sq.c.equal, df.c.equal , lower.tail = FALSE))

# You can specify restrictions also via a list instead of an external file:
# All r equal
r.equal.2 &lt;- fit.mpt(rb.fig2.data, model2, list("r0 = r1 = r2= r3 = r4"), n.optim = 5)
all.equal(r.equal, r.equal.2)

# All c equal
c.equal.2 &lt;- fit.mpt(rb.fig2.data, model2, list("c0 = c1 = c2 = c3= c4"))
all.equal(c.equal, c.equal.2)


## Not run: 

# Example from Broder &amp; Schutz (2009)
# We fit the data from the 40 individuals from their Experiment 3
# We fit three different models:
# 1. Their 2HTM model: br.2htm
# 2. A restricted 2HTM model with Dn = Do: br.2htm.res
# 3. A 1HTM model (i.e., Dn = 0): br.1htm
# We fit the models with, as well as without, applied inequality restrictions (see Details)
# that is, for some models (.ineq) we impose: G1 &lt; G2 &lt; G3 &lt; G4 &lt; G5 
# As will be apparent, the inequality restrictions do not hold for all individuals.
# Finally, we compute the FIA for all models, taking inequalities into account.

data(d.broeder, package = "MPTinR")
m.2htm &lt;- system.file("extdata", "5points.2htm.model", package = "MPTinR")
r.2htm &lt;- system.file("extdata", "broeder.2htm.restr", package = "MPTinR")
r.1htm &lt;- system.file("extdata", "broeder.1htm.restr", package = "MPTinR")
i.2htm &lt;- system.file("extdata", "broeder.2htm.ineq", package = "MPTinR")
ir.2htm &lt;- system.file("extdata", "broeder.2htm.restr.ineq", package = "MPTinR")
ir.1htm &lt;- system.file("extdata", "broeder.1htm.restr.ineq", package = "MPTinR")

# fit the original 2HTM
br.2htm &lt;- fit.mpt(d.broeder, m.2htm)
br.2htm.ineq &lt;- fit.mpt(d.broeder, m.2htm, i.2htm)

# do the inequalities hold for all participants?
br.2htm.ineq[["parameters"]][["individual"]][,"estimates",]
br.2htm[["parameters"]][["individual"]][,"estimates",]
# See the difference between forced and non-forced inequality restrictions:
round(br.2htm[["parameters"]][["individual"]][,"estimates",] -
		br.2htm.ineq[["parameters"]][["individual"]][,"estimates",],2)

# The same for the other two models
# The restricted 2HTM
br.2htm.res &lt;- fit.mpt(d.broeder, m.2htm, r.2htm)
br.2htm.res.ineq &lt;- fit.mpt(d.broeder, m.2htm, ir.2htm)
round(br.2htm.res[["parameters"]][["individual"]][,"estimates",] - 
		br.2htm.res.ineq[["parameters"]][["individual"]][,"estimates",],2)
# The 1HTM
br.1htm &lt;- fit.mpt(d.broeder, m.2htm, r.1htm)
br.1htm.ineq &lt;- fit.mpt(d.broeder, m.2htm, ir.1htm)
round(br.2htm.res[["parameters"]][["individual"]][,"estimates",] - 
		br.2htm.res.ineq[["parameters"]][["individual"]][,"estimates",],2)

# identical to the last fit of the 1HTM (using a list as restriction):
br.1htm.ineq.list &lt;- fit.mpt(d.broeder, m.2htm, list("G1 &lt; G2 &lt; G3 &lt; G4 &lt; G5", "Dn = 0"))
all.equal(br.1htm.ineq, br.1htm.ineq.list)  # TRUE

# These results show that inequality restrictions do not hold for all datasets.
# (It would look differently if we excluded critical cases, 
# i.e., 2, 6, 7, 10, 18, 21, 25, 29, 32, 34, 35, 37, 38)
# Therefore, we get the FIA for the models as computed above 

br.2htm.fia &lt;- fit.mpt(d.broeder, m.2htm, fia = 200000)
br.2htm.ineq.fia &lt;- fit.mpt(d.broeder, m.2htm, i.2htm, fia = 200000)
br.2htm.res.fia &lt;- fit.mpt(d.broeder, m.2htm, r.2htm, fia = 200000 )
br.2htm.res.ineq.fia &lt;- fit.mpt(d.broeder, m.2htm, ir.2htm, fia = 200000)
br.1htm.fia &lt;- fit.mpt(d.broeder, m.2htm, r.1htm, fia = 200000)
br.1htm.ineq.fia &lt;- fit.mpt(d.broeder, m.2htm, ir.1htm, fia = 200000)

# Model selection using the FIA
(br.select &lt;- select.mpt(list(br.2htm.fia, br.2htm.ineq.fia, br.2htm.res.fia, 
                              br.2htm.res.ineq.fia, br.1htm.fia, br.1htm.ineq.fia)))
                              
# The same results, ordered by FIA
br.select[order(br.select[,"delta.FIA.sum"]),]

# Note that FIA for individual data (.sum) is not consistent (i.e., the penalty
# for the nested model br.1htm.ineq.fia is not really smaller than the penalty
# for the superordinate model br.2htm.ineq.fia).
# Hence, one should use the aggregated data for this analysis (not shown here)! 

# Compare this with the model selection not using FIA:
select.mpt(list(br.2htm, br.2htm.ineq, br.2htm.res, br.2htm.res.ineq, br.1htm, br.1htm.ineq))

# Only use the aggregated data:
d.broeder.agg &lt;- colSums(d.broeder)
br.2htm.agg &lt;- fit.mpt(d.broeder.agg, m.2htm)
br.2htm.res.agg &lt;- fit.mpt(d.broeder.agg, m.2htm, r.2htm)
br.1htm.agg &lt;- fit.mpt(d.broeder.agg, m.2htm, r.1htm)

select.mpt(list(br.2htm.agg, br.2htm.res.agg, br.1htm.agg), output = "full")


# compare speed of no multicore versus multicore for multiple datasets:

require(snowfall)
# change number of CPUs if more are available
nCPU = 2
sfInit( parallel=TRUE, cpus=nCPU, type = "SOCK" )

# NO multicore
system.time(fit.mpt(d.broeder, m.2htm))

# multicore:
system.time(fit.mpt(d.broeder, m.2htm, multicore = "individual"))

sfStop()

## End(Not run)

  </code></pre>

<hr>
<h2 id='fit.mpt.old'>
Function to fit MPT models (old)
</h2><span id='topic+fit.mpt.old'></span>

<h3>Description</h3>

<p><code>fit.mpt.old</code> function fits <em>binary</em> multinomial processing tree models (MPT models; e.g., Riefer &amp; Batchelder, 1988). However, this function is an old version  using the L-BFGS-B optimization routine. See <code><a href="#topic+fit.mpt">fit.mpt</a></code> for the new version. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit.mpt.old(
	data,
	model.filename, 
	restrictions.filename = NULL, 
	n.optim = 5,
	fia = NULL,
	ci = 95, 
	starting.values = NULL,
	output = c("standard", "fia", "full"),
	reparam.ineq = TRUE,
	sort.param = TRUE,
	model.type = c("easy", "eqn", "eqn2"),
	multicore = c("none", "individual", "n.optim"), sfInit = FALSE, nCPU = 2
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit.mpt.old_+3A_data">data</code></td>
<td>

<p>Either a <em>numeric</em> <code>vector</code> for individual fit or a <em>numeric</em> <code>matrix</code> or <code>data.frame</code> for multi-individual fit. The data on each position (column for multi-individual fit) must correspond to the respective line in the model file. Fitting for multiple individuals can be parallelized via <code>multicore</code>.
</p>
</td></tr>
<tr><td><code id="fit.mpt.old_+3A_model.filename">model.filename</code></td>
<td>

<p>A character <code>vector</code> specifying the location and name of the model file. 
</p>
</td></tr>
<tr><td><code id="fit.mpt.old_+3A_restrictions.filename">restrictions.filename</code></td>
<td>

<p><code>NULL</code> or a character <code>vector</code> or a <code>list</code> of characters. The default is <code>NULL</code> which corresponds to no restrictions. A character <code>vector</code> specifies the location or name of the restrictions file. A <code>list</code> of characters contains the restrictions directly.
</p>
</td></tr>
<tr><td><code id="fit.mpt.old_+3A_n.optim">n.optim</code></td>
<td>

<p>Number of optimization runs. Can be parallelized via <code>multicore</code>. Default is 5. If the number is high, fitting can take long for <em>large</em> models.
</p>
</td></tr>
<tr><td><code id="fit.mpt.old_+3A_fia">fia</code></td>
<td>

<p>Number of random samples to be drawn in the Monte Carlo algorithm to estimate the Fisher Information Approximation (FIA), a minimum description length based measure of model complexity (see Wu, Myung &amp; Batchelder, 2010). The default is <code>NULL</code> which corresponds to no computation of the FIA. Reasonable values (e.g., &gt; 200000) can lead to long computation times (minutes to hours) depending on the size of the model. See Details.
</p>
</td></tr>
<tr><td><code id="fit.mpt.old_+3A_ci">ci</code></td>
<td>

<p>A scalar corresponding to the size of the confidence intervals for the parameter estimates. Default is 95 which corresponds to 95% confidence intervals.
</p>
</td></tr>
<tr><td><code id="fit.mpt.old_+3A_starting.values">starting.values</code></td>
<td>

<p>A <code>vector</code> or <code>NULL</code>. If <code>NULL</code> (the default), starting values for parameters are randomly drawn from a uniform distribution with the interval <code>(0.05 - 0.95)</code>. If <code>length(starting.values)==2</code>, starting values  are randomly drawn from a uniform distribution with the interval <code>starting.values[1] - starting.values[2])</code>. If <code>length(starting.values)</code> matches the number of parameters in the model, <code>starting.values</code> will be used as the starting values for fitting and <code>n.optim</code> will be set to 1. See Details.
</p>
</td></tr>
<tr><td><code id="fit.mpt.old_+3A_output">output</code></td>
<td>

<p>If &quot;fia&quot;, <code>fit.mpt</code> will additionally return the results from <code><a href="#topic+get.mpt.fia">get.mpt.fia</a></code> (if calculated <code>fia</code> not equal <code>NULL</code>). If &quot;full&quot; <code>fit.mpt</code> will additionally return the results from <code><a href="#topic+get.mpt.fia">get.mpt.fia</a></code> and the output of <code><a href="stats.html#topic+optim">optim</a></code>.
</p>
</td></tr>
<tr><td><code id="fit.mpt.old_+3A_reparam.ineq">reparam.ineq</code></td>
<td>

<p>Logical. Indicates whether or not inequality restrictions (when present in the model file) should be enforced while fitting the model. If <code>TRUE</code> (the default) inequality restricted parameters will be reparameterized, if <code>FALSE</code> not. See Details.
</p>
</td></tr>
<tr><td><code id="fit.mpt.old_+3A_sort.param">sort.param</code></td>
<td>

<p>Logical. If TRUE, parameters are alphabetically sorted in the parameter table. If FALSE, the first parameters in the parameter table are the non-restricted ones, followed by the restricted parameters. Default is TRUE.
</p>
</td></tr>
<tr><td><code id="fit.mpt.old_+3A_model.type">model.type</code></td>
<td>

<p>Character vector specifying whether the model file is formatted in the easy way (<code>"easy"</code>; i.e., each line represents all branches corresponding to a response category) or the traditional EQN syntax (<code>"eqn"</code> or <code>"eqn2"</code>; see Details and e.g., Stahl &amp; Klauer, 2007). If <code>model.filename</code> ends with .eqn or .EQN, <code>model.type</code> is automatically set to <code>"eqn"</code>. Default is <code>"easy"</code>.
</p>
</td></tr>
<tr><td><code id="fit.mpt.old_+3A_multicore">multicore</code></td>
<td>

<p>Character vector. If not <code>"none"</code>, uses <code>snowfall</code> for parallelization (which needs to be installed separately via <code>install.packages(snowfall)</code>). If <code>"individual"</code>, parallelizes the optimization for each individual (i.e., data needs to be a <code>matrix</code> or <code>data.frame</code>). If <code>"n.optim"</code>, parallelizes the <code>n.optim</code> optimization runs. Default is <code>"none"</code> which corresponds to no parallelization. Note that you need to initialize <code>snowfall</code> in default settings. See <code>sfInit</code> and Details.
</p>
</td></tr>
<tr><td><code id="fit.mpt.old_+3A_sfinit">sfInit</code></td>
<td>

<p>Logical. Relevant if <code>multicore</code> is not <code>"none"</code>. If <code>TRUE</code>, <code>fit.mpt</code> will initialize and close the multicore support. If <code>FALSE</code>, (the default) assumes that <code>sfInit()</code> was initialized before. See Details.
</p>
</td></tr>
<tr><td><code id="fit.mpt.old_+3A_ncpu">nCPU</code></td>
<td>

<p>Scalar. Only relevant if <code>multicore</code> is not <code>"none"</code> and <code>sfInit</code> is TRUE. Number of CPUs used by <code>snowfall</code>. Default is 2.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There is a new version of this function using <code><a href="stats.html#topic+nlminb">nlminb</a></code> and the analytically derived gradient and hessian. See <code><a href="#topic+fit.mpt">fit.mpt</a></code>. We recommend using the new version <code><a href="#topic+fit.mpt">fit.mpt</a></code>, only use this version if you are sure on what to do.
</p>
<p>The model file is either of the easy format or the &quot;classical&quot; EQN format (see below).<br />
In the easy format (the default) the model file contains all trees of the model. Trees are separated by at least one empty line. Everything to the right of a hash (#) is ignored (this behavior is new since version 0.9.2). Lines starting with a # are treated as empty. Each line in each tree corresponds to all branches of this tree (concatenated by a +) that correspond to one of the possible response categories. The position of each line must correspond to the position of this response category in the data object (for multi-individual fit to the respective column).
</p>
<p>The difference between both types of EQN format (<code>"eqn"</code> or<code>"eqn2"</code>) is the way the first line of the model file is treated. If <code>model.file</code> is set to <code>"eqn"</code>, <code>MPTinR</code> will ignore the first line of the model file and will read the rest of the file (as does multiTree; Moshagen, 2010). If <code>model.file</code> is set to <code>"eqn2"</code> MPTinR will only read as many lines as indicated in the first line of the EQN model file (as does e.g., HMMTree; Stahl &amp; Klauer, 2007). As default <code>fit.mpt</code> expects the easy format, but if the filename ends with .eqn or .EQN and <code>model.type</code> is <code>"easy"</code>, <code>model.type</code> is set to <code>"eqn"</code><br />
For the EQN format consult one of the corresponding papers (see e.g., Moshagen, 2010; Stahl &amp; Klauer, 2007). The positions in the data object (number of column for multi-individual fit) must correspond to the category number in the EQN file.<br />
</p>
<p>Note that names of parameters in the model file should not start with <code>hank.</code>. Variables with these names can lead to unforeseen problems as variables starting with these letters are internally used.
</p>
<p>The restrictions file may contain (sequential) equality (i.e., =) and inequality (i.e., &lt;) restrictions and must adhere to the following rules:<br />
1. Inequalities first.<br />
2. If a variable appears in an inequality restriction, it can not be on the LHS of any further restriction.<br />
3. If a variable appears on RHS of an equality restriction, it can not appear on LHS of an equality restriction.<br />
Note that only &quot;&lt;&quot; is supported as inequality operator but not &quot;&gt;&quot;!<br />
Examples of restrictions are (the following could all appear in one restrictions file):<br />
<code>D1 &lt; D2 &lt; D3</code><br />
<code>D4 = D3</code><br />
<code>B1 = B3 = 0.3333</code><br />
<code>X4 = X5 = D3</code><br />
Restrictions file may contain comments (i.e., everything to the right of a # will be ignored; new behavior since version 0.9.2)
</p>
<p>For equality restrictions, the equality restricted parameters are simply exchanged with their restrictions before the fitting.<br />
For inequality restricted parameters, the model is reparameterized so that only the rightmost parameter of an inequality restriction remains the original parameter. Each instance of the other parameters in this restriction is replaced by the product of the rightmost parameter and dummy parameters (see Knapp &amp; Batchelder, 2004). This procedure (which is equivalent to method A described in Knapp &amp; Batchelder, 2004) leads to an equivalent model (although the binary MPT structure is not apparent in the resulting equations).<br />
To prohibit this reparameterization (i.e., if the inequality restrictions hold without reparameterization), you can set <code>reparam.ineq</code> to <code>FALSE</code>. This can be useful for obtaining the FIA (see examples in Wu, Myung, &amp; Batchelder, 2010).
</p>
<p>The fitting/optimization is achieved via <code><a href="stats.html#topic+optim">optim</a></code>'s L-BFGS-B method by Byrd et al. (1995) with random starting values. To avoid local minima it is useful to set <code>n.optim</code> &gt; 1. If <code>n.optim</code> &gt; 1, the <code><a href="base.html#topic+summary">summary</a></code> of the vector containing the Log-Likelihood values returned by each run of <code>optim</code> is added to the output (to check whether local minima were present). If the model is rather big, <code>n.optim</code> &gt; 1 can be slow.
</p>
<p>To obtain a measure of the model's complexity beyond the number of parameters (and taking inequality restrictions into account), set <code>fia</code> to a (reasonably high) scalar integer (i.e., a number). Then, <code>fit.mpt</code> will obtain the Fisher information approximation (FIA), a minimum description based measure of model complexity, using the algorithm provided by Wu, Myung, &amp; Batchelder (2010a, 2010b) ported from Matlab to R. When performing model-selection, this measure is superior to other methods such as the Akaike information criterion (AIC) or Bayesian information criterion (BIC) which basically only take the number of parameters into account.<br />
To get the FIA, <code>fit.mpt.old</code> performs the following steps:<br />
1. The representation of the model as equations is transformed into the string representation of the model in the context-free language of MPT models (L-BMPT; Purdy &amp; Batchelder, 2009). For this step to be successful it is <em>absolutely necessary</em> that the equations representing the model perfectly map the tree structure of the MPT. That is, the model file is only allowed to contain parameters, their negations (e.g., <code>Dn</code> and <code>(1 - Dn)</code>) and the operators + and *, but nothing else. Simplifications of the equations will seriously distort this step. This step is achieved by <code><a href="#topic+make.mpt.cf">make.mpt.cf</a></code>.<br />
2. The context free representation of the model is then fed into the MCMC function computing the FIA (the port of BMPTFIA provided by Wu, Myung &amp; Batchelder (2010a), see <code><a href="#topic+bmpt.fia">bmpt.fia</a></code>).<br />
(Actually, both steps are achieved by a call to <code><a href="#topic+get.mpt.fia">get.mpt.fia</a></code>)
</p>
<p>Once again: If one wants to compute the FIA, it is <em>absolutely necessary</em>, that the representation of the model via equations in the model file exactly maps on the structure of the binary MPT (see <code><a href="#topic+make.mpt.cf">make.mpt.cf</a></code> for more details).
</p>
<p>Confidence intervals (CI) are based on the observed Hessian matrix returned by the minimization algorithm (<code><a href="stats.html#topic+optim">optim</a></code>).<br />
For inequality restricted parameters, the CIs are computed using the parameter estimates' variance bounds (see Baldi &amp; Batchelder, 2003; especially equation 19). Note that these bounds represent the &quot;worst case scenario&quot; variances, and can lead to CIs outside parameter boundaries if the set of inequalities is large and/or the variances for the reparameterized model are large (Note that CIs for non-restricted parameters can be outside the parameter boundaries as well due to large variances).
</p>
<p>To set the starting values for the fitting process (e.g., to avoid local minima) one can set <code>starting.values</code> to a vector of length 2. Then, starting values are randomly drawn from a uniform distribution from <code>starting.values[1]</code> to <code>starting.values[2]</code>.<br />
Furthermore, one can specify the starting values individually by supplying a vector with the same length as the number of parameters. Starting values must be ordered according to the alphabetical order of the parameters. Use <code><a href="#topic+check.mpt">check.mpt</a></code> for a function that returns the alphabetical order of the parameters. If one specifies the starting values like that, <code>n.optim</code> will be set to 1 as all other values would not make any sense (the optimization routine will produce identical results with identical starting values).
</p>
<p>Multicore fitting is achieved via the <code>snowfall</code> package and needs to be initialized via <code>sfInit</code>. As initialization needs some time, you can either initialize multicore facilities yourself using <code>sfInit()</code> and setting the <code>sfInit</code> argument to <code>FALSE</code> (the default) or let MPTinR initialize multicore facilities by setting the <code>sfInit</code> argument to <code>TRUE</code>. The former is recommended as initializing <code>snowfall</code> takes some time and only needs to be done once if you run <code>fit.mpt.old</code> multiple times. If there are any problems with multicore fitting, first try to initialize <code>snowfall</code> outside MPTinR (e.g., <code>sfInit( parallel=TRUE, cpus=2 )</code>). If this does not work, the problem is not related to MPTinR but to snowfall (for support and references visit: <a href="https://www.imbi.uni-freiburg.de/parallel/">https://www.imbi.uni-freiburg.de/parallel/</a>).<br />
Note that you need to <em>close</em> snowfall via <code>sfStop()</code> after using MPTinR.
</p>
<p><code>fit.model()</code> is essentially a copy of <code>fit.mpt.old</code> that allows the user to specify the upper and lower bounds of the parameters. This function can be used to fit other models than MPT models that can be described in a model file. That is, the model file can contain any type of valid R expressions including R functions (potentially self-written) visible in the global environment (i.e., not only +, *, and - as operators).  Currently <code>fit.model</code> should be viewed as experimental.
</p>
<p>Note that <code>fit.model()</code> is usually slower than <code>fit.mpt.old</code> as there are some more checks in the critical function calculating the likelihood of the model. <br />
</p>
<p>The <code>lower.bound</code> and <code>upper.bound</code> needs to be of length 1 or equal to the number of <code>free</code> parameters. If length &gt; 1, parameters are mapped to the bounds in alphabetic order of the parameters. Use <code><a href="#topic+check.mpt">check.mpt</a></code> to obtain the alphabetical order of parameters for your model.
</p>
<p>While it should be possible to specify equality or fixed restrictions it will probably lead to unforeseen consequences to specify inequality restrictions for non-MPT models.
</p>


<h3>Value</h3>

<p>For individual fits (i.e., <code>data</code> is a <code>vector</code>) a <code>list</code> containing one or more of the following components from the best fitting model:
</p>
<table>
<tr><td><code>goodness.of.fit</code></td>
<td>
<p>A <code>data.frame</code> containing the goodness of fit values for the model. <code>Log.Likelihood</code> is the Log-Likelihood value. <code>G.Squared</code>, <code>df</code>, and <code>p.value</code> are the <code class="reqn">G^2</code> goodness of fit statistic.</p>
</td></tr>
<tr><td><code>information.criteria</code></td>
<td>
<p>A <code>data.frame</code> containing model information criteria based on the G^2 value. The FIA values(s) are presented if <code>fia</code> is not <code>NULL</code>.</p>
</td></tr>
<tr><td><code>model.info</code></td>
<td>
<p>A <code>data.frame</code> containing other information about the model. If the rank of the Hessian matrix (<code>rank.hessian</code>) <em>does not</em> correspond to the number of parameters in the model (<code>n.parameters</code>) this indicates a serious issue with the identifiability of the model.</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>
<p>A data.frame containing the parameter estimates and corresponding confidence intervals. If a restriction file was present, the restricted parameters are marked.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>A <code>list</code> of two matrices; the first one (<code>observed</code>) contains the entered data, the second one (<code>predicted</code>) contains the predicted values.</p>
</td></tr>
</table>
<p>For multi-individual fits (i.e., <code>data</code> is a <code>matrix</code> or <code>data.frame</code>) a <code>list</code> with similar elements, but the following differences.<br />
The first elements, <code>goodness.of.fit</code>, <code>information.criteria</code>, and <code>model.info</code>, contain the same information as for individual fits, but each are <code>lists</code> with three elements containing the respective values for: each individual in the list element <code>individual</code>, the sum of the individual values in the list element <code>sum</code>, and the values corresponding to the fit for the aggregated data in the list element <code>aggregated</code>.<br />
<code>parameters</code> is a list containing:
</p>
<table>
<tr><td><code>individual</code></td>
<td>
<p>A 3-dimensional array containing the parameter estimates ([,1,]), confidence intervals [,2:3,], and, if restrictions not <code>NULL</code>, column 4 [,4,] is 0 for non-restricted parameters, 1 for equality restricted parameters, and 2 for inequality restricted parameters. The first dimension refers to the parameters, the second to the information on each parameter, and the third to the individuals.</p>
</td></tr>
<tr><td><code>mean</code></td>
<td>
<p>A <code>data.frame</code> with the mean parameter estimates from the individual estimates. No confidence intervals can be provided for these values.</p>
</td></tr>
<tr><td><code>aggregated</code></td>
<td>
<p>A data.frame containing the parameter estimates and corresponding confidence intervals for the aggregated data. If a restriction file was present, the restricted parameters are marked.</p>
</td></tr>
</table>
<p>The element <code>data</code> contains two matrices, one with the <code>observed</code>, and one with the <code>predicted</code> data.
</p>
<p>If <code>n.optim</code> &gt; 1, the <code><a href="base.html#topic+summary">summary</a></code> of the vector (matrix for multi-individual fit) containing the Log-Likelihood values returned by each run of <code>optim</code> is added to the output.
</p>
<p>When using R (&gt;= 2.13.0) compiling <code>fit.mpt.old</code> using <code>compilers</code> <code>cmpfun</code> can significantly improve fitting time.
</p>


<h3>Note</h3>

<p>There may be several warnings <code>fit.mpt.old</code> throws while fitting MPT models. Most of them are not problematic and related to matrix operations needed for confidence intervals. Examples:<br />
<code>In sqrt(var.params) : NaNs produced</code><br />
<code>In sqrt(min(var.bound.tmp)) : NaNs produced</code><br />
These warnings are not critical.
</p>
<p>Other warnings may relate to the optimization routine (e.g., <code>Optimization routine [...] did not converge successfully</code>).<br />
In these cases it is recommended to rerun <code>fit.mpt.old</code> to check if the results are stable.
</p>


<h3>Note</h3>

<p>All (model or restriction) files should end with an empty line, otherwise a warning will be shown.
</p>


<h3>Author(s)</h3>

<p>Henrik Singmann and David Kellen with help from Karl Christoph Klauer and Fabian Hoelzenbein.
</p>


<h3>References</h3>

<p>Baldi, P. &amp; Batchelder, W. H. (2003). Bounds on variances of estimators for multinomial processing tree models. <em>Journal of Mathematical Psychology</em>, 47, 467-470. 
</p>
<p>Broeder, A., &amp; Schuetz, J. (2009). Recognition ROCs are curvilinear-or are they? On premature arguments against the two-high-threshold model of recognition. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, 35(3), 587. doi:10.1037/a0015279
</p>
<p>Byrd, R. H., Lu, P., Nocedal, J., &amp; Zhu, C. (1995). A limited memory algorithm for bound constrained optimization. <em>SIAM J. Scientific Computing</em>, 16, 1190-1208.
</p>
<p>Knapp, B. R., &amp; Batchelder, W. H. (2004). Representing parametric order constraints in multi-trial applications of multinomial processing tree models. <em>Journal of Mathematical Psychology</em>, 48, 215-229.
</p>
<p>Moshagen, M. (2010). multiTree: A computer program for the analysis of multinomial processing tree models. <em>Behavior Research Methods</em>, 42, 42-54.
</p>
<p>Purdy, B. P., &amp; Batchelder, W. H. (2009). A context-free language for binary multinomial processing tree models. <em>Journal of Mathematical Psychology</em>, 53, 547-561.
</p>
<p>Riefer, D. M., &amp; Batchelder, W. H. (1988). Multinomial modeling and the measurement of cognitive processes. <em>Psychological Review</em>, 95, 318-339.
</p>
<p>Stahl, C. &amp; Klauer, K. C. (2007). HMMTree: A computer program for latent-class hierarchical multinomial processing tree models. <em>Behavior Research Methods</em>, 39, 267- 273.
</p>
<p>Wu, H., Myung, J.I., &amp; Batchelder, W.H. (2010a). Minimum description length model selection of multinomial processing tree models. <em>Psychonomic Bulletin &amp; Review</em>, 17, 275-286.
</p>
<p>Wu, H., Myung, J.I., &amp; Batchelder, W.H. (2010b). On the minimum description length complexity of multinomial processing trees. <em>Journal of Mathematical Psychology</em>, 54, 291-303.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit.mpt">fit.mpt</a></code> for the current and recommended function fot fitting MPTs
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

# The first example fits the MPT model presented in Riefer and Batchelder (1988, Figure 1)
# to the data presented in Riefer and Batchelder (1988, Table 1)
# Note that Riefer and Batchelder (1988, pp. 328) did some hypotheses tests, that are not done here.
# Rather, we use each condition (i.e., row in Table 1) as a different individual.
# We try to use n.optim = 1 here, but this can lead to local minima
# In general we recommend to set n.optim &gt;= 5

# load the data
data(rb.fig1.data)

#get the character string with the position of the model:
model1 &lt;- system.file("extdata", "rb.fig1.model", package = "MPTinR")
model1.eqn &lt;- system.file("extdata", "rb.fig1.model.eqn", package = "MPTinR")

# just fit the first "individual":
fit.mpt.old(rb.fig1.data[1,], model1, n.optim = 1)

#fit all "individuals":
fit.mpt.old(rb.fig1.data, model1, n.optim = 1)

#fit all "individuals" using the .EQN model file:
fit.mpt.old(rb.fig1.data, model1.eqn, n.optim = 1)



# The second example fits the MPT model presented in Riefer and Batchelder (1988, Figure 2)
# to the data presented in Riefer and Batchelder (1988, Table 3)
# First, the model without restrictions is fitted: ref.model
# Next, the model with all r set equal is fitted: r.equal
# Then, the model with all c set equal is fitted: c.equal
# Finally, the inferential tests reported by Riefer &amp; Batchelder, (1988, p. 332) are executed.
# Note, that n.optim = 10, because of frequent local minima.

# get the data
data(rb.fig2.data)

# positions of model and restriction files:
model2 &lt;- system.file("extdata", "rb.fig2.model", package = "MPTinR")
model2r.r.eq &lt;- system.file("extdata", "rb.fig2.r.equal", package = "MPTinR")
model2r.c.eq &lt;- system.file("extdata", "rb.fig2.c.equal", package = "MPTinR")

# The full (i.e., unconstrained) model
(ref.model &lt;- fit.mpt.old(rb.fig2.data, model2, n.optim = 10))

# All r equal
(r.equal &lt;- fit.mpt.old(rb.fig2.data, model2, model2r.r.eq, n.optim = 10))

# All c equal
(c.equal &lt;- fit.mpt.old(rb.fig2.data, model2, model2r.c.eq, n.optim = 10))

# is setting all r equal a good idea?
(g.sq.r.equal &lt;- r.equal[["goodness.of.fit"]][["G.Squared"]] - 
			ref.model[["goodness.of.fit"]][["G.Squared"]])
(df.r.equal &lt;- r.equal[["goodness.of.fit"]][["df"]] - 
			ref.model[["goodness.of.fit"]][["df"]])
(p.value.r.equal &lt;- pchisq(g.sq.r.equal, df.r.equal , lower.tail = FALSE))

# is setting all c equal a good idea?
(g.sq.c.equal &lt;- c.equal[["goodness.of.fit"]][["G.Squared"]] - 
		ref.model[["goodness.of.fit"]][["G.Squared"]])
(df.c.equal &lt;- c.equal[["goodness.of.fit"]][["df"]] - 
		ref.model[["goodness.of.fit"]][["df"]])
(p.value.c.equal &lt;- pchisq(g.sq.c.equal, df.c.equal , lower.tail = FALSE))


# Example from Broeder &amp; Schuetz (2009)
# We fit the data from the 40 individuals from their Experiment 3
# We fit three different models:
# 1. Their 2HTM model: br.2htm
# 2. A restricted 2HTM model with Dn = Do: br.2htm.res
# 3. A 1HTM model (i.e., Dn = 0): br.1htm
# We fit the models with, as well as without, applied inequality restrictions (see Details)
# that is, for some models (.ineq) we impose: G1 &lt; G2 &lt; G3 &lt; G4 &lt; G5 
# As will be apparent, the inequality restrictions do not hold for all individuals.
# Finally, we compute the FIA for all models, taking inequalities into account.
# Note: The following examples will take some time (&gt; 1 hour).

data(d.broeder)
m.2htm &lt;- system.file("extdata", "5points.2htm.model", package = "MPTinR")
r.2htm &lt;- system.file("extdata", "broeder.2htm.restr", package = "MPTinR")
r.1htm &lt;- system.file("extdata", "broeder.1htm.restr", package = "MPTinR")
i.2htm &lt;- system.file("extdata", "broeder.2htm.ineq", package = "MPTinR")
ir.2htm &lt;- system.file("extdata", "broeder.2htm.restr.ineq", package = "MPTinR")
ir.1htm &lt;- system.file("extdata", "broeder.1htm.restr.ineq", package = "MPTinR")

# fit the original 2HTM
br.2htm &lt;- fit.mpt.old(d.broeder, m.2htm)
br.2htm.ineq &lt;- fit.mpt.old(d.broeder, m.2htm, i.2htm)

# do the inequalities hold for all participants?
br.2htm.ineq[["parameters"]][["individual"]][,"estimates",]
br.2htm[["parameters"]][["individual"]][,"estimates",]
# See the difference between forced and non-forced inequality restrictions:
round(br.2htm[["parameters"]][["individual"]][,"estimates",] -
		br.2htm.ineq[["parameters"]][["individual"]][,"estimates",],2)

# The same for the other two models
# The restricted 2HTM
br.2htm.res &lt;- fit.mpt(d.broeder, m.2htm, r.2htm)
br.2htm.res.ineq &lt;- fit.mpt(d.broeder, m.2htm, ir.2htm)
round(br.2htm.res[["parameters"]][["individual"]][,"estimates",] -
		br.2htm.res.ineq[["parameters"]][["individual"]][,"estimates",],2)
# The 1HTM
br.1htm &lt;- fit.mpt(d.broeder, m.2htm, r.1htm)
br.1htm.ineq &lt;- fit.mpt(d.broeder, m.2htm, ir.1htm)
round(br.2htm.res[["parameters"]][["individual"]][,"estimates",] -
		br.2htm.res.ineq[["parameters"]][["individual"]][,"estimates",],2)

# These results show that we cannot compute inequality constraints for the non inequality
#  imposed models (It would look differently if we excluded critical cases, 
# i.e., 2, 6, 7, 10, 18, 21, 25, 29, 32, 34, 35, 37, 38)
# Therefore, we get the FIA for the models as computed above 
# WARNING: The following part will take a long time!

br.2htm.fia &lt;- fit.mpt.old(d.broeder, m.2htm, fia = 200000)
br.2htm.ineq.fia &lt;- fit.mpt.old(d.broeder, m.2htm, i.2htm, fia = 200000)
br.2htm.res.fia &lt;- fit.mpt.old(d.broeder, m.2htm, r.2htm, fia = 200000 )
br.2htm.res.ineq.fia &lt;- fit.mpt.old(d.broeder, m.2htm, ir.2htm, fia = 200000)
br.1htm.fia &lt;- fit.mpt.old(d.broeder, m.2htm, r.1htm, fia = 200000)
br.1htm.ineq.fia &lt;- fit.mpt.old(d.broeder, m.2htm, ir.1htm, fia = 200000)

# Model selection using the FIA
(br.select &lt;- select.mpt(list(orig.2htm = br.2htm.fia, orig.2htm.ineq = br.2htm.ineq.fia,
		res.2htm = br.2htm.res.fia, res.2htm.ineq = br.2htm.res.ineq.fia, 
		orig.1htm = br.1htm.fia, orig.1htm.ineq = br.1htm.ineq.fia)))
# The same results, ordered by FIA
br.select[order(br.select[,"delta.FIA.sum"]),]

# Compare this with the model selection not using FIA:
select.mpt(list(orig.2htm = br.2htm, orig.2htm.ineq = br.2htm.ineq, 
		res.2htm = br.2htm.res, res.2htm.ineq = br.2htm.res.ineq, 
		orig.1htm = br.1htm, orig.1htm.ineq = br.1htm.ineq))




# compare speed of no multicore versus multicore for multiple optimization runs:

require(snowfall)
# change number of CPUs if more are available
nCPU = 2
sfInit( parallel=TRUE, cpus=nCPU, type = "SOCK" )

# NO multicore
system.time(fit.mpt.old(d.broeder, m.2htm))

# multicore:
system.time(fit.mpt.old(d.broeder, m.2htm, multicore = "n.optim"))

sfStop()

## End(Not run)

  </code></pre>

<hr>
<h2 id='fit.mptinr'>
Fit cognitive models for categorical data using an objective function
</h2><span id='topic+fit.mptinr'></span>

<h3>Description</h3>

<p>Fitting function for package MPTinR. Can fit any model for categorical data specified in an objective function. Fitting can be enhanced with gradient and or Hessian. Predicted values will be added when a prediction function is present.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
fit.mptinr(
	data,
	objective, 
	param.names,
	categories.per.type,
	gradient = NULL, use.gradient = TRUE,
	hessian = NULL, use.hessian = FALSE,
	prediction = NULL,
	n.optim = 5,
	fia.df = NULL,
	ci = 95, 
	starting.values = NULL,
	lower.bound = 0,
	upper.bound = 1,
	output = c("standard", "fia", "full"),
	fit.aggregated = TRUE,
	sort.param = TRUE,
	show.messages = TRUE,
	use.restrictions = FALSE,
	orig.params = NULL,
	restrictions = NULL,	
	multicore = c("none", "individual", "n.optim"), sfInit = FALSE, nCPU = 2,
	control = list(),
    numDeriv = TRUE,
	...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit.mptinr_+3A_data">data</code></td>
<td>

<p>Either a <em>numeric</em> <code>vector</code> for individual fit or a <em>numeric</em> <code>matrix</code> or <code>data.frame</code> for multi-dataset fit. The data on each position (column for multi-dataset fit) must correspond to the respective line in the model file. Fitting for multiple datasets can be parallelized via <code>multicore</code>.
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_objective">objective</code></td>
<td>

<p>the objective function used for fitting. Needs to return a scalar likelihood value.
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_param.names">param.names</code></td>
<td>

<p>character vector giving the parameters present in the model. The order of this vector determines the order with which the output from the fitting routine is interpreted.
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_categories.per.type">categories.per.type</code></td>
<td>

<p>numeric vector indicating how many response categories each item type has.
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_gradient">gradient</code></td>
<td>

<p>the gradient function used for fitting. Needs to return a vector of same length as <code>param.names</code>.
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_use.gradient">use.gradient</code></td>
<td>

<p>logical. indicating whether or not <code>gradient</code> should be used for fitting. Default is <code>TRUE</code>
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_hessian">hessian</code></td>
<td>

<p>the Hessian function used for fitting. Needs to return a matrix with <code>dim = c(length(param.names), length(param.names)</code>.
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_use.hessian">use.hessian</code></td>
<td>

<p>logical. indicating whether or not <code>hessian</code> should be used for fitting. Default is <code>FALSE</code>
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_prediction">prediction</code></td>
<td>

<p>the prediction function. Needs to return a vector of equal length as the response categories or data. Needs to return probabilities!
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_n.optim">n.optim</code></td>
<td>

<p>Number of optimization runs. Can be parallelized via <code>multicore</code>. Default is 5. 
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_fia.df">fia.df</code></td>
<td>

<p>needed for handling MPTs with computation of FIA coming from <code><a href="#topic+fit.mpt">fit.mpt</a></code> or <code>fit.model</code>. Do not use.
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_ci">ci</code></td>
<td>

<p>A scalar corresponding to the size of the confidence intervals for the parameter estimates. Default is 95 which corresponds to 95% confidence intervals.
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_starting.values">starting.values</code></td>
<td>

<p>A <code>vector</code>, a <code>list</code>, or <code>NULL</code> (the default). If <code>NULL</code> starting values for parameters are randomly drawn from a uniform distribution with the interval <code>(0.1 - 0.9)</code>. See Details for the other options.
</p>
</td></tr> 
<tr><td><code id="fit.mptinr_+3A_lower.bound">lower.bound</code></td>
<td>

<p>numeric scalar or vector. Can be used in <code>fit.model</code> to set the lower bounds of the parameter space. See Details.
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_upper.bound">upper.bound</code></td>
<td>

<p>numeric scalar or vector. Can be used in <code>fit.model</code> to set the upper bounds of the parameter space. See Details.
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_output">output</code></td>
<td>

<p>If &quot;full&quot; <code>fit.mpt</code> will additionally return the return values of <code><a href="stats.html#topic+nlminb">nlminb</a></code> and the Hessian matrices. (If &quot;fia&quot;, <code>fit.mpt</code> will additionally return the results from <code><a href="#topic+get.mpt.fia">get.mpt.fia</a></code> (if <code>fia</code> not equal <code>NULL</code>).)
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_fit.aggregated">fit.aggregated</code></td>
<td>

<p>logical. Only relevant for multiple datasets (i.e., <code>matrix</code> or <code>data.frame</code>). Should the aggregated dataset (i.e., data summed over rows) be additionally fitted? Default (<code>TRUE</code>) fits the aggregated data. 
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_sort.param">sort.param</code></td>
<td>

<p>Logical. If TRUE, parameters are alphabetically sorted in the parameter table. If FALSE, the first parameters in the parameter table are the non-restricted ones, followed by the restricted parameters. Default is TRUE.
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_show.messages">show.messages</code></td>
<td>

<p>Logical. If TRUE the time the fitting algorithms takes is printed to the console.
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_use.restrictions">use.restrictions</code></td>
<td>

<p>needed for handling MPTs coming from <code><a href="#topic+fit.mpt">fit.mpt</a></code>. Do not use, unless you are sure what you are doing.
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_orig.params">orig.params</code></td>
<td>

<p>needed for handling models coming from <code><a href="#topic+fit.mpt">fit.mpt</a></code> or <code><a href="#topic+fit.model">fit.model</a></code>. Do not use, unless you are sure what you are doing.
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_restrictions">restrictions</code></td>
<td>

<p>needed for handling models coming from <code><a href="#topic+fit.mpt">fit.mpt</a></code> or <code><a href="#topic+fit.model">fit.model</a></code>. Do not use, unless you are sure what you are doing.
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_multicore">multicore</code></td>
<td>

<p>Character vector. If not <code>"none"</code>, uses <code>snowfall</code> for parallelization (which needs to be installed separately via <code>install.packages(snowfall)</code>). If <code>"individual"</code>, parallelizes the optimization for each individual (i.e., data needs to be a <code>matrix</code> or <code>data.frame</code>). If <code>"n.optim"</code>, parallelizes the <code>n.optim</code> optimization runs. Default is <code>"none"</code> which corresponds to no parallelization. Note that you need to initialize <code>snowfall</code> in default settings. See <code>sfInit</code> and Details.
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_sfinit">sfInit</code></td>
<td>

<p>Logical. Relevant if <code>multicore</code> is not <code>"none"</code>. If <code>TRUE</code>, <code>fit.mpt</code> will initialize and close the multicore support. If <code>FALSE</code>, (the default) assumes that <code>sfInit()</code> was initialized before. See Details.
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_ncpu">nCPU</code></td>
<td>

<p>Scalar. Only relevant if <code>multicore</code> is not <code>"none"</code> and <code>sfInit</code> is TRUE. Number of CPUs used by <code>snowfall</code>. Default is 2.
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_control">control</code></td>
<td>

<p>list containing control arguments passed on to <code><a href="stats.html#topic+nlminb">nlminb</a></code>. See there.
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_numderiv">numDeriv</code></td>
<td>

<p>logical. Should the Hessian matrix of the maximum likelihood estimates be estimated numerically using <code>numDeriv::hessian</code> in case it cannot be estimated analytically? This can be extremely time and memory consuming for larger models. Default is TRUE.
</p>
</td></tr>
<tr><td><code id="fit.mptinr_+3A_...">...</code></td>
<td>

<p>arguments passed on to the objective function, the gradient function, the hessian function and the prediction function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This functions can be used to fit any model for categorical data that can be specified via a (objective) function (i.e., especially models that are not MPTs). For fitting MPTs or other similar models such as SDTs see <code><a href="#topic+fit.mpt">fit.mpt</a></code> or <code><a href="#topic+fit.model">fit.model</a></code>.
</p>
<p>The only mandatory arguments are: <code>data</code>, <code>objective</code>, <code>param.names</code>, and <code>categories.per.type</code>. Adding a function calculating the <code>gradient</code> will usually significantly speed up the fitting. However, in extreme cases (i.e., many empty cells) using the gradient can interfere with finding the global minima. Adding the function computing the <code>hessian</code> matrix is usually only useful for obtaining the accurate confidence intervals (usually the numerically estimated Hessian matrix is equivalent unless there are many empty cells or parameters at the boundary).
</p>
<p>The <code>objective</code> (and <code>gradient</code> and <code>hessian</code>) function need to take as the first argument a numerical vector of <code>length(param.names)</code> representing the parameters. The other mandatory arguments for these functions are:<br />
<code>data</code>: A vector containing the data for the dataset being fitted.<br />
<code>param.names</code>: The character vector containing the parameter names is handed over to the objective.<br />
<code>n.params</code>: = <code>length(param.names)</code>. To speed up computation the number of parameters is also handed over to the objective on each iteration.<br />
<code>tmp.env</code>: A <code><a href="base.html#topic+environment">environment</a></code> (created with <code>new.env</code>). The objective function produced by <code>fit.mpt</code> assign the parameter values into this environment using the following statement:<br />
<code>for (i in seq_len(n.params))  assign(param.names[i],Q[i], envir = tmp.env)</code><br />
Furthermore, <code>fit.mptinr</code> assigns the data points before fitting each dataset into <code>tmp.env</code> with the variables names <code>hank.data.x</code> where <code>x</code> is the ordinal number of that data point (i.e., position or column). In other words, you can use <code>tmp.env</code> to <code><a href="base.html#topic+eval">eval</a></code> you model within this environment and access both parameters and data in it. <br />
<code>lower.bound</code> and <code>upper.bound</code>: both <code>lower.bound</code> and <code>upper.bound</code> will be passed on to the user-supplied functions as when nlminb fits without <code>gradient</code> it can try to use parameter values outside the bounds. This can be controlled with these arguments isnide the objective function.
</p>
<p>Furthermore, note that all arguments passed via <code>...</code> will be passed to <code>objective</code>, <code>gradient</code>, and <code>hessian</code>. And that these three functions need to take the same arguments. Furthermore <code>gradient</code> must return a vector as long as <code>param.names</code> and <code>hessian</code> must return a square matrix of order <code>length(param.names</code>). See <code><a href="stats.html#topic+nlminb">nlminb</a></code> for (slightly) more info.
</p>
<p>Usage of <code>gradient</code> and/or <code>hessian</code> can be controlled with <code>use.gradient</code> and <code>use.hessian</code>.
</p>
<p><code>prediction</code> is a function similar to <code>objective</code> with the difference that it should return a vector of length <code>sum(categories.per.type</code> giving the probabilities for each item type. This function needs to take the same arguments as <code>objective</code> with the only exception that it does not take <code>lower.bound</code> and <code>upper.bound</code> (but <code>...</code> is passed on to it).
</p>
<p>Note that parameters names should not start with <code>hank.</code>. 
</p>
<p>To set the starting values for the fitting process (e.g., to avoid local minima) one can set <code>starting.values</code> to a vector of length 2 and <code>n.optim &gt; 1</code>. Then, starting values are randomly drawn from a uniform distribution from <code>starting.values[1]</code> to <code>starting.values[2]</code>.
</p>
<p>Alternatively, one can supply a list with two elements to <code>starting.values</code>. Both elements need to be either of length 1 or of length equal to the number of parameters (if both are of length 1, it is the same as if you supply a vector of length 2). For each parameter n (in alphabetical order), a starting value is randomly drawn from a uniform distribution <code>starting.values[[1]][n]</code> to <code>starting.values[[2]][n]</code> (if length is 1, this is the border for all parameters).
</p>
<p>The least interesting option is to specify the starting values individually by supplying a vector with the same length as the number of parameters. Starting values must be ordered according to the alphabetical order of the parameter names. Use <code><a href="#topic+check.mpt">check.mpt</a></code> for a function that returns the alphabetical order of the parameters. If one specifies the starting values like that, <code>n.optim</code> will be set to 1 as all other values would not make any sense (the optimization routine will produce identical results with identical starting values).
</p>
<p>Multicore fitting is achieved via the <code>snowfall</code> package and needs to be initialized via <code>sfInit</code>. As initialization needs some time, you can either initialize multicore facilities yourself using <code>sfInit()</code> and setting the <code>sfInit</code> argument to <code>FALSE</code> (the default) or let MPTinR initialize multicore facilities by setting the <code>sfInit</code> argument to <code>TRUE</code>. The former is recommended as initializing <code>snowfall</code> takes some time and only needs to be done once if you run <code>fit.mpt</code> multiple times. If there are any problems with multicore fitting, first try to initialize <code>snowfall</code> outside MPTinR (e.g., <code>sfInit( parallel=TRUE, cpus=2 )</code>). If this does not work, the problem is not related to MPTinR but to snowfall (for support and references visit: <a href="https://www.imbi.uni-freiburg.de/parallel/">https://www.imbi.uni-freiburg.de/parallel/</a>).<br />
Note that you need to <em>close</em> snowfall via <code>sfStop()</code> after using MPTinR.
</p>


<h3>Value</h3>

<p>For individual fits (i.e., <code>data</code> is a <code>vector</code>) a <code>list</code> containing one or more of the following components from the best fitting model:
</p>
<table>
<tr><td><code>goodness.of.fit</code></td>
<td>
<p>A <code>data.frame</code> containing the goodness of fit values for the model. <code>Log.Likelihood</code> is the Log-Likelihood value. <code>G.Squared</code>, <code>df</code>, and <code>p.value</code> are the <code class="reqn">G^2</code> goodness of fit statistic.</p>
</td></tr>
<tr><td><code>information.criteria</code></td>
<td>
<p>A <code>data.frame</code> containing model information criteria based on the <code class="reqn">G^2</code> value. The FIA values(s) are presented if <code>fia</code> is not <code>NULL</code>.</p>
</td></tr>
<tr><td><code>model.info</code></td>
<td>
<p>A <code>data.frame</code> containing other information about the model. If the rank of the Fisher matrix (<code>rank.fisher</code>) <em>does not</em> correspond to the number of parameters in the model (<code>n.parameters</code>) this indicates a serious issue with the identifiability of the model. A common reason is that one of the parameter estimates lies on the bound of the parameter space (i.e., 0 or 1).</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>
<p>A data.frame containing the parameter estimates and corresponding confidence intervals. If a restriction file was present, the restricted parameters are marked.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>A <code>list</code> of two matrices; the first one (<code>observed</code>) contains the entered data, the second one (<code>predicted</code>) contains the predicted values.</p>
</td></tr>
</table>
<p>For multi-dataset fits (i.e., <code>data</code> is a <code>matrix</code> or <code>data.frame</code>) a <code>list</code> with similar elements, but the following differences:<br />
The first elements, <code>goodness.of.fit</code>, <code>information.criteria</code>, and <code>model.info</code>, contain the same information as for individual fits, but each are <code>lists</code> with three elements containing the respective values for: each individual in the list element <code>individual</code>, the sum of the individual values in the list element <code>sum</code>, and the values corresponding to the fit for the aggregated data in the list element <code>aggregated</code>.<br />
<code>parameters</code> is a list containing:
</p>
<table>
<tr><td><code>individual</code></td>
<td>
<p>A 3-dimensional array containing the parameter estimates ([,1,]), confidence intervals [,2:3,], and, if restrictions not <code>NULL</code>, column 4 [,4,] is 0 for non-restricted parameters, 1 for equality restricted parameters, and 2 for inequality restricted parameters. The first dimension refers to the parameters, the second to the information on each parameter, and the third to the individual/dataset.</p>
</td></tr>
<tr><td><code>mean</code></td>
<td>
<p>A <code>data.frame</code> with the mean parameter estimates from the individual estimates. No confidence intervals can be provided for these values.</p>
</td></tr>
<tr><td><code>aggregated</code></td>
<td>
<p>A data.frame containing the parameter estimates and corresponding confidence intervals for the aggregated data. If a restriction file was present, the restricted parameters are marked.</p>
</td></tr>
</table>
<p>The element <code>data</code> contains two matrices, one with the <code>observed</code>, and one with the <code>predicted</code> data (or is a list containing lists with <code>individual</code> and <code>aggregated</code> <code>observed</code> and <code>predicted</code> data).
</p>
<p>If <code>n.optim</code> &gt; 1, the <code><a href="base.html#topic+summary">summary</a></code> of the vector (matrix for multi-individual fit) containing the Log-Likelihood values returned by each run of <code>optim</code> is added to the output: <code>fitting.runs</code>
</p>
<p>When <code>output == "full"</code> the list contains the additional items:<br />
</p>
<table>
<tr><td><code>optim.runs</code></td>
<td>
<p>A list (or list of lists for multiple datasets) containing the outputs from all runs by <code>nlminb</code> (including those runs produced when fitting did not converge)</p>
</td></tr>
<tr><td><code>best.fits</code></td>
<td>
<p>A list (or list of lists for multiple datasets) containing the outputs from the runs by <code>nlminb</code> that had the lowest likelihood (i.e., the successful runs)</p>
</td></tr>
<tr><td><code>hessian</code></td>
<td>
<p>A list  containing the Hessian matrix or matrices of the final parameter estimates.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Warnings may relate to the optimization routine (e.g., <code>Optimization routine [...] did not converge successfully</code>).<br />
In these cases it is recommended to rerun the model to check if the results are stable.
</p>


<h3>Note</h3>

<p>All (model or restriction) files should end with an empty line, otherwise a warning will be shown.
</p>


<h3>Author(s)</h3>

<p>Henrik Singmann and David Kellen.
</p>


<h3>References</h3>

<p>Kellen, D., Klauer, K. C., &amp; Singmann, H. (2012). On the Measurement of Criterion Noise in Signal Detection Theory: The Case of Recognition Memory. <em>Psychological Review</em>. doi:10.1037/a0027727
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit.model">fit.model</a></code> or <code><a href="#topic+fit.mpt">fit.mpt</a></code> for a function that can fit model represented in a model file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# the example may occasionally fail due to a starting values - integration mismatch.

# Fit an SDT for a 4 alternative ranking task (Kellen, Klauer, &amp; Singmann, 2012).

ranking.data &lt;- structure(c(39, 80, 75, 35, 61, 54, 73, 52, 44, 63, 40, 48, 80,
49, 43, 80, 68, 53, 81, 60, 60, 65, 49, 58, 69, 75, 71, 47, 44,
85, 23, 9, 11, 21, 12, 21, 14, 20, 19, 15, 29, 13, 14, 15, 22,
11, 12, 16, 13, 20, 20, 9, 26, 19, 13, 9, 14, 15, 24, 9, 19,
7, 9, 26, 16, 14, 6, 17, 21, 14, 20, 18, 5, 19, 17, 5, 11, 21,
4, 9, 15, 17, 7, 17, 11, 11, 9, 19, 20, 3, 19, 4, 5, 18, 11,
11, 7, 11, 16, 8, 11, 21, 1, 17, 18, 4, 9, 10, 2, 11, 5, 9, 18,
6, 7, 5, 6, 19, 12, 3), .Dim = c(30L, 4L))

expSDTrank &lt;- function(Q, param.names, n.params, tmp.env){
   
    e &lt;- vector("numeric",4)

    mu &lt;- Q[1]
    ss &lt;- Q[2]
       
    G1&lt;-function(x){
        ((pnorm(x)^3)*dnorm(x,mean=mu,sd=ss))
    }

    G2&lt;-function(x){
        ((pnorm(x)^2)*dnorm(x,mean=mu,sd=ss)*(1-pnorm(x)))*3
    }

     G3&lt;-function(x){
        (pnorm(x)*dnorm(x,mean=mu,sd=ss)*(1-pnorm(x))^2)*3
    }
 

    e[1] &lt;- integrate(G1,-Inf,Inf,rel.tol = .Machine$double.eps^0.5)$value    
    e[2] &lt;- integrate(G2,-Inf,Inf,rel.tol = .Machine$double.eps^0.5)$value
    e[3] &lt;- integrate(G3,-Inf,Inf,rel.tol = .Machine$double.eps^0.5)$value
    e[4] &lt;- 1-e[1]-e[2]-e[3]  
   
    return(e)
}



SDTrank &lt;- function(Q, data, param.names, n.params, tmp.env, lower.bound, upper.bound){
   
    e&lt;-vector("numeric",4)

    mu &lt;- Q[1]
    ss &lt;- Q[2]
       
    G1&lt;-function(x){
        ((pnorm(x)^3)*dnorm(x,mean=mu,sd=ss))
    }

    G2&lt;-function(x){
        ((pnorm(x)^2)*dnorm(x,mean=mu,sd=ss)*(1-pnorm(x)))*3
    }

     G3&lt;-function(x){
        (pnorm(x)*dnorm(x,mean=mu,sd=ss)*(1-pnorm(x))^2)*3
    }
 

    e[1] &lt;- integrate(G1,-Inf,Inf,rel.tol = .Machine$double.eps^0.5)$value    
    e[2] &lt;- integrate(G2,-Inf,Inf,rel.tol = .Machine$double.eps^0.5)$value
    e[3] &lt;- integrate(G3,-Inf,Inf,rel.tol = .Machine$double.eps^0.5)$value
    e[4] &lt;- 1-e[1]-e[2]-e[3]  
   
    LL &lt;- -sum(data[data!=0]*log(e[data!=0]))
    return(LL)
}

fit.mptinr(ranking.data, SDTrank, c("mu", "sigma"), 4, prediction = expSDTrank, 
		lower.bound = c(0,0.1), upper.bound = Inf)
 
## End(Not run)
</code></pre>

<hr>
<h2 id='gen.data'>
Generate or bootstrap data and get predictions from a model specified in a model file (or connection).
</h2><span id='topic+gen.data'></span><span id='topic+sample.data'></span><span id='topic+gen.predictions'></span>

<h3>Description</h3>

<p><code>gen.data</code> generates random dataset(s) from given paramater values and model (specified via model file or textConnection) for paramteric bootstrap.<br />
<code>sample.data</code> generates random dataset(s) from given data for nonparametric bootstrap.<br />
<code>gen.predictions</code> generates response probabilities or predicted responses from given paramater values and model (specified via model file or textConnection). <br />
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen.data(parameter.values, samples,
	model.filename, 
	data = NULL, n.per.item.type = NULL,
	restrictions.filename = NULL, model.type = c("easy", "eqn", "eqn2"), 
	reparam.ineq = TRUE, check.model = TRUE)

sample.data(data, samples,
	model.filename = NULL, categories.per.type = NULL,
	model.type = c("easy", "eqn", "eqn2"), check.model = TRUE)	

gen.predictions(parameter.values, 
	model.filename, 
	restrictions.filename = NULL, 
	n.per.item.type = NULL, 
	model.type = c("easy", "eqn", "eqn2"), 
	reparam.ineq = TRUE, check.model = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gen.data_+3A_parameter.values">parameter.values</code></td>
<td>

<p><code>vector</code> of paramater values. Either named then order is irrelevant or unnamed then must follow the alphabetical order of paramaters (<code><a href="#topic+check.mpt">check.mpt</a></code> returns the alphabetical order of paramater names).
</p>
</td></tr>
<tr><td><code id="gen.data_+3A_samples">samples</code></td>
<td>

<p>Number of random datasets to be generated from a given set of paramater values.
</p>
</td></tr>
<tr><td><code id="gen.data_+3A_n.per.item.type">n.per.item.type</code></td>
<td>

<p><code>vector</code> of length equal to number of item types (or trees) specifying how many item each item type has. Default is <code>NULL</code>. See Details.
</p>
</td></tr> 
<tr><td><code id="gen.data_+3A_data">data</code></td>
<td>

<p>data <code>vector</code>. See Details.
</p>
</td></tr>
<tr><td><code id="gen.data_+3A_categories.per.type">categories.per.type</code></td>
<td>

<p>numeric vector indicating how many response categories each item type has.
</p>
</td></tr> 
<tr><td><code id="gen.data_+3A_model.filename">model.filename</code></td>
<td>

<p>A character <code>vector</code> specifying the location and name of the model file, pssoble a <code><a href="base.html#topic+textConnection">textConnection</a></code>. 
</p>
</td></tr>
<tr><td><code id="gen.data_+3A_restrictions.filename">restrictions.filename</code></td>
<td>

<p><code>NULL</code> or a character <code>vector</code> or a <code>list</code> of characters. The default is <code>NULL</code> which corresponds to no restrictions. A character <code>vector</code> specifies the location or name of the restrictions file. A <code>list</code> of characters contains the restrictions directly. See <code><a href="#topic+fit.mpt">fit.mpt</a></code> for Details and Examples.
</p>
</td></tr>
<tr><td><code id="gen.data_+3A_model.type">model.type</code></td>
<td>

<p>Character vector specifying whether the model file is formatted in the easy way (<code>"easy"</code>; i.e., each line represents all branches corresponding to a response category) or the traditional EQN syntax (<code>"eqn"</code> or <code>"eqn2"</code>; see Details and e.g., Stahl &amp; Klauer, 2007). If <code>model.filename</code> ends with .eqn or .EQN, <code>model.type</code> is automatically set to <code>"eqn"</code>. Default is <code>"easy"</code>.
</p>
</td></tr>
<tr><td><code id="gen.data_+3A_reparam.ineq">reparam.ineq</code></td>
<td>

<p>Should inequality restrictions be applied (i.e., the model reparametrized)? Default is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="gen.data_+3A_check.model">check.model</code></td>
<td>

<p>logical. Should model be chekced with random values whether or not the expected values sum to one per tree? Default is <code>TRUE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gen.data</code> and <code>sample.data</code> are basically wrapper for <code><a href="stats.html#topic+rmultinom">rmultinom</a></code> (called multiple times, if there is more than one item type). The <code>prob</code> argument of <code>rmultinom</code> is obtained differently for the two functions. For <code>gen.data</code> it corresponds to the predicted response proportions as returned by <code>get.predictions</code> (which is actually called by <code>gen.data</code>). For <code>sample.data</code> it is the proprtion of responses for each item type.
</p>
<p><code>gen.data</code> needs to know how big the n for each item type is. This can either be specified via the <code>data</code> or the <code>n.per.item.type</code> argument (i.e., one of those needs to be non-<code>NULL</code>). See the examples.
</p>
<p><code>sample.data</code> needs to know which response categories correspond to each item type. This can either be specified via the <code>model.filename</code> or the <code>categories.per.type</code> argument (i.e., one of those needs to be non-<code>NULL</code>). See the examples.
</p>


<h3>Value</h3>

<p>Either a vector or matrix containing the generated data (for <code>gen.data</code> and <code>sample.data</code>) or a vector containing the predictions (for <code>gen.predictions</code>).
</p>


<h3>Author(s)</h3>

<p>Henrik Singmann and David Kellen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit.mpt">fit.mpt</a></code> or <code><a href="#topic+fit.model">fit.model</a></code> for functions that will fit the generated data. Note that it is probably a very good idea to set <code>fit.aggregated = FALSE</code> when fitting larger sets of generated data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#### using the model and data from Broeder &amp; Schuetz:
data(d.broeder, package = "MPTinR")
m.2htm &lt;- system.file("extdata", "5points.2htm.model", package = "MPTinR")
m.sdt &lt;- "pkg/MPTinR/inst/extdata/broeder.sdt.model"

m.sdt &lt;- system.file("extdata", "broeder.sdt.model", package = "MPTinR")

# fit the 2HTM
br.2htm &lt;- fit.mpt(colSums(d.broeder), m.2htm)

# fit the SDT model
br.sdt &lt;- fit.model(colSums(d.broeder), m.sdt, lower.bound = c(rep(-Inf, 5), 0, 1),
	upper.bound = Inf)

# get one random dataset using the paramater values obtained (i.e., parametric bootstrap) 
# and the data argument.
gen.data(br.2htm[["parameters"]][,1], 1, m.2htm, data = colSums(d.broeder))

gen.data(br.sdt[["parameters"]][,1], 1, m.sdt, data = colSums(d.broeder))

# get one random dataset using the paramater values obtained (i.e., parametric bootstrap) 
# and the n.per.item.type argument.
gen.data(br.2htm[["parameters"]][,1], 1, m.2htm, 
	n.per.item.type = c(240, 2160, 600, 1800, 1200, 1200, 1800, 600, 2160, 240))

gen.data(br.sdt[["parameters"]][,1], 1, m.sdt, 
	n.per.item.type = c(240, 2160, 600, 1800, 1200, 1200, 1800, 600, 2160, 240))

# sample one random dataset from the original data:
sample.data(colSums(d.broeder), 1, model.filename = m.2htm)
# above uses the model.filename argument

sample.data(colSums(d.broeder), 1, categories.per.type = rep(2,10))
# above uses the categories.per.type argument


# just get the predicted proportions:
predictions.mpt &lt;- gen.predictions(br.2htm[["parameters"]][,1], m.2htm)
predictions.sdt &lt;- gen.predictions(br.sdt[["parameters"]][,1], m.sdt)

# predicting using the proactive Inhibiton Model (Riefer &amp; Batchelder, 1988, Figure 1)

model1 &lt;- system.file("extdata", "rb.fig1.model", package = "MPTinR")

gen.predictions(c(r = 0.3, p = 1, q = 0.4944), model1)  
gen.predictions(c(r = 0.3, p = 1, q = 0.4944), model1, n.per.item.type = 180)

# the order of parameters is reordered (i.e., not alphabetically)
# but as the vector is named, it does not matter!
# Compare with:
data(rb.fig1.data, package = "MPTinR")
fit.mpt(rb.fig1.data[1,], model1, n.optim = 1)
</code></pre>

<hr>
<h2 id='get.mpt.fia'>
Convenient function to get FIA for MPT
</h2><span id='topic+get.mpt.fia'></span>

<h3>Description</h3>

<p><code>get.mpt.fia</code> is a comfortable wrapper for the R-port of Wu, Myung, and Batchelder's (2010) BMPTFIA <code><a href="#topic+bmpt.fia">bmpt.fia</a></code>. It takes data, a model file, and (optionally) a restrictions file, computes the context-free representation of this file and then feeds this into <code><a href="#topic+bmpt.fia">bmpt.fia</a></code> which returns the FIA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.mpt.fia(data, model.filename, restrictions.filename = NULL, Sample = 2e+05, 
	model.type = c("easy", "eqn", "eqn2"), round.digit = 6, 
	multicore = FALSE, split = NULL, mConst = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.mpt.fia_+3A_data">data</code></td>
<td>

<p>Same as in <code><a href="#topic+fit.mpt">fit.mpt</a></code>
</p>
</td></tr>
<tr><td><code id="get.mpt.fia_+3A_model.filename">model.filename</code></td>
<td>

<p>Same as in <code><a href="#topic+fit.mpt">fit.mpt</a></code>
</p>
</td></tr>
<tr><td><code id="get.mpt.fia_+3A_restrictions.filename">restrictions.filename</code></td>
<td>

<p>Same as in <code><a href="#topic+fit.mpt">fit.mpt</a></code>
</p>
</td></tr>
<tr><td><code id="get.mpt.fia_+3A_sample">Sample</code></td>
<td>

<p>The number of random samples to be drawn in the Monte Carlo algorithm. Default is 200000.
</p>
</td></tr>
<tr><td><code id="get.mpt.fia_+3A_model.type">model.type</code></td>
<td>

<p>Same as in <code><a href="#topic+fit.mpt">fit.mpt</a></code>
</p>
</td></tr>
<tr><td><code id="get.mpt.fia_+3A_round.digit">round.digit</code></td>
<td>

<p>scalar numeric indicating to which decimal the ratios between ns in trees should be rounded (for minimizing computations with differing ns, see Details)
</p>
</td></tr>
<tr><td><code id="get.mpt.fia_+3A_multicore">multicore</code></td>
<td>

<p>Same as in <code><a href="#topic+bmpt.fia">bmpt.fia</a></code>
</p>
</td></tr>
<tr><td><code id="get.mpt.fia_+3A_split">split</code></td>
<td>

<p>Same as in <code><a href="#topic+bmpt.fia">bmpt.fia</a></code>
</p>
</td></tr>
<tr><td><code id="get.mpt.fia_+3A_mconst">mConst</code></td>
<td>

<p>A constant which is added in the Monte Carlo integration to avoid numerical underflows and is later subtracted (after appropriate transformation). Should be a power of 2 to avoid unnecessary numerical imprecision. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is called from <code><a href="#topic+fit.mpt">fit.mpt</a></code> to obtain the FIA, but can also be called independently.
</p>
<p>It performs the following steps:<br />
1.) Equality restrictions (if present) are applied to the model.<br />
2.) The representation of the model as equations is transformed to the string representation of the model into the context-free language of MPT models (L-BMPT; Purdy &amp; Batchelder, 2009). For this step to be successful it is <em>absolutely necessary</em> that the equations representing the model perfectly map the tree structure of the MPT. That is, the model file is only allowed to contain parameters, their negations (e.g., <code>Dn</code> and <code>(1 - Dn)</code>) and the operators + and *, but nothing else. Simplifications of the equations will seriously distort this step. This step is achieved by calling <code><a href="#topic+make.mpt.cf">make.mpt.cf</a></code>.<br />
Note that inequality restrictions are not included in this transformation.<br />
3.) The context free representation of the model is then fed into the MCMC function computing the FIA (the port of BMPTFIA provided by Wu, Myung, &amp; Batchelder, 2010; see <code><a href="#topic+bmpt.fia">bmpt.fia</a></code>).<br />
If inequality restrictions are present, these are specified in the call to <code><a href="#topic+bmpt.fia">bmpt.fia</a></code>.
</p>
<p>For multi-individual data sets (i.e., <code>data</code> is a <code>matrix</code> or <code>data.frame</code>), <code>get.mpt.fia</code> tries to minimize computation time. That is done by comparing the ratios of the number items between trees. To not run into problems related to floating point precision, these values are rounded to <code>round.digit</code>. Then, <code>get.mpt.fia</code> will only call <code><a href="#topic+bmpt.fia">bmpt.fia</a></code> as many times as there are differing ratios. As a consequence, the final penalty factor for FIA (<code>CFIA</code>) is calculated by <code>get.mpt.fia</code>, <em>without providing confidence intervals for the penalty factor</em>.
</p>


<h3>Value</h3>

<p>A <code>data.frame</code> containing the results as returned by <code><a href="#topic+bmpt.fia">bmpt.fia</a></code>:
</p>
<table>
<tr><td><code>CFIA</code></td>
<td>
<p>The FIA complexity value of the model with the corresponding confidence interval <code>CI.l</code> (lower bound) and <code>CI.u</code> (upper bound).</p>
</td></tr>
<tr><td><code>lnInt</code></td>
<td>
<p>The log integral term in C_FIA (Wu, Myung, &amp; Batchelder, 2010a; Equation 7) for models without inequality constraints. When inequality constraints are present, 'lnInt' does not take into account the change in the normalizing constant in the proposal distribution and must be adjusted with the output argument &lsquo;lnconst&rsquo;. The corresponding confidence interval ranges from <code>CI.lnint.l</code> (lower bound) to <code>CI.lnint.u</code> (upper bound).</p>
</td></tr>
<tr><td><code>lnconst</code></td>
<td>
<p>When inequality constraints are present, <code>lnconst</code> serves as an adjustment of codelnInt. It estimates the logarithm of the proportion of parameter space [0,1]^S that satisfies those inequality constraints, and the log integral term is given by <code>lnInt+lnconst</code>.
</p>
<p>The next [two] output argument [CI.lnconst] give the Monte Carlo confidence interval of &lsquo;lnconst&rsquo;. [.l = lower &amp; .u = upper bound of the CI]</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Henrik Singmann
</p>


<h3>References</h3>

<p>Purdy, B. P., &amp; Batchelder, W. H. (2009). A context-free language for binary multinomial processing tree models. <em>Journal of Mathematical Psychology</em>, 53, 547-561.
</p>
<p>Wu, H., Myung, J.I., &amp; Batchelder, W.H. (2010). Minimum description length model selection of multinomial processing tree models. <em>Psychonomic Bulletin &amp; Review</em>, 17, 275-286.
</p>


<h3>See Also</h3>

<p>calls <code><a href="#topic+bmpt.fia">bmpt.fia</a></code><br />
is called by <code><a href="#topic+fit.mpt">fit.mpt</a></code>, the main function for fitting MPT models
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Get the FIA for the 40 datasets from Broeder &amp; Schuetz (2009, Experiment 3)
# for the 2HTM model with inequality restrictions
# (Can take a while.)

data(d.broeder)
m.2htm &lt;- system.file("extdata", "5points.2htm.model", package = "MPTinR")
i.2htm &lt;- system.file("extdata", "broeder.2htm.ineq", package = "MPTinR")

get.mpt.fia(d.broeder, m.2htm, Sample = 1000) # Way too little samples
get.mpt.fia(d.broeder, m.2htm, i.2htm, Sample = 1000)

## Not run: 
# should produce very similar results:
get.mpt.fia(d.broeder, m.2htm, i.2htm)
get.mpt.fia(d.broeder, m.2htm, i.2htm, mConst = 2L^8)

## End(Not run)
  </code></pre>

<hr>
<h2 id='make.eqn'>
Creates an EQN model file oir MDT data file
</h2><span id='topic+make.eqn'></span><span id='topic+make.mdt'></span>

<h3>Description</h3>

<p><code>make.eqn</code> takes a model file in the &quot;easy&quot; format and creates a model file in the EQN format. <code>make.mdt</code> takes a data vector and produces an .mdt data file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make.eqn(model.filename, eqn.filename)
make.mdt(data, mdt.filename, index, prefix = "dataset")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make.eqn_+3A_model.filename">model.filename</code></td>
<td>

<p>A character <code>vector</code> specifying the location and name of the model file in the <code>easy</code> format.
</p>
</td></tr>
<tr><td><code id="make.eqn_+3A_eqn.filename">eqn.filename</code></td>
<td>

<p>A character vector specifying the location and name of the target .eqn file.
</p>
</td></tr>
<tr><td><code id="make.eqn_+3A_data">data</code></td>
<td>
<p>A vector, matrix or data.frame containing an individual data set to write to a .mdt file</p>
</td></tr>
<tr><td><code id="make.eqn_+3A_mdt.filename">mdt.filename</code></td>
<td>
<p>character vector specifying name and location of mdt file to be written.</p>
</td></tr>
<tr><td><code id="make.eqn_+3A_index">index</code></td>
<td>
<p>index or second word written to the header of the mdt file. Ignored if <code>data</code> is a matrix or data.frame. </p>
</td></tr>
<tr><td><code id="make.eqn_+3A_prefix">prefix</code></td>
<td>
<p>first word or prefix written to the mdt file. Default is <code>dataset</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>eqn and mdt files are the usual files used for programs to fit MPTs. You can use these functions to compare the results of MPTinR with other prgrams such as HMMTree or multiTree.
</p>
<p>Note that these function do not add the endings .eqn or .mdt to the filename.
</p>
<p>Since the MPTinR 0.9.4 <code>make.mdt</code> writes a single mdt file from a matrix or data.frame separating the participants via <code>===</code>.
</p>


<h3>Value</h3>

<p>Nothing
</p>


<h3>Author(s)</h3>

<p>Henrik Singmann
</p>


<h3>References</h3>

<p>More information on the .eqn format in e.g.:<br />
Stahl, C., &amp; Klauer, K. C. (2007). HMMTree: A computer program for latent-class hierarchical multinomial processing tree models. <em>Behavior Research Methods</em>, 39, 267-273.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit.mpt">fit.mpt</a></code> for the main function of MPTinR
</p>

<hr>
<h2 id='make.mpt.cf'>
Functions to transform MPT models.
</h2><span id='topic+make.mpt.cf'></span><span id='topic+lbmpt.to.mpt'></span>

<h3>Description</h3>

<p>(Helper) functions that takes an MPT model file and transforms it into a representation in the context-free language of MPT models L-BMPT (Purdy &amp; Batchelder, 2009) or takes the representation in LBMPT and returns the model equations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make.mpt.cf(model.filename, restrictions.filename = NULL, 
            model.type = c("easy", "eqn"), treewise = FALSE)

lbmpt.to.mpt(model.list, outfile = NULL, category.names= TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make.mpt.cf_+3A_model.filename">model.filename</code></td>
<td>

<p>A character <code>vector</code> specifying the location and name of the model file. 
</p>
</td></tr>
<tr><td><code id="make.mpt.cf_+3A_restrictions.filename">restrictions.filename</code></td>
<td>

<p><code>NULL</code> or a character <code>vector</code> or a <code>list</code> of characters. The default is <code>NULL</code> which corresponds to no restrictions. A character <code>vector</code> specifies the location or name of the restrictions file. A <code>list</code> of characters contains the restrictions directly. Inequality/order restrictions are silently ignored.
</p>
</td></tr>
<tr><td><code id="make.mpt.cf_+3A_model.type">model.type</code></td>
<td>

<p>Character vector specifying whether the model file is formatted in the <code>easy</code> format (<code>"easy"</code>; i.e., each line represents all branches corresponding to a response categories) or the traditional EQN syntax (<code>"eqn"</code> or <code>"eqn2"</code>). See Details in <code><a href="#topic+fit.mpt">fit.mpt</a></code>.
</p>
</td></tr>
<tr><td><code id="make.mpt.cf_+3A_treewise">treewise</code></td>
<td>

<p>logical. Should the model be concatenated to one tree before transforming to LBMPT? Default is <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="make.mpt.cf_+3A_model.list">model.list</code></td>
<td>

<p>A list of character <code>vector</code>s representing a model in LBMPT. Each element of the vector corresponds to either a parameter or category. Each list element corresponds to one tree. Can be returned from <code>make.mpt.cf</code>.
</p>
</td></tr>
<tr><td><code id="make.mpt.cf_+3A_outfile">outfile</code></td>
<td>

<p>Name of the file the model equation should be saved in (in easy format). If <code>NULL</code> (the default) prints it to the console instead (<code>stdout()</code>).
</p>
</td></tr>
<tr><td><code id="make.mpt.cf_+3A_category.names">category.names</code></td>
<td>

<p>logical. Should category names (e.g., &quot;category 1&quot;) be printed at the end of each line?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Purdy and Batchelder (2009) provide a new way of how binary multinomial processing tree (MPT) models can be represented, a context free language called L-BMPT. This function takes a model file that consists of the equations defining a model and returns a character vector representing this model in L-BMPT.
</p>
<p>There are three important things to know about this function:
</p>
<p>1. L-BMPT distinguishes between observable categories (C) and parameters (theta). As MPTinR allows parameters to have any name that is legal for a variable in R (with the only restriction that parameters should NOT start with <code>hank</code>) the L-BMPT representation of the model's parameters can also consist of any name that is a legal variable name in R. To distinguish parameters from categories, categories are represented as integers (i.e., numbers) (a number is not a legal variable name in R). Furthermore, as legal variable names may end with a number, concatenating parameters and categories into one string could lead to an ambiguous representation of the model. Therefore, the returned representation in L-BMPT is a character vector with each element representing either a parameter (any legal variable name in R) or a category (an integer).<br />
Theta: Names that are legal variable names in R.<br />
C: Integers.
</p>
<p>2. If a model consists of more than n &gt; 1 trees, this function per default concatenates the trees into a single binary MPT model by adding n-1 parameters (named <code>hank.join.x</code> with <code>x</code> be a integer starting at 1; see Wu, Myung &amp; Batchelder, 2010). This can be turned off, by setting <code>treewise</code> to TRUE.
</p>
<p>3. It is absolutely necessary that the representation of the model via equations in the model file exactly maps on the structure of the binary tree. In other words, equations in the model file can NOT be simplified in any way. The equations in the model file may only consist of the parameters and their negations (e.g. <code>d</code> and <code>(1-d)</code>). Simplifications and aggregations in the model file (e.g., from <code>u * (1-u) + u * (1-u)</code> to <code>2*u*(1-u</code>) will lead to erroneous results! Similarly, reparameterizations for inequality constraints (which can be done by <code>fit.mpt</code>) can not be represented in L-BMPT.
</p>


<h3>Value</h3>

<p><code>make.mpt.cf</code>: A character vector with each element representing either a parameter or a category (categories are represented by integer numbers). In case of multiple trees and <code>treewise = TRUE</code>, a list of such vectors.
</p>
<p><code>lbmpt.to.mpt</code>: Either prints the model to the screen or returns nothing and saves the model equations in the specified file.
</p>


<h3>Note</h3>

<p>It is absolutely necessary that the model file exactly maps on the structure of the binary tree. See Details.
</p>


<h3>Author(s)</h3>

<p>Henrik Singmann (make.mpt.cf)
</p>
<p>Quentin Gronau and Franz Dietrich (lbmpt.to.mpt, using a function from Akhil S Bhel, LinearizeNestedList)
</p>


<h3>References</h3>

<p>Purdy, B. P., &amp; Batchelder, W. H. (2009). A context-free language for binary multinomial processing tree models. <em>Journal of Mathematical Psychology</em>, 53, 547-561.
</p>
<p>Riefer, D. M., &amp; Batchelder, W. H. (1988). Multinomial modeling and the measurement of cognitive processes. <em>Psychological Review</em>, 95, 318-339.
</p>
<p>Wu, H., Myung, J., I., &amp; Batchelder, William, H. (2010). Minimum description length model selection of multinomial processing tree models. <em>Psychonomic Bulletin &amp; Review</em>, 17, 275-286.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+get.mpt.fia">get.mpt.fia</a></code> and <code>link{bmpt.fia}</code> for functions calling <code>make.mpt.cf</code> to obtain the FIA of a MPT model.
</p>
<p>See <code><a href="#topic+fit.mpt">fit.mpt</a></code> for the main function of MPTinR which also calls <code>make.mpt.cf</code> for obtaining the FIA.
</p>
<p><code><a href="#topic+prepare.mpt.fia">prepare.mpt.fia</a></code> will provide the code needed for obtaining the Minimum Description Length of a MPT model using Matlab (Wu, Myung &amp; Batchelder, 2010) and calls <code>make.mpt.cf</code> for obtaining the L-BMPT representation.<br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model2 &lt;- system.file("extdata", "rb.fig2.model", package = "MPTinR")

make.mpt.cf(model2)

make.mpt.cf(model2, treewise = TRUE)
  
lbmpt.to.mpt(make.mpt.cf(model2, treewise = TRUE))
</code></pre>

<hr>
<h2 id='MPTinR-package'>
Analyze Multinomial Processing Tree Models
</h2><span id='topic+MPTinR-package'></span><span id='topic+MPTinR'></span>

<h3>Description</h3>

<p>Provides a user-friendly way for the analysis of multinomial processing tree (MPT) models (e.g.,  Riefer, D. M., and Batchelder, W. H. [1988]. Multinomial modeling and the measurement of cognitive processes. Psychological Review, 95, 318-339) for single and multiple datasets. The main functions perform model fitting and model selection. Model selection can be done using AIC, BIC, or the Fisher Information Approximation (FIA) a measure based on the Minimum Description Length (MDL) framework. The model and restrictions can be specified in external files or within an R script in an intuitive syntax or using the context-free language for MPTs. The 'classical' .EQN file format for model files is also supported. Besides MPTs, this package can fit a wide variety of other cognitive models such as SDT models (see fit.model). It also supports multicore fitting and FIA calculation (using the snowfall package), can generate or bootstrap data for simulations, and plot predicted versus observed data.
</p>


<h3>Details</h3>

<p>The DESCRIPTION file:
</p>

<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> MPTinR</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Title: </td><td style="text-align: left;"> Analyze Multinomial Processing Tree Models</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.14.1</td>
</tr>
<tr>
 <td style="text-align: left;">
Authors@R: </td><td style="text-align: left;"> c(person("Henrik", "Singmann", role = c("aut", "cre"),
    email = "singmann@gmail.com"),
    person("David", "Kellen", role =  "aut"),
    person("Quentin", "Gronau", role =  "aut"),
    person("Christian", "Mueller", role =  "ctb"),
    person("Akhil S", "Bhel", role =  "ctb"))</td>
</tr>
<tr>
 <td style="text-align: left;">
Description: </td><td style="text-align: left;"> Provides a user-friendly way for the analysis of multinomial processing tree (MPT) models (e.g.,  Riefer, D. M., and Batchelder, W. H. [1988]. Multinomial modeling and the measurement of cognitive processes. Psychological Review, 95, 318-339) for single and multiple datasets. The main functions perform model fitting and model selection. Model selection can be done using AIC, BIC, or the Fisher Information Approximation (FIA) a measure based on the Minimum Description Length (MDL) framework. The model and restrictions can be specified in external files or within an R script in an intuitive syntax or using the context-free language for MPTs. The 'classical' .EQN file format for model files is also supported. Besides MPTs, this package can fit a wide variety of other cognitive models such as SDT models (see fit.model). It also supports multicore fitting and FIA calculation (using the snowfall package), can generate or bootstrap data for simulations, and plot predicted versus observed data.</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;= 2)</td>
</tr>
<tr>
 <td style="text-align: left;">
Depends: </td><td style="text-align: left;"> R (&gt;= 2.15.1)</td>
</tr>
<tr>
 <td style="text-align: left;">
Imports: </td><td style="text-align: left;"> numDeriv, Brobdingnag, Rcpp, stats, utils</td>
</tr>
<tr>
 <td style="text-align: left;">
Suggests: </td><td style="text-align: left;"> snowfall (&gt;= 1.84), knitr</td>
</tr>
<tr>
 <td style="text-align: left;">
LinkingTo: </td><td style="text-align: left;"> Rcpp, RcppEigen</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyLoad: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
ByteCompile: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
VignetteBuilder: </td><td style="text-align: left;"> knitr</td>
</tr>
<tr>
 <td style="text-align: left;">
NeedsCompilation: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
Packaged: </td><td style="text-align: left;"> 2021-07-13 10:44:49 UTC; singm</td>
</tr>
<tr>
 <td style="text-align: left;">
Author: </td><td style="text-align: left;"> Henrik Singmann [aut, cre],
  David Kellen [aut],
  Quentin Gronau [aut],
  Christian Mueller [ctb],
  Akhil S Bhel [ctb]</td>
</tr>
<tr>
 <td style="text-align: left;">
Maintainer: </td><td style="text-align: left;"> Henrik Singmann &lt;singmann@gmail.com&gt;</td>
</tr>
<tr>
 <td style="text-align: left;">
Repository: </td><td style="text-align: left;"> CRAN</td>
</tr>
<tr>
 <td style="text-align: left;">
Date/Publication: </td><td style="text-align: left;"> 2021-07-13 11:30:02 UTC</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<p>Index of help topics:
</p>
<pre>
MPTinR-package          Analyze Multinomial Processing Tree Models
bmpt.fia                Compute FIA for MPTs
check.mpt               Check construction of MPT models.
d.broeder               Broeder &amp; Schuetz (2009) Experiment 3
fit.model               Fit cognitive models for categorical data using
                        model files
fit.mpt                 Function to fit MPT models
fit.mpt.old             Function to fit MPT models (old)
fit.mptinr              Fit cognitive models for categorical data using
                        an objective function
gen.data                Generate or bootstrap data and get predictions
                        from a model specified in a model file (or
                        connection).
get.mpt.fia             Convenient function to get FIA for MPT
make.eqn                Creates an EQN model file oir MDT data file
make.mpt.cf             Functions to transform MPT models.
prediction.plot         Plot observed versus predicted values for
                        categorical data.
prepare.mpt.fia         Provides MATLAB command to get FIA
rb.fig1.data            Data to be used for the examples of MPTinR.
roc6                    Recognition memory ROCs used by Klauer &amp; Kellen
                        (2015)
select.mpt              Model Selection with MPTinR
</pre>

<p>Further information is available in the following vignettes:<br /><br />
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>mptinr_introduction</code> </td><td style="text-align: left;"> MPTinR: Analysis of Multinomial Processing Tree Models (source, pdf)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>To fit MPT Models use <code><a href="#topic+fit.mpt">fit.mpt</a></code>, to fit other models use <code><a href="#topic+fit.model">fit.model</a></code> or <code><a href="#topic+fit.mptinr">fit.mptinr</a></code> (which is called by the other two functions).
</p>
<p>For model selection use <code><a href="#topic+select.mpt">select.mpt</a></code>.
</p>
<p>A helper function for writing model files is <code><a href="#topic+check.mpt">check.mpt</a></code>
</p>


<h3>References</h3>

<p>Riefer, D. M., &amp; Batchelder, W. H. (1988). Multinomial modeling and the measurement of cognitive processes. <em>Psychological Review</em>, 95, 318-339
</p>
<p>Singmann, H., &amp; Kellen, D. (2013). MPTinR: Analysis of multinomial processing tree models in R. <em>Behavior Research Methods</em>, 45(2), 560-575. <a href="https://doi.org/10.3758/s13428-012-0259-0">doi:10.3758/s13428-012-0259-0</a>
</p>

<hr>
<h2 id='prediction.plot'>
Plot observed versus predicted values for categorical data.
</h2><span id='topic+prediction.plot'></span>

<h3>Description</h3>

<p>Plot observed minus predicted responses from a cognitive model for categorical data fit with MPTinR. Values above 0 indicate that there are to many responses in that category compared to the predictions, values below 0 indicate that there are to little responses compared to the predictions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prediction.plot(results, model.filename, 
dataset = 1, 
absolute = TRUE, 
spacing = 2, 
axis.labels = NULL, 
ylim, model.type = c("easy", "eqn", "eqn2"), 
args.plot = list(), args.rect = list(), args.box = list(), args.points = list(), 
args.labels = list(), numbers = c("individual", "continuous"), 
pos.numbers = c("plot", "axis"), args.numbers = list(), args.abline = list(), abline)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prediction.plot_+3A_results">results</code></td>
<td>

<p>list. Results from <code><a href="#topic+fit.mpt">fit.mpt</a></code>, <code><a href="#topic+fit.model">fit.model</a></code>, or <code><a href="#topic+fit.mptinr">fit.mptinr</a></code>.
</p>
</td></tr>
<tr><td><code id="prediction.plot_+3A_model.filename">model.filename</code></td>
<td>

<p>Same as in <code><a href="#topic+fit.mpt">fit.mpt</a></code>.
</p>
</td></tr>
<tr><td><code id="prediction.plot_+3A_dataset">dataset</code></td>
<td>

<p>integer scalar or <code>"aggregated"</code> defining which dataset to plot.
</p>
</td></tr>
<tr><td><code id="prediction.plot_+3A_absolute">absolute</code></td>
<td>

<p>logical. Should absolute deviations (the default) or G^2 deviations be plotted. See Details.
</p>
</td></tr>
<tr><td><code id="prediction.plot_+3A_spacing">spacing</code></td>
<td>

<p>The spacing between two trees in x-axis ticks.
</p>
</td></tr>
<tr><td><code id="prediction.plot_+3A_axis.labels">axis.labels</code></td>
<td>

<p>The labels on the x-axis. Default is <code>Tree 1</code> to codeTree n.
</p>
</td></tr>
<tr><td><code id="prediction.plot_+3A_ylim">ylim</code></td>
<td>

<p>the <code>ylim</code> argument to <code>plot</code>. If missing taken from data.
</p>
</td></tr>
<tr><td><code id="prediction.plot_+3A_model.type">model.type</code></td>
<td>

<p>Same as in <code><a href="#topic+fit.mpt">fit.mpt</a></code>.
</p>
</td></tr>
<tr><td><code id="prediction.plot_+3A_args.plot">args.plot</code></td>
<td>

<p><code>list</code>. Further arguments to <code><a href="graphics.html#topic+plot">plot</a></code>, see details.
</p>
</td></tr>
<tr><td><code id="prediction.plot_+3A_args.rect">args.rect</code></td>
<td>

<p><code>list</code>. Further arguments to <code><a href="graphics.html#topic+rect">rect</a></code>, see details.
</p>
</td></tr>
<tr><td><code id="prediction.plot_+3A_args.box">args.box</code></td>
<td>

<p><code>list</code>. Further arguments to <code><a href="graphics.html#topic+box">box</a></code>, see details.
</p>
</td></tr>
<tr><td><code id="prediction.plot_+3A_args.points">args.points</code></td>
<td>

<p><code>list</code>. Further arguments to <code><a href="graphics.html#topic+points">points</a></code>, see details.
</p>
</td></tr>
<tr><td><code id="prediction.plot_+3A_args.labels">args.labels</code></td>
<td>

<p><code>list</code>. Further arguments to <code><a href="graphics.html#topic+axis">axis</a></code>, see details.
</p>
</td></tr>
<tr><td><code id="prediction.plot_+3A_numbers">numbers</code></td>
<td>

<p>character vector (using partial matching) or <code>NULL</code> indicating where/if to plot numbers. Possible values are <code>"individual"</code>, <code>"continuous"</code>, or <code>NULL</code>. <code>"individual"</code> will start with <code>1</code> for the first response category in each tree/item type. <code>"continuous"</code> will use consecutive numbering matching the column numbers/ position of the data, <code>NULL</code> will plot no numbers. The default plots <code>"individual"</code> numbers.
</p>
</td></tr>
<tr><td><code id="prediction.plot_+3A_pos.numbers">pos.numbers</code></td>
<td>

<p>character vector, indicating where to plot the points. Possible values are <code>"plot"</code> or <code>"axis"</code> (using partial matching).
</p>
</td></tr>
<tr><td><code id="prediction.plot_+3A_args.numbers">args.numbers</code></td>
<td>

<p><code>list</code>. Further arguments to either <code><a href="graphics.html#topic+text">text</a></code> (if <code>pos.numbers = "plot"</code>) or <code><a href="graphics.html#topic+axis">axis</a></code> (if <code>pos.numbers = "axis"</code>), see details.
</p>
</td></tr>
<tr><td><code id="prediction.plot_+3A_args.abline">args.abline</code></td>
<td>

<p><code>list</code>. Further arguments to <code><a href="graphics.html#topic+abline">abline</a></code>, see details.
</p>
</td></tr>
<tr><td><code id="prediction.plot_+3A_abline">abline</code></td>
<td>

<p>logical. Whether to print vertical line at the positions of each point. If missing is set to <code>TRUE</code> if <code>pos.numbers = "axis"</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses base graphics to produce the plots and calls the following functions in the order given to do so: <code>plot</code> (produces an empty plot with axes), <code>rect</code> (produces the shaded area for each tree/ item type), <code>box</code> (produces another box around the plot), possibly <code>abline</code> (produces the vertical lines for each point), <code>points</code> (adds the data points), and depending on the value of <code>numbers</code> and <code>pos.numbers</code> either <code>text</code> (adds the numbers in the plot) or <code>axis</code> (adds the numbers below the plot).
</p>
<p>For all of those functions default values are set but can be changed using the corresponding argument. These argument must be a named list containing arguments to that function (see Examples). Default arguments are:
</p>

<ul>
<li> <p><code>args.plot</code>:  <code>list(xlab = "", ylab = "", main = "")</code>
</p>
</li>
<li> <p><code>args.rect</code>: <code>list(col = "grey", border = "transparent", density = 30, angle = 45)</code>
</p>
</li>
<li> <p><code>args.box</code>: nothing
</p>
</li>
<li><p>args.points: <code>list(pch = 1, cex = 2.25)</code>
</p>
</li>
<li><p>args.labels: either <code>list(line = -1)</code> or if plotting <code>numbers</code> at <code>"axis"</code>, <code>list(line = 1)</code>
</p>
</li>
<li><p>args.numbers (if <code>pos.numbers = "plot"</code>): <code>list(labels = as.character(numbers.pch), cex = 0.7)</code> (If you change <code>"labels"</code> you can define what to plot instead of numbers).
</p>
</li>
<li><p>args.numbers (if <code>pos.numbers = "axis"</code>): <code>list(labels = numbers.pch, cex.axis = 0.6, mgp = c(0,0.3,0))</code> (If you change <code>"labels"</code> you can define what to plot instead of numbers)
</p>
</li>
<li><p>args.abline: <code>list(col = "darkgrey")</code>.
</p>
</li></ul>

<p>If <code>absolute = TRUE</code> (the default) absolute deviations are plotted (i.e., observed - predicted from the model). If <code>absolute = FALSE</code> G^2 values are plotted which are computed for all predictions where data is non 0 with: </p>
<p style="text-align: center;"><code class="reqn">2 \times \mbox{data} \times (log(\mbox{data}) - log(\mbox{predictions}))</code>
</p>



<h3>Value</h3>

<p>Invoked for its side effects, but invisibly returns a <code>list</code> with the x and y positions for each point.
</p>


<h3>Note</h3>

<p>Please report all problems.
</p>


<h3>Author(s)</h3>

<p>Henrik Singmann. Thanks to David Kellen for discussion and ideas.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit.mpt">fit.mpt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#### using the model and data from Broeder &amp; Schuetz:
data(d.broeder, package = "MPTinR")
m.2htm &lt;- system.file("extdata", "5points.2htm.model", package = "MPTinR")
m.sdt &lt;- "pkg/MPTinR/inst/extdata/broeder.sdt.model"

m.sdt &lt;- system.file("extdata", "broeder.sdt.model", package = "MPTinR")

# fit the 2HTM
br.2htm &lt;- fit.mpt(d.broeder, m.2htm)

# graphical parameters
par(mfrow = c(2,2))
prediction.plot(br.2htm, m.2htm, 4)
prediction.plot(br.2htm, m.2htm, 4, ylim = c(-4, 4), numbers = NULL, 
	args.points = list(pch = 16, cex = 1.5))
prediction.plot(br.2htm, m.2htm, 4, ylim = c(-4, 4), args.plot = list(main = "Dataset 4 - A"),
	abline = TRUE, numbers = "continuous")
prediction.plot(br.2htm, m.2htm, 4, ylim = c(-4, 4), args.plot = list(main = "Dataset 4 - B"),
	pos.numbers = "axis", abline = TRUE, 
	args.numbers = list(mgp = c(3, 0.2, 0), cex.axis = 0.35),
	args.points = list(pch = 4, cex = 1.5))
dev.off()

prediction.plot(br.2htm, m.2htm, "aggregated", axis.labels = unlist(lapply(c(10, 25, 50, 75, 90),
	paste, c("o.o", "o.n"), sep = "")))

# fit the SDT
br.sdt &lt;- fit.model(d.broeder, m.sdt, lower.bound = c(rep(-Inf, 5), 0, 1), upper.bound = Inf)

axis.labels &lt;- unlist(lapply(c(10, 25, 50, 75, 90), paste, c("o.o", "o.n"), sep = ""))
# compare predictions for aggregated data:
par(mfrow = c(2,2))
prediction.plot(br.2htm, m.2htm, "aggregated", ylim = c(-30, 30), 
	args.plot = list(main = "MPT model - absolute"), axis.labels = axis.labels)
prediction.plot(br.sdt, m.2htm, "aggregated", ylim = c(-30, 30),
	args.plot = list(main = "SDT model - absolute"), axis.labels = axis.labels)
prediction.plot(br.2htm, m.2htm, "aggregated", ylim = c(-60, 60), 
	args.plot = list(main = "MPT model - G.squared"), absolute = FALSE, 
	axis.labels = axis.labels, pos.numbers = "axis", args.points = list(pch = 8, cex = 1))
prediction.plot(br.sdt, m.2htm, "aggregated", ylim = c(-60, 60),
	args.plot = list(main = "SDT model - G.squared"), absolute = FALSE, 
	axis.labels = axis.labels, pos.numbers = "axis", args.points = list(pch = 8, cex = 1))

# comparing absoulte and G-sqaured plot with zero counts in cell 2:
par(mfrow = c(2,2))
prediction.plot(br.2htm, m.2htm, 2, ylim = c(-1, 1),
	args.plot = list(main = "MPT model - absolute"))
prediction.plot(br.sdt, m.2htm, 2, ylim = c(-1, 1),
	args.plot = list(main = "SDT model - absolute"))
prediction.plot(br.2htm, m.2htm, 2, ylim = c(-2, 2),
	args.plot = list(main = "MPT model - G.squared"), absolute = FALSE)
prediction.plot(br.sdt, m.2htm, 2, ylim = c(-2, 2),
	args.plot = list(main = "SDT model - G.squared"), absolute = FALSE)

## End(Not run)

</code></pre>

<hr>
<h2 id='prepare.mpt.fia'>
Provides MATLAB command to get FIA
</h2><span id='topic+prepare.mpt.fia'></span>

<h3>Description</h3>

<p>This function needs data and a model files and outputs the exact command needed to obtain the minimum description length measure for MPT models using the procedure by Wu, Myung, and Batchelder (2010) for MATLAB. It can be considered an extended wrapper for <code><a href="#topic+make.mpt.cf">make.mpt.cf</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prepare.mpt.fia(data, model.filename, restrictions.filename = NULL,
	outfile = "clipboard", Sample = 2e+05, model.type = c("easy", "eqn", "eqn2"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prepare.mpt.fia_+3A_data">data</code></td>
<td>

<p>Either a <em>numeric</em> <code>vector</code> for individual fit or a <em>numeric</em> <code>matrix</code> or <code>data.frame</code> for multi-individual fit. The data on each position (column for multi individual fit) must correpsond to the relevant line in the model file.
</p>
</td></tr>
<tr><td><code id="prepare.mpt.fia_+3A_model.filename">model.filename</code></td>
<td>

<p>A character <code>vector</code> specifying the location and name of the model file.
</p>
</td></tr>
<tr><td><code id="prepare.mpt.fia_+3A_restrictions.filename">restrictions.filename</code></td>
<td>

<p><code>NULL</code> or a character <code>vector</code> specifying the location and name of the restrictions file. Default is <code>NULL</code> which corresponds to no restrictions.
</p>
</td></tr>
<tr><td><code id="prepare.mpt.fia_+3A_outfile">outfile</code></td>
<td>

<p>A character vector specifying the name of the file where the MATLAB code is saved. Default is <code>"clipboard"</code> which will copy the output to the clipboard and will not write it to a file (Windows only). Actually, this parameter is directly passed to <code><a href="base.html#topic+writeLines">writeLines</a></code> which interprets character vectors as filenames, so any other legal <code><a href="base.html#topic+connection">connection</a></code> can be used.
</p>
</td></tr>
<tr><td><code id="prepare.mpt.fia_+3A_sample">Sample</code></td>
<td>

<p>Number of Monte Carlo samples to be used by the procedure of Wu, Myung, and Batchelder (2010). Default is 200.000.
</p>
</td></tr>
<tr><td><code id="prepare.mpt.fia_+3A_model.type">model.type</code></td>
<td>

<p>Character vector specifying whether the model file is formatted in the <code>easy</code> format (<code>"easy"</code>; i.e., each line represents all branches corresponding to a response categories) or the traditional EQN syntax (<code>"eqn"</code> or <code>"eqn2"</code>). See Details in <code><a href="#topic+fit.mpt">fit.mpt</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses <code><a href="#topic+make.mpt.cf">make.mpt.cf</a></code> to create the representation in the L-BMPT. Therefore, it is necessary that the representation of the model via equations in the model file exactly maps on the structure of the binary tree (see <code><a href="#topic+make.mpt.cf">make.mpt.cf</a></code> for more details).
</p>
<p>Whereas <code><a href="#topic+fit.mpt">fit.mpt</a></code> can reparameterize MPT models for fitting inequality constraints, Wu, Myung, and Batchelder (2010) have used another method to deal with these issues that is also adopted here. Our function does not report a reparameterized version of the MPT model that satisfies the inequality contraints, but modifies the appropriate argument in the call to the function by Wu et al (2010).
</p>
<p>Note that MATLAB needs the statistics toolbox to run the script by Wu, Myung, and Batchelder (2010).
</p>


<h3>Value</h3>

<p>The most important value is the output to a file or clipboard (Windows only) of the MATLAB code to get the minimum description length. For multiple individuals multiple outputs are generated which only differ if the ns of the data differ. Furthermore, each argument is returned in a list:
</p>
<table>
<tr><td><code>s</code></td>
<td>
<p>The string representation of the model.</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>
<p>A list of the numbers representing the parameters.</p>
</td></tr>
<tr><td><code>param.codes</code></td>
<td>
<p>A vector describing which number corresponds to which parameter in the parameters vector.</p>
</td></tr>
<tr><td><code>category</code></td>
<td>
<p>The numbers representing the categories.</p>
</td></tr>
<tr><td><code>ineq</code></td>
<td>
<p>The matrix representing the inequality constraints.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>The n of the data.</p>
</td></tr>
<tr><td><code>internal</code></td>
<td>
<p>The L-BMPT representation as returned by <code>make.mpt.cf</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Henrik Singmann
</p>


<h3>References</h3>

<p>Wu, H., Myung, J., I., &amp; Batchelder, William, H. (2010). Minimum description length model selection of multinomial processing tree models. <em>Psychonomic Bulletin &amp; Review</em>, 17, 275-286.
</p>


<h3>See Also</h3>

<p>Since we ported the original BMPTFIA function by Wu, Myung, &amp; Batchelder (2010) to R (<code><a href="#topic+bmpt.fia">bmpt.fia</a></code>), this function is a little bit outdated. However, getting the FIA in Matlab is (still) faster than getting it in R.
</p>
<p>See also <code><a href="#topic+get.mpt.fia">get.mpt.fia</a></code> which takes the same arguments but will then compute the FIA using the function provided by Wu et al. (2010) ported to R.
</p>
<p><code><a href="#topic+make.mpt.cf">make.mpt.cf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# This example produces the code for the first example of how to use the 
# function by Wu, Myung &amp; Batchelder (2010, pp. 280):
# Value should be around 12.61 and 12.62

model.1htm &lt;- system.file("extdata", "wmb.ex1.model", package = "MPTinR")
model.1htm.restr &lt;- system.file("extdata", "wmb.ex1.restr", package = "MPTinR")

prepare.mpt.fia(c(250,0,0,250,0,0,500,0,0), model.1htm, model.1htm.restr)

## End(Not run)
</code></pre>

<hr>
<h2 id='rb.fig1.data'>
Data to be used for the examples of MPTinR.
</h2><span id='topic+rb.fig1.data'></span><span id='topic+rb.fig2.data'></span>

<h3>Description</h3>

<p>Dataset 1 (fig1) is taken from Riefer &amp; Batchelder (1988, Table 1) and contains multiple individuals.<br />
Dataset 2 (fig2) is taken from Riefer &amp; Batchelder (1988, Table 3).<br />
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(rb.fig1.data)
data(rb.fig2.data)
</code></pre>


<h3>Source</h3>

<p>Riefer, D. M., &amp; Batchelder, W. H. (1988). Multinomial modeling and the measurement of cognitive processes. <em>Psychological Review</em>, 95, 318-339.
</p>

<hr>
<h2 id='ROCs'>
Recognition memory ROCs used by Klauer &amp; Kellen (2015)
</h2><span id='topic+roc6'></span><span id='topic+roc8'></span>

<h3>Description</h3>

<p>Data of the meta-analysis on recognition memory ROC (receiver operating characteristic) curves reported in Klauer and Kellen (2015). In total there are 850 individual ROCs, 459 6-point ROCs and 391 8-point ROCs. Both data sets first report responses to old items and then to new item. For both item types the response categories are ordered from sure-new to sure-old. Please always cite the original authors when using this data. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("roc6")
data("roc8")
</code></pre>


<h3>Details</h3>

<p>The source of each data set is given in the <code>exp</code> column of each data set. The <code>id</code> column gives a unique id for each data set. For the 6-point ROCs the first 12 columns contain the data, for the 8-point ROCs, the first 16 columns.
</p>


<h3>Note</h3>

<p><b>Whenever using any of the data available here, please make sure to cite the original sources given in the following.</b>
</p>


<h3>Source</h3>

<p>The 6-point ROCs contains data from the following sources:
</p>

<ul>
<li> <p><code>Dube_2012-P</code> and <code>Dube_2012-W</code>:<br />
Dube, C., &amp; Rotello, C. M. (2012). Binary ROCs in perception and recognition memory are curved. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, 38(1), 130-151. <a href="https://doi.org/10.1037/a0024957">doi:10.1037/a0024957</a>
</p>
</li>
<li> <p><code>heathcote_2006_e1</code> and <code>heathcote_2006_e2</code>:<br />
Heathcote, A., Ditton, E., &amp; Mitchell, K. (2006). Word frequency and word likeness mirror effects in episodic recognition memory. <code>Memory &amp; Cognition</code>, 34(4), 826-838. <a href="https://doi.org/10.3758/BF03193430">doi:10.3758/BF03193430</a>
</p>
</li>
<li> <p><code>Jaeger_2013</code>:<br />
Jaeger, A., Cox, J. C., &amp; Dobbins, I. G. (2012). Recognition confidence under violated and confirmed memory expectations. Journal of Experimental Psychology: General, 141(2), 282-301. <a href="https://doi.org/10.1037/a0025687">doi:10.1037/a0025687</a>
</p>
</li>
<li> <p><code>Koen_2010_pure</code>:<br />
Koen, J. D., &amp; Yonelinas, A. P. (2010). Memory variability is due to the contribution of recollection and familiarity, not to encoding variability. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, 36(6), 1536-1542. <a href="https://doi.org/10.1037/a0020448">doi:10.1037/a0020448</a>
</p>
</li>
<li> <p><code>Koen_2011</code>:<br />
Koen, J. D., &amp; Yonelinas, A. P. (2011). From humans to rats and back again: Bridging the divide between human and animal studies of recognition memory with receiver operating characteristics. <em>Learning &amp; Memory</em>, 18(8), 519-522. <a href="https://doi.org/10.1101/lm.2214511">doi:10.1101/lm.2214511</a>
</p>
</li>
<li> <p><code>Koen-2013_full</code> and <code>Koen-2013_immediate</code>:<br />
Koen, J. D., Aly, M., Wang, W.-C., &amp; Yonelinas, A. P. (2013). Examining the causes of memory strength variability: Recollection, attention failure, or encoding variability? <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, 39(6), 1726-1741. <a href="https://doi.org/10.1037/a0033671">doi:10.1037/a0033671</a>
</p>
</li>
<li> <p><code>Pratte_2010</code>:<br />
Pratte, M. S., Rouder, J. N., &amp; Morey, R. D. (2010). Separating mnemonic process from participant and item effects in the assessment of ROC asymmetries. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, 36(1), 224-232. <a href="https://doi.org/10.1037/a0017682">doi:10.1037/a0017682</a>
</p>
</li>
<li> <p><code>Smith_2004</code>:<br />
Smith, D. G., &amp; Duncan, M. J. J. (2004). Testing Theories of Recognition Memory by Predicting Performance Across Paradigms. <em>Journal of Experimental Psychology. Learning, Memory &amp; Cognition</em>, 30(3), 615-625.
</p>
</li></ul>

<p>The 8-point ROCs contains data from the following sources:
</p>

<ul>
<li> <p><code>Benjamin_2013</code>:<br />
Benjamin, A. S., Tullis, J. G., &amp; Lee, J. H. (2013). Criterion Noise in Ratings-Based Recognition: Evidence From the Effects of Response Scale Length on Recognition Accuracy. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, 39, 1601-1608. <a href="https://doi.org/10.1037/a0031849">doi:10.1037/a0031849</a>
</p>
</li>
<li> <p><code>Onyper_2010-Pics</code> and <code>Onyper_2010-Words</code>:<br />
Onyper, S. V., Zhang, Y. X., &amp; Howard, M. W. (2010). Some-or-none recollection: Evidence from item and source memory. <em>Journal of Experimental Psychology: General</em>, 139(2), 341-364. <a href="https://doi.org/10.1037/a0018926">doi:10.1037/a0018926</a>
</p>
</li></ul>



<h3>References</h3>

<p>Klauer, K. C., &amp; Kellen, D. (2015). The flexibility of models of recognition memory: The case of confidence ratings. <em>Journal of Mathematical Psychology</em>, 67, 8-25. <a href="https://doi.org/10.1016/j.jmp.2015.05.002">doi:10.1016/j.jmp.2015.05.002</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# This example shows only how to fit the 6-point ROCs
data("roc6")

# 2HTM (2-high threshold model)
htm &lt;- "
(1-Do)*(1-g)*(1-gn1)*(1-gn2)
(1-Do)*(1-g)*(1-gn1)*gn2
(1-Do)*(1-g)*gn1
Do*(1-do1)*(1-do2)  + (1-Do)*g*go1
Do*do1 + (1-Do)*g*(1-go1)*go2
Do*(1-do1)*do2 + (1-Do)*g*(1-go1)*(1-go2)

Dn*(1-dn1)*dn2 + (1-Dn)*(1-g)*(1-gn1)*(1-gn2)
Dn*dn1 + (1-Dn)*(1-g)*(1-gn1)*gn2
Dn*(1-dn1)*(1-dn2) + (1-Dn)*(1-g)*gn1
(1-Dn)*g*go1
(1-Dn)*g*(1-go1)*go2
(1-Dn)*g*(1-go1)*(1-go2)
"

# full 2HTM is over-parametereized:
check.mpt(textConnection(htm))
# apply some symmetric response mapping restrictions for D and g:
check.mpt(textConnection(htm), list("dn2 = do2", "gn2 = go2"))



# UVSD (unequal variance signal detection model)
uvsd &lt;- "
pnorm(cr1, mu, sigma)
pnorm(cr1+cr2, mu, sigma) - pnorm(cr1, mu, sigma)
pnorm(cr3+cr2+cr1, mu, sigma) - pnorm(cr2+cr1, mu, sigma)
pnorm(cr4+cr3+cr2+cr1, mu, sigma) - pnorm(cr3+cr2+cr1, mu, sigma)
pnorm(cr5+cr4+cr3+cr2+cr1, mu, sigma) - pnorm(cr4+cr3+cr2+cr1, mu, sigma)
1 - pnorm(cr5+cr4+cr3+cr2+cr1, mu, sigma)
  
pnorm(cr1)
pnorm(cr2+cr1) - pnorm(cr1)
pnorm(cr3+cr2+cr1) - pnorm(cr2+cr1)
pnorm(cr4+cr3+cr2+cr1) - pnorm(cr3+cr2+cr1)
pnorm(cr5+cr4+cr3+cr2+cr1) - pnorm(cr4+cr3+cr2+cr1)
1 - pnorm(cr5+cr4+cr3+cr2+cr1)
"

# confidence criteria are parameterized as increments:
check.mpt(textConnection(uvsd))
# cr1 = [-Inf, Inf]
# cr2, cr3, cr4, cr5 = [0, Inf]
# mu = [-Inf, Inf]
# sigma = [0, Inf]


# MSD (mixture signal detection model): 
# NOTE: To follow CRAN rules restricting examples to a width of 100 characters, 
# the following example is splitted into multiple strings concatenated by paste().
# To view the full model use: cat(msd)
msd &lt;- paste(c("
l*(pnorm(cr1-mu))  +  (1 - l) * (pnorm(cr1-mu2))
l*(pnorm(cr1+cr2-mu) - pnorm(cr1-mu)) + (1 - l)*(pnorm(cr1+cr2-mu2)-pnorm(cr1-mu2))
l*(pnorm(cr1+cr2+cr3-mu)-pnorm(cr1+cr2-mu)) + (1-l)*(pnorm(cr1+cr2+cr3-mu2)-pnorm(cr1+cr2-mu2))
",
"l*(pnorm(cr1+cr2+cr3+cr4-mu) - pnorm(cr1+cr2+cr3-mu)) + ",
"(1 - l)*(pnorm(cr1+cr2+cr3+cr4-mu2)-pnorm(cr1+cr2+cr3-mu2))",
"
l*(pnorm(cr1+cr2+cr3+cr4+cr5-mu)-pnorm(cr1+cr2+cr3+cr4-mu)) + ",
"(1 - l)*(pnorm(cr1+cr2+cr3+cr4+cr5-mu2)-pnorm(cr1+cr2+cr3+cr4-mu2))",
"
l * (1-pnorm(cr1+cr2+cr3+cr4+cr5-mu))  +  (1 - l)*(1-pnorm(cr1+cr2+cr3+cr4+cr5-mu2))

pnorm(cr1)
pnorm(cr1+cr2) - pnorm(cr1)
pnorm(cr1+cr2+cr3) - pnorm(cr1+cr2)
pnorm(cr1+cr2+cr3+cr4) - pnorm(cr1+cr2+cr3)
pnorm(cr1+cr2+cr3+cr4+cr5) - pnorm(cr1+cr2+cr3+cr4)
1-pnorm(cr1+cr2+cr3+cr4+cr5)
"), collapse = "") 
cat(msd)

# confidence criteria are again parameterized as increments:
check.mpt(textConnection(msd))
# cr1 = [-Inf, Inf]
# cr2, cr3, cr4, cr5 = [0, Inf]
# lambda = [0, 1]
# mu, mu2 = [-Inf, Inf]


# DPSD (dual-process signal detection model)
dpsd &lt;- "
(1-R)*pnorm(cr1- mu)
(1-R)*(pnorm(cr1 + cr2 - mu) - pnorm(cr1 - mu))
(1-R)*(pnorm(cr1 + cr2 + cr3 - mu) - pnorm(cr1 + cr2 - mu))
(1-R)*(pnorm(cr1 + cr2 + cr3 + cr4 - mu) - pnorm(cr1 + cr2 + cr3 - mu))
(1-R)*(pnorm(cr1 + cr2 + cr3 + cr4 + cr5 - mu) - pnorm(cr1 + cr2 + cr3 + cr4 - mu))
R + (1-R)*(1 - pnorm(cr1 + cr2 + cr3 + cr4 + cr5 - mu))

pnorm(cr1)
pnorm(cr1 + cr2) - pnorm(cr1)
pnorm(cr1 + cr2 + cr3) - pnorm(cr1 + cr2)
pnorm(cr1 + cr2 + cr3 + cr4) - pnorm(cr1 + cr2 + cr3)
pnorm(cr1 + cr2 + cr3 + cr4 + cr5) - pnorm(cr1 + cr2 + cr3 + cr4)
1 - pnorm(cr1 + cr2 + cr3 + cr4 + cr5)
"

uvsd_fit &lt;- fit.model(roc6[,1:12], textConnection(uvsd),
            lower.bound=c(-Inf, rep(0, 5), 0.001), upper.bound=Inf)

msd_fit &lt;- fit.model(roc6[,1:12], textConnection(msd),
            lower.bound=c(-Inf, rep(0, 7)), upper.bound=c(rep(Inf, 5), 1, Inf, Inf))

dpsd_fit &lt;- fit.model(roc6[,1:12], textConnection(dpsd),
            lower.bound=c(-Inf, rep(0, 6)), upper.bound=c(rep(Inf, 6), 1))

htm_fit &lt;- fit.mpt(roc6[,1:12], textConnection(htm), 
                   list("dn2 = do2", "gn2 = go2"))

select.mpt(list(uvsd_fit, dpsd_fit, msd_fit, htm_fit))
# Note that the AIC and BIC results do not adequately take model flexibility into account.
##      model n.parameters G.Squared.sum df.sum p.sum p.smaller.05
## 1 uvsd_fit            7      1820.568   1377     0           50
## 2 dpsd_fit            7      2074.188   1377     0           64
## 3  msd_fit            8      1345.595    918     0           51
## 4  htm_fit            9      1994.217    459     0          138
##   delta.AIC.sum wAIC.sum AIC.best delta.BIC.sum wBIC.sum BIC.best
## 1        0.0000        1      230        0.0000        1      273
## 2      253.6197        0      161      253.6197        0      183
## 3      443.0270        0       16     4996.8517        0        3
## 4     2009.6489        0       56    11117.2982        0        4

## End(Not run)
</code></pre>

<hr>
<h2 id='select.mpt'>
Model Selection with MPTinR
</h2><span id='topic+select.mpt'></span>

<h3>Description</h3>

<p>This function performs model selection for results produced by MPTinR's <code><a href="#topic+fit.mpt">fit.mpt</a></code>. It takes multiple results from <code><a href="#topic+fit.mpt">fit.mpt</a></code> as a list and returns a <code>data.frame</code> comparing the models using various model selection criteria (e.g., FIA) and AIC and BIC weights. For model selection of multi-dataset fits <code>select.mpt</code> will additionally count how often each model provided the best fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>select.mpt(mpt.results, output = c("standard", "full"), round.digit = 6, dataset)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="select.mpt_+3A_mpt.results">mpt.results</code></td>
<td>

<p>A <code>list</code> containing results from <code><a href="#topic+fit.mpt">fit.mpt</a></code>.
</p>
</td></tr>
<tr><td><code id="select.mpt_+3A_output">output</code></td>
<td>

<p><code>"standard"</code> or <code>"full"</code>. If <code>"full"</code> additionally returns original FIA, AIC, and BIC values, and, for multi-individual fits, compares the model-selection criteria for the aggregated data.
</p>
</td></tr>
<tr><td><code id="select.mpt_+3A_round.digit">round.digit</code></td>
<td>

<p>Integer specifying to which decimal place the results should be rounded. Default is 6. Is also used for rounding FIA, AIC, and BIC values before counting the best fitting values per individual datasets.
</p>
</td></tr>
<tr><td><code id="select.mpt_+3A_dataset">dataset</code></td>
<td>

<p>Integer vector specifying whether or not to restrict the individual comparison top certain dataset(s). Aggregated results will not be displayed if this argument is present. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>select.mpt</code> is the second major function of MPTinR, next to <code><a href="#topic+fit.mpt">fit.mpt</a></code>. It takes a list of results produced by <code>fit.mpt</code> and returns a <code>data.frame</code> comparing the models using the information criteria obtained by <code>fit.mpt</code>. That is, if FIA was not obtained for the models, <code>select.mpt</code> only uses AIC and BIC. We strongly recommend using FIA for model selection (see e.g., Gruenwald, 2000).
</p>
<p>The outputs follows the same principle for all information criteria. The lowest value is taken as the reference value and the differences to this value (i.e., the <code>delta</code>) are reported for all models (e.g., <code>delta.FIA</code>). If one additionally wants the original values, <code>output</code> needs to be set to <code>"full"</code>.
</p>
<p>For AIC and BIC, AIC and BIC weights are reported as <code>wAIC</code> and <code>wBIC</code> (Wagenmakers &amp; Farrell, 2004).
</p>
<p>For multi-individual fit, <code>select.mpt</code> will additionally return how often each model provided the best fit (e.g., <code>FIA.best</code>). Values are rounded before determining which is the best fitting model. Note that there can be ties so that two models provide the best fit. Furthermore, if <code>output</code> is <code>"standard"</code>, only results for the summed information criteria are returned (indicated by the postfix <code>.sum</code>). To obtain model selection results for the aggregated data (indicated by postfix <code>.aggregated</code>), <code>output</code> needs to be set to <code>"full"</code>.
</p>
<p>select.mpt will check if the data of the results returned from <code>fit.mpt</code> are equal. (If they are not equal model selection can not be done.)
</p>
<p>Note that the values in the returned <code>data.frame</code> are rounded to the <code>round.digit</code>th decimal place.
</p>


<h3>Value</h3>

<p>A <code>data.frame</code> containing the model selection values:<br />
<code>model</code>: Name or number of model (names are either taken from <code>mpt.results</code> or obtained via <code>match.call</code>).<br />
<code>n.parameters</code>: Number of parameters for each model.<br />
<code>G.Squared</code>: G.Squared values of the model (from summed fits for multiple datasets).<br />
<code>df</code>: df values of the model (from summed fits for multiple datasets).<br />
<code>p.value</code>: p values of the model (from summed fits for multiple datasets).<br /> 
<code>p.smaller.05</code>: How many of the individual data sets have p &lt; .05 (for multiple datasets only).<br /> 
For the information criteria (i.e., FIA, AIC, BIC) <code>X</code>, <code>delta.X</code>, <code>X.best</code>, <code>X</code>, <code>wX</code> represent: The difference from the reference model, how often each model provided the best fit (only for multi-individual fit), the absolute value, the weights (only AIC and BIC).<br />
For multi-indivudal fit the postfix indicates whether the results refer to the summed information criteria from individual fit <code>.sum</code> or the information criteria from the aggregated data <code>.aggregated</code>.
</p>


<h3>Note</h3>

<p>As of March 2015 BIC and FIA are calculated anew if the results are displayed for multiple data sets as BIC and FIA cannot directly be summed across participants due to the <code class="reqn">log(n)</code> terms in their formula (while AIC can be summed). Instead one first needs to sum the <code class="reqn">G^2</code> values, <code class="reqn">n</code>, and the number of parameters, and only then can BIC and FIA be calculated for those summed values.
</p>
<p>If any of the models is fitted with <code>fit.aggregated = FALSE</code> no aggregated results are presented.
</p>


<h3>Author(s)</h3>

<p>Henrik Singmann
</p>


<h3>References</h3>

<p>Gruenwald, P.D. (2000). Model selection based on minimum description length. <em>Journal of Mathematical Psychology</em>, 44, 133-152.
</p>
<p>Wagenmakers, E.J. &amp; Farrell, S. (2004). AIC model selection using Akaike weights. <em>Psychonomic Bulletin &amp; Review</em>, 11, 192-196.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit.mpt">fit.mpt</a></code> for obtaining the results needed here and an example using multi-individual fit and FIA.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# This example compares the three versions of the model in 
# Riefer and Batchelder (1988, Figure 2)

data(rb.fig2.data)
model2 &lt;- system.file("extdata", "rb.fig2.model", package = "MPTinR")
model2r.r.eq &lt;- system.file("extdata", "rb.fig2.r.equal", package = "MPTinR")
model2r.c.eq &lt;- system.file("extdata", "rb.fig2.c.equal", package = "MPTinR")

# The full (i.e., unconstrained) model
ref.model &lt;- fit.mpt(rb.fig2.data, model2)
# All r equal
r.equal &lt;- fit.mpt(rb.fig2.data, model2, model2r.r.eq)
# All c equal
c.equal &lt;- fit.mpt(rb.fig2.data, model2, model2r.c.eq)

select.mpt(list(ref.model, r.equal, c.equal))



## Not run: 

# Example from Broder &amp; Schutz (2009)

data(d.broeder, package = "MPTinR")
m.2htm &lt;- system.file("extdata", "5points.2htm.model", package = "MPTinR")
r.2htm &lt;- system.file("extdata", "broeder.2htm.restr", package = "MPTinR")
r.1htm &lt;- system.file("extdata", "broeder.1htm.restr", package = "MPTinR")

br.2htm.fia &lt;- fit.mpt(d.broeder, m.2htm, fia = 50000, fit.aggregated = FALSE)
br.2htm.res.fia &lt;- fit.mpt(d.broeder, m.2htm, r.2htm, fia = 50000, fit.aggregated = FALSE)
br.1htm.fia &lt;- fit.mpt(d.broeder, m.2htm, r.1htm, fia = 50000, fit.aggregated = FALSE)

select.mpt(list(br.2htm.fia, br.2htm.res.fia, br.1htm.fia))
# This table shows that the n (number of trials) is too small to correctly compute 
# FIA for the 1HT model (as the penalty for the 1HTM is larger than for the 2HTM, 
# although the former is nested in the latter).
# This problem with FIA can only be overcome by collecting more trials per participant,
# but NOT by collecting more participants (as the penalties are simply summed).

# using the dataset argument we see the same
select.mpt(list(br.2htm.fia, br.2htm.res.fia, br.1htm.fia), dataset = 4, output = "full")

select.mpt(list(br.2htm.fia, br.2htm.res.fia, br.1htm.fia),	dataset = 1:10)

## End(Not run)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
