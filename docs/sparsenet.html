<!DOCTYPE html><html><head><title>Help for package sparsenet</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {sparsenet}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cv.sparsenet'><p>Cross-validation for sparsenet</p></a></li>
<li><a href='#gendata'>
<p>Generate data for testing sparse model selection</p></a></li>
<li><a href='#plot.cv.sparsenet'><p>plot the cross-validation curves produced by cv.sparsenet</p></a></li>
<li><a href='#plot.sparsenet'><p>plot coefficients from a &quot;sparsenet&quot; object</p></a></li>
<li><a href='#predict.cv.sparsenet'><p>make predictions from a &quot;cv.sparsenet&quot; object.</p></a></li>
<li><a href='#predict.sparsenet'><p>make predictions from a &quot;sparsenet&quot; object.</p></a></li>
<li><a href='#sparsenet'>
<p>Fit a linear model regularized by the nonconvex MC+ sparsity penalty</p></a></li>
<li><a href='#sparsenet-internal'><p>Internal sparsenet functions</p></a></li>
<li><a href='#sparsenet-package'>
<p>Fit a linear model regularized by the nonconvex MC+ sparsity penalty</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Fit Sparse Linear Regression Models via Nonconvex Optimization</td>
</tr>
<tr>
<td>Version:</td>
<td>1.6</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-05</td>
</tr>
<tr>
<td>Author:</td>
<td>Rahul Mazumder [aut, cre],
	Trevor Hastie [aut, cre],
	Jerome Friedman [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Trevor Hastie &lt;hastie@stanford.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Efficient procedure for fitting regularization paths between L1 and L0, using the MC+ penalty of Zhang, C.H. (2010)&lt;<a href="https://doi.org/10.1214%2F09-AOS729">doi:10.1214/09-AOS729</a>&gt;. Implements the methodology described in Mazumder, Friedman and Hastie (2011) &lt;<a href="https://doi.org/10.1198%2Fjasa.2011.tm09738">doi:10.1198/jasa.2011.tm09738</a>&gt;. Sparsenet computes the regularization surface over both the family parameter and the tuning parameter by coordinate descent.</td>
</tr>
<tr>
<td>Depends:</td>
<td>Matrix (&ge; 1.0-6), shape</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://hastie.su.domains/public/Papers/Sparsenet/Mazumder-SparseNetCoordinateDescent-2011.pdf">https://hastie.su.domains/public/Papers/Sparsenet/Mazumder-SparseNetCoordinateDescent-2011.pdf</a></td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-05 20:12:57 UTC; hastie</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-05 21:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='cv.sparsenet'>Cross-validation for sparsenet</h2><span id='topic+cv.sparsenet'></span>

<h3>Description</h3>

<p>Does k-fold cross-validation for sparsenet, produces a plot,
and returns values for <code>gamma, lambda</code></p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.sparsenet(x, y, weights, type.measure = c("mse", "mae"), ...,nfolds = 10,
       foldid, keep=FALSE, trace.it=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.sparsenet_+3A_x">x</code></td>
<td>
<p><code>x</code> matrix as in <code>sparsenet</code>.</p>
</td></tr>
<tr><td><code id="cv.sparsenet_+3A_y">y</code></td>
<td>
<p>response <code>y</code> as in <code>sparsenet</code>.</p>
</td></tr>
<tr><td><code id="cv.sparsenet_+3A_weights">weights</code></td>
<td>
<p>Observation weights; defaults to 1 per observation</p>
</td></tr>
<tr><td><code id="cv.sparsenet_+3A_type.measure">type.measure</code></td>
<td>
<p>loss to use for cross-validation. Currently two
options:
squared-error (<code>type.measure="mse"</code>) or
mean-absolute error ( <code>type.measure="mae"</code> )
</p>
</td></tr> 
<tr><td><code id="cv.sparsenet_+3A_...">...</code></td>
<td>
<p>Other arguments that can be passed to <code>sparsenet</code>.</p>
</td></tr>
<tr><td><code id="cv.sparsenet_+3A_nfolds">nfolds</code></td>
<td>
<p>number of folds - default is 10. Although <code>nfolds</code>
can be as large as the sample size (leave-one-out CV), it is not
recommended for large datasets. Smallest value allowable is <code>nfolds=3</code></p>
</td></tr>
<tr><td><code id="cv.sparsenet_+3A_foldid">foldid</code></td>
<td>
<p>an optional vector of values between 1 and <code>nfold</code>
identifying whhat fold each observation is in. If supplied,
<code>nfold</code> can be missing.</p>
</td></tr>
<tr><td><code id="cv.sparsenet_+3A_keep">keep</code></td>
<td>
<p>If <code>TRUE</code>, we include the prevalidation array as
component <code>fit.preval</code> on the returned object. Default is
<code>keep = FALSE</code>.</p>
</td></tr>
<tr><td><code id="cv.sparsenet_+3A_trace.it">trace.it</code></td>
<td>
<p>If <code>TRUE</code>, then we get a printout that shows the
progress</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function runs <code>sparsenet</code> <code>nfolds</code>+1 times; the
first to get the <code>lambda</code> sequence, and then the remainder to
compute the fit with each of the folds omitted. The error is
accumulated, and the average error and standard deviation over the
folds is computed. 
</p>


<h3>Value</h3>

<p>an object of class <code>"cv.sparsenet"</code> is returned, which is a
list with the ingredients of the cross-validation fit.
</p>
<table>
<tr><td><code>lambda</code></td>
<td>
<p>the values of <code>lambda</code> used in the fits. This is an
<code>nlambda x ngamma</code> matrix</p>
</td></tr>
<tr><td><code>cvm</code></td>
<td>
<p>The mean cross-validated error - a matrix shaped like lambda</p>
</td></tr>
<tr><td><code>cvsd</code></td>
<td>
<p>estimate of standard error of <code>cvm</code>.</p>
</td></tr>
<tr><td><code>cvup</code></td>
<td>
<p>upper curve = <code>cvm+cvsd</code>.</p>
</td></tr>
<tr><td><code>cvlo</code></td>
<td>
<p>lower curve = <code>cvm-cvsd</code>.</p>
</td></tr>
<tr><td><code>nzero</code></td>
<td>
<p>number of non-zero coefficients at each <code>lambda,
      gamma</code> pair.</p>
</td></tr>
<tr><td><code>name</code></td>
<td>
<p>a text string indicating type of measure (for plotting
purposes).</p>
</td></tr>
<tr><td><code>sparsenet.fit</code></td>
<td>
<p>a fitted sparsenet object for the full data.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The call that produced this object</p>
</td></tr>
<tr><td><code>parms.min</code></td>
<td>
<p>values of <code>gamma, lambda</code> that gives minimum
<code>cvm</code>.</p>
</td></tr>
<tr><td><code>which.min</code></td>
<td>
<p>indices for the above</p>
</td></tr>
<tr><td><code>lambda.1se</code></td>
<td>
<p><code>gamma, lambda</code> of smallest model (df) such that error is
within 1 standard error of the minimum.</p>
</td></tr>
<tr><td><code>which.1se</code></td>
<td>
<p>indices of the above</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rahul Mazumder, Jerome Friedman and Trevor Hastie
</p>
<p>Maintainer: Trevor Hastie &lt;hastie@stanford.edu&gt;
</p>


<h3>References</h3>

<p>Mazumder, Rahul, Friedman, Jerome and Hastie, Trevor (2011)
<em>SparseNet: Coordinate Descent with Nonconvex Penalties. JASA, Vol 106(495), 1125-38</em>,
<a href="https://hastie.su.domains/public/Papers/Sparsenet/Mazumder-SparseNetCoordinateDescent-2011.pdf">https://hastie.su.domains/public/Papers/Sparsenet/Mazumder-SparseNetCoordinateDescent-2011.pdf</a>
</p>


<h3>See Also</h3>

<p><code>glmnet</code> package,  <code>predict</code>, <code>coef</code>, <code>print</code> and <code>plot</code> methods, and the <code>sparsenet</code> function.</p>


<h3>Examples</h3>

<pre><code class='language-R'>train.data=gendata(100,1000,nonzero=30,rho=0.3,snr=3)
fit=sparsenet(train.data$x,train.data$y)
par(mfrow=c(3,3))
plot(fit)
par(mfrow=c(1,1))
fitcv=cv.sparsenet(train.data$x,train.data$y,trace.it=TRUE)
plot(fitcv)
</code></pre>

<hr>
<h2 id='gendata'>
Generate data for testing sparse model selection
</h2><span id='topic+gendata'></span>

<h3>Description</h3>

<p>This function generates x/y data for testing sparsenet and glmnet
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gendata(N, p, nonzero, rho, snr = 3, alternate = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gendata_+3A_n">N</code></td>
<td>

<p>Sample size (eg 500)
</p>
</td></tr>
<tr><td><code id="gendata_+3A_p">p</code></td>
<td>

<p>Number of features or variables (eg 1000)
</p>
</td></tr>
<tr><td><code id="gendata_+3A_nonzero">nonzero</code></td>
<td>

<p>Number if nonzero coefficients (eg 30)
</p>
</td></tr>
<tr><td><code id="gendata_+3A_rho">rho</code></td>
<td>

<p>pairwise correlation between features
</p>
</td></tr>
<tr><td><code id="gendata_+3A_snr">snr</code></td>
<td>

<p>Signal to noise ratio - SD signal/ SD noise - try 3
</p>
</td></tr>
<tr><td><code id="gendata_+3A_alternate">alternate</code></td>
<td>

<p>Alternate sign of coefficients
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generates Gaussian x and y data. The nonzero coefficients decrease
linearly in absolute value from nonzero down to 0. If
<code>alternate=TRUE</code> their signs alternate, else not
</p>


<h3>Value</h3>

<p>A list with components x and y as well some other details about the dataset
</p>


<h3>Author(s)</h3>

<p>Trevor Hastie and Jerome Friedman
</p>


<h3>Examples</h3>

<pre><code class='language-R'>train.data=gendata(100,1000,nonzero=30,rho=0.3,snr=3)
fit=sparsenet(train.data$x,train.data$y)
par(mfrow=c(3,3))
plot(fit)
par(mfrow=c(1,1))
fitcv=cv.sparsenet(train.data$x,train.data$y,trace.it=TRUE)
plot(fitcv)
</code></pre>

<hr>
<h2 id='plot.cv.sparsenet'>plot the cross-validation curves produced by cv.sparsenet</h2><span id='topic+plot.cv.sparsenet'></span>

<h3>Description</h3>

<p>Plots the cross-validation curves for each value of <code>gamma</code> in one figure, as a function of the <code>lambda</code> values used.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.sparsenet'
plot(x,  ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cv.sparsenet_+3A_x">x</code></td>
<td>
<p>fitted <code>"cv.sparsenet"</code> object</p>
</td></tr>
<tr><td><code id="plot.cv.sparsenet_+3A_...">...</code></td>
<td>
<p>Other graphical parameters to plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A plot is produced, and nothing is returned.</p>


<h3>Author(s)</h3>

<p>Rahul Mazumder, Jerome Friedman and Trevor Hastie
</p>
<p>Maintainer: Trevor Hastie &lt;hastie@stanford.edu&gt;
</p>


<h3>References</h3>

<p>Mazumder, Rahul, Friedman, Jerome and Hastie, Trevor (2011)
<em>SparseNet: Coordinate Descent with Nonconvex Penalties. JASA, Vol 106(495), 1125-38</em>,
<a href="https://hastie.su.domains/public/Papers/Sparsenet/Mazumder-SparseNetCoordinateDescent-2011.pdf">https://hastie.su.domains/public/Papers/Sparsenet/Mazumder-SparseNetCoordinateDescent-2011.pdf</a>
</p>


<h3>See Also</h3>

<p><code>glmnet</code> package, <code>sparsenet</code>,  <code>cv.sparsenet</code>  and
<code>print</code> and <code>plot</code> methods for both.</p>


<h3>Examples</h3>

<pre><code class='language-R'>x=matrix(rnorm(100*20),100,20)
y=rnorm(100)
fitcv=cv.sparsenet(x,y)
plot(fitcv)
</code></pre>

<hr>
<h2 id='plot.sparsenet'>plot coefficients from a &quot;sparsenet&quot; object</h2><span id='topic+plot.sparsenet'></span>

<h3>Description</h3>

<p>Produces a series of coefficient profile plots of the coefficient paths for a
fitted <code>"sparsenet"</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sparsenet'
plot(x, xvar = c("rsq","lambda","norm"), which.gamma=NULL, label = FALSE,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.sparsenet_+3A_x">x</code></td>
<td>
<p>fitted <code>"sparsenet"</code> model</p>
</td></tr>
<tr><td><code id="plot.sparsenet_+3A_xvar">xvar</code></td>
<td>
<p>What is on the X-axis. <code>"rsq"</code> plots against the
percent variance explained on the training data,  <code>"lambda"</code> against the log-lambda
sequence, and <code>"norm"</code> plots against the
L1-norm of the coefficients</p>
</td></tr>
<tr><td><code id="plot.sparsenet_+3A_which.gamma">which.gamma</code></td>
<td>
<p>sequence numbers of <code>gamma</code> values to be used
in the plots; default is all used in the fit</p>
</td></tr>
<tr><td><code id="plot.sparsenet_+3A_label">label</code></td>
<td>
<p>If <code>TRUE</code>, label the curves with variable sequence numbers.</p>
</td></tr>
<tr><td><code id="plot.sparsenet_+3A_...">...</code></td>
<td>
<p>Other graphical parameters to plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A series of coefficient profile plots is produced, one for each
<code>gamma</code> specified. Users should set up the appropriate layout.
</p>


<h3>Author(s)</h3>

<p>Rahul Mazumder, Jerome Friedman and Trevor Hastie
</p>
<p>Maintainer: Trevor Hastie &lt;hastie@stanford.edu&gt;
</p>


<h3>References</h3>

<p>Mazumder, Rahul, Friedman, Jerome and Hastie, Trevor (2011)
<em>SparseNet: Coordinate Descent with Nonconvex Penalties. JASA, Vol 106(495), 1125-38</em>,
<a href="https://hastie.su.domains/public/Papers/Sparsenet/Mazumder-SparseNetCoordinateDescent-2011.pdf">https://hastie.su.domains/public/Papers/Sparsenet/Mazumder-SparseNetCoordinateDescent-2011.pdf</a>
</p>


<h3>See Also</h3>

<p><code>glmnet</code> package, <code>sparsenet</code>,  <code>cv.sparsenet</code>  and
<code>print</code> and <code>plot</code> methods for both.</p>


<h3>Examples</h3>

<pre><code class='language-R'>x=matrix(rnorm(100*20),100,20)
y=rnorm(100)
fit=sparsenet(x,y)
par(mfrow=c(3,3))
plot(fit)
</code></pre>

<hr>
<h2 id='predict.cv.sparsenet'>make predictions from a &quot;cv.sparsenet&quot; object.</h2><span id='topic+coef.cv.sparsenet'></span><span id='topic+predict.cv.sparsenet'></span>

<h3>Description</h3>

<p>This function makes predictions from a cross-validated sparsenet model,
using the stored <code>"sparsenet.fit"</code> object, and the optimal value
chosen for <code>lambda</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.sparsenet'
predict(object, newx, which=c("parms.min","parms.1se"),...)
## S3 method for class 'cv.sparsenet'
coef(object, which=c("parms.min","parms.1se"),...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.cv.sparsenet_+3A_object">object</code></td>
<td>
<p>Fitted <code>"cv.sparsenet"</code>  object.</p>
</td></tr>
<tr><td><code id="predict.cv.sparsenet_+3A_newx">newx</code></td>
<td>
<p>Matrix of new values for <code>x</code> at which predictions are
to be made. Must be a matrix. See documentation for <code>predict.sparsenet</code>.</p>
</td></tr>
<tr><td><code id="predict.cv.sparsenet_+3A_which">which</code></td>
<td>
<p>Either the paramaters of the minimum of the CV curves
(default <code>"parms.min"</code> or the parameters corresponding to the
one standard-error rule <code>parms.1se</code>)</p>
</td></tr>
<tr><td><code id="predict.cv.sparsenet_+3A_...">...</code></td>
<td>
<p>Not used. Other arguments to predict. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function makes it easier to use the results of
cross-validation to make a prediction.</p>


<h3>Value</h3>

<p>The object returned depends the ... argument which is passed on
to the <code>predict</code> method for <code>sparsenet</code> objects.</p>


<h3>Author(s)</h3>

<p>Rahul Mazumder, Jerome Friedman and Trevor Hastie
</p>
<p>Maintainer: Trevor Hastie &lt;hastie@stanford.edu&gt;
</p>


<h3>References</h3>

<p>Mazumder, Rahul, Friedman, Jerome and Hastie, Trevor (2011)
<em>SparseNet: Coordinate Descent with Nonconvex Penalties. JASA, Vol 106(495), 1125-38</em>,
<a href="https://hastie.su.domains/public/Papers/Sparsenet/Mazumder-SparseNetCoordinateDescent-2011.pdf">https://hastie.su.domains/public/Papers/Sparsenet/Mazumder-SparseNetCoordinateDescent-2011.pdf</a>
</p>


<h3>See Also</h3>

<p><code>glmnet</code> package, <code>sparsenet</code>,  <code>cv.sparsenet</code>  and
<code>print</code> and <code>plot</code> methods for both.</p>


<h3>Examples</h3>

<pre><code class='language-R'>x=matrix(rnorm(100*20),100,20)
y=rnorm(100)
fitcv=cv.sparsenet(x,y)
predict(fitcv,x)
</code></pre>

<hr>
<h2 id='predict.sparsenet'>make predictions from a &quot;sparsenet&quot; object.</h2><span id='topic+coef.sparsenet'></span><span id='topic+predict.sparsenet'></span>

<h3>Description</h3>

<p>Similar to other predict methods, this functions predicts fitted values,
coefficients and more from a fitted <code>"sparsenet"</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sparsenet'
predict(object, newx, s = NULL,  which.gamma = NULL,
type=c("response","coefficients","nonzero"), exact = FALSE, ...)
## S3 method for class 'sparsenet'
coef(object,s=NULL, which.gamma = NULL,exact=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.sparsenet_+3A_object">object</code></td>
<td>
<p>Fitted <code>"sparsenet"</code> model object.</p>
</td></tr>
<tr><td><code id="predict.sparsenet_+3A_newx">newx</code></td>
<td>
<p>Matrix of new values for <code>x</code> at which predictions are
to be made. Must be a matrix. This argument is not used for <code>type=c("coefficients","nonzero")</code></p>
</td></tr>
<tr><td><code id="predict.sparsenet_+3A_s">s</code></td>
<td>
<p>Value(s) of the penalty parameter <code>lambda</code> at which
predictions are required. Default is the entire sequence used to
create the model. </p>
</td></tr>
<tr><td><code id="predict.sparsenet_+3A_which.gamma">which.gamma</code></td>
<td>
<p>Index or indices of <code>gamma</code> values at which
predictions are to be made. Default is all those used in the fit</p>
</td></tr>
<tr><td><code id="predict.sparsenet_+3A_type">type</code></td>
<td>
<p><code>"response"</code> returns fitted predictions at
<code>newx</code>.  Type
<code>"coefficients"</code> computes the coefficients at the requested
values for <code>s</code>.   Type  <code>"nonzero"</code> returns lists of the indices of the nonzero
coefficients for each value of <code>s</code>.</p>
</td></tr>
<tr><td><code id="predict.sparsenet_+3A_exact">exact</code></td>
<td>
<p>By default (<code>exact=FALSE</code>) the predict function uses linear interpolation
to make predictions for values of <code>s</code> that do not coincide with
those used in the fitting algorithm. Currently <code>exact=TRUE</code> is
not implemented, but prints an error message telling the user how to
achieve the exact predictions. This is done my rerunning the algorithm
with the desired values interspersed (in order) with the values used in
the original fit</p>
</td></tr>
<tr><td><code id="predict.sparsenet_+3A_...">...</code></td>
<td>
<p>Not used. Other arguments to predict. </p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The shape of the objects returned depends on which
<code>which.gamma</code> has more than one element.
If more than one element, a list of predictions is returned, one for
each gamma.
</p>


<h3>Value</h3>

<p>The object returned depends on type.</p>


<h3>Author(s)</h3>

<p>Rahul Mazumder, Jerome Friedman and Trevor Hastie
</p>
<p>Maintainer: Trevor Hastie &lt;hastie@stanford.edu&gt;
</p>


<h3>References</h3>

<p>Mazumder, Rahul, Friedman, Jerome and Hastie, Trevor (2011)
<em>SparseNet: Coordinate Descent with Nonconvex Penalties. JASA, Vol 106(495), 1125-38</em>,
<a href="https://hastie.su.domains/public/Papers/Sparsenet/Mazumder-SparseNetCoordinateDescent-2011.pdf">https://hastie.su.domains/public/Papers/Sparsenet/Mazumder-SparseNetCoordinateDescent-2011.pdf</a>
</p>


<h3>See Also</h3>

<p><code>glmnet</code> package, <code>sparsenet</code>,  <code>cv.sparsenet</code>  and
<code>print</code> and <code>plot</code> methods for both.</p>


<h3>Examples</h3>

<pre><code class='language-R'>x=matrix(rnorm(100*20),100,20)
y=rnorm(100)
fit=sparsenet(x,y)
predict(fit, which.gamma=5,type="nonzero")
predict(fit,x)
</code></pre>

<hr>
<h2 id='sparsenet'>
Fit a linear model regularized by the nonconvex MC+ sparsity penalty
</h2><span id='topic+sparsenet'></span>

<h3>Description</h3>

<p>Sparsenet uses coordinate descent on the MC+ nonconvex penalty family,
and fits a surface of solutions over the two-dimensional parameter
space. This penalty family is indexed by an overall strength paramter lambda
(like lasso), and a convexity parameter gamma. Gamma = infinity
corresponds to the lasso, and gamma = 1 best subset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sparsenet(x, y, weights, exclude, dfmax = nvars + 1, pmax = min(dfmax *2, nvars),
ngamma = 9, nlambda = 50, max.gamma = 150, min.gamma = 1.000001,
lambda.min.ratio = ifelse(nobs &lt; nvars, 0.01, 1e-04), lambda = NULL,
gamma = NULL, parms = NULL, warm = c("lambda", "gamma", "both"),
thresh = 1e-05, maxit = 1e+06)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sparsenet_+3A_x">x</code></td>
<td>
<p>Input matrix of nobs x nvars predictors
</p>
</td></tr>
<tr><td><code id="sparsenet_+3A_y">y</code></td>
<td>
<p>response vector
</p>
</td></tr>
<tr><td><code id="sparsenet_+3A_weights">weights</code></td>
<td>
<p>Observation weights; default 1 for each observation
</p>
</td></tr>
<tr><td><code id="sparsenet_+3A_exclude">exclude</code></td>
<td>
<p>Indices of variables to be excluded from the
model. Default is none.
</p>
</td></tr>
<tr><td><code id="sparsenet_+3A_dfmax">dfmax</code></td>
<td>
<p>Limit the maximum number of variables in the
model. Useful for very large <code>nvars</code>, if a partial path is desired.</p>
</td></tr>
<tr><td><code id="sparsenet_+3A_pmax">pmax</code></td>
<td>
<p>Limit the maximum number of variables ever to be nonzero</p>
</td></tr>
<tr><td><code id="sparsenet_+3A_ngamma">ngamma</code></td>
<td>

<p>Number of gamma values, if <code>gamma</code> not supplied; default is 9.
</p>
</td></tr>
<tr><td><code id="sparsenet_+3A_nlambda">nlambda</code></td>
<td>
<p> Number of lambda values, if <code>lambda</code> not
supplied; default is 50
</p>
</td></tr>
<tr><td><code id="sparsenet_+3A_max.gamma">max.gamma</code></td>
<td>
<p>Largest gamma value to be used, apart from infinity
(lasso), if <code>gamma</code> not supplied; default is 150
</p>
</td></tr>
<tr><td><code id="sparsenet_+3A_min.gamma">min.gamma</code></td>
<td>
<p>Smallest value of gamma to use, and should be &gt;1;
default is 1.000001
</p>
</td></tr>
<tr><td><code id="sparsenet_+3A_lambda.min.ratio">lambda.min.ratio</code></td>
<td>
<p>Smallest value for <code>lambda</code>, as a fraction of
<code>lambda.max</code>, the (data derived) entry value (i.e. the smallest
value for which all coefficients are zero). The default depends on the
sample size <code>nobs</code> relative to the number of variables
<code>nvars</code>. If <code>nobs &gt; nvars</code>, the default is <code>0.0001</code>,
close to zero.  If <code>nobs &lt; nvars</code>, the default is <code>0.01</code>.
A very small value of
<code>lambda.min.ratio</code> will lead to a saturated fit in the <code>nobs &lt;
    nvars</code> case.
</p>
</td></tr>
<tr><td><code id="sparsenet_+3A_lambda">lambda</code></td>
<td>
<p>A user supplied <code>lambda</code> sequence, in decreasing order. Typical usage
is to have the 
program compute its own <code>lambda</code> sequence based on
<code>nlambda</code> and <code>lambda.min.ratio</code>. Supplying a value of
<code>lambda</code> overrides this. WARNING: use with care. Do not supply
a single value for <code>lambda</code> (for predictions after CV use <code>predict()</code>
instead).  Supply instead
a decreasing sequence of <code>lambda</code> values. <code>sparsenet</code> relies
on its warms starts for speed, and its often faster to fit a whole
path than compute a single fit.</p>
</td></tr>
<tr><td><code id="sparsenet_+3A_gamma">gamma</code></td>
<td>

<p>Sparsity parameter vector, with 1&lt;gamma&lt;infty. Gamma=1 corresponds to
best-subset regression, gamma=infty to the lasso. Should be given in
decreasing order.
</p>
</td></tr>
<tr><td><code id="sparsenet_+3A_parms">parms</code></td>
<td>

<p>An optional three-dimensional array: 2x ngamma x nlambda.
Here the user can supply exactly the gamma, lambda pairs that are to
be traversed by the coordinate descent algorithm. 
</p>
</td></tr>
<tr><td><code id="sparsenet_+3A_warm">warm</code></td>
<td>

<p>How to traverse the grid. Default is &quot;lambda&quot;, meaning warm starts from
the previous lambda with the same gamma. &quot;gamma&quot; means the opposite,
previous gamma for the same lambda. &quot;both&quot; tries both warm starts, and
uses the one that improves the criterion the most. 
</p>
</td></tr>
<tr><td><code id="sparsenet_+3A_thresh">thresh</code></td>
<td>
<p>Convergence threshold for coordinate descent. Each
coordinate-descent loop continues until the maximum change in the
objective after any coefficient update is less than <code>thresh</code>
times the null Rss. Defaults value is <code>1E-5</code>.</p>
</td></tr>
<tr><td><code id="sparsenet_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of passes over the data for all lambda/gamma
values; default is 10^6.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This algorithm operates like <code>glmnet</code>, with its alpha parameter
which moves the penalty between lasso and ridge; here gamma moves it
between lasso and best subset.
The algorithm traverses the two dimensional gamma/lambda array in a nested loop, with
decreasing gamma in the outer loop, and decreasing lambda in the inner
loop. Because of the nature of the MC+ penalty, each coordinate update
is a convex problem, with a simple two-threshold shrinking scheme:
beta&lt; lambda set to zero; beta &gt; lambda*gamma leave alone; beta
inbetween, shrink proportionally. Note that this algorithm ALWAYS
standardizes the columns of x and y to have mean zero and variance 1
(using the 1/N averaging) before it computes its fit. The
coefficients reflect the original scale.
</p>


<h3>Value</h3>

<p>An object of class <code>"sparsenet"</code>, with a number of
components. Mostly one will access the components via generic
functions
like <code>coef()</code>, <code>plot()</code>, <code>predict()</code> etc.
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>the call that produced this object</p>
</td></tr>
<tr><td><code>rsq</code></td>
<td>
<p>The percentage variance explained on the training data;
an ngamma x nlambda matrix.</p>
</td></tr>
<tr><td><code>jerr</code></td>
<td>
<p>error flag, for warnings and errors (largely for internal debugging).</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>A coefficient list with ngamma elements; each of
these is a coefficient list with various components: the matrix beta
of coefficients, its dimension dim, the vector of intercepts, the lambda sequence, the gamma value,  the sequence
of df (nonzero coefficients) for each solution.</p>
</td></tr>
<tr><td><code>parms</code></td>
<td>
<p>Irrespective how the parameters were input, the three-way
array of what was used.</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>
<p>The gamma values used</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The lambda values used</p>
</td></tr>
<tr><td><code>max.lambda</code></td>
<td>
<p>The entry value for lambda</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rahul Mazumder, Jerome Friedman and Trevor Hastie
</p>
<p>Maintainer: Trevor Hastie &lt;hastie@stanford.edu&gt;
</p>


<h3>References</h3>

<p>Mazumder, Rahul, Friedman, Jerome and Hastie, Trevor (2011)
<em>SparseNet: Coordinate Descent with Nonconvex Penalties. JASA, Vol 106(495), 1125-38</em>,
<a href="https://hastie.su.domains/public/Papers/Sparsenet/Mazumder-SparseNetCoordinateDescent-2011.pdf">https://hastie.su.domains/public/Papers/Sparsenet/Mazumder-SparseNetCoordinateDescent-2011.pdf</a>
</p>


<h3>See Also</h3>

<p><code>glmnet</code> package,  <code>predict</code>, <code>coef</code>, <code>print</code> and <code>plot</code> methods, and the <code>cv.sparsenet</code> function.</p>


<h3>Examples</h3>

<pre><code class='language-R'>train.data=gendata(100,1000,nonzero=30,rho=0.3,snr=3)
fit=sparsenet(train.data$x,train.data$y)
par(mfrow=c(3,3))
plot(fit)
par(mfrow=c(1,1))
fitcv=cv.sparsenet(train.data$x,train.data$y,trace.it=TRUE)
plot(fitcv)
</code></pre>

<hr>
<h2 id='sparsenet-internal'>Internal sparsenet functions</h2><span id='topic+argmin'></span><span id='topic+getcoef_list'></span><span id='topic+lambda0'></span><span id='topic+sparsepredict'></span><span id='topic+zeromat'></span><span id='topic+summary.sparsenet'></span><span id='topic+print.cv.sparsenet'></span><span id='topic+print.sparsenet'></span><span id='topic+nonzeroCoef'></span><span id='topic+plotCoef'></span><span id='topic+lambda.interp'></span>

<h3>Description</h3>

<p>Internal sparsenet functions</p>


<h3>Details</h3>

<p>These are not intended for use by users. <code>argmin</code>
identifies the lambda, gamma pair that minimizes cv
error. <code>lambda0</code> should go away; it currently evaluates the
entry value for lambda.
</p>


<h3>Author(s)</h3>

<p>Trevor Hastie</p>

<hr>
<h2 id='sparsenet-package'>
Fit a linear model regularized by the nonconvex MC+ sparsity penalty
</h2><span id='topic+sparsenet-package'></span>

<h3>Description</h3>

<p>Sparsenet uses coordinate descent on the MC+ nonconvex penalty family,
and fits a surface of solutions over the two-dimensional parameter space.
</p>


<h3>Details</h3>

<p>At its simplest, provide <code>x,y</code> data and it returns the solution
paths. There are tools for prediction, cross-validation, plotting and printing.
</p>


<h3>Author(s)</h3>

     
<p>Rahul Mazumder, Jerome Friedman and Trevor Hastie
</p>
<p>Maintainer: Trevor Hastie &lt;hastie@stanford.edu&gt;
</p>


<h3>References</h3>

<p>Mazumder, Rahul, Friedman, Jerome and Hastie, Trevor (2011)
<em>SparseNet: Coordinate Descent with Nonconvex Penalties. JASA, Vol 106(495), 1125-38</em>,
<a href="https://hastie.su.domains/public/Papers/Sparsenet/Mazumder-SparseNetCoordinateDescent-2011.pdf">https://hastie.su.domains/public/Papers/Sparsenet/Mazumder-SparseNetCoordinateDescent-2011.pdf</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x=matrix(rnorm(100*20),100,20)
y=rnorm(100)
fit=sparsenet(x,y)
plot(fit)
cvfit=cv.sparsenet(x,y)
plot(cvfit)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
