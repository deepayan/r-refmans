<!DOCTYPE html><html><head><title>Help for package PerformanceAnalytics</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {PerformanceAnalytics}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#PerformanceAnalytics-package'>
<p>Econometric tools for performance and risk analysis.</p></a></li>
<li><a href='#ActiveReturn'><p>Active Premium or Active Return</p></a></li>
<li><a href='#AdjustedSharpeRatio'><p>Adjusted Sharpe ratio of the return distribution</p></a></li>
<li><a href='#apply.fromstart'><p>calculate a function over an expanding window always starting from the</p>
beginning of the series</a></li>
<li><a href='#apply.rolling'><p>calculate a function over a rolling window</p></a></li>
<li><a href='#AppraisalRatio'><p>Appraisal ratio of the return distribution</p></a></li>
<li><a href='#AverageDrawdown'><p>Calculates the average depth of the observed drawdowns.</p></a></li>
<li><a href='#AverageLength'><p>Calculates the average length (in periods) of the observed drawdowns.</p></a></li>
<li><a href='#AverageRecovery'><p>Calculates the average length (in periods) of the observed recovery period.</p></a></li>
<li><a href='#BernardoLedoitRatio'><p>Bernardo and Ledoit ratio of the return distribution</p></a></li>
<li><a href='#BetaCoMoments'><p>Functions to calculate systematic or beta co-moments of return series</p></a></li>
<li><a href='#BurkeRatio'><p>Burke ratio of the return distribution</p></a></li>
<li><a href='#CalmarRatio'><p>calculate a Calmar or Sterling reward/risk ratio</p>
</p>
<p>Calmar and Sterling Ratios are yet another method of creating a</p>
risk-adjusted measure for ranking investments similar to the
<code>SharpeRatio</code>.</a></li>
<li><a href='#CAPM.alpha'><p>calculate single factor model (CAPM) alpha</p></a></li>
<li><a href='#CAPM.beta'><p>calculate single factor model (CAPM) beta</p></a></li>
<li><a href='#CAPM.CML.slope'><p>utility functions for single factor (CAPM) CML, SML, and RiskPremium</p></a></li>
<li><a href='#CAPM.dynamic'><p>Time-varying conditional single factor model beta</p></a></li>
<li><a href='#CAPM.epsilon'><p>Regression epsilon of the return distribution</p></a></li>
<li><a href='#CAPM.jensenAlpha'><p>Jensen's alpha of the return distribution</p></a></li>
<li><a href='#CDD'><p>Calculate Uryasev's proposed Conditional Drawdown at Risk (CDD or CDaR)</p>
measure</a></li>
<li><a href='#chart.ACF'><p>Create ACF chart or ACF with PACF two-panel chart</p></a></li>
<li><a href='#chart.Bar'><p>wrapper for barchart of returns</p></a></li>
<li><a href='#chart.BarVaR'><p>Periodic returns in a bar chart with risk metric overlay</p></a></li>
<li><a href='#chart.Boxplot'><p>box whiskers plot wrapper</p></a></li>
<li><a href='#chart.CaptureRatios'><p>Chart of Capture Ratios against a benchmark</p></a></li>
<li><a href='#chart.Correlation'><p>correlation matrix chart</p></a></li>
<li><a href='#chart.CumReturns'><p>Cumulates and graphs a set of periodic returns</p></a></li>
<li><a href='#chart.Drawdown'><p>Time series chart of drawdowns through time</p></a></li>
<li><a href='#chart.ECDF'><p>Create an ECDF overlaid with a Normal CDF</p></a></li>
<li><a href='#chart.Events'><p>Plots a time series with event dates aligned</p></a></li>
<li><a href='#chart.Histogram'><p>histogram of returns</p></a></li>
<li><a href='#chart.QQPlot'><p>Plot a QQ chart</p></a></li>
<li><a href='#chart.Regression'><p>Takes a set of returns and relates them to a market benchmark in a</p>
scatterplot</a></li>
<li><a href='#chart.RelativePerformance'><p>relative performance chart between multiple return series</p></a></li>
<li><a href='#chart.RiskReturnScatter'><p>scatter chart of returns vs risk for comparing multiple instruments</p></a></li>
<li><a href='#chart.RollingCorrelation'><p>chart rolling correlation fo multiple assets</p></a></li>
<li><a href='#chart.RollingMean'><p>chart the rolling mean return</p></a></li>
<li><a href='#chart.RollingPerformance'><p>wrapper to create a chart of rolling performance metrics in a line chart</p></a></li>
<li><a href='#chart.RollingQuantileRegression'><p>A wrapper to create charts of relative regression performance through time</p></a></li>
<li><a href='#chart.Scatter'><p>wrapper to draw scatter plot with sensible defaults</p></a></li>
<li><a href='#chart.SnailTrail'><p>chart risk versus return over rolling time periods</p></a></li>
<li><a href='#chart.StackedBar'><p>create a stacked bar plot</p></a></li>
<li><a href='#chart.TimeSeries'><p>Creates a time series chart with some extensions.</p></a></li>
<li><a href='#chart.VaRSensitivity'><p>show the sensitivity of Value-at-Risk or Expected Shortfall estimates</p></a></li>
<li><a href='#charts.PerformanceSummary'><p>Create combined wealth index, period performance, and drawdown chart</p></a></li>
<li><a href='#charts.RollingPerformance'><p>rolling performance chart</p></a></li>
<li><a href='#checkData'><p>check input data type and format and coerce to the desired output type</p></a></li>
<li><a href='#checkSeedValue'><p>Check 'seedValue' to ensure it is compatible with coredata_content attribute of 'R' (an xts object)</p></a></li>
<li><a href='#clean.boudt'><p>clean extreme observations in a time series to to provide more robust risk</p>
estimates</a></li>
<li><a href='#CoMoments'><p>Functions for calculating comoments of financial time series</p></a></li>
<li><a href='#DownsideDeviation'><p>downside risk (deviation, variance) of the return distribution</p></a></li>
<li><a href='#DownsideFrequency'><p>downside frequency of the return distribution</p></a></li>
<li><a href='#DRatio'><p>d ratio of the return distribution</p></a></li>
<li><a href='#DrawdownDeviation'><p>Calculates a standard deviation-type statistic using individual drawdowns.</p></a></li>
<li><a href='#DrawdownPeak'><p>Drawdawn peak of the return distribution</p></a></li>
<li><a href='#Drawdowns'><p>Find the drawdowns and drawdown levels in a timeseries.</p></a></li>
<li><a href='#edhec'><p>EDHEC-Risk Hedge Fund Style Indices</p></a></li>
<li><a href='#ETL'><p>calculates Expected Shortfall(ES) (or Conditional Value-at-Risk(CVaR) for</p>
univariate and component, using a variety of analytical methods.</a></li>
<li><a href='#EWMAMoments'><p>Functions for calculating EWMA comoments of financial time series</p></a></li>
<li><a href='#FamaBeta'><p>Fama beta of the return distribution</p></a></li>
<li><a href='#Frequency'><p>Frequency of the return distribution</p></a></li>
<li><a href='#HurstIndex'><p>calculate the Hurst Index</p>
The Hurst index can be used to measure whether returns are mean reverting,
totally random, or persistent.</a></li>
<li><a href='#InformationRatio'><p>InformationRatio = ActivePremium/TrackingError</p></a></li>
<li><a href='#Kappa'><p>Kappa of the return distribution</p></a></li>
<li><a href='#KellyRatio'><p>calculate Kelly criterion ratio (leverage or bet size) for a strategy</p></a></li>
<li><a href='#kurtosis'><p>Kurtosis</p></a></li>
<li><a href='#legend'><p>internal functions for setting useful defaults for graphs</p></a></li>
<li><a href='#Level.calculate'><p>Calculate appropriate cumulative return series or asset level using xts attribute information</p></a></li>
<li><a href='#lpm'><p>calculate a lower partial moment for a time series</p></a></li>
<li><a href='#M2Sortino'><p>M squared for Sortino of the return distribution</p></a></li>
<li><a href='#managers'><p>Hypothetical Alternative Asset Manager and Benchmark Data</p></a></li>
<li><a href='#MarketTiming'><p>Market timing models</p></a></li>
<li><a href='#MartinRatio'><p>Martin ratio of the return distribution</p></a></li>
<li><a href='#maxDrawdown'><p>caclulate the maximum drawdown from peak equity</p></a></li>
<li><a href='#MCA'><p>Functions for doing Moment Component Analysis (MCA) of financial time series</p></a></li>
<li><a href='#mean.geometric'><p>calculate attributes relative to the mean of the observation series given,</p>
including geometric, stderr, LCL and UCL</a></li>
<li><a href='#MeanAbsoluteDeviation'><p>Mean absolute deviation of the return distribution</p></a></li>
<li><a href='#MinTrackRecord'><p>Minimum Track Record Length</p></a></li>
<li><a href='#Modigliani'><p>Modigliani-Modigliani measure</p></a></li>
<li><a href='#MSquared'><p>M squared of the return distribution</p></a></li>
<li><a href='#MSquaredExcess'><p>M squared excess of the return distribution</p></a></li>
<li><a href='#NetSelectivity'><p>Net selectivity of the return distribution</p></a></li>
<li><a href='#Omega'><p>calculate Omega for a return series</p></a></li>
<li><a href='#OmegaExcessReturn'><p>Omega excess return of the return distribution</p></a></li>
<li><a href='#OmegaSharpeRatio'><p>Omega-Sharpe ratio of the return distribution</p></a></li>
<li><a href='#PainIndex'><p>Pain index of the return distribution</p></a></li>
<li><a href='#PainRatio'><p>Pain ratio of the return distribution</p></a></li>
<li><a href='#portfolio_bacon'><p>Bacon(2008) Data</p></a></li>
<li><a href='#prices'><p>Selected Price Series Example Data</p></a></li>
<li><a href='#ProbSharpeRatio'><p>Probabilistic Sharpe Ratio</p></a></li>
<li><a href='#ProspectRatio'><p>Prospect ratio of the return distribution</p></a></li>
<li><a href='#RachevRatio'><p>Standard Error Estimate for Rachev Ratio of Returns</p></a></li>
<li><a href='#replaceTabs.inner'><p>Display text information in a graphics plot.</p></a></li>
<li><a href='#Return.annualized'><p>calculate an annualized return for comparing instruments with different</p>
length history</a></li>
<li><a href='#Return.annualized.excess'><p>calculates an annualized excess return for comparing instruments with different</p>
length history</a></li>
<li><a href='#Return.calculate'><p>calculate simple or compound returns from prices</p></a></li>
<li><a href='#Return.centered'><p>calculate centered Returns</p></a></li>
<li><a href='#Return.clean'><p>clean returns in a time series to to provide more robust risk estimates</p></a></li>
<li><a href='#Return.convert'><p>Convert coredata content from one type of return to another</p></a></li>
<li><a href='#Return.cumulative'><p>calculate a compounded (geometric) cumulative return</p></a></li>
<li><a href='#Return.excess'><p>Calculates the returns of an asset in excess of the given risk free rate</p></a></li>
<li><a href='#Return.Geltner'><p>calculate Geltner liquidity-adjusted return series</p></a></li>
<li><a href='#Return.locScaleRob'><p>Robust Filter for Time Series Returns</p></a></li>
<li><a href='#Return.portfolio'><p>Calculate weighted returns for a portfolio of assets</p></a></li>
<li><a href='#Return.read'><p>Read returns data with different date formats</p></a></li>
<li><a href='#Return.relative'><p>calculate the relative return of one asset to another</p></a></li>
<li><a href='#RPESE.control'><p>Controls Function for the Computation of Standard Errors for Risk and Performance estimators</p></a></li>
<li><a href='#Selectivity'><p>Selectivity of the return distribution</p></a></li>
<li><a href='#SharpeRatio'><p>calculate a traditional or modified Sharpe Ratio of Return over StdDev or</p>
VaR or ES</a></li>
<li><a href='#SharpeRatio.annualized'><p>calculate annualized Sharpe Ratio</p></a></li>
<li><a href='#ShrinkageMoments'><p>Functions for calculating shrinkage-based comoments of financial time series</p></a></li>
<li><a href='#skewness'><p>Skewness</p></a></li>
<li><a href='#SkewnessKurtosisRatio'><p>Skewness-Kurtosis ratio of the return distribution</p></a></li>
<li><a href='#SmoothingIndex'><p>calculate Normalized Getmansky Smoothing Index</p></a></li>
<li><a href='#sortDrawdowns'><p>order list of drawdowns from worst to best</p></a></li>
<li><a href='#SortinoRatio'><p>calculate Sortino Ratio of performance over downside risk</p></a></li>
<li><a href='#SpecificRisk'><p>Specific risk of the return distribution</p></a></li>
<li><a href='#StdDev'><p>calculates Standard Deviation for univariate and multivariate series, also</p>
calculates component contribution to standard deviation of a portfolio</a></li>
<li><a href='#StdDev.annualized'><p>calculate a multiperiod or annualized Standard Deviation</p></a></li>
<li><a href='#StructuredMoments'><p>Functions for calculating structured comoments of financial time series</p></a></li>
<li><a href='#SystematicRisk'><p>Systematic risk of the return distribution</p></a></li>
<li><a href='#table.AnnualizedReturns'><p>Annualized Returns Summary: Statistics and Stylized Facts</p></a></li>
<li><a href='#table.Arbitrary'><p>wrapper function for combining arbitrary function list into a table</p></a></li>
<li><a href='#table.Autocorrelation'><p>table for calculating the first six autocorrelation coefficients and</p>
significance</a></li>
<li><a href='#table.CalendarReturns'><p>Monthly and Calendar year Return table</p></a></li>
<li><a href='#table.CaptureRatios'><p>Calculate and display a table of capture ratio and related statistics</p></a></li>
<li><a href='#table.Correlation'><p>calculate correlalations of multicolumn data</p></a></li>
<li><a href='#table.Distributions'><p>Distributions Summary: Statistics and Stylized Facts</p></a></li>
<li><a href='#table.DownsideRisk'><p>Downside Risk Summary: Statistics and Stylized Facts</p></a></li>
<li><a href='#table.DownsideRiskRatio'><p>Downside Summary: Statistics and ratios</p></a></li>
<li><a href='#table.Drawdowns'><p>Worst Drawdowns Summary: Statistics and Stylized Facts</p></a></li>
<li><a href='#table.DrawdownsRatio'><p>Drawdowns Summary: Statistics and ratios</p></a></li>
<li><a href='#table.HigherMoments'><p>Higher Moments Summary: Statistics and Stylized Facts</p></a></li>
<li><a href='#table.InformationRatio'><p>Information ratio Summary: Statistics and Stylized Facts</p></a></li>
<li><a href='#table.ProbOutPerformance'><p>Outperformance Report of Asset vs Benchmark</p></a></li>
<li><a href='#table.RollingPeriods'><p>Rolling Periods Summary: Statistics and Stylized Facts</p></a></li>
<li><a href='#table.SFM'><p>Single Factor Asset-Pricing Model Summary: Statistics and Stylized Facts</p></a></li>
<li><a href='#table.SpecificRisk'><p>Specific risk Summary: Statistics and Stylized Facts</p></a></li>
<li><a href='#table.Stats'><p>Returns Summary: Statistics and Stylized Facts</p></a></li>
<li><a href='#table.Variability'><p>Variability Summary: Statistics and Stylized Facts</p></a></li>
<li><a href='#test_returns'><p>Sample sector returns for use by unit tests</p></a></li>
<li><a href='#test_weights'><p>Sample sector weights for use by unit tests</p></a></li>
<li><a href='#to.period.contributions'><p>Aggregate contributions through time</p></a></li>
<li><a href='#TotalRisk'><p>Total risk of the return distribution</p></a></li>
<li><a href='#TrackingError'><p>Calculate Tracking Error of returns against a benchmark</p></a></li>
<li><a href='#TreynorRatio'><p>calculate Treynor Ratio or modified Treynor Ratio of excess return over CAPM beta</p></a></li>
<li><a href='#UlcerIndex'><p>calculate the Ulcer Index</p></a></li>
<li><a href='#UpDownRatios'><p>calculate metrics on up and down markets for the benchmark asset</p></a></li>
<li><a href='#UpsideFrequency'><p>upside frequency of the return distribution</p></a></li>
<li><a href='#UpsidePotentialRatio'><p>calculate Upside Potential Ratio of upside performance over downside risk</p></a></li>
<li><a href='#UpsideRisk'><p>upside risk, variance and potential of the return distribution</p></a></li>
<li><a href='#VaR'><p>calculate various Value at Risk (VaR) measures</p></a></li>
<li><a href='#VolatilitySkewness'><p>Volatility and variability of the return distribution</p></a></li>
<li><a href='#weights'><p>Selected Portfolio Weights Data</p></a></li>
<li><a href='#zerofill'><p>zerofill</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Econometric Tools for Performance and Risk Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-02-05</td>
</tr>
<tr>
<td>Description:</td>
<td>Collection of econometric functions for performance and risk 
    analysis. In addition to standard risk and performance metrics, this 
    package aims to aid practitioners and researchers in utilizing the latest
    research in analysis of non-normal return streams.  In general, it is most 
    tested on return (rather than price) data on a regular scale, but most 
    functions will work with irregular return data as well, and increasing
    numbers of functions will work with P&amp;L or price data where possible.</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, quadprog, zoo</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), xts (&ge; 0.10.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>dygraphs, Hmisc, MASS, quantmod, gamlss, gamlss.dist,
robustbase, quantreg, tinytest, ggplot2, RColorBrewer,
googleVis, plotly, gridExtra, ggpubr, RPESE, R.rsp, RobStatTM</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>R.rsp</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/braverock/PerformanceAnalytics">https://github.com/braverock/PerformanceAnalytics</a></td>
</tr>
<tr>
<td>Copyright:</td>
<td>(c) 2004-2020</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.0.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-02-05 23:43:30.960783 UTC; brian</td>
</tr>
<tr>
<td>Author:</td>
<td>Brian G. Peterson [cre, aut, cph],
  Peter Carl [aut, cph],
  Kris Boudt [ctb, cph],
  Ross Bennett [ctb],
  Joshua Ulrich [ctb],
  Eric Zivot [ctb],
  Dries Cornilly [ctb],
  Eric Hung [ctb],
  Matthieu Lestel [ctb],
  Kyle Balkissoon [ctb],
  Diethelm Wuertz [ctb],
  Anthony Alexander Christidis [ctb],
  R. Douglas Martin [ctb],
  Zeheng 'Zenith' Zhou [ctb],
  Justin M. Shea [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Brian G. Peterson &lt;brian@braverock.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-02-06 12:10:11 UTC</td>
</tr>
</table>
<hr>
<h2 id='PerformanceAnalytics-package'>
Econometric tools for performance and risk analysis.
</h2><span id='topic+PerformanceAnalytics-package'></span><span id='topic+PerformanceAnalytics'></span>

<h3>Description</h3>

<p><kbd>PerformanceAnalytics</kbd> provides an <span class="rlang"><b>R</b></span> package of econometric functions for performance and risk analysis of financial instruments or portfolios. This package aims to aid practitioners and researchers in using the latest research for analysis of both normally and non-normally distributed return streams.
</p>
<p>We created this package to include functionality that has been appearing in the academic literature on performance analysis and risk over the past several years, but had no functional equivalent in <span class="rlang"><b>R</b></span>.  In doing so, we also found it valuable to have wrappers for some functionality with good defaults and naming consistent with common usage in the finance literature.  
</p>
<p>In general, this package requires return (rather than price) data. Almost all of the functions will work with any periodicity, from annual, monthly, daily, to even minutes and seconds, either regular or irregular.
</p>
<p>The following sections cover Time Series Data, Performance Analysis, Risk Analysis (with a separate treatment of VaR), Summary Tables of related statistics, Charts and Graphs, a variety of Wrappers and Utility functions, and some thoughts on work yet to be done.
</p>
<p>In this summary, we attempt to provide an overview of the capabilities provided by <kbd>PerformanceAnalytics</kbd> and pointers to other literature and resources in <span class="rlang"><b>R</b></span> useful for performance and risk analysis.  We hope that this summary and the accompanying package and documentation partially fill a hole in the tools available to a financial engineer or analyst.
</p>


<h3>Time Series Data</h3>

<p>Not all, but many of the measures in this package require time series data.  <kbd>PerformanceAnalytics</kbd> uses the <code><a href="xts.html#topic+xts">xts</a></code> package for managing time series data for several reasons.  Besides being fast and efficient, <code><a href="xts.html#topic+xts">xts</a></code> includes functions that test the data for periodicity and draw attractive and readable time-based axes on charts.  Another benefit is that <code><a href="xts.html#topic+xts">xts</a></code> provides compatability with Rmetrics' <code><a href="timeSeries.html#topic+timeSeries">timeSeries</a></code>, <code><a href="zoo.html#topic+zoo">zoo</a></code> and other time series classes, such that <kbd>PerformanceAnalytics</kbd> functions that return a time series will return the results in the same format as the object that was passed in.  Jeff Ryan and Josh Ulrich, the authors of <code><a href="xts.html#topic+xts">xts</a></code>, have been extraordinarily helpful to the development of <kbd>PerformanceAnalytics</kbd> and we are very greatful for their contributions to the community.  The <code><a href="xts.html#topic+xts">xts</a></code> package extends the excellent <code><a href="zoo.html#topic+zoo">zoo</a></code> package written by Achim Zeileis and Gabor Grothendieck. <code><a href="zoo.html#topic+zoo">zoo</a></code> provides more general time series support, whereas <code><a href="xts.html#topic+xts">xts</a></code> provides functionality that is specifically aimed at users in finance.
</p>
<p>Users can easily load returns data as time series for analysis with <kbd>PerformanceAnalytics</kbd> by using the <code><a href="#topic+Return.read">Return.read</a></code> function.  The <code><a href="#topic+Return.read">Return.read</a></code> function loads csv files of returns data where the data is organized as dates in the first column and the returns for the period in subsequent columns.  See <code><a href="zoo.html#topic+read.zoo">read.zoo</a></code> and <code><a href="xts.html#topic+as.xts">as.xts</a></code> if more flexibility is needed.  
</p>
<p>The functions described below assume that input data is organized with asset returns in columns and dates represented in rows.  All of the metrics in <kbd>PerformanceAnalytics</kbd> are calculated by column and return values for each column in the results.  This is the default arrangement of time series data in <code>xts</code>.
</p>
<p>Some sample data is available in the <code><a href="#topic+managers">managers</a></code> dataset. It is an xts object that contains columns of monthly returns for six hypothetical asset managers (HAM1 through HAM6), the EDHEC Long-Short Equity hedge fund index, the S&amp;P 500 total returns, and total return series for the US Treasury 10-year bond and 3-month bill. Monthly returns for all series end in December 2006 and begin at different periods starting from January 1996. That data set is used extensively in our examples and should serve as a model for formatting your data.
</p>
<p>For retrieving market data from online sources, see <code>quantmod</code>'s <code><a href="quantmod.html#topic+getSymbols">getSymbols</a></code> function for downloading prices and <code><a href="quantmod.html#topic+chartSeries">chartSeries</a></code> for graphing price data.  Also see the <code>tseries</code> package for the function <code><a href="tseries.html#topic+get.hist.quote">get.hist.quote</a></code>. Look at <code>xts</code>'s <code><a href="xts.html#topic+to.period">to.period</a></code> function to rationally coerce irregular price data into regular data of a specified periodicity.  The <code><a href="stats.html#topic+aggregate">aggregate</a></code> function has methods for <code>tseries</code> and <code>zoo</code> timeseries data classes to rationally coerce irregular data into regular data of the correct periodicity.  
</p>
<p>Finally, see the function <code><a href="#topic+Return.calculate">Return.calculate</a></code> for calculating returns from prices.
</p>


<h3>Performance Analysis</h3>

<p>The literature around the subject of performance analysis seems to have exploded with the popularity of alternative assets such as hedge funds, managed futures, commodities, and structured products. Simpler tools that may have seemed appropriate in a relative investment world seem inappropriate for an absolute return world.  Risk measurement, which is nearly inseparable from performance assessment, has become multi-dimensional and multi-moment while trying to answer a simple question: &ldquo;How much could I lose?&rdquo;  Portfolio construction and risk budgeting are two sides of the same coin: &ldquo;How do I maximize my expected gain and avoid going broke?&rdquo;  But before we can approach those questions we first have to ask: &ldquo;Is this something I might want in my portfolio?&rdquo;
</p>
<p>With the the increasing availability of complicated alternative investment strategies to both retail and institutional investors, and the broad availability of financial data, an engaging debate about performance analysis and evaluation is as important as ever.  There won't be one <em>right</em> answer delivered in these metrics and charts.  What there will be is an accretion of evidence, organized to <em>assist</em> a decision maker in answering a specific question that is pertinent to the decision at hand.  Using such tools to uncover information and ask better questions will, in turn, create a more informed investor.
</p>
<p>Performance measurement starts with returns.  Traders may object, complaining that &ldquo;You can't eat returns,&rdquo; and will prefer to look for numbers with currency signs.  To some extent, they have a point - the normalization inherent in calculating returns can be deceiving.  Most of the recent work in performance analysis, however, is focused on returns rather than prices and sometimes called &quot;returns-based analysis&quot; or RBA.  This &ldquo;price per unit of investment&rdquo; standardization is important for two reasons - first, it helps the decision maker to compare opportunities, and second, it has some useful statistical qualities.  As a result, the <kbd>PerformanceAnalytics</kbd> package focuses on returns.  See <code><a href="#topic+Return.calculate">Return.calculate</a></code> for converting net asset values or prices into returns, either discrete or continuous.  Many papers and theories refer to &ldquo;excess returns&rdquo;: we implement a simple function for aligning time series and calculating excess returns in <code><a href="#topic+Return.excess">Return.excess</a></code>.
</p>
<p><code><a href="#topic+Return.portfolio">Return.portfolio</a></code> can be used to calculate weighted returns for a portfolio of assets.  The function was recently changed to support several use-cases: a single weighting vector, an equal weighted portfolio, periodic rebalancing, or irregular rebalancing.  That replaces functionality that had been split between that function and <code><a href="#topic+Return.rebalancing">Return.rebalancing</a></code>.  The function will subset the return series to only include returns for assets for which <code><a href="#topic+weights">weights</a></code> are provided.
</p>
<p>Returns and risk may be annualized as a way to simplify comparison over longer time periods.  Although it requires a bit of estimating, such aggregation is popular because it offers a reference point for easy comparison.  Examples are in <code><a href="#topic+Return.annualized">Return.annualized</a></code>, <code><a href="#topic+sd.annualized">sd.annualized</a></code>, and <code><a href="#topic+SharpeRatio.annualized">SharpeRatio.annualized</a></code>.
</p>
<p>Basic measures of performance tend to treat returns as independent observations.  In this case, the entirety of R's base is applicable to such analysis.  Some basic statistics we have collected in <code><a href="#topic+table.Stats">table.Stats</a></code> include:
<br />
</p>

<table>
<tr>
 <td style="text-align: left;">
<code><a href="base.html#topic+mean">mean</a></code>  </td><td style="text-align: left;">  arithmetic mean </td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+mean.geometric">mean.geometric</a></code> </td><td style="text-align: left;"> geometric mean </td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+mean.stderr">mean.stderr</a></code> </td><td style="text-align: left;"> standard error of the mean (S.E. mean) </td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+mean.LCL">mean.LCL</a></code> </td><td style="text-align: left;"> lower confidence level (LCL) of the mean </td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+mean.UCL">mean.UCL</a></code> </td><td style="text-align: left;"> upper confidence level (UCL) of the mean </td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="stats.html#topic+quantile">quantile</a></code>  </td><td style="text-align: left;"> for calculating various quantiles of the distribution </td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="base.html#topic+min">min</a></code>  </td><td style="text-align: left;"> minimum return </td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="base.html#topic+max">max</a></code>  </td><td style="text-align: left;"> maximum return </td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="base.html#topic+range">range</a></code> </td><td style="text-align: left;"> range of returns </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>length(R)</code>  </td><td style="text-align: left;"> number of observations </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>sum(is.na(R))</code> </td><td style="text-align: left;"> number of NA's </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>It is often valuable when evaluating an investment to know whether the instrument that you are examining follows a normal distribution.  One of the first methods to determine how close the asset is to a normal or log-normal distribution is to visually look at your data.  Both <code><a href="#topic+chart.QQPlot">chart.QQPlot</a></code> and <code><a href="#topic+chart.Histogram">chart.Histogram</a></code> will quickly give you a feel for whether or not you are looking at a normally distributed return history.  Differences between <code><a href="stats.html#topic+var">var</a></code> and <code><a href="#topic+SemiVariance">SemiVariance</a></code> will help you identify <code><a href="#topic+skewness">skewness</a></code> in the returns.  Skewness measures the degree of asymmetry in the return distribution.  Positive skewness indicates that more of the returns are positive, negative skewness indicates that more of the returns are negative.  An investor should in most cases prefer a positively skewed asset to a similar (style, industry, region) asset that has a negative skewness. 
</p>
<p>Kurtosis measures the concentration of the returns in any given part of the distribution (as you should see visually in a histogram).  The <code><a href="#topic+kurtosis">kurtosis</a></code> function will by default return what is referred to as &ldquo;excess kurtosis&rdquo;, where 0 is a normal distribution, other methods of calculating kurtosis than <code>method="excess"</code> will set the normal distribution at a value of 3.  In general a rational investor should prefer an asset with a low to negative excess kurtosis, as this will indicate more predictable returns (the major exception is generally a combination of high positive skewness and high excess kurtosis).  If you find yourself needing to analyze the distribution of complex or non-smooth asset distributions, the <code>nortest</code> package has several advanced statistical tests for analyzing the normality of a distribution.
</p>
<p><em>Modern Portfolio Theory (MPT)</em> is the collection of tools and techniques by which a risk-averse investor may construct an &ldquo;optimal&rdquo; portfolio.  It was pioneered by Markowitz's ground-breaking 1952 paper <cite>Portfolio Selection</cite>.  It also encompasses CAPM, below, the efficient market hypothesis, and all forms of quantitative portfolio construction and optimization.
</p>
<p><em>The Capital Asset Pricing Model (CAPM)</em>, initially developed by William Sharpe in 1964, provides a justification for passive or index investing by positing that assets that are not on the efficient frontier will either rise or fall in price until they are. The <code><a href="#topic+CAPM.RiskPremium">CAPM.RiskPremium</a></code> is the measure of how much the asset's performance differs from the risk free rate.  Negative Risk Premium generally indicates that the investment is a bad investment, and the money should be allocated to the risk free asset or to a different asset with a higher risk premium.  <code><a href="#topic+CAPM.alpha">CAPM.alpha</a></code> is the degree to which the assets returns are not due to the return that could be captured from the market. Conversely, <code><a href="#topic+CAPM.beta">CAPM.beta</a></code> describes the portions of the returns of the asset that could be directly attributed to the returns of a passive investment in the benchmark asset. 
</p>
<p>The Capital Market Line <code><a href="#topic+CAPM.CML">CAPM.CML</a></code> relates the excess expected return on an efficient market portfolio to its risk (represented in CAPM by <code><a href="stats.html#topic+sd">sd</a></code>).  The slope of the CML, <code><a href="#topic+CAPM.CML.slope">CAPM.CML.slope</a></code>, is the Sharpe Ratio for the market portfolio. The Security Market Line is constructed by calculating the line of <code><a href="#topic+CAPM.RiskPremium">CAPM.RiskPremium</a></code> over <code><a href="#topic+CAPM.beta">CAPM.beta</a></code>.  For the benchmark asset this will be 1 over the risk premium of the benchmark asset. The slope of the SML, primarily for plotting purposes, is given by <code><a href="#topic+CAPM.SML.slope">CAPM.SML.slope</a></code>. CAPM is a market equilibrium model or a general equilibrium theory of the relation of prices to risk, but it is usually applied to partial equilibrium portfolios, which can create (sometimes serious) problems in valuation.
</p>
<p>One extension to the CAPM contemplates evaluating an active manager's ability to time the market.  Two other functions apply the same notion of best fit to positive and negative market returns, separately.  The <code><a href="#topic+CAPM.beta.bull">CAPM.beta.bull</a></code> is a regression for only positive market returns, which can be used to understand the behavior of the asset or portfolio in positive or 'bull' markets.  Alternatively, <code><a href="#topic+CAPM.beta.bear">CAPM.beta.bear</a></code> provides the calculation on negative market returns. The <code><a href="#topic+TimingRatio">TimingRatio</a></code> uses the ratio of those to help assess whether the manager has shown evidence that of timing skill.
</p>
<p>The performance premium provided by an investment over a passive strategy (the benchmark) is provided by <code><a href="#topic+ActivePremium">ActivePremium</a></code>, which is the investment's annualized return minus the benchmark's annualized return. A closely related measure is the <code><a href="#topic+TrackingError">TrackingError</a></code>, which  measures the unexplained portion of the investment's performance relative to a benchmark. The <code><a href="#topic+InformationRatio">InformationRatio</a></code> of an investment in a MPT or CAPM framework is the Active Premium divided by the Tracking Error.  Information Ratio may be used to rank investments in a relative fashion.
</p>
<p>We have also included a function to compute the <code><a href="#topic+KellyRatio">KellyRatio</a></code>.  The Kelly criterion applied to position sizing will maximize log-utility of returns and avoid risk of ruin.  For our purposes, it can also be used as a stack-ranking method like <code><a href="#topic+InformationRatio">InformationRatio</a></code> to describe the &ldquo;edge&rdquo; an investment would have over a random strategy or distribution.
</p>
<p>These metrics and others such as <code><a href="#topic+SharpeRatio">SharpeRatio</a></code>, <code><a href="#topic+SortinoRatio">SortinoRatio</a></code>, <code><a href="#topic+UpsidePotentialRatio">UpsidePotentialRatio</a></code>, Spearman rank correlation (see <code><a href="Hmisc.html#topic+rcorr">rcorr</a></code>), etc., are all methods of rank-ordering relative performance. <cite>Alexander and Dimitriu (2004) in &ldquo;The Art of Investing in Hedge Funds&rdquo;</cite> show that relative rankings across multiple pricing methodologies may be positively correlated with each other and with expected returns.  This is quite an important finding because it shows that multiple methods of predicting returns and risk which have underlying measures and factors that are not directly correlated to another measure or factor will still produce widely similar quantile rankings, so that the &ldquo;buckets&rdquo; of target instruments will have significant overlap.  This observation specifically supports the point made early in this document regarding &ldquo;accretion of the evidence&rdquo; for a positive or negative investment decision.
</p>


<h3>Style Analysis</h3>

<p>Style analysis is one way to help determine a fund's exposures to the changes in returns of major asset classes or other factors.  <kbd>PerformanceAnalytics</kbd> previously had a few functions that calculate style weights using an asset class style model as described in detail in Sharpe (1992).
</p>
<p>These functions have been moved to <kbd>R-Forge</kbd> in package <kbd>FactorAnalytics</kbd> as part of a collaboration with Eric Zivot at the University of Washington. The functions combine to calculate effective style weights and display the results in a bar chart.  <code>chart.Style</code> calculates and displays style weights calculated over a single period. <code>chart.RollingStyle</code> calculates and displays those weights in rolling windows through time.  <code>style.fit</code> manages the calculation of the weights by method, and <code>style.QPfit</code> calculates the specific constraint case that requires quadratic programming.  [note: these functions do not currently appear in the development codebase, but should reappear as a supported method at some point]
</p>
<p>There is a significant amount of academic literature on identifying and attributing sources of risk or returns.  Much of it falls into the field of &ldquo;factor analysis&rdquo; where &ldquo;risk factors&rdquo; are used to retrospectively explain sources of risk, and through regression and other analytical methods <em>predict</em> future period returns and risk based on factor drivers.  These are well covered in chapters on factor analysis in <cite>Zivot and Wang(2006)</cite> and also in the <span class="rlang"><b>R</b></span> functions <code><a href="stats.html#topic+factanal">factanal</a></code> for basic factor analysis and <code><a href="stats.html#topic+princomp">princomp</a></code> for Principal Component Analysis.  The authors feel that financial engineers and analysts would benefit from some wrapping of this functionality focused on finance, but the capabilities already available from the base functions are quite powerful.  We are hopeful that our new collaboration with Prof. Zivot will provide additional functionality in the near future.
</p>


<h3>Risk Analysis</h3>

<p>Many methods have been proposed to measure, monitor, and control the risks of a diversified portfolio. Perhaps a few definitions are in order on how different risks are generally classified. <em>Market Risk</em> is the risk to the portfolio from a decline in the market price of instruments in the portfolio.  <em>Liquidity Risk</em> is the risk that the holder of an instrument will find that a position is illiquid, and will incur extra costs in unwinding the position resulting in a less favorable price for the instrument. In  extreme cases of liquidity risk, the seller may be unable to find a buyer for the instrument at all, making the value unknowable or zero.  <em>Credit Risk</em> encompasses <em>Default Risk</em>, or the risk that promised payments on a loan or bond will not be made, or that a convertible instrument will not be converted in a timely manner or at all.  There are also <em>Counterparty Risks</em> in over the counter markets, such as those for complex derivatives.  Tools have evolved to measure all these different components of risk.  Processes must be put into place inside a firm to monitor the changing risks in a portfolio, and to control the magnitude of risks.  For an extensive treatment of these topics, see Litterman, Gumerlock, et. al.(1998).  For our purposes, <kbd>PerformanceAnalytics</kbd> tends to focus on market and liquidity risk.
</p>
<p>The simplest risk measure in common use is volatility, usually modeled quantitatively with a univariate standard deviation on a portfolio.  See <code><a href="stats.html#topic+sd">sd</a></code>.  Volatility or Standard Deviation is an appropriate risk measure when the distribution of returns is normal or resembles a random walk, and may be annualized using <code><a href="#topic+sd.annualized">sd.annualized</a></code>, or the equivalent function <code><a href="#topic+sd.multiperiod">sd.multiperiod</a></code> for scaling to an arbitrary number of periods.  Many assets, including hedge funds, commodities, options, and even most common stocks over a sufficiently long period, do not follow a normal distribution.  For such common but non-normally distributed assets, a more sophisticated approach than standard deviation/volatility is required to adequately model the risk.
</p>
<p>Markowitz, in his Nobel acceptance speech and in several papers, proposed that <code><a href="#topic+SemiVariance">SemiVariance</a></code> would be a better measure of risk than variance.  See <cite>Zin, Markowitz, Zhao (2006)</cite>.  This measure is also called <code><a href="#topic+SemiDeviation">SemiDeviation</a></code>.  The more general case is <code><a href="#topic+DownsideDeviation">DownsideDeviation</a></code>, as proposed by <cite>Sortino and Price(1994)</cite>, where the minimum acceptable return (MAR) is a parameter to the function.  It is interesting to note that variance and mean return can produce a smoothly elliptical efficient frontier for portfolio optimization using <code><a href="quadprog.html#topic+solve.QP">solve.QP</a></code> or <code><a href="tseries.html#topic+portfolio.optim">portfolio.optim</a></code> or <kbd>fPortfolio</kbd>. Use of semivariance or many other risk measures will not necessarily create a smooth ellipse, causing significant additional difficulties for the portfolio manager trying to build an optimal portfolio.  We'll leave a more complete treatment and implementation of portfolio optimization techniques for another time.
</p>
<p>Another very widely used downside risk measures is analysis of drawdowns, or loss from peak value achieved. The simplest method is to check the <code><a href="#topic+maxDrawdown">maxDrawdown</a></code>, as this will tell you the worst cumulative loss ever sustained by the asset.  If you want to look at all the drawdowns, you can <code><a href="#topic+findDrawdowns">findDrawdowns</a></code> and <code><a href="#topic+sortDrawdowns">sortDrawdowns</a></code> in order from worst/major to smallest/minor. The <code><a href="#topic+UpDownRatios">UpDownRatios</a></code> function will give you some insight into the impacts of the skewness and kurtosis of the returns, and letting you know how length and magnitude of up or down moves compare to each other.  You can also plot drawdowns with <code><a href="#topic+chart.Drawdown">chart.Drawdown</a></code>.
</p>
<p>One of the most commonly used and cited measures of the risk/reward tradeoff of an investment or portfolio is the <code><a href="#topic+SharpeRatio">SharpeRatio</a></code>, which measures return over standard deviation.  If you are comparing multiple assets using Sharpe, you should use <code><a href="#topic+SharpeRatio.annualized">SharpeRatio.annualized</a></code>. It is important to note that William Sharpe now recommends <code><a href="#topic+InformationRatio">InformationRatio</a></code> preferentially to the original Sharpe Ratio. The <code><a href="#topic+SortinoRatio">SortinoRatio</a></code> uses mean return over <code><a href="#topic+DownsideDeviation">DownsideDeviation</a></code> below the MAR as the risk measure to produce a similar ratio that is more sensitive to downside risk. Sortino later enhanced his ideas to use upside returns for the numerator and <code><a href="#topic+DownsideDeviation">DownsideDeviation</a></code> as the denominator in <code><a href="#topic+UpsidePotentialRatio">UpsidePotentialRatio</a></code>. <cite>Favre and Galeano(2002)</cite> propose using the ratio of expected excess return over the Cornish-Fisher <code><a href="#topic+VaR">VaR</a></code> to produce <code><a href="#topic+SharpeRatio.modified">SharpeRatio.modified</a></code>. <code><a href="#topic+TreynorRatio">TreynorRatio</a></code> is also similar to the Sharpe Ratio, except it uses <code><a href="#topic+CAPM.beta">CAPM.beta</a></code> in place of the volatility measure to produce the ratio of the investment's excess return over the beta.
</p>
<p>One of the newer statistical methods developed for analyzing the risk of financial instruments is <code><a href="#topic+Omega">Omega</a></code>.  Omega analytically constructs a cumulative distribution function, in a manner similar to <code><a href="#topic+chart.QQPlot">chart.QQPlot</a></code>, but then extracts additional information from the location and slope of the derived function at the point indicated by the risk quantile that the researcher is interested in.  Omega seeks to combine a large amount of data about the shape, magnitude, and slope of the distribution into one method.  The academic literature is still exploring the best manner to use Omega in a risk measurement and control process, or in portfolio construction.
</p>
<p>Any risk measure should be viewed with suspicion if there are not a large number of historical observations of returns for the asset in question available.  Depending on the measure, the number of observations required will vary greatly from a statistical standpoint.  As a heuristic rule, ideally you will have data available on how the instrument performed through several economic cycles and shocks.  When such a long history is not available, the investor or researcher has several options.  A full discussion of the various approaches is beyond the scope of this introduction, so we will merely touch on several areas that an interested party may wish to explore in additional detail. Examining the returns of assets with a similar style, industry, or asset class to which the asset in question is highly correlated and shares other characteristics can be quite informative.  Factor analysis may be used to uncover specific risk factors where transparency is not available. Various resampling (see <code><a href="tseries.html#topic+tsbootstrap">tsbootstrap</a></code>) and simulation methods are available in <span class="rlang"><b>R</b></span> to construct an artificially long distribution for testing.  If you use a method such as Monte Carlo simulation or the bootstrap, it is often valuable to use <code><a href="#topic+chart.Boxplot">chart.Boxplot</a></code> to visualize the different estimates of the risk measure produced by the simulation, to see how small (or wide) a range the estimates cover, and thus gain a level of confidence with the results.  Proceed with extreme caution when your historical data is lacking.  Problems with lack of historical data are a major reason why many institutional investors will not invest in an alternative asset without several years of historical return data available.
</p>


<h3>Value at Risk - VaR</h3>

<p><em>Traditional mean-VaR</em>:
In the early 90's, academic literature started referring to &ldquo;value at risk&rdquo;, typically written as VaR. Take care to capitalize VaR in the commonly accepted manner, to avoid confusion with var (variance) and VAR (vector auto-regression).  With a sufficiently large data set, you may choose to use a non-parametric VaR estimation method using the historical distribution and the probability quantile of the distribution calculated using <code><a href="stats.html#topic+qnorm">qnorm</a></code>. The negative return at the correct quantile (usually 95% or 99%), is the non-parametric VaR estimate.  J.P. Morgan's RiskMetrics parametric mean-VaR was published in 1994 and this methodology for estimating parametric mean-VaR has become what people are generally referring to as &ldquo;VaR&rdquo; and what we have implemented as <code><a href="#topic+VaR">VaR</a></code> with <code>method="historical"</code>.  See <cite>Return to RiskMetrics: Evolution of a Standard</cite> at <a href="https://www.msci.com/documents/10199/dbb975aa-5dc2-4441-aa2d-ae34ab5f0945">https://www.msci.com/documents/10199/dbb975aa-5dc2-4441-aa2d-ae34ab5f0945</a>. Parametric traditional VaR does a better job of accounting for the tails of the distribution by more precisely estimating the tails below the risk quantile.  It is still insufficient if the assets have a distribution that varies widely from normality.  That is available in <code><a href="#topic+VaR">VaR</a></code> with <code>method="gaussian"</code>.
</p>
<p>The <span class="rlang"><b>R</b></span> package VaR, now orphaned, contains methods for simulating and estimating lognormal <kbd>VaR.norm</kbd> and generalized Pareto <kbd>VaR.gpd</kbd> distributions to overcome some of the problems with nonparametric or parametric mean-VaR calculations on a limited sample size.  There is also a <kbd>VaR.backtest</kbd> function to apply simulation methods to create a more robust estimate of the potential distribution of losses.  The VaR package also provides plots for its functions.  We will attempt to incoporate this orphaned functionality in PerformanceAnalytics in an upcoming release.
</p>
<p><em>Modified Cornish-Fisher VaR</em>:
The limitations of traditional mean-VaR are all related to the use of a symmetrical distribution function.  Use of simulations, resampling, or Pareto distributions all help in making a more accurate prediction, but they are still flawed for assets with significantly non-normal (skewed and/or kurtotic) distributions. <cite>Huisman (1999)</cite> and <cite>Favre and Galleano (2002)</cite> propose to overcome this extensively documented failing of traditional VaR by directly incorporating the higher moments of the return distribution into the VaR calculation.  
</p>
<p>This new VaR measure incorporates skewness and kurtosis via an analytical estimation using a Cornish-Fisher (special case of a Taylor) expansion. The resulting measure is referred to variously as &ldquo;Cornish-Fisher VaR&rdquo; or &ldquo;Modified VaR&rdquo;.  We provide this measure in function <code><a href="#topic+VaR">VaR</a></code> with <code>method="modified"</code>.  Modified VaR produces the same results as traditional mean-VaR when the return distribution is normal, so it may be used as a direct replacement.  Many papers in the finance literature have reached the conclusion that Modified VaR is a superior measure, and may be substituted in any case where mean-VaR would previously have been used.  
</p>
<p><em>Conditional VaR and Expected Shortfall</em>:
We have implemented Conditional Value at Risk, also called Expected Shortfall (not to be confused with shortfall probability, which is much less useful), in function <code><a href="#topic+ES">ES</a></code>.  Expected Shortfall attempts to measure the magnitude of the average loss exceeding the traditional mean-VaR. Expected Shortfall has proven to be a reasonable risk predictor for many asset classes.  We have provided traditional historical, Gaussian and modified Cornish-Fisher measures of Expected Shortfall by using <code>method="historical"</code>, <code>method="gaussian"</code> or <code>method="modified"</code>. See <cite>Uryasev(2000)</cite> and <cite>Sherer and Martin(2005)</cite> for more information on Conditional Value at Risk and Expected Shortfall.  Please note that your milage will vary; expect that values obtained from the normal distribution may differ radically from the real situation, depending on the assets under analysis.
</p>
<p><em>Multivariate extensions to risk measures</em>:
We have extened all moments calculations to work in a multivariate portfolio context.  In a portfolio context the multivariate moments are generally to be preferred to their univariate counterparts, so that all information is available to subsequent calculations.  Both the <code><a href="#topic+VaR">VaR</a></code> and <code><a href="#topic+ES">ES</a></code> functions allow calculation of metrics in a portfolio context when <code>weights</code> and a <code>portfolio_method</code> are passed into the function call.
</p>
<p><em>Marginal, Incremental, and Component VaR</em>:
Marginal VaR is the difference between the VaR of the portfolio without the asset in question and the entire portfolio.  The <code><a href="#topic+VaR">VaR</a></code> function calculates Marginal VaR for all instruments in the portfolio if you set <code>method="marginal"</code>. Marginal VaR as provided here may use traditional mean-VaR or Modified VaR for the calculation. Per <cite>Artzner,et.al.(1997)</cite> properties of a coherent risk measure include subadditivity (risks of the portfolio should not exceed the sum of the risks of individual components) as a significantly desirable trait.  VaR measures, including Marginal VaR, on individual components of a portfolio are <em>not</em> subadditive. 
</p>
<p>Clearly, a general subadditive risk measure for downside risk is required.  In Incremental or Component VaR, the Component VaR value for each element of the portfolio will sum to the total VaR of the portfolio.  Several EDHEC papers suggest using Modified VaR instead of mean-VaR in the Incremental and Component VaR calculation.  We have succeeded in implementing Component VaR and ES calculations that use Modified Cornish-Fisher VaR, historical decomposition, and kernel estimators.  You may access these with <code><a href="#topic+VaR">VaR</a></code> or <code><a href="#topic+ES">ES</a></code> by setting the appropriate <code>portfolio_method</code> and <code>method</code> arguments.
</p>
<p>The <code><a href="#topic+chart.VaRSensitivity">chart.VaRSensitivity</a></code> function creates a chart of Value-at-Risk or Expected Shortfall estimates by confidence interval for multiple methods. Useful for comparing a calculated VaR or ES method to the historical VaR or ES, it may also be used to visually examine whether the VaR method &ldquo;breaks down&rdquo; or gives nonsense results at a certain threshold.
</p>
<p>Which VaR measure to use will depend greatly on the portfolio and instruments being analyzed.  If there is any generalization to be made on VaR measures, we agree with <cite>Bali and Gokcan(2004)</cite> who conclude that &ldquo;the VaR estimations based on the generalized Pareto distribution and the Cornish-Fisher approximation perform best&rdquo;.
</p>


<h3>Moments and Co-moments</h3>

<p>Analysis of financial time series often involves evaluating their mathematical moments.  While <code><a href="stats.html#topic+var">var</a></code> and <code><a href="stats.html#topic+cov">cov</a></code> for variance has always been available, as well as  <code><a href="#topic+skewness">skewness</a></code> and <code><a href="#topic+kurtosis">kurtosis</a></code> (which we have extended to make multivariate and multi-column aware), a larger suite of multivariate moments calculations was not available in <span class="rlang"><b>R</b></span>.  We have now implemented multivariate moments and co-moments and their beta or systematic co-moments in <kbd>PerformanceAnalytics</kbd>.
</p>
<p><cite>Ranaldo and Favre (2005)</cite> define coskewness and cokurtosis as the skewness and kurtosis of a given asset analysed with the skewness and kurtosis of the reference asset or portfolio.  The co-moments are useful for measuring the marginal contribution of each asset to the portfolio's resulting risk.  As such, co-moments of an asset return distribution should be useful as inputs for portfolio optimization in addition to the covariance matrix.  Functions include <code><a href="#topic+CoVariance">CoVariance</a></code>, <code><a href="#topic+CoSkewness">CoSkewness</a></code>, <code><a href="#topic+CoKurtosis">CoKurtosis</a></code>.
</p>
<p>Measuring the co-moments should be useful for evaluating whether or not an asset is likely to provide diversification potential to a portfolio.  But the co-moments do not allow the marginal impact of an asset on a portfolio to be directly measured.  Instead, <cite>Martellini and Zieman (2007)</cite> develop a framework that assesses the potential diversification of an asset relative to a portfolio. They use higher moment betas to estimate how much portfolio risk will be impacted by adding an asset.  
</p>
<p>Higher moment betas are defined as proportional to the derivative of the covariance, coskewness and cokurtosis of the second, third and fourth portfolio moment with respect to the portfolio weights.  A beta that is less than 1 indicates that adding the new asset should reduce the resulting portfolio's volatility and kurtosis, and to an increase in skewness. More specifically, the lower the beta the higher the diversification effect, not only in terms of normal risk (i.e. volatility) but also the risk of assymetry (skewness) and extreme events (kurtosis).  See the functions for <code><a href="#topic+BetaCoVariance">BetaCoVariance</a></code>, <code><a href="#topic+BetaCoSkewness">BetaCoSkewness</a></code>, and <code><a href="#topic+BetaCoKurtosis">BetaCoKurtosis</a></code>.
</p>


<h3>Robust Data Cleaning</h3>

<p>The functions <code><a href="#topic+Return.clean">Return.clean</a></code> and <code><a href="#topic+clean.boudt">clean.boudt</a></code> implement statistically robust data cleaning methods tuned to portfolio construction and risk analysis and prediction in financial time series while trying to avoid some of the pitfalls of standard robust statistical methods.
</p>
<p>The primary value of data cleaning lies in creating a more
robust and stable estimation of the distribution generating the
large majority of the return data. The increased robustness and
stability of the estimated moments using cleaned data should be
used for portfolio construction. If an investor wishes to
have a more conservative risk estimate, cleaning may not be
indicated for risk monitoring. 
</p>
<p>In actual practice, it is probably best to back-test the out-of-sample results of
both cleaned and uncleaned series to see what works best when forecasting risk with the
particular combination of assets under consideration.
</p>


<h3>Summary Tabular Data</h3>

<p>Summary statistics are then the necessary aggregation and reduction of (potentially thousands) of periodic return numbers. Usually these statistics are most palatable when organized into a table of related statistics, assembled for a particular purpose.  A common offering of past returns organized by month and cumulated by calendar year is usually presented as a table, such as in <code><a href="#topic+table.CalendarReturns">table.CalendarReturns</a></code>.  Adding benchmarks or peers alongside the annualized data is helpful for comparing returns in calendar years.
</p>
<p>When we started this project, we debated whether such tables would be broadly useful or not.  No reader is likely to think that we captured the precise statistics to help their decision. We merely offer these as a starting point for creating your own.  Add, subtract, do whatever seems useful to you.  If you think that your work may be useful to others, please consider sharing it so that we may include it in a future version of this package.
</p>
<p>Other tables for comparison of related groupings of statistics discussed elsewhere:
</p>

<table>
<tr>
 <td style="text-align: right;">

    <code><a href="#topic+table.Stats">table.Stats</a></code> </td><td style="text-align: left;"> Basic statistics and stylized facts </td>
</tr>
<tr>
 <td style="text-align: right;">
    <code><a href="#topic+table.TrailingPeriods">table.TrailingPeriods</a></code> </td><td style="text-align: left;"> Statistics and stylized facts compared over different trailing periods </td>
</tr>
<tr>
 <td style="text-align: right;">
    <code><a href="#topic+table.AnnualizedReturns">table.AnnualizedReturns</a></code> </td><td style="text-align: left;"> Annualized return, standard deviation, and Sharpe ratio </td>
</tr>
<tr>
 <td style="text-align: right;">
    <code><a href="#topic+table.CalendarReturns">table.CalendarReturns</a></code> </td><td style="text-align: left;"> Monthly and calendar year return table </td>
</tr>
<tr>
 <td style="text-align: right;">
    <code><a href="#topic+table.CAPM">table.CAPM</a></code> </td><td style="text-align: left;"> CAPM-related measures </td>
</tr>
<tr>
 <td style="text-align: right;">
    <code><a href="#topic+table.Correlation">table.Correlation</a></code> </td><td style="text-align: left;"> Comparison of correlalations and significance statistics </td>
</tr>
<tr>
 <td style="text-align: right;">
    <code><a href="#topic+table.DownsideRisk">table.DownsideRisk</a></code> </td><td style="text-align: left;"> Downside risk metrics and statistics </td>
</tr>
<tr>
 <td style="text-align: right;">
    <code><a href="#topic+table.Drawdowns">table.Drawdowns</a></code> </td><td style="text-align: left;"> Ordered list of drawdowns and when they occurred </td>
</tr>
<tr>
 <td style="text-align: right;">
    <code><a href="#topic+table.Autocorrelation">table.Autocorrelation</a></code> </td><td style="text-align: left;"> The first six autocorrelation coefficients and significance </td>
</tr>
<tr>
 <td style="text-align: right;">
    <code><a href="#topic+table.HigherMoments">table.HigherMoments</a></code> </td><td style="text-align: left;"> Higher co-moments and beta co-moments </td>
</tr>
<tr>
 <td style="text-align: right;">
    <code><a href="#topic+table.Arbitrary">table.Arbitrary</a></code> </td><td style="text-align: left;"> Combines a function list into a table </td>
</tr>
<tr>
 <td style="text-align: right;">
  </td>
</tr>

</table>



<h3>Charts and Graphs</h3>

<p>Graphs and charts can also help to organize the information visually. Our goal in creating these charts was to simplify the process of creating well-formatted charts that are used often in performance analysis, and to create high-quality graphics that may be used in documents for consumption by non-analysts or researchers. <span class="rlang"><b>R</b></span>'s graphics capabilities are substantial, but the simplicity of the output of <span class="rlang"><b>R</b></span> default graphics functions such as <code><a href="graphics.html#topic+plot">plot</a></code> does not always compare well against graphics delivered with commercial asset or performance analysis from places such as MorningStar or PerTrac.
</p>
<p>The cumulative returns or wealth index is usually the first thing displayed, even though neither conveys much information.  See <code><a href="#topic+chart.CumReturns">chart.CumReturns</a></code>.  Individual period returns may be helpful for identifying problematic periods, such as in <code><a href="#topic+chart.Bar">chart.Bar</a></code>.  Risk measures can be helpful when overlaid on the period returns, to display the bounds at which losses may be expected.  See <code><a href="#topic+chart.BarVaR">chart.BarVaR</a></code> and the prior section on Risk Analysis.  More information can be conveyed when such charts are displayed together, as in <code><a href="#topic+charts.PerformanceSummary">charts.PerformanceSummary</a></code>, which combines the performance data with detail on downside risk (see <code><a href="#topic+chart.Drawdown">chart.Drawdown</a></code>).
</p>
<p><code><a href="#topic+chart.RelativePerformance">chart.RelativePerformance</a></code> can plot the relative performance through time of two assets.  This plot displays the ratio of the cumulative performance at each point in time and makes periods of under- or out-performance easy to see.  The value of the chart is less important than the slope of the line.  If the slope is positive, the first asset is outperforming the second, and vice verse.  Affectionately known as the Canto chart, it was used effectively in Canto (2006).
</p>
<p>Two-dimensional charts can also be useful while remaining easy to understand.  <code><a href="#topic+chart.Scatter">chart.Scatter</a></code> is a utility scatter chart with some additional attributes that are used in <code><a href="#topic+chart.RiskReturnScatter">chart.RiskReturnScatter</a></code>.  Overlaying Sharpe ratio lines or boxplots helps to add information about relative performance along those dimensions. 
</p>
<p>For distributional analysis, a few graphics may be useful.  <code><a href="#topic+chart.Boxplot">chart.Boxplot</a></code> is an example of a graphic that is difficult to create in Excel and is under-utilized as a result.  A boxplot of returns is, however, a very useful way to instantly observe the shape of large collections of asset returns in a manner that makes them easy to compare to one another.  <code><a href="#topic+chart.Histogram">chart.Histogram</a></code> and <code><a href="#topic+chart.QQPlot">chart.QQPlot</a></code> are two charts originally found elsewhere and now substantially expanded in <kbd>PerformanceAnalytics</kbd>.
</p>
<p>Rolling performance is typically used as a way to assess stability of a return stream.  Although perhaps it doesn't get much credence in the financial literature as it derives from work in digital signal processing, many practitioners find it a useful way to examine and segment performance and risk periods.  See <code><a href="#topic+chart.RollingPerformance">chart.RollingPerformance</a></code>, which is a way to display different metrics over rolling time periods.  <code><a href="#topic+chart.RollingMean">chart.RollingMean</a></code> is a specific example of a rolling mean and standard error bands.  A group of related metrics is offered in <code><a href="#topic+charts.RollingPerformance">charts.RollingPerformance</a></code>.  These charts use utility functions such as <code><a href="zoo.html#topic+rollapply">rollapply</a></code>.
</p>
<p><code><a href="#topic+chart.SnailTrail">chart.SnailTrail</a></code> is a scatter chart that shows how rolling calculations of annualized return and annualized standard deviation have proceeded through time where the color of lines and dots on the chart diminishes with respect to time. <code><a href="#topic+chart.RollingCorrelation">chart.RollingCorrelation</a></code> shows how correlations change over rolling periods.  <code><a href="#topic+chart.RollingRegression">chart.RollingRegression</a></code> displays the coefficients of a linear model fitted over rolling periods.  A group of charts in <code><a href="#topic+charts.RollingRegression">charts.RollingRegression</a></code> displays alpha, beta, and R-squared estimates in three aligned charts in a single device.
</p>
<p><code><a href="#topic+chart.StackedBar">chart.StackedBar</a></code> creates a stacked column chart with time on the horizontal axis and values in categories.  This kind of chart is commonly used for showing portfolio 'weights' through time, although the function will plot any values by category. 
</p>
<p>We have been greatly inspired by other peoples' work, some of which is on display at addictedtor.free.fr.  Particular inspiration came from Dirk Eddelbuettel and John Bollinger for their work at http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=65. Those interested in price charting in <span class="rlang"><b>R</b></span> should also look at the <code>quantmod</code> package.
</p>


<h3>Wrapper and Utility Functions</h3>

<p><span class="rlang"><b>R</b></span> is a very powerful environment for manipulating data.  It can also be quite confusing to a user more accustomed to Excel or even MatLAB.  As such, we have written some wrapper functions that may aid you in coercing data into the correct forms or finding data that you need to use regularly.  To simplify the management of multiple-source data stored in <span class="rlang"><b>R</b></span> in multiple data formats, we have provided <code><a href="#topic+checkData">checkData</a></code>.  This function will attempt to coerce data in and out of <span class="rlang"><b>R</b></span>'s multitude of mostly fungible data classes into the class required for a particular analysis.  The data-coercion function has been hidden inside the functions here, but it may also save you time and trouble in your own code and functions as well.
</p>
<p><span class="rlang"><b>R</b></span>'s built-in <code><a href="base.html#topic+apply">apply</a></code> function in enormously powerful, but is can be tricky to use with timeseries data, so we have provided wrapper functions to <code><a href="#topic+apply.fromstart">apply.fromstart</a></code> and <code><a href="#topic+apply.rolling">apply.rolling</a></code> to make handling of &ldquo;from inception&rdquo; and &ldquo;rolling window&rdquo; calculations easier.
</p>


<h3>Further Work</h3>

<p>We have attempted to standardize function parameters and variable names, but more work exists to be done here.
</p>
<p>Any comments, suggestions, or code patches are invited.
</p>
<p>If you've implemented anything that you think would be generally useful to include, please consider donating it for inclusion in a later version of this package.
</p>


<h3>Acknowledgments</h3>

<p>Data series <code><a href="#topic+edhec">edhec</a></code> used in <kbd>PerformanceAnalytics</kbd> and related publications with the kind permission of the EDHEC Risk and Asset Management Research Center. <br />
<a href="http://www.edhec-risk.com/indexes/pure_style">http://www.edhec-risk.com/indexes/pure_style</a>
</p>
<p>Kris Boudt was instrumental in our research on component risk for portfolios with non-normal distributions, and is responsible for much of the code for multivariate moments and co-moments.
</p>
<p>Jeff Ryan and Josh Ulrich are active participants in the R finance community and created <code><a href="xts.html#topic+xts">xts</a></code>, upon which much of PerformanceAnalytics depends.
</p>
<p>Prototypes of the drawdowns functionality were provided by Sankalp Upadhyay, and modified with permission. Stephan Albrecht provided detailed feedback on the Getmansky/Lo Smoothing Index.  Diethelm Wuertz provided prototypes of modified VaR and skewness and kurtosis functions (and is of course the maintainer of the RMetrics suite of pricing and optimization functions).  He also contributed prototypes for many other functions from Bacon's book that were incorporated into PerformanceAnalytics by Matthieu Lestel.  Any errors are, of course, our own.
</p>
<p>Thanks to Joe Wayne Byers and Dirk Eddelbuettel for comments on early versions of these functions, and to Khanh Nguyen, Tobias Verbeke, H. Felix Wittmann, and Ryan Sheftel for careful testing and detailed problem reports.
</p>
<p>Thanks also to our Google Summer of Code students through the years for their contributions.  Significant contributions from GSOC students to this package have come from Matthieu Lestel and Andrii Babii so far.  We expect to eventually incorporate contributions from Pulkit Mehrotra and Shubhankit Mohan, who worked with us during the summer of 2013.
</p>
<p>Thanks to the R-SIG-Finance community without whom this package would not be possible.  We are indebted to the R-SIG-Finance community for many helpful suggestions, bugfixes, and requests.
</p>


<h3>Author(s)</h3>

<p>Brian G. Peterson <br />
Peter Carl <br />
</p>
<p>Maintainer: Brian G. Peterson <a href="mailto:brian@braverock.com">brian@braverock.com</a>
</p>


<h3>References</h3>

<p>Amenc, N. and Le Sourd, V. <em>Portfolio Theory and Performance Analysis</em>. Wiley. 2003. <br /> 
</p>
<p>Bacon, C. <em>Practical Portfolio Performance Measurement and Attribution</em>. Wiley. 2004. <br />
</p>
<p>Canto, V. <em>Understanding Asset Allocation</em>. FT Prentice Hall. 2006. <br />
</p>
<p>Lhabitant, F. <em>Hedge Funds: Quantitative Insights</em>. Wiley. 2004. <br />
</p>
<p>Litterman, R., Gumerlock R., et. al. <em>The Practice of Risk Management: Implementing Processes for Managing Firm-Wide Market Risk</em>. Euromoney. 1998. <br />
</p>
<p>Martellini, Lionel, and Volker Ziemann. <em>Improved Forecasts of Higher-Order Comoments and Implications for Portfolio Selection.</em> EDHEC Risk and Asset Management Research Centre working paper. 2007. <br />
</p>
<p>Ranaldo, Angelo, and Laurent Favre Sr. <em>How to Price Hedge Funds: From Two- to Four-Moment CAPM.</em> SSRN eLibrary. 2005.
</p>
<p>Murrel, P. <em>R Graphics</em>. Chapman and Hall. 2006.  <br />
</p>
<p>Ruppert, D. <em>Statistics and Finance, an Introduction</em>. Springer. 2004. <br />
</p>
<p>Scherer, B. and Martin, D. <em>Modern Portfolio Optimization</em>. Springer. 2005. <br />
</p>
<p>Shumway, R. and Stoffer, D. <em>Time Series Analysis and it's Applications, with R examples</em>, Springer, 2006. <br />
</p>
<p>Tsay, R. <em>Analysis of Financial Time Series</em>. Wiley. 2001. <br />
</p>
<p>Zin, Markowitz, Zhao A Note on Semivariance. Mathematical Finance, Vol. 16, No. 1, pp. 53-61, January 2006 
</p>
<p>Zivot, E. and Wang, Z. <em>Modeling Financial Time Series with S-Plus: second edition</em>. Springer. 2006. <br />
</p>


<h3>See Also</h3>

<p>CRAN task view on Empirical Finance <br /> <a href="https://CRAN.R-project.org/view=Econometrics">https://CRAN.R-project.org/view=Econometrics</a>
</p>
<p>Grant Farnsworth's Econometrics in R <br /> <a href="https://cran.r-project.org/doc/contrib/Farnsworth-EconometricsInR.pdf">https://cran.r-project.org/doc/contrib/Farnsworth-EconometricsInR.pdf</a>
</p>
<p>Collection of R charts and graphs <br /> http://addictedtor.free.fr/graphiques/
</p>

<hr>
<h2 id='ActiveReturn'>Active Premium or Active Return</h2><span id='topic+ActiveReturn'></span><span id='topic+ActivePremium'></span>

<h3>Description</h3>

<p>The return on an investment's annualized return minus the benchmark's
annualized return.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ActiveReturn(Ra, Rb, scale = NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ActiveReturn_+3A_ra">Ra</code></td>
<td>
<p>return vector of the portfolio</p>
</td></tr>
<tr><td><code id="ActiveReturn_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="ActiveReturn_+3A_scale">scale</code></td>
<td>
<p>number of periods in a year
(daily scale = 252, monthly scale = 12, quarterly scale = 4)</p>
</td></tr>
<tr><td><code id="ActiveReturn_+3A_...">...</code></td>
<td>
<p>any other passthru parameters to Return.annualized
(e.g., <code>geometric=FALSE</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Active Premium = Investment's annualized return - Benchmark's annualized
return
</p>
<p>Also commonly referred to as 'active return'.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>Sharpe, W.F. The Sharpe Ratio,<em>Journal of Portfolio
Management</em>, Fall 1994, 49-58.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+InformationRatio">InformationRatio</a></code> <code><a href="#topic+TrackingError">TrackingError</a></code>
<code><a href="#topic+Return.annualized">Return.annualized</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
    data(managers)
    ActivePremium(managers[, "HAM1", drop=FALSE], managers[, "SP500 TR", drop=FALSE])
    ActivePremium(managers[,1,drop=FALSE], managers[,8,drop=FALSE])
    ActivePremium(managers[,1:6], managers[,8,drop=FALSE])
    ActivePremium(managers[,1:6], managers[,8:7,drop=FALSE])
</code></pre>

<hr>
<h2 id='AdjustedSharpeRatio'>Adjusted Sharpe ratio of the return distribution</h2><span id='topic+AdjustedSharpeRatio'></span>

<h3>Description</h3>

<p>Adjusted Sharpe ratio was introduced by Pezier and White (2006) to adjusts
for skewness and kurtosis by incorporating a penalty factor for negative skewness
and excess kurtosis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AdjustedSharpeRatio(R, Rf = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AdjustedSharpeRatio_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="AdjustedSharpeRatio_+3A_rf">Rf</code></td>
<td>
<p>the risk free rate</p>
</td></tr>
<tr><td><code id="AdjustedSharpeRatio_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">Adjusted Sharpe Ratio = SR * [1 + (\frac{S}{6}) * SR - (\frac{K - 3}{24}) * SR^2]</code>
</p>

<p>where <code class="reqn">SR</code> is the sharpe ratio with data annualized, <code class="reqn">S</code> is the skewness and <code class="reqn">K</code> is the kurtosis
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel, Brian G. Peterson
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.99
</p>
<p>Pezier, Jaques and White, Anthony. 2006. The Relative Merits of Investable 
Hedge Fund Indices and of Funds of Hedge Funds in Optimal Passive Portfolios.
<a href="http://econpapers.repec.org/paper/rdgicmadp/icma-dp2006-10.htm">http://econpapers.repec.org/paper/rdgicmadp/icma-dp2006-10.htm</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SharpeRatio.annualized">SharpeRatio.annualized</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(portfolio_bacon)
print(AdjustedSharpeRatio(portfolio_bacon[,1])) #expected 0.7591435

data(managers)
print(AdjustedSharpeRatio(managers['1996']))
</code></pre>

<hr>
<h2 id='apply.fromstart'>calculate a function over an expanding window always starting from the
beginning of the series</h2><span id='topic+apply.fromstart'></span>

<h3>Description</h3>

<p>A function to calculate a function over an expanding window from the start
of the timeseries.  This wrapper allows easy calculation of &ldquo;from
inception&rdquo; statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>apply.fromstart(R, FUN = "mean", gap = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="apply.fromstart_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="apply.fromstart_+3A_fun">FUN</code></td>
<td>
<p>any function that can be evaluated using a single set of returns
(e.g., rolling beta won't work, but <code><a href="#topic+Return.annualized">Return.annualized</a></code> will)</p>
</td></tr>
<tr><td><code id="apply.fromstart_+3A_gap">gap</code></td>
<td>
<p>the number of data points from the beginning of the series
required to &ldquo;train&rdquo; the calculation</p>
</td></tr>
<tr><td><code id="apply.fromstart_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="zoo.html#topic+rollapply">rollapply</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
apply.fromstart(managers[,1,drop=FALSE], FUN="mean", width=36)

</code></pre>

<hr>
<h2 id='apply.rolling'>calculate a function over a rolling window</h2><span id='topic+apply.rolling'></span>

<h3>Description</h3>

<p>Creates a results timeseries of a function applied over a rolling window.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>apply.rolling(R, width, trim = TRUE, gap = 12, by = 1, FUN = "mean", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="apply.rolling_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="apply.rolling_+3A_width">width</code></td>
<td>
<p>number of periods to apply rolling function window over</p>
</td></tr>
<tr><td><code id="apply.rolling_+3A_trim">trim</code></td>
<td>
<p>TRUE/FALSE, whether to keep alignment caused by NA's</p>
</td></tr>
<tr><td><code id="apply.rolling_+3A_gap">gap</code></td>
<td>
<p>numeric number of periods from start of series to use to train
risk calculation</p>
</td></tr>
<tr><td><code id="apply.rolling_+3A_by">by</code></td>
<td>
<p>calculate FUN for trailing width points at every by-th time point.</p>
</td></tr>
<tr><td><code id="apply.rolling_+3A_fun">FUN</code></td>
<td>
<p>any function that can be evaluated using a single set of returns
(e.g., rolling beta won't work, but <code><a href="#topic+Return.annualized">Return.annualized</a></code> will)</p>
</td></tr>
<tr><td><code id="apply.rolling_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Wrapper function for <code><a href="zoo.html#topic+rollapply">rollapply</a></code> to hide some of the
complexity of managing single-column zoo objects.
</p>


<h3>Value</h3>

<p>A timeseries in a zoo object of the calculation results
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+apply">apply</a></code> <br /> <code><a href="zoo.html#topic+rollapply">rollapply</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
apply.rolling(managers[,1,drop=FALSE], FUN="mean", width=36)

</code></pre>

<hr>
<h2 id='AppraisalRatio'>Appraisal ratio of the return distribution</h2><span id='topic+AppraisalRatio'></span>

<h3>Description</h3>

<p>Appraisal ratio is the Jensen's alpha adjusted for specific risk. The numerator
is divided by specific risk instead of total risk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AppraisalRatio(
  Ra,
  Rb,
  Rf = 0,
  method = c("appraisal", "modified", "alternative"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AppraisalRatio_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="AppraisalRatio_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="AppraisalRatio_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="AppraisalRatio_+3A_method">method</code></td>
<td>
<p>is one of &quot;appraisal&quot; to calculate appraisal ratio, &quot;modified&quot; to
calculate modified Jensen's alpha or &quot;alternative&quot; to calculate alternative
Jensen's alpha.</p>
</td></tr>
<tr><td><code id="AppraisalRatio_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Modified Jensen's alpha is Jensen's alpha divided by beta.
</p>
<p>Alternative Jensen's alpha is Jensen's alpha divided by systematic risk.
</p>
<p style="text-align: center;"><code class="reqn">Appraisal ratio = \frac{\alpha}{\sigma_{\epsilon}}</code>
</p>

<p style="text-align: center;"><code class="reqn">Modified Jensen's alpha = \frac{\alpha}{\beta}</code>
</p>

<p style="text-align: center;"><code class="reqn">Alternative Jensen's alpha = \frac{\alpha}{\sigma_S}</code>
</p>

<p>where <code class="reqn">alpha</code> is the Jensen's alpha, <code class="reqn">\sigma_{epsilon}</code> is the specific risk,
<code class="reqn">\sigma_S</code> is the systematic risk.
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.77
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(portfolio_bacon)
print(AppraisalRatio(portfolio_bacon[,1], portfolio_bacon[,2], method="appraisal")) #expected -0.430
print(AppraisalRatio(portfolio_bacon[,1], portfolio_bacon[,2], method="modified")) 
print(AppraisalRatio(portfolio_bacon[,1], portfolio_bacon[,2], method="alternative"))

data(managers)
print(AppraisalRatio(managers['1996',1], managers['1996',8]))
print(AppraisalRatio(managers['1996',1:5], managers['1996',8]))

</code></pre>

<hr>
<h2 id='AverageDrawdown'>Calculates the average depth of the observed drawdowns.</h2><span id='topic+AverageDrawdown'></span>

<h3>Description</h3>

<p>ADD = abs(sum[j=1,2,...,d](D_j/d)) where
D'_j = jth drawdown over entire period
d = total number of drawdowns in the entire period
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AverageDrawdown(R, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AverageDrawdown_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="AverageDrawdown_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Carl
</p>

<hr>
<h2 id='AverageLength'>Calculates the average length (in periods) of the observed drawdowns.</h2><span id='topic+AverageLength'></span>

<h3>Description</h3>

<p>Similar to <code><a href="#topic+AverageDrawdown">AverageDrawdown</a></code>, which calculates the average depth of drawdown, this function calculates the average length of the drawdowns observed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AverageLength(R, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AverageLength_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="AverageLength_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Carl
</p>

<hr>
<h2 id='AverageRecovery'>Calculates the average length (in periods) of the observed recovery period.</h2><span id='topic+AverageRecovery'></span>

<h3>Description</h3>

<p>Similar to <code><a href="#topic+AverageDrawdown">AverageDrawdown</a></code>, which calculates the average depth of drawdown, this function calculates the average length of the recovery period of the drawdowns observed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AverageRecovery(R, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AverageRecovery_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="AverageRecovery_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Carl
</p>

<hr>
<h2 id='BernardoLedoitRatio'>Bernardo and Ledoit ratio of the return distribution</h2><span id='topic+BernardoLedoitRatio'></span>

<h3>Description</h3>

<p>To calculate Bernardo and Ledoit ratio we take the sum of the subset of
returns that are above 0 and we divide it by the opposite of the sum of
the subset of returns that are below 0
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BernardoLedoitRatio(R, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BernardoLedoitRatio_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="BernardoLedoitRatio_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">BernardoLedoitRatio(R) = \frac{\frac{1}{n}\sum^{n}_{t=1}{max(R_{t},0)}}{\frac{1}{n}\sum^{n}_{t=1}{max(-R_{t},0)}}</code>
</p>

<p>where <code class="reqn">n</code> is the number of observations of the entire series
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.95
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(portfolio_bacon)
print(BernardoLedoitRatio(portfolio_bacon[,1])) #expected 1.78

data(managers)
print(BernardoLedoitRatio(managers['1996']))
print(BernardoLedoitRatio(managers['1996',1])) #expected 4.598

</code></pre>

<hr>
<h2 id='BetaCoMoments'>Functions to calculate systematic or beta co-moments of return series</h2><span id='topic+BetaCoMoments'></span><span id='topic+BetaCoVariance'></span><span id='topic+BetaCoSkewness'></span><span id='topic+BetaCoKurtosis'></span><span id='topic+SystematicSkewness'></span><span id='topic+SystematicKurtosis'></span>

<h3>Description</h3>

<p>calculate higher co-moment betas, or 'systematic' variance, skewness, and
kurtosis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BetaCoVariance(Ra, Rb)

BetaCoSkewness(Ra, Rb, test = FALSE)

BetaCoKurtosis(Ra, Rb)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BetaCoMoments_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="BetaCoMoments_+3A_rb">Rb</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
index, benchmark, or secondary asset returns to compare against</p>
</td></tr>
<tr><td><code id="BetaCoMoments_+3A_test">test</code></td>
<td>
<p>condition not implemented yet</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The co-moments, including covariance, coskewness, and cokurtosis, do not
allow the marginal impact of an asset on a portfolio to be directly
measured.  Instead, Martellini and Zieman (2007) develop a framework that
assesses the potential diversification of an asset relative to a portfolio.
They use higher moment betas to estimate how much portfolio risk will be
impacted by adding an asset, in terms of symmetric risk (i.e., volatility),
in asymmetry risk (i.e., skewness), and extreme risks (i.e. kurtosis). That
allows them to show that adding an asset to a portfolio (or benchmark) will
reduce the portfolio's variance to be reduced if the second-order beta of
the asset with respect to the portfolio is less than one.  They develop the
same concepts for the third and fourth order moments.  The authors offer
these higher moment betas as a measure of the diversification potential of
an asset.
</p>
<p>Higher moment betas are defined as proportional to the derivative of the
covariance, coskewness and cokurtosis of the second, third and fourth
portfolio moment with respect to the portfolio weights. The beta co-variance
is calculated as: 
</p>
<p style="text-align: center;"><code class="reqn"> BetaCoV(Ra,Rb) = \beta^{(2)}_{a,b} =
\frac{CoV(R_a,R_b)}{\mu^{(2)}(R_b)} </code>
</p>
 
<p>Beta co-skewness is given as: 
</p>
<p style="text-align: center;"><code class="reqn"> BetaCoS(Ra,Rb) = \beta^{(3)}_{a,b}= \frac{CoS(R_a,R_b)}{\mu^{(3)}(R_b)} </code>
</p>
 
<p>Beta co-kurtosis is: 
</p>
<p style="text-align: center;"><code class="reqn"> BetaCoK(Ra,Rb)=\beta^{(4)}_{a,b}
= \frac{CoK(R_a,R_b)}{\mu^{(4)}(R_b)} </code>
</p>
 
<p>where the <code class="reqn">n</code>-th centered moment is
calculated as 
</p>
<p style="text-align: center;"><code class="reqn"> \mu^{(n)}(R) = E\lbrack(R-E(R))^n\rbrack </code>
</p>

<p>A beta is greater than one indicates that no diversification benefits should
be expected from the introduction of that asset into the portfolio.
Conversely, a beta that is less than one indicates that adding the new asset
should reduce the resulting portfolio's volatility and kurtosis, and to an
increase in skewness. More specifically, the lower the beta the higher the
diversification effect on normal risk (i.e. volatility). Similarly, since
extreme risks are generally characterised by negative skewness and positive
kurtosis, the lower the beta, the higher the diversification effect on
extreme risks (as reflected in Modified Value-at-Risk or ER).
</p>
<p>The addition of a small fraction of a new asset to a portfolio leads to a
decrease in the portfolio's second moment (respectively, an increase in the
portfolio's third moment and a decrease in the portfolio's fourth moment) if
and only if the second moment (respectively, the third moment and fourth
moment) beta is less than one (see Martellini and Ziemann (2007) for more
details).
</p>
<p>For skewness, the interpretation is slightly more involved.  If the skewness
of the portfolio is negative, we would expect an increase in portfolio
skewness when the third moment beta is lower than one. When the skewness of
the portfolio is positive, then the condition is that the third moment beta
is greater than, as opposed to lower than, one.
</p>
<p>Because the interpretation of beta coskewness is made difficult by the need
to condition on it's skewness, we deviate from the more widely used measure
slightly.  To make the interpretation consistent across all three measures,
the beta coskewness function tests the skewness and multiplies the result by
the sign of the skewness.  That allows an analyst to review the metric and
interpret it without needing additional information.  To use the more widely
used metric, simply set the parameter <code>test = FALSE</code>.
</p>


<h3>Author(s)</h3>

<p>Kris Boudt, Peter Carl, Brian Peterson
</p>


<h3>References</h3>

<p>Boudt, Kris, Brian G. Peterson, and Christophe Croux. 2008. Estimation and
Decomposition of Downside Risk for Portfolios with Non-Normal Returns.
Journal of Risk. Winter.
</p>
<p>Martellini, Lionel, and Volker Ziemann. 2007. Improved Forecasts of
Higher-Order Comoments and Implications for Portfolio Selection. EDHEC Risk
and Asset Management Research Centre working paper.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CoMoments">CoMoments</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)

BetaCoVariance(managers[, "HAM2", drop=FALSE], managers[, "SP500 TR", drop=FALSE])
BetaCoSkewness(managers[, "HAM2", drop=FALSE], managers[, "SP500 TR", drop=FALSE])
BetaCoKurtosis(managers[, "HAM2", drop=FALSE], managers[, "SP500 TR", drop=FALSE])
BetaCoKurtosis(managers[,1:6], managers[,8,drop=FALSE])
BetaCoKurtosis(managers[,1:6], managers[,8:7])

</code></pre>

<hr>
<h2 id='BurkeRatio'>Burke ratio of the return distribution</h2><span id='topic+BurkeRatio'></span>

<h3>Description</h3>

<p>To calculate Burke ratio we take the difference between the portfolio
return and the risk free rate and we divide it by the square root of the
sum of the square of the drawdowns. To calculate the modified Burke ratio
we just multiply the Burke ratio by the square root of the number of datas.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BurkeRatio(R, Rf = 0, modified = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BurkeRatio_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="BurkeRatio_+3A_rf">Rf</code></td>
<td>
<p>the risk free rate</p>
</td></tr>
<tr><td><code id="BurkeRatio_+3A_modified">modified</code></td>
<td>
<p>a boolean to decide which ratio to calculate between Burke ratio and modified Burke ratio.</p>
</td></tr>
<tr><td><code id="BurkeRatio_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">Burke Ratio = \frac{r_P - r_F}{\sqrt{\sum^{d}_{t=1}{D_t}^2}}</code>
</p>

<p style="text-align: center;"><code class="reqn">Modified Burke Ratio = \frac{r_P - r_F}{\sqrt{\sum^{d}_{t=1}\frac{{D_t}^2}{n}}}</code>
</p>

<p>where <code class="reqn">n</code> is the number of observations of the entire series, <code class="reqn">d</code> is number of drawdowns, <code class="reqn">r_P</code> is the portfolio return, <code class="reqn">r_F</code> is the risk free rate and <code class="reqn">D_t</code> the <code class="reqn">t^{th}</code> drawdown.
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.90-91
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(portfolio_bacon)
print(BurkeRatio(portfolio_bacon[,1])) #expected 0.74
print(BurkeRatio(portfolio_bacon[,1], modified = TRUE)) #expected 3.65

data(managers)
print(BurkeRatio(managers['1996']))
print(BurkeRatio(managers['1996',1])) 
print(BurkeRatio(managers['1996'], modified = TRUE))
print(BurkeRatio(managers['1996',1], modified = TRUE)) 

</code></pre>

<hr>
<h2 id='CalmarRatio'>calculate a Calmar or Sterling reward/risk ratio
Calmar and Sterling Ratios are yet another method of creating a
risk-adjusted measure for ranking investments similar to the
<code><a href="#topic+SharpeRatio">SharpeRatio</a></code>.</h2><span id='topic+CalmarRatio'></span><span id='topic+SterlingRatio'></span>

<h3>Description</h3>

<p>Both the Calmar and the Sterling ratio are the ratio of annualized return
over the absolute value of the maximum drawdown of an investment. The
Sterling ratio adds an excess risk measure to the maximum drawdown,
traditionally and defaulting to 10%.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CalmarRatio(R, scale = NA)

SterlingRatio(R, scale = NA, excess = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CalmarRatio_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="CalmarRatio_+3A_scale">scale</code></td>
<td>
<p>number of periods in a year (daily scale = 252, monthly scale =
12, quarterly scale = 4)</p>
</td></tr>
<tr><td><code id="CalmarRatio_+3A_excess">excess</code></td>
<td>
<p>for Sterling Ratio, excess amount to add to the max drawdown,
traditionally and default .1 (10%)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is also traditional to use a three year return series for these
calculations, although the functions included here make no effort to
determine the length of your series.  If you want to use a subset of your
series, you'll need to truncate or subset the input data to the desired
length.
</p>
<p>Many other measures have been proposed to do similar reward to risk ranking.
It is the opinion of this author that newer measures such as Sortino's
<code><a href="#topic+UpsidePotentialRatio">UpsidePotentialRatio</a></code> or Favre's modified
<code><a href="#topic+SharpeRatio">SharpeRatio</a></code> are both &ldquo;better&rdquo; measures, and
should be preferred to the Calmar or Sterling Ratio.
</p>


<h3>Author(s)</h3>

<p>Brian G. Peterson
</p>


<h3>References</h3>

<p>Bacon, Carl. <em>Practical Portfolio Performance Measurement
and Attribution</em>. Wiley. 2004.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Return.annualized">Return.annualized</a></code>, <br /> 
<code><a href="#topic+maxDrawdown">maxDrawdown</a></code>, <br />
<code><a href="#topic+SharpeRatio.modified">SharpeRatio.modified</a></code>, <br /> 
<code><a href="#topic+UpsidePotentialRatio">UpsidePotentialRatio</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
    data(managers)
    CalmarRatio(managers[,1,drop=FALSE])
    CalmarRatio(managers[,1:6]) 
    SterlingRatio(managers[,1,drop=FALSE])
    SterlingRatio(managers[,1:6])

</code></pre>

<hr>
<h2 id='CAPM.alpha'>calculate single factor model (CAPM) alpha</h2><span id='topic+CAPM.alpha'></span><span id='topic+SFM.alpha'></span>

<h3>Description</h3>

<p>This is a wrapper for calculating a single factor model (CAPM) alpha.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CAPM.alpha(Ra, Rb, Rf = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CAPM.alpha_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="CAPM.alpha_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="CAPM.alpha_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&quot;Alpha&quot; purports to be a measure of a manager's skill by measuring the
portion of the managers returns that are not attributable to &quot;Beta&quot;, or the
portion of performance attributable to a benchmark.
</p>
<p>While the classical CAPM has been almost completely discredited by the 
literature, it is an example of a simple single factor model, 
comparing an asset to any arbitrary benchmark.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>Sharpe, W.F. Capital Asset Prices: A theory of market
equilibrium under conditions of risk. <em>Journal of finance</em>, vol 19,
1964, 425-442. <br /> Ruppert, David. <em>Statistics and Finance, an
Introduction</em>. Springer. 2004. <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CAPM.beta">CAPM.beta</a></code> <code><a href="#topic+CAPM.utils">CAPM.utils</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# First we load the data
    data(managers)
    CAPM.alpha(managers[,1,drop=FALSE], 
			managers[,8,drop=FALSE], 
			Rf=.035/12) 
    CAPM.alpha(managers[,1,drop=FALSE], 
			managers[,8,drop=FALSE], 
			Rf = managers[,10,drop=FALSE])
    CAPM.alpha(managers[,1:6], 
			managers[,8,drop=FALSE], 
			Rf=.035/12)
    CAPM.alpha(managers[,1:6], 
			managers[,8,drop=FALSE], 
			Rf = managers[,10,drop=FALSE])
    CAPM.alpha(managers[,1:6], 
			managers[,8:7,drop=FALSE], 
			Rf=.035/12) 
    CAPM.alpha(managers[,1:6], 
			managers[,8:7,drop=FALSE], 
			Rf = managers[,10,drop=FALSE])
  		
</code></pre>

<hr>
<h2 id='CAPM.beta'>calculate single factor model (CAPM) beta</h2><span id='topic+CAPM.beta'></span><span id='topic+CAPM.beta.bull'></span><span id='topic+CAPM.beta.bear'></span><span id='topic+TimingRatio'></span><span id='topic+SFM.beta'></span>

<h3>Description</h3>

<p>The single factor model or CAPM Beta is the beta of an asset to the variance 
and covariance of an initial portfolio.  Used to determine diversification potential.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CAPM.beta(Ra, Rb, Rf = 0)

CAPM.beta.bull(Ra, Rb, Rf = 0)

CAPM.beta.bear(Ra, Rb, Rf = 0)

TimingRatio(Ra, Rb, Rf = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CAPM.beta_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="CAPM.beta_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="CAPM.beta_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses a linear intercept model to achieve the same results as
the symbolic model used by <code><a href="#topic+BetaCoVariance">BetaCoVariance</a></code>
</p>
<p style="text-align: center;"><code class="reqn">\beta_{a,b}=\frac{CoV_{a,b}}{\sigma_{b}}=\frac{\sum((R_{a}-\bar{R_{a}})(R_{b}-\bar{R_{b}}))}{\sum(R_{b}-\bar{R_{b}})^{2}}</code>
</p>

<p>Ruppert(2004) reports that this equation will give the estimated slope of
the linear regression of <code class="reqn">R_{a}</code> on <code class="reqn">R_{b}</code> and that this
slope can be used to determine the risk premium or excess expected return
(see Eq. 7.9 and 7.10, p. 230-231).
</p>
<p>Two other functions apply the same notion of best fit to positive and
negative market returns, separately.  The <code>CAPM.beta.bull</code> is a
regression for only positive market returns, which can be used to understand
the behavior of the asset or portfolio in positive or 'bull' markets.
Alternatively, <code>CAPM.beta.bear</code> provides the calculation on negative
market returns.
</p>
<p>The <code>TimingRatio</code> may help assess whether the manager is a good timer
of asset allocation decisions.  The ratio, which is calculated as
</p>
<p style="text-align: center;"><code class="reqn">TimingRatio =\frac{\beta^{+}}{\beta^{-}}</code>
</p>

<p>is best when greater than one in a rising market and less than one in a
falling market.
</p>
<p>While the classical CAPM has been almost completely discredited by the 
literature, it is an example of a simple single factor model, 
comparing an asset to any arbitrary benchmark.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>Sharpe, W.F. Capital Asset Prices: A theory of market
equilibrium under conditions of risk. <em>Journal of finance</em>, vol 19,
1964, 425-442. <br /> Ruppert, David. <em>Statistics and Finance, an
Introduction</em>. Springer. 2004. <br /> Bacon, Carl. <em>Practical portfolio
performance measurement and attribution</em>. Wiley. 2004. <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BetaCoVariance">BetaCoVariance</a></code> <code><a href="#topic+CAPM.alpha">CAPM.alpha</a></code>
<code><a href="#topic+CAPM.utils">CAPM.utils</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
    CAPM.alpha(managers[,1,drop=FALSE], 
			managers[,8,drop=FALSE], 
			Rf=.035/12) 
    CAPM.alpha(managers[,1,drop=FALSE], 
			managers[,8,drop=FALSE], 
			Rf = managers[,10,drop=FALSE])
    CAPM.alpha(managers[,1:6], 
			managers[,8,drop=FALSE], 
			Rf=.035/12)
    CAPM.alpha(managers[,1:6], 
			managers[,8,drop=FALSE], 
			Rf = managers[,10,drop=FALSE])
    CAPM.alpha(managers[,1:6], 
			managers[,8:7,drop=FALSE], 
			Rf=.035/12) 
    CAPM.alpha(managers[,1:6], 
			managers[,8:7,drop=FALSE], 
			Rf = managers[,10,drop=FALSE])
    CAPM.beta(managers[, "HAM2", drop=FALSE], 
			managers[, "SP500 TR", drop=FALSE], 
			Rf = managers[, "US 3m TR", drop=FALSE])
    CAPM.beta.bull(managers[, "HAM2", drop=FALSE], 
			managers[, "SP500 TR", drop=FALSE], 
			Rf = managers[, "US 3m TR", drop=FALSE])
    CAPM.beta.bear(managers[, "HAM2", drop=FALSE], 
			managers[, "SP500 TR", drop=FALSE], 
			Rf = managers[, "US 3m TR", drop=FALSE])
    TimingRatio(managers[, "HAM2", drop=FALSE], 
			managers[, "SP500 TR", drop=FALSE], 
			Rf = managers[, "US 3m TR", drop=FALSE])
    chart.Regression(managers[, "HAM2", drop=FALSE], 
			managers[, "SP500 TR", drop=FALSE], 
			Rf = managers[, "US 3m TR", drop=FALSE], 
			fit="conditional", 
			main="Conditional Beta")
  		
</code></pre>

<hr>
<h2 id='CAPM.CML.slope'>utility functions for single factor (CAPM) CML, SML, and RiskPremium</h2><span id='topic+CAPM.CML.slope'></span><span id='topic+CAPM.CML'></span><span id='topic+CAPM.RiskPremium'></span><span id='topic+CAPM.utils'></span><span id='topic+CAPM.SML.slope'></span><span id='topic+SFM.utils'></span><span id='topic+SFM.RiskPremium'></span><span id='topic+SFM.CML'></span><span id='topic+SFM.CML.slope'></span><span id='topic+SFM.SML.slope'></span>

<h3>Description</h3>

<p>The Capital Asset Pricing Model, from which the popular
<code><a href="#topic+SharpeRatio">SharpeRatio</a></code> is derived, is a theory of market equilibrium.
These utility functions provide values for various measures proposed in the
CAPM.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CAPM.CML.slope(Rb, Rf = 0)

CAPM.CML(Ra, Rb, Rf = 0)

CAPM.RiskPremium(Ra, Rf = 0)

CAPM.SML.slope(Rb, Rf = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CAPM.CML.slope_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="CAPM.CML.slope_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="CAPM.CML.slope_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
</table>


<h3>Details</h3>

<p>At it's core, the CAPM is a single factor linear model.  In light of 
the general ustility and wide use of single factor model, all 
functions in the CAPM suite will also be available with SFM (single factor model)
prefixes.
</p>
<p>The CAPM provides a justification for passive or index investing by positing
that assets that are not on the efficient frontier will either rise or lower
in price until they are on the efficient frontier of the market portfolio.
</p>
<p>The CAPM Risk Premium on an investment is the measure of how much the
asset's performance differs from the risk free rate.  Negative Risk Premium
generally indicates that the investment is a bad investment, and the money
should be allocated to the risk free asset or to a different asset with a
higher risk premium.
</p>
<p>The Capital Market Line relates the excess expected return on an efficient
market portfolio to it's Risk.  The slope of the CML is the Sharpe Ratio for
the market portfolio. The Security Market line is constructed by calculating
the line of Risk Premium over <code><a href="#topic+CAPM.beta">CAPM.beta</a></code>.  For the benchmark
asset this will be 1 over the risk premium of the benchmark asset.  The CML
also describes the only path allowed by the CAPM to a portfolio that
outperforms the efficient frontier: it describes the line of reward/risk
that a leveraged portfolio will occupy.  So, according to CAPM, no portfolio
constructed of the same assets can lie above the CML.
</p>
<p>Probably the most complete criticism of CAPM in actual practice (as opposed
to structural or theory critiques) is that it posits a market equilibrium,
but is most often used only in a partial equilibrium setting, for example by
using the S\&amp;P 500 as the benchmark asset.  A better method of using and
testing the CAPM would be to use a general equilibrium model that took
global assets from all asset classes into consideration.
</p>
<p>Chapter 7 of Ruppert(2004) gives an extensive overview of CAPM, its
assumptions and deficiencies.
</p>
<p><code>SFM.RiskPremium</code> is the premium returned to the investor over the
risk free asset
</p>
<p style="text-align: center;"><code class="reqn">\overline{(R_{a}-R_{f})}</code>
</p>

<p><code>SFM.CML</code> calculates the expected return of the asset against the
benchmark Capital Market Line
</p>
<p><code>SFM.CML.slope</code> calculates the slope of the Capital Market Line for
looking at how a particular asset compares to the CML
</p>
<p><code>SFM.SML.slope</code> calculates the slope of the Security Market Line for
looking at how a particular asset compares to the SML created by the
benchmark
</p>


<h3>Author(s)</h3>

<p>Brian G. Peterson
</p>


<h3>References</h3>

<p>Sharpe, W.F. The Sharpe Ratio,<em>Journal of Portfolio
Management</em>,Fall 1994, 49-58. <br /> Sharpe, W.F. Capital Asset Prices: A
theory of market equilibrium under conditions of risk. <em>Journal of
finance</em>, vol 19, 1964, 425-442. <br /> Ruppert, David. <em>Statistics and
Finance, an Introduction</em>. Springer. 2004. <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CAPM.beta">CAPM.beta</a></code> <code><a href="#topic+CAPM.alpha">CAPM.alpha</a></code>
<code><a href="#topic+SharpeRatio">SharpeRatio</a></code> <code><a href="#topic+InformationRatio">InformationRatio</a></code>
<code><a href="#topic+TrackingError">TrackingError</a></code> <code><a href="#topic+ActivePremium">ActivePremium</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
CAPM.CML.slope(managers[,"SP500 TR",drop=FALSE], managers[,10,drop=FALSE])
CAPM.CML(managers[,"HAM1",drop=FALSE], managers[,"SP500 TR",drop=FALSE], Rf=0)
CAPM.RiskPremium(managers[,"SP500 TR",drop=FALSE], Rf=0)
CAPM.RiskPremium(managers[,"HAM1",drop=FALSE], Rf=0)
CAPM.SML.slope(managers[,"SP500 TR",drop=FALSE], Rf=0)
# should create plots like in Ruppert 7.1 7.2
</code></pre>

<hr>
<h2 id='CAPM.dynamic'>Time-varying conditional single factor model beta</h2><span id='topic+CAPM.dynamic'></span><span id='topic+SFM.dynamic'></span>

<h3>Description</h3>

<p>CAPM is estimated assuming that betas and alphas change over time. It is 
assumed that the market prices of securities fully reflect readily available
and public information. A matrix of market information variables, <code class="reqn">Z</code>
measures this information. Possible variables in <code class="reqn">Z</code> could be the
divident yield, Tresaury yield, etc. The betas of stocks and managed
portfolios are allowed to change with market conditions:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CAPM.dynamic(Ra, Rb, Rf = 0, Z, lags = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CAPM.dynamic_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
the asset returns</p>
</td></tr>
<tr><td><code id="CAPM.dynamic_+3A_rb">Rb</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of 
the benchmark asset return</p>
</td></tr>
<tr><td><code id="CAPM.dynamic_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="CAPM.dynamic_+3A_z">Z</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of 
k variables that reflect public information</p>
</td></tr>
<tr><td><code id="CAPM.dynamic_+3A_lags">lags</code></td>
<td>
<p>number of lags before the current period on which the alpha and
beta are conditioned</p>
</td></tr>
<tr><td><code id="CAPM.dynamic_+3A_...">...</code></td>
<td>
<p>any other passthrough parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">\beta_{p}(z_{t})=b_{0p}+B_{p}'z_{t}</code>
</p>

<p>where <code class="reqn">z_{t}=Z_{t}-E[Z]</code> 
</p>
<p>- a normalized vector of the deviations of <code class="reqn">Z_{t}</code>, <code class="reqn">B_{p}</code> 
</p>
<p>- a vector with the same dimension as <code class="reqn">Z_{t}</code>. 
</p>
<p>The coefficient <code class="reqn">b_{0p}</code> can be 
interpreted as the &quot;average beta&quot; or the beta when all infromation variables
are at their means. The elements of <code class="reqn">B_{p}</code> measure the sensitivity 
of the conditional beta to the deviations of the <code class="reqn">Z_{t}</code> from their
means. 
In the similar way the time-varying conditional alpha is modeled:
</p>
<p style="text-align: center;"><code class="reqn">\alpha_{pt}=\alpha_{p}(z_{t})=\alpha_{0p}+A_{p}'z_{t}</code>
</p>

<p>The modified regression is therefore:
</p>
<p style="text-align: center;"><code class="reqn">r_{pt+1}=\alpha_{0p}+A_{p}'z_{t}+b_{0p}r_{bt+1}+B_{p}'[z_{t}r_{bt+1}]+
\mu_{pt+1}</code>
</p>



<h3>Author(s)</h3>

<p>Andrii Babii
</p>


<h3>References</h3>

<p>J. Christopherson, D. Carino, W. Ferson. <em>Portfolio 
Performance Measurement and Benchmarking</em>. 2009. McGraw-Hill. Chapter 12. 
<br /> Wayne E. Ferson and Rudi Schadt, &quot;Measuring Fund Strategy and 
Performance in Changing Economic Conditions,&quot; <em>Journal of Finance</em>, 
vol. 51, 1996, pp.425-462 <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CAPM.beta">CAPM.beta</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
CAPM.dynamic(managers[,1,drop=FALSE], managers[,8,drop=FALSE], 
             Rf=.035/12, Z=managers[, 9:10])

CAPM.dynamic(managers[80:120,1:6], managers[80:120,7,drop=FALSE], 
             Rf=managers[80:120,10,drop=FALSE], Z=managers[80:120, 9:10])
             
CAPM.dynamic(managers[80:120,1:6], managers[80:120,8:7],
              managers[80:120,10,drop=FALSE], Z=managers[80:120, 9:10])

</code></pre>

<hr>
<h2 id='CAPM.epsilon'>Regression epsilon of the return distribution</h2><span id='topic+CAPM.epsilon'></span><span id='topic+SFM.epsilon'></span>

<h3>Description</h3>

<p>The regression epsilon is an error term measuring the vertical distance between
the return predicted by the equation and the real result.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CAPM.epsilon(Ra, Rb, Rf = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CAPM.epsilon_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="CAPM.epsilon_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="CAPM.epsilon_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="CAPM.epsilon_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">\epsilon_r = r_p - \alpha_r - \beta_r * b</code>
</p>

<p>where <code class="reqn">\alpha_r</code> is the regression alpha, <code class="reqn">\beta_r</code> is the regression beta,
<code class="reqn">r_p</code> is the portfolio return and b is the benchmark return
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.71
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(portfolio_bacon)
print(SFM.epsilon(portfolio_bacon[,1], portfolio_bacon[,2])) #expected -0.013

data(managers)
print(SFM.epsilon(managers['1996',1], managers['1996',8]))
print(SFM.epsilon(managers['1996',1:5], managers['1996',8]))

</code></pre>

<hr>
<h2 id='CAPM.jensenAlpha'>Jensen's alpha of the return distribution</h2><span id='topic+CAPM.jensenAlpha'></span><span id='topic+SFM.jensenAlpha'></span>

<h3>Description</h3>

<p>The Jensen's alpha is the intercept of the regression equation in the Capital
Asset Pricing Model and is in effect the exess return adjusted for systematic risk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CAPM.jensenAlpha(Ra, Rb, Rf = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CAPM.jensenAlpha_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="CAPM.jensenAlpha_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="CAPM.jensenAlpha_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="CAPM.jensenAlpha_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">\alpha = r_p - r_f - \beta_p * (b - r_f)</code>
</p>

<p>where <code class="reqn">r_f</code> is the risk free rate, <code class="reqn">\beta_r</code> is the regression beta,
<code class="reqn">r_p</code> is the portfolio return and b is the benchmark return
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.72
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(portfolio_bacon)
print(SFM.jensenAlpha(portfolio_bacon[,1], portfolio_bacon[,2])) #expected -0.014

data(managers)
print(SFM.jensenAlpha(managers['1996',1], managers['1996',8]))
print(SFM.jensenAlpha(managers['1996',1:5], managers['1996',8]))

</code></pre>

<hr>
<h2 id='CDD'>Calculate Uryasev's proposed Conditional Drawdown at Risk (CDD or CDaR)
measure</h2><span id='topic+CDD'></span><span id='topic+CDaR'></span>

<h3>Description</h3>

<p>For some confidence level <code class="reqn">p</code>, the conditional drawdown is the the mean
of the worst <code class="reqn">p\%</code> drawdowns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CDD(R, weights = NULL, geometric = TRUE, invert = TRUE, p = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CDD_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="CDD_+3A_weights">weights</code></td>
<td>
<p>portfolio weighting vector, default NULL, see Details</p>
</td></tr>
<tr><td><code id="CDD_+3A_geometric">geometric</code></td>
<td>
<p>utilize geometric chaining (TRUE) or simple/arithmetic chaining (FALSE) to aggregate returns,
default TRUE</p>
</td></tr>
<tr><td><code id="CDD_+3A_invert">invert</code></td>
<td>
<p>TRUE/FALSE whether to invert the drawdown measure.  see
Details.</p>
</td></tr>
<tr><td><code id="CDD_+3A_p">p</code></td>
<td>
<p>confidence level for calculation, default p=0.95</p>
</td></tr>
<tr><td><code id="CDD_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Brian G. Peterson
</p>


<h3>References</h3>

<p>Chekhlov, A., Uryasev, S., and M. Zabarankin. Portfolio
Optimization With Drawdown Constraints. B. Scherer (Ed.) Asset and Liability
Management Tools, Risk Books, London, 2003
http://www.ise.ufl.edu/uryasev/drawdown.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ES">ES</a></code> <code><a href="#topic+maxDrawdown">maxDrawdown</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)
t(round(CDD(edhec),4))

</code></pre>

<hr>
<h2 id='chart.ACF'>Create ACF chart or ACF with PACF two-panel chart</h2><span id='topic+chart.ACF'></span><span id='topic+chart.ACFplus'></span>

<h3>Description</h3>

<p>Creates an ACF chart or a two-panel plot with the ACF and PACF set to some
specific defaults.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chart.ACF(R, maxlag = NULL, elementcolor = "gray", main = NULL, ...)

chart.ACFplus(R, maxlag = NULL, elementcolor = "gray", main = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chart.ACF_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="chart.ACF_+3A_maxlag">maxlag</code></td>
<td>
<p>the number of lags to calculate for, optional</p>
</td></tr>
<tr><td><code id="chart.ACF_+3A_elementcolor">elementcolor</code></td>
<td>
<p>the color to use for chart elements, defaults to &quot;gray&quot;</p>
</td></tr>
<tr><td><code id="chart.ACF_+3A_main">main</code></td>
<td>
<p>title of the plot; uses the column name by default.</p>
</td></tr>
<tr><td><code id="chart.ACF_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Inspired by the website:
http://www.stat.pitt.edu/stoffer/tsa2/Rcode/acf2.R &quot;...here's an R
function that will plot the ACF and PACF of a time series at the same time
on the SAME SCALE, and it leaves out the zero lag in the ACF: acf2.R. If
your time series is in x and you want the ACF and PACF of x to lag 50, the
call to the function is acf2(x,50). The number of lags is optional, so
acf2(x) will use a default number of lags [sqrt(n) + 10, where n is the
number of observations].&quot;
</p>
<p>That description made a lot of sense, so it's implemented here for both the
ACF alone and the ACF with the PACF.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+plot">plot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)
chart.ACFplus(edhec[,1,drop=FALSE])

</code></pre>

<hr>
<h2 id='chart.Bar'>wrapper for barchart of returns</h2><span id='topic+chart.Bar'></span><span id='topic+charts.Bar'></span>

<h3>Description</h3>

<p>A wrapper to create a chart of periodic returns in a bar chart.  This is a
difficult enough graph to read that it doesn't get much use.  Still, it is
useful for viewing a single set of data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chart.Bar(R, legend.loc = NULL, colorset = (1:12), ...)

charts.Bar(R, main = "Returns", cex.legend = 0.8, cex.main = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chart.Bar_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="chart.Bar_+3A_legend.loc">legend.loc</code></td>
<td>
<p>places a legend into one of nine locations on the chart:
bottomright, bottom, bottomleft, left, topleft, top, topright, right, or
center</p>
</td></tr>
<tr><td><code id="chart.Bar_+3A_colorset">colorset</code></td>
<td>
<p>color palette to use, set by default to rational choices</p>
</td></tr>
<tr><td><code id="chart.Bar_+3A_...">...</code></td>
<td>
<p>any other passthru parameters, see <code>plot</code></p>
</td></tr>
<tr><td><code id="chart.Bar_+3A_main">main</code></td>
<td>
<p>sets the title text, such as in <code><a href="#topic+chart.TimeSeries">chart.TimeSeries</a></code></p>
</td></tr>
<tr><td><code id="chart.Bar_+3A_cex.legend">cex.legend</code></td>
<td>
<p>sets the legend text size, such as in
<code><a href="#topic+chart.TimeSeries">chart.TimeSeries</a></code></p>
</td></tr>
<tr><td><code id="chart.Bar_+3A_cex.main">cex.main</code></td>
<td>
<p>sets the title text size, such as in
<code><a href="#topic+chart.TimeSeries">chart.TimeSeries</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is really a wrapper for chart.TimeSeries, so several other attributes
can also be passed.
</p>
<p>Creates a plot of time on the x-axis and vertical lines for each period to
indicate value on the y-axis.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chart.TimeSeries">chart.TimeSeries</a></code> <br /> <code><a href="base.html#topic+plot">plot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)
chart.Bar(edhec[,"Funds of Funds"], main="Monthly Returns")

</code></pre>

<hr>
<h2 id='chart.BarVaR'>Periodic returns in a bar chart with risk metric overlay</h2><span id='topic+chart.BarVaR'></span><span id='topic+charts.BarVaR'></span>

<h3>Description</h3>

<p>Plots the periodic returns as a bar chart overlayed with a risk metric
calculation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chart.BarVaR(
  R,
  width = 0,
  gap = 12,
  methods = c("none", "ModifiedVaR", "GaussianVaR", "HistoricalVaR", "StdDev",
    "ModifiedES", "GaussianES", "HistoricalES"),
  p = 0.95,
  clean = c("none", "boudt", "geltner"),
  all = FALSE,
  ...,
  show.clean = FALSE,
  show.horizontal = FALSE,
  show.symmetric = FALSE,
  show.endvalue = FALSE,
  show.greenredbars = FALSE,
  legend.loc = "bottomleft",
  ylim = NA,
  lwd = 2,
  colorset = 1:12,
  lty = c(1, 2, 4, 5, 6),
  ypad = 0,
  legend.cex = 0.8,
  plot.engine = "default"
)

charts.BarVaR(
  R,
  main = "Returns",
  cex.legend = 0.8,
  colorset = 1:12,
  ylim = NA,
  ...,
  perpanel = NULL,
  show.yaxis = c("all", "firstonly", "alternating", "none")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chart.BarVaR_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="chart.BarVaR_+3A_width">width</code></td>
<td>
<p>periods specified for rolling-period calculations.  Note that
VaR, ES, and Std Dev with width=0 are calculated from the start of the
timeseries</p>
</td></tr>
<tr><td><code id="chart.BarVaR_+3A_gap">gap</code></td>
<td>
<p>numeric number of periods from start of series to use to train
risk calculation</p>
</td></tr>
<tr><td><code id="chart.BarVaR_+3A_methods">methods</code></td>
<td>
<p>Used to select the risk parameter of trailing <code>width</code>
returns to use: May be any of: </p>
 <ul>
<li><p> none - does not add a risk
line, </p>
</li>
<li><p> ModifiedVaR - uses Cornish-Fisher modified VaR, </p>
</li>
<li>
<p>GaussianVaR - uses traditional Value at Risk, </p>
</li>
<li><p> HistoricalVaR -
calculates historical Value at Risk, </p>
</li>
<li><p> ModifiedES - uses Cornish-Fisher
modified Expected Shortfall, </p>
</li>
<li><p> GaussianES - uses traditional Expected
Shortfall, </p>
</li>
<li><p> HistoricalES - calculates historical Expected Shortfall,
</p>
</li>
<li><p> StdDev - per-period standard deviation </p>
</li></ul>
</td></tr>
<tr><td><code id="chart.BarVaR_+3A_p">p</code></td>
<td>
<p>confidence level for <code>VaR</code> or <code>ModifiedVaR</code> calculation,
default is .99</p>
</td></tr>
<tr><td><code id="chart.BarVaR_+3A_clean">clean</code></td>
<td>
<p>the method to use to clean outliers from return data prior to
risk metric estimation. See <code><a href="#topic+Return.clean">Return.clean</a></code> and <code><a href="#topic+VaR">VaR</a></code>
for more detail</p>
</td></tr>
<tr><td><code id="chart.BarVaR_+3A_all">all</code></td>
<td>
<p>if TRUE, calculates risk lines for each column given in R.  If
FALSE, only calculates the risk line for the first column</p>
</td></tr>
<tr><td><code id="chart.BarVaR_+3A_...">...</code></td>
<td>
<p>any other passthru parameters to <code><a href="#topic+chart.TimeSeries">chart.TimeSeries</a></code></p>
</td></tr>
<tr><td><code id="chart.BarVaR_+3A_show.clean">show.clean</code></td>
<td>
<p>if TRUE and a method for 'clean' is specified, overlays
the actual data with the &quot;cleaned&quot; data.  See <code><a href="#topic+Return.clean">Return.clean</a></code> for
more detail</p>
</td></tr>
<tr><td><code id="chart.BarVaR_+3A_show.horizontal">show.horizontal</code></td>
<td>
<p>if TRUE, shows a line across the timeseries at the
value of the most recent VaR estimate, to help the reader evaluate the
number of exceptions thus far</p>
</td></tr>
<tr><td><code id="chart.BarVaR_+3A_show.symmetric">show.symmetric</code></td>
<td>
<p>if TRUE and the metric is symmetric, this will show
the metric's positive values as well as negative values, such as for method
&quot;StdDev&quot;.</p>
</td></tr>
<tr><td><code id="chart.BarVaR_+3A_show.endvalue">show.endvalue</code></td>
<td>
<p>if TRUE, show the final (out of sample) value</p>
</td></tr>
<tr><td><code id="chart.BarVaR_+3A_show.greenredbars">show.greenredbars</code></td>
<td>
<p>if TRUE, show the per-period returns using green
and red bars for positive and negative returns</p>
</td></tr>
<tr><td><code id="chart.BarVaR_+3A_legend.loc">legend.loc</code></td>
<td>
<p>legend location, such as in <code><a href="#topic+chart.TimeSeries">chart.TimeSeries</a></code></p>
</td></tr>
<tr><td><code id="chart.BarVaR_+3A_ylim">ylim</code></td>
<td>
<p>set the y-axis limit, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.BarVaR_+3A_lwd">lwd</code></td>
<td>
<p>set the line width, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.BarVaR_+3A_colorset">colorset</code></td>
<td>
<p>color palette to use, such as in
<code><a href="#topic+chart.TimeSeries">chart.TimeSeries</a></code></p>
</td></tr>
<tr><td><code id="chart.BarVaR_+3A_lty">lty</code></td>
<td>
<p>set the line type, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.BarVaR_+3A_ypad">ypad</code></td>
<td>
<p>adds a numerical padding to the y-axis to keep the data away
when legend.loc=&quot;bottom&quot;.  See examples below.</p>
</td></tr>
<tr><td><code id="chart.BarVaR_+3A_legend.cex">legend.cex</code></td>
<td>
<p>sets the legend text size, such as in
<code><a href="#topic+chart.TimeSeries">chart.TimeSeries</a></code></p>
</td></tr>
<tr><td><code id="chart.BarVaR_+3A_plot.engine">plot.engine</code></td>
<td>
<p>Choose the engine for plotting, including &quot;default&quot;,&quot;dygraph&quot;,&quot;ggplot&quot;,&quot;plotly&quot; and &quot;googleVis&quot;</p>
</td></tr>
<tr><td><code id="chart.BarVaR_+3A_main">main</code></td>
<td>
<p>sets the title text, such as in <code><a href="#topic+chart.TimeSeries">chart.TimeSeries</a></code></p>
</td></tr>
<tr><td><code id="chart.BarVaR_+3A_cex.legend">cex.legend</code></td>
<td>
<p>sets the legend text size, such as in
<code><a href="#topic+chart.TimeSeries">chart.TimeSeries</a></code></p>
</td></tr>
<tr><td><code id="chart.BarVaR_+3A_perpanel">perpanel</code></td>
<td>
<p>default NULL, controls column display</p>
</td></tr>
<tr><td><code id="chart.BarVaR_+3A_show.yaxis">show.yaxis</code></td>
<td>
<p>one of &quot;all&quot;, &quot;firstonly&quot;, &quot;alternating&quot;, or &quot;none&quot; to
control where y axis is plotted in multipanel charts</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that <code>StdDev</code> and <code>VaR</code> are symmetric calculations, so a high
and low measure will be plotted.  <code>ModifiedVaR</code>, on the other hand, is
assymetric and only a lower bound will be drawn.
</p>
<p>Creates a plot of time on the x-axis and vertical lines for each period to
indicate value on the y-axis.  Overlays a line to indicate the value of a
risk metric calculated at that time period.
</p>
<p><code>charts.BarVaR</code> places multile bar charts in a single 
graphic, with associated risk measures
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chart.TimeSeries">chart.TimeSeries</a></code> <br /> <code><a href="base.html#topic+plot">plot</a></code> <br />
<code><a href="#topic+ES">ES</a></code> <br /> <code><a href="#topic+VaR">VaR</a></code> <br /> <code><a href="#topic+Return.clean">Return.clean</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  # not run on CRAN because of example time
data(managers)
# plain
chart.BarVaR(managers[,1,drop=FALSE], main="Monthly Returns")

# with risk line
chart.BarVaR(managers[,1,drop=FALSE], 
		methods="HistoricalVaR", 
		main="... with Empirical VaR from Inception")
		
# with lines for all managers in the sample
chart.BarVaR(managers[,1:6], 
		methods="GaussianVaR", 
		all=TRUE, lty=1, lwd=2, 
		colorset= c("red", rep("gray", 5)), 
		main="... with Gaussian VaR and Estimates for Peers")

# with multiple methods
chart.BarVaR(managers[,1,drop=FALSE],
		methods=c("HistoricalVaR", "ModifiedVaR", "GaussianVaR"), 
		main="... with Multiple Methods")

# cleaned up a bit
chart.BarVaR(managers[,1,drop=FALSE],
		methods=c("HistoricalVaR", "ModifiedVaR", "GaussianVaR"), 
		lwd=2, ypad=.01, 
		main="... with Padding for Bottom Legend")

# with 'cleaned' data for VaR estimates
chart.BarVaR(managers[,1,drop=FALSE],
		methods=c("HistoricalVaR", "ModifiedVaR"), 
		lwd=2, ypad=.01, clean="boudt", 
		main="... with Robust ModVaR Estimate")

# Cornish Fisher VaR estimated with cleaned data, 
# with horizontal line to show exceptions
chart.BarVaR(managers[,1,drop=FALSE],
		methods="ModifiedVaR", 
		lwd=2, ypad=.01, clean="boudt", 
		show.horizontal=TRUE, lty=2, 
		main="... with Robust ModVaR and Line for Identifying Exceptions")

## End(Not run)

</code></pre>

<hr>
<h2 id='chart.Boxplot'>box whiskers plot wrapper</h2><span id='topic+chart.Boxplot'></span>

<h3>Description</h3>

<p>A wrapper to create box and whiskers plot with some defaults useful for
comparing distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chart.Boxplot(
  R,
  names = TRUE,
  as.Tufte = FALSE,
  plot.engine = "default",
  sort.by = c(NULL, "mean", "median", "variance"),
  colorset = "black",
  symbol.color = "red",
  mean.symbol = 1,
  median.symbol = "|",
  outlier.symbol = 1,
  show.data = NULL,
  add.mean = TRUE,
  sort.ascending = FALSE,
  xlab = "Return",
  main = "Return Distribution Comparison",
  element.color = "darkgray",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chart.Boxplot_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="chart.Boxplot_+3A_names">names</code></td>
<td>
<p>logical. if TRUE, show the names of each series</p>
</td></tr>
<tr><td><code id="chart.Boxplot_+3A_as.tufte">as.Tufte</code></td>
<td>
<p>logical. default FALSE. if TRUE use method derived for Tufte
for limiting chartjunk</p>
</td></tr>
<tr><td><code id="chart.Boxplot_+3A_plot.engine">plot.engine</code></td>
<td>
<p>choose the plot engine you wish to use:
ggplot2, plotly, googlevis and default</p>
</td></tr>
<tr><td><code id="chart.Boxplot_+3A_sort.by">sort.by</code></td>
<td>
<p>one of &quot;NULL&quot;, &quot;mean&quot;, &quot;median&quot;, &quot;variance&quot;</p>
</td></tr>
<tr><td><code id="chart.Boxplot_+3A_colorset">colorset</code></td>
<td>
<p>color palette to use, set by default to rational choices</p>
</td></tr>
<tr><td><code id="chart.Boxplot_+3A_symbol.color">symbol.color</code></td>
<td>
<p>draws the symbols described in
<code>mean.symbol</code>,<code>median.symbol</code>,<code>outlier.symbol</code> in the color
specified</p>
</td></tr>
<tr><td><code id="chart.Boxplot_+3A_mean.symbol">mean.symbol</code></td>
<td>
<p>symbol to use for the mean of the distribution</p>
</td></tr>
<tr><td><code id="chart.Boxplot_+3A_median.symbol">median.symbol</code></td>
<td>
<p>symbol to use for the median of the distribution</p>
</td></tr>
<tr><td><code id="chart.Boxplot_+3A_outlier.symbol">outlier.symbol</code></td>
<td>
<p>symbol to use for the outliers of the distribution</p>
</td></tr>
<tr><td><code id="chart.Boxplot_+3A_show.data">show.data</code></td>
<td>
<p>numerical vector of column numbers to display on top of
boxplot, default NULL</p>
</td></tr>
<tr><td><code id="chart.Boxplot_+3A_add.mean">add.mean</code></td>
<td>
<p>logical. if TRUE, show a line for the mean of all
distributions plotted</p>
</td></tr>
<tr><td><code id="chart.Boxplot_+3A_sort.ascending">sort.ascending</code></td>
<td>
<p>logical.  If TRUE sort the distributions by ascending
<code>sort.by</code></p>
</td></tr>
<tr><td><code id="chart.Boxplot_+3A_xlab">xlab</code></td>
<td>
<p>set the x-axis label, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.Boxplot_+3A_main">main</code></td>
<td>
<p>set the chart title, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.Boxplot_+3A_element.color">element.color</code></td>
<td>
<p>specify the color of chart elements.  Default is
&quot;darkgray&quot;</p>
</td></tr>
<tr><td><code id="chart.Boxplot_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We have also provided controls for all the symbols and lines in the chart.
One default, set by <code>as.Tufte=TRUE</code>, will strip chartjunk and draw a
Boxplot per recommendations by Edward Tufte. It can also be useful when
comparing several series to sort them in order of ascending or descending
&quot;mean&quot;, &quot;median&quot;, &quot;variance&quot; by use of <code>sort.by</code> and
<code>sort.ascending=TRUE</code>.
</p>


<h3>Value</h3>

<p>box plot of returns
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>Tufte, Edward R.  <em>The Visual Display of Quantitative
Information</em>. Graphics Press. 1983. p. 124-129
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+boxplot">boxplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)
chart.Boxplot(edhec)
chart.Boxplot(edhec,as.Tufte=TRUE)

</code></pre>

<hr>
<h2 id='chart.CaptureRatios'>Chart of Capture Ratios against a benchmark</h2><span id='topic+chart.CaptureRatios'></span>

<h3>Description</h3>

<p>Scatter plot of Up Capture versus Down Capture against a benchmark
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chart.CaptureRatios(
  Ra,
  Rb,
  main = "Capture Ratio",
  add.names = TRUE,
  xlab = "Downside Capture",
  ylab = "Upside Capture",
  colorset = 1,
  symbolset = 1,
  legend.loc = NULL,
  xlim = NULL,
  ylim = NULL,
  cex.legend = 1,
  cex.axis = 0.8,
  cex.main = 1,
  cex.lab = 1,
  element.color = "darkgray",
  benchmark.color = "darkgray",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chart.CaptureRatios_+3A_ra">Ra</code></td>
<td>
<p>Returns to test, e.g., the asset to be examined</p>
</td></tr>
<tr><td><code id="chart.CaptureRatios_+3A_rb">Rb</code></td>
<td>
<p>Returns of a benchmark to compare the asset with</p>
</td></tr>
<tr><td><code id="chart.CaptureRatios_+3A_main">main</code></td>
<td>
<p>Set the chart title, same as in <code>plot</code></p>
</td></tr>
<tr><td><code id="chart.CaptureRatios_+3A_add.names">add.names</code></td>
<td>
<p>Plots the row name with the data point.  Default TRUE. Can
be removed by setting it to NULL</p>
</td></tr>
<tr><td><code id="chart.CaptureRatios_+3A_xlab">xlab</code></td>
<td>
<p>Set the x-axis label, as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.CaptureRatios_+3A_ylab">ylab</code></td>
<td>
<p>Set the y-axis label, as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.CaptureRatios_+3A_colorset">colorset</code></td>
<td>
<p>Color palette to use, set by default to &quot;black&quot;</p>
</td></tr>
<tr><td><code id="chart.CaptureRatios_+3A_symbolset">symbolset</code></td>
<td>
<p>From <code>pch</code> in <code><a href="base.html#topic+plot">plot</a></code>. Submit a set of
symbols to be used in the same order as the data sets submitted</p>
</td></tr>
<tr><td><code id="chart.CaptureRatios_+3A_legend.loc">legend.loc</code></td>
<td>
<p>Places a legend into one of nine locations on the chart:
bottomright, bottom, bottomleft, left, topleft, top, topright, right, or
center.</p>
</td></tr>
<tr><td><code id="chart.CaptureRatios_+3A_xlim">xlim</code></td>
<td>
<p>set the x-axis limit, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.CaptureRatios_+3A_ylim">ylim</code></td>
<td>
<p>set the y-axis limit, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.CaptureRatios_+3A_cex.legend">cex.legend</code></td>
<td>
<p>The magnification to be used for sizing the legend
relative to the current setting of 'cex'.</p>
</td></tr>
<tr><td><code id="chart.CaptureRatios_+3A_cex.axis">cex.axis</code></td>
<td>
<p>The magnification to be used for axis annotation relative to
the current setting of 'cex', same as in <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
<tr><td><code id="chart.CaptureRatios_+3A_cex.main">cex.main</code></td>
<td>
<p>The magnification to be used for sizing the title relative
to the current setting of 'cex'.</p>
</td></tr>
<tr><td><code id="chart.CaptureRatios_+3A_cex.lab">cex.lab</code></td>
<td>
<p>The magnification to be used for x and y labels relative to
the current setting of 'cex'.</p>
</td></tr>
<tr><td><code id="chart.CaptureRatios_+3A_element.color">element.color</code></td>
<td>
<p>Specify the color of the box, axes, and other chart
elements.  Default is &quot;darkgray&quot;</p>
</td></tr>
<tr><td><code id="chart.CaptureRatios_+3A_benchmark.color">benchmark.color</code></td>
<td>
<p>Specify the color of the benchmark reference and
crosshairs.  Default is &quot;darkgray&quot;</p>
</td></tr>
<tr><td><code id="chart.CaptureRatios_+3A_...">...</code></td>
<td>
<p>Any other passthru parameters to <code>plot</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Scatter plot shows the coordinates of each set of returns' Up and Down
Capture against a benchmark.  The benchmark value is by definition plotted
at (1,1) with solid crosshairs.  A diagonal dashed line with slope equal to
1 divides the plot into two regions: above that line the UpCapture exceeds
the DownCapture, and vice versa.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+plot">plot</a></code>, <br /> <code><a href="graphics.html#topic+par">par</a></code>, <br />
<code><a href="#topic+UpDownRatios">UpDownRatios</a></code>, <br /> <code><a href="#topic+table.UpDownRatios">table.UpDownRatios</a></code> <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
    data(managers)
    chart.CaptureRatios(managers[,1:6], managers[,7,drop=FALSE])

</code></pre>

<hr>
<h2 id='chart.Correlation'>correlation matrix chart</h2><span id='topic+chart.Correlation'></span>

<h3>Description</h3>

<p>Visualization of a Correlation Matrix. On top the (absolute) value of the
correlation plus the result of the cor.test as stars. On bottom, the
bivariate scatterplots, with a fitted line
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chart.Correlation(
  R,
  histogram = TRUE,
  method = c("pearson", "kendall", "spearman"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chart.Correlation_+3A_r">R</code></td>
<td>
<p>data for the x axis, can take matrix,vector, or timeseries</p>
</td></tr>
<tr><td><code id="chart.Correlation_+3A_histogram">histogram</code></td>
<td>
<p>TRUE/FALSE whether or not to display a histogram</p>
</td></tr>
<tr><td><code id="chart.Correlation_+3A_method">method</code></td>
<td>
<p>a character string indicating which correlation coefficient
(or covariance) is to be computed.  One of &quot;pearson&quot;
(default), &quot;kendall&quot;, or &quot;spearman&quot;, can be abbreviated.</p>
</td></tr>
<tr><td><code id="chart.Correlation_+3A_...">...</code></td>
<td>
<p>any other passthru parameters into <code><a href="graphics.html#topic+pairs">pairs</a></code></p>
</td></tr>
</table>


<h3>Note</h3>

<p>based on plot at originally found at addictedtor.free.fr/graphiques/sources/source_137.R
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="#topic+table.Correlation">table.Correlation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
chart.Correlation(managers[,1:8], histogram=TRUE, pch="+")

</code></pre>

<hr>
<h2 id='chart.CumReturns'>Cumulates and graphs a set of periodic returns</h2><span id='topic+chart.CumReturns'></span>

<h3>Description</h3>

<p>Chart that cumulates the periodic returns given and draws a line graph of
the results as a &quot;wealth index&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chart.CumReturns(
  R,
  wealth.index = FALSE,
  geometric = TRUE,
  legend.loc = NULL,
  colorset = (1:12),
  begin = c("first", "axis"),
  plot.engine = "default",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chart.CumReturns_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="chart.CumReturns_+3A_wealth.index">wealth.index</code></td>
<td>
<p>if <code>wealth.index</code> is <code>TRUE</code>, shows the &quot;value
of $1&quot;, starting the cumulation of returns at 1 rather than zero</p>
</td></tr>
<tr><td><code id="chart.CumReturns_+3A_geometric">geometric</code></td>
<td>
<p>utilize geometric chaining (TRUE) or simple/arithmetic chaining (FALSE) to aggregate returns,
default TRUE</p>
</td></tr>
<tr><td><code id="chart.CumReturns_+3A_legend.loc">legend.loc</code></td>
<td>
<p>places a legend into one of nine locations on the chart:
bottomright, bottom, bottomleft, left, topleft, top, topright, right, or
center.</p>
</td></tr>
<tr><td><code id="chart.CumReturns_+3A_colorset">colorset</code></td>
<td>
<p>color palette to use, set by default to rational choices</p>
</td></tr>
<tr><td><code id="chart.CumReturns_+3A_begin">begin</code></td>
<td>
<p>Align shorter series to: </p>
 <ul>
<li><p> first - prior value of
the first column given for the reference or longer series or, </p>
</li>
<li><p> axis -
the initial value (1 or zero) of the axis.  </p>
</li></ul>
</td></tr>
<tr><td><code id="chart.CumReturns_+3A_plot.engine">plot.engine</code></td>
<td>
<p>choose the plot engine you wish to use&quot;
ggplot2, plotly,dygraph,googlevis and default</p>
</td></tr>
<tr><td><code id="chart.CumReturns_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Cumulates the return series and displays either as a wealth index or as
cumulative returns.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>Bacon, Carl. <em>Practical Portfolio Performance Measurement
and Attribution</em>. Wiley. 2004. <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chart.TimeSeries">chart.TimeSeries</a></code> <br /> <code><a href="base.html#topic+plot">plot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)
chart.CumReturns(edhec[,"Funds of Funds"],main="Cumulative Returns")
chart.CumReturns(edhec[,"Funds of Funds"],wealth.index=TRUE, main="Growth of $1")
data(managers)
chart.CumReturns(managers,main="Cumulative Returns",begin="first")
chart.CumReturns(managers,main="Cumulative Returns",begin="axis")

</code></pre>

<hr>
<h2 id='chart.Drawdown'>Time series chart of drawdowns through time</h2><span id='topic+chart.Drawdown'></span>

<h3>Description</h3>

<p>A time series chart demonstrating drawdowns from peak equity attained
through time, calculated from periodic returns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chart.Drawdown(
  R,
  geometric = TRUE,
  legend.loc = NULL,
  colorset = (1:12),
  plot.engine = "default",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chart.Drawdown_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="chart.Drawdown_+3A_geometric">geometric</code></td>
<td>
<p>utilize geometric chaining (TRUE) or simple/arithmetic chaining (FALSE) to aggregate returns,
default TRUE</p>
</td></tr>
<tr><td><code id="chart.Drawdown_+3A_legend.loc">legend.loc</code></td>
<td>
<p>places a legend into one of nine locations on the chart:
bottomright, bottom, bottomleft, left, topleft, top, topright, right, or
center.</p>
</td></tr>
<tr><td><code id="chart.Drawdown_+3A_colorset">colorset</code></td>
<td>
<p>color palette to use, set by default to rational choices</p>
</td></tr>
<tr><td><code id="chart.Drawdown_+3A_plot.engine">plot.engine</code></td>
<td>
<p>choose the plot engine you wish to use:
ggplot2, plotly,dygraph,googlevis and default</p>
</td></tr>
<tr><td><code id="chart.Drawdown_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Any time the cumulative returns dips below the maximum cumulative returns,
it's a drawdown.  Drawdowns are measured as a percentage of that maximum
cumulative return, in effect, measured from peak equity.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>Bacon, C. <em>Practical Portfolio Performance Measurement and
Attribution</em>. Wiley. 2004. p. 88 <br />
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+plot">plot</a></code> <br /> 
<code><a href="#topic+chart.TimeSeries">chart.TimeSeries</a></code> <br />
<code><a href="#topic+findDrawdowns">findDrawdowns</a></code> <br /> 
<code><a href="#topic+sortDrawdowns">sortDrawdowns</a></code> <br />
<code><a href="#topic+maxDrawdown">maxDrawdown</a></code> <br /> 
<code><a href="#topic+table.Drawdowns">table.Drawdowns</a></code> <br />
<code><a href="#topic+table.DownsideRisk">table.DownsideRisk</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)
chart.Drawdown(edhec[,c(1,2)], 
		main="Drawdown from Peak Equity Attained", 
		legend.loc="bottomleft")
</code></pre>

<hr>
<h2 id='chart.ECDF'>Create an ECDF overlaid with a Normal CDF</h2><span id='topic+chart.ECDF'></span>

<h3>Description</h3>

<p>Creates an emperical cumulative distribution function (ECDF) overlaid with a
cumulative distribution function (CDF)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chart.ECDF(
  R,
  main = "Empirical CDF",
  xlab = "x",
  ylab = "F(x)",
  colorset = c("black", "#005AFF"),
  lwd = 1,
  lty = c(1, 1),
  element.color = "darkgray",
  xaxis = TRUE,
  yaxis = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chart.ECDF_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="chart.ECDF_+3A_main">main</code></td>
<td>
<p>set the chart title, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.ECDF_+3A_xlab">xlab</code></td>
<td>
<p>set the x-axis label, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.ECDF_+3A_ylab">ylab</code></td>
<td>
<p>set the y-axis label, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.ECDF_+3A_colorset">colorset</code></td>
<td>
<p>color palette to use, defaults to c(&quot;black&quot;, &quot;\#005AFF&quot;),
where first value is used to color the step function and the second color is
used for the fitted normal</p>
</td></tr>
<tr><td><code id="chart.ECDF_+3A_lwd">lwd</code></td>
<td>
<p>set the line width, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.ECDF_+3A_lty">lty</code></td>
<td>
<p>set the line type, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.ECDF_+3A_element.color">element.color</code></td>
<td>
<p>specify the color of chart elements.  Default is
&quot;darkgray&quot;</p>
</td></tr>
<tr><td><code id="chart.ECDF_+3A_xaxis">xaxis</code></td>
<td>
<p>if true, draws the x axis</p>
</td></tr>
<tr><td><code id="chart.ECDF_+3A_yaxis">yaxis</code></td>
<td>
<p>if true, draws the y axis</p>
</td></tr>
<tr><td><code id="chart.ECDF_+3A_...">...</code></td>
<td>
<p>any other passthru parameters to <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The empirical cumulative distribution function (ECDF for short) calculates
the fraction of observations less or equal to a given value.  The resulting
plot is a step function of that fraction at each observation.  This function
uses <code>ecdf</code> and overlays the CDF for a fitted normal function as well.
Inspired by a chart in Ruppert (2004).
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>Ruppert, David. <em>Statistics and Finance, an Introduction</em>.
Springer. 2004. Ch. 2 Fig. 2.5
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+plot">plot</a></code>, <code><a href="stats.html#topic+ecdf">ecdf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)
chart.ECDF(edhec[, 1, drop=FALSE])


</code></pre>

<hr>
<h2 id='chart.Events'>Plots a time series with event dates aligned</h2><span id='topic+chart.Events'></span>

<h3>Description</h3>

<p>Creates a time series plot where events given by a set of dates are aligned,
with the adjacent prior and posterior time series data plotted in order.
The x-axis is time, but relative to the date specified, e.g., number of
months preceeding or following the events.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chart.Events(R, dates, prior = 12, post = 12, main = NULL, xlab = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chart.Events_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="chart.Events_+3A_dates">dates</code></td>
<td>
<p>a list of dates (e.g., <code>c("09/03","05/06"))</code> formatted the
same as in R.  This function matches the re-formatted row or index names
(dates) with the given list, so to get a match the formatting needs to be
correct.</p>
</td></tr>
<tr><td><code id="chart.Events_+3A_prior">prior</code></td>
<td>
<p>the number of periods to plot prior to the event.  Interpreted
as a positive number.</p>
</td></tr>
<tr><td><code id="chart.Events_+3A_post">post</code></td>
<td>
<p>the number of periods to plot following to the event.
Interpreted as a positive number.</p>
</td></tr>
<tr><td><code id="chart.Events_+3A_main">main</code></td>
<td>
<p>set the chart title, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.Events_+3A_xlab">xlab</code></td>
<td>
<p>set the x-axis label, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.Events_+3A_...">...</code></td>
<td>
<p>any other passthru parameters to the <code><a href="base.html#topic+plot">plot</a></code>
function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a chart that is commonly used for event studies in econometrics,
usually with recession dates, to demonstrate the path of a time series going
into and coming out of an event.  The time axis is simply the number of
periods prior and following the event, and each line represents a different
event.  Note that if time periods are close enough together and the window
shown is wide enough, the data will appear to repeat.  That can be
confusing, but the function does not currently allow for different windows
around each event.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chart.TimeSeries">chart.TimeSeries</a></code>, <br /> <code><a href="base.html#topic+plot">plot</a></code>, <br />
<code><a href="graphics.html#topic+par">par</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(managers)
n = table.Drawdowns(managers[,2,drop=FALSE])                          
chart.Events(Drawdowns(managers[,2,drop=FALSE]), 
		dates = n$Trough, 
		prior=max(na.omit(n$"To Trough")), 
		post=max(na.omit(n$Recovery)), 
		lwd=2, colorset=redfocus, legend.loc=NULL, 
		main = "Worst Drawdowns")

## End(Not run)
</code></pre>

<hr>
<h2 id='chart.Histogram'>histogram of returns</h2><span id='topic+chart.Histogram'></span>

<h3>Description</h3>

<p>Create a histogram of returns, with optional curve fits for density and
normal.  This is a wrapper function for <code><a href="graphics.html#topic+hist">hist</a></code>, see
the help for that function for additional arguments you may wish to pass in.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chart.Histogram(
  R,
  breaks = "FD",
  main = NULL,
  xlab = "Returns",
  ylab = "Frequency",
  methods = c("none", "add.density", "add.normal", "add.centered", "add.cauchy",
    "add.sst", "add.rug", "add.risk", "add.qqplot"),
  show.outliers = TRUE,
  colorset = c("lightgray", "#00008F", "#005AFF", "#23FFDC", "#ECFF13", "#FF4A00",
    "#800000"),
  border.col = "white",
  lwd = 2,
  xlim = NULL,
  ylim = NULL,
  element.color = "darkgray",
  note.lines = NULL,
  note.labels = NULL,
  note.cex = 0.7,
  note.color = "darkgray",
  probability = FALSE,
  p = 0.95,
  cex.axis = 0.8,
  cex.legend = 0.8,
  cex.lab = 1,
  cex.main = 1,
  xaxis = TRUE,
  yaxis = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chart.Histogram_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_breaks">breaks</code></td>
<td>
<p>one of: 
</p>
 
<ul>
<li><p> a vector giving the breakpoints between histogram cells, 
</p>
</li>
<li><p> a single number giving the number of cells for the histogram, 
</p>
</li>
<li><p> a character string naming an algorithm to compute the number of cells (see &lsquo;Details&rsquo;), 
</p>
</li>
<li><p> a function to compute the number of cells.  
</p>
</li></ul>
 
<p>For the last three the number is a suggestion only.
see <code><a href="graphics.html#topic+hist">hist</a></code> for details, default &quot;FD&quot;</p>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_main">main</code></td>
<td>
<p>set the chart title, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_xlab">xlab</code></td>
<td>
<p>set the x-axis label, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_ylab">ylab</code></td>
<td>
<p>set the y-axis label, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_methods">methods</code></td>
<td>
<p>what to graph, one or more of: 
</p>
 
<ul>
<li><p> add.density to display the density plot 
</p>
</li>
<li><p> add.normal  to display a fitted normal distibution line over the mean 
</p>
</li>
<li><p> add.centered to display a fitted normal line over zero 
</p>
</li>
<li><p> add.rug to display a rug of the observations
</p>
</li>
<li><p> add.risk to display common risk metrics 
</p>
</li>
<li><p> add.qqplot to display a small qqplot in the upper corner of the histogram plot 
</p>
</li></ul>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_show.outliers">show.outliers</code></td>
<td>
<p>logical; if TRUE (the default), the histogram will show
all of the data points.  If FALSE, it will show only the first through the
fourth quartile and will exclude outliers.</p>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_colorset">colorset</code></td>
<td>
<p>color palette to use, set by default to rational choices</p>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_border.col">border.col</code></td>
<td>
<p>color to use for the border</p>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_lwd">lwd</code></td>
<td>
<p>set the line width, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_xlim">xlim</code></td>
<td>
<p>set the x-axis limit, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_ylim">ylim</code></td>
<td>
<p>set the y-axis limits, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_element.color">element.color</code></td>
<td>
<p>provides the color for drawing chart elements, such as
the box lines, axis lines, etc. Default is &quot;darkgray&quot;</p>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_note.lines">note.lines</code></td>
<td>
<p>draws a vertical line through the value given.</p>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_note.labels">note.labels</code></td>
<td>
<p>adds a text label to vertical lines specified for
note.lines.</p>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_note.cex">note.cex</code></td>
<td>
<p>The magnification to be used for note line labels relative
to the current setting of 'cex'.</p>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_note.color">note.color</code></td>
<td>
<p>specifies the color(s) of the vertical lines drawn.</p>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_probability">probability</code></td>
<td>
<p>logical; if TRUE, the histogram graphic is a
representation of frequencies, the counts component of the result; if FALSE,
probability densities, component density, are plotted (so that the histogram
has a total area of one). Defaults to TRUE if and only if breaks are
equidistant (and probability is not specified). see
<code><a href="graphics.html#topic+hist">hist</a></code></p>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_p">p</code></td>
<td>
<p>confidence level for calculation, default p=.99</p>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_cex.axis">cex.axis</code></td>
<td>
<p>The magnification to be used for axis annotation relative to
the current setting of 'cex', same as in <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_cex.legend">cex.legend</code></td>
<td>
<p>The magnification to be used for sizing the legend
relative to the current setting of 'cex'.</p>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_cex.lab">cex.lab</code></td>
<td>
<p>The magnification to be used for x- and y-axis labels
relative to the current setting of 'cex'.</p>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_cex.main">cex.main</code></td>
<td>
<p>The magnification to be used for the main title relative to
the current setting of 'cex'.</p>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_xaxis">xaxis</code></td>
<td>
<p>if true, draws the x axis</p>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_yaxis">yaxis</code></td>
<td>
<p>if true, draws the y axis</p>
</td></tr>
<tr><td><code id="chart.Histogram_+3A_...">...</code></td>
<td>
<p>any other passthru parameters to <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default for <code>breaks</code> is <code>"FD"</code>. Other names for which
algorithms are supplied are <code>"Sturges"</code> (see
<code><a href="grDevices.html#topic+nclass.Sturges">nclass.Sturges</a></code>), <code>"Scott"</code>, and <code>"FD"</code> /
<code>"Freedman-Diaconis"</code> (with corresponding functions
<code><a href="grDevices.html#topic+nclass.scott">nclass.scott</a></code> and <code><a href="grDevices.html#topic+nclass.FD">nclass.FD</a></code>).  Case is ignored
and partial matching is used.  Alternatively, a function can be supplied
which will compute the intended number of breaks as a function of <code>R</code>.
</p>


<h3>Note</h3>

<p>Code inspired by a chart on: <br />
<a href="http://zoonek2.free.fr/UNIX/48_R/03.html">http://zoonek2.free.fr/UNIX/48_R/03.html</a>
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+hist">hist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
    data(edhec)
    chart.Histogram(edhec[,'Equity Market Neutral',drop=FALSE])

    # version with more breaks and the 
	   # standard close fit density distribution
    chart.Histogram(edhec[,'Equity Market Neutral',drop=FALSE], 
			breaks=40, methods = c("add.density", "add.rug") )

    chart.Histogram(edhec[,'Equity Market Neutral',drop=FALSE], 
			methods = c( "add.density", "add.normal") )

    # version with just the histogram and 
    # normal distribution centered on 0
    chart.Histogram(edhec[,'Equity Market Neutral',drop=FALSE], 
			methods = c( "add.density", "add.centered") )

    # add a rug to the previous plot 
	   # for more granularity on precisely where the distribution fell
    chart.Histogram(edhec[,'Equity Market Neutral',drop=FALSE], 
			methods = c( "add.centered", "add.density", "add.rug") )

    # now show a qqplot to give us another view 
    # on how normal the data are
    chart.Histogram(edhec[,'Equity Market Neutral',drop=FALSE], 
			methods = c("add.centered","add.density","add.rug","add.qqplot"))

    # add risk measure(s) to show where those are 
	   # in relation to observed returns
    chart.Histogram(edhec[,'Equity Market Neutral',drop=FALSE], 
			methods = c("add.density","add.centered","add.rug","add.risk"))

</code></pre>

<hr>
<h2 id='chart.QQPlot'>Plot a QQ chart</h2><span id='topic+chart.QQPlot'></span>

<h3>Description</h3>

<p>Plot the return data against any theoretical distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chart.QQPlot(
  R,
  distribution = "norm",
  ylab = NULL,
  xlab = paste(distribution, "Quantiles"),
  main = NULL,
  las = par("las"),
  envelope = FALSE,
  labels = FALSE,
  col = c(1, 4),
  lwd = 2,
  pch = 1,
  cex = 1,
  line = c("quartiles", "robust", "none"),
  element.color = "darkgray",
  cex.axis = 0.8,
  cex.legend = 0.8,
  cex.lab = 1,
  cex.main = 1,
  xaxis = TRUE,
  yaxis = TRUE,
  ylim = NULL,
  distributionParameter = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chart.QQPlot_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="chart.QQPlot_+3A_distribution">distribution</code></td>
<td>
<p>root name of comparison distribution - e.g., 'norm' for
the normal distribution; 't' for the t-distribution. See examples for other
ideas.</p>
</td></tr>
<tr><td><code id="chart.QQPlot_+3A_ylab">ylab</code></td>
<td>
<p>set the y-axis label, as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.QQPlot_+3A_xlab">xlab</code></td>
<td>
<p>set the x-axis label, as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.QQPlot_+3A_main">main</code></td>
<td>
<p>set the chart title, same as in <code>plot</code></p>
</td></tr>
<tr><td><code id="chart.QQPlot_+3A_las">las</code></td>
<td>
<p>set the direction of axis labels, same as in <code>plot</code></p>
</td></tr>
<tr><td><code id="chart.QQPlot_+3A_envelope">envelope</code></td>
<td>
<p>confidence level for point-wise confidence envelope, or
FALSE for no envelope.</p>
</td></tr>
<tr><td><code id="chart.QQPlot_+3A_labels">labels</code></td>
<td>
<p>vector of point labels for interactive point identification,
or FALSE for no labels.</p>
</td></tr>
<tr><td><code id="chart.QQPlot_+3A_col">col</code></td>
<td>
<p>color for points and lines; the default is the <em>second</em>
entry in the current color palette (see 'palette' and 'par').</p>
</td></tr>
<tr><td><code id="chart.QQPlot_+3A_lwd">lwd</code></td>
<td>
<p>set the line width, as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.QQPlot_+3A_pch">pch</code></td>
<td>
<p>symbols to use, see also <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.QQPlot_+3A_cex">cex</code></td>
<td>
<p>symbols to use, see also <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.QQPlot_+3A_line">line</code></td>
<td>
<p>'quartiles' to pass a line through the quartile-pairs, or
'robust' for a robust-regression line; the latter uses the 'rlm' function
in the 'MASS' package. Specifying 'line = &quot;none&quot;' suppresses the line.</p>
</td></tr>
<tr><td><code id="chart.QQPlot_+3A_element.color">element.color</code></td>
<td>
<p>provides the color for drawing chart elements, such as
the box lines, axis lines, etc. Default is &quot;darkgray&quot;</p>
</td></tr>
<tr><td><code id="chart.QQPlot_+3A_cex.axis">cex.axis</code></td>
<td>
<p>The magnification to be used for axis annotation relative to
the current setting of 'cex'</p>
</td></tr>
<tr><td><code id="chart.QQPlot_+3A_cex.legend">cex.legend</code></td>
<td>
<p>The magnification to be used for sizing the legend
relative to the current setting of 'cex'</p>
</td></tr>
<tr><td><code id="chart.QQPlot_+3A_cex.lab">cex.lab</code></td>
<td>
<p>The magnification to be used for x- and y-axis labels
relative to the current setting of 'cex'</p>
</td></tr>
<tr><td><code id="chart.QQPlot_+3A_cex.main">cex.main</code></td>
<td>
<p>The magnification to be used for the main title relative to
the current setting of 'cex'.</p>
</td></tr>
<tr><td><code id="chart.QQPlot_+3A_xaxis">xaxis</code></td>
<td>
<p>if true, draws the x axis</p>
</td></tr>
<tr><td><code id="chart.QQPlot_+3A_yaxis">yaxis</code></td>
<td>
<p>if true, draws the y axis</p>
</td></tr>
<tr><td><code id="chart.QQPlot_+3A_ylim">ylim</code></td>
<td>
<p>set the y-axis limits, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.QQPlot_+3A_distributionparameter">distributionParameter</code></td>
<td>
<p>a string of the parameters of the distribution
e.g., distributionParameter = 'location = 1, scale = 2, shape = 3, df = 4' 
for skew-T distribution</p>
</td></tr>
<tr><td><code id="chart.QQPlot_+3A_...">...</code></td>
<td>
<p>any other passthru parameters to the distribution function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A Quantile-Quantile (QQ) plot is a scatter plot designed to compare the data
to the theoretical distributions to visually determine if the observations
are likely to have come from a known population. The empirical quantiles are
plotted to the y-axis, and the x-axis contains the values of the theorical
model.  A 45-degree reference line is also plotted. If the empirical data
come from the population with the choosen distribution, the points should
fall approximately along this reference line. The larger the departure from
the reference line, the greater the evidence that the data set have come
from a population with a different distribution.
</p>


<h3>Author(s)</h3>

<p>John Fox, ported by Peter Carl
</p>


<h3>References</h3>

<p>main code forked/borrowed/ported from the excellent: <br /> Fox,
John (2007) <em>car: Companion to Applied Regression</em> <br />
<a href="http://socserv.socsci.mcmaster.ca/jfox/">http://socserv.socsci.mcmaster.ca/jfox/</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+qqplot">qqplot</a></code> <br /> 
<code><a href="car.html#topic+qq.plot">qq.plot</a></code> <br />
<code><a href="base.html#topic+plot">plot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS) 
library(PerformanceAnalytics)
data(managers)
x = checkData(managers[,2, drop = FALSE], na.rm = TRUE, method = "vector")

# Panel 1: Normal distribution
chart.QQPlot(x, main = "Normal Distribution",
		line=c("quartiles"), distribution = 'norm',  
		envelope=0.95)


# Panel 2, Log-Normal distribution
fit = fitdistr(1+x, 'lognormal')
chart.QQPlot(1+x, main = "Log-Normal Distribution", envelope=0.95, 
    distribution='lnorm',distributionParameter='meanlog = fit$estimate[[1]], 
    sdlog = fit$estimate[[2]]')


## Not run:  
# Panel 3: Mixture Normal distribution
library(nor1mix)
obj = norMixEM(x,m=2)
chart.QQPlot(x, main = "Normal Mixture Distribution",
		line=c("quartiles"), distribution = 'norMix',  distributionParameter='obj',
		envelope=0.95)


# Panel 4: Symmetric t distribution
library(sn)
n = length(x)
fit.tSN = st.mple(as.matrix(rep(1,n)),x,symmetr = TRUE)
names(fit.tSN$dp) = c("location","scale","dof")
round(fit.tSN$dp,3)

chart.QQPlot(x, main = "MO Symmetric t-Distribution QQPlot",
		xlab = "quantilesSymmetricTdistEst",line = c("quartiles"),
		envelope = .95, distribution = 't', 
		distributionParameter='df=fit.tSN$dp[3]',pch = 20)

# Panel 5: Skewed t distribution
fit.st = st.mple(as.matrix(rep(1,n)),x)
# fit.st = st.mple(y=x)  Produces same result as line above
names(fit.st$dp) = c("location","scale","skew","dof")
round(fit.st$dp,3)

chart.QQPlot(x, main = "MO Returns Skewed t-Distribution QQPlot",
		xlab = "quantilesSkewedTdistEst",line = c("quartiles"),
		envelope = .95, distribution = 'st',
		distributionParameter = 'xi = fit.st$dp[1],
				omega = fit.st$dp[2],alpha = fit.st$dp[3],
				nu=fit.st$dp[4]',
		pch = 20)

# Panel 6: Stable Parietian
library(fBasics)
fit.stable = stableFit(x,doplot=FALSE)
chart.QQPlot(x, main = "Stable Paretian Distribution", envelope=0.95, 
             distribution = 'stable', 
             distributionParameter = 'alpha = fit(stable.fit)$estimate[[1]], 
                 beta = fit(stable.fit)$estimate[[2]], 
                 gamma = fit(stable.fit)$estimate[[3]], 
                 delta = fit(stable.fit)$estimate[[4]], pm = 0')

## End(Not run)

#end examples

</code></pre>

<hr>
<h2 id='chart.Regression'>Takes a set of returns and relates them to a market benchmark in a
scatterplot</h2><span id='topic+chart.Regression'></span>

<h3>Description</h3>

<p>Uses a scatterplot to display the relationship of a set of returns to a
market benchmark.  Fits a linear model and overlays the resulting model.
Also overlays a Loess line for comparison.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chart.Regression(
  Ra,
  Rb,
  Rf = 0,
  excess.returns = FALSE,
  reference.grid = TRUE,
  main = "Title",
  ylab = NULL,
  xlab = NULL,
  xlim = NA,
  colorset = 1:12,
  symbolset = 1:12,
  element.color = "darkgray",
  legend.loc = NULL,
  ylog = FALSE,
  fit = c("loess", "linear", "conditional", "quadratic"),
  span = 2/3,
  degree = 1,
  family = c("symmetric", "gaussian"),
  ylim = NA,
  evaluation = 50,
  legend.cex = 0.8,
  cex = 0.8,
  lwd = 2,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chart.Regression_+3A_ra">Ra</code></td>
<td>
<p>a vector of returns to test, e.g., the asset to be examined</p>
</td></tr>
<tr><td><code id="chart.Regression_+3A_rb">Rb</code></td>
<td>
<p>a matrix, data.frame, or timeSeries of benchmark(s) to test the
asset against</p>
</td></tr>
<tr><td><code id="chart.Regression_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as the returns</p>
</td></tr>
<tr><td><code id="chart.Regression_+3A_excess.returns">excess.returns</code></td>
<td>
<p>logical; should excess returns be used?</p>
</td></tr>
<tr><td><code id="chart.Regression_+3A_reference.grid">reference.grid</code></td>
<td>
<p>if true, draws a grid aligned with the points on the x
and y axes</p>
</td></tr>
<tr><td><code id="chart.Regression_+3A_main">main</code></td>
<td>
<p>set the chart title, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.Regression_+3A_ylab">ylab</code></td>
<td>
<p>set the y-axis title, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.Regression_+3A_xlab">xlab</code></td>
<td>
<p>set the x-axis title, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.Regression_+3A_xlim">xlim</code></td>
<td>
<p>set the x-axis limit, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.Regression_+3A_colorset">colorset</code></td>
<td>
<p>color palette to use</p>
</td></tr>
<tr><td><code id="chart.Regression_+3A_symbolset">symbolset</code></td>
<td>
<p>symbols to use, see also 'pch' in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.Regression_+3A_element.color">element.color</code></td>
<td>
<p>provides the color for drawing chart elements, such as
the box lines, axis lines, etc. Default is &quot;darkgray&quot;</p>
</td></tr>
<tr><td><code id="chart.Regression_+3A_legend.loc">legend.loc</code></td>
<td>
<p>places a legend into one of nine locations on the chart:
bottomright, bottom, bottomleft, left, topleft, top, topright, right, or
center.</p>
</td></tr>
<tr><td><code id="chart.Regression_+3A_ylog">ylog</code></td>
<td>
<p>Not used</p>
</td></tr>
<tr><td><code id="chart.Regression_+3A_fit">fit</code></td>
<td>
<p>for values of &quot;loess&quot;, &quot;linear&quot;, or &quot;conditional&quot;, plots a line
to fit the data.  Conditional lines are drawn separately for positive and
negative benchmark returns.  &quot;Quadratic&quot; is not yet implemented.</p>
</td></tr>
<tr><td><code id="chart.Regression_+3A_span">span</code></td>
<td>
<p>passed to loess line fit, as in <code><a href="stats.html#topic+loess.smooth">loess.smooth</a></code></p>
</td></tr>
<tr><td><code id="chart.Regression_+3A_degree">degree</code></td>
<td>
<p>passed to loess line fit, as in <code><a href="stats.html#topic+loess.smooth">loess.smooth</a></code></p>
</td></tr>
<tr><td><code id="chart.Regression_+3A_family">family</code></td>
<td>
<p>passed to loess line fit, as in <code><a href="stats.html#topic+loess.smooth">loess.smooth</a></code></p>
</td></tr>
<tr><td><code id="chart.Regression_+3A_ylim">ylim</code></td>
<td>
<p>set the y-axis limit, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.Regression_+3A_evaluation">evaluation</code></td>
<td>
<p>passed to loess line fit, as in <code><a href="stats.html#topic+loess.smooth">loess.smooth</a></code></p>
</td></tr>
<tr><td><code id="chart.Regression_+3A_legend.cex">legend.cex</code></td>
<td>
<p>set the legend size</p>
</td></tr>
<tr><td><code id="chart.Regression_+3A_cex">cex</code></td>
<td>
<p>set the cex size, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.Regression_+3A_lwd">lwd</code></td>
<td>
<p>set the line width for fits, same as in <code><a href="graphics.html#topic+lines">lines</a></code></p>
</td></tr>
<tr><td><code id="chart.Regression_+3A_...">...</code></td>
<td>
<p>any other passthru parameters to <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>Chapter 7 of Ruppert(2004) gives an extensive overview of CAPM,
its assumptions and deficiencies.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+plot">plot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
chart.Regression(managers[, 1:2, drop = FALSE], 
		managers[, 8, drop = FALSE], 
		Rf = managers[, 10, drop = FALSE], 
		excess.returns = TRUE, fit = c("loess", "linear"), 
		legend.loc = "topleft")

</code></pre>

<hr>
<h2 id='chart.RelativePerformance'>relative performance chart between multiple return series</h2><span id='topic+chart.RelativePerformance'></span>

<h3>Description</h3>

<p>Plots a time series chart that shows the ratio of the cumulative performance
for two assets at each point in time and makes periods of under- or
out-performance easier to see.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chart.RelativePerformance(
  Ra,
  Rb,
  main = "Relative Performance",
  xaxis = TRUE,
  colorset = (1:12),
  legend.loc = NULL,
  ylog = FALSE,
  elementcolor = "darkgray",
  lty = 1,
  cex.legend = 0.7,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chart.RelativePerformance_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="chart.RelativePerformance_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="chart.RelativePerformance_+3A_main">main</code></td>
<td>
<p>set the chart title, same as in <code>plot</code></p>
</td></tr>
<tr><td><code id="chart.RelativePerformance_+3A_xaxis">xaxis</code></td>
<td>
<p>if true, draws the x axis</p>
</td></tr>
<tr><td><code id="chart.RelativePerformance_+3A_colorset">colorset</code></td>
<td>
<p>color palette to use, set by default to rational choices</p>
</td></tr>
<tr><td><code id="chart.RelativePerformance_+3A_legend.loc">legend.loc</code></td>
<td>
<p>places a legend into one of nine locations on the chart:
bottomright, bottom, bottomleft, left, topleft, top, topright, right, or
center.</p>
</td></tr>
<tr><td><code id="chart.RelativePerformance_+3A_ylog">ylog</code></td>
<td>
<p>TRUE/FALSE set the y-axis to logarithmic scale, similar to
<code><a href="base.html#topic+plot">plot</a></code>, default FALSE</p>
</td></tr>
<tr><td><code id="chart.RelativePerformance_+3A_elementcolor">elementcolor</code></td>
<td>
<p>provides the color for drawing less-important chart
elements, such as the box lines, axis lines, etc. replaces <code>darken</code></p>
</td></tr>
<tr><td><code id="chart.RelativePerformance_+3A_lty">lty</code></td>
<td>
<p>set the line type, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.RelativePerformance_+3A_cex.legend">cex.legend</code></td>
<td>
<p>the magnification to be used for sizing the legend
relative to the current setting of 'cex'.</p>
</td></tr>
<tr><td><code id="chart.RelativePerformance_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To show under- and out-performance through different periods of time, a time
series view is more helpful. The value of the chart is less important than
the slope of the line. If the slope is positive, the first asset (numerator)
is outperforming the second, and vice versa. May be used to look at the
returns of a fund relative to each member of the peer group and the peer
group index. Alternatively, it might be used to assess the peers
individually against an asset class or peer group index.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Return.relative">Return.relative</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
chart.RelativePerformance(managers[, 1:6, drop=FALSE], 
		managers[, 8, drop=FALSE], 
		colorset=rich8equal, legend.loc="bottomright", 
		main="Relative Performance to S&amp;P")

</code></pre>

<hr>
<h2 id='chart.RiskReturnScatter'>scatter chart of returns vs risk for comparing multiple instruments</h2><span id='topic+chart.RiskReturnScatter'></span>

<h3>Description</h3>

<p>A wrapper to create a scatter chart of annualized returns versus annualized
risk (standard deviation) for comparing manager performance. Also puts a box
plot into the margins to help identify the relative performance quartile.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chart.RiskReturnScatter(
  R,
  Rf = 0,
  main = "Annualized Return and Risk",
  add.names = TRUE,
  xlab = "Annualized Risk",
  ylab = "Annualized Return",
  method = "calc",
  geometric = TRUE,
  scale = NA,
  add.sharpe = c(1, 2, 3),
  add.boxplots = FALSE,
  colorset = 1,
  symbolset = 1,
  element.color = "darkgray",
  legend.loc = NULL,
  xlim = NULL,
  ylim = NULL,
  cex.legend = 1,
  cex.axis = 0.8,
  cex.main = 1,
  cex.lab = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chart.RiskReturnScatter_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="chart.RiskReturnScatter_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="chart.RiskReturnScatter_+3A_main">main</code></td>
<td>
<p>set the chart title, same as in <code>plot</code></p>
</td></tr>
<tr><td><code id="chart.RiskReturnScatter_+3A_add.names">add.names</code></td>
<td>
<p>plots the row name with the data point.  default TRUE. Can
be removed by setting it to NULL</p>
</td></tr>
<tr><td><code id="chart.RiskReturnScatter_+3A_xlab">xlab</code></td>
<td>
<p>set the x-axis label, as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.RiskReturnScatter_+3A_ylab">ylab</code></td>
<td>
<p>set the y-axis label, as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.RiskReturnScatter_+3A_method">method</code></td>
<td>
<p>if set as &quot;calc&quot;, then the function will calculate values from
the set of returns passed in.  If method is set to &quot;nocalc&quot; then we assume
that R is a column of return and a column of risk (e.g., annualized returns,
annualized risk), in that order.  Other method cases may be set for
different risk/return calculations.</p>
</td></tr>
<tr><td><code id="chart.RiskReturnScatter_+3A_geometric">geometric</code></td>
<td>
<p>utilize geometric chaining (TRUE) or simple/arithmetic chaining (FALSE) to aggregate returns,
default TRUE</p>
</td></tr>
<tr><td><code id="chart.RiskReturnScatter_+3A_scale">scale</code></td>
<td>
<p>number of periods in a year (daily scale = 252, monthly scale =
12, quarterly scale = 4)</p>
</td></tr>
<tr><td><code id="chart.RiskReturnScatter_+3A_add.sharpe">add.sharpe</code></td>
<td>
<p>this draws a Sharpe ratio line that indicates Sharpe ratio
levels of <code>c(1,2,3)</code>.  Lines are drawn with a y-intercept of the risk
free rate and the slope of the appropriate Sharpe ratio level.  Lines should
be removed where not appropriate (e.g., sharpe.ratio = NULL).</p>
</td></tr>
<tr><td><code id="chart.RiskReturnScatter_+3A_add.boxplots">add.boxplots</code></td>
<td>
<p>TRUE/FALSE adds a boxplot summary of the data on the
axis</p>
</td></tr>
<tr><td><code id="chart.RiskReturnScatter_+3A_colorset">colorset</code></td>
<td>
<p>color palette to use, set by default to rational choices</p>
</td></tr>
<tr><td><code id="chart.RiskReturnScatter_+3A_symbolset">symbolset</code></td>
<td>
<p>from <code>pch</code> in <code><a href="base.html#topic+plot">plot</a></code>, submit a set of
symbols to be used in the same order as the data sets submitted</p>
</td></tr>
<tr><td><code id="chart.RiskReturnScatter_+3A_element.color">element.color</code></td>
<td>
<p>provides the color for drawing chart elements, such as
the box lines, axis lines, etc. Default is &quot;darkgray&quot;</p>
</td></tr>
<tr><td><code id="chart.RiskReturnScatter_+3A_legend.loc">legend.loc</code></td>
<td>
<p>places a legend into one of nine locations on the chart:
bottomright, bottom, bottomleft, left, topleft, top, topright, right, or
center.</p>
</td></tr>
<tr><td><code id="chart.RiskReturnScatter_+3A_xlim">xlim</code></td>
<td>
<p>set the x-axis limit, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.RiskReturnScatter_+3A_ylim">ylim</code></td>
<td>
<p>set the y-axis limit, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.RiskReturnScatter_+3A_cex.legend">cex.legend</code></td>
<td>
<p>The magnification to be used for sizing the legend
relative to the current setting of 'cex'.</p>
</td></tr>
<tr><td><code id="chart.RiskReturnScatter_+3A_cex.axis">cex.axis</code></td>
<td>
<p>The magnification to be used for axis annotation relative to
the current setting of 'cex', same as in <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
<tr><td><code id="chart.RiskReturnScatter_+3A_cex.main">cex.main</code></td>
<td>
<p>The magnification to be used for sizing the title relative
to the current setting of 'cex'.</p>
</td></tr>
<tr><td><code id="chart.RiskReturnScatter_+3A_cex.lab">cex.lab</code></td>
<td>
<p>The magnification to be used for x and y labels relative to
the current setting of 'cex'.</p>
</td></tr>
<tr><td><code id="chart.RiskReturnScatter_+3A_...">...</code></td>
<td>
<p>any other passthru parameters to <code>plot</code></p>
</td></tr>
</table>


<h3>Note</h3>

<p>Code inspired by a chart on:
<a href="http://zoonek2.free.fr/UNIX/48_R/03.html">http://zoonek2.free.fr/UNIX/48_R/03.html</a>
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)
chart.RiskReturnScatter(edhec, Rf = .04/12)
chart.RiskReturnScatter(edhec, Rf = .04/12, add.boxplots = TRUE)

</code></pre>

<hr>
<h2 id='chart.RollingCorrelation'>chart rolling correlation fo multiple assets</h2><span id='topic+chart.RollingCorrelation'></span>

<h3>Description</h3>

<p>A wrapper to create a chart of rolling correlation metrics in a line chart
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chart.RollingCorrelation(
  Ra,
  Rb,
  width = 12,
  xaxis = TRUE,
  legend.loc = NULL,
  colorset = (1:12),
  ...,
  fill = NA
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chart.RollingCorrelation_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="chart.RollingCorrelation_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="chart.RollingCorrelation_+3A_width">width</code></td>
<td>
<p>number of periods to apply rolling function window over</p>
</td></tr>
<tr><td><code id="chart.RollingCorrelation_+3A_xaxis">xaxis</code></td>
<td>
<p>if true, draws the x axis</p>
</td></tr>
<tr><td><code id="chart.RollingCorrelation_+3A_legend.loc">legend.loc</code></td>
<td>
<p>places a legend into one of nine locations on the chart:
bottomright, bottom, bottomleft, left, topleft, top, topright, right, or
center.</p>
</td></tr>
<tr><td><code id="chart.RollingCorrelation_+3A_colorset">colorset</code></td>
<td>
<p>color palette to use, set by default to rational choices</p>
</td></tr>
<tr><td><code id="chart.RollingCorrelation_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
<tr><td><code id="chart.RollingCorrelation_+3A_fill">fill</code></td>
<td>
<p>a three-component vector or list (recycled otherwise) providing 
filling values at the left/within/to the right of the data range. See the 
fill argument of <code><a href="zoo.html#topic+na.fill">na.fill</a></code> for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The previous parameter <code>na.pad</code> has been replaced with <code>fill</code>; use <code>fill = NA</code> instead of 
<code>na.pad = TRUE</code>, or <code>fill = NULL</code> instead of <code>na.pad = FALSE</code>.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# First we get the data
data(managers)
chart.RollingCorrelation(managers[, 1:6, drop=FALSE], 
		managers[, 8, drop=FALSE], 
		colorset=rich8equal, legend.loc="bottomright", 
		width=24, main = "Rolling 12-Month Correlation")

</code></pre>

<hr>
<h2 id='chart.RollingMean'>chart the rolling mean return</h2><span id='topic+chart.RollingMean'></span>

<h3>Description</h3>

<p>A wrapper to create a rolling mean return chart with 95
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chart.RollingMean(
  R,
  width = 12,
  xaxis = TRUE,
  ylim = NULL,
  lwd = c(2, 1, 1),
  ...,
  fill = NA
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chart.RollingMean_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="chart.RollingMean_+3A_width">width</code></td>
<td>
<p>number of periods to apply rolling function window over</p>
</td></tr>
<tr><td><code id="chart.RollingMean_+3A_xaxis">xaxis</code></td>
<td>
<p>if true, draws the x axis</p>
</td></tr>
<tr><td><code id="chart.RollingMean_+3A_ylim">ylim</code></td>
<td>
<p>set the y-axis limit, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.RollingMean_+3A_lwd">lwd</code></td>
<td>
<p>set the line width, same as in <code><a href="base.html#topic+plot">plot</a></code>.  Specified in
order of the main line and the two confidence bands.</p>
</td></tr>
<tr><td><code id="chart.RollingMean_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
<tr><td><code id="chart.RollingMean_+3A_fill">fill</code></td>
<td>
<p>a three-component vector or list (recycled otherwise) providing 
filling values at the left/within/to the right of the data range. See the 
fill argument of <code><a href="zoo.html#topic+na.fill">na.fill</a></code> for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The previous parameter <code>na.pad</code> has been replaced with <code>fill</code>; use <code>fill = NA</code> instead of 
<code>na.pad = TRUE</code>, or <code>fill = NULL</code> instead of <code>na.pad = FALSE</code>.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)
chart.RollingMean(edhec[, 9, drop = FALSE])

</code></pre>

<hr>
<h2 id='chart.RollingPerformance'>wrapper to create a chart of rolling performance metrics in a line chart</h2><span id='topic+chart.RollingPerformance'></span>

<h3>Description</h3>

<p>A wrapper to create a chart of rolling performance metrics in a line chart
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chart.RollingPerformance(
  R,
  width = 12,
  FUN = "Return.annualized",
  ...,
  ylim = NULL,
  main = NULL,
  fill = NA
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chart.RollingPerformance_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="chart.RollingPerformance_+3A_width">width</code></td>
<td>
<p>number of periods to apply rolling function window over</p>
</td></tr>
<tr><td><code id="chart.RollingPerformance_+3A_fun">FUN</code></td>
<td>
<p>any function that can be evaluated using a single set of returns
(e.g., rolling <code><a href="#topic+CAPM.beta">CAPM.beta</a></code> won't work, but
<code><a href="#topic+Return.annualized">Return.annualized</a></code> will)</p>
</td></tr>
<tr><td><code id="chart.RollingPerformance_+3A_...">...</code></td>
<td>
<p>any other passthru parameters to <code><a href="base.html#topic+plot">plot</a></code> or the
function specified</p>
</td></tr>
<tr><td><code id="chart.RollingPerformance_+3A_ylim">ylim</code></td>
<td>
<p>set the y-axis limit, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.RollingPerformance_+3A_main">main</code></td>
<td>
<p>set the chart title, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.RollingPerformance_+3A_fill">fill</code></td>
<td>
<p>a three-component vector or list (recycled otherwise) providing 
filling values at the left/within/to the right of the data range. See the 
fill argument of <code><a href="zoo.html#topic+na.fill">na.fill</a></code> for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The parameter <code>na.pad</code> has been deprecated; use <code>fill = NA</code> instead of <code>na.pad = TRUE</code>, 
or <code>fill = NULL</code> instead of <code>na.pad = FALSE</code>.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="#topic+charts.RollingPerformance">charts.RollingPerformance</a></code>,
<code><a href="zoo.html#topic+rollapply">rollapply</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(!( Sys.info()[['sysname']]=="Windows") ){
# if on Windows, cut and paste this example
data(edhec)
chart.RollingPerformance(edhec[, 1:3], width = 24)
chart.RollingPerformance(edhec[, 1:3], 
		FUN = 'mean', width = 24, colorset = rich8equal, 
		lwd = 2, legend.loc = "topleft", 
		main = "Rolling 24-Month Mean Return")
chart.RollingPerformance(edhec[, 1:3], 
		FUN = 'SharpeRatio.annualized', width = 24, 
		colorset = rich8equal, lwd = 2, legend.loc = "topleft", 
		main = "Rolling 24-Month Sharpe Ratio")
}

</code></pre>

<hr>
<h2 id='chart.RollingQuantileRegression'>A wrapper to create charts of relative regression performance through time</h2><span id='topic+chart.RollingQuantileRegression'></span><span id='topic+chart.RollingRegression'></span><span id='topic+charts.RollingRegression'></span>

<h3>Description</h3>

<p>A wrapper to create a chart of relative regression performance through time
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chart.RollingQuantileRegression(
  Ra,
  Rb,
  width = 12,
  Rf = 0,
  attribute = c("Beta", "Alpha", "R-Squared"),
  main = NULL,
  na.pad = TRUE,
  ...
)

chart.RollingRegression(
  Ra,
  Rb,
  width = 12,
  Rf = 0,
  attribute = c("Beta", "Alpha", "R-Squared"),
  main = NULL,
  na.pad = TRUE,
  ...
)

charts.RollingRegression(
  Ra,
  Rb,
  width = 12,
  Rf = 0,
  main = NULL,
  legend.loc = NULL,
  event.labels = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chart.RollingQuantileRegression_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="chart.RollingQuantileRegression_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="chart.RollingQuantileRegression_+3A_width">width</code></td>
<td>
<p>number of periods to apply rolling function window over</p>
</td></tr>
<tr><td><code id="chart.RollingQuantileRegression_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="chart.RollingQuantileRegression_+3A_attribute">attribute</code></td>
<td>
<p>one of &quot;Beta&quot;,&quot;Alpha&quot;,&quot;R-Squared&quot; for which attribute to
show</p>
</td></tr>
<tr><td><code id="chart.RollingQuantileRegression_+3A_main">main</code></td>
<td>
<p>set the chart title, same as in <code>plot</code></p>
</td></tr>
<tr><td><code id="chart.RollingQuantileRegression_+3A_na.pad">na.pad</code></td>
<td>
<p>TRUE/FALSE If TRUE it adds any times that would not otherwise
have been in the result with a value of NA. If FALSE those times are
dropped.</p>
</td></tr>
<tr><td><code id="chart.RollingQuantileRegression_+3A_...">...</code></td>
<td>
<p>any other passthru parameters to <code><a href="#topic+chart.TimeSeries">chart.TimeSeries</a></code></p>
</td></tr>
<tr><td><code id="chart.RollingQuantileRegression_+3A_legend.loc">legend.loc</code></td>
<td>
<p>used to set the position of the legend</p>
</td></tr>
<tr><td><code id="chart.RollingQuantileRegression_+3A_event.labels">event.labels</code></td>
<td>
<p>if not null and event.lines is not null, this will apply a 
list of text labels to the vertical lines drawn</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A group of charts in <code>charts.RollingRegression</code> displays alpha, beta,
and R-squared estimates in three aligned charts in a single device.
</p>
<p>The attribute parameter is probably the most confusing.  In mathematical
terms, the different choices yield the following:
</p>
<p>Alpha - shows the y-intercept<br /> Beta - shows the slope of the regression
line<br /> R-Squared - shows the degree of fit of the regression to the data<br />
</p>
<p><code>chart.RollingQuantileRegression</code> uses <code><a href="quantreg.html#topic+rq">rq</a></code>
rather than <code><a href="stats.html#topic+lm">lm</a></code> for the regression, and may be more
robust to outliers in the data.
</p>


<h3>Note</h3>

<p>Most inputs are the same as &quot;<code><a href="base.html#topic+plot">plot</a></code>&quot; and are principally
included so that some sensible defaults could be set.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code> <br /> <code><a href="quantreg.html#topic+rq">rq</a></code> <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# First we load the data
data(managers)
chart.RollingRegression(managers[, 1, drop=FALSE], 
		managers[, 8, drop=FALSE], Rf = .04/12)
charts.RollingRegression(managers[, 1:6], 
		managers[, 8, drop=FALSE], Rf = .04/12, 
		colorset = rich6equal, legend.loc="topleft")
dev.new()
chart.RollingQuantileRegression(managers[, 1, drop=FALSE], 
		managers[, 8, drop=FALSE], Rf = .04/12)
# not implemented yet
#charts.RollingQuantileRegression(managers[, 1:6], 
#		managers[, 8, drop=FALSE], Rf = .04/12, 
#		colorset = rich6equal, legend.loc="topleft")

</code></pre>

<hr>
<h2 id='chart.Scatter'>wrapper to draw scatter plot with sensible defaults</h2><span id='topic+chart.Scatter'></span>

<h3>Description</h3>

<p>Draws a scatter chart.  This is another chart &quot;primitive&quot;, since it only
contains a set of sensible defaults.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chart.Scatter(
  x,
  y,
  reference.grid = TRUE,
  main = "Title",
  ylab = NULL,
  xlab = NULL,
  xlim = NULL,
  ylim = NULL,
  colorset = 1,
  symbolset = 1,
  element.color = "darkgray",
  cex.axis = 0.8,
  cex.legend = 0.8,
  cex.lab = 1,
  cex.main = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chart.Scatter_+3A_x">x</code></td>
<td>
<p>data for the x axis, can take matrix,vector, or timeseries</p>
</td></tr>
<tr><td><code id="chart.Scatter_+3A_y">y</code></td>
<td>
<p>data for the y axis, can take matrix,vector, or timeseries</p>
</td></tr>
<tr><td><code id="chart.Scatter_+3A_reference.grid">reference.grid</code></td>
<td>
<p>if true, draws a grid aligned with the points on the x
and y axes</p>
</td></tr>
<tr><td><code id="chart.Scatter_+3A_main">main</code></td>
<td>
<p>set the chart title, same as in <code>plot</code></p>
</td></tr>
<tr><td><code id="chart.Scatter_+3A_ylab">ylab</code></td>
<td>
<p>set the y-axis label, as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.Scatter_+3A_xlab">xlab</code></td>
<td>
<p>set the x-axis label, as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.Scatter_+3A_xlim">xlim</code></td>
<td>
<p>set the x-axis limit, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.Scatter_+3A_ylim">ylim</code></td>
<td>
<p>set the y-axis limit, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.Scatter_+3A_colorset">colorset</code></td>
<td>
<p>color palette to use, set by default to rational choices</p>
</td></tr>
<tr><td><code id="chart.Scatter_+3A_symbolset">symbolset</code></td>
<td>
<p>from <code>pch</code> in <code><a href="base.html#topic+plot">plot</a></code>, submit a set of
symbols to be used in the same order as the data sets submitted</p>
</td></tr>
<tr><td><code id="chart.Scatter_+3A_element.color">element.color</code></td>
<td>
<p>provides the color for drawing chart elements, such as
the box lines, axis lines, etc. Default is &quot;darkgray&quot;</p>
</td></tr>
<tr><td><code id="chart.Scatter_+3A_cex.axis">cex.axis</code></td>
<td>
<p>The magnification to be used for axis annotation relative to
the current setting of 'cex', same as in <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
<tr><td><code id="chart.Scatter_+3A_cex.legend">cex.legend</code></td>
<td>
<p>The magnification to be used for sizing the legend
relative to the current setting of 'cex'.</p>
</td></tr>
<tr><td><code id="chart.Scatter_+3A_cex.lab">cex.lab</code></td>
<td>
<p>The magnification to be used for x- and y-axis labels
relative to the current setting of 'cex'</p>
</td></tr>
<tr><td><code id="chart.Scatter_+3A_cex.main">cex.main</code></td>
<td>
<p>The magnification to be used for the main title relative to
the current setting of 'cex'.</p>
</td></tr>
<tr><td><code id="chart.Scatter_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Most inputs are the same as &quot;<code><a href="base.html#topic+plot">plot</a></code>&quot; and are principally
included so that some sensible defaults could be set.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+plot">plot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  data(edhec)
  chart.Scatter(edhec[,1],edhec[,2])

## End(Not run)

</code></pre>

<hr>
<h2 id='chart.SnailTrail'>chart risk versus return over rolling time periods</h2><span id='topic+chart.SnailTrail'></span>

<h3>Description</h3>

<p>A chart that shows rolling calculations of annualized return and annualized
standard deviation have proceeded through time.  Lines and dots are darker
for more recent time periods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chart.SnailTrail(
  R,
  Rf = 0,
  main = "Annualized Return and Risk",
  add.names = c("all", "lastonly", "firstandlast", "none"),
  xlab = "Annualized Risk",
  ylab = "Annualized Return",
  add.sharpe = c(1, 2, 3),
  colorset = 1:12,
  symbolset = 16,
  legend.loc = NULL,
  xlim = NULL,
  ylim = NULL,
  width = 12,
  stepsize = 12,
  lty = 1,
  lwd = 2,
  cex.axis = 0.8,
  cex.main = 1,
  cex.lab = 1,
  cex.text = 0.8,
  cex.legend = 0.8,
  element.color = "darkgray",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chart.SnailTrail_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="chart.SnailTrail_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="chart.SnailTrail_+3A_main">main</code></td>
<td>
<p>set the chart title, same as in <code>plot</code></p>
</td></tr>
<tr><td><code id="chart.SnailTrail_+3A_add.names">add.names</code></td>
<td>
<p>plots the row name with the data point.  default TRUE. Can
be removed by setting it to NULL</p>
</td></tr>
<tr><td><code id="chart.SnailTrail_+3A_xlab">xlab</code></td>
<td>
<p>set the x-axis label, as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.SnailTrail_+3A_ylab">ylab</code></td>
<td>
<p>set the y-axis label, as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.SnailTrail_+3A_add.sharpe">add.sharpe</code></td>
<td>
<p>this draws a Sharpe ratio line that indicates Sharpe ratio
levels of <code>c(1,2,3)</code>.  Lines are drawn with a y-intercept of the risk
free rate and the slope of the appropriate Sharpe ratio level.  Lines should
be removed where not appropriate (e.g., sharpe.ratio = NULL).</p>
</td></tr>
<tr><td><code id="chart.SnailTrail_+3A_colorset">colorset</code></td>
<td>
<p>color palette to use, set by default to rational choices</p>
</td></tr>
<tr><td><code id="chart.SnailTrail_+3A_symbolset">symbolset</code></td>
<td>
<p>from <code>pch</code> in <code><a href="base.html#topic+plot">plot</a></code>, submit a set of
symbols to be used in the same order as the data sets submitted</p>
</td></tr>
<tr><td><code id="chart.SnailTrail_+3A_legend.loc">legend.loc</code></td>
<td>
<p>places a legend into one of nine locations on the chart:
bottomright, bottom, bottomleft, left, topleft, top, topright, right, or
center.</p>
</td></tr>
<tr><td><code id="chart.SnailTrail_+3A_xlim">xlim</code></td>
<td>
<p>set the x-axis limit, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.SnailTrail_+3A_ylim">ylim</code></td>
<td>
<p>set the y-axis limit, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.SnailTrail_+3A_width">width</code></td>
<td>
<p>number of periods to apply rolling calculations over, sometimes
referred to as a 'window'</p>
</td></tr>
<tr><td><code id="chart.SnailTrail_+3A_stepsize">stepsize</code></td>
<td>
<p>the frequency with which to make the rolling calculation</p>
</td></tr>
<tr><td><code id="chart.SnailTrail_+3A_lty">lty</code></td>
<td>
<p>set the line type, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.SnailTrail_+3A_lwd">lwd</code></td>
<td>
<p>set the line width, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.SnailTrail_+3A_cex.axis">cex.axis</code></td>
<td>
<p>The magnification to be used for sizing the axis text
relative to the current setting of 'cex', similar to <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
<tr><td><code id="chart.SnailTrail_+3A_cex.main">cex.main</code></td>
<td>
<p>The magnification to be used for sizing the main chart
relative to the current setting of 'cex', as in <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
<tr><td><code id="chart.SnailTrail_+3A_cex.lab">cex.lab</code></td>
<td>
<p>The magnification to be used for sizing the label relative to
the current setting of 'cex', similar to <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
<tr><td><code id="chart.SnailTrail_+3A_cex.text">cex.text</code></td>
<td>
<p>The magnification to be used for sizing the text relative to
the current setting of 'cex', similar to <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
<tr><td><code id="chart.SnailTrail_+3A_cex.legend">cex.legend</code></td>
<td>
<p>The magnification to be used for sizing the legend
relative to the current setting of 'cex'.</p>
</td></tr>
<tr><td><code id="chart.SnailTrail_+3A_element.color">element.color</code></td>
<td>
<p>provides the color for drawing chart elements, such as
the box lines, axis lines, etc. Default is &quot;darkgray&quot;</p>
</td></tr>
<tr><td><code id="chart.SnailTrail_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>~put references to the literature/web site here ~
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chart.RiskReturnScatter">chart.RiskReturnScatter</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
chart.SnailTrail(managers[,c("HAM2","SP500 TR"),drop=FALSE], 
		width=36, stepsize=12, 
		colorset=c('red','orange'),
		add.names="firstandlast", 
		rf=.04/12, 
		main="Trailing 36-month Performance Calc'd Every 12 Months")


</code></pre>

<hr>
<h2 id='chart.StackedBar'>create a stacked bar plot</h2><span id='topic+chart.StackedBar'></span>

<h3>Description</h3>

<p>This creates a stacked column chart with time on the horizontal axis and
values in categories.  This kind of chart is commonly used for showing
portfolio 'weights' through time, although the function will plot any values
by category.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chart.StackedBar(
  w,
  colorset = NULL,
  space = 0.2,
  cex.axis = 0.8,
  cex.legend = 0.8,
  cex.lab = 1,
  cex.labels = 0.8,
  cex.main = 1,
  xaxis = TRUE,
  legend.loc = "under",
  element.color = "darkgray",
  unstacked = TRUE,
  xlab = "Date",
  ylab = "Value",
  ylim = NULL,
  date.format = "%b %y",
  major.ticks = "auto",
  minor.ticks = TRUE,
  las = 0,
  xaxis.labels = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chart.StackedBar_+3A_w">w</code></td>
<td>
<p>a matrix, data frame or zoo object of values to be plotted.
Rownames should contain dates or period labels; column names should indicate
categories.  See examples for detail.</p>
</td></tr>
<tr><td><code id="chart.StackedBar_+3A_colorset">colorset</code></td>
<td>
<p>color palette to use, set by default to rational choices</p>
</td></tr>
<tr><td><code id="chart.StackedBar_+3A_space">space</code></td>
<td>
<p>the amount of space (as a fraction of the average bar width)
left before each bar, as in <code><a href="graphics.html#topic+barplot">barplot</a></code>. Default is 0.2.</p>
</td></tr>
<tr><td><code id="chart.StackedBar_+3A_cex.axis">cex.axis</code></td>
<td>
<p>The magnification to be used for sizing the axis text
relative to the current setting of 'cex', similar to <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
<tr><td><code id="chart.StackedBar_+3A_cex.legend">cex.legend</code></td>
<td>
<p>The magnification to be used for sizing the legend
relative to the current setting of 'cex', similar to <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
<tr><td><code id="chart.StackedBar_+3A_cex.lab">cex.lab</code></td>
<td>
<p>The magnification to be used for x- and y-axis labels
relative to the current setting of 'cex'.</p>
</td></tr>
<tr><td><code id="chart.StackedBar_+3A_cex.labels">cex.labels</code></td>
<td>
<p>The magnification to be used for event line labels
relative to the current setting of 'cex'.</p>
</td></tr>
<tr><td><code id="chart.StackedBar_+3A_cex.main">cex.main</code></td>
<td>
<p>The magnification to be used for the chart title relative to
the current setting of 'cex'.</p>
</td></tr>
<tr><td><code id="chart.StackedBar_+3A_xaxis">xaxis</code></td>
<td>
<p>If true, draws the x axis</p>
</td></tr>
<tr><td><code id="chart.StackedBar_+3A_legend.loc">legend.loc</code></td>
<td>
<p>places a legend into a location on the chart similar to
<code><a href="#topic+chart.TimeSeries">chart.TimeSeries</a></code>. The default, &quot;under,&quot; is the only location
currently implemented for this chart.  Use 'NULL' to remove the legend.</p>
</td></tr>
<tr><td><code id="chart.StackedBar_+3A_element.color">element.color</code></td>
<td>
<p>provides the color for drawing less-important chart
elements, such as the box lines, axis lines, etc.</p>
</td></tr>
<tr><td><code id="chart.StackedBar_+3A_unstacked">unstacked</code></td>
<td>
<p>logical.  If set to 'TRUE' <em>and</em> only one row of data
is submitted in 'w', then the chart creates a normal column chart.  If more
than one row is submitted, then this is ignored.  See examples below.</p>
</td></tr>
<tr><td><code id="chart.StackedBar_+3A_xlab">xlab</code></td>
<td>
<p>the x-axis label, which defaults to 'NULL'.</p>
</td></tr>
<tr><td><code id="chart.StackedBar_+3A_ylab">ylab</code></td>
<td>
<p>Set the y-axis label, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.StackedBar_+3A_ylim">ylim</code></td>
<td>
<p>set the y-axis limit, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.StackedBar_+3A_date.format">date.format</code></td>
<td>
<p>Re-format the dates for the xaxis; the default is &quot;%m/%y&quot;</p>
</td></tr>
<tr><td><code id="chart.StackedBar_+3A_major.ticks">major.ticks</code></td>
<td>
<p>Should major tickmarks be drawn and labeled, default
'auto'</p>
</td></tr>
<tr><td><code id="chart.StackedBar_+3A_minor.ticks">minor.ticks</code></td>
<td>
<p>Should minor tickmarks be drawn, default TRUE</p>
</td></tr>
<tr><td><code id="chart.StackedBar_+3A_las">las</code></td>
<td>
<p>sets the orientation of the axis labels, as described in
<code><a href="graphics.html#topic+par">par</a></code>.  Defaults to '3'.</p>
</td></tr>
<tr><td><code id="chart.StackedBar_+3A_xaxis.labels">xaxis.labels</code></td>
<td>
<p>Allows for non-date labeling of date axes, default is
NULL</p>
</td></tr>
<tr><td><code id="chart.StackedBar_+3A_...">...</code></td>
<td>
<p>arguments to be passed to <code><a href="graphics.html#topic+barplot">barplot</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a wrapper for <code><a href="graphics.html#topic+barplot">barplot</a></code> but adds three
additional capabilities.  First, it calculates and sets a bottom margin for
long column names that are rotated vertically.  That doesn't always result
in the prettiest chart, but it does ensure readable labels.
</p>
<p>Second, it places a legend &quot;under&quot; the graph rather than within the bounds
of the chart (which would obscure the data).  The legend is created from the
column names.  The default is to create the legend when there's more than
one row of data being presented.  If there is one row of data, the chart may
be &quot;unstacked&quot; and the legend removed.
</p>
<p>Third, it plots or stacks negative values from an origin of zero, similar to
the behavior of <code><a href="lattice.html#topic+barchart">barchart</a></code> from the 'lattice' package.
</p>


<h3>Note</h3>

<p>The &quot;w&quot; attribute is so named because this is a popular way to show
portfolio weights through time.  That being said, this function is not
limited to portfolio weight values and does not provide any normalization 
so that the chart can be used more generally with different data.
</p>
<p>The principal drawback of stacked column charts is that it is very difficult
for the reader to judge size of 2nd, 3rd, etc., data series because they do
not have common baseline.  Another is that with a large number of series,
the colors may be difficult to discern.  As alternatives, Cleveland
advocates the use of trellis like displays, and Tufte advocates the use of
small multiple charts.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>Cleveland, W.S. (1994), The Elements of Graphing Data, Summit,
NJ: Hobart Press.
</p>
<p>Tufte, Edward R. (2001) The Visual Display of Quantitative Information, 2nd
edition. The Graphics Press, Cheshire, Connecticut. See
http://www.edwardtufte.com for this and other references.
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+barplot">barplot</a></code>, <code><a href="graphics.html#topic+par">par</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(weights)
head(weights)

# With the legend "under" the chart
chart.StackedBar(weights, date.format="%Y", cex.legend = 0.7, colorset=rainbow12equal)

# Without the legend
chart.StackedBar(weights, colorset=rainbow12equal, legend.loc=NULL)

# for one row of data, use 'unstacked' for a better chart
chart.StackedBar(weights[1,,drop=FALSE], unstacked=TRUE, las=3)

</code></pre>

<hr>
<h2 id='chart.TimeSeries'>Creates a time series chart with some extensions.</h2><span id='topic+chart.TimeSeries'></span><span id='topic+chart.TimeSeries.base'></span><span id='topic+chart.TimeSeries.builtin'></span><span id='topic+chart.TimeSeries.dygraph'></span><span id='topic+chart.TimeSeries.ggplot2'></span><span id='topic+chart.TimeSeries.googlevis'></span><span id='topic+chart.TimeSeries.plotly'></span><span id='topic+charts.TimeSeries'></span>

<h3>Description</h3>

<p>Draws a line chart and labels the x-axis with the appropriate dates.  This
is really a &quot;primitive&quot;, since it extends the base <code><a href="base.html#topic+plot">plot</a></code> and
standardizes the elements of a chart.  Adds attributes for shading areas of
the timeline or aligning vertical lines along the timeline. This function is
intended to be used inside other charting functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chart.TimeSeries(
  R,
  ...,
  auto.grid = TRUE,
  xaxis = TRUE,
  yaxis = TRUE,
  yaxis.right = FALSE,
  type = "l",
  lty = 1,
  lwd = 1,
  las = par("las"),
  main = "",
  ylab = "",
  xlab = "",
  date.format.in = "%Y-%m-%d",
  date.format = NULL,
  xlim = NULL,
  ylim = NULL,
  element.color = "darkgray",
  event.lines = NULL,
  event.labels = NULL,
  period.areas = NULL,
  event.color = "darkgray",
  period.color = "aliceblue",
  colorset = (1:12),
  pch = (1:12),
  legend.loc = NULL,
  ylog = FALSE,
  cex.axis = 0.8,
  cex.legend = 0.8,
  cex.lab = 1,
  cex.labels = 0.8,
  cex.main = 1,
  major.ticks = "auto",
  minor.ticks = TRUE,
  grid.color = "lightgray",
  grid.lty = "dotted",
  xaxis.labels = NULL,
  plot.engine = "default",
  yaxis.pct = FALSE
)

chart.TimeSeries.base(
  R,
  auto.grid,
  xaxis,
  yaxis,
  yaxis.right,
  type,
  lty,
  lwd,
  las,
  main,
  ylab,
  xlab,
  date.format.in,
  date.format,
  xlim,
  ylim,
  element.color,
  event.lines,
  event.labels,
  period.areas,
  event.color,
  period.color,
  colorset,
  pch,
  legend.loc,
  ylog,
  cex.axis,
  cex.legend,
  cex.lab,
  cex.labels,
  cex.main,
  major.ticks,
  minor.ticks,
  grid.color,
  grid.lty,
  xaxis.labels,
  plot.engine,
  yaxis.pct,
  ...
)

chart.TimeSeries.builtin(
  R,
  auto.grid,
  xaxis,
  yaxis,
  yaxis.right,
  type,
  lty,
  lwd,
  las,
  main,
  ylab,
  xlab,
  date.format.in,
  date.format,
  xlim,
  ylim,
  element.color,
  event.lines,
  event.labels,
  period.areas,
  event.color,
  period.color,
  colorset,
  pch,
  legend.loc,
  ylog,
  cex.axis,
  cex.legend,
  cex.lab,
  cex.labels,
  cex.main,
  major.ticks,
  minor.ticks,
  grid.color,
  grid.lty,
  xaxis.labels,
  yaxis.pct
)

chart.TimeSeries.dygraph(R)

chart.TimeSeries.ggplot2(
  R,
  auto.grid,
  xaxis,
  yaxis,
  yaxis.right,
  type,
  lty,
  lwd,
  las,
  main,
  ylab,
  xlab,
  date.format.in,
  date.format,
  xlim,
  ylim,
  element.color,
  event.lines,
  event.labels,
  period.areas,
  event.color,
  period.color,
  colorset,
  pch,
  legend.loc,
  ylog,
  cex.axis,
  cex.legend,
  cex.lab,
  cex.labels,
  cex.main,
  major.ticks,
  minor.ticks,
  grid.color,
  grid.lty,
  xaxis.labels,
  plot.engine,
  yaxis.pct
)

chart.TimeSeries.googlevis(R, xlab, ylab, main)

chart.TimeSeries.plotly(R, main, ...)

charts.TimeSeries(R, space = 0, main = "Returns", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chart.TimeSeries_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_auto.grid">auto.grid</code></td>
<td>
<p>if true, draws a grid aligned with the points on the x and
y axes</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_xaxis">xaxis</code></td>
<td>
<p>if true, draws the x axis</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_yaxis">yaxis</code></td>
<td>
<p>if true, draws the y axis</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_yaxis.right">yaxis.right</code></td>
<td>
<p>if true, draws the y axis on the right-hand side of the
plot</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_type">type</code></td>
<td>
<p>set the chart type, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_lty">lty</code></td>
<td>
<p>set the line type, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_lwd">lwd</code></td>
<td>
<p>set the line width, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_las">las</code></td>
<td>
<p>set the axis label rotation, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_main">main</code></td>
<td>
<p>set the chart title, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_ylab">ylab</code></td>
<td>
<p>set the y-axis label, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_xlab">xlab</code></td>
<td>
<p>set the x-axis label, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_date.format.in">date.format.in</code></td>
<td>
<p>allows specification of other date formats in the data
object, defaults to &quot;%Y-%m-%d&quot;</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_date.format">date.format</code></td>
<td>
<p>re-format the dates for the xaxis; the default is &quot;%m/%y&quot;</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_xlim">xlim</code></td>
<td>
<p>set the x-axis limit, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_ylim">ylim</code></td>
<td>
<p>set the y-axis limit, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_element.color">element.color</code></td>
<td>
<p>provides the color for drawing chart elements, such as
the box lines, axis lines, etc. Default is &quot;darkgray&quot;</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_event.lines">event.lines</code></td>
<td>
<p>if not null, vertical lines will be drawn to indicate
that an event happened during that time period.  <code>event.lines</code> should
be a list of dates (e.g., <code>c("09/03","05/06"))</code> formatted the same as
date.format.  This function matches the re-formatted row names (dates) with
the events.list, so to get a match the formatting needs to be correct.</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_event.labels">event.labels</code></td>
<td>
<p>if not null and event.lines is not null, this will apply
a list of text labels (e.g., <code>c("This Event", "That Event")</code> to the
vertical lines drawn.  See the example below.</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_period.areas">period.areas</code></td>
<td>
<p>these are shaded areas described by start and end dates
in a vector of xts date rangees, e.g.,
<code>c("1926-10::1927-11","1929-08::1933-03")</code> See the examples below.</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_event.color">event.color</code></td>
<td>
<p>draws the event described in <code>event.labels</code> in the
color specified</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_period.color">period.color</code></td>
<td>
<p>draws the shaded region described by <code>period.areas</code>
in the color specified</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_colorset">colorset</code></td>
<td>
<p>color palette to use, set by default to rational choices</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_pch">pch</code></td>
<td>
<p>symbols to use, see also <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_legend.loc">legend.loc</code></td>
<td>
<p>places a legend into one of nine locations on the chart:
bottomright, bottom, bottomleft, left, topleft, top, topright, right, or
center.</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_ylog">ylog</code></td>
<td>
<p>TRUE/FALSE set the y-axis to logarithmic scale, similar to
<code><a href="base.html#topic+plot">plot</a></code>, default FALSE</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_cex.axis">cex.axis</code></td>
<td>
<p>The magnification to be used for axis annotation relative to
the current setting of 'cex', same as in <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_cex.legend">cex.legend</code></td>
<td>
<p>The magnification to be used for sizing the legend
relative to the current setting of 'cex'.</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_cex.lab">cex.lab</code></td>
<td>
<p>The magnification to be used for x- and y-axis labels
relative to the current setting of 'cex'.</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_cex.labels">cex.labels</code></td>
<td>
<p>The magnification to be used for event line labels
relative to the current setting of 'cex'.</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_cex.main">cex.main</code></td>
<td>
<p>The magnification to be used for the chart title relative to
the current setting of 'cex'.</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_major.ticks">major.ticks</code></td>
<td>
<p>Should major tickmarks be drawn and labeled, default
'auto'</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_minor.ticks">minor.ticks</code></td>
<td>
<p>Should minor tickmarks be drawn, default TRUE</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_grid.color">grid.color</code></td>
<td>
<p>sets the color for the reference grid</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_grid.lty">grid.lty</code></td>
<td>
<p>defines the line type for the grid</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_xaxis.labels">xaxis.labels</code></td>
<td>
<p>Allows for non-date labeling of date axes, default is
NULL</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_plot.engine">plot.engine</code></td>
<td>
<p>choose the plot engine you wish to use:
ggplot2, plotly,dygraph,googlevis and default</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_yaxis.pct">yaxis.pct</code></td>
<td>
<p>if TRUE, scales the y axis labels by 100</p>
</td></tr>
<tr><td><code id="chart.TimeSeries_+3A_space">space</code></td>
<td>
<p>default 0</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+plot">plot</a></code>, <code><a href="graphics.html#topic+par">par</a></code>,
<code><a href="xts.html#topic+axTicksByTime">axTicksByTime</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# These are start and end dates, formatted as xts ranges.
## http://www.nber.org-cycles.html
cycles.dates&lt;-c("1857-06/1858-12",
                "1860-10/1861-06",
                "1865-04/1867-12",
                "1869-06/1870-12",
                "1873-10/1879-03",
                "1882-03/1885-05",
                "1887-03/1888-04",
                "1890-07/1891-05",
                "1893-01/1894-06",
                "1895-12/1897-06",
                "1899-06/1900-12",
                "1902-09/1904-08",
                "1907-05/1908-06",
                "1910-01/1912-01",
                "1913-01/1914-12",
                "1918-08/1919-03",
                "1920-01/1921-07",
                "1923-05/1924-07",
                "1926-10/1927-11",
                "1929-08/1933-03",
                "1937-05/1938-06",
                "1945-02/1945-10",
                "1948-11/1949-10",
                "1953-07/1954-05",
                "1957-08/1958-04",
                "1960-04/1961-02",
                "1969-12/1970-11",
                "1973-11/1975-03",
                "1980-01/1980-07",
                "1981-07/1982-11",
                "1990-07/1991-03",
                "2001-03/2001-11",
                "2007-12/2009-06"
                )
# Event lists - FOR BEST RESULTS, KEEP THESE DATES IN ORDER
risk.dates = c(
    "Oct 87",
    "Feb 94",
    "Jul 97",
    "Aug 98",
    "Oct 98",
    "Jul 00",
    "Sep 01")
risk.labels = c(
    "Black Monday",
    "Bond Crash",
    "Asian Crisis",
    "Russian Crisis",
    "LTCM",
    "Tech Bubble",
    "Sept 11")
data(edhec)

R=edhec[,"Funds of Funds",drop=FALSE]
Return.cumulative = cumprod(1+R) - 1
chart.TimeSeries(Return.cumulative)
chart.TimeSeries(Return.cumulative, colorset = "darkblue", 
                 legend.loc = "bottomright", 
                 period.areas = cycles.dates, 
                 period.color = rgb(204/255, 204/255, 204/255, alpha=0.25), 
                 event.lines = risk.dates, 
                 event.labels = risk.labels, 
                 event.color = "red", lwd = 2)

</code></pre>

<hr>
<h2 id='chart.VaRSensitivity'>show the sensitivity of Value-at-Risk or Expected Shortfall estimates</h2><span id='topic+chart.VaRSensitivity'></span>

<h3>Description</h3>

<p>Creates a chart of Value-at-Risk and/or Expected Shortfall estimates by
confidence interval for multiple methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chart.VaRSensitivity(
  R,
  methods = c("GaussianVaR", "ModifiedVaR", "HistoricalVaR", "GaussianES", "ModifiedES",
    "HistoricalES"),
  clean = c("none", "boudt", "geltner"),
  elementcolor = "darkgray",
  reference.grid = TRUE,
  xlab = "Confidence Level",
  ylab = "Value at Risk",
  type = "l",
  lty = c(1, 2, 4),
  lwd = 1,
  colorset = (1:12),
  pch = (1:12),
  legend.loc = "bottomleft",
  cex.legend = 0.8,
  main = NULL,
  ylim = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chart.VaRSensitivity_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="chart.VaRSensitivity_+3A_methods">methods</code></td>
<td>
<p>one or more calculation methods indicated &quot;GaussianVaR&quot;,
&quot;ModifiedVaR&quot;, &quot;HistoricalVaR&quot;, &quot;GaussianES&quot;, &quot;ModifiedES&quot;, &quot;HistoricalES&quot;.
See <code><a href="#topic+VaR">VaR</a></code> or <code><a href="#topic+ES">ES</a></code> for more detail.</p>
</td></tr>
<tr><td><code id="chart.VaRSensitivity_+3A_clean">clean</code></td>
<td>
<p>method for data cleaning through <code><a href="#topic+Return.clean">Return.clean</a></code>.
Current options are &quot;none&quot; or &quot;boudt&quot; or &quot;geltner&quot;.</p>
</td></tr>
<tr><td><code id="chart.VaRSensitivity_+3A_elementcolor">elementcolor</code></td>
<td>
<p>the color used to draw chart elements. The default is
&quot;darkgray&quot;</p>
</td></tr>
<tr><td><code id="chart.VaRSensitivity_+3A_reference.grid">reference.grid</code></td>
<td>
<p>if true, draws a grid aligned with the points on the x
and y axes</p>
</td></tr>
<tr><td><code id="chart.VaRSensitivity_+3A_xlab">xlab</code></td>
<td>
<p>set the x-axis label, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.VaRSensitivity_+3A_ylab">ylab</code></td>
<td>
<p>set the y-axis label, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.VaRSensitivity_+3A_type">type</code></td>
<td>
<p>set the chart type, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.VaRSensitivity_+3A_lty">lty</code></td>
<td>
<p>set the line type, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.VaRSensitivity_+3A_lwd">lwd</code></td>
<td>
<p>set the line width, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.VaRSensitivity_+3A_colorset">colorset</code></td>
<td>
<p>color palette to use, set by default to rational choices</p>
</td></tr>
<tr><td><code id="chart.VaRSensitivity_+3A_pch">pch</code></td>
<td>
<p>symbols to use, see also <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.VaRSensitivity_+3A_legend.loc">legend.loc</code></td>
<td>
<p>places a legend into one of nine locations on the chart:
bottomright, bottom, bottomleft, left, topleft, top, topright, right, or
center.</p>
</td></tr>
<tr><td><code id="chart.VaRSensitivity_+3A_cex.legend">cex.legend</code></td>
<td>
<p>The magnification to be used for sizing the legend
relative to the current setting of 'cex'.</p>
</td></tr>
<tr><td><code id="chart.VaRSensitivity_+3A_main">main</code></td>
<td>
<p>set the chart title, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.VaRSensitivity_+3A_ylim">ylim</code></td>
<td>
<p>set the y-axis dimensions, same as in <code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="chart.VaRSensitivity_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This chart shows estimated VaR along a series of confidence intervals for
selected calculation methods.  Useful for comparing a method to the
historical VaR calculation.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>Boudt, K., Peterson, B. G., Croux, C., 2008. Estimation and
Decomposition of Downside Risk for Portfolios with Non-Normal Returns.
Journal of Risk, forthcoming.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VaR">VaR</a></code> <br /> <code><a href="#topic+ES">ES</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
chart.VaRSensitivity(managers[,1,drop=FALSE], 
		methods=c("HistoricalVaR", "ModifiedVaR", "GaussianVaR"), 
		colorset=bluefocus, lwd=2)

</code></pre>

<hr>
<h2 id='charts.PerformanceSummary'>Create combined wealth index, period performance, and drawdown chart</h2><span id='topic+charts.PerformanceSummary'></span>

<h3>Description</h3>

<p>For a set of returns, create a wealth index chart, bars for per-period
performance, and underwater chart for drawdown.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>charts.PerformanceSummary(
  R,
  Rf = 0,
  main = NULL,
  geometric = TRUE,
  methods = "none",
  width = 0,
  event.labels = NULL,
  ylog = FALSE,
  wealth.index = FALSE,
  gap = 12,
  begin = c("first", "axis"),
  legend.loc = "topleft",
  p = 0.95,
  plot.engine = "default",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="charts.PerformanceSummary_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="charts.PerformanceSummary_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="charts.PerformanceSummary_+3A_main">main</code></td>
<td>
<p>set the chart title, as in <code>plot</code></p>
</td></tr>
<tr><td><code id="charts.PerformanceSummary_+3A_geometric">geometric</code></td>
<td>
<p>utilize geometric chaining (TRUE) or simple/arithmetic chaining (FALSE) to aggregate returns,
default TRUE</p>
</td></tr>
<tr><td><code id="charts.PerformanceSummary_+3A_methods">methods</code></td>
<td>
<p>Used to select the risk parameter of trailing <code>width</code>
returns to use in the <code><a href="#topic+chart.BarVaR">chart.BarVaR</a></code> panel: May be any of:
</p>
 <ul>
<li><p> None - does not add a line, </p>
</li>
<li><p> ModifiedVaR - uses
Cornish-Fisher modified VaR, </p>
</li>
<li><p> GaussianVaR - uses traditional Value at
Risk, </p>
</li>
<li><p> HistoricalVaR - calculates historical Value at Risk, </p>
</li>
<li>
<p>ModifiedES - uses Cornish-Fisher modified Expected Shortfall, </p>
</li>
<li>
<p>GaussianES - uses traditional Expected Shortfall, </p>
</li>
<li><p> HistoricalES -
calculates historical Expected Shortfall, </p>
</li>
<li><p> StdDev - per-period standard
deviation </p>
</li></ul>
</td></tr>
<tr><td><code id="charts.PerformanceSummary_+3A_width">width</code></td>
<td>
<p>number of periods to apply rolling function window over</p>
</td></tr>
<tr><td><code id="charts.PerformanceSummary_+3A_event.labels">event.labels</code></td>
<td>
<p>TRUE/FALSE whether or not to display lines and labels
for historical market shock events</p>
</td></tr>
<tr><td><code id="charts.PerformanceSummary_+3A_ylog">ylog</code></td>
<td>
<p>TRUE/FALSE set the y-axis to logarithmic scale, similar to
<code><a href="base.html#topic+plot">plot</a></code>, default FALSE</p>
</td></tr>
<tr><td><code id="charts.PerformanceSummary_+3A_wealth.index">wealth.index</code></td>
<td>
<p>if <code>wealth.index</code> is <code>TRUE</code>, shows the &quot;value
of $1&quot;, starting the cumulation of returns at 1 rather than zero</p>
</td></tr>
<tr><td><code id="charts.PerformanceSummary_+3A_gap">gap</code></td>
<td>
<p>numeric number of periods from start of series to use to train
risk calculation</p>
</td></tr>
<tr><td><code id="charts.PerformanceSummary_+3A_begin">begin</code></td>
<td>
<p>Align shorter series to: </p>
 <ul>
<li><p> first - prior value of
the first column given for the reference or longer series or, </p>
</li>
<li><p> axis -
the initial value (1 or zero) of the axis.  </p>
</li></ul>
<p> passthru to
<code><a href="#topic+chart.CumReturns">chart.CumReturns</a></code></p>
</td></tr>
<tr><td><code id="charts.PerformanceSummary_+3A_legend.loc">legend.loc</code></td>
<td>
<p>sets the legend location in the top chart.  Can be set to
NULL or nine locations on the chart: bottomright, bottom, bottomleft, left,
topleft, top, topright, right, or center.</p>
</td></tr>
<tr><td><code id="charts.PerformanceSummary_+3A_p">p</code></td>
<td>
<p>confidence level for calculation, default p=.95</p>
</td></tr>
<tr><td><code id="charts.PerformanceSummary_+3A_plot.engine">plot.engine</code></td>
<td>
<p>choose the plot engine you wish to use&quot;
ggplot2, plotly, and default</p>
</td></tr>
<tr><td><code id="charts.PerformanceSummary_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Most inputs are the same as &quot;<code><a href="base.html#topic+plot">plot</a></code>&quot; and are principally
included so that some sensible defaults could be set.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chart.CumReturns">chart.CumReturns</a></code> <br /> <code><a href="#topic+chart.BarVaR">chart.BarVaR</a></code> <br />
<code><a href="#topic+chart.Drawdown">chart.Drawdown</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)
charts.PerformanceSummary(edhec[,c(1,13)])

</code></pre>

<hr>
<h2 id='charts.RollingPerformance'>rolling performance chart</h2><span id='topic+charts.RollingPerformance'></span>

<h3>Description</h3>

<p>A wrapper to create a rolling annualized returns chart, rolling annualized
standard deviation chart, and a rolling annualized sharpe ratio chart.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>charts.RollingPerformance(
  R,
  width = 12,
  Rf = 0,
  main = NULL,
  event.labels = NULL,
  legend.loc = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="charts.RollingPerformance_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="charts.RollingPerformance_+3A_width">width</code></td>
<td>
<p>number of periods to apply rolling function over</p>
</td></tr>
<tr><td><code id="charts.RollingPerformance_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="charts.RollingPerformance_+3A_main">main</code></td>
<td>
<p>set the chart title, same as in <code>plot</code></p>
</td></tr>
<tr><td><code id="charts.RollingPerformance_+3A_event.labels">event.labels</code></td>
<td>
<p>TRUE/FALSE whether or not to display lines and labels
for historical market shock events</p>
</td></tr>
<tr><td><code id="charts.RollingPerformance_+3A_legend.loc">legend.loc</code></td>
<td>
<p>places a legend into one of nine locations on the chart:
bottomright, bottom, bottomleft, left, topleft, top, topright, right, or
center.</p>
</td></tr>
<tr><td><code id="charts.RollingPerformance_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chart.RollingPerformance">chart.RollingPerformance</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(!( Sys.info()[['sysname']]=="Windows") ){
# if on Windows, cut and paste this example

data(managers)
charts.RollingPerformance(managers[,1:8], 
                          Rf=managers[,10,drop=FALSE], 
                          colorset=tim8equal, 
                          main="Rolling 12-Month Performance", 
                          legend.loc="topleft")
}

</code></pre>

<hr>
<h2 id='checkData'>check input data type and format and coerce to the desired output type</h2><span id='topic+checkData'></span>

<h3>Description</h3>

<p>This function was created to make the different kinds of data classes at
least <em>seem</em> more fungible.  It allows the user to pass in a data
object without being concerned that the function requires a matrix,
data.frame, vector, xts, or timeSeries object.  By using <code>checkData</code>, 
the function &quot;knows&quot; what data format it has to work with.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkData(
  x,
  method = c("xts", "zoo", "data.frame", "matrix", "vector"),
  na.rm = TRUE,
  quiet = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checkData_+3A_x">x</code></td>
<td>
<p>a vector, matrix, data.frame, xts, timeSeries or zoo object to be
checked and coerced</p>
</td></tr>
<tr><td><code id="checkData_+3A_method">method</code></td>
<td>
<p>type of coerced data object to return, one of
c(&quot;xts&quot;, &quot;zoo&quot;, &quot;data.frame&quot;, &quot;matrix&quot;, &quot;vector&quot;), default &quot;xts&quot;</p>
</td></tr>
<tr><td><code id="checkData_+3A_na.rm">na.rm</code></td>
<td>
<p>TRUE/FALSE Remove NA's from the data? used only with 'vector'</p>
</td></tr>
<tr><td><code id="checkData_+3A_quiet">quiet</code></td>
<td>
<p>TRUE/FALSE if false, it will throw warnings when errors are
noticed, default TRUE</p>
</td></tr>
<tr><td><code id="checkData_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)
x = checkData(edhec)
class(x)
head(x)
tail(x)
# Note that passing in a single column loses the row and column names
x = checkData(edhec[,1])
class(x)
head(x)
# Include the "drop" attribute to keep row and column names
x = checkData(edhec[,1,drop=FALSE])
class(x)
head(x)
x = checkData(edhec, method = "matrix")
class(x)
head(x)
x = checkData(edhec[,1], method = "vector")
class(x)
head(x)

</code></pre>

<hr>
<h2 id='checkSeedValue'>Check 'seedValue' to ensure it is compatible with coredata_content attribute of 'R' (an xts object)</h2><span id='topic+checkSeedValue'></span>

<h3>Description</h3>

<p>Check 'seedValue' to ensure it is compatible with coredata_content attribute of 'R' (an xts object)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkSeedValue(R, seedValue)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checkSeedValue_+3A_r">R</code></td>
<td>
<p>an xts object</p>
</td></tr>
<tr><td><code id="checkSeedValue_+3A_seedvalue">seedValue</code></td>
<td>
<p>a numeric scalar indicating the (usually initial) index level or price of the series</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Erol Biceroglu
</p>

<hr>
<h2 id='clean.boudt'>clean extreme observations in a time series to to provide more robust risk
estimates</h2><span id='topic+clean.boudt'></span>

<h3>Description</h3>

<p>Robustly clean a time series to reduce the magnitude, but not the number or
direction, of observations that exceed the <code class="reqn">1-\alpha\%</code> risk threshold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clean.boudt(R, alpha = 0.01, trim = 0.001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clean.boudt_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="clean.boudt_+3A_alpha">alpha</code></td>
<td>
<p>probability to filter at 1-alpha, defaults to .01 (99%)</p>
</td></tr>
<tr><td><code id="clean.boudt_+3A_trim">trim</code></td>
<td>
<p>where to set the &quot;extremeness&quot; of the Mahalanobis distance</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Many risk measures are calculated by using the first two (four) moments of
the asset or portfolio return distribution. Portfolio moments are extremely
sensitive to data spikes, and this sensitivity is only exacerbated in a
multivariate context. For this reason, it seems appropriate to consider
estimates of the multivariate moments that are robust to return observations
that deviate extremely from the Gaussian distribution.
</p>
<p>There are two main approaches in defining robust alternatives to estimate
the multivariate moments by their sample means (see e.g. Maronna[2006]). One
approach is to consider a more robust estimator than the sample means.
Another one is to first clean (in a robust way) the data and then take the
sample means and moments of the cleaned data.
</p>
<p>Our cleaning method follows the second approach. It is designed in such a
way that, if we want to estimate downside risk with loss probability
<code class="reqn">\alpha</code>, it will never clean observations that belong to the
<code class="reqn">1-\alpha</code> least extreme observations. Suppose we have an
<code class="reqn">n</code>-dimensional vector time series of length <code class="reqn">T</code>: <code class="reqn">r_1,...,r_T</code>.
We clean this time series in three steps.
</p>
 <ol>
<li> <p><em> Ranking the observations in function of their
extremeness. </em>Denote <code class="reqn">\mu</code> and <code class="reqn">\Sigma</code> the mean and covariance
matrix of the bulk of the data and let <code class="reqn">\lfloor \cdot \rfloor</code>
be the operator that takes the integer part of its argument. As a measure of
the extremeness of the return observation <code class="reqn">r_t</code>, we use its squared
Mahalanobis distance <code class="reqn"> d^2_t = (r_t-\mu)'\Sigma^{-1}(r_t-\mu)</code>.  We
follow Rousseeuw(1985) by estimating <code class="reqn">\mu</code> and <code class="reqn">\Sigma</code> as the mean
vector and covariance matrix (corrected to ensure consistency) of the subset
of size <code class="reqn">\lfloor (1-\alpha)T\rfloor</code> for which the
determinant of the covariance matrix of the elements in that subset is the
smallest. These estimates will be robust against the <code class="reqn">\alpha</code> most
extreme returns. Let <code class="reqn">d^2_{(1)},...,d^2_{(T)}</code> be the ordered sequence
of the estimated squared Mahalanobis distances such that <code class="reqn">d^2_{(i)}\leq
d^2_{(i+1)}</code>.
</p>
</li>
<li> <p><em>Outlier identification.</em> Return observations are qualified as
outliers if their estimated squared Mahalanobis distance <code class="reqn">d^2_t</code> is
greater than the empirical <code class="reqn">1-\alpha</code> quantile <code class="reqn">d^2_{(\lfloor
(1-\alpha)T \rfloor)}</code> and exceeds a very extreme
quantile of the Chi squared distribution function with <code class="reqn">n</code> degrees of
freedom, which is the distribution function of <code class="reqn">d^2_t</code> when the returns
are normally distributed. In this application we take the 99.9% quantile,
denoted <code class="reqn">\chi ^2_{n,0.999}</code>.
</p>
</li>
<li> <p><em>Data cleaning. </em> Similarly to Khan(2007) we only clean the
returns that are identified as outliers in step 2 
by replacing these returns <code class="reqn">r_t</code> with 
</p>
<p style="text-align: center;"><code class="reqn">r_t\sqrt{\frac{\max(d^2_{(\lfloor(1-\alpha)T)\rfloor},\chi^2_{n,0.999})}{d^2_t}}</code>
</p>

<p>The cleaned
return vector has the same orientation as the original return vector, but
its magnitude is smaller. Khan(2007) calls this procedure of limiting the
value of <code class="reqn">d^2_t</code> to a quantile of the <code class="reqn">\chi^2_n</code> distribution,
&ldquo;multivariate Winsorization'.
</p>
</li></ol>

<p>Note that the primary value of data cleaning lies in creating a more robust
and stable estimation of the distribution describing the large majority of
the return data. The increased robustness and stability of the estimated
moments utilizing cleaned data should be used for portfolio construction. If
a portfolio manager wishes to have a more conservative risk estimate,
cleaning may not be indicated for risk monitoring. It is also important to
note that the robust method proposed here does not remove data from the
series, but only decreases the magnitude of the extreme events. It may also
be appropriate in practice to use a cleaning threshold somewhat outside the
VaR threshold that the manager wishes to consider. In actual practice, it is
probably best to back-test the results of both cleaned and uncleaned series
to see what works best with the particular combination of assets under
consideration.
</p>


<h3>Value</h3>

<p>cleaned data matrix
</p>


<h3>Note</h3>

<p>This function and much of this text was originally written for Boudt,
et. al, 2008
</p>


<h3>Author(s)</h3>

<p>Kris Boudt, Brian G. Peterson
</p>


<h3>References</h3>

<p>Boudt, K., Peterson, B. G., Croux, C., 2008. Estimation and
Decomposition of Downside Risk for Portfolios with Non-Normal Returns.
Journal of Risk, forthcoming.
</p>
<p>Khan, J. A., S. Van Aelst, and R. H. Zamar (2007). Robust linear model
selection based on least angle regression. Journal of the American
Statistical Association 102.
</p>
<p>Maronna, R. A., D. R. Martin, and V. J. Yohai (2006). Robust Statistics:
Theory and Methods. Wiley.
</p>
<p>Rousseeuw, P. J. (1985). Multivariate estimation with high breakdown point.
In W. Grossmann, G. Pflug, I. Vincze, and W. Wertz (Eds.), Mathematical
Statistics and Its Applications, Volume B, pp. 283?297. Dordrecht-Reidel.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Return.clean">Return.clean</a></code>
</p>

<hr>
<h2 id='CoMoments'>Functions for calculating comoments of financial time series</h2><span id='topic+CoMoments'></span><span id='topic+CoSkewnessMatrix'></span><span id='topic+CoKurtosisMatrix'></span><span id='topic+CoVariance'></span><span id='topic+CoSkewness'></span><span id='topic+CoKurtosis'></span><span id='topic+M3.MM'></span><span id='topic+M4.MM'></span>

<h3>Description</h3>

<p>calculates coskewness and cokurtosis as the skewness and kurtosis of two
assets with reference to one another.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoSkewnessMatrix(R, ...)

CoKurtosisMatrix(R, ...)

CoVariance(Ra, Rb)

CoSkewness(Ra, Rb)

CoKurtosis(Ra, Rb)

M3.MM(R, unbiased = FALSE, as.mat = TRUE, ...)

M4.MM(R, as.mat = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoMoments_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="CoMoments_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
<tr><td><code id="CoMoments_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="CoMoments_+3A_rb">Rb</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
index, benchmark, portfolio, or secondary asset returns to compare against</p>
</td></tr>
<tr><td><code id="CoMoments_+3A_unbiased">unbiased</code></td>
<td>
<p>TRUE/FALSE whether to use a correction to have an unbiased
estimator, default FALSE</p>
</td></tr>
<tr><td><code id="CoMoments_+3A_as.mat">as.mat</code></td>
<td>
<p>TRUE/FALSE whether to return the full moment matrix or only
the vector with the unique elements (the latter is advised for speed), default
TRUE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Ranaldo and Favre (2005) define coskewness and cokurtosis as the skewness
and kurtosis of a given asset analysed with the skewness and kurtosis of the
reference asset or portfolio.  Adding an asset to a portfolio, such as a
hedge fund with a significant level of coskewness to the portfolio, can
increase or decrease the resulting portfolio's skewness. Similarly, adding a
hedge fund with a positive cokurtosis coefficient will add kurtosis to the
portfolio.
</p>
<p>The co-moments are useful for measuring the marginal contribution of each
asset to the portfolio's resulting risk.  As such, comoments of asset return
distribution should be useful as inputs for portfolio optimization in
addition to the covariance matrix.  Martellini and Ziemann (2007) point out
that the problem of portfolio selection becomes one of selecting tangency
points in four dimensions, incorporating expected return, second, third and
fourth centered moments of asset returns.
</p>
<p>Even outside of the optimization problem, measuring the co-moments should be
a useful tool for evaluating whether or not an asset is likely to provide
diversification potential to a portfolio, not only in terms of normal risk
(i.e. volatility) but also the risk of assymetry (skewness) and extreme
events (kurtosis).
</p>


<h3>Author(s)</h3>

<p>Kris Boudt, Peter Carl, Dries Cornilly, Brian Peterson
</p>


<h3>References</h3>

<p>Boudt, Kris, Brian G. Peterson, and Christophe Croux. 2008.
Estimation and Decomposition of Downside Risk for Portfolios with Non-Normal
Returns. Journal of Risk. Winter.
</p>
<p>Boudt, Kris, Cornilly, Dries and Verdonck, Tim. 2017. A Coskewness Shrinkage 
Approach for Estimating the Skewness of Linear Combinations of Random Variables. 
Submitted. Available at SSRN: https://ssrn.com/abstract=2839781
</p>
<p>Martellini, L., &amp; Ziemann, V. 2010. Improved estimates of higher-order 
comoments and implications for portfolio selection. Review of Financial 
Studies, 23(4), 1467-1502.
</p>
<p>Ranaldo, Angelo, and Laurent Favre Sr. 2005. How to Price Hedge Funds: From
Two- to Four-Moment CAPM. SSRN eLibrary.
</p>
<p>Scott, Robert C., and Philip A. Horvath. 1980. On the Direction of
Preference for Moments of Higher Order than the Variance. Journal of Finance
35(4):915-919.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BetaCoSkewness">BetaCoSkewness</a></code> <br /> <code><a href="#topic+BetaCoKurtosis">BetaCoKurtosis</a></code> <br />
<code><a href="#topic+BetaCoMoments">BetaCoMoments</a></code> <br /> <code><a href="#topic+ShrinkageMoments">ShrinkageMoments</a></code> <br /> <code><a href="#topic+EWMAMoments">EWMAMoments</a></code>
<br /> <code><a href="#topic+StructuredMoments">StructuredMoments</a></code> <br /> <code><a href="#topic+MCA">MCA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
CoVariance(managers[, "HAM2", drop=FALSE], managers[, "SP500 TR", drop=FALSE])
CoSkewness(managers[, "HAM2", drop=FALSE], managers[, "SP500 TR", drop=FALSE])
CoKurtosis(managers[, "HAM2", drop=FALSE], managers[, "SP500 TR", drop=FALSE])

</code></pre>

<hr>
<h2 id='DownsideDeviation'>downside risk (deviation, variance) of the return distribution</h2><span id='topic+DownsideDeviation'></span><span id='topic+SemiDeviation'></span><span id='topic+SemiVariance'></span><span id='topic+DownsidePotential'></span><span id='topic+SemiSD'></span>

<h3>Description</h3>

<p>Downside deviation, semideviation, and semivariance are measures of downside
risk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DownsideDeviation(
  R,
  MAR = 0,
  method = c("full", "subset"),
  ...,
  potential = FALSE
)

DownsidePotential(R, MAR = 0)

SemiDeviation(R, SE = FALSE, SE.control = NULL, ...)

SemiSD(R, SE = FALSE, SE.control = NULL, ...)

SemiVariance(R)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DownsideDeviation_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="DownsideDeviation_+3A_mar">MAR</code></td>
<td>
<p>Minimum Acceptable Return, in the same periodicity as your
returns</p>
</td></tr>
<tr><td><code id="DownsideDeviation_+3A_method">method</code></td>
<td>
<p>one of &quot;full&quot; or &quot;subset&quot;, indicating whether to use the
length of the full series or the length of the subset of the series below
the MAR as the denominator, defaults to &quot;full&quot;</p>
</td></tr>
<tr><td><code id="DownsideDeviation_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
<tr><td><code id="DownsideDeviation_+3A_potential">potential</code></td>
<td>
<p>if TRUE, calculate downside potential instead, default
FALSE</p>
</td></tr>
<tr><td><code id="DownsideDeviation_+3A_se">SE</code></td>
<td>
<p>TRUE/FALSE whether to ouput the standard errors of the estimates of the risk measures, default FALSE. Only available for <code><a href="#topic+SemiDeviation">SemiDeviation</a></code> and <code><a href="#topic+SemiSD">SemiSD</a></code></p>
</td></tr>
<tr><td><code id="DownsideDeviation_+3A_se.control">SE.control</code></td>
<td>
<p>Control parameters for the computation of standard errors. Should be done using the <code><a href="#topic+RPESE.control">RPESE.control</a></code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Downside deviation, similar to semi deviation, eliminates positive returns
when calculating risk.  Instead of using the mean return or zero, it uses
the Minimum Acceptable Return as proposed by Sharpe (which may be the mean
historical return or zero). It measures the variability of underperformance
below a minimum targer rate. The downside variance is the square of the downside
potential.
</p>
<p>To calculate it, we take the subset of returns that are less than the target
(or Minimum Acceptable Returns (MAR)) returns and take the differences of
those to the target.  We sum the squares and divide by the total number of
returns to get a below-target semi-variance.
</p>
<p style="text-align: center;"><code class="reqn">DownsideDeviation(R , MAR) = \delta_{MAR} = \sqrt{\sum^{n}_{t=1}\frac{min[(R_{t} - MAR), 0]^2}{n}}</code>
</p>

<p style="text-align: center;"><code class="reqn"> DownsideVariance(R, MAR) = \sum^{n}_{t=1}\frac{min[(R_{t} - MAR), 0]^2}{n}</code>
</p>

<p style="text-align: center;"><code class="reqn">DownsidePotential(R, MAR) = \sum^{n}_{t=1}\frac{min[(R_{t} - MAR), 0]} {n}</code>
</p>

<p>where <code class="reqn">n</code> is either the number of observations of the entire series or
the number of observations in the subset of the series falling below the
MAR.
</p>
<p>SemiDeviation or SemiVariance is a popular alternative downside risk measure
that may be used in place of standard deviation or variance. SemiDeviation
and SemiVariance are implemented as a wrapper of DownsideDeviation with
MAR=mean(R).
</p>
<p>In many functions like Markowitz optimization, semideviation may be
substituted directly, and the covariance matrix may be constructed from
semideviation or the vector of returns below the mean rather than from
variance or the full vector of returns.
</p>
<p>In semideviation, by convention, the value of <code class="reqn">n</code> is set to the full
number of observations. In semivariance the the value of <code class="reqn">n</code> is set to
the subset of returns below the mean.  It should be noted that while this is
the correct mathematical definition of semivariance, this result doesn't
make any sense if you are also going to be using the time series of returns
below the mean or below a MAR to construct a semi-covariance matrix for
portfolio optimization.
</p>
<p>Sortino recommends calculating downside deviation utilizing a continuous
fitted distribution rather than the discrete distribution of observations.
This would have significant utility, especially in cases of a small number
of observations. He recommends using a lognormal distribution, or a fitted
distribution based on a relevant style index, to construct the returns below
the MAR to increase the confidence in the final result.  Hopefully, in the
future, we'll add a fitted option to this function, and would be happy to
accept a contribution of this nature.
</p>


<h3>Author(s)</h3>

<p>Peter Carl, Brian G. Peterson, Matthieu Lestel
</p>


<h3>References</h3>

<p>Sortino, F. and Price, L. Performance Measurement in a Downside
Risk Framework. <em>Journal of Investing</em>. Fall 1994, 59-65. <br /> 
Carl Bacon, <em>Practical portfolio performance measurement and attribution</em>, 
second edition 2008
</p>
<p>Plantinga, A., van der Meer, R. and Sortino, F. The Impact of Downside Risk
on Risk-Adjusted Performance of Mutual Funds in the Euronext Markets. July
19, 2001. Available at SSRN: <a href="http://ssrn.com/abstract=277352">http://ssrn.com/abstract=277352</a> <br />
</p>
<p><a href="http://www.sortino.com/htm/performance.htm">http://www.sortino.com/htm/performance.htm</a> see especially end note 10
</p>
<p><a href="http://en.wikipedia.org/wiki/Semivariance">http://en.wikipedia.org/wiki/Semivariance</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#with data used in Bacon 2008

data(portfolio_bacon)
MAR = 0.005
DownsideDeviation(portfolio_bacon[,1], MAR) #expected 0.0255
DownsidePotential(portfolio_bacon[,1], MAR) #expected 0.0137

#with data of managers

data(managers)
apply(managers[,1:6], 2, sd, na.rm=TRUE)
DownsideDeviation(managers[,1:6])  # MAR 0%
DownsideDeviation(managers[,1:6], MAR = .04/12) #MAR 4%
SemiDeviation(managers[,1,drop=FALSE])
SemiDeviation(managers[,1:6])
SemiVariance (managers[,1,drop=FALSE])
SemiVariance (managers[,1:6]) #calculated using method="subset"

</code></pre>

<hr>
<h2 id='DownsideFrequency'>downside frequency of the return distribution</h2><span id='topic+DownsideFrequency'></span>

<h3>Description</h3>

<p>To calculate Downside Frequency, we take the subset of returns that are
less than the target (or Minimum Acceptable Returns (MAR)) returns and
divide the length of this subset by the total number of returns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DownsideFrequency(R, MAR = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DownsideFrequency_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="DownsideFrequency_+3A_mar">MAR</code></td>
<td>
<p>Minimum Acceptable Return, in the same periodicity as your
returns</p>
</td></tr>
<tr><td><code id="DownsideFrequency_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn"> DownsideFrequency(R , MAR) = \sum^{n}_{t=1}\frac{min[(R_{t} - MAR),
 0]}{R_{t}*n}</code>
</p>

<p>where <code class="reqn">n</code> is the number of observations of the entire series
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.94
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(portfolio_bacon)
MAR = 0.005
print(DownsideFrequency(portfolio_bacon[,1], MAR)) #expected 0.458

data(managers)
print(DownsideFrequency(managers['1996']))
print(DownsideFrequency(managers['1996',1])) #expected 0.25

</code></pre>

<hr>
<h2 id='DRatio'>d ratio of the return distribution</h2><span id='topic+DRatio'></span>

<h3>Description</h3>

<p>The d ratio is similar to the Bernado Ledoit ratio but inverted and
taking into account the frequency of positive and negative returns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DRatio(R, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DRatio_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="DRatio_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It has values between zero and infinity. It can be used to rank the 
performance of portfolios. The lower the d ratio the better the 
performance, a value of zero indicating there are no returns less than
zero and a value of infinity indicating there are no returns greater than zero.
</p>
<p style="text-align: center;"><code class="reqn">DRatio(R) = \frac{n_{d}*\sum^{n}_{t=1}{max(-R_{t},0)}}{n_{u}*\sum^{n}_{t=1}
{max(R_{t},0)}}</code>
</p>

<p>where <code class="reqn">n</code> is the number of observations of the entire series,
<code class="reqn">n_{d}</code> is the number of observations less than zero,
<code class="reqn">n_{u}</code> is the number of observations greater than zero
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.95
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(portfolio_bacon)
print(DRatio(portfolio_bacon[,1])) #expected 0.401

data(managers)
print(DRatio(managers['1996']))
print(DRatio(managers['1996',1])) #expected 0.0725

</code></pre>

<hr>
<h2 id='DrawdownDeviation'>Calculates a standard deviation-type statistic using individual drawdowns.</h2><span id='topic+DrawdownDeviation'></span>

<h3>Description</h3>

<p>DD = sqrt(sum[j=1,2,...,d](D_j^2/n)) where
D_j = jth drawdown over the entire period
d = total number of drawdowns in entire period
n = number of observations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DrawdownDeviation(R, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DrawdownDeviation_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="DrawdownDeviation_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>

<hr>
<h2 id='DrawdownPeak'>Drawdawn peak of the return distribution</h2><span id='topic+DrawdownPeak'></span>

<h3>Description</h3>

<p>Drawdawn peak is for each return its drawdown since the previous peak
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DrawdownPeak(R, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DrawdownPeak_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="DrawdownPeak_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>

<hr>
<h2 id='Drawdowns'>Find the drawdowns and drawdown levels in a timeseries.</h2><span id='topic+Drawdowns'></span><span id='topic+findDrawdowns'></span>

<h3>Description</h3>

<p><code>findDrawdowns</code> will find the starting period, the ending period, and
the amount and length of the drawdown.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Drawdowns(R, geometric = TRUE, ...)

findDrawdowns(R, geometric = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Drawdowns_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="Drawdowns_+3A_geometric">geometric</code></td>
<td>
<p>utilize geometric chaining (TRUE) or simple/arithmetic chaining (FALSE) to aggregate returns,
default TRUE</p>
</td></tr>
<tr><td><code id="Drawdowns_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Often used with <code><a href="#topic+sortDrawdowns">sortDrawdowns</a></code> to get the largest drawdowns.
</p>
<p><code>Drawdowns</code> will calculate the drawdown levels as percentages, for use
in <code><a href="#topic+chart.Drawdown">chart.Drawdown</a></code>.
</p>
<p>Returns an unordered list: <br /> 
</p>
 
<ul>
<li><p> return depth of drawdown
</p>
</li>
<li><p> from starting period 
</p>
</li>
<li><p> to ending period </p>
</li>
<li><p> length length in periods 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Peter Carl
</p>
<p><code>findDrawdowns</code> modified with permission from function by Sankalp
Upadhyay
</p>


<h3>References</h3>

<p>Bacon, C. <em>Practical Portfolio Performance Measurement and
Attribution</em>. Wiley. 2004. p. 88 <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sortDrawdowns">sortDrawdowns</a></code> <br /> 
<code><a href="#topic+maxDrawdown">maxDrawdown</a></code> <br />
<code><a href="#topic+sortDrawdowns">sortDrawdowns</a></code> <br /> 
<code><a href="#topic+table.Drawdowns">table.Drawdowns</a></code> <br />
<code><a href="#topic+table.DownsideRisk">table.DownsideRisk</a></code> <br /> 
<code><a href="#topic+chart.Drawdown">chart.Drawdown</a></code> <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)
findDrawdowns(edhec[,"Funds of Funds", drop=FALSE])
sortDrawdowns(findDrawdowns(edhec[,"Funds of Funds", drop=FALSE]))

</code></pre>

<hr>
<h2 id='edhec'>EDHEC-Risk Hedge Fund Style Indices</h2><span id='topic+edhec'></span>

<h3>Description</h3>

<p>EDHEC composite hedge fund style index returns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>edhec</code></pre>


<h3>Format</h3>

<p>CSV conformed into an xts object with monthly observations</p>


<h3>Details</h3>

<p>EDHEC Data used in PerformanceAnalytics and related publications with the kind permission of the EDHEC Risk and Asset Management Research Center.
</p>
<p>The 'edhec' data set included with PerformanceAnalytics will be periodically updated (typically annually) to include additional observations.  If you intend to use this data set in automated tests, please be sure to subset your data like <code>edhec[1:120,]</code> to use the first ten years of observations.
</p>
<p>From the EDHEC website:
&ldquo;The EDHEC Risk and Asset Management Research Centre plays a noted role in furthering applied financial research and systematically highlighting its practical uses. As part of its philosophy, the centre maintains a dialogue with professionals which benefits the industry as a whole. At the same time, its proprietary R&amp;D provides sponsors with an edge over competition and joint ventures allow selected partners to develop new business opportunities.
</p>
<p>To further assist financial institutions and investors implement the latest research advances in order to meet the challenges of the changing asset management landscape, the centre has spawned two consultancies and an executive education arm. Clients of these derivative activities include many of the leading organisations throughout Europe.&rdquo;
</p>
<p>see <a href="http://www.edhec-risk.com/about_us">http://www.edhec-risk.com/about_us</a>
</p>


<h3>Source</h3>

<p><a href="http://www.edhec-risk.com/indexes/pure_style">http://www.edhec-risk.com/indexes/pure_style</a></p>


<h3>References</h3>

<p>About EDHEC Alternative Indexes. December 16, 2003. EDHEC-Risk. <br />
<a href="http://www.edhec-risk.com/indexes/pure_style/about">http://www.edhec-risk.com/indexes/pure_style/about</a>
</p>
<p>Vaissie Mathieu. A Detailed Analysis of the Construction Methods and Management Principles of Hedge Fund Indices. October 2003. EDHEC. <br />
<a href="http://www.edhec-risk.com/site_edhecrisk/public/indexes/EDHEC_Publications/RISKReview1072705188065793513">http://www.edhec-risk.com/site_edhecrisk/public/indexes/EDHEC_Publications/RISKReview1072705188065793513</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(edhec)

#preview the data
head(edhec)

#summary period statistics
summary(edhec)

#cumulative index returns
tail(cumprod(1+edhec),1)
</code></pre>

<hr>
<h2 id='ETL'>calculates Expected Shortfall(ES) (or Conditional Value-at-Risk(CVaR) for
univariate and component, using a variety of analytical methods.</h2><span id='topic+ETL'></span><span id='topic+ES'></span><span id='topic+CVaR'></span>

<h3>Description</h3>

<p>Calculates Expected Shortfall(ES) (also known as) Conditional Value at
Risk(CVaR) or Expected Tail Loss (ETL) for univariate, component, 
and marginal cases using a variety of analytical methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ETL(
  R = NULL,
  p = 0.95,
  ...,
  method = c("modified", "gaussian", "historical"),
  clean = c("none", "boudt", "geltner", "locScaleRob"),
  portfolio_method = c("single", "component"),
  weights = NULL,
  mu = NULL,
  sigma = NULL,
  m3 = NULL,
  m4 = NULL,
  invert = TRUE,
  operational = TRUE,
  SE = FALSE,
  SE.control = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ETL_+3A_r">R</code></td>
<td>
<p>a vector, matrix, data frame, timeSeries or zoo object of asset
returns</p>
</td></tr>
<tr><td><code id="ETL_+3A_p">p</code></td>
<td>
<p>confidence level for calculation, default p=.95</p>
</td></tr>
<tr><td><code id="ETL_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
<tr><td><code id="ETL_+3A_method">method</code></td>
<td>
<p>one of &quot;modified&quot;,&quot;gaussian&quot;,&quot;historical&quot;, see
Details.</p>
</td></tr>
<tr><td><code id="ETL_+3A_clean">clean</code></td>
<td>
<p>method for data cleaning through <code><a href="#topic+Return.clean">Return.clean</a></code>.
Current options are &quot;none&quot;, &quot;boudt&quot;, &quot;geltner&quot;, or &quot;locScaleRob&quot;.</p>
</td></tr>
<tr><td><code id="ETL_+3A_portfolio_method">portfolio_method</code></td>
<td>
<p>one of &quot;single&quot;,&quot;component&quot;,&quot;marginal&quot; defining
whether to do univariate, component, or marginal calc, see Details.</p>
</td></tr>
<tr><td><code id="ETL_+3A_weights">weights</code></td>
<td>
<p>portfolio weighting vector, default NULL, see Details</p>
</td></tr>
<tr><td><code id="ETL_+3A_mu">mu</code></td>
<td>
<p>If univariate, mu is the mean of the series. Otherwise mu is the
vector of means of the return series, default NULL, see Details</p>
</td></tr>
<tr><td><code id="ETL_+3A_sigma">sigma</code></td>
<td>
<p>If univariate, sigma is the variance of the series. Otherwise
sigma is the covariance matrix of the return series, default NULL, see
Details</p>
</td></tr>
<tr><td><code id="ETL_+3A_m3">m3</code></td>
<td>
<p>If univariate, m3 is the skewness of the series. Otherwise m3 is
the coskewness matrix (or vector with unique coskewness values) of the 
returns series, default NULL, see Details</p>
</td></tr>
<tr><td><code id="ETL_+3A_m4">m4</code></td>
<td>
<p>If univariate, m4 is the excess kurtosis of the series. Otherwise
m4 is the cokurtosis matrix (or vector with unique cokurtosis values) of the 
return series, default NULL, see Details</p>
</td></tr>
<tr><td><code id="ETL_+3A_invert">invert</code></td>
<td>
<p>TRUE/FALSE whether to invert the VaR measure, see Details.</p>
</td></tr>
<tr><td><code id="ETL_+3A_operational">operational</code></td>
<td>
<p>TRUE/FALSE, default TRUE, see Details.</p>
</td></tr>
<tr><td><code id="ETL_+3A_se">SE</code></td>
<td>
<p>TRUE/FALSE whether to ouput the standard errors of the estimates of the risk measures, default FALSE.</p>
</td></tr>
<tr><td><code id="ETL_+3A_se.control">SE.control</code></td>
<td>
<p>Control parameters for the computation of standard errors. Should be done using the <code><a href="#topic+RPESE.control">RPESE.control</a></code> function.</p>
</td></tr>
</table>


<h3>Background</h3>

<p>This function provides several estimation methods for
the Expected Shortfall (ES) (also called Expected Tail Loss (ETL)
or Conditional Value at Risk (CVaR)) of a return series and the Component ES
(ETL/CVaR) of a portfolio.
</p>
<p>At a preset probability level denoted <code class="reqn">c</code>, which typically is between 1
and 5 per cent, the ES of a return series is the negative value of the
expected value of the return when the return is less than its
<code class="reqn">c</code>-quantile.  Unlike value-at-risk, conditional value-at-risk has all
the properties a risk measure should have to be coherent and is a convex
function of the portfolio weights (Pflug, 2000).  With a sufficiently large
data set, you may choose to estimate ES with the sample average of all
returns that are below the <code class="reqn">c</code> empirical quantile. More efficient
estimates of VaR are obtained if a (correct) assumption is made on the
return distribution, such as the normal distribution. If your return series
is skewed and/or has excess kurtosis, Cornish-Fisher estimates of ES can be
more appropriate. For the ES of a portfolio, it is also of interest to
decompose total portfolio ES into the risk contributions of each of the
portfolio components. For the above mentioned ES estimators, such a
decomposition is possible in a financially meaningful way.
</p>


<h3>Univariate estimation of ES</h3>

<p>The ES at a probability level <code class="reqn">p</code> (e.g. 95%) is  the negative value of
the expected value of the return when the return is less than its
<code class="reqn">c=1-p</code> quantile. In a set of returns for which sufficently long history
exists, the per-period ES can be estimated by the negative value of the
sample average of all returns below the quantile. This method is also
sometimes called &ldquo;historical ES&rdquo;, as it is by definition <em>ex
post</em> analysis of the return distribution, and may be accessed with
<code>method="historical"</code>.
</p>
<p>When you don't have a sufficiently long set of returns to use non-parametric
or historical ES, or wish to more closely model an ideal distribution, it is
common to us a parmetric estimate based on the distribution. Parametric ES
does a better job of accounting for the tails of the distribution by more
precisely estimating shape of the distribution tails of the risk quantile.
The most common estimate is a normal (or Gaussian) distribution  <code class="reqn">R\sim
N(\mu,\sigma)</code> for the return series. In this case, estimation of ES requires
the mean return  <code class="reqn">\bar{R}</code>, the return distribution and the variance of
the returns  <code class="reqn">\sigma</code>. In the most common case, parametric VaR is thus
calculated by
</p>
<p style="text-align: center;"><code class="reqn">\sigma=variance(R)</code>
</p>

<p style="text-align: center;"><code class="reqn">ES=-\bar{R} + \sqrt{\sigma} \cdot \frac{1}{c}\phi(z_{c}) </code>
</p>

<p>where  <code class="reqn">z_{c}</code> is the  <code class="reqn">c</code>-quantile of the standard normal
distribution. Represented in <span class="rlang"><b>R</b></span> by <code>qnorm(c)</code>, and may be accessed with
<code>method="gaussian"</code>. The function <code class="reqn">\phi</code> is the Gaussian
density function.
</p>
<p>The limitations of Gaussian ES are well covered in the literature, since most
financial return series are non-normal. Boudt, Peterson and Croux (2008)
provide a modified ES calculation that takes the higher moments of non-normal
distributions (skewness, kurtosis) into account through the use of a
Cornish-Fisher expansion, and collapses to standard (traditional) Gaussian ES
if the return stream follows a standard distribution. More precisely, for a
loss probability <code class="reqn">c</code>, modified ES is defined as the negative of the
expected value of all returns below the <code class="reqn">c</code> Cornish-Fisher quantile and
where the expectation is computed under the second order Edgeworth expansion
of the true distribution function.
</p>
<p>Modified expected shortfall should always be larger than modified Value at
Risk. Due to estimation problems, this might not always be the case. Set
Operational = TRUE to replace modified ES with modified VaR in the
(exceptional) case where the modified ES is smaller than modified VaR.
</p>


<h3>Component ES</h3>

<p>By setting <code>portfolio_method="component"</code> you may calculate the ES
contribution of each element of the portfolio. The return from the function in
this case will be a list with three components: the univariate portfolio ES,
the scalar contribution of each component to the portfolio ES (these will sum
to the portfolio ES), and a percentage risk contribution (which will sum to
100%).
</p>
<p>Both the numerical and percentage component contributions to ES may contain
both positive and negative contributions. A negative contribution to Component
ES indicates a portfolio risk diversifier. Increasing the position weight will
reduce overall portoflio ES.
</p>
<p>If a weighting vector is not passed in via <code>weights</code>, the function will
assume an equal weighted (neutral) portfolio.
</p>
<p>Multiple risk decomposition approaches have been suggested in the literature.
A naive approach is to set the risk contribution equal to the stand-alone
risk. This approach is overly simplistic and neglects important
diversification effects of the units being exposed differently to the
underlying risk factors. An alternative approach is to measure the ES
contribution as the weight of the position in the portfolio times the partial
derivative of the portfolio ES with respect to the component weight. </p>
<p style="text-align: center;"><code class="reqn">C_i
\mbox{ES} = w_i \frac{ \partial \mbox{ES} }{\partial w_i}.</code>
</p>
<p> Because the portfolio ES is linear in position size, we
have that by Euler's theorem the portfolio VaR is the sum of these risk
contributions. Scaillet (2002) shows that for ES, this mathematical
decomposition of portfolio risk has a financial meaning. It equals the
negative value of the asset's expected contribution to the portfolio return
when the portfolio return is less or equal to the negative portfolio VaR:
</p>
<p style="text-align: center;"><code class="reqn">C_i \mbox{ES} = = -E\left[ w_i r_{i} | r_{p} \leq - \mbox{VaR}\right]</code>
</p>

<p>For the decomposition of Gaussian ES, the estimated mean and covariance
matrix are needed. For the decomposition of modified ES, also estimates of
the coskewness and cokurtosis matrices are needed. If <code class="reqn">r</code> denotes the
<code class="reqn">Nx1</code> return vector and <code class="reqn">mu</code> is the mean vector, then the <code class="reqn">N
\times N^2</code> co-skewness matrix is
</p>
<p style="text-align: center;"><code class="reqn"> m3 = E\left[ (r - \mu)(r - \mu)' \otimes (r - \mu)'\right]</code>
</p>

<p>The <code class="reqn">N \times N^3</code> co-kurtosis matrix is
</p>
<p style="text-align: center;"><code class="reqn"> m_{4} =
    E\left[ (r - \mu)(r - \mu)' \otimes (r - \mu)'\otimes (r - \mu)'
\right] </code>
</p>
 
<p>where <code class="reqn">\otimes</code> stands for the Kronecker product. The matrices can
be estimated through the functions <code>skewness.MM</code> and <code>kurtosis.MM</code>.
More efficient estimators were proposed by Martellini and Ziemann (2007) and
will be implemented in the future.
</p>
<p>As discussed among others in Cont, Deguest and Scandolo (2007), it is
important that the estimation of the ES measure is robust to single outliers.
This is especially the case for  modified VaR and its decomposition, since
they use higher order moments. By default, the portfolio moments are
estimated by their sample counterparts. If <code>clean="boudt"</code> then the
<code class="reqn">1-p</code> most extreme observations are winsorized if they are detected as
being outliers. For more information, see Boudt, Peterson and Croux (2008)
and <code><a href="#topic+Return.clean">Return.clean</a></code>.  If your data consist of returns for highly
illiquid assets, then <code>clean="geltner"</code> may be more appropriate to
reduce distortion caused by autocorrelation, see <code><a href="#topic+Return.Geltner">Return.Geltner</a></code>
for details.
</p>


<h3>Note</h3>

<p>The option to <code>invert</code> the ES measure should appease both
academics and practitioners.  The mathematical definition of ES as the
negative value of extreme losses will (usually) produce a positive number.
Practitioners will argue that ES denotes a loss, and should be internally
consistent with the quantile (a negative number).  For tables and charts,
different preferences may apply for clarity and compactness.  As such, we
provide the option, and set the default to TRUE to keep the return
consistent with prior versions of PerformanceAnalytics, but make no value
judgement on which approach is preferable.
</p>


<h3>Author(s)</h3>

<p>Brian G. Peterson and Kris Boudt
</p>


<h3>References</h3>

<p>Boudt, Kris, Peterson, Brian, and Christophe Croux. 2008.
Estimation and decomposition of downside risk for portfolios with non-normal
returns. 2008. The Journal of Risk, vol. 11, 79-103.
</p>
<p>Cont, Rama, Deguest, Romain and Giacomo Scandolo. Robustness and sensitivity
analysis of risk measurement procedures. Financial Engineering Report No.
2007-06, Columbia University Center for Financial Engineering.
</p>
<p>Laurent Favre and Jose-Antonio Galeano. Mean-Modified Value-at-Risk
Optimization with Hedge Funds. Journal of Alternative Investment, Fall 2002,
v 5.
</p>
<p>Martellini, L. and Ziemann, V., 2010. Improved estimates of higher-order 
comoments and implications for portfolio selection. Review of Financial 
Studies, 23(4):1467-1502.
</p>
<p>Pflug, G. Ch.  Some remarks on the value-at-risk and the conditional
value-at-risk. In S. Uryasev, ed., Probabilistic Constrained Optimization:
Methodology and Applications, Dordrecht: Kluwer, 2000, 272-281.
</p>
<p>Scaillet, Olivier. Nonparametric estimation and sensitivity analysis of
expected shortfall. Mathematical Finance, 2002, vol. 14, 74-86.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VaR">VaR</a></code> <br /> <code><a href="#topic+SharpeRatio.modified">SharpeRatio.modified</a></code> <br />
<code><a href="#topic+chart.VaRSensitivity">chart.VaRSensitivity</a></code> <br /> <code><a href="#topic+Return.clean">Return.clean</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if(!( Sys.info()[['sysname']]=="Windows") ){
# if on Windows, cut and paste this example

    data(edhec)

    # first do normal ES calc
    ES(edhec, p=.95, method="historical")

    # now use Gaussian
    ES(edhec, p=.95, method="gaussian")

    # now use modified Cornish Fisher calc to take non-normal distribution into account
    ES(edhec, p=.95, method="modified")

    # now use p=.99
    ES(edhec, p=.99)
    # or the equivalent alpha=.01
    ES(edhec, p=.01)

    # now with outliers squished
    ES(edhec, clean="boudt")

    # add Component ES for the equal weighted portfolio
    ES(edhec, clean="boudt", portfolio_method="component")

} # end CRAN Windows check
    
</code></pre>

<hr>
<h2 id='EWMAMoments'>Functions for calculating EWMA comoments of financial time series</h2><span id='topic+EWMAMoments'></span><span id='topic+M2.ewma'></span><span id='topic+M3.ewma'></span><span id='topic+M4.ewma'></span>

<h3>Description</h3>

<p>calculates exponentially weighted moving average covariance, coskewness and cokurtosis matrices
</p>


<h3>Usage</h3>

<pre><code class='language-R'>M2.ewma(R, lambda = 0.97, last.M2 = NULL, ...)

M3.ewma(R, lambda = 0.97, last.M3 = NULL, as.mat = TRUE, ...)

M4.ewma(R, lambda = 0.97, last.M4 = NULL, as.mat = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EWMAMoments_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns (with mean zero)</p>
</td></tr>
<tr><td><code id="EWMAMoments_+3A_lambda">lambda</code></td>
<td>
<p>decay coefficient</p>
</td></tr>
<tr><td><code id="EWMAMoments_+3A_last.m2">last.M2</code></td>
<td>
<p>last estimated covariance matrix before the observed returns R</p>
</td></tr>
<tr><td><code id="EWMAMoments_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
<tr><td><code id="EWMAMoments_+3A_last.m3">last.M3</code></td>
<td>
<p>last estimated coskewness matrix before the observed returns R</p>
</td></tr>
<tr><td><code id="EWMAMoments_+3A_as.mat">as.mat</code></td>
<td>
<p>TRUE/FALSE whether to return the full moment matrix or only
the vector with the unique elements (the latter is advised for speed), default
TRUE</p>
</td></tr>
<tr><td><code id="EWMAMoments_+3A_last.m4">last.M4</code></td>
<td>
<p>last estimated cokurtosis matrix before the observed returns R</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The coskewness and cokurtosis matrices are defined as the matrices of dimension 
p x p^2 and p x p^3 containing the third and fourth order central moments. They
are useful for measuring nonlinear dependence between different assets of the 
portfolio and computing modified VaR and modified ES of a portfolio.
</p>
<p>EWMA estimation of the covariance matrix was popularized by the RiskMetrics report in 1996.
The M3.ewma and M4.ewma are straightforward extensions to the setting of third and fourth
order central moments
</p>


<h3>Author(s)</h3>

<p>Dries Cornilly
</p>


<h3>References</h3>

<p>JP Morgan. Riskmetrics technical document. 1996.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CoMoments">CoMoments</a></code> <br /> <code><a href="#topic+ShrinkageMoments">ShrinkageMoments</a></code> <br /> <code><a href="#topic+StructuredMoments">StructuredMoments</a></code> <br /> <code><a href="#topic+MCA">MCA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)

# EWMA estimation
# 'as.mat = F' would speed up calculations in higher dimensions
sigma &lt;- M2.ewma(edhec, 0.94)
m3 &lt;- M3.ewma(edhec, 0.94)
m4 &lt;- M4.ewma(edhec, 0.94)

# compute equal-weighted portfolio modified ES 
mu &lt;- colMeans(edhec)
p &lt;- length(mu)
ES(p = 0.95, portfolio_method = "component", weights = rep(1 / p, p), mu = mu, 
    sigma = sigma, m3 = m3, m4 = m4)

# compare to sample method
sigma &lt;- cov(edhec)
m3 &lt;- M3.MM(edhec)
m4 &lt;- M4.MM(edhec)
ES(p = 0.95, portfolio_method = "component", weights = rep(1 / p, p), mu = mu, 
    sigma = sigma, m3 = m3, m4 = m4)

</code></pre>

<hr>
<h2 id='FamaBeta'>Fama beta of the return distribution</h2><span id='topic+FamaBeta'></span>

<h3>Description</h3>

<p>Fama beta is a beta used to calculate the loss of diversification. It is made
so that the systematic risk is equivalent to the total portfolio risk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FamaBeta(Ra, Rb, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FamaBeta_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="FamaBeta_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="FamaBeta_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">\beta_F = \frac{\sigma_P}{\sigma_M}</code>
</p>

<p>where <code class="reqn">\sigma_P</code> is the portfolio standard deviation and <code class="reqn">\sigma_M</code> is the
market risk
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.78
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(portfolio_bacon)
print(FamaBeta(portfolio_bacon[,1], portfolio_bacon[,2])) #expected 1.03

data(managers)
print(FamaBeta(managers['1996',1], managers['1996',8]))
print(FamaBeta(managers['1996',1:5], managers['1996',8]))

</code></pre>

<hr>
<h2 id='Frequency'>Frequency of the return distribution</h2><span id='topic+Frequency'></span>

<h3>Description</h3>

<p>Gives the period of the return distribution (ie 12 if monthly return, 4 if quarterly return)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Frequency(R, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Frequency_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="Frequency_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(portfolio_bacon)
print(Frequency(portfolio_bacon[,1])) #expected 12
data(managers)
print(Frequency(managers['1996',1:5]))

</code></pre>

<hr>
<h2 id='HurstIndex'>calculate the Hurst Index
The Hurst index can be used to measure whether returns are mean reverting,
totally random, or persistent.</h2><span id='topic+HurstIndex'></span>

<h3>Description</h3>

<p>Hurst obtained a dimensionless statistical exponent by dividing the range 
by the standard deviation of the observations, 
so this approach is commonly referred to as rescaled range (R/S) analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HurstIndex(R, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HurstIndex_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of asset returns</p>
</td></tr>
<tr><td><code id="HurstIndex_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">H = log(m)/log(n)</code>
</p>
 
<p>where
<code class="reqn">m = [max(r_i) - min(r_i)]/sigma_p</code> and
<code class="reqn">n = number of observations</code>
A Hurst index between 0.5 and 1 suggests that the returns are persistent.
At 0.5, the index suggests returns are totally random.  Between 0 and 0.5
it suggests that the returns are mean reverting.
</p>
<p>H.E. Hurst originally developed the Hurst index to help establish optimal
water storage along the Nile.  Nile floods are extremely persistent,
measuring a Hurst index of 0.9.  Peters (1991) notes that Equity markets 
have a Hurst index in excess of 0.5, with typical values of around 0.7.
That appears to be anomalous in the context of the mainstream 'rational 
behaviour' theories of economics, and suggests existence of a powerful
'long-term memory' causal dependence.  Clarkson (2001) suggests that an
'over-reaction bias' could be expected to generate a powerful 'long-term
memory' effect in share prices.
</p>


<h3>References</h3>

<p>Clarkson, R. (2001) FARM: a financial actuarial risk model.  In Chapter
12 of Managing Downside Risk in Financial Markets, ed. Sortino, F.  
and Satchel, S.  Woburn MA. Butterworth-Heinemann Finance.
</p>
<p>Peters, E.E (1991) Chaos and Order in Capital Markets, New York: Wiley.
</p>
<p>Bacon, Carl. (2008) Practical Portfolio Performance Measurement and Attribution, 2nd Edition. London: John Wiley &amp; Sons.
</p>

<hr>
<h2 id='InformationRatio'>InformationRatio = ActivePremium/TrackingError</h2><span id='topic+InformationRatio'></span>

<h3>Description</h3>

<p>The Active Premium divided by the Tracking Error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>InformationRatio(Ra, Rb, scale = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="InformationRatio_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="InformationRatio_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="InformationRatio_+3A_scale">scale</code></td>
<td>
<p>number of periods in a year (daily scale = 252, monthly scale =
12, quarterly scale = 4)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>InformationRatio = ActivePremium/TrackingError
</p>
<p>This relates the degree to which an investment has beaten the benchmark to
the consistency with which the investment has beaten the benchmark.
</p>


<h3>Note</h3>

<p>William Sharpe now recommends <code>InformationRatio</code> preferentially
to the original <code><a href="#topic+SharpeRatio">SharpeRatio</a></code>.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>Sharpe, W.F. The Sharpe Ratio,<em>Journal of Portfolio
Management</em>,Fall 1994, 49-58.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+TrackingError">TrackingError</a></code> <br /> <code><a href="#topic+ActivePremium">ActivePremium</a></code> <br />
<code><a href="#topic+SharpeRatio">SharpeRatio</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
InformationRatio(managers[,"HAM1",drop=FALSE], managers[, "SP500 TR", drop=FALSE])
InformationRatio(managers[,1:6], managers[,8,drop=FALSE])
InformationRatio(managers[,1:6], managers[,8:7])

</code></pre>

<hr>
<h2 id='Kappa'>Kappa of the return distribution</h2><span id='topic+Kappa'></span>

<h3>Description</h3>

<p>Introduced by Kaplan and Knowles (2004), Kappa is a generalized
downside risk-adjusted performance measure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Kappa(R, MAR, l, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Kappa_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="Kappa_+3A_mar">MAR</code></td>
<td>
<p>Minimum Acceptable Return, in the same periodicity as your
returns</p>
</td></tr>
<tr><td><code id="Kappa_+3A_l">l</code></td>
<td>
<p>the coefficient of the Kappa</p>
</td></tr>
<tr><td><code id="Kappa_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To calculate it, we take the difference of the mean of the distribution
to the target and we divide it by the l-root of the lth lower partial
moment. To calculate the lth lower partial moment we take the subset of
returns below the target and we sum the differences of the target to
these returns. We then return return this sum divided by the length of
the whole distribution.
</p>
<p style="text-align: center;"><code class="reqn">Kappa(R, MAR, l) = \frac{r_{p}-MAR}{\sqrt[l]{\frac{1}{n}*\sum^n_{t=1}
max(MAR-R_{t}, 0)^l}}</code>
</p>

<p>For l=1 kappa is the Sharpe-omega ratio and for l=2 kappa
is the sortino ratio.
</p>
<p>Kappa should only be used to rank portfolios as it is difficult to
interpret the absolute differences between kappas. The higher the
kappa is, the better.
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.96
</p>


<h3>Examples</h3>

<pre><code class='language-R'>l = 2

data(portfolio_bacon)
MAR = 0.005
print(Kappa(portfolio_bacon[,1], MAR, l)) #expected 0.157

data(managers)
MAR = 0
print(Kappa(managers['1996'], MAR, l))
print(Kappa(managers['1996',1], MAR, l)) #expected 1.493

</code></pre>

<hr>
<h2 id='KellyRatio'>calculate Kelly criterion ratio (leverage or bet size) for a strategy</h2><span id='topic+KellyRatio'></span>

<h3>Description</h3>

<p>Kelly criterion ratio (leverage or bet size) for a strategy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KellyRatio(R, Rf = 0, method = "half")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KellyRatio_+3A_r">R</code></td>
<td>
<p>a vector of returns to perform a mean over</p>
</td></tr>
<tr><td><code id="KellyRatio_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="KellyRatio_+3A_method">method</code></td>
<td>
<p>method=half will use the half-Kelly, this is the default</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Kelly Criterion was identified by Bell Labs scientist John Kelly, and
applied to blackjack and stock strategy sizing by Ed Thorpe.
</p>
<p>The Kelly ratio can be simply stated as: &ldquo;bet size is the ratio of
edge over odds.&rdquo; Mathematically, you are maximizing log-utility.  As such,
the Kelly criterion is equal to the expected excess return of the strategy
divided by the expected variance of the excess return, or
</p>
<p style="text-align: center;"><code class="reqn">leverage=\frac{(\overline{R}_{s}-R_{f})}{StdDev(R)^{2}}</code>
</p>

<p>As a performance metric, the Kelly Ratio is calculated retrospectively on a
particular investment as a measure of the edge that investment has over the
risk free rate.  It may be use as a stack ranking method to compare
investments in a manner similar to the various ratios related to the Sharpe
ratio.
</p>


<h3>Author(s)</h3>

<p>Brian G. Peterson
</p>


<h3>References</h3>

<p>Thorp, Edward O. (1997; revised 1998). The Kelly Criterion in
Blackjack, Sports Betting, and the Stock Market.
<a href="http://www.bjmath.com/bjmath/thorp/paper.htm">http://www.bjmath.com/bjmath/thorp/paper.htm</a> <br />
<a href="http://en.wikipedia.org/wiki/Kelly_criterion">http://en.wikipedia.org/wiki/Kelly_criterion</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
    data(managers)
    KellyRatio(managers[,1,drop=FALSE], Rf=.04/12)
    KellyRatio(managers[,1,drop=FALSE], Rf=managers[,10,drop=FALSE])
    KellyRatio(managers[,1:6], Rf=managers[,10,drop=FALSE])

</code></pre>

<hr>
<h2 id='kurtosis'>Kurtosis</h2><span id='topic+kurtosis'></span>

<h3>Description</h3>

<p>compute kurtosis of a univariate distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kurtosis(
  x,
  na.rm = FALSE,
  method = c("excess", "moment", "fisher", "sample", "sample_excess"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kurtosis_+3A_x">x</code></td>
<td>
<p>a numeric vector or object.</p>
</td></tr>
<tr><td><code id="kurtosis_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical. Should missing values be removed?</p>
</td></tr>
<tr><td><code id="kurtosis_+3A_method">method</code></td>
<td>
<p>a character string which specifies the method of computation.
These are either <code>"moment"</code>, <code>"fisher"</code>, or <code>"excess"</code>.  If
<code>"excess"</code> is selected, then the value of the kurtosis is computed by
the <code>"moment"</code> method and a value of 3 will be subtracted.  The
<code>"moment"</code> method is based on the definitions of kurtosis for
distributions; these forms should be used when resampling (bootstrap or
jackknife). The <code>"fisher"</code> method correspond to the usual &quot;unbiased&quot;
definition of sample variance, although in the case of kurtosis exact
unbiasedness is not possible. The <code>"sample"</code> method gives the sample
kurtosis of the distribution.</p>
</td></tr>
<tr><td><code id="kurtosis_+3A_...">...</code></td>
<td>
<p>arguments to be passed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function was ported from the RMetrics package fUtilities to eliminate a
dependency on fUtilties being loaded every time.  This function is identical
except for the addition of <code><a href="#topic+checkData">checkData</a></code> and additional labeling.
</p>
<p style="text-align: center;"><code class="reqn">Kurtosis(moment) = \frac{1}{n}*\sum^{n}_{i=1}(\frac{r_i - \overline{r}}{\sigma_P})^4</code>
</p>

<p style="text-align: center;"><code class="reqn">Kurtosis(excess) = \frac{1}{n}*\sum^{n}_{i=1}(\frac{r_i - \overline{r}}{\sigma_P})^4 - 3</code>
</p>

<p style="text-align: center;"><code class="reqn">Kurtosis(sample) =  \frac{n*(n+1)}{(n-1)*(n-2)*(n-3)}*\sum^{n}_{i=1}(\frac{r_i - \overline{r}}{\sigma_{S_P}})^4 </code>
</p>

<p style="text-align: center;"><code class="reqn">Kurtosis(fisher) = \frac{(n+1)*(n-1)}{(n-2)*(n-3)}*(\frac{\sum^{n}_{i=1}\frac{(r_i)^4}{n}}{(\sum^{n}_{i=1}(\frac{(r_i)^2}{n})^2} - \frac{3*(n-1)}{n+1})</code>
</p>

<p style="text-align: center;"><code class="reqn">Kurtosis(sample excess) =  \frac{n*(n+1)}{(n-1)*(n-2)*(n-3)}*\sum^{n}_{i=1}(\frac{r_i - \overline{r}}{\sigma_{S_P}})^4  - \frac{3*(n-1)^2}{(n-2)*(n-3)}</code>
</p>

<p>where <code class="reqn">n</code> is the number of return, <code class="reqn">\overline{r}</code> is the mean of the return
distribution, <code class="reqn">\sigma_P</code> is its standard deviation and <code class="reqn">\sigma_{S_P}</code> is its
sample standard deviation
</p>


<h3>Author(s)</h3>

<p>Diethelm Wuertz, Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.84-85
</p>


<h3>See Also</h3>

<p><code><a href="#topic+skewness">skewness</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## mean -
## var -
   # Mean, Variance:
   r = rnorm(100)
   mean(r)
   var(r)

## kurtosis -
   kurtosis(r)

data(managers)
kurtosis(managers[,1:8])

data(portfolio_bacon)
print(kurtosis(portfolio_bacon[,1], method="sample")) #expected 3.03
print(kurtosis(portfolio_bacon[,1], method="sample_excess")) #expected -0.41
print(kurtosis(managers['1996'], method="sample"))
print(kurtosis(managers['1996',1], method="sample"))

</code></pre>

<hr>
<h2 id='legend'>internal functions for setting useful defaults for graphs</h2><span id='topic+legend'></span><span id='topic+PerformanceAnalytics.internal'></span><span id='topic+bluefocus'></span><span id='topic+bluemono'></span><span id='topic+dark6equal'></span><span id='topic+dark8equal'></span><span id='topic+greenfocus'></span><span id='topic+greenmono'></span><span id='topic+grey6mono'></span><span id='topic+grey8mono'></span><span id='topic+rainbow10equal'></span><span id='topic+rainbow12equal'></span><span id='topic+rainbow6equal'></span><span id='topic+rainbow8equal'></span><span id='topic+redfocus'></span><span id='topic+redmono'></span><span id='topic+rich10equal'></span><span id='topic+rich12equal'></span><span id='topic+rich6equal'></span><span id='topic+rich8equal'></span><span id='topic+set6equal'></span><span id='topic+set8equal'></span><span id='topic+tim10equal'></span><span id='topic+tim12equal'></span><span id='topic+tim6equal'></span><span id='topic+tim8equal'></span><span id='topic+bond.dates'></span><span id='topic+bond.labels'></span><span id='topic+cycles.dates'></span><span id='topic+equity.dates'></span><span id='topic+equity.labels'></span><span id='topic+macro.dates'></span><span id='topic+macro.labels'></span><span id='topic+risk.dates'></span><span id='topic+risk.labels'></span><span id='topic+allsymbols'></span><span id='topic+closedsymbols'></span><span id='topic+fillsymbols'></span><span id='topic+linesymbols'></span><span id='topic+opensymbols'></span><span id='topic+tol1qualitative'></span><span id='topic+tol2qualitative'></span><span id='topic+tol3qualitative'></span><span id='topic+tol4qualitative'></span><span id='topic+tol5qualitative'></span><span id='topic+tol6qualitative'></span><span id='topic+tol7qualitative'></span><span id='topic+tol8qualitative'></span><span id='topic+tol9qualitative'></span><span id='topic+tol10qualitative'></span><span id='topic+tol11qualitative'></span><span id='topic+tol12qualitative'></span><span id='topic+tol14rainbow'></span><span id='topic+tol15rainbow'></span><span id='topic+tol18rainbow'></span><span id='topic+tol21rainbow'></span>

<h3>Description</h3>

<p>Internal functions and data objects to make graphs easier to read, and
better for print and presentation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>legend(
  x,
  y = NULL,
  legend,
  fill = NULL,
  col = par("col"),
  lty,
  lwd,
  pch,
  angle = 45,
  density = NULL,
  bty = "o",
  bg = par("bg"),
  pt.bg = NA,
  cex = 1,
  pt.cex = cex,
  pt.lwd = lwd,
  xjust = 0,
  yjust = 1,
  x.intersp = 1,
  y.intersp = 1,
  adj = c(0, 0.5),
  text.width = NULL,
  text.col = par("col"),
  merge = do.lines &amp;&amp; has.pch,
  trace = FALSE,
  plot = TRUE,
  ncol = 1,
  horiz = FALSE,
  title = NULL,
  inset = 0,
  border.col = NULL,
  border.lwd = 1,
  border.lty = "solid",
  box.col = NULL,
  box.lwd = 1,
  box.lty = "solid",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="legend_+3A_x">x</code>, <code id="legend_+3A_y">y</code></td>
<td>
<p>the x and y co-ordinates to be used to position the legend.  They
can be specified by keyword or in any way which is accepted by
<code><a href="grDevices.html#topic+xy.coords">xy.coords</a></code>: See Details.</p>
</td></tr>
<tr><td><code id="legend_+3A_legend">legend</code></td>
<td>
<p>a character or <a href="base.html#topic+expression">expression</a> vector.  of length <code class="reqn">\ge
1</code> to appear in the legend.</p>
</td></tr>
<tr><td><code id="legend_+3A_fill">fill</code></td>
<td>
<p>if specified, this argument will cause boxes filled with the
specified colors (or shaded in the specified colors) to appear beside the
legend text.</p>
</td></tr>
<tr><td><code id="legend_+3A_col">col</code></td>
<td>
<p>the color of points or lines appearing in the legend.</p>
</td></tr>
<tr><td><code id="legend_+3A_lty">lty</code>, <code id="legend_+3A_lwd">lwd</code></td>
<td>
<p>the line types and widths for lines appearing in the legend.
One of these two <em>must</em> be specified for line drawing.</p>
</td></tr>
<tr><td><code id="legend_+3A_pch">pch</code></td>
<td>
<p>the plotting symbols appearing in the legend, either as vector of
1-character strings, or one (multi character) string.  <em>Must</em> be
specified for symbol drawing.</p>
</td></tr>
<tr><td><code id="legend_+3A_angle">angle</code></td>
<td>
<p>angle of shading lines.</p>
</td></tr>
<tr><td><code id="legend_+3A_density">density</code></td>
<td>
<p>the density of shading lines, if numeric and positive. If
<code>NULL</code> or negative or <code>NA</code> color filling is assumed.</p>
</td></tr>
<tr><td><code id="legend_+3A_bty">bty</code></td>
<td>
<p>the type of box to be drawn around the legend.  The allowed
values are <code>"o"</code> (the default) and <code>"n"</code>.</p>
</td></tr>
<tr><td><code id="legend_+3A_bg">bg</code></td>
<td>
<p>the background color for the legend box.  (Note that this is only
used if <code>bty != "n"</code>.)</p>
</td></tr>
<tr><td><code id="legend_+3A_pt.bg">pt.bg</code></td>
<td>
<p>the background color for the <code><a href="graphics.html#topic+points">points</a></code>,
corresponding to its argument <code>bg</code>.</p>
</td></tr>
<tr><td><code id="legend_+3A_cex">cex</code></td>
<td>
<p>character expansion factor <b>relative</b> to current
<code>par("cex")</code>.</p>
</td></tr>
<tr><td><code id="legend_+3A_pt.cex">pt.cex</code></td>
<td>
<p>expansion factor(s) for the points.</p>
</td></tr>
<tr><td><code id="legend_+3A_pt.lwd">pt.lwd</code></td>
<td>
<p>line width for the points, defaults to the one for lines, or
if that is not set, to <code>par("lwd")</code>.</p>
</td></tr>
<tr><td><code id="legend_+3A_xjust">xjust</code></td>
<td>
<p>how the legend is to be justified relative to the legend x
location.  A value of 0 means left justified, 0.5 means centered and 1 means
right justified.</p>
</td></tr>
<tr><td><code id="legend_+3A_yjust">yjust</code></td>
<td>
<p>the same as <code>xjust</code> for the legend y location.</p>
</td></tr>
<tr><td><code id="legend_+3A_x.intersp">x.intersp</code></td>
<td>
<p>character interspacing factor for horizontal (x) spacing.</p>
</td></tr>
<tr><td><code id="legend_+3A_y.intersp">y.intersp</code></td>
<td>
<p>the same for vertical (y) line distances.</p>
</td></tr>
<tr><td><code id="legend_+3A_adj">adj</code></td>
<td>
<p>numeric of length 1 or 2; the string adjustment for legend text.
Useful for y-adjustment when <code>labels</code> are <a href="grDevices.html#topic+plotmath">plotmath</a> expressions.</p>
</td></tr>
<tr><td><code id="legend_+3A_text.width">text.width</code></td>
<td>
<p>the width of the legend text in x (<code>"user"</code>)
coordinates.  (Should be positive even for a reversed x axis.)  Defaults to
the proper value computed by <code><a href="graphics.html#topic+strwidth">strwidth</a>(legend)</code>.</p>
</td></tr>
<tr><td><code id="legend_+3A_text.col">text.col</code></td>
<td>
<p>the color used for the legend text.</p>
</td></tr>
<tr><td><code id="legend_+3A_merge">merge</code></td>
<td>
<p>logical; if <code>TRUE</code>, &ldquo;merge&rdquo; points and lines but
not filled boxes.  Defaults to <code>TRUE</code> if there are points and lines.</p>
</td></tr>
<tr><td><code id="legend_+3A_trace">trace</code></td>
<td>
<p>logical; if <code>TRUE</code>, shows how <code>legend</code> does all its
magical computations.</p>
</td></tr>
<tr><td><code id="legend_+3A_plot">plot</code></td>
<td>
<p>logical.  If <code>FALSE</code>, nothing is plotted but the sizes are
returned.</p>
</td></tr>
<tr><td><code id="legend_+3A_ncol">ncol</code></td>
<td>
<p>the number of columns in which to set the legend items (default
is 1, a vertical legend).</p>
</td></tr>
<tr><td><code id="legend_+3A_horiz">horiz</code></td>
<td>
<p>logical; if <code>TRUE</code>, set the legend horizontally rather
than vertically (specifying <code>horiz</code> overrides the <code>ncol</code>
specification).</p>
</td></tr>
<tr><td><code id="legend_+3A_title">title</code></td>
<td>
<p>a character string or length-one expression giving a title to
be placed at the top of the legend.</p>
</td></tr>
<tr><td><code id="legend_+3A_inset">inset</code></td>
<td>
<p>inset distance(s) from the margins as a fraction of the plot
region when legend is placed by keyword.</p>
</td></tr>
<tr><td><code id="legend_+3A_border.lty">border.lty</code>, <code id="legend_+3A_border.lwd">border.lwd</code></td>
<td>
<p>the line type and width for the legend border.</p>
</td></tr>
<tr><td><code id="legend_+3A_box.lty">box.lty</code>, <code id="legend_+3A_box.lwd">box.lwd</code></td>
<td>
<p>the line type and width for the legend box.</p>
</td></tr>
<tr><td><code id="legend_+3A_...">...</code></td>
<td>
<p>any other passthrough parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Also contains common economic cycle dates and dates of serious market events
per asset class.
</p>
<p>All items ending in .labels or .dates contain labels or dates that would be
appropriate for specific asset classes or economic cycles.
</p>
<p><code>legend</code> is a wrapper function for <code><a href="graphics.html#topic+legend">legend</a></code> to
better handle placement and formatting of a legend for the charts
</p>
<p>all objects ending in symbol are symbol sets for line charts.
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+legend">legend</a></code>
</p>

<hr>
<h2 id='Level.calculate'>Calculate appropriate cumulative return series or asset level using xts attribute information</h2><span id='topic+Level.calculate'></span>

<h3>Description</h3>

<p>This function calculates the time varying index level over 
the entire period of available data.  It will work with arithmetic or log returns, using attribute information from an xts object.
If the first value in the left-most column is NA, it will be populated with the seedValue.  
However, if the first value in the left-most column is not NA, the previous date will be estimated
based on the periodicity of the time series, and be populated with the seedValue.
This is so that information is not lost in case levels are converted back to returns 
(where the first value would result in an NA).  Note: previous date does not consider weekdays or
holidays, it will simply calculate the previous calendar day.  
If the user has a preference, they should ensure that the first row has the appropriate time index with an NA value.  
If users run Return.calculate() from this package, this will be a non-issue.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Level.calculate(R, seedValue = NULL, initial = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Level.calculate_+3A_r">R</code></td>
<td>
<p>an xts object</p>
</td></tr>
<tr><td><code id="Level.calculate_+3A_seedvalue">seedValue</code></td>
<td>
<p>a numeric scalar indicating the (usually initial) index level or price of the series</p>
</td></tr>
<tr><td><code id="Level.calculate_+3A_initial">initial</code></td>
<td>
<p>(default TRUE) a TRUE/FALSE flag associated with 'seedValue', indicating if this value is at the begginning of the series (TRUE) or at the end of the series (FALSE)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Product of all the individual period returns
</p>
<p>For arithmetic returns:
</p>
<p style="text-align: center;"><code class="reqn">(1+r_{1})(1+r_{2})(1+r_{3})\ldots(1+r_{n})=cumprod(1+R)</code>
</p>

<p>For log returns:
</p>
<p style="text-align: center;"><code class="reqn">exp(r_{1}+r_{2}+r_{3} + \ldots + r_{n})=exp(cumsum(R))</code>
</p>



<h3>Author(s)</h3>

<p>Erol Biceroglu
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Return.calculate">Return.calculate</a></code>
</p>

<hr>
<h2 id='lpm'>calculate a lower partial moment for a time series</h2><span id='topic+lpm'></span>

<h3>Description</h3>

<p>Caclulate a Lower Partial Moment around the mean or a specified threshold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lpm(
  R,
  n = 2,
  threshold = 0,
  about_mean = FALSE,
  SE = FALSE,
  SE.control = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lpm_+3A_r">R</code></td>
<td>
<p>xts data</p>
</td></tr>
<tr><td><code id="lpm_+3A_n">n</code></td>
<td>
<p>the n-th moment to return</p>
</td></tr>
<tr><td><code id="lpm_+3A_threshold">threshold</code></td>
<td>
<p>threshold can be the mean or any point as desired</p>
</td></tr>
<tr><td><code id="lpm_+3A_about_mean">about_mean</code></td>
<td>
<p>TRUE/FALSE calculate LPM about the mean under the threshold or use the threshold to calculate the LPM around (if FALSE)</p>
</td></tr>
<tr><td><code id="lpm_+3A_se">SE</code></td>
<td>
<p>TRUE/FALSE whether to ouput the standard errors of the estimates of the risk measures, default FALSE.</p>
</td></tr>
<tr><td><code id="lpm_+3A_se.control">SE.control</code></td>
<td>
<p>Control parameters for the computation of standard errors. Should be done using the <code><a href="#topic+RPESE.control">RPESE.control</a></code> function.</p>
</td></tr>
<tr><td><code id="lpm_+3A_...">...</code></td>
<td>
<p>Additional parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Lower partial moments capture negative deviation from a reference point.  
That reference point may be the mean, or some specified threshold that
has other meaning for the investor.
</p>


<h3>Author(s)</h3>

<p>Kyle Balkissoon <a href="mailto:kylebalkisoon@gmail.com">kylebalkisoon@gmail.com</a>
</p>


<h3>References</h3>

<p>Huffman S.P. &amp; Moll C.R., 
&quot;The impact of Asymmetry on Expected Stock Returns: An Investigation of Alternative Risk Measures&quot;, 
Algorithmic Finance 1, 2011 p. 79-93
</p>

<hr>
<h2 id='M2Sortino'>M squared for Sortino of the return distribution</h2><span id='topic+M2Sortino'></span>

<h3>Description</h3>

<p>M squared for Sortino is a M^2 calculated for Downside risk instead of Total Risk
</p>


<h3>Usage</h3>

<pre><code class='language-R'>M2Sortino(Ra, Rb, MAR = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="M2Sortino_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset return</p>
</td></tr>
<tr><td><code id="M2Sortino_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="M2Sortino_+3A_mar">MAR</code></td>
<td>
<p>the minimum acceptable return</p>
</td></tr>
<tr><td><code id="M2Sortino_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">M^2_S = r_P + Sortino ratio * (\sigma_{DM} - \sigma_D)</code>
</p>

<p>where <code class="reqn">M^2_S</code> is MSquared for Sortino, <code class="reqn">r_P</code> is the annualised portfolio return,
<code class="reqn">\sigma_{DM}</code> is the benchmark annualised downside risk and <code class="reqn">D</code> is the portfolio
annualised downside risk
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.102-103
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(portfolio_bacon)
MAR = 0.005
print(M2Sortino(portfolio_bacon[,1], portfolio_bacon[,2], MAR)) #expected 0.1035

data(managers)
MAR = 0
print(MSquaredExcess(managers['1996',1], managers['1996',8], MAR))
print(MSquaredExcess(managers['1996',1:5], managers['1996',8], MAR))

</code></pre>

<hr>
<h2 id='managers'>Hypothetical Alternative Asset Manager and Benchmark Data</h2><span id='topic+managers'></span>

<h3>Description</h3>

<p>A xts object that contains columns of monthly returns for six hypothetical
asset managers (HAM1 through HAM6), the EDHEC Long-Short Equity hedge
fund index, the S\&amp;P 500 total returns, and total return series for
the US Treasury 10-year bond and 3-month bill. Monthly returns for
all series end in December 2006 and begin at different periods starting
from January 1996.
</p>
<p>Note that all the EDHEC indices are available in <code><a href="#topic+edhec">edhec</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>managers</code></pre>


<h3>Format</h3>

<p>CSV conformed into an xts object with monthly observations</p>


<h3>Details</h3>

<p>Please note that the &lsquo;managers&rsquo; data set included with PerformanceAnalytics will be periodically updated with new managers and information.  If you intend to use this data set in automated tests, please be sure to subset your data like <code>managers[1:120,1:6]</code> to use the first ten years of observations on HAM1-HAM6.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(managers)

#preview the data
head(managers)

#summary period statistics
summary(managers)

#cumulative returns
tail(cumprod(1+managers),1)
</code></pre>

<hr>
<h2 id='MarketTiming'>Market timing models</h2><span id='topic+MarketTiming'></span>

<h3>Description</h3>

<p>Allows to estimate Treynor-Mazuy or Merton-Henriksson market timing model.
The Treynor-Mazuy model is essentially a quadratic extension of the basic
CAPM. It is estimated using a multiple regression. The second term in the
regression is the value of excess return squared. If the gamma coefficient
in the regression is positive, then the estimated equation describes a 
convex upward-sloping regression &quot;line&quot;. The quadratic regression is:
</p>
<p style="text-align: center;"><code class="reqn">R_{p}-R_{f}=\alpha+\beta (R_{b} - R_{f})+\gamma (R_{b}-R_{f})^2+
\varepsilon_{p}</code>
</p>

<p><code class="reqn">\gamma</code> is a measure of the curvature of the regression line.
If <code class="reqn">\gamma</code> is positive, this would indicate that the manager's
investment strategy demonstrates market timing ability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MarketTiming(Ra, Rb, Rf = 0, method = c("TM", "HM"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MarketTiming_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
the asset returns</p>
</td></tr>
<tr><td><code id="MarketTiming_+3A_rb">Rb</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of 
the benchmark asset return</p>
</td></tr>
<tr><td><code id="MarketTiming_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="MarketTiming_+3A_method">method</code></td>
<td>
<p>used to select between Treynor-Mazuy and Henriksson-Merton
models. May be any of: </p>
 <ul>
<li><p> TM - Treynor-Mazuy model, 
</p>
</li>
<li><p> HM - Henriksson-Merton model</p>
</li></ul>
<p> By default Treynor-Mazuy is selected</p>
</td></tr>
<tr><td><code id="MarketTiming_+3A_...">...</code></td>
<td>
<p>any other passthrough parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The basic idea of the Merton-Henriksson test is to perform a multiple 
regression in which the dependent variable (portfolio excess return and a 
second variable that mimics the payoff to an option). This second variable 
is zero when the market excess return is at or below zero and is 1 when it 
is above zero:
</p>
<p style="text-align: center;"><code class="reqn">R_{p}-R_{f}=\alpha+\beta (R_{b}-R_{f})+\gamma D+\varepsilon_{p}</code>
</p>

<p>where all variables are familiar from the CAPM model, except for the 
up-market return <code class="reqn">D=max(0,R_{f}-R_{b})</code> and market 
timing abilities <code class="reqn">\gamma</code>
</p>


<h3>Author(s)</h3>

<p>Andrii Babii, Peter Carl
</p>


<h3>References</h3>

<p>J. Christopherson, D. Carino, W. Ferson. <em>Portfolio 
Performance Measurement and Benchmarking</em>. 2009. McGraw-Hill, p. 127-133.
<br /> J. L. Treynor and K. Mazuy, &quot;Can Mutual Funds Outguess the Market?&quot; 
<em>Harvard Business Review</em>, vol44, 1966, pp. 131-136 
<br /> Roy D. Henriksson and Robert C. Merton, &quot;On Market Timing and Investment
Performance. II. Statistical Procedures for Evaluating Forecast Skills,&quot; 
<em>Journal of Business</em>, vol.54, October 1981, pp.513-533 <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CAPM.beta">CAPM.beta</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
MarketTiming(managers[,1], managers[,8], Rf=.035/12, method = "HM")
MarketTiming(managers[80:120,1:6], managers[80:120,7], managers[80:120,10])
MarketTiming(managers[80:120,1:6], managers[80:120,8:7], managers[80:120,10], method = "TM")

</code></pre>

<hr>
<h2 id='MartinRatio'>Martin ratio of the return distribution</h2><span id='topic+MartinRatio'></span>

<h3>Description</h3>

<p>To calculate Martin ratio we divide the difference of the portfolio return
and the risk free rate by the Ulcer index
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MartinRatio(R, Rf = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MartinRatio_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="MartinRatio_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="MartinRatio_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">Martin ratio = \frac{r_P - r_F}{\sqrt{\sum^{n}_{i=1} \frac{{D'_i}^2}{n}}}</code>
</p>

<p>where <code class="reqn">r_P</code> is the annualized portfolio return, <code class="reqn">r_F</code> is the risk free
rate, <code class="reqn">n</code> is the number of observations of the entire series, <code class="reqn">D'_i</code> is
the drawdown since previous peak in period i
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.91
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(portfolio_bacon)
print(MartinRatio(portfolio_bacon[,1])) #expected 1.70

data(managers)
print(MartinRatio(managers['1996']))
print(MartinRatio(managers['1996',1])) 

</code></pre>

<hr>
<h2 id='maxDrawdown'>caclulate the maximum drawdown from peak equity</h2><span id='topic+maxDrawdown'></span>

<h3>Description</h3>

<p>To find the maximum drawdown in a return series, we need to first calculate
the cumulative returns and the maximum cumulative return to that point.  Any
time the cumulative returns dips below the maximum cumulative returns, it's
a drawdown.  Drawdowns are measured as a percentage of that maximum
cumulative return, in effect, measured from peak equity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>maxDrawdown(R, weights = NULL, geometric = TRUE, invert = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="maxDrawdown_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="maxDrawdown_+3A_weights">weights</code></td>
<td>
<p>portfolio weighting vector, default NULL, see Details</p>
</td></tr>
<tr><td><code id="maxDrawdown_+3A_geometric">geometric</code></td>
<td>
<p>utilize geometric chaining (TRUE) or simple/arithmetic chaining (FALSE) to aggregate returns,
default TRUE</p>
</td></tr>
<tr><td><code id="maxDrawdown_+3A_invert">invert</code></td>
<td>
<p>TRUE/FALSE whether to invert the drawdown measure.  see
Details.</p>
</td></tr>
<tr><td><code id="maxDrawdown_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The option to <code>invert</code> the measure should appease both academics and
practitioners. The default option <code>invert=TRUE</code> will provide the
drawdown as a positive number.  This should be useful for optimization
(which usually seeks to minimize a value), and for tables (where having
negative signs in front of every number may be considered clutter).
Practitioners will argue that drawdowns denote losses, and should be
internally consistent with the quantile (a negative number), for which
<code>invert=FALSE</code> will provide the value they expect.  Individually,
different preferences may apply for clarity and compactness.  As such, we
provide the option, but make no value judgment on which approach is
preferable.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>Bacon, C. <em>Practical Portfolio Performance Measurement and
Attribution</em>. Wiley. 2004. p. 88 <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+findDrawdowns">findDrawdowns</a></code> <br /> <code><a href="#topic+sortDrawdowns">sortDrawdowns</a></code> <br />
<code><a href="#topic+table.Drawdowns">table.Drawdowns</a></code> <br /> <code><a href="#topic+table.DownsideRisk">table.DownsideRisk</a></code> <br />
<code><a href="#topic+chart.Drawdown">chart.Drawdown</a></code> <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)
t(round(maxDrawdown(edhec[,"Funds of Funds"]),4))
data(managers)
t(round(maxDrawdown(managers),4))

</code></pre>

<hr>
<h2 id='MCA'>Functions for doing Moment Component Analysis (MCA) of financial time series</h2><span id='topic+MCA'></span><span id='topic+M3.MCA'></span><span id='topic+M4.MCA'></span>

<h3>Description</h3>

<p>calculates MCA coskewness and cokurtosis matrices
</p>


<h3>Usage</h3>

<pre><code class='language-R'>M3.MCA(R, k = 1, as.mat = TRUE, ...)

M4.MCA(R, k = 1, as.mat = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MCA_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="MCA_+3A_k">k</code></td>
<td>
<p>the number of components to use</p>
</td></tr>
<tr><td><code id="MCA_+3A_as.mat">as.mat</code></td>
<td>
<p>TRUE/FALSE whether to return the full moment matrix or only
the vector with the unique elements (the latter is advised for speed), default
TRUE</p>
</td></tr>
<tr><td><code id="MCA_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The coskewness and cokurtosis matrices are defined as the matrices of dimension 
p x p^2 and p x p^3 containing the third and fourth order central moments. They
are useful for measuring nonlinear dependence between different assets of the 
portfolio and computing modified VaR and modified ES of a portfolio.
</p>
<p>MCA is a generalization of PCA to higher moments. The principal components in 
MCA are the ones that maximize the coskewness and cokurtosis present when projecting
onto these directions. It was introduced by Lim and Morton (2007) and applied to financial returns
data by Jondeau and Rockinger (2017)
</p>
<p>If a coskewness matrix (argument M3) or cokurtosis matrix (argument M4) is passed in using ..., then 
MCA is performed on the given comoment matrix instead of the sample coskewness or cokurtosis matrix.
</p>


<h3>Author(s)</h3>

<p>Dries Cornilly
</p>


<h3>References</h3>

<p>Lim, Hek-Leng and Morton, Jason. 2007. Principal Cumulant Component Analysis. working paper
</p>
<p>Jondeau, Eric and Jurczenko, Emmanuel. 2017. Moment Component Analysis: An Illustration 
With International Stock Markets. Journal of Business and Economic Statistics
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CoMoments">CoMoments</a></code> <br /> <code><a href="#topic+ShrinkageMoments">ShrinkageMoments</a></code> <br /> <code><a href="#topic+StructuredMoments">StructuredMoments</a></code> <br /> <code><a href="#topic+EWMAMoments">EWMAMoments</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(edhec)

# coskewness matrix based on two components
M3mca &lt;- M3.MCA(edhec, k = 2)$M3mca

# screeplot MCA 
M3dist &lt;- M4dist &lt;- rep(NA, ncol(edhec))
M3S &lt;- M3.MM(edhec)  # sample coskewness estimator
M4S &lt;- M4.MM(edhec)  # sample cokurtosis estimator
for (k in 1:ncol(edhec)) {
  M3MCA_list &lt;- M3.MCA(edhec, k)
  M4MCA_list &lt;- M4.MCA(edhec, k)

  M3dist[k] &lt;- sqrt(sum((M3S - M3MCA_list$M3mca)^2))
  M4dist[k] &lt;- sqrt(sum((M4S - M4MCA_list$M4mca)^2))
}
par(mfrow = c(2, 1))
plot(1:ncol(edhec), M3dist)
plot(1:ncol(edhec), M4dist)
par(mfrow = c(1, 1))

</code></pre>

<hr>
<h2 id='mean.geometric'>calculate attributes relative to the mean of the observation series given,
including geometric, stderr, LCL and UCL</h2><span id='topic+mean.geometric'></span><span id='topic+mean.utils'></span><span id='topic+mean.UCL'></span><span id='topic+mean.LCL'></span><span id='topic+mean.stderr'></span><span id='topic+Mean.arithmetic'></span>

<h3>Description</h3>


<table>
<tr>
 <td style="text-align: left;"> <code><a href="#topic+mean.geometric">mean.geometric</a></code> </td><td style="text-align: left;"> geometric mean </td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+mean.stderr">mean.stderr</a></code> </td><td style="text-align: left;"> standard error of the mean (S.E. mean) </td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+mean.LCL">mean.LCL</a></code> </td><td style="text-align: left;"> lower confidence level (LCL) of the mean </td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+mean.UCL">mean.UCL</a></code> </td><td style="text-align: left;"> upper confidence level (UCL) of the mean </td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>



<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'geometric'
mean(x, ...)

## S3 method for class 'arithmetic'
Mean(x, SE = FALSE, SE.control = NULL, ...)

## S3 method for class 'stderr'
mean(x, ...)

## S3 method for class 'LCL'
mean(x, ci = 0.95, ...)

## S3 method for class 'UCL'
mean(x, ci = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mean.geometric_+3A_x">x</code></td>
<td>
<p>a vector, matrix, data frame, or time series to calculate the
modified mean statistic over</p>
</td></tr>
<tr><td><code id="mean.geometric_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
<tr><td><code id="mean.geometric_+3A_se">SE</code></td>
<td>
<p>TRUE/FALSE whether to ouput the standard errors of the estimates of the risk measures, default FALSE. Only available for  <code><a href="#topic+Mean.arithmetic">Mean.arithmetic</a></code>.</p>
</td></tr>
<tr><td><code id="mean.geometric_+3A_se.control">SE.control</code></td>
<td>
<p>Control parameters for the computation of standard errors. Should be done using the <code><a href="#topic+RPESE.control">RPESE.control</a></code> function.
Only available for <code><a href="#topic+Mean.arithmetic">Mean.arithmetic</a></code>.</p>
</td></tr>
<tr><td><code id="mean.geometric_+3A_ci">ci</code></td>
<td>
<p>the confidence interval to use</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+sd">sd</a></code> <br /> <code><a href="base.html#topic+mean">mean</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)
mean.geometric(edhec[,"Funds of Funds"])
mean.stderr(edhec[,"Funds of Funds"])
mean.UCL(edhec[,"Funds of Funds"])
mean.LCL(edhec[,"Funds of Funds"])
</code></pre>

<hr>
<h2 id='MeanAbsoluteDeviation'>Mean absolute deviation of the return distribution</h2><span id='topic+MeanAbsoluteDeviation'></span>

<h3>Description</h3>

<p>To calculate Mean absolute deviation we take the sum of the absolute value of the difference between the returns and the mean of the returns and we divide it by the number of returns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MeanAbsoluteDeviation(R, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MeanAbsoluteDeviation_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="MeanAbsoluteDeviation_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">MeanAbsoluteDeviation = \frac{\sum^{n}_{i=1}\mid r_i - \overline{r}\mid}{n}</code>
</p>

<p>where <code class="reqn">n</code> is the number of observations of the entire series, <code class="reqn">r_i</code> is the
return in month i and <code class="reqn">\overline{r}</code> is the mean return
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.62
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(portfolio_bacon)
print(MeanAbsoluteDeviation(portfolio_bacon[,1])) #expected 0.0310

data(managers)
print(MeanAbsoluteDeviation(managers['1996']))
print(MeanAbsoluteDeviation(managers['1996',1]))

</code></pre>

<hr>
<h2 id='MinTrackRecord'>Minimum Track Record Length</h2><span id='topic+MinTrackRecord'></span>

<h3>Description</h3>

<p>The Minimum Track Record Length responds to the following question: &quot;How long should a track record be in 
order to have a p-level statistical confidence that its Sharpe ratio is above a given threshold?&quot;.
Obviously, the main assumption is the returns will continue displaying the same statistical properties out-of-sample.
For example, if the input contains fifty observations and the Minimum Track Record is forty, then for the next ten observations
the relevant measures (sharpe ratio, skewness and kyrtosis) need to remain the same as the input so to achieve 
statistical significance after exactly ten time points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MinTrackRecord(
  R = NULL,
  Rf = 0,
  refSR,
  p = 0.95,
  weights = NULL,
  n = NULL,
  sr = NULL,
  sk = NULL,
  kr = NULL,
  ignore_skewness = FALSE,
  ignore_kurtosis = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MinTrackRecord_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of the returns input</p>
</td></tr>
<tr><td><code id="MinTrackRecord_+3A_rf">Rf</code></td>
<td>
<p>the risk free rate</p>
</td></tr>
<tr><td><code id="MinTrackRecord_+3A_refsr">refSR</code></td>
<td>
<p>a single value or a vector when R is multicolumn. It defines the reference Sharpe Ratio and should be in the same periodicity as the returns (non-annualized).</p>
</td></tr>
<tr><td><code id="MinTrackRecord_+3A_p">p</code></td>
<td>
<p>the confidence level</p>
</td></tr>
<tr><td><code id="MinTrackRecord_+3A_weights">weights</code></td>
<td>
<p>(if R is multicolumn and the underlying assets form a portfolio) the portfolio weights</p>
</td></tr>
<tr><td><code id="MinTrackRecord_+3A_n">n</code></td>
<td>
<p>(if R is NULL) the track record length of the returns</p>
</td></tr>
<tr><td><code id="MinTrackRecord_+3A_sr">sr</code></td>
<td>
<p>(if R is NULL) the sharpe ratio of the returns</p>
</td></tr>
<tr><td><code id="MinTrackRecord_+3A_sk">sk</code></td>
<td>
<p>(if R is NULL) the skewness of the returns</p>
</td></tr>
<tr><td><code id="MinTrackRecord_+3A_kr">kr</code></td>
<td>
<p>(if R is NULL) the kurtosis of the returns</p>
</td></tr>
<tr><td><code id="MinTrackRecord_+3A_ignore_skewness">ignore_skewness</code></td>
<td>
<p>If TRUE, it ignores the effects of skewness in the calculations</p>
</td></tr>
<tr><td><code id="MinTrackRecord_+3A_ignore_kurtosis">ignore_kurtosis</code></td>
<td>
<p>If TRUE, it ignores the effects of kurtosis in the calculations</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the below
</p>
  <ul>
<li><p> min_TRL:       The minimum track record length value (periodicity follows R)
</p>
</li>
<li><p> IS_SR_SIGNIFICANT:       TRUE if the sharpe ratio is statistically significant, FALSE otherwise 
</p>
</li>
<li><p> num_of_extra_obs_needed: If the sharpe ratio is not statistically significant, how many more observations are needed so as to achieve this</p>
</li></ul>



<h3>Author(s)</h3>

<p>Tasos Grivas &lt;tasos@openriskcalculator.com&gt;, Pulkit Mehrotra
</p>


<h3>References</h3>

<p>Bailey, David H. and Lopez de Prado, Marcos, The Sharpe Ratio Efficient Frontier (July 1, 2012).
Journal of Risk, Vol. 15, No. 2, Winter 2012/13
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ProbSharpeRatio">ProbSharpeRatio</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)
MinTrackRecord(edhec[,1],refSR = 0.23) 
MinTrackRecord(refSR = 1/12^0.5,Rf = 0,p=0.95,sr = 2/12^0.5,sk=-0.72,kr=5.78,n=59)

### Higher moments are data intensive, kurtosis shouldn't be used for short timeseries
MinTrackRecord(edhec[,1:2],refSR = c(0.28,0.24), ignore_skewness = FALSE, ignore_kurtosis = FALSE)
MinTrackRecord(edhec[,1:2],refSR = c(0.28,0.24), ignore_skewness = FALSE, ignore_kurtosis = TRUE)
MinTrackRecord(edhec[,1:2],refSR = c(0.28,0.24), ignore_skewness = TRUE, ignore_kurtosis = TRUE)

MinTrackRecord(edhec[,1:2],refSR = 0.26,weights = c(0.5,0.5), 
               ignore_skewness = FALSE, ignore_kurtosis = FALSE)

</code></pre>

<hr>
<h2 id='Modigliani'>Modigliani-Modigliani measure</h2><span id='topic+Modigliani'></span>

<h3>Description</h3>

<p>The Modigliani-Modigliani measure is the portfolio return adjusted upward
or downward to match the benchmark's standard deviation. This puts the 
portfolio return and the benchmark return on 'equal footing' from a standard
deviation perspective.
</p>
<p style="text-align: center;"><code class="reqn">MM_{p}=\frac{E[R_{p} - R_{f}]}{\sigma_{p}}=SR_{p} * \sigma_{b} + 
E[R_{f}]</code>
</p>

<p>where <code class="reqn">SR_{p}</code> - Sharpe ratio, <code class="reqn">\sigma_{b}</code> - benchmark
standard deviation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Modigliani(Ra, Rb, Rf = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Modigliani_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="Modigliani_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="Modigliani_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="Modigliani_+3A_...">...</code></td>
<td>
<p>any other passthrough parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is also analogous to some approaches to 'risk parity' portfolios, which
use (presumably costless) leverage to increase the portfolio standard 
deviation to some target.
</p>


<h3>Author(s)</h3>

<p>Andrii Babii, Brian G. Peterson
</p>


<h3>References</h3>

<p>J. Christopherson, D. Carino, W. Ferson. <em>Portfolio 
Performance Measurement and Benchmarking</em>. 2009. McGraw-Hill, p. 97-99. <br />
Franco Modigliani and Leah Modigliani, &quot;Risk-Adjusted Performance: How to 
Measure It and Why,&quot; <em>Journal of Portfolio Management</em>, vol.23, no., 
Winter 1997, pp.45-54 <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SharpeRatio">SharpeRatio</a></code>, <code><a href="#topic+TreynorRatio">TreynorRatio</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
Modigliani(managers[,1,drop=FALSE], managers[,8,drop=FALSE], Rf=.035/12)
Modigliani(managers[,1:6], managers[,8,drop=FALSE], managers[,8,drop=FALSE])
Modigliani(managers[,1:6], managers[,8:7], managers[,8,drop=FALSE])

</code></pre>

<hr>
<h2 id='MSquared'>M squared of the return distribution</h2><span id='topic+MSquared'></span>

<h3>Description</h3>

<p>M squared is a risk adjusted return useful to judge the size of relative
performance between differents portfolios. With it you can compare portfolios
with different levels of risk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MSquared(Ra, Rb, Rf = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MSquared_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset return</p>
</td></tr>
<tr><td><code id="MSquared_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="MSquared_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="MSquared_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">M^2 = r_P + SR * (\sigma_M - \sigma_P) = (r_P - r_F) * \frac{\sigma_M}{\sigma_P} + r_F</code>
</p>

<p>where <code class="reqn">r_P</code> is the portfolio return annualized, <code class="reqn">\sigma_M</code> is the market
risk and <code class="reqn">\sigma_P</code> is the portfolio risk
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.67-68
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(portfolio_bacon)
print(MSquared(portfolio_bacon[,1], portfolio_bacon[,2])) #expected 0.10062

data(managers)
print(MSquared(managers['1996',1], managers['1996',8]))
print(MSquared(managers['1996',1:5], managers['1996',8]))

</code></pre>

<hr>
<h2 id='MSquaredExcess'>M squared excess of the return distribution</h2><span id='topic+MSquaredExcess'></span>

<h3>Description</h3>

<p>M squared excess is the quantity above the standard M. There is a geometric excess return which is better for Bacon and an arithmetic excess return
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MSquaredExcess(Ra, Rb, Rf = 0, Method = c("geometric", "arithmetic"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MSquaredExcess_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset return</p>
</td></tr>
<tr><td><code id="MSquaredExcess_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="MSquaredExcess_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="MSquaredExcess_+3A_method">Method</code></td>
<td>
<p>one of &quot;geometric&quot; or &quot;arithmetic&quot; indicating the method to use
to calculate MSquareExcess</p>
</td></tr>
<tr><td><code id="MSquaredExcess_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">M^2 excess (geometric) = \frac{1 + M^2}{1 + b} - 1</code>
</p>

<p style="text-align: center;"><code class="reqn">M^2 excess (arithmetic) = M^2 - b</code>
</p>

<p>where <code class="reqn">M^2</code> is MSquared and <code class="reqn">b</code> is the benchmark annualised return.
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.68
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(portfolio_bacon)
MSquaredExcess(portfolio_bacon[,1], portfolio_bacon[,2]) #expected -0.00998

MSquaredExcess(portfolio_bacon[,1], portfolio_bacon[,2], Method="arithmetic") #expected -0.011

data(managers)
MSquaredExcess(managers['1996',1], managers['1996',8])
MSquaredExcess(managers['1996',1:5], managers['1996',8])

</code></pre>

<hr>
<h2 id='NetSelectivity'>Net selectivity of the return distribution</h2><span id='topic+NetSelectivity'></span>

<h3>Description</h3>

<p>Net selectivity is the remaining selectivity after deducting the amount of return
require to justify not being fully diversified
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NetSelectivity(Ra, Rb, Rf = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NetSelectivity_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="NetSelectivity_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="NetSelectivity_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="NetSelectivity_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If net selectivity is negative the portfolio manager has not justified the loss of
diversification
</p>
<p style="text-align: center;"><code class="reqn">Net selectivity = \alpha - d</code>
</p>

<p>where <code class="reqn">\alpha</code> is the selectivity and <code class="reqn">d</code> is the diversification
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.78
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(portfolio_bacon)
print(NetSelectivity(portfolio_bacon[,1], portfolio_bacon[,2])) #expected -0.017

data(managers)
print(NetSelectivity(managers['1996',1], managers['1996',8]))
print(NetSelectivity(managers['1996',1:5], managers['1996',8]))

</code></pre>

<hr>
<h2 id='Omega'>calculate Omega for a return series</h2><span id='topic+Omega'></span>

<h3>Description</h3>

<p>Keating and Shadwick (2002) proposed Omega (referred to as Gamma in their
original paper) as a way to capture all of the higher moments of the returns
distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Omega(
  R,
  L = 0,
  method = c("simple", "interp", "binomial", "blackscholes"),
  output = c("point", "full"),
  Rf = 0,
  SE = FALSE,
  SE.control = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Omega_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="Omega_+3A_l">L</code></td>
<td>
<p>L is the loss threshold that can be specified as zero, return from
a benchmark index, or an absolute rate of return - any specified level</p>
</td></tr>
<tr><td><code id="Omega_+3A_method">method</code></td>
<td>
<p>one of: simple, interp, binomial, blackscholes</p>
</td></tr>
<tr><td><code id="Omega_+3A_output">output</code></td>
<td>
<p>one of: point (in time), or full (distribution of Omega)</p>
</td></tr>
<tr><td><code id="Omega_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, as a single number</p>
</td></tr>
<tr><td><code id="Omega_+3A_se">SE</code></td>
<td>
<p>TRUE/FALSE whether to ouput the standard errors of the estimates of the risk measures, default FALSE.</p>
</td></tr>
<tr><td><code id="Omega_+3A_se.control">SE.control</code></td>
<td>
<p>Control parameters for the computation of standard errors. Should be done using the <code><a href="#topic+RPESE.control">RPESE.control</a></code> function.</p>
</td></tr>
<tr><td><code id="Omega_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Mathematically, Omega is: integral[L to b](1 - F(r))dr / integral[a to
L](F(r))dr
</p>
<p>where the cumulative distribution F is defined on the interval (a,b). L is
the loss threshold that can be specified as zero, return from a benchmark
index, or an absolute rate of return - any specified level. When comparing
alternatives using Omega, L should be common.
</p>
<p>Input data can be transformed prior to calculation, which may be useful for
introducing risk aversion.
</p>
<p>This function returns a vector of Omega, useful for plotting.  The steeper,
the less risky.  Above it's mean, a steeply sloped Omega also implies a very
limited potential for further gain.
</p>
<p>Omega has a value of 1 at the mean of the distribution.
</p>
<p>Omega is sub-additive.  The ratio is dimensionless.
</p>
<p>Kazemi, Schneeweis, and Gupta (2003), in &quot;Omega as a Performance Measure&quot;
show that Omega can be written as: Omega(L) = C(L)/P(L) where C(L) is
essentially the price of a European call option written on the investment
and P(L) is essentially the price of a European put option written on the
investment.  The maturity for both options is one period (e.g., one month)
and L is the strike price of both options.
</p>
<p>The numerator and the denominator can be expressed as: exp(-Rf=0) * E[max(x
- L, 0)] exp(-Rf=0) * E[max(L - x, 0)] with exp(-Rf=0) calculating the
present values of the two, where rf is the per-period riskless rate.
</p>
<p>The first three methods implemented here focus on that observation. The
first method takes the simplification described above.  The second uses the
Black-Scholes option pricing as implemented in fOptions.  The third uses the
binomial pricing model from fOptions.  The second and third methods are not
implemented here.
</p>
<p>The fourth method, &quot;interp&quot;, creates a linear interpolation of the cdf of
returns, calculates Omega as a vector, and finally interpolates a function
for Omega as a function of L.  This method requires library <code>Hmisc</code>,
which can be found on CRAN.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>Keating, J. and Shadwick, W.F. The Omega Function. working
paper. Finance Development Center, London. 2002. Kazemi, Schneeweis, and
Gupta. Omega as a Performance Measure. 2003.
</p>


<h3>See Also</h3>

<p><code><a href="Hmisc.html#topic+Ecdf">Ecdf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
    data(edhec)
    Omega(edhec)
    Omega(edhec[,13],method="interp",output="point")
    Omega(edhec[,13],method="interp",output="full")

</code></pre>

<hr>
<h2 id='OmegaExcessReturn'>Omega excess return of the return distribution</h2><span id='topic+OmegaExcessReturn'></span><span id='topic+OmegaExessReturn'></span>

<h3>Description</h3>

<p>Omega excess return is another form of downside risk-adjusted return. It is
calculated by multiplying the downside variance of the style benchmark by 3
times the style beta.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OmegaExcessReturn(Ra, Rb, MAR = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OmegaExcessReturn_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="OmegaExcessReturn_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="OmegaExcessReturn_+3A_mar">MAR</code></td>
<td>
<p>the minimum acceptable return</p>
</td></tr>
<tr><td><code id="OmegaExcessReturn_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">\omega = r_P - 3*\beta_S*\sigma_{MD}^2</code>
</p>

<p>where <code class="reqn">\omega</code> is omega excess return, <code class="reqn">\beta_S</code> is style beta, <code class="reqn">\sigma_D</code> 
is the portfolio annualised downside risk and <code class="reqn">\sigma_{MD}</code> is the benchmark annualised downside risk.
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.103
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(portfolio_bacon)
MAR = 0.005
print(OmegaExcessReturn(portfolio_bacon[,1], portfolio_bacon[,2], MAR)) #expected 0.0805

data(managers)
MAR = 0
print(OmegaExcessReturn(managers['1996',1], managers['1996',8], MAR))
print(OmegaExcessReturn(managers['1996',1:5], managers['1996',8], MAR))

</code></pre>

<hr>
<h2 id='OmegaSharpeRatio'>Omega-Sharpe ratio of the return distribution</h2><span id='topic+OmegaSharpeRatio'></span>

<h3>Description</h3>

<p>The Omega-Sharpe ratio is a conversion of the omega ratio to a ranking statistic 
in familiar form to the Sharpe ratio.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OmegaSharpeRatio(R, MAR = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OmegaSharpeRatio_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="OmegaSharpeRatio_+3A_mar">MAR</code></td>
<td>
<p>Minimum Acceptable Return, in the same periodicity as your
returns</p>
</td></tr>
<tr><td><code id="OmegaSharpeRatio_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To calculate the Omega-Sharpe ration we subtract the target (or Minimum
Acceptable Returns (MAR)) return from the portfolio return and we divide
it by the opposite of the Downside Deviation.
</p>
<p style="text-align: center;"><code class="reqn">OmegaSharpeRatio(R,MAR) = \frac{r_p - r_t}{\sum^n_{t=1}\frac{max(r_t - r_i, 0)}{n}}</code>
</p>

<p>where <code class="reqn">n</code> is the number of observations of the entire series
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008, p.95
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(portfolio_bacon)
MAR = 0.005
print(OmegaSharpeRatio(portfolio_bacon[,1], MAR)) #expected 0.29

MAR = 0
data(managers)
print(OmegaSharpeRatio(managers['1996'], MAR))
print(OmegaSharpeRatio(managers['1996',1], MAR)) #expected 3.60

</code></pre>

<hr>
<h2 id='PainIndex'>Pain index of the return distribution</h2><span id='topic+PainIndex'></span>

<h3>Description</h3>

<p>The pain index is the mean value of the drawdowns over the entire 
analysis period. The measure is similar to the Ulcer index except that 
the drawdowns are not squared.  Also, it's different than the average
drawdown, in that the numerator is the total number of observations 
rather than the number of drawdowns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PainIndex(R, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PainIndex_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="PainIndex_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Visually, the pain index is the area of the region that is enclosed by 
the horizontal line at zero percent and the drawdown line in the 
Drawdown chart.
</p>
<p style="text-align: center;"><code class="reqn">Pain index = \sum^{n}_{i=1} \frac{\mid D'_i \mid}{n}</code>
</p>

<p>where <code class="reqn">n</code> is the number of observations of the entire series, <code class="reqn">D'_i</code> is
the drawdown since previous peak in period i
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.89, Becker, Thomas (2006) Zephyr Associates
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(portfolio_bacon)
print(PainIndex(portfolio_bacon[,1])) #expected 0.04

data(managers)
print(PainIndex(100*managers['1996']))
print(PainIndex(100*managers['1996',1])) 

</code></pre>

<hr>
<h2 id='PainRatio'>Pain ratio of the return distribution</h2><span id='topic+PainRatio'></span>

<h3>Description</h3>

<p>To calculate Pain ratio we divide the difference of the portfolio return
and the risk free rate by the Pain index
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PainRatio(R, Rf = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PainRatio_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="PainRatio_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="PainRatio_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">Pain ratio = \frac{r_P - r_F}{\sum^{n}_{i=1} \frac{\mid D'_i \mid}{n}}</code>
</p>

<p>where <code class="reqn">r_P</code> is the annualized portfolio return, <code class="reqn">r_F</code> is the risk free
rate, <code class="reqn">n</code> is the number of observations of the entire series, <code class="reqn">D'_i</code> is
the drawdown since previous peak in period i
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.91
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(portfolio_bacon)
print(PainRatio(portfolio_bacon[,1])) #expected 2.66

data(managers)
print(PainRatio(managers['1996']))
print(PainRatio(managers['1996',1])) 

</code></pre>

<hr>
<h2 id='portfolio_bacon'>Bacon(2008) Data</h2><span id='topic+portfolio_bacon'></span>

<h3>Description</h3>

<p>A xts object that contains columns of monthly returns for an example of portfolio
and its benchmark
</p>


<h3>Usage</h3>

<pre><code class='language-R'>portfolio_bacon</code></pre>


<h3>Format</h3>

<p>CSV conformed into an xts object with monthly observations</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(portfolio_bacon)

#preview the data
head(portfolio_bacon)

#summary period statistics
summary(portfolio_bacon)

#cumulative returns
tail(cumprod(1+portfolio_bacon),1)
</code></pre>

<hr>
<h2 id='prices'>Selected Price Series Example Data</h2><span id='topic+prices'></span>

<h3>Description</h3>

<p>A object returned by get.hist.quote of price data for use in the example for <code><a href="#topic+Return.calculate">Return.calculate</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prices</code></pre>


<h3>Format</h3>

<p><span class="rlang"><b>R</b></span> variable 'prices'</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(prices)

#preview the data
head(prices)

</code></pre>

<hr>
<h2 id='ProbSharpeRatio'>Probabilistic Sharpe Ratio</h2><span id='topic+ProbSharpeRatio'></span>

<h3>Description</h3>

<p>Given a predefined benchmark Sharpe ratio,the observed Sharpe Ratio 
can be expressed in probabilistic terms known as the Probabilistic 
Sharpe Ratio. PSR provides an adjusted estimate of SR, by removing the inflationary effect caused by short series with skewed and/or fat-tailed returns and
is defined as the probability of the observed sharpe ratio being higher than the reference sharpe ratio.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ProbSharpeRatio(
  R = NULL,
  Rf = 0,
  refSR,
  p = 0.95,
  weights = NULL,
  n = NULL,
  sr = NULL,
  sk = NULL,
  kr = NULL,
  ignore_skewness = FALSE,
  ignore_kurtosis = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ProbSharpeRatio_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of the returns input</p>
</td></tr>
<tr><td><code id="ProbSharpeRatio_+3A_rf">Rf</code></td>
<td>
<p>the risk free rate</p>
</td></tr>
<tr><td><code id="ProbSharpeRatio_+3A_refsr">refSR</code></td>
<td>
<p>a single value or a vector when R is multicolumn. It defines the reference Sharpe Ratio and should be in the same periodicity as the returns (non-annualized).</p>
</td></tr>
<tr><td><code id="ProbSharpeRatio_+3A_p">p</code></td>
<td>
<p>the confidence level</p>
</td></tr>
<tr><td><code id="ProbSharpeRatio_+3A_weights">weights</code></td>
<td>
<p>(if R is multicolumn and the underlying assets form a portfolio) the portfolio weights</p>
</td></tr>
<tr><td><code id="ProbSharpeRatio_+3A_n">n</code></td>
<td>
<p>(if R is NULL) the track record length of the returns</p>
</td></tr>
<tr><td><code id="ProbSharpeRatio_+3A_sr">sr</code></td>
<td>
<p>(if R is NULL) the sharpe ratio of the returns</p>
</td></tr>
<tr><td><code id="ProbSharpeRatio_+3A_sk">sk</code></td>
<td>
<p>(if R is NULL) the skewness of the returns</p>
</td></tr>
<tr><td><code id="ProbSharpeRatio_+3A_kr">kr</code></td>
<td>
<p>(if R is NULL) the kurtosis of the returns</p>
</td></tr>
<tr><td><code id="ProbSharpeRatio_+3A_ignore_skewness">ignore_skewness</code></td>
<td>
<p>If TRUE, it ignores the effects of skewness in the calculations</p>
</td></tr>
<tr><td><code id="ProbSharpeRatio_+3A_ignore_kurtosis">ignore_kurtosis</code></td>
<td>
<p>If TRUE, it ignores the effects of kurtosis in the calculations</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the below
</p>
  <ul>
<li><p> The probability that the observed Sharpe Ratio is higher than the reference one 
</p>
</li>
<li><p> The p-level confidence interval of the Sharpe Ratio</p>
</li></ul>



<h3>Author(s)</h3>

<p>Tasos Grivas &lt;tasos@openriskcalculator.com&gt;, Pulkit Mehrotra
</p>


<h3>References</h3>

<p>Marcos Lopez de Prado. 2018. Advances in Financial Machine Learning (1st ed.). Wiley Publishing.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)
ProbSharpeRatio(edhec[,1],refSR = 0.23) 
ProbSharpeRatio(refSR = 1/12^0.5,Rf = 0,p=0.95,sr = 2/12^0.5,sk=-0.72,kr=5.78,n=59)

### Higher moments are data intensive, kurtosis shouldn't be used for short timeseries
ProbSharpeRatio(edhec[,1:2],refSR = c(0.28,0.24), ignore_skewness = FALSE, ignore_kurtosis = FALSE)
ProbSharpeRatio(edhec[,1:2],refSR = c(0.28,0.24), ignore_skewness = FALSE, ignore_kurtosis = TRUE)
ProbSharpeRatio(edhec[,1:2],refSR = c(0.28,0.24), ignore_skewness = TRUE, ignore_kurtosis = TRUE)

ProbSharpeRatio(edhec[,1:2],refSR = 0.26,weights = c(0.5,0.5), 
                ignore_skewness = FALSE, ignore_kurtosis = FALSE)

</code></pre>

<hr>
<h2 id='ProspectRatio'>Prospect ratio of the return distribution</h2><span id='topic+ProspectRatio'></span>

<h3>Description</h3>

<p>Prospect ratio is a ratio used to penalise loss since most people feel loss
greater than gain
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ProspectRatio(R, MAR, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ProspectRatio_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="ProspectRatio_+3A_mar">MAR</code></td>
<td>
<p>the minimum acceptable return</p>
</td></tr>
<tr><td><code id="ProspectRatio_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">ProspectRatio(R) = \frac{\frac{1}{n}*\sum^{n}_{i=1}(Max(r_i,0)+2.25*Min(r_i,0) - MAR)}{\sigma_D}</code>
</p>

<p>where <code class="reqn">n</code> is the number of observations of the entire series, MAR is the minimum acceptable return and <code class="reqn">\sigma_D</code> is the downside risk
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.100
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(portfolio_bacon)
MAR = 0.05
print(ProspectRatio(portfolio_bacon[,1], MAR)) #expected -0.134

data(managers)
MAR = 0
print(ProspectRatio(managers['1996'], MAR))
print(ProspectRatio(managers['1996',1], MAR))

</code></pre>

<hr>
<h2 id='RachevRatio'>Standard Error Estimate for Rachev Ratio of Returns</h2><span id='topic+RachevRatio'></span>

<h3>Description</h3>

<p><code>RachevRatio.SE</code> computes the standard error of the Rachev ratio of the returns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RachevRatio(
  R,
  alpha = 0.1,
  beta = 0.1,
  rf = 0,
  SE = FALSE,
  SE.control = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RachevRatio_+3A_r">R</code></td>
<td>
<p>Data of returns for one or multiple assets or portfolios.</p>
</td></tr>
<tr><td><code id="RachevRatio_+3A_alpha">alpha</code></td>
<td>
<p>Lower tail probability.</p>
</td></tr>
<tr><td><code id="RachevRatio_+3A_beta">beta</code></td>
<td>
<p>Upper tail probability.</p>
</td></tr>
<tr><td><code id="RachevRatio_+3A_rf">rf</code></td>
<td>
<p>Risk-free interest rate.</p>
</td></tr>
<tr><td><code id="RachevRatio_+3A_se">SE</code></td>
<td>
<p>TRUE/FALSE whether to ouput the standard errors of the estimates of the risk measures, default FALSE.</p>
</td></tr>
<tr><td><code id="RachevRatio_+3A_se.control">SE.control</code></td>
<td>
<p>Control parameters for the computation of standard errors. Should be done using the <code><a href="#topic+RPESE.control">RPESE.control</a></code> function.</p>
</td></tr>
<tr><td><code id="RachevRatio_+3A_...">...</code></td>
<td>
<p>Additional parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector or a list depending on <code>se.method</code>.
</p>


<h3>Author(s)</h3>

<p>Anthony-Alexander Christidis, <a href="mailto:anthony.christidis@stat.ubc.ca">anthony.christidis@stat.ubc.ca</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Loading data from PerformanceAnalytics
data(edhec, package = "PerformanceAnalytics")
class(edhec)
# Changing the data colnames
names(edhec) = c("CA", "CTA", "DIS", "EM", "EMN",
                 "ED", "FIA", "GM", "LS", "MA",
                 "RV", "SS", "FOF")
# Compute Rachev ratio for managers data
RachevRatio(edhec)

</code></pre>

<hr>
<h2 id='replaceTabs.inner'>Display text information in a graphics plot.</h2><span id='topic+replaceTabs.inner'></span><span id='topic+replaceTabs'></span><span id='topic+textplot'></span><span id='topic+textplot.default'></span><span id='topic+textplot.character'></span><span id='topic+textplot.matrix'></span><span id='topic+textplot.data.frame'></span>

<h3>Description</h3>

<p>This function displays text output in a graphics window.  It is the
equivalent of 'print' except that the output is displayed as a plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>replaceTabs.inner(text, width = 8)

replaceTabs(text, width = 8)

textplot(
  object,
  halign = "center",
  valign = "center",
  cex,
  max.cex = 1,
  cmar = 2,
  rmar = 0.5,
  show.rownames = TRUE,
  show.colnames = TRUE,
  hadj = 1,
  vadj = NULL,
  row.valign = "center",
  heading.valign = "bottom",
  mar = c(0, 0, 0, 0) + 0.1,
  col.data = par("col"),
  col.rownames = par("col"),
  col.colnames = par("col"),
  wrap = TRUE,
  wrap.colnames = 10,
  wrap.rownames = 10,
  ...
)

## Default S3 method:
textplot(
  object,
  halign = c("center", "left", "right"),
  valign = c("center", "top", "bottom"),
  cex,
  max.cex,
  cmar,
  rmar,
  show.rownames,
  show.colnames,
  hadj,
  vadj,
  row.valign,
  heading.valign,
  mar,
  col.data,
  col.rownames,
  col.colnames,
  wrap,
  wrap.colnames,
  wrap.rownames,
  ...
)

## S3 method for class 'data.frame'
textplot(
  object,
  halign = c("center", "left", "right"),
  valign = c("center", "top", "bottom"),
  cex,
  max.cex = 1,
  cmar = 2,
  rmar = 0.5,
  show.rownames = TRUE,
  show.colnames = TRUE,
  hadj = 1,
  vadj = NULL,
  row.valign = "center",
  heading.valign = "bottom",
  mar = c(0, 0, 0, 0) + 0.1,
  col.data = par("col"),
  col.rownames = par("col"),
  col.colnames = par("col"),
  wrap = TRUE,
  wrap.colnames = 10,
  wrap.rownames = 10,
  ...
)

## S3 method for class 'matrix'
textplot(
  object,
  halign = c("center", "left", "right"),
  valign = c("center", "top", "bottom"),
  cex,
  max.cex = 1,
  cmar = 2,
  rmar = 0.5,
  show.rownames = TRUE,
  show.colnames = TRUE,
  hadj = 1,
  vadj = NULL,
  row.valign = "center",
  heading.valign = "bottom",
  mar = c(0, 0, 0, 0) + 0.1,
  col.data = par("col"),
  col.rownames = par("col"),
  col.colnames = par("col"),
  wrap = TRUE,
  wrap.colnames = 10,
  wrap.rownames = 10,
  ...
)

## S3 method for class 'character'
textplot(
  object,
  halign = c("center", "left", "right"),
  valign = c("center", "top", "bottom"),
  cex,
  max.cex = 1,
  cmar = 2,
  rmar = 0.5,
  show.rownames = TRUE,
  show.colnames = TRUE,
  hadj = 1,
  vadj = NULL,
  row.valign = "center",
  heading.valign = "bottom",
  mar = c(0, 0, 3, 0) + 0.1,
  col.data = par("col"),
  col.rownames = par("col"),
  col.colnames = par("col"),
  wrap = TRUE,
  wrap.colnames = 10,
  wrap.rownames = 10,
  fixed.width = TRUE,
  cspace = 1,
  lspace = 1,
  tab.width = 8,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="replaceTabs.inner_+3A_text">text</code></td>
<td>
<p>in the function 'replaceTabs', the text string to be processed</p>
</td></tr>
<tr><td><code id="replaceTabs.inner_+3A_width">width</code></td>
<td>
<p>in the function 'replaceTabs', the number of spaces to replace
tabs with</p>
</td></tr>
<tr><td><code id="replaceTabs.inner_+3A_object">object</code></td>
<td>
<p>Object to be displayed.</p>
</td></tr>
<tr><td><code id="replaceTabs.inner_+3A_halign">halign</code></td>
<td>
<p>Alignment in the x direction, one of &quot;center&quot;, &quot;left&quot;, or
&quot;right&quot;.</p>
</td></tr>
<tr><td><code id="replaceTabs.inner_+3A_valign">valign</code></td>
<td>
<p>Alignment in the y direction, one of &quot;center&quot;, &quot;top&quot; , or
&quot;bottom&quot;</p>
</td></tr>
<tr><td><code id="replaceTabs.inner_+3A_cex">cex</code></td>
<td>
<p>Character size, see <code><a href="graphics.html#topic+par">par</a></code> for details. If unset, the
code will attempt to use the largest value which allows the entire object to
be displayed.</p>
</td></tr>
<tr><td><code id="replaceTabs.inner_+3A_max.cex">max.cex</code></td>
<td>
<p>Sets the largest text size as a ceiling</p>
</td></tr>
<tr><td><code id="replaceTabs.inner_+3A_rmar">rmar</code>, <code id="replaceTabs.inner_+3A_cmar">cmar</code></td>
<td>
<p>Space between rows or columns, in fractions of the size of
the letter 'M'.</p>
</td></tr>
<tr><td><code id="replaceTabs.inner_+3A_show.rownames">show.rownames</code>, <code id="replaceTabs.inner_+3A_show.colnames">show.colnames</code></td>
<td>
<p>Logical value indicating whether row or
column names will be displayed.</p>
</td></tr>
<tr><td><code id="replaceTabs.inner_+3A_hadj">hadj</code>, <code id="replaceTabs.inner_+3A_vadj">vadj</code></td>
<td>
<p>Vertical and horizontal location of elements within matrix
cells.  These have the same meaning as the <code>adj</code> graphics paramter (see
<code><a href="graphics.html#topic+par">par</a></code>).</p>
</td></tr>
<tr><td><code id="replaceTabs.inner_+3A_row.valign">row.valign</code></td>
<td>
<p>Sets the vertical alignment of the row as &quot;top&quot;, &quot;bottom&quot;,
or (default) &quot;center&quot;.</p>
</td></tr>
<tr><td><code id="replaceTabs.inner_+3A_heading.valign">heading.valign</code></td>
<td>
<p>Sets the vertical alignment of the heading as &quot;top&quot;,
(default) &quot;bottom&quot;, or &quot;center&quot;.</p>
</td></tr>
<tr><td><code id="replaceTabs.inner_+3A_mar">mar</code></td>
<td>
<p>Figure margins, see the documentation for <code>par</code>.</p>
</td></tr>
<tr><td><code id="replaceTabs.inner_+3A_col.data">col.data</code></td>
<td>
<p>Colors for data elements.  If a single value is provided,
all data elements will be the same color.  If a matrix matching the
dimensions of the data is provided, each data element will receive the
specified color.</p>
</td></tr>
<tr><td><code id="replaceTabs.inner_+3A_col.rownames">col.rownames</code>, <code id="replaceTabs.inner_+3A_col.colnames">col.colnames</code></td>
<td>
<p>Colors for row names and column names,
respectively.  Either may be specified as a scalar or a vector of
appropriate length.</p>
</td></tr>
<tr><td><code id="replaceTabs.inner_+3A_wrap">wrap</code></td>
<td>
<p>If TRUE (default), will wrap column names and rownames</p>
</td></tr>
<tr><td><code id="replaceTabs.inner_+3A_wrap.colnames">wrap.colnames</code></td>
<td>
<p>The number of characters after which column labels will
be wrapped.  Default is 10.</p>
</td></tr>
<tr><td><code id="replaceTabs.inner_+3A_wrap.rownames">wrap.rownames</code></td>
<td>
<p>The number of characters after which row headings will
be wrapped.  Default is 10.</p>
</td></tr>
<tr><td><code id="replaceTabs.inner_+3A_...">...</code></td>
<td>
<p>Optional arguments passed to the text plotting command or
specialized object methods</p>
</td></tr>
<tr><td><code id="replaceTabs.inner_+3A_fixed.width">fixed.width</code></td>
<td>
<p>default is TRUE</p>
</td></tr>
<tr><td><code id="replaceTabs.inner_+3A_cspace">cspace</code></td>
<td>
<p>default is 1</p>
</td></tr>
<tr><td><code id="replaceTabs.inner_+3A_lspace">lspace</code></td>
<td>
<p>default is 1</p>
</td></tr>
<tr><td><code id="replaceTabs.inner_+3A_tab.width">tab.width</code></td>
<td>
<p>default is 8</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A new plot is created and the object is displayed using the largest font
that will fit on in the plotting region.  The <code>halign</code> and
<code>valign</code> parameters can be used to control the location of the string
within the plotting region.
</p>
<p>For matrixes and vectors a specialized textplot function is available, which
plots each of the cells individually, with column widths set according to
the sizes of the column elements.  If present, row and column labels will be
displayed in a bold font.
</p>
<p>textplot also uses replaceTabs, a function to replace all tabs in a string
with an appropriate number of spaces.  That function was also written by
Gregory R. Warnes and included in the 'gplots' package.
</p>


<h3>Author(s)</h3>

<p>Originally written by Gregory R. Warnes
<a href="mailto:warnes@bst.rochester.edu">warnes@bst.rochester.edu</a> for the package 'gplots', modified by
Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+plot">plot</a></code>, <br /> <code><a href="graphics.html#topic+text">text</a></code>, <br />
<code><a href="utils.html#topic+capture.output">capture.output</a></code>, <br /> <code><a href="gplots.html#topic+textplot">textplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Also see the examples in the original gplots textplot function
data(managers)
textplot(table.AnnualizedReturns(managers[,1:6]))

# This was really nice before Hmisc messed up 'format' from R-base
# prettify with format.df in hmisc package
# require("Hmisc")
# result = t(table.CalendarReturns(managers[,1:8]))[-1:-12,]

#  textplot(Hmisc::format.df(result, na.blank=TRUE, numeric.dollar=FALSE, 
#           cdec=rep(1,dim(result)[2])), rmar = 0.8, cmar = 1,  max.cex=.9, 
#           halign = "center", valign = "top", row.valign="center", wrap.rownames=20, 
#           wrap.colnames=10, col.rownames=c("red", rep("darkgray",5), 
#           rep("orange",2)), mar = c(0,0,4,0)+0.1)
#
# title(main="Calendar Returns")

</code></pre>

<hr>
<h2 id='Return.annualized'>calculate an annualized return for comparing instruments with different
length history</h2><span id='topic+Return.annualized'></span>

<h3>Description</h3>

<p>An average annualized return is convenient for comparing returns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Return.annualized(R, scale = NA, geometric = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Return.annualized_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="Return.annualized_+3A_scale">scale</code></td>
<td>
<p>number of periods in a year (daily scale = 252, monthly scale =
12, quarterly scale = 4)</p>
</td></tr>
<tr><td><code id="Return.annualized_+3A_geometric">geometric</code></td>
<td>
<p>utilize geometric chaining (TRUE) or simple/arithmetic chaining (FALSE) to aggregate returns,
default TRUE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Annualized returns are useful for comparing two assets.  To do so, you must
scale your observations to an annual scale by raising the compound return to
the number of periods in a year, and taking the root to the number of total
observations:
</p>
<p style="text-align: center;"><code class="reqn">prod(1+R_{a})^{\frac{scale}{n}}-1=\sqrt[n]{prod(1+R_{a})^{scale}}-1</code>
</p>

<p>where scale is the number of periods in a year, and n is the total number of
periods for which you have observations.
</p>
<p>For simple returns (geometric=FALSE), the formula is:
</p>
<p style="text-align: center;"><code class="reqn">\overline{R_{a}} \cdot scale</code>
</p>



<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>Bacon, Carl. <em>Practical Portfolio Performance Measurement
and Attribution</em>. Wiley. 2004. p. 6
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Return.cumulative">Return.cumulative</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
Return.annualized(managers[,1,drop=FALSE])
Return.annualized(managers[,1:8])
Return.annualized(managers[,1:8],geometric=FALSE)

</code></pre>

<hr>
<h2 id='Return.annualized.excess'>calculates an annualized excess return for comparing instruments with different
length history</h2><span id='topic+Return.annualized.excess'></span>

<h3>Description</h3>

<p>An average annualized excess return is convenient for comparing excess 
returns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Return.annualized.excess(Rp, Rb, scale = NA, geometric = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Return.annualized.excess_+3A_rp">Rp</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
portfolio returns</p>
</td></tr>
<tr><td><code id="Return.annualized.excess_+3A_rb">Rb</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of 
benchmark returns</p>
</td></tr>
<tr><td><code id="Return.annualized.excess_+3A_scale">scale</code></td>
<td>
<p>number of periods in a year (daily scale = 252, monthly scale =
12, quarterly scale = 4)</p>
</td></tr>
<tr><td><code id="Return.annualized.excess_+3A_geometric">geometric</code></td>
<td>
<p>generate geometric (TRUE) or simple (FALSE) excess returns,
default TRUE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Annualized returns are useful for comparing two assets. To do so, you must
scale your observations to an annual scale by raising the compound return to
the number of periods in a year, and taking the root to the number of total 
observations:
</p>
<p style="text-align: center;"><code class="reqn">prod(1+R_{a})^{\frac{scale}{n}}-1=\sqrt[n]{prod(1+R_{a})^{scale}}-
1</code>
</p>

<p>where scale is the number of periods in a year, and n is the total number of
periods for which you have observations.
</p>
<p>Finally having annualized returns for portfolio and benchmark we can compute
annualized excess return as difference in the annualized portfolio and 
benchmark returns in the arithmetic case:
</p>
<p style="text-align: center;"><code class="reqn">er = R_{pa} - R_{ba}</code>
</p>

<p>and as a geometric difference in the geometric case:
</p>
<p style="text-align: center;"><code class="reqn">er = \frac{(1 + R_{pa})}{(1 + R_{ba})} - 1</code>
</p>



<h3>Author(s)</h3>

<p>Andrii Babii
</p>


<h3>References</h3>

<p>Bacon, Carl. <em>Practical Portfolio Performance Measurement
and Attribution</em>. Wiley. 2004. p. 206-207
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Return.annualized">Return.annualized</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(managers)
Return.annualized.excess(Rp = managers[,1], Rb = managers[,8])

</code></pre>

<hr>
<h2 id='Return.calculate'>calculate simple or compound returns from prices</h2><span id='topic+Return.calculate'></span><span id='topic+CalculateReturns'></span>

<h3>Description</h3>

<p>calculate simple or compound returns from prices
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Return.calculate(prices, method = c("discrete", "log", "difference"))

CalculateReturns(prices, method = c("discrete", "log"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Return.calculate_+3A_prices">prices</code></td>
<td>
<p>data object containing ordered price observations</p>
</td></tr>
<tr><td><code id="Return.calculate_+3A_method">method</code></td>
<td>
<p>calculate &quot;discrete&quot; or &quot;log&quot; returns, default discrete(simple)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Two requirements should be made clear.  First, the function
<code>Return.calculate</code> assumes regular price data.  In this case, we
downloaded monthly close prices.  Prices can be for any time scale, such as
daily, weekly, monthly or annual, as long as the data consists of regular
observations.  Irregular observations require time period scaling to be
comparable.  Fortunately, <code><a href="xts.html#topic+to.period">to.period</a></code> in the <code>xts</code>
package, or the <code><a href="zoo.html#topic+aggregate.zoo">aggregate.zoo</a></code> in the <code>zoo</code> package
supports supports management and conversion of irregular time series.
</p>
<p>Second, if corporate actions, dividends, or other adjustments such as time-
or money-weighting are to be taken into account, those calculations must be
made separately. This is a simple function that assumes fully adjusted close
prices as input.  For the IBM timeseries in the example below, dividends and
corporate actions are not contained in the &quot;close&quot; price series, so we end
up with &quot;price returns&quot; instead of &quot;total returns&quot;.  This can lead to
significant underestimation of the return series over longer time periods.
To use adjusted returns, specify <code>quote="AdjClose"</code> in
<code><a href="tseries.html#topic+get.hist.quote">get.hist.quote</a></code>, which is found in package
<code>tseries</code>.
</p>
<p>We have changes the default arguments and settings for <code>method</code>
from <code>compound</code> and <code>simple</code> to <code>discrete</code> and 
<code>log</code> and <code>discrete</code> to avoid confusing between the return type
and the chaining method.  In most of the rest of <code>PerformanceAnalytics</code>,
compound and simple are used to refer to the <em>return chaining</em> method used for the returns.
The default for this function is to use discrete returns, because most other package 
functions use compound chaining by default.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>Bacon, C. <em>Practical Portfolio Performance Measurement and
Attribution</em>. Wiley. 2004. Chapter 2 <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Return.cumulative">Return.cumulative</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  ## Not run: 
    require(quantmod)
    prices = getSymbols("IBM", from = "1999-01-01", to = "2007-01-01")
  
## End(Not run)
  
R.IBM = Return.calculate(xts(prices), method="discrete")
colnames(R.IBM)="IBM"
chart.CumReturns(R.IBM,legend.loc="topleft", main="Cumulative Daily Returns for IBM")
round(R.IBM,2)
</code></pre>

<hr>
<h2 id='Return.centered'>calculate centered Returns</h2><span id='topic+Return.centered'></span><span id='topic+centeredcomoment'></span><span id='topic+centeredmoment'></span>

<h3>Description</h3>

<p>the <code class="reqn">n</code>-th centered moment is calculated as </p>
<p style="text-align: center;"><code class="reqn"> </code>
</p>
<p style="text-align: center;"><code class="reqn"> \mu^{(n)}(R) = E\lbrack(R-E(R))^n\rbrack </code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>Return.centered(R, ...)

centeredmoment(R, power)

centeredcomoment(Ra, Rb, p1, p2, normalize = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Return.centered_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="Return.centered_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
<tr><td><code id="Return.centered_+3A_power">power</code></td>
<td>
<p>power or moment to calculate</p>
</td></tr>
<tr><td><code id="Return.centered_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="Return.centered_+3A_rb">Rb</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
index, benchmark, portfolio, or secondary asset returns to compare against</p>
</td></tr>
<tr><td><code id="Return.centered_+3A_p1">p1</code></td>
<td>
<p>first power of the comoment</p>
</td></tr>
<tr><td><code id="Return.centered_+3A_p2">p2</code></td>
<td>
<p>second power of the comoment</p>
</td></tr>
<tr><td><code id="Return.centered_+3A_normalize">normalize</code></td>
<td>
<p>whether to standardize the calculation to agree with common
usage, or leave the default mathematical meaning</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions are used internally by PerformanceAnalytics to calculate
centered moments for a multivariate distribution as well as the standardized
moments of a portfolio distribution.  They are exposed here for users who
wish to use them directly, and we'll get more documentation written when we
can.
</p>
<p>These functions were first utilized in Boudt, Peterson, and Croux (2008),
and have been subsequently used in our other research.
</p>
<p>~~ Additional Details will be added to documentation as soon as we have time
to write them. Documentation Patches Welcome. ~~
</p>


<h3>Author(s)</h3>

<p>Kris Boudt and Brian Peterson
</p>


<h3>References</h3>

<p>Boudt, Kris, Brian G. Peterson, and Christophe Croux. 2008.
Estimation and Decomposition of Downside Risk for Portfolios with Non-Normal
Returns. Journal of Risk. Winter.
</p>
<p>Martellini, L. and Ziemann, V., 2010. Improved estimates of higher-order 
comoments and implications for portfolio selection. Review of Financial 
Studies, 23(4):1467-1502.
</p>
<p>Ranaldo, Angelo, and Laurent Favre Sr. 2005. How to Price Hedge Funds: From
Two- to Four-Moment CAPM. SSRN eLibrary.
</p>
<p>Scott, Robert C., and Philip A. Horvath. 1980. On the Direction of
Preference for Moments of Higher Order than the Variance. Journal of Finance
35(4):915-919.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

data(managers)
Return.centered(managers[,1:3,drop=FALSE])

</code></pre>

<hr>
<h2 id='Return.clean'>clean returns in a time series to to provide more robust risk estimates</h2><span id='topic+Return.clean'></span>

<h3>Description</h3>

<p>A function that provides access to multiple methods for cleaning outliers
from return data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Return.clean(R, method = c("none", "boudt", "geltner"), alpha = 0.01, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Return.clean_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="Return.clean_+3A_method">method</code></td>
<td>
<p>one of &quot;none&quot;, &quot;boudt&quot;, which applies the function
<code><a href="#topic+clean.boudt">clean.boudt</a></code> or &quot;geltner&quot; which applies the function
<code><a href="#topic+Return.Geltner">Return.Geltner</a></code>to R</p>
</td></tr>
<tr><td><code id="Return.clean_+3A_alpha">alpha</code></td>
<td>
<p>the percentage of outliers you want to clean</p>
</td></tr>
<tr><td><code id="Return.clean_+3A_...">...</code></td>
<td>
<p>additional parameters passed into the underlying cleaning
function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a wrapper for offering multiple data cleaning methods for data
objects containing returns.
</p>
<p>The primary value of data cleaning lies in creating a more robust and stable
estimation of the distribution generating the large majority of the return
data. The increased robustness and stability of the estimated moments using
cleaned data should be used for portfolio construction. If an investor
wishes to have a more conservative risk estimate, cleaning may not be
indicated for risk monitoring.
</p>
<p>In actual practice, it is probably best to back-test the results of both
cleaned and uncleaned series to see what works best when forecasting risk
with the particular combination of assets under consideration.
</p>
<p>In this version, only one method is supported.  See
<code><a href="#topic+clean.boudt">clean.boudt</a></code> for more details.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clean.boudt">clean.boudt</a></code> <br /> <code><a href="#topic+Return.Geltner">Return.Geltner</a></code> <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run:  # CRAN doesn't like how long this takes (&gt;5 secs)
data(managers)
head(Return.clean(managers[,1:4]),n=20)
chart.BarVaR(managers[,1,drop=FALSE], show.clean=TRUE, clean="boudt", lwd=2, methods="ModifiedVaR")

## End(Not run)

</code></pre>

<hr>
<h2 id='Return.convert'>Convert coredata content from one type of return to another</h2><span id='topic+Return.convert'></span>

<h3>Description</h3>

<p>This function takes an xts object, and using its attribute information, will convert 
information in the object into the desired output, selected by the user.  For example, all 
combinations of moving from one of 'discrete', 'log', 'difference' and 'level', to another different
data type (from the same list) are permissible.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Return.convert(
  R,
  destinationType = c("discrete", "log", "difference", "level"),
  seedValue = NULL,
  initial = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Return.convert_+3A_r">R</code></td>
<td>
<p>an xts object</p>
</td></tr>
<tr><td><code id="Return.convert_+3A_destinationtype">destinationType</code></td>
<td>
<p>one of 'discrete', 'log', 'difference' or 'level'</p>
</td></tr>
<tr><td><code id="Return.convert_+3A_seedvalue">seedValue</code></td>
<td>
<p>a numeric scalar indicating the (usually initial) index level or price of the series</p>
</td></tr>
<tr><td><code id="Return.convert_+3A_initial">initial</code></td>
<td>
<p>(default TRUE) a TRUE/FALSE flag associated with 'seedValue', indicating if this value is at the begginning of the series (TRUE) or at the end of the series (FALSE)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Erol Biceroglu
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Return.calculate">Return.calculate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># TBD

</code></pre>

<hr>
<h2 id='Return.cumulative'>calculate a compounded (geometric) cumulative return</h2><span id='topic+Return.cumulative'></span>

<h3>Description</h3>

<p>This is a useful function for calculating cumulative return over a period of
time, say a calendar year.  Can produce simple or geometric return.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Return.cumulative(R, geometric = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Return.cumulative_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="Return.cumulative_+3A_geometric">geometric</code></td>
<td>
<p>utilize geometric chaining (TRUE) or simple/arithmetic chaining (FALSE) to aggregate returns,
default TRUE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>product of all the individual period returns
</p>
<p style="text-align: center;"><code class="reqn">(1+r_{1})(1+r_{2})(1+r_{3})\ldots(1+r_{n})-1=prod(1+R)-1</code>
</p>



<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>Bacon, Carl. <em>Practical Portfolio Performance Measurement
and Attribution</em>. Wiley. 2004. p. 6
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Return.annualized">Return.annualized</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
Return.cumulative(managers[,1,drop=FALSE])
Return.cumulative(managers[,1:8])
Return.cumulative(managers[,1:8],geometric=FALSE)

</code></pre>

<hr>
<h2 id='Return.excess'>Calculates the returns of an asset in excess of the given risk free rate</h2><span id='topic+Return.excess'></span>

<h3>Description</h3>

<p>Calculates the returns of an asset in excess of the given &quot;risk free rate&quot;
for the period.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Return.excess(R, Rf = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Return.excess_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="Return.excess_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns, or as a single
digit average</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Ideally, your risk free rate will be for each period you have returns
observations, but a single average return for the period will work too.
</p>
<p>Mean of the period return minus the period risk free rate
</p>
<p style="text-align: center;"><code class="reqn">\overline{(R_{a}-R_{f})}</code>
</p>

<p>OR
</p>
<p>mean of the period returns minus a single numeric risk free rate
</p>
<p style="text-align: center;"><code class="reqn">\overline{R_{a}}-R_{f}</code>
</p>

<p>Note that while we have, in keeping with common academic usage, assumed that
the second parameter will be a risk free rate, you may also use any other
timeseries as the second argument.  A common alteration would be to use a
benchmark to produce excess returns over a specific benchmark, as
demonstrated in the examples below.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>Bacon, Carl. <em>Practical Portfolio Performance Measurement
and Attribution</em>. Wiley. 2004. p. 47-52
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
head(Return.excess(managers[,1,drop=FALSE], managers[,10,drop=FALSE]))
head(Return.excess(managers[,1,drop=FALSE], .04/12))
head(Return.excess(managers[,1:6], managers[,10,drop=FALSE]))
head(Return.excess(managers[,1,drop=FALSE], managers[,8,drop=FALSE]))

</code></pre>

<hr>
<h2 id='Return.Geltner'>calculate Geltner liquidity-adjusted return series</h2><span id='topic+Return.Geltner'></span>

<h3>Description</h3>

<p>David Geltner developed a method to remove estimating or liquidity bias in
real estate index returns.  It has since been applied with success to other
return series that show autocorrelation or illiquidity effects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Return.Geltner(Ra, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Return.Geltner_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="Return.Geltner_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The theory is that by correcting for autocorrelation, you are uncovering a
&quot;true&quot; return from a series of observed returns that contain illiquidity or
manual pricing effects.
</p>
<p>The Geltner autocorrelation adjusted return series may be calculated via:
</p>
<p style="text-align: center;"><code class="reqn"> </code>
</p>
<p style="text-align: center;"><code class="reqn">
R_{G}=\frac{R_{t}-(R_{t-1}\cdot\rho_{1})}{1-\rho_{1}} </code>
</p>

<p>where <code class="reqn">\rho_{1}</code> is the first-order autocorrelation of the
return series <code class="reqn">R_{a}</code> and <code class="reqn">R_{t}</code> is the return of
<code class="reqn">R_{a}</code> at time <code class="reqn">t</code> and <code class="reqn">R_{t-1}</code> is the one-period
lagged return.
</p>


<h3>Author(s)</h3>

<p>Brian Peterson
</p>


<h3>References</h3>

<p>&quot;Edhec Funds of Hedge Funds Reporting Survey : A Return-Based
Approach to Funds of Hedge Funds Reporting&quot;,Edhec Risk and Asset Management
Research Centre, January 2005,p. 27
</p>
<p>Geltner, David, 1991, Smoothing in Appraisal-Based Returns, Journal of Real
Estate Finance and Economics, Vol.4, p.327-345.
</p>
<p>Geltner, David, 1993, Estimating Market Values from Appraised Values without
Assuming an Efficient Market, Journal of Real Estate Research, Vol.8,
p.325-345.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
head(Return.Geltner(managers[,1:3]),n=20)

</code></pre>

<hr>
<h2 id='Return.locScaleRob'>Robust Filter for Time Series Returns</h2><span id='topic+Return.locScaleRob'></span>

<h3>Description</h3>

<p><code>Return.locScaleRob</code> returns the data after passing through a robust location and scale filter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Return.locScaleRob(R, alpha.robust = 0.05, normal.efficiency = 0.99, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Return.locScaleRob_+3A_r">R</code></td>
<td>
<p>Data of returns for assets or portfolios.</p>
</td></tr>
<tr><td><code id="Return.locScaleRob_+3A_alpha.robust">alpha.robust</code></td>
<td>
<p>Tuning parameter for the robust filter.</p>
</td></tr>
<tr><td><code id="Return.locScaleRob_+3A_normal.efficiency">normal.efficiency</code></td>
<td>
<p>Normal efficiency for robust filter.</p>
</td></tr>
<tr><td><code id="Return.locScaleRob_+3A_...">...</code></td>
<td>
<p>any other passthrough parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of the cleaned data.
</p>


<h3>Author(s)</h3>

<p>Xin Chen, <a href="mailto:chenx26@uw.edu">chenx26@uw.edu</a>
</p>
<p>Anthony-Alexander Christidis, <a href="mailto:anthony.christidis@stat.ubc.ca">anthony.christidis@stat.ubc.ca</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Loading data from PerformanceAnalytics
data(edhec, package = "PerformanceAnalytics")
class(edhec)
# Changing the data colnames
names(edhec) = c("CA", "CTA", "DIS", "EM", "EMN",
                 "ED", "FIA", "GM", "LS", "MA",
                 "RV", "SS", "FOF")
# Cleaning the returns time series for manager data
outRob &lt;- Return.locScaleRob(edhec$CA)

</code></pre>

<hr>
<h2 id='Return.portfolio'>Calculate weighted returns for a portfolio of assets</h2><span id='topic+Return.portfolio'></span><span id='topic+Return.rebalancing'></span>

<h3>Description</h3>

<p>Using a time series of returns and any regular or irregular time series of weights
for each asset, this function calculates the returns of a portfolio with the same 
periodicity of the returns data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Return.portfolio(
  R,
  weights = NULL,
  wealth.index = FALSE,
  contribution = FALSE,
  geometric = TRUE,
  rebalance_on = c(NA, "years", "quarters", "months", "weeks", "days"),
  value = 1,
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Return.portfolio_+3A_r">R</code></td>
<td>
<p>An xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="Return.portfolio_+3A_weights">weights</code></td>
<td>
<p>A time series or single-row matrix/vector containing asset
weights, as decimal percentages, treated as beginning of period weights.  
See Details below.</p>
</td></tr>
<tr><td><code id="Return.portfolio_+3A_wealth.index">wealth.index</code></td>
<td>
<p>TRUE/FALSE whether to return a wealth index. Default FALSE</p>
</td></tr>
<tr><td><code id="Return.portfolio_+3A_contribution">contribution</code></td>
<td>
<p>if contribution is TRUE, add the weighted return 
contributed by the asset in a given period. Default FALSE</p>
</td></tr>
<tr><td><code id="Return.portfolio_+3A_geometric">geometric</code></td>
<td>
<p>utilize geometric chaining (TRUE) or simple/arithmetic (FALSE)
to aggregate returns. Default TRUE.</p>
</td></tr>
<tr><td><code id="Return.portfolio_+3A_rebalance_on">rebalance_on</code></td>
<td>
<p>Default &quot;none&quot;; alternatively &quot;daily&quot; &quot;weekly&quot; &quot;monthly&quot; 
&quot;annual&quot;  to specify calendar-period rebalancing supported by 
<code><a href="xts.html#topic+endpoints">endpoints</a></code>. Ignored if <code>weights</code> is an xts object
that specifies the rebalancing dates.</p>
</td></tr>
<tr><td><code id="Return.portfolio_+3A_value">value</code></td>
<td>
<p>The beginning of period total portfolio value. This is used for calculating position value.</p>
</td></tr>
<tr><td><code id="Return.portfolio_+3A_verbose">verbose</code></td>
<td>
<p>If verbose is TRUE, return a list of intermediary calculations. 
See Details below.</p>
</td></tr>
<tr><td><code id="Return.portfolio_+3A_...">...</code></td>
<td>
<p>any other passthru parameters. Not currently used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, this function calculates the time series of portfolio returns given asset
returns and weights. In verbose mode, the function returns a list of intermediary 
calculations that users may find helpful, including both asset contribution and  
asset value through time.
</p>
<p>When asset return and weights are matched by period, contribution is simply the 
weighted return of the asset.  c_i = w_i * R_i Contributions are summable across the 
portfolio to calculate the total portfolio return.
</p>
<p>Contribution cannot be aggregated through time.  For example, say we have an equal 
weighted portfolio of five assets with monthly returns.  The geometric return of the 
portfolio over several months won't match any aggregation of the individual 
contributions of the assets, particularly if any rebalancing was done during the 
period.
</p>
<p>To aggregate contributions through time such that they are summable to the geometric 
returns of the portfolio, the calculation must track changes in the notional value of 
the assets and portfolio.  For example, contribution during a quarter will be 
calculated as the change in value of the position through those three months, divided 
by the original value of the portfolio.  Approaching it this way makes the 
calculation robust to weight changes as well. c_pi = V_(t-p)i - V_t)/V_ti  
</p>
<p>If the user does not specify weights, an equal weight portfolio is assumed.  
Alternatively, a vector or single-row matrix of weights that matches the length 
of the asset columns may be specified.  In either case, if no rebalancing period is
specified, the weights will be applied at the beginning of the asset time series
and no further rebalancing will take place. If a rebalancing period is specified, 
the portfolio will be rebalanced to the starting weights at the interval specified.
</p>
<p>Note that if <code>weights</code> is an xts object, then any value passed to 
<code>rebalance_on</code> is ignored. The <code>weights</code> object specifies the 
rebalancing dates, therefore a regular rebalancing frequency provided via
<code>rebalance_on</code> is not needed and ignored.
</p>
<p><code>Return.portfolio</code> will work only on daily or lower frequencies. If you are 
rebalancing intraday, you should be using a trades/prices framework like 
the <code>blotter</code> package, not a weights/returns framework.
</p>
<p>Irregular rebalancing can be done by specifying a time series of weights.  The 
function uses the date index of the weights for xts-style subsetting of rebalancing 
periods.
</p>
<p>Weights specified for rebalancing should be thought of as &quot;end-of-period&quot; weights. 
Rebalancing periods can be thought of as taking effect immediately after the close 
of the bar. So, a March 31 rebalancing date will actually be in effect for April 1. 
A December 31 rebalancing date will be in effect on Jan 1, and so forth. This 
convention was chosen because it fits with common usage, and because it simplifies 
xts Date subsetting via endpoints.
</p>
<p>In verbose mode, the function returns a list of data and intermediary calculations.
</p>

<ul>
<li><p><code>returns</code>: The portfolio returns.
</p>
</li>
<li><p><code>contribution</code>: The per period contribution to portfolio 
return of each asset. Contribution is calculated as BOP weight times the 
period's return divided by BOP value. Period contributions are summed 
across the individual assets to calculate portfolio return
</p>
</li>
<li><p><code>BOP.Weight</code>: Beginning of Period (BOP) Weight for each 
asset. An asset's BOP weight is calculated using the input weights 
(or assumed weights, see below) and rebalancing parameters given. The next 
period's BOP weight is either the EOP weights from the prior period or 
input weights given on a rebalance period.
</p>
</li>
<li><p><code>EOP.Weight:</code> End of Period (BOP) Weight for each asset. 
An asset's EOP weight is the sum of the asset's BOP weight and 
contribution for the period divided by the sum of the contributions and 
initial weights for the portfolio.
</p>
</li>
<li><p><code>BOP.Value:</code> BOP Value for each asset. The BOP value for each 
asset is the asset's EOP value from the prior period, unless there is a 
rebalance event.  If there is a rebalance event, the BOP value of the 
asset is the rebalance weight times the EOP value of the portfolio. That 
effectively provides a zero-transaction cost change to the position values 
as of that date to reflect the rebalance.  Note that the sum of the BOP 
values of the assets is the same as the prior period's EOP portfolio value.
</p>
</li>
<li><p><code>EOP.Value:</code> EOP Value for each asset. The EOP value is for 
each asset is calculated as (1 + asset return) times the asset's BOP value. 
The EOP portfolio value is the sum of EOP value across assets.
</p>
</li></ul>

<p>To calculate BOP and EOP position value, we create an index for each position.  The 
sum of that value across assets represents an indexed value of the total portfolio.  
Note that BOP and EOP position values are only computed when <code>geometric = TRUE</code>.
</p>
<p>From the value calculations, we can calculate different aggregations through time 
for the asset contributions.  Those are calculated as the EOP asset value less the 
BOP asset value; that quantity is divided by the BOP portfolio value.  
Across assets, those will sum to equal the geometric chained returns of the 
portfolio for that same time period.  The function does not do this directly, however.
</p>


<h3>Value</h3>

<p>returns a time series of returns weighted by the <code>weights</code>
parameter, or a list that includes intermediate calculations
</p>


<h3>Note</h3>

<p>This function was previously two functions: <code>Return.portfolio</code> and 
<code>Return.rebalancing</code>.  Both function names are still exported,
but the code is now common, and <code>Return.portfolio</code> is probably to be preferred.
</p>


<h3>Author(s)</h3>

<p>Peter Carl, Ross Bennett, Brian Peterson
</p>


<h3>References</h3>

<p>Bacon, C. <em>Practical Portfolio Performance Measurement and
Attribution</em>. Wiley. 2004. Chapter 2<br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Return.calculate">Return.calculate</a></code> <code><a href="xts.html#topic+endpoints">endpoints</a></code> <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)
Return.portfolio(edhec["1997",1:5], rebalance_on="quarters") # returns time series
Return.portfolio(edhec["1997",1:5], rebalance_on="quarters", verbose=TRUE) # returns list
# with a weights object
data(weights) # rebalance at the beginning of the year to various weights through time
chart.StackedBar(weights)
x &lt;- Return.portfolio(edhec["2000::",1:11], weights=weights,verbose=TRUE)
chart.CumReturns(x$returns)
chart.StackedBar(x$BOP.Weight)
chart.StackedBar(x$BOP.Value)

</code></pre>

<hr>
<h2 id='Return.read'>Read returns data with different date formats</h2><span id='topic+Return.read'></span>

<h3>Description</h3>

<p>A simple wrapper of read.zoo with some defaults for different date formats
and xts conversion
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Return.read(
  filename = stop("Please specify a filename"),
  frequency = c("d", "m", "q", "i", "o"),
  format.in = c("ISO8601", "excel", "oo", "gnumeric"),
  sep = ",",
  header = TRUE,
  check.names = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Return.read_+3A_filename">filename</code></td>
<td>
<p>the name of the file to be read</p>
</td></tr>
<tr><td><code id="Return.read_+3A_frequency">frequency</code></td>
<td>
 
<ul>
<li><p> &quot;d&quot; sets as a daily timeseries using <code><a href="base.html#topic+as.Date">as.Date</a></code>, 
</p>
</li>
<li><p> &quot;m&quot; sets as monthly timeseries using <code><a href="zoo.html#topic+as.yearmon">as.yearmon</a></code>, 
</p>
</li>
<li><p> &quot;q&quot; sets as a quarterly timeseries using <code><a href="zoo.html#topic+as.yearqtr">as.yearqtr</a></code>, and 
</p>
</li>
<li><p> &quot;i&quot; sets as irregular timeseries using <code><a href="base.html#topic+as.POSIXct">as.POSIXct</a></code> 
</p>
</li></ul>
</td></tr>
<tr><td><code id="Return.read_+3A_format.in">format.in</code></td>
<td>
<p>says how the data being read is formatted.  Although the
default is set to the ISO 8601 standard (which can also be set as &quot;
most spreadsheets have less sensible date formats as defaults. See below.</p>
</td></tr>
<tr><td><code id="Return.read_+3A_sep">sep</code></td>
<td>
<p>separator, default is &quot;,&quot;</p>
</td></tr>
<tr><td><code id="Return.read_+3A_header">header</code></td>
<td>
<p>a logical value indicating whether the file contains the names
of the variables as its first line.</p>
</td></tr>
<tr><td><code id="Return.read_+3A_check.names">check.names</code></td>
<td>
<p>logical. If TRUE then the names of the variables in the
data frame are checked to ensure that they are syntactically valid variable
names. If necessary they are adjusted (by make.names) so that they are, and
also to ensure that there are no duplicates. See
<code><a href="utils.html#topic+read.table">read.table</a></code></p>
</td></tr>
<tr><td><code id="Return.read_+3A_...">...</code></td>
<td>
<p>passes through any other parameters to
<code><a href="zoo.html#topic+read.zoo">read.zoo</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The parameter 'format.in' takes several values, including: 
</p>

<dl>
<dt>excel</dt><dd><p>default date format for MS Excel spreadsheet csv format, which is &quot;%m/%d/%Y&quot;</p>
</dd> 
<dt>oo</dt><dd><p>default date format for OpenOffice spreadsheet csv format, &quot;%m/%d/%y&quot;, although this may be operating system dependent</p>
</dd>
<dt>gnumeric</dt><dd><p>default date format for Gnumeric spreadsheet, which is &quot;%d-%b-%Y&quot;</p>
</dd> 
<dt>...</dt><dd><p>alternatively, any specific format may be passed in, such as &quot;%M/%y&quot;</p>
</dd> 
</dl>



<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="zoo.html#topic+read.zoo">read.zoo</a></code>, <code><a href="utils.html#topic+read.table">read.table</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
     ## Not run: 
     Return.read("managers.cvs", frequency="d")
     
## End(Not run)

</code></pre>

<hr>
<h2 id='Return.relative'>calculate the relative return of one asset to another</h2><span id='topic+Return.relative'></span>

<h3>Description</h3>

<p>Calculates the ratio of the cumulative performance for two assets through
time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Return.relative(Ra, Rb, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Return.relative_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="Return.relative_+3A_rb">Rb</code></td>
<td>
<p>return object for the benchmark asset</p>
</td></tr>
<tr><td><code id="Return.relative_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>xts or other time series of relative return
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chart.RelativePerformance">chart.RelativePerformance</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
head(Return.relative(managers[,1:3], managers[,8,drop=FALSE]),n=20)

</code></pre>

<hr>
<h2 id='RPESE.control'>Controls Function for the Computation of Standard Errors for Risk and Performance estimators</h2><span id='topic+RPESE.control'></span>

<h3>Description</h3>

<p><code>RPESE.controls</code> sets the different control parameters used in 
the compuation of standard errors for risk and performance estimators.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RPESE.control(
  estimator = c("Mean", "SD", "VaR", "ES", "SR", "SoR", "ESratio", "VaRratio", "SoR",
    "LPM", "OmegaRatio", "SemiSD", "RachevRatio")[1],
  se.method = NULL,
  cleanOutliers = NULL,
  fitting.method = NULL,
  freq.include = NULL,
  freq.par = NULL,
  a = NULL,
  b = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RPESE.control_+3A_estimator">estimator</code></td>
<td>
<p>Risk or performance estimator used to set default control parameters. Default is &quot;Mean&quot; estimator.</p>
</td></tr>
<tr><td><code id="RPESE.control_+3A_se.method">se.method</code></td>
<td>
<p>A character string indicating which method should be used to compute
the standard error of the estimated standard deviation. One or a combination of:
<code>"IFiid"</code> (default), <code>"IFcor"</code> (default), <code>"IFcorPW"</code>, <code>"IFcorAdapt"</code>,
<code>"BOOTiid"</code> or <code>"BOOTcor"</code>.</p>
</td></tr>
<tr><td><code id="RPESE.control_+3A_cleanoutliers">cleanOutliers</code></td>
<td>
<p>Boolean variable to indicate whether the pre-whitenning of the influence functions TS should be done through a robust filter.</p>
</td></tr>
<tr><td><code id="RPESE.control_+3A_fitting.method">fitting.method</code></td>
<td>
<p>Distribution used in the standard errors computation. Should be one of &quot;Exponential&quot; (default) or &quot;Gamma&quot;.</p>
</td></tr>
<tr><td><code id="RPESE.control_+3A_freq.include">freq.include</code></td>
<td>
<p>Frequency domain inclusion criteria. Must be one of &quot;All&quot; (default), &quot;Decimate&quot; or &quot;Truncate.&quot;</p>
</td></tr>
<tr><td><code id="RPESE.control_+3A_freq.par">freq.par</code></td>
<td>
<p>Percentage of the frequency used if <code>"freq.include"</code> is &quot;Decimate&quot; or &quot;Truncate.&quot; Default is 0.5.</p>
</td></tr>
<tr><td><code id="RPESE.control_+3A_a">a</code></td>
<td>
<p>First adaptive method parameter.</p>
</td></tr>
<tr><td><code id="RPESE.control_+3A_b">b</code></td>
<td>
<p>Second adaptive method parameter.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of different control parameters for the computation of standard errors.
</p>


<h3>Author(s)</h3>

<p>Anthony-Alexander Christidis, <a href="mailto:anthony.christidis@stat.ubc.ca">anthony.christidis@stat.ubc.ca</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Case where we want the default parameters for the ES
ES.control &lt;- RPESE.control(estimator="ES")
# Case where we also set additional parameters manually
ES.control.2 &lt;- RPESE.control(estimator="ES", se.method=c("IFcor", "BOOTiid"),
                              cleanOutliers=TRUE, freq.include="Decimate")
# These lists can be passed onto the functions (e.g., ES) to control the parameters
# for computing and returning standard errors.

</code></pre>

<hr>
<h2 id='Selectivity'>Selectivity of the return distribution</h2><span id='topic+Selectivity'></span>

<h3>Description</h3>

<p>Selectivity is the same as Jensen's alpha
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Selectivity(Ra, Rb, Rf = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Selectivity_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="Selectivity_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="Selectivity_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="Selectivity_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">Selectivity = r_p - r_f - \beta_p * (b - r_f)</code>
</p>

<p>where <code class="reqn">r_f</code> is the risk free rate, <code class="reqn">\beta_r</code> is the regression beta,
<code class="reqn">r_p</code> is the portfolio return and b is the benchmark return
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.78
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(portfolio_bacon)
print(Selectivity(portfolio_bacon[,1], portfolio_bacon[,2])) #expected -0.0141

data(managers)
print(Selectivity(managers['1996',1], managers['1996',8]))
print(Selectivity(managers['1996',1:5], managers['1996',8]))

</code></pre>

<hr>
<h2 id='SharpeRatio'>calculate a traditional or modified Sharpe Ratio of Return over StdDev or
VaR or ES</h2><span id='topic+SharpeRatio'></span><span id='topic+SharpeRatio.modified'></span>

<h3>Description</h3>

<p>The Sharpe ratio is simply the return per unit of risk (represented by
variability).  In the classic case, the unit of risk is the standard
deviation of the returns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SharpeRatio(
  R,
  Rf = 0,
  p = 0.95,
  FUN = c("StdDev", "VaR", "ES"),
  weights = NULL,
  annualize = FALSE,
  SE = FALSE,
  SE.control = NULL,
  ...
)

SharpeRatio.modified(
  R,
  Rf = 0,
  p = 0.95,
  FUN = c("StdDev", "VaR", "ES"),
  weights = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SharpeRatio_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="SharpeRatio_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="SharpeRatio_+3A_p">p</code></td>
<td>
<p>confidence level for calculation, default p=.95</p>
</td></tr>
<tr><td><code id="SharpeRatio_+3A_fun">FUN</code></td>
<td>
<p>one of &quot;StdDev&quot; or &quot;VaR&quot; or &quot;ES&quot; to use as the denominator</p>
</td></tr>
<tr><td><code id="SharpeRatio_+3A_weights">weights</code></td>
<td>
<p>portfolio weighting vector, default NULL, see Details in
<code><a href="#topic+VaR">VaR</a></code></p>
</td></tr>
<tr><td><code id="SharpeRatio_+3A_annualize">annualize</code></td>
<td>
<p>if TRUE, annualize the measure, default FALSE</p>
</td></tr>
<tr><td><code id="SharpeRatio_+3A_se">SE</code></td>
<td>
<p>TRUE/FALSE whether to ouput the standard errors of the estimates of the risk measures, default FALSE.</p>
</td></tr>
<tr><td><code id="SharpeRatio_+3A_se.control">SE.control</code></td>
<td>
<p>Control parameters for the computation of standard errors. Should be done using the <code><a href="#topic+RPESE.control">RPESE.control</a></code> function.</p>
</td></tr>
<tr><td><code id="SharpeRatio_+3A_...">...</code></td>
<td>
<p>any other passthru parameters to the VaR or ES functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">\frac{\overline{(R_{a}-R_{f})}}{\sqrt{\sigma_{(R_{a}-R_{f})}}}</code>
</p>

<p>William Sharpe now recommends <code><a href="#topic+InformationRatio">InformationRatio</a></code> preferentially
to the original Sharpe Ratio.
</p>
<p>The higher the Sharpe ratio, the better the combined performance of &quot;risk&quot;
and return.
</p>
<p>As noted, the traditional Sharpe Ratio is a risk-adjusted measure of return
that uses standard deviation to represent risk.
</p>
<p>A number of papers now recommend using a &quot;modified Sharpe&quot; ratio using a
Modified Cornish-Fisher VaR or CVaR/Expected Shortfall as the measure of
Risk.
</p>
<p>We have recently extended this concept to create multivariate modified
Sharpe-like Ratios for standard deviation, Gaussian VaR, modified VaR,
Gaussian Expected Shortfall, and modified Expected Shortfall. See
<code><a href="#topic+VaR">VaR</a></code> and <code><a href="#topic+ES">ES</a></code>.  You can pass additional arguments
to <code><a href="#topic+VaR">VaR</a></code> and <code><a href="#topic+ES">ES</a></code> via ... The most important is
probably the 'method' argument/
</p>
<p>This function returns a traditional or modified Sharpe ratio for the same
periodicity of the data being input (e.g., monthly data -&gt; monthly SR)
</p>


<h3>Author(s)</h3>

<p>Brian G. Peterson
</p>


<h3>References</h3>

<p>Sharpe, W.F. The Sharpe Ratio,<em>Journal of Portfolio
Management</em>,Fall 1994, 49-58.
</p>
<p>Laurent Favre and Jose-Antonio Galeano. Mean-Modified Value-at-Risk
Optimization with Hedge Funds. Journal of Alternative Investment, Fall 2002,
v 5.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SharpeRatio.annualized">SharpeRatio.annualized</a></code> <br />
<code><a href="#topic+InformationRatio">InformationRatio</a></code> <br /> <code><a href="#topic+TrackingError">TrackingError</a></code> <br />
<code><a href="#topic+ActivePremium">ActivePremium</a></code> <br /> <code><a href="#topic+SortinoRatio">SortinoRatio</a></code> <br />
<code><a href="#topic+VaR">VaR</a></code> <br /> <code><a href="#topic+ES">ES</a></code> <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
SharpeRatio(managers[,1,drop=FALSE], Rf=.035/12, FUN="StdDev") 
SharpeRatio(managers[,1,drop=FALSE], Rf = managers[,10,drop=FALSE], FUN="StdDev")
SharpeRatio(managers[,1:6], Rf=.035/12, FUN="StdDev") 
SharpeRatio(managers[,1:6], Rf = managers[,10,drop=FALSE], FUN="StdDev")



data(edhec)
SharpeRatio(edhec[, 6, drop = FALSE], FUN="VaR")
SharpeRatio(edhec[, 6, drop = FALSE], Rf = .04/12, FUN="VaR")
SharpeRatio(edhec[, 6, drop = FALSE], Rf = .04/12, FUN="VaR" , method="gaussian")
SharpeRatio(edhec[, 6, drop = FALSE], FUN="ES")

# and all the methods
SharpeRatio(managers[,1:9], Rf = managers[,10,drop=FALSE])
SharpeRatio(edhec,Rf = .04/12)

</code></pre>

<hr>
<h2 id='SharpeRatio.annualized'>calculate annualized Sharpe Ratio</h2><span id='topic+SharpeRatio.annualized'></span>

<h3>Description</h3>

<p>The Sharpe Ratio is a risk-adjusted measure of return that uses standard
deviation to represent risk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SharpeRatio.annualized(R, Rf = 0, scale = NA, geometric = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SharpeRatio.annualized_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="SharpeRatio.annualized_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="SharpeRatio.annualized_+3A_scale">scale</code></td>
<td>
<p>number of periods in a year (daily scale = 252, monthly scale =
12, quarterly scale = 4)</p>
</td></tr>
<tr><td><code id="SharpeRatio.annualized_+3A_geometric">geometric</code></td>
<td>
<p>utilize geometric chaining (TRUE) or simple/arithmetic chaining (FALSE) to aggregate returns,
default TRUE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Sharpe ratio is simply the return per unit of risk (represented by
variance).  The higher the Sharpe ratio, the better the combined performance
of &quot;risk&quot; and return.
</p>
<p>This function annualizes the number based on the scale parameter.
</p>
<p style="text-align: center;"><code class="reqn">\frac{\sqrt[n]{prod(1+R_{a})^{scale}}-1}{\sqrt{scale}\cdot\sqrt{\sigma}}</code>
</p>

<p>Using an annualized Sharpe Ratio is useful for comparison of multiple return
streams.  The annualized Sharpe ratio is computed by dividing the annualized
mean monthly excess return by the annualized monthly standard deviation of
excess return.
</p>
<p>William Sharpe now recommends Information Ratio preferentially to the
original Sharpe Ratio.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>Sharpe, W.F. The Sharpe Ratio,<em>Journal of Portfolio
Management</em>,Fall 1994, 49-58.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SharpeRatio">SharpeRatio</a></code> <br /> <code><a href="#topic+InformationRatio">InformationRatio</a></code> <br />
<code><a href="#topic+TrackingError">TrackingError</a></code> <br /> <code><a href="#topic+ActivePremium">ActivePremium</a></code> <br />
<code><a href="#topic+SortinoRatio">SortinoRatio</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
SharpeRatio.annualized(managers[,1,drop=FALSE], Rf=.035/12) 
SharpeRatio.annualized(managers[,1,drop=FALSE], Rf = managers[,10,drop=FALSE])
SharpeRatio.annualized(managers[,1:6], Rf=.035/12) 
SharpeRatio.annualized(managers[,1:6], Rf = managers[,10,drop=FALSE])
SharpeRatio.annualized(managers[,1:6], Rf = managers[,10,drop=FALSE],geometric=FALSE)

</code></pre>

<hr>
<h2 id='ShrinkageMoments'>Functions for calculating shrinkage-based comoments of financial time series</h2><span id='topic+ShrinkageMoments'></span><span id='topic+M2.shrink'></span><span id='topic+M3.shrink'></span><span id='topic+M4.shrink'></span>

<h3>Description</h3>

<p>calculates covariance, coskewness and cokurtosis matrices using linear shrinkage
between the sample estimator and a structured estimator
</p>


<h3>Usage</h3>

<pre><code class='language-R'>M2.shrink(R, targets = 1, f = NULL)

M3.shrink(R, targets = 1, f = NULL, unbiasedMSE = FALSE, as.mat = TRUE)

M4.shrink(R, targets = 1, f = NULL, as.mat = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ShrinkageMoments_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="ShrinkageMoments_+3A_targets">targets</code></td>
<td>
<p>vector of integers selecting the target matrices to shrink to. The first four
structures are, in order: 'independent marginals', 'independent and identical marginals', 
'observed 1-factor model' and 'constant correlation'. See Details.</p>
</td></tr>
<tr><td><code id="ShrinkageMoments_+3A_f">f</code></td>
<td>
<p>vector or matrix with observations of the factor, to be used with target 3. See Details.</p>
</td></tr>
<tr><td><code id="ShrinkageMoments_+3A_unbiasedmse">unbiasedMSE</code></td>
<td>
<p>TRUE/FALSE whether to use a correction to have an unbiased
estimator for the marginal skewness values, in case of targets 1 and/or 2, default FALSE</p>
</td></tr>
<tr><td><code id="ShrinkageMoments_+3A_as.mat">as.mat</code></td>
<td>
<p>TRUE/FALSE whether to return the full moment matrix or only
the vector with the unique elements (the latter is advised for speed), default
TRUE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The coskewness and cokurtosis matrices are defined as the matrices of dimension 
p x p^2 and p x p^3 containing the third and fourth order central moments. They
are useful for measuring nonlinear dependence between different assets of the 
portfolio and computing modified VaR and modified ES of a portfolio.
</p>
<p>Shrinkage estimation for the covariance matrix was popularized by Ledoit and 
Wolf (2003, 2004). An extension to coskewness and cokurtosis matrices by
Martellini and Ziemann (2010) uses the 1-factor and constant-correlation structured
comoment matrices as targets. In Boudt, Cornilly and Verdonck (2017) the framework
of single-target shrinkage for the coskewness and cokurtosis matrices is 
extended to a multi-target setting, making it possible to include several target matrices
at once. Also, an option to enhance small sample performance for coskewness estimation
was proposed, resulting in the option 'unbiasedMSE' present in the 'M3.shrink' function.
</p>
<p>The first four target matrices of the 'M2.shrink', 'M3.shrink' and 'M4.shrink' 
correspond to the models 'independent marginals', 'independent and identical marginals', 
'observed 1-factor model' and 'constant correlation'. Coskewness shrinkage includes two
more options, target 5 corresponds to the latent 1-factor model proposed in Simaan (1993)
and target 6 is the coskewness matrix under central-symmetry, a matrix full of zeros.
For more details on the targets, we refer to Boudt, Cornilly and Verdonck (2017) and
the supplementary appendix.
</p>
<p>If f is a matrix containing multiple factors, then the shrinkage estimator will
use each factor in a seperate single-factor model and use multi-target shrinkage
to all targets matrices at once.
</p>


<h3>Author(s)</h3>

<p>Dries Cornilly
</p>


<h3>References</h3>

<p>Boudt, Kris, Brian G. Peterson, and Christophe Croux. 2008.
Estimation and Decomposition of Downside Risk for Portfolios with Non-Normal
Returns. Journal of Risk. Winter.
</p>
<p>Boudt, Kris, Cornilly, Dries and Verdonck, Tim. 2017. A Coskewness Shrinkage 
Approach for Estimating the Skewness of Linear Combinations of Random Variables. 
Submitted. Available at SSRN: https://ssrn.com/abstract=2839781
</p>
<p>Ledoit, Olivier and Wolf, Michael. 2003. Improved estimation of the covariance matrix 
of stock returns with an application to portfolio selection. Journal of empirical 
finance, 10(5), 603-621.
</p>
<p>Ledoit, Olivier and Wolf, Michael. 2004. A well-conditioned estimator for large-dimensional 
covariance matrices. Journal of multivariate analysis, 88(2), 365-411.
</p>
<p>Martellini, Lionel and Ziemann, V\&quot;olker. 2010. Improved estimates of higher-order 
comoments and implications for portfolio selection. Review of Financial 
Studies, 23(4), 1467-1502.
</p>
<p>Simaan, Yusif. 1993. Portfolio selection and asset pricing: three-parameter framework. 
Management Science, 39(5), 68-577.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CoMoments">CoMoments</a></code> <br /> <code><a href="#topic+StructuredMoments">StructuredMoments</a></code> <br /> <code><a href="#topic+EWMAMoments">EWMAMoments</a></code> <br /> <code><a href="#topic+MCA">MCA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)

# construct an underlying factor (market-factor, observed factor, PCA, ...)
f &lt;- rowSums(edhec)

# multi-target shrinkage with targets 1, 3 and 4
# as.mat = F' would speed up calculations in higher dimensions
targets &lt;- c(1, 3, 4)
sigma &lt;- M2.shrink(edhec, targets, f)$M2sh
m3 &lt;- M3.shrink(edhec, targets, f)$M3sh
m4 &lt;- M4.shrink(edhec, targets, f)$M4sh

# compute equal-weighted portfolio modified ES
mu &lt;- colMeans(edhec)
p &lt;- length(mu)
ES(p = 0.95, portfolio_method = "component", weights = rep(1 / p, p), mu = mu, 
    sigma = sigma, m3 = m3, m4 = m4)

# compare to sample method
sigma &lt;- cov(edhec)
m3 &lt;- M3.MM(edhec)
m4 &lt;- M4.MM(edhec)
ES(p = 0.95, portfolio_method = "component", weights = rep(1 / p, p), mu = mu, 
    sigma = sigma, m3 = m3, m4 = m4)

</code></pre>

<hr>
<h2 id='skewness'>Skewness</h2><span id='topic+skewness'></span>

<h3>Description</h3>

<p>compute skewness of a univariate distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>skewness(x, na.rm = FALSE, method = c("moment", "fisher", "sample"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="skewness_+3A_x">x</code></td>
<td>
<p>a numeric vector or object.</p>
</td></tr>
<tr><td><code id="skewness_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical. Should missing values be removed?</p>
</td></tr>
<tr><td><code id="skewness_+3A_method">method</code></td>
<td>
<p>a character string which specifies the method of computation.
These are either <code>"moment"</code> or <code>"fisher"</code> The <code>"moment"</code>
method is based on the definitions of skewnessfor distributions; these forms
should be used when resampling (bootstrap or jackknife). The <code>"fisher"</code>
method correspond to the usual &quot;unbiased&quot; definition of sample variance,
although in the case of skewness exact unbiasedness is not possible. The 
<code>"sample"</code> method gives the sample skewness of the distribution.</p>
</td></tr>
<tr><td><code id="skewness_+3A_...">...</code></td>
<td>
<p>arguments to be passed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function was ported from the RMetrics package fUtilities to eliminate a
dependency on fUtiltiies being loaded every time.  The function is identical
except for the addition of <code><a href="#topic+checkData">checkData</a> and column support.</code>
</p>
<p style="text-align: center;"><code class="reqn">Skewness(moment) = \frac{1}{n}*\sum^{n}_{i=1}(\frac{r_i - \overline{r}}{\sigma_P})^3</code>
</p>

<p style="text-align: center;"><code class="reqn">Skewness(sample) =  \frac{n}{(n-1)*(n-2)}*\sum^{n}_{i=1}(\frac{r_i - \overline{r}}{\sigma_{S_P}})^3 </code>
</p>

<p style="text-align: center;"><code class="reqn">Skewness(fisher) = \frac{\frac{\sqrt{n*(n-1)}}{n-2}*\sum^{n}_{i=1}\frac{x^3}{n}}{\sum^{n}_{i=1}(\frac{x^2}{n})^{3/2}}</code>
</p>

<p>where <code class="reqn">n</code> is the number of return, <code class="reqn">\overline{r}</code> is the mean of the return
distribution, <code class="reqn">\sigma_P</code> is its standard deviation and <code class="reqn">\sigma_{S_P}</code> is its
sample standard deviation
</p>


<h3>Author(s)</h3>

<p>Diethelm Wuertz, Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.83-84
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kurtosis">kurtosis</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## mean -
## var -
   # Mean, Variance:
   r = rnorm(100)
   mean(r)
   var(r)

## skewness -
   skewness(r)
data(managers)
skewness(managers)

</code></pre>

<hr>
<h2 id='SkewnessKurtosisRatio'>Skewness-Kurtosis ratio of the return distribution</h2><span id='topic+SkewnessKurtosisRatio'></span><span id='topic+Skewness-KurtosisRatio'></span>

<h3>Description</h3>

<p>Skewness-Kurtosis ratio is the division of Skewness by Kurtosis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SkewnessKurtosisRatio(R, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SkewnessKurtosisRatio_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="SkewnessKurtosisRatio_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is used in conjunction with the Sharpe ratio to rank portfolios.
The higher the rate the better.
</p>
<p style="text-align: center;"><code class="reqn"> SkewnessKurtosisRatio(R , MAR) = \frac{S}{K}</code>
</p>

<p>where <code class="reqn">S</code> is the skewness and <code class="reqn">K</code> is the Kurtosis
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.100
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(portfolio_bacon)
print(SkewnessKurtosisRatio(portfolio_bacon[,1])) #expected -0.034

data(managers)
print(SkewnessKurtosisRatio(managers['1996']))
print(SkewnessKurtosisRatio(managers['1996',1]))

</code></pre>

<hr>
<h2 id='SmoothingIndex'>calculate Normalized Getmansky Smoothing Index</h2><span id='topic+SmoothingIndex'></span>

<h3>Description</h3>

<p>Proposed by Getmansky et al to provide a normalized measure of &quot;liquidity
risk.&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SmoothingIndex(R, neg.thetas = FALSE, MAorder = 2, verbose = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SmoothingIndex_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="SmoothingIndex_+3A_neg.thetas">neg.thetas</code></td>
<td>
<p>if FALSE, function removes negative coefficients (thetas)
when calculating the index</p>
</td></tr>
<tr><td><code id="SmoothingIndex_+3A_maorder">MAorder</code></td>
<td>
<p>specify the number of periods used to calculate the moving
average, defaults to 2</p>
</td></tr>
<tr><td><code id="SmoothingIndex_+3A_verbose">verbose</code></td>
<td>
<p>if TRUE, return a list containing the Thetas in addition to
the smoothing index/</p>
</td></tr>
<tr><td><code id="SmoothingIndex_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To measure the effects of smoothing, Getmansky, Lo, et al (2004) define a
&quot;smoothing profile&quot; as a vector of coefficients for an MLE fit on returns
using a two-period moving-average process.
</p>
<p>The moving-average process of order <code class="reqn">k=2</code> (specified using
<code>MAorder</code>) gives <code class="reqn">R_t = \theta_{0} R_{t} + \theta_1 R_{t -1} +
\theta_2 R_{t-2}</code>, under the constraint that the sum of the coefficients is
equal to 1. In , the <code>arima</code> function allows us to create an MA(2)
model using an &quot;ARIMA(p,d,q)&quot; model, where <code class="reqn">p</code> is the number of
autoregressive terms (AR), <code class="reqn">d</code> is the degree of differencing, and
<code class="reqn">q</code> is the number of lagged forecast errors (MA) in the prediction
equation.  The <code>order</code> parameter allows us to specify the three
components <code class="reqn">(p, d, q)</code> as an argument, e.g., <code>order = c(0, 0, 2)</code>.
The <code>method</code> specifies how to fit the model, in this case using maximum
likelihood estimation (MLE) in a fashion similar to the estimation of
standard moving-average time series models, using:
</p>
<p><code>arima(ra, order=c(0,0,2), method="ML", transform.pars=TRUE,
include.mean=FALSE)</code>
</p>
<p><code>include.mean</code>: Getmansky, et al. (2004) p 555 &quot;By applying the above
procedure to observed de-meaned returns...&quot;, so we set that parameter to
'FALSE'.
</p>
<p><code>transform.pars</code>: ibid, &quot;we impose the additional restriction that the
estimated MA(k) process be invertible,&quot; so we set the parameter to 'TRUE'.
</p>
<p>The coefficients, <code class="reqn">\theta_{j}</code>, are then normalized to sum to
interpreted as a &quot;weighted average of the fund's true returns over the most
recent <code class="reqn">k + 1</code> periods, including the current period.&quot;
</p>
<p>If these weights are disproportionately centered on a small number of lags,
relatively little serial correlation will be induced. However, if the
weights are evenly distributed among many lags, this would show higher
serial correlation.
</p>
<p>The paper notes that because <code class="reqn">\theta_j \in [0, 1]</code>, <code class="reqn">\xi</code> is also
confined to the unit interval, and is minimized when all the
<code class="reqn">\theta_j</code>'s are identical.  That implies a value of <code class="reqn">1/(k + 1)</code> for
<code class="reqn">\xi</code>, and a maximum value of <code class="reqn">\xi = 1</code> when one coefficient is 1
and the rest are 0.  In the context of smoothed returns, a lower value of
<code class="reqn">\xi</code> implies more smoothing, and the upper bound of 1 implies no
smoothing.
</p>
<p>The &quot;smoothing index&quot;, represented as <code class="reqn">\xi</code>, is calculated the same way
the Herfindahl index.  The Herfindal measure is well known in the industrial
organization literature as a measure of the concentration of firms in a
given industry where <code class="reqn">y_j</code> represents the market share of firm <code class="reqn">j</code>.
</p>
<p>This method (as well as the implementation described in the paper), does not
enforce <code class="reqn">\theta_j \in [0, 1]</code>, so <code class="reqn">\xi</code> is not limited to that range
either.  All we can say is that lower values are &quot;less liquid&quot; and higher
values are &quot;more liquid&quot; or mis-specified.  In this function, setting the
parameter neg.thetas = FALSE does enforce the limitation, eliminating
negative autocorrelation coefficients from the calculation (the papers below
do not make an economic case for eliminating negative autocorrelation,
however).
</p>
<p>Interpretation of the resulting value is difficult.  All we can say is that
lower values appear to have autocorrelation structure like we might expect
of &quot;less liquid&quot; instruments.  Higher values appear &quot;more liquid&quot; or are
poorly fit or mis-specified.
</p>


<h3>Acknowledgments</h3>

<p>Thanks to Dr. Stefan Albrecht, CFA, for invaluable
input.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>Chan, Nicholas, Mila Getmansky, Shane M. Haas, and Andrew W. Lo.
2005. Systemic Risk and Hedge Funds. NBER Working Paper Series (11200).
Getmansky, Mila, Andrew W. Lo, and Igor Makarov. 2004. An Econometric Model
of Serial Correlation and Illiquidity in Hedge Fund Returns. Journal of
Financial Economics (74): 529-609.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
data(edhec)
SmoothingIndex(managers[,1,drop=FALSE])
SmoothingIndex(managers[,1:8])
SmoothingIndex(edhec)

</code></pre>

<hr>
<h2 id='sortDrawdowns'>order list of drawdowns from worst to best</h2><span id='topic+sortDrawdowns'></span>

<h3>Description</h3>

<p>sortDrawdowns(findDrawdowns(R)) Gives the drawdowns in order of worst to
best
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sortDrawdowns(runs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sortDrawdowns_+3A_runs">runs</code></td>
<td>
<p>pass in runs array from findDrawdowns to be sorted</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns a sorted list: </p>
 
<ul>
<li><p> return depth of drawdown 
</p>
</li>
<li><p> from starting period 
</p>
</li>
<li><p> to ending period 
</p>
</li>
<li><p> length length in periods 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Peter Carl <br /> modified with permission from prototype function by
Sankalp Upadhyay
</p>


<h3>References</h3>

<p>Bacon, C. <em>Practical Portfolio Performance Measurement and
Attribution</em>. Wiley. 2004. p. 88 <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DownsideDeviation">DownsideDeviation</a></code> <br /> <code><a href="#topic+maxDrawdown">maxDrawdown</a></code> <br />
<code><a href="#topic+findDrawdowns">findDrawdowns</a></code> <br /> <code><a href="#topic+sortDrawdowns">sortDrawdowns</a></code> <br />
<code><a href="#topic+chart.Drawdown">chart.Drawdown</a></code> <br /> <code><a href="#topic+table.Drawdowns">table.Drawdowns</a></code> <br />
<code><a href="#topic+table.DownsideRisk">table.DownsideRisk</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)
findDrawdowns(edhec[,"Funds of Funds", drop=FALSE])
sortDrawdowns(findDrawdowns(edhec[,"Funds of Funds", drop=FALSE]))

</code></pre>

<hr>
<h2 id='SortinoRatio'>calculate Sortino Ratio of performance over downside risk</h2><span id='topic+SortinoRatio'></span>

<h3>Description</h3>

<p>Sortino proposed an improvement on the Sharpe Ratio to better account for
skill and excess performance by using only downside semivariance as the
measure of risk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SortinoRatio(
  R,
  MAR = 0,
  ...,
  weights = NULL,
  threshold = c("MAR", "mean")[1],
  SE = FALSE,
  SE.control = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SortinoRatio_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="SortinoRatio_+3A_mar">MAR</code></td>
<td>
<p>Minimum Acceptable Return, in the same periodicity as your
returns</p>
</td></tr>
<tr><td><code id="SortinoRatio_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
<tr><td><code id="SortinoRatio_+3A_weights">weights</code></td>
<td>
<p>portfolio weighting vector, default NULL</p>
</td></tr>
<tr><td><code id="SortinoRatio_+3A_threshold">threshold</code></td>
<td>
<p>Parameter to determine whether we use a &quot;MAR&quot; (default) or &quot;mean&quot; threshold.</p>
</td></tr>
<tr><td><code id="SortinoRatio_+3A_se">SE</code></td>
<td>
<p>TRUE/FALSE whether to ouput the standard errors of the estimates of the risk measures, default FALSE.</p>
</td></tr>
<tr><td><code id="SortinoRatio_+3A_se.control">SE.control</code></td>
<td>
<p>Control parameters for the computation of standard errors. Should be done using the <code><a href="#topic+RPESE.control">RPESE.control</a></code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Sortino contends that risk should be measured in terms of not meeting the
investment goal.  This gives rise to the notion of &ldquo;Minimum
Acceptable Return&rdquo; or MAR.  All of Sortino's proposed measures include the
MAR, and are more sensitive to downside or extreme risks than measures that
use volatility(standard deviation of returns) as the measure of risk.
</p>
<p>Choosing the MAR carefully is very important, especially when comparing
disparate investment choices.  If the MAR is too low, it will not adequately
capture the risks that concern the investor, and if the MAR is too high, it
will unfavorably portray what may otherwise be a sound investment.  When
comparing multiple investments, some papers recommend using the risk free
rate as the MAR.  Practitioners may wish to choose one MAR for consistency,
several standardized MAR values for reporting a range of scenarios, or a MAR
customized to the objective of the investor.
</p>
<p style="text-align: center;"><code class="reqn"> SortinoRatio=\frac{(\overline{R_{a} - MAR})}{\delta_{MAR}} </code>
</p>
<p> where
<code class="reqn">\delta_{MAR}</code> is the <code><a href="#topic+DownsideDeviation">DownsideDeviation</a></code>.
</p>


<h3>Author(s)</h3>

<p>Brian G. Peterson
</p>


<h3>References</h3>

<p>Sortino, F. and Price, L. Performance Measurement in a Downside
Risk Framework. <em>Journal of Investing</em>. Fall 1994, 59-65.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SharpeRatio">SharpeRatio</a></code> <br /> <code><a href="#topic+DownsideDeviation">DownsideDeviation</a></code> <br />
<code><a href="#topic+SemiVariance">SemiVariance</a></code> <br /> <code><a href="#topic+SemiDeviation">SemiDeviation</a></code> <br />
<code><a href="#topic+InformationRatio">InformationRatio</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
round(SortinoRatio(managers[, 1]),4)
round(SortinoRatio(managers[, 1:8]),4)

</code></pre>

<hr>
<h2 id='SpecificRisk'>Specific risk of the return distribution</h2><span id='topic+SpecificRisk'></span>

<h3>Description</h3>

<p>Specific risk is the standard deviation of the error term in the
regression equation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SpecificRisk(Ra, Rb, Rf = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SpecificRisk_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="SpecificRisk_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="SpecificRisk_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="SpecificRisk_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.75
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(portfolio_bacon)
print(SpecificRisk(portfolio_bacon[,1], portfolio_bacon[,2])) #expected 0.0329

data(managers)
print(SpecificRisk(managers['1996',1], managers['1996',8]))
print(SpecificRisk(managers['1996',1:5], managers['1996',8]))

</code></pre>

<hr>
<h2 id='StdDev'>calculates Standard Deviation for univariate and multivariate series, also
calculates component contribution to standard deviation of a portfolio</h2><span id='topic+StdDev'></span>

<h3>Description</h3>

<p>calculates Standard Deviation for univariate and multivariate series, also
calculates component contribution to standard deviation of a portfolio
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StdDev(
  R,
  ...,
  clean = c("none", "boudt", "geltner", "locScaleRob"),
  portfolio_method = c("single", "component"),
  weights = NULL,
  mu = NULL,
  sigma = NULL,
  use = "everything",
  method = c("pearson", "kendall", "spearman"),
  SE = FALSE,
  SE.control = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StdDev_+3A_r">R</code></td>
<td>
<p>a vector, matrix, data frame, timeSeries or zoo object of asset
returns</p>
</td></tr>
<tr><td><code id="StdDev_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
<tr><td><code id="StdDev_+3A_clean">clean</code></td>
<td>
<p>method for data cleaning through <code><a href="#topic+Return.clean">Return.clean</a></code>.
Current options are &quot;none&quot;, &quot;boudt&quot;, &quot;geltner&quot;, or &quot;locScaleRob&quot;.</p>
</td></tr>
<tr><td><code id="StdDev_+3A_portfolio_method">portfolio_method</code></td>
<td>
<p>one of &quot;single&quot;,&quot;component&quot; defining whether to do
univariate/multivariate or component calc, see Details.</p>
</td></tr>
<tr><td><code id="StdDev_+3A_weights">weights</code></td>
<td>
<p>portfolio weighting vector, default NULL, see Details</p>
</td></tr>
<tr><td><code id="StdDev_+3A_mu">mu</code></td>
<td>
<p>If univariate, mu is the mean of the series. Otherwise mu is the
vector of means of the return series , default NULL, , see Details</p>
</td></tr>
<tr><td><code id="StdDev_+3A_sigma">sigma</code></td>
<td>
<p>If univariate, sigma is the variance of the series. Otherwise
sigma is the covariance matrix of the return series , default NULL, see
Details</p>
</td></tr>
<tr><td><code id="StdDev_+3A_use">use</code></td>
<td>
<p>an optional character string giving a method for computing
covariances in the presence of missing values.  This must be (an
abbreviation of) one of the strings <code>"everything"</code>, <code>"all.obs"</code>,
<code>"complete.obs"</code>, <code>"na.or.complete"</code>, or
<code>"pairwise.complete.obs"</code>.</p>
</td></tr>
<tr><td><code id="StdDev_+3A_method">method</code></td>
<td>
<p>a character string indicating which correlation coefficient
(or covariance) is to be computed.  One of <code>"pearson"</code> (default),
<code>"kendall"</code>, or <code>"spearman"</code>, can be abbreviated.</p>
</td></tr>
<tr><td><code id="StdDev_+3A_se">SE</code></td>
<td>
<p>TRUE/FALSE whether to ouput the standard errors of the estimates of the risk measures, default FALSE.</p>
</td></tr>
<tr><td><code id="StdDev_+3A_se.control">SE.control</code></td>
<td>
<p>Control parameters for the computation of standard errors. Should be done using the <code><a href="#topic+RPESE.control">RPESE.control</a></code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>TODO add more details
</p>
<p>This wrapper function provides fast matrix calculations for univariate,
multivariate, and component contributions to Standard Deviation.
</p>
<p>It is likely that the only one that requires much description is the
component decomposition.  This provides a weighted decomposition of the
contribution each portfolio element makes to the univariate standard
deviation of the whole portfolio.
</p>
<p>Formally, this is the partial derivative of each univariate standard
deviation with respect to the weights.
</p>
<p>As with <code><a href="#topic+VaR">VaR</a></code>, this contribution is presented in two forms, both
a scalar form that adds up to the univariate standard deviation of the
portfolio, and a percentage contribution, which adds up to 100
as with any contribution calculation, contribution can be negative.  This
indicates that the asset in question is a diversified to the overall
standard deviation of the portfolio, and increasing its weight in relation
to the rest of the portfolio would decrease the overall portfolio standard
deviation.
</p>


<h3>Author(s)</h3>

<p>Brian G. Peterson and Kris Boudt
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Return.clean">Return.clean</a></code> <code>sd</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if(!( Sys.info()[['sysname']]=="Windows") ){
# if on Windows, cut and paste this example

    data(edhec)

    # first do normal StdDev calc
    StdDev(edhec)
    # or the equivalent
    StdDev(edhec, portfolio_method="single")

    # now with outliers squished
    StdDev(edhec, clean="boudt")

    # add Component StdDev for the equal weighted portfolio
    StdDev(edhec, clean="boudt", portfolio_method="component")

} # end CRAN Windows check

</code></pre>

<hr>
<h2 id='StdDev.annualized'>calculate a multiperiod or annualized Standard Deviation</h2><span id='topic+StdDev.annualized'></span><span id='topic+sd.multiperiod'></span><span id='topic+sd.annualized'></span>

<h3>Description</h3>

<p>Standard Deviation of a set of observations <code class="reqn">R_{a}</code> is given by:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StdDev.annualized(x, scale = NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StdDev.annualized_+3A_x">x</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="StdDev.annualized_+3A_scale">scale</code></td>
<td>
<p>number of periods in a year (daily scale = 252, monthly scale =
12, quarterly scale = 4)</p>
</td></tr>
<tr><td><code id="StdDev.annualized_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">\sigma = variance(R_{a}) , std=\sqrt{\sigma} </code>
</p>

<p>It should follow that the variance is not a linear function of the number of
observations.  To determine possible variance over multiple periods, it
wouldn't make sense to multiply the single-period variance by the total
number of periods: this could quickly lead to an absurd result where total
variance (or risk) was greater than 100
variance needs to demonstrate a decreasing period-to-period increase as the
number of periods increases. Put another way, the increase in incremental
variance per additional period needs to decrease with some relationship to
the number of periods. The standard accepted practice for doing this is to
apply the inverse square law. To normalize standard deviation across
multiple periods, we multiply by the square root of the number of periods we
wish to calculate over. To annualize standard deviation, we multiply by the
square root of the number of periods per year.
</p>
<p style="text-align: center;"><code class="reqn">\sqrt{\sigma}\cdot\sqrt{periods}</code>
</p>

<p>Note that any multiperiod or annualized number should be viewed with
suspicion if the number of observations is small.
</p>


<h3>Author(s)</h3>

<p>Brian G. Peterson
</p>


<h3>References</h3>

<p>Bacon, C. <em>Practical Portfolio Performance Measurement and
Attribution</em>. Wiley. 2004. p. 27 <br />
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+sd">sd</a></code> <br />
<a href="http://wikipedia.org/wiki/inverse-square_law">http://wikipedia.org/wiki/inverse-square_law</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
    data(edhec)
    sd.annualized(edhec)
    sd.annualized(edhec[,6,drop=FALSE])
    # now for three periods:
    sd.multiperiod(edhec[,6,drop=FALSE],scale=3)

</code></pre>

<hr>
<h2 id='StructuredMoments'>Functions for calculating structured comoments of financial time series</h2><span id='topic+StructuredMoments'></span><span id='topic+M2.struct'></span><span id='topic+M3.struct'></span><span id='topic+M4.struct'></span>

<h3>Description</h3>

<p>calculates covariance, coskewness and cokurtosis matrices as structured estimators
</p>


<h3>Usage</h3>

<pre><code class='language-R'>M2.struct(R, struct = c("Indep", "IndepId", "observedfactor", "CC"), f = NULL)

M3.struct(
  R,
  struct = c("Indep", "IndepId", "observedfactor", "CC", "latent1factor", "CS"),
  f = NULL,
  unbiasedMarg = FALSE,
  as.mat = TRUE
)

M4.struct(
  R,
  struct = c("Indep", "IndepId", "observedfactor", "CC"),
  f = NULL,
  as.mat = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StructuredMoments_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="StructuredMoments_+3A_struct">struct</code></td>
<td>
<p>string containing the preferred method. See Details.</p>
</td></tr>
<tr><td><code id="StructuredMoments_+3A_f">f</code></td>
<td>
<p>vector or matrix with observations of the factor, to be used with 'observedfactor'. See Details.</p>
</td></tr>
<tr><td><code id="StructuredMoments_+3A_unbiasedmarg">unbiasedMarg</code></td>
<td>
<p>TRUE/FALSE whether to use a correction to have an unbiased
estimator for the marginal skewness values, in case of 'Indep' or 'IndepId', default FALSE</p>
</td></tr>
<tr><td><code id="StructuredMoments_+3A_as.mat">as.mat</code></td>
<td>
<p>TRUE/FALSE whether to return the full moment matrix or only
the vector with the unique elements (the latter is advised for speed), default
TRUE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The coskewness and cokurtosis matrices are defined as the matrices of dimension 
p x p^2 and p x p^3 containing the third and fourth order central moments. They
are useful for measuring nonlinear dependence between different assets of the 
portfolio and computing modified VaR and modified ES of a portfolio.
</p>
<p>Structured estimation is based on the assumption that the underlying data-generating
process is known, or at least resembles the assumption. The first four structured estimators correspond to the models 'independent marginals', 
'independent and identical marginals', 'observed multi-factor model' and 'constant correlation'. 
Coskewness estimation includes an additional model based on the latent 1-factor model
proposed in Simaan (1993).
</p>
<p>The constant correlation and 1-factor coskewness and cokurtosis matrices can be found in 
Martellini and Ziemann (2010). If f is a matrix containing multiple factors, 
then the multi-factor model of Boudt, Lu and Peeters (2915) is used. For information
about the other structured matrices, we refer to Boudt, Cornilly and Verdonck (2017)
</p>


<h3>Author(s)</h3>

<p>Dries Cornilly
</p>


<h3>References</h3>

<p>Boudt, Kris, Lu, Wanbo and Peeters, Benedict. 2015. Higher order comoments of multifactor 
models and asset allocation. Finance Research Letters, 13, 225-233.
</p>
<p>Boudt, Kris, Brian G. Peterson, and Christophe Croux. 2008.
Estimation and Decomposition of Downside Risk for Portfolios with Non-Normal
Returns. Journal of Risk. Winter.
</p>
<p>Boudt, Kris, Cornilly, Dries and Verdonck, Tim. 2017. A Coskewness Shrinkage 
Approach for Estimating the Skewness of Linear Combinations of Random Variables. 
Submitted. Available at SSRN: https://ssrn.com/abstract=2839781
</p>
<p>Ledoit, Olivier and Wolf, Michael. 2003. Improved estimation of the covariance matrix 
of stock returns with an application to portfolio selection. Journal of empirical 
finance, 10(5), 603-621.
</p>
<p>Martellini, Lionel and Ziemann, V\&quot;olker. 2010. Improved estimates of higher-order 
comoments and implications for portfolio selection. Review of Financial 
Studies, 23(4), 1467-1502.
</p>
<p>Simaan, Yusif. 1993. Portfolio selection and asset pricing: three-parameter framework. 
Management Science, 39(5), 68-577.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CoMoments">CoMoments</a></code> <br /> <code><a href="#topic+ShrinkageMoments">ShrinkageMoments</a></code> <br /> <code><a href="#topic+EWMAMoments">EWMAMoments</a></code> <br /> <code><a href="#topic+MCA">MCA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)

# structured estimation with constant correlation model
# 'as.mat = F' would speed up calculations in higher dimensions
sigma &lt;- M2.struct(edhec, "CC")
m3 &lt;- M3.struct(edhec, "CC")
m4 &lt;- M4.struct(edhec, "CC")

# compute equal-weighted portfolio modified ES
mu &lt;- colMeans(edhec)
p &lt;- length(mu)
ES(p = 0.95, portfolio_method = "component", weights = rep(1 / p, p), mu = mu, 
    sigma = sigma, m3 = m3, m4 = m4)

# compare to sample method
sigma &lt;- cov(edhec)
m3 &lt;- M3.MM(edhec)
m4 &lt;- M4.MM(edhec)
ES(p = 0.95, portfolio_method = "component", weights = rep(1 / p, p), mu = mu, 
    sigma = sigma, m3 = m3, m4 = m4)

</code></pre>

<hr>
<h2 id='SystematicRisk'>Systematic risk of the return distribution</h2><span id='topic+SystematicRisk'></span>

<h3>Description</h3>

<p>Systematic risk as defined by Bacon(2008) is the product of beta by market 
risk. Be careful ! It's not the same definition as the one given by Michael
Jensen. Market risk is the standard deviation of the benchmark. The systematic
risk is annualized
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SystematicRisk(Ra, Rb, Rf = 0, scale = NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SystematicRisk_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="SystematicRisk_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="SystematicRisk_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="SystematicRisk_+3A_scale">scale</code></td>
<td>
<p>number of periods in a year (daily scale = 252, monthly scale =
12, quarterly scale = 4)</p>
</td></tr>
<tr><td><code id="SystematicRisk_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">\sigma_s = \beta * \sigma_m</code>
</p>

<p>where <code class="reqn">\sigma_s</code> is the systematic risk, <code class="reqn">\beta</code> is the regression beta,
and <code class="reqn">\sigma_m</code> is the market risk
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.75
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(portfolio_bacon)
print(SystematicRisk(portfolio_bacon[,1], portfolio_bacon[,2])) #expected 0.013

data(managers)
print(SystematicRisk(managers['1996',1], managers['1996',8]))
print(SystematicRisk(managers['1996',1:5], managers['1996',8]))

</code></pre>

<hr>
<h2 id='table.AnnualizedReturns'>Annualized Returns Summary: Statistics and Stylized Facts</h2><span id='topic+table.AnnualizedReturns'></span>

<h3>Description</h3>

<p>Table of Annualized Return, Annualized Std Dev, and Annualized Sharpe
</p>


<h3>Usage</h3>

<pre><code class='language-R'>table.AnnualizedReturns(R, scale = NA, Rf = 0, geometric = TRUE, digits = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="table.AnnualizedReturns_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="table.AnnualizedReturns_+3A_scale">scale</code></td>
<td>
<p>number of periods in a year (daily scale = 252, monthly scale =
12, quarterly scale = 4)</p>
</td></tr>
<tr><td><code id="table.AnnualizedReturns_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="table.AnnualizedReturns_+3A_geometric">geometric</code></td>
<td>
<p>utilize geometric chaining (TRUE) or simple/arithmetic chaining (FALSE) to aggregate returns,
default TRUE</p>
</td></tr>
<tr><td><code id="table.AnnualizedReturns_+3A_digits">digits</code></td>
<td>
<p>number of digits to round results to</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Return.annualized">Return.annualized</a></code> <br /> <code><a href="#topic+StdDev.annualized">StdDev.annualized</a></code>
<br /> <code><a href="#topic+SharpeRatio.annualized">SharpeRatio.annualized</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
table.AnnualizedReturns(managers[,1:8])

require("Hmisc")
result = t(table.AnnualizedReturns(managers[,1:8], Rf=.04/12))

textplot(format.df(result, na.blank=TRUE, numeric.dollar=FALSE, 
         cdec=c(3,3,1)), rmar = 0.8, cmar = 2,  max.cex=.9, 
         halign = "center", valign = "top", row.valign="center", 
         wrap.rownames=20, wrap.colnames=10, col.rownames=c("red", 
         rep("darkgray",5), rep("orange",2)), mar = c(0,0,3,0)+0.1)
         
title(main="Annualized Performance")

</code></pre>

<hr>
<h2 id='table.Arbitrary'>wrapper function for combining arbitrary function list into a table</h2><span id='topic+table.Arbitrary'></span><span id='topic+statsTable'></span>

<h3>Description</h3>

<p>This function creates a table of statistics from vectors of functions and
labels passed in.  The resulting table is formatted such that metrics are
calculated separately for each column of returns in the data object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>table.Arbitrary(
  R,
  metrics = c("mean", "sd"),
  metricsNames = c("Average Return", "Standard Deviation"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="table.Arbitrary_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="table.Arbitrary_+3A_metrics">metrics</code></td>
<td>
<p>lisdt of functions to apply</p>
</td></tr>
<tr><td><code id="table.Arbitrary_+3A_metricsnames">metricsNames</code></td>
<td>
<p>column names for each function</p>
</td></tr>
<tr><td><code id="table.Arbitrary_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Assumes an input of period returns.  Scale arguements can be used to specify
the number of observations during a year (e.g., 12 = monthly returns).
</p>
<p>The idea here is to be able to pass in sets of metrics and values, like:
</p>
<p>metrics = c(DownsideDeviation(x,MAR=mean(x)), sd(subset(x,x&gt;0)),
sd(subset(x,x&lt;0)), DownsideDeviation(x,MAR=MAR),
DownsideDeviation(x,MAR=Rf=0), DownsideDeviation(x,MAR=0),maxDrawdown(x))
</p>
<p>metricsNames = c(&quot;Semi Deviation&quot;, &quot;Gain Deviation&quot;, &quot;Loss Deviation&quot;,
paste(&quot;Downside Deviation (MAR=&quot;,MAR*scale*100,&quot;
paste(&quot;Downside Deviation (rf=&quot;,rf*scale*100,&quot;
Deviation (0
</p>
<p>Here's how it's working right now: &gt;
table.Arbitrary(monthlyReturns.ts,metrics=c(&quot;VaR&quot;,&quot;mean&quot;),
metricsNames=c(&quot;modVaR&quot;,&quot;mean&quot;),p=.95) </p>
<pre> Actual S&amp;P500TR modVaR
0.04186461 0.06261451 mean 0.00945000 0.01013684 </pre>
<p>Passing in two different sets of attributes to the same function doesn't
quite work currently.  The issue is apparent in: &gt;
table.Arbitrary(edhec,metrics=c(&quot;VaR&quot;, &quot;VaR&quot;), metricsNames=c(&quot;Modified
VaR&quot;,&quot;Traditional VaR&quot;), modified=c(TRUE,FALSE)) </p>
<pre>
Convertible.Arbitrage CTA.Global Distressed.Securities Modified VaR
0.04081599 0.0456767 0.1074683 Traditional VaR 0.04081599 0.0456767
0.1074683 Emerging.Markets Equity.Market.Neutral Event.Driven Modified VaR
0.1858624 0.01680917 0.1162714 Traditional VaR 0.1858624 0.01680917
0.1162714 Fixed.Income.Arbitrage Global.Macro Long.Short.Equity Modified VaR
0.2380379 0.03700478 0.04661244 Traditional VaR 0.2380379 0.03700478
0.04661244 Merger.Arbitrage Relative.Value Short.Selling Funds.of.Funds
Modified VaR 0.07510643 0.04123920 0.1071894 0.04525633 Traditional VaR
0.07510643 0.04123920 0.1071894 0.04525633 </pre>
<p>In the case of this example, you would simply call VaR as the second
function, like so: &gt; table.Arbitrary(edhec,metrics=c(&quot;VaR&quot;,
&quot;VaR&quot;),metricsNames=c(&quot;Modified VaR&quot;,&quot;Traditional VaR&quot;)) </p>
<pre>
Convertible.Arbitrage CTA.Global Distressed.Securities Modified VaR
0.04081599 0.04567670 0.10746831 Traditional VaR 0.02635371 0.04913361
0.03517855 Emerging.Markets Equity.Market.Neutral Event.Driven Modified VaR
0.18586240 0.01680917 0.11627142 Traditional VaR 0.07057278 0.01746554
0.03563019 Fixed.Income.Arbitrage Global.Macro Long.Short.Equity Modified
VaR 0.23803787 0.03700478 0.04661244 Traditional VaR 0.02231236 0.03692096
0.04318713 Merger.Arbitrage Relative.Value Short.Selling Funds.of.Funds
Modified VaR 0.07510643 0.04123920 0.1071894 0.04525633 Traditional VaR
0.02510709 0.02354012 0.0994635 0.03502065 </pre><p> but we don't know of a way to
compare the same function side by side with different parameters for each.
Suggestions Welcome.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)
table.Arbitrary(edhec,metrics=c("VaR", "ES"),
                metricsNames=c("Modified VaR","Modified Expected Shortfall"))

</code></pre>

<hr>
<h2 id='table.Autocorrelation'>table for calculating the first six autocorrelation coefficients and
significance</h2><span id='topic+table.Autocorrelation'></span>

<h3>Description</h3>

<p>Produces data table of autocorrelation coefficients <code class="reqn">\rho</code> and
corresponding Q(6)-statistic for each column in R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>table.Autocorrelation(R, digits = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="table.Autocorrelation_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="table.Autocorrelation_+3A_digits">digits</code></td>
<td>
<p>number of digits to round results to for display</p>
</td></tr>
</table>


<h3>Note</h3>

<p>To test returns for autocorrelation, Lo (2001) suggests the use of the
Ljung-Box test, a significance test for the auto-correlation coefficients.
Ljung and Box (1978) provide a refinement of the Q-statistic proposed by Box
and Pierce (1970) that offers a better fit for the <code class="reqn">\chi^2</code> test
for small sample sizes. <code><a href="stats.html#topic+Box.test">Box.test</a></code> provides both.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>Lo, Andrew W. 2001. Risk Management for Hedge Funds:
Introduction and Overview. SSRN eLibrary.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Box.test">Box.test</a></code>, <code><a href="stats.html#topic+acf">acf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
t(table.Autocorrelation(managers))

result = t(table.Autocorrelation(managers[,1:8]))

textplot(result, rmar = 0.8, cmar = 2,  max.cex=.9, halign = "center", 
         valign = "top", row.valign="center", wrap.rownames=15, 
         wrap.colnames=10, mar = c(0,0,3,0)+0.1)
         
title(main="Autocorrelation")

</code></pre>

<hr>
<h2 id='table.CalendarReturns'>Monthly and Calendar year Return table</h2><span id='topic+table.CalendarReturns'></span><span id='topic+table.Returns'></span>

<h3>Description</h3>

<p>Returns a table of returns formatted with years in rows, months in columns,
and a total column in the last column.  For additional columns in <code>R</code>,
annual returns will be appended as columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>table.CalendarReturns(R, digits = 1, as.perc = TRUE, geometric = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="table.CalendarReturns_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="table.CalendarReturns_+3A_digits">digits</code></td>
<td>
<p>number of digits to round results to for presentation</p>
</td></tr>
<tr><td><code id="table.CalendarReturns_+3A_as.perc">as.perc</code></td>
<td>
<p>TRUE/FALSE if TRUE, multiply simple returns by 100 to get %</p>
</td></tr>
<tr><td><code id="table.CalendarReturns_+3A_geometric">geometric</code></td>
<td>
<p>utilize geometric chaining (TRUE) or simple/arithmetic chaining (FALSE) to aggregate returns,
default TRUE</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function assumes monthly returns and does not currently have
handling for other scales.
</p>
<p>This function defaults to the first column as the monthly returns to be
formatted.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
t(table.CalendarReturns(managers[,c(1,7,8)]))

# prettify with format.df in hmisc package
require("Hmisc")
result = t(table.CalendarReturns(managers[,c(1,8)]))

textplot(format.df(result, na.blank=TRUE, numeric.dollar=FALSE, 
         cdec=rep(1,dim(result)[2])), rmar = 0.8, cmar = 1,  
         max.cex=.9, halign = "center", valign = "top", 
         row.valign="center", wrap.rownames=20, wrap.colnames=10, 
         col.rownames=c( rep("darkgray",12), "black", "blue"), 
         mar = c(0,0,3,0)+0.1)
         
title(main="Calendar Returns")

</code></pre>

<hr>
<h2 id='table.CaptureRatios'>Calculate and display a table of capture ratio and related statistics</h2><span id='topic+table.CaptureRatios'></span><span id='topic+table.UpDownRatios'></span>

<h3>Description</h3>

<p>Creates a table of capture ratios and similar metrics for a set of returns
against a benchmark.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>table.CaptureRatios(Ra, Rb, digits = 4)

table.UpDownRatios(Ra, Rb, digits = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="table.CaptureRatios_+3A_ra">Ra</code></td>
<td>
<p>a vector of returns to test, e.g., the asset to be examined</p>
</td></tr>
<tr><td><code id="table.CaptureRatios_+3A_rb">Rb</code></td>
<td>
<p>a matrix, data.frame, or timeSeries of benchmark(s) to test the
asset against.</p>
</td></tr>
<tr><td><code id="table.CaptureRatios_+3A_digits">digits</code></td>
<td>
<p>number of digits to round results to for presentation</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This table will show statistics pertaining to an asset against a set of
benchmarks, or statistics for a set of assets against a benchmark.
<code>table.CaptureRatios</code> shows only the capture ratio;
<code>table.UpDownRatios</code> shows three: the capture ratio, the number ratio,
and the percentage ratio.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="#topic+UpDownRatios">UpDownRatios</a></code>, <code><a href="#topic+chart.CaptureRatios">chart.CaptureRatios</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
table.CaptureRatios(managers[,1:6], managers[,7,drop=FALSE])
table.UpDownRatios(managers[,1:6], managers[,7,drop=FALSE])

result = t(table.UpDownRatios(managers[,1:6], managers[,7,drop=FALSE])) 
colnames(result)=colnames(managers[,1:6])
textplot(result, rmar = 0.8, cmar = 1.5,  max.cex=.9, 
         halign = "center", valign = "top", row.valign="center", 
         wrap.rownames=15, wrap.colnames=10, mar = c(0,0,3,0)+0.1)
         
title(main="Capture Ratios for EDHEC LS EQ")

</code></pre>

<hr>
<h2 id='table.Correlation'>calculate correlalations of multicolumn data</h2><span id='topic+table.Correlation'></span>

<h3>Description</h3>

<p>This is a wrapper for calculating correlation and significance against each
column of the data provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>table.Correlation(Ra, Rb, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="table.Correlation_+3A_ra">Ra</code></td>
<td>
<p>a vector of returns to test, e.g., the asset to be examined</p>
</td></tr>
<tr><td><code id="table.Correlation_+3A_rb">Rb</code></td>
<td>
<p>a matrix, data.frame, or timeSeries of benchmark(s) to test the
asset against.</p>
</td></tr>
<tr><td><code id="table.Correlation_+3A_...">...</code></td>
<td>
<p>any other passthru parameters to <code><a href="stats.html#topic+cor.test">cor.test</a></code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor.test">cor.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# First we load the data
data(managers)
table.Correlation(managers[,1:6],managers[,7:8])

result=table.Correlation(managers[,1:6],managers[,8])
rownames(result)=colnames(managers[,1:6])
require("Hmisc")
textplot(format.df(result, na.blank=TRUE, numeric.dollar=FALSE, 
         cdec=rep(3,dim(result)[2])), rmar = 0.8, cmar = 1.5,  
         max.cex=.9, halign = "center", valign = "top", row.valign="center"
         , wrap.rownames=20, wrap.colnames=10, mar = c(0,0,3,0)+0.1)
title(main="Correlations to SP500 TR")

ctable = table.Correlation(managers[,1:6],managers[,8,drop=FALSE], conf.level=.99)
dotchart(ctable[,1],labels=rownames(ctable),xlim=c(-1,1))

</code></pre>

<hr>
<h2 id='table.Distributions'>Distributions Summary: Statistics and Stylized Facts</h2><span id='topic+table.Distributions'></span>

<h3>Description</h3>

<p>Table of standard deviation, Skewness, Sample standard deviation,
Kurtosis, Excess kurtosis, Sample Skweness and Sample excess kurtosis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>table.Distributions(R, scale = NA, digits = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="table.Distributions_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="table.Distributions_+3A_scale">scale</code></td>
<td>
<p>number of periods in a year (daily scale = 252, monthly scale =
12, quarterly scale = 4)</p>
</td></tr>
<tr><td><code id="table.Distributions_+3A_digits">digits</code></td>
<td>
<p>number of digits to round results to</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.87
</p>


<h3>See Also</h3>

<p><code><a href="#topic+StdDev.annualized">StdDev.annualized</a></code> <br /> <code><a href="#topic+skewness">skewness</a></code> <br />
<code><a href="#topic+kurtosis">kurtosis</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
table.Distributions(managers[,1:8])

require("Hmisc")
result = t(table.Distributions(managers[,1:8]))

textplot(format.df(result, na.blank=TRUE, numeric.dollar=FALSE, cdec=c(3,3,1)),
rmar = 0.8, cmar = 2,  max.cex=.9, halign = "center", valign = "top",
row.valign="center", wrap.rownames=20, wrap.colnames=10,
col.rownames=c("red", rep("darkgray",5), rep("orange",2)), mar = c(0,0,3,0)+0.1)
title(main="Portfolio Distributions statistics")

</code></pre>

<hr>
<h2 id='table.DownsideRisk'>Downside Risk Summary: Statistics and Stylized Facts</h2><span id='topic+table.DownsideRisk'></span>

<h3>Description</h3>

<p>Creates a table of estimates of downside risk measures for comparison across
multiple instruments or funds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>table.DownsideRisk(
  R,
  ci = 0.95,
  scale = NA,
  Rf = 0,
  MAR = 0.1/12,
  p = 0.95,
  digits = 4
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="table.DownsideRisk_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="table.DownsideRisk_+3A_ci">ci</code></td>
<td>
<p>confidence interval, defaults to 95%</p>
</td></tr>
<tr><td><code id="table.DownsideRisk_+3A_scale">scale</code></td>
<td>
<p>number of periods in a year (daily scale = 252, monthly scale =
12, quarterly scale = 4)</p>
</td></tr>
<tr><td><code id="table.DownsideRisk_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="table.DownsideRisk_+3A_mar">MAR</code></td>
<td>
<p>Minimum Acceptable Return, in the same periodicity as your
returns</p>
</td></tr>
<tr><td><code id="table.DownsideRisk_+3A_p">p</code></td>
<td>
<p>confidence level for calculation, default p=.99</p>
</td></tr>
<tr><td><code id="table.DownsideRisk_+3A_digits">digits</code></td>
<td>
<p>number of digits to round results to</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DownsideDeviation">DownsideDeviation</a></code> <br /> 
<code><a href="#topic+maxDrawdown">maxDrawdown</a></code> <br />
<code><a href="#topic+VaR">VaR</a></code> <br /> 
<code><a href="#topic+ES">ES</a></code> <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)
table.DownsideRisk(edhec, Rf=.04/12, MAR =.05/12, p=.95)

result=t(table.DownsideRisk(edhec, Rf=.04/12, MAR =.05/12, p=.95))
require("Hmisc")
textplot(format.df(result, na.blank=TRUE, numeric.dollar=FALSE, 
         cdec=rep(3,dim(result)[2])), rmar = 0.8, cmar = 1.5,  
         max.cex=.9, halign = "center", valign = "top", row.valign="center", 
         wrap.rownames=15, wrap.colnames=10, mar = c(0,0,3,0)+0.1)
title(main="Downside Risk Statistics")

</code></pre>

<hr>
<h2 id='table.DownsideRiskRatio'>Downside Summary: Statistics and ratios</h2><span id='topic+table.DownsideRiskRatio'></span>

<h3>Description</h3>

<p>Table of downside risk, Annualised downside risk, Downside potential,
Omega, Sortino ratio, Upside potential, Upside potential ratio and
Omega-Sharpe ratio
</p>


<h3>Usage</h3>

<pre><code class='language-R'>table.DownsideRiskRatio(R, MAR = 0, scale = NA, digits = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="table.DownsideRiskRatio_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="table.DownsideRiskRatio_+3A_mar">MAR</code></td>
<td>
<p>Minimum Acceptable Return, in the same periodicity as your
returns</p>
</td></tr>
<tr><td><code id="table.DownsideRiskRatio_+3A_scale">scale</code></td>
<td>
<p>number of periods in a year (daily scale = 252, monthly scale =</p>
</td></tr>
<tr><td><code id="table.DownsideRiskRatio_+3A_digits">digits</code></td>
<td>
<p>number of digits to round results to</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.98
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CalmarRatio">CalmarRatio</a></code> <br /> <code><a href="#topic+BurkeRatio">BurkeRatio</a></code>
<br /> <code><a href="#topic+PainIndex">PainIndex</a></code> <br /> <code><a href="#topic+UlcerIndex">UlcerIndex</a></code> <br /> 
<code><a href="#topic+PainRatio">PainRatio</a></code> <br /> <code><a href="#topic+MartinRatio">MartinRatio</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
table.DownsideRiskRatio(managers[,1:8])

require("Hmisc")
result = t(table.DownsideRiskRatio(managers[,1:8]))

textplot(format.df(result, na.blank=TRUE, numeric.dollar=FALSE, cdec=c(3,3,1)),
rmar = 0.8, cmar = 2,  max.cex=.9, halign = "center", valign = "top",
row.valign="center", wrap.rownames=20, wrap.colnames=10,
col.rownames=c("red", rep("darkgray",5), rep("orange",2)), mar = c(0,0,3,0)+0.1)
title(main="Downside risk statistics")

</code></pre>

<hr>
<h2 id='table.Drawdowns'>Worst Drawdowns Summary: Statistics and Stylized Facts</h2><span id='topic+table.Drawdowns'></span>

<h3>Description</h3>

<p>Creates table showing statistics for the worst drawdowns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>table.Drawdowns(R, top = 5, digits = 4, geometric = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="table.Drawdowns_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="table.Drawdowns_+3A_top">top</code></td>
<td>
<p>the number of drawdowns to include</p>
</td></tr>
<tr><td><code id="table.Drawdowns_+3A_digits">digits</code></td>
<td>
<p>number of digits to round results to</p>
</td></tr>
<tr><td><code id="table.Drawdowns_+3A_geometric">geometric</code></td>
<td>
<p>utilize geometric chaining (TRUE) or simple/arithmetic 
chaining (FALSE) to aggregate returns, default TRUE</p>
</td></tr>
<tr><td><code id="table.Drawdowns_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns an data frame with columns: <br /> 
</p>
 
<ul>
<li><p> From starting period, high water mark 
</p>
</li>
<li><p> Trough period of low point 
</p>
</li>
<li><p> To ending period, when initial high water mark is recovered 
</p>
</li>
<li><p> Depth drawdown to trough (typically as percentage returns) 
</p>
</li>
<li><p> Length length in periods 
</p>
</li>
<li><p> toTrough number of periods to trough 
</p>
</li>
<li><p> Recovery number of periods to recover
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>Bacon, C. <em>Practical Portfolio Performance Measurement and
Attribution</em>. Wiley. 2004. p. 88 <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DownsideDeviation">DownsideDeviation</a></code> <br /> 
<code><a href="#topic+maxDrawdown">maxDrawdown</a></code> <br />
<code><a href="#topic+findDrawdowns">findDrawdowns</a></code> <br /> 
<code><a href="#topic+sortDrawdowns">sortDrawdowns</a></code> <br />
<code><a href="#topic+chart.Drawdown">chart.Drawdown</a></code> <br /> 
<code><a href="#topic+table.DownsideRisk">table.DownsideRisk</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)
table.Drawdowns(edhec[,1,drop=FALSE])
table.Drawdowns(edhec[,12,drop=FALSE])
data(managers)
table.Drawdowns(managers[,8,drop=FALSE])

result=table.Drawdowns(managers[,1,drop=FALSE])

# This was really nice before Hmisc messed up 'format' from R-base
#require("Hmisc")
#textplot(Hmisc::format.df(result, na.blank=TRUE, numeric.dollar=FALSE, 
#           cdec=c(rep(3,4), rep(0,3))), rmar = 0.8, cmar = 1.5,  
#           max.cex=.9, halign = "center", valign = "top", row.valign="center", 
#           wrap.rownames=5, wrap.colnames=10, mar = c(0,0,3,0)+0.1) 
# title(main="Largest Drawdowns for HAM1")

</code></pre>

<hr>
<h2 id='table.DrawdownsRatio'>Drawdowns Summary: Statistics and ratios</h2><span id='topic+table.DrawdownsRatio'></span>

<h3>Description</h3>

<p>Table of Calmar ratio, Sterling ratio, Burke ratio, Pain index, Ulcer index, 
Pain ratio and Martin ratio
</p>


<h3>Usage</h3>

<pre><code class='language-R'>table.DrawdownsRatio(R, Rf = 0, scale = NA, digits = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="table.DrawdownsRatio_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="table.DrawdownsRatio_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="table.DrawdownsRatio_+3A_scale">scale</code></td>
<td>
<p>number of periods in a year (daily scale = 252, monthly scale =
12, quarterly scale = 4)</p>
</td></tr>
<tr><td><code id="table.DrawdownsRatio_+3A_digits">digits</code></td>
<td>
<p>number of digits to round results to</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.93
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CalmarRatio">CalmarRatio</a></code> <br /> <code><a href="#topic+BurkeRatio">BurkeRatio</a></code>
<br /> <code><a href="#topic+PainIndex">PainIndex</a></code> <br /> <code><a href="#topic+UlcerIndex">UlcerIndex</a></code> <br /> 
<code><a href="#topic+PainRatio">PainRatio</a></code> <br /> <code><a href="#topic+MartinRatio">MartinRatio</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
table.DrawdownsRatio(managers[,1:8])

require("Hmisc")
result = t(table.DrawdownsRatio(managers[,1:8], Rf=.04/12))

textplot(format.df(result, na.blank=TRUE, numeric.dollar=FALSE, cdec=c(3,3,1)),
rmar = 0.8, cmar = 2,  max.cex=.9, halign = "center", valign = "top",
row.valign="center", wrap.rownames=20, wrap.colnames=10,
col.rownames=c("red", rep("darkgray",5), rep("orange",2)), mar = c(0,0,3,0)+0.1)
title(main="Drawdowns ratio statistics")

</code></pre>

<hr>
<h2 id='table.HigherMoments'>Higher Moments Summary: Statistics and Stylized Facts</h2><span id='topic+table.HigherMoments'></span>

<h3>Description</h3>

<p>Summary of the higher moements and Co-Moments of the return distribution.
Used to determine diversification potential. Also called &quot;systematic&quot;
moments by several papers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>table.HigherMoments(Ra, Rb, scale = NA, Rf = 0, digits = 4, method = "moment")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="table.HigherMoments_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="table.HigherMoments_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="table.HigherMoments_+3A_scale">scale</code></td>
<td>
<p>number of periods in a year (daily scale = 252, monthly scale =
12, quarterly scale = 4)</p>
</td></tr>
<tr><td><code id="table.HigherMoments_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="table.HigherMoments_+3A_digits">digits</code></td>
<td>
<p>number of digits to round results to</p>
</td></tr>
<tr><td><code id="table.HigherMoments_+3A_method">method</code></td>
<td>
<p>method to use when computing <code><a href="#topic+kurtosis">kurtosis</a></code> one of:
<code>excess</code>, <code>moment</code>, <code>fisher</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>Martellini L., Vaissie M., Ziemann V. Investing in Hedge Funds:
Adding Value through Active Style Allocation Decisions. October 2005. Edhec
Risk and Asset Management Research Centre.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CoSkewness">CoSkewness</a></code> <br /> <code><a href="#topic+CoKurtosis">CoKurtosis</a></code> <br />
<code><a href="#topic+BetaCoVariance">BetaCoVariance</a></code> <br /> <code><a href="#topic+BetaCoSkewness">BetaCoSkewness</a></code> <br />
<code><a href="#topic+BetaCoKurtosis">BetaCoKurtosis</a></code> <br /> <code><a href="#topic+skewness">skewness</a></code> <br />
<code><a href="#topic+kurtosis">kurtosis</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
table.HigherMoments(managers[,1:3],managers[,8,drop=FALSE])
result=t(table.HigherMoments(managers[,1:6],managers[,8,drop=FALSE]))
rownames(result)=colnames(managers[,1:6])
require("Hmisc")
textplot(format.df(result, na.blank=TRUE, numeric.dollar=FALSE, 
         cdec=rep(3,dim(result)[2])), rmar = 0.8, cmar = 1.5,  
         max.cex=.9, halign = "center", valign = "top", row.valign="center", 
         wrap.rownames=5, wrap.colnames=10, mar = c(0,0,3,0)+0.1)
title(main="Higher Co-Moments with SP500 TR")

</code></pre>

<hr>
<h2 id='table.InformationRatio'>Information ratio Summary: Statistics and Stylized Facts</h2><span id='topic+table.InformationRatio'></span>

<h3>Description</h3>

<p>Table of Tracking error, Annualised tracking error and Information ratio
</p>


<h3>Usage</h3>

<pre><code class='language-R'>table.InformationRatio(R, Rb, scale = NA, digits = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="table.InformationRatio_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="table.InformationRatio_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="table.InformationRatio_+3A_scale">scale</code></td>
<td>
<p>number of periods in a year (daily scale = 252, monthly scale =
12, quarterly scale = 4)</p>
</td></tr>
<tr><td><code id="table.InformationRatio_+3A_digits">digits</code></td>
<td>
<p>number of digits to round results to</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.81
</p>


<h3>See Also</h3>

<p><code><a href="#topic+InformationRatio">InformationRatio</a></code>
<br /> <code><a href="#topic+TrackingError">TrackingError</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
table.InformationRatio(managers[,1:8], managers[,8])

require("Hmisc")
result = t(table.InformationRatio(managers[,1:8], managers[,8]))

textplot(format.df(result, na.blank=TRUE, numeric.dollar=FALSE, cdec=c(3,3,1)),
rmar = 0.8, cmar = 2,  max.cex=.9, halign = "center", valign = "top",
row.valign="center", wrap.rownames=20, wrap.colnames=10,
col.rownames=c("red", rep("darkgray",5), rep("orange",2)), mar = c(0,0,3,0)+0.1)
title(main="Portfolio information ratio")

</code></pre>

<hr>
<h2 id='table.ProbOutPerformance'>Outperformance Report of Asset vs Benchmark</h2><span id='topic+table.ProbOutPerformance'></span>

<h3>Description</h3>

<p>Table of Outperformance Reporting vs Benchmark
</p>


<h3>Usage</h3>

<pre><code class='language-R'>table.ProbOutPerformance(R, Rb, period_lengths = c(1, 3, 6, 9, 12, 18, 36))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="table.ProbOutPerformance_+3A_r">R</code></td>
<td>
<p>an xts, timeSeries or zoo object of asset returns</p>
</td></tr>
<tr><td><code id="table.ProbOutPerformance_+3A_rb">Rb</code></td>
<td>
<p>an xts, timeSeries or zoo object of the benchmark returns</p>
</td></tr>
<tr><td><code id="table.ProbOutPerformance_+3A_period_lengths">period_lengths</code></td>
<td>
<p>a vector of periods the user wants to evaluate this 
over i.e. c(1,3,6,9,12,18,36)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns a table that contains the counts and probabilities 
of outperformance relative to benchmark for the various period_lengths
</p>
<p>Tool for robustness analysis of an asset or strategy, can be used to 
give the probability an investor investing at any point in time will 
outperform the benchmark over a given horizon. Calculates Count of 
trailing periods where a fund outperformed its benchmark and calculates 
the proportion of those periods, this is commonly used in marketing as 
the probability of outperformance on a N period basis.
</p>
<p>Returns a table that contains the counts and probabilities 
of outperformance relative to benchmark for the various period_lengths
</p>


<h3>Author(s)</h3>

<p>Kyle Balkissoon
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec) 

table.ProbOutPerformance(edhec[,1],edhec[,2]) 
title(main='Table of Convertible Arbitrage vs Benchmark')

</code></pre>

<hr>
<h2 id='table.RollingPeriods'>Rolling Periods Summary: Statistics and Stylized Facts</h2><span id='topic+table.RollingPeriods'></span><span id='topic+table.TrailingPeriods'></span><span id='topic+table.TrailingPeriodsRel'></span>

<h3>Description</h3>

<p>A table of estimates of rolling period return measures
</p>


<h3>Usage</h3>

<pre><code class='language-R'>table.RollingPeriods(
  R,
  periods = subset(c(12, 36, 60), c(12, 36, 60) &lt; length(as.matrix(R[, 1]))),
  FUNCS = c("mean", "sd"),
  funcs.names = c("Average", "Std Dev"),
  digits = 4,
  ...
)

table.TrailingPeriodsRel(
  R,
  Rb,
  periods = subset(c(12, 36, 60), c(12, 36, 60) &lt; length(as.matrix(R[, 1]))),
  FUNCS = c("cor", "CAPM.beta"),
  funcs.names = c("Correlation", "Beta"),
  digits = 4,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="table.RollingPeriods_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="table.RollingPeriods_+3A_periods">periods</code></td>
<td>
<p>number of periods to use as rolling window(s), subset of
<code>c(3, 6, 9, 12, 18, 24, 36, 48)</code></p>
</td></tr>
<tr><td><code id="table.RollingPeriods_+3A_funcs">FUNCS</code></td>
<td>
<p>list of functions to apply the rolling period to</p>
</td></tr>
<tr><td><code id="table.RollingPeriods_+3A_funcs.names">funcs.names</code></td>
<td>
<p>vector of function names used for labeling table rows</p>
</td></tr>
<tr><td><code id="table.RollingPeriods_+3A_digits">digits</code></td>
<td>
<p>number of digits to round results to</p>
</td></tr>
<tr><td><code id="table.RollingPeriods_+3A_...">...</code></td>
<td>
<p>any other passthru parameters for functions specified in FUNCS</p>
</td></tr>
<tr><td><code id="table.RollingPeriods_+3A_rb">Rb</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
index, benchmark, portfolio, or secondary asset returns to compare against</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="zoo.html#topic+rollapply">rollapply</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)
table.TrailingPeriods(edhec[,10:13], periods=c(12,24,36))

result=table.TrailingPeriods(edhec[,10:13], periods=c(12,24,36))
require("Hmisc")
textplot(format.df(result, na.blank=TRUE, numeric.dollar=FALSE, 
                   cdec=rep(3,dim(result)[2])), rmar = 0.8, cmar = 1.5,  
                   max.cex=.9, halign = "center", valign = "top", row.valign="center", 
                   wrap.rownames=15, wrap.colnames=10, mar = c(0,0,3,0)+0.1)
title(main="Trailing Period Statistics")

</code></pre>

<hr>
<h2 id='table.SFM'>Single Factor Asset-Pricing Model Summary: Statistics and Stylized Facts</h2><span id='topic+table.SFM'></span><span id='topic+table.CAPM'></span>

<h3>Description</h3>

<p>Takes a set of returns and relates them to a benchmark return. Provides a
set of measures related to an excess return single factor model, or CAPM.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>table.SFM(Ra, Rb, scale = NA, Rf = 0, digits = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="table.SFM_+3A_ra">Ra</code></td>
<td>
<p>a vector of returns to test, e.g., the asset to be examined</p>
</td></tr>
<tr><td><code id="table.SFM_+3A_rb">Rb</code></td>
<td>
<p>a matrix, data.frame, or timeSeries of benchmark(s) to test the
asset against.</p>
</td></tr>
<tr><td><code id="table.SFM_+3A_scale">scale</code></td>
<td>
<p>number of periods in a year (daily scale = 252, monthly scale =
12, quarterly scale = 4)</p>
</td></tr>
<tr><td><code id="table.SFM_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="table.SFM_+3A_digits">digits</code></td>
<td>
<p>number of digits to round results to</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This table will show statistics pertaining to an asset against a set of
benchmarks, or statistics for a set of assets against a benchmark.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CAPM.alpha">CAPM.alpha</a></code> <br /> <code><a href="#topic+CAPM.beta">CAPM.beta</a></code> <br />
<code><a href="#topic+TrackingError">TrackingError</a></code> <br /> <code><a href="#topic+ActivePremium">ActivePremium</a></code> <br />
<code><a href="#topic+InformationRatio">InformationRatio</a></code> <br /> <code><a href="#topic+TreynorRatio">TreynorRatio</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
table.SFM(managers[,1:3], managers[,8], Rf = managers[,10])

result = table.SFM(managers[,1:3], managers[,8], Rf = managers[,10])
textplot(result, rmar = 0.8, cmar = 1.5,  max.cex=.9, 
         halign = "center", valign = "top", row.valign="center", 
         wrap.rownames=15, wrap.colnames=10, mar = c(0,0,3,0)+0.1)
title(main="Single Factor Model Related Statistics")

</code></pre>

<hr>
<h2 id='table.SpecificRisk'>Specific risk Summary: Statistics and Stylized Facts</h2><span id='topic+table.SpecificRisk'></span>

<h3>Description</h3>

<p>Table of specific risk, systematic risk and total risk
</p>


<h3>Usage</h3>

<pre><code class='language-R'>table.SpecificRisk(Ra, Rb, Rf = 0, digits = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="table.SpecificRisk_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="table.SpecificRisk_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="table.SpecificRisk_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="table.SpecificRisk_+3A_digits">digits</code></td>
<td>
<p>number of digits to round results to</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.76
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SystematicRisk">SystematicRisk</a></code> <br /> <code><a href="#topic+SpecificRisk">SpecificRisk</a></code>
<br /> <code><a href="#topic+TotalRisk">TotalRisk</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
table.SpecificRisk(managers[,1:8], managers[,8])

require("Hmisc")
result = t(table.SpecificRisk(managers[,1:8], managers[,8], Rf=.04/12))

textplot(format.df(result, na.blank=TRUE, numeric.dollar=FALSE, cdec=c(3,3,1)),
rmar = 0.8, cmar = 2,  max.cex=.9, halign = "center", valign = "top", 
row.valign="center", wrap.rownames=20, wrap.colnames=10, 
col.rownames=c("red", rep("darkgray",5), rep("orange",2)), mar = c(0,0,3,0)+0.1)
title(main="Portfolio specific, systematic and total risk")

</code></pre>

<hr>
<h2 id='table.Stats'>Returns Summary: Statistics and Stylized Facts</h2><span id='topic+table.Stats'></span><span id='topic+table.MonthlyReturns'></span>

<h3>Description</h3>

<p>Returns a basic set of statistics that match the period of the data passed
in (e.g., monthly returns will get monthly statistics, daily will be daily
stats, and so on)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>table.Stats(R, ci = 0.95, digits = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="table.Stats_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="table.Stats_+3A_ci">ci</code></td>
<td>
<p>confidence interval, defaults to 95%</p>
</td></tr>
<tr><td><code id="table.Stats_+3A_digits">digits</code></td>
<td>
<p>number of digits to round results to</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This was created as a way to display a set of related statistics together
for comparison across a set of instruments or funds.  Careful consideration
to missing data or unequal time series should be given when intepreting the
results.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)
table.Stats(edhec[,1:3])
t(table.Stats(edhec))

result=t(table.Stats(edhec))
require("Hmisc")
textplot(format.df(result, na.blank=TRUE, numeric.dollar=FALSE, cdec=c(rep(1,2),rep(3,14))), 
         rmar = 0.8, cmar = 1.5,  max.cex=.9, halign = "center", valign = "top", 
         row.valign="center", wrap.rownames=10, wrap.colnames=10, mar = c(0,0,3,0)+0.1)
title(main="Statistics for EDHEC Indexes")

</code></pre>

<hr>
<h2 id='table.Variability'>Variability Summary: Statistics and Stylized Facts</h2><span id='topic+table.Variability'></span>

<h3>Description</h3>

<p>Table of Mean absolute difference, period standard deviation and annualised
standard deviation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>table.Variability(R, scale = NA, geometric = TRUE, digits = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="table.Variability_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="table.Variability_+3A_scale">scale</code></td>
<td>
<p>number of periods in a year (daily scale = 252, monthly scale =
12, quarterly scale = 4)</p>
</td></tr>
<tr><td><code id="table.Variability_+3A_geometric">geometric</code></td>
<td>
<p>utilize geometric chaining (TRUE) or simple/arithmetic chaining (FALSE) to aggregate returns,
default TRUE</p>
</td></tr>
<tr><td><code id="table.Variability_+3A_digits">digits</code></td>
<td>
<p>number of digits to round results to</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.65
</p>


<h3>See Also</h3>

<p><code><a href="#topic+StdDev.annualized">StdDev.annualized</a></code>
<br /> <code><a href="#topic+MeanAbsoluteDeviation">MeanAbsoluteDeviation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
table.Variability(managers[,1:8])

require("Hmisc")
result = t(table.Variability(managers[,1:8]))

textplot(format.df(result, na.blank=TRUE, numeric.dollar=FALSE, cdec=c(3,3,1)),
rmar = 0.8, cmar = 2,  max.cex=.9, halign = "center", valign = "top",
row.valign="center", wrap.rownames=20, wrap.colnames=10,
col.rownames=c("red", rep("darkgray",5), rep("orange",2)), mar = c(0,0,3,0)+0.1)
title(main="Portfolio variability")

</code></pre>

<hr>
<h2 id='test_returns'>Sample sector returns for use by unit tests</h2><span id='topic+test_returns'></span>

<h3>Description</h3>

<p>A dataset containing returns for 10 sectors over 5 month-end periods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test_returns
</code></pre>


<h3>Format</h3>

<p>A data frame with 5 rows and 10 variables:
</p>

<dl>
<dt>Sector1</dt><dd><p>returns for Sector1, numeric</p>
</dd>
<dt>Sector2</dt><dd><p>returns for Sector2, numeric</p>
</dd>
<dt>Sector3</dt><dd><p>returns for Sector3, numeric</p>
</dd>
<dt>Sector4</dt><dd><p>returns for Sector4, numeric</p>
</dd>
<dt>Sector5</dt><dd><p>returns for Sector5, numeric</p>
</dd>
<dt>Sector6</dt><dd><p>returns for Sector6, numeric</p>
</dd>
<dt>Sector7</dt><dd><p>returns for Sector7, numeric</p>
</dd>
<dt>Sector8</dt><dd><p>returns for Sector8, numeric</p>
</dd>
<dt>Sector9</dt><dd><p>returns for Sector9, numeric</p>
</dd>
<dt>Sector10</dt><dd><p>returns for Sector10, numeric</p>
</dd>
</dl>

<hr>
<h2 id='test_weights'>Sample sector weights for use by unit tests</h2><span id='topic+test_weights'></span>

<h3>Description</h3>

<p>A dataset containing weights for 10 sectors over 5 month-end periods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test_weights
</code></pre>


<h3>Format</h3>

<p>A data frame with 5 rows and 10 variables:
</p>

<dl>
<dt>Sector1</dt><dd><p>weight in Sector1, numeric</p>
</dd>
<dt>Sector2</dt><dd><p>weight in Sector2, numeric</p>
</dd>
<dt>Sector3</dt><dd><p>weight in Sector3, numeric</p>
</dd>
<dt>Sector4</dt><dd><p>weight in Sector4, numeric</p>
</dd>
<dt>Sector5</dt><dd><p>weight in Sector5, numeric</p>
</dd>
<dt>Sector6</dt><dd><p>weight in Sector6, numeric</p>
</dd>
<dt>Sector7</dt><dd><p>weight in Sector7, numeric</p>
</dd>
<dt>Sector8</dt><dd><p>weight in Sector8, numeric</p>
</dd>
<dt>Sector9</dt><dd><p>weight in Sector9, numeric</p>
</dd>
<dt>Sector10</dt><dd><p>weight in Sector10, numeric</p>
</dd>
</dl>

<hr>
<h2 id='to.period.contributions'>Aggregate contributions through time</h2><span id='topic+to.period.contributions'></span><span id='topic+to.monthly.contributions'></span><span id='topic+to.weekly.contributions'></span><span id='topic+to.quarterly.contributions'></span><span id='topic+to.yearly.contributions'></span>

<h3>Description</h3>

<p>Higher frequency contributions provided as a time series are converted to a lower
frequency for a specified calendar period.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>to.period.contributions(
  Contributions,
  period = c("years", "quarters", "months", "weeks", "all")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="to.period.contributions_+3A_contributions">Contributions</code></td>
<td>
<p>a time series of the per period contribution to portfolio return of each asset</p>
</td></tr>
<tr><td><code id="to.period.contributions_+3A_period">period</code></td>
<td>
<p>period to convert to.  See details. &quot;weeks&quot;, &quot;months&quot;, &quot;quarters&quot;, &quot;years&quot;, or &quot;all&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>From the portfolio contributions of individual assets, such as those of a particular asset class
or manager, the multiperiod contribution is neither summable from nor the geometric compounding of
single-period contributions.  Because the weights of the individual assets change through time as
transactions occur, the capital base for the asset changes.
</p>
<p>Instead, the asset's multiperiod contribution is the sum of the asset's dollar contributions from
each period, as calculated from the wealth index of the total portfolio. Once contributions are
expressed in cumulative terms, asset contributions then sum to the returns of the total portfolio for
the period.
</p>
<p>Valid period character strings for period include: &quot;weeks&quot;, &quot;months&quot;, &quot;quarters&quot;, &quot;years&quot;, or &quot;all&quot;.
These are calculated internally via <code><a href="xts.html#topic+endpoints">endpoints</a></code>. See that function's help page for further details.
</p>
<p>For the special period &quot;all&quot;, the contribution is calculated over all rows,
giving a single contribution across all observations.
</p>


<h3>Author(s)</h3>

<p>Peter Carl, with thanks to Paolo Cavatore
</p>


<h3>References</h3>

<p>Morningstar, <em>Total Portfolio Performance Attribution Methodology</em>, p.36.
Available at
<a href="http://corporate.morningstar.com/US/documents/MethodologyDocuments/MethodologyPapers/TotalPortfolioPerformanceAttributionMethodology.pdf">http://corporate.morningstar.com/US/documents/MethodologyDocuments/MethodologyPapers/TotalPortfolioPerformanceAttributionMethodology.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Return.portfolio">Return.portfolio</a></code> <br /> <code><a href="xts.html#topic+endpoints">endpoints</a></code> <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(managers, package="PerformanceAnalytics")

res_qtr_rebal = Return.portfolio(  managers["2002::",1:5]
                                 , weights=c(.05,.1,.3,.4,.15)
                                 , rebalance_on = "quarters"
                                 , verbose=TRUE)
                                 
to.period.contributions(res_qtr_rebal$contribution, period="years")
to.yearly.contributions(res_qtr_rebal$contribution)

</code></pre>

<hr>
<h2 id='TotalRisk'>Total risk of the return distribution</h2><span id='topic+TotalRisk'></span>

<h3>Description</h3>

<p>The square of total risk is the sum of the square of systematic risk and the square
of specific risk. Specific risk is the standard deviation of the error term in the
regression equation. Both terms are annualized to calculate total risk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TotalRisk(Ra, Rb, Rf = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TotalRisk_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="TotalRisk_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="TotalRisk_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="TotalRisk_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">Total Risk = \sqrt{Systematic Risk^2 + Specific Risk^2}</code>
</p>



<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.75
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(portfolio_bacon)
print(TotalRisk(portfolio_bacon[,1], portfolio_bacon[,2])) #expected 0.0134

data(managers)
print(TotalRisk(managers['1996',1], managers['1996',8]))
print(TotalRisk(managers['1996',1:5], managers['1996',8]))

</code></pre>

<hr>
<h2 id='TrackingError'>Calculate Tracking Error of returns against a benchmark</h2><span id='topic+TrackingError'></span>

<h3>Description</h3>

<p>A measure of the unexplained portion of performance relative to a benchmark.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TrackingError(Ra, Rb, scale = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TrackingError_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="TrackingError_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="TrackingError_+3A_scale">scale</code></td>
<td>
<p>number of periods in a year (daily scale = 252, monthly scale =
12, quarterly scale = 4)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Tracking error is calculated by taking the square root of the average of the
squared deviations between the investment's returns and the benchmark's
returns, then multiplying the result by the square root of the scale of the
returns.
</p>
<p style="text-align: center;"><code class="reqn"> TrackingError =
\sqrt{\sum\frac{(R_{a}-R_{b})^{2}}{len(R_{a})\sqrt{scale}}} </code>
</p>



<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>Sharpe, W.F. The Sharpe Ratio,<em>Journal of Portfolio
Management</em>,Fall 1994, 49-58.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+InformationRatio">InformationRatio</a></code> <code><a href="#topic+TrackingError">TrackingError</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
TrackingError(managers[,1,drop=FALSE], managers[,8,drop=FALSE]) 
TrackingError(managers[,1:6], managers[,8,drop=FALSE]) 
TrackingError(managers[,1:6], managers[,8:7,drop=FALSE])

</code></pre>

<hr>
<h2 id='TreynorRatio'>calculate Treynor Ratio or modified Treynor Ratio of excess return over CAPM beta</h2><span id='topic+TreynorRatio'></span>

<h3>Description</h3>

<p>The Treynor ratio is similar to the Sharpe Ratio, except it uses beta as the
volatility measure (to divide the investment's excess return over the beta).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TreynorRatio(Ra, Rb, Rf = 0, scale = NA, modified = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TreynorRatio_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="TreynorRatio_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="TreynorRatio_+3A_rf">Rf</code></td>
<td>
<p>risk free rate, in same period as your returns</p>
</td></tr>
<tr><td><code id="TreynorRatio_+3A_scale">scale</code></td>
<td>
<p>number of periods in a year (daily scale = 252, monthly scale =
12, quarterly scale = 4)</p>
</td></tr>
<tr><td><code id="TreynorRatio_+3A_modified">modified</code></td>
<td>
<p>a boolean to decide whether to return the Treynor ratio or
Modified Treynor ratio</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To calculate modified Treynor ratio, we divide the numerator by the systematic risk
instead of the beta.
</p>
<p>Equation:
</p>
<p style="text-align: center;"><code class="reqn">TreynorRatio = \frac{\overline{(R_{a}-R_{f})}}{\beta_{a,b}}</code>
</p>

<p style="text-align: center;"><code class="reqn">ModifiedTreynorRatio = \frac{r_p - r_f}{\sigma_s}</code>
</p>



<h3>Author(s)</h3>

<p>Peter Carl, Matthieu Lestel
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Treynor_ratio">http://en.wikipedia.org/wiki/Treynor_ratio</a>, 
Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.77
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SharpeRatio">SharpeRatio</a></code> <code><a href="#topic+SortinoRatio">SortinoRatio</a></code>
<code><a href="#topic+CAPM.beta">CAPM.beta</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(portfolio_bacon) 
data(managers)
round(TreynorRatio(managers[,1], managers[,8], Rf=.035/12),4) 
round(TreynorRatio(managers[,1], managers[,8], Rf = managers[,10]),4) 
round(TreynorRatio(managers[,1:6], managers[,8], Rf=.035/12),4) 
round(TreynorRatio(managers[,1:6], managers[,8], Rf = managers[,10]),4)
round(TreynorRatio(managers[,1:6], managers[,8:7], Rf=.035/12),4) 
round(TreynorRatio(managers[,1:6], managers[,8:7], Rf = managers[,10]),4)

print(TreynorRatio(portfolio_bacon[,1], portfolio_bacon[,2], modified = TRUE)) #expected 0.7975 

print(TreynorRatio(managers['1996',1], managers['1996',8], modified = TRUE))
print(TreynorRatio(managers['1996',1:5], managers['1996',8], modified = TRUE)) 

</code></pre>

<hr>
<h2 id='UlcerIndex'>calculate the Ulcer Index</h2><span id='topic+UlcerIndex'></span>

<h3>Description</h3>

<p>Developed by Peter G. Martin in 1987 (Martin and McCann, 1987) and named
for the worry caused to the portfolio manager or investor.  This is
similar to drawdown deviation except that the impact of the duration of 
drawdowns is incorporated by selecting the negative return for each 
period below the previous peak or high water mark.  The impact of long,
deep drawdowns will have significant impact because the underperformance
since the last peak is squared.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UlcerIndex(R, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="UlcerIndex_+3A_r">R</code></td>
<td>
<p>a vector, matrix, data frame, timeSeries or zoo object of asset
returns</p>
</td></tr>
<tr><td><code id="UlcerIndex_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>UI = sqrt(sum[i=1,2,...,n](D'_i^2/n)) where
D'_i = drawdown since previous peak in period i
</p>
<p>DETAILS:
This approach is sensitive to the frequency of the time periods involved 
and penalizes managers that take time to recover to previous highs.
</p>
<p>REFERENCES:
Martin, P. and McCann, B. (1989) The investor's Guide to Fidelity Funds: 
Winning Strategies for Mutual Fund Investors.  John Wiley &amp; Sons, Inc.
Peter Martin's web page on UI: http://www.tangotools.com/ui/ui.htm
</p>
<p>## Test against spreadsheet at: 
http://www.tangotools.com/ui/UlcerIndex.xls
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>

<hr>
<h2 id='UpDownRatios'>calculate metrics on up and down markets for the benchmark asset</h2><span id='topic+UpDownRatios'></span>

<h3>Description</h3>

<p>Calculate metrics on how the asset in R performed in up and down markets,
measured by periods when the benchmark asset was up or down.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UpDownRatios(
  Ra,
  Rb,
  method = c("Capture", "Number", "Percent"),
  side = c("Up", "Down")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="UpDownRatios_+3A_ra">Ra</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="UpDownRatios_+3A_rb">Rb</code></td>
<td>
<p>return vector of the benchmark asset</p>
</td></tr>
<tr><td><code id="UpDownRatios_+3A_method">method</code></td>
<td>
<p>&quot;Capture&quot;, &quot;Number&quot;, or &quot;Percent&quot; to indicate which measure to
return</p>
</td></tr>
<tr><td><code id="UpDownRatios_+3A_side">side</code></td>
<td>
<p>&quot;Up&quot; or &quot;Down&quot; market statistics</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a function designed to calculate several related metrics:
</p>
<p>Up (Down) Capture Ratio: this is a measure of an investment's compound
return when the benchmark was up (down) divided by the benchmark's compound
return when the benchmark was up (down). The greater (lower) the value, the
better.
</p>
<p>Up (Down) Number Ratio: similarly, this is a measure of the number of
periods that the investment was up (down) when the benchmark was up (down),
divided by the number of periods that the Benchmark was up (down).
</p>
<p>Up (Down) Percentage Ratio: this is a measure of the number of periods that
the investment outperformed the benchmark when the benchmark was up (down),
divided by the number of periods that the benchmark was up (down). Unlike
the prior two metrics, in both cases a higher value is better.
</p>


<h3>Author(s)</h3>

<p>Peter Carl
</p>


<h3>References</h3>

<p>Bacon, C. <em>Practical Portfolio Performance Measurement and
Attribution</em>. Wiley. 2004. p. 47 <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(managers)
UpDownRatios(managers[,1, drop=FALSE], managers[,8, drop=FALSE])
UpDownRatios(managers[,1:6, drop=FALSE], managers[,8, drop=FALSE])
UpDownRatios(managers[,1, drop=FALSE], managers[,8, drop=FALSE], method="Capture")
# Up Capture:
UpDownRatios(managers[,1, drop=FALSE], managers[,8, drop=FALSE], side="Up", method="Capture")
# Down Capture:
UpDownRatios(managers[,1, drop=FALSE], managers[,8, drop=FALSE], side="Down", method="Capture")

</code></pre>

<hr>
<h2 id='UpsideFrequency'>upside frequency of the return distribution</h2><span id='topic+UpsideFrequency'></span>

<h3>Description</h3>

<p>To calculate Upside Frequency, we take the subset of returns that are
more than the target (or Minimum Acceptable Returns (MAR)) returns and
divide the length of this subset by the total number of returns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UpsideFrequency(R, MAR = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="UpsideFrequency_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="UpsideFrequency_+3A_mar">MAR</code></td>
<td>
<p>Minimum Acceptable Return, in the same periodicity as your
returns</p>
</td></tr>
<tr><td><code id="UpsideFrequency_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn"> UpsideFrequency(R , MAR) = \sum^{n}_{t=1}\frac{max[(R_{t} - MAR),
 0]}{R_{t}*n}</code>
</p>

<p>where <code class="reqn">n</code> is the number of observations of the entire series
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.94
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(portfolio_bacon)
MAR = 0.005
print(UpsideFrequency(portfolio_bacon[,1], MAR)) #expected 0.542

data(managers)
print(UpsideFrequency(managers['1996']))
print(UpsideFrequency(managers['1996',1])) #expected 0.75

</code></pre>

<hr>
<h2 id='UpsidePotentialRatio'>calculate Upside Potential Ratio of upside performance over downside risk</h2><span id='topic+UpsidePotentialRatio'></span><span id='topic+UPR'></span>

<h3>Description</h3>

<p>Sortino proposed an improvement on the Sharpe Ratio to better account for
skill and excess performance by using only downside semivariance as the
measure of risk.  That measure is the <code><a href="#topic+SortinoRatio">SortinoRatio</a></code>. This
function, Upside Potential Ratio, was a further improvement, extending the
measurement of only upside on the numerator, and only downside of the
denominator of the ratio equation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UpsidePotentialRatio(R, MAR = 0, method = c("subset", "full"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="UpsidePotentialRatio_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="UpsidePotentialRatio_+3A_mar">MAR</code></td>
<td>
<p>Minimum Acceptable Return, in the same periodicity as your
returns</p>
</td></tr>
<tr><td><code id="UpsidePotentialRatio_+3A_method">method</code></td>
<td>
<p>one of &quot;full&quot; or &quot;subset&quot;, indicating whether to use the
length of the full series or the length of the subset of the series
above(below) the MAR as the denominator, defaults to &quot;subset&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p>calculate Upside Potential Ratio of upside performance over downside risk
</p>
<p>Sortino proposed an improvement on the Sharpe Ratio to better account for
skill and excess performance by using only downside semivariance as the
measure of risk.  That measure is the <code><a href="#topic+SortinoRatio">SortinoRatio</a></code>. This
function, Upside Potential Ratio, was a further improvement, extending the
measurement of only upside on the numerator, and only downside of the
denominator of the ratio equation.
</p>
<p>Sortino contends that risk should be measured in terms of not meeting the
investment goal.  This gives rise to the notion of &ldquo;Minimum
Acceptable Return&rdquo; or MAR.  All of Sortino's proposed measures include the
MAR, and are more sensitive to downside or extreme risks than measures that
use volatility(standard deviation of returns) as the measure of risk.
</p>
<p>Choosing the MAR carefully is very important, especially when comparing
disparate investment choices.  If the MAR is too low, it will not adequately
capture the risks that concern the investor, and if the MAR is too high, it
will unfavorably portray what may otherwise be a sound investment.  When
comparing multiple investments, some papers recommend using the risk free
rate as the MAR.  Practitioners may wish to choose one MAR for consistency,
several standardized MAR values for reporting a range of scenarios, or a MAR
customized to the objective of the investor.
</p>
<p style="text-align: center;"><code class="reqn"> UPR=\frac{ \sum^{n}_{t=1} (R_{t} - MAR) }{ \delta_{MAR} } </code>
</p>
<p> where
<code class="reqn">\delta_{MAR}</code> is the <code><a href="#topic+DownsideDeviation">DownsideDeviation</a></code>.
</p>
<p>The numerator in <code>UpsidePotentialRatio</code> only uses returns that exceed
the MAR, and the denominator (in <code><a href="#topic+DownsideDeviation">DownsideDeviation</a></code>) only uses
returns that fall short of the MAR by default.  Sortino contends that this
is a more accurate and balanced protrayal of return potential, wherase
<code><a href="#topic+SortinoRatio">SortinoRatio</a></code> can reward managers most at the peak of a cycle,
without adequately penalizing them for past mediocre performance.  Others
have used the full series, and this is provided as an option by the
<code>method</code> argument.
</p>


<h3>Author(s)</h3>

<p>Brian G. Peterson
</p>


<h3>References</h3>

<p>Sortino, F. and Price, L. Performance Measurement in a Downside
Risk Framework. <em>Journal of Investing</em>. Fall 1994, 59-65.
</p>
<p>Plantinga, A., van der Meer, R. and Sortino, F. The Impact of Downside Risk
on Risk-Adjusted Performance of Mutual Funds in the Euronext Markets. July
19, 2001. Available at SSRN: <a href="http://ssrn.com/abstract=277352">http://ssrn.com/abstract=277352</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SharpeRatio">SharpeRatio</a></code> <br /> <code><a href="#topic+SortinoRatio">SortinoRatio</a></code> <br />
<code><a href="#topic+DownsideDeviation">DownsideDeviation</a></code> <br /> <code><a href="#topic+SemiVariance">SemiVariance</a></code> <br />
<code><a href="#topic+SemiDeviation">SemiDeviation</a></code> <br /> <code><a href="#topic+InformationRatio">InformationRatio</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(edhec)
UpsidePotentialRatio(edhec[, 6], MAR=.05/12) #5 percent/yr MAR
UpsidePotentialRatio(edhec[, 1:6], MAR=0)
</code></pre>

<hr>
<h2 id='UpsideRisk'>upside risk, variance and potential of the return distribution</h2><span id='topic+UpsideRisk'></span>

<h3>Description</h3>

<p>Upside Risk is the similar of semideviation taking the return above the
Minimum Acceptable Return instead of using the mean return or zero.
To calculate it, we take the subset of returns that are more than the target
(or Minimum Acceptable Returns (MAR)) returns and take the differences of
those to the target.  We sum the squares and divide by the total number of
returns and return the square root.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UpsideRisk(
  R,
  MAR = 0,
  method = c("full", "subset"),
  stat = c("risk", "variance", "potential"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="UpsideRisk_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="UpsideRisk_+3A_mar">MAR</code></td>
<td>
<p>Minimum Acceptable Return, in the same periodicity as your
returns</p>
</td></tr>
<tr><td><code id="UpsideRisk_+3A_method">method</code></td>
<td>
<p>one of &quot;full&quot; or &quot;subset&quot;, indicating whether to use the
length of the full series or the length of the subset of the series below
the MAR as the denominator, defaults to &quot;full&quot;</p>
</td></tr>
<tr><td><code id="UpsideRisk_+3A_stat">stat</code></td>
<td>
<p>one of &quot;risk&quot;, &quot;variance&quot; or &quot;potential&quot; indicating whether
to return the Upside risk, variance or potential</p>
</td></tr>
<tr><td><code id="UpsideRisk_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn"> UpsideRisk(R , MAR) = \sqrt{\sum^{n}_{t=1}\frac{
max[(R_{t} - MAR), 0]^2}{n}}</code>
</p>

<p style="text-align: center;"><code class="reqn"> UpsideVariance(R, MAR) = \sum^{n}_{t=1}\frac{max[(R_{t} - MAR), 0]^2} {n}</code>
</p>

<p style="text-align: center;"><code class="reqn">UpsidePotential(R, MAR) = \sum^{n}_{t=1}\frac{max[(R_{t} - MAR), 0]} {n}</code>
</p>

<p>where <code class="reqn">n</code> is either the number of observations of the entire series or
the number of observations in the subset of the series falling below the
MAR.
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(portfolio_bacon)
MAR = 0.005
print(UpsideRisk(portfolio_bacon[,1], MAR, stat="risk")) #expected 0.02937
print(UpsideRisk(portfolio_bacon[,1], MAR, stat="variance")) #expected 0.08628
print(UpsideRisk(portfolio_bacon[,1], MAR, stat="potential")) #expected 0.01771

MAR = 0
data(managers)
print(UpsideRisk(managers['1996'], MAR, stat="risk"))
print(UpsideRisk(managers['1996',1], MAR, stat="risk")) #expected 1.820

</code></pre>

<hr>
<h2 id='VaR'>calculate various Value at Risk (VaR) measures</h2><span id='topic+VaR'></span><span id='topic+VaR.CornishFisher'></span>

<h3>Description</h3>

<p>Calculates Value-at-Risk(VaR) for univariate, component, and marginal cases
using a variety of analytical methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VaR(
  R = NULL,
  p = 0.95,
  ...,
  method = c("modified", "gaussian", "historical", "kernel"),
  clean = c("none", "boudt", "geltner", "locScaleRob"),
  portfolio_method = c("single", "component", "marginal"),
  weights = NULL,
  mu = NULL,
  sigma = NULL,
  m3 = NULL,
  m4 = NULL,
  invert = TRUE,
  SE = FALSE,
  SE.control = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VaR_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="VaR_+3A_p">p</code></td>
<td>
<p>confidence level for calculation, default p=.95</p>
</td></tr>
<tr><td><code id="VaR_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
<tr><td><code id="VaR_+3A_method">method</code></td>
<td>
<p>one of &quot;modified&quot;,&quot;gaussian&quot;,&quot;historical&quot;, &quot;kernel&quot;, see
Details.</p>
</td></tr>
<tr><td><code id="VaR_+3A_clean">clean</code></td>
<td>
<p>method for data cleaning through <code><a href="#topic+Return.clean">Return.clean</a></code>.
Current options are &quot;none&quot;, &quot;boudt&quot;, &quot;geltner&quot;, or &quot;locScaleRob&quot;.</p>
</td></tr>
<tr><td><code id="VaR_+3A_portfolio_method">portfolio_method</code></td>
<td>
<p>one of &quot;single&quot;,&quot;component&quot;,&quot;marginal&quot; defining
whether to do univariate, component, or marginal calc, see Details.</p>
</td></tr>
<tr><td><code id="VaR_+3A_weights">weights</code></td>
<td>
<p>portfolio weighting vector, default NULL, see Details</p>
</td></tr>
<tr><td><code id="VaR_+3A_mu">mu</code></td>
<td>
<p>If univariate, mu is the mean of the series. Otherwise mu is the
vector of means of the return series, default NULL, see Details</p>
</td></tr>
<tr><td><code id="VaR_+3A_sigma">sigma</code></td>
<td>
<p>If univariate, sigma is the variance of the series. Otherwise
sigma is the covariance matrix of the return series, default NULL, see
Details</p>
</td></tr>
<tr><td><code id="VaR_+3A_m3">m3</code></td>
<td>
<p>If univariate, m3 is the skewness of the series. Otherwise m3 is
the coskewness matrix (or vector with unique coskewness values) of the 
returns series, default NULL, see Details</p>
</td></tr>
<tr><td><code id="VaR_+3A_m4">m4</code></td>
<td>
<p>If univariate, m4 is the excess kurtosis of the series. Otherwise
m4 is the cokurtosis matrix (or vector with unique cokurtosis values) of the 
return series, default NULL, see Details</p>
</td></tr>
<tr><td><code id="VaR_+3A_invert">invert</code></td>
<td>
<p>TRUE/FALSE whether to invert the VaR measure.  see Details.</p>
</td></tr>
<tr><td><code id="VaR_+3A_se">SE</code></td>
<td>
<p>TRUE/FALSE whether to ouput the standard errors of the estimates of the risk measures, default FALSE.</p>
</td></tr>
<tr><td><code id="VaR_+3A_se.control">SE.control</code></td>
<td>
<p>Control parameters for the computation of standard errors. Should be done using the <code><a href="#topic+RPESE.control">RPESE.control</a></code> function.</p>
</td></tr>
</table>


<h3>Background </h3>

<p>This function provides several estimation methods for
the Value at Risk (typically written as VaR) of a return series and the
Component VaR of a portfolio. Take care to capitalize VaR in the commonly
accepted manner, to avoid confusion with var (variance) and VAR (vector
auto-regression).  VaR is an industry standard for measuring downside risk.
For a return series, VaR is defined as the high quantile (e.g. ~a 95
quantile) of the negative value of the returns. This quantile needs to be
estimated.  With a sufficiently large data set, you may choose to utilize
the empirical quantile calculated using <code><a href="stats.html#topic+quantile">quantile</a></code>.  More
efficient estimates of VaR are obtained if a (correct) assumption is made on
the return distribution, such as the normal distribution.  If your return
series is skewed and/or has excess kurtosis, Cornish-Fisher estimates of VaR
can be more appropriate.  For the VaR of a portfolio, it is also of interest
to decompose total portfolio VaR into the risk contributions of each of the
portfolio components.  For the above mentioned VaR estimators, such a
decomposition is possible in a financially meaningful way.
</p>


<h3>Univariate VaR estimation methods </h3>

<p>The VaR at a probability level <code class="reqn">p</code> (e.g. 95%) is the <code class="reqn">p</code>-quantile of
the negative returns, or equivalently, is the negative value of the
<code class="reqn">c=1-p</code> quantile of the returns. In a set of returns for which
sufficently long history exists, the per-period Value at Risk is simply the
quantile of the period negative returns :
</p>
<p style="text-align: center;"><code class="reqn">VaR=q_{.99}</code>
</p>

<p>where  <code class="reqn">q_{.99}</code> is the 99% empirical quantile of the negative return series.
</p>
<p>This method is also sometimes called &ldquo;historical VaR&rdquo;, as it is by
definition <em>ex post</em> analysis of the return distribution, and may be
accessed with <code>method="historical"</code>.
</p>
<p>When you don't have a sufficiently long set of returns to use non-parametric
or historical VaR, or wish to more closely model an ideal distribution, it is
common to us a parmetric estimate based on the distribution. J.P. Morgan's
RiskMetrics parametric mean-VaR was published in 1994 and this methodology
for estimating parametric mean-VaR has become what most literature generally
refers to as &ldquo;VaR&rdquo; and what we have implemented as <code><a href="#topic+VaR">VaR</a></code>.
See <cite>Return to RiskMetrics: Evolution of a
Standard</cite><a href="https://www.msci.com/documents/10199/dbb975aa-5dc2-4441-aa2d-ae34ab5f0945">https://www.msci.com/documents/10199/dbb975aa-5dc2-4441-aa2d-ae34ab5f0945</a>.
</p>
<p>Parametric mean-VaR does a better job of accounting for the tails of the
distribution by more precisely estimating shape of the distribution tails of
the risk quantile. The most common estimate is a normal (or Gaussian)
distribution  <code class="reqn">R\sim N(\mu,\sigma)</code> for the return series. In this case,
estimation of VaR requires the mean return  <code class="reqn">\bar{R}</code>, the return
distribution and the variance of the returns  <code class="reqn">\sigma</code>. In the most
common case, parametric VaR is thus calculated by
</p>
<p style="text-align: center;"><code class="reqn">\sigma=variance(R)</code>
</p>

<p style="text-align: center;"><code class="reqn">VaR=-\bar{R} -  \sqrt{\sigma} \cdot z_{c} </code>
</p>

<p>where  <code class="reqn">z_{c}</code> is the  <code class="reqn">c</code>-quantile of the standard normal distribution. Represented in <span class="rlang"><b>R</b></span> by <code>qnorm(c)</code>,
and may be accessed with <code>method="gaussian"</code>.
</p>
<p>Other forms of parametric mean-VaR estimation utilize a different
distribution for the distribution of losses to better account for the
possible fat-tailed nature of downside risk. The now-archived package
<code>VaR</code> contained methods for simulating and estimating lognormal and
generalized Pareto distributions to overcome some of the problems with
nonparametric or parametric mean-VaR calculations on a limited sample size or
on potentially fat-tailed distributions. There was also a
VaR.backtest function to apply simulation methods to create a more robust
estimate of the potential distribution of losses. Less commonly a covariance
matrix of multiple risk factors may be applied. This functionality should 
probably be 
</p>
<p>The limitations of mean Value-at-Risk are well covered in the literature.
The limitations of traditional mean-VaR are all related to the use of a
symetrical distribution function. Use of simulations, resampling, or Pareto
distributions all help in making a more accurate prediction, but they are
still flawed for assets with significantly non-normal (skewed or kurtotic)
distributions. Zangari (1996) and Favre and Galeano(2002) provide a modified
VaR calculation that takes the higher moments of non-normal distributions
(skewness, kurtosis) into account through the use of a Cornish Fisher
expansion, and collapses to standard (traditional) mean-VaR if the return
stream follows a standard distribution. This measure is now widely cited and
used in the literature, and is usually referred to as &ldquo;Modified VaR&rdquo;
or &ldquo;Modified Cornish-Fisher VaR&rdquo;. They arrive at their modified VaR
calculation in the following manner:
</p>
<p style="text-align: center;"><code class="reqn">z_{cf}=z_{c}+\frac{(z_{c}^{2}-1)S}{6}+\frac{(z_{c}^{3}-3z_{c})K}{24}-\frac{(2z_{c}^{3}-5z_{c})S^{2}}{36}</code>
</p>

<p style="text-align: center;"><code class="reqn">Cornish-Fisher VaR =-\bar{R} - \sqrt(\sigma) \cdot z_{cf}</code>
</p>

<p>where <code class="reqn">S</code> is the skewness of <code class="reqn">R</code> and <code class="reqn">K</code> is the excess kurtosis of <code class="reqn">R</code>.
</p>
<p>Cornish-Fisher VaR collapses to traditional mean-VaR when returns are
normally distributed. As such, the <code><a href="#topic+VaR">VaR</a></code> and <code><a href="#topic+VaR">VaR</a></code>
functions are wrappers for the <code>VaR</code> function. The Cornish-Fisher
expansion also naturally encompasses much of the variability in returns that
could be uncovered by more computationally intensive techniques such as
resampling or Monte-Carlo simulation.  This is the default method for the
<code>VaR</code> function, and may be accessed by setting <code>method="modified"</code>.
</p>
<p>Favre and Galeano also utilize modified VaR in a modified Sharpe Ratio as the
return/risk measure for their portfolio optimization analysis, see
<code><a href="#topic+SharpeRatio.modified">SharpeRatio.modified</a></code> for more information.
</p>


<h3>Component VaR </h3>

<p>By setting <code>portfolio_method="component"</code> you may calculate the risk
contribution of each element of the portfolio.  The return from the function
in this case will be a list with three components: the univariate portfolio
VaR, the scalar contribution of each component to the portfolio VaR (these
will sum to the portfolio VaR), and a percentage risk contribution (which
will sum to 100%).
</p>
<p>Both the numerical and percentage component contributions to VaR may contain
both positive and negative contributions.  A negative contribution to
Component VaR indicates a portfolio risk diversifier.  Increasing the
position weight will reduce overall portoflio VaR.
</p>
<p>If a weighting vector is not passed in via <code>weights</code>, the function will
assume an equal weighted (neutral) portfolio.
</p>
<p>Multiple risk decomposition approaches have been suggested in the literature. 
A naive approach is to set the risk contribution equal to the stand-alone risk.
This approach is overly simplistic and neglects important diversification
effects of the units being exposed differently to the underlying risk
factors. An alternative approach is to measure the VaR contribution as the
weight of the position in the portfolio times the partial derivative of the
portfolio VaR with respect to the component weight. </p>
<p style="text-align: center;"><code class="reqn">C_i \mbox{VaR} =
w_i \frac{ \partial \mbox{VaR} }{\partial w_i}.</code>
</p>
<p> Because the portfolio VaR is linear in position size, we
have that by Euler's theorem the portfolio VaR is the sum of these risk
contributions. Gourieroux (2000) shows that for VaR, this mathematical
decomposition of portfolio risk has a financial meaning. It equals the
negative value of the asset's expected contribution to the portfolio return
when the portfolio return equals the negative portfolio VaR:
</p>
<p style="text-align: center;"><code class="reqn">C_i \mbox{VaR} = = -E\left[ w_i r_{i} | r_{p} = - \mbox{VaR}\right]</code>
</p>

<p>For the decomposition of Gaussian VaR, the estimated mean and covariance
matrix are needed. For the decomposition of modified VaR, also estimates of
the coskewness and cokurtosis matrices are needed. If <code class="reqn">r</code> denotes the
<code class="reqn">Nx1</code> return vector and <code class="reqn">mu</code> is the mean vector, then the <code class="reqn">N
\times N^2</code> co-skewness matrix is </p>
<p style="text-align: center;"><code class="reqn"> m3 = E\left[ (r - \mu)(r - \mu)'
\otimes (r - \mu)'\right]</code>
</p>
<p> The
<code class="reqn">N \times N^3</code> co-kurtosis matrix is
</p>
<p style="text-align: center;"><code class="reqn"> m_{4} =
  E\left[ (r - \mu)(r - \mu)' \otimes (r - \mu)'\otimes (r - \mu)'
  \right] </code>
</p>

<p>where <code class="reqn">\otimes</code> stands for the Kronecker product. The matrices can
be estimated through the functions <code>skewness.MM</code> and <code>kurtosis.MM</code>.
More efficient estimators have been proposed by Martellini and Ziemann (2007)
and will be implemented in the future.
</p>
<p>As discussed among others in Cont, Deguest and Scandolo (2007), it is
important that the estimation of the VaR measure is robust to single
outliers. This is especially the case for  modified VaR and its
decomposition, since they use higher order moments. By default, the portfolio
moments are estimated by their sample counterparts. If <code>clean="boudt"</code>
then the <code class="reqn">1-p</code> most extreme observations are winsorized if they are
detected as being outliers. For more information, see Boudt, Peterson and
Croux (2008) and <code><a href="#topic+Return.clean">Return.clean</a></code>.  If your data consist of returns
for highly illiquid assets, then <code>clean="geltner"</code> may be more
appropriate to reduce distortion caused by autocorrelation, see
<code><a href="#topic+Return.Geltner">Return.Geltner</a></code> for details.
</p>
<p>Epperlein and Smillie (2006) introduced a non-parametric kernel estimator for 
component risk contributions, which is available via <code>method="kernel"</code> 
and <code>portfolio_method="component"</code>.
</p>


<h3>Marginal VaR </h3>

<p>Different papers call this different things.  In the Denton and Jayaraman
paper referenced here, this calculation is called Incremental VaR. We have
chosen the more common usage of calling this difference in VaR's in
portfolios without the instrument and with the instrument as the
&ldquo;difference at the Margin&rdquo;, thus the name Marginal VaR. This is
incredibly confusing, and hasn't been resolved in the literature at this
time.
</p>
<p>Simon Keel and David Ardia (2009) attempt to reconcile some of the
definitional issues and address some of the shortcomings of this measure in
their working paper titled &ldquo;Generalized Marginal Risk&rdquo;. Hopefully 
their improved Marginal Risk measures may be included here in the future.
</p>


<h3>Note</h3>

<p>The option to <code>invert</code> the VaR measure should appease both
academics and practitioners.  The mathematical definition of VaR as the
negative value of a quantile will (usually) produce a positive number.
Practitioners will argue that VaR denotes a loss, and should be internally
consistent with the quantile (a negative number).  For tables and charts,
different preferences may apply for clarity and compactness.  As such, we
provide the option, and set the default to TRUE to keep the return
consistent with prior versions of PerformanceAnalytics, but make no value
judgment on which approach is preferable.
</p>
<p>The prototype of the univariate Cornish Fisher VaR function was completed by
Prof. Diethelm Wuertz.  All corrections to the calculation and error
handling are the fault of Brian Peterson.
</p>


<h3>Author(s)</h3>

<p>Brian G. Peterson and Kris Boudt
</p>


<h3>References</h3>

<p>Boudt, Kris, Peterson, Brian, and Christophe Croux. 2008.
Estimation and decomposition of downside risk for portfolios with non-normal
returns. 2008. The Journal of Risk, vol. 11, 79-103.
</p>
<p>Cont, Rama, Deguest, Romain and Giacomo Scandolo. Robustness and sensitivity
analysis of risk measurement procedures. Financial Engineering Report No.
2007-06, Columbia University Center for Financial Engineering.
</p>
<p>Denton M. and Jayaraman, J.D. Incremental, Marginal, and Component VaR.
Sunguard. 2004.
</p>
<p>Epperlein, E., Smillie, A. Cracking VaR with kernels. RISK, 2006, vol.  19,
70-74.
</p>
<p>Gourieroux, Christian, Laurent, Jean-Paul and Olivier Scaillet.  Sensitivity
analysis of value at risk. Journal of Empirical Finance, 2000, Vol. 7,
225-245.
</p>
<p>Keel, Simon and Ardia, David. Generalized marginal risk. Aeris CAPITAL
discussion paper.
</p>
<p>Laurent Favre and Jose-Antonio Galeano. Mean-Modified Value-at-Risk
Optimization with Hedge Funds. Journal of Alternative Investment, Fall 2002,
v 5.
</p>
<p>Martellini, L. and Ziemann, V., 2010. Improved estimates of higher-order 
comoments and implications for portfolio selection. Review of Financial 
Studies, 23(4):1467-1502.
</p>
<p>Return to RiskMetrics: Evolution of a Standard
<a href="https://www.msci.com/documents/10199/dbb975aa-5dc2-4441-aa2d-ae34ab5f0945">https://www.msci.com/documents/10199/dbb975aa-5dc2-4441-aa2d-ae34ab5f0945</a>
</p>
<p>Zangari, Peter. A VaR Methodology for Portfolios that include Options. 1996.
RiskMetrics Monitor, First Quarter, 4-12.
</p>
<p>Rockafellar, Terry and Uryasev, Stanislav. Optimization of Conditional VaR.
The Journal of Risk, 2000, vol. 2, 21-41.
</p>
<p>Dowd, Kevin. Measuring Market Risk, John Wiley and Sons, 2010.
</p>
<p>Jorian, Phillippe. Value at Risk, the new benchmark for managing financial risk.
3rd Edition, McGraw Hill, 2006.
</p>
<p>Hallerback, John. &quot;Decomposing Portfolio Value-at-Risk: A General Analysis&quot;,
2003. The Journal of Risk vol 5/2.
</p>
<p>Yamai and Yoshiba (2002). &quot;Comparative Analyses of Expected Shortfall and 
Value-at-Risk: Their Estimation Error, Decomposition, and Optimization&quot;,
Bank of Japan.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SharpeRatio.modified">SharpeRatio.modified</a></code> <br />
<code><a href="#topic+chart.VaRSensitivity">chart.VaRSensitivity</a></code> <br />
<code><a href="#topic+Return.clean">Return.clean</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if(!( Sys.info()[['sysname']]=="Windows") ){
# if on Windows, cut and paste this example

    data(edhec)

    # first do normal VaR calc
    VaR(edhec, p=.95, method="historical")

    # now use Gaussian
    VaR(edhec, p=.95, method="gaussian")

    # now use modified Cornish Fisher calc to take non-normal distribution into account
    VaR(edhec, p=.95, method="modified")

    # now use p=.99
    VaR(edhec, p=.99)
    # or the equivalent alpha=.01
    VaR(edhec, p=.01)

    # now with outliers squished
    VaR(edhec, clean="boudt")

    # add Component VaR for the equal weighted portfolio
    VaR(edhec, clean="boudt", portfolio_method="component")

} # end Windows check

</code></pre>

<hr>
<h2 id='VolatilitySkewness'>Volatility and variability of the return distribution</h2><span id='topic+VolatilitySkewness'></span>

<h3>Description</h3>

<p>Volatility skewness is a similar measure to omega but using the second
partial moment. It's the ratio of the upside variance compared to the
downside variance. Variability skewness is the ratio of the upside risk
compared to the downside risk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VolatilitySkewness(R, MAR = 0, stat = c("volatility", "variability"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VolatilitySkewness_+3A_r">R</code></td>
<td>
<p>an xts, vector, matrix, data frame, timeSeries or zoo object of
asset returns</p>
</td></tr>
<tr><td><code id="VolatilitySkewness_+3A_mar">MAR</code></td>
<td>
<p>Minimum Acceptable Return, in the same periodicity as your
returns</p>
</td></tr>
<tr><td><code id="VolatilitySkewness_+3A_stat">stat</code></td>
<td>
<p>one of &quot;volatility&quot;, &quot;variability&quot; indicating whether
to return the volatility skewness or the variability skweness</p>
</td></tr>
<tr><td><code id="VolatilitySkewness_+3A_...">...</code></td>
<td>
<p>any other passthru parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn"> VolatilitySkewness(R , MAR) = \frac{\sigma_U^2}{\sigma_D^2}</code>
</p>

<p style="text-align: center;"><code class="reqn"> VariabilitySkewness(R , MAR) = \frac{\sigma_U}{\sigma_D}</code>
</p>

<p>where <code class="reqn">\sigma_U</code> is the Upside risk and <code class="reqn">\sigma_D</code> is the Downside Risk
</p>


<h3>Author(s)</h3>

<p>Matthieu Lestel
</p>


<h3>References</h3>

<p>Carl Bacon, <em>Practical portfolio performance measurement 
and attribution</em>, second edition 2008 p.97-98
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(portfolio_bacon)
MAR = 0.005
print(VolatilitySkewness(portfolio_bacon[,1], MAR, stat="volatility")) #expected 1.32
print(VolatilitySkewness(portfolio_bacon[,1], MAR, stat="variability")) #expected 1.15

MAR = 0
data(managers)
# print(VolatilitySkewness(managers['1996'], MAR, stat="volatility"))
print(VolatilitySkewness(managers['1996',1], MAR, stat="volatility"))

</code></pre>

<hr>
<h2 id='weights'>Selected Portfolio Weights Data</h2><span id='topic+weights'></span>

<h3>Description</h3>

<p>An xts object that contains columns of monthly weights for a subset of the EDHEC hedge
fund indexes that demonstrate rebalancing portfolios through time.
</p>
<p>Note that all the EDHEC indices are available in <code><a href="#topic+edhec">edhec</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>managers</code></pre>


<h3>Format</h3>

<p>CSV conformed into an xts object with monthly observations</p>


<h3>Details</h3>

<p>A relatively random weights file used for charting examples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(weights)

#preview the data
head(weights)

</code></pre>

<hr>
<h2 id='zerofill'>zerofill</h2><span id='topic+zerofill'></span>

<h3>Description</h3>

<p>Fill NA's with zeros in a time series to allow analysis when the data must
be complete.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zerofill(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zerofill_+3A_x">x</code></td>
<td>
<p>time series to zero fill</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that this function has risks, use carefully.  Complete data is
preferred.  Barring that, filling a small percentage of results in the
middle of a large set is unlikely to cause problems. Barring that, realize
that this will skew your results.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
