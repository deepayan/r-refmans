<!DOCTYPE html><html><head><title>Help for package REBayes</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {REBayes}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#B2mix'><p>Bivariate Binomial mixture estimation via Kiefer Wolfowitz MLE</p></a></li>
<li><a href='#bball'><p>U.S. Major League Batting Average Data: 2002-2012</p></a></li>
<li><a href='#BDGLmix'><p>Efron Bayesian Deconvolution Estimator for Gaussian Mixtures</p></a></li>
<li><a href='#Bmix'><p>Binomial mixture estimation via Kiefer Wolfowitz MLE</p></a></li>
<li><a href='#BPmix'><p>Binomial mixtures with Poisson Trials via Kiefer Wolfowitz NPMLE</p></a></li>
<li><a href='#bwKW'><p>Bandwidth selection for KW smoothing</p></a></li>
<li><a href='#bwKW2'><p>Bandwidth selection for bivariate KW smoothing</p></a></li>
<li><a href='#Cosslett'><p>Kiefer-Wolfowitz estimator for Cosslett (1983) estimator</p></a></li>
<li><a href='#dhuber'><p>Huber density function</p></a></li>
<li><a href='#Finv'><p>Function inversion</p></a></li>
<li><a href='#flies'><p>Medfly Data</p></a></li>
<li><a href='#Gammamix'><p>NPMLE for Gamma Mixtures</p></a></li>
<li><a href='#GLmix'><p>Kiefer-Wolfowitz NPMLE for Gaussian Location Mixtures</p></a></li>
<li><a href='#GLVmix'><p>NPMLE of Gaussian Location-Scale Mixture Model</p></a></li>
<li><a href='#Gompertzmix'><p>NPMLE for Gompertz Mixtures</p></a></li>
<li><a href='#Gosset'><p>Gosset Criminal Finger Data</p></a></li>
<li><a href='#Guvenen'><p>Annual Increments in Log Income</p></a></li>
<li><a href='#GVmix'><p>NPMLE for Gaussian Variance Heterogeneity</p></a></li>
<li><a href='#HLmix'><p>Kiefer-Wolfowitz NPMLE for Huber Location Mixtures</p></a></li>
<li><a href='#hubereps'><p>Huber epsilon</p></a></li>
<li><a href='#KW2smooth'><p>Smooth a bivariate Kiefer-Wolfowitz NPMLE</p></a></li>
<li><a href='#KWDual'><p>Dual optimization for Kiefer-Wolfowitz problems</p></a></li>
<li><a href='#KWPrimal'><p>Primal optimization for Kiefer-Wolfowitz problems</p></a></li>
<li><a href='#KWsmooth'><p>Smooth a Kiefer-Wolfowitz NPMLE</p></a></li>
<li><a href='#L1norm'><p>L1norm for piecewise linear functions</p></a></li>
<li><a href='#Lfdr'><p>Local False Discovery Rate Estimation</p></a></li>
<li><a href='#medde'><p>Maximum Entropy [De]Regularized Density Estimation</p></a></li>
<li><a href='#Norberg'><p>Norberg Life Insurance Data</p></a></li>
<li><a href='#NPmix'><p>Normal mixture with Poisson sample size via Kiefer Wolfowitz NPMLE</p></a></li>
<li><a href='#plot.GLVmix'><p>Plot a GLVmix object</p></a></li>
<li><a href='#plot.medde'><p>Plotting method for medde objects</p></a></li>
<li><a href='#Pmix'><p>Poisson mixture estimation via Kiefer Wolfowitz MLE</p></a></li>
<li><a href='#predict.B2mix'><p>Predict Method for Bmix</p></a></li>
<li><a href='#predict.Bmix'><p>Predict Method for Bmix</p></a></li>
<li><a href='#predict.GLmix'><p>Predict Method for GLmix</p></a></li>
<li><a href='#predict.GLVmix'><p>Predict Method for GLVmix</p></a></li>
<li><a href='#predict.HLmix'><p>Predict Method for HLmix</p></a></li>
<li><a href='#predict.Pmix'><p>Predict Method for Pmix</p></a></li>
<li><a href='#predict.WGLVmix'><p>Predict Method for WGLVmix</p></a></li>
<li><a href='#psychtest'><p>Lord and Cressie Binomial Psychological Test Data</p></a></li>
<li><a href='#qKW'><p>Quantiles of KW fit</p></a></li>
<li><a href='#qKW2'><p>Quantiles of bivariate KW fit</p></a></li>
<li><a href='#qmedde'><p>Quantile function for medde estimate</p></a></li>
<li><a href='#rKW'><p>Random sample from KW object</p></a></li>
<li><a href='#RLR'><p>Regularized Logistic Regression</p></a></li>
<li><a href='#rmedde'><p>Random number generation from a medde estimate</p></a></li>
<li><a href='#Rxiv'><p>Archive function for auxiliary files for latex documents</p></a></li>
<li><a href='#tacks'><p>Beckett and Diaconis flipping tacks data</p></a></li>
<li><a href='#tannenbaum'><p>Perverse Gaussian Mixture data</p></a></li>
<li><a href='#ThreshFDR'><p>Thresholding for False Discovery Rate</p></a></li>
<li><a href='#TLmix'><p>NPMLE for Student t location mixtures</p></a></li>
<li><a href='#Tncpmix'><p>NPMLE for Student t non-centrality parameter mixtures</p></a></li>
<li><a href='#traprule'><p>Integration by Trapezoidal Rule</p></a></li>
<li><a href='#Umix'><p>NPMLE for Uniform Scale Mixtures</p></a></li>
<li><a href='#velo'><p>Rotational Velocity of Stars</p></a></li>
<li><a href='#Weibullmix'><p>NPMLE for Weibull Mixtures</p></a></li>
<li><a href='#WGLVmix'><p>Weighted NPMLE of Longitudinal Gaussian Mean and Variances Model</p></a></li>
<li><a href='#WGVmix'><p>WGVmix: Weighted Generalized Maximum Likelihood for Empirical Bayes</p>
Estimation of Gamma Variances</a></li>
<li><a href='#WLVmix'><p>NPMLE for Longitudinal Gaussian Means and Variances Model with Independent Prior</p></a></li>
<li><a href='#WTLVmix'><p>NPMLE for Longitudinal Gaussian Means and Variances Model</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Empirical Bayes Estimation and Inference</td>
</tr>
<tr>
<td>Description:</td>
<td>Kiefer-Wolfowitz maximum likelihood estimation for mixture models
    and some other density estimation and regression methods based on convex
    optimization.  See Koenker and Gu (2017) REBayes: An R Package for Empirical
    Bayes Mixture Methods, Journal of Statistical Software, 82, 1&ndash;26, 
    &lt;<a href="https://doi.org/10.18637%2Fjss.v082.i08">doi:10.18637/jss.v082.i08</a>&gt;.</td>
</tr>
<tr>
<td>Version:</td>
<td>2.56</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Roger Koenker &lt;rkoenker@uiuc.edu&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), Matrix</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, utils, lattice</td>
</tr>
<tr>
<td>Suggests:</td>
<td>Rmosek, knitr, digest</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>MOSEK (http://www.mosek.com) and MOSEK license.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.r-project.org">https://www.r-project.org</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-06-22 08:08:19 UTC; roger</td>
</tr>
<tr>
<td>Author:</td>
<td>Roger Koenker [aut, cre],
  Jiaying Gu [ctb],
  Ivan Mizera [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-06-22 08:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='B2mix'>Bivariate Binomial mixture estimation via Kiefer Wolfowitz MLE</h2><span id='topic+B2mix'></span>

<h3>Description</h3>

<p>Interior point solution of Kiefer-Wolfowitz NPMLE for mixture of bivariate binomials
</p>


<h3>Usage</h3>

<pre><code class='language-R'>B2mix(x, k, u = 40, v = 40, weights = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="B2mix_+3A_x">x</code></td>
<td>
<p>n by 2 matrix of counts of &quot;successes&quot; for binomial observations</p>
</td></tr>
<tr><td><code id="B2mix_+3A_k">k</code></td>
<td>
<p>n by 2 matrix of Number of trials for binomial observations</p>
</td></tr>
<tr><td><code id="B2mix_+3A_u">u</code></td>
<td>
<p>Grid Values for the mixing distribution defaults to equal
spacing of length u on [eps, 1- eps], if u is scalar.</p>
</td></tr>
<tr><td><code id="B2mix_+3A_v">v</code></td>
<td>
<p>Grid Values for the mixing distribution defaults to equal
spacing of length v on [eps, 1- eps], if v is scalar.</p>
</td></tr>
<tr><td><code id="B2mix_+3A_weights">weights</code></td>
<td>
<p>replicate weights for x obervations, should sum to 1</p>
</td></tr>
<tr><td><code id="B2mix_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to KWDual to control optimization</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function was inspired by a paper by Kline and Walters (2019) on evaluation of audit
experiments for employment discrimination.  An example of its usage is available
with 'demo(B2mix1)'.  There can be identification issues particularly when the
numbers of trials are modest as described in Koenker and Gu (2024).  Caveat emptor!
The predict method for B2mix objects will compute posterior means,
</p>


<h3>Value</h3>

<p>An object of class density with components: 
</p>
<table>
<tr><td><code>u</code></td>
<td>
<p>grid of evaluation points of the mixing density</p>
</td></tr> 
<tr><td><code>v</code></td>
<td>
<p>grid of evaluation points of the mixing density</p>
</td></tr> 
<tr><td><code>y</code></td>
<td>
<p>function values of the mixing density at x</p>
</td></tr> 
<tr><td><code>g</code></td>
<td>
<p>estimates of the mixture density at the distinct data values</p>
</td></tr> 
<tr><td><code>logLik</code></td>
<td>
<p>Log Likelihood value at the estimate</p>
</td></tr>
<tr><td><code>dy</code></td>
<td>
<p>Bayes rule estimates of binomial probabilities for distinct data values</p>
</td></tr>
<tr><td><code>status</code></td>
<td>
<p>exit code from the optimizer</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Koenker
</p>


<h3>References</h3>

<p>Kiefer, J. and J. Wolfowitz Consistency of the Maximum
Likelihood Estimator in the Presence of Infinitely Many Incidental
Parameters <em>Ann. Math. Statist</em>. 27, (1956), 887-906.
</p>
<p>Kline, P. and C. Walters, (2019) Audits as Evidence: Experiments, Ensembles
and Enforcement, preprint.
</p>
<p>Koenker, R. and Gu, J. (2024) Empirical Bayes: Some Tools, Rules and Duals,
Cambridge University Press.
</p>


<h3>See Also</h3>

<p>'Bmix' for univariate binomial mixtures.
</p>

<hr>
<h2 id='bball'>U.S. Major League Batting Average Data: 2002-2012</h2><span id='topic+bball'></span>

<h3>Description</h3>

<p>Data frame consisting of the following variables:
</p>


<h3>Details</h3>

<p>Data is aggregated into half seasons: so season indicates whether
the observation is in the first or second half of the season of a
given year. Only players who have more than 10 at bats in any half
season are included, and only players who have more than three
half seasons are represented. The transformed batting average is
<code class="reqn">arcsin(sqrt((H + 1/4)/(AB + 1/2)))</code>. Only regular seasons data are included. 
R programs to extract the data from the original sources are available on request. 
</p>

<ul>
<li><p> Name
</p>
</li>
<li><p> IdNum
</p>
</li>
<li><p> Year
</p>
</li>
<li><p> Halfseason
</p>
</li>
<li><p> Pitcher
</p>
</li>
<li><p> HA transformed batting average; 
</p>
</li>
<li><p> AB at bats 
</p>
</li>
<li><p> H hits 
</p>
</li>
<li><p> BB walks 
</p>
</li>
<li><p> YOB Year of Birth; 
</p>
</li>
<li><p> age age of the player
</p>
</li>
<li><p> agesq age squared
</p>
</li></ul>



<h3>Source</h3>

<p>ESPN Website: <a href="https://www.espn.com/mlb/stats">https://www.espn.com/mlb/stats</a>
</p>


<h3>References</h3>

<p>Gu, Jiaying and Roger Koenker (2015) Empirical Bayesball Remixed:
Empirical Bayes Methods for Longitudinal Data, J. Applied Econometrics, forthcoming.
</p>

<hr>
<h2 id='BDGLmix'>Efron Bayesian Deconvolution Estimator for Gaussian Mixtures</h2><span id='topic+BDGLmix'></span>

<h3>Description</h3>

<p>Efron (2016, 2019) penalized logspline density estimator for Gaussian
mixture model g-modeling.  Returns an object of class GLmix to facilitate
prediction compatible with Kiefer-Wolfowitz GLmix  estimation.  In particular
percentile confidence intervals can be constructed based on posterior quantiles.
Assumes homoscedastic standard Gaussian noise, for the moment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BDGLmix(y, T = 300, sigma = 1, df = 5, c0 = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BDGLmix_+3A_y">y</code></td>
<td>
<p>Data: Sample Observations</p>
</td></tr>
<tr><td><code id="BDGLmix_+3A_t">T</code></td>
<td>
<p>Undata: Grid Values defaults equal spacing of with T bins, when T is
a scalar</p>
</td></tr>
<tr><td><code id="BDGLmix_+3A_sigma">sigma</code></td>
<td>
<p>scale parameter of the Gaussian noise, may take vector value of 
length(y)</p>
</td></tr>
<tr><td><code id="BDGLmix_+3A_df">df</code></td>
<td>
<p>degrees of freedom of the natural spline basis</p>
</td></tr>
<tr><td><code id="BDGLmix_+3A_c0">c0</code></td>
<td>
<p>penalty parameter for the Euclidean norm penalty.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class GLmix, density with components: 
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>points of  evaluation on the domain of the density</p>
</td></tr> 
<tr><td><code>y</code></td>
<td>
<p>estimated function values at these points of the mixing density</p>
</td></tr> 
<tr><td><code>sigma</code></td>
<td>
<p>returns a sigma = 1 for compatibility with GLmix</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Adapted from a similar implementation in the R package deconvolveR of
Narasimhan and Efron.
</p>


<h3>References</h3>

<p>Efron, B. (2016) Empirical Bayes deconvolution estimates,
Biometrika, 103, 1â€“20, 
Efron, B. (2019) Bayes, Oracle Bayes and Empirical Bayes,  
Statistical Science, 34, 177-201.
</p>

<hr>
<h2 id='Bmix'>Binomial mixture estimation via Kiefer Wolfowitz MLE</h2><span id='topic+Bmix'></span>

<h3>Description</h3>

<p>Interior point solution of Kiefer-Wolfowitz NPMLE for mixture of binomials
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Bmix(x, k, v = 300, collapse = TRUE, weights = NULL, unique = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Bmix_+3A_x">x</code></td>
<td>
<p>Count of &quot;successes&quot; for binomial observations</p>
</td></tr>
<tr><td><code id="Bmix_+3A_k">k</code></td>
<td>
<p>Number of trials for binomial observations</p>
</td></tr>
<tr><td><code id="Bmix_+3A_v">v</code></td>
<td>
<p>Grid Values for the mixing distribution defaults to equal
spacing of length v on [eps, 1- eps], if v is scalar.</p>
</td></tr>
<tr><td><code id="Bmix_+3A_collapse">collapse</code></td>
<td>
<p>Collapse observations into cell counts.</p>
</td></tr>
<tr><td><code id="Bmix_+3A_weights">weights</code></td>
<td>
<p>replicate weights for x obervations, should sum to 1</p>
</td></tr>
<tr><td><code id="Bmix_+3A_unique">unique</code></td>
<td>
<p>option to check unique of reported solution</p>
</td></tr>
<tr><td><code id="Bmix_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to KWDual to control optimization</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The predict method for <code>Bmix</code> objects will compute means, medians or
modes of the posterior according to whether the <code>Loss</code> argument is 2, 1
or 0, or posterior quantiles if <code>Loss</code> is in (0,1).
When the number of trials is small the NPMLE may be non-unique.  This happens
when there exists a vector <code class="reqn">v</code> in the unit simplex of <code class="reqn">R^m</code>  
such that <code class="reqn">Av = f</code> where <code class="reqn">f = (n_0/n , ... , n_k/n)</code> the observed frequencies, 
and A is the k by m matrix with typical element </p>
<p style="text-align: center;"><code class="reqn">C(k,x) p_j^x (1-p_j)^{k - x}.</code>
</p>

<p>If there exists such a solution, it follows that the maximal likelihood value is attained by any Ghat
such that </p>
<p style="text-align: center;"><code class="reqn">p_j = \int C(k,j) p^j (1-p)^{k-j} dGhat (p) = n_j/n,</code>
</p>
<p> for j = 0, ... , k.
There will be many such solutions, but by the Caratheodory theorem any one of them can be expressed
as a linear combination of no more than k extreme points of the constraint set.
In contrast, when there are no solutions
inside the simplex satisfying the equation, then the NPMLE is the unique projection onto the boundary
of that set.  To facilitate checking this condition if the <code>check</code> parameter is <code>TRUE</code>, the 
linear program is feasible and the <code>unique</code> component is returned as <code>TRUE</code> if
the program is infeasible, and <code>FALSE</code> is returned otherwise.  This check is restricted to
settings in which k is fixed, and <code>collapse</code> is <code>TRUE</code>.  See Robbins (1956, p 161) for
some further discussion of the binomial mixture model and a very clever alternative approach to
prediction.
</p>


<h3>Value</h3>

<p>An object of class density with components: 
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>grid midpoints of evaluation of the mixing density</p>
</td></tr> 
<tr><td><code>y</code></td>
<td>
<p>function values of the mixing density at x</p>
</td></tr> 
<tr><td><code>g</code></td>
<td>
<p>estimates of the mixture density at the distinct data values</p>
</td></tr> 
<tr><td><code>logLik</code></td>
<td>
<p>Log Likelihood value at the estimate</p>
</td></tr>
<tr><td><code>dy</code></td>
<td>
<p>Bayes rule estimates of binomial probabilities for distinct data values</p>
</td></tr>
<tr><td><code>unique</code></td>
<td>
<p>Flag indicating whether the solution is unique</p>
</td></tr>
<tr><td><code>status</code></td>
<td>
<p>exit code from the optimizer</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Koenker
</p>


<h3>References</h3>

<p>Kiefer, J. and J. Wolfowitz Consistency of the Maximum
Likelihood Estimator in the Presence of Infinitely Many Incidental
Parameters <em>Ann. Math. Statist</em>. 27, (1956), 887-906.
</p>
<p>Koenker, R and I. Mizera, (2013) &ldquo;Convex Optimization, Shape Constraints,
Compound Decisions, and Empirical Bayes Rules,&rdquo; <em>JASA</em>, 109, 674&ndash;685.
</p>
<p>Robbins, H. (1956) An Empirical Bayes Approach to Statistics, 3rd Berkeley
Symposium.
</p>
<p>Koenker, R. and J. Gu, (2017) REBayes: An R Package for Empirical Bayes Mixture Methods,
<em>Journal of Statistical Software</em>, 82, 1&ndash;26.
</p>

<hr>
<h2 id='BPmix'>Binomial mixtures with Poisson Trials via Kiefer Wolfowitz NPMLE</h2><span id='topic+BPmix'></span>

<h3>Description</h3>

<p>Interior point solution of Kiefer-Wolfowitz NPMLE for mixture of Poisson Binomials
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BPmix(x, m, v = 50, weights = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BPmix_+3A_x">x</code></td>
<td>
<p>Count of &quot;successes&quot; for binomial observations</p>
</td></tr>
<tr><td><code id="BPmix_+3A_m">m</code></td>
<td>
<p>Number of trials for binomial observations</p>
</td></tr>
<tr><td><code id="BPmix_+3A_v">v</code></td>
<td>
<p>Grid Values for the mixing distribution defaults to equal
spacing of length v on [eps, 1- eps], if v is scalar.</p>
</td></tr>
<tr><td><code id="BPmix_+3A_weights">weights</code></td>
<td>
<p>replicate weights for x obervations, should sum to 1</p>
</td></tr>
<tr><td><code id="BPmix_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to KWDual to control optimization</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The joint distribution of the probabilities of success and the number of trials
is estimated.  The grid specification for success probabilities is as for <code>Bmix</code>
whereas the grid for the Poisson rate parameters is currently the support of the 
observed trials.  There is no predict method as yet.  See <code>demo(BPmix1)</code>.
</p>


<h3>Value</h3>

<p>An object of class density with components: 
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>grid points of evaluation of the success probabilities</p>
</td></tr> 
<tr><td><code>u</code></td>
<td>
<p>grid points of evaluation of the Poisson rate for number of trials</p>
</td></tr> 
<tr><td><code>y</code></td>
<td>
<p>function values of the mixing density at (v,u)</p>
</td></tr> 
<tr><td><code>g</code></td>
<td>
<p>estimates of the mixture density at the distinct data values</p>
</td></tr> 
<tr><td><code>logLik</code></td>
<td>
<p>Log Likelihood value at the estimate</p>
</td></tr>
<tr><td><code>status</code></td>
<td>
<p>exit code from the optimizer</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Koenker
</p>


<h3>References</h3>

<p>Kiefer, J. and J. Wolfowitz Consistency of the Maximum
Likelihood Estimator in the Presence of Infinitely Many Incidental
Parameters <em>Ann. Math. Statist</em>. 27, (1956), 887-906.
</p>

<hr>
<h2 id='bwKW'>Bandwidth selection for KW smoothing</h2><span id='topic+bwKW'></span>

<h3>Description</h3>

<p>Bandwidth selection for KW smoothing
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bwKW(g, k = 1, minbw = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bwKW_+3A_g">g</code></td>
<td>
<p>KW fitted object</p>
</td></tr>
<tr><td><code id="bwKW_+3A_k">k</code></td>
<td>
<p>multiplicative fudge factor</p>
</td></tr>
<tr><td><code id="bwKW_+3A_minbw">minbw</code></td>
<td>
<p>minimum allowed value of bandwidth</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Koenker
</p>

<hr>
<h2 id='bwKW2'>Bandwidth selection for bivariate KW smoothing</h2><span id='topic+bwKW2'></span>

<h3>Description</h3>

<p>Bandwidth selection for bivariate KW smoothing
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bwKW2(g, k = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bwKW2_+3A_g">g</code></td>
<td>
<p>bivariate KW fitted object</p>
</td></tr>
<tr><td><code id="bwKW2_+3A_k">k</code></td>
<td>
<p>multiplicative fudge factor</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Koenker
</p>

<hr>
<h2 id='Cosslett'>Kiefer-Wolfowitz estimator for Cosslett (1983) estimator</h2><span id='topic+Cosslett'></span>

<h3>Description</h3>

<p>Kiefer-Wolfowitz-Cosslett  estimator for binary response model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Cosslett(x, y, v = 300, weights = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cosslett_+3A_x">x</code></td>
<td>
<p>is the observed utility difference between two choices, it would be
possible to extend this to make x a linear (index) function of some parameters</p>
</td></tr>
<tr><td><code id="Cosslett_+3A_y">y</code></td>
<td>
<p>is the binary outcome</p>
</td></tr>
<tr><td><code id="Cosslett_+3A_v">v</code></td>
<td>
<p>the unobserved utility difference taking values on a grid, by default
this grid is equally spaced with 300 distinct points, however it is known that
the mass points for the problem are located at the data points, x, so users may
wish to set <code>v = sort(x)</code> although if the sample size is large this can be
slow.</p>
</td></tr>
<tr><td><code id="Cosslett_+3A_weights">weights</code></td>
<td>
<p>replicate weights for x observations, should sum to 1</p>
</td></tr>
<tr><td><code id="Cosslett_+3A_...">...</code></td>
<td>
<p>optional parameters to be passed to KWDual to control optimization</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the primal form of the problem the pseudo log likelihood is:
</p>
<p style="text-align: center;"><code class="reqn">l(f|y) =  sum_i [ y_i \log \sum_j (I(v_j &lt;= x_i) * f_j) + 
		(1 - y_i) \log \sum_j (I(v_j &gt; x_i) * f_j) ]</code>
</p>

<p>as usual the implementation used here solves the corresponding dual problem.
Cumsum of the output y gives the CDF of the unobserved utility difference.
See the <code>demo(Cosslett1)</code>and  <code>demo(Cosslett2)</code> for illustrations
without any covariate, and <code>demo(Cosslett3)</code> for an illustration with a
covariate using profile likelihood.  This model is also known as current
status linear regression in the biostatistics literature, see e.g. Groeneboom
and Hendrickx (2016) for recent results and references.
</p>


<h3>Value</h3>

<p>an object of class density with the components:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>points of evaluation of the mixing density</p>
</td></tr> 
<tr><td><code>y</code></td>
<td>
<p>function values of the mixing density at x</p>
</td></tr> 
<tr><td><code>logL</code></td>
<td>
<p>log likelihood of estimated model</p>
</td></tr> 
<tr><td><code>status</code></td>
<td>
<p>exit code from the optimizer</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jiaying Gu and Roger Koenker
</p>


<h3>References</h3>

<p>Kiefer, J. and J. Wolfowitz (1956) Consistency of the Maximum
Likelihood Estimator in the Presence of Infinitely Many Incidental
Parameters, <em>Ann. Math. Statist</em>, 27, 887-906.
</p>
<p>Cosslett, S. (1983) Distribution Free Maximum Likelihood Estimator of the 
Binary Choice Model, <em>Econometrica</em>, 51, 765-782.
</p>
<p>Groeneboom, P. and K. Hendrickx (2016) Current Status Linear Regression,
preprint available from <a href="https://arxiv.org/abs/1601.00202">https://arxiv.org/abs/1601.00202</a>.
</p>

<hr>
<h2 id='dhuber'>Huber density function</h2><span id='topic+dhuber'></span>

<h3>Description</h3>

<p>Huber (1964) least favorable density for the Gaussian contamination model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dhuber(x, mu = 0, sigma = 1, k = 1.642, heps = hubereps(k))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dhuber_+3A_x">x</code></td>
<td>
<p>points to evaluate the density</p>
</td></tr>
<tr><td><code id="dhuber_+3A_mu">mu</code></td>
<td>
<p>center of symmetry of the density</p>
</td></tr>
<tr><td><code id="dhuber_+3A_sigma">sigma</code></td>
<td>
<p>standard deviation of the nominal Gaussian model</p>
</td></tr>
<tr><td><code id="dhuber_+3A_k">k</code></td>
<td>
<p>Huber k value</p>
</td></tr>
<tr><td><code id="dhuber_+3A_heps">heps</code></td>
<td>
<p>Huber epsilson value</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of density values
</p>


<h3>Author(s)</h3>

<p>R. Koenker
</p>

<hr>
<h2 id='Finv'>Function inversion</h2><span id='topic+Finv'></span>

<h3>Description</h3>

<p>Given a function, F(x, ...), and a scalar y, find
x such that F(x, ...) = y.  Note that there is no
checking for the monotonicity of F wrt to x, or that
the interval specified is appropriate to the problem.
Such fine points are entirely the responsibility of
the user/abuser.  If the interval specified doesn't
contain a root some automatic attempt to expand the
interval will be made.  Originally intended for use 
with F as <code>ThreshFDR</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Finv(y, F, interval = c(0, 1), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Finv_+3A_y">y</code></td>
<td>
<p>the scalar at which to evaluate the inverse</p>
</td></tr>
<tr><td><code id="Finv_+3A_f">F</code></td>
<td>
<p>the function</p>
</td></tr>
<tr><td><code id="Finv_+3A_interval">interval</code></td>
<td>
<p>the domain within which to begin looking</p>
</td></tr>
<tr><td><code id="Finv_+3A_...">...</code></td>
<td>
<p>other arguments for the function F</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Koenker
</p>

<hr>
<h2 id='flies'>Medfly Data</h2><span id='topic+flies'></span>

<h3>Description</h3>

<p>Medfly data from the Carey et al (1992) experiment.  
There are 1,203,646 uncensored survival times!
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flies
</code></pre>


<h3>Format</h3>

<p>A data frame with 19072 observations on the following 17 variables.
</p>

<dl>
<dt><code>age</code></dt><dd><p>age at death in days</p>
</dd>
<dt><code>num</code></dt><dd><p>frequency count of age at death</p>
</dd>
<dt><code>prcurr</code></dt><dd><p>current proportion male</p>
</dd>
<dt><code>current</code></dt><dd><p>current density</p>
</dd>
<dt><code>cohort</code></dt><dd><p>cohort/pupal batch</p>
</dd>
<dt><code>size</code></dt><dd><p>pupal size</p>
</dd>
<dt><code>cage</code></dt><dd><p>cage number</p>
</dd>
<dt><code>female</code></dt><dd><p>female = 1</p>
</dd>
<dt><code>cumul</code></dt><dd><p>cumulative density</p>
</dd>
<dt><code>prcumu</code></dt><dd><p>cumulative proportion male</p>
</dd>
<dt><code>begin</code></dt><dd><p>initial cage density</p>
</dd>
<dt><code>prbegin</code></dt><dd><p>initial proportion mail</p>
</dd>
<dt><code>size4</code></dt><dd><p>size group 4</p>
</dd>
<dt><code>size5</code></dt><dd><p>size group 5</p>
</dd>
<dt><code>size6</code></dt><dd><p>size group 6</p>
</dd>
<dt><code>size7</code></dt><dd><p>size group 7</p>
</dd>
<dt><code>size8</code></dt><dd><p>size group 8</p>
</dd>
</dl>



<h3>Details</h3>

<p>Quoting from Carey et al (1992) &ldquo;...Pupae
were sorted into one of five size classes using a pupal sorter.  This
enabled size dimorphism to be eliminated as a potential source of sex-specific
mortality differences.  Approximately, 7,200 medflies (both sexes) of a given
size class were maintained in each of 167 mesh covered, 15 cm by 60 cm
by 90 cm aluminum cages.  Adults were given a diet of sugar and water,
ad libitum,  and each day dead flies were removed, counted and their sex
determined ...&rdquo;
</p>


<h3>References</h3>

<p>Carey, J.R., Liedo, P.,  Orozco, D.  and  Vaupel, J.W.  (1992)
Slowing of mortality rates at older ages in large Medfly cohorts,
<em>Science,</em> 258, 457-61.
</p>
<p>Koenker, R. and O. Geling (2001)  Reappraising Medfly Longevity:
A Quantile Regression Survival Analysis, <em>J. Am. Stat. Assoc</em>,
96, 458-468.
</p>
<p>Koenker, R. and  Jiaying Gu, (2013) &ldquo;Frailty, Profile Likelihood and Medfly 
Mortality,&rdquo; <em> Contemporary Developments in Statistical Theory: 
A Festschrift for Hira Lal Koul</em>, S.N. Lahiri,  A. Schick,  Ashis Sengupta, 
and T.N. Sriram, (eds.), Springer.
</p>

<hr>
<h2 id='Gammamix'>NPMLE for Gamma Mixtures</h2><span id='topic+Gammamix'></span>

<h3>Description</h3>

<p>A Kiefer-Wolfowitz MLE for Gamma mixture models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Gammamix(x, v = 300, shape = 1, weights = NULL, eps = 1e-10, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gammamix_+3A_x">x</code></td>
<td>
<p>vector of observed variances</p>
</td></tr>
<tr><td><code id="Gammamix_+3A_v">v</code></td>
<td>
<p>A vector of bin boundaries, if scalar then v equally spaced bins
are constructed</p>
</td></tr>
<tr><td><code id="Gammamix_+3A_shape">shape</code></td>
<td>
<p>vector of shape parameters corresponding to x</p>
</td></tr>
<tr><td><code id="Gammamix_+3A_weights">weights</code></td>
<td>
<p>replicate weights for x obervations, should sum to 1</p>
</td></tr>
<tr><td><code id="Gammamix_+3A_eps">eps</code></td>
<td>
<p>tolerance for default gridding</p>
</td></tr>
<tr><td><code id="Gammamix_+3A_...">...</code></td>
<td>
<p>optional parameters passed to KWDual to control optimization</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>density</code> with components:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>midpoints of the bin boundaries</p>
</td></tr> 
<tr><td><code>y</code></td>
<td>
<p>estimated function values of the mixing density</p>
</td></tr> 
<tr><td><code>g</code></td>
<td>
<p>function values of the mixture density at the observed x's.</p>
</td></tr> 
<tr><td><code>logLik</code></td>
<td>
<p>the value of the log likelihood at the solution</p>
</td></tr> 
<tr><td><code>dy</code></td>
<td>
<p>Bayes rule estimates of </p>
</td></tr> 
<tr><td><code>status</code></td>
<td>
<p>the Mosek convergence status.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>J. Gu and R. Koenker
</p>


<h3>References</h3>

<p>Gu J. and R. Koenker (2014) Unobserved heterogeneity in 
income dynamics: an empirical Bayes perspective, <em>JBES</em>, 35, 1-16.
</p>
<p>Koenker, R. and J. Gu, (2017) REBayes: An R Package for Empirical Bayes Mixture Methods,
<em>Journal of Statistical Software</em>, 82, 1&ndash;26.
</p>


<h3>See Also</h3>

<p>Gammamix for a general implementation for Gamma mixtures
</p>

<hr>
<h2 id='GLmix'>Kiefer-Wolfowitz NPMLE for Gaussian Location Mixtures</h2><span id='topic+GLmix'></span>

<h3>Description</h3>

<p>Kiefer Wolfowitz Nonparametric MLE for Gaussian Location Mixtures
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GLmix(x, v = 300, sigma = 1, hist = FALSE, histm = 300, weights = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GLmix_+3A_x">x</code></td>
<td>
<p>Data: Sample Observations</p>
</td></tr>
<tr><td><code id="GLmix_+3A_v">v</code></td>
<td>
<p>Undata: Grid Values defaults equal spacing of with v bins, when v is
a scalar</p>
</td></tr>
<tr><td><code id="GLmix_+3A_sigma">sigma</code></td>
<td>
<p>scale parameter of the Gaussian noise, may take vector values
of length(x)</p>
</td></tr>
<tr><td><code id="GLmix_+3A_hist">hist</code></td>
<td>
<p>If TRUE then aggregate x to histogram bins, when sigma is vector
valued this option is inappropriate unless there are only a small number of
distinct sigma values.</p>
</td></tr>
<tr><td><code id="GLmix_+3A_histm">histm</code></td>
<td>
<p>histogram bin boundaries, equally spacing with <code>histm</code> 
bins when  scalar.</p>
</td></tr>
<tr><td><code id="GLmix_+3A_weights">weights</code></td>
<td>
<p>replicate weights for x obervations, should sum to 1</p>
</td></tr>
<tr><td><code id="GLmix_+3A_...">...</code></td>
<td>
<p>other parameters to pass to KWDual to control optimization</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Kiefer Wolfowitz MLE as proposed by Jiang and Zhang for
the Gaussian compound decision problem.  The histogram option is intended
for large problems, say n &gt; 1000, where reducing the sample size dimension
is desirable. When <code>sigma</code> is heterogeneous and <code>hist = TRUE</code> the
procedure tries to do separate histogram binning for distinct values of
<code>sigma</code>, however this is only feasible when there are only a small
number of distinct <code>sigma</code>. By default the grid for the binning is
equally spaced on the support of the data. This function does the normal
convolution problem, for gamma mixtures of variances see <code>GVmix</code>, or
for mixtures of both means and variances <code>TLVmix</code>.  
</p>
<p>The predict method for <code>GLmix</code> objects will compute means, medians or
modes of the posterior according to whether the <code>Loss</code> argument is 2, 1
or 0, or posterior quantiles if <code>Loss</code> is in (0,1).
</p>


<h3>Value</h3>

<p>An object of class density with components: 
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>points of  evaluation on the domain of the density</p>
</td></tr> 
<tr><td><code>y</code></td>
<td>
<p>estimated function values at the points v, the mixing density</p>
</td></tr> 
<tr><td><code>g</code></td>
<td>
<p>the estimated mixture density function values at x</p>
</td></tr> 
<tr><td><code>logLik</code></td>
<td>
<p>Log likelihood value at the proposed solution</p>
</td></tr> 
<tr><td><code>dy</code></td>
<td>
<p>prediction of mean parameters for each observed x value via Bayes Rule</p>
</td></tr> 
<tr><td><code>status</code></td>
<td>
<p>exit code from the optimizer</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Roger Koenker
</p>


<h3>References</h3>

<p>Kiefer, J. and J. Wolfowitz Consistency of the Maximum
Likelihood Estimator in the Presence of Infinitely Many Incidental
Parameters <em>Ann. Math. Statist</em>.  Volume 27, Number 4 (1956), 887-906.
</p>
<p>Jiang, Wenhua and Cun-Hui Zhang General maximum likelihood empirical Bayes
estimation of normal means <em>Ann. Statist.</em>, Volume 37, Number 4 (2009),
1647-1684.
</p>
<p>Koenker, R and I. Mizera, (2013) &ldquo;Convex Optimization, Shape Constraints,
Compound Decisions, and Empirical Bayes Rules,&rdquo; <em>JASA</em>, 109, 674&ndash;685.
</p>
<p>Koenker, R. and J. Gu, (2017) REBayes: An R Package for Empirical Bayes Mixture Methods,
<em>Journal of Statistical Software</em>, 82, 1&ndash;26.
</p>

<hr>
<h2 id='GLVmix'>NPMLE of Gaussian Location-Scale Mixture Model</h2><span id='topic+GLVmix'></span>

<h3>Description</h3>

<p>A Kiefer-Wolfowitz procedure for ML estimation of a Gaussian model with
possibly dependent mean and variance components. This version differs from
<code>WGLVmix</code> in that it doesn't assume the data is in longitudinal form.
This version assumes a general bivariate distribution for the mixing
distribution. The defaults use a rather coarse bivariate gridding.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GLVmix(t, s, m, u = 30, v = 30, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GLVmix_+3A_t">t</code></td>
<td>
<p>A vector of location estimates</p>
</td></tr>
<tr><td><code id="GLVmix_+3A_s">s</code></td>
<td>
<p>A vector of variance estimates</p>
</td></tr>
<tr><td><code id="GLVmix_+3A_m">m</code></td>
<td>
<p>A vector of sample sizes of the same length as t and s, or if scalar
a common sample size length</p>
</td></tr>
<tr><td><code id="GLVmix_+3A_u">u</code></td>
<td>
<p>A vector of bin boundaries for the location effects</p>
</td></tr>
<tr><td><code id="GLVmix_+3A_v">v</code></td>
<td>
<p>A vector of bin boundaries for the variance effects</p>
</td></tr>
<tr><td><code id="GLVmix_+3A_...">...</code></td>
<td>
<p>optional parameters to be passed to KWDual to control optimization</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list consisting of the following components:
</p>
<table>
<tr><td><code>u</code></td>
<td>
<p>midpoints of mean bin boundaries</p>
</td></tr>
<tr><td><code>v</code></td>
<td>
<p>midpoints of variance bin boundaries</p>
</td></tr>
<tr><td><code>fuv</code></td>
<td>
<p>the function values of the mixing density.</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>log likelihood value for mean problem</p>
</td></tr>
<tr><td><code>du</code></td>
<td>
<p>Bayes rule estimate of the mixing density means.</p>
</td></tr>
<tr><td><code>dv</code></td>
<td>
<p>Bayes rule estimate of the mixing density variances.</p>
</td></tr>
<tr><td><code>A</code></td>
<td>
<p>Constraint matrix</p>
</td></tr>
<tr><td><code>status</code></td>
<td>
<p>Mosek convergence status</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Koenker and J. Gu
</p>


<h3>References</h3>

<p>Gu, J. and R. Koenker (2014) Heterogeneous Income Dynamics: An
Empirical Bayes Perspective, <em>JBES</em>,35, 1-16.
</p>
<p>Koenker, R. and J. Gu, (2017) REBayes: An R Package for Empirical Bayes Mixture Methods,
<em>Journal of Statistical Software</em>, 82, 1&ndash;26.
</p>


<h3>See Also</h3>

<p>WTLVmix for an implementation assuming independent heterogeneity, and WGLVmix
for a version that requires access to a full longitudinal data structure.
</p>

<hr>
<h2 id='Gompertzmix'>NPMLE for Gompertz Mixtures</h2><span id='topic+Gompertzmix'></span>

<h3>Description</h3>

<p>Kiefer-Wolfowitz NPMLE for Gompertz Mixtures of scale parameter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Gompertzmix(
  x,
  v = 300,
  u = 300,
  alpha,
  theta,
  hist = FALSE,
  weights = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gompertzmix_+3A_x">x</code></td>
<td>
<p>Survival times</p>
</td></tr>
<tr><td><code id="Gompertzmix_+3A_v">v</code></td>
<td>
<p>Grid values for mixing distribution</p>
</td></tr>
<tr><td><code id="Gompertzmix_+3A_u">u</code></td>
<td>
<p>Grid values for mixing distribution</p>
</td></tr>
<tr><td><code id="Gompertzmix_+3A_alpha">alpha</code></td>
<td>
<p>Shape parameter for Gompertz distribution</p>
</td></tr>
<tr><td><code id="Gompertzmix_+3A_theta">theta</code></td>
<td>
<p>Scale parameter for Gompertz Distribution</p>
</td></tr>
<tr><td><code id="Gompertzmix_+3A_hist">hist</code></td>
<td>
<p>If TRUE aggregate to histogram counts</p>
</td></tr>
<tr><td><code id="Gompertzmix_+3A_weights">weights</code></td>
<td>
<p>replicate weights for x obervations, should sum to 1</p>
</td></tr>
<tr><td><code id="Gompertzmix_+3A_...">...</code></td>
<td>
<p>optional parameters passed to KWDual to control optimization</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Kiefer Wolfowitz NPMLE density estimation for Gompertz scale mixtures. The
histogram option is intended for relatively large problems, say n &gt; 1000,
where reducing the sample size dimension is desirable. By default the grid
for the binning is equally spaced on the support of the data. 
Parameterization: f(t|alpha,theta,v) = theta * exp(v) * exp(alpha * t) * 
exp(-(theta/alpha) * exp(v) * (exp(alpha*t)-1))
</p>


<h3>Value</h3>

<p>An object of class density with components 
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>points of evaluation on the domain of the density</p>
</td></tr> 
<tr><td><code>y</code></td>
<td>
<p>estimated function values at the points x, the mixing density</p>
</td></tr> 
<tr><td><code>logLik</code></td>
<td>
<p>Log likelihood value at the proposed solution</p>
</td></tr> 
<tr><td><code>dy</code></td>
<td>
<p>Bayes rule estimates of theta at observed x</p>
</td></tr> 
<tr><td><code>status</code></td>
<td>
<p>exit code from the optimizer</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Roger Koenker and Jiaying Gu
</p>


<h3>References</h3>

<p>Kiefer, J. and J. Wolfowitz Consistency of the Maximum
Likelihood Estimator in the Presence of Infinitely Many Incidental
Parameters <em>Ann. Math. Statist</em>. Volume 27, Number 4 (1956), 887-906.
</p>


<h3>See Also</h3>

<p><code>Weibullmix</code>
</p>

<hr>
<h2 id='Gosset'>Gosset Criminal Finger Data</h2><span id='topic+Gosset'></span>

<h3>Description</h3>

<p>This data was generated by dithering the cell counts
in the <code>crimtab</code> available in the base <span class="pkg">stats</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Gosset
</code></pre>


<h3>Format</h3>

<p>A data frame with 3000 observations on 2 variables.
</p>

<dl>
<dt><code>LMFinger</code></dt><dd><p>Length of Left Middle Finger (cm).</p>
</dd>
<dt><code>Height</code></dt><dd><p>Height (cm)</p>
</dd>
</dl>



<h3>Source</h3>

<p>see the man page for <code>crimtab</code>
</p>

<hr>
<h2 id='Guvenen'>Annual Increments in Log Income</h2><span id='topic+Guvenen'></span>

<h3>Description</h3>

<p>Kernel density estimates of the log density of annual increments in
log income for U.S. individuals over the period 1994-2013, as estimated by <cite>Guvenen</cite>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Guvenen
</code></pre>


<h3>Format</h3>

<p>A data frame with 279 observations on two variables.
</p>

<dl>
<dt><code>earnings</code></dt><dd><p>annual increment in log income</p>
</dd>
<dt><code>logdensity</code></dt><dd><p>estimated log density values</p>
</dd>
</dl>



<h3>Source</h3>

<p>Fatih Guvenen, Fatih Karahan, Serdar Ozkan and Jae Song, (2016)
What Do Data on Millions of U.S. Workers Reveal about Life-Cycle Earnings Dynamics?
<a href="https://www.nber.org/system/files/working_papers/w20913/w20913.pdf">https://www.nber.org/system/files/working_papers/w20913/w20913.pdf</a>
</p>

<hr>
<h2 id='GVmix'>NPMLE for Gaussian Variance Heterogeneity</h2><span id='topic+GVmix'></span>

<h3>Description</h3>

<p>A Kiefer-Wolfowitz MLE for Gaussian models with independent variances.  This
can be viewed as a general form for <code class="reqn">\chi^2</code> mixtures, see <code>Gammamix</code>
for a more general form for Gamma mixtures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GVmix(x, m, v = 300, weights = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GVmix_+3A_x">x</code></td>
<td>
<p>vector of observed variances</p>
</td></tr>
<tr><td><code id="GVmix_+3A_m">m</code></td>
<td>
<p>vector of sample sizes corresponding to x</p>
</td></tr>
<tr><td><code id="GVmix_+3A_v">v</code></td>
<td>
<p>A vector of bin boundaries, if scalar then v equally spaced bins
are constructed</p>
</td></tr>
<tr><td><code id="GVmix_+3A_weights">weights</code></td>
<td>
<p>replicate weights for x obervations, should sum to 1</p>
</td></tr>
<tr><td><code id="GVmix_+3A_...">...</code></td>
<td>
<p>optional parameters passed to KWDual to control optimization</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>density</code> with components:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>midpoints of the bin boundaries</p>
</td></tr> 
<tr><td><code>y</code></td>
<td>
<p>estimated function values of the mixing density</p>
</td></tr> 
<tr><td><code>g</code></td>
<td>
<p>function values of the mixture density at the observed x's.</p>
</td></tr> 
<tr><td><code>logLik</code></td>
<td>
<p>the value of the log likelihood at the solution</p>
</td></tr> 
<tr><td><code>dy</code></td>
<td>
<p>Bayes rule estimates of </p>
</td></tr> 
<tr><td><code>status</code></td>
<td>
<p>the Mosek convergence status.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Koenker
</p>


<h3>References</h3>

<p>Koenker, R and I. Mizera, (2013) &ldquo;Convex Optimization, Shape Constraints,
Compound Decisions, and Empirical Bayes Rules,&rdquo; <em>JASA</em>, 109, 674&ndash;685.
</p>
<p>Gu J. and R. Koenker (2014) Unobserved heterogeneity in 
income dynamics: an empirical Bayes perspective, <em>JBES</em>, 35, 1-16. 
</p>
<p>Koenker, R. and J. Gu, (2017) REBayes: An R Package for Empirical Bayes Mixture Methods,
<em>Journal of Statistical Software</em>, 82, 1&ndash;26.
</p>


<h3>See Also</h3>

<p>Gammamix for a general implementation for Gamma mixtures
</p>

<hr>
<h2 id='HLmix'>Kiefer-Wolfowitz NPMLE for Huber Location Mixtures</h2><span id='topic+HLmix'></span>

<h3>Description</h3>

<p>Kiefer Wolfowitz Nonparametric MLE for Huber Location Mixtures
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HLmix(x, v = 300, sigma = 1, k = 1.345, heps = hubereps(k), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HLmix_+3A_x">x</code></td>
<td>
<p>Data: Sample Observations</p>
</td></tr>
<tr><td><code id="HLmix_+3A_v">v</code></td>
<td>
<p>Undata: Grid Values defaults equal spacing of with v bins, when v is
a scalar</p>
</td></tr>
<tr><td><code id="HLmix_+3A_sigma">sigma</code></td>
<td>
<p>scale parameter of the Gaussian noise, may take vector values
of length(x)</p>
</td></tr>
<tr><td><code id="HLmix_+3A_k">k</code></td>
<td>
<p>Huber k value</p>
</td></tr>
<tr><td><code id="HLmix_+3A_heps">heps</code></td>
<td>
<p>Huber epsilon contamination value, should match k, by default
this is automatically enforced.</p>
</td></tr>
<tr><td><code id="HLmix_+3A_...">...</code></td>
<td>
<p>other parameters to pass to KWDual to control optimization</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Kiefer Wolfowitz NPMLE for location mixtures with Huber (1964) base density
The Huber <code>k</code> specifies the point at which the influence function of
the Huber M-estimator kinks.  
The predict method for <code>HLmix</code> objects compute means, medians or
modes of the posterior according to whether the <code>Loss</code> argument is 2, 1
or 0, or posterior quantiles if <code>Loss</code> is in (0,1).
</p>


<h3>Value</h3>

<p>An object of class density with components: 
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>points of  evaluation on the domain of the density</p>
</td></tr> 
<tr><td><code>y</code></td>
<td>
<p>estimated function values at the points v, the mixing density</p>
</td></tr> 
<tr><td><code>g</code></td>
<td>
<p>marginal density values</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>log likelihood</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>sigma</p>
</td></tr>
<tr><td><code>dy</code></td>
<td>
<p>posterior means at the observed <code>x</code> values</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>Huber k</p>
</td></tr>
<tr><td><code>heps</code></td>
<td>
<p>Huber epsilon</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Roger Koenker
</p>

<hr>
<h2 id='hubereps'>Huber epsilon</h2><span id='topic+hubereps'></span>

<h3>Description</h3>

<p>Find the epsilon corresponding to a Huber k value
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hubereps(k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hubereps_+3A_k">k</code></td>
<td>
<p>Huber k value</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Huber epsilon value
</p>


<h3>Author(s)</h3>

<p>R. Koenker
</p>

<hr>
<h2 id='KW2smooth'>Smooth a bivariate Kiefer-Wolfowitz NPMLE</h2><span id='topic+KW2smooth'></span>

<h3>Description</h3>

<p>Smooth a bivariate Kiefer-Wolfowitz NPMLE
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KW2smooth(f, bw = NULL, k = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KW2smooth_+3A_f">f</code></td>
<td>
<p>bivariate KW fitted object as from GLVmix</p>
</td></tr>
<tr><td><code id="KW2smooth_+3A_bw">bw</code></td>
<td>
<p>bandwidth defaults to bwKW2(f),</p>
</td></tr>
<tr><td><code id="KW2smooth_+3A_k">k</code></td>
<td>
<p>kernel 1 for Gaussian, 2 for biweight, 3 for triweight</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Koenker
</p>

<hr>
<h2 id='KWDual'>Dual optimization for Kiefer-Wolfowitz problems</h2><span id='topic+KWDual'></span>

<h3>Description</h3>

<p>Interface function for calls to optimizer from various REBayes functions
There is currently only one option for the optimization that based on  Mosek. 
It relies on the <span class="pkg">Rmosek</span> interface to R see installation instructions in
the Readme file in the inst directory of this package.  This version of the function
is intended to work with versions of Mosek after 7.0.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KWDual(A, d, w, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KWDual_+3A_a">A</code></td>
<td>
<p>Linear constraint matrix</p>
</td></tr>
<tr><td><code id="KWDual_+3A_d">d</code></td>
<td>
<p>constraint vector</p>
</td></tr>
<tr><td><code id="KWDual_+3A_w">w</code></td>
<td>
<p>weights for <code>x</code> should sum to one.</p>
</td></tr>
<tr><td><code id="KWDual_+3A_...">...</code></td>
<td>
<p>other parameters passed to control optimization:  These may
include <code>rtol</code> the relative tolerance for dual gap convergence criterion,
<code>verb</code> to control verbosity desired from mosek, <code>verb = 0</code> is quiet,
<code>verb = 5</code> produces a fairly detailed iteration log,
<code>control</code> is a control list consisting of sublists <code>iparam</code>,
<code>dparam</code>, and <code>sparam</code>, containing elements of various mosek
control parameters.  See the Rmosek and Mosek manuals for further details.
A prime example is <code>rtol</code> which should eventually be deprecated and
folded into <code>control</code>, but will persist for a while for compatibility
reasons.  The default for <code>rtol</code> is 1e-6, but in some cases it is
desirable to tighten this, say to 1e-10.  Another example that motivated the introduction of
<code>control</code> would be <code>control = list(iparam = list(num_threads =
1))</code>, which forces Mosek to use a single threaded process.  The default
allows Mosek to uses multiple threads (cores) if available, which is
generally desirable, but may have unintended (undesirable) consequences when running
simulations on clusters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with components: </p>
<table>
<tr><td><code>f</code></td>
<td>
<p>dual solution vector, the
mixing density</p>
</td></tr> <tr><td><code>g</code></td>
<td>
<p>primal solution vector, the mixture density
evaluated at the data points</p>
</td></tr> <tr><td><code>logLik</code></td>
<td>
<p>log likelihood</p>
</td></tr>
<tr><td><code>status</code></td>
<td>
<p>return status from Mosek</p>
</td></tr></table>
<p>.  Mosek termination messages are
treated as warnings from an R perspective since solutions producing, for example,
MSK_RES_TRM_STALL: The optimizer is terminated due to slow progress, may still
provide a satisfactory solution, especially when the return status variable is
&quot;optimal&quot;.
</p>


<h3>Author(s)</h3>

<p>R. Koenker
</p>


<h3>References</h3>

<p>Koenker, R and I. Mizera, (2013) &ldquo;Convex Optimization, Shape Constraints,
Compound Decisions, and Empirical Bayes Rules,&rdquo; <em>JASA</em>, 109, 674&ndash;685.
</p>
<p>Mosek Aps (2015) Users Guide to the R-to-Mosek Optimization Interface, 
<a href="https://docs.mosek.com/8.1/rmosek/index.html">https://docs.mosek.com/8.1/rmosek/index.html</a>.  
</p>
<p>Koenker, R. and J. Gu, (2017) REBayes: An R Package for Empirical Bayes Mixture Methods,
<em>Journal of Statistical Software</em>, 82, 1&ndash;26.
</p>

<hr>
<h2 id='KWPrimal'>Primal optimization for Kiefer-Wolfowitz problems</h2><span id='topic+KWPrimal'></span>

<h3>Description</h3>

<p>Interface function for calls to optimizer from various REBayes functions
There is currently only one option for the optimization that based on  Mosek. 
It relies on the <span class="pkg">Rmosek</span> interface to R see installation instructions in
the Readme file in the inst directory of this package.  This version of the function
works only with versions of Mosek 9.0.  This is an experimental alternative to the
main KWDual which is the usual interface from fitting functions to Mosek, caveat emptor..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KWPrimal(A, d, w, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KWPrimal_+3A_a">A</code></td>
<td>
<p>Linear constraint matrix</p>
</td></tr>
<tr><td><code id="KWPrimal_+3A_d">d</code></td>
<td>
<p>constraint vector</p>
</td></tr>
<tr><td><code id="KWPrimal_+3A_w">w</code></td>
<td>
<p>weights for <code>x</code> should sum to one.</p>
</td></tr>
<tr><td><code id="KWPrimal_+3A_...">...</code></td>
<td>
<p>other parameters passed to control optimization:  These may
include <code>rtol</code> the relative tolerance for dual gap convergence criterion,
<code>verb</code> to control verbosity desired from mosek, <code>verb = 0</code> is quiet,
<code>verb = 5</code> produces a fairly detailed iteration log,
<code>control</code> is a control list consisting of sublists <code>iparam</code>,
<code>dparam</code>, and <code>sparam</code>, containing elements of various mosek
control parameters.  See the Rmosek and Mosek manuals for further details.
A prime example is <code>rtol</code> which should eventually be deprecated and
folded into <code>control</code>, but will persist for a while for compatibility
reasons.  The default for <code>rtol</code> is 1e-6, but in some cases it is
desirable to tighten this, say to 1e-10.  Another example that motivated the introduction of
<code>control</code> would be <code>control = list(iparam = list(num_threads =
1))</code>, which forces Mosek to use a single threaded process.  The default
allows Mosek to uses multiple threads (cores) if available, which is
generally desirable, but may have unintended (undesirable) consequences when running
simulations on clusters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with components: </p>
<table>
<tr><td><code>f</code></td>
<td>
<p>primal solution vector, the
mixing density</p>
</td></tr> <tr><td><code>g</code></td>
<td>
<p>the mixture density
evaluated at the data points</p>
</td></tr> <tr><td><code>logLik</code></td>
<td>
<p>log likelihood</p>
</td></tr>
<tr><td><code>status</code></td>
<td>
<p>return status from Mosek</p>
</td></tr></table>
<p>.  Mosek termination messages are
treated as warnings from an R perspective since solutions producing, for example,
MSK_RES_TRM_STALL: The optimizer is terminated due to slow progress, may still
provide a satisfactory solution, especially when the return status variable is
&quot;optimal&quot;.
</p>


<h3>Author(s)</h3>

<p>R. Koenker
</p>


<h3>References</h3>

<p>Koenker, R and I. Mizera, (2013) &ldquo;Convex Optimization, Shape Constraints,
Compound Decisions, and Empirical Bayes Rules,&rdquo; <em>JASA</em>, 109, 674&ndash;685.
</p>
<p>Mosek Aps (2015) Users Guide to the R-to-Mosek Optimization Interface, 
<a href="https://docs.mosek.com/8.1/rmosek/index.html">https://docs.mosek.com/8.1/rmosek/index.html</a>.  
</p>
<p>Koenker, R. and J. Gu, (2017) REBayes: An R Package for Empirical Bayes Mixture Methods,
<em>Journal of Statistical Software</em>, 82, 1&ndash;26.
</p>

<hr>
<h2 id='KWsmooth'>Smooth a Kiefer-Wolfowitz NPMLE</h2><span id='topic+KWsmooth'></span>

<h3>Description</h3>

<p>Smooth a Kiefer-Wolfowitz NPMLE
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KWsmooth(f, bw = NULL, k = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KWsmooth_+3A_f">f</code></td>
<td>
<p>KW fitted object</p>
</td></tr>
<tr><td><code id="KWsmooth_+3A_bw">bw</code></td>
<td>
<p>bandwidth defaults to 2 * mad</p>
</td></tr>
<tr><td><code id="KWsmooth_+3A_k">k</code></td>
<td>
<p>kernel 2 for biweight, 3 for triweight</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Koenker
</p>

<hr>
<h2 id='L1norm'>L1norm for piecewise linear functions</h2><span id='topic+L1norm'></span>

<h3>Description</h3>

<p>Intended to compute the L1norm of the difference between two distribution
functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>L1norm(F, G, eps = 1e-06)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="L1norm_+3A_f">F</code></td>
<td>
<p>A stepfunction</p>
</td></tr>
<tr><td><code id="L1norm_+3A_g">G</code></td>
<td>
<p>Another stepfunction</p>
</td></tr>
<tr><td><code id="L1norm_+3A_eps">eps</code></td>
<td>
<p>A tolerance parameter</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Both F and G should be of class <code>stepfun</code>, and they should be
non-defective distribution functions.  There are some tolerance issues in
checking whether both functions are proper distribution functions at the
extremes of their support.  For simulations it may be prudent to wrap
<code>L1norm</code> in <code>try</code>.
</p>


<h3>Value</h3>

<p>A real number.
</p>


<h3>Author(s)</h3>

<p>R. Koenker
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Make a random step (distribution) function with Gaussian knots
rstep &lt;- function(n){
        x &lt;- sort(rnorm(n))
        y &lt;- runif(n)
        y &lt;- c(0,cumsum(y/sum(y)))
        stepfun(x,y)
        }
F &lt;- rstep(20)
G &lt;- rstep(10)
S &lt;- L1norm(F,G)
plot(F,main = paste("||F - G|| = ", round(S,4)))
lines(G,col = 2)

</code></pre>

<hr>
<h2 id='Lfdr'>Local False Discovery Rate Estimation</h2><span id='topic+Lfdr'></span><span id='topic+Lfdr.GLVmix'></span><span id='topic+Lfdr.WGLVmix'></span><span id='topic+Lfdr.GLmix'></span>

<h3>Description</h3>

<p>A Generic function for estimation of Local FDR
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lfdr(G, ...)

## S3 method for class 'GLVmix'
Lfdr(G, newdata, cnull, tail = "R", ...)

## S3 method for class 'WGLVmix'
Lfdr(G, newdata, cnull, tail = "R", ...)

## S3 method for class 'GLmix'
Lfdr(G, newdata, cnull, tail = "R", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Lfdr_+3A_g">G</code></td>
<td>
<p>A fitted object from some G-modeling function.</p>
</td></tr>
<tr><td><code id="Lfdr_+3A_...">...</code></td>
<td>
<p>other arguments</p>
</td></tr>
<tr><td><code id="Lfdr_+3A_newdata">newdata</code></td>
<td>
<p>data frame to in which to evaluate Lfdr</p>
</td></tr>
<tr><td><code id="Lfdr_+3A_cnull">cnull</code></td>
<td>
<p>threshold for evaluation of Lfdr</p>
</td></tr>
<tr><td><code id="Lfdr_+3A_tail">tail</code></td>
<td>
<p>either &quot;R&quot; or &quot;L&quot; to specify tail focus</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given an estimated mixing distribution, G, Lfdr computes
an estimated local false discovery rate at a specified set
of points and threshold value cnull.  The argument G can be
specified as the fitted object from one of several possible
fitting routines for nonparametric mixing distributions.
</p>

<hr>
<h2 id='medde'>Maximum Entropy [De]Regularized Density Estimation</h2><span id='topic+medde'></span>

<h3>Description</h3>

<p>Density estimation based on maximum entropy methods
</p>


<h3>Usage</h3>

<pre><code class='language-R'>medde(
  x,
  v = 300,
  lambda = 0.5,
  alpha = 1,
  Dorder = 1,
  w = NULL,
  mass = 1,
  rtol = 1e-06,
  verb = 0,
  control = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="medde_+3A_x">x</code></td>
<td>
<p>Data: either univariate or bivariate, the latter is highly experimental</p>
</td></tr>
<tr><td><code id="medde_+3A_v">v</code></td>
<td>
<p>Undata: either univariate or bivariate, univariate default is an
equally spaced grid of 300 values, for bivariate data there is not (yet) a default.
Making v extend well beyond the support of x is advisable to avoid weird boundary
behavior of the estimated density.</p>
</td></tr>
<tr><td><code id="medde_+3A_lambda">lambda</code></td>
<td>
<p>total variation penalty smoothing parameter, if lambda is in [-1,0], a
shape constraint is imposed. see Koenker and Mizera (2010)  for further details.
When Dorder = 0, the shape constraint imposes that the density is monotonically
decreasing, when Dorder = 1 it imposes a concavity constraint.</p>
</td></tr>
<tr><td><code id="medde_+3A_alpha">alpha</code></td>
<td>
<p>Renyi entropy parameter characterizing fidelity criterion
by default 1 is log-concave and 0.5 is Hellinger.</p>
</td></tr>
<tr><td><code id="medde_+3A_dorder">Dorder</code></td>
<td>
<p>Order of the derivative operator for the penalty
default is Dorder = 1, corresponding to TV norm constraint on the first derivative,
or a concavity constraint on some transform of the density.  Dorder = 0 imposes
a TV penalty on the function itself, or when lambda &lt; 0 a monotonicity constraint.</p>
</td></tr>
<tr><td><code id="medde_+3A_w">w</code></td>
<td>
<p>weights associated with x,</p>
</td></tr>
<tr><td><code id="medde_+3A_mass">mass</code></td>
<td>
<p>normalizing constant for fitted density,</p>
</td></tr>
<tr><td><code id="medde_+3A_rtol">rtol</code></td>
<td>
<p>Convergence tolerance for Mosek algorithm,</p>
</td></tr>
<tr><td><code id="medde_+3A_verb">verb</code></td>
<td>
<p>Parameter controlling verbosity of solution, 0 for silent, 5
gives rather detailed iteration log.</p>
</td></tr>
<tr><td><code id="medde_+3A_control">control</code></td>
<td>
<p>Mosek control list see KWDual documentation</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See the references for further details. And also Mosek &quot;Manuals&quot;. The
acronym, according to the urban dictionary has a nice connection to
a term used in Bahamian dialect, mostly on the Family Islands like Eleuthera
and Cat Island meaning &quot;mess with&quot; &quot;get involved,&quot; &quot;get entangled,&quot; &quot;fool
around,&quot; &quot;bother:&quot;
&quot;I don't like to medder up with all kinda people&quot;
&quot;Don't medder with people (chirren)&quot;
&quot;Why you think she medderin up in their business.&quot;
</p>
<p>This version implements a class of penalized density estimators solving:
</p>
<p style="text-align: center;"><code class="reqn">\min_x \phi(x_1) | A_1 x_1 - A_2 x_2 = b,  0 \le x_1, -\lambda \le x_2 \le \lambda </code>
</p>

<p>where <code class="reqn">x</code> is a vector with two component subvectors: <code class="reqn">x_1</code> is a 
vector of function values of the density <code class="reqn">x_2</code> is a vector of dual values,
<code class="reqn">\lambda</code> is typically positive, and controls the fluctuation of the Dorder
derivative of some transform of the density. When alpha = 1 this transform is
simply the logarithm of the density, and Dorder = 1 yields a piecewise exponential
estimate; when Dorder = 2 we obtain a variant of Silverman's (1982) estimator
that shrinks the fitted density toward the Gaussian, i.e. with total variation
of the second derivative of <code class="reqn">log f</code> equal to zero.  See demo(Silverman) for
an illustration of this case.  If <code class="reqn">\lambda</code> is in <code class="reqn">(-1,0]</code> then the 
<code class="reqn">x_2</code> TV constraint is replaced by <code class="reqn">x_2 \geq 0</code>, which for <code class="reqn">\alpha = 1</code>, 
constrains the fitted density to be log-concave; for <code class="reqn">\alpha = 0.5</code>,  <code class="reqn">-1/\sqrt f</code>
is constrained to be concave; and for <code class="reqn">\alpha \le 0</code>, <code class="reqn">1/f^{\alpha -1}</code> is
constrained to be concave.  In these cases no further regularization of the smoothness
of density is required as the concavity constraint acts as  regularizer.
As explained further in Koenker and Mizera (2010) and
Han and Wellner (2016) decreasing <code class="reqn">\alpha</code> constrains the fitted density to lie 
in a larger class of quasi-concave
densities.  See <code>demo(velo)</code> for an illustration of these options, but be aware
that more extreme <code class="reqn">\alpha</code> pose more challenges from an numerical optimization
perspective.  Fitting for <code class="reqn">\alpha &lt; 1</code> employs a fidelity criterion closely 
related to Renyi entropy that is more suitable than likelihood for very peaked, or very heavy
tailed target densities.  For <code class="reqn">\lambda &lt; 0</code>  fitting for <code>Dorder != 1</code>
proceed at your own risk.  A closely related problem is illustrated in the demo
Brown which imposes a convexity constraint 
on <code class="reqn">0.5 x^2 + log f(x)</code>. This ensures that the resulting Bayes rule,
aka Tweedie formula, is monotone in <code class="reqn">x</code>, as described further in Koenker and
Mizera (2013).
</p>


<h3>Value</h3>

<p>An object of class &quot;medde&quot; with components </p>
<table>
<tr><td><code>x</code></td>
<td>
<p>points of
evaluation on the domain of the density</p>
</td></tr> <tr><td><code>y</code></td>
<td>
<p>estimated function values
at the evaluation points x</p>
</td></tr>  <tr><td><code>status</code></td>
<td>
<p>exit status from Mosek</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Roger Koenker and Ivan Mizera
</p>


<h3>References</h3>

<p>Chen, Y. and R.J. Samworth, (2013) &quot;Smoothed log-concave
maximum likelihood estimation with applications&quot;, <em>Statistica Sinica</em>,
23, 1373&ndash;1398.
</p>
<p>Han, Qiyang and Jon Wellner (2016) &ldquo;Approximation and estimation of s-concave 
densities via Renyi divergences, <em>Annals of Statistics</em>, 44, 1332-1359.
</p>
<p>Koenker, R and I. Mizera, (2007) &ldquo;Density Estimation by Total Variation
Regularization,&rdquo; <em>Advances in Statistical Modeling and Inference:
Essays in Honor of Kjell Doksum</em>, V.N. Nair (ed.), 613-634.
</p>
<p>Koenker, R and I. Mizera, (2006) &ldquo;The alter egos of the regularized maximum
likelihood density estimators: deregularized maximum-entropy, Shannon,
Renyi, Simpson, Gini, and stretched strings,&rdquo; <em> Proceedings of the 7th
Prague Symposium on Asymptotic Statistics</em>.
</p>
<p>Koenker, R and I. Mizera, (2010) &ldquo;Quasi-Concave Density Estimation&rdquo;
<em>Annals of Statistics</em>, 38, 2998-3027.
</p>
<p>Koenker, R and I. Mizera, (2013) &ldquo;Convex Optimization, Shape Constraints,
Compound Decisions, and Empirical Bayes Rules,&rdquo; JASA, 109, 674&ndash;685.
</p>
<p>Koenker, R and I. Mizera, (2014) &ldquo;Convex Optimization in R.&rdquo;,
<em>Journal of Statistical Software</em>, 60, 1-23.
</p>


<h3>See Also</h3>

<p>This function is based on an earlier function of the same name in
the deprecated package MeddeR that was based on an R-Matlab interface.
A plotting method is available, or medde estimates can be added to plots
with the usual <code>lines(meddefit, ...</code> invocation.  For log concave
estimates there is also a quantile function <code>qmedde</code> and a random
number generation function <code>rmedde</code>, eventually there should be
corresponding functionality for other alphas.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
#Maximum Likelihood Estimation of a Log-Concave Density
set.seed(1968)
x &lt;- rgamma(50,10)
m &lt;- medde(x, v = 50, lambda = -.5, verb = 5)
plot(m, type = "l", xlab = "x", ylab = "f(x)")
lines(m$x,dgamma(m$x,10),col = 2)
title("Log-concave Constraint")

## End(Not run)

## Not run: 
#Maximum Likelihood Estimation of a Gamma Density with TV constraint
set.seed(1968)
x &lt;- rgamma(50,5)
f &lt;- medde(x, v = 50, lambda = 0.2, verb = 5)
plot(f, type = "l", xlab = "x", ylab = "f(x)")
lines(f$x,dgamma(f$x,5),col = 2)
legend(10,.15,c("ghat","true"),lty = 1, col = 1:2)
title("Total Variation Norm Constraint")

## End(Not run)

</code></pre>

<hr>
<h2 id='Norberg'>Norberg Life Insurance Data</h2><span id='topic+Norberg'></span>

<h3>Description</h3>

<p>Norwegian Life Insurance Exposures and Claims
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Norberg
</code></pre>


<h3>Format</h3>

<p>A data frame with 72 observations on the following 3 variables.
</p>

<dl>
<dt><code>OccGroup</code></dt><dd><p>Occupational Group</p>
</dd>
<dt><code>Exposure</code></dt><dd><p>Exposures</p>
</dd>
<dt><code>Death</code></dt><dd><p>Observed Deaths</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data arise from 1125 original groups insured during all or part of
the period 1982-85 by a major Nowegian insurance company.  Exposures
can be normalized by a factor of 344 as in Hastrup (2000) and then can be
interpreted as the apriori expected number of claims (deaths) for each group.
The original 1125 groups were aggregated into 72 as in Norberg (1989).
</p>


<h3>References</h3>

<p>Norberg, R. (1989) Experience rating in group life insurance,
Scand. Actuarial J.,194-224.
</p>
<p>Haastrup, S. (2000) Comparison of some Bayesian analyses of heterogeneity 
in group life insurance, Scand. Actuarial J.,2-16.
</p>

<hr>
<h2 id='NPmix'>Normal mixture with Poisson sample size via Kiefer Wolfowitz NPMLE</h2><span id='topic+NPmix'></span>

<h3>Description</h3>

<p>Interior point solution of Kiefer-Wolfowitz NPMLE for mixture of Normal/Poissons
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NPmix(x, m, v = 50, u = 50, weights = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NPmix_+3A_x">x</code></td>
<td>
<p>observed response for Gaussian observations</p>
</td></tr>
<tr><td><code id="NPmix_+3A_m">m</code></td>
<td>
<p>Number of trials for Poisson observations</p>
</td></tr>
<tr><td><code id="NPmix_+3A_v">v</code></td>
<td>
<p>Grid Values for the Gaussian means mixing distribution defaults to equal
spacing of length v on [min(x) + eps, max(x) - eps], if v is scalar.</p>
</td></tr>
<tr><td><code id="NPmix_+3A_u">u</code></td>
<td>
<p>Grid Values for the Poisson rate mixing distribution defaults to equal
spacing of length u on [min(m) + eps, max(m) - eps], if u is scalar.</p>
</td></tr>
<tr><td><code id="NPmix_+3A_weights">weights</code></td>
<td>
<p>replicate weights for x obervations, should sum to 1</p>
</td></tr>
<tr><td><code id="NPmix_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to KWDual to control optimization</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The joint distribution of the means and the number of trials determining sample standard
deviations is estimated.  The grid specification for means is as for <code>GLmix</code>
whereas the grid for the Poisson rate parameters by default depends on the support of the 
observed trials.  There is no predict method as yet.  See <code>demo(NPmix1)</code>.
</p>


<h3>Value</h3>

<p>An object of class density with components: 
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>grid points of evaluation of the success probabilities</p>
</td></tr> 
<tr><td><code>u</code></td>
<td>
<p>grid points of evaluation of the Poisson rate for number of trials</p>
</td></tr> 
<tr><td><code>y</code></td>
<td>
<p>function values of the mixing density at (v,u)</p>
</td></tr> 
<tr><td><code>g</code></td>
<td>
<p>estimates of the mixture density at the distinct data values</p>
</td></tr> 
<tr><td><code>logLik</code></td>
<td>
<p>Log Likelihood value at the estimate</p>
</td></tr>
<tr><td><code>status</code></td>
<td>
<p>exit code from the optimizer</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Koenker and J. Gu
</p>


<h3>References</h3>

<p>Kiefer, J. and J. Wolfowitz Consistency of the Maximum
Likelihood Estimator in the Presence of Infinitely Many Incidental
Parameters <em>Ann. Math. Statist</em>. 27, (1956), 887-906.
</p>

<hr>
<h2 id='plot.GLVmix'>Plot a GLVmix object</h2><span id='topic+plot.GLVmix'></span>

<h3>Description</h3>

<p>Given a fitted mixture model by GLVmix plot the estimated mass points
</p>
<p>Given a fitted mixture model by GLVmix plot the estimated mass points
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'GLVmix'
plot(x, ...)

## S3 method for class 'GLVmix'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.GLVmix_+3A_x">x</code></td>
<td>
<p>is the fitted object</p>
</td></tr>
<tr><td><code id="plot.GLVmix_+3A_...">...</code></td>
<td>
<p>other arguments to pass to <code>symbols</code>, notably e.g. <code>add = TRUE</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>nothing (invisibly)
</p>
<p>nothing (invisibly)
</p>

<hr>
<h2 id='plot.medde'>Plotting method for medde objects</h2><span id='topic+plot.medde'></span>

<h3>Description</h3>

<p>Plotting method for medde objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'medde'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.medde_+3A_x">x</code></td>
<td>
<p>object obtained from medde fitting</p>
</td></tr>
<tr><td><code id="plot.medde_+3A_...">...</code></td>
<td>
<p>other parameters to be passed to plot method</p>
</td></tr>
</table>

<hr>
<h2 id='Pmix'>Poisson mixture estimation via Kiefer Wolfowitz MLE</h2><span id='topic+Pmix'></span>

<h3>Description</h3>

<p>Poisson mixture estimation via Kiefer Wolfowitz MLE
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Pmix(x, v = 300, support = NULL, exposure = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Pmix_+3A_x">x</code></td>
<td>
<p>Data: Sample observations (integer valued)</p>
</td></tr>
<tr><td><code id="Pmix_+3A_v">v</code></td>
<td>
<p>Grid Values for the mixing distribution defaults to equal
spacing of length v when v is specified as a scalar</p>
</td></tr>
<tr><td><code id="Pmix_+3A_support">support</code></td>
<td>
<p>a 2-vector containing the lower and upper support points
of sample observations to account for possible truncation.</p>
</td></tr>
<tr><td><code id="Pmix_+3A_exposure">exposure</code></td>
<td>
<p>observation specific exposures to risk see details</p>
</td></tr>
<tr><td><code id="Pmix_+3A_...">...</code></td>
<td>
<p>other parameters passed to KWDual to control optimization</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The predict method for <code>Pmix</code> objects will compute means, medians or
modes of the posterior according to whether the <code>Loss</code> argument is 2, 1
or 0, or posterior quantiles if <code>Loss</code> is in (0,1).
</p>
<p>In the default case <code>exposure = 1</code> it is assumed that
<code>x</code> contains individual observations that are aggregated into
count bins via <code>table</code>.  When <code>exposure</code> has the same length as
<code>x</code> then it is presumed to be individual specific risk exposure and
the Poisson mixture is taken to be <code class="reqn">x | v ~ Poi(v * exposure)</code> and the
is not aggregated.  See for example the analysis of the Norberg data in
Koenker and Gu (2016).
</p>


<h3>Value</h3>

<p>An object of class density with components: 
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>points of evaluation of the mixing density</p>
</td></tr> 
<tr><td><code>y</code></td>
<td>
<p>function values of the mixing density at x</p>
</td></tr> 
<tr><td><code>g</code></td>
<td>
<p>function values of the mixture density on <code class="reqn">0, 1, ... max(x)+1</code></p>
</td></tr> 
<tr><td><code>logLik</code></td>
<td>
<p>Log Likelihood value at the estimate</p>
</td></tr> 
<tr><td><code>dy</code></td>
<td>
<p>Bayes rule estimate of Poisson rate parameter at each x</p>
</td></tr>  
<tr><td><code>status</code></td>
<td>
<p>exit code from the optimizer</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Roger Koenker and Jiaying Gu
</p>


<h3>References</h3>

<p>Kiefer, J. and J. Wolfowitz Consistency of the Maximum
Likelihood Estimator in the Presence of Infinitely Many Incidental
Parameters <em>Ann. Math. Statist</em>. Volume 27, Number 4 (1956), 887-906.
</p>
<p>Koenker, R. and J. Gu, (2017) REBayes: An R Package for Empirical Bayes Mixture Methods,
<em>Journal of Statistical Software</em>, 82, 1&ndash;26.
</p>

<hr>
<h2 id='predict.B2mix'>Predict Method for Bmix</h2><span id='topic+predict.B2mix'></span>

<h3>Description</h3>

<p>Predict Method for Binomial Mixtures
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'B2mix'
predict(object, newdata, Loss = 2, newk, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.B2mix_+3A_object">object</code></td>
<td>
<p>fitted object of class &quot;B2mix&quot;</p>
</td></tr>
<tr><td><code id="predict.B2mix_+3A_newdata">newdata</code></td>
<td>
<p>Values at which prediction is desired an n by 2 matrix</p>
</td></tr>
<tr><td><code id="predict.B2mix_+3A_loss">Loss</code></td>
<td>
<p>Loss function used to generate prediction:  Currently supported values:
2 to get mean predictions, 1 to get median predictions, 0 to get modal predictions
or any tau in (0,1) to get tau-th quantile predictions.</p>
</td></tr>
<tr><td><code id="predict.B2mix_+3A_newk">newk</code></td>
<td>
<p>k values (number of trials) for the predictions an n by 2 matrix</p>
</td></tr>
<tr><td><code id="predict.B2mix_+3A_...">...</code></td>
<td>
<p>optional arguments to predict</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The predict method for B2mix objects will compute posterior means.
</p>


<h3>Value</h3>

<p>A vector of predictions
</p>


<h3>Author(s)</h3>

<p>Jiaying Gu and Roger Koenker
</p>

<hr>
<h2 id='predict.Bmix'>Predict Method for Bmix</h2><span id='topic+predict.Bmix'></span>

<h3>Description</h3>

<p>Predict Method for Binomial Mixtures
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Bmix'
predict(object, newdata, Loss = 2, newk, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.Bmix_+3A_object">object</code></td>
<td>
<p>fitted object of class &quot;Bmix&quot;</p>
</td></tr>
<tr><td><code id="predict.Bmix_+3A_newdata">newdata</code></td>
<td>
<p>Values at which prediction is desired</p>
</td></tr>
<tr><td><code id="predict.Bmix_+3A_loss">Loss</code></td>
<td>
<p>Loss function used to generate prediction:  Currently supported values:
2 to get mean predictions, 1 to get median predictions, 0 to get modal predictions
or any tau in (0,1) to get tau-th quantile predictions.</p>
</td></tr>
<tr><td><code id="predict.Bmix_+3A_newk">newk</code></td>
<td>
<p>k values (number of trials) for the predictions</p>
</td></tr>
<tr><td><code id="predict.Bmix_+3A_...">...</code></td>
<td>
<p>optional arguments to predict</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The predict method for <code>Bmix</code> objects will compute means, quantiles or
modes of the posterior according to the <code>Loss</code> argument.  Typically,
<code>newdata</code> would be passed to <code>predict</code>
</p>


<h3>Value</h3>

<p>A vector of predictions
</p>


<h3>Author(s)</h3>

<p>Jiaying Gu
</p>

<hr>
<h2 id='predict.GLmix'>Predict Method for GLmix</h2><span id='topic+predict.GLmix'></span>

<h3>Description</h3>

<p>Predict Method for Gaussian Location Mixtures
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'GLmix'
predict(object, newdata, Loss = 2, newsigma = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.GLmix_+3A_object">object</code></td>
<td>
<p>fitted object of class &quot;GLmix&quot;</p>
</td></tr>
<tr><td><code id="predict.GLmix_+3A_newdata">newdata</code></td>
<td>
<p>Values at which prediction is desired</p>
</td></tr>
<tr><td><code id="predict.GLmix_+3A_loss">Loss</code></td>
<td>
<p>Loss function used to generate prediction:  Currently supported values: 
2 to get mean predictions, 1 to get median predictions, 0 to get modal predictions
or any tau in (0,1) to get tau-th quantile predictions.</p>
</td></tr>
<tr><td><code id="predict.GLmix_+3A_newsigma">newsigma</code></td>
<td>
<p>sigma values for the predictions</p>
</td></tr>
<tr><td><code id="predict.GLmix_+3A_...">...</code></td>
<td>
<p>optional arguments to predict</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The predict method for <code>GLmix</code> objects will compute means, quantiles or
modes of the posterior according to the <code>Loss</code> argument.  Typically,
<code>newdata</code> would be passed to <code>predict</code>
</p>


<h3>Value</h3>

<p>A vector of predictions
</p>


<h3>Author(s)</h3>

<p>Roger Koenker
</p>

<hr>
<h2 id='predict.GLVmix'>Predict Method for GLVmix</h2><span id='topic+predict.GLVmix'></span>

<h3>Description</h3>

<p>Predict Method for Gaussian Location-scale Mixtures
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'GLVmix'
predict(object, newdata, Loss = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.GLVmix_+3A_object">object</code></td>
<td>
<p>Fitted object of class &quot;GLVmix&quot;</p>
</td></tr>
<tr><td><code id="predict.GLVmix_+3A_newdata">newdata</code></td>
<td>
<p>data.frame with components(t,s,m) at which prediction is desired</p>
</td></tr>
<tr><td><code id="predict.GLVmix_+3A_loss">Loss</code></td>
<td>
<p>Loss function used to generate prediction:  Currently supported values: 
2 to get mean predictions, 1 to get median predictions, 0 to get modal predictions
or any tau in (0,1) to get tau-th quantile predictions.</p>
</td></tr>
<tr><td><code id="predict.GLVmix_+3A_...">...</code></td>
<td>
<p>optional arguments to predict</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The predict method for <code>GLmix</code> objects will compute means, quantiles or
modes of the posterior according to the <code>Loss</code> argument.  Typically,
<code>newdata</code> would be passed to <code>predict</code>.  Note that these predictions
are for the location parameter only.
</p>


<h3>Value</h3>

<p>A vector of predictions
</p>


<h3>Author(s)</h3>

<p>Roger Koenker
</p>

<hr>
<h2 id='predict.HLmix'>Predict Method for HLmix</h2><span id='topic+predict.HLmix'></span>

<h3>Description</h3>

<p>Predict Method for Huber Location Mixtures
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'HLmix'
predict(object, newdata, Loss = 2, newsigma = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.HLmix_+3A_object">object</code></td>
<td>
<p>fitted object of class &quot;HLmix&quot;</p>
</td></tr>
<tr><td><code id="predict.HLmix_+3A_newdata">newdata</code></td>
<td>
<p>Values at which prediction is desired</p>
</td></tr>
<tr><td><code id="predict.HLmix_+3A_loss">Loss</code></td>
<td>
<p>Loss function used to generate prediction:  Currently supported values: 
2 to get mean predictions, 1 to get median predictions, 0 to get modal predictions
or any tau in (0,1) to get tau-th quantile predictions.</p>
</td></tr>
<tr><td><code id="predict.HLmix_+3A_newsigma">newsigma</code></td>
<td>
<p>sigma values for the predictions</p>
</td></tr>
<tr><td><code id="predict.HLmix_+3A_...">...</code></td>
<td>
<p>optional arguments to predict</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The predict method for <code>HLmix</code> objects computes means, quantiles or
modes of the posterior according to the <code>Loss</code> argument.  Typically,
<code>newdata</code> would be passed to <code>predict</code>.  Note that if newdata
is simply equal to the original observations (denoising case) then the
</p>


<h3>Value</h3>

<p>A vector of predictions
</p>


<h3>Author(s)</h3>

<p>Roger Koenker
</p>

<hr>
<h2 id='predict.Pmix'>Predict Method for Pmix</h2><span id='topic+predict.Pmix'></span>

<h3>Description</h3>

<p>Predict Method for Poisson Mixtures
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Pmix'
predict(object, newdata, Loss = 2, newexposure = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.Pmix_+3A_object">object</code></td>
<td>
<p>fitted object of class &quot;Pmix&quot;</p>
</td></tr>
<tr><td><code id="predict.Pmix_+3A_newdata">newdata</code></td>
<td>
<p>Values at which prediction is desired</p>
</td></tr>
<tr><td><code id="predict.Pmix_+3A_loss">Loss</code></td>
<td>
<p>Loss function used to generate prediction.  Currently supported values:
2 to get mean predictions, 1 to get harmonic mean predictions, 0 to get modal predictions
or any tau in (0,1) to get tau-th quantile predictions.  The posterior harmonic mean is
the Bayes rule for quadratic loss weighted by variances as in Clevenson and Zidek (1975).</p>
</td></tr>
<tr><td><code id="predict.Pmix_+3A_newexposure">newexposure</code></td>
<td>
<p>exposure values for the predictions</p>
</td></tr>
<tr><td><code id="predict.Pmix_+3A_...">...</code></td>
<td>
<p>optional arguments to predict</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The predict method for <code>Pmix</code> objects will compute means, quantiles or
modes of the posterior according to the <code>Loss</code> argument.  Typically,
<code>newdata</code> would be passed to <code>predict</code>
</p>


<h3>Value</h3>

<p>A vector of predictions
</p>


<h3>Author(s)</h3>

<p>Jiaying Gu and Roger Koenker
</p>


<h3>References</h3>

<p>Clevenson, M. L. and Zidek, J. V. 1975. Simultaneous Estimation of the
Means of Independent Poisson Laws, Journal of the American Statistical Association,
70, 698-705.
</p>

<hr>
<h2 id='predict.WGLVmix'>Predict Method for WGLVmix</h2><span id='topic+predict.WGLVmix'></span>

<h3>Description</h3>

<p>Predict Method for Gaussian Location-scale Mixtures (Longitudinal Version)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'WGLVmix'
predict(object, newdata, Loss = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.WGLVmix_+3A_object">object</code></td>
<td>
<p>Fitted object of class &quot;GLVmix&quot;</p>
</td></tr>
<tr><td><code id="predict.WGLVmix_+3A_newdata">newdata</code></td>
<td>
<p>data.frame with components(y,id,w) at which prediction is desired
this data structure must be compatible with that of <code>WGLVmix</code>, if newdata$w
is NULL then w is replaced by a vector of ones of length(y)</p>
</td></tr>
<tr><td><code id="predict.WGLVmix_+3A_loss">Loss</code></td>
<td>
<p>Loss function used to generate prediction:  Currently supported values: 
2 to get mean predictions, 1 to get median predictions, 0 to get modal predictions
or any tau in (0,1) to get tau-th quantile predictions.</p>
</td></tr>
<tr><td><code id="predict.WGLVmix_+3A_...">...</code></td>
<td>
<p>optional arguments to predict</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The predict method for <code>WGLmix</code> objects will compute means, quantiles or
modes of the posterior according to the <code>Loss</code> argument.  Typically,
<code>newdata</code> would be passed to <code>predict</code>.  Note that these predictions
are for the location parameter only.
</p>


<h3>Value</h3>

<p>A vector of predictions
</p>


<h3>Author(s)</h3>

<p>Roger Koenker
</p>

<hr>
<h2 id='psychtest'>Lord and Cressie Binomial Psychological Test Data</h2><span id='topic+psychtest'></span>

<h3>Description</h3>

<p>Frequencies of test scores (number of correct answers) 
on a psychological test with 20 questions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>psychtest
</code></pre>


<h3>Format</h3>

<p>A data frame with 21 observations on 2 variables.
</p>

<dl>
<dt><code>x</code></dt><dd><p>number of correct answers (out of 20 questions)</p>
</dd>
<dt><code>k</code></dt><dd><p>frequency out of 12990 exams.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Lord, F.M. and N. Cressie  (1975).  An Empirical Bayes Procedure for 
Finding an Interval Estimate, Sankhya, 37, 1-9.
</p>

<hr>
<h2 id='qKW'>Quantiles of KW fit</h2><span id='topic+qKW'></span>

<h3>Description</h3>

<p>Quantiles of KW fit
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qKW(g, q)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qKW_+3A_g">g</code></td>
<td>
<p>KW fitted object</p>
</td></tr>
<tr><td><code id="qKW_+3A_q">q</code></td>
<td>
<p>vector of quantiles to be computed</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Koenker
</p>

<hr>
<h2 id='qKW2'>Quantiles of bivariate KW fit</h2><span id='topic+qKW2'></span>

<h3>Description</h3>

<p>Quantiles of bivariate KW fit
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qKW2(g, q)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qKW2_+3A_g">g</code></td>
<td>
<p>KW fitted object</p>
</td></tr>
<tr><td><code id="qKW2_+3A_q">q</code></td>
<td>
<p>vector of quantiles to be computed</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Koenker
</p>

<hr>
<h2 id='qmedde'>Quantile function for medde estimate</h2><span id='topic+qmedde'></span>

<h3>Description</h3>

<p>Slightly modified version  borrowed from the package logcondens 
Todo:  extend this to cases with <code class="reqn">\alpha != 1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qmedde(p, medde)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qmedde_+3A_p">p</code></td>
<td>
<p>vector of probabilities at which to evaluate the quantiles</p>
</td></tr>
<tr><td><code id="qmedde_+3A_medde">medde</code></td>
<td>
<p>fitted object from medde</p>
</td></tr>
</table>

<hr>
<h2 id='rKW'>Random sample from KW object</h2><span id='topic+rKW'></span>

<h3>Description</h3>

<p>Random sample from KW object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rKW(n, g)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rKW_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="rKW_+3A_g">g</code></td>
<td>
<p>KW object</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Koenker
</p>

<hr>
<h2 id='RLR'>Regularized Logistic Regression</h2><span id='topic+RLR'></span>

<h3>Description</h3>

<p>Logistic Regression with lasso like penalties
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RLR(X, Y, D, lambda, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RLR_+3A_x">X</code></td>
<td>
<p>a design matrix for the unconstrained logistic regression model</p>
</td></tr>
<tr><td><code id="RLR_+3A_y">Y</code></td>
<td>
<p>a response vector of Boolean values, or n by 2 matrix of binomials as in <code>glm</code></p>
</td></tr>
<tr><td><code id="RLR_+3A_d">D</code></td>
<td>
<p>is a matrix specifying the penalty, <code>diag(ncol(X))</code> for the conventional 
lasso penalty</p>
</td></tr>
<tr><td><code id="RLR_+3A_lambda">lambda</code></td>
<td>
<p>a scalar specifying the intensity of one's belief in the prior.  No
provision for automatic selection has been made (yet).</p>
</td></tr>
<tr><td><code id="RLR_+3A_...">...</code></td>
<td>
<p>other parameters passed to control optimization:  These may
include <code>rtol</code> the relative tolerance for dual gap convergence criterion,
<code>verb</code> to control verbosity desired from mosek, <code>verb = 0</code> is quiet,
<code>verb = 5</code> produces a fairly detailed iteration log.  See the documentation for 
<code>KWDual</code> for further details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In some logistic regression problems, especially those with a large number of fixed effects
like the Bradley-Terry rating model, it may be plausible to consider groups of effects that 
would be considered equivalence classes.  One way to implement such prior information is to
impose some form of regularization penalty.  In the general formulation we are trying to
solve the problem:
</p>
<p style="text-align: center;"><code class="reqn"> \min \ell (\theta | X, y) + \| D \theta \|_1 </code>
</p>
<p>.
For example in the Bradley-Terry rating model, we may consider penalties of the form, 
</p>
<p style="text-align: center;"><code class="reqn"> \| D \theta \|_1 = \sum_{i &lt; j} |\theta_i - \theta_j | </code>
</p>
   
<p>so differences in all pairs of ratings are pulled together.  This form of the penalty
has been used by Hocking et al (2011) for clustering, by Masarotto and Varin (2012)
for estimation of the Bradley Terry model and by Gu and Volgushev (2019) for grouping
fixed effects in panel data models.  This is an implementation in
Mosek, so the package <span class="pkg">Rmosek</span> and Mosek must be available at run time.
The <code>demo(RLR1)</code> illustrates use with the conventional lasso penalty and produces a 
lasso shrinkage plot.  The <code>demo(RLR2)</code> illustrates use with the ranking/grouping
lasso penalty and produces a plot of how the number of groups is reduced as lambda rises.
</p>


<h3>Value</h3>

<p>A list with components: </p>
<table>
<tr><td><code>coef</code></td>
<td>
<p>vector of coefficients</p>
</td></tr><tr><td><code>logLik</code></td>
<td>
<p>log likelihood
value at the solution</p>
</td></tr><tr><td><code>status</code></td>
<td>
<p>return status from the Mosek optimizer</p>
</td></tr></table>
<p>.
</p>


<h3>Author(s)</h3>

<p>Roger Koenker with crucial help from Michal Adamaszek of Mosek ApS
</p>


<h3>References</h3>

<p>Gu, J. and Volgushev, S. (2019), 'Panel data quantile regression with grouped 
fixed effects', <em>Journal of Econometrics</em>, 213, 68&ndash;91.
</p>
<p>Hocking, T. D., Joulin, A., Bach, F. and Vert, J.-P. (2011), 'Clusterpath: an algorithm for
clustering using convex fusion penalties', Proceedings of the 28th International Conference
on International Conference on Machine Learning, 745&ndash;752.
</p>
<p>Masarotto, G. and Varin, C. (2012), 'The ranking lasso and its application to sport 
tournaments', <em>The Annals of Applied Statistics</em>, 6, 1949&ndash;1970.
</p>

<hr>
<h2 id='rmedde'>Random number generation from a medde estimate</h2><span id='topic+rmedde'></span>

<h3>Description</h3>

<p>Random number generation from a medde estimate
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmedde(n, medde, smooth = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmedde_+3A_n">n</code></td>
<td>
<p>number of observations desired in calls to rmedde</p>
</td></tr>
<tr><td><code id="rmedde_+3A_medde">medde</code></td>
<td>
<p>fitted medde object for calls in qmedde and rmedde</p>
</td></tr>
<tr><td><code id="rmedde_+3A_smooth">smooth</code></td>
<td>
<p>option to draw random meddes from the smoothed density</p>
</td></tr>
</table>

<hr>
<h2 id='Rxiv'>Archive function for auxiliary files for latex documents</h2><span id='topic+Rxiv'></span>

<h3>Description</h3>

<p>Creates a tar.gz file with all of the R files needed to recreate the tables
and figures that appear in the paper.  Should be considered experimental at
this stage.  It presumes that tables are generated with something like the
<span class="pkg">Hmisc</span>  <code>latex</code> function and included in the latex document with
<code>input</code> commands.  Likewise figures are assumed to be included with
<code>includegraphics</code> and generated by R in pdf format.  This
was originally developed to sort out the files for &quot;Empirical Bayesball Remixed&quot;.
An optional side of effect of the function to create a tar.gz file with the gzipped
R files required for the paper.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Rxiv(fname, figures = "figures", tables = "tables", tar = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Rxiv_+3A_fname">fname</code></td>
<td>
<p>name of the latex file of the paper sans .tex suffix</p>
</td></tr>
<tr><td><code id="Rxiv_+3A_figures">figures</code></td>
<td>
<p>name of the directory with the files for figures</p>
</td></tr>
<tr><td><code id="Rxiv_+3A_tables">tables</code></td>
<td>
<p>name of the directory with the files for tables</p>
</td></tr>
<tr><td><code id="Rxiv_+3A_tar">tar</code></td>
<td>
<p>logical flag, if TRUE generate a gzipped tar file of .R files</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with the following components
</p>
<table>
<tr><td><code>Rtables</code></td>
<td>
<p>a character array with two columns:  .tex files and .R files</p>
</td></tr>
<tr><td><code>Rfigures</code></td>
<td>
<p>a character array with two columns:  .pdf files and .R files</p>
</td></tr>
<tr><td><code>Rother</code></td>
<td>
<p>a character vector with other R files required.</p>
</td></tr>
<tr><td><code>Rcached</code></td>
<td>
<p>a character vector with cached Rda files</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Koenker
</p>

<hr>
<h2 id='tacks'>Beckett and Diaconis flipping tacks data</h2><span id='topic+tacks'></span>

<h3>Description</h3>

<p>This data was generated by Beckett and Diaconis (1994).  
They describe it as follows: 
&quot;The example involves repeated rolls of a common thumbtack.  A one was
recorded if the tack landed point up and a zero was recorded if the tack
landed point down.  All tacks started point down.  Each tack was flicked
or hit with the fingers from where it last rested.  A fixed tack was flicked
9 times. The data are recorded in Table 1.  There are 320 9-tuples.  These
arose from 16 different tacks, 2 &ldquo;flickers,&rdquo;  and 10 surfaces.  The tacks
vary considerably in shape and in proportion of ones.  The surfaces varied
from rugs through tablecloths through bathroom floors.&quot;
Following Liu (1996), we treat the data as though they came from 
320 independent binomials.  See <code>demo(Bmix1)</code> for further details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tacks
</code></pre>


<h3>Format</h3>

<p>A data frame with 320 observations on 2 variables.
</p>

<dl>
<dt><code>x</code></dt><dd><p>a numeric vector giving the number of tacks landed point up.</p>
</dd>
<dt><code>k</code></dt><dd><p>a numeric vector giving the number of trials.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Beckett, L. and Diaconis. P. (1994). Spectral analysis 
for discrete longitudinal data, Adv. Math., 103: 107-128.
</p>


<h3>References</h3>

<p>Liu, J.S. (1996). Nonparametric Hierarchical Bayes via 
Sequential Imputations.  <em>Annals of Statistics</em>, 24: 911-930.
</p>

<hr>
<h2 id='tannenbaum'>Perverse Gaussian Mixture data</h2><span id='topic+tannenbaum'></span>

<h3>Description</h3>

<p>Gaussian Location Mixture data to illustrate Mosek tolerance problem
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tannenbaum
</code></pre>


<h3>Format</h3>

<p>5000 iid Gaussians
This data set was randomly generated in the course of trying to understand some
anomalies in estimating Gaussian location mixture problems with <code>GLmix</code>.
It is used by <code>demo(tannenbaum)</code> to illustrate that sometimes it is
worthwhile to tighten the default convergence tolerance for Mosek.
</p>

<hr>
<h2 id='ThreshFDR'>Thresholding for False Discovery Rate</h2><span id='topic+ThreshFDR'></span>

<h3>Description</h3>

<p>This function approximates FDR for various values of lambda
and is usually employed in conjunction with <code>Finv</code> to
find an appropriate cutoff value lambda.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ThreshFDR(lambda, stat, v)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ThreshFDR_+3A_lambda">lambda</code></td>
<td>
<p>is the proposed threshold</p>
</td></tr>
<tr><td><code id="ThreshFDR_+3A_stat">stat</code></td>
<td>
<p>is the statistic used for ranking</p>
</td></tr>
<tr><td><code id="ThreshFDR_+3A_v">v</code></td>
<td>
<p>is the local false discovery statistic</p>
</td></tr>
</table>

<hr>
<h2 id='TLmix'>NPMLE for Student t location mixtures</h2><span id='topic+TLmix'></span>

<h3>Description</h3>

<p>Kiefer Wolfowitz NPMLE for Student t location mixtures
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TLmix(x, v = 300, u = 300, df = 1, hist = FALSE, weights = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TLmix_+3A_x">x</code></td>
<td>
<p>Data: Sample Observations</p>
</td></tr>
<tr><td><code id="TLmix_+3A_v">v</code></td>
<td>
<p>bin boundaries defaults to equal spacing of length v</p>
</td></tr>
<tr><td><code id="TLmix_+3A_u">u</code></td>
<td>
<p>bin boundaries for histogram binning: defaults to equal spacing</p>
</td></tr>
<tr><td><code id="TLmix_+3A_df">df</code></td>
<td>
<p>Number of degrees of freedom of Student base density</p>
</td></tr>
<tr><td><code id="TLmix_+3A_hist">hist</code></td>
<td>
<p>If TRUE then aggregate x to histogram weights</p>
</td></tr>
<tr><td><code id="TLmix_+3A_weights">weights</code></td>
<td>
<p>replicate weights for x obervations, should sum to 1</p>
</td></tr>
<tr><td><code id="TLmix_+3A_...">...</code></td>
<td>
<p>optional parameters passed to KWDual to control optimization</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Kiefer Wolfowitz MLE density estimation as proposed by Jiang and Zhang for
a Student t compound decision problem.  The histogram option is intended
for large problems, say n &gt; 1000, where reducing the sample size dimension
is desirable. By default the grid for the binning is equally spaced on the
interval between the 0.01 and 0.99 quantiles of the observed sample.  This
is intended to avoid extreme gridding for Student's with small df.
</p>


<h3>Value</h3>

<p>An object of class density with components: 
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>midpoints of evaluation on the domain of the mixing density</p>
</td></tr> 
<tr><td><code>y</code></td>
<td>
<p>estimated function values at the points x of the mixing density</p>
</td></tr> 
<tr><td><code>logLik</code></td>
<td>
<p>Log likelihood value at the proposed solution</p>
</td></tr> 
<tr><td><code>dy</code></td>
<td>
<p>Bayes rule estimates of location at x</p>
</td></tr> 
<tr><td><code>status</code></td>
<td>
<p>Mosek exit code</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Roger Koenker
</p>


<h3>References</h3>

<p>Kiefer, J. and J. Wolfowitz Consistency of the Maximum
Likelihood Estimator in the Presence of Infinitely Many Incidental
Parameters <em>Ann. Math. Statist</em>.  27, (1956), 887-906.
</p>
<p>Jiang, Wenhua and Cun-Hui Zhang General maximum likelihood empirical Bayes
estimation of normal means <em>Ann. Statist.</em>, 37, (2009), 1647-1684.
</p>
<p>Koenker, R. and J. Gu, (2017) REBayes: An R Package for Empirical Bayes Mixture Methods,
<em>Journal of Statistical Software</em>, 82, 1&ndash;26.
</p>


<h3>See Also</h3>

<p>GLmix for Gaussian version
</p>

<hr>
<h2 id='Tncpmix'>NPMLE for Student t non-centrality parameter mixtures</h2><span id='topic+Tncpmix'></span>

<h3>Description</h3>

<p>Kiefer Wolfowitz NPMLE for Student t non-centrality parameter mixtures
Model: <code class="reqn">y_{ig} = mu_{g} + e_{ig}, e_{ig} ~ N(0,sigma_{g}^{2})</code>
x is the vector of t statistics for all groups, which follows t dist
if <code class="reqn">mu_g = 0</code>, and noncentral t dist if <code class="reqn">mu_g \neq 0</code>, 
with <code class="reqn">ncp_{g} = \mu_g / \sigma_{g}</code>.
This leads to a mixture of t distribution with ncp as the mixing parameter.  
df (degree of freedom) is determined by the group size in the simplest case.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Tncpmix(x, v = 300, u = 300, df = 1, hist = FALSE, weights = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tncpmix_+3A_x">x</code></td>
<td>
<p>Data: Sample Observations</p>
</td></tr>
<tr><td><code id="Tncpmix_+3A_v">v</code></td>
<td>
<p>bin boundaries defaults to equal spacing of length v</p>
</td></tr>
<tr><td><code id="Tncpmix_+3A_u">u</code></td>
<td>
<p>bin boundaries for histogram binning: defaults to equal spacing</p>
</td></tr>
<tr><td><code id="Tncpmix_+3A_df">df</code></td>
<td>
<p>Number of degrees of freedom of Student base density</p>
</td></tr>
<tr><td><code id="Tncpmix_+3A_hist">hist</code></td>
<td>
<p>If TRUE then aggregate x to histogram weights</p>
</td></tr>
<tr><td><code id="Tncpmix_+3A_weights">weights</code></td>
<td>
<p>replicate weights for x obervations, should sum to 1</p>
</td></tr>
<tr><td><code id="Tncpmix_+3A_...">...</code></td>
<td>
<p>optional parameters passed to KWDual to control optimization</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class density with components: 
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>midpoints of evaluation on the domain of the mixing density</p>
</td></tr> 
<tr><td><code>y</code></td>
<td>
<p>estimated function values at the points x of the mixing density</p>
</td></tr> 
<tr><td><code>g</code></td>
<td>
<p>estimated function values at the observed points of mixture density</p>
</td></tr> 
<tr><td><code>logLik</code></td>
<td>
<p>Log likelihood value at the proposed solution</p>
</td></tr> 
<tr><td><code>dy</code></td>
<td>
<p>Bayes rule estimates of location at x</p>
</td></tr> 
<tr><td><code>status</code></td>
<td>
<p>Mosek exit code</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Roger Koenker
</p>


<h3>References</h3>

<p>Kiefer, J. and J. Wolfowitz Consistency of the Maximum
Likelihood Estimator in the Presence of Infinitely Many Incidental
Parameters <em>Ann. Math. Statist</em>.  27, (1956), 887-906.
</p>
<p>Koenker, R. and J. Gu, (2017) REBayes: An R Package for Empirical Bayes Mixture Methods,
<em>Journal of Statistical Software</em>, 82, 1&ndash;26.
</p>


<h3>See Also</h3>

<p>GLmix for Gaussian version
</p>

<hr>
<h2 id='traprule'>Integration by Trapezoidal Rule</h2><span id='topic+traprule'></span>

<h3>Description</h3>

<p>Integration by Trapezoidal Rule
</p>


<h3>Usage</h3>

<pre><code class='language-R'>traprule(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="traprule_+3A_x">x</code></td>
<td>
<p>points of evaluation</p>
</td></tr>
<tr><td><code id="traprule_+3A_y">y</code></td>
<td>
<p>function values</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Crude Riemann sum approximation.
</p>


<h3>Value</h3>

<p>A real number.
</p>


<h3>Author(s)</h3>

<p>R. Koenker
</p>

<hr>
<h2 id='Umix'>NPMLE for Uniform Scale Mixtures</h2><span id='topic+Umix'></span>

<h3>Description</h3>

<p>Kiefer-Wolfowitz Nonparametric MLE for Uniform Scale Mixtures
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Umix(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Umix_+3A_x">x</code></td>
<td>
<p>Data: Sample Observations</p>
</td></tr>
<tr><td><code id="Umix_+3A_...">...</code></td>
<td>
<p>other parameters to pass to KWDual to control optimization</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Kiefer-Wolfowitz MLE for the mixture model <code class="reqn">Y \sim U[0,T], \; T \sim G</code> 
No gridding is required since mass points of the mixing distribution, <code class="reqn">G</code>,
must occur at the data points.  This formalism is equivalent, as noted by
Groeneboom and Jongbloed (2014) to the Grenander estimator of a monotone
density in the sense that the estimated mixture density, i.e. the marginal
density of <code class="reqn">Y</code>, is the Grenander estimate,  see the remark at the end
of their Section 2.2.  See also <code>demo(Grenander)</code>.  Note that this
refers to the decreasing version of the Grenander estimator, for the 
increasing version try standing on your head.
</p>


<h3>Value</h3>

<p>An object of class density with components: 
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>points of  evaluation on the domain of the density</p>
</td></tr> 
<tr><td><code>y</code></td>
<td>
<p>estimated mass at the points x of the mixing density</p>
</td></tr> 
<tr><td><code>g</code></td>
<td>
<p>the estimated mixture density function values at x</p>
</td></tr> 
<tr><td><code>logLik</code></td>
<td>
<p>Log likelihood value at the proposed solution</p>
</td></tr> 
<tr><td><code>status</code></td>
<td>
<p>exit code from the optimizer</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jiaying Gu and Roger Koenker
</p>


<h3>References</h3>

<p>Kiefer, J. and J. Wolfowitz Consistency of the Maximum
Likelihood Estimator in the Presence of Infinitely Many Incidental
Parameters <em>Ann. Math. Statist</em>.  Volume 27, Number 4 (1956), 887-906.
</p>
<p>Groeneboom, P. and G. Jongbloed, <em>Nonparametric Estimation under 
Shape Constraints</em>, 2014, Cambridge U. Press.
</p>

<hr>
<h2 id='velo'>Rotational Velocity of Stars</h2><span id='topic+velo'></span>

<h3>Description</h3>

<p>A sample of rotational velocities of stars from Hoffleit and 
Warren (1991) similar to that previosly considered by Pal, Woodroofe and Meyer (2007)
and used by Koenker and Mizera (2010).  The <code>demo(velo)</code> illustrates fitted
densities for three relatively weak concavity constraints corresponding to
<code class="reqn">-1/sqrt(f)</code>, <code class="reqn">-1/f</code> and <code class="reqn">-1/f^2</code> constrained to be concave.
Note that last of these pushes the optimization methods about as far as they can do.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>velo
</code></pre>


<h3>Format</h3>

<p>A numeric vector with 3933 observations on one variable.
</p>

<dl>
<dt><code>velo</code></dt><dd><p>a numeric vector with rotational velocities.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Hoffleit, D. and Warren, W. H. (1991). The Bright Star Catalog (5th ed.). 
Yale University Observatory, New Haven.
</p>


<h3>References</h3>

<p>Pal, J. K., Woodroofe, M. and Meyer, M. (2007). Estimating a Polya frequency 
function. In Complex Datasets and Inverse Problems: Tomography, Networks and 
Beyond, (R. Liu, W. Strawderman, and C.-H. Zhang, eds.). IMS Lecture Notes-Monograph 
Series 54 239-249. Institute of Mathematical Statistics.
Koenker, R. and Mizera, I. (2010) Quasi-Concave Density Estimation, 
Annals of Statistics, 38, 2998-3027.
</p>

<hr>
<h2 id='Weibullmix'>NPMLE for Weibull Mixtures</h2><span id='topic+Weibullmix'></span>

<h3>Description</h3>

<p>Kiefer-Wolfowitz NPMLE for Weibull Mixtures of scale parameter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Weibullmix(
  x,
  v = 300,
  u = 300,
  alpha,
  lambda = 1,
  event = NULL,
  hist = FALSE,
  weights = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Weibullmix_+3A_x">x</code></td>
<td>
<p>Survival times</p>
</td></tr>
<tr><td><code id="Weibullmix_+3A_v">v</code></td>
<td>
<p>Grid values for mixing distribution</p>
</td></tr>
<tr><td><code id="Weibullmix_+3A_u">u</code></td>
<td>
<p>Grid values for histogram bins, if needed</p>
</td></tr>
<tr><td><code id="Weibullmix_+3A_alpha">alpha</code></td>
<td>
<p>Shape parameter for Weibull distribution</p>
</td></tr>
<tr><td><code id="Weibullmix_+3A_lambda">lambda</code></td>
<td>
<p>Scale parameter for Weibull Distribution; must either have length 1, or length
equal to <code>length(x)</code> the latter case accommodates the possibility of a linear predictor</p>
</td></tr>
<tr><td><code id="Weibullmix_+3A_event">event</code></td>
<td>
<p>censoring indicator, 1 if actual event time, 0 if censored</p>
</td></tr>
<tr><td><code id="Weibullmix_+3A_hist">hist</code></td>
<td>
<p>If TRUE aggregate to histogram counts</p>
</td></tr>
<tr><td><code id="Weibullmix_+3A_weights">weights</code></td>
<td>
<p>replicate weights for x obervations, should sum to 1</p>
</td></tr>
<tr><td><code id="Weibullmix_+3A_...">...</code></td>
<td>
<p>optional parameters passed to KWDual to control optimization</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Kiefer Wolfowitz NPMLE density estimation for Weibull scale mixtures. The
histogram option is intended for relatively large problems, say n &gt; 1000,
where reducing the sample size dimension is desirable. By default the grid
for the binning is equally spaced on the support of the data.  Parameterization:
f(t|alpha, lambda) = alpha * exp(v) * (lambda * t )^(alpha-1) * 
exp(-(lambda * t)^alpha * exp(v)); shape = alpha; scale = lambda^(-1) * (exp(v))^(-1/alpha)
This version purports to handle right censoring.
</p>


<h3>Value</h3>

<p>An object of class density with components 
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>points of evaluation on the domain of the density</p>
</td></tr> 
<tr><td><code>y</code></td>
<td>
<p>estimated function values at the points x of the mixing density</p>
</td></tr> 
<tr><td><code>logLik</code></td>
<td>
<p>Log likelihood value at the proposed solution</p>
</td></tr> 
<tr><td><code>dy</code></td>
<td>
<p>Bayes Rule estimates of mixing parameter</p>
</td></tr> 
<tr><td><code>status</code></td>
<td>
<p>exit code from the optimizer</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Roger Koenker and Jiaying Gu
</p>


<h3>References</h3>

<p>Kiefer, J. and J. Wolfowitz Consistency of the Maximum
Likelihood Estimator in the Presence of Infinitely Many Incidental
Parameters <em>Ann. Math. Statist</em>. Volume 27, Number 4 (1956), 887-906.
</p>
<p>Koenker, R. and J. Gu, (2017) REBayes: An R Package for Empirical Bayes Mixture Methods,
<em>Journal of Statistical Software</em>, 82, 1&ndash;26.
</p>


<h3>See Also</h3>

<p><code>Gompertzmix</code>
</p>

<hr>
<h2 id='WGLVmix'>Weighted NPMLE of Longitudinal Gaussian Mean and Variances Model</h2><span id='topic+WGLVmix'></span>

<h3>Description</h3>

<p>A Kiefer-Wolfowitz procedure for ML estimation of a Gaussian model with
dependent mean and variance components and weighted longitudinal data.
This version assumes a general bivariate distribution for the mixing
distribution. The defaults use a rather coarse bivariate gridding.
In contrast to the function <code>GLVmix</code> the full longitudinal data
structure is required for this function and the likelihood evaluation
reflects this difference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WGLVmix(y, id, w, u = 30, v = 30, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WGLVmix_+3A_y">y</code></td>
<td>
<p>A vector of observations</p>
</td></tr>
<tr><td><code id="WGLVmix_+3A_id">id</code></td>
<td>
<p>A strata indicator vector of the same length</p>
</td></tr>
<tr><td><code id="WGLVmix_+3A_w">w</code></td>
<td>
<p>A vector of weights</p>
</td></tr>
<tr><td><code id="WGLVmix_+3A_u">u</code></td>
<td>
<p>A vector of bin boundaries for the mean effects</p>
</td></tr>
<tr><td><code id="WGLVmix_+3A_v">v</code></td>
<td>
<p>A vector of bin boundaries for the variance effects</p>
</td></tr>
<tr><td><code id="WGLVmix_+3A_...">...</code></td>
<td>
<p>optional parameters to be passed to KWDual to control optimization</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list consisting of the following components: 
</p>
<table>
<tr><td><code>u</code></td>
<td>
<p>midpoints of mean bin boundaries</p>
</td></tr> 
<tr><td><code>v</code></td>
<td>
<p>midpoints of variance bin boundaries</p>
</td></tr> 
<tr><td><code>fuv</code></td>
<td>
<p>the function values of the mixing density.</p>
</td></tr> 
<tr><td><code>logLik</code></td>
<td>
<p>log likelihood value for mean problem</p>
</td></tr> 
<tr><td><code>du</code></td>
<td>
<p>Bayes rule estimate of the mixing density means.</p>
</td></tr> 
<tr><td><code>dv</code></td>
<td>
<p>Bayes rule estimate of the mixing density variances.</p>
</td></tr> 
<tr><td><code>A</code></td>
<td>
<p>Constraint matrix</p>
</td></tr> 
<tr><td><code>status</code></td>
<td>
<p>Mosek convergence status</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Koenker and J. Gu
</p>


<h3>References</h3>

<p>Gu, J. and R. Koenker (2014) Heterogeneous Income Dynamics: An
Empirical Bayes Perspective, <em>JBES</em>,35, 1-16. 
</p>
<p>Koenker, R. and J. Gu, (2017) REBayes: An R Package for Empirical Bayes Mixture Methods,
<em>Journal of Statistical Software</em>, 82, 1&ndash;26.
</p>


<h3>See Also</h3>

<p>WTLVmix for an implementation assuming independent heterogeneity,
GLVmix for an implementation that assumes the availability of only the summary 
statistics but not the full longitudinal data structure.
</p>

<hr>
<h2 id='WGVmix'>WGVmix: Weighted Generalized Maximum Likelihood for Empirical Bayes
Estimation of Gamma Variances</h2><span id='topic+WGVmix'></span>

<h3>Description</h3>

<p>A Kiefer-Wolfowitz procedure for ML estimation of a Gaussian model with
independent variance components with weighted longitudinal data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WGVmix(
  y,
  id,
  w,
  v,
  pv = 300,
  eps = 1e-06,
  rtol = 1e-06,
  verb = 0,
  control = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WGVmix_+3A_y">y</code></td>
<td>
<p>A vector of observations</p>
</td></tr>
<tr><td><code id="WGVmix_+3A_id">id</code></td>
<td>
<p>A strata indicator vector of the same length</p>
</td></tr>
<tr><td><code id="WGVmix_+3A_w">w</code></td>
<td>
<p>A vector of weights</p>
</td></tr>
<tr><td><code id="WGVmix_+3A_v">v</code></td>
<td>
<p>A vector of bin boundaries for the variance effects</p>
</td></tr>
<tr><td><code id="WGVmix_+3A_pv">pv</code></td>
<td>
<p>The number of variance effect bins, if u is missing</p>
</td></tr>
<tr><td><code id="WGVmix_+3A_eps">eps</code></td>
<td>
<p>A tolerance for determining the support of the bins</p>
</td></tr>
<tr><td><code id="WGVmix_+3A_rtol">rtol</code></td>
<td>
<p>A tolerance for determining duality gap convergence tolerance in
Mosek</p>
</td></tr>
<tr><td><code id="WGVmix_+3A_verb">verb</code></td>
<td>
<p>A flag indicating how verbose the Mosek output should be</p>
</td></tr>
<tr><td><code id="WGVmix_+3A_control">control</code></td>
<td>
<p>Mosek control list see KWDual documentation</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See Gu and Koenker (2012?)
</p>


<h3>Value</h3>

<p>An object of class <code>density</code> consisting of the following
components: </p>
<table>
<tr><td><code>x</code></td>
<td>
<p>the variance bin boundaries</p>
</td></tr> <tr><td><code>y</code></td>
<td>
<p>the function
values of the mixing density for the variances. </p>
</td></tr> <tr><td><code>logLik</code></td>
<td>
<p>the value of
the log likelihood at the solution</p>
</td></tr> <tr><td><code>status</code></td>
<td>
<p>the mosek convergence
status.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Koenker
</p>


<h3>References</h3>

<p>Gu Y. and R. Koenker (2017) Empirical Bayesball Remixed:  Empirical
Bayes Methods for Longitudinal Data, <em>J. of Applied Econometrics</em>, 32, 575-599.
</p>
<p>Koenker, R. and J. Gu, (2017) REBayes: An R Package for Empirical Bayes Mixture Methods,
<em>Journal of Statistical Software</em>, 82, 1&ndash;26.
</p>

<hr>
<h2 id='WLVmix'>NPMLE for Longitudinal Gaussian Means and Variances Model with Independent Prior</h2><span id='topic+WLVmix'></span>

<h3>Description</h3>

<p>A Kiefer-Wolfowitz NPMLE procedure for estimation of a Gaussian model with
independent mean and variance prior components with weighted longitudinal data.
This version iterates back and forth from Gamma and Gaussian forms of the likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WLVmix(y, id, w, u = 300, v = 300, eps = 1e-04, maxit = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WLVmix_+3A_y">y</code></td>
<td>
<p>A vector of observations</p>
</td></tr>
<tr><td><code id="WLVmix_+3A_id">id</code></td>
<td>
<p>A strata indicator vector indicating grouping of y</p>
</td></tr>
<tr><td><code id="WLVmix_+3A_w">w</code></td>
<td>
<p>A vector of weights corresponding to y</p>
</td></tr>
<tr><td><code id="WLVmix_+3A_u">u</code></td>
<td>
<p>A vector of bin boundaries for the mean effects</p>
</td></tr>
<tr><td><code id="WLVmix_+3A_v">v</code></td>
<td>
<p>A vector of bin boundaries for the variance effects</p>
</td></tr>
<tr><td><code id="WLVmix_+3A_eps">eps</code></td>
<td>
<p>Convergence tolerance for iterations</p>
</td></tr>
<tr><td><code id="WLVmix_+3A_maxit">maxit</code></td>
<td>
<p>A limit on the number of allowed iterations</p>
</td></tr>
<tr><td><code id="WLVmix_+3A_...">...</code></td>
<td>
<p>optional parameters to be passed to KWDual to control optimization</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list consisting of the following components: 
</p>
<table>
<tr><td><code>u</code></td>
<td>
<p>midpoints of the mean bin boundaries</p>
</td></tr> 
<tr><td><code>fu</code></td>
<td>
<p>the function values of the mixing density of the means </p>
</td></tr> 
<tr><td><code>v</code></td>
<td>
<p>midpoints of the variance bin boundaries</p>
</td></tr> 
<tr><td><code>fv</code></td>
<td>
<p>the function values of the mixing density of the variances.</p>
</td></tr> 
<tr><td><code>logLik</code></td>
<td>
<p>vector of log likelihood values for each iteration</p>
</td></tr> 
<tr><td><code>du</code></td>
<td>
<p>Bayes rule estimate of the mixing density means.</p>
</td></tr> 
<tr><td><code>dv</code></td>
<td>
<p>Bayes rule estimate of the mixing density variances.</p>
</td></tr> 
<tr><td><code>status</code></td>
<td>
<p>Mosek convergence status for each iteration</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>J. Gu and R. Koenker
</p>


<h3>References</h3>

<p>Gu, J. and R. Koenker (2015)  Empirical Bayesball Remixed:  Empirical
Bayes Methods for Longitudinal Data, <em>J. Applied Econometrics</em>, 32, 575-599.
</p>
<p>Koenker, R. and J. Gu, (2017) REBayes: An R Package for Empirical Bayes Mixture Methods,
<em>Journal of Statistical Software</em>, 82, 1&ndash;26.
</p>


<h3>See Also</h3>

<p>WGLVmix for a more general bivariate mixing distribution version and
WTLVmix for an alternative estimator exploiting a Student/Gamma decomposition
</p>

<hr>
<h2 id='WTLVmix'>NPMLE for Longitudinal Gaussian Means and Variances Model</h2><span id='topic+WTLVmix'></span>

<h3>Description</h3>

<p>A Kiefer-Wolfowitz NPMLE procedure for estimation of a Gaussian model with
independent mean and variance components with weighted longitudinal data.
This version exploits a Student t decomposition of the likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WTLVmix(y, id, w, u = 300, v = 300, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WTLVmix_+3A_y">y</code></td>
<td>
<p>A vector of observations</p>
</td></tr>
<tr><td><code id="WTLVmix_+3A_id">id</code></td>
<td>
<p>A strata indicator vector indicating grouping of y</p>
</td></tr>
<tr><td><code id="WTLVmix_+3A_w">w</code></td>
<td>
<p>A vector of weights corresponding to y</p>
</td></tr>
<tr><td><code id="WTLVmix_+3A_u">u</code></td>
<td>
<p>A vector of bin boundaries for the mean effects</p>
</td></tr>
<tr><td><code id="WTLVmix_+3A_v">v</code></td>
<td>
<p>A vector of bin boundaries for the variance effects</p>
</td></tr>
<tr><td><code id="WTLVmix_+3A_...">...</code></td>
<td>
<p>optional parameters to be passed to KWDual to control optimization</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list consisting of the following components: 
</p>
<table>
<tr><td><code>u</code></td>
<td>
<p>midpoints of the mean bin boundaries</p>
</td></tr> 
<tr><td><code>fu</code></td>
<td>
<p>the function values of the mixing density of the means </p>
</td></tr> 
<tr><td><code>v</code></td>
<td>
<p>midpoints of the variance bin boundaries</p>
</td></tr> 
<tr><td><code>fv</code></td>
<td>
<p>the function values of the mixing density of the variances.</p>
</td></tr> 
<tr><td><code>logLik</code></td>
<td>
<p>log likelihood value for mean problem</p>
</td></tr> 
<tr><td><code>du</code></td>
<td>
<p>Bayes rule estimate of the mixing density means.</p>
</td></tr> 
<tr><td><code>dv</code></td>
<td>
<p>Bayes rule estimate of the mixing density variances.</p>
</td></tr> 
<tr><td><code>status</code></td>
<td>
<p>Mosek convergence status</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>J. Gu and R. Koenker
</p>


<h3>References</h3>

<p>Koenker, R. and J. Gu, (2017) REBayes: An R Package for Empirical 
Bayes Mixture Methods, <em>Journal of Statistical Software</em>, 82, 1&ndash;26.
</p>


<h3>See Also</h3>

<p>WGLVmix for a more general bivariate mixing distribution version
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
