<!DOCTYPE html><html lang="en"><head><title>Help for package plsVarSel</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {plsVarSel}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bve_pls'><p>Backward variable elimination PLS (BVE-PLS)</p></a></li>
<li><a href='#covSel'><p>Covariance Selection - CovSel</p></a></li>
<li><a href='#filterPLSR'><p>Optimisation of filters for Partial Least Squares</p></a></li>
<li><a href='#ga_pls'><p>Genetic algorithm combined with PLS regression (GA-PLS)</p></a></li>
<li><a href='#ipw_pls'><p>Iterative predictor weighting PLS (IPW-PLS)</p></a></li>
<li><a href='#lda_from_pls'><p>LDA/QDA classification from PLS model</p></a></li>
<li><a href='#lda_from_pls_cv'><p>Cross-validated LDA/QDA classification from PLS model</p></a></li>
<li><a href='#mcuve_pls'><p>Uninformative variable elimination in PLS (UVE-PLS)</p></a></li>
<li><a href='#mvrV'><p>Multivariate regression function</p></a></li>
<li><a href='#myImagePlot'><p>Matrix plotting</p></a></li>
<li><a href='#plsVarSel'><p>Variable selection in Partial Least Squares</p></a></li>
<li><a href='#rep_pls'><p>Regularized elimination procedure in PLS</p></a></li>
<li><a href='#setDA'><p>Set chosen Discriminant Analysis</p></a></li>
<li><a href='#shaving'><p>Repeated shaving of variables</p></a></li>
<li><a href='#simulate_classes'><p>Simulate classes</p></a></li>
<li><a href='#spa_pls'><p>Sub-window permutation analysis coupled with PLS (SwPA-PLS)</p></a></li>
<li><a href='#stpls'><p>Soft-Threshold PLS (ST-PLS)</p></a></li>
<li><a href='#summary.mvrV'><p>Summary method for stpls and trunc</p></a></li>
<li><a href='#T2_pls'><p>Hotelling's T^2 based variable selection in PLS &ndash; T^2-PLS)</p></a></li>
<li><a href='#truncation'><p>Trunction PLS</p></a></li>
<li><a href='#VIP'><p>Filter methods for variable selection with Partial Least Squares.</p></a></li>
<li><a href='#WVC_pls'><p>Weighted Variable Contribution in PLS (WVC-PLS)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Variable Selection in Partial Least Squares</td>
</tr>
<tr>
<td>Version:</td>
<td>0.9.12</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-05-22</td>
</tr>
<tr>
<td>Description:</td>
<td>Interfaces and methods for variable selection in Partial Least
    Squares. The methods include filter methods, wrapper methods and embedded
    methods. Both regression and classification is supported.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/khliland/plsVarSel/">https://github.com/khliland/plsVarSel/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/khliland/plsVarSel/issues/">https://github.com/khliland/plsVarSel/issues/</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>pls</td>
</tr>
<tr>
<td>Imports:</td>
<td>grDevices, graphics, genalg, mvtnorm, bdsmatrix, MASS,
progress, parallel, stats, praznik</td>
</tr>
<tr>
<td>Suggests:</td>
<td>Rmpi</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-05-22 11:07:56 UTC; kristian</td>
</tr>
<tr>
<td>Author:</td>
<td>Kristian Hovde Liland
    <a href="https://orcid.org/0000-0001-6468-9423"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Tahir Mehmood [ctb],
  Solve Sæbø [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kristian Hovde Liland &lt;kristian.liland@nmbu.no&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-05-22 11:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='bve_pls'>Backward variable elimination PLS (BVE-PLS)</h2><span id='topic+bve_pls'></span>

<h3>Description</h3>

<p>A backward variable elimination procedure for elimination
of non informative variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bve_pls(y, X, ncomp = 10, ratio = 0.75, VIP.threshold = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bve_pls_+3A_y">y</code></td>
<td>
<p>vector of response values (<code>numeric</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="bve_pls_+3A_x">X</code></td>
<td>
<p>numeric predictor <code>matrix</code>.</p>
</td></tr>
<tr><td><code id="bve_pls_+3A_ncomp">ncomp</code></td>
<td>
<p>integer number of components (default = 10).</p>
</td></tr>
<tr><td><code id="bve_pls_+3A_ratio">ratio</code></td>
<td>
<p>the proportion of the samples to use for calibration (default = 0.75).</p>
</td></tr>
<tr><td><code id="bve_pls_+3A_vip.threshold">VIP.threshold</code></td>
<td>
<p>thresholding to remove non-important variables (default = 1).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Variables are first sorted with respect to some importancemeasure, 
and usually one of the filter measures described above are used. Secondly, a 
threshold is used to eliminate a subset of the least informative variables. Then
a model is fitted again to the remaining variables and performance is measured. 
The procedure is repeated until maximum model performance is achieved.
</p>


<h3>Value</h3>

<p>Returns a vector of variable numbers corresponding to the model 
having lowest prediction error.
</p>


<h3>Author(s)</h3>

<p>Tahir Mehmood, Kristian Hovde Liland, Solve Sæbø.
</p>


<h3>References</h3>

<p>I. Frank, Intermediate least squares regression method, Chemometrics and
Intelligent Laboratory Systems 1 (3) (1987) 233-242.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VIP">VIP</a></code> (SR/sMC/LW/RC), <code><a href="#topic+filterPLSR">filterPLSR</a></code>, <code><a href="#topic+shaving">shaving</a></code>, 
<code><a href="#topic+stpls">stpls</a></code>, <code><a href="#topic+truncation">truncation</a></code>,
<code><a href="#topic+bve_pls">bve_pls</a></code>, <code><a href="#topic+ga_pls">ga_pls</a></code>, <code><a href="#topic+ipw_pls">ipw_pls</a></code>, <code><a href="#topic+mcuve_pls">mcuve_pls</a></code>,
<code><a href="#topic+rep_pls">rep_pls</a></code>, <code><a href="#topic+spa_pls">spa_pls</a></code>,
<code><a href="#topic+lda_from_pls">lda_from_pls</a></code>, <code><a href="#topic+lda_from_pls_cv">lda_from_pls_cv</a></code>, <code><a href="#topic+setDA">setDA</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gasoline, package = "pls")
with( gasoline, bve_pls(octane, NIR) )

</code></pre>

<hr>
<h2 id='covSel'>Covariance Selection - CovSel</h2><span id='topic+covSel'></span>

<h3>Description</h3>

<p>Sequential selection of variables based on squared covariance
with response and intermediate deflation (as in Partial Least Squares).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>covSel(X, Y, nvar)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="covSel_+3A_x">X</code></td>
<td>
<p><code>matrix</code> of input variables</p>
</td></tr>
<tr><td><code id="covSel_+3A_y">Y</code></td>
<td>
<p><code>matrix</code> of response variable(s)</p>
</td></tr>
<tr><td><code id="covSel_+3A_nvar">nvar</code></td>
<td>
<p>maximum number of variables</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>selected</code></td>
<td>
<p>an integer vector of selected variables</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>
<p>a matrix of score vectors</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>a matrix of loading vectors</p>
</td></tr>
<tr><td><code>Yloadings</code></td>
<td>
<p>a matrix of Y loadings</p>
</td></tr>
</table>


<h3>References</h3>

<p>J.M. Roger, B. Palagos, D. Bertrand, E. Fernandez-Ahumada. CovSel: Variable selection for highly multivariate and multi-response calibration: Application to IR spectroscopy. Chemom Intel Lab Syst. 2011;106(2):216-223.
P. Mishra, A brief note on a new faster covariate's selection (fCovSel) algorithm, Journal of Chemometrics 36(5) 2022.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gasoline, package = "pls")
sels &lt;- with(gasoline, covSel(NIR, octane, 5))
matplot(t(gasoline$NIR), type = "l")
abline(v = sels$selected, col = 2)
</code></pre>

<hr>
<h2 id='filterPLSR'>Optimisation of filters for Partial Least Squares</h2><span id='topic+filterPLSR'></span>

<h3>Description</h3>

<p>Extract the index of influential variables based on threshold defiend for
LW (loading weights), RC (regression coef), JT (jackknife testing) and VIP (variable 
importance on projection).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>filterPLSR(
  y,
  X,
  ncomp = 10,
  ncomp.opt = c("minimum", "same"),
  validation = "LOO",
  LW.threshold = NULL,
  RC.threshold = NULL,
  URC.threshold = NULL,
  FRC.threshold = NULL,
  JT.threshold = NULL,
  VIP.threshold = NULL,
  SR.threshold = NULL,
  sMC.threshold = NULL,
  mRMR.threshold = NULL,
  WVC.threshold = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="filterPLSR_+3A_y">y</code></td>
<td>
<p>vector of response values (<code>numeric</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="filterPLSR_+3A_x">X</code></td>
<td>
<p>numeric predictor <code>matrix</code>.</p>
</td></tr>
<tr><td><code id="filterPLSR_+3A_ncomp">ncomp</code></td>
<td>
<p>integer number of components (default = 10).</p>
</td></tr>
<tr><td><code id="filterPLSR_+3A_ncomp.opt">ncomp.opt</code></td>
<td>
<p>use the number of components corresponding to minimum error (minimum)
or <code>ncomp</code> (same).</p>
</td></tr>
<tr><td><code id="filterPLSR_+3A_validation">validation</code></td>
<td>
<p>type of validation in the PLS modelling (default = &quot;LOO&quot;).</p>
</td></tr>
<tr><td><code id="filterPLSR_+3A_lw.threshold">LW.threshold</code></td>
<td>
<p>threshold for Loading Weights if applied (default = NULL).</p>
</td></tr>
<tr><td><code id="filterPLSR_+3A_rc.threshold">RC.threshold</code></td>
<td>
<p>threshold for Regression Coefficients if applied (default = NULL).</p>
</td></tr>
<tr><td><code id="filterPLSR_+3A_urc.threshold">URC.threshold</code></td>
<td>
<p>threshold for Unit normalized Regression Coefficients if applied (default = NULL).</p>
</td></tr>
<tr><td><code id="filterPLSR_+3A_frc.threshold">FRC.threshold</code></td>
<td>
<p>threshold for Fitness normalized Regression Coefficients if applied (default = NULL).</p>
</td></tr>
<tr><td><code id="filterPLSR_+3A_jt.threshold">JT.threshold</code></td>
<td>
<p>threshold for Jackknife Testing if applied (default = NULL).</p>
</td></tr>
<tr><td><code id="filterPLSR_+3A_vip.threshold">VIP.threshold</code></td>
<td>
<p>threshold for Variable Importance on Projections if applied (default = NULL).</p>
</td></tr>
<tr><td><code id="filterPLSR_+3A_sr.threshold">SR.threshold</code></td>
<td>
<p>threshold for Selectivity Ration if applied (default = NULL).</p>
</td></tr>
<tr><td><code id="filterPLSR_+3A_smc.threshold">sMC.threshold</code></td>
<td>
<p>threshold for Significance Multivariate Correlation if applied (default = NULL).</p>
</td></tr>
<tr><td><code id="filterPLSR_+3A_mrmr.threshold">mRMR.threshold</code></td>
<td>
<p>threshold for minimum Redundancy Maximum Releveance if applied (default = NULL).</p>
</td></tr>
<tr><td><code id="filterPLSR_+3A_wvc.threshold">WVC.threshold</code></td>
<td>
<p>threshold for Weighted Variable Contribution if applied (default = NULL).</p>
</td></tr>
<tr><td><code id="filterPLSR_+3A_...">...</code></td>
<td>
<p>additional paramters for <code>pls</code>, e.g. segmentation or similar.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Filter methods are applied for variable selection with PLSR. This function can 
return selected variables and Root Mean Squared Error of Cross-Validation for various 
filter methods and determine optimum numbers of components.
</p>


<h3>Value</h3>

<p>Returns a list of lists containing filters (outer list), their selected variables,
optimal numbers of components and prediction accuracies.
</p>


<h3>Author(s)</h3>

<p>Tahir Mehmood, Kristian Hovde Liland, Solve Sæbø.
</p>


<h3>References</h3>

<p>T. Mehmood, K.H. Liland, L. Snipen, S. Sæbø, A review of variable selection 
methods in Partial Least Squares Regression, Chemometrics and Intelligent Laboratory Systems
118 (2012) 62-69.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VIP">VIP</a></code> (SR/sMC/LW/RC/URC/FRC/mRMR), <code><a href="#topic+filterPLSR">filterPLSR</a></code>, <code><a href="#topic+spa_pls">spa_pls</a></code>, 
<code><a href="#topic+stpls">stpls</a></code>, <code><a href="#topic+truncation">truncation</a></code>, <code><a href="#topic+bve_pls">bve_pls</a></code>, <code><a href="#topic+mcuve_pls">mcuve_pls</a></code>,
<code><a href="#topic+ipw_pls">ipw_pls</a></code>, <code><a href="#topic+ga_pls">ga_pls</a></code>, <code><a href="#topic+rep_pls">rep_pls</a></code>, <code><a href="#topic+WVC_pls">WVC_pls</a></code>, <code><a href="#topic+T2_pls">T2_pls</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gasoline, package = "pls")
## Not run: 
with( gasoline, filterPLSR(octane, NIR, ncomp = 10, "minimum", validation = "LOO",
 RC.threshold = c(0.1,0.5), SR.threshold = 0.5))

## End(Not run)

</code></pre>

<hr>
<h2 id='ga_pls'>Genetic algorithm combined with PLS regression (GA-PLS)</h2><span id='topic+ga_pls'></span>

<h3>Description</h3>

<p>A subset search algorithm inspired by biological
evolution theory and natural selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ga_pls(y, X, GA.threshold = 10, iters = 5, popSize = 100)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ga_pls_+3A_y">y</code></td>
<td>
<p>vector of response values (<code>numeric</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="ga_pls_+3A_x">X</code></td>
<td>
<p>numeric predictor <code>matrix</code>.</p>
</td></tr>
<tr><td><code id="ga_pls_+3A_ga.threshold">GA.threshold</code></td>
<td>
<p>the change for a zero for mutations and initialization (default = 10). (The ratio of non-selected variables for each chromosome.)</p>
</td></tr>
<tr><td><code id="ga_pls_+3A_iters">iters</code></td>
<td>
<p>the number of iterations (default = 5).</p>
</td></tr>
<tr><td><code id="ga_pls_+3A_popsize">popSize</code></td>
<td>
<p>the population size (default = 100).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>1. Building an initial population of variable sets by setting bits for each variable
randomly, where bit '1' represents selection of corresponding variable while '0' presents
non-selection. The approximate size of the variable sets must be set in advance.
</p>
<p>2. Fitting a PLSR-model to each variable set and computing the performance by, for instance,
a leave one out cross-validation procedure.
</p>
<p>3. A collection of variable sets with higher performance are selected to survive until the
next &quot;generation&quot;.
</p>
<p>4. Crossover and mutation: new variable sets are formed 1) by crossover of selected
variables between the surviving variable sets, and 2) by changing (mutating) the bit
value for each variable by small probability.
</p>
<p>5. The surviving and modified variable sets form the population serving as input to point 2.
</p>


<h3>Value</h3>

<p>Returns a vector of variable numbers corresponding to the model 
having lowest prediction error.
</p>


<h3>Author(s)</h3>

<p>Tahir Mehmood, Kristian Hovde Liland, Solve Sæbø.
</p>


<h3>References</h3>

<p>K. Hasegawa, Y. Miyashita, K. Funatsu, GA strategy for variable selection
in QSAR studies: GA-based PLS analysis of calcium channel antagonists, Journal of Chemical
Information and Computer Sciences 37 (1997) 306-310.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VIP">VIP</a></code> (SR/sMC/LW/RC), <code><a href="#topic+filterPLSR">filterPLSR</a></code>, <code><a href="#topic+shaving">shaving</a></code>, 
<code><a href="#topic+stpls">stpls</a></code>, <code><a href="#topic+truncation">truncation</a></code>,
<code><a href="#topic+bve_pls">bve_pls</a></code>, <code><a href="#topic+ga_pls">ga_pls</a></code>, <code><a href="#topic+ipw_pls">ipw_pls</a></code>, <code><a href="#topic+mcuve_pls">mcuve_pls</a></code>,
<code><a href="#topic+rep_pls">rep_pls</a></code>, <code><a href="#topic+spa_pls">spa_pls</a></code>,
<code><a href="#topic+lda_from_pls">lda_from_pls</a></code>, <code><a href="#topic+lda_from_pls_cv">lda_from_pls_cv</a></code>, <code><a href="#topic+setDA">setDA</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gasoline, package = "pls")
# with( gasoline, ga_pls(octane, NIR, GA.threshold = 10) ) # Time-consuming

</code></pre>

<hr>
<h2 id='ipw_pls'>Iterative predictor weighting PLS (IPW-PLS)</h2><span id='topic+ipw_pls'></span><span id='topic+ipw_pls_legacy'></span>

<h3>Description</h3>

<p>An iterative procedure for variable elimination.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ipw_pls(
  y,
  X,
  ncomp = 10,
  no.iter = 10,
  IPW.threshold = 0.01,
  filter = "RC",
  scale = TRUE
)

ipw_pls_legacy(y, X, ncomp = 10, no.iter = 10, IPW.threshold = 0.1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ipw_pls_+3A_y">y</code></td>
<td>
<p>vector of response values (<code>numeric</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="ipw_pls_+3A_x">X</code></td>
<td>
<p>numeric predictor <code>matrix</code>.</p>
</td></tr>
<tr><td><code id="ipw_pls_+3A_ncomp">ncomp</code></td>
<td>
<p>integer number of components (default = 10).</p>
</td></tr>
<tr><td><code id="ipw_pls_+3A_no.iter">no.iter</code></td>
<td>
<p>the number of iterations (default = 10).</p>
</td></tr>
<tr><td><code id="ipw_pls_+3A_ipw.threshold">IPW.threshold</code></td>
<td>
<p>threshold for regression coefficients (default = 0.1).</p>
</td></tr>
<tr><td><code id="ipw_pls_+3A_filter">filter</code></td>
<td>
<p>which filtering method to use (among &quot;RC&quot;, &quot;SR&quot;, &quot;LW&quot;, &quot;VIP&quot;, &quot;sMC&quot;)</p>
</td></tr>
<tr><td><code id="ipw_pls_+3A_scale">scale</code></td>
<td>
<p>standardize data (default=TRUE, as in reference)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is an iterative elimination procedure where a measure of predictor 
importance is computed after fitting a PLSR model (with complexity chosen based
on predictive performance). The importance measure is used both to re-scale the 
original X-variables and to eliminate the least important variables before
subsequent model re-fitting
</p>
<p>The IPW implementation was corrected in <code>plsVarSel</code> version 0.9.5. For backward
compatibility the old implementation is included as <code>ipw_pls_legacy</code>.
</p>


<h3>Value</h3>

<p>Returns a vector of variable numbers corresponding to the model 
having lowest prediction error.
</p>


<h3>Author(s)</h3>

<p>Kristian Hovde Liland
</p>


<h3>References</h3>

<p>M. Forina, C. Casolino, C. Pizarro Millan, Iterative predictor weighting
(IPW) PLS: a technique for the elimination of useless predictors in regression problems,
Journal of Chemometrics 13 (1999) 165-184.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VIP">VIP</a></code> (SR/sMC/LW/RC), <code><a href="#topic+filterPLSR">filterPLSR</a></code>, <code><a href="#topic+shaving">shaving</a></code>, 
<code><a href="#topic+stpls">stpls</a></code>, <code><a href="#topic+truncation">truncation</a></code>,
<code><a href="#topic+bve_pls">bve_pls</a></code>, <code><a href="#topic+ga_pls">ga_pls</a></code>, <code><a href="#topic+ipw_pls">ipw_pls</a></code>, <code><a href="#topic+mcuve_pls">mcuve_pls</a></code>,
<code><a href="#topic+rep_pls">rep_pls</a></code>, <code><a href="#topic+spa_pls">spa_pls</a></code>,
<code><a href="#topic+lda_from_pls">lda_from_pls</a></code>, <code><a href="#topic+setDA">setDA</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gasoline, package = "pls")
with( gasoline, ipw_pls(octane, NIR) )

</code></pre>

<hr>
<h2 id='lda_from_pls'>LDA/QDA classification from PLS model</h2><span id='topic+lda_from_pls'></span>

<h3>Description</h3>

<p>For each number of components LDA/QDA models are created from the 
scores of the supplied PLS model and classifications are performed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lda_from_pls(model, grouping, newdata, ncomp)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lda_from_pls_+3A_model">model</code></td>
<td>
<p><code>pls</code> model fitted with the <code>pls</code> package</p>
</td></tr>
<tr><td><code id="lda_from_pls_+3A_grouping">grouping</code></td>
<td>
<p>vector of grouping labels</p>
</td></tr>
<tr><td><code id="lda_from_pls_+3A_newdata">newdata</code></td>
<td>
<p>predictors in the same format as in the <code>pls</code> model</p>
</td></tr>
<tr><td><code id="lda_from_pls_+3A_ncomp">ncomp</code></td>
<td>
<p>maximum number of PLS components</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix of classifications
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VIP">VIP</a></code> (SR/sMC/LW/RC), <code><a href="#topic+filterPLSR">filterPLSR</a></code>, <code><a href="#topic+shaving">shaving</a></code>, 
<code><a href="#topic+stpls">stpls</a></code>, <code><a href="#topic+truncation">truncation</a></code>,
<code><a href="#topic+bve_pls">bve_pls</a></code>, <code><a href="#topic+ga_pls">ga_pls</a></code>, <code><a href="#topic+ipw_pls">ipw_pls</a></code>, <code><a href="#topic+mcuve_pls">mcuve_pls</a></code>,
<code><a href="#topic+rep_pls">rep_pls</a></code>, <code><a href="#topic+spa_pls">spa_pls</a></code>,
<code><a href="#topic+lda_from_pls">lda_from_pls</a></code>, <code><a href="#topic+lda_from_pls_cv">lda_from_pls_cv</a></code>, <code><a href="#topic+setDA">setDA</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(mayonnaise, package = "pls")
mayonnaise &lt;- within(mayonnaise, {dummy &lt;- model.matrix(~y-1,data.frame(y=factor(oil.type)))})
pls &lt;- plsr(dummy ~ NIR, ncomp = 10, data = mayonnaise, subset = train)
with(mayonnaise, {
 classes &lt;- lda_from_pls(pls, oil.type[train], NIR[!train,], 10)
 colSums(oil.type[!train] == classes) # Number of correctly classified out of 42
})

</code></pre>

<hr>
<h2 id='lda_from_pls_cv'>Cross-validated LDA/QDA classification from PLS model</h2><span id='topic+lda_from_pls_cv'></span>

<h3>Description</h3>

<p>For each number of components LDA/QDA models are created from the 
scores of the supplied PLS model and classifications are performed.
This use of cross-validation has limitations. Handle with care!
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lda_from_pls_cv(model, X, y, ncomp, Y.add = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lda_from_pls_cv_+3A_model">model</code></td>
<td>
<p><code>pls</code> model fitted with the <code>pls</code> package</p>
</td></tr>
<tr><td><code id="lda_from_pls_cv_+3A_x">X</code></td>
<td>
<p>predictors in the same format as in the <code>pls</code> model</p>
</td></tr>
<tr><td><code id="lda_from_pls_cv_+3A_y">y</code></td>
<td>
<p>vector of grouping labels</p>
</td></tr>
<tr><td><code id="lda_from_pls_cv_+3A_ncomp">ncomp</code></td>
<td>
<p>maximum number of PLS components</p>
</td></tr>
<tr><td><code id="lda_from_pls_cv_+3A_y.add">Y.add</code></td>
<td>
<p>additional responses</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix of classifications
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VIP">VIP</a></code> (SR/sMC/LW/RC), <code><a href="#topic+filterPLSR">filterPLSR</a></code>, <code><a href="#topic+shaving">shaving</a></code>, 
<code><a href="#topic+stpls">stpls</a></code>, <code><a href="#topic+truncation">truncation</a></code>,
<code><a href="#topic+bve_pls">bve_pls</a></code>, <code><a href="#topic+ga_pls">ga_pls</a></code>, <code><a href="#topic+ipw_pls">ipw_pls</a></code>, <code><a href="#topic+mcuve_pls">mcuve_pls</a></code>,
<code><a href="#topic+rep_pls">rep_pls</a></code>, <code><a href="#topic+spa_pls">spa_pls</a></code>,
<code><a href="#topic+lda_from_pls">lda_from_pls</a></code>, <code><a href="#topic+lda_from_pls_cv">lda_from_pls_cv</a></code>, <code><a href="#topic+setDA">setDA</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(mayonnaise, package = "pls")
mayonnaise &lt;- within(mayonnaise, {dummy &lt;- model.matrix(~y-1,data.frame(y=factor(oil.type)))})
pls &lt;- plsr(dummy ~ NIR, ncomp = 8, data = mayonnaise, subset = train, 
            validation = "CV", segments = 40, segment.type = "consecutive")
with(mayonnaise, {
 classes &lt;- lda_from_pls_cv(pls, NIR[train,], oil.type[train], 8)
 colSums(oil.type[train] == classes) # Number of correctly classified out of 120
})

</code></pre>

<hr>
<h2 id='mcuve_pls'>Uninformative variable elimination in PLS (UVE-PLS)</h2><span id='topic+mcuve_pls'></span>

<h3>Description</h3>

<p>Artificial noise variables are added to the predictor set before the PLSR 
model is fitted. All the original variables having lower &quot;importance&quot; than the artificial 
noise variables are eliminated before the procedure is repeated until a stop criterion is 
reached.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mcuve_pls(y, X, ncomp = 10, N = 3, ratio = 0.75, MCUVE.threshold = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mcuve_pls_+3A_y">y</code></td>
<td>
<p>vector of response values (<code>numeric</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="mcuve_pls_+3A_x">X</code></td>
<td>
<p>numeric predictor <code>matrix</code>.</p>
</td></tr>
<tr><td><code id="mcuve_pls_+3A_ncomp">ncomp</code></td>
<td>
<p>integer number of components (default = 10).</p>
</td></tr>
<tr><td><code id="mcuve_pls_+3A_n">N</code></td>
<td>
<p>number of samples Mone Carlo simulations (default = 3).</p>
</td></tr>
<tr><td><code id="mcuve_pls_+3A_ratio">ratio</code></td>
<td>
<p>the proportion of the samples to use for calibration (default = 0.75).</p>
</td></tr>
<tr><td><code id="mcuve_pls_+3A_mcuve.threshold">MCUVE.threshold</code></td>
<td>
<p>thresholding separate signal from noise (default = NA creates 
automatic threshold from data).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector of variable numbers corresponding to the model 
having lowest prediction error.
</p>


<h3>Author(s)</h3>

<p>Tahir Mehmood, Kristian Hovde Liland, Solve Sæbø.
</p>


<h3>References</h3>

<p>V. Centner, D. Massart, O. de Noord, S. de Jong, B. Vandeginste, C. Sterna, 
Elimination of uninformative variables for multivariate calibration, Analytical Chemistry 
68 (1996) 3851-3858.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VIP">VIP</a></code> (SR/sMC/LW/RC), <code><a href="#topic+filterPLSR">filterPLSR</a></code>, <code><a href="#topic+shaving">shaving</a></code>, 
<code><a href="#topic+stpls">stpls</a></code>, <code><a href="#topic+truncation">truncation</a></code>,
<code><a href="#topic+bve_pls">bve_pls</a></code>, <code><a href="#topic+ga_pls">ga_pls</a></code>, <code><a href="#topic+ipw_pls">ipw_pls</a></code>, <code><a href="#topic+mcuve_pls">mcuve_pls</a></code>,
<code><a href="#topic+rep_pls">rep_pls</a></code>, <code><a href="#topic+spa_pls">spa_pls</a></code>,
<code><a href="#topic+lda_from_pls">lda_from_pls</a></code>, <code><a href="#topic+lda_from_pls_cv">lda_from_pls_cv</a></code>, <code><a href="#topic+setDA">setDA</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gasoline, package = "pls")
with( gasoline, mcuve_pls(octane, NIR) )

</code></pre>

<hr>
<h2 id='mvrV'>Multivariate regression function</h2><span id='topic+mvrV'></span>

<h3>Description</h3>

<p>Adaptation of <code>mvr</code> from package <code>pls</code> v 2.4.3.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvrV(
  formula,
  ncomp,
  Y.add,
  data,
  subset,
  na.action,
  shrink,
  method = c("truncation", "stpls", "model.frame"),
  scale = FALSE,
  validation = c("none", "CV", "LOO"),
  model = TRUE,
  x = FALSE,
  y = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mvrV_+3A_formula">formula</code></td>
<td>
<p>a model formula. Most of the lm formula constructs are supported. See below.</p>
</td></tr>
<tr><td><code id="mvrV_+3A_ncomp">ncomp</code></td>
<td>
<p>the number of components to include in the model (see below).</p>
</td></tr>
<tr><td><code id="mvrV_+3A_y.add">Y.add</code></td>
<td>
<p>a vector or matrix of additional responses containing relevant information about the observations. Only used for cppls.</p>
</td></tr>
<tr><td><code id="mvrV_+3A_data">data</code></td>
<td>
<p>an optional data frame with the data to fit the model from.</p>
</td></tr>
<tr><td><code id="mvrV_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="mvrV_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data contain missing values. The default is set by the na.action setting of options, and is na.fail if that is unset. The 'factory-fresh' default is na.omit. Another possible value is NULL, no action. Value na.exclude can be useful. See na.omit for other alternatives.</p>
</td></tr>
<tr><td><code id="mvrV_+3A_shrink">shrink</code></td>
<td>
<p>optional shrinkage parameter for <code>stpls</code>.</p>
</td></tr>
<tr><td><code id="mvrV_+3A_method">method</code></td>
<td>
<p>the multivariate regression method to be used. If &quot;model.frame&quot;, the model frame is returned.</p>
</td></tr>
<tr><td><code id="mvrV_+3A_scale">scale</code></td>
<td>
<p>numeric vector, or logical. If numeric vector, X is scaled by dividing each variable with the corresponding element of scale. If scale is TRUE, X is scaled by dividing each variable by its sample standard deviation. If cross-validation is selected, scaling by the standard deviation is done for every segment.</p>
</td></tr>
<tr><td><code id="mvrV_+3A_validation">validation</code></td>
<td>
<p>character. What kind of (internal) validation to use. See below.</p>
</td></tr>
<tr><td><code id="mvrV_+3A_model">model</code></td>
<td>
<p>a logical. If TRUE, the model frame is returned.</p>
</td></tr>
<tr><td><code id="mvrV_+3A_x">x</code></td>
<td>
<p>a logical. If TRUE, the model matrix is returned.</p>
</td></tr>
<tr><td><code id="mvrV_+3A_y">y</code></td>
<td>
<p>a logical. If TRUE, the response is returned.</p>
</td></tr>
<tr><td><code id="mvrV_+3A_...">...</code></td>
<td>
<p>additional arguments, passed to the underlying fit functions, and mvrCv.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="pls.html#topic+mvr">mvr</a></code>
</p>

<hr>
<h2 id='myImagePlot'>Matrix plotting</h2><span id='topic+myImagePlot'></span>

<h3>Description</h3>

<p>Plot a heatmap with colorbar.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>myImagePlot(x, main, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="myImagePlot_+3A_x">x</code></td>
<td>
<p>a <code>matrix</code> to be plotted.</p>
</td></tr>
<tr><td><code id="myImagePlot_+3A_main">main</code></td>
<td>
<p>header text for the plot.</p>
</td></tr>
<tr><td><code id="myImagePlot_+3A_...">...</code></td>
<td>
<p>additional arguments (not implemented).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tahir Mehmood, Kristian Hovde Liland, Solve Sæbø.
</p>


<h3>References</h3>

<p>T. Mehmood, K.H. Liland, L. Snipen, S. Sæbø, A review of variable selection 
methods in Partial Least Squares Regression, Chemometrics and Intelligent Laboratory Systems
118 (2012) 62-69.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VIP">VIP</a></code> (SR/sMC/LW/RC), <code><a href="#topic+filterPLSR">filterPLSR</a></code>, <code><a href="#topic+shaving">shaving</a></code>, 
<code><a href="#topic+stpls">stpls</a></code>, <code><a href="#topic+truncation">truncation</a></code>,
<code><a href="#topic+bve_pls">bve_pls</a></code>, <code><a href="#topic+ga_pls">ga_pls</a></code>, <code><a href="#topic+ipw_pls">ipw_pls</a></code>, <code><a href="#topic+mcuve_pls">mcuve_pls</a></code>,
<code><a href="#topic+rep_pls">rep_pls</a></code>, <code><a href="#topic+spa_pls">spa_pls</a></code>,
<code><a href="#topic+lda_from_pls">lda_from_pls</a></code>, <code><a href="#topic+lda_from_pls_cv">lda_from_pls_cv</a></code>, <code><a href="#topic+setDA">setDA</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>myImagePlot(matrix(1:12,3,4), 'A header')

</code></pre>

<hr>
<h2 id='plsVarSel'>Variable selection in Partial Least Squares</h2><span id='topic+plsVarSel'></span>

<h3>Description</h3>

<p>A large collection of variable selection methods for use with
Partial Least Squares. These include all methods in Mehmood et al. 2012
and more. All functions treat numeric responses as regression and
factor responses as classification. Default classification is PLS + LDA, 
but <code>setDA()</code> can be used to choose PLS + QDA or PLS with response column maximization.
</p>


<h3>References</h3>

<p>T. Mehmood, K.H. Liland, L. Snipen, S. Sæbø, A review of variable selection 
methods in Partial Least Squares Regression, Chemometrics and Intelligent Laboratory Systems
118 (2012) 62-69.
T. Mehmood, S. Sæbø, K.H. Liland, Comparison of variable selection methods in partial least
squares regression, Journal of Chemometrics 34 (2020) e3226.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VIP">VIP</a></code> (SR/sMC/LW/RC), <code><a href="#topic+filterPLSR">filterPLSR</a></code>, <code><a href="#topic+shaving">shaving</a></code>, 
<code><a href="#topic+stpls">stpls</a></code>, <code><a href="#topic+truncation">truncation</a></code>,
<code><a href="#topic+bve_pls">bve_pls</a></code>, <code><a href="#topic+ga_pls">ga_pls</a></code>, <code><a href="#topic+ipw_pls">ipw_pls</a></code>, <code><a href="#topic+mcuve_pls">mcuve_pls</a></code>,
<code><a href="#topic+rep_pls">rep_pls</a></code>, <code><a href="#topic+spa_pls">spa_pls</a></code>,
<code><a href="#topic+lda_from_pls">lda_from_pls</a></code>, <code><a href="#topic+lda_from_pls_cv">lda_from_pls_cv</a></code>, <code><a href="#topic+setDA">setDA</a></code>.
</p>

<hr>
<h2 id='rep_pls'>Regularized elimination procedure in PLS</h2><span id='topic+rep_pls'></span>

<h3>Description</h3>

<p>A regularized variable elimination procedure for parsimonious
variable selection, where also a stepwise elimination is carried out
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rep_pls(y, X, ncomp = 5, ratio = 0.75, VIP.threshold = 0.5, N = 3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rep_pls_+3A_y">y</code></td>
<td>
<p>vector of response values (<code>numeric</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="rep_pls_+3A_x">X</code></td>
<td>
<p>numeric predictor <code>matrix</code>.</p>
</td></tr>
<tr><td><code id="rep_pls_+3A_ncomp">ncomp</code></td>
<td>
<p>integer number of components (default = 5).</p>
</td></tr>
<tr><td><code id="rep_pls_+3A_ratio">ratio</code></td>
<td>
<p>the proportion of the samples to use for calibration (default = 0.75).</p>
</td></tr>
<tr><td><code id="rep_pls_+3A_vip.threshold">VIP.threshold</code></td>
<td>
<p>thresholding to remove non-important variables (default = 0.5).</p>
</td></tr>
<tr><td><code id="rep_pls_+3A_n">N</code></td>
<td>
<p>number of samples in the selection matrix (default = 3).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A stability based variable selection procedure is adopted, where the
samples have been split randomly into a predefined number of training and test sets.
For each split, g, the following stepwise procedure is adopted to select the variables.
</p>


<h3>Value</h3>

<p>Returns a vector of variable numbers corresponding to the model 
having lowest prediction error.
</p>


<h3>Author(s)</h3>

<p>Tahir Mehmood, Kristian Hovde Liland, Solve Sæbø.
</p>


<h3>References</h3>

<p>T. Mehmood, H. Martens, S. Sæbø, J. Warringer, L. Snipen, A partial 
least squares based algorithm for parsimonious variable selection, Algorithms for
Molecular Biology 6 (2011).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VIP">VIP</a></code> (SR/sMC/LW/RC), <code><a href="#topic+filterPLSR">filterPLSR</a></code>, <code><a href="#topic+shaving">shaving</a></code>, 
<code><a href="#topic+stpls">stpls</a></code>, <code><a href="#topic+truncation">truncation</a></code>,
<code><a href="#topic+bve_pls">bve_pls</a></code>, <code><a href="#topic+ga_pls">ga_pls</a></code>, <code><a href="#topic+ipw_pls">ipw_pls</a></code>, <code><a href="#topic+mcuve_pls">mcuve_pls</a></code>,
<code><a href="#topic+rep_pls">rep_pls</a></code>, <code><a href="#topic+spa_pls">spa_pls</a></code>,
<code><a href="#topic+lda_from_pls">lda_from_pls</a></code>, <code><a href="#topic+lda_from_pls_cv">lda_from_pls_cv</a></code>, <code><a href="#topic+setDA">setDA</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gasoline, package = "pls")
## Not run: 
with( gasoline, rep_pls(octane, NIR) )

## End(Not run)

</code></pre>

<hr>
<h2 id='setDA'>Set chosen Discriminant Analysis</h2><span id='topic+setDA'></span>

<h3>Description</h3>

<p>The default methods is LDA, but QDA and column of maximum prediction can be chosen.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setDA(LQ = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="setDA_+3A_lq">LQ</code></td>
<td>
<p>character argument 'lda', 'qda', 'max' or NULL</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the default set method.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VIP">VIP</a></code> (SR/sMC/LW/RC), <code><a href="#topic+filterPLSR">filterPLSR</a></code>, <code><a href="#topic+shaving">shaving</a></code>, 
<code><a href="#topic+stpls">stpls</a></code>, <code><a href="#topic+truncation">truncation</a></code>,
<code><a href="#topic+bve_pls">bve_pls</a></code>, <code><a href="#topic+ga_pls">ga_pls</a></code>, <code><a href="#topic+ipw_pls">ipw_pls</a></code>, <code><a href="#topic+mcuve_pls">mcuve_pls</a></code>,
<code><a href="#topic+rep_pls">rep_pls</a></code>, <code><a href="#topic+spa_pls">spa_pls</a></code>,
<code><a href="#topic+lda_from_pls">lda_from_pls</a></code>, <code><a href="#topic+lda_from_pls_cv">lda_from_pls_cv</a></code>, <code><a href="#topic+setDA">setDA</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
setDA() # Query 'lda', 'qda' or 'max'
setDA('qda') # Set default method to QDA

## End(Not run)
</code></pre>

<hr>
<h2 id='shaving'>Repeated shaving of variables</h2><span id='topic+shaving'></span><span id='topic+plot.shaved'></span><span id='topic+print.shaved'></span>

<h3>Description</h3>

<p>One of five filter methods can be chosen for repeated shaving of
a certain percentage of the worst performing variables. Performance of the
reduced models are stored and viewable through <code>print</code> and <code>plot</code>
methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shaving(
  y,
  X,
  ncomp = 10,
  method = c("SR", "VIP", "sMC", "LW", "RC"),
  prop = 0.2,
  min.left = 2,
  comp.type = c("CV", "max"),
  validation = c("CV", 1),
  fixed = integer(0),
  newy = NULL,
  newX = NULL,
  segments = 10,
  plsType = "plsr",
  Y.add = NULL,
  ...
)

## S3 method for class 'shaved'
plot(x, y, what = c("error", "spectra"), index = "min", log = "x", ...)

## S3 method for class 'shaved'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="shaving_+3A_y">y</code></td>
<td>
<p>vector of response values (<code>numeric</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="shaving_+3A_x">X</code></td>
<td>
<p>numeric predictor <code>matrix</code>.</p>
</td></tr>
<tr><td><code id="shaving_+3A_ncomp">ncomp</code></td>
<td>
<p>integer number of components (default = 10).</p>
</td></tr>
<tr><td><code id="shaving_+3A_method">method</code></td>
<td>
<p>filter method, i.e. SR, VIP, sMC, LW or RC given as <code>character</code>.</p>
</td></tr>
<tr><td><code id="shaving_+3A_prop">prop</code></td>
<td>
<p>proportion of variables to be removed in each iteration (<code>numeric</code>).</p>
</td></tr>
<tr><td><code id="shaving_+3A_min.left">min.left</code></td>
<td>
<p>minimum number of remaining variables.</p>
</td></tr>
<tr><td><code id="shaving_+3A_comp.type">comp.type</code></td>
<td>
<p>use number of components chosen by cross-validation, <code>"CV"</code>,
or fixed, <code>"max"</code>.</p>
</td></tr>
<tr><td><code id="shaving_+3A_validation">validation</code></td>
<td>
<p>type of validation for <code>plsr</code>. The default is &quot;CV&quot;. If more
than one set of CV segments is wanted, use a vector of lenth two, e.g. <code>c("CV",5)</code>.</p>
</td></tr>
<tr><td><code id="shaving_+3A_fixed">fixed</code></td>
<td>
<p>vector of indeces for compulsory/fixed variables that should always be
included in the modelling.</p>
</td></tr>
<tr><td><code id="shaving_+3A_newy">newy</code></td>
<td>
<p>validation response for RMSEP/error computations.</p>
</td></tr>
<tr><td><code id="shaving_+3A_newx">newX</code></td>
<td>
<p>validation predictors for RMSEP/error computations.</p>
</td></tr>
<tr><td><code id="shaving_+3A_segments">segments</code></td>
<td>
<p>see <code>mvr</code> for documentation of segment choices.</p>
</td></tr>
<tr><td><code id="shaving_+3A_plstype">plsType</code></td>
<td>
<p>Type of PLS model, &quot;plsr&quot; or &quot;cppls&quot;.</p>
</td></tr>
<tr><td><code id="shaving_+3A_y.add">Y.add</code></td>
<td>
<p>Additional response for CPPLS, see <code>plsType</code>.</p>
</td></tr>
<tr><td><code id="shaving_+3A_...">...</code></td>
<td>
<p>additional arguments for <code>plsr</code> or <code>cvsegments</code>.</p>
</td></tr>
<tr><td><code id="shaving_+3A_x">x</code></td>
<td>
<p>object of class <code>shaved</code> for plotting or printing.</p>
</td></tr>
<tr><td><code id="shaving_+3A_what">what</code></td>
<td>
<p>plot type. Default = &quot;error&quot;. Alternative = &quot;spectra&quot;.</p>
</td></tr>
<tr><td><code id="shaving_+3A_index">index</code></td>
<td>
<p>which iteration to plot. Default = &quot;min&quot;; corresponding to minimum RMSEP.</p>
</td></tr>
<tr><td><code id="shaving_+3A_log">log</code></td>
<td>
<p>logarithmic x (default) or y scale.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Variables are first sorted with respect to some importancemeasure, 
and usually one of the filter measures described above are used. Secondly, a 
threshold is used to eliminate a subset of the least informative variables. Then
a model is fitted again to the remaining variables and performance is measured. 
The procedure is repeated until maximum model performance is achieved.
</p>


<h3>Value</h3>

<p>Returns a list object of class <code>shaved</code> containing the method type,
the error, number of components, and number of variables per reduced model. It
also contains a list of all sets of reduced variable sets plus the original data.
</p>


<h3>Author(s)</h3>

<p>Kristian Hovde Liland
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VIP">VIP</a></code> (SR/sMC/LW/RC), <code><a href="#topic+filterPLSR">filterPLSR</a></code>, <code><a href="#topic+shaving">shaving</a></code>, 
<code><a href="#topic+stpls">stpls</a></code>, <code><a href="#topic+truncation">truncation</a></code>,
<code><a href="#topic+bve_pls">bve_pls</a></code>, <code><a href="#topic+ga_pls">ga_pls</a></code>, <code><a href="#topic+ipw_pls">ipw_pls</a></code>, <code><a href="#topic+mcuve_pls">mcuve_pls</a></code>,
<code><a href="#topic+rep_pls">rep_pls</a></code>, <code><a href="#topic+spa_pls">spa_pls</a></code>,
<code><a href="#topic+lda_from_pls">lda_from_pls</a></code>, <code><a href="#topic+lda_from_pls_cv">lda_from_pls_cv</a></code>, <code><a href="#topic+setDA">setDA</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(mayonnaise, package = "pls")
sh &lt;- shaving(mayonnaise$design[,1], pls::msc(mayonnaise$NIR), type = "interleaved")
pars &lt;- par(mfrow = c(2,1), mar = c(4,4,1,1))
plot(sh)
plot(sh, what = "spectra")
par(pars)
print(sh)

</code></pre>

<hr>
<h2 id='simulate_classes'>Simulate classes</h2><span id='topic+simulate_classes'></span><span id='topic+simulate_data'></span>

<h3>Description</h3>

<p>Simulate multivariate normal data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulate_classes(p, n1, n2)

simulate_data(dims, n1 = 150, n2 = 50)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulate_classes_+3A_p">p</code></td>
<td>
<p>integer number of variables.</p>
</td></tr>
<tr><td><code id="simulate_classes_+3A_n1">n1</code></td>
<td>
<p>integer number of samples in each of two classes in training/calibration data.</p>
</td></tr>
<tr><td><code id="simulate_classes_+3A_n2">n2</code></td>
<td>
<p>integer number of samples in each of two classes in test/validation data.</p>
</td></tr>
<tr><td><code id="simulate_classes_+3A_dims">dims</code></td>
<td>
<p>a 10 element vector of group sizes.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The class simulation is a straigh forward simulation of mulitvariate normal
data into two classes for training and test data, respectively.
The data simulation uses a strictly structured multivariate normal simulation for 
with continuous response data.
</p>


<h3>Value</h3>

<p>Returns a list of predictor and response data for training and testing.
</p>


<h3>Author(s)</h3>

<p>Tahir Mehmood, Kristian Hovde Liland, Solve Sæbø.
</p>


<h3>References</h3>

<p>T. Mehmood, K.H. Liland, L. Snipen, S. Sæbø, A review of variable selection 
methods in Partial Least Squares Regression, Chemometrics and Intelligent Laboratory Systems
118 (2012) 62-69.
T. Mehmood, S. Sæbø, K.H. Liland, Comparison of variable selection methods in partial least
squares regression, Journal of Chemometrics 34 (2020) e3226.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VIP">VIP</a></code> (SR/sMC/LW/RC), <code><a href="#topic+filterPLSR">filterPLSR</a></code>, <code><a href="#topic+shaving">shaving</a></code>, 
<code><a href="#topic+stpls">stpls</a></code>, <code><a href="#topic+truncation">truncation</a></code>,
<code><a href="#topic+bve_pls">bve_pls</a></code>, <code><a href="#topic+ga_pls">ga_pls</a></code>, <code><a href="#topic+ipw_pls">ipw_pls</a></code>, <code><a href="#topic+mcuve_pls">mcuve_pls</a></code>,
<code><a href="#topic+rep_pls">rep_pls</a></code>, <code><a href="#topic+spa_pls">spa_pls</a></code>,
<code><a href="#topic+lda_from_pls">lda_from_pls</a></code>, <code><a href="#topic+lda_from_pls_cv">lda_from_pls_cv</a></code>, <code><a href="#topic+setDA">setDA</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>str(simulate_classes(5,4,4))

</code></pre>

<hr>
<h2 id='spa_pls'>Sub-window permutation analysis coupled with PLS (SwPA-PLS)</h2><span id='topic+spa_pls'></span>

<h3>Description</h3>

<p>SwPA-PLS provides the influence of each variable without considering the 
influence of the rest of the variables through sub-sampling of samples and variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spa_pls(y, X, ncomp = 10, N = 3, ratio = 0.8, Qv = 10, SPA.threshold = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="spa_pls_+3A_y">y</code></td>
<td>
<p>vector of response values (<code>numeric</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="spa_pls_+3A_x">X</code></td>
<td>
<p>numeric predictor <code>matrix</code>.</p>
</td></tr>
<tr><td><code id="spa_pls_+3A_ncomp">ncomp</code></td>
<td>
<p>integer number of components (default = 10).</p>
</td></tr>
<tr><td><code id="spa_pls_+3A_n">N</code></td>
<td>
<p>number of Monte Carlo simulations (default = 3).</p>
</td></tr>
<tr><td><code id="spa_pls_+3A_ratio">ratio</code></td>
<td>
<p>the proportion of the samples to use for calibration (default = 0.8).</p>
</td></tr>
<tr><td><code id="spa_pls_+3A_qv">Qv</code></td>
<td>
<p>integer number of variables to be sampled in each iteration (default = 10).</p>
</td></tr>
<tr><td><code id="spa_pls_+3A_spa.threshold">SPA.threshold</code></td>
<td>
<p>thresholding to remove non-important variables (default = 0.05).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector of variable numbers corresponding to the model 
having lowest prediction error.
</p>


<h3>Author(s)</h3>

<p>Tahir Mehmood, Kristian Hovde Liland, Solve Sæbø.
</p>


<h3>References</h3>

<p>H. Li, M. Zeng, B. Tan, Y. Liang, Q. Xu, D. Cao, Recipe for revealing 
informative metabolites based on model population analysis, Metabolomics 6 (2010) 353-361.
http://code.google.com/p/spa2010/downloads/list.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VIP">VIP</a></code> (SR/sMC/LW/RC), <code><a href="#topic+filterPLSR">filterPLSR</a></code>, <code><a href="#topic+shaving">shaving</a></code>, 
<code><a href="#topic+stpls">stpls</a></code>, <code><a href="#topic+truncation">truncation</a></code>,
<code><a href="#topic+bve_pls">bve_pls</a></code>, <code><a href="#topic+ga_pls">ga_pls</a></code>, <code><a href="#topic+ipw_pls">ipw_pls</a></code>, <code><a href="#topic+mcuve_pls">mcuve_pls</a></code>,
<code><a href="#topic+rep_pls">rep_pls</a></code>, <code><a href="#topic+spa_pls">spa_pls</a></code>,
<code><a href="#topic+lda_from_pls">lda_from_pls</a></code>, <code><a href="#topic+lda_from_pls_cv">lda_from_pls_cv</a></code>, <code><a href="#topic+setDA">setDA</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gasoline, package = "pls")
with( gasoline, spa_pls(octane, NIR) )

</code></pre>

<hr>
<h2 id='stpls'>Soft-Threshold PLS (ST-PLS)</h2><span id='topic+stpls'></span>

<h3>Description</h3>

<p>A soft-thresholding step in PLS algorithm (ST-PLS) based on
ideas from the nearest shrunken centroid method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stpls(..., method = c("stpls", "model.frame"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stpls_+3A_...">...</code></td>
<td>
<p>arguments passed on to <code>mvrV</code>).</p>
</td></tr>
<tr><td><code id="stpls_+3A_method">method</code></td>
<td>
<p>choice between the default <code>stpls</code> and alternative <code>model.frame</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ST-PLS approach is more or less identical to the Sparse-PLS presented
independently by Lè Cao et al. This implementation is an expansion of code from the
pls package.
</p>


<h3>Value</h3>

<p>Returns an object of class mvrV, simliar to to mvr object of the pls package.
</p>


<h3>Author(s)</h3>

<p>Solve Sæbø, Tahir Mehmood, Kristian Hovde Liland.
</p>


<h3>References</h3>

<p>S. Sæbø, T. Almøy, J. Aarøe, A.H. Aastveit, ST-PLS: a multi-dimensional 
nearest shrunken centroid type classifier via pls, Journal of Chemometrics 20 (2007) 54-62.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VIP">VIP</a></code> (SR/sMC/LW/RC), <code><a href="#topic+filterPLSR">filterPLSR</a></code>, <code><a href="#topic+shaving">shaving</a></code>, 
<code><a href="#topic+stpls">stpls</a></code>, <code><a href="#topic+truncation">truncation</a></code>,
<code><a href="#topic+bve_pls">bve_pls</a></code>, <code><a href="#topic+ga_pls">ga_pls</a></code>, <code><a href="#topic+ipw_pls">ipw_pls</a></code>, <code><a href="#topic+mcuve_pls">mcuve_pls</a></code>,
<code><a href="#topic+rep_pls">rep_pls</a></code>, <code><a href="#topic+spa_pls">spa_pls</a></code>,
<code><a href="#topic+lda_from_pls">lda_from_pls</a></code>, <code><a href="#topic+lda_from_pls_cv">lda_from_pls_cv</a></code>, <code><a href="#topic+setDA">setDA</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(yarn, package = "pls")
st &lt;- stpls(density~NIR, ncomp=5, shrink=c(0.1,0.2), validation="CV", data=yarn)
summary(st)

</code></pre>

<hr>
<h2 id='summary.mvrV'>Summary method for stpls and trunc</h2><span id='topic+summary.mvrV'></span>

<h3>Description</h3>

<p>Adaptation of <code>summary.mvr</code> from the <code>pls</code> package v 2.4.3.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mvrV'
summary(
  object,
  what = c("all", "validation", "training"),
  digits = 4,
  print.gap = 2,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.mvrV_+3A_object">object</code></td>
<td>
<p>an mvrV object</p>
</td></tr>
<tr><td><code id="summary.mvrV_+3A_what">what</code></td>
<td>
<p>one of &quot;all&quot;, &quot;validation&quot; or &quot;training&quot;</p>
</td></tr>
<tr><td><code id="summary.mvrV_+3A_digits">digits</code></td>
<td>
<p>integer. Minimum number of significant digits in the output. Default is 4.</p>
</td></tr>
<tr><td><code id="summary.mvrV_+3A_print.gap">print.gap</code></td>
<td>
<p>Integer. Gap between coloumns of the printed tables.</p>
</td></tr>
<tr><td><code id="summary.mvrV_+3A_...">...</code></td>
<td>
<p>Other arguments sent to underlying methods.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="pls.html#topic+summary.mvr">summary.mvr</a></code>
</p>

<hr>
<h2 id='T2_pls'>Hotelling's T^2 based variable selection in PLS &ndash; T^2-PLS)</h2><span id='topic+T2_pls'></span>

<h3>Description</h3>

<p>Variable selection based on the T^2 statistic. A side effect
of running the selection is printing of tables and production of plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>T2_pls(ytr, Xtr, yts, Xts, ncomp = 10, alpha = c(0.2, 0.15, 0.1, 0.05, 0.01))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="T2_pls_+3A_ytr">ytr</code></td>
<td>
<p>Vector of responses for model training.</p>
</td></tr>
<tr><td><code id="T2_pls_+3A_xtr">Xtr</code></td>
<td>
<p>Matrix of predictors for model training.</p>
</td></tr>
<tr><td><code id="T2_pls_+3A_yts">yts</code></td>
<td>
<p>Vector of responses for model testing.</p>
</td></tr>
<tr><td><code id="T2_pls_+3A_xts">Xts</code></td>
<td>
<p>Matrix of predictors for model testing.</p>
</td></tr>
<tr><td><code id="T2_pls_+3A_ncomp">ncomp</code></td>
<td>
<p>Number of PLS components.</p>
</td></tr>
<tr><td><code id="T2_pls_+3A_alpha">alpha</code></td>
<td>
<p>Hotelling's T^2 significance levels.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Parameters and variables corresponding to variable selections
of minimum error and minimum variable set.
</p>


<h3>References</h3>

<p>Tahir Mehmood, Hotelling T^2 based variable selection in partial 
least squares regression, Chemometrics and Intelligent Laboratory Systems 154 (2016), pp 23-28
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gasoline, package = "pls")
library(pls)
if(interactive()){
  t2 &lt;- T2_pls(gasoline$octane[1:40], gasoline$NIR[1:40,], 
             gasoline$octane[-(1:40)], gasoline$NIR[-(1:40),], 
             ncomp = 10, alpha = c(0.2, 0.15, 0.1, 0.05, 0.01))
  matplot(t(gasoline$NIR), type = 'l', col=1, ylab='intensity')
  points(t2$mv[[1]], colMeans(gasoline$NIR)[t2$mv[[1]]], col=2, pch='x')
  points(t2$mv[[2]], colMeans(gasoline$NIR)[t2$mv[[2]]], col=3, pch='o')
}
</code></pre>

<hr>
<h2 id='truncation'>Trunction PLS</h2><span id='topic+truncation'></span>

<h3>Description</h3>

<p>Distribution based truncation for variable selection in subspace 
methods for multivariate regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>truncation(..., Y.add, weights, method = "truncation")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="truncation_+3A_...">...</code></td>
<td>
<p>arguments passed on to <code>mvrV</code>).</p>
</td></tr>
<tr><td><code id="truncation_+3A_y.add">Y.add</code></td>
<td>
<p>optional additional response vector/matrix found in the input data.</p>
</td></tr>
<tr><td><code id="truncation_+3A_weights">weights</code></td>
<td>
<p>optional object weighting vector.</p>
</td></tr>
<tr><td><code id="truncation_+3A_method">method</code></td>
<td>
<p>choice (default = <code>truncation</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Loading weights are truncated around their median based on confidence intervals
for modelling without replicates (Lenth et al.). The arguments passed to <code>mvrV</code> include
all possible arguments to <code><a href="pls.html#topic+mvr">cppls</a></code> and the following truncation parameters 
(with defaults) trunc.pow=FALSE, truncation=NULL, trunc.width=NULL, trunc.weight=0, 
reorth=FALSE, symmetric=FALSE.
</p>
<p>The default way of performing truncation involves the following parameter values:
truncation=&quot;Lenth&quot;, trunc.width=0.95, indicating Lenth's confidence intervals (assymmetric),
with a confidence of 95
shrinkage instead of a hard threshold. An alternative truncation strategy can be used with:
truncation=&quot;quantile&quot;, in which a quantile line is used for detecting outliers/inliers.
</p>


<h3>Value</h3>

<p>Returns an object of class mvrV, simliar to to mvr object of the pls package.
</p>


<h3>Author(s)</h3>

<p>Kristian Hovde Liland.
</p>


<h3>References</h3>

<p>K.H. Liland, M. Høy, H. Martens, S. Sæbø: Distribution based truncation for 
variable selection in subspace methods for multivariate regression, Chemometrics and
Intelligent Laboratory Systems 122 (2013) 103-111.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VIP">VIP</a></code> (SR/sMC/LW/RC), <code><a href="#topic+filterPLSR">filterPLSR</a></code>, <code><a href="#topic+shaving">shaving</a></code>, 
<code><a href="#topic+stpls">stpls</a></code>, <code><a href="#topic+truncation">truncation</a></code>,
<code><a href="#topic+bve_pls">bve_pls</a></code>, <code><a href="#topic+ga_pls">ga_pls</a></code>, <code><a href="#topic+ipw_pls">ipw_pls</a></code>, <code><a href="#topic+mcuve_pls">mcuve_pls</a></code>,
<code><a href="#topic+rep_pls">rep_pls</a></code>, <code><a href="#topic+spa_pls">spa_pls</a></code>,
<code><a href="#topic+lda_from_pls">lda_from_pls</a></code>, <code><a href="#topic+lda_from_pls_cv">lda_from_pls_cv</a></code>, <code><a href="#topic+setDA">setDA</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(yarn, package = "pls")
tr &lt;- truncation(density ~ NIR, ncomp=5, data=yarn, validation="CV",
 truncation="Lenth", trunc.width=0.95) # Default truncation
summary(tr)

</code></pre>

<hr>
<h2 id='VIP'>Filter methods for variable selection with Partial Least Squares.</h2><span id='topic+VIP'></span><span id='topic+SR'></span><span id='topic+sMC'></span><span id='topic+LW'></span><span id='topic+RC'></span><span id='topic+URC'></span><span id='topic+FRC'></span><span id='topic+mRMR'></span>

<h3>Description</h3>

<p>Various filter methods extracting and using information from 
<code>mvr</code> objects to assign importance to all included variables. Available 
methods are Significance Multivariate Correlation (sMC), Selectivity Ratio (SR), 
Variable Importance in Projections (VIP), Loading Weights (LW), Regression Coefficients (RC).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VIP(pls.object, opt.comp, p = dim(pls.object$coef)[1])

SR(pls.object, opt.comp, X)

sMC(pls.object, opt.comp, X, alpha_mc = 0.05)

LW(pls.object, opt.comp)

RC(pls.object, opt.comp)

URC(pls.object, opt.comp)

FRC(pls.object, opt.comp)

mRMR(pls.object, nsel, X)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="VIP_+3A_pls.object">pls.object</code></td>
<td>
<p><code>mvr</code> object from PLS regression.</p>
</td></tr>
<tr><td><code id="VIP_+3A_opt.comp">opt.comp</code></td>
<td>
<p>optimal number of components of PLS model.</p>
</td></tr>
<tr><td><code id="VIP_+3A_p">p</code></td>
<td>
<p>number of variables in PLS model.</p>
</td></tr>
<tr><td><code id="VIP_+3A_x">X</code></td>
<td>
<p>data matrix used as predictors in PLS modelling.</p>
</td></tr>
<tr><td><code id="VIP_+3A_alpha_mc">alpha_mc</code></td>
<td>
<p>quantile significance for automatic selection of variables in <code>sMC</code>.</p>
</td></tr>
<tr><td><code id="VIP_+3A_nsel">nsel</code></td>
<td>
<p>number of variables to select.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>From plsVarSel 0.9.10, the VIP method handles multiple responses
correctly, as does the LW method. All other filter methods implemented in 
this package assume a single response and will give its results based on the
first response in multi-response cases.
</p>


<h3>Value</h3>

<p>A vector having the same lenght as the number of variables in the associated
PLS model. High values are associated with high importance, explained variance or
relevance to the model.
</p>
<p>The sMC has an attribute &quot;quantile&quot;, which is the associated quantile of the
F-distribution, which can be used as a cut-off for significant variables, similar
to the cut-off of 1 associated with the VIP.
</p>


<h3>Author(s)</h3>

<p>Tahir Mehmood, Kristian Hovde Liland, Solve Sæbø.
</p>


<h3>References</h3>

<p>T. Mehmood, K.H. Liland, L. Snipen, S. Sæbø, A review of variable selection 
methods in Partial Least Squares Regression, Chemometrics and Intelligent Laboratory Systems
118 (2012) 62-69.
T. Mehmood, S. Sæbø, K.H. Liland, Comparison of variable selection methods in partial least
squares regression, Journal of Chemometrics 34 (2020) e3226.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VIP">VIP</a></code> (SR/sMC/LW/RC), <code><a href="#topic+filterPLSR">filterPLSR</a></code>, <code><a href="#topic+shaving">shaving</a></code>, 
<code><a href="#topic+stpls">stpls</a></code>, <code><a href="#topic+truncation">truncation</a></code>,
<code><a href="#topic+bve_pls">bve_pls</a></code>, <code><a href="#topic+ga_pls">ga_pls</a></code>, <code><a href="#topic+ipw_pls">ipw_pls</a></code>, <code><a href="#topic+mcuve_pls">mcuve_pls</a></code>,
<code><a href="#topic+rep_pls">rep_pls</a></code>, <code><a href="#topic+spa_pls">spa_pls</a></code>,
<code><a href="#topic+lda_from_pls">lda_from_pls</a></code>, <code><a href="#topic+lda_from_pls_cv">lda_from_pls_cv</a></code>, <code><a href="#topic+setDA">setDA</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gasoline, package = "pls")
library(pls)
pls  &lt;- plsr(octane ~ NIR, ncomp = 10, validation = "LOO", data = gasoline)
comp &lt;- which.min(pls$validation$PRESS)
X    &lt;- unclass(gasoline$NIR)
vip &lt;- VIP(pls, comp)
sr  &lt;- SR (pls, comp, X)
smc &lt;- sMC(pls, comp, X)
lw  &lt;- LW (pls, comp)
rc  &lt;- RC (pls, comp)
urc &lt;- URC(pls, comp)
frc &lt;- FRC(pls, comp)
mrm &lt;- mRMR(pls, 401, X)$score
matplot(scale(cbind(vip, sr, smc, lw, rc, urc, frc, mrm)), type = 'l')

</code></pre>

<hr>
<h2 id='WVC_pls'>Weighted Variable Contribution in PLS (WVC-PLS)</h2><span id='topic+WVC_pls'></span>

<h3>Description</h3>

<p>This implements the PLS-WVC2 component dependent version of WVC from Lin et al., i.e.,
using Equations 14, 16 and 19. The 
implementation is used in T. Mehmood, S. Sæbø, K.H. Liland, Comparison of variable selection methods in partial least
squares regression, Journal of Chemometrics 34 (2020) e3226. However, there is a mistake
in the notation in Mehmood et al. exchanging the denominator of Equation 19 (w'X'Xw) with (w'X'Yw).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WVC_pls(y, X, ncomp, normalize = FALSE, threshold = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="WVC_pls_+3A_y">y</code></td>
<td>
<p>Vector of responses.</p>
</td></tr>
<tr><td><code id="WVC_pls_+3A_x">X</code></td>
<td>
<p>Matrix of predictors.</p>
</td></tr>
<tr><td><code id="WVC_pls_+3A_ncomp">ncomp</code></td>
<td>
<p>Number of components.</p>
</td></tr>
<tr><td><code id="WVC_pls_+3A_normalize">normalize</code></td>
<td>
<p>Divide WVC vectors by maximum value.</p>
</td></tr>
<tr><td><code id="WVC_pls_+3A_threshold">threshold</code></td>
<td>
<p>Set loading weights smaller than threshold to 0 and recompute component.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>loading weights, loadings, regression coefficients, scores and Y-loadings
plus the WVC weights.
</p>


<h3>References</h3>

<p>Variable selection in partial least squares with the weighted variable contribution to the first singular value of the covariance matrix,
Weilu Lin, Haifeng Hang, Yingping Zhuang, Siliang Zhang, Chemometrics and Intelligent Laboratory Systems 183 (2018) 113–121.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(pls)
data(mayonnaise, package = "pls")
wvc &lt;- WVC_pls(factor(mayonnaise$oil.type), mayonnaise$NIR, 10)
wvcNT &lt;- WVC_pls(factor(mayonnaise$oil.type), mayonnaise$NIR, 10, TRUE, 0.5)
old.par &lt;- par(mfrow=c(3,1), mar=c(2,4,1,1))
matplot(t(mayonnaise$NIR), type='l', col=1, ylab='intensity')
matplot(wvc$W[,1:3], type='l', ylab='W')
matplot(wvcNT$W[,1:3], type='l', ylab='W, thr.=0.5')
par(old.par)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
