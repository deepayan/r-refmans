<!DOCTYPE html><html><head><title>Help for package traineR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {traineR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#categorical.predictive.power'><p>categorical.predictive.power</p></a></li>
<li><a href='#confusion.matrix'><p>confusion.matrix</p></a></li>
<li><a href='#contr.dummy'><p>contr.dummy</p></a></li>
<li><a href='#contr.metric'><p>contr.metric</p></a></li>
<li><a href='#contr.ordinal'><p>contr.ordinal</p></a></li>
<li><a href='#create.model'><p>create.model</p></a></li>
<li><a href='#create.prediction'><p>create.prediction</p></a></li>
<li><a href='#dummy.data.frame'><p>dummy.data.frame</p></a></li>
<li><a href='#general.indexes'><p>general.indexes</p></a></li>
<li><a href='#get_test_less_predict'><p>get_test_less_predict</p></a></li>
<li><a href='#get.default.parameters'><p>get.default.parameters</p></a></li>
<li><a href='#gg_color'><p>gg_color</p></a></li>
<li><a href='#importance.plot'><p>importance.plot</p></a></li>
<li><a href='#max_col'><p>max_col</p></a></li>
<li><a href='#numeric_to_predict'><p>numeric_to_predict</p></a></li>
<li><a href='#numerical.predictive.power'><p>numerical.predictive.power</p></a></li>
<li><a href='#original_model'><p>original_model</p></a></li>
<li><a href='#plot.prmdt'><p>Plotting prmdt models</p></a></li>
<li><a href='#predict.ada.prmdt'><p>predict.ada.prmdt</p></a></li>
<li><a href='#predict.adabag.prmdt'><p>predict.adabag.prmdt</p></a></li>
<li><a href='#predict.bayes.prmdt'><p>predict.bayes.prmdt</p></a></li>
<li><a href='#predict.gbm.prmdt'><p>predict.gbm.prmdt</p></a></li>
<li><a href='#predict.glm.prmdt'><p>predict.glm.prmdt</p></a></li>
<li><a href='#predict.glmnet.prmdt'><p>predict.glmnet.prmdt</p></a></li>
<li><a href='#predict.knn.prmdt'><p>predict.knn.prmdt</p></a></li>
<li><a href='#predict.lda.prmdt'><p>predict.lda.prmdt</p></a></li>
<li><a href='#predict.neuralnet.prmdt'><p>predict.neuralnet.prmdt</p></a></li>
<li><a href='#predict.nnet.prmdt'><p>predict.nnet.prmdt</p></a></li>
<li><a href='#predict.qda.prmdt'><p>predict.qda.prmdt</p></a></li>
<li><a href='#predict.randomForest.prmdt'><p>predict.randomForest.prmdt</p></a></li>
<li><a href='#predict.rpart.prmdt'><p>predict.rpart.prmdt</p></a></li>
<li><a href='#predict.svm.prmdt'><p>predict.svm.prmdt</p></a></li>
<li><a href='#predict.xgb.Booster.prmdt'><p>predict.xgb.Booster</p></a></li>
<li><a href='#prediction.variable.balance'><p>prediction.variable.balance</p></a></li>
<li><a href='#print.indexes.prmdt'><p>Printing prmdt index object</p></a></li>
<li><a href='#print.prediction.prmdt'><p>Printing prmdt prediction object</p></a></li>
<li><a href='#print.prmdt'><p>Printing prmdt models</p></a></li>
<li><a href='#ROC.area'><p>ROC.area</p></a></li>
<li><a href='#ROC.plot'><p>ROC.plot</p></a></li>
<li><a href='#scaler'><p>scaler</p></a></li>
<li><a href='#select_on_class'><p>select_on_class</p></a></li>
<li><a href='#train.ada'><p>train.ada</p></a></li>
<li><a href='#train.adabag'><p>train.adabag</p></a></li>
<li><a href='#train.bayes'><p>train.bayes</p></a></li>
<li><a href='#train.gbm'><p>train.gbm</p></a></li>
<li><a href='#train.glm'><p>train.glm</p></a></li>
<li><a href='#train.glmnet'><p>train.glmnet</p></a></li>
<li><a href='#train.knn'><p>train.knn</p></a></li>
<li><a href='#train.lda'><p>train.lda</p></a></li>
<li><a href='#train.neuralnet'><p>train.neuralnet</p></a></li>
<li><a href='#train.nnet'><p>train.nnet</p></a></li>
<li><a href='#train.qda'><p>train.qda</p></a></li>
<li><a href='#train.randomForest'><p>train.randomForest</p></a></li>
<li><a href='#train.rpart'><p>train.rpart</p></a></li>
<li><a href='#train.svm'><p>train.svm</p></a></li>
<li><a href='#train.xgboost'><p>train.xgboost</p></a></li>
<li><a href='#traineR'><p>Predictive (Classification and Regression) Models Homologator</p></a></li>
<li><a href='#type_correction'><p>type_correction</p></a></li>
<li><a href='#varplot'><p>Plotting prmdt ada models</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Predictive (Classification and Regression) Models Homologator</td>
</tr>
<tr>
<td>Version:</td>
<td>2.2.0</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5)</td>
</tr>
<tr>
<td>Imports:</td>
<td>neuralnet (&ge; 1.44.2), rpart (&ge; 4.1-13), xgboost (&ge;
0.81.0.1), randomForest (&ge; 4.6-14), e1071 (&ge; 1.7-0.1), kknn
(&ge; 1.3.1), dplyr (&ge; 0.8.0.1), MASS (&ge; 7.3-53), ada (&ge;
2.0-5), nnet (&ge; 7.3-12), stringr (&ge; 1.4.0), adabag, glmnet,
ROCR, gbm, ggplot2</td>
</tr>
<tr>
<td>Description:</td>
<td>Methods to unify the different ways of creating predictive models and their different predictive formats for classification and regression. It includes 
       methods such as K-Nearest Neighbors Schliep, K. P. (2004) &lt;<a href="https://doi.org/10.5282%2Fubm%2Fepub.1769">doi:10.5282/ubm/epub.1769</a>&gt;, Decision Trees Leo Breiman, Jerome H. Friedman, Richard A. Olshen, Charles J. Stone (2017) &lt;<a href="https://doi.org/10.1201%2F9781315139470">doi:10.1201/9781315139470</a>&gt;, 
       ADA Boosting Esteban Alfaro, Matias Gamez, Noelia García (2013) &lt;<a href="https://doi.org/10.18637%2Fjss.v054.i02">doi:10.18637/jss.v054.i02</a>&gt;, Extreme Gradient Boosting Chen &amp; Guestrin (2016) &lt;<a href="https://doi.org/10.1145%2F2939672.2939785">doi:10.1145/2939672.2939785</a>&gt;, 
       Random Forest Breiman (2001) &lt;<a href="https://doi.org/10.1023%2FA%3A1010933404324">doi:10.1023/A:1010933404324</a>&gt;, Neural Networks Venables, W. N., &amp; Ripley, B. D. (2002) &lt;ISBN:0-387-95457-0&gt;,
       Support Vector Machines Bennett, K. P. &amp; Campbell, C. (2000) &lt;<a href="https://doi.org/10.1145%2F380995.380999">doi:10.1145/380995.380999</a>&gt;, Bayesian Methods Gelman, A., Carlin, J. B., Stern, H. S., &amp; Rubin, D. B. (1995) &lt;<a href="https://doi.org/10.1201%2F9780429258411">doi:10.1201/9780429258411</a>&gt;, 
       Linear Discriminant Analysis Venables, W. N., &amp; Ripley, B. D. (2002) &lt;ISBN:0-387-95457-0&gt;, Quadratic Discriminant Analysis Venables, W. N., &amp; Ripley, B. D. (2002) &lt;ISBN:0-387-95457-0&gt;, 
       Logistic Regression Dobson, A. J., &amp; Barnett, A. G. (2018) &lt;<a href="https://doi.org/10.1201%2F9781315182780">doi:10.1201/9781315182780</a>&gt; and Penalized Logistic Regression Friedman, J. H., Hastie, T., &amp; Tibshirani, R. (2010) &lt;<a href="https://doi.org/10.18637%2Fjss.v033.i01">doi:10.18637/jss.v033.i01</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://promidat.website/">https://promidat.website/</a>,<a href="https://github.com/PROMiDAT/traineR">https://github.com/PROMiDAT/traineR</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/PROMiDAT/traineR/issues">https://github.com/PROMiDAT/traineR/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-09 20:11:13 UTC; promidat05</td>
</tr>
<tr>
<td>Author:</td>
<td>Oldemar Rodriguez R. [aut, cre],
  Andres Navarro D. [aut],
  Ariel Arroyo S. [aut],
  Diego Jimenez A. [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Oldemar Rodriguez R. &lt;oldemar.rodriguez@ucr.ac.cr&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-09 23:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='categorical.predictive.power'>categorical.predictive.power</h2><span id='topic+categorical.predictive.power'></span>

<h3>Description</h3>

<p>Function that graphs the distribution of individuals and shows their category according to a categorical variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>categorical.predictive.power(
  data,
  predict.variable,
  variable.to.compare,
  ylab = "",
  xlab = "",
  main = paste("Variable Distribution", variable.to.compare, "according to",
    predict.variable),
  col = NA
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="categorical.predictive.power_+3A_data">data</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="categorical.predictive.power_+3A_predict.variable">predict.variable</code></td>
<td>
<p>Character type. The name of the variable to predict. This name must be part of the columns of the data frame.</p>
</td></tr>
<tr><td><code id="categorical.predictive.power_+3A_variable.to.compare">variable.to.compare</code></td>
<td>
<p>Character type. The name of the categorical variable to compare. This name must be part of the columns of the data frame.</p>
</td></tr>
<tr><td><code id="categorical.predictive.power_+3A_ylab">ylab</code></td>
<td>
<p>A character string that describes the y-axis on the graph.</p>
</td></tr>
<tr><td><code id="categorical.predictive.power_+3A_xlab">xlab</code></td>
<td>
<p>A character string that describes the x-axis on the graph.</p>
</td></tr>
<tr><td><code id="categorical.predictive.power_+3A_main">main</code></td>
<td>
<p>Character type. The main title of the chart.</p>
</td></tr>
<tr><td><code id="categorical.predictive.power_+3A_col">col</code></td>
<td>
<p>A vector that specifies the colors of the categories of the variable to predict.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object.
</p>


<h3>Note</h3>

<p>With this function we can analyze the predictive power of a categorical variable.
</p>


<h3>See Also</h3>

<p><code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
cars &lt;- datasets::mtcars
cars$cyl &lt;- as.factor(cars$cyl)
cars$vs &lt;- as.factor(cars$vs)
categorical.predictive.power(cars,"vs","cyl")

</code></pre>

<hr>
<h2 id='confusion.matrix'>confusion.matrix</h2><span id='topic+confusion.matrix'></span>

<h3>Description</h3>

<p>create the confusion matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>confusion.matrix(newdata, prediction)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confusion.matrix_+3A_newdata">newdata</code></td>
<td>
<p>matrix or data frame of test data.</p>
</td></tr>
<tr><td><code id="confusion.matrix_+3A_prediction">prediction</code></td>
<td>
<p>a prmdt prediction object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with predicted and actual values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("iris")

n &lt;- seq_len(nrow(iris))
.sample &lt;- sample(n, length(n) * 0.75)
data.train &lt;- iris[.sample,]
data.test &lt;- iris[-.sample,]

modelo.knn &lt;- train.knn(Species~., data.train)
modelo.knn
prob &lt;- predict(modelo.knn, data.test, type = "prob")
prob
prediccion &lt;- predict(modelo.knn, data.test, type = "class")
prediccion
confusion.matrix(data.test, prediccion)

</code></pre>

<hr>
<h2 id='contr.dummy'>contr.dummy</h2><span id='topic+contr.dummy'></span>

<h3>Description</h3>

<p>Returns a matrix of contrasts for the <code><a href="kknn.html#topic+train.kknn">train.kknn</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>contr.dummy(n, contrasts = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="contr.dummy_+3A_n">n</code></td>
<td>
<p>A vector containing levels of a factor, or the number of levels.</p>
</td></tr>
<tr><td><code id="contr.dummy_+3A_contrasts">contrasts</code></td>
<td>
<p>A logical value indicating whether contrasts should be computed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with n rows and n-1 columns for contr.ordinal, a matrix with n rows and n columns for contr.dummy and a vector of length n for contr.metric.
</p>

<hr>
<h2 id='contr.metric'>contr.metric</h2><span id='topic+contr.metric'></span>

<h3>Description</h3>

<p>Returns a matrix of contrasts for the <code><a href="kknn.html#topic+train.kknn">train.kknn</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>contr.metric(n, contrasts = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="contr.metric_+3A_n">n</code></td>
<td>
<p>A vector containing levels of a factor, or the number of levels.</p>
</td></tr>
<tr><td><code id="contr.metric_+3A_contrasts">contrasts</code></td>
<td>
<p>A logical value indicating whether contrasts should be computed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with n rows and n-1 columns for contr.ordinal, a matrix with n rows and n columns for contr.dummy and a vector of length n for contr.metric.
</p>

<hr>
<h2 id='contr.ordinal'>contr.ordinal</h2><span id='topic+contr.ordinal'></span>

<h3>Description</h3>

<p>Returns a matrix of contrasts for the <code><a href="kknn.html#topic+train.kknn">train.kknn</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>contr.ordinal(n, contrasts = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="contr.ordinal_+3A_n">n</code></td>
<td>
<p>A vector containing levels of a factor, or the number of levels.</p>
</td></tr>
<tr><td><code id="contr.ordinal_+3A_contrasts">contrasts</code></td>
<td>
<p>A logical value indicating whether contrasts should be computed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with n rows and n-1 columns for contr.ordinal, a matrix with n rows and n columns for contr.dummy and a vector of length n for contr.metric.
</p>

<hr>
<h2 id='create.model'>create.model</h2><span id='topic+create.model'></span>

<h3>Description</h3>

<p>create.model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.model(model, formula, data, name = NULL)
</code></pre>

<hr>
<h2 id='create.prediction'>create.prediction</h2><span id='topic+create.prediction'></span>

<h3>Description</h3>

<p>create.prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.prediction(model, prediction)
</code></pre>

<hr>
<h2 id='dummy.data.frame'>dummy.data.frame</h2><span id='topic+dummy.data.frame'></span>

<h3>Description</h3>

<p>dummy.data.frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dummy.data.frame(data)
</code></pre>

<hr>
<h2 id='general.indexes'>general.indexes</h2><span id='topic+general.indexes'></span>

<h3>Description</h3>

<p>Calculates the confusion matrix, overall accuracy, overall error and the category accuracy for a classification problem
and the Root Mean Square Error, Mean Absolute Error, Relative Error and Correlation for a regression problem.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>general.indexes(newdata, prediction, mc = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="general.indexes_+3A_newdata">newdata</code></td>
<td>
<p>matrix or data frame of test data.</p>
</td></tr>
<tr><td><code id="general.indexes_+3A_prediction">prediction</code></td>
<td>
<p>a prmdt prediction object.</p>
</td></tr>
<tr><td><code id="general.indexes_+3A_mc">mc</code></td>
<td>
<p>(optional) a matrix for calculating the indices. If mc is entered as parameter newdata and prediction are not necessary.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the appropiate error and precision measurement. The class of this list is indexes.prmdt
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Classification
data("iris")

n &lt;- seq_len(nrow(iris))
.sample &lt;- sample(n, length(n) * 0.75)
data.train &lt;- iris[.sample,]
data.test &lt;- iris[-.sample,]

modelo.knn &lt;- train.knn(Species~., data.train)
prediccion &lt;- predict(modelo.knn, data.test, type = "class")
general.indexes(data.test, prediccion)

# Regression
len &lt;- nrow(swiss)
sampl &lt;- sample(x = 1:len,size = len*0.20,replace = FALSE)
ttesting &lt;- swiss[sampl,]
ttraining &lt;- swiss[-sampl,]
model.knn &lt;- train.knn(Infant.Mortality~.,ttraining)
prediccion &lt;- predict(model.knn, ttesting)
prediccion
general.indexes(ttesting, prediccion)

</code></pre>

<hr>
<h2 id='get_test_less_predict'>get_test_less_predict</h2><span id='topic+get_test_less_predict'></span>

<h3>Description</h3>

<p>get_test_less_predict
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_test_less_predict(data, var.pred)
</code></pre>

<hr>
<h2 id='get.default.parameters'>get.default.parameters</h2><span id='topic+get.default.parameters'></span>

<h3>Description</h3>

<p>get.default.parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.default.parameters(mcall, myFormals)
</code></pre>

<hr>
<h2 id='gg_color'>gg_color</h2><span id='topic+gg_color'></span>

<h3>Description</h3>

<p>gg_color
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gg_color(n)
</code></pre>

<hr>
<h2 id='importance.plot'>importance.plot</h2><span id='topic+importance.plot'></span>

<h3>Description</h3>

<p>Function that graphs the importance of the variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>importance.plot(model, col = "steelblue")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="importance.plot_+3A_model">model</code></td>
<td>
<p>fitted model object.</p>
</td></tr>
<tr><td><code id="importance.plot_+3A_col">col</code></td>
<td>
<p>the color of the chart bars.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object.
</p>


<h3>Note</h3>

<p>With this function we can identify how important the variables are for the generation of a predictive model.
</p>


<h3>See Also</h3>

<p><code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>, <code><a href="#topic+train.adabag">train.adabag</a></code>, <code><a href="adabag.html#topic+boosting">boosting</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data &lt;- iris
n &lt;- nrow(data)

sam &lt;- sample(1:n,n*0.75)
training &lt;- data[sam,]
testing &lt;- data[-sam,]

model &lt;- train.adabag(formula = Species~.,data = training,minsplit = 2,
 maxdepth = 30, mfinal = 10)
importance.plot(model)

</code></pre>

<hr>
<h2 id='max_col'>max_col</h2><span id='topic+max_col'></span>

<h3>Description</h3>

<p>max_col
</p>


<h3>Usage</h3>

<pre><code class='language-R'>max_col(m)
</code></pre>

<hr>
<h2 id='numeric_to_predict'>numeric_to_predict</h2><span id='topic+numeric_to_predict'></span>

<h3>Description</h3>

<p>numeric_to_predict
</p>


<h3>Usage</h3>

<pre><code class='language-R'>numeric_to_predict(real, predic.var = NULL, niveles = NULL)
</code></pre>

<hr>
<h2 id='numerical.predictive.power'>numerical.predictive.power</h2><span id='topic+numerical.predictive.power'></span>

<h3>Description</h3>

<p>Function that graphs the density of individuals and shows their category according to a numerical variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>numerical.predictive.power(
  data,
  predict.variable,
  variable.to.compare,
  ylab = "",
  xlab = "",
  main = paste("Variable Density", variable.to.compare, "according to", predict.variable),
  col = NA
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="numerical.predictive.power_+3A_data">data</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="numerical.predictive.power_+3A_predict.variable">predict.variable</code></td>
<td>
<p>Character type. The name of the variable to predict. This name must be part of the columns of the data frame.</p>
</td></tr>
<tr><td><code id="numerical.predictive.power_+3A_variable.to.compare">variable.to.compare</code></td>
<td>
<p>Character type. The name of the numeric variable to compare. This name must be part of the columns of the data frame.</p>
</td></tr>
<tr><td><code id="numerical.predictive.power_+3A_ylab">ylab</code></td>
<td>
<p>A character string that describes the y-axis on the graph.</p>
</td></tr>
<tr><td><code id="numerical.predictive.power_+3A_xlab">xlab</code></td>
<td>
<p>A character string that describes the x-axis on the graph.</p>
</td></tr>
<tr><td><code id="numerical.predictive.power_+3A_main">main</code></td>
<td>
<p>Character type. The main title of the chart.</p>
</td></tr>
<tr><td><code id="numerical.predictive.power_+3A_col">col</code></td>
<td>
<p>A vector that specifies the colors of the categories of the variable to predict.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object.
</p>


<h3>Note</h3>

<p>With this function we can analyze the predictive power of a numerical variable.
</p>


<h3>See Also</h3>

<p><code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
numerical.predictive.power(iris,"Species","Sepal.Length")

</code></pre>

<hr>
<h2 id='original_model'>original_model</h2><span id='topic+original_model'></span>

<h3>Description</h3>

<p>original_model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>original_model(x)
</code></pre>

<hr>
<h2 id='plot.prmdt'>Plotting prmdt models</h2><span id='topic+plot.prmdt'></span>

<h3>Description</h3>

<p>Plotting prmdt models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'prmdt'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.prmdt_+3A_x">x</code></td>
<td>
<p>A prmdt models</p>
</td></tr>
<tr><td><code id="plot.prmdt_+3A_...">...</code></td>
<td>
<p>optional arguments to print o format method</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a plot of a model.
</p>

<hr>
<h2 id='predict.ada.prmdt'>predict.ada.prmdt</h2><span id='topic+predict.ada.prmdt'></span>

<h3>Description</h3>

<p>Return prediction for a <code><a href="ada.html#topic+ada">ada</a></code> model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ada.prmdt'
predict(object, newdata, type = "class", n.iter = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.ada.prmdt_+3A_object">object</code></td>
<td>
<p>a <code><a href="ada.html#topic+ada">ada</a></code> model object for which prediction is desired.</p>
</td></tr>
<tr><td><code id="predict.ada.prmdt_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame in which to look for variables with which to predict.</p>
</td></tr>
<tr><td><code id="predict.ada.prmdt_+3A_type">type</code></td>
<td>
<p>type of prediction 'prob' or 'class' (default).</p>
</td></tr>
<tr><td><code id="predict.ada.prmdt_+3A_n.iter">n.iter</code></td>
<td>
<p>number of iterations to consider for the prediction. By default this is iter from the ada call (n.iter&lt; iter).</p>
</td></tr>
<tr><td><code id="predict.ada.prmdt_+3A_...">...</code></td>
<td>
<p>additional arguments affecting the predictions produced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector or matrix of predictions for ada model.
</p>

<hr>
<h2 id='predict.adabag.prmdt'>predict.adabag.prmdt</h2><span id='topic+predict.adabag.prmdt'></span>

<h3>Description</h3>

<p>Return prediction for a <code><a href="adabag.html#topic+boosting">boosting</a></code> model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'adabag.prmdt'
predict(object, newdata, type = "class", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.adabag.prmdt_+3A_object">object</code></td>
<td>
<p>a <code><a href="adabag.html#topic+boosting">boosting</a></code> model object for which prediction is desired.</p>
</td></tr>
<tr><td><code id="predict.adabag.prmdt_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame in which to look for variables with which to predict.</p>
</td></tr>
<tr><td><code id="predict.adabag.prmdt_+3A_type">type</code></td>
<td>
<p>type of prediction 'prob' or 'class' (default).</p>
</td></tr>
<tr><td><code id="predict.adabag.prmdt_+3A_...">...</code></td>
<td>
<p>additional arguments affecting the predictions produced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector or matrix of predictions adabag model.
</p>

<hr>
<h2 id='predict.bayes.prmdt'>predict.bayes.prmdt</h2><span id='topic+predict.bayes.prmdt'></span>

<h3>Description</h3>

<p>Return prediction for a <code><a href="e1071.html#topic+naiveBayes">naiveBayes</a></code> model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bayes.prmdt'
predict(object, newdata, type = "class", threshold = 0.001, eps = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.bayes.prmdt_+3A_object">object</code></td>
<td>
<p>a <code><a href="e1071.html#topic+naiveBayes">naiveBayes</a></code> model object for which prediction is desired.</p>
</td></tr>
<tr><td><code id="predict.bayes.prmdt_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame in which to look for variables with which to predict.</p>
</td></tr>
<tr><td><code id="predict.bayes.prmdt_+3A_type">type</code></td>
<td>
<p>type of prediction 'prob' or 'class' (default).</p>
</td></tr>
<tr><td><code id="predict.bayes.prmdt_+3A_threshold">threshold</code></td>
<td>
<p>Value replacing cells with 0 probabilities.</p>
</td></tr>
<tr><td><code id="predict.bayes.prmdt_+3A_eps">eps</code></td>
<td>
<p>double for specifying an epsilon-range to apply laplace smoothing (to replace zero or close-zero probabilities by theshold).</p>
</td></tr>
<tr><td><code id="predict.bayes.prmdt_+3A_...">...</code></td>
<td>
<p>additional arguments affecting the predictions produced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector or matrix of predictions for bayes model.
</p>

<hr>
<h2 id='predict.gbm.prmdt'>predict.gbm.prmdt</h2><span id='topic+predict.gbm.prmdt'></span>

<h3>Description</h3>

<p>Return prediction for a <code><a href="gbm.html#topic+gbm">gbm</a></code> model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gbm.prmdt'
predict(
  object,
  newdata,
  type = "class",
  n.trees = NULL,
  single.tree = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.gbm.prmdt_+3A_object">object</code></td>
<td>
<p>a <code><a href="gbm.html#topic+gbm">gbm</a></code> model object for which prediction is desired.</p>
</td></tr>
<tr><td><code id="predict.gbm.prmdt_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame in which to look for variables with which to predict.</p>
</td></tr>
<tr><td><code id="predict.gbm.prmdt_+3A_type">type</code></td>
<td>
<p>type of prediction 'prob' or 'class' (default).</p>
</td></tr>
<tr><td><code id="predict.gbm.prmdt_+3A_n.trees">n.trees</code></td>
<td>
<p>Number of trees used in the prediction. n.trees may be a vector in which case predictions are returned for each iteration specified</p>
</td></tr>
<tr><td><code id="predict.gbm.prmdt_+3A_single.tree">single.tree</code></td>
<td>
<p>If single.tree=TRUE then predict.gbm returns only the predictions from tree(s) n.trees.</p>
</td></tr>
<tr><td><code id="predict.gbm.prmdt_+3A_...">...</code></td>
<td>
<p>additional arguments affecting the predictions produced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector or matrix of predictions gbm model.
</p>

<hr>
<h2 id='predict.glm.prmdt'>predict.glm.prmdt</h2><span id='topic+predict.glm.prmdt'></span>

<h3>Description</h3>

<p>Return prediction for a <code><a href="stats.html#topic+glm">glm</a></code> model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glm.prmdt'
predict(
  object,
  newdata,
  type = "class",
  se.fit = FALSE,
  dispersion = NULL,
  terms = NULL,
  na.action = na.pass,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.glm.prmdt_+3A_object">object</code></td>
<td>
<p>a <code><a href="stats.html#topic+glm">glm</a></code> model object for which prediction is desired.</p>
</td></tr>
<tr><td><code id="predict.glm.prmdt_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame in which to look for variables with which to predict.</p>
</td></tr>
<tr><td><code id="predict.glm.prmdt_+3A_type">type</code></td>
<td>
<p>type of prediction 'prob' or 'class' (default).</p>
</td></tr>
<tr><td><code id="predict.glm.prmdt_+3A_se.fit">se.fit</code></td>
<td>
<p>logical switch indicating if standard errors are required.</p>
</td></tr>
<tr><td><code id="predict.glm.prmdt_+3A_dispersion">dispersion</code></td>
<td>
<p>the dispersion of the GLM fit to be assumed in computing the standard errors. If omitted, that returned by summary applied to the object is used.</p>
</td></tr>
<tr><td><code id="predict.glm.prmdt_+3A_terms">terms</code></td>
<td>
<p>with type = &quot;terms&quot; by default all terms are returned. A character vector specifies which terms are to be returned.</p>
</td></tr>
<tr><td><code id="predict.glm.prmdt_+3A_na.action">na.action</code></td>
<td>
<p>function determining what should be done with missing values in newdata. The default is to predict NA.</p>
</td></tr>
<tr><td><code id="predict.glm.prmdt_+3A_...">...</code></td>
<td>
<p>additional arguments affecting the predictions produced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector or matrix of predictions for glm model.
</p>

<hr>
<h2 id='predict.glmnet.prmdt'>predict.glmnet.prmdt</h2><span id='topic+predict.glmnet.prmdt'></span>

<h3>Description</h3>

<p>Return prediction for a <code><a href="glmnet.html#topic+glmnet">glmnet</a></code> model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glmnet.prmdt'
predict(object, newdata, type = "class", s = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.glmnet.prmdt_+3A_object">object</code></td>
<td>
<p>a <code><a href="glmnet.html#topic+glmnet">glmnet</a></code> model object for which prediction is desired.</p>
</td></tr>
<tr><td><code id="predict.glmnet.prmdt_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame in which to look for variables with which to predict.</p>
</td></tr>
<tr><td><code id="predict.glmnet.prmdt_+3A_type">type</code></td>
<td>
<p>type of prediction 'prob' or 'class' (default).</p>
</td></tr>
<tr><td><code id="predict.glmnet.prmdt_+3A_s">s</code></td>
<td>
<p>a <code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a></code> object (optional).</p>
</td></tr>
<tr><td><code id="predict.glmnet.prmdt_+3A_...">...</code></td>
<td>
<p>additional arguments affecting the predictions produced.</p>
</td></tr>
</table>

<hr>
<h2 id='predict.knn.prmdt'>predict.knn.prmdt</h2><span id='topic+predict.knn.prmdt'></span>

<h3>Description</h3>

<p>Return prediction for a <code><a href="kknn.html#topic+train.kknn">train.kknn</a></code> model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'knn.prmdt'
predict(object, newdata, type = "class", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.knn.prmdt_+3A_object">object</code></td>
<td>
<p>a <code><a href="kknn.html#topic+train.kknn">train.kknn</a></code> model object for which prediction is desired.</p>
</td></tr>
<tr><td><code id="predict.knn.prmdt_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame in which to look for variables with which to predict.</p>
</td></tr>
<tr><td><code id="predict.knn.prmdt_+3A_type">type</code></td>
<td>
<p>type of prediction 'prob' or 'class' (default).</p>
</td></tr>
<tr><td><code id="predict.knn.prmdt_+3A_...">...</code></td>
<td>
<p>additional arguments affecting the predictions produced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector or matrix of predictions for knn model.
</p>

<hr>
<h2 id='predict.lda.prmdt'>predict.lda.prmdt</h2><span id='topic+predict.lda.prmdt'></span>

<h3>Description</h3>

<p>Return prediction for a <code><a href="MASS.html#topic+lda">lda</a></code> model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lda.prmdt'
predict(object, newdata, type = "class", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.lda.prmdt_+3A_object">object</code></td>
<td>
<p>a <code><a href="MASS.html#topic+lda">lda</a></code> model object for which prediction is desired.</p>
</td></tr>
<tr><td><code id="predict.lda.prmdt_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame in which to look for variables with which to predict.</p>
</td></tr>
<tr><td><code id="predict.lda.prmdt_+3A_type">type</code></td>
<td>
<p>type of prediction 'prob' or 'class' (default).</p>
</td></tr>
<tr><td><code id="predict.lda.prmdt_+3A_...">...</code></td>
<td>
<p>additional arguments affecting the predictions produced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector or matrix of predictions for lda model.
</p>

<hr>
<h2 id='predict.neuralnet.prmdt'>predict.neuralnet.prmdt</h2><span id='topic+predict.neuralnet.prmdt'></span>

<h3>Description</h3>

<p>Return prediction for a <code><a href="neuralnet.html#topic+neuralnet">neuralnet</a></code> model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'neuralnet.prmdt'
predict(object, newdata, type = "class", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.neuralnet.prmdt_+3A_object">object</code></td>
<td>
<p>a <code><a href="neuralnet.html#topic+neuralnet">neuralnet</a></code> model object for which prediction is desired.</p>
</td></tr>
<tr><td><code id="predict.neuralnet.prmdt_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame in which to look for variables with which to predict.</p>
</td></tr>
<tr><td><code id="predict.neuralnet.prmdt_+3A_type">type</code></td>
<td>
<p>type of prediction 'prob' or 'class' (default).</p>
</td></tr>
<tr><td><code id="predict.neuralnet.prmdt_+3A_...">...</code></td>
<td>
<p>additional arguments affecting the predictions produced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector or matrix of predictions for neuralnet.
</p>

<hr>
<h2 id='predict.nnet.prmdt'>predict.nnet.prmdt</h2><span id='topic+predict.nnet.prmdt'></span>

<h3>Description</h3>

<p>Return prediction for a <code><a href="nnet.html#topic+nnet">nnet</a></code> model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'nnet.prmdt'
predict(object, newdata, type = "class", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.nnet.prmdt_+3A_object">object</code></td>
<td>
<p>a <code><a href="nnet.html#topic+nnet">nnet</a></code> model object for which prediction is desired.</p>
</td></tr>
<tr><td><code id="predict.nnet.prmdt_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame in which to look for variables with which to predict.</p>
</td></tr>
<tr><td><code id="predict.nnet.prmdt_+3A_type">type</code></td>
<td>
<p>type of prediction 'prob' or 'class' (default).</p>
</td></tr>
<tr><td><code id="predict.nnet.prmdt_+3A_...">...</code></td>
<td>
<p>additional arguments affecting the predictions produced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector or matrix of predictions for nnet model.
</p>

<hr>
<h2 id='predict.qda.prmdt'>predict.qda.prmdt</h2><span id='topic+predict.qda.prmdt'></span>

<h3>Description</h3>

<p>Return prediction for a <code><a href="MASS.html#topic+qda">qda</a></code> model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'qda.prmdt'
predict(object, newdata, type = "class", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.qda.prmdt_+3A_object">object</code></td>
<td>
<p>a <code><a href="MASS.html#topic+qda">qda</a></code> model object for which prediction is desired.</p>
</td></tr>
<tr><td><code id="predict.qda.prmdt_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame in which to look for variables with which to predict.</p>
</td></tr>
<tr><td><code id="predict.qda.prmdt_+3A_type">type</code></td>
<td>
<p>type of prediction 'prob' or 'class' (default).</p>
</td></tr>
<tr><td><code id="predict.qda.prmdt_+3A_...">...</code></td>
<td>
<p>additional arguments affecting the predictions produced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector or matrix of predictions for qda model.
</p>

<hr>
<h2 id='predict.randomForest.prmdt'>predict.randomForest.prmdt</h2><span id='topic+predict.randomForest.prmdt'></span>

<h3>Description</h3>

<p>Return prediction for a <code><a href="randomForest.html#topic+randomForest">randomForest</a></code> model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'randomForest.prmdt'
predict(
  object,
  newdata,
  type = "class",
  norm.votes = TRUE,
  predict.all = FALSE,
  proximity = FALSE,
  nodes = FALSE,
  cutoff,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.randomForest.prmdt_+3A_object">object</code></td>
<td>
<p>a <code><a href="randomForest.html#topic+randomForest">randomForest</a></code> model object for which prediction is desired.</p>
</td></tr>
<tr><td><code id="predict.randomForest.prmdt_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame in which to look for variables with which to predict.</p>
</td></tr>
<tr><td><code id="predict.randomForest.prmdt_+3A_type">type</code></td>
<td>
<p>type of prediction 'prob' or 'class' (default).</p>
</td></tr>
<tr><td><code id="predict.randomForest.prmdt_+3A_norm.votes">norm.votes</code></td>
<td>
<p>Should the vote counts be normalized (i.e., expressed as fractions)? Ignored if object$type is regression.</p>
</td></tr>
<tr><td><code id="predict.randomForest.prmdt_+3A_predict.all">predict.all</code></td>
<td>
<p>Should the predictions of all trees be kept?</p>
</td></tr>
<tr><td><code id="predict.randomForest.prmdt_+3A_proximity">proximity</code></td>
<td>
<p>Should proximity measures be computed? An error is issued if object$type is regression.</p>
</td></tr>
<tr><td><code id="predict.randomForest.prmdt_+3A_nodes">nodes</code></td>
<td>
<p>Should the terminal node indicators (an n by ntree matrix) be return? If so, it is in the &ldquo;nodes&rdquo; attribute of the returned object.</p>
</td></tr>
<tr><td><code id="predict.randomForest.prmdt_+3A_cutoff">cutoff</code></td>
<td>
<p>(Classification only) A vector of length equal to number of classes. The &lsquo;winning&rsquo; class for an observation is the one with the maximum ratio of proportion of votes to cutoff. Default is taken from the forest$cutoff component of object (i.e., the setting used when running randomForest).</p>
</td></tr>
<tr><td><code id="predict.randomForest.prmdt_+3A_...">...</code></td>
<td>
<p>additional arguments affecting the predictions produced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector or matrix of predictions for randomforest model.
</p>

<hr>
<h2 id='predict.rpart.prmdt'>predict.rpart.prmdt</h2><span id='topic+predict.rpart.prmdt'></span>

<h3>Description</h3>

<p>Return prediction for a <code><a href="rpart.html#topic+rpart">rpart</a></code> model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rpart.prmdt'
predict(object, newdata, type = "class", na.action = na.pass, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.rpart.prmdt_+3A_object">object</code></td>
<td>
<p>a <code><a href="rpart.html#topic+rpart">rpart</a></code> model object for which prediction is desired.</p>
</td></tr>
<tr><td><code id="predict.rpart.prmdt_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame in which to look for variables with which to predict.</p>
</td></tr>
<tr><td><code id="predict.rpart.prmdt_+3A_type">type</code></td>
<td>
<p>type of prediction 'prob' or 'class' (default).</p>
</td></tr>
<tr><td><code id="predict.rpart.prmdt_+3A_na.action">na.action</code></td>
<td>
<p>a function to determine what should be done with missing values in newdata. The default is to pass them down the tree using surrogates in the way selected when the model was built. Other possibilities are na.omit and na.fail.</p>
</td></tr>
<tr><td><code id="predict.rpart.prmdt_+3A_...">...</code></td>
<td>
<p>additional arguments affecting the predictions produced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector or matrix of predictions for rpart model.
</p>

<hr>
<h2 id='predict.svm.prmdt'>predict.svm.prmdt</h2><span id='topic+predict.svm.prmdt'></span>

<h3>Description</h3>

<p>Return prediction for a <code><a href="e1071.html#topic+svm">svm</a></code> model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'svm.prmdt'
predict(
  object,
  newdata,
  type = "class",
  decision.values = FALSE,
  ...,
  na.action = na.omit
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.svm.prmdt_+3A_object">object</code></td>
<td>
<p>a <code><a href="e1071.html#topic+svm">svm</a></code> model object for which prediction is desired.</p>
</td></tr>
<tr><td><code id="predict.svm.prmdt_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame in which to look for variables with which to predict.</p>
</td></tr>
<tr><td><code id="predict.svm.prmdt_+3A_type">type</code></td>
<td>
<p>type of prediction 'prob' or 'class' (default).</p>
</td></tr>
<tr><td><code id="predict.svm.prmdt_+3A_decision.values">decision.values</code></td>
<td>
<p>Logical controlling whether the decision values of all binary classifiers computed in multiclass classification shall be computed and returned.</p>
</td></tr>
<tr><td><code id="predict.svm.prmdt_+3A_...">...</code></td>
<td>
<p>additional arguments affecting the predictions produced.</p>
</td></tr>
<tr><td><code id="predict.svm.prmdt_+3A_na.action">na.action</code></td>
<td>
<p>A function to specify the action to be taken if ‘NA’s are found. The default action is na.omit, which leads to rejection of cases with missing values on any required variable. An alternative is na.fail, which causes an error if NA cases are found. (NOTE: If given, this argument must be named.)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector or matrix of predictionsfor svm model.
</p>

<hr>
<h2 id='predict.xgb.Booster.prmdt'>predict.xgb.Booster</h2><span id='topic+predict.xgb.Booster.prmdt'></span>

<h3>Description</h3>

<p>Return prediction for a <code><a href="xgboost.html#topic+xgb.train">xgb.train</a></code> model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'xgb.Booster.prmdt'
predict(
  object,
  newdata,
  type = "class",
  missing = NA,
  outputmargin = FALSE,
  ntreelimit = NULL,
  predleaf = FALSE,
  predcontrib = FALSE,
  approxcontrib = FALSE,
  predinteraction = FALSE,
  reshape = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.xgb.Booster.prmdt_+3A_object">object</code></td>
<td>
<p>a <code><a href="xgboost.html#topic+xgb.train">xgb.train</a></code> model object for which prediction is desired.</p>
</td></tr>
<tr><td><code id="predict.xgb.Booster.prmdt_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame in which to look for variables with which to predict.</p>
</td></tr>
<tr><td><code id="predict.xgb.Booster.prmdt_+3A_type">type</code></td>
<td>
<p>type of prediction 'prob' or 'class' (default).</p>
</td></tr>
<tr><td><code id="predict.xgb.Booster.prmdt_+3A_missing">missing</code></td>
<td>
<p>Missing is only used when input is dense matrix. Pick a float value that represents missing values in data (e.g., sometimes 0 or some other extreme value is used).</p>
</td></tr>
<tr><td><code id="predict.xgb.Booster.prmdt_+3A_outputmargin">outputmargin</code></td>
<td>
<p>whether the prediction should be returned in the for of original untransformed sum of predictions from boosting iterations' results. E.g., setting outputmargin=TRUE for logistic regression would result in predictions for log-odds instead of probabilities.</p>
</td></tr>
<tr><td><code id="predict.xgb.Booster.prmdt_+3A_ntreelimit">ntreelimit</code></td>
<td>
<p>Deprecated, use iterationrange instead.</p>
</td></tr>
<tr><td><code id="predict.xgb.Booster.prmdt_+3A_predleaf">predleaf</code></td>
<td>
<p>whether predict leaf index.</p>
</td></tr>
<tr><td><code id="predict.xgb.Booster.prmdt_+3A_predcontrib">predcontrib</code></td>
<td>
<p>whether to return feature contributions to individual predictions (see Details).</p>
</td></tr>
<tr><td><code id="predict.xgb.Booster.prmdt_+3A_approxcontrib">approxcontrib</code></td>
<td>
<p>whether to use a fast approximation for feature contributions (see Details).</p>
</td></tr>
<tr><td><code id="predict.xgb.Booster.prmdt_+3A_predinteraction">predinteraction</code></td>
<td>
<p>whether to return contributions of feature interactions to individual predictions (see Details).</p>
</td></tr>
<tr><td><code id="predict.xgb.Booster.prmdt_+3A_reshape">reshape</code></td>
<td>
<p>whether to reshape the vector of predictions to a matrix form when there are several prediction outputs per case. This option has no effect when either of predleaf, predcontrib, or predinteraction flags is TRUE.</p>
</td></tr>
<tr><td><code id="predict.xgb.Booster.prmdt_+3A_...">...</code></td>
<td>
<p>additional arguments affecting the predictions produced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector or matrix of predictions for xgb model.
</p>

<hr>
<h2 id='prediction.variable.balance'>prediction.variable.balance</h2><span id='topic+prediction.variable.balance'></span>

<h3>Description</h3>

<p>Function that graphs the balance of the different categories of a column of a data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prediction.variable.balance(
  data,
  predict.variable,
  ylab = "Number of individuals",
  xlab = "",
  main = paste("Variable Distribution", predict.variable),
  col = NA
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prediction.variable.balance_+3A_data">data</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="prediction.variable.balance_+3A_predict.variable">predict.variable</code></td>
<td>
<p>Character type. The name of the variable to predict. This name must be part of the columns of the data frame.</p>
</td></tr>
<tr><td><code id="prediction.variable.balance_+3A_ylab">ylab</code></td>
<td>
<p>A character string that describes the y-axis on the graph.</p>
</td></tr>
<tr><td><code id="prediction.variable.balance_+3A_xlab">xlab</code></td>
<td>
<p>A character string that describes the x-axis on the graph.</p>
</td></tr>
<tr><td><code id="prediction.variable.balance_+3A_main">main</code></td>
<td>
<p>Character type. The main title of the chart.</p>
</td></tr>
<tr><td><code id="prediction.variable.balance_+3A_col">col</code></td>
<td>
<p>A vector that specifies the colors of the categories represented by bars within the chart.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object.
</p>


<h3>Note</h3>

<p>With this function we can identify if the data is balanced or not, according to the variable to be predicted.
</p>


<h3>See Also</h3>

<p><code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
prediction.variable.balance(iris,"Species")

</code></pre>

<hr>
<h2 id='print.indexes.prmdt'>Printing prmdt index object</h2><span id='topic+print.indexes.prmdt'></span>

<h3>Description</h3>

<p>Printing prmdt index object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'indexes.prmdt'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.indexes.prmdt_+3A_x">x</code></td>
<td>
<p>A prmdt index object</p>
</td></tr>
<tr><td><code id="print.indexes.prmdt_+3A_...">...</code></td>
<td>
<p>optional arguments to print o format method</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a print of the results of a prediction model.
</p>

<hr>
<h2 id='print.prediction.prmdt'>Printing prmdt prediction object</h2><span id='topic+print.prediction.prmdt'></span>

<h3>Description</h3>

<p>Printing prmdt prediction object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'prediction.prmdt'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.prediction.prmdt_+3A_x">x</code></td>
<td>
<p>A prmdt prediction object</p>
</td></tr>
<tr><td><code id="print.prediction.prmdt_+3A_...">...</code></td>
<td>
<p>optional arguments to print o format method</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a print prediction of a model.
</p>

<hr>
<h2 id='print.prmdt'>Printing prmdt models</h2><span id='topic+print.prmdt'></span>

<h3>Description</h3>

<p>Printing prmdt models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'prmdt'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.prmdt_+3A_x">x</code></td>
<td>
<p>A prmdt models</p>
</td></tr>
<tr><td><code id="print.prmdt_+3A_...">...</code></td>
<td>
<p>optional arguments to print o format method</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a print information of a model.
</p>

<hr>
<h2 id='ROC.area'>ROC.area</h2><span id='topic+ROC.area'></span>

<h3>Description</h3>

<p>Function that calculates the area of the ROC curve of a prediction with only 2 categories.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ROC.area(prediction, real)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ROC.area_+3A_prediction">prediction</code></td>
<td>
<p>A vector of real numbers representing the prediction score of a category.</p>
</td></tr>
<tr><td><code id="ROC.area_+3A_real">real</code></td>
<td>
<p>A vector with the real categories of the individuals in the prediction.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value of the area(numeric).
</p>


<h3>See Also</h3>

<p><code><a href="ROCR.html#topic+prediction">prediction</a></code> and <code><a href="ROCR.html#topic+performance">performance</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
iris2 &lt;- dplyr::filter(iris,(Species == "setosa") | (Species == "virginica"))
iris2$Species &lt;- factor(iris2$Species,levels = c("setosa","virginica"))
sam &lt;- sample(1:100,20)
ttesting &lt;- iris2[sam,]
ttraining &lt;- iris2[-sam,]
model &lt;- train.rpart(Species~.,ttraining)
prediction.prob &lt;- predict(model,ttesting, type = "prob")
ROC.area(prediction.prob$prediction[,2],ttesting$Species)

</code></pre>

<hr>
<h2 id='ROC.plot'>ROC.plot</h2><span id='topic+ROC.plot'></span>

<h3>Description</h3>

<p>Function that plots the ROC curve of a prediction with only 2 categories.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ROC.plot(prediction, real, .add = FALSE, color = "red")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ROC.plot_+3A_prediction">prediction</code></td>
<td>
<p>A vector of real numbers representing the prediction score of a category.</p>
</td></tr>
<tr><td><code id="ROC.plot_+3A_real">real</code></td>
<td>
<p>A vector with the real categories of the individuals in the prediction.</p>
</td></tr>
<tr><td><code id="ROC.plot_+3A_.add">.add</code></td>
<td>
<p>A logical value that indicates if it should be added to an existing graph</p>
</td></tr>
<tr><td><code id="ROC.plot_+3A_color">color</code></td>
<td>
<p>Color of the ROC curve in the graph</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot object.
</p>


<h3>See Also</h3>

<p><code><a href="ROCR.html#topic+prediction">prediction</a></code> and <code><a href="ROCR.html#topic+performance">performance</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
iris2 &lt;- dplyr::filter(iris,(Species == "setosa") | (Species == "virginica"))
iris2$Species &lt;- factor(iris2$Species,levels = c("setosa","virginica"))
sam &lt;- sample(1:100,20)
ttesting &lt;- iris2[sam,]
ttraining &lt;- iris2[-sam,]
model &lt;- train.rpart(Species~.,ttraining)
prediction.prob &lt;- predict(model,ttesting, type = "prob")
ROC.plot(prediction.prob$prediction[,2],ttesting$Species)

</code></pre>

<hr>
<h2 id='scaler'>scaler</h2><span id='topic+scaler'></span>

<h3>Description</h3>

<p>Returns a scaled data.frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scaler(df)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scaler_+3A_df">df</code></td>
<td>
<p>A data.frame only with numeric variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame.
</p>

<hr>
<h2 id='select_on_class'>select_on_class</h2><span id='topic+select_on_class'></span>

<h3>Description</h3>

<p>select_on_class
</p>


<h3>Usage</h3>

<pre><code class='language-R'>select_on_class(.data, clases = "numeric")
</code></pre>

<hr>
<h2 id='train.ada'>train.ada</h2><span id='topic+train.ada'></span>

<h3>Description</h3>

<p>Provides a wrapping function for the <code><a href="ada.html#topic+ada">ada</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train.ada(formula, data, ..., subset, na.action = na.rpart)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train.ada_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit.</p>
</td></tr>
<tr><td><code id="train.ada_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model.</p>
</td></tr>
<tr><td><code id="train.ada_+3A_...">...</code></td>
<td>
<p>arguments passed to rpart.control. For stumps, use rpart.control(maxdepth=1,cp=-1,minsplit=0,xval=0). maxdepth controls the depth of
trees, and cp controls the complexity of trees. The priors should also be fixed through the parms argument as discussed in the second reference.</p>
</td></tr>
<tr><td><code id="train.ada_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="train.ada_+3A_na.action">na.action</code></td>
<td>
<p>a function that indicates how to process ‘NA’ values. Default=na.rpart.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A object ada.prmdt with additional information to the model that allows to homogenize the results.
</p>


<h3>Note</h3>

<p>the parameter information was taken from the original function <code><a href="ada.html#topic+ada">ada</a></code>.
</p>


<h3>See Also</h3>

<p>The internal function is from package <code><a href="ada.html#topic+ada">ada</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Puromycin")

n &lt;- seq_len(nrow(Puromycin))
.sample &lt;- sample(n, length(n) * 0.75)
data.train &lt;- Puromycin[.sample,]
data.test &lt;- Puromycin[-.sample,]

modelo.ada &lt;- train.ada(state~., data.train)
modelo.ada
prob &lt;- predict(modelo.ada, data.test , type = "prob")
prob
prediccion &lt;- predict(modelo.ada, data.test , type = "class")
prediccion

</code></pre>

<hr>
<h2 id='train.adabag'>train.adabag</h2><span id='topic+train.adabag'></span>

<h3>Description</h3>

<p>Provides a wrapping function for the <code><a href="adabag.html#topic+boosting">boosting</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train.adabag(
  formula,
  data,
  boos = TRUE,
  mfinal = 100,
  coeflearn = "Breiman",
  minsplit = 20,
  maxdepth = 30,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train.adabag_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit.</p>
</td></tr>
<tr><td><code id="train.adabag_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model.</p>
</td></tr>
<tr><td><code id="train.adabag_+3A_boos">boos</code></td>
<td>
<p>if TRUE (by default), a bootstrap sample of the training set is drawn using the weights for each observation on that iteration.
If FALSE, every observation is used with its weights.</p>
</td></tr>
<tr><td><code id="train.adabag_+3A_mfinal">mfinal</code></td>
<td>
<p>an integer, the number of iterations for which boosting is run or the number of trees to use. Defaults to mfinal=100 iterations.</p>
</td></tr>
<tr><td><code id="train.adabag_+3A_coeflearn">coeflearn</code></td>
<td>
<p>if 'Breiman'(by default), alpha=1/2ln((1-err)/err) is used. If 'Freund' alpha=ln((1-err)/err) is used.
In both cases the AdaBoost.M1 algorithm is used and alpha is the weight updating coefficient.
On the other hand, if coeflearn is 'Zhu' the SAMME algorithm is implemented with alpha=ln((1-err)/err)+ ln(nclasses-1).</p>
</td></tr>
<tr><td><code id="train.adabag_+3A_minsplit">minsplit</code></td>
<td>
<p>the minimum number of observations that must exist in a node in order for a split to be attempted.</p>
</td></tr>
<tr><td><code id="train.adabag_+3A_maxdepth">maxdepth</code></td>
<td>
<p>Set the maximum depth of any node of the final tree, with the root node counted as depth 0. Values greater than 30 rpart will give nonsense results on 32-bit machines.</p>
</td></tr>
<tr><td><code id="train.adabag_+3A_...">...</code></td>
<td>
<p>arguments passed to rpart.control or adabag::boosting. For stumps, use rpart.control(maxdepth=1,cp=-1,minsplit=0,xval=0). maxdepth controls the depth of
trees, and cp controls the complexity of trees.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A object adabag.prmdt with additional information to the model that allows to homogenize the results.
</p>


<h3>Note</h3>

<p>The parameter information was taken from the original function <code><a href="adabag.html#topic+boosting">boosting</a></code> and <code><a href="rpart.html#topic+rpart.control">rpart.control</a></code>.
</p>


<h3>See Also</h3>

<p>The internal function is from package <code><a href="adabag.html#topic+boosting">boosting</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data &lt;- iris
n &lt;- nrow(data)

sam &lt;- sample(1:n,n*0.75)
training &lt;- data[sam,]
testing &lt;- data[-sam,]

model &lt;- train.adabag(formula = Species~.,data = training,minsplit = 2,
                      maxdepth = 30, mfinal = 10)
model
predict &lt;- predict(object = model,testing,type = "class")
predict

</code></pre>

<hr>
<h2 id='train.bayes'>train.bayes</h2><span id='topic+train.bayes'></span>

<h3>Description</h3>

<p>Provides a wrapping function for the <code><a href="e1071.html#topic+naiveBayes">naiveBayes</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train.bayes(formula, data, laplace = 0, ..., subset, na.action = na.pass)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train.bayes_+3A_formula">formula</code></td>
<td>
<p>A formula of the form class ~ x1 + x2 + .... Interactions are not allowed.</p>
</td></tr>
<tr><td><code id="train.bayes_+3A_data">data</code></td>
<td>
<p>Either a data frame of predictors (categorical and/or numeric) or a contingency table.</p>
</td></tr>
<tr><td><code id="train.bayes_+3A_laplace">laplace</code></td>
<td>
<p>positive double controlling Laplace smoothing. The default (0) disables Laplace smoothing.</p>
</td></tr>
<tr><td><code id="train.bayes_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
<tr><td><code id="train.bayes_+3A_subset">subset</code></td>
<td>
<p>For data given in a data frame, an index vector specifying the cases to be used in the training sample. (NOTE: If given, this argument must be named.)</p>
</td></tr>
<tr><td><code id="train.bayes_+3A_na.action">na.action</code></td>
<td>
<p>A function to specify the action to be taken if NAs are found. The default action is not to count them for the computation of the probability factors. An alternative is na.omit, which leads to rejection of cases with missing values on any required variable. (NOTE: If given, this argument must be named.)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A object bayes.prmdt with additional information to the model that allows to homogenize the results.
</p>


<h3>Note</h3>

<p>the parameter information was taken from the original function  <code><a href="e1071.html#topic+naiveBayes">naiveBayes</a></code>.
</p>


<h3>See Also</h3>

<p>The internal function is from package <code><a href="e1071.html#topic+naiveBayes">naiveBayes</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Classification
data("iris")

n &lt;- seq_len(nrow(iris))
.sample &lt;- sample(n, length(n) * 0.75)
data.train &lt;- iris[.sample,]
data.test &lt;- iris[-.sample,]

modelo.bayes &lt;- train.bayes(Species ~., data.train)
modelo.bayes
prob &lt;- predict(modelo.bayes, data.test, type = "prob")
prob
prediccion &lt;- predict(modelo.bayes, data.test, type = "class")
prediccion

# Regression
len &lt;- nrow(swiss)
sampl &lt;- sample(x = 1:len,size = len*0.20,replace = FALSE)
ttesting &lt;- swiss[sampl,]
ttraining &lt;- swiss[-sampl,]
model.bayes &lt;- train.bayes(Infant.Mortality~.,ttraining)
prediction &lt;- predict(model.bayes, ttesting)
prediction

</code></pre>

<hr>
<h2 id='train.gbm'>train.gbm</h2><span id='topic+train.gbm'></span>

<h3>Description</h3>

<p>Provides a wrapping function for the <code><a href="gbm.html#topic+gbm">gbm</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train.gbm(
  formula,
  data,
  distribution = "bernoulli",
  weights,
  var.monotone = NULL,
  n.trees = 100,
  interaction.depth = 1,
  n.minobsinnode = 10,
  shrinkage = 0.001,
  bag.fraction = 0.5,
  train.fraction = 1,
  cv.folds = 0,
  keep.data = TRUE,
  verbose = F,
  class.stratify.cv = NULL,
  n.cores = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train.gbm_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit.</p>
</td></tr>
<tr><td><code id="train.gbm_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model.</p>
</td></tr>
<tr><td><code id="train.gbm_+3A_distribution">distribution</code></td>
<td>
<p>Either a character string specifying the name of the distribution to use or a list with a component name specifying the distribution and any additional parameters needed.</p>
</td></tr>
<tr><td><code id="train.gbm_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights to be used in the fitting process. Must be positive but do not need to be normalized.</p>
</td></tr>
<tr><td><code id="train.gbm_+3A_var.monotone">var.monotone</code></td>
<td>
<p>an optional vector, the same length as the number of predictors, indicating which variables have a monotone increasing (+1), decreasing (-1), or arbitrary (0) relationship with the outcome.</p>
</td></tr>
<tr><td><code id="train.gbm_+3A_n.trees">n.trees</code></td>
<td>
<p>Integer specifying the total number of trees to fit. This is equivalent to the number of iterations and the number of basis functions in the additive expansion. Default is 100.</p>
</td></tr>
<tr><td><code id="train.gbm_+3A_interaction.depth">interaction.depth</code></td>
<td>
<p>Integer specifying the maximum depth of each tree (i.e., the highest level of variable interactions allowed). A value of 1 implies an additive model, a value of 2 implies a model with up to 2-way interactions, etc. Default is 1.</p>
</td></tr>
<tr><td><code id="train.gbm_+3A_n.minobsinnode">n.minobsinnode</code></td>
<td>
<p>Integer specifying the minimum number of observations in the terminal nodes of the trees. Note that this is the actual number of observations, not the total weight.</p>
</td></tr>
<tr><td><code id="train.gbm_+3A_shrinkage">shrinkage</code></td>
<td>
<p>a shrinkage parameter applied to each tree in the expansion. Also known as the learning rate or step-size reduction; 0.001 to 0.1 usually work, but a smaller learning rate typically requires more trees. Default is 0.1.</p>
</td></tr>
<tr><td><code id="train.gbm_+3A_bag.fraction">bag.fraction</code></td>
<td>
<p>the fraction of the training set observations randomly selected to propose the next tree in the expansion. This introduces randomnesses into the model fit.</p>
</td></tr>
<tr><td><code id="train.gbm_+3A_train.fraction">train.fraction</code></td>
<td>
<p>The first train.fraction * nrows(data) observations are used to fit the gbm and the remainder are used for computing out-of-sample estimates of the loss function.</p>
</td></tr>
<tr><td><code id="train.gbm_+3A_cv.folds">cv.folds</code></td>
<td>
<p>Number of cross-validation folds to perform. If cv.folds&gt;1 then gbm, in addition to the usual fit, will perform a cross-validation, calculate an estimate of generalization error returned in cv.error.</p>
</td></tr>
<tr><td><code id="train.gbm_+3A_keep.data">keep.data</code></td>
<td>
<p>a logical variable indicating whether to keep the data and an index of the data stored with the object. Keeping the data and index makes subsequent calls to gbm.more faster at the cost of storing an extra copy of the dataset.</p>
</td></tr>
<tr><td><code id="train.gbm_+3A_verbose">verbose</code></td>
<td>
<p>Logical indicating whether or not to print out progress and performance indicators (TRUE). If this option is left unspecified for gbm.more, then it uses verbose from object. Default is FALSE.</p>
</td></tr>
<tr><td><code id="train.gbm_+3A_class.stratify.cv">class.stratify.cv</code></td>
<td>
<p>Logical indicating whether or not the cross-validation should be stratified by class.</p>
</td></tr>
<tr><td><code id="train.gbm_+3A_n.cores">n.cores</code></td>
<td>
<p>The number of CPU cores to use. The cross-validation loop will attempt to send different CV folds off to different cores. If n.cores is not specified by the user, it is guessed using the detectCores function in the parallel package.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A object gbm.prmdt with additional information to the model that allows to homogenize the results.
</p>


<h3>Note</h3>

<p>The parameter information was taken from the original function <code><a href="gbm.html#topic+gbm">gbm</a></code>.
</p>


<h3>See Also</h3>

<p>The internal function is from package <code><a href="gbm.html#topic+gbm">gbm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Classification
data &lt;- iris
n &lt;- nrow(data)

sam &lt;- sample(1:n, n*0.75)
training &lt;- data[sam,]
testing &lt;- data[-sam,]

model &lt;- train.gbm(formula = Species ~ ., data = training)
model
predict &lt;- predict(object = model, testing)
predict

# Regression
len &lt;- nrow(swiss)
sampl &lt;- sample(x = 1:len,size = len*0.10,replace = FALSE)
ttesting &lt;- swiss[sampl,]
ttraining &lt;- swiss[-sampl,]
model.gbm &lt;- train.gbm(Infant.Mortality~., ttraining, distribution = "gaussian")
prediction &lt;- predict(model.gbm, ttesting)
prediction

</code></pre>

<hr>
<h2 id='train.glm'>train.glm</h2><span id='topic+train.glm'></span>

<h3>Description</h3>

<p>Provides a wrapping function for the <code><a href="stats.html#topic+glm">glm</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train.glm(
  formula,
  data,
  family = binomial,
  weights,
  subset,
  na.action,
  start = NULL,
  etastart,
  mustart,
  offset,
  control = list(...),
  model = TRUE,
  method = "glm.fit",
  x = FALSE,
  y = TRUE,
  singular.ok = TRUE,
  contrasts = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train.glm_+3A_formula">formula</code></td>
<td>
<p>an object of class &quot;formula&quot; (or one that can be coerced to that class): a symbolic description of the model to be fitted. The details of model specification are given under ‘Details’.</p>
</td></tr>
<tr><td><code id="train.glm_+3A_data">data</code></td>
<td>
<p>an optional data frame, list or environment (or object coercible by as.data.frame to a data frame) containing the variables in the model. If not found in data, the variables are taken from environment(formula), typically the environment from which glm is called.</p>
</td></tr>
<tr><td><code id="train.glm_+3A_family">family</code></td>
<td>
<p>a description of the error distribution and link function to be used in the model. For glm this can be a character string naming a family function, a family function or the result of a call to a family function. For glm.fit only the third option is supported. (See family for details of family functions.)</p>
</td></tr>
<tr><td><code id="train.glm_+3A_weights">weights</code></td>
<td>
<p>an optional vector of ‘prior weights’ to be used in the fitting process. Should be NULL or a numeric vector.</p>
</td></tr>
<tr><td><code id="train.glm_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="train.glm_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data contain NAs. The default is set by the na.action setting of options, and is na.fail if that is unset. The ‘factory-fresh’ default is na.omit. Another possible value is NULL, no action. Value na.exclude can be useful.</p>
</td></tr>
<tr><td><code id="train.glm_+3A_start">start</code></td>
<td>
<p>starting values for the parameters in the linear predictor.</p>
</td></tr>
<tr><td><code id="train.glm_+3A_etastart">etastart</code></td>
<td>
<p>starting values for the linear predictor.</p>
</td></tr>
<tr><td><code id="train.glm_+3A_mustart">mustart</code></td>
<td>
<p>starting values for the vector of means.</p>
</td></tr>
<tr><td><code id="train.glm_+3A_offset">offset</code></td>
<td>
<p>this can be used to specify an a priori known component to be included in the linear predictor during fitting. This should be NULL or a numeric vector of length equal to the number of cases. One or more offset terms can be included in the formula instead or as well, and if more than one is specified their sum is used. See model.offset.</p>
</td></tr>
<tr><td><code id="train.glm_+3A_control">control</code></td>
<td>
<p>a list of parameters for controlling the fitting process. For glm.fit this is passed to glm.control.</p>
</td></tr>
<tr><td><code id="train.glm_+3A_model">model</code></td>
<td>
<p>a logical value indicating whether model frame should be included as a component of the returned value.</p>
</td></tr>
<tr><td><code id="train.glm_+3A_method">method</code></td>
<td>
<p>the method to be used in fitting the model. The default method &quot;glm.fit&quot; uses iteratively reweighted least squares (IWLS): the alternative &quot;model.frame&quot; returns the model frame and does no fitting.
User-supplied fitting functions can be supplied either as a function or a character string naming a function, with a function which takes the same arguments as glm.fit. If specified as a character string it is looked up from within the stats namespace.</p>
</td></tr>
<tr><td><code id="train.glm_+3A_x">x</code>, <code id="train.glm_+3A_y">y</code></td>
<td>
<p>For glm: logical values indicating whether the response vector and model matrix used in the fitting process should be returned as components of the returned value.
For glm.fit: x is a design matrix of dimension n * p, and y is a vector of observations of length n.</p>
</td></tr>
<tr><td><code id="train.glm_+3A_singular.ok">singular.ok</code></td>
<td>
<p>logical; if FALSE a singular fit is an error.</p>
</td></tr>
<tr><td><code id="train.glm_+3A_contrasts">contrasts</code></td>
<td>
<p>an optional list. See the contrasts.arg of model.matrix.default.</p>
</td></tr>
<tr><td><code id="train.glm_+3A_...">...</code></td>
<td>
<p>For glm: arguments to be used to form the default control argument if it is not supplied directly.
For weights: further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A object glm.prmdt with additional information to the model that allows to homogenize the results.
</p>


<h3>See Also</h3>

<p>The internal function is from package <code><a href="stats.html#topic+glm">glm</a></code>.
</p>
<p>The internal function is from package <code><a href="stats.html#topic+glm">glm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Classification
data("Puromycin")

n &lt;- seq_len(nrow(Puromycin))
.sample &lt;- sample(n, length(n) * 0.65)
data.train &lt;- Puromycin[.sample,]
data.test &lt;- Puromycin[-.sample,]

modelo.glm &lt;- train.glm(state~., data.train)
modelo.glm
prob &lt;- predict(modelo.glm, data.test , type = "prob")
prob
prediccion &lt;- predict(modelo.glm, data.test , type = "class")
prediccion

# Regression
len &lt;- nrow(swiss)
sampl &lt;- sample(x = 1:len,size = len*0.20,replace = FALSE)
ttesting &lt;- swiss[sampl,]
ttraining &lt;- swiss[-sampl,]
model.glm &lt;- train.glm(Infant.Mortality~.,ttraining, family = "gaussian")
prediction &lt;- predict(model.glm, ttesting)
prediction


</code></pre>

<hr>
<h2 id='train.glmnet'>train.glmnet</h2><span id='topic+train.glmnet'></span>

<h3>Description</h3>

<p>Provides a wrapping function for the <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train.glmnet(
  formula,
  data,
  standardize = TRUE,
  alpha = 1,
  family = "multinomial",
  cv = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train.glmnet_+3A_formula">formula</code></td>
<td>
<p>A formula of the form groups ~ x1 + x2 + ... That is, the response is the grouping factor and the right hand side specifies the (non-factor) discriminators.</p>
</td></tr>
<tr><td><code id="train.glmnet_+3A_data">data</code></td>
<td>
<p>An optional data frame, list or environment from which variables specified in formula are preferentially to be taken.</p>
</td></tr>
<tr><td><code id="train.glmnet_+3A_standardize">standardize</code></td>
<td>
<p>Logical flag for x variable standardization, prior to fitting the model sequence.
The coefficients are always returned on the original scale. Default is standardize=TRUE.
If variables are in the same units already, you might not wish to standardize.
See details below for y standardization with family=&quot;gaussian&quot;.</p>
</td></tr>
<tr><td><code id="train.glmnet_+3A_alpha">alpha</code></td>
<td>
<p>The elasticnet mixing parameter. alpha=1 is the lasso penalty, and alpha=0 the ridge penalty.</p>
</td></tr>
<tr><td><code id="train.glmnet_+3A_family">family</code></td>
<td>
<p>Either a character string representing one of the built-in families, or else a glm() family object.
For more information, see Details section below or the documentation for response type (above).</p>
</td></tr>
<tr><td><code id="train.glmnet_+3A_cv">cv</code></td>
<td>
<p>True or False. Perform cross-validation to find the best value of the penalty parameter lambda and save this value in the model.
This value could be used in predict() function.</p>
</td></tr>
<tr><td><code id="train.glmnet_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A object glmnet.prmdt with additional information to the model that allows to homogenize the results.
</p>


<h3>Note</h3>

<p>The parameter information was taken from the original function <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>.
</p>


<h3>See Also</h3>

<p>The internal function is from package <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Classification
len &lt;- nrow(iris)
sampl &lt;- sample(x = 1:len,size = len*0.20,replace = FALSE)
ttesting &lt;- iris[sampl,]
ttraining &lt;- iris[-sampl,]
model.glmnet &lt;- train.glmnet(Species~.,ttraining)
prediction &lt;- predict(model.glmnet,ttesting)
prediction

# Regression
len &lt;- nrow(swiss)
sampl &lt;- sample(x = 1:len,size = len*0.20,replace = FALSE)
ttesting &lt;- swiss[sampl,]
ttraining &lt;- swiss[-sampl,]
model.glmnet &lt;- train.glmnet(Infant.Mortality~.,ttraining, family = "gaussian")
prediction &lt;- predict(model.glmnet, ttesting)
prediction

</code></pre>

<hr>
<h2 id='train.knn'>train.knn</h2><span id='topic+train.knn'></span>

<h3>Description</h3>

<p>Provides a wrapping function for the <code><a href="kknn.html#topic+train.kknn">train.kknn</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train.knn(
  formula,
  data,
  kmax = 11,
  ks = NULL,
  distance = 2,
  kernel = "optimal",
  ykernel = NULL,
  scale = TRUE,
  contrasts = c(unordered = "contr.dummy", ordered = "contr.ordinal"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train.knn_+3A_formula">formula</code></td>
<td>
<p>A formula object.</p>
</td></tr>
<tr><td><code id="train.knn_+3A_data">data</code></td>
<td>
<p>Matrix or data frame.</p>
</td></tr>
<tr><td><code id="train.knn_+3A_kmax">kmax</code></td>
<td>
<p>Maximum number of k, if ks is not specified.</p>
</td></tr>
<tr><td><code id="train.knn_+3A_ks">ks</code></td>
<td>
<p>A vector specifying values of k. If not null, this takes precedence over kmax.</p>
</td></tr>
<tr><td><code id="train.knn_+3A_distance">distance</code></td>
<td>
<p>Parameter of Minkowski distance.</p>
</td></tr>
<tr><td><code id="train.knn_+3A_kernel">kernel</code></td>
<td>
<p>Kernel to use. Possible choices are &quot;rectangular&quot; (which is standard unweighted knn), &quot;triangular&quot;, &quot;epanechnikov&quot; (or beta(2,2)),
&quot;biweight&quot; (or beta(3,3)), &quot;triweight&quot; (or beta(4,4)), &quot;cos&quot;, &quot;inv&quot;, &quot;gaussian&quot; and &quot;optimal&quot;.</p>
</td></tr>
<tr><td><code id="train.knn_+3A_ykernel">ykernel</code></td>
<td>
<p>Window width of an y-kernel, especially for prediction of ordinal classes.</p>
</td></tr>
<tr><td><code id="train.knn_+3A_scale">scale</code></td>
<td>
<p>logical, scale variable to have equal sd.</p>
</td></tr>
<tr><td><code id="train.knn_+3A_contrasts">contrasts</code></td>
<td>
<p>A vector containing the 'unordered' and 'ordered' contrasts to use.</p>
</td></tr>
<tr><td><code id="train.knn_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A object knn.prmdt with additional information to the model that allows to homogenize the results.
</p>


<h3>Note</h3>

<p>the parameter information was taken from the original function <code><a href="kknn.html#topic+train.kknn">train.kknn</a></code>.
</p>


<h3>See Also</h3>

<p>The internal function is from package <code><a href="kknn.html#topic+train.kknn">train.kknn</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Classification
data("iris")

n &lt;- seq_len(nrow(iris))
.sample &lt;- sample(n, length(n) * 0.75)
data.train &lt;- iris[.sample,]
data.test &lt;- iris[-.sample,]

modelo.knn &lt;- train.knn(Species~., data.train)
modelo.knn
prob &lt;- predict(modelo.knn, data.test, type = "prob")
prob
prediccion &lt;- predict(modelo.knn, data.test, type = "class")
prediccion

# Regression
len &lt;- nrow(swiss)
sampl &lt;- sample(x = 1:len,size = len*0.20,replace = FALSE)
ttesting &lt;- swiss[sampl,]
ttraining &lt;- swiss[-sampl,]
model.knn &lt;- train.knn(Infant.Mortality~.,ttraining)
prediction &lt;- predict(model.knn, ttesting)
prediction

</code></pre>

<hr>
<h2 id='train.lda'>train.lda</h2><span id='topic+train.lda'></span>

<h3>Description</h3>

<p>Provides a wrapping function for the <code><a href="MASS.html#topic+lda">lda</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train.lda(formula, data, ..., subset, na.action)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train.lda_+3A_formula">formula</code></td>
<td>
<p>A formula of the form groups ~ x1 + x2 + ... That is, the response is the grouping factor and the right hand side specifies the (non-factor) discriminators.</p>
</td></tr>
<tr><td><code id="train.lda_+3A_data">data</code></td>
<td>
<p>An optional data frame, list or environment from which variables specified in formula are preferentially to be taken.</p>
</td></tr>
<tr><td><code id="train.lda_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="train.lda_+3A_subset">subset</code></td>
<td>
<p>An index vector specifying the cases to be used in the training sample. (NOTE: If given, this argument must be named.)</p>
</td></tr>
<tr><td><code id="train.lda_+3A_na.action">na.action</code></td>
<td>
<p>Function to specify the action to be taken if NAs are found. The default action is for the procedure to fail.
An alternative is na.omit, which leads to rejection of cases with missing values on any required variable.
(NOTE: If given, this argument must be named.)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A object lda.prmdt with additional information to the model that allows to homogenize the results.
</p>


<h3>Note</h3>

<p>The parameter information was taken from the original function <code><a href="MASS.html#topic+lda">lda</a></code>.
</p>


<h3>See Also</h3>

<p>The internal function is from package <code><a href="MASS.html#topic+lda">lda</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
len &lt;- nrow(iris)
sampl &lt;- sample(x = 1:len,size = len*0.20,replace = FALSE)
ttesting &lt;- iris[sampl,]
ttraining &lt;- iris[-sampl,]
model.lda &lt;- train.lda(Species~.,ttraining)
model.lda
prediction &lt;- predict(model.lda,ttesting)
prediction

</code></pre>

<hr>
<h2 id='train.neuralnet'>train.neuralnet</h2><span id='topic+train.neuralnet'></span>

<h3>Description</h3>

<p>Provides a wrapping function for the <code><a href="neuralnet.html#topic+neuralnet">neuralnet</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train.neuralnet(
  formula,
  data,
  hidden = 1,
  threshold = 0.01,
  stepmax = 1e+05,
  rep = 1,
  startweights = NULL,
  learningrate.limit = NULL,
  learningrate.factor = list(minus = 0.5, plus = 1.2),
  learningrate = NULL,
  lifesign = "none",
  lifesign.step = 1000,
  algorithm = "rprop+",
  err.fct = "sse",
  act.fct = "logistic",
  linear.output = TRUE,
  exclude = NULL,
  constant.weights = NULL,
  likelihood = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train.neuralnet_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fitted.</p>
</td></tr>
<tr><td><code id="train.neuralnet_+3A_data">data</code></td>
<td>
<p>a data frame containing the variables specified in formula.</p>
</td></tr>
<tr><td><code id="train.neuralnet_+3A_hidden">hidden</code></td>
<td>
<p>a vector of integers specifying the number of hidden neurons (vertices) in each layer.</p>
</td></tr>
<tr><td><code id="train.neuralnet_+3A_threshold">threshold</code></td>
<td>
<p>a numeric value specifying the threshold for the partial derivatives of the error function as stopping criteria.</p>
</td></tr>
<tr><td><code id="train.neuralnet_+3A_stepmax">stepmax</code></td>
<td>
<p>the maximum steps for the training of the neural network. Reaching this maximum leads to a stop of the neural network's training process.</p>
</td></tr>
<tr><td><code id="train.neuralnet_+3A_rep">rep</code></td>
<td>
<p>the number of repetitions for the neural network's training.</p>
</td></tr>
<tr><td><code id="train.neuralnet_+3A_startweights">startweights</code></td>
<td>
<p>a vector containing starting values for the weights. Set to NULL for random initialization.</p>
</td></tr>
<tr><td><code id="train.neuralnet_+3A_learningrate.limit">learningrate.limit</code></td>
<td>
<p>a vector or a list containing the lowest and highest limit for the learning rate. Used only for RPROP and GRPROP.</p>
</td></tr>
<tr><td><code id="train.neuralnet_+3A_learningrate.factor">learningrate.factor</code></td>
<td>
<p>a vector or a list containing the multiplication factors for the upper and lower learning rate. Used only for RPROP and GRPROP.</p>
</td></tr>
<tr><td><code id="train.neuralnet_+3A_learningrate">learningrate</code></td>
<td>
<p>a numeric value specifying the learning rate used by traditional backpropagation. Used only for traditional backpropagation.</p>
</td></tr>
<tr><td><code id="train.neuralnet_+3A_lifesign">lifesign</code></td>
<td>
<p>a string specifying how much the function will print during the calculation of the neural network. 'none', 'minimal' or 'full'.</p>
</td></tr>
<tr><td><code id="train.neuralnet_+3A_lifesign.step">lifesign.step</code></td>
<td>
<p>an integer specifying the stepsize to print the minimal threshold in full lifesign mode.</p>
</td></tr>
<tr><td><code id="train.neuralnet_+3A_algorithm">algorithm</code></td>
<td>
<p>a string containing the algorithm type to calculate the neural network. The
following types are possible: 'backprop', 'rprop+', 'rprop-', 'sag', or 'slr'. 'backprop'
refers to backpropagation, 'rprop+' and 'rprop-' refer to the resilient backpropagation
with and without weight backtracking, while 'sag' and 'slr' induce the usage of the modified globally
convergent algorithm (grprop). See Details for more information.</p>
</td></tr>
<tr><td><code id="train.neuralnet_+3A_err.fct">err.fct</code></td>
<td>
<p>a differentiable function that is used for the calculation of the error. Alternatively, the strings 'sse'
and 'ce' which stand for the sum of squared errors and the cross-entropy can be used.</p>
</td></tr>
<tr><td><code id="train.neuralnet_+3A_act.fct">act.fct</code></td>
<td>
<p>a differentiable function that is used for smoothing the result of the cross product of the covariate or neurons and the weights.
Additionally the strings, 'logistic' and 'tanh' are possible for the logistic function and tangent hyperbolicus.</p>
</td></tr>
<tr><td><code id="train.neuralnet_+3A_linear.output">linear.output</code></td>
<td>
<p>logical. If act.fct should not be applied to the output neurons set linear output to TRUE, otherwise to FALSE.</p>
</td></tr>
<tr><td><code id="train.neuralnet_+3A_exclude">exclude</code></td>
<td>
<p>a vector or a matrix specifying the weights, that are excluded from the calculation.
If given as a vector, the exact positions of the weights must be known. A matrix with n-rows and 3 columns will exclude n weights,
where the first column stands for the layer, the second column for the input neuron and the third column for the output neuron of the weight.</p>
</td></tr>
<tr><td><code id="train.neuralnet_+3A_constant.weights">constant.weights</code></td>
<td>
<p>a vector specifying the values of the weights that are excluded from the training process and treated as fix.</p>
</td></tr>
<tr><td><code id="train.neuralnet_+3A_likelihood">likelihood</code></td>
<td>
<p>logical. If the error function is equal to the negative log-likelihood function, the
information criteria AIC and BIC will be calculated. Furthermore the usage of confidence.interval is meaningfull.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A object neuralnet.prmdt with additional information to the model that allows to homogenize the results.
</p>


<h3>Note</h3>

<p>the parameter information was taken from the original function <code><a href="neuralnet.html#topic+neuralnet">neuralnet</a></code>.
</p>


<h3>See Also</h3>

<p>The internal function is from package <code><a href="neuralnet.html#topic+neuralnet">neuralnet</a></code>.
</p>

<hr>
<h2 id='train.nnet'>train.nnet</h2><span id='topic+train.nnet'></span>

<h3>Description</h3>

<p>Provides a wrapping function for the <code><a href="nnet.html#topic+nnet">nnet</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train.nnet(formula, data, weights, ..., subset, na.action, contrasts = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train.nnet_+3A_formula">formula</code></td>
<td>
<p>A formula of the form class ~ x1 + x2 + ...</p>
</td></tr>
<tr><td><code id="train.nnet_+3A_data">data</code></td>
<td>
<p>Data frame from which variables specified in formula are preferentially to be taken.</p>
</td></tr>
<tr><td><code id="train.nnet_+3A_weights">weights</code></td>
<td>
<p>(case) weights for each example – if missing defaults to 1.</p>
</td></tr>
<tr><td><code id="train.nnet_+3A_...">...</code></td>
<td>
<p>arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="train.nnet_+3A_subset">subset</code></td>
<td>
<p>An index vector specifying the cases to be used in the training sample. (NOTE: If given, this argument must be named.)</p>
</td></tr>
<tr><td><code id="train.nnet_+3A_na.action">na.action</code></td>
<td>
<p>A function to specify the action to be taken if NAs are found. The default action is for the
procedure to fail. An alternative is na.omit, which leads to rejection of cases with missing
values on any required variable. (NOTE: If given, this argument must be named.)</p>
</td></tr>
<tr><td><code id="train.nnet_+3A_contrasts">contrasts</code></td>
<td>
<p>a list of contrasts to be used for some or all of the factors appearing as variables in the model formula.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A object nnet.prmdt with additional information to the model that allows to homogenize the results.
</p>


<h3>Note</h3>

<p>the parameter information was taken from the original function <code><a href="nnet.html#topic+nnet">nnet</a></code>.
</p>


<h3>See Also</h3>

<p>The internal function is from package <code><a href="nnet.html#topic+nnet">nnet</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Classification
data("iris")

n &lt;- seq_len(nrow(iris))
.sample &lt;- sample(n, length(n) * 0.75)
data.train &lt;- iris[.sample,]
data.test &lt;- iris[-.sample,]

modelo.nn &lt;- train.nnet(Species~., data.train, size = 20)
modelo.nn
prob &lt;- predict(modelo.nn, data.test, type = "prob")
prob
prediccion &lt;- predict(modelo.nn, data.test, type = "class")
prediccion

# Regression
len &lt;- nrow(swiss)
sampl &lt;- sample(x = 1:len,size = len*0.20,replace = FALSE)
ttesting &lt;- swiss[sampl,]
ttraining &lt;- swiss[-sampl,]
model.knn &lt;- train.nnet(Infant.Mortality~.,ttraining, size = 20)
prediction &lt;- predict(model.knn, ttesting)
prediction

</code></pre>

<hr>
<h2 id='train.qda'>train.qda</h2><span id='topic+train.qda'></span>

<h3>Description</h3>

<p>Provides a wrapping function for the <code><a href="MASS.html#topic+qda">qda</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train.qda(formula, data, ..., subset, na.action)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train.qda_+3A_formula">formula</code></td>
<td>
<p>A formula of the form groups ~ x1 + x2 + ... That is, the response is the grouping factor and the right hand side specifies the (non-factor) discriminators.</p>
</td></tr>
<tr><td><code id="train.qda_+3A_data">data</code></td>
<td>
<p>An optional data frame, list or environment from which variables specified in formula are preferentially to be taken.</p>
</td></tr>
<tr><td><code id="train.qda_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="train.qda_+3A_subset">subset</code></td>
<td>
<p>An index vector specifying the cases to be used in the training sample. (NOTE: If given, this argument must be named.)</p>
</td></tr>
<tr><td><code id="train.qda_+3A_na.action">na.action</code></td>
<td>
<p>Function to specify the action to be taken if NAs are found. The default action is for the procedure to fail.
An alternative is na.omit, which leads to rejection of cases with missing values on any required variable.
(NOTE: If given, this argument must be named.)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A object qda.prmdt with additional information to the model that allows to homogenize the results.
</p>


<h3>Note</h3>

<p>The parameter information was taken from the original function <code><a href="MASS.html#topic+qda">qda</a></code>.
</p>


<h3>See Also</h3>

<p>The internal function is from package <code><a href="MASS.html#topic+qda">qda</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
len &lt;- nrow(iris)
sampl &lt;- sample(x = 1:len,size = len*0.20,replace = FALSE)
ttesting &lt;- iris[sampl,]
ttraining &lt;- iris[-sampl,]
model.qda &lt;- train.qda(Species~.,ttraining)
model.qda
prediction &lt;- predict(model.qda, ttesting)
prediction

</code></pre>

<hr>
<h2 id='train.randomForest'>train.randomForest</h2><span id='topic+train.randomForest'></span>

<h3>Description</h3>

<p>Provides a wrapping function for the <code><a href="randomForest.html#topic+randomForest">randomForest</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train.randomForest(formula, data, ..., subset, na.action = na.fail)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train.randomForest_+3A_formula">formula</code></td>
<td>
<p>a formula describing the model to be fitted (for the print method, an randomForest object).</p>
</td></tr>
<tr><td><code id="train.randomForest_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model. By default the variables are taken from the environment which randomForest is called from.</p>
</td></tr>
<tr><td><code id="train.randomForest_+3A_...">...</code></td>
<td>
<p>optional parameters to be passed to the low level function randomForest.default.</p>
</td></tr>
<tr><td><code id="train.randomForest_+3A_subset">subset</code></td>
<td>
<p>an index vector indicating which rows should be used. (NOTE: If given, this argument must be named.)</p>
</td></tr>
<tr><td><code id="train.randomForest_+3A_na.action">na.action</code></td>
<td>
<p>A function to specify the action to be taken if NAs are found. (NOTE: If given, this argument must be named.)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A object randomForest.prmdt with additional information to the model that allows to homogenize the results.
</p>


<h3>Note</h3>

<p>the parameter information was taken from the original function  <code><a href="randomForest.html#topic+randomForest">randomForest</a></code>.
</p>


<h3>See Also</h3>

<p>The internal function is from package <code><a href="randomForest.html#topic+randomForest">randomForest</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Classification
data("iris")

n &lt;- seq_len(nrow(iris))
.sample &lt;- sample(n, length(n) * 0.75)
data.train &lt;- iris[.sample,]
data.test &lt;- iris[-.sample,]

modelo.rf &lt;- train.randomForest(Species~., data.train)
modelo.rf
prob &lt;- predict(modelo.rf, data.test, type = "prob")
prob
prediccion &lt;- predict(modelo.rf, data.test, type = "class")
prediccion

# Regression
len &lt;- nrow(swiss)
sampl &lt;- sample(x = 1:len,size = len*0.20,replace = FALSE)
ttesting &lt;- swiss[sampl,]
ttraining &lt;- swiss[-sampl,]
model.rf &lt;- train.randomForest(Infant.Mortality~.,ttraining)
prediction &lt;- predict(model.rf, ttesting)
prediction

</code></pre>

<hr>
<h2 id='train.rpart'>train.rpart</h2><span id='topic+train.rpart'></span>

<h3>Description</h3>

<p>Provides a wrapping function for the <code><a href="rpart.html#topic+rpart">rpart</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train.rpart(
  formula,
  data,
  weights,
  subset,
  na.action = na.rpart,
  method,
  model = TRUE,
  x = FALSE,
  y = TRUE,
  parms,
  control,
  cost,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train.rpart_+3A_formula">formula</code></td>
<td>
<p>a formula, with a response but no interaction terms. If this a a data frame, that is taken as the model frame.</p>
</td></tr>
<tr><td><code id="train.rpart_+3A_data">data</code></td>
<td>
<p>an optional data frame in which to interpret the variables named in the formula.</p>
</td></tr>
<tr><td><code id="train.rpart_+3A_weights">weights</code></td>
<td>
<p>optional case weights.</p>
</td></tr>
<tr><td><code id="train.rpart_+3A_subset">subset</code></td>
<td>
<p>optional expression saying that only a subset of the rows of the data should be used in the fit.</p>
</td></tr>
<tr><td><code id="train.rpart_+3A_na.action">na.action</code></td>
<td>
<p>the default action deletes all observations for which y is missing, but keeps those in which one or more predictors are missing.</p>
</td></tr>
<tr><td><code id="train.rpart_+3A_method">method</code></td>
<td>
<p>one of &quot;anova&quot;, &quot;poisson&quot;, &quot;class&quot; or &quot;exp&quot;. If method is missing then the routine tries to make an intelligent guess. If y is a survival object, then method = &quot;exp&quot; is assumed, if y has 2 columns then method = &quot;poisson&quot; is assumed, if y is a factor then method = &quot;class&quot; is assumed, otherwise method = &quot;anova&quot; is assumed. It is wisest to specify the method directly, especially as more criteria may added to the function in future.
Alternatively, method can be a list of functions named init, split and eval. Examples are given in the file ‘tests/usersplits.R’ in the sources, and in the vignettes ‘User Written Split Functions’.</p>
</td></tr>
<tr><td><code id="train.rpart_+3A_model">model</code></td>
<td>
<p>if logical: keep a copy of the model frame in the result? If the input value for model is a model frame (likely from an earlier call to the rpart function), then this frame is used rather than constructing new data.</p>
</td></tr>
<tr><td><code id="train.rpart_+3A_x">x</code></td>
<td>
<p>keep a copy of the x matrix in the result.</p>
</td></tr>
<tr><td><code id="train.rpart_+3A_y">y</code></td>
<td>
<p>keep a copy of the dependent variable in the result. If missing and model is supplied this defaults to FALSE.</p>
</td></tr>
<tr><td><code id="train.rpart_+3A_parms">parms</code></td>
<td>
<p>optional parameters for the splitting function.
Anova splitting has no parameters.
Poisson splitting has a single parameter, the coefficient of variation of the prior distribution on the rates. The default value is 1.
Exponential splitting has the same parameter as Poisson.
For classification splitting, the list can contain any of: the vector of prior probabilities (component prior), the loss matrix (component loss) or the splitting index (component split). The priors must be positive and sum to 1. The loss matrix must have zeros on the diagonal and positive off-diagonal elements. The splitting index can be gini or information. The default priors are proportional to the data counts, the losses default to 1, and the split defaults to gini.</p>
</td></tr>
<tr><td><code id="train.rpart_+3A_control">control</code></td>
<td>
<p>a list of options that control details of the rpart algorithm. See <code><a href="rpart.html#topic+rpart.control">rpart.control</a></code>.</p>
</td></tr>
<tr><td><code id="train.rpart_+3A_cost">cost</code></td>
<td>
<p>a vector of non-negative costs, one for each variable in the model. Defaults to one for all variables. These are scalings to be applied when considering splits, so the improvement on splitting on a variable is divided by its cost in deciding which split to choose.</p>
</td></tr>
<tr><td><code id="train.rpart_+3A_...">...</code></td>
<td>
<p>arguments to <code><a href="rpart.html#topic+rpart.control">rpart.control</a></code> may also be specified in the call to rpart. They are checked against the list of valid arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A object rpart.prmdt with additional information to the model that allows to homogenize the results.
</p>


<h3>Note</h3>

<p>the parameter information was taken from the original function <code><a href="rpart.html#topic+rpart">rpart</a></code>.
</p>


<h3>See Also</h3>

<p>The internal function is from package <code><a href="rpart.html#topic+rpart">rpart</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Classification
data("iris")

n &lt;- seq_len(nrow(iris))
.sample &lt;- sample(n, length(n) * 0.75)
data.train &lt;- iris[.sample,]
data.test &lt;- iris[-.sample,]

modelo.rpart &lt;- train.rpart(Species~., data.train)
modelo.rpart
prob &lt;- predict(modelo.rpart, data.test, type = "prob")
prob
prediccion &lt;- predict(modelo.rpart, data.test, type = "class")
prediccion

# Regression
len &lt;- nrow(swiss)
sampl &lt;- sample(x = 1:len,size = len*0.20,replace = FALSE)
ttesting &lt;- swiss[sampl,]
ttraining &lt;- swiss[-sampl,]
model.rpart &lt;- train.rpart(Infant.Mortality~.,ttraining)
prediction &lt;- predict(model.rpart,ttesting)
prediction

</code></pre>

<hr>
<h2 id='train.svm'>train.svm</h2><span id='topic+train.svm'></span>

<h3>Description</h3>

<p>Provides a wrapping function for the <code><a href="e1071.html#topic+svm">svm</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train.svm(formula, data, ..., subset, na.action = na.omit, scale = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train.svm_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit.</p>
</td></tr>
<tr><td><code id="train.svm_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model. By default the variables are taken from the environment which ‘svm’ is called from.</p>
</td></tr>
<tr><td><code id="train.svm_+3A_...">...</code></td>
<td>
<p>additional parameters for the low level fitting function svm.default</p>
</td></tr>
<tr><td><code id="train.svm_+3A_subset">subset</code></td>
<td>
<p>An index vector specifying the cases to be used in the training sample. (NOTE: If given, this argument must be named.)</p>
</td></tr>
<tr><td><code id="train.svm_+3A_na.action">na.action</code></td>
<td>
<p>A function to specify the action to be taken if NAs are found. The default action is
na.omit, which leads to rejection of cases with missing values on any required variable.
An alternative is na.fail, which causes an error if NA cases are found. (NOTE: If given, this argument must be named.)</p>
</td></tr>
<tr><td><code id="train.svm_+3A_scale">scale</code></td>
<td>
<p>A logical vector indicating the variables to be scaled. If scale is of length 1, the value is
recycled as many times as needed. Per default, data are scaled internally (both x and y variables) to zero mean and unit variance.
The center and scale values are returned and used for later predictions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A object svm.prmdt with additional information to the model that allows to homogenize the results.
</p>


<h3>Note</h3>

<p>the parameter information was taken from the original function <code><a href="e1071.html#topic+svm">svm</a></code>.
</p>


<h3>See Also</h3>

<p>The internal function is from package <code><a href="e1071.html#topic+svm">svm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Classification
data("iris")

n &lt;- seq_len(nrow(iris))
.sample &lt;- sample(n, length(n) * 0.75)
data.train &lt;- iris[.sample,]
data.test &lt;- iris[-.sample,]

modelo.svm &lt;- train.svm(Species~., data.train)
modelo.svm
prob &lt;- predict(modelo.svm, data.test , type = "prob")
prob
prediccion &lt;- predict(modelo.svm, data.test , type = "class")
prediccion

# Regression
len &lt;- nrow(swiss)
sampl &lt;- sample(x = 1:len,size = len*0.20,replace = FALSE)
ttesting &lt;- swiss[sampl,]
ttraining &lt;- swiss[-sampl,]
model.svm &lt;- train.svm(Infant.Mortality~.,ttraining)
prediction &lt;- predict(model.svm, ttesting)
prediction

</code></pre>

<hr>
<h2 id='train.xgboost'>train.xgboost</h2><span id='topic+train.xgboost'></span>

<h3>Description</h3>

<p>Provides a wrapping function for the <code><a href="xgboost.html#topic+xgb.train">xgb.train</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train.xgboost(
  formula,
  data,
  nrounds,
  watchlist = list(),
  obj = NULL,
  feval = NULL,
  verbose = 1,
  print_every_n = 1L,
  early_stopping_rounds = NULL,
  maximize = NULL,
  save_period = NULL,
  save_name = "xgboost.model",
  xgb_model = NULL,
  callbacks = list(),
  eval_metric = "mlogloss",
  extra_params = NULL,
  booster = "gbtree",
  objective = NULL,
  eta = 0.3,
  gamma = 0,
  max_depth = 6,
  min_child_weight = 1,
  subsample = 1,
  colsample_bytree = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train.xgboost_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit.</p>
</td></tr>
<tr><td><code id="train.xgboost_+3A_data">data</code></td>
<td>
<p>training dataset. xgb.train accepts only an xgb.DMatrix as the input. xgboost, in addition, also accepts matrix, dgCMatrix, or name of a local data file.</p>
</td></tr>
<tr><td><code id="train.xgboost_+3A_nrounds">nrounds</code></td>
<td>
<p>max number of boosting iterations.</p>
</td></tr>
<tr><td><code id="train.xgboost_+3A_watchlist">watchlist</code></td>
<td>
<p>named list of xgb.DMatrix datasets to use for evaluating model performance.
Metrics specified in either eval_metric or feval will be computed for each of these
datasets during each boosting iteration, and stored in the end as a field named evaluation_log in the resulting object.
When either verbose&gt;=1 or cb.print.evaluation callback is engaged, the performance results are continuously printed out
during the training. E.g., specifying watchlist=list(validation1=mat1, validation2=mat2) allows to track the performance
of each round's model on mat1 and mat2.</p>
</td></tr>
<tr><td><code id="train.xgboost_+3A_obj">obj</code></td>
<td>
<p>customized objective function. Returns gradient and second order gradient with given prediction and dtrain.</p>
</td></tr>
<tr><td><code id="train.xgboost_+3A_feval">feval</code></td>
<td>
<p>custimized evaluation function. Returns list(metric='metric-name', value='metric-value') with given prediction and dtrain.</p>
</td></tr>
<tr><td><code id="train.xgboost_+3A_verbose">verbose</code></td>
<td>
<p>If 0, xgboost will stay silent. If 1, it will print information about performance. If 2, some additional information will be printed out.
Note that setting verbose &gt; 0 automatically engages the cb.print.evaluation(period=1) callback function.</p>
</td></tr>
<tr><td><code id="train.xgboost_+3A_print_every_n">print_every_n</code></td>
<td>
<p>Print each n-th iteration evaluation messages when verbose&gt;0. Default is 1 which means all messages are printed.
This parameter is passed to the cb.print.evaluation callback.</p>
</td></tr>
<tr><td><code id="train.xgboost_+3A_early_stopping_rounds">early_stopping_rounds</code></td>
<td>
<p>If NULL, the early stopping function is not triggered. If set to an integer k,
training with a validation set will stop if the performance doesn't improve for k rounds.
Setting this parameter engages the cb.early.stop callback.</p>
</td></tr>
<tr><td><code id="train.xgboost_+3A_maximize">maximize</code></td>
<td>
<p>If feval and early_stopping_rounds are set, then this parameter must be set as well. When it is TRUE, it means the larger
the evaluation score the better. This parameter is passed to the cb.early.stop callback.</p>
</td></tr>
<tr><td><code id="train.xgboost_+3A_save_period">save_period</code></td>
<td>
<p>when it is non-NULL, model is saved to disk after every save_period rounds, 0 means save at the end. The saving is handled by the cb.save.model callback.</p>
</td></tr>
<tr><td><code id="train.xgboost_+3A_save_name">save_name</code></td>
<td>
<p>the name or path for periodically saved model file.</p>
</td></tr>
<tr><td><code id="train.xgboost_+3A_xgb_model">xgb_model</code></td>
<td>
<p>a previously built model to continue the training from. Could be either an object of class xgb.Booster, or its raw data, or the name
of a file with a previously saved model.</p>
</td></tr>
<tr><td><code id="train.xgboost_+3A_callbacks">callbacks</code></td>
<td>
<p>a list of callback functions to perform various task during boosting. See callbacks. Some of the callbacks are automatically created
depending on the parameters' values. User can provide either existing or their own callback methods in order to customize the training process.</p>
</td></tr>
<tr><td><code id="train.xgboost_+3A_eval_metric">eval_metric</code></td>
<td>
<p>eval_metric evaluation metrics for validation data. Users can pass a self-defined function to it. Default: metric will be assigned
according to objective(rmse for regression, and error for classification, mean average precision for ranking). List is
provided in detail section.</p>
</td></tr>
<tr><td><code id="train.xgboost_+3A_extra_params">extra_params</code></td>
<td>
<p>the list of parameters. The complete list of parameters is available at http://xgboost.readthedocs.io/en/latest/parameter.html.</p>
</td></tr>
<tr><td><code id="train.xgboost_+3A_booster">booster</code></td>
<td>
<p>booster which booster to use, can be gbtree or gblinear. Default: gbtree.</p>
</td></tr>
<tr><td><code id="train.xgboost_+3A_objective">objective</code></td>
<td>
<p>objective specify the learning task and the corresponding learning objective, users can pass a self-defined function to it. The default objective options are below:
+ reg:linear linear regression (Default).
+ reg:logistic logistic regression.
+ binary:logistic logistic regression for binary classification. Output probability.
+ binary:logitraw logistic regression for binary classification, output score before logistic transformation.
+ num_class set the number of classes. To use only with multiclass objectives.
+ multi:softmax set xgboost to do multiclass classification using the softmax objective. Class is represented by a number and should be from 0 to num_class - 1.
+ multi:softprob same as softmax, but prediction outputs a vector of ndata * nclass elements, which can be further reshaped to ndata, nclass matrix. The result contains predicted probabilities of each data point belonging to each class.
+ rank:pairwise set xgboost to do ranking task by minimizing the pairwise loss.</p>
</td></tr>
<tr><td><code id="train.xgboost_+3A_eta">eta</code></td>
<td>
<p>eta control the learning rate: scale the contribution of each tree by a factor of 0 &lt; eta &lt; 1 when it is added to the current approximation.
Used to prevent overfitting by making the boosting process more conservative. Lower value for eta implies larger value for nrounds: low eta
value means model more robust to overfitting but slower to compute. Default: 0.3</p>
</td></tr>
<tr><td><code id="train.xgboost_+3A_gamma">gamma</code></td>
<td>
<p>gamma minimum loss reduction required to make a further partition on a leaf node of the tree. the larger, the more conservative
the algorithm will be.gamma minimum loss reduction required to make a further partition on a leaf node of the tree. the larger, the more
conservative the algorithm will be.</p>
</td></tr>
<tr><td><code id="train.xgboost_+3A_max_depth">max_depth</code></td>
<td>
<p>max_depth maximum depth of a tree. Default: 6</p>
</td></tr>
<tr><td><code id="train.xgboost_+3A_min_child_weight">min_child_weight</code></td>
<td>
<p>min_child_weight minimum sum of instance weight (hessian) needed in a child. If the tree partition step results in a leaf node
with the sum of instance weight less than min_child_weight, then the building process will give up further partitioning. In linear
regression mode, this simply corresponds to minimum number of instances needed to be in each node. The larger, the more conservative
the algorithm will be. Default: 1</p>
</td></tr>
<tr><td><code id="train.xgboost_+3A_subsample">subsample</code></td>
<td>
<p>subsample subsample ratio of the training instance. Setting it to 0.5 means that xgboost randomly collected half of the data instances to
grow trees and this will prevent overfitting. It makes computation shorter (because less data to analyse). It is advised to use this parameter
with eta and increase nrounds. Default: 1</p>
</td></tr>
<tr><td><code id="train.xgboost_+3A_colsample_bytree">colsample_bytree</code></td>
<td>
<p>colsample_bytree subsample ratio of columns when constructing each tree. Default: 1</p>
</td></tr>
<tr><td><code id="train.xgboost_+3A_...">...</code></td>
<td>
<p>other parameters to pass to params.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A object xgb.Booster.prmdt with additional information to the model that allows to homogenize the results.
</p>


<h3>Note</h3>

<p>the parameter information was taken from the original function <code><a href="xgboost.html#topic+xgb.train">xgb.train</a></code>.
</p>


<h3>See Also</h3>

<p>The internal function is from package <code><a href="xgboost.html#topic+xgb.train">xgb.train</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# Classification
data("iris")

n &lt;- seq_len(nrow(iris))
.sample &lt;- sample(n, length(n) * 0.75)
data.train &lt;- iris[.sample,]
data.test &lt;- iris[-.sample,]

modelo.xg &lt;- train.xgboost(Species~., data.train, nrounds = 10, maximize = FALSE)
modelo.xg
prob &lt;- predict(modelo.xg, data.test, type = "prob")
prob
prediccion &lt;- predict(modelo.xg, data.test, type = "class")
prediccion

# Regression
len &lt;- nrow(swiss)
sampl &lt;- sample(x = 1:len,size = len*0.20,replace = FALSE)
ttesting &lt;- swiss[sampl,]
ttraining &lt;- swiss[-sampl,]
model.xgb &lt;- train.xgboost(Infant.Mortality~.,ttraining, nrounds = 10, maximize = FALSE)
prediction &lt;- predict(model.xgb, ttesting)
prediction


</code></pre>

<hr>
<h2 id='traineR'>Predictive (Classification and Regression) Models Homologator</h2><span id='topic+traineR'></span>

<h3>Description</h3>

<p>Methods to unify the different ways of creating predictive models and their different predictive formats for classification and regression. It includes
methods such as K-Nearest Neighbors Schliep, K. P. (2004) &lt;doi:10.5282/ubm/epub.1769&gt;, Decision Trees Leo Breiman, Jerome H. Friedman, Richard A. Olshen, Charles J. Stone (2017) &lt;doi:10.1201/9781315139470&gt;,
ADA Boosting Esteban Alfaro, Matias Gamez, Noelia García (2013) &lt;doi:10.18637/jss.v054.i02&gt;, Extreme Gradient Boosting Chen &amp; Guestrin (2016) &lt;doi:10.1145/2939672.2939785&gt;,
Random Forest Breiman (2001) &lt;doi:10.1023/A:1010933404324&gt;, Neural Networks Venables, W. N., &amp; Ripley, B. D. (2002) &lt;ISBN:0-387-95457-0&gt;,
Support Vector Machines Bennett, K. P. &amp; Campbell, C. (2000) &lt;doi:10.1145/380995.380999&gt;, Bayesian Methods Gelman, A., Carlin, J. B., Stern, H. S., &amp; Rubin, D. B. (1995) &lt;doi:10.1201/9780429258411&gt;,
Linear Discriminant Analysis Venables, W. N., &amp; Ripley, B. D. (2002) &lt;ISBN:0-387-95457-0&gt;, Quadratic Discriminant Analysis Venables, W. N., &amp; Ripley, B. D. (2002) &lt;ISBN:0-387-95457-0&gt;,
Logistic Regression Dobson, A. J., &amp; Barnett, A. G. (2018) &lt;doi:10.1201/9781315182780&gt; and Penalized Logistic Regression Friedman, J. H., Hastie, T., &amp; Tibshirani, R. (2010) &lt;doi:10.18637/jss.v033.i01&gt;.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> traineR</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 2.2.0</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2023-11-09</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;=2)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Maintainer: Oldemar Rodriguez Rojas &lt;oldemar.rodriguez@ucr.ac.cr&gt;<br />
</p>

<ul>
<li><p> Oldemar Rodriguez Rojas &lt;oldemar.rodriguez@ucr.ac.cr&gt;
</p>
</li>
<li><p> Andres Navarro D
</p>
</li>
<li><p> Ariel Arroyo S
</p>
</li>
<li><p> Diego Jiménez
</p>
</li></ul>


<hr>
<h2 id='type_correction'>type_correction</h2><span id='topic+type_correction'></span>

<h3>Description</h3>

<p>type_correction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>type_correction(model, prediction, fix)
</code></pre>

<hr>
<h2 id='varplot'>Plotting prmdt ada models</h2><span id='topic+varplot'></span>

<h3>Description</h3>

<p>Plotting prmdt ada models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varplot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varplot_+3A_x">x</code></td>
<td>
<p>A ada prmdt model</p>
</td></tr>
<tr><td><code id="varplot_+3A_...">...</code></td>
<td>
<p>optional arguments to print o format method</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a plot of the importance of variables.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
