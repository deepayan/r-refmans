<!DOCTYPE html><html><head><title>Help for package KODAMA</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {KODAMA}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#categorical.test'><p>Categorical Information</p></a></li>
<li><a href='#clinical'><p>Clinical Data of a Cohort of Prostate Cancer Patiens</p></a></li>
<li><a href='#continuous.test'><p>Continuous Information</p></a></li>
<li><a href='#core_cpp'><p>Maximization of Cross-Validateed Accuracy Methods</p></a></li>
<li><a href='#correlation.test'><p>Continuous Information</p></a></li>
<li><a href='#dinisurface'><p>Ulisse Dini Data Set Generator</p></a></li>
<li><a href='#floyd'><p>Find Shortest Paths Between All Nodes in a Graph</p></a></li>
<li><a href='#frequency_matching'><p>Frequency Matching</p></a></li>
<li><a href='#grid-internal'><p>Internal Grid Functions</p></a></li>
<li><a href='#helicoid'><p>Helicoid Data Set Generator</p></a></li>
<li><a href='#k.test'><p>K-Test of Statistical Association</p></a></li>
<li><a href='#knn.double.cv'><p>Cross-Validation with k-Nearest Neighbors algorithm.</p></a></li>
<li><a href='#knn.kodama'><p>k-Nearest Neighbors Classifier.</p></a></li>
<li><a href='#KODAMA.matrix'><p>Knowledge Discovery by Accuracy Maximization</p></a></li>
<li><a href='#KODAMA.visualization'><p>Visualization of KODAMA output</p></a></li>
<li><a href='#loads'><p>Variable Ranking</p></a></li>
<li><a href='#lymphoma'><p>Lymphoma Gene Expression Dataset</p></a></li>
<li><a href='#mcplot'><p>Evaluation of the Monte Carlo accuracy results</p></a></li>
<li><a href='#MetRef'><p>Nuclear Magnetic Resonance Spectra of Urine Samples</p></a></li>
<li><a href='#multi_analysis'><p>Continuous Information</p></a></li>
<li><a href='#normalization'><p>Normalization Methods</p></a></li>
<li><a href='#pca'><p>Principal Components Analysis</p></a></li>
<li><a href='#pls.double.cv'><p>Cross-Validation with PLS-DA.</p></a></li>
<li><a href='#pls.kodama'><p>Partial Least Squares regression.</p></a></li>
<li><a href='#scaling'><p>Scaling Methods</p></a></li>
<li><a href='#spirals'><p>Spirals Data Set Generator</p></a></li>
<li><a href='#swissroll'><p>Swiss Roll Data Set Generator</p></a></li>
<li><a href='#transformy'><p>Conversion Classification Vector to Matrix</p></a></li>
<li><a href='#txtsummary'><p>Median and Coefficient Interval</p></a></li>
<li><a href='#USA'><p>State of the Union Data Set</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>2.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-01-11</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Stefano Cacciatore &lt;tkcaccia@gmail.com&gt;</td>
</tr>
<tr>
<td>Title:</td>
<td>Knowledge Discovery by Accuracy Maximization</td>
</tr>
<tr>
<td>Description:</td>
<td>An unsupervised and semi-supervised learning algorithm that performs feature extraction 
  from noisy and high-dimensional data. It facilitates identification of patterns representing underlying 
  groups on all samples in a data set. Based on Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA. 
  (2017) Bioinformatics &lt;<a href="https://doi.org/10.1093%2Fbioinformatics%2Fbtw705">doi:10.1093/bioinformatics/btw705</a>&gt; and Cacciatore S, Luchinat C, Tenori L. (2014) 
  Proc Natl Acad Sci USA &lt;<a href="https://doi.org/10.1073%2Fpnas.1220873111">doi:10.1073/pnas.1220873111</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10.0), stats, minerva, Rtsne, umap</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.12.4)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Suggests:</td>
<td>rgl, knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>SuggestsNote:</td>
<td>No suggestions</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-01-11 15:27:04 UTC; user</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Author:</td>
<td>Stefano Cacciatore
    <a href="https://orcid.org/0000-0001-7052-7156"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, trl,
    cre],
  Leonardo Tenori <a href="https://orcid.org/0000-0001-6438-059X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-01-12 11:20:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='categorical.test'>Categorical Information</h2><span id='topic+categorical.test'></span>

<h3>Description</h3>

<p>Summarization of the categorical information.</p>


<h3>Usage</h3>

<pre><code class='language-R'>categorical.test (name,x,y,total.column=FALSE,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="categorical.test_+3A_name">name</code></td>
<td>
<p>the name of the feature.</p>
</td></tr>
<tr><td><code id="categorical.test_+3A_x">x</code></td>
<td>
<p>the information to summarize.</p>
</td></tr>
<tr><td><code id="categorical.test_+3A_y">y</code></td>
<td>
<p>the classification of the cohort.</p>
</td></tr>
<tr><td><code id="categorical.test_+3A_total.column">total.column</code></td>
<td>
<p>option to visualize the total (by default = &quot;<code>FALSE</code>&quot;).</p>
</td></tr>
<tr><td><code id="categorical.test_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to the function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a table with the summarized information and The p-value computated using the Fisher's test.
</p>


<h3>Author(s)</h3>

<p>Stefano Cacciatore</p>


<h3>References</h3>

<p>Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+correlation.test">correlation.test</a></code>,<code><a href="#topic+continuous.test">continuous.test</a></code>, <code><a href="#topic+txtsummary">txtsummary</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(clinical)

hosp=clinical[,"Hospital"]
gender=clinical[,"Gender"]
GS=clinical[,"Gleason score"]
BMI=clinical[,"BMI"]
age=clinical[,"Age"]

A=categorical.test("Gender",gender,hosp)
B=categorical.test("Gleason score",GS,hosp)

C=continuous.test("BMI",BMI,hosp,digits=2)
D=continuous.test("Age",age,hosp,digits=1)

rbind(A,B,C,D)


</code></pre>

<hr>
<h2 id='clinical'>Clinical Data of a Cohort of Prostate Cancer Patiens</h2><span id='topic+clinical'></span>

<h3>Description</h3>

<p>The data belong to a cohort of 35 patients with prostate cancer from two different hospitals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(clinical)</code></pre>


<h3>Value</h3>

<p>The data.frame &quot;<code>prcomp</code>&quot; with the following elements: &quot;<code>Hospital</code>&quot;, &quot;<code>Gender</code>&quot;, &quot;<code>Gleason score</code>&quot;,  &quot;<code>BMI</code>&quot;, and &quot;<code>Age</code>&quot;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(clinical)

head(clinical)
</code></pre>

<hr>
<h2 id='continuous.test'>Continuous Information</h2><span id='topic+continuous.test'></span>

<h3>Description</h3>

<p>Summarization of the continuous information.</p>


<h3>Usage</h3>

<pre><code class='language-R'>continuous.test (name,
                 x,    
                 y,
                 digits = 3,
                 scientific = FALSE, 
                 range = c("IQR","95%CI"), 
                 logchange = FALSE,
                 pos=2, 
                 method=c("non-parametric","parametric"),
                 total.column=FALSE, ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="continuous.test_+3A_name">name</code></td>
<td>
<p>the name of the feature.</p>
</td></tr>
<tr><td><code id="continuous.test_+3A_x">x</code></td>
<td>
<p>the information to summarize.</p>
</td></tr>
<tr><td><code id="continuous.test_+3A_y">y</code></td>
<td>
<p>the classification of the cohort.</p>
</td></tr>
<tr><td><code id="continuous.test_+3A_digits">digits</code></td>
<td>
<p>how many significant digits are to be used.</p>
</td></tr>
<tr><td><code id="continuous.test_+3A_scientific">scientific</code></td>
<td>
<p>either a logical specifying whether result should be encoded in scientific format.</p>
</td></tr>
<tr><td><code id="continuous.test_+3A_range">range</code></td>
<td>
<p>the range to be visualized.</p>
</td></tr>
<tr><td><code id="continuous.test_+3A_logchange">logchange</code></td>
<td>
<p>either a logical specifying whether log2 of fold change  should be visualized.</p>
</td></tr>
<tr><td><code id="continuous.test_+3A_pos">pos</code></td>
<td>
<p>a value indicating the position of range to be visualized. 1 for column, 2 for row.</p>
</td></tr>
<tr><td><code id="continuous.test_+3A_method">method</code></td>
<td>
<p>a character string indicating which test method is to be computed. &quot;non-parametric&quot; (default), or &quot;parametric&quot;.</p>
</td></tr>
<tr><td><code id="continuous.test_+3A_total.column">total.column</code></td>
<td>
<p>option to visualize the total (by default = &quot;<code>FALSE</code>&quot;)</p>
</td></tr>
<tr><td><code id="continuous.test_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a table with the summarized information and the relative p-value. For non-parametric method, if the number of group is equal to two, the p-value is computed using the Wilcoxon rank-sum test, Kruskal-Wallis test otherwise. For parametric method, if the number of group is equal to two, the p-value is computed using the Student's t-Test, ANOVA one-way otherwise.
</p>


<h3>Author(s)</h3>

<p>Stefano Cacciatore</p>


<h3>References</h3>

<p>Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+correlation.test">correlation.test</a></code>, <code><a href="#topic+categorical.test">categorical.test</a></code>, <code><a href="#topic+txtsummary">txtsummary</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(clinical)

hosp=clinical[,"Hospital"]
gender=clinical[,"Gender"]
GS=clinical[,"Gleason score"]
BMI=clinical[,"BMI"]
age=clinical[,"Age"]

A=categorical.test("Gender",gender,hosp)
B=categorical.test("Gleason score",GS,hosp)

C=continuous.test("BMI",BMI,hosp,digits=2)
D=continuous.test("Age",age,hosp,digits=1)

rbind(A,B,C,D)


</code></pre>

<hr>
<h2 id='core_cpp'>Maximization of Cross-Validateed Accuracy Methods</h2><span id='topic+core_cpp'></span>

<h3>Description</h3>

<p>This function performs the maximization of cross-validated accuracy by an iterative process</p>


<h3>Usage</h3>

<pre><code class='language-R'>core_cpp(x, 
         xTdata=NULL,
         clbest, 
         Tcycle=20, 
         FUN=c("PLS-DA","KNN"), 
         fpar=2, 
         constrain=NULL, 
         fix=NULL, 
         shake=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="core_cpp_+3A_x">x</code></td>
<td>
<p>a matrix.</p>
</td></tr>
<tr><td><code id="core_cpp_+3A_xtdata">xTdata</code></td>
<td>
<p>a matrix for projections. This matrix contains samples that are not used for the maximization of the cross-validated accuracy. Their classification is obtained by predicting samples on the basis of the final classification vector.</p>
</td></tr>
<tr><td><code id="core_cpp_+3A_clbest">clbest</code></td>
<td>
<p>a vector to optimize.</p>
</td></tr>
<tr><td><code id="core_cpp_+3A_tcycle">Tcycle</code></td>
<td>
<p>number of iterative cycles that leads to the maximization of cross-validated accuracy.</p>
</td></tr>
<tr><td><code id="core_cpp_+3A_fun">FUN</code></td>
<td>
<p>classifier to be consider. Choices are &quot;<code>KNN</code>&quot; and &quot;<code>PLS-DA</code>&quot;.</p>
</td></tr>
<tr><td><code id="core_cpp_+3A_fpar">fpar</code></td>
<td>
<p>parameters of the classifier. If the classifier is <code>KNN</code>, <code>fpar</code> represents the number of neighbours. If the classifier is <code>PLS-DA</code>, <code>fpar</code> represents the number of components.</p>
</td></tr>
<tr><td><code id="core_cpp_+3A_constrain">constrain</code></td>
<td>

<p>a vector of <code>nrow(data)</code> elements. Supervised constraints can be imposed by linking some samples in such a way that if one of them is changed, all other linked samples change in the same way (<em>i.e.</em>, they are forced to belong to the same class) during the maximization of the cross-validation accuracy procedure. Samples with the same identifying constrain will be forced to stay together.
</p>
</td></tr>
<tr><td><code id="core_cpp_+3A_fix">fix</code></td>
<td>

<p>a vector of <code>nrow(data)</code> elements. The values of this vector must  be <code>TRUE</code> or <code>FALSE</code>. By default all elements are <code>FALSE</code>. Samples with the <code>TRUE</code> fix value will not change the class label defined in <code>W</code> during the maximization of the cross-validation accuracy procedure. For more information refer to Cacciatore, <em>et al.</em> (2014).
</p>
</td></tr>
<tr><td><code id="core_cpp_+3A_shake">shake</code></td>
<td>
<p>if <code>shake = FALSE</code> the cross-validated accuracy is computed with the class defined in <code>W</code>, before the maximization of the cross-validation accuracy procedure.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list with 3 items:
</p>
<table>
<tr><td><code>clbest</code></td>
<td>
<p>a classification vector with a maximized cross-validated accuracy.</p>
</td></tr>
<tr><td><code>accbest</code></td>
<td>
<p>the maximum cross-validated accuracy achieved.</p>
</td></tr>
<tr><td><code>vect_acc</code></td>
<td>
<p>a vector of all cross-validated accuracies obtained.</p>
</td></tr>
<tr><td><code>vect_proj</code></td>
<td>
<p>a prediction of samples in <code>xTdata</code> matrix using the vector clbest. This output is present only if <code>xTdata</code> is not <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Stefano Cacciatore and Leonardo Tenori</p>


<h3>References</h3>

<p>Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+KODAMA.matrix">KODAMA.matrix</a></code>,<code><a href="#topic+KODAMA.visualization">KODAMA.visualization</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Here, the famous (Fisher's or Anderson's) iris data set was loaded
data(iris)
u=as.matrix(iris[,-5])
s=sample(1:150,150,TRUE)

# The maximization of the accuracy of the vector s is performed
results=core_cpp(u, clbest=s,fpar = 5)


print(as.numeric(results$clbest))

</code></pre>

<hr>
<h2 id='correlation.test'>Continuous Information</h2><span id='topic+correlation.test'></span>

<h3>Description</h3>

<p>Summarization of the continuous information.</p>


<h3>Usage</h3>

<pre><code class='language-R'>correlation.test (x,
                  y,
                  method = c("pearson", "spearman","MINE"), 
                  name=NA, 
                  perm=100, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="correlation.test_+3A_x">x</code></td>
<td>
<p>a numeric vector.</p>
</td></tr>
<tr><td><code id="correlation.test_+3A_y">y</code></td>
<td>
<p>a numeric vector.</p>
</td></tr>
<tr><td><code id="correlation.test_+3A_method">method</code></td>
<td>
<p>a character string indicating which correlation method is to be computed. &quot;pearson&quot; (default), &quot;spearman&quot;, or &quot;MINE&quot;.</p>
</td></tr>
<tr><td><code id="correlation.test_+3A_name">name</code></td>
<td>
<p>the name of the feature.</p>
</td></tr>
<tr><td><code id="correlation.test_+3A_perm">perm</code></td>
<td>
<p>number of permutation needed to estimate the p-value with MINE correlation.</p>
</td></tr>
<tr><td><code id="correlation.test_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a table with the summarized information. 
</p>


<h3>Author(s)</h3>

<p>Stefano Cacciatore</p>


<h3>References</h3>

<p>Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+categorical.test">categorical.test</a></code>,<code><a href="#topic+continuous.test">continuous.test</a></code>, <code><a href="#topic+txtsummary">txtsummary</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(clinical)

correlation.test(clinical[,"Age"],clinical[,"BMI"],name="correlation between Age and BMI")

</code></pre>

<hr>
<h2 id='dinisurface'>Ulisse Dini Data Set Generator</h2><span id='topic+dinisurface'></span>

<h3>Description</h3>

<p>This function creates a data set based upon data points distributed on a Ulisse Dini's surface.</p>


<h3>Usage</h3>

<pre><code class='language-R'>dinisurface(N=1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dinisurface_+3A_n">N</code></td>
<td>
<p>Number of data points.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a three dimensional data set.
</p>


<h3>Author(s)</h3>

<p>Stefano Cacciatore and Leonardo Tenori</p>


<h3>References</h3>

<p>Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+helicoid">helicoid</a></code>, <code><a href="#topic+swissroll">swissroll</a></code>, <code><a href="#topic+spirals">spirals</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>require("rgl")
x=dinisurface()
open3d()
plot3d(x, col=rainbow(1000),box=FALSE,size=3)
</code></pre>

<hr>
<h2 id='floyd'>Find Shortest Paths Between All Nodes in a Graph</h2><span id='topic+floyd'></span>

<h3>Description</h3>

<p>The <code>floyd</code> function finds all shortest paths in a graph using Floyd's algorithm. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>floyd(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="floyd_+3A_data">data</code></td>
<td>
<p>matrix or distance object</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>floyd</code> returns a matrix with the total lengths of the shortest path between each pair of points.
</p>


<h3>References</h3>

<p>Floyd, Robert W	<br />
Algorithm 97: Shortest Path.<br />
<em>Communications of the ACM</em> 1962; 5 (6): 345. doi:10.1145/367766.368168. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'># build a graph with 5 nodes
x=matrix(c(0,NA,NA,NA,NA,30,0,NA,NA,NA,10,NA,0,NA,NA,NA,70,50,0,10,NA,40,20,60,0),ncol=5)
print(x)

# compute all path lengths
z=floyd(x)
print(z)

</code></pre>

<hr>
<h2 id='frequency_matching'>Frequency Matching</h2><span id='topic+frequency_matching'></span>

<h3>Description</h3>

<p>A method to select unbalanced groupd in a cohort.</p>


<h3>Usage</h3>

<pre><code class='language-R'>frequency_matching (data,label,times=5,seed=1234)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="frequency_matching_+3A_data">data</code></td>
<td>
<p>a data.frame of data.</p>
</td></tr>
<tr><td><code id="frequency_matching_+3A_label">label</code></td>
<td>
<p>a classification of the groups.</p>
</td></tr>
<tr><td><code id="frequency_matching_+3A_times">times</code></td>
<td>
<p>The ratio between the two groups.</p>
</td></tr>
<tr><td><code id="frequency_matching_+3A_seed">seed</code></td>
<td>
<p>a single number for random number generation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list with 2 items or 4 items (if a test data set is present):
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>the data after the frequency matching.</p>
</td></tr>
<tr><td><code>label</code></td>
<td>
<p>the label after the frequency matching.</p>
</td></tr>
<tr><td><code>selection</code></td>
<td>
<p>the rows selected for the frequency matching.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Stefano Cacciatore</p>


<h3>References</h3>

<p>Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(clinical)

hosp=clinical[,"Hospital"]
gender=clinical[,"Gender"]
GS=clinical[,"Gleason score"]
BMI=clinical[,"BMI"]
age=clinical[,"Age"]

A=categorical.test("Gender",gender,hosp)
B=categorical.test("Gleason score",GS,hosp)

C=continuous.test("BMI",BMI,hosp,digits=2)
D=continuous.test("Age",age,hosp,digits=1)

# Analysis without matching
rbind(A,B,C,D)



# The order is important. Right is more important than left in the vector
# So, Ethnicity will be more important than Age
var=c("Age","BMI","Gleason score")
t=frequency_matching(clinical[,var],clinical[,"Hospital"],times=1)

newdata=clinical[t$selection,]

hosp.new=newdata[,"Hospital"]
gender.new=newdata[,"Gender"]
GS.new=newdata[,"Gleason score"]
BMI.new=newdata[,"BMI"]
age.new=newdata[,"Age"]

A=categorical.test("Gender",gender.new,hosp.new)
B=categorical.test("Gleason score",GS.new,hosp.new)

C=continuous.test("BMI",BMI.new,hosp.new,digits=2)
D=continuous.test("Age",age.new,hosp.new,digits=1)

# Analysis with matching
rbind(A,B,C,D)

</code></pre>

<hr>
<h2 id='grid-internal'>Internal Grid Functions</h2><span id='topic+RQ'></span><span id='topic+another'></span><span id='topic+knn_Armadillo'></span>

<h3>Description</h3>

<p>Internal Grid functions
</p>


<h3>Details</h3>

<p>These are not to be called by the user (or in some cases are just
waiting for proper documentation to be written :).
</p>


<h3>Value</h3>

<p>The return values of these function are used for internal usage.
</p>

<hr>
<h2 id='helicoid'>Helicoid Data Set Generator</h2><span id='topic+helicoid'></span>

<h3>Description</h3>

<p>This function creates a data set based upon data points distributed on a Helicoid surface.</p>


<h3>Usage</h3>

<pre><code class='language-R'>helicoid(N=1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="helicoid_+3A_n">N</code></td>
<td>
<p>Number of data points.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a three dimensional data set.
</p>


<h3>Author(s)</h3>

<p>Stefano Cacciatore and Leonardo Tenori</p>


<h3>References</h3>

<p>Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+swissroll">swissroll</a></code>,<code><a href="#topic+dinisurface">dinisurface</a></code>,<code><a href="#topic+spirals">spirals</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>require("rgl")
x=helicoid()
open3d()
plot3d(x, col=rainbow(1000),box=FALSE,size=3)
</code></pre>

<hr>
<h2 id='k.test'>K-Test of Statistical Association</h2><span id='topic+k.test'></span>

<h3>Description</h3>

<p>This function performs a permutation test using PLS to assess association between the KODAMA output and any additional related parameters such as clinical metadata.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k.test(data, labels, n = 100)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k.test_+3A_data">data</code></td>
<td>
<p>a matrix.</p>
</td></tr>
<tr><td><code id="k.test_+3A_labels">labels</code></td>
<td>
<p>a classification vector.</p>
</td></tr>
<tr><td><code id="k.test_+3A_n">n</code></td>
<td>
<p>number of iterations of the permutation test.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The p-value of the test.
</p>


<h3>Author(s)</h3>

<p>Stefano Cacciatore</p>


<h3>References</h3>

<p>Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+KODAMA.matrix">KODAMA.matrix</a></code>,<code><a href="#topic+KODAMA.visualization">KODAMA.visualization</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
  data(iris)
 data=iris[,-5]
 labels=iris[,5]
 kk=KODAMA.matrix(data,FUN="KNN",f.par=2)
 kkplot=KODAMA.visualization(kk,"t-SNE")
 k1=k.test(kkplot,labels)
 print(k1)
 k2=k.test(kkplot,sample(labels))
 print(k2)

</code></pre>

<hr>
<h2 id='knn.double.cv'>Cross-Validation with k-Nearest Neighbors algorithm.</h2><span id='topic+knn.double.cv'></span>

<h3>Description</h3>

<p>This function performs a 10-fold cross validation on a given data set using <em>k</em>-Nearest Neighbors (<em>k</em>NN) model. To assess the prediction ability of the model, a 10-fold cross-validation is conducted by generating splits with a ratio 1:9 of the data set, that is by removing 10% of samples prior to any step of the statistical analysis, including PLS component selection and scaling. Best number of component for PLS was carried out by means of 10-fold cross-validation on the remaining 90% selecting the best Q2y value. Permutation testing was undertaken to estimate the classification/regression performance of predictors.</p>


<h3>Usage</h3>

<pre><code class='language-R'>knn.double.cv(Xdata,
              Ydata,
              constrain=1:nrow(Xdata),
              compmax=min(5,c(ncol(Xdata),nrow(Xdata))),
              perm.test=FALSE,
              optim=TRUE,
              scaling = c("centering","autoscaling"),
              times=100,
              runn=10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="knn.double.cv_+3A_xdata">Xdata</code></td>
<td>
<p>a matrix.</p>
</td></tr>
<tr><td><code id="knn.double.cv_+3A_ydata">Ydata</code></td>
<td>
<p>the responses. If Ydata is a numeric vector, a regression analysis will be performed. If Ydata is factor, a classification analysis will be performed. </p>
</td></tr>
<tr><td><code id="knn.double.cv_+3A_constrain">constrain</code></td>
<td>
<p>a vector of <code>nrow(data)</code> elements. Sample with the same identifying constrain will be split in the training set or in the test set of cross-validation together.</p>
</td></tr>
<tr><td><code id="knn.double.cv_+3A_compmax">compmax</code></td>
<td>
<p>the number of k to be used for classification.</p>
</td></tr>
<tr><td><code id="knn.double.cv_+3A_perm.test">perm.test</code></td>
<td>
<p>a classification vector.</p>
</td></tr>
<tr><td><code id="knn.double.cv_+3A_optim">optim</code></td>
<td>
<p>if perform the optmization of the number of k.</p>
</td></tr>
<tr><td><code id="knn.double.cv_+3A_scaling">scaling</code></td>
<td>
<p>the scaling method to be used. Choices are &quot;<code>centering</code>&quot; or &quot;<code>autoscaling</code>&quot; (by default = &quot;<code>centering</code>&quot;). A partial string sufficient to uniquely identify the choice is permitted.</p>
</td></tr>
<tr><td><code id="knn.double.cv_+3A_times">times</code></td>
<td>
<p>number of cross-validations with permutated samples</p>
</td></tr>
<tr><td><code id="knn.double.cv_+3A_runn">runn</code></td>
<td>
<p>number of cross-validations loops.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>Ypred</code></td>
<td>
<p>the vector containing the predicted values of the response variables obtained by cross-validation.</p>
</td></tr>
<tr><td><code>Yfit</code></td>
<td>
<p>the vector containing the fitted values of the response variables.</p>
</td></tr>
<tr><td><code>Q2Y</code></td>
<td>
<p>Q2y value.</p>
</td></tr>
<tr><td><code>R2Y</code></td>
<td>
<p>R2y value.</p>
</td></tr>
<tr><td><code>conf</code></td>
<td>
<p>The confusion matrix (only in classification mode).</p>
</td></tr>
<tr><td><code>acc</code></td>
<td>
<p>The cross-validated accuracy (only in classification mode).</p>
</td></tr>
<tr><td><code>txtQ2Y</code></td>
<td>
<p>a summary of the Q2y values.</p>
</td></tr>
<tr><td><code>txtR2Y</code></td>
<td>
<p>a summary of the R2y values.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Stefano Cacciatore</p>


<h3>References</h3>

<p>Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 data(iris)
 data=iris[,-5]
 labels=iris[,5]
 pp=knn.double.cv(data,labels)
 print(pp$Q2Y)
 table(pp$Ypred,labels)
 

 data(MetRef)
 u=MetRef$data;
 u=u[,-which(colSums(u)==0)]
 u=normalization(u)$newXtrain
 u=scaling(u)$newXtrain
 pp=knn.double.cv(u,as.factor(MetRef$donor))
 print(pp$Q2Y)
 table(pp$Ypred,MetRef$donor)


</code></pre>

<hr>
<h2 id='knn.kodama'>k-Nearest Neighbors Classifier.</h2><span id='topic+knn.kodama'></span>

<h3>Description</h3>

<p>k-nearest neighbour classification for a test set from a training set.</p>


<h3>Usage</h3>

<pre><code class='language-R'>knn.kodama(Xtrain, 
           Ytrain, 
           Xtest,
           Ytest=NULL, 
           k, 
           scaling = c("centering","autoscaling"),
           perm.test=FALSE,
           times=1000)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="knn.kodama_+3A_xtrain">Xtrain</code></td>
<td>
<p>a matrix of training set cases.</p>
</td></tr>
<tr><td><code id="knn.kodama_+3A_ytrain">Ytrain</code></td>
<td>
<p>a classification vector.</p>
</td></tr>
<tr><td><code id="knn.kodama_+3A_xtest">Xtest</code></td>
<td>
<p>a matrix of test set cases.</p>
</td></tr>
<tr><td><code id="knn.kodama_+3A_ytest">Ytest</code></td>
<td>
<p>a classification vector.</p>
</td></tr>
<tr><td><code id="knn.kodama_+3A_k">k</code></td>
<td>
<p>the number of nearest neighbors to consider.</p>
</td></tr>
<tr><td><code id="knn.kodama_+3A_scaling">scaling</code></td>
<td>
<p>the scaling method to be used. Choices are &quot;<code>centering</code>&quot; or &quot;<code>autoscaling</code>&quot; (by default = &quot;<code>centering</code>&quot;). A partial string sufficient to uniquely identify the choice is permitted.</p>
</td></tr>
<tr><td><code id="knn.kodama_+3A_perm.test">perm.test</code></td>
<td>
<p>a classification vector.</p>
</td></tr>
<tr><td><code id="knn.kodama_+3A_times">times</code></td>
<td>
<p>a classification vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function utilizes the Approximate Nearest Neighbor (ANN) C++ library, 
which can give the exact nearest neighbours or (as the name suggests) 
approximate nearest neighbours to within a specified error bound.  For more 
information on the ANN library please visit http://www.cs.umd.edu/~mount/ANN/.
</p>


<h3>Value</h3>

<p>The function returns a vector of predicted labels.</p>


<h3>Author(s)</h3>

<p>Stefano Cacciatore and Leonardo Tenori</p>


<h3>References</h3>

<p>Bentley JL (1975)<br />
Multidimensional binary search trees used for associative search. <br />
<em>Communication ACM</em> 1975;18:309-517.<br /><br />
</p>
<p>Arya S, Mount DM<br />
Approximate nearest neighbor searching<br />
<em>Proc. 4th Ann. ACM-SIAM Symposium on Discrete Algorithms (SODA'93)</em>;271-280.<br /><br />
</p>
<p>Arya S, Mount DM, Netanyahu NS, Silverman R, Wu AY<br />
An optimal algorithm for approximate nearest neighbor searching<br />
<em>Journal of the ACM</em> 1998;45:891-923.<br /><br />
</p>
<p>Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+KODAMA.matrix">KODAMA.matrix</a></code>,<code><a href="#topic+KODAMA.visualization">KODAMA.visualization</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'> data(iris)
 data=iris[,-5]
 labels=iris[,5]
 ss=sample(150,15)

 z=knn.kodama(data[-ss,], labels[-ss], data[ss,], k=5) 
 table(z$Ypred[,5],labels[ss])
</code></pre>

<hr>
<h2 id='KODAMA.matrix'>Knowledge Discovery by Accuracy Maximization</h2><span id='topic+KODAMA.matrix'></span>

<h3>Description</h3>

<p>KODAMA (KnOwledge Discovery by Accuracy MAximization) is an unsupervised and semi-supervised learning algorithm that performs feature extraction from noisy and high-dimensional data. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KODAMA.matrix (data, 
               M = 100, 
               Tcycle = 20, 
               FUN_VAR = function(x) {  ceiling(ncol(x)) }, 
               FUN_SAM = function(x) {  ceiling(nrow(x) * 0.75)},
               bagging = FALSE, 
               FUN = c("PLS-DA","KNN"), 
               f.par = 5,
               W = NULL, 
               constrain = NULL, 
               fix=NULL, 
               epsilon = 0.05,
               dims=2,
               landmarks=1000,
               neighbors=min(c(landmarks,nrow(data)))-1) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KODAMA.matrix_+3A_data">data</code></td>
<td>
<p>a matrix.</p>
</td></tr>
<tr><td><code id="KODAMA.matrix_+3A_m">M</code></td>
<td>

<p>number of iterative processes (step I-III).
</p>
</td></tr>
<tr><td><code id="KODAMA.matrix_+3A_tcycle">Tcycle</code></td>
<td>

<p>number of iterative cycles that leads to the maximization of cross-validated accuracy.
</p>
</td></tr>
<tr><td><code id="KODAMA.matrix_+3A_fun_var">FUN_VAR</code></td>
<td>

<p>function to select the number of variables to select randomly. By default all variable are taken.
</p>
</td></tr>
<tr><td><code id="KODAMA.matrix_+3A_fun_sam">FUN_SAM</code></td>
<td>

<p>function to select the number of samples to select randomly. By default the 75 per cent of all samples are taken.
</p>
</td></tr>
<tr><td><code id="KODAMA.matrix_+3A_bagging">bagging</code></td>
<td>

<p>Should sampling be with replacement, <code>bagging = TRUE</code>. By default <code>bagging = FALSE</code>.
</p>
</td></tr>
<tr><td><code id="KODAMA.matrix_+3A_fun">FUN</code></td>
<td>
<p>classifier to be considered. Choices are &quot;<code>PLS-DA</code>&quot; and &quot;<code>KNN</code>&quot;.
</p>
</td></tr>
<tr><td><code id="KODAMA.matrix_+3A_f.par">f.par</code></td>
<td>

<p>parameters of the classifier.
</p>
</td></tr>
<tr><td><code id="KODAMA.matrix_+3A_w">W</code></td>
<td>

<p>a vector of <code>nrow(data)</code> elements. The KODAMA procedure can be started by different initializations of the vector <code>W</code>. Without any <em>a priori</em> information the vector <code>W</code> can be initialized with each element being different from the others (<em>i.e.</em>, each sample categorized in a one-element class). Alternatively, the vector <code>W</code> can be initialized by a clustering procedure, such as <code><a href="stats.html#topic+kmeans">kmeans</a></code>.
</p>
</td></tr>
<tr><td><code id="KODAMA.matrix_+3A_constrain">constrain</code></td>
<td>

<p>a vector of <code>nrow(data)</code> elements. Supervised constraints can be imposed by linking some samples in such a way that if one of them is changed the remaining linked samples must change in the same way (<em>i.e.</em>, they are forced to belong to the same class) during the maximization of the cross-validation accuracy procedure. Samples with the same identifying constrain will be forced to stay together.
</p>
</td></tr>
<tr><td><code id="KODAMA.matrix_+3A_fix">fix</code></td>
<td>

<p>a vector of <code>nrow(data)</code> elements. The values of this vector must to be <code>TRUE</code> or <code>FALSE</code>. By default all elements are <code>FALSE</code>. Samples with the <code>TRUE</code> fix value will not change the class label defined in <code>W</code> during the maximization of the cross-validation accuracy procedure.
</p>
</td></tr>
<tr><td><code id="KODAMA.matrix_+3A_epsilon">epsilon</code></td>
<td>

<p>cut-off value for low proximity. High proximity are typical of intracluster relationships, whereas low proximities are expected for intercluster relationships. Very low proximities between samples are ignored by (default) setting <code>epsilon = 0.05</code>.
</p>
</td></tr>
<tr><td><code id="KODAMA.matrix_+3A_dims">dims</code></td>
<td>

<p>dimensions of the configurations of t-SNE based on the KODAMA dissimilarity matrix.
</p>
</td></tr>
<tr><td><code id="KODAMA.matrix_+3A_landmarks">landmarks</code></td>
<td>

<p>number of landmarks to use.
</p>
</td></tr>
<tr><td><code id="KODAMA.matrix_+3A_neighbors">neighbors</code></td>
<td>

<p>number of neighbors to include in the dissimilarity matrix yo pass to the <code><a href="#topic+KODAMA.visualization">KODAMA.visualization</a></code> function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>KODAMA consists of five steps. These can be in turn divided into two parts: (i) the maximization of cross-validated accuracy by an iterative process (step I and II), resulting in the construction of a proximity matrix (step III), and (ii) the definition of a dissimilarity matrix (step IV and V). The first part entails the core idea of KODAMA, that is, the partitioning of data guided by the maximization of the cross-validated accuracy. At the beginning of this part, a fraction of the total samples (defined by <code>FUN_SAM</code>) are randomly selected from the original data. The whole iterative process (step I-III) is repeated <code>M</code> times to average the effects owing to the randomness of the iterative procedure. Each time that this part is repeated, a different fraction of samples is selected. The second part aims at collecting and processing these results by constructing a dissimilarity matrix to provide a holistic view of the data while maintaining their intrinsic structure (steps IV and V). Then, <code><a href="#topic+KODAMA.visualization">KODAMA.visualization</a></code> function is used to visualise the results of KODAMA dissimilarity matrix. 
</p>


<h3>Value</h3>

<p>The function returns a list with 4 items:
</p>
<table>
<tr><td><code>dissimilarity</code></td>
<td>
<p>a dissimilarity matrix.</p>
</td></tr>
<tr><td><code>acc</code></td>
<td>
<p>a vector with the <code>M</code> cross-validated accuracies.</p>
</td></tr>
<tr><td><code>proximity</code></td>
<td>
<p>a proximity matrix.</p>
</td></tr>
<tr><td><code>v</code></td>
<td>
<p>a matrix containing the all classification obtained maximizing the cross-validation accuracy.</p>
</td></tr>
<tr><td><code>res</code></td>
<td>
<p>a matrix containing all classification vectors obtained through maximizing the cross-validation accuracy.</p>
</td></tr>
<tr><td><code>f.par</code></td>
<td>
<p>parameters of the classifier..</p>
</td></tr>
<tr><td><code>entropy</code></td>
<td>
<p>Shannon's entropy of the KODAMA proximity matrix.</p>
</td></tr>
<tr><td><code>landpoints</code></td>
<td>
<p>indexes of the landmarks used.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>original data.</p>
</td></tr>
<tr><td><code>knn_Armadillo</code></td>
<td>
<p>dissimilarity matrix used as input for the <code><a href="#topic+KODAMA.visualization">KODAMA.visualization</a></code> function.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Stefano Cacciatore and Leonardo Tenori</p>


<h3>References</h3>

<p>Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
<br />	<br />
L.J.P. van der Maaten and G.E. Hinton.<br />
Visualizing High-Dimensional Data Using t-SNE. <br />
<em>Journal of Machine Learning Research</em> 9 (Nov) : 2579-2605, 2008.
<br />	<br />
L.J.P. van der Maaten. <br />
Learning a Parametric Embedding by Preserving Local Structure. <br />
<em>In Proceedings of the Twelfth International Conference on Artificial Intelligence and Statistics (AISTATS), JMLR W&amp;CP</em> 5:384-391, 2009.
<br />	<br />
McInnes L, Healy J, Melville J. <br />
Umap: Uniform manifold approximation and projection for dimension reduction. <br />
<em>arXiv preprint</em>:1802.03426. 2018 Feb 9.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+KODAMA.visualization">KODAMA.visualization</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>

 data(iris)
 data=iris[,-5]
 labels=iris[,5]
 kk=KODAMA.matrix(data,FUN="KNN",f.par=2)
 cc=KODAMA.visualization(kk,"t-SNE")
 plot(cc,col=as.numeric(labels),cex=2)


</code></pre>

<hr>
<h2 id='KODAMA.visualization'>Visualization of KODAMA output</h2><span id='topic+KODAMA.visualization'></span>

<h3>Description</h3>

<p>Provides a simple function to transform the KODAMA dissimilarity matrix in a low-dimensional space.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KODAMA.visualization(kk,
                     method=c("t-SNE","MDS","UMAP"),
                     perplexity=min(30,floor((kk$knn_Armadillo$neighbors+1)/3)-1), 
                     ...)
  
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KODAMA.visualization_+3A_kk">kk</code></td>
<td>
<p>output of <code><a href="#topic+KODAMA.matrix">KODAMA.matrix</a></code> function.</p>
</td></tr>
<tr><td><code id="KODAMA.visualization_+3A_method">method</code></td>
<td>

<p>method to be considered for transforming the dissimilarity matrix in a low-dimensional space. Choices are &quot;<code>t-SNE</code>&quot;, &quot;<code>MDS</code>&quot;, and &quot;<code>UMAP</code>&quot;.
</p>
</td></tr>
<tr><td><code id="KODAMA.visualization_+3A_perplexity">perplexity</code></td>
<td>

<p>Perplexity parameter. (optimal number of neighbors) for &quot;<code>t-SNE</code>&quot; only.
</p>
</td></tr>
<tr><td><code id="KODAMA.visualization_+3A_...">...</code></td>
<td>

<p>other parameters for &quot;<code>t-SNE</code>&quot;, &quot;<code>MDS</code>&quot;, or &quot;<code>UMAP</code>&quot;.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a matrix contains the coordinates of the datapoints in a low-dimensional space.
</p>


<h3>Author(s)</h3>

<p>Stefano Cacciatore and Leonardo Tenori</p>


<h3>References</h3>

<p>Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
<br />	<br />
L.J.P. van der Maaten and G.E. Hinton.<br />
Visualizing High-Dimensional Data Using t-SNE. <br />
<em>Journal of Machine Learning Research</em> 9 (Nov) : 2579-2605, 2008.
<br />	<br />
L.J.P. van der Maaten. <br />
Learning a Parametric Embedding by Preserving Local Structure. <br />
<em>In Proceedings of the Twelfth International Conference on Artificial Intelligence and Statistics (AISTATS), JMLR W&amp;CP</em> 5:384-391, 2009.
<br />	<br />
McInnes L, Healy J, Melville J. <br />
Umap: Uniform manifold approximation and projection for dimension reduction. <br />
<em>arXiv preprint</em>:1802.03426. 2018 Feb 9.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+KODAMA.visualization">KODAMA.visualization</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>

 data(iris)
 data=iris[,-5]
 labels=iris[,5]
 kk=KODAMA.matrix(data,FUN="KNN",f.par=2)
 cc=KODAMA.visualization(kk,"t-SNE")
 plot(cc,col=as.numeric(labels),cex=2)


</code></pre>

<hr>
<h2 id='loads'>Variable Ranking</h2><span id='topic+loads'></span>

<h3>Description</h3>

<p>This function can be used to extract the variable ranking when KODAMA is performed with the PLS-DA classifier.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loads(model,method=c("loadings","kruskal.test"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loads_+3A_model">model</code></td>
<td>
<p>output of KODAMA.</p>
</td></tr>
<tr><td><code id="loads_+3A_method">method</code></td>
<td>
<p>method to be used. Choices are &quot;<code>loadings</code>&quot; and &quot;<code>kruskal.test</code>&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a vector of values indicating the &quot;importance&quot; of each variable. If &quot;<code>method="loadings"</code> the average of the loading of the first component of PLS models based on the cross-validated accuracy maximized vector is computed. If &quot;<code>method="kruskal.test"</code> the average of minus logarithm of p-value of Kruskal-Wallis Rank Sum test is computed. 
</p>


<h3>Author(s)</h3>

<p>Stefano Cacciatore</p>


<h3>References</h3>

<p>Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+KODAMA.matrix">KODAMA.matrix</a></code>,<code><a href="#topic+KODAMA.visualization">KODAMA.visualization</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
 data(iris)
 data=iris[,-5]
 labels=iris[,5]
 kk=KODAMA.matrix(data,FUN="PLS-DA")
 loads(kk)

</code></pre>

<hr>
<h2 id='lymphoma'>Lymphoma Gene Expression Dataset</h2><span id='topic+lymphoma'></span>

<h3>Description</h3>

<p>This dataset consists of gene expression profiles of the three most prevalent adult lymphoid malignancies: diffuse large B-cell lymphoma (DLBCL), follicular lymphoma (FL), and B-cell chronic lymphocytic leukemia (B-CLL). The dataset consists of 4,682 mRNA genes for 62 samples (42 samples of DLBCL, 9 samples of FL, and 11 samples of B-CLL). Missing value are imputed and data are standardized as described in Dudoit, <em>et al</em>. (2002).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(lymphoma)</code></pre>


<h3>Value</h3>

<p>A list with the following elements:
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>Gene expression data. A matrix with 62 rows and 4,682 columns.</p>
</td></tr>
<tr><td><code>class</code></td>
<td>
<p>Class index. A vector with 62 elements.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
<br />
<br />
Alizadeh AA, Eisen MB, Davis RE, <em>et al.</em><br />
Distinct types of diffuse large B-cell lymphoma identified by gene expression profiling. <br />
<em>Nature</em> 2000;403(6769):503-511.
<br />
<br />
Dudoit S, Fridlyand J, Speed TP<br />
Comparison of discrimination methods for the classification of tumors using gene expression data. <br />
<em>J Am Stat Assoc</em> 2002;97(417):77-87.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(lymphoma)
class=1+as.numeric(lymphoma$class)
cc=pca(lymphoma$data)$x
plot(cc,pch=21,bg=class)

kk=KODAMA.matrix(lymphoma$data)
cc=KODAMA.visualization(kk,"t-SNE")

plot(cc,pch=21,bg=class)


</code></pre>

<hr>
<h2 id='mcplot'>Evaluation of the Monte Carlo accuracy results</h2><span id='topic+mcplot'></span>

<h3>Description</h3>

<p>This function can be used to plot the accuracy values obtained during KODAMA procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mcplot(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mcplot_+3A_model">model</code></td>
<td>
<p>output of KODAMA.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value.
</p>


<h3>Author(s)</h3>

<p>Stefano Cacciatore</p>


<h3>References</h3>

<p>Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+KODAMA.matrix">KODAMA.matrix</a></code>,<code><a href="#topic+KODAMA.visualization">KODAMA.visualization</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
 data=as.matrix(iris[,-5])
 kk=KODAMA.matrix(data)
 mcplot(kk)

</code></pre>

<hr>
<h2 id='MetRef'>Nuclear Magnetic Resonance Spectra of Urine Samples</h2><span id='topic+MetRef'></span>

<h3>Description</h3>

<p>The data belong to a cohort of 22 healthy donors (11 male and 11 female) where each provided about 40 urine samples over the time course of approximately 2 months, for a total of 873 samples. Each sample was analysed by Nuclear Magnetic Resonance Spectroscopy. Each spectrum was divided in 450 spectral bins.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(MetRef)</code></pre>


<h3>Value</h3>

<p>A list with the following elements:
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>Metabolomic data. A matrix with 873 rows and 450 columns.</p>
</td></tr>
<tr><td><code>gender</code></td>
<td>
<p>Gender index. A vector with 873 elements.</p>
</td></tr>
<tr><td><code>donor</code></td>
<td>
<p>Donor index. A vector with 873 elements.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Assfalg M, Bertini I, Colangiuli D, <em>et al.</em>	<br />
Evidence of different metabolic phenotypes in humans.<br />
<em>Proc Natl Acad Sci U S A</em> 2008;105(5):1420-4. doi: 10.1073/pnas.0705685105.  <a href="https://www.pnas.org/doi/full/10.1073/pnas.0705685105">Link</a>
<br />	<br />
Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(MetRef)
u=MetRef$data;
u=u[,-which(colSums(u)==0)]
u=normalization(u)$newXtrain
u=scaling(u)$newXtrain
class=as.numeric(as.factor(MetRef$gender))
cc= pca(u)$x
plot(cc,pch=21,bg=class)

class=as.numeric(as.factor(MetRef$donor))
plot(cc,pch=21,bg=rainbow(22)[class])

kk=KODAMA.matrix(u)
cc=KODAMA.visualization(kk,"t-SNE")
plot(cc,pch=21,bg=rainbow(22)[class])



</code></pre>

<hr>
<h2 id='multi_analysis'>Continuous Information</h2><span id='topic+multi_analysis'></span>

<h3>Description</h3>

<p>Summarization of the continuous information.</p>


<h3>Usage</h3>

<pre><code class='language-R'>multi_analysis  (data, 
                 y, 
                 FUN=c("continuous.test","correlation.test"), ...)                 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multi_analysis_+3A_data">data</code></td>
<td>
<p>the matrix containing the continuous values. Each row corresponds to a different sample. Each column corresponds to a different variable.</p>
</td></tr>
<tr><td><code id="multi_analysis_+3A_y">y</code></td>
<td>
<p>the classification of the cohort.</p>
</td></tr>
<tr><td><code id="multi_analysis_+3A_fun">FUN</code></td>
<td>
<p>function to be considered. Choices are &quot;<code>continuous.test</code>&quot; and &quot;<code>correlation.test</code>&quot;</p>
</td></tr>
<tr><td><code id="multi_analysis_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a table with the summarized information. If the number of group is equal to two, the p-value is computed using the Wilcoxon rank-sum test, Kruskal-Wallis test otherwise.
</p>


<h3>Author(s)</h3>

<p>Stefano Cacciatore</p>


<h3>References</h3>

<p>Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+categorical.test">categorical.test</a></code>,<code><a href="#topic+continuous.test">continuous.test</a></code>,<code><a href="#topic+correlation.test">correlation.test</a></code>, <code><a href="#topic+txtsummary">txtsummary</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(clinical)


multi_analysis(clinical[,c("BMI","Age")],clinical[,"Hospital"],FUN="continuous.test")

</code></pre>

<hr>
<h2 id='normalization'>Normalization Methods</h2><span id='topic+normalization'></span>

<h3>Description</h3>

<p>Collection of Different Normalization Methods.</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalization(Xtrain,Xtest=NULL, method = "pqn",ref=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalization_+3A_xtrain">Xtrain</code></td>
<td>
<p>a matrix of data (training data set).</p>
</td></tr>
<tr><td><code id="normalization_+3A_xtest">Xtest</code></td>
<td>
<p>a matrix of data (test data set).(by default = NULL).</p>
</td></tr>
<tr><td><code id="normalization_+3A_method">method</code></td>
<td>
<p>the normalization method to be used. Choices are &quot;<code>none</code>&quot;, &quot;<code>pqn</code>&quot;, &quot;<code>sum</code>&quot;, &quot;<code>median</code>&quot;, &quot;<code>sqrt</code>&quot; (by default = &quot;<code>pqn</code>&quot;). A partial string sufficient to uniquely identify the choice is permitted.</p>
</td></tr>
<tr><td><code id="normalization_+3A_ref">ref</code></td>
<td>
<p>Reference sample for Probabilistic Quotient Normalization. (by default = NULL).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A number of different normalization methods are provided:
</p>

<ul>
<li><p> &quot;<code>none</code>&quot;: no normalization method is applied.
</p>
</li>
<li><p> &quot;<code>pqn</code>&quot;: the Probabilistic Quotient Normalization is computed as described in <em>Dieterle, et al.</em> (2006).
</p>
</li>
<li><p> &quot;<code>sum</code>&quot;: samples are normalized to the sum of the absolute value of all variables for a given sample.
</p>
</li>
<li><p> &quot;<code>median</code>&quot;: samples are normalized to the median value of all variables for a given sample.
</p>
</li>
<li><p> &quot;<code>sqrt</code>&quot;: samples are normalized to the root of the sum of the squared value of all variables for a given sample.
</p>
</li></ul>



<h3>Value</h3>

<p>The function returns a list with 2 items or 4 items (if a test data set is present):
</p>
<table>
<tr><td><code>newXtrain</code></td>
<td>
<p>a normalized matrix (training data set).</p>
</td></tr>
<tr><td><code>coeXtrain</code></td>
<td>
<p>a vector of normalization coefficient of the training data set.</p>
</td></tr>
<tr><td><code>newXtest</code></td>
<td>
<p>a normalized matrix (test data set).</p>
</td></tr>
<tr><td><code>coeXtest</code></td>
<td>
<p>a vector of normalization coefficient of the test data set.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Stefano Cacciatore and Leonardo Tenori</p>


<h3>References</h3>

<p>Dieterle F,Ross A, Schlotterbeck G, Senn H.<br />
Probabilistic Quotient Normalization as Robust Method to Account for Diluition of Complex Biological Mixtures. Application in 1H NMR Metabolomics.<br />
<em>Anal Chem</em> 2006;78:4281-90.
<br />
<br />
Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+scaling">scaling</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(MetRef)
u=MetRef$data;
u=u[,-which(colSums(u)==0)]
u=normalization(u)$newXtrain
u=scaling(u)$newXtrain
class=as.numeric(as.factor(MetRef$gender))
cc=pca(u)
plot(cc$x,pch=21,bg=class)
</code></pre>

<hr>
<h2 id='pca'>Principal Components Analysis</h2><span id='topic+pca'></span>

<h3>Description</h3>

<p>Performs a principal components analysis on the given data matrix and returns the results as an object of class &quot;<code>prcomp</code>&quot;.</p>


<h3>Usage</h3>

<pre><code class='language-R'>pca(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pca_+3A_x">x</code></td>
<td>
<p>a matrix of data.</p>
</td></tr>
<tr><td><code id="pca_+3A_...">...</code></td>
<td>
<p>arguments passed to <code><a href="stats.html#topic+prcomp">prcomp</a></code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns  a list with class <code>prcomp</code> containing the following components:
</p>
<table>
<tr><td><code>sdev</code></td>
<td>
<p>the standard deviations of the principal components (i.e., the square roots of the eigenvalues of the covariance/correlation matrix, though the calculation is actually done with the singular values of the data matrix).</p>
</td></tr>
<tr><td><code>rotation</code></td>
<td>
<p>the matrix of variable loadings (i.e., a matrix whose columns contain the eigenvectors). The function <code>princomp</code> returns this in the element <code>loadings</code>.</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>if <code>retx</code> is <code>TRUE</code> the value of the rotated data (the centred (and scaled if requested) data multiplied by the <code>rotation</code> matrix) is returned. Hence, <code>cov(x)</code> is the diagonal matrix <code>diag(sdev^2)</code>. For the formula method, <code>napredict()</code> is applied to handle the treatment of values omitted by the <code>na.action</code>.</p>
</td></tr>
<tr><td><code>center</code>, <code>scale</code></td>
<td>
<p>the centering and scaling used, or <code>FALSE</code>.</p>
</td></tr>
<tr><td><code>txt</code></td>
<td>
<p>the component of variance of each Principal Component.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Stefano Cacciatore</p>


<h3>References</h3>

<p>Pearson, K	<br />
On Lines and Planes of Closest Fit to Systems of Points in Space.<br />
<em>Philosophical Magazine</em> 1901;2 (11): 559-572. doi:10.1080/14786440109462720. <a href="https://www.tandfonline.com/doi/abs/10.1080/14786440109462720">Link</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+prcomp">prcomp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(MetRef)
u=MetRef$data;
u=u[,-which(colSums(u)==0)]
u=normalization(u)$newXtrain
u=scaling(u)$newXtrain
class=as.numeric(as.factor(MetRef$gender))
cc=pca(u)
plot(cc$x,pch=21,bg=class)
</code></pre>

<hr>
<h2 id='pls.double.cv'>Cross-Validation with PLS-DA.</h2><span id='topic+pls.double.cv'></span>

<h3>Description</h3>

<p>This function performs a 10-fold cross validation on a given data set using Partial Least Squares (PLS) model. To assess the prediction ability of the model, a 10-fold cross-validation is conducted by generating splits with a ratio 1:9 of the data set, that is by removing 10% of samples prior to any step of the statistical analysis, including PLS component selection and scaling. Best number of component for PLS was carried out by means of 10-fold cross-validation on the remaining 90% selecting the best Q2y value. Permutation testing was undertaken to estimate the classification/regression performance of predictors.</p>


<h3>Usage</h3>

<pre><code class='language-R'>pls.double.cv(Xdata,
              Ydata,
              constrain=1:nrow(Xdata),
              compmax=min(5,c(ncol(Xdata),nrow(Xdata))),
              perm.test=FALSE,
              optim=TRUE,
              scaling = c("centering","autoscaling"),
              times=100,
              runn=10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pls.double.cv_+3A_xdata">Xdata</code></td>
<td>
<p>a matrix.</p>
</td></tr>
<tr><td><code id="pls.double.cv_+3A_ydata">Ydata</code></td>
<td>
<p>the responses. If Ydata is a numeric vector, a regression analysis will be performed. If Ydata is factor, a classification analysis will be performed. </p>
</td></tr>
<tr><td><code id="pls.double.cv_+3A_constrain">constrain</code></td>
<td>
<p>a vector of <code>nrow(data)</code> elements. Sample with the same identifying constrain will be split in the training set or in the test set of cross-validation together.</p>
</td></tr>
<tr><td><code id="pls.double.cv_+3A_compmax">compmax</code></td>
<td>
<p>the number of latent components to be used for classification.</p>
</td></tr>
<tr><td><code id="pls.double.cv_+3A_perm.test">perm.test</code></td>
<td>
<p>a classification vector.</p>
</td></tr>
<tr><td><code id="pls.double.cv_+3A_optim">optim</code></td>
<td>
<p>if perform the optmization of the number of components.</p>
</td></tr>
<tr><td><code id="pls.double.cv_+3A_scaling">scaling</code></td>
<td>
<p>the scaling method to be used. Choices are &quot;<code>centering</code>&quot; or &quot;<code>autoscaling</code>&quot; (by default = &quot;<code>centering</code>&quot;). A partial string sufficient to uniquely identify the choice is permitted.</p>
</td></tr>
<tr><td><code id="pls.double.cv_+3A_times">times</code></td>
<td>
<p>number of cross-validations with permutated samples</p>
</td></tr>
<tr><td><code id="pls.double.cv_+3A_runn">runn</code></td>
<td>
<p>number of cross-validations loops.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>B</code></td>
<td>
<p>the (p x m x length(ncomp)) array containing the regression coefficients. Each row corresponds to a predictor variable and each column to a response variable. The third dimension of the matrix B corresponds to the number of PLS components used to compute the regression coefficients. If ncomp has length 1, B is just a (p x m) matrix.</p>
</td></tr>
<tr><td><code>Ypred</code></td>
<td>
<p>the vector containing the predicted values of the response variables obtained by cross-validation.</p>
</td></tr>
<tr><td><code>Yfit</code></td>
<td>
<p>the vector containing the fitted values of the response variables.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>the (p x max(ncomp)) matrix containing the X-loadings.</p>
</td></tr>
<tr><td><code>Q</code></td>
<td>
<p>the (m x max(ncomp)) matrix containing the Y-loadings.</p>
</td></tr>
<tr><td><code>T</code></td>
<td>
<p>the (ntrain x max(ncomp)) matrix containing the X-scores (latent components)</p>
</td></tr>
<tr><td><code>R</code></td>
<td>
<p>the (p x max(ncomp)) matrix containing the weights used to construct the latent components.</p>
</td></tr>
<tr><td><code>Q2Y</code></td>
<td>
<p>Q2y value.</p>
</td></tr>
<tr><td><code>R2Y</code></td>
<td>
<p>R2y value.</p>
</td></tr>
<tr><td><code>R2X</code></td>
<td>
<p>vector containg the explained variance of X by each PLS component.</p>
</td></tr>
<tr><td><code>txtQ2Y</code></td>
<td>
<p>a summary of the Q2y values.</p>
</td></tr>
<tr><td><code>txtR2Y</code></td>
<td>
<p>a summary of the R2y values.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Stefano Cacciatore</p>


<h3>References</h3>

<p>Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(iris)
data=iris[,-5]
labels=iris[,5]
pp=pls.double.cv(data,labels)
print(pp$Q2Y)
table(pp$Ypred,labels)

data(MetRef)
u=MetRef$data;
u=u[,-which(colSums(u)==0)]
u=normalization(u)$newXtrain
u=scaling(u)$newXtrain
pp=pls.double.cv(u,as.factor(MetRef$donor))
print(pp$Q2Y)
table(pp$Ypred,MetRef$donor)


</code></pre>

<hr>
<h2 id='pls.kodama'>Partial Least Squares regression.</h2><span id='topic+pls.kodama'></span>

<h3>Description</h3>

<p>Partial Least Squares (PLS) regression for test set from training set.</p>


<h3>Usage</h3>

<pre><code class='language-R'>pls.kodama(Xtrain, 
           Ytrain, 
           Xtest, 
           Ytest = NULL, 
           ncomp, 
           scaling = c("centering","autoscaling"),
           perm.test=FALSE,
           times=1000) 

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pls.kodama_+3A_xtrain">Xtrain</code></td>
<td>
<p>a matrix of training set cases.</p>
</td></tr>
<tr><td><code id="pls.kodama_+3A_ytrain">Ytrain</code></td>
<td>
<p>a classification vector.</p>
</td></tr>
<tr><td><code id="pls.kodama_+3A_xtest">Xtest</code></td>
<td>
<p>a matrix of test set cases.</p>
</td></tr>
<tr><td><code id="pls.kodama_+3A_ytest">Ytest</code></td>
<td>
<p>a classification vector.</p>
</td></tr>
<tr><td><code id="pls.kodama_+3A_ncomp">ncomp</code></td>
<td>
<p>the number of components to consider.</p>
</td></tr>
<tr><td><code id="pls.kodama_+3A_scaling">scaling</code></td>
<td>
<p>the scaling method to be used. Choices are &quot;<code>centering</code>&quot; or &quot;<code>autoscaling</code>&quot; (by default = &quot;<code>centering</code>&quot;). A partial string sufficient to uniquely identify the choice is permitted.</p>
</td></tr>
<tr><td><code id="pls.kodama_+3A_perm.test">perm.test</code></td>
<td>
<p>a classification vector.</p>
</td></tr>
<tr><td><code id="pls.kodama_+3A_times">times</code></td>
<td>
<p>a classification vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>B</code></td>
<td>
<p>the (p x m x length(ncomp)) matrix containing the regression coefficients. Each row corresponds to a predictor variable and each column to a response variable. The third dimension of the matrix B corresponds to the number of PLS components used to compute the regression coefficients. If ncomp has length 1, B is just a (p x m) matrix.</p>
</td></tr>
<tr><td><code>Ypred</code></td>
<td>
<p>the (ntest x m x length(ncomp)) containing the predicted values of the response variables for the observations from Xtest. The third dimension of the matrix Ypred corresponds to the number of PLS components used to compute the regression coefficients.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>the (p x max(ncomp)) matrix containing the X-loadings.</p>
</td></tr>
<tr><td><code>Q</code></td>
<td>
<p>the (m x max(ncomp)) matrix containing the Y-loadings.</p>
</td></tr>
<tr><td><code>T</code></td>
<td>
<p>the (ntrain x max(ncomp)) matrix containing the X-scores (latent components)</p>
</td></tr>
<tr><td><code>R</code></td>
<td>
<p>the (p x max(ncomp)) matrix containing the weights used to construct the latent components.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Stefano Cacciatore</p>


<h3>References</h3>

<p>Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+KODAMA.matrix">KODAMA.matrix</a></code>,<code><a href="#topic+KODAMA.visualization">KODAMA.visualization</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
data=iris[,-5]
labels=iris[,5]
ss=sample(150,15)
ncomponent=3

z=pls.kodama(data[-ss,], labels[-ss], data[ss,], ncomp=ncomponent) 
table(z$Ypred[,ncomponent],labels[ss])
</code></pre>

<hr>
<h2 id='scaling'>Scaling Methods</h2><span id='topic+scaling'></span>

<h3>Description</h3>

<p>Collection of Different Scaling Methods.</p>


<h3>Usage</h3>

<pre><code class='language-R'>scaling(Xtrain,Xtest=NULL, method = "autoscaling")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scaling_+3A_xtrain">Xtrain</code></td>
<td>
<p>a matrix of data (training data set).</p>
</td></tr>
<tr><td><code id="scaling_+3A_xtest">Xtest</code></td>
<td>
<p>a matrix of data (test data set).(by default = NULL).</p>
</td></tr>
<tr><td><code id="scaling_+3A_method">method</code></td>
<td>
<p>the scaling method to be used. Choices are &quot;<code>none</code>&quot;, &quot;<code>centering</code>&quot;, &quot;<code>autoscaling</code>&quot;, &quot;<code>rangescaling</code>&quot;, &quot;<code>paretoscaling</code>&quot; (by default = &quot;<code>autoscaling</code>&quot;). A partial string sufficient to uniquely identify the choice is permitted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A number of different scaling methods are provided:
</p>

<ul>
<li><p> &quot;<code>none</code>&quot;: no scaling method is applied.
</p>
</li>
<li><p> &quot;<code>centering</code>&quot;: centers the mean to zero.
</p>
</li>
<li><p> &quot;<code>autoscaling</code>&quot;: centers the mean to zero and scales data by dividing each variable by the variance.
</p>
</li>
<li><p> &quot;<code>rangescaling</code>&quot;: centers the mean to zero and scales data by dividing each variable by the difference between the minimum and the maximum value.
</p>
</li>
<li><p> &quot;<code>paretoscaling</code>&quot;: centers the mean to zero and scales data by dividing each variable by the square root of the standard deviation. Unit scaling divides each variable by the standard deviation so that each variance equal to 1.
</p>
</li></ul>



<h3>Value</h3>

<p>The function returns a list with 1 item or 2 items (if a test data set is present):
</p>
<table>
<tr><td><code>newXtrain</code></td>
<td>
<p>a scaled matrix (training data set).</p>
</td></tr>
<tr><td><code>newXtest</code></td>
<td>
<p>a scale matrix (test data set).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Stefano Cacciatore and Leonardo Tenori</p>


<h3>References</h3>

<p>van den Berg RA, Hoefsloot HCJ, Westerhuis JA, <em>et al.</em><br />
Centering, scaling, and transformations: improving the biological information content of metabolomics data. <br />
<em>BMC Genomics</em> 2006;7(1):142.
<br />
<br />
Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+normalization">normalization</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(MetRef)
u=MetRef$data;
u=u[,-which(colSums(u)==0)]
u=normalization(u)$newXtrain
u=scaling(u)$newXtrain
class=as.numeric(as.factor(MetRef$gender))
cc=pca(u)
plot(cc$x,pch=21,bg=class,xlab=cc$txt[1],ylab=cc$txt[2])
</code></pre>

<hr>
<h2 id='spirals'>Spirals Data Set Generator</h2><span id='topic+spirals'></span>

<h3>Description</h3>

<p>Produces a data set of spiral clusters.</p>


<h3>Usage</h3>

<pre><code class='language-R'>spirals(n=c(100,100,100),sd=c(0,0,0))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spirals_+3A_n">n</code></td>
<td>
<p>a vector of integer. The length of the vector is the number of clusters and each number corresponds to the number of data points in each cluster.</p>
</td></tr>
<tr><td><code id="spirals_+3A_sd">sd</code></td>
<td>
<p>amount of noise for each spiral.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a two dimensional data set.
</p>


<h3>Author(s)</h3>

<p>Stefano Cacciatore and Leonardo Tenori</p>


<h3>References</h3>

<p>Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+helicoid">helicoid</a></code>,<code><a href="#topic+dinisurface">dinisurface</a></code>,<code><a href="#topic+swissroll">swissroll</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
v1=spirals(c(100,100,100),c(0.1,0.1,0.1))
plot(v1,col=rep(2:4,each=100))
v2=spirals(c(100,100,100),c(0.1,0.2,0.3))
plot(v2,col=rep(2:4,each=100))
v3=spirals(c(100,100,100,100,100),c(0,0,0.2,0,0))
plot(v3,col=rep(2:6,each=100))
v4=spirals(c(20,40,60,80,100),c(0.1,0.1,0.1,0.1,0.1))
plot(v4,col=rep(2:6,c(20,40,60,80,100)))
</code></pre>

<hr>
<h2 id='swissroll'>Swiss Roll Data Set Generator</h2><span id='topic+swissroll'></span>

<h3>Description</h3>

<p>Computes the Swiss Roll data set of a given number of data points.</p>


<h3>Usage</h3>

<pre><code class='language-R'>swissroll(N=1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="swissroll_+3A_n">N</code></td>
<td>
<p>Number of data points.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a three dimensional matrix.
</p>


<h3>Author(s)</h3>

<p>Stefano Cacciatore and Leonardo Tenori</p>


<h3>References</h3>

<p>Balasubramanian M, Schwartz EL<br />
The isomap algorithm and topological stability. <br />
<em>Science</em> 2002;295(5552):7.
<br />
<br />
Roweis ST, Saul LK<br />
Nonlinear dimensionality reduction by locally linear embedding.<br />
<em>Science</em> 2000;290(5500):2323-6.
<br />
<br />
Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+helicoid">helicoid</a></code>,<code><a href="#topic+dinisurface">dinisurface</a></code>,<code><a href="#topic+spirals">spirals</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>require("rgl")
x=swissroll()
open3d()
plot3d(x, col=rainbow(1000),box=FALSE,size=3)
</code></pre>

<hr>
<h2 id='transformy'>Conversion Classification Vector to Matrix</h2><span id='topic+transformy'></span>

<h3>Description</h3>

<p>This function converts a classification vector into a classification matrix.</p>


<h3>Usage</h3>

<pre><code class='language-R'>transformy(y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transformy_+3A_y">y</code></td>
<td>
<p>a vector or factor.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function converts a classification vector into a classification matrix.
</p>


<h3>Value</h3>

<p>A matrix.
</p>


<h3>Author(s)</h3>

<p>Stefano Cacciatore and Leonardo Tenori</p>


<h3>References</h3>

<p>Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y=rep(1:10,3)
print(y)
z=transformy(y)
print(z)
</code></pre>

<hr>
<h2 id='txtsummary'>Median and Coefficient Interval</h2><span id='topic+txtsummary'></span>

<h3>Description</h3>

<p>Summarization of a numeric vector.</p>


<h3>Usage</h3>

<pre><code class='language-R'>txtsummary (x,digits=0,scientific=FALSE,range=c("IQR","95%CI"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="txtsummary_+3A_x">x</code></td>
<td>
<p>a numeric vector.</p>
</td></tr>
<tr><td><code id="txtsummary_+3A_digits">digits</code></td>
<td>
<p>how many significant digits are to be used.</p>
</td></tr>
<tr><td><code id="txtsummary_+3A_scientific">scientific</code></td>
<td>
<p>either a logical specifying whether result should be encoded in scientific format.</p>
</td></tr>
<tr><td><code id="txtsummary_+3A_range">range</code></td>
<td>
<p>the range to be visualized.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns the median and the range (interquartile or 95% coefficient interval) of numeric vetor.
</p>


<h3>Author(s)</h3>

<p>Stefano Cacciatore</p>


<h3>References</h3>

<p>Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+categorical.test">categorical.test</a></code>,<code><a href="#topic+continuous.test">continuous.test</a></code>,<code><a href="#topic+correlation.test">correlation.test</a></code>, <code><a href="#topic+txtsummary">txtsummary</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(clinical)

txtsummary(clinical[,"BMI"])


</code></pre>

<hr>
<h2 id='USA'>State of the Union Data Set</h2><span id='topic+USA'></span>

<h3>Description</h3>

<p>This dataset consists of the spoken, not written, addresses from 1900 until the sixth address by Barack Obama in 2014. Punctuation characters, numbers, words shorter than three characters, and stop-words (e.g., &quot;that&quot;, &quot;and&quot;, and &quot;which&quot;) were removed from the dataset. This resulted in a dataset of 86 speeches containing 834 different meaningful words each. Term frequency-inverse document frequency (TF-IDF) was used to obtain feature vectors. It is often used as a weighting factor in information retrieval and text mining. The TF-IDF value increases proportionally to the number of times a word appears in the document, but is offset by the frequency of the word in the corpus, which helps to control for the fact that some words are generally more common than others.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(USA)</code></pre>


<h3>Value</h3>

<p>A list with the following elements:
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>TF-IDF data. A matrix with 86 rows and 834 columns.</p>
</td></tr>
<tr><td><code>year</code></td>
<td>
<p>Year index. A vector with 86 elements.</p>
</td></tr>
<tr><td><code>president</code></td>
<td>
<p>President index. A vector with 86 elements.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Stefano Cacciatore and Leonardo Tenori</p>


<h3>References</h3>

<p>Cacciatore S, Luchinat C, Tenori L	<br />
Knowledge discovery by accuracy maximization.<br />
<em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br />	<br />
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br />
KODAMA: an updated R package for knowledge discovery and data mining.	<br />
<em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Here is reported the analysis on the State of the Union
# of USA president as shown in Cacciatore, et al. (2014)

data(USA)
kk=KODAMA.matrix(USA$data,FUN="KNN")
cc=KODAMA.visualization(kk,"t-SNE",perplexity = 10)
oldpar &lt;- par(cex=0.5,mar=c(15,6,2,2));
plot(USA$year,cc[,1],axes=FALSE,pch=20,xlab="",ylab="First Component");
axis(1,at=USA$year,labels=rownames(USA$data),las=2);
axis(2,las=2);
box()

par(oldpar)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
