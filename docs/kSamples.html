<!DOCTYPE html><html><head><title>Help for package kSamples</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {kSamples}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#kSamples-package'>
<p>The Package kSamples Contains Several Nonparametric K-Sample Tests and</p>
their Combinations over Blocks</a></li>
<li><a href='#ad.pval'>
<p><code class="reqn">P</code>-Value for the Asymptotic Anderson-Darling Test Distribution</p></a></li>
<li><a href='#ad.test'>
<p>Anderson-Darling k-Sample Test</p></a></li>
<li><a href='#ad.test.combined'>
<p>Combined Anderson-Darling k-Sample Tests</p></a></li>
<li><a href='#contingency2xt'>
<p>Kruskal-Wallis Test for the 2 x t Contingency Table</p></a></li>
<li><a href='#contingency2xt.comb'>
<p>Combined Kruskal-Wallis Tests for the 2 x t Contingency Tables</p></a></li>
<li><a href='#conv'>
<p>Convolution of Two Discrete Distributions</p></a></li>
<li><a href='#JT.dist'>
<p>Null Distribution of the</p>
Jonckheere-Terpstra k-Sample Test Statistic</a></li>
<li><a href='#jt.test'>
<p>Jonckheere-Terpstra k-Sample Test for Increasing Alternatives</p></a></li>
<li><a href='#pp.kSamples'>
<p>Upper Tail Probability Plots for Objects of Class kSamples</p></a></li>
<li><a href='#qn.test'>
<p>Rank Score k-Sample Tests</p></a></li>
<li><a href='#qn.test.combined'>
<p>Combined Rank Score k-Sample Tests</p></a></li>
<li><a href='#ShorelineFireEMS'>
<p>Shoreline Fire and EMS Turnout Times</p></a></li>
<li><a href='#Steel.test'>
<p>Steel's Multiple Comparison Wilcoxon Tests</p></a></li>
<li><a href='#SteelConfInt'>
<p>Simultaneous Confidence Bounds Based on Steel's Multiple Comparison Wilcoxon Tests</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>K-Sample Rank Tests and their Combinations</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2-10</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-10-07</td>
</tr>
<tr>
<td>Author:</td>
<td>Fritz Scholz [aut, cre],
  Angie Zhu [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Fritz Scholz &lt;fscholz@u.washington.edu&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>SuppDists</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, graphics, stats</td>
</tr>
<tr>
<td>Description:</td>
<td>Compares k samples using the Anderson-Darling test, Kruskal-Wallis type tests 
	with different rank score criteria, Steel's multiple comparison test, and the 
        Jonckheere-Terpstra (JT) test. It computes asymptotic, simulated or (limited) exact 
        P-values, all valid under randomization, with or without ties, or conditionally 
        under random sampling from populations, given the observed tie pattern.  Except for 
        Steel's test and the JT test it also combines these tests across several blocks of 
	samples.  Also analyzed are 2 x t contingency tables and their blocked combinations 
	using the Kruskal-Wallis criterion.  Steel's test is inverted to provide simultaneous 
	confidence bounds for shift parameters.  A plotting function compares tail probabilities
	obtained under asymptotic approximation with those obtained via simulation or exact 
	calculations.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-07 20:27:25 UTC; fritz</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-07 23:10:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='kSamples-package'>
The Package kSamples Contains Several Nonparametric K-Sample Tests and 
their Combinations over Blocks
</h2><span id='topic+kSamples-package'></span><span id='topic+kSamples'></span>

<h3>Description</h3>

<p>The k-sample Anderson-Darling, Kruskal-Wallis, normal score and van der Waerden score tests
are used to test the hypothesis that k samples of 
sizes <code class="reqn">n_1, \ldots, n_k</code>
come from a common continuous distribution <code class="reqn">F</code> that is otherwise unspecified. They are rank tests.
Average rank scores are used in case of ties. 
While <code><a href="#topic+ad.test">ad.test</a></code> is consistent against all alternatives, <code><a href="#topic+qn.test">qn.test</a></code>
tends to be sensitive mainly to shifts between samples.
The combined versions of these tests,
<code><a href="#topic+ad.test.combined">ad.test.combined</a></code> and
<code><a href="#topic+qn.test.combined">qn.test.combined</a></code>, are 
used to simultaneously test such hypotheses across several blocks of samples.
The hypothesized common distributions and the number k of samples for each block of samples
may vary from block to block. 
</p>
<p>The Jonckheere-Terpstra test addresses the same hypothesis as above but is sensitive to increasing
alternatives (stochastic ordering).
</p>
<p>Also treated is the analysis of 2 x t contingency tables
using the Kruskal-Wallis criterion and its extension to blocks.
</p>
<p>Steel's simultaneous comparison test of a common control sample with <code class="reqn">s=k-1</code> treatment samples
using pairwise Wilcoxon tests for each control/treatment pair is provided, and also 
the simultaneous confidence bounds of treatment shift effects resulting from the inversion of these tests
when sampling from continuous populations.
</p>
<p>Distributional aspects are handled asymptotically in all cases, and by choice also
via simulation or exact enumeration.
While simulation is always an option, exact calculations
are only possible for small sample sizes and only when few samples are involved. These exact
calculations can be done with or without ties in the pooled samples, based on a recursively extended
version of Algorithm C (Chase's sequence) in Knuth (2011), which allows the 
enumeration of all possible splits of the pooled data into samples of
sizes of <code class="reqn">n_1, \ldots, n_k</code>, as appropriate under treatment randomization
or random sampling, when viewing tests conditionally given the observed tie pattern.
</p>


<h3>Author(s)</h3>

<p>Fritz Scholz and Angie Zhu
</p>
<p>Maintainer: Fritz Scholz &lt;fscholz@u.washington.edu&gt;
</p>


<h3>References</h3>

<p>Hajek, J., Sidak, Z., and Sen, P.K. (1999), <em>Theory of Rank Tests (Second Edition)</em>, Academic Press.
</p>
<p>Knuth, D.E. (2011), <em>The Art of Computer Programming, Volume 4A 
Combinatorial Algorithms Part 1</em>, Addison-Wesley
</p>
<p>Kruskal, W.H. (1952), A Nonparametric Test for the Several Sample Problem,
<em>The Annals of Mathematical Statistics</em>,
<b>Vol 23, No. 4</b>, 525-540
</p>
<p>Kruskal, W.H. and Wallis, W.A. (1952), Use of Ranks in One-Criterion Variance Analysis,
<em>Journal of the American Statistical Association</em>, 
<b>Vol 47, No. 260</b>, 583&ndash;621. 
</p>
<p>Lehmann, E.L. (2006), <em>Nonparametrics, Statistical Methods Based on Ranks</em>,
Revised First Edition, 
Springer, New York.
</p>
<p>Scholz, F.W. (2023), &quot;On Steel's Test with Ties&quot;, <a href="https://arxiv.org/abs/2308.05873">https://arxiv.org/abs/2308.05873</a>
</p>
<p>Scholz, F. W. and Stephens, M. A. (1987), K-sample Anderson-Darling Tests, <em>Journal of the American Statistical Association</em>, 
<b>Vol 82, No. 399</b>, 918&ndash;924. 
</p>

<hr>
<h2 id='ad.pval'>
<code class="reqn">P</code>-Value for the Asymptotic Anderson-Darling Test Distribution
</h2><span id='topic+ad.pval'></span>

<h3>Description</h3>

<p>This function computes upper tail probabilities for the limiting distribution of the 
standardized Anderson-Darling test statistic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ad.pval(tx,m,version=1) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ad.pval_+3A_tx">tx</code></td>
<td>

<p>a vector of desired thresholds <code class="reqn">\ge 0</code>
</p>
</td></tr>
<tr><td><code id="ad.pval_+3A_m">m</code></td>
<td>
 
<p>The degrees of freedom for the asymptotic standardized Anderson-Darling test statistic
</p>
</td></tr>
<tr><td><code id="ad.pval_+3A_version">version</code></td>
<td>
<p><code>= 1</code> (default) if <code class="reqn">P</code>-value for version 1 of the 
test statistic is desired, otherwise the version 2 <code class="reqn">P</code>-value is calculated.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extensive simulations (sampling from a common continuous distribution)
were used to extend the range of the asymptotic 
<code class="reqn">P</code>-value calculation from the original <code class="reqn">[.01,.25]</code> in Table 1 of the reference paper
to 36 quantiles corresponding to <code class="reqn">P</code>  = .00001, .00005, .0001, .0005, .001, .005, .01, .025, 
.05, .075, .1, .2, .3, .4, .5, .6, .7, .8, .9, .925, .95, .975, .99, .9925, .995, .9975, .999,
.99925, .9995, .99975, .9999, .999925, .99995, .999975, .99999. Note that the entries of the original Table 1
were obtained by using the first 4 moments of the asymptotic distribution and a
Pearson curve approximation.
</p>
<p>Using <code>ad.test</code>,
1 million replications of the standardized <code class="reqn">AD</code> statistics with sample sizes
<code class="reqn">n_i=500</code>, <code class="reqn">i=1,\ldots,k</code> were run for <code class="reqn">k=2,3,4,5,7</code> (<code class="reqn">k=2</code> was done twice).
These values of <code class="reqn">k</code> correspond to degrees of freedom
<code class="reqn">m=k-1=1,2,3,4,6</code> in the asymptotic distribution. The random variable described by this 
distribution is denoted by <code class="reqn">T_m</code>.
The actual variances (for <code class="reqn">n_i=500</code>) agreed fairly well with the asymptotic variances.
</p>
<p>Using the convolution nature of the asymptotic distribution, the performed simulations
were exploited to result in an effective simulation of 2 million cases, except for 
<code class="reqn">k=11</code>, i.e., <code class="reqn">m=k-1=10</code>, for which the asymptotic distribution of 
<code class="reqn">T_{10}</code>
was approximated by the sum of the <code class="reqn">AD</code> statistics for <code class="reqn">k=7</code> and <code class="reqn">k=5</code>, 
for just the 1 million cases run for each <code class="reqn">k</code>. 
</p>
<p>The interpolation of tail 
probabilities <code class="reqn">P</code>
for any desired <code class="reqn">k</code> is done in two stages. First, a spline in <code class="reqn">1/\sqrt{m}</code> is
fitted to each of the 36 quantiles obtained for <code class="reqn">m=1,2,3,4,6,8,10,\infty</code> to obtain 
the corresponding interpolated quantiles for the <code class="reqn">m</code> in question. 
</p>
<p>Then a spline is fitted
to the <code class="reqn">\log((1-P)/P)</code> as a function of these 36 interpolated quantiles. This latter
spline is used to determine the tail probabilities <code class="reqn">P</code> for the 
specified threshold <code>tx</code>, corresponding to either <code class="reqn">AD</code> 
statistic version. The above procedure is based on simulations for either version
of the test statistic,
appealing to the same limiting distribution.
</p>


<h3>Value</h3>

<p>a vector of upper tail probabilities corresponding to <code>tx</code>
</p>


<h3>References</h3>

<p>Scholz, F. W. and Stephens, M. A. (1987), K-sample Anderson-Darling Tests, 
<em>Journal of the American Statistical Association</em>, 
<b>Vol 82, No. 399</b>, 918&ndash;924. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ad.test">ad.test</a></code>,
<code><a href="#topic+ad.test.combined">ad.test.combined</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ad.pval(tx=c(3.124,5.65),m=2,version=1)
ad.pval(tx=c(3.124,5.65),m=2,version=2)
</code></pre>

<hr>
<h2 id='ad.test'>
Anderson-Darling k-Sample Test
</h2><span id='topic+ad.test'></span>

<h3>Description</h3>

<p>This function uses the Anderson-Darling criterion to test
the hypothesis that <code class="reqn">k</code> independent samples with sample sizes  
<code class="reqn">n_1,\ldots, n_k</code> arose
from a common unspecified distribution function <code class="reqn">F(x)</code> and testing is 
done conditionally given the observed tie pattern. Thus this is a permutation test.
Both versions of the <code class="reqn">AD</code> statistic are computed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ad.test(..., data = NULL, method = c("asymptotic", "simulated", "exact"),
	dist = FALSE, Nsim = 10000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ad.test_+3A_...">...</code></td>
<td>

<p>Either several sample vectors, say 
<code class="reqn">x_1, \ldots, x_k</code>, 
with <code class="reqn">x_i</code> containing <code class="reqn">n_i</code> sample values.
<code class="reqn">n_i &gt; 4</code> is recommended for reasonable asymptotic 
<code class="reqn">P</code>-value calculation. The pooled sample size is denoted 
by <code class="reqn">N=n_1+\ldots+n_k</code>,
</p>
<p>or a list of such sample vectors,
</p>
<p>or a formula y ~ g, where y contains the pooled sample values 
and g is a factor (of same length as y) with levels identifying 
the samples to which the elements of y belong. 
</p>
</td></tr>
<tr><td><code id="ad.test_+3A_data">data</code></td>
<td>
<p>= an optional data frame providing the variables in formula y ~ g.
</p>
</td></tr>
<tr><td><code id="ad.test_+3A_method">method</code></td>
<td>
<p>= <code>c("asymptotic","simulated","exact")</code>, where
</p>
<p><code>"asymptotic"</code> uses only an asymptotic <code class="reqn">P</code>-value approximation, reasonable 
for P in [.00001, .99999] when all <code class="reqn">n_i &gt; 4</code>. 
Linear extrapolation via <code class="reqn">\log(P/(1-P))</code>
is used outside [.00001, .99999]. This calculation is always done.
See <code><a href="#topic+ad.pval">ad.pval</a></code> for details. 
The adequacy of the asymptotic <code class="reqn">P</code>-value calculation
may be checked using <code><a href="#topic+pp.kSamples">pp.kSamples</a></code>.
</p>
<p><code>"simulated"</code> uses <code>Nsim</code> simulated <code class="reqn">AD</code> statistics, based on random 
splits of the pooled samples into samples of sizes 
<code class="reqn">n_1, \ldots, n_k</code>, to estimate the exact conditional <code class="reqn">P</code>-value.
</p>
<p><code>"exact"</code> uses full enumeration of all sample splits with 
resulting <code class="reqn">AD</code> statistics to obtain the exact conditional <code class="reqn">P</code>-values. 
It is used only when <code>Nsim</code> is at least as large as the number
</p>
<p style="text-align: center;"><code class="reqn">ncomb = \frac{N!}{n_1!\ldots n_k!}</code>
</p>

<p>of full enumerations. Otherwise, <code>method</code>
reverts to <code>"simulated"</code> using the given <code>Nsim</code>. It also reverts
to <code>"simulated"</code> when <code class="reqn">ncomb &gt; 1e8</code> and <code>dist = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="ad.test_+3A_dist">dist</code></td>
<td>
<p><code>= FALSE</code> (default) or <code>TRUE</code>. If <code>TRUE</code>, the 
simulated or fully enumerated distribution vectors <code>null.dist1</code> and
<code>null.dist2</code> are returned for the respective test statistic versions.
Otherwise, <code>NULL</code> is returned. When <code>dist = TRUE</code> then 
<code>Nsim &lt;- min(Nsim, 1e8)</code>, to limit object size.
</p>
</td></tr>
<tr><td><code id="ad.test_+3A_nsim">Nsim</code></td>
<td>
<p><code>= 10000</code> (default), number of simulation sample splits to use.	
It is only used when <code>method = "simulated"</code>,
or when <code>method = "exact"</code> reverts to <code>method =</code>
<code> "simulated"</code>, as previously explained.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code class="reqn">AD</code> is the Anderson-Darling criterion for the <code class="reqn">k</code> samples, 
its standardized test statistic is <code class="reqn">T.AD = (AD - \mu)/\sigma</code>, with 
<code class="reqn">\mu = k-1</code> and
<code class="reqn">\sigma</code> representing mean and standard deviation of <code class="reqn">AD</code>. This statistic 
is used to test the hypothesis that the samples all come 
from the same but unspecified continuous distribution function <code class="reqn">F(x)</code>.
</p>
<p>According to the reference article, two versions
of the <code class="reqn">AD</code> test statistic are provided.
The above mean and standard deviation are strictly
valid only for version 1 in the 
continuous distribution case.
</p>
<p>NA values are removed and the user is alerted with the total NA count.
It is up to the user to judge whether the removal of NA's is appropriate.
</p>
<p>The continuity assumption can be dispensed with, if we deal with 
independent random samples, or if randomization was used in allocating
subjects to samples or treatments, and if we view
the simulated or exact <code class="reqn">P</code>-values conditionally, given the tie pattern
in the pooled samples. Of course, under such randomization any conclusions 
are valid only with respect to the group of subjects that were randomly allocated
to their respective samples.
The asymptotic <code class="reqn">P</code>-value calculation assumes distribution continuity. No adjustment 
for lack thereof is known at this point. For details on the asymptotic 
<code class="reqn">P</code>-value calculation see <code><a href="#topic+ad.pval">ad.pval</a></code>.
</p>


<h3>Value</h3>

<p>A list of class <code>kSamples</code> with components 
</p>
<table>
<tr><td><code>test.name</code></td>
<td>
<p><code>"Anderson-Darling"</code></p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>number of samples being compared</p>
</td></tr>
<tr><td><code>ns</code></td>
<td>
<p>vector of the <code class="reqn">k</code> sample sizes <code class="reqn">(n_1,\ldots,n_k)</code></p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>size of the pooled sample <code class="reqn">= n_1+\ldots+n_k</code></p>
</td></tr>
<tr><td><code>n.ties</code></td>
<td>
<p>number of ties in the pooled samples</p>
</td></tr>
<tr><td><code>sig</code></td>
<td>
<p>standard deviations <code class="reqn">\sigma</code> of version 1 of <code class="reqn">AD</code> under the continuity assumption</p>
</td></tr>
<tr><td><code>ad</code></td>
<td>
<p>2 x 3 (2 x 4) matrix containing <code class="reqn">AD, T.AD</code>, asymptotic <code class="reqn">P</code>-value, 
(simulated or exact <code class="reqn">P</code>-value), for each version of the standardized test statistic <code class="reqn">T</code>,
version 1 in row 1, version 2 in row 2.</p>
</td></tr>
<tr><td><code>warning</code></td>
<td>
<p>logical indicator, warning = TRUE when at least one 
<code class="reqn">n_i &lt; 5</code></p>
</td></tr>
<tr><td><code>null.dist1</code></td>
<td>
<p>simulated or enumerated null distribution of version 1 
of the test statistic, given as vector of all generated <code class="reqn">AD</code> statistics.</p>
</td></tr>
<tr><td><code>null.dist2</code></td>
<td>
<p>simulated or enumerated null distribution of version 2 
of the test statistic, given as vector of all generated <code class="reqn">AD</code> statistics.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>The <code>method</code> used.</p>
</td></tr>
<tr><td><code>Nsim</code></td>
<td>
<p>The number of simulations.</p>
</td></tr>
</table>


<h3>warning </h3>

<p><code>method = "exact"</code> should only be used with caution.
Computation time is proportional to the number of enumerations. In most cases
<code>dist = TRUE</code> should not be used, i.e.,  
when the returned distribution vectors <code>null.dist1</code> and <code>null.dist2</code>
become too large for the R work space. These vectors are limited in length by 1e8. 
</p>


<h3>Note</h3>

<p>For small sample sizes and small <code class="reqn">k</code> exact null distribution
calculations are possible (with or without ties), based on a recursively extended
version of Algorithm C (Chase's sequence) in Knuth (2011), Ch. 7.2.1.3, which allows the 
enumeration of all possible splits of the pooled data into samples of
sizes of <code class="reqn">n_1, \ldots, n_k</code>, as appropriate under treatment randomization. The
enumeration and simulation are both done in C.
</p>


<h3>Note</h3>

<p>It has recently come to our attention that the Anderson-Darling test, originally 
proposed by Pettitt (1976) in the 2-sample case and generalized to k samples by
Scholz and Stephens, has a close relative created by Baumgartner et al (1998) in
the 2 sample case and populatized by Neuhaeuser (2012) with at least 6 papers 
among his cited references and generalized by Murakami (2006) to k samples.
</p>


<h3>References</h3>

<p>Baumgartner, W., Weiss, P. and Schindler, H. (1998), A nonparametric test for the 
general two-sample problem, <em>Bionetrics</em>, <b>54</b>, 1129-1135.
</p>
<p>Knuth, D.E. (2011), <em>The Art of Computer Programming, Volume 4A 
Combinatorial Algorithms Part 1</em>, Addison-Wesley
</p>
<p>Neuhaeuser, M. (2012), <em>Nonparametric Statistical Tests, A Computational Approach</em>,
CRC Press.
</p>
<p>Murakami, H. (2006), A k-sample rank test based on modified Baumgartner statistic and
it power comparison, 
<em>Jpn. Soc. Comp. Statist.</em>, <b>19</b>, 1-13.
</p>
<p>Murakami, H. (2012), Modified Baumgartner statistic for the two-sample and multisample 
problems: a numerical comparison.
<em>J. of Statistical Comput. and Simul.</em>, <b>82:5</b>, 711-728.
</p>
<p>Pettitt, A.N. (1976), A two-sample Anderson_Darling rank statistic, <em>Biometrika</em>,
<b>63</b>, 161-168.
</p>
<p>Scholz, F. W. and Stephens, M. A. (1987), K-sample Anderson-Darling Tests, 
<em>Journal of the American Statistical Association</em>, 
<b>Vol 82, No. 399</b>, 918&ndash;924. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ad.test.combined">ad.test.combined</a></code>, <code><a href="#topic+ad.pval">ad.pval</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>u1 &lt;- c(1.0066, -0.9587,  0.3462, -0.2653, -1.3872)
u2 &lt;- c(0.1005, 0.2252, 0.4810, 0.6992, 1.9289)
u3 &lt;- c(-0.7019, -0.4083, -0.9936, -0.5439, -0.3921)
y &lt;- c(u1, u2, u3)
g &lt;- as.factor(c(rep(1, 5), rep(2, 5), rep(3, 5)))
set.seed(2627)
ad.test(u1, u2, u3, method = "exact", dist = FALSE, Nsim = 1000)
# or with same seed
# ad.test(list(u1, u2, u3), method = "exact", dist = FALSE, Nsim = 1000)
# or with same seed
# ad.test(y ~ g, method = "exact", dist = FALSE, Nsim = 1000)
</code></pre>

<hr>
<h2 id='ad.test.combined'>
Combined Anderson-Darling k-Sample Tests
</h2><span id='topic+ad.test.combined'></span>

<h3>Description</h3>

<p>This function combines several independent Anderson-Darling <code class="reqn">k</code>-sample tests
into one overall test of the hypothesis that the independent samples within 
each block come from a common unspecified distribution, while the common
distributions may vary from block to block.  Both versions of the 
Anderson-Darling test statistic are provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ad.test.combined(..., data = NULL,
	method = c("asymptotic", "simulated", "exact"),
	dist = FALSE, Nsim = 10000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ad.test.combined_+3A_...">...</code></td>
<td>

<p>Either a sequence of several lists, say <code class="reqn">L_1, \ldots, L_M</code> (<code class="reqn">M &gt; 1</code>)
where list <code class="reqn">L_i</code> contains <code class="reqn">k_i &gt; 1</code>  sample vectors of respective 
sizes <code class="reqn">n_{i1}, \ldots, n_{ik_i}</code>, 
where <code class="reqn">n_{ij} &gt; 4</code> is recommended
for reasonable asymptotic <code class="reqn">P</code>-value calculation. 
<code class="reqn">N_i=n_{i1}+\ldots+n_{ik_i}</code>
is the pooled sample size for block <code class="reqn">i</code>,
</p>
<p>or a list of such lists,
</p>
<p>or a formula, like y ~ g | b, where y is a numeric response vector,
g is a factor with levels indicating different treatments and
b is a factor indicating different blocks; y, g, b are or equal length. 
y is split separately for each block level into separate samples 
according to the g levels. The same g level may occur in different blocks. 
The variable names may correspond to variables in an optionally supplied 
data frame via the data = argument,
</p>
</td></tr>
<tr><td><code id="ad.test.combined_+3A_data">data</code></td>
<td>
<p>= an optional data frame providing the variables in formula input
</p>
</td></tr>
<tr><td><code id="ad.test.combined_+3A_method">method</code></td>
<td>
<p>= <code>c("asymptotic","simulated","exact")</code>, where
</p>
<p><code>"asymptotic"</code> uses only an asymptotic <code class="reqn">P</code>-value approximation, reasonable 
for P in [0.00001, .99999], linearly extrapolated via 
<code class="reqn">\log(P/(1-P))</code> outside 
that range. See <code><a href="#topic+ad.pval">ad.pval</a></code> for details. 		
The adequacy of the asymptotic <code class="reqn">P</code>-value calculation may be checked using 
<code><a href="#topic+pp.kSamples">pp.kSamples</a></code>.
</p>
<p><code>"simulated"</code> uses simulation to get <code>Nsim</code> simulated <code class="reqn">AD</code> statistics 
for each block of samples, adding them across blocks component wise to get <code>Nsim</code> 
combined values. These are compared with the observed combined value to obtain the 
estimated	<code class="reqn">P</code>-value.
</p>
<p><code>"exact"</code> uses full enumeration of the test statistic values 
for all sample splits of the pooled samples within each block.
The test statistic vectors for the first 2 blocks are added 
(each component against each component, as in the R <code>outer(x,y,</code> <code>"+")</code> command) 
to get the convolution enumeration for the combined test statistic. The resulting
vector is convoluted against the next block vector in the same fashion, and so on.
It is possible only for small problems, and is attempted only when <code>Nsim</code>
is at least the (conservatively maximal) length 
</p>
<p style="text-align: center;"><code class="reqn">\frac{N_1!}{n_{11}!\ldots n_{1k_1}!}\times\ldots\times 
			\frac{N_M!}{n_{M1}!\ldots n_{Mk_M}!}</code>
</p>

<p>of the final distribution vector. Otherwise, it reverts to the 
simulation method using the provided <code>Nsim</code>.
</p>
</td></tr>
<tr><td><code id="ad.test.combined_+3A_dist">dist</code></td>
<td>
<p><code>FALSE</code> (default) or <code>TRUE</code>. If <code>TRUE</code>, the 
simulated or fully enumerated convolution vectors 
<code>null.dist1</code> and <code>null.dist2</code> are returned for the respective
test statistic versions. Otherwise, <code>NULL</code> is returned for each.
</p>
</td></tr>
<tr><td><code id="ad.test.combined_+3A_nsim">Nsim</code></td>
<td>
<p><code>= 10000</code> (default), number of simulation splits to use within 
each block of samples. It is only used when <code>method = "simulated"</code>
or when <code>method =</code> <code>"exact"</code> reverts to <code>method = "simulated"</code>, 
as previously explained. Simulations are independent across blocks, 
using <code>Nsim</code> for each block. <code>Nsim</code> is limited by <code>1e7</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code class="reqn">AD_i</code> is the Anderson-Darling criterion for the i-th block of 
<code class="reqn">k_i</code> samples, 
its standardized test statistic is 
<code class="reqn">T_i = (AD_i - \mu_i)/\sigma_i</code>, with 
<code class="reqn">\mu_i</code> and
<code class="reqn">\sigma_i</code> representing mean and standard deviation of 
<code class="reqn">AD_i</code>. This statistic 
is used to test the hypothesis that the samples in the i-th block all come 
from the same but unspecified continuous distribution function <code class="reqn">F_i(x)</code>.
</p>
<p>The combined Anderson-Darling criterion is 
<code class="reqn">AD_{comb}=AD_1 + \ldots + AD_M</code> and 
<code class="reqn">T_{comb} = </code> <code class="reqn">(AD_{comb} - \mu_c)/\sigma_c</code> is the standardized form, 
where <code class="reqn">\mu_c=\mu_1+\ldots+\mu_M</code> and <code class="reqn">\sigma_c =
\sqrt{\sigma_1^2 +\ldots+\sigma_M^2}</code> 
represent the mean and standard deviation of <code class="reqn">AD_{comb}</code>.
The statistic <code class="reqn">T_{comb}</code> is used to simultaneously 
test whether the samples 
in each block come from the same continuous distribution function 
<code class="reqn">F_i(x), i=1,\ldots,M</code>. 
The unspecified common distribution function <code class="reqn">F_i(x)</code> may change 
from block to block. According to the reference article, two versions
of the test statistic and its corresponding combinations are provided.
</p>
<p>The <code class="reqn">k_i</code> for each block of <code class="reqn">k_i</code>
independent samples may change from block to block.
</p>
<p>NA values are removed and the user is alerted with the total NA count.
It is up to the user to judge whether the removal of NA's is appropriate.
</p>
<p>The continuity assumption can be dispensed with if we deal with 
independent random samples, or if randomization was used in allocating
subjects to samples or treatments, independently from block to block, and if we view
the simulated or exact <code class="reqn">P</code>-values conditionally, given the tie patterns
within each block. Of course, under such randomization any conclusions 
are valid only with respect to the blocks of subjects that were randomly allocated.
The asymptotic <code class="reqn">P</code>-value calculation assumes distribution continuity. No adjustment 
for lack thereof is known at this point. The same comment holds for the means
and standard deviations of respective statistics.
</p>


<h3>Value</h3>

<p>A list of class <code>kSamples</code> with components 
</p>
<table>
<tr><td><code>test.name</code></td>
<td>
<p><code class="reqn">=</code> <code>"Anderson-Darling"</code></p>
</td></tr>
<tr><td><code>M</code></td>
<td>
<p>number of blocks of samples being compared</p>
</td></tr>
<tr><td><code>n.samples</code></td>
<td>
<p>list of <code>M</code> vectors, each vector giving the sample sizes for 
each block of samples being compared</p>
</td></tr>
<tr><td><code>nt</code></td>
<td>
<p><code class="reqn">= (N_1,\ldots,N_M)</code></p>
</td></tr>
<tr><td><code>n.ties</code></td>
<td>
<p>vector giving the number of ties in each the <code>M</code>
comparison blocks</p>
</td></tr>
<tr><td><code>ad.list</code></td>
<td>
<p>list of <code>M</code> matrices giving the <code>ad</code> results 
for <code>ad.test</code> applied to the samples in each of
the <code>M</code> blocks</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>vector of means of the <code class="reqn">AD</code> statistic for the  <code>M</code> blocks</p>
</td></tr>
<tr><td><code>sig</code></td>
<td>
<p>vector of standard deviations of the <code class="reqn">AD</code> statistic for the  <code>M</code> blocks</p>
</td></tr>
<tr><td><code>ad.c</code></td>
<td>
<p>2 x 3 (2 x 4) matrix containing 
<code class="reqn">AD_{comb}, T_{comb}</code>, asymptotic <code class="reqn">P</code>-value, 
(simulated or exact <code class="reqn">P</code>-value), for each version of the combined test statistic,
version 1 in row 1 and version 2 in row 2</p>
</td></tr>
<tr><td><code>mu.c</code></td>
<td>
<p>mean of <code class="reqn">AD_{comb}</code></p>
</td></tr>
<tr><td><code>sig.c</code></td>
<td>
<p>standard deviation of <code class="reqn">AD_{comb}</code></p>
</td></tr>
<tr><td><code>warning</code></td>
<td>
<p>logical indicator, <code>warning = TRUE</code> when at least one 
<code class="reqn">n_{ij} &lt; 5</code></p>
</td></tr>
<tr><td><code>null.dist1</code></td>
<td>
<p>simulated or enumerated null distribution of version 1 
of <code class="reqn">AD_{comb}</code></p>
</td></tr>
<tr><td><code>null.dist2</code></td>
<td>
<p>simulated or enumerated null distribution of version 2 
of <code class="reqn">AD_{comb}</code></p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the <code>method</code> used.</p>
</td></tr>
<tr><td><code>Nsim</code></td>
<td>
<p>the number of simulations used for each block of samples.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This test is useful in analyzing treatment effects in randomized 
(incomplete) block experiments and in examining performance 
equivalence of several laboratories when presented with different 
test materials for comparison.
</p>


<h3>References</h3>

<p>Scholz, F. W. and Stephens, M. A. (1987), K-sample Anderson-Darling Tests, 
<em>Journal of the American Statistical Association</em>, 
<b>Vol 82, No. 399</b>, 918&ndash;924. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ad.test">ad.test</a></code>, <code><a href="#topic+ad.pval">ad.pval</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create two lists of sample vectors.
x1 &lt;- list( c(1, 3, 2, 5, 7), c(2, 8, 1, 6, 9, 4), c(12, 5, 7, 9, 11) )
x2 &lt;- list( c(51, 43, 31, 53, 21, 75), c(23, 45, 61, 17, 60) )
# and a corresponding data frame datx1x2
x1x2 &lt;- c(unlist(x1),unlist(x2))
gx1x2 &lt;- as.factor(c(rep(1,5),rep(2,6),rep(3,5),rep(1,6),rep(2,5)))
bx1x2 &lt;- as.factor(c(rep(1,16),rep(2,11)))
datx1x2 &lt;- data.frame(A = x1x2, G = gx1x2, B = bx1x2)

## Run ad.test.combined.
set.seed(2627)
ad.test.combined(x1, x2, method = "simulated", Nsim = 1000) 
# or with same seed
# ad.test.combined(list(x1, x2), method = "simulated", Nsim = 1000)
# ad.test.combined(A~G|B,data=datx1x2,method="simulated",Nsim=1000)


</code></pre>

<hr>
<h2 id='contingency2xt'>
Kruskal-Wallis Test for the 2 x t Contingency Table 
</h2><span id='topic+contingency2xt'></span>

<h3>Description</h3>

<p>This function uses the Kruskal-Wallis criterion to test
the hypothesis of no association between the counts 
for two responses
&quot;A&quot; and &quot;B&quot; across t categories.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>contingency2xt(Avec, Bvec, 
	method = c("asymptotic", "simulated", "exact"), 
	dist = FALSE, tab0 = TRUE, Nsim = 1e+06)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="contingency2xt_+3A_avec">Avec</code></td>
<td>

<p>vector of length <code class="reqn">t</code> giving the counts <code class="reqn">A_1,\ldots, A_t</code>
for response &quot;A&quot; according to <code class="reqn">t</code> categories. 
<code class="reqn">m = A_1 + \ldots + A_t</code>.
</p>
</td></tr>
<tr><td><code id="contingency2xt_+3A_bvec">Bvec</code></td>
<td>

<p>vector of length <code class="reqn">t</code> giving the counts <code class="reqn">B_1,\ldots, B_t</code>
for response &quot;B&quot; according to <code class="reqn">t</code> categories. 
<code class="reqn">n = B_1 + \ldots + B_t = N-m</code>.
</p>
</td></tr>
<tr><td><code id="contingency2xt_+3A_method">method</code></td>
<td>
<p>= <code>c("asymptotic","simulated","exact")</code>, where
</p>
<p><code>"asymptotic"</code> uses only an asymptotic chi-square approximation 
with <code class="reqn">t-1</code> degrees of freedom to approximate the <code class="reqn">P</code>-value. 
This calculation is always done.
</p>
<p><code>"simulated"</code> uses <code>Nsim</code> simulated counts for <code>Avec</code> and 
<code>Bvec</code> with the observed marginal totals, <code>m, n, d = Avec+Bvec</code>, 
to estimate the <code class="reqn">P</code>-value.
</p>
<p><code>"exact"</code> enumerates all counts for <code>Avec</code> and <code>Bvec</code> with 
the observed marginal totals to get an exact <code class="reqn">P</code>-value. It is used only 
when <code>Nsim</code> is at least as large as the number <code>choose(m+t-1,t-1)</code>
of full enumerations. 
Otherwise, <code>method</code> reverts to <code>"simulated"</code> using the given <code>Nsim</code>.
</p>
</td></tr>
<tr><td><code id="contingency2xt_+3A_dist">dist</code></td>
<td>
<p><code>FALSE</code> (default) or <code>TRUE</code>. If <code>dist = TRUE</code>, the distribution of the
simulated or fully enumerated Kruskal-Wallis test statistics is
returned as <code>null.dist</code>, if <code>dist = FALSE</code> the value
of <code>null.dist</code> is <code>NULL</code>.
The coice <code>dist = TRUE</code> also limits <code>Nsim &lt;- min(Nsim,1e8)</code>.
</p>
</td></tr>
<tr><td><code id="contingency2xt_+3A_tab0">tab0</code></td>
<td>
<p><code>TRUE</code> (default) or <code>FALSE</code>. If <code>tab0 = TRUE</code>, the null distribution
is returned in 2 column matrix form when 
<code>method = "simulated"</code>. When <code>tab0 = FALSE</code> the simulated null distribution 
is returned as a vector of all simulated values of the test statistic.
</p>
</td></tr>
<tr><td><code id="contingency2xt_+3A_nsim">Nsim</code></td>
<td>
<p><code>=10000</code> (default), number of simulated <code>Avec</code> splits to use.	
It is only used when <code>method = "simulated"</code>,
or when <code>method = "exact"</code> reverts to <code>method =</code>
<code>"simulated"</code>, as previously explained.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For this data scenario the Kruskal-Wallis criterion is
</p>
<p style="text-align: center;"><code class="reqn">K.star = \frac{N(N-1)}{mn}(\sum\frac{A_i^2}{d_i}-\frac{m^2}{N})</code>
</p>

<p>with <code class="reqn">d_i=A_i+B_i</code>, treating &quot;A&quot; responses
as 1 and &quot;B&quot; responses as 2, and using midranks as explained in Lehmann (2006), Chapter 5.3.
</p>
<p>For small sample sizes exact null distribution
calculations are possible, based on Algorithm C (Chase's sequence) in Knuth (2011),
which allows the enumeration of all possible splits of <code class="reqn">m</code> into counts
<code class="reqn">A_1,\ldots, A_t</code> such that 
<code class="reqn">m = A_1 + \ldots + A_t</code>,
followed by the calculation of the statistic 
<code class="reqn">K.star</code> for each such split. 
Simulation of <code class="reqn">A_1,\ldots, A_t</code> uses the probability model (5.35) in Lehmann (2006)
to successively generate hypergeometric counts <code class="reqn">A_1,\ldots, A_t</code>.
Both these processes, enumeration and simulation, are done in C.
</p>


<h3>Value</h3>

<p>A list of class <code>kSamples</code> with components 
</p>
<table>
<tr><td><code>test.name</code></td>
<td>
<p><code>"2 x t Contingency Table"</code></p>
</td></tr>
<tr><td><code>t</code></td>
<td>
<p>number of classification categories</p>
</td></tr>
<tr><td><code>KW.cont</code></td>
<td>
<p>2 (3) vector giving the observed KW statistic, its asymptotic 
<code class="reqn">P</code>-value (and simulated or exact <code class="reqn">P</code>-value) </p>
</td></tr>
<tr><td><code>null.dist</code></td>
<td>
<p>simulated or enumerated null distribution 
of the test statistic. It is given as an <code>M</code> by 2 matrix,
where the first column (named <code>KW</code>) gives the <code>M</code> unique ordered 
values of the Kruskal-Wallis 
statistic and the second column (named <code>prob</code>) gives the corresponding (simulated or exact)
probabilities. 
</p>
<p>This format of <code>null.dist</code> is returned when <code>method = "exact"</code> 
and <code>dist</code> <code>= TRUE</code> or when <code>method =</code><code> "simulated"</code> 
and <code>dist = TRUE</code> and <code>tab0</code> <code>= TRUE</code> are specified.
</p>
<p>For <code>method =</code> <code>"simulated"</code>, <code>dist = TRUE</code>, and 
<code>tab0 = FALSE</code> the null distribution <code>null.dist</code> is returned as the vector of
all simulated test statistic values. This is used in <code><a href="#topic+contingency2xt.comb">contingency2xt.comb</a></code>
in the simulation mode.
</p>
<p><code>null.dist = NULL</code> is returned 
when <code>dist = FALSE</code> or when <code>method =</code>
<code>"asymptotic"</code>. </p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the <code>method</code> used.</p>
</td></tr>
<tr><td><code>Nsim</code></td>
<td>
<p>the number of simulations.</p>
</td></tr>
</table>


<h3>warning</h3>

<p><code>method = "exact"</code> should only be used with caution.
Computation time is proportional to the number of enumerations. In most cases
<code>dist = TRUE</code> should not be used, i.e.,  
when the returned distribution objects 
become too large for R's work space.</p>


<h3>References</h3>

<p>Knuth, D.E. (2011), <em>The Art of Computer Programming, Volume 4A 
Combinatorial Algorithms Part 1</em>, Addison-Wesley
</p>
<p>Kruskal, W.H. (1952), A Nonparametric Test for the Several Sample Problem,
<em>The Annals of Mathematical Statistics</em>,
<b>Vol 23, No. 4</b>, 525-540
</p>
<p>Kruskal, W.H. and Wallis, W.A. (1952), Use of Ranks in One-Criterion Variance Analysis,
<em>Journal of the American Statistical Association</em>, 
<b>Vol 47, No. 260</b>, 583&ndash;621. 
</p>
<p>Lehmann, E.L. (2006), <em>Nonparametrics, Statistical Methods Based on Ranks</em>,
Revised First Edition, 
Springer, New York.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>contingency2xt(c(25,15,20),c(16,6,18),method="exact",dist=FALSE,
	tab0=TRUE,Nsim=1e3)
</code></pre>

<hr>
<h2 id='contingency2xt.comb'>
Combined Kruskal-Wallis Tests for the 2 x t Contingency Tables
</h2><span id='topic+contingency2xt.comb'></span>

<h3>Description</h3>

<p>This function uses the Kruskal-Wallis criterion to test
the hypothesis of no association between the counts 
for two responses
&quot;A&quot; and &quot;B&quot; across t categories and across <code class="reqn">M</code> blocks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>contingency2xt.comb(..., 
	method = c("asymptotic", "simulated", "exact"), 
	dist = FALSE, Nsim = 10000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="contingency2xt.comb_+3A_...">...</code></td>
<td>
 
<p>Either several lists <code class="reqn">L_1,\ldots,L_M</code>, each
of two equal length vectors <code class="reqn">A_i</code> and
<code class="reqn">B_i</code>, <code class="reqn">i=1,\ldots,M</code>, of counts <code class="reqn">\ge 0</code>, 
where the common length <code class="reqn">t_i</code> of <code class="reqn">A_i</code> and
<code class="reqn">B_i</code> may vary from list to list
</p>
<p>or a list of <code>M</code> such lists
</p>
</td></tr>
<tr><td><code id="contingency2xt.comb_+3A_method">method</code></td>
<td>
<p>= <code>c("asymptotic","simulated","exact")</code>, where
</p>
<p><code>"asymptotic"</code> uses only an asymptotic chi-square approximation 
with <code class="reqn">(t_1-1)+\ldots+(t_M-1)</code> degrees of freedom
to approximate the <code class="reqn">P</code>-value, This calculation is always done.
</p>
<p><code>"simulated"</code> uses <code>Nsim</code> simulated counts for the two vectors
<code class="reqn">A_i</code> and <code class="reqn">B_i</code> in list <code class="reqn">L_i</code>, 
with the observed marginal totals, <code class="reqn">m_i=\sum A_i</code>, 
<code class="reqn">n_i = \sum B_i</code>, <code class="reqn">d_i = A_i+B_i</code>. 
It does this independently from list to list using the same <code>Nsim</code> each time, 
adding the resulting Kruskal-Wallis criteria across lists
to get <code>Nsim</code> such summed values to estimate the <code class="reqn">P</code>-value.
</p>
<p><code>"exact"</code> enumerates all counts for <code class="reqn">A_i</code> and <code class="reqn">B_i</code> with 
the respective observed marginal totals to get an exact distribution for each list. 
These distributions are then convolved to obtain the <code class="reqn">P</code>-value.
It is used only when <code>Nsim</code> is at least as large as the product across blocks
of the number <code>choose(m+t-1,t-1)</code> of full enumerations per block, where
<code class="reqn">t = t_1,\ldots, t_M</code>.
Otherwise, <code>method</code> reverts to <code>"simulated"</code> using the given <code>Nsim</code>.
</p>
</td></tr>
<tr><td><code id="contingency2xt.comb_+3A_dist">dist</code></td>
<td>
<p><code>FALSE</code> (default) or <code>TRUE</code>. If <code>TRUE</code>, the 
simulated or fully enumerated null distribution <code>null.dist</code> is returned
for the Kruskal-Wallis test statistic. Otherwise <code>null.dist = NULL</code> is returned.
</p>
</td></tr>
<tr><td><code id="contingency2xt.comb_+3A_nsim">Nsim</code></td>
<td>
<p><code>=10000</code> (default), number of simulated <code class="reqn">A_i</code> splits to use per block.
It is only used when <code>method = "simulated"</code>,
or when <code>method = "exact"</code> reverts to <code>method = "simulated"</code>, as previously explained.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details on the calculation of the Kruskal-Wallis criterion and its exact or simulated
distribution for each block see <code><a href="#topic+contingency2xt">contingency2xt</a></code>.
</p>


<h3>Value</h3>

<p>A list of class <code>kSamples</code> with components 
</p>
<table>
<tr><td><code>test.name</code></td>
<td>
<p><code>"Combined 2 x t Contingency Tables"</code></p>
</td></tr>
<tr><td><code>t</code></td>
<td>
<p>vector giving the number of classification categories per block</p>
</td></tr>
<tr><td><code>M</code></td>
<td>
<p>number of blocked tables</p>
</td></tr>
<tr><td><code>kw.list</code></td>
<td>
<p>a list of the <code>KW.cont</code> output componenents from 
<code><a href="#topic+contingency2xt">contingency2xt</a></code> for each of the blocks</p>
</td></tr>
<tr><td><code>null.dist</code></td>
<td>
<p>simulated or enumerated null distribution 
of the combined test statistic. It is given as an <code>L</code> by 2 matrix,
where the first column (named <code>KW</code>) gives the <code>L</code> unique ordered 
values of the combined Kruskal-Wallis 
statistic and the second column (named <code>prob</code>) gives the corresponding (simulated or exact)
probabilities.
</p>
<p><code>null.dist = NULL</code> is returned when <code>dist = FALSE</code> or when 
<code>method =</code> <code>"asymptotic"</code>.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the <code>method</code> used.</p>
</td></tr>
<tr><td><code>Nsim</code></td>
<td>
<p>the number of simulations.</p>
</td></tr>
</table>


<h3>warning</h3>

<p><code>method = "exact"</code> should only be used with caution.
Computation time is proportional to the number of enumerations. In most cases
<code>dist = TRUE</code> should not be used, i.e.,  
when the returned distribution objects 
become too large for R's work space.</p>


<h3>Note</h3>

<p>The required level for <code>Nsim</code> in order for <code>method = "exact"</code>
to be carried out, is conservative, but there is no transparent way to get a 
better estimate. The actual dimension <code>L</code> of the realized <code>null.dist</code>
will typically be much smaller, since the distribution is compacted to
its unique support values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>out &lt;- contingency2xt.comb(list(c(25,15,20),c(16,6,18)),
list(c(12,4,5),c(13,8,9)),method = "simulated", dist=FALSE, Nsim=1e3)
</code></pre>

<hr>
<h2 id='conv'>
Convolution of Two Discrete Distributions
</h2><span id='topic+conv'></span>

<h3>Description</h3>

<p>This function convolutes two discrete distribution, each given by strictly increasing support vectors
and corresponding probability vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	conv(x1,p1,x2,p2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="conv_+3A_x1">x1</code></td>
<td>

<p>support vector of the first distribution, with strictly increasing elements.
</p>
</td></tr>
<tr><td><code id="conv_+3A_p1">p1</code></td>
<td>
<p>vector of probabilities corresponding to <code>x1</code>.
</p>
</td></tr>
<tr><td><code id="conv_+3A_x2">x2</code></td>
<td>

<p>support vector of the second distribution, with strictly increasing elements.
</p>
</td></tr>
<tr><td><code id="conv_+3A_p2">p2</code></td>
<td>
<p>vector of probabilities corresponding to <code>x2</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The convolution is performed in C, looping through all paired sums, 
augmenting existing values or inserting them with an update of the 
corresponding probabilities.
</p>


<h3>Value</h3>

<p>A matrix with first column the new support vector and the second column the 
corresponding probability vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- c(1,2,3.5)
p1 &lt;- c(.2,.3,.5)
x2 &lt;- c(0,2.3,3,4)
p2 &lt;- c(.1,.3,.3,.3)


conv(x1,p1,x2,p2)
</code></pre>

<hr>
<h2 id='JT.dist'>
Null Distribution of the 
Jonckheere-Terpstra k-Sample Test Statistic
</h2><span id='topic+djt'></span><span id='topic+pjt'></span><span id='topic+qjt'></span>

<h3>Description</h3>

<p>The
Jonckheere-Terpstra k-sample test statistic JT is defined
as <code class="reqn">JT = \sum_{i&lt;j} W_{ij}</code> where
<code class="reqn">W_{ij}</code> is the Mann-Whitney statistic comparing 
samples <code class="reqn">i</code> and <code class="reqn">j</code>, indexed in the order 
of the stipulated increasing alternative. 
It is assumed that there are no ties
in the pooled samples.
</p>
<p>This function uses Harding's algorithm as far as computations
are possible without becoming unstable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>djt(x, nn)

pjt(x, nn)

qjt(p, nn)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="JT.dist_+3A_x">x</code></td>
<td>
<p>a numeric vector, typically integers</p>
</td></tr>
<tr><td><code id="JT.dist_+3A_nn">nn</code></td>
<td>
<p>a vector of integers, representing the sample sizes
in the order stipulated by the alternative</p>
</td></tr>
<tr><td><code id="JT.dist_+3A_p">p</code></td>
<td>
<p>a vector of probabilities</p>
</td></tr>
</table>


<h3>Details</h3>

<p>While Harding's algorithm is mathematically correct, 
it is problematic in its computing implementation. 
The counts become very large and normalizing 
them by combinatorials leads to significance loss. 
When that happens the functions return an error message: 
can't compute due to numerical instability.
This tends to happen when the total number of sample values 
becomes too large.
That depends also on the way the sample sizes are allocated. 
</p>


<h3>Value</h3>

<p>For <code>djt</code> it is a vector 
<code class="reqn">p = (p_1,\ldots,p_n)</code>
giving the values of 
<code class="reqn">p_i = P(JT = x_i)</code>, where <code>n</code> is the length
of the input <code>x</code>.
</p>
<p>For <code>pjt</code> it is a vector 
<code class="reqn">P = (P_1,\ldots,P_n)</code>
giving the values of 
<code class="reqn">P_i = P(JT \leq x_i)</code>.
</p>
<p>For <code>qjt</code> is a vecto r <code class="reqn">x = (x_1,\ldots,x_n)</code>,where <code class="reqn">x_i</code>
is the smallest <code class="reqn">x</code>
such that <code class="reqn">P(JT \leq x) \geq p_i</code>.
</p>


<h3>References</h3>

<p>Harding, E.F. (1984), An Efficient, Minimal-storage Procedure for
Calculating the Mann-Whitney U, Generalized U and Similar Distributions,
<em>Appl. Statist.</em> <b>33</b> No. 1, 1-6.
</p>
<p>Jonckheere, A.R. (1954), A Distribution Free <em>k</em>-sample Test against Ordered 
Alternatives,
<em>Biometrika</em>, <b>41</b>, 133-145.
</p>
<p>Lehmann, E.L. (2006),
<em>Nonparametrics, Statistical Methods Based on Ranks, Revised First Edition</em>,
Springer Verlag.
</p>
<p>Terpstra, T.J. (1952), The Asymptotic Normality and Consistency of Kendall's Test against Trend, when Ties are Present in One Ranking,
<em>Indagationes Math.</em> <b>14</b>, 327-333.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>djt(c(-1.5,1.2,3), 2:4)
pjt(c(2,3.4,7), 3:5)
qjt(c(0,.2,.5), 2:4)
</code></pre>

<hr>
<h2 id='jt.test'>
Jonckheere-Terpstra k-Sample Test for Increasing Alternatives
</h2><span id='topic+jt.test'></span>

<h3>Description</h3>

<p>The
Jonckheere-Terpstra k-sample test statistic JT is defined
as <code class="reqn">JT = \sum_{i&lt;j} W_{ij}</code> where
<code class="reqn">W_{ij}</code> is the Mann-Whitney statistic comparing 
samples <code class="reqn">i</code> and <code class="reqn">j</code>, indexed in the order 
of the stipulated increasing alternative. 
There may be ties in the pooled samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jt.test(..., data = NULL, method=c("asymptotic","simulated","exact"),
		dist = FALSE, Nsim = 10000) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jt.test_+3A_...">...</code></td>
<td>

<p>Either several sample vectors, say 
<code class="reqn">x_1, \ldots, x_k</code>, 
with <code class="reqn">x_i</code> containing <code class="reqn">n_i</code> sample values.
<code class="reqn">n_i &gt; 4</code> is recommended for reasonable asymptotic 
<code class="reqn">P</code>-value calculation. The pooled sample size is denoted 
by <code class="reqn">N=n_1+\ldots+n_k</code>. The order of samples should be
as stipulated under the alternative
</p>
<p>or a list of such sample vectors,
</p>
<p>or a formula y ~ g, where y contains the pooled sample values 
and g (same length as y) is a factor with levels identifying 
the samples to which the elements of y belong, the factor levels
reflecting the order under the stipulated alternative,
</p>
</td></tr>
<tr><td><code id="jt.test_+3A_data">data</code></td>
<td>
<p>= an optional data frame providing the variables in formula y ~ g.
</p>
</td></tr>
<tr><td><code id="jt.test_+3A_method">method</code></td>
<td>
<p>= <code>c("asymptotic","simulated","exact")</code>, where
</p>
<p><code>"asymptotic"</code> uses only an asymptotic normal <code class="reqn">P</code>-value approximation.
</p>
<p><code>"simulated"</code> uses <code>Nsim</code> simulated <code class="reqn">JT</code> statistics based on random splits of the 
pooled samples into samples of sizes 
<code class="reqn">n_1, \ldots, n_k</code>, to estimate the <code class="reqn">P</code>-value.
</p>
<p><code>"exact"</code> uses full enumeration of all sample splits with 
resulting <code class="reqn">JT</code> statistics to obtain the exact <code class="reqn">P</code>-value. 
It is used only when <code>Nsim</code> is at least as large as the number
</p>
<p style="text-align: center;"><code class="reqn">ncomb = \frac{N!}{n_1!\ldots n_k!}</code>
</p>

<p>of full enumerations. Otherwise, <code>method</code>
reverts to <code>"simulated"</code> using the given <code>Nsim</code>. It also reverts
to <code>"simulated"</code> when <code class="reqn">ncomb &gt; 1e8</code> and <code>dist = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="jt.test_+3A_dist">dist</code></td>
<td>
<p><code>= FALSE</code> (default) or <code>TRUE</code>. If <code>TRUE</code>, the 
simulated or fully enumerated distribution vector <code>null.dist</code>
is returned for the JT test statistic. Otherwise, <code>NULL</code> is returned. 
When <code>dist = TRUE</code> then <code>Nsim &lt;- min(Nsim, 1e8)</code>, 
to limit object size.
</p>
</td></tr>
<tr><td><code id="jt.test_+3A_nsim">Nsim</code></td>
<td>
<p><code>= 10000</code> (default), number of simulation sample splits to use.	
It is only used when <code>method = "simulated"</code>,
or when <code>method = "exact"</code> reverts to <code>method =</code>
<code> "simulated"</code>, as previously explained.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The JT statistic 
is used to test the hypothesis that the samples all come 
from the same but unspecified continuous distribution function <code class="reqn">F(x)</code>.
It is specifically aimed at alternatives where the sampled distributions
are stochastically increasing.
</p>
<p>NA values are removed and the user is alerted with the total NA count.
It is up to the user to judge whether the removal of NA's is appropriate.
</p>
<p>The continuity assumption can be dispensed with, if we deal with 
independent random samples, or if randomization was used in allocating
subjects to samples or treatments, and if we view
the simulated or exact <code class="reqn">P</code>-values conditionally, given the tie pattern
in the pooled samples. Of course, under such randomization any conclusions 
are valid only with respect to the group of subjects that were randomly allocated
to their respective samples.
The asymptotic <code class="reqn">P</code>-value calculation is valid provided all sample sizes become large.
</p>


<h3>Value</h3>

<p>A list of class <code>kSamples</code> with components 
</p>
<table>
<tr><td><code>test.name</code></td>
<td>
<p><code>"Jonckheere-Terpstra"</code></p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>number of samples being compared</p>
</td></tr>
<tr><td><code>ns</code></td>
<td>
<p>vector <code class="reqn">(n_1,\ldots,n_k)</code> of the <code class="reqn">k</code> sample sizes</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>size of the pooled sample <code class="reqn">= n_1+\ldots+n_k</code></p>
</td></tr>
<tr><td><code>n.ties</code></td>
<td>
<p>number of ties in the pooled sample</p>
</td></tr>
<tr><td><code>qn</code></td>
<td>
<p>4 (or 5) vector containing the observed <code class="reqn">JT</code>, its mean and standard deviation
and its asymptotic <code class="reqn">P</code>-value, 
(and its simulated or exact <code class="reqn">P</code>-value)</p>
</td></tr>
<tr><td><code>warning</code></td>
<td>
<p>logical indicator, <code>warning = TRUE</code> when at least one 
<code class="reqn">n_i &lt; 5</code></p>
</td></tr>
<tr><td><code>null.dist</code></td>
<td>
<p>simulated or enumerated null distribution 
of the test statistic. It is <code>NULL</code> when <code>dist = FALSE</code> or when
<code>method = "asymptotic"</code>.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the <code>method</code> used.</p>
</td></tr>
<tr><td><code>Nsim</code></td>
<td>
<p>the number of simulations used.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Harding, E.F. (1984), An Efficient, Minimal-storage Procedure for
Calculating the Mann-Whitney U, Generalized U and Similar Distributions,
<em>Appl. Statist.</em> <b>33</b> No. 1, 1-6.
</p>
<p>Jonckheere, A.R. (1954), A Distribution Free <em>k</em>-sample Test against Ordered 
Alternatives,
<em>Biometrika</em>, <b>41</b>, 133-145.
</p>
<p>Lehmann, E.L. (2006),
<em>Nonparametrics, Statistical Methods Based on Ranks, Revised First Edition</em>,
Springer Verlag.
</p>
<p>Terpstra, T.J. (1952), The Asymptotic Normality and Consistency of Kendall's Test against Trend, when Ties are Present in One Ranking,
<em>Indagationes Math.</em> <b>14</b>, 327-333.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- c(1,2)
x2 &lt;- c(1.5,2.1)
x3 &lt;- c(1.9,3.1)
yy &lt;- c(x1,x2,x3)
gg &lt;- as.factor(c(1,1,2,2,3,3))
jt.test(x1, x2, x3,method="exact",Nsim=90)
# or 
# jt.test(list(x1, x2, x3), method = "exact", Nsim = 90)
# or
# jt.test(yy ~ gg, method = "exact", Nsim = 90)
</code></pre>

<hr>
<h2 id='pp.kSamples'>
Upper Tail Probability Plots for Objects of Class kSamples
</h2><span id='topic+pp.kSamples'></span>

<h3>Description</h3>

<p>This function plots upper tail probabilities of the limiting distribution 
against the corresponding exact or simulated probabilities, both on a log-scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pp.kSamples(x) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pp.kSamples_+3A_x">x</code></td>
<td>
<p>an object of class <code>kSamples</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Objects of class <code>kSamples</code> are produced by any of the following functions
</p>
<p><code><a href="#topic+ad.test">ad.test</a></code> Anderson-Darling k-sample test.
</p>
<p><code><a href="#topic+ad.test.combined">ad.test.combined</a></code> Combined Anderson-Darling k-sample tests.
</p>
<p><code><a href="#topic+qn.test">qn.test</a></code> <code class="reqn">QN</code> rank scores test.
</p>
<p><code><a href="#topic+qn.test.combined">qn.test.combined</a></code> Combined <code class="reqn">QN</code> rank scores tests.
</p>
<p><code><a href="#topic+contingency2xt">contingency2xt</a></code> test for <code class="reqn">2 * t</code> contingency table.
</p>
<p><code><a href="#topic+contingency2xt.comb">contingency2xt.comb</a></code> test for the combination of <code class="reqn">2 * t</code> contingency tables.
</p>
<p><code><a href="#topic+jt.test">jt.test</a></code> Jonckheere-Terpstra test.
</p>
<p><code><a href="#topic+Steel.test">Steel.test</a></code> Steel test. This will work only for alternative = &quot;greater&quot; or &quot;two-sided&quot;.
The approximation quality for &quot;less&quot; is the same as for &quot;greater&quot;.
</p>
<p>The command <code>pp.kSamples(x)</code> for an object of class <code>kSamples</code>
will only produce a plot when the object <code>x</code> contains 
non-NULL entries for the null distribution. The purpose of this function is to give the user
a sense of the asymptotic distribution accuracy.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ad.test">ad.test</a></code>,
<code><a href="#topic+ad.test.combined">ad.test.combined</a></code>,
<code><a href="#topic+qn.test">qn.test</a></code>,
<code><a href="#topic+qn.test.combined">qn.test.combined</a></code>,
</p>
<p><code><a href="#topic+contingency2xt">contingency2xt</a></code>,
<code><a href="#topic+contingency2xt.comb">contingency2xt.comb</a></code>
<code><a href="#topic+jt.test">jt.test</a></code>
<code><a href="#topic+Steel.test">Steel.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>qn.out &lt;- qn.test(c(1,3,7,2,9),c(1,4,6,11,2),test="KW",
		method="simulated",dist=TRUE,Nsim=1000) 
pp.kSamples(qn.out)
</code></pre>

<hr>
<h2 id='qn.test'>
Rank Score k-Sample Tests
</h2><span id='topic+qn.test'></span>

<h3>Description</h3>

<p>This function uses the <code class="reqn">QN</code> criterion (Kruskal-Wallis, van der Waerden scores, normal scores) to test
the hypothesis that <code class="reqn">k</code> independent samples arise
from a common unspecified distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qn.test(..., data = NULL, test = c("KW", "vdW", "NS"), 
	method = c("asymptotic", "simulated", "exact"),
	dist = FALSE, Nsim = 10000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qn.test_+3A_...">...</code></td>
<td>

<p>Either several sample vectors, say 
<code class="reqn">x_1, \ldots, x_k</code>, 
with <code class="reqn">x_i</code> containing <code class="reqn">n_i</code> sample values.
<code class="reqn">n_i &gt; 4</code> is recommended for reasonable asymptotic 
<code class="reqn">P</code>-value calculation. The pooled sample size is denoted 
by <code class="reqn">N=n_1+\ldots+n_k</code>,
</p>
<p>or a list of such sample vectors,
</p>
<p>or a formula y ~ g, where y contains the pooled sample values 
and g (same length as y) is a factor with levels identifying 
the samples to which the elements of y belong. 
</p>
</td></tr>
<tr><td><code id="qn.test_+3A_data">data</code></td>
<td>
<p>= an optional data frame providing the variables in formula y ~ g.
</p>
</td></tr>
<tr><td><code id="qn.test_+3A_test">test</code></td>
<td>
<p>= <code>c("KW", "vdW", "NS")</code>, where
</p>
<p><code>"KW"</code> uses scores <code>1:N</code> (Kruskal-Wallis test)
</p>
<p><code>"vdW"</code> uses van der Waerden scores, <code>qnorm( (1:N) / (N+1) )</code>
</p>
<p><code>"NS"</code> uses normal scores, i.e., expected standard normal order statistics,
invoking function <code>normOrder</code> of <code>package SuppDists (&gt;=1.1-9.4)</code>
</p>
</td></tr>
<tr><td><code id="qn.test_+3A_method">method</code></td>
<td>
<p>= <code>c("asymptotic","simulated","exact")</code>, where
</p>
<p><code>"asymptotic"</code> uses only an asymptotic chi-square approximation 
with <code>k-1</code> degrees of freedom to approximate the <code class="reqn">P</code>-value. 
This calculation is always done.
</p>
<p><code>"simulated"</code> uses <code>Nsim</code> simulated <code class="reqn">QN</code> statistics based on random 
splits of the pooled samples into samples of sizes 
<code class="reqn">n_1, \ldots, n_k</code>, to estimate the <code class="reqn">P</code>-value.
</p>
<p><code>"exact"</code> uses full enumeration of all sample splits with resulting 
<code class="reqn">QN</code> statistics to obtain the exact <code class="reqn">P</code>-value. 
It is used only when <code>Nsim</code> is at least as large as the number
</p>
<p style="text-align: center;"><code class="reqn">ncomb = \frac{N!}{n_1!\ldots n_k!}</code>
</p>
<p> of
full enumerations. Otherwise, <code>method</code>
reverts to <code>"simulated"</code> using the given <code>Nsim</code>. It also reverts
to <code>"simulated"</code> when <code class="reqn">ncomb &gt; 1e8</code> and <code>dist = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="qn.test_+3A_dist">dist</code></td>
<td>
<p><code>FALSE</code> (default) or <code>TRUE</code>. If <code>TRUE</code>, the 
simulated or fully enumerated null distribution vector <code>null.dist</code> 
is returned for the <code class="reqn">QN</code> test statistic. Otherwise, <code>NULL</code> 
is returned. When <code>dist = TRUE</code> then <code>Nsim &lt;- min(Nsim, 1e8)</code>, 
to limit object size.
</p>
</td></tr>
<tr><td><code id="qn.test_+3A_nsim">Nsim</code></td>
<td>
<p><code>= 10000</code> (default), number of simulation sample splits to use.	
It is only used when <code>method = "simulated"</code>,
or when <code>method = "exact"</code> reverts to <code>method =</code>
<code> "simulated"</code>, as previously explained.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">QN</code> criterion based on rank scores <code class="reqn">v_1,\ldots,v_N</code> is
</p>
<p style="text-align: center;"><code class="reqn">QN=\frac{1}{s_v^2}\left(\sum_{i=1}^k \frac{(S_{iN}-n_i \bar{v}_{N})^2}{n_i}\right)</code>
</p>

<p>where <code class="reqn">S_{iN}</code> is the sum of rank scores for the <code class="reqn">i</code>-th sample and 
<code class="reqn">\bar{v}_N</code> and 
<code class="reqn">s_v^2</code> are sample mean and sample variance (denominator <code class="reqn">N-1</code>)
of all scores.
</p>
<p>The statistic <code class="reqn">QN</code> is used to test the hypothesis that the samples all come 
from the same but unspecified continuous distribution function <code class="reqn">F(x)</code>.
<code class="reqn">QN</code> is always adjusted for ties by averaging the scores of tied observations.
</p>
<p>Conditions for the asymptotic approximation (chi-square  with <code class="reqn">k-1</code> degrees of freedom)  
can be found in Lehmann, E.L. (2006), Appendix Corollary 10, or in 
Hajek, Sidak, and Sen (1999), Ch. 6, problems 13 and 14.
</p>
<p>For small sample sizes exact null distribution
calculations are possible (with or without ties), based on a recursively extended
version of Algorithm C (Chase's sequence) in Knuth (2011), which allows the 
enumeration of all possible splits of the pooled data into samples of
sizes of <code class="reqn">n_1, \ldots, n_k</code>, as appropriate under treatment randomization. This 
is done in C, as is the simulation.
</p>
<p>NA values are removed and the user is alerted with the total NA count.
It is up to the user to judge whether the removal of NA's is appropriate.
</p>
<p>The continuity assumption can be dispensed with, if we deal with 
independent random samples from any common distribution, 
or if randomization was used in allocating
subjects to samples or treatments, and if 
the asymptotic, simulated or exact <code class="reqn">P</code>-values are viewed conditionally, given the tie pattern
in the pooled sample. Under such randomization any conclusions 
are valid only with respect to the subjects that were randomly allocated
to their respective treatment samples.
</p>


<h3>Value</h3>

<p>A list of class <code>kSamples</code> with components 
</p>
<table>
<tr><td><code>test.name</code></td>
<td>
<p><code>"Kruskal-Wallis"</code>, <code>"van der Waerden scores"</code>, or
</p>
<p><code>"normal scores"</code></p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>number of samples being compared</p>
</td></tr>
<tr><td><code>ns</code></td>
<td>
<p>vector <code class="reqn">(n_1,\ldots,n_k)</code> of the <code class="reqn">k</code> sample sizes</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>size of the pooled samples <code class="reqn">= n_1+\ldots+n_k</code></p>
</td></tr>
<tr><td><code>n.ties</code></td>
<td>
<p>number of ties in the pooled sample</p>
</td></tr>
<tr><td><code>qn</code></td>
<td>
<p>2 (or 3) vector containing the observed <code class="reqn">QN</code>, its asymptotic <code class="reqn">P</code>-value, 
(its simulated or exact <code class="reqn">P</code>-value)</p>
</td></tr>
<tr><td><code>warning</code></td>
<td>
<p>logical indicator, <code>warning = TRUE</code> when at least one 
<code class="reqn">n_i &lt; 5</code></p>
</td></tr>
<tr><td><code>null.dist</code></td>
<td>
<p>simulated or enumerated null distribution 
of the test statistic. It is <code>NULL</code> when <code>dist = FALSE</code> or when
<code>method = "asymptotic"</code>.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the <code>method</code> used.</p>
</td></tr>
<tr><td><code>Nsim</code></td>
<td>
<p>the number of simulations used.</p>
</td></tr>
</table>


<h3>warning</h3>

<p><code>method = "exact"</code> should only be used with caution.
Computation time is proportional to the number of enumerations. 
Experiment with <code><a href="base.html#topic+system.time">system.time</a></code> and trial values for
<code>Nsim</code> to get a sense of the required computing time.
In most cases
<code>dist = TRUE</code> should not be used, i.e.,  
when the returned distribution objects 
become too large for R's work space.</p>


<h3>References</h3>

<p>Hajek, J., Sidak, Z., and Sen, P.K. (1999), <em>Theory of Rank Tests (Second Edition)</em>, Academic Press.
</p>
<p>Knuth, D.E. (2011), <em>The Art of Computer Programming, Volume 4A 
Combinatorial Algorithms Part 1</em>, Addison-Wesley
</p>
<p>Kruskal, W.H. (1952), A Nonparametric Test for the Several Sample Problem,
<em>The Annals of Mathematical Statistics</em>,
<b>Vol 23, No. 4</b>, 525-540
</p>
<p>Kruskal, W.H. and Wallis, W.A. (1952), Use of Ranks in One-Criterion Variance Analysis,
<em>Journal of the American Statistical Association</em>, 
<b>Vol 47, No. 260</b>, 583&ndash;621. 
</p>
<p>Lehmann, E.L. (2006),
<em>Nonparametrics, Statistical Methods Based on Ranks, Revised First Edition</em>,
Springer Verlag.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qn.test.combined">qn.test.combined</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>u1 &lt;- c(1.0066, -0.9587,  0.3462, -0.2653, -1.3872)
u2 &lt;- c(0.1005, 0.2252, 0.4810, 0.6992, 1.9289)
u3 &lt;- c(-0.7019, -0.4083, -0.9936, -0.5439, -0.3921)
yy &lt;- c(u1, u2, u3)
gy &lt;- as.factor(c(rep(1,5), rep(2,5), rep(3,5)))
set.seed(2627)
qn.test(u1, u2, u3, test="KW", method = "simulated", 
  dist = FALSE, Nsim = 1000)
# or with same seed
# qn.test(list(u1, u2, u3),test = "KW", method = "simulated", 
#  dist = FALSE, Nsim = 1000)
# or with same seed
# qn.test(yy ~ gy, test = "KW", method = "simulated", 
#  dist = FALSE, Nsim = 1000)
</code></pre>

<hr>
<h2 id='qn.test.combined'>
Combined Rank Score k-Sample Tests
</h2><span id='topic+qn.test.combined'></span>

<h3>Description</h3>

<p>This function combines several independent rank score <code class="reqn">k</code>-sample tests
into one overall test of the hypothesis that the independent samples within 
each block come from a common unspecified distribution, while the common
distributions may vary from block to block.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qn.test.combined(..., data = NULL, test = c("KW", "vdW", "NS"),
	method = c("asymptotic", "simulated", "exact"),
	dist = FALSE, Nsim = 10000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qn.test.combined_+3A_...">...</code></td>
<td>

<p>Either a sequence of several lists, say <code class="reqn">L_1, \ldots, L_M</code> (<code class="reqn">M &gt; 1</code>)
where list <code class="reqn">L_i</code> contains <code class="reqn">k_i &gt; 1</code>  sample vectors of respective 
sizes <code class="reqn">n_{i1}, \ldots, n_{ik_i}</code>, 
where <code class="reqn">n_{ij} &gt; 4</code> is recommended
for reasonable asymptotic <code class="reqn">P</code>-value calculation. 
<code class="reqn">N_i=n_{i1}+\ldots+n_{ik_i}</code>
is the pooled sample size for block <code class="reqn">i</code>,
</p>
<p>or a list of such lists,
</p>
<p>or a formula, like y ~ g | b, where y is a numeric response vector,
g is a factor with levels indicating different treatments and
b is a factor indicating different blocks; y, g, b have same length. 
y is split separately for each block level into separate samples 
according to the g levels. The same g level may occur in different 
blocks. The variable names may correspond to variables in an optionally 
supplied data frame via the data = argument.
</p>
</td></tr>
<tr><td><code id="qn.test.combined_+3A_data">data</code></td>
<td>
<p>= an optional data frame providing the variables in formula input
</p>
</td></tr>
<tr><td><code id="qn.test.combined_+3A_test">test</code></td>
<td>
<p>= <code>c("KW", "vdW", "NS")</code>, 
</p>
<p>where <code>"KW"</code> uses scores <code>1:N</code> (Kruskal-Wallis test)
</p>
<p><code>"vdW"</code> uses van der Waerden scores, <code>qnorm( (1:N) / (N+1) )</code>
</p>
<p><code>"NS"</code> uses normal scores, i.e., expected values of 
standard normal order statistics,
invoking function <code>normOrder</code> of <code>package SuppDists (&gt;=1.1-9.4)</code>
</p>
<p>For the above scores <code class="reqn">N</code> changes from block to block and represents the total 
pooled sample size <code class="reqn">N_i</code> for block <code class="reqn">i</code>. 
</p>
</td></tr>
<tr><td><code id="qn.test.combined_+3A_method">method</code></td>
<td>
<p>=<code>c("asymptotic","simulated","exact")</code>, where
</p>
<p><code>"asymptotic"</code> uses only an asymptotic chi-square approximation for the  <code class="reqn">P</code>-value.
The adequacy of asymptotic <code class="reqn">P</code>-values for use with moderate sample sizes
may be checked with <code>method = "simulated"</code>.
</p>
<p><code>"simulated"</code> uses simulation to get <code>Nsim</code> simulated <code class="reqn">QN</code> statistics for each
block of samples, adding them component wise across blocks to get <code>Nsim</code> 
combined values, and compares these with the observed combined value to 
get the estimated <code class="reqn">P</code>-value.
</p>
<p><code>"exact"</code> uses full enumeration of the test statistic value 
for all sample splits of the pooled samples within each block.
The test statistic vectors for each block are added 
(each component against each component, as in the R <code>outer(x,y,</code> <code>"+")</code> command) 
to get the convolution enumeration for the combined test statistic.
This &quot;addition&quot; is done one block at a time. 
It is possible only for small problems, and is attempted only when <code>Nsim</code>
is at least the (conservatively maximal) length 
</p>
<p style="text-align: center;"><code class="reqn">\frac{N_1!}{n_{11}!\ldots n_{1k_1}!}\times\ldots\times \frac{N_M!}{n_{M1}!\ldots n_{Mk_M}!}</code>
</p>

<p>of the final distribution vector, were <code class="reqn">N_i = n_{i1}+\ldots+n_{ik_i}</code> 
is the sample size of the pooled samples for the i-th block. Otherwise, it reverts to the 
simulation method using the provided <code>Nsim</code>.
</p>
</td></tr>
<tr><td><code id="qn.test.combined_+3A_dist">dist</code></td>
<td>
<p><code>FALSE</code> (default) or <code>TRUE</code>. If <code>TRUE</code>, the 
simulated or fully enumerated convolution vector <code>null.dist</code> is returned for the 
<code class="reqn">QN</code> test statistic. 
</p>
<p>Otherwise, <code>NULL</code> is returned.
</p>
</td></tr>
<tr><td><code id="qn.test.combined_+3A_nsim">Nsim</code></td>
<td>
<p><code>= 10000</code> (default), number of simulation splits to use within 
each block of samples. It is only used when <code>method =</code> <code>"simulated"</code>
or when <code>method =</code> <code>"exact"</code> reverts to <code>method =</code> <code>"simulated"</code>, 
as previously explained.
Simulations are independent across blocks, using <code>Nsim</code> for each block.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The rank score <code class="reqn">QN</code> criterion <code class="reqn">QN_i</code> for the <code class="reqn">i</code>-th block of 
<code class="reqn">k_i</code> samples, 
is used to test the hypothesis that the samples in the <code class="reqn">i</code>-th block all come 
from the same but unspecified continuous distribution function <code class="reqn">F_i(x)</code>.
See <code><a href="#topic+qn.test">qn.test</a></code> for the definition of the <code class="reqn">QN</code> criterion
and the exact calculation of its null distribution.
</p>
<p>The combined <code class="reqn">QN</code> criterion <code class="reqn">QN_{\rm comb} = QN_1 + \ldots + QN_M</code>
is used to simultaneously test whether the samples 
in block i come from the same continuous distribution function <code class="reqn">F_i(x)</code>. 
However, the unspecified common distribution function <code class="reqn">F_i(x)</code> may change 
from block to block. 
</p>
<p>The <code class="reqn">k</code> for each block of <code class="reqn">k</code>
independent samples may change from block to block.
</p>
<p>The asymptotic approximating chi-square distribution has 
<code class="reqn">f = (k_1-1)+\ldots+(k_M-1)</code> degrees of freedom.
</p>
<p>NA values are removed and the user is alerted with the total NA count.
It is up to the user to judge whether the removal of NA's is appropriate.
</p>
<p>The continuity assumption can be dispensed with if we deal with 
independent random samples, or if randomization was used in allocating
subjects to samples or treatments, independently from block to block, and if
the asymptotic, simulated or exact <code class="reqn">P</code>-values are viewed conditionally, given the tie patterns
within each block. Under such randomization any conclusions 
are valid only with respect to the blocks of subjects that were randomly allocated.
In case of ties the average rank scores are used across tied observations within each block.
</p>


<h3>Value</h3>

<p>A list of class <code>kSamples</code> with components 
</p>
<table>
<tr><td><code>test.name</code></td>
<td>
<p><code>"Kruskal-Wallis"</code>, <code>"van der Waerden scores"</code>, or
</p>
<p><code>"normal scores"</code></p>
</td></tr>
<tr><td><code>M</code></td>
<td>
<p>number of blocks of samples being compared</p>
</td></tr>
<tr><td><code>n.samples</code></td>
<td>
<p>list of <code>M</code> vectors, each vector giving the sample sizes for 
each block of samples being compared</p>
</td></tr>
<tr><td><code>nt</code></td>
<td>
<p>vector of length <code>M</code> of total sample sizes involved in each of the 
<code>M</code> comparisons of <code class="reqn">k_i</code> samples, respectively</p>
</td></tr>
<tr><td><code>n.ties</code></td>
<td>
<p>vector giving the number of ties in each the <code>M</code>
comparison blocks</p>
</td></tr>
<tr><td><code>qn.list</code></td>
<td>
<p>list of <code>M</code> matrices giving the <code>qn</code> results 
from <code>qn.test</code>, applied to the samples in each of
the <code>M</code> blocks</p>
</td></tr>
<tr><td><code>qn.c</code></td>
<td>
<p>2 (or 3) vector containing the observed 
<code class="reqn">QN_{\rm comb}</code>, asymptotic <code class="reqn">P</code>-value, 
(simulated or exact <code class="reqn">P</code>-value).</p>
</td></tr>
<tr><td><code>warning</code></td>
<td>
<p>logical indicator, <code>warning = TRUE</code> when at least one 
<code class="reqn">n_{ij} &lt; 5</code>.</p>
</td></tr>
<tr><td><code>null.dist</code></td>
<td>
<p>simulated or enumerated null distribution of the 
<code class="reqn">QN_{\rm comb}</code> statistic.
It is <code>NULL</code> when <code>dist = FALSE</code> or when <code>method = "asymptotic"</code>.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>The <code>method</code> used.</p>
</td></tr>
<tr><td><code>Nsim</code></td>
<td>
<p>The number of simulations used for each block of samples.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>These tests are useful in analyzing treatment effects of shift nature in randomized 
(incomplete) block experiments.
</p>


<h3>References</h3>

<p>Lehmann, E.L. (2006), <em>Nonparametric, Statistical Methods Based on Ranks</em>, Springer Verlag, New York. Ch. 6, Sec. 5D.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qn.test">qn.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create two lists of sample vectors.
x1 &lt;- list( c(1, 3, 2, 5, 7), c(2, 8, 1, 6, 9, 4), c(12, 5, 7, 9, 11) )
x2 &lt;- list( c(51, 43, 31, 53, 21, 75), c(23, 45, 61, 17, 60) )
# and a corresponding data frame datx1x2
x1x2 &lt;- c(unlist(x1),unlist(x2))
gx1x2 &lt;- as.factor(c(rep(1,5),rep(2,6),rep(3,5),rep(1,6),rep(2,5)))
bx1x2 &lt;- as.factor(c(rep(1,16),rep(2,11)))
datx1x2 &lt;- data.frame(A = x1x2, G = gx1x2, B = bx1x2)

## Run qn.test.combined.
set.seed(2627)
qn.test.combined(x1, x2, method = "simulated", Nsim = 1000) 
# or with same seed
# qn.test.combined(list(x1, x2), method = "simulated", Nsim = 1000)
# or qn.test.combined(A~G|B,data=datx1x2,method="simulated",Nsim=1000)
</code></pre>

<hr>
<h2 id='ShorelineFireEMS'>
Shoreline Fire and EMS Turnout Times
</h2><span id='topic+ShorelineFireEMS'></span>

<h3>Description</h3>

<p>This data set gives turnout response times for Fire and EMS (Emergency Medical Services) 
dispatch calls to the Shoreline, WA, Fire Department in 2006. The turnout time refers to 
time elapsed between the emergency call dispatch and the crew leaving the fire station,
or signaling that they are on their way while being on route already. The latter scenario
may explain the bimodal distribution character.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ShorelineFireEMS)
</code></pre>


<h3>Format</h3>

<p>A list of two sublists <code>$EMSTOT</code> and <code>$FireTOT</code>, 
each with 4 vector components <code>$ST57</code>, <code>$ST63</code>, <code>$ST64</code>, and
<code>$ST65</code> respectively, giving the turnout times (in seconds) (for EMS and Fire)
at fire stations ST57, ST63, ST64, and ST65.
</p>


<h3>Note</h3>

<p>These data sets are provided to illustrate usage of <code>ad.test</code> and <code>qn.test</code> 
and their combined versions in testing for performance equivalence across fire stations.
</p>


<h3>Source</h3>

<p>Thanks to Michael Henderson and the Fire Fighters
and Paramedics of the Shoreline Fire Department in Washington State.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ShorelineFireEMS)
boxplot(ShorelineFireEMS$EMSTOT,xlab="Station", ylab="seconds",
	main="EMS Turnout Time")
boxplot(ShorelineFireEMS$FireTOT,xlab="Station", ylab="seconds",
	main="Fire Turnout Time")
</code></pre>

<hr>
<h2 id='Steel.test'>
Steel's Multiple Comparison Wilcoxon Tests
</h2><span id='topic+Steel.test'></span>

<h3>Description</h3>

<p>This function uses pairwise Wilcoxon tests, comparing a common control sample with each of
several treatment samples, in a multiple comparison fashion. The experiment wise
significance probabity is calculated, estimated, or approximated, when
testing
the hypothesis that all independent samples arise
from a common unspecified distribution, or that treatments have no effect when assigned
randomly to the given subjects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Steel.test(..., data = NULL, 
	method = c("asymptotic", "simulated", "exact"),
	alternative = c("greater","less","two-sided"),
	dist = FALSE, Nsim = 10000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Steel.test_+3A_...">...</code></td>
<td>

<p>Either several sample vectors, say 
<code class="reqn">x_1, \ldots, x_k</code>, 
with <code class="reqn">x_i</code> containing <code class="reqn">n_i</code> sample values.
<code class="reqn">n_i &gt; 4</code> is recommended for reasonable asymptotic 
<code class="reqn">P</code>-value calculation. The pooled sample size is denoted 
by <code class="reqn">N=n_1+\ldots+n_k</code>. The first vector serves as control sample,
the others as treatment samples.
</p>
<p>or a list of such sample vectors.
</p>
<p>or a formula y ~ g, where y contains the pooled sample values 
and g (same length as y) is a factor with levels identifying 
the samples to which the elements of y belong. The lowest factor level
corresponds to the control sample, the other levels to treatment samples.
</p>
</td></tr>
<tr><td><code id="Steel.test_+3A_data">data</code></td>
<td>
<p>= an optional data frame providing the variables in formula y ~ g or y, g input
</p>
</td></tr>
<tr><td><code id="Steel.test_+3A_method">method</code></td>
<td>
<p>= <code>c("asymptotic","simulated","exact")</code>, where
</p>
<p><code>"asymptotic"</code> uses only an asymptotic normal approximation 
to approximate the <code class="reqn">P</code>-value, This calculation is always done.
</p>
<p><code>"simulated"</code> uses <code>Nsim</code> simulated standardized
Steel statistics based on random splits of the 
pooled samples into samples of sizes 
<code class="reqn">n_1, \ldots, n_k</code>, to estimate the <code class="reqn">P</code>-value.
</p>
<p><code>"exact"</code> uses full enumeration of all sample splits with resulting 
standardized Steel statistics to obtain the exact <code class="reqn">P</code>-value. 
It is used only when <code>Nsim</code> is at least as large as the number
</p>
<p style="text-align: center;"><code class="reqn">ncomb = \frac{N!}{n_1!\ldots n_k!}</code>
</p>

<p>of full enumerations. Otherwise, <code>method</code> reverts to 
<code>"simulated"</code> using the given <code>Nsim</code>. It also reverts
to <code>"simulated"</code> when <code class="reqn">ncomb &gt; 1e8</code> and <code>dist = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="Steel.test_+3A_alternative">alternative</code></td>
<td>
<p>= <code>c("greater","less","two-sided")</code>, where for <code>"greater"</code> the 
maximum of the pairwise standardized Wilcoxon test statistics is used and 
a large maximum value is judged significant.
For <code>"less"</code> the minimum of the pairwise standardized Wilcoxon test 
statistics is used and a low minimum value is judged significant.
For <code>"two-sided"</code> the maximum of the absolute pairwise standardized Wilcoxon test 
statistics is used and a large maximum value is judged significant.
</p>
</td></tr>
<tr><td><code id="Steel.test_+3A_dist">dist</code></td>
<td>
<p><code>= FALSE</code> (default) or <code>TRUE</code>. If <code>TRUE</code>, the 
simulated or fully enumerated null distribution vector <code>null.dist</code> 
is returned for the Steel test statistic, as chosen via <code>alternative</code>.
Otherwise, <code>NULL</code> is returned. When <code>dist = TRUE</code> then 
<code>Nsim &lt;- min(Nsim, 1e8)</code>, to limit object size.
</p>
</td></tr>
<tr><td><code id="Steel.test_+3A_nsim">Nsim</code></td>
<td>
<p><code>= 10000</code> (default), number of simulation sample splits to use.	
It is only used when <code>method = "simulated"</code>,
or when <code>method = "exact"</code> reverts to <code>method =</code>
<code> "simulated"</code>, as previously explained.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Steel criterion uses the Wilcoxon test statistic in the pairwise comparisons of the 
common control sample with each of the treatment samples. These statistics are used in 
standardized form, using the means and standard deviations as they apply conditionally
given the tie pattern in the pooled data, see Scholz (2016). This conditional treatment allows for 
correct usage in the presence of ties and is appropriate either when the samples are independent
and come from the same distribution (continuous or not) or when treatments are assigned 
randomly among the total of <code>N</code> subjects. However, in the case of ties the significance probability
has to be viewed conditionally given the tie pattern.
</p>
<p>The Steel statistic is used to test the hypothesis that the samples all come 
from the same but unspecified distribution function <code class="reqn">F(x)</code>, or, under random treatment 
assigment, that the treatments have no effect. The significance probability is the probability
of obtaining test results as extreme or more extreme than the observed test statistic,
when testing for the possibility of a treatment effect under any of the treatments.
</p>
<p>For small sample sizes exact (conditional) null distribution
calculations are possible (with or without ties), based on a recursively extended
version of Algorithm C (Chase's sequence) in Knuth (2011), which allows the 
enumeration of all possible splits of the pooled data into samples of
sizes of <code class="reqn">n_1, \ldots, n_k</code>, as appropriate under treatment randomization. This 
is done in C, as is the simulation of such splits.
</p>
<p>NA values are removed and the user is alerted with the total NA count.
It is up to the user to judge whether the removal of NA's is appropriate.
</p>


<h3>Value</h3>

<p>A list of class <code>kSamples</code> with components 
</p>
<table>
<tr><td><code>test.name</code></td>
<td>
<p><code>"Steel"</code></p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p> &quot;greater&quot;, &quot;less&quot;, or &quot;two-sided&quot;</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>number of samples being compared, including the control sample as the first one</p>
</td></tr>
<tr><td><code>ns</code></td>
<td>
<p>vector <code class="reqn">(n_1,\ldots,n_k)</code> of the <code class="reqn">k</code> sample sizes</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>size of the pooled sample <code class="reqn">= n_1+\ldots+n_k</code></p>
</td></tr>
<tr><td><code>n.ties</code></td>
<td>
<p>number of ties in the pooled sample</p>
</td></tr>
<tr><td><code>st</code></td>
<td>
<p>2 (or 3) vector containing the observed standardized Steel statistic, 
its asymptotic <code class="reqn">P</code>-value, 
(its simulated or exact <code class="reqn">P</code>-value)</p>
</td></tr>
<tr><td><code>warning</code></td>
<td>
<p>logical indicator, <code>warning = TRUE</code> when at least one 
<code class="reqn">n_i &lt; 5</code>
</p>
</td></tr>
<tr><td><code>null.dist</code></td>
<td>
<p>simulated or enumerated null distribution vector
of the test statistic. It is <code>NULL</code> when <code>dist = FALSE</code> or when
<code>method = "asymptotic"</code>.
</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the <code>method</code> used.</p>
</td></tr>
<tr><td><code>Nsim</code></td>
<td>
<p>the number of simulations used.</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>vector 
<code class="reqn">(W_{12},\ldots, W_{1k})</code>
of Mann-Whitney statistics comparing each  observation under treatment <code class="reqn">i (&gt; 1)</code> 
against each observation of the control sample.
</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>mean vector <code class="reqn">(n_1n_2/2,\ldots,n_1n_k/2)</code> of <code>W</code>.</p>
</td></tr> 
<tr><td><code>tau</code></td>
<td>
<p>vector of standard deviations of <code>W</code>.</p>
</td></tr> 
<tr><td><code>sig0</code></td>
<td>
<p>standard deviation used in calculating the significance probability
of the maximum (minimum) of (absolute) standardized Mann-Whitney statistics, see Scholz (2016).</p>
</td></tr>
<tr><td><code>sig</code></td>
<td>
<p>vector 
<code class="reqn">(\sigma_1,\ldots, \sigma_k)</code>
of standard deviations used in calculating the significance probability
of the maximum (minimum) of (absolute)  standardized Mann-Whitney statistics, see Scholz (2016).</p>
</td></tr>
</table>


<h3>warning</h3>

<p><code>method = "exact"</code> should only be used with caution.
Computation time is proportional to the number of enumerations. 
Experiment with <code><a href="base.html#topic+system.time">system.time</a></code> and trial values for
<code>Nsim</code> to get a sense of the required computing time.
In most cases
<code>dist = TRUE</code> should not be used, i.e.,  
when the returned distribution objects 
become too large for R's work space.</p>


<h3>References</h3>

<p>Knuth, D.E. (2011), <em>The Art of Computer Programming, Volume 4A 
Combinatorial Algorithms Part 1</em>, Addison-Wesley
</p>
<p>Lehmann, E.L. (2006),
<em>Nonparametrics, Statistical Methods Based on Ranks, Revised First Edition</em>,
Springer Verlag.
</p>
<p>Scholz, F.W. (2023), &quot;On Steel's Test with Ties&quot;, <a href="https://arxiv.org/abs/2308.05873">https://arxiv.org/abs/2308.05873</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>z1 &lt;- c(103, 111, 136, 106, 122, 114)
z2 &lt;- c(119, 100,  97,  89, 112,  86)
z3 &lt;- c( 89, 132,  86, 114, 114, 125)
z4 &lt;- c( 92, 114,  86, 119, 131,  94)
y &lt;- c(z1, z2, z3, z4)
g &lt;- as.factor(c(rep(1, 6), rep(2, 6), rep(3, 6), rep(4, 6)))
set.seed(2627)
Steel.test(list(z1, z2, z3, z4), method = "simulated", 
  alternative = "less", Nsim = 1000)
# or with same seed
# Steel.test(z1, z2, z3, z4,method = "simulated", 
#   alternative = "less", Nsim = 1000)
# or with same seed
# Steel.test(y ~ g, method = "simulated", 
#   alternative = "less", Nsim=1000)
</code></pre>

<hr>
<h2 id='SteelConfInt'>
Simultaneous Confidence Bounds Based on Steel's Multiple Comparison Wilcoxon Tests
</h2><span id='topic+SteelConfInt'></span>

<h3>Description</h3>

<p>This function inverts pairwise Wilcoxon tests, comparing a common control sample with each of
several treatment samples to provide simultaneous confidence bounds
for the respective shift parameters by which the sampled treatment populations may differ
from the control population. It is assumed that all samples are independent 
and
that the sampled distributions are continuous to avoid ties.
The joint coverage probability for all bounds/intervals is calculated, estimated, or approximated, see
Details. For treatment of ties also see Details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SteelConfInt(..., data = NULL, conf.level = 0.95, 
	alternative = c("less", "greater", "two.sided"), 
     	method = c("asymptotic", "exact", "simulated"), Nsim = 10000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SteelConfInt_+3A_...">...</code></td>
<td>

<p>Either several sample vectors, say 
<code class="reqn">x_1, \ldots, x_k</code>, 
with <code class="reqn">x_i</code> containing <code class="reqn">n_i</code> sample values.
<code class="reqn">n_i &gt; 4</code> is recommended for reasonable asymptotic 
<code class="reqn">P</code>-value calculation. The pooled sample size is denoted 
by <code class="reqn">N=n_1+\ldots+n_k</code>. The first vector serves as control sample,
the others as treatment samples.
</p>
<p>or a list of such sample vectors.
</p>
<p>or a formula y ~ g, where y contains the pooled sample values 
and g (same length as y) is a factor with levels identifying 
the samples to which the elements of y belong. The lowest factor level
corresponds to the control sample, the other levels to treatment samples. 
</p>
</td></tr>
<tr><td><code id="SteelConfInt_+3A_data">data</code></td>
<td>
<p>= an optional data frame providing the variables in formula y ~ g.
</p>
</td></tr>
<tr><td><code id="SteelConfInt_+3A_conf.level">conf.level</code></td>
<td>
<p><code>= 0.95</code> (default) the target joint confidence level for all bounds/intervals.
</p>
<p><code>0 &lt; conf.level &lt; 1</code>.
</p>
</td></tr>
<tr><td><code id="SteelConfInt_+3A_alternative">alternative</code></td>
<td>
<p>= <code>c("less", "greater", "two.sided")</code>, where <code>"less"</code> results in
simultaneous upper confidence bounds for all shift parameters and any negative upper bound
should lead to the rejection of the null hypothesis of all shift parameters 
being zero or positive in favor of at least one being less than zero.
</p>
<p><code>"greater"</code> results in simultaneous lower confidence bounds for all shift parameters 
and any positive lower bound should lead to the rejection of the null hypothesis of all
shift parameters being zero or negative in favor of at least one being greater 
than zero.
</p>
<p><code>"two.sided"</code> results in simultaneous confidence intervals for all shift parameters 
and any interval not straddling zero should lead to the rejection of the null hypothesis 
of all shift parameters being zero in favor of at least one being different from zero.
</p>
</td></tr>
<tr><td><code id="SteelConfInt_+3A_method">method</code></td>
<td>
<p>= <code>c("asymptotic", "exact", "simulated")</code>, where
</p>
<p><code>"asymptotic"</code> uses only an asymptotic normal approximation 
to approximate the achieved joint coverage probability. 
This calculation is always done.
</p>
<p><code>"exact"</code> uses full enumeration of all sample splits to obtain the exact achieved 
joint coverage probability (see Details).
It is used only when <code>Nsim</code> is at least as large as the number of full enumerations. 
Otherwise, <code>method</code> reverts to <code>"simulated"</code> using the given <code>Nsim</code>.
</p>
<p><code>"simulated"</code> uses <code>Nsim</code> simulated random splits of the 
pooled samples into samples of sizes <code class="reqn">n_1, \ldots, n_k</code>, 
to estimate the achieved joint coverage probability.
</p>
</td></tr>
<tr><td><code id="SteelConfInt_+3A_nsim">Nsim</code></td>
<td>
<p><code>= 10000</code> (default), number of simulated sample splits to use.	
It is only used when <code>method = "simulated"</code>,
or when <code>method = "exact"</code> reverts to <code>method =</code>
<code>"simulated"</code>, as previously explained.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first sample is treated as control sample with sample size <code class="reqn">n_1</code>. The remaining 
<code class="reqn">s=k-1</code> samples are treatment samples.
Let <code class="reqn">W_{1i}, i=2,\ldots,k</code> denote the respective Wilcoxon statistics comparing the common control sample (index 1)
with each of the <code class="reqn">s</code> treatment samples (indexed by <code class="reqn">i</code>). 
For each comparison of control and treatment <code class="reqn">i</code>
sample
only the observations of the two samples involved are ranked.
By <code class="reqn">W_i=W_{1i}-n_i(n_i+1)/2</code> we denote
the corresponding Mann-Whitney test statistic.
Furthermore, let <code class="reqn">D_{i(j)}</code> denote the <code class="reqn">j</code>-th ordered value (ascending order) of the <code class="reqn">n_1n_i</code>
paired differences between the observations in treatment sample <code class="reqn">i</code> and those of the control
sample. By simple extension of results in Lehmann (2006), pages 87 and 92, the following equations hold, 
relating the null distribution of the 
Mann-Whitney statistics and the joint coverage probabilities of the <code class="reqn">D_{i(j_i)}</code> for any set of
<code class="reqn">j_1,\ldots,j_s</code> with <code class="reqn">1\le j_i \le n_1 n_i</code>.
</p>
<p style="text-align: center;"><code class="reqn">P_\Delta(\Delta_i \le D_{i(j_i)}, i=2,\ldots,k)=P_0(W_i\le j_i -1, i=2,\ldots,k)</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">P_\Delta(\Delta_i \ge D_{i(j_i)}, i=2,\ldots,s)=P_0(W_{i}\le n_1 n_i -j_i, i=2,\ldots,k)</code>
</p>

<p>where <code class="reqn">P_\Delta</code> refers to the distribution under <code class="reqn">\Delta=(\Delta_2,\ldots,\Delta_k)</code>
and <code class="reqn">P_0</code> refers to the joint null distribution of the <code class="reqn">W_i</code> when all sampled 
distributions are the same and continuous. There are <code class="reqn">k-1</code> indices <code class="reqn">j_i</code> that can be manipulated
to affect the achieved confidence level. To limit the computational complexity
standardized versions of the <code class="reqn">W_i</code>, i.e.,  <code class="reqn">(W_i-\mu_i)/\tau_i</code> with 
<code class="reqn">\mu_i</code> and <code class="reqn">\tau_i</code> representing mean and standard deviation of <code class="reqn">W_i</code>,
are used to choose a common value for <code class="reqn">(j_i -1-\mu_i)/\tau_i</code>  (satisfying the 
<code class="reqn">\gamma</code> level) from the multivariate normal approximation 
for the <code class="reqn">W_i</code> (see Miller (1981) and Scholz (2016)), and reduce that 
to integer values for <code class="reqn">j_i</code>, rounding up, rounding down, and rounding to the nearest integer. These
integers  <code class="reqn">j_i</code> are then used in approximating the actual joint probabilities
<code class="reqn">P_0(W_i\le j_i -1, i=2,\ldots,k)</code>, and from these three coverage probabilities 
the one that is closest to the nominal confidence level <code class="reqn">\gamma</code> and <code class="reqn">\ge \gamma</code>
and also also the one that is closest without the restriction <code class="reqn">\ge \gamma</code> are chosen.
</p>
<p>When <code>method = "exact"</code> or <code>= "simulated"</code> is specified, the same process
is used, using either the fully enumerated exact distribution of <code class="reqn">W_i, i=2,\ldots,k</code> (based on a recursive 
version of Chase's sequence as presented in Knuth (2011)) for all sample splits,
or the simulated distribution of <code class="reqn">W_i, i=2,\ldots,k</code>. However, since these distributions are discrete
the starting point before rounding up is the smallest quantile such that the proportion of distribution values less 
or equal to it is at least <code class="reqn">\gamma</code>. The starting point before rounding down is the highest quantile such that 
the proportion of distribution values less 
or equal to it is at most <code class="reqn">\gamma</code>. The third option of rounding to the closest integer is performed using 
the average of the first two.
</p>
<p>Confidence intervals are constructed by using upper and lower confidence bounds, each with
same confidence level of <code class="reqn">(1+\gamma)/2</code>.
</p>
<p>When the original sample data appear to be rounded, and especially when there are ties,
one should widen the computed intervals or bounds by the rounding <code class="reqn">\epsilon</code>, as illustrated
in Lehmann (2006), pages 85 and 94. For example, when all sample values appear to end in one of <code class="reqn">.0, .2, .4, .6, .8</code>,
the rounding <code class="reqn">\epsilon</code> would be <code class="reqn">.2</code>. Ultimately, this is a judgment call for the user. Such widening
of intervals will make the actually achieved confidence level <code class="reqn">\ge</code> the stated achieved level. 
</p>


<h3>Value</h3>

<p>A list of class <code>kSamples</code> with components 
</p>
<table>
<tr><td><code>test.name</code></td>
<td>
<p><code>"Steel.bounds"</code></p>
</td></tr>
<tr><td><code>n1</code></td>
<td>
<p>the control sample size <code class="reqn">= n_1</code></p>
</td></tr>
<tr><td><code>ns</code></td>
<td>
<p>vector <code class="reqn">(n_2,\ldots,n_k)</code> of the <code class="reqn">s=k-1</code> treatment sample sizes</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>size of the pooled sample <code class="reqn">= n_1+\ldots+n_k</code></p>
</td></tr>
<tr><td><code>n.ties</code></td>
<td>
<p>number of ties in the pooled sample</p>
</td></tr>
<tr><td><code>bounds</code></td>
<td>
<p>a list of data frames. When <code>method = "asymptotic"</code> is specified, the list
consists of two data frames named <code>conservative.bounds.asymptotic</code>
and <code>closest.bounds.asymptotic</code>. Each data frame consists of <code class="reqn">s</code> rows
corresponding to the <code class="reqn">s</code> shift parameters <code class="reqn">\Delta_i</code> and three columns,
the first column giving the lower bound, the second column the upper bound, while
the first row of the third column states the computed confidence level by asymptotic 
approximation, applying jointly to all <code class="reqn">s</code> sets of bounds. For one-sided bounds
the corresponding other bound is set to <code>Inf</code> or <code>-Inf</code>, respectively.
</p>
<p>In case of <code>conservative.bounds.asymptotic</code> the achieved asymptotic confidence level is 
targeted to be <code class="reqn">\ge</code> <code>conf.level</code>, but closest to it among three possible choices (see Details).
</p>
<p>In the case of <code>closest.bounds.asymptotic</code> the achieved level is targeted to
be closest to <code>conf.level</code>.
</p>
<p>When <code>method = "exact"</code> or <code>method = "simulated"</code>
is specified the list consists in addition of two further data frames named either
</p>
<p><code>conservative.bounds.exact</code> and 
<code>closest.bounds.exact</code> or
</p>
<p><code>conservative.bounds.simulated</code> and 
<code>closest.bounds.simulated</code>. 
</p>
<p>In either case the structure and meaning
of these data frames parallels that of the <code>"asymptotic"</code> case. 
</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the <code>method</code> used.</p>
</td></tr>
<tr><td><code>Nsim</code></td>
<td>
<p>the number of simulations used.</p>
</td></tr>
<tr><td><code>j.LU</code></td>
<td>
<p>an <code class="reqn">s</code> by 4 matrix giving the indices <code class="reqn">j_i</code> used for computing the bounds
<code class="reqn">D_{i(j_i)}</code> for <code class="reqn">\Delta_i, i=1,\ldots, s</code>.
</p>
</td></tr>
</table>


<h3>warning</h3>

<p><code>method = "exact"</code> should only be used with caution.
Computation time is proportional to the number of enumerations. 
Experiment with <code><a href="base.html#topic+system.time">system.time</a></code> and trial values for
<code>Nsim</code> to get a sense of the required computing time.</p>


<h3>References</h3>

<p>Knuth, D.E. (2011), <em>The Art of Computer Programming, Volume 4A 
Combinatorial Algorithms Part 1</em>, Addison-Wesley
</p>
<p>Lehmann, E.L. (2006),
<em>Nonparametrics, Statistical Methods Based on Ranks, Revised First Edition</em>,
Springer Verlag.
</p>
<p>Miller, Rupert G., Jr. (1981), <em>Simultaneous Statistical Inference, Second Edition</em>,
Springer Verlag, New York.
</p>
<p>Scholz, F.W. (2023), &quot;On Steel's Test with Ties&quot;, <a href="https://arxiv.org/abs/2308.05873">https://arxiv.org/abs/2308.05873</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>z1 &lt;- c(103, 111, 136, 106, 122, 114)
z2 &lt;- c(119, 100,  97,  89, 112,  86)
z3 &lt;- c( 89, 132,  86, 114, 114, 125)
z4 &lt;- c( 92, 114,  86, 119, 131,  94)
set.seed(2627)
SteelConfInt(list(z1,z2,z3,z4),conf.level=0.95,alternative="two.sided", 
   method="simulated",Nsim=10000)
# or with same seed
# SteelConfInt(z1,z2,z3,z4,conf.level=0.95,alternative="two.sided", 
#   method="simulated",Nsim=10000)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
