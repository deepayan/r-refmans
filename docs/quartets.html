<!DOCTYPE html><html><head><title>Help for package quartets</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {quartets}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#anscombe_leverage'><p>Anscombe's Quartet High Leverage Data</p></a></li>
<li><a href='#anscombe_linear'><p>Anscombe's Quartet Linear Data</p></a></li>
<li><a href='#anscombe_nonlinear'><p>Anscombe's Quartet Nonlinear Data</p></a></li>
<li><a href='#anscombe_outlier'><p>Anscombe's Quartet Outlier Data</p></a></li>
<li><a href='#anscombe_quartet'><p>Anscombe's Quartet Data</p></a></li>
<li><a href='#causal_collider'><p>Collider Data</p></a></li>
<li><a href='#causal_collider_time'><p>Time-varying Causal Quartet Data</p></a></li>
<li><a href='#causal_confounding'><p>Confounder Data</p></a></li>
<li><a href='#causal_m_bias'><p>M-Bias Data</p></a></li>
<li><a href='#causal_mediator'><p>Mediator Data</p></a></li>
<li><a href='#causal_quartet'><p>Causal Quartet Data</p></a></li>
<li><a href='#datasaurus_dozen'><p>Datasaurus Dozen Data</p></a></li>
<li><a href='#heterogeneous_causal_quartet'><p>Gelman Heterogeneity Causal Quartet Data</p></a></li>
<li><a href='#interaction_triptych'><p>Interaction Triptych Data</p></a></li>
<li><a href='#rashomon_quartet'><p>Rashomon Quartet Data</p></a></li>
<li><a href='#variation_causal_quartet'><p>Gelman Variation Causal Quartet Data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Datasets to Help Teach Statistics</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Description:</td>
<td>In the spirit of Anscombe's quartet, this package includes datasets
   that demonstrate the importance of visualizing your data, the importance of 
   not relying on statistical summary measures alone, and why additional 
   assumptions about the data generating mechanism are needed when estimating 
   causal effects. The package includes "Anscombe's Quartet" (Anscombe 1973) &lt;<a href="https://doi.org/10.1080%2F00031305.1973.10478966">doi:10.1080/00031305.1973.10478966</a>&gt;,
   D'Agostino McGowan &amp; Barrett (2023) "Causal Quartet" &lt;<a href="https://doi.org/10.48550%2FarXiv.2304.02683">doi:10.48550/arXiv.2304.02683</a>&gt;, 
   "Datasaurus Dozen" (Matejka &amp; Fitzmaurice 2017), "Interaction Triptych" (Rohrer &amp; Arslan 2021) &lt;<a href="https://doi.org/10.1177%2F25152459211007368">doi:10.1177/25152459211007368</a>&gt;, "Rashomon Quartet" (Biecek et al. 2023) &lt;<a href="https://doi.org/10.48550%2FarXiv.2302.13356">doi:10.48550/arXiv.2302.13356</a>&gt;, and
   Gelman "Variation and Heterogeneity Causal Quartets" (Gelman et al. 2023) &lt;<a href="https://doi.org/10.48550%2FarXiv.2302.12878">doi:10.48550/arXiv.2302.12878</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/r-causal/quartets">https://github.com/r-causal/quartets</a>,
<a href="https://r-causal.github.io/quartets/">https://r-causal.github.io/quartets/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/r-causal/quartets/issues">https://github.com/r-causal/quartets/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-04-13 20:31:30 UTC; lucymcgowan</td>
</tr>
<tr>
<td>Author:</td>
<td>Lucy D'Agostino McGowan
    <a href="https://orcid.org/0000-0002-6983-2759"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Lucy D'Agostino McGowan &lt;lucydagostino@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-04-13 23:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='anscombe_leverage'>Anscombe's Quartet High Leverage Data</h2><span id='topic+anscombe_leverage'></span>

<h3>Description</h3>

<p>This dataset contains 11 observations generated by Francis Anscombe to
demonstrate that statistical summary measures alone cannot capture the full
relationship between two variables (here, <code>x</code> and <code>y</code>). Anscombe emphasized
the importance of visualizing data prior to calculating summary statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>anscombe_leverage
</code></pre>


<h3>Format</h3>

<p>A dataframe with 11 rows and 2 variables:
</p>

<ul>
<li> <p><code>x</code>: the x-variable
</p>
</li>
<li> <p><code>y</code>: the y-variable
</p>
</li></ul>



<h3>Details</h3>

<p>This Dataset has a no relationship between <code>x</code> and <code>y</code> with a single
high leverage point
</p>
<p>Additionally, the following statistical summaries hold:
</p>

<ul>
<li><p> mean of <code>x</code>: 9
</p>
</li>
<li><p> variance of <code>x</code>: 11
</p>
</li>
<li><p> mean of <code>y</code>: 7.5
</p>
</li>
<li><p> variance of y: 4.125
</p>
</li>
<li><p> correlation between <code>x</code> and <code>y</code>: 0.816
</p>
</li>
<li><p> linear regression between <code>x</code> and <code>y</code>: <code style="white-space: pre;">&#8288;y = 3 + 0.5x&#8288;</code>
</p>
</li>
<li> <p><code class="reqn">R^2</code> for the regression: 0.67
</p>
</li></ul>



<h3>References</h3>

<p>Anscombe, F. J. (1973). &quot;Graphs in Statistical Analysis&quot;.
American Statistician. 27 (1): 17–21. doi:10.1080/00031305.1973.10478966.
JSTOR 2682899.
</p>

<hr>
<h2 id='anscombe_linear'>Anscombe's Quartet Linear Data</h2><span id='topic+anscombe_linear'></span>

<h3>Description</h3>

<p>This dataset contains 11 observations generated by Francis Anscombe to
demonstrate that statistical summary measures alone cannot capture the full
relationship between two variables (here, <code>x</code> and <code>y</code>). Anscombe emphasized
the importance of visualizing data prior to calculating summary statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>anscombe_linear
</code></pre>


<h3>Format</h3>

<p>A dataframe with 11 rows and 2 variables:
</p>

<ul>
<li> <p><code>x</code>: the x-variable
</p>
</li>
<li> <p><code>y</code>: the y-variable
</p>
</li></ul>



<h3>Details</h3>

<p>This Dataset has a linear relationship between <code>x</code> and <code>y</code>
</p>
<p>Additionally, the following statistical summaries hold:
</p>

<ul>
<li><p> mean of <code>x</code>: 9
</p>
</li>
<li><p> variance of <code>x</code>: 11
</p>
</li>
<li><p> mean of <code>y</code>: 7.5
</p>
</li>
<li><p> variance of y: 4.125
</p>
</li>
<li><p> correlation between <code>x</code> and <code>y</code>: 0.816
</p>
</li>
<li><p> linear regression between <code>x</code> and <code>y</code>: <code style="white-space: pre;">&#8288;y = 3 + 0.5x&#8288;</code>
</p>
</li>
<li> <p><code class="reqn">R^2</code> for the regression: 0.67
</p>
</li></ul>



<h3>References</h3>

<p>Anscombe, F. J. (1973). &quot;Graphs in Statistical Analysis&quot;.
American Statistician. 27 (1): 17–21. doi:10.1080/00031305.1973.10478966.
JSTOR 2682899.
</p>

<hr>
<h2 id='anscombe_nonlinear'>Anscombe's Quartet Nonlinear Data</h2><span id='topic+anscombe_nonlinear'></span>

<h3>Description</h3>

<p>This dataset contains 11 observations generated by Francis Anscombe to
demonstrate that statistical summary measures alone cannot capture the full
relationship between two variables (here, <code>x</code> and <code>y</code>). Anscombe emphasized
the importance of visualizing data prior to calculating summary statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>anscombe_nonlinear
</code></pre>


<h3>Format</h3>

<p>A dataframe with 11 rows and 2 variables:
</p>

<ul>
<li> <p><code>x</code>: the x-variable
</p>
</li>
<li> <p><code>y</code>: the y-variable
</p>
</li></ul>



<h3>Details</h3>

<p>This Dataset has a nonlinear relationship between <code>x</code> and <code>y</code>
</p>
<p>Additionally, the following statistical summaries hold:
</p>

<ul>
<li><p> mean of <code>x</code>: 9
</p>
</li>
<li><p> variance of <code>x</code>: 11
</p>
</li>
<li><p> mean of <code>y</code>: 7.5
</p>
</li>
<li><p> variance of y: 4.125
</p>
</li>
<li><p> correlation between <code>x</code> and <code>y</code>: 0.816
</p>
</li>
<li><p> linear regression between <code>x</code> and <code>y</code>: <code style="white-space: pre;">&#8288;y = 3 + 0.5x&#8288;</code>
</p>
</li>
<li> <p><code class="reqn">R^2</code> for the regression: 0.67
</p>
</li></ul>



<h3>References</h3>

<p>Anscombe, F. J. (1973). &quot;Graphs in Statistical Analysis&quot;.
American Statistician. 27 (1): 17–21. doi:10.1080/00031305.1973.10478966.
JSTOR 2682899.
</p>

<hr>
<h2 id='anscombe_outlier'>Anscombe's Quartet Outlier Data</h2><span id='topic+anscombe_outlier'></span>

<h3>Description</h3>

<p>This dataset contains 11 observations generated by Francis Anscombe to
demonstrate that statistical summary measures alone cannot capture the full
relationship between two variables (here, <code>x</code> and <code>y</code>). Anscombe emphasized
the importance of visualizing data prior to calculating summary statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>anscombe_outlier
</code></pre>


<h3>Format</h3>

<p>A dataframe with 11 rows and 2 variables:
</p>

<ul>
<li> <p><code>x</code>: the x-variable
</p>
</li>
<li> <p><code>y</code>: the y-variable
</p>
</li></ul>



<h3>Details</h3>

<p>This Dataset has a linear relationship between <code>x</code> and <code>y</code> with a single
outlier
</p>
<p>Additionally, the following statistical summaries hold:
</p>

<ul>
<li><p> mean of <code>x</code>: 9
</p>
</li>
<li><p> variance of <code>x</code>: 11
</p>
</li>
<li><p> mean of <code>y</code>: 7.5
</p>
</li>
<li><p> variance of y: 4.125
</p>
</li>
<li><p> correlation between <code>x</code> and <code>y</code>: 0.816
</p>
</li>
<li><p> linear regression between <code>x</code> and <code>y</code>: <code style="white-space: pre;">&#8288;y = 3 + 0.5x&#8288;</code>
</p>
</li>
<li> <p><code class="reqn">R^2</code> for the regression: 0.67
</p>
</li></ul>



<h3>References</h3>

<p>Anscombe, F. J. (1973). &quot;Graphs in Statistical Analysis&quot;.
American Statistician. 27 (1): 17–21. doi:10.1080/00031305.1973.10478966.
JSTOR 2682899.
</p>

<hr>
<h2 id='anscombe_quartet'>Anscombe's Quartet Data</h2><span id='topic+anscombe_quartet'></span>

<h3>Description</h3>

<p>This dataset contains 44 observations, 11 observations from 4 datasets
generated by Francis Anscombe to demonstrate that statistical summary
measures alone cannot capture the full relationship between two variables
(here, <code>x</code> and <code>y</code>). Anscombe emphasized the importance of visualizing data
prior to calculating summary statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>anscombe_quartet
</code></pre>


<h3>Format</h3>

<p>A dataframe with 44 rows and 3 variables:
</p>

<ul>
<li> <p><code>dataset</code>: the dataset the values come from
</p>
</li>
<li> <p><code>x</code>: the x-variable
</p>
</li>
<li> <p><code>y</code>: the y-variable
</p>
</li></ul>



<h3>Details</h3>


<ul>
<li><p> Dataset 1 has a linear relationship between <code>x</code> and <code>y</code>
</p>
</li>
<li><p> Dataset 2 has shows a nonlinear relationship between <code>x</code> and <code>y</code>
</p>
</li>
<li><p> Dataset 3 has a linear relationship between <code>x</code> and <code>y</code> with a single outlier
</p>
</li>
<li><p> Dataset 4 has shows no relationship between <code>x</code> and <code>y</code> with a single
outlier that serves as a high-leverage point.
</p>
</li></ul>

<p>In each of the datasets the following statistical summaries hold:
</p>

<ul>
<li><p> mean of <code>x</code>: 9
</p>
</li>
<li><p> variance of <code>x</code>: 11
</p>
</li>
<li><p> mean of <code>y</code>: 7.5
</p>
</li>
<li><p> variance of y: 4.125
</p>
</li>
<li><p> correlation between <code>x</code> and <code>y</code>: 0.816
</p>
</li>
<li><p> linear regression between <code>x</code> and <code>y</code>: <code style="white-space: pre;">&#8288;y = 3 + 0.5x&#8288;</code>
</p>
</li>
<li> <p><code class="reqn">R^2</code> for the regression: 0.67
</p>
</li></ul>



<h3>References</h3>

<p>Anscombe, F. J. (1973). &quot;Graphs in Statistical Analysis&quot;.
American Statistician. 27 (1): 17–21. doi:10.1080/00031305.1973.10478966.
JSTOR 2682899.
</p>

<hr>
<h2 id='causal_collider'>Collider Data</h2><span id='topic+causal_collider'></span>

<h3>Description</h3>

<p>This dataset contains 100 observations, generated under the following mechanism:
X ~ N(0, 1) (exposure)
Y ~ X + N(0,1) (outcome)
Z ~ 0.45X + 0.77Y + N(0, 1) (measured factor: collider)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>causal_collider
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100 rows and 3 variables:
</p>

<ul>
<li> <p><code>exposure</code>: exposure
</p>
</li>
<li> <p><code>outcome</code>: outcome
</p>
</li>
<li> <p><code>covariate</code>: a known factor (collider)
</p>
</li></ul>



<h3>References</h3>

<p>D'Agostino McGowan L, Barrett M (2023). Causal inference is not a statistical problem. Preprint arXiv:2304.02683v1.
</p>

<hr>
<h2 id='causal_collider_time'>Time-varying Causal Quartet Data</h2><span id='topic+causal_collider_time'></span><span id='topic+causal_confounding_time'></span><span id='topic+causal_mediator_time'></span><span id='topic+causal_m_bias_time'></span><span id='topic+causal_quartet_time'></span>

<h3>Description</h3>

<p>These datasets contains 100 observations, each generated under a different
data generating mechanism:
</p>

<ul>
<li><p> (1) A collider
</p>
</li>
<li><p> (2) A confounder
</p>
</li>
<li><p> (3) A mediator
</p>
</li>
<li><p> (4) M-bias
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>causal_collider_time

causal_confounding_time

causal_mediator_time

causal_m_bias_time

causal_quartet_time
</code></pre>


<h3>Format</h3>

<p><code>causal_collider_time</code>: A dataframe with 100 rows and 7 variables:
</p>

<ul>
<li> <p><code>covariate_baseline</code>: known factor measured at baseline
</p>
</li>
<li> <p><code>exposure_baseline</code>: exposure measured at baseline
</p>
</li>
<li> <p><code>outcome_baseline</code>: outcome measured at baseline
</p>
</li>
<li> <p><code>exposure_followup</code>: exposure measured at the followup visit (final time)
</p>
</li>
<li> <p><code>outcome_followup</code>: outcome measured at the followup visit (final time)
</p>
</li>
<li> <p><code>covariate_followup</code>: known factor measured at the followup visit (final time)
</p>
</li></ul>

<p><code>causal_confounding_time</code>: A dataframe with 100 rows and 7 variables:
</p>

<ul>
<li> <p><code>covariate_baseline</code>: known factor measured at baseline
</p>
</li>
<li> <p><code>exposure_baseline</code>: exposure measured at baseline
</p>
</li>
<li> <p><code>outcome_baseline</code>: outcome measured at baseline
</p>
</li>
<li> <p><code>exposure_followup</code>: exposure measured at the followup visit (final time)
</p>
</li>
<li> <p><code>outcome_followup</code>: outcome measured at the followup visit (final time)
</p>
</li>
<li> <p><code>covariate_followup</code>: known factor measured at the followup visit (final time)
</p>
</li></ul>

<p><code>causal_mediator_time</code>: A dataframe with 100 rows and 7 variables:
</p>

<ul>
<li> <p><code>covariate_baseline</code>: known factor measured at baseline
</p>
</li>
<li> <p><code>exposure_baseline</code>: exposure measured at baseline
</p>
</li>
<li> <p><code>outcome_baseline</code>: outcome measured at baseline
</p>
</li>
<li> <p><code>covariate_mid</code>: known factor measured at some mid-point
</p>
</li>
<li> <p><code>exposure_mid</code>: exposure measured at some mid-point
</p>
</li>
<li> <p><code>outcome_mid</code>: outcome measured at some mid-point
</p>
</li>
<li> <p><code>exposure_followup</code>: exposure measured at the followup visit (final time)
</p>
</li>
<li> <p><code>outcome_followup</code>: outcome measured at the followup visit (final time)
</p>
</li>
<li> <p><code>covariate_followup</code>: known factor measured at the followup visit (final time)
</p>
</li></ul>

<p><code>causal_m_bias_time</code>: A dataframe with 100 rows and 9 variables:
</p>

<ul>
<li> <p><code>u1</code>: unmeasured factor
</p>
</li>
<li> <p><code>u2</code>: unmeasured factor
</p>
</li>
<li> <p><code>covariate_baseline</code>: known factor measured at baseline
</p>
</li>
<li> <p><code>exposure_baseline</code>: exposure measured at baseline
</p>
</li>
<li> <p><code>outcome_baseline</code>: outcome measured at baseline
</p>
</li>
<li> <p><code>exposure_followup</code>: exposure measured at the followup visit (final time)
</p>
</li>
<li> <p><code>outcome_followup</code>: outcome measured at the followup visit (final time)
</p>
</li>
<li> <p><code>covariate_followup</code>: known factor measured at the followup visit (final time)
</p>
</li></ul>

<p>An object of class <code>tbl_df</code> (inherits from <code>tbl</code>, <code>data.frame</code>) with 400 rows and 12 columns.
</p>


<h3>Details</h3>

<p>There are two time points:
</p>

<ul>
<li><p> baseline
</p>
</li>
<li><p> follow up
</p>
</li></ul>

<p>These datasets help demonstrate that a model that includes only pre-exposure
covariates (that is, only adjusting for covariates measured at baseline), will
be less prone to potential biases. Adjusting for only pre-exposure covariates
&quot;solves&quot; the bias in datasets 1-3. It does not solve the data generated under
the &quot;M-bias&quot; scenario, however this is more of a toy example, it has been
shown many times that the assumptions needed for this M-bias to hold are
often not ones we practically see in data analysis.
</p>


<h3>References</h3>

<p>D'Agostino McGowan L, Barrett M (2023). Causal inference is not a statistical problem. Preprint arXiv:2304.02683v1.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## incorrect model because covariate is post-treatment
lm(outcome_followup ~ exposure_baseline + covariate_followup,
   data = causal_collider_time)

## correct model because covariate is pre-treatment
## even though the true mechanism dictates that the covariate is a collider,
## because the pre-exposure variable is used, the collider bias does not
## occur.
lm(outcome_followup ~ exposure_baseline + covariate_baseline,
   data = causal_collider_time)
</code></pre>

<hr>
<h2 id='causal_confounding'>Confounder Data</h2><span id='topic+causal_confounding'></span>

<h3>Description</h3>

<p>This dataset contains 100 observations, generated under the following mechanism:
Z ~ N(0, 1) (measured factor: confounder)
X ~ Z + N(0,1) (exposure)
Y ~ 0.5X + Z + N(0, 1) (outcome)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>causal_confounding
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100 rows and 3:
</p>

<ul>
<li> <p><code>covariate</code>: a known factor (confounder)
</p>
</li>
<li> <p><code>exposure</code>: exposure
</p>
</li>
<li> <p><code>outcome</code>: outcome
</p>
</li></ul>



<h3>References</h3>

<p>D'Agostino McGowan L, Barrett M (2023). Causal inference is not a statistical problem. Preprint arXiv:2304.02683v1.
</p>

<hr>
<h2 id='causal_m_bias'>M-Bias Data</h2><span id='topic+causal_m_bias'></span>

<h3>Description</h3>

<p>This dataset contains 100 observations, generated under the following mechanism:
U1 ~ N(0, 1)
U2 ~ N(0, 1)
Z ~ 8 U1 + U2 + N(0, 1) (measured factor)
X ~ U1 + N(0, 1) (exposure)
Y ~ X + U2 + N(0, 1) (outcome)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>causal_m_bias
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100 rows and 5 variables:
</p>

<ul>
<li> <p><code>u1</code>: an unknown factor
</p>
</li>
<li> <p><code>u2</code>: an unknown factor
</p>
</li>
<li> <p><code>covariate</code>: a known factor
</p>
</li>
<li> <p><code>exposure</code>: exposure
</p>
</li>
<li> <p><code>outcome</code>: outcome
</p>
</li></ul>



<h3>References</h3>

<p>D'Agostino McGowan L, Barrett M (2023). Causal inference is not a statistical problem. Preprint arXiv:2304.02683v1.
</p>

<hr>
<h2 id='causal_mediator'>Mediator Data</h2><span id='topic+causal_mediator'></span>

<h3>Description</h3>

<p>This dataset contains 100 observations, generated under the following mechanism:
X ~ N(0, 1) (exposure)
Z ~ X + N(0,1) (measured factor: mediator)
Y ~ Z + N(0, 1) (outcome)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>causal_mediator
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100 rows and 3 variables:
</p>

<ul>
<li> <p><code>exposure</code>: exposure
</p>
</li>
<li> <p><code>covariate</code>: a known factor (mediator)
</p>
</li>
<li> <p><code>outcome</code>: outcome
</p>
</li></ul>



<h3>References</h3>

<p>D'Agostino McGowan L, Barrett M (2023). Causal inference is not a statistical problem. Preprint arXiv:2304.02683v1.
</p>

<hr>
<h2 id='causal_quartet'>Causal Quartet Data</h2><span id='topic+causal_quartet'></span>

<h3>Description</h3>

<p>This dataset contains 400 observations, each generated under a different
data generating mechanism:
</p>

<ul>
<li><p> (1) A collider
</p>
</li>
<li><p> (2) A confounder
</p>
</li>
<li><p> (3) A mediator
</p>
</li>
<li><p> (4) M-bias
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>causal_quartet
</code></pre>


<h3>Format</h3>

<p>A dataframe with 400 rows and 6 variables:
</p>

<ul>
<li> <p><code>dataset</code>: The data generating mechanism
</p>
</li>
<li> <p><code>exposure</code>: exposure
</p>
</li>
<li> <p><code>outcome</code>: outcome
</p>
</li>
<li> <p><code>covariate</code>: a known factor
</p>
</li>
<li> <p><code>u1</code>: an unknown factor
</p>
</li>
<li> <p><code>u2</code>: an unknown factor
</p>
</li></ul>



<h3>References</h3>

<p>D'Agostino McGowan L, Barrett M (2023). Causal inference is not a statistical problem. Preprint arXiv:2304.02683v1.
</p>

<hr>
<h2 id='datasaurus_dozen'>Datasaurus Dozen Data</h2><span id='topic+datasaurus_dozen'></span>

<h3>Description</h3>

<p>A dataset containing 12 datasets that are equal in mean, variance, and
Pearson's correlation but very different when visualized.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>datasaurus_dozen
</code></pre>


<h3>Format</h3>

<p>A data frame with 1846 rows and 3 variables:
</p>

<ul>
<li> <p><code>dataset</code>: the dataset the values come from
</p>
</li>
<li> <p><code>x</code>: the x-variable
</p>
</li>
<li> <p><code>y</code>: the y-variable
</p>
</li></ul>



<h3>References</h3>

<p>Davies R, Locke S, D'Agostino McGowan L (2022). <em>datasauRus: Datasets from the
Datasaurus Dozen</em>. R package version 0.1.6, <a href="https://CRAN.R-project.org/package=datasauRus">https://CRAN.R-project.org/package=datasauRus</a>.
</p>
<p>Matejka, J., &amp; Fitzmaurice, G. (2017). Same Stats, Different Graphs:
Generating Datasets with Varied Appearance and Identical Statistics through
Simulated Annealing. CHI 2017 Conference proceedings: ACM SIGCHI Conference
on Human Factors in Computing Systems. Retrieved from https://www.autodesk.com/research/publications/same-stats-different-graphs
</p>

<hr>
<h2 id='heterogeneous_causal_quartet'>Gelman Heterogeneity Causal Quartet Data</h2><span id='topic+heterogeneous_causal_quartet'></span>

<h3>Description</h3>

<p>This dataset contains 88 observations, each generated under a different
mechanism treatment heterogeneity with respect to some
pre-exposure characteristic, <code>z</code>:
</p>

<ul>
<li><p> (1) Linear interaction
</p>
</li>
<li><p> (2) No effect then steady increase
</p>
</li>
<li><p> (3) Plateau
</p>
</li>
<li><p> (4) Intermediate zone with large effects
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>heterogeneous_causal_quartet
</code></pre>


<h3>Format</h3>

<p>A dataframe with 88 rows and 5 variables:
</p>

<ul>
<li> <p><code>dataset</code>: The data generating mechanism
</p>
</li>
<li> <p><code>exposure</code>: exposure
</p>
</li>
<li> <p><code>covariate</code>: a pre-exposure factor
</p>
</li>
<li> <p><code>outcome</code>: outcome
</p>
</li>
<li> <p><code>.causal_effect</code>: latent true causal effect
</p>
</li></ul>



<h3>References</h3>

<p>Gelman, A., Hullman, J., &amp; Kennedy, L. (2023). Causal quartets: Different ways to attain the same average treatment effect. arXiv preprint arXiv:2302.12878.
</p>
<p>Hullman J (2023). <em>causalQuartet: Create Causal Quartets for Interrogating Average Treatment Effects</em>. R package version 0.0.0.9000.
</p>

<hr>
<h2 id='interaction_triptych'>Interaction Triptych Data</h2><span id='topic+interaction_triptych'></span>

<h3>Description</h3>

<p>This dataset contains 2,700 observations, generated under 3 different conditions
</p>

<ul>
<li><p> (1) Ideal case
</p>
</li>
<li><p> (2) Floor effect, No latent interaction
</p>
</li>
<li><p> (3) Smaller correlation at larger slope
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>interaction_triptych
</code></pre>


<h3>Format</h3>

<p>A dataframe with 2700 rows and 5 variables:
</p>

<ul>
<li> <p><code>dataset</code>: ideal, floor, or smaller correlation at larger slope
</p>
</li>
<li> <p><code>moderator</code>: a factor that potentially interacts with <code>x</code>, values: low, medium, or high
</p>
</li>
<li> <p><code>x</code>
</p>
</li>
<li> <p><code>y</code>
</p>
</li></ul>



<h3>Details</h3>

<p>In the ideal scenario, only the slopes differ by moderator level. In the
&quot;floor effect&quot; scenario, there is an illusion of an interaction, even though
only main effects were simulated. In the third scenario, the slopes increase
with higher moderator values but the correlation decreases. Running only a
linear model would not allow for appropriate differentiation between these
effects.
</p>
<p>In each case there is a potential moderator with &quot;low&quot; &quot;medium&quot; and &quot;high&quot; values.
</p>


<h3>References</h3>

<p>Rohrer, Julia M., and Ruben C. Arslan. &quot;Precise answers to vague questions: Issues with interactions.&quot; Advances in Methods and Practices in Psychological Science 4.2 (2021): 25152459211007368.
</p>

<hr>
<h2 id='rashomon_quartet'>Rashomon Quartet Data</h2><span id='topic+rashomon_quartet'></span><span id='topic+rashomon_quartet_train'></span><span id='topic+rashomon_quartet_test'></span>

<h3>Description</h3>

<p>This dataset contains 2,000 observations, 1,000 training observations and
1,000 testing observations. These were generated such that 4 modeling
techniques (regression tree, linear model, neural network, random forest)
will yield the same <code class="reqn">R^2</code> and RMSE but will fit the models very differently.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rashomon_quartet

rashomon_quartet_train

rashomon_quartet_test
</code></pre>


<h3>Format</h3>

<p><code>rashomon_quartet</code>: A dataframe with 2000 rows and 5 variables:
</p>

<ul>
<li> <p><code>split</code>: train, test
</p>
</li>
<li> <p><code>x1</code>
</p>
</li>
<li> <p><code>x2</code>
</p>
</li>
<li> <p><code>x3</code>
</p>
</li>
<li> <p><code>y</code>
</p>
</li></ul>

<p><code>rashomon_quartet_train</code>: A dataframe with 1000 rows and 4 variables:
</p>

<ul>
<li> <p><code>x1</code>
</p>
</li>
<li> <p><code>x2</code>
</p>
</li>
<li> <p><code>x3</code>
</p>
</li>
<li> <p><code>y</code>
</p>
</li></ul>

<p><code>rashomon_quartet_test</code>: A dataframe with 1000 rows and 4 variables:
</p>

<ul>
<li> <p><code>x1</code>
</p>
</li>
<li> <p><code>x2</code>
</p>
</li>
<li> <p><code>x3</code>
</p>
</li>
<li> <p><code>y</code>
</p>
</li></ul>



<h3>Details</h3>

<p>There are three explanatory variables <code>x1</code>, <code>x2</code>, <code>x3</code> and one outcome <code>y</code>
generated as:
</p>
<p><code class="reqn">y = sin((3x_1 + x_2)/5)+\varepsilon</code>
</p>
<p>where <code class="reqn">\varepsilon\sim N(0,1/3)</code> and <code class="reqn">[x_1,x_2,x_3]\sim N(0, \Sigma_{3x3})</code>
and <code class="reqn">\Sigma_{3x3}</code> has 1 on the diagonal and 0.9 elsewhere.
</p>
<p>If fit using the following hyperparameters, each model will yield an <code class="reqn">R^2</code> of 0.73 and an RMSE of 0.354
</p>

<ul>
<li><p> Regression tree: max depth: 3, min split: 250
</p>
</li>
<li><p> Linear model: all main effects
</p>
</li>
<li><p> Random Forest: mtry: 1, number of trees: 100
</p>
</li>
<li><p> Neural network: hidden neurons in each layer: 8, 4, threshold for partial derivatives of the error function as stopping criteria: 0.05
</p>
</li></ul>

<p><code><a href="#topic+rashomon_quartet_train">rashomon_quartet_train</a></code> contains just the training data and <code><a href="#topic+rashomon_quartet_test">rashomon_quartet_test</a></code> contains only the test data.
</p>


<h3>References</h3>

<p>P. Biecek, H. Baniecki, M. Krzyziński, D. Cook. Performance is not enough: the story of Rashomon’s quartet. Preprint arXiv:2302.13356v2, 2023.
</p>

<hr>
<h2 id='variation_causal_quartet'>Gelman Variation Causal Quartet Data</h2><span id='topic+variation_causal_quartet'></span>

<h3>Description</h3>

<p>This dataset contains 88 observations, each generated under a different
mechanism of variation of the treatment effect with respect to some
pre-exposure characteristic, <code>z</code>:
</p>

<ul>
<li><p> (1) Constant effect
</p>
</li>
<li><p> (2) Low variation
</p>
</li>
<li><p> (3) High variation
</p>
</li>
<li><p> (4) Occasional large effects
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>variation_causal_quartet
</code></pre>


<h3>Format</h3>

<p>A dataframe with 88 rows and 5 variables:
</p>

<ul>
<li> <p><code>dataset</code>: The data generating mechanism
</p>
</li>
<li> <p><code>exposure</code>: exposure
</p>
</li>
<li> <p><code>covariate</code>: a pre-exposure factor
</p>
</li>
<li> <p><code>outcome</code>: outcome
</p>
</li>
<li> <p><code>.causal_effect</code>: Latent true causal effect
</p>
</li></ul>



<h3>References</h3>

<p>Gelman, A., Hullman, J., &amp; Kennedy, L. (2023). Causal quartets: Different ways to attain the same average treatment effect. arXiv preprint arXiv:2302.12878.
</p>
<p>Hullman J (2023). <em>causalQuartet: Create Causal Quartets for Interrogating Average Treatment Effects</em>. R package version 0.0.0.9000.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
