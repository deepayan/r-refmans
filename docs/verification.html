<!DOCTYPE html><html><head><title>Help for package verification</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {verification}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#attribute'><p>Attribute plot</p></a></li>
<li><a href='#brier'><p>Brier Score</p></a></li>
<li><a href='#check.func'><p>check loss function</p></a></li>
<li><a href='#conditional.quantile'><p>Conditional Quantile Plot</p></a></li>
<li><a href='#crps'><p>Continuous Ranked Probability Score</p></a></li>
<li><a href='#crpsDecompostion'><p>Decompostion of Continuous Ranked Probability Score</p></a></li>
<li><a href='#disc.dat'><p> Discrimination plot dataset.</p></a></li>
<li><a href='#discrimination.plot'><p>Discrimination  plot</p></a></li>
<li><a href='#fss'><p>Fractional Skill Score</p></a></li>
<li><a href='#leps'><p>Linear Error in Probability Space (LEPS)</p></a></li>
<li><a href='#lines.verify'><p>Add lines to ROC or attribute diagrams</p></a></li>
<li><a href='#measurement.error'><p>Skill score with measurement error.</p></a></li>
<li><a href='#multi.cont'><p>Multiple Contingency Table Statistics</p></a></li>
<li><a href='#observation.error'><p>Observation Error</p></a></li>
<li><a href='#performance.diagram'><p>Performance Diagram</p></a></li>
<li><a href='#pop'><p> Probability of precipitation (pop) data.</p></a></li>
<li><a href='#precip.ensemble'>
<p>An ensemble of precipitation forecasts</p></a></li>
<li><a href='#predcomp.test'>
<p>Time Series Prediction Comparison Test</p></a></li>
<li><a href='#prob.frcs.dat'><p> Probablisitic  Forecast Dataset.</p></a></li>
<li><a href='#probcont2disc'><p>Converts continuous probability values into binned</p>
discrete probability forecasts.</a></li>
<li><a href='#qrel.plot'><p>Quantile Reliability Plot</p></a></li>
<li><a href='#quantile2disc'><p>Convert Continuous Forecast Values to Discrete Forecast Values.</p></a></li>
<li><a href='#quantileScore'><p>Quantile Score</p></a></li>
<li><a href='#rcrv'><p>Reduced centered random variable</p></a></li>
<li><a href='#reliability.plot'><p>Reliability Plot</p></a></li>
<li><a href='#roc.area'><p>Area under curve (AUC) calculation for Response Operating Characteristic curve.</p></a></li>
<li><a href='#roc.plot'><p>Relative operating characteristic curve.</p></a></li>
<li><a href='#rps'><p>Ranked Probability Score</p></a></li>
<li><a href='#table.stats'><p>Verification statistics for a 2 by 2  Contingency Table</p></a></li>
<li><a href='#table.stats.boot'><p>Percentile bootstrap for 2 by 2 table</p></a></li>
<li><a href='#value'><p>Forecast Value Function</p></a></li>
<li><a href='#verify'><p>Verification function</p></a></li>
<li><a href='#verify-internal'>
<p>Verification internal and secondary functions</p>
</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.42</td>
</tr>
<tr>
<td>Date:</td>
<td>2015-07-10</td>
</tr>
<tr>
<td>Title:</td>
<td>Weather Forecast Verification Utilities</td>
</tr>
<tr>
<td>Author:</td>
<td>NCAR - Research Applications Laboratory</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Eric Gilleland &lt;ericg@ucar.edu&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10), methods, fields, boot, CircStats, MASS, dtw</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, stats</td>
</tr>
<tr>
<td>Description:</td>
<td>Utilities for verifying discrete, continuous and probabilistic forecasts, and forecasts expressed as parametric distributions are included.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2015-07-14 19:10:31 UTC; ericg</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2015-07-15 01:30:51</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
</table>
<hr>
<h2 id='attribute'>Attribute plot</h2><span id='topic+attribute'></span><span id='topic+attribute.default'></span><span id='topic+attribute.prob.bin'></span>

<h3>Description</h3>

<p>An attribute plot  illustrates
the reliability, resolution and uncertainty of a forecast with
respect to the observation.
The frequency of binned forecast probabilities are plotted
against proportions of binned observations.  A perfect forecast would
be indicated by a line plotted along the 1:1 line.  Uncertainty
is described as the vertical distance between this point and the
1:1 line.  The
relative frequency for each forecast value is displayed in parenthesis. </p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
attribute(x, obar.i,  prob.y = NULL, obar = NULL,
    class = "none", main = NULL, CI = FALSE, n.boot = 100, alpha = 0.05,
    tck = 0.01, freq = TRUE, pred = NULL, obs = NULL, thres = thres,
    bins = FALSE, ...)

## S3 method for class 'prob.bin'
attribute(x, ...)
       </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="attribute_+3A_x">x</code></td>
<td>
<p>A vector of forecast probabilities or a &ldquo;prob.bin&rdquo;
class object produced by the <code>verify</code> function. </p>
</td></tr>
<tr><td><code id="attribute_+3A_obar.i">obar.i</code></td>
<td>
<p>A vector of observed relative frequency of forecast bins.</p>
</td></tr> 
<tr><td><code id="attribute_+3A_prob.y">prob.y</code></td>
<td>
<p>Relative frequency of forecasts of forecast bins. </p>
</td></tr>
<tr><td><code id="attribute_+3A_obar">obar</code></td>
<td>
<p>Climatological or sample mean of observed
events.</p>
</td></tr>
<tr><td><code id="attribute_+3A_class">class</code></td>
<td>
<p>Class of object.  If prob.bin, the function will
use the data to estimate confidence intervals.</p>
</td></tr>
<tr><td><code id="attribute_+3A_main">main</code></td>
<td>
<p>Plot title.</p>
</td></tr>
<tr><td><code id="attribute_+3A_ci">CI</code></td>
<td>
<p>Confidence Intervals. This is only an option if the
data is accessible by using the verify command first. Calculated by bootstrapping
the observations and prediction, then calculating PODy and
PODn values.  </p>
</td></tr>
<tr><td><code id="attribute_+3A_n.boot">n.boot</code></td>
<td>
<p>Number of bootstrap samples.</p>
</td></tr>
<tr><td><code id="attribute_+3A_alpha">alpha</code></td>
<td>
<p>Confidence interval.  By default = 0.05</p>
</td></tr>
<tr><td><code id="attribute_+3A_tck">tck</code></td>
<td>
<p>Tick width on confidence interval whiskers.</p>
</td></tr>
<tr><td><code id="attribute_+3A_freq">freq</code></td>
<td>
<p>Should the frequecies be plotted. Default = TRUE</p>
</td></tr> 
<tr><td><code id="attribute_+3A_pred">pred</code></td>
<td>
<p>Required to create confidence intervals</p>
</td></tr>
<tr><td><code id="attribute_+3A_obs">obs</code></td>
<td>
<p>Required to create confidence intervals</p>
</td></tr> 
<tr><td><code id="attribute_+3A_thres">thres</code></td>
<td>
<p>thresholds used to create bins for plotting confidence intervals.</p>
</td></tr>   
<tr><td><code id="attribute_+3A_bins">bins</code></td>
<td>
<p>Should probabilities be binned or treated as unique predictions?</p>
</td></tr>
<tr><td><code id="attribute_+3A_...">...</code></td>
<td>
<p>Graphical parameters</p>
</td></tr> 
</table>


<h3>Note</h3>

<p>Points and bins are plotted at the mid-point of bins.  This can create distorted graphs if forecasts are created at irregular intervals.
</p>


<h3>Author(s)</h3>

<p>Matt Pocernich</p>


<h3>References</h3>

<p>Hsu, W. R., and A. H. Murphy, 1986: The attributes diagram: A geometrical framework for assessing the quality of probability forecasts.  <em>Int. J. Forecasting</em> <b>2</b>, 285&ndash;293.
</p>
<p>Wilks, D. S. (2005) <em>Statistical Methods in the Atmospheric Sciences </em> Chapter 7, San Diego: Academic Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+verify">verify</a></code>  <code><a href="#topic+reliability.plot">reliability.plot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Data from Wilks, table 7.3 page 246.
 y.i   &lt;- c(0,0.05, seq(0.1, 1, 0.1))
 obar.i &lt;- c(0.006, 0.019, 0.059, 0.15, 0.277, 0.377, 0.511, 
             0.587, 0.723, 0.779, 0.934, 0.933)
 prob.y&lt;- c(0.4112, 0.0671, 0.1833, 0.0986, 0.0616, 0.0366,
            0.0303,  0.0275, 0.245, 0.022, 0.017, 0.203) 
 obar&lt;- 0.162
 
attribute(y.i, obar.i, prob.y, obar, main = "Sample Attribute Plot")  

## Function will work with a ``prob.bin'' class objects as well.
## Note this is a random forecast.
obs&lt;- round(runif(100))
pred&lt;- runif(100)

A&lt;- verify(obs, pred, frcst.type = "prob", obs.type = "binary")
attribute(A, main = "Alternative plot", xlab = "Alternate x label" )
## to add a line from another model
obs&lt;- round(runif(100))
pred&lt;- runif(100)

B&lt;- verify(obs, pred, frcst.type = "prob", obs.type = "binary")
lines.attrib(B, col = "green")


## Same with confidence intervals
attribute(A, main = "Alternative plot", xlab = "Alternate x label", CI =
TRUE)

#### add lines to plot
data(pop)
d &lt;- pop.convert()
## internal function used to
## make binary observations for
## the pop figure.

### note the use of bins = FALSE
mod24 &lt;- verify(d$obs_rain, d$p24_rain,
    bins = FALSE)

mod48 &lt;- verify(d$obs_rain, d$p48_rain,
    bins = FALSE)
plot(mod24, freq = FALSE)

lines.attrib(mod48, col = "green",
    lwd = 2, type = "b")

</code></pre>

<hr>
<h2 id='brier'>Brier Score</h2><span id='topic+brier'></span>

<h3>Description</h3>

<p>Calculates verification statistics for
probabilistic forecasts of binary events.</p>


<h3>Usage</h3>

<pre><code class='language-R'>    brier(obs, pred, baseline, thresholds = seq(0,1,0.1), bins = TRUE, ... )
       </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="brier_+3A_obs">obs</code></td>
<td>
<p>Vector of binary observations </p>
</td></tr>
<tr><td><code id="brier_+3A_pred">pred</code></td>
<td>
<p>Vector of probablistic predictions [0,1] </p>
</td></tr>
<tr><td><code id="brier_+3A_baseline">baseline</code></td>
<td>
<p>Vector of climatological (no - skill) forecasts. If
this is null, a sample climatology will be calculated.</p>
</td></tr>
<tr><td><code id="brier_+3A_thresholds">thresholds</code></td>
<td>
<p>Values used to bin the forecasts.  By default the
bins are {[0,0.1), [0.1, 0.2), ....} .</p>
</td></tr>
<tr><td><code id="brier_+3A_bins">bins</code></td>
<td>
<p>If TRUE, thresholds define bins
into which the probablistic forecasts are entered and assigned
the midpoint as a forecast.  Otherwise, each unique forecast is considered as a 
seperate forecast.  For example, set bins to FALSE when dealing with a finite number of 
probabilities generated by an ensemble forecast.</p>
</td></tr>
<tr><td><code id="brier_+3A_...">...</code></td>
<td>
<p>Optional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>baseline.tf</code></td>
<td>
<p>Logical indicator of whether climatology was
provided.</p>
</td></tr>
<tr><td><code>bs</code></td>
<td>
<p>Brier score</p>
</td></tr>
<tr><td><code>bs.baseline</code></td>
<td>
<p>Brier Score for climatology</p>
</td></tr>
<tr><td><code>ss</code></td>
<td>
<p>Skill score</p>
</td></tr>
<tr><td><code>bs.reliability</code></td>
<td>
<p>Reliability portion of Brier score.</p>
</td></tr>
<tr><td><code>bs.resolution</code></td>
<td>
<p>Resolution component of Brier score.</p>
</td></tr>
<tr><td><code>bs.uncert</code></td>
<td>
<p>Uncertainty component of Brier score.</p>
</td></tr>
<tr><td><code>y.i</code></td>
<td>
<p>Forecast bins &ndash; described as the center value of
the bins.</p>
</td></tr>
<tr><td><code>obar.i</code></td>
<td>
<p>Observation bins &ndash; described as the center value
of the bins.</p>
</td></tr>
<tr><td><code>prob.y</code></td>
<td>
<p>Proportion of time using each forecast</p>
</td></tr>
<tr><td><code>obar</code></td>
<td>
<p>Forecast based on climatology or average sample
observations.</p>
</td></tr>
<tr><td><code>check</code></td>
<td>
<p> Reliability - resolution + uncertainty should
equal brier score.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is used within <code>verify</code>.</p>


<h3>Author(s)</h3>

<p>Matt Pocernich</p>


<h3>References</h3>

<p>Wilks, D. S. (1995) <em>Statistical Methods in the Atmospheric Sciences </em>
Chapter 7, San Diego: Academic Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#  probabilistic/ binary example

pred&lt;- runif(100)
obs&lt;- round(runif(100))
brier(obs, pred)

</code></pre>

<hr>
<h2 id='check.func'>check loss function</h2><span id='topic+check.func'></span>

<h3>Description</h3>

<p>Calculates the check loss function.</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.func(u, p)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check.func_+3A_u">u</code></td>
<td>
<p>Value to be evaluated</p>
</td></tr>
<tr><td><code id="check.func_+3A_p">p</code></td>
<td>
<p>Probability level [0,1]</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The check loss is calculated as <code class="reqn">\rho_{p} (u) = (abs(u) + (2*p-1)*u)/2</code>.
</p>


<h3>Value</h3>

<p>The check loss for value u and probability level p.
</p>


<h3>Note</h3>

<p>This function is used within <code>quantileScore</code>.</p>


<h3>Author(s)</h3>

<p>Sabrina Bentzien</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The function is currently defined as
function (u, p) 
{
    rho &lt;- (abs(u) + (2 * p - 1) * u) * 0.5
  }
</code></pre>

<hr>
<h2 id='conditional.quantile'>Conditional Quantile Plot</h2><span id='topic+conditional.quantile'></span>

<h3>Description</h3>

<p>This function creates a conditional quantile plot as shown in
Murphy, et al (1989) and Wilks (1995).</p>


<h3>Usage</h3>

<pre><code class='language-R'>    conditional.quantile(pred, obs, bins = NULL, thrs = c(10, 20), main, ... ) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="conditional.quantile_+3A_pred">pred</code></td>
<td>
<p>Forecasted value. <em>([n,1] vector, n = No. of forecasts)</em></p>
</td></tr>
<tr><td><code id="conditional.quantile_+3A_obs">obs</code></td>
<td>
<p>Observed value.<em>([n,1] vector, n = No. of observations)</em></p>
</td></tr>
<tr><td><code id="conditional.quantile_+3A_bins">bins</code></td>
<td>
<p>Bins for forecast and observed values.  A minimum number of
values are required to calculate meaningful statistics.  So for
variables that are continuous, such as temperature, it is frequently
convenient to bin these values. <em>([m,1] vector, m = No. of bins)</em></p>
</td></tr>
<tr><td><code id="conditional.quantile_+3A_thrs">thrs</code></td>
<td>
<p>The minimum number of values in a bin required to calculate
the 25th and 75th quantiles and the 10th and 90th percentiles
respectively.  The median values will always be displayed. <em>( [2,1]
vector)</em> </p>
</td></tr>
<tr><td><code id="conditional.quantile_+3A_main">main</code></td>
<td>
<p>Plot title</p>
</td></tr>
<tr><td><code id="conditional.quantile_+3A_...">...</code></td>
<td>
<p> Plotting options. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function produces a conditional.quantile plot.
The <code>y</code> axis represents the observed values, while the <code>x</code> axis
represents the forecasted values.  The histogram along the bottom axis
illustrates the frequency of each forecast.</p>


<h3>Note</h3>

<p>In the example below, the median line extends beyond the range of
the quartile or 10th and 90th percentile lines.  This is because there
are not enough points in each bin to calculate these quartile values.
That is, there are fewer than the limits set in the <code>thrs</code> input.</p>


<h3>Author(s)</h3>

<p>Matt Pocernich</p>


<h3>References</h3>

<p>Murphy, A. H., B. G. Brown and Y. Chen. (1989) Diagnostic Verification of Temperature Forecasts. <em>Weather and Forecasting</em>, <b>4</b>, 485&ndash;501.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(10)
m&lt;- seq(10, 25, length = 1000)  
frcst &lt;- round(rnorm(1000, mean = m, sd = 2) )
obs&lt;- round(rnorm(1000, mean = m, sd = 2 ))
bins &lt;- seq(0, 30,1)
thrs&lt;- c( 10, 20) # number of obs needed for a statistic to be printed #1,4 quartile, 2,3 quartiles

conditional.quantile(frcst, obs, bins, thrs, main = "Sample Conditional Quantile Plot")
#### Or plots a ``cont.cont'' class object.

obs&lt;- rnorm(100)
pred&lt;- rnorm(100)
baseline &lt;- rnorm(100, sd = 0.5) 

A&lt;- verify(obs, pred, baseline = baseline,  frcst.type = "cont", obs.type = "cont")
 plot(A)
</code></pre>

<hr>
<h2 id='crps'>Continuous Ranked Probability Score</h2><span id='topic+crps'></span>

<h3>Description</h3>

<p>Calculates the crps for a forecast made in terms of
a normal probability distribution and an observation expressed
in terms of a continuous variable.</p>


<h3>Usage</h3>

<pre><code class='language-R'>    crps(obs, pred, ...)
       </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crps_+3A_obs">obs</code></td>
<td>
<p>A vector of observations.</p>
</td></tr>
<tr><td><code id="crps_+3A_pred">pred</code></td>
<td>
<p>A vector or matrix of the mean and standard
deviation of a normal distribution.  If the vector has a
length of 2, it is assumed that these values represent the
mean and standard deviation of the normal distribution that
will be used for all forecasts.</p>
</td></tr>
<tr><td><code id="crps_+3A_...">...</code></td>
<td>
<p>Optional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>crps</code></td>
<td>
<p>Continous ranked probability scores</p>
</td></tr>
<tr><td><code>CRPS</code></td>
<td>
<p>Mean of crps</p>
</td></tr>
<tr><td><code>ign</code></td>
<td>
<p>Ignorance score</p>
</td></tr>
<tr><td><code>IGN</code></td>
<td>
<p>Mean of the ignorance score</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is used within <code>verify</code>.</p>


<h3>Author(s)</h3>

<p>Matt Pocernich</p>


<h3>References</h3>

<p>Gneiting, T., Westveld, A., Raferty, A. and Goldman, T, 2004:
<em>Calibrated Probabilistic Forecasting Using Ensemble Model Output
Statistics and Minimum CRPS Estimation.</em> Technical Report no. 449,
Department of Statistics, University of Washington. [ Available online
at <a href="http://www.stat.washington.edu/www/research/reports/">http://www.stat.washington.edu/www/research/reports/</a> ]</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#  probabilistic/ binary example


x &lt;- runif(100) ## simulated observation.
crps(x, c(0,1))

## simulated forecast in which mean and sd differs for each forecast.
frcs&lt;- data.frame( runif(100, -2, 2), runif(100, 1, 3 ) )
crps(x, frcs)

</code></pre>

<hr>
<h2 id='crpsDecompostion'>Decompostion of Continuous Ranked Probability Score</h2><span id='topic+crpsDecomposition'></span><span id='topic+crpsFromAlphaBeta'></span>

<h3>Description</h3>

<p>The CRPS measures the distance between the predicted and the observed cumulative density functions (CDFs) of scalar variables. Furthermore, the crpsDecomposition function provides the reliability and resolution terms obtained by the CRPS decomposition proposed by Hersbach. The alpha, beta matrices and Heavisides vectors of outliers calculated in the CRPS decomposition are also returned. To speed up calculation time, these matrices/vectors can then be used to recalculate the CRPS's in a bootstrap by using the crpsFromAlphaBeta function.</p>


<h3>Usage</h3>

<pre><code class='language-R'>      crpsDecomposition(obs, eps)
      crpsFromAlphaBeta(alpha,beta,heaviside0,heavisideN)
       </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crpsDecompostion_+3A_obs">obs</code></td>
<td>
<p>Vector of observations</p>
</td></tr>
<tr><td><code id="crpsDecompostion_+3A_eps">eps</code></td>
<td>
<p>Matrix of ensemble forecast. Each column represent a member.</p>
</td></tr>
<tr><td><code id="crpsDecompostion_+3A_alpha">alpha</code></td>
<td>
<p>Matrix of alpha (returned from crpsDecomposition)</p>
</td></tr>
<tr><td><code id="crpsDecompostion_+3A_beta">beta</code></td>
<td>
<p>Vector of beta (returned from crpsDecomposition)</p>
</td></tr>
<tr><td><code id="crpsDecompostion_+3A_heaviside0">heaviside0</code></td>
<td>
<p>Vector of Heaviside for outlier i=0 (returned from crpsDecomposition)</p>
</td></tr>
<tr><td><code id="crpsDecompostion_+3A_heavisiden">heavisideN</code></td>
<td>
<p>Vector of Heaviside for outlier i=N (returned from crpsDecomposition)</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>CRPS</code></td>
<td>
<p>CRPS score</p>
</td></tr>
<tr><td><code>CRPSpot</code></td>
<td>
<p>The potential CRPS (Resolution - Uncertainty)</p>
</td></tr>
<tr><td><code>Reli</code></td>
<td>
<p>The Reliability term of the CRPS</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>Matrix (Nobservation rows x Nmember +1 columns) of alpha used in the CRPS decomposition.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>Matrix (Nobservation rows x Nmember +1 columns) of beta used in the CRPS decomposition.</p>
</td></tr>
<tr><td><code>heaviside0</code></td>
<td>
<p>Vector (Nobservation length) of Heaviside for outlier i=0 used in the CRPS decomposition</p>
</td></tr>
<tr><td><code>heavisideN</code></td>
<td>
<p>Vector (Nobservation length) of Heaviside for outlier i=N used in the CRPS decomposition</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ronald Frenette &lt;Ronald.Frenette@ec.gc.ca&gt;</p>


<h3>References</h3>

<p>G. Candille,  P. L. Houtekamer, and G. Pellerin: Verification of an Ensemble Prediction System against Observations, <em>Monthly Weather Review</em>,<b>135</b>, pp. 2688-2699 
</p>
<p>Hershcach, Hans, 2000. Decomposition of the Continuous Ranked Probability Score for Ensemble Prediction Systems. <em>Weather and Forecasting</em>, <b>15</b>, (5) pp. 559-570.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(precip.ensemble)
x &lt;- precip.ensemble[seq(5,5170,5),]

#Observations are in the column
obs&lt;-x[,3]

#Forecast values of ensemble are in the column 4 to 54
eps&lt;-x[,4:54]

#CRPS calculation 
c&lt;-crpsDecomposition(obs,eps)

#CRPS with alpha and beta
#Resampling indices
nObs&lt;-length(obs)
i&lt;-sample(seq(nObs),nObs,replace=TRUE)
crps2&lt;-crpsFromAlphaBeta(c$alpha[i,],c$beta[i,],c$heaviside0[i],c$heavisideN[i])

</code></pre>

<hr>
<h2 id='disc.dat'> Discrimination plot dataset.</h2><span id='topic+disc.dat'></span>

<h3>Description</h3>

<p>This dataset is used to illustrate the <code><a href="#topic+discrimination.plot">discrimination.plot</a></code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(disc.dat)</code></pre>

<hr>
<h2 id='discrimination.plot'>Discrimination  plot</h2><span id='topic+discrimination.plot'></span>

<h3>Description</h3>

<p>This function creates a plot of discrimination plots
(overlay histograms).   In the context of verification, this is often
used to compare the distribution of event and no-event
forecasts.  This may be useful in comparing any set of
observations. By default, boxplots of groups appear as upper
marginal plots.  These may be surpressed. </p>


<h3>Usage</h3>

<pre><code class='language-R'>discrimination.plot(group.id, value, breaks = 11, main =
"Discrimination Plot", xlim = NULL, ylim = NULL,  legend =
FALSE, leg.txt = paste("Model", sort(unique(group.id)) ),   marginal = TRUE, cols =
seq(2, length(unique(group.id)) + 1), xlab = "Forecast",  ... )</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="discrimination.plot_+3A_group.id">group.id</code></td>
<td>
<p>A vector identifying groups.  A histogram is
created for each unique value.</p>
</td></tr>
<tr><td><code id="discrimination.plot_+3A_value">value</code></td>
<td>
<p>A vector of values corresponding to the group.id
vector used to create the histograms</p>
</td></tr>
<tr><td><code id="discrimination.plot_+3A_breaks">breaks</code></td>
<td>
<p>Number of breaks in the x-axis of the histogram.
The range of values is taken to be the range of prediction values.</p>
</td></tr>
<tr><td><code id="discrimination.plot_+3A_main">main</code></td>
<td>
<p>Title for plot.</p>
</td></tr>
<tr><td><code id="discrimination.plot_+3A_xlim">xlim</code></td>
<td>
<p>Range of histogram - x axis - main plot coordinates.</p>
</td></tr>
<tr><td><code id="discrimination.plot_+3A_ylim">ylim</code></td>
<td>
<p>Range of histogram - y axis - main plot coordinates.</p>
</td></tr>
<tr><td><code id="discrimination.plot_+3A_legend">legend</code></td>
<td>
<p>Should there be a legend? Default = FALSE</p>
</td></tr>
<tr><td><code id="discrimination.plot_+3A_leg.txt">leg.txt</code></td>
<td>
<p>Legend text.  If FALSE or if a marginal plot is
created, no legend is added.</p>
</td></tr>
<tr><td><code id="discrimination.plot_+3A_cols">cols</code></td>
<td>
<p>A vector showing the colors to be used in the
histograms and in the marginal boxplots</p>
</td></tr>
<tr><td><code id="discrimination.plot_+3A_marginal">marginal</code></td>
<td>
<p>Should a boxplots be placed in the top margin?
Defaults to TRUE</p>
</td></tr>
<tr><td><code id="discrimination.plot_+3A_xlab">xlab</code></td>
<td>
<p> Label of the x-axis on the main plot.</p>
</td></tr>
<tr><td><code id="discrimination.plot_+3A_...">...</code></td>
<td>
<p>Additional plotting options.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matt Pocernich</p>


<h3>Examples</h3>

<pre><code class='language-R'> #  A sample forecast.  

data(disc.dat)
discrimination.plot(disc.dat$group.id, disc.dat$frcst, main = "Default  Plot")

discrimination.plot(disc.dat$group.id, disc.dat$frcst, main = "New Labels", cex = 1.2,
leg.txt = c("Low", "Med", "High" ) )

discrimination.plot(disc.dat$group.id, disc.dat$frcst, main = "Without Marginal Plots ",
marginal = FALSE)


 </code></pre>

<hr>
<h2 id='fss'>Fractional Skill Score</h2><span id='topic+fss'></span>

<h3>Description</h3>

<p>Calculates the fractional skill score for spatial forecasts and spatial observations.</p>


<h3>Usage</h3>

<pre><code class='language-R'>    fss(obs, pred,w = 0, FUN = mean, ...)
       </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fss_+3A_obs">obs</code></td>
<td>
<p>A matrix of binomial observed values.</p>
</td></tr>
<tr><td><code id="fss_+3A_pred">pred</code></td>
<td>
<p>A matrix of binomial forecasted values</p>
</td></tr>
<tr><td><code id="fss_+3A_w">w</code></td>
<td>
<p> Box width.  When w = 0, each pixel is considered alone.  w = 2 creates a box with a length of 5  units.</p>
</td></tr>
<tr><td><code id="fss_+3A_fun">FUN</code></td>
<td>
<p>Function to be applied to each subgrid.  By default, the mean of each box is used to calculate the fraction of each subgrid. </p>
</td></tr>
<tr><td><code id="fss_+3A_...">...</code></td>
<td>
<p>Optional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return the fraction skill score.</p>


<h3>Note</h3>

<p>This function contain several loops and consequently is not particularly fast.</p>


<h3>Author(s)</h3>

<p>Matt Pocernich</p>


<h3>References</h3>

<p>Roberts, N.M and H.W. Lean: 2008: Scale-Selective Verification of Rainfall Accumulations from High-Resolution Forecasts of Convective Events.  <em>Monthly Weather Review</em> <b>136</b>, 78-97.</p>


<h3>Examples</h3>

<pre><code class='language-R'>grid&lt;- list( x= seq( 0,5,,100), y= seq(0,5,,100)) 
obj&lt;-Exp.image.cov( grid=grid, theta=.5, setup=TRUE)
look&lt;- sim.rf( obj)
look[look &lt; 0] &lt;- 0

look2 &lt;- sim.rf( obj)
look2[look2&lt;0] &lt;- 0

fss(look, look2, w=5)


## Not run: 
#  The following example replicates Figure 4 in Roberts and Lean (2008).
####      examples

LAG &lt;- c(1,3,11,21)
box.radius &lt;- seq(0,24,2)

OUT &lt;- matrix(NA, nrow = length(box.radius), ncol = length(LAG) )

for(w in 1:4){

FRCS &lt;- OBS &lt;- matrix(0, nrow = 100, ncol = 100)

obs.id        &lt;- 50
OBS[,obs.id]  &lt;- 1

FRCS[, obs.id + LAG[w]] &lt;- 1

for(i in 1:length(box.radius)){

OUT[i, w] &lt;- fss(obs = OBS, pred = FRCS, w = box.radius[i] )

} ### close i
} ### close w

b &lt;- mean(OBS) ## base rate

fss.uniform  &lt;- 0.5 + b/2
fss.random   &lt;- b

matplot(OUT, ylim = c(0,1), ylab = "FSS", xlab = "grid squares", 
type = "b", lty = 1, axes = FALSE , lwd = 2)

abline(h = c(fss.uniform, fss.random), lty = 2)  
axis(2)
box()
axis(1, at = 1:length(box.radius), lab = 2*box.radius + 1)
grid()

legend("bottomright", legend = LAG, col = 1:4, pch = as.character(1:4), 
 title = "Spatial Lag", inset = 0.02, lwd = 2 )

## End(Not run)

</code></pre>

<hr>
<h2 id='leps'>Linear Error in Probability Space (LEPS) </h2><span id='topic+leps'></span>

<h3>Description</h3>

<p>Calculates the linear error in probability spaces.
This is the mean absolute difference between the forecast
cumulative distribution value (cdf) and the observation.  This
function creates the empirical cdf function for the observations
using the sample population.  Linear interpretation is used to
estimate the cdf values between observation values.  Therefore;
this may produce awkward results with small datasets.</p>


<h3>Usage</h3>

<pre><code class='language-R'> leps(x, pred, plot = TRUE, ... )
                         </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="leps_+3A_x">x</code></td>
<td>
<p>A vector of observations or a verification object with &ldquo;cont.cont&rdquo; properties.</p>
</td></tr>
<tr><td><code id="leps_+3A_pred">pred</code></td>
<td>
<p>A vector of predictions.</p>
</td></tr>  
<tr><td><code id="leps_+3A_plot">plot</code></td>
<td>
<p>Logical to generate a plot or not.</p>
</td></tr>
<tr><td><code id="leps_+3A_...">...</code></td>
<td>
<p>Additional plotting options.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If assigned to an object, the following values are reported.
</p>
<table>
<tr><td><code>leps.0</code></td>
<td>
<p>Negatively oriented score on the [0,1] scale, where 0
is a perfect score.</p>
</td></tr>
<tr><td><code>leps.1</code></td>
<td>
<p>Positively oriented score proposed by Potts.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matt Pocernich</p>


<h3>References</h3>

<p>DeQue, Michel. (2003) &ldquo;Continuous Variables&rdquo; <b>Chapter 5</b>,
<em>Forecast Verification: A Practitioner's Guide in Atmospheric
Science.</em>
</p>
<p>Potts, J. M., Folland, C.K., Jolliffe, I.T. and Secton, D. (1996)
&ldquo;Revised &lsquo;LEPS&rsquo; scores fore assessing climate model simulations and
long-range forecasts.&rdquo; <em>J. Climate</em>, <b>9</b>, pp. 34-54.
</p>




<h3>Examples</h3>

<pre><code class='language-R'> obs &lt;- rnorm(100, mean = 1, sd = sqrt(50))
 pred&lt;-  rnorm(100, mean = 10, sd = sqrt(500))

 leps(obs, pred, main = "Sample Plot") 
## values approximated

OBS &lt;- c(2.7, 2.9, 3.2, 3.3, 3.4, 3.4, 3.5, 3.8, 4, 4.2, 4.4, 4.4, 4.6,
5.8, 6.4)
PRED &lt;- c(2.05, 3.6, 3.05, 4.5, 3.5, 3.0, 3.9, 3.2, 2.4, 5.3, 2.5, 2.8,
3.2, 2.8, 7.5)

a &lt;- leps(OBS, PRED)
a
</code></pre>

<hr>
<h2 id='lines.verify'>Add lines to ROC or attribute diagrams</h2><span id='topic+lines.roc'></span><span id='topic+lines.attrib'></span>

<h3>Description</h3>

<p>Add lines to attribute and verification diagrams from verify.prob.bin objects.</p>


<h3>Usage</h3>

<pre><code class='language-R'>       ## S3 method for class 'roc'
lines(x,binormal = FALSE, ...)
        ## S3 method for class 'attrib'
lines(x,...)
       </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lines.verify_+3A_x">x</code></td>
<td>
<p>An object created by the verify function with the prob.bin class</p>
</td></tr>
<tr><td><code id="lines.verify_+3A_binormal">binormal</code></td>
<td>
<p>Logical value indicating whether the lines to be added to a ROC plot are empirical or a binormal fit. </p>
</td></tr>
<tr><td><code id="lines.verify_+3A_...">...</code></td>
<td>
<p>Optional arguments for the lines function.  These include color, line weight (ltw) and line stype (lty) </p>
</td></tr>
</table>


<h3>Note</h3>

<p> This will soon be replaced the a lines command constructed using S4 class properites. </p>


<h3>Author(s)</h3>

<p>Matt Pocernich</p>


<h3>See Also</h3>

<p><code><a href="#topic+verify">verify</a></code>  </p>

<hr>
<h2 id='measurement.error'>Skill score with measurement error.</h2><span id='topic+measurement.error'></span>

<h3>Description</h3>

<p>Skill score that incorporates measurement error.
This function allows the user to incorporate measurement error
in an observation in a skill score.</p>


<h3>Usage</h3>

<pre><code class='language-R'>measurement.error( obs, frcs = NULL, theta = 0.5, CI =
          FALSE, t = 1, u = 0, h = NULL, ...)
       </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="measurement.error_+3A_obs">obs</code></td>
<td>
<p>Information about a forecast and observation can be
done in one of two ways.  First,  the results of a
contingency table can be entered as a vector containing
c(n11, n10, n01, n00), where n11 are the number of correctly
predicted events and n01 is the number of incorrectly
predicted non-events.  Actual forecasts and observations can
be used.  In this case, obs is a vector of binary outcomes
[0,1].</p>
</td></tr>
<tr><td><code id="measurement.error_+3A_frcs">frcs</code></td>
<td>
<p>If obs is entered as a contingency table, this
argument is null.  If obs is a vector of outcomes, this
column is a vector of probabilistic forecasts.</p>
</td></tr>
<tr><td><code id="measurement.error_+3A_theta">theta</code></td>
<td>
<p>Loss value (cost) of making a incorrect forecast
by a non-event. Defaults to 0.5.</p>
</td></tr>
<tr><td><code id="measurement.error_+3A_ci">CI</code></td>
<td>
<p>Calculate confidence intervals for skill score.</p>
</td></tr>
<tr><td><code id="measurement.error_+3A_t">t</code></td>
<td>
<p>Probability of forecasting an event, when an event
occurs.  A perfect value is 1.</p>
</td></tr>
<tr><td><code id="measurement.error_+3A_u">u</code></td>
<td>
<p>Probability of forecasting that no event will occur,
when and event occurs.  A perfect value is 0.</p>
</td></tr>
<tr><td><code id="measurement.error_+3A_h">h</code></td>
<td>
<p>Threshold for converting a probabilistic forecast into
a binary forecast.  By default, this value is NULL and the
theta is used as this threshold.</p>
</td></tr>
<tr><td><code id="measurement.error_+3A_...">...</code></td>
<td>
<p>Optional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>z</code></td>
<td>
<p>Error code</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>Skill score</p>
</td></tr>
<tr><td><code>G</code></td>
<td>
<p>Likelihood ratio statistic</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>p-value for the null hypothesis that the forecast
contains skill.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Loss value.  Loss associated with an incorrect
forecast of a non-event.</p>
</td></tr>
<tr><td><code>ciLO</code></td>
<td>
<p>Lower confidence interval</p>
</td></tr>
<tr><td><code>ciHI</code></td>
<td>
<p>Upper confidence interval</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matt Pocernich (R - code)
</p>
<p>W.M Briggs &lt;wib2004(at)med.cornell.edu&gt; (Method questions) </p>


<h3>References</h3>

<p>W.M. Briggs, 2004.  <em>Incorporating Cost in the  Skill Score</em>
Technical Report, wm-briggs.com/public/skillocst.pdf. 
</p>
<p>W.M. Briggs and D. Ruppert, 2004. <em> Assessing the skill
of yes/no forecasts. Submitting to Biometrics</em>.
</p>
<p>J.P. Finley, 1884. Tornado forecasts. <em> Amer. Meteor. J.</em>
85-88. (Tornado data used in example.)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>DAT&lt;- data.frame( obs = round(runif(50)), frcs = runif(50))

A&lt;-   measurement.error(DAT$obs, DAT$frcs, CI = TRUE)
A
### Finley Data

measurement.error(c(28, 23, 72, 2680)) ## assuming perfect observation,
                                       
     </code></pre>

<hr>
<h2 id='multi.cont'>Multiple Contingency Table Statistics </h2><span id='topic+multi.cont'></span>

<h3>Description</h3>

<p>Provides a variety of statistics for a data
summarized in a contingency table.  This will work for a 2 by 2
table, but is more useful for tables of greater dimensions.</p>


<h3>Usage</h3>

<pre><code class='language-R'>multi.cont(DAT, baseline = NULL)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multi.cont_+3A_dat">DAT</code></td>
<td>
<p>A contingency table in the form of a matrix.  It is
assumed that columns represent observation, rows represent
forecasts.</p>
</td></tr>
<tr><td><code id="multi.cont_+3A_baseline">baseline</code></td>
<td>
<p>A vector indicating the baseline probabilities of each category.  By default, it the baseline or naive forecasts is based on teh </p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>pc</code></td>
<td>
<p>Percent correct - events along the diagonal.</p>
</td></tr>
<tr><td><code>bias</code></td>
<td>
<p>Bias</p>
</td></tr>
<tr><td><code>ts</code></td>
<td>
<p>Threat score a.k.a. Critical success index (CSI) </p>
</td></tr>
<tr><td><code>hss</code></td>
<td>
<p>Heidke Skill Score</p>
</td></tr>
<tr><td><code>pss</code></td>
<td>
<p>Peirce Skill Score</p>
</td></tr>
<tr><td><code>gs</code></td>
<td>
<p>Gerrity Score</p>
</td></tr>
<tr><td><code>pc2</code></td>
<td>
<p>Percent correct by category (vector)</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>Hit Rate by category (vector)</p>
</td></tr>
<tr><td><code>false.alarm.ratio</code></td>
<td>
<p>False alarm ratio by category (vector)</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Some verification statistics for a contingency table assume that the forecasts and observations are ordered, while others do not.  An example of an ordered or ordinal forecast is &quot;low, medium and high&quot;.  An example of an unordered or nominal forecast is &quot;snow, rain, hail, and none.&quot;  If the forecasts are ordered, it is possible to account for forecasts which are close to the the observed value.  For example, the Gerrity score takes this closeness into account.  The Pierce Skill Score does not.  
</p>
<p>For ordered forecast, it is assumed that the columns and rows of the input matrix are ordered sequentially. 
</p>
<p>When multiple values are returned, as in the case of pc2, h, f and false.alarm.ratio, these values are conditioned on that category having occurred.  For example, in the example included in Jolliffe, given that a below average temperature was observed, the forecast had a bias of 2.3 and had a 0.47 chance of being detected.
</p>


<h3>Author(s)</h3>

<p>Matt Pocernich</p>


<h3>References</h3>

<p>Gerrity, J.P. Jr (1992).  A  note on Gandin and Murphy's equitable skill 
score. <em>Mon. Weather Rev.</em>, <b>120</b>, 2707-2712.
</p>
<p>Jolliffe, I.T. and D.B. Stephenson (2003). Forecast verification: a 
practitioner's guide in atmospheric science. John Wiley and Sons.  See
chapter 4 concerning categorical events, written by R. E. Livezey.
</p>


<h3>See Also</h3>

<p><code>binary.table</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>DAT&lt;- matrix(c(7,4,4,14,9,8,14,16,24), nrow = 3) # from p. 80 - Jolliffe
multi.cont(DAT)

DAT&lt;- matrix(c(3,8,7,8,13,14,4,18,25), ncol = 3) ## Jolliffe JJA
multi.cont(DAT)

DAT&lt;- matrix(c(50,47,54,91,2364,205,71,170,3288), ncol = 3) # Wilks p. 245
multi.cont(DAT)

DAT&lt;- matrix(c(28, 23, 72, 2680 ), ncol = 2) ## Finley
multi.cont(DAT)
## Finnish clouds
DAT&lt;- matrix(c(65, 10, 21, 29,17,48, 18, 10, 128), nrow = 3, ncol = 3, byrow = TRUE)
multi.cont(DAT)  
 ### alternatively, the verify function and summary can be used.
 
 mod &lt;- verify(DAT, frcst.type = "cat", obs.type = "cat")
 summary(mod)
 
 </code></pre>

<hr>
<h2 id='observation.error'>Observation Error</h2><span id='topic+observation.error'></span>

<h3>Description</h3>

<p>Quantifies observation error through use of a &ldquo;Gold
Standard&rdquo; of observations.</p>


<h3>Usage</h3>

<pre><code class='language-R'>observation.error(obs, gold.standard = NULL, ...) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="observation.error_+3A_obs">obs</code></td>
<td>
<p>Observation made by method to be quantified.   This
information can be entered two ways.  If obs is a vector of
length 4, it is assumed that is contains the values c(n11,
n10, n01, n00), where n11 are the number of correctly
predicted events and n01 is the number of incorrectly
predicted non-events.  </p>
</td></tr>
<tr><td><code id="observation.error_+3A_gold.standard">gold.standard</code></td>
<td>
<p>The gold standard.  This is considered a
higher quality observation (coded {0, 1 } ).</p>
</td></tr>
<tr><td><code id="observation.error_+3A_...">...</code></td>
<td>
<p>Optional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>t</code></td>
<td>
<p>Probability of forecasting an event, when an event
occurs.  A perfect value is 1. </p>
</td></tr>
<tr><td><code>u</code></td>
<td>
<p>Probability of forecasting that no event will occur,
when and event occurs.  A perfect value is 0. </p>
</td></tr>
</table>


<h3>Note</h3>

<p> This function is used to calculate values for the
<code><a href="#topic+measurement.error">measurement.error</a></code> function.</p>


<h3>Author(s)</h3>

<p>Matt Pocernich</p>


<h3>See Also</h3>

<p><code><a href="#topic+measurement.error">measurement.error</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>obs &lt;- round(runif(100))
gold &lt;- round(runif(100) )
observation.error(obs, gold)

## Pirep gold standard

observation.error(c(43,10,17,4) )
</code></pre>

<hr>
<h2 id='performance.diagram'>Performance Diagram</h2><span id='topic+performance.diagram'></span>

<h3>Description</h3>

<p>Creates plot displaying multiple skill scores on a single plot</p>


<h3>Usage</h3>

<pre><code class='language-R'> performance.diagram(...) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="performance.diagram_+3A_...">...</code></td>
<td>
<p>Optional plotting parameters.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Currently this function just produces the base plot.  Points summarizing model performance can be added using the points function. 
</p>


<h3>Author(s)</h3>

<p>Matt Pocernich</p>


<h3>References</h3>

<p>Roebber, P.J. (2009). Visualizing Multiple Measures of Forecast Quality, <em>Weather and Forecasting</em>. <b>24</b>, pp - 601 - 608.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>performance.diagram(main = "Sample Plot")
RB1 &lt;- matrix(c(95, 55, 42, 141), ncol = 2)
## at point
pts     &lt;- table.stats(RB1)
boot.pts &lt;- table.stats.boot(RB1, R = 100   )
## add confidence intervals
segments(x0=1-pts$FAR, y0=boot.pts["up","pod"],
    x1=1-pts$FAR, y1=boot.pts["dw", "pod"], col=2, lwd=2)

segments(x0=1-boot.pts["up","far"], y0=pts$POD,
    x1=1-boot.pts["dw","far"], y1=pts$POD, col=2, lwd=2)
points(1 - pts$FAR, pts$POD, col = 2, cex = 2)


</code></pre>

<hr>
<h2 id='pop'> Probability of precipitation (pop) data. </h2><span id='topic+pop'></span>

<h3>Description</h3>

<p>These datasets are used to illustrate several functions including
<code><a href="#topic+value">value</a></code> and <code><a href="#topic+roc.plot">roc.plot</a></code>.
</p>
<p>These forecasts are summaries of 24-hour  probability of precipitation
forecasts that were made by the Finnish Meteorological Institute (FMI) during 2003, for daily
precipitation in the city of Tampere in south central Finland.  Light
precipitation is considered rainfall greater than .2 mm.  Rainfall
accumulation is considered values greater than 4.4 mm.  Rows of data
either missing forecasts or observations have been removed.
</p>
<p>This data has been kindly provided by Dr. Pertti Nurmi of the Finnish
Meteorological Institute. 
<a href="http://www.cawcr.gov.au/projects/verification/POP3/POP3.html">http://www.cawcr.gov.au/projects/verification/POP3/POP3.html</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(pop)</code></pre>

<hr>
<h2 id='precip.ensemble'>
An ensemble of precipitation forecasts 
</h2><span id='topic+precip.ensemble'></span>

<h3>Description</h3>

<p>This is an example of an ensemble of precipitation forecasts.  The
data set contains forecast for 517 days (3 monsoon seasons) at lead
times of 1 to 10 days.  Observations and forecasts are in millimeters.
</p>

<hr>
<h2 id='predcomp.test'>
Time Series Prediction Comparison Test
</h2><span id='topic+predcomp.test'></span><span id='topic+losserr'></span><span id='topic+exponentialACV'></span><span id='topic+summary.predcomp.test'></span>

<h3>Description</h3>

<p>Forecast prediction comparison test for two competing forecasts against an observation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predcomp.test(x, xhat1, xhat2, alternative = c("two.sided", "less", "greater"),
    lossfun = "losserr", lossfun.args = NULL, test = c("DM", "HG"), ...)

losserr(x, xhat, method = c("abserr", "sqerr", "simple", "power", 
    "corrskill", "dtw"), scale = 1, p = 1, dtw.interr = c("abserr", 
    "sqerr", "simple", "power"), ...)

exponentialACV(x, y, ...)

## S3 method for class 'predcomp.test'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predcomp.test_+3A_x">x</code>, <code id="predcomp.test_+3A_xhat1">xhat1</code>, <code id="predcomp.test_+3A_xhat2">xhat2</code>, <code id="predcomp.test_+3A_xhat">xhat</code></td>
<td>
<p>numeric vectors giving the verification data and each competing forecast model output (1 and 2).  For <code>losserr</code>, <code>xhat</code> is a numeric giving a single forecast model output (i.e., by default the function is called internally by <code>predcomp.test</code> once for <code>xhat1</code> and once for <code>xhat2</code>). For <code>exponentialACV</code>, see argument <code>y</code> below.</p>
</td></tr>
<tr><td><code id="predcomp.test_+3A_y">y</code></td>
<td>

<p><code>x</code> for <code>exponentialACV</code> is a numeric giving the separation distance, and <code>y</code> a numeric giving the autocovariance values.
</p>
</td></tr>
<tr><td><code id="predcomp.test_+3A_object">object</code></td>
<td>
<p>list object of class &ldquo;predcomp.test&rdquo; as returned by <code>predcomp.test</code>.</p>
</td></tr>
<tr><td><code id="predcomp.test_+3A_alternative">alternative</code></td>
<td>
<p>character string stating which type of hypothesis test to conduct.</p>
</td></tr>
<tr><td><code id="predcomp.test_+3A_lossfun">lossfun</code></td>
<td>
<p>character string naming the loss function to call.  The default, <code>losserr</code>, calls one of several methods depending on its <code>method</code> argument.  Any function that takes <code>x</code> and <code>xhat</code> numeric vectors as arguments and returns a numeric vector of the same length can be used.</p>
</td></tr>
<tr><td><code id="predcomp.test_+3A_lossfun.args">lossfun.args</code></td>
<td>
<p>List providing additional arguments to <code>lossfun</code>.</p>
</td></tr>
<tr><td><code id="predcomp.test_+3A_test">test</code></td>
<td>
<p>character string stating whether to run the Diebold-Mariano type of test or the Hering-Genton modification of it (i.e., use a parametric autocovariance function).</p>
</td></tr>
<tr><td><code id="predcomp.test_+3A_method">method</code>, <code id="predcomp.test_+3A_dtw.interr">dtw.interr</code></td>
<td>
<p>character string stating which type of loss (or skill) function to use.  In the case of <code>dtw.interr</code>, this is the loss function for the intensity part of the error only.</p>
</td></tr>
<tr><td><code id="predcomp.test_+3A_scale">scale</code></td>
<td>
<p>numeric giving a value by which to scale the loss function.  In the case of &ldquo;<code>dtw</code>&rdquo;, this is only applied to the intensity part of the loss function, and can be used to scale the influence of the intensity vs. temporal lag errors.  See Details section for more.</p>
</td></tr>
<tr><td><code id="predcomp.test_+3A_p">p</code></td>
<td>
<p>numeric only used by the &ldquo;power&rdquo; loss function.</p>
</td></tr>
<tr><td><code id="predcomp.test_+3A_...">...</code></td>
<td>
<p>For <code>predcomp.test</code>, these are any additional arguments to the <code>acf</code> function besides <code>x</code>, <code>type</code> and <code>plot</code>, which may not be passed.
</p>
<p>For <code>losserr</code>, these are any additional arguments to <code>dtw</code> except for <code>x</code>, <code>y</code>, and <code>step.pattern</code>, which may not be passed.
</p>
<p>For <code>exponentialACV</code> these are any optional arguments to <code>nls</code> except for <code>formula</code> and <code>data</code>.  If <code>start</code> is not passed, then reasonable starting values are calculated and passed in for this argument.
</p>
<p>For the <code>summary</code> method function, these are not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs the analyses described in Gilleland and Roux (2014); although note that while working on another manuscript (Gilleland and Hering, in preparation), a better optimization routine has replaced the one used in said paper, which has been thoroughly tested to yield good size and power under a variety of temporal dependence structures, as well as having far fewer situations where a fit cannot be found.  Namely, the Diebold Mariano test for competing forecast performance, the Hering and Genton (2011) modification of this test, as well as the dynamic time warping extension.
</p>
<p>The Diebold-Mariano test was proposed in Diebold and Mariano (1995) for obtaining hypothesis tests to compare the forecast accuracy of two competing forecasts against a common verification series.  The null hypothesis is that they have the same accuracy.  The test statistic is of the form
</p>
<p>S = dbar/sqrt(2*pi*se_d(0)/N),
</p>
<p>where d is the loss differential, d = e1 - e2 (e1 = loss(x, xhat1) and e2 = loss(x, xhat2)), dbar is its sample mean, and se_d(0) is the standard error for d, which must be estimated, and N is the length of the series investigated.  Let V = 2*pi*se_d(0), then V is estimated by
</p>
<p>V = sum(gamma(tau)),
</p>
<p>where the summation is over tau = -(k - 1) to (k - 1) for temporal lags k, and gamma are the empirical autocovariances.  
</p>
<p>Hering and Genton (2011) propose a modification that employs fitting a parameteric covariance model in determining the standard error for the test statistic (they also propose a spatial extension, see, e.g., <code>spatMLD</code> from <span class="pkg">SpatialVx</span>).
</p>
<p>In either case, asymptotic results suggest that S ~ N(0,1), and the hypothesis test is conducted subsequently.
</p>
<p>Discrete time warping can be applied (see examples below) in order to obtain a loss function based on location (in time) and intensity errors similar to the spatial version in Gilleland (2013).
</p>
<p>The loss functions supplied by <code>losserr</code> include:
</p>
<p><code>abserr</code>: Absolute error loss, defined by abs((xhat - x)/scale),
</p>
<p><code>sqerr</code>: Square error loss, defined by ((xhat - x)/scale)^2,
</p>
<p><code>simple</code>: Simple loss, defined by (xhat - x)/scale,
</p>
<p><code>power</code>: Power loss, defined by ((xhat - x)/scale)^p (same as <code>sqerr</code> if <code>p</code>=2),
</p>
<p><code>corrskill</code>: Correlation skill defined by scale * (x - mean(x)) * (xhat - mean(xhat)),
</p>
<p><code>dtw</code>: Discrete time warp loss defined by: d1 + d2, where d1 is the absolute distance (ignoring direction) of warp movement, and d2 is one of the above loss functions (except for <code>corrskill</code>) applied to the resulting intensity errors after warping the series.
</p>
<p>The <code>exponential</code> function takes numeric vector arguments <code>x</code> and <code>y</code> and estimates the parameters, <code>c(sigma, theta)</code>, that optimize
</p>
<p>y = sigma^2*exp(-3*x/theta)
</p>


<h3>Value</h3>

<p><code>predcomp.test</code> returns a list object of class c(&ldquo;predcomp.test&rdquo;, &ldquo;htest&rdquo;) with components:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>the calling string</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>character string giving the full name of the method (Diebold-Mariano or Hering-Genton) used.</p>
</td></tr>
<tr><td><code>fitmodel</code></td>
<td>
<p>character naming the function used to fit the parametric model to the autocovariances or &ldquo;none&rdquo;.</p>
</td></tr>
<tr><td><code>fitmodel.args</code></td>
<td>
<p>If fitmodel is used, then this will be a list of any arguments passed in for it.</p>
</td></tr>
<tr><td><code>loss.function</code></td>
<td>
<p>character string naming the loss function called.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>numeric giving the value of the statistic.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>character string naming which type of hypothesis test was used (i.e., two-sided or one of the one-sided possibilities).</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>numeric giving the p-value for the test.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>character vector naming the verification and competing forecast series applied to the test.</p>
</td></tr>
</table>
<p><code>losserr</code> returns a numeric vector of loss values.
</p>
<p><code>exponentialACV</code> returns a list object of class &ldquo;nls&rdquo; as returned by <code>nls</code>.
</p>


<h3>Author(s)</h3>

<p>Eric Gilleland
</p>


<h3>References</h3>

<p>Diebold, F. X. and Mariano, R. S. (1995) Comparing predictive accuracy. <em>Journal of Business and Economic Statistics</em>, <b>13</b>, 253&ndash;263.
</p>
<p>Gilleland, E. (2013) Testing competing precipitation forecasts accurately and efficiently: The spatial prediction comparison test. <em>Mon. Wea. Rev.</em>, <b>141</b> (1), 340&ndash;355, <a href="http://dx.doi.org/10.1175/MWR-D-12-00155.1">http://dx.doi.org/10.1175/MWR-D-12-00155.1</a>.
</p>
<p>Gilleland, E. and Roux, G. (2014) A New Approach to Testing Forecast Predictive Accuracy. Accepted to <em>Meteorol. Appl.</em> Available at: <a href="http://onlinelibrary.wiley.com/doi/10.1002/met.1485/abstract">http://onlinelibrary.wiley.com/doi/10.1002/met.1485/abstract</a>
</p>
<p>Hering, A. S. and Genton, M. G. (2011) Comparing spatial predictions.  <em>Technometrics</em>, <b>53</b>, (4), 414&ndash;425, doi:10.1198/TECH.2011.10136.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+print.htest">print.htest</a></code>, <code><a href="stats.html#topic+nls">nls</a></code>, <code><a href="dtw.html#topic+dtw">dtw</a></code>, <code><a href="stats.html#topic+acf">acf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>z0 &lt;- arima.sim(list(order=c(2,0,0), ar=c(0.8,-0.2)), n=1000)
z1 &lt;- c(z0[10:1000], z0[1:9]) + rnorm(1000, sd=0.5)
z2 &lt;- arima.sim(list(order=c(3,0,1), ar=c(0.7,0,-0.1), ma=0.1), n=1000) + 
    abs(rnorm(1000, mean=1.25))

test &lt;- predcomp.test(z0, z1, z2)
summary(test)

test2 &lt;- predcomp.test(z0, z1, z2, test = "HG" )
summary(test2)

## Not run: 
test2 &lt;- predcomp.test(z0, z1, z2, test = "HG" )
summary(test2)

test2.2 &lt;- predcomp.test(z0, z1, z2, alternative="less")
summary(test2.2)

test3 &lt;- predcomp.test(z0, z1, z2, lossfun.args=list(method="dtw") )
summary(test3)

test3.2 &lt;- predcomp.test(z0, z1, z2, alternative="less",
    lossfun.args=list(method="dtw"), test = "HG" )
summary(test3.2)

test4 &lt;- predcomp.test(z0, z1, z2, lossfun.args = list(method="corrskill"), test = "HG" )
summary(test4)

test5 &lt;- predcomp.test(z0, z1, z2, lossfun.args = list(method="dtw", dtw.interr="sqerr"),
    test = "HG" )
summary(test5)

test5.2 &lt;- predcomp.test(z0, z1, z2, alternative="less",
    lossfun.args=list(method="dtw", dtw.interr="sqerr"), test = "HG" )
summary(test5.2) 

## End(Not run)

</code></pre>

<hr>
<h2 id='prob.frcs.dat'> Probablisitic  Forecast Dataset. </h2><span id='topic+prob.frcs.dat'></span>

<h3>Description</h3>

<p>This data set is used as an example of data used by the <code>roc.plot</code>
function.  The first column contains a probablisitic forecast for
aviation icing.  The second column contains a logical variable
indicating whether or not icing was observed.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(prob.frcs.dat) </code></pre>


<h3>References</h3>

<p><em>PROBABILITY FORECASTS OF IN-FLIGHT ICING
CONDITIONS</em> Barbara G. Brown, Ben C. Bernstein, Frank McDonough and
Tiffany A. O. Bernstein, 8th Conference on Aviation, Range, and
Aerospace Meteorology, Dallas TX, 10-15 January 1999.
</p>

<hr>
<h2 id='probcont2disc'>Converts continuous probability values into binned
discrete probability forecasts.</h2><span id='topic+probcont2disc'></span>

<h3>Description</h3>

<p>Converts continuous probability values into binned
discrete probability forecasts.  This is useful in calculated
Brier type scores for values with continuous probabilities.
Each probability is assigned the value of the midpoint. </p>


<h3>Usage</h3>

<pre><code class='language-R'>    probcont2disc(x, bins = seq(0,1,0.1) )
       </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="probcont2disc_+3A_x">x</code></td>
<td>
<p>A vector of probabilities</p>
</td></tr>
<tr><td><code id="probcont2disc_+3A_bins">bins</code></td>
<td>
<p>Bins.  Defaults to 0 to 1 by 0.1 .</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of discrete probabilities.  E
</p>


<h3>Note</h3>

<p>This function is used within <code>brier</code>.</p>


<h3>Author(s)</h3>

<p>Matt Pocernich</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#  probabilistic/ binary example

set.seed(1)
x &lt;- runif(10) ## simulated probabilities.

probcont2disc(x)
probcont2disc(x, bins = seq(0,1,0.25) )

## probcont2disc(4, bins = seq(0,1,0.3)) ## gets error

</code></pre>

<hr>
<h2 id='qrel.plot'>Quantile Reliability Plot</h2><span id='topic+qrel.plot'></span>

<h3>Description</h3>

<p>The quantile reliability plot gives detailed insights into the performance of quantile forecasts. The conditional observed quantiles are plotted against the discretized quantile forecasts. For calibrated forecasts (i.e., reliability), the points should lie on a diagonal line. The interpretation concerning over or under forecasting of a quantile reliability diagram is analogous to the interpretation of a reliability diagram for probability forecasts of dichotomous events (see for example Wilks (2006), pp. 287 - 290).</p>


<h3>Usage</h3>

<pre><code class='language-R'>qrel.plot(A, ...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qrel.plot_+3A_a">A</code></td>
<td>
<p>A &quot;quantile&quot; class object from <code>verify</code></p>
</td></tr>
<tr><td><code id="qrel.plot_+3A_...">...</code></td>
<td>
<p>optional arguments.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is based on <code>reliabiliy.plot</code> by Matt Pocernich.</p>


<h3>Author(s)</h3>

<p>Sabrina Bentzien</p>


<h3>References</h3>

<p>Bentzien and Friederichs (2013), Decomposition and graphical portrayal of the quantile score, submitted to QJRMS.</p>


<h3>See Also</h3>

<p><code><a href="#topic+quantileScore">quantileScore</a></code>, <code><a href="#topic+reliability.plot">reliability.plot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(precip.ensemble)

#Observations are in column 3
obs &lt;- precip.ensemble[,3]

#Forecast values of ensemble are in columns 4 to 54
eps &lt;- precip.ensemble[,4:54]

#Quantile forecasts from ensemble
p &lt;- 0.9
qf &lt;- apply(eps,1,quantile,prob=p,type=8)

#generate equally populated binnng intervals
breaks &lt;- quantile(qf,seq(0,1,length.out=11))

qs &lt;- quantileScore(obs,qf,p,breaks)
qrel.plot(qs)

</code></pre>

<hr>
<h2 id='quantile2disc'>Convert Continuous Forecast Values to Discrete Forecast Values.</h2><span id='topic+quantile2disc'></span>

<h3>Description</h3>

<p>Converts continuous forecast values into discrete forecast values. This is necessary in calculating the quantile score decomposition. Discrete forecasts are defined by the mean value of forecasts within a bin specified by the bin vector (bin boundaries).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quantile2disc(x, bins)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quantile2disc_+3A_x">x</code></td>
<td>
<p>A vector of forecast values</p>
</td></tr>
<tr><td><code id="quantile2disc_+3A_bins">bins</code></td>
<td>
<p>Vector with bin boundaries</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>new</code></td>
<td>
<p>New vector x (continuous forecast values replaced with disretized forecast values)</p>
</td></tr>
<tr><td><code>mids</code></td>
<td>
<p>Vector of discrete forecast values</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is used within <code>quantileScore</code>.</p>


<h3>Author(s)</h3>

<p>Sabrina Bentzien</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100)
bins &lt;- quantile(x,seq(0,1,length.out=11))

newx &lt;- quantile2disc(x,bins)

</code></pre>

<hr>
<h2 id='quantileScore'>Quantile Score</h2><span id='topic+quantileScore'></span>

<h3>Description</h3>

<p>Calculates verification statistics for quantile forecasts.</p>


<h3>Usage</h3>

<pre><code class='language-R'>quantileScore(obs, pred, p, breaks, ...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quantileScore_+3A_obs">obs</code></td>
<td>
<p>Vector of observations</p>
</td></tr>
<tr><td><code id="quantileScore_+3A_pred">pred</code></td>
<td>
<p>Vector of quantile forecasts</p>
</td></tr>
<tr><td><code id="quantileScore_+3A_p">p</code></td>
<td>
<p>Probability level of quantile forecasts [0,1].</p>
</td></tr>
<tr><td><code id="quantileScore_+3A_breaks">breaks</code></td>
<td>
<p>Values used to bin the forecasts</p>
</td></tr>
<tr><td><code id="quantileScore_+3A_...">...</code></td>
<td>
<p>Optional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the quantile score and its decomposition into reliability, resolution, and uncertainty. Note that a careful binning (discretization of forecast values) is necessary to obtain good estimates of reliability and resolution (see Bentzien and Friederichs (2013) for more details).
</p>


<h3>Value</h3>

<table>
<tr><td><code>qs.orig</code></td>
<td>
<p>Quantile score for original data</p>
</td></tr>
<tr><td><code>qs</code></td>
<td>
<p>Quantile score for binned data</p>
</td></tr>
<tr><td><code>qs.baseline</code></td>
<td>
<p>Quantile score for climatology</p>
</td></tr>
<tr><td><code>ss</code></td>
<td>
<p>Quantile skill score</p>
</td></tr>
<tr><td><code>qs.reliability</code></td>
<td>
<p>Reliability part of the quantile score</p>
</td></tr>
<tr><td><code>qs.resolution</code></td>
<td>
<p>Resolution part of the quantile score</p>
</td></tr>
<tr><td><code>qs.uncert</code></td>
<td>
<p>Uncertainty part of the quantile score</p>
</td></tr>
<tr><td><code>y.i</code></td>
<td>
<p>Discretized forecast values &ndash; defined as the mean value of forecasts in each bin</p>
</td></tr>
<tr><td><code>obar.i</code></td>
<td>
<p>Conditional observed quantiles</p>
</td></tr>
<tr><td><code>prob.y</code></td>
<td>
<p>Number of forecast-observation pairs in each bin</p>
</td></tr>
<tr><td><code>obar</code></td>
<td>
<p>Climatology &ndash; unconditional sample quantile of observations</p>
</td></tr>
<tr><td><code>breaks</code></td>
<td>
<p>Values used to bin the forecasts</p>
</td></tr>
<tr><td><code>check</code></td>
<td>
<p>Difference between original quantile score and quantile score decomposition</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is used within <code>verify</code>.</p>


<h3>Author(s)</h3>

<p>Sabrina Bentzien</p>


<h3>References</h3>

<p>Bentzien, S. and Friederichs, P. (2013) Decomposition and graphical portrayal of the quantile score. Submitted to <em>QJRMS</em>.</p>


<h3>See Also</h3>

<p><code><a href="#topic+check.func">check.func</a></code>, <code><a href="#topic+qrel.plot">qrel.plot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(precip.ensemble)

#Observations are in column 3
obs &lt;- precip.ensemble[,3]

#Forecast values of ensemble are in columns 4 to 54
eps &lt;- precip.ensemble[,4:54]

#Quantile forecasts from ensemble
p &lt;- 0.9
qf &lt;- apply(eps,1,quantile,prob=p,type=8)

#generate equally populated binnng intervals
breaks &lt;- quantile(qf,seq(0,1,length.out=11))

qs &lt;- quantileScore(obs,qf,p,breaks)
## Not run:  qrel.plot(qs) 

</code></pre>

<hr>
<h2 id='rcrv'>Reduced centered random variable</h2><span id='topic+rcrv'></span>

<h3>Description</h3>

<p>The RCRV provides information on the reliability of an ensemble system
in terms of the bias and the dispersion. A perfectly reliable system as no bias and a 
dispersion equal to 1. The observational error is taken into account </p>


<h3>Usage</h3>

<pre><code class='language-R'>      rcrv(obs,epsMean,epsVariance,obsError)
       </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rcrv_+3A_obs">obs</code></td>
<td>
<p>A vector of observations</p>
</td></tr>
<tr><td><code id="rcrv_+3A_epsmean">epsMean</code></td>
<td>
<p>A vector of the means of the ensemble</p>
</td></tr>
<tr><td><code id="rcrv_+3A_epsvariance">epsVariance</code></td>
<td>
<p>A vector of the variances of the ensemble</p>
</td></tr>
<tr><td><code id="rcrv_+3A_obserror">obsError</code></td>
<td>
<p>Observational error</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>bias</code></td>
<td>
<p>The weighted bias between the ensemble and the observation.  A value equal to 0 indicates no bias.  A positive (negative) value indicates a positive (negative) bias</p>
</td></tr>
<tr><td><code>disp</code></td>
<td>
<p>The dispersion of the ensemble.
A value equal to 1 indicates no dispersion.
A value greater (smaller) then 1 indicates underdispersion (overdispersion)</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>Vector of y. Mean of y equals bias and standard deviation of y equals dispersion</p>
</td></tr>
<tr><td><code>obsError</code></td>
<td>
<p>Observational error (passed to function)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ronald Frenette &lt;Ronald.Frenette@ec.gc.ca&gt;</p>


<h3>References</h3>

<p>G. Candille, C. P. L. Houtekamer, and G. Pellerin: Verification of an Ensemble Prediction System against Observations, <em>Monthly Weather Review</em>,<b>135</b>, pp. 2688-2699
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(precip.ensemble) 
#Observations are in the column
obs&lt;-precip.ensemble[,3] 

#Forecast values of ensemble are in the column 4 to 54
eps&lt;-precip.ensemble[,4:54]   

#Means and variances of the ensemble
mean&lt;-apply(eps,1,mean)
var&lt;-apply(eps,1,var)

#observation error of 0.5mm 
sig0 &lt;- 0.5 

rcrv(obs,mean,var,sig0)

</code></pre>

<hr>
<h2 id='reliability.plot'>Reliability Plot</h2><span id='topic+reliability.plot'></span><span id='topic+reliability.plot.default'></span><span id='topic+reliability.plot.verify'></span>

<h3>Description</h3>

<p>A reliability plot is a simple form of an attribute
diagram that depicts the performance of a probabilistic forecast
for a binary event.  In this diagram, the forecast probability is
plotted against the observed relative frequency.  Ideally, this
value should be near to each other and so points falling on the
1:1 line are desirable.  For added information, if one or two
forecasts are being verified, sharpness diagrams are presented in
the corners of the plot.  Ideally, these histograms should be
relatively flat, indicating that each bin of probabilities is use
an appropriate amount of times.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>   ## Default S3 method:
reliability.plot(x, obar.i, prob.y, titl = NULL, legend.names = NULL, ... )
## S3 method for class 'verify'
reliability.plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reliability.plot_+3A_x">x</code></td>
<td>
<p>Forecast probabilities.(<code class="reqn">y_i</code>) or a &ldquo;prob.bin&rdquo;
class object from <code>verify</code>.</p>
</td></tr>
<tr><td><code id="reliability.plot_+3A_obar.i">obar.i</code></td>
<td>
<p>Observed relative frequency <code class="reqn">\bar{o}_i</code>.</p>
</td></tr>
<tr><td><code id="reliability.plot_+3A_prob.y">prob.y</code></td>
<td>
<p>Relative frequency of forecasts</p>
</td></tr>
<tr><td><code id="reliability.plot_+3A_titl">titl</code></td>
<td>
<p>Title</p>
</td></tr>
<tr><td><code id="reliability.plot_+3A_legend.names">legend.names</code></td>
<td>
<p>Names of each model that will appear in the
legend.  </p>
</td></tr>
<tr><td><code id="reliability.plot_+3A_...">...</code></td>
<td>
<p>Graphical parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function works either by entering vectors or
on a verify class object.</p>


<h3>Note</h3>

<p>If a single prob.bin class object is used, a reliability
plot along with a sharpness diagram is displayed.  If two
forecasts are provided in the form of a matrix of predictions,
two sharpness diagrams are provided.  If more forecasts are
provided, the sharpness diagrams are not displayed.</p>


<h3>Author(s)</h3>

<p>Matt Pocernich</p>


<h3>References</h3>

<p>Wilks, D. S. (1995) <em>Statistical Methods in the Atmospheric Sciences </em>
Chapter 7, San Diego: Academic Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Data from Wilks, table 7.3 page 246.
 y.i   &lt;- c(0,0.05, seq(0.1, 1, 0.1))
 obar.i &lt;- c(0.006, 0.019, 0.059, 0.15, 0.277, 0.377, 0.511,
    0.587, 0.723, 0.779, 0.934, 0.933)

 prob.y &lt;- c(0.4112, 0.0671, 0.1833, 0.0986, 0.0616, 0.0366,
    0.0303,  0.0275, 0.245, 0.022, 0.017, 0.203) 

 obar &lt;- 0.162

reliability.plot(y.i, obar.i, prob.y, titl = "Test 1", legend.names =
c("Model A") )


## Function will work with a ``prob.bin'' class object as well.
## Note this is a very bad forecast.
obs&lt;- round(runif(100))
pred&lt;- runif(100)

A&lt;- verify(obs, pred, frcst.type = "prob", obs.type = "binary")

reliability.plot(A, titl = "Alternative plot")
 

</code></pre>

<hr>
<h2 id='roc.area'>Area under curve (AUC) calculation for Response Operating Characteristic curve.</h2><span id='topic+roc.area'></span>

<h3>Description</h3>

<p>This function calculates the area underneath a ROC
curve following the process outlined in Mason and Graham (2002).  The
p-value produced is related to the Mann-Whitney U statistics.
The p-value is calculated using the wilcox.test function which
automatically handles ties and makes approximations for large values.
</p>
<p>The p-value addresses the null hypothesis $H_o:$ The area under the ROC
curve is 0.5 i.e. the forecast has no skill. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    roc.area(obs, pred)
       </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="roc.area_+3A_obs">obs</code></td>
<td>
<p>A binary observation (coded {0, 1 } ).</p>
</td></tr>
<tr><td><code id="roc.area_+3A_pred">pred</code></td>
<td>
<p>A probability prediction on the interval [0,1].</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>A</code></td>
<td>
<p>Area under ROC curve, adjusted for ties in
forecasts, if present</p>
</td></tr>
<tr><td><code>n.total</code></td>
<td>
<p>Total number of records</p>
</td></tr>
<tr><td><code>n.events</code></td>
<td>
<p>Number of events</p>
</td></tr>
<tr><td><code>n.noevents</code></td>
<td>
<p>Number of non-events</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Unadjusted p-value</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is used internally in the <code>roc.plot</code> command
to calculate areas.</p>


<h3>Author(s)</h3>

<p>Matt Pocernich</p>


<h3>References</h3>

<p>Mason, S. J. and Graham, N. E. (2002) Areas beneath the
relative operating characteristics (ROC) and relative operating
levels (ROL) curves: Statistical significance and interpretation,
<em>Q. J. R. Meteorol. Soc.</em> <b>128</b>, 2145&ndash;2166.</p>


<h3>See Also</h3>

<p><code><a href="#topic+roc.plot">roc.plot</a></code>, <code><a href="#topic+verify">verify</a></code>,
<code><a href="stats.html#topic+wilcox.test">wilcox.test</a> </code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># Data used from Mason and Graham (2002).
a&lt;- c(1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990,
 1991, 1992, 1993, 1994, 1995)
b&lt;- c(0,0,0,1,1,1,0,1,1,0,0,0,0,1,1)
c&lt;- c(.8, .8, 0, 1,1,.6, .4, .8, 0, 0, .2, 0, 0, 1,1)
d&lt;- c(.928,.576, .008, .944, .832, .816, .136, .584, .032, .016, .28, .024, 0, .984, .952)

A&lt;- data.frame(a,b,c, d)
names(A)&lt;- c("year", "event", "p1", "p2")

## for model with ties
roc.area(A$event, A$p1)

## for model without ties
roc.area(A$event, A$p2)


</code></pre>

<hr>
<h2 id='roc.plot'>Relative operating characteristic curve.</h2><span id='topic+roc.plot'></span><span id='topic+roc.plot.default'></span><span id='topic+roc.plot.prob.bin'></span>

<h3>Description</h3>

<p>This function creates Receiver Operating
Characteristic (ROC) plots for one or more models.  A ROC curve
plots the false alarm rate against the hit rate for a
probablistic forecast for a range of thresholds. The area under
the curve is viewed as a measure of a forecast's accuracy.  A
measure of 1 would indicate a perfect model.  A measure of 0.5
would indicate a random forecast. </p>


<h3>Usage</h3>

<pre><code class='language-R'>    ## Default S3 method:
roc.plot(x, pred, thresholds = NULL, binormal =
FALSE,   legend = FALSE, leg.text = NULL,  plot = "emp", CI = FALSE,
n.boot = 1000, alpha = 0.05, tck = 0.01, plot.thres = seq(0.1,
0.9, 0.1), show.thres = TRUE, main = "ROC Curve", xlab = "False Alarm Rate",
ylab = "Hit Rate", extra = FALSE,  ...)
## S3 method for class 'prob.bin'
roc.plot(x, ...) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="roc.plot_+3A_x">x</code></td>
<td>
<p>A binary observation (coded {0, 1 } ) or a verification
object.</p>
</td></tr>
<tr><td><code id="roc.plot_+3A_pred">pred</code></td>
<td>
<p>A probability prediction on the interval [0,1].  If
multiple models are compared, this may be a matrix where each
column represents a different prediction.</p>
</td></tr>
<tr><td><code id="roc.plot_+3A_thresholds">thresholds</code></td>
<td>
<p>Thresholds may be provided. These thresholds
will be used to calculate the hit rate ($h$) and false alarm
rate ($f$).  If thresholds is NULL, all unique thresholds are
used as a threshold. Alternatively, if the number of bins is
specified,  thresholds will be calculated using the
specified numbers of quantiles. </p>
</td></tr>



<tr><td><code id="roc.plot_+3A_binormal">binormal</code></td>
<td>
<p> If TRUE, in addition to the empirical ROC curve, the
binormal ROC curve will be calculated.  To get a plot draw, plot must
be either &ldquo;binorm&rdquo; or &ldquo;both&rdquo;.  </p>
</td></tr>
<tr><td><code id="roc.plot_+3A_legend">legend</code></td>
<td>
<p>Binomial.  Defaults to FALSE indicating whether a legend
should be displayed.</p>
</td></tr>
<tr><td><code id="roc.plot_+3A_leg.text">leg.text</code></td>
<td>
<p>Character vector for legend.  If NULL, models are
labeled  &ldquo;Model A&quot;, &ldquo;Model B&quot;,...</p>
</td></tr>
<tr><td><code id="roc.plot_+3A_plot">plot</code></td>
<td>
<p>Either &ldquo;emp&rdquo; (default), &ldquo;binorm&rdquo; or &ldquo;both&rdquo; to
determine which plot is shown.  If set to NULL, a plot is not
created</p>
</td></tr>
<tr><td><code id="roc.plot_+3A_ci">CI</code></td>
<td>
<p>Confidence Intervals.  Calculated by bootstrapping
the observations and prediction, then calculating PODy and
PODn values.  </p>
</td></tr>
<tr><td><code id="roc.plot_+3A_n.boot">n.boot</code></td>
<td>
<p>Number of bootstrap samples.</p>
</td></tr>
<tr><td><code id="roc.plot_+3A_alpha">alpha</code></td>
<td>
<p> Confidence interval.  By default = 0.05</p>
</td></tr>
<tr><td><code id="roc.plot_+3A_tck">tck</code></td>
<td>
<p>Tick width on confidence interval whiskers.</p>
</td></tr>
<tr><td><code id="roc.plot_+3A_plot.thres">plot.thres</code></td>
<td>
<p>By default, displays the threshold levels on
the ROC diagrams.  To surpress these values, set it equal to
NULL.  If confidence intervals (CI) is set to TRUE, levels
specified here will determine where confidence interval boxes
are placed. </p>
</td></tr>
<tr><td><code id="roc.plot_+3A_show.thres">show.thres</code></td>
<td>
<p> Show thresholds for points indicated by
plot.thres.  Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="roc.plot_+3A_main">main</code></td>
<td>
<p>Title for plot.</p>
</td></tr>
<tr><td><code id="roc.plot_+3A_xlab">xlab</code>, <code id="roc.plot_+3A_ylab">ylab</code></td>
<td>
<p>Plot axes labels.  Defaults to &ldquo;Hit Rate&rdquo;
and &ldquo;False Alarm Rate&rdquo;, for the y and x axes respectively.</p>
</td></tr> 
<tr><td><code id="roc.plot_+3A_extra">extra</code></td>
<td>
<p> Extra text describing binormal and empirical lines. </p>
</td></tr>
<tr><td><code id="roc.plot_+3A_...">...</code></td>
<td>
<p>Additional plotting options.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If assigned to an object, the following values are reported.
</p>
<table>
<tr><td><code>plot.data</code></td>
<td>
<p>The data used to generate the ROC plots.  This
is a array. Column headers are thresholds, empirical hit and
false alarm rates, and binormal hit and false alarm rates.  Each
model is depicted on an array indexed by the third dimension.</p>
</td></tr>
<tr><td><code>roc.vol</code></td>
<td>
<p>The areas under the ROC curves.  By default,this
is printed on the plots.  Areas and p-values are
calculated with and without adjustments for ties along with
the p-value for the area.  These
values are calculated using <code><a href="#topic+roc.area">roc.area</a></code>.  The
fifth column contains the area under the binormal curve, if
binormal is selected.</p>
</td></tr>
<tr><td><code>A.boot</code></td>
<td>
<p>If confidence intervals are calculated, the area under the ROC curve are returned. </p>
</td></tr>
</table>


<h3>Note</h3>

<p>  Other packages in R provide functions to create ROC diagrams and different diagnostics.  The <b>ROCR</b> package provides excellent functions to generate ROC diagrams with lines coded by threshold.  Large datasets are handled by a sampling routine and the user may plot a number of threshold dependent, contingency table scores.  Arguably, this is a superior package with respect to ROC plotting.
</p>
<p>There is not a minimum size required to create confidence
limits or show thresholds.  When there are few data points, it
is possilbe to make some pretty unattractive graphs. 
</p>
<p>The roc.plot method can be used to summarize a &quot;verify, prob.bin&quot; class object created with the verify command.  It is appropriate to use the roc plot for forecast which are not probabilities, but rather forecasts made on a continuous scale.  The roc plot function can be used to summarize such forecasts but it is not possible to use the verify function to summarize such forecasts.  An example is shown below.
</p>


<h3>Author(s)</h3>

<p>Matt Pocernich</p>


<h3>References</h3>

<p>Mason, I. (1982) &ldquo;A model for assessment of weather forecasts,&rdquo;
<em>Aust. Met. Mag</em> <b>30</b> (1982) 291-303.  
</p>
<p>Mason, S.J. and N.E. Graham. (2002) &ldquo;Areas beneath the
relative operating characteristics (ROC) and relative operating
levels (ROL) curves: Statistical significance and interpretation, &rdquo;
<em>Q. J. R. Meteorol. Soc.</em> <b>128</b> pp. 2145-2166.  
</p>
<p>Swets, John A. (1996) <em>Signal Detection Theory and ROC Analysis
in Psychology and Diagnostics</em>, Lawrence Erlbaum Associates, Inc.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pop">pop</a> </code>  and <code><a href="#topic+lines.roc">lines.roc</a> </code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Data from Mason and Graham article.

a&lt;- c(0,0,0,1,1,1,0,1,1,0,0,0,0,1,1)
b&lt;- c(.8, .8, 0, 1,1,.6, .4, .8, 0, 0, .2, 0, 0, 1,1)
c&lt;- c(.928,.576, .008, .944, .832, .816, .136, .584, .032, .016, .28, .024, 0, .984, .952)

A&lt;- data.frame(a,b,c)
names(A)&lt;- c("event", "p1", "p2")

## for model with ties
roc.plot(A$event, A$p1)

## for model without ties
roc.plot(A$event, A$p2)

### show binormal curve fit.

roc.plot(A$event, A$p2, binormal = TRUE)
## Not run: 
# icing forecast

data(prob.frcs.dat)
A &lt;- verify(prob.frcs.dat$obs, prob.frcs.dat$frcst/100)
roc.plot(A, main = "AWG Forecast")


# plotting a ``prob.bin'' class object.
obs&lt;- round(runif(100))
pred&lt;- runif(100)

A&lt;- verify(obs, pred, frcst.type = "prob", obs.type = "binary")

roc.plot(A, main = "Test 1", binormal = TRUE, plot = "both")

## show confidence intervals.  MAY BE SLOW
roc.plot(A, threshold = seq(0.1,0.9, 0.1), main = "Test 1", CI = TRUE,
alpha = 0.1)

###   example from forecast verification website. 
data(pop)
d &lt;- pop.convert() ## internal function used to make binary observations for the pop figure.
### note the use of bins = FALSE !!
 mod24 &lt;- verify(d$obs_norain, d$p24_norain, bins = FALSE)

 mod48 &lt;- verify(d$obs_norain, d$p48_norain, bins = FALSE)

roc.plot(mod24, plot.thres = NULL)
lines.roc(mod48, col = 2, lwd = 2)
leg.txt &lt;- c("24 hour forecast", "48 hour forecast")
legend( 0.6, 0.4, leg.txt, col = c(1,2), lwd = 2)

## End(Not run)
</code></pre>

<hr>
<h2 id='rps'>Ranked Probability Score</h2><span id='topic+rps'></span>

<h3>Description</h3>

<p>Calculates the ranked probability score (rps) and
ranked probability skill score (rpss) for probabilistic
forecasts of ordered events.</p>


<h3>Usage</h3>

<pre><code class='language-R'> rps(obs, pred, baseline=NULL) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rps_+3A_obs">obs</code></td>
<td>
<p>A vector of observed outcomes.  These values correspond to
columns of prediction probabilities.   </p>
</td></tr>
<tr><td><code id="rps_+3A_pred">pred</code></td>
<td>
<p>A matrix of probabilities for each outcome
occurring.  Each column represents a category of prediction.</p>
</td></tr>
<tr><td><code id="rps_+3A_baseline">baseline</code></td>
<td>
<p>If NULL (default) the probability based on the
sample data of each event to occur.    Alternatively,  a
vector the same length of the as the number categories  can be
entered. </p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>rps</code></td>
<td>
<p>Ranked probability scores</p>
</td></tr>
<tr><td><code>rpss</code></td>
<td>
<p>Ranked probability skill score.  Uses baseline or
sample climatology as a references score.</p>
</td></tr>
<tr><td><code>rps.clim</code></td>
<td>
<p>Ranked probability score for baseline forecast.</p>
</td></tr>
</table>


<h3>Note</h3>

<p> Perhaps the format of the data is best understood in the
context of an example.  Consider a probability of
precipitation forecast of &quot;none&quot;, &quot;light&quot; or  &quot;heavy&quot;.  This
could be [0.5, 0.3, 0.2].  If heavy rain occurred, the observed
value would be 3, indicating event summarized in the third column
occurred.
</p>
<p><b>The RPS value is scaled to a [0,1 ] interval by dividing by (number
of categories -1 .  There is a discrepancy in the way this is
explained in Wilks (2005) and the WWRF web page. </b> </p>


<h3>Author(s)</h3>

<p>Matt Pocernich</p>


<h3>References</h3>

<p>WWRP/WGNE Joint Working Group on Verification - Forecast Verification - Issues, Methods and FAQ
<a href="http://www.cawcr.gov.au/projects/verification/verif_web_page.html#RPS">http://www.cawcr.gov.au/projects/verification/verif_web_page.html#RPS</a>
</p>
<p>Wilks, D. S. (2005) <em>Statistical Methods in the Atmospheric Sciences </em>
Chapter 7, San Diego: Academic Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+crps">crps</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
###  Example from Wilks, note without a baseline and only one
### forecast, the rpss and ss are not too meaningfull.



rps( obs = c(1), pred = matrix(c(0.2, 0.5, 0.3), nrow = 1))

</code></pre>

<hr>
<h2 id='table.stats'>Verification statistics for a 2 by 2  Contingency Table </h2><span id='topic+table.stats'></span>

<h3>Description</h3>

<p>Provides a variety of statistics for a data
summarized in a 2 by 2 contingency table. </p>


<h3>Usage</h3>

<pre><code class='language-R'>       	table.stats(obs, pred, fudge = 0.01, silent = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="table.stats_+3A_obs">obs</code></td>
<td>
<p> Either a vector of contingency table counts, a vector of binary observations, or a 2 by 2 matrix in the form of a contingency table. (See note below.)</p>
</td></tr>
<tr><td><code id="table.stats_+3A_pred">pred</code></td>
<td>
<p>Either null or a vector of binary forecasts. </p>
</td></tr>
<tr><td><code id="table.stats_+3A_fudge">fudge</code></td>
<td>
<p>A numeric fudge factor to be added to each cell of the contingency table in order to avoid division by zero.</p>
</td></tr>
<tr><td><code id="table.stats_+3A_silent">silent</code></td>
<td>
<p>Should warning statements be surpressed.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>tab.out</code></td>
<td>
<p> Contingency table</p>
</td></tr>
<tr><td><code>TS</code></td>
<td>
<p>Threat score a.k.a. Critical success index (CSI) </p>
</td></tr>
<tr><td><code>TS.se</code></td>
<td>
<p>Standard Error for TS</p>
</td></tr>
<tr><td><code>POD</code></td>
<td>
<p>Hit Rate aka probability of detection</p>
</td></tr>
<tr><td><code>POD.se</code></td>
<td>
<p>Standard Error for POD</p>
</td></tr>
<tr><td><code>M</code></td>
<td>
<p>Miss rate</p>
</td></tr>
<tr><td><code>F</code></td>
<td>
<p>False Alarm RATE</p>
</td></tr>
<tr><td><code>F.se</code></td>
<td>
<p>Standard Error for F</p>
</td></tr>
<tr><td><code>FAR</code></td>
<td>
<p>False Alarm RATIO</p>
</td></tr>
<tr><td><code>FAR.se</code></td>
<td>
<p>Standard Error for FAR</p>
</td></tr>
<tr><td><code>HSS</code></td>
<td>
<p>Heidke Skill Score</p>
</td></tr>
<tr><td><code>HSS.se</code></td>
<td>
<p>Standard Error for HSS</p>
</td></tr>
<tr><td><code>PSS</code></td>
<td>
<p>Peirce Skill Score</p>
</td></tr>
<tr><td><code>PSS.se</code></td>
<td>
<p>Standard Error for PSS</p>
</td></tr>
<tr><td><code>KSS</code></td>
<td>
<p>Kuiper's Skill Score </p>
</td></tr>  
<tr><td><code>PC</code></td>
<td>
<p>Percent correct - events along the diagonal.</p>
</td></tr>
<tr><td><code>PC.se</code></td>
<td>
<p>Standard Error for PC</p>
</td></tr>
<tr><td><code>BIAS</code></td>
<td>
<p>Bias</p>
</td></tr>
<tr><td><code>ETS</code></td>
<td>
<p>Equitable Threat Score</p>
</td></tr>
<tr><td><code>ETS.se</code></td>
<td>
<p>Standard Error for ETS</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Odds Ratio</p>
</td></tr>
<tr><td><code>log.theta</code></td>
<td>
<p>Log Odds Ratio</p>
</td></tr>
<tr><td><code>LOR.se</code></td>
<td>
<p>Standard Error for Log Odds Ratio</p>
</td></tr>
<tr><td><code>n.h</code></td>
<td>
<p>Degrees of freedom for log.theta</p>
</td></tr>
<tr><td><code>orss</code></td>
<td>
<p>Odds ratio skill score, aka Yules's Q</p>
</td></tr>
<tr><td><code>ORSS.se</code></td>
<td>
<p>Standard Error for Odds ratio skill score</p>
</td></tr>
<tr><td><code>eds</code></td>
<td>
<p>Extreme Dependency Score</p>
</td></tr>
<tr><td><code>esd.se</code></td>
<td>
<p>Standard Error for EDS</p>
</td></tr>
<tr><td><code>seds</code></td>
<td>
<p>Symmetric Extreme Dependency Score</p>
</td></tr>
<tr><td><code>seds.se</code></td>
<td>
<p>Standard Error for Symmetric Extreme Dependency Score</p>
</td></tr>
<tr><td><code>EDI</code></td>
<td>
<p>Extreme Dependency Index</p>
</td></tr>
<tr><td><code>EDI.se</code></td>
<td>
<p>Standard Error for EDI</p>
</td></tr>
<tr><td><code>SEDI</code></td>
<td>
<p>Symmetric EDI</p>
</td></tr>
<tr><td><code>SEDI.se</code></td>
<td>
<p>Standard Error for SEDI</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Initially, table.stats was an internal function used by verify for binary events and multi.cont for categorical events. But occassionally, it is nice to use it directly.</p>


<h3>Author(s)</h3>

<p>Matt Pocernich</p>


<h3>References</h3>

 
<p>Jolliffe, I.T. and D.B. Stephenson (2003). Forecast verification: a practitioner's guide in atmospheric science. John Wiley and Sons.  See chapter 3 concerning categorical events. 
</p>
<p>Stephenson, D.B. (2000).  &quot;Use of 'Odds Ratio for Diagnosing Forecast Skill.&quot; <em>Weather and Forecasting</em> <b>15</b> 221-232.  
</p>
<p>Hogan, R.J., O'Connor E.J. and Illingworth, 2009.  &quot;Verification of cloud-fraction forecasts.&quot; <em>Q.J.R. Meteorol. Soc.</em> <b>135</b>, 1494-1511.
</p>


<h3>See Also</h3>

<p><code>verify</code> and <code>multi.cont</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>DAT&lt;- matrix(c(28, 23, 72, 2680 ), ncol = 2) ## Finley
table.stats(DAT)
</code></pre>

<hr>
<h2 id='table.stats.boot'>Percentile bootstrap for 2 by 2 table</h2><span id='topic+table.stats.boot'></span>

<h3>Description</h3>

<p> Performs a bootstrap on data from a 2 by 2 contingency table returning verification statistics.  Potentially useful in creating error bars for performance diagrams.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>table.stats.boot(CT, R = 100, alpha = 0.05, fudge = 0.01)
       </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="table.stats.boot_+3A_ct">CT</code></td>
<td>
<p>Two by two contingency table.  Columns summarize observed values.  Rows summarize forecasted values.</p>
</td></tr>
<tr><td><code id="table.stats.boot_+3A_r">R</code></td>
<td>
<p>Number of resamples</p>
</td></tr>
<tr><td><code id="table.stats.boot_+3A_alpha">alpha</code></td>
<td>
<p>Confidence intervals.</p>
</td></tr>
<tr><td><code id="table.stats.boot_+3A_fudge">fudge</code></td>
<td>
<p>A numeric fudge factor to be added to each cell of the contingency table in order to avoid division by zero.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>2 row matrix with upper and lower intervals for bias, pod, far, ets.
</p>


<h3>Author(s)</h3>

<p>Matt  Pocernich</p>


<h3>See Also</h3>

<p><code>table.stats</code></p>


<h3>Examples</h3>

<pre><code class='language-R'> 	
### example from Roebber. 	
RB1 &lt;- matrix(c(95, 55, 42, 141), ncol = 2)
table.stats.boot(RB1, R = 1000   )

</code></pre>

<hr>
<h2 id='value'>Forecast Value Function</h2><span id='topic+value'></span>

<h3>Description</h3>

<p>Calculates the economic value of a forecast based on
a cost/loss ratio.</p>


<h3>Usage</h3>

<pre><code class='language-R'>
value(obs, pred= NULL, baseline = NULL, cl = seq(0.05, 0.95, 0.05),
    plot = TRUE, all = FALSE, thresholds = seq(0.05, 0.95, 0.05),
    ylim = c(-0.05, 1), xlim = c(0,1), ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="value_+3A_obs">obs</code></td>
<td>
<p>A vector of binary observations or a contingency
table summary of values in the form c(n11, n01, n10, n00)
where in  nab a = obs, b = forecast.</p>
</td></tr> 
<tr><td><code id="value_+3A_pred">pred</code></td>
<td>
<p>A vector of probabilistic predictions.</p>
</td></tr>  
<tr><td><code id="value_+3A_baseline">baseline</code></td>
<td>
<p>Baseline  or naive forecast.  Typically climatology.</p>
</td></tr>
<tr><td><code id="value_+3A_cl">cl</code></td>
<td>
<p>Cost loss ratio.  The relative value of being
unprepared and taking a loss to that of un-necessarily
preparing.  For example,  cl = 0.1 indicates it
would cost \$ 1 to prevent a \$10 loss.  This defaults to the
sequence 0.05 to 0.95  by 0.05.  </p>
</td></tr>
<tr><td><code id="value_+3A_plot">plot</code></td>
<td>
<p> Should a plot be created? Default is TRUE</p>
</td></tr>
<tr><td><code id="value_+3A_all">all</code></td>
<td>
<p>In the case of probabilistic forecasts, should value
curves for each thresholds be displayed.</p>
</td></tr>
<tr><td><code id="value_+3A_thresholds">thresholds</code></td>
<td>
<p>Thresholds considered for a probabilistic
forecast.</p>
</td></tr>
<tr><td><code id="value_+3A_ylim">ylim</code>, <code id="value_+3A_xlim">xlim</code></td>
<td>
<p> Plotting options.</p>
</td></tr>
<tr><td><code id="value_+3A_...">...</code></td>
<td>
<p>Options to be passed into the plotting function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If assigned to an object, the following values are reported.
</p>
<table>
<tr><td><code>vmax</code></td>
<td>
<p>Maximum value</p>
</td></tr>
<tr><td><code>V</code></td>
<td>
<p>Vector of values for each cl value</p>
</td></tr>
<tr><td><code>F</code></td>
<td>
<p>Conditional false alarm rate.</p>
</td></tr>
<tr><td><code>H</code></td>
<td>
<p>Conditional hit rate</p>
</td></tr>
<tr><td><code>cl</code></td>
<td>
<p>Vector of cost loss ratios.</p>
</td></tr>
<tr><td><code>s</code></td>
<td>
<p>Base rate</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matt Pocernich</p>


<h3>References</h3>

<p>Jolliffe, Ian and David B. Stephensen (2003) <em>Forecast
Verification: A Practioner's Guide in Atmospheric Science</em>, Chapter
8. Wiley
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## value as a contingency table
## Finley tornado data
obs&lt;- c(28, 72, 23, 2680) 
value(obs)
aa &lt;- value(obs)
aa$Vmax # max value

## probabilistic forecast example
 obs  &lt;- round(runif(100) )
 pred &lt;-  runif(100)

value(obs, pred, main = "Sample Plot",
             thresholds = seq(0.02, 0.98, 0.02) ) 
##########
data(pop)
d &lt;- pop.convert()

value(obs = d$obs_rain, pred = d$p24_rain, all = TRUE)

 </code></pre>

<hr>
<h2 id='verify'>Verification function</h2><span id='topic+verify'></span>

<h3>Description</h3>

<p>Based on the type of inputs, this function
calculates a range of verification statistics and skill scores.
Additionally, it creates a verify  class object that can be
used in further analysis or with other methods such as plot and summary.</p>


<h3>Usage</h3>

<pre><code class='language-R'>
verify(obs, pred, p = NULL, baseline = NULL, 
    frcst.type = "prob", obs.type = "binary",
    thresholds = seq(0,1,0.1), show = TRUE, bins = TRUE,
    fudge = 0.01, ...)

       </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="verify_+3A_obs">obs</code></td>
<td>
<p>The values with which the verifications are
verified. May be a vector of length 4 if the forecast and
predictions are binary data summarized in a contingency
table.  In this case, the value are entered in the order of
c(n11, n01, n10, n00).
If  obs is a matrix, it is assumed to be a contingency table with observed values summarized in the columns and forecasted values summarized in the rows.
</p>
</td></tr>
<tr><td><code id="verify_+3A_pred">pred</code></td>
<td>
<p>Prediction of event.  The prediction may be in the
form of the a point prediction or the probability of a
forecast.  Let pred = NULL if obs is a contingency
table. </p>
</td></tr>
<tr><td><code id="verify_+3A_p">p</code></td>
<td>
<p>the probability level of the quantile forecast, any value between 0 and 1.</p>
</td></tr>
<tr><td><code id="verify_+3A_baseline">baseline</code></td>
<td>
<p>In meteorology, climatology is the baseline
that represents the
no-skill forecast.  In other fields this field would
differ.  This field is used to calculate certain skill
scores.  If left NULL, these statistics are calculated using
sample climatology.  If this is not NULL, the mean of these values is used as the baseline forecast.  This interpretation is not appropriate for all applications.  For example, if a baseline forecast is different for each forecast this will not work appropriately.  </p>
</td></tr>


<tr><td><code id="verify_+3A_frcst.type">frcst.type</code></td>
<td>
<p>Forecast type.  One of &quot;prob&quot;, &quot;binary&quot;,
&quot;norm.dist&quot;, &quot;cat&quot; or &quot;cont&quot;, or &quot;quantile&quot;.  Defaults to &quot;prob&quot;.
&quot;norm.dist&quot; is used when the forecast is in the form of a
normal distribution.  See crps for more details. </p>
</td></tr>
<tr><td><code id="verify_+3A_obs.type">obs.type</code></td>
<td>
<p>Observation type.  Either  &quot;binary&quot;, &quot;cat&quot; or
&quot;cont&quot;.  Defaults to &quot;binary&quot;</p>
</td></tr>
<tr><td><code id="verify_+3A_thresholds">thresholds</code></td>
<td>
<p>Thresholds to be considered for point
forecasts of continuous events.</p>
</td></tr>
<tr><td><code id="verify_+3A_show">show</code></td>
<td>
<p>Binary; if TRUE (the default), print warning message</p>
</td></tr>
<tr><td><code id="verify_+3A_bins">bins</code></td>
<td>
<p>Binary; if TRUE (default), the probabilistic forecasts
are placed in bins defined by the sequence defined in threshold
and assigned the midpoint value.</p>
</td></tr>
<tr><td><code id="verify_+3A_fudge">fudge</code></td>
<td>
<p>A numeric fudge factor to be added to each cell of the contingency table in order to avoid division by zero.</p>
</td></tr>
<tr><td><code id="verify_+3A_...">...</code></td>
<td>
<p>Additional options.</p>
</td></tr>
</table>


<h3>Details</h3>

<p> See Wilks (2006) and the WMO Joint WWRP/WGNE Working Group web site on verification for more details about these verification statistics.  See Stephenson et al. (2008) and Ferro and Stephenson (2011) for more on the extreme dependence scores and indices.  For information on confidence intervals for these scores, see Gilleland (2010).
</p>


<h3>Value</h3>

<p>An object of the verify class.  Depending on the type of
data used, the following information may be returned.  The
following notation is used to describe which values are
produced for which type of forecast/observations. (BB =
binary/binary, PB = probablistic/binary, CC =
continuous/continuous, CTCT = categorical/categorical)   
</p>
<table>
<tr><td><code>BS</code></td>
<td>
<p>Brier Score (PB)</p>
</td></tr>
<tr><td><code>BSS</code></td>
<td>
<p>Brier Skill Score(PB)</p>
</td></tr>
<tr><td><code>SS</code></td>
<td>
<p>Skill Score (BB)</p>
</td></tr>
<tr><td><code>hit.rate</code></td>
<td>
<p>Hit rate, aka PODy, $h$ (PB, CTCT)</p>
</td></tr>
<tr><td><code>false.alarm.rate</code></td>
<td>
<p>False alarm rate, PODn,
$f$ (PB, CTCT)</p>
</td></tr>
<tr><td><code>TS</code></td>
<td>
<p>Threat Score or Critical Success Index (CSI)(BB, CTCT) </p>
</td></tr>
<tr><td><code>ETS</code></td>
<td>
<p>Equitable Threat Score (BB, CTCT)</p>
</td></tr>
<tr><td><code>BIAS</code></td>
<td>
<p>Bias (BB, CTCT) </p>
</td></tr>
<tr><td><code>PC</code></td>
<td>
<p>Percent correct or hit rate (BB, CTCT)</p>
</td></tr>
<tr><td><code>Cont.Table</code></td>
<td>
<p>Contingency Table (BB)</p>
</td></tr>
<tr><td><code>HSS</code></td>
<td>
<p>Heidke Skill Score(BB, CTCT) </p>
</td></tr>
<tr><td><code>KSS</code></td>
<td>
<p>Kuniper Skill Score (BB)</p>
</td></tr>
<tr><td><code>PSS</code></td>
<td>
<p>Pierce Skill Score (CTCT) </p>
</td></tr>
<tr><td><code>GS</code></td>
<td>
<p>Gerrity Score (CTCT) </p>
</td></tr>
<tr><td><code>ME</code></td>
<td>
<p>Mean error (CC) </p>
</td></tr>
<tr><td><code>MSE</code></td>
<td>
<p>Mean-squared error (CC)</p>
</td></tr>
<tr><td><code>MAE</code></td>
<td>
<p>Mean absolute error (CC)</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Odds Ratio (BB)</p>
</td></tr>
<tr><td><code>log.theta</code></td>
<td>
<p>Log Odds Ratio</p>
</td></tr>
<tr><td><code>n.h</code></td>
<td>
<p>Degrees of freedom for log.theta (BB)</p>
</td></tr>
<tr><td><code>orss</code></td>
<td>
<p>Odds ratio skill score, aka Yules's Q (BB)</p>
</td></tr>
<tr><td><code>eds</code></td>
<td>
<p>Extreme Dependency Score (BB)</p>
</td></tr>
<tr><td><code>eds.se</code></td>
<td>
<p>Standard Error for Extreme Dependence Score (BB)</p>
</td></tr>
<tr><td><code>seds</code></td>
<td>
<p>Symmetric Extreme Dependency Score (BB)</p>
</td></tr>
<tr><td><code>seds.se</code></td>
<td>
<p>Standard Error for Symmetric Extreme Dependency Score (BB)</p>
</td></tr>
<tr><td><code>EDI</code></td>
<td>
<p>Extremal Dependence Index (BB)</p>
</td></tr>
<tr><td><code>EDI.se</code></td>
<td>
<p>Standard Error for Extremal Dependence Index (BB)</p>
</td></tr>
<tr><td><code>SEDI</code></td>
<td>
<p>Symmetric Extremal Dependence Index (BB)</p>
</td></tr>
<tr><td><code>SEDI.se</code></td>
<td>
<p>Standard Error for Symmetric Extremal Dependence Index (BB)</p>
</td></tr>
</table>


<h3>Note</h3>

 
<p>There are other packages in R and Bioconductor which are usefull for verification tasks.  This includes the <span class="pkg">ROCR</span>, <span class="pkg">ROC</span>, package and the <span class="pkg">limma</span> package (in the Bioconductor repository.)  Written by people in different fields, each provides tools for verification from  different perspectives.
</p>
<p>For the categorical forecast and verification, the Gerrity
score only makes sense for forecast that have order, or are
basically ordinal. It is assumed that the forecasts are listed
in order.  For example, if the rows of a contigency table were summarized as &quot;medium, low, high&quot;, the Gerrity score will be incorrectly summarized.
</p>
<p>As of version 1.37, the intensity scale (IS) verification funcitons have been removed from this package.  Please use <span class="pkg">SpatialVx</span> for this functionality.
</p>


<h3>Author(s)</h3>

<p>Matt Pocernich</p>


<h3>References</h3>

<p>Ferro, C. A. T. and D. B. Stephenson, 2011.  Extremal dependence indices: Improved verification measures for deterministic forecasts of rare binary events.  <em>Wea. Forecasting</em>, <b>26</b>, 699 - 713.
</p>
<p>Gilleland, E., 2010. Confidence intervals for forecast verification. NCAR Technical Note NCAR/TN-479+STR, 71pp.  Available at: http://nldr.library.ucar.edu/collections/technotes/asset-000-000-000-846.pdf
</p>
<p>Stephenson, D. B., B. Casati, C. A. T. Ferro, and C. A. Wilson, 2008.  The extreme dependency score: A non-vanishing measure for forecasts of rare events.  <em>Meteor. Appl.</em>, <b>15</b>, 41 - 50.
</p>
<p>Wilks, D. S., 2006. <em>Statistical Methods in the Atmospheric Sciences </em>, San Diego: Academic Press., 627 pp. (2nd Editiion).
</p>
<p>WMO Joint WWRP/WGNE Working Group on Verification Website
</p>
<p><a href="http://www.cawcr.gov.au/projects/verification/">http://www.cawcr.gov.au/projects/verification/</a>
</p>


<h3>See Also</h3>

<p><code>table.stats</code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># binary/binary example
obs&lt;- round(runif(100))
pred&lt;- round(runif(100))

# binary/binary example
# Finley tornado data.

obs&lt;- c(28, 72, 23, 2680)
A&lt;- verify(obs, pred = NULL, frcst.type = "binary", obs.type = "binary")

summary(A)

# categorical/categorical example
# creates a simulated 5 category forecast and observation.
obs &lt;- round(runif(100, 1,5) )
pred &lt;- round(runif(100, 1,5) )

A&lt;- verify(obs, pred, frcst.type = "cat", obs.type = "cat" )
summary(A)

#  probabilistic/ binary example

pred&lt;- runif(100)
A&lt;- verify(obs, pred, frcst.type = "prob", obs.type = "binary")
summary(A)

# continuous/ continuous example
obs&lt;- rnorm(100)
pred&lt;- rnorm(100)
baseline &lt;- rnorm(100, sd = 0.5) 

A&lt;- verify(obs, pred, baseline = baseline,  frcst.type = "cont", obs.type = "cont")
summary(A)
</code></pre>

<hr>
<h2 id='verify-internal'>
Verification internal and secondary functions
</h2><span id='topic+summary.prob.bin'></span><span id='topic+summary.bin.bin'></span><span id='topic+summary.cont.cont'></span><span id='topic+summary.norm.dist.cont'></span><span id='topic+summary.cat.cat'></span><span id='topic+ranked.hist'></span><span id='topic+plot.prob.bin'></span><span id='topic+plot.cont.cont'></span><span id='topic+calc.ES.VM.comp1'></span><span id='topic+angle.dist'></span><span id='topic+ES.VM.comp1'></span><span id='topic+ES.VM.comp1.array'></span><span id='topic+approx.comp2'></span><span id='topic+dvm2'></span><span id='topic+ES.VM.comp2'></span><span id='topic+ES.VM.comp2.array'></span><span id='topic+roc.int'></span><span id='topic+pop.convert'></span><span id='topic+matrix.func'></span><span id='topic+qrelPlotDefault'></span><span id='topic+ORSS.exp'></span><span id='topic+WRSS.exp'></span><span id='topic+exponential'></span><span id='topic+hg.test'></span>

<h3>Description</h3>

<p>internal and secondary functions.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
