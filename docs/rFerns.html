<!DOCTYPE html><html><head><title>Help for package rFerns</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {rFerns}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#merge.rFerns'><p>Merge two random ferns models</p></a></li>
<li><a href='#naiveWrapper'><p>Naive feature selection method utilising the rFerns shadow imporance</p></a></li>
<li><a href='#predict.rFerns'><p>Prediction with random ferns model</p></a></li>
<li><a href='#rFerns'><p>Classification with random ferns</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Random Ferns Classifier</td>
</tr>
<tr>
<td>Version:</td>
<td>5.0.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides the random ferns classifier by Ozuysal, Calonder, Lepetit and Fua (2009) &lt;<a href="https://doi.org/10.1109%2FTPAMI.2009.23">doi:10.1109/TPAMI.2009.23</a>&gt;, modified for generic and multi-label classification and featuring OOB error approximation and importance measure as introduced in Kursa (2014) &lt;<a href="https://doi.org/10.18637%2Fjss.v061.i10">doi:10.18637/jss.v061.i10</a>&gt;.</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://gitlab.com/mbq/rFerns">https://gitlab.com/mbq/rFerns</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://gitlab.com/mbq/rFerns/-/issues">https://gitlab.com/mbq/rFerns/-/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-09-21 12:11:46 UTC; mbq</td>
</tr>
<tr>
<td>Author:</td>
<td>Miron Bartosz Kursa
    <a href="https://orcid.org/0000-0001-7672-648X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Miron Bartosz Kursa &lt;M.Kursa@icm.edu.pl&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-09-22 10:00:13 UTC</td>
</tr>
</table>
<hr>
<h2 id='merge.rFerns'>Merge two random ferns models</h2><span id='topic+merge.rFerns'></span>

<h3>Description</h3>

<p>This function combines two compatible (same decision, same training data structure and same depth) models into a single ensemble.
It can be used to distribute model training, perform it on batches of data, save checkouts or precisely investigate its course.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rFerns'
merge(
  x,
  y,
  dropModel = FALSE,
  ignoreObjectConsistency = FALSE,
  trueY = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="merge.rFerns_+3A_x">x</code></td>
<td>
<p>Object of a class <code>rFerns</code>; a first model to be merged.</p>
</td></tr>
<tr><td><code id="merge.rFerns_+3A_y">y</code></td>
<td>
<p>Object of a class <code>rFerns</code>; a second model to be merged.
Can also be <code>NULL</code>, <code>x</code> is immediately returned in that case.
Has to have be built on the same kind of training data as <code>x</code>, with the same depth.</p>
</td></tr>
<tr><td><code id="merge.rFerns_+3A_dropmodel">dropModel</code></td>
<td>
<p>If <code>TRUE</code>, model structure will be dropped to save size.
This disallows prediction using the merged model, but retains importance and OOB approximations.</p>
</td></tr>
<tr><td><code id="merge.rFerns_+3A_ignoreobjectconsistency">ignoreObjectConsistency</code></td>
<td>
<p>If <code>TRUE</code>, merge will be done even if both models were built on a different sets of objects.
This drops OOB approximations.</p>
</td></tr>
<tr><td><code id="merge.rFerns_+3A_truey">trueY</code></td>
<td>
<p>Copy of the training decision, used to re-construct OOB error and confusion matrix.
Can be omitted, OOB error and confusion matrix will disappear in that case; ignored when <code>ignoreObjectConsistency</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="merge.rFerns_+3A_...">...</code></td>
<td>
<p>Ignored, for S3 gerneric/method consistency.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>rFerns</code>, which is a list with the  following components:
</p>
<table>
<tr><td><code>model</code></td>
<td>
<p>The merged model in case both <code>x</code> and <code>y</code> had model structures included and <code>dropModel</code> was <code>FALSE</code>.
Otherwise <code>NULL</code>.</p>
</td></tr>
<tr><td><code>oobErr</code></td>
<td>
<p>OOB approximation of accuracy, if can be computed.
Namely, when <code>oobScores</code> could be and <code>trueY</code> is provided.</p>
</td></tr>
<tr><td><code>importance</code></td>
<td>
<p>The merged importance scores in case both <code>x</code> and <code>y</code> had importance calculated.
Shadow importance appears only if both models had it enabled.</p>
</td></tr>
<tr><td><code>oobScores</code></td>
<td>
<p>OOB scores, if can be computed; namely if both models had it calculated and <code>ignoreObjectConsistency</code> was not used.</p>
</td></tr>
<tr><td><code>oobPreds</code></td>
<td>
<p>A vector of OOB predictions of class for each object in training set, if can be computed.</p>
</td></tr>
<tr><td><code>oobConfusionMatrix</code></td>
<td>
<p>OOB confusion matrix, if can be computed.
Namely, when <code>oobScores</code> could be and <code>trueY</code> is provided.</p>
</td></tr>
<tr><td><code>timeTaken</code></td>
<td>
<p>Time used to train the model, calculated as a sum of training times of <code>x</code> and <code>y</code>.</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>
<p>Numerical vector of three elements: <code>classes</code>, <code>depth</code> and <code>ferns</code>.</p>
</td></tr>
<tr><td><code>classLabels</code></td>
<td>
<p>Copy of <code>levels(Y)</code> after purging unused levels.</p>
</td></tr>
<tr><td><code>isStruct</code></td>
<td>
<p>Copy of the train set structure.</p>
</td></tr>
<tr><td><code>merged</code></td>
<td>
<p>Set to <code>TRUE</code> to mark that merging was done.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>In case of different training object sets were used to build the merged models, merged importance is calculated but mileage may vary; for substantially different sets it may become biased.
Your have been warned.
</p>
<p>Shadow importance is only merged when both models have shadow importance and the same <code>consistentSeed</code> value; otherwise shadow importance would be biased down.
</p>
<p>The order of objects in <code>x</code> and <code>y</code> is not important; the only exception is merging with <code>NULL</code>, in which case <code>x</code> must be an <code>rFerns</code> object for R to use proper merge method.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(77)
#Fetch Iris data
data(iris)
#Build models
rFerns(Species~.,data=iris)-&gt;modelA
rFerns(Species~.,data=iris)-&gt;modelB
modelAB&lt;-merge(modelA,modelB)
print(modelA)
print(modelAB)
</code></pre>

<hr>
<h2 id='naiveWrapper'>Naive feature selection method utilising the rFerns shadow imporance</h2><span id='topic+naiveWrapper'></span>

<h3>Description</h3>

<p>Proof-of-concept ensemble of rFerns models, built to stabilise and improve selection based on shadow importance.
It employs a super-ensemble of <code>iterations</code> small rFerns forests, each built on a subspace of <code>size</code> attributes, which is selected randomly, but with a higher selection probability for attributes claimed important by previous sub-models.
Final selection is a group of attributes which hold a substantial weight at the end of the procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>naiveWrapper(
  x,
  y,
  iterations = 1000,
  depth = 5,
  ferns = 100,
  size = 30,
  lambda = 5,
  threads = 0,
  saveHistory = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="naiveWrapper_+3A_x">x</code></td>
<td>
<p>Data frame containing attributes; must have unique names and contain only numeric, integer or (ordered) factor columns.
Factors must have less than 31 levels. No <code>NA</code> values are permitted.</p>
</td></tr>
<tr><td><code id="naiveWrapper_+3A_y">y</code></td>
<td>
<p>A decision vector. Must a factor of the same length as <code>nrow(X)</code> for ordinary many-label classification, or a logical matrix with each column corresponding to a class for multi-label classification.</p>
</td></tr>
<tr><td><code id="naiveWrapper_+3A_iterations">iterations</code></td>
<td>
<p>Number of iterations i.e., the number of sub-models built.</p>
</td></tr>
<tr><td><code id="naiveWrapper_+3A_depth">depth</code></td>
<td>
<p>The depth of the ferns; must be in 1&ndash;16 range. Note that time and memory requirements scale with <code>2^depth</code>.</p>
</td></tr>
<tr><td><code id="naiveWrapper_+3A_ferns">ferns</code></td>
<td>
<p>Number of ferns to be build in each sub-model. This should be a small number, around 3-5 times <code>size</code>.</p>
</td></tr>
<tr><td><code id="naiveWrapper_+3A_size">size</code></td>
<td>
<p>Number of attributes considered by each sub-model.</p>
</td></tr>
<tr><td><code id="naiveWrapper_+3A_lambda">lambda</code></td>
<td>
<p>Lambda parameter driving the re-weighting step of the method.</p>
</td></tr>
<tr><td><code id="naiveWrapper_+3A_threads">threads</code></td>
<td>
<p>Number of parallel threads, copied to the underlying <code>rFerns</code> call.</p>
</td></tr>
<tr><td><code id="naiveWrapper_+3A_savehistory">saveHistory</code></td>
<td>
<p>Should weight history be stored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>naiveWrapper</code>, which is a list with the following components:
</p>
<table>
<tr><td><code>found</code></td>
<td>
<p>Names of all selected attributes.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>Vector of weights indicating the confidence that certain feature is relevant.</p>
</td></tr>
<tr><td><code>timeTaken</code></td>
<td>
<p>Time of computation.</p>
</td></tr>
<tr><td><code>weightHistory</code></td>
<td>
<p>History of weights over all iterations, present if <code>saveHistory</code> was <code>TRUE</code>.</p>
</td></tr>
<tr><td><code>params</code></td>
<td>
<p>Copies of algorithm parameters, <code>iterations</code>, <code>depth</code>, <code>ferns</code> and <code>size</code>, as a named vector.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Kursa MB (2017). <em>Efficient all relevant feature selection with random ferns</em>. In: Kryszkiewicz M., Appice A., Slezak D., Rybinski H., Skowron A., Ras Z. (eds) Foundations of Intelligent Systems. ISMIS 2017. Lecture Notes in Computer Science, vol 10352. Springer, Cham.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(77)
#Fetch Iris data
data(iris)
#Extend with random noise
noisyIris&lt;-cbind(iris[,-5],apply(iris[,-5],2,sample))
names(noisyIris)[5:8]&lt;-sprintf("Nonsense%d",1:4)
#Execute selection
naiveWrapper(noisyIris,iris$Species,iterations=50,ferns=20,size=8)
</code></pre>

<hr>
<h2 id='predict.rFerns'>Prediction with random ferns model</h2><span id='topic+predict.rFerns'></span>

<h3>Description</h3>

<p>This function predicts classes of new objects with given <code>rFerns</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rFerns'
predict(object, x, scores = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.rFerns_+3A_object">object</code></td>
<td>
<p>Object of a class <code>rFerns</code>; a model that will be used for prediction.</p>
</td></tr>
<tr><td><code id="predict.rFerns_+3A_x">x</code></td>
<td>
<p>Data frame containing attributes; must have corresponding names to training set (although order is not important) and do not introduce new factor levels.
If this argument is not given, OOB predictions on the training set will be returned.</p>
</td></tr>
<tr><td><code id="predict.rFerns_+3A_scores">scores</code></td>
<td>
<p>If <code>TRUE</code>, the result will contain score matrix instead of simple predictions.</p>
</td></tr>
<tr><td><code id="predict.rFerns_+3A_...">...</code></td>
<td>
<p>Additional parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Predictions.
If <code>scores</code> is <code>TRUE</code>, a factor vector (for many-class classification) or a logical data.frame (for multi-class classification) with predictions, else a data.frame with class' scores.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(77)
#Fetch Iris data
data(iris)
#Split into tRain and tEst set
iris[c(TRUE,FALSE),]-&gt;irisR
iris[c(FALSE,TRUE),]-&gt;irisE
#Build model
rFerns(Species~.,data=irisR)-&gt;model
print(model)

#Test
predict(model,irisE)-&gt;p
print(table(
 Predictions=p,
 True=irisE[["Species"]]))
err&lt;-mean(p!=irisE[["Species"]])
print(paste("Test error",err,sep=" "))

#Show first OOB scores
head(predict(model,scores=TRUE))
</code></pre>

<hr>
<h2 id='rFerns'>Classification with random ferns</h2><span id='topic+rFerns'></span><span id='topic+rFerns.formula'></span><span id='topic+rFerns.matrix'></span><span id='topic+rFerns.default'></span>

<h3>Description</h3>

<p>This function builds a random ferns model on the given training data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rFerns(x, ...)

## S3 method for class 'formula'
rFerns(formula, data = .GlobalEnv, ...)

## S3 method for class 'matrix'
rFerns(x, y, ...)

## Default S3 method:
rFerns(
  x,
  y,
  depth = 5,
  ferns = 1000,
  importance = "none",
  saveForest = TRUE,
  consistentSeed = NULL,
  threads = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rFerns_+3A_x">x</code></td>
<td>
<p>Data frame containing attributes; must have unique names and contain only numeric, integer or (ordered) factor columns.
Factors must have less than 31 levels. No <code>NA</code> values are permitted.</p>
</td></tr>
<tr><td><code id="rFerns_+3A_...">...</code></td>
<td>
<p>For formula and matrix methods, a place to state parameters to be passed to default method.
For the print method, arguments to be passed to <code>print</code>.</p>
</td></tr>
<tr><td><code id="rFerns_+3A_formula">formula</code></td>
<td>
<p>alternatively, formula describing model to be analysed.</p>
</td></tr>
<tr><td><code id="rFerns_+3A_data">data</code></td>
<td>
<p>in which to interpret formula.</p>
</td></tr>
<tr><td><code id="rFerns_+3A_y">y</code></td>
<td>
<p>A decision vector. Must a factor of the same length as <code>nrow(X)</code> for ordinary many-label classification, or a logical matrix with each column corresponding to a class for multi-label classification.</p>
</td></tr>
<tr><td><code id="rFerns_+3A_depth">depth</code></td>
<td>
<p>The depth of the ferns; must be in 1&ndash;16 range. Note that time and memory requirements scale with <code>2^depth</code>.</p>
</td></tr>
<tr><td><code id="rFerns_+3A_ferns">ferns</code></td>
<td>
<p>Number of ferns to be build.</p>
</td></tr>
<tr><td><code id="rFerns_+3A_importance">importance</code></td>
<td>
<p>Set to calculate attribute importance measure (VIM);
<code>"simple"</code> will calculate the default mean decrease of true class score (MDTS, something similar to Random Forest's MDA/MeanDecreaseAccuracy),
<code>"shadow"</code> will calculate MDTS and additionally MDTS of this attribute shadow, an implicit feature build by shuffling values within it, thus stripping it from information (which is slightly slower).
Shadow importance is useful as a reference to judge significance of a regular importance.
<code>"none"</code> turns importance calculation off, for a slightly faster execution.
For compatibility with pre-1.2 rFerns, <code>TRUE</code> will resolve to <code>"simple"</code> and <code>FALSE</code> to <code>"none"</code>.
Abbreviation can be used instead of a full value.</p>
</td></tr>
<tr><td><code id="rFerns_+3A_saveforest">saveForest</code></td>
<td>
<p>Should the model be saved? It must be <code>TRUE</code> if you want to use the model for prediction; however, if you are interested in importance or OOB error only, setting it to <code>FALSE</code> significantly improves memory requirements, especially for large <code>depth</code> and <code>ferns</code>.</p>
</td></tr>
<tr><td><code id="rFerns_+3A_consistentseed">consistentSeed</code></td>
<td>
<p>PRNG seed used for shadow importance <em>only</em>.
Must be either a 2-element integer vector or <code>NULL</code>, which corresponds to seeding from the default PRNG.</p>
</td></tr>
<tr><td><code id="rFerns_+3A_threads">threads</code></td>
<td>
<p>Number or OpenMP threads to use. The default value of <code>0</code> means all available to OpenMP.
It should be set to the same value in two merged models to make shadow importance meaningful.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>rFerns</code>, which is a list with the following components:
</p>
<table>
<tr><td><code>model</code></td>
<td>
<p>The built model; <code>NULL</code> if <code>saveForest</code> was <code>FALSE</code>.</p>
</td></tr>
<tr><td><code>oobErr</code></td>
<td>
<p>OOB approximation of accuracy.
Ignores never-OOB-tested objects (see oobScores element).</p>
</td></tr>
<tr><td><code>importance</code></td>
<td>
<p>The importance scores or <code>NULL</code> if <code>importance</code> was set to <code>"none"</code>.
In a first case it is a <code>data.frame</code> with two or three columns:
<code>MeanScoreLoss</code> which is a mean decrease of a score of a correct class when a certain attribute is permuted,
<code>Tries</code> which is number of ferns which utilised certain attribute, and, only when <code>importance</code> was set to <code>"shadow"</code>,
<code>Shadow</code>, which is a mean decrease of accuracy for the correct class for a permuted copy of an attribute (useful as a baseline for normal importance).
The <code>rownames</code> are set and equal to the <code>names(x)</code>.</p>
</td></tr>
<tr><td><code>oobScores</code></td>
<td>
<p>A matrix of OOB scores of each class for each object in training set.
Rows correspond to classes in the same order as in <code>levels(Y)</code>.
If the <code>ferns</code> is too small, some columns may contain <code>NA</code>s, what means that certain objects were never in test set.</p>
</td></tr>
<tr><td><code>oobPreds</code></td>
<td>
<p>A vector of OOB predictions of class for each object in training set. Never-OOB-tested objects (see above) have predictions equal to <code>NA</code>.</p>
</td></tr>
<tr><td><code>oobConfusionMatrix</code></td>
<td>
<p>Confusion matrix build from <code>oobPreds</code> and <code>y</code>.</p>
</td></tr>
<tr><td><code>timeTaken</code></td>
<td>
<p>Time used to train the model (smaller than wall time because data preparation and model final touches are excluded; however it includes the time needed to compute importance, if it applies).
An object of <code>difftime</code> class.</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>
<p>Numerical vector of three elements: <code>classes</code>, <code>depth</code> and <code>ferns</code>, containing respectively the number of classes in decision and copies of <code>depth</code> and <code>ferns</code> parameters.</p>
</td></tr>
<tr><td><code>classLabels</code></td>
<td>
<p>Copy of <code>levels(Y)</code> after purging unused levels.</p>
</td></tr>
<tr><td><code>consistentSeed</code></td>
<td>
<p>Consistent seed used; only present for <code>importance="shadow"</code>.
Can be used to seed a new model via <code>consistentSeed</code> argument.</p>
</td></tr>
<tr><td><code>isStruct</code></td>
<td>
<p>Copy of the train set structure, required internally by predict method.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The unused levels of the decision will be removed; on the other hand unused levels of categorical attributes will be preserved, so that they could be present in the data later predicted with the model.
The levels of ordered factors in training and predicted data must be identical.
</p>
<p>Do not use formula interface for a data with large number of attributes; the overhead from handling the formula may be significant.
</p>


<h3>References</h3>

<p>Ozuysal M, Calonder M, Lepetit V &amp; Fua P. (2009). <em>Fast Keypoint Recognition using Random Ferns</em>, IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(3), 448-461.
</p>
<p>Kursa MB (2014). <em>rFerns: An Implementation of the Random Ferns Method for General-Purpose Machine Learning</em>, Journal of Statistical Software, 61(10), 1-13.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(77)
#Fetch Iris data
data(iris)
#Build model
rFerns(Species~.,data=iris)
##Importance
rFerns(Species~.,data=iris,importance="shadow")-&gt;model
print(model$imp)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
