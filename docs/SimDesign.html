<!DOCTYPE html><html><head><title>Help for package SimDesign</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SimDesign}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#SimDesign'><p>Structure for Organizing Monte Carlo Simulation Designs</p></a></li>
<li><a href='#add_missing'><p>Add missing values to a vector given a MCAR, MAR, or MNAR scheme</p></a></li>
<li><a href='#aggregate_simulations'><p>Collapse separate simulation files into a single result</p></a></li>
<li><a href='#Analyse'><p>Compute estimates and statistics</p></a></li>
<li><a href='#AnalyseIf'><p>Perform a test that indicates whether a given <code>Analyse()</code> function should be executed</p></a></li>
<li><a href='#Attach'><p>Attach objects for easier reference</p></a></li>
<li><a href='#BF_sim'><p>Example simulation from Brown and Forsythe (1974)</p></a></li>
<li><a href='#BF_sim_alternative'><p>(Alternative) Example simulation from Brown and Forsythe (1974)</p></a></li>
<li><a href='#bias'><p>Compute (relative/standardized) bias summary statistic</p></a></li>
<li><a href='#boot_predict'><p>Compute prediction estimates for the replication size using bootstrap MSE estimates</p></a></li>
<li><a href='#Bradley1978'><p>Bradley's (1978) empirical robustness interval</p></a></li>
<li><a href='#CC'><p>Compute congruence coefficient</p></a></li>
<li><a href='#colVars'><p>Form Column Standard Deviation and Variances</p></a></li>
<li><a href='#convertWarnings'><p>Wrapper to convert all/specific warning messages to errors</p></a></li>
<li><a href='#createDesign'><p>Create the simulation Design object</p></a></li>
<li><a href='#ECR'><p>Compute empirical coverage rates</p></a></li>
<li><a href='#EDR'><p>Compute the empirical detection/rejection rate for Type I errors and Power</p></a></li>
<li><a href='#Generate'><p>Generate data</p></a></li>
<li><a href='#GenerateIf'><p>Perform a test that indicates whether a given <code>Generate()</code> function should be executed</p></a></li>
<li><a href='#IRMSE'><p>Compute the integrated root mean-square error</p></a></li>
<li><a href='#MAE'><p>Compute the mean absolute error</p></a></li>
<li><a href='#MSRSE'><p>Compute the relative performance behavior of collections of standard errors</p></a></li>
<li><a href='#nc'><p>Auto-named Concatenation of Vector or List</p></a></li>
<li><a href='#PBA'><p>Probabilistic Bisection Algorithm</p></a></li>
<li><a href='#quiet'><p>Suppress function messages and Concatenate and Print (cat)</p></a></li>
<li><a href='#RAB'><p>Compute the relative absolute bias of multiple estimators</p></a></li>
<li><a href='#rbind.SimDesign'><p>Combine two separate SimDesign objects by row</p></a></li>
<li><a href='#RD'><p>Compute the relative difference</p></a></li>
<li><a href='#RE'><p>Compute the relative efficiency of multiple estimators</p></a></li>
<li><a href='#rejectionSampling'><p>Rejection sampling (i.e., accept-reject method)</p></a></li>
<li><a href='#reSummarise'><p>Run a summarise step for results that have been saved to the hard drive</p></a></li>
<li><a href='#rHeadrick'><p>Generate non-normal data with Headrick's (2002) method</p></a></li>
<li><a href='#rint'><p>Generate integer values within specified range</p></a></li>
<li><a href='#rinvWishart'><p>Generate data with the inverse Wishart distribution</p></a></li>
<li><a href='#rmgh'><p>Generate data with the multivariate g-and-h distribution</p></a></li>
<li><a href='#RMSE'><p>Compute the (normalized) root mean square error</p></a></li>
<li><a href='#rmvnorm'><p>Generate data with the multivariate normal (i.e., Gaussian) distribution</p></a></li>
<li><a href='#rmvt'><p>Generate data with the multivariate t distribution</p></a></li>
<li><a href='#RobbinsMonro'><p>Robbins-Monro (1951) stochastic root-finding algorithm</p></a></li>
<li><a href='#RSE'><p>Compute the relative standard error ratio</p></a></li>
<li><a href='#rtruncate'><p>Generate a random set of values within a truncated range</p></a></li>
<li><a href='#runSimulation'><p>Run a Monte Carlo simulation given a data.frame of conditions and simulation functions</p></a></li>
<li><a href='#rValeMaurelli'><p>Generate non-normal data with Vale &amp; Maurelli's (1983) method</p></a></li>
<li><a href='#Serlin2000'><p>Empirical detection robustness method suggested by Serlin (2000)</p></a></li>
<li><a href='#SFA'><p>Surrogate Function Approximation via the Generalized Linear Model</p></a></li>
<li><a href='#SimAnova'><p>Function for decomposing the simulation into ANOVA-based effect sizes</p></a></li>
<li><a href='#SimCheck'><p>Check the status of the simulation's temporary results</p></a></li>
<li><a href='#SimClean'><p>Removes/cleans files and folders that have been saved</p></a></li>
<li><a href='#SimExtract'><p>Function to extract extra information from SimDesign objects</p></a></li>
<li><a href='#SimFunctions'><p>Template-based generation of the Generate-Analyse-Summarise functions</p></a></li>
<li><a href='#SimResults'><p>Function to read in saved simulation results</p></a></li>
<li><a href='#SimShiny'><p>Generate a basic Monte Carlo simulation GUI template</p></a></li>
<li><a href='#SimSolve'><p>One Dimensional Root (Zero) Finding in Simulation Experiments</p></a></li>
<li><a href='#Summarise'><p>Summarise simulated data using various population comparison statistics</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Structure for Organizing Monte Carlo Simulation Designs</td>
</tr>
<tr>
<td>Version:</td>
<td>2.14</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides tools to safely and efficiently organize and execute 
    Monte Carlo simulation experiments in R.
    The package controls the structure and back-end of Monte Carlo simulation experiments
    by utilizing a generate-analyse-summarise workflow. The workflow safeguards against 
    common simulation coding issues, such as automatically re-simulating non-convergent results, 
    prevents inadvertently overwriting simulation files, catches error and warning messages
    during execution, and implicitly supports parallel processing.
    For a pedagogical introduction to the package see
    Sigal and Chalmers (2016) &lt;<a href="https://doi.org/10.1080%2F10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>&gt;. For a more in-depth overview of 
    the package and its design philosophy see Chalmers and Adkins (2020) &lt;<a href="https://doi.org/10.20982%2Ftqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>&gt;.</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>foreach, methods, parallel, dplyr, sessioninfo, beepr, pbapply
(&ge; 1.3-0), RPushbullet, future, future.apply, progressr, stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, ggplot2, tidyr, purrr, shiny, doMPI, copula,
extraDistr, renv, cli, job, future.batchtools, FrF2, rmarkdown</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/philchalmers/SimDesign">https://github.com/philchalmers/SimDesign</a>,
<a href="https://github.com/philchalmers/SimDesign/wiki">https://github.com/philchalmers/SimDesign/wiki</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-08 16:12:20 UTC; phil</td>
</tr>
<tr>
<td>Author:</td>
<td>Phil Chalmers <a href="https://orcid.org/0000-0001-5332-2810"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Matthew Sigal [ctb],
  Ogreden Oguzhan [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Phil Chalmers &lt;rphilip.chalmers@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-09 09:10:11 UTC</td>
</tr>
</table>
<hr>
<h2 id='SimDesign'>Structure for Organizing Monte Carlo Simulation Designs</h2><span id='topic+SimDesign'></span><span id='topic+SimDesign-package'></span>

<h3>Description</h3>

<p>Structure for Organizing Monte Carlo Simulation Designs
</p>


<h3>Details</h3>

<p>Provides tools to help organize Monte Carlo simulations in R. The package
controls the structure and back-end of Monte Carlo simulations
by utilizing a general generate-analyse-summarise strategy. The functions provided control common
simulation issues such as re-simulating non-convergent results, support parallel
back-end and MPI distributed computations, save and restore temporary files,
aggregate results across independent nodes, and provide native support for debugging.
The primary function for organizing the simulations is <code><a href="#topic+runSimulation">runSimulation</a></code>.
For an in-depth tutorial of the package please refer to
Chalmers and Adkins (2020; <a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>).
For an earlier didactic presentation of the package users can refer to Sigal and Chalmers
(2016; <a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>). Finally, see the associated
wiki on Github (<a href="https://github.com/philchalmers/SimDesign/wiki">https://github.com/philchalmers/SimDesign/wiki</a>)
for other tutorial material, examples, and applications of <code>SimDesign</code> to real-world simulations.
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>

<hr>
<h2 id='add_missing'>Add missing values to a vector given a MCAR, MAR, or MNAR scheme</h2><span id='topic+add_missing'></span>

<h3>Description</h3>

<p>Given an input vector, replace elements of this vector with missing values according to some scheme.
Default method replaces input values with a MCAR scheme (where on average 10% of the values will be
replaced with <code>NA</code>s). MAR and MNAR are supported by replacing the default <code>FUN</code> argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_missing(y, fun = function(y, rate = 0.1, ...) rep(rate, length(y)), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_missing_+3A_y">y</code></td>
<td>
<p>an input vector that should contain missing data in the form of <code>NA</code>'s</p>
</td></tr>
<tr><td><code id="add_missing_+3A_fun">fun</code></td>
<td>
<p>a user defined function indicating the missing data mechanism for each element in <code>y</code>.
Function must return a vector of probability values with the length equal to the length of <code>y</code>.
Each value in the returned vector indicates the probability that
the respective element in y will be replaced with <code>NA</code>.
Function must contain the argument <code>y</code>, representing the
input vector, however any number of additional arguments can be included</p>
</td></tr>
<tr><td><code id="add_missing_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code>FUN</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given an input vector y, and other relevant variables
inside (X) and outside (Z) the data-set, the three types of missingness are:
</p>

<dl>
<dt>MCAR</dt><dd><p>Missing completely at random (MCAR). This is realized by randomly
sampling the values of the
input vector (y) irrespective of the possible values in X and Z.
Therefore missing values are randomly sampled and do not depend on any data characteristics and
are truly random</p>
</dd>
<dt>MAR</dt><dd><p>Missing at random (MAR). This is realized when values in the dataset (X)
predict the missing data  mechanism in y; conceptually this is equivalent to
<code class="reqn">P(y = NA | X)</code>. This requires the user to define a custom missing data function</p>
</dd>
<dt>MNAR</dt><dd><p>Missing not at random (MNAR). This is similar to MAR except
that the missing mechanism comes
from the value of y itself or from variables outside the working dataset;
conceptually this is equivalent to <code class="reqn">P(y = NA | X, Z, y)</code>. This requires
the user to define a custom missing data function</p>
</dd>
</dl>



<h3>Value</h3>

<p>the input vector <code>y</code> with the sampled <code>NA</code> values
(according to the <code>FUN</code> scheme)
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

set.seed(1)
y &lt;- rnorm(1000)

## 10% missing rate with default FUN
head(ymiss &lt;- add_missing(y), 10)

## 50% missing with default FUN
head(ymiss &lt;- add_missing(y, rate = .5), 10)

## missing values only when female and low
X &lt;- data.frame(group = sample(c('male', 'female'), 1000, replace=TRUE),
                level = sample(c('high', 'low'), 1000, replace=TRUE))
head(X)

fun &lt;- function(y, X, ...){
    p &lt;- rep(0, length(y))
    p[X$group == 'female' &amp; X$level == 'low'] &lt;- .2
    p
}

ymiss &lt;- add_missing(y, X, fun=fun)
tail(cbind(ymiss, X), 10)

## missingness as a function of elements in X (i.e., a type of MAR)
fun &lt;- function(y, X){
   # missingness with a logistic regression approach
   df &lt;- data.frame(y, X)
   mm &lt;- model.matrix(y ~ group + level, df)
   cfs &lt;- c(-5, 2, 3) #intercept, group, and level coefs
   z &lt;- cfs %*% t(mm)
   plogis(z)
}

ymiss &lt;- add_missing(y, X, fun=fun)
tail(cbind(ymiss, X), 10)

## missing values when y elements are large (i.e., a type of MNAR)
fun &lt;- function(y) ifelse(abs(y) &gt; 1, .4, 0)
ymiss &lt;- add_missing(y, fun=fun)
tail(cbind(y, ymiss), 10)


## End(Not run)

</code></pre>

<hr>
<h2 id='aggregate_simulations'>Collapse separate simulation files into a single result</h2><span id='topic+aggregate_simulations'></span>

<h3>Description</h3>

<p>This function aggregates the results from SimDesign's <code><a href="#topic+runSimulation">runSimulation</a></code> into a single
objects suitable for post-analyses, or combines all the saved results directories and combines
them into one. This is useful when results are run piecewise on one node (e.g., 500 replications
in one batch, 500 again at a later date) or run independently across different
nodes/computers that are not on the same network.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aggregate_simulations(
  files = NULL,
  file_name = "SimDesign_aggregate.rds",
  dirs = NULL,
  results_dirname = "SimDesign_aggregate_results"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aggregate_simulations_+3A_files">files</code></td>
<td>
<p>a <code>character</code> vector containing the names of the simulation's final <code>.rds</code> files</p>
</td></tr>
<tr><td><code id="aggregate_simulations_+3A_file_name">file_name</code></td>
<td>
<p>name of .rds file to save aggregate simulation file to. Default is
<code>'SimDesign_aggregate.rds'</code></p>
</td></tr>
<tr><td><code id="aggregate_simulations_+3A_dirs">dirs</code></td>
<td>
<p>a <code>character</code> vector containing the names of the <code>save_results</code> directories to be
aggregated. A new folder will be created and placed in the <code>results_dirname</code> output folder</p>
</td></tr>
<tr><td><code id="aggregate_simulations_+3A_results_dirname">results_dirname</code></td>
<td>
<p>the new directory to place the aggregated results files</p>
</td></tr>
</table>


<h3>Value</h3>

<p>if <code>files</code> is used the function returns a <code>data.frame</code> with the (weighted) average
of the simulation results. Otherwise, if <code>dirs</code> is used, the function returns NULL
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+runSimulation">runSimulation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

setwd('my_working_directory')

## run simulations to save the .rds files (or move them to the working directory)
# ret1 &lt;- runSimulation(..., filename='file1')
# ret2 &lt;- runSimulation(..., filename='file2')

# saves to the hard-drive and stores in workspace
final &lt;- aggregate_simulations(files = c('file1.rds', 'file2.rds'))
final

# If filename not included, can be extracted from results
# files &lt;- c(SimExtract(ret1, 'filename'), SimExtract(ret2, 'filename'))
# final &lt;- aggregate_simulations(files = files)

# aggregate saved results for .rds files and results directories
# runSimulation(..., save_results = TRUE, save_details = list(save_results_dirname = 'dir1'))
# runSimulation(..., save_results = TRUE, save_details = list(save_results_dirname = 'dir2'))

# place new saved results in 'SimDesign_results/' by default
aggregate_simulations(files = c('file1.rds', 'file2.rds'),
                      dirs = c('dir1', 'dir2'))

# If dirnames not included, can be extracted from results
# dirs &lt;- c(SimExtract(ret1, 'save_results_dirname'),
            SimExtract(ret2, 'save_results_dirname'))
# aggregate_simulations(dirs = dirs)


## End(Not run)
</code></pre>

<hr>
<h2 id='Analyse'>Compute estimates and statistics</h2><span id='topic+Analyse'></span>

<h3>Description</h3>

<p>Compute all relevant test statistics, parameter estimates, detection rates, and so on.
This is the computational heavy lifting portion of the Monte Carlo simulation. Users
may define a single Analysis function to perform all the analyses in the same function environment,
or may define a <code>list</code> of named functions to <code><a href="#topic+runSimulation">runSimulation</a></code> to allow for a more
modularized approach to performing the analyses in independent blocks (but that share the same generated
data). Note that if a suitable <code><a href="#topic+Generate">Generate</a></code> function was not supplied then this function
can be used to be generate and analyse the Monte Carlo data (though in general this
setup is not recommended for larger simulations).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Analyse(condition, dat, fixed_objects = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Analyse_+3A_condition">condition</code></td>
<td>
<p>a single row from the design input (as a <code>data.frame</code>), indicating the
simulation conditions</p>
</td></tr>
<tr><td><code id="Analyse_+3A_dat">dat</code></td>
<td>
<p>the <code>dat</code> object returned from the <code><a href="#topic+Generate">Generate</a></code> function
(usually a <code>data.frame</code>, <code>matrix</code>, <code>vector</code>, or <code>list</code>)</p>
</td></tr>
<tr><td><code id="Analyse_+3A_fixed_objects">fixed_objects</code></td>
<td>
<p>object passed down from <code><a href="#topic+runSimulation">runSimulation</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>In some cases, it may be easier to change the output to a named <code>list</code> containing
different parameter configurations (e.g., when
determining RMSE values for a large set of population parameters).
</p>
<p>The use of <code><a href="base.html#topic+try">try</a></code> functions is generally not required in this function because <code>Analyse</code>
is internally wrapped in a <code><a href="base.html#topic+try">try</a></code> call. Therefore, if a function stops early
then this will cause the function to halt internally, the message which triggered the <code><a href="base.html#topic+stop">stop</a></code>
will be recorded, and <code><a href="#topic+Generate">Generate</a></code> will be called again to obtain a different dataset.
That said, it may be useful for users to throw their own <code><a href="base.html#topic+stop">stop</a></code> commands if the data
should be re-drawn for other reasons (e.g., an estimated model terminated correctly
but the maximum number of iterations were reached).
</p>


<h3>Value</h3>

<p>returns a named <code>numeric</code> vector or <code>data.frame</code> with the values of interest
(e.g., p-values, effects sizes, etc), or a <code>list</code> containing values of interest
(e.g., separate matrix and vector of parameter estimates corresponding to elements in
<code>parameters</code>). If a <code>data.frame</code> is returned with more than 1 row then these
objects will be wrapped into suitable <code>list</code> objects
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+stop">stop</a></code>, <code><a href="#topic+AnalyseIf">AnalyseIf</a></code>, <code><a href="#topic+convertWarnings">convertWarnings</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

analyse &lt;- function(condition, dat, fixed_objects = NULL) {

    # require packages/define functions if needed, or better yet index with the :: operator
    require(stats)
    mygreatfunction &lt;- function(x) print('Do some stuff')

    #wrap computational statistics in try() statements to control estimation problems
    welch &lt;- t.test(DV ~ group, dat)
    ind &lt;- stats::t.test(DV ~ group, dat, var.equal=TRUE)

    # In this function the p values for the t-tests are returned,
    #  and make sure to name each element, for future reference
    ret &lt;- c(welch = welch$p.value,
             independent = ind$p.value)

    return(ret)
}

# A more modularized example approach

analysis_welch &lt;- function(condition, dat, fixed_objects = NULL) {
    welch &lt;- t.test(DV ~ group, dat)
    ret &lt;- c(p=welch$p.value)
    ret
}

analysis_ind &lt;- function(condition, dat, fixed_objects = NULL) {
    ind &lt;- t.test(DV ~ group, dat, var.equal=TRUE)
    ret &lt;- c(p=ind$p.value)
    ret
}

# pass functions as a named list
# runSimulation(..., analyse=list(welch=analyse_welch, independent=analysis_ind))


## End(Not run)
</code></pre>

<hr>
<h2 id='AnalyseIf'>Perform a test that indicates whether a given <code>Analyse()</code> function should be executed</h2><span id='topic+AnalyseIf'></span>

<h3>Description</h3>

<p>This function is designed to prevent specific analysis function executions when the
design conditions are not met. Primarily useful when the <code>analyse</code> argument to
<code><a href="#topic+runSimulation">runSimulation</a></code> was input as a named list object, however some of the
analysis functions are not interesting/compatible with the generated data and should
therefore be skipped.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AnalyseIf(x, condition = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AnalyseIf_+3A_x">x</code></td>
<td>
<p>logical statement to evaluate. If the statement evaluates to <code>TRUE</code>
then the remainder of the defined function will be evaluated</p>
</td></tr>
<tr><td><code id="AnalyseIf_+3A_condition">condition</code></td>
<td>
<p>(optional) the current design condition. This does not need to be supplied
if the expression in <code>x</code> evaluates to valid logical (e.g., use <code>Attach(condition)</code>
prior to using <code>AnalyseIf</code>, or use <code>with(condition, AnalyseIf(someLogicalTest))</code>)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Analyse">Analyse</a></code>, <code><a href="#topic+runSimulation">runSimulation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

Design &lt;- createDesign(N=c(10,20,30), var.equal = c(TRUE, FALSE))

Generate &lt;- function(condition, fixed_objects = NULL) {
  Attach(condition)
  dat &lt;- data.frame(DV = rnorm(N*2), IV = gl(2, N, labels=c('G1', 'G2')))
  dat
}

# always run this analysis for each row in Design
Analyse1 &lt;- function(condition, dat, fixed_objects = NULL) {
  mod &lt;- t.test(DV ~ IV, data=dat)
  mod$p.value
}

# Only perform analysis when variances are equal and N = 20 or 30
Analyse2 &lt;- function(condition, dat, fixed_objects = NULL) {
  AnalyseIf(var.equal &amp;&amp; N %in% c(20, 30), condition)
  mod &lt;- t.test(DV ~ IV, data=dat, var.equal=TRUE)
  mod$p.value
}

Summarise &lt;- function(condition, results, fixed_objects = NULL) {
  ret &lt;- EDR(results, alpha=.05)
  ret
}

#-------------------------------------------------------------------

# append names 'Welch' and 'independent' to associated output
res &lt;- runSimulation(design=Design, replications=100, generate=Generate,
                     analyse=list(Welch=Analyse1, independent=Analyse2),
                     summarise=Summarise)
res

# leave results unnamed
res &lt;- runSimulation(design=Design, replications=100, generate=Generate,
                     analyse=list(Analyse1, Analyse2),
                     summarise=Summarise)



## End(Not run)

</code></pre>

<hr>
<h2 id='Attach'>Attach objects for easier reference</h2><span id='topic+Attach'></span>

<h3>Description</h3>

<p>The behaviour of this function is very similar to <code><a href="base.html#topic+attach">attach</a></code>,
however it is environment specific, and
therefore only remains defined in a given function rather than in the Global Environment.
Hence, this function is much safer to use than the <code><a href="base.html#topic+attach">attach</a></code>, which
incidentally should never be used in your code. This
is useful primarily as a convenience function when you prefer to call the variable names
in <code>condition</code> directly rather than indexing with <code>condition$sample_size</code> or
<code>with(condition, sample_size)</code>, for example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Attach(
  ...,
  omit = NULL,
  check = TRUE,
  attach_listone = TRUE,
  RStudio_flags = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Attach_+3A_...">...</code></td>
<td>
<p>a comma separated list of <code>data.frame</code>, <code>tibble</code>, <code>list</code>,
or <code>matrix</code> objects containing (column) elements that should be placed in the
current working environment</p>
</td></tr>
<tr><td><code id="Attach_+3A_omit">omit</code></td>
<td>
<p>an optional character vector containing the names of objects that should not
be attached to the current environment. For instance, if the objects named 'a' and 'b' should
not be attached then use <code>omit = c('a', 'b')</code>.
When NULL (default) all objects are attached</p>
</td></tr>
<tr><td><code id="Attach_+3A_check">check</code></td>
<td>
<p>logical; check to see if the function will accidentally replace previously defined
variables with the same names as in <code>condition</code>? Default is <code>TRUE</code>, which will avoid
this error</p>
</td></tr>
<tr><td><code id="Attach_+3A_attach_listone">attach_listone</code></td>
<td>
<p>logical; if the element to be assign is a list of length one
then assign the first element of this list with the associated name. This generally avoids
adding an often unnecessary list 1 index, such as <code>name &lt;- list[[1L]]</code></p>
</td></tr>
<tr><td><code id="Attach_+3A_rstudio_flags">RStudio_flags</code></td>
<td>
<p>logical; print R script output comments that disable flagged
missing variables in RStudio? Requires the form <code>Attach(Design, RStudio_flags=TRUE)</code> or
in an interactive debugging session <code>Attach(condition, RStudio_flags=TRUE)</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that if you are using RStudio with the <em>&quot;Warn if variable used has no definition in scope&quot;</em>
diagnostic flag then using <code>Attach()</code> will raise suspensions. To suppress such issues,
you can either disable such flags (the atomic solution) or evaluate the following output
in the R console and place the output in your working simulation file.
</p>
<p><code>Attach(Design, RStudio_flags = TRUE)</code>
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+runSimulation">runSimulation</a></code>, <code><a href="#topic+Generate">Generate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
Design &lt;- createDesign(N1=c(10,20),
                       N2=c(10,20),
                       sd=c(1,2))
Design

# does not use Attach()
Generate &lt;- function(condition, fixed_objects = NULL) {
    # condition = single row of Design input (e.g., condition &lt;- Design[1,])
    N1 &lt;- condition$N1
    N2 &lt;- condition$N2
    sd &lt;- condition$sd

    group1 &lt;- rnorm(N1)
    group2 &lt;- rnorm(N2, sd=sd)
    dat &lt;- data.frame(group = c(rep('g1', N1), rep('g2', N2)),
                      DV = c(group1, group2))
    dat
}

# similar to above, but using the Attach() function instead of indexing
Generate &lt;- function(condition, fixed_objects = NULL) {
    Attach(condition) # N1, N2, and sd are now 'attached' and visible

    group1 &lt;- rnorm(N1)
    group2 &lt;- rnorm(N2, sd=sd)
    dat &lt;- data.frame(group = c(rep('g1', N1), rep('g2', N2)),
                      DV = c(group1, group2))
    dat
}

#####################
# NOTE: if you're using RStudio with code diagnostics on then evaluate + add the
# following output to your source file to manually support the flagged variables

Attach(Design, RStudio_flags=TRUE)

# Below is the same example, however with false positive missing variables suppressed
# when # !diagnostics ... is added added to the source file(s)

# !diagnostics suppress=N1,N2,sd
Generate &lt;- function(condition, fixed_objects = NULL) {
    Attach(condition) # N1, N2, and sd are now 'attached' and visible

    group1 &lt;- rnorm(N1)
    group2 &lt;- rnorm(N2, sd=sd)
    dat &lt;- data.frame(group = c(rep('g1', N1), rep('g2', N2)),
                      DV = c(group1, group2))
    dat
}


</code></pre>

<hr>
<h2 id='BF_sim'>Example simulation from Brown and Forsythe (1974)</h2><span id='topic+BF_sim'></span>

<h3>Description</h3>

<p>Example results from the Brown and Forsythe (1974) article on robust estimators for
variance ratio tests. Statistical tests are organized by columns and the unique design conditions
are organized by rows. See <code><a href="#topic+BF_sim_alternative">BF_sim_alternative</a></code> for an alternative form of the same
simulation. Code for this simulation is available of the wiki
(<a href="https://github.com/philchalmers/SimDesign/wiki">https://github.com/philchalmers/SimDesign/wiki</a>).
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Brown, M. B. and Forsythe, A. B. (1974). Robust tests for the equality of variances.
<em>Journal of the American Statistical Association, 69</em>(346), 364&ndash;367.
</p>
<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
data(BF_sim)
head(BF_sim)

#Type I errors
subset(BF_sim, var_ratio == 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='BF_sim_alternative'>(Alternative) Example simulation from Brown and Forsythe (1974)</h2><span id='topic+BF_sim_alternative'></span>

<h3>Description</h3>

<p>Example results from the Brown and Forsythe (1974) article on robust estimators for
variance ratio tests. Statistical tests and distributions are organized by columns
and the unique design conditions are organized by rows. See <code><a href="#topic+BF_sim">BF_sim</a></code> for an alternative
form of the same simulation where distributions are also included in the rows.
Code for this simulation is available on the wiki (<a href="https://github.com/philchalmers/SimDesign/wiki">https://github.com/philchalmers/SimDesign/wiki</a>).
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Brown, M. B. and Forsythe, A. B. (1974). Robust tests for the equality of variances.
<em>Journal of the American Statistical Association, 69</em>(346), 364&ndash;367.
</p>
<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
data(BF_sim_alternative)
head(BF_sim_alternative)

#' #Type I errors
subset(BF_sim_alternative, var_ratio == 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='bias'>Compute (relative/standardized) bias summary statistic</h2><span id='topic+bias'></span>

<h3>Description</h3>

<p>Computes the (relative) bias of a sample estimate from the parameter value.
Accepts estimate and parameter values, as well as estimate values which are in deviation form.
If relative bias is requested the <code>estimate</code> and <code>parameter</code> inputs are both required.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bias(
  estimate,
  parameter = NULL,
  type = "bias",
  abs = FALSE,
  percent = FALSE,
  unname = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bias_+3A_estimate">estimate</code></td>
<td>
<p>a <code>numeric</code> vector, <code>matrix</code>/<code>data.frame</code>, or <code>list</code>
of parameter estimates. If a vector,
the length is equal to the number of replications. If a <code>matrix</code>/<code>data.frame</code>,
the number of rows must equal the number of replications. <code>list</code> objects will be looped
over using the same rules after above after first translating the information into one-dimensional
vectors and re-creating the structure upon return</p>
</td></tr>
<tr><td><code id="bias_+3A_parameter">parameter</code></td>
<td>
<p>a <code>numeric</code> scalar/vector indicating the fixed parameters.
If a single value is supplied and <code>estimate</code> is a <code>matrix</code>/<code>data.frame</code>
then the value will be recycled for each column; otherwise, each element will be associated
with each respective column in the <code>estimate</code> input.
If <code>NULL</code> then it will be assumed that the <code>estimate</code> input is in a deviation
form (therefore <code>mean(estimate))</code> will be returned)</p>
</td></tr>
<tr><td><code id="bias_+3A_type">type</code></td>
<td>
<p>type of bias statistic to return. Default (<code>'bias'</code>) computes the standard bias
(average difference between sample and population), <code>'relative'</code> computes
the relative bias statistic (i.e., divide the bias by the value
in <code>parameter</code>; note that multiplying this by 100 gives the &quot;percent bias&quot; measure),
<code>'abs_relative'</code> computes the relative bias but the absolute values of the parameters
are used in the denominator rather than the (potentially) signed input values,
and <code>'standardized'</code> computes the standardized bias estimate
(standard bias divided by the standard deviation of the sample estimates)</p>
</td></tr>
<tr><td><code id="bias_+3A_abs">abs</code></td>
<td>
<p>logical; find the absolute bias between the parameters and estimates? This effectively
just applies the <code><a href="base.html#topic+abs">abs</a></code> transformation to the returned result. Default is FALSE</p>
</td></tr>
<tr><td><code id="bias_+3A_percent">percent</code></td>
<td>
<p>logical; change returned result to percentage by multiplying by 100?
Default is FALSE</p>
</td></tr>
<tr><td><code id="bias_+3A_unname">unname</code></td>
<td>
<p>logical; apply <code><a href="base.html#topic+unname">unname</a></code> to the results to remove any variable
names?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a <code>numeric</code> vector indicating the overall (relative/standardized)
bias in the estimates
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RMSE">RMSE</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pop &lt;- 2
samp &lt;- rnorm(100, 2, sd = 0.5)
bias(samp, pop)
bias(samp, pop, type = 'relative')
bias(samp, pop, type = 'standardized')

dev &lt;- samp - pop
bias(dev)

# equivalent here
bias(mean(samp), pop)

# matrix input
mat &lt;- cbind(M1=rnorm(100, 2, sd = 0.5), M2 = rnorm(100, 2, sd = 1))
bias(mat, parameter = 2)
bias(mat, parameter = 2, type = 'relative')
bias(mat, parameter = 2, type = 'standardized')

# different parameter associated with each column
mat &lt;- cbind(M1=rnorm(1000, 2, sd = 0.25), M2 = rnorm(1000, 3, sd = .25))
bias(mat, parameter = c(2,3))

# same, but with data.frame
df &lt;- data.frame(M1=rnorm(100, 2, sd = 0.5), M2 = rnorm(100, 2, sd = 1))
bias(df, parameter = c(2,2))

# parameters of the same size
parameters &lt;- 1:10
estimates &lt;- parameters + rnorm(10)
bias(estimates, parameters)

# relative difference dividing by the magnitude of parameters
bias(estimates, parameters, type = 'abs_relative')

# relative bias as a percentage
bias(estimates, parameters, type = 'abs_relative', percent = TRUE)


</code></pre>

<hr>
<h2 id='boot_predict'>Compute prediction estimates for the replication size using bootstrap MSE estimates</h2><span id='topic+boot_predict'></span>

<h3>Description</h3>

<p>This function computes bootstrap mean-square error estimates to approximate the sampling behavior
of the meta-statistics in SimDesign's <code>summarise</code> functions. A single design condition is
supplied, and a simulation with <code>max(Rstar)</code> replications is performed whereby the
generate-analyse results are collected. After obtaining these replication values, the
replications are further drawn from (with replacement) using the differing sizes in <code>Rstar</code>
to approximate the bootstrap MSE behavior given different replication sizes. Finally, given these
bootstrap estimates linear regression models are fitted using the predictor term
<code>one_sqrtR = 1 / sqrt(Rstar)</code> to allow extrapolation to replication sizes not observed in
<code>Rstar</code>. For more information about the method and subsequent bootstrap MSE plots,
refer to Koehler, Brown, and Haneuse (2009).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot_predict(
  condition,
  generate,
  analyse,
  summarise,
  fixed_objects = NULL,
  ...,
  Rstar = seq(100, 500, by = 100),
  boot_draws = 1000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boot_predict_+3A_condition">condition</code></td>
<td>
<p>a <code>data.frame</code> consisting of one row from the original <code>design</code>
input object used within <code><a href="#topic+runSimulation">runSimulation</a></code></p>
</td></tr>
<tr><td><code id="boot_predict_+3A_generate">generate</code></td>
<td>
<p>see <code><a href="#topic+runSimulation">runSimulation</a></code></p>
</td></tr>
<tr><td><code id="boot_predict_+3A_analyse">analyse</code></td>
<td>
<p>see <code><a href="#topic+runSimulation">runSimulation</a></code></p>
</td></tr>
<tr><td><code id="boot_predict_+3A_summarise">summarise</code></td>
<td>
<p>see <code><a href="#topic+runSimulation">runSimulation</a></code></p>
</td></tr>
<tr><td><code id="boot_predict_+3A_fixed_objects">fixed_objects</code></td>
<td>
<p>see <code><a href="#topic+runSimulation">runSimulation</a></code></p>
</td></tr>
<tr><td><code id="boot_predict_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code><a href="#topic+runSimulation">runSimulation</a></code></p>
</td></tr>
<tr><td><code id="boot_predict_+3A_rstar">Rstar</code></td>
<td>
<p>a vector containing the size of the bootstrap subsets to obtain. Default
investigates the vector [100, 200, 300, 400, 500] to compute the respective MSE terms</p>
</td></tr>
<tr><td><code id="boot_predict_+3A_boot_draws">boot_draws</code></td>
<td>
<p>number of bootstrap replications to draw. Default is 1000</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a list of linear model objects (via <code><a href="stats.html#topic+lm">lm</a></code>) for each
meta-statistics returned by the <code>summarise()</code> function
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Koehler, E., Brown, E., &amp; Haneuse, S. J.-P. A. (2009). On the Assessment of Monte Carlo Error in
Simulation-Based Statistical Analyses. <em>The American Statistician, 63</em>, 155-162.
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(4321)
Design &lt;- createDesign(sigma = c(1, 2))

#-------------------------------------------------------------------

Generate &lt;- function(condition, fixed_objects = NULL) {
    dat &lt;- rnorm(100, 0, condition$sigma)
    dat
}

Analyse &lt;- function(condition, dat, fixed_objects = NULL) {
    CIs &lt;- t.test(dat)$conf.int
    names(CIs) &lt;- c('lower', 'upper')
    ret &lt;- c(mean = mean(dat), CIs)
    ret
}

Summarise &lt;- function(condition, results, fixed_objects = NULL) {
    ret &lt;- c(mu_bias = bias(results[,1], 0),
             mu_coverage = ECR(results[,2:3], parameter = 0))
    ret
}

## Not run: 
# boot_predict supports only one condition at a time
out &lt;- boot_predict(condition=Design[1L, , drop=FALSE],
    generate=Generate, analyse=Analyse, summarise=Summarise)
out # list of fitted linear model(s)

# extract first meta-statistic
mu_bias &lt;- out$mu_bias

dat &lt;- model.frame(mu_bias)
print(dat)

# original R metric plot
R &lt;- 1 / dat$one_sqrtR^2
plot(R, dat$MSE, type = 'b', ylab = 'MSE', main = "Replications by MSE")

plot(MSE ~ one_sqrtR, dat, main = "Bootstrap prediction plot", xlim = c(0, max(one_sqrtR)),
     ylim = c(0, max(MSE)), ylab = 'MSE', xlab = expression(1/sqrt(R)))
beta &lt;- coef(mu_bias)
abline(a = 0, b = beta, lty = 2, col='red')

# what is the replication value when x-axis = .02? What's its associated expected MSE?
1 / .02^2 # number of replications
predict(mu_bias, data.frame(one_sqrtR = .02)) # y-axis value

# approximately how many replications to obtain MSE = .001?
(beta / .001)^2

## End(Not run)

</code></pre>

<hr>
<h2 id='Bradley1978'>Bradley's (1978) empirical robustness interval</h2><span id='topic+Bradley1978'></span>

<h3>Description</h3>

<p>Robustness interval criteria for empirical detection rate estimates and
empirical coverage estimates defined by Bradley (1978).
See <code><a href="#topic+EDR">EDR</a></code> and <code><a href="#topic+ECR">ECR</a></code> to obtain such estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Bradley1978(
  rate,
  alpha = 0.05,
  type = "liberal",
  CI = FALSE,
  out.logical = FALSE,
  out.labels = c("conservative", "robust", "liberal"),
  unname = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Bradley1978_+3A_rate">rate</code></td>
<td>
<p>(optional) numeric vector containing the empirical detection
rate(s) or empirical confidence interval estimates.
If supplied a character vector with elements defined in
<code>out.labels</code> or a logical vector will be returned indicating whether the
detection rate estimate is considered 'robust'.
</p>
<p>When the input is an empirical coverage rate the argument <code>CI</code> must be
set to <code>TRUE</code>.
</p>
<p>If this input is missing, the interval criteria will be printed to the console</p>
</td></tr>
<tr><td><code id="Bradley1978_+3A_alpha">alpha</code></td>
<td>
<p>Type I error rate to evaluated (default is .05)</p>
</td></tr>
<tr><td><code id="Bradley1978_+3A_type">type</code></td>
<td>
<p>character vector indicating the type of interval classification to use.
Default is 'liberal', however can be 'stringent' to use Bradley's more
stringent robustness criteria</p>
</td></tr>
<tr><td><code id="Bradley1978_+3A_ci">CI</code></td>
<td>
<p>logical; should this robust interval be constructed on empirical detection
rates (<code>FALSE</code>) or empirical coverage rates (<code>TRUE</code>)?</p>
</td></tr>
<tr><td><code id="Bradley1978_+3A_out.logical">out.logical</code></td>
<td>
<p>logical; should the output vector be TRUE/FALSE indicating whether
the supplied empirical detection rate/CI should be considered &quot;robust&quot;? Default is
FALSE, in which case the out.labels elements are used instead</p>
</td></tr>
<tr><td><code id="Bradley1978_+3A_out.labels">out.labels</code></td>
<td>
<p>character vector of length three indicating the classification
labels according to the desired robustness interval</p>
</td></tr>
<tr><td><code id="Bradley1978_+3A_unname">unname</code></td>
<td>
<p>logical; apply <code><a href="base.html#topic+unname">unname</a></code> to the results to remove any variable
names?</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Bradley, J. V. (1978). Robustness? <em>British Journal of Mathematical and
Statistical Psychology, 31</em>, 144-152.
</p>
<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+EDR">EDR</a></code>, <code><a href="#topic+ECR">ECR</a></code>, <code><a href="#topic+Serlin2000">Serlin2000</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# interval criteria used for empirical detection rates
Bradley1978()
Bradley1978(type = 'stringent')
Bradley1978(alpha = .01, type = 'stringent')

# intervals applied to empirical detection rate estimates
edr &lt;- c(test1 = .05, test2 = .027, test3 = .051, test4 = .076, test5 = .024)

Bradley1978(edr)
Bradley1978(edr, out.logical=TRUE) # is robust?

#####
# interval criteria used for coverage estimates

Bradley1978(CI = TRUE)
Bradley1978(CI = TRUE, type = 'stringent')
Bradley1978(CI = TRUE, alpha = .01, type = 'stringent')

# intervals applied to empirical coverage rate estimates
ecr &lt;- c(test1 = .950, test2 = .973, test3 = .949, test4 = .924, test5 = .976)

Bradley1978(ecr, CI=TRUE)
Bradley1978(ecr, CI=TRUE, out.logical=TRUE) # is robust?

</code></pre>

<hr>
<h2 id='CC'>Compute congruence coefficient</h2><span id='topic+CC'></span>

<h3>Description</h3>

<p>Computes the congruence coefficient, also known as an &quot;unadjusted&quot; correlation
or Tucker's congruence coefficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CC(x, y = NULL, unname = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CC_+3A_x">x</code></td>
<td>
<p>a vector or <code>data.frame</code>/<code>matrix</code> containing the
variables to use. If a vector then the input <code>y</code> is required,
otherwise the congruence coefficient is computed for all bivariate
combinations</p>
</td></tr>
<tr><td><code id="CC_+3A_y">y</code></td>
<td>
<p>(optional) the second vector input to use if
<code>x</code> is a vector</p>
</td></tr>
<tr><td><code id="CC_+3A_unname">unname</code></td>
<td>
<p>logical; apply <code><a href="base.html#topic+unname">unname</a></code> to the results to remove any variable
names?</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor">cor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
vec1 &lt;- runif(1000)
vec2 &lt;- runif(1000)

CC(vec1, vec2)
# compare to cor()
cor(vec1, vec2)

# column input
df &lt;- data.frame(vec1, vec2, vec3 = runif(1000))
CC(df)
cor(df)

</code></pre>

<hr>
<h2 id='colVars'>Form Column Standard Deviation and Variances</h2><span id='topic+colVars'></span><span id='topic+colSDs'></span>

<h3>Description</h3>

<p>Form column standard deviation and variances for numeric arrays (or data frames).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colVars(x, na.rm = FALSE, unname = FALSE)

colSDs(x, na.rm = FALSE, unname = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="colVars_+3A_x">x</code></td>
<td>
<p>an array of two dimensions containing numeric, complex, integer or logical values,
or a numeric data frame</p>
</td></tr>
<tr><td><code id="colVars_+3A_na.rm">na.rm</code></td>
<td>
<p>logical; remove missing values in each respective column?</p>
</td></tr>
<tr><td><code id="colVars_+3A_unname">unname</code></td>
<td>
<p>logical; apply <code><a href="base.html#topic+unname">unname</a></code> to the results to remove any variable
names?</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="Matrix.html#topic+colMeans">colMeans</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
results &lt;- matrix(rnorm(100), ncol=4)
colnames(results) &lt;- paste0('stat', 1:4)

colVars(results)
colSDs(results)

results[1,1] &lt;- NA
colSDs(results)
colSDs(results, na.rm=TRUE)
colSDs(results, na.rm=TRUE, unname=TRUE)

</code></pre>

<hr>
<h2 id='convertWarnings'>Wrapper to convert all/specific warning messages to errors</h2><span id='topic+convertWarnings'></span>

<h3>Description</h3>

<p>Function is intended to be a message converter for functions
that are known to throw warning messages that should generally
be treated as errors instead (e.g., non-positive definite matrix
warnings, negative variance estimate warnings, etc). Specific
warning messages can be caught if specified, otherwise all
detected warning messages will be converted to errors for the evaluated
R expression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convertWarnings(expr, warning2error = NULL, muffle = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="convertWarnings_+3A_expr">expr</code></td>
<td>
<p>expression to be evaluated (e.g., <code>ret &lt;- myfun(args)</code>
should be wrapped as either <code>convertWarnings(ret &lt;- myfun(args))</code>,
<code>ret &lt;- convertWarnings(myfun(args))</code>, or more readably
<code>ret &lt;- myfun(args) |&gt; convertWarnings()</code> )</p>
</td></tr>
<tr><td><code id="convertWarnings_+3A_warning2error">warning2error</code></td>
<td>
<p>a character vector of warning messages
that should be converted to errors. Each warning message is
matched using a <code><a href="base.html#topic+grepl">grepl</a></code> expression, so partial matching
is supported (though more specific messages are less likely to throw
false positives). If <code>NULL</code> then all observed warning messages
will be treated as errors</p>
</td></tr>
<tr><td><code id="convertWarnings_+3A_muffle">muffle</code></td>
<td>
<p>logical; muffle any warning message not caught by
<code>warning2error</code> specification? Generally not recommended unless
you know <em>all</em> of the warning messages returned by a function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>General goal of this function is to <em>explicitly</em>
indicate warning that are problematic. In many function implementations
only a subset of identified warnings should be treated
as errors, rather than the more nuclear default of treating all warnings
as errors (e.g., see <code>warnings_as_errors</code> in
<code><a href="#topic+runSimulation">runSimulation</a></code>, which is primarily included for debugging
purposes early in the simulation design,
as well as <code>option(warn=2)</code> to convert all warnings to errors
globally).
</p>


<h3>Value</h3>

<p>returns the original result of <code>eval(expr)</code>
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

fun &lt;- function(warn1=FALSE, warn2=FALSE, warn3=FALSE, error=FALSE){
   if(warn1) warning('Show this warning')
   if(warn2) warning('Show a different warning')
   if(warn3) warning('Last warning message')
   if(error) stop('terminate function call')
   return('Returned from fun()')
}

# normal run (no warnings or errors)
out &lt;- fun()
out

# these are all the same
convertWarnings(out &lt;- fun())
out &lt;- convertWarnings(fun())
out &lt;- fun() |&gt; convertWarnings()

# errors treated normally
fun(error=TRUE)
fun(error=TRUE) |&gt; convertWarnings()

# all warnings converted to errors
fun(warn1=TRUE)
fun(warn1=TRUE) |&gt; convertWarnings()
fun(warn2=TRUE) |&gt; convertWarnings()

# muffle all non-caught warnings (not recommended unless you know
#  the R expression/function very intimately!)
retmuffle &lt;- fun(warn1=TRUE) |&gt;
                 convertWarnings('Warning not caught', muffle=TRUE)
retmuffle

# Specific warnings treated as errors (others stay as warnings)
# Here, treat first warning message as error but not the second or third
fun(warn1=TRUE) # warning
ret &lt;- fun(warn1=TRUE) |&gt; convertWarnings("Show this warning")  # now error

fun(warn2=TRUE, warn3=TRUE) # warnings
ret23 &lt;- fun(warn2=TRUE, warn3=TRUE) |&gt;   # continues, but prints warnings
             convertWarnings("Show this warning")
ret23

# Explicitly convert multiple warning messages, allowing others through.
#   This is generally the best use of the function's specificity
fun(warn1=TRUE, warn2=TRUE)
ret &lt;- fun(warn1=TRUE) |&gt;   # error given either message
           convertWarnings(c("Show this warning", "Show a different warning"))
ret &lt;- fun(warn2=TRUE) |&gt;
           convertWarnings(c("Show this warning", "Show a different warning"))

# last warning gets through (left as valid warning), but message still raised
ret3 &lt;- fun(warn3=TRUE) |&gt;
            convertWarnings(c("Show this warning", "Show a different warning"))
ret3


## End(Not run)

</code></pre>

<hr>
<h2 id='createDesign'>Create the simulation Design object</h2><span id='topic+createDesign'></span><span id='topic+print.Design'></span>

<h3>Description</h3>

<p>Create a partially or fully-crossed data object reflecting the unique
simulation design conditions. Each row of the returned object represents
a unique simulation condition, and each column represents the named factor
variables under study.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createDesign(
  ...,
  subset,
  fractional = NULL,
  tibble = TRUE,
  stringsAsFactors = FALSE
)

## S3 method for class 'Design'
print(x, list2char = TRUE, pillar.sigfig = 5, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createDesign_+3A_...">...</code></td>
<td>
<p>comma separated list of named input objects representing the simulation
factors to completely cross. Note that these arguments are passed to
<code><a href="base.html#topic+expand.grid">expand.grid</a></code> to perform the complete crossings</p>
</td></tr>
<tr><td><code id="createDesign_+3A_subset">subset</code></td>
<td>
<p>(optional) a logical vector indicating elements or rows to keep
to create a partially crossed simulation design</p>
</td></tr>
<tr><td><code id="createDesign_+3A_fractional">fractional</code></td>
<td>
<p>a fractional design matrix returned from the
<code>FrF2</code> package.
Note that the order of the factor names/labels are associated with the
respective <code>...</code> inputs</p>
</td></tr>
<tr><td><code id="createDesign_+3A_tibble">tibble</code></td>
<td>
<p>logical; return a <code>tibble</code> object instead of a
<code>data.frame</code>? Default is TRUE</p>
</td></tr>
<tr><td><code id="createDesign_+3A_stringsasfactors">stringsAsFactors</code></td>
<td>
<p>logical; should character variable inputs be coerced
to factors when building a <code>data.frame</code>? Default is FALSE</p>
</td></tr>
<tr><td><code id="createDesign_+3A_x">x</code></td>
<td>
<p>object returned by <code><a href="#topic+createDesign">createDesign</a></code></p>
</td></tr>
<tr><td><code id="createDesign_+3A_list2char">list2char</code></td>
<td>
<p>logical; for <code>tibble</code> object re-evaluate list elements
as character vectors for better printing of the levels? Note that this
does not change the original classes of the object, just how they are printed.
Default is TRUE</p>
</td></tr>
<tr><td><code id="createDesign_+3A_pillar.sigfig">pillar.sigfig</code></td>
<td>
<p>number of significant digits to print. Default is 5</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>tibble</code> or <code>data.frame</code> containing the simulation experiment
conditions to be evaluated in <code><a href="#topic+runSimulation">runSimulation</a></code>
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# modified example from runSimulation()

Design &lt;- createDesign(N = c(10, 20),
                       SD = c(1, 2))
Design

# remove N=10, SD=2 row from initial definition
Design &lt;- createDesign(N = c(10, 20),
                       SD = c(1, 2),
                       subset = !(N == 10 &amp; SD == 2))
Design

# example with list inputs
Design &lt;- createDesign(N = c(10, 20),
                       SD = c(1, 2),
                       combo = list(c(0,0), c(0,0,1)))
Design   # notice levels printed (not typical for tibble)
print(Design, list2char = FALSE)   # standard tibble output

Design &lt;- createDesign(N = c(10, 20),
                       SD = c(1, 2),
                       combo = list(c(0,0), c(0,0,1)),
                       combo2 = list(c(5,10,5), c(6,7)))
Design
print(Design, list2char = FALSE)   # standard tibble output

## fractional factorial example

library(FrF2)
# help(FrF2)

# 7 factors in 32 runs
fr &lt;- FrF2(32,7)
dim(fr)
fr[1:6,]

# Create working simulation design given -1/1 combinations
fDesign &lt;- createDesign(sample_size=c(100,200),
                        mean_diff=c(.25, 1, 2),
                        variance.ratio=c(1,4, 8),
                        equal_size=c(TRUE, FALSE),
                        dists=c('norm', 'skew'),
                        same_dists=c(TRUE, FALSE),
                        symmetric=c(TRUE, FALSE),
                        # remove same-normal combo
                        subset = !(symmetric &amp; dists == 'norm'),
                        fractional=fr)
fDesign


## End(Not run)
</code></pre>

<hr>
<h2 id='ECR'>Compute empirical coverage rates</h2><span id='topic+ECR'></span>

<h3>Description</h3>

<p>Computes the detection rate for determining empirical coverage rates given a set of estimated
confidence intervals. Note that using <code>1 - ECR(CIs, parameter)</code> will provide the empirical
detection rate. Also supports computing the average width of the CIs, which may be useful when comparing
the efficiency of CI estimators.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ECR(
  CIs,
  parameter,
  tails = FALSE,
  CI_width = FALSE,
  complement = FALSE,
  names = NULL,
  unname = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ECR_+3A_cis">CIs</code></td>
<td>
<p>a <code>numeric</code> vector or <code>matrix</code> of confidence interval values for a
given parameter value, where the first element/column indicates the lower confidence interval
and the second element/column the upper confidence interval. If a
vector of length 2 is passed instead then the returned value will be either a 1 or 0 to indicate
whether the parameter value was or was not within the interval, respectively. Otherwise,
the input must be a matrix with an even number of columns</p>
</td></tr>
<tr><td><code id="ECR_+3A_parameter">parameter</code></td>
<td>
<p>a numeric scalar indicating the fixed parameter value. Alternative, a <code>numeric</code>
vector object with length equal to the number of rows as <code>CIs</code> (use to compare sets of parameters
at once)</p>
</td></tr>
<tr><td><code id="ECR_+3A_tails">tails</code></td>
<td>
<p>logical; when TRUE returns a vector of length 2 to indicate the proportion of times
the parameter was lower or higher than the supplied interval, respectively. This is mainly only
useful when the coverage region is not expected to be symmetric, and therefore is generally not
required. Note that <code>1 - sum(ECR(CIs, parameter, tails=TRUE)) == ECR(CIs, parameter)</code></p>
</td></tr>
<tr><td><code id="ECR_+3A_ci_width">CI_width</code></td>
<td>
<p>logical; rather than returning the overall coverage rate, return the
average width of the CIs instead? Useful when comparing the efficiency of different CI
estimators</p>
</td></tr>
<tr><td><code id="ECR_+3A_complement">complement</code></td>
<td>
<p>logical; rather than computing the proportion of
population parameters within the CI, return the proportion outside the
advertised CI (1 - ECR = alpha). In the case where only one value is provided,
which normally would return a 0 if outside the CI or 1 if inside, the values
will be switched (useful when using, for example, CI tests of for the significance
of parameters)</p>
</td></tr>
<tr><td><code id="ECR_+3A_names">names</code></td>
<td>
<p>an optional character vector used to name the returned object. Generally useful
when more than one CI estimate is investigated at once</p>
</td></tr>
<tr><td><code id="ECR_+3A_unname">unname</code></td>
<td>
<p>logical; apply <code><a href="base.html#topic+unname">unname</a></code> to the results to remove any variable
names?</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+EDR">EDR</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
CIs &lt;- matrix(NA, 100, 2)
for(i in 1:100){
   dat &lt;- rnorm(100)
   CIs[i,] &lt;- t.test(dat)$conf.int
}

ECR(CIs, 0)
ECR(CIs, 0, tails = TRUE)
ECR(CIs, 0, complement = TRUE) # proportion outside interval

# single vector input
CI &lt;- c(-1, 1)
ECR(CI, 0)
ECR(CI, 0, complement = TRUE)
ECR(CI, 2)
ECR(CI, 2, complement = TRUE)
ECR(CI, 2, tails = TRUE)

# parameters of the same size as CI
parameters &lt;- 1:10
CIs &lt;- cbind(parameters - runif(10), parameters + runif(10))
parameters &lt;- parameters + rnorm(10)
ECR(CIs, parameters)

# average width of CIs
ECR(CIs, parameters, CI_width=TRUE)

# ECR() for multiple CI estimates in the same object
parameter &lt;- 10
CIs &lt;- data.frame(lowerCI_1=parameter - runif(10),
                  upperCI_1=parameter + runif(10),
                  lowerCI_2=parameter - 2*runif(10),
                  upperCI_2=parameter + 2*runif(10))
head(CIs)
ECR(CIs, parameter)
ECR(CIs, parameter, tails=TRUE)
ECR(CIs, parameter, CI_width=TRUE)

# often a good idea to provide names for the output
ECR(CIs, parameter, names = c('this', 'that'))
ECR(CIs, parameter, CI_width=TRUE, names = c('this', 'that'))
ECR(CIs, parameter, tails=TRUE, names = c('this', 'that'))

</code></pre>

<hr>
<h2 id='EDR'>Compute the empirical detection/rejection rate for Type I errors and Power</h2><span id='topic+EDR'></span><span id='topic+ERR'></span>

<h3>Description</h3>

<p>Computes the detection/rejection rate for determining empirical
Type I error and power rates using information from p-values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EDR(p, alpha = 0.05, unname = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EDR_+3A_p">p</code></td>
<td>
<p>a <code>numeric</code> vector or <code>matrix</code>/<code>data.frame</code> of p-values from the
desired statistical estimator. If a <code>matrix</code>, each statistic must be organized by
column, where the number of rows is equal to the number of replications</p>
</td></tr>
<tr><td><code id="EDR_+3A_alpha">alpha</code></td>
<td>
<p>the detection threshold (typical values are .10, .05, and .01).
Default is .05</p>
</td></tr>
<tr><td><code id="EDR_+3A_unname">unname</code></td>
<td>
<p>logical; apply <code><a href="base.html#topic+unname">unname</a></code> to the results to remove any variable
names?</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ECR">ECR</a></code>, <code><a href="#topic+Bradley1978">Bradley1978</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
rates &lt;- numeric(100)
for(i in 1:100){
   dat &lt;- rnorm(100)
   rates[i] &lt;- t.test(dat)$p.value
}

EDR(rates)
EDR(rates, alpha = .01)

# multiple rates at once
rates &lt;- cbind(runif(1000), runif(1000))
EDR(rates)

</code></pre>

<hr>
<h2 id='Generate'>Generate data</h2><span id='topic+Generate'></span>

<h3>Description</h3>

<p>Generate data from a single row in the <code>design</code> input (see <code><a href="#topic+runSimulation">runSimulation</a></code>). R contains
numerous approaches to generate data, some of which are contained in the base package, as well
as in <code>SimDesign</code> (e.g., <code><a href="#topic+rmgh">rmgh</a></code>, <code><a href="#topic+rValeMaurelli">rValeMaurelli</a></code>, <code><a href="#topic+rHeadrick">rHeadrick</a></code>).
However the majority can be found in external packages. See CRAN's list of possible distributions here:
<a href="https://CRAN.R-project.org/view=Distributions">https://CRAN.R-project.org/view=Distributions</a>. Note that this function technically
can be omitted if the data generation is provided in the <code><a href="#topic+Analyse">Analyse</a></code> step, though
in general this is not recommended.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Generate(condition, fixed_objects = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Generate_+3A_condition">condition</code></td>
<td>
<p>a single row from the <code>design</code> input (as a <code>data.frame</code>), indicating the
simulation conditions</p>
</td></tr>
<tr><td><code id="Generate_+3A_fixed_objects">fixed_objects</code></td>
<td>
<p>object passed down from <code><a href="#topic+runSimulation">runSimulation</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The use of <code><a href="base.html#topic+try">try</a></code> functions is generally not required in this function because <code>Generate</code>
is internally wrapped in a <code><a href="base.html#topic+try">try</a></code> call. Therefore, if a function stops early
then this will cause the function to halt internally, the message which triggered the <code><a href="base.html#topic+stop">stop</a></code>
will be recorded, and <code>Generate</code> will be called again to obtain a different dataset.
That said, it may be useful for users to throw their own <code><a href="base.html#topic+stop">stop</a></code> commands if the data
should be re-drawn for other reasons (e.g., an estimated model terminated correctly
but the maximum number of iterations were reached).
</p>


<h3>Value</h3>

<p>returns a single object containing the data to be analyzed (usually a
<code>vector</code>, <code>matrix</code>, or <code>data.frame</code>),
or <code>list</code>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+add_missing">add_missing</a></code>, <code><a href="#topic+Attach">Attach</a></code>,
<code><a href="#topic+rmgh">rmgh</a></code>, <code><a href="#topic+rValeMaurelli">rValeMaurelli</a></code>, <code><a href="#topic+rHeadrick">rHeadrick</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

generate &lt;- function(condition, fixed_objects = NULL) {
    N1 &lt;- condition$sample_sizes_group1
    N2 &lt;- condition$sample_sizes_group2
    sd &lt;- condition$standard_deviations

    group1 &lt;- rnorm(N1)
    group2 &lt;- rnorm(N2, sd=sd)
    dat &lt;- data.frame(group = c(rep('g1', N1), rep('g2', N2)),
                      DV = c(group1, group2))
    # just a silly example of a simulated parameter
    pars &lt;- list(random_number = rnorm(1))

    list(dat=dat, parameters=pars)
}

# similar to above, but using the Attach() function instead of indexing
generate &lt;- function(condition, fixed_objects = NULL) {
    Attach(condition)
    N1 &lt;- sample_sizes_group1
    N2 &lt;- sample_sizes_group2
    sd &lt;- standard_deviations

    group1 &lt;- rnorm(N1)
    group2 &lt;- rnorm(N2, sd=sd)
    dat &lt;- data.frame(group = c(rep('g1', N1), rep('g2', N2)),
                      DV = c(group1, group2))
    dat
}

generate2 &lt;- function(condition, fixed_objects = NULL) {
    mu &lt;- sample(c(-1,0,1), 1)
    dat &lt;- rnorm(100, mu)
    dat        #return simple vector (discard mu information)
}

generate3 &lt;- function(condition, fixed_objects = NULL) {
    mu &lt;- sample(c(-1,0,1), 1)
    dat &lt;- data.frame(DV = rnorm(100, mu))
    dat
}


## End(Not run)

</code></pre>

<hr>
<h2 id='GenerateIf'>Perform a test that indicates whether a given <code>Generate()</code> function should be executed</h2><span id='topic+GenerateIf'></span>

<h3>Description</h3>

<p>This function is designed to prevent specific generate function executions when the
design conditions are not met. Primarily useful when the <code>generate</code> argument to
<code><a href="#topic+runSimulation">runSimulation</a></code> was input as a named list object, however should only be
applied for some specific design condition (otherwise, the data generation moves to the
next function in the list).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GenerateIf(x, condition = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GenerateIf_+3A_x">x</code></td>
<td>
<p>logical statement to evaluate. If the statement evaluates to <code>TRUE</code>
then the remainder of the defined function will be evaluated</p>
</td></tr>
<tr><td><code id="GenerateIf_+3A_condition">condition</code></td>
<td>
<p>(optional) the current design condition. This does not need to be supplied
if the expression in <code>x</code> evaluates to valid logical (e.g., use <code>Attach(condition)</code>
prior to using <code>AnalyseIf</code>, or use <code>with(condition, AnalyseIf(someLogicalTest))</code>)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Analyse">Analyse</a></code>, <code><a href="#topic+runSimulation">runSimulation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# SimFunctions(nGenerate = 2)

Design &lt;- createDesign(N=c(10,20,30), var.equal = c(TRUE, FALSE))

Generate.G1 &lt;- function(condition, fixed_objects = NULL) {
  GenerateIf(condition$var.equal == FALSE) # only run when unequal vars
  Attach(condition)
  dat &lt;- data.frame(DV = c(rnorm(N), rnorm(N, sd=2)),
                    IV = gl(2, N, labels=c('G1', 'G2')))
  dat
}

Generate.G2 &lt;- function(condition, fixed_objects = NULL) {
  Attach(condition)
  dat &lt;- data.frame(DV = rnorm(N*2), IV = gl(2, N, labels=c('G1', 'G2')))
  dat
}

# always run this analysis for each row in Design
Analyse &lt;- function(condition, dat, fixed_objects = NULL) {
  mod &lt;- t.test(DV ~ IV, data=dat)
  mod$p.value
}

Summarise &lt;- function(condition, results, fixed_objects = NULL) {
  ret &lt;- EDR(results, alpha=.05)
  ret
}

#-------------------------------------------------------------------

# append names 'Welch' and 'independent' to associated output
res &lt;- runSimulation(design=Design, replications=1000,
                     generate=list(G1=Generate.G1, G2=Generate.G2),
                     analyse=Analyse,
                     summarise=Summarise)
res


## End(Not run)

</code></pre>

<hr>
<h2 id='IRMSE'>Compute the integrated root mean-square error</h2><span id='topic+IRMSE'></span>

<h3>Description</h3>

<p>Computes the average/cumulative deviation given two continuous functions and an optional
function representing the probability density function. Only one-dimensional integration
is supported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IRMSE(
  estimate,
  parameter,
  fn,
  density = function(theta, ...) 1,
  lower = -Inf,
  upper = Inf,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IRMSE_+3A_estimate">estimate</code></td>
<td>
<p>a vector of parameter estimates</p>
</td></tr>
<tr><td><code id="IRMSE_+3A_parameter">parameter</code></td>
<td>
<p>a vector of population parameters</p>
</td></tr>
<tr><td><code id="IRMSE_+3A_fn">fn</code></td>
<td>
<p>a continuous function where the first argument is to be integrated and the second argument is
a vector of parameters or parameter estimates. This function
represents a implied continuous function which uses the sample estimates or population parameters</p>
</td></tr>
<tr><td><code id="IRMSE_+3A_density">density</code></td>
<td>
<p>(optional) a density function used to marginalize (i.e., average), where the first
argument is to be integrated, and must be of the form <code>density(theta, ...)</code> or
<code>density(theta, param1, param2)</code>, where <code>param1</code> is a placeholder name for the
hyper-parameters associated with the probability density function. If omitted then
the cumulative different between the respective functions will be computed instead</p>
</td></tr>
<tr><td><code id="IRMSE_+3A_lower">lower</code></td>
<td>
<p>lower bound to begin numerical integration from</p>
</td></tr>
<tr><td><code id="IRMSE_+3A_upper">upper</code></td>
<td>
<p>upper bound to finish numerical integration to</p>
</td></tr>
<tr><td><code id="IRMSE_+3A_...">...</code></td>
<td>
<p>additional parameters to pass to <code>fnest</code>, <code>fnparam</code>, <code>density</code>,
and <code><a href="stats.html#topic+integrate">integrate</a></code>,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The integrated root mean-square error (IRMSE) is of the form
</p>
<p style="text-align: center;"><code class="reqn">IRMSE(\theta) = \sqrt{\int [f(\theta, \hat{\psi}) - f(\theta, \psi)]^2 g(\theta, ...)}</code>
</p>

<p>where <code class="reqn">g(\theta, ...)</code> is the density function used to marginalize the continuous sample
(<code class="reqn">f(\theta, \hat{\psi})</code>) and population (<code class="reqn">f(\theta, \psi)</code>) functions.
</p>


<h3>Value</h3>

<p>returns a single <code>numeric</code> term indicating the average/cumulative deviation
given the supplied continuous functions
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RMSE">RMSE</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# logistic regression function with one slope and intercept
fn &lt;- function(theta, param) 1 / (1 + exp(-(param[1] + param[2] * theta)))

# sample and population sets
est &lt;- c(-0.4951, 1.1253)
pop &lt;- c(-0.5, 1)

theta &lt;- seq(-10,10,length.out=1000)
plot(theta, fn(theta, pop), type = 'l', col='red', ylim = c(0,1))
lines(theta, fn(theta, est), col='blue', lty=2)

# cumulative result (i.e., standard integral)
IRMSE(est, pop, fn)

# integrated RMSE result by marginalizing over a N(0,1) distribution
den &lt;- function(theta, mean, sd) dnorm(theta, mean=mean, sd=sd)

IRMSE(est, pop, fn, den, mean=0, sd=1)

# this specification is equivalent to the above
den2 &lt;- function(theta, ...) dnorm(theta, ...)

IRMSE(est, pop, fn, den2, mean=0, sd=1)

</code></pre>

<hr>
<h2 id='MAE'>Compute the mean absolute error</h2><span id='topic+MAE'></span>

<h3>Description</h3>

<p>Computes the average absolute deviation of a sample estimate from the parameter value.
Accepts estimate and parameter values, as well as estimate values which are in deviation form.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MAE(estimate, parameter = NULL, type = "MAE", percent = FALSE, unname = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MAE_+3A_estimate">estimate</code></td>
<td>
<p>a <code>numeric</code> vector, <code>matrix</code>/<code>data.frame</code>, or <code>list</code>
of parameter estimates.
If a vector, the length is equal to the number of replications. If a
<code>matrix</code>/<code>data.frame</code> the number of rows must equal the number of replications.
<code>list</code> objects will be looped
over using the same rules after above after first translating the information into one-dimensional
vectors and re-creating the structure upon return</p>
</td></tr>
<tr><td><code id="MAE_+3A_parameter">parameter</code></td>
<td>
<p>a <code>numeric</code> scalar/vector or <code>matrix</code> indicating the fixed parameter values.
If a single value is supplied and <code>estimate</code> is a <code>matrix</code>/<code>data.frame</code>
then the value will be
recycled for each column; otherwise, each element will be associated
with each respective column in the <code>estimate</code> input.
If <code>NULL</code>, then it will be assumed that the <code>estimate</code> input is in a deviation
form (therefore <code>mean(abs(estimate))</code> will be returned)</p>
</td></tr>
<tr><td><code id="MAE_+3A_type">type</code></td>
<td>
<p>type of deviation to compute. Can be <code>'MAE'</code> (default) for the mean absolute error,
<code>'NMSE'</code> for the normalized MAE (MAE / (max(estimate) - min(estimate))), or
<code>'SMSE'</code> for the standardized MAE (MAE / sd(estimate))</p>
</td></tr>
<tr><td><code id="MAE_+3A_percent">percent</code></td>
<td>
<p>logical; change returned result to percentage by multiplying by 100?
Default is FALSE</p>
</td></tr>
<tr><td><code id="MAE_+3A_unname">unname</code></td>
<td>
<p>logical; apply <code><a href="base.html#topic+unname">unname</a></code> to the results to remove any variable
names?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a numeric vector indicating the overall mean absolute error in the estimates
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>See Also</h3>

<p>RMSE
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pop &lt;- 1
samp &lt;- rnorm(100, 1, sd = 0.5)
MAE(samp, pop)

dev &lt;- samp - pop
MAE(dev)
MAE(samp, pop, type = 'NMAE')
MAE(samp, pop, type = 'SMAE')

# matrix input
mat &lt;- cbind(M1=rnorm(100, 2, sd = 0.5), M2 = rnorm(100, 2, sd = 1))
MAE(mat, parameter = 2)

# same, but with data.frame
df &lt;- data.frame(M1=rnorm(100, 2, sd = 0.5), M2 = rnorm(100, 2, sd = 1))
MAE(df, parameter = c(2,2))

# parameters of the same size
parameters &lt;- 1:10
estimates &lt;- parameters + rnorm(10)
MAE(estimates, parameters)

</code></pre>

<hr>
<h2 id='MSRSE'>Compute the relative performance behavior of collections of standard errors</h2><span id='topic+MSRSE'></span>

<h3>Description</h3>

<p>The mean-square relative standard error (MSRSE) compares standard error
estimates to the standard deviation of the respective
parameter estimates. Values close to 1 indicate that the behavior of the standard errors
closely matched the sampling variability of the parameter estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MSRSE(SE, SD, percent = FALSE, unname = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MSRSE_+3A_se">SE</code></td>
<td>
<p>a <code>numeric</code> scalar/vector indicating the average standard errors across
the replications, or a <code>matrix</code> of collected standard error estimates themselves
to be used to compute the average standard errors. Each column/element in this input
corresponds to the column/element in <code>SD</code></p>
</td></tr>
<tr><td><code id="MSRSE_+3A_sd">SD</code></td>
<td>
<p>a <code>numeric</code> scalar/vector indicating the standard deviation across
the replications, or a <code>matrix</code> of collected parameter estimates themselves
to be used to compute the standard deviations. Each column/element in this input
corresponds to the column/element in <code>SE</code></p>
</td></tr>
<tr><td><code id="MSRSE_+3A_percent">percent</code></td>
<td>
<p>logical; change returned result to percentage by multiplying by 100?
Default is FALSE</p>
</td></tr>
<tr><td><code id="MSRSE_+3A_unname">unname</code></td>
<td>
<p>logical; apply <code><a href="base.html#topic+unname">unname</a></code> to the results to remove any variable
names?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Mean-square relative standard error (MSRSE) is expressed as
</p>
<p style="text-align: center;"><code class="reqn">MSRSE = \frac{E(SE(\psi)^2)}{SD(\psi)^2} =
  \frac{1/R * \sum_{r=1}^R SE(\psi_r)^2}{SD(\psi)^2}</code>
</p>

<p>where <code class="reqn">SE(\psi_r)</code> represents the estimate of the standard error at the <code class="reqn">r</code>th
simulation replication, and <code class="reqn">SD(\psi)</code> represents the standard deviation estimate
of the parameters across all <code class="reqn">R</code> replications. Note that <code class="reqn">SD(\psi)^2</code> is used,
which corresponds to the variance of <code class="reqn">\psi</code>.
</p>


<h3>Value</h3>

<p>returns a <code>vector</code> of ratios indicating the relative performance
of the standard error estimates to the observed parameter standard deviation.
Values less than 1 indicate that the standard errors were larger than the standard
deviation of the parameters (hence, the SEs are interpreted as more conservative),
while values greater than 1 were smaller than the standard deviation of the
parameters (i.e., more liberal SEs)
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
Generate &lt;- function(condition, fixed_objects = NULL) {
   X &lt;- rep(0:1, each = 50)
   y &lt;- 10 + 5 * X + rnorm(100, 0, .2)
   data.frame(y, X)
}

Analyse &lt;- function(condition, dat, fixed_objects = NULL) {
   mod &lt;- lm(y ~ X, dat)
   so &lt;- summary(mod)
   ret &lt;- c(SE = so$coefficients[,"Std. Error"],
            est = so$coefficients[,"Estimate"])
   ret
}

Summarise &lt;- function(condition, results, fixed_objects = NULL) {
   MSRSE(SE = results[,1:2], SD = results[,3:4])
}

results &lt;- runSimulation(replications=500, generate=Generate,
                         analyse=Analyse, summarise=Summarise)
results


</code></pre>

<hr>
<h2 id='nc'>Auto-named Concatenation of Vector or List</h2><span id='topic+nc'></span>

<h3>Description</h3>

<p>This is a wrapper to the function <code><a href="base.html#topic+c">c</a></code>, however names the respective elements
according to their input object name. For this reason, nesting <code>nc()</code> calls
is not recommended (joining independent <code>nc()</code> calls via <code>c()</code>
is however reasonable).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nc(..., use.names = FALSE, error.on.duplicate = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nc_+3A_...">...</code></td>
<td>
<p>objects to be concatenated</p>
</td></tr>
<tr><td><code id="nc_+3A_use.names">use.names</code></td>
<td>
<p>logical indicating if <code>names</code> should be preserved (unlike <code><a href="base.html#topic+c">c</a></code>,
default is <code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="nc_+3A_error.on.duplicate">error.on.duplicate</code></td>
<td>
<p>logical; if the same object name appears in the returning object
should an error be thrown? Default is <code>TRUE</code></p>
</td></tr>
</table>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
A &lt;- 1
B &lt;- 2
C &lt;- 3

names(C) &lt;- 'LetterC'

# compare the following
c(A, B, C) # unnamed

nc(A, B, C) # named
nc(this=A, B, C) # respects override named (same as c() )
nc(this=A, B, C, use.names = TRUE) # preserve original name

## Not run: 
# throws errors if names not unique
nc(this=A, this=B, C)
nc(LetterC=A, B, C, use.names=TRUE)

## End(Not run)

# poor input choice names
nc(t.test(c(1:2))$p.value, t.test(c(3:4))$p.value)

# better to explicitly provide name
nc(T1 = t.test(c(1:2))$p.value,
   T2 = t.test(c(3:4))$p.value)

# vector of unnamed inputs
A &lt;- c(5,4,3,2,1)
B &lt;- c(100, 200)

nc(A, B, C) # A's and B's numbered uniquely
c(A, B, C)  # compare
nc(beta=A, B, C) # replacement of object name

# retain names attributes (but append object name, when appropriate)
names(A) &lt;- letters[1:5]
nc(A, B, C)
nc(beta=A, B, C)
nc(A, B, C, use.names=TRUE)

# mix and match if some named elements work while others do not
c( nc(A, B, use.names=TRUE), nc(C))

## Not run: 
# error, 'b' appears twice
names(B) &lt;- c('b', 'b2')
nc(A, B, C, use.names=TRUE)

## End(Not run)

# List input
A &lt;- list(1)
B &lt;- list(2:3)
C &lt;- list('C')

names(C) &lt;- 'LetterC'

# compare the following
c(A, B, C) # unnamed

nc(A, B, C) # named
nc(this=A, B, C) # respects override named (same as c() and list() )
nc(this=A, B, C, use.names = TRUE) # preserve original name


</code></pre>

<hr>
<h2 id='PBA'>Probabilistic Bisection Algorithm</h2><span id='topic+PBA'></span><span id='topic+print.PBA'></span><span id='topic+plot.PBA'></span>

<h3>Description</h3>

<p>The function <code>PBA</code> searches a specified <code>interval</code> for a root
(i.e., zero) of the function <code>f(x)</code> with respect to its first argument.
However, this function differs from deterministic cousins such as
<code><a href="stats.html#topic+uniroot">uniroot</a></code> in that <code>f</code> may contain stochastic error
components, and instead provides a Bayesian interval where the root
is likely to lie. Note that it is assumed that <code>E[f(x)]</code> is non-decreasing
in <code>x</code> and that the root is between the search interval (evaluated
approximately when <code>check.interval=TRUE</code>).
See Waeber, Frazier, and Henderson (2013) for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PBA(
  f,
  interval,
  ...,
  p = 0.6,
  integer = FALSE,
  tol = if (integer) 0.01 else 1e-04,
  maxiter = 300L,
  miniter = 100L,
  wait.time = NULL,
  f.prior = NULL,
  resolution = 10000L,
  check.interval = TRUE,
  check.interval.only = FALSE,
  verbose = TRUE
)

## S3 method for class 'PBA'
print(x, ...)

## S3 method for class 'PBA'
plot(x, type = "posterior", main = "Probabilistic Bisection Posterior", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PBA_+3A_f">f</code></td>
<td>
<p>noisy function for which the root is sought</p>
</td></tr>
<tr><td><code id="PBA_+3A_interval">interval</code></td>
<td>
<p>a vector containing the end-points of the interval
to be searched for the root</p>
</td></tr>
<tr><td><code id="PBA_+3A_...">...</code></td>
<td>
<p>additional named arguments to be passed to <code>f</code></p>
</td></tr>
<tr><td><code id="PBA_+3A_p">p</code></td>
<td>
<p>assumed constant for probability of correct responses (must be &gt; 0.5)</p>
</td></tr>
<tr><td><code id="PBA_+3A_integer">integer</code></td>
<td>
<p>logical; should the values of the root be considered integer
or numeric? The former uses a discreet grid to track the updates, while the
latter currently creates a grid with <code>resolution</code> points</p>
</td></tr>
<tr><td><code id="PBA_+3A_tol">tol</code></td>
<td>
<p>tolerance criteria for convergence based on average of the
<code>f(x)</code> evaluations</p>
</td></tr>
<tr><td><code id="PBA_+3A_maxiter">maxiter</code></td>
<td>
<p>the maximum number of iterations (default 300)</p>
</td></tr>
<tr><td><code id="PBA_+3A_miniter">miniter</code></td>
<td>
<p>minimum number of iterations (default 100)</p>
</td></tr>
<tr><td><code id="PBA_+3A_wait.time">wait.time</code></td>
<td>
<p>(optional) instead of terminating after specific estimate criteria
are satisfied (e.g., <code>tol</code>), terminate after a specific
wait time. Input must be a numeric vector indicating the number of minutes to
wait. Not that users should increase the number of <code>maxiter</code> as well
so that termination can occur if either the maximum iterations are satisfied
or the specified wait time has elapsed (whichever occurs first)</p>
</td></tr>
<tr><td><code id="PBA_+3A_f.prior">f.prior</code></td>
<td>
<p>density function indicating the likely location of the prior
(e.g., if root is within [0,1] then <code><a href="stats.html#topic+dunif">dunif</a></code> works, otherwise custom
functions will be required)</p>
</td></tr>
<tr><td><code id="PBA_+3A_resolution">resolution</code></td>
<td>
<p>constant indicating the
number of equally spaced grid points to track when <code>integer = FALSE</code>.</p>
</td></tr>
<tr><td><code id="PBA_+3A_check.interval">check.interval</code></td>
<td>
<p>logical; should an initial check be made to determine
whether <code>f(interval[1L])</code> and <code>f(interval[2L])</code> have opposite
signs? Default is TRUE</p>
</td></tr>
<tr><td><code id="PBA_+3A_check.interval.only">check.interval.only</code></td>
<td>
<p>logical; return only TRUE or FALSE to test
whether there is a likely root given <code>interval</code>? Setting this to TRUE
can be useful when you are unsure about the root location interval and
may want to use a higher <code>replication</code> input from <code><a href="#topic+SimSolve">SimSolve</a></code></p>
</td></tr>
<tr><td><code id="PBA_+3A_verbose">verbose</code></td>
<td>
<p>logical; should the iterations and estimate be printed to the
console?</p>
</td></tr>
<tr><td><code id="PBA_+3A_x">x</code></td>
<td>
<p>an object of class <code>PBA</code></p>
</td></tr>
<tr><td><code id="PBA_+3A_type">type</code></td>
<td>
<p>type of plot to draw for PBA object. Can be either 'posterior' or
'history' to plot the PBA posterior distribution or the mediation iteration
history</p>
</td></tr>
<tr><td><code id="PBA_+3A_main">main</code></td>
<td>
<p>plot title</p>
</td></tr>
</table>


<h3>References</h3>

<p>Horstein, M. (1963). Sequential transmission using noiseless feedback.
IEEE Trans. Inform. Theory, 9(3):136-143.
</p>
<p>Waeber, R., Frazier, P. I. &amp; Henderson, S. G. (2013). Bisection Search
with Noisy Responses. SIAM Journal on Control and Optimization,
Society for Industrial &amp; Applied Mathematics (SIAM), 51, 2261-2279.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+uniroot">uniroot</a></code>, <code><a href="#topic+RobbinsMonro">RobbinsMonro</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# find x that solves f(x) - b = 0 for the following
f.root &lt;- function(x, b = .6) 1 / (1 + exp(-x)) - b
f.root(.3)

xs &lt;- seq(-3,3, length.out=1000)
plot(xs, f.root(xs), type = 'l', ylab = "f(x)", xlab='x', las=1)
abline(h=0, col='red')

retuni &lt;- uniroot(f.root, c(0,1))
retuni
abline(v=retuni$root, col='blue', lty=2)

# PBA without noisy root
retpba &lt;- PBA(f.root, c(0,1))
retpba
retpba$root
plot(retpba)
plot(retpba, type = 'history')

# Same problem, however root function is now noisy. Hence, need to solve
#  fhat(x) - b + e = 0, where E(e) = 0
f.root_noisy &lt;- function(x) 1 / (1 + exp(-x)) - .6 + rnorm(1, sd=.02)
sapply(rep(.3, 10), f.root_noisy)

# uniroot "converges" unreliably
set.seed(123)
uniroot(f.root_noisy, c(0,1))$root
uniroot(f.root_noisy, c(0,1))$root
uniroot(f.root_noisy, c(0,1))$root

# probabilistic bisection provides better convergence
retpba.noise &lt;- PBA(f.root_noisy, c(0,1))
retpba.noise
plot(retpba.noise)
plot(retpba.noise, type = 'history')

## Not run: 
# ignore termination criteria and instead run for 1/2 minutes or 30000 iterations
retpba.noise_30sec &lt;- PBA(f.root_noisy, c(0,1), wait.time = 1/2, maxiter=30000)
retpba.noise_30sec


## End(Not run)

</code></pre>

<hr>
<h2 id='quiet'>Suppress function messages and Concatenate and Print (cat)</h2><span id='topic+quiet'></span>

<h3>Description</h3>

<p>This function is used to suppress information printed from external functions
that make internal use of <code>link{message}</code> and <code><a href="base.html#topic+cat">cat</a></code>, which
provide information in interactive R sessions. For simulations, the session
is not interactive, and therefore this type of output should be suppressed.
For similar behaviour for suppressing warning messages see
<code><a href="base.html#topic+suppressWarnings">suppressWarnings</a></code>, though use this function carefully as some
warnings can be meaningful and unexpected.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quiet(..., messages = FALSE, cat = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quiet_+3A_...">...</code></td>
<td>
<p>the functional expression to be evaluated</p>
</td></tr>
<tr><td><code id="quiet_+3A_messages">messages</code></td>
<td>
<p>logical; suppress all messages?</p>
</td></tr>
<tr><td><code id="quiet_+3A_cat">cat</code></td>
<td>
<p>logical; suppress all concatenate and print calls from <code><a href="base.html#topic+cat">cat</a></code>?</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>myfun &lt;- function(x){
   message('This function is rather chatty')
   cat("It even prints in different output forms!\n")
   message('And even at different....')
   cat("...times!\n")
   x
}

out &lt;- myfun(1)
out

# tell the function to shhhh
out &lt;- quiet(myfun(1))
out

</code></pre>

<hr>
<h2 id='RAB'>Compute the relative absolute bias of multiple estimators</h2><span id='topic+RAB'></span>

<h3>Description</h3>

<p>Computes the relative absolute bias given the bias estimates for multiple estimators.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RAB(x, percent = FALSE, unname = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RAB_+3A_x">x</code></td>
<td>
<p>a <code>numeric</code> vector of bias estimates (see <code><a href="#topic+bias">bias</a></code>),
where the first element will be used as the reference</p>
</td></tr>
<tr><td><code id="RAB_+3A_percent">percent</code></td>
<td>
<p>logical; change returned result to percentage by multiplying by 100?
Default is FALSE</p>
</td></tr>
<tr><td><code id="RAB_+3A_unname">unname</code></td>
<td>
<p>logical; apply <code><a href="base.html#topic+unname">unname</a></code> to the results to remove any variable
names?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a <code>vector</code> of absolute bias ratios indicating the relative bias
effects compared to the first estimator. Values less than 1 indicate better bias estimates
than the first estimator, while values greater than 1 indicate worse bias than the first estimator
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pop &lt;- 1
samp1 &lt;- rnorm(5000, 1)
bias1 &lt;- bias(samp1, pop)
samp2 &lt;- rnorm(5000, 1)
bias2 &lt;- bias(samp2, pop)

RAB(c(bias1, bias2))
RAB(c(bias1, bias2), percent = TRUE) # as a percentage

</code></pre>

<hr>
<h2 id='rbind.SimDesign'>Combine two separate SimDesign objects by row</h2><span id='topic+rbind.SimDesign'></span>

<h3>Description</h3>

<p>This function combines two Monte Carlo simulations executed by
<code>SimDesign</code>'s <code><a href="#topic+runSimulation">runSimulation</a></code> function which, for all
intents and purposes, could have been executed in a single run.
This situation arises when a simulation has been completed, however
the <code>Design</code> object was later modified to include more levels in the
defined simulation factors. Rather than re-executing the previously completed
simulation combinations, only the new combinations need to be evaluated
into a different object and then <code>rbind</code> together to create the complete
object combinations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SimDesign'
rbind(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rbind.SimDesign_+3A_...">...</code></td>
<td>
<p>two or more <code>SimDesign</code> objects that should be
combined by rows</p>
</td></tr>
</table>


<h3>Value</h3>

<p>same object that is returned by <code><a href="#topic+runSimulation">runSimulation</a></code>
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# modified example from runSimulation()

Design &lt;- createDesign(N = c(10, 20),
                       SD = c(1, 2))

Generate &lt;- function(condition, fixed_objects = NULL) {
    dat &lt;- with(condition, rnorm(N, 10, sd=SD))
    dat
}

Analyse &lt;- function(condition, dat, fixed_objects = NULL) {
    ret &lt;- mean(dat) # mean of the sample data vector
    ret
}

Summarise &lt;- function(condition, results, fixed_objects = NULL) {
    ret &lt;- c(mu=mean(results), SE=sd(results)) # mean and SD summary of the sample means
    ret
}

Final1 &lt;- runSimulation(design=Design, replications=1000,
                       generate=Generate, analyse=Analyse, summarise=Summarise)
Final1

###
# later decide that N = 30 should have also been investigated. Rather than
# running the following object ....
newDesign &lt;- createDesign(N = c(10, 20, 30),
                          SD = c(1, 2))

# ... only the new subset levels are executed to save time
subDesign &lt;- subset(newDesign, N == 30)
subDesign

Final2 &lt;- runSimulation(design=subDesign, replications=1000,
                       generate=Generate, analyse=Analyse, summarise=Summarise)
Final2

# glue results together by row into one object as though the complete 'Design'
# object were run all at once
Final &lt;- rbind(Final1, Final2)
Final

summary(Final)


## End(Not run)
</code></pre>

<hr>
<h2 id='RD'>Compute the relative difference</h2><span id='topic+RD'></span>

<h3>Description</h3>

<p>Computes the relative difference statistic of the form <code>(est - pop)/ pop</code>, which
is equivalent to the form <code>est/pop - 1</code>. If matrices are supplied then
an equivalent matrix variant will be used of the form
<code>(est - pop) * solve(pop)</code>. Values closer to 0 indicate better
relative parameter recovery. Note that for single variable inputs this is equivalent to
<code>bias(..., type = 'relative')</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RD(est, pop, as.vector = TRUE, unname = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RD_+3A_est">est</code></td>
<td>
<p>a <code>numeric</code> vector, <code>matrix/data.frame</code>, or <code>list</code> containing
the parameter estimates</p>
</td></tr>
<tr><td><code id="RD_+3A_pop">pop</code></td>
<td>
<p>a <code>numeric</code> vector or matrix containing the true parameter values. Must be
of comparable dimension to <code>est</code></p>
</td></tr>
<tr><td><code id="RD_+3A_as.vector">as.vector</code></td>
<td>
<p>logical; always wrap the result in a <code><a href="base.html#topic+as.vector">as.vector</a></code> function
before returning?</p>
</td></tr>
<tr><td><code id="RD_+3A_unname">unname</code></td>
<td>
<p>logical; apply <code><a href="base.html#topic+unname">unname</a></code> to the results to remove any variable
names?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a <code>vector</code> or <code>matrix</code> depending on the inputs and whether
<code>as.vector</code> was used
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# vector
pop &lt;- seq(1, 100, length.out=9)
est1 &lt;- pop + rnorm(9, 0, .2)
(rds &lt;- RD(est1, pop))
summary(rds)

# matrix
pop &lt;- matrix(c(1:8, 10), 3, 3)
est2 &lt;- pop + rnorm(9, 0, .2)
RD(est2, pop, as.vector = FALSE)
(rds &lt;- RD(est2, pop))
summary(rds)


</code></pre>

<hr>
<h2 id='RE'>Compute the relative efficiency of multiple estimators</h2><span id='topic+RE'></span>

<h3>Description</h3>

<p>Computes the relative efficiency given the RMSE (default) or MSE values for multiple estimators.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RE(x, MSE = FALSE, percent = FALSE, unname = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RE_+3A_x">x</code></td>
<td>
<p>a <code>numeric</code> vector of root mean square error values (see <code><a href="#topic+RMSE">RMSE</a></code>),
where the first element will be used as the reference. Otherwise, the object could contain
MSE values if the flag <code>MSE = TRUE</code> is also included</p>
</td></tr>
<tr><td><code id="RE_+3A_mse">MSE</code></td>
<td>
<p>logical; are the input value mean squared errors instead of root mean square errors?</p>
</td></tr>
<tr><td><code id="RE_+3A_percent">percent</code></td>
<td>
<p>logical; change returned result to percentage by multiplying by 100?
Default is FALSE</p>
</td></tr>
<tr><td><code id="RE_+3A_unname">unname</code></td>
<td>
<p>logical; apply <code><a href="base.html#topic+unname">unname</a></code> to the results to remove any variable
names?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a <code>vector</code> of variance ratios indicating the relative efficiency compared
to the first estimator. Values less than 1 indicate better efficiency than the first
estimator, while values greater than 1 indicate worse efficiency than the first estimator
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pop &lt;- 1
samp1 &lt;- rnorm(100, 1, sd = 0.5)
RMSE1 &lt;- RMSE(samp1, pop)
samp2 &lt;- rnorm(100, 1, sd = 1)
RMSE2 &lt;- RMSE(samp2, pop)

RE(c(RMSE1, RMSE2))
RE(c(RMSE1, RMSE2), percent = TRUE) # as a percentage

# using MSE instead
mse &lt;- c(RMSE1, RMSE2)^2
RE(mse, MSE = TRUE)

</code></pre>

<hr>
<h2 id='rejectionSampling'>Rejection sampling (i.e., accept-reject method)</h2><span id='topic+rejectionSampling'></span>

<h3>Description</h3>

<p>This function supports the rejection sampling (i.e., accept-reject) approach
to drawing values from seemingly difficult (probability) density functions
by sampling values from more manageable proxy distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rejectionSampling(
  n,
  df,
  dg,
  rg,
  M,
  method = "optimize",
  interval = NULL,
  logfuns = FALSE,
  maxM = 1e+05,
  parstart = rg(1L),
  ESRS_Mstart = 1.0001
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rejectionSampling_+3A_n">n</code></td>
<td>
<p>number of samples to draw</p>
</td></tr>
<tr><td><code id="rejectionSampling_+3A_df">df</code></td>
<td>
<p>the desired (potentially un-normed) density function to draw
independent samples from. Must be in the form of a <code>function</code> with a
single input corresponding to the values sampled from <code>rg</code>. Function
is assumed to be vectorized (if not, see <code><a href="base.html#topic+Vectorize">Vectorize</a></code>)</p>
</td></tr>
<tr><td><code id="rejectionSampling_+3A_dg">dg</code></td>
<td>
<p>the proxy (potentially un-normed) density function to
draw samples from in lieu of drawing samples from <code>df</code>.
The support for this density function should be the same as <code>df</code>
(i.e., when <code>df(x) &gt; 0</code> then <code>dg(x) &gt; 0</code>).
Must be in the form of a <code>function</code> with a single input
corresponding to the values sampled from <code>rg</code>. Function is
assumed to be vectorized (if not, see <code><a href="base.html#topic+Vectorize">Vectorize</a></code>)</p>
</td></tr>
<tr><td><code id="rejectionSampling_+3A_rg">rg</code></td>
<td>
<p>the proxy random number generation function, associated with
<code>dg</code>, used to draw proposal samples from.
Must be in the form of a <code>function</code> with a single input corresponding
to the number of values to draw, while the output can either be a vector
or a matrix (if a matrix, each independent observation must be stored in
a unique row). Function is assumed to be vectorized (if not, see
<code><a href="base.html#topic+Vectorize">Vectorize</a></code>)</p>
</td></tr>
<tr><td><code id="rejectionSampling_+3A_m">M</code></td>
<td>
<p>the upper-bound of the ratio of probability density functions to help
minimize the number of discarded draws and define the corresponding
rescaled proposal envelope. When missing, <code>M</code> is computed
internally by finding a reasonable maximum of <code>log(df(x)) - log(dg(x))</code>,
and this value is returned to the console.
When both <code>df</code> and <code>dg</code> are true probability density functions
(i.e., integrate to 1) the acceptance probability is equal to 1/M</p>
</td></tr>
<tr><td><code id="rejectionSampling_+3A_method">method</code></td>
<td>
<p>when M is missing, the optimization of M is done either by
finding the mode of the log-density values (<code>"optimize"</code>) or by
using the &quot;Empirical Supremum Rejection Sampling&quot; method (<code>"ESRS"</code>)</p>
</td></tr>
<tr><td><code id="rejectionSampling_+3A_interval">interval</code></td>
<td>
<p>when M is missing, for univariate density function draws,
the interval to search within via <code><a href="stats.html#topic+optimize">optimize</a></code>.
If not specified, a sample of 5000 values from the <code>rg</code>
function definition will be
collected, and the min/max will be obtained via this random sample</p>
</td></tr>
<tr><td><code id="rejectionSampling_+3A_logfuns">logfuns</code></td>
<td>
<p>logical; have the <code>df</code> and <code>dg</code> function been
written so as to return log-densities instead of the original densities?
The FALSE default assumes the original densities are returned
(use TRUE when higher accuracy is required when generating each density
definition)</p>
</td></tr>
<tr><td><code id="rejectionSampling_+3A_maxm">maxM</code></td>
<td>
<p>logical; if when optimizing M the value is greater than this
cut-off then stop; ampler would likelihood be too efficient,
or optimization is failing</p>
</td></tr>
<tr><td><code id="rejectionSampling_+3A_parstart">parstart</code></td>
<td>
<p>starting value vector for optimization of M in
multidimensional distributions</p>
</td></tr>
<tr><td><code id="rejectionSampling_+3A_esrs_mstart">ESRS_Mstart</code></td>
<td>
<p>starting M value for the ESRS algorithm</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The accept-reject algorithm is a flexible approach to obtaining i.i.d.'s from
a difficult to sample from (probability) density function  where either the
transformation method fails or inverse transform method is
difficult to manage. The algorithm does so by sampling from
a more &quot;well-behaved&quot; proxy distribution (with identical support, up to some
proportionality constant <code>M</code> that reshapes the proposal density
to envelope the target density), and accepts the
draws if they are likely within the target density. Hence, the closer the
shape of <code>dg(x)</code> is to the desired <code>df(x)</code>, the more likely the draws
are to be accepted; otherwise, many iterations of the accept-reject algorithm
may be required, which decreases the computational efficiency.
</p>


<h3>Value</h3>

<p>returns a vector or matrix of draws (corresponding to the
output class from <code>rg</code>) from the desired <code>df</code>
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Caffo, B. S., Booth, J. G., and Davison, A. C. (2002). Empirical supremum
rejection sampling. <code>Biometrika</code>, 89, 745&ndash;754.
</p>
<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable
Monte Carlo Simulations with the SimDesign Package.
<code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics
with Monte Carlo simulation. <code>Journal of Statistics Education, 24</code>(3),
136-156. <a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Generate X ~ beta(a,b), where a and b are a = 2.7 and b = 6.3,
# and the support is Y ~ Unif(0,1)
dfn &lt;- function(x) dbeta(x, shape1 = 2.7, shape2 = 6.3)
dgn &lt;- function(x) dunif(x, min = 0, max = 1)
rgn &lt;- function(n) runif(n, min = 0, max = 1)

# when df and dg both integrate to 1, acceptance probability = 1/M
M &lt;- rejectionSampling(df=dfn, dg=dgn, rg=rgn)
M
dat &lt;- rejectionSampling(10000, df=dfn, dg=dgn, rg=rgn, M=M)
hist(dat, 100)
hist(rbeta(10000, 2.7, 6.3), 100) # compare

# obtain empirical estimate of M via ESRS method
M &lt;- rejectionSampling(1000, df=dfn, dg=dgn, rg=rgn, method='ESRS')
M

# generate using better support function (here, Y ~ beta(2,6)),
#   and use log setup in initial calls (more numerically accurate)
dfn &lt;- function(x) dbeta(x, shape1 = 2.7, shape2 = 6.3, log = TRUE)
dgn &lt;- function(x) dbeta(x, shape1 = 2, shape2 = 6, log = TRUE)
rgn &lt;- function(n) rbeta(n, shape1 = 2, shape2 = 6)
M &lt;- rejectionSampling(df=dfn, dg=dgn, rg=rgn, logfuns=TRUE) # better M
M

## Alternative estimation of M
## M &lt;- rejectionSampling(10000, df=dfn, dg=dgn, rg=rgn, logfuns=TRUE,
##                        method='ESRS')
dat &lt;- rejectionSampling(10000, df=dfn, dg=dgn, rg=rgn, M=M, logfuns=TRUE)
hist(dat, 100)

#------------------------------------------------------
# sample from wonky (and non-normalized) density function, like below
dfn &lt;- function(x){
    ret &lt;- numeric(length(x))
    ret[x &lt;= .5] &lt;- dnorm(x[x &lt;= .5])
    ret[x &gt; .5] &lt;-  dnorm(x[x &gt; .5]) + dchisq(x[x &gt; .5], df = 2)
    ret
}
y &lt;- seq(-5,5, length.out = 1000)
plot(y, dfn(y), type = 'l', main = "Function to sample from")

# choose dg/rg functions that have support within the range [-inf, inf]
rgn &lt;- function(n) rnorm(n, sd=4)
dgn &lt;- function(x) dnorm(x, sd=4)

## example M height from above graphic
##  (M selected using ESRS to help stochastically avoid local mins)
M &lt;- rejectionSampling(10000, df=dfn, dg=dgn, rg=rgn, method='ESRS')
M
lines(y, dgn(y)*M, lty = 2)
dat &lt;- rejectionSampling(10000, df=dfn, dg=dgn, rg=rgn, M=M)
hist(dat, 100, prob=TRUE)

# true density (normalized)
C &lt;- integrate(dfn, -Inf, Inf)$value
ndfn &lt;- function(x) dfn(x) / C
curve(ndfn, col='red', lwd=2, add=TRUE)


#-----------------------------------------------------
# multivariate distribution
dfn &lt;- function(x) sum(log(c(dnorm(x[1]) + dchisq(x[1], df = 5),
                   dnorm(x[2], -1, 2))))
rgn &lt;- function(n) c(rnorm(n, sd=3), rnorm(n, sd=3))
dgn &lt;- function(x) sum(log(c(dnorm(x[1], sd=3), dnorm(x[1], sd=3))))

# M &lt;- rejectionSampling(df=dfn, dg=dgn, rg=rgn, logfuns=TRUE)
dat &lt;- rejectionSampling(5000, df=dfn, dg=dgn, rg=rgn, M=4.6, logfuns=TRUE)
hist(dat[,1], 30)
hist(dat[,2], 30)
plot(dat)



## End(Not run)

</code></pre>

<hr>
<h2 id='reSummarise'>Run a summarise step for results that have been saved to the hard drive</h2><span id='topic+reSummarise'></span>

<h3>Description</h3>

<p>When <code>runSimulation()</code> uses the option <code>save_results = TRUE</code>
the R replication results from the Generate-Analyse functions are
stored to the hard drive. As such, additional summarise components
may be required at a later time, whereby the respective <code>.rds</code> files
must be read back into R to be summarised. This function performs
the reading of these files, application of a provided summarise function,
and final collection of the respective results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reSummarise(
  summarise,
  dir = NULL,
  files = NULL,
  results = NULL,
  Design = NULL,
  fixed_objects = NULL,
  boot_method = "none",
  boot_draws = 1000L,
  CI = 0.95,
  prefix = "results-row"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reSummarise_+3A_summarise">summarise</code></td>
<td>
<p>a summarise function to apply to the read-in files.
See <code><a href="#topic+runSimulation">runSimulation</a></code> for details</p>
</td></tr>
<tr><td><code id="reSummarise_+3A_dir">dir</code></td>
<td>
<p>directory pointing to the .rds files to be
read-in that were saved from <code>runSimulation(..., save_results=TRUE)</code>.
If <code>NULL</code>, it is assumed the current working directory contains
the .rds files</p>
</td></tr>
<tr><td><code id="reSummarise_+3A_files">files</code></td>
<td>
<p>(optional) names of files to read-in. If <code>NULL</code> all files
located within <code>dir</code> will be used</p>
</td></tr>
<tr><td><code id="reSummarise_+3A_results">results</code></td>
<td>
<p>(optional) the results of <code><a href="#topic+runSimulation">runSimulation</a></code> when no
<code>summarise</code> function was provided. Can be either a <code>tibble</code> or
<code>matrix</code> (indicating that exactly one design condition was evaluated),
or a <code>list</code> of <code>matrix</code>/<code>tibble</code>
objects indicating that multiple conditions were performed with no summarise evaluation.
</p>
<p>Alternatively, if <code>store_results = TRUE</code> in the <code>runSimulation()</code> execution then
the final SimDesign object may be passed, where the generate-analyse information will be
extracted from the object instead</p>
</td></tr>
<tr><td><code id="reSummarise_+3A_design">Design</code></td>
<td>
<p>(optional) if <code>results</code> input used, and design condition information
important in the summarise step, then the original <code>design</code> object from
<code><a href="#topic+runSimulation">runSimulation</a></code> should be included</p>
</td></tr>
<tr><td><code id="reSummarise_+3A_fixed_objects">fixed_objects</code></td>
<td>
<p>(optional) see <code><a href="#topic+runSimulation">runSimulation</a></code> for details</p>
</td></tr>
<tr><td><code id="reSummarise_+3A_boot_method">boot_method</code></td>
<td>
<p>method for performing non-parametric bootstrap confidence intervals
for the respective meta-statistics computed by the <code>Summarise</code> function.
See <code><a href="#topic+runSimulation">runSimulation</a></code> for details</p>
</td></tr>
<tr><td><code id="reSummarise_+3A_boot_draws">boot_draws</code></td>
<td>
<p>number of non-parametric bootstrap draws to sample for the <code>summarise</code>
function after the generate-analyse replications are collected. Default is 1000</p>
</td></tr>
<tr><td><code id="reSummarise_+3A_ci">CI</code></td>
<td>
<p>bootstrap confidence interval level (default is 95%)</p>
</td></tr>
<tr><td><code id="reSummarise_+3A_prefix">prefix</code></td>
<td>
<p>character indicating prefix used for stored files</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
Design &lt;- createDesign(N = c(10, 20, 30))

Generate &lt;- function(condition, fixed_objects = NULL) {
    dat &lt;- with(condition, rnorm(N, 10, 5)) # distributed N(10, 5)
    dat
}

Analyse &lt;- function(condition, dat, fixed_objects = NULL) {
    ret &lt;- c(mean=mean(dat), median=median(dat)) # mean/median of sample data
    ret
}

Summarise &lt;- function(condition, results, fixed_objects = NULL){
    colMeans(results)
}

## Not run: 
# run the simulation
runSimulation(design=Design, replications=50,
              generate=Generate, analyse=Analyse,
              summarise=Summarise, save_results=TRUE,
              save_details = list(save_results_dirname='simresults'))


res &lt;- reSummarise(Summarise, dir = 'simresults/')
res

Summarise2 &lt;- function(condition, results, fixed_objects = NULL){
    ret &lt;- c(mean_ests=colMeans(results), SE=colSDs(results))
    ret
}

res2 &lt;- reSummarise(Summarise2, dir = 'simresults/')
res2

SimClean('simresults/')


## End(Not run)

###
# Similar, but with results stored within the final object

res &lt;- runSimulation(design=Design, replications=50, store_results = TRUE,
                     generate=Generate, analyse=Analyse, summarise=Summarise)
res

# same summarise but with bootstrapping
res2 &lt;- reSummarise(Summarise, results = res, boot_method = 'basic')
res2

</code></pre>

<hr>
<h2 id='rHeadrick'>Generate non-normal data with Headrick's (2002) method</h2><span id='topic+rHeadrick'></span>

<h3>Description</h3>

<p>Generate multivariate non-normal distributions using the fifth-order polynomial
method described by Headrick (2002).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rHeadrick(
  n,
  mean = rep(0, nrow(sigma)),
  sigma = diag(length(mean)),
  skew = rep(0, nrow(sigma)),
  kurt = rep(0, nrow(sigma)),
  gam3 = NaN,
  gam4 = NaN,
  return_coefs = FALSE,
  coefs = NULL,
  control = list(trace = FALSE, max.ntry = 15, obj.tol = 1e-10, n.valid.sol = 1)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rHeadrick_+3A_n">n</code></td>
<td>
<p>number of samples to draw</p>
</td></tr>
<tr><td><code id="rHeadrick_+3A_mean">mean</code></td>
<td>
<p>a vector of k elements for the mean of the variables</p>
</td></tr>
<tr><td><code id="rHeadrick_+3A_sigma">sigma</code></td>
<td>
<p>desired k x k covariance matrix between bivariate non-normal variables</p>
</td></tr>
<tr><td><code id="rHeadrick_+3A_skew">skew</code></td>
<td>
<p>a vector of k elements for the skewness of the variables</p>
</td></tr>
<tr><td><code id="rHeadrick_+3A_kurt">kurt</code></td>
<td>
<p>a vector of k elements for the kurtosis of the variables</p>
</td></tr>
<tr><td><code id="rHeadrick_+3A_gam3">gam3</code></td>
<td>
<p>(optional) explicitly supply the gamma 3 value? Default computes this internally</p>
</td></tr>
<tr><td><code id="rHeadrick_+3A_gam4">gam4</code></td>
<td>
<p>(optional) explicitly supply the gamma 4 value? Default computes this internally</p>
</td></tr>
<tr><td><code id="rHeadrick_+3A_return_coefs">return_coefs</code></td>
<td>
<p>logical; return the estimated coefficients only? See below regarding why this is useful.</p>
</td></tr>
<tr><td><code id="rHeadrick_+3A_coefs">coefs</code></td>
<td>
<p>(optional) supply previously estimated coefficients? This is useful when there must be multiple
data sets drawn and will avoid repetitive computations. Must be the object returned after passing
<code>return_coefs = TRUE</code></p>
</td></tr>
<tr><td><code id="rHeadrick_+3A_control">control</code></td>
<td>
<p>a list of control parameters when locating the polynomial coefficients</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is primarily a wrapper for the code written by Oscar L. Olvera Astivia
(last edited Feb 26, 2015) with some modifications (e.g., better starting values
for the Newton optimizer, passing previously saved coefs, etc).
</p>


<h3>Author(s)</h3>

<p>Oscar L. Olvera Astivia and Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>
<p>Headrick, T. C. (2002). Fast fifth-order polynomial transforms for generating univariate and
multivariate nonnormal distributions. <em>Computational Statistics &amp; Data Analysis, 40</em>, 685-711.
</p>
<p>Olvera Astivia, O. L., &amp; Zumbo, B. D. (2015). A Cautionary Note on the Use of the Vale and Maurelli
Method to Generate Multivariate, Nonnormal Data for Simulation Purposes.
<em>Educational and Psychological Measurement, 75</em>, 541-567.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(1)

N &lt;- 200
mean &lt;- c(rep(0,4))
Sigma &lt;- matrix(.49, 4, 4)
diag(Sigma) &lt;- 1
skewness &lt;- c(rep(1,4))
kurtosis &lt;- c(rep(2,4))

nonnormal &lt;- rHeadrick(N, mean, Sigma, skewness, kurtosis)
# cor(nonnormal)
# psych::describe(nonnormal)

#-----------
# compute the coefficients, then supply them back to the function to avoid
# extra computations

cfs &lt;- rHeadrick(N, mean, Sigma, skewness, kurtosis, return_coefs = TRUE)
cfs

# compare
system.time(nonnormal &lt;- rHeadrick(N, mean, Sigma, skewness, kurtosis))
system.time(nonnormal &lt;- rHeadrick(N, mean, Sigma, skewness, kurtosis,
                                   coefs=cfs))

## End(Not run)

</code></pre>

<hr>
<h2 id='rint'>Generate integer values within specified range</h2><span id='topic+rint'></span>

<h3>Description</h3>

<p>Efficiently generate positive and negative integer values with (default) or without replacement.
This function is mainly a wrapper to the <code><a href="base.html#topic+sample.int">sample.int</a></code> function (which itself is much
more efficient integer sampler than the more general <code><a href="base.html#topic+sample">sample</a></code>), however is intended
to work with both positive and negative integer ranges since <code>sample.int</code> only returns
positive integer values that must begin at <code>1L</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rint(n, min, max, replace = TRUE, prob = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rint_+3A_n">n</code></td>
<td>
<p>number of samples to draw</p>
</td></tr>
<tr><td><code id="rint_+3A_min">min</code></td>
<td>
<p>lower limit of the distribution. Must be finite</p>
</td></tr>
<tr><td><code id="rint_+3A_max">max</code></td>
<td>
<p>upper limit of the distribution. Must be finite</p>
</td></tr>
<tr><td><code id="rint_+3A_replace">replace</code></td>
<td>
<p>should sampling be with replacement?</p>
</td></tr>
<tr><td><code id="rint_+3A_prob">prob</code></td>
<td>
<p>a vector of probability weights for obtaining the elements of the vector being sampled</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)

# sample 1000 integer values within 20 to 100
x &lt;- rint(1000, min = 20, max = 100)
summary(x)

# sample 1000 integer values within 100 to 10 billion
x &lt;- rint(1000, min = 100, max = 1e8)
summary(x)

# compare speed to sample()
system.time(x &lt;- rint(1000, min = 100, max = 1e8))
system.time(x2 &lt;- sample(100:1e8, 1000, replace = TRUE))

# sample 1000 integer values within -20 to 20
x &lt;- rint(1000, min = -20, max = 20)
summary(x)

</code></pre>

<hr>
<h2 id='rinvWishart'>Generate data with the inverse Wishart distribution</h2><span id='topic+rinvWishart'></span>

<h3>Description</h3>

<p>Function generates data in the form of symmetric matrices from the inverse
Wishart distribution given a covariance matrix and degrees of freedom.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rinvWishart(n = 1, df, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rinvWishart_+3A_n">n</code></td>
<td>
<p>number of matrix observations to generate. By default <code>n = 1</code>, which returns a single
symmetric matrix. If <code>n &gt; 1</code> then a list of <code>n</code> symmetric matrices are returned instead</p>
</td></tr>
<tr><td><code id="rinvWishart_+3A_df">df</code></td>
<td>
<p>degrees of freedom</p>
</td></tr>
<tr><td><code id="rinvWishart_+3A_sigma">sigma</code></td>
<td>
<p>positive definite covariance matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric matrix with columns equal to <code>ncol(sigma)</code> when <code>n = 1</code>, or a list
of <code>n</code> matrices with the same properties
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+runSimulation">runSimulation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# random inverse Wishart matrix given variances [3,6], covariance 2, and df=15
sigma &lt;- matrix(c(3,2,2,6), 2, 2)
x &lt;- rinvWishart(sigma = sigma, df = 15)
x

# list of matrices
x &lt;- rinvWishart(20, sigma = sigma, df = 15)
x

</code></pre>

<hr>
<h2 id='rmgh'>Generate data with the multivariate g-and-h distribution</h2><span id='topic+rmgh'></span>

<h3>Description</h3>

<p>Generate non-normal distributions using the multivariate g-and-h distribution. Can be used to
generate several different classes of univariate and multivariate distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmgh(n, g, h, mean = rep(0, length(g)), sigma = diag(length(mean)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmgh_+3A_n">n</code></td>
<td>
<p>number of samples to draw</p>
</td></tr>
<tr><td><code id="rmgh_+3A_g">g</code></td>
<td>
<p>the g parameter(s) which control the skew of a distribution in terms of both direction
and magnitude</p>
</td></tr>
<tr><td><code id="rmgh_+3A_h">h</code></td>
<td>
<p>the h parameter(s) which control the tail weight or elongation of a distribution and
is positively related with kurtosis</p>
</td></tr>
<tr><td><code id="rmgh_+3A_mean">mean</code></td>
<td>
<p>a vector of k elements for the mean of the variables</p>
</td></tr>
<tr><td><code id="rmgh_+3A_sigma">sigma</code></td>
<td>
<p>desired k x k covariance matrix between bivariate non-normal variables</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)

# univariate
norm &lt;- rmgh(10000,1e-5,0)
hist(norm)

skew &lt;- rmgh(10000,1/2,0)
hist(skew)

neg_skew_platykurtic &lt;- rmgh(10000,-1,-1/2)
hist(neg_skew_platykurtic)

# multivariate
sigma &lt;- matrix(c(2,1,1,4), 2)
mean &lt;- c(-1, 1)
twovar &lt;- rmgh(10000, c(-1/2, 1/2), c(0,0),
    mean=mean, sigma=sigma)
hist(twovar[,1])
hist(twovar[,2])
plot(twovar)

</code></pre>

<hr>
<h2 id='RMSE'>Compute the (normalized) root mean square error</h2><span id='topic+RMSE'></span><span id='topic+RMSD'></span>

<h3>Description</h3>

<p>Computes the average deviation (root mean square error; also known as the root mean square deviation)
of a sample estimate from the parameter value. Accepts estimate and parameter values,
as well as estimate values which are in deviation form.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RMSE(
  estimate,
  parameter = NULL,
  type = "RMSE",
  MSE = FALSE,
  percent = FALSE,
  unname = FALSE
)

RMSD(
  estimate,
  parameter = NULL,
  type = "RMSE",
  MSE = FALSE,
  percent = FALSE,
  unname = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RMSE_+3A_estimate">estimate</code></td>
<td>
<p>a <code>numeric</code> vector, <code>matrix</code>/<code>data.frame</code>, or <code>list</code>
of parameter estimates.
If a vector, the length is equal to the number of replications. If a
<code>matrix</code>/<code>data.frame</code>, the number of rows must equal the number of replications.
<code>list</code> objects will be looped
over using the same rules after above after first translating the information into one-dimensional
vectors and re-creating the structure upon return</p>
</td></tr>
<tr><td><code id="RMSE_+3A_parameter">parameter</code></td>
<td>
<p>a <code>numeric</code> scalar/vector indicating the fixed parameter values.
If a single value is supplied and <code>estimate</code> is a <code>matrix</code>/<code>data.frame</code> then
the value will be recycled for each column; otherwise, each element will be associated
with each respective column in the <code>estimate</code> input.
If <code>NULL</code> then it will be assumed that the <code>estimate</code> input is in a deviation
form (therefore <code>sqrt(mean(estimate^2))</code> will be returned)</p>
</td></tr>
<tr><td><code id="RMSE_+3A_type">type</code></td>
<td>
<p>type of deviation to compute. Can be <code>'RMSE'</code> (default) for the root mean square-error,
<code>'NRMSE'</code> for the normalized RMSE (RMSE / (max(estimate) - min(estimate))),
<code>'SRMSE'</code> for the standardized RMSE (RMSE / sd(estimate)),
<code>'CV'</code> for the coefficient of variation, or <code>'RMSLE'</code> for the root mean-square log-error</p>
</td></tr>
<tr><td><code id="RMSE_+3A_mse">MSE</code></td>
<td>
<p>logical; return the mean square error equivalent of the results instead of the root
mean-square error (in other words, the result is squared)? Default is <code>FALSE</code></p>
</td></tr>
<tr><td><code id="RMSE_+3A_percent">percent</code></td>
<td>
<p>logical; change returned result to percentage by multiplying by 100?
Default is FALSE</p>
</td></tr>
<tr><td><code id="RMSE_+3A_unname">unname</code></td>
<td>
<p>logical; apply <code><a href="base.html#topic+unname">unname</a></code> to the results to remove any variable
names?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a <code>numeric</code> vector indicating the overall average deviation in the estimates
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bias">bias</a></code>
</p>
<p>MAE
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pop &lt;- 1
samp &lt;- rnorm(100, 1, sd = 0.5)
RMSE(samp, pop)

dev &lt;- samp - pop
RMSE(dev)

RMSE(samp, pop, type = 'NRMSE')
RMSE(dev, type = 'NRMSE')
RMSE(dev, pop, type = 'SRMSE')
RMSE(samp, pop, type = 'CV')
RMSE(samp, pop, type = 'RMSLE')

# percentage reported
RMSE(samp, pop, type = 'NRMSE')
RMSE(samp, pop, type = 'NRMSE', percent = TRUE)

# matrix input
mat &lt;- cbind(M1=rnorm(100, 2, sd = 0.5), M2 = rnorm(100, 2, sd = 1))
RMSE(mat, parameter = 2)
RMSE(mat, parameter = c(2, 3))

# different parameter associated with each column
mat &lt;- cbind(M1=rnorm(1000, 2, sd = 0.25), M2 = rnorm(1000, 3, sd = .25))
RMSE(mat, parameter = c(2,3))

# same, but with data.frame
df &lt;- data.frame(M1=rnorm(100, 2, sd = 0.5), M2 = rnorm(100, 2, sd = 1))
RMSE(df, parameter = c(2,2))

# parameters of the same size
parameters &lt;- 1:10
estimates &lt;- parameters + rnorm(10)
RMSE(estimates, parameters)

</code></pre>

<hr>
<h2 id='rmvnorm'>Generate data with the multivariate normal (i.e., Gaussian) distribution</h2><span id='topic+rmvnorm'></span>

<h3>Description</h3>

<p>Function generates data from the multivariate normal distribution given some mean vector and/or
covariance matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmvnorm(n, mean = rep(0, nrow(sigma)), sigma = diag(length(mean)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmvnorm_+3A_n">n</code></td>
<td>
<p>number of observations to generate</p>
</td></tr>
<tr><td><code id="rmvnorm_+3A_mean">mean</code></td>
<td>
<p>mean vector, default is <code>rep(0, length = ncol(sigma))</code></p>
</td></tr>
<tr><td><code id="rmvnorm_+3A_sigma">sigma</code></td>
<td>
<p>positive definite covariance matrix, default is <code>diag(length(mean))</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric matrix with columns equal to <code>length(mean)</code>
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+runSimulation">runSimulation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# random normal values with mean [5, 10] and variances [3,6], and covariance 2
sigma &lt;- matrix(c(3,2,2,6), 2, 2)
mu &lt;- c(5,10)
x &lt;- rmvnorm(1000, mean = mu, sigma = sigma)
head(x)
summary(x)
plot(x[,1], x[,2])


</code></pre>

<hr>
<h2 id='rmvt'>Generate data with the multivariate t distribution</h2><span id='topic+rmvt'></span>

<h3>Description</h3>

<p>Function generates data from the multivariate t distribution given a covariance matrix,
non-centrality parameter (or mode), and degrees of freedom.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmvt(n, sigma, df, delta = rep(0, nrow(sigma)), Kshirsagar = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmvt_+3A_n">n</code></td>
<td>
<p>number of observations to generate</p>
</td></tr>
<tr><td><code id="rmvt_+3A_sigma">sigma</code></td>
<td>
<p>positive definite covariance matrix</p>
</td></tr>
<tr><td><code id="rmvt_+3A_df">df</code></td>
<td>
<p>degrees of freedom. <code>df = 0</code> and <code>df = Inf</code>
corresponds to the multivariate normal distribution</p>
</td></tr>
<tr><td><code id="rmvt_+3A_delta">delta</code></td>
<td>
<p>the vector of non-centrality parameters of length <code>n</code>
which specifies the either the modes (default) or non-centrality parameters</p>
</td></tr>
<tr><td><code id="rmvt_+3A_kshirsagar">Kshirsagar</code></td>
<td>
<p>logical; triggers whether to generate data with non-centrality parameters
or to adjust the simulated data to the mode of the distribution. The default uses the mode</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric matrix with columns equal to <code>ncol(sigma)</code>
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+runSimulation">runSimulation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# random t values given variances [3,6], covariance 2, and df = 15
sigma &lt;- matrix(c(3,2,2,6), 2, 2)
x &lt;- rmvt(1000, sigma = sigma, df = 15)
head(x)
summary(x)
plot(x[,1], x[,2])


</code></pre>

<hr>
<h2 id='RobbinsMonro'>Robbins-Monro (1951) stochastic root-finding algorithm</h2><span id='topic+RobbinsMonro'></span><span id='topic+print.RM'></span><span id='topic+plot.RM'></span>

<h3>Description</h3>

<p>Function performs stochastic root solving for the provided <code>f(x)</code>
using the Robbins-Monro (1951) algorithm. Differs from deterministic
cousins such as <code><a href="stats.html#topic+uniroot">uniroot</a></code> in that <code>f</code> may contain stochastic error
components, where the root is obtained through the running average method
provided by noise filter (see also <code><a href="#topic+PBA">PBA</a></code>).
Assumes that <code>E[f(x)]</code> is non-decreasing in <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RobbinsMonro(
  f,
  p,
  ...,
  Polyak_Juditsky = FALSE,
  maxiter = 500L,
  miniter = 100L,
  k = 3L,
  tol = 1e-05,
  verbose = TRUE,
  fn.a = function(iter, a = 1, b = 1/2, c = 0, ...) a/(iter + c)^b
)

## S3 method for class 'RM'
print(x, ...)

## S3 method for class 'RM'
plot(x, par = 1, main = NULL, Polyak_Juditsky = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RobbinsMonro_+3A_f">f</code></td>
<td>
<p>noisy function for which the root is sought</p>
</td></tr>
<tr><td><code id="RobbinsMonro_+3A_p">p</code></td>
<td>
<p>vector of starting values to be passed as <code>f(p, ...)</code></p>
</td></tr>
<tr><td><code id="RobbinsMonro_+3A_...">...</code></td>
<td>
<p>additional named arguments to be passed to <code>f</code></p>
</td></tr>
<tr><td><code id="RobbinsMonro_+3A_polyak_juditsky">Polyak_Juditsky</code></td>
<td>
<p>logical; apply the Polyak and Juditsky (1992)
running-average method? Returns the final running average estimate
using the Robbins-Monro  updates (also applies to <code>plot</code>).
Note that this should only be
used when the step-sizes are sufficiently large so that the Robbins-Monro
have the ability to stochastically explore around the root (not just
approach it from one side, which occurs when using small steps)</p>
</td></tr>
<tr><td><code id="RobbinsMonro_+3A_maxiter">maxiter</code></td>
<td>
<p>the maximum number of iterations (default 500)</p>
</td></tr>
<tr><td><code id="RobbinsMonro_+3A_miniter">miniter</code></td>
<td>
<p>minimum number of iterations (default 100)</p>
</td></tr>
<tr><td><code id="RobbinsMonro_+3A_k">k</code></td>
<td>
<p>number of consecutive <code>tol</code> criteria required before terminating</p>
</td></tr>
<tr><td><code id="RobbinsMonro_+3A_tol">tol</code></td>
<td>
<p>tolerance criteria for convergence on the changes in the
updated <code>p</code> elements. Must be achieved on <code>k</code> (default 3)
successive occasions</p>
</td></tr>
<tr><td><code id="RobbinsMonro_+3A_verbose">verbose</code></td>
<td>
<p>logical; should the iterations and estimate be printed to the
console?</p>
</td></tr>
<tr><td><code id="RobbinsMonro_+3A_fn.a">fn.a</code></td>
<td>
<p>function to create the <code>a</code> coefficient in the Robbins-Monro
noise filter. Requires the first argument is the current iteration (<code>iter</code>),
provide one or more arguments, and (optionally) the <code>...</code>. Sequence function
is of the form recommended by Spall (2000).
</p>
<p>Note that if a different function is provided it must satisfy the property
that <code class="reqn">\sum^\infty_{i=1} a_i = \infty</code> and
<code class="reqn">\sum^\infty_{i=1} a_i^2 &lt; \infty</code></p>
</td></tr>
<tr><td><code id="RobbinsMonro_+3A_x">x</code></td>
<td>
<p>an object of class <code>RM</code></p>
</td></tr>
<tr><td><code id="RobbinsMonro_+3A_par">par</code></td>
<td>
<p>which parameter in the original vector <code>p</code> to include in the plot</p>
</td></tr>
<tr><td><code id="RobbinsMonro_+3A_main">main</code></td>
<td>
<p>plot title</p>
</td></tr>
</table>


<h3>References</h3>

<p>Polyak, B. T. and Juditsky, A. B. (1992). Acceleration of Stochastic
Approximation by Averaging. SIAM Journal on Control and Optimization,
30(4):838.
</p>
<p>Robbins, H. and Monro, S. (1951). A stochastic approximation method.
Ann.Math.Statistics, 22:400-407.
</p>
<p>Spall, J.C. (2000). Adaptive stochastic approximation by the simultaneous
perturbation method. IEEE Trans. Autom. Control 45, 1839-1853.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+uniroot">uniroot</a></code>, <code><a href="#topic+PBA">PBA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# find x that solves f(x) - b = 0 for the following
f.root &lt;- function(x, b = .6) 1 / (1 + exp(-x)) - b
f.root(.3)

xs &lt;- seq(-3,3, length.out=1000)
plot(xs, f.root(xs), type = 'l', ylab = "f(x)", xlab='x')
abline(h=0, col='red')

retuni &lt;- uniroot(f.root, c(0,1))
retuni
abline(v=retuni$root, col='blue', lty=2)

# Robbins-Monro without noisy root, start with p=.9
retrm &lt;- RobbinsMonro(f.root, .9)
retrm
plot(retrm)

# Same problem, however root function is now noisy. Hence, need to solve
#  fhat(x) - b + e = 0, where E(e) = 0
f.root_noisy &lt;- function(x) 1 / (1 + exp(-x)) - .6 + rnorm(1, sd=.02)
sapply(rep(.3, 10), f.root_noisy)

# uniroot "converges" unreliably
set.seed(123)
uniroot(f.root_noisy, c(0,1))$root
uniroot(f.root_noisy, c(0,1))$root
uniroot(f.root_noisy, c(0,1))$root

# Robbins-Monro provides better convergence
retrm.noise &lt;- RobbinsMonro(f.root_noisy, .9)
retrm.noise
plot(retrm.noise)

# different power (b) for fn.a()
retrm.b2 &lt;- RobbinsMonro(f.root_noisy, .9, b = .01)
retrm.b2
plot(retrm.b2)

# use Polyak-Juditsky averaging (b should be closer to 0 to work well)
retrm.PJ &lt;- RobbinsMonro(f.root_noisy, .9, b = .01,
                         Polyak_Juditsky = TRUE)
retrm.PJ   # final Polyak_Juditsky estimate
plot(retrm.PJ) # Robbins-Monro history
plot(retrm.PJ, Polyak_Juditsky = TRUE) # Polyak_Juditsky history

</code></pre>

<hr>
<h2 id='RSE'>Compute the relative standard error ratio</h2><span id='topic+RSE'></span>

<h3>Description</h3>

<p>Computes the relative standard error ratio given the set of estimated standard errors (SE) and the
deviation across the R simulation replications (SD). The ratio is formed by finding the expectation
of the SE terms, and compares this expectation to the general variability of their respective parameter
estimates across the R replications (ratio should equal 1). This is used to roughly evaluate whether the
SEs being advertised by a given estimation method matches the sampling variability of the respective
estimates across samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RSE(SE, ests, unname = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RSE_+3A_se">SE</code></td>
<td>
<p>a <code>numeric</code> matrix of SE estimates across the replications (extracted
from the <code>results</code> object in the Summarise step). Alternatively, can be a vector containing
the mean of the SE estimates across the R simulation replications</p>
</td></tr>
<tr><td><code id="RSE_+3A_ests">ests</code></td>
<td>
<p>a <code>numeric</code> matrix object containing the parameter estimates under investigation
found within the <code><a href="#topic+Summarise">Summarise</a></code> function. This input is used to compute the
standard deviation/variance estimates for each column to evaluate how well the expected SE
matches the standard deviation</p>
</td></tr>
<tr><td><code id="RSE_+3A_unname">unname</code></td>
<td>
<p>logical; apply <code><a href="base.html#topic+unname">unname</a></code> to the results to remove any variable
names?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns vector of variance ratios, (RSV = SE^2/SD^2)
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
R &lt;- 10000
par_ests &lt;- cbind(rnorm(R), rnorm(R, sd=1/10),
                  rnorm(R, sd=1/15))
colnames(par_ests) &lt;- paste0("par", 1:3)
(SDs &lt;- colSDs(par_ests))

SEs &lt;- cbind(1 + rnorm(R, sd=.01),
             1/10 + + rnorm(R, sd=.01),
             1/15 + rnorm(R, sd=.01))
(E_SEs &lt;- colMeans(SEs))
RSE(SEs, par_ests)

# equivalent to the form
colMeans(SEs) / SDs


</code></pre>

<hr>
<h2 id='rtruncate'>Generate a random set of values within a truncated range</h2><span id='topic+rtruncate'></span>

<h3>Description</h3>

<p>Function generates data given a supplied random number generating function that
are constructed to fall within a particular range. Sampled values outside this
range are discarded and re-sampled until the desired criteria has been met.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rtruncate(n, rfun, range, ..., redraws = 100L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rtruncate_+3A_n">n</code></td>
<td>
<p>number of observations to generate. This should be the first argument
passed to <code>rfun</code></p>
</td></tr>
<tr><td><code id="rtruncate_+3A_rfun">rfun</code></td>
<td>
<p>a function to generate random values. Function can return
a numeric/integer vector or matrix, and additional arguments
requred for this function are passed through the argument <code>...</code></p>
</td></tr>
<tr><td><code id="rtruncate_+3A_range">range</code></td>
<td>
<p>a numeric vector of length two, where the first element
indicates the lower bound and the second the upper bound. When values are
generated outside these two bounds then data are redrawn until the bounded
criteria is met. When the output of <code>rfun</code> is a matrix then this input
can be specified as a matrix with two rows, where each the first row
corresponds to the lower bound and the second row the upper bound for
each generated column in the output</p>
</td></tr>
<tr><td><code id="rtruncate_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code>rfun</code></p>
</td></tr>
<tr><td><code id="rtruncate_+3A_redraws">redraws</code></td>
<td>
<p>the maximum number of redraws to take before terminating the
iterative sequence. This is in place as a safety in case the <code>range</code>
is too small given the random number generator, causing too many
consecutive rejections. Default is 100</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In simulations it is often useful to draw numbers from truncated distributions
rather than across the full theoretical range. For instance, sampling parameters
within the range [-4,4] from a normal distribution. The <code>rtruncate</code>
function has been designed to accept any sampling function, where the first
argument is the number of values to sample, and will draw values iteratively
until the number of values within the specified bound are obtained.
In situations where it is unlikely for the bounds to be located
(e.g., sampling from a standard normal distribution where all values are
within [-10,-6]) then the sampling scheme will throw an error if too many
re-sampling executions are required (default will stop if more that 100
calls to <code>rfun</code> are required).
</p>


<h3>Value</h3>

<p>either a numeric vector or matrix, where all values are within the
desired <code>range</code>
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable
Monte Carlo Simulations with the SimDesign Package.
<code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics
with Monte Carlo simulation. <code>Journal of Statistics Education, 24</code>(3),
136-156. <a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+runSimulation">runSimulation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# n = 1000 truncated normal vector between [-2,3]
vec &lt;- rtruncate(1000, rnorm, c(-2,3))
summary(vec)

# truncated correlated multivariate normal between [-1,4]
mat &lt;- rtruncate(1000, rmvnorm, c(-1,4),
   sigma = matrix(c(2,1,1,1),2))
summary(mat)

# truncated correlated multivariate normal between [-1,4] for the
#  first column and [0,3] for the second column
mat &lt;- rtruncate(1000, rmvnorm, cbind(c(-1,4), c(0,3)),
   sigma = matrix(c(2,1,1,1),2))
summary(mat)

# truncated chi-square with df = 4 between [2,6]
vec &lt;- rtruncate(1000, rchisq, c(2,6), df = 4)
summary(vec)

</code></pre>

<hr>
<h2 id='runSimulation'>Run a Monte Carlo simulation given a data.frame of conditions and simulation functions</h2><span id='topic+runSimulation'></span><span id='topic+summary.SimDesign'></span><span id='topic+print.SimDesign'></span>

<h3>Description</h3>

<p>This function runs a Monte Carlo simulation study given a set of predefined simulation functions,
design conditions, and number of replications. Results can be saved as temporary files in case of
interruptions and may be restored by re-running <code>runSimulation</code>, provided that the respective temp
file can be found in the working directory. <code>runSimulation</code> supports parallel
and cluster computing (with the <code>parallel</code> and <code>future</code> packages),
global and local debugging, error handling (including fail-safe
stopping when functions fail too often, even across nodes), provides bootstrap estimates of the
sampling variability (optional), and automatic tracking of error and warning messages
with their associated <code>.Random.seed</code> states.
For convenience, all functions available in the R work-space are exported across all nodes
so that they are more easily accessible (however, other R objects are not, and therefore
must be passed to the <code>fixed_objects</code> input to become available across nodes).
For an in-depth tutorial of the package please refer to Chalmers and Adkins (2020;
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>).
For an earlier didactic presentation of the package refer to Sigal and Chalmers
(2016; <a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>). Finally, see the associated
wiki on Github (<a href="https://github.com/philchalmers/SimDesign/wiki">https://github.com/philchalmers/SimDesign/wiki</a>)
for tutorial material, examples, and applications of <code>SimDesign</code> to real-world
simulation experiments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runSimulation(
  design,
  replications,
  generate,
  analyse,
  summarise,
  fixed_objects = NULL,
  packages = NULL,
  filename = NULL,
  debug = "none",
  load_seed = NULL,
  save = replications &gt; 10,
  store_results = TRUE,
  save_results = FALSE,
  parallel = FALSE,
  ncores = parallel::detectCores() - 1L,
  cl = NULL,
  notification = "none",
  beep = FALSE,
  sound = 1,
  CI = 0.95,
  seed = NULL,
  boot_method = "none",
  boot_draws = 1000L,
  max_errors = 50L,
  save_seeds = FALSE,
  resume = TRUE,
  save_details = list(),
  control = list(),
  progress = TRUE,
  verbose = TRUE
)

## S3 method for class 'SimDesign'
summary(object, ...)

## S3 method for class 'SimDesign'
print(x, list2char = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="runSimulation_+3A_design">design</code></td>
<td>
<p>a <code>tibble</code> or <code>data.frame</code> object containing the Monte Carlo simulation
conditions to be studied, where each row represents a unique condition and each column a factor
to be varied. See <code><a href="#topic+createDesign">createDesign</a></code> for the standard approach
to create this simulation design object</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_replications">replications</code></td>
<td>
<p>number of independent replications to perform per
condition (i.e., each row in <code>design</code>).
Must be greater than 0</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_generate">generate</code></td>
<td>
<p>user-defined data and parameter generating function (or named list of functions).
See <code><a href="#topic+Generate">Generate</a></code> for details. Note that this argument may be omitted by the
user if they wish to generate the data with the <code>analyse</code> step, but for real-world
simulations this is generally not recommended. If multiple generate functions are provided
as a list then the list of generate functions are executed in order until the first valid
generate function is executed, where the subsequent generation functions are then ignored
(see <code><a href="#topic+GenerateIf">GenerateIf</a></code> to only apply data generation for specific conditions).</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_analyse">analyse</code></td>
<td>
<p>user-defined analysis function (or named list of functions)
that acts on the data generated from
<code><a href="#topic+Generate">Generate</a></code> (or, if <code>generate</code> was omitted, can be used to generate and
analyses the simulated data). See <code><a href="#topic+Analyse">Analyse</a></code> for details</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_summarise">summarise</code></td>
<td>
<p>optional (but strongly recommended) user-defined summary function
from <code><a href="#topic+Summarise">Summarise</a></code> to be used to compute meta-statistical summary
information after all the replications have completed within
each <code>design</code> condition. Note that unlike the Generate and Analyse
steps, the Summarise portion is not as important to perfectly organize
as the results can be summarised later on by using the built-in
<code><a href="#topic+reSummarise">reSummarise</a></code> function (provided either
<code>store_results = TRUE</code> or <code>save_results = TRUE</code> were included).
</p>
<p>Omitting this function will return a tibble with the <code>Design</code>
and associated results information for all
<code>nrow(Design) * repliations</code> evaluations if the results from each
<code>Analyse()</code> call was a one-dimensional vector.
For more general objects returned by <code>Analyse()</code>
(such as <code>list</code>s), a <code>list</code>
containing the results returned form <code><a href="#topic+Analyse">Analyse</a></code>.
This is generally only recommended for didactic purposes because the results
will leave out a large amount of
information (e.g., try-errors, warning messages, saving files, etc), can
witness memory related issues if the Analyse function returns larger objects,
and generally is not as flexible internally. However, it may be useful
when replications are expensive and ANOVA-based decompositions involving
the within-condition replication information are of interest, though
of course this  can be circumvented by using <code>store_results = TRUE</code> or
<code>save_results = TRUE</code> with or without a supplied <code>summarise</code>
definition.</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_fixed_objects">fixed_objects</code></td>
<td>
<p>(optional) an object (usually a named <code>list</code>)
containing additional user-defined objects
that should remain fixed across conditions. This is useful when including
large vectors/matrices of population parameters, fixed data information
that should be used across all conditions and replications (e.g., including a
common design matrix for linear regression models), or simply control
constant global elements (e.g., a constant for sample size)</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_packages">packages</code></td>
<td>
<p>a character vector of external packages to be used during the simulation (e.g.,
<code>c('MASS', 'extraDistr', 'simsem')</code> ). Use this input when running code in
parallel to use non-standard functions from additional packages,
otherwise the functions must be made available by using explicit
<code><a href="base.html#topic+library">library</a></code> or <code><a href="base.html#topic+require">require</a></code> calls within the provided simulation functions.
Alternatively, functions can be called explicitly without attaching the package
with the <code>::</code> operator
(e.g., <code>extraDistr::rgumbel()</code>)</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_filename">filename</code></td>
<td>
<p>(optional) the name of the <code>.rds</code> file to save the final
simulation results to. If the extension
<code>.rds</code> is not included in the file name (e.g. <code>"mysimulation"</code>
versus <code>"mysimulation.rds"</code>) then the
<code>.rds</code> extension will be automatically added to the file name to ensure
the file extension is correct.
</p>
<p>Note that if the same file name already exists in the working
directly at the time of saving then a new
file will be generated instead and a warning will be thrown. This helps to
avoid accidentally overwriting
existing files. Default is <code>NULL</code>, indicating no file will be saved by default</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_debug">debug</code></td>
<td>
<p>a string indicating where to initiate a <code>browser()</code> call for editing
and debugging, and pairs particularly well with the <code>load_seed</code> argument for precise debugging.
General options are <code>'none'</code> (default; no debugging), <code>'error'</code>, which
starts the debugger
when any error in the code is detected in one of three generate-analyse-summarise functions,
and <code>'all'</code>, which debugs all the user defined functions regardless of
whether an error was thrown
or not. Specific options include: <code>'generate'</code>
to debug the data simulation function, <code>'analyse'</code> to debug the computational function, and
<code>'summarise'</code> to debug the aggregation function.
</p>
<p>If the <code>Analyse</code> argument is supplied as a named list of functions then it is also possible
to debug the specific function of interest by passing the name of the respective function in the list.
For instance, if <code>analyse = list(A1=Analyse.A1, A2=Analyse.A2)</code> then passing
<code>debug = 'A1'</code> will debug only the first function in this list, and all remaining analysis
functions will be ignored.
</p>
<p>For debugging specific rows in the <code>Design</code> input (e.g.,
when a number of initial rows successfully complete but the <code>k</code>th
row fails) the row number can be appended to the standard
<code>debug</code> input using a <code>'-'</code> separator.
For instance, debugging whenever an error is raised
in the second row of <code>Design</code> can be declared via <code>debug = 'error-2'</code>.
</p>
<p>Finally, users may place <code><a href="base.html#topic+browser">browser</a></code> calls within the respective functions for
debugging at specific lines, which is useful when debugging based on conditional evaluations (e.g.,
<code>if(this == 'problem') browser()</code>). Note that parallel computation flags
will automatically be disabled when a <code>browser()</code> is detected or when a debugging
argument other than
<code>'none'</code> is supplied</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_load_seed">load_seed</code></td>
<td>
<p>used to replicate an exact simulation state, which is
primarily useful for debugging purposes.
Input can be a character object indicating which file to load from when the
<code>.Random.seed</code>s have
be saved (after a call with <code>save_seeds = TRUE</code>), or an integer vector
indicating the actual
<code>.Random.seed</code> values. E.g., <code>load_seed = 'design-row-2/seed-1'</code>
will load the first seed in the second row of the <code>design</code> input, or
explicitly passing the
elements from <code>.Random.seed</code> (see <code><a href="#topic+SimExtract">SimExtract</a></code> to extract
the seeds associated explicitly
with errors during the simulation, where each column represents a unique seed).
If the input is a character vector then it is important NOT
to modify the <code>design</code> input object, otherwise the path may not point
to the correct saved location, while
if the input is an integer vector (or single column <code>tbl</code> object)
then it WILL be important to modify the <code>design</code> input in order to load this
exact seed for the corresponding design row. Default is <code>NULL</code></p>
</td></tr>
<tr><td><code id="runSimulation_+3A_save">save</code></td>
<td>
<p>logical; save the temporary simulation state to the hard-drive? This is useful
for simulations which require an extended amount of time, though for shorter simulations
can be disabled to slightly improve computational efficiency. When <code>TRUE</code>,
which is the default when evaluating <code>replications &gt; 10</code>, a temp file
will be created in the working directory which allows the simulation state to be saved
and recovered (in case of power outages, crashes, etc). As well, triggering this flag will
save any fatal <code>.Random.seed</code> states when conditions unexpectedly crash (where each seed
is stored row-wise in an external .rds file), which provides a much easier mechanism
to debug issues (see <code>load_seed</code> for details). Upon completion, this temp file will
be removed.
</p>
<p>To recover your simulation at the last known location (having patched the issues in the
previous execution code) simply re-run the code you used to
initially define the simulation and the external file will automatically be detected and read-in.
Default is <code>TRUE</code> when <code>replications &gt; 10</code> and <code>FALSE</code> otherwise</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_store_results">store_results</code></td>
<td>
<p>logical; store the complete tables of simulation results
in the returned object? This is <code>TRUE</code> default, though if RAM anticipated to
be an issue see <code>save_results</code> instead. Note that if the <code>Design</code>
object is omitted from the call to <code>runSimulation()</code>, or the number of rows in <code>Design</code>
is exactly 1, then this argument is automatically set to <code>TRUE</code> as RAM storage is no
longer an issue.
</p>
<p>To extract these results
pass the returned object to <code>SimExtract(..., what = 'results')</code>, which will return a named list
of all the simulation results for each condition if <code>nrow(Design) &gt; 1</code>; otherwise, if
<code>nrow(Design) == 1</code> or <code>Design</code> was missing the <code>results</code> object will be stored as-is</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_save_results">save_results</code></td>
<td>
<p>logical; save the results returned from <code><a href="#topic+Analyse">Analyse</a></code> to external
<code>.rds</code> files located in the defined <code>save_results_dirname</code> directory/folder?
Use this if you would like to keep track of the individual parameters returned from
the <code>analysis</code> function.
Each saved object will contain a list of three elements containing the
condition (row from <code>design</code>),
results (as a <code>list</code> or <code>matrix</code>), and try-errors.
See <code><a href="#topic+SimResults">SimResults</a></code> for an example of how to read these <code>.rds</code> files back into R
after the simulation is complete. Default is <code>FALSE</code>.
</p>
<p>WARNING: saving results to your hard-drive can fill up space very quickly for
larger simulations. Be sure to
test this option using a smaller number of replications before the full Monte
Carlo simulation is performed.
See also <code><a href="#topic+reSummarise">reSummarise</a></code> for applying summarise functions from saved
simulation results</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_parallel">parallel</code></td>
<td>
<p>logical; use parallel processing from the <code>parallel</code>
package over each unique condition?
</p>
<p>Alternatively, if the <code><a href="future.html#topic+future">future</a></code> package approach is desired then passing
<code>parallel = 'future'</code> to <code>runSimulation()</code> will use the defined
<code><a href="future.html#topic+plan">plan</a></code> for execution. This allows for greater flexibility when
specifying the general computing plan (e.g., <code>plan(multisession)</code>) for parallel computing
on the same machine, <code>plan(future.batchtools::batchtools_torque)</code> or
<code>plan(future.batchtools::batchtools_slurm)</code> for common MPI schedulers, etc).
However, it is the responsibility of the user to use <code>plan(sequential)</code> to reset the
computing plan when the jobs are completed</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_ncores">ncores</code></td>
<td>
<p>number of cores to be used in parallel execution (ignored if using the
<code>future</code> package approach). Default uses all available minus 1</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_cl">cl</code></td>
<td>
<p>cluster object defined by <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code> used to run code in parallel
(ignored if using the <code><a href="future.html#topic+future">future</a></code> package approach).
If <code>NULL</code> and <code>parallel = TRUE</code>, a local cluster object will be defined which
selects the maximum number cores available
and will be stopped when the simulation is complete. Note that supplying a <code>cl</code>
object will automatically set the <code>parallel</code> argument to <code>TRUE</code>. Define and supply this
cluster object yourself whenever you have multiple nodes to chain together (note in this case
that you must  use either the &quot;MPI&quot; or &quot;PSOCK&quot; clusters).
</p>
<p>Note that if the <code>future</code> package has
been attached prior to executing <code>runSimulation()</code> then the associated
<code>plan()</code> will be followed instead</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_notification">notification</code></td>
<td>
<p>an optional character vector input that can be used to send
Pushbullet notifications from a configured
computer. This reports information such as the total execution time, the condition
completed, and error/warning
messages recorded. This arguments assumes that users have already A) registered for
a Pushbullet account,
B) installed the application on their mobile device and computer, and C) created an
associated JSON file of the form
<code>~/.rpushbullet.json</code> using <code>RPushbullet::pbSetup()</code>).
</p>
<p>To utilize the <code>RPushbullet</code> in <code>SimDesign</code> first call <code>library(RPushbullet</code>
before running <code>runSimulation()</code> to read-in the default JSON file. Next,
pass one of the following supported
options: <code>'none'</code> (default; send no notification),
<code>'condition'</code> to send a notification after each condition has completed,
or <code>'complete'</code> to send
a notification only when the simulation has finished.</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_beep">beep</code></td>
<td>
<p>logical; call the <code>beepr</code> package when the simulation is completed?</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_sound">sound</code></td>
<td>
<p><code>sound</code> argument passed to <code>beepr::beep()</code></p>
</td></tr>
<tr><td><code id="runSimulation_+3A_ci">CI</code></td>
<td>
<p>bootstrap confidence interval level (default is 95%)</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_seed">seed</code></td>
<td>
<p>a vector of integers to be used for reproducibility.
The length of the vector must be equal the number of rows in <code>design</code>.
This argument calls <code><a href="base.html#topic+set.seed">set.seed</a></code> or
<code><a href="parallel.html#topic+clusterSetRNGStream">clusterSetRNGStream</a></code> for each condition, respectively,
but will not be run when <code>MPI = TRUE</code>.
Default randomly generates seeds within the range 1 to 2147483647 for each condition.</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_boot_method">boot_method</code></td>
<td>
<p>method for performing non-parametric bootstrap confidence intervals
for the respective meta-statistics computed by the <code>Summarise</code> function.
Can be <code>'basic'</code> for the empirical bootstrap CI, <code>'percentile'</code>
for percentile CIs, <code>'norm'</code> for normal approximations CIs, or <code>'studentized'</code>
for Studentized CIs (should only be used for simulations with lower replications due to its
computational intensity). Alternatively, CIs can be constructed using the argument <code>'CLT'</code>,
which computes the intervals according to the large-sample standard error
approximation <code class="reqn">SD(results)/\sqrt{R}</code>. Default is <code>'none'</code>, which performs no CI computations</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_boot_draws">boot_draws</code></td>
<td>
<p>number of non-parametric bootstrap draws to sample for the <code>summarise</code>
function after the generate-analyse replications are collected. Default is 1000</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_max_errors">max_errors</code></td>
<td>
<p>the simulation will terminate when more than this number of consecutive
errors are thrown in any
given condition, causing the simulation to continue to the next unique <code>design</code> condition.
This is included to avoid getting stuck in infinite re-draws, and to indicate that
something fatally problematic
is going wrong in the generate-analyse phases. Default is 50</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_save_seeds">save_seeds</code></td>
<td>
<p>logical; save the <code>.Random.seed</code> states prior to performing
each replication into
plain text files located in the defined <code>save_seeds_dirname</code> directory/folder?
Use this if you would like to keep track of every simulation state within each
replication and design
condition. This can be used to completely replicate any cell in the simulation if need be.
As well, see the <code>load_seed</code> input
to load a given <code>.Random.seed</code> to exactly replicate the generated data and
analysis state (mostly useful
for debugging). When <code>TRUE</code>, temporary files will also be saved
to the working directory (in the same way as when <code>save = TRUE</code>).
Default is <code>FALSE</code>
</p>
<p>Note, however, that this option is not typically necessary or recommended since
the <code>.Random.seed</code> states for simulation
replications that throw errors during the execution are automatically stored
within the final simulation
object, and can be extracted and investigated using <code><a href="#topic+SimExtract">SimExtract</a></code>.
Hence, this option is only of
interest when <em>all</em> of the replications must be reproducible (which occurs very rarely),
otherwise the defaults to <code>runSimulation</code> should be sufficient</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_resume">resume</code></td>
<td>
<p>logical; if a temporary <code>SimDesign</code> file is detected should
the simulation resume from this location? Keeping this <code>TRUE</code> is generally recommended,
however this should be disabled if using <code>runSimulation</code> within <code>runSimulation</code> to avoid
reading improper save states. Alternatively, if an integer is supplied then the simulation
will continue at the associated row location in <code>design</code> (e.g., <code>resume=10</code>).
This is useful to overwrite a previously evaluate element in the temporary files that was detected
to contain fatal errors that require re-evaluation without discarding the originally valid rows
in the simulation</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_save_details">save_details</code></td>
<td>
<p>a list pertaining to information regarding how and where files should be saved
when the <code>save</code> or <code>save_results</code> flags are triggered.
</p>

<dl>
<dt><code>safe</code></dt><dd><p>logical; trigger whether safe-saving should be performed. When <code>TRUE</code> files
will never be overwritten accidentally, and where appropriate the program will either stop or generate
new files with unique names. Default is <code>TRUE</code></p>
</dd>
<dt><code>compname</code></dt><dd><p>name of the computer running the simulation. Normally this doesn't need
to be modified, but in the event that a manual node breaks down while running a simulation the
results from the temp files may be resumed on another computer by changing the name of the
node to match the broken computer. Default is the result of evaluating
<code>unname(Sys.info()['nodename'])</code></p>
</dd>
<dt><code>out_rootdir</code></dt><dd><p>root directory to save all files to. Default uses the
current working directory</p>
</dd>
<dt><code>save_results_dirname</code></dt><dd><p>a string indicating the name of the folder to save
result objects to when <code>save_results = TRUE</code>. If a directory/folder does not exist
in the current working directory then a unique one will be created automatically. Default is
<code>'SimDesign-results_'</code> with the associated <code>compname</code> appended if no
<code>filename</code> is defined, otherwise the filename is used to replace 'SimDesign'
in the string</p>
</dd>
<dt><code>save_results_filename</code></dt><dd><p>a string indicating the name file to store, where the
<code>Design</code> row ID will be appended to ensure uniqueness across rows. Specifying
this input will disable any checking for the uniqueness of the file folder, thereby
allowing independent <code>runSimulation</code> calls to write to the same
<code>save_results_dirname</code>. Useful when the files should all be stored in the same
working directory, however the rows of <code>Design</code> are evaluated in isolation (e.g.,
for HPC structures that allow asynchronous file storage).
WARNING: the uniqueness of the file names are not checked using
this approach, therefore please ensure that each generated name will be unique a priori,
such as naming the file based on the supplied row condition information</p>
</dd>
<dt><code>save_seeds_dirname</code></dt><dd><p>a string indicating the name of the folder to save
<code>.Random.seed</code> objects to when <code>save_seeds = TRUE</code>. If a directory/folder
does not exist
in the current working directory then one will be created automatically. Default is
<code>'SimDesign-seeds_'</code> with the associated <code>compname</code> appended if no
<code>filename</code> is defined, otherwise the filename is used to replace 'SimDesign'
in the string</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="runSimulation_+3A_control">control</code></td>
<td>
<p>a list for extra information flags for controlling less
commonly used features. These include
</p>

<dl>
<dt><code>stop_on_fatal</code></dt><dd><p>logical (default is <code>FALSE</code>); should the simulation be
terminated immediately when
the maximum number of consecutive errors (<code>max_errors</code>) is reached? If <code>FALSE</code>,
the simulation will continue as though errors did not occur, however a column
<code>FATAL_TERMINATION</code> will be included in the resulting object indicating the final
error message observed, and <code>NA</code> placeholders will be placed in all other row-elements.
Default is <code>FALSE</code></p>
</dd>
<dt><code>warnings_as_errors</code></dt><dd><p>logical (default is <code>FALSE</code>);
treat warning messages as error messages during the simulation? Default is FALSE,
therefore warnings are only collected and not used to restart the data generation step,
and the seeds associated with
the warning message conditions are not stored within the final simulation object.
</p>
<p>Note that this argument is generally intended for debugging/early planning
stages when designing a simulation experiment. If specific warnings are known to
be problematic and should be treated as errors then please use
<code><a href="#topic+convertWarnings">convertWarnings</a></code> instead</p>
</dd>
<dt><code>store_warning_seeds</code></dt><dd><p>logical (default is <code>FALSE</code>);
in addition to storing the <code>.Random.seed</code> states whenever error messages
are raised, also store the <code>.Random.seed</code> states when warnings are raised? This is
disabled by default
since warnings are generally less problematic than errors, and because many more
warnings messages may be raised
throughout the simulation (potentially causing RAM related issues when constructing
the final simulation object as
any given simulation replicate could generate numerous warnings, and storing the seeds
states could add up quickly).
</p>
<p>Set this to <code>TRUE</code> when replicating warning messages is important, however be aware
that too many warnings messages raised during the simulation implementation could cause
RAM related issues.</p>
</dd>
<dt><code>include_replication_index</code> or
<code>include_reps</code></dt><dd><p>logical (default is <code>FALSE</code>);
should a REPLICATION element be added to
the <code>condition</code> object when performing the simulation to track which specific
replication experiment is being evaluated? This is useful when, for instance, attempting
to run external software programs (e.g., Mplus) that require saving temporary data sets
to the hard-drive (see the Wiki for examples)</p>
</dd>
<dt><code>try_all_analyse</code></dt><dd><p>logical; when <code>analyse</code> is a list, should every generated
data set be analyzed by each function definition in the <code>analyse</code> list?
Default is <code>TRUE</code>.
</p>
<p>Note that this <code>TRUE</code> default can be computationally demanding when some analysis
functions require more computational resources than others, and the data should be
discarded early as an invalid candidate (e.g., estimating a model via maximum-likelihood
in on analyze component, while estimating a model using MCMC estimation on another). Hence,
the main benefit of using <code>FALSE</code> instead is that the data set may be rejected earlier,
where easier/faster to estimate <code>analyse</code> definitions should be placed earlier in the list
as the functions are evaluated in sequence
(e.g., <code>Analyse = list(MLE=MLE_definition, MCMC=MCMC_definition)</code>) </p>
</dd>
<dt><code>allow_na</code></dt><dd><p>logical (default is <code>FALSE</code>); should <code>NA</code>s be allowed in the
analyse step as a valid result from the simulation analysis?</p>
</dd>
<dt><code>allow_nan</code></dt><dd><p>logical (default is <code>FALSE</code>); should <code>NaN</code>s be allowed in the
analyse step as a valid result from the simulation analysis?</p>
</dd>
<dt><code>type</code></dt><dd><p>default type of cluster to create for the <code>cl</code> object if no supplied.
For Windows OS this defaults to <code>"PSOCK"</code>, otherwise <code>"SOCK"</code> is selected
(suitable for Linux and Mac OSX). This is ignored if the user specifies their own <code>cl</code> object</p>
</dd>
<dt><code>MPI</code></dt><dd><p>logical (default is <code>FALSE</code>); use the <code>foreach</code> package in a
form usable by MPI to run simulation in parallel on a cluster? </p>
</dd>
<dt><code>print_RAM</code></dt><dd><p>logical (default is <code>TRUE</code>); print the amount of RAM
used throughout the simulation? Set to <code>FALSE</code> if unnecessary or if the call to
<code><a href="base.html#topic+gc">gc</a></code> is unnecessarily time consuming</p>
</dd>
<dt><code>.options.mpi</code></dt><dd><p>list of arguments passed to <code>foreach()</code> to control the MPI execution
properties. Only used when <code>MPI = TRUE</code></p>
</dd>
</dl>
</td></tr>
<tr><td><code id="runSimulation_+3A_progress">progress</code></td>
<td>
<p>logical; display a progress bar (using the <code>pbapply</code> package)
for each simulation condition?
This is useful when simulations conditions take a long time to run (see also the
<code>notifications</code> argument). Default is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="runSimulation_+3A_verbose">verbose</code></td>
<td>
<p>logical; print messages to the R console? Default is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="runSimulation_+3A_object">object</code></td>
<td>
<p>SimDesign object returned from <code><a href="#topic+runSimulation">runSimulation</a></code></p>
</td></tr>
<tr><td><code id="runSimulation_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
<tr><td><code id="runSimulation_+3A_x">x</code></td>
<td>
<p>SimDesign object returned from <code><a href="#topic+runSimulation">runSimulation</a></code></p>
</td></tr>
<tr><td><code id="runSimulation_+3A_list2char">list2char</code></td>
<td>
<p>logical; for <code>tibble</code> object re-evaluate list elements
as character vectors for better printing of the levels? Note that this
does not change the original classes of the object, just how they are printed.
Default is TRUE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The strategy for organizing the Monte Carlo simulation work-flow is to
</p>

<dl>
<dt>1)</dt><dd><p>Define a suitable <code>Design</code> object (a <code>tibble</code> or <code>data.frame</code>)
containing fixed conditional
information about the Monte Carlo simulations. Each row or this <code>design</code> object pertains
to a unique set of simulation to study, while each column the simulation factor under
investigation (e.g., sample size,
distribution types, etc). This is often expedited by using the
<code><a href="#topic+createDesign">createDesign</a></code> function, and if necessary the argument <code>subset</code>
can be used to remove redundant or non-applicable rows</p>
</dd>
<dt>2)</dt><dd><p>Define the three step functions to generate the data (<code><a href="#topic+Generate">Generate</a></code>; see also
<a href="https://CRAN.R-project.org/view=Distributions">https://CRAN.R-project.org/view=Distributions</a> for a list of distributions in R),
analyse the generated data by computing the respective parameter estimates, detection rates,
etc (<code><a href="#topic+Analyse">Analyse</a></code>), and finally summarise the results across the total
number of replications (<code><a href="#topic+Summarise">Summarise</a></code>).
</p>
</dd>
<dt>3)</dt><dd><p>Pass the <code>design</code> object and three defined R functions to <code>runSimulation</code>,
and declare the number of replications to perform with the <code>replications</code> input.
This function will return a suitable
<code>tibble</code> object with the complete simulation results and execution details</p>
</dd>
<dt>4)</dt><dd><p>Analyze the output from <code>runSimulation</code>, possibly using ANOVA techniques
(<code><a href="#topic+SimAnova">SimAnova</a></code>) and generating suitable plots and tables</p>
</dd>
</dl>

<p>Expressing the above more succinctly, the functions to be called have the following form,
with the exact functional arguments listed:
</p>

<dl>
<dt><code>Design &lt;- createDesign(...)</code></dt><dd></dd>
<dt><code>Generate &lt;- function(condition, fixed_objects = NULL) {...} </code></dt><dd></dd>
<dt><code>Analyse &lt;- function(condition, dat, fixed_objects = NULL) {...} </code></dt><dd></dd>
<dt><code>Summarise &lt;- function(condition, results, fixed_objects = NULL) {...} </code></dt><dd></dd>
<dt><code>res &lt;- runSimulation(design=Design, replications, generate=Generate,
        analyse=Analyse, summarise=Summarise)</code></dt><dd></dd>
</dl>

<p>The <code>condition</code> object above represents a single row from the <code>design</code> object, indicating
a unique Monte Carlo simulation condition. The <code>condition</code> object also contains two
additional elements to help track the simulation's state: an <code>ID</code> variable, indicating
the respective row number in the <code>design</code> object, and a <code>REPLICATION</code> element
indicating the replication iteration number (an integer value between 1 and <code>replication</code>).
This setup allows users to easily locate the <code>r</code>th replication (e.g., <code>REPLICATION == 500</code>)
within the <code>j</code>th row in the simulation design (e.g., <code>ID == 2</code>). The
<code>REPLICATION</code> input is also useful when temporarily saving files to the hard-drive
when calling external command line utilities (see examples on the wiki).
</p>
<p>For a template-based version of the work-flow, which is often useful when initially
defining a simulation, use the <code><a href="#topic+SimFunctions">SimFunctions</a></code> function. This
function will write a template simulation
to one/two files so that modifying the required functions and objects can begin immediately.
This means that users can focus on their Monte Carlo simulation details right away rather
than worrying about the repetitive administrative code-work required to organize the simulation's
execution flow.
</p>
<p>Finally, examples, presentation files, and tutorials can be found on the package wiki located at
<a href="https://github.com/philchalmers/SimDesign/wiki">https://github.com/philchalmers/SimDesign/wiki</a>.
</p>


<h3>Value</h3>

<p>a <code>tibble</code> from the <code>dplyr</code> package (also of class <code>'SimDesign'</code>)
with the original <code>design</code> conditions in the left-most columns,
simulation results in the middle columns, and additional information in the right-most columns (see below).
</p>
<p>The right-most column information for each condition are:
<code>REPLICATIONS</code> to indicate the number of Monte Carlo replications,
<code>SIM_TIME</code> to indicate how long (in seconds) it took to complete
all the Monte Carlo replications for each respective design condition,
<code>RAM_USED</code> amount of RAM that was in use at the time of completing
each simulation condition,
<code>COMPLETED</code> to indicate the date in which the given simulation condition completed,
<code>SEED</code> for the integer values in the <code>seed</code> argument, and, if applicable,
<code>ERRORS</code> and <code>WARNINGS</code> which contain counts for the number of error or warning
messages that were caught (if no errors/warnings were observed these columns will be omitted).
Note that to extract the specific error and warnings messages see
<code><a href="#topic+SimExtract">SimExtract</a></code>. Finally,
if <code>boot_method</code> was a valid input other than 'none' then the final right-most
columns will contain the labels
<code>BOOT_</code> followed by the name of the associated meta-statistic defined in <code>summarise()</code> and
and bootstrapped confidence interval location for the meta-statistics.
</p>


<h3>Saving data, results, seeds, and the simulation state</h3>

<p>To conserve RAM, temporary objects (such as data generated across conditions and replications)
are discarded; however, these can be saved to the hard-disk by passing the appropriate flags.
For longer simulations it is recommended to use the <code>save_results</code> flag to write the
analysis results to the hard-drive.
</p>
<p>The use of the <code>save_seeds</code> option can be evoked to save R's <code>.Random.seed</code>
state to allow for complete reproducibility of each replication within each condition. These
individual <code>.Random.seed</code> terms can then be read in with the
<code>load_seed</code> input to reproduce the exact simulation state at any given replication.
Most often though, <code>save_seeds</code> is less useful since problematic seeds are
automatically stored in the final simulation object to allow for easier replicability
of potentially problematic errors (which incidentally can be extracted
using <code>SimExtract(res, 'error_seeds')</code> and passed to the <code>load_seed</code> argument). Finally,
providing a vector of <code>seeds</code> is also possible to ensure
that each simulation condition is macro reproducible under the single/multi-core method selected.
</p>
<p>Finally, when the Monte Carlo simulation is complete
it is recommended to write the results to a hard-drive for safe keeping, particularly with the
<code>filename</code> argument provided (for reasons that are more obvious in the parallel computation
descriptions below). Using the <code>filename</code> argument supplied is safer than using, for instance,
<code><a href="base.html#topic+saveRDS">saveRDS</a></code> directly because files will never accidentally be overwritten,
and instead a new file name will be created when a conflict arises; this type of implementation safety
is prevalent in many locations in the package to help avoid unrecoverable (yet surprisingly
common) mistakes during the process of designing and executing Monte Carlo simulations.
</p>


<h3>Resuming temporary results</h3>

<p>In the event of a computer crash, power outage, etc, if <code>save = TRUE</code> was used (the default)
then the original code used to execute <code>runSimulation()</code> need only be re-run to resume
the simulation. The saved temp file will be read into the function automatically, and the
simulation will continue one the condition where it left off before the simulation
state was terminated. If users wish to remove this temporary
simulation state entirely so as to start anew then simply pass <code>SimClean(temp = TRUE)</code>
in the R console to remove any previously saved temporary objects.
</p>


<h3>A note on parallel computing</h3>

<p>When running simulations in parallel (either with <code>parallel = TRUE</code> or <code>MPI = TRUE</code>,
or when using the <code><a href="future.html#topic+future">future</a></code> approach with a <code>plan()</code> other than sequential)
R objects defined in the global environment will generally <em>not</em> be visible across nodes.
Hence, you may see errors such as <code>Error: object 'something' not found</code> if you try to use
an object that is defined in the work space but is not passed to <code>runSimulation</code>.
To avoid this type or error, simply pass additional objects to the
<code>fixed_objects</code> input (usually it's convenient to supply a named list of these objects).
Fortunately, however, <em>custom functions defined in the global environment are exported across
nodes automatically</em>. This makes it convenient when writing code because custom functions will
always be available across nodes if they are visible in the R work space. As well, note the
<code>packages</code> input to declare packages which must be loaded via <code>library()</code> in order to make
specific non-standard R functions available across nodes.
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SimFunctions">SimFunctions</a></code>, <code><a href="#topic+createDesign">createDesign</a></code>,
<code><a href="#topic+Generate">Generate</a></code>, <code><a href="#topic+Analyse">Analyse</a></code>, <code><a href="#topic+Summarise">Summarise</a></code>,
<code><a href="#topic+SimExtract">SimExtract</a></code>,
<code><a href="#topic+reSummarise">reSummarise</a></code>, <code><a href="#topic+SimClean">SimClean</a></code>, <code><a href="#topic+SimAnova">SimAnova</a></code>, <code><a href="#topic+SimResults">SimResults</a></code>,
<code><a href="#topic+aggregate_simulations">aggregate_simulations</a></code>, <code><a href="#topic+Attach">Attach</a></code>, <code><a href="#topic+AnalyseIf">AnalyseIf</a></code>,
<code><a href="#topic+SimShiny">SimShiny</a></code>, <code><a href="#topic+convertWarnings">convertWarnings</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#-------------------------------------------------------------------------------
# Example 1: Sampling distribution of mean

# This example demonstrate some of the simpler uses of SimDesign,
# particularly for classroom settings. The only factor varied in this simulation
# is sample size.

# skeleton functions to be saved and edited
SimFunctions()

#### Step 1 --- Define your conditions under study and create design data.frame

Design &lt;- createDesign(N = c(10, 20, 30))


#~~~~~~~~~~~~~~~~~~~~~~~~
#### Step 2 --- Define generate, analyse, and summarise functions

# help(Generate)
Generate &lt;- function(condition, fixed_objects = NULL) {
    dat &lt;- with(condition, rnorm(N, 10, 5)) # distributed N(10, 5)
    dat
}

# help(Analyse)
Analyse &lt;- function(condition, dat, fixed_objects = NULL) {
    ret &lt;- c(mean=mean(dat)) # mean of the sample data vector
    ret
}

# help(Summarise)
Summarise &lt;- function(condition, results, fixed_objects = NULL) {
    # mean and SD summary of the sample means
    ret &lt;- c(mu=mean(results$mean), SE=sd(results$mean))
    ret
}


#~~~~~~~~~~~~~~~~~~~~~~~~
#### Step 3 --- Collect results by looping over the rows in design

# run the simulation
Final &lt;- runSimulation(design=Design, replications=10,
                       generate=Generate, analyse=Analyse, summarise=Summarise)
Final

## Not run: 
# reproduce exact simulation
Final_rep &lt;- runSimulation(design=Design, replications=10, seed=Final$SEED,
                       generate=Generate, analyse=Analyse, summarise=Summarise)
Final_rep

# run with more standard number of replications (note the storage message)
Final &lt;- runSimulation(design=Design, replications=1000,
                       generate=Generate, analyse=Analyse, summarise=Summarise)
Final

#~~~~~~~~~~~~~~~~~~~~~~~~
#### Extras
# compare SEs estimates to the true SEs from the formula sigma/sqrt(N)
5 / sqrt(Design$N)

# To store the results from the analyse function either
#   a) omit a definition of summarise() to return all results,
#   b) use store_results = TRUE (default) to store results internally and later
#      extract with SimExtract(..., what = 'results'), or
#   c) pass save_results = TRUE to runSimulation() and read the results in with SimResults()
#
#   Note that method c) should be adopted for larger simulations, particularly
#   if RAM storage could be an issue and error/warning message information is important.

# a) approach
res &lt;- runSimulation(design=Design, replications=5,
                     generate=Generate, analyse=Analyse)
res

# b) approach (store_results = TRUE by default)
res &lt;- runSimulation(design=Design, replications=5,
                     generate=Generate, analyse=Analyse, summarise=Summarise)
res
SimExtract(res, 'results')

# c) approach
Final &lt;- runSimulation(design=Design, replications=5, save_results=TRUE,
                       generate=Generate, analyse=Analyse, summarise=Summarise)

# read-in all conditions (can be memory heavy)
res &lt;- SimResults(Final)
res
head(res[[1]]$results)

# just first condition
res &lt;- SimResults(Final, which=1)
head(res$results)
dplyr::tibble(res$condition, res$results)


# obtain empirical bootstrapped CIs during an initial run
# the simulation was completed (necessarily requires save_results = TRUE)
res &lt;- runSimulation(design=Design, replications=1000, boot_method = 'basic',
                     generate=Generate, analyse=Analyse, summarise=Summarise)
res

# alternative bootstrapped CIs that uses saved results via reSummarise().
# Default directory save to:
dirname &lt;- paste0('SimDesign-results_', unname(Sys.info()['nodename']), "/")
res &lt;- reSummarise(summarise=Summarise, dir=dirname, boot_method = 'basic')
res

# remove the saved results from the hard-drive if you no longer want them
SimClean(results = TRUE)


## End(Not run)


#-------------------------------------------------------------------------------
# Example 2: t-test and Welch test when varying sample size, group sizes, and SDs

# skeleton functions to be saved and edited
SimFunctions()

## Not run: 
# in real-world simulations it's often better/easier to save
# these functions directly to your hard-drive with
SimFunctions('my-simulation')

## End(Not run)

#### Step 1 --- Define your conditions under study and create design data.frame

Design &lt;- createDesign(sample_size = c(30, 60, 90, 120),
                       group_size_ratio = c(1, 4, 8),
                       standard_deviation_ratio = c(.5, 1, 2))
Design

#~~~~~~~~~~~~~~~~~~~~~~~~
#### Step 2 --- Define generate, analyse, and summarise functions

Generate &lt;- function(condition, fixed_objects = NULL) {
    N &lt;- condition$sample_size      # could use Attach() to make objects available
    grs &lt;- condition$group_size_ratio
    sd &lt;- condition$standard_deviation_ratio
    if(grs &lt; 1){
        N2 &lt;- N / (1/grs + 1)
        N1 &lt;- N - N2
    } else {
        N1 &lt;- N / (grs + 1)
        N2 &lt;- N - N1
    }
    group1 &lt;- rnorm(N1)
    group2 &lt;- rnorm(N2, sd=sd)
    dat &lt;- data.frame(group = c(rep('g1', N1), rep('g2', N2)), DV = c(group1, group2))
    dat
}

Analyse &lt;- function(condition, dat, fixed_objects = NULL) {
    welch &lt;- t.test(DV ~ group, dat)$p.value
    independent &lt;- t.test(DV ~ group, dat, var.equal=TRUE)$p.value

    # In this function the p values for the t-tests are returned,
    #  and make sure to name each element, for future reference
    ret &lt;- nc(welch, independent)
    ret
}

Summarise &lt;- function(condition, results, fixed_objects = NULL) {
    #find results of interest here (e.g., alpha &lt; .1, .05, .01)
    ret &lt;- EDR(results, alpha = .05)
    ret
}


#~~~~~~~~~~~~~~~~~~~~~~~~
#### Step 3 --- Collect results by looping over the rows in design

# first, test to see if it works
res &lt;- runSimulation(design=Design, replications=5,
                     generate=Generate, analyse=Analyse, summarise=Summarise)
res

## Not run: 
# complete run with 1000 replications per condition
res &lt;- runSimulation(design=Design, replications=1000, parallel=TRUE,
                     generate=Generate, analyse=Analyse, summarise=Summarise)
res
View(res)

## save final results to a file upon completion, and play a beep when done
runSimulation(design=Design, replications=1000, parallel=TRUE, filename = 'mysim',
              generate=Generate, analyse=Analyse, summarise=Summarise, beep=TRUE)

## same as above, but send a notification via Pushbullet upon completion
library(RPushbullet) # read-in default JSON file
runSimulation(design=Design, replications=1000, parallel=TRUE, filename = 'mysim',
              generate=Generate, analyse=Analyse, summarise=Summarise,
              notification = 'complete')

## Submit as RStudio job (requires job package and active RStudio session)
job::job({
  res &lt;- runSimulation(design=Design, replications=100,
                       generate=Generate, analyse=Analyse, summarise=Summarise)
}, title='t-test simulation')
res  # object res returned to console when completed

## Debug the generate function. See ?browser for help on debugging
##   Type help to see available commands (e.g., n, c, where, ...),
##   ls() to see what has been defined, and type Q to quit the debugger
runSimulation(design=Design, replications=1000,
              generate=Generate, analyse=Analyse, summarise=Summarise,
              parallel=TRUE, debug='generate')

## Alternatively, place a browser() within the desired function line to
##   jump to a specific location
Summarise &lt;- function(condition, results, fixed_objects = NULL) {
    #find results of interest here (e.g., alpha &lt; .1, .05, .01)
    browser()
    ret &lt;- EDR(results[,nms], alpha = .05)
    ret
}

## The following debugs the analyse function for the
## second row of the Design input
runSimulation(design=Design, replications=1000,
              generate=Generate, analyse=Analyse, summarise=Summarise,
              parallel=TRUE, debug='analyse-2')


####################################
## EXTRA: To run the simulation on a MPI cluster, use the following setup (not run)
library(doMPI)
cl &lt;- startMPIcluster()
registerDoMPI(cl)
Final &lt;- runSimulation(design=Design, replications=1000, MPI=TRUE,
                       generate=Generate, analyse=Analyse, summarise=Summarise)
saveRDS(Final, 'mysim.rds')
closeCluster(cl)
mpi.quit()


## Similarly, run simulation on a network linked via ssh
##  (two way ssh key-paired connection must be possible between master and slave nodes)
##
## define IP addresses, including primary IP
primary &lt;- '192.168.2.20'
IPs &lt;- list(
    list(host=primary, user='phil', ncore=8),
    list(host='192.168.2.17', user='phil', ncore=8)
)
spec &lt;- lapply(IPs, function(IP)
                   rep(list(list(host=IP$host, user=IP$user)), IP$ncore))
spec &lt;- unlist(spec, recursive=FALSE)

cl &lt;- parallel::makeCluster(type='PSOCK', master=primary, spec=spec)
res &lt;- runSimulation(design=Design, replications=1000, parallel = TRUE,
                     generate=Generate, analyse=Analyse, summarise=Summarise, cl=cl)


## Using parallel='future' to allow the future framework to be used instead
library(future) # future structure to be used internally
plan(multisession) # specify different plan (default is sequential)

res &lt;- runSimulation(design=Design, replications=100, parallel='future',
                     generate=Generate, analyse=Analyse, summarise=Summarise)
head(res)

# The progressr package is used for progress reporting with futures. To redefine
#  use progressr::handlers() (see below)
library(progressr)
with_progress(res &lt;- runSimulation(design=Design, replications=100, parallel='future',
                     generate=Generate, analyse=Analyse, summarise=Summarise))
head(res)

# re-define progressr's bar (below requires cli)
handlers(handler_pbcol(
   adjust = 1.0,
   complete = function(s) cli::bg_red(cli::col_black(s)),
   incomplete = function(s) cli::bg_cyan(cli::col_black(s))
))

with_progress(res &lt;- runSimulation(design=Design, replications=100, parallel='future',
                     generate=Generate, analyse=Analyse, summarise=Summarise))

# reset future computing plan when complete (good practice)
plan(sequential)

####################################

###### Post-analysis: Analyze the results via functions like lm() or SimAnova(), and create
###### tables(dplyr) or plots (ggplot2) to help visualize the results.
###### This is where you get to be a data analyst!

library(dplyr)
res %&gt;% summarise(mean(welch), mean(independent))
res %&gt;% group_by(standard_deviation_ratio, group_size_ratio) %&gt;%
   summarise(mean(welch), mean(independent))

# quick ANOVA analysis method with all two-way interactions
SimAnova( ~ (sample_size + group_size_ratio + standard_deviation_ratio)^2, res,
  rates = TRUE)

# or more specific ANOVAs
SimAnova(independent ~ (group_size_ratio + standard_deviation_ratio)^2,
    res, rates = TRUE)

# make some plots
library(ggplot2)
library(tidyr)
dd &lt;- res %&gt;%
   select(group_size_ratio, standard_deviation_ratio, welch, independent) %&gt;%
   pivot_longer(cols=c('welch', 'independent'), names_to = 'stats')
dd

ggplot(dd, aes(factor(group_size_ratio), value)) + geom_boxplot() +
    geom_abline(intercept=0.05, slope=0, col = 'red') +
    geom_abline(intercept=0.075, slope=0, col = 'red', linetype='dotted') +
    geom_abline(intercept=0.025, slope=0, col = 'red', linetype='dotted') +
    facet_wrap(~stats)

ggplot(dd, aes(factor(group_size_ratio), value, fill = factor(standard_deviation_ratio))) +
    geom_boxplot() + geom_abline(intercept=0.05, slope=0, col = 'red') +
    geom_abline(intercept=0.075, slope=0, col = 'red', linetype='dotted') +
    geom_abline(intercept=0.025, slope=0, col = 'red', linetype='dotted') +
    facet_grid(stats~standard_deviation_ratio) +
    theme(legend.position = 'none')


## End(Not run)

</code></pre>

<hr>
<h2 id='rValeMaurelli'>Generate non-normal data with Vale &amp; Maurelli's (1983) method</h2><span id='topic+rValeMaurelli'></span>

<h3>Description</h3>

<p>Generate multivariate non-normal distributions using the third-order polynomial method described
by Vale &amp; Maurelli (1983). If only a single variable is generated then this function
is equivalent to the method described by Fleishman (1978).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rValeMaurelli(
  n,
  mean = rep(0, nrow(sigma)),
  sigma = diag(length(mean)),
  skew = rep(0, nrow(sigma)),
  kurt = rep(0, nrow(sigma))
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rValeMaurelli_+3A_n">n</code></td>
<td>
<p>number of samples to draw</p>
</td></tr>
<tr><td><code id="rValeMaurelli_+3A_mean">mean</code></td>
<td>
<p>a vector of k elements for the mean of the variables</p>
</td></tr>
<tr><td><code id="rValeMaurelli_+3A_sigma">sigma</code></td>
<td>
<p>desired k x k covariance matrix between bivariate non-normal variables</p>
</td></tr>
<tr><td><code id="rValeMaurelli_+3A_skew">skew</code></td>
<td>
<p>a vector of k elements for the skewness of the variables</p>
</td></tr>
<tr><td><code id="rValeMaurelli_+3A_kurt">kurt</code></td>
<td>
<p>a vector of k elements for the kurtosis of the variables</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>
<p>Fleishman, A. I. (1978). A method for simulating non-normal distributions.
<em>Psychometrika, 43</em>, 521-532.
</p>
<p>Vale, C. &amp; Maurelli, V. (1983). Simulating multivariate nonnormal distributions.
<em>Psychometrika, 48</em>(3), 465-471.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)

# univariate with skew
nonnormal &lt;- rValeMaurelli(10000, mean=10, sigma=5, skew=1, kurt=3)
# psych::describe(nonnormal)

# multivariate with skew and kurtosis
n &lt;- 10000
r12 &lt;- .4
r13 &lt;- .9
r23 &lt;- .1
cor &lt;- matrix(c(1,r12,r13,r12,1,r23,r13,r23,1),3,3)
sk &lt;- c(1.5,1.5,0.5)
ku &lt;- c(3.75,3.5,0.5)

nonnormal &lt;- rValeMaurelli(n, sigma=cor, skew=sk, kurt=ku)
# cor(nonnormal)
# psych::describe(nonnormal)

</code></pre>

<hr>
<h2 id='Serlin2000'>Empirical detection robustness method suggested by Serlin (2000)</h2><span id='topic+Serlin2000'></span>

<h3>Description</h3>

<p>Hypothesis test to determine whether an observed empirical detection rate,
coupled with a given robustness interval, statistically differs from the
population value. Uses the methods described by Serlin (2000) as well to
generate critical values (similar to confidence intervals, but define a fixed
window of robustness). Critical values may be computed without performing the simulation
experiment (hence, can be obtained a priori).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Serlin2000(p, alpha, delta, R, CI = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Serlin2000_+3A_p">p</code></td>
<td>
<p>(optional) a vector containing the empirical detection rate(s) to be tested.
Omitting this input will compute only the CV1 and CV2 values, while including this
input will perform a one-sided hypothesis test for robustness</p>
</td></tr>
<tr><td><code id="Serlin2000_+3A_alpha">alpha</code></td>
<td>
<p>Type I error rate (e.g., often set to .05)</p>
</td></tr>
<tr><td><code id="Serlin2000_+3A_delta">delta</code></td>
<td>
<p>(optional) symmetric robustness interval around <code>alpha</code> (e.g., a value
of .01 when <code>alpha = .05</code> would test the robustness window .04-.06)</p>
</td></tr>
<tr><td><code id="Serlin2000_+3A_r">R</code></td>
<td>
<p>number of replications used in the simulation</p>
</td></tr>
<tr><td><code id="Serlin2000_+3A_ci">CI</code></td>
<td>
<p>confidence interval for <code>alpha</code> as a proportion. Default of 0.95
indicates a 95% interval</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Serlin, R. C. (2000). Testing for Robustness in Monte Carlo Studies.
<em>Psychological Methods, 5</em>, 230-240.
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Cochran's criteria at alpha = .05 (i.e., 0.5 +- .01), assuming N = 2000
Serlin2000(p = .051, alpha = .05, delta = .01, R = 2000)

# Bradley's liberal criteria given p = .06 and .076, assuming N = 1000
Serlin2000(p = .060, alpha = .05, delta = .025, R = 1000)
Serlin2000(p = .076, alpha = .05, delta = .025, R = 1000)

# multiple p-values
Serlin2000(p = c(.05, .06, .07), alpha = .05, delta = .025, R = 1000)

# CV values computed before simulation performed
Serlin2000(alpha = .05, R = 2500)

</code></pre>

<hr>
<h2 id='SFA'>Surrogate Function Approximation via the Generalized Linear Model</h2><span id='topic+SFA'></span><span id='topic+print.SFA'></span>

<h3>Description</h3>

<p>Given a simulation that was executed with <code><a href="#topic+runSimulation">runSimulation</a></code>,
potentially with the argument <code>store_results = TRUE</code> to store the
unsummarised analysis results, fit a surrogate function approximation (SFA)
model to the results and (optionally) perform a root-solving
step to solve a target quantity. See Schoemann et al. (2014) for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SFA(
  results,
  formula,
  family = "binomial",
  b = NULL,
  design = NULL,
  CI = 0.95,
  interval = NULL,
  ...
)

## S3 method for class 'SFA'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SFA_+3A_results">results</code></td>
<td>
<p>data returned from <code><a href="#topic+runSimulation">runSimulation</a></code>. This can be
the original results object or the extracted results stored when using
<code>store_results = TRUE</code> included to store the analysis results.</p>
</td></tr>
<tr><td><code id="SFA_+3A_formula">formula</code></td>
<td>
<p>formula to specify for the regression model</p>
</td></tr>
<tr><td><code id="SFA_+3A_family">family</code></td>
<td>
<p>character vector indicating the family of GLMs to use
(see <code><a href="stats.html#topic+family">family</a></code>)</p>
</td></tr>
<tr><td><code id="SFA_+3A_b">b</code></td>
<td>
<p>(optional) Target quantity to use for root solving given the fitted
surrogate function (e.g., find sample size associated with SFA implied power of .80)</p>
</td></tr>
<tr><td><code id="SFA_+3A_design">design</code></td>
<td>
<p>(optional) <code>data.frame</code> object containing all the information
relevant for the surrogate model (passed to <code>newdata</code> in
<code><a href="stats.html#topic+predict">predict</a></code>) with an <code>NA</code> value in the variable to be solved</p>
</td></tr>
<tr><td><code id="SFA_+3A_ci">CI</code></td>
<td>
<p>advertised confidence interval of SFA prediction around solved target</p>
</td></tr>
<tr><td><code id="SFA_+3A_interval">interval</code></td>
<td>
<p>interval to be passed to <code><a href="stats.html#topic+uniroot">uniroot</a></code> if not specified then
the lowest and highest values from <code>results</code> for the respective variable
will be used</p>
</td></tr>
<tr><td><code id="SFA_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to <code><a href="stats.html#topic+glm">glm</a></code></p>
</td></tr>
<tr><td><code id="SFA_+3A_x">x</code></td>
<td>
<p>an object of class <code>SFA</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Schoemann, A. M., Miller, P., Pornprasertmanit, S., and Wu, W. (2014).
Using Monte Carlo simulations to determine power and sample size for planned
missing designs. <em>International Journal of Behavioral Development,
SAGE Publications, 38</em>, 471-479.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+runSimulation">runSimulation</a></code>, <code><a href="#topic+SimSolve">SimSolve</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# create long Design object to fit surrogate over
Design &lt;- createDesign(N = 100:500,
                       d = .2)
Design

#~~~~~~~~~~~~~~~~~~~~~~~~
#### Step 2 --- Define generate, analyse, and summarise functions

Generate &lt;- function(condition, fixed_objects = NULL) {
    Attach(condition)
    group1 &lt;- rnorm(N)
    group2 &lt;- rnorm(N, mean=d)
    dat &lt;- data.frame(group = gl(2, N, labels=c('G1', 'G2')),
                      DV = c(group1, group2))
    dat
}

Analyse &lt;- function(condition, dat, fixed_objects = NULL) {
    p &lt;- c(p = t.test(DV ~ group, dat, var.equal=TRUE)$p.value)
    p
}

Summarise &lt;- function(condition, results, fixed_objects = NULL) {
    ret &lt;- EDR(results, alpha = .05)
    ret
}

#~~~~~~~~~~~~~~~~~~~~~~~~
#### Step 3 --- Estimate power over N

# Use small number of replications given range of sample sizes
## note that due to the lower replications disabling the
## RAM printing will help reduce overhead

sim &lt;- runSimulation(design=Design, replications=10,
                     generate=Generate, analyse=Analyse,
                     summarise=Summarise, store_results=TRUE,
                     progress=FALSE, control=list(print_RAM=FALSE))
sim

# total of 4010 replication
sum(sim$REPLICATIONS)

# use the unsummarised results for the SFA, and include p.values &lt; alpha
sim_results &lt;- SimExtract(sim, what = 'results')
sim_results &lt;- within(sim_results, sig &lt;- p &lt; .05)
sim_results

# fitted model
sfa &lt;- SFA(sim_results, formula = sig ~ N)
sfa
summary(sfa)

# plot the observed and SFA expected values
plot(p ~ N, sim, las=1, pch=16, main='Rejection rates with R=10')
pred &lt;- predict(sfa, type = 'response')
lines(sim_results$N, pred, col='red', lty=2)

# fitted model + root-solved solution given f(.) = b,
#   where b = target power of .8
design &lt;- data.frame(N=NA, d=.2)
sfa.root &lt;- SFA(sim_results, formula = sig ~ N,
                b=.8, design=design)
sfa.root

# true root
pwr::pwr.t.test(power=.8, d=.2)


################
# example with smaller range but higher precision
Design &lt;- createDesign(N = 375:425,
                       d = .2)
Design

sim2 &lt;- runSimulation(design=Design, replications=100,
                     generate=Generate, analyse=Analyse,
                     summarise=Summarise, store_results=TRUE,
                     progress=FALSE, control=list(print_RAM=FALSE))
sim2
sum(sim2$REPLICATIONS) # more replications in total

# use the unsummarised results for the SFA, and include p.values &lt; alpha
sim_results &lt;- SimExtract(sim2, what = 'results')
sim_results &lt;- within(sim_results, sig &lt;- p &lt; .05)
sim_results

# fitted model
sfa &lt;- SFA(sim_results, formula = sig ~ N)
sfa
summary(sfa)

# plot the observed and SFA expected values
plot(p ~ N, sim2, las=1, pch=16, main='Rejection rates with R=100')
pred &lt;- predict(sfa, type = 'response')
lines(sim_results$N, pred, col='red', lty=2)

# fitted model + root-solved solution given f(.) = b,
#   where b = target power of .8
design &lt;- data.frame(N=NA, d=.2)
sfa.root &lt;- SFA(sim_results, formula = sig ~ N,
                b=.8, design=design, interval=c(100, 500))
sfa.root

# true root
pwr::pwr.t.test(power=.8, d=.2)

###################
# vary multiple parameters (e.g., sample size + effect size) to fit
# multi-parameter surrogate

Design &lt;- createDesign(N = seq(from=10, to=500, by=10),
                       d = seq(from=.1, to=.5, by=.1))
Design

sim3 &lt;- runSimulation(design=Design, replications=50,
                      generate=Generate, analyse=Analyse,
                      summarise=Summarise, store_results=TRUE,
                      progress=FALSE, control=list(print_RAM=FALSE))
sim3
sum(sim3$REPLICATIONS)

# use the unsummarised results for the SFA, and include p.values &lt; alpha
sim_results &lt;- SimExtract(sim3, what = 'results')
sim_results &lt;- within(sim_results, sig &lt;- p &lt; .05)
sim_results

# additive effects (logit(sig) ~ N + d)
sfa0 &lt;- SFA(sim_results, formula = sig ~ N+d)
sfa0

# multiplicative effects (logit(sig) ~ N + d + N:d)
sfa &lt;- SFA(sim_results, formula = sig ~ N*d)
sfa

# multiplicative better fit (sample size interacts with effect size)
anova(sfa0, sfa, test = "LRT")
summary(sfa)

# plot the observed and SFA expected values
library(ggplot2)
sim3$pred &lt;- predict(sfa, type = 'response', newdata=sim3)
ggplot(sim3, aes(N, p, color = factor(d))) +
  geom_point() + geom_line(aes(y=pred)) +
  facet_wrap(~factor(d))

# fitted model + root-solved solution given f(.) = b,
#   where b = target power of .8
design &lt;- data.frame(N=NA, d=.2)
sfa.root &lt;- SFA(sim_results, formula = sig ~ N * d,
                b=.8, design=design, interval=c(100, 500))
sfa.root

# true root
pwr::pwr.t.test(power=.8, d=.2)

# root prediction where d *not* used in original data
design &lt;- data.frame(N=NA, d=.25)
sfa.root &lt;- SFA(sim_results, formula = sig ~ N * d,
                b=.8, design=design, interval=c(100, 500))
sfa.root

# true root
pwr::pwr.t.test(power=.8, d=.25)


## End(Not run)

</code></pre>

<hr>
<h2 id='SimAnova'>Function for decomposing the simulation into ANOVA-based effect sizes</h2><span id='topic+SimAnova'></span>

<h3>Description</h3>

<p>Given the results from a simulation with <code><a href="#topic+runSimulation">runSimulation</a></code> form an ANOVA table (without
p-values) with effect sizes based on the eta-squared statistic. These results provide approximate
indications of observable simulation effects, therefore these ANOVA-based results are generally useful
as exploratory rather than inferential tools.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SimAnova(formula, dat, subset = NULL, rates = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SimAnova_+3A_formula">formula</code></td>
<td>
<p>an R formula generally of a form suitable for <code><a href="stats.html#topic+lm">lm</a></code> or
<code><a href="stats.html#topic+aov">aov</a></code>. However, if the dependent variable (left size of the equation) is omitted
then all the dependent variables in the simulation will be used and the result will return
a list of analyses</p>
</td></tr>
<tr><td><code id="SimAnova_+3A_dat">dat</code></td>
<td>
<p>an object returned from <code><a href="#topic+runSimulation">runSimulation</a></code> of class <code>'SimDesign'</code></p>
</td></tr>
<tr><td><code id="SimAnova_+3A_subset">subset</code></td>
<td>
<p>an optional argument to be passed to <code><a href="base.html#topic+subset">subset</a></code> with the same name. Used to
subset the results object while preserving the associated attributes</p>
</td></tr>
<tr><td><code id="SimAnova_+3A_rates">rates</code></td>
<td>
<p>logical; does the dependent variable consist of rates (e.g., returned from
<code><a href="#topic+ECR">ECR</a></code> or <code><a href="#topic+EDR">EDR</a></code>)? Default is TRUE, which will use the logit of the DV
to help stabilize the proportion-based summary statistics when computing the parameters and
effect sizes</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(BF_sim)

# all results (not usually good to mix Power and Type I results together)
SimAnova(alpha.05.F ~ (groups_equal + distribution)^2, BF_sim)

# only use anova for Type I error conditions
SimAnova(alpha.05.F ~ (groups_equal + distribution)^2, BF_sim, subset = var_ratio == 1)

# run all DVs at once using the same formula
SimAnova(~ groups_equal * distribution, BF_sim, subset = var_ratio == 1)

</code></pre>

<hr>
<h2 id='SimCheck'>Check the status of the simulation's temporary results</h2><span id='topic+SimCheck'></span>

<h3>Description</h3>

<p>This function reads the temporary file saved by <code><a href="#topic+runSimulation">runSimulation</a></code>
by collapsing the information into a suitable (albeit temporary) object of
class <code>'SimDesign'</code>. This is useful when taking a quick-peak at how the
early simulation results are performing (useful long running simulation
results with many rows in the <code>Design</code> object). Returns a tibble-based
data.frame object (<code>tbl_df</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SimCheck(file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SimCheck_+3A_file">file</code></td>
<td>
<p>the temp file currently saving the simulation state. If missing
the file is assumed to be in the current working directory, and start with the
name <code>'SIMDESIGN-TEMPFILE'</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+runSimulation">runSimulation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# explicit
temp_results &lt;- SimCheck(file = 'SIMDESIGN-TEMPFILE_mycomp.rds')
temp_results

# works if file is in the current working directory
temp_results &lt;- SimCheck()
temp_results


## End(Not run)

</code></pre>

<hr>
<h2 id='SimClean'>Removes/cleans files and folders that have been saved</h2><span id='topic+SimClean'></span>

<h3>Description</h3>

<p>This function is mainly used in pilot studies where results and datasets have been temporarily saved
by <code><a href="#topic+runSimulation">runSimulation</a></code> but should be removed before beginning the full
Monte Carlo simulation (e.g., remove files and folders which contained bugs/biased results).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SimClean(
  ...,
  dirs = NULL,
  temp = TRUE,
  results = FALSE,
  seeds = FALSE,
  save_details = list()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SimClean_+3A_...">...</code></td>
<td>
<p>one or more character objects indicating which files to remove. Used to remove
<code>.rds</code> files which were saved with <code><a href="base.html#topic+saveRDS">saveRDS</a></code> or when using the <code>save</code>
and <code>filename</code> inputs to <code><a href="#topic+runSimulation">runSimulation</a></code></p>
</td></tr>
<tr><td><code id="SimClean_+3A_dirs">dirs</code></td>
<td>
<p>a character vector indicating which directories to remove</p>
</td></tr>
<tr><td><code id="SimClean_+3A_temp">temp</code></td>
<td>
<p>logical; remove the temporary file saved when passing <code>save = TRUE</code>?</p>
</td></tr>
<tr><td><code id="SimClean_+3A_results">results</code></td>
<td>
<p>logical; remove the <code>.rds</code> results files
saved when passing <code>save_results = TRUE</code>?</p>
</td></tr>
<tr><td><code id="SimClean_+3A_seeds">seeds</code></td>
<td>
<p>logical; remove the seed files
saved when passing <code>save_seeds = TRUE</code>?</p>
</td></tr>
<tr><td><code id="SimClean_+3A_save_details">save_details</code></td>
<td>
<p>a list pertaining to information about how and where files were saved
(see the corresponding list in <code><a href="#topic+runSimulation">runSimulation</a></code>)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+runSimulation">runSimulation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# remove file called 'results.rds'
SimClean('results.rds')

# remove default temp file
SimClean()

# remove customized saved-results directory called 'mydir'
SimClean(results = TRUE, save_details = list(save_results_dirname = 'mydir'))


## End(Not run)
</code></pre>

<hr>
<h2 id='SimExtract'>Function to extract extra information from SimDesign objects</h2><span id='topic+SimExtract'></span>

<h3>Description</h3>

<p>Function used to extract any error or warnings messages, the seeds associated
with any error or warning messages, and any analysis results that were stored in the
final simulation object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SimExtract(object, what, fuzzy = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SimExtract_+3A_object">object</code></td>
<td>
<p>object returned from <code><a href="#topic+runSimulation">runSimulation</a></code></p>
</td></tr>
<tr><td><code id="SimExtract_+3A_what">what</code></td>
<td>
<p>character indicating what information to extract. Possible inputs
include <code>'errors'</code> to return a <code>tibble</code> object containing counts of any
error messages, <code>'warnings'</code> to return a <code>data.frame</code> object containing
counts of any warning messages, <code>'error_seeds'</code> and <code>'warning_seeds'</code>
to extract the associated <code>.Random.seed</code> values associated with the ERROR/WARNING messages,
<code>'results'</code> to extract the simulation results if the option <code>store_results</code> was passed to
<code><a href="#topic+runSimulation">runSimulation</a></code>, <code>'filename'</code> and <code>'save_results_dirname'</code> for extracting
the saved file/directory name information (if used),
and <code>'summarise'</code> if the <code><a href="#topic+Summarise">Summarise</a></code>
definition returned a named <code>list</code> rather than a named numeric vector.
</p>
<p>Note that <code>'warning_seeds'</code> are not stored automatically in
simulations and require passing <code>store_warning_seeds = TRUE</code> to <code><a href="#topic+runSimulation">runSimulation</a></code>.</p>
</td></tr>
<tr><td><code id="SimExtract_+3A_fuzzy">fuzzy</code></td>
<td>
<p>logical; use fuzzy string matching to reduce effectively identical messages?
For example, when attempting to invert a matrix the error message
<em>&quot;System is computationally singular: reciprocal condition number = 1.92747e-17&quot;</em> and
<em>&quot;System is computationally singular: reciprocal condition number = 2.15321e-16&quot;</em> are
effectively the same, and likely should be reported in the same columns of the extracted output</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

Generate &lt;- function(condition, fixed_objects = NULL) {
    int &lt;- sample(1:10, 1)
    if(int &gt; 5) warning('GENERATE WARNING: int greater than 5')
    if(int == 1) stop('GENERATE WARNING: integer is 1')
    rnorm(5)
}

Analyse &lt;- function(condition, dat, fixed_objects = NULL) {
    int &lt;- sample(1:10, 1)
    if(int &gt; 5) warning('ANALYSE WARNING: int greater than 5')
    if(int == 1) stop('ANALYSE WARNING: int is 1')
    c(ret = 1)
}

Summarise &lt;- function(condition, results, fixed_objects = NULL) {
    mean(results)
}

res &lt;- runSimulation(replications = 100, seed=1234, verbose=FALSE,
                     generate=Generate, analyse=Analyse, summarise=Summarise)
res

SimExtract(res, what = 'errors')
SimExtract(res, what = 'warnings')
seeds &lt;- SimExtract(res, what = 'error_seeds')
seeds[,1:3]

# replicate a specific error for debugging (type Q to exit debugger)
res &lt;- runSimulation(replications = 100, load_seed=seeds[,1], debug='analyse',
                     generate=Generate, analyse=Analyse, summarise=Summarise)




## End(Not run)
</code></pre>

<hr>
<h2 id='SimFunctions'>Template-based generation of the Generate-Analyse-Summarise functions</h2><span id='topic+SimFunctions'></span>

<h3>Description</h3>

<p>This function prints template versions of the required <code>Design</code> and Generate-Analyse-Summarise functions
for <code>SimDesign</code> to run simulations. Templated output comes complete with the correct inputs,
class of outputs, and optional comments to help with the initial definitions.
Use this at the start of your Monte Carlo simulation study. Following
the definition of the <code>SimDesign</code> template file please refer to detailed the information
in <code><a href="#topic+runSimulation">runSimulation</a></code> for how to edit this template to make a working simulation study.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SimFunctions(
  filename = NULL,
  dir = getwd(),
  save_structure = "single",
  extra_file = FALSE,
  nAnalyses = 1,
  nGenerate = 1,
  summarise = TRUE,
  comments = FALSE,
  openFiles = TRUE,
  spin_header = TRUE,
  SimSolve = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SimFunctions_+3A_filename">filename</code></td>
<td>
<p>a character vector indicating whether the output should be saved to two respective files
containing the simulation design and the functional components, respectively. Using this option
is generally the recommended approach when beginning to write a Monte Carlo simulation</p>
</td></tr>
<tr><td><code id="SimFunctions_+3A_dir">dir</code></td>
<td>
<p>the directory to write the files to. Default is the working directory</p>
</td></tr>
<tr><td><code id="SimFunctions_+3A_save_structure">save_structure</code></td>
<td>
<p>character indicating the number of files to break the simulation code into
when <code>filename</code> is included (default is 'single' for one file). When <code>save_structure = 'double'</code> the
output is saved to two separate files containing the functions and design definitions,
and when <code>save_structure = 'all'</code> the generate, analyse, summarise, and execution code area all saved into
separate files. The purpose for this structure is because multiple structured files
often makes organization and debugging slightly easier larger Monte Carlo simulations, though in principle
all files could be stored into a single R script</p>
</td></tr>
<tr><td><code id="SimFunctions_+3A_extra_file">extra_file</code></td>
<td>
<p>logical; should and extra file be saved containing user-defined functions or objects?
Default is <code>FALSE</code></p>
</td></tr>
<tr><td><code id="SimFunctions_+3A_nanalyses">nAnalyses</code></td>
<td>
<p>number of analysis functions to create (default is 1). Increasing the value
of this argument when independent analysis are being performed allows function definitions
to be better partitioned and potentially more modular</p>
</td></tr>
<tr><td><code id="SimFunctions_+3A_ngenerate">nGenerate</code></td>
<td>
<p>number of generate functions to create (default is 1). Increase the value
of this argument when when the data generation functions are very different and should
be isolated from each other (otherwise, if there is much in common between the generate
steps, the default of 1 should be preferred). Otherwise, if <code>nGenerate == 0</code>
then no generate function will be provided and instead this data-generation
step can be defined in the analysis function(s) (only recommended for smaller simulations)</p>
</td></tr>
<tr><td><code id="SimFunctions_+3A_summarise">summarise</code></td>
<td>
<p>include <code>summarise</code> function? Default is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="SimFunctions_+3A_comments">comments</code></td>
<td>
<p>logical; include helpful comments? Default is <code>FALSE</code></p>
</td></tr>
<tr><td><code id="SimFunctions_+3A_openfiles">openFiles</code></td>
<td>
<p>logical; after files have been generated, open them in your text editor
(e.g., if Rstudio is running the scripts will open in a new tab)?</p>
</td></tr>
<tr><td><code id="SimFunctions_+3A_spin_header">spin_header</code></td>
<td>
<p>logical; include a basic <code>knitr::spin</code> header to allow the simulation
to be knitted? Default is <code>TRUE</code>. For those less familiar with <code>spin</code> documents
see <code>https://bookdown.org/yihui/rmarkdown-cookbook/spin.html</code> for further details</p>
</td></tr>
<tr><td><code id="SimFunctions_+3A_simsolve">SimSolve</code></td>
<td>
<p>logical; should the template be generated that is intended for a
<code><a href="#topic+SimSolve">SimSolve</a></code> implementation? Default is <code>FALSE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The recommended approach to organizing Monte Carlo simulation files is to first save the template generated
by this function to the hard-drive by passing a suitable <code>filename</code> argument
(which, if users are interacting
with R via the RStudio IDE, will also open the template file after it has been saved).
For larger simulations, two
separate files could also be used (achieved by changing <code>out.files</code>),
and may be easier for debugging/sourcing the simulation code; however, this is a
matter of preference and does not change any functionality in the package.
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+runSimulation">runSimulation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
SimFunctions()
SimFunctions(comments = TRUE) #with helpful comments

## Not run: 

# write output files to a single file with comments
SimFunctions('mysim', comments = TRUE)

# Multiple analysis functions for optional partitioning
SimFunctions(nAnalyses = 2)
SimFunctions(nAnalyses = 3)

# Multiple analysis + generate functions
SimFunctions(nAnalyses = 2, nGenerate=2)

# save multiple files for the purpose of designing larger simulations
#  (also include extra_file for user-defined objects/functions)
SimFunctions('myBigSim', save_structure = 'all',
   nAnalyses = 3, nGenerate=2, extra_file = TRUE)



## End(Not run)

</code></pre>

<hr>
<h2 id='SimResults'>Function to read in saved simulation results</h2><span id='topic+SimResults'></span>

<h3>Description</h3>

<p>If <code><a href="#topic+runSimulation">runSimulation</a></code> was passed the flag <code>save_results = TRUE</code> then the
row results corresponding to the <code>design</code> object will be stored to a suitable
sub-directory as individual <code>.rds</code> files. While users could use <code><a href="base.html#topic+readRDS">readRDS</a></code> directly
to read these files in themselves, this convenience function will read the desired rows in
automatically given the returned object
from the simulation. Can be used to read in 1 or more <code>.rds</code> files at once (if more than 1 file
is read in then the result will be stored in a list).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SimResults(results, which, prefix = "results-row", wd = getwd())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SimResults_+3A_results">results</code></td>
<td>
<p>object returned from <code><a href="#topic+runSimulation">runSimulation</a></code> where <code>save_results = TRUE</code>
was used</p>
</td></tr>
<tr><td><code id="SimResults_+3A_which">which</code></td>
<td>
<p>a numeric vector indicating which rows should be read in. If missing, all rows will be
read in</p>
</td></tr>
<tr><td><code id="SimResults_+3A_prefix">prefix</code></td>
<td>
<p>character indicating prefix used for stored files</p>
</td></tr>
<tr><td><code id="SimResults_+3A_wd">wd</code></td>
<td>
<p>working directory; default is found with <code><a href="base.html#topic+getwd">getwd</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the returned result is either a nested list (when <code>length(which) &gt; 1</code>) or a single list
(when <code>length(which) == 1</code>) containing the simulation results. Each read-in result refers to
a list of 4 elements:
</p>

<dl>
<dt><code>condition</code></dt><dd><p>the associate row (ID) and conditions from the
respective <code>design</code> object</p>
</dd>
<dt><code>results</code></dt><dd><p>the object with returned from the <code>analyse</code> function, potentially
simplified into a matrix or data.frame</p>
</dd>
<dt><code>errors</code></dt><dd><p>a table containing the message and number of errors that caused
the generate-analyse steps to be rerun. These should be inspected carefully as they
could indicate validity issues with the simulation that should be noted</p>
</dd>
<dt><code>warnings</code></dt><dd><p>a table containing the message and number of non-fatal warnings
which arose from the analyse step. These should be inspected carefully as they
could indicate validity issues with the simulation that should be noted</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

results &lt;- runSimulation(..., save_results = TRUE)

# row 1 results
row1 &lt;- SimResults(results, 1)

# rows 1:5, stored in a named list
rows_1to5 &lt;- SimResults(results, 1:5)

# all results
rows_all &lt;- SimResults(results)


## End(Not run)
</code></pre>

<hr>
<h2 id='SimShiny'>Generate a basic Monte Carlo simulation GUI template</h2><span id='topic+SimShiny'></span>

<h3>Description</h3>

<p>This function generates suitable stand-alone code from the <code>shiny</code> package to create simple
web-interfaces for performing single condition Monte Carlo simulations. The template
generated is relatively minimalistic, but allows the user to quickly and easily
edit the saved files to customize the associated shiny elements as they see fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SimShiny(filename = NULL, dir = getwd(), design, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SimShiny_+3A_filename">filename</code></td>
<td>
<p>an optional name of a text file to save the server and UI components
(e.g., 'mysimGUI.R'). If omitted, the code will be printed to the R console instead</p>
</td></tr>
<tr><td><code id="SimShiny_+3A_dir">dir</code></td>
<td>
<p>the directory to write the files to. Default is the working directory</p>
</td></tr>
<tr><td><code id="SimShiny_+3A_design">design</code></td>
<td>
<p><code>design</code> object from <code><a href="#topic+runSimulation">runSimulation</a></code></p>
</td></tr>
<tr><td><code id="SimShiny_+3A_...">...</code></td>
<td>
<p>arguments to be passed to <code><a href="#topic+runSimulation">runSimulation</a></code>. Note that the
<code>design</code> object is not used directly, and instead provides options to be
selected in the GUI</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+runSimulation">runSimulation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

Design &lt;- createDesign(sample_size = c(30, 60, 90, 120),
                       group_size_ratio = c(1, 4, 8),
                       standard_deviation_ratio = c(.5, 1, 2))

Generate &lt;- function(condition, fixed_objects = NULL) {
    N &lt;- condition$sample_size
    grs &lt;- condition$group_size_ratio
    sd &lt;- condition$standard_deviation_ratio
    if(grs &lt; 1){
        N2 &lt;- N / (1/grs + 1)
        N1 &lt;- N - N2
    } else {
        N1 &lt;- N / (grs + 1)
        N2 &lt;- N - N1
    }
    group1 &lt;- rnorm(N1)
    group2 &lt;- rnorm(N2, sd=sd)
    dat &lt;- data.frame(group = c(rep('g1', N1), rep('g2', N2)), DV = c(group1, group2))
    dat
}

Analyse &lt;- function(condition, dat, fixed_objects = NULL) {
    welch &lt;- t.test(DV ~ group, dat)
    ind &lt;- t.test(DV ~ group, dat, var.equal=TRUE)

    # In this function the p values for the t-tests are returned,
    #  and make sure to name each element, for future reference
    ret &lt;- c(welch = welch$p.value, independent = ind$p.value)
    ret
}

Summarise &lt;- function(condition, results, fixed_objects = NULL) {
    #find results of interest here (e.g., alpha &lt; .1, .05, .01)
    ret &lt;- EDR(results, alpha = .05)
    ret
}

# test that it works
# Final &lt;- runSimulation(design=Design, replications=5,
#                       generate=Generate, analyse=Analyse, summarise=Summarise)

# print code to console
SimShiny(design=Design, generate=Generate, analyse=Analyse,
         summarise=Summarise, verbose=FALSE)

# save shiny code to file
SimShiny('app.R', design=Design, generate=Generate, analyse=Analyse,
         summarise=Summarise, verbose=FALSE)

# run the application
shiny::runApp()
shiny::runApp(launch.browser = TRUE) # in web-browser


## End(Not run)
</code></pre>

<hr>
<h2 id='SimSolve'>One Dimensional Root (Zero) Finding in Simulation Experiments</h2><span id='topic+SimSolve'></span><span id='topic+summary.SimSolve'></span><span id='topic+plot.SimSolve'></span>

<h3>Description</h3>

<p>This function provides a stochastic root-finding approach to solving
specific quantities in simulation experiments (e.g., solving for a specific
sample size to meet a target power rate) using the
Probablistic Bisection Algorithm with Bolstering and Interpolations
(ProBABLI; Chalmers, in review). The structure follows the
steps outlined in <code><a href="#topic+runSimulation">runSimulation</a></code>, however portions of
the <code>design</code> input are taken as variables to be estimated rather than
fixed, and the constant <code>b</code> is required in order to
solve the root equation <code>f(x) - b = 0</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SimSolve(
  design,
  interval,
  b,
  generate,
  analyse,
  summarise,
  replications = list(burnin.iter = 15L, burnin.reps = 100L, max.reps = 500L,
    min.total.reps = 9000L, increase.by = 10L),
  integer = TRUE,
  formula = y ~ poly(x, 2),
  family = "binomial",
  parallel = FALSE,
  cl = NULL,
  save = TRUE,
  resume = TRUE,
  method = "ProBABLI",
  wait.time = NULL,
  ncores = parallel::detectCores() - 1L,
  type = ifelse(.Platform$OS.type == "windows", "PSOCK", "FORK"),
  maxiter = 100L,
  check.interval = TRUE,
  verbose = TRUE,
  control = list(),
  predCI = 0.95,
  ...
)

## S3 method for class 'SimSolve'
summary(object, tab.only = FALSE, reps.cutoff = 300, ...)

## S3 method for class 'SimSolve'
plot(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SimSolve_+3A_design">design</code></td>
<td>
<p>a <code>tibble</code> or <code>data.frame</code> object containing
the Monte Carlo simulation conditions to be studied, where each row
represents a unique condition and each column a factor  to be varied
(see also <code><a href="#topic+createDesign">createDesign</a></code>). However, exactly one column of this
object must be specified with <code>NA</code> placeholders to indicate
that the missing value should be solved via the stochastic optimizer</p>
</td></tr>
<tr><td><code id="SimSolve_+3A_interval">interval</code></td>
<td>
<p>a vector of length two, or matrix with <code>nrow(design)</code>
and two columns, containing the end-points of the interval to be searched.
If a vector then the interval will be used for all rows in the supplied
<code>design</code> object</p>
</td></tr>
<tr><td><code id="SimSolve_+3A_b">b</code></td>
<td>
<p>a single constant used to solve the root equation <code>f(x) - b = 0</code></p>
</td></tr>
<tr><td><code id="SimSolve_+3A_generate">generate</code></td>
<td>
<p>generate function. See <code><a href="#topic+runSimulation">runSimulation</a></code></p>
</td></tr>
<tr><td><code id="SimSolve_+3A_analyse">analyse</code></td>
<td>
<p>analysis function. See <code><a href="#topic+runSimulation">runSimulation</a></code></p>
</td></tr>
<tr><td><code id="SimSolve_+3A_summarise">summarise</code></td>
<td>
<p>summary function that returns a single number corresponding
to a function evaluation <code>f(x)</code> in the equation
<code>f(x) = b</code> to be solved as a root <code>f(x) - b = 0</code>.
Unlike in the standard <code>runSimulation()</code> definitions this input
is required. For further information on this function specification,
see <code><a href="#topic+runSimulation">runSimulation</a></code></p>
</td></tr>
<tr><td><code id="SimSolve_+3A_replications">replications</code></td>
<td>
<p>a named list or vector indicating the number of replication to
use for each design condition per PBA iteration. By default the input is a
<code>list</code> with the arguments <code>burnin.iter = 15L</code>, specifying the number
of burn-in iterations to used, <code>burnin.reps = 100L</code> to indicate how many
replications to use in each burn-in iteration, <code>max.reps = 500L</code> to
prevent the replications from increasing higher than this number,
<code>min.total.reps = 9000L</code> to avoid termination when very few replications
have been explored (lower bound of the replication budget),
and <code>increase.by = 10L</code> to indicate how many replications to increase
after the burn-in stage. Unless otherwise specified these defaults will
be used, but can be overwritten by explicit definition (e.g.,
<code>replications = list(increase.by = 25L)</code>)
</p>
<p>Vector inputs can specify the exact replications
for each iterations. As a general rule, early iterations
should be relatively low for initial searches to avoid unnecessary computations
for locating the approximate root, though the number of replications should
gradually increase to reduce the sampling variability as the PBA approaches
the root.</p>
</td></tr>
<tr><td><code id="SimSolve_+3A_integer">integer</code></td>
<td>
<p>logical; should the values of the root be considered integer
or numeric? If <code>TRUE</code> then bolstered directional decisions will be
made in the <code>pba</code> function based on the collected sampling history
throughout the search</p>
</td></tr>
<tr><td><code id="SimSolve_+3A_formula">formula</code></td>
<td>
<p>regression formula to use when <code>interpolate = TRUE</code>. Default
fits an orthogonal polynomial of degree 2</p>
</td></tr>
<tr><td><code id="SimSolve_+3A_family">family</code></td>
<td>
<p><code>family</code> argument passed to <code><a href="stats.html#topic+glm">glm</a></code>. By default
the <code>'binomial'</code> family is used, as this function defaults to power
analysis setups where isolated results passed to <code>summarise</code> will
return 0/1s, however other families should be used had <code>summarise</code>
returned something else (e.g., if solving for a particular standard error
then a <code>'gaussian'</code> family would be more appropriate).
</p>
<p>Note that if individual  results from the <code>analyse</code> steps should
not be used (i.e., only the aggregate from <code>summarise</code> is meaningful)
then set <code>control = list(summarise.reg_data = TRUE)</code> to override the default
behaviour, thereby using only the aggregate information and weights</p>
</td></tr>
<tr><td><code id="SimSolve_+3A_parallel">parallel</code></td>
<td>
<p>for parallel computing for slower simulation experiments
(see <code><a href="#topic+runSimulation">runSimulation</a></code> for details)</p>
</td></tr>
<tr><td><code id="SimSolve_+3A_cl">cl</code></td>
<td>
<p>see <code><a href="#topic+runSimulation">runSimulation</a></code></p>
</td></tr>
<tr><td><code id="SimSolve_+3A_save">save</code></td>
<td>
<p>logical; store temporary file in case of crashes. If detected
in the working directory will automatically be loaded to resume (see
<code><a href="#topic+runSimulation">runSimulation</a></code> for similar behaviour)</p>
</td></tr>
<tr><td><code id="SimSolve_+3A_resume">resume</code></td>
<td>
<p>logical; if a temporary <code>SimDesign</code> file is detected should
the simulation resume from this location? Keeping this <code>TRUE</code> is generally
recommended, however this should be disabled
if using <code>SimSolve</code> within <code><a href="#topic+runSimulation">runSimulation</a></code> to avoid
reading improper save states</p>
</td></tr>
<tr><td><code id="SimSolve_+3A_method">method</code></td>
<td>
<p>optimizer method to use. Default is the stochastic root-finder
<code>'ProBABLI'</code>, but can also be the deterministic options <code>'Brent'</code>
(which uses the function <code><a href="stats.html#topic+uniroot">uniroot</a></code>) or <code>'bisection'</code>
(for the classical bisection method). If using deterministic root-finders then
<code>replications</code> must either equal a single constant to reflect
the number of replication to use per deterministic iteration or be a
vector of length <code>maxiter</code> to indicate the replications to use per
iteration</p>
</td></tr>
<tr><td><code id="SimSolve_+3A_wait.time">wait.time</code></td>
<td>
<p>(optional) argument passed to <code><a href="#topic+PBA">PBA</a></code> to indicate
the time to wait (specified in minutes) per row in the <code>Design</code> object
rather than using pre-determined termination criteria based on the estimates.
For example, if three three conditions were defined in
<code>Design</code>, and <code>wait.time=5</code>,
then the total search time till terminate after 15 minutes regardless of
independently specified termination criteria in <code>control</code>. Note that
<code>maxiter</code> is still used alongside <code>wait.time</code>, therefore this should
be increased as well (e.g., to <code>maxiter = 1000</code>)
</p>

<dl>
<dt><code>tol</code></dt><dd><p>tolerance criteria for early termination (.1 for
<code>integer = TRUE</code> searches; .00025 for non-integer searches</p>
</dd>
<dt><code>rel.tol</code></dt><dd><p>relative tolerance criteria for early termination (default .0001)</p>
</dd>
<dt><code>k.success</code></dt><dd><p>number of consecutive tolerance success given <code>rel.tol</code> and
<code>tol</code> criteria. Consecutive failures add -1 to the counter (default is 3)</p>
</dd>
<dt><code>bolster</code></dt><dd><p>logical; should the PBA evaluations use bolstering based on previous
evaluations? Default is <code>TRUE</code>, though only applicable when <code>integer = TRUE</code> </p>
</dd>
<dt><code>interpolate.R</code></dt><dd><p>number of replications to collect prior to performing
the interpolation step (default is 3000 after accounting for data exclusion
from <code>burnin.iter</code>). Setting this to 0 will disable any
interpolation computations</p>
</dd>
<dt><code>include_reps</code></dt><dd><p>logical; include a column in the <code>condition</code>
elements to indicate how many replications are currently being evaluated? Mainly
useful when further precision tuning within each ProBABLI iteration is
desirable (e.g., for bootstrapping). Default is <code>FALSE</code></p>
</dd>
<dt><code>summarise.reg_data</code></dt><dd><p>logical; should the aggregate results from <code>Summarise</code>
(along with its associated weights) be used for the interpolation steps, or the
raw data from the <code>Analyse</code> step? Set this to <code>TRUE</code> when the individual
results from <code>Analyse</code> give less meaningful information</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="SimSolve_+3A_ncores">ncores</code></td>
<td>
<p>see <code><a href="#topic+runSimulation">runSimulation</a></code></p>
</td></tr>
<tr><td><code id="SimSolve_+3A_type">type</code></td>
<td>
<p>type of cluster object to define. If <code>type</code> used in <code>plot</code>
then can be <code>'density'</code> to plot the density of the iteration history
after the burn-in stage, <code>'iterations'</code> for a bubble plot with inverse
replication weights. If not specified then the default PBA
plots are provided (see <code><a href="#topic+PBA">PBA</a></code>)</p>
</td></tr>
<tr><td><code id="SimSolve_+3A_maxiter">maxiter</code></td>
<td>
<p>the maximum number of iterations (default 100)</p>
</td></tr>
<tr><td><code id="SimSolve_+3A_check.interval">check.interval</code></td>
<td>
<p>logical; should an initial check be made to determine
whether <code>f(interval[1L])</code> and <code>f(interval[2L])</code> have opposite
signs? If <code>FALSE</code>, the specified <code>interval</code> is assumed to contain a root,
where <code>f(interval[1]) &lt; 0</code> and <code>f(interval[2] &gt; 0</code>. Default is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="SimSolve_+3A_verbose">verbose</code></td>
<td>
<p>logical; print information to the console?</p>
</td></tr>
<tr><td><code id="SimSolve_+3A_control">control</code></td>
<td>
<p>a <code>list</code> of the algorithm control parameters. If not specified,
the defaults described below are used.</p>
</td></tr>
<tr><td><code id="SimSolve_+3A_predci">predCI</code></td>
<td>
<p>advertised confidence interval probability for final
model-based prediction of target <code>b</code> given the root input estimate.
Returned as an element in the <code>summary()</code> list output</p>
</td></tr>
<tr><td><code id="SimSolve_+3A_...">...</code></td>
<td>
<p>additional arguments to be pasted to <code><a href="#topic+PBA">PBA</a></code></p>
</td></tr>
<tr><td><code id="SimSolve_+3A_object">object</code></td>
<td>
<p>object of class <code>'SimSolve'</code></p>
</td></tr>
<tr><td><code id="SimSolve_+3A_tab.only">tab.only</code></td>
<td>
<p>logical; print only the (reduce) table of estimates?</p>
</td></tr>
<tr><td><code id="SimSolve_+3A_reps.cutoff">reps.cutoff</code></td>
<td>
<p>integer indicating the rows to omit from output
if the number of replications do no reach this value</p>
</td></tr>
<tr><td><code id="SimSolve_+3A_x">x</code></td>
<td>
<p>object of class <code>'SimSolve'</code></p>
</td></tr>
<tr><td><code id="SimSolve_+3A_y">y</code></td>
<td>
<p>design row to plot. If omitted defaults to 1</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Root finding is performed using a progressively bolstered version of the
probabilistic bisection algorithm (<code><a href="#topic+PBA">PBA</a></code>) to find the
associated root given the noisy simulation
objective function evaluations. Information is collected throughout
the search to make more accurate predictions about the
associated root via interpolation. If interpolations fail, then the last
iteration of the PBA search is returned as the best guess.
</p>


<h3>Value</h3>

<p>the filled-in <code>design</code> object containing the associated lower and upper interval
estimates from the stochastic optimization
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SFA">SFA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

##########################
## A Priori Power Analysis
##########################

# GOAL: Find specific sample size in each group for independent t-test
# corresponding to a power rate of .8
#
# For ease of the setup, assume the groups are the same size, and the mean
# difference corresponds to Cohen's d values of .2, .5, and .8
# This example can be solved numerically using the pwr package (see below),
# though the following simulation setup is far more general and can be
# used for any generate-analyse combination of interest

# SimFunctions(SimSolve=TRUE)

#### Step 1 --- Define your conditions under study and create design data.frame.
#### However, use NA placeholder for sample size as it must be solved,
#### and add desired power rate to object

Design &lt;- createDesign(N = NA,
                       d = c(.2, .5, .8),
                       sig.level = .05)
Design    # solve for NA's

#~~~~~~~~~~~~~~~~~~~~~~~~
#### Step 2 --- Define generate, analyse, and summarise functions

Generate &lt;- function(condition, fixed_objects = NULL) {
    Attach(condition)
    group1 &lt;- rnorm(N)
    group2 &lt;- rnorm(N, mean=d)
    dat &lt;- data.frame(group = gl(2, N, labels=c('G1', 'G2')),
                      DV = c(group1, group2))
    dat
}

Analyse &lt;- function(condition, dat, fixed_objects = NULL) {
    p &lt;- t.test(DV ~ group, dat, var.equal=TRUE)$p.value
    p
}

Summarise &lt;- function(condition, results, fixed_objects = NULL) {
    # Must return a single number corresponding to f(x) in the
    # root equation f(x) = b

    ret &lt;- c(power = EDR(results, alpha = condition$sig.level))
    ret
}

#~~~~~~~~~~~~~~~~~~~~~~~~
#### Step 3 --- Optimize N over the rows in design

# (For debugging) may want to see if simulation code works as intended first
# for some given set of inputs
runSimulation(design=createDesign(N=100, d=.8, sig.level=.05),
              replications=10, generate=Generate, analyse=Analyse,
              summarise=Summarise)

# Initial search between N = [10,500] for each row using the default
   # integer solver (integer = TRUE). In this example, b = target power
solved &lt;- SimSolve(design=Design, b=.8, interval=c(10, 500),
                generate=Generate, analyse=Analyse,
                summarise=Summarise)
solved
summary(solved)
plot(solved, 1)
plot(solved, 2)
plot(solved, 3)

# also can plot median history and estimate precision
plot(solved, 1, type = 'history')
plot(solved, 1, type = 'density')
plot(solved, 1, type = 'iterations')

# verify with true power from pwr package
library(pwr)
pwr.t.test(d=.2, power = .8) # sig.level/alpha = .05 by default
pwr.t.test(d=.5, power = .8)
pwr.t.test(d=.8, power = .8)

# use estimated N results to see how close power was
N &lt;- solved$N
pwr.t.test(d=.2, n=N[1])
pwr.t.test(d=.5, n=N[2])
pwr.t.test(d=.8, n=N[3])

# with rounding
N &lt;- ceiling(solved$N)
pwr.t.test(d=.2, n=N[1])
pwr.t.test(d=.5, n=N[2])
pwr.t.test(d=.8, n=N[3])

# failing analytic formula, confirm results with more precise
#  simulation via runSimulation()
#  (not required, if accuracy is important then ProBABLI should be run longer)
csolved &lt;- solved
csolved$N &lt;- ceiling(solved$N)
confirm &lt;- runSimulation(design=csolved, replications=10000, parallel=TRUE,
                         generate=Generate, analyse=Analyse,
                         summarise=Summarise)
confirm

# Alternatively, and more realistically, the wait.time argument can be used
# to specify how long the user is willing to wait for a final estimate.
# Solutions involving more iterations will be more accurate,
# and therefore it is recommended to run the ProBABLI root-solver as long
# the analyst can tolerate if the most accurate estimates are desired.
# Below executes the simulation for 2 minutes for each condition up
# to a maximum of 1000 iterations, terminating based on whichever occurs first

solved_2min &lt;- SimSolve(design=Design, b=.8, interval=c(10, 500),
                generate=Generate, analyse=Analyse, summarise=Summarise,
                wait.time=2, maxiter=1000)
solved_2min
summary(solved_2min)

# use estimated N results to see how close power was
N &lt;- solved_2min$N
pwr.t.test(d=.2, n=N[1])
pwr.t.test(d=.5, n=N[2])
pwr.t.test(d=.8, n=N[3])

#------------------------------------------------

#######################
## Sensitivity Analysis
#######################

# GOAL: solve effect size d given sample size and power inputs (inputs
# for root no longer required to be an integer)

# Generate-Analyse-Summarise functions identical to above, however
# Design input includes NA for d element
Design &lt;- createDesign(N = c(100, 50, 25),
                       d = NA,
                       sig.level = .05)
Design    # solve for NA's

#~~~~~~~~~~~~~~~~~~~~~~~~
#### Step 2 --- Define generate, analyse, and summarise functions (same as above)

#~~~~~~~~~~~~~~~~~~~~~~~~
#### Step 3 --- Optimize d over the rows in design
# search between d = [.1, 2] for each row

# In this example, b = target power
# note that integer = FALSE to allow smooth updates of d
solved &lt;- SimSolve(design=Design, b = .8, interval=c(.1, 2),
                   generate=Generate, analyse=Analyse,
                   summarise=Summarise, integer=FALSE)
solved
summary(solved)
plot(solved, 1)
plot(solved, 2)
plot(solved, 3)

# plot median history and estimate precision
plot(solved, 1, type = 'history')
plot(solved, 1, type = 'density')
plot(solved, 1, type = 'iterations')

# verify with true power from pwr package
library(pwr)
pwr.t.test(n=100, power = .8)
pwr.t.test(n=50, power = .8)
pwr.t.test(n=25, power = .8)

# use estimated d results to see how close power was
pwr.t.test(n=100, d = solved$d[1])
pwr.t.test(n=50, d = solved$d[2])
pwr.t.test(n=25, d = solved$d[3])

# failing analytic formula, confirm results with more precise
#  simulation via runSimulation()
confirm &lt;- runSimulation(design=solved, replications=10000, parallel=TRUE,
                         generate=Generate, analyse=Analyse,
                         summarise=Summarise)
confirm


#------------------------------------------------

#####################
## Criterion Analysis
#####################

# GOAL: solve Type I error rate (alpha) given sample size, effect size, and
# power inputs (inputs for root no longer required to be an integer). Only useful
# when Type I error is less important than achieving the desired 1-beta (power)

Design &lt;- createDesign(N = 50,
                        d = c(.2, .5, .8),
                        sig.level = NA)
Design    # solve for NA's

# all other function definitions same as above

# search for alpha within [.0001, .8]
solved &lt;- SimSolve(design=Design, b = .8, interval=c(.0001, .8),
                   generate=Generate, analyse=Analyse,
                   summarise=Summarise, integer=FALSE)
solved
summary(solved)
plot(solved, 1)
plot(solved, 2)
plot(solved, 3)

# plot median history and estimate precision
plot(solved, 1, type = 'history')
plot(solved, 1, type = 'density')
plot(solved, 1, type = 'iterations')

# verify with true power from pwr package
library(pwr)
pwr.t.test(n=50, power = .8, d = .2, sig.level=NULL)
pwr.t.test(n=50, power = .8, d = .5, sig.level=NULL)
pwr.t.test(n=50, power = .8, d = .8, sig.level=NULL)

# use estimated alpha results to see how close power was
pwr.t.test(n=50, d = .2, sig.level=solved$sig.level[1])
pwr.t.test(n=50, d = .5, sig.level=solved$sig.level[2])
pwr.t.test(n=50, d = .8, sig.level=solved$sig.level[3])

# failing analytic formula, confirm results with more precise
#  simulation via runSimulation()
confirm &lt;- runSimulation(design=solved, replications=10000, parallel=TRUE,
                         generate=Generate, analyse=Analyse,
                         summarise=Summarise)
confirm


## End(Not run)
</code></pre>

<hr>
<h2 id='Summarise'>Summarise simulated data using various population comparison statistics</h2><span id='topic+Summarise'></span>

<h3>Description</h3>

<p>This collapses the simulation results within each condition to composite
estimates such as RMSE, bias, Type I error rates, coverage rates, etc. See the
<code>See Also</code> section below for useful functions to be used within <code>Summarise</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Summarise(condition, results, fixed_objects = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Summarise_+3A_condition">condition</code></td>
<td>
<p>a single row from the <code>design</code> input from <code><a href="#topic+runSimulation">runSimulation</a></code>
(as a <code>data.frame</code>), indicating the simulation conditions</p>
</td></tr>
<tr><td><code id="Summarise_+3A_results">results</code></td>
<td>
<p>a <code>tibble</code> data frame (if <code>Analyse</code> returned a named numeric vector of any
length) or a <code>list</code> (if <code>Analyse</code> returned a <code>list</code> or multi-rowed <code>data.frame</code>)
containing the analysis results from <code><a href="#topic+Analyse">Analyse</a></code>,
where each cell is stored in a unique row/list element</p>
</td></tr>
<tr><td><code id="Summarise_+3A_fixed_objects">fixed_objects</code></td>
<td>
<p>object passed down from <code><a href="#topic+runSimulation">runSimulation</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>for best results should return a named <code>numeric</code> vector or <code>data.frame</code>
with the desired meta-simulation results. Named <code>list</code> objects can also be returned,
however the subsequent results must be extracted via <code><a href="#topic+SimExtract">SimExtract</a></code>
</p>


<h3>References</h3>

<p>Chalmers, R. P., &amp; Adkins, M. C.  (2020). Writing Effective and Reliable Monte Carlo Simulations
with the SimDesign Package. <code>The Quantitative Methods for Psychology, 16</code>(4), 248-280.
<a href="https://doi.org/10.20982/tqmp.16.4.p248">doi:10.20982/tqmp.16.4.p248</a>
</p>
<p>Sigal, M. J., &amp; Chalmers, R. P. (2016). Play it again: Teaching statistics with Monte
Carlo simulation. <code>Journal of Statistics Education, 24</code>(3), 136-156.
<a href="https://doi.org/10.1080/10691898.2016.1246953">doi:10.1080/10691898.2016.1246953</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bias">bias</a></code>, <code><a href="#topic+RMSE">RMSE</a></code>, <code><a href="#topic+RE">RE</a></code>, <code><a href="#topic+EDR">EDR</a></code>,
<code><a href="#topic+ECR">ECR</a></code>, <code><a href="#topic+MAE">MAE</a></code>, <code><a href="#topic+SimExtract">SimExtract</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

summarise &lt;- function(condition, results, fixed_objects = NULL) {

    #find results of interest here (alpha &lt; .1, .05, .01)
    lessthan.05 &lt;- EDR(results, alpha = .05)

    # return the results that will be appended to the design input
    ret &lt;- c(lessthan.05=lessthan.05)
    ret
}


## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
