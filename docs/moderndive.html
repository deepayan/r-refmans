<!DOCTYPE html><html><head><title>Help for package moderndive</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {moderndive}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#moderndive'><p>moderndive - Tidyverse-Friendly Introductory Linear Regression</p></a></li>
<li><a href='#+25+26gt+3B+25'><p>Pipe operator</p></a></li>
<li><a href='#alaska_flights'><p>Alaska flights data</p></a></li>
<li><a href='#almonds_bowl'><p>Chocolate-covered almonds data</p></a></li>
<li><a href='#almonds_sample_100'><p>Chocolate-covered almonds data sample</p></a></li>
<li><a href='#amazon_books'><p>Sample of Amazon books</p></a></li>
<li><a href='#avocados'><p>Avocado Prices by US Region</p></a></li>
<li><a href='#babies'><p>Data on maternal smoking and infant health</p></a></li>
<li><a href='#bowl'><p>A sampling bowl of red and white balls</p></a></li>
<li><a href='#bowl_sample_1'><p>Tactile sample of size 50 from a bowl of balls</p></a></li>
<li><a href='#bowl_samples'><p>Sampling from a bowl of balls</p></a></li>
<li><a href='#coffee_ratings'><p>Data from the Coffee Quality Institute's review pages in January 2018</p></a></li>
<li><a href='#DD_vs_SB'><p>Dunkin Donuts vs Starbucks</p></a></li>
<li><a href='#early_january_2023_weather'><p>Early January hourly weather data for 2023</p></a></li>
<li><a href='#early_january_weather'><p>Early January hourly weather data</p></a></li>
<li><a href='#envoy_flights'><p>Envoy Air flights data for 2023</p></a></li>
<li><a href='#ev_charging'><p>Electric vehicle charging sessions for a workplace charging program</p></a></li>
<li><a href='#evals'><p>Teaching evaluations at the UT Austin</p></a></li>
<li><a href='#geom_categorical_model'><p>Regression model with one categorical explanatory/predictor variable</p></a></li>
<li><a href='#geom_parallel_slopes'><p>Parallel slopes regression model</p></a></li>
<li><a href='#get_correlation'><p>Get correlation value in a tidy way</p></a></li>
<li><a href='#get_regression_points'><p>Get regression points</p></a></li>
<li><a href='#get_regression_summaries'><p>Get regression summary values</p></a></li>
<li><a href='#get_regression_table'><p>Get regression table</p></a></li>
<li><a href='#gg_parallel_slopes'><p>Plot parallel slopes model</p></a></li>
<li><a href='#house_prices'><p>House Sales in King County, USA</p></a></li>
<li><a href='#ipf_lifts'><p>International Power Lifting Results</p>
A subset of international powerlifting results.</a></li>
<li><a href='#MA_schools'><p>Massachusetts Public High Schools Data</p></a></li>
<li><a href='#ma_traffic_2020_vs_2019'><p>Massachusetts 2020 vs. 2019 Traffic Data Comparison</p></a></li>
<li><a href='#mario_kart_auction'><p>Data from Mario Kart Ebay auctions</p></a></li>
<li><a href='#mass_traffic_2020'><p>2020 road traffic volume and crash level date for 13 Massachusetts counties</p></a></li>
<li><a href='#movies_sample'><p>Random sample of 68 action and romance movies</p></a></li>
<li><a href='#mythbusters_yawn'><p>Data from Mythbusters' study on contagiousness of yawning</p></a></li>
<li><a href='#orig_pennies_sample'><p>A random sample of 40 pennies sampled from the <code>pennies</code> data frame</p></a></li>
<li><a href='#pennies'><p>A population of 800 pennies sampled in 2011</p></a></li>
<li><a href='#pennies_resamples'><p>Bootstrap resamples of a sample of 50 pennies</p></a></li>
<li><a href='#pennies_sample'><p>A sample of 50 pennies</p></a></li>
<li><a href='#promotions'><p>Bank manager recommendations based on (binary) gender</p></a></li>
<li><a href='#promotions_shuffled'><p>One permutation/shuffle of promotions</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#saratoga_houses'><p>House Prices and Properties in Saratoga, New York</p></a></li>
<li><a href='#tactile_prop_red'><p>Tactile sampling from a tub of balls</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Tidyverse-Friendly Introductory Linear Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>0.6.1</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Albert Y. Kim &lt;albert.ys.kim@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Datasets and wrapper functions for tidyverse-friendly introductory linear regression, used in "Statistical Inference via Data Science: A ModernDive into R and the Tidyverse" available at <a href="https://moderndive.com/">https://moderndive.com/</a>.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://moderndive.github.io/moderndive/">https://moderndive.github.io/moderndive/</a>,
<a href="https://github.com/moderndive/moderndive/">https://github.com/moderndive/moderndive/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/moderndive/moderndive/issues">https://github.com/moderndive/moderndive/issues</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>magrittr, dplyr, ggplot2, tibble, janitor, broom (&ge; 0.4.3),
formula.tools, stringr, knitr, infer, rlang (&ge; 0.2.0), glue</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, covr, rmarkdown, vdiffr, openintro, patchwork,
viridis, readr, nycflights13, nycflights23</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-06-29 15:45:38 UTC; akim04</td>
</tr>
<tr>
<td>Author:</td>
<td>Albert Y. Kim <a href="https://orcid.org/0000-0001-7824-306X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Chester Ismay <a href="https://orcid.org/0000-0003-2820-2547"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Andrew Bray <a href="https://orcid.org/0000-0002-4037-7414"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb],
  Delaney Moran [ctb],
  Evgeni Chasnovski <a href="https://orcid.org/0000-0002-1617-4019"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Will Hopper <a href="https://orcid.org/0000-0002-7848-1946"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb],
  Benjamin S. Baumer
    <a href="https://orcid.org/0000-0002-3279-0516"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb],
  Marium Tapal <a href="https://orcid.org/0000-0001-5093-6462"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Wayne Ndlovu [ctb],
  Catherine Peppers [ctb],
  Annah Mutaya [ctb],
  Anushree Goswami [ctb],
  Ziyue Yang <a href="https://orcid.org/0000-0002-9299-8327"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb],
  Clara Li <a href="https://orcid.org/0000-0003-2456-0849"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb],
  Caroline McKenna [ctb],
  Catherine Park <a href="https://orcid.org/0000-0002-8273-9620"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Abbie Benfield [ctb],
  Georgia Gans [ctb],
  Kacey Jean-Jacques [ctb],
  Swaha Bhattacharya [ctb],
  Vivian Almaraz [ctb],
  Elle Jo Whalen [ctb],
  Jacqueline Chen [ctb],
  Michelle Flesaker [ctb],
  Irene Foster [ctb],
  Aushanae Haller [ctb],
  Benjamin Bruncati <a href="https://orcid.org/0000-0001-8545-5984"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Quinn White <a href="https://orcid.org/0000-0001-5399-0237"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb],
  Tianshu Zhang <a href="https://orcid.org/0000-0002-3004-4472"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Katelyn Diaz <a href="https://orcid.org/0000-0001-6108-1682"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Rose Porta [ctb],
  Renee Wu [ctb],
  Arris Moise [ctb],
  Kate Phan [ctb],
  Grace Hartley [ctb],
  Silas Weden [ctb],
  Emma Vejcik [ctb],
  Nikki Schuldt [ctb],
  Tess Goldmann [ctb],
  Hongtong Lin [ctb],
  Alejandra Munoz [ctb],
  Elina Gordon-Halpern [ctb],
  Haley Schmidt <a href="https://orcid.org/0000-0002-6184-2266"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-06-30 07:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='moderndive'>moderndive - Tidyverse-Friendly Introductory Linear Regression</h2><span id='topic+moderndive-package'></span><span id='topic+moderndive'></span>

<h3>Description</h3>

<p>Datasets and wrapper functions for tidyverse-friendly introductory linear
regression, used in &quot;Statistical Inference via Data Science: A ModernDive
into R and the tidyverse&quot; available at <a href="https://moderndive.com/">https://moderndive.com/</a>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Albert Y. Kim <a href="mailto:albert.ys.kim@gmail.com">albert.ys.kim@gmail.com</a> (<a href="https://orcid.org/0000-0001-7824-306X">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Chester Ismay <a href="mailto:chester.ismay@gmail.com">chester.ismay@gmail.com</a> (<a href="https://orcid.org/0000-0003-2820-2547">ORCID</a>)
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Andrew Bray <a href="mailto:abray@reed.edu">abray@reed.edu</a> (<a href="https://orcid.org/0000-0002-4037-7414">ORCID</a>) [contributor]
</p>
</li>
<li><p> Delaney Moran <a href="mailto:delaneyemoran@gmail.com">delaneyemoran@gmail.com</a> [contributor]
</p>
</li>
<li><p> Evgeni Chasnovski <a href="mailto:evgeni.chasnovski@gmail.com">evgeni.chasnovski@gmail.com</a> (<a href="https://orcid.org/0000-0002-1617-4019">ORCID</a>) [contributor]
</p>
</li>
<li><p> Will Hopper <a href="mailto:wjhopper510@gmail.com">wjhopper510@gmail.com</a> (<a href="https://orcid.org/0000-0002-7848-1946">ORCID</a>) [contributor]
</p>
</li>
<li><p> Benjamin S. Baumer <a href="mailto:ben.baumer@gmail.com">ben.baumer@gmail.com</a> (<a href="https://orcid.org/0000-0002-3279-0516">ORCID</a>) [contributor]
</p>
</li>
<li><p> Marium Tapal <a href="mailto:mariumtapal@gmail.com">mariumtapal@gmail.com</a> (<a href="https://orcid.org/0000-0001-5093-6462">ORCID</a>) [contributor]
</p>
</li>
<li><p> Wayne Ndlovu <a href="mailto:waynedndlovu5@gmail.com">waynedndlovu5@gmail.com</a> [contributor]
</p>
</li>
<li><p> Catherine Peppers <a href="mailto:cpeppers@smith.edu">cpeppers@smith.edu</a> [contributor]
</p>
</li>
<li><p> Annah Mutaya <a href="mailto:annahmutaya18@gmail.com">annahmutaya18@gmail.com</a> [contributor]
</p>
</li>
<li><p> Anushree Goswami <a href="mailto:anushreeegoswami@gmail.com">anushreeegoswami@gmail.com</a> [contributor]
</p>
</li>
<li><p> Ziyue Yang <a href="mailto:zyang2k@gmail.com">zyang2k@gmail.com</a> (<a href="https://orcid.org/0000-0002-9299-8327">ORCID</a>) [contributor]
</p>
</li>
<li><p> Clara Li <a href="mailto:clarasepianli@gmail.com">clarasepianli@gmail.com</a> (<a href="https://orcid.org/0000-0003-2456-0849">ORCID</a>) [contributor]
</p>
</li>
<li><p> Caroline McKenna <a href="mailto:carolinemckenna101@gmail.com">carolinemckenna101@gmail.com</a> [contributor]
</p>
</li>
<li><p> Catherine Park <a href="mailto:jcathyp@gmail.com">jcathyp@gmail.com</a> (<a href="https://orcid.org/0000-0002-8273-9620">ORCID</a>) [contributor]
</p>
</li>
<li><p> Abbie Benfield <a href="mailto:abbidabbers@gmail.com">abbidabbers@gmail.com</a> [contributor]
</p>
</li>
<li><p> Georgia Gans <a href="mailto:georgiagans@live.com">georgiagans@live.com</a> [contributor]
</p>
</li>
<li><p> Kacey Jean-Jacques <a href="mailto:kjeanjacques@smith.edu">kjeanjacques@smith.edu</a> [contributor]
</p>
</li>
<li><p> Swaha Bhattacharya <a href="mailto:itsswahabhattacharya@gmail.com">itsswahabhattacharya@gmail.com</a> [contributor]
</p>
</li>
<li><p> Vivian Almaraz <a href="mailto:viviansofia101@gmail.com">viviansofia101@gmail.com</a> [contributor]
</p>
</li>
<li><p> Elle Jo Whalen <a href="mailto:ewhalen@smith.edu">ewhalen@smith.edu</a> [contributor]
</p>
</li>
<li><p> Jacqueline Chen <a href="mailto:jchen76@smith.edu">jchen76@smith.edu</a> [contributor]
</p>
</li>
<li><p> Michelle Flesaker <a href="mailto:mflesaker@smith.edu">mflesaker@smith.edu</a> [contributor]
</p>
</li>
<li><p> Irene Foster <a href="mailto:ifoster25@smith.edu">ifoster25@smith.edu</a> [contributor]
</p>
</li>
<li><p> Aushanae Haller <a href="mailto:aushanaenhaller@gmail.com">aushanaenhaller@gmail.com</a> [contributor]
</p>
</li>
<li><p> Benjamin Bruncati <a href="mailto:kbruncati@smith.edu">kbruncati@smith.edu</a> (<a href="https://orcid.org/0000-0001-8545-5984">ORCID</a>) [contributor]
</p>
</li>
<li><p> Quinn White <a href="mailto:quinnarlise@gmail.com">quinnarlise@gmail.com</a> (<a href="https://orcid.org/0000-0001-5399-0237">ORCID</a>) [contributor]
</p>
</li>
<li><p> Tianshu Zhang <a href="mailto:tzhang26@smith.edu">tzhang26@smith.edu</a> (<a href="https://orcid.org/0000-0002-3004-4472">ORCID</a>) [contributor]
</p>
</li>
<li><p> Katelyn Diaz <a href="mailto:katndiaz@gmail.com">katndiaz@gmail.com</a> (<a href="https://orcid.org/0000-0001-6108-1682">ORCID</a>) [contributor]
</p>
</li>
<li><p> Rose Porta <a href="mailto:rporta@smith.edu">rporta@smith.edu</a> [contributor]
</p>
</li>
<li><p> Renee Wu <a href="mailto:rwu30@smith.edu">rwu30@smith.edu</a> [contributor]
</p>
</li>
<li><p> Arris Moise <a href="mailto:amoise@smith.edu">amoise@smith.edu</a> [contributor]
</p>
</li>
<li><p> Kate Phan <a href="mailto:kphan@smith.edu">kphan@smith.edu</a> [contributor]
</p>
</li>
<li><p> Grace Hartley <a href="mailto:grace.hartley@gmail.com">grace.hartley@gmail.com</a> [contributor]
</p>
</li>
<li><p> Silas Weden <a href="mailto:silasweden@gmail.com">silasweden@gmail.com</a> [contributor]
</p>
</li>
<li><p> Emma Vejcik <a href="mailto:evejcik@gmail.com">evejcik@gmail.com</a> (<a href="https://orcid.org/0000-0001-5093-6462">ORCID</a>) [contributor]
</p>
</li>
<li><p> Nikki Schuldt <a href="mailto:nikkischuldt@gmail.com">nikkischuldt@gmail.com</a> [contributor]
</p>
</li>
<li><p> Tess Goldmann <a href="mailto:tessgoldmann@aol.com">tessgoldmann@aol.com</a> [contributor]
</p>
</li>
<li><p> Hongtong Lin <a href="mailto:cccynthialht@gmail.com">cccynthialht@gmail.com</a> [contributor]
</p>
</li>
<li><p> Alejandra Munoz <a href="mailto:amunozgarcia@smith.edu">amunozgarcia@smith.edu</a> [contributor]
</p>
</li>
<li><p> Elina Gordon-Halpern <a href="mailto:egordonhalpern@smith.edu">egordonhalpern@smith.edu</a> [contributor]
</p>
</li>
<li><p> Haley Schmidt <a href="mailto:heschmidt00@gmail.com">heschmidt00@gmail.com</a> (<a href="https://orcid.org/0000-0002-6184-2266">ORCID</a>) [contributor]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://moderndive.github.io/moderndive/">https://moderndive.github.io/moderndive/</a>
</p>
</li>
<li> <p><a href="https://github.com/moderndive/moderndive/">https://github.com/moderndive/moderndive/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/moderndive/moderndive/issues">https://github.com/moderndive/moderndive/issues</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>library(moderndive)

# Fit regression model:
mpg_model &lt;- lm(mpg ~ hp, data = mtcars)

# Regression tables:
get_regression_table(mpg_model)

# Information on each point in a regression:
get_regression_points(mpg_model)

# Regression summaries
get_regression_summaries(mpg_model)

# Plotting parallel slopes models
library(ggplot2)
ggplot(evals, aes(x = age, y = score, color = ethnicity)) +
  geom_point() +
  geom_parallel_slopes(se = FALSE)
</code></pre>

<hr>
<h2 id='+25+26gt+3B+25'>Pipe operator</h2><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>See <code style="white-space: pre;">&#8288;magrittr::[\%&gt;\%][magrittr::pipe]&#8288;</code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lhs %&gt;% rhs
</code></pre>

<hr>
<h2 id='alaska_flights'>Alaska flights data</h2><span id='topic+alaska_flights'></span>

<h3>Description</h3>

<p>On-time data for all Alaska Airlines flights that departed NYC (i.e. JFK, LGA or EWR)
in 2013. This is a subset of the <code>flights</code> data frame from <code>nycflights13</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alaska_flights
</code></pre>


<h3>Format</h3>

<p>A data frame of 714 rows representing Alaska Airlines flights and 19 variables
</p>

<dl>
<dt>year, month, day</dt><dd><p>Date of departure.</p>
</dd>
<dt>dep_time, arr_time</dt><dd><p>Actual departure and arrival times (format HHMM or HMM), local tz.</p>
</dd>
<dt>sched_dep_time, sched_arr_time</dt><dd><p>Scheduled departure and arrival times (format HHMM or HMM), local tz.</p>
</dd>
<dt>dep_delay, arr_delay</dt><dd><p>Departure and arrival delays, in minutes.
Negative times represent early departures/arrivals.</p>
</dd>
<dt>carrier</dt><dd><p>Two letter carrier abbreviation. See <code><a href="nycflights13.html#topic+airlines">nycflights13::airlines</a></code>
to get name.</p>
</dd>
<dt>flight</dt><dd><p>Flight number.</p>
</dd>
<dt>tailnum</dt><dd><p>Plane tail number. See <code><a href="nycflights13.html#topic+planes">nycflights13::planes</a></code> for additional metadata.</p>
</dd>
<dt>origin, dest</dt><dd><p>Origin and destination. See <code><a href="nycflights13.html#topic+airports">nycflights13::airports</a></code> for
additional metadata.</p>
</dd>
<dt>air_time</dt><dd><p>Amount of time spent in the air, in minutes.</p>
</dd>
<dt>distance</dt><dd><p>Distance between airports, in miles.</p>
</dd>
<dt>hour, minute</dt><dd><p>Time of scheduled departure broken into hour and minutes.</p>
</dd>
<dt>time_hour</dt><dd><p>Scheduled date and hour of the flight as a <code>POSIXct</code> date.
Along with <code>origin</code>, can be used to join flights data to <code><a href="nycflights13.html#topic+weather">nycflights13::weather</a></code> data.</p>
</dd>
</dl>



<h3>Source</h3>

<p>RITA, Bureau of transportation statistics
</p>


<h3>See Also</h3>

<p><code><a href="nycflights13.html#topic+flights">nycflights13::flights</a></code>.
</p>

<hr>
<h2 id='almonds_bowl'>Chocolate-covered almonds data</h2><span id='topic+almonds_bowl'></span>

<h3>Description</h3>

<p>5000 chocolate-covered almonds selected from a large batch, weighed in grams.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>almonds_bowl
</code></pre>


<h3>Format</h3>

<p>A data frame with 5000 observations on the following 2 variables
</p>

<dl>
<dt>ID</dt><dd><p>Identification value for a given chocolate-covered almond</p>
</dd>
<dt>weight</dt><dd><p>Weight of the chocolate-covered almond in grams (to the nearest tenth)</p>
</dd>
</dl>


<hr>
<h2 id='almonds_sample_100'>Chocolate-covered almonds data sample</h2><span id='topic+almonds_sample_100'></span>

<h3>Description</h3>

<p>A sample of 100 chocolate-covered almonds, weighed in grams.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>almonds_sample_100
</code></pre>


<h3>Format</h3>

<p>A data frame with 100 observations on the following 2 variables
</p>

<dl>
<dt>ID</dt><dd><p>Identification value for a given chocolate-covered almond</p>
</dd>
<dt>weight</dt><dd><p>Weight of the chocolate-covered almond in grams (to the nearest tenth)</p>
</dd>
</dl>


<hr>
<h2 id='amazon_books'>Sample of Amazon books</h2><span id='topic+amazon_books'></span>

<h3>Description</h3>

<p>A random sample of 325 books from Amazon.com.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>amazon_books
</code></pre>


<h3>Format</h3>

<p>A data frame of 325 rows representing books listed on Amazon and 13 variables.
</p>

<dl>
<dt>title</dt><dd><p>Book title</p>
</dd>
<dt>author</dt><dd><p>Author who wrote book</p>
</dd>
<dt>list_price</dt><dd><p>recommended retail price of book</p>
</dd>
<dt>amazon_price</dt><dd><p>lowest price of book shown on Amazon</p>
</dd>
<dt>hard_paper</dt><dd><p>book is either hardcover or paperback</p>
</dd>
<dt>num_pages</dt><dd><p>number of pages in book</p>
</dd>
<dt>publisher</dt><dd><p>Company that issues the book for sale</p>
</dd>
<dt>pub_year</dt><dd><p>Year the book was published</p>
</dd>
<dt>isbn_10</dt><dd><p>10-character ISBN number</p>
</dd>
<dt>height, width, thick, weight_oz</dt><dd><p>height, width, weight and thickness of the book</p>
</dd>
</dl>



<h3>Source</h3>

<p>The Data and Story Library (DASL) <a href="https://dasl.datadescription.com/datafile/amazon-books">https://dasl.datadescription.com/datafile/amazon-books</a>
</p>

<hr>
<h2 id='avocados'>Avocado Prices by US Region</h2><span id='topic+avocados'></span>

<h3>Description</h3>

<p>Gathered from <a href="https://docs.google.com/spreadsheets/d/1cNuj9V-9Xe8fqV3DQRhvsXJhER3zTkO1dSsQ1Q0j96g/edit#gid=1419070688">https://docs.google.com/spreadsheets/d/1cNuj9V-9Xe8fqV3DQRhvsXJhER3zTkO1dSsQ1Q0j96g/edit#gid=1419070688</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>avocados
</code></pre>


<h3>Format</h3>

<p>A data frame of 54 regions over 3 years of weekly results
</p>

<dl>
<dt>date</dt><dd><p>Week of Data Recording</p>
</dd>
<dt>average_price</dt><dd><p>Average Price of Avocado</p>
</dd>
<dt>total_volume</dt><dd><p>Total Amount of Avocados</p>
</dd>
<dt>small_hass_sold</dt><dd><p>Amount of Small Haas Avocados Sold</p>
</dd>
<dt>large_hass_sold</dt><dd><p>Amount of Large Haas Avocados Sold</p>
</dd>
<dt>xlarge_hass_sold</dt><dd><p>Amount of Extra Large Haas Avocados Sold</p>
</dd>
<dt>total_bags</dt><dd><p>Total Amount of Bags of Avocados</p>
</dd>
<dt>small_bags</dt><dd><p>Total Amount of Bags of Small Haas Avocados</p>
</dd>
<dt>large_bags</dt><dd><p>Total Amount of Bags of Large Haas Avocados</p>
</dd>
<dt>x_large_bags</dt><dd><p>Total Amount of Bags of Extra Large Haas Avocados</p>
</dd>
<dt>type</dt><dd><p>Type of Sale</p>
</dd>
<dt>year</dt><dd><p>Year of Sale</p>
</dd>
<dt>region</dt><dd><p>Region Where Sale Took Place</p>
</dd>
</dl>


<hr>
<h2 id='babies'>Data on maternal smoking and infant health</h2><span id='topic+babies'></span>

<h3>Description</h3>

<p>Data on maternal smoking and infant health
</p>


<h3>Usage</h3>

<pre><code class='language-R'>babies
</code></pre>


<h3>Format</h3>

<p>A data frame of 1236 rows of individual mothers.
</p>

<dl>
<dt>id</dt><dd><p>Identification number</p>
</dd>
<dt>pluralty</dt><dd><p>Marked 5 for single fetus, otherwise number of fetuses</p>
</dd>
<dt>outcome</dt><dd><p>Marked 1 for live birth that survived at least 28 days</p>
</dd>
<dt>date</dt><dd><p>Birth date where 1096 is January 1st, 1961</p>
</dd>
<dt>birthday</dt><dd><p>Birth date in mm-dd-yyyy format</p>
</dd>
<dt>gestation</dt><dd><p>Length of gestation in days, marked 999 if unknown</p>
</dd>
<dt>sex</dt><dd><p>Infant's sex, where 1 is male, 2 is female, and 9 is unknown</p>
</dd>
<dt>wt</dt><dd><p>Birth weight in ounces, marked 999 if unknown</p>
</dd>
<dt>parity</dt><dd><p>Total number of previous pregnancies including fetal deaths and stillbirths, marked 99 if unknown</p>
</dd>
<dt>race</dt><dd><p>Mother's race where 0-5 is white, 6 is Mexican, 7 is Black, 8 is Asian, 9 is mixed, and 99 is unknown</p>
</dd>
<dt>age</dt><dd><p>Mother's age in years at termination of pregnancy, 99=unknown</p>
</dd>
<dt>ed</dt><dd><p>Mother's education 0= less than 8th grade, 1 = 8th -12th grade - did not graduate, 2= HS graduate&ndash;no other schooling , 3= HS+trade, 4=HS+some college 5= College graduate, 6&amp;7 Trade school HS unclear, 9=unknown</p>
</dd>
<dt>ht</dt><dd><p>Mother's height in inches to the last completed inch, 99=unknown</p>
</dd>
<dt>wt_1</dt><dd><p>Mother prepregnancy wt in pounds, 999=unknown</p>
</dd>
<dt>drace</dt><dd><p>Father's race, coding same as mother's race</p>
</dd>
<dt>dage</dt><dd><p>Father's age, coding same as mother's age</p>
</dd>
<dt>ded</dt><dd><p>Father's education, coding same as mother's education</p>
</dd>
<dt>dht</dt><dd><p>Father's height, coding same as for mother's height</p>
</dd>
<dt>dwt</dt><dd><p>Father's weight coding same as for mother's weight</p>
</dd>
<dt>marital</dt><dd><p>0= legally separated, 1=married, 2= divorced, 3=widowed, 5=never married</p>
</dd>
<dt>inc</dt><dd><p>Family yearly income in $2500 increments 0 = under 2500, 1=2500-4999, ..., 8= 12,500-14,999, 9=15000+, 98=unknown, 99=not asked</p>
</dd>
<dt>smoke</dt><dd><p>Does mother smoke? 0=never, 1= smokes now, 2=until current pregnancy, 3=once did, not now, 9=unknown</p>
</dd>
<dt>time</dt><dd><p>If mother quit, how long ago? 0=never smoked, 1=still smokes, 2=during current preg, 3=within 1 yr, 4= 1 to 2 years ago, 5= 2 to 3 yr ago, 6= 3 to 4 yrs ago, 7=5 to 9yrs ago, 8=10+yrs ago, 9=quit and don't know, 98=unknown, 99=not asked</p>
</dd>
<dt>number</dt><dd><p>Number of cigs smoked per day for past and current smokers  0=never, 1=1-4, 2=5-9, 3=10-14, 4=15-19, 5=20-29, 6=30-39, 7=40-60, 8=60+, 9=smoke but don't know, 98=unknown, 99=not asked</p>
</dd>
</dl>



<h3>Source</h3>

<p>Data on maternal smoking and infant health from <a href="https://www.stat.berkeley.edu/~statlabs/labs.html">https://www.stat.berkeley.edu/~statlabs/labs.html</a>
</p>

<hr>
<h2 id='bowl'>A sampling bowl of red and white balls</h2><span id='topic+bowl'></span>

<h3>Description</h3>

<p>A sampling bowl used as the population in a simulated sampling exercise. Also
known as the urn sampling framework <a href="https://en.wikipedia.org/wiki/Urn_problem">https://en.wikipedia.org/wiki/Urn_problem</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bowl
</code></pre>


<h3>Format</h3>

<p>A data frame 2400 rows representing different balls in the bowl, of which
900 are red and 1500 are white.
</p>

<dl>
<dt>ball_ID</dt><dd><p>ID variable used to denote all balls. Note this value is not
marked on the balls themselves</p>
</dd>
<dt>color</dt><dd><p>color of ball: red or white</p>
</dd>
</dl>


<hr>
<h2 id='bowl_sample_1'>Tactile sample of size 50 from a bowl of balls</h2><span id='topic+bowl_sample_1'></span>

<h3>Description</h3>

<p>A single tactile sample of size n = 50 balls from
<a href="https://github.com/moderndive/moderndive/blob/master/data-raw/sampling_bowl.jpeg">https://github.com/moderndive/moderndive/blob/master/data-raw/sampling_bowl.jpeg</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bowl_sample_1
</code></pre>


<h3>Format</h3>

<p>A data frame of 50 rows representing different balls and 1 variable.
</p>

<dl>
<dt>color</dt><dd><p>Color of ball sampled</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+bowl">bowl()</a></code>
</p>

<hr>
<h2 id='bowl_samples'>Sampling from a bowl of balls</h2><span id='topic+bowl_samples'></span>

<h3>Description</h3>

<p>Counting the number of red balls in 10 samples of size n = 50 balls from
<a href="https://github.com/moderndive/moderndive/blob/master/data-raw/sampling_bowl.jpeg">https://github.com/moderndive/moderndive/blob/master/data-raw/sampling_bowl.jpeg</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bowl_samples
</code></pre>


<h3>Format</h3>

<p>A data frame 10 rows representing different groups of students'
samples of size n = 50 and 5 variables
</p>

<dl>
<dt>group</dt><dd><p>Group name</p>
</dd>
<dt>red</dt><dd><p>Number of red balls sampled</p>
</dd>
<dt>white</dt><dd><p>Number of white balls sampled</p>
</dd>
<dt>green</dt><dd><p>Number of green balls sampled</p>
</dd>
<dt>n</dt><dd><p>Total number of balls samples</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+bowl">bowl()</a></code>
</p>

<hr>
<h2 id='coffee_ratings'>Data from the Coffee Quality Institute's review pages in January 2018</h2><span id='topic+coffee_ratings'></span>

<h3>Description</h3>

<p>1,340 digitized reviews on coffee samples from
<a href="https://database.coffeeinstitute.org/">https://database.coffeeinstitute.org/</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coffee_ratings
</code></pre>


<h3>Format</h3>

<p>A data frame of 1,340 rows representing each sample of coffee.
</p>

<dl>
<dt>total_cup_points</dt><dd><p>Number of points in final rating (scale of 0-100)</p>
</dd>
<dt>species</dt><dd><p>Species of coffee bean plant (Arabica or Robusta)</p>
</dd>
<dt>owner</dt><dd><p>Owner of coffee plant farm</p>
</dd>
<dt>country_of_origin</dt><dd><p>Coffee bean's country of origin</p>
</dd>
<dt>farm_name</dt><dd><p>Name of coffee plant farm</p>
</dd>
<dt>lot_number</dt><dd><p>Lot number for tested coffee beans</p>
</dd>
<dt>mill</dt><dd><p>Name of coffee bean's processing facility</p>
</dd>
<dt>ico_number</dt><dd><p>International Coffee Organization number</p>
</dd>
<dt>company</dt><dd><p>Name of coffee bean's company</p>
</dd>
<dt>altitude</dt><dd><p>Altitude at which coffee plants were grown</p>
</dd>
<dt>region</dt><dd><p>Region where coffee plants were grown</p>
</dd>
<dt>producer</dt><dd><p>Name of coffee bean roaster</p>
</dd>
<dt>number_of_bags</dt><dd><p>Number of tested bags</p>
</dd>
<dt>bag_weight</dt><dd><p>Tested bag weight</p>
</dd>
<dt>in_country_partner</dt><dd><p>Partner for the country</p>
</dd>
<dt>harvest_year</dt><dd><p>Year the coffee beans were harvested</p>
</dd>
<dt>grading_date</dt><dd><p>Day the coffee beans were graded</p>
</dd>
<dt>owner_1</dt><dd><p>Owner of the coffee beans</p>
</dd>
<dt>variety</dt><dd><p>Variety of the coffee beans</p>
</dd>
<dt>processing_method</dt><dd><p>Method used for processing the coffee beans</p>
</dd>
<dt>aroma</dt><dd><p>Coffee aroma rating</p>
</dd>
<dt>flavor</dt><dd><p>Coffee flavor rating</p>
</dd>
<dt>aftertaste</dt><dd><p>Coffee aftertaste rating</p>
</dd>
<dt>acidity</dt><dd><p>Coffee acidity rating</p>
</dd>
<dt>body</dt><dd><p>Coffee body rating</p>
</dd>
<dt>balance</dt><dd><p>Coffee balance rating</p>
</dd>
<dt>uniformity</dt><dd><p>Coffee uniformity rating</p>
</dd>
<dt>clean_cup</dt><dd><p>Cup cleanliness rating</p>
</dd>
<dt>sweetness</dt><dd><p>Coffee sweetness rating</p>
</dd>
<dt>cupper_points</dt><dd><p>Cupper Points, an overall rating for the coffee</p>
</dd>
<dt>moisture</dt><dd><p>Coffee moisture content</p>
</dd>
<dt>category_one_defects</dt><dd><p>Number of category one defects for the coffee beans</p>
</dd>
<dt>quakers</dt><dd><p>Number of coffee beans that don't dark brown when roasted</p>
</dd>
<dt>color</dt><dd><p>Color of the coffee beans</p>
</dd>
<dt>category_two_defects</dt><dd><p>Number of category two defects for the coffee beans</p>
</dd>
<dt>expiration</dt><dd><p>Expiration date of the coffee beans</p>
</dd>
<dt>certification_body</dt><dd><p>Entity/Institute that certified the coffee beans</p>
</dd>
<dt>certification_address</dt><dd><p>Body address of certification for coffee beans</p>
</dd>
<dt>certification_contact</dt><dd><p>Certification contact for coffee beans</p>
</dd>
<dt>unit_of_measurement</dt><dd><p>Unit of measurement for altitude</p>
</dd>
<dt>altitude_low_meters</dt><dd><p>Lower altitude level coffee beans grow at</p>
</dd>
<dt>altitude_high_meters</dt><dd><p>Higher altitude level coffee beans grow at</p>
</dd>
<dt>altitude_mean_meters</dt><dd><p>Average altitude level coffee beans grow at</p>
</dd>
</dl>



<h3>Source</h3>

<p>Coffee Quality Institute. Access cleaned data available at <a href="https://github.com/jldbc/coffee-quality-database">https://github.com/jldbc/coffee-quality-database</a>
</p>

<hr>
<h2 id='DD_vs_SB'>Dunkin Donuts vs Starbucks</h2><span id='topic+DD_vs_SB'></span>

<h3>Description</h3>

<p>Number of Dunkin Donuts &amp; Starbucks, median income, and population in 1024
census tracts in eastern Massachusetts in 2016.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DD_vs_SB
</code></pre>


<h3>Format</h3>

<p>A data frame of 1024 rows representing census tracts and 6 variables
</p>

<dl>
<dt>county</dt><dd><p>County where census tract is located. Either Bristol, Essex, Middlesex, Norfolk, Plymouth, or Suffolk county</p>
</dd>
<dt>FIPS</dt><dd><p>Federal Information Processing Standards code identifying census tract</p>
</dd>
<dt>median_income</dt><dd><p>Median income of census tract</p>
</dd>
<dt>population</dt><dd><p>Population of census tract</p>
</dd>
<dt>shop_type</dt><dd><p>Coffee shop type: Dunkin Donuts or Starbucks</p>
</dd>
<dt>shops</dt><dd><p>Number of shops</p>
</dd>
</dl>



<h3>Source</h3>

<p>US Census Bureau. Code used to scrape data available at <a href="https://github.com/DelaneyMoran/FinalProject">https://github.com/DelaneyMoran/FinalProject</a>
</p>

<hr>
<h2 id='early_january_2023_weather'>Early January hourly weather data for 2023</h2><span id='topic+early_january_2023_weather'></span>

<h3>Description</h3>

<p>Hourly meteorological data for LGA, JFK and EWR for the month of January 2023.
This is a subset of the <code>weather</code> data frame from <code>nycflights23</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>early_january_2023_weather
</code></pre>


<h3>Format</h3>

<p>A data frame of 360 rows representing hourly measurements and 15 variables
</p>

<dl>
<dt>origin</dt><dd><p>Weather station. Named <code>origin</code> to facilitate merging with
<code><a href="nycflights23.html#topic+flights">nycflights23::flights</a></code> data.</p>
</dd>
<dt>year, month, day, hour</dt><dd><p>Time of recording.</p>
</dd>
<dt>temp, dewp</dt><dd><p>Temperature and dewpoint in F.</p>
</dd>
<dt>humid</dt><dd><p>Relative humidity.</p>
</dd>
<dt>wind_dir, wind_speed, wind_gust</dt><dd><p>Wind direction (in degrees), speed
and gust speed (in mph).</p>
</dd>
<dt>precip</dt><dd><p>Precipitation, in inches.</p>
</dd>
<dt>pressure</dt><dd><p>Sea level pressure in millibars.</p>
</dd>
<dt>visib</dt><dd><p>Visibility in miles.</p>
</dd>
<dt>time_hour</dt><dd><p>Date and hour of the recording as a <code>POSIXct</code> date.</p>
</dd>
</dl>



<h3>Source</h3>

<p>ASOS download from Iowa Environmental Mesonet,
<a href="https://mesonet.agron.iastate.edu/request/download.phtml">https://mesonet.agron.iastate.edu/request/download.phtml</a>.
</p>


<h3>See Also</h3>

<p><code><a href="nycflights23.html#topic+weather">nycflights23::weather</a></code>.
</p>

<hr>
<h2 id='early_january_weather'>Early January hourly weather data</h2><span id='topic+early_january_weather'></span>

<h3>Description</h3>

<p>Hourly meteorological data for LGA, JFK and EWR for the month of January 2013.
This is a subset of the <code>weather</code> data frame from <code>nycflights13</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>early_january_weather
</code></pre>


<h3>Format</h3>

<p>A data frame of 358 rows representing hourly measurements and 15 variables
</p>

<dl>
<dt>origin</dt><dd><p>Weather station. Named <code>origin</code> to facilitate merging with
<code><a href="nycflights13.html#topic+flights">nycflights13::flights</a></code> data.</p>
</dd>
<dt>year, month, day, hour</dt><dd><p>Time of recording.</p>
</dd>
<dt>temp, dewp</dt><dd><p>Temperature and dewpoint in F.</p>
</dd>
<dt>humid</dt><dd><p>Relative humidity.</p>
</dd>
<dt>wind_dir, wind_speed, wind_gust</dt><dd><p>Wind direction (in degrees), speed
and gust speed (in mph).</p>
</dd>
<dt>precip</dt><dd><p>Precipitation, in inches.</p>
</dd>
<dt>pressure</dt><dd><p>Sea level pressure in millibars.</p>
</dd>
<dt>visib</dt><dd><p>Visibility in miles.</p>
</dd>
<dt>time_hour</dt><dd><p>Date and hour of the recording as a <code>POSIXct</code> date.</p>
</dd>
</dl>



<h3>Source</h3>

<p>ASOS download from Iowa Environmental Mesonet,
<a href="https://mesonet.agron.iastate.edu/request/download.phtml">https://mesonet.agron.iastate.edu/request/download.phtml</a>.
</p>


<h3>See Also</h3>

<p><code><a href="nycflights13.html#topic+weather">nycflights13::weather</a></code>.
</p>

<hr>
<h2 id='envoy_flights'>Envoy Air flights data for 2023</h2><span id='topic+envoy_flights'></span>

<h3>Description</h3>

<p>On-time data for all Envoy Air flights that departed NYC (i.e. JFK, LGA or EWR)
in 2023. This is a subset of the <code>flights</code> data frame from <code>nycflights23</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>envoy_flights
</code></pre>


<h3>Format</h3>

<p>A data frame of 357 rows representing Alaska Airlines flights and 19 variables
</p>

<dl>
<dt>year, month, day</dt><dd><p>Date of departure.</p>
</dd>
<dt>dep_time, arr_time</dt><dd><p>Actual departure and arrival times (format HHMM or HMM), local tz.</p>
</dd>
<dt>sched_dep_time, sched_arr_time</dt><dd><p>Scheduled departure and arrival times (format HHMM or HMM), local tz.</p>
</dd>
<dt>dep_delay, arr_delay</dt><dd><p>Departure and arrival delays, in minutes.
Negative times represent early departures/arrivals.</p>
</dd>
<dt>carrier</dt><dd><p>Two letter carrier abbreviation. See <code><a href="nycflights23.html#topic+airlines">nycflights23::airlines</a></code>
to get name.</p>
</dd>
<dt>flight</dt><dd><p>Flight number.</p>
</dd>
<dt>tailnum</dt><dd><p>Plane tail number. See <code><a href="nycflights23.html#topic+planes">nycflights23::planes</a></code> for additional metadata.</p>
</dd>
<dt>origin, dest</dt><dd><p>Origin and destination. See <code><a href="nycflights23.html#topic+airports">nycflights23::airports</a></code> for
additional metadata.</p>
</dd>
<dt>air_time</dt><dd><p>Amount of time spent in the air, in minutes.</p>
</dd>
<dt>distance</dt><dd><p>Distance between airports, in miles.</p>
</dd>
<dt>hour, minute</dt><dd><p>Time of scheduled departure broken into hour and minutes.</p>
</dd>
<dt>time_hour</dt><dd><p>Scheduled date and hour of the flight as a <code>POSIXct</code> date.
Along with <code>origin</code>, can be used to join flights data to <code><a href="nycflights23.html#topic+weather">nycflights23::weather</a></code> data.</p>
</dd>
</dl>



<h3>Source</h3>

<p>RITA, Bureau of transportation statistics
</p>


<h3>See Also</h3>

<p><code><a href="nycflights23.html#topic+flights">nycflights23::flights</a></code>.
</p>

<hr>
<h2 id='ev_charging'>Electric vehicle charging sessions for a workplace charging program</h2><span id='topic+ev_charging'></span>

<h3>Description</h3>

<p>This dataset consists of information on 3,395 electric vehicle charging sessions across
locations for a workplace charging program. The data contains information on multiple
charging sessions from 85 electric vehicle drivers across 25 workplace locations, which
are located at facilities of various types.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ev_charging
</code></pre>


<h3>Format</h3>

<p>A data frame of 3,395 rows on 24 variables, where each row is an electric vehicle
charging session.
</p>

<dl>
<dt>session_id</dt><dd><p>Unique identifier specifying the electric vehicle charging session</p>
</dd>
<dt>kwh_total</dt><dd><p>Total energy used at the charging session, in kilowatt hours (kWh)</p>
</dd>
<dt>dollars</dt><dd><p>Quantity of money paid for the charging session in U.S. dollars</p>
</dd>
<dt>created</dt><dd><p>Date and time recorded at the beginning of the charging session</p>
</dd>
<dt>ended</dt><dd><p>Date and time recorded at the end of the charging session</p>
</dd>
<dt>start_time</dt><dd><p>Hour of the day when the charging session began (1 through 24)</p>
</dd>
<dt>end_time</dt><dd><p>Hour of the day when the charging session ended (1 through 24)</p>
</dd>
<dt>charge_time_hrs</dt><dd><p>Length of the charging session in hours</p>
</dd>
<dt>weekday</dt><dd><p>First three characters of the name of the weekday when the charging session occurred</p>
</dd>
<dt>platform</dt><dd><p>Digital platform the driver used to record the session (android, ios, web)</p>
</dd>
<dt>distance</dt><dd><p>Distance from the charging location to the driver's home, expressed in miles
NA if the driver did not report their address</p>
</dd>
<dt>user_id</dt><dd><p>Unique identifier for each driver</p>
</dd>
<dt>station_id</dt><dd><p>Unique identifier for each charging station</p>
</dd>
<dt>location_id</dt><dd><p>Unique identifier for each location owned by the company where charging stations
were located</p>
</dd>
<dt>manager_vehicle</dt><dd><p>Binary variable that is 1 when the vehicle is a type commonly used
by managers of the firm and 0 otherwise</p>
</dd>
<dt>facility_type</dt><dd><p>Categorical variable that represents the facility type:
</p>

<ul>
<li><p> 1 = manufacturing
</p>
</li>
<li><p> 2 = office
</p>
</li>
<li><p> 3 = research and development
</p>
</li>
<li><p> 4 = other</p>
</li></ul>
 </dd>
<dt>mon, tues, wed, thurs, fri, sat, sun</dt><dd><p>Binary variables; 1 if the charging session took place on that day,
0 otherwise</p>
</dd>
<dt>reported_zip</dt><dd><p>Binary variable; 1 if the driver did report their zip code, 0 if they did not</p>
</dd>
</dl>



<h3>Source</h3>

<p>Harvard Dataverse <a href="https://doi.org/10.7910/DVN/NFPQLW">doi:10.7910/DVN/NFPQLW</a>.
Note data is released under a CC0: Public Domain license.
</p>

<hr>
<h2 id='evals'>Teaching evaluations at the UT Austin</h2><span id='topic+evals'></span>

<h3>Description</h3>

<p>The data are gathered from end of semester student evaluations for a sample of 463 courses taught by
94 professors from the University of Texas at Austin. In addition, six
students rate the professors' physical appearance. The result is a data frame
where each row contains a different course and each column has information on
either the course or the professor <a href="https://www.openintro.org/data/index.php?data=evals">https://www.openintro.org/data/index.php?data=evals</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evals
</code></pre>


<h3>Format</h3>

<p>A data frame with 463 observations corresponding to courses on the following 13 variables.
</p>

<dl>
<dt>ID</dt><dd><p>Identification variable for course.</p>
</dd>
<dt>prof_ID</dt><dd><p>Identification variable for professor. Many professors are included more than once in this dataset.</p>
</dd>
<dt>score</dt><dd><p>Average professor evaluation score: (1) very unsatisfactory - (5) excellent.</p>
</dd>
<dt>age</dt><dd><p>Age of professor.</p>
</dd>
<dt>bty_avg</dt><dd><p>Average beauty rating of professor.</p>
</dd>
<dt>gender</dt><dd><p>Gender of professor (collected as a binary variable at the time of the study): female, male.</p>
</dd>
<dt>ethnicity</dt><dd><p>Ethnicity of professor: not minority, minority.</p>
</dd>
<dt>language</dt><dd><p>Language of school where professor received education: English or non-English.</p>
</dd>
<dt>rank</dt><dd><p>Rank of professor: teaching, tenure track, tenured.</p>
</dd>
<dt>pic_outfit</dt><dd><p>Outfit of professor in picture: not formal, formal.</p>
</dd>
<dt>pic_color</dt><dd><p>Color of professor’s picture: color, black &amp; white.</p>
</dd>
<dt>cls_did_eval</dt><dd><p>Number of students in class who completed evaluation.</p>
</dd>
<dt>cls_students</dt><dd><p>Total number of students in class.</p>
</dd>
<dt>cls_level</dt><dd><p>Class level: lower, upper.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Çetinkaya-Rundel M, Morgan KL, Stangl D. 2013. Looking Good on Course Evaluations. CHANCE 26(2).
</p>


<h3>See Also</h3>

<p>The data in <code>evals</code> is a slight modification of <code><a href="openintro.html#topic+evals">openintro::evals()</a></code>.
</p>

<hr>
<h2 id='geom_categorical_model'>Regression model with one categorical explanatory/predictor variable</h2><span id='topic+geom_categorical_model'></span>

<h3>Description</h3>

<p><code>geom_categorical_model()</code> fits a regression model using the categorical
x axis as the explanatory variable, and visualizes the model's fitted values
as piece-wise horizontal line segments. Confidence interval bands can be
included in the visualization of the model. Like <code><a href="#topic+geom_parallel_slopes">geom_parallel_slopes()</a></code>,
this function has the same nature as <code>geom_smooth()</code> from
the <code>{ggplot2}</code> package, but provides functionality that <code>geom_smooth()</code>
currently doesn't have. When using a categorical predictor variable,
the intercept corresponds to the mean for the baseline group, while
coefficients for the non-baseline groups are offsets from this baseline.
Thus in the visualization the baseline for comparison group's median is
marked with a solid line, whereas all offset groups' medians are marked with
dashed lines.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>geom_categorical_model(
  mapping = NULL,
  data = NULL,
  position = "identity",
  ...,
  se = TRUE,
  level = 0.95,
  na.rm = FALSE,
  show.legend = NA,
  inherit.aes = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="geom_categorical_model_+3A_mapping">mapping</code></td>
<td>
<p>Set of aesthetic mappings created by <code><a href="ggplot2.html#topic+aes">aes()</a></code>. If specified and
<code>inherit.aes = TRUE</code> (the default), it is combined with the default mapping
at the top level of the plot. You must supply <code>mapping</code> if there is no plot
mapping.</p>
</td></tr>
<tr><td><code id="geom_categorical_model_+3A_data">data</code></td>
<td>
<p>The data to be displayed in this layer. There are three
options:
</p>
<p>If <code>NULL</code>, the default, the data is inherited from the plot
data as specified in the call to <code><a href="ggplot2.html#topic+ggplot">ggplot()</a></code>.
</p>
<p>A <code>data.frame</code>, or other object, will override the plot
data. All objects will be fortified to produce a data frame. See
<code><a href="ggplot2.html#topic+fortify">fortify()</a></code> for which variables will be created.
</p>
<p>A <code>function</code> will be called with a single argument,
the plot data. The return value must be a <code>data.frame</code>, and
will be used as the layer data. A <code>function</code> can be created
from a <code>formula</code> (e.g. <code>~ head(.x, 10)</code>).</p>
</td></tr>
<tr><td><code id="geom_categorical_model_+3A_position">position</code></td>
<td>
<p>A position adjustment to use on the data for this layer. This
can be used in various ways, including to prevent overplotting and
improving the display. The <code>position</code> argument accepts the following:
</p>

<ul>
<li><p> The result of calling a position function, such as <code>position_jitter()</code>.
This method allows for passing extra arguments to the position.
</p>
</li>
<li><p> A string naming the position adjustment. To give the position as a
string, strip the function name of the <code>position_</code> prefix. For example,
to use <code>position_jitter()</code>, give the position as <code>"jitter"</code>.
</p>
</li>
<li><p> For more information and other ways to specify the position, see the
<a href="ggplot2.html#topic+layer_positions">layer position</a> documentation.
</p>
</li></ul>
</td></tr>
<tr><td><code id="geom_categorical_model_+3A_...">...</code></td>
<td>
<p>Other arguments passed on to <code><a href="ggplot2.html#topic+layer">layer()</a></code>'s <code>params</code> argument. These
arguments broadly fall into one of 4 categories below. Notably, further
arguments to the <code>position</code> argument, or aesthetics that are required
can <em>not</em> be passed through <code>...</code>. Unknown arguments that are not part
of the 4 categories below are ignored.
</p>

<ul>
<li><p> Static aesthetics that are not mapped to a scale, but are at a fixed
value and apply to the layer as a whole. For example, <code>colour = "red"</code>
or <code>linewidth = 3</code>. The geom's documentation has an <strong>Aesthetics</strong>
section that lists the available options. The 'required' aesthetics
cannot be passed on to the <code>params</code>. Please note that while passing
unmapped aesthetics as vectors is technically possible, the order and
required length is not guaranteed to be parallel to the input data.
</p>
</li>
<li><p> When constructing a layer using
a <code style="white-space: pre;">&#8288;stat_*()&#8288;</code> function, the <code>...</code> argument can be used to pass on
parameters to the <code>geom</code> part of the layer. An example of this is
<code>stat_density(geom = "area", outline.type = "both")</code>. The geom's
documentation lists which parameters it can accept.
</p>
</li>
<li><p> Inversely, when constructing a layer using a
<code style="white-space: pre;">&#8288;geom_*()&#8288;</code> function, the <code>...</code> argument can be used to pass on parameters
to the <code>stat</code> part of the layer. An example of this is
<code>geom_area(stat = "density", adjust = 0.5)</code>. The stat's documentation
lists which parameters it can accept.
</p>
</li>
<li><p> The <code>key_glyph</code> argument of <code><a href="ggplot2.html#topic+layer">layer()</a></code> may also be passed on through
<code>...</code>. This can be one of the functions described as
<a href="ggplot2.html#topic+draw_key">key glyphs</a>, to change the display of the layer in the legend.
</p>
</li></ul>
</td></tr>
<tr><td><code id="geom_categorical_model_+3A_se">se</code></td>
<td>
<p>Display confidence interval around model lines? <code>TRUE</code> by
default.</p>
</td></tr>
<tr><td><code id="geom_categorical_model_+3A_level">level</code></td>
<td>
<p>Level of confidence interval to use (0.95 by default).</p>
</td></tr>
<tr><td><code id="geom_categorical_model_+3A_na.rm">na.rm</code></td>
<td>
<p>If <code>FALSE</code>, the default, missing values are removed with
a warning. If <code>TRUE</code>, missing values are silently removed.</p>
</td></tr>
<tr><td><code id="geom_categorical_model_+3A_show.legend">show.legend</code></td>
<td>
<p>logical. Should this layer be included in the legends?
<code>NA</code>, the default, includes if any aesthetics are mapped.
<code>FALSE</code> never includes, and <code>TRUE</code> always includes.
It can also be a named logical vector to finely select the aesthetics to
display.</p>
</td></tr>
<tr><td><code id="geom_categorical_model_+3A_inherit.aes">inherit.aes</code></td>
<td>
<p>If <code>FALSE</code>, overrides the default aesthetics,
rather than combining with them. This is most useful for helper functions
that define both data and aesthetics and shouldn't inherit behaviour from
the default plot specification, e.g. <code><a href="ggplot2.html#topic+borders">borders()</a></code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+geom_parallel_slopes">geom_parallel_slopes()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(dplyr)
library(ggplot2)

p &lt;- ggplot(mpg, aes(x = drv, y = hwy)) +
  geom_point() +
  geom_categorical_model()
p

# In the above visualization, the solid line corresponds to the mean of 19.2
# for the baseline group "4", whereas the dashed lines correspond to the
# means of 28.19 and 21.02 for the non-baseline groups "f" and "r" respectively.
# In the corresponding regression table however the coefficients for "f" and "r"
# are presented as offsets from the mean for "4":
model &lt;- lm(hwy ~ drv, data = mpg)
get_regression_table(model)

# You can use different colors for each categorical level
p %+% aes(color = drv)

# But mapping the color aesthetic doesn't change the model that is fit
p %+% aes(color = class)
</code></pre>

<hr>
<h2 id='geom_parallel_slopes'>Parallel slopes regression model</h2><span id='topic+geom_parallel_slopes'></span>

<h3>Description</h3>

<p><code>geom_parallel_slopes()</code> fits parallel slopes model and adds its line
output(s) to a <code>ggplot</code> object. Basically, it fits a unified model with
intercepts varying between groups (which should be supplied as standard
<code>{ggplot2}</code> grouping aesthetics: <code>group</code>, <code>color</code>, <code>fill</code>,
etc.). This function has the same nature as <code>geom_smooth()</code> from
<code>{ggplot2}</code> package, but provides functionality that <code>geom_smooth()</code>
currently doesn't have.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>geom_parallel_slopes(
  mapping = NULL,
  data = NULL,
  position = "identity",
  ...,
  se = TRUE,
  formula = y ~ x,
  n = 100,
  fullrange = FALSE,
  level = 0.95,
  na.rm = FALSE,
  show.legend = NA,
  inherit.aes = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="geom_parallel_slopes_+3A_mapping">mapping</code></td>
<td>
<p>Set of aesthetic mappings created by <code><a href="ggplot2.html#topic+aes">aes()</a></code>. If specified and
<code>inherit.aes = TRUE</code> (the default), it is combined with the default mapping
at the top level of the plot. You must supply <code>mapping</code> if there is no plot
mapping.</p>
</td></tr>
<tr><td><code id="geom_parallel_slopes_+3A_data">data</code></td>
<td>
<p>The data to be displayed in this layer. There are three
options:
</p>
<p>If <code>NULL</code>, the default, the data is inherited from the plot
data as specified in the call to <code><a href="ggplot2.html#topic+ggplot">ggplot()</a></code>.
</p>
<p>A <code>data.frame</code>, or other object, will override the plot
data. All objects will be fortified to produce a data frame. See
<code><a href="ggplot2.html#topic+fortify">fortify()</a></code> for which variables will be created.
</p>
<p>A <code>function</code> will be called with a single argument,
the plot data. The return value must be a <code>data.frame</code>, and
will be used as the layer data. A <code>function</code> can be created
from a <code>formula</code> (e.g. <code>~ head(.x, 10)</code>).</p>
</td></tr>
<tr><td><code id="geom_parallel_slopes_+3A_position">position</code></td>
<td>
<p>A position adjustment to use on the data for this layer. This
can be used in various ways, including to prevent overplotting and
improving the display. The <code>position</code> argument accepts the following:
</p>

<ul>
<li><p> The result of calling a position function, such as <code>position_jitter()</code>.
This method allows for passing extra arguments to the position.
</p>
</li>
<li><p> A string naming the position adjustment. To give the position as a
string, strip the function name of the <code>position_</code> prefix. For example,
to use <code>position_jitter()</code>, give the position as <code>"jitter"</code>.
</p>
</li>
<li><p> For more information and other ways to specify the position, see the
<a href="ggplot2.html#topic+layer_positions">layer position</a> documentation.
</p>
</li></ul>
</td></tr>
<tr><td><code id="geom_parallel_slopes_+3A_...">...</code></td>
<td>
<p>Other arguments passed on to <code><a href="ggplot2.html#topic+layer">layer()</a></code>'s <code>params</code> argument. These
arguments broadly fall into one of 4 categories below. Notably, further
arguments to the <code>position</code> argument, or aesthetics that are required
can <em>not</em> be passed through <code>...</code>. Unknown arguments that are not part
of the 4 categories below are ignored.
</p>

<ul>
<li><p> Static aesthetics that are not mapped to a scale, but are at a fixed
value and apply to the layer as a whole. For example, <code>colour = "red"</code>
or <code>linewidth = 3</code>. The geom's documentation has an <strong>Aesthetics</strong>
section that lists the available options. The 'required' aesthetics
cannot be passed on to the <code>params</code>. Please note that while passing
unmapped aesthetics as vectors is technically possible, the order and
required length is not guaranteed to be parallel to the input data.
</p>
</li>
<li><p> When constructing a layer using
a <code style="white-space: pre;">&#8288;stat_*()&#8288;</code> function, the <code>...</code> argument can be used to pass on
parameters to the <code>geom</code> part of the layer. An example of this is
<code>stat_density(geom = "area", outline.type = "both")</code>. The geom's
documentation lists which parameters it can accept.
</p>
</li>
<li><p> Inversely, when constructing a layer using a
<code style="white-space: pre;">&#8288;geom_*()&#8288;</code> function, the <code>...</code> argument can be used to pass on parameters
to the <code>stat</code> part of the layer. An example of this is
<code>geom_area(stat = "density", adjust = 0.5)</code>. The stat's documentation
lists which parameters it can accept.
</p>
</li>
<li><p> The <code>key_glyph</code> argument of <code><a href="ggplot2.html#topic+layer">layer()</a></code> may also be passed on through
<code>...</code>. This can be one of the functions described as
<a href="ggplot2.html#topic+draw_key">key glyphs</a>, to change the display of the layer in the legend.
</p>
</li></ul>
</td></tr>
<tr><td><code id="geom_parallel_slopes_+3A_se">se</code></td>
<td>
<p>Display confidence interval around model lines? <code>TRUE</code> by
default.</p>
</td></tr>
<tr><td><code id="geom_parallel_slopes_+3A_formula">formula</code></td>
<td>
<p>Formula to use per group in parallel slopes model. Basic
linear <code>y ~ x</code> by default.</p>
</td></tr>
<tr><td><code id="geom_parallel_slopes_+3A_n">n</code></td>
<td>
<p>Number of points per group at which to evaluate model.</p>
</td></tr>
<tr><td><code id="geom_parallel_slopes_+3A_fullrange">fullrange</code></td>
<td>
<p>If <code>TRUE</code>, the smoothing line gets expanded to the range of the plot,
potentially beyond the data. This does not extend the line into any additional padding
created by <code>expansion</code>.</p>
</td></tr>
<tr><td><code id="geom_parallel_slopes_+3A_level">level</code></td>
<td>
<p>Level of confidence interval to use (0.95 by default).</p>
</td></tr>
<tr><td><code id="geom_parallel_slopes_+3A_na.rm">na.rm</code></td>
<td>
<p>If <code>FALSE</code>, the default, missing values are removed with
a warning. If <code>TRUE</code>, missing values are silently removed.</p>
</td></tr>
<tr><td><code id="geom_parallel_slopes_+3A_show.legend">show.legend</code></td>
<td>
<p>logical. Should this layer be included in the legends?
<code>NA</code>, the default, includes if any aesthetics are mapped.
<code>FALSE</code> never includes, and <code>TRUE</code> always includes.
It can also be a named logical vector to finely select the aesthetics to
display.</p>
</td></tr>
<tr><td><code id="geom_parallel_slopes_+3A_inherit.aes">inherit.aes</code></td>
<td>
<p>If <code>FALSE</code>, overrides the default aesthetics,
rather than combining with them. This is most useful for helper functions
that define both data and aesthetics and shouldn't inherit behaviour from
the default plot specification, e.g. <code><a href="ggplot2.html#topic+borders">borders()</a></code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+geom_categorical_model">geom_categorical_model()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(dplyr)
library(ggplot2)

ggplot(evals, aes(x = age, y = score, color = ethnicity)) +
  geom_point() +
  geom_parallel_slopes(se = FALSE)

# Basic usage
ggplot(evals, aes(x = age, y = score, color = ethnicity)) +
  geom_point() +
  geom_parallel_slopes()
ggplot(evals, aes(x = age, y = score, color = ethnicity)) +
  geom_point() +
  geom_parallel_slopes(se = FALSE)

# Supply custom aesthetics
ggplot(evals, aes(x = age, y = score, color = ethnicity)) +
  geom_point() +
  geom_parallel_slopes(se = FALSE, size = 4)

# Fit non-linear model
example_df &lt;- house_prices %&gt;%
  slice(1:1000) %&gt;%
  mutate(
    log10_price = log10(price),
    log10_size = log10(sqft_living)
  )
ggplot(example_df, aes(x = log10_size, y = log10_price, color = condition)) +
  geom_point(alpha = 0.1) +
  geom_parallel_slopes(formula = y ~ poly(x, 2))

# Different grouping
ggplot(example_df, aes(x = log10_size, y = log10_price)) +
  geom_point(alpha = 0.1) +
  geom_parallel_slopes(aes(fill = condition))
</code></pre>

<hr>
<h2 id='get_correlation'>Get correlation value in a tidy way</h2><span id='topic+get_correlation'></span>

<h3>Description</h3>

<p>Determine the Pearson correlation coefficient between two variables in
a data frame using pipeable and formula-friendly syntax
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_correlation(data, formula, na.rm = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_correlation_+3A_data">data</code></td>
<td>
<p>a data frame object</p>
</td></tr>
<tr><td><code id="get_correlation_+3A_formula">formula</code></td>
<td>
<p>a formula with the response variable name on the left and
the explanatory variable name on the right</p>
</td></tr>
<tr><td><code id="get_correlation_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical value indicating whether NA values should be stripped
before the computation proceeds.</p>
</td></tr>
<tr><td><code id="get_correlation_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="stats.html#topic+cor">stats::cor()</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A 1x1 data frame storing the correlation value
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(moderndive)

# Compute correlation between mpg and cyl:
mtcars %&gt;%
  get_correlation(formula = mpg ~ cyl)

# Group by one variable:
library(dplyr)
mtcars %&gt;%
  group_by(am) %&gt;%
  get_correlation(formula = mpg ~ cyl)

# Group by two variables:
mtcars %&gt;%
  group_by(am, gear) %&gt;%
  get_correlation(formula = mpg ~ cyl)
</code></pre>

<hr>
<h2 id='get_regression_points'>Get regression points</h2><span id='topic+get_regression_points'></span>

<h3>Description</h3>

<p>Output information on each point/observation used in an <code>lm()</code> regression in
&quot;tidy&quot; format. This function is a wrapper function for <code>broom::augment()</code>
and renames the variables to have more intuitive names.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_regression_points(
  model,
  digits = 3,
  print = FALSE,
  newdata = NULL,
  ID = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_regression_points_+3A_model">model</code></td>
<td>
<p>an <code>lm()</code> model object</p>
</td></tr>
<tr><td><code id="get_regression_points_+3A_digits">digits</code></td>
<td>
<p>number of digits precision in output table</p>
</td></tr>
<tr><td><code id="get_regression_points_+3A_print">print</code></td>
<td>
<p>If TRUE, return in print format suitable for R Markdown</p>
</td></tr>
<tr><td><code id="get_regression_points_+3A_newdata">newdata</code></td>
<td>
<p>A new data frame of points/observations to apply <code>model</code> to
obtain new fitted values and/or predicted values y-hat. Note the format of
<code>newdata</code> must match the format of the original <code>data</code> used to fit
<code>model</code>.</p>
</td></tr>
<tr><td><code id="get_regression_points_+3A_id">ID</code></td>
<td>
<p>A string indicating which variable in either the original data used to fit
<code>model</code> or <code>newdata</code> should be used as
an identification variable to distinguish the observational units
in each row. This variable will be the left-most variable in the output data
frame. If <code>ID</code> is unspecified, a column <code>ID</code> with values 1 through the number of
rows is returned as the identification variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble-formatted regression table of outcome/response variable,
all explanatory/predictor variables, the fitted/predicted value, and residual.
</p>


<h3>See Also</h3>

<p><code><a href="broom.html#topic+reexports">augment()</a></code>, <code><a href="#topic+get_regression_table">get_regression_table()</a></code>, <code><a href="#topic+get_regression_summaries">get_regression_summaries()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(dplyr)
library(tibble)

# Convert rownames to column
mtcars &lt;- mtcars %&gt;%
  rownames_to_column(var = "automobile")

# Fit lm() regression:
mpg_model &lt;- lm(mpg ~ cyl, data = mtcars)

# Get information on all points in regression:
get_regression_points(mpg_model, ID = "automobile")

# Create training and test set based on mtcars:
training_set &lt;- mtcars %&gt;%
  sample_frac(0.5)
test_set &lt;- mtcars %&gt;%
  anti_join(training_set, by = "automobile")

# Fit model to training set:
mpg_model_train &lt;- lm(mpg ~ cyl, data = training_set)

# Make predictions on test set:
get_regression_points(mpg_model_train, newdata = test_set, ID = "automobile")
</code></pre>

<hr>
<h2 id='get_regression_summaries'>Get regression summary values</h2><span id='topic+get_regression_summaries'></span>

<h3>Description</h3>

<p>Output scalar summary statistics for an <code>lm()</code> regression in &quot;tidy&quot;
format. This function is a wrapper function for <code>broom::glance()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_regression_summaries(model, digits = 3, print = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_regression_summaries_+3A_model">model</code></td>
<td>
<p>an <code>lm()</code> model object</p>
</td></tr>
<tr><td><code id="get_regression_summaries_+3A_digits">digits</code></td>
<td>
<p>number of digits precision in output table</p>
</td></tr>
<tr><td><code id="get_regression_summaries_+3A_print">print</code></td>
<td>
<p>If TRUE, return in print format suitable for R Markdown</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A single-row tibble with regression summaries. Ex: <code>r_squared</code> and <code>mse</code>.
</p>


<h3>See Also</h3>

<p><code><a href="broom.html#topic+reexports">glance()</a></code>, <code><a href="#topic+get_regression_table">get_regression_table()</a></code>, <code><a href="#topic+get_regression_points">get_regression_points()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(moderndive)

# Fit lm() regression:
mpg_model &lt;- lm(mpg ~ cyl, data = mtcars)

# Get regression summaries:
get_regression_summaries(mpg_model)
</code></pre>

<hr>
<h2 id='get_regression_table'>Get regression table</h2><span id='topic+get_regression_table'></span>

<h3>Description</h3>

<p>Output regression table for an <code>lm()</code> regression in &quot;tidy&quot; format. This function
is a wrapper function for <code>broom::tidy()</code> and includes confidence
intervals in the output table by default.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_regression_table(
  model,
  conf.level = 0.95,
  digits = 3,
  print = FALSE,
  default_categorical_levels = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_regression_table_+3A_model">model</code></td>
<td>
<p>an <code>lm()</code> model object</p>
</td></tr>
<tr><td><code id="get_regression_table_+3A_conf.level">conf.level</code></td>
<td>
<p>The confidence level to use for the confidence interval
if <code>conf.int = TRUE</code>. Must be strictly greater than 0 and less than 1.
Defaults to 0.95, which corresponds to a 95 percent confidence interval.</p>
</td></tr>
<tr><td><code id="get_regression_table_+3A_digits">digits</code></td>
<td>
<p>number of digits precision in output table</p>
</td></tr>
<tr><td><code id="get_regression_table_+3A_print">print</code></td>
<td>
<p>If TRUE, return in print format suitable for R Markdown</p>
</td></tr>
<tr><td><code id="get_regression_table_+3A_default_categorical_levels">default_categorical_levels</code></td>
<td>
<p>If TRUE, do not change the non-baseline
categorical variables in the term column. Otherwise non-baseline
categorical variables will be displayed in the format
&quot;categorical_variable_name: level_name&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble-formatted regression table along with lower and upper end
points of all confidence intervals for all parameters <code>lower_ci</code> and
<code>upper_ci</code>; the confidence levels default to 95\
</p>


<h3>See Also</h3>

<p><code><a href="broom.html#topic+reexports">tidy()</a></code>, <code><a href="#topic+get_regression_points">get_regression_points()</a></code>, <code><a href="#topic+get_regression_summaries">get_regression_summaries()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(moderndive)

# Fit lm() regression:
mpg_model &lt;- lm(mpg ~ cyl, data = mtcars)

# Get regression table:
get_regression_table(mpg_model)

# Vary confidence level of confidence intervals
get_regression_table(mpg_model, conf.level = 0.99)
</code></pre>

<hr>
<h2 id='gg_parallel_slopes'>Plot parallel slopes model</h2><span id='topic+gg_parallel_slopes'></span>

<h3>Description</h3>

<p>NOTE: This function is deprecated; please use <code><a href="#topic+geom_parallel_slopes">geom_parallel_slopes()</a></code>
instead. Output a visualization of linear regression when you have one numerical
and one categorical explanatory/predictor variable: a separate colored
regression line for each level of the categorical variable
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gg_parallel_slopes(y, num_x, cat_x, data, alpha = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gg_parallel_slopes_+3A_y">y</code></td>
<td>
<p>Character string of outcome variable in <code>data</code></p>
</td></tr>
<tr><td><code id="gg_parallel_slopes_+3A_num_x">num_x</code></td>
<td>
<p>Character string of numerical explanatory/predictor variable in
<code>data</code></p>
</td></tr>
<tr><td><code id="gg_parallel_slopes_+3A_cat_x">cat_x</code></td>
<td>
<p>Character string of categorical explanatory/predictor variable
in <code>data</code></p>
</td></tr>
<tr><td><code id="gg_parallel_slopes_+3A_data">data</code></td>
<td>
<p>an optional data frame, list or environment (or object
coercible by <code><a href="base.html#topic+as.data.frame">as.data.frame</a></code> to a data frame) containing
the variables in the model.  If not found in <code>data</code>, the
variables are taken from <code>environment(formula)</code>,
typically the environment from which <code>lm</code> is called.</p>
</td></tr>
<tr><td><code id="gg_parallel_slopes_+3A_alpha">alpha</code></td>
<td>
<p>Transparency of points</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code><a href="ggplot2.html#topic+ggplot">ggplot2::ggplot()</a></code> object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+geom_parallel_slopes">geom_parallel_slopes()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(ggplot2)
library(dplyr)
library(moderndive)

# log10() transformations
house_prices &lt;- house_prices %&gt;%
  mutate(
    log10_price = log10(price),
    log10_size = log10(sqft_living)
  )

# Output parallel slopes model plot:
gg_parallel_slopes(
  y = "log10_price", num_x = "log10_size", cat_x = "condition",
  data = house_prices, alpha = 0.1
) +
  labs(
    x = "log10 square feet living space", y = "log10 price in USD",
    title = "House prices in Seattle: Parallel slopes model"
  )

# Compare with interaction model plot:
ggplot(house_prices, aes(x = log10_size, y = log10_price, col = condition)) +
  geom_point(alpha = 0.1) +
  geom_smooth(method = "lm", se = FALSE, size = 1) +
  labs(
    x = "log10 square feet living space", y = "log10 price in USD",
    title = "House prices in Seattle: Interaction model"
  )

## End(Not run)
</code></pre>

<hr>
<h2 id='house_prices'>House Sales in King County, USA</h2><span id='topic+house_prices'></span>

<h3>Description</h3>

<p>This dataset contains house sale prices for King County, which includes
Seattle. It includes homes sold between May 2014 and May 2015. This dataset
was obtained from Kaggle.com <a href="https://www.kaggle.com/harlfoxem/housesalesprediction/data">https://www.kaggle.com/harlfoxem/housesalesprediction/data</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>house_prices
</code></pre>


<h3>Format</h3>

<p>A data frame with 21613 observations on the following 21 variables.
</p>

<dl>
<dt>id</dt><dd><p>a notation for a house</p>
</dd>
<dt>date</dt><dd><p>Date house was sold</p>
</dd>
<dt>price</dt><dd><p>Price is prediction target</p>
</dd>
<dt>bedrooms</dt><dd><p>Number of Bedrooms/House</p>
</dd>
<dt>bathrooms</dt><dd><p>Number of bathrooms/bedrooms</p>
</dd>
<dt>sqft_living</dt><dd><p>square footage of the home</p>
</dd>
<dt>sqft_lot</dt><dd><p>square footage of the lot</p>
</dd>
<dt>floors</dt><dd><p>Total floors (levels) in house</p>
</dd>
<dt>waterfront</dt><dd><p>House which has a view to a waterfront</p>
</dd>
<dt>view</dt><dd><p>Has been viewed</p>
</dd>
<dt>condition</dt><dd><p>How good the condition is (Overall)</p>
</dd>
<dt>grade</dt><dd><p>overall grade given to the housing unit, based on King County grading system</p>
</dd>
<dt>sqft_above</dt><dd><p>square footage of house apart from basement</p>
</dd>
<dt>sqft_basement</dt><dd><p>square footage of the basement</p>
</dd>
<dt>yr_built</dt><dd><p>Built Year</p>
</dd>
<dt>yr_renovated</dt><dd><p>Year when house was renovated</p>
</dd>
<dt>zipcode</dt><dd><p>zip code</p>
</dd>
<dt>lat</dt><dd><p>Latitude coordinate</p>
</dd>
<dt>long</dt><dd><p>Longitude coordinate</p>
</dd>
<dt>sqft_living15</dt><dd><p>Living room area in 2015 (implies&ndash; some renovations) This might or might not have affected the lotsize area</p>
</dd>
<dt>sqft_lot15</dt><dd><p>lotSize area in 2015 (implies&ndash; some renovations)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Kaggle <a href="https://www.kaggle.com/harlfoxem/housesalesprediction">https://www.kaggle.com/harlfoxem/housesalesprediction</a>.
Note data is released under a CC0: Public Domain license.
</p>

<hr>
<h2 id='ipf_lifts'>International Power Lifting Results
A subset of international powerlifting results.</h2><span id='topic+ipf_lifts'></span>

<h3>Description</h3>

<p>International Power Lifting Results
A subset of international powerlifting results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ipf_lifts
</code></pre>


<h3>Format</h3>

<p>A data frame with 41,152 entries, one entry for individual lifter
</p>

<dl>
<dt>name</dt><dd><p>Individual lifter name</p>
</dd>
<dt>sex</dt><dd><p>Binary sex (M/F)</p>
</dd>
<dt>event</dt><dd><p>The type of competition that the lifter entered</p>
</dd>
<dt>equipment</dt><dd><p>The equipment category under which the lifts were performed</p>
</dd>
<dt>age</dt><dd><p>The age of the lifter on the start date of the meet</p>
</dd>
<dt>age_class</dt><dd><p>The age class in which the filter falls</p>
</dd>
<dt>division</dt><dd><p>division of competition</p>
</dd>
<dt>bodyweight_kg</dt><dd><p>The recorded bodyweight of the lifter at the time of competition, to two decimal places</p>
</dd>
<dt>weight_class_kg</dt><dd><p>The weight class in which the lifter competed, to two decimal places</p>
</dd>
<dt>best3squat_kg</dt><dd><p>Maximum of the first three successful attempts for the lift</p>
</dd>
<dt>best3bench_kg</dt><dd><p>Maximum of the first three successful attempts for the lift</p>
</dd>
<dt>best3deadlift_kg</dt><dd><p>Maximum of the first three successful attempts for the lift</p>
</dd>
<dt>place</dt><dd><p>The recorded place of the lifter in the given division at the end of the meet</p>
</dd>
<dt>date</dt><dd><p>Date of the event</p>
</dd>
<dt>federation</dt><dd><p>The federation that hosted the meet</p>
</dd>
<dt>meet_name</dt><dd><p>The name of the meet</p>
</dd>
</dl>



<h3>Source</h3>

<p>This data is a subset of the open dataset <a href="https://www.openpowerlifting.org/">Open Powerlifting</a>
</p>

<hr>
<h2 id='MA_schools'>Massachusetts Public High Schools Data</h2><span id='topic+MA_schools'></span>

<h3>Description</h3>

<p>Data on Massachusetts public high schools in 2017
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MA_schools
</code></pre>


<h3>Format</h3>

<p>A data frame of 332 rows representing Massachusetts high schools and 4 variables
</p>

<dl>
<dt>school_name</dt><dd><p>High school name.</p>
</dd>
<dt>average_sat_math</dt><dd><p>Average SAT math score. Note 58 of the original 390 values of this variable were missing; these rows were dropped from consideration.</p>
</dd>
<dt>perc_disadvan</dt><dd><p>Percent of the student body that are considered economically disadvantaged.</p>
</dd>
<dt>size</dt><dd><p>Size of school enrollment; small 13-341 students, medium 342-541 students, large 542-4264 students.</p>
</dd>
</dl>



<h3>Source</h3>

<p>The original source of the data are Massachusetts Department of
Education reports <a href="https://profiles.doe.mass.edu/state_report/">https://profiles.doe.mass.edu/state_report/</a>, however
the data was downloaded from Kaggle at <a href="https://www.kaggle.com/ndalziel/massachusetts-public-schools-data">https://www.kaggle.com/ndalziel/massachusetts-public-schools-data</a>
</p>

<hr>
<h2 id='ma_traffic_2020_vs_2019'>Massachusetts 2020 vs. 2019 Traffic Data Comparison</h2><span id='topic+ma_traffic_2020_vs_2019'></span>

<h3>Description</h3>

<p>This dataset contains information about changes in speed, volume, and accidents of traffic
between 2020 and 2019 by community and class of road in Massachusetts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ma_traffic_2020_vs_2019
</code></pre>


<h3>Format</h3>

<p>A data frame of 264 rows each representing a different community in Massachusetts.
</p>

<dl>
<dt>community</dt><dd><p>City or Town</p>
</dd>
<dt>functional_class</dt><dd><p>Class or group the road belongs to</p>
</dd>
<dt>change_in_speed</dt><dd><p>Average estimated Speed (mph)</p>
</dd>
<dt>change_in_volume</dt><dd><p>Average traffic</p>
</dd>
<dt>change_in_accidents</dt><dd><p>Average number of accidents</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://massdot-impact-crashes-vhb.opendata.arcgis.com/datasets/MassDOT::2020-vehicle-level-crash-details/explore">https://massdot-impact-crashes-vhb.opendata.arcgis.com/datasets/MassDOT::2020-vehicle-level-crash-details/explore</a>
<a href="https://mhd.public.ms2soft.com/tcds/tsearch.asp?loc=Mhd&amp;mod=">https://mhd.public.ms2soft.com/tcds/tsearch.asp?loc=Mhd&amp;mod=</a>
</p>

<hr>
<h2 id='mario_kart_auction'>Data from Mario Kart Ebay auctions</h2><span id='topic+mario_kart_auction'></span>

<h3>Description</h3>

<p>Ebay auction data for the Nintendo Wii game Mario Kart.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mario_kart_auction
</code></pre>


<h3>Format</h3>

<p>A data frame of 143 auctions.
</p>

<dl>
<dt>id</dt><dd><p>Auction ID assigned by Ebay</p>
</dd>
<dt>duration</dt><dd><p>Auction length in days</p>
</dd>
<dt>n_bids</dt><dd><p>Number of bids</p>
</dd>
<dt>cond</dt><dd><p>Game condition, either <code>new</code> or <code>used</code></p>
</dd>
<dt>start_pr</dt><dd><p>Price at the start of the auction</p>
</dd>
<dt>ship_pr</dt><dd><p>Shipping price</p>
</dd>
<dt>total_pr</dt><dd><p>Total price, equal to auction price plus shipping price</p>
</dd>
<dt>ship_sp</dt><dd><p>Shipping speed or method</p>
</dd>
<dt>seller_rate</dt><dd><p>Seller's rating on Ebay, equal to the number of positive ratings minus the number of negative ratings</p>
</dd>
<dt>stock_photo</dt><dd><p>Whether the auction photo was a stock photo or not, pictures used in many options were considered stock photos</p>
</dd>
<dt>wheels</dt><dd><p>Number of Wii wheels included in the auction</p>
</dd>
<dt>title</dt><dd><p>The title of the auctions</p>
</dd>
</dl>



<h3>Source</h3>

<p>This data is from <a href="https://www.openintro.org/data/index.php?data=mariokart">https://www.openintro.org/data/index.php?data=mariokart</a>
</p>

<hr>
<h2 id='mass_traffic_2020'>2020 road traffic volume and crash level date for 13 Massachusetts counties</h2><span id='topic+mass_traffic_2020'></span>

<h3>Description</h3>

<p>2020 road traffic volume and crash level date for 13 Massachusetts counties
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mass_traffic_2020
</code></pre>


<h3>Format</h3>

<p>A data frame of 874 rows representing traffic data at the 874 sites
</p>

<dl>
<dt>site_id</dt><dd><p>Site id</p>
</dd>
<dt>county</dt><dd><p>County in which the site is located</p>
</dd>
<dt>community</dt><dd><p>Community in which the site is located</p>
</dd>
<dt>rural_urban</dt><dd><p>Rural (R) or Urban (U)</p>
</dd>
<dt>dir</dt><dd><p>Direction for traffic movement. Either 1-WAY, 2-WAY, EB (eastbound), RAMP or WB (westbound)</p>
</dd>
<dt>functional_class</dt><dd><p>Classification of road. Either Arterial, Collector, Freeway &amp; Expressway, Interstate or Local Road</p>
</dd>
<dt>avg_speed</dt><dd><p>Average traffic speed</p>
</dd>
<dt>total_volume</dt><dd><p>Number of vehicles recorded at each site in 2020</p>
</dd>
<dt>crashes</dt><dd><p>Number of vehicle crashes at each site</p>
</dd>
<dt>nonfatal_injuries</dt><dd><p>Number of non-fatal injuries for all recorded vehicle crashes</p>
</dd>
<dt>fatal_injuries</dt><dd><p>Number of fatal injuries for all recorded vehicle crashes</p>
</dd>
</dl>


<hr>
<h2 id='movies_sample'>Random sample of 68 action and romance movies</h2><span id='topic+movies_sample'></span>

<h3>Description</h3>

<p>A random sample of 32 action movies and 36 romance movies from
<a href="https://www.imdb.com/">https://www.imdb.com/</a> and their ratings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>movies_sample
</code></pre>


<h3>Format</h3>

<p>A data frame of 68 rows movies.
</p>

<dl>
<dt>title</dt><dd><p>Movie title</p>
</dd>
<dt>year</dt><dd><p>Year released</p>
</dd>
<dt>rating</dt><dd><p>IMDb rating out of 10 stars</p>
</dd>
<dt>genre</dt><dd><p>Action or Romance</p>
</dd>
</dl>



<h3>See Also</h3>

<p>This data was sampled from the <code>movies</code> data frame in the <code>ggplot2movies</code> package.
</p>

<hr>
<h2 id='mythbusters_yawn'>Data from Mythbusters' study on contagiousness of yawning</h2><span id='topic+mythbusters_yawn'></span>

<h3>Description</h3>

<p>From a study on whether yawning is contagious
<a href="https://www.imdb.com/title/tt0768479/">https://www.imdb.com/title/tt0768479/</a>.
The data here was derived from the final proportions of yawns given
in the show.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mythbusters_yawn
</code></pre>


<h3>Format</h3>

<p>A data frame of 50 rows representing each of the 50 participants
in the study.
</p>

<dl>
<dt>subj</dt><dd><p>integer value corresponding to identifier variable of
subject ID</p>
</dd>
<dt>group</dt><dd><p>string of either <code>"seed"</code>, participant was shown a
yawner, or <code>"control"</code>, participant was not shown a yawner</p>
</dd>
<dt>yawn</dt><dd><p>string of either <code>"yes"</code>, the participant yawned, or
<code>"no"</code>, the participant did not yawn</p>
</dd>
</dl>


<hr>
<h2 id='orig_pennies_sample'>A random sample of 40 pennies sampled from the <code>pennies</code> data frame</h2><span id='topic+orig_pennies_sample'></span>

<h3>Description</h3>

<p>A dataset of 40 pennies to be treated as a random sample with <code><a href="#topic+pennies">pennies()</a></code> acting
as the population. Data on these pennies were recorded in 2011.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>orig_pennies_sample
</code></pre>


<h3>Format</h3>

<p>A data frame of 40 rows representing 40 randomly sampled pennies from <code><a href="#topic+pennies">pennies()</a></code> and 2 variables
</p>

<dl>
<dt>year</dt><dd><p>Year of minting</p>
</dd>
<dt>age_in_2011</dt><dd><p>Age in 2011</p>
</dd>
</dl>



<h3>Source</h3>

<p>StatCrunch <a href="https://www.statcrunch.com:443/app/index.html?dataid=301596">https://www.statcrunch.com:443/app/index.html?dataid=301596</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pennies">pennies()</a></code>
</p>

<hr>
<h2 id='pennies'>A population of 800 pennies sampled in 2011</h2><span id='topic+pennies'></span>

<h3>Description</h3>

<p>A dataset of 800 pennies to be treated as a sampling population. Data on
these pennies were recorded in 2011.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pennies
</code></pre>


<h3>Format</h3>

<p>A data frame of 800 rows representing different pennies and 2 variables
</p>

<dl>
<dt>year</dt><dd><p>Year of minting</p>
</dd>
<dt>age_in_2011</dt><dd><p>Age in 2011</p>
</dd>
</dl>



<h3>Source</h3>

<p>StatCrunch <a href="https://www.statcrunch.com:443/app/index.html?dataid=301596">https://www.statcrunch.com:443/app/index.html?dataid=301596</a>
</p>

<hr>
<h2 id='pennies_resamples'>Bootstrap resamples of a sample of 50 pennies</h2><span id='topic+pennies_resamples'></span>

<h3>Description</h3>

<p>35 bootstrap resamples with replacement of sample of 50 pennies contained in
a 50 cent roll from Florence Bank on Friday February 1, 2019 in downtown Northampton,
Massachusetts, USA <a href="https://goo.gl/maps/AF88fpvVfm12">https://goo.gl/maps/AF88fpvVfm12</a>. The original sample
of 50 pennies is available in <code><a href="#topic+pennies_sample">pennies_sample()</a></code> .
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pennies_resamples
</code></pre>


<h3>Format</h3>

<p>A data frame of 1750 rows representing 35 students' bootstrap
resamples of size 50 and 3 variables
</p>

<dl>
<dt>replicate</dt><dd><p>ID variable of replicate/resample number.</p>
</dd>
<dt>name</dt><dd><p>Name of student</p>
</dd>
<dt>year</dt><dd><p>Year on resampled penny</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+pennies_sample">pennies_sample()</a></code>
</p>

<hr>
<h2 id='pennies_sample'>A sample of 50 pennies</h2><span id='topic+pennies_sample'></span>

<h3>Description</h3>

<p>A sample of 50 pennies contained in a 50 cent roll from Florence Bank on
Friday February 1, 2019 in downtown Northampton, Massachusetts, USA
<a href="https://goo.gl/maps/AF88fpvVfm12">https://goo.gl/maps/AF88fpvVfm12</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pennies_sample
</code></pre>


<h3>Format</h3>

<p>A data frame of 50 rows representing 50 sampled pennies and 2 variables
</p>

<dl>
<dt>ID</dt><dd><p>Variable used to uniquely identify each penny.</p>
</dd>
<dt>year</dt><dd><p>Year of minting.</p>
</dd>
</dl>



<h3>Note</h3>

<p>The original <code>pennies_sample</code> has been renamed <code><a href="#topic+orig_pennies_sample">orig_pennies_sample()</a></code>
as of <code>moderndive</code> v0.3.0.
</p>

<hr>
<h2 id='promotions'>Bank manager recommendations based on (binary) gender</h2><span id='topic+promotions'></span>

<h3>Description</h3>

<p>Data from a 1970's study on whether gender influences hiring recommendations.
Originally used in OpenIntro.org.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>promotions
</code></pre>


<h3>Format</h3>

<p>A data frame with 48 observations on the following 3 variables.
</p>

<dl>
<dt>id</dt><dd><p>Identification variable used to distinguish rows.</p>
</dd>
<dt>gender</dt><dd><p>gender (collected as a binary variable at the time of the study): a factor with two levels <code>male</code> and <code>female</code></p>
</dd>
<dt>decision</dt><dd><p>a factor with two levels: <code>promoted</code> and <code>not</code></p>
</dd>
</dl>



<h3>Source</h3>

<p>Rosen B and Jerdee T. 1974. Influence of sex role stereotypes on personnel
decisions. Journal of Applied Psychology 59(1):9-14.
</p>


<h3>See Also</h3>

<p>The data in <code>promotions</code> is a slight modification of <code><a href="openintro.html#topic+gender_discrimination">openintro::gender_discrimination()</a></code>.
</p>

<hr>
<h2 id='promotions_shuffled'>One permutation/shuffle of promotions</h2><span id='topic+promotions_shuffled'></span>

<h3>Description</h3>

<p>Shuffled/permuted data from a 1970's study on whether gender influences hiring recommendations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>promotions_shuffled
</code></pre>


<h3>Format</h3>

<p>A data frame with 48 observations on the following 3 variables.
</p>

<dl>
<dt>id</dt><dd><p>Identification variable used to distinguish rows.</p>
</dd>
<dt>gender</dt><dd><p>shuffled/permuted (binary) gender: a factor with two levels <code>male</code> and <code>female</code></p>
</dd>
<dt>decision</dt><dd><p>a factor with two levels: <code>promoted</code> and <code>not</code></p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+promotions">promotions()</a></code>.
</p>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+rep_sample_n'></span><span id='topic+rep_slice_sample'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>infer</dt><dd><p><code><a href="infer.html#topic+rep_sample_n">rep_sample_n</a></code>, <code><a href="infer.html#topic+rep_sample_n">rep_slice_sample</a></code></p>
</dd>
</dl>

<hr>
<h2 id='saratoga_houses'>House Prices and Properties in Saratoga, New York</h2><span id='topic+saratoga_houses'></span>

<h3>Description</h3>

<p>Random sample of 1057 houses taken from full Saratoga Housing Data (De Veaux)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>saratoga_houses
</code></pre>


<h3>Format</h3>

<p>A data frame with 1057 observations on the following 8 variables
</p>

<dl>
<dt>price</dt><dd><p>price (US dollars)</p>
</dd>
<dt>living_area</dt><dd><p>Living Area (square feet)</p>
</dd>
<dt>bathrooms</dt><dd><p>Number of Bathroom (half bathrooms have no shower or tub)</p>
</dd>
<dt>bedrooms</dt><dd><p>Number of Bedrooms</p>
</dd>
<dt>fireplaces</dt><dd><p>Number of Fireplaces</p>
</dd>
<dt>lot_size</dt><dd><p>Size of Lot (acres)</p>
</dd>
<dt>age</dt><dd><p>Age of House (years)</p>
</dd>
<dt>fireplace</dt><dd><p>Whether the house has a Fireplace</p>
</dd>
</dl>



<h3>Source</h3>

<p>Gathered from <a href="https://docs.google.com/spreadsheets/d/1AY5eECqNIggKpYF3kYzJQBIuuOdkiclFhbjAmY3Yc8E/edit#gid=622599674">https://docs.google.com/spreadsheets/d/1AY5eECqNIggKpYF3kYzJQBIuuOdkiclFhbjAmY3Yc8E/edit#gid=622599674</a>
</p>

<hr>
<h2 id='tactile_prop_red'>Tactile sampling from a tub of balls</h2><span id='topic+tactile_prop_red'></span>

<h3>Description</h3>

<p>Counting the number of red balls in 33 tactile samples of size n = 50 balls from
<a href="https://github.com/moderndive/moderndive/blob/master/data-raw/sampling_bowl.jpeg">https://github.com/moderndive/moderndive/blob/master/data-raw/sampling_bowl.jpeg</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tactile_prop_red
</code></pre>


<h3>Format</h3>

<p>A data frame of 33 rows representing different groups of students'
samples of size n = 50 and 4 variables
</p>

<dl>
<dt>group</dt><dd><p>Group members</p>
</dd>
<dt>replicate</dt><dd><p>Replicate number</p>
</dd>
<dt>red_balls</dt><dd><p>Number of red balls sampled out of 50</p>
</dd>
<dt>prop_red</dt><dd><p>Proportion red balls out of 50</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+bowl">bowl()</a></code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
