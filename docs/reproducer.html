<!DOCTYPE html><html lang="en"><head><title>Help for package reproducer</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {reproducer}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aggregateIndividualDocumentStatistics'><p>aggregateIndividualDocumentStatistics</p></a></li>
<li><a href='#AnalyseResiduals'><p>AnalyseResiduals</p></a></li>
<li><a href='#boxplotAndDensityCurveOnHistogram'><p>boxplotAndDensityCurveOnHistogram</p></a></li>
<li><a href='#boxplotHV'><p>boxplotHV</p></a></li>
<li><a href='#calc.a'><p>calc.a</p></a></li>
<li><a href='#calc.b'><p>calc.b</p></a></li>
<li><a href='#Calc4GroupNPStats'><p>Calc4GroupNPStats</p></a></li>
<li><a href='#calcCliffdConfidenceIntervals'><p>calcCliffdConfidenceIntervals</p></a></li>
<li><a href='#calcCliffdTestStatistics'><p>calcCliffdTestStatistics</p></a></li>
<li><a href='#calcEffectSizeConfidenceIntervals'><p>calcEffectSizeConfidenceIntervals</p></a></li>
<li><a href='#calcPHatConfidenceIntervals'><p>calcPHatConfidenceIntervals</p></a></li>
<li><a href='#calcPHatMATestStatistics'><p>calcPHatMATestStatistics</p></a></li>
<li><a href='#calculate2GBias'><p>calculate2GBias</p></a></li>
<li><a href='#calculate2GType1Error'><p>calculate2GType1Error</p></a></li>
<li><a href='#calculate4GBias'><p>calculate4GBias</p></a></li>
<li><a href='#calculate4GType1Error'><p>calculate4GType1Error</p></a></li>
<li><a href='#calculateBasicStatistics'><p>calculateBasicStatistics</p></a></li>
<li><a href='#calculateCliffd'><p>calculateCliffd</p></a></li>
<li><a href='#calculateGroupSummaryStatistics'><p>calculateGroupSummaryStatistics</p></a></li>
<li><a href='#calculateHg'><p>calculateHg</p></a></li>
<li><a href='#calculateKendalltaupb'><p>@title calculateKendalltaupb</p>
@description  Computes point bi-serial version of  Kendall's tau plus a 1-alpha confidence interval using the method recommended by Long and Cliff (1997).  The algorithm is based on Wilcox's code but was extended to return the consistent variance and the confidence intervals based on the t-distribution. Also added a Diagnostic parameter to output internal calculations.</a></li>
<li><a href='#calculateLargeSampleRandomizedBlockDesignEffectSizes'><p>calculateLargeSampleRandomizedBlockDesignEffectSizes</p></a></li>
<li><a href='#calculateLargeSampleRandomizedDesignEffectSizes'><p>calculateLargeSampleRandomizedDesignEffectSizes</p></a></li>
<li><a href='#CalculateLevel2ExperimentRData'><p>CalculateLevel2ExperimentRData</p></a></li>
<li><a href='#calculateMABias'><p>calculateMABias</p></a></li>
<li><a href='#calculateMAType1Error'><p>calculateMAType1Error</p></a></li>
<li><a href='#calculateNullESAccuracy'><p>calculateNullESAccuracy</p></a></li>
<li><a href='#calculatePhat'><p>calculatePhat</p></a></li>
<li><a href='#calculatePopulationStatistics'><p>calculatePopulationStatistics</p></a></li>
<li><a href='#CalculateRLevel1'><p>CalculateRLevel1</p></a></li>
<li><a href='#calculateSmallSampleSizeAdjustment'><p>calculateSmallSampleSizeAdjustment</p></a></li>
<li><a href='#CatchError'><p>CatchError</p></a></li>
<li><a href='#checkIfValidDummyVariable'><p>checkIfValidDummyVariable</p></a></li>
<li><a href='#Ciolkowski09ESEM.MetaAnalysis.PBRvsCBRorAR'><p>Ciolkowski09ESEM.MetaAnalysis.PBRvsCBRorAR data</p></a></li>
<li><a href='#Cliffd.test'><p>Cliffd.test</p></a></li>
<li><a href='#constructEffectSizes'><p>constructEffectSizes</p></a></li>
<li><a href='#ConstructLevel1ExperimentRData'><p>ConstructLevel1ExperimentRData</p></a></li>
<li><a href='#crossoverResidualAnalysis'><p>crossoverResidualAnalysis</p></a></li>
<li><a href='#densityCurveOnHistogram'><p>densityCurveOnHistogram</p></a></li>
<li><a href='#doLM'><p>doLM</p></a></li>
<li><a href='#effectSizeCI'><p>effectSizeCI</p></a></li>
<li><a href='#ExtractExperimentData'><p>ExtractExperimentData</p></a></li>
<li><a href='#ExtractGroupSizeData'><p>ExtractGroupSizeData</p></a></li>
<li><a href='#ExtractMAStatistics'><p>ExtractMAStatistics</p></a></li>
<li><a href='#ExtractSummaryStatisticsRandomizedExp'><p>ExtractSummaryStatisticsRandomizedExp</p></a></li>
<li><a href='#fmt'><p>fmt</p></a></li>
<li><a href='#getEffectSizesABBA'><p>getEffectSizesABBA</p></a></li>
<li><a href='#getEffectSizesABBAIgnoringPeriodEffect'><p>getEffectSizesABBAIgnoringPeriodEffect</p></a></li>
<li><a href='#getSimulationData'><p>getSimulationData</p></a></li>
<li><a href='#getTheoreticalEffectSizeVariancesABBA'><p>getTheoreticalEffectSizeVariancesABBA</p></a></li>
<li><a href='#KitchenhamEtAl.CorrelationsAmongParticipants.Abrahao13TSE'><p>KitchenhamEtAl.CorrelationsAmongParticipants.Abrahao13TSE data</p></a></li>
<li><a href='#KitchenhamEtAl.CorrelationsAmongParticipants.Gravino15JVLC'><p>KitchenhamEtAl.CorrelationsAmongParticipants.Gravino15JVLC data</p></a></li>
<li><a href='#KitchenhamEtAl.CorrelationsAmongParticipants.Madeyski10'><p>KitchenhamEtAl.CorrelationsAmongParticipants.Madeyski10 data</p></a></li>
<li><a href='#KitchenhamEtAl.CorrelationsAmongParticipants.Reggio15SSM'><p>KitchenhamEtAl.CorrelationsAmongParticipants.Reggio15SSM data</p></a></li>
<li><a href='#KitchenhamEtAl.CorrelationsAmongParticipants.Ricca10TSE'><p>KitchenhamEtAl.CorrelationsAmongParticipants.Ricca10TSE data</p></a></li>
<li><a href='#KitchenhamEtAl.CorrelationsAmongParticipants.Ricca14TOSEM'><p>KitchenhamEtAl.CorrelationsAmongParticipants.Ricca14TOSEM data</p></a></li>
<li><a href='#KitchenhamEtAl.CorrelationsAmongParticipants.Romano18ESEM'><p>KitchenhamEtAl.CorrelationsAmongParticipants.Romano18ESEM data</p></a></li>
<li><a href='#KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14EASE'><p>KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14EASE data</p></a></li>
<li><a href='#KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14JVLC'><p>KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14JVLC data</p></a></li>
<li><a href='#KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14TOSEM'><p>KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14TOSEM data</p></a></li>
<li><a href='#KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello15EMSE'><p>KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello15EMSE data</p></a></li>
<li><a href='#KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello17TOSEM'><p>KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello17TOSEM data</p></a></li>
<li><a href='#KitchenhamEtAl.CorrelationsAmongParticipants.Torchiano17JVLC'><p>KitchenhamEtAl.CorrelationsAmongParticipants.Torchiano17JVLC data</p></a></li>
<li><a href='#KitchenhamMadeyski.SimulatedCrossoverDataSets'><p>KitchenhamMadeyski.SimulatedCrossoverDataSets data</p></a></li>
<li><a href='#KitchenhamMadeyskiBrereton.ABBAMetaAnalysisReportedResults'><p>KitchenhamMadeyskiBrereton.ABBAMetaAnalysisReportedResults data</p></a></li>
<li><a href='#KitchenhamMadeyskiBrereton.ABBAReportedEffectSizes'><p>KitchenhamMadeyskiBrereton.ABBAReportedEffectSizes data</p></a></li>
<li><a href='#KitchenhamMadeyskiBrereton.DocData'><p>KitchenhamMadeyskiBrereton.DocData data</p></a></li>
<li><a href='#KitchenhamMadeyskiBrereton.ExpData'><p>KitchenhamMadeyskiBrereton.ExpData data</p></a></li>
<li><a href='#KitchenhamMadeyskiBrereton.MetaAnalysisReportedResults'><p>KitchenhamMadeyskiBrereton.MetaAnalysisReportedResults data</p></a></li>
<li><a href='#KitchenhamMadeyskiBrereton.ReportedEffectSizes'><p>KitchenhamMadeyskiBrereton.ReportedEffectSizes data</p></a></li>
<li><a href='#KitchenhamMadeyskiBudgen16.COCOMO'><p>KitchenhamMadeyskiBudgen16.COCOMO data</p></a></li>
<li><a href='#KitchenhamMadeyskiBudgen16.DiffInDiffData'><p>KitchenhamMadeyskiBudgen16.DiffInDiffData data</p></a></li>
<li><a href='#KitchenhamMadeyskiBudgen16.FINNISH'><p>KitchenhamMadeyskiBudgen16.FINNISH data</p></a></li>
<li><a href='#KitchenhamMadeyskiBudgen16.PolishData'><p>KitchenhamMadeyskiBudgen16.PolishData data</p></a></li>
<li><a href='#KitchenhamMadeyskiBudgen16.PolishSubjects'><p>KitchenhamMadeyskiBudgen16.PolishSubjects data</p></a></li>
<li><a href='#KitchenhamMadeyskiBudgen16.SubjectData'><p>KitchenhamMadeyskiBudgen16.SubjectData</p></a></li>
<li><a href='#LaplaceDist'><p>LaplaceDist</p></a></li>
<li><a href='#Madeyski15EISEJ.OpenProjects'><p>Madeyski15EISEJ.OpenProjects data</p></a></li>
<li><a href='#Madeyski15EISEJ.PropProjects'><p>Madeyski15EISEJ.PropProjects data</p></a></li>
<li><a href='#Madeyski15EISEJ.StudProjects'><p>Madeyski15EISEJ.StudProjects data</p></a></li>
<li><a href='#Madeyski15SQJ.NDC'><p>Madeyski15SQJ.NDC data</p></a></li>
<li><a href='#MadeyskiKitchenham.EUBASdata'><p>MadeyskiKitchenham.EUBASdata data</p></a></li>
<li><a href='#MadeyskiKitchenham.MetaAnalysis.PBRvsCBRorAR'><p>MadeyskiKitchenham.MetaAnalysis.PBRvsCBRorAR data</p></a></li>
<li><a href='#MadeyskiLewowski.IndustryRelevantGitHubJavaProjects20190324'><p>MadeyskiLewowski.IndustryRelevantGitHubJavaProjects20190324 data</p></a></li>
<li><a href='#MadeyskiLewowski.IndustryRelevantGitHubJavaProjects20191022'><p>MadeyskiLewowski.IndustryRelevantGitHubJavaProjects20191022 data</p></a></li>
<li><a href='#metaanalyse.Cliffd'><p>metaanalyse.Cliffd</p></a></li>
<li><a href='#metaanalyse.PHat'><p>metaanalyse.PHat</p></a></li>
<li><a href='#metaanalyseSmallSampleSizeExperiments'><p>metaanalyseSmallSampleSizeExperiments</p></a></li>
<li><a href='#MetaAnalysisSimulations'><p>MetaAnalysisSimulations</p></a></li>
<li><a href='#NP2GMetaAnalysisSimulation'><p>NP2GMetaAnalysisSimulation</p></a></li>
<li><a href='#NP4GMetaAnalysisSimulation'><p>NP4GMetaAnalysisSimulation</p></a></li>
<li><a href='#percentageInaccuracyOfLargeSampleVarianceApproximation'><p>percentageInaccuracyOfLargeSampleVarianceApproximation</p></a></li>
<li><a href='#PHat.test'><p>PHat.test</p></a></li>
<li><a href='#PHatonesidedTestStatistics'><p>PHatonesidedTestStatistics</p></a></li>
<li><a href='#PHattwosidedTestStatistics'><p>PHattwosidedTestStatistics</p></a></li>
<li><a href='#plotOutcomesForIndividualsInEachSequenceGroup'><p>plotOutcomesForIndividualsInEachSequenceGroup</p></a></li>
<li><a href='#PrepareForMetaAnalysisGtoR'><p>PrepareForMetaAnalysisGtoR</p></a></li>
<li><a href='#printXTable'><p>printXTable</p></a></li>
<li><a href='#proportionOfSignificantTValuesUsingCorrectAnalysis'><p>proportionOfSignificantTValuesUsingCorrectAnalysis</p></a></li>
<li><a href='#proportionOfSignificantTValuesUsingIncorrectAnalysis'><p>proportionOfSignificantTValuesUsingIncorrectAnalysis</p></a></li>
<li><a href='#RandomExperimentSimulations'><p>RandomExperimentSimulations</p></a></li>
<li><a href='#RandomizedBlockDesignEffectSizes'><p>RandomizedBlockDesignEffectSizes</p></a></li>
<li><a href='#RandomizedBlocksAnalysis'><p>RandomizedBlocksAnalysis</p></a></li>
<li><a href='#RandomizedBlocksExperimentSimulations'><p>title RandomizedBlocksExperimentSimulations</p>
description This function performs multiple simulations of 4 group balanced randomised Block experiments with two control groups and two treatment groups where one control group and one treatment group are assigned to block 1 and the other control group and treatment group are assigned to block 2.  The simulations are based on one of four distributions and a specific group size. The function identifies the average value of the non-parametric effect sizes P-hat, Cliff' d and their variances and whether ot not the statistics were significant at the 0.05 level. We also present the values of the t-test as a comparison.</a></li>
<li><a href='#RandomizedDesignEffectSizes'><p>RandomizedDesignEffectSizes</p></a></li>
<li><a href='#readExcelSheet'><p>readExcelSheet</p></a></li>
<li><a href='#reproduceForestPlotRandomEffects'><p>reproduceForestPlotRandomEffects()</p></a></li>
<li><a href='#reproduceMixedEffectsAnalysisWithEstimatedVarianceAndExperimentalDesignModerator'><p>reproduceMixedEffectsAnalysisWithEstimatedVarianceAndExperimentalDesignModerator()</p></a></li>
<li><a href='#reproduceMixedEffectsAnalysisWithExperimentalDesignModerator'><p>reproduceMixedEffectsAnalysisWithExperimentalDesignModerator()</p></a></li>
<li><a href='#reproduceMixedEffectsForestPlotWithExperimentalDesignModerator'><p>reproduceMixedEffectsForestPlotWithExperimentalDesignModerator()</p></a></li>
<li><a href='#reproduceSimulationResultsBasedOn500Reps1000Obs'><p>reproduceSimulationResultsBasedOn500Reps1000Obs</p></a></li>
<li><a href='#reproduceTablesOfPaperMetaAnalysisForFamiliesOfExperiments'><p>reproduceTablesOfPaperMetaAnalysisForFamiliesOfExperiments</p></a></li>
<li><a href='#reproduceTableWithEffectSizesBasedOnMeanDifferences'><p>reproduceTableWithEffectSizesBasedOnMeanDifferences()</p></a></li>
<li><a href='#reproduceTableWithPossibleModeratingFactors'><p>reproduceTableWithPossibleModeratingFactors()</p></a></li>
<li><a href='#reproduceTableWithSourceDataByCiolkowski'><p>reproduceTableWithSourceDataByCiolkowski</p></a></li>
<li><a href='#rSimulations'><p>rSimulations</p></a></li>
<li><a href='#searchForIndustryRelevantGitHubProjects'><p>searchForIndustryRelevantGitHubProjects</p></a></li>
<li><a href='#simulate2GExperimentData'><p>simulate2GExperimentData</p></a></li>
<li><a href='#simulate4GExperimentData'><p>simulate4GExperimentData</p></a></li>
<li><a href='#simulateRandomizedBlockDesignEffectSizes'><p>simulateRandomizedBlockDesignEffectSizes</p></a></li>
<li><a href='#simulateRandomizedDesignEffectSizes'><p>simulateRandomizedDesignEffectSizes</p></a></li>
<li><a href='#testfunctionParameterChecks'><p>testfunctionParameterChecks</p></a></li>
<li><a href='#transformHgtoR'><p>transformHgtoR</p></a></li>
<li><a href='#transformHgtoZr'><p>transformHgtoZr</p></a></li>
<li><a href='#transformRtoHg'><p>transformRtoHg</p></a></li>
<li><a href='#transformRtoZr'><p>transformRtoZr</p></a></li>
<li><a href='#transformZrtoHg'><p>transformZrtoHg</p></a></li>
<li><a href='#transformZrtoHgapprox'><p>transformZrtoHgapprox</p></a></li>
<li><a href='#transformZrtoR'><p>transformZrtoR</p></a></li>
<li><a href='#varStandardizedEffectSize'><p>varStandardizedEffectSize</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Reproduce Statistical Analyses and Meta-Analyses</td>
</tr>
<tr>
<td>Version:</td>
<td>0.5.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-10-18</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Lech Madeyski &lt;lech.madeyski@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Includes data analysis and meta-analysis functions (e.g., to 
    calculate effect sizes and 95% Confidence Intervals (CI) on Standardised 
    Effect Sizes (d) for AB/BA cross-over repeated-measures experimental 
    designs), data presentation functions (e.g., density curve overlaid on 
    histogram),and the data sets analyzed in different research papers in 
    software engineering (e.g., related to software defect prediction or multi-
    site experiment concerning the extent to which structured abstracts were
    clearer and more complete than conventional abstracts) to streamline
    reproducible research in software engineering.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://madeyski.e-informatyka.pl/reproducible-research/">https://madeyski.e-informatyka.pl/reproducible-research/</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr(&ge; 0.8.0.1), GetoptLong(&ge; 0.1.7), ggplot2(&ge; 2.0.0),
gridExtra(&ge; 0.9.1), httr(&ge; 1.4.0), jsonlite(&ge; 1.6), lme4(&ge;
1.1-10), MASS(&ge; 7.3-45), metafor(&ge; 1.9-2), nortest(&ge; 1.0-4),
openxlsx(&ge; 2.4.0), readr(&ge; 1.3.1), reshape(&ge; 0.8.8),
stats(&ge; 3.5.0), stringr(&ge; 1.4.0), tibble(&ge; 2.1.1), tidyr(&ge;
0.8.3), xtable(&ge; 1.7-4)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>assertthat, testthat</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-18 14:12:53 UTC; lma</td>
</tr>
<tr>
<td>Author:</td>
<td>Lech Madeyski [cre, aut, ctb] (The main contributor and maintainer),
  Barbara Kitchenham [ctb] (Data and code contributor),
  Tomasz Lewowski [ctb] (Data and code contributor),
  Marian Jureczko [ctb] (Data contributor),
  David Budgen [ctb] (Data contributor),
  Pearl Brereton [ctb] (Data contributor),
  Jacky Keung [ctb] (Data contributor),
  Stuart Charters [ctb] (Data contributor),
  Shirley Gibbs [ctb] (Data contributor),
  Amnart Pohthong [ctb] (Data contributor),
  Giuseppe Scanniello [ctb] (Data contributor),
  Carmine Gravino [ctb] (Data contributor)</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-18 14:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='aggregateIndividualDocumentStatistics'>aggregateIndividualDocumentStatistics</h2><span id='topic+aggregateIndividualDocumentStatistics'></span>

<h3>Description</h3>

<p>This function assumes an ABBA crossover experiment has reported means and variances for each technique in each time period. We calculate the weighted mean and pooled within group variance for the observations arising from the two different sets of materials for a specific technique.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aggregateIndividualDocumentStatistics(D1.M, D1.SD, D1.N, D2.M, D2.SD, D2.N)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="aggregateIndividualDocumentStatistics_+3A_d1.m">D1.M</code></td>
<td>
<p>is a vector of mean values from a set of experiments in a family reporting observations from participants using a specific document in the first time period with either the control or the treatment technique.</p>
</td></tr>
<tr><td><code id="aggregateIndividualDocumentStatistics_+3A_d1.sd">D1.SD</code></td>
<td>
<p>is a vector of results from the set of experiment in a family reporting the standard deviations of observations from participants using the same document in the first time period with the same technique.</p>
</td></tr>
<tr><td><code id="aggregateIndividualDocumentStatistics_+3A_d1.n">D1.N</code></td>
<td>
<p>is a vector of the numbers of participants in each experiment in a family, using the same document for participants using either the same technique.</p>
</td></tr>
<tr><td><code id="aggregateIndividualDocumentStatistics_+3A_d2.m">D2.M</code></td>
<td>
<p>is a vector of mean values of observations from participants using the alternative document in the second time period, but using the same technique.</p>
</td></tr>
<tr><td><code id="aggregateIndividualDocumentStatistics_+3A_d2.sd">D2.SD</code></td>
<td>
<p>is a vector of the standard deviations of observations from participants using the alternative document in the second time period with the same technique.</p>
</td></tr>
<tr><td><code id="aggregateIndividualDocumentStatistics_+3A_d2.n">D2.N</code></td>
<td>
<p>is a vector of the numbers of participants using the same document in the second time period for participants using the same technique.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame incl. the overall weighted mean and pooled standard deviation
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>aggregateIndividualDocumentStatistics(10, 2, 20, 15, 2, 20)
#     M SD
# 1 12.5  2
</code></pre>

<hr>
<h2 id='AnalyseResiduals'>AnalyseResiduals</h2><span id='topic+AnalyseResiduals'></span>

<h3>Description</h3>

<p>The function calculates sample statistics based on the residuals from a specified experiment
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AnalyseResiduals(Residuals, ExperimentName = "ExpName")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AnalyseResiduals_+3A_residuals">Residuals</code></td>
<td>
<p>a vector of residuals</p>
</td></tr>
<tr><td><code id="AnalyseResiduals_+3A_experimentname">ExperimentName</code></td>
<td>
<p>a character string identifying the data set</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe identifying the ExperimentName and its associated sample parameter: Length, Mean, Median, Variance, Standard deviation, skewness, kurtosis, the outcome of the Shapiro and Anderson-Darling normality test and the number of outliers.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ExpData=rnorm(30,0,1)
set.seed(123)
AnalyseResiduals(Residuals=ExpData,ExperimentName='ExpName')
#  ExperimentName       Mean      Median  Variance   Skewness Kurtosis ShapiroTest AndersonDarling
#1        ExpName -0.1396192 -0.01943395 0.8424521 -0.1964175 4.559587   0.1608315       0.1316835
#  NumOut
#  1
</code></pre>

<hr>
<h2 id='boxplotAndDensityCurveOnHistogram'>boxplotAndDensityCurveOnHistogram</h2><span id='topic+boxplotAndDensityCurveOnHistogram'></span>

<h3>Description</h3>

<p>Boxplot and density curve overlaid on histogram
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boxplotAndDensityCurveOnHistogram(df, colName, limLow, limHigh)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="boxplotAndDensityCurveOnHistogram_+3A_df">df</code></td>
<td>
<p>Data frame with data to be displayed</p>
</td></tr>
<tr><td><code id="boxplotAndDensityCurveOnHistogram_+3A_colname">colName</code></td>
<td>
<p>Name of the selected column in a given data frame</p>
</td></tr>
<tr><td><code id="boxplotAndDensityCurveOnHistogram_+3A_limlow">limLow</code></td>
<td>
<p>the limit on the lower side of the displayed range</p>
</td></tr>
<tr><td><code id="boxplotAndDensityCurveOnHistogram_+3A_limhigh">limHigh</code></td>
<td>
<p>the limit on the higher side of the displayed range</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A figure being a density curve overlaid on histogram
</p>


<h3>Author(s)</h3>

<p>Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(ggplot2)
library(grid)
library(gridExtra)
boxplotAndDensityCurveOnHistogram(Madeyski15EISEJ.PropProjects, "STUD", 0, 100)
boxplotAndDensityCurveOnHistogram(Madeyski15SQJ.NDC, "simple", 0, 100)
</code></pre>

<hr>
<h2 id='boxplotHV'>boxplotHV</h2><span id='topic+boxplotHV'></span>

<h3>Description</h3>

<p>Box plot
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boxplotHV(df, colName, limLow, limHigh, isHorizontal)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="boxplotHV_+3A_df">df</code></td>
<td>
<p>Data frame with data to be displayed</p>
</td></tr>
<tr><td><code id="boxplotHV_+3A_colname">colName</code></td>
<td>
<p>Name of the selected column in a given data frame</p>
</td></tr>
<tr><td><code id="boxplotHV_+3A_limlow">limLow</code></td>
<td>
<p>the limit on the lower side of the displayed range</p>
</td></tr>
<tr><td><code id="boxplotHV_+3A_limhigh">limHigh</code></td>
<td>
<p>the limit on the higher side of the displayed range</p>
</td></tr>
<tr><td><code id="boxplotHV_+3A_ishorizontal">isHorizontal</code></td>
<td>
<p>Boolean value to control whether the box plot should be horizontal or not (i.e., vertical)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A box plot
</p>


<h3>Author(s)</h3>

<p>Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>boxplotHV(Madeyski15EISEJ.PropProjects, "STUD", 0, 100, TRUE)
boxplotHV(Madeyski15EISEJ.PropProjects, "STUD", 0, 100, FALSE)
boxplotHV(Madeyski15SQJ.NDC, "simple", 0, 100, FALSE)
boxplotHV(Madeyski15SQJ.NDC, "simple", 0, 100, TRUE)
</code></pre>

<hr>
<h2 id='calc.a'>calc.a</h2><span id='topic+calc.a'></span>

<h3>Description</h3>

<p>This function is a helper function that calculates one element of the standardized mean difference effect size variance based on Hedges and Olkin p128-131.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc.a(f, A)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc.a_+3A_f">f</code></td>
<td>
<p>a vector defining the degrees of freedom for the effect sizes</p>
</td></tr>
<tr><td><code id="calc.a_+3A_a">A</code></td>
<td>
<p>a vector defining the constants that relate each StdMD to its related t-variable where t^2=Ad^2</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value of a.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>reproducer:::calc.a(10,2/10)
# [1] 0.2128649
</code></pre>

<hr>
<h2 id='calc.b'>calc.b</h2><span id='topic+calc.b'></span>

<h3>Description</h3>

<p>This function is a helper function that calculates one element of the standardized mean difference effect size variance based on Hedges and Olkin p128-131.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc.b(f)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc.b_+3A_f">f</code></td>
<td>
<p>a vector defining the degrees of freedom for the effect sizes</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value of b.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>reproducer:::calc.b(8)
#0.08649774

</code></pre>

<hr>
<h2 id='Calc4GroupNPStats'>Calc4GroupNPStats</h2><span id='topic+Calc4GroupNPStats'></span>

<h3>Description</h3>

<p>This function does a non-parametric analysis of a randomized
blocks experiment assuming 2 blocks and 2 treatment conditions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Calc4GroupNPStats(
  x1,
  x2,
  x3,
  x4,
  sigfig = -1,
  alpha = 0.05,
  alternative = "two.sided"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Calc4GroupNPStats_+3A_x1">x1</code></td>
<td>
<p>is the data associated with  treatment A in one block 1</p>
</td></tr>
<tr><td><code id="Calc4GroupNPStats_+3A_x2">x2</code></td>
<td>
<p>is the data associated with treatment B in block 1</p>
</td></tr>
<tr><td><code id="Calc4GroupNPStats_+3A_x3">x3</code></td>
<td>
<p>is the data associated with treatment A in block 2</p>
</td></tr>
<tr><td><code id="Calc4GroupNPStats_+3A_x4">x4</code></td>
<td>
<p>is the data associated with treatment B in block 2</p>
</td></tr>
<tr><td><code id="Calc4GroupNPStats_+3A_sigfig">sigfig</code></td>
<td>
<p>is the number of significant digits in the data. If &gt;0
the datav will be appropriately truncated.</p>
</td></tr>
<tr><td><code id="Calc4GroupNPStats_+3A_alpha">alpha</code></td>
<td>
<p>is the significance level for all statistical tests</p>
</td></tr>
<tr><td><code id="Calc4GroupNPStats_+3A_alternative">alternative</code></td>
<td>
<p>The type of statistical test. Valid values are one of
c('two.sided', 'greater', 'less')</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns the Cliff's d and its variance, the probability
of superiority, phat, and its variance for the 4 group experiment experiment.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
x &lt;- list()
x[[1]] &lt;- rnorm(10, 0, 1)
x[[2]] &lt;- rnorm(10, 0.8, 1)
x[[3]] &lt;- rnorm(10, 0.5, 1)
x[[4]] &lt;- rnorm(10, 1.3, 1)
as.data.frame(
Calc4GroupNPStats(x[[1]], x[[2]], x[[3]], x[[4]], sigfig = -1, alpha = 0.05)
)
#   N phat    phat.var  phat.df phat.test  phat.pvalue phat.sig phat.ci.upper
# 1 40 0.17 0.004966667 31.00131 -4.682539 5.324252e-05     TRUE     0.3137336
#  phat.ci.lower     d       vard d.sig d.ci.lower d.ci.upper        cor       sqse
# 1    0.02626639 -0.66 0.02060121  TRUE -0.8545073 -0.3031667 -0.3473684 0.01315789
#        ctvar n1 n2 sigCVt
# 1 0.005990797 20 20   TRUE
as.data.frame(
Calc4GroupNPStats(x[[1]], x[[2]], x[[3]], x[[4]], sigfig = -1, alpha = 0.05,
alternative = "less")
)
#   N phat    phat.var  phat.df phat.test  phat.pvalue phat.sig phat.ci.upper
# 1 40 0.17 0.004966667 31.00131 -4.682539 2.662126e-05     TRUE     0.2894908
#  phat.ci.lower     d       vard d.sig d.ci.lower d.ci.upper        cor       sqse
# 1             0 -0.66 0.02060121  TRUE         -1 -0.3677704 -0.3473684 0.01315789
#        ctvar n1 n2 sigCVt
# 0.005990797 20 20   TRUE
as.data.frame(
Calc4GroupNPStats(x[[2]], x[[1]], x[[4]], x[[3]], sigfig = -1, alpha = 0.05,
alternative = "greater")
)
#   N phat    phat.var  phat.df phat.test  phat.pvalue phat.sig phat.ci.upper
# 1 40 0.83 0.004966667 31.00131  4.682539 2.662126e-05     TRUE             1
#  phat.ci.lower    d       vard d.sig d.ci.lower d.ci.upper       cor       sqse
# 1     0.7105092 0.66 0.02060121  TRUE  0.3677704          1 0.3473684 0.01315789
#        ctvar n1 n2 sigCVt
# 1 0.005990797 20 20   TRUE

#as.data.frame(
#Calc4GroupNPStats(x[[1]],x[[2]],x[[3]],x[[4]],sigfig=-1,alpha=0.00))
#Error in testfunctionParameterChecks(alternative = alternative, alpha = alpha,  :
#  Invalid alpha parameter, select alpha in range (0.0001,0.2)

</code></pre>

<hr>
<h2 id='calcCliffdConfidenceIntervals'>calcCliffdConfidenceIntervals</h2><span id='topic+calcCliffdConfidenceIntervals'></span>

<h3>Description</h3>

<p>This functions is a helper function. It assesses the significance one-sided and two-sided statistical of Cliff's d based on its confidence interval. The type of test is determined by the parameter One.Sided.Tests, the direction of one-sided tests is determined by the parameter Positive.MD.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcCliffdConfidenceIntervals(
  d.value,
  d.variance,
  d.df,
  alpha = 0.05,
  alternative = "two.sided"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcCliffdConfidenceIntervals_+3A_d.value">d.value</code></td>
<td>
<p>This is the value of Cliff's d.</p>
</td></tr>
<tr><td><code id="calcCliffdConfidenceIntervals_+3A_d.variance">d.variance</code></td>
<td>
<p>This is the estimated variance of Cliff's d</p>
</td></tr>
<tr><td><code id="calcCliffdConfidenceIntervals_+3A_d.df">d.df</code></td>
<td>
<p>The degrees of freedom.</p>
</td></tr>
<tr><td><code id="calcCliffdConfidenceIntervals_+3A_alpha">alpha</code></td>
<td>
<p>This is the alpha level required for the statistical tests (default 0.05)</p>
</td></tr>
<tr><td><code id="calcCliffdConfidenceIntervals_+3A_alternative">alternative</code></td>
<td>
<p>This defines whether a one-sided test or a two-sided
(default) test is required. For a one-sided test use parameter values
greater' or 'less' to define whether the d-value should be greater or less
than zero.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a Boolean variable identifying whether the effect size is significant and the confidence interval bounds.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>reproducer:::calcCliffdConfidenceIntervals(d.value=0.5, d.variance=0.04,d.df=18)
# A tibble: 1 x 5
#  d.tvalue d.pvalue d.ci.lower d.ci.upper d.sig
#     &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;lgl&gt;
#1      2.5   0.0223     0.0479      0.782 TRUE

reproducer:::calcCliffdConfidenceIntervals(
  d.value=0.5,d.variance=0.04,d.df=18,alternative='greater')
# A tibble: 1 x 5
#  d.tvalue d.pvalue d.ci.lower d.ci.upper d.sig
#   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;lgl&gt;
#1    2.5   0.0112      0.123          1 TRUE

reproducer:::calcCliffdConfidenceIntervals(
  d.value=0.2,d.variance=0.04,d.df=18,alternative='greater')
# A tibble: 1 x 3
#  d.tvalue d.pvalue d.ci.lower d.ci.upper d.sig
#     &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;lgl&gt;
#1        1    0.165     -0.133          1 FALSE

reproducer:::calcCliffdConfidenceIntervals(
  d.value=-0.5,d.variance=0.04,d.df=18,alternative='less')
# A tibble: 1 x 5
#  d.tvalue d.pvalue d.ci.lower d.ci.upper d.sig
#   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;lgl&gt;
#1     -2.5   0.0112         -1     -0.123 TRUE
</code></pre>

<hr>
<h2 id='calcCliffdTestStatistics'>calcCliffdTestStatistics</h2><span id='topic+calcCliffdTestStatistics'></span>

<h3>Description</h3>

<p>This function is a helper function for meta-analysis of experiments using Cliff's d as an effect size. It returns the 100*(1-alpha/2)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcCliffdTestStatistics(
  d.value,
  d.variance,
  d.df = 0,
  alpha = 0.05,
  alternative = "two.sided"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcCliffdTestStatistics_+3A_d.value">d.value</code></td>
<td>
<p>The overall estimate of Cliff's d from a group of effect sizes to be meta-analysed</p>
</td></tr>
<tr><td><code id="calcCliffdTestStatistics_+3A_d.variance">d.variance</code></td>
<td>
<p>The estimate of the variance of the overall estimate of Cliff's d</p>
</td></tr>
<tr><td><code id="calcCliffdTestStatistics_+3A_d.df">d.df</code></td>
<td>
<p>The total degrees of freedom for the set of effect sizes. If d.df&gt;0, the pvalues and significance test use the t-distribution probability values. If d.df=0 (default) the pvalues and significance test use the normal distribution probability values. The confidence intervals are always based on the normal probability values.</p>
</td></tr>
<tr><td><code id="calcCliffdTestStatistics_+3A_alpha">alpha</code></td>
<td>
<p>The significance level used to control the significance tests and calculation of confidence limits (default 0.05).</p>
</td></tr>
<tr><td><code id="calcCliffdTestStatistics_+3A_alternative">alternative</code></td>
<td>
<p>Specifies the type of significance test and can take the values &quot;two.sided&quot;, &quot;less&quot; or &quot;greater&quot; (default &quot;two.sided&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>d.tvalue The value of the t-statistic
</p>
<p>d.pvalue The p-value of the t-test if the parameter d.df&gt;0, or the normal probability value if d.df=0
</p>
<p>d.ci.lower The lower 100*(1-alpha/2)
</p>
<p>d.ci.upper The upper 100*(1-alpha/2)
</p>
<p>d.sig The significance of the statistical test of the d.tvalue return value at the alpha level for one sided tests and aplha/2 for two sided tests as specified by the input parameter alternative
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>aveCliffd=mean(c(0.84,0.2,-0.04,0.44,0.76))
aveCliffdvar=sum(c(0.04,0.18,0.21,0.15,0.06))/25
df=45
calcCliffdTestStatistics(d.value=aveCliffd,d.variance=aveCliffdvar,d.df=df)
# A tibble: 1 x 5
#   d.tvalue d.pvalue d.ci.lower d.ci.upper d.sig
#      &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;lgl&gt;
# 1     2.75  0.00855     0.0923      0.692 TRUE
</code></pre>

<hr>
<h2 id='calcEffectSizeConfidenceIntervals'>calcEffectSizeConfidenceIntervals</h2><span id='topic+calcEffectSizeConfidenceIntervals'></span>

<h3>Description</h3>

<p>This function provides single-sided and two-sided confidence interval of an effect size (assuming that the null hypothesis value is zero).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcEffectSizeConfidenceIntervals(
  effectsize,
  effectsize.variance,
  effectsize.df = 0,
  alpha = 0.05,
  alternative = "two.sided",
  UpperValue = Inf,
  LowerValue = -Inf
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcEffectSizeConfidenceIntervals_+3A_effectsize">effectsize</code></td>
<td>
<p>The effect size</p>
</td></tr>
<tr><td><code id="calcEffectSizeConfidenceIntervals_+3A_effectsize.variance">effectsize.variance</code></td>
<td>
<p>The effect size variance</p>
</td></tr>
<tr><td><code id="calcEffectSizeConfidenceIntervals_+3A_effectsize.df">effectsize.df</code></td>
<td>
<p>The degrees of freedom for confidence intervals based on the t- distribution. If df=0 (default), the confidence interval is based on the normal distribution</p>
</td></tr>
<tr><td><code id="calcEffectSizeConfidenceIntervals_+3A_alpha">alpha</code></td>
<td>
<p>The significance level of the confidence interval
(default 0.05).</p>
</td></tr>
<tr><td><code id="calcEffectSizeConfidenceIntervals_+3A_alternative">alternative</code></td>
<td>
<p>This defines whether a one-sided test or a two-sided
(default) test is required. For a one-sided test use parameter values
greater' or 'less' to define whether the d-value should be greater or less
than zero.</p>
</td></tr>
<tr><td><code id="calcEffectSizeConfidenceIntervals_+3A_uppervalue">UpperValue</code></td>
<td>
<p>The maximum legal value of the effect size (default Inf).
Used to ensure that confidence intervals of effect sizes such as correlation
coefficients are restricted to sensible values.</p>
</td></tr>
<tr><td><code id="calcEffectSizeConfidenceIntervals_+3A_lowervalue">LowerValue</code></td>
<td>
<p>The minimum legal value of the effect size (default -Inf).
Used to ensure that confidence intervals of effect sizes
such as correlation coefficients are restricted to sensible values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value of the test statistic, the p.value of test statistic, the upper and lower confidence interval of the effect size, a logical value specifying whether the effect size is significantly different from zero based on the confidence interval and the lower and upper confidence interval bounds.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>reproducer:::calcEffectSizeConfidenceIntervals(
  effectsize=0.37,effectsize.variance=0.00847,effectsize.df=11.1,
  alpha=0.05,alternative='two.sided',UpperValue=0.5,LowerValue=-0.5)
# A tibble: 1 x 5
#  ES.test ES.pvalue ES.sig ES.ci.lower ES.ci.upper
#    &lt;dbl&gt;     &lt;dbl&gt; &lt;lgl&gt;        &lt;dbl&gt;       &lt;dbl&gt;
#1    4.02   0.00198 TRUE         0.168         0.5
</code></pre>

<hr>
<h2 id='calcPHatConfidenceIntervals'>calcPHatConfidenceIntervals</h2><span id='topic+calcPHatConfidenceIntervals'></span>

<h3>Description</h3>

<p>This functions is a helper function. It assesses the significance one-sided and two-sided statistical of the probability of superiority based on its confidence interval. The type of test and the direction of the test is determined by the parameter alternative which takes one of the values 'two.sided', 'greater' or 'less'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcPHatConfidenceIntervals(
  phat,
  phat.variance,
  phat.df,
  alpha = 0.05,
  alternative = "two.sided"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcPHatConfidenceIntervals_+3A_phat">phat</code></td>
<td>
<p>This is the value of the probability of superiority.</p>
</td></tr>
<tr><td><code id="calcPHatConfidenceIntervals_+3A_phat.variance">phat.variance</code></td>
<td>
<p>This is the estimated variance of the probability of superiority.</p>
</td></tr>
<tr><td><code id="calcPHatConfidenceIntervals_+3A_phat.df">phat.df</code></td>
<td>
<p>The degrees of freedom associated with phat value.</p>
</td></tr>
<tr><td><code id="calcPHatConfidenceIntervals_+3A_alpha">alpha</code></td>
<td>
<p>This is the alpha level required for the statistical tests
(default 0.05)</p>
</td></tr>
<tr><td><code id="calcPHatConfidenceIntervals_+3A_alternative">alternative</code></td>
<td>
<p>This defines whether a one-sided test or a two-sided
(i.e. default) test is required. For a one-sided test use parameter values
greater' or 'less' to define whether the phat-value should be greater or
less than 0.5.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a Boolean variable identifying whether the effect size is significant and the confidence interval bounds.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>reproducer:::calcPHatConfidenceIntervals(.65,0.005,8)
# A tibble: 1 x 5
#  phat.test pvalue phat.sig phat.ci.lower phat.ci.upper
#     &lt;dbl&gt;  &lt;dbl&gt; &lt;lgl&gt;            &lt;dbl&gt;         &lt;dbl&gt;
# 1      2.12 0.0667 FALSE            0.487         0.813
reproducer:::calcPHatConfidenceIntervals(.65,0.005,8,alternative='greater')
# A tibble: 1 x 5
#  phat.test pvalue phat.sig phat.ci.lower phat.ci.upper
#      &lt;dbl&gt;  &lt;dbl&gt; &lt;lgl&gt;            &lt;dbl&gt;         &lt;dbl&gt;
# 1      2.12 0.0333 TRUE             0.519             1
</code></pre>

<hr>
<h2 id='calcPHatMATestStatistics'>calcPHatMATestStatistics</h2><span id='topic+calcPHatMATestStatistics'></span>

<h3>Description</h3>

<p>This function is a helper function for meta-analysis of experiments using PHat as an effect size. It returns the 100*(1-alpha/2)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcPHatMATestStatistics(
  effectsize,
  effectsize.variance,
  effectsize.df = 0,
  alpha = 0.05,
  alternative = "two.sided"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcPHatMATestStatistics_+3A_effectsize">effectsize</code></td>
<td>
<p>The overall estimate of the centralized PHat (ie.Phat-0.5) from a group of effect sizes to be meta-analysed</p>
</td></tr>
<tr><td><code id="calcPHatMATestStatistics_+3A_effectsize.variance">effectsize.variance</code></td>
<td>
<p>The estimate of the variance of the overall estimate ofPHat</p>
</td></tr>
<tr><td><code id="calcPHatMATestStatistics_+3A_effectsize.df">effectsize.df</code></td>
<td>
<p>The total degrees of freedom for the set of effect sizes. If effectsize.df&gt;0, the confidence intervals, pvalues and significance test use the t-distribution probability values. If effectsize.df=0 (default), the confidence intervals, the pvalues and significance test use the normal distribution probability values.</p>
</td></tr>
<tr><td><code id="calcPHatMATestStatistics_+3A_alpha">alpha</code></td>
<td>
<p>The significance level used to control the significance tests and calculation of confidence limits (default 0.05).</p>
</td></tr>
<tr><td><code id="calcPHatMATestStatistics_+3A_alternative">alternative</code></td>
<td>
<p>Specifies the type of significance test and can take the values &quot;two.sided&quot; (default), &quot;less&quot; or &quot;greater&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ES.test The value of the t-statistic
</p>
<p>ES.pvalue The p-value of the t-test if the parameter d.df&gt;0, or the normal probability value if d.df=0
</p>
<p>ES.sig The significance of the statistical test of the d.tvalue return value at the alpha level for one sided tests and aplha/2 for two sided tests as specified by the input parameter alternative.
</p>
<p>ES.ci.lower The lower 100*(1-alpha/2)
</p>
<p>ES.ci.upper The upper 100*(1-alpha/2)
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>avePHat=mean(c(0.92,0.6,0.48,0.72,0.88))
avePHatvar=sum(c(0.01,0.04,0.05,0.04,0.01))/25
PHatdf=sum(c(6.63,6.63,5.08,5.61,8))
calcPHatMATestStatistics(effectsize=avePHat-0.5,effectsize.variance=avePHatvar,effectsize.df=PHatdf)
# A tibble: 1 x 5
#   ES.test ES.pvalue ES.sig ES.ci.lower ES.ci.upper
#     &lt;dbl&gt;     &lt;dbl&gt; &lt;lgl&gt;        &lt;dbl&gt;       &lt;dbl&gt;
# 1    2.84   0.00778 TRUE        0.0622       0.378
</code></pre>

<hr>
<h2 id='calculate2GBias'>calculate2GBias</h2><span id='topic+calculate2GBias'></span>

<h3>Description</h3>

<p>The function simulates two-group experiments and estimates the power, individual estimate error, and the small sample bias obtained obtained from the set of simulated experiments. The set of simulations for a specific mean difference are repeated for three different values of the difference between the treatment and control groups specified by the parameter &quot;diff&quot;. The power is estimated as the percentage of experiments for which the  mean of the experiment was significantly different from zero. The experiment data may be one of four different type: Normal, Log-normal, Gamma or Laplace. The output is a table of values identifying the observed values of three effect sizes: Cliff's d, PHat and StdMD, estimate error and their related small sample bias and power for each set of simulated experiments. This function supports the production of the values reported in data tables in the paper &quot;Recommendations for Analyzing Small Sample Size Software Engineering Experiments&quot; and its Supplementary Material.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculate2GBias(
  mean = 0,
  sd = 1,
  N,
  reps,
  diff = c(0.2, 0.5, 0.8),
  Expected.StdMD = c(0.2, 0.5, 0.8),
  Expected.PHat = c(0.556, 0.638, 0.714),
  type = "n",
  seed = 223,
  StdAdj = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calculate2GBias_+3A_mean">mean</code></td>
<td>
<p>This is the mean value of the control and treatment group(s) used in the simulations of each experiment for simulations of a specified sample size and mean difference (default 0).</p>
</td></tr>
<tr><td><code id="calculate2GBias_+3A_sd">sd</code></td>
<td>
<p>This is the standard deviation  value of the control group(s) and treatment group(s) used in the simulations of each experiment of each family for simulations of a specified sample size (default 1).</p>
</td></tr>
<tr><td><code id="calculate2GBias_+3A_n">N</code></td>
<td>
<p>This specifies the sample size per group that will be used in each set of simulations.</p>
</td></tr>
<tr><td><code id="calculate2GBias_+3A_reps">reps</code></td>
<td>
<p>The number of experiments simulated for each mean difference.</p>
</td></tr>
<tr><td><code id="calculate2GBias_+3A_diff">diff</code></td>
<td>
<p>This specifies the mean difference between the control and treatment that will be used in each set of simulations. It must always have three values representing small, medium and large differences (default c(0.2, 0.5, 0.8)).</p>
</td></tr>
<tr><td><code id="calculate2GBias_+3A_expected.stdmd">Expected.StdMD</code></td>
<td>
<p>This defines the theoretical value of the average StdMD obtained from the simulations for each mean difference. (default c(0.2, 0.5, 0.8))</p>
</td></tr>
<tr><td><code id="calculate2GBias_+3A_expected.phat">Expected.PHat</code></td>
<td>
<p>This defines the expected population value of the average Phat obtained from the simulations for each mean difference (default c(0.556,0.638,0.714)).</p>
</td></tr>
<tr><td><code id="calculate2GBias_+3A_type">type</code></td>
<td>
<p>This specifies the distribution of the data samples that will be simulated. Options ae &quot;n&quot; for Normal, &quot;l&quot;, for Log-normal,'g&quot; for Gamma, &quot;lap&quot; for LaPlace (default &quot;n&quot;).</p>
</td></tr>
<tr><td><code id="calculate2GBias_+3A_seed">seed</code></td>
<td>
<p>A seed for the simulations (default 123).</p>
</td></tr>
<tr><td><code id="calculate2GBias_+3A_stdadj">StdAdj</code></td>
<td>
<p>Used to introduce variance heterogeneity for Laplace and Normal samples (default 0).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Design. Specifies the type of experiment, the sample distribution (n,l,g,lap), and whether variance heterogeneity was added (het)
</p>
<p>GrpSize. Specifies the size of each group in the simulated experiments.
</p>
<p>Diff. The size of the difference between the control and treatment converted to an ordinal scale (Small, Medium, Large)
</p>
<p>NPBias The relative difference between the average of the observed values of either Cliff's d or centralised PHat and the population value
</p>
<p>StdMDBias. The relative difference between the average of the observed values of StdMDBias and the theoretical value
</p>
<p>NPMdMRE The median of the absolute relative difference between the observed values of either Cliff's d or centralised PHat and the theoretical value for each experiment.
</p>
<p>StdMDMdMRE The median of the relative difference between the observed values of StdMD and the population value for each experiment.
</p>
<p>ObsPHat. The average of the  Phat values found  in the set of simulations.
</p>
<p>ObsCliffd. The average of the  Cliffd values found  in the set of simulations.
</p>
<p>ObsStdES. The average of StdMD values found in the set of simulations.
</p>
<p>PHatPower. The percentage of the simulations, for a specific mean difference, for which the Phat estimate was significantly different from zero at the 0.05 alpha level based on one-sided tests.
</p>
<p>CliffdPower. The percentage of the simulations, for a specific mean difference, for which the  Cliff's d estimate was significantly different from zero at the 0.05 alpha level based on one-sided tests.
</p>
<p>StdMDPower. The percentage of the simulations, for a specific mean difference, for which the StdMD estimate was significantly different from zero at the 0.05 alpha level based on one-sided tests.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'># as.data.frame(calculate2GBias(mean=0,sd=1,diff=c(0.2,0.5,0.8),Expected.StdMD=c(0.157,0.392,0.628),
#  Expected.PHat=c(0.544,0.609,0.671), N=5,reps=50, type="n", seed=523, StdAdj =0.5 ))
# Results for reps=100 (due to NOTE "Examples with CPU (user + system) or elapsed time &gt; 5s"):
#    Design GrpSize   Diff        NPBias  StdMDBias  NPMdMRE StdMDMdMRE ObsPHat ObsCliffd  ObsSt..
# 1 2G_n_het       5  Small -6.308085e-16 0.07088601 3.272727  3.2700082  0.5440    0.0880 0.168..
# 2 2G_n_het       5 Medium  3.486239e-02 0.09914637 1.385321  1.3502057  0.6128    0.2256 0.430..
# 3 2G_n_het       5  Large  2.222222e-02 0.10446123 0.754386  0.8626523  0.6748    0.3496 0.693..
as.data.frame(calculate2GBias(mean=0,sd=1,diff=c(0.283,0.707104,1.131374),
 Expected.StdMD=c(0.157,0.392,0.628),Expected.PHat=c(0.556,0.636,0.705),N=10, reps=20,
 type="lap",seed=1423,StdAdj=0.5 ))
 #Parameter reps changed due to NOTE "Examples with CPU (user + system) or elapsed time &gt; 5s"
 #Results for reps=100:
#      Design GrpSize   Diff      NPBias    StdMDBias   NPMdMRE StdMDMdMRE ObsPHat ObsCliffd  Ob..
#1 2G_lap_het      10  Small -0.11071429 -0.080855612 1.8928571  2.1256888  0.5498    0.0996 0.1..
#2 2G_lap_het      10 Medium -0.07426471  0.003940804 0.6323529  0.8170856  0.6259    0.2518 0.3..
#3 2G_lap_het      10  Large -0.05756098  0.023696619 0.4146341  0.5447941  0.6932    0.3864 0.6..
</code></pre>

<hr>
<h2 id='calculate2GType1Error'>calculate2GType1Error</h2><span id='topic+calculate2GType1Error'></span>

<h3>Description</h3>

<p>The function simulates  multiple two-group experiments and estimates the Type1 Error rate obtained from the set of simulated experiments. The Type1 Error is estimated as the percentage of experiments for which the mean the experiment was significantly different from zero at the 0.05 significance level using two-sided tests. The experiment data may be one of four different type: Normal, Log-normal, Gamma or Laplace. The output is a set of values identifying three observed effect size estimates (Cliff's d, PHat and StdMD) and their related type 1 error rates. This function supports the production of the values reported in data tables in the paper &quot;Recommendations for Analyzing Small Sample Size Software Engineering Experiments&quot; and its Supplementary Material.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculate2GType1Error(
  mean = 0,
  sd = 1,
  N = 10,
  reps,
  type = "n",
  seed = 123,
  StdAdj = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calculate2GType1Error_+3A_mean">mean</code></td>
<td>
<p>This is the mean value of the control and treatment group(s) used in the simulations of each experiment for simulations of a specified sample size (default 0).</p>
</td></tr>
<tr><td><code id="calculate2GType1Error_+3A_sd">sd</code></td>
<td>
<p>This is the standard deviation  value of the control group(s) and treatment group(s) used in the simulations of each experiment of each family for simulations of a specified sample size (default 1).</p>
</td></tr>
<tr><td><code id="calculate2GType1Error_+3A_n">N</code></td>
<td>
<p>This specifies the sample size per group that will be used in each set of simulations (default 5).</p>
</td></tr>
<tr><td><code id="calculate2GType1Error_+3A_reps">reps</code></td>
<td>
<p>The number of experiments to simulated.</p>
</td></tr>
<tr><td><code id="calculate2GType1Error_+3A_type">type</code></td>
<td>
<p>This specifies the distribution of the data samples that will be simulated. Options ae &quot;n&quot; for Normal, &quot;l&quot;, for Log-normal,'g&quot; for Gamma, &quot;lap&quot; for LaPlace (default &quot;n&quot;).</p>
</td></tr>
<tr><td><code id="calculate2GType1Error_+3A_seed">seed</code></td>
<td>
<p>A seed for the simulations (default 123).</p>
</td></tr>
<tr><td><code id="calculate2GType1Error_+3A_stdadj">StdAdj</code></td>
<td>
<p>Used to introduce variance heterogeneity for Laplace and Normal samples(default 0).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Design. Specifies the type of experiment 2G or 4G, the sample distribution (n,l,g,lap), and whether variance heterogeneity was added (het)
</p>
<p>GrpSize. Specifies the size of each group in the individual experiments.
</p>
<p>ObsPHat. The average Phat values found in the set of simulations.
</p>
<p>ObsCliffd. The average Cliffd values found  in the set of simulations.
</p>
<p>ObsStdES. The average of StdMD values found in the set of simulations.
</p>
<p>PHatType1ER. The proportion of the simulations for which the Phat estimate was significantly different from zero at the nominated alpha level.
</p>
<p>CliffdType1ER. The  proportion of the simulations for which the  Cliff's d estimate was significantly different from zero at the nominated alpha level.
</p>
<p>StdMDType1ER. The  proportion of the simulations for which the StdMD estimate was significantly different from zero at the nominated 0.05 significance level.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>calculate2GType1Error(mean=1,sd=3,N=10,reps=100,type="g",seed=3256,StdAdj = 0)
# A tibble: 1 x 8
#   Design GrpSize ObsPHat ObsCliffd ObsStdES PHatType1ER CliffdType1ER StdESType1ER
#   &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;
# 1 2G_g   10        0.498   -0.0034 -0.00464        0.02          0.01         0.02
</code></pre>

<hr>
<h2 id='calculate4GBias'>calculate4GBias</h2><span id='topic+calculate4GBias'></span>

<h3>Description</h3>

<p>The function simulates four-group experiments and estimates of the power, individual estimate error and small sample bias obtained from a set of simulated experiments. The function produces three set of simulations obtained using three different values of the mean difference between the treatment and control groups as specified by the parameter &quot;diff&quot;. The power is estimated as the percentage of simulated experiments for which the mean of the experiment was significantly different from zero using one-sided tests. The experiment data may be one of four different type: Normal, Log-normal, Gamma or Laplace. The output is a table of values identifying the observed values of three effect sizes: Cliff's d, PHat and StdMD, their relted estimate error, small sample bias and power for each set of simulated experiments. This function supports the production of the values reported in data tables in the paper &quot;Recommendations for Analyzing Small Sample Size&quot; and its Supplementary Material.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculate4GBias(
  mean = 0,
  sd = 1,
  N,
  reps,
  diff = c(0.2, 0.5, 0.8),
  Expected.StdMD = c(0.2, 0.5, 0.8),
  Expected.PHat = c(0.556, 0.638, 0.714),
  type = "n",
  seed = 223,
  StdAdj = 0,
  Blockmean = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calculate4GBias_+3A_mean">mean</code></td>
<td>
<p>This is the mean value of the control group(s) used in the simulations of each experiment for simulations of a specified mean difference (default 0).</p>
</td></tr>
<tr><td><code id="calculate4GBias_+3A_sd">sd</code></td>
<td>
<p>This is the standard deviation  value of the control group(s) and treatment group(s) used in the simulations of each experiment of each family for simulations of a specified sample size (default 1).</p>
</td></tr>
<tr><td><code id="calculate4GBias_+3A_n">N</code></td>
<td>
<p>This specifies the sample size per group that will be used in each set of simulations.</p>
</td></tr>
<tr><td><code id="calculate4GBias_+3A_reps">reps</code></td>
<td>
<p>The number of families simulated for each sample size.</p>
</td></tr>
<tr><td><code id="calculate4GBias_+3A_diff">diff</code></td>
<td>
<p>This specifies the difference between the control and treatment that will be used in each set of simulations. It must always have three values representing small, medium and large mean differences (default c(0.2, 0.5, 0.8)).</p>
</td></tr>
<tr><td><code id="calculate4GBias_+3A_expected.stdmd">Expected.StdMD</code></td>
<td>
<p>This defines the expected value of the overall average StdMD for each mean difference (default c(0.2, 0.5, 0.8)).</p>
</td></tr>
<tr><td><code id="calculate4GBias_+3A_expected.phat">Expected.PHat</code></td>
<td>
<p>This defines the expected population value of the overall average Phat for each mean difference (default c(0.556,0.638,0.714)).</p>
</td></tr>
<tr><td><code id="calculate4GBias_+3A_type">type</code></td>
<td>
<p>This specifies the distribution of the data samples that will be simulated. Options ae &quot;n&quot; for Normal, &quot;l&quot;, for Log-normal,'g&quot; for Gamma, &quot;lap&quot; for LaPlace (default &quot;n&quot;).</p>
</td></tr>
<tr><td><code id="calculate4GBias_+3A_seed">seed</code></td>
<td>
<p>A seed for the simulations (default 123).</p>
</td></tr>
<tr><td><code id="calculate4GBias_+3A_stdadj">StdAdj</code></td>
<td>
<p>Used to introduce variance heterogeneity for Laplace and Normal samples (default 0).</p>
</td></tr>
<tr><td><code id="calculate4GBias_+3A_blockmean">Blockmean</code></td>
<td>
<p>Specifies he value of the block effect (default 0).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Design. Specifies the type of experiment 2G, the sample distribution (n,l,g,lap), and whether variance heterogeneity was added (het)
</p>
<p>BEIncluded. Specifies whether or not a block effect was introduced.
</p>
<p>GrpSize. Specifies the size of each group in the individual experiments.
</p>
<p>Diff. The size of the difference between the control and treatment converted to an ordinal scale (Small, Medium, Large)
</p>
<p>NPBias The relative difference between the average of the observed values of either Cliff's d or centralised PHat and the population value
</p>
<p>StdMDBias. The relative difference between the average of the observed values of StdMDBias and the theoretical value
</p>
<p>NPMdMRE The median of the absolute relative difference between the observed values of either Cliff's d or centralised PHat and the theoretical value for each experiment.
</p>
<p>StdMDMdMRE The median of the relative difference between the observed values of StdMD and the population value for each experiment.
</p>
<p>ObsPHat. The average Phat value found for each simulation.
</p>
<p>ObsCliffd. The  average Cliffd value found for each simulation.
</p>
<p>ObsStdES. The average of StdMD calculated for each simulation.
</p>
<p>PHatPower. The proportion of the simulations, for a given mean difference, for which the  Phat estimate was significantly different from zero at the 0.05 alpha level based on one-sided tests.
</p>
<p>CliffdPower. The proportion of the simulations, for a given mean difference, for which the Cliff's d estimate was significantly different from zero at the 0.05 alpha level based on one-sided tests.
</p>
<p>StdMDPower. The proportion of the simulations, for a given mean difference, for which the StdMD estimate was significantly different from zero at the 0.05 alpha level based on one-sided tests.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#as.data.frame(calculate4GBias(mean=0,sd=1,diff=c(0.266,0.72375,1.43633),
#  Expected.StdMD=c(0.2,0.5,0.8),Expected.PHat=c(0.575,0.696,0.845),N=10,reps=200,type="l",
#  seed=17+1823,StdAdj=0,Blockmean=0))
#  Design BEIncluded GrpSize   Diff      NPBias StdMDBias   NPMdMRE StdMDMdMRE  ObsPHat ObsCliffd.
#  1 4G_l         No      10  Small -0.05933333 0.1247408 0.8666667  1.2047848 0.570550   0.1411..
#  2 4G_l         No      10 Medium -0.01760204 0.1565643 0.3112245  0.4426859 0.692550   0.3851..
#  3 4G_l         No      10  Large -0.00326087 0.2273638 0.1594203  0.2924361 0.843875   0.6877..
as.data.frame(calculate4GBias(mean=1,sd=3,diff=c(0.1225,0.3415,0.6224),
 Expected.StdMD=c(-0.208,-0.52,-0.833),Expected.PHat=c(0.444,0.360,0.277),N=20,reps=30,type="g",
 seed=17+977,StdAdj=0 ,Blockmean=0.5))
# Results for reps=200:
#  Design BEIncluded GrpSize   Diff     NPBias  StdMDBias   NPMdMRE StdMDMdMRE   ObsPHat  ObsCli..
#1   4G_g        Yes      20  Small 0.04274554 0.02242895 0.8370536  0.7960052 0.4416062 -0.1167..
#2   4G_g        Yes      20 Medium 0.01959821 0.01585829 0.3348214  0.3210435 0.3572562 -0.2854..
#3   4G_g        Yes      20  Large 0.01303251 0.01515967 0.1905830  0.1871956 0.2740938 -0.4518..
</code></pre>

<hr>
<h2 id='calculate4GType1Error'>calculate4GType1Error</h2><span id='topic+calculate4GType1Error'></span>

<h3>Description</h3>

<p>The function simulates multiple four-group experiments and estimates the Type1 Error rate obtained from the set of simulated experiments. The Type1 Error is estimated as the percentage of experiments for which the mean the experiment was significantly different from zero at the 0.05 significance level using two-sided tests. The experiment data may be one of four different type: Normal, Log-normal, Gamma or Laplace. The output is a set of values identifying three observed effect size estimates (Cliff's d, PHat and StdMD) and their related type 1 error rates. This function supports the production of the values reported in data tables in the paper &quot;Recommendations for Analyzing Small Sample Size Software Engineering Experiments&quot; and its Supplementary Material.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculate4GType1Error(
  mean = 0,
  sd = 1,
  N = 10,
  reps = 10,
  type = "n",
  seed = 123,
  StdAdj = 0,
  Blockmean = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calculate4GType1Error_+3A_mean">mean</code></td>
<td>
<p>This is the mean value of the control and treatment group(s) used in the simulations (default 0).</p>
</td></tr>
<tr><td><code id="calculate4GType1Error_+3A_sd">sd</code></td>
<td>
<p>This is the standard deviation  value of the control group(s) and treatment group(s) used in the simulations (default 1).</p>
</td></tr>
<tr><td><code id="calculate4GType1Error_+3A_n">N</code></td>
<td>
<p>This specifies the sample size per group that will be used in each simulation (default 5).</p>
</td></tr>
<tr><td><code id="calculate4GType1Error_+3A_reps">reps</code></td>
<td>
<p>The number of experiments to simulated.</p>
</td></tr>
<tr><td><code id="calculate4GType1Error_+3A_type">type</code></td>
<td>
<p>This specifies the distribution of the data samples that will be simulated. Options are &quot;n&quot; for Normal, &quot;l&quot;, for Log-normal,'g&quot; for Gamma, &quot;lap&quot; for LaPlace (default &quot;n&quot;).</p>
</td></tr>
<tr><td><code id="calculate4GType1Error_+3A_seed">seed</code></td>
<td>
<p>A seed for the simulations (default 123).</p>
</td></tr>
<tr><td><code id="calculate4GType1Error_+3A_stdadj">StdAdj</code></td>
<td>
<p>Used to introduce variance heterogeneity for Laplace and Normal samples (default 0).</p>
</td></tr>
<tr><td><code id="calculate4GType1Error_+3A_blockmean">Blockmean</code></td>
<td>
<p>Used to specify the block effect (default 0).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Design. Specifies the type of experiment 2G or 4G, the sample distribution (n,l,g,lap), and whether variance heterogeneity was added (het)
</p>
<p>GrpSize. Specifies the size of each group in the simulations.
</p>
<p>BEIncluded. Specifies whether or not a block effect was introduced.
</p>
<p>ObsPHat. The average of the average Phat values found in the set of simulations.
</p>
<p>ObsCliffd. The average of the average Cliffd values found  in the set of simulations.
</p>
<p>ObsStdES. The average of StdMD values found in the set of simulations.
</p>
<p>PHatType1ER. The percentage of the simulations for which the Phat estimate was significantly different from zero at the 0.05 alpha level.
</p>
<p>CliffdType1ER. The percentage of the simulations for which the overall Cliff's d estimate was significantly different from zero at the 0.05 alpha level.
</p>
<p>StdMDType1ER. The percentage of the simulations for which the overall StdMD estimate was significantly different from zero at the 0.05 significance level.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>as.data.frame(calculate4GType1Error(mean=0,sd=1,N=40,reps=100,type="n",seed=17+1056,StdAdj = 0.5,
 Blockmean=0.5))
 # Results for reps=300
#    Design GrpSize BEIncluded   ObsPHat   ObsCliffd   ObsStdES PHatType1ER CliffdType1ER StdES..
#1 4G_n_het      40        Yes 0.5034729 0.006945833 0.01316457        0.03    0.02333333 0.046..

#as.data.frame(calculate4GType1Error(mean=0,sd=1,N=40,reps=300,type="lap",seed=17+2056,
#  StdAdj = 0.5,Blockmean=0.5))
#      Design GrpSize BEIncluded   ObsPHat    ObsCliffd  ObsStdES PHatType1ER CliffdType1ER Std..
#1 4G_lap_het      40        Yes 0.4992708 -0.001458333 0.0014446  0.04333333          0.04  0.06
</code></pre>

<hr>
<h2 id='calculateBasicStatistics'>calculateBasicStatistics</h2><span id='topic+calculateBasicStatistics'></span>

<h3>Description</h3>

<p>This function calculates the following statistics for a set of data: length, mean, median, variance, standard error of the mean, and confidence interval bounds. The input data must be a vector of 2 or more numerical values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculateBasicStatistics(x, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calculateBasicStatistics_+3A_x">x</code></td>
<td>
<p>The data to be summarized</p>
</td></tr>
<tr><td><code id="calculateBasicStatistics_+3A_alpha">alpha</code></td>
<td>
<p>The probability level to be used when constructing the confidence interval bounds.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe comprising the length, mean, variance, standard error and confidence limit bounds of the input data x.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ShortExperimentNames &lt;- c("E1", "E2", "E3", "E4")
FullExperimentNames &lt;- c("EUBAS", "R1UCLM", "R2UCLM", "R3UCLM")
Metrics &lt;- c("Comprehension", "Modification")
Groups &lt;- c("A", "B", "C", "D")
Type &lt;- c(rep("4G", 4))
StudyID &lt;- "S2"
Control &lt;- "SC"
ReshapedData &lt;- ExtractExperimentData(
  KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14TOSEM,
  ExperimentNames = FullExperimentNames, idvar = "ParticipantID",
  timevar = "Period", ConvertToWide = TRUE
)
NewTable &lt;- ConstructLevel1ExperimentRData(
  ReshapedData, StudyID, ShortExperimentNames, Groups,
  Metrics, Type, Control
)
calculateBasicStatistics(NewTable$r)
#    N    Mean Median Variance      SE LowerBound UpperBound
# 1 32 0.06175 0.1688   0.2482 0.08808    -0.1109     0.2344

</code></pre>

<hr>
<h2 id='calculateCliffd'>calculateCliffd</h2><span id='topic+calculateCliffd'></span>

<h3>Description</h3>

<p>This function implements finds Cliff's d and its confidence intervals. The null hypothesis is that for two independent group, P(X&lt;Y)=P(X&gt;Y). The function reports a 1-alpha confidence interval for P(X&gt;Y)-P(X&lt;Y). The algorithm computes a confidence interval for Cliff's d using the method in Cliff, 1996, p. 140, eq 5.12. The function is based on code produce by Rand Wilcox but has been amended. The plotting function has been removed and the dependency on Wilcox's binomci function has been removed. Construction of confidence intervals if values in one group are all larger than values in the other group has been amended to use the smallest non-zero variance method. Upper and lower confidence interval bounds cannot assume invalid values, i.e. values &lt;-1 or &gt;1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculateCliffd(x, y, alpha = 0.05, sigfig = -1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calculateCliffd_+3A_x">x</code></td>
<td>
<p>is a vector of values from group 1</p>
</td></tr>
<tr><td><code id="calculateCliffd_+3A_y">y</code></td>
<td>
<p>is a vector of values from group 2</p>
</td></tr>
<tr><td><code id="calculateCliffd_+3A_alpha">alpha</code></td>
<td>
<p>is the Type 1 error level for statistical tests</p>
</td></tr>
<tr><td><code id="calculateCliffd_+3A_sigfig">sigfig</code></td>
<td>
<p>is the number of significant digit. If sigfig&gt;0 the data in x and y is truncated to the specified value.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list including the value of Cliffs d its consistent variance and confidence intervals and the equivalent probability of superiority value and its confidence intervals.
</p>


<h3>Author(s)</h3>

<p>Rand Wilcox, amendments Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x=c(1.2,3,2.2,4,2.5,3)
y=c(3,4.2,4,6,7,5.9)
calculateCliffd(x,y)
#  $n1
# [1] 6
# $n2
# [1] 6
# $d
# [1] -0.8611111
# $sqse.d
# [1] 0.02017931
# $phat
# [1] 0.06944444
z=c(1,2,3,4)
y=c(5,6,7,8)
calculateCliffd(z,y)
# $n1
# [1] 4
# $n2
# [1] 4
# $d
# [1] -1
# $sqse.d
# [1] 0.009765625
# $phat
# [1] 0
</code></pre>

<hr>
<h2 id='calculateGroupSummaryStatistics'>calculateGroupSummaryStatistics</h2><span id='topic+calculateGroupSummaryStatistics'></span>

<h3>Description</h3>

<p>This function calculates the following statistics data within groups: length, mean, median, variance, standard error of the mean, and confidence interval bounds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculateGroupSummaryStatistics(x, Group)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calculateGroupSummaryStatistics_+3A_x">x</code></td>
<td>
<p>The data to be summarized. This must be a vector of 2 or more numerical values</p>
</td></tr>
<tr><td><code id="calculateGroupSummaryStatistics_+3A_group">Group</code></td>
<td>
<p>The categorical data data defining the groups. This must vector of the same length as x containing factors specifying the data groups</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe comprising the number, mean, variance, standard error and confidence limit bounds of the data in each category
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ShortExperimentNames &lt;- c("E1", "E2", "E3", "E4")
FullExperimentNames &lt;- c("EUBAS", "R1UCLM", "R2UCLM", "R3UCLM")
Metrics &lt;- c("Comprehension", "Modification")
Groups &lt;- c("A", "B", "C", "D")
Type &lt;- c(rep("4G", 4))
StudyID &lt;- "S2"
Control &lt;- "SC"
ReshapedData &lt;- ExtractExperimentData(
  KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14TOSEM,
  ExperimentNames = FullExperimentNames, idvar = "ParticipantID", timevar = "Period",
  ConvertToWide = TRUE
)
NewTable &lt;- ConstructLevel1ExperimentRData(
  ReshapedData, StudyID,
  ShortExperimentNames, Groups, Metrics, Type, Control
)
SeqGroupLev &lt;- NULL
N.NT &lt;- length(NewTable$r)
for (i in 1:N.NT) {
  if (NewTable$n[i] &lt;= 8) SeqGroupLev[i] &lt;- as.character(NewTable$n[i])
  if (NewTable$n[i] &gt; 8) SeqGroupLev[i] &lt;- as.character(9)
}
calculateGroupSummaryStatistics(NewTable$r, Group = SeqGroupLev)
#     N    Mean  Median Variance  StDev     SE
#  1  4 -0.0833 -0.1699   0.2314 0.4810 0.2405
#  2 12  0.3658  0.4477   0.2109 0.4592 0.1326
#  3 16 -0.1300 -0.2214   0.1933 0.4397 0.1099

</code></pre>

<hr>
<h2 id='calculateHg'>calculateHg</h2><span id='topic+calculateHg'></span>

<h3>Description</h3>

<p>This function calculates Hedges g and Hedges g adjusted given the basic experimental statistics - the mean values for participants, number of observations (participants), and standard deviation in both the control group and the treatment group. . Hence, the function assumes the data is held as summary statistics including the control group mean, standard deviation and sample size and equivalent values for treatment group
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculateHg(Mc, Mt, Nc, Nt, SDc, SDt)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calculateHg_+3A_mc">Mc</code></td>
<td>
<p>is a vector containing the mean value of the control group for each experiment.</p>
</td></tr>
<tr><td><code id="calculateHg_+3A_mt">Mt</code></td>
<td>
<p>is a vector containing the mean value of the treatment group for each experiment.</p>
</td></tr>
<tr><td><code id="calculateHg_+3A_nc">Nc</code></td>
<td>
<p>is a vector containing the the number of observations (participants) in the control group for each experiment.</p>
</td></tr>
<tr><td><code id="calculateHg_+3A_nt">Nt</code></td>
<td>
<p>is a vector of the number of observations (participants) in the treatment group for each experiment.</p>
</td></tr>
<tr><td><code id="calculateHg_+3A_sdc">SDc</code></td>
<td>
<p>is a vector of the standard deviations of the control group for each experiment.</p>
</td></tr>
<tr><td><code id="calculateHg_+3A_sdt">SDt</code></td>
<td>
<p>is a vector of the standard deviations of the the treatment group for each experiment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame composed of Hedges' g and Hedges' g adjusted effect sizes
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>calculateHg(10, 15, 20, 20, 2, 2)
#    Hg    HgAdjusted
# 1  2.5   2.450276
</code></pre>

<hr>
<h2 id='calculateKendalltaupb'>@title calculateKendalltaupb
@description  Computes point bi-serial version of  Kendall's tau plus a 1-alpha confidence interval using the method recommended by Long and Cliff (1997).  The algorithm is based on Wilcox's code but was extended to return the consistent variance and the confidence intervals based on the t-distribution. Also added a Diagnostic parameter to output internal calculations.</h2><span id='topic+calculateKendalltaupb'></span>

<h3>Description</h3>

<p>@title calculateKendalltaupb
@description  Computes point bi-serial version of  Kendall's tau plus a 1-alpha confidence interval using the method recommended by Long and Cliff (1997).  The algorithm is based on Wilcox's code but was extended to return the consistent variance and the confidence intervals based on the t-distribution. Also added a Diagnostic parameter to output internal calculations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculateKendalltaupb(x, y = NULL, alpha = 0.05, alternative = "two.sided")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calculateKendalltaupb_+3A_x">x</code></td>
<td>
<p>either a matrix with two columns containing two correlated variables or a vector of variables</p>
</td></tr>
<tr><td><code id="calculateKendalltaupb_+3A_y">y</code></td>
<td>
<p>if y=NULL, assume x is a matrix with two columns, otherwise y is a vector of variables with x[i] and y[i] being from the same experimental unit</p>
</td></tr>
<tr><td><code id="calculateKendalltaupb_+3A_alpha">alpha</code></td>
<td>
<p>the Type 1 error level used for statistical tests (default 0.05)</p>
</td></tr>
<tr><td><code id="calculateKendalltaupb_+3A_alternative">alternative</code></td>
<td>
<p>The type of statistical test. Valid values are one of
c('two.sided', 'greater', 'less')</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list containing the estimate of Kendall's tau, the consistent variance of tau and its confidence intervals based on the t-test (recommended by Long and Cliff)
</p>


<h3>Author(s)</h3>

<p>Rand Wilcox, Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
a &lt;- c(1.2, 3, 1.8, 2, 2, 0.5, 0.5, 1, 3, 1)
b &lt;- c(1, 1, 1, 1, 1, 0, 0, 0, 0, 0)
calculateKendalltaupb(a,b,alpha=.05)
#$cor
#[1] 0.3555556
#$cit
#[1] -0.1240567  0.5555556
#$n
#[1] 10
#$df
#[1] 7
#$consistentvar
#[1] 0.04113925
#$sig
#[1] FALSE
set.seed(234)
a2=c(rnorm(10,0,1),rnorm(10,0.5,1))
b2=c(rep(0,10),rep(1,10))
calculateKendalltaupb(a2,b2,alpha=.05,alternative='greater')
#$cor
#[1] 0.2842105
#$cit
#[1] 0.06517342 0.52631579
#$n
#[1] 20
#$df
#[1] 17
#consistentvar
#1] 0.01585379
#$sig
#[1] TRUE
calculateKendalltaupb(a2,b2,alpha=.05,alternative='less')
#$cor
#[1] 0.2842105
#$cit
#[1] -0.5263158  0.5032476
#$n
#[1] 20
#$df
#[1] 17
#$consistentvar
#[1] 0.01585379
#$sig
#[1] FALSE
</code></pre>

<hr>
<h2 id='calculateLargeSampleRandomizedBlockDesignEffectSizes'>calculateLargeSampleRandomizedBlockDesignEffectSizes</h2><span id='topic+calculateLargeSampleRandomizedBlockDesignEffectSizes'></span>

<h3>Description</h3>

<p>The function uses a simulates a large experiment  to estimate the asymptotic values of the probability of superiority, Cliff's d and the standardized mean difference data for a four group randomized blocks experiment for four different distributions: Normal (i.e. type='n'), log-normal (i.e. type='l'), gama (i.e. type='g') and Laplace (i.e., type='lap').
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculateLargeSampleRandomizedBlockDesignEffectSizes(
  meanC = 0,
  sdC = 1,
  diff,
  N = 5e+06,
  type = "n",
  Blockmean = 0,
  StdAdj = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calculateLargeSampleRandomizedBlockDesignEffectSizes_+3A_meanc">meanC</code></td>
<td>
<p>to act as the mean of the distribution (default 0) used to
generate the control group data (note for the gamma distribution this is the
rate parameter and must not be zero)</p>
</td></tr>
<tr><td><code id="calculateLargeSampleRandomizedBlockDesignEffectSizes_+3A_sdc">sdC</code></td>
<td>
<p>the variance/spread of the distribution (default 1) used to
generate the control group data.</p>
</td></tr>
<tr><td><code id="calculateLargeSampleRandomizedBlockDesignEffectSizes_+3A_diff">diff</code></td>
<td>
<p>a value added to meanC to generate the treatment group data
(default 0).</p>
</td></tr>
<tr><td><code id="calculateLargeSampleRandomizedBlockDesignEffectSizes_+3A_n">N</code></td>
<td>
<p>the size of each group (default 5000000)</p>
</td></tr>
<tr><td><code id="calculateLargeSampleRandomizedBlockDesignEffectSizes_+3A_type">type</code></td>
<td>
<p>the distribution of the data to be generated. One of: 'n' for
normal (default), 'l' for log-normal, 'g' for gamma, and 'lap' for Laplace.</p>
</td></tr>
<tr><td><code id="calculateLargeSampleRandomizedBlockDesignEffectSizes_+3A_blockmean">Blockmean</code></td>
<td>
<p>a value that can be added one of the blocks to represent
a fixed block effect (default 0).</p>
</td></tr>
<tr><td><code id="calculateLargeSampleRandomizedBlockDesignEffectSizes_+3A_stdadj">StdAdj</code></td>
<td>
<p>a value that can be added to sdC to introduce heterogeneity
into the treatment group (default 0).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble identifying the sample statistics and the values of the
probability of superiority, Cliff's d and StdMD (labelled StdES)
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed=400
calculateLargeSampleRandomizedBlockDesignEffectSizes(
  meanC=0, sdC=1, diff=.5, N=100000, type='n',Blockmean=0.5,StdAdj = 0)
#  MeanC   SdC MeanT   SdT    BE  Phat Cliffd   UES   Var StdES
#  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
#1     0     1   0.5     1   0.5 0.638  0.277 0.501 0.998 0.502

</code></pre>

<hr>
<h2 id='calculateLargeSampleRandomizedDesignEffectSizes'>calculateLargeSampleRandomizedDesignEffectSizes</h2><span id='topic+calculateLargeSampleRandomizedDesignEffectSizes'></span>

<h3>Description</h3>

<p>The function simulates a large experiment  to estimate the asymptotic values of the probability of superiority, Cliff's d and the standardized mean difference data for a two group randomized experiment for four different distributions: Normal (i.e. type=&quot;n&quot;), log-normal (i.e. type=&quot;l&quot;), gama (i.e. tyep=&quot;g&quot;) and Laplace (i.e., type=&quot;lap&quot;).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculateLargeSampleRandomizedDesignEffectSizes(
  meanC = 0,
  sdC = 1,
  diff = 0,
  N = 5e+06,
  type = "n",
  StdAdj = 0,
  reporttrans = "No"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calculateLargeSampleRandomizedDesignEffectSizes_+3A_meanc">meanC</code></td>
<td>
<p>to act as the mean of the distribution used to generate the control group data (default 0) (note for the gamma distribution this is the rate parameter and must not be zero)</p>
</td></tr>
<tr><td><code id="calculateLargeSampleRandomizedDesignEffectSizes_+3A_sdc">sdC</code></td>
<td>
<p>the variance/spread of the distribution used to generate the control group data (default 1).</p>
</td></tr>
<tr><td><code id="calculateLargeSampleRandomizedDesignEffectSizes_+3A_diff">diff</code></td>
<td>
<p>a value added to meanC to generate the treatment group data (default 0).</p>
</td></tr>
<tr><td><code id="calculateLargeSampleRandomizedDesignEffectSizes_+3A_n">N</code></td>
<td>
<p>the size of each group (default 5000000)</p>
</td></tr>
<tr><td><code id="calculateLargeSampleRandomizedDesignEffectSizes_+3A_type">type</code></td>
<td>
<p>the distribution of the data to be generated (default &quot;n&quot;).</p>
</td></tr>
<tr><td><code id="calculateLargeSampleRandomizedDesignEffectSizes_+3A_stdadj">StdAdj</code></td>
<td>
<p>a value that can be added to sdC to introduce heterogeneity into the treatment group (default 0).</p>
</td></tr>
<tr><td><code id="calculateLargeSampleRandomizedDesignEffectSizes_+3A_reporttrans">reporttrans</code></td>
<td>
<p>If set to &quot;Yes&quot; AND type=&quot;l&quot; the algorithm returns the values obtained by analysing applying the logarithmic transformation to the simulated data (default &quot;No&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble identifying the sample statistics and the values of the probability of superiority, Cliff's d and StdMD (labelled StdES)
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed=400
calculateLargeSampleRandomizedDesignEffectSizes(meanC=0, sdC=1, diff=.5,
N=10000, type="n",StdAdj = 0) #N=100000, type="n",StdAdj = 0)
# A tibble: 1 x 9
#     MeanC   SdC MeanT   SdT  Phat Cliffd   UES   Var StdES
#     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
#1  0.00642  1.00 0.519 0.995 0.642  0.284 0.513 0.996 0.514
#1     0     1   0.5     1 0.637  0.275 0.499  1.01 0.497
as.data.frame(calculateLargeSampleRandomizedDesignEffectSizes(meanC=0, sdC=1, diff=0.707104,
N=100000, type="l",StdAdj = 0,reporttrans="Yes"))
#N=1000000, type="l",StdAdj = 0,reporttrans="Yes"))
#     MeanC     StdC    MeanT     StdT      Phat    Cliffd      UES      Var
#1 1.647446 2.219114  3.33124 4.404537 0.6926779 0.3853558 1.683795 12.1622
#       StdES   MeanCTrans MeanTTrans StdCTrans StdTTrans PhatTrans CliffdTrans
#1  0.4828175 -0.004298487  0.7066049  1.001199 0.9963736 0.6926779   0.3853558
#   UESTrans VarTrans StdESTrans
#1 0.7109034  0.99758  0.7117651
</code></pre>

<hr>
<h2 id='CalculateLevel2ExperimentRData'>CalculateLevel2ExperimentRData</h2><span id='topic+CalculateLevel2ExperimentRData'></span>

<h3>Description</h3>

<p>This function analyses data on r values obtained in the format obtained from  the ConstructLevel1ExperimentRData function and finds the r-value for each metric for each experiment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CalculateLevel2ExperimentRData(
  Level1Data,
  Groups,
  StudyID,
  ExperimentNames,
  Metrics,
  Type
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CalculateLevel2ExperimentRData_+3A_level1data">Level1Data</code></td>
<td>
<p>a tibble in the format produced by the ConstructLevel1ExperimentRData function which has r-values for each sequence group in a crossover experiment</p>
</td></tr>
<tr><td><code id="CalculateLevel2ExperimentRData_+3A_groups">Groups</code></td>
<td>
<p>This is a list that defines the sequence group labels used in the dataset.</p>
</td></tr>
<tr><td><code id="CalculateLevel2ExperimentRData_+3A_studyid">StudyID</code></td>
<td>
<p>This holds an identifier used to identify the origin of the experimental data in the output from this function.</p>
</td></tr>
<tr><td><code id="CalculateLevel2ExperimentRData_+3A_experimentnames">ExperimentNames</code></td>
<td>
<p>This a list of identifiers used to define each experiment in the output from this function.</p>
</td></tr>
<tr><td><code id="CalculateLevel2ExperimentRData_+3A_metrics">Metrics</code></td>
<td>
<p>This is a list of of character strings identifying each outcome metric reported in each of the experiments in the set of replicated experiments.</p>
</td></tr>
<tr><td><code id="CalculateLevel2ExperimentRData_+3A_type">Type</code></td>
<td>
<p>this is a list of character strings specifying for each experiment whether the experiment is a two sequence group '2G' or four sequence group '4G' experiment.
return RExp.Table This is a table containing the pooled data variance and the pooled difference variance for the experiment and the value r for the experiment for each metric</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ShortExperimentNames &lt;- c("E1", "E2", "E3", "E4")
FullExperimentNames &lt;- c("EUBAS", "R1UCLM", "R2UCLM", "R3UCLM")
Metrics &lt;- c("Comprehension", "Modification")
Groups &lt;- c("A", "B", "C", "D")
Type &lt;- c(rep("4G", 4))
StudyID &lt;- "S2"
Control &lt;- "SC"
# Obtain experimental data from each file and put in wide format
ReshapedData &lt;- ExtractExperimentData(
  KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14TOSEM,
  ExperimentNames = FullExperimentNames, idvar = "ParticipantID",
  timevar = "Period", ConvertToWide = TRUE
)
Lev1Data &lt;- ConstructLevel1ExperimentRData(
  ReshapedData, StudyID, ShortExperimentNames, Groups,
  Metrics, Type, Control
)
CalculateLevel2ExperimentRData(Lev1Data,
  Groups = Groups, StudyID = StudyID,
  ExperimentNames = ShortExperimentNames, Metrics = Metrics, Type = Type
)
# A tibble: 8 x 10
#  StudyID ExpID     N Metric        PooledVar1 PooledVar2 VarProp PooledVar PooledDiffVar    r.Exp
#  &lt;chr&gt;   &lt;chr&gt; &lt;int&gt; &lt;chr&gt;              &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt;
# 1 S2      S2E1     24 Comprehension     0.0148     0.0212   0.412    0.0180        0.0248  0.311
# 3 S2      S2E2     22 Comprehension     0.0487     0.0224   0.684    0.0356        0.0534  0.250
# 4 S2      S2E2     22 Modification      0.0445     0.0266   0.626    0.0356        0.0628  0.117
# 5 S2      S2E3     22 Comprehension     0.0353     0.0402   0.467    0.0377        0.105  -0.391
# 6 S2      S2E3     22 Modification      0.0433     0.0414   0.511    0.0424        0.0997 -0.176
# 7 S2      S2E4     18 Comprehension     0.0439     0.0237   0.649    0.0338        0.0355  0.475
# 8 S2      S2E4     18 Modification      0.0322     0.0592   0.353    0.0457        0.0894  0.0222

</code></pre>

<hr>
<h2 id='calculateMABias'>calculateMABias</h2><span id='topic+calculateMABias'></span>

<h3>Description</h3>

<p>The function simulates multiple five group families of either two-group or four-group experiments and estimates the power, individual estimate error, and the small sample bias obtained after synthesizing the analysis results obtained from the experiments in each family. The power is estimated as the percentage of families for which the overall mean of the five experiments was significantly different from zero. The experiment data may be one of four different type: Normal, Log-normal, Gamma or Laplace. The simulations can be repeated for different mean differences between the control mean and treatment mean depending on the parameter diff. The output is a table of values identifying the observed values of three effect sizes: Cliff's d, PHat and StdMD, estimate error and their related small sample bias and power for each set of simulated families. The synthesis method for all the effect sizes is based on calculating the overall mean and variance for experiments in each family and then using those values to calculate the overall effect size and its variance. This function supports the production of the values reported in data tables in the paper &quot;Recommendations for Analyzing Small Sample Size Software Engineering Experiments&quot; and its Supplementary Material.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculateMABias(
  mean = 0,
  sd = 1,
  N,
  reps,
  diff = c(0.2, 0.5, 0.8),
  Experiments = 5,
  Expected.StdMD = c(0.2, 0.5, 0.8),
  Expected.PHat = c(0.556, 0.638, 0.714),
  type = "n",
  FourG = FALSE,
  seed = 223,
  StdAdj = 0,
  Blockmean = 0,
  StdExp = 0,
  MAMethod = "PM",
  alpha = 0.05
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calculateMABias_+3A_mean">mean</code></td>
<td>
<p>This is the mean value of the control and treatment group(s) used in the simulations of each experiment of each family for simulations of a specified sample size (default 0).</p>
</td></tr>
<tr><td><code id="calculateMABias_+3A_sd">sd</code></td>
<td>
<p>This is the standard deviation  value of the control group(s) and treatment group(s) used in the simulations of each experiment of each family for simulations of a specified sample size (default 1).</p>
</td></tr>
<tr><td><code id="calculateMABias_+3A_n">N</code></td>
<td>
<p>This specifies the sample size per group that will be used in each set of simulations.</p>
</td></tr>
<tr><td><code id="calculateMABias_+3A_reps">reps</code></td>
<td>
<p>The number of families simulated for each sample size.</p>
</td></tr>
<tr><td><code id="calculateMABias_+3A_diff">diff</code></td>
<td>
<p>This specifies the difference between the control and treatment that will be used in each set of simulations. It must always have three values representing small, medium and large values (default c(0.2, 0.5, 0.8)).</p>
</td></tr>
<tr><td><code id="calculateMABias_+3A_experiments">Experiments</code></td>
<td>
<p>The number of experiments in each family (default 5).</p>
</td></tr>
<tr><td><code id="calculateMABias_+3A_expected.stdmd">Expected.StdMD</code></td>
<td>
<p>This defines the expected value of the overall average StdMD for each mean difference (default c(0.2,0.5,0.8)).</p>
</td></tr>
<tr><td><code id="calculateMABias_+3A_expected.phat">Expected.PHat</code></td>
<td>
<p>This defines the expected population value of the overall average Phat for each mean difference (default c(0.556,0.638,0.714)).</p>
</td></tr>
<tr><td><code id="calculateMABias_+3A_type">type</code></td>
<td>
<p>This specifies the distribution of the data samples that will be simulated. Options ae &quot;n&quot; for Normal, &quot;l&quot;, for Log-normal,'g&quot; for Gamma, &quot;lap&quot; for LaPlace (default &quot;n&quot;).</p>
</td></tr>
<tr><td><code id="calculateMABias_+3A_fourg">FourG</code></td>
<td>
<p>If FourG is FALSE (default) the individual experiments in each family will be two-group experiments, otherwise the individual experiments will be four-group families.</p>
</td></tr>
<tr><td><code id="calculateMABias_+3A_seed">seed</code></td>
<td>
<p>A seed for the simulations (default 123).</p>
</td></tr>
<tr><td><code id="calculateMABias_+3A_stdadj">StdAdj</code></td>
<td>
<p>Used to introduce variance heterogeneity for Laplace and Normal samples (default 0).</p>
</td></tr>
<tr><td><code id="calculateMABias_+3A_blockmean">Blockmean</code></td>
<td>
<p>Used to set a fixed block effect for four-group experiments (default 0).</p>
</td></tr>
<tr><td><code id="calculateMABias_+3A_stdexp">StdExp</code></td>
<td>
<p>Used to introduce heterogeneity among families of experiments (default 0).</p>
</td></tr>
<tr><td><code id="calculateMABias_+3A_mamethod">MAMethod</code></td>
<td>
<p>Not used (default &quot;PM&quot;).</p>
</td></tr>
<tr><td><code id="calculateMABias_+3A_alpha">alpha</code></td>
<td>
<p>The significance level for statistical tests (default 0.05).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Design. Specifies the type of experiment 2G or 4G, the sample distribution (n,l,g,lap), and whether variance heterogeneity was added (het)
</p>
<p>BEIncluded. Specifies whether or not a block effect was introduced. Always set to &quot;No&quot; for two-group experiments.
</p>
<p>GrpSize. Specifies the size of each group in the individual experiments.
</p>
<p>Diff. The size of the difference between the control and treatment converted to an ordinal scale (Small, Medium, Large)
</p>
<p>NPBias The relative difference between the average of the observed values of either Cliff's d or centralised PHat and the population value
</p>
<p>StdMDBias. The relative difference between the average of the observed values of StdMDBias and the theoretical value
</p>
<p>NPMdMRE The median of the absolute relative difference between the observed values of either Cliff's d or centralised PHat and the theoretical value for each experiment.
</p>
<p>StdMDMdMRE The median of the absolute relative difference between the observed values of StdMD and the population value for each experiment.
</p>
<p>ObsPHat. The average of the average Phat value found for each family in the set of simulations.
</p>
<p>ObsCliffd. The average of the average Cliffd value found for each family in the set of simulations.
</p>
<p>ObsStdES. The average of StdMD calculated for each family in the set of simulations.
</p>
<p>PHatPower. The percentage of the simulations, for a specific mean difference, for which the overall Phat estimate was significantly different from zero at the nominated alpha level using one-sided tests.
</p>
<p>CliffdPower. The percentage of the simulations, for a specific mean difference, for which the overall Cliff's d estimate was significantly different from zero at the nominated alpha level using one-sided tests.
</p>
<p>StdMDPower. The percentage of the simulations, for a specific mean difference, for which the overall StdMD estimate was significantly different from zero at the nominated alpha level using one-sided tests.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'># as.data.frame(calculateMABias(mean=0,sd=1,N=10,diff=c(0.2,0.5,0.8), Experiments=5,reps=10,
# Expected.StdMD=c(0.2,0.5,0.8), Expected.PHat=c(0.556,0.638,0.714), type="n",FourG=FALSE,
# seed= 123, StdAdj = 0, Blockmean=0, StdExp=0))
#  Design Blockmean GrpSize   Diff     NPBias  StdMDBias   NPMdMRE StdMDMdMRE ObsPHat ObsCliffd..
#1   2G_n        No      10  Small 0.09285714 0.02606704 0.8928571  1.0741432  0.5612    0.1224..
#2   2G_n        No      10 Medium 0.03768116 0.01740262 0.2391304  0.4171896  0.6432    0.2864..
#3   2G_n        No      10  Large 0.03738318 0.01523651 0.2009346  0.2490287  0.7220    0.4440..
#  PHatPower CliffdPower StdESPower
#1       0.2         0.2        0.3
#2       0.7         0.7        0.7
#3       1.0         1.0        1.0
as.data.frame(calculateMABias(mean=0,sd=1,N=10,diff=c(0.2,0.5,0.8), Experiments=5,reps=4,
 Expected.StdMD=c(0.2,0.5,0.8), Expected.PHat=c(0.556,0.638,0.714), type="n",FourG=TRUE,
 seed= 123,StdAdj = 0.5,Blockmean=0.5,StdExp=0))
 #Results for reps=10
#    Design Blockmean GrpSize   Diff     NPBias  StdMDBias   NPMdMRE StdMDMdMRE ObsPHat ObsClif..
#1 4G_n_het       Yes      10  Small -0.1321429 -0.1372277 0.6696429  0.4698935  0.5486  0.0972..
#2 4G_n_het       Yes      10 Medium -0.1869565 -0.1882479 0.2318841  0.1472392  0.6122  0.2244..
#3 4G_n_het       Yes      10  Large -0.1864486 -0.2010029 0.1612150  0.1531253  0.6741  0.3482..
#  PHatPower CliffdPower StdESPower
#1       0.4         0.4        0.4
#2       0.9         0.9        0.8
#3       1.0         1.0        1.0
</code></pre>

<hr>
<h2 id='calculateMAType1Error'>calculateMAType1Error</h2><span id='topic+calculateMAType1Error'></span>

<h3>Description</h3>

<p>The function simulates multiple five group families of either two-group or four-group experiments and estimates the Type1 Error rate obtained after synthesizing  the analysis results obtained from the experiments in each family. The Type1 Error is estimated as the percentage of families for which the overall mean of the five experiments was significantly different from zero. The experiment data may be one of four different type: Normal, Log-normal, Gamma or Laplace. The simulations can be repeated for different sample sizes depending on the parameter N. The output is a table of values identifying three observed effect size estimates (Cliff's d, PHat and StdMD) and their related type 1 error rates for each set of simulated families. The synthesis method for all three effect sizes is based on calculating the overall mean and variance for the family of experiments, and then using those values to calculate the effect size variance and its variance. This function supports the production of the values reported in data tables in the paper &quot;Recommendations for Analyzing Small Sample Size Software Engineering Experiments&quot; and its Supplementary Material.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculateMAType1Error(
  mean = 0,
  sd = 1,
  N = c(5, 10, 15, 20, 30, 40),
  reps,
  type = "n",
  seed = 123,
  Experiments = 5,
  FourG = FALSE,
  StdAdj = 0,
  Blockmean = 0,
  BlockStdAdj = 0,
  StdExp = 0,
  MAMethod = "PM",
  alpha = 0.05
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calculateMAType1Error_+3A_mean">mean</code></td>
<td>
<p>This is the mean value of the control and treatment group(s) used in the simulations of each experiment of each family for simulations of a specified sample size (default 0).</p>
</td></tr>
<tr><td><code id="calculateMAType1Error_+3A_sd">sd</code></td>
<td>
<p>This is the standard deviation  value of the control group(s) and treatment group(s) used in the simulations of each experiment of each family for simulations of a specified sample size (default 1).</p>
</td></tr>
<tr><td><code id="calculateMAType1Error_+3A_n">N</code></td>
<td>
<p>This specifies the sample sizes per group that will be used in each set of simulations (default c(5,10,15,20,30,40)).</p>
</td></tr>
<tr><td><code id="calculateMAType1Error_+3A_reps">reps</code></td>
<td>
<p>The number of families simulated for each sample size.</p>
</td></tr>
<tr><td><code id="calculateMAType1Error_+3A_type">type</code></td>
<td>
<p>This specifies the distribution of the data samples that will be simulated. Options ae &quot;n&quot; for Normal, &quot;l&quot;, for Log-normal,'g&quot; for Gamma, &quot;lap&quot; for LaPlace (default &quot;n&quot;).</p>
</td></tr>
<tr><td><code id="calculateMAType1Error_+3A_seed">seed</code></td>
<td>
<p>A seed for the simulations (default 123).</p>
</td></tr>
<tr><td><code id="calculateMAType1Error_+3A_experiments">Experiments</code></td>
<td>
<p>The number of experiments in each family (default 5).</p>
</td></tr>
<tr><td><code id="calculateMAType1Error_+3A_fourg">FourG</code></td>
<td>
<p>If FourG is FALSE the individual experiments in each family will be two-group experiments, otherwise the individual experiments will be four-group families (default FALSE).</p>
</td></tr>
<tr><td><code id="calculateMAType1Error_+3A_stdadj">StdAdj</code></td>
<td>
<p>Used to introduce variance heterogeneity for Laplace and Normal samples (default 0).</p>
</td></tr>
<tr><td><code id="calculateMAType1Error_+3A_blockmean">Blockmean</code></td>
<td>
<p>Used to set a fixed block effect for four-group experiments (default 0).</p>
</td></tr>
<tr><td><code id="calculateMAType1Error_+3A_blockstdadj">BlockStdAdj</code></td>
<td>
<p>Not used (default 0).</p>
</td></tr>
<tr><td><code id="calculateMAType1Error_+3A_stdexp">StdExp</code></td>
<td>
<p>Used to introduce heterogeneity among families of experiments (default 0).</p>
</td></tr>
<tr><td><code id="calculateMAType1Error_+3A_mamethod">MAMethod</code></td>
<td>
<p>Not used (default &quot;PM&quot;).</p>
</td></tr>
<tr><td><code id="calculateMAType1Error_+3A_alpha">alpha</code></td>
<td>
<p>The significance level for statistical tests (default 0.05).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Design. Specifies the type of experiment 2G or 4G, the sample distribution (n,l,g,lap), and whether variance heterogeneity was added (het)
</p>
<p>BEIncluded. Specifies whether or not a block effect was introduced. Always set to &quot;No&quot; for two-group experiments.
</p>
<p>GrpSize. Specifies the size of each group in the individual experiments.
</p>
<p>ObsPHat. The average of the average Phat value found for each family in the set of simulations.
</p>
<p>ObsCliffd. The average of the average Cliffd value found for each family in the set of simulations.
</p>
<p>ObsStdES. The average of StdMD calculated for each family in the set of simulations.
</p>
<p>PHatType1ER. The percentage of the simulations, for a specific group size, for which the overall Phat estimate was significantly different from zero at the nominated alpha level.
</p>
<p>CliffdType1ER. The percentage of the simulations, for a specific group size, for which the overall Cliff's d estimate was significantly different from zero at the nominated alpha level.
</p>
<p>StdMDType1ER. The percentage of the simulations, for a specific group size, for which the overall StdMD estimate was significantly different from zero at the nominated alpha level.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'># as.data.frame(calculateMAType1Error(mean=0,sd=1,N=c(5,10),reps=10,type="n",Experiments=5,
#  FourG=FALSE,StdAdj=0,Blockmean=0,seed=123))
#  Design BEIncluded GrpSize ObsPHat ObsCliffd     ObsStdES PHatType1ER CliffdType1ER StdMDType1ER
#1   2G_n         No       5  0.4848   -0.0304 -0.054156883           0             0          0.0
#2   2G_n         No      10  0.5036    0.0072  0.002888142           0             0          0.1

#as.data.frame(calculateMAType1Error(mean=0,sd=1,N=c(5,10),reps=10,type="l",Experiments=5,
#  FourG=FALSE,StdAdj=0,Blockmean=0,seed=123))
#   Design BEIncluded GrpSize ObsPHat ObsCliffd    ObsStdES PHatType1ER CliffdType1ER StdMDType1ER
#1   2G_l         No       5  0.4848   -0.0304 -0.02789656           0             0          0.0
#2   2G_l         No      10  0.5036    0.0072  0.06473696           0             0          0.2

#as.data.frame(calculateMAType1Error(mean=0,sd=1,N=c(5,10),reps=10,type="n",Experiments=5,
#  FourG=TRUE,StdAdj=0.5,Blockmean=0.5,seed=123))
#   Design BEIncluded GrpSize ObsPHat ObsCliffd   ObsStdES PHatType1ER CliffdType1ER StdMDType1ER
#  1 4G_n_het        Yes       5  0.5108    0.0216 0.01361820           0             0          0.1
#  2 4G_n_het        Yes      10  0.5069    0.0138 0.01700672           0             0          0.0

as.data.frame(calculateMAType1Error(mean=0,sd=1,N=c(5,10),reps=5,type="l",Experiments=5,
 FourG=TRUE,StdAdj=0,Blockmean=0.5,seed=123))
 #Results for reps=10
#   Design BEIncluded GrpSize ObsPHat ObsCliffd   ObsStdES PHatType1ER CliffdType1ER StdMDType1ER
#1   4G_l        Yes       5  0.5108    0.0216 0.07578257           0             0          0.2
#2   4G_l        Yes      10  0.5072    0.0144 0.04839936           0             0          0.0
</code></pre>

<hr>
<h2 id='calculateNullESAccuracy'>calculateNullESAccuracy</h2><span id='topic+calculateNullESAccuracy'></span>

<h3>Description</h3>

<p>The function uses simulation to assess the accuracy when the mean difference is zero, and the type 1 error rates of parametric and non-parametric effect sizes for both two group randomized designs and four group randomized block designs, for each of four different distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculateNullESAccuracy(
  mean = 0,
  sd = 1,
  N = 10,
  reps = 10,
  type = "n",
  seed = 123,
  StdAdj = 0,
  Blockmean = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calculateNullESAccuracy_+3A_mean">mean</code></td>
<td>
<p>The mean of the baseline distribution.</p>
</td></tr>
<tr><td><code id="calculateNullESAccuracy_+3A_sd">sd</code></td>
<td>
<p>The standard deviation or shape of the baseline distribution</p>
</td></tr>
<tr><td><code id="calculateNullESAccuracy_+3A_n">N</code></td>
<td>
<p>The number of observations per group for two group experiments and N/2 the sample sizes for four group experiments. N must be even to ensure equal N/2 defines appropriate sample sizes per group for 4 group experiments</p>
</td></tr>
<tr><td><code id="calculateNullESAccuracy_+3A_reps">reps</code></td>
<td>
<p>The number of replications (i.e. two-group and four group experiments) to be simulated</p>
</td></tr>
<tr><td><code id="calculateNullESAccuracy_+3A_type">type</code></td>
<td>
<p>A string parameter defining the distribution being simulated i.e. 'n' for normal data, 'l' for log-normal data, 'g' for gamma data and 'lap' for LaPlace data.</p>
</td></tr>
<tr><td><code id="calculateNullESAccuracy_+3A_seed">seed</code></td>
<td>
<p>A starting value for the simulations</p>
</td></tr>
<tr><td><code id="calculateNullESAccuracy_+3A_stdadj">StdAdj</code></td>
<td>
<p>A numerical parameter that can be used to add additional variance for normal, lognormal and Laplce data and to change the shape parameter for gamma data.</p>
</td></tr>
<tr><td><code id="calculateNullESAccuracy_+3A_blockmean">Blockmean</code></td>
<td>
<p>A numerical parameter used to introduce a fixed Block effect for four group experiments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble identifying the median absolute error for the effect sizes Cliff's d, phat and StdMD and the Type 1 error rate, estimated from the proportion of significant effect sizes in the simulated experiments.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>as.data.frame(
  calculateNullESAccuracy(
    mean=0,sd=1,N=10,reps=30,type='n',seed=123,StdAdj = 0,Blockmean = 0.5))
#   Design Obs CliffdAbsError PHatAbsError StdESdAbsError  varCliffd    varPHat
# 1   2G_n  20           0.20         0.10      0.2624447 0.05530851 0.01382713
# 2   4G_n  20           0.16         0.08      0.1848894 0.05447540 0.01361885
#    varStdES    ObsCliffd   ObsPHat     ObsStdES CliffdType1ER PHatType1ER
# 1 0.1425374  0.021333333 0.5106667 0.0001190251             0           0
# 2 0.1484728 -0.009333333 0.4953333 0.0295002335             0           0
#   StdESType1ER
# 1   0.03333333
# 2   0.03333333
#as.data.frame(
 # calculateNullESAccuracy(
 #   mean=0,sd=1,N=10,reps=100,type='n',seed=123,StdAdj = 0,Blockmean = 0.5))
#  Design Obs CliffdAbsError PHatAbsError StdESdAbsError  varCliffd    varPHat  varStdES ObsCliffd
#1   2G_n  20           0.21        0.105      0.3303331 0.08064949 0.02016237 0.2488365   -0.0010
#2   4G_n  20           0.16        0.080      0.2565372 0.05933430 0.01483358 0.1769521    0.0052
#  ObsPHat    ObsStdES CliffdType1ER PHatType1ER StdESType1ER
#1  0.4995 -0.02395895          0.07        0.08         0.08
#2  0.5026  0.03769940          0.01        0.01         0.02
</code></pre>

<hr>
<h2 id='calculatePhat'>calculatePhat</h2><span id='topic+calculatePhat'></span>

<h3>Description</h3>

<p>This function calculates the probability of superiority (i.e., Phat) and its confidence interval based on Brunner and Munzel (2000) heteroscedastic analog of WMW test. It is based on Wilcox'x bmp function with some amendments. It does not include a plotit facility. It uses the smallest non-zero variance to identify confidence intervals and statistical significance for values of Phat=0 and Phat=1. It ensure that confidence intervals do not take on invalid values such as values &lt;0 or &gt;1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculatePhat(x, y, alpha = 0.05, sigfig = -1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calculatePhat_+3A_x">x</code></td>
<td>
<p>is a vector of values from group 1</p>
</td></tr>
<tr><td><code id="calculatePhat_+3A_y">y</code></td>
<td>
<p>is a vector of values from group 2</p>
</td></tr>
<tr><td><code id="calculatePhat_+3A_alpha">alpha</code></td>
<td>
<p>is the Type 1 error level for statistical tests</p>
</td></tr>
<tr><td><code id="calculatePhat_+3A_sigfig">sigfig</code></td>
<td>
<p>is the number of significant digits. If sigfig&gt;0 the data in x
and y is truncated to the specified number of significant digits.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list including the value of the t-test for PHat, the estimate of PHat and Cliff's d, and the confidence intervals for PHat.
</p>


<h3>Author(s)</h3>

<p>Rand Wilcox amendments by Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(1.2, 3.0, 2.2, 4.0, 2.5, 3.0)
y &lt;- c(3, 4.2, 4, 6, 7, 5.9)
reproducer:::calculatePhat(x, y)
# $test.stat
# [1] 6.381249
# $phat
# [1] 0.9305556
# $dhat
# [1] 0.8611111
# $sig.level
# [1] 0.0001191725
# $s.e.
# [1] 0.06747199
# $ci.p
# [1] 0.7783001 1.0000000
# $df
# [1] 9.148489
# Another example:
z &lt;- c(1, 2, 3, 4)
y &lt;- c(5, 6, 7, 8)
reproducer:::calculatePhat(z, y)
# $test.stat
# [1] 10.6066
# $phat
# [1] 1
# $dhat
# [1] 1
# $sig.level
# [1] 4.135921e-05
# $s.e.
# [1] 0.04419417
# $ci.p
# [1] 0.8918608 1.0000000
# $df
# [1] 6
</code></pre>

<hr>
<h2 id='calculatePopulationStatistics'>calculatePopulationStatistics</h2><span id='topic+calculatePopulationStatistics'></span>

<h3>Description</h3>

<p>This helper function constructs the theoretical effect sizes and distribution statistics four (normal, lognormal, Laplace &amp; gamma) given specific parameter values for the distributions and is used to support the calculation of population statistics for two and four group experiments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculatePopulationStatistics(mean, std, type = "n")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calculatePopulationStatistics_+3A_mean">mean</code></td>
<td>
<p>The theoretical central location parameter for the distribution specified by the type parameter.</p>
</td></tr>
<tr><td><code id="calculatePopulationStatistics_+3A_std">std</code></td>
<td>
<p>The theoretical spread parameter for the distribution specified by the type parameter.</p>
</td></tr>
<tr><td><code id="calculatePopulationStatistics_+3A_type">type</code></td>
<td>
<p>String identifying the distribution, 'n' for normal, 'ln' for lognormal, 'lap' for Laplace, 'g' for Gamm</p>
</td></tr>
</table>


<h3>Value</h3>

<p>dataframe containing the expected standardized effect size, mean, variance,skewness and kurtosis statistics for samples from the specific distribution
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>reproducer:::calculatePopulationStatistics(mean=0, std=1, type='l')
#   RawMean RawVariance RawEffectSize RawSkewness RawKurtosis
#1 1.648721    4.670774      0.762874    6.184877    88.54343
reproducer:::calculatePopulationStatistics(mean=0, std=1, type='n')
#   RawMean RawVariance RawEffectSize RawSkewness RawKurtosis
# 1       0           1             0           0           3
</code></pre>

<hr>
<h2 id='CalculateRLevel1'>CalculateRLevel1</h2><span id='topic+CalculateRLevel1'></span>

<h3>Description</h3>

<p>This function calculates the r value for a 2-group (2G) or 4-Group (4G) Crossover experiment for each sequence group and each outcome metric. The function returns both the exact r value and the r value based on pooled variances for each sequence group and outcome metric
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CalculateRLevel1(
  Dataset,
  StudyID,
  Groups = c("A", "B", "C", "D"),
  ExperimentName,
  Metrics,
  Type,
  Control
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CalculateRLevel1_+3A_dataset">Dataset</code></td>
<td>
<p>This holds the data for each participant in a 2-group or 4-group crossover experiment in the 'wide' format. I.e., there is only one entry per participant. The data set should have been generated from a long version of the data based on a variable labelled 'Period' which is used to define which participant data was collected in the first period of the experiment - see function ExtractLevel1ExperimentRData.</p>
</td></tr>
<tr><td><code id="CalculateRLevel1_+3A_studyid">StudyID</code></td>
<td>
<p>This holds an identifier used to identify the origin of the experimental data in the output from this function.</p>
</td></tr>
<tr><td><code id="CalculateRLevel1_+3A_groups">Groups</code></td>
<td>
<p>This is a list that defined the sequence group identifiers used in the dataset.</p>
</td></tr>
<tr><td><code id="CalculateRLevel1_+3A_experimentname">ExperimentName</code></td>
<td>
<p>This an identifiers used to define the specific experiment in the output from this function.</p>
</td></tr>
<tr><td><code id="CalculateRLevel1_+3A_metrics">Metrics</code></td>
<td>
<p>This is a list of metrics, e.g., ('Correctness','Time','Efficiency').</p>
</td></tr>
<tr><td><code id="CalculateRLevel1_+3A_type">Type</code></td>
<td>
<p>this is a character string specifying whether the experiment is a two sequence group of four sequence group experiment.</p>
</td></tr>
<tr><td><code id="CalculateRLevel1_+3A_control">Control</code></td>
<td>
<p>this is a character string that defines the control treatment in the experiment.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>script to obtain correlation coefficients
</p>


<h3>Value</h3>

<p>table this is a tibble holding information identifying for each metric and sequence group the first time period and second time period variance, the pooled variance, the variance of the difference values and the exact r and pooled r.
# importFrom stats
# importFrom var
# importFrom tibble
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ExperimentNames &lt;- c("EUBAS", "R1UCLM", "R2UCLM", "R3UCLM")
ShortExperimentNames &lt;- c("E1", "E2", "E3", "E4")
Metrics &lt;- c("Comprehension", "Modification")
Type &lt;- c("4G", "4G", "4G", "4G")
Groups &lt;- c("A", "B", "C", "D")
StudyID &lt;- "S2"
Control &lt;- "SC"
# Obtain experimental data from a file and put in wide format
dataset2 &lt;- KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14TOSEM
ReshapedData &lt;- ExtractExperimentData(dataset2,
  ExperimentNames = ExperimentNames,
  idvar = "ParticipantID", timevar = "Period", ConvertToWide = TRUE
)
# Calculate the correlations for each sequence group and each metric.
CalculateRLevel1(
  Dataset = ReshapedData[[1]], StudyID, Groups = c("A", "B", "C", "D"),
  ExperimentName = ShortExperimentNames[1], Metrics, Type = Type[1], Control
)
# A tibble: 8 x 15
# # A tibble: 8 x 15
# Study Exp   Group Metric Id        n ControlFirst    var1   var2
# &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt; &lt;int&gt; &lt;lgl&gt;          &lt;dbl&gt;  &lt;dbl&gt;
#   1 S2    E1    A     Compr… S2E1A     6 FALSE        0.0183  0.0163
# 2 S2    E1    B     Compr… S2E1B     6 TRUE         0.0201  0.0326
# 3 S2    E1    C     Compr… S2E1C     6 FALSE        0.00370 0.0155
# 4 S2    E1    D     Compr… S2E1D     6 TRUE         0.0173  0.0201
# 5 S2    E1    A     Modif… S2E1A     6 FALSE        0.0527  0.0383
# 6 S2    E1    B     Modif… S2E1B     6 TRUE         0.0185  0.0482
# 7 S2    E1    C     Modif… S2E1C     6 FALSE        0.00655 0.0244
# 8 S2    E1    D     Modif… S2E1D     6 TRUE         0.0222  0.0266
# # … with 6 more variables: varp &lt;dbl&gt;, ControlVarProp &lt;dbl&gt;,
# #   VarProp &lt;dbl&gt;, vardiff &lt;dbl&gt;, r &lt;dbl&gt;, r.p &lt;dbl&gt;

</code></pre>

<hr>
<h2 id='calculateSmallSampleSizeAdjustment'>calculateSmallSampleSizeAdjustment</h2><span id='topic+calculateSmallSampleSizeAdjustment'></span>

<h3>Description</h3>

<p>Function calculates the Hedges small sample size adjustment for standardized mean effect sizes. It calculates the exact value unless the caller sets the parameter exact to FALSE, or the degrees of freedom is too large.
</p>
<p>Function calculates the small sample size adjustment for standardized mean effect sizes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculateSmallSampleSizeAdjustment(df, exact = TRUE)

calculateSmallSampleSizeAdjustment(df, exact = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calculateSmallSampleSizeAdjustment_+3A_df">df</code></td>
<td>
<p>A vector of degrees of freedom</p>
</td></tr>
<tr><td><code id="calculateSmallSampleSizeAdjustment_+3A_exact">exact</code></td>
<td>
<p>Default value=TRUE, if exact==TRUE the function returns the exact value of the adjustment(s) which is suitable for small values of df, if exact==FALSE the function returns the approximate version of the adjustment(s). See Hedges and Olkin 'Statistical methods for Meta-Analysis' Academic Press 1985.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>small sample size adjustment value
</p>
<p>small sample size adjustment value
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df &lt;- 2
c &lt;- calculateSmallSampleSizeAdjustment(df)

df &lt;- c(5, 10, 17)
adjexact &lt;- calculateSmallSampleSizeAdjustment(df)
# adjexact=0.8407487 0.9227456 0.9551115
# Hedges and Olkin values 0.8408, 0.9228,0.9551
adjapprox &lt;- calculateSmallSampleSizeAdjustment(df, FALSE)
# adjapprox=0.8421053 0.9230769 0.9552239
df &lt;- 2
a &lt;- calculateSmallSampleSizeAdjustment(df)
# &gt; a
# [1] 0.5641896

df &lt;- c(5, 10, 17)
adjexact &lt;- calculateSmallSampleSizeAdjustment(df)
# &gt; adjexact
# [1] 0.8407487 0.9227456 0.9551115
# Hedges and Olkin values 0.8408, 0.9228,0.9551
adjapprox &lt;- calculateSmallSampleSizeAdjustment(df, FALSE)
# &gt; adjapprox
# [1] 0.8421053 0.9230769 0.9552239
# Another example:
df &lt;- c(10, 25, 50)
calculateSmallSampleSizeAdjustment(df, exact = TRUE)
# [1] 0.9227456 0.9696456 0.9849119
calculateSmallSampleSizeAdjustment(df, exact = FALSE)
# [1] 0.9230769 0.9696970 0.9849246
</code></pre>

<hr>
<h2 id='CatchError'>CatchError</h2><span id='topic+CatchError'></span>

<h3>Description</h3>

<p>This is a helper function to stop simulations failing if the
metafor function rma fails for example cannot converge properly for
a specific dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CatchError(expr)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CatchError_+3A_expr">expr</code></td>
<td>
<p>The expression that is being monitored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A message confirming whether the expression has performed
successfully
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ES=c(0.2,0.3)
ESvar=c(0.04,0.03)
outcome=reproducer:::CatchError(metafor::rma(ES,ESvar,method='Meth'))
outcome
# [1] 'Failure'
</code></pre>

<hr>
<h2 id='checkIfValidDummyVariable'>checkIfValidDummyVariable</h2><span id='topic+checkIfValidDummyVariable'></span>

<h3>Description</h3>

<p>This helper function checks whether a vector variable comprises
only zeros and 1's.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkIfValidDummyVariable(vector)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="checkIfValidDummyVariable_+3A_vector">vector</code></td>
<td>
<p>Vector variable</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The logical value:
TRUE - if a vector variable passed as the function's parameter represents a
valid dummy variable, i.e., comprises only zeros and 1's.
FALSE - if a vector variable passed as the function's parameter does not
represent a valid dummy variable.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>print(reproducer:::checkIfValidDummyVariable(c(0, 1, 0, 0)))
# [1] TRUE
print(reproducer:::checkIfValidDummyVariable(c(0, 1, 2, 0)))
# [1] FALSE
</code></pre>

<hr>
<h2 id='Ciolkowski09ESEM.MetaAnalysis.PBRvsCBRorAR'>Ciolkowski09ESEM.MetaAnalysis.PBRvsCBRorAR data</h2><span id='topic+Ciolkowski09ESEM.MetaAnalysis.PBRvsCBRorAR'></span>

<h3>Description</h3>

<p>Data form a set of primary studies on reading methods for software inspections. They were reported and analysed by M. Ciolkowski ('What do we know about perspective-based reading? an approach for quantitative aggregation in software engineering', in Proceedings of the 3rd International Symposium on Empirical Software Engineering and Measurement, ESEM'09, pp. 133-144, IEEE Computer Society, 2009), corrected and re-analysed by Madeyski and Kitchenham ('How variations in experimental designs impact the construction of comparable effect sizes for meta-analysis' (to be submitted)).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Ciolkowski09ESEM.MetaAnalysis.PBRvsCBRorAR
</code></pre>


<h3>Format</h3>

<p>A data frame with 21 rows and 7 variables:
</p>

<dl>
<dt>Study</dt><dd><p>Name of empirical study</p>
</dd>
<dt>Ref.</dt><dd><p>Reference to the paper reporting primary study or experimental run where data were originally reported</p>
</dd>
<dt>Control</dt><dd><p>Control treatment: Check-Based Reading (CBR) or Ad-hoc Reading (AR)</p>
</dd>
<dt>Within-subjects</dt><dd><p>Yes - if the primary study used the within-subjects experimental design, No - if the primary study did not use the within-subjects experimental design</p>
</dd>
<dt>Cross-over</dt><dd><p>Yes - if the primary study used the cross-over experimental design, No - if the primary study did not use the cross-over experimental design</p>
</dd>
<dt>d_ByCiolkowski</dt><dd><p>d effect size calculated by Ciolkowski</p>
</dd>
<dt>d_ByOriginalAuthors</dt><dd><p>d effect size as reported by the original authors</p>
</dd>
</dl>



<h3>Details</h3>

<p>If you use this data set please cite: Lech Madeyski and Barbara Kitchenham, 'How variations in experimental designs impact the construction of comparable effect sizes for meta-analysis', 2015.
</p>


<h3>Source</h3>

<p><a href="https://madeyski.e-informatyka.pl/reproducible-research/">https://madeyski.e-informatyka.pl/reproducible-research/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Ciolkowski09ESEM.MetaAnalysis.PBRvsCBRorAR

</code></pre>

<hr>
<h2 id='Cliffd.test'>Cliffd.test</h2><span id='topic+Cliffd.test'></span>

<h3>Description</h3>

<p>This function provides single-sided and two-sided tests of Cliff's d
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Cliffd.test(x, y, alpha = 0.05, alternative = "two.sided", sigfig = -1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Cliffd.test_+3A_x">x</code></td>
<td>
<p>The data from one group</p>
</td></tr>
<tr><td><code id="Cliffd.test_+3A_y">y</code></td>
<td>
<p>The data from the alternative group</p>
</td></tr>
<tr><td><code id="Cliffd.test_+3A_alpha">alpha</code></td>
<td>
<p>The significance level of tests which also controls
the values of the confidence interval (default 0.05)</p>
</td></tr>
<tr><td><code id="Cliffd.test_+3A_alternative">alternative</code></td>
<td>
<p>This defines whether a one-sided test or a two-sided test
is required (default &quot;two.sided&quot;). For a one-sided test use parameter values
'greater' or 'less' to define whether the d-value should be greater or
less than zero.</p>
</td></tr>
<tr><td><code id="Cliffd.test_+3A_sigfig">sigfig</code></td>
<td>
<p>is the number of significant digits. If sigfig&gt;0 the data in x
and y is truncated to the specified number of significant digits.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The values of Cliff's d and its standard error, the t-value,
its pvalue and the upper and lower confidence interval.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a=c(1.2,3,2.2,4,2.5,3)
b=c(3,4.2,4,6,7,5.9)
Cliffd.test(a,b,alpha = .05,alternative='two.sided',sigfig = -1)
# A tibble: 1 x 7
#       d sqse.d d.tvalue d.pvalue d.ci.lower d.ci.upper d.sig
#   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;lgl&gt;
#1 -0.861 0.0202    -42.7 1.20e-12     -0.896     -0.816 TRUE

Cliffd.test(b,a,alpha = .05,alternative='greater',sigfig = -1)
# A tibble: 1 x 7
#      d sqse.d d.tvalue d.pvalue d.ci.lower d.ci.upper d.sig
#  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;lgl&gt;
#1 0.861 0.0202     42.7 5.99e-13      0.824          1 TRUE

</code></pre>

<hr>
<h2 id='constructEffectSizes'>constructEffectSizes</h2><span id='topic+constructEffectSizes'></span>

<h3>Description</h3>

<p>The function constructs various different d-style effect sizes for a set of different experiments given basic statistics from each experiment ( the mean value of the control group Mc, the mean value of the treatment group Mt, the standard deviation of the control group SDc, standard deviation of the the treatment group SDt, the number of observations (participants) in the control group Nc, and the number of observations (participants) in the treatment group Nt). The input variables can be vectors or individual numbers but all input vectors must be of the same length. The function returns Glass's Delta, Cohen's D, point bi-serial r (based on Hedges'g unadjusted), Hedges'g and Hegdes' g adjusted for small sample size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>constructEffectSizes(Mc, Mt, SDc, SDt, Nc, Nt)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="constructEffectSizes_+3A_mc">Mc</code></td>
<td>
<p>is a vector containing the mean value of the control group for each experiment.</p>
</td></tr>
<tr><td><code id="constructEffectSizes_+3A_mt">Mt</code></td>
<td>
<p>is a vector containing the mean value of the treatment group for each experiment.</p>
</td></tr>
<tr><td><code id="constructEffectSizes_+3A_sdc">SDc</code></td>
<td>
<p>is a vector of the standard deviations of the control group for each experiment.</p>
</td></tr>
<tr><td><code id="constructEffectSizes_+3A_sdt">SDt</code></td>
<td>
<p>is a vector of the standard deviations of the the treatment group for each experiment.</p>
</td></tr>
<tr><td><code id="constructEffectSizes_+3A_nc">Nc</code></td>
<td>
<p>is a vector containing the the number of observations (participants) in the control group for each experiment.</p>
</td></tr>
<tr><td><code id="constructEffectSizes_+3A_nt">Nt</code></td>
<td>
<p>is a vector of the number of observations (participants) in the treatment group for each experiment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame composed of five effect sizes (Glass delta, Cohen's d, Hedges' g, r, Hedges' g adjusted)
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>constructEffectSizes(10, 15, 0.3, 0.2, 15, 15)

Mt &lt;- c(0.633, 0.673, 0.423, 0.727, 0.631)
Mc &lt;- c(0.612, 0.526, 0.356, 0.618, 0.534)
SDt &lt;- c(0.198, 0.115, 0.172, 0.088, 0.122)
SDc &lt;- c(0.159, 0.089, 0.111, 0.166, 0.119)
Nt &lt;- c(12, 12, 14, 10, 8)
Nc &lt;- c(12, 12, 14, 10, 8)
EffectSizes &lt;- constructEffectSizes(Mc, Mt, SDc, SDt, Nt, Nc)
EffectSizes
# GlassDelta    Cohend   Hedgesg          r HedgesgAdjusted
# 1  0.1320755 0.1221516 0.1169513 0.05837591       0.1129107
# 2  1.6516854 1.4931812 1.4296121 0.58151846       1.3802200
# 3  0.6036036 0.4803405 0.4628677 0.22547423       0.4493641
# 4  0.6566265 0.8648343 0.8204538 0.37953300       0.7857047
# 5  0.8151261 0.8604924 0.8049169 0.37335594       0.7608781
</code></pre>

<hr>
<h2 id='ConstructLevel1ExperimentRData'>ConstructLevel1ExperimentRData</h2><span id='topic+ConstructLevel1ExperimentRData'></span>

<h3>Description</h3>

<p>This function returns the r value for a 2-group (2G) or 4-Group (4G) Crossover experiment for a group of 1 or more experiments for each sequence group and each outcome metric. For sets of 2 or more experiments, the experiments are assumed to be replicates and to report the same sets of Metrics and have the same Control treatment and use the same sequence Group identifiers, but are not necessarily the same Type. We return both the exact r value and the r value based on pooled variances for each sequence group and outcome metric.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ConstructLevel1ExperimentRData(
  Data,
  StudyID,
  ExperimentNames,
  Groups,
  Metrics,
  Type,
  Control
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ConstructLevel1ExperimentRData_+3A_data">Data</code></td>
<td>
<p>This is a list parameter each entry in the list holds the data for each participant in a 2-group or 4-group crossover experiment in the 'wide' format. I.e., there is only one entry per participant. The data should have been generated from a long version of the data based on a variable labelled 'Period' which is used to define which participant data was collected in the first period of the experiment - see function ExtractLevel1ExperimentRData.</p>
</td></tr>
<tr><td><code id="ConstructLevel1ExperimentRData_+3A_studyid">StudyID</code></td>
<td>
<p>This holds an identifier used to identify the origin of the experimental data in the output from this function.</p>
</td></tr>
<tr><td><code id="ConstructLevel1ExperimentRData_+3A_experimentnames">ExperimentNames</code></td>
<td>
<p>This a list of identifiers used to define each experiment in the output from this function.</p>
</td></tr>
<tr><td><code id="ConstructLevel1ExperimentRData_+3A_groups">Groups</code></td>
<td>
<p>This is a list that defined the sequence group identifiers used in the dataset.</p>
</td></tr>
<tr><td><code id="ConstructLevel1ExperimentRData_+3A_metrics">Metrics</code></td>
<td>
<p>This is a list of of character strings identifying each outcome metric reported in each of the experiments in the set of replicated experiments.</p>
</td></tr>
<tr><td><code id="ConstructLevel1ExperimentRData_+3A_type">Type</code></td>
<td>
<p>this is a list of character strings specifying for each experiment whether the experiment is a 2-group or 4-group experiment</p>
</td></tr>
<tr><td><code id="ConstructLevel1ExperimentRData_+3A_control">Control</code></td>
<td>
<p>this is a character string that defines the control treatment in the experiment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>R.Data.Table this is a tibble holding information identifying for each metric and sequence group the first time period and second time period variance, the pooled variance, the variance of the difference values and the exact r and pooled r.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#
ShortExperimentNames &lt;- c("E1", "E2", "E3", "E4")
FullExperimentNames &lt;- c("EUBAS", "R1UCLM", "R2UCLM", "R3UCLM")
Metrics &lt;- c("Comprehension", "Modification")
Groups &lt;- Groups &lt;- c("A", "B", "C", "D")
Type &lt;- c(rep("4G", 4))
StudyID &lt;- "S2"
Control &lt;- "SC"
# Obtain experimental data from each file and put in wide format
dataset2 &lt;- KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14TOSEM
ReshapedData &lt;- ExtractExperimentData(dataset2,
  ExperimentNames = FullExperimentNames,
  idvar = "ParticipantID", timevar = "Period", ConvertToWide = TRUE
)
# Calculate the correlations for each sequence group and each metric in each experiment
ConstructLevel1ExperimentRData(
  Data = ReshapedData, StudyID = StudyID,
  ExperimentNames = ShortExperimentNames, Groups = Groups, Metrics = Metrics, Type = Type,
  Control = Control
)
# # A tibble: 32 x 15
# Study Exp   Group Metric Id        n ControlFirst    var1   var2    varp
# &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt; &lt;int&gt; &lt;lgl&gt;          &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
#   1 S2    E1    A     Compr… S2E1A     6 FALSE        0.0183  0.0163 0.0173
# 2 S2    E1    B     Compr… S2E1B     6 TRUE         0.0201  0.0326 0.0263
# 3 S2    E1    C     Compr… S2E1C     6 FALSE        0.00370 0.0155 0.00962
# 4 S2    E1    D     Compr… S2E1D     6 TRUE         0.0173  0.0201 0.0187
# 5 S2    E1    A     Modif… S2E1A     6 FALSE        0.0527  0.0383 0.0455
# 6 S2    E1    B     Modif… S2E1B     6 TRUE         0.0185  0.0482 0.0333
# 7 S2    E1    C     Modif… S2E1C     6 FALSE        0.00655 0.0244 0.0155
# 8 S2    E1    D     Modif… S2E1D     6 TRUE         0.0222  0.0266 0.0244
# 9 S2    E2    A     Compr… S2E2A     6 FALSE        0.0194  0.0425 0.0309
# 10 S2    E2    B     Compr… S2E2B     6 TRUE         0.0198  0.0192 0.0195
# # … with 22 more rows, and 5 more variables: ControlVarProp &lt;dbl&gt;,
# #   VarProp &lt;dbl&gt;, vardiff &lt;dbl&gt;, r &lt;dbl&gt;, r.p &lt;dbl&gt;

</code></pre>

<hr>
<h2 id='crossoverResidualAnalysis'>crossoverResidualAnalysis</h2><span id='topic+crossoverResidualAnalysis'></span>

<h3>Description</h3>

<p>This function analyses one or more crossover experiments where each experiment can be either a two group or four group experiment as specified by Type parameter. The file parameter includes a dataset comprising one or more experiments as defined by the ExperimentNames parameter and each experiment includes values for every output variable defined in the Metrics parameter. After being analysed using the linear modeling lmer function of the lme4 package, the residuals are assessed for normality based on  the Anderson-Darling test. Warning 1. This function should only be used with data sets that include one or more individual crossover experiments in the format used in the datasets reported in the reproducer package that were used in the paper B. Kitchenham, L. Madeyski, G. Scanniello, and C. Gravino, “The importance of the correlation between results from individual participants in crossover studies,” IEEE Transactions in SoftwareEngineering, 2021 (Accepted for Publication). [Online]. Available: https://doi.org/10.1109/TSE.2021.30. Warning 2. The lmer function assumes that when experiments include multiple data from the same participant, the correlation between measures for the same participant will be positive. If there is no positive correlation, the function will deliver the warning: boundary (singular) fit: see ?isSingular. This does not mean the analysis has failed. It means that the within participant and between participant variance are set to the same value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crossoverResidualAnalysis(file, StudyID, ExperimentNames, Type, Metrics)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="crossoverResidualAnalysis_+3A_file">file</code></td>
<td>
<p>The dataset to be analysed.</p>
</td></tr>
<tr><td><code id="crossoverResidualAnalysis_+3A_studyid">StudyID</code></td>
<td>
<p>A character string used to identify the origin of the dataset</p>
</td></tr>
<tr><td><code id="crossoverResidualAnalysis_+3A_experimentnames">ExperimentNames</code></td>
<td>
<p>A vector of one or more strings variables identifying each experiment in the file.</p>
</td></tr>
<tr><td><code id="crossoverResidualAnalysis_+3A_type">Type</code></td>
<td>
<p>A vector of string variables identifying the design for each experiment. Each element should have the value '2G' or '4G'</p>
</td></tr>
<tr><td><code id="crossoverResidualAnalysis_+3A_metrics">Metrics</code></td>
<td>
<p>A vector of string variables identifying the variables to be analysed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The results of analysing the residuals for each experiment and metric using the Anderson-Darling test (ADpval) and the number of outliers (NUmOut).
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>File=reproducer::KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello15EMSE
crossoverResidualAnalysis(
  File,StudyID='S1',ExperimentNames=c('USB2'),Type=c('4G'),
  Metrics=c('Correctness','Time','Efficiency'))
#  Study  Exp     Metrics  N ADpval NumOut
#1    S1 USB2 Correctness 24 0.0846      2
#2    S1 USB2        Time 24 0.0448      1
#3    S1 USB2  Efficiency 24  0.365      4
</code></pre>

<hr>
<h2 id='densityCurveOnHistogram'>densityCurveOnHistogram</h2><span id='topic+densityCurveOnHistogram'></span>

<h3>Description</h3>

<p>Density curve overlaid on histogram
</p>


<h3>Usage</h3>

<pre><code class='language-R'>densityCurveOnHistogram(df, colName, limLow, limHigh)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="densityCurveOnHistogram_+3A_df">df</code></td>
<td>
<p>Data frame with data to be displayed</p>
</td></tr>
<tr><td><code id="densityCurveOnHistogram_+3A_colname">colName</code></td>
<td>
<p>Name of the selected column in a given data frame</p>
</td></tr>
<tr><td><code id="densityCurveOnHistogram_+3A_limlow">limLow</code></td>
<td>
<p>the limit on the lower side of the displayed range</p>
</td></tr>
<tr><td><code id="densityCurveOnHistogram_+3A_limhigh">limHigh</code></td>
<td>
<p>the limit on the higher side of the displayed range</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A figure being a density curve overlaid on histogram
</p>


<h3>Author(s)</h3>

<p>Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>densityCurveOnHistogram(Madeyski15EISEJ.PropProjects, "STUD", 0, 100)
# densityCurveOnHistogram(data.frame(x&lt;-rnorm(50, mean=50, sd=5)), 'x', 0, 100)
</code></pre>

<hr>
<h2 id='doLM'>doLM</h2><span id='topic+doLM'></span>

<h3>Description</h3>

<p>This helper function is called by the function 'crossoverResidualAnalysis' to perform either an AB/BA crossover analysis or a four-group crossover on the data set defined by the parameter DataSet depending on the value of the Type parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>doLM(DataSet, Metric, Type)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="doLM_+3A_dataset">DataSet</code></td>
<td>
<p>The dataset to be analysed.</p>
</td></tr>
<tr><td><code id="doLM_+3A_metric">Metric</code></td>
<td>
<p>The name of the variable to be analysed</p>
</td></tr>
<tr><td><code id="doLM_+3A_type">Type</code></td>
<td>
<p>Defines the experimental design</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The data analysis results provided by the lmer function of the lme4 package
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>

<hr>
<h2 id='effectSizeCI'>effectSizeCI</h2><span id='topic+effectSizeCI'></span>

<h3>Description</h3>

<p>95
The procedure is based on finding the upper and lower 0.025 bounds for the related t-variable.
The t-variable needs to be adjusted for bias by multiplying by c
The upper and lower bounds on the t-variable are then used to calculate to upper and lower bounds on the
repeated measures effect size (d_RM) by multiplying the upper and lower bound of the t-variable by sqrt((n1+n2)/(2*(n1*n2))).
Upper and lower bounds on the equivalent independent groups effect size (d_IG) are found by multiplying the upper and lower
bounds on d_RM by sqrt(1-r).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>effectSizeCI(
  expDesign,
  t,
  n1,
  n2,
  r = 0,
  epsilon = 1e-10,
  maxsteps = 1000,
  stepsize = 3
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="effectSizeCI_+3A_expdesign">expDesign</code></td>
<td>
<p>Experimental design: 1) crossover repeated measures ('CrossOverRM'), 2) before-after repeated measures (expDesign=='BeforeAfterRM'), 3) independent groups ('IG)</p>
</td></tr>
<tr><td><code id="effectSizeCI_+3A_t">t</code></td>
<td>
<p>t-statistics (t must be less than or equal to 37.62, the limit from the R function documentation)</p>
</td></tr>
<tr><td><code id="effectSizeCI_+3A_n1">n1</code></td>
<td>
<p>The number of observations in sequence group 1 (expDesign=='CrossOverRM'), the number of observations in group 1 (expDesign=='IG'), or the total number of observations (expDesign=='BeforeAfterRM')</p>
</td></tr>
<tr><td><code id="effectSizeCI_+3A_n2">n2</code></td>
<td>
<p>The number of observations in sequence group 2 (expDesign=='CrossOverRM') or the number of observations in group 2 (expDesign=='IG')</p>
</td></tr>
<tr><td><code id="effectSizeCI_+3A_r">r</code></td>
<td>
<p>The correlation between outcomes for individual subject (the within subject correlation)</p>
</td></tr>
<tr><td><code id="effectSizeCI_+3A_epsilon">epsilon</code></td>
<td>
<p>The precision of the iterative procedure</p>
</td></tr>
<tr><td><code id="effectSizeCI_+3A_maxsteps">maxsteps</code></td>
<td>
<p>The maximum number of steps of the iterative procedure (the procedure terminates at maxsteps or earlier if CI with enough precision have been calculated)</p>
</td></tr>
<tr><td><code id="effectSizeCI_+3A_stepsize">stepsize</code></td>
<td>
<p>The size of steps (influences the convergence of the calculations, i.e., the number of steps required to obtain the final result of precision defined by the epsilon)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of Confidence Intervals for: t-statistic (t_LB and t_UB), repeated-measures effect size d_RM (d_RM_LB, d_RM_UB), independent groups effect size (d_IG_LB, d_IG_UB)
</p>


<h3>Author(s)</h3>

<p>Lech Madeyski and Barbara Kitchenham
</p>


<h3>Examples</h3>

<pre><code class='language-R'>effectSizeCI(expDesign = "CrossOverRM", t = 14.4, n1 = 15, n2 = 15, r = 0.6401)
effectSizeCI(expDesign = "BeforeAfterRM", t = 14.16536, n1 = 15, n2 = 0, r = 0.6146771)
effectSizeCI(expDesign = "IG", t = -6.344175, n1 = 15, n2 = 15)
effectSizeCI(expDesign = "CrossOverRM", t = 0.5581, n1 = 6, n2 = 6, r = 0.36135)
effectSizeCI(expDesign = "CrossOverRM", r = 0.855, t = 4.33, n1 = 7, n2 = 6)
</code></pre>

<hr>
<h2 id='ExtractExperimentData'>ExtractExperimentData</h2><span id='topic+ExtractExperimentData'></span>

<h3>Description</h3>

<p>This function reads datasets from a defined directory in the reproducer package that hold the results of a family crossover experiments in the long format. It converts the data to the wide format if required.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ExtractExperimentData(
  DataSet,
  ExperimentNames,
  idvar = "ParticipantID",
  timevar = "Period",
  ConvertToWide = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ExtractExperimentData_+3A_dataset">DataSet</code></td>
<td>
<p>This is a tibble holding the data for each crossover experiment in a family (a family can include only one experiment).</p>
</td></tr>
<tr><td><code id="ExtractExperimentData_+3A_experimentnames">ExperimentNames</code></td>
<td>
<p>This is a list with the full names of each experiment.</p>
</td></tr>
<tr><td><code id="ExtractExperimentData_+3A_idvar">idvar</code></td>
<td>
<p>This is the name of the column that contains the data for specific participants. It is only assumed to be unique within an experiment (default idvar='ParticipantID').</p>
</td></tr>
<tr><td><code id="ExtractExperimentData_+3A_timevar">timevar</code></td>
<td>
<p>This is the name of the table column that defines which data was collected in a specific time period. This function assumes that there are only two time periods (default timevar='Period').</p>
</td></tr>
<tr><td><code id="ExtractExperimentData_+3A_converttowide">ConvertToWide</code></td>
<td>
<p>This determine whether the function converts the data to the wide format (default ConvertToWide=TRUE).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with an entry for the data for each experiment. If ConvertToWide is TRUE, it returns the data in the wide format otherwise it returns the data as it was read. Within each list item the data is returned as a tibble
#importFrom stats
# importFrom tibble
# importFrom base
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ExperimentNames &lt;- c("EUBAS", "R1UCLM", "R2UCLM", "R3UCLM")
Metrics &lt;- c("Comprehension", "Modification")
Groups &lt;- c("A", "B", "C", "D")
Type &lt;- c(rep("4G", 4))
StudyID &lt;- "S2"
Control &lt;- "SC"
# Obtain experimental data from each file and put in wide format
dataset2 &lt;- KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14TOSEM
ReshapedData &lt;- ExtractExperimentData(dataset2,
  ExperimentNames = ExperimentNames,
  idvar = "ParticipantID", timevar = "Period", ConvertToWide = TRUE
)
ReshapedData[[1]]

# A tibble: 24 x 15
# ParticipantID ExperimentID.1 SequenceGroup.1 System.1 Treatment.1 Comprehension.1
# &lt;fct&gt;         &lt;fct&gt;          &lt;fct&gt;           &lt;fct&gt;    &lt;fct&gt;                 &lt;dbl&gt;
#   1 1             EUBAS          A               S1       AM                     0.77
# 2 5             EUBAS          A               S1       AM                     0.61
# 3 9             EUBAS          A               S1       AM                     0.61
# 4 13            EUBAS          A               S1       AM                     0.52
# 5 17            EUBAS          A               S1       AM                     0.43
# 6 21            EUBAS          A               S1       AM                     0.77
# 7 2             EUBAS          B               S1       SC                     0.92
# 8 6             EUBAS          B               S1       SC                     0.63
# 9 10            EUBAS          B               S1       SC                     0.51
# 10 14            EUBAS          B               S1       SC                     0.64
# … with 14 more rows, and 9 more variables: Modification.1 &lt;dbl&gt;, CrossOverID.1 &lt;fct&gt;,
#   ExperimentID.2 &lt;fct&gt;, SequenceGroup.2 &lt;fct&gt;, System.2 &lt;fct&gt;, Treatment.2 &lt;fct&gt;,
#   Comprehension.2 &lt;dbl&gt;, Modification.2 &lt;dbl&gt;, CrossOverID.2 &lt;fct&gt;

</code></pre>

<hr>
<h2 id='ExtractGroupSizeData'>ExtractGroupSizeData</h2><span id='topic+ExtractGroupSizeData'></span>

<h3>Description</h3>

<p>This function constructs a table identifying the number of participants in each sequence group for a set of experiments each of which used a crossover design.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ExtractGroupSizeData(
  ExpDataWide,
  StudyID,
  ShortExperimentNames,
  Type,
  Groups = c("A", "B", "C", "D")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ExtractGroupSizeData_+3A_expdatawide">ExpDataWide</code></td>
<td>
<p>this is a list of tibbles each comprising data from one experiment in its wide format</p>
</td></tr>
<tr><td><code id="ExtractGroupSizeData_+3A_studyid">StudyID</code></td>
<td>
<p>an identifier for the group of related experiments (i.e., a family).</p>
</td></tr>
<tr><td><code id="ExtractGroupSizeData_+3A_shortexperimentnames">ShortExperimentNames</code></td>
<td>
<p>a list of character strings identifying each experiment.</p>
</td></tr>
<tr><td><code id="ExtractGroupSizeData_+3A_type">Type</code></td>
<td>
<p>A list identifying the type of crossover '2G' or '4G' for each experiment in the family</p>
</td></tr>
<tr><td><code id="ExtractGroupSizeData_+3A_groups">Groups</code></td>
<td>
<p>a list of the terms used to specify sequence groups in the experiments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing the number of participants in each sequence group in each experiment.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ExperimentNames &lt;- c("EUBAS", "R1UCLM", "R2UCLM", "R3UCLM")
ShortExperimentNames &lt;- c("E1", "E2", "E3", "E4")
Metrics &lt;- c("Comprehension", "Modification")
Type &lt;- c("4G", "4G", "4G", "4G")
Groups &lt;- c("A", "B", "C", "D")
StudyID &lt;- "S2"
Control &lt;- "SC"
# Obtain experimental data from a file and put in wide format
dataset2 &lt;- KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14TOSEM
ReshapedData &lt;- ExtractExperimentData(dataset2,
  ExperimentNames = ExperimentNames,
  idvar = "ParticipantID", timevar = "Period", ConvertToWide = TRUE
)
ExtractGroupSizeData(ReshapedData, StudyID, ShortExperimentNames, Type, Groups = Groups)
# A tibble: 16 x 4
#  Study Exp   Group     n
#  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt;
# 1 S2    Exp1  A         6
# 2 S2    Exp1  B         6
# 3 S2    Exp1  C         6
# 4 S2    Exp1  D         6
# 5 S2    Exp2  A         6
# 6 S2    Exp2  B         6
# 7 S2    Exp2  C         5
# 8 S2    Exp2  D         5
# 9 S2    Exp3  A         5
# 10 S2    Exp3  B         5
# 11 S2    Exp3  C         6
# 12 S2    Exp3  D         6
# 13 S2    Exp4  A         5
# 14 S2    Exp4  B         5
# 15 S2    Exp4  C         4
# 16 S2    Exp4  D         4

</code></pre>

<hr>
<h2 id='ExtractMAStatistics'>ExtractMAStatistics</h2><span id='topic+ExtractMAStatistics'></span>

<h3>Description</h3>

<p>This function extracts summary statistics from meta-analysis results obtained from the rma function of the metafor R package. If required the function transform back to standardized mean difference (effect size type 'd' i.e. Hg) or point biserial correlations (effect size type 'r').
Warning: the &lsquo;ExtractMAStatistics' function works with 'metafor' version 2.0-0, but changes to metafor&rsquo;s method of providing access to its individual results may introduce errors into the function.
</p>
<p>This function extracts summary statistics from meta-analysis results obtained from the rma function of the metafor R package. If required the function transform back to standardized mean difference (effect size type 'd' i.e. Hg) or point biserial correlations (effect size type 'r').
Warning: the &lsquo;ExtractMAStatistics' function works with 'metafor' version 2.0-0, but changes to metafor&rsquo;s method of providing access to its individual results may introduce errors into the function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ExtractMAStatistics(
  maresults,
  Nc,
  Nt,
  Transform = TRUE,
  type = "d",
  sig = 4,
  returnse = FALSE
)

ExtractMAStatistics(
  maresults,
  Nc,
  Nt,
  Transform = TRUE,
  type = "d",
  sig = 4,
  returnse = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ExtractMAStatistics_+3A_maresults">maresults</code></td>
<td>
<p>is the output from the rma function.</p>
</td></tr>
<tr><td><code id="ExtractMAStatistics_+3A_nc">Nc</code></td>
<td>
<p>is the number of participants in the control condition group.</p>
</td></tr>
<tr><td><code id="ExtractMAStatistics_+3A_nt">Nt</code></td>
<td>
<p>is the number of participants in the treatment condition group.</p>
</td></tr>
<tr><td><code id="ExtractMAStatistics_+3A_transform">Transform</code></td>
<td>
<p>is a boolean value indicating whether the outcome values need to be transformed back to standardized mean difference ('d' i.e. Hg or d) or point biserial correlations ('r'). It is defaulted to TRUE. If this parameter is set to FALSE, no transformation will be applied.</p>
</td></tr>
<tr><td><code id="ExtractMAStatistics_+3A_type">type</code></td>
<td>
<p>this indicates the type of transformation required - it defaults to 'd' which requests transformation from Zr to Hg, using 'r' requests transformation from Zr to r.</p>
</td></tr>
<tr><td><code id="ExtractMAStatistics_+3A_sig">sig</code></td>
<td>
<p>indicates the number of significant digits requested in the output, the default is 4; it rounds the values of mean, pvalue, upper and lower bound to the specified number of significant digits.</p>
</td></tr>
<tr><td><code id="ExtractMAStatistics_+3A_returnse">returnse</code></td>
<td>
<p>if set to TRUE returns the standard error of the effect size (default: returnse=FALSE)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame incl. summary statistics from meta-analysis results: overall mean value for the effect sizes, the p-value of the mean, the upper and lower confidence interval bounds (UB and LB), QE which is the heterogeneity test statistic and QEp which the the p-value of the heterogeneity statistic
</p>
<p>data frame incl. summary statistics from meta-analysis results: overall mean value for the effect sizes, the p-value of the mean, the upper and lower confidence interval bounds (UB and LB), QE which is the heterogeneity test statistic and QEp which the the p-value of the heterogeneity statistic
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ExpData &lt;- reproducer::KitchenhamMadeyskiBrereton.ExpData
# Extract the experiment basic statics
S1data &lt;- subset(ExpData, ExpData == "S1")
# Use the descriptive data to construct effect size
S1EffectSizes &lt;- reproducer::PrepareForMetaAnalysisGtoR(
  S1data$Mc, S1data$Mt, S1data$SDc, S1data$SDt, S1data$Nc, S1data$Nt
)
# Do a random effect meta-analysis of the transformed r_pbs effect size
S1MA &lt;- metafor::rma(S1EffectSizes$zr, S1EffectSizes$vi)
# Extract summary statistics from meta-analysis results and transform back to Hg scale
S1MAStats &lt;- reproducer::ExtractMAStatistics(S1MA, sum(S1data$Nc), sum(S1data$Nt), TRUE, "d", 4)
#    mean   pvalue    UB     LB QE  QEp
# 1 0.6658 0.002069 1.122 0.2384  4 0.41
ExpData &lt;- reproducer::KitchenhamMadeyskiBrereton.ExpData
# Extract the experiment basic statics
S1data &lt;- subset(ExpData, ExpData == "S1")
# Use the descriptive data to construct effect size
S1EffectSizes &lt;- reproducer::PrepareForMetaAnalysisGtoR(
  S1data$Mc, S1data$Mt, S1data$SDc, S1data$SDt, S1data$Nc, S1data$Nt
)
# Do a random effect meta-analysis of the transformed r_pbs effect size
S1MA &lt;- metafor::rma(S1EffectSizes$zr, S1EffectSizes$vi)
# Extract summary statistics from meta-analysis results and transform back to Hg scale
ExtractMAStatistics(S1MA, sum(S1data$Nc), sum(S1data$Nt), TRUE, "d", 4)
#     mean   pvalue    UB     LB QE  QEp
# 1 0.6658 0.002069 1.122 0.2384  4 0.41
ExtractMAStatistics(S1MA, sum(S1data$Nc), sum(S1data$Nt), FALSE, "d", 4)
# A tibble: 1 x 6
#   mean  pvalue    UB    LB    QE   QEp
#  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
# 1 0.327 0.00207 0.535 0.119     4  0.41

</code></pre>

<hr>
<h2 id='ExtractSummaryStatisticsRandomizedExp'>ExtractSummaryStatisticsRandomizedExp</h2><span id='topic+ExtractSummaryStatisticsRandomizedExp'></span>

<h3>Description</h3>

<p>This function extracts data obtained from the lme4 package lmer function. It assumes a simple randomized experiment with each element having one or more repeated measures. It outputs the mean together with its standard error and confidence interval bounds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ExtractSummaryStatisticsRandomizedExp(lmeRA, N, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ExtractSummaryStatisticsRandomizedExp_+3A_lmera">lmeRA</code></td>
<td>
<p>The output from the lmer function</p>
</td></tr>
<tr><td><code id="ExtractSummaryStatisticsRandomizedExp_+3A_n">N</code></td>
<td>
<p>The total number of observations</p>
</td></tr>
<tr><td><code id="ExtractSummaryStatisticsRandomizedExp_+3A_alpha">alpha</code></td>
<td>
<p>the probability level to be used when constructing the confidence interval bounds.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>REA.Summary A dataframe holding the number of observations N, the overall mean value as
its standard error reported as by the lmer function, and its confidence interval bounds.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ShortExperimentNames &lt;- c("E1", "E2", "E3", "E4")
FullExperimentNames &lt;- c("EUBAS", "R1UCLM", "R2UCLM", "R3UCLM")
Metrics &lt;- c("Comprehension", "Modification")
Groups &lt;- c("A", "B", "C", "D")
Type &lt;- c(rep("4G", 4))
StudyID &lt;- "S2"
Control &lt;- "SC"
ReshapedData &lt;- ExtractExperimentData(
  KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14TOSEM,
  ExperimentNames = FullExperimentNames, idvar = "ParticipantID", timevar = "Period",
  ConvertToWide = TRUE
)
NewTable &lt;- ConstructLevel1ExperimentRData(
  ReshapedData, StudyID, ShortExperimentNames, Groups,
  Metrics, Type, Control
)
resRe &lt;- lme4::lmer(r ~ (1 | Id), data = NewTable)
summary(resRe)
# Linear mixed model fit by REML ['lmerMod']
# Formula: r ~ (1 | Id)
# REML criterion at convergence: 47.8
# Scaled residuals:
#    Min      1Q  Median      3Q     Max
# -1.4382 -0.9691  0.2190  0.8649  1.4761
#
# Random effects:
#  Groups   Name        Variance Std.Dev.
#   Id       (Intercept) 0.03978  0.1994
#   Residual             0.20974  0.4580
#  Number of obs: 32, groups:  Id, 16
#
#  Fixed effects:
#             Estimate Std. Error t value
#  (Intercept)  0.06175    0.09508   0.649
#  N=length(NewTable$r)
ExtractSummaryStatisticsRandomizedExp(lmeRA = resRe, N = 32, alpha = 0.05)
#      N    Mean      SE LowerBound UpperBound
#   1 32 0.06175 0.09508    -0.1319     0.2554

</code></pre>

<hr>
<h2 id='fmt'>fmt</h2><span id='topic+fmt'></span>

<h3>Description</h3>

<p>Formatting function to set decimal precision in labels
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fmt()
</code></pre>


<h3>Author(s)</h3>

<p>Lech Madeyski
</p>

<hr>
<h2 id='getEffectSizesABBA'>getEffectSizesABBA</h2><span id='topic+getEffectSizesABBA'></span>

<h3>Description</h3>

<p>Function to calculate both effect sizes (dIG, dRM), i.e., independent groups and repeated measures standardized effect sizes and variances, for AB/BA crossover design studies. Function is used in a paper 'Effect Sizes and their Variance for AB/BA Crossover Design Studies' by Lech Madeyski and Barbara Kitchenham.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getEffectSizesABBA(simulationData)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getEffectSizesABBA_+3A_simulationdata">simulationData</code></td>
<td>
<p>- data set in a form required to calculate effect sizes in AB/BA crossover experimental designs</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame incl. calculated effect sizes and variances:
# dIG - independent groups standardized effect size
# var.dIG - variance of independent groups standardized effect size
# dRM - repeated measures (within-subjects) standardized effect size
# var.dRM - variance of repeated measures (within-subjects) standardized effect size
# dIG.Fromt - independent groups standardized effect size calculated from t: dIG.Fromt=t*sqrt(1-r)*sqrt((N1+N2)/(2*N1*N2))
# var.dIG.Fromt - variance of independent groups standardized effect size calculated from t: var.dIG.Fromt=var.t*(1-r)*((N1+N2)/(2*N1*N2))
# dRM.Fromt - dRM calculated from t: dRM.Fromt=t*sqrt((N1+N2)/(2*N1*N2))
# var.dRM.Fromt - var.dRM calculated from t: var.dRM.Fromt = var.t*((N1+N2)/(2*N1*N2))
# var.dRM.Fromt2 - var.dRM calculated from t or rather dRM.Fromt: var.dRM.Fromt2=(df/(df-2))*((N1+N2)/(2*N1*N2)+dRM.Fromt^2)- dRM.Fromt^2/c^2
# var.dRM.Approx - var.dRM calculated on a basis of Johnson and Welch (1940) report an approximate formulate for the variance of a t variable: var.dRM.Approx=((N1+N2)/(2*N1*N2)) + (dRM^2)/(2*(N1+N2-2)) #see paper and Equation 49
# var.dIG.Approx - var.dIG calculated on a basis of Johnson and Welch (1940) report an approximate formulate for the variance of a t variable: var.dIG.Approx=(((N1+N2)*(1-r))/(2*N1*N2)) + (dIG^2)/(2*(N1+N2-2)) #see paper and Equation 50
# unstandardizedES - estimated unstandardized technique effect size
# periodES - estimated period effect
# var.sig - sum of within-subjects variance and between-subjects variance
# var.within - within-subjects variance
# var.between - between-subjects variance
# t - t-value
# var.t - variance of t-variable
# gRM - Hedges and Olkin (1985) unbiased estimator of the repeated measures effect size gRM=dRM*c
# var.gRM - variance of gRM calculated as follows: var.gRM=(df/(df-2))*(((N1+N2)/(2*N1*N2))*c^2+gRM^2)- gRM^2/c^2 #Equation 56
# var.gRM2 - variance of gRM calculated as follows: var.gRM2=var.dRM*c^2
# gIG - Hedges and Olkin (1985) unbiased estimator of the independent groups effect size gIG=dIG*c
# var.gIG - variance of gIG calculated as follows: var.gIG=(df/(df-2))*(((N1+N2)/(2*N1*N2))*c^2+gIG^2)- gIG^2/c^2 #Equation 57
# var.gIG2 - variance of gRM calculated as follows: var.gIG2=var.dIG*c^2
# r - the correlation between the values observed for the same subject
</p>


<h3>Author(s)</h3>

<p>Lech Madeyski and Barbara Kitchenham
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simulationData &lt;- getSimulationData(25, 18.75, 50, 10, 5, 500) # generate simulated data set
es &lt;- getEffectSizesABBA(simulationData) # return effect sizes and variances
# OR
simulationData &lt;- getSimulationData(25, 18.75, 50, 10, 5, 15)
es &lt;- getEffectSizesABBA(simulationData) # return effect sizes and variances
</code></pre>

<hr>
<h2 id='getEffectSizesABBAIgnoringPeriodEffect'>getEffectSizesABBAIgnoringPeriodEffect</h2><span id='topic+getEffectSizesABBAIgnoringPeriodEffect'></span>

<h3>Description</h3>

<p>Function to calculate both effect sizes (dIG.ipe, dRM.ipe), i.e., independent groups and repeated measures standardized effect sizes and variances, for AB/BA crossover design studies ignoring period effect (thus wrong). Function was removed in the revision of the paper 'Effect Sizes and their Variance for AB/BA Crossover Design Studies' by Lech Madeyski and Barbara Kitchenham.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getEffectSizesABBAIgnoringPeriodEffect(simulationData)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getEffectSizesABBAIgnoringPeriodEffect_+3A_simulationdata">simulationData</code></td>
<td>
<p>- data set in a form required to calculate effect sizes in AB/BA crossover experimental designs</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame incl. calculated effect sizes and variances:
# dIG.ipe - independent groups standardized effect size
# var.dIG.ipe - variance of independent groups standardized effect size
# dRM.ipe - repeated measures (within-subjects) standardized effect size
# var.dRM.ipe - variance of repeated measures (within-subjects) standardized effect size
# dIG.Fromt.ipe - independent groups standardized effect size calculated from t: dIG.Fromt=t*sqrt(1-r)*sqrt((N1+N2)/(2*N1*N2))
# var.dIG.Fromt.ipe - variance of independent groups standardized effect size calculated from t: var.dIG.Fromt=var.t*(1-r)*((N1+N2)/(2*N1*N2))
# dRM.Fromt.ipe - dRM calculated from t: dRM.Fromt=t*sqrt((N1+N2)/(2*N1*N2))
# var.dRM.Fromt.ipe - var.dRM calculated from t: var.dRM.Fromt = var.t*((N1+N2)/(2*N1*N2))
# var.dRM.Fromt2.ipe - var.dRM calculated from t or rather dRM.Fromt: var.dRM.Fromt2=(df/(df-2))*((N1+N2)/(2*N1*N2)+dRM.Fromt^2)- dRM.Fromt^2/c^2
# unstandardizedES.ipe - estimated unstandardized technique effect size
# var.sig.ipe - sum of within-subjects variance and between-subjects variance
# var.within.ipe - within-subjects variance
# var.between.ipe - between-subjects variance
# t.ipe - t-value
# var.t.ipe - variance of t-variable
</p>


<h3>Author(s)</h3>

<p>Lech Madeyski and Barbara Kitchenham
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simulationData &lt;- getSimulationData(25, 18.75, 50, 10, 5, 500) # generate simulated data set
es.ipe &lt;- getEffectSizesABBAIgnoringPeriodEffect(simulationData) # return effect sizes and variances
</code></pre>

<hr>
<h2 id='getSimulationData'>getSimulationData</h2><span id='topic+getSimulationData'></span>

<h3>Description</h3>

<p>Function to generate the simulated data set used in a paper 'Effect Sizes and their Variance for AB/BA Crossover Design Studies' by Lech Madeyski and Barbara Kitchenham
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getSimulationData(
  var,
  covar,
  meanA1,
  treatmentDiff,
  periodEffect,
  numOfSamples
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getSimulationData_+3A_var">var</code></td>
<td>
<p>Variance among subjects is a sum of the between subjects variance and the within subjects variance</p>
</td></tr>
<tr><td><code id="getSimulationData_+3A_covar">covar</code></td>
<td>
<p>Covariance equal to the between subjects variance</p>
</td></tr>
<tr><td><code id="getSimulationData_+3A_meana1">meanA1</code></td>
<td>
<p>Mean for treatment sequence A1</p>
</td></tr>
<tr><td><code id="getSimulationData_+3A_treatmentdiff">treatmentDiff</code></td>
<td>
<p>technique effect which is the difference between the effect of technique A and technique B</p>
</td></tr>
<tr><td><code id="getSimulationData_+3A_periodeffect">periodEffect</code></td>
<td>
<p>Period effect which is the difference between period 1 and period 2</p>
</td></tr>
<tr><td><code id="getSimulationData_+3A_numofsamples">numOfSamples</code></td>
<td>
<p>Number of samples ('rows' of data) required for each technique and period</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-
Functions related to a paper 'Effect sizes and their variance for AB/BA crossover design studies' by Lech Madeyski and Barbara Kitchenham
&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-
</p>


<h3>Value</h3>

<p>Data frame:
'data.frame':  4*numOfSamples obs. of  5 variables:
$ pid      : int  1 2 3 4 5 6 7 8 9 10 ...
$ technique: Factor w/ 2 levels 'T1','T2':  ...
$ period   : Factor w/ 2 levels 'P1','P2':  ...
$ sequence : Factor w/ 2 levels 'S1','S2':  ...
$ result   : num  ...
</p>


<h3>Author(s)</h3>

<p>Lech Madeyski and Barbara Kitchenham
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate the simulated data set from the paper
data &lt;- getSimulationData(25, 18.75, 50, 10, 5, 500)
data &lt;- getSimulationData(25, 18.75, 50, 10, 5, 15)
</code></pre>

<hr>
<h2 id='getTheoreticalEffectSizeVariancesABBA'>getTheoreticalEffectSizeVariancesABBA</h2><span id='topic+getTheoreticalEffectSizeVariancesABBA'></span>

<h3>Description</h3>

<p>Function provides the theoretical value of the t-statistic, variance of t, and variance of the effect sizes based on the parameters built into crossover model data simulated by the getSimilationData() function.
Function is used in a paper 'Effect Sizes and their Variance for AB/BA Crossover Design Studies' by Lech Madeyski and Barbara Kitchenham.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTheoreticalEffectSizeVariancesABBA(
  theoreticalvarW,
  theoreticalTechniqueEffect,
  theoreticalrho,
  N1,
  N2
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getTheoreticalEffectSizeVariancesABBA_+3A_theoreticalvarw">theoreticalvarW</code></td>
<td>
<p>- The within subject variance used to construct the simulation, i.e., the built-in Variance - the built-in Covariance</p>
</td></tr>
<tr><td><code id="getTheoreticalEffectSizeVariancesABBA_+3A_theoreticaltechniqueeffect">theoreticalTechniqueEffect</code></td>
<td>
<p>- The technique effect built into the crossover model data</p>
</td></tr>
<tr><td><code id="getTheoreticalEffectSizeVariancesABBA_+3A_theoreticalrho">theoreticalrho</code></td>
<td>
<p>- The between subject correlation built into the crossover model simulation data</p>
</td></tr>
<tr><td><code id="getTheoreticalEffectSizeVariancesABBA_+3A_n1">N1</code></td>
<td>
<p>- The number of subjects in sequence group 1 in the crossover model simulation</p>
</td></tr>
<tr><td><code id="getTheoreticalEffectSizeVariancesABBA_+3A_n2">N2</code></td>
<td>
<p>- The number of subjects in sequence group 2 in the crossover model simulation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame incl. calculated:
theoreticalt - the theoretical value of the t-statistic
theoreticalvart - variance of t
theoreticalvardIG -  variance of the effect size dIG based on the parameters built into crossover model data simulated by the getSimilationData function
theoreticalvardRM -  variance of the effect size dRM based on the parameters built into crossover model data simulated by the getSimilationData function
</p>


<h3>Author(s)</h3>

<p>Lech Madeyski and Barbara Kitchenham
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generates data used in Table 15 of the paper
theoreticalEffectSizeVariances &lt;- getTheoreticalEffectSizeVariancesABBA(6.25, -10, 0.75, 15, 15)
</code></pre>

<hr>
<h2 id='KitchenhamEtAl.CorrelationsAmongParticipants.Abrahao13TSE'>KitchenhamEtAl.CorrelationsAmongParticipants.Abrahao13TSE data</h2><span id='topic+KitchenhamEtAl.CorrelationsAmongParticipants.Abrahao13TSE'></span>

<h3>Description</h3>

<p>Data illustrate correlations between results from individual participants in a family of five
cross-over experiments conducted by Abrahao et al:
[1] S. Abrahao, C. Gravino, E. Insfran Pelozo, G. Scanniello, and
G. Tortora, 'Assessing the effectiveness of sequence diagrams in the comprehension of functional
requirements: Results from a family of five experiments,' IEEE Transactions on Software
Engineering, vol. 39, no. 3, pp. 327–342, March 2013
The five experiments assess whether the comprehensibility of function requirements improve when
software models include UML sequence diagrams.
If you use this data set please cite:
[1] S. Abrahao, C. Gravino, E. Insfran Pelozo, G. Scanniello, and
G. Tortora, 'Assessing the effectiveness of sequence diagrams in the comprehension of
functional requirements: Results from a family of five experiments,' IEEE Transactions on
Software Engineering, vol. 39, no. 3, pp. 327–342, March 2013
[2] Barbara Kitchenham, Lech Madeyski, Giuseppe Scanniello and Carmine Gravino, 'The importance
of the Correlation between Results from Individual Participants in Crossover Experiments'
(to be submitted as of 2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Abrahao13TSE
</code></pre>


<h3>Format</h3>

<p>A data frame with 224 rows and 8 variables:
</p>

<dl>
<dt>ExperimentID</dt><dd><p>&lt;fct&gt;|ExperimentID: A unique identifier for each of the five experiments in
the data set.</p>
</dd>
<dt>ParticipantID</dt><dd><p>&lt;fct&gt;|Participant ID: An identifier for each participant, unique for a
specific experiment.</p>
</dd>
<dt>SequenceGroup</dt><dd><p>&lt;fct&gt;|Experimental Sequence Group: A (DM-NODM,ECP-EPlat or MShop-Theatre ),
B (NODM-DM,ECP-EPlat or  MShop-Theatre ), C(DM-NODM,EPlat-ECP or Theatre-MShop),
D(NODM-DM,EPlat-ECP or Theatre-MShop)</p>
</dd>
<dt>System</dt><dd><p>&lt;fct&gt;|Software systems used in the experiment: ECP an e-commerce platform from
which CDs and books can be bought, EPlat a system for the management of courses, lectures and
students of a university, M-Shop a system for managing sales at a music shop, Theatre a system
for managing bookings for a theatre.</p>
</dd>
<dt>Period</dt><dd><p>&lt;fct&gt;|Time period of the cross-over experiment: 1 or 2</p>
</dd>
<dt>Treatment</dt><dd><p>&lt;fct&gt;|Experimental Treatment: A Dynamic Model (DM) vs No Dynamic Model (NODM)</p>
</dd>
<dt>Comprehension</dt><dd><p>&lt;dbl&gt;|Dependent variable: The comprehension level the software engineer
achieved based on the F-measure </p>
</dd>
<dt>CrossOverID</dt><dd><p>&lt;fct&gt;|CrossOver category: For 4 group crossover designs, the crossover
category specifies the matching pairs of sequence groups, CO1 and CO2. For a 2 group crossover,
the category is set to CO1 only</p>
</dd>
<dt>Ability</dt><dd><p>&lt;fct&gt;|Ability: An assessment of the ability of participants: Low, High, NA (not
available)</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Abrahao13TSE

</code></pre>

<hr>
<h2 id='KitchenhamEtAl.CorrelationsAmongParticipants.Gravino15JVLC'>KitchenhamEtAl.CorrelationsAmongParticipants.Gravino15JVLC data</h2><span id='topic+KitchenhamEtAl.CorrelationsAmongParticipants.Gravino15JVLC'></span>

<h3>Description</h3>

<p>Data illustrate correlations between results from individual participants in a family of two
cross-over experiments conducted by Gravino et al.:
[1] C. Gravino, G. Scanniello, and G. Tortora, 'Source-code comprehension tasks supported by
UML design models: Results from a controlled experiment and a differentiated replication,'
Journal of Visual Languages and Computing, vol. 28, pp. 23–38, 2015.
The experiments assess whether the comprehension of object oriented source-code increases used
with UML class and sequence diagrams produced in the software design phase.
If you use this data set please cite:
[1] C. Gravino, G. Scanniello, and G. Tortora, 'Source-code comprehension tasks supported by UML
design models: Results from a controlled experiment and a differentiated replication,'
Journal of Visual Languages and Computing, vol. 28, pp. 23–38, 2015.
[2] Barbara Kitchenham, Lech Madeyski, Giuseppe Scanniello and Carmine Gravino, 'The importance
of the Correlation between Results from Individual Participants in Crossover Experiments'
(to be submitted as of 2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Gravino15JVLC
</code></pre>


<h3>Format</h3>

<p>A data frame with 64  rows and 9 variables:
</p>

<dl>
<dt>ExperimentID</dt><dd><p>&lt;fct&gt;|ExperimentID: A unique identifier for each of the three experiments
in the data set.</p>
</dd>
<dt>ParticipantID</dt><dd><p>&lt;fct&gt;|Participant ID: An identifier for each participant, unique for a
specific experiment.</p>
</dd>
<dt>SequenceGroup</dt><dd><p>&lt;fct&gt;|Experimental Sequence Group: A , B , C, D</p>
</dd>
<dt>System</dt><dd><p>&lt;fct&gt;|Software systems used in the experiment: Music shop, a system for handling
the sales of a music shop. Theater ticket, a system for managing theatre reservations.  </p>
</dd>
<dt>Period</dt><dd><p>&lt;fct&gt;|Time period of the cross-over experiment: 1 or 2</p>
</dd>
<dt>Treatment</dt><dd><p>&lt;fct&gt;|Experimental Treatment: Mo, design models were available, NOMo design
models were not available</p>
</dd>
<dt>Comprehension</dt><dd><p>&lt;dbl&gt;|Dependent variable: The level of comprehension achieved by the
software engineer. </p>
</dd>
<dt>Time </dt><dd><p>&lt;dbl&gt;|Dependent variable: The time [min] taken to complete the comprehension task. </p>
</dd>
<dt>CrossOverID</dt><dd><p>&lt;fct&gt;|CrossOver category: For 4 group crossover designs, the crossover
category specifies the matching pairs of sequence groups, CO1 and CO2. For 2 group crossover,
the category is set to CO1 only</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Gravino15JVLC
</code></pre>

<hr>
<h2 id='KitchenhamEtAl.CorrelationsAmongParticipants.Madeyski10'>KitchenhamEtAl.CorrelationsAmongParticipants.Madeyski10 data</h2><span id='topic+KitchenhamEtAl.CorrelationsAmongParticipants.Madeyski10'></span>

<h3>Description</h3>

<p>Data illustrate correlations between results from individual participants in cross-over
experiment P2007 (Smell and Library) conducted by Madeyski, see:
[1] Lech Madeyski, Test-Driven Development: An Empirical Evaluation of Agile Practice.
(Heidelberg, London, New York): Springer, 2010. Foreword by Prof. Claes Wohlin.
If you use this data set please cite:
[1] Lech Madeyski, Test-Driven Development: An Empirical Evaluation of Agile Practice.
(Heidelberg, London, New York): Springer, 2010. Foreword by Prof. Claes Wohlin.
[2] Barbara Kitchenham, Lech Madeyski, Giuseppe Scanniello and Carmine Gravino, 'The importance
of the Correlation between Results from Individual Participants in Crossover Experiments'
(to be submitted as of 2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Madeyski10
</code></pre>


<h3>Format</h3>

<p>'KitchenhamEtAl.CorrelationsAmongParticipants.Madeyski10': a data frame with 45 rows
and 10 variables:
</p>

<dl>
<dt>ExperimentID</dt><dd><p>&lt;fct&gt;| ExperimentID: This experiment is the only cross-over experiment in
the family of TDD and Pair-Programming experiments conducted by Madeyski, so all values in this
column are set to 'P2007'.</p>
</dd>
<dt>ParticipantID</dt><dd><p>&lt;fct&gt; | Participant ID: An identifier for each participant, unique for a
specific experiment.</p>
</dd>
<dt>SequenceGroup</dt><dd><p>&lt;fct&gt; | Experimental Sequence Group: A (TLSP-TFSP), B (TFSP-TLSP)</p>
</dd>
<dt>System</dt><dd><p>&lt;fct&gt; | Software system to develop: Smell (a tool for identifying bad code smells
in Java source code through the use of a set of software metrics) or Library (a library
application)</p>
</dd>
<dt>Period</dt><dd><p>&lt;fct&gt; | Time period of the cross-over experiment: 1 or 2</p>
</dd>
<dt>Treatment</dt><dd><p>&lt;fct&gt; | Experimental Treatment: Test-First Solo Programming (TFSP) vs Test-Last
Solo Programming (TLSP)</p>
</dd>
<dt>PATP</dt><dd><p>&lt;dbl&gt; | Dependent variable: Percentage of Acceptance Tests Passed</p>
</dd>
<dt>NATPPH</dt><dd><p>&lt;dbl&gt; | Dependent variable: Number of Acceptance Tests Passed Per Hour</p>
</dd>
<dt>CBO</dt><dd><p>&lt;dbl&gt; | Dependent variable: Mean value of Coupling Between Objects (CBO), see CK set
of metrics</p>
</dd>
<dt>WMC</dt><dd><p>&lt;dbl&gt; | Dependent variable: Mean value of Weighted Number of Methods in Class (WMC),
see CK set of metrics</p>
</dd>
<dt>RFC</dt><dd><p>&lt;dbl&gt; | Dependent variable: Mean value of Response For a Class (RFC), see CK set of
metrics</p>
</dd>
<dt>CrossOverID</dt><dd><p>&lt;fct&gt; | Cross-Over Code. This experiment is a simple two-group cross-over
experiment with one cross-over code, so all values in this column are set to 'CO1'.
However, four-group experiments require a code to identify the linked sequence groups
(although that can be deduced from the system used in the first time period).
A crossover code is also essential for non-parametric analysis.</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://madeyski.e-informatyka.pl/reproducible-research/">https://madeyski.e-informatyka.pl/reproducible-research/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Madeyski10

</code></pre>

<hr>
<h2 id='KitchenhamEtAl.CorrelationsAmongParticipants.Reggio15SSM'>KitchenhamEtAl.CorrelationsAmongParticipants.Reggio15SSM data</h2><span id='topic+KitchenhamEtAl.CorrelationsAmongParticipants.Reggio15SSM'></span>

<h3>Description</h3>

<p>Data illustrate correlations between results from individual participants in a family of two
cross-over experiments conducted by Reggio et al:
[1] G. Reggio, F. Ricca, G. Scanniello, F. D. Cerbo, and G. Dodero,'On the comprehension of
workflows modeled with a precise style: results from a family of controlled experiments'.
Software and Systems Modeling, vol. 14, pp. 1481–1504, 2015.
The experiments assess whether the level of formality/precision in workflow model influences
comprehension.
If you use this data set please cite:
[1] G. Reggio, F. Ricca, G. Scanniello, F. D. Cerbo, and G. Dodero, 'On the comprehension of
workflows modeled with a precise style: results from a family of controlled experiments'.
Software and Systems Modeling, vol. 14, pp. 1481–1504, 2015.
[2] Barbara Kitchenham, Lech Madeyski, Giuseppe Scanniello and Carmine Gravino, 'The Importance
of the Correlation between Results from Individual Participants in Crossover Experiments'
(to be submitted as of 2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Reggio15SSM
</code></pre>


<h3>Format</h3>

<p>A data frame with 78 rows and 9 variables:
</p>

<dl>
<dt>ExperimentID</dt><dd><p>&lt;fct&gt;|ExperimentID: A unique identifier for each of the three experiments
in the data set.</p>
</dd>
<dt>ParticipantID</dt><dd><p>&lt;fct&gt;|Participant ID: An identifier for each participant, unique for a
specific experiment.</p>
</dd>
<dt>SequenceGroup</dt><dd><p>&lt;fct&gt;|Experimental Sequence Group: A , B , C, D</p>
</dd>
<dt>System</dt><dd><p>&lt;fct&gt;|Software systems used in the experiment: PO, a system to process orders for
an online shop. DM, a system to manage an online document review process.</p>
</dd>
<dt>Period</dt><dd><p>&lt;fct&gt;|Time period of the cross-over experiment: 1 or 2</p>
</dd>
<dt>Treatment</dt><dd><p>&lt;fct&gt;|Experimental Treatment: </p>
</dd>
<dt>Comprehension</dt><dd><p>&lt;dbl&gt;|Dependent variable: The comprehension level obtained by each
participant.</p>
</dd>
<dt>Time</dt><dd><p>&lt;dbl&gt;|Dependent variable: The time [min] taken by each participant to complete the
comprehension task.</p>
</dd>
<dt>CrossOverID</dt><dd><p>&lt;fct&gt;|CrossOver category: For 4 group crossover designs, the crossover
category specifies the matching pairs of sequence groups, CO1 and CO2. For a 2 group crossover,
the category is set to CO1 only</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Reggio15SSM

</code></pre>

<hr>
<h2 id='KitchenhamEtAl.CorrelationsAmongParticipants.Ricca10TSE'>KitchenhamEtAl.CorrelationsAmongParticipants.Ricca10TSE data</h2><span id='topic+KitchenhamEtAl.CorrelationsAmongParticipants.Ricca10TSE'></span>

<h3>Description</h3>

<p>Data illustrate correlations between results from individual participants in a family of four
cross-over experiments conducted by Ricca et al.:
[1] F. Ricca, M. D. Penta, M. Torchiano, P. Tonella, and M. Ceccato 'How developers’ experience
and ability influence web application comprehension tasks supported by uml stereotypes: A series
of four experiments', IEEE Transactions on Software Engineering, vol. 36, no. 1, pp. 96-118,
2010.
Although we present the full data set, only the first two experiments were used in the
correlation study, because many of the observations in the final two studies were unpaired.
The experiments assess whether participants performance comprehension tasks better when using
source code complemented by standard UML diagrams (UML) or by diagrams stereotyped using the
Conallen notation (Conallen).
If you use this data set please cite:
[1] F. Ricca, M. D. Penta, M. Torchiano, P. Tonella, and M. Ceccato 'How developers’ experience
and ability influence web application comprehension tasks supported by uml stereotypes: A series
of four experiments', IEEE Transactions on Software Engineering, vol. 36, no. 1, pp. 96—118,
2010.
[2] Barbara Kitchenham, Lech Madeyski, Giuseppe Scanniello and Carmine Gravino, 'The Importance
of the Correlation between Results from Individual Participants in Crossover Experiments'
(to be submitted as of 2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Ricca10TSE
</code></pre>


<h3>Format</h3>

<p>A data frame with 176 rows and 10 variables:
</p>

<dl>
<dt>ExperimentID</dt><dd><p>&lt;fct&gt;|ExperimentID: A unique identifier for each of the four experiments in
the data set.</p>
</dd>
<dt>ParticipantID</dt><dd><p>&lt;fct&gt;|Participant ID: An identifier for each participant, unique for a
specific experiment.</p>
</dd>
<dt>SequenceGroup</dt><dd><p>&lt;fct&gt;|Experimental Sequence Group: A , B , C, D</p>
</dd>
<dt>System</dt><dd><p>&lt;fct&gt;|Software systems used in the experiment: Two Java-based Web applications,
Claros and WfMS  </p>
</dd>
<dt>Period</dt><dd><p>&lt;fct&gt;|Time period of the cross-over experiment: 1 or 2</p>
</dd>
<dt>Treatment</dt><dd><p>&lt;fct&gt;|Experimental Treatment: UML or Conallon</p>
</dd>
<dt>FMeasure</dt><dd><p>&lt;dbl&gt;|Dependent variable: The comprehension level achieved by the participant.</p>
</dd>
<dt>Time</dt><dd><p>&lt;dbl&gt;|Dependent variable: The time [min] to complete the experimental task</p>
</dd>
<dt>CrossOverID</dt><dd><p>&lt;fct&gt;|CrossOver category: For 4 group crossover designs, the crossover
category specifies the matching pairs of sequence groups, CO1 and CO2. For 2 group crossover,
the category is set to CO1 only</p>
</dd>
<dt>Ability</dt><dd><p>&lt;fct&gt;| h: High l: Low, NA: Not available</p>
</dd>
<dt>Experience</dt><dd><p>&lt;fct&gt;| G: Master students, U: undergraduates, P: researchers</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Ricca10TSE

</code></pre>

<hr>
<h2 id='KitchenhamEtAl.CorrelationsAmongParticipants.Ricca14TOSEM'>KitchenhamEtAl.CorrelationsAmongParticipants.Ricca14TOSEM data</h2><span id='topic+KitchenhamEtAl.CorrelationsAmongParticipants.Ricca14TOSEM'></span>

<h3>Description</h3>

<p>Data illustrate correlations between results from individual participants in a family of three
of four cross-over experiments conducted by Ricca et al:
[1] F. Ricca, G. Scanniello, M. Torchiano, G. Reggio, and E. Astesiano,
'Assessing the effect of screen mockups on the comprehension of functional requirements,'
ACM Transactions on Software Engineering and Methodology, vol. 24, no. 1, pp. 1:1–1:38, Oct.
2014.
The goal of the study was to assess whether stakeholders benefit from the presence of screen
mock-ups in the comprehension of functional requirements represented with use cases.
[2] Barbara Kitchenham, Lech Madeyski, Giuseppe Scanniello and Carmine Gravino, 'The importance
of the Correlation between Results from Individual Participants in Crossover Experiments'
(to be submitted as of 2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Ricca14TOSEM
</code></pre>


<h3>Format</h3>

<p>A data frame with 176 rows and 10 variables:
</p>

<dl>
<dt>ExperimentID</dt><dd><p>&lt;fct&gt;|ExperimentID: A unique identifier for each of the three experiments
in the data set.</p>
</dd>
<dt>ParticipantID</dt><dd><p>&lt;fct&gt;|Participant ID: An identifier for each participant, unique for a
specific experiment.</p>
</dd>
<dt>SequenceGroup</dt><dd><p>&lt;fct&gt;|Experimental Sequence Group: A , B , C, D</p>
</dd>
<dt>System</dt><dd><p>&lt;fct&gt;|Software systems used in the experiment: AMICO, a system for management of
condominiums. EasyCoin, a system for cataloguing collections of coins.</p>
</dd>
<dt>Period</dt><dd><p>&lt;fct&gt;|Time period of the cross-over experiment: 1 or 2</p>
</dd>
<dt>Treatment</dt><dd><p>&lt;fct&gt;|Experimental Treatment: Screen mockup available (S) vs Text only (T)</p>
</dd>
<dt>Time</dt><dd><p>&lt;dbl&gt;|Dependent variable: The time [min] taken to perform the software engineering
task.</p>
</dd>
<dt>Comprehension</dt><dd><p>&lt;dbl&gt;|Dependent variable: The comprehension level the software engineers.</p>
</dd>
<dt>Efficiency</dt><dd><p>&lt;dbl&gt;|Dependent variable: The ratio of comprehension to time. </p>
</dd>
<dt>CrossOverID</dt><dd><p>&lt;fct&gt;|CrossOver category: For 4 group crossover designs, the crossover
category specifies the matching pairs of sequence groups, CO1 and CO2. For a 2 group crossover,
the category is set to CO1 only.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Ricca14TOSEM
</code></pre>

<hr>
<h2 id='KitchenhamEtAl.CorrelationsAmongParticipants.Romano18ESEM'>KitchenhamEtAl.CorrelationsAmongParticipants.Romano18ESEM data</h2><span id='topic+KitchenhamEtAl.CorrelationsAmongParticipants.Romano18ESEM'></span>

<h3>Description</h3>

<p>Data illustrate correlations between results from individual participants in a cross-over
experiment conducted by Romano et al.:
[1] S. Romano, G. Scanniello, D. Fucci, N. Juristo, and B. Turhan, 'The effect of noise on
software engineers’ performance', in Proceedings of the 12th ACM/IEEE International Symposium on
Empirical Software Engineering and Measurement, ser. ESEM'18, 2018.
The experiments assess whether noise has an impact on the performance of software engineers.
If you use this data set please cite:
[1] S. Romano, G. Scanniello, D. Fucci, N. Juristo, and B. Turhan, 'The effect of noise on
software engineers’ performance', in Proceedings of the 12th ACM/IEEE International Symposium on
Empirical Software Engineering and Measurement, ser. ESEM'18, 2018.
[2] Barbara Kitchenham, Lech Madeyski, Giuseppe Scanniello and Carmine Gravino, 'The Importance
of the Correlation between Results from Individual Participants in Crossover Experiments'
(to be submitted as of 2020).
The experiment had two parts but Kitchenham et al. only use the data from the first part of the experiment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Romano18ESEM
</code></pre>


<h3>Format</h3>

<p>A data frame with 194 and 10 variables:
</p>

<dl>
<dt>ExperimentID</dt><dd><p>&lt;fct&gt;|ExperimentID: A unique identifier for each part of the experiment.
Exp.1 identifies data from the first part of the experiment, Exp.2 identifies data from the
second part of the experiment.</p>
</dd>
<dt>ParticipantID</dt><dd><p>&lt;fct&gt;|Participant ID: An identifier for each participant, unique for both
parts of the experiment.</p>
</dd>
<dt>SequenceGroup</dt><dd><p>&lt;fct&gt;|Experimental Sequence Group: A , B </p>
</dd>
<dt>System</dt><dd><p>&lt;fct&gt;|Software systems used in the experiment: For the first part of the
experiment, M-Shop (a system for managing a music shop) and Theater (a system for managing
theatre reservations). For the second part of the experiment: AveCalc (a system that manages as
electronic register and LaTazza  (a system for a drinks vending machine)  </p>
</dd>
<dt>Period</dt><dd><p>&lt;fct&gt;|Time period of the cross-over experiment: 1 or 2</p>
</dd>
<dt>Treatment</dt><dd><p>&lt;fct&gt;|Experimental Treatment: NOISE, participants were asked to perform a
comprehension task in a noisy environment.
NORMAL, participants were asked to perform a comprehension task under normal working conditions.</p>
</dd>
<dt>Fc</dt><dd><p>&lt;dbl&gt;|Dependent variable: the balanced F-measure which represents the trade-off
between  precision and recall, measured in the first part of the experiment.</p>
</dd>
<dt>Avg</dt><dd><p>&lt;dbl&gt;|Dependent variable: The average number of fully correct answers, measured in
the first part of the experiment. </p>
</dd>
<dt>Ff</dt><dd><p>&lt;dbl&gt;|Dependent variable: Effectiveness of fault correction. Measured in the second
part of the experiment. </p>
</dd>
<dt>CrossOverID</dt><dd><p>&lt;fct&gt;|CrossOver category: For 4 group crossovers, the crossover category
specifies the matching pairs of sequence groups, CO1 and CO2. For 2 group crossover, the
category is set to CO1 only.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Romano18ESEM

</code></pre>

<hr>
<h2 id='KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14EASE'>KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14EASE data</h2><span id='topic+KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14EASE'></span>

<h3>Description</h3>

<p>Data illustrate correlations between results from individual participants in a family of two
cross-over experiments conducted by Scanniello et al:
[1] G. Scanniello, M. Staron, H. Burden, and R. Heldal, 'On the effect of using SysML
requirement diagrams to comprehend requirements: results from two controlled experiments,' in
Proceedings of the 18th International Conference on Evaluation and Assessment in Software
Engineering, EASE. ACM, 2014.
The two experiments investigate whether requirements specified as SysML requirement diagrams
improve the comprehensibility of requirements.
If you use this data set please cite:
[1] G. Scanniello, M. Staron, H. Burden, and R. Heldal, 'On the effect of using SysML
requirement diagrams to comprehend requirements: results from two controlled experiments',
in Proceedings of the 18th International Conference on Evaluation and Assessment in Software
Engineering, EASE. ACM, 2014.
[2] Barbara Kitchenham, Lech Madeyski, Giuseppe Scanniello and Carmine Gravino, 'The importance
of the Correlation between Results from Individual Participants in Crossover Experiments'
(to be submitted as of 2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14EASE
</code></pre>


<h3>Format</h3>

<p>A data frame with 174 rows and 9 variables:
</p>

<dl>
<dt>ExperimentID</dt><dd><p>&lt;fct&gt;|ExperimentID: A unique identifier for each experiment in the data set.</p>
</dd>
<dt>ParticipantID</dt><dd><p>&lt;fct&gt;|Participant ID: An identifier for each participant, unique for a
specific experiment.</p>
</dd>
<dt>SequenceGroup</dt><dd><p>&lt;fct&gt;|Experimental Sequence Group: A (RD-NORD,Automobile-ESS),
B (NORD-RD,ESS-Automobile), C(NORD-RD,Automobile-ESS), D(RD-NORD,ESS-Automobile).</p>
</dd>
<dt>System</dt><dd><p>&lt;fct&gt;|Software systems used in the experiment: Automobile: A system for
controlling car behavior with use cases about entering the car, anti-lock breaking or operating
the climate control of a car. ESS (Enhanced Security System) a system designed
to detect potential home intruders.</p>
</dd>
<dt>Period</dt><dd><p>&lt;fct&gt;|Time period of the cross-over experiment: 1 or 2</p>
</dd>
<dt>Treatment</dt><dd><p>&lt;fct&gt;|Experimental Treatment: RD availability of a SysML requirements diagram
vs No requirements diagram (NORD)</p>
</dd>
<dt>Time</dt><dd><p>&lt;dbl&gt;|Dependent variable: The time [min] required for the comprehension task.</p>
</dd>
<dt>Comprehension</dt><dd><p>&lt;dbl&gt;|Dependent variable: The comprehension level the software engineer
achieved. </p>
</dd>
<dt>CrossOverID</dt><dd><p>&lt;fct&gt;|CrossOver category: For 4 group crossover designs, the crossover
category specifies the matching pairs of sequence groups, CO1 and CO2. For 2 group crossover,
the category is set to CO1 only</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14EASE

</code></pre>

<hr>
<h2 id='KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14JVLC'>KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14JVLC data</h2><span id='topic+KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14JVLC'></span>

<h3>Description</h3>

<p>Data illustrate correlations between results from individual participants in a cross-over
experiment conducted by Scanniello and Erra:
[1] G. Scanniello and U. Erra, 'Distributed modeling of use case diagrams with a method based on think-pair-square: Results from two controlled experiments', Journal of Visual Languages and
Computing, vol. 25, no. 4, pp. 494–517, 2014.
The experiment investigated whether a new method based on think-pair-square and its
implementation in a integrated communication/modeling environment (TPS approach) is as effective
as traditional face-to-face (F2F approach) for requirements elicitation. The experiment was performed in two stages using different software systems.
If you use this data set please cite:
[1] G. Scanniello and U. Erra, 'Distributed modeling of use case diagrams with a method based on
think-pair-square: Results from two controlled experiments,” Journal of Visual Languages and
Computing, vol. 25, no. 4, pp. 494–517, 2014.
[2] Barbara Kitchenham, Lech Madeyski, Giuseppe Scanniello and Carmine Gravino, 'The Importance
of the Correlation between Results from Individual Participants in Crossover Experiments'
(to be submitted as of 2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14JVLC
</code></pre>


<h3>Format</h3>

<p>A data frame with 36 rows and 12 variables:
</p>

<dl>
<dt>ExperimentID</dt><dd><p>&lt;fct&gt;|ExperimentID: A unique identifier for each experiment in the data set.</p>
</dd>
<dt>ParticipantID</dt><dd><p>&lt;fct&gt;|Participant ID: An identifier for each team of four participants, unique for the specific experiment.</p>
</dd>
<dt>SequenceGroup</dt><dd><p>&lt;fct&gt;|Experimental Sequence Group: A , B</p>
</dd>
<dt>System</dt><dd><p>&lt;fct&gt;|Software systems used in the experiment: Library (a software system to manage
books and users of a library) and FilmCollection (a software system for the selling and the
rental of films in a shop) in ExperimentStage1 and Rent (a car rental software to manage
cars, customers, and reservations) and ECP (an E-Commerce Platform to order CDs and books via
the Internet from an on line catalogue), in ExperimentStage2. </p>
</dd>
<dt>Treatment</dt><dd><p>&lt;fct&gt;|Experimental Treatment: TPS vs F2F.</p>
</dd>
<dt>Period</dt><dd><p>&lt;fct&gt;|Time period of the cross-over experiment: 1 or 2 within each stage of the
experiment</p>
</dd>
<dt>Time</dt><dd><p>&lt;dbl&gt;|Dependent variable: The total time [min] to accomplish the requirement
engineering task.</p>
</dd>
<dt>Quality</dt><dd><p>&lt;dbl&gt;|Dependent variable: The quality of the requirements engineering task. </p>
</dd>
<dt>CrossOverID</dt><dd><p>&lt;fct&gt;|Crossover category: For a single 2 group crossover experiment, the
value is set to CO1 for each experiment stage.</p>
</dd>
<dt>ExperimentPeriod</dt><dd><p>&lt;fct&gt;|ExperimentPeriod: The time period across both stages of the
experiment.</p>
</dd>
<dt>ExperimentStage</dt><dd><p>&lt;fct&gt;|ExperimentStage: 1 first stage, 2 second stage.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14JVLC

</code></pre>

<hr>
<h2 id='KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14TOSEM'>KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14TOSEM data</h2><span id='topic+KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14TOSEM'></span>

<h3>Description</h3>

<p>Data illustrate correlations between results from individual participants in a family of four
cross-over experiments conducted by Scanniello et al:
[1] G.  Scanniello,  C. Gravino,  M. Genero, J.A. Cruz-Lemus, and  G. Tortora,  'On the Impact
of UML Analysis Models on Source-Code Comprehensibility and Modifiability', ACM Transactions on
Software Engineering and Methodlogy, vol. 23, no. 2, pp. 13:1-13:26, 2014
The family of experiments investigated whether the availability of analysis models in addition
to the source code made the code easier to understand and modify.
If you use this data set please cite:
[1] G.  G.  Scanniello,  C. Gravino,  M. Genero, J.A. Cruz-Lemus, and  G. Tortora, 'On the
Impact of UML Analysis Models on Source-Code Comprehensibility and Modifiability', ACM
Transactions on Software Engineering and Methodology, vol. 23, no. 2, pp. 13:1-13:26, 2014
[2] Barbara Kitchenham, Lech Madeyski, Giuseppe Scanniello and Carmine Gravino, 'The importance
of the Correlation between Results from Individual Participants in Crossover Experiments'
(to be submitted as of 2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14TOSEM
</code></pre>


<h3>Format</h3>

<p>'KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14TOSEM': a data frame with 172
rows and 9 variables:
</p>

<dl>
<dt>ExperimentID</dt><dd><p>&lt;fct&gt; | ExperimentID: A unique identifier for each experiment in the data
set.</p>
</dd>
<dt>ParticipantID</dt><dd><p>&lt;fct&gt; | Participant ID: An identifier for each participant, unique for a
specific experiment.</p>
</dd>
<dt>Treatment</dt><dd><p>&lt;fct&gt; | Experimental Treatment: AM an Analysis Model with source code (AM) vs
Source Code only (SC)</p>
</dd>
<dt>SequenceGroup</dt><dd><p>&lt;fct&gt; | Experimental Sequence Group: A (AM-SC,S1-S2), B (SC-AM,S1-S2),
C(AM-SC,S2-S1), D(SC-AM,S2-S1)</p>
</dd>
<dt>System</dt><dd><p>&lt;fct&gt; | Software systems used in the experiment: S1 A system to sell and manage
CDs/DVDs in a music shop, S2 A system to book and by theater tickets.</p>
</dd>
<dt>Comprehension</dt><dd><p>&lt;dbl&gt; | Dependent variable: The comprehension level the software engineer
achieved based on the F-measure </p>
</dd>
<dt>Modification</dt><dd><p>&lt;dbl&gt; | Dependent variable: The modifiability level the software engineer
achieved based on the F-measure</p>
</dd>
<dt>Period</dt><dd><p>&lt;fct&gt; | Time period of the cross-over experiment: 1 or 2</p>
</dd>
<dt>CrossOverID</dt><dd><p>&lt;fct&gt; | CrossOver category: For 4 group the crossover category specifies the
matching pairs of sequence groups, CO1 and CO2. For 2 group crossover, the category is set to
CO1 only</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello14TOSEM

</code></pre>

<hr>
<h2 id='KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello15EMSE'>KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello15EMSE data</h2><span id='topic+KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello15EMSE'></span>

<h3>Description</h3>

<p>Data illustrate correlations between results from individual participants in cross-over
experiment usb2 conducted by Scanniello et al:
[1] G. Scanniello, A. Marcus, and D. Pascale, 'Link analysis algorithms for static concept
location: an empirical assessment', Empirical Software Engineering, vol. 20, no. 6,
pp. 1666–1720, 2015.
The goal of the experiment is to assess whether a new technique (implemented as an Eclipse
plug-in) for static concept location (proposed by the authors) supports users in identifying the
places in the code where changes are to be made.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello15EMSE
</code></pre>


<h3>Format</h3>

<p>'KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello15EMSE': a data frame with 48
rows and 10 variables:
</p>

<dl>
<dt>ExperimentID</dt><dd><p>&lt;fct&gt;|ExperimentID: A unique identifier for each experiment in the data set.</p>
</dd>
<dt>ParticipantID</dt><dd><p>&lt;fct&gt;|Participant ID: An identifier for each participant, unique for a
specific experiment.</p>
</dd>
<dt>SequenceGroup</dt><dd><p>&lt;fct&gt;|Experimental Sequence Group: A (CL-NOCL,Jedit-Atunes),
B (NOCL-CL,Atunes-Jedit), C(NOCL-CL,Jedit-Atunes), D(CL-NOCL,Atunes-Jedit)</p>
</dd>
<dt>System</dt><dd><p>&lt;fct&gt;|Software systems used in the experiment: Jedit and Atunes</p>
</dd>
<dt>Treatment</dt><dd><p>&lt;fct&gt;|Experimental Treatment: Use of Concept Location plug-in (CL) vs
no Concept Location plug-in (NOCL)</p>
</dd>
<dt>Period</dt><dd><p>&lt;fct&gt;|Time period of the cross-over experiment: 1 or 2</p>
</dd>
<dt>Correctness</dt><dd><p>&lt;int&gt;|Dependent variable: 0, 1, 2, 3, 4. The participants are asked to
indicate a single change method for each of 4 bug reports. A change method is correctly
identified if that method is in the change set of the bug report.</p>
</dd>
<dt>Time</dt><dd><p>&lt;dbl&gt;|Dependent variable: The total time [min] to accomplish concept location tasks,
i.e.,to identify (four) bugs given their reports</p>
</dd>
<dt>Efficiency</dt><dd><p>&lt;dbl&gt;|Dependent variable: The participants’ efficiency in the execution of
concept location tasks. It is computed dividing correctness by time. </p>
</dd>
<dt>CrossOverID</dt><dd><p>&lt;fct&gt;|Crossover category: For 4 group crossover designs, the crossover
category specifies the matching pairs of sequence groups, CO1 and CO2. </p>
</dd>
</dl>



<h3>Details</h3>

<p>If you use this data set please cite:
[1] G. Scanniello, A. Marcus, and D. Pascale, 'Link analysis algorithms for static concept
location: an empirical assessment', Empirical Software Engineering, vol. 20, no. 6,
pp. 1666–1720, 2015.
[2] Barbara Kitchenham, Lech Madeyski, Giuseppe Scanniello and Carmine Gravino, 'The importance
of the Correlation between Results from Individual Participants in Crossover Experiments'
(to be submitted as of 2020).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello15EMSE

</code></pre>

<hr>
<h2 id='KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello17TOSEM'>KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello17TOSEM data</h2><span id='topic+KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello17TOSEM'></span>

<h3>Description</h3>

<p>Data illustrate correlations between results from individual participants in a family of four
cross-over experiments conducted by Scanniello et al.:
[1] G. Scanniello, M. Risi, P. Tramontana, and S. Romano, 'Fixing faults in C and Java source
code: Abbreviated vs. full-word identifier names', ACM Transactions on Software Engineering
Methodology, vol. 26, no. 2, 2017.
The experiments assess whether whether the use of abbreviated identifier names (ABBR), impacts
the effectiveness of fault fixing in C and Java source code in comparison with full-word
identifier names (FULL).
If you use this data set please cite:
[1] G. Scanniello, M. Risi, P. Tramontana, and S. Romano, “Fixing faults in C and Java source
code: Abbreviated vs. full-word identifier names', ACM Transactions on Software Engineering
Methodology, vol. 26, no. 2, 2017.
[2] Barbara Kitchenham, Lech Madeyski, Giuseppe Scanniello and Carmine Gravino, 'On the
Importance of the Correlation between Results from Individual Participants in Crossover
Experiments' (to be submitted as of 2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello17TOSEM
</code></pre>


<h3>Format</h3>

<p>A data frame with 200 rows and 17 variables:
</p>

<dl>
<dt>ExperimentID</dt><dd><p>&lt;fct&gt;|ExperimentID: A unique identifier for each of the experiments in the
data set.</p>
</dd>
<dt>ParticipantID</dt><dd><p>&lt;fct&gt;|Participant ID: An identifier for each participant, unique for a
specific experiment.</p>
</dd>
<dt>SequenceGroup</dt><dd><p>&lt;fct&gt;|Experimental Sequence Group: A , B , C, D</p>
</dd>
<dt>System</dt><dd><p>&lt;fct&gt;|Software systems used in the experiments: The Unibas experiment used Agenda
(a system for tracking personal contacts) and Gas-Station (a system for managing a petrol
station). The UniNa experiment used Financial (a system which is a command line option price
calculator) and Hotel-Reservation. The POLINA and PROF experiments used AveCalc (a system that
manages as electronic register and LaTazza  (a system for a drinks vending machine).</p>
</dd>
<dt>Period</dt><dd><p>&lt;fct&gt;|Time period of the cross-over experiment: 1 or 2</p>
</dd>
<dt>Treatment</dt><dd><p>&lt;fct&gt;|Experimental Treatment:ABBR, abbreviated names. FULL, full names</p>
</dd>
<dt>Time</dt><dd><p>&lt;dbl&gt;|Dependent variable: The time each participant spent performing the SE task.</p>
</dd>
<dt>FMeasure</dt><dd><p>&lt;dbl&gt;|Dependent variable: The effectiveness of the participants taking into
account correctness and completeness of the fault fixing tasks</p>
</dd>
<dt>Efficiency</dt><dd><p>&lt;dbl&gt;|Dependent variable: The ratio of effectiveness to time. </p>
</dd>
<dt>CrossOverID</dt><dd><p>&lt;fct&gt;|CrossOver category: For 4 group crossover designs, the crossover
category specifies the matching pairs of sequence groups, CO1 and CO2. For 2 group crossover,
the category is set to CO1 only.</p>
</dd>
<dt>Language</dt><dd><p>&lt;fct&gt;|Java or C. The language was the same for all participants in a specific
experiment. POLINA and PROF used Java, UNIBAS and UNINA used C.</p>
</dd>
<dt>Ident</dt><dd><p>&lt;dbl&gt;|Dependent variable: The number of faults identified.</p>
</dd>
<dt>Fixed</dt><dd><p>&lt;dbl&gt;|Dependent variable: The number of faults identified.</p>
</dd>
<dt>WrongIdent</dt><dd><p>&lt;dbl&gt;|Dependent variable: The number of faults incorrectly identified</p>
</dd>
<dt>WronglyFixed</dt><dd><p>&lt;dbl&gt;|Dependent variable: The number of faults incorrectly fixed.</p>
</dd>
<dt>precision</dt><dd><p>&lt;dbl&gt;|Dependent variable: The ratio of number of faults correctly fixed to the
number of faults correctly identified.</p>
</dd>
<dt>recall</dt><dd><p>&lt;dbl&gt;|Dependent variable: The ratio of number of faults correctly fixed to the
total number of fault.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Scanniello17TOSEM

</code></pre>

<hr>
<h2 id='KitchenhamEtAl.CorrelationsAmongParticipants.Torchiano17JVLC'>KitchenhamEtAl.CorrelationsAmongParticipants.Torchiano17JVLC data</h2><span id='topic+KitchenhamEtAl.CorrelationsAmongParticipants.Torchiano17JVLC'></span>

<h3>Description</h3>

<p>Data illustrate correlations between results from individual participants in a family of three
cross-over experiments conducted by Torchiano et al:
[1] M. Torchiano, G. Scanniello, F. Ricca, G. Reggio, and M. Leotta,
'Do UML object diagrams affect design comprehensibility? Results
from a family of four controlled experiments.' Journal of Visual Languages
and  Computing, vol. 41, pp. 10–21, 2017.
Although the paper reports four experiment, we only have data from three of those experiments.
The experiments assess whether the comprehensibility of UML specifications improve when the
software documents include UML object diagrams as well as the standard UML class diagrams.
If you use this data set please cite:
[1] M. Torchiano, G. Scanniello, F. Ricca, G. Reggio, and M. Leotta,
'Do UML object diagrams affect design comprehensibility? Results
from a family of four controlled experiments.' Journal of Visual Languages
and  Computing, vol. 41, pp. 10–21, 2017.
[2] Barbara Kitchenham, Lech Madeyski, Giuseppe Scanniello and Carmine Gravino, 'The importance
of the Correlation between Results from Individual Participants in Crossover Experiments'
(to be submitted as of 2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Torchiano17JVLC
</code></pre>


<h3>Format</h3>

<p>A data frame with 214 rows and 8 variables:
</p>

<dl>
<dt>ExperimentID</dt><dd><p>&lt;fct&gt;|ExperimentID: A unique identifier for each of the three experiments
in the data set.</p>
</dd>
<dt>ParticipantID</dt><dd><p>&lt;fct&gt;|Participant ID: An identifier for each participant, unique for a
specific experiment.</p>
</dd>
<dt>SequenceGroup</dt><dd><p>&lt;fct&gt;|Experimental Sequence Group: A , B , C, D</p>
</dd>
<dt>System</dt><dd><p>&lt;fct&gt;|Software systems used in the experiment: File System manager (FS) for
folders, files, links. Roads system (R) handles maps made up of cities connected by means of
roads. Train (T) a system to manage timetables, trains, and paths. Catalogue system (C).
It collects category of items (e.g., cars) and items (e.g., car models) based on a set of
features (e.g., number of  doors). In PoliTo2, only FS and T were administered to the
participants, while in UniBas1 and UniGe1 all the four experimental objects were used. </p>
</dd>
<dt>Period</dt><dd><p>&lt;fct&gt;|Time period of the cross-over experiment: 1 or 2</p>
</dd>
<dt>Treatment</dt><dd><p>&lt;fct&gt;|Experimental Treatment: Object Diagram (OD) vs No Object Diagram (NoOD)</p>
</dd>
<dt>Comprehension</dt><dd><p>&lt;dbl&gt;|Dependent variable: The comprehension level the software engineers.
For PoliTo2 Comprehension was based on answering a set of 4 questions, for UniBas and UniGe
comprehension was measured using the F metric. </p>
</dd>
<dt>CrossOverID</dt><dd><p>&lt;fct&gt;|CrossOver category: For 4 group crossover designs, the crossover
category specifies the matching pairs of sequence groups, CO1 and CO2. For 2 group crossover,
the category is set to CO1 only</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamEtAl.CorrelationsAmongParticipants.Torchiano17JVLC

</code></pre>

<hr>
<h2 id='KitchenhamMadeyski.SimulatedCrossoverDataSets'>KitchenhamMadeyski.SimulatedCrossoverDataSets data</h2><span id='topic+KitchenhamMadeyski.SimulatedCrossoverDataSets'></span>

<h3>Description</h3>

<p>If you use this data set please cite this R package and the following paper: Lech Madeyski and Barbara Kitchenham, 'Effect Sizes and their Variance for AB/BA Crossover Design Studies', Empirical Software Engineering, vol. 24, no.4, p. 1982-2017, 2018. DOI: 10.1007/s10664-017-9574-5
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamMadeyski.SimulatedCrossoverDataSets
</code></pre>


<h3>Format</h3>

<p>A data frame with variables:
</p>

<dl>
<dt>actualSampleSize</dt><dd><p>Sample size</p>
</dd>
<dt>SSFull</dt><dd><p>Sample Size</p>
</dd>
<dt>CFull</dt><dd><p>Correlation</p>
</dd>
<dt>ESFull</dt><dd><p>Effect Size</p>
</dd>
<dt>Accuracy</dt><dd><p>Accuracy</p>
</dd>
<dt>PropSig</dt><dd><p>...</p>
</dd>
<dt>WrongTSig</dt><dd><p>...</p>
</dd>
</dl>



<h3>Details</h3>

<p>This is simulated normally distributed data from 30 subjects, with technique A being 10 units more effective than technique B, and there is a period effect equaling 5 units. Subject 1 to 15 used technique B first while subjects 16 to 30 used technique A first.
</p>


<h3>Source</h3>

<p><a href="https://madeyski.e-informatyka.pl/reproducible-research/">https://madeyski.e-informatyka.pl/reproducible-research/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamMadeyski.SimulatedCrossoverDataSets

</code></pre>

<hr>
<h2 id='KitchenhamMadeyskiBrereton.ABBAMetaAnalysisReportedResults'>KitchenhamMadeyskiBrereton.ABBAMetaAnalysisReportedResults data</h2><span id='topic+KitchenhamMadeyskiBrereton.ABBAMetaAnalysisReportedResults'></span>

<h3>Description</h3>

<p>This data is used in the paper: Barbara Kitchenham, Lech Madeyski and Pearl Brereton. Meta-analysis for Families of Experiments: A Systematic Review and Reproducibility Assessment, Empirical Software Engineering (2019) doi:10.1007/s10664-019-09747-0.
This data set reports the meta-analysis results reported by the authors of the primary studies included in the systematic review that reported results on a per document basis which for S7 and S11 was equivalent to reporting the results for each time period.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamMadeyskiBrereton.ABBAMetaAnalysisReportedResults
</code></pre>


<h3>Format</h3>

<p>A text file with variables:
</p>

<dl>
<dt>Study</dt><dd><p>This field includes the study identifier of each of the the 3 primary studies which reported results per document.</p>
</dd>
<dt>Type</dt><dd><p>This identifies the type of effect size used by the study authors. d or g refer to d_IG and g_IG, P is the aggregated p values, if the repeated measures (RM) estimate was obtained it is appropriately specified.</p>
</dd>
<dt>Source</dt><dd><p>Always set to Rep. This identifies that the data was as reported by the primary study authors.</p>
</dd>
<dt>mean</dt><dd><p>The overall mean effect size reported by the study authors</p>
</dd>
<dt>pvalue</dt><dd><p>The one-sided p-value associated with the overall mean reported by the study authors. NA means the authors did not report this statistic.</p>
</dd>
<dt>UB</dt><dd><p>The upper bound of the confidence interval of the overall mean as reported by the primary study authors. NA means the authors did not report this statistic.</p>
</dd>
<dt>LB</dt><dd><p>The lower bound of the confidence interval of the overall mean as reported by the primary study authors. NA means the authors did not report this statistic.</p>
</dd>
<dt>QE</dt><dd><p>The heterogeneity statistic associated with the meta-analysis as reported by the study authors. NA means the authors did not report this statistic.</p>
</dd>
<dt>Qep</dt><dd><p>The p-value of the heterogeneity statistic associated with the meta-analysis as reported by the study authors. NA means the authors did not report this statistic.</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://madeyski.e-informatyka.pl/reproducible-research/">https://madeyski.e-informatyka.pl/reproducible-research/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamMadeyskiBrereton.ABBAMetaAnalysisReportedResults

</code></pre>

<hr>
<h2 id='KitchenhamMadeyskiBrereton.ABBAReportedEffectSizes'>KitchenhamMadeyskiBrereton.ABBAReportedEffectSizes data</h2><span id='topic+KitchenhamMadeyskiBrereton.ABBAReportedEffectSizes'></span>

<h3>Description</h3>

<p>This data is used in the paper: Barbara Kitchenham, Lech Madeyski and Pearl Brereton. Meta-analysis for Families of Experiments: A Systematic Review and Reproducibility Assessment, Empirical Software Engineering (2019) doi:10.1007/s10664-019-09747-0.
This file holds the individual effect sizes for the first time period (or equivalently the first document), as reported by the 3 primary studies in the systematic review that reported results for each document/time period separately.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamMadeyskiBrereton.ABBAReportedEffectSizes
</code></pre>


<h3>Format</h3>

<p>A text file with variables:
</p>

<dl>
<dt>Study</dt><dd><p>This field includes the study identifier of each of the 3 primary studies which were included in the systematic review. The studies are S3, S7 and S11.</p>
</dd>
<dt>Type</dt><dd><p>This identifies the type of effect size used by the study authors. d  or g refer to dIG and gIG.</p>
</dd>
<dt>Source</dt><dd><p>Always set to Rep. This identifies that the data was as reported by the primary study authors.</p>
</dd>
<dt>Design</dt><dd><p>Mixed means different experiments in a particular family used different methods (onlyS3 used mixed methods and 4 experiments used the 4 group crossover and one used an independent groups design). ABBACO is the standard 2-group crossover design. </p>
</dd>
<dt>Exp1</dt><dd><p>This is the reported standardised effect size for the first time period and the first experiment in the family.</p>
</dd>
<dt>Exp2</dt><dd><p>This is the reported standardised effect size for the first time period and second experiment in the family.</p>
</dd>
<dt>Exp3</dt><dd><p>This is the reported standardised effect size for the first time period and the third experiment in the family.</p>
</dd>
<dt>Exp4</dt><dd><p>This is the reported standardised effect size for the first time period and the fourth experiment in the family. NA means there was no fourth experiment in the family.</p>
</dd>
<dt>Exp5</dt><dd><p>This is the reported standardised effect size for the first time period and the fifth experiment in the family. NA means there was no fifth experiment in the family.</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://madeyski.e-informatyka.pl/reproducible-research/">https://madeyski.e-informatyka.pl/reproducible-research/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamMadeyskiBrereton.ABBAReportedEffectSizes

</code></pre>

<hr>
<h2 id='KitchenhamMadeyskiBrereton.DocData'>KitchenhamMadeyskiBrereton.DocData data</h2><span id='topic+KitchenhamMadeyskiBrereton.DocData'></span>

<h3>Description</h3>

<p>This data is used in the paper: Barbara Kitchenham, Lech Madeyski and Pearl Brereton. Meta-analysis for Families of Experiments: A Systematic Review and Reproducibility Assessment, Empirical Software Engineering (2019) doi:10.1007/s10664-019-09747-0.
This file holds the descriptive data for each document and each experiment for studies 3, 7 and 11 which include the mean, standard deviation and sample size for the control and treatment techniques. These studies performed ABBA crossover experiments and reported data for each document separately. Note Study 3 also undertook an independent groups study but data from that experiment is held in the ExpData file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamMadeyskiBrereton.DocData
</code></pre>


<h3>Format</h3>

<p>A text file with variables:
</p>

<dl>
<dt>Study</dt><dd><p>This field includes the study identifier of each of the 3 primary studies which reported their basic statistics on a time period &amp; document basis. </p>
</dd>
<dt>Exp</dt><dd><p>This identifies the experiment to which the descriptive data belongs.</p>
</dd>
<dt>Doc</dt><dd><p>This identifies whether the data arose from the document used in the first or second time period. The value 'Doc1' identifies the data as coming from the first document or first time period. The value 'Doc2' identifies the data as coming from the second time period or document. Note for Study 3 we used the analysis of a specific document that was used in all 4 ABBA experiments. For studies 7 and 11, the authors identified which we used in r=each time period and Doc1 refers to data from the first time period.</p>
</dd>
<dt>Mc</dt><dd><p>The mean value of the observations obtained using the control technique for the identified document.</p>
</dd>
<dt>SDc</dt><dd><p>The standard deviation of the observations obtained using the control technique for the identified document.</p>
</dd>
<dt>Nc</dt><dd><p>The number of participants using the control technique in the first time period for the identified document.</p>
</dd>
<dt>Mt</dt><dd><p>The mean value of the observations obtained using the treatment technique for the identified document.</p>
</dd>
<dt>SDt</dt><dd><p>The standard deviation of the observations obtained using the treatment technique for the identified document.</p>
</dd>
<dt>Nt</dt><dd><p>The number of participants using the treatment technique in the first time period for the identified document.</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://madeyski.e-informatyka.pl/reproducible-research/">https://madeyski.e-informatyka.pl/reproducible-research/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamMadeyskiBrereton.DocData

</code></pre>

<hr>
<h2 id='KitchenhamMadeyskiBrereton.ExpData'>KitchenhamMadeyskiBrereton.ExpData data</h2><span id='topic+KitchenhamMadeyskiBrereton.ExpData'></span>

<h3>Description</h3>

<p>This data is used in the paper: Barbara Kitchenham, Lech Madeyski and Pearl Brereton. Meta-analysis for Families of Experiments: A Systematic Review and Reproducibility Assessment, Empirical Software Engineering (2019) doi:10.1007/s10664-019-09747-0.
This file holds the descriptive data for each experiment which include the mean, standard deviation and sample size for the control and treatment techniques. Note in the case of studies 3, 7 and 11, which reported descriptive data for each time period (or equivalently each document) separately, the values for of the descriptive data were obtained by analysing the data reported in the DocData file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamMadeyskiBrereton.ExpData
</code></pre>


<h3>Format</h3>

<p>A text file with variables:
</p>

<dl>
<dt>Study</dt><dd><p>This field includes the study identifier of each of the 13 primary studies which were included in the systematic review. </p>
</dd>
<dt>Exp</dt><dd><p>This identifies the experiment to which the descriptive data belongs.</p>
</dd>
<dt>Source</dt><dd><p>Always set to Rep. This identifies that the data was as reported by the primary study authors.</p>
</dd>
<dt>Mc</dt><dd><p>The mean value of the observations obtained using the control technique.</p>
</dd>
<dt>SDc</dt><dd><p>The standard deviation of the observations obtained using the control technique.</p>
</dd>
<dt>Nc</dt><dd><p>The number of participants using the control technique in the first time period.</p>
</dd>
<dt>Mt</dt><dd><p>The mean value of the observations obtained using the treatment technique.</p>
</dd>
<dt>SDt</dt><dd><p>The standard deviation of the observations obtained using the treatment technique.</p>
</dd>
<dt>Nt</dt><dd><p>The number of participants using the treatment technique in the first time period.</p>
</dd>
<dt>r</dt><dd><p>The correlation between repeated measures. NA if not reported. Note only study 13 reported this correlation.</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://madeyski.e-informatyka.pl/reproducible-research/">https://madeyski.e-informatyka.pl/reproducible-research/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamMadeyskiBrereton.ExpData

</code></pre>

<hr>
<h2 id='KitchenhamMadeyskiBrereton.MetaAnalysisReportedResults'>KitchenhamMadeyskiBrereton.MetaAnalysisReportedResults data</h2><span id='topic+KitchenhamMadeyskiBrereton.MetaAnalysisReportedResults'></span>

<h3>Description</h3>

<p>This data is used in the paper: Barbara Kitchenham, Lech Madeyski and Pearl Brereton. Meta-analysis for Families of Experiments: A Systematic Review and Reproducibility Assessment (to be submitted).
This data set reports the meta-analysis results reported by the authors of the 13 primary studies included in the systematic review.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamMadeyskiBrereton.MetaAnalysisReportedResults
</code></pre>


<h3>Format</h3>

<p>A text file file with variables:
</p>

<dl>
<dt>Study</dt><dd><p>This field includes the study identifier of each of the 13 primary studies which were included in the systematic review.</p>
</dd>
<dt>Type</dt><dd><p>This identifies the type of effect size used by the study authors. d  or g refer to d_IG and g_IG, P is the aggregated p values, if the repeated measures estimate was obtained it is appropriately specified, r refers to the point bi-serial correlation.</p>
</dd>
<dt>Source</dt><dd><p>Always set to Rep. This identifies that the data was as reported by the primary study authors.</p>
</dd>
<dt>mean</dt><dd><p>The overall mean effect size reported by the study authors</p>
</dd>
<dt>pvalue</dt><dd><p>The one-sided p-value associated with the overall mean reported by the study authors. NA means the authors did not report this statistic.</p>
</dd>
<dt>UB</dt><dd><p>The upper bound of the confidence interval of the overall mean as reported by the primary study authors. NA means the authors did not report this statistic.</p>
</dd>
<dt>LB</dt><dd><p>The lower bound of the confidence interval of the overall mean as reported by the primary study authors. NA means the authors did not report this statistic.</p>
</dd>
<dt>QE</dt><dd><p>The heterogeneity statistic associated with the meta-analysis as reported by the study authors. NA means the authors did not report this statistic.</p>
</dd>
<dt>Qep</dt><dd><p>The p-value of the heterogeneity statistic associated with the meta-analysis as reported by the study authors. NA means the authors did not report this statistic.</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://madeyski.e-informatyka.pl/reproducible-research/">https://madeyski.e-informatyka.pl/reproducible-research/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamMadeyskiBrereton.MetaAnalysisReportedResults

</code></pre>

<hr>
<h2 id='KitchenhamMadeyskiBrereton.ReportedEffectSizes'>KitchenhamMadeyskiBrereton.ReportedEffectSizes data</h2><span id='topic+KitchenhamMadeyskiBrereton.ReportedEffectSizes'></span>

<h3>Description</h3>

<p>This data is used in the paper: Barbara Kitchenham, Lech Madeyski and Pearl Brereton. Meta-analysis for Families of Experiments: A Systematic Review and Reproducibility Assessment, Empirical Software Engineering (2019) doi:10.1007/s10664-019-09747-0.
This file holds the individual effect sizes for each experiment, as reported by 13 primary studies in the systematic review.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamMadeyskiBrereton.ReportedEffectSizes
</code></pre>


<h3>Format</h3>

<p>A text file with variables:
</p>

<dl>
<dt>Study</dt><dd><p>This field includes the study identifier of each of the 13 primary studies which were included in the systematic review.</p>
</dd>
<dt>Type</dt><dd><p>This identifies the type of effect size used by the study authors. d  or g refer to dIG and gIG, p is the p-value used for aggregation, if the repeated measures estimate was obtained it is appropriately specified as gRM, r refers to the point bi-serial correlation.</p>
</dd>
<dt>Source</dt><dd><p>Always set to Rep. This identifies that the data was as reported by the primary study authors.</p>
</dd>
<dt>Design</dt><dd><p>The refers to the design method used by the study author. 4GroupCO is a 4-group crossover design. Mixed means different experiments in a particular family used different methods (only S3 used mixed methods and 4 experiments used the 4 group crossover and one used an independent groups design). ABBACO is the standard 2-group crossover design. IndGroups is the independent groups design also called between groups design or a randomised design. PrePost is pretest and posttest design with a post test control.</p>
</dd>
<dt>Exp1</dt><dd><p>This is the reported standardized effect size for the first experiment in the family.</p>
</dd>
<dt>Exp2</dt><dd><p>This is the reported standardized effect size for the second experiment in the family.</p>
</dd>
<dt>Exp3</dt><dd><p>This is the reported standardized effect size for the third experiment in the family.</p>
</dd>
<dt>Exp4</dt><dd><p>This is the reported standardized effect size for the fourth experiment in the family. NA means there was no fourth experiment in the family.</p>
</dd>
<dt>Exp5</dt><dd><p>This is the reported standardized effect size for the fifth experiment in the family. NA means there was no fifth experiment in the family.</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://madeyski.e-informatyka.pl/reproducible-research/">https://madeyski.e-informatyka.pl/reproducible-research/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamMadeyskiBrereton.ReportedEffectSizes

</code></pre>

<hr>
<h2 id='KitchenhamMadeyskiBudgen16.COCOMO'>KitchenhamMadeyskiBudgen16.COCOMO data</h2><span id='topic+KitchenhamMadeyskiBudgen16.COCOMO'></span>

<h3>Description</h3>

<p>If you use this data set please cite this R package and the following paper when accepted: Barbara Kitchenham, Lech Madeyski, David Budgen, Jacky Keung, Pearl Brereton, Stuart Charters, Shirley Gibbs, and Amnart Pohthong, 'Robust Statistical Methods for Empirical Software Engineering', Empirical Software Engineering, vol. 22, no.2, p. 579-630, 2017. DOI: 10.1007/s10664-016-9437-5 (https://dx.doi.org/10.1007/s10664-016-9437-5), URL: https://madeyski.e-informatyka.pl/download/KitchenhamMadeyskiESE.pdf
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamMadeyskiBudgen16.COCOMO
</code></pre>


<h3>Format</h3>

<p>A data frame with variables:
</p>

<dl>
<dt>Project</dt><dd><p>Project ID</p>
</dd>
<dt>Type</dt><dd><p>A categorical variable describing the type of the project</p>
</dd>
<dt>Year</dt><dd><p>The year the project was completed</p>
</dd>
<dt>Lang</dt><dd><p>A categorical variable describing the development language used</p>
</dd>
<dt>Rely</dt><dd><p>Ordinal value defining the required software reliability</p>
</dd>
<dt>Data</dt><dd><p>Ordinal value defining the data complexity / Data base size</p>
</dd>
<dt>Cplx</dt><dd><p>Ordinal value defining the complexity of the software / Process complexity</p>
</dd>
<dt>Aaf</dt><dd><p>??</p>
</dd>
<dt>Time</dt><dd><p>Ordinal value defining the stringency of timing constraints / Time constraint for cpu</p>
</dd>
<dt>Stor</dt><dd><p>Ordinal value defining the stringency of the data storage requirements / Main memory constraint</p>
</dd>
<dt>Virt</dt><dd><p>Virtual Machine volatility</p>
</dd>
<dt>Turn</dt><dd><p>Turnaround time</p>
</dd>
<dt>Type2</dt><dd><p>A categorical variable defining the hardware type: mini, max=mainframe, midi</p>
</dd>
<dt>Acap</dt><dd><p>Ordinal value defining the analyst capability</p>
</dd>
<dt>Aexp</dt><dd><p>Ordinal value defining the analyst experience / application experience</p>
</dd>
<dt>Pcap</dt><dd><p>Ordinal value defining the programming capability of the team / Programmers capability</p>
</dd>
<dt>Vexp</dt><dd><p>Ordinal value defining the virtual machine experience of the team</p>
</dd>
<dt>Lexp</dt><dd><p>Ordinal value defining the programming language experience of the team</p>
</dd>
<dt>Cont</dt><dd><p>??</p>
</dd>
<dt>Modp</dt><dd><p> / Modern programming practices</p>
</dd>
<dt>Tool</dt><dd><p>Ordinal value defining the extent of tool use / Use of software tools</p>
</dd>
<dt>ToolCat</dt><dd><p>Recoding of Tool to labelled ordinal scale</p>
</dd>
<dt>Sced</dt><dd><p>Ordinal value defining the stringency of the schedule requirements / Schedule constraint</p>
</dd>
<dt>Rvol</dt><dd><p>Ordinal value defining the requirements volatility of the project</p>
</dd>
<dt>Select</dt><dd><p>Categorical value calculated by BAK for an analysis example</p>
</dd>
<dt>Rvolcat</dt><dd><p>Recoding of Rvol to a labelled ordinal scale</p>
</dd>
<dt>Modecat</dt><dd><p>Mode of the projects: O=Organic, E=Embedded, SD-Semi-Detached</p>
</dd>
<dt>Mode1</dt><dd><p>Dummy variable calculated by BAK: 1 if the project is Organic, 0 otherwise</p>
</dd>
<dt>Mode2</dt><dd><p>Dummy variable calculated by BAK: 1 if the project is Semi-detached, 0 otherwise</p>
</dd>
<dt>Mode3</dt><dd><p>Dummy variable calculated by BAK: 1 if the project is Embedded, 0 otherwise</p>
</dd>
<dt>KDSI</dt><dd><p>Product Size Thousand of Source Instructions</p>
</dd>
<dt>AKDSI</dt><dd><p>Adjusted Product Size for Project in Thousand Source Instructions - differs from KDSI for enhancement projects</p>
</dd>
<dt>Effort</dt><dd><p>Project Effort in Man months</p>
</dd>
<dt>Duration</dt><dd><p>Duration in months</p>
</dd>
<dt>Productivity</dt><dd><p>Productivity of project calculated by BAK as AKDSI/Effort, so the the larger the value the better the productivity</p>
</dd>
</dl>



<h3>Details</h3>

<p>Data set collected at TRW by Barry Boehm see: B.W. Boehm. 1981.  Software Engineering Economics. Prentice-Hall.
</p>
<p>Explanations by Barbara Kitchenham / https://terapromise.csc.ncsu.edu:8443/!/#repo/view/head/effort/cocomo/cocomo1/nasa93/nasa93.arff
</p>
<p>COCOMO.txt: pro type year Lang Rely Data CPLX aaf time store virt turn type2 acap aexp pcap vexp lexp cont modp TOOL TOOLcat SCED RVOL Select rvolcat Modecat Mode1 Mode2 Mode3 KDSI AKDSI Effort Dur Productivity
</p>


<h3>Source</h3>

<p><a href="https://madeyski.e-informatyka.pl/reproducible-research/">https://madeyski.e-informatyka.pl/reproducible-research/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamMadeyskiBudgen16.COCOMO

</code></pre>

<hr>
<h2 id='KitchenhamMadeyskiBudgen16.DiffInDiffData'>KitchenhamMadeyskiBudgen16.DiffInDiffData data</h2><span id='topic+KitchenhamMadeyskiBudgen16.DiffInDiffData'></span>

<h3>Description</h3>

<p>If you use this data set please cite this R package and the following paper when accepted: Barbara Kitchenham, Lech Madeyski, David Budgen, Jacky Keung, Pearl Brereton, Stuart Charters, Shirley Gibbs, and Amnart Pohthong, 'Robust Statistical Methods for Empirical Software Engineering', Empirical Software Engineering, vol. 22, no.2, p. 579-630, 2017. DOI: 10.1007/s10664-016-9437-5 (https://dx.doi.org/10.1007/s10664-016-9437-5), URL: https://madeyski.e-informatyka.pl/download/KitchenhamMadeyskiESE.pdf
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamMadeyskiBudgen16.DiffInDiffData
</code></pre>


<h3>Format</h3>

<p>A data frame with variables:
</p>

<dl>
<dt>Abstract</dt><dd><p>The abstract identifier</p>
</dd>
<dt>Site</dt><dd><p>A numeric identifier of the site</p>
</dd>
<dt>Treatment</dt><dd><p>A three character alphanumeric identifying the journal and time period of the abstract</p>
</dd>
<dt>Journal</dt><dd><p>The journal in which the abstract was published: IST or JSS</p>
</dd>
<dt>Timeperiod</dt><dd><p>The time period in which the abstract: 1 or 2</p>
</dd>
<dt>J1</dt><dd><p>The identifier for the judge who made the next 2 assessments</p>
</dd>
<dt>J1Completeness</dt><dd><p>The average completeness made by judge J1 based on the 8 completeness questions</p>
</dd>
<dt>J1Clarity</dt><dd><p>The clarity assessment made by judge J1</p>
</dd>
<dt>J2</dt><dd><p>The identifier for the judge who made the next 2 assessments</p>
</dd>
<dt>J2Completeness</dt><dd><p>The average completeness made by judge J2 based on the 8 completeness questions</p>
</dd>
<dt>J2Clarity</dt><dd><p>The clarity assessment made by judge J2</p>
</dd>
<dt>J3</dt><dd><p>The identifier for the judge who made the next 2 assessments</p>
</dd>
<dt>J3Completeness</dt><dd><p>The average completeness made by judge J3 based on the 8 completeness questions</p>
</dd>
<dt>J3Clarity</dt><dd><p>The clarity assessment made by judge J3</p>
</dd>
<dt>J4</dt><dd><p>The identifier for the judge who made the next 2 assessments</p>
</dd>
<dt>J4Completeness</dt><dd><p>The average completeness made by judge J4 based on the 8 completeness questions</p>
</dd>
<dt>J4Clarity</dt><dd><p>The clarity assessment made by judge J4</p>
</dd>
<dt>MeanCompleteness</dt><dd><p>The mean of J1Completeness, J2Completeness, J3Completeness, J4Completeness</p>
</dd>
<dt>MedianCompleteness</dt><dd><p>The median of J1Completeness, J2Completeness, J3Completeness, J4Completeness</p>
</dd>
<dt>MedianClarity</dt><dd><p>The median clarity of J1Clarity, J2Clarity, J3Clarity, J4Clarity</p>
</dd>
<dt>MeanClarity</dt><dd><p>The mean clarity of J1Clarity, J2Clarity, J3Clarity, J4Clarity</p>
</dd>
<dt>VarCompleteness</dt><dd><p>The variance of J1Completeness, J2Completeness, J3Completeness, J4Completeness</p>
</dd>
<dt>VarClarity</dt><dd><p>The variance clarity of J1Clarity, J2Clarity, J3Clarity, J4Clarity</p>
</dd>
</dl>



<h3>Details</h3>

<p>Data set was derived from the data reported in the SubjectData data set (subjectdata.txt). It contains the summary completeness and clarity data from 4 judges who assessed the same abstract. Only the initial 5 sites are included.
</p>
<p>dinddata.txt
</p>


<h3>Source</h3>

<p><a href="https://madeyski.e-informatyka.pl/reproducible-research/">https://madeyski.e-informatyka.pl/reproducible-research/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamMadeyskiBudgen16.DiffInDiffData

</code></pre>

<hr>
<h2 id='KitchenhamMadeyskiBudgen16.FINNISH'>KitchenhamMadeyskiBudgen16.FINNISH data</h2><span id='topic+KitchenhamMadeyskiBudgen16.FINNISH'></span>

<h3>Description</h3>

<p>If you use this data set please cite this R package and the following paper when accepted: Barbara Kitchenham, Lech Madeyski, David Budgen, Jacky Keung, Pearl Brereton, Stuart Charters, Shirley Gibbs, and Amnart Pohthong, 'Robust Statistical Methods for Empirical Software Engineering', Empirical Software Engineering, vol. 22, no.2, p. 579-630, 2017. DOI: 10.1007/s10664-016-9437-5 (https://dx.doi.org/10.1007/s10664-016-9437-5), URL: https://madeyski.e-informatyka.pl/download/KitchenhamMadeyskiESE.pdf
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamMadeyskiBudgen16.FINNISH
</code></pre>


<h3>Format</h3>

<p>A data frame with variables:
</p>

<dl>
<dt>Project</dt><dd><p>Project ID</p>
</dd>
<dt>DevEffort</dt><dd><p>Development Effort measured in hours</p>
</dd>
<dt>UserEffort</dt><dd><p>Effort provided by the customer/user organisation measured in hours</p>
</dd>
<dt>Duration</dt><dd><p>Project duration measured in months</p>
</dd>
<dt>HWType</dt><dd><p>A categorical variable defining the hardware type</p>
</dd>
<dt>AppType</dt><dd><p>A categorical variable defining the application type</p>
</dd>
<dt>FP</dt><dd><p>Function Points measured using the TIEKE organisation method</p>
</dd>
<dt>Co</dt><dd><p>A categorical variable defining the company</p>
</dd>
</dl>



<h3>Details</h3>

<p>Data set collected from 9 Finish companies by Mr Hanna M\'aki from the TIEKE organisation see Barbara Kitchenham and Kari Kansala, Inter-item correlations among function points, Proceedings ICSE 15, 1983, pp 477-480
</p>


<h3>Source</h3>

<p><a href="https://madeyski.e-informatyka.pl/reproducible-research/">https://madeyski.e-informatyka.pl/reproducible-research/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamMadeyskiBudgen16.FINNISH

</code></pre>

<hr>
<h2 id='KitchenhamMadeyskiBudgen16.PolishData'>KitchenhamMadeyskiBudgen16.PolishData data</h2><span id='topic+KitchenhamMadeyskiBudgen16.PolishData'></span>

<h3>Description</h3>

<p>If you use this data set please cite this R package and the following paper when accepted: Barbara Kitchenham, Lech Madeyski, David Budgen, Jacky Keung, Pearl Brereton, Stuart Charters, Shirley Gibbs, and Amnart Pohthong, 'Robust Statistical Methods for Empirical Software Engineering', Empirical Software Engineering, vol. 22, no.2, p. 579-630, 2017. DOI: 10.1007/s10664-016-9437-5 (https://dx.doi.org/10.1007/s10664-016-9437-5), URL: https://madeyski.e-informatyka.pl/download/KitchenhamMadeyskiESE.pdf
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamMadeyskiBudgen16.PolishData
</code></pre>


<h3>Format</h3>

<p>A data frame with variables:
</p>

<dl>
<dt>Abstract</dt><dd><p>The abstract identifier</p>
</dd>
<dt>Site</dt><dd><p>Numeric identifier for the site</p>
</dd>
<dt>Treatment</dt><dd><p>The first three characters of the Abstract field which identifies the journal and time period of the abstract</p>
</dd>
<dt>Journal</dt><dd><p>An acronym for the journal from which the abstract was obtained: IST or JSS</p>
</dd>
<dt>Timeperiod</dt><dd><p>The Time period in which the abstract was found: 1 or 2</p>
</dd>
<dt>J1</dt><dd><p>The identifier for the judge who made the next 2 assessments</p>
</dd>
<dt>J1Completeness</dt><dd><p>The average completeness made by judge J1 based on the 8 completeness questions</p>
</dd>
<dt>J1Clarity</dt><dd><p>The clarity assessment made by judge J1</p>
</dd>
<dt>J2</dt><dd><p>The identifier for the judge who made the next 2 assessments</p>
</dd>
<dt>J2Completeness</dt><dd><p>The average completeness made by judge J2 based on the 8 completeness questions</p>
</dd>
<dt>J2Clarity</dt><dd><p>The clarity assessment made by judge J2</p>
</dd>
<dt>J3</dt><dd><p>The identifier for the judge who made the next 2 assessments</p>
</dd>
<dt>J3Completeness</dt><dd><p>The average completeness made by judge J3 based on the 8 completeness questions</p>
</dd>
<dt>J3Clarity</dt><dd><p>The clarity assessment made by judge J3</p>
</dd>
<dt>J4</dt><dd><p>The identifier for the judge who made the next 2 assessments</p>
</dd>
<dt>J4Completeness</dt><dd><p>The average completeness made by judge J4 based on the 8 completeness questions</p>
</dd>
<dt>J4Clarity</dt><dd><p>The clarity assessment made by judge J4</p>
</dd>
<dt>MedianCompleteness</dt><dd><p>The median of J1Completeness, J2Completeness, J3Completeness, J4Completeness</p>
</dd>
<dt>MedianClarity</dt><dd><p>The median of J1Clarity, J2Clarity, J3Clarity, J4Clarity</p>
</dd>
</dl>



<h3>Details</h3>

<p>Data set derived from PolishSubjects data set collected at Wroclaw University. It summarizes the completeness and clarity data collected from 4 judges about the same abstract.
</p>
<p>PolishData.txt
</p>


<h3>Source</h3>

<p><a href="https://madeyski.e-informatyka.pl/reproducible-research/">https://madeyski.e-informatyka.pl/reproducible-research/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamMadeyskiBudgen16.PolishData

</code></pre>

<hr>
<h2 id='KitchenhamMadeyskiBudgen16.PolishSubjects'>KitchenhamMadeyskiBudgen16.PolishSubjects data</h2><span id='topic+KitchenhamMadeyskiBudgen16.PolishSubjects'></span>

<h3>Description</h3>

<p>If you use this data set please cite this R package and the following paper when accepted: Barbara Kitchenham, Lech Madeyski, David Budgen, Jacky Keung, Pearl Brereton, Stuart Charters, Shirley Gibbs, and Amnart Pohthong, 'Robust Statistical Methods for Empirical Software Engineering', Empirical Software Engineering, vol. 22, no.2, p. 579-630, 2017. DOI: 10.1007/s10664-016-9437-5 (https://dx.doi.org/10.1007/s10664-016-9437-5), URL: https://madeyski.e-informatyka.pl/download/KitchenhamMadeyskiESE.pdf
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamMadeyskiBudgen16.PolishSubjects
</code></pre>


<h3>Format</h3>

<p>A data frame with variables:
</p>

<dl>
<dt>Judge</dt><dd><p>The identifier for each subject</p>
</dd>
<dt>Abstract</dt><dd><p>The identifier for each abstract - the code starts with a three alphanumeric string that defines the source of the abstract</p>
</dd>
<dt>OrderViewed</dt><dd><p>Each judge assessed 4 abstracts in sequence, this data item identifies the order in which the subject viewed the specified abstract</p>
</dd>
<dt>Completness1</dt><dd><p>Assessment by judge of question 1:Is the reason for the project clear? Can take values:  Yes/No/Partly</p>
</dd>
<dt>Completness2</dt><dd><p>Assessment by judge of question 2: Is the specific aim/purpose of the study clear? Can take values:  Yes/No/Partly</p>
</dd>
<dt>Completness3</dt><dd><p>Assessment by judge of question 3: If the aim is to describe a new or enhanced software technology (e.g. method, tool, procedure or process) is the method used to develop this technology defined? Can take values:  Yes/No/Partly/NA</p>
</dd>
<dt>Completness4</dt><dd><p>Assessment by judge of question 4: Is the form (e.g. experiment, general empirical study, data mining, case study, survey, simulation etc.) that was used to evaluate the technology made clear? Can take values:  Yes/No/Partly</p>
</dd>
<dt>Completness5</dt><dd><p>Assessment by judge of question 5: Is there a description of how the evaluation process was organised? Can take values:  Yes/No/Partly</p>
</dd>
<dt>Completness6</dt><dd><p>Assessment by judge of question 6: Are the results of the evaluation clearly described? Can take values:  Yes/No/Partly</p>
</dd>
<dt>Completness7</dt><dd><p>Assessment by judge of question 7: Are any limitations of the study reported?:  Yes/No/Partly</p>
</dd>
<dt>Completness8</dt><dd><p>Assessment by judge of question 8: Are any ideas for future research presented?:  Yes/No/Partly</p>
</dd>
<dt>Clarity</dt><dd><p>Assessment by judge of question regarding the overall understandability of the abstract: Please give an assessment of the clarity of this abstract by circling a number on the scale of 1-10 below, where a value of 1 represents Very Obscure and 10 represents Extremely Clearly Written.</p>
</dd>
<dt>Completness1NumValue</dt><dd><p>A numerical value for completeness question 1 where 0=No, Partly=0.5, yes =1</p>
</dd>
<dt>Completness2NumValue</dt><dd><p>A numerical value for completeness question 2 where 0=No, Partly=0.5, yes =1, NA means not applicable</p>
</dd>
<dt>Completness3NumValue</dt><dd><p>A numerical value for completeness question 3 where 0=No, Partly=0.5, yes =1, NA means not applicable or not answered</p>
</dd>
<dt>Completness4NumValue</dt><dd><p>A numerical value for completeness question 4 where 0=No, Partly=0.5, yes =1, NA means not applicable</p>
</dd>
<dt>Completness5NumValue</dt><dd><p>A numerical value for completeness question 5 where 0=No, Partly=0.5, yes =1, NA means not applicable</p>
</dd>
<dt>Completness6NumValue</dt><dd><p>A numerical value for completeness question 6 where 0=No, Partly=0.5, yes =1, NA means not applicable</p>
</dd>
<dt>Completness7NumValue</dt><dd><p>A numerical value for completeness question 7 where 0=No, Partly=0.5, yes =1, NA means not applicable</p>
</dd>
<dt>Completness8NumValue</dt><dd><p>A numerical value for completeness question 8 where 0=No, Partly=0.5, yes =1, NA means not applicable</p>
</dd>
<dt>Sum</dt><dd><p>The sum of the numerical completeness questions excluding those labelled NA</p>
</dd>
<dt>TotalQuestions</dt><dd><p>The count of the number of question related to completeness excluding questions considered not applicable </p>
</dd>
<dt>Completeness</dt><dd><p>Sum/TotalQuestions</p>
</dd>
</dl>



<h3>Details</h3>

<p>Data set collected at Wroclaw University of Technology (POLAND) by Lech Madeyski includes separate entries for each abstract assessed by a judge, that is 4 entries for each judge. Data collected from 16 subjects recruited from Wroclaw  University of Technology who were each asked to assess 4 abstracts.
</p>
<p>Note Only completeness question 2 was expected to be context dependent and have a NA (not applicable)  answer, if other completeness answers were left blank, BAK coded the answer as NA
</p>
<p>polishsubjects.txt
</p>


<h3>Source</h3>

<p><a href="https://madeyski.e-informatyka.pl/reproducible-research/">https://madeyski.e-informatyka.pl/reproducible-research/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamMadeyskiBudgen16.PolishSubjects

</code></pre>

<hr>
<h2 id='KitchenhamMadeyskiBudgen16.SubjectData'>KitchenhamMadeyskiBudgen16.SubjectData</h2><span id='topic+KitchenhamMadeyskiBudgen16.SubjectData'></span>

<h3>Description</h3>

<p>If you use this data set please cite this R package and the following paper when accepted: Barbara Kitchenham, Lech Madeyski, David Budgen, Jacky Keung, Pearl Brereton, Stuart Charters, Shirley Gibbs, and Amnart Pohthong, 'Robust Statistical Methods for Empirical Software Engineering', Empirical Software Engineering, vol. 22, no. 2, pp. 579–630, 2017. DOI: 10.1007/s10664-016-9437-5 (https://dx.doi.org/10.1007/s10664-016-9437-5), URL: https://madeyski.e-informatyka.pl/download/KitchenhamMadeyskiESE.pdf
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KitchenhamMadeyskiBudgen16.SubjectData
</code></pre>


<h3>Format</h3>

<p>A data frame with variables:
</p>

<dl>
<dt>Judge</dt><dd><p>Alphanumeric identifier for each judge</p>
</dd>
<dt>Institution</dt><dd><p>Numerical value identifying each site from which data was collected</p>
</dd>
<dt>JudgeID</dt><dd><p>Numerical value identifying each judge</p>
</dd>
<dt>Age</dt><dd><p>Age of the judge in years</p>
</dd>
<dt>Eng1st</dt><dd><p>Whether the judge's first language was Enlish: Yes/No</p>
</dd>
<dt>YearsStudy</dt><dd><p>The number of years have student been studying computing at University: 1, 2, 3, 4</p>
</dd>
<dt>AbstractsRead</dt><dd><p>Number of abstracts the judge had read prior to the study' 0, 1 to 10, 10+</p>
</dd>
<dt>AbstractsWritten</dt><dd><p>Whether the judge had ever written an abstract for a scientific report/article</p>
</dd>
<dt>AbstractID</dt><dd><p>Alphanumeric identifier for an abstract. The first character identifies the journal, I=IST, J=JSS, the third digit identifies the time period as 1 or 2, the remaining digits identify the abstract number within the set of abstracts found for the specified journal and time period</p>
</dd>
<dt>Treat</dt><dd><p>The initial 3 characters of AbstractID</p>
</dd>
<dt>TreatID</dt><dd><p>A numeric identifier for the journal and time period, 1=IB1, 2=IB2, 3=JB1, 4=JB2</p>
</dd>
<dt>Order</dt><dd><p>The order in which the judge should have viewed the specified abstract</p>
</dd>
<dt>Completness1NumValue</dt><dd><p>The numeric answer to completeness question 1</p>
</dd>
<dt>Completness2NumValue</dt><dd><p>The numeric answer to completeness question 2</p>
</dd>
<dt>Completness3NumValue</dt><dd><p>The numeric answer to completeness question 3</p>
</dd>
<dt>Completness4NumValue</dt><dd><p>The numeric answer to completeness question 4</p>
</dd>
<dt>Completness5NumValue</dt><dd><p>The numeric answer to completeness question 5</p>
</dd>
<dt>Completness6NumValue</dt><dd><p>The numeric answer to completeness question 6</p>
</dd>
<dt>Completness7NumValue</dt><dd><p>The numeric answer to completeness question 7</p>
</dd>
<dt>Completness8NumValue</dt><dd><p>The numeric answer to completeness question 8</p>
</dd>
<dt>Clarity</dt><dd><p>The response to the clarity question or NA if not answered</p>
</dd>
<dt>NumberOfAnsweredCompletnessQuestions</dt><dd><p>The number of completeness questions excluding those with NA</p>
</dd>
<dt>TotalScore</dt><dd><p>Sum of the numeric values of the 8 completeness questions</p>
</dd>
<dt>MeanScore</dt><dd><p>Sum of the completeness questions 1 to 8 divided by TotalScore</p>
</dd>
<dt>Site</dt><dd><p>The name of the site which provided the data. HongKong refers to the Polytechnic University, HongKong.2 refers to the City University</p>
</dd>
</dl>



<h3>Details</h3>

<p>Data set collected from 16 judges assessing 4 abstracts at 6 sites: Lincoln University NZ=1, Hong Kong Polytechnic University=2, PSu Thailand=3, Durham=4, Keele=5, Hong Kong City University=6
</p>
<p>subjectdata.txt: Judge Institution JudgeID age eng1st years.study abs.read Absid Treat TreatID Order Com.1 Com.2 Com.3 Com.4 Com.5 Com.6
Com.7 Com.8 Clarity num.questions total.score av.score Site
</p>


<h3>Source</h3>

<p><a href="https://madeyski.e-informatyka.pl/reproducible-research/">https://madeyski.e-informatyka.pl/reproducible-research/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>KitchenhamMadeyskiBudgen16.SubjectData

</code></pre>

<hr>
<h2 id='LaplaceDist'>LaplaceDist</h2><span id='topic+LaplaceDist'></span>

<h3>Description</h3>

<p>Returns a sample of N observations from a Laplace distribution with specified mean and spread.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LaplaceDist(N, mean, spread, max = 0.5, min = -0.5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LaplaceDist_+3A_n">N</code></td>
<td>
<p>is the required sample size</p>
</td></tr>
<tr><td><code id="LaplaceDist_+3A_mean">mean</code></td>
<td>
<p>is the required mean</p>
</td></tr>
<tr><td><code id="LaplaceDist_+3A_spread">spread</code></td>
<td>
<p>is the spread of the function</p>
</td></tr>
<tr><td><code id="LaplaceDist_+3A_max">max</code></td>
<td>
<p>the upper limit of the distribution. Must be finite.</p>
</td></tr>
<tr><td><code id="LaplaceDist_+3A_min">min</code></td>
<td>
<p>the lower limit of the distribution. Must be finite.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>N values from a Laplace distribution
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
LaplaceDist(10, 0, 1)
#  [1] -0.55311564  0.85946218 -0.20094937  1.45258293  2.12808209 -2.39565480  0.05785263
#   [8]  1.53636446  0.10855453 -0.09076809

</code></pre>

<hr>
<h2 id='Madeyski15EISEJ.OpenProjects'>Madeyski15EISEJ.OpenProjects data</h2><span id='topic+Madeyski15EISEJ.OpenProjects'></span>

<h3>Description</h3>

<p>If you use this data set please cite: Marian Jureczko and Lech Madeyski, 'Cross-project defect prediction with respect to code ownership model: An empirical study', e-Informatica Software Engineering Journal, vol. 9, no. 1, pp. 21-35, 2015. DOI: 10.5277/e-Inf150102 (https://dx.doi.org/10.5277/e-Inf150102) URL: https://madeyski.e-informatyka.pl/download/JureczkoMadeyski15.pdf)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Madeyski15EISEJ.OpenProjects
</code></pre>


<h3>Format</h3>

<p>A data frame with variables:
</p>

<dl>
<dt>PROP</dt><dd><p>The percentage of classes of proprietary (i.e., industrial) projects that must be tested in order to find 80% of defects in case of software defect prediction models built on open source projects.</p>
</dd>
<dt>NOTOPEN</dt><dd><p>The percentage of classes of projects which are not open source projects that must be tested in order to find 80% of defects in case of software defect prediction models built on open source projects.</p>
</dd>
<dt>STUD</dt><dd><p>The percentage of classes of student (i.e., academic) projects that must be tested in order to find 80% of defects in case of software defect prediction models built on open source projects.</p>
</dd>
<dt>OPEN</dt><dd><p>The percentage of classes of open source projects that must be tested in order to find 80% of defects in case of software defect prediction models built on open source projects.</p>
</dd>
</dl>



<h3>Details</h3>

<p>This paper presents an analysis of 84 versions of industrial, open-source and academic projects. We have empirically evaluated whether those project types constitute separate classes of projects with regard to defect prediction. The predictions obtained from the models trained on the data from the open source projects were compared with the predictions from the other models (built on proprietary, i.e. industrial, student, open source, and not open source projects).
</p>


<h3>Source</h3>

<p><a href="https://madeyski.e-informatyka.pl/reproducible-research/">https://madeyski.e-informatyka.pl/reproducible-research/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Madeyski15EISEJ.OpenProjects

</code></pre>

<hr>
<h2 id='Madeyski15EISEJ.PropProjects'>Madeyski15EISEJ.PropProjects data</h2><span id='topic+Madeyski15EISEJ.PropProjects'></span>

<h3>Description</h3>

<p>If you use this data set please cite: Marian Jureczko and Lech Madeyski, 'Cross-project defect prediction with respect to code ownership model: An empirical study', e-Informatica Software Engineering Journal, vol. 9, no. 1, pp. 21-35, 2015. DOI: 10.5277/e-Inf150102 (https://dx.doi.org/10.5277/e-Inf150102) URL: https://madeyski.e-informatyka.pl/download/JureczkoMadeyski15.pdf)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Madeyski15EISEJ.PropProjects
</code></pre>


<h3>Format</h3>

<p>A data frame with variables:
</p>

<dl>
<dt>NOTPROP</dt><dd><p>The percentage of classes of non-proprietary (i.e., non-industrial) projects that must be tested in order to find 80% of defects in case of software defect prediction models built on proprietary (i.e., industrial) projects.</p>
</dd>
<dt>OPEN</dt><dd><p>The percentage of classes of open source projects that must be tested in order to find 80% of defects in case of software defect prediction models built on proprietary (i.e., industrial) projects.</p>
</dd>
<dt>STUD</dt><dd><p>The percentage of classes of student (i.e., academic) projects that must be tested in order to find 80% of defects in case of software defect prediction models built on proprietary (i.e., industrial) projects.</p>
</dd>
<dt>PROP</dt><dd><p>The percentage of classes of proprietary (i.e., industrial) projects that must be tested in order to find 80% of defects in case of software defect prediction models built on proprietary (i.e., industrial) projects.</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://madeyski.e-informatyka.pl/reproducible-research/">https://madeyski.e-informatyka.pl/reproducible-research/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Madeyski15EISEJ.PropProjects

</code></pre>

<hr>
<h2 id='Madeyski15EISEJ.StudProjects'>Madeyski15EISEJ.StudProjects data</h2><span id='topic+Madeyski15EISEJ.StudProjects'></span>

<h3>Description</h3>

<p>If you use this data set please cite: Marian Jureczko and Lech Madeyski, 'Cross-project defect prediction with respect to code ownership model: An empirical study', e-Informatica Software Engineering Journal, vol. 9, no. 1, pp. 21-35, 2015. DOI: 10.5277/e-Inf150102 (https://dx.doi.org/10.5277/e-Inf150102) URL: https://madeyski.e-informatyka.pl/download/JureczkoMadeyski15.pdf)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Madeyski15EISEJ.StudProjects
</code></pre>


<h3>Format</h3>

<p>A data frame with variables:
</p>

<dl>
<dt>PROP</dt><dd><p>The percentage of classes of proprietary (i.e., industrial) projects that must be tested in order to find 80% of defects in case of software defect prediction models built on student (i.e., academic) projects.</p>
</dd>
<dt>NOTSTUD</dt><dd><p>The percentage of classes of projects which are not student projects that must be tested in order to find 80% of defects in case of software defect prediction models built on student (i.e., academic) projects.</p>
</dd>
<dt>STUD</dt><dd><p>The percentage of classes of student (i.e., academic) projects that must be tested in order to find 80% of defects in case of software defect prediction models built on student (i.e., academic) projects.</p>
</dd>
<dt>OPEN</dt><dd><p>The percentage of classes of open source projects that must be tested in order to find 80% of defects in case of software defect prediction models built on student (i.e., academic) projects.</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://madeyski.e-informatyka.pl/reproducible-research/">https://madeyski.e-informatyka.pl/reproducible-research/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Madeyski15EISEJ.StudProjects

</code></pre>

<hr>
<h2 id='Madeyski15SQJ.NDC'>Madeyski15SQJ.NDC data</h2><span id='topic+Madeyski15SQJ.NDC'></span>

<h3>Description</h3>

<p>If you use this data set please cite: Lech Madeyski and Marian Jureczko, 'Which Process Metrics Can Significantly Improve Defect Prediction Models? An Empirical Study,' Software Quality Journal, vol. 23, no. 3, pp.393-422, 2015. DOI: 10.1007/s11219-014-9241-7
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Madeyski15SQJ.NDC
</code></pre>


<h3>Format</h3>

<p>A data frame with variables:
</p>

<dl>
<dt>Project</dt><dd><p>In case of open source projects this field includes the name of the project as well as its version. In case of industrial projects this field includes the string 'proprietary' (we were not allowed to disclose the names of the analyzed industrial software projects developed by Capgemini Polska).</p>
</dd>
<dt>simple</dt><dd><p>The percentage of classes that must be tested in order to find 80% of defects in case of simple defect prediction models, i.e., using only software product metrics as predictors.</p>
</dd>
<dt>advanced</dt><dd><p>The percentage of classes that must be tested in order to find 80% of defects in case of advanced defect prediction models, using not only software product metrics but also the NDC (Number of distinct committers) process metric.</p>
</dd>
</dl>



<h3>Details</h3>

<p>'This paper presents an empirical evaluation in which several process metrics were investigated in order to identify the ones which significantly improve the defect prediction models based on product metrics. Data from a wide range of software projects (both, industrial and open source) were collected. The predictions of the models that use only product metrics (simple models) were compared with the predictions of the models which used product metrics, as well as one of the process metrics under scrutiny (advanced models). To decide whether the improvements were significant or not, statistical tests were performed and effect sizes were calculated. The advanced defect prediction models trained on a data set containing product metrics and additionally Number of Distinct Committers (NDC) were significantly better than the simple models without NDC, while the effect size was medium and the probability of superiority (PS) of the advanced models over simple ones was high (p=.016, r=-.29, PS=.76), which is a substantial finding useful in defect prediction. A similar result with slightly smaller PS was achieved by the advanced models trained on a data set containing product metrics and additionally all of the investigated process metrics (p=.038, r=-.29, PS=.68). The advanced models trained on a data set containing product metrics and additionally Number of Modified Lines (NML) were significantly better than the simple models without NML, but the effect size was small (p=.038, r=.06). Hence, it is reasonable to recommend the NDC process metric in building the defect prediction models.' [https://dx.doi.org/10.1007/s11219-014-9241-7]
</p>


<h3>Source</h3>

<p><a href="https://madeyski.e-informatyka.pl/reproducible-research/">https://madeyski.e-informatyka.pl/reproducible-research/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Madeyski15SQJ.NDC

</code></pre>

<hr>
<h2 id='MadeyskiKitchenham.EUBASdata'>MadeyskiKitchenham.EUBASdata data</h2><span id='topic+MadeyskiKitchenham.EUBASdata'></span>

<h3>Description</h3>

<p>If you use this data set please cite this R package and the paper where we analyze the data set: Lech Madeyski and Barbara Kitchenham, 'Effect Sizes and their Variance for AB/BA Crossover Design Studies', Empirical Software Engineering, vol. 24, no.4, p. 1982-2017, 2018. DOI: 10.1007/s10664-017-9574-5
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MadeyskiKitchenham.EUBASdata
</code></pre>


<h3>Format</h3>

<p>A data frame with variables:
</p>

<dl>
<dt>ID</dt><dd><p>Project ID</p>
</dd>
<dt>TimePeriod</dt><dd><p>Period of time (run): R1, R2</p>
</dd>
<dt>SequenceGroup</dt><dd><p>Sequence group: G1, G2, G3, G4</p>
</dd>
<dt>System</dt><dd><p>Software system identifier indicates the system (i.e., S1 or S2) used as the experimental object: S1. A software system to sell and manage CDs/DVDs in a music shop, S2. A software system to book and buy theater tickets</p>
</dd>
<dt>Technique</dt><dd><p>The independent variable. It is a nominal variable that can assume the following two values: AM (analysis models plus source code) and SC (source code alone)</p>
</dd>
<dt>Comp_Level</dt><dd><p>This denotes the comprehension level of the source code achieved by a software engineer</p>
</dd>
<dt>Modi_Level</dt><dd><p>This denotes the capability of a maintainer to modify source code</p>
</dd>
</dl>



<h3>Details</h3>

<p>Data set comes from an experiment conducted in Italy at the University of Basilicata (with 24 first-year students from the Master's Program in Computer Science) to answer the question 'Do the software models produced in the requirements analysis process aid in the comprehensibility and modifiability of source code?', see G. Scanniello, C. Gravino, M. Genero, J. A. Cruz-Lemus, and G. Tortora, 'On the Impact of UML Analysis Models on Source-code Comprehensibility and Modifiability,' ACM Transactions on Software Engineering and Methodology, vol. 23, pp. 13:1-13:26, Apr. 2014. However, the inconsistent subject data for subject 2 was removed, see the aforementioned paper by Madeyski and Kitchenham.
</p>


<h3>Source</h3>

<p><a href="https://madeyski.e-informatyka.pl/reproducible-research/">https://madeyski.e-informatyka.pl/reproducible-research/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>MadeyskiKitchenham.EUBASdata

</code></pre>

<hr>
<h2 id='MadeyskiKitchenham.MetaAnalysis.PBRvsCBRorAR'>MadeyskiKitchenham.MetaAnalysis.PBRvsCBRorAR data</h2><span id='topic+MadeyskiKitchenham.MetaAnalysis.PBRvsCBRorAR'></span>

<h3>Description</h3>

<p>Data form a set of primary studies on reading methods for software inspections. They were analysed by Lech Madeyski and Barbara Kitchenham, 'How variations in experimental designs impact the construction of comparable effect sizes for meta-analysis', 2015.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MadeyskiKitchenham.MetaAnalysis.PBRvsCBRorAR
</code></pre>


<h3>Format</h3>

<p>A data frame with 17 rows and 26 variables:
</p>

<dl>
<dt>Study</dt><dd><p>Name of empirical study</p>
</dd>
<dt>Ref.</dt><dd><p>Reference to the paper reporting primary study or experimental run where data were originally reported</p>
</dd>
<dt>Teams</dt><dd><p>The number of teams including both, PBR and Control teams</p>
</dd>
<dt>DesignDesc</dt><dd><p>Experimental design description: Before-after, Between-groups, Cross-over</p>
</dd>
<dt>ExpDesign</dt><dd><p>Experimental design: between-groups (BG), within-subjects cross-over (WSCO), within-subjects before-after (WSBA)</p>
</dd>
<dt>M_PBR</dt><dd><p>The average proportion of defects found by teams using PBR</p>
</dd>
<dt>M_C</dt><dd><p>The average proportion of defects found by teams using Control treatment: Check-Based Reading (CBR) or Ad-Hoc Reading (AR)</p>
</dd>
<dt>Diff</dt><dd><p>The difference between M_PBR and M_C, i.e. Diff = M_PBR - M_C</p>
</dd>
<dt>Inc</dt><dd><p>The percentage increase in defect rate detection, i.e. Inc=100*[(M_PBR-M_C)/M_C]</p>
</dd>
<dt>SD_C_ByAuthors</dt><dd><p>The standard deviation of the control group values reported by the original Authors, i.e., obtained from the papers/raw data</p>
</dd>
<dt>SD_C</dt><dd><p>The standard deviation of the control group values equals SD_C_ByAuthors for studies for which the data was available OR the weighted average of SD_C_ByAuthors (i.e., 0.169) for studies where SD_C_ByAuthors is missing.</p>
</dd>
<dt>V_C</dt><dd><p>The variance of the Control group observations, i.e., the variance obtained from the teams using the Control method V_C=SD_C^2</p>
</dd>
<dt>V_D</dt><dd><p>The variance of the unstandardized mean difference D (between the mean value for the treatment group and the mean value for the Control group)</p>
</dd>
<dt>SD_C_Alt</dt><dd><p>This is the equivalent of SD_C (the standard deviation of the control group) based on a different variance for the student studies or the practitioner studies depending on the subject type of the study with the missing value.</p>
</dd>
<dt>V_Alt</dt><dd><p>The variance of the mean difference in the meta-analysis based on SD_C_Alt</p>
</dd>
<dt>SS_C</dt><dd><p>The sum of squares of the Control group values. For within subjects studies SS=V_C*(n-1). For between subjects studies SS=V_C*(n_C-1)</p>
</dd>
<dt>n_PBR</dt><dd><p>The number of PBR teams</p>
</dd>
<dt>n_C</dt><dd><p>The number of Control (CBR or AR) teams</p>
</dd>
<dt>ControlType</dt><dd><p>Type of Control treatment: CRB or AR</p>
</dd>
<dt>ParticipantsType</dt><dd><p>Type of participants: Engineers or Students</p>
</dd>
<dt>TeamType</dt><dd><p>Type of team: Nominal or Real</p>
</dd>
<dt>TwoPersonTeamVsLargerTeam</dt><dd><p>Reflects size of the teams: 2-PersonTeam or LargerTeam</p>
</dd>
<dt>ArtefactType</dt><dd><p>The type of artefact: Requirements or Other</p>
</dd>
<dt>AssociatedWithBasili</dt><dd><p>Whether study is associated with Basili (the forerunner): Yes or No</p>
</dd>
<dt>ControlType_Basili</dt><dd><p>Combined ControlType and AssociatedWithBasili: AH_AssociatedWithBasili, CBR_AssociatedWithBasili, CBR_NotAssociatedWithBasili</p>
</dd>
</dl>



<h3>Details</h3>

<p>If you use this data set please cite: Lech Madeyski and Barbara Kitchenham, 'How variations in experimental designs impact the construction of comparable effect sizes for meta-analysis', 2015.
</p>


<h3>Source</h3>

<p><a href="https://madeyski.e-informatyka.pl/reproducible-research/">https://madeyski.e-informatyka.pl/reproducible-research/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>MadeyskiKitchenham.MetaAnalysis.PBRvsCBRorAR

</code></pre>

<hr>
<h2 id='MadeyskiLewowski.IndustryRelevantGitHubJavaProjects20190324'>MadeyskiLewowski.IndustryRelevantGitHubJavaProjects20190324 data</h2><span id='topic+MadeyskiLewowski.IndustryRelevantGitHubJavaProjects20190324'></span>

<h3>Description</h3>

<p>This data is used in the paper:
Tomasz Lewowski and Lech Madeyski, 'Creating Evolving Project Data Sets in Software Engineering', vol. 851 of Studies in Computational Intelligence, pp. 1–14. Cham: Springer, 2020. DOI: 10.1007/978-3-030-26574-8_1
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MadeyskiLewowski.IndustryRelevantGitHubJavaProjects20190324
</code></pre>


<h3>Format</h3>

<p>A text file with variables:
</p>

<dl>
<dt>rowID</dt><dd><p>unique id assigned to projects before filtering (source: API)</p>
</dd>
<dt>id</dt><dd><p>GitHub repository ID (source: API)</p>
</dd>
<dt>repository owner</dt><dd><p>the organization or user owning the repository (source: API)</p>
</dd>
<dt>project name</dt><dd><p>name of the project (source: API)</p>
</dd>
<dt>manual</dt><dd><p>link to best found project documentation - wiki, webpage, documentation directory or readme. Projects with limited documentation were marked with (limited) and ones that had documentation in Chinese - (Chinese) (source: manual)</p>
</dd>
<dt>installation</dt><dd><p>the recommended installation medium(s) for the project. Some mediums may be missing for projects with multiple recommendations. (source: manual)</p>
</dd>
<dt>support</dt><dd><p>channel(s) that can be used to get support and/or report bugs. Some channels may be missing for projects with multiple ones. Abbreviations used (source: manual):
GH GitHub Issues
SO Stack Overflow
GG Google Groups
ML Mailing list
FB Facebook
MM Mattermost
LI LinkedIn
?  not found</p>
</dd>
<dt>is not sample/playground/docs/...</dt><dd><p>1 if the project is an actual application or library, 0 if it is a set of samples, only documentation or some experimental area (source: manual)</p>
</dd>
<dt>is industrial</dt><dd><p>whether the project can be treated as industrial quality one. Values and their meanings:
1   the repository can be classified as industrial grade;
0,5 the repository can sometimes be classified as industrial grade, but it is either a minor project or its documentation or support may be lacking the depth;
0   the repository cannot be classified as industrial-grade;
-1  the repository is no longer actively maintained as of the date of data acquisition;
-2  the repository is no longer in Java as of the date of data acquisition. (source: manual)</p>
</dd>
<dt>createdAt</dt><dd><p>the date at which the repository was created (source: API)</p>
</dd>
<dt>updatedAt</dt><dd><p>the date of last repository update - including changes in projects, watchers, issues etc. (source: API)</p>
</dd>
<dt>pushedAt</dt><dd><p>the date of last push to the repository - NOT the date of last pushed commit (source: API)</p>
</dd>
<dt>diskUsage</dt><dd><p>total number of bytes on disk that are needed to store the repository (source: API)</p>
</dd>
<dt>forkCount</dt><dd><p>number of existing repository forks (independent copies managed by other entities) (source: API)</p>
</dd>
<dt>isArchived</dt><dd><p>true if the repository is archived (no longer maintained), false otherwise (source: API)</p>
</dd>
<dt>isFork</dt><dd><p>true if the repository is a fork (not the main repository), false otherwise (source: API)</p>
</dd>
<dt>isMirror</dt><dd><p>true if the repository is a mirror, false otherwise (source: API)</p>
</dd>
<dt>sshUrlOfRepository</dt><dd><p>URL that can be used to immediately clone the repository (source: API)</p>
</dd>
<dt>licenseInfo.name</dt><dd><p>name of license under which the project is distributed. Names are the same as in https://choosealicense.com/appendix/ (source: API)</p>
</dd>
<dt>commitSHA</dt><dd><p>unique Git identifier of commit that was top of the main branch at the time of data acquisition (source: API)</p>
</dd>
<dt>defaultBranchRef.target.history.totalCount</dt><dd><p>number of commits on the default branch in the repository (usually master) at the time of data acquisition (source: API)</p>
</dd>
<dt>stargazers.totalCount</dt><dd><p>number of stargazers for the repository at the time of data acquisition (source: API)</p>
</dd>
<dt>watchers.totalCount</dt><dd><p>number of watchers for the repository at the time of data acquisition (source: API)</p>
</dd>
<dt>languages.totalSize</dt><dd><p>total size of all source code files (source: API)</p>
</dd>
<dt>Java.byte.count</dt><dd><p>total size of Java files (source: API)</p>
</dd>
<dt>Language</dt><dd><p>main programming language used in the repository, i.e. one that the most code is written in (source: API)</p>
</dd>
<dt>searchQuery</dt><dd><p>query used during search that obtained this project (source: API)</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://madeyski.e-informatyka.pl/reproducible-research/">https://madeyski.e-informatyka.pl/reproducible-research/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>MadeyskiLewowski.IndustryRelevantGitHubJavaProjects20190324

</code></pre>

<hr>
<h2 id='MadeyskiLewowski.IndustryRelevantGitHubJavaProjects20191022'>MadeyskiLewowski.IndustryRelevantGitHubJavaProjects20191022 data</h2><span id='topic+MadeyskiLewowski.IndustryRelevantGitHubJavaProjects20191022'></span>

<h3>Description</h3>

<p>This data is used in the paper: Tomasz Lewowski and Lech Madeyski, 'How do software engineering data sets evolve? A reproduction study', 2020 (submitted).
Generated by:
token &lt;- '...'
MadeyskiLewowski.IndustryRelevantGitHubJavaProjects20191022&lt;-searchForIndustryRelevantGitHubProjects(token, '2019-03-01', '2018-08-01')
usethis::use_data(MadeyskiLewowski.IndustryRelevantGitHubJavaProjects20191022)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MadeyskiLewowski.IndustryRelevantGitHubJavaProjects20191022
</code></pre>


<h3>Format</h3>

<p>A text file with variables:
</p>

<dl>
<dt>rowID</dt><dd><p>unique id assigned to projects before filtering (source: API)</p>
</dd>
<dt>id</dt><dd><p>GitHub repository ID (source: API)</p>
</dd>
<dt>repository owner</dt><dd><p>the organization or user owning the repository (source: API)</p>
</dd>
<dt>project name</dt><dd><p>name of the project (source: API)</p>
</dd>
<dt>manual</dt><dd><p>link to best found project documentation - wiki, webpage, documentation directory or readme. Projects with limited documentation were marked with (limited) and ones that had documentation in Chinese - (Chinese) (source: manual)</p>
</dd>
<dt>installation</dt><dd><p>the recommended installation medium(s) for the project. Some mediums may be missing for projects with multiple recommendations. (source: manual)</p>
</dd>
<dt>support</dt><dd><p>channel(s) that can be used to get support and/or report bugs. Some channels may be missing for projects with multiple ones. Abbreviations used (source: manual):
GH GitHub Issues
SO Stack Overflow
GG Google Groups
ML Mailing list
FB Facebook
MM Mattermost
LI LinkedIn
?  not found</p>
</dd>
<dt>is not sample/playground/docs/...</dt><dd><p>1 if the project is an actual application or library, 0 if it is a set of samples, only documentation or some experimental area (source: manual)</p>
</dd>
<dt>is industrial</dt><dd><p>whether the project can be treated as industrial quality one. Values and their meanings:
1   the repository can be classified as industrial grade;
0,5 the repository can sometimes be classified as industrial grade, but it is either a minor project or its documentation or support may be lacking the depth;
0   the repository cannot be classified as industrial-grade;
-1  the repository is no longer actively maintained as of the date of data acquisition;
-2  the repository is no longer in Java as of the date of data acquisition. (source: manual)</p>
</dd>
<dt>createdAt</dt><dd><p>the date at which the repository was created (source: API)</p>
</dd>
<dt>updatedAt</dt><dd><p>the date of last repository update - including changes in projects, watchers, issues etc. (source: API)</p>
</dd>
<dt>pushedAt</dt><dd><p>the date of last push to the repository - NOT the date of last pushed commit (source: API)</p>
</dd>
<dt>diskUsage</dt><dd><p>total number of bytes on disk that are needed to store the repository (source: API)</p>
</dd>
<dt>forkCount</dt><dd><p>number of existing repository forks (independent copies managed by other entities) (source: API)</p>
</dd>
<dt>isArchived</dt><dd><p>true if the repository is archived (no longer maintained), false otherwise (source: API)</p>
</dd>
<dt>isFork</dt><dd><p>true if the repository is a fork (not the main repository), false otherwise (source: API)</p>
</dd>
<dt>isMirror</dt><dd><p>true if the repository is a mirror, false otherwise (source: API)</p>
</dd>
<dt>sshUrlOfRepository</dt><dd><p>URL that can be used to immediately clone the repository (source: API)</p>
</dd>
<dt>licenseInfo.name</dt><dd><p>name of license under which the project is distributed. Names are the same as in https://choosealicense.com/appendix/ (source: API)</p>
</dd>
<dt>commitSHA</dt><dd><p>unique Git identifier of commit that was top of the main branch at the time of data acquisition (source: API)</p>
</dd>
<dt>defaultBranchRef.target.history.totalCount</dt><dd><p>number of commits on the default branch in the repository (usually master) at the time of data acquisition (source: API)</p>
</dd>
<dt>stargazers.totalCount</dt><dd><p>number of stargazers for the repository at the time of data acquisition (source: API)</p>
</dd>
<dt>watchers.totalCount</dt><dd><p>number of watchers for the repository at the time of data acquisition (source: API)</p>
</dd>
<dt>languages.totalSize</dt><dd><p>total size of all source code files (source: API)</p>
</dd>
<dt>Java.byte.count</dt><dd><p>total size of Java files (source: API)</p>
</dd>
<dt>Language</dt><dd><p>main programming language used in the repository, i.e. one that the most code is written in (source: API)</p>
</dd>
<dt>searchQuery</dt><dd><p>query used during search that obtained this project (source: API)</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://madeyski.e-informatyka.pl/reproducible-research/">https://madeyski.e-informatyka.pl/reproducible-research/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>MadeyskiLewowski.IndustryRelevantGitHubJavaProjects20191022

</code></pre>

<hr>
<h2 id='metaanalyse.Cliffd'>metaanalyse.Cliffd</h2><span id='topic+metaanalyse.Cliffd'></span>

<h3>Description</h3>

<p>This function provides a simple meta-analysis of experiments using Cliff's d as an effect size. It returns the 100*(1-alpha/2)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metaanalyse.Cliffd(
  Cliffd,
  Cliffdvar,
  df = 0,
  alternative = "two.sided",
  alpha = 0.05
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="metaanalyse.Cliffd_+3A_cliffd">Cliffd</code></td>
<td>
<p>A vector of one or more numerical values, identifying the effect sizes to be meta-analysed</p>
</td></tr>
<tr><td><code id="metaanalyse.Cliffd_+3A_cliffdvar">Cliffdvar</code></td>
<td>
<p>A vector of the estimates variance of each of the effect sizes</p>
</td></tr>
<tr><td><code id="metaanalyse.Cliffd_+3A_df">df</code></td>
<td>
<p>The total degrees of freedom for the set of effect sizes. If df&gt;0, the pvalues and significance test use the t-distribution probability values. If df=0 (default) the pvalues and significance test use the normal distribution probability values. The confidence intervals are always based on the normal probability values, as recommended by Cliff.</p>
</td></tr>
<tr><td><code id="metaanalyse.Cliffd_+3A_alternative">alternative</code></td>
<td>
<p>Specifies the type of significance test and can take the values &quot;two.sided&quot; (default), &quot;less&quot; or &quot;greater&quot;.</p>
</td></tr>
<tr><td><code id="metaanalyse.Cliffd_+3A_alpha">alpha</code></td>
<td>
<p>The significance level used to control the significance tests and calculation of confidence limits (default 0.05).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Estimate The overall estimate of Cliff's d obtained from the set of experiments
</p>
<p>UpperCI The upper 100*(1-alpha/2)
</p>
<p>LowerCI The lower 100*(1-alpha/2)
</p>
<p>The variance of the Estimate
</p>
<p>tvalue The value of the t-statistic
</p>
<p>df The supplied degrees of freedom or NA if the input parameter df was set to zero
</p>
<p>AltHyp Defines the alternative hypothesis used for significance testing and depends on the value of the input parameter alternative. It takes the values &quot;Not=0&quot;, &quot;&gt;0&quot;, or &quot;&lt;0&quot;
</p>
<p>NullHyp Defines the null hypothesis and depends on the value of the input parameter alternative. It takes the values &quot;~0&quot;, &quot;&lt;0&quot;, or &quot;&gt;0&quot;
</p>
<p>pvalue The p-value of the t-test if the parameter df&gt;0, or the normal probability value if d=0
</p>
<p>RejectNullHyp &quot;Yes&quot; or &quot;No&quot; depending on whether or not the null hypothesis should be rejected at the alpha/2 level for two-sided tests and alpha level for one-sided tests
</p>
<p>The Q homogeneity statistic
</p>
<p>The I-squared estimate of the extent of heterogeneity
</p>
<p>ProbQHomogeneous. The probability that the set of Cliff's d values come from a set of homogeneous experiments.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Cliffd=c(0.84,0.2,-0.04,0.44,0.76)
CliffdvarInvalid=c(0.04,0.18,0.21,0.15)
Cliffdvar=c(0.04,0.18,0.21,0.15,0.06)
CliffdvarInvalid=c(0.04,0.18,0.21,0.15)
df=45
as.data.frame(metaanalyse.Cliffd(Cliffd=Cliffd,Cliffdvar=Cliffdvar,df=df,alternative="greater",
 alpha=0.05))
#  Estimate   UpperCI   LowerCI Variance tvalue df AltHyp NullHyp      pvalue
#1     0.44 0.6601381 0.1502568   0.0256   2.75 45     &gt;0     &lt;=0 0.004275955
#  RejectNullHyp    Q I.square ProbQHomogeneous
#1           Yes 21.5 81.39535     0.0002519835
as.data.frame(metaanalyse.Cliffd(Cliffd=Cliffd,Cliffdvar=Cliffdvar,df=df,alternative="less",
 alpha=0.05))
#  Estimate   UpperCI   LowerCI Variance tvalue df AltHyp NullHyp   pvalue RejectNullHyp
#1     0.44 0.6601381 0.1502568   0.0256   2.75 45     &lt;0     &gt;=0 0.995724            No
#     Q I.square ProbQHomogeneous
#1 21.5 81.39535     0.0002519835
as.data.frame(metaanalyse.Cliffd(Cliffd=Cliffd,Cliffdvar=Cliffdvar,df=df,alternative="two.sided",
 alpha=0.05))
#  Estimate  UpperCI    LowerCI Variance tvalue df AltHyp NullHyp      pvalue
#1     0.44 0.692073 0.09227496   0.0256   2.75 45  Not=0      ~0 0.008551911
#  RejectNullHyp    Q I.square ProbQHomogeneous
#1           Yes 21.5 81.39535     0.0002519835
as.data.frame(metaanalyse.Cliffd(Cliffd=Cliffd,Cliffdvar=Cliffdvar,df=df,alpha=0.05))
#  Estimate  UpperCI    LowerCI Variance tvalue df AltHyp NullHyp      pvalue
#1     0.44 0.692073 0.09227496   0.0256   2.75 45  Not=0      ~0 0.008551911
#  RejectNullHyp    Q I.square ProbQHomogeneous
#1           Yes 21.5 81.39535     0.0002519835
metaanalyse.Cliffd(Cliffd=Cliffd,Cliffdvar=Cliffdvar,df=0,alternative="two.sided",alpha=0.05)
#Error in testfunctionParameterChecks(alternative = alternative, alpha = alpha,  :
#  Invalid alternative parameter, choose one of two.sided, greater or less
# metaanalyse.Cliffd(Cliffd=Cliffd,Cliffdvar=CliffdvarInvalid,df=df,alternative="greater",
# alpha=0.05)
#Error in metaanalyse.Cliffd(Cliffd = Cliffd, Cliffdvar = CliffdvarInvalid,  :
#  Length of Cliffdvar parameter must equal the length of the Cliffd parameter
</code></pre>

<hr>
<h2 id='metaanalyse.PHat'>metaanalyse.PHat</h2><span id='topic+metaanalyse.PHat'></span>

<h3>Description</h3>

<p>This function performs a meta-analysis of experiments using PHat as an effect size. It returns the 100*(1-alpha/2)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metaanalyse.PHat(
  PHat,
  PHatvar,
  DFUnknown,
  df,
  alternative = "two.sided",
  alpha = 0.05
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="metaanalyse.PHat_+3A_phat">PHat</code></td>
<td>
<p>The estimates of PHat obtained from a group of experiments to be meta-analysed</p>
</td></tr>
<tr><td><code id="metaanalyse.PHat_+3A_phatvar">PHatvar</code></td>
<td>
<p>The estimate of the variance of each PHat estimate</p>
</td></tr>
<tr><td><code id="metaanalyse.PHat_+3A_dfunknown">DFUnknown</code></td>
<td>
<p>If DFUnknown=FALSE the degrees of freedom for each experiment is known, and the df parameter must be a vector specifying the effect size of each experiment, otherwise the df parameter is ignored.</p>
</td></tr>
<tr><td><code id="metaanalyse.PHat_+3A_df">df</code></td>
<td>
<p>If DFUnknown is TRUE, this parameter is a vector of numerical values specifying the degrees of freedom for each experiment, and the confidence intervals, pvalues and significance test use the t-distribution probability values. If the parameter DFUNknown is FALSE, the confidence intervals, pvalues and significance test use the normal distribution probability values.</p>
</td></tr>
<tr><td><code id="metaanalyse.PHat_+3A_alternative">alternative</code></td>
<td>
<p>Specifies the type of significance test and can take the values &quot;two.sided&quot; (default), &quot;less&quot; or &quot;greater&quot;.</p>
</td></tr>
<tr><td><code id="metaanalyse.PHat_+3A_alpha">alpha</code></td>
<td>
<p>The significance level (default 0.05) used to control the significance tests and calculation of confidence limits.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Estimate. The simple average of the PHat values recommended by Kromrey as the best estimator for meta-analysis.
</p>
<p>UpperCI The upper 100*(1-alpha/2)
</p>
<p>LowerCI The lower 100*(1-alpha/2)
</p>
<p>Variance The variance of the Estimate output
</p>
<p>tvalue The value of the t-statistic
</p>
<p>df Either NA if the parameter DFUnknown is TRUE, or sum of the degrees of freedom for each experiment.
</p>
<p>AltHyp Defines the alternative hypothesis used for significance testing and depends on the value of the input parameter alternative. It takes the values &quot;Not=0.5&quot;, &quot;&gt;0.5&quot;, or &quot;&lt;0.5&quot;.
</p>
<p>NullHyp Defines the null hypothesis and depends on the value of the input parameter alternative. It takes the values &quot;~0.5&quot;, &quot;&lt;0.5&quot;, or &quot;&gt;0.5&quot;.
</p>
<p>pvalue The p-value of the t-test if the parameter DFUnknown is FALSE, otherwise the normal probability value.
</p>
<p>RejectNullHyp &quot;Yes&quot; or &quot;No&quot; depending on whether or not the null hypothesis should be rejected at the alpha/2 level for two-sided tests and alpha level for one-sided tests
</p>
<p>The I-squared estimate of the extent of heterogeneity
</p>
<p>The Q homogeneity statistic
</p>
<p>ProbQHomogeneous. The probability that the set of Phat values come from a set of homogeneous experiments.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>PHat=c(0.92,0.6,0.48,0.72,0.88)
PHatvar=c(0.01,0.04,0.05,0.04,0.01)
PHatdf=c(6.63,6.63,5.08,5.61,8)
PHatInvalid=c(0.92,0.6,0.48,0.72)
as.data.frame(metaanalyse.PHat(PHat=PHat,PHatvar=PHatvar,DFUnknown=FALSE,df=PHatdf,
 alternative="greater",alpha=0.05))
#  Estimate   UpperCI   LowerCI Variance   tvalue    df AltHyp NullHyp      pvalue RejectNullHyp..
#  1     0.72 0.8777899 0.5622101    0.006 2.840188 31.95   &gt;0.5   &lt;=0.5 0.003890609         Yes..
as.data.frame(metaanalyse.PHat(PHat=PHat,PHatvar=PHatvar,DFUnknown=TRUE,df=PHatdf,
  alternative="greater",alpha=0.05))
#  Estimate   UpperCI   LowerCI Variance   tvalue df AltHyp NullHyp      pvalue RejectNullHyp..
# 1     0.72 0.8718182 0.5681818    0.006 2.840188 NA   &gt;0.5   &lt;=0.5 0.002254349           Yes..
as.data.frame(metaanalyse.PHat(PHat=PHat,PHatvar=PHatvar,DFUnknown=FALSE,df=PHatdf,
 alternative="two.sided",alpha=0.05))
#  Estimate   UpperCI   LowerCI Variance   tvalue    df  AltHyp NullHyp      pvalue RejectNullH..
#1     0.72 0.8777899 0.5622101    0.006 2.840188 31.95 Not=0.5    ~0.5 0.007781218         Yes..
as.data.frame(metaanalyse.PHat(PHat=PHat,PHatvar=PHatvar,DFUnknown=TRUE,df=PHatInvalid,
 alpha=0.05))
# Estimate   UpperCI   LowerCI Variance   tvalue df  AltHyp NullHyp      pvalue RejectNullHyp I..
#1     0.72 0.8718182 0.5681818    0.006 2.840188 NA Not=0.5    ~0.5 0.004508698         Yes 82..
</code></pre>

<hr>
<h2 id='metaanalyseSmallSampleSizeExperiments'>metaanalyseSmallSampleSizeExperiments</h2><span id='topic+metaanalyseSmallSampleSizeExperiments'></span>

<h3>Description</h3>

<p>Implements analysis of small sample size experiments based on Hedges and Olkin p128-131.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metaanalyseSmallSampleSizeExperiments(d, f, A)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="metaanalyseSmallSampleSizeExperiments_+3A_d">d</code></td>
<td>
<p>a vector of standardized mean differences for different experiments (not adjusted for small sample size)</p>
</td></tr>
<tr><td><code id="metaanalyseSmallSampleSizeExperiments_+3A_f">f</code></td>
<td>
<p>a vector defining the degrees  for each experiment</p>
</td></tr>
<tr><td><code id="metaanalyseSmallSampleSizeExperiments_+3A_a">A</code></td>
<td>
<p>a vector defining the relationship between d and its related t value for each experiment</p>
</td></tr>
</table>


<h3>Value</h3>

<p>UnweightedMean The unweighted mean of the small size adjusted standardized mean differences
</p>
<p>WeightedMean The weighted mean of the small size adjusted standardized mean differences
</p>
<p>VarWeightedMean The variance of the weighted mean
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d=c(.461,.782,.513,.612,-0.131,-0.018,0.774,0.138,-0.482,0.333,.701,-0.222,
  .399,.538,-0.19,0.833,0.512,0.601,-0.366,.510)
A=c(2/5,2/5,2/7,2/10,2/8,2/10,2/6,2/6,2/4,2/9,2/9,2/7,2/7,2/5,2/5,2/4,2/10,2/8,2/4,2/8)
f=c(8,8,12,18,14,18,10,10,6,16,16,12,12,8,8,6,18,14,6,14)
metaanalyseSmallSampleSizeExperiments(d,f,A)
</code></pre>

<hr>
<h2 id='MetaAnalysisSimulations'>MetaAnalysisSimulations</h2><span id='topic+MetaAnalysisSimulations'></span>

<h3>Description</h3>

<p>This function simulates data from many families of experiments. The number of families simulated is defined by the Replications parameter. The parameter Exp determines the number of experiments in each family. The function simulates data from one of four distributions and uses the data to construct two of groups of equal size (GroupSize). The experimental design of individual experiments in each family is determined by the FourGroup parameter. If FourGroup=FALSE, the basic experimental design is a balanced two group randomized experiment, otherwise the experimental design is a balanced four group experiment corresponding to a randomized blocks experiment. The function calls either NP2GMetaAnalysisSimulation or NP2GMetaAnalysisSimulation to generate and analyse data for each individual family. The function either returns the meta-analysed data from each experiment or provides summary statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MetaAnalysisSimulations(
  mean = 0,
  sd = 1,
  diff = 0.5,
  GroupSize = 10,
  type = "n",
  Replications = 50,
  Exp = 5,
  seed = 456,
  alpha = 0.05,
  FourGroup = FALSE,
  StdAdj = 0,
  BlockEffect = 0,
  BlockStdAdj = 0,
  StdExp = 0,
  MAMethod = "PM",
  returnES = FALSE,
  AlwaysTwoSidedTests = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MetaAnalysisSimulations_+3A_mean">mean</code></td>
<td>
<p>the value used for the mean of control group in the simulated data. It can be any real number including zero.</p>
</td></tr>
<tr><td><code id="MetaAnalysisSimulations_+3A_sd">sd</code></td>
<td>
<p>the value used for the spread of the control group and the spread of the treatment group in the simulated data. The value must be a real value greater than 0.</p>
</td></tr>
<tr><td><code id="MetaAnalysisSimulations_+3A_diff">diff</code></td>
<td>
<p>mean+diff is the value used for the mean of the treatment group. It can be zero.</p>
</td></tr>
<tr><td><code id="MetaAnalysisSimulations_+3A_groupsize">GroupSize</code></td>
<td>
<p>is the size of each of the groups comprising one experiment. Groupsize should be an integer of 4 or more</p>
</td></tr>
<tr><td><code id="MetaAnalysisSimulations_+3A_type">type</code></td>
<td>
<p>specifies the distribution being simulated. The permitted values
are 'n' for the normal distribution (default), 'l' for the lognormal
distribution, 'g' for the gamma distribution and 'lap' for the Laplace
distribution.</p>
</td></tr>
<tr><td><code id="MetaAnalysisSimulations_+3A_replications">Replications</code></td>
<td>
<p>The number of times the set of experiments is simulated.</p>
</td></tr>
<tr><td><code id="MetaAnalysisSimulations_+3A_exp">Exp</code></td>
<td>
<p>is the number of experiments in each family of experiments being
simulated. Exp should be an integer of 2 or more (default 5).</p>
</td></tr>
<tr><td><code id="MetaAnalysisSimulations_+3A_seed">seed</code></td>
<td>
<p>specifies the seed to be used to initiate the simulation, so the simulation is repeatable.</p>
</td></tr>
<tr><td><code id="MetaAnalysisSimulations_+3A_alpha">alpha</code></td>
<td>
<p>The significance level used for tests and confidence intervals
(default 0.05)</p>
</td></tr>
<tr><td><code id="MetaAnalysisSimulations_+3A_fourgroup">FourGroup</code></td>
<td>
<p>is a Boolean variable that determines whether the experiment
is a two group experiments or a 4-Group randomised block experiment. It
defaults to FALSE which means a two-group experiment is the default condition</p>
</td></tr>
<tr><td><code id="MetaAnalysisSimulations_+3A_stdadj">StdAdj</code></td>
<td>
<p>If non-zero that can be used to introduced variability into
the treatment spread/variance (default 0). Not appropriate for gamma data.</p>
</td></tr>
<tr><td><code id="MetaAnalysisSimulations_+3A_blockeffect">BlockEffect</code></td>
<td>
<p>A factor used to change the mean difference between
blocks (default 0.5)</p>
</td></tr>
<tr><td><code id="MetaAnalysisSimulations_+3A_blockstdadj">BlockStdAdj</code></td>
<td>
<p>if non-zero this can be used to change the BlockEffect
from a fixed to random effect (default 0).</p>
</td></tr>
<tr><td><code id="MetaAnalysisSimulations_+3A_stdexp">StdExp</code></td>
<td>
<p>if non-zero it simulates a random effect between experiments
in the same family (default 0).</p>
</td></tr>
<tr><td><code id="MetaAnalysisSimulations_+3A_mamethod">MAMethod</code></td>
<td>
<p>specifies the model to be used when experimental effect sizes ar aggregated using the R metafor package.</p>
</td></tr>
<tr><td><code id="MetaAnalysisSimulations_+3A_returnes">returnES</code></td>
<td>
<p>if TRUE the function outputs the summary statistics otherwise it outputs the meta-analysis results for each family (default FALSE)</p>
</td></tr>
<tr><td><code id="MetaAnalysisSimulations_+3A_alwaystwosidedtests">AlwaysTwoSidedTests</code></td>
<td>
<p>This parameter can be used to override the
one-sided tests used as default if the diff parameter is non-zero
(default FALSE). This should only be set to TRUE to check simulation
reported in other papers that seem to have used two-sided tests.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The parameter either returns the meta-analysis values obtained from
each family or the average values of the meta-analysis over all replications.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>as.data.frame(
  MetaAnalysisSimulations(
    mean=0, sd=1, diff=0.5, GroupSize=10, type='n', Replications=5, Exp=5,
    seed=456, alpha=0.05, FourGroup=FALSE, StdAdj=0, BlockEffect=0.5,
    BlockStdAdj=0,StdExp=0,MAMethod='PM',returnES=FALSE))
#  AverageCliffd AverageCliffdvar AverageCliffdsig Averagephat Averagephatvar
#1        0.3336        0.0132419              0.8      0.6668    0.003214756
#Averagephatsig  AveMDStd AveMDStdvar AveMDStdsig MAMean.phat  MAphat.var
#1          0.9 0.6176206  0.04278117         0.9    0.689908 0.003888047
#MAphat.sig MAMean.Cliffd MACliffd.var MACliffd.sig Mean.StdMDUnweighted
#1      0.9       0.37984   0.01575063          0.9            0.6449963
#StdMDUnweighted.var StdMDUnweighted.sig Mean.StdMDAdjUnweighted
#1        0.04299001                 0.9               0.6145034
#StdMDAdjUnweighted.var StdMDAdjUnweighted.sig Mean.HedgesMA Hedges.var
#1           0.04192908                    0.9     0.6150575 0.04455833
#Hedges.sig Mean.StdMDAdjMA.exact StdMDAdjMA.exact.var StdMDAdjMA.exact.sig
#1      0.9             0.5834754           0.05171067                  0.8
#Mean.StdMDAdjMA.approx StdMDAdjMA.approx.var StdMDAdjMA.approx.sig
#1              0.58643            0.04749064                   0.9
#Mean.StdMDMA.exact StdMDMA.exact.var StdMDMA.exact.sig Mean.StdMDMA.approx
#1        0.6134374        0.05711235               0.8           0.6165884
#StdMDMA.approx.var StdMDMA.approx.sig
#1       0.05242339                0.9
#as.data.frame(
 # MetaAnalysisSimulations(
 #   mean=0, sd=1, diff=0.5, GroupSize=10, type='n', Replications=50, Exp=5,
 #   seed=456, alpha=0.05, FourGroup=FALSE, StdAdj=0, BlockEffect=0.5,
 #   BlockStdAdj=0,StdExp=0,MAMethod='PM',returnES=FALSE))
# AverageCliffd AverageCliffdvar AverageCliffdsig Averagephat Averagephatvar
#1      0.29808       0.01333744             0.74     0.64904    0.003236444
# Averagephatsig  AveMDStd   AveMDStdvar AveMDStdsig MAMean.phat  MAphat.var
#           0.78 0.5450377    0.04217901        0.78   0.6677884 0.004538661
#  MAphat.sig MAMean.Cliffd MACliffd.var MACliffd.sig  Mean.StdMDUnweighted
#1       0.72     0.3356298   0.01833956         0.72             0.5686653
#  StdMDUnweighted.var StdMDUnweighted.sig Mean.StdMDAdjUnweighted
#1          0.04237386                0.82               0.5419554
#StdMDAdjUnweighted.var StdMDAdjUnweighted.sig Mean.HedgesMA Hedges.var
#            0.04138573                   0.78     0.5420552 0.04388383
#  Hedges.sig Mean.StdMDAdjMA.exact StdMDAdjMA.exact.var StdMDAdjMA.exact.sig
#1       0.76             0.5163304           0.05874152                 0.72
#Mean.StdMDAdjMA.approx StdMDAdjMA.approx.var StdMDAdjMA.approx.sig
#1            0.5203279            0.05591752                  0.74
# Mean.StdMDMA.exact StdMDMA.exact.var
#        0.5418705        0.06468786
# StdMDMA.exact.sig Mean.StdMDMA.approx StdMDMA.approx.var StdMDMA.approx.sig
#              0.72           0.5461255         0.06159257               0.74

#as.data.frame(
#   MetaAnalysisSimulations(
#     mean=0, sd=1, diff=0.5, GroupSize=10, type='n', Replications=50, Exp=5,
#     seed=456, alpha=0.05, FourGroup=TRUE, StdAdj=0, BlockEffect=0.5,
#     BlockStdAdj=0, StdExp=0, MAMethod='PM', returnES=FALSE))
#  AverageCliffd AverageCliffdvar AverageCliffdsig Averagephat ...
#1       0.27968       0.00683327             0.92     0.63984 ...
# as.data.frame(
#   MetaAnalysisSimulations(
#     mean=0, sd=1, diff=0.5, GroupSize=10, type='n', Replications=10, Exp=5,
#     seed=456, alpha=0.05, FourGroup=TRUE, StdAdj=0, BlockEffect=0.5,
#     BlockStdAdj=0, StdExp=0, MAMethod='PM', returnES=TRUE))
#Family NumExp GroupSize AveCliffd AveCliffdvar AveCliffdsig Avephat  ...
#     1      1         5        10        0.252  0.007423693    TRUE  ...
# Family NumExp GroupSize AveCliffd AveCliffdvar AveCliffdsig Avephat ...
#1     1      5        10     0.252  0.007423693         TRUE   0.626 ...
</code></pre>

<hr>
<h2 id='NP2GMetaAnalysisSimulation'>NP2GMetaAnalysisSimulation</h2><span id='topic+NP2GMetaAnalysisSimulation'></span>

<h3>Description</h3>

<p>This function simulates data from a family of experiments. The parameter Exp determines the number of experiments in the family. The function simulates data from one of four distributions and uses the data to construct two of groups of equal size (GroupSize). The distribution for one  of the groups corresponds to the control and is based on the given mean and spread, the distribution for the other group corresponds to the treatment group and  is based on the mean+diff and the spread plus any variance adjustment requested (determined by the parameter StdAdj). The data from each experiment is analysed separately to estimate three non-parametric effect sizes: the Cliff's d and the probability of superiority referred to as phat and their variances. Parametric effect sizes Cohen's d (also known as the standarized means difference, SMD) and the small sample size adjusted standardized mean difference g are also calculated together with their variances. The effect sizes are then meta-analysed using various methods: the simple average of the effect size and the variance weighted averages (using the exact and approximate normal variance and the weighted and unweighted standardized mean difference). The function uses the metafor package for formal meta-analysis, and the specific method of formal meta-analysis used is determined by the MAMethod. All tests of significance are done at the 0.05 level. If the parameter returnES is TRUE, the function returns the effect sizes for each experiment in the family, otherwise it returns the meta-analysis results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NP2GMetaAnalysisSimulation(
  mean,
  sd,
  diff,
  GroupSize,
  Exp = 5,
  type = "n",
  StdAdj = 0,
  alpha = 0.05,
  seed = 123,
  StdExp = 0,
  MAMethod,
  returnES = FALSE,
  AlwaysTwoSidedTests = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="NP2GMetaAnalysisSimulation_+3A_mean">mean</code></td>
<td>
<p>the value used for the mean of control group in the simulated data. It can be any real number including zero.</p>
</td></tr>
<tr><td><code id="NP2GMetaAnalysisSimulation_+3A_sd">sd</code></td>
<td>
<p>the value used for the spread of the control group and the spread of the treatment group in the simulated data. The value must be a real value greater than 0.</p>
</td></tr>
<tr><td><code id="NP2GMetaAnalysisSimulation_+3A_diff">diff</code></td>
<td>
<p>mean+diff is the value used for the mean of the treatment group. It can be zero.</p>
</td></tr>
<tr><td><code id="NP2GMetaAnalysisSimulation_+3A_groupsize">GroupSize</code></td>
<td>
<p>is the size of each of the 2 groups comprising one experiment. Groupsize should be an integer of 4 or more</p>
</td></tr>
<tr><td><code id="NP2GMetaAnalysisSimulation_+3A_exp">Exp</code></td>
<td>
<p>is the number of experiments being simulated. Exp should be an integer of 2 or more. It defaults to 5.</p>
</td></tr>
<tr><td><code id="NP2GMetaAnalysisSimulation_+3A_type">type</code></td>
<td>
<p>specifies the distribution being simulated. The permitted values are &quot;n&quot; for the normal distribution,  &quot;l&quot; for the lognormal distribution, &quot;g&quot; for the gamma distribution and &quot;lap&quot; for the Laplace distribution. The parameter defaults to &quot;n&quot;.</p>
</td></tr>
<tr><td><code id="NP2GMetaAnalysisSimulation_+3A_stdadj">StdAdj</code></td>
<td>
<p>specifies a level used to adjust the treatment variance. It allows heterogeneity to be modelled. It defaults to zero meaning no variance heterogeneity is introduced.</p>
</td></tr>
<tr><td><code id="NP2GMetaAnalysisSimulation_+3A_alpha">alpha</code></td>
<td>
<p>the Type 1 error rate level use for statistical tests.</p>
</td></tr>
<tr><td><code id="NP2GMetaAnalysisSimulation_+3A_seed">seed</code></td>
<td>
<p>specifies the seed to be used to initiate the simulation, so the simulation is repeatable. It defauls to 123.</p>
</td></tr>
<tr><td><code id="NP2GMetaAnalysisSimulation_+3A_stdexp">StdExp</code></td>
<td>
<p>defines whether any additional heterogeneity is introduced between families. The value (set to 0 or 0.5 for our simulations) is used when we generate a deviation to be added to the control mean (control rate for gamma data) for each family. The deviation is generated from a Normal distribution with mean 0 and standard deviation=0.5. If StdExp=0 we do not add any deviations to the mean.</p>
</td></tr>
<tr><td><code id="NP2GMetaAnalysisSimulation_+3A_mamethod">MAMethod</code></td>
<td>
<p>the meta-analysis method needed for the call to the metafor package rma algorithm</p>
</td></tr>
<tr><td><code id="NP2GMetaAnalysisSimulation_+3A_returnes">returnES</code></td>
<td>
<p>Determines the format of the output. It defaults to FALSE which causes the function to output the meta-analysis results for the family of experiments. If set to TRUE it returns the effect sizes for each experiment.</p>
</td></tr>
<tr><td><code id="NP2GMetaAnalysisSimulation_+3A_alwaystwosidedtests">AlwaysTwoSidedTests</code></td>
<td>
<p>If FALSE the function performs one-sided tests if diff!=0, and two-sided tests if diff=0. If set to TRUE the function alsways does two-sided tests.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Depending on the value of the returnES parameter, the function either returns the effect sizes for each experiment or the aggregated results for the family
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>as.data.frame(NP2GMetaAnalysisSimulation(mean=0,sd=1,diff=0.5,GroupSize=10,
  Exp=5,type="n",StdAdj=0,alpha=0.05,seed=457,StdExp=1,MAMethod="PM",
  returnES=FALSE))
#  NumExp GroupSize AveCliffd AveCliffdvar AveCliffdsig Avephat  Avephatvar Avephatsig AveMDStd..
#      5        10     0.252   0.01499003         TRUE   0.626 0.003645333       TRUE 0.4883188..
#  AveMDStdsig MAphat   MAphatvar MAphatsig MACliffd MACliffdvar MACliffdsig StdMDAdjUnweighted..
#1        TRUE 0.6288 0.003620188      TRUE   0.2575  0.01490134        TRUE          0.4748065..
#  StdMDAdjUnweightedvar StdMDAdjUnweightedsig StdMDUnweighted StdMDUnweightedvar StdMDUnweight..
#1            0.04065614                  TRUE       0.4980148         0.04157691            TRUE
#  HedgesMA.Weighted HedgesMA.Weightedvar HedgesMA.Weightedsig StdMDAdjMAexact StdMDAdjMAexactvar
#1         0.4755316           0.04307274                 TRUE       0.4725834         0.04315211
#  StdMDAdjMAexactsig StdMDAdjMAapprox StdMDAdjMAapproxvar StdMDAdjMAapproxsig StdMDMAapprox St..
#1               TRUE           0.4716          0.03762363                TRUE     0.4955783 ..
#  StdMDMAapproxsig StdMDMAexact StdMDMAexactvar StdMDMAexactsig
#1             TRUE    0.4966121      0.04756193            TRUE
as.data.frame(NP2GMetaAnalysisSimulation(mean=0,sd=1,diff=0.5,GroupSize=10,Exp=5,type="n",
  StdAdj=0,alpha=0.05,seed=457,StdExp=1,MAMethod="PM",returnES=TRUE))
#    MeanExp   VarExp     StdMD       df      tval t.sig Cliffd  Cliffdvar Cliffd.sig PHat PHat..
#1 0.5641594 1.437447 0.4705502 17.77980 1.0521822 FALSE   0.26 0.08149818      FALSE 0.63 0.02..
#2 0.6400936 1.081352 0.6155452 17.23411 1.3764009 FALSE   0.36 0.06527192      FALSE 0.68 0.01..
#3 0.8199650 1.698610 0.6291418 15.42141 1.4068038 FALSE   0.28 0.07362909      FALSE 0.64 0.01..
#4 0.2970819 1.709441 0.2272214 13.87833 0.5080824 FALSE   0.04 0.07936485      FALSE 0.52 0.01..
#5 0.5688567 1.079082 0.5476154 16.79899 1.2245053 FALSE   0.32 0.07498667      FALSE 0.66 0.01..
#  Phat.sig  StdMDAdj StdMDAdjvar.exact StdMDAdjvar.approx StdMDvar.exact StdMDvar.approx
#1    FALSE 0.4503698         0.2129598          0.1884384      0.2324722       0.2057040
#2    FALSE 0.5882961         0.2182075          0.1918563      0.2388898       0.2100409
#3    FALSE 0.5979539         0.2211428          0.1911344      0.2448130       0.2115926
#4    FALSE 0.2146782         0.2105671          0.1800107      0.2358918       0.2016604
#5    FALSE 0.5227345         0.2162500          0.1896495      0.2373259       0.2081330
as.data.frame(NP2GMetaAnalysisSimulation(mean=0,sd=1,diff=0.724,GroupSize=10,Exp=5,type="l",
  StdAdj=0,alpha=0.05,seed=123,StdExp=1,MAMethod="PM",returnES=FALSE))
#  NumExp GroupSize AveCliffd AveCliffdvar AveCliffdsig Avephat  Avephatvar Avephatsig  AveMDSt..
#1      5        10     0.344   0.01288023         TRUE   0.672 0.003118222       TRUE 0.483665..
#  AveMDStdsig MAphat   MAphatvar MAphatsig MACliffd MACliffdvar MACliffdsig StdMDAdjUnweighted
#1        TRUE 0.7014 0.004229764      TRUE    0.403  0.01690867        TRUE          0.5722448
#  StdMDAdjUnweightedvar StdMDAdjUnweightedsig StdMDUnweighted StdMDUnweightedvar StdMDUnweight..
#1            0.04146189                  TRUE       0.6046947         0.04260837            TRUE
#  HedgesMA.Weighted HedgesMA.Weightedvar HedgesMA.Weightedsig StdMDAdjMAexact StdMDAdjMAexactvar
#1         0.5742311           0.04453436                 TRUE       0.5405307          0.0450343
#  StdMDAdjMAexactsig StdMDAdjMAapprox StdMDAdjMAapproxvar StdMDAdjMAapproxsig StdMDMAapprox S..
#1               TRUE           0.5411          0.03819079                TRUE     0.5737401 0...
#  StdMDMAapproxsig StdMDMAexact StdMDMAexactvar StdMDMAexactsig
#1             TRUE    0.5727409      0.05042801            TRUE
</code></pre>

<hr>
<h2 id='NP4GMetaAnalysisSimulation'>NP4GMetaAnalysisSimulation</h2><span id='topic+NP4GMetaAnalysisSimulation'></span>

<h3>Description</h3>

<p>This function simulates data from a family of experiments, where the number of experiments in a family is defined by the parameter Exp. It simulates data from one of four distributions and uses the data to construct four of groups of equal size (GroupSize). Two groups are assigned as control groups and their distribution is based on the parameter, mean, and the parameter, spread. However, the mean and spread for the control group in Block 2 can be adjusted using the parameters BlockEffect and BlockStdAdj respectively. The other two groups are treatment groups and their distribution is based on the mean+diff and the spread parameter, but the distributions can be adjusted using the StdAdj, BlockEffect and BlockStdAdj parameters. The data from each experiment is analysed separately to estimate the non-parametric statistics P-hat, Cliff's d and their variances. In addition, the estimates of the standardized mean difference and the small sample size adjusted standardized mean difference are calculated. The effect size statistics are then meta-analysed using the method specified by the MAMethod parameter. We output both the average non-parametric effect statistics across the Exp experimet analysed as if they arose from a single large experiment and also the results of meta-analysising each non-parametric effect size. We use the standard parametric effect sizes and their meta-analysis as baselines.Tests of significance are one-sided if the mean difference is non-zero. If the mean difference is zero, two-sided tests are used. In addition, the user can force the use of two-sided tests using the parameter AlwaysTwoSidedTests. This should only be used for comparison with results reported in other simulation studies. The alpha parameter determines the significance level used in the tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NP4GMetaAnalysisSimulation(
  mean,
  sd,
  diff,
  GroupSize,
  Exp = 5,
  type = "n",
  alpha = 0.05,
  seed = 123,
  StdAdj = 0,
  BlockEffect = 0,
  BlockStdAdj = 0,
  StdExp = 0,
  MAMethod,
  returnES = FALSE,
  AlwaysTwoSidedTests = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="NP4GMetaAnalysisSimulation_+3A_mean">mean</code></td>
<td>
<p>The default value used for the group means in the simulated data. It can be any real number including zero.</p>
</td></tr>
<tr><td><code id="NP4GMetaAnalysisSimulation_+3A_sd">sd</code></td>
<td>
<p>The default value used for the spread of the control group and the spread of the treatment group in the simulated data. The value must be a real value greater than 0.</p>
</td></tr>
<tr><td><code id="NP4GMetaAnalysisSimulation_+3A_diff">diff</code></td>
<td>
<p>mean+diff is the value used for the mean of the treatment group. It can be zero.</p>
</td></tr>
<tr><td><code id="NP4GMetaAnalysisSimulation_+3A_groupsize">GroupSize</code></td>
<td>
<p>is the size of each of the 4 groups comprising one experiment. Groupsize should be an integer of 4 or more</p>
</td></tr>
<tr><td><code id="NP4GMetaAnalysisSimulation_+3A_exp">Exp</code></td>
<td>
<p>is the number of experiments being simulated. Exp should be an integer of 2 or more. It defaults to 5.</p>
</td></tr>
<tr><td><code id="NP4GMetaAnalysisSimulation_+3A_type">type</code></td>
<td>
<p>specifies the distribution being simulated. The permitted values are &quot;n&quot; for the normal distribution,  &quot;l&quot; for the lognormal distribution, &quot;g&quot; for the gamma distribution and &quot;lap&quot; for the Laplace dsitribution. The parameter defaults to &quot;n&quot;.</p>
</td></tr>
<tr><td><code id="NP4GMetaAnalysisSimulation_+3A_alpha">alpha</code></td>
<td>
<p>the Type 1 error rate level use for statistical tests.</p>
</td></tr>
<tr><td><code id="NP4GMetaAnalysisSimulation_+3A_seed">seed</code></td>
<td>
<p>specifies the seed to be used to initiate the simulation, so the simulation is repeatable. It defaults to 123.</p>
</td></tr>
<tr><td><code id="NP4GMetaAnalysisSimulation_+3A_stdadj">StdAdj</code></td>
<td>
<p>The value used to introduce heterogeneity into the treatment groups variance if required.</p>
</td></tr>
<tr><td><code id="NP4GMetaAnalysisSimulation_+3A_blockeffect">BlockEffect</code></td>
<td>
<p>is the effect of having two different blocks</p>
</td></tr>
<tr><td><code id="NP4GMetaAnalysisSimulation_+3A_blockstdadj">BlockStdAdj</code></td>
<td>
<p>is the variance associated with the Block. If BlockStdAdj is zero it means we are treating the block effect as a fixed effect. If BlockStdAdj&gt;0, we treat the block effect as a random effect and increase the variance of Block 2 data.</p>
</td></tr>
<tr><td><code id="NP4GMetaAnalysisSimulation_+3A_stdexp">StdExp</code></td>
<td>
<p>defines whether any additional heterogeneity is introduced between families. The value (set to 0 or 0.5 for our simulations) is used when we generate a deviation to be added to the control mean (control rate for gamma data) for each family. The deviation is generated from a Normal distribution with mean 0 and standard deviation=0.5. If StdExp=0 we do not add any deviations to the mean.</p>
</td></tr>
<tr><td><code id="NP4GMetaAnalysisSimulation_+3A_mamethod">MAMethod</code></td>
<td>
<p>defines the method used for meta-analysis</p>
</td></tr>
<tr><td><code id="NP4GMetaAnalysisSimulation_+3A_returnes">returnES</code></td>
<td>
<p>This determines the format of the output. If returnES=FALSE it returns the summary meta-analysis statistics otherwise it returns the effect sizes and their variances for each experiment in the family</p>
</td></tr>
<tr><td><code id="NP4GMetaAnalysisSimulation_+3A_alwaystwosidedtests">AlwaysTwoSidedTests</code></td>
<td>
<p>If this parameter is TRUE, the function always does two-sided tests. IF the parameter is FALSE, the function does two-sided statistical tests if the difference between treatment groups is 0, if the difference is not 0, it does one-sided tests</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If returnES is FALSE, the function returns the summary meta-analysis summary statistics otherwise the function returns the effect sizes for each experiment
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>as.data.frame(NP4GMetaAnalysisSimulation(mean=0,sd=1,diff=0.8,GroupSize=5,Exp=5,type="n",
alpha=0.05,seed=457,StdAdj=0,BlockEffect=0.5,BlockStdAdj=0,StdExp=0,MAMethod="FE",returnES=TRUE))
#     MeanExp    VarExp       StdMD       df       tval t.sig Cliffd  Cliffdvar PHat PHatvar PH..
#1  1.0761565 1.3874542  0.91362108 14.42773  2.0429188  TRUE   0.52 0.05530667 0.76  0.0132 13..
#2  0.1012680 0.9779431  0.10240368 12.74930  0.2289816 FALSE   0.20 0.09048000 0.60  0.0224 10..
#3  1.2100986 0.9909894  1.21558760 11.16850  2.7181365  TRUE   0.64 0.04720000 0.82  0.0110 13..
#4 -0.1452027 2.3106703 -0.09552252 11.93764 -0.2135949 FALSE   0.04 0.09888000 0.52  0.0244 10..
#5  1.1701075 0.9623530  1.19277505 12.72802  2.6671261  TRUE   0.52 0.05048000 0.76  0.0124 15..
#     StdMDAdj StdMDAdjvar.exact StdMDAdjvar.approx StdMDvar.exact StdMDvar.approx
#1  0.86514731         0.2357247          0.2025998      0.2664156       0.2259389
#2  0.09623845         0.2098977          0.1769637      0.2377103       0.2003632
#3  1.13176658         0.2732955          0.2230773      0.3262821       0.2573441
#4 -0.08937076         0.2106627          0.1753619      0.2407210       0.2003345
#5  1.12084087         0.2623764          0.2201822      0.3050637       0.2493511
as.data.frame(NP4GMetaAnalysisSimulation(mean=0,sd=1,diff=0.8,GroupSize=5,Exp=5,type="n",
alpha=0.05,seed=457,StdAdj=0,BlockEffect=0.5,BlockStdAdj=0,StdExp=0,MAMethod="FE",returnES=FALSE))
#  NumExp GroupSize AveCliffd AveCliffdvar AveCliffdsig Avephat Avephatvar Avephatsig  AveMDStd..
#1      5         5     0.384   0.01369387         TRUE   0.692   0.003336       TRUE 0.5927084..
#  AveMDStdsig    MAphat  MAphatvar MAphatsig  MACliffd MACliffdvar MACliffdsig StdMDAdjUnweigh..
#1        TRUE 0.7253858 0.00300356      TRUE 0.4471125  0.01246219        TRUE          0.6249..
#  StdMDAdjUnweightedvar StdMDAdjUnweightedsig StdMDUnweighted StdMDUnweightedvar StdMDUnweight..
#1            0.04220968                  TRUE        0.665773         0.04366035            TRUE
#  HedgesMA.Weighted HedgesMA.Weightedvar HedgesMA.Weightedsig StdMDAdjMAexact StdMDAdjMAexactvar
#1         0.6250243           0.04574766                 TRUE       0.5709401         0.04711703
#  StdMDAdjMAexactsig StdMDAdjMAapprox StdMDAdjMAapproxvar StdMDAdjMAapproxsig StdMDMAapprox St..
#1               TRUE        0.5715637          0.03950437                TRUE     0.6090632 0...
#  StdMDMAapproxsig StdMDMAexact StdMDMAexactvar StdMDMAexactsig
#1             TRUE    0.6013198      0.05417894            TRUE
</code></pre>

<hr>
<h2 id='percentageInaccuracyOfLargeSampleVarianceApproximation'>percentageInaccuracyOfLargeSampleVarianceApproximation</h2><span id='topic+percentageInaccuracyOfLargeSampleVarianceApproximation'></span>

<h3>Description</h3>

<p>Plot the extent of inaccuracy using the large sample approximate effect size variance on 4 related graphs corresponding to the four different correlation values. Plot visualizes the relationship between sample size and effect size and the percentage inaccuracy of the large sample variance approximation. Function is used in a paper 'Effect Sizes and their Variance for AB/BA Crossover Design Studies' by Lech Madeyski and Barbara Kitchenham.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>percentageInaccuracyOfLargeSampleVarianceApproximation(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="percentageInaccuracyOfLargeSampleVarianceApproximation_+3A_data">data</code></td>
<td>
<p>- data behind the plot returned by getSimulatedCrossoverDataSets() or stored in reproducer::KitchenhamMadeyski.SimulatedCrossoverDataSets</p>
</td></tr>
</table>


<h3>Value</h3>

<p>plot described in description
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- KitchenhamMadeyski.SimulatedCrossoverDataSets
myPlot &lt;- percentageInaccuracyOfLargeSampleVarianceApproximation(data)
</code></pre>

<hr>
<h2 id='PHat.test'>PHat.test</h2><span id='topic+PHat.test'></span>

<h3>Description</h3>

<p>This function provides single-sided and two-sided tests of the probability of superiority (phat).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PHat.test(x, y, alpha = 0.05, alternative = "two.sided", sigfig = -1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PHat.test_+3A_x">x</code></td>
<td>
<p>The data from one group</p>
</td></tr>
<tr><td><code id="PHat.test_+3A_y">y</code></td>
<td>
<p>The data from the alternative group</p>
</td></tr>
<tr><td><code id="PHat.test_+3A_alpha">alpha</code></td>
<td>
<p>The significance level of tests which also controls the values
of the confidence interval (default 0.05)</p>
</td></tr>
<tr><td><code id="PHat.test_+3A_alternative">alternative</code></td>
<td>
<p>This defines whether a one-sided test or a two-sided
(default) test is required. For a one-sided test use parameter values
greater' or 'less' to define whether the d-value should be greater or less
than zero.</p>
</td></tr>
<tr><td><code id="PHat.test_+3A_sigfig">sigfig</code></td>
<td>
<p>is the number of significant digits in the data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The values of phat and its standard error,the t-value, its pvalue and the upper and lower confidence interval.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(456)
x &lt;- rnorm(10, 0, 1)
y &lt;- rnorm(10, 0.8, 1)
PHat.test(x, y, alpha = .05, alternative = "greater", sigfig = -1)
# A tibble: 1 x 8
#    phat sqse.phat phat.df phat.tvalue phat.pvalue phat.ci.lower phat.ci.upper phat.sig
#   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt; &lt;lgl&gt;
# 1  0.79    0.0118    13.6        2.67     0.00924         0.599             1 TRUE
PHat.test(x, y, alpha = .05, alternative = "two.sided", sigfig = -1)
# A tibble: 1 x 8
# phat sqse.phat phat.df phat.tvalue phat.pvalue phat.ci.lower phat.ci.upper phat.sig
#  &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt; &lt;lgl&gt;
# 1  0.79    0.0118    13.6        2.67      0.0185         0.557             1 TRUE

</code></pre>

<hr>
<h2 id='PHatonesidedTestStatistics'>PHatonesidedTestStatistics</h2><span id='topic+PHatonesidedTestStatistics'></span>

<h3>Description</h3>

<p>This function is a helper function for meta-analysis of experiments using PHat as an effect size. It returns the 100*(1-alpha)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PHatonesidedTestStatistics(
  effectsize,
  effectsize.variance,
  effectsize.df = 0,
  alpha = 0.05,
  alternative = "greater"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PHatonesidedTestStatistics_+3A_effectsize">effectsize</code></td>
<td>
<p>The overall estimate of the centralized PHat (i.e. Phat-0.5) from a group of effect sizes to be meta-analysed</p>
</td></tr>
<tr><td><code id="PHatonesidedTestStatistics_+3A_effectsize.variance">effectsize.variance</code></td>
<td>
<p>The estimate of the variance of the overall estimate ofPHat</p>
</td></tr>
<tr><td><code id="PHatonesidedTestStatistics_+3A_effectsize.df">effectsize.df</code></td>
<td>
<p>The total degrees of freedom for the set of effect sizes. If effectsize.df&gt;0, the confidence intervals, pvalues and significance test use the t-distribution probability values. If effectsize.df=0 (default), the confidence intervals, the pvalues and significance test use the normal distribution probability values.</p>
</td></tr>
<tr><td><code id="PHatonesidedTestStatistics_+3A_alpha">alpha</code></td>
<td>
<p>The significance level (default 0.05) used to control the significance tests and calculation of confidence limits.</p>
</td></tr>
<tr><td><code id="PHatonesidedTestStatistics_+3A_alternative">alternative</code></td>
<td>
<p>Specifies the type of significance test and can take the values &quot;less&quot; or &quot;greater&quot; (default).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ES.test The value of the t-statistic
</p>
<p>ES.pvalue The p-value of the two-sided t-test if the parameter d.df&gt;0, or the normal probability value if d.df=0
</p>
<p>ES.sig The significance of the statistical test of the d.tvalue return value at the alpha level for one sided tests and aplha/2 for two sided tests as specified by the input parameter alternative.
</p>
<p>ES.ci.lower The lower 100*(1-alpha/2)
</p>
<p>ES.ci.upper The upper 100*(1-alpha/2)
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>PHatES=mean(c(0.92,0.6,0.48,0.72,0.88))-0.5
PHatESvar=sum(c(0.01,0.04,0.05,0.04,0.01))/25
PHatdf=sum(c(6.63,6.63,5.08,5.61,8))
#PHatonesidedTestStatistics(effectsize=PHatES,effectsize.variance=PHatESvar,effectsize.df=PHatdf)
# A tibble: 1 x 5
#  ES.test ES.pvalue ES.sig ES.ci.lower ES.ci.upper
#    &lt;dbl&gt;     &lt;dbl&gt; &lt;lgl&gt;        &lt;dbl&gt;       &lt;dbl&gt;
#1    2.84   0.00389 TRUE        0.0888       0.351
#PHatonesidedTestStatistics(effectsize=PHatES,effectsize.variance=PHatESvar,effectsize.df=0,
# alternative="less")
# A tibble: 1 x 5
#  ES.test ES.pvalue ES.sig ES.ci.lower ES.ci.upper
#    &lt;dbl&gt;     &lt;dbl&gt; &lt;lgl&gt;        &lt;dbl&gt;       &lt;dbl&gt;
#1    2.84     0.998 FALSE       0.0926       0.347
</code></pre>

<hr>
<h2 id='PHattwosidedTestStatistics'>PHattwosidedTestStatistics</h2><span id='topic+PHattwosidedTestStatistics'></span>

<h3>Description</h3>

<p>This function is a helper function for meta-analysis of experiments using PHat as an effect size. It returns the 100*(1-alpha/2)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PHattwosidedTestStatistics(
  effectsize,
  effectsize.variance,
  effectsize.df = 0,
  alpha = 0.05
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PHattwosidedTestStatistics_+3A_effectsize">effectsize</code></td>
<td>
<p>The overall estimate of the centralized PHat (ie.Phat-0.5) from a group of effect sizes to be meta-analysed</p>
</td></tr>
<tr><td><code id="PHattwosidedTestStatistics_+3A_effectsize.variance">effectsize.variance</code></td>
<td>
<p>The estimate of the variance of the overall estimate ofPHat</p>
</td></tr>
<tr><td><code id="PHattwosidedTestStatistics_+3A_effectsize.df">effectsize.df</code></td>
<td>
<p>The total degrees of freedom for the set of effect sizes. If effectsize.df&gt;0, the confidence intervals, pvalues and significance test use the t-distribution probability values. If effectsize.df=0 (default), the confidence intervals, the pvalues and significance test use the normal distribution probability values.</p>
</td></tr>
<tr><td><code id="PHattwosidedTestStatistics_+3A_alpha">alpha</code></td>
<td>
<p>The significance level (default 0.05) used to control the significance tests and calculation of confidence limits.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ES.test The value of the t-statistic
</p>
<p>ES.pvalue The p-value of the two-sided t-test if the parameter d.df&gt;0, or the normal probability value if d.df=0
</p>
<p>ES.sig The significance of the statistical test of the d.tvalue return value at the alpha level for one sided tests and aplha/2 for two sided tests as specified by the input parameter alternative.
</p>
<p>ES.ci.lower The lower 100*(1-alpha/2)
</p>
<p>ES.ci.upper The upper 100*(1-alpha/2)
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>PHatES=mean(c(0.92,0.6,0.48,0.72,0.88))-0.5
PHatESvar=sum(c(0.01,0.04,0.05,0.04,0.01))/25
PHatdf=sum(c(6.63,6.63,5.08,5.61,8))
#PHattwosidedTestStatistics(effectsize=PHatES,effectsize.variance=PHatESvar)
# A tibble: 1 x 5
# ES.test ES.pvalue ES.sig ES.ci.lower ES.ci.upper
#     &lt;dbl&gt;     &lt;dbl&gt; &lt;lgl&gt;        &lt;dbl&gt;       &lt;dbl&gt;
# 1    2.84   0.00451 TRUE        0.0682       0.372
# PHattwosidedTestStatistics(effectsize=PHatES,effectsize.variance=PHatESvar,effectsize.df=PHatdf)
#  A tibble: 1 x 5
#   ES.test ES.pvalue ES.sig ES.ci.lower ES.ci.upper
#     &lt;dbl&gt;     &lt;dbl&gt; &lt;lgl&gt;        &lt;dbl&gt;       &lt;dbl&gt;
# 1    2.84   0.00778 TRUE        0.0622       0.378
</code></pre>

<hr>
<h2 id='plotOutcomesForIndividualsInEachSequenceGroup'>plotOutcomesForIndividualsInEachSequenceGroup</h2><span id='topic+plotOutcomesForIndividualsInEachSequenceGroup'></span>

<h3>Description</h3>

<p>Function to plot a figure on the outcomes for individuals in each sequence group used in a paper 'Effect Sizes and their Variance for AB/BA Crossover Design Studies' by Lech Madeyski and Barbara Kitchenham
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotOutcomesForIndividualsInEachSequenceGroup(
  var,
  covar,
  meanA1,
  treatmentDiff,
  periodEffect,
  numOfSamples
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotOutcomesForIndividualsInEachSequenceGroup_+3A_var">var</code></td>
<td>
<p>Variance among subjects is a sum of the between subjects variance and the within subjects variance</p>
</td></tr>
<tr><td><code id="plotOutcomesForIndividualsInEachSequenceGroup_+3A_covar">covar</code></td>
<td>
<p>Covariance equal to the between subjects variance</p>
</td></tr>
<tr><td><code id="plotOutcomesForIndividualsInEachSequenceGroup_+3A_meana1">meanA1</code></td>
<td>
<p>Mean for treatment sequence A1</p>
</td></tr>
<tr><td><code id="plotOutcomesForIndividualsInEachSequenceGroup_+3A_treatmentdiff">treatmentDiff</code></td>
<td>
<p>technique effect which is the difference between the effect of technique A and technique B</p>
</td></tr>
<tr><td><code id="plotOutcomesForIndividualsInEachSequenceGroup_+3A_periodeffect">periodEffect</code></td>
<td>
<p>Period effect which is the difference between period 1 and period 2</p>
</td></tr>
<tr><td><code id="plotOutcomesForIndividualsInEachSequenceGroup_+3A_numofsamples">numOfSamples</code></td>
<td>
<p>Number of samples ('rows' of data) required for each technique and period</p>
</td></tr>
</table>


<h3>Value</h3>

<p>plot
</p>


<h3>Author(s)</h3>

<p>Lech Madeyski and Barbara Kitchenham
</p>


<h3>Examples</h3>

<pre><code class='language-R'>myPlot &lt;- plotOutcomesForIndividualsInEachSequenceGroup(25, 18.75, 50, 10, 5, 15)
</code></pre>

<hr>
<h2 id='PrepareForMetaAnalysisGtoR'>PrepareForMetaAnalysisGtoR</h2><span id='topic+PrepareForMetaAnalysisGtoR'></span>

<h3>Description</h3>

<p>This function calculates the standardized effect sizes and their confidence intervals, the equivalence point biserial effect size and the Zr and var(Zr) needed for input into the metafor rma function (meta analysis). In this function the point bi-serial effect size is based on the adjusted Hedges g value. The function uses the Hedges g to r transformation to prepare for meta-analysing the data where the mean values, the standard deviations, and the number of observations are available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PrepareForMetaAnalysisGtoR(Mc, Mt, SDc, SDt, Nc, Nt)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PrepareForMetaAnalysisGtoR_+3A_mc">Mc</code></td>
<td>
<p>is a vector containing the mean value of the control group for each experiment.</p>
</td></tr>
<tr><td><code id="PrepareForMetaAnalysisGtoR_+3A_mt">Mt</code></td>
<td>
<p>is a vector containing the mean value of the treatment group for each experiment.</p>
</td></tr>
<tr><td><code id="PrepareForMetaAnalysisGtoR_+3A_sdc">SDc</code></td>
<td>
<p>is a vector of the standard deviations of the control group for each experiment.</p>
</td></tr>
<tr><td><code id="PrepareForMetaAnalysisGtoR_+3A_sdt">SDt</code></td>
<td>
<p>is a vector of the standard deviations of the the treatment group for each experiment.</p>
</td></tr>
<tr><td><code id="PrepareForMetaAnalysisGtoR_+3A_nc">Nc</code></td>
<td>
<p>is a vector containing the the number of observations (participants) in the control group for each experiment.</p>
</td></tr>
<tr><td><code id="PrepareForMetaAnalysisGtoR_+3A_nt">Nt</code></td>
<td>
<p>is a vector of the number of observations (participants) in the treatment group for each experiment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame incl. calculated effect sizes (Hedges' g, Hedges' g adjusted), upper and lower confidence bounds on Hedges' g, zr, vi - variance of zr, r and pvalue
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>PrepareForMetaAnalysisGtoR(c(10, 10), c(12, 14), c(4, 4), c(4, 4), c(20, 20), c(40, 40))
# HGvalues.Hg HGvalues.HgAdjusted  Hgupper     Hglower        zr         vi         r       pvalue
#        0.5           0.4935018 1.082017 -0.06156572 0.2305901 0.01754386 0.2265882 0.0816981743
#        1.0           0.9870036 1.634701  0.40620071 0.4499419 0.01754386 0.4218513 0.0006813222
</code></pre>

<hr>
<h2 id='printXTable'>printXTable</h2><span id='topic+printXTable'></span>

<h3>Description</h3>

<p>print data table using xtable R package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>printXTable(
  data,
  selectedColumns,
  tableType = "latex",
  alignCells,
  digits,
  caption,
  label,
  fontSize,
  captionPlacement = "bottom",
  alignHeader
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="printXTable_+3A_data">data</code></td>
<td>
<p>Data structure including columns to be printed.</p>
</td></tr>
<tr><td><code id="printXTable_+3A_selectedcolumns">selectedColumns</code></td>
<td>
<p>Columns selected to be printed.</p>
</td></tr>
<tr><td><code id="printXTable_+3A_tabletype">tableType</code></td>
<td>
<p>Type of table to produce. Possible values are 'latex' or 'html'. Default value is 'latex'.</p>
</td></tr>
<tr><td><code id="printXTable_+3A_aligncells">alignCells</code></td>
<td>
<p>Defines how to align data cells.</p>
</td></tr>
<tr><td><code id="printXTable_+3A_digits">digits</code></td>
<td>
<p>Defines the number of decimal points in each column.</p>
</td></tr>
<tr><td><code id="printXTable_+3A_caption">caption</code></td>
<td>
<p>Caption of the table.</p>
</td></tr>
<tr><td><code id="printXTable_+3A_label">label</code></td>
<td>
<p>Label of the table.</p>
</td></tr>
<tr><td><code id="printXTable_+3A_fontsize">fontSize</code></td>
<td>
<p>Size of the font used to produce a table.</p>
</td></tr>
<tr><td><code id="printXTable_+3A_captionplacement">captionPlacement</code></td>
<td>
<p>The caption will be have placed at the bottom of the table if captionPlacement is 'bottom' and at the top of the table if it equals 'top'. Default value is 'bottom'.</p>
</td></tr>
<tr><td><code id="printXTable_+3A_alignheader">alignHeader</code></td>
<td>
<p>Defines how to align column headers of a table.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A table generated on the fly on a basis of passed data (data, selectedColumns etc.).
</p>


<h3>Author(s)</h3>

<p>Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d &lt;- reproducer::MadeyskiKitchenham.MetaAnalysis.PBRvsCBRorAR
printXTable(d, "Study", "latex", "cc", 0, "C", "L", "tiny", "top", "l")
</code></pre>

<hr>
<h2 id='proportionOfSignificantTValuesUsingCorrectAnalysis'>proportionOfSignificantTValuesUsingCorrectAnalysis</h2><span id='topic+proportionOfSignificantTValuesUsingCorrectAnalysis'></span>

<h3>Description</h3>

<p>Plots visualize the relationship between sample size, effect size and the proportion of significant t-values using the correct analysis. Function is used in a paper 'Effect Sizes and their Variance for AB/BA Crossover Design Studies' by Lech Madeyski and Barbara Kitchenham.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>proportionOfSignificantTValuesUsingCorrectAnalysis(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="proportionOfSignificantTValuesUsingCorrectAnalysis_+3A_data">data</code></td>
<td>
<p>- data behind the plot returned by getSimulatedCrossoverDataSets() or stored in reproducer::KitchenhamMadeyski.SimulatedCrossoverDataSets</p>
</td></tr>
</table>


<h3>Value</h3>

<p>plot described in description
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- KitchenhamMadeyski.SimulatedCrossoverDataSets
myPlot &lt;- proportionOfSignificantTValuesUsingCorrectAnalysis(data)
</code></pre>

<hr>
<h2 id='proportionOfSignificantTValuesUsingIncorrectAnalysis'>proportionOfSignificantTValuesUsingIncorrectAnalysis</h2><span id='topic+proportionOfSignificantTValuesUsingIncorrectAnalysis'></span>

<h3>Description</h3>

<p>Plots visualize the relationship between sample size, effect size and the proportion of significant t-values using the incorrect analysis. Function is used in a paper 'Effect Sizes and their Variance for AB/BA Crossover Design Studies' by Lech Madeyski and Barbara Kitchenham.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>proportionOfSignificantTValuesUsingIncorrectAnalysis(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="proportionOfSignificantTValuesUsingIncorrectAnalysis_+3A_data">data</code></td>
<td>
<p>- data behind the plot returned by getSimulatedCrossoverDataSets() or stored in reproducer::KitchenhamMadeyski.SimulatedCrossoverDataSets</p>
</td></tr>
</table>


<h3>Value</h3>

<p>plot described in description
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- KitchenhamMadeyski.SimulatedCrossoverDataSets
myPlot &lt;- proportionOfSignificantTValuesUsingIncorrectAnalysis(data)
</code></pre>

<hr>
<h2 id='RandomExperimentSimulations'>RandomExperimentSimulations</h2><span id='topic+RandomExperimentSimulations'></span>

<h3>Description</h3>

<p>This function performs multiple simulations of two-group balanced experiments for one of four distributions and a specific group size. It identifies the average value of phat, Cliff' d and their variances. It either returns the effect sizes for each non-parametric effect size or it reports the number of times the each non-parametric effect size is assessed to be significantly different from zero. We also present the values for the t-test as a comparison. For log-normal data the results of analysing the transformed data are also reported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RandomExperimentSimulations(
  mean,
  sd,
  diff,
  N,
  reps,
  type = "n",
  seed = 123,
  StdAdj = 0,
  alpha = 0.05,
  returnData = FALSE,
  AlwaysTwoSidedTests = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RandomExperimentSimulations_+3A_mean">mean</code></td>
<td>
<p>The default mean used for both groups (one treatment group and one control group). It can be changed for the treatment group using  the parameter diff</p>
</td></tr>
<tr><td><code id="RandomExperimentSimulations_+3A_sd">sd</code></td>
<td>
<p>This is the default spread for both groups. It must be a real value greater than 0. It can be adjusted for the treatment group using the parameter StdAdj</p>
</td></tr>
<tr><td><code id="RandomExperimentSimulations_+3A_diff">diff</code></td>
<td>
<p>This is added to the treatment group mean. It can be a real value avd can take the value zero.</p>
</td></tr>
<tr><td><code id="RandomExperimentSimulations_+3A_n">N</code></td>
<td>
<p>this is the number of observations in each group. It must be an integer greater than 3.</p>
</td></tr>
<tr><td><code id="RandomExperimentSimulations_+3A_reps">reps</code></td>
<td>
<p>this identifies the number of times each experiment simulation is replicated.</p>
</td></tr>
<tr><td><code id="RandomExperimentSimulations_+3A_type">type</code></td>
<td>
<p>this specifies the underlying distribution used to generate the data. It takes the values 'n' for a normal distribution, 'l' for lognormal distribution,'g' for a gamma distribution, 'lap' for a Laplace distribution.</p>
</td></tr>
<tr><td><code id="RandomExperimentSimulations_+3A_seed">seed</code></td>
<td>
<p>This specifies the initial seed for the set of replications
(default 123).</p>
</td></tr>
<tr><td><code id="RandomExperimentSimulations_+3A_stdadj">StdAdj</code></td>
<td>
<p>this specifies the extent of variance instability introduced by the treatment and it must be non-negative but can be 0.</p>
</td></tr>
<tr><td><code id="RandomExperimentSimulations_+3A_alpha">alpha</code></td>
<td>
<p>This specifies the level of significance used for statistical
tests (default 0.05).</p>
</td></tr>
<tr><td><code id="RandomExperimentSimulations_+3A_returndata">returnData</code></td>
<td>
<p>If TRUE, the function returns the individual effect sizes and their variances, otherwise it returns summary statistics (default FALSE).</p>
</td></tr>
<tr><td><code id="RandomExperimentSimulations_+3A_alwaystwosidedtests">AlwaysTwoSidedTests</code></td>
<td>
<p>If set to FALSE (default) the algorithms uses one-sided tests if diff!=0 and two-sided tests if diff=0. If set to TRUE the algorithm always uses two-sided tests.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>as.data.frame(
  RandomExperimentSimulations(
    mean = 0, sd = 1, diff = 0.5, N = 20, reps = 50, type = "n",
    seed = 123, StdAdj = 0, alpha = 0.05))
#        phat     phatvar sigphat emp.phat.var       d       dvar sigd
# 1  0.636675 0.007980072    0.38  0.006413391 0.27335 0.03257962 0.36
#    emp.d.var   tpower        ES Variance     StdES   MedDiff
#1  0.02565356     0.41 0.4849609 0.988889 0.4982554 0.4666802
#as.data.frame(
 # RandomExperimentSimulations(
 #   mean = 0, sd = 1, diff = 0.5, N = 20, reps = 500, type = "n",
 #   seed = 123, StdAdj = 0, alpha = 0.05))
#     phat     phatvar sigphat emp.phat.var      d       dvar  sigd  emp.d.var
# 1 0.63915 0.007925803   0.444  0.007904962 0.2783 0.03235111 0.414 0.03161985
#     tpower        ES Variance
# 1     0.444 0.4999034 1.002012
# 1      StdES   MedDiff
# 1 0.5099792 0.4901394

#as.data.frame(
#   RandomExperimentSimulations(
#     mean = 0, sd = 1, diff = 0.2, N = 20, reps = 500, type = "n",
#     seed = 123, StdAdj = 0, alpha = 0.05, AlwaysTwoSidedTests = TRUE))
#     phat     phatvar sigphat emp.phat.var       d       dvar  sigd emp.d.var
# 1 0.55762 0.008596555   0.092  0.008457325 0.11524 0.03505528 0.076 0.0338293
#     tpower        ES Variance     StdES   MedDiff
# 1       0.1 0.1999034 1.002012 0.2043908 0.1901394

#as.data.frame(
#   RandomExperimentSimulations(
#     mean = 0, sd = 1, diff = 0.2, N = 20, reps = 500, type = "n",
#     seed = 123, StdAdj = 0, alpha = 0.05, AlwaysTwoSidedTests = FALSE))
#     phat     phatvar sigphat emp.phat.var       d       dvar  sigd emp.d.var
# 1 0.55762 0.008596555   0.154  0.008457325 0.11524 0.03505528 0.146 0.0338293
#        tpower        ES Variance
# 1         0.16 0.1999034 1.002012
#      StdES   MedDiff
# 1 0.2043908 0.1901394

RandomExperimentSimulations(
  mean = 0, sd = 1, diff = 0.5, N = 20, reps = 10, type = "l", seed = 456,
  StdAdj = 0, alpha = 0.05, returnData = TRUE, AlwaysTwoSidedTests = FALSE)
# A tibble: 10 x 6
#   Cliffd CliffdSig  PHat PHatSig  StdES ESSig
#    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;
# 1 -0.185         0 0.407       0 -0.246     0
# 2 -0.08          0 0.46        0  0.185     0
# 3  0.1           0 0.55        0  0.149     0
# 4  0.42          1 0.71        1  0.885     1
# 5  0.51          1 0.755       1  0.827     1
# 6  0.185         0 0.592       0  0.628     1
# 7  0.465         1 0.732       1  0.818     1
# 8  0.42          1 0.71        1  0.341     0
# 9  0.37          1 0.685       1  0.419     0
# 10  0.115         0 0.557       0  0.273     0

</code></pre>

<hr>
<h2 id='RandomizedBlockDesignEffectSizes'>RandomizedBlockDesignEffectSizes</h2><span id='topic+RandomizedBlockDesignEffectSizes'></span>

<h3>Description</h3>

<p>This function finds the theoretical effect sizes for a four-group randomized block experiments assuming one of four different underlying distributions specified by the type parameter. The design assumes two blocks each comprising a control and treatment group. If required a fixed Blocking effect is added to the mean for Block 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RandomizedBlockDesignEffectSizes(
  m1,
  std1,
  m2,
  std2,
  m3,
  std3,
  m4,
  std4,
  BE = 0,
  type = "n"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RandomizedBlockDesignEffectSizes_+3A_m1">m1</code></td>
<td>
<p>The theoretical mean for the control group in Block 1</p>
</td></tr>
<tr><td><code id="RandomizedBlockDesignEffectSizes_+3A_std1">std1</code></td>
<td>
<p>The theoretical variance for the control group in Block 1</p>
</td></tr>
<tr><td><code id="RandomizedBlockDesignEffectSizes_+3A_m2">m2</code></td>
<td>
<p>The theoretical mean for the treatment group in Block 1</p>
</td></tr>
<tr><td><code id="RandomizedBlockDesignEffectSizes_+3A_std2">std2</code></td>
<td>
<p>The theoretical variance for the treatment group in Block 1</p>
</td></tr>
<tr><td><code id="RandomizedBlockDesignEffectSizes_+3A_m3">m3</code></td>
<td>
<p>The theoretical mean for the control group in Block 2</p>
</td></tr>
<tr><td><code id="RandomizedBlockDesignEffectSizes_+3A_std3">std3</code></td>
<td>
<p>The theoretical variance for the control group in Block 2</p>
</td></tr>
<tr><td><code id="RandomizedBlockDesignEffectSizes_+3A_m4">m4</code></td>
<td>
<p>The theoretical mean for the treatment group in Block 2</p>
</td></tr>
<tr><td><code id="RandomizedBlockDesignEffectSizes_+3A_std4">std4</code></td>
<td>
<p>The theoretical variance for the treatment group in Block 2</p>
</td></tr>
<tr><td><code id="RandomizedBlockDesignEffectSizes_+3A_be">BE</code></td>
<td>
<p>A fixed block effect to be added to the Block 2 mean values.</p>
</td></tr>
<tr><td><code id="RandomizedBlockDesignEffectSizes_+3A_type">type</code></td>
<td>
<p>String identifying the distribution, 'n' for normal, 'ln' for lognormal, 'lap' for Laplace, 'g' for Gamma</p>
</td></tr>
</table>


<h3>Value</h3>

<p>dataframe holing the expected unstandardized mean difference effect size, the pooled within group variance, the standardized effect size and the point bi-serial correlation.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>RandomizedBlockDesignEffectSizes(m1=0,std1=1,m2=1,std2=1,m3=0,std3=1,m4=1,
  std4=1,BE = 1,type = 'n')
# ES Var StdES      rPBS
#1  1   1     1 0.4472136
RandomizedBlockDesignEffectSizes(m1=0,std1=1,m2=1,std2=1,m3=0,std3=1,m4=1,
  std4=1,BE = 1,type = 'l')
#        ES      Var     StdES      rPBS
#1 5.266886 82.17791 0.5810004 0.2789675
RandomizedBlockDesignEffectSizes(
  m1=0,std1=1,m2=0.266,std2=1,m3=0,std3=1,m4=0.266,std4=1,BE = 0,type = 'l')
#        ES      Var     StdES       rPBS
#1 0.5024232 6.310995 0.1999957 0.09950162
</code></pre>

<hr>
<h2 id='RandomizedBlocksAnalysis'>RandomizedBlocksAnalysis</h2><span id='topic+RandomizedBlocksAnalysis'></span>

<h3>Description</h3>

<p>The function performs a heteroscedastic test of a two treatment by J blocks randomized blocks effect size. The data are assumed to be stored in $x$ in list mode. All groups are assumed to be independent. Missing values are not permitted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RandomizedBlocksAnalysis(
  x,
  con = c(-0.5, 0.5, -0.5, 0.5),
  alpha = 0.05,
  alternative = "two.sided"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RandomizedBlocksAnalysis_+3A_x">x</code></td>
<td>
<p>the structure holding the data. In list format, for a 2 treatment by J block randomized blocks experiments, there are  2J list elements each one specifying the outcome for a specific block and a specific treatment.</p>
</td></tr>
<tr><td><code id="RandomizedBlocksAnalysis_+3A_con">con</code></td>
<td>
<p>is a 2J list containing the contrast coefficients that are used to calculate the mean effect size.</p>
</td></tr>
<tr><td><code id="RandomizedBlocksAnalysis_+3A_alpha">alpha</code></td>
<td>
<p>is the Type 1 error level used for the test of significance
(default 0.05)</p>
</td></tr>
<tr><td><code id="RandomizedBlocksAnalysis_+3A_alternative">alternative</code></td>
<td>
<p>The type of statistical test. Valid values are one of
c('two.sided', 'greater', 'less')</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The t-test and its associated metrics (i.e., critical value standard error and degrees of freedom) and the estimate of the contrast with its upper and lower confidence interval bounds and p-value.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
x &lt;- list()
x[[1]] &lt;- rnorm(10, 0, 1)
x[[2]] &lt;- rnorm(10, 0.8, 1)
x[[3]] &lt;- rnorm(10, 0.5, 1)
x[[4]] &lt;- rnorm(10, 1.3, 1)
vec &lt;- c(-1, 1, -1, 1) / 2
RandomizedBlocksAnalysis(x, con = vec, alpha = 0.05)
# $n
# [1] 10 10 10 10
# $test
#      test     crit        se       df
# [1,] 4.432644 2.038622 0.2798104 31.33793
# $psihat
#      psihat  ci.lower ci.upper      p.value
# [1,] 1.2403 0.6698721 1.810728 0.0001062952
# $sig
# [1] TRUE
RandomizedBlocksAnalysis(x,con=vec,alpha=0.05,alternative='greater')
# n
# [1] 10 10 10 10
# $test
#          test     crit        se       df
# [1,] 4.432644 1.694956 0.2798104 31.33793
# $psihat
# psihat  ci.lower ci.upper      p.value
#[1,] 1.2403 0.7660336      Inf 5.314762e-05
# $sig
# [1] TRUE
RandomizedBlocksAnalysis(x,con=-vec,alpha=0.05,alternative='greater')
#$n
#[1] 10 10 10 10
#$test
#          test     crit        se       df
#[1,] -4.432644 1.694956 0.2798104 31.33793
#$psihat
#      psihat  ci.lower ci.upper   p.value
#[1,] -1.2403 -1.714566      Inf 0.9999469
#$sig
#[1] FALSE
x[[5]]=rnorm(10,-0.2,1)
x[[6]]=rnorm(10,0.6,1)
vec=c(1,-1,1,-1,1,-1)/3
RandomizedBlocksAnalysis(x,con=vec,alpha=0.05,alternative='less')
#$n
#[1] 10 10 10 10 10 10
#$test
#          test     crit       se       df
#[1,] -4.946987  1.677021 0.236575 48.29776
#$psihat
#        psihat ci.lower   ci.upper     p.value
#[1,] -1.170334     -Inf -0.7735925 4.76961e-06
#$sig
#[1] TRUE
</code></pre>

<hr>
<h2 id='RandomizedBlocksExperimentSimulations'>title RandomizedBlocksExperimentSimulations
description This function performs multiple simulations of 4 group balanced randomised Block experiments with two control groups and two treatment groups where one control group and one treatment group are assigned to block 1 and the other control group and treatment group are assigned to block 2.  The simulations are based on one of four distributions and a specific group size. The function identifies the average value of the non-parametric effect sizes P-hat, Cliff' d and their variances and whether ot not the statistics were significant at the 0.05 level. We also present the values of the t-test as a comparison.</h2><span id='topic+RandomizedBlocksExperimentSimulations'></span>

<h3>Description</h3>

<p>title RandomizedBlocksExperimentSimulations
description This function performs multiple simulations of 4 group balanced randomised Block experiments with two control groups and two treatment groups where one control group and one treatment group are assigned to block 1 and the other control group and treatment group are assigned to block 2.  The simulations are based on one of four distributions and a specific group size. The function identifies the average value of the non-parametric effect sizes P-hat, Cliff' d and their variances and whether ot not the statistics were significant at the 0.05 level. We also present the values of the t-test as a comparison.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RandomizedBlocksExperimentSimulations(
  mean,
  sd,
  diff,
  N,
  reps,
  type = "n",
  alpha = 0.05,
  Blockmean = 0,
  BlockStdAdj = 0,
  StdAdj = 0,
  seed = 123,
  returnData = FALSE,
  AlwaysTwoSidedTests = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RandomizedBlocksExperimentSimulations_+3A_mean">mean</code></td>
<td>
<p>The default mean for all 4 groups. The default for the two treatment groups can be altered using the parameter diff and the block mean for block 2 can be altered using the parameter Blockmean.</p>
</td></tr>
<tr><td><code id="RandomizedBlocksExperimentSimulations_+3A_sd">sd</code></td>
<td>
<p>The default spread for all 4 groups. It must be a real value greater than 0. If can be altered for treatment groups using the parameter StdAdj and for Block 2 groups using BlockStdAdj</p>
</td></tr>
<tr><td><code id="RandomizedBlocksExperimentSimulations_+3A_diff">diff</code></td>
<td>
<p>The is is added to the parameter mean, to define the mean of the other treatment group. It can be a real value ad can take the value zero.</p>
</td></tr>
<tr><td><code id="RandomizedBlocksExperimentSimulations_+3A_n">N</code></td>
<td>
<p>this is the number of observations in each group. It must be an integer greater than 3.</p>
</td></tr>
<tr><td><code id="RandomizedBlocksExperimentSimulations_+3A_reps">reps</code></td>
<td>
<p>this identifies the number of times the simulation is replicated.</p>
</td></tr>
<tr><td><code id="RandomizedBlocksExperimentSimulations_+3A_type">type</code></td>
<td>
<p>this specifies the underlying distribution used to generate the data. it takes the values 'n' for a normal distribution, 'l' for lognormal distribution,'g' for a gamma distribution, 'lap' for a Laplace distribution.</p>
</td></tr>
<tr><td><code id="RandomizedBlocksExperimentSimulations_+3A_alpha">alpha</code></td>
<td>
<p>is the Type 1 error level used for constructing confidence
intervals and statistical tests (default 0.05)</p>
</td></tr>
<tr><td><code id="RandomizedBlocksExperimentSimulations_+3A_blockmean">Blockmean</code></td>
<td>
<p>is the effect of having two different blocks</p>
</td></tr>
<tr><td><code id="RandomizedBlocksExperimentSimulations_+3A_blockstdadj">BlockStdAdj</code></td>
<td>
<p>is the variance associated with the Block mean. If Blockvar is zero it means we are treat the block effect as a fixed effect. If BlockStdAdj&gt;0, we treat the block effect as a random effect.</p>
</td></tr>
<tr><td><code id="RandomizedBlocksExperimentSimulations_+3A_stdadj">StdAdj</code></td>
<td>
<p>The value used to introduce heterogeneity into the treatment groups variance if required.</p>
</td></tr>
<tr><td><code id="RandomizedBlocksExperimentSimulations_+3A_seed">seed</code></td>
<td>
<p>this specifies the seed value for the simulations and allows the experiment to be repeated.</p>
</td></tr>
<tr><td><code id="RandomizedBlocksExperimentSimulations_+3A_returndata">returnData</code></td>
<td>
<p>if TRUE the function returns the generated data otherwise it returns summary statistics.</p>
</td></tr>
<tr><td><code id="RandomizedBlocksExperimentSimulations_+3A_alwaystwosidedtests">AlwaysTwoSidedTests</code></td>
<td>
<p>A boolean variable. If TRUE the simulations always used two-sided tests otherwise the simulations use one-sided tests.
return depending on the parameter returnData it returns the generated nonparametric and parametric values and their statistical significance (1 for significant, 0 for not significant) or the summary statistics (averages of effect sizes and their variances and the proportion significant effect sizes)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>as.data.frame(
  RandomizedBlocksExperimentSimulations(
    mean = 0, sd = 1, diff = 0.5, N = 10, reps = 50, type = "n",
    alpha = 0.05, Blockmean = 0.5, BlockStdAdj = 0, StdAdj = 0, seed = 123,
    AlwaysTwoSidedTests = FALSE))
#     phat     varphat sigphat emp.phat.var      d      vard sigd  emp.d.var
#1 0.64415 0.008271389    0.45  0.005888917 0.2883 0.0340919 0.41 0.02355567
#        StdES        ES       Var emp.StdESvar   MedDiff tpower
#1   0.5413961 0.5264245 0.9904726   0.08811262 0.5538213   0.46
#as.data.frame(
 # RandomizedBlocksExperimentSimulations(
 #   mean = 0, sd = 1, diff = 0.5, N = 10, reps = 500, type = "n",
 #   alpha = 0.05, Blockmean = 0.5, BlockStdAdj = 0, StdAdj = 0, seed = 123,
 #   AlwaysTwoSidedTests = FALSE))
#  phat    varphat       sigphat emp.phat.var  d       vard        sigd  emp.d.var
# 1  0.63967  0.008322856  0.436   0.007728698   0.27934 0.03430328  0.416 0.03091479
#       StdES        ES      Var emp.StdESvar   MedDiff
# 1 0.5130732 0.5029075 1.001602    0.1116687 0.5110203
#  tpower
# 1   0.45

#as.data.frame(
 # RandomizedBlocksExperimentSimulations(
 #   mean = 0, sd = 1, diff = 0.5, N = 10, reps = 500, type = "n",
 #   alpha = 0.05, Blockmean = 0.5, BlockStdAdj = 0, StdAdj = 0, seed = 123,
 #   AlwaysTwoSidedTests = TRUE))
#       phat     varphat sigphat emp.phat.var        d       vard   sigd
# 1  0.63967 0.008322856   0.326  0.007728698  0.27934 0.03430328  0.282
#     emp.d.var        StdES        ES      Var
# 1  0.03091479    0.5130732 0.5029075 1.001602
# emp.StdESvar   MedDiff tpower
# 1    0.1116687 0.5110203  0.334

#RandomizedBlocksExperimentSimulations(
 # mean = 0, sd = 1, diff = 0.5, N = 10, reps = 10, type = "n", alpha = 0.05,
 #Blockmean = 0.5, BlockStdAdj = 0, StdAdj = 0, seed = 123, returnData = TRUE)
# A tibble: 10 x 6
#   Cliffd  PHat StdES CliffdSig PHatSig ESSig
#    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;
# 1   0.58 0.79  1.06          1       1     1
# 2   0.21 0.605 0.383         0       0     0
# 3   0.37 0.685 0.761         1       1     1
# 4   0.44 0.72  0.821         1       1     1
# 5   0.13 0.565 0.240         0       0     0
# 6   0.16 0.58  0.222         0       0     0
# 7   0.38 0.69  0.580         1       1     1
# 8   0.48 0.74  0.882         1       1     1
# 9   0.11 0.555 0.181         0       0     0
# 10  -0.03 0.485 0.124        0       0     0

</code></pre>

<hr>
<h2 id='RandomizedDesignEffectSizes'>RandomizedDesignEffectSizes</h2><span id='topic+RandomizedDesignEffectSizes'></span>

<h3>Description</h3>

<p>This function creates the theoretical effect sizes for data from one of four different distributions for specified parameter values for the distribution specified by the type parameter. It assumes there are two samples, one corresponding to a control group and the other to the treatment group. It returns the theoretical effect sizes for a fully randomized experiment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RandomizedDesignEffectSizes(m1, std1, m2, std2, type = "n")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RandomizedDesignEffectSizes_+3A_m1">m1</code></td>
<td>
<p>The theoretical mean for the control group</p>
</td></tr>
<tr><td><code id="RandomizedDesignEffectSizes_+3A_std1">std1</code></td>
<td>
<p>The theoretical variance for the control group</p>
</td></tr>
<tr><td><code id="RandomizedDesignEffectSizes_+3A_m2">m2</code></td>
<td>
<p>The theoretical mean for the treatment group</p>
</td></tr>
<tr><td><code id="RandomizedDesignEffectSizes_+3A_std2">std2</code></td>
<td>
<p>The theoretical variance for the treatment group</p>
</td></tr>
<tr><td><code id="RandomizedDesignEffectSizes_+3A_type">type</code></td>
<td>
<p>String identifying the distribution, 'n' for normal, 'ln' for lognormal, 'lap' for Laplace, 'g' for Gamma</p>
</td></tr>
</table>


<h3>Value</h3>

<p>dataframe containing the expected values of the unstandardized mean difference effect size, the pooled within group variance, the standardized mean difference effect size and the point bi-serial correlation.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>RandomizedDesignEffectSizes(m1=0, std1=1, m2=1, std2=3, type = 'n')
#  ES Var     StdES      rPBS
#1  1   5 0.4472136 0.2182179
RandomizedDesignEffectSizes(m1=0, std1=1, m2=1, std2=3, type = 'l')
#        ES       Var     StdES        rPBS
#1 243.0432 242552663 0.0156056 0.007802562
 RandomizedDesignEffectSizes(m1=0, std1=1, m2=0.266, std2=1, type = 'l')
#          ES      Var     StdES       rPBS
# 1 0.5024232 6.310995 0.1999957 0.09950162
</code></pre>

<hr>
<h2 id='readExcelSheet'>readExcelSheet</h2><span id='topic+readExcelSheet'></span>

<h3>Description</h3>

<p>Function reads data from an Excel file from a specified sheet
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readExcelSheet(path, sheet, colNames)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="readExcelSheet_+3A_path">path</code></td>
<td>
<p>Path to an Excel file, e.g. /User/lma/datasets/MyDataSet.xls</p>
</td></tr>
<tr><td><code id="readExcelSheet_+3A_sheet">sheet</code></td>
<td>
<p>Name of a sheet within an Excel file we want to read</p>
</td></tr>
<tr><td><code id="readExcelSheet_+3A_colnames">colNames</code></td>
<td>
<p>If TRUE, first row of data will be used as column names.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>myPath &lt;- system.file("extdata", "DataSet.xlsx", package = "reproducer")
Madeyski15SQJ.NDC &lt;- readExcelSheet(path = myPath, sheet = "Madeyski15SQJ.NDC", colNames = TRUE)
</code></pre>

<hr>
<h2 id='reproduceForestPlotRandomEffects'>reproduceForestPlotRandomEffects()</h2><span id='topic+reproduceForestPlotRandomEffects'></span>

<h3>Description</h3>

<p>Function reproduces Forest Plot of a Random-Effects Meta-analysis of Mean Differences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reproduceForestPlotRandomEffects()
</code></pre>


<h3>Author(s)</h3>

<p>Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>reproduceForestPlotRandomEffects()
</code></pre>

<hr>
<h2 id='reproduceMixedEffectsAnalysisWithEstimatedVarianceAndExperimentalDesignModerator'>reproduceMixedEffectsAnalysisWithEstimatedVarianceAndExperimentalDesignModerator()</h2><span id='topic+reproduceMixedEffectsAnalysisWithEstimatedVarianceAndExperimentalDesignModerator'></span>

<h3>Description</h3>

<p>Function reproduces Mixed-Effects Analysis using Subject Specific Estimated Variance with Experimental Design as a Moderator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reproduceMixedEffectsAnalysisWithEstimatedVarianceAndExperimentalDesignModerator(
  
)
</code></pre>


<h3>Author(s)</h3>

<p>Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>reproduceMixedEffectsAnalysisWithEstimatedVarianceAndExperimentalDesignModerator()
</code></pre>

<hr>
<h2 id='reproduceMixedEffectsAnalysisWithExperimentalDesignModerator'>reproduceMixedEffectsAnalysisWithExperimentalDesignModerator()</h2><span id='topic+reproduceMixedEffectsAnalysisWithExperimentalDesignModerator'></span>

<h3>Description</h3>

<p>Function reproduces Mixed-Effects Analysis with Experimental Design as a Moderator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reproduceMixedEffectsAnalysisWithExperimentalDesignModerator()
</code></pre>


<h3>Author(s)</h3>

<p>Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>reproduceMixedEffectsAnalysisWithExperimentalDesignModerator()
</code></pre>

<hr>
<h2 id='reproduceMixedEffectsForestPlotWithExperimentalDesignModerator'>reproduceMixedEffectsForestPlotWithExperimentalDesignModerator()</h2><span id='topic+reproduceMixedEffectsForestPlotWithExperimentalDesignModerator'></span>

<h3>Description</h3>

<p>Function reproduces Forest Plot of a Mixed Effects Meta-analysis of Mean Differences with Experimental Design as a Moderator Variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reproduceMixedEffectsForestPlotWithExperimentalDesignModerator()
</code></pre>


<h3>Author(s)</h3>

<p>Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>reproduceMixedEffectsForestPlotWithExperimentalDesignModerator()
</code></pre>

<hr>
<h2 id='reproduceSimulationResultsBasedOn500Reps1000Obs'>reproduceSimulationResultsBasedOn500Reps1000Obs</h2><span id='topic+reproduceSimulationResultsBasedOn500Reps1000Obs'></span>

<h3>Description</h3>

<p>Function to calculate simulation results based on 500 repetitions of 1000 observation samples. Function is used in a paper 'Effect Sizes and their Variance for AB/BA Crossover Design Studies' by Lech Madeyski and Barbara Kitchenham.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reproduceSimulationResultsBasedOn500Reps1000Obs()
</code></pre>


<h3>Value</h3>

<p>data frame including the following simulation results:
# treatmentEffect.Ave - Average Technique Effect
# dRM.Ave - Average dRM
# dRM.Var - Variance of dRM
# dRM.Var.Ave - Average of var(dRM)
# dRM.Var.ModerateSampleSizeApprox -
# dIG.Ave - Average dIG
# dIG.Var - Variance of dIG
# dIG.Var.Ave - Average of var(dIG)
# dIG.Var.ModerateSampleSizeApprox -
</p>


<h3>Author(s)</h3>

<p>Lech Madeyski and Barbara Kitchenham
</p>


<h3>Examples</h3>

<pre><code class='language-R'># return simulation results based on 500 repetitions of 1000 observation samples
simulationResultsTable500x1000 &lt;- reproduceSimulationResultsBasedOn500Reps1000Obs()
</code></pre>

<hr>
<h2 id='reproduceTablesOfPaperMetaAnalysisForFamiliesOfExperiments'>reproduceTablesOfPaperMetaAnalysisForFamiliesOfExperiments</h2><span id='topic+reproduceTablesOfPaperMetaAnalysisForFamiliesOfExperiments'></span>

<h3>Description</h3>

<p>This function reproduces five of the output tables used in the systematic review paper 'Meta-analysis for Families of Experiments: A Systematic Review and Reproducibility Assessment'. It extracts the reported values for effect sizes, meta-analysis and descriptive statistics in the primary studies. It uses the descriptive statistics to re-calculate effect sizes and then performs a meta-analyses using the constructed effect sizes and compares the calculated values with the reported values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reproduceTablesOfPaperMetaAnalysisForFamiliesOfExperiments()
</code></pre>


<h3>Value</h3>

<p>list incl. the data presented in five of the tables presented in the paper.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rrData &lt;- reproduceTablesOfPaperMetaAnalysisForFamiliesOfExperiments()
# Reproduce Table 'Overall Mean Values of Effect Sizes Reported and Calculated':
xtable::xtable(rrData$MAStats)
# Reproduce Table 'Calculated and Reported Effect Sizes':
xtable::xtable(rrData$ESdata)
# Report values for 3 papers that reported per document
rrData$MAStatsTP1 &lt;- data.frame(rrData$MAStatsTP1, row.names = NULL)
rrData$ESTP1res &lt;- data.frame(rrData$ESTP1res, row.names = NULL)
xtable::xtable(rrData$MAStatsTP1)
xtable::xtable(rrData$ESTP1res)
# Report extra results for Study 8
# Reproduce Table 'Calculating r_PB Effect Size from Probabilities'
xtable::xtable(rrData$GH2015extra)
</code></pre>

<hr>
<h2 id='reproduceTableWithEffectSizesBasedOnMeanDifferences'>reproduceTableWithEffectSizesBasedOnMeanDifferences()</h2><span id='topic+reproduceTableWithEffectSizesBasedOnMeanDifferences'></span>

<h3>Description</h3>

<p>Function reproduces Table, which shows the effect sizes based on mean differences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reproduceTableWithEffectSizesBasedOnMeanDifferences()
</code></pre>


<h3>Author(s)</h3>

<p>Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>reproduceTableWithEffectSizesBasedOnMeanDifferences()
</code></pre>

<hr>
<h2 id='reproduceTableWithPossibleModeratingFactors'>reproduceTableWithPossibleModeratingFactors()</h2><span id='topic+reproduceTableWithPossibleModeratingFactors'></span>

<h3>Description</h3>

<p>Function reproduces Table with possible moderating factors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reproduceTableWithPossibleModeratingFactors()
</code></pre>


<h3>Author(s)</h3>

<p>Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>reproduceTableWithPossibleModeratingFactors()
</code></pre>

<hr>
<h2 id='reproduceTableWithSourceDataByCiolkowski'>reproduceTableWithSourceDataByCiolkowski</h2><span id='topic+reproduceTableWithSourceDataByCiolkowski'></span>

<h3>Description</h3>

<p>Function reproduces Table, which shows the effect sizes reported by Ciolkowski identifying the type of design used in each study.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reproduceTableWithSourceDataByCiolkowski()
</code></pre>


<h3>Author(s)</h3>

<p>Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>reproduceTableWithSourceDataByCiolkowski()
</code></pre>

<hr>
<h2 id='rSimulations'>rSimulations</h2><span id='topic+rSimulations'></span>

<h3>Description</h3>

<p>This function simulates many datasets from the same bivariate distribution to
investigate the distribution of correlations for specific sample sizes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rSimulations(
  mean,
  var,
  diff,
  r,
  N,
  reps,
  VarAdj = 0,
  seed = 123,
  returntSignificant = F,
  returndata = F,
  plothist = F
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rSimulations_+3A_mean">mean</code></td>
<td>
<p>The mean used for one of bivariate distributions - assumed to be the control condition in an experiment.</p>
</td></tr>
<tr><td><code id="rSimulations_+3A_var">var</code></td>
<td>
<p>The variance used for both treatment groups. It must be a real value greater than 0.</p>
</td></tr>
<tr><td><code id="rSimulations_+3A_diff">diff</code></td>
<td>
<p>This value is added to the parameter mean to specify the mean for the other bivariate distribution - assumed to be the treatment condition in an experiment.</p>
</td></tr>
<tr><td><code id="rSimulations_+3A_r">r</code></td>
<td>
<p>This specifies the correlation coefficient to be used for the bivariate normal distribution it must be a value in the range [-1,1].</p>
</td></tr>
<tr><td><code id="rSimulations_+3A_n">N</code></td>
<td>
<p>The number of observations in each simulated bivariate normal data set.</p>
</td></tr>
<tr><td><code id="rSimulations_+3A_reps">reps</code></td>
<td>
<p>The number of bivariate data sets that will be simulated.</p>
</td></tr>
<tr><td><code id="rSimulations_+3A_varadj">VarAdj</code></td>
<td>
<p>This value will be added to the variance of the treatment condition.</p>
</td></tr>
<tr><td><code id="rSimulations_+3A_seed">seed</code></td>
<td>
<p>This specifies the seed value for the simulations and allows the experiment to be repeated.</p>
</td></tr>
<tr><td><code id="rSimulations_+3A_returntsignificant">returntSignificant</code></td>
<td>
<p>If set to true the percentage of times the t-test delivered a value significant at the 0.05 level is reported (default returntSignificant=F).</p>
</td></tr>
<tr><td><code id="rSimulations_+3A_returndata">returndata</code></td>
<td>
<p>If set to FALSE, the function returns the summary information across all the replications  (default returndata=F). If set to TRUE the function outputs the r and variance ratio, and variance accuracy values generated in each replication.</p>
</td></tr>
<tr><td><code id="rSimulations_+3A_plothist">plothist</code></td>
<td>
<p>If set to T, the function outputs a histogram of the r-values, the varprop values and the accuracy values (default plothist=F).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>output If returndata=F, the output returns summary information about the average of r and the variance properties across the replicated data sets. If returndata=T, the function returns the r-values obtained for each of the simulated data sets to gather with the variance ratio, the variance accuracy measure and a dummy variable indicating whether a test of significance between the mean values was significant (which is indicated by the dummy variable being set to 1) or not (which is indicated by the dummy variable being set to 0)
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'># output=rSimulations(mean=0,var=1,diff=0,r=0.25,N=4,reps=10000)
# reduced reps to pass CRAN time limits
output &lt;- rSimulations(mean = 0, var = 1, diff = 0, r = 0.25, N = 4, reps = 1000)
output &lt;- signif(output, 4)
output
#  r.Mean r.Median  Var.r PercentNegative Mean.VarProp Variance.VarProp ...
# 1 0.2132   0.3128 0.3126           34.21       0.5036          0.06046 ...
# output=rSimulations(mean=0,var=1,diff=0.8,r=0.25,N=60,reps=10000,returntSignificant=TRUE)
# reduced reps to pass CRAN time limits
output &lt;- rSimulations(mean = 0, var = 1, diff = 0.8, r = 0.25, N = 60,
  reps = 1000, returntSignificant = TRUE)
output &lt;- signif(output, 4)
output
#   r.Mean r.Median   Var.r PercentNegative Mean.VarProp Variance.VarProp ...
# 1 0.2492   0.2534 0.01529            2.62       0.5009         0.003897 ...
output &lt;- rSimulations(mean = 0, var = 1, diff = 0, r = 0.25, N = 30, reps = 10, returndata = TRUE)
output
#     rvalues   VarProp VarAccuracy VarDiffAccuracy tSig
# 1  0.3981111 0.4276398   0.8630528       0.6974386    0
# 2  0.2104742 0.4994285   0.7812448       0.8224174    0
# 3  0.4252424 0.4933579   1.1568545       0.8866058    0
# 4  0.3502651 0.6004373   0.8710482       0.7628923    0
# 5  0.3845145 0.6029086   0.9618363       0.7998859    0
# 6  0.1397217 0.4201069   1.1817022       1.3582855    0
# 7  0.2311455 0.3894894   0.8322239       0.8594886    0
# 8  0.3725047 0.5985897   1.1742117       0.9938662    0
# 9  0.4881618 0.2712268   0.7585261       0.5723671    0
# 10 0.1568071 0.3936400   0.9869924       1.1143561    0

</code></pre>

<hr>
<h2 id='searchForIndustryRelevantGitHubProjects'>searchForIndustryRelevantGitHubProjects</h2><span id='topic+searchForIndustryRelevantGitHubProjects'></span>

<h3>Description</h3>

<p>Function searches for industry relevant software projects available from GitHub. The function was used to deliver data set of software projects in an NCBiR project. More details are described in a report: Lech Madeyski, “Training data preparation method,” tech. rep., code quest (research project NCBiR POIR.01.01.01-00-0792/16), 2019, as well as a paper: Tomasz Lewowski and Lech Madeyski, &quot;Creating evolving project data sets in software engineering&quot;, 2019.
If you use this function or the returned data set than please cite:
Tomasz Lewowski and Lech Madeyski, &quot;Creating evolving project data sets in software engineering&quot;, 2019
</p>


<h3>Usage</h3>

<pre><code class='language-R'>searchForIndustryRelevantGitHubProjects(
  myToken,
  earliestPushDate,
  latestCreationDate
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="searchForIndustryRelevantGitHubProjects_+3A_mytoken">myToken</code></td>
<td>
<p>A private token used to access GitHub</p>
</td></tr>
<tr><td><code id="searchForIndustryRelevantGitHubProjects_+3A_earliestpushdate">earliestPushDate</code></td>
<td>
<p>Only repositories which were pushed after this date will be included in the results (i.e., repositories for which the latest push was before this date will not be included in the results)</p>
</td></tr>
<tr><td><code id="searchForIndustryRelevantGitHubProjects_+3A_latestcreationdate">latestCreationDate</code></td>
<td>
<p>Only repositories which were created before this date will be included in the results (i.e., repositories created after this date will not be included in the results)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>selected GitHub projects
</p>


<h3>Author(s)</h3>

<p>Lech Madeyski and Tomasz Lewowski
</p>


<h3>Examples</h3>

<pre><code class='language-R'># to run this function you need to use your own token as a parameter of the function
# use your own token as the first parameter of the function
# searchForIndustryRelevantGitHubProjects("...", "2019-03-01", "2018-08-01")
</code></pre>

<hr>
<h2 id='simulate2GExperimentData'>simulate2GExperimentData</h2><span id='topic+simulate2GExperimentData'></span>

<h3>Description</h3>

<p>The function returns a two group data set based on one of four different distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulate2GExperimentData(
  mean,
  sd,
  diff,
  GroupSize,
  type = "n",
  ExpAdj = 0,
  StdAdj = 0,
  BlockEffect = 0,
  BlockStdAdj = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulate2GExperimentData_+3A_mean">mean</code></td>
<td>
<p>The mean (or rate for gamma data) of the baseline distribution</p>
</td></tr>
<tr><td><code id="simulate2GExperimentData_+3A_sd">sd</code></td>
<td>
<p>The standard deviation (or shape for gamma data) of the baseline distribution</p>
</td></tr>
<tr><td><code id="simulate2GExperimentData_+3A_diff">diff</code></td>
<td>
<p>The adjustment to the baseline mean for the alternative distribution.</p>
</td></tr>
<tr><td><code id="simulate2GExperimentData_+3A_groupsize">GroupSize</code></td>
<td>
<p>An integer defining the number of data items in each group.</p>
</td></tr>
<tr><td><code id="simulate2GExperimentData_+3A_type">type</code></td>
<td>
<p>A string identifying the distribution used to simulate the data: 'n' for normal, 'ln' for log-normal, 'g' for gamma, 'lap' for Laplace.</p>
</td></tr>
<tr><td><code id="simulate2GExperimentData_+3A_expadj">ExpAdj</code></td>
<td>
<p>An additional adjustment factor that is added to both the mean value. Defaults to zero.</p>
</td></tr>
<tr><td><code id="simulate2GExperimentData_+3A_stdadj">StdAdj</code></td>
<td>
<p>An additional adjustment factor that is added to both group variance (or rate for gamma data). Defaults to zero.</p>
</td></tr>
<tr><td><code id="simulate2GExperimentData_+3A_blockeffect">BlockEffect</code></td>
<td>
<p>An additional factor that is added to the mean of the both groups (shape for the gamma distribution). Defaults to zero.</p>
</td></tr>
<tr><td><code id="simulate2GExperimentData_+3A_blockstdadj">BlockStdAdj</code></td>
<td>
<p>An additional factor that is added to the variance of both groups (shape for the gamma distribution). Defaults to zero.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A table with two columns (BaselineData and AlternativeData) holding the data for each group. For lognormal data an additional two columns are added which return the log transformed data.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(236)
simulate2GExperimentData(mean = 0, sd = 1, diff = 0.5, GroupSize = 10,
  type = "n", ExpAdj = 0, StdAdj = 0, BlockEffect = 0, BlockStdAdj = 0)
# A tibble: 10 x 2
#    BaselineData AlternativeData
#           &lt;dbl&gt;           &lt;dbl&gt;
#          &lt;dbl&gt;           &lt;dbl&gt;
# 1      -0.285           -0.255
# 2      -0.972            0.112
# 3      -0.549            1.36
# 4       1.05             1.47
# 5      -0.267            0.107
# 6      -0.137            0.395
# 7       1.30             1.27
# 8      -0.722            1.70
# 9      -0.525            0.264
# 10      -0.0222           0.787
set.seed(345)
simulate2GExperimentData(mean = 0, sd = 1, diff = 0.5, GroupSize = 10,
  type = "l", ExpAdj = 0, StdAdj = 0, BlockEffect = 0, BlockStdAdj = 0)
# A tibble: 10 x 4
#    BaselineData AlternativeData transBaselineData transAlternativeData
#          &lt;dbl&gt;           &lt;dbl&gt;             &lt;dbl&gt;                &lt;dbl&gt;
# 1        0.456          10.7             -0.785                 2.37
# 2        0.756           0.407           -0.280                -0.900
# 3        0.851           0.705           -0.161                -0.350
# 4        0.748           2.27            -0.291                 0.818
# 5        0.935           4.07            -0.0675                1.40
# 6        0.531           0.405           -0.634                -0.903
# 7        0.395           2.91            -0.928                 1.07
# 8        5.53            4.69             1.71                  1.55
# 9        5.23            0.602            1.65                 -0.508
# 10        6.11            2.23             1.81                  0.802

</code></pre>

<hr>
<h2 id='simulate4GExperimentData'>simulate4GExperimentData</h2><span id='topic+simulate4GExperimentData'></span>

<h3>Description</h3>

<p>The function returns a four group data set based on one of four different distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulate4GExperimentData(
  mean,
  sd,
  diff,
  GroupSize,
  type = "n",
  ExpAdj = 0,
  StdAdj = 0,
  BlockEffect = 0,
  BlockStdAdj = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulate4GExperimentData_+3A_mean">mean</code></td>
<td>
<p>The mean (or rate for gamma data) of the baseline distribution</p>
</td></tr>
<tr><td><code id="simulate4GExperimentData_+3A_sd">sd</code></td>
<td>
<p>The standard deviation (or shape for gamma data) of the baseline distribution</p>
</td></tr>
<tr><td><code id="simulate4GExperimentData_+3A_diff">diff</code></td>
<td>
<p>The adjustment to the baseline mean for the alternative distribution.</p>
</td></tr>
<tr><td><code id="simulate4GExperimentData_+3A_groupsize">GroupSize</code></td>
<td>
<p>An integer defining the number of data items in each group.</p>
</td></tr>
<tr><td><code id="simulate4GExperimentData_+3A_type">type</code></td>
<td>
<p>A string identifying the distrubtion used to simulate the data: 'n' for normal, 'l' for log-normal, 'g' for gamma, 'lap' for Laplace.</p>
</td></tr>
<tr><td><code id="simulate4GExperimentData_+3A_expadj">ExpAdj</code></td>
<td>
<p>An additional adjument factor that is added to both the mean values. Defaults to zero.</p>
</td></tr>
<tr><td><code id="simulate4GExperimentData_+3A_stdadj">StdAdj</code></td>
<td>
<p>An aditional adjustment factor that is added to the second group variance (or rate for gamma data). Defaults to zero.</p>
</td></tr>
<tr><td><code id="simulate4GExperimentData_+3A_blockeffect">BlockEffect</code></td>
<td>
<p>An additional factor that is added to the mean of the second group groups (shape for the gamma distribution). Defaults to zero.</p>
</td></tr>
<tr><td><code id="simulate4GExperimentData_+3A_blockstdadj">BlockStdAdj</code></td>
<td>
<p>An additional factor that is added to the variance of the second group (shape for the gamma distribution). Defaults to zero.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A table with four columns (BaselineData.B1, AlternativeData.B1,BaselineData.B2, AlternativeData.B2,) holding the data for each group and block. For lognormal data an additional four columns are added which return the log transformed data for each group.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(246)
simulate4GExperimentData(mean = 0, sd = 1, diff = 0.5, GroupSize = 5,
  type = "n", ExpAdj = 0, StdAdj = 0, BlockEffect = 0.5, BlockStdAdj = 0)
# A tibble: 5 x 4
#  BaselineData.B1 AlternativeData.B1 BaselineData.B2 AlternativeData.B2
#            &lt;dbl&gt;              &lt;dbl&gt;           &lt;dbl&gt;              &lt;dbl&gt;
# 1          0.533               1.84            0.749              3.98
# 2          0.251               2.03            1.56               1.09
# 3         -0.290               0.929           0.213              3.94
# 4         -1.48                1.17            1.13               0.106
# 5          0.0340              0.895           0.399              0.879
as.data.frame(
  simulate4GExperimentData(
    mean=0, sd=1, diff=0.5, GroupSize=5, type='l', ExpAdj=0, StdAdj=0,
    BlockEffect = 0.5, BlockStdAdj = 0))
#  BaselineData.B1 AlternativeData.B1 transBaselineData.B1 transAlternativeData.B1
#1       1.4019869           1.049158            0.3378905               0.0479875
#2       3.8514120           0.769227            1.3484398              -0.2623692
#3       6.5162726           1.574126            1.8743025               0.4537002
#4       1.3309218           1.082774            0.2858718               0.0795259
#5       0.2772234           1.630194           -1.2829316               0.4886992
#  BaselineData.B2 AlternativeData.B2 transBaselineData.B2 transAlternativeData.B2
#1       5.4656049          4.6095688            1.6984748               1.5281343
#2       1.6149559          2.0244244            0.4793077               0.7052854
#3       1.7718620          0.5504016            0.5720310              -0.5971070
#4       0.6774067          1.5434812           -0.3894834               0.4340404
#5       0.4507284          5.4987830           -0.7968903               1.7045268
</code></pre>

<hr>
<h2 id='simulateRandomizedBlockDesignEffectSizes'>simulateRandomizedBlockDesignEffectSizes</h2><span id='topic+simulateRandomizedBlockDesignEffectSizes'></span>

<h3>Description</h3>

<p>This simulates a two-block and two-treatment design based on one of four distributions, and finds the values of ktau and Cliffs d and their variances. It simulates a randomised blocks experiment with two treatment groups and two control groups each of which being divided into two blocks. It assumes equal group sizes but  group spread (standard deviation can be changed, see StAdj). It returns values of both parametric and non-parametric effect sizes and their variance and significance. For the logarithmic distribution it calculates effect sizes based on the log transformed data as well as the raw data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulateRandomizedBlockDesignEffectSizes(
  mean,
  sd,
  diff,
  N,
  type = "n",
  alpha = 0.05,
  Blockmean = 0,
  BlockStdAdj = 0,
  StdAdj = 0,
  AlwaysTwoSidedTests = FALSE,
  ReturnData = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulateRandomizedBlockDesignEffectSizes_+3A_mean">mean</code></td>
<td>
<p>The default value for all groups which can be changed for the two treatment groups using the parameter diff and for the two block 2 groups using the parameter Blockmean</p>
</td></tr>
<tr><td><code id="simulateRandomizedBlockDesignEffectSizes_+3A_sd">sd</code></td>
<td>
<p>The default spread used for all four groups unless adjusted by the StdAdj. It must be a real value greater than 0.</p>
</td></tr>
<tr><td><code id="simulateRandomizedBlockDesignEffectSizes_+3A_diff">diff</code></td>
<td>
<p>This is added to the parameter mean to obtain the required mean for treatment groups. It can be a real value and can take the value zero.</p>
</td></tr>
<tr><td><code id="simulateRandomizedBlockDesignEffectSizes_+3A_n">N</code></td>
<td>
<p>this is the number of observations in each group. It must be an integer greater than 3.</p>
</td></tr>
<tr><td><code id="simulateRandomizedBlockDesignEffectSizes_+3A_type">type</code></td>
<td>
<p>this specifies the underlying distribution used to generate the data. it takes the values 'n' for a normal distribution, 'l' for lognormal distribution,'g' for a gamma distribution, 'lap' for a Laplace distribution.</p>
</td></tr>
<tr><td><code id="simulateRandomizedBlockDesignEffectSizes_+3A_alpha">alpha</code></td>
<td>
<p>The level used for statistical tests (default 0.05).</p>
</td></tr>
<tr><td><code id="simulateRandomizedBlockDesignEffectSizes_+3A_blockmean">Blockmean</code></td>
<td>
<p>if &gt;0 an adjustment made to both group means in Block 2</p>
</td></tr>
<tr><td><code id="simulateRandomizedBlockDesignEffectSizes_+3A_blockstdadj">BlockStdAdj</code></td>
<td>
<p>if &gt;0, an adjustment that can be made to the sd of each group in block 2</p>
</td></tr>
<tr><td><code id="simulateRandomizedBlockDesignEffectSizes_+3A_stdadj">StdAdj</code></td>
<td>
<p>this specifies the extent of variance instability introduced by the treatment and if &gt;0 will be used to amend the sd parameter for both treatment groups. This value must be positive and less than 0.5</p>
</td></tr>
<tr><td><code id="simulateRandomizedBlockDesignEffectSizes_+3A_alwaystwosidedtests">AlwaysTwoSidedTests</code></td>
<td>
<p>Logical varable (default FALSE) if TRUE the
function always performs two-sided tests. Otherwise if the parameter diff is
not equal to zero, the function performs one-sided tests.</p>
</td></tr>
<tr><td><code id="simulateRandomizedBlockDesignEffectSizes_+3A_returndata">ReturnData</code></td>
<td>
<p>Logical variable, If TRUE, the function simply returns the
generated data. If false (which is default value) the function returns
various effect sizes and whether the effect sizes are statistically
significant.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame incl. either the non-parametric and parametric effect
sizes and whether the effect sizes are significant at the 0.05 level or the
generated data depending on the value of the ReturnData parameter.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
as.data.frame(
  simulateRandomizedBlockDesignEffectSizes(
    mean = 0, sd = 1, diff = .5, N = 10, type = "n", alpha = 0.05,
    Blockmean = 0.5, BlockStdAdj = 0, StdAdj = 0))
#  N phat    phat.var  phat.df phat.test  phat.pvalue phat.sig phat.ci.upper phat.ci.lower    d
# 1 40 0.79 0.005866667 30.15715  3.786189 0.0003403047     TRUE             1     0.6600213 0.58
#     vard d.sig d.ci.lower d.ci.upper       cor       sqse       ctvar n1 n2 sigCVt sigCVn
# 1 0.02430788  TRUE  0.2775601          1 0.3052632 0.01315789 0.006953352 20 20   TRUE   TRUE
#    ttest.sig     ES  Variance   StdES BlockEffect MedianDiff
# 1      TRUE 0.9402999 0.7829385 1.06268    0.307119   1.313642
set.seed(123)
as.data.frame(
  simulateRandomizedBlockDesignEffectSizes(
    mean = 0, sd = 1, diff = 0.5, N = 10, type = "n", alpha = 0.05,
    Blockmean = 0.5, BlockStdAdj = 0, StdAdj = 0, AlwaysTwoSidedTests = TRUE)
    )
#   N phat    phat.var  phat.df phat.test  phat.pvalue phat.sig phat.ci.upper phat.ci.lower
# 1 40 0.79 0.005866667 30.15715  3.786189 0.0006806094     TRUE      0.946392      0.633608
#     d       vard d.sig d.ci.lower d.ci.upper       cor       sqse       ctvar n1 n2 sigCVt
# 1 0.58 0.02430788  TRUE  0.2135334  0.8033737 0.3052632 0.01315789 0.006953352 20 20   TRUE
#  ttest.sig        ES  Variance   StdES BlockEffect MedianDiff
# 1      TRUE 0.9402999 0.7829385 1.06268    0.307119   1.313642
set.seed(123)
as.data.frame(
  simulateRandomizedBlockDesignEffectSizes(
    mean = 0, sd = 1, diff = .5, N = 10, type = "l", alpha = 0.05,
    Blockmean = 0.5, BlockStdAdj = 0, StdAdj = 0, ReturnData = TRUE))
#   BaselineData.B1 AlternativeData.B1 transBaselineData.B1 transAlternativeData.B1
# 1        0.5709374          5.6073700          -0.56047565              1.72408180
# 2        0.7943926          2.3627208          -0.23017749              0.85981383
# 3        4.7526783          2.4615013           1.55870831              0.90077145
# 4        1.0730536          1.8416883           0.07050839              0.61068272
# 5        1.1380175          0.9456894           0.12928774             -0.05584113
# 6        5.5570366          9.8445021           1.71506499              2.28691314
# 7        1.5855260          2.7124451           0.46091621              0.99785048
# 8        0.2822220          0.2307046          -1.26506123             -1.46661716
# 9        0.5031571          3.3246217          -0.68685285              1.20135590
# 10       0.6404002          1.0275821          -0.44566197              0.02720859
#   BaselineData.B2 AlternativeData.B2 transBaselineData.B2 transAlternativeData.B2
# 1        0.5667575           4.163950           -0.5678237               1.4264642
# 2        1.3258120           2.023702            0.2820251               0.7049285
# 3        0.5909615           6.653384           -0.5260044               1.8951257
# 4        0.7954150           6.541284           -0.2288912               1.8781335
# 5        0.8824622           6.181624           -0.1250393               1.8215811
# 6        0.3052289           5.412117           -1.1866933               1.6886403
# 7        3.8106015           4.729964            1.3377870               1.5539177
# 8        1.9220131           2.555092            0.6533731               0.9380883
# 9        0.5282757           2.001781           -0.6381369               0.6940373
# 10       5.7765980           1.858053            1.7538149               0.6195290
</code></pre>

<hr>
<h2 id='simulateRandomizedDesignEffectSizes'>simulateRandomizedDesignEffectSizes</h2><span id='topic+simulateRandomizedDesignEffectSizes'></span>

<h3>Description</h3>

<p>This simulates one of four data distributions (normal, log-normal, gamma and Laplace), and finds the values of phat and Cliffs d and their variances. It assumes equal group sizes. It returns values of the effect sizes and their variance for a simulated randomized experiment with two treatments.  It returns whether or not each non-parametric effect size was significant. It also returns the parametric (standardized and unstandardized) Effect Size and the whether the t-test was significant.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulateRandomizedDesignEffectSizes(
  mean,
  sd,
  diff,
  N,
  type = "n",
  StdAdj = 0,
  alpha = 0.05,
  AlwaysTwoSidedTests = FALSE,
  Return.Data = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulateRandomizedDesignEffectSizes_+3A_mean">mean</code></td>
<td>
<p>The mean used for one of the treatment groups (this is the rate for the gamma data)</p>
</td></tr>
<tr><td><code id="simulateRandomizedDesignEffectSizes_+3A_sd">sd</code></td>
<td>
<p>The spread used for both treatment groups. It mus be a real value greater than 0 (this is the shape for the gamma data).</p>
</td></tr>
<tr><td><code id="simulateRandomizedDesignEffectSizes_+3A_diff">diff</code></td>
<td>
<p>This is added to the parameter mean, to define the mean of the other treatment group. It can be a real value avd can take the value zero.</p>
</td></tr>
<tr><td><code id="simulateRandomizedDesignEffectSizes_+3A_n">N</code></td>
<td>
<p>this is the number of observations in each group. It must be an integer greater than 3.</p>
</td></tr>
<tr><td><code id="simulateRandomizedDesignEffectSizes_+3A_type">type</code></td>
<td>
<p>this specifies the underlying distribution used to generate the data. it takes the values 'n' for a normal distribution, 'l' for lognormal distribution,'g' for a gamma distribution, 'lap' for a Laplace distribution.</p>
</td></tr>
<tr><td><code id="simulateRandomizedDesignEffectSizes_+3A_stdadj">StdAdj</code></td>
<td>
<p>this specifies the extent of variance instability to be introduced.</p>
</td></tr>
<tr><td><code id="simulateRandomizedDesignEffectSizes_+3A_alpha">alpha</code></td>
<td>
<p>the level for all statistical tests (default 0.05)</p>
</td></tr>
<tr><td><code id="simulateRandomizedDesignEffectSizes_+3A_alwaystwosidedtests">AlwaysTwoSidedTests</code></td>
<td>
<p>if set to FALSE (i.e. default) the algorithms uses one-sided tests if diff!=0 and two-sided tests otherwise. If set to TRUE the algorithm always uses two-sided tests.</p>
</td></tr>
<tr><td><code id="simulateRandomizedDesignEffectSizes_+3A_return.data">Return.Data</code></td>
<td>
<p>if set to true the algorithm returns the data not the effect sizes (default FALSE).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame incl. the non-parametric and parametric effect sizes and whether the effect sizes are significant at the specified alpha level. For log-normal data the function returns the effect sizes for the transformed data.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
as.data.frame(
  simulateRandomizedDesignEffectSizes(
    mean = 0, sd = 1, diff = 0.8, N = 10, type = "n", StdAdj = 0))
#   phat    varphat   dfphat sigphat   d       vard sigd       cor     varcor sigCVt  t.value
# 1 0.75 0.01522222 17.46405    TRUE 0.5 0.06237576 TRUE 0.2631579 0.01754995   TRUE 2.095142
#      t.se     t.df      t.lb t.ub t.sig        ES  Variance     StdES  MedDiff
# 1 0.4457915 17.87244 0.1606665  Inf  TRUE 0.9339963 0.9936502 0.9369759 1.260127
set.seed(123)
as.data.frame(
  simulateRandomizedDesignEffectSizes(
    mean = 0, sd = 1, diff = 0.8, N = 10, type = "n", StdAdj = 0,
    AlwaysTwoSidedTests = TRUE))
#  phat    varphat   dfphat sigphat   d       vard  sigd       cor
# 1 0.75 0.01522222 17.46405   FALSE 0.5 0.06237576 FALSE 0.2631579
#      varcor sigCVt  t.value      t.se     t.df         t.lb     t.ub t.sig
# 1 0.01754995  FALSE 2.095142 0.4457915 17.87244 -0.003056196 1.871049 FALSE
#         ES  Variance     StdES  MedDiff
# 1 0.9339963 0.9936502 0.9369759 1.260127
set.seed(456)
as.data.frame(
  simulateRandomizedDesignEffectSizes(
    mean = 0, sd = 1, diff = 0.8, N = 10, type = "l", StdAdj = 0))
# phat     varphat  dfphat sigphat    d      vard sigd       cor     varcor
# 1 0.87 0.008466667 11.1111    TRUE 0.74 0.0350497 TRUE 0.3894737 0.01039674
#  sigCVt  t.value     t.se     t.df     t.lb t.ub t.sig       ES Variance
# 1   TRUE 3.599375 2.148297 9.312472 3.809448  Inf  TRUE 7.732529 23.07591
#    StdES MedDiff transttest  EStrans StdEStrans VarTrans
# 1 1.60969 7.77893   0.998772 1.731323   1.598065 1.173728

set.seed(123)
as.data.frame(
  simulateRandomizedDesignEffectSizes(
    mean = 0, sd = 1, diff = 0.8, N = 10, type = "n", StdAdj = 0,
    Return.Data = TRUE))
#   BaselineData AlternativeData
# 1   -0.69470698       1.0533185
# 2   -0.20791728       0.7714532
# 3   -1.26539635       0.7571295
# 4    2.16895597       2.1686023
# 5    1.20796200       0.5742290
# 6   -1.12310858       2.3164706
# 7   -0.40288484      -0.7487528
# 8   -0.46665535       1.3846137
# 9    0.77996512       0.9238542
# 10  -0.08336907       1.0159416
</code></pre>

<hr>
<h2 id='testfunctionParameterChecks'>testfunctionParameterChecks</h2><span id='topic+testfunctionParameterChecks'></span>

<h3>Description</h3>

<p>This is a helper function that ensures parameter values used
for performing special statistical tests are valid.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>testfunctionParameterChecks(alternative, alpha, stderr)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="testfunctionParameterChecks_+3A_alternative">alternative</code></td>
<td>
<p>The type of statistical test. Valid values are one of
c('two.sided', 'greater', 'less')</p>
</td></tr>
<tr><td><code id="testfunctionParameterChecks_+3A_alpha">alpha</code></td>
<td>
<p>The test level. Valid values are between 0.0001 and 0.2</p>
</td></tr>
<tr><td><code id="testfunctionParameterChecks_+3A_stderr">stderr</code></td>
<td>
<p>The standard error of a parameter whose confidence intervals
is to be calculated</p>
</td></tr>
</table>


<h3>Value</h3>

<p>'Success' or an error message.
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#reproducer:::testfunctionParameterChecks(alternative='larger',alpha=0.1,stderr=0.002)
#Error in testfunctionParameterChecks(alternative = 'larger', alpha = 0.1) :
#  Invalid alternative parameter, choose one of two.sided, greater or less
reproducer:::testfunctionParameterChecks(alternative='greater',alpha=0.1,stderr=0.002)
#[1] 'Success'
#reproducer:::testfunctionParameterChecks(alternative='greater',alpha=0.1,stderr=0.000)
#Error in testfunctionParameterChecks(alternative = 'greater', alpha = 0.1,  :
#  Improbably small variance, data are essentially constant
</code></pre>

<hr>
<h2 id='transformHgtoR'>transformHgtoR</h2><span id='topic+transformHgtoR'></span>

<h3>Description</h3>

<p>The functions transforms a vector of Hedges g values to their equivalent point bi-serial values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transformHgtoR(g, Nc, Nt)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="transformHgtoR_+3A_g">g</code></td>
<td>
<p>A vector of Hegdes g values.</p>
</td></tr>
<tr><td><code id="transformHgtoR_+3A_nc">Nc</code></td>
<td>
<p>A vector of numbers identifying the number of control condition participants in each group</p>
</td></tr>
<tr><td><code id="transformHgtoR_+3A_nt">Nt</code></td>
<td>
<p>A vector of numbers identifying the number of treatment condition participants in each group</p>
</td></tr>
</table>


<h3>Value</h3>

<p>value of point biserial r
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>transformHgtoR(0.4, 20, 20)
# [1] 0.1961161
</code></pre>

<hr>
<h2 id='transformHgtoZr'>transformHgtoZr</h2><span id='topic+transformHgtoZr'></span>

<h3>Description</h3>

<p>The functions transforms a vector of Hedges g values to their normal approximation of point bi-serial values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transformHgtoZr(g, Nc, Nt)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="transformHgtoZr_+3A_g">g</code></td>
<td>
<p>value of Hedges' g</p>
</td></tr>
<tr><td><code id="transformHgtoZr_+3A_nc">Nc</code></td>
<td>
<p>the number of observations (participants) in the first (control) group</p>
</td></tr>
<tr><td><code id="transformHgtoZr_+3A_nt">Nt</code></td>
<td>
<p>the number of observations (participants) in the second (treatment) group</p>
</td></tr>
</table>


<h3>Value</h3>

<p>value of normal approximation of point biserial r
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>transformHgtoZr(0.5, 20, 20)
# [1] 0.2474665
</code></pre>

<hr>
<h2 id='transformRtoHg'>transformRtoHg</h2><span id='topic+transformRtoHg'></span>

<h3>Description</h3>

<p>This function coverts a vector of point bi-serial r values with associated sample size information back to the mean difference effect size Hedges g.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transformRtoHg(r, Nc, Nt)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="transformRtoHg_+3A_r">r</code></td>
<td>
<p>A vector of point bi-serial correlation values.</p>
</td></tr>
<tr><td><code id="transformRtoHg_+3A_nc">Nc</code></td>
<td>
<p>A vector of the number of observations in the control condition for the related experiments.</p>
</td></tr>
<tr><td><code id="transformRtoHg_+3A_nt">Nt</code></td>
<td>
<p>A vector of the number of observations in the treatment condition for the related experiments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>value of Hedges' g
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>transformRtoHg(c(0.4, 0.2), c(20, 20), c(20, 20))
# [1] 0.8728716 0.4082483
</code></pre>

<hr>
<h2 id='transformRtoZr'>transformRtoZr</h2><span id='topic+transformRtoZr'></span>

<h3>Description</h3>

<p>The function transforms a vector of point biserial r values to their normal approximation. It also works for the correlation r.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transformRtoZr(r)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="transformRtoZr_+3A_r">r</code></td>
<td>
<p>A vector of r-values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>value of normal approximation of point biserial r
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>reproducer::transformRtoZr(0.4)
# [1] 0.4236489
Zr &lt;- reproducer::transformRtoZr(c(0.4, 0.2))
Zr
# [1] 0.4236489 0.2027326
</code></pre>

<hr>
<h2 id='transformZrtoHg'>transformZrtoHg</h2><span id='topic+transformZrtoHg'></span>

<h3>Description</h3>

<p>Transforms Zr to Hedge's g.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transformZrtoHg(Zr, Nc, Nt)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="transformZrtoHg_+3A_zr">Zr</code></td>
<td>
<p>the normal variate</p>
</td></tr>
<tr><td><code id="transformZrtoHg_+3A_nc">Nc</code></td>
<td>
<p>the number of observations (participants) in the first (control) group</p>
</td></tr>
<tr><td><code id="transformZrtoHg_+3A_nt">Nt</code></td>
<td>
<p>the number of observations (participants) in the second (treatment) group</p>
</td></tr>
</table>


<h3>Value</h3>

<p>value of Hedges' g
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>transformZrtoHg(0.5, 20, 20)
# [1] 1.042191
</code></pre>

<hr>
<h2 id='transformZrtoHgapprox'>transformZrtoHgapprox</h2><span id='topic+transformZrtoHgapprox'></span>

<h3>Description</h3>

<p>This function provides an approximate transformation from Zr to Hedges g when the number of observations in the treatment and control group are unknown. It is also used to allow the forest plots to display Hedge's g when they are based on r. It is necessary because the transformation function in the forest plot function does not allow any parameters other than effect size used. The function assumes that Nc=Nt and gives the same results as transformZrtoHg when Nc=Nt.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transformZrtoHgapprox(Zr)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="transformZrtoHgapprox_+3A_zr">Zr</code></td>
<td>
<p>A vector of normalised point bi-serial values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>approx. value of Hedges' g
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>transformZrtoHgapprox(c(0.4, 0.2))
# [1] 0.8215047 0.4026720
</code></pre>

<hr>
<h2 id='transformZrtoR'>transformZrtoR</h2><span id='topic+transformZrtoR'></span>

<h3>Description</h3>

<p>The function transforms a vector of standardized normal variates to their equivalent r-values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transformZrtoR(zr)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="transformZrtoR_+3A_zr">zr</code></td>
<td>
<p>A vector of standard normal variates.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>value of point biserial r
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>transformZrtoR(0.4236489)
# [1] 0.4
transformZrtoR(c(0.4236489, 0.2027326))
# [1] 0.4 0.2
</code></pre>

<hr>
<h2 id='varStandardizedEffectSize'>varStandardizedEffectSize</h2><span id='topic+varStandardizedEffectSize'></span>

<h3>Description</h3>

<p>Function calculates the exact variance of a standardized effect size based on the relationship between t and the standardized effect size, see Morris and DeShon, Combining Effect Size Estimates in Meta-Analysis With Repeated Measures and Independent-Groups Designs, Psychological Methods, 7 (1), pp 105-125.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varStandardizedEffectSize(d, A, f, returnVarg = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="varStandardizedEffectSize_+3A_d">d</code></td>
<td>
<p>An unadjusted standardized effect size</p>
</td></tr>
<tr><td><code id="varStandardizedEffectSize_+3A_a">A</code></td>
<td>
<p>The squared constant linking t and d i.e. t*sqrt(A)=d</p>
</td></tr>
<tr><td><code id="varStandardizedEffectSize_+3A_f">f</code></td>
<td>
<p>The degrees of freedom of the t value</p>
</td></tr>
<tr><td><code id="varStandardizedEffectSize_+3A_returnvarg">returnVarg</code></td>
<td>
<p>if set to TRUE return the variance of the small sample size adjusted standardized effect size (g), otherwise returns var(d) where d is the input parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>if returnVarg if set to TRUE, return var(g) otherwise var(d)
</p>


<h3>Author(s)</h3>

<p>Barbara Kitchenham and Lech Madeyski
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d &lt;- 0.5
varStandardizedEffectSize(d, 2 / 20, 38, returnVarg = FALSE)
# [1]  0.1047567
varStandardizedEffectSize(d, 2 / 20, 38, returnVarg = TRUE)
# [1] 0.1090516
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
